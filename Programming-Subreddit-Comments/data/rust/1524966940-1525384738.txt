[removed]
Yes, I know that everyone learned it this semester, and thats fine. I go to UMD and am very profficient in Rust, I kind of wish that someone would have asked me for help about designing the slides (which I saw some issues in) and project. Overall it is very good work IMO. My friends in 330 feel like they dont really understand it though, but its not like people felt differently about Prolog :p Good job this 
It was not hard in that they had already decided to stop teaching prolog, since it is dated and not really practical. Rust's ownership is unique enough to warrant teaching in a class about programming language paradigms. Plus it's new and it's practical. The only other real choice was Go, but it wasn't interesting enough to count as a model for a "paradigm"
&gt; I could add the population size, but it might bump up the crate size too much adding another field. Ah, that's a great point. &gt; I can add a search for the nearest x locations, it's already part of the kdtree crate I'm using. Awesome that you've added it. One thing that might be interesting to consider is that using `Vec` for everything forces people to know how many elements they need to begin with, but using an iterator (e.g. a wrapper around `KdTree::iter_nearest`) lets the user keep iterating until they've found what they want. &gt; I was using an f64 for lat and long, if I change it to f32 the size goes down to 19M and you still have enough precision. Thanks for making me think of that. Just pushed a new version with your recommendations. Cool! Another possibility for pushing the size down even more would be trading less binary space for more initialization time: the included data could be compressed in the binary, and then decompressed before deserialization. Compressing the file with `gzip` pushes it down to 6.1MB for me, and there's various crates for various algorithms available on crates.io.
It would be nice if we could do the compiler project in Rust.
Wrong. Haskell code was proved, then it was 1-to-1 ported to C, *then* it was also proved that C code behaves exactly like Haskell code.
I can answer the last question. One of motivation of developing theorem proving software (usually called proof assistant) is exactly to address such subtle errors in normal mathematical proofs. Proofs verified by proof assistants are immune to such errors. (At least, much less error-prone than normal ones.) For example, there were worries of such errors in proofs of Four color theorem and Kepler conjecture. Now both proofs are re-done in proof assistants and mathematicians are much more confident they are correct.
`String::new("myString").as_str()` is of type `&amp;str`, whereas `&amp;String::new("myString")` is of type `&amp;String` which is able to to be used as if it were an `&amp;str` because it implements `Deref&lt;Item=str&gt;`
[removed]
Ah finally I can see another Rust user from Vietnam!
Come join us, we have a group of Rust users back home [http://chat.ruby.org.vn/](http://chat.ruby.org.vn/) \(the name is Ruby Vietnam but we have #rustlang section :D\)
Why is it so difficult to verify post-hock, and what does designing for verification entail?
(ok this thread got me to finally bite the bullet and get my toy language lexer working on wasm like I've wanted to do for a while It works http://cad97.com/nafi/ I am still sort of amazed at how easy it was though)
What happens if you attach a debugger to the application before running it?
If i have a string with numbers separated by a space whats the best way to split and parse them all (minimal error checking for now). for example in C# i would write. given args[0] == "4 9 7 8 3 2" int[] numbers = args[0].Split(' ').Select(int.Parse).ToArray(); how would i write this in rust I prefer lambda statements for clarity. 
Nice to see that people are using web-view :) &gt; Note: I maintain my own version of zserge/webview and Boscop/web-view, because I want to add some customized titlebar on macOS, and my code is ugly enough to create a PR on these repos. I'd be interested in merging that, but I don't have a mac so I can't test it.. But I invite you to do a PR and then we can continue from there :)
If you have a JIT debugger installed (like Visual Studio), you should get an option to debug the program in that error dialog. If that option is missing, you may have to disable Windows Error Reporting in the local group policy editor. Stack overflows are not panics, so that is not a bug. We should still be able to print a backtrace on Windows though.
I had the same problem, I wasn't getting a stacktrace for non-main threads. It works with this: use std::any::Any; fn print_panic_payload(ctx: &amp;str, payload: &amp;(Any + Send + 'static)) { let d = format!("{:?}", payload); let s = if let Some(s) = payload.downcast_ref::&lt;String&gt;() { &amp;s } else if let Some(s) = payload.downcast_ref::&lt;&amp;str&gt;() { s } else { // "PAYLOAD IS NOT A STRING" d.as_str() }; println!("{}: PANIC OCCURED: {}", ctx, s); } fn main() { use std::panic; use error_chain::Backtrace; panic::set_hook(box |panic_info| { print_panic_payload("set_hook", panic_info.payload()); if let Some(location) = panic_info.location() { println!("LOCATION: {}:{}", location.file(), location.line()); } else { println!("NO LOCATION INFORMATION"); } println!("{:?}", Backtrace::new()); }); // ... } Btw, most of the time it's actually enough info to print the `panic_info.location()`. Also I give all my threads descriptive names: let thread_launchpad = thread::Builder::new().name("launchpad".to_string()).spawn(move || {
Hey, boscop, just a quick heads-up: **occured** is actually spelled **occurred**. You can remember it by **two cs, two rs**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
In basically the same way. You can find these pretty easily in the [reference documentation](https://doc.rust-lang.org/std/index.html). fn main() { let args = vec!["4 9 7 8 3 2"]; let numbers = args[0].split(' ') .map(|s| s.parse().expect("could not parse number")) .collect::&lt;Vec&lt;i32&gt;&gt;(); println!("{:?}", numbers); } 
Hey, nice to meet you here, you made a great Rust binding! My customized code for the macOS colored titlebar included changes in both webview and web\-view, that's why it's a bit hard to create a PR. I'll make some cleanup and submit PR in both repos :D 
Wow i was closer then i thought let numbers:Vec&lt;&amp;str&gt; = args[1].split(' ').collect(); let numbers = numbers.iter().map(|f|f.parse::&lt;i32&gt;().unwrap() ); missing the collect. Thank you
&gt; which is also able to to be used as if it were an &amp;str Except in generic contexts, which is why sometimes `string.as_str()` or the shorter but more cryptic `&amp;*string` is necessary.
That depends on how you define "character".
I'm not aware of any such PR. The status of AVR is that the Rust team is (preliminarily) OK with both enabling the AVR backend in upstream rustc and patching core to work around bugs in the AVR backend (upstream core doesn't compile for AVR so the rust-avr org has a fork of core). With this in place people would be able to use vanilla rustc (instead of having to build the fork themselves) to cross compile for AVR using Xargo and a custom target. But someone needs to do the work to make this happen.
If I understand correctly, this desktop app can't access the local filesystem, so it stores data on jsonbin.io which is a kind of pastebin-for-JSON service? How difficult would it be to add some kind of local storage, either a web-based thing like IndexDB or a custom filesystem API?
Hello all! This is probably a very trivial problem but coming from JavaScript this programming language is very weird to me. I am writing a function that is supposed to be re\-used to get use input through out a larger program. I am getting an error in the return statement. I have tried not using &amp;mut in the return statement. error: `expected (), found mutable reference` the program: `use rand::random; use std::io; extern crate rand; fn get_input() { let mut input = String::new(); io::stdin().read_line(&amp;mut input) .ok() .expect("Couldn't read line."); let returned_input = input.to_string(); return (&amp;mut returned_input); } fn main() { let mut tuple = rand::random::&lt;(u8)&gt;(); println!("A single number i8 random number: {}", tuple); let my_input = get_input(); }`
Nah, I'm not in HCMC :D 
Yeah, it's weird for me that even with a small app like this, it takes around 50MB RAM, maybe something with webkit.
You need to specify the return type of your function, e.g. `fn bla(u32) -&gt; String`. Also returning borrows means you have to borrow it from somewhere. If you e.g. take a `String`, you cannot return a borrow from it because your function will already have consumed it by the time you've returned. So take a mutable borrow instead.
Also depends how you define "remove".
no, it doesn't
It does actually. Is `aÃê` a single character?
If you only care about ascii, something like this should work: fn without_first(string: &amp;str) -&gt; &amp;str { string .char_indices() .next() .and_then(|(i, _)| string.get(i + 1..)) .unwrap_or("") } But really you should use something like the [unicode-segmentation](https://crates.io/crates/unicode-segmentation) crate to operate on grapheme clusters.
This reads a lot like a homework question, so I'm guessing the context wasn't provided. (I.e. Teacher/professor may want them to state assumptions, etc.) OP may want to look at things like [`str::chars`](https://doc.rust-lang.org/std/primitive.str.html#method.chars), the methods available on [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html), and [`String`'s `FromIterator` implementation](https://doc.rust-lang.org/std/string/struct.String.html#impl-FromIterator%3Cchar%3E). 
How can I cast from a &amp;\[u8\] to a &amp;'a str WITHOUT using any std functions? Ideally using only safe code Thanks :\)
This funny because (a derivative of) Prologue is probably going to be used in rustc
Thanks. When I get back to working on it, I'll probably use this in one of my hobby projects where as much of the heavy lifting as possible is in a Rust-based backend library and then I use rust-cpython to glue a PyQt-based frontend GUI onto it.
This is fantastic. Are there any examples of sending typed data between processes or is everything raw bytes?
are you sure your byte slice only contains valid UTF-8? If so, `core::str::from_utf8_unchecked` is your unsafe translation method. Otherwise you're probably better of with `core::str::from_utf8`. Remember, invalid data in str slices may lead to undefined behavior. If you use any of the unsafe methods, the onus is on you to ensure sanity.
I‚Äôm an idiot, thanks so much! I thought str was only in std. :)
I'm in HCMC
depends on what you do. it's like saying "if i learn how to use a hammer, will i still have to use a screwdriver?"
Oh, I expect *some* breakage. The policy is clear on the fact that bug fixes are considered "stable", even though anybody that a change of behavior will always break some code. It's a little pain now for long-term gain. I just don't think that 7.5% of users of stable experienced such breakage :)
Thanks for the numbers, that's super useful!
I already know what a screwdriver can do that a hammer won't though. I don't know what python can do that rust won't.
Sorry, me again, I have a new issue now: borrowed value must be valid for the lifetime 'a as defined on the impl The code is here, can you point me in the right direction? Thanks so much :\) impl\&lt;'a\&gt; Font\&lt;'a\&gt; for Font6x8\&lt;'a\&gt; { fn render\_str\(text: &amp;'a str\) \-\&gt; Font6x8\&lt;'a\&gt; { Self { pos: \(0, 0\), text } } fn render\_num\&lt;T: itoa::Integer\&gt;\(num: T, \_sf: usize, \_pad: bool\) \-\&gt; Font6x8\&lt;'a\&gt; { let mut buffer: \[u8; 20\] = \[0; 20\]; let n = itoa::write\(&amp;mut buffer\[..\], num\).unwrap\(\); let text = from\_utf8\(&amp;buffer\[..n\]\).unwrap\(\); Self { pos: \(0, 0\), text } } }
They are both useful in different use cases. Python is much easier to write code quickly in but rust is much easier to write fast code. Rust is still a new language and so will attract two kinds of posts: 1. How to move from old language X to new language 2. New hyped language is terrible to you should continue to use old language X Rust is a good core language so get a lot less of the second kinds of posts so you are only seeing the first kind. Now as rust ages and a new language pops up you might see *move from rust to shiny new language* posts - but currently rust is the shiny new language. Also being a newer language there are far less new to programming people learning it atm, and those that do have not had enough time to learn it then decide to learn a new language and move away from it (plus write posts about this process). But you also don't need a guide for moving from X to Y you can just learn Y from basics - and there are a lot of guides out there on learning python already. But the choice at the end of the day will be yours. I think it is a great idea to learn multiple languages as they all fit a different use case and learning about how other languages work gives you a better understanding of your main language - whichever it may be. You don't have to learn it in as much depth as your main language, but knowing when to use what tool you have is a valuable skill. That said when you are starting out focus on one language until you can grasp that. Learning a second one too soon just overloads you with more information then most people can handle.
That's nice! If I may make a suggestion... is there a way to *always* print the relative outputs? If I was to look for the step that took the most time, I'd be tempted to pipe the output of rtss to `sort` and sort numerically on the second field. However, if sometimes the second field is there and sometimes it's not, it makes things much more complicated. *Note: also, for sorting to work, the duration should always be written in the same unit. `ns` would be overkill but work like a charm.*
At [clippy] (https://github.com/rust-lang-nursery/rust-clippy), we use some python scripts for automating tasks such as keeping the `lib.rs` and `README` up to date.
Strictly speaking, any program that is writeable in one language will also be writeable in any other language; this is something Turing and Church proved. But every language has a different focus, and what matters is that writing programs in Python will probably always be faster than writing programs in Rust. There are plenty of problems for which Python is absolutely the better choice, because performance is irrelevant and all you care about is how long it takes you to write it (and how much time you spend maintaining it as time passes and requirements change). Finally, you should learn as many languages as you can. Obviously you should pick one to start and learn it well, but once you've done this it becomes much easier to learn new languages. We learn more about programming as a whole by learning a new language than we do by learning more about one we already know well; they cross-pollinate in our mind and our programs are better for it. It's perfectly natural to want to pick the "right" language to learn at the beginning of our lives and thus save ourselves a lot of time and effort in the long run, but I think it's important to realize that the best programmers never stop learning new languages.
`buffer` is created inside the function body, so it will be freed at the end of the block, invalidating `text` that borrows from it. You can solve this by letting `render_num` have an extra parameter of `&amp;'a mut [u8; 20]`, so the buffer will live at least as long as the borrow.
It seems that your time would be better spent focusing on one or the other. There are far more resources to learn from within the Python ecosystem. Eventually, Rust will have them but it doesn't yet. Knowing how to do something requires deliberate learning. Once you generally understand how something is done, then you learn how to do it well. 
Async/await. (Tongue in cheek)
If you only care about ascii, `&amp;string[1..]` suffices. This will panic if the codepoint is non-ascii though, if you may have non-ascii contents then `chars` is your friend: let mut it = s.chars(); if let Some(_) = it.next() { it.as_str() } else { "" } *this*, however, fill fail in the presence of combining characters (e.g. a flag, or a character with an accent, or an emoji using combining characters like a group or a smiley with a skin tone modifier) and that's where you bust out uniseg: let mut it = UnicodeSegmentation::graphemes(s, true); if let Some(_) = it.next() { it.as_str() } else { "" }
Thank you so much! :)
I love writing prototyping in python, personally
Hardware is optimized for floating point operations (e.g. CPUs have dedicated FPUs) so using that is the fastest and for numerical code you will often want maximal performance. Fixed point arithmetic is nice since it is less complicated but most often you have to implement it in software which is way slower. It's possible that the difference does not matter for an application, but given the wider range of covered values I think IEEE 754 floating point numbers are just fine you just have to keep a few things in mind when using them.
Just a quick question...where‚Äôs the code for the ui?
You were the bottom! Now I'm the bottom!
Thanks for the responses! I understand bits of the practical comparisons, and will probably understand them more when I learn more programming. I think I'll just learn python to a good standard then try the same with rust.
I believe python is important to know purely due to its popularity. In certain fields, like machine learning and scientific computing, it is one of the most popular languages. Not knowing it will leave whole sub fields difficult to learn. If I were to decide on a language for a project purely by asking the question ‚Äúhow quickly can I accomplish this task myself correctly without using external libraries‚Äù, personally I would never choose python. However, that‚Äôs not a reasonable way to choose a language - you‚Äôre going to want to use pre-existing libraries and frameworks, and often you‚Äôll want collaborators. For these reasons, I end up reaching for python often.
I believe python is important to know purely due to its popularity. In certain fields, like machine learning and scientific computing, it is one of the most popular languages. Not knowing it will leave whole sub fields difficult to learn. If I were to decide on a language for a project purely by asking the question ‚Äúhow quickly can I accomplish this task myself correctly without using external libraries‚Äù, personally I would never choose python. However, that‚Äôs not a reasonable way to choose a language - you‚Äôre going to want to use pre-existing libraries and frameworks, and often you‚Äôll want collaborators. For these reasons, I end up reaching for python often.
Seems I am unable to get to the point quickly‚Ä¶ **TL;DR**: I try to use rust whenever possible because it greatly helps carrying the burden of being a perfect programmer. Work experience has lead me to loathe dynamically typed languages. A point of view similar to mine has been put into words quite well in the post linked [here (Reflections on Rust, and the Sand Castle Metaphor)](https://www.reddit.com/r/rust/comments/8fcxgf/reflections_on_rust_and_the_sand_castle_metaphor/). Yes, using python, I can sketch out an application quicker, it comes with batteries included and it is widely known across many fields. But I find myself caring less and less when facing non-trivial projects. Rust will actively stand in the way of taking certain shortcuts. And this does have some nice properties: The immutability of these constraints is like a set of guard rails no pressure from management or timelines can discuss away (as long as you get to choose the language). I might not be allowed to take the direct route and some things will take longer, but there will also be no unforeseen quagmire suddenly trapping me along the way. No doubt, functional and safe applications can be built using python. There is also a whole host of literature available on that. And if you have the time (arbitrary time to market?) for thorough enough (how to measure that?) testing, then a certain degree of assurance can be obtained. If you feel more comfortable using it, use python. But when rushing towards a solution, I find myself constantly thinking about all the gaps I'm leaving (and the language allows!), out of the sheer necessity to solve a time-sensitive problem *right now*. And every time I think "this needs a test!" and skip implementing it because #reasons, I implicitly accept another brittle piece of code and every crash or malfunction coming with that. If you hold yourself to a high standard, this will feel frustrating. Thus, I find myself in an uphill battle, trying to get colleagues to look at rust. I recently discussed switching from python to java for a new project, to get at least *some* compile-time checks. For private projects, I have switched 100% to rust. One aspect of that is sleeping well because stuff either fails explicitly at an easily identifiable place or just *works*. Another reason being: Only practice makes perfect. And it seems worthwhile to me to become proficient at using a language that gets (in my humble opinion) so many things right on a conceptual level (as opposed to third party tools, analysers trying to overcome the halting problem, etc.). All in all, I recommend looking into as many niches of programming as possible. Often, a polyglot will understand languages on the whole better than someone only native to one. The broader your experience, the more accurate your judgement can be. Should this be off-topic or feel too much like a rant, I will not mind down-votes and will certainly appreciate comments.
I once did that, but never checked it in, because I didn't find the time to make it fully working and IIRC something in the python scripts had changed meanwhile...
Sounds like python could still be useful for writing mock-ups to test ideas out. I'll try switching 100% to rust for a while when I'm a real programmer (:
I write lots of stuff in lots of languages; Rust, C#, Python, JavaScript, etc.. Python I mainly use in development infrastructures, automation scripts, deployment, stuff like that. Rust is not a good language for simple tasks where there are no particular security, safety or performance concerns. Python is *much* faster for those.
Stable gui programming, probably some kinds of data analysis and machine learning, writing a fast, stable and feature-complete web server, possibly other things? In general Python has a large base of libraries right now which really just don't exist to the same extent for Rust. There's also the whole aspect of Python being extremely fast to write and to change code - live reloading a webserver with changes is not insane in python.
This seems like a good plan to me :)
I think that Rust can cover a lot of use cases that Python does. I have been a professional Python programmer for 15 years. Now that I am comfortable with Rust, I've given up Python for all my personal projects. After 15 years of Python I've developed a vendetta against null values. Most of our runtime errors are caused people forgetting to check for None. That said, Python is used everywhere and I'd say there is value in learning Python. If you learn Rust first, I'm sure you'll wrinkle your nose a lot but Python is good to learn. I'd suggest that Javascript and NodeJS would be a good next platform to familiarize yourself with. Again, Javascript will wrinkle your nose, but it is popular and you'll run into it often. Go is also a popular language. Many Python developers have become Go programmers for static typing. I hope that Rust eventually replaces Go but I don't know it'll happen. The easy learning curve for Go makes it a hard language to replace. Rust will ruin you for all these platforms. 
Note that this only supports ASCII. If the OP means to support only ASCII characters and panic otherwise, it's a valid solution.
It depends on the structure of your application. [`ErrorKind::Path`](https://github.com/BurntSushi/imdb-rename/blob/a0e56557d3ae302bf9da9522204224c2abd5fd2b/imdb-index/src/error.rs#L89) is a nice example, since it is often paired with a [`ErrorKind::Csv`](https://github.com/BurntSushi/imdb-rename/blob/a0e56557d3ae302bf9da9522204224c2abd5fd2b/imdb-index/src/error.rs#L128-L129).
Great! Wasn't quite sure myself, thank you!
All the runtime monkey patching features of Python cannot really exist in Rust. Most of the magic methods have a Rust equivalent, but some cannot function in a compiled language, such as `__getattr__`. There are areas where Rust is much better than Python. One example is consuming JSON APIs. Since Rust is fully typed, serde can deserialize JSON recursively to objects, where Python requires a model or manual structuring.
Why are you avoiding cloning? Do you want to mutate or what? Have you read about borrowing? For you to own that value?
That looks really useful.. What is the default .json that it needed. I just got too many errors complaining the guesses were wrong and couldn't create a true null.
Which is damn annoying, actually.
How do programs designed for verification skirt these problems?
I think to do this successfully you'd need to design your program in such a way that it is composed of lots of small components and those components and their compositions are verified to work. Maybe lots of small functions with clearly defined pre and post conditions. Maybe some annotations in loops to help verification programs discover loop invariants, etc. I don't really know, though, I never tried this approach myself.
Yeah, I'm thinking something like: 0.0019 0.0019 | foo 0.0019 0.0000 | bar 1.0664 1.0664 # moo If the output isn't a tty or an appropriate flag is specified. Also kind of tempted to do a --sorted mode that does it for you, could preserve the pretty-printing then. Or how about I get really fancy and make a curses display that lets you switch between them and can display sorted output in real time :D
It's in std: https://doc.rust-lang.org/std/sync/atomic/index.html
How about string .char_indices() .skip(1) .map(|i, _| string[i..]) .unwrap_or("")
Everything there says that `AtomicXXX` has the same representation as `xxx`, though.
Yes, i think eventually it should be possible to implement that through this lib, i just need to add support for events/signaling through the shared memory. Right now, the processes would have to poll the shmem
The thing about it, though, is that GNOME is really the best game in town for a modern desktop experience. awesome, i3, openbox, etc, might be really low latency, but they also don't support high DPI, display management, network management, etc, at least not out of the box. And I think many, many desktop apps these days are tied to GTK3 anyway, so your window borders are going to look like GNOME whether you're using it or not. It's also just hands down the most actively maintained project. I wish they would focus more on improving performance, but nothing else even comes close to the user experience, I think (except maybe KDE, whose performance is arguably worse).
I like the idea ! Once i add events/signaling to this, it might be better to implement another crate that takes care of that. As a side note, im pretty sure on most OS, you can expand the shared memory but not shrink it, so you might have to set a hard limit on the message/queue size
Awesome, will merge it whenever i get a chance. I'll also have to doublecheck on that MAX_PATH value for freeBSD
I don't actually buy that all programming languages are strictly speaking equivalent. Sure you can do all the same computations, but there's a lot more to a language than basic calculations. For example, I actually can't write a webserver in brainfuck because I don't have the ability to use a tcp/ip stack.
Caveat: a big part of this is just learning typed functional programming √† la OCaml. If you already have experience with, say, C and OCaml, then you can really hit the ground running with Rust.
Unfortunately, I think even with the best auditing and software development practices, we are going to kill people with self driving cars; especially before the technology matures
Isn't rust typesytem being formally proved? It's not the same but it may help calculate and even assure that all safe rust programs are "formally proved"
Are they formally proving other FOSS things?
Where is `as_str` defined? For some reason I recall us removing `x.as_str()` and `x.as_slice()` in favor of automatic coercions or explicit `&amp;x[..]` (when coercions can't kick in because a slice is not necessarily the expected type).
&gt; For example, I actually can't write a webserver in brainfuck because I don't have the ability to use a tcp/ip stack. You could write one so long as you can compile your brainfuck to whatever code runs on the metal for that system. At the level that the poster was talking about - turing completeness - they are all equivalent in power. Naturally, different languages express "power" in many other, more abstract ways.
I hit a warning all the time saying that it's deprecated and in the future it will be a hard error. It will break my code if I don't fix, so rust will break things, it's understandable. But in a large codebase something like that can happen (if you wrote before the warning even existed).
I would not recommend learning two languages at once. I have not seen that go super well. Learning one language for the first time is already serious work. Usually, once you learn one language, learning another is not so hard (and each new language often makes it even easier). I would learn Python first. * There are far more learning resources * There are far more Python developers * There are far more Python jobs * Python is a lot easier for new programmers * It is often easier to write 'fun' programs (easier to appreciate as a new developer) in Python As you said, there are also a lot of resources (and there will likely always be more resources) for going from Python -&gt; Rust instead of Rust -&gt; Python. So if you want to eventually learn rust, that'll already be an existing path. That said, if you are committed to learning Rust, I think that it would be trivial for any Rust developer to move from Python. I went from C++ to Python, which I feel is a similar transition. It was hard, in that everything felt so, so much worse, but there were very few concepts I had to learn, mostly it was a shift in how I thought about structuring code. I expect a transition from Rust to Python to feel similar.
https://play.rust-lang.org/?gist=c3771ef9a32b2b9c18733f2407d22016&amp;version=stable&amp;mode=debug am I missing something? this compiles.
&gt; Not sure how sort handles decimal numbers, might require integers. GNU and BSD sort handle decimals, but POSIX doesn't require it and it seems Solaris doesn't bother. Maybe a good compromise is the format `tcpdump -ttt` uses; `00:00:00.000087`, which just sorts lexicographically. &gt; I don't think it's necessary to build sorting yourself; sort works, and has plenty of fanciful options, also it allows filtering before (to buffer less). Curses would prevent piping. It wouldn't be *instead* of, it would just be an additional interactive output mode, allowing sorting while seeing real-time output, nicely formatted durations, and switching between sorts on the fly. Not sure I can quite be bothered, but I do want to play with curses at some point and this might be a nice focused exercise in it. &gt; Letting the user specify the unit they want the display to be on might help. Short tasks would benefit from us while longer running ones would prefer ms/s/... and the user should know. Half tempted to do something like [tj]'s customisable format strings. Then you can select something predefined or make up your own.
That's really not a fair, realistic, or even logical position to take. Engineering is about tradeoffs. You have a finite number of engineers and time, so you have to choose how to spend that time, and which things take priority. It's perfectly valid to favor user experience over being low enough latency to work smoothly on old machines, or in constrained environments. Nor does the latter imply that performance is disregarded in design choices. You may feel like low latency is the most important thing, but that does not generalize to other people and projects. Having different priorities does not mean they're not following "good practices" (whatever that means to you).
But I need iter(), not into_iter().
Fixed in 1.0.1!
ok, how about now? https://play.rust-lang.org/?gist=2303c2b74fac6a24e77d2b2c4fd903da&amp;version=stable&amp;mode=debug
Gnome 3 offers nothing but a playground for kids over gnome 2. (managed language virtual machine desktop).
Please correct me if I'm mistaken, but from what I've read and tested so far cloning in rust refers to making a deep copy. That I'd like to avoid because the cached data is potentially large. I have read about borrowing and I'm under the impression that inserted data belongs to the HashMap and it is not possible for me to own it afterwards. This, I imagine, is the reason the or_insert method returns &amp;mut T, as opposed to T. I do need to mutate the cache and the cached values as neither are expected to be entirely constant.
Thanks! It worked. I didn't know that I allowed to use custom lifetimes.
Did you try an empty object? 
[both `String::as_str()` and `Vec::as_slice()` appear to have been stabilized in 1.7.0](https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-170-2016-03-03)
I'd throw money at this
&gt; I remember a bunch of people were complaining about unbalanced apostrophes‚Ä¶ So I propose we just replace apostrophe with crab in the next Rust edition. MUH IMBALANCED CRABS
Empty as in {}?.. it complains JSON cannot be empty. As null is suggests "you need to add the JSON data"
To render a web-based UI, it needs a HTML rendering engine + a JS engine. So your solution is just the same stack as Electron. You use WebKit, Electron uses Chromium (which is Blink, derivative of WebKit, + some additional features) . You use Qt's JS engine, Electron uses V8. That is why the RAM consumption is big.
Actually, it will not necessarily break. The idea of Rust editions is to allow a clean transition: - warn for things that are not allowed in later editions, - but let the user opt-in to the new edition on their timeline, so they can continue upgrading the compiler without breaking their code.
Sure, accidents will happen. Even rockets explode, and they have the most stringent processes I've ever heard of. However, just because some accidents will happen doesn't mean we should throw our hands up :)
Patch to add wasm support: https://github.com/nafi-lang/rust-nafi/commit/2ac59159043e845b097123bea072a277ec0cc01c Homepage: https://github.com/nafi-lang/rust-nafi It's still _very_ rough, but I've been iterating on a toy language and experimenting with parser implementation. What I've got working on wasm is the lexer, which turns source into tokens. So you type some text into the input, and it shows you some text representation of the produced tokens in the output box. The intent of the project is actually to be an interpreter with high quality documentation throughout, though in its experimental phase of course some of the stuff that might be ripped out has subpar docs. Running on wasm is just a bonus to show off the language. Though the blocker for getting the final steps done is stubbing out rayon on wasm, which'll be interesting should I get to that point before a) wasm gets multithreading or b) the rayon team has otherwise got rayon "working" on wasm.
Just to be a little more specific, Python (as well as JavaScript, Ruby, Haskell, Java, and many other ones) has a REPL. Basically, you can log in to a running Python app and type in Python code while it's running. I've used a REPL to diagnose and debug a lot of webapp problems.
I have mixed feelings about one telling others that rust is amazing having not actually used it. I'm actually a bit confused. You jump from: &gt; Some day, maybe in a few years, I'll write Rust. To: &gt; so I went ahead and creates uq. So you did end up writing rust? I feel like there's a story in between these two that would be interesting to hear, since you pointed out such a significant struggle learning rust and then started publishing crates. I think it would be useful to at least touch upon that transition in the article.
On the other hand, the problem of proofs is that they only prove that the specifications are verified. If the specifications are faulty/incomplete...
Python scarred me when it told me that 5 &gt; 10. The lack of explicit typing made me not realise that it was using strings, especially since Python 2 would have parsed the input as numbers but Python 3 wouldn't. Making the same kind of stupid mistake would either fail at compile time or crash at runtime with Rust.
BF can do IO, but it can't do a syscall, so it has no way of signalling to the OS that it wants the data it's written to be put out onto the wire. Or does it? A syscall is nothing more than a conventional way of structuring IO. You could translate it into an IO protocol that a BF program can deal with, since the kernel could just scan the BF program's memory looking for packets to write out to the network, and writing responses to them into the memory. This is a form of polling, and it would be a lot slower than the interrupts we conventionally use, but this is BF after all. It would be awful in a lot of ways, but it wouldn't be impossible. You could even write the kernel side in BF, since it can read and write the memory in the same way. The kernel talks to the network card in the same way, except now it's memory-mapped IO.
&gt; I just said that Rust‚Äôs safeness guarantees are still way weaker than the requirements for formal verifications. Why would only safe Rust be verifiable? One of the goals of refining the semantics of Rust, and what unsafe is allowed and not allowed to do, is to produce an *executable* model; I would expect the WG to try and make it verifiable as well.
I miss `with contextmanager_function() as r:` in other GC languages, but with Rust having RIIA i'm not actually sure it's needed in general there.
Just got a chance to open my laptop, I didn't handle the empty JSON case yet :( let's try this: ``` {"taskInput": "", "tasks": [], "movingTask": null} ``` I updated the README file for this as well. :D
You don't. Take a look at MutexGuard or RwLockRead/WriteGuard. Basically, in Rust, everything implementing Drop is a context manager.
Anyone wanna take a crack at why type inference fails here? Both `c.is_numeric()` and `c.is_digit(10)` fail on `c`, with `rustc 1.25.0` saying `the type of this value must be known in this context` and both bet and nightly telling me `consider giving this closure parameter a type`.`char::is_numeric` works fine on any of the three versions which would seem to suggest that Rust either thinks there are types other than `char` which have `is_digit` or `is_numeric` definitions, but I'm not importing anything (literally, the entire file is just the main fn as it is below) and checking the std rustdoc only has char with `is_digit`/`is_numeric` fn main () { let v: Vec&lt;&amp;str&gt; = "12(2a1b)".split(|c| c.is_numeric()).collect(); println!("{:?}", v); }
You can use fn remove_first(s: &amp;str) -&gt; Option&lt;&amp;str&gt; { s.chars().next().map(|c| &amp;s[c.len_utf8()..]) } This will produce a `Some` shortened string when there is at least one character, or `None` if the string is empty: "üòûüòÑ" -&gt; Some("üòÑ") "üòÑ" -&gt; Some("") "" -&gt; None If you want to always produce a string and return `""` when the original string is empty, you can add `.unwrap_or("")` at the end.
I use rust for scripting. std::process::Command is what you need go run subprocesses. If you want your script to be flexible use quicli or structopt to make getting params easy. Only downside is that you have to compile it
If you don't need shared memory, you can do IPC on Windows with something like zeromq/nanomsg. I like it because it's simple to swap out IPC for TCP when I want to move processes to other machines. I use scaproust, which is a native rust implementation of the nanomsg protocol: https://github.com/blabaere/scaproust 
There's [cargo-script](https://github.com/DanielKeep/cargo-script) which while also inactive, is a little more comprehensive and up to date. If you're just looking for something bash-like then there's the [ion shell](https://github.com/redox-os/ion), although it's not yet finished.
I agree. Nothing seems quite baked for use yet. Scripting languages have a (limited) purpose and one as similar as possible would reduce cognitive load of context switches, What would a Rusty script language be like? My take is Dyon isn't yet aimed at productive expression. I'd rather see Rust syntax relaxed such that function signatures are simple/lazy, And all variables implicitly heavily wrapped (Arc etc) is just fine for starting simplicity and useful for expanding the target audience, 
May be this is what you need.. struct DeadCompiler { value: Arc&lt;RwLock&lt;String&gt;&gt; } Then use it for your Haspmap value... 
I think it was one of the Atomic stabilization issues. There is the question of how to handle atomic types on platforms which don't support some or all of them. One proposal is to embed a spinlock in the atomic type to emulate large atomics, which of course prevents it from having the same representation as the corresponding integer type. Though I think currently the "Don't offer large atomics on platforms which don't natively support them" approach is seen as preferable.
While making the region readonly on the receiver side certainly looks clear, I don't see much of a practical benefit over making the region read/write on both ends.
The problem here is that `rustc` won't infer a type for an expression by looking at what methods you call on it. For example, this fails to compile too: #[derive(Default)] struct Foo; impl Foo { fn some_very_specific_name(&amp;self) {} } fn main() { let x = Default::default(); x.some_very_specific_name(); // ~ERROR: the type of this value must be known in this context } I think this is by design - this way type inference won't start to fail on existing code when you add a method with the same name on another type. And `str::split`'s parameter has type `P where P: Pattern` - so the compiler can't immediately figure out that parameter of your closure must be `char`. 
&gt; I don't actually buy that all programming languages are strictly speaking equivalent. That's not really what the poster meant. They were just expressing that concept that any program you can express in one turing complete language is tecnically expressible in another turing complete language. You might not be able to use your existing tcp/ip stack (although I'm betting you probably could in some way), but you could write it in brainfuck. Hell, you could write a whole OS in brainfuck. That it's possible doesn't diminish the fact that it would be a very poor choice.
People actually donate money to have other people import emoji into unicode? Whaaat... 
Thanks for this! Enjoyed the read.
No. Please see the official page on the matter: https://unicode.org/consortium/adopt-a-character.html The point is to support the Unicode Consortium. The "adopt a character" part of it is a technique to drive support.
Defensive programming is mostly runtime tests to make up for a bad type checker IMO. Rust has a much stronger type system than eg C# and Java, and can catch many errors on compile time rather than with ‚Äúdefensive‚Äù assertions at runtime.
Excellent! Thank you
Usually, this is done via `assert!` or `debug_assert!`. Those will panic if the expression you call them with evaluates to `false`, so you can put your requirements right in there: ```rust assert!(message.is_valid()); assert!(!vec.is_empty()); ``` `debug_assert!` will only be checked in debug builds. This is useful for sanity checks that are expensive to compute and not strictly required. Of course, you won't have to check for null references, and the `IsDisposed` example is also not needed in Rust because destructors actually *always* destroy the object, with no way to resurrect them or access them.
Not the OP, but it was more or less same for me. Keeping eye on Rust since 0.6 days and advocating the design decisions. Waiting too much time to get higher-kinded types but jumped to implement some POC and compared with similar POC I have written in C++: the learning curve is steep (I knew C++) but the assurance you get from program compiling is greater. There is also no arguing about what is the right/sane subset of language X to use in production when it comes to Rust and this is huge when you work on a team. As a context, I come from Scala and lot less C++ background. At the end, I still miss HKT, but not so much. I didn't expect being fluent in a new language in 1 week and I knew it's going to be up-hill battle at the beginning, similar with my learning of Haskell a few years ago. Nothing new - new language requires time to get used to and learn the nuances. May be the expectations of the people are different but I give myself time to get into the any new language - it's not just syntax as a lot of people believe. 
See I'm the opposite, if I have a lot of calls to that macro or a bunch of similar ones, I'd gladly use another macro to DRY it out. With all the repetition it becomes much easier to make mistakes (especially when changing the `x` and `y` names later) and to change the naming scheme (maybe it should be `fn_x_and_y` or we also need a `Struct_x_y`...). 
Most Rust code does not need __runtime__ defensive checks because it has types that support __compile-time__ defensive checks. For example, there is no need to check for null, because types can not be null. Objects in many languages have two types at runtime: one that can be null, and another that can not. That's the reason for defensive checks. Imagine if in Java had no nulls, and "Message" would never be able to be null. Instead, this imaginary Java would provide another generic type that could make object optional. If someone wanted to pass an optional object to function, they would need to explicitly wrap a Message into a generic Option&lt;T&gt; type: private void SendMessage(Option&lt;Message&gt; maybeMessage) { } Additionally, the compiler would ensure that it is not possible to get to Message type without first doing an explicit check: private void SendMessage(Option&lt;Message&gt; maybeMessage) { if let Some(Message message) = maybeMessage { // Do some work, message can't be null here } } The point here is that we would not need to raise the exception if the message does not exist; instead, we would simply change argument type from `Option&lt;Message&gt;` to `Message`: private void SendMessage(Message maybeMessage) { // Message can't be null here, because no one can pass Option&lt;Message&gt; to this function! } This alternative is __very__ simple, it's just that everyone is super used to the null type being part of every object, instead of something that extends the object. (I know the latest Java has optional type, however the object inside can still be null, which renders said optional type silly)
Yes! Btw, it's also possible to do it with a PureScript frontend: To send a msg from host to frontend: register an event handler on `window` for a custom event. From the Rust host, call eval to raise a `CustomEvent` on `window` that will get caught by the event handler. To send a msg from frontend to host: Have a simple wrapper js function that calls the external invoke function, and write a FFI decl for it so it can be used from your PureScript app.
That's because of Webkit. On windows (with MSHTML) it uses less RAM. But it would be nice to be able to use Webkit on Windows, too, to get Wasm support so that one can write the app in Rust with Yew and compile to Wasm.
Why is it that I need to use `as` in line 7? I'm trying to learn Rust and understand Option\&lt;T\&gt;, but don't quite get why it is that if I remove the `as Option&lt;i32&gt;` it fails compilation and says match is returning \( \). fn main() { let mut test = Some(5); let test2 = match test { None =&gt; None, Some(i) =&gt; { println!("{:?}", i); Some(i) as Option&lt;i32&gt; }, }; assert_eq!(test2, Some(5)); } Thanks!
If you don't need a full game engine you can just use `sdl2` directly. Here is a small example: http://dpaste.com/3GXJBKC
Yes, I'm thinking something along those lines could work. I'll give it try tomorrow. Thanks again!
[when you skip leg day](http://onemoregeneration.org/wp-content/uploads/2011/08/OMG-Trivia-08-23-11.jpg).
Thanks! Btw, any idea which latency this has compared to IPC channels over shared memory? It's going through the full network stack twice, right? (For sending and receiving.) When would you recommend using nanomsg instead of zeromq? Btw, why are you using scaproust instead of nanomsg-rs?
&gt; Vint G. Serf Ah yes, the ~~Father~~ Servant of the Internet.
If you put a `;` at the end, that means the match arm no longer results in `Some(i)`, it results in `()`. The result of a block is the value of the last *expression*, and `Some(i);` is a *statement*.
That was the error! Thanks! Now I get it.
I think a fork of Rust with string interpolation, more coercions and custom implicit conversions could be used as a scripting language (with something like cargo-script and/or a Rust shell/repl based on miri). E.g. being able to omit `&amp;` when calling operators or even functions with args that are `Copy`, and being able to define and import custom implicit conversions like in Scala. Also it should have a more streamlined syntax and auto glob imports of enum cases in `match` (`use foo::Enum::*; match ..`) Btw, here is my interpretation of what Rust with indentation-based syntax would look like: http://dpaste.com/02MC2VS I implemented a transpiler, detranspiler and cargo proxy for it (that backtranslates error messages' locations based on the source maps), also implemented swift-like string interpolation but I'm not sure how far I should take this whole project..
Also `duct` for complex subprocess chains is very useful! 
[removed]
[removed]
[removed]
You also forgot to state that it‚Äôs very easy to write bad code in python while it‚Äôs harder in Rust.
So, how would someone go about using this? It doesn't seem possible to register.
Is there a way to make a certain test binary compile in release mode every time?
More quality content yet again, never disappointed :D Thanks for all the work you're putting into this Phil. I think making an accessible way for newcomers to start OS development is fantastic and I know a few people on the Rust Discord server (yes we have an `#osdev` channel!) have been working away on their own kernels for a while. Personally I'd like to get my Raspberry Pi Zero W OS doing more than just printing out on QEMU (for those wondering, the RPi ZW uses the same SoC as the RPi 1) but OS development resources for the Pi (and ARM in general) seem fairly thin compared to x86 and x86_64. Maybe some day. :)
Sweet that worked thanks a lot!!
/r/playrust
Hey all. Thanks for looking. I'm trying to figure out how to return a vec of trait objs of some structs inside the struct implementing this method. In the examples here, rooms is a Vec&lt;Room&gt; where Room is a type that implements the Collidable trait. I've tried two ways. This works (although I'm not sure why I need Box and a reference. Shouldn't box be sufficient?): ``` pub fn produce_collidables(&amp;self) -&gt; Vec&lt;Box&lt;&amp;Collidable&gt;&gt; { let mut ret: Vec&lt;Box&lt;&amp;Collidable&gt;&gt; = Vec::new(); self.rooms.iter().for_each(|r| ret.push(Box::new(r))); ret } ``` But this doesn't, which seems to me to be perfectly semantically equivalent: ``` pub fn produce_collidables(&amp;self) -&gt; Vec&lt;Box&lt;&amp;Collidable&gt;&gt; { self.rooms.iter().map(|r| Box::new(r)).collect() } error[E0277]: the trait bound `std::vec::Vec&lt;std::boxed::Box&lt;&amp;collision::Collidable&gt;&gt;: std::iter::FromIterator&lt;std::boxed::Box&lt;&amp;dungeongen::rooms::Room&gt;&gt;` is not satisfied --&gt; src\dungeongen\level.rs:167:44 | 167 | self.rooms.iter().map(|r| Box::new(r)).collect() | ^^^^^^^ a collection of type `std::vec::Vec&lt;std::boxed::Box&lt;&amp;collision::Collidable&gt;&gt;` cannot be built from an iterator over elements of type `std::boxed::Box&lt;&amp;dungeongen::rooms::Room&gt;` | = help: the trait `std::iter::FromIterator&lt;std::boxed::Box&lt;&amp;dungeongen::rooms::Room&gt;&gt;` is not implemented for `std::vec::Vec&lt;std::boxed::Box&lt;&amp;collision::Collidable&gt;&gt;` ``` Why!? Is it simply that the Vec conversions just aren't that smart yet? Alternatively, how could I do this better?
ha thanks
Unfortunately, you can't store both a String and a `Chars` iterator over that same `String` in the same struct. (In general, you can't store an object and a reference that borrows from that object within the same struct.) However, if you're willing to have the `String` live outside the struct, you can borrow both a `&amp;str` and a `Chars` from it, like so: https://play.rust-lang.org/?gist=74d813a3ae65d4defa286180380af113&amp;version=stable&amp;mode=debug
`Box::new(r)` returns a `Box&lt;&amp;Room&gt;` unless it is coerced to `Box&lt;&amp;Collidable&gt; by the context. If you write a cast, like ``` self.rooms.iter().map(|r| Box::new(r as &amp;Collidable)).collect() ``` that should work. Are you sure you want a `Vec&lt;Box&lt;&amp;Collidable&gt;&gt;`, rather than a `Vec&lt;&amp;Collidable&gt;` or `Vec&lt;Box&lt;Collidable&gt;&gt;`? The double indirection is a bit weird and generally not useful.
Python is an awful, awful language, but if you are just learning to program and the choice is between sweet, beautiful Rust and Python, you should choose Python.
Why PyQt instead of PySide?(Which Qt is adopting as an official Python API)
Because, when I started the project, I was scared away by the list of TODOs on PySide's Qt5 support. I'll probably migrate it over to PySide when I upgrade my machine from Kubuntu 14.04 LTS to something with newer packages.
To expand on rieux's answer: what you're asking it to do is impossible. `&amp;Collidable` is a different size to `&amp;Room`, so there's just no way to convert between `Vec`s of the two. You need to convert the elements first, then collect the result of that. And, yeah, you probably want `Vec&lt;&amp;Collidable&gt;`. There's almost never any reason for `Box&lt;&amp;_&gt;`.
Being proficient in Python and Ok in Rust will give a programmer super powers. This person can compose a top level really quickly, but then dive into low level code and target correctness, speed or both. Or if they start doing the majority of their coding in Rust, they can call into Python because of the breadth of available libraries. The vast majority of code runs once, so writing as few lines as possible is a net win.
I'm fairly good with Python and I'm at least ok in rust and I don't think I have superpowers.
I think you do. We aren't often a good judge of our own skill. 
[removed]
It would be cool if one option for `rustup` would be to create a `.tar.gz` that one can simply copy to a folder and run. Understandably, most cargo features would probably be inaccessible and / or limited, but there are still so many use cases where you can't count on being online and / or having `root` or `admin` privileges. 
Give it a try if you get the time, and feel free to contribute (e.g. documentation, testing, ...). Just beware, the target version is 1.19 nightly.
 fn main() { //starting robot at 0 let mut robot_location = Location { X: 0, Y: 0 }; let grid = make_grid(); let mut move_allowed = false; let orders = get_orders(); for order in orders { println!("{:?}", grid); let old_location = Location { X: robot_location.X, Y: robot_location.Y, }; robot_location = move_robot(robot_location, &amp;mut move_allowed, order); process_move(&amp;mut robot_location, old_location, &amp;mut grid); } } fn process_move( mut robot_location: &amp;Location, old_location: Location, mut grid: &amp;Vec&lt;Vec&lt;char&gt;&gt;, ) -&gt; bool { let x = robot_location.X; let y = robot_location.Y; if grid[x][y] == field { grid[old_location.X][old_location.Y] = field; grid[x][y] = robot; } if grid[x][y] == wall { robot_location = Location { X: old_location.X, Y: old_location.Y, }; } else if grid[x][y] == mine { return false; } return true; } I am getting an error expected type &amp;location. if grid[x][y] == wall { robot_location = Location { X: old_location.X, Y: old_location.Y, }; here. does old location X and Y which are both usize not have the copy trait? if i add &amp;location i get other errors. I also think it might be helpful if i discuss my reasoning mut robot_location: &amp;Location is because i may need to change the value but i don't want ownership as that belongs to my main method. old_location: Location is read only but is causing my error. mut grid: &amp;Vec&lt;Vec&lt;char&gt;&gt;, I am modifying this but i do not want ownsership. 
Wow, this work is impressive, tho with the small projects I have, it's noticeable. A question, the percentage improvements in the article, are they calculated seperately? and are there changes for one that affect another? Because if there isn't, it works out to a 50%ish improvement. As well as that, building the compiler takes a long time on my machine, and many other peoples as well, which may be deterring more people from doing this kind of work, as it requires more smaller changes to the code and frequent rebuilding in release mode.
Your link goes to HIPv1; are you aware of HIPv2 having been published as [RFC 7401](https://tools.ietf.org/html/rfc7401) (with [RFC 7402](https://tools.ietf.org/html/rfc740) for the IPsec integration)? Note that HIPv2 basically came out of doing multiple _deployments_ of HIPv1, and fixing the various issues and rough edges that cropped up. You may find the HIP WG's [document tracker](https://datatracker.ietf.org/wg/hip/documents/) useful, as well - you basically want RFC 7343 and up, along with the three still-pending drafts (they've been submitted for publication, but haven't gone through yet). In addition, past HIP implementations - OpenHIP, InfraHIP, etc - historically _have_ been in userspace, so I'm not sure "HIP in userspace" is much of a distinguishing characteristic... HIP can run over UDP, not just over raw IP, and IPsec has been implemented in userspace several times. Furthermore, if you're addressing NAT traversal and hole punching, the [relevant draft](https://tools.ietf.org/html/draft-ietf-hip-native-nat-traversal-28) is likely worth keeping handy.
 fn main() { //starting robot at 0 let mut robot_location = Location { X: 0, Y: 0 }; let mut grid = make_grid(); let mut move_allowed = false; let orders = get_orders(); for order in orders { println!("{:?}", grid); let old_location = Location { X: robot_location.X, Y: robot_location.Y, }; robot_location = move_robot(robot_location, &amp;mut move_allowed, order); process_move( robot_location, old_location, &amp;mut grid); } } like this fn process_move( mut robot_location: Location, old_location: Location, grid: &amp;mut Vec&lt;Vec&lt;char&gt;&gt;, ) -&gt; bool { let x = robot_location.X; let y = robot_location.Y; if grid[x][y] == field { grid[old_location.X][old_location.Y] = field; grid[x][y] = robot; } if grid[x][y] == wall { robot_location = Location { X: old_location.X, Y: old_location.Y, }; } else if grid[x][y] == mine { return false; } return true; } almost modified clone #[derive(Clone, Copy)] struct Location { X: usize, Y: usize, }
Thanks for responding. I knew I should have read the docs!
Yes.
I think not, but you can make all profiles the same as release (see [the Cargo Guide: Manifest Format](https://doc.rust-lang.org/cargo/reference/manifest.html#the-profile-sections)).
Might I suggest something more like this as your "something like this" example? user=nnethercote git clone https://github.com/$user/rust rust0 (cd rust0 git remote add upstream https://github.com/rust-lang/rust git remote set-url origin git@github.com:$user/rust ) cp -r rust0 rust1 You don't really want to be subtly encouraging novice or "might as well just copy, paste, and adjust" users to clone against the server twice. A new push could land in between and, even if it doesn't, it's wasted bandwidth when you can do a local copy.
You should also check out https://github.com/est31/cargo-local-serve . A copy of all crates on crates.io (including all older releases... so really everything) takes 14 GB for the bare .crate files, and 3.4 GB for a compressed version (everything still being recoverable from that).
Yeah, I thought the double indirection made no sense. I guess I'm just not sure I understand why I need the "as". Why do I need to explicitly cast to the trait type, there, where in my odd working example I don't need to? Thanks!
I don't recall where I came across that bit of info, but I'll try to find it for you after I get some sleep. &gt; Does it mean that those methods are valid only when using a trait smart pointer like &amp;View or Box&lt;View&gt;? Essentially, yes. [Here](https://play.rust-lang.org/?gist=e6d14f32053efc55926237fe158986f0&amp;version=stable&amp;mode=debug) is an example. &gt; What's the point of that? Maybe I can find my original source tomorrow to confirm, but I believe that this is just a couple language features coming together. First is the inherent impl. Just as you can have `struct S` and `impl S`, you can have `trait T` and `impl T`. So the method is valid for any `T`, which is different than saying the method is valid for any `S` with `impl T for S`. It just so happens that `T` is a trait, and traits are unsized types, so the only methods you can define in an `impl T` block are ones with take `&amp;self`, `&amp;mut self`, or do not take `self` at all (since `self` requires `T: Sized`). Then the type of `self` is `T`, which makes `&amp;self: &amp;T`, which results in the method only being valid for trait objects. And then `Deref` kicks in, which makes `Box`, `Rc`, `Arc`, etc work with the method, since they can all become `&amp;T`. I recall my source made good use of all this, but since I don't have the details in working memory I'll have to get back to you on that front. I think maybe it had to do with "unifying" static and dynamic dispatch, in some sense, like being able to dynamically delegate to an appropriately specialized function without having to do a bunch of casting. Anyway I'll search tomorrow unless someone can magick it out of the ether based on that vague description :D
If `process_move` needs to actually change `robot_location` in `main`, then the function should take `robot_location: &amp;mut Location` so that the assignment in the function as an effect in `main`. If `process_move` only needs the `robot_location` at the time of the call and you just want to reuse that variable within the function, then what you have is fine.
Because if you don't use `as`, the compiler has no idea you expect it to cast those references, so you end up with incompatible types on either side of `collect`. Your example works because the coercion happens at the point you call `push`, which is a position the compiler is allowed to automatically coerce reference types.
yeah i needed it to have an effect on the main function changed 
Although it seems to be no longer in fashion, offline installation and upgrade capabilities are very important for reproduceability, availability and security purposes. We never use rustup, instead we grab the standalone installer via lynx -dump https://www.rust-lang.org/en-US/other-installers.html |grep "dist/rust" | grep x86_64-unknown-linux-gnu |cut -b 7- |head --lines 1 and (re)build a Rust dev environment in a Docker container. The same on Arm32/64. Everyone uses same image. Can be instantly rebuild without internet. When file is locally cached it is only downloaded once.
 fn main() { //starting robot at 0 let mut robot_location = Location { x: 0, y: 0 }; let mut grid = make_grid(); let mut move_allowed = false; let orders = get_orders(); for order in orders { println!("{:?}", grid); let old_location = Location { x: robot_location.x, y: robot_location.y, }; robot_location = move_robot(robot_location, &amp;mut move_allowed, order); process_move(&amp;mut robot_location, old_location, &amp;mut grid); } } fn process_move( robot_location: &amp;mut Location, old_location: Location, grid: &amp;mut Vec&lt;Vec&lt;char&gt;&gt;, ) -&gt; bool { let x = robot_location.x; let y = robot_location.y; if grid[x][y] == FIELD { grid[old_location.x][old_location.y] = FIELD; grid[x][y] = ROBOT; } if grid[x][y] == WALL { robot_location = &amp;mut Location { x: old_location.x, y: old_location.y, }; } else if grid[x][y] == MINE { return false; } return true; } i get an error in the location part if grid[x][y] == wall { robot_location = Location { X: old_location.X, Y: old_location.Y, }; expected type &amp;mut Location found type Location
Engaging read, and awesome results! I like the quick overview of how you can set up profiling yourself, makes me want to take a crack at it :\^\)
It's not an offline installer, but my alternative Rust toolchain manager [rustup](https://gitlab.com/Screwtapello/rustbud) will create a standalone directory that can be tarred up and copied around. The official Rust binaries are designed to support this kind of portable-installation, but rustup doesn't make that a front-and-center feature.
Thanks for the answer. I suppose I'm just trying to understand *why* it's safe for the compiler to do it in push but not when just collecting.
sorry was meant to reply to this comment fn main() { //starting robot at 0 let mut robot_location = Location { x: 0, y: 0 }; let mut grid = make_grid(); let mut move_allowed = false; let orders = get_orders(); for order in orders { println!("{:?}", grid); let old_location = Location { x: robot_location.x, y: robot_location.y, }; robot_location = move_robot(robot_location, &amp;mut move_allowed, order); process_move(&amp;mut robot_location, old_location, &amp;mut grid); } } fn process_move( robot_location: &amp;mut Location, old_location: Location, grid: &amp;mut Vec&lt;Vec&lt;char&gt;&gt;, ) -&gt; bool { let x = robot_location.x; let y = robot_location.y; if grid[x][y] == FIELD { grid[old_location.x][old_location.y] = FIELD; grid[x][y] = ROBOT; } if grid[x][y] == WALL { robot_location = &amp;mut Location { x: old_location.x, y: old_location.y, }; } else if grid[x][y] == MINE { return false; } return true; } i get an error in the location part if grid[x][y] == wall { robot_location = Location { X: old_location.X, Y: old_location.Y, }; expected type &amp;mut Location found type Location
[removed]
I'll have to say, I am impressed with the upcoming performance improvements: rustc 1.25.0 (84203cac6 2018-03-25) binary: rustc commit-hash: 84203cac67e65ca8640b8392348411098c856985 commit-date: 2018-03-25 host: x86_64-pc-windows-msvc release: 1.25.0 LLVM version: 6.0 Finished release [optimized] target(s) in 571.98 secs real 9m32,512s user 0m0,000s sys 0m0,000s ------------------------------------------------------- rustc 1.27.0-nightly (79252ff4e 2018-04-29) binary: rustc commit-hash: 79252ff4e25d82f9fe856cb66f127b79cdace163 commit-date: 2018-04-29 host: x86_64-pc-windows-msvc release: 1.27.0-nightly LLVM version: 6.0 Finished release [optimized] target(s) in 314.72 secs real 5m14,822s user 0m0,000s sys 0m0,000s This was on a release build using LTO, on a project with 166 total dependencies, ~10k (including all dependencies ~6 million) LOC, using MSVC for linking, on an 8-core AMD FX8320. I am not sure how much of this was due to improvements in parallelization of LLVM and how much was just the compiler. But still, shaving 4 minutes off of the build time is pretty good. I hope the compiler speed improves more in 2018, it is really the #1 problem for me.
Agreed. Over 30,000 people per year die in human-driven vehicle accidents in the U.S. alone. (1.1 to 1.2 fatalities per 100 million vehicle miles travelled.) ([source](https://en.wikipedia.org/wiki/List_of_motor_vehicle_deaths_in_U.S._by_year)). We need to do our best to ensure that citizens and politicians think in terms of "is it safer?" rather than "is it safe?".
Yes, it is. Here's a talk about it from December 2017: https://www.youtube.com/watch?v=Y9vemQmVeLI
I thin you meant *rustbud* instead of *rustup*
I just started a bit of work on rustc, and while the first build takes a while (not insignificantly because of LLVM), testing if my changes compile at least is pretty fast. Make sure you‚Äôre passing ‚Äîincremental to x.py if you plan to compile more than once
The pattern i usually use is : | | || ---|---|---|--- stream | | | sink stream | channel | struct | sink stream | | | sink 'split' any connection into a stream and sink. join all streams into a channel. Store your state and sinks in a structure and 'fold' over it for each incoming message. P.S. This is the pattern i used because it was the first one i got working. If someone knows of other approaches, i would also like to hear them. 
follow up on these questions https://www.reddit.com/r/rust/comments/8e96nt/hey_rustaceans_got_an_easy_question_ask_here/dy762s0/ fn main() { //starting robot at 0 let mut robot_location = Location { x: 0, y: 0 }; let mut grid = make_grid(); let mut move_allowed = false; let orders = get_orders(); for order in orders { println!("{:?}", grid); let old_location = Location { x: robot_location.x, y: robot_location.y, }; robot_location = move_robot(robot_location, &amp;mut move_allowed, order); process_move(&amp;mut robot_location, old_location, &amp;mut grid); } } fn process_move( robot_location: &amp;mut Location, old_location: Location, grid: &amp;mut Vec&lt;Vec&lt;char&gt;&gt;, ) -&gt; bool { let x = robot_location.x; let y = robot_location.y; if grid[x][y] == FIELD { grid[old_location.x][old_location.y] = FIELD; grid[x][y] = ROBOT; } if grid[x][y] == WALL { robot_location = &amp;mut Location { x: old_location.x, y: old_location.y, }; } else if grid[x][y] == MINE { return false; } return true; } i get an error in the location part if grid[x][y] == wall { robot_location = Location { X: old_location.X, Y: old_location.Y, }; expected type &amp;mut Location found type Location
Thanks so much! It's the first time that I hear about the discord server. Awesome that you have such an active osdev channel!
Let me know if you have any problems! 
Maybe that could be a clippy lint?
I am working in a command line flashacard learning tool. I stated learning Rust only a month ago so any feedback or help would be welcomed. https://github.com/Indy2222/vole
Thanks, yes, yes I did. :(
Let me know if it works.... Or this struct DeadCompiler { value: Arc&lt;Mutex&lt;String&gt;&gt; }
Thank you everyone, but specially u/Nextil and u/ocuppy_paul_st because `cargo-script` is what I was expecting, at least to execute Rust code \(not a new gc\-dynamic language\). I have been testing it and it is awesome. It support dependencies, hidden compilation \(cached in cargo's directory\), and can be used as scripting perfectly.
Thanks, didn't know about it. It is great to work with pipes and subprocess.
Is there a serde-compatible HOCON parser? If yes, it'd be piece of cake to switch it. :) I'was already considering adding an extra API to allow any serde-compatible format with `toml` being the default.
This might be obvious, but BTreeMap implement a BTree, which is a complex thing by itself if you want to do that efficiently.
In short, there is a lot of `unsafe` code.
I am about to finish imag 0.8.0 in the next two weeks, before my departure into my sabbatical. This will be a rather small release, but hey... :-)
I have problems convincing the compiler about my universal bound: extern crate serde; extern crate serde_json; use serde::de::DeserializeOwned; use serde::Serialize; trait Bar where for&lt;'a&gt; &amp;'a Self::T: DeserializeOwned, Self::T: Serialize, { type T; } fn test&lt;I: Bar&gt;(t: I::T) -&gt; String where // why is this bound needed? for&lt;'a&gt; &amp;'a I::T: DeserializeOwned { serde_json::to_string(&amp;t).unwrap() } https://play.rust-lang.org/?gist=f57f3c86590f5b1950f20f6f2d8e4235&amp;version=stable&amp;mode=debug Why do I need to duplicate the bound `for&lt;'a&gt; &amp;'a I::T: DeserializeOwned` on the function? As I understand it, if there exists an implementation of Bar for t, then &amp;T must have an implementation of DeserializeOwned, because of the bound of the trait, therefore the function should work. Can anyone explain why the bound on the function is needed?
&gt;Btw, here is my interpretation of what Rust with indentation\-based syntax would look like Just like with Python, it's harder to read and navigate \- can't press &amp;#37; in vim to walk between start/end of a block, in IDEA you can't see the snippet of where a block begins when it's off screen, auto indentation is much trickier as IDE wouldn't know where to place the cursor on the new line and you'd have to manually adjust by counting spaces, etc. What's cool though is semicolons are gone \- the biggest ergonomics fail of Rust for me. Kotlin and Scala proved you don't need them, yet some languages cling to that vestigial organ, so to speak.
Prolog is one of those languages that is great to know but might be hard to get into in your free time. I think that it should remain a part of many curriculums.
Great work. I'd still really hope for an unbiased, in\-depth comparison \(features, benchmarks\) between CockroachDB and TiDB, which I haven't found anywhere.
Thank you
Usual context-as-a-service comment: &gt; warmy is a crate that helps you introduce hot-reloading in your software.
Hehe, thanks!
Great improvements! I noticed that cargo is compiling every crate regardless if it's actually used or not. Couldn't the compiler walk the functions used in [`main.rs`](https://main.rs) , and compile these recursively? Sorry if it's a dump remark :\-S
Couldn't Vim treat increased/decreased indent level as start/end of a block? How does Vim do this with Python code? Yes, I don't like semicolons either, and Rust is not consistent, because commas are used inside structs and enums, but semicolons inside traits and to separate statements. My transpiler basically works in 2 passes, first inserting braces and semicolons, then changing the semicolons inside structs/enums into commas. The detranspiler has the two passes inverted. So the transpiler could be modified to just remove the need for semicolons (and commas inside structs/enums) but braces would still have to be typed manually. Then this inconsistency between semicolons/commas would become invisible.. Also the transpiler auto inserts a comma at the end of single line match cases like `pattern =&gt; x`. For me the biggest practical downside of this dialect is that F12 / "Jump to Symbol Definition" doesn't work anymore and that Syntax Highlighting fails (both because of the way Rust-Enhanced works in Sublime Text).. Not unsolvable problems but the braces/semicolons in Rust aren't a huge issue. This dialect is mostly a proof of concept experiment..
The work described by the blog post took place over about 14 or 15 work days. I took 2 or 3 days at the start were to make rustc-perf changes, and the rest for the optimizations. Builds are slow, as is doing proper benchmarking runs of the suite, as are the profilers. So I actually have three different clones that I switch back and forth between while I'm waiting on various things. (Plus one unmodified clone as a reference point.) Making the code modifications is often quicker than doing the initial profiling and the subsequent measurements. (The FxHashMap PR is the most extreme case of that, and the dump_allocs one was almost as simple.) There were another 3 or 4 optimization attempts that failed, where profiling data suggested an opportunity but I wasn't able to get a worthwhile improvement.
You still have the choice of IPC (named pipes) or TCP, so you don't need to rely on the network stack. You'll need to test it, but it should be fairly low latency. I prefer scaproust's native implementation because I don't want to install nanomsg/zeromq libraries everywhere I use my rust crate.
Thanks for the pointers. Maybe I worded it wrong, I'm not trying to implement HIP, just something similar. The transport uses DTLS and the signaling happens over the same connections as the transport, to avoid problems with middleboxes. RFC 7343 looks interessting. Maybe I'll even try to HIP compatible in the long run.
[removed]
The optimization attempts that failed would be useful info in the blog post, both for the educational value as well as to help avoid having someone else waste their time chasing them down. Thank you for doing this work and these write ups about it! So great.
In the rare cases where you absolutely cannot encode your invariants into the type system - for example, if you have a `Foo` that might be invalid, you might actually want (to take it to an odd extreme) a `FooParams` which becomes a `FooBuilder` which becomes a `Foo` that is guaranteed to be valid and you can't create a `Foo` any other way - asserts work. But sit down and think about RAII for a bit first - can you design your program so that creating a `Message` always results in a valid `Message`, and it stays valid until it's dropped? Could you split it into multiple types to make it work like this?
&gt; Please, learn how to internet. No.
it also depends on how you define "define" and "you"
Just mostly finished [language server support](https://github.com/reproto/reproto/blob/master/doc/usage/language-server.md). I'll be using that and the visual studio code plugin to record a screencast showing off why it's awesome. Next we need to specify how to do query parameters in our [HTTP/1.1 support](https://github.com/reproto/reproto/blob/master/doc/spec.md#http-services).
Great :) I plan to use warmy in my project together with spectra's cheddar soon (after finishing the work on the other modules).. 
When you're calling `to_string` you need the type to be `Serialize` only. Also, the whole point of `DeserializeOwned` is that you don't need a lifetime. So you could do `trait Bar { type T: Serialize + DeserializeOwned; }` or `trait Bar: Serialize + DeserializeOwned {}` but why do you even introduce this `Bar` trait?
&gt; Even rockets explode, and they have the most stringent processes I've ever heard of. Fun story: apparently there are some rockets that use Java. They even use the GC; it's determined that, with the distance the rocket can fly, it can't generate enough garbage to ever have a collection kick in...
The rallying cry here is ‚Äúmake invalid states unrepresentable!‚Äù, which is using the compiler as a theorem-prover for your code. That's done using the type-system. So, rather than needing null-checks (null being an invalid state), Rust references *cannot* be null - the invalid state is not representable. Rather than testing Message for validity, Rust code will typically have a way of creating a valid Message (possibly returning a `Result&lt;Message, Error&gt;` if the creation can fail). It's then impossible to create an invalid Message. Then, if any method would invalidate a Message it would take the Message by value rather than reference. Since Rust types are move-only, it's not possible to use the Message you pass to such a function after calling it; the invalid state is not accessible. In such code, the compiler successfully compiling it proves that any Message object encountered *is* valid, so runtime checks are unnecessary. It's not *always* possible to use the compiler to prove correctness in this fashion, so there's still some call for the defensive programming you're used to. The choice of panic-vs-Result is generally ‚Äúis this a programmer error, or a thing that could happen in a perfect program?‚Äù For example, it's generally not possible to prove you're not indexing out-of-bounds into a Vec^1 - this results in a panic. It's impossible to prove at compile time that a file will exist, and it's not a flaw of the program, so the file operations return Result. This all assumes no-unsafe blocks a a non-buggy compiler. Unsafe blocks need to carefully ensure they maintain these invariants... And there's nothing much to do about compiler bugs other than fix them :) ^1: but by using an iterator instead it *is* possible to prove no out-of-bounds access.
I'm slowly porting the original Zork text\-based adventure game to Rust. It's a hard lesson in the evils of GOTO.
Every crate is a compilation unit and the linker links up the imported symbols, so while it's compiling a crate it doesn't know which symbols of it are imported by deps (and it couldn't, there could be glob imports). Theoretically it's possible to make the whole compilation lazy in that way, but it would take **a lot** of work to re-architect the whole compiler/linker to be able to do cross-crate lazy compilation, and it's not guaranteed that it would speed up the compilation. It depends on what percentage of symbols are used on average, weighted by the time it takes to compile them, and how parallelizable the lazy compilation would be. I think what could be done more easily is AST diffing to only recompile symbols affected by changes, but maybe it's doing that already for incremental compilation.. But I think the incremental compilation should be much faster than it currently is with AST diffing..
&gt; Is there a way I could still make it explicit? It *is* explicit; you're passing in `&amp;mut` references. There's no reason to do that *unless* you're mutating them. You could refactor it to take `grid_1` and `grid_2` by-value, then return the mutated vectors, but what you have is absolutely fine.
I think the more honest approach is the one we‚Äôve taken at work with our open source projects: ‚Äúalpha quality, it‚Äôs only tested in production‚Äù :P
Might be unrelated, but have you looked at the Ion Shell? Ion is the CLI shell in Redox OS, but it is designed to also work on Linux. It has its own scripting language designed to be a superior alternative to bash/zsh/fish. The syntax is based on Rust and has some similar features.
Wow. This looks amazing. Especially chuffed with the TiSpark work - looks like one of the most featureful Spark connectors I‚Äôve seen to date.
Just as u/Quxxy said, passing in `&amp;mut` is considered good enough. But if you want to go the second way, perhaps because you want to re-use the references in the same expression, you could add some explicit lifetimes to make it compile: fn generation&lt;'a, 'b&gt;( grid_1: &amp;'a mut Vec&lt;Vec&lt;bool&gt;&gt;, grid_2: &amp;'b mut Vec&lt;Vec&lt;bool&gt;&gt;, rule: &amp;generation_rule::GenerationRule, x_size: i32, y_size: i32, ) -&gt; ( &amp;'a mut Vec&lt;Vec&lt;bool&gt;&gt;, &amp;'b mut Vec&lt;Vec&lt;bool&gt;&gt; )
Wrapping everything in `Option&lt;_&gt;` is easy, but has some overhead. The discussion is apparently around `unsafe` trickery to do this without overhead.
Neither of those has functions are likely to be appropriate for cryptographic uses. Rather, we‚Äôre talking about hash functions that work well for hash maps in adversarial situations: if used on a public-facing application, can I abuse weaknesses of the hash to make writes/lookus linear instead of constant-ish? In the compiler you control the inputs and any such pain is self-inflicted, so that sort of collision resistances matters less
Fair enough. I understand that this would be a lot of work. About the AST diffing, there was a blog post a while ago, I think incremental compilation is already working that way.
I don't find it weird. The "stability and correctness" section in the OP mentions a number of things they did to create better tests.
I'm curious if your use case is going to involve integration with any other National Instruments formats or products.
It depends on what you're using it for. I have a project where the backend is in Rust and the frontend would be in Rust if it had mature Qt bindings. ...I still use Python to prototype the algorithms before I write them in Rust because I don't really know what I'm trying to write at first. I just have a big corpus of "given input -&gt; desired output" pairs and a harness I wrote to give me an aggregate accuracy score and Python is the quickest way to experiment with different ideas for the heuristic algorithm.
Sadly I don't have the capacity to provide this fully unmoderated. If you want to have a project included, just send me a DM. :)
More work on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). I finished review on a couple huge PRs from /u/Aehmlo to add 8 new quantities! I also spent a bit of time investigating why the `rustc` privacy checking phase is taking [forever](https://github.com/iliekturtles/uom/issues/52).
Most of the time the keys are either pointers or sequentially assigned indices, which means the hash function doesn't matter as long as it's fast for constant-size input and doesn't cause too many collisions (in fact, `BTree{Map,Set}` can have better performance in some of those cases, but it's not clear how we can fine tune this). In *this* instance, however, the map in the interner has strings as keys, so the hash function should do well on typically small but variable length input, but *also* it's directly affected by user input (e.g. variable names and string literals), so unlike most of the compiler, it's closer to those "pathological lookup/insert behavior" situations. But still, the compiler team's stance is that if you *have to go out of your way* to craft an example that is pathological, you can also do worse with less sophisticated large inputs or very deep nesting types and expressions, so defending against them isn't necessary. If you have a service like https://play.rust-lang.org which has to compile untrusted input, it's *your* responsibility to sandbox is and enforce resource (time, memory &amp; disk) limits.
Thanks
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust.
yeah, specifically, you don't want every access to branch on "hey are we empty?". Right now we get a considerable simplification from BTreeMap being able to assume that there's always a properly initialized node. Basically you want to very carefully ensure that *existing* checks naturally cover the empty case, which the naive answer of Option or a null root pointer don't. details at: https://github.com/rust-lang/rust/issues/50266
Thanks!
It's really a trade-off between certainty that the code is right (i.e. having `assert!()`) and performance. Considering that you might use release-builds on different scenarios from debug-builds (e.g. real world data rather than test data), and that the performance implication of an assertion usually is very *very* low, choosing `assert!` often makes sense.
With the (rare) caveat that destructors aren't actually guaranteed to run. :)
im using the old tokio core btw. I have an instance of the channel Sender in the main struct. The message type is something like enum Msg&lt;T&gt; { SetupConnection(Box&lt;_&gt;),Msg(T),DropChannel } When it receives SetupConnection it does something like let forwarding = input.forward(tx).then( if Ok((stream,sink)) { sink.send(Msg::DropChannel) ); handle.spawn(forwarding) Then if i receive DropChannel it cleans up the rest. 
Awesome; this answers my question exactly. Incidentally, ggez is straightforward enough when going off their examples, that I'm able to do other neat things related to my project easily.
The original Fortran version, not the Z-machine-based re-implementation? That's hardcore.
Use `*robot_location = ...` to do the assignment through the mutable reference.
Yes, it's a layered system. The lowest layer is RocksDB, which is written in C++ for a single-node key-value store. This was an existing database that they are building on top of. TiKV is layered on top of that to provide a distributed, consistent, horizontally scalable key-value store. TiKV is written in Rust. The Placement Driver (PD) manages the TiKV cluster, providing tools to allocate and balance data between nodes in the TiKV cluster. It is written in Go, and uses etcd (also written in Go). TiDB is an implementation of a MySQL compatible relational database on top of TiKV and PD. Each instance appears to be stateless; the state is all stored in the lower layers. This allows you to use a load balancer to distribute load between different instances of TiDB. TiDB is written in Go. So yes, in this stack only TiKV is written in Rust.
If I want to run a bunch of futures until one of them returns, should I be using future's `select` where possible, as opposed to tokio's `spawn`? Up until recently I've used a future mpsc channel where I send a stop pulse to the future used in tokio's `run`. [Commit](https://github.com/jD91mZM2/xidlehook/commit/e0115677e0725781808ba816b91b4f5c342db50a#diff-639fbc4ef05b315af92b4d836c31b023R343). I'm wondering if this approach is better or worse... It certainly can get confusing when you want to [make one of the selects optional](https://github.com/jD91mZM2/xidlehook/commit/bb8e18d94b3d995b57094a79199f3f199d300100#diff-639fbc4ef05b315af92b4d836c31b023R293).
Python is the first language I ever learned, and probably the one I'm most proficient in. I've been writing Rust for two years and it's by far my favourite language. That said, there are times where Python is just flat out a better choice. I use it all the time for small, throwaway scripts, and it's a lot faster to write than Rust for certain tasks like simple text and file manipulations. Speaking purely from a personal perspective (since different fields/workplaces will have different requirements) I would use python for anything I don't expect to have to maintain. e.g. it does one simple job, and I don't plan on adding any more complexity to it. I would use Rust for any larger project which I expect to update, extend, and keep well tested for a longer period of time.
Another thing I would add since I haven't seen this precise point made: it is _never_ a waste of time learning a language. They all have their uses, and they will all help you to understand other languages. I would still suggest learning one at a time (start with Python) but you will never be wasting your time learning another.
I don't understand what the problem is. "Battle tested" doesn't have a precise meaning and is open to interpretation. The content of the post unambiguously clarifies what they meant by it. There's no problem here.
I wish here was a bot for that. Almost every announce here comes about changes, but what is it for, first of all? /offtop
Very cool. I hadn't even thought of using rayon with wasm. I like the last commit message. :) Also, I did more digging and came across this link: https://pspdfkit.com/blog/2018/optimize-webassembly-startup-performance/ I haven't read through it completely, but it looks to be exactly what I want. The only thing is that I got an `imports` not defined when I tried their last code block along with their getCache() function.
I only find the use to be weird, not blasphemous or anything. I find the use odd, and not aligning with how I believe the common interpretation for "battle-tested" would be, with a newly-released major revision containing large amounts of new code being the exact opposite of "battle-tested".
No JIT just an interpreter? I don't quite get this: why not just use cretonne?
Just a disclaimer: We are having a *very* pedantic debate about the use of the term "battle-tested", *not* about TiDB quality or anything along those lines. If you do not care for linguistic debates, abandon ship! Hmm, that's a fair interpretation. However, I still find it to be a bit of a grand label to put on a freshly minted major revision. For reference, one can definitely consider Postgres to be a "battle-tested" product with 29 years having passed since v1, but even then I wouldn't consider PostgreSQL 11.0 to be "battle-tested" on the day of its release. It can't "go to battle" before it is released, after all. It would be entirely fair for TiDB to refer to themselves as battle-tested *in general*.
Is there any chance of getting Rust appimages/snaps/etc? 
wasm-core is built to support multiple backends, so it's not just an interpreter. Ideally [it should support cretonne](https://github.com/losfair/wasm-core/issues/11) as a backend option :-).
Just to clarify -- this is hot-reloading of external assets, not code, correct?
Yes - the type system covers much more, so you have to check much less at runtime. BTW, even when the type checker is not enough, you can often create wrapper types that add more guarantees. For example, in the standard library you have [`OsStr`](https://doc.rust-lang.org/beta/std/ffi/struct.OsStr.html) which can be any sequence of non-zero numbers and [`str`](https://doc.rust-lang.org/beta/std/primitive.str.html) which has to be a valid UTF8 string. You can convert from OS string to string with [methods that do runtime checks and can potentially fail](https://doc.rust-lang.org/beta/std/ffi/struct.OsString.html#method.into_string), but once you got the verified type you can pass it along with it's guarantees. Let's modify our example - let's say that valid messages have numbers lower than 20 (negatives are always OK, for some odd reason) for numeric messages and strings of at least 4 characters for textual messages. We create a wrapper type `VerifiedMessage` - that can only hold messages that have passed these checks: https://play.rust-lang.org/?gist=1547f39b83dcbec9c7b2d4737aee76d9&amp;version=stable&amp;mode=debug `Client::send_message` requires a `ValidatedMessage` - so it does not need to perform the validation itself. We know that `ValidatedMessage`s are always valid because the only way to create one outside the `messages` module is to use `into_validated()`. Also, because it's field is private, a `ValidatedMessage` will stay valid. So, if we still have to verify the message at runtime - what is this good for? For one, we can choose where we want to do the verification, and handle possible errors accordingly: * If we got the message from somewhere external, we can do the verification and handle the failure as soon as we read the message (e.g. - warning the user that their message is invalid) * If we constructed the message ourselves, and know for sure that it should be valid, we can `unwrap()` the result to just get the `ValidatedMessage`, crashing the program with a stack trace if it happens to be invalid.
Woohoo, it works great! We've been wrestling this bear for a long time, trying to make an API that makes both warmy and ggez cooperate well, so it feels really good to have something good at last. [Example code here.](https://github.com/ggez/game-template/blob/master/src/resources.rs) Contrary to your changelog I don't know if we want `warmy` to become part of ggez itself any more than `specs` or `log`... But having them able to work together with a minimum of glue code is arguably even better.
Yes, and I‚Äôve already done that. [Blog post here](http://phaazon.net/blog/spectra_plugins).
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [warmy-0.7.0: VFS, context passing, (re)load methods and tutorial](https://www.reddit.com/r/rust_gamedev/comments/8g0ht0/warmy070_vfs_context_passing_reload_methods_and/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
That‚Äôs a good precision to add. I‚Äôll edit the changelog! Thanks!
Switching over [tarpaulin](https://github.com/xd009642/tarpaulin) from syntex_syntax to syn! Once that's done I'll look into how much work is left in HTML reports and either finish that or just release another version + blog post cause a lot has changed since the last release in december. 
It would have the same semantics, with the caveat that in Rust-as-it-is [certain values can't actually be moved](https://play.rust-lang.org/?gist=a040193962ff6a1405d3f918ab9111ad&amp;version=stable&amp;mode=debug). So you'd have to add some hand-wavy rules like values are magically moved back into place in case of a panic, etc. But if you wave your hands enough for the corner cases, I think your intuition is correct. 
a version of rust with whole program (or intra-file at least) type inference :) 
At first glance, I'd guess it's that you are constantly crossing the JS/WASM boundary to invoke randomness. Instead "Rust part was quite bad", you might want to say "Rust combined with external JS invocations are quite bad". Even though you had rand problems, I'd say it's not fair to compare pure JS with impure Rust.
I see a lot of mentions of OLAP things, is it suitable for OLTP workloads?
Python is good for some things. It tends to be faster to write. Performance is worse, or course, and the dynamic typing can lead to bugs and reduced maintainability. There are some things where I think you can make a good case for either, and have a holy war about the best programming language. But there are others where most advantages of Rust are simply irrelevant. For instance, single-use scripts where performance is not important. Not necessarily a perfect example, but one thing I've written is [this script](https://github.com/ids1024/lscli/blob/master/extract.py) which converts an xml format to an sqlite database. It takes advantage of Python's great capability to hack together complicated string manipulation fairly easily. I personally would not favor Python for large, complicated software (or anything performance critical), though others might. But it is great for quick scripts.
Yesterday I happend to watch [https://www.youtube.com/watch?v=pBYqen3B2gc](https://www.youtube.com/watch?v=pBYqen3B2gc). Around the 18:00 mark there is a slide about performance. Based on what I learned from that talk WASM does not sound like a good fit serverless as the promised speedup will come from skipping both JS parsing and generating bytecode outweighing all the years of JS optimizations. \(I am assuming Azure will try to skip the JS parsing and generating bytecode step as well in one way or another. But I have only heard of serverless, so what do I know...\)
Hey, Darsstar, just a quick heads-up: **happend** is actually spelled **happened**. You can remember it by **ends with -ened**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
[removed]
This is such a red herring. Yes, you can't rely on destructors running *as the author of a type*. But that doesn't mean destructors will magically stop running! That only happens when the user of the type *explicitly* does something to prevent it. And this has nothing to do with whether you need to check the equivalent of `IsDisposed` in Rust- regardless of the guarantees around when destructors run, there's still no way to get a dead object. If the destructor has run, it's gone; if it hasn't you can use it.
You shouldn't use assertions in cases where it makes sense for destructors to run. Assume that the result of a user triggering an assertion is an email to the developers with a printscreen of the stack trace (they don't know how to copy-paste form a console)
delete
[Here](https://www.reddit.com/r/rust/comments/6pgyy1/serde_trait_objects_work_again/dkphgsj?context=3) is the thread where I first grokked this aspect of Rust. The "unifying static/dynamic dispatch" thing I mentioned was actually type erasure, delegating a generic method to a non-generic one and back to a generic one. In that thread there are two traits, `T1` and `T2`, with a statement like `impl T2 for T1`, which means "implement `T2` for `T1` trait objects". That's what really solidified for me that a trait is just as much of a type as a struct, so `impl Type` and `impl Trait for Type` work when the `Type` is a trait just as they do when `Type` is a struct. Moreover, the meaning is the same - the methods are applicable for everything of that `Type`. When `Type` is a trait `T`, methods in the `impl T` or `impl Trait for T` blocks are only callable on things matching the the type `T`. Because `T` is a trait and the methods can only take `&amp;self` or `&amp;mut self`, that means only things that are (or `Deref` to) `&amp;T` fit the bill, and those things are by definition trait objects. Given that the meaning is the same, it's not _too_ surprising that the book doesn't explicitly call out this behavior, though it certainly would be useful if it did! All in all I think the full comments and linked repo are a practical answer to "what's the point of that" :D
I'm putting the finishing touches on a suite of small utilities I've authored to turn the PC motherboard speakers of a lab of ~80 computers into one big polyphonic MIDI synthesizer. The utilities are: - [MIDIplex](https://github.com/jswrenn/midiplex), for volume-aware distribution of a polyphonic MIDI stream across _N_ strictly-monophonic outputs. - [bam](https://github.com/jswrenn/bam), for turning the PC motherboard speaker into an ALSA-integrated monophonic MIDI synthesizer. - [MIDInet](https://github.com/jswrenn/midinet), for shooting MIDI events over the network from the conducting computer to the performers. - [lsMIDI](https://github.com/jswrenn/lsmidi), which provides a computer-friendly output of MIDI devices that I use in the bash scripts that glue all these utilities together. It's been a tremendously gratifying side project to hack on, and I've just gotten it to the point where things Just Work, even for _really_ intensive MIDI files. I'm looking forward to recording a proper demonstration video, and, eventually, we're going to hook up a physical keyboard and hold a proper recital!
It's trivial to prove that you're not hitting UB if you use a language that doesn't have UB.
Awesome! I had no idea calling tensorflow from rust was possible. It doesn't even look too difficult either!
But that would be impossible with writing extremely inefficient C code since Haskell uses a completely different memory model. "exactly like Haskell code" to me implies that the C code was written in a way that enables lazy evaluation and heap allocates everywhere. In an ideal world, then what Church and Turring said about all programming languages being equal would be true. But we don't live in that ideal world. If we did, C would have been obsoleted years ago as opposed to just recently when Rust released.
I apologize -- my intent was to be helpful, but I think my comment ended up not being so. Thanks for making sure the facts are straight. :)
I love writing my software twice! It means I have twice as many chances for bugs. That said, it's less likely that I'll make the same bugs on both versions unless I try translating it verbatim, but if I don't, I may end up with a completely different design that the prover can't find anything in common.
I'm hoping we can finish incorporating the last of my outstanding PRs on [`uom`](https://github.com/iliekturtles/uom), and I'm going to try to get linting working on it as well, but I anticipate being pretty busy elsewhere this week.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/iliekturtles/uom) - Previous text "uom" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
If it involves correctness (especially safety), `assert` all the way. Treat that as a programmer error, since it isn't really something normally expected, or that a programmer should recover from. I find I use `debug_assert`s internally in some libs when I might have complicated state that is hard to express in the type system. This is mostly to help myself, if I change something around and violate a contract I made myself, the debug assertions should hopefully be triggered by the test suite. But I wouldn't want the assertions check every single call, since it doesn't help more, but has a performance cost in hot code.
You can use assert, but I'd say that's not quite the rusty thing to do all the time. For example, let's say I have a Message struct, with an 'is_valid()' method. That method, in your case, might look like this: fn is_valid(&amp;self) -&gt; bool { unimplemented!() } But now you're requiring that others call this method, and it may cause redundant execution of code if called in many places. Instead, what if we had: struct InitialMessage {} struct ValidMessage {} Now, you can change your `is_valid` method to: fn is_valid(self) -&gt; ValidMessage { unimplemented!() } Now callers just take `ValidMessage` as their type - and it's a compile time failure if the *caller* does not first validate. And, as another benefit, calling `is_valid` once is sufficient to know that for the rest of the program the message is valid - no one else has to check, just one call. I recently took some code that had structs with Optional fields that represented their possible states. It was fine for a first pass but led to cumbersome edge cases and code. I split the single struct into multiple structures that defined their states within their types and fixed some bugs just by virtue of restructuring.
When your software is processing external data (e.g. web server requests), it can be vulnerable to [hash collision attacks](https://en.m.wikipedia.org/wiki/Collision_attack). An attacker can send carefully crafted payloads that can cause system overload by turning an anticipated O(1) operation into an O(n) operation. The short version of how the attack works: * make lots of different values which you know will have the same hash, for the server's hash function * make a request with these values as POST data, knowing that the web server will store them in a hash map. * Congratulations! You've turned a hash map with O(1) access into a linked list with O(n) access.
**Collision attack** In cryptography, a collision attack on a cryptographic hash tries to find two inputs producing the same hash value, i.e. a hash collision. This is in contrast to a preimage attack where a specific target hash value is specified. There are roughly two types of collision attacks: Collision attack Find two different messages m1 and m2 such that hash(m1) = hash(m2). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Non-Mobile link: https://en.wikipedia.org/wiki/Collision_attack *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^176801
Are you using the plain beep or modulate some sample on the speaker? 
My Cretonne [toy language demo](https://github.com/sunfishcode/simplejit-demo) works, and the associated tutorial is about half finished, but working on that made me notice several more things that I want to fix before broadcasting it too widely: support for older CPUs in simplejit, a simpler targeting system, and we have someone starting on Windows support, which should broaden the audience.
op here. This is an article explaining a pattern (which may or may not be good!) I'm exploring as I try to write a dataframe in Rust. I'm new at writing articles to explain code, so please be gentle! I also welcome feedback, on the code or on the article itself. (For those who are impatient readers, there are direct links to code snippets in the intro, or you can go straight to my dataframe PoC [llamas2](https://github.com/hwchen/llamas2).
I was trying to refer to any modern language does doesn't have UB in safe code and I'm pretty sure Rust is one of them. I've heard of Idris in my search for Rust-Haskell hybrids, but from what I can tell, it uses a C-runtime and implicitly heap allocates. In my preferred field (OSDev), I don't have a heap to allocate from. My closest matches have been LinearML and Lollipop, both of which have very little development and Lollipop only exists as an interpreter in Haskell the last time I checked.
"Science advances one funeral at a time."
I guess that shows how idiomatic this style is in Rust
1. Doesn't support `-` to indicate standard input should be read. 2. No files being given doesn't imply standard input as the only file name (meaning that it should be passed through to standard output).
https://docs.rs/utah/0.1.2/utah/ You may be interested. The project is not in active development but the goals are the same. I'm not the author, but he was my cospeaker at RustConf and we discussed writing a Rust dataframe quite a bit. I'm glad someone is reviving interest in the topic. The thing about a dataframe in Rust is I don't think dynamic typing is the way to go. What we found (as discussed in our conf talk) was that having static types for our data was really helpful. As we had experienced in the past, nans (or empty strings, or None, or all sorts of garbage) could propagate / lead to weird behavior in feature extraction, and then later crash in model generation. Having a strong sense of types for our data let us have more confidence in our pipeline and, subsequently, in the correctness of our model - we knew our features were being extracted to what we had expected. I think the goal of Utah was to focus on the combinatorial aspect of a dataframe - mapping columns to new columns, iteration over rows, etc - as well as the really nice tabular, queryable nature. Anyways, food for thought.
I'm not too vested in `rand` (I've used it in very few projects), however it would be nice to have a convenience function in the crate IMO. Make it obvious in the docs that it isn't the most secure or best RNG but for simple, non-critical applications it works well enough.
You want to post this to /r/playrust. This subreddit is for the Rust programming language.
Two raspberries should do the trick. Having them connected through a wifi hotspot, or wire if that's possible, is probably the easiest way.
Looks like these are already in an issue [here](https://github.com/sharkdp/bat/issues/2) -- good to know, though!
Sometimes there are [objective arguments against using it](https://www.reddit.com/r/rust/comments/7wxk7m/ripgrep_080_configuration_files_compressed_file/du4jn1k/) (although I, personally, would still try and make it happen). Understandable though. 
Awesome, that sounds simple enough. What would you say is the most minimal/cheap model of raspberry I could use for this? The Zero W looks like it could work.
From RTFA, it seems this has nothing to do with security, and little to do with performance. It's just about encouraging people to use `thread_rng().gen()` to make it more obvious what's going on under the hood.
Thanks for the explanation! I suspected the policy was something like that, but it's nice to have it clearly explained.
I haven't toyed with them since model 2b, but it looks like the zero w should work. Would be cool to see it when you have it running!
Bam makes a plain beep on the PC motherboard speaker. It does not actually execute Johnathan Nightingale's [beep](https://github.com/johnath/beep) utility. Instead, [bam itself makes the `KIOCSOUND` `ioctl` request to `/dev/tty0`](https://github.com/jswrenn/beep/blob/cbf38e06405ab80b2a22d6dc1d10da7a5216152b/src/lib.rs#L47-L58). 
`cat` is not for printing files with file numbers, compressing blank lines or syntax highlighting. It's for con`cat`enating files! Please don't say that you made a `$UNIX_COREUTIL_NAME` clone if you completely change the purpose.
RasPi seems overkill, an stm32 (like bluepill) or an esp8266 if you really want wifi would be much cheaper and still be more than enough
I tried this yesterday without success. Libsodium can compile to WASM so I guess it is possible. Let me know if you find a way!
For what it's worth, I quite like just being able to call `random()` and be done with it if I'm not reusing or otherwise fussed about efficiency. It's convenient, it's obvious, it requires essentially no additional thought. `thread_rng` on the other hand, although explicit, does not exactly trip off the tongue. I guess it's another instance of deciding whether we'd rather have the papercut to make people pay attention to what they're doing.
You may find [this] (https://github.com/Xaeroxe/platform/commit/d4e88742df348de4cd116f23b4e45cca93a3754a) commit to be of interest.
That, and the only thing that POSIX actually *requires* is unbuffered support. (Which GNU cat seems to ignore according to it's man page, which might just mean that it's always unbuffered, I guess?)
I think folks are getting hung on it not being POSIX-compliant, and that's fair enough---but as a quick terminal file-viewer / checker, this is really good and will make a great addition to my toolbelt! &gt; cat is for concatenating files I love combining unix tools into ingenious one-liners as much as the next person, but 99% of the time I use `cat` is to check out a file's content.
I'll make a post for sure! Will be my first foray into microcontroller stuff with Rust so it should be fun.
I prototyped [Pyret](https://www.pyret.org/)'s initial* language-level support for [a data science curriculum](http://www.bootstrapworld.org/materials/spring2017/courses/data-science/). I left with a _tremendous_ appreciation for the value of language support for anonymous record types for data processing (aka "object literals"). If your language has some mechanism of defining syntactic sugar, higher-order functions, anonymous records and, optionally, support for _row polymorphism_ (e.g., you can express the idea that a function's parameter _must_ have the fields `foo` and `bar` but can also have some other stuff), you can trivially build all sorts of _really_ ergonomic type-safe interfaces for data processing pipelines. For a while, we basically had something shaping up to be a better version of LINQ. I think this is a major untapped area of exploration for ergonomic, unopinionated language-level support for data science. If anybody knows of a statically-typed language that checks these boxes, I'd love to hear about it. --- ^*_What‚Äã ‚Äãis‚Äã ‚Äãin‚Äã ‚Äãthe‚Äã ‚Äãlanguage‚Äã ‚Äãnow‚Äã ‚Äãand‚Äã ‚Äãused‚Äã ‚Äãby‚Äã ‚Äãthat‚Äã ‚Äãcurriculum‚Äã ‚Äãis‚Äã ‚Äãvery‚Äã ‚Äãdifferent‚Äã ‚Äãfrom‚Äã ‚Äãthe‚Äã ‚Äãinitial‚Äã ‚Äãprototype‚Äã ‚ÄãI‚Äã ‚Äãrefer‚Äã ‚Äãto‚Äã ‚Äãin‚Äã ‚Äãthis‚Äã ‚Äãcomment._ 
&gt; not POSIX-compliant It's not just not POSIX compliant. It's **not cat**. It's literally in the name, it's used to *concatenate* files. There's very few uses of cat that only involve one (or no) arguments that couldn't be replaced with something else. It's like someone calling C# a C clone. Yes, C# is a good language. But it's not C. 
+1, might want to use `FnOnce` instead of `Fn` though.
There's also [bat](https://github.com/astaxie/bat), which is a moderately popular cURL alternative for certain use cases... which is not to say that `bat` is an eternally reserved name now, but maybe something else could be invented. `codeview` with an alias of `cv`, for instance. More descriptive name, shorter alias.
It's actually `fn`. I tried to get `FnOnce` going but I don't think it's possible to implement in stable Rust right now.
Yeah totally, the title is misleading, but I still think the tool is neat. I do 'live' in the terminal, I didn't say 99% of their time I view files I use cat; but the other way around. If it's some tiny script that I want to inspect while doing other things cat is handy, not bringing the context switch vim requires (tho even there, head, tail or rg is generally more useful). I don't often need to concatenate files is the point I guess. Anyway wasn't saying that people weren't right about it not being a cat clone, more that they didn't seem to judge it on its own merits,despite the title. 
yup, dont make cross calls inside a tight loop, rand supposed to work in wasm according to this https://github.com/rust-lang-nursery/rand/pull/197
lmao where were all you clowns when git shipped `git cat-file`
Well, in my case I live inside NeoVim that is running inside suckless terminal. Suckless terminal doesn't have scroll buffer. I rarely heed to spit file into stdout, so I either rg/nvim/less it. Now if there was a pager with git and syntax highlighting support...That would be an amazing feature. 80% of my use of cat is `cat /dev/null /some/file` and `cat xa* &gt;&gt; something.tar.gz` 
I don't know what you mean by "RTFA" but from the first response in the linked issue: &gt;`random()` is cool but prone to be used in sub-optimal ways ‚Äî although that doesn't always matter. If performance nor security was/is a concern with the function existing, then I don't see what good making the user "realize what's going under the hood" serves. I think the people most likely to use the `rand` crate are beginner programmers or those learning the language, and making a small little game a la in the book. In that scenario you really don't gain anything by revealing the internals. Again, I don't have strong feelings either way, I barely use the crate, so if people who do use it have better/stronger opinions then that's probably worth more here.
`git-cat-file` doesn't claim to be a cat(1) clone. It's a utility to concat or read *git objects* and provides options useful to people using it like that.
OK. I used to code assembly against the PC hardware in the 90s and we had some neat tricks to get some actual samples out of PC speakers using DMA.
`random()` is not a zero-cost abstraction and I don't really see how it is better than `thread_rng().gen()`, which scales better: 1. You can easily use a different/deterministic/faster RNG. 2. It is more efficient if you create one `ThreadRng` and use it to generate several values rather than calling `random()` several times. I don't think discoverability is an issue, because it is the first example provided in the docs/readme.
I wonder if the ok_or api should be reversed so that the shorter invocation is lazy and the eager invocation is longer to type. Seems like it would lead more people into the pit of success
Thanks! I suspected as much, but I was surprised that the wasm implementation was that much slower. I'll continue my tests and once I get rand working, there is going to be an update üëç (I'll also think about the wording as suggested)
&gt;however the object inside can still be null No, that is not so. The Option\&lt;T\&gt; object can be null, but, what is inside cannot be null. It is either present, and has a non\-null value, or is absent. This is equivalent \(pretty much\) to Rust's None \(absent\) and Some\(T\) \(present\). The problem with the Java Option\&lt;T\&gt; is that the Option\&lt;T\&gt; itself is an object \(not an enum/sum type like in Rust\) and can itself have the value "NULL", which, to your point, kind of undermines its usefulness. That being said, in Java, Option\&lt;T\&gt; is only really supposed to be used as a return value. It is not intended to be used as a parameter or as a type of a field or local variable \(though many abuse it for such purposes\). See [The Mother of All Bikesheds](https://www.youtube.com/watch?v=Ej0sss6cq14) [https://www.youtube.com/watch?v=Ej0sss6cq14](https://www.youtube.com/watch?v=Ej0sss6cq14)
Python was my first language, too. And for an absolute beginner it has many helpful features: * forgiving, dynamically typed * large and capable standard library * lots of resources, 3rd party libraries, and local meetups near you * a nice REPL and debugger built in (but install ipython3, right now) I started using it at work for database scripts and data analysis scripts. I did a lot of PERSONALLY useful stuff with it in a relatively short period of time. So, go for it! It will pay off. But there are also some things I found difficult. Some caution: For one, frameworks like Flask and Django were difficult for me to get started on, so I couldn't make a dynamic, database-driven website very easily. In retrospect is because those frameworks are 1) highly opinionated, 2) use fairly complicated metaprogramming tecniques (look up "decorators" in python, the thing's with `@` above functions) and 3) deploying them is _hard_. Another thing, packaging Python was pretty confusing to me. So while I had a ton of scripts on my local machine, it was hard for me to take a bunch of code files and bundle them up into something someone else could use. Find someone who is experienced to show you how to do this. I wish I'd asked for help sooner. Python hides things from you. I loved using the debugger in Python, and stepping deeper and deeper into libraries to see how they work, but all too often I remember hitting the "C wall", where Python ends and bindings to C begin. Contrast this to Go, where that is (almost) never the case. [All the Go source is online](https://golang.org/src/net/http/client.go?s=12847:12907#L381). (Rust has great online docs like this, too!) And Go accomplishes this by being only _slightly_ lower level than Python. And networking stuff? To be frank, I didn't really understand how http worked until I found Go. With Go, you're dealing with a more faithful representation of bytes coming in and out of the network. Also, deploying Go is _really easy_. If you can compile it, you can copy a binary to any computer with the same OS and it "just works". With Go, you can use the standard library's http server and writing something that someone could run in production. The TL;DR of this is I'd like to qualify the "one language at a time" advice others have posted. It's good advice, but don't wait too long to learn a second language. 
Could make 2 entirely new apis
Yes, if the implementation ignores `-u` for POSIX compatibility then it must be unbuffered by default.
Although not everybody seems to be too enthusiastic, I really like what you have made here! 
I can see myself using this a lot on READMEs
Just from a usability perspective, people already complain that `rand` isn't in the standard library. If the `rand` library then doesn't have an obviously-named function, it's another speedbump. I understand the desire to name the function such that you have to understand a bit of the context -- that's why we answer "how do I get the first character of a string?" with "what do you mean by character?" but here it seems like there's not much gained. 
GNOME 3 has actual satisfied users (like me). Calling them "kids" is quite rude and arrogant.
GNU tools may disregard the standard when they believe the tool becomes more user friendly. 
I can't remember the last time I ever needed to concatenate files 
This is nice, although for the use cases in your screenshot, I would use `vim` \(or its readonly version `view`\). Vim supports syntax highlighting and can show changed lines with the GitGutter plugin :\)
I think [PureScript](http://www.purescript.org/) ticks those boxes
Thanks! Thanks makes sense.
will do!
it seems there are quite a few implementations in about every language, so I just figured there'd be a rust one. would it be better to just use the C one if it can be converted to WASM? \(I'm thinking yes, since it's the original/main implementation\)
The title doesn't bother me. It did a great job of communicating what `bat` does in a small amount of text.
`rat` would have been a fun name too :)
I don't have strong opinions about `random()` itself staying around as I'm the type who is going to do `thread_rng().rng()` anyway, but I do think it would be beneficial to have sensible, zero-setup, zero-arg defaults available that cover the 80% casual use case. There can even be multiple, e.g. * `secure_random()` =&gt; lazy static rng that gathers a bunch of entropy and uses a high quality, if slow generator * `thread_random()` =&gt; basically `random` renamed * `insecure_random()` =&gt; lazy static rng that is seeded reasonably and uses some faster generator, e.g. MT19937 * `fast_random()` =&gt; "just give me a number now" rng, something a game might use I don't even have strong opinions about these as the ultimate options. Maybe `rand` doesn't want to commit to maintaining something cryptographically secure, for instance. Maybe they want to offer `secure_thread_random()`. But I wholeheartedly believe in having extremely simple "good enough" options within easy reach.
Be careful with that, though - rat in computer terminology tends to relate to Remote Administration Tools, usually malware used to control machines. 
Rust doesn't need Visual Studio at all; I'm not sure where you got that impression. It needs the Visual C++ Build Tools (which are also included in Visual Studio), because it needs the linker. Rust neither comes with, nor requires, any sort of IDE.
Please don't link to that website.
It doesn't concat at all, it's named after cat(1) because people use cat(1) to display files in their terminals.
Isn't mingw64 much smaller than VC++ build tools?
Which instructions are you following?
One thing to be aware of is that there's no guarantee that any wasm instructions are constant-time. A compiled crypto library may suffer from timing side channels.
I really don't understand people that get upset about this. It's hard to avoid concluding that it is anything other than the height of irrational philosophy for philosophy's sake. Firstly, I'm not even aware of a tool whose sole purpose is to print out the contents of a only a single file. You could make the same silly argument that sed, awk, grep, head, tail, and dd are *only* for their respective purposes, and *not* for printing a file. But even if such a tool existed, it would be strictly a subset of cat in functionality. Why would one even bother keeping it in their mind when cat does the job, and is the simplest to use? To tell someone that they are using cat wrong simply because they only gave it one positional argument is like telling someone driving by themselves that they're using a car wrong because there are 4 seats. It's simply asinine. cat is a simple tool with a simple purpose. Please stop berating people for using a tool to get something done, especially when it has no rational, demonstrable negative consequence.
It's the latency: A method JIT based on LLVM is used in [Ice](https://github.com/losfair/IceCore/), which is a server-side wasm container, and it takes more than 400ms for even a simple "Hello, world!" to start. I expect this to be better if Cretonne is used instead of LLVM, but after all, most common utilities like `ls` and `cat` run for no more than a few milliseconds, and doesn't need really good code generation to achieve full performance, compared to the server situation where high performance is important. With a tracing JIT, I expect that we would cover most of the cases that are slow in the interpreter, while Cretonne can be selected on code load if you want full codegen.
It's the latency: A method JIT based on LLVM is used in [Ice](https://github.com/losfair/IceCore/), which is a server-side wasm container, and it takes more than 400ms for even a simple "Hello, world!" to start. I expect this to be better if Cretonne is used instead of LLVM, but after all, most common utilities like `ls` and `cat` run for no more than a few milliseconds, and doesn't need really good code generation to achieve full performance, compared to the server situation where high performance is important. With a tracing JIT, I expect that we would cover most of the cases that are slow in the interpreter, while Cretonne can be selected on code load if you want full codegen.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/losfair/IceCore/) - Previous text "Ice" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
It's the latency: A method JIT based on LLVM is used in [Ice](https://github.com/losfair/IceCore/), which is a server-side wasm container, and it takes more than 400ms for even a simple "Hello, world!" to start. I expect this to be better if Cretonne is used instead of LLVM, but after all, most common utilities like `ls` and `cat` run for no more than a few milliseconds, and doesn't need really good code generation to achieve full performance, compared to the server situation where high performance is important. With a tracing JIT, I expect that we would cover most of the cases that are slow in the interpreter, while Cretonne can be selected on code load if you want full codegen.
I asked about this specifically during one of the WASM WG meetings at the all hands a few weeks ago. Inlining external WASM modules should be possible, but is unsupported and not recommended as it might break unexpectedly. Something about LLVM was mentioned. I chose not to ask any further as it became clear that there was much work to be done for WASM, and this seemed less important than much of the other things. To my knowledge there are currently no plans to support inlining external WASM modules. What I've chosen to do instead for my own work is to move to standalone implementations of the crypto algorithms libsodium ships with. Especially the Dalek-* suite from some of the Tor developers is looking really promising! Hope this is helpful!
Some suggestions for Rust crates that might be worth adding (many of which I've submitted PRs to fix on FreeBSD or OpenBSD): - [libc](https://github.com/rust-lang/libc) - [nix](https://github.com/nix-rust/nix) - [shared_memory](https://github.com/elast0ny/shared_memory-rs) (currently does not build on OpenBSD) - [web-view](https://github.com/Boscop/web-view) - [rust-users](https://github.com/ogham/rust-users) - [dot](https://github.com/ubnt-intrepid/dot) - [platform](https://github.com/Xaeroxe/platform)
I was actually [playing around with this yesterday](https://github.com/alexcrichton/wasm-sodium) and managed to get it working! It's not super pretty with the wasm32-unknown-unknown target, but we'll hopefully improve it over time!
The `-mingw` toolchain actually includes gcc, ld, etc. in `.rustup\toolchains\nightly-x86_64-pc-windows-gnu\lib\rustlib\x86_64-pc-windows-gnu\bin`, so you don't need to install anything else. You might still want MSYS2 eventually when that one crate needs `openssl` or `sdl` or something.
There's certainly plenty of *interest* in rust data science. I know I follow it closely, anyway, and a few posts pop up here every once in a while
Actually I consider myself in that camp too. There have been some very good fledgling efforts but I don't know what it would take to create critical mass
That website, while somewhat brash is correct nonetheless. 
Yes, I use PureScript at work because we have to support old browsers that don't support Wasm (IE11). It ticks all those boxes except custom syntactic sugar (beyond custom operators, monads/do-notation), afaik. But it's still great. I wish there was a PureScript to Rust compiler or PureScript interpreter in Rust that would make Rust crates + PureScript a power-couple like C libs + Python.
Interesting, I've never heard of that one. At work, "rat" usually refers to the Maven (Java build tool) plugin which verifies that all your code files have a compliant license at the top.
I mean it was just an example, but I'm still genuinely curious: terrible how?
Huge state size per generator compared to other generator types (2.5k, compared to 16 bytes or so for other good gens), extremely predictable, not particularly fast even. The best feature it has is a big period, but since you're never going to loop your generator in the first place it's not particularly useful to have a big period.
Thank you! I don't like the ux of Visual Studio, all the toolbars and whatnot are overwhelming to me, and a lot of its "conveniences" slow me down or annoy me.
I know that the precise names are just examples, but what is the use case for `insecure_random` that isn't better covered by `fast_random`?
Why does it need specifically the VS build tools?
I am confused about one thing: Why's can't the thread_local instance used by rand::random() be cached. Security implications?
Aw, yeah. I see. No worries, you just need the build tools; not necessarily the entire IDE. You‚Äôll also need the C++ build tools for Visual Studio 2013 or later. The easiest way to acquire the build tools is by installing Build Tools for Visual Studio 2017 which provides only the Visual C++ build tools. Similar to needing Xcode Command Line Utilities to install git for MacOS. It seems like to need the whole thing, when in reality is just one piece of functionality that's required.
Because it has to use the VC++ build tools (not "VS build tools"; VS and VC++ are different things) if it wants to be compatible with MSVC-compiled code. `gcc`/`ld` are effectively a completely different dev environment that is only *sometimes* compatible, hence why it has a different target triple (`x86_64-pc-windows-gnu` versus `x86_64-pc-windows-msvc`). `lld` is not ready for prime-time.
As others have said, it only needs it for the command line tools anyway, you don't need to ever touch VS at all.
The rust toolchain? It's fairly self-contained, and fully managed through rustup. On the surface there's not much to gain from using snaps, so I wouldn't expect it to be a priority.
The only other thing I can think of is that the content of the struct will probably have to be copied around on the stack, which can be a hog if it's big. A reference always has a fixed, small size.
:o) //bin/true; rustc -o "/tmp/$0.bin" 1&gt;&amp;2 "$0" &amp;&amp; "/tmp/$0.bin" "$@"; exit $? fn main() { println!("Hello, rust scripting."); } Don't forget to `chmod +x` or run through sh or bash. 
Can you share the code of your statement? I really have no idea how you can get that in Python2 or Python3.
 fn remove_first(s: &amp;str) -&gt; &amp;str { let mut chars = s.chars(); chars.next(); chars.as_str() }
&gt;The easiest way to acquire the build tools is by installing Build Tools for Visual Studio 2017 **which provides only the Visual C++ build tools.** Alternately, you can install Visual Studio 2017, Visual Studio 2015, or Visual Studio 2013 and during installation select the desktop development with C++ workload.
Yeah, the version that's been translated from MDL to Fortran to C and now to Rust. It's to practice converting existing C projects into Rust, and to mess around with the origin of Text Based Adventure games.
Python 3: &gt;&gt;&gt; x = input() 5 &gt;&gt;&gt; y = input() 10 &gt;&gt;&gt; x &lt; y False Python 2: &gt;&gt;&gt; x = input() 5 &gt;&gt;&gt; y = input() 10 &gt;&gt;&gt; x &lt; y True Identical input, different result.
Nice article! It's funny timing for me because I've just submitted a PR to Apache Arrow to refactor it to move away from the original enum representation to use traits and generics instead. I was running into limitations of the enum approach. Here's the Arrow PR: https://github.com/apache/arrow/pull/1971 I will be releasing DataFusion 0.3.0 as soon as this all settles down. 
oh input as in result of `input()`. I see. Yeah python3 is not backward compatible with python2 and that's a bit mess! Also `3/4` is float division in python3 and integer division in python2.
I am working on a minimal library for NodeJS N-API bindings in rustÔºå[napi-rs](https://github.com/Brooooooklyn/napi-rs) Ôºåthis project was initialized from [xray](https://github.com/atom/xray) And I need your help to make it better.
I'm not sure what exactly you mean. But then again: I think some people were posting confusing statements about performance. `random()` is literally defined as `thread_rng().gen()`. So you can only get better performance by storing the `ThreadRng` in a local variable instead of "creating" it with `thread_rng()` all the time. But the important part: `ThreadRng` is just an `Rc&lt;_&gt;`... which is copied from a `thread_local!`. So calling `thread_rng().gen()` only does two things more than if you'd store `ThreadRng` in a local variable: - A lookup in thread local memory (Super fast after it's in the CPU cache) - Cloning an `Rc` which is literally only a non-atomic increment, one of the cheapest instructions there is So: it is already cached. By the `thread_local!`. That's exactly what `ThreadRng` is for.
Currently working on a language called [Pikelet](https://github.com/brendanzab/pikelet) that will hopefully be able to meet some of those goals eventually. Long way to go before it can do anything useful though! :(
Then I am not sure what the suboptimal uses proposed are. I was looking at the signature and thought I was just misunderstanding something about the invocation of thread_rng()
Mostly correct as far as I can tell, but as far as I know TiKV is not horizontally scalable without the placement driver. Mainly because the Raft algorithm is not horizontally scalable. The only way to have horizontally scalable raft is to shard over multiple raft clusters, which is what the placement driver does. 
I'm doing more TWiR and [mutagen](https://github.com/llogiq/mutagen) (adding timeouts, more opportunistic mutations) and maybe some Rust doc improvements.
Read The *** Article would be my guess No, there are no security concerns and not a lot of performance ones either.
We may eventually remove the `Rc` and just return a pointer (with some protection so it's not `Send`), in which case the only overhead is checking whether the generator was already initialised.
Reminds me of a Daily WTF where the interviewers were convinced that his approach was unnecessary because the language's fault-tolerant runtime would ensure destructors would get run, even if that meant having to respawn the actor... and he stunned them by asking what would happen if you pulled the plug on the machine?
Probably because it's shorter. Do not underestimate the laziness of humans in your api's lest you regret it.
Thanks for your input. I have to agree with /u/meadowfire - some details on those failed attempts would be very useful, especially if one encouraged with your work and well written blog post would want to optimize `rustc` further and encounter the same cases as you. 
Proper way to wipe logs of running applications and easiest way to truncate a file.
You know you can just do &gt;file to truncate a file? Or, more literally, truncate -s0 And my point was about it being used in addition to another file in cat.
Wat? 
What FFT implementation are you using? 
I don't have truncate on my computer. Anyway it's an old habit to do it this way. It was a typo: `cat /Dev/null &gt; some/file` is what meant.
How so?
I think this is one of the steps to being formally verified, which would be cool.. but I'm not sure.
Yes. But Rust currently has no formal language specification at all. It's useful for other things, like parsers, analytics and other tools. Formal verification would still be quite far off, even if this was more than a subset.
TLDR: The reference in WrappedBar was a silly idea, and I'm not even sure why it made it a reference. I'm sorry this turned out to be an XY Problem, I wanted to simplify the problem as much as I could. I am writing a program that talk to the RLS to query for type information using the `languageserver_types` crate. It defines a trait Request: pub trait Request { type Params; type Result; const METHOD: &amp;'static str; } with implementations like this: #[derive(Debug)] pub enum Initialize {} impl Request for Initialize { type Params = InitializeParams; type Result = InitializeResult; const METHOD: &amp;'static str = "initialize"; } Evey the types Params and Result of every implementation of Request is serializable and deserializable. Because I am using a lot of (de)serialization in my functions, I would need to duplicate the bounds `R::Params: Serialize + DeserializeOwned, R::Result: Serialize + DeserializeOwned` on almost every method. To avoid that, I created a trait RlsRequest (the Bar in the question) that carries the bound in its type: pub trait RlsRequest where Self::Params: Serialize + DeserializeOwned, Self::Result: Serialize + DeserializeOwned { type Params; type Result; const METHOD: &amp;'static str; } I have an generic impl for every Request: impl&lt;R&gt; RlsRequest for R where R: LsRequest, R::Params: Serialize + DeserializeOwned, R::Result: Serialize + DeserializeOwned, { type Params = R::Params; type Result = R::Result; const METHOD: &amp;'static str = R::METHOD; } The WrappedBar is actually this struct, which contains some extra fields for jsonrpc. I know realise the reference to params was silly, so I changed it to an owned value: #[derive(Serialize, Deserialize)] pub struct ExtendedForSerialization&lt;R: RlsRequest&gt; { params: R::Params, jsonrpc: String, id: usize, method: &amp;'static str, } I now get another error in this function (Child is from std::process): fn handle_request&lt;R: RlsRequest&gt;(child: &amp;mut Child) { let res: String = read_response(child); println!("{}", res); let request: ExtendedForSerialization&lt;R&gt; = serde_json::from_str::&lt;ExtendedForSerialization&lt;R&gt;&gt;(&amp;res).unwrap(); request; } The compiler complains with error[E0597]: `res` does not live long enough --&gt; src/main.rs:129:62 | 129 | serde_json::from_str::&lt;ExtendedForSerialization&lt;R&gt;&gt;(&amp;res).unwrap(); | ^^^ borrowed value does not live long enough 130 | request; 131 | } | - borrowed value only lives until here | = note: borrowed value must be valid for the static lifetime... I think this is because serde must construct an object with a `&amp;'static str` out of nowhere. I changed it to String and copy the value when constructing it. The code now compiles.
Jesus christ reddit. We are cetainly a friendly community, aren't we? 
[removed]
And calling MATE incapable of serving your needs is likewise so.
You can do `echo &gt; some/file`, fewer characters. Though it might leave a new line
Does `MayDefault` need two methods? It seems like it could be `fn get_default() -&gt; Option&lt;X&gt;` ? Also, I kinda wonder if `MayDefaulter` doesn't need to be parameterized (and, possibly, doesn't need to exist): pub trait MayDefault&lt;X&gt; { fn get_default() -&gt; Option&lt;X&gt;; } impl&lt;X&gt; MayDefault&lt;X&gt; for () { default fn get_default() -&gt; Option&lt;X&gt; { None } } impl&lt;X: Default&gt; MayDefault&lt;X&gt; for () { fn get_default() -&gt; Option&lt;X&gt; { Some(Default::default()) } } fn do_it&lt;X&gt;() -&gt; Option&lt;X&gt; { &lt;()&gt;::get_default() } Of course, it may be nicer to have a type, but it can be simpler
I have an operation on pairs of iterators, that only makes sense if both iterators point to the same container: struct RopeIter&lt;'a&gt; { owning_rope: &amp;'a Rope, ... } impl&lt;'a&gt; RopeIter&lt;'a&gt; { fn distance(&amp;self, other: &amp;RopeIter&lt;'a&gt;) -&gt; usize { assert_eq!(self.owning_rope as *const _, other.owning_rope as *const _); ... } } Is it possible to express this constraint statically? Based on what I know, it doesn't seem possible in Rust, but I can't demonstrate in convincingly. Anyway, what this type system feature is called and what languages do have it? 
bad bot
Thank you, nicnux, for voting on CommonMisspellingBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
There are some operations, that take more or less time, depending on the values, they act upon. If the value is part of a cryptographic secret, and an attacker can measure the timing of enough encryption or decryption processes, they can guess the key. Therefor it is important to implement cryptographic libraries in a way, that their timing is not dependent on secret values, especially private keys. https://en.wikipedia.org/wiki/Timing_attack
**Timing attack** In cryptography, a timing attack is a side channel attack in which the attacker attempts to compromise a cryptosystem by analyzing the time taken to execute cryptographic algorithms. Every logical operation in a computer takes time to execute, and the time can differ based on the input; with precise measurements of the time for each operation, an attacker can work backwards to the input. Information can leak from a system through measurement of the time it takes to respond to certain queries. How much this information can help an attacker depends on many variables: crypto system design, the CPU running the system, the algorithms used, assorted implementation details, timing attack countermeasures, the accuracy of the timing measurements, etc. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
It probably isn't relevant to you, but I am just going to throw it out there anyway: [A **German** lecture about Rust](https://www.youtube.com/playlist?list=PL0Ur-09iGhpwMbNiVTBeHmIjs0GuIXhNg) (26 videos each ca. 1 1/2h, 2016/17, conducted by Lukas Kalbertodt).
You're accusing me of the thing I didn't do - I didn't criticize anyone for *using* `cat` incorrectly. I criticized the author for making a very specific false claim. Imagine if you were hitting nails with a `wrench`. Fine, whatever works for you. Now you make your own tool to hit nails and say "Look! I made a `wrench` clone! You can hit nails with it!". The right answer is not to congratulate you on making a `wrench` clone, but to notify you that you made a hammer.
Really interesting series you got going here! Apparently "[fully qualified syntax](https://www.reddit.com/r/rust/comments/89r1yr/list_of_all_the_little_magic_of_rustc/dwt21lv)" is preferred over "unified/universal function call syntax". 
We certainly are. Nothing is better than friendly criticism?
Today I learned. Will change the wording. Thank you!
Good simplification. Thank you!
&gt; Please don't say that you made a $UNIX_COREUTIL_NAME clone if you completely change the purpose. &gt; I criticized the author for making a very specific false claim. Author here :-). `bat` is currently in version 0.2 and still lacks a lot of features ([reading from stdin](https://github.com/sharkdp/bat/issues/2), [detecting non-interactive terminals](https://github.com/sharkdp/bat/issues/26), [an option to disable "decorations"](https://github.com/sharkdp/bat/issues/5), ..). Agreed, it's not a "clone" yet. Concerning the main use case for `cat`: Yes, the original purpose was for this tool to concatenate files. However, even if you look at the [POSIX-standard man page](https://www.unix.com/man-page/posix/1P/cat/), you will find that `cat` is a tool to "concatenate *and print* files". Also, the very first example in that man page is a simple `cat myfile`. And I don't think there is anything wrong with that.
libsodium is compiled to WASM, and this WASM version is widely used: https://github.com/jedisct1/libsodium.js
So? I was just saying to the guy who asked not to post that site that the website is right when it comes to the purpose of cat, not mocking or disparaging anyone
Also, it is far more idiomatic in Rust to create new types with additional guarantees, rather than to add defensive checks everywhere like you were proposing in the OP. For example, if you have a number that must be between 20 and 40, you can create a newtype: pub struct MyToken(u8); and then make it so that the only way to create a `MyToken` instance (outside of the current module) is by calling a special constructor that performs the check: impl MyToken { // You could also define a more meaningful error type, but for the example I'll use () pub new(x: u8) -&gt; Result&lt;Self, ()&gt; { if x &gt;= 20 &amp;&amp; x &lt; 40 { Ok(MyToken(x)) } else { Err(()) } } } Now you have a new type `MyToken` which is guaranteed to always have a valid value, because there is no way of constructing an instance without having passed the check. If you have a `MyToken` instance, you know it must be valid. You can write all of your methods that expect these guarantees to accept `MyToken`s as arguments instead of plain integers. This is clearer in your code (the method signature communicates to the reader: "this method requires a `MyToken`", rather than "this method accepts any plain old integer"). This also means that you can rely on the guarantee that a `MyToken` is valid, so you don't need any defensive checks or asserts at the start of each method/function. Littering all your methods/functions with a whole bunch of defensive checks/asserts is also bad style, because it requires you to express redundant information. You have to put the same checks in many methods that all expect similar guarantees. They are scattered all over the place. What if you forget some? It is much better to enforce your assumptions in one single place, such as the constructor of a newtype like I showed before. You can then rely on those guarantees everywhere where you use the newtype. The standard library also does similar things. `String`/`str` are guaranteed to be a valid UTF-8 encoded sequence of bytes. They perform utf-8 validation at construction. This means that if you have a `String` or `str` object anywhere in your program, it is guaranteed to be valid utf-8 (because it is not possible to construct such an object without passing utf-8 validation (without unsafe code)) and you can rely on that guarantee. You do not have to do additional utf-8 checks all the time and you do not have to write code that can handle invalid/corrupt byte sequences either. This is why defensive checks like you described in the OP are unidiomatic in Rust. The idiomatic Rust way is to liberally define many new types for all the things you want to express and then use the type system to enforce your guarantees. All of this also has the performance benefit that your guarantees are enforced at compile time instead of runtime and that validation/checks are only done once, when constructing an object of a given type, rather than many times, in every method that uses such an object. That said, if you have some complex invariants that are difficult to express and enforce using custom types, or for localized things in specific situations, feel free to use `assert`. Tip: there are crates, such as [`derive_more`](https://crates.io/crates/derive_more) that help reduce the boilerplate code you need to write for defining your own custom newtypes. Use them to make your life easier. Be liberal with types. Define custom `struct`s and `enum`s for every idea you want to express in your code.
Yeah, I agree with you. This is why a production-quality system would need some dynamic approach with heuristics. If your project ever gets to that stage, it would be best to do something similar to the Android Runtime, which combines an interpreter, a JIT with caching, and an AOT compiler, to get the best of all worlds and be flexible to different workloads.
&gt; There's also bat, which is a moderately popular cURL alternative for certain use cases Is it? I think it's fair to call HTTPie moderately popular. The `bat` you linked to, not so much. Well, maybe some gophers like it. But that doesn't make it *popular*.
At some day, I‚Äôll get `cheddar` out of `spectra`, I promise‚Ä¶ :D
You could map the tuple types to "real" types and impl methods on them, like https://play.rust-lang.org/?gist=81b3ecdc0288d90bb3420e321f16dfdf&amp;version=nightly&amp;mode=debug (sorry for the drive-by comment, don't have much time)
&gt; I would use vim (or its readonly version view). `rview`, and I agree. `view` is originally a `vi` alias, and we don't want people to accidentally use it ;)
Ah, so you are saying that they are not referring to TiDB 2.0, but TiDB in general when using the term battle-tested? TiDB 1.0 can be battle-tested, but even though TiDB 2.0 builds on observations and experiences from TiDB 1.0, test results are *not* inherited‚Äîthey are explicitly invalidated by changes. Thus, TiDB 1.0 is battle-tested, and TiDB 2.0 is "green" and awaiting its trial by fire, even if it is much better prepared.
&gt; searching for time As well as ‚åö, ‚è≥, and ‚è≤. Of the hourglasses, ‚è≥ may be better than ‚åõ because ‚åõ implies the lifetime has ended, while ‚è≥ is still running. ^(long live the bikeshed)
&gt; This is a position that pays out in crypto. I assume your own crypto. Yeah no thanks, I can't pay my bills with that, sorry. Unless you have an option to pay your employees in real money, I don't think that's going to work out well for you. It would also be good to note if the job is remote or local, if you support relocation, what the company benefits are, etc. etc., it's not only about what the employee can do for you.
It is good enough for all scientific applications I know of. But yes, it is superseded by modern RNGs.
As discussed in the issue, your benchmarks are probably flawed.
It seems there's some source code and instructions for this over at a related site: http://sist.shanghaitech.edu.cn/faculty/songfu/Projects/KRust/
ah ok, so the original libsodium was compiled to both js and WASM. I did see that repo, but brushed it off as a js implementation that wouldn't have type safety.
I don't think WiFi latency matters, an attacker can connect to your server without using it. It might also possible to average out the noise from latency and the attacker might use a connection with little latency, so I'm not sure you can rely on latency to protect you from timing attacks.
looking through some of the issues on that repo \-\- this may actually be what I want. thanks!
Great feedback, thanks! I know, the information is scarce, and I just passed on the message since I know of this reddit. Position is remote, you work from where you want, as long as you have access to a laptop and internet connection. It's not a real company, it's more of a community where you get paid for your work. No benefits, no company car. Like an internet company. There are numerous ways to process cryptocurrencies to fiat, that should not be the deciding factor. But again, i'm just the guy passing on a message. If people are interested, they should talk to the guy mentioned in the ad.
I'll mention [runner](https://crates.io/crates/runner) since it fits in the same space as cargo-script: compiling and running little Rust programs with shared external dependencies - without having to _explicitly_ create cargo projects. I find it very useful to try out little bits of logic, which I then tie together as actual projects.
There are devs who have accepted payment in crypto over these last few years who are multi millionaires now as a result. The world's first live atomic swap exchange was built almost completely by anonymous individuals for good reason. This is not the corporate plantation. This is the wild west. 
Pretty much what I came up with one sleepness night :) RustScript, anyone? Although the trouble here is that it would be _too close_ to proper Rust in syntax an/semantics and perhaps cause cognitive confusion.
For the build tools go here: https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017 Then search the page for "Build Tools for Visual Studio 2017", This should give you just the compiler, linker, etc. Though not the full visual studio.
It's things like the import libraries not containing functions that have existed for a while, or binding functions in the wrong import library. Heck, that's why `winapi` has to include its own import libraries to override the ones MinGW comes with, because the MinGW ones just aren't good enough. Also, to be fair, my MSYS2 folder is about the same size as my VC++ build tools folder, but VC++ also includes x86-&gt;ARM cross compilers which MSYS2 doesn't.
So, the real money is in selling shovels whilst others chase the dream?
Thanks! I've added those crates, so far all of them are passing, except shared_memory and nix. shared_memory is currently failing because nix 0.10 doesn't build on openbsd 6.3, the PR for that is pending: https://github.com/nix-rust/nix/pull/893
If you want something more complex, you could create a struct to hold the data in the form you want and then do : impl From&lt;(User, Vec&lt;Post&gt;)&gt; for MyStruct and combine it with: let data = users.into_iter().zip(posts).map(MyStruct::from).collect::&lt;Vec&lt;_&gt;&gt;(); or if you prefer to hide that away: impl MyStruct { pub fn load_all(connection: &amp;Connection) -&gt; Result&lt;Vec&lt;MyStruct&gt;, Box&lt;Error&gt;&gt; { let users = users::table.load::&lt;User&gt;(&amp;connection)?; let posts = Post::belonging_to(&amp;users) .load::&lt;Post&gt;(&amp;connection)? .grouped_by(&amp;users); users.into_iter().zip(posts).map(MyStruct::from).collect::&lt;Vec&lt;_&gt;&gt;() } }
right \-\- I may have forgotten to mention this, but there is no encryption on the server \(other than SSL, of course\). I'm doing a p2p app \(with *super* lightweight servers for handling cross\-subnet communication\).
Thanks! I've definitely looked at Utah, and seen the talk. I definitely agree with your thoughts in general on dynamic typing. I love static types, which is one reason I love Rust. I think part of my exploration in writing a dataframe is how to build in enough flexibility so that there isn't too much user friction, but to also maintain static typing and great performance. I guess I've called that dynamic typing here, but maybe that isn't the right term.
Yip :/ Gonna fix those later, if I find the time
If your shovels are stacks of usable code, then yes. 
Cool! I'm excited to take a look at this soon.
Neat, do you think it would be difficult ho adapt it to the 81x series? The 810 is the only available arm core in DIP and I kind of like it. 
I used [RustFFT](https://github.com/awelkie/RustFFT) in the [vox_box library](https://github.com/andrewcsmith/vox_box.rs) I wrote way back the first 6 months learning Rust. But I'm also on [RustFFT 1.0 still](https://github.com/andrewcsmith/vox_box.rs/blob/master/src/spectrum.rs#L400), and that whole bit could use a redesign to allow for reusing the FFT scratch memory. But, that said, FFT operations and large matrix multiplications are the things that GPUs are well suited for, so I thought this would be a useful test case even aside from optimizing my own code. 
That _definitely_ suits my style more than python. I have not been into all the one-time-use-only variables that the imperative programming style of numpy uses. Yours actually starts to look a lot like a handful of audio graph compilation languages (which, in the end, are just declaring the composite function "give me another block of 64 samples.")
Thank you for the effort to get some data. But actually we already have the benchmarks, just see the bench directory in rand. We/I have spend a lot of effort optimizing `StdRng` and `ThreadRng`, and performance is mostly the same now, except for the time it takes to retrieve `ThreadRng` from tls (about 10% if I remember correctly).
&gt;but the assurance you get from program compiling is greater. Not quite so..but yes I am still a beginner trying to get my BST code working...and it been quite some time üòâ . But the learning would be worth it.
I'm pretty sure you don't need to install VS to get the build tools, doesn't [this](http://landinghub.visualstudio.com/visual-cpp-build-tools) work? Or are the build tools seriously 4 gb by themselves?
Ah, perfect! Sorry for not searching for benchmarks first. 
There are people who have dropped their paycheques into casinos over the last few years are multi millionaries now as a result.
&gt; Glad you're not designing the `rand` lib :D You may have missed my intent. I wasn't trying to design anything; merely making a point about ease of use and naming. Pretty much everything else was throwaway. Still, I'm glad I'm not designing it too! It'd have to be a side project for me and those pretty much never get finished :D
The short answer is that it doesn't really but people seem to prefer it...
good point. but getting paid for your services in crypto bears no resemblance to gambling. you can easily find a service to convert your crypto to the fiat currency of your choice.
I guess we should learn together. I am also learning. My git handle is janus
&gt; There are numerous ways to process cryptocurrencies to fiat, that should not be the deciding factor. In that case, process the cryptocurrency yourself and give the employees the fiat, if it's so easy
It has several thousand stars. It *is* moderately popular. "moderately popular" does not mean "talked about on CNN". It just means that it is known to more than a few people. I've never actually heard of anyone using HTTPie, let alone seen it used, but I have seen coworkers use bat. I don't know why you're trying to say that you're own anecdotes are the gold standard for popularity. Just going off of GitHub stars, HTTPie is 10x as popular as bat, and... wait... 3x as popular as cURL itself? Right, GitHub stars paint a very broad picture. Reality is much harder to pin down, but we all know cURL is actually way more popular.
I think it also applies to clients, which can be exposed to malicious servers.
My only issue with calling the generic `random` function `thread_random()`, although honest, is that straight newbie programmers tend to avoid anything that mentions threads. It took me ages to accept that I needed the threading library in python to sleep my program. Not to say we should promote ignorance in programmers, but this is a simple case where having just a `random()` function helps newbies feel comfortable with the code they write.
&gt; straight newbie programmers tend to avoid anything that mentions threads I think that's one more case for having multiple names with various properties. Perhaps `local_random` or `static_random` or some such would be appropriate. You could even keep `random` around as an alias for `thread_random` as it is a pretty good default already.
&gt; It has several thousand stars Really? several thousand? starts? &gt; It is moderately popular. "moderately popular" does not mean "talked about on CNN". It just means that it is known to more than a few people. Moderately popular means &gt;3 people heard about it, got it. &gt; I've never actually heard of anyone using HTTPie, let alone seen it used, but I have seen coworkers use bat. I don't know why you're trying to say that your own anecdotes are the gold standard for popularity. I like how you talked about your own unfamiliarity with HTTPie, your coworkers, then proceeded to complain about my anecdotes! btw, you might want to read the first 2 lines of your `bat`'s README. &gt; Just going off of GitHub stars, Really? stars? ------- ~2.5 year old HTTP client with zero activity in the last 6 months is not *moderately popular*, period.
Have you read [this](http://edp.org/work/Construction.pdf)? In my experience offloading the FFT to the GPU is slower than using an optimized, CPU bound implementation, at least for audio. Iirc tensorflow is slower than both FFTW and IPP. 
&gt; I like how you talked about your own unfamiliarity with HTTPie, your coworkers, then proceeded to complain about my anecdotes! I provided an anecdote since you were so fond of them, but I never claimed it was anything else.
Looking at the github issue now the primary discussion is whether random() should be a random number generator or just a random number. 
[Sure, but how much of that fiat will you get?](http://www.brainlesstales.com/images/misc/bitcoin-roller-coaster.gif)
dumb question, but can someone tell me the significance here? I get the impression it's important from an overall language development point of view, but I'm not certain in exactly how. Thanks
Eh? Rust is valuable precisely because of the ability to write *correct* software without cutting corners on performance.
Seriously. I said nothing technical about `bat`, nor have I mentioned its author. I just questioned **your assertion** that it's *moderately popular*. The way questioning assertions made **here** about X turns into "insulting the hard work of someone else", and "you are here just to argue that X sucks. What did X ever do to you?" is exactly why many people don't take this community seriously. But let's not go there.
This looks interesting to me, because we use Node a lot over here. I'll try and find the time this week to test it on Windows so that the "only tested on MacOS" disclaimer on the readme file can be expended :)
`Drop` means there is something to do when a type goes out of scope. For example, all types that allocate heap memory have a `Drop` implementation to release that memory back to the operating system. 
Does this paper actually say anything of interest? It looks like they wrote an interpreter for a small subset of Rust in a particular formal system. But the subset is extremely small, and it doesn't look like they derived any novel results from this. The examples they give, of proving the running time of a GCD algorithm, would work in pretty much any procedural language; it's pretty much just a syntax modification away from the same example in any language. They implement a very simple model of borrow checking, but their subset doesn't seem to support references in type signatures, so it doesn't seem like they can even model any inter-procedural effects of the borrow checker, just some purely local restrictions on aliasing. I suppose that this is a good first step if you want to write a formal semantics of Rust in ùïÇ, but it seems like there's not really enough here yet to be of interest.
&gt; their subset doesn't seem to support references in type signatures aww, I didn't notice that :(
It's a first step toward proving Rust's correctness formally.
In my conception of addition, the sum of two or more things is of the same type as the operands. Why is there an opening for deviations from that here?
This is essentially what I end up doing in Haskell FWIW.
But if Battle-tested applies to &lt; 2.0 versions, then Faster, Smarter logically do too. Why am I upgrading to 2.0? 
Your statement and my statement are not in conflict.
Expanding [wee_alloc](https://github.com/rustwasm/wee_alloc) into an even more generally-usable allocator for any old embedded thing, not just WASM, by beefing up a [compile-time-sized backend](https://github.com/rustwasm/wee_alloc/pull/39).
Well, then I am happy that `winapi` is filling the gap.
I see that "HTML Parser" is not marked as to be written in Rust". Does it mean that html5ever is not going to be used by Firefox then? 
The arguments made in the article apply to Rust. The difference is that rust *leans into* that, whereas C holds onto the "we are just sugar over asm" culture.
I don't even know where to begin with picking that apart. I felt like (at least) half the assertions he made about C were flat out wrong. It's like that article was written by a parody of a computer scientist who wishes never to have to think about hardware and live in a world of pure computational models.
So the title is missing an 'L'. Pun unintended. I'll leave it so you can laugh at my miserable typing skills.
so i have been getting this kind of lag for about 2 years but it has never been this bad. i do not know the name for this lag or how to fix it. please, if you know a way too fix it or know a youtube video where they show how to, please, tell me or send a link. Thank you!
Have you tried using rayon? It may improve performance with its **F E A R L E S S** parallellism
That's a little out of my depth (uh, I'm a mere grad student in music composition), but I believe that RustFFT has an almost identical implementation strategy to FFTW, in that it creates a plan depending on the size of the bin, butterflies things, and maybe even unrolls loops. Although I'm not sure about that last part. I'm sure that's true re: speed with round-trip processing for real-time audio; just doing an fft on a single 1024-sample bin is way too small to justify a round-trip GPU excursion. I'm processing a huge batch of samples, though, to feed data for a genetic algorithm -- not doing this in real-time. Perhaps once I get this really rolling in production I'll do some benchmarks and see what's there.
This subreddit is for the Rust programming language. I think you're looking for /r/playrust. :)
This has nothing to do with the custom test frameworks. It only uses the default `cargo test`. However, it might be possible to add integration tests via a custom test framework for the next post. The question is whether the feature will be implemented in time.
Nope, see [low\-level language definition](https://en.wikipedia.org/wiki/Low-level_programming_language)
This article just seems like one big "No True Scotsman" fallacy. If C isn't a low level language, then what is? They briefly mention Fortran, but only in the context that its arrays are non-aliasing, which is true, but not really relevant to how x86 or the PDP-11 work at a low level, it's just relevant to the kind of optimizations that can be performed. If C isn't low level, then no, Rust is not low level either... but C is absolutely "low level," since this ill-defined term is relative to other languages, and "high level" languages must have a "low level" language to compare against, or the term is meaningless. Perhaps they mean that assembly is the "one true low level language"? But even writing assembly would not have prevented Meltdown or Spectre, rendering their point moot.
My speculation is that HTML parsing is not a bottleneck, so the other components have a higher impact when integrated into Firefox.
&gt; a parody of a computer scientist who wishes never to have to think about hardware and live in a world of pure computational models. I can't judge the accuracy of the assertions about C, but given that the entire point of the article (again, whether accurate or not!) is to assert that the vision of the hardware C provides (via the abstract machine) and the actual hardware are severely out of alignment, and therefore the reason (according to the author) that C isn't a low-level language is that it obscures the actual hardware, this assertion is bizarre. I mean, dispute if you like the descriptions of the functioning of the PDP-11 as against modern processors and the resources C provides one for programming against each. But this wasn't written by someone who doesn't care or want to care about hardware.
Mostly for types like BigInt which want to produce an owned `BigInt` while only borrowing the two summed types, I think. There's also `+` on `String` and `&amp;'a str`, where borrowed strings can be concatenated onto owned Strings, and the result always has to be an owned string. The other usage is in time keeping or other areas where you have "durations" which can be added to an "absolute time", and the result should be "absolute time". There are implementations `Add&lt;Duration&gt; for Instant { type Output = Instant; }` and `Add&lt;Duration&gt; for SystemTime { type Output = SystemTime; }`. Without a separate output type, none of these other usages of `+` could work or make sense. I think `BigInt` is the most crucial one (we don't want to force all operands on BigInts to take ownership of both sides), but others are also helpful.
Possibly of interest, given ongoing work around "macros 1.2/2.0"!
This is definitely QotW material. /u/llogiq? :\)
&gt; This article just seems like one big "No True Scotsman" fallacy. If C isn't a low level language, then what is? Serious question: why isn't the answer allowed to be "nothing"? The author is pretty explicit about what he thinks a "low-level language" is: "One of the key attributes of a low-level language is that programmers can easily understand how the language's abstract machine maps to the underlying physical machine." He then argues that C does not answer that description. It does seem to me that often when people say that C is low-level, they *do* mean that you can control what will happen, if you wish to (or sometimes that you *have* to control what will happen, even if you don't wish to), or (a very similar claim) that you can look at a bit of C code and know what will happen on the actual machine when it executes, *and that's why it's low-level*, and that seems to be ‚Ä¶ maybe not so much the case. ("According to the results of the survey, 36 percent were sure that they would be [wrongly], and 29 percent didn't know." And the surveyed were compiler writers and standards committee members!) That isn't No-True-Scotsmanning, an exercise which involves continually changing what is meant in order to maintain an increasingly untenable position. It's an attempt to formulate what "low-level language" does or ought to mean, and assess whether a language popularly considered to be one actually meets the standard. That seems, to me, to be a much more worthwhile way of thinking about the issue than just saying, basically, "C is a low-level language" and then formulating one's understanding of "low-level language" based on the fixed star that C must be one, come what may. *Why* is C "absolutely 'low-level'"? Given that the levels beneath C, and the mapping of C onto those levels, have been steadily gaining in complexity, isn't it possible that what was *once* low-level is now not, and that there are just more levels than there used to be?
You saying it like I don't have alias for it :) 
&gt; why isn't the answer allowed to be "nothing"? Because then the term is useless, and there's no point in having the term. But, the term has proven useful over the past several decades, so redefining it to be useless now doesn't seem helpful. &gt; It does seem to me that often when people say that C is low-level, they do mean that you can control what will happen, if you wish to Which is true. You can do *anything* the machine is capable of doing, if you want to. Most of the time, people don't actually want to, they're just writing C code because they know C compilers make fast executables. There are even "intrinsic" functions for SIMD and other platform-specific instructions that map to those instructions. It's even possible to write inline assembly. But most of the time, people write C code which doesn't impose these constraints on the compiler, so the compiler feels free to do things the fastest way it can figure out. If you *really* care about compiling your code the way you wrote it, you can compile with `-O0` and get no optimizations. No magic. But, the magic isn't bad, and the magic isn't responsible for Meltdown or Spectre. &gt; Given that the levels beneath C, and the mapping of C onto those levels, have been steadily gaining in complexity, isn't it possible that what was once low-level is now not, and that there are just more levels than there used to be? That is something I can agree with.
For types like `Vec`, the value on the stack is just a pointer, a length and a capacity, so only 24 bytes. Moving the `Vec` just moves those 24 bytes. It doesn't move the contents of the vector (which are stored at the other end of the pointer). The same is true for most other container types (including Strings, which are just `Vec&lt;u8&gt;` under the hood.) On the other hand, if you have a `[u8; 1048576]`, that will take up 1 MB, and will be very expensive to move. (By contrast, moving a `Box&lt;[u8; 1048576]&gt;` just has to move the pointer.) Whether anything *actually* has to be moved depends a lot on compiler optimizations. The compiler (or LLVM) might perform [return value optimization](https://en.wikipedia.org/wiki/Copy_elision#Return_value_optimization) to avoid having to make a value then immediately copy it, opting instead to create the value directly in its ultimate location in the parent stack frame.
Can you please explain which wrong assertions were made and why you think the article is baseless and the author is ignorant? Because, to be frank, your comment strikes me as ridiculous. I am prepared to be proven utterly wrong here, but it seems like you either didn't fully read the article or have some strongly-held misconceptions about modern hardware and systems programming, and it astounds me that this comment has got upvotes in a subreddit devoted to a systems programming language.
Firefox's HTML parser isn't a high priority candidate for replacement, so I don't know of any plans to do so at the moment.
When you get a alphabetically sorted list of api functions ‚Äúok_or‚Äù appears first. If you‚Äôre on a hunt you‚Äôre probably going to stop at the first match.
How far along are the other parts of Servo in being added Firefox? That is, how do other parts of Servo compare to Gecko, Blink, etc.?
[I think this is the same article.](https://www.reddit.com/r/rust/comments/8fixy2/should_safetycritical_software_be_written_in_c/)
I think working with an AST has its uses but I am not a big fan of it. (This includes custom derive) Personally I would rather do metaprogramming on types directly with a nice functional API. For example D and C++ can do this. In C++ there is [hana](https://github.com/boostorg/hana) and in D you have some compiler builtins like [FieldNameTuple](https://dlang.org/phobos/std_traits.html#FieldNameTuple) I have also written a [blog post](https://maikklein.github.io/2016-03-01-metaprogramming-typeobject/) about type metaprogramming in D a few years ago. For example enum types = tupleFromTypes!(int, double, string, float); enum biggerThan4 = filter!(t =&gt; t.type.sizeof &gt; 4)(types); writeln(biggerThan4);// TypeTuple!(Type!(double), Type!(string)) If you don't know D anything here is probably unreadable but a lot of things are extremely trivial to implement. For example [vector swizzling](https://github.com/BreezeEngine/breeze/blob/master/source/breeze/math/vector.d#L74-L86) (Although this might be a bad example because it mostly uses constant expressions). I have also implemented [SoA](https://github.com/BreezeEngine/breeze/blob/master/source/breeze/util/soa.d#L97-L153) but it is not the prettiest code because D still lacks a high level metaprogramming lib like hana. I always wanted to write a blog post where I would extend Rust with a hypothetical syntax that would allow type level metaprogramming, but I haven't found the time yet. Is this something that you would be interested in?
Rust is exactly as low-level as C is. If C isn't low level, than neither is Rust.
&gt; The author is pretty explicit about what **he thinks** a "low-level language" is: "One of the key attributes of a low-level language is that programmers can easily understand how the language's abstract machine maps to the underlying physical machine." Yes, he writes a definition of the term that is entirely his own and then builds his article around it. He has very valid points about the abstractions from the hardware that C provides; but I'm not a fan of the statement that it is therefore not low-level because it doesn't match his personal definition. As /u/enzain said, low/high-level is a spectrum, and it doesn't make much sense to say "it's only low-level if it's at exactly this point of the spectrum".
Someone post it on the rust-users thread, please, I'm busy cradling my 18months old and finding a bug in my timeout extension to cargo-mutagen
There's also https://alan.ci/buildbot/ if you want to do FreeBSD. By the way, it doesn't look like openbsd.rs is reporting GitHub Statuses. You should fix that; it would allow your users to gate bors on your OpenBSD builds. Ask alan how he did it.
I'm trying to analyze a benchmark. I've made good use of linux perf in the past, so I'm using that. I know how to run the benchmark binary, but the problem is the benchmark has some nontrivial setup (loads a largeish file). When running it via cargo, all seems ok since I'm loading the file outside of benchmark.iter. But when running it directly via the binary, that does not seem to be the case, at least it doesn't seem so, since the IO is dwarfing every other activity quite a bit. What am I to do here? Can I have the binary run the "real" benchmark more often to diminish the influence of loading the file? Or what else can I do? I assume the IO uses some functions I'm using in the benchmarked function as well, so it doesn't seem easy to just "not look at the iO"... Thanks for any pointers!
Well, that's not the main problem for now while there isn't a graphical IDE for rust, but will be soon.
One Komodo is currently worth $3.90. So you could pay your bills with it. https://coinmarketcap.com/currencies/komodo/
Works fine for me. I've been using Neovim + ALE without any issues.
ƒ∞s this guide eligible for people that has no info about OS and Rust but languages closer to Rust(such as C/C++)? I have interest about operating systems and this seems good way to start.
This is something I've been using for awhile in my personal projects. I've found it pretty damn useful, if maybe a bit against typical rust style.
&gt; Because then the term is useless, and there's no point in having the term. But, the term has proven useful over the past several decades, so redefining it to be useless now doesn't seem helpful. I believe the author's point is that it is possible for the context of the industry to shift such that it bumps languages out of categories that they previously inhabited. I.e., that C was once a low-level language, but may not be anymore. Anyway, mostly this article seems like it's arguing semantics, and the opposition to this article seems like it's mostly rooted in the desire for people to define "low-level language" as *meaning* "whatever C is (and Rust, by extension)". Rather than get bogged down in more semantic arguments, let's just posit the following to appease everyone: 1. Relative to Java, C is a low-level language 2. Rust is as low-level of a language as C is 3. Thanks to optimizing compilers and CPU microcode, C in practice is no longer a transparent mapping to machine code on most hardware, and if such a language existed that provided such a transparent mapping (which none does) then that language would be lower-level than C 4. Historically, original C was considered a high-level language by dint of providing any abstraction at all, so there's no need for us to be overly defensive about its status on whatever spectrum of power we can come up with
https://wiki.mozilla.org/Oxidation
I see. Great. Thanks 
A fairly short answer: because you can mutate it internally (you marked it as such) and because you have proven unique ownership. The reference example could have been shared and is thus too dangerous to mutate.
I have tried to give a single example, to illustrate the point. To expand on that, Option&lt;T&gt; is an enum: enum Option&lt;T&gt; { Some(T), None, } So, the language allows building your own types that give similar guarantees. Contrived example: enum MessageKind { Verified(Message), Draft(Draft), } Where `Message` and `Draft` have methods that are only valid for verified and draft message, respectively. All the places where `MessageKind` is used would have to explicitly unpack it to get to `Message` and `Draft` types, and there may be many methods that only need to know about `Message` or `Draft`. This often results in many, many small structs and enums, but this is how idiomatic Rust looks like, because composition is easy.
This is exactly why I was interpreting those three attributes to be explicitly tied to TiDB 2.0, rather than TiDB itself. However, then we're back to the initial problem that a release cannot be "battle-tested" on the first day of its existence, regardless of the experience that was used to form it.
tbh the real point of this article is that *assembly* is no longer a low-level language. And if the hardware itself only provides a mid-level interface without the ability to truly target it at a native level, then it's not too far-fetched to say that neither C, nor Rust, nor any other language are low-level.
&gt; Suckless terminal doesn't have scroll buffer. https://st.suckless.org/patches/scrollback/ ;)
But that same logic could be applied for value members of the struct (let‚Äôs say my struct had an i32 field), but Rust wouldn‚Äôt let me modify that through an immutable binding even though it would technically be safe...
&gt; Assembly is high level compared to bytecode machine code* [bytecode](https://en.wikipedia.org/wiki/Bytecode) is for a software interpreter.
I'm using neovim with LanguageClient-neovim, rust.vim and RLS and I do not have weird warnings.
:D
Ha! Of course.
Awesome! Thank you.
I have deliberately not defined a target audience for the blog because I don't want to exclude anyone. Also, it's very difficult to estimate whether a post is understandable for someone, because people are different. That said, I try my best to provide at least short explanations for the OS concepts and non-standard Rust features we use, and links to further information. So I'd say just give it a try and ask if anything is unclear! 
Oh I see. I will surely give a try after my final exams.
It may be helpful to do something like this: #[bench] fn bench(b: &amp;mut Bencher) { // expensive setup things... b.iter(|| do()); } #[no_mangle] // help c tools with function name #[inline(never)] fn do() { // what you want to benchmark } Using a separate function should help tools notice the separation.
Congratulations! üéâüéâ
In Rust you can have mutability *or* aliasing, but not both (unless you use things like Cell/RefCell/etc). In your second example you do: // Trying to mutate it through this reference won't work let ref_a = &amp;a; *ref_a.val = 10; But the compiler sees the possibility of aliasing, because `&amp;T` is always `Copy` (for any `T`). So you could just as easily do: // Trying to mutate it through this reference won't work let (ref_a, other_ref_a, another_ref_a, even_more_ref_a) = (&amp;a,&amp;a,&amp;a,&amp;a); *ref_a.val = 10; Clearly if the above would be allowed we would violate the mutability xor aliasing rule.
You could avoid misuse by using a type which bundles the iterators together: struct RopeIters&lt;'a&gt; { owning_rope: &amp;'a Rope, ... } impl&lt;'a&gt; RopeIters&lt;'a&gt; { fn distance(&amp;self) -&gt; usize { ... } fn into_iters(self) -&gt; (impl Iterator, impl Iterator) { ... } } Don't know anything about fancy typesystem stuff to do this, though.
&gt; I always wanted to write a blog post where I would extend Rust with a hypothetical syntax that would allow type level metaprogramming, but I haven't found the time yet. Is this something that you would be interested in? Yes! I'd very much like to read that.
I have a macro that takes only a static string and does calculations and function calls and iterators with it until it panics or returns a value. I expect the compiled code to have evaluated the macro down to the value or panic, but is there any way at all to have the compilation fail if a macro will ultimately evaluate to a panic or whatever error value?
&gt; The From&lt;regex_syntax::Error&gt; impl has been removed. This formally removes the public dependency on regex-syntax. regex-syntax is still a public-facing dep in cargo.toml. I might have misunderstood something, though.
If you're using ALE make sure it's not using rustc as the checker. Rustc does not have the ability to read outside of the current file. Try using something such as Cargo or RLS.
A public dependency means it's visible in the API, and thus part of its semver compatibility. For instance, if it were public, then bumping `regex` to use `regex-syntax` 0.7.0 would be a breaking change, since the API would not be compatible with people still using `regex-syntax` 0.6.0.
I'm not sure what this pattern is called, but if you make `RopeIter` invariant over `'a` it becomes impossible to pass an iterator with a different reference lifetime: use std::marker::PhantomData; struct RopeIter&lt;'a&gt; { owning_rope: &amp;'a Rope, // this doesn't actually contain anything, it's just a type marker // *mut T is invariant (cannot be subtyped) so there is no intersecting lifetime // with any other reference except the one that created this iterator _invariant: PhantomData&lt;*mut &amp;'a Rope&gt;, } impl Rope { pub fn iter(&amp;self) -&gt; RopeIter { RopeIter { owning_rope: self, _invariant: PhantomData, } } } fn main() { let rope1 = Rope::new(); let rope2 = Rope::new(); // error: borrowed value `rope2` does not live long enough rope1.iter().distance(&amp;rope2.iter()); } However, the user experience isn't great as you just get some generic lifetime error. I guess most users shouldn't stub their toes on it if you document this behavior well enough but I don't know how to make a unique type otherwise. Closures have unique types but they are now (in beta) copyable if their captures are copyable, so you can't really use those to ensure uniqueness anymore as someone could just copy the same closure to both constructors of `RopeIter`.
None of these are details I think can be safely relied upon: - The specific layout of fat pointers - Fat pointers do not affect destructors - Vtables do not need destruction - That `Box&lt;T&gt;::from_raw` is able to take a pointer created by `Box&lt;U&gt;::into_raw` without UB Probably others but those are the main things which come to mind.
Hmm... Okay so I do agree that ‚Äúletting me mutate through the reference‚Äù is bad, but then why is it okay to do it through the binding? Especially since I wouldn‚Äôt be allowed to modify a value type field in the same struct.
That's fine because `x` is a mutable binding. You cannot change `val_ref` itself because the reference of type `&amp;mut` is bound immutably, but since `x` is bound mutably and `*val_ref` gives you the value bound to `x`, it all works swimmingly.
I'd tried to answer the question with the same invariance trick earlier, but mine always compiled so I didn't post an answer. It looks very similar to your. Maybe you can you tell me what I'm missing? [Playground](https://play.rust-lang.org/?gist=1c0fd5998fb5242d4864b99a753d5ca0&amp;version=stable&amp;mode=debug).
Function calls and iterations and the like are performed only at runtime; Rust doesn't have fully fledged constant evaluation yet. If you want to have all calculations done and errors emitted at compile time you could [implement it as a proc macro](https://doc.rust-lang.org/unstable-book/language-features/proc-macro.html#function-like-procedural-macros) instead. Don't be turned off by the unstable feature, basic usage should be stabilized very soon.
Thanks for the good answers man. But then my next question would be - Why won't Rust let me do the same thing through an immutable reference then? Doesn't the same logic apply? I have an immutable reference so I can't change `foo.val` or `foo.val_ref` through the reference, but `*foo.val_ref` is still a reference to a mutable thing.
If you own `Foo` (which you do in the above example), then you're in control of all possible paths of mutation. But if you only have a `&amp;Foo` then you don't, because taking a `&amp;Foo` comes with the specific guarantee that anyone else can also take a `&amp;Foo` at the same time as you. So the compiler doesn't let you mutate stuff. tbh there are some people who think that mutable vs immutable bindings are kind of redundant and maybe shouldn't have been included in the language, as it's the system of ownership vs shared borrows vs exclusive borrows that's what *really* matters.
My original example also doesn't work if you swap the `Cell` for `*mut &amp;'a Rope`, i.e. it still compiles when it shouldn't.
I'm an experienced C &amp; C++ dev and trying to really dig into Rust for the first time. I'm using `bindgen` to generating bindings for Vulkan but I'm having a problem with the syntax and my Google-foo has failed me so far. **C code** typedef void (VKAPI_PTR *PFN_vkVoidFunction)(void); typedef VkResult (VKAPI_PTR *PFN_vkCreateInstance)(const VkInstanceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkInstance* pInstance); // ... VKAPI_ATTR PFN_vkVoidFunction VKAPI_CALL vkGetInstanceProcAddr( VkInstance instance, const char* pName); **Generated Rust code** pub type PFN_vkVoidFunction = ::std::option::Option&lt;unsafe extern "C" fn()&gt;; pub type PFN_vkCreateInstance = ::std::option::Option&lt;unsafe extern "C" fn(pCreateInfo: *const VkInstanceCreateInfo, pAllocator: *const VkAllocationCallbacks, pInstance: *mut VkInstance) -&gt; VkResult&gt;; // ... pub fn vkGetInstanceProcAddr(instance: VkInstance, pName: *const ::std::os::raw::c_char) -&gt; PFN_vkVoidFunction; In C, if I want to use `vkGetInstanceProcAddr` to get the address of `vkCreateInstance`, I can do a simple cast: `PFN_vkCreateInstance vkCreateInstance = (PFN_vkCreateInstance)vkGetInstanceProcAddr(NULL, "vkCreateInstance");` I would like to do something similar in Rust, and I feel like there's a way, but I don't know what it is. I'm not sure how to convert the `PFN_vkVoidFunction` (`::std::option::Option&lt;unsafe extern "C" fn()&gt;`) into a `PFN_vkCreateInstance`. My first attempt was the most naive I could think of: let vkEnumerateInstanceExtensionProperties = unsafe { vkGetInstanceProcAddr( ptr::null_mut(), "vkEnumerateInstanceExtensionProperties".as_ptr() as *const i8, ) as PFN_vkEnumerateInstanceExtensionProperties }; but that obviously didn't work: `error[E0605]: non-primitive cast: std::option::Option&lt;unsafe extern "C" fn()&gt; as std::option::Option&lt;unsafe extern "C" fn(*const i8, *mut u32, *mut vkrs::vk::VkExtensionProperties) -&gt; vkrs::vk::VkResult&gt;` I next tried something that seemed more idiomatic, unwrapping and rewrapping: let vkEnumerateInstanceExtensionProperties: PFN_vkEnumerateInstanceExtensionProperties = unsafe { Some( vkGetInstanceProcAddr( ptr::null_mut(), "vkEnumerateInstanceExtensionProperties".as_ptr() as *const i8, ).unwrap(), ) }; which also failed: = note: expected type `unsafe extern "C" fn(*const i8, *mut u32, *mut vkrs::vk::VkExtensionProperties) -&gt; vkrs::vk::VkResult` found type `unsafe extern "C" fn()` The last thing I did, which seems to work, is use `mem::transmute`. While it works, it doesn't exactly feel idiomatic or right: let vkCreateInstance = unsafe { mem::transmute::&lt;PFN_vkVoidFunction, PFN_vkCreateInstance&gt;(vkGetInstanceProcAddr( ptr::null_mut(), "vkCreateInstance".as_ptr() as *const i8, )) }; My question is, is there something I'm missing that would make this cleaner? 
Basically per [RFC 1122](https://github.com/rust-lang/rfcs/blob/master/text/1122-language-semver.md) I think that all of this is fine. &gt; The specific layout of fat pointers I don't believe I'm relying on that, only that `as` succesfully converts a fat pointer to a thin pointer. I believe changing that would be a breaking change disallowed by the stability guarantee and probably cause trouble in some other peoples FFI code as well. &gt; That Box&lt;T&gt;::from_raw is able to take a pointer created by Box&lt;U&gt;::into_raw without UB This is an interesting argument. You might be technically correct at the moment. I am using the api's in a way that the documentation could be interpreted to not support. You could also argue the opposite since it doesn't explicitly mention `Box&lt;T&gt;::into_raw` just `Box::into_raw` and it goes to the trouble of explaining the reason why (allocation). Once the [coercion API](https://doc.rust-lang.org/std/ops/trait.CoerceUnsized.html) is stabalized I think it will be even closer to defintiely guaranteed, since the `as` statement will be guaranteed to just be copying the pointer around. The rest of the library stands without the `Box` feature... maybe I should throw it behind a feature flag. &gt; Vtables do not need destruction Nothing *needs* destruction, that's guaranteed by `mem::forget`. I might be leaking memory, except not on any sane platform. &gt; Fat pointers do not affect destructors The question isn't if fat pointers affect destruction (e.g. by also destroying a vtable), but if destroying the thin pointer and not destroying the fat pointer can cause undefined behavior. The answer to this is the same as the one to `Box&lt;T&gt;::from_raw(Box&lt;U&gt;::into_raw...`.
I figured out the difference between our examples. What I actually tested on the Playground looked more like this: https://play.rust-lang.org/?gist=41b9a3d9e3a182a863b84fbaae087a92&amp;version=stable&amp;mode=debug So the borrow of `r1` is actually a wider lifetime than the borrow of `r2`, but only because `r1_iter` was created before `r2`.
Ah, yes, okay. That was the case for me as well when I tested extracting the iterators to their own variables. Makes sense. But then unless I can figure out a way to generate a truly unique lifetime I don't think the variance trick is going to work. I suspect it'll take some unsafe code to summon the lifetime from the ether.
This is a compile-time reflection api, right? Java also has a nice run-time reflection api, though an inscrutable compile time 'annotation processing' api.
&gt; eg. if you are javascript and are storing integers in a floating point value, then you can rely on small integers being represented exactly Is javascript different from rust in this regard?
Could you expand on what you mean by type metaprogramming vs AST metaprogramming. Would type metaprogramming be something like [Shapeless](https://github.com/milessabin/shapeless) for Scala? It seems like there is some overlap. I'm coming at this familiar with the Scala side things and a bit of a C++ noob.
There's been discussion of removing it because it's infrequent you have a fallback Option already instantiated. 
Go fuck yourselves
Or how about this guy sells the Crypto and then pays the devs in cash? Oh wait, that would cause the price to tank, wouldn‚Äôt it? Ah well that‚Äôs awkward, suppose paying people in fake money is pretty dishonest isn‚Äôt it?
No, javascript is just an example: in rust you would normally have no need to store integers in a floating point type: you would just use an integer type.
Congrats! Your regex crate is something I often point to for what can be done with rust and it's great to hear that 1.0 is out!
I use [Spacevim](http://spacevim.org) instead of rolling my own config for NeoVim, and its been great. That being said, I get the sense that several core rust developers really like VSCode. I suspect that its getting closer to "first class" support than other editors (which doesn't upset me, I'm just pointing it out.) For example, the reference plugin they made for RLS was for... VSCode: https://github.com/rust-lang-nursery/rls-vscode
&gt; Experimental support for server side symbolication is also provided if you upload debug symbols. Cool! Also, extremely easy to get started with, that's a compelling example. Does it capture all panics across threads? Or would I have to register for each thread I spawn?
Thanks a lot for your help. I think I understand. That's a really interesting approach!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/buttcoin] [Decentralized cryptocurrency exchange startup seeks Rust developers willing to be paid in their cryptocurrency](https://www.reddit.com/r/Buttcoin/comments/8gcxdg/decentralized_cryptocurrency_exchange_startup/) - [/r/recruitinghell] [This is a position that pays out in crypto](https://www.reddit.com/r/recruitinghell/comments/8gdboy/this_is_a_position_that_pays_out_in_crypto/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
This is great news! One more thing that will reduce the friction of getting Rust into more production environments.
The meta point from the article is that this is as much a hardware problem as it is a language or developer one. An arms race was waged to create CPUs that are very effective in running sequential programs; to the point that what they present to the program is a very much a facade and they hide an increasing great deal of internal implementation detail. To drive this juxtaposition home, I'd point to PALcode on Alpha processors in which C (and others) can very much be a low level language. Very few commercial processors let you code at the microcode level. The overarching premise is then brought home by GPU programming, which shows that you don't necessarily need to be writing at the ucode level if the ecosystem was built around how the modern hardware functioned.
Awesome!
&gt; some people who think that mutable vs immutable bindings are kind of redundant Interesting - Could you elaborate on that a bit more? Would every binding be mutable only? Or do they mean that bindings would only be about ownership transfer, and everything else would be done through borrows?
Okay, look. I'm not a fan of cryptocurrency and I wouldn't take any job that pays out in cryptocurrency, but this is a perfectly polite post asking for expressions of interest in what might be an interesting project for the right person. You've reacted to that with unreserved vitriol. Please take a look over at the side bar, specifically "Respect our Code of Conduct", "Constructive comments only", and "Chill out", since I'm pretty sure you just violated all three of those.
&gt; Serious question: why isn't the answer allowed to be "nothing"? That doesn't sound like a useful category. It reminds me of the free will and determinism debate
It still says to add regex 0.2 as a dependency in `Cargo.toml`. Should it not be regex 1.0? Also congrats, the more mature crates Rust has, the better.
Cool article, but looks little complicated. With stdweb you can have a working app in a minute, and it's much easier.
I'll direct you toward https://crates.io/crates/vk-sys, in case you don't know about it. There's nothing technically wrong with your final solution. The layout of an `Option&lt;reference-type&gt;` [is defined to be the same as the equivalent pointer](https://doc.rust-lang.org/nightly/nomicon/ffi.html#the-nullable-pointer-optimization), so it's safe to use transmute between the different option types. However, I do think it would be more idiomatic to move the `Option`s outside of the types: // vulkan uses stdcall on win &amp; aapcs on android-arm, so use "system" pub type PFN_vkVoidFunction = unsafe extern "system" fn(); pub type PFN_vkCreateInstance = unsafe extern "system" fn( pCreateInfo:*const VkInstanceCreateInfo, pAllocator: *const VkAllocationCallbacks, pInstance: *mut VkInstance) -&gt; VkResult; pub fn vkGetInstanceProcAddr( instance: VkInstance, pName: *const ::std::os::raw::c_char) -&gt; Option&lt;PFN_vkVoidFunction&gt;; I don't know if Bindgen has an option to do this automatically. You could also omit the `Option` altogether; since calling `vkGetInstanceProcAddr` is unsafe, you could consider using a valid `pName` to be part of its safety contract. Also remember to null-terminate strings you pass to C: `b"vkGetInstanceProcAddr\0"`.
It sadly isn't an option, but there is an [open issue](https://github.com/rust-lang-nursery/rust-bindgen/issues/1278). Perhaps when I'm a bit more comfortable with Rust I can tackle that. Thanks for the reminder about the C strings, that's a tough habit to break. 
So to clarify, you have something like this in your main crate? #![feature(proc_macro)] extern crate my_macro_crate; use my_macro_crate::ni32; pub struct ni32(pub i32); Then the import is simply shadowing your struct. Proc-macros are resolved through the normal means instead of `#[macro_use]` magically importing them into a special global scope so you can end up accidentally shadowing like this. The only advice I have is to pick a different name for one or the other.
I imagine they would just be mutable. Like if you have `let x: i32 = 42`, that's an owned binding with no outstanding borrows, so as far as I understand it, there's no reason to forbid modifying that binding purely from a *safety* perspective. But if you then did `let x_ref = &amp;x` then yeah, at that point you'd be forbidden from mutating `x` until `x_ref` is gone. So if you only ever hand out shared references to your value, you know that no one else can change it even if your own binding happens to be mutable. Same would hold true for passing unique references. You'd express that you're okay with someone else mutating your value by passing them a `&amp;mut` reference in the first place. But that being said, it can still be nice to know that *you* can't change your own values either, even if just for the sake of you or others who are reading through the code later on. So it's not like immutable bindings are completely useless, even if it is sometimes annoying to go back and change a `let` to `let mut` despite the fact that passing a `&amp;mut` already conveys everything that the type system needs to know about how to treat the referenced value.
I have both the macro and the struct in the same crate. I also tried reimplementing the macro except it calls a renamed procedural macro internally which fixes ni32() but ni32!() fails with `expected struct `proc_macro::TokenStream`, found floating-point variable`
You can't have the `#[proc_macro]` in the same crate, it has to be a separate crate because of how procedural macros are implemented in the compiler currently.
&gt; (1) The C abstract machine is not an accurate model of how modern hardware works and has not been for some time; thus, it is misleading at best (and outright wrong at worst) to call C a low-level language. I'm confused how calling a language low level or high level or anything in between has any relationship to the appropriateness of that language for hardware, be it ancient or "modern" (whatever that's supposed to mean - &gt;99% of all new processors manufactured don't have features like speculative execution, or operation reordering, or op fusion). Is C++ somehow magically more appropriate? Is the illusion that it's a viable language for modern programming any more or less destructive than C? Classicaly, dating back to early computing, C was considered kind of a medium-level language, in an ecosystem of languages like Cobol, Basic, Pascal, and Fortran, the span from what was called "low level" to what was considered "high level" wasn't very wide. It's not that C has gotten lower, it's that C has gotten more languages derived from it that are higher than it. &gt; Whether you agree with the title or not is just a matter of your preferred definition of "low-level" and is totally subjective. I didn't argue with the title on its own merits, I argued the title on the merits put forward by the author, and I find them wanting. &gt; (2) Modern hardware is being held back by trying to maintain the illusion that C is a low-level language. I can find no way to, for lack of a better way of putting it, connect with your mentality here. Perhaps the problem I have with your statement is the contention another fellow made - that seems like a setup for a "No True Scotsman" argument. Is the definition of low-level language completely subjective as you previously asserted? Under what definition has anyone been trying to "maintain the illusion" that C is anything? Who's writing all this new C code for modern processors? I see lots of new C++ code for modern hardware, but most of the new C code I see is for embedded hardware, but all this really seems beside the point. &gt; As for the second thesis, the author never claims that C in particular is responsible for Meltdown and Spectre Really? &gt; The features that led to these vulnerabilities, along with several others, were added to let C programmers continue to believe they were programming in a low-level language, when this hasn't been the case for decades. He says the CPU features were added for C programmers in particular. &gt; the article says that Meltdown and Spectre, and all of the broadly related speculative execution bugs that have been uncovered in the past will be uncovered in the years to come, are the result of an industry of computer hardware that is frantically trying to keep up the illusion of serial execution, sequential consistency, and determinacy because it is convenient for programmers while achieving real performance gains from generation to generation So which is it? Are our processors overengineered because we have crappy languages for them, or are our languages too crappy for our processors? He argues both, poorly, and ignores the more likely third-cause explanation. Speaking of our saviors - the massively parallel processors that we can't make use of because the world is obsessed with C as a low level language - sideband channel vulnerabilities can exist in anything. nvidia's parallel processors are pipelined, with shared execution hardware - if anyone were actually executed privileged code on those things, there's all kinds of timing attacks you could do to extract information about what a parallel thread is doing. So tell me, how is that C's fault? And those parallel processors have [significant hardware in front of them](http://www.nvidia.com/docs/IO/55972/220401_Reprint.pdf). An nvidia board has hardware for managing 1536 threads each GPU. Each thread has its own stack, register file, program counter, and local memory. Each thread processor has 1,024 physical registers, 32 bits wide, implemented in SRAM instead of latches. The GPU preserves the state of inactive threads and restores their state when they become active again. That's a lot of complexity in hardware for bugs to hide in. In fact, that sounds a bit like an operating system implemented in hardware, with a lot of silicon dedicated to it. And all that complexity to create an illusion for software - an illusion that your instruction is being directly executed simultaneously on all the supplied data. 
I am the author of KRust and still working on it. I admit that the syntax implemented is very limited, but I am still updating KRust to make it complete. I never thought this project would be so difficult. K is horrible to use. However, K is still the first choice to generate executable semantics. BTW, I hope someone familiary with K or Rust can join me!
Excellent trick. Didn't know `less` could be used like that. 
Thanks for chiming in! Are you aware of the Formal Verification working group? https://internals.rust-lang.org/t/announcing-the-formal-verification-working-group/7240
Potentially, yes, since Servo is intended to have a good embedded story (which has long been one of Gecko's weak points). There's lots of people who are hopeful that they'll eventually be able to use Servo as a sort of cross-platform GUI. Servo isn't quite there yet though, and it will take time. In the meantime, Github is already experimenting with what Atom-as-an-Electron-app-but-with-Rust might look like: https://github.com/atom/xray
Done that thank you
Is it mostly because it is hard to complete, hard to replace, or just not a large enough benefit to do so?
&gt; which has long been one of Gecko's weak points Hasn't xulrunner been a thing way before Google started working on Chrome, let alone the release of electron?
I know it! Actually, I replied to this announcement. JerryWang304 is me :)
Did you read my post? Go fuck yourselves!
Not really - this was something I started last year for a misc thing that didn't really come to fruition. It had sat idle for awhile, so I polished it up a bit and rolled it out. Originally I was just going to call it labview and have an lvm module, but I realized that was a bit silly since I myself haven't used labview much.
I feel like maybe I should write a blog post too on this. Your example looks good but you have generics now. This means the top level array enum would also need generics (if we are trying to stick with enums) and because arrays can contain mixed types, that won't work. However, your suggestion could maybe work if there is trait that it implements. It seems there are quite a few ways to skin this cat.
I'm working on a working `libm` implementation [here](https://github.com/shingtaklam1324/mish). Currently it is quite slow, using convergent series and iterative methods instead of bit manipulation.
While I definitely meant machine code, bytecode is correct in the context of my sentence.
Not sure if this is an easy question -- but how does Rust actually build static binaries? Considering `glibc` isn't an option (you could swap it out with musl libc) but even if you do that `libnss` hinders you (the only viable alternative I've seen is the chromium patched one, and mozillas somewaht abandoned attempt)... I'm actually now really confused as to whether 100% static binaries are even a real thing that exists, even if it's only in the context of unix system.
You're right mostly bytecode/machine code is used interchangeably to mean the extreme low-level, however in this context it should have been machine code.
I've never seen it used interchangably, but it's possible some people do.
I do see `rustc_driver` and others listed under "Crates" in the sidebar on https://doc.rust-lang.org/nightly/nightly-rustc/rustc/, don‚Äôt you? (I think this sidebar is populated with JS, I‚Äôm not sure of the details.)
Timing attacks over network connections are not unheard of. Given enough datapoints, networkjitter can be statistically removed. 
[Wow.](https://github.com/rust-lang/regex/commit/63c6c541fc39f9b77605e47cace087ea398bb101)
The code of conduct also applies to people you despise. If it would only apply to situations in which you would already be polite, what is the point?
Same here.
Rust has `println!` despite it being more efficient to `writeln!` with a stdout lock, and `HashMap` uses a hasher that is DoS-resistant despite the slowdown. "Call `rand::random::&lt;i32&gt;()` to get a random number." would be a great introductory paragraph to `rand`'s documentation. If profiling says it's a problem, then fixing it is pretty mechanical.
Don't make this personal. 
Yes, but print is used with a very specific meaning, see also this &gt; STDOUT &gt; The standard output shall contain the sequence of bytes read from the input files. Nothing &gt; else shall be written to the standard output. 
If anyone tries to get you to do anything involving crypto, it's a scam. It's a ponzi scheme built on the fact that the only money in the system is what people put into it themselves. A Zero sum game where the only winners are the people who, coincidentally, happened to own half of all the coins before they shilled it to the public...
In general, as a project, we love all your editors[*]. One thing not to be forgotten is that VSCode is also very popular at our user base _and_ we frequently got questions about the previous plugins. It's not only that we like it, the users like it. That said, we don't build specific support just for VSCode outside of the plugin and want to make development for all editors easy. Please give feedback if you see anything! [*] eyes for emacs-vim war outsite.
It is more like March/April 2014 if memory serves. It was initially part of the Rust distribution before Cargo was a thing. At that point, it was moved to a separate repo, which was the best thing that ever happened to it because it let me pick it back up and iterate on it very easily.
It is populated with JS.
&gt; Most functions have been checked to 4 d.p. with a Casio Scientific Calculator Well done for validating your implementation, but would it be more impressive if you had a test suite that verified your answers against the real `libm`, possibly with something like [quickcheck](https://crates.io/crates/quickcheck) or [proptest](https://crates.io/crates/proptest) to automatically generate test-cases.
Oh that's true, *facepalm*. I did initially search for that list, but I didn't find it when I searched before I posted this.
Congratulations! It's good to see rust stabilizing after watching it for these years. I know it wasn't done lightly. PS: The README still references version 0.2 btw.
Yeah, this is a simple proof of concept. I wouldn't recommend using it at the moment. Also testing floats are going to be a pain, and with the number of rewrites I'm planning to do, it may not be worth it to add tests at the moment. As well as that, all of the convergent/taylor series that I am using are very well documented in academia and mathematics literature, so I would say those should be fine. Only thing that remains unverified are the CORDIC inverse trig functions. `sqrt` being a binary search at the moment is not the best for accuracy so I may switch that back to `powf`. Regarding checking with `libm`, I have tested some of the functions with `std`, but those lower into `intrinsic` calls so I'm not sure whether those are `libm`. It will pretty much never be 100% `==` with `libm` as the different algorithms lead to slightly different answers, especially for functions like `sin`
I think you're misunderstanding some things. Rust isn't a silver bullet, but it *was* designed to eliminate a class of bugs that makes parallel programming hard. The mentioned achievements aren't just technical. There's also a time and manpower component. With enough effort, every technical achievement is possible, but that doesn't make everything feasible. Rust made the mentioned achievements feasible enough that a small group of developers tackled and conquered them.
Yes, they're native OS threads, if available at all.
Well, no, it's not actually an honest response. If you look at that user's history they don't appear to have *ever* commented in this community before, meaning they specifically came into this subreddit to attack this post. That definitely crosses more than a few lines. Again, I'm not a fan of cryptocurrency. I have no problem whatsoever with the *polite* objections that were elsewhere in this post, and actually agree with most of them. However, /u/unitaker_ is right; if you make exceptions to the Code of Conduct because this particular thing is something you object to, what even is the point? If you have a problem with something, object, loudly and clearly, but do so in a civilised manner.
&gt; lso testing floats are going to be a pain At least for testing 32 bit floats, you can just tests all bit patterns easily by transmuting `u32` to `f32` and then calling your functions.
&gt; possible vs feasible I think I *wanted* to say feasible. We say "m√∂glich" in both cases in German, which is most often translated back to "possible". &gt; I think you're misunderstanding some things. Rust isn't a silver bullet, but it was designed to eliminate a class of bugs that makes parallel programming hard. I do realise that, but it does not prevent race conditions, for example, thus claiming "it makes parallel programming safe and easy" is wrong at best, dangerous at worst. "Memory safe" would be better wording, but I guess it sounds less sexy than "safe and easy". This kind of incorrect marketing statements creates false expectations and Rust does not even need them, so why bother having them?
US law doesn‚Äôt recognize anything but USD as valid payment for wages. By paying in crypto, you are inviting legal trouble from employees who cash out the crypto and then file wage claims with the state labor department. The labor department will investigate, correctly determine that you have paid your employees nothing, and order you to pay them in USD. Retroactive to date of hire. Save everyone the trouble and pay your employees in USD.
We could argue about whether or not it is explicit enough. This is drifting into a matter of personal taste. My reason for asking was to satisfy a personal preference. For what it's worth, I use the same argument when doing code reviews at work (Java development backing university admissions). I prefer: private Object mutateObject(Object thingToMutate) {...} as opposed to private void mutateObject(Object thingToMutate) {...} The first version has an explicit return type and makes the usage obvious. Useful when you do refactors and reuse months and years later. That said, I agree that passing `&amp;mut` is explicit. I'm just being picky on my return types.
This worked perfectly and prompted me to study explicit lifetimes. Or, put another way, probably the first time that I understood what the lifetimes were doing rather than writing them as a magic incantation... Thank you.
This is amazing news, have been waiting for this for a while!
I have added some tests, I'll push onto GitHub later. Most functions are equal with libm to `1E-4` at the moment. I need to add more terms to the taylor series for `sin`, `cos`, `tan` to be more accurate than `1E-2`. With the use of convergent series, it's currently a compromise between speed and accuracy, and so far I have chosen to do it with about `1E-4` accuracy as the target. You have raised a good point however, now with verification, turns out inverse trig functions aren't accurate enough at the moment. I'm going to switch it to a convergent series implementation and see how that goes. &gt; 100% compatibility with libm I'm not sure about that one. Floats are strange when comparing direct bit manipulation (libm) to convergent series / iterative methods (mish). To get accuracy to within `fXX::EPSILON` would take a large number of iteations, where it is not feasible anymore due to how long it takes.
With floating-point, it's never going to be 100%, but it's useful to measure how close you get to some external reference. If I can download your crate, run `cargo run --example test-against-libm` and get a report that says something like "this crate agrees with your libm to 20 bits of precision" that's very different than a report saying "this crate agrees with your libm to 10 bits of precision". And if most of your functions agree with libm to 50 bits of precision but one set of functions only gets to 35 bits, that would be pretty useful to know, too. It's easy to take a mathematically verified algorithm and accidentally miss a negation or something when transcribing it to executable code, and wind up with something that happens to work perfectly for positive integers (or whatever your manual test-cases happen to be) and does weird things outside that set. Tools like `quickcheck` and `proptest` are excellent for flushing out those kinds of accidents. &gt; Regarding checking with libm, I have tested some of the functions with std, but those lower into intrinsic calls so I'm not sure whether those are libm. Whether the resulting binary happens to include a call to libm or not, on a desktop or laptop I expect it'll all wind up as the same floating-point hardware instructions so it doesn't much matter
&gt; It's easy to take a mathematically verified algorithm and accidentally miss a negation or something when transcribing it to executable code, and wind up with something that happens to work perfectly for positive integers (or whatever your manual test-cases happen to be) and does weird things outside that set. Tools like quickcheck and proptest are excellent for flushing out those kinds of accidents. Good point. The mathematically verified functions all passed `quickcheck`. The only functions that doesn't are the CORDIC functions. &gt; on a desktop or laptop one of the targets / my hopes for this is being used on embedded platforms
awesome, I had been using the m crate from /u/japaric . It looks like this has more functions ported though. I'll have to compare when I get home next week.
&gt; I'm not sure about that one. There are many libraries faster than `libm` producing incorrect results (including some "pure Rust" ones). There are also many libraries much slower than `libm`, some of them, producing correct results. There aren't, AFAIK, any libraries that perform on the libm ballpark (&lt;2x slower) producing correct results in pure Rust. Such a library would be a candidate for inclusion in the Rust `core` library, because right now many mathematical operations are not available in `core` due to the `libm` dependency.
&gt; I thought sqlite would lock the database during writes and that the other threads would block until it was unlocked, then proceed. Instead, all other transactions simply failed while the database was locked. If you were getting `SQLITE_LOCKED`, I believe the preferred approach is to use different connections, one for each thread (instead of sharing a single database connection). There's also `SQLITE_BUSY`, which is a little [more complicated](http://beets.io/blog/sqlite-nightmare.html).
I do not post in all the reddits I am subscribed to. That doesn't mean I am not active in em. That's not how it works. I do not know how you do it, but I am pretty sure that most people subscribe to stuff and usually do not post until there is a strong urge to do so. So you do not know if that person came here to just post that. 
I think that should be relatively straight\-forward. I've worked with LPC81x before switching to 82x, and as far as I remember, they are very similar. I think you could copy/paste most code with little to no changes \(but please be careful, always consult the user manual\). Things get interesting, if you want to share code. I've thought about this for a bit, and I think it may be most straight\-forward to create an lpc800\-hal crate that serves as a toolbox for more specialized crates. Basically, lpc800\-hal would contain everything that any lpc800 chip could offer, and more specific crates \(lpc82x\-hal, lpc81x\-hal\) re\-export whatever is actually available in that family. I haven't attempted this, though, just thought about it. There might be a better way. If you want to work on this, let me know! I'm not sure if I can be of much help, but I'd love to talk.
I wouldn't actually use it for anything serious at the moment. It is pretty accurate apart from `arcXXX` trig functions which are broken.
I agree with your point. This was more of a proof of concept and a mathematical exercise than a serious project to replace `libm`. With the use of iterative/convergent methods, there is no chance it is as fast as `libm`. The title isn't great now that I have though about it, and the name (and Github description) is more accurate, where it is `libm`-ish, and different. Sorry for any confusion caused by the title. For a project that actually has performance close to `libm`, I believe there are two? libraries which were WIP but are both semi-abandoned by now. One of which was `m` by japaric, which I feel like should be the one that the community effort should be going to, as getting that working, along with `libc` implementations like `relibc` would be a boost to `no_std` development.
true that
Yes
Typically you would want to use a threadpool and use threads from it. The likelihood of all your threads being executed at the same time is pretty slim but for the average case I believe it's not perceivable and can be thought of as executing parallel. What do you mean by linked? You could use channels or something of that sort if you need inter-thread communication. You could have one thread waiting on the results of 4 worker threads via a channel.
Great! There are some code improvements to be done on rust side * why using a `vec![Vec::new(); 5]`, can't you have a `[Vec::new(); 5]` directly ... or even a single `Vec` only since you will flatten it anyway? * in `unpack_cascade`: * `&amp;mut buff: Read&lt;u8&gt;` =&gt; you should be able just to call `buff.read(_i32/_f32/_exact)` consecutively without resetting it (no need to keep track of `p`), use some `Vec::split_at` if needed. * perf: you should reserve various Vec capacity as soon as possible (just after getting `depth`/`ntrees`), either by calling `Vec::reserve`, `Vec::with_capacity` or directly by extending it with lot of `0`s * you may probably be able to avoid an entire loop with [read_f32_into_unchecked](https://docs.rs/byteorder/1.2.2/byteorder/trait.ByteOrder.html#method.read_f32_into_unchecked) ... which will probably be much faster * overall, depending on the endianness and the size of the data you're unpacking, it might be possible to have a first `transmute` into some intermediary struct which can be added to a `Pico` struct * in 
The world does not revolve around your fucking United States you know? Plenty of people from different countries would be more than happy to accept the job, as long as it pays out in a liquid crypto such as BTC or ETH.
I‚Äôm no expert, but I imagine most developed countries would have similar policies about trying to pay employees in something other than the national currency. Calm down. 
Awesome work. Writing traits everywhere for dependency injection was one of the thing I wanted to avoid in Rust - and this macro handles such work perfectly. Keep in going!
Sorry when I said "linked" i meant to say linked above, as in the link I posted.
So I noticed a lot (all) of your functions are duplicated for f32 and f64. Have you thought about using a generic type instead of duplicating them? I mean, this isn't go.
Nice, looks very interesting. I'm interested in using more dependent types..
Why do you even have this field `method: &amp;'static str`? Isn't it always the same as `R::METHOD`? If you really need it (if it differs from `R::METHOD`) you could also make it `&amp;'a str` in `ExtendedForSerialization&lt;'a, R: RlsRequest&gt;`.
Yup, the client has [integrations](https://docs.rs/sentry/0.5.1/sentry/integrations/log/index.html) with the `log` crate, so can be configured to do as you suggested.
[Cretonne](https://github.com/cretonne/cretonne) is working towards being a replacement for SpiderMonkey. Or, at least, it is intended to be the JIT back\-end for it in the long\-term. Once that is done, then, it, or a related project, could move up the stack and take over for SpiderMonkey/IonMonkey.
&gt; (even trivial in many cases) ...as in changing `.iter()` to `.par_iter()` and possibly making minor tweaks to address ownership problems.
Good point... The main issue is with constants that need to be hard coded into the program, ie. Pi and Fractions of it. I guess I could use an associated type to do that.
Analyzing and verifying the format string is done *before* the compiler knows that the variable `tup` is indeed a tuple, so what's Python is doing won't be possible in Rust. Your choices are either to use `{:?}` to print the whole tuple; unpack the tuple manually; or create a wrapper struct with a custom `Display` impl.
And yeah, this one is easy. I‚Äôll do it soon, `warmy` is stable enough, I can get back to graphics stuff! 
I don't believe concurrency means what you think it does. Concurrency is when multiple threads make progress. They may be running on different cores at the same time, they may be scheduled to run in time slices on a single core.
Exactly. There is a C meme that the first thing you write when starting a new project is `#define max(x,y)`. Let us not repeat this with `random`.
Did you try something along the lines of: ``` let (first, second, third, fourth) = (1, 2, 3, 4); println!("{} {} {} {}", first, second, third, fourth); ``` Or is that not what you expect?
I am aware of the standard library but I think that type objects are a bit nicer. For example this is how I implemented the sort. enum sort(alias f,Tup)(Tup){ enum tup = Tup(); static if(tup.length == 0){ return typeTuple(); } else static if(tup.length == 1){ return typeTuple(tup[0]); } else{ enum middle= tup[0]; enum t = partition!(t =&gt; f(t, middle))(typeTuple(tup[1..$])); enum left = t[0]; enum right = t[1]; return typeTuple(left.expand, middle, right.expand); } } Which can then be used like this: enum types = tupleFromTypes!(int, double, string, float); enum sortedTypes = sort!((t1, t2) =&gt; t1.type.sizeof &gt; t2.type.sizeof)(types); writeln(sortedTypes);// TypeTuple!(Type!(string), Type!(double), Type!(int), Type!(float)) The downside is that the D compiler is not nearly as fast as the C++ compiler for type objects. I think one guy did a big refactoring once but I don't think he finished it.
That said, always stop to think about whether your type is a value or a reference. "First Name" is a value. Once it's been validated (eg. as valid UTF-8), it's guaranteed to stay valid. A file path/URL/network address/etc. is a reference. You can use validation to bail out early to minimize the chance of having a non-interactive job error out (as opposed to prompting for a replacement value) after doing a lot of work, but, no matter what you do, it's outside your program's control, so it's possible that, between check and use, the resource it points to will change in a way which invalidates assumptions. (Thus, use `Result&lt;T, E&gt;` liberally when building APIs around references.)
Thanks. I'm reminded of the "What git features do you use?" survey I took. (It was a massive flood of "git *has* that feature? Why did I not know this?!")
Python-ish `*` for destructuring tuples/arrays does seem like it might be a nice shortcut to have, and I feel like it should be able to be be implemented as a macro. Might be interesting to try...
That is ridiculous and amazing. I want youtube videos!
Pondering [adding the `gfx_glyph` font cache to ggez](https://github.com/ggez/ggez/issues/132#issuecomment-384446176), mainly due to [some nice PR's that got me interested again](https://github.com/ggez/ggez/pull/343) as well as [Ratysz being a baller and doing a lot of tinkering](https://github.com/ggez/ggez/pull/362). So far, it looks like it's going to be a strict improvement over the current font rendering with plain `rusttype`, which makes me super happy. Current plan is to make it its own module for a 0.4.3 release and see how it works out in practice, and assuming everything goes well replace the current font rendering with it for 0.5.0.
I doubt you'd be able to implement it as a macro while still allowing stuff like the following to work as users would suspect. let x = &amp;5; println!("{}", *x);
Well you'd need a different syntax, yes. I was thinking something like let x = (1,2,3,4); println!("{}", explode!(x));
Done. Everything is now generic
Compared to `m`: This is slower, but has full coverage. `m` is more thoroighly tested against `libm` and might be more accurate. Compared to `libm`: Use `libm` unless you really don't want any C dependencies.
&gt; Now if there was a pager with git and syntax highlighting support...That would be an amazing feature fyi.. you can setup 'less' to show syntax highlighting: https://www.gnu.org/software/src-highlite/source-highlight.html#Using-source_002dhighlight-with-less 
Huge thanks to such a patiently review. Currently this project is just a line by line rewrite of the picojs, and I would going to improve the code in the following days. And I think I should start from your review comments :) Thanks again.
i would never say ‚Äúm√∂glich‚Äù when i mean ‚Äúpossible‚Äù. the closest thing to ‚Äúfeasible‚Äù in german is probably ‚Äúpraktikabel‚Äù or more freely ‚Äúrealistisch‚Äù. you‚Äôre right that we should avoid loose language and raising false expectations. if you‚Äôre convinced of something, use facts to support it, they‚Äôre on your side. but rust does make parallel programming safe \(as in, you don‚Äôt accidentally overwrite the wrong piece of data\) and easy \(compared to languages without the same memory safety guarantees\). the ownership model naturally translates to a parallelization model that allows fewer errors than \(obviously\) C, C\+\+, and so on, but also Java, Python, JS, ‚Ä¶
The type you are returning is something that implements `de::Deserialize&lt;'de&gt;`. The lifetime `'de` shows that this type depends on the lifetime of another object; in this case it appears to be the vec you allocate with the raw data, `bytes`. In this case your `Foo` struct doesn't actually need any of that data, since it makes its own copies (it contains `String` instead of `&amp;str`). So you have two easy options. One, you can make the function return `Foo` instead of a generic `T`, since `Foo` doesn't have a lifetime. Two, you can make the `T` be [`de::DeserializeOwned`](https://docs.serde.rs/serde/de/trait.DeserializeOwned.html), which can only deserialize objects that don't depend on external data... like your `Foo` type. Examples: https://play.rust-lang.org/?gist=d7187bcdcc3a8cbdc1055e45c1abca4b&amp;version=stable&amp;mode=debug
just out of curiosity, you are coming from python, yes?
maybe you can take some inspiration from the included sampling functions: https://docs.rs/rand/0.4.2/rand/seq/index.html
Could you make an explode2!, explode3!, explode4!, etc?
Probably just want `println!("{} {} {} {}", tup.0, tup.1, tup.2, tup.3);`
Thanks, I might understand now. Previous versions of `regex` required users to use `regex-syntax` for some things, but now it's all "under the covers".
Typically, Servo components that see benefits in both performance and safety/security top the priority list. Right now, H5E doesn't move the needle on performance enough (if at all). That could, of course, change. :)
For anyone (such as myself) who does not know what `libm` is: https://en.wikipedia.org/wiki/C_mathematical_functions#libm &gt; Under Linux and BSD, the mathematical functions (as declared in math.h) are bundled separately in the mathematical library `libm`.
Rust `std` just doesn't use things that can't be provided by a standard `libc`. `libnss` is an implementation detail (not standardized by POSIX, it appears?), and `glibc` doing dynamic loading for `libnss` even when you make a static binary is a non-standard feature to offer more functionality than what the standard mandates. `musl-libc` doesn't use NSS at all (see https://wiki.musl-libc.org/future-ideas.html). musl also provides its own implementation of pthreads and several other things.
Creator here! Feature suggestions, code review, and contributions are welcome :)
Ahh so to make sure I understand -- `std` just doesn't use `libnss`? All the network-related functions `gethostbyname` are provided by some other crate that's written in pure rust (or comes from `libc`?) I just looked it up and I didn't realise that `gethostbyname` was provided by both `libnss` and `libc`. To make my intentions a little clearer, I'm actually asking because doing static builds on my haskell program is actually requiring `libnss` right now for `gethostbyname` (DNS lookup), and I was wondering how languages like Go and Rust were able to get by this without something hacky like pulling in a patched version of `libnss`. 
&gt;I get the sense that several core rust developers really like VSCode. I suspect that its getting closer to "first class" support than other editors I think that it is due to the popularity of VSCode, and not a personal preference of individual developers. Also, remember that LSP was born in VSCode, so it can be considered the reference implementation.
This post made my day! The benchmarks validate the value proposition of Rust, and the problems Figma ran into validate that the things we're focusing on improving are important. Hard to imagine a blog post that could make me feel better about my work.
Right but only one of those time slices, or however it's implemented, is ever running at once. Only one thread, time slice or other computational unit is ever mutating or progressing the task at once. 
The Pros and Cons list in this post was actually really nice. I appreciate when critiques arne't "It's hard to learn", but are actually issues that many of us have faced and are in the process of being improved. That said, if any Figma people show up in the thread, I spent 15 minutes on your website and still don't know what Figma is. Imo you're missing any type of hook for potential clients. 
I'm trying to build a library, where the structures are generated from an .xml file. I already have a prototype of the code generation tool. The user might modify the .xml file, so I would like to design my project such that cargo build will run the tool and generate the library. The flow would be: - run cargo build - cargo calls the codegen tool - codegen tool reads the xml and generates .rs files - cargo builds the generated library Is this the best way to handle libraries with codegen? Is there a better way to approach this? How can I make cargo run my tool first? 
Nicely written. Please do more stuff like this. It is very educational.
Cool, thank you.
The standard way to do this is [cargo build scripts](https://doc.rust-lang.org/cargo/reference/build-scripts.html).
I am not a fan of downcasting, personally, but I am quite impressed that you managed to implement downcasting *as a library*. Kudos!
Knowing that Matt is at Google I knew this was coming, but I still find the way it exactly happened a bit surprising.
&gt; The following graphs show various metrics for the week before, during, and after the progressive rollout. No matter how often I look at this graph, I really don't know what it means. The x axis appears to be time, but no idea what the y axis is. The description doesn't help: &gt; The huge drop in the middle is where the progressive rollout hit 100%. In the middle, I only see spikes :/
&gt; We ended up converting all errors to strings immediately and then using a macro that includes the line and column of the failure in the string. This was verbose but got the job done. You should check the `error_chain` or `failure` crates.
&gt; there is a chance htat all 4 will be used as scheduled by the OS? If you want to eliminate chance, you can just pin each thread to a different core. 
Interesting. It seems they even have [a free hobbyist tier](https://sentry.io/pricing/). Anyone have experience with this? Would this be something you would recommend to us CLI authors? - Does the feature set / UX line up well? I'm used to services like this focusing on backend events. - Does their hobbiest tier fit with open source CLIs we're writing in Rust? Not sure if the focus is more for someone tinkering in their home or if it can handle cases like ripgrep. Members of the CLI-WG saw a similar need and wrote [human-panic](https://github.com/yoshuawuyts/human-panic) to make it easier to collect relevant information for opening issues but it doesn't do any automatic reporting.
Ditto. What does Figma "do" exactly?
This post doesn't directly mention Rust, but it makes for good discussion about what it means to be a low level language, and how sticking with C is actually holding us back in terms of performance. The really interesting bits are around how, because C is the go-to language for performance sensitive tasks, the PC ecosystem is shaped to make C code perform as best it can; this means extracting as much instruction-level parallelism (instead of threaded parallelism) as possible via behind-the-scenes compiler and hardware magic. The argument is that a "true" low level language would not require jumping through so many obscure hoops to be performant, but would be built for easy threaded parallelism. This in turn would make it simpler to create hardware that doesn't have to alter the behavior of the code it needs to run to be performant, making the code automatically be lower level, because it better matches what the processer actually does. E.g.: &gt; The key idea behind these designs is that with enough high-level parallelism, you can suspend the threads that are waiting for data from memory and fill your execution units with instructions from others. The problem with such designs is that C programs tend to have few busy threads. and &gt; The cache coherency protocol is one of the hardest parts of a modern CPU to make both fast and correct. Most of the complexity involved comes from supporting a language in which data is expected to be both shared and mutable The article concludes: &gt; There is a common myth in software development that parallel programming is hard. [...] It's more accurate to say that parallel programming in a language with a C-like abstract machine is difficult, and given the prevalence of parallel hardware, from multicore CPUs to many-core GPUs, that's just another way of saying that C doesn't map to modern hardware very well. The thought that strikes me as fascinating (even if it is very, very far out) is that, while Rust is ultimately still quite C-like, it would stand a much better chance of performing well enough on hardware designed for threaded parallelism than C. In other words, Rust could actually be the programming language that helps us bridge the gap towards having programming languages that are highly parallel and low level, which would allow us to simplify our hardware a great deal to match, without cutting off reasonably performant backwards compatibility.
If it's going to be a `throw` expression, then it should be a `catch` block.
Yay for `Cell::update()` :)
I think failure has a discoverability problem. It and a number of other libs are, at this point, pseudo-official but there‚Äôs nothing capturing that. I remember about 6 to 8months ahi there was some sort of discussion about this sort of thing, but I don‚Äôt recall if there was an outcome that satisfied or upset everyone.
His point was that parallelism is a form of concurrency \-\- it's a superset.
Good thing it‚Äôs a Try trait and a try block then. 
In addition to what /u/CUViper said, this was basically an oversight. I didn't realize `regex-syntax` was a public dep of `regex` until recently (when I was very very carefully scrutinizing every detail of the public API to prep for 1.0). Namely, `regex-syntax` was always explicitly intended to be a private dep, where the only interface in common between the crates was the concrete syntax of the regex itself. For example, if you use `regex-syntax` to parse a pattern into an Ast (or HIR), then there is literally no way to turn that into `Regex` without doing `Regex::new(ast.to_string()).unwrap()`. And yes, of course, `Regex::new` will internally just re-parse the string, which means it is indeed wasted work. But thankfully, this sort of thing isn't necessary often, and when it is, you can often pay for it.
Good luck convincing anyone with a real skillset to buy that argument.
&gt; I think failure has a discoverability problem. That might be true, but did they even look for a solution to the problem? Converting all errors to strings to handle backtraces should at least have made someone on the team ask the question "isn't there really a better way?". Had they ask here, on `users.rust-lang.org`, IRC, or basically anywhere, would have give them an instantaneous answer that there is indeed a better way. 
As I understand it, a mutable borrow is currently the only way to express taking a *part* of an object, mutating that part, and then conceptually ‚Äúputting it back‚Äù into the whole object. For example, with a mutable borrow it‚Äôs easy to take a sub-slice of a vector, sort just that sub-slice in place, and then have that change be reflected in the original vector. If sorting used a move-based API, it wouldn‚Äôt be nearly as easy, and certain move-based designs would actually make it impossible.
I work for a large company and we won‚Äôt touch anything but ¬£GBP ever. Multimillion company. OP needs to grow up or he/they are going to get bitten.
Do you think it would be possible to automatically detect this sort of violation?
That‚Äôs a load of bollocks, as well as being a huge sweeping statement across a plethora of different technologies and underpinned by communities or huge multi billion dollar companies. Rubbish.
Someone said this over on HN https://news.ycombinator.com/item?id=16979592
Let me put this in no uncertain terms: the notion that informal questions are the right way to discover critical knowledge is 100% toxic to helping people do things right. I have been in those kinds of organizations and people just don‚Äôt get the answers they need because they don‚Äôt know that they are even missing something.
I figured. Rust seems to absolve itself from bad code and it's 100% on the coder. Wasn't sure if there was a trick and it doesn't surprise me that this is by design. I've been spoiled by python for too long!
build.rs is exactly what I was looking for. Will it still work if the library I'm building requires no_std, but my build.rs does?
Personally, I find the semantics of `dispatch` problematic. I have experience working with a framework with a similar functionality, where the task can be executed either synchronously or asynchronously, and this results in *brittleness*. The problem? Side-effects. There is a huge difference between side-effects happening *now* or *later*, so when most of the times (or for most of the tests) they happen now, but sometime (or outsides of the tests) they happen later, the system as a whole can behave unexpectedly. `post` and `defer` look great, however. In particular, for performance, being able to keep computations local to a core help getting the most out of CPU caches, so the distinction is quite helpful.
Is anyone else receiving a DNS failure?
Nice, that's the book I'm using but I'm only on the ownership chapter. That's what I did but I was wondering if there was a shortcut. I appreciate how Rust forces us to be conscious of what we're doing so it makes sense that this doesn't exist.
&gt; I think failure has a discoverability problem. I thought `failure` was still an experiment for now? I don't mean to say that there is no discoverability issue; just that before advertising a crate as *the way to go*, I'd rather wait until it's matured and the API/performance has settled. Early advertising may lead to people *getting burned*, and then shunning the library even after it's hugely improved as they remember their past experience.
This was a while ago, and my memory is a little hazy, but: a lot of things. This feature wasn't designed for general programmers, but rather for absolute beginners (usually middle school students). The primary motivation with the LINQ-like syntax was simply hiding the existence of lambdas and higher-order functions from students (the whole thing desugared into `map`, `filter` and `fold`s over lists of records). Ultimately, however, we decided that there were enough other details we wanted to hide from absolute beginners (e.g., records) or features which this did not provide (e.g., field names as first-class citizens) that we moved to a language-defined, opaque `Table` type. Designing a language around curricula is an exercise in compromise and very often what is best for a curriculum isn't exactly what we, the wizened developers of Pyret, would want in our "dream" language.
Yuuup. Tribal Knowledge isn't good. It needs to be written down and shared
Yes.
I'm back playing with WASM, currently trying to rewrite HLS.js\(a js hls client that transmuxes .ts to .mp4\), or at least part of it to rust. It seems to be a perfect fit for it, since we basically pass an array buffer in, move bytes around and send it back to the browser.
Thanks for the clarification. I think I understand better now. I believe the Scala macros are typed abstract syntax trees. So, I believe it can support any combination of AST and type metaprogramming. Do you think that is the best of both worlds or do you think the AST metaprogramming is a liability?
Thanks!
So what do you propose? So we are talking about helping organizations that: * are completely isolated from outsider Rust programmers * don't ask questions / don't look for information when something doesn't look right * don't inform themselves / don't read the docs / don't watch talks (`error_chain!` is mentioned in the book!) * probably don't even use linters nor know that linters like `clippy` even exist 
&gt; It needs to be written down and shared But it is? https://rust-lang-nursery.github.io/rust-cookbook/basics.html#ex-error-chain-backtrace 
&gt; Failure is on the way to 1.0 Well, that's half my point :) The other half is that if the consensus was that failure is the way to go for error handling, I'd expect to see RFCs for including it in the `std` library and possibly deprecating the current `Error` trait as part of Rust 2018.
I came from Python, and so many things I did I look back on today and almost regret doing lol. Rust is constantly introducing new ergonomics, but this isn't one I would expect to see for a long time, if at all.
Yeah, the concrete proposal is "bless" a bunch of libs as being "the canon" and link to it prominently from official places. The thing that was up in the air from what I remember was how to arrive at what goes into "the canon". At least one criteria I remember everyone agreeing about was "must be actively maintained".
If Rust ever gets variadics, this would be trivial to implement (in conjunction with const generics).
We tried to do this a few years back and the community was not happy with it.
So how does an organization that doesn't read anything about Rust whatsoever discover these libraries? 
To get to there from the official documentation page, you have to click on this link: "rust-learning. A community-maintained collection of resources for learning Rust.", then go down about 30 links to here: "Rust Cookbook", and *then* you see the title for the thing you're having a problem with. Maybe you and I have a different notion of what "discoverable" means, but that's not discoverable by newcomers in my book.
bytecode is machine code for a virtual machine imo 
"link to it prominently from official places" Are you having a bad day?
I just started with rust. My code mostly works but I feel it's a bit clunky. It could be nicer. I have a few questions: **Repetitions:** While I like the idea of having an option type like Some/None or Ok/Err it also is bad to use unwrap everywhere. I also dislike to use .expect because it does print to stderr and exit \(or is that wrong\)? What's the best way to handle a lot of Option types? **Nightly vs stable:** What's the best way to figure out if a crate uses nightly features if I want to stick with stable for now? Is there a way to check it somehow/quickly \(if it's not written in the docs\)? **Unused code &amp; warnings hell** I understand that error checking and unused code is potentially dangerous and stupid. But when I'm learning I want to explore and do the clean up in the refactoring phase. Is there a way or macro/directive to actually disable these unused code/unused variable warnings for an entire file? **how are modules grouped?** like in c#, meaning: 1 class per file or is it okay to group it logically? **Mentoring** Since I'm a rookie I would love to share my code in a bitbucket repository and let my code reviewed by someone more experienced \(via pull requests\). If someone wants to help me then please pm me or reply and I will pm you. My goal is to learn the language but without much pressure. I don't understand what ' means in 'a and so forth \(as an example\) and I wouldn't be able to write a linked list yet nor create a beautiful crate or code like burntsushi does \(for example\) Thank you and sorry if my questions are too off topic.
Yeah, I know. It's a king-maker issue. And if it was *included* in a standard library you could just download, then it turns into the Python stagnation problem. I don't have a perfect answer. I'm kinda thinking a quarterly survey might address some of the issues, but even then, there's the issue of what topics do you try to cover? What I remember the schism being was between people who wanted to do it manually and people who wanted to solve the problem through tooling on top of crates.io I thought that was a few months ago, not years though.
In the most correct sense I agree with you. However, Rust is somewhat higher level than secure C because it automagically takes care of huge amounts of scaffolding that are shoved out of sight beneath safe rust, whereas C doesn't do this. So in one sense I see Rust as being slightly higher level than C \(in a good way!\), but as far as relation to the hardware goes I agree that they are both equally low level. calloc\(1, 100\); Box::new\(\[0u8; 100\]\); Actually perhaps C is still slightly lower level there as you have the ability to directly initialize the heap allocated memory whereas in Rust the compiler currently first allocates to the stack and then memcpy to the heap allocated memory. I believe this is considered a bug of the Rust compiler currently however, rather than being intended behavior. 
IIUC, the way it would detect this exact case is the `From&lt;regex_syntax::Error&gt;` impl having a different `regex_syntax::Error` type because the `regex_syntax` dependency versions don't unify in Cargo between the two `regex` versions being checked. Maybe you should try it on such a bump, just to see what happens!
A few years ago we proposed the ‚ÄúRust Platform‚Äù, which would be a curated set of packages. You could like, say you wanted the 2018 platform and it would have unified docs, CI, we‚Äôd know that everything worked together, etc. that‚Äôs what I was thinking of at least.
`remote_file.write( buffer.as_mut_slice()).unwrap();` `write` returns the number of bytes written. You should probably be using `write_all`.
would it be because the file is not UTF\-8 encoded?
 libc::calloc(100)
I'm making a crate that defines a trait, and would like to conditionally implement it (with Cargo features) for some types in another crate. That other crate is currently at version 0.x. Now let's assume someone else finds my crate useful, but is for some reason forced to use the slightly older version 0.y of the third-party crate. (Maybe there is yet another crate that requires that version.) If they try to bring in my crate as dependency with the mentioned feature enabled, they will just end up with two incompatible versions of same third-party crate in their program and won't practically be able to use my trait. Let's also boldly assume the part of the third-party crate that my trait applies to is pretty much stable, even though the 0.* version numbers don't naturally any promises about it. Would it be a good idea for my crate to have multiple features with names like anothercrate07, anothercrate08 etc, with each feature matching a version of the third party crate? The first one would naturally depend to version 0.7 of that crate, the second to version 0.8 etc., and implement my trait for it. Because the types relevant to my trait are pretty much stable, I wouldn't even have to have multiple impls, just one long, ugly #[cfg] line. The user of my crate would only have to enable the feature that matches the version of anothercrate they are using - differences in patch versions would not cause incompability, if I'm understanding things correctly. I haven't actually tested if something this would even build, but the Cargo and cfg documentation made it seem like it could. Of course if you have better suggestions (even if it's just "it's not worth it, just support one version and hope the crate ecosystem gets in sync fast enough"), I'd be interested hear about them.
Last time I looked, cretonne was aiming at becoming a jit for wasm specifically with no intent to tackle JS (optimizing which is whole different story). The "moving up the stack" part is probably not very far from being the equivalent of "rewrite SpiderMonkey". Not that I wouldn't like to see it happen, but I don't think it should be naturally expected. 
I remember learning cdecl in C, then *args, **kwargs in python. I feel like Rust wouldn't dare let a developer do something so dangerous. I've only used println but that's a macro and I have no idea how those are written. Oh, I bring that up because a tuple would be handy here.
This is what I wound up doing. I'm learning there's no lazy way to go anything in Rust. ...not necessarily a bad thing.
&gt; This is the opposite of using message passing to run blocking operations on a threadpool. Instead of moving the blocking operation to another thread, the entire event loop is moved. In practice, moving the event loop to another thread is much cheaper than moving the blocking operation. Doing so only requires a few atomic operations. Whoa, that's clever! I wouldn't have expected that to be cheaper. Is this a well-known approach used in other projects, or is Tokio blazing a trail here?
Touche! 
All this stuff with `try { ... }` blocks and `throw` expressions seems silly. Is `throw expr` really that much better than `return Err(expr)`? Is `try { if(blah) { success } else { failure } }` really that much better than `if(blah) { Ok(success) } else { Err(failure) }` ? These seem like very minor conveniences at the expense of introducing some pretty exceptional language features which mimic exception handling, which Rust doesn't even have.
take a look at [mocktopus](https://crates.io/crates/mocktopus) which does a lot more when it comes to mocks. It actually generates mocks for you
that would mean all futures needs to be `Sync + Send`?
A `Vec&lt;u8&gt;` is not UTF-8 aware. It is just a bunch of bytes and doesn't care. A couple of things: `read_to_end` returns the number of bytes. Does that number match `file_size`? Do you need to do anything to close `remote_file`? I'm not very familiar with the `ssh2` API. It looks like you might want to do something like this: remote_file.close().unwrap(); remote_file.wait_close().unwrap(); If none of this works, you could also try using the `Sftp` API [provided here.](https://docs.rs/ssh2/0.2.13/ssh2/struct.Sftp.html) `ssh2-rs` is just a very thin wrapper around the SSH C library, so if the C library requires you to do things in a very specific, quirky way, `ssh2-rs` probably does too.
Why do helpful bots always get downvoted so much on this sub?
Only `Send`.
I use it a lot. Its an interface design tool, similar to sketch and gravit designer. Its basically a vector tool like inkscape, dumbed down to what is really necessary and a huge emphasis on usability and user experience. All that while running in a webbrowser/electron wrapper and having a constant connection with the server so that multiple people can work on the same document.
That's the default match bindings that stabilize tomorrow.
&gt; (lack of impl Trait on stable) Incidentally, you've got eight days to wait...
Nice use of Futures, in that the post is from May 5.
such cool stuff. I'd love to work on this but... &gt; - Solid development experience in distributed systems, understanding of distributed transactions, and consensus algorithms like Paxos or Raft; - Development experience in high-performance services, knowledge of performance testing, and system optimization based on relevant profile tools, such as FlameGraph; - Testing experience on distributed systems, knowledge of creating corner cases of distributed environments and verification of system stability. Despite trying multiple times I have to get exposure to any of that fucking shit. This is why I can't read about anything without feeling like a useless piece of shit. sigh.
I agree. I can kind of understand the need for try blocks. Basically it allows us to write code imperatively that can have errors at any point. Instead of functionally chaining things through `Result`'s functor/monadic methods, you could simply put things in a block, and the block always returns a `Result` with the last value of the block of an error. It'd be cool if Rust offered macros that could expose new block types, because the benefit, though real, is small enough that adding a whole new thing to the language may be too much, but a library would result in something great. I can also see the value of `throw`, basically it works like a `return` except when inside a `try` block it only exits the block, unlike a `return` that always exits the function. If there's a `try` block above then the `throw` has some utility. Still I wonder if a macro wouldn't be better here still. Basically a `throw!(err)` that becomes `Err(err)?` behind the scenes. No need to add a new keyword for something that can already be described well enough and it should cover, AFAIK, all the use cases. AFAICT this completely ignores the `?` and kind of lets it fly. I feel that we should focus on having one way of exposing errors, and then build on top of that separate abstractions as library, not language features.
I agree. It's a bit like nested event handler calls. You get loads of weird gotchas if your runtime allows them. Best to queue it and bounce back to the main loop, and only run one handler at a time. At work I have a locally-written custom runtime for communication between Lua VMs, and I found that often problems were solved by explicitly deferring something to run a short while later (on a defer queue). Actually I switched to actor-like "defer everything" because things were going that way anyway and it simplified things (e.g. allowing remote actors). I didn't start out wanting to write an async distributed actor runtime but that appears to have been the inevitable conclusion given the requirements.
Thanks for pointing me to rayon! I was starting on working with threads in Rust for the first time just today and rayon's thread pool seems to fit my use case much better than the thing I have hacked up so far ;)
Looks great and I can't wait to try this out! Filesystem-IO is the biggest bottleneck in my project at this moment. Are there some examples somewhere? The docs are a little spares on that part (or I'm looking at the wrong place)! Either way thanks so much for all that hard and great work!
What about [stdx](https://github.com/brson/stdx)?
That is a similar idea to tackle the same problem. It didn't particularly catch on either, or at least, not that I'm aware.
900+ stars means that somebody's probably using it. However, it seems outdated. Should probably mention that.
* `Option` and `Result` can be used with the `?` operator, so if your method returns either an `Option` or `Result`, you can have an ergonomic early exit. I personally use this more often with `Result`, and use `Option`s combinator functions (I'm particularly fond of `map_or`), but I acknowledge that's simply personal preference * Unfortunately, there is no easy way to find out if a crate is nightly only. The one sure way is to look into `src/lib.rs` or `src/main.rs` and see if there are any `#[feature]` definitions ‚Äì those are nightly only. If you try to compile such a crate with a stable or beta compiler, you'll get a mostly useful error. On the other hand, you can use a nightly compiler to compile stable code, and I've personally never encountered bad problems with nightly. * When starting out, it's often OK to ignore warnings. You can "allow" lints by writing `#[allow(..)]` with the lint names, or call rustc / cargo with `-A ..`. * Modules are grouped however you group them. I find that I will split up crates into modules once the file becomes too large; and then I try to find a partition that leaves a lean interface. It works quite organically for me. * Many projects including Rust itself will include mentoring if you collaborate, Look at [this week in rust](https://this-week-in-rust.org) for a list of easy mentored issues. You can also post what you have right in this thread and ask for a code review.
It is definitely a bit light... If you want to write some better docs, I can help you figure it out: https://gitter.im/tokio-rs/tokio or open a github issue.
&gt; * Yes, there are some operating systems that provide fully asynchronous filesystem APIs, but these are either incomplete or not portable. For operating systems which do support asynchronous, would it be possible to `#[cfg(..)]` specialize for those and use the non-portable APIs for that? If it is possible, is there some other reason that would be a bad idea?
It's not that simple as replacing one function call with another. On Linux, AIO is mostly useless AFAIK (although there have been plans to improve it for quite some time now), while the Windows implementation works, but doesn't play well with the `tokio/futures` model. Right now, `tokio-fs` only has a bare-bones API that mostly mirrors what's in `std`. It can't, for example, [read part of a file](http://man7.org/linux/man-pages/man2/pread.2.html) without seeking to it first. `tokio-fs` implements `tokio`'s `AsyncRead`, which doesn't have that operation. And without `pread`, you can't use multiple threads to different read parts of the same file. Admittedly, someone might add an `AsyncRandomRead` trait with something that corresponds to `pread`, but it's probably not a priority right now. And even with that, it wouldn't be true async IO, as `pread` is still blocking. Right now, `mio` implements a Unix-centric take on async socket IO, but I don't think anyone is planning on extending it to work with files, especially with the poor cross-platform support.
&gt;provided here. actually it was my stupid mistake ! i was adding on the same file on remote machine !! removing the file on remote server and redoing and everything is fine!!! thank a lot @coder543
&gt; Why would there be a subset of users who can't upgrade to newer versions? Maybe they're using a compiler version packaged by their Linux distribution instead of `rustup`. Those typically get upgraded only once a year or two. There have been [a lot of discussions](https://github.com/rust-lang-nursery/api-guidelines/issues/123) about whether bumping the required compiler version should be a semver-breaking change or not.
Well, isn't C was supposed to be exactly how the machine will execute it. You still can eyeball how the compiled code will look in assembly language, the same is true for most of Rust code. Just because rust inserts allocations and deallocations for you doesn't mean it's not as low level as C. What you can't do is eyeball how CPU will execute this code. 
Yeah, the answer to that is long and complicated, but the simplest answer is that not everyone agrees on what the policy should be. I myself have made my way through many sides of it...
Yeah I meant "how discoverable is it" as well when I said shared but I was firing that off quickly on mobile. Searching "get a backtrace rust" on Google gets me the backtrace crate which is good, but those docs aren't there. Even then that's just for error-chain. Not failure or std::error::Error which is where new people might look.
I have almost fixed the problem, except that my documentation which uses the macros cannot use them unless the macro crate is imported to the crate root (which leads to a cyclic dependency that cannot compile, since the macro crate uses the main crate). I can put the procedural macro crate under `[dev-dependencies]`, which fixes the separate test modules but it seems that the docs use the regular dependencies.
When I google for "Rust backtrace from error" it's the second list on my search results. But that doesn't really matter, since we are talking about organizations that don't search for information they need, ask questions, google for information, read the docs, etc. You could put this on the www.rust-lang.org front-page, and it still wouldn't help those who explicitly don't want to learn.
&gt; Maybe you and I have a different notion of what "discoverable" means, but that's not discoverable by newcomers in my book. What would then be discoverable for an organization that's not willing to read the docs, look up anything online, google anything, ask anybody, etc? Could you make any concrete suggestions? When I google for "Rust backtrace from Result error" the first three links point to `error_chain!`, `failure`, and this link. 
You mention in the post that stdin and stdout are handled in a similar manner to file system APIs. Linux, and I believe also macOS, support using stdin / stdout almost the same way as any other network socket / pipe in terms of asynchronous programming. Does tokio‚Äôs handling of stdin / stdout take advantage of this with CFGs, or does it - like the file system APIs - unconditionally use a threadpool? 
thank you x 1 000 000!!! DeserializedOwned is exactly what I need! Thank you for detailed explanation. I knew the reason, I just didn't know this trait :)
It would be fairly easy to add `pread` support to tokio-fs. Probably less than 5 LOC. Also, you don't need `AsyncRandomRead`, you could just add it on the `File` type.
The issue w/ STDIN / STDOUT on *nix platforms is that they are *global* resources. If you change them to non blocking, libs or other code that expect them to be blocking would break.
`dispatch` aside (sibling comment covers it), the distinction between `post` and `defer` is essentially the difference between `spawn` and `poll` (though the caller and callee for `poll` are reversed). That is, when a task has a continuation, it doesn't submit a *new* task; it merely signals that it is not complete and would thus like to be `poll`ed again when its associated `Waker` is signaled. Or in other words, `Future`s are poll-based rather than callback-based. The way you control where the task is spawned and polled is by your choice of executor. `Executor::spawn_obj` is primarily a "default" way to create new tasks, for when "use whatever executor I'm already using" is a good enough answer. If you need additional guarantees you can use executor-specific APIs instead.
Why would it be dangerous? It's still strongly, statically typed...
&gt;This is the opposite of using message passing to run blocking operations on a threadpool. Instead of moving the blocking operation to another thread, the entire event loop is moved. Let me see if I understand this. If you have a chain of futures, the entire chain is moved to a dedicated thread, which is a special "blocking" thread. Other running futures will exist on the main async pool. Once the work completes, the future is returned back as per normal. Does this mean that if you have a future chain like: * Async work * Blocking work * More async work * Even more async work The `More async work` &amp; `Even more async work` will be completed on the blocking thread? 
Why does the macro crate need to import from the main crate? To share code? Can you move that code into another crate that they then both import separately? That should fix the cycle.
`try { .. }` blocks contain the propagation of errors via `?` to a single expression, something that would otherwise require you to split that code out into a new function. It was also *included in the RFC that introduced `?`,* and has merely been delayed pending some unresolved questions. `throw expr` does the same error conversion that the `?` operator does, while `return Err(expr)` does not. With `try { .. }`, it also matches the expression-localized behavior of `?`, while `return` does not. Further, given `try { .. }`'s "`Ok`-wrapping" behavior where the normal value of the block doesn't need to specify `Ok` (no more `Ok(())`!), it makes sense to provide the same functionality to errors. So sure, they may be "minor" in some sense- but they're a large part of the original plan for `?`, they synergize well with it, and they clean up a not-insignificant amount of boilerplate.
Just a thought since this whole tuple question. Honestly they have to support it but if any language was to ban them it would be this one. 
I had been using crossbeam typically, but on a recent project I went and tried out rayon. Let me say that I will never be going back. The iterator-combinator approach to parallelism is just infinitely better. It might be that sometimes I cant use rayon (like if I have lots of unrelated threads constantly working and talking over channels), but whenever I can I absolutely will be. It is so painlessly easy that if I know a piece of code is going to be intensive (like running a bunch of pathfinding algorithms for various entities), I won't feel like its a huge deal to parallelize it; I can just do it right on the spot.
You're entire perspective of this is as someone who *knows the answer already*. You have to figure out the idea that a Result, which is a *value* could have a trace, which isn't immediately intuitive, before you can come up with the idea to google for that.
When the `blocking` ends, does the event loop return to the original thread, or is the original thread returned to the thread pool?
Great article! I'd like to see their code for handling the node&lt;-&gt;rust communication.
https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err `someRes.map_err(|e| e.into())`
&gt; I think failure has a discoverability problem. It and a number of other libs are, at this point, pseudo-official but there‚Äôs nothing capturing that. Personally I shy away from "pseudo-official" libs if I happen to know about them because around 1 out of every 3 crates I try just straight up doesn't work so I fall into a habit of trying to use as few dependencies as possible.
A bit of a simplified version: https://play.rust-lang.org/?gist=62ca678274cf3505aca0f53e715c7318&amp;version=stable&amp;mode=debug
`Ok(someRes?)` is shorter and pretty common though, despite looking weird at first. I wouldn't call it an antipattern. 
I seem to always forget about being able to do that :/
error-chain is accepted as the standard approach from what I understand. I use it whenever I start to be able to have more than one error type, otherwise I use the upstream error type. Also, [that error] you have is definitely pretty bad. Rust is also working to fix issues like that using [impl Trait](https://github.com/rust-lang/rust/issues/34511). The async/await that will be built into the language will also be helpful, but of course many of us will continue to use the combinator approach to futures where it is convenient, so the impl Trait features will help to make the output from the compiler a lot cleaner (whenever all the work in that RFC is finished =P).
I need to get deeper into this book. I kind of skip ahead when doing the exercises which is why I'm here. This question didn't have any hits on google. To be fair, I'm sure the correct terminology isn't "break out".
No, since you're mostly dealing with strings you shouldn't need the actual type to be imported in the proc macro crate.
I honestly only just remembered lol I've been writing it the way you suggested in all of my recent code.
You're welcome. I didn't have time to review it all. I don't understand all the logic :). Nice project
Can I use it with futures 0.2.x?
There are different types of midi clock / syncing midi devices, and this midi beat clock is often very unreliable, e.g. when Ableton Live is the slave. Apparently that's why Reaper doesn't even support this kind of midi clock, only other kinds like Midi Timecode (MTC)... Anyway, no matter which clock you want to use, you can easily do it. If you want to send a msg 24 times per beat, just calculate the current frame (ticktime / TICKS_PER_BEAT / 24) and compare this frame with the frame of the previous loop iteration. Since this kind of behavior occurs often in my code, I abstracted it away into a small `Observer` util struct. `ticktime` is your global monotonic tick time which is calculated at the beginning of every loop iteration based on current bpm and current system time in nanoseconds. `TICKS_PER_BEAT` is a constant, depending on the kind of resolution you want to use (I use 8192), all your midi clips that you are playing have to be encoded with this same constant. The callback you pass to midir's midi input when opening will already run in a different thread so you don't need to spawn another one. This is what I do: pub fn open_input(port_name: &amp;str) -&gt; Result&lt;(MidiInputConnection&lt;()&gt;, Receiver&lt;ChanMsg&gt;), Box&lt;Error + Send + Sync&gt;&gt; { let mut midi = MidiInput::new("")?; let port = (|| { for i in 0..midi.port_count() { if let Ok(name) = midi.port_name(i) { if name == port_name { return Some(i); } } } None })().ok_or(format!("midi input port '{}' not found", port_name))?; let (tx_midi_to_daw, rx_midi_to_daw) = channel(); Ok((midi.connect(port, "", move |_stamp, msg, _| { if let Some(msg) = LowLvlMsg::parse(msg) { let msg = ChanMsg::from(msg); trace!("{:?}", msg); tx_midi_to_daw.send(msg).unwrap(); } }, ()).map_err(|e| e.kind())?, rx_midi_to_daw)) } // and then, after opening all my input and ouput ports: let mut gui_update = AtFps::new(10.); let mut save_state_to_cache = AtFps::new(0.1); let mut midi_beat_clock_frame = Observer::default(); for (now, frame_time_ns) in FpsLoop::new(DAW_FPS) { if terminate.load(Ordering::SeqCst) { break; } if save_state_to_cache.is_due(now) { let _ = self.save(); } let bpm = self.state.param_state[ParamSelector::Global(GlobalParam::Bpm)] as f64; let timeframe = (frame_time_ns as f64 * bpm * (TICKS_PER_BEAT_D / 60. / 1_000_000_000.)) as TickTime; self.process(now, timeframe); // will add timeframe to self.state.cur_time at the end if gui_update.is_due(now) { self.tx_daw_to_core.send(MsgDawToCore::ToUi(Deck(0, SongPointer(self.state.session_view.cur_clip_pointer())))).unwrap(); self.tx_daw_to_launchpad.send(MsgDawToLaunchpad::SessViewFrameView(self.state.session_view.frame_view())).unwrap(); } // when it's time to send midi beat clock (24 times per beat) if midi_beat_clock_frame.update(self.state.cur_time / TICKS_PER_BEAT / 24) { // send clock msg } // ... #[derive(Default, Clone, Serialize, Deserialize)] pub struct Observer&lt;T&gt; { val: T, } impl&lt;T: PartialEq + Copy&gt; Observer&lt;T&gt; { pub fn val(&amp;self) -&gt; T { self.val } pub fn update(&amp;mut self, new_val: T) -&gt; bool { let changed = new_val != self.val; self.val = new_val; changed } } 
If the macro returns an `ni32`, how does the compiler know what this `ni32` is? I am getting undeclared type or module errors.
Hey thanks for doing so much research! When I did builds on Alpline (which uses `musl`), I was still getting issues with certain network-related function calls not properly statically building -- so if I tried to move the generated executable from an alpine container to say a ubuntu container it would error on *use* of a call like `gethostbyname`. If i was writing rust it looks like I could just make sure to use some other DNS resolver library and side-step the need at all. Unfortunately I haven't found the right project to use rust on quite yet so I'm not a rustacean but looking forward to visiting this again when I do.
How are you structuring your code? Your `#[proc_macro]` has to be n its own crate. I don't think you can reexport proc macros right now so if you're wrapping it with a `macro_rules!` macro I don't think that's going to work how you want it to.
Ahhh, yeah, good point.
In my main crate is the `ni32` struct, and I have a separate macro crate for the `ni32!` macro (that does not have a wrapping macro_rules) like you said to. I have run all the tests on both crates and a third party crate, and the tests say that `ni32` and `ni32!` are working as I intend, except that the docs are broken. I checked the `extprim` crate which has a macro similar to mine and it appears that it is using `from_str_radix` everywhere in its docs instead of the macro it has. Am I just going to have to do that?
&gt; That's the default match bindings that stabilize tomorrow. Before we stabilize `default_match_bindings`, can we talk about this? https://github.com/rust-lang/rust/issues/50008 Basically, it should be allowed to take all tuple args by implicit `ref` but move out certain constituents instead, by using `&amp;foo`.
Yeah honestly default\_match\_bindings seem a bit rushed to me as well. But well, Rust 2018 is around the corner, stuff needs to stabilize fast now I guess :\(
Nice! A pronunciation dictionary is a rad tool to have access too. I think I used the CMU one to make this terrible and now abandoned haiku bot: https://twitter.com/orpheus_orifice
That is a good point. What honestly happened is that I misread the question and thought OP was asking for "alternatives". I wouldn't call it an anti-pattern either as I use it myself. :p
Sorry for comment without reading content, but to quote a blogger named Hillel: &gt; I‚Äôd personally put much more faith in the Cleanroom process than any language when it comes to correctness.
Nice, I was toying around with CMUdict once, trying to use it to generate rhyming lyrics with consistent syllables in combination with n-gram markov chains trained on pop lyrics scraped from genius.com..
That seems like an idea worth revisiting.
I think I should make this concrete with an example. Take two components A and B. A responds to an external event by changing several elements of its state. The first thing it changes causes a notification to be fired off to B. In response to that, B changes some element of its state which gets notified back to A. If notification calls are being run immediately, then now A is in a nested event handler. A responds to B's change of state and returns. B's handler also returns. Now we're back in A's original event handler, and it continues fixing up its state, responding to the original event, but now it's overwriting changes done by the nested handler, and everything gets into a mess. This is only a simple example -- it can get a lot more complicated and harder to debug with more components. Allowing nested handlers breaks the ability of a coder to reason locally about code. For actors, it also breaks the actor contract. I've been tripped up by this many times, e.g. SWT GUI programming in Java, or layered device driver state machines. So having nested handlers in any form seems like a bad idea to me. Combined with something like actor guarantees, maybe you could get away with it, but still it may be useful to have a testing mode which randomly defers certain calls to shake out any bugs that depend on the order that events are executed in different actors. (Which shouldn't matter for correctly-coded actors, but you never know.)
I really want aio \+ iocp.
Novice here, with two comments on the example of `blocking`: 1. It says "... This example is a little silly ..." That's fine, it's just an example, but, it could be less noisy and thus more instructive to just use `std::thread::sleep` for the blocking operation. 2. This comment confuses me: &gt; "Because `blocking` returns `Poll`, it is intended to be used from the context of a `Future` implementation. Since we don't have a complicated requirement, we can use `poll_fn` in this case. Would it be possible to see the typical use case instead, from the context of a `Future` implementation?
Very nice. I'm always glad to see more gba stuff. I was porting some of the TONC examples to rust. https://github.com/tbelaire/rusty-TONC Feel free to borrow anything useful, like the tri state buttons. How do your image macros work?
The image macros read the image into an rgb8 representation and approximates it with the 16 bit gba format, while keeping track of a set of colors that is the pallette. Then the images are stored as i think a 1D representation using 8bpp or 16bpp. This explanation probably sucks as im pretty tired, apologies 
It has been set to be stabilized for ~5 weeks. I'm not 100% sure if this means it's stabilized now or in 6 weeks, though. RE: 50008 though: I think this can safely be fixed backwards compatibly after it's stabilized.
All your threads executing at the same time is normal, especially if you have architected your code to avoid locks. 4 cores is common nowadays.
 fn main() { println("#!/bin/echo Hello, Rust"); }
Or just const int main[] = { -443987883, 440, 113408, -1922629632, 4149, 899584, 84869120, 15544, 266023168, 1818576901, 1461743468, 1684828783, -1017312735 };
Will I be able to pass tokio-fs' stdin and stdout to APIs that are not async?
I had the exact same error with tungstenite! It took me 30 minutes of intense frustration to understand what was going on.
It's a fun exercise, but not very accurate. He hand waves away that some people might argue that Rust is more complicated. But, at least in this case, it is. This example takes us from a Rust macro using println to a simple buffered puts in C, to an unbuffered write syscall in and, for the same input file. I haven't tried it myself, but would the Rust compiler be quicker when we simplified the actual Rust code similarly? Surely it wouldn't become as fast as this bare bones, single purpose compiler. But the comparison would at least be a bit more apples to apples üòâ
This is really helpful, thank you. It would not have occurred to me to use an actual iterator for the main loop. Aside from calls to actually process and send stuff, I don't see anything that looks like it would block the loop. Where is that happening? Or are we just letting this loop run as fast as possible?
Yesterday, I found your repo while searching for GBA projects on github and was blown away when coming across yours. Fantastic to see this announced and released as a library!
How did you deploy the C code? You [can use](https://medium.com/@paramaggarwal/converting-an-stm32f103-board-to-a-black-magic-probe-c013cf2cc38c) a Blue Pill board instead of a ST-Link, but you still need to bootstrap that somehow.
Oh totally, there's lots of cutting corners. For example, I jump straight to a C string instead of using Rust's &amp;str. It's meant to be tongue-firmly-in-cheek. That said, the macro itself shouldn't take much time to expand, as it's just calling into a format call, which is then passed to a print (I don't go into this in the blog post as it was already getting a bit long). The resulting assembly isn't all that different, though here it calls into the libstd print function rather than the C function: https://godbolt.org/g/eowUvW The assembly calls the same puts as the C, not sure what you mean about unbuffered syscall.
I'm having trouble understanding how this works. From [the `tokio::runtime` docs](https://docs.rs/tokio/0.1.6/tokio/runtime/index.html), I see "The thread pool ... is configured to start a worker thread for each CPU core available on the system." That sounded pretty good when it was for only CPU-bound work, but I don't understand how it fits in with `blocking`. In particular, what happens if I start a bunch of slow `blocking` calls on an 4-core system? Does the system lose concurrency with each one, and once I have 4 going, completely stall until one completes? or does `blocking` cause the thread pool to grow? if it grows, does it shrink later?
&gt; On Linux, AIO is mostly useless AFAIK (although there have been plans to improve it for quite some time now), fwiw, I hear there's a `preadv2(..., RWF_NOWAIT)` which is guaranteed not to block (and thus only does anything if the request can be satisfied from cache). If it fails, you're supposed to retry with a blocking request. I wonder if this would be worth using in tokio-fs, or if `blocking` is cheap enough that it's not helpful.
I wanted RlsRequest to be exactly the same as Request, but carrying the bound around. The method is later copied to ExtendedForSerialization and send to the rls.
If I have a reference to a thread local value and my future is moved without my knowledge what happens to that reference? What will stop me from doing that?
`RefCell` is in `src/libcore/cells.rs`. I'm on mobile, so no direct link, but you can browse rust's github repo. Safety is ensured by runtime checks ‚Äì the RefCell maintains a counter of all borrows. Whenever one tries to get at the inner while the counter is non-zero, it will panic.
Yes, for mutable vs immutable borrows. That's not the question \- somehow, the borrow checker can tell at compile\-time whether there's a loose `Ref` somewhere, and won't let the origina`l RefCe`ll be moved / dropped, and I have no idea how.
I don't think you can do deprecations like that with rust editions. You need to be able to combine all editions of rust, and what if your dependency uses the Error trait?
Is there a quickstart for developing a gba app with rust? This standard library is a cool resource, but without knowing how to actually compile for the platform I am a little out of my depth.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://doc.rust-lang.org/1.24.1/std/cell/struct.Ref.html) - Previous text "Ref" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
If I recall correctly, the borrow checker has some special handling for `UnsafeCell` which is the base abstraction for all `Cell` types.
Looking at https://doc.rust-lang.org/1.24.1/src/core/cell.rs.html#722-730, I see `Ref&lt;'b&gt;` which is returned by a call to borrow contains a `BorrowRef&lt;'b&gt;` which contains a `&amp;'b Cell&lt;T&gt;` reference to the internal cell of the `RefCell`. (And similarly for the mut variant) I believe this provides the borrow checker with enough to make a static guarantee. &gt; Internally, they keep a raw pointer to their parent RefCell Where in the code do you see this?
Thanks, I was silly and thought an `unsafe` dereference meant a raw pointer. 
Why not do `.map_err(Box::from)` ?
That‚Äôs a great release, thanks! I'm curious, should this blocking API style be exposed publicly and be used for CPU intensive tasks like a prime sieve, or would that be an abuse of this API because unlike disk io, the CPU would get saturated?
Hmm. I used an FTDI adapter and the serial option in the arduino IDE.
No, both parallel-running systems and time-sliced systems can be concurrent. Something being parallel doesn't make it non-concurrent. Then again, neither of those are supersets of each other: A threaded server using OS threads - parallel AND concurrent An async server using an single-threaded event loop - concurrent BUT NOT parallel A single threaded batch computation - NOT paraller NOR concurrent A batch computation running on Rayon threadpool - parallel but hardly concurrent A single threaded batch computation using SIMD - parallel but definitely not concurrent
&gt; For example, I jump straight to a C string instead of using Rust's &amp;str. It's meant to be tongue-firmly-in-cheek. I definitely like it, so no comment there ;-) &gt; That said, the macro itself shouldn't take much time to expand, as it's just calling into a format call, which is then passed to a print True, but that is hitting the expansion logic, generating more statements that all have to be type checked etc. So it might not be the most expensive thing to do, but it's taxes a lot more of compiler machinery than a simply outputting a plain string or blob. &gt; The assembly calls the same puts as the C, not sure what you mean about unbuffered syscall. Sorry, I hadn't inspected the assembler too carefulle and assumed it was calling write or invoking the syscall directly. Entirely my early morning brain taking shortcuts here. Now where is that coffee...
Because I'm new to Rust :)
Wait does that mean a German company can't pay a remote us employee in Euros, since its not USD?
He was asking because Python is basically the only language that would cause you to ask this question. :) In Python, threading.Thread *is* a completely new OS thread that is scheduled independently, but they're all fighting for the global interpreter lock, and only the thread holding the lock get to run Python code (although the others may run I/O). This is a *very* Python specific issue.
What the earlier comment left out was it was a choice between crypto or fiat for building that exchange and a lot of these work that way. You choose what you want to be paid in.
Haha ok. well I also know Ruby and I also know that Ruby also has a GIL that causes the same confusion.
You are assuming that they started using Rust in the last 7 months and were lazy (I'm basing this on when that particular scenario was added to the cookbook).
Yeah that's more what it is, just another reason to write more Rust.
Great question, to which I don't know the answer. :-] I certainly _hope_ so, though ‚Äì it will be a terrible shame if const generics end up good for little more than setting array bounds.
It's "destructure"!
That should work with Rust binaries, as far as I know.
I always wanted something similar, too. Like a way to unpack a tuple to an array and back. Or at least a way to iterate the tuple type. However, the latter is probably possible with a custom iterator implemented for the each possible tuple. Wait, but.. it's already done in a [tuple](https://docs.rs/tuple/0.3.8/tuple/trait.TupleElements.html) crate.
I remember when MMX (the first ever batch of SIMD instructions) wer released. The Fortran compiler was re-written and started using them frequently and by default within a year. It took about 8 years before the C compilers had the necessary intelligence to do the same. Oddly, the reason this happened was because Fortran was a slightly *higher-level* language: it had support for applying numeric operators (plus, minus, times, etc.) to arrays. Hence it was trivial to re-implement those operators with MMX. The C compiler by contrast, as the author points out, had to determine if iterative, mutable for loops were performing an operation equivalent to plus, minus, etc. array wide, without over-writing, with aliasing guarantees, and only if they could do that, then employ MMX. Which goes to show the fallacy of low-level being fast. Particuarly when the machine targetted by the low-level language is a 50-year old museum piece. Incidentally, the reason C uses null-terminated strings is because PDP-11 had hardware for those string types. Had they used a high-level String type like their contemporary Pascal did, they could have ensured fast buffer-overflow detection on subsequent hardware
When a blocking action finishes, does the event loop move back to the thread of the blocking action and move its current thread back in the pool? That is a judo move. I wonder how that plays with thread scheduler heuristics.
Multinational companies pay their employees in whatever the local currency is. 
Thanks for that - I was unaware of those functions. But my problem is less to do with functions themselves, and more to do with getting them to work through a trait.
if i i am interpreting the "official" version right: you also need to get the length, even the iterator version asks for a sized iterator.
Why is stdin/stdout not using PollEvented?
Deciding things by feature flags like that tends to infect your dependency graph. If we add another layer of dependencies, we'll face the same problem. That said, it will probably work. But the errors facing the user won't be very helpful. There are two additional approaches here that you might want to consider: The third party crate performs the [semver-trick](https://github.com/dtolnay/semver-trick) and you can happily interchange types from one version with another. You build a modular API that doesn't directly depend on a third party crate, instead it can be plugged in as an adapter through a separate impl that must be specified by the end user.
I think in your library you can specify external crate's version requirement as a range, like `some_crate = "&gt;= 1.0.0, &lt; 4.0.0"`. Then you wouldn't have to specify each valid version by hand.
if you are using something that requires your Future to be `Send`, you already have a problem. But, these are currently your choices: * Use the [current_thread Runtime mentioned at the bottom of the article](https://tokio.rs/blog/2018-05-tokio-fs/#current-thread-runtime). * Use [Task-local data](https://docs.rs/futures/0.2.0-beta/futures/task/struct.LocalKey.html), or [whatever ends up replacing it](https://github.com/rust-lang-nursery/net-wg/issues/7). * [Write a future](https://tokio.rs/docs/getting-started/futures/) where you can store any state you need. * Store the state in the context where the future is used (e.g. use a `Arc&lt;Mutex&lt;T&gt;&gt;` that you move around). What you choose to do depends on what you are using the thread-local to solve.
`Into::into` works, as does `ApiError::into`. The problem with `Error::into` is that `Error` is a trait, and I don't believe there are any `From`/`Into` impls on `Error` directly. Also, in this context, you're trying to convert your own concrete error to a `Box&lt;Error&gt;`, so you don't want to call `Error`'s `into` impl, but rather, `ApiError`'s `into` impl. That's why `ApiError::into` works. `Box::from`, or more specifically, `Box::&lt;Error&gt;::from`, works because there is an `impl&lt;E: Error&gt; From&lt;E&gt; for Box&lt;Error&gt;` which knows how to convert anything implementing the `Error` trait to a `Box&lt;Error&gt;`.
TIL
Seems like a fun and light exercise, but the real question is - can Rust as it is compile faster? I don't mean Go speed, just fast enough so people don't count it as a fault.
`UnsafeCell` has special handling for alias analysis. The borrowing mechanics work fine with the ordinary borrow checker.
Rust 1.26 will be released on May 10. I know how you feel, can't wait for auto-deref in pattern matching and ? in main. The milestone for the release is here: https://github.com/rust-lang/rust/milestone/48 Or you meant /r/playrust, but I still don't understand what you mean by the "3 may update". If you meant the EU Facepunch 3 server, it's down for 6 days, they are probably working on it right now. The last community update was on May 1, it already happened: https://rust.facepunch.com/blog/community-update-182/. It may take a while to update the servers, just be patient.
Courious, is there any crate to do this? Afaik you can't know which core a thread is going to run on.
The hwloc crate [0]. You might want to check out this blogpost as an introduction: http://nitschinger.at/Binding-Threads-And-Processes-to-CPUs-in-Rust/ [0] https://crates.io/crates/hwloc
I think a macro will be worse in this case, because `.map_err(Box::from)` can just be appended to stuff and a macro will need to be wrapped around it.
No problem here.
That would be neat!
As best I can tell, Tokio is still on Futures 0.1.2
Well, the first thing that jumps out is that the function is called "divide_each", but you're trying to import it as "init_ffi" in Python. The second thing is that you're returning nested arrays from Rust, but the Python interface expects a flat array. Also, you're using unsigned integers in Rust, but signed integers in Python. Finally, you're trying to return a Rust type (`Vec`) as a C type, which is straight up *never* going to work. I'd point you to the [FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/), except that uses `ctypes` not `ffi`, and doesn't cover returning nested arrays. Fundamentally, the solution is to work out how to do it with C instead of Rust, then just do that in Rust instead of in C. When you use C FFI, you're not talking Rust, you're talking C *from both ends*. For example, FFI (according to a cursory reading of the docs) expects returned arrays and pointers to own the memory they point to, which means you **definitely** cannot use `Vec` on the Rust side. You'd have to manually allocate with `malloc` and use unsafe code to construct the array... but at that point, you're really just having to learn C. That's the thing about FFI: it doesn't *allow* you to not know what's going on, and it's not conducive to short-cuts.
Are you referring to https://docs.rs/rand/0.4.2/rand/seq/fn.sample_iter.html ? The size is the amount of items to return, not the amount passed in.
Absolutely!
Another issue is that the parent process can pass in any kind of file as stdin/stdout. If you pipe a file in a stdin via a shell it will pass that file in directly. Although you could detect if it's a pty/pipe/file or socket and change implementation accordingly.
If that format is Valve's KV{1,2,3}, correctly parsing it will be a pain - it's really random. Here's a few example parsers for that format: https://github.com/Perryvw/PHPValveKV/blob/master/src/valveKV.php https://github.com/SteamDatabase/ValveKeyValue
Thank you for the response! Would you happen to know any alternatives to CFFI that might support Rust functionality beyond emulating C (that doesn't have to be compatible with Python)? I'd rather stay away from the potential "undefined bugfest" known as C, if I can somehow avoid it. My experiences with `malloc` have been... less than desirable. 
This only works with futures that implement `Send`, this means that you should not be using thread locals. The future task system provides the concept of task locals which are similar but move with the task across threads.
The `blocking` API is exposed and can be used by other libs :) https://docs.rs/tokio-threadpool/0.1.3/tokio_threadpool/fn.blocking.html
The event loop stays on the new thread it was transferred to. The old thread gets added back to a pool of threads that the scheduler draws from when it needs to transfer the event loop. So, the runtime might have a pool of 100 threads but only 4 event loops. Those extra threads are there to accept the event loop hand off.
Yes, you are correct. The docs probably need to be updated to include all the new details.
Wrong sub. You want /r/playrust.
Is the performance actually significantly improved? It's not like the file system is that fast anyway, - I'd be interested to know more about the performance rational.
Last time I tried stdin/stdout don't work in kqueue.
It's working now. Weird
We'll be linking to the cookbook more prominently in the coming months.
Well, that's a shame. :p Guess I'll just implement the whole program in Rust and see how that goes, then!
It's still possible for people to write code which hides the C from you. I use `rust-cpython` to glue a PyQt frontend onto a Rust backend and it abstracts away a lot of Python&lt;-&gt;C&lt;-&gt;Rust type conversion. Beyond that, someone else [recently posted](https://www.reddit.com/r/rust/comments/8fq3dv/serde_python_cpython_helper_library/) their effort to make it easy to move more complex stuff back and forth. If requiring nightly Rust is OK with you, PyO3 is a rust-cpython fork which aims to provide a nicer abstraction.
There are two things to keep in mind. First, a lot of ‚Äúblocking‚Äù calls don‚Äôt actually block most of the time. Writes get queued in kernel memory and reads might be cached. The problem is the caller doesn‚Äôt know which calls will block and which calls will complete immediately Seconds, it is also about being able to provide an AsyncRead / AsyncWrite api. Without that, the caller always has to determine the point in their application that they will pass messages. Message passing isn‚Äôt free and it adds queuing (usually bidirectional). Anything with queuing adds complexity, especially when figuring out how to bound the queues to avoid infinite memory growth. 
Yes, I have actually started one [here](https://github.com/glaubitz/rust/tree/m68k-linux) I am waiting for LLVM upstream to add the m68k backend to be able to continue. Currently, one LLVM developer is developing the backend [out of tree](https://github.com/M680x0/M680x0-llvm). I am Debian‚Äôs m68k maintainer and I want to have Rust on Debian/m68k.
Experience has taught me that self-solved issues should be treated with the deepest of suspicion :D
Huh, I didn't realize that this format was used outside of these config files. Thanks for pointing me in the right direction - I've found plenty of other resources about VDF now! I might just end up porting an existing VDF library as a `serde` implementation now.
I recommend looking at `failure` crate. It boxes errors and holds stacktrace information. :)
Maybe I'm missing something, but it looks like all product code has to create and expose observers to UTs in order to avoid the arbitrary wait?
&gt; just never remove Why is that?
So this actually makes me wonder... how fast would a _true_ rust-&gt;C transpiler be? Would/could it be much faster end-to-end than using LLVM as the backend? I'm talking MIR -&gt; C. Basically adding a new backend for the rust compiler.
Really a great project - you said you would like help? Maybe we can get in touch as soon as I finished my master thesis about a custom Rust game engine - GBA Dev sounds really interesting :)
That would be cool! I'll have a bit more free time once my semester ends too so I can actually consistently work on this.
For those who are interested, here are a few resources/examples that use this library: [an skeleton of a game that may one day become an actual game](https://github.com/jkarns275/g) [a very simple etch-a-sketch game that uses the gba link cable to communicate with up to 3 peers](https://github.com/jkarns275/gba-mp)
wow, I almost never have this problem. Although if I encounter a bug I typically open a PR for it and just clone my repo down and hard-code the dependency to that using `[replace]` in `Cargo.toml`. This process has allowed me to develop pretty quickly even though the rust ecosystem is immature. The benefits of rust more than make up for the time commitment... and I just really like contributing to open source projects :)
Your username matches your comment quite well.
I've always been curious about m68k. Are there any machines capable of running for example Debian? 
I was always wondering if I could write hardware wallet for cryptocurrencies for GBA. Seems like it is relatively cheap and powerfull platform for such a thing.
Yes, generally, it is considered idiomatic in Rust to use the type system as much as possible to make invalid states unrepresentable. That way you don't have to trust your future self to not make mistakes (and as a result, bugs and exploits in your code), because you have made many of them impossible to make in the first place!
I believe this is interesting for Rust because we often see arguments in favor of generics for performance reasons. And while that is often a useful change to make, it can easily be taken too far- sometimes avoiding generics, even by replacing them with trait objects, can be smaller and even faster on the whole.
Huh, I feel like the compiler should at least complain about that, if not require it to be in an unsafe block, since as I understand the resulting program is just running arbitrary bytes interpreted as code. Something along the lines of any public global that uses `#[no_mangle]` to be the same name as `main` or other important assembly symbols (idk if there are other important ones to consider).
It should, but currently these are [open issues](https://github.com/rust-lang/rust/issues/47685). You can do a lot of ~~funny~~ terrible things with no_mangle by redefining stuff like LLVM intrinsics as well.
Pretty easy! This is the kind of case that `blocking` was added for. Maybe you could investigate adding mmap type abstractions directly to `tokio-fs`? http://gitter.im/tokio-rs/dev if you want to talk more about that :)
That is where the "non-blocking" part comes in. When you start the runtime, you specify a max number of concurrent `blocking` threads. When that limit is hit, `blocking` returns `NotReady`. Once some calls to `blocking` complete and there is availability, then the task is notified and it tries to call `blocking` again (and succeeds).
As mentioned, Tokio only supports futures 0.1. However, you can use the futures compat shim written by /u/seanmonstar https://github.com/seanmonstar/futures-compat
There are ways to do this, but why not just use the blocking `std` version in that case?
Writing a shell for hashicorp vault https://github.com/abhijat/mosler I tried to support windows, linux and Mac OS x since I have to use all three in a typical work day. At this time only three commands work but now I have a decent mental model of how to make the project work and it's just the work of implementing individual commands right now. Got the error structure a bit cleaned up yesterday. I've found this project a good way to get used to rust.
Thanks for the opinions, I think I will continue to use `Ok(x?)` at the end of functions or if early return is desired, and `map_err` otherwise.
I got round to [writing about a little utility](https://www.jamestease.co.uk/blether/introducing-rust-to-our-development-workflow) I created at work, think it's the first bit of Rust there. Eventually I'll persuade them to rewrite everything in Rust :)
Worth reading just for learning about [Bloaty McBloatface](https://github.com/google/bloaty).
To format a block of code, add a blank line, then indent each line of the code block by four spaces: Text: line 1 line 2 shows up as: Text: line 1 line 2
There is also an alternative written in Rust :) https://github.com/rustwasm/twiggy Right now it only supports wasm tho.
I'd like to use termion's [alternate screen functionality](https://github.com/ticki/termion/blob/master/examples/alternate_screen.rs), which wraps stdout. Termion assumes that it can write to stdout in a blocking fashion for setup and teardown, but later interactions with the terminal are just calls to `write!`.
It sounded like suggesting to wrap the `data.as_ref()` call internally in hyper, in case that call blocks loading from mmap. However, I think that would hurt the performance of any that didn't need to block, since it'd require the atomic operations in the threadpool regardless.
I was also inspired by reading this post, `faster` abstracts away most of the SIMD boilerplate, but you still have to bother around the edges. The SPMD model seems ideal for writing this kind of code. I think it should be possible to make a procedural macro which takes an SPMD kernel and outputs SIMD intrinsic code. Something like this: #![feature(proc_macro, stdsimd)] extern crate sprnd_macros; use sprnd_macros::*; extern crate sprnd; // Scalar arguments should be annotated with `#[uniform]` #[kernel] fn simple(input: f32) -&gt; f32 { if input &lt; 3.0 { input * input } else { input.sqrt() } } fn main() { let input = [0f32, 1, 2, 3, 4, 5, 6, 7]; let mut output = [0f32; 7]; // &amp;slice =&gt; arguments of kernel // &amp;mut slice =&gt; return values of kernel // scalar arguments can be captured by the closure dispatch!(&amp;input, &amp;mut output, |i| simple(i)); } // The above gets translated into something like this, but with worse variable names: fn simple(input: &amp;[f32], output: &amp;mut [f32]) { assert!(input.len() &lt;= output.len()); #[cfg(any(target_arch = "x86", target_arch = "x86_64"))] { if is_x86_feature_detected!("avx2") { return unsafe { simple_avx2(input.as_ptr(), output.as_mut_ptr(), input.len()) }; } unsafe fn simple_avx2(input: *const f32, output: *mut f32, count: usize) { #[cfg(target_arch = "x86")] use std::arch::x86::*; #[cfg(target_arch = "x86_64")] use std::arch::x86_64::*; let mut i = 0; while i &lt; count { // This should actually use an execution mask let inp = input.offset(i as isize); let outp = output.offset(i as isize); let inv = _mm256_loadu_ps(inp); let constv = _mm256_load_ps([3.0f32; 8].as_ptr()); let gev = _mm256_castps_si256(_mm256_cmp_ps(inv, constv, _CMP_GE_OS)); let ltv = _mm256_andnot_si256(gev, _mm256_set1_epi64x(-1)); let sqrtv = _mm256_sqrt_ps(inv); _mm256_maskstore_ps(outp, gev, sqrtv); let sqrv = _mm256_mul_ps(inv, inv); _mm256_maskstore_ps(outp, ltv, sqrv); i += 8; } } } // scalar fallback for i in 0..input.len() { let in1 = input[i]; let mut out1 = &amp;mut output[i]; *out1 = if in1 &lt; 3.0 { in1 * in1 } else { in1.sqrt() } } } fn main() { let input: [f32; 8] = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]; let mut output = [0f32; 8]; simple(&amp;input, &amp;mut output); } I've started working on that idea a bit. `ispc` is only 40,000 lines, how hard can it be? ;)
I mean, macro code doing the same in C would be "bloated" too. "generic" code needs to handle all cases, while crafting a single data-structure for a single purpose and a single data-type does not. Even something as trivial as a `Vec` can be simplified if you know that it can grow infinitely without reallocating.
If this is in a context where the compiler knows that `self` is of type `Foo`, then it just generates a call to `Foo`'s implementation of `Bar::bar`. Otherwise, if the type is only known at runtime, then `&amp;self` is a "fat pointer" indicating a table of function pointers where `&lt;Foo as Bar&gt;::bar` can be looked up at runtime. You can read about how that works [in the old book](https://doc.rust-lang.org/book/first-edition/trait-objects.html). 
&gt; I think it should be possible to make a procedural macro which takes an SPMD kernel and outputs SIMD intrinsic code. Something like this: With `std::simd` you can already do most of that. // Scalar arguments should be annotated with `#[uniform]` #[kernel] fn simple(input: f32) -&gt; f32 { if input &lt; 3.0 { input * input } else { input.sqrt() } } becomes // Vector implementation using `std::simd`. fn simple(input: f32x4) -&gt; f32x4 { (input &lt; f32x4::splat(3.0)).select(input * input, input.sqrt()) { }
Interesting! Thank you for telling me; I'll have a look at these ASAP. :)
Will take a look tomorrow; thank you!
Sure, I use CPython the most even if I do dabble with PyPy from time to time. 
I still don‚Äôt understand why helpful bots are downvoted.
I‚Äôm actually surprised that the author did not mention any difficulties or annoyances implementing containers. As you mention, you could implement a `NoExpandVec&lt;T&gt;` in C++ or Rust, but in C you would either have to implement it using hacky macros or make a copy for every `T` that you want to use it with. I‚Äôve been working on a C project for the last year and, without a doubt, lack of generics is my biggest complaint. I wonder if it would be possible for the author to rewrite the C codebase in C++ again but to retain the minimized binary size!
Very nice, but you might want to rename this as it conflicts with Tesla's self driving feature... (not really re: renaming... just a poor attempt at a joke)
There is also [cargo\-bloat](https://github.com/RazrFalcon/cargo-bloat), although it only works for Rust functions and doesn't do the diff thing. It is pretty cool \(and was somewhat insightful for me\) to be able to easily see the per\-crate bloatedness of my binaries though :\)
&gt;You'd have to manually allocate with malloc and use unsafe code to construct the array Couldn't you do: let v = vec![.....]; let s = v.into_boxed_slice(); let raw_array_ptr = v.into_raw(); mem::forget(s); To just have a raw pointer to owned memory? As long as the pointer gets passed back to rust land eventually to regain ownership it should be fine.
I agree, that's kind of what I was getting at. Sometimes writing the simplest possible, non-reusable thing leads to a better result.
&gt; I‚Äôve been working on a C project for the last year and, without a doubt, lack of generics is my biggest complaint. I've wondered whether it would be worth building a C/C++/Rust-level language that has polymorphic *types* but doesn't do any monomorphization. Something targeted at giving better types to the kinds of patterns you see in e.g. the Linux kernel- intrusive linked lists, function pointers taking void*, data structures that handle different sizes without code duplication in the binary, etc.
Yea, I started this project because I wanted to use it to write a rhyming bot. But then I got distracted and ended up taking forever to finish this, to the point where I don't even remember exactly what bot I wanted to write!
thank you :-) I will try it. What keywords do I need to enter to find more about the ? operator? The thing is that I have a loop and I don't want "early returns" but "early continue's". :)
Tried this, but cargo seems to just get the newest version that fits the range (for example "&gt;= 0.7 , &lt;= 0.9" would seem to lead 0.9 being compiled), and if another crate depends on different version, another copy of the dependency is compiled, even if the version number is within the range that the other crate specified (say 0.8). It would be neat if there was a way to tell Cargo that certain (transitive) dependencies should match. Or maybe it would lead to really messy Cargo.toml files.
&gt; in C you would either have to implement it using hacky macros or make a copy for every `T` that you want to use it with ‚Ä¶or store `void *` in it, which is the approach I've usually seen taken.
I do, often. I was just *stupid*. :P
Wait what?!
Yay, more Rust homebrew on game consoles! I've been contributing to a similar project for the 3DS and it's cool to see more stuff like that being done.
Not really though: all you need for a solid Vec implementation in C are 4 members: length, capacity, item_size and a void* to the alloced memory. Basically exactly as in other langauges, except those can omit the item_size member thanks to generics. Sorry for shotty formatting, am on phone.
impl trait is on stable next week.
Very good point! I've actually never used this variant, I really should try using it sometime though!
&gt; early continue https://doc.rust-lang.org/rust-by-example/flow_control/loop/nested.html
Yeah, now that you mention it, I can see version-specifying features leading to trees of similar features in many crates. Semver trick is something I feel I can't justify with only my personal need - I don't even know if the idea for my crate is worth it - but yeah, it seems to be a cleaner way to handle this kind of situation. The modular API suggestion made me think that maybe, just maybe I could make this thing work by making the user of the crate specify some kind of helper type that takes a bunch of generic parameters, and somehow derive what I need from there. (For most types in the third party crate I don't actually care at all about their fields or functions, just that I can wrap them with my specific wrapper types.) Back to the drawing board!
What are some use-cases for establishing auth with GitHub on the CLI?
Is there an error message?
These two goals are at odds. If you want to avoid monomorphization then you likely need indirection for elements of collections, at least for anything not pointer-sized. But having to put everything separately on the heap goes against C/C++/Rust-level. I guess you could look/pass offsets dynamically? Probably depends on access patterns on how badly that would wreck performance, though.
Ohh, I really like that question! Soo, I wanted to use this GitHub bot that automatically comments on issues when a new release has been made. Like, I maintain enough modules that going back on all issues to mention that their issues have been fixed by a new release is a bit of a pain. But it turned out just creating a git tag isn't enough to create a release. You actually have to talk to the GitHub API to do that. So I needed to build a tool that can convert a tag to a release on GitHub. The first step to doing so is to create a single-application token that's just for local use. And that's what this crate does. It allows you to create GitHub tokens quickly for local use, and once it's created once you never have to worry about them again! Hope that make sense :D
&gt;I also did similar tests on Windows and got similar results. A good way to account for startup time overhead would be to measure `rustc -vV`: that loads LLVM, but does nothing else. That is certainly significant on Linux, but I haven't measured other platforms. &gt;Makes me wonder if we could fix it. We sort-of fixed it in https://github.com/rust-lang/cargo/pull/5359: Cargo now caches compiler information, so only the first build will pay the cost of the two extra `rustc` invocations. &gt;Maybe it should invoke rustc as a library? I guess that would be faster (if we retain the parallelism we get today by executing several rustc processes), but the perspective of linking in `rustc` into `cargo` sounds outright horrifying to me :-) Currently a single Cargo binary can work with different compilers and compiler wrappers, such as sccahe, and losing that would be sad. But even more important is that separate processes enforce strong isolation and limited interfaces, and that makes development so much easier! Today, Cargo is built with a stable compiler, and it is so much easier to work on than other tools :) 
Twiggy is designed such that it should support arbitrary binary formats, though, so if anyone is interested in getting their feet wet... :) https://github.com/rustwasm/twiggy/blob/master/CONTRIBUTING.md
Makes sense! I think including something like that in the README.md would help those who come across it understand the benefit. :)
&gt; I‚Äôve been working on a C project for the last year and, without a doubt, lack of generics is my biggest complaint. Actually, newer C standards do have `_Generic` (i.e. statically overloaded) functions. I believe that plus some pre-processor hacking gets you quite close to "true" generics, at least for very simple cases/
Is `sqrt` implemented for `f32x4`? Or, more generally, how complete are the portable vectors expected to become? I can't find anything mentioned in LLVM docs. It would be nice to only need one "backend" and to ignore feature detection and fallback code. Re: head/tail/alignment I was planning on just using mask{load,store,mov} to deal with this. Apparently [that might not be enough](https://software.intel.com/en-us/forums/intel-isa-extensions/topic/537028) due to racing out of bounds memory from non-temporal stores or somesuch. Need to read deeper about this.
&gt; And while that is often a useful change to make, it can easily be taken too far- sometimes avoiding generics, even by replacing them with trait objects, can be smaller and even faster on the whole. I believe the real solution is to carefully "outline" the parts of the generic code that are not in fact type-dependent, so that type-specific generic instantiations can share a single instance of that code. Sometimes this amounts to avoiding generics altogether, but this is not the case in general; on the contrary, performance gains from monomorphization can be quite real. It would sure be nice if LLVM could help w/ this outlining task, though...
I would probably just forbid the use of type variables in positions that would require monomorphization. So they would primarily be a replacement for `void*`, with a way to opt-in to passing offsets around dynamically for other use cases. I'm not sure you would need to leave out traits. The Linux kernel does use tables of function pointers occasionally- the key is that they only use them where the dynamic version makes sense. Given that the point of such a language would be to avoid monomorphization bloat, this feels like a reasonable position to take. Of course, you could also just leave out traits as a language feature and use generic structs of function pointers directly. The visibility of the cost would be on the same level as C that way. It would also drastically simplify the type system, which is probably also a good thing in this space.
Isn't that what the Qt collections \(like `Qlist` do\)?
no idea except I've used \`replace\` and it's worked for me.
No, you need an `alignment_size` too.
That has costs of its own, though- either more function call overhead, or less helpful stack traces, etc. The best code is often simply not generic at all- at which point monomorphization simply isn't necessary because you're not losing any performance anyway.
[wasm-bindgen](https://github.com/rustwasm/wasm-bindgen) will make your life so much easier. Give it the `--no-modules` flag and it will generate code to do the asynchronous instantiation (so you don't need the wasm2es6js hack for Chrome) and adds the exported functions on an object on `window`, rather than generating an ES6 module. If you don't want to use babel/webpack, you won't be able to use async/await.
On that note, I believe PGO does do this sort of thing quite a bit. (That is, decide *against* inlining when the function in question is cold, and decide to do more outlining when a piece of a function is cold.)
:O