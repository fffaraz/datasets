I don't know why but it looks so much like Berlin (Germany) ... It's probably just me and this is how every public toilet with tiles looks like. Anyway, this proves rust world domination :P
The one thing that pains me the most is the error messages with a super long type in them. Like, how am I supposed to even begin to work with adding some explicit type that is a mile long to my code? I can barely even read the message.
I bet you put it there yourself ;)
I used it for some application tests and I must say I love libs which are good to get a quickstart and powerful enough with a thin layer beneath (sweet tough spot!). For me it works good right now, will see if there are bugs. I see one issue on GitHub about adding tests. I would like to contribute to this library and learn more Rust and AMPQ along the way. How can I start on this task?
&gt; free parallelism and concurrency So Erlang?
shout out to /u/varkor for their herculean effort on const generics which will make us all much much safer.
Yes, you certainly can! The entire project is very modular. The io part is separated into its own [root-io](https://github.com/cbourjau/alice-rs/tree/master/root-io) crate. It should have you covered for most of the standard types and also provides some tools to get you started if you'd need to read some new types (see the [root-ls](https://crates.io/crates/root-ls) binary) &amp;#x200B; Currently, there is some boilerplate needed to get a nice API for iterating over events in the analysis. See this file which essentially creates a struct of iterators (one for each TBranch): [https://github.com/cbourjau/alice-rs/blob/master/malice/src/dataset\_rust.rs](https://github.com/cbourjau/alice-rs/blob/master/malice/src/dataset_rust.rs) . It looks ugly, but actually, its not complicated (The ALICE ESD trees are certainly a bit of a mess). I think this part could be automated to a very large extend with macros! Depending on how serious you are about the analysis, you might want to double check that you wired up your TTree correctly. You probably want to do that by for example computing the sum over a branch in the TBrowser and in your Rust code. If you want to go the extra 100 miles, you can take a look at the [alice-sys](https://github.com/cbourjau/alice-sys) crate on how you can link ROOT with your Rust code to do that comparison in proper tests. What kind of analysis were you guys thinking about?
How is this different to this implementation? [https://github.com/gnzlbg/mimallocator](https://github.com/gnzlbg/mimallocator) ?
It probably isn't.
There's another sticker that looks like it has german writing on it so you might not be far off.
This is a loaded question, for several reasons. The first one being that I don't think this is production-quality code. I want to say "The Rust one" of course but I have to take in account that I would likely give the (at least notionally improved) first version to someone else who would be tasked with maintaining it. So, this raises another question: which language would make them the least angry? :)
It even has the word "Berlina" on it.
3... 2... 1... merge!
I just finished a big UI refactor in [A/B Street](https://github.com/dabreegster/abstreet) to use a stack of states. So now the player could be nested in something like "splash screen &gt; mission edit mode &gt; edit scenario &gt; seed parked cars", escape a few levels out, and wind up somewhere on that stack. This was very ad-hoc before. Next up are some visual UI tweaks (separators between groups of related commands in the gigantic modal menus) and continuing to manually resolve problems with the geometry of certain roads and intersections.
I wonder how much work it will be to do a true Rust port of mimalloc, i.e. rewrite it fully in Rust from scratch. It may be interesting to compare performance and resulting code may be useful in future. Do you know if anyone wants to try it?
A bit of an anecdote, I hope it's the exception: A company adopted Go almost overnight and some teams found themselves now with Go projects to write without anyone in the team knowing Go. They had to learn on the job while still delivering their features at there previous fast pace. It was a bumpy ride. You might say it was a management mistake, that it shouldn't have happened. The fast pace as one would expect didn't turn out that fast in the long term, but certainly felt it in the short term. There was a bit of frustration learning Go in a hurry, but ultimately Go stuck. I don't think Rust would have, I think the kickback would have been severe enough that they would have gone back to their previous mix of dynamic languages. (They often run into certain classes of bugs in the Go codebases that wouldn't have occurred in Rust, but the time spent fixing these I would guess is less than would have been lost in the extra ramp up time needed with Rust.)
Lol, made me think of a the time I found a Xamarin sticker on the underside of a fiber bar toilet seat.
&gt;Can you talk a little bit more of the advantages of RUST over C++? Forgot to answer that part. Oh boy, where to start... The possible performance is obviously equal, so it really boils down to the ergonomics: 1. Compile time checks and Rust's preference for "local-reasoning" It is invaluable to have a compiler to tell you straight away that you are doing something silly. Especially after not having looked at the code for a few month you can just jump right back in: You want to implement a given feature. You open some related file. You look at nothing but the `struct`s and a few function signatures and you can pretty much start to prototype straight away. Hardly any need to look at any other files or to read the actual implementation of some existing functions. If you end up doing something silly, the compiler will tell you straight way. Maybe one can get the same feeling in a very strictly managed and very well designed C++ project, but I never had that feeling using ALICE's software stack with its very deep inheritance. &amp;#x200B; 2. Prototyping your API This may be surprising, but this is really a point where Rust shines! I usually start by writing out the structs I think I'll need. Maybe not even writing out the members. Then I start mocking up function signatures and instead of writing any actual logic I just put `unimplemented!()` everywhere to get everything to compile. By the time I start writing the first line of "actual" code I'm usually already several design iterations in. Its like documentation-driven-development with compile time checks! 3. Sum types (`enum`) I don't think that I will ever start a large project in a language without them again. One obvious use case is of course `Option`/`Result` and thus the absence of any null pointer issues. But even in more custom situations this is just invaluable. See for example this `enum` which virtually makes it impossible to ever assume that we already read a certain object (`TBasket`) from disk when we didn't: enum Container { /// Decompressed content of a `TBasket` InMemory(Vec&lt;u8&gt;), /// Filename, Position, and len of a `TBasket` on disk OnDisk(PathBuf, SeekFrom, usize), } 4. Really easy concurrency &amp;#x200B; On first sight, this might seem like a mute point: On the grid one could just spawn more processes. Why do multi-threading? In ALICE many analyses are computationally fairly cheap and thus often 50% of the computing time is actually spend waiting for IO (read and decompress). Using Rust it becomes trivial to do the IO in one thread, and message-pass the finished events to another without ever worrying that some member relies on some pointer somewhere. The result is a 2x speedup without any additional memory usage. Of course one can also use several analysis threads fed by a single IO thread. Last but not least there is also the beautiful documentation, the great dependency management with cargo, Windows support, and a very active and helpful community (To be fair: I don't know how C++ fairs wrt the last point). And on a last note: The integration of Rust into a C++ code base is actually much easier than one might think! [rust-bindgen](https://github.com/rust-lang/rust-bindgen) it the project to thank in this regard.
Note that I said "I don't want to", not "I'm not going to". My standard is perfectly consistent with preferring something that *may* have undefined behaviour over something that is *confirmed* to have it. &gt; So it's (relatively) ok to have soundness bugs as long as you know what and where it is and whether it applies to you? Of course, to do that you have to actually know(ie, confirm) what and where the problems are.. Nothing is perfect. It's greatly preferable to work with tooling where I feel it's within my means to make a reasonable effort to avoid triggering undefined behaviour. PyO3 has aliasing bugs which make UB pretty much inherent to using it for *anything* while those `I-unsound` bugs apply narrowly enough to be avoidable... often, simply by choosing what kinds of tasks I use Rust for. (eg. I can avoid "#35836: RwLock and Mutex on Window theoretically allows undefined behavior in safe code" just by not using Rust for Windows development and "#59220: format_args! with certain arguments segfaults at run-time on x86_64-unknown-linux-gnux32" is irrelevant to me because I have no plans to target x32 in the first place. In fact, last I heard, they were planning to deprecate it since it never really gained much traction.) &gt; Your own argument rules out rust-cpython kid. Are you, like, all there? mentally speaking? You seem to have serious problems with basic reasoning. Please respect the rules for this subreddit. Ad hominem attacks are neither constructive (rule 2) nor in line with the code of conduct (rule 1).
Sounds like a lot of hard work for very little payoff. It also sounds like a lot of fun and something I'd like to do. :) u/alexlie has already begun a project: https://github.com/rusch95/mimallocator
Once you've worked your way through the book, I highly recommend [Learn Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/) as a way to of how to implement data structures in Rust, given the special considerations imposed by the borrow checker.) [Rust By Example](https://doc.rust-lang.org/stable/rust-by-example/) is another one people often point to.
&gt;I have tried a similar approach, but found it very limiting. Do you remember anything in particular to be harder using that approach? I've been quite pleased using a `Parser` trait, but I've never parsed very complicated grammars, so I'm not surprised I've never run into it.
Other than doing it as a learning experience or for research purposes, I see little point in doing a re-write.
They go hand in hand, a reference can't outlive it's origin and the object can't disappear while it's borrowed. That would result in a dangling reference and that's not allowed. Rust's references have strict rules that make them very powerful and allow for aggressive optimizations.
Yeah, splitting those up into threads probably would work (using [thread::spawn](https://doc.rust-lang.org/std/thread/fn.spawn.html). If they need to communicate they can use channels. For your side question, looking at the `notify` example, which is something like ``` loop { match rx.recv() { ... } } ``` Blocking on `Receiver::recv` like that yields to the OS until the channel has something, so it shouldn't use the CPU except when it gets a message - that is to say, it only is resumed when there's an fs notification and then it goes back to sleep.
At the very least it will make cross-compilation easier, plus it may provide some optimization opportunities for compiler.
Thank you for your reply, much appreciated!
Why can't rust infer the type of this expression? The variable n has the type BigUint n += One::one(); And then if I try to give a type annotation, it also fails, saying that this type ascription is experimental. n += One::one() : BigUint;
I have that exact same sticker on my laptop. It was given to me by a Servo core dev at my first Rust meetup in Brisbane.
True, but it requires more effort than doing the said optimizations on the already existing source and/or making it cross-compile. I’m not trying to shut you down or anything. I’m just pointing out that it should always be the first choice to use the implementation of a software that is most likely to be maintained/fixed. And I can assure you that no open source development effort will ever beat the backing of Microsoft.
Since I'm not sure what One::one() is my best guess would be that you could probably add multiple different numeric types to a BigUint such as another BigUint or just a regular uint, so Rust needs you to specify which one for sure. What you would do in this situation is something like this (I'm guessing) n += One::one::&lt;BigUint&gt;() hooray for the [turbofish](https://matematikaadit.github.io/posts/rust-turbofish.html)
I had a quick look at the code, and it looks pretty nice to me: properly broken up into small functions. Good job, and good luck on your Rust journey! You could consider using a third-party crate to provide the vector type (nalgebra, maybe) rather than writing your own, but that's a minor thing: there's nothing wrong with re-inventing the wheel when you're still learning! A couple of very trivial things: you have often included an explicit type in variable declarations, when the compiler could have inferred it. It's generally considered good Rust style to omit the type unless it's needed for some reason - instead of: let a: f64 = calculation(); just write: let a = calculation(); Also, in the function `random_in_unit_sphere`, there's no need to declare the variable `p` outside of the loop. I would instead declare it **inside** the loop, where it's used. One final thing is that raytracing is almost never used in game engines - it's just too slow. I think there is now some high-end hardware that can do raytracing in real time, but it's the exception rather than the rule. If your goal is to create a game engine, you'll need to learn some other techniques, and how to use APIs like OpenGL, Vulkan, or Direct3D.
mimalloc-sys?
The arithmetic operators can be overloaded for types on the right-hand side, so it's not immediately clear to the compiler which implementation of `One::one()` to invoke. `BigUint` implements `AddAssign` (the trait defining the implementation of the `+=` operator) for all the primitive unsigned types (`u8, u16, u32, u64`) as well as `BigUint` and `&amp;BigUint`. To disambiguate, you can explicitly invoke the trait method on `BigUint`: n += BigUint::one(); However, this incurs an allocation so I would instead just do `n += 1u32;` (`u32` is the type that `BigUint` uses internally)
Why do we have to "beat" it? A pure-Rust allocator which heavily borrows mimalloc ideas and tailored for Rust needs is already a great result in my opinion. Even if it will be a bit less performant than the parent project or will support smaller list of targets.
Thank you, I'm still figuring out how traits and trait methods work. I didn't know that you could invoke the method from `BigUint` directly. &amp;#x200B; One you say about `u32` possibly being the most efficient is interesting, I have been giving number literals arbitrary types throghout my code. Do you think that performance might improve if I switch to `u32` or remove the `one(), zero()` values?
This form doesn't compile because the turbofish is in the wrong place; where you've placed it here means you're trying to specify a type parameter for the `fn one()` method but it has no type parameters so you get an error: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=459674a668663585182cdd5472f7a671 [This form](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0637166d32c94fd8d1449a01be0d823c) works but it's more verbose than `BigUint::one()` which is how you can invoke static trait methods for an implementing type.
I feel the exact same way. Rust and the tools made in it have made my daily workflow much better, even when coding in C++. Huge thank you from deep in my soul to everyone who devoted the time to make such a great language.
&gt; Do you think that performance might improve if I switch to u32 or remove the one(), zero() values? Perhaps? It's hard to say without seeing the code. In debug mode it most likely will but in release mode the optimizer may elide the allocations entirely and produce equivalent code to adding a `u32`. `u8` and `u16` work fine for adding to `BigUint` as well as they are basically widened to `u32` for free. On the other hand, `u64` touches a different, somewhat more complex code path. This is because `BigUint` is essentially a wrapper around `Vec&lt;u32&gt;` where overflows from the 0th element get added to the 1st element, etc. so when adding a `u64` it has to check if it needs to touch 1 or 2 elements.
Not so surprising for Berlin :P
Cool. I'm currently using `pyinstaller` for a small project of mine but I'll try this out.
That's another thing altogether. Writing a performant allocator in pure rust would feel quite satisfying as a project. So if you want to have fun, go ahead and do it man.
I couldn't help but laugh outloud at this
You can use a slice, which will require a lifetime constraint (since slices are not owned data, just borrowed). If you want the struct to own the array and don't know the size at compile time you need a vec. If you do know the size of the array at compile time, but want it to be generic over that size, you need to wait for const-generics to stabilize. They're on nightly now in some capacity but I haven't been keeping up with their support for this use case.
&gt; I feel it's within my means to make a reasonable effort to avoid triggering undefined behaviour. Do tell how you plan to avoid undefined behavior in rust-cpython when it could be anything and everything, as nobody, including you, has bothered to actually test, despite happily spouting FUD nonsense about it, apparently. &gt; it for anything while those I-unsound bugs apply narrowly enough to be avoidable... often, simply by choosing what kinds of tasks I use Rust for. And that somehow doesn't apply to PyO3.. why, exactly? The [aliasing issue](https://github.com/PyO3/pyo3/issues/342) is only possible on a single thread, and you can just.. not do it, the same way you can just not use `RwLock` or `Mutex` on windows. or not [add class objects to modules](https://github.com/PyO3/pyo3/issues/320) &gt; constructive Blind FUD isn't constructive either and yet here you are, so... &gt; My standard is perfectly consistent with preferring something that may have undefined behaviour over something that is confirmed to have it. Which goes back to not using rust, which is *confirmed* to have UB. Along with C/C++, your operating system, the internet, computers in general, but hey, it's your FUD standard. What you're claiming is your standard is not compatible with what you're arguing, but i can understand why someone as seriously mentally deficient as you wouldn't notice. Your so called "argument" is not consistent in any way, shape, or form. You say it's better if you can avoid UB or it's narrow enough in scope to not apply, but then explicitly prefer stuff where thats impossible, by definition, *because you don't know where the UB is*, but at the same time awknoleding it likely has UB(as PyO3 is a fork of cpython), and you call that consistent? "Ad hominem" or **not**, it's not my fault you clearly demonstrate serious deficiency in reasoning. &gt; Note that I said "I don't want to", not "I'm not going to". Then, by your "arguments", you should be using PyO3, since it's a helluva lot easier to avoid UB when you know what and where it is. Or you could go and test your FUD nonsense until it stops being FUD. Back up the claim you explicitly tell us is complete unconfirmed bullshit. Looking at the graphs on both crates.io and github, PyO3 is far more actively used and maintained. The last version of `cpython` is from September 2018, and has few recent downloads. PyO3 is actively being developed and bugs being fixed and is being used in practice far more. If you want to go against everyone else and claim it's fundamentally broken and unusable, back it up Mr. FUD. If you want to use old, unmaintained software and claim it's better than the newer, actively developed fork, back it up. Extraordinary bullshit requires extraordinary evidence.
You mean something like https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f10b06a4e2330b4a21fec02851868154 ?
In Rust, every value needs to have a compile-time known size, so that they can have the necessary stack space reserved. The sizes of a `[u8; 3]` and a `[u8; 5]` are different, so they can't both be valid types for `values`. There are two ways around this: 1. Use `Vec&lt;u8&gt;` instead. That has a fixed amount of data stored as part of the struct, but that includes a pointer to where a varying amount of data can be stored. 2. Use `&amp;[u8]`. That's a reference to a varying amount of data that is stored somewhere else, in a `Vec&lt;u8&gt;`, `[u8; 5]`, or anything else like that. You can store that reference in your struct to give it a fixed size, but then you need to set up the lifetimes to make sure that the struct doesn't outlive the data that it's referring to.
It does feel like a minor miracle how well its pieces fit together.
It belongs in the bowl, the under the lid will do I guess.
I moved it into [https://github.com/rusch95/mimalloc-rs/](https://github.com/rusch95/mimalloc-rs/) as the linked one was my fork as I explored some ideas. I got the hello-world of calling Rust code from mimalloc working, so I'm working on porting a few functions over right now (going to try corrode and a few of the auto-converters) while my friend is adding more tests (which I want to upstream to mimallocator to be good code neighbor).
Haha runs fast too
I have experience with neither of these but I have used diesel which has worked well for me. Have you considered diesel? If you have and I doesn't meet your needs I'd love to hear why?
You can use the generic array crate to store an array that's generic over its size at compile time. If however you need an array that's growable you will need to use a Vec or some other heap allocated data structure. Link to crate: https://crates.io/crates/generic-array
For sure. Like I said I didn't know how One worked
I'm building this following along James Coglan's excellent book "Building Git". I'd appreciate any feedback/comments about the code.
Why would you want it to trickle down when you could directly help make possible for someone to spend more time on rust?
The "[Nomicon](https://doc.rust-lang.org/nomicon/README.html)" has a really great write-up of lifetimes (kind of like variable scopes) here: [https://doc.rust-lang.org/nomicon/lifetimes.html](https://doc.rust-lang.org/nomicon/lifetimes.html)
Thanks, I use Diesel when I'm using MySQL or SQLite, but Diesel doesn't support SQL Server...
Ah yes, my apologies. I didn't read your post closely enough. Thank you for your response.
For 5, the regex docs suggest it since constructing a regex is somewhat expensive.
I've been using my fork of tiberius for our [product](https://www.schoolbench.com.au/) as an integration component and haven't had much issues with it. It's not the primary database we're using, but whenever we need to talk to mssql systems we use it. [In my fork](https://github.com/cetra3/tiberius/tree/column_vals) I had to add a few data types, adjust the connection settings and allow column metadata to be gathered. The maintainer is not very active, I've had an outstanding [PR since last year](https://github.com/steffengy/tiberius/pull/85), so my adjustments just sits in my fork for now. One issue that just popped up was talking to SQL server 2008 doesn't appear to get past the handshake, but that is EOL next month, so not sure whether I will pursue this as an issue. ODBC I have had no experience with, but I think I will need to use it to integrate with DB2...
Have a look in the Rust book here: [https://doc.rust-lang.org/stable/book/ch10-03-lifetime-syntax.html#lifetime-elision](https://doc.rust-lang.org/stable/book/ch10-03-lifetime-syntax.html#lifetime-elision) For instance a function that takes a reference and returns a reference it is assumed the lifetimes are linked like this fn first_word(s: &amp;str) -&gt; &amp;str // Turns into fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;'a str Now there is a rule in rust around aliasing - you are not allowed to have two mutable references to the same thing. https://doc.rust-lang.org/nomicon/aliasing.html Your example code that you linked actually breaks this rule. That is only possible because you used unsafe.
I'm using ODBC - seems solid once you get it working
Understands lifetimes
It may be popular to hate on C++ here, but both C++ and Rust have reputations for being difficult languages to learn. Without data I'm not buying that it takes longer to "really" know C++ than Rust or vice versa, especially with such a nebulous bar. How would you measure such a thing anyway. That was my point, poorly articulated, I wasn't trying to imply I really "know" C++. At the end of the day you get some value out of the time you put into learning a language and you can use that skill again and again, it's up to the individual whether that value is worth the time. And you can spend a lot less than decades and come up far short of really "knowing" C++ or Rust and still get significant value from them.
Nope, if you zoom in on it you can see it’s quite worn, and I had never eaten at this place before
Yep! You’re right
Once you start making rust projects, check out rustfmt and clippy. These tools are super helpful. Also, once you get your program working, if you have any compiler warnings, try to figure out why and get rid of them.
Thank you for your help ^^
1. Understands borrowing and how to structure code on both large and small scales to safely share data. 2. Understands the underlying machine model of Rust (the same one as C and C++) and how Rust's language constructs relate to it. That includes things like the difference between the stack and the heap, undefined behavior, and how parallel threads of execution interact with each other. 3. Is able to apply both of those knowledge bases to create software.
Honestly that third point is the most important. You can have all the understanding of something in the world, but if you can't apply it it's basically useless. Knowing something is easy. Being able to apply said knowledge shows understanding.
Sure! It could look something like this: trait Parser&lt;Input&gt; { type Output; fn parse(&amp;self, input: &amp;mut Input) -&gt; Option&lt;Self::Output&gt;; } Then something could implement `Parser&lt;&amp;str&gt;` to be parsable from a string. This is essentially how my parser is defined, except that I also have additional traits for parsers that need to either mutate state inside `fn parse` or even consume something.
&gt; Do tell how you plan to avoid undefined behavior in rust-cpython when it could be anything and everything, as nobody, including you, has bothered to actually test, despite happily spouting FUD nonsense about it, apparently. I was referring to the `I-unsound` bugs you linked to at that point, not rust-cpython, as should be obvious by my giving #35836 and #59220 as examples. &gt; And that somehow doesn't apply to PyO3.. why, exactly? As I said when I mentioned C++ and Haskell, thicker, heavier abstractions make it more burdensome. Beyond that, I *know* I'm not up to snuff on how to do C FFI safely. Feel free to show me evidence that rust-cpython is as scary as PyO3 and I'll readily go back to writing pure Python codebases. &gt; Blind FUD isn't constructive either and yet here you are, so... Now we finally get to our point of disagreement. Blind FUD was not my intent and you are the first person to see it that way. Plenty of other people have thanked me for pointing out a flaw they overlooked when evaluating their options... whether or not they consider it to be PyO3 vs. rust-cpython or PyO3 and rust-cpython vs. something else. &gt; Which goes back to not using rust, which is confirmed to have UB. Along with C/C++, your operating system, the internet, computers in general, but hey, it's your FUD standard. I get the impression you're being purposefully obtuse. Your argument comes across as equivalent to "Why bother using anything more typesafe than assembly language? It'll still let you shoot yourself in the foot!" My point is and always has been to *minimize* the chance that I'll shoot myself in the foot. &gt; Then, by your "arguments", you should be using PyO3, since it's a helluva lot easier to avoid UB when you know what and where it is. That's a fallacious argument equivalent to "If I send a *known* combatant into the jungle, all *unknown* combatants will vanish." "PyO3 has known flaws" does not imply "All flaws in PyO3 are known". More importantly for me personally, If you'll go back to my very first post, you'll note that I also mentioned the nightly requirement, and compiling on stable Rust is 100% non-negotiable. &gt; The last version of cpython is from September 2018, and has few recent downloads. I will admit that they're overdue for rolling a new release from the commits in the repo. &gt; If you want to use old, unmaintained software and claim it's better than the newer, actively developed fork, back it up. Extraordinary bullshit requires extraordinary evidence. First, while I admit I should have been more clear, my initial comment said nothing about *using* rust-cpython. It just said that I preferred to *not* to use PyO3. Second, I already mentioned that, once I finish prototyping and code churn subsides, I'll probably switch from rust-cpython to an RPC-based solution for binding my Python frontends to my Rust backends to get rid of the uncertainty surrounding rust-cpython. Either way, this conversation clearly isn't productive, so I'll let you have the last word and get on with my life.
You've correctly used `for&lt;'a&gt;` without referring to documentation or asking for help, at least once.
Is it not allowed to discuss unofficial communities? I thought my wording was constructive enough, but I've come to see that the bar is extremely high for anything that's critical of the Rust leadership.
Wondering if there is a way to set this up so I can reference the "editor" variable listed below. Can't find a way to reference this outside of the closure it's declared in, so I'm wondering if there is a way to format it to be accessible in the spot I pointed to below. let file = BufReader::new(File::open(&amp;path).unwrap()); for line in file.lines() { match line { Ok(line) =&gt; if line.starts_with("edit: ") { let editpath: Vec&lt;_&gt; = line.split(":").collect(); let editor = &amp;editpath[1]; &lt;-----------Variable I need to reference }; Ok(line) =&gt; if line.starts_with("edit: ") { let aliaspath: Vec&lt;_&gt; = line.split(":").collect(); let file = &amp;aliaspath[1]; Commans::new(&amp;editor) &lt;------------ Where I would like to reference it
If you have an issue with the moderation message the mods
Nom produces recursive decent parsers, no automata involved. Performance compared to automata should be pretty good unless backtracking is involved. Fortunately, most sane formats can be parsed without serious backtracking.
He said "expert", not "wizard".
&gt; Understands the underlying machine model of Rust (the same one as C and C++) and how Rust's language constructs relate to it. The machine model of Rust is *not* the same as C and C++ (the latter two probably don't have the same machine model either). While some aspects are the same, you will get yourself into trouble if you broadly assume that Rust's abstract machine allows the same thing as C's.
I can just think of things that are specified in one and unspecified/undefined in the other. Are there parts of their machine models that actually contradict each other?
Simple things like that tend to be simple with either way, though -- that might just be `my_strings.map(str::trim)` in rust, no `x` no `in`, etc.
Well, with `itertools`, ```rust [1, 2, 3, 4, 5, 6] .iter() .tuple_windows() .all(|(prev, next)| prev &lt; next) ```
Well if things specified/defined in one are unspecified/undefined in the other, then they contradict each other, no? Since Rust's machine model isn't fully specified/defined, the extent of the difference isn't fully known.
[OT, sorry] Thanks for educating me about Building Git! It looks really good, and I think I'll pick it up myself.
Are there a limited set of values which `editor` should be? Or can it be any string value? In either case, the starting point would likely be adding `let mut editor = None;` (or pick some other default value) above the start of your for loop. Where to go from there depends on if you want editor to hold any string value, or if it should be an enumeration. If you want it to be any string value, you'll have to decide whether you care about allocating or updating a string value for each change to editor, or if you want to store a reference to a string slice (which may be a little more effort, but perform better).
You could disambiguate with e.g. `\x -&gt; body` as in many functional programming languages. I think the bigger problem is that Rust wants a place for the return type, i.e. `|x| -&gt; u8 { body }`. While that isn't used so often, we would need a replacement for that. However, type ascription could largely render the need for `-&gt; u8` redundant.
&gt; That's not a real criticism: a language is not its syntax, but sometimes I am a little sad that the language designers did not have a time machine to see the future, at that time. To be clear, several people in the language team wish for a different syntax than `Struct { field: expr }` in hindsight.
Interesting; List/Monad comprehensions is one of the few things I wish Haskell didn't have.
Yeah, I agree! The best way to fix that however is to help out with the effort, assuming that you are interested in that sort of thing.
Yeah, this is a known issue/bug that I'm nagging Esteban Kuber about to fix :)
Would it break anything to allow an `=` there in addition to a `:`?
Not to my knowledge (unless there's some unexpected funny business with macros). However, it doesn't feel very "fiscally responsible" to add `field = expr` as well?
Yep, I'm finding it to be clearly written and very well-organized so far. It is a pretty big book(I'm done with 10 of 34 chapters so far), but I'm hoping to continue working through it.
I'd count the unspecified/undefined vs. specified as pretty large differences. For instance, signed number overflow being undefined in C and being well-defined in Rust. What else is an underlying machine but a specification of valid things that could happen, and what they do?
It'd be a step into deprecating the colon there in the long run. I doubt it'll actually happen, but I can still dream...
Would it be possible to separate the git interface part into a library? I've been trying to find a simple way to serve files over HTTP directly from a branch in a git database without checking it out into the file system (for reasons). Implementing such a tool in Rust could be fun.
Yeah; I think `field: expr` would need to be awful enough tho to offset the cost of the increased compiler complexity and fact that `field: expr` is used in probably every single Rust crate ever. =P For `dyn Trait` this was clearer.
 fn head_path(&amp;self) -&gt; PathBuf { self.pathname.as_path().join("HEAD").to_path_buf() } The call to `to_path_buf` is unnecessary as `Path::join` returns a `PathBuf`. If you wanted to shorten it even further, you could do `(*self.pathname).join("HEAD")` since `PathBuf` implements `Deref&lt;Target=Path&gt;`.
I’d say, answer properly the following quiz for every question [rust quiz](https://dtolnay.github.io/rust-quiz)
I guess I think of it more idealistically than that. Anything that you'd write in C or C++ should be written in Rust. Tools, environments, OS's, embedded, etc. Anything that's living at the Application level - IE a collection of things written in Rust being glued together in a way that solves a higher level problem should be written in Go. Container orchestrators, app servers, file processing, etc. I guess I am pretty contrary to Rust's "General Purpose" idea. I am prepared to be disagreed with almost unanimously.
Im just here because of welyn
Even 10x would be an unexpected result. Java is pretty fast, and so many ports wouldn't even reach 2x the performance when moving to a native implementation. The minimum required memory footprint for a JVM might however be another problem.
I actually don't think Rust is a good general purpose language. I think that Rust is a very specific tool for a very specific job, and should absolutely not be overused.
My observation has been that outside of obviously spam/hate posts, the only other thing moderation tends to cut down on is public discussion of the moderation. I speculate this is because discussions of moderation can easily turn into a place to bring up topics from old heavily censored posts, and those posts were usually heavily censored for a reason. I personally wouldn't have chosen to take down the post you linked, but I can see how that decision could be logically made. One comment point made is that the moderation team is happy to discuss moderation in private. As I understand it, those discussions are usually productive, especially if you're willing to understand their perspective when coming into the discussion?
[removed]
The left edge doesn't move as much as the middle edge that in turn doesn't move as much as the right edge. That's consistent with scaling, not moving.
You can make `values` a generic field - like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=279710f50e5bef7c0a12fc941e0a7614)
Thanks! Changed this.
No, because the defined behaviour would satisfy both.
[Something like this?](https://github.com/rust-lang/git2-rs/blob/master/examples/cat-file.rs) The `arg_object` argument takes an [object spec](https://git-scm.com/docs/git-rev-parse.html#_specifying_revisions), so you can cat it straight out of the git repo.
In general, why use an iterator over a while loop? For example, if one was writing a lexer, I’ve seen approaches that implement Iterator for the lexer that progress through the source text and build the list of tokens. You could also write a method on the Lexer that uses a while loop instead. What would the iterator provide could make it a better approach? Not having to worry about indices?
Gotcha, thanks
Yes, thanks! This will fit my needs.
Could still make the struct a `struct MyStruct&lt;T&gt; { values: T }`, if you're ok with it being able to be instantiated with any type. Depends on the use case if that's helpful or not, since you still can't act generically over the array
If `A` is defined in Rust but undefined in C++ then the models contradict each other wrt. `A`. Conversely, if `B` is undefined in Rust but defined in C++ then the models also contradict each other wrt. `B`. The take-away is that one cannot blindly apply knowledge about C++s machine model when using `unsafe` Rust (and vice versa).
It would be more useful to do `struct MyStruct&lt;T: Index&lt;usize&gt;&gt; { values: T }`, but (again thanks to the lack of const generics) traits like that aren't implemented on all array sizes.
Having BurntSushi in your name or something.
If they truly do need any size, the unbound T will work if they just want to iterate over the array. [Limited, but it works](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ee06c38845f0b1e1d5c1347f2771b624)
Mainly for convenience - with iterators you can create code that is usually more eligible (for another fellow programmer) than the one with `while` loops.
... which means that `*` is unnecessary. The `.` automatically derefs when looking for methods.
Oh neat, I thought it only auto-refed
Note: there's already another Rust project that shares the same name: https://crates.io/crates/rug
... with hours and access to documentation. Seriously, this quiz is full of traps and involves a lot of otherwise useless knowledge to totally solve.
My concern was with your use of "Contradict" - you appear to mean "these things don't match" and yes, they do not. However contradict actually means "These things stand in complete opposition to each other." It's like if I said I like fruit and you said you liked ONLY apples, you could give both of us apples and we would both be happy. However, If I said I like ONLY Oranges and you like ONLY Apples then our food preferences contradict and there is no possible fruit choice that will satisfy us both. Now I agree that C++ is often ill defined and so I like Rust much better in that everything I care about is very well defined. That feels much safer to me and helps me have a clear mental model. But for almost everything I have seen, I could take a C++ program and run it with a "Rust Machine Model" and C++ would be happy. The models mostly do not contradict (I don't know of any contradictions yet). Data representation is mostly the same, etc.
I released v0.2.0 of [crossref](https://github.com/MattsSe/crossref-rs), which is a client to ccess metadata of scientific publications via the [crossref-api](https://github.com/CrossRef/rest-api-doc). v0.2.0 brings support for [deep-paging](https://github.com/CrossRef/rest-api-doc#deep-paging-with-cursors) which allows to gather huge chunks of works. This release also introduces a [command line app](https://github.com/MattsSe/crossref-rs#command-line-application) to query a DOI's metadata directly from the terminal. &amp;#x200B; This week I continue working on [rustika](https://github.com/MattsSe/rustika) v0.1.0 which brings rust bindings to the Apache Tika™ REST services, just like [tika-python](https://github.com/chrismattmann/tika-python) does for python.
Honestly having to know all of this sucks. I wish we had dynamically sized types so that the allocation functions could return a [u8] to at least deal with the size and dereferenceable hints. I have no idea how to attach alignment information without carrying a runtime cost though. We would need much more powerful types for that.
I think you could replace all \`filter\_map\`s with \`flat\_map\`s, but they are not 100% identical. E.g. they have a different \`size\_hint\` implementation. The \`filter\_map\` *might* be faster due to less allocation in a \`collect\` context. This might also be true for other Iterator methods. \`flat\_map\` has to deal with iterators (potentially multiple return values within a closure), while \`filter\_map\` knows only a single Option will get returned by the given closure. This could lead to better optimized code in the \`filter\_map\` case (and if it is just a missed optimization in the \`flat\_map\` case.) The program logic should be the same with both methods, there can be just some different details how the task is accomplished.
&gt; I was referring to the I-unsound bugs you linked to at that point, not rust-cpython, as should be obvious by my giving #35836 and #59220 as examples. Way to completely miss the point, not that i'm surprised. My point, which should have been obvious to anyone with more than one functioning brain cell, and elaborated in my next point where i explicitly tell say "And that somehow doesn't apply to PyO3.. why, exactly?", was, well, that. You said Rust was ok to use for bullshit reasons, so I pointed out that your argument completely fails for `rust-cpython`, unless you're saying you feel confident in avoiding unknown UB, which is even more illogical. &gt; I know I'm not up to snuff on how to do C FFI safely And yet you feel qualified to spout FUD on widely used, actively developed, C FFI libraries.. funny how that works. If you know you're not up to snuff then stop spouting nonsense. &gt; Feel free to show me evidence that rust-cpython is as scary as PyO3 and I'll readily go back to writing pure Python codebases. Hell no. I'm not going to argue your point for you. You make extraordinary claims, you back them up. You claim PyO3 is more scary than rust-cpython and dangerous and shouldn't be used, you back it up. It's a widely used popular library, actively maintained, a fork of rust-cpython, so you back up your claim that it's dangerous but it's parent isnt. Your feelings of "waaa scary" are not evidence. Not that you can, since you just stole the claim from our resident FUD expert, Shnatsel, and have nothing to back it up yourself. I see them on here often and they give good advice just often enough for the less experienced to believe them when they're wrong on the important stuff. Like [here](https://www.reddit.com/r/rust/comments/98ahv5/sdset_set_theory_applied_on_sorted_and/e4ejgd9/) and [here](https://www.reddit.com/r/rust/comments/c3qc9z/mimalloc_a_compact_general_purpose_allocator_with/ertarme/?context=3). I've had them RES tagged as such ever since. &gt; Blind FUD was not my intent and you are the first person to see it that way. Not in this thread, since i'm the only one replying to you. &gt; Plenty of other people have thanked me for pointing out a flaw Your *perceived* "flaw", it doesnt have to be actual. Are you really that dense to not realize they just took your word for it? Theres no deeper meaning to it other than people believed you. It doesn't matter whether you're right or not, **especially since you're not in this case.** They'd be just as likely to believe you if you had said rust-cpython was dangerous and shouldn't be used, they'll assume you know what you're talking about/looked into it more than them and trust that. People value the opinions of others. [And again, the data doesn't pan out.](https://crates.io/search?q=python) &gt; rust-cpython stats: &gt; All-Time: 51,294 &gt; Recent: 9,611 ---- &gt; PyO3 stats &gt; All-Time: 53,138 &gt; Recent: 28,617 It's pretty clear which one people are using. And it isnt because it's fundamentally dangerous and unusable. &gt; Your argument comes across as equivalent to "Why bother using anything more typesafe than assembly language? It'll still let you shoot yourself in the foot!" It's literally your argument. You keep saying you don't want to use anything with confirmed UB, thats one of your big arguments here against PyO3, but then listing exceptions when i point out stuff you use with UB. I guarantee you've never dug into the Rust and LLVM source to find out how UB affects your programs. And for some reason PyO3 is an exception to the exceptions and it's confirmed UB is a problem, but none of the others is. &gt; My point is and always has been to minimize the chance that I'll shoot myself in the foot. And the best way to do that is, apparently, use something that *probably* has UB but we've never tested it, it's unmaintained, old, and has a newer fork. Because that makes sense? Somehow?? PyO3's soundness bugs are bad and make it fundamentally broken, but Rust, LLVMs, your OSes, etc, their soundness bugs are ok! For some reason. &gt; That's a fallacious argument equivalent to "If I send a known combatant into the jungle, all unknown combatants will vanish." Well, no it isnt and i understand how someone like you could have trouble with basic reading comprehension, but that wasnt my argument at all. About Rust UB earlier you said it was OK because it doesn't apply to the kinds of programs you write. So far so good. ***But wait!*** HOW do you know it doesn't apply to your programs? Because they're *known* bugs. You want to avoid UB and minimize risk. The best way to do that is to know what issues exist and where. You also conveniently ignore unknown bugs here, despite using them as an argument **against* PyO3? Why is PyO3 bad because it has known and unknown soundness bugs, but Rust isnt for the same reason, but rust-cpython is good because it only has unknown soundness bugs? Pick an argument! You keep prefering rust-cpython because it has unknown bugs, which makes it look less "scary" to you(what are you, four?) &gt; "PyO3 has known flaws" does not imply "All flaws in PyO3 are known". Thankfully the only one trying to make that point is you. &gt; you'll note that I also mentioned the nightly requirement, and compiling on stable Rust is 100% non-negotiable. You mentioned it only in passing, not as a hard requirement for your uses, if you had just said you require stable that would've been legitimate reason enough to use rust-cpython, but you didnt, you spouted FUD. &gt; I will admit that they're overdue for rolling a new release from the commits in the repo. [I wouldn't hold my breath](https://github.com/dgrunwald/rust-cpython/graphs/commit-activity). [Compare with PyO3](https://github.com/PyO3/pyo3/graphs/commit-activity) and it's clear which one is maintained. &gt; First, while I admit I should have been more clear, my initial comment said nothing about using rust-cpython. It just said that I preferred to not to use PyO3. Thats the same thing. The two of them are ***the*** way to use Python from rust. There arent a lot of other choices, if any. &gt; Second, I already mentioned that, once I finish prototyping and code churn subsides, I'll probably switch from rust-cpython to an RPC-based solution for binding my Python frontends to my Rust backends to get rid of the uncertainty surrounding rust-cpython. How do you plan to avoid the uncertainty in your RPC-based solution? Not exactly a lot of native Rust RPC frameworks, and no matter how expert the writers are for the C/C++ ones, their *will* be soundness bugs(a class of which would be statically impossible in rust, adding a higher degree of confidence in that specific area). Not to mention the underlying OS mechanisms. Or hell, even soundness bugs in python itself! What makes an RPC-based solution more "certain" than proper bindings? Hell, always the raw C bindings that Python provides if you're so untrustworthy of everyone elses. &gt; Either way, this conversation clearly isn't productive, so I'll let you have the last word and get on with my life. That sure is a funny way to say "I'm wrong and refuse to learn, so i'll leave and feel smug about an imagined moral high-ground"
`filter_map` should exist, in whatever form, since it communicates the intent better than `flat_map`, anyway.
We were talking about expert, did we?
I would do this: ``` struct MyStruct&lt;'a&gt; { values: &amp;'a [u8], } ``` This is the most versatile way to implement a byte array as you can pass a reference to both a Vec or an array.
Different intentions. If I see a for loop it gives off the intention of going through a complete set of items. A while loop can do the same, but is also used when you need to loop for an undetermined amount of time/open set of items. And personally, that's where I split them. Also I personally prefer the way for loops and iterators in general read and compose.
Yes. But did you really try to do all the questions ? It's more than rust expertise, it's also a trick game and unspecified details trivia.
A contradiction happens when two things do not agree. My use of "contradict" here is intentional and I mean it literally in the propositional logic sense. That is, say we have some predicate `P : Program -&gt; Prop`, which tells whether a specific property holds about `x: Program` in a language. Now, if you assume `P(x) = ⊤` in Rust because of C's abstract machine, but it in fact you have `P(x) = ⊥` then you can derive `P(x) ^ ¬P(x)` (a contradiction). &gt; But for almost everything I have seen, I could take a C++ program and run it with a "Rust Machine Model" and C would be happy. I am personally more concerned about people taking Rust program with assumptions about C's abstract machine and getting UB as a result. &gt; The models mostly do not contradict (I don't know of any contradictions yet). Data representation is mostly the same, etc. I don't think that's the case. For example, C is much more keen on specifying the layout of data types whereas the representation of `repr(Rust)` is mostly unspecified (you should assume that means undefined in terms of `transmute` and whatnot). If you want C's layout and ABI you instead use `repr(C)`. For an example of something you might think is specified behavior but is in fact not, you cannot soundly transmute `struct A(u8, u8);` to `struct B(u8, u8);`. In C, unsigned integers [are very special](https://github.com/crossbeam-rs/crossbeam/issues/315#issuecomment-458911215) but there is no precedent for e.g. that a transmute to a byte-buffer and back is roundtrippable. I'm not familiar with what the C/C++ standards say on this, but e.g. `let x: bool = uninitialized();` is instant UB in Rust and so too is `let x: &amp;T = uninitialized();`.
&gt; This is of course why it is possible to call C or C++ functions from Rust or have calls back. If the two languages didn't agree what a i32 or f32 was we would be in dire straights indeed. [One exception is when you involve unwinding.](https://github.com/rust-lang/rust/issues/58794)
https://github.com/viperproject/prusti-dev ?
it's the same kind of issue that happen with futures. Implementing some combinators , like `alt` or `permutation`, is annoying, because you would either try to use static dispatch by making a huge chain of `Or` (or `Either` for futures), or you would hide the child parsers in `Box` to do dynamic dispatching. Then there's the issue of the huge types that are generated, and are complex to debug. Closures on the other hand erase a lot of type information, which make it more manageable
So you're talking about a language/DSL/framework(I didn't bother to look into it) specifically for building UIs? &gt; Declarative vs Procedural. Sooo... something like React, and I think Flutter?(I don't know much about Flutter but heard it's similar)
I'm also doing this. There must be dozens of us! Probably because Git is actually a really simple system wrapped in a hilariously unintuitive CLI. The most complex bit I've had to do is reading the packfile index. Anyway I'm doing it so that I can make a GUI client that has these features: 1. Instantly refreshes when the repo changes without locking it. 2. Works remotely via SSH, like VSCode's remote development extension. It's a fun project - good luck!
In case you’re curious, kutt.it, appears to be a URL shortener.
Why?
&gt; and fact that &gt; field: expr &gt; is used in probably every single Rust crate ever. =P I thought I had read some blogpost about one of the rust releases that Cargo could compile crates with different versions of Rust, so that if that syntax was deprecated for a v2.0 release of the language or different epoch, then until a crate is compatible with a newer rust version, it'd be compilable with an older version while your other code can use the latest rust has to offer?
How does this compare to ShadowSocks?
Doing a C# job, I can confirm that: everything is so simple from refactoring to add the correct `using`. In Rust, we're far from such a smooth flow.
Cargo basically passes `--edition 2015` or `--edition 2018` to `rustc`. However, both modes have to be supported by the compiler (in this case it would be `--edition 2021`). There's no technical problem in making this work as far as I know. We could introduce `field = expr` and remove `field: expr` in 2021. However, there are social costs. Plenty of documentation and guides need to be rewritten and people need to adapt to the change.
&gt; However, there are social costs. Plenty of documentation and guides need to be rewritten and people need to adapt to the change. Yeah, I understand that. Though if you were to ever make such a change, it'd possibly better while the lanugage is still young rather than later on? I'm not all that fussed about this specific syntax personally. I'd much rather fat arrow =&gt; syntax for closures myself, as well as `...` instead of `..=` (but I'm aware of what a long debate that was with the RFC so I doubt that'd ever happen). I know with one language (Haxe, which uses OCaml to build it iirc), there was quite a fair amount of users wanting arrow syntax and other features too, someone ended up forking/patching the language to support it(the maintainers were against it, as they felt it added more friction to learning the language if there were multiple ways to do things). I wouldn't expect such to happen with Rust though, a transpiler might be neat :P
I guess you're welcome?
What's unintuitive about it? You only need a few commands. Commit to add nodes to the graph, merge to join nodes, rebase to move nodes, push to upload, fetch to download. Git gets a lot of criticism but I don't really see what's so difficult about it? And I'm decisively mediocre
I think this link is more accurate now: https://readrust.net/support.html
Thank you indeed! ^~^
I didn't end up reading the article thoroughly as it was a bit over my head as interesting as it looks and I don't have a specific need afaik for such in any projects right now. &amp;#x200B; When would someone want to reach out for swym? How much of a difference can it make, or is it catering to a specific niche case? Is it more likely to be used when developing a project/program or a library/crate?
* The `Iterator` trait comes with a long list of useful adapters. For example, the effects of the `zip`, `step_by` and `skip` methods are not always trivial to achieve using naked `while` loops. * Writing an iterator moves the `while` loop from the method body to the callsite. This enables the method's caller to make decisions like "I want to read one token, and finish processing it before I read another", or "I want to collect the iterator's results into a `VecDeque` rather than a `Vec`".
The list of contributors is quite long as you'll discover. `onur` is the one who started docs.rs and is still contributing to it. I've been working on rustdoc since a long time (2015, maybe even 2014?) and /u/quietmisdreavus came in later on and did an amazing job both on rustdoc and more recently docs.rs. Anyway, that's a lot of people haha.
If this plays nice with Flask then I am sold.
That's silly. I upvoted.
&gt; Though if you were to ever make such a change, it'd possibly better while the lanugage is still young rather than later on? Sure; always better to break sooner rather than later. &gt; I'm not all that fussed about this specific syntax personally. The reason people are fussed is because of type ascription; `S { f: u8 }` would parse `u8` as a binding, not a type. With `S { f = pat }` you could write `S { f: type }` and `S { f = pat: type }` when you want type ascription.
[removed]
[Rust Learning](https://github.com/ctjhoa/rust-learning) is, “a bunch of links to blog posts, articles, videos, etc for learning Rust”.
BTW the most common use case is higher kinded lifetime bound emulation trait A&lt;'a&gt; { type Type; } trait B: for&lt;'a&gt; A&lt;'a&gt; { fn foo&lt;'a&gt;(&amp;'a self) -&gt; &lt;Self as A&lt;'a&gt;&gt;::Type; } One day it will be possible to write trait B { type Type&lt;'a&gt;; fn foo&lt;'a&gt;(&amp;'a self) -&gt; Self::Type&lt;'a&gt;; }
You have commits to std
I wrote a C wrapper for some tool and it worked fine until last week. I already found the problem: https://github.com/greaka/arcdps_bindings/blob/b8a1e08b53d78c9bba5914d82f284539c7ca33d1/src/lib.rs#L195 `FUNCTIONS` is `None`. It is still `None` on the line that I linked to. Can someone explain to me why and maybe how to fix it?
&gt; Your own argument rules out rust-cpython kid. Are you, like, all there? mentally speaking? You seem to have serious problems Looked in a mirror lately? For some reason you felt it necessary to fling insults to further demonstrate how wrong someone else must be? The lack of ability to keep your cool and be respectful and educate rather than demean seems to be something you struggle with? You seem to be knowledgeable to some regard, but your attitude in the discussion makes it hard to take you seriously, especially with the defensive obsession that ensues. I'm a rust/low-level peasant so go to town on me if that makes you feel better btw. I got a bit lost in what your motives were, it seemed you were opposed to rust because of a lack of safety, expecting that a developer knows where every possible flaw is, right down to the compiler and LLVM codebase? It's great that you have the time to invest in doing that and care so much about attaining that level of confidence, but I wouldn't say it justifies the way you responded here. Later on, it appears you're just super defensive towards PyO3 down for any reason. You got really worked up over this, if you're having a bad day, that sucks dude but no need to project the way you feel onto others.
Cleaning up my randomization crate, hopefully we can see a v3 this week.
&gt; You're talking to someone who uses rust-cpython to write PyQt GUIs for Rust backends because it's harder to screw up than using C++ to combine Qt and Rust Did you give the rust crates for Qt/C++ a go? (just curious about experience) Any reason you're building the GUIs with PyQt instead of PySide which Qt officially supports as Qt for Python now? Is it just because you're more comfortable with PyQt from past work and see little benefit from PySide?(I recall in the past PyQt was superior but in recent years PySide had been getting quite a bit of love, especially with the official Qt support)
Ah, yeah that'd be nice :) and I can see how that'd also be confusing viewing third-party code!
Wow. May be emacs can use this.
I've only looked briefly at the code, but something seems off. This is the allocation function: ```rust unsafe fn alloc(&amp;self, layout: Layout) -&gt; *mut u8 { mi_malloc_aligned(layout.size(), layout.align()); null_mut() } ``` This always returns a null pointer?
For me, checking out, resetting and branching (especially keeping sync with remote repos) were hard for a long time.
Adding my thanks too. Rust is the programming language that gave me the confidence to learn how a computer actually works.
I wrote my bachelor project about performance-comparison of Rust and C implementations of numerical methods.
Does anyone know why it's possible to add `use std` to rust source files without causing a reimport error. `std::prelude` has a line in the docs stating it's automatically imported into every crate. I noticed it was possible when trying to figure out a way to get `std` docs to show along side my documentation offline.
Knowing those unspecified details is what makes a language expert, no?
Pls help me understand, what was it that you found difficult about it? (serious) I mean, my approach is to just look at the graph (git log --oneline --graph), decide how I want to change it, run a command, look again at the graph, if it's not how I wanted it I'd just reset back. (Repeat until happy)
It worked. Thank you!
Hi Great, thanks! I think this way is more like an "integration test", where you check the router and the handler integrated with it than a simple granular unit test. I will use it.
The *names* of the commands are highly unintuitive.
Got it, thank you!
Thanks!
Great counterexample. Same problem with Panicing across FFI boundraries back into callers of your Rust externs.
Yeah, there is far too much that is ill defined on the C / C++ side. And then a few things which Rust (sensibly) decided not to lock down unless requested such as memory sequence of fields in a struct / tuple. Probably my most simple dislike about C / C++ was when I first discovered all the different flavors of "int" in C/C++ (this is before lovely typedefs like i32 became common). There is a reason why I code primarily in Rust now. I like clear definitions and concrete understanding of exactly what the compiler will give me. And there is a nice feeling you get when everything you look at is well engineered - you get the strong feeling that everything you cannot see has had similar thought put in.
Note that I don't find these things hard anymore - but I used to. For starters, checking out with a path param does totally different thing (reset that file to the current commit) than checking out with a commit/branch parameter (set HEAD to that commit and check out the files) and the behaviour changes again with -b: now it DOESN'T reset or check out anything but keeps everything as is and creates a new branch. Why do I have to use checkout to reset a file but reset to reset otherwise?
I've thought about it and decided I'll just change these to Acquire since its more conservative.
&gt; Why is creating a branch git checkout -b, but deleting a branch is git branch -d? Umm no, creating a branch is also `git branch name`... not sure what you mean. `git checkout -b` checks out a branch just like the name suggests (creating it while doing so)
Really? I thought I was just a noob and missing something. What would you say it should do ideally?
&gt; For starters, checking out with a path param does totally different thing (reset that file to the current commit) Wait what no? `git checkout path` checks out that file. I mean that would seem to be the only logical thing right? `git checkout commit` checks out the commit, `git checkout` without arguments checks out the current commit, and so `git checkout file` checkouts out the current commit filtered for the file specified? And adding the `-b` flag checks out a new branch? &gt; Why do I have to use checkout to reset a file but reset to reset otherwise? Not sure I follow, checkout always changes your files to the commit/sha1 given, reset always changes the state of the current HEAD?
There's a good crate for this, [notify](https://crates.io/crates/notify)
So ideally, if you have done `use path::to::Foo;` then the error message should use the local name in scope, i.e. `Bar`, instead of `path::to::Bar`. The same idea also applies to things in the prelude. You will still have nested types, but at least you won't get drowned down in the super long paths. Also, if there's a type alias, then that type alias should be used, and not the right-hand side of the type alias.
OK, I don't like being provoked into responding after I say I won't, but there *is* one misconception on your part which I think can be fairly argued to be my fault, so I'll respond to that once more. I was referring to RPC in the abstract... as in "I'll put the Rust and Python code in separate processes and use *some* form of IPC to have the Python frontend call functions in a long-lived Rust backend." By that definition, something as simple as sending a chunk of JSON through a named pipe and receiving a chunk of JSON in reply counts as RPC.
So editor will be reading a single line in the file that starts with "Editor: ", and grabbing a text editor command from that line. For example mine would pull "nvim" as a string, after splitting with ":" and pulling the second part of the vec.
Yeah, it would have. For now I'm hoping we can just go with `S { f: pat: type }` and use some linting (based on α-conversion) on cases that look confusing in favor of `S { f: (pat: type) }` (parenthesis to disambiguate).
I suggest a new name rig (rust implementation of git).
It's also a colon in javascript, so it would be strange if it would be an equal sign.
Oh yeah, I agree! We should try, as much as we can muster, to provide clear, consistent, and composable rules that avoid special cases.
&gt; Did you give the rust crates for Qt/C++ a go? (just curious about experience) I investigated what I could but... * rust-qt's documentation says "Not implemented yet but planned: Creating custom signals from Rust code.", which takes it out of the running. * rust-qt-binding-generator is for embedding Rust inside a C++ project and made no provisions for wrapping the Qt/C++ API for Rust's use last I checked. * The QML-based options can't make use of the QWidget API, which is necessary for writing native-feeling KDE applications. &gt; Any reason you're building the GUIs with PyQt instead of PySide which Qt officially supports as Qt for Python now? &gt; &gt; Is it just because you're more comfortable with PyQt from past work and see little benefit from PySide?(I recall in the past PyQt was superior but in recent years PySide had been getting quite a bit of love, especially with the official Qt support) Nothing against PySide. I just started my most recent project on Kubuntu 14.04 LTS, which didn't get updated with a suitably mature release of PySide for Qt 5 and haven't yet had time to switch over when I've got other, more pressing ports to do. (eg. QuickTile from Python 2.x, PyGTK+, and GTK+ 2.x to Python 3, PyGI, and GTK+ 3.x)
Fair enough :) So PyOxidizer is for packaging Python software into executables cross-platform? I haven't done much Python dev myself but when looking into how to distribute I remember that being a bit of a confusing mess(never got to that point and just ran python scripts in-house with instructions on how to get it running to other members of the team. I haven't tried the rust crates like PyO3 that are meant to let you use Rust to some extent when writing Python software, are those usable with PyOxidizer?
Arcana and trivia does not make an expert. Don’t confuse that with experience and knowledge.
There's also the case where the array content will not change. Then it can be `&amp;'static [u8]`, but it's not the most useful...
I would generally prefer that unsafe blocks didn't exist yet accept that they aren't inherently bad when used correctly. Have you studied any in PyO3 that lead to the aforementioned undefined behavior?
Holy crap that sounds amazing! Thanks for working on fixing this!
I think you approach it from the wrong angle maybe. I find it very intuitive. There basically one toggle for different behavior: if you specify a path, then any existing changes in the working directory will be overwritten for this path. If you don't supply a path then none of the uncommitted changes will be overwritten. This difference in behavior makes sense, why else would you specify a path, if you don't want something to happen to this specific path? If it would also keep the changes intact, then it would be exactly the same as not giving any path at all. In summary: * `git checkout &lt;branch&gt;` - will checkout an existing branch, keeping any local changes intact. * `git checkout -b &lt;branch&gt;` - will create a new branch an then check it out, keeping any local changes intact. This is a shortcut for `git branch &lt;branch&gt;; git checkout &lt;branch&gt;`. * `git checkout [--] &lt;path&gt;` - will overwrite the file(s) in the given path, discarding local changes.
Not really, no.
Well, I'm not, but I'm lobbying for it. ^^ If you want to help out, [I made a Zulip thread for this](https://rust-lang.zulipchat.com/#narrow/stream/147480-t-compiler.2Fwg-diagnostics/topic/The.20long-types.20problem).
I've seen Firefox users frustrated that they cannot contribute to Firefox development. I wonder if there will be a way that this can change (for both).
Are you using it with [r2d2-odbc](https://github.com/Koka/r2d2-odbc)? That crate seems to be missing health checks in `is_valid`/`has_broken`.
Okay, that's yet a slightly different case. In rough pseudo-rust: let lines = file.lines(); let first_line = lines.next().unwrap(); // you may want to handle this error let editor = // do something with first line to get editor for line in lines() // put the rest of your loop here
Creating a branch is actually `git branch &lt;branchname&gt;` but this will create it "in the background" without checking it out. So you actually have to do it in two steps: ``` $ git branch &lt;branchname&gt; $ git checkout &lt;branchname&gt; ``` `git checkout -b &lt;branchname&gt;` is a handy shortcut that combines these two actions. Most people prefer this since it is quicker.
The numbers are very weird though. Kotlin on top, which should have almost the same runtime characteristics as Java (but Java is more than 100% slower and uses 18 times more memory). Seems sketchy.
I imagine `AsRef&lt;[u8]&gt;` would work in most cases if we're talking about byte containers.
Then I'm the noobiest expert ever.
I've been meaning to put together a plan for a 1.0 release. Mostly I need to review open issues to see if there are any more breaking changes that should be included. I also have plans for a possible 2.0 that I hope will make the library more ergonomic to use. At the same time I review issues for 1.0 I want to explicitly tag some as 2.0.
Thanks! And thank *you* for being an important part of the Rust game/graphics community, especially by helping and inspiring others.
WOW, i don't know if this was just pure luck – or if there is really something in the picture i (or every normal person) cannot pinpoint, but as someone living there would instantly recognise. Fascinating.
Because you only used safe rust, no that shouldn't work. You should open an issue on github.
It's because of a mistake in a previous version of the compiler that has been kept as a warning for backwards compatibility. It will be fixed in a future release. Did you read the warning? ``` warning: this error has been downgraded to a warning for backwards compatibility with previous releases warning: this represents potential undefined behavior in your code and this warning will become a hard error in the future ```
Features should be additive: [api-guidelines](https://rust-lang-nursery.github.io/api-guidelines/print.html#feature-names-are-free-of-placeholder-words-c-feature) (last paragraph of section). `no-secure` should be renamed `secure` and included as a default feature.
It doesn't compile without replacing String::new with String::from. Also rust emits warning (only warning due to backward compatibility) that will become hard error in the future: warning[E0382]: use of moved value: `bar`--&gt; src/lib.rs:10:16 | 7 | let bar = String::from("BAR"); | --- move occurs because `bar` has type `std::string::String`, which does not implement the `Copy` trait 8 | let bar = match 0 { 9 | 0 if { tst_func(bar) } =&gt; unreachable!(), | --- value moved here 10 | _ =&gt; { bar }, | ^^^ value used here after move | = warning: this error has been downgraded to a warning for backwards compatibility with previous releases = warning: this represents potential undefined behavior in your code and this warning will become a hard error in the future [Source](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=533ca351c6e02912332c8c65e1a7c17a)
Whoa, I've never even seen `for`. Does it have drawbacks when compared to your GATs example? /me looks up documentation on `for`, is not expert
 you'd be amazed how easy it is to deploy and distribute crates of your shit
Yes. I was surprised, because my impression was that no such issue is possible on the first hand. Another thing is, why when compiled with `rustc` the warning didn't appear?
Try it out and let us know ;)
You shouldn't, it's already fixed, and the compiler only warns on it instead of erroring because code was found that depended on this behavior.
Think it is the same issue as this one: https://github.com/rust-lang/rust/issues/31287
No, using it directly
Anything is possible if the compiler has a bug.
The warning depends on the edition. Compile with "--edition=2018" to see it.
`String::from` treats even the double quotes as strings then.
The error is the same, to keep backward compatible I think. &gt;&gt; rustc --edition=2018 ss.rs -o ss;./ss warning[E0382]: use of moved value: `foo` --&gt; ss.rs:9:13 | 2 | let foo = String::from("FOO"); | --- move occurs because `foo` has type `std::string::String`, which does not implement the `Copy` trait ... 6 | some_func(foo) | --- value moved here ... 9 | foo | ^^^ value used here after move | = warning: this error has been downgraded to a warning for backwards compatibility with previous releases = warning: this represents potential undefined behavior in your code and this warning will become a hard error in the future "h�&gt;" Segmentation fault
`git reset` doesn't always change the current HEAD, it can also change your files.
I originally wanted this to search for the editor line, but this does work the way I want it to, if I place this on the first line of the config file. Awesome, thanks!
Is it safe to assume that part of Rust's memory safety comes from compiler as well?
&gt; println!("{:#?}", bar); That because of this line. In order to not show the double quotes change it to println!("{}", bar);
How difficult are you finding it to translate the code from Ruby to Rust?
You can do this too, you just might have to loop over the lines twice (the first loop you'd exit early as soon as you find the editor line). It's probably possible to do this without looping twice, but that will be more difficult and if your file is small-ish it won't matter either way.
Cool...
Arguably all of it comes from the compiler, because the compiler determines the exact sequence of bytes that makes up with binary. Even written in Rust, Rust's memory safety doesn't enforce that an arbitrary sequence of bytes that the compiler can write are necessarily memory safe. Even if it did, there is a lot of unsafe code in the compiler. And even if there wasn't, the compiler's backend is LLVM, which is written in C++.
https://github.com/rust-lang/rust/labels/I-unsound%20%F0%9F%92%A5 lists known safety holes in Rust.
you can compile some code ;)
For memory safety, we rely on the compiler and all unsafe Rust code blocks within a program (most of them are in the standard library) to not have any bugs that would allow the remaining safe Rust code to invoke undefined behaviour w.r.t. memory accesses and data races.
&gt;Yes. I was surprised, because my impression was that no such issue is possible on the first hand. The language is designed to that the undefined behavior can be caught at compile time. The compiler should have noticed that `bar` is moved-from and then moved-from again. If dropping `bar` frees memory (and it does) this is use-after-free. But there's a bug in the implementation of the language. The only thing I'm surprised by is that the fix isn't deny-by-default, an error but one which could be overridden on a case by case basic basis.
Think the Apple guy goes into it here: https://9to5mac.com/2019/06/06/craig-federighi-interview-ipados-swift-ui-catalyst/
Just updated this.
It does make more sense. Just updated this.
Good prompt :), I won't be back at my laptop until next Monday but if anyones interested I will post if the app I'm currently building via PyInstaller works with the tool.
Here is discussion of crater runs that evaluate the impact on the ecosystem of fixing this soundness hole. It seems to be mostly in old versions of crates. https://github.com/rust-lang/rust/issues/60680
All of it comes from the compiler, because it's the compiler that implements and enforces the language semantics. If the compiler is unable to statically enforce the invariants it promises to enforce, then that's it.
I'm unclear why you think you need a lifetime on the struct to begin with; by removing the lifetime parameter, and making the closure take the original value by reference, I get to https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=74b2f87c46ad2d195501a446b5d14044 which appears to work.
I used to closely follow nom's development, but not so much recently. Last time I tried it, the major blocker for me was that it doesn't keep track of line numbers in parsed text and there was no easy way to work around it, and that's a critical feature for programming language compiler. What's the story now? Is it possible to keep track of line numbers now?
That's what I meant, change the current HEAD so that files match what tell it too. Example `git reset --hard remote/branch`
If you'd just read the compiler output you'd have known 🙄
&gt; Be able to write in the most minimal, clear, readable, expressable way, what you want the interface to be and have the system infer, okay how am I going to get that done? If the UI changes, if the underlying state changes such that the UI contents changes from this to that, handle the animation automatically… Yeah... that's nothing new. React-Spring can do the same regarding animation Not particularly interested in listening through a 45 min talk on some UI toolkit/whatever that's only usable for a niche set of devices. Apple might boast it as new/revolutionary but that's nothing new from them. I'm doubtful that they're doing anything different than existing options already out there. The main advantage will be it's tailored specifically for the hardware/OS and language that they control in full, the main disadvantage is also that, if it's not usable elsewhere in a cross-platform manner, it's a lock-in that has no appeal to me. With React, you'll likely find you can achieve the same thing anyhow. There is React-Native which can support iOS and will likely get this new iPad exclusive OS they're introducing supported as well since it'd be of interest to Facebook who maintains React/React-Native. From there, if they want to, they can hook into whatever SwiftUI stuff is doing afaik, but retaining the declarative approach in JSX instead of... SwiftUI?(which I assume is very similar, just less flexible)
There's been some talk of a Rust Foundation, but it comes with its own set of issues. We'll see!
I've been using git daily for years, and as much as I believe I have it mostly figured out, I still feel I'm always one keystroke away from a disaster. It's a tool that inspires power, but not confidence. On another level, git is also ambivalent about process and there are multiple ways to do the same thing (merge or rebase? etc) which always require coordination between team members concerning best practices, which may even vary from project to project. I'd prefer a tool that can be more prescriptive about workflow. Actually, I think GitHub brought some order here and that's what made it popular. It'd be nice if GitHub's features were available client-side.
I find iterators more understandable than raw for loops because they're a higher operation, conceptually speaking.
That may be what you meant, but it doesn't capture what git reset does. `git reset --hard` doesn't change HEAD (note I didn't specify a branch, so if it were changing the current HEAD it would change it to HEAD). `git reset some_file` doesn't change HEAD either (it changes the index, but that's something different). `git reset --patch` also doesn't change HEAD.
Good thing that JS isn't the only other language out there :) As a counterexample, C# uses = for its object initialization syntax. I really don't care about it...but if i _had_ a choice, I'd probably pick = .
the error was left in the language for backwards compatibility, so that otherwise correct programs which move from a place twice without causing UB will compile unchanged. making it deny-by-default would require editing all of those programs to include the new `allow` attribute, which is unacceptable for a language that's supposed to guarantee backwards compatibility.
Not really hate, but I'm concerned about the need for (and resulting prevalence of) macros in a lot of places. Now per se, I like macros. They're a great tool, probably indispensible in Rust, and stuff like function macros can be used quite beautifully. But a loot of stuff that some other languages have nice syntactic tricks up their sleeve _require_ macros in Rust. I admit, I'm a big Kotlin fanboy, but just look at the stuff you can do with its "builders". Or take a look at Elixir: Not the macro stuff, just the way that keyword lists and the general syntax works together. It enables developers to build DSLs like this: query = from w in Weather, where: w.prcp &gt; 0, where: w.temp &lt; 20, select: w without using full-blown macros. Now, of course, this wholly depends on the syntax of the language, and it probably doesn't make a lot of sense comparing Elixir and Rust. But I like the general idea: Some syntactic elements of Elixir and Kotlin are _designed_ with the idea in mind that users of the language want to build DSLs. So they don't need macros all the time. I don't get this feeling in Rust. Maybe this is a deliberate decision (or series thereof), which I'd understand, encouraging DSLs can lead to messy outcomes. But, uh... I like 'em :) Macros make autocompletion and IDE stuff in general a whooole lot more difficult. I don't know about compile times (is it still true that the vast majority of time is spent in LLVM?) or other negative effects... But the dependence on library authors to give their macros good error messages, as well as the IDE problems just concern me a bit. Dunno, maybe this will be solved in the future. And macros do unbelievably cool things in Rust (Serde, thank *god*). But that's a concern of mine :D
From the users perspective this is all the same. You change the current branch to the SHA1 given. I don't understand what you mean... :( Seems all simple. I mean if I want to reset my current branch to `upstream/branch` I do `git reset --hard upstream/branch`. If I don't give it a branch name it resets to the current branch, as you'd expect. If I give a filename it also filters on that file
If from a user from a users perspective `git reset somefile`changes the current branch to the SHA1 given, explain to me why (a) I'm able to call this command without providing a SHA1/commit/branch name, (b) the current branch is not changed (this is true even if I did provide a SHA1). &gt; You change the current branch to the SHA1 given. &gt; If I don't give it a branch name it resets to the current branch How is changing the current branch to the current branch a sensible way to think about the operation `git resest --hard` is performing. It's not changing any branch, it's changing your working directory. &gt; If I give a filename it also filters on that file If you give it a filename it doesn't do anything, other than printing an error message.
&gt; I've been using git daily for years, and as much as I believe I have it mostly figured out, I still feel I'm always one keystroke away from a disaster. It's a tool that inspires power, but not confidence. It's the opposite, git is liberating because it seems impossible to screw up beyond repair. At least I've never managed to. If something goes wrong you check the reflog and reset to the previously known good state. &gt; On another level, git is also ambivalent about process and there are multiple ways to do the same thing (merge or rebase? etc) Hmm merge and rebase are not the same thing and are useful in different contexts. I don't see how you can get away with only one of them
This is exactly what I was looking for! Thank you very much :)
Super cool!
Yes, this works fantastically! Thank you for the help :)
Super cool! Restaurant is called “The Bird” if you’re curious. Would highly recommend.
&gt; warns on it instead of erroring Couldn't there / shouldn't there be an option so that for all projects created after a specific date, it will be an error? Kinda like edition=2018 except more strict?
I wasn't looking to make it growable yet, since I haven't had experience with Vec. This code was mostly for educational purposes more than solving an actual problem. But I'll definitely add the generic-array to my list of things to checkout! Thanks for the reply :)
Awesome! I like the versatility! I'll have to give this a try. Thanks much for the reply :)
How will this compare with [combine](https://docs.rs/combine)? It seems like the two are quite similar now.
I'm reading through a tutorial on Data Structures and Algorithms in Python and implementing the code in Rust. It's sort of my way of transition from my training wheels language, to a very robust language. As well as a way to teach myself the fundamentals of Data Structures and Algorithms :) &amp;#x200B; I'm not very good at Rust, but I think this project will really help solidify some of the syntax I don't quite get, along with the uniquely Rust features :)
The Burger "Shop"? near Schönhauser? I know it very well :P
Thanks for the tip and the explanation!
Just wanted to to say thankyou, this is amazing work!
&gt; If from a user from a users perspective git reset somefilechanges the current branch to the SHA1 given, explain to me why (a) I'm able to call this command without providing a SHA1/commit/branch name, (b) the current branch is not changed (this is true even if I did provide a SHA1). Reset changes your files and branch to the SHA1/commit/branch given. If you don't give it a SHA1/commit/branch means there is no branch to change, only the files How could the behavior be any different?
Oh great, they've finally released it! Thanks for the link!
Yep, it’s very good! Check the bathroom next time and you’ll see this sticker haha
I think one thing to focus on is that Apple is not churning out another "JS like language." The market is flooded with them. Google and Facebook's main goal is to sell Ad's. That's how they survive. It's not Apples business. There is a big difference in how Apple approaches software vs Google. Apple is a hardware company, and you are not going to dive deep into hardware unless you get down to bare metal, and that's something you can do in Apples eco/system. (imho) PS, post any software/hardware links, I'll read, and listen to them all. I just build things. :-)
Do you want struct1 and struct2 to be the same type or different types? &amp;#x200B; If you want them to be the same type, use a Vec instead of an array. struct MyStruct { values: Vec&lt;u8&gt;, } fn main() { let vs: Vec&lt;u8&gt; = vec![1,2,3,4,5]; let ws: Vec&lt;u8&gt; = vec![1,2,3]; let struct1: MyStruct = MyStruct {values: vs}; let struct2: MyStruct = MyStruct {values: ws}; } &amp;#x200B; If you want them to be different types, things are more interesting. On nightly rust, the feature "const generics" is just barely starting to become usable. This feature allows you to do exactly what you want: #![feature(const_generics)] struct MyStruct&lt;const N: usize&gt; { values: [u8; N], } fn main() { let vs: [u8;5] = [1,2,3,4,5]; let ws: [u8;3] = [1,2,3]; let struct1: MyStruct&lt;5&gt; = MyStruct {values: vs}; let struct2: MyStruct&lt;3&gt; = MyStruct {values: ws}; } &amp;#x200B; However, the const generics feature is still incomplete. Even so, I have created a helper crate for working with length-generic arrays: [array-helpers](https://crates.io/crates/array-helpers). &amp;#x200B; If the feature is still too incomplete to be usable for your purposes, though, there are also crates that simulate length-generic arrays with established features. See the [generic-array](https://crates.io/crates/generic-array) crate.
Oh nice! Just yesterday I saw yet another Rust project depending on libgit2 and thought "I wish we had a git implementation in safe Rust"
Seeing a replacement for libgit2 in safe Rust would be great because it's used in Cargo, so almost any memory safety bug in libgit2 C code would be a remote code execution vulnerability in Cargo
Oh, this bug. I spent a long time trying to fix it with no success. The move analysis just couldn't understand it properly. There was actually a proposal to just disallow moving in guards due to how difficult this issue was (is? I'm not sure if the actual status/fix).
&gt; Reset changes your files and branch to the SHA1/commit/branch given. Note that this is a different explanation than the one I objected to: "Not sure I follow, checkout always changes your files to the commit/sha1 given, reset always changes the state of the current HEAD?" Notice how (a) reset doesn't always change the state of the current HEAD, and (b) the contrast with checkout becomes a lot more muddled, which makes your question at the beginning rather condescending. &gt; How could the behavior be any different? And it explains both (a) and (b) The behaviour could be different in a lot of ways, as evidenced by the fact that when I checked `git help reset` it listed two additional possibilities that I had never heard of, compared with a few years ago, at least one of which I don't understand at all.
&gt; On another level, git is also ambivalent about process and there are multiple ways to do the same thing (merge or rebase? etc) It's actually worse than that. There are three different semi-obvious ways to merge two branches and _all of them are wrong._ Every single one breaks something or loses data. Compare that to bazaar that only has one way that just works and has none of the drawbacks of git's thee ways. And it's like that for _everything_ in git.
I see a lot of explanations about why this is the way it is, but does anyone know when it will be .. "fixed"? I get that it's already fixed, but it's not actively running for backwards compat reasons. When will this not be the case? When will it be fixed by default? Perhaps there's a way to enable a project includes all of the fixes like this?
Great job! Thanks.
I'm not too sure why it was handled that way, but that's how it is.
&gt; move from a place twice without causing UB That feels like a contradiction in terms. I'll admit that UB isn't well enough defined yet to say for sure. So the rest of this comment isn't grounded in strong definitions and should be taken with a grain of salt. "Stability as a Deliverable" says this: &gt; We reserve the right to fix compiler bugs, patch safety holes, and change type inference in ways that may occasionally require new type annotations. "Affine typing" - no more than one use - is a core idea of the language. Code which breaks this rule is, imo, simply incorrect. If the compiler incidentally does what the programmer expects that's not a justification. It's just good luck. It's not a broken stability promise to break code which wasn't correct. The only part of this which is unfair to existing code is that UB wasn't and still isn't precisely defined. I haven't found all the discussion about this bug, but the parts I've seen didn't consider the stability angle. It's a difficult bug to fix because the previous borrow-checking analysis needed to be modified, and NLL can do it but needs work. As I understand, the compiler needs to distinguish between `ref x` bindings (which are limited by lifetimes) and move-into-`x` bindings (which may be limited by lifetimes but in different ways) and the fine details were being worked out.
Thanks, this explained exactly what I was looking for! Great resource ! I read the nomicon in the past, but I probably tried to read too much of various topics and I forgot about this explaination!
Thanks, this explained exactly what I was looking for! Great resource ! I read the nomicon in the past, but I probably tried to read too much of various topics and I forgot about this explaination!
I'd much rather ask a question of someone who understands the ecosystem and design patterns along with lots of libraries over someone who knows really weird invariants of the compiler.
To be clear, I am not the author!
&gt; There are three different semi-obvious ways to merge two branches and all of them are wrong. Every single one breaks something or loses data. Please expand on this. What do you mean?
&gt; There are three different semi-obvious ways to merge two branches and all of them are wrong. Every single one breaks something or loses data. My second explanation is the same, just from a different perspective to try to understand why some people find git hard to use Genuinely, git is probably my favorite piece of software just because of how intuitive and fail-proof it is to use. It never breaks (at least I've never managed to) You have a DAG and a few simple commands to manipulate it. Using git is mostly about just looking up what the command is called to manipulate the DAG in the way I want it
Thank you for the reply! My goal was mostly educational, and for that reason, both your answers are extremely helpful! I'll have to check out the things you've linked :) Thanks again for the help
I really miss bitfields or arbitrary bit sized integers. I understand that there is a crate for it, and you can do it by manual masking/shifting but that doesn't work nicely with Rust's powerful enums. If you design a compact data structure for cache efficiency, it's quite common to want to pack things with special bits, like: enum My64bitThing { None, Active(u62), InActive(u62), Special(bool, u61), } It's painful that despite Rust's powerful type system, such structures are actually easier to work with in C than in Rust.
This throws at me a doubt: Standing on top of a unsafe memory platform (or at least platform built with bug prone bricks and approach) can we achieve memory safety? Isn't possible for a self-hosting compiler at this point? Or is in the pipeline?
it has been possible for a long time with [nom\_locate](https://github.com/fflorent/nom_locate) which provides an input type that carries line and column information. I have not tested it yet with nom 5, but it should be straightforward to port to the new version
&gt; A niche? Believe there are over 1 billion Apple hardware users out-there. And that may be a low number. -) Yep. There's a range of products/devices that don't use Apple hardware. The reach of the internet far exceeds Apple devices, as does Android hardware, let alone Windows/*nix machines. If you're a big fan of Apple and that's the market you want to target, great, go all in. I prefer to write applications that can reach more than just Apple devices, and I prefer to do that with technology choices that enable me to do so across multiple platforms without having to maintain separate codebases as much as possible. Rewriting UIs in a variety of languages each with their own pros/cons costs more time and more than likely money if you're hiring talent skilled enough to work on each separate tech stack. If you have a specific demographic where that sort of reach or reduced cost is not an concern, then you can take advantage of platform specific technology available to you and cater the UI/UX to take advantage of what the platform offers. I'm personally not a fan of writing software in something that I cannot use out of their ecosystem/platform. So while I may be interested in catering to a demographic that's far more niche (linux users), my software also works on Windows and macOS, and if the software also has a mobile app, Android and iOS. If I need to tap into anything specific for any platform, I usually can, it's just more work to do so. &gt; Think one thing to re/focus on is that Apple is not churning out another "JS like language." The market is flooded with them. JSX isn't a JS like language, it is JS, just with a markup extension that makes the UI part of code that much easier to work with. If you want to, you can write it with pure JS, but nobody really does that. That aside, React roles are in good demand and pay pretty well too, I've seen some around 100-150k (and more but that's rare). &gt; Google and Facebook's main goal is to sell Ad's. That's how they survive Funny, not a single Ad in any of my software using React, how is that relevant? &gt; Apple is a hardware company, Kinda. They still use Intel/AMD/Nvidia(at various points in time), they're more of an integrator with fancy design on the exterior. Usually at ridiculous prices, like that recent $999 monitor stand, that Apple fans defend for some reason as an acceptable price for the functionality/aesthetic. They've shafted nvidia with recent versions of their OS rejecting any newer hardware, so if you wanted to use ThunderBolt with an eGPU of the current nvidia models since they're the only ones with CUDA and certain software only accelerates on the GPU with CUDA cores, you're out of luck if you want to run the current macOS, shows how much they care about their users(Nvidia is more than happy to support their hardware on macOS, Apple just refuses to collaborate). In the past, their mobile hardware relied on Samsung quite a bit for CPU and I think memory as well? Not sure about display, it's been so long since I last cared to know about this stuff. The GPU was from another vendor(whom I think Apple may have acquired since, I can't recall, I know they've got their own CPU design now). Point is the actual hardware usually isn't anything special, they just charge a large amount for it. You could get the same quality from a non macOS vendor too if you wanted to pay that much without having to think. Otherwise, if you know how to pick quality hardware, you're not going to have issues there, then it's up to the OS(personally I don't enjoy macOS, I think it's great for a casual user but it would often get in my way or do some weird shit). One last thing I recall from my last mac experience mid 2016. Their wireless mouse product, it ran out of battery charge, and presumably for aesthetic purposes rather than functionality, the charge port was on the flat surface at the bottom, so while charging you could not use the mouse and continue to be productive... I've witnessed my fair share times where the OS itself crashes over the years on a variety of mac machines, so I really don't understand the praise/genius that it's fans attribute to it. &gt; SwiftUI is not an "animation" builder. Who told you that? Don't follow that pundit. OMG. I was quoting the article you linked me, which only really touched on the animation benefits SwiftUI was bringing? I couldn't be bothered to listen to 45 minutes of something that is highly unlikely to interest me or convey any real innovation. &gt; PS, post any software/hardware links, I'll read, and listen to them all. I just build things. :-) ? There's plenty of that on the web if you want, just use Google or participate in communities of interest?
as usual - knows the language inside-out, can answer most random/comvoluted questions.
Suggestion of continuing to invent the same thing independently.... Name checks out.
the design is still different. Combine uses an API a bit like futures while nom is mainly a set of functions. We'll see how the UX and perf compare once combine 4.0 is out
Ok, thanks for the writeup. At least check out the Reality Kit video, it's crazy! I'm into AR, Apples got the lead there for sure. Their glasses will be out in a year, will change it all. :-) It's just so much fun to code in Apples world. Never found it really "fun" elsewhere. But that's me.
Yes of course. Memory unsafety in the compiler doesn't mean programs compiled by this compiler will be memory unsafe.
You're replying to the wrong comment. Anyway, I don't think git is complicated, I just don't think your initial "what's so difficult to understand" comment was helpful, because it contrasted checkout changing files and reset changing HEAD, which is only sort of true, but misleading.
It's meant to be a co-invent!
Well, if you don't want a `Vec` you could use a `Box` ;-) fn main() { struct Me { values: Box&lt;[u8]&gt; } let s1 = Me { values: vec![1,2,3,4,5].into_boxed_slice(), }; let s2 = Me { values: vec![1,2,3,4].into_boxed_slice(), }; let s3 = Me { values: vec![1,2,3].into_boxed_slice(), }; } You could also keep the length as part of the type and then "erase" it when needed: fn main() { struct Me&lt;T: ?Sized&gt; { values: T } let s1 = Me { values: [1,2,3,4,5u8], }; // Me&lt;[u8;5]&gt; let s2 = Me { values: [1,2,3,4u8], }; // Me&lt;[u8;4]&gt; let s3 = Me { values: [1,2,3u8], }; // Me&lt;[u8;3]&gt; let r1: &amp;Me&lt;[u8]&gt; = &amp;s1; let r2: &amp;Me&lt;[u8]&gt; = &amp;s2; let bx: Box&lt;Me&lt;[u8]&gt;&gt; = Box::new(s3); } There are other options but at this point (without knowing your requirements), I'll just stop here.
I'm not sure I'm quite on board with keeping Rust below the application level but I think your point of view is perfectly reasonable and such a strategy would be very successful. I've been programming with Rust for all of about 6months and am still pondering it's application level usefulness. I'm encouraged by this observation: The more I use it , the more productive it seems to reveal itself to be. That may seem obvious and true for other languages but in Rust, it seems more so. Having said that I'm definitely still in the childlike naive state of "(re)Write everything in Rust!"
It's gonna give nightmares to me now on. What I mean is, by having all the unsafe code under the hood (in std library) we kind of passively force ourselves to think that we're developing a memory safe program/software but actually not. This gains importance when a carefully written unsafe block in Rust is equivalent to a carefully written C/C++ block. Now I begin to question my faith that Rust is a memory safety language. With out any offense, Placing all the unsafe blocks (unsafe: in Rust terms) in the standard library kind of covers the mistakes/errors in language implementation from most developers and leaving/relying only experts for finding/fixing implementation caveats in Rust, such as the above one. I may be completely wrong, but would like to hear from fellow Rustaceans. &amp;#x200B; I am not a proponent of C/C++. I have had hard time learning them and one fine day quit banging my head against the C/C++ wall and switched to Rust and committed to stay with Rust, even if it is not a memory safe language (pardon me for making this comparative statement).
TCP is built as a reliable connection protocol on top of an unreliable communication stack. Just because some layer is potentially faulty doesn't mean that you can't build reliable systems on top of it.
Here are some types that all are a Box&lt;Iterator&lt;Item = u8&gt;&gt; let iter_1 = Box::new((0..5)); let iter_2 = Box::new("Hello!".bytes()); let iter_3 = [0..8].into_iter(); An Iterator is just a trait. The type that actually implements the trait can vary wildly, and this type information is kind of "lost" when you box it (provided you don't use the Any trait). Thus the compiler cannot actually tell what size the dereferenced Box will be, since it does not have a known size.
The [server](https://github.com/thedevs-network/kutt) is MIT-licensed and implemented with Node.js.
The Linux memory allocation strategy is to just promise whatever requested memory is available and to kill processes to free memory if it isn't. Hardware itself is unsafe. For example the [Row hammer vulnerability](https://en.wikipedia.org/wiki/Row_hammer), it involves toggling a whole row of memory on and off, causing nearby bits to get flipped. Background radiation can do the same. ECC memory can help somewhat but if the processor is hit it won't. The universe itself is unsafe. Shrinking the size of processors runs into the problem of quantum particles randomly popping into existence that can cause transistors to get flipped. But there is a point where the chance of something happening is very low that it is unlikely to happen ever.
But why the version without dereferencing compiles?
So we're programming in C++ now? 🙄
Maybe there could be another approach to write pac and hal crates. Is there another MCU on market that uses Xtensa processors? If so, there could be a chance to dig into it (as far as I think).
C++ compiler output is useless tho? Why the comparison?
Every memory safe language is built on top of unsafety, with safety enforced by the compiler/vm.
By that argument no language is memory safe, making the whole concept of safety completely useless. What rust gives you is that unsafety can be hidden and conveniently packaged, so that you wouldn't need to think about it when writing your own code. Most safe languages accomplish this by keeping all that unsafety in the standard library and runtime, and not even letting you create any new abstractions.
&gt; At least check out the Reality Kit video, it's crazy! Nope, sorry it's almost 3.30am here and I really have very little interest. AR is cool, but I don't have the time atm to get into it myself, nor the hardware(I've got a good phone that should be capable but official AR support on android devices isn't as good(mine is bit too old I think and some recent politic issues, Huawei Mate 10 Pro). If I could I'd combine it with a hobby I had, photogrammetry. I [made this statue](https://sketchfab.com/3d-models/statue-temple-wind-lion-d07e885e8c4e42e2b7b9ab78f22fd881) and [this pizza](https://sketchfab.com/3d-models/pizza-slice-optimized-7de0fd39416e4910a28fc23d3c887d53) via photos from my phones camera and some photogrammetry software(followed by a bit of optimizations in Blender), if it's your first time on sketchfab, wait for the blue progress bar at the top of the viewport to complete as it's loading in the texture data). You could combine those with AR or VR(I did that a prior job but at a full environment scale). &gt; It's just so much fun to code in Apples world. Never found it really "fun" elsewhere. But that's me. I can't comment. I only briefly used XCode and Obj-C(Swift wasn't out at the time but looked like a nice language) to contribute a small feature to iTerm2 when I was using a mac a few years back. Personally I quite enjoy web technologies like React, that's "fun" to me :P All good, enjoy the apple devving and AR stuff(I'm a tad jealous!)
One example is rebasing and force pushing. If someone else is working on the same branch as you, you'll mess up their branch. I've never used bazaar, so don't know how it works in comparison.
Having to watch the compiler warnings and distinguish which ones matter is classic C++ behavior. The Rust compiler isn't supposed to compile code with UB: here it does even though it knows it's doing it. That makes me very sad. I could use the Rust equivalent of `-Werror` in my build or code: heck, I guess I have to. All for "backward compatibility" with code that should never have compiled in the first place. Not really the language I signed up for at that point. I get that there can be compiler bugs, but I would strongly prefer that they be outright fixed when found even if that breaks code that depended on UB to work.
The runtime can and does keep track of the size of the box contents. As long as the compiler doesn't need to know the size of the box contents to generate code it's good.
I swear this guy has written something at least decently popular in every language under the sun.
My guess would be you simply don't know better.
I am guessing maybe in the next edition, as that is an explicit opt-in to new behaviour? Though that might still clash with some backwards compatibility promises. So 2021?
The [RustBelt](http://plv.mpi-sws.org/rustbelt/) project is working on your (very legitimate) concerns. I think you'll find their mission statement interesting. It's a hard problem, but there's some hope of solving it.
This one. I understood most concepts relatively quickly. But I still do not fully understand lifetimes.
&gt;old versions of crates = **public** crates **published on crates io** The more mainstream the language will be, the more projects there will be that are either not public or not published on crates.io (e.g a binary project with git dependencies), and with that crater runs become less of an indicator of "acceptable breakage". Curious to know what the long-term plans of dealing with this are?
Maybe I oversaw somethingm but my impresion is that this time interfaces just supports a single clock, probably the system clock. &amp;#x200B; Just, there are multiple clocks and depending on the use-case a different clock should be used to calculate timeout/deadlines. Please compare with C++ \`std::chrono' supporting std::chrono::system\_clock and std::chrono::steady\_clock. Or, check with C-API \`clock\_getttime\` suporting CLOCK\_REALTIME, CLOCK\_MONOTONIC, CLOCK\_PROCESS\_CPUTIME\_ID or CLOCK\_THREAD\_CPUTIME\_ID. Depending on the use case, one should use one or the other clock, for example * network-protocols timeouts/delays should be based on a local monotonic clock * Visual HMI time representation should be based on the system-clock, probably in sync with GPS or similar. Having a look onto the API of std::time, I am missing the possibility to tell which clock should be used to create an Instant or measuring the elapsed time
Looking through the comments in the thread, I believe you're correct.
I couldn't agree more. The idea that "we can't break code that happened to 'work' [may not actually work on your machine/environment] because of a compiler bug" seems to me to be antithetical to everything I thought Rust stood for. At this point, allowing the compiler to accept the UB described by OP is not a "compiler bug" anymore, it's a deliberate choice. Emitting a warning is not an acceptable design alternative: warnings are missed all the time by competent software developers. If Rust has proven too hard to analyze accurately, it needs to be restricted until it can be. Even if that breaks a lot of existing code. Even if that breaks *all* the existing code.
❤️
Git isn't difficult. It is just badly taught from day one. The proper way to teach is to give an overall idea of the model, the undelrying use cases, and the commands for those use cases. Git teachers are the kind who teach about squares using examples drawn square to the apper, so that when students are introduced to a kite which as 4 sides of equal length with all four sides 90 degrees, they don't recognize that it is also a square. Too many abbreviated commands which don't give a proper view of the model.
This (that reliable systems can be built on top of unreliable ones) is one of my favourite surprising facts!
Shortcuts which don't convey the underlying model is the bane of git. See my other response. I feel a blog post coming on.
&gt; This is a lot of detail but the takeaway to me is that on any platform with support in Rust for these atomics, the current code is not faulty, because it behaves how I expect it to behave on any platform with data-dependence I think so, yes, which is why I prefaced all this with "theoretical". However I am not an expert so I may be overseeing potential wonkiness in either the optimizer or the CPU. &gt; EDIT: I'm also unclear how the memory backing a node being constructed on thread A could have gotten into thread B's cache before it was constructed, I guess by being in a neighboring object's cacheline? Either sharing a cacheline or simply the allocator reusing a previously freed memory cell.
Did you observe any performance penalty in doing so?
That's why there are versions... The problem will be a hard error in the next release. Please read up on how version numbering works. Rust's premise has always been backwards compatibility fyi. So in fact you did sign up for this. Also, not breaking stuff is strongly needed for any serious project. They have to be sure that they aren't required to rewrite their codebase every few months. And we all want to see the language grow, right? So big projects are a must. All of this said, your argument is completely irrelevant. OP asked why the example code compiles. The answer is clearly stated in the compiler message. So, again, if he'd read the message he'd have known. No arguing about that, right? PS: all messages the compiler gives you are relevant. Unlike, as you correctly stated, in C++ where some errors are useless and the result of other errors. Again, compiler driven development.
with `&lt;T: ?Sized&gt;` you get to even coerce a `&amp;MyStruct&lt;[T;N]&gt;` or `Box&lt;MyStruct&lt;[T;N]&gt;&gt;` into a `&amp;MyStruct&lt;[T]&gt;` or `Box&lt;MyStruct&lt;[T]&gt;&gt;`, respectively.
Finally I see someone else having a problem reading the Rust docs. People apparently universally love it (and in [this thread](https://www.reddit.com/r/ProgrammingLanguages/comments/c39ib1/what_do_you_consider_the_gold_standards_in/) even voted as the number one programming language documentation) but I find them very hard to read and navigate!
The easiest way would be to use `include_bytes!` and write it to a temporary directory, but why do you need an external application to resolve a domain?
How about [std::process::Command](https://doc.rust-lang.org/std/process/struct.Command.html)?
Hi, I just modified your code, I didn't change the method. I don't know if it's faster or not, I let you test =) fn modal_of_list(list: &amp;Vec&lt;i32&gt;) -&gt; HashMap&lt;i32, i32&gt; { let mut map = HashMap::with_capacity(list.len()); // Get frequency values for numbers in the list for &amp;i in list { let count = map.entry(i).or_insert(0); *count += 1; } // Only keep values with max frequency if let Some((_, &amp;max_freq)) = map.iter().max() { map.retain(|_, &amp;mut frequency| frequency == max_freq); } map } And to format your code just add 4 spaces to the indentation you want.
That's what I am using currently :).
Looks good, I still haven't tried to profile the code with timers though, will save this to try, thanks!
You probably want to start with Vec, not fixed-size arrays. Vec is usually the most appropriate choice, especially when first learning.
I don't have any benchmarks.
Unfortunately it's not a typical DNS resolver. It's a custom stuff does some magic and gets the private best routes. That's a good idea, writing it to a temporary directory. It does solve my problem but hoping see if there is a way to write to the memory and run from there.
&gt; Unfortunately it's not a typical DNS resolver. It's a custom stuff does some magic and gets the private best routes. Uhm, okay. &gt; if there is a way to write to the memory and run from there You pretty much can't run programs from memory. That's not a limitation of the language, but an artefact of how common operating systems work.
Firstly, this case differentiation would complicate the compiler to the point where it becomes too complex to extend and maintain. Think of all the corner case that would emerge. Secondly, it would break down if more than one crate was involved: Imagine an "old" crate which exports a macro that generates this code. So on its own and as a dependency of an "old" crate, it would still compile but it would not if the dependent was "new" because the expanded code resides in the "new" code. The owner of the library thus needs to rewrite the code to stay relevant to the ecosystem. Not sure if this actually forward or backward incompatibility.
Maybe because there's no C/C++ wall... There's a C and a different C++ wall.
&gt; all messages the compiler gives you are relevant. So I disagree with this very much. Do you really care if a const is not UPPERCASE? You shouldn't, and it has no relevance to safety at all.
So it is possible ... but what you are describing are techniques used by malware and are not portable across OS. Either you are writing a malware or you are looking for an exotic and over-engineered solution to a simple problem.
Thanks for explanation.
Except rig is already taken on crates.io: [https://crates.io/crates/rig](https://crates.io/crates/rig).
I've spent the past year trying to figure out how to support a tool that uses tech that's impossible to hire for, poorly written and nonperformant. I've done lots of thinking around what tech is right for when, and I think that Rust is just not the right tech for "everything, everywhere." Things like how long something takes to get productive with, how long it takes to become totally self sufficient with, how easily can you hire someone with the skills you need, etc. Rust is a language that is very similar to Haskell to me. I know that they are both probably the closest approximations to legitimately "correct" software. I know they both have huge benefits in the medium and long terms. But put a 20 year Java dev in front of a Rust application and ask them to contribute meaningfully, in most scenarios you will find tremendous difficulty. This is what made me land on Go as the "best" (and not most "correct") language for general use. The language is almost *too* simple, so it is easy to ramp up on and easy to understand, and is generally only outperformed by Rust, C and C++, so performance conerns aren't too intense. I think lots of people could tackle a Go project much faster, and with a much higher likelihood of success than in Rust. Go's footprint is just so much smaller.
swym is currently locked on nightly because of 1 feature flag it needs. It might be on stable in a couple months or so depending on whether I'm willing to settle for an extra indirection or not. I'd say the niche swym primarily fills is making it possible to implement certain data structures concurrently. The red black tree demo data structure for example is the only concurrent red black tree in rust AFAIK, and outperforms lock-free skiplists. Implementing a lock-free red black tree would be a very challenging task.
&gt; So PyOxidizer is for packaging Python software into executables cross-platform? Yes... depending on how you define "cross-platform". According to the docs... * It can currently build for Linux if you run it on Linux, build for MacOS if you run it on MacOS, or build for Windows if you run it on Windows. (In other words, it's currently like [japaric/trust](https://github.com/japaric/trust) in that you'll need to use AppVeyor and Travis-CI for cross-compilation.) * True cross-compilation (eg. building for Windows while running on Linux) is still on the TODO list. When reading through the docs, I found that the most illuminating explanation of PyOxidizer is the[comparisons with other tools](https://pyoxidizer.readthedocs.io/en/latest/comparisons.html) page. &gt; I haven't tried the rust crates like PyO3 that are meant to let you use Rust to some extent when writing Python software, are those usable with PyOxidizer? I haven't tried them but, judging by what I read in the docs, I'd assume that it'll work as long as you properly integrate them into Python's packaging system so that `setup.py build` or `pip install` can properly set them up. (eg. by building a wheel for each Rust project using [pyo3-pack](https://github.com/PyO3/pyo3-pack) or integrating Rust into a Python project using [setuptools-rust](https://pypi.org/project/setuptools-rust/)... both of which support PyO3, rust-cpython, and approaches based on manually using Rust's C FFI support without libpython such as Python's `cffi` module.)
I have a little piece of code that uses `impl Trait` with a long trait declaration in multiple places, and I'd like to avoid this repetition. I'll try to extract a bit of code from my codebase here, I hope it's enough context to understand the use-case. These are the types I use in the examples: type Token&lt;'a&gt; = &amp;'a str; #[derive(Debug, Clone, Copy)] struct Input&lt;'a&gt; { // a pointer to a slice of grapheme clusters source: &amp;'a [Token&lt;'a&gt;], } type ParseResult&lt;Result&gt; = Option&lt;Result&gt;; Then I have multiple functions in this format: fn map&lt;A, R&gt;( parser: impl Fn(&amp;mut Input) -&gt; ParseResult&lt;A&gt;, map_fn: impl Fn(A) -&gt; R) -&gt; impl Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt; { move |input| parser(input).map(|result| map_fn(result)) } As you can see, there are a lot of repetitions of `Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt;`, and I have trouble dealing with it. -- First I tried to use a trait alias: #![feature(trait_alias)] trait ParseFn&lt;R&gt; = Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt;; fn map&lt;A, R&gt;( parser: impl ParseFn&lt;A&gt;, map_fn: impl Fn(A) -&gt; R) -&gt; impl ParseFn&lt;R&gt; { move |input| parser(input).map(|result| map_fn(result)) } This does not work, the return type gives me a type error: trait ParseFn&lt;R&gt; = Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt; type mismatch in closure arguments expected signature of `for&lt;'r, 's&gt; fn(&amp;'r mut parser::Input&lt;'s&gt;) -&gt; _` note: the return type of a function must have a statically known sizerustc(E0631) parser.rs(68, 5): expected signature of `for&lt;'r, 's&gt; fn(&amp;'r mut parser::Input&lt;'s&gt;) -&gt; _` parser.rs(70, 3): found signature of `fn(&amp;mut parser::Input&lt;'_&gt;) -&gt; _` type mismatch resolving `for&lt;'r, 's&gt; &lt;[closure@src\parser.rs:70:3: 70:58 parser:_, map_fn:_] as std::ops::FnOnce&lt;(&amp;'r mut parser::Input&lt;'s&gt;,)&gt;&gt;::Output == std::option::Option&lt;R&gt;` expected bound lifetime parameter, found concrete lifetime note: the return type of a function must have a statically known sizerustc(E0271) parser.rs(68, 5): expected bound lifetime parameter, found concrete lifetime -- Alright, the feature is still unstable, so it might simply not work right yet. So I tried to define an actual Trait for the Trait with the same usage: trait ParseFn&lt;R&gt;: Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt; {} impl&lt;R, F&gt; ParseFn&lt;R&gt; for F where F: Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt;{} This gives me a different error for the return type: trait ParseFn&lt;R&gt;: Fn(&amp;mut Input) -&gt; ParseResult&lt;R&gt; type mismatch resolving `for&lt;'r, 's&gt; &lt;[closure@src\parser.rs:70:3: 70:58 parser:_, map_fn:_] as std::ops::FnOnce&lt;(&amp;'r mut parser::Input&lt;'s&gt;,)&gt;&gt;::Output == std::option::Option&lt;R&gt;` expected bound lifetime parameter, found concrete lifetime note: required because of the requirements on the impl of `parser::ParseFn&lt;R&gt;` for `[closure@src\parser.rs:70:3: 70:58 parser:_, map_fn:_]` note: the return type of a function must have a statically known sizerustc(E0271) parser.rs(68, 5): expected bound lifetime parameter, found concrete lifetime type mismatch in closure arguments expected signature of `for&lt;'r, 's&gt; fn(&amp;'r mut parser::Input&lt;'s&gt;) -&gt; _` note: required because of the requirements on the impl of `parser::ParseFn&lt;R&gt;` for `[closure@src\parser.rs:70:3: 70:58 parser:_, map_fn:_]` note: the return type of a function must have a statically known sizerustc(E0631) parser.rs(68, 5): expected signature of `for&lt;'r, 's&gt; fn(&amp;'r mut parser::Input&lt;'s&gt;) -&gt; _` parser.rs(70, 3): found signature of `fn(&amp;mut parser::Input&lt;'_&gt;) -&gt; _` -- Why does none of it work? What do the errors mean exactly? And what options do I have instead?
Every program has to be written to memory for it to execute. That's what your os does. So its should be possible but I just dont know.
How about grit? (I think it's avaialbe!).
True memory safely is impossible because hardware is imperfect and buggy.
You should care. Conventions exist for a reason. It's all about making it yourself easy. Conventions promote consistency which in its turn results in a more streamlined programming process. For yourself as well as your coworkers.
Yes, exotic is the right way to put it. I think what wellmakeitsomehow seems like a solution for now. I do would like to hear other ways just for the sake of learning :)
Everyone else thinks his some kind of alien intelligence trapped in a government dungeon somewhere with a few hours of internet a week? No takers? Ok, it's just a theory
Programs usually need to load libraries from disk, and those libraries often don't know where they will end up in memory. You also want to share them, so if 10 running programs use the same library, you don't load it 10 times into RAM. All this (and probably more) is the job of an operating system component called "loader".
Did you try doing what the compiler literally told you to do? ``` expected signature of `for&lt;'r, 's&gt; fn(&amp;'r mut parser::Input&lt;'s&gt;) -&gt; _` ``` I'm not saying I'm sure it will work but it's usually a waste of time trying to come up with other solutions when the compiler has already given you one. You need to add lifetimes to your trait, either universally quantified like the compiler said or maybe bound to the definition of `map` (but probably the former).
Currently working on my orthogonal array library, oars. I started writing it for some graphics research I started writing a while back, and our paper actually ended up getting published. Rumor has it my advisor is thinking about switching his graphics class from C++ to Rust so I think I might’ve had some influence!
*&gt; The idea that "we can't break code that happened to 'work' [may not actually work on your machine/environment] because of a compiler bug" seems to me to be antithetical to everything I thought Rust stood for.* Let's calm down before we begin putting words in the mouths of the compiler developers. The stance of the Rust authors is that any undefined behavior that is achievable from code that doesn't use `unsafe` represents a bug (a "soundness hole"), and will eventually be fixed, even if they break backwards compatibility. In the past these sorts of bugs have indeed been discovered and fixed, breaking stable code in the process. Afterwards, people whose code had broken asked for more forewarning next time. Therefore, these days any breakage due to fixing soundness holes is evaluated against the body of code on crates.io, and high-risk changes are introduced gradually in order to give people a chance to fix them before the warning is turned into a hard error. If we take the time to read the compiler warning that the root commenter of this thread took the time to quote: "warning: this error has been downgraded to a warning for backwards compatibility with previous releases warning: this represents potential undefined behavior in your code **and this warning will become a hard error in the future**" [emphasis added]
Why do you think it should cause an error? Rust isn't c++. Nothing is being "imported". Names are being brought into scope. There's no reason bringing a name into scope twice should be a problem, and besides, `use std::prelude::*;` and `use std;` *don't* bring the same names into scope.
Others have covered the compiler warning. But another option is to put #!\[deny(warnings)\] in your crate root. That way this (and other potential bugs) will have to be fixed in order to compile the crate. See [https://github.com/rust-unofficial/patterns/blob/master/anti\_patterns/deny-warnings.md](https://github.com/rust-unofficial/patterns/blob/master/anti_patterns/deny-warnings.md)
By reading the compiler warning quoted above, one will see that the idea that stable code cannot be broken by soundness fixes is mistaken.
&gt; The only thing I'm surprised by is that the fix isn't deny-by-default, an error but one which could be overridden on a case by case basic basis. This is how breakage-from-soundness-fixes has been handled for a good while now: first a compiler is released with the fix as a lint warning (so that users can deny it if they want), then a compiler is released with the fix as a lint deny (so that people can explicitly opt into unsafety if they have some good reason to), and then a compiler is released where the code no longer compiles regardless of lint settings.
The only reliable, cross-platform execute-from-memory solution I can think of is to patch `resolve_dns` to build as a library and then statically link it into your Rust program.
Information wants to be free after all ;-) It’s called process hollowing under Windows: you load a random program in a stopped state (as a debugger would), empty the original program from memory, replace it with your own code then resume execution. You can do something similar under POSIX system using the ptrace system APIs (originally made for debuggers). Thing is, you need to handle dynamic library loading by yourself. Under Windows you have APIs for loading DLLs in a remote process. But under Linux you have to do it from the process itself so you have to inject a shellcode to bootsrap the process... Under macOS I think you can do something similar than under Windows using the Mach ports APIs but don’t quote me on that. Anyway, exotic and not really stable ^^
Worth noting that I raised this issue in [#32187](https://github.com/rust-lang/rust/issues/31287) which was mistakenly closed during NLL cleanup. It was re-opened so hopefully will be fixed again in the future.
The bug that allows this has been fixed, though the fix is still working its way through the breakage mitigation procedure, which is why currently the compiler only issues a warning that will become a hard error someday. Tracking issue at https://github.com/rust-lang/rust/issues/31287
Try annotating the type of `input` in your closure: ``` move |input: &amp;mut Input| parser(input).map(|result| map_fn(result)) ``` It's interpreting the closure as a plain `fn(_) -&gt; _`, when it needs to have an HRTB (`for&lt;'a&gt; fn(&amp;'a _) -&gt; _`.)
Nice! Doing the same https://github.com/afnanenayet/weekend-ray-tracer
I don't see a reason why a long-term plan would be necessary, given that the percentage of libraries broken by any given change should still be representative regardless of the amount of Rust code out there that isn't in crates.io. One would need to assert the existence of a type of coding style that exists exclusively in private repositories. Furthermore, the Rust team offers a service wherein they will agree to sign NDAs in order to procure proprietary code in order to expand the backwards-compatibility test suite. Crates.io isn't the only thing that gets tested.
Feel free to leave a comment asking this question in the tracking issue at https://github.com/rust-lang/rust/issues/31287 .
&gt; the compiler only warns on it instead of erroring because code was found that depended on this behavior. The aforementioned warning further notes that this behavior will become a hard error eventually. The warning exists to enable users to gradually discover any issues they may have and correct them before then.
But it makes no difference in functionality. If I'm using a crate that has a bunch of non-uppercase consts, I really don't care about that, I just use the API the crate provides. On the other hand, if a crate just happens to have the bug this thread is about, it *may or may not be causing UB* and that is something I care very much about. If said crate only causes UB in very specific circumstances, it is entirely possible for the bug to go unnoticed, and because this warning is thrown in with all the other warnings it might get glanced over because I didn't care about the other 99 warnings this crate generated, why would I care about this one?
Current syntax for specialization(nightly only) looks like this([Playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=846b6ac3c08a31414d2142665a4c5f3a)): #![feature(specialization)] trait Traito { fn functo(); } struct Structo; impl&lt;T&gt; Traito for T { default fn functo() { println!(":("); } } impl Traito for Structo { fn functo() { println!("Hello, world!"); } } fn main() { i32::functo(); Structo::functo(); }
&gt; heck, I guess I have to. Rather, one merely needs to not freeze their version of Rust for all time, because this will become an error eventually, as noted in the warning itself.
thank you, very interesting! I want something stable so i will go with dumping it into a temp dir :)
Entropy is a bitch.
I haven't come from a c++ background but maybe I haven't been clear. The `std::prelude` documents state that 'std' is brought into scope on every crate. Not sure why it's in the prelude docs and but that's where I found the note. Try importing anything else twice and you get an error.
&gt; Furthermore, the Rust team offers a service wherein they will agree to sign NDAs in order to procure proprietary code in order to expand the backwards-compatibility test suite. Crates.io isn't the only thing that gets tested. Oh okay, I wasn't aware of that. That's certainly reassuring, and the reasoning makes sense. Thanks for the response!
Soundness bugs are exempt from the usual back-compact rules, I think they're done on a case by case basis.
To clarify on what's happening here: when the borrow-checker was rewritten last year to support non-lexical lifetimes (NLL), an open question was how much code in the wild using the *old* borrow checker would no longer compile--despite the fact that the new borrow checker implements a superset of the rules of the old--due to bugs in the old borrow checker (thereby allowing code that cannot be proven to be safe). If the answer to that question was "essentially no code in the wild relies on this buggy behavior", then the change could be classified as "low-risk" and the compiler authors could just bite the bullet and make the change in a single go, since the stability guarantees explicitly allow breaking code that was unsound due to bugs. However, any higher amount of breakage means that a mitigation procedure has to be carried out wherein code that *would* break is first warned about before becoming a hard error. The Rust compiler currently achieves this by running *both* the old and new borrow checkers on code as it compiles, and issuing warnings like this when code is rejected by the new one but accepted by the old one. Periodically tests such as the one linked above are performed in order to gather information on how soon this transition can be completed by ripping out the old borrow checker altogether.
No problem. :) Indeed, I know there are a few large companies that have been taking advantage of this service for some time.
Alternatively, this issue may be the relevant one: https://github.com/rust-lang/rust/issues/58781 , which tracks the switch that #31287 is waiting to be flipped.
The std library documentation says "A measurement of a monotonically nondecreasing clock"
1. Entirely your fault for not giving a shit. Rust pushes really hard for good code quality (mentioned warnings, clippy, cargo fmt, ...). If you disregard that stuff then that's on you. Again, this is all for your benefit. 2. I'm pretty sure dependency warnings aren't shown together with the warnings of your own crate. Disregard the libraries and focus on your own. If it's a problem in the library, people will see it when contributing/testing/etc. as it is the top crate in their case. If the library isn't actively maintained it's better to look for another in general. To sum it up: * it can't be an error (in this version) because it would break code. We don't want that otherwise big projects won't ever use Rust and the language won't grow. * a warning is *almost* as important as an error. There is a reason why flags exist to get more warnings and treat warnings as errors. It's there to help make everyone's life as a developer less stressful. And don't we all want less complications in life? Less grumbly coworkers cursing over some triviality? Maybe there should be a special flashier and more important looking warning? But where does it stop then?
Indeed, the transition timeframes are individually considered depending on the observed magnitude of breakage on code that the Rust team has access to. The Rust developers have also been known in the past to manually issue PRs to repos that are at risk of breakage in order to accelerate this timeframe.
Very cool!
Imports. In Java/IntelliJ you can cmd-shift-O, and it resolves everything, and prompts when it is ambiguous. In Rust, you have to write it all yourself. &amp;#x200B; It's particularly an issue when refactoring/moving code between modules.
Maybe this already exists, but there could be a build build flag to treat all "future hard errors" as actual errors, at least that way I can easily audit any crates I use without needing to waste time looking through other warnings that I probably don't care about.
I actually like the colon syntax. Struct construction isn't a series of assignments, it's more like a function call that takes a bunch of variables, and returns a Struct value. You can't write: MyStruct { field_a: u64, field_b: u64 } let struct = MyStruct {}; struct.field_a = foo; struct.field_b = bar;
Your argument is definitely stronger in the context of "putting a 20 year Java dev in front of a Rust application". I can't really disagree with that! I've been looking at some Go recently, As an exercise I started going through the "Write an interpreter in Go" book but using the Go code as pseudo-code and implementing in Rust. I don't know if that's very wise but so far it's fun. I suppose that goes to your point about how quick it is to pick up the language. I don't know Go but I can still read and understand it well enough to convert to Rust. The inverse would not work nearly as well.
But does it use Arabic numerals?
Correct. Make no mistake, I think Rust is the better language with respect to the quality of the language itself. I just think that Go is better for general use, by actual real live programmers.
Yes, but then I receive the nondescript error `hidden type for 'impl Trait' captures lifetime that does not appear in bounds`. However, together with the suggestion from /u/asymmetrikon to explicitly annotating the argument type of the closure, it compiles (but then it also does without the explicit lifetime arguments). The lifetimes there would also be pretty difficult (map having to define 4 lifetimes with varying interdependencies to properly portray the situation as far as I noticed from trying around), not something I'd want to have to type out for every function.
Well, you have: 1. **Merge.** Messes up history, throwing off any history analysis such as bisection. Example: merge `feature1` to master and then `feature2` to master; expected history: old master &gt; feature1 &gt; feature1+feature2; instead you get a weird mix of half-baked feature1 and feature2 in your history at most points, even though those states have never existed in master. Requires ad-hoc, untracked manual conflict resolution, so it's impossible to audit later whether conflict resolution was done correctly - or whether it was performed at all, so good luck figuring out why something broke after a merge! Impossible to return to pre-merge state by simply going one commit back, now you need to revert the merge. This interacts in conflict resolution in interesting ways and generally causes fallout in unexpected places later on. 2. **Rebase.** Frankly I never used it, [but people are very vocal about advising against it](https://medium.com/@fredrikmorken/why-you-should-stop-using-git-rebase-5552bee4fed1). 3. **Squash.** Gets you sane history in master for once, without the weird invalid states that have never existed. There is just one problem: it loses data. Every single feature branch is now a single commit, with no history or rationale for individual decisions. It makes `git blame` useless too. `git bisect` now kinda sorta works but can only point to a branch, which might have had hundreds of commits. But you still have the original fine-grained commits, with authors and rationales in commit messages, in a branch so you can look them up if needed, right? WRONG. All of your fine-grained history will be lost on the next `git gc`. And this is a method that Github allows as one of the 3 good ways of merging a branch in its web UI, without any warnings! I think git is the only post-2005 revision control system that actively destroys history in the course of normal operation. And this is just one, more glaring aspect of how utterly unusable git is as a revision control system. The waste of productive hours in teams spent on babysitting git is enormous, it's nearly as bad as older C build systems. Git needs to be sent the way of Autotools and forgotten like the nightmare it is.
This works perfectly as far as I see (even with the trait alias), thanks a lot! I wonder why the type isn't properly detected there? The only thing changed is that a trait alias is used, intuitively the behavior of the code shouldn't change because of that.
I'm not quite sure either. I wonder what lifetime it's attempting to infer? Maybe something to do with [this open issue.](https://github.com/rust-lang/rust/issues/58052)
I am not sure what you are asking, but I think the simplest answer is pure absolute memory safety is a pipedream. There isn't some feature that is "no issues anymore" that someone can work on. Compilers are software. Software has bugs. In compilers for "safe languages" like Haskell, python, or Rust, those bugs can break memory safety for the produced code, even if the compilers are themselves written in safe languages. Theoretically (and in actuality for a few research compilers), you can prove a compiler correct, but that is not to my knowledge anywhere near in the works for Rust. That would be a crazy undertaking, even if you stopped adding features to the compiler to keep a static target. Even if you did prove it correct, you would have an insanely complicated theorem that you proved. How do you know that the theorem even means what you want it to mean? Even if all the software was perfect, a random cosmic ray could screw up a calculation. Even if you have redundancy or error correction, you could have a bigger cosmic ray or an underlying hardware issue cause a problem.
Empty crate, empty repository, empty GitHub identity. There really needs to be a process to deal with these sorts of packages.
To move an object out of the box, you need to know its size. To call `next` on it, all you need to know is which function `next` is and then give that function a reference to the object, which are both stored in the trait object.
&gt; wym considers a thread to have made progress if a transaction has successfully committed, encountered an uncaught panic, or returned AWAIT_RETRY. A lock returning "_retry the lock_" isn't making progress.
You know it
Never used it, but for comprehensions there’s cute: https://crates.io/crates/cute
Extremely useful exploration of the design space, good job!
The later. Why rewrite something that exists and works. The biggest reason would be that you want to do something differently this time.
Sure. I don't much like it either as currently, the more money you have, the more you can use various schemes to avoid paying taxes, so the less of your income you pay relative to poorer people. However, it currently IS legal.
Why would they be? Rewriting is a huge endeavour. Rust is great, but existing things that work well are unlikely to be rewritten in it without a _**very** good_ reason.
&gt; However, it seems to me that the mechanisms that let you hide it from one party can be used for the other unless you propose some way for the authorities to get access to this data on a non-voluntary basis. The current banking system. Yes, the banks can see your information, but unlike Facebook, the banks are in the money business and (in theory, of course in practice its often not the case...) aren't making money off selling your information or mining your transactions. Facebook are in the advertising business, which in this day an age means mining your data to be used against you. They benefit greatly from seeing your purchase history. Its like how Apple lately cares more about privacy than Google: one makes money selling you devices, the other makes money from your data. &gt; There are things that should be part of the public record for things that individuals and companies do. Sure, but there is far more that is not anybodies business and I think its super dangerous to erode privacy and personal rights for this. The criminals will find ways to launder their money or hide their transactions in some way. Politicians will find a way to take their handouts and bribes. The average citizen will have all their shit on public display, whether they like it or not. I would much rather live in a world where all money transactions are private, even illegal ones or ones that really should be public knowledge, than in a world where all transactions are public.
&gt; I would much rather live in a world where all money transactions are private, even illegal ones or ones that really should be public knowledge, than in a world where all transactions are public. This might work if you favor laissez faire capitalism but not if your goal is to maintain at minimum a social democratic form of government (which I consider a baseline for any civilized society [the US is not a civilized society]).
/u/alexendoo's suggestion to use `notify` is a good one. In case you're curious about the API that Linux exposes (which `notify` uses), have a look at the Linux kernel docs for [`inotify`](https://linux.die.net/man/7/inotify) and check out the [`inotify` crate](https://crates.io/crates/inotify) that binds to it.
The statement I’ve heard that has resonated most with me is that git isn’t a version control system, it’s a database for a version control system that comes with a database administration tool. Making your developers work directly with git is akin to making your accounting system users use raw SQL. Can they do everything they need to? Absolutely. Can they fat finger something and cause a royal mess, also absolutely. The invariants that git guarantees are too low level and more like foreign keys than the necessary double-entry accounting ledger entries. What we should be doing, and what GitHub has done to a certain extent, is building workflows on top of git that maintain specific higher-level invariants of a team’s workflow and simplify the overall mental model. Lots of teams do this informally, but it’s mostly through a “pretend like these git features don’t exist” head-in-the-sand approach that, invariably, leads to some developer straying outside the prescribed workflow and some resident git expert who has taken the time to learn the underlying data model being needed to get the team back into a usable state again. I’ve been that “git guy” in a number of orgs where I’ve worked, so I have to acknowledge that, despite my being able to learn and understand that underlying data model, many developers struggle to get that and are limited to regurgitating the few commands necessary to get their code committed and merged. I used to be with you that all developers should go through the learning process that I did and that there was nothing wrong with git. But it’s just been way too consistent an experience seeing people struggle with it and, eventually, you have to concede that there’s a problem with the tool, and particularly the interface to the tool.
This is sick. This reminds me of what I learned of Idris type level programming, but in fast.
RIGged
Hi, you just need to add `move`: self.slices.iter().enumerate().map(move |(index, (start, end))| (index, &amp;self.buffer[*start..*end]))
You can shadow all prelude imports. e.g. `use std::convert::From;` also compiles even though From is in the prelude.
``` let c = 'A'; let matches = match c as u32 { 0x9 | 0xA | 0xD | 0x20...0xFFFF =&gt; true, _ =&gt; false, }; dbg!(matches); ```
Very neat. Big fan of how it's designed, I think I'll learn loads perusing your code.
... My Third Strike player instincts have blended with my interest in working with rust... ....I know little about linear algebra... I confuse.
cool i will take a look later :)
Just a guess, but I bet the vast majority of git users don't even know what the reflog is.
&gt;A lock returning " &gt; &gt;retry the lock &gt; &gt;" doesn't sound like making progress. Or am I missing something? Is that the future's retry enum that you aren't intended to ever return without every scheduler breaking? No. `AWAIT_RETRY` is swym specific. It's a designed to intentionally block. It does the same thing as haskell's [`retry`](https://hackage.haskell.org/package/stm-2.5.0.0/docs/Control-Monad-STM.html#v:retry). Basically it parks the thread and waits for _anything_ in the transaction read set to change, then wakes the thread up and retries the transaction. This can be used to create channels, implement `select` and other fun things. It is not returned when there is a conflict or contention. conc_vec.pop_front(tx)?.map(Ok).unwrap_or(Err(Status::AWAIT_RETRY)) `AWAIT_RETRY` itself is _unfair_ (subject to change) and is similar to a condition variable, but it currently only has `notify_all` semantics. Similar to the code below, except the cond_var is signaled whenever any thread modifies `conc_vec`. let value = loop { let mut conc_vec = conc_vec.lock().unwrap(); if let Some(x) = conc_vec.pop() { break x } else { cond_var.wait(guard) } };
Specialization hasn't been stabilized yet. There's a WIP implementation available on nightly with `#![feature(specialization)]`, but it's not a finalized design and I believe changes are planned. Part of the tricky thing is making sure that out of two implementations, one is always clearly more specific. There's been a lot of discussion on how to avoid ambiguous traits - but the "best" set of rules hasn't been implemented and stabilized yet. I'd recommend checking out https://aturon.github.io/tech/2018/04/05/sound-specialization/ and then following the links back from there if you want more history.
You can do this a bit more idiomatically: use std::ops::Range; struct Struct { buffer: String, slices: Vec&lt;Range&lt;usize&gt;&gt;, } impl Struct { pub fn slices(&amp;self) -&gt; impl Iterator&lt;Item=&amp;str&gt; { self.slices.iter().map(move |r| &amp;self.buffer[r.clone()]) } } You don't need to iterate the first `usize`, because it's identical to the code above but using `s.slices().enumerate()`. The `enumerate()` method takes an `Iterator&lt;Item=T&gt;` and returns an `Iterator&lt;Item=(usize,T)&gt;` where the first value in the tuple is the index of the item. Which is identical to what you're returning. If your string table does not contain any gaps, then it's worth noticing that your `Vec&lt;(usize, usize)&gt;` or `Vec&lt;Range&lt;usize&gt;&gt;` contains a lot of duplicated information. You can reduce that by structuring it like so: struct PackedStrings { buffer: String, // Contains n+1 entries ends: Vec&lt;usize&gt; } impl PackedStrings { pub fn new() -&gt; PackedStrings { PackedStrings { buffer: String::new(), ends: vec![0] } } pub fn len(&amp;self) -&gt; usize { self.ends.len() - 1 } pub fn slices(&amp;self) -&gt; impl Iterator&lt;Item=&amp;str&gt; { self.ends.windows(2).map(move |w| &amp;self.buffer[w[0]..w[1]]) } pub fn push_str(&amp;mut self, s: &amp;str) { self.ends.push(self.buffer.len()); self.buffer.push_str(s); } } impl std::ops::Index&lt;usize&gt; for PackedStrings { type Output = str; fn index(&amp;self, i: usize) -&gt; &amp;str { &amp;self.buffer[self.ends[i] .. self.ends[i + 1]] } }
People vastly underestimate how expensive it is to build large pieces of software. I'm not super familiar with Kafka or Hadoop, but looking at them briefly either of them could plausibly represent millions or tens of millions of dollars work to build. That's as much as a building! Surely you won't advocate tearing down and constructing new buildings every time there was a new trendy idea in architecture or some advance in fire safe building materials, but that's basically what the RIIR crowd is calling for with software.
We’ve encountered a problem that I also encountered, this is not a subreddit for the game rust, it’s for a programming language, go to r/playrust for the game rust, yeah I did the same thing as you lmao
&gt;I think you could replace all `filter_map`s with `flat_map`s, but they are not 100% identical. E.g. they have a different `size_hint` implementation. The `filter_map` *might* be faster due to less allocation in a `collect` context. That was a good guess, but I don't think this is the case. `Vec::from_iter` only uses the first component (i.e. the lower bound) of the iterator's `size_hint`, which is 0 in both cases.
I subbed btw, Hey also if you’re tryna play rust at some point HMU, I’ll teach you the way of the game, except I’m 14...
Depending on what you're trying to match, you might also want to consider using the `unicode_categories` crate and matches like `x if x.is_punctuation_open()` so you don't have to manually keep up to date with what's defined in the Unicode tables.
It's unclear to me exactly why "two layers deep" is a downside? I get that for writing, the current method is slightly longer. But is this really the end of the world? I'd like to say that this is a problem for IDE support and docs, not changing the library design. When reading code, I find the current form much more readable. `time::now()` gives no indication at all what type is returned, while `time::Instant::now()` makes it entirely clear. I'd also be unsure whether `time::SEC` is just a `u32` constant, or a type. To correctly interpret `2 * time::SEC` I have to understand A) that `SEC` is a constant of a different type, B) that cross-type multiplication is being used here, and C) that the type returned from `u32 * Duration` is indeed `Duration` (and not `u32` milliseconds). It's slightly short to write, but I would argue that you'd be sacrificing a great amount of clarity.
What you say is an accurate description of what we are doing right now. That said, it is true that the reason we haven't moved more aggressively is due to old un-updated crates. The fundamental issue behind this slowness is `--cap-lints allow` and the fact that C-future-compatibility lints do not pierce through it. In the future I hope some of they will on an opt-in basis so our migration system can be more effective.
You really need to learn to read a subreddit before posting to it. This sub is for the Rust programming language. You're looking for /r/playrust.
You really need to learn to read a subreddit before posting to it. This sub is for the Rust programming language. You're looking for /r/playrust.
Reddit has a process where one can request an abandoned or inactive subreddit to be transferred to them – /r/RedditRequest. As far as I understand the admins try to reach the previous owner/mod, and if nothing comes of it – it gets transferred to the requester. I wonder if something similar is feasible for crates?
&gt; If the library isn't actively maintained it's better to look for another in general. This makes me wonder - how are the Rust devs going to handle crates that are no longer maintained? Surely there will be some of these, and surely some of these will contain this bug. So if the Rust devs are hell-bent on not breaking code, at what point do they just say "fuck it, if you haven't fixed your code by now that's on you" and make the change? I can see the benefits of making this change on a new edition to prevent older crates from being broken... but that does nothing to help me as a user of Rust ensure that my dependencies aren't affected by this bug. Unless I am expected to check cargo.toml for every dependency, and all of their dependencies, and so on, to make sure they are all using a fixed edition of the language. And even if I choose dependencies that *are* actively maintained (so I can be reasonably sure without having to manually check it myself), I have no idea if their dependencies are *also* actively maintained.
A good candidate would be airflow
Does this mean that non blocking socket though epoll is dead? Or is it a choice? Will async have as good or better latency characteristics?
Or: let c = 'A'; let matches = match c { '\u{0009}' | '\u{000A}' | '\u{000D}' | '\u{0020}'...'\u{FFFF}' =&gt; true, _ =&gt; false, }; dbg!(matches);
Not sure what you mean? That's what tokio does under the hood to drive async I/O.
Is there a new tokio example with async await?
What are the generated code and performance like?
Not *quite* working on master (almost), but here is one: https://gist.github.com/carllerche/d4b5f3fb0c2d3383720ce9835e2420a4
I might be misunderstanding your comment but crates are compiled with your version of the compiler. If you use the new compiler (with OP's problem made an error) but an old crate (bug not fixed), that crate will not compile.
Your CPU is fundamentally unsafe, and will continue being fundamentally unsafe unless you encode memory access semantics into hardware directly, at which point it will not be _obviously_ unsafe, it'll just be buggy and unsafe. Also, even if you do make a fully safe, formally verified CPU, and connect it to any piece of non-fully-safe-formally-verified hardware, all of your memory safety goes out of the window because DMA is a thing that exists. There is no ultimate solution, but also, does there _need to be_?
Tokio uses the best mechanism it can find. If that's epoll on your platform, then that's what it uses. The [networking I/O section](https://tokio.rs/docs/internals/net/) of the docs on the website includes this introduction: &gt; This section describes the network resources and drivers provided by Tokio. This component provides one of Tokio’s primary functions: non-blocking, event-driven, networking provided by the appropriate operating system primitives (epoll, kqueue, IOCP, …)
Is this basically what romio already is, as a prototype? Does that mean romio's finally getting merged back into tokio?
romio, as far as I can tell, was basically a short-term experiment to see how async/await would pan out in an executor like tokio without waiting on the full implementation to transition. It did this by implementing only necessary core functionality, while leaving more sophisticated features, backwards compatibility, and performance as secondary concerns. I don't think there's a reason to use romio in practice, especially in production code, though maybe someone with more knowledge of romio can clarify?
When you say, "char", do you mean Unicode codepoint or Unicode scalar value?
 map.iter().max() This will give you the (key, val) with largest key. I believe this is the fix: if let Some(&amp;max_freq) = map.values().max(){...}
It said moved to future, and I didn't know what that meant. Does tokio entirely uses futures now?
That really does not seem like a valid argument to me. There already has to be checks somewhere that if edition=2018 then warn about dyn Box else no. This would be if strict_edition=2018 then error else warn. The macro thing might make sense, but then you could still just put a note under the error that you can change compat level - and I doubt you want to actually use a library that provides a macro that generates unsafe code like that
Or r/rustjerk, maybe, if it's that meta.
Having unsafe code in libstd is not "covering a mistake/error". Type-safe languages *establish* safety on top of unsafety. The underlying hardware platform has no type system -- aside from raw machine pointers and integers and floating point values. Rust (and languages such as Java, C#, OCaml, and many, many more) *define* their type system on top of the underlying machine model. There will always be aspects of a type-safe language that cannot be expressed in the type system of that language. For example, consider how a garbage collector works. The view of the GC, to the programmer, is that it protects / constraints how memory can be used (by the application). However, in order to actually do its job, the GC must violate precisely those same constraints. It must have access to raw pointers. It must be able to call system calls that allocate virtual memory and free it. This is not a flaw, a weakness. This is how all of these systems work. Some of these systems do a better job of minimizing the unverifiable set of code (the "unsafe" code), but eliminating it is virtually impossible. Please read up on the history and design of type-safe languages. It's fascinating stuff. There's no reason for alarmism, here.
Hmm... what is `#[tokio::main]` doing here? Setting up the tokio runtime? A not-strictly-relevant-aside: I'm not at all a fan of the postfix `await ` syntax in this example. I really had to work hard to find which lines were awaiting. I guess I'll just have to hope I get used to it.
The link says it is moving to async and futures, does that mean the callback based epoll is going to be dead and it will now use async/await and futures going forward? I wasn't quite sure this entirely meant. I realize it is all built on epoll under the hood, but that futures interface comes with some issues and you do give up a little control (eg, I've never figured out how to do heartbeat monitoring efficiently where you need to keep kicking a timer down the road or handle the expiration efficiently). Networking in rust can sometimes be a muddled story that seems to either too high a level or just dumps into using the C api - and I'm just trying to figure out this fits together with the new async stuff and mio and epoll etc. Such as in Java there is an NIO selector that you use to service epoll events in your event loop (which can be done very efficiently), and I'm not sure how that maps onto tokio.
If it's seen as a shadow that helps my understanding. Below was what I wrote to get the docs offline. #[doc(inline)] pub use std; I couldn't find any mention of this after a search, which led me to believe there must be an issue in doing so.
Looks like it's actually [pretty straightforward](https://github.com/tokio-rs/tokio/blob/455782b964df5ea96101085d55298f52fe425bc7/tokio-macros/src/lib.rs#L18-L46). It basically turns ``` #[tokio::main] async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { /* code */ } ``` into ``` fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { let mut rt = tokio::runtime::Runtime::new().unwrap(); rt.block_on_async(async { /* code */ }) } ```
Tokio has always been using futures -- it is just now moving to using `std::future::Future` instead of the `Future` trait from `futures 0.1`. Tokio is specifically an implementation of the core event loop, including I/O polling (reactors) and scheduling of compute (executors), and is built on top of `mio`, which provides the interaction with the lower-level OS features. I haven't found using futures to be a particular obstacle to writing even complex I/O interactions, including heartbeat-like functionality like the one you describe. Is there a particular problem you've run into? The change linked to here is _purely_ about changing which `Future` tokio is relying on, and the resulting compatibility with `async`/`await`. The futures "model", and the underlying execution machinery, is independent of this. I think it's important to point out that you can get as high or low level control as you want with futures + tokio. You can work only with the very highest-level abstractions (like `tower` or `hyper`), you can work only at the low level by writing your own reactors/executors, or you can work in between by writing combinators on top of existing futures at any intermediate level in the stack. I'm not sure what it is you have found lacking in that model?
I'm kinda confused then. What's the difference between old tokio, new tokio (this post), and romio? My guess right now is that new tokio uses the new futures, but not any async/await syntax, and romio uses both the new futures and the async/await syntax. Am I right? If so, is tokio ever going to switch to using async/await where possible, even if it doesn't technically matter?
Async/await syntax is not stable yet, but neither library uses it. They just export types that implement `std::future::Future`, which you can use with `await` if you use a nightly compiler. The difference with romio is that romio is a fork of *just* `tokio-reactor`, whereas this is all of the tokio pieces (well, some are still WIP).
There is tricky bits to this. What kind of constraints do you have on the directory? &amp;#x200B; Can it be a remote directory for example? Depending on how that remote directory is handled, it may not actually support telling you that a file has been created, you may have to crawl the directory and check. Are you checking only that directory for a specific file? or any file? or any file in any sub directory? etc etc etc. I had to write a service on windows to do this very thing and to solve 90% of the problem, depending on the constraints, is dead simple. Grab the correct API, use it. solving the other 10% of the problem (again, depending on constraints), may end up taking 90% of the effort and time. &amp;#x200B; For the vast majority of cases, the notify crate will solve almost all of the problem right off the bat. Just be aware, there are edge cases depending on what you want to do and it may require a lot more effort. remote files, remote directories which are actually API's hiding underneath which can have http connection and security issues, remote directories which are actually mountings for hardware which may or may not correctly report changes, etc etc etc. The list for this is nearly endless.
&gt; Standing on top of a unsafe memory platform (or at least platform built with bug prone bricks and approach) can we achieve memory safety The compiler could be completely safe and generated code could still have a bug. Those are separate things entirely. Similarly, even if the compiler is unsafe, it's pretty easy to add runtime checks for safety if you're really worried. They're just separate issues.
I couldn't run this on a Ubuntu 18.10 Server machine, it failed after the first benchmark with: Running target/release/deps/hashmap-7f96d21a8f64e6b1 Gnuplot not found, disabling plotting Benchmarking hashbrown_rwlock_insert_100k_u64_u64: Collecting 100 samples in estimated 38.300 s (5050 iterations) error: process didn't exit successfully: `/home/matt/code/rs-hm-bench/target/release/deps/hashmap-7f96d21a8f64e6b1 --bench` (signal: 9, SIGKILL: kill) A different machine running WSL got further, but also failed during a different test: Benchmarking cht_insert_100k_u64_u64: Collecting 100 samples in estimated 661.02 s (5050 iterations)error: process didn't exit successfully: `/home/matt/code/rust/rs-hm-bench/target/release/deps/hashmap-7f96d21a8f64e6b1 --bench` (signal: 11, SIGSEGV: invalid memory reference)
Yes, all it does is setup the runtime. Out of curiosity, do you think you will commonly hunt out `await` when reading code or was it just for browsing the example? Do explicitly hunt for fns that might block in synchronous code?
Huh. CHT must have some kind of issue. Care to chime in? u/Razznak
Seems like it's not quite an echo server? It should only be writing back the number of bytes read from the stream, and it should be doing that forever until the connection is closed.
CHT ran out of memory (32GB) for me.
Huh. Alright i did ping the author above. His crate must be faulty. I will remove it from the benchmark until then.
CHT has now been removed. Could you try again please?
CHT has now been removed from the bench. Could you rerun and report back?
You are right, it should be `Vec::with_capacity(1024)` and not `vec![0; 1024]`(i will admit, I didn't run it and the APIs aren't 100% in place either yet). In this echo example, it will be using `Buf` and `BufMut`, which tracks position. So, passing in an empty vec to read will set the capacity on it...
Now \`hashbrown\_rwlock\_insert\` is running out of memory. Could it be something with the benchmark harness?
Huh. This should definently not happen. The values should be dropped after each iteration. Didn't run into this issue myself.
Much of my network code can be framed as this - it isn't a very complex situation, just a couple things going on at once: I have a set of connections/sockets that both read and write. Each socket has a set of logical streams. Each stream has read and write timeouts. Each read or write resets that specific timer (eg - if a write timeout expires I need to push a heatbeat, if a read timeout expires I need to go into a recover more to see if logical stream or physical socket is still okay). There are a set of other timers on there too (eg - a timer that tells me when to write out my event stream). With an epoll loop it isn't too difficult to do this efficiently. I can find the next timeout set to expires (usually O(1)), wait in epoll for that long, when I wake up service any events or timeouts, rinse, repeat. Resetting the timers is pretty easy too depending on the timing structure I'm using. (The timers can be somewhat fine grained so 100ms buckets doesn't often work.) With futures, it has never been very to do this effiently since the isn't a single thing to do a single point in time (a read vs timeout sets the logical stream into a different state). The constant resetting the timers and receive events if not done efficiently can impact the latency of the system (eg - you can't just keep throwing up new timers or cancel/submit read futures over and over). A lot of this does replicate the event pump of async, and I can kind of think through ways to get this to work, but it isn't the most straight forward at times. It is obviously doable with some huge match statements, but not always very clean or easy.
Weird. I’m running last nights nightly on NixOS. If this gets resolved ping me and I’m happy to run it again.
The plural of chain is chains, so why does everyone use blockchain as a plural?
You're posting this on reddit
&gt; `filter_map` ... communicates the intent better than `flat_map` Only insofar as `flat_map` is called "`flat_map`" rather than its true name "`bind`"; and insofar as we don't have a `join` to complete the identity `xs.bind(f) == xs.map(f).join()` nor a `return` to complete the identity `xs.map(f) == xs.bind(|x| f(return(x)))`.
Cool. OK, have an awesome day! Thanks, Will check out the photogrammetry links. Using iTerm right now. :-)
The use case you outline should be pretty easy to implement as a Sink + Stream on top of AsyncRead and AsyncWrite, though without knowing the exact specifications it's hard to say. Also keep in mind that you don't generally want to fully block in the futures context, because there may be other futures you can execute. Instead, you'd want to only do a blocking epoll if there is truly no other work to be done. Tokio will manage all of that for you. You may be right that doing what you want at the high level of async/await will be hard, but operating on top of AsyncRead/Write should be pretty easy. Getting comfortable writing your own combinators takes a little practice, but it's basically what you'll want to do if you want that level of control. And it isn't actually that complicated once you get a hang of the programming model :) I'm also sure the Tokio devs would be happy to help in the Gitter channel!
Wrong sub; this is for the Rust programming language, while you're looking for r/playrust.
I haven’t checked, but I’m guessing it’s nothing special but not horrible.
r/playrustservers seems more like it.
Thanks for your suggestions. I followed your suggestions and made the solution `iterative`. Like this: pub fn solution&lt;'a&gt;( board_stack: &amp;mut VecDeque&lt;(Board, Vec&lt;ChessPiece&gt;)&gt;, solutions: &amp;'a mut HashSet&lt;Board&gt;, tested_configurations: &amp;mut HashSet&lt;Board&gt;, ) -&gt; &amp;'a HashSet&lt;Board&gt; { while !board_stack.is_empty() { let (board, pieces) = board_stack.pop_back().unwrap(); for row in 1..=board.m { for col in 1..=board.n { let new_piece = Piece { row, col, piece: pieces[0], }; if board.is_safe(new_piece) { let new_board = board.place(new_piece); if pieces.len() != 1 { if tested_configurations.insert(new_board.clone()) { let next_board = new_board.clone(); let tail = Vec::from_iter(pieces[1..pieces.len()].iter().cloned()); board_stack.push_front((next_board, tail)); } } else { solutions.insert(new_board); } } } } } solutions } It was only 3 seconds faster.
Tokio sets the rhythm of the async community. Tokio transitioning to std::futures will set off the dominoes, and finally I can use async again without resorting to block_on_all when I want to just do something simple that doesn't need async complexity.
Typo
I am well aware of the issues on the IO threads. I'm pretty good at this stuff and know what I'm doing. I'll look in the AsyncRead/Write stuff though.
Now there's a different SIGSEGV Benchmarking hashbrown_rwlock_insert_100k_u64_u128x16: Collecting 100 samples in estimated 695.18 s (5050 iterations)error: process didn't exit successfully: `/home/matt/code/rust/rs-hm-bench/target/release/deps/hashmap-7f96d21a8f64e6b1 --bench` (signal: 11, SIGSEGV: invalid memory reference) It's probably an issue with WSL, I guess? I think that's more likely than an issue in hashbrown or criterion or rayon, TBH.
I don't know of any linear algebra crates that support `qr_delete()` in particular, but check out [nalgebra](https://github.com/rustsim/nalgebra). There is also [cgmath](https://github.com/rustgd/cgmath) as well, but that's optimized for computer graphics specifically, so I assume `nalgebra` might be better suited for your use case. If you cannot find what you need in there, maybe open an issue or submit a PR?
If it is done that way, then that would be much better that I thought it would be. I guess I was assuming it would be done similarly to keyword changes, where an old crate will compile with old compiler behavior (in that case, ignoring new keywords)
&gt;But it makes no difference in functionality How are you defining functionality here? Rust is a language, a form of communication; it's function is to be read and understood not only by a compiler but also by other programmers and possibly you in the future. When a non-fluent English speaker flubs on tenses it's not unreadable, but it takes an extra moment to get what's being said. Same thing here, you name a const magic_number rather than MAGIC_NUMBER it takes an extra moment to realize that particular magic number isn't being dynamically determined, it makes it measurably harder to fully understand your code. Understanding is the function of code.
&gt; do you think you will commonly hunt out await when reading code or was it just for browsing the example? I think so, for the same reason that I did in the example. They tend to be the most significant function calls in async code, so reading them gives you an overall flow of the function. And they also tend to be the slow ones. Do explicitly hunt for fns that might block in synchronous code? I haven't written a lot of sync code recently. But now that you mention it, I often do do this when reading PHP code. I look for database calls, etc.
I find it generally varies by crate, std and other well known crates usually have better docs. One thing Rust is good at though is that it makes it easy to have docs and doctests that are compiled and checked, thus preventing things from rotting. One language I really dislike are python docs. It's usually a giant wall of text in a guide style, but includes little detail on what the parameters do, nor are there concise examples of usage (something most rust projects have)
You can make a whole web app while only *authoring* Rust with `wasm-bindgen` and `wasm-pack` et al *today*. It will use mechanically-generated JS bindings under the hood, but this is an implementation detail and you don't actually need to write any JS if you don't want to. The tutorial shows how to interact with JS because that is something many people need to do, but it isn't required. The only JS you have to have today is an import and a call to `init`: &lt;script type="module"&gt; // Import the init function from the mechanically // generated JS bindings and call it: import init from "./url/to/pkg/my_package.js"; init(); &lt;/script&gt; That's it; you don't need to write any more JS than that today. Once ES+wasm module integration and Web IDL bindings ship in browsers, we can reduce that to simply: &lt;script type="module" src="./url/to/pkg/my_package.wasm"&gt;&lt;/script&gt; And there can be zero JS even under the hood. Here are some links you may find helpful: * https://rustwasm.github.io/docs/wasm-bindgen/examples/without-a-bundler.html * https://rustwasm.github.io/docs/wasm-bindgen/reference/attributes/on-rust-exports/start.html * https://rustwasm.github.io/docs/wasm-bindgen/web-sys/index.html * https://github.com/WebAssembly/webidl-bindings/blob/master/proposals/webidl-bindings/Explainer.md
Would you like the prefix await? [https://github.com/quininer/prefix-await/blob/master/examples/hello-world/src/main.rs](https://github.com/quininer/prefix-await/blob/master/examples/hello-world/src/main.rs)
I'm not saying it is a good idea to ignore these warnings, but I am saying that you cannot force every person who writes a crate to follow your rules, and it is difficult to control precisely what crates your own depends on. I agree that there is good reason for the warnings, and I personally like the fact that I get warned about things like that. But the warnings are not errors, and the crate still compiles, which makes it valid rust. Also, I would argue that if you want to use consts as a make-shift enum, which I have had use cases for, that it can make more sense to use PascalCase to be more consistent with real enums. It breaks convention to keep consistency. Granted, in these situations I've always used `#[allow(non_uppercase_const)]` (or whatever the warning is called), so even *not* following conventions shouldn't cause warnings in a well-maintained crate.
Neat! Efficiency wasn't really the point at this stage; it was to enable some cleanups. I haven't tried to compile this, but I think it's *close* to right. Maybe need to stick some more `mut`s wherever or something. pub fn solution(board: Board, pieces: Vec&lt;ChessPiece&gt;) -&gt; Vec&lt;Board&gt; { let mut board_stack: VecDeque&lt;(Board, Vec&lt;ChessPiece&gt;)&gt; = VecDeque::new(); let mut solutions: Vec&lt;Board&gt; = Vec::new(); let mut tested_configurations: HashSet&lt;Board&gt; = HashSet::new(); board_stack.push_front((board, pieces)); while let Some((board, pieces)) = board_stack.pop_back() { match pieces.pop() { Some(mut piece) =&gt; { for row in 1..=board.m { for col in 1..=board.n { piece.row = row; piece.col = col; if board.is_safe(piece) { let new_board = board.clone(); new_board.place(new_piece); if tested_configurations.insert(new_board) { board_stack.push_front((new_board, pieces.clone())); } } } } }, None =&gt; solutions.push(new_board), } } solutions } Should be some faster, since there's less cloning and more use of simple data structures. I find it easier to read, and it seems cleaner to call.
On a Mac mini, Macmini8,1: &amp;#x200B; Benchmarking hashbrown\_rwlock\_insert\_100k\_u64\_u128x16: Collecting 100 samples in estimated 281.78 s (5050 iterations)**error:** process didn't exit successfully: \`/Users/eian/bench/rs-hm-bench/target/release/deps/hashmap-57f95134e3e26694 --bench\` (signal: 9, SIGKILL: kill)
Coding velocity of rust leaves more to be desired though
&gt;\[Europe\] Island Keeper looking for new habitants! High performance and low latency server. oops guys! Thank you:)!
haven't been here long enough to id its ceo as a psycopath. but feel free to fill me in.
Can you break hbhf sensors?
Just a guess: Option&lt;ArcdpsFunctions&gt; is optimized to be the same size as ArcdpsFunctions because the compiler was able to prove that ArcdpsFunctions will never be inhabited by only zero bytes. mem::uninitialized is giving you only zero bytes, so the Option appears to be None.
I've been using GitHub Actions beta for a few months now and it works pretty well. I use it to deploy applications, run tests, etc.
I'm working on chttp (an HTTP client) as usual. I just recently merged in a branch I've been working on for the last month which refactors both the API and internals to be wholly based on `std::future::Future` in preparation for the Rust 1.36 release. I am now putting on some finishing touches before releasing a couple alphas, then a `v0.5` the day that 1.36 is released (hopefully).
Hey, I have a question. How do you parse the language inside the macro? If I understand correctly, Syn gives you an array of tokens that are rust tokens, then you already work from there. You don't need to create a custom lexer. Am I understanding correctly? Sorry. I don't have experience with rust macros.
You're in the wrong sub. Try /r/playrust.
[/r/playrust/](https://www.reddit.com/r/playrust/)
Yes, Syn gives me a tree (called an abstract syntax tree) that holds the hierarchical structure of the code. Then, I simply traverse this tree generating OpenCL code. I would highly recommend taking a look at Rust's macro system - it's pretty cool what you can do with it.
Aw, damn. I realized there was a name-collision with a Ruby project but didn't think to check crates.io :/ I'll probably try to come up with a new name, but I'll probably not rush to change it since I don't intend for this to become much more than a project for my own edification.
Thanks
Especially in the context of async networking. I can feel async await helping though.
Currently, WebAssembly doesn't have access to web browser APIs, so no, that's not possible. However, as mentioned by /u/fitzgen, wasm-bindgen abstracts that away from you. Whenever the API for web API access for WebAssembly is implemented in a few years, it can also switch on the backend without you having to change your code. That said, keep in mind that the frameworks for doing web frontends in JavaScript are much more mature than the ones written for Rust. All of them for Rust are highly experimental at the moment.
You wouldn't even necessarily need proc macros (or at least that much advanced logic in them), here's something you could theoretically generate: #[wasm_bindgen(inline_js = "const constant = "str")] extern "C" { #[wasm_bindgen] static constant: JsValue; }
&gt;Currently, WebAssembly doesn't have access to web browser APIs, so no, that's not possible. This is the answer I was asking for, thanks for the clarification. So would you agree with this rule of thump , at least for the current moment: It is more efficient , and easier to write all the UI components in Javascripts, and only resort for webassembly for heavy workloads, that has very little to do with rendereing of the UI. For example, If I'm designing a web site to convert files to PDFs . it would be wise to implement the UI in pure Javascript and only the core functionality of converting the files should be implemented in WebAssembly
It might be worth trying without mimallocator, in case that has some bug or worst-case scenario being triggered.
Ye
Yes, I agree. I personally am writing a WebGL renderer in Rust/WASM. The API is very minimal for that, so it works quite well. My demo code for the presentation I did about it yesterday is available [here](https://github.com/anlumo/webgl_rust_demo). I have done some tests with DOM manipulation, but it’s cumbersome and probably very inefficient, because you have so many calls that cross the barrier.
Hmm. In a way, `await` points can be seen as additional interfaces of the function. They are part of how the function interacts with the outside world, and they can be the places where you find the inputs and outputs of the function. The goal of the `await` syntax discussion was generally to make code written in a "fluent" style read better; but it presupposed that a fluent style was how you'd want to write async code. I'm not sure if there were many comparisons to the usual style you use for async code in languages that have prefix async subtract, which is only one `await` per line, either at they beginning or immediately after an `=` when binding the result to a variable. Since there is only at most one per line, and it stands out in either placement, especially when space delimited, it's quite easy to scan the function and get a sense for the shape of it's interactions with the rest of the world.
Alright. Everything should be fixed now!
Alright. I think I fixed it. Care to try again?
That I didn't know of until your reply. Thanks
However, DOM access from WebAssembly *is* on the roadmap... it just first requires the involved process of designing an API for allowing WebAssembly code to interact with objects managed by the browser's garbage collector.
Yes I know about the AST, but it's made of rust syntax tokens, right?
Are you guys making fun of C++?
I'm not too familiar with GNU Parallel, but I have to say those times looks a little too good to be true. How do you actually manage to get nearly 100 times faster than well-known and hopefully well-tested and well-maintained? Is there something GNU Parallel is doing that you're not, or is GNU Parallel just that poorly optimised? Could it be something like less locking thanks to Rust's safety guarantees similar to how Firefox's components were less parallel than they are now from the developers being afraid of messing it up? I just want to know what's being done differently to explain those massive speedups.
`future` is a pretty common word, especially given that futures are a programming concept shared by many languages.
While is use this at the moment, notice it has not had any commits in a long time, and has known bugs (it can't be run multiple times simultaneously without producing warnings for example}.
I agree, the readme does mention building with MUSL instead of glibc, but I don’t know if that accounts for all the performance differences :/ No free meals...
\--will-you-cite?
I was also having a memory leak problem (exposing the fact I need to adjust my system config as it ground my laptop to a halt twice), but the removal of mimallocator fixed it. I re-enabled CHT and am running the bench now.
The issue is that the elided lifetime at`impl&lt;'a, T&gt; MyTrait&lt;&amp;'a T&gt; for T` is not equal to the elided lifetime at `F: for&lt;'b&gt; Fn(&amp;'b T) -&gt; TOut`. Writing the `impl` declaration explicitly and using that same lifetime specifier at the generic bound solves that problem. After that, you will run into an issue in the same impl that the captured value doesn't live long enough. That's because it is now owned within the scope of the call to `f`, we borrow it within that call to and it will be dropped at the end of that scope. That lifetime is not the same as `'a`, and I don't know of a way to fix this. My guess is that you'd have a constraint for `'a` in some way, but I'm not sure.
Submitted an issue with my results! Not sure how helpful a 2 core laptop will be for benchmarking concurrent access, but hopefully it helps.
Gnu parallel is written in perl which explains at least that performance difference. With that said, I have tried rust parallel and use gnu parallel every time; it's an incredible accomplishment.
And without the compiler warnings which help avoid most of the pitfalls.
There's not a Rust meetup group in CPT, there is one in Jozi though. That being said, there is a good tech community scene in Cape Town, and the FP Meetup's last talk was on Rust. You can also hop onto the [zatech slack](https://zatech.github.io/) group and find some Rustaceans hanging around.
Any particular reason for posting this today? As far as I can tell, this is a fairly old, abandoned project which, while fast, never truly implemented the full functionality of Parallel.
`SafeCombatCallback` is an `fn()`, not a raw pointer. It's undefined behavior to assign `combat: std::mem::uninitialized()`. See https://doc.rust-lang.org/reference/behavior-considered-undefined.html: I believe this falls under "Invalid values in primitive types, even in private fields and locals". In the `fn()` docs: ["function pointers are assumed to not be null"](https://doc.rust-lang.org/std/primitive.fn.html). In this particular instance, your undefined behavior is manifesting as `Some()` appearing as `None`.
Really cool! I am not a macro lover but I think that macros might be a good match for vector/matrix construction instead of a ton of specialized constructor functions.
It depends on your application, but generally yeah, for now it's easier to do the DOM wrangling in JS. For something like a WebGL centric app though, doing it pretty much completely in Rust-&gt;WebAssembly is much more feasible. See [my pong game](https://github.com/bzar/wasm-pong-rs) for example. It has all 3 lines of JavaScript. The only hacky parts of the code (IMO) are ones dealing with DOM events. But in your use case a JS UI with WebAssembly logic or parts is probably the way to go for now.
You might be interested in my progress at [my htsp implementation](https://gitlab.com/rubdos/compass/tree/master/hts). I'm trying to follow the latest of async/await/tokio. I currently have issues combining std::future with `tokio::proto::Framed`, but I think OP's linked comment is the way to resolve that. With that repo goes [my recent blog post](https://www.rubdos.be/rust/async/programming/2019/06/22/implementing-htsp-in-rust.html). Note that after the "UPDATE" in my post, not everything works yet because of the above.
A few days I ago I visited found an article on webtitan website about supply chain attacks. And today I've seen this post. That's why I think you should checkout that blog as well. [Click here](https://www.webtitan.com/blog/msps-targeted-as-hackers-realize-potential-for-profit-in-supply-chain-attacks/) to read the full blog.
Musl tends to be regarded as slower, I thought
Hey /u/kimgfromthe99 I think you meant to post in /r/playrust
I have started converting `pdf.js` to Rust using `wasm-bindgen` (link)[https://github.com/ThomasdenH/pdf.js-wasm]. SO far I've converted some basic functionality, mainly as a PoC. The trick is to incrementally convert functions while making sure the test suite passes. However, it is tricky to modify the original build/test suite correctly. One issue is that (`webpack` doesn't support loading `wasm` in the main thread)[https://github.com/webpack/webpack/issues/6615]. To circumvent this, I used a technique I first saw in the [`rusty-typescript`](https://github.com/yever/rusty-typescript) project. The test suite is mostly passing now in Firefox, so I just have a bit more debugging to do.
what about the GNU serial port? that's the one everyone is interested in... ...i'll see myself out :)
But doesnt a fully static binary allow for more compiler optimaztions?
Here is a comparison by the author of GNU parallel between GNU parallel and alternative projects: https://www.gnu.org/software/parallel/parallel\_alternatives.html The deficiencies of “rust-parallel” noted there are, to me, bad enough to not use. The speed advantages are of course nice; I, however, use it primarily for expensive, long* running process, where the overhead of GNU parallel is negligible. * long compared to the wall time of GNU parallel
Thank you for bringing awareness to the details. Currently I don't care about any specific things. What I am writing is more of an automation script that I will run on my server. I want it to detect when I (or my friends who also use my server) have uploaded some files or directories to a specific directory and then process said files. Everything is on the local filesystem. No need to traverse subdirectories, only top level. If my thing turns out useful, I will publish it. Only then I might think about the details needed to make it robust so it can work well for other people too.
Thank you!
Zed's dead baby, Zed's dead. (c) Last commit: Dec 4, 2017
Thanks! :) I assume `#[tokio::main]` + `async fn main` is going to be optional?
Thanks a ton. Your result should be published very soon.
Yeah CHT still causes some issues. I did ping the author here but no response. u/Razznak
Oh wow, this is great! Exactly what I wished I could have made back when I started cgmath! Losing the parameterisation on constants when switching from D to Rust was a big annoyance - I'm glad we're getting it at last!
I don't believe so. There is link-time optimization, but I don't believe that can cross the FFI boundary. Happy to be corrected!
Came here to say this. [hangs head in shame]
In my lock-free trees I've had a lot of luck finding leaks using LSAN, check this out if you think it might help with the issues you're hitting. I have spent significant time debugging race conditions in lock-free rust, so feel free to ping me directly if there's anything you'd like a hand with hunting down! &amp;#x200B; [https://github.com/spacejam/sled/blob/fa5fd0676c29d57ab3bb3a334b2afea7220184b0/.travis.yml#L85](https://github.com/spacejam/sled/blob/fa5fd0676c29d57ab3bb3a334b2afea7220184b0/.travis.yml#L85)
Hey its the sled author. How cool! The issues i was hitting was with a new lockfree map called \`cht\`. So it wasnt my crate. Purely there for becnhmarking purposes. It has currently been removed from the benchmark until the author fixes the isses.
I haven't looked at it closely, but isn't this a case where higher-ranked trait bounds might help? Occurs with Fn stuff often
Hello, Thanks for your reply. The reason I had a lifetime on the struct is that I initially wanted to have ``` type Original = OccupiedEntry&lt;'a, K, V&gt; ``` The reason for this, is that the closure passed to the `try_extend` function is a way for the user to define the error case, and so far I can see three cases, which I will detail below. The closure is called when the key already exists in the map/set. Then we can: - decide to do like `Extend`, and systematically overwrite the value. This is easy if I have access to the occupied entry: `entry.insert(v)`. - decide, based on the values, if it's an error, eg ``` if entry.get() == v { Ok(()) } else { Err(format!("sorry, no can't do!")) } ``` - Or decide that it's an error The solution you gave is the good answer to the question I asked, thanks. But... I had modified the code beyond recognition, and it wasn't obvious that I wanted access to the entry (or the map) to possibly insert the value from within the closure.
Oooh, seems like this is the repo: https://github.com/CraneStation/lightbeam
Or riGit, because it isn't taken.
That's it, yes!
Your link seems broken
Works fine on my side. Just clicked on it. What doesn't seem to work for you? This is the official project page: https://www.gnu.org/software/parallel/ If you search for `alternatives` there, you can see the link. Alternatively, if you have GNU parallel installed, `man parallel_alternatives` gives you the same content.
Just in case you didn't realize, there's already a popular project named [tox](https://en.wikipedia.org/wiki/Tox_(Python_testing_wrapper\)). I mostly wanted to let you know, because if I was putting all my effort into making a programming language or similarly sized project, I wouldn't want to be overshadowed. Thankfully, it's not something in the Rust community, it's Python. That said, it is big enough to have its own Wikipedia page. ¯\\\_(ツ)\_/¯ --- In any case, this is pretty impressive. I have no idea what you're doing or what's going on with those graphs. 😅
There is another solution, which is to use \`try\_fold\`. Originally I thought it would be nice to extend the \`Extend\` trait (no pun intended) to include fallible cases, but it just doesn't improve much over the 'try\_fold' code... just a thought
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/webassembly] [Lightbeam: A Highly-Optimising Streaming WebAssembly Compiler](https://www.reddit.com/r/WebAssembly/comments/c5nqzo/lightbeam_a_highlyoptimising_streaming/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
The link on the gnu page is `https://www.gnu.org/software/parallel/parallel_alternatives.html` the link I can see on your post is `https://www.gnu.org/software/parallel/parallel\_alternatives.html`
.. in the first try .. while refactoring
That is super weird. So it looks like for whatever reason reddit escapes the underscore for you, but not for me? I don't really understand what's going on. &amp;#x200B; Both the link title and the link reference contain exactly \`https://www.gnu.org/software/parallel/parallel\_alternatives.html\` for me. &amp;#x200B; I will insert a proper markdown link in the hops that this fixes it. Can you check in a second?
Even the two results so far are super interesting to me (as the author of kudzu). I'm guessing kudzu's insert is not handling contention very well because when we have to retry we start again all the way at the top of the list, which is why its getting worse results on the machine with more cores than crossbeam, but better results on the machine with only two cores. This isn't surprising since the paper I modified the algorithm from had the same results. It can be improved :)
I must be because of the redesign. I still use the old design.
It is, definitely, in at least two cases I've had personal experience with. One is its `memchr` implementation, and it's one of the reasons why the pure Rust `memchr` crate exists and prioritizes its own `x86_64` implementation over any `libc` implementation. The second case is its allocator. For details, see: https://github.com/BurntSushi/ripgrep/commit/03bf37ff4a29361c47843369f7d3dc5689b8fdac
thank you! using `Option` solved it. I hoped to save some instructions there.
so thats undefined behaviour i guess. thank you for your help :)
Woah. Pleasure talk to you! I was guessing something similar after looking at the source. If you want it rerun and the crates updated you are free to ping me or open an issue. I recently got contacted by my dream uni and they were willing to provide a range of hardware to test on so hopefully we are going to get loads more results soon on everything from pentiums to quad E7's.
Not sure what's going on with here -- I pushed out an update last night after reading the manual of crossbeam-epoch. When built against cht 0.1.2, AddressSanitizer reports no memory leaks when running your benchmarks or cht's test cases. However, the insert benchmark ran OOM when I ran the full deal overnight with ASan enabled. Still, no leaks detected. Might be that ASan can't detect leaks with mimalloc enabled -- will run again without and see what happens. In addition, there's an intermittent segfault when reading from CHT_U64_U64. ASan isn't reporting anything, so debugging continues!
Yeah. Something wierd is going on here. Cht will continue to stay disabled until we can get the bench to run successfully with it. Thanks for your understanding. Personally I had just been eyeballing lockfree algorithms and it has worked out. Maybe im just good writing them or I have a lot of luck.
r/playrust
`Iterator::flatten` is essentially `join`, and `iter::once` is essentially `return` (assuming you meant `return(f(x))` instead of `f(return(x))`?).
Thanks for the reading list, this should keep me busy for a while! I have no problem with writing javascript or Rust, but I was under the illusion that Web assembly is replacing JS. Well, not yet, but it might do so, quite soon! &amp;#x200B; Thanks again,
[removed]
Because it is exactly a series of assignments like in C: struct S { uint64_t a; uint64_t b; }; struct S s = { .a = 4, .b = 8000 }; struct S t; t.a = 4; t.b = 8000; Rust: struct S { a: u64, b: u64 } let s = S { a: 4, b: 8000 }; let mut t: S = unsafe { std::mem::uninitialized() }; t.a = 4; t.b = 8000; It's not dissimilar to writing `let t_a = 4; let t_b = 8000;` except that we can refer to its compound `t` by using structs.
I have code like this: trait Stream {} trait Sink {} trait Protocol&lt;C&gt; { type Stream; fn new_stream(&amp;self, conn: C) -&gt; Self::Stream; } trait StreamSink: Stream + Sink {} impl&lt;T: Stream + Sink&gt; StreamSink for T {} type MyStream = Box&lt;dyn StreamSink&gt;; struct AProtocol; impl&lt;C: Stream + Sink&gt; Protocol&lt;C&gt; for AProtocol { type Stream = MyStream; fn new_stream(&amp;self, conn: C) -&gt; MyStream { // In reality, `conn` will be wrapped and produce a complex type: // let conn = conn.and_then(..).with(..); Box::new(conn) } } And error: error[E0310]: the parameter type `C` may not live long enough --&gt; src/lib.rs:23:9 | 17 | impl&lt;C: Stream + Sink&gt; Protocol&lt;C&gt; for AProtocol { | -- help: consider adding an explicit lifetime bound `C: 'static`... ... 23 | Box::new(conn) | ^^^^^^^^^^^^^^ | I'd like boxing here to avoid writing down complex signatures like `type MyStream&lt;C&gt; = AndThen&lt;FromErr&lt;With&lt;..&gt;&gt;&gt;;`, which works but bothers me. I wonder if there is a way to express `type MyStream&lt;C&gt; = Box&lt;dyn StreamSink + lifetimeof(C)&gt;;`.
No problem! `Option&lt;fn()&gt;` will be stored as a single nullable pointer with None being represented as null, so it should be pretty efficient. It is effectively zeroed rather than uninitialized, but hopefully that can be optimized out too.
&gt;`dynasm` sucks Hey that's just rude. Seriously though, do you have any suggestions that would make it less painful to use for you, or a description of what parts of it caused issues for you? I understand the macro DSL can be a bit annoying but there are good reasons for why it is the way it is.
How do i pass enum subtype as generic? I want to match on a particular subtype in a function. Naturally i want that subtype to be defined when function if called. So far i can't pass it as generic and i can't match on variable. tldr i want to enum Tp { Sub, Dub } call::&lt;Tp ::Sub&gt;(smth: Tp); fn call&lt;T&gt;(smth: Tp) { match smth { T =&gt; (), _ =&gt; () } } call::&lt;Tp ::Sub&gt;(smth: Tp); fn call&lt;T&gt;(smth: Tp) { match smth { T =&gt; (), _ =&gt; () } }
I wonder if adding an extension trait to `std::time` to be able to do `1.nanoseconds()`/`1.nanos()`/`1.ns()` has been considered.
Apologies for being so confrontational, you're right that it exists how it does for a good reason. I don't think that `dynasm` sucks really, it's basically just that it doesn't fit the requirements of a compiler at all (or at least, not my compiler). I can't have any work done in the macro itself, since the macro acts as a barrier where all abstraction that ultimately calls the macro must be done using other macros and I want my code to be abstract where possible. It's a pretty fundamental part of `dynasm` that the macro doesn't return an error, so we're at a limit where we can't make more code runtime-determinable. I want to have it so I can pass an abstract _place_ that can be either a memory location or a register, but that would take a lot to implement since some instructions can only take registers or only memory locations. I'd like to have it so that instructions exist as either values or types so that I can write a function that is abstract over different instructions and call into it with different instructions (right now I have to use macros for this). I would also like it so that generating an instruction stream and writing it to a buffer are separate, so I can query the instruction stream for (for example) the flags that it dirties. Ideally I would have no macros anywhere in Lightbeam.
Looks like there is a repository now, so if you are interested in details you can check it out: [https://github.com/vlang/v](https://github.com/vlang/v)
Is there a tracking issue for the switch?
&gt;How do i pass enum subtype as generic? Enum variants are not their own types, so you cannot do this.
So on a scale from 1 to 10 you'd say 3.6?
You can express the lifetime of `C` by declaring a lifetime parameter and making `C` depend on it like so: trait Protocol&lt;'a, C: 'a&gt; { type Stream: 'a; fn new_stream(&amp;self, conn: C) -&gt; Self::Stream; } Then, the implementation of the trait for `AProtocol` will be like this: impl&lt;'a, C: StreamSink + 'a&gt; Protocol&lt;'a, C&gt; for AProtocol { type Stream = Box&lt;dyn StreamSink + 'a&gt;; fn new_stream(&amp;self, conn: C) -&gt; Self::Stream { Box::new(conn) } }
Git Commit: ff7b3de838aa9e44655ac2569aa370c467b6bfbf Rust: rustc 1.37.0-nightly (5f9c0448d 2019-06-25) OS: FreeBSD 1_fsn1-dc1_hetzner 12.0-RELEASE-p6 FreeBSD 12.0-RELEASE-p6 GENERIC amd64 System: Hetzner SX62 CPU: Intel_ Xeon_ E3-1270 v3 Quad-Core Haswell Memory: 32 GB ECC DDR3 RAM Results from target/criterion folder: https://share.thaller.ws/Bei35a5Q9Vr130DKxVsJrgF0/criterion.tar.gz
having a look basic implementation of std::time [https://github.com/rust-lang/rust/blob/master/src/libstd/time.rs](https://github.com/rust-lang/rust/blob/master/src/libstd/time.rs) the Linux-sys-impl is based on "gettimeofday". "gettimeofday" should never be used, due to timezone issues and NTP interference! This seems to me a major flaw in overall std-lib of Rust, reaching out all deadline/timeout handling in mio, tokio. To me, reliable networking seems impossible with this time/clock-infrastructure! As I said std::time lib should support different clocks, each for a different purpose. Why is rust repeating API-failures done in the past, instead of learning from C++ std::chrono or newer C-API "clock\_getttime"?
So what, match arms are hardcoded in a function?
You an only take a \`Tp\` as an argument, and then call \`match\` inside to check that you get the variant that you want. This may change in the future, but for now, it's the best you can do.
Actually yes, I had that epiphany this morning. I had no clue exactly what use higher-ranked trait bounds had over normal generic lifetimes, but now I know. Updating original post
can you give code example please?
 enum Tp { Sub, Dub } fn call(smth: Tp) { match smth { Tp::Sub =&gt; { // you got a sub! }, _ =&gt; { // you did not get a sub }, } } What you do in the `_` case depends on your use case; you can panic or return a `Result` from `call`.
but i want to change the Tp::Sub match into a generic match controlled by function argument in some fashion. i want to call both wit sub and dub and match against them respectively.
Yes. As I said originally, you cannot do that in Rust today.
Ooh! you have the easy and fun version of the problem. Yes, the notify crate will easily handle this use case. I wish you luck and hope it is useful!
&gt; async as a modifier for closure literals is not stabilized here. More design work is needed regarding capture and abstraction over async closures with lifetimes. That's a real bummer but I'm still very excited to see async/await stabilize.
i can do just that with macros. keep forgetting about 'em macros.
Thanks a ton. This will be published. How do you want credit? Some kind of handle?
Thanks!
I've been waiting for futures to become stable before reimplementing this from scratch with best practices of today.
All `std::time` really needs by my estimation is to stabilize the `as_secs_f64` and `from_secs_f64` functions and their `f32` counterparts. Writing `time::now()` isn't going to make my life noticeably easier than writing `time::Instant::now()`.
Tracking issue for this is this I think: https://github.com/rust-lang/rfcs/pull/2593
you can use 'Alexander Thaller' if you want :D happy to help
How do I keep the leading zeros of a u8? I want to have 5 print as 005 rather than 5
actually what i'm talking about makes little sense, as matching also destructures the contents. matching against an empty type is a very specific case of that. on the other hand macros already have :pat it's just that i keep thinking of generics as templates since they use &lt;&gt;, whilst the actual rust equivalent would be macros.
A base abstraction for spawning a future is provided in [`futures::task::Spawn`](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.16/futures/task/trait.Spawn.html). In terms of spawning on some "contextual" executor I've experimented with having a spawner wrapper that provides itself via thread-locals to every future run on it, there's also [`runtime`](https://docs.rs/runtime/0.3.0-alpha.5/runtime/) which aims to be a generic interface to a global executor/reactor. Personally I find that spawning futures is something that happens in few enough places that it makes sense to just pass explicit spawners where needed, the majority of the time using internal concurrency in a task is enough.
Thank you for the write up! I appreciate how much effort this team puts into documenting the decision-making process.
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fb9a6188e2911d55d1b43e63b5be7994
Here is an example (modified slightly from [https://github.com/hyperium/hyper/blob/master/examples/client.rs](https://github.com/hyperium/hyper/blob/master/examples/client.rs)): fn fetch_url(url: hyper::Uri) -&gt; impl Future&lt;Item=(), Error=()&gt; { let client = Client::new(); let file_name = String::from(url.path().split('/').last().unwrap()); client // Fetch the url... .get(url) // And then, if we get a response back... .and_then(|res| { println!("Response: {}", res.status()); println!("Headers: {:#?}", res.headers()); let mut file = std::fs::File::create(file_name).unwrap(); // The body is a stream, and for_each returns a new Future // when the stream is finished, and calls the closure on // each chunk of the body... res.into_body().for_each(move |chunk| { file.write_all(&amp;chunk) .map_err(|e| panic!("example expects stdout is open, error={}", e)) }) }) // If all good, just tell the user... .map(|_| { println!("\n\nDone."); }) // If there was an error, let the user know... .map_err(|err| { eprintln!("Error {}", err); }) }
When I see "bind" I think of either [`bind()`](http://man7.org/linux/man-pages/man2/bind.2.html) or [`std::bind()`](https://en.cppreference.com/w/cpp/utility/functional/bind). The name `flat_map` is much clearer in what it does.
Also, unless you need async, you could use [`reqwest`](https://github.com/seanmonstar/reqwest) to do this a little more easily. Just swap a `File` for the `StdOut` in this example ([https://github.com/seanmonstar/reqwest/blob/master/examples/simple.rs](https://github.com/seanmonstar/reqwest/blob/master/examples/simple.rs)). I believe the `Read` impl for `reqwest::Response` does **not** buffer the response body into memory.
The `#[tokio::main]` macro generates a small amount of code (you can look). All it does is construct a runtime and spawns the body of the main fn as an async block, waiting for it to complete. It is not at all required. Regarding spawning. Tokio allows configuring the executor that is used by `tokio::spawn`. See the `tokio-executor` crate, which contains an `Executor` trait.
Thanks! How do I store that output?
``` let s = format!("{:03}", 5); ```
Started a project with rust again for the first time after learning the basics a year ago! I am building a SPH fluid simulator, outputting to wasm and then rendering it on a web page.
That's neat! I'm starting a master's degree soon, and want to learn a bit about sampling methods for ray tracing, and maybe pursue it over the course of my degree. What do you suggest are some good places to start reading?
Is there any way to also allow runtime-dynamically sized vectors/matrices using this approach?
Awesome! I love the name too.
So the for\_each doesn't read stream chunks at a time as the file is downloading? only reads the stream when all chunks are in memory?? thats a bit wacky.
Results on a Macbook Pro 2018 (2,2 GHz Intel Core i7): https://file.io/vYPruk
Thanks
I'd check the sources in the paper for a more comprehensive list. At first, make sure you understand the basics of random numbers and stats, stuff like variance, expected value, PDFs/CDFs, etc. After that, you should be more or less ready to look into sampling specific to Monte Carlo integration. Art Owen has a really nice unpublished [book](https://statweb.stanford.edu/~owen/mc/) on Monte Carlo sampling. In particular, pay attention to Chapters 8 and 10. Check out the original jittering, and multi-jittering (Pete Shirley) papers. Andrew Kensler (also an author on the paper I worked on) did a nice follow-up to multi-jittering called correlated mult-jittering. Once you feel like you have a handle on those techniques, check out quasi-Monte Carlo sampling theory. First, I'd try to have an understanding of elementary intervals, then look at the papers for Halton and Sobol sampling (sorry I'm lazy and don't feel like searching for the links right now, but it's pretty easy to google these topics and find the papers). My advisor and another author wrote a nice [SIGGRAPH course](https://cs.dartmouth.edu/~wjarosz/publications/subr16fourier.html) on doing Fourier analyses on sampling point sets and how that relates to MC integration convergence rates. For our paper, we modified the empirical error analysis tool to generate theoretical convergence rates. If you want to do something more tangible, I highly recommend playing around with the EEA tool, generating some analysis and seeing how they relate to your point sets. You can write your own sampling methods (go ahead and implement, jittered, multi-jittered, play around with randomization and jittering constraints, and see what happens). I also wrote my [Bachelor's thesis](https://www.cs.dartmouth.edu/~trdata/reports/abstracts/TR2019-872/) on this topic, and since I didn't have a page limit, I tried to explain things from first principles and make the topic more approachable.
No, I don't believe all the chunks are in memory. `res.into_body()` returns `hyper::Body`, which is a wrapper around a futures `Stream` that yields the response body as chunks of bytes. I'm not an async expert though.
The issue you're facing is I think that you're trying to directly assemble low-level machine code from a high-level representation while trying to optimize both the translation and the assembly process at the same time. `dynasm` is an assembler. It is capable of figuring out exactly what encoding a specific assembly statement needs and actually emitting the bytes necessary for that. But it doesn't have any logic of actually reasoning about the code. It doesn't understand what those bytes do at all. Which is completely okay for the final codegen pass backend, as the only thing you want to do there is handle actual branches, register allocation, and perform memory reference / immediate propagation to use more compact instruction forms. What I'd advice to do is essentially split up your code generation pass into two passes. The first pass starts from your Lightbeam IR and emits a lower level IR where you can reason about the semantics of operations in your chosen instruction set (whether they affect flags,) and where they just operate on *place*s. You can optimize the logical flow of the to be emitted code there. You can for instance define an abstract "add" operation that doesn't affect flags, and an abstract "adds" that does. And then the second pass you do the actual opcode selection to match your semantically optimized program. One semantic instruction, depending on the involved values, can be expanded to multiple instructions, you do the actual register painting, and emit the actual machine code. the abstract "add" might compile into anything like `add rax, 1` (add immediate), `lea rax, [ebx + ecx]`(non flag setting add), `mov rax, [eax + ebx]; add rax, [eax + ecx]` (flag setting add starting from two memory locations). Trying to optimize both the semantic meaning and actual encoding of instructions in the same pass can make encoding such an inconsistent instruction set as x64 really difficult. While it can result in more optimal code, I'd try to avoid it in a streaming compiler as it is an iterative problem at best. As a side note, if you want to abstract over instructions, by far the easiest way is just defining functions that implement the actual encoding like this: fn encode_add_reg_mem_indexed1_q&lt;A: DynasmApi&gt;(assembler: &amp;mut A, dst: Reg, base: Reg, index: Reg) { dynasm!(assembler; add Rq(dst.code()), [Rq(base.code()) + Rq(index.code())] ); } And then you can of course just use this function dynamically. You can even define a macro to define these functions in shorthand (which you probably will want to use to just instantiate the functions you need, there are hundreds of thousands of instruction variants in x64 easily ;) ). `dynasm` itself was the result of me trying to write such a runtime assembler by hand itself, and getting frustrated with how extremely verbose this code becomes if you try to do it all dynamically.
Whoa, havent heard anything about PDF.js in a long time! I was really excited when this came out as PDFs were a huge pain point in FOSS and Linux realms before. Is this you toying around with things or might this work actually be merged in and this project will become mostly Rust?
How do I print a string with [proper escapes](https://stackoverflow.com/questions/1133031/shell-prompt-line-wrapping-issue#2774197) for use in a [Bash shell prompt](https://github.com/glfmn/glitter/issues/10)? I have tried variations of: print!("\[...\]"); // missing escape code ([ is the escape code) print!("\\[...\\]"); // prints literal "\[" print!("\x01...\x02"); // prints unicode garbage print!("\u{01}...\u{02}"); // prints unicode garbage None of which work for various reasons.
The following works in the 2018 edition but not the 2015 edition: let mut m = HashMap::new(); let s = "foo".to_string(); m.insert(0, s.as_str()); I totally understand why this didn't compile in 2015. The `String` `s` gets dropped before the `HashMap` `m`, so `m` ends up containing a dangling pointer. So...why does the 2018 edition allow it? How does the compiler know that `HashMap::drop` isn't going to observe the dangling pointer?
You've still got a bunch of unnecessary cloning. You're set up to remove most of it now. For example, /u/internet_eq_epic pointed out: &gt; There is at least one place you can eliminate a clone easily. Your solution `fn` takes a `Vec&lt;ChessPiece&gt;` but only uses it like a slice (and it is not even `mut`). If you change that type to a slice reference (`&amp;[ChessPiece]`) then when you get to the recursive call, you no longer need the clone. Having said that, I feel like I've done too much violence to your original code to make a comparison fair. Let me think about what we have done and get back to you…
Thanks!
I don’t know enough compiler internals to review this, but it looks like a nice improvement. Thanks!
thanks. I got it working, with progress :) &amp;#x200B; `.and_then( |res|{` `let head = res.headers();` `let total_len = head.get("content-length").unwrap().to_str().unwrap().parse::&lt;usize&gt;().unwrap();` &amp;#x200B; `let mut path_buf = std::env::current_exe().unwrap();` `path_buf.set_file_name("image.gif");` `let mut file = File::create( path_buf ).unwrap();` `let mut cnt: usize = 0;` &amp;#x200B; `res.into_body().for_each( move |chunk|{` `let i = file.write( &amp;chunk ).unwrap();` `cnt += i;` `println!("WriteChunk {:?} - {} / {} :: {:.2}", i, cnt, total_len, (cnt as f32) / ( total_len as f32) * 100.0 );` `Ok(())` `//file` `// .write_all(&amp;chunk)` `// .map_err(|e| panic!("example expects stdout is open, error={}", e))` `})` `})`
 print!("\u{01}...\u{02}"); Does work after all, it just prints garbage in all non-shell contexts, but is interpreted properly when it's part of a shell context.
Yeah, just toying around, I'm not affiliated with the project in any way. I am familiar with the code base from another project though, so I thought it would be a good way to try it out. I currently have no commitments as to how far I'll take it, but I'll probably make some contributions to the `wasm_bindgen` ecosystem.
I find it easier to write frontend code in Rust due to the complicated tooling required for JS dev, and Rust's comparatively cleaner package system, docs, community, and language.
Thank you for the detailed response! I'll look into these. My understanding of probability theory is a bit shaky, unfortunately. I plan to go through Grinstead and Snell's book cover to cover. Your bachelor's thesis is quite approachable to start with. Thanks again!
Just opened: https://github.com/tokio-rs/tokio/issues/1201
I believe this is due to NLL.
This is big! I hope to set this up for work soon, right now we do everything via git URLs, having proper versioning and the usual `cargo publish` workflow will be such a big plus! I discovered your project a while ago through a comment you made here on reddit, I'm really glad to see documentation! I hope this gets as much attention as it deserves! 💙
From what I've seen, I don't really see much of a difference between `async |x| { ... }` and `|x| async { ... }`. I may be wrong though.
&gt; Because the core use case for futures is to perform some sort of IO, the vast majority of futures evaluate to a Result with some sort of error. Throughout all of Rust's Future development, this has always irked me. It is as if the Rust team think everyone is using the language for writing web servers, and that async compute is somehow a niche use case. As someone who largely writes game-related code, it has been months since I last wrote a function that returns `Result`, and went so long without ever calling into code that returns one that I forgot that the `?` syntax exists in the language for a while. Async compute, on the other hand, is just about everything.
Some comments: * Since you're only returning references from `nth`, you can make the return type `(&amp;'static str, &amp;'static str)` and skip all the `String::from`s. * You're just iterating over the list of presents, so you don't need to turn it into a vector. You could, after you print the first line of the verse, do: ``` for i in (1..=iteration).rev() { println!("{}", nth(i).1); } ``` You could even make this more concise by having `presents` be an iterator over presents and looping/printing that: ``` let presents = (1..=iteration).rev().map(|i| nth(i).1); for present in presents { println!("{}", present); } ``` * I'd split up `nth` into two different functions, since one is just turning a digit into an ordinal, and the other is getting the present. You could also make a struct to contain them (like `Day` or something) to make it more explicit so instead of `nth(i).1` you would have `nth(i).present`. * You can use `x..=y` for ranges instead of `x..y+1` if you want to include y. --- [Here's](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=284984672bc5b97c76f1cff882ab609d) a playground with some of these changes made.
I’m glad you find it useful — feel free to hit me up with any questions!
Great resource. Thanks! I've been trying to figure out which concurrent map types to use recently, and didn't even know some of these existed. Thanks a bunch.
Why do you think webservers are the only things that can fail / deserve a Result?
You're welcome! I didn't imagine what started as a research project being useful for others. Glad to see it being used.
How are you using futures for compute tasks? Is everything using `tokio_threadpool::blocking`? How do you think `rayon` would work for what you are doing?
It's kind of unfortunate that it's not written in Rust. I (and probably a lot of other redditors) cannot read or write Clojure and therefore it is not easy to "judge" this software.
[Grassland](https://www.grassland.network/), an open source project that generates a real-life "SimCity" using anonymous, P2P, computer vision software connected to cameras. [Most of the code](https://github.com/grasslandnetwork/node_lite) is written in Python because it uses deep learning frameworks like Tensorflow for computer vision. And I originally intended to use something more familiar like C++ to enable data sharing and validation between nodes since memory management is so important, but I've been hearing a lot about the benefits of Rust so I'm playing around with it to see if it would be a better choice.
I would like `async` to to be a prefix, that way it is still possible to have an explizit return without using `{`.
 They aren't, but compute tasks very often don't, and Rust's futures and async/await syntax have been quite explicitly designed under the assumption that virtually all async calls are going to be returning results. Early versions of Future even made it mandatory.
&gt; but I don't believe that can cross the FFI boundary It could; though I can't say whether it *does*. The typical compilation model for C is that each source file `.c` gets translated independent into an object file `.o`: one symbol per function/global, assembly already optimized, etc... and then the linker gather all those together, eliminate duplicates, and bundles things into a library (roughly). With LTO, the compiler will instead add some IR to the `.o`, so that the linker can bundle all the IR together and produce a single big object file to optimize which is immediately transformed into a library. There is no reason for said IR to be source-specific, so in theory you could generate LTO-enabled `.o` for your C code, generate LTO-enabled `.o` for your Rust code, and throw all of them at the linker at once to get cross-language LTO.
As noted by the author here: https://www.reddit.com/r/rust/comments/c5jrkm/gnu_parallel_port_to_rust/es3a4go, they are waiting on the stabilization of async/await to rewrite it from scratch.
That's not how I took it at all. Many things do IO, not just web servers. Most things read files for example. So, cli tools can be includes. Oh and GUIs. So I think async compute is not the main usecase, but it's not because everybody is writing web servers.
How strange. I think `Struct { field: expr }` is quite clear and reasonably concise. What's the objection with this syntax?
The language's async/await syntax (and to a lesser extent, future abstraction) should work just as well for compute work as they do for IO. The language team operating as if virtually everyone is only going to use it for IO is irritating. At the moment, async compute is actually a total pain to do in Rust, because the futures ecosystem for it is so under developed. Rayon is the only real option, and its future support is still primitive and does not always fit naturally into how rayon was designed to operate, as its natural API is very much focused on fork/join type workloads (though the core scheduler could handle futures well).
I cannot write Rust myself, that's why it's written in Clojure ;)
My point is not that async IO is uncommon, but rather that not everyone is exclusively writing async code for IO. Both IO and compute should have been equally considered during the language's design, but the design team appear to be openly dismissive of anything but IO. It is just an assumption that has been baked into all of the design discussions.
You mentioned what I wanted to already, but I'll add that you don't need to reverse the iterator, you can range backwards like `day..=1` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8343653a13c115aa781f01b418c0d719
Thanks Brendan! That means a lot to me
So,how are infallible async operations pessimised by the current design?
That's awesome to hear! I do like the project, I was just a bit confused as to why OP was posting this _now_. I guess because you'll be working on it again soon-ish?
I'm sorry, but I'm having a hard time understanding what async compute is used for. Computations that have a real time component?
This was one of the major changes between Futures 0.1 and the final stdlib futures; Futures are no longer required to have an error type.
There definitely are Rust developers who get paid to work with Rust, but it is also true that the proportion of enthusiasts and professionals is very different compared to the more-mainstream languages like Python or C++.
[It detects the Drop implementation](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b93e2b0c4cf8cc069a1168a2a890bc09). Must be NLL.
This is not exactly true. On linux for example you can create an memory-backed file descriptor and call fexecute on it. I am sure there are ways to do something similar in other operating systems. Example code (excuse me for using C on this sub, I am not very good with rust): #define _GNU_SOURCE #include &lt;sys/mman.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; struct span { char *data; size_t size; }; // this could come from anywhere, no reason to read it from a file struct span get_executable_data() { FILE *f = fopen("/bin/ls", "r"); fseek(f, 0l, SEEK_END); size_t size = ftell(f); rewind(f); char *data = malloc(size); fread(data, size, 1, f); fclose(f); return (struct span){ data, size }; } int main() { struct span executable_data = get_executable_data(); int memfd = memfd_create("a_memfd_file", MFD_CLOEXEC); write(memfd, executable_data.data, executable_data.size); free(executable_data.data); char *const argv[] = { "", "/root", NULL }; char *const envp[] = { "an_env_var=2", NULL }; fexecve(memfd, argv, envp); }
What's wrong with this though? They are just saying most use cases return Results. Almost everything I have seen does. They're using postfix awaits for this reason. If they used prefixed awaits then what would you do for everyone who is returning Results?
One day, it says. Sounds ominously far in the future to me. :-)
I am saying that they are wrong to assume that "core use case for futures is to perform some sort of IO", when they should instead consider the core use case to be BOTH IO and compute. They are just totally dismissive of async compute, and this has shown up a few times during the future development, with things like virtually all discussions being only in the context of tokio, or how early futures required `Result`, or even in the motivation for the postfix await syntax. The postfix syntax is not _wrong_ because of this (and may still have been the sensible decision), but the design team have still based this decision upon a warped perspective that ignores entire classes of use cases as if they were of little concern.
Yes, and I was very pleased to see that when it happened, but it still worries me with how dismissive the team appear to be around people wanting to use async for anything other than IO.
Any forums where I can contact some of the pros or is there anyone here I can chat to?
Who is pushing for compute-oriented async? It would be odd to expect them to consider this a core use case if nobody(or a small enough minority) was pushing for it.
Your use of std::mem::uninitialized() is my point. The struct construction operator imposes conditions that don't really map to sequential assignment code. An assignment-like syntax would imply that you could add assignments, remove assignments, or assign twice. Struct constructions are constrained as a whole, and the syntax expresses that.
There is still quite a lot of active development on the async features. Including a big \[ICE\]([https://github.com/rust-lang/rust/issues/61834#event-2439883370](https://github.com/rust-lang/rust/issues/61834#event-2439883370)) that was just fixed yesterday, work on multiple lifetimes, ... I wonder if it would be wiser to wait until 1.38. That would mean October instead of August, which is annoying, but it would seem more sensible to let this big feature bake for a while longer before stabilizing.
I'm saying postfix works for both IO and comoute Futures. Prefix works only for compute. What is the problem with postfix?
I am not complaining about the postfix syntax, but rather about the apparent blind spot in the dev team with regards to what they thing people will be doing with the langauge.
Oh, I actually did not realize there were async blocks.
Yes, it makes sense to me that if the wrapper struct implements `Drop`, that it won't compile. But what surprises me, is that *HashMap implements Drop* and yet this still compiles. Why isn't the compiler worried about what `HashMap` does inside its `Drop` impl? Is it something to do with the generic-ness of the contents?
Why is async compute even needed? It's the same as using a threadpool. Coroutines are useful for network I/O specifically because of the difference between the cost of a network connection (low) and the cost of a thread (not that low).
[https://www.helium.com/senior-firmware-engineer-rustc](https://www.helium.com/senior-firmware-engineer-rustc)
The "Lightbeam as a generalized codegen backend" item confuses me a bit. Doesn't Lightbeam use Cranelift as codegen backend which is already kinda generalized?
I still don't get it. One option works for everyone, another works for only you. They chose the option that works for everyone. What aren't you getting?
Rust was used a little internally at my old job. At my new job, it's a lot more core to the business. You might also take a look at the [friends of rust page](https://www.rust-lang.org/production).
There's a special `#[may_dangle]` attribute that you can add to generic parameters on `Drop` impl. [Here's it is on Vec's Drop impl](https://doc.rust-lang.org/src/alloc/vec.rs.html#2130-2139). This attribute makes the compiler assume that the value is actually allowed to dangle when dropped, so the lifetime of the items in the collection does not need to extend to the collections destructor. However, when you add that attribute then the impl must be unsafe, because you actually need to be careful not to touch those values.
What's the fastest way to decide of a given `&amp;[u8]` (of somewhat short length, if it matters) represents a floating number? Exponential notation needs to be allowed. Right now, I'm using [`lexical::try_parse_lossy`](https://docs.rs/lexical/2.2.1/lexical/fn.try_parse_lossy.html), but discard the result, so I'm wondering if someone knows something I could try to speed this up under the assumption that I don't need the value. Thanks for any pointers :)
As /u/jDomantas wrote, a type constructor like `Vec` circumvents some borrow checks. [See this playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=c14fa8ccb06464d7b669627fc1e5bee7). HashMap does **not** implement Drop, that's the reason it does not error.
I do know about the reflog, but only because git forced me to know about it. Most users shouldn't need to know about the reflog.
The web focus really worries me. This is Rust not Javascript. I just can't wait until this WebAssembly/Async phase is over.
Oh my sweet Jesus.
I know a few companies here in Moscow that run Rust in production, to some extent. I've been advocating for it at my workplace too.
Here I am. Ask me \[almost\] anything
Heap allocation is one of the big roadblocks before getting to write kernel code mostly the same as everyday application code. No more worrying about stack allocation and lifetimes when they get too unwieldy! With the `core::alloc` library and `core::alloc::Alloc` unstable trait, it shouldn't be too hard to write containers with selectable allocators. One thing I figured would be useful first is something like an `AllocRef` trait so that if the allocator used is something like `Global`, then it uses no extra space in the boxed pointer, but if the allocator is stored elsewhere, then it could package a reference alongside the normal pointer. While prototyping, I decided to parametrize `AllocRef` on the type it allocates to allow for things like typed arenas to implement it. I'm unaware of anyone actually using the unstable `core::alloc` module as most just implement `GlobalAlloc` and use the standard containers. I did notice you mentioned async/await at the end and I really want to try implementing as much of a kernel as possible with `Future`s and, when it's available `no_std`, async/await. Things like interrupt handlers could be done by just writing to a location in memory and waking up whoever's listening. I think I've mentioned in the past that a hard-disk driver can be painful to write with synchronous code since, despite most OSes providing a blocking interface, the kernel itself has to wait for the disk to send an interrupt before doing anything.
I'm at the chapter on "[Control Flow](https://doc.rust-lang.org/book/ch03-05-control-flow.html)" from the book. I'm working on the practice suggestion "Convert temperatures between Fahrenheit and Celsius." With the code snippet below, I'm trying to get a floating-point number as input from the command line but the program keeps looping at the `println!`. I'm thinking that the `Err(_)` arm is being executed despite providing inputs such as `0`, `1.1`, `2` etc... loop { println!("Enter fahrenheit value to convert from:"); // input is declared outside of the loop io::stdin().read_line(&amp;mut input) .expect("Failed to read line"); let fahrenheit: f64 = match input.trim().parse() { Ok(num) =&gt; num, Err(_) =&gt; continue, }; // ---snip--- } How should I resolve this? My code to get the user input is based on the example provided in the chapter "[Programming a Guessing Game](https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html)".
Compute tasks? I'm waiting for interrupts. My keyboard driver can't do anything while waiting for a key event and there's not many ways that can fail while still sending an event. Disk access is the same way.
I'm sorry, but I thought the point of async was to be able to send out an arbitrary number of requests to some external high-latency thing that doesn't use the requester's own CPU cycles, while maintaining the ability to do other work while requests are in-flight. But what could possibly be doing compute, unless it is either a remote system (hence I/O) or the requester's own CPU?
That's really a minor stylistic difference that is very easily changed in the future.
You're looking for r/playrust
No, lightbeam and cranelift are two separate code generators - they each have their own way of doing instruction selection and encoding. Lightbeam re-uses some small bits of infrastructure from cranelift, like the types that define function signatures, and implements a few cranelift traits for interop with the wasmtime runtime.
I think for how futures work, async compute *is* a niche or even *discouraged* use case. My understanding is that a given thread of your program is waiting for work from outside, ie: IO. That said, there are many different kinds of IO beyond network IO, and most are just as asynchronous. CPU IO via interrupts and serial ports is asynchronous IO, as is user IO from the keyboard and mouse, co-processor IO (which could be seen as compute) with the GPU or FPU, and interprocess IO. Some of those are more or less infallible than others.
You can find the new implementation here: [https://github.com/brave/adblock-rust](https://github.com/brave/adblock-rust)
Gotcha, so because the only interaction between HashMap and Drop is that HashMap contains a Vec, and Vec's Drop impl is marked #[may_dangle], then HashMap benefits from the may_dangle property too, and that's why our example here works. IIUC.
I think it must just not be a common use case? There's nothing illegal about the code, and as mentioned, we're allowed to shadow prelude imports.
Here. AMA
Correct me if I'm wrong, but I think the reason why async/await is primarily geared for IO is that IO bound tasks and compute bound tasks are really different. Async code makes sense only if the amount of time that a thread would spend blocked not executing instructions is greater than the cost of scheduling at a yield point. Compute bound tasks have a number of instructions which have to happen in a particular order and are never blocked. This means that introducing yield points into your functions so that you can context switch between them is pure overhead as opposed to just calling your task synchronously. If your task is parallelizable to numbers greater than the number of cores on your machine and you want to optimize better than the system scheduler you can use a thread pool and a work queue or something and `rayon` is really geared towards that. But it isn't obvious, to me at least, why you'd want to use async/await if there isn't any IO going on anywhere.
That makes sense to me because execution would be stalled waiting for something. In the comment I was responding to it sounded like the individual wanted to use futures for compute bound tasks (like just doing a lot of math) and I was wondering how they were doing that.
You are aware that CPU's have more than one core? One core _is_ another external resource that does not use the requester's own CPU cycles. Async compute is useful in any situation where you wish to kick of a computation that you want to run on another thread. It is very common to start a compute future early (when you know what you need, but before you need the result), and then do something else while it is running, or to spin up multiple futures at once and then use the futures API to merge the results back together or wait for the first to complete, etc. Unlike actual threads, the requestee does not need to spin or block when waiting, as the work just gets suspended until its dependencies are complete. It is therefore both easier to write such code with async, and also more efficient. Literally any situation where you are using multiple threads is better with a good async/await API/syntax. Are you saying that there are no use cases for threads?
I think you have missed my point. I am not complaining about the postfix syntax...
Almost, sorry for the confusion. HashMap is not implemented in terms of Vec, they are unrelated. Vec was just an example of a collection that implements Drop and uses may\_dangle. What I was trying to say is that the compiler with NLL knows that the code you posted involving HashMaps is safe because HashMap does in fact not implement Drop. So for all types without a Drop impl, this type of code is safe. Now, there are types like BTreeMap, Vec and many others which do implement Drop. In general, this would lead to UB in safe code but the implementors of those collections I just named assure you with an `unsafe impl` (may\_dangle) that their code is safe.
Is it working the first time through the loop? It should be fine when `input` is new, but unless you clear `input` out in the snipped code, it'll never parse another float.
This is an implementation detail though - another container might make use of both sizes for example.
Threads are a completely different technology from async, hence my confusion.
The objections revolve around `field: u8` looking like type ascription, that is `field: type` rather than `field: binding` (which is what it actually is). By using `=` the ambiguity goes away.
Interessant! Although he probably got those from some list online. Turbo Pascal being the odd one...
Oh, I missed that the comment I replied to only talked about `collect` in general, not about `Vec` in particular. You're absolutely correct.
I’d say a 5. It’s probably on par with other unoptimized linalg crates
Two friends and myself made our own startup and make money with a an instant search engine all made in Rust http://meilisearch.com
Ok, I can see why people dislike that. Me, I'm happy with it.
I totally agree, my use of the `std` docs offline is purely during development and I can't, at this point, see any another reason I would attempt a `use` of this kind. I was a little concerned if I started to promote its use I would potentially be in for a suprise down the line but I'm glad it's not considered an issue.
What decision have they made then that you are complaining about?
Does it require JS to render pages of static text? If not, great, it's better than crates.io!
Async/await and futures are the very API through which a thread pool should be presented. Rayon has already started some work on supporting this. The action of dispatching work and then wanting to do further work once the result is ready is fundamentally the same for work that happened in a CPU core or work that an external device performed. That is what async/await is an abstraction over. It is not in the slightest more naturally suited to IO than compute. The very first async/await implementation, that in C#, was motivated by compute workloads (one common example was far simplified dispatching off the UI thread to do processing and then bringing us back onto the UI thread to present the results - without occupying or blocking the UI). Their version of `Future`, `Task&lt;T&gt;`, existed in .NET's version of rayon before the async/await language feature was implemented. It was only later extended to support IO. Say, another example might be where you have work incoming that each need to be processed, and you need to do something with all the results together once procssed, but you do not know up-front all of the work. If you were manually dispatching each item into a threadpool (or their own thread), then it is relatively tricky (with a fair amount of boilerplate) to hook up the logic for continueing the next stage of processing once all tasks are complete. If, instead, the threadpool returned a `Future` for each item scheduled, you could just hold onto the most recently scheduled future, and then merge it with each work item as they arrive, then await it once you know you have no more work arriving. There is not really any threading/parallism API that would not become more egonomic when expressed in terms of futures (and more efficient than most naive implementations).
This is almost certainly the case. `read_line()` *appends* to the buffer instead of replacing the contents.
&gt; The postfix syntax is not wrong because of this (and may still have been the sensible decision), but the design team have still based this decision upon a warped perspective that ignores entire classes of use cases as if they were of little concern. No we haven't. While the language team collectively believes that `.await?` fits well together, it is not the sole reason for a postfix `await` syntax. There are other rationales (not mentioned in the report) such as a better IDE experience and better chaining in general (which is more than just `?`). And besides, non-IO based async isn't forbidden from having `Option` or `Result` in them.
I haven't thought about this at all except right now, but I could imagine something like realtime computation of things for which there is no correct answer but only more detailed answers. for example ray tracing where the color of each pixel is calculated independently, or image processing. and you could maybe do dynamic up scaling depending on whats your time available in that moment
At no point have I said I had concerns over decisions made. I said that I am worried about the lack of aknowledgement (in fact, even explicit dismissal) of important use cases of the language.
Again, I (kind of) disagree. I think privacy is an important part of life and individual comfort. However, I agree with the overall sentiment of your comment and I believe that capitalism isn't sustainable (no growth can continue forever and capitalism is all about economic growth). Certainly, as the population and automation keep rising, there simply won't be enough jobs, so the concept of working for money to live will have to be replaced. In my opinion, small community-scale societies are the solution and I could imagine that in such a society, financial transactions could probably be completely public without ill-effect, but I think in such societies in an overpopulated world where automation controls production and people live in small social communities, the concept of financial transactions and money in general seems somewhat misplaced (dare I say, obsolete) anyway.
Multithreading and parallism _are_ asynchronous (the reverse is not always true). The very same abstractions apply equally to both situations. Any situation where one process is occuring out of complete lockstep with another is async. Any situation where you have other work running elsewhere (either an IO operation or some set of computations) and you want to do something when it completes, the `async`/`await` syntax should be of use.
Async/await (and futures) provide a much more natural syntax for dealing with the results of any asynchronous action (both IO and compute), with a unified API that works the same regardless of the source of the result. A threadpool would ideally return a `Future` when you schedule work onto it.
Even better, the repo has ```#![forbid(unsafe_code)]```.
Oh interesting, I'm digging into this further. I think(?) `HashMap` used to contain a `Vec`, and I guess it benefited from `#[may_dangle]` that way at one point. But now `HashMap` is based on the `hashbrown` crate, which internally contains a `RawTable` type that itself implements `Drop` and includes `#[may_dangle]`.
After actually using bstr 0.1 quite a bit, I became fairly annoyed with the fact that I couldn't just use `&amp;[u8]`/`Vec&lt;u8&gt;` directly, and instead had to convert between those types and `&amp;BStr`/`BString` fairly frequently. I originally thought this wouldn't be that big of a deal, but practice and theory are often different. The primary reason why I had made them distinct types in the first place was to support a better `fmt::Debug` impl (to show `&amp;[u8]` as a string instead of a sequence of integers) and many more `PartialEq`/`PartialOrd` impls than what std provides. (The latter could arguably be added to std, but the former is difficult to justify.) So bstr 0.2 switches this around to use extension traits on `[u8]`/`Vec&lt;u8&gt;` instead. It definitely feels nicer, although I do occasionally miss the `fmt::Debug` impl. bstr 0.2 retains the `BStr`/`BString` types for that reason, but they are now simple wrapper types that implement `Deref`. For more info, see: https://github.com/BurntSushi/bstr/issues/5
Here another one.
Why can't enthusiastic people also be making money?
And for me. I hate that. I will refuse to use a system that works that way. Unless there is no better option.
Nice.
For those not familiar, `bstr` provides string operations on byte strings which can be considered conventionally but not guaranteed to be UTF-8. [Previous discussion of bstr 0.1.0](https://www.reddit.com/r/rust/comments/b8ck8l/bstr_a_new_string_type_that_is_not_required_to_be/). This allows for easier processing of data that might have a mix of ASCII or UTF-8 with non-UTF-8 data. An example might be parsing data in an indeterminate ASCII-compatible encoding, in which all of the relevant syntax is in plain ASCII but there may be payloads which are in some unknown encoding, such as parsing HTTP streams.
Most uses of async I have seen have nothing to do with any of those. Networking and work scheduling are huge topics nowadays.
I don't agree with this reading, std::future::Futures has been specifically designed under the assumption that Futures just produce a value. There's trait implementations/extensions for futures that return results, but only because given that information, you can build a lot of useful API around it.
I disagree, but it doesn't really matter. Even if what you said were true it's still the case that all languages compete, it's just a matter of degree. As I said, when choosing a language for a project, between JS and Rust, the conversation will likely come down to very obvious and upfront constraints. Rust v Go would be similar, but there are fewer obvious/ upfront constraints, so the conversation may be longer. As for rust being a good general purpose language, I just don't agree. Unlike Go, Rust is an extremely flexible language. It's young, so some of the abstractions just aren't there yet, but the language itself is well suited to just about anything other than scripting. The major differentiator for me when choosing between Rust and another tool (usually Python) is library support. Otherwise, Rust is almost exclusively my choice, with only a few exceptions (`eval` is super powerful in Python, and if I expect the code to be read by data scientists or infosec people, Python is more familiar and the right choice).
I'm not certain that this is what they're referring to, but it can be nice to use coroutines as a substitute to explicitly writing out state machines for different systems, so in the game you could write `sleep(3).await` so an NPC waits 3 seconds before performing their next action, or `get_player_choice(&amp;choices).await` so your thread of execution blocks until the player chooses a dialog option for example
Thanks /u/asymmetrikon and /u/DroidLogician. I indeed used `input` outside the loop to ask the user to input which conversion that he/she/they would like to perform. I redeclared `input` in the loop above and it worked! P.S. I get a compilation error when I played with another approach: I added the following line before the loop above to clear `input`: input = ""; ^^ | expected struct `std::string::String`, found reference help: try using a conversion method: `"".to_string()` I thought that it should be as straightforward as assigning an empty string literal to clear `input`. I haven't ventured beyond the "Control Flow" chapter so I'll just leave it at this for now.
That's due to the fact that a `""` is not a `String` (like `input` is,) but a `&amp;str`. You can clear `input` by calling `input.clear()`, or by setting it to a new `String` using `String::new()`.
Just curious, why did you conclude that they are *dismissive*? I'm sure they listen to you if you have any concern on CPU-bound usage.
Where do you work and what do you write at work in Rust?
Where do you work and what do you write at work in Rust?
Tried both suggestions and I can confirm both works. Thanks again! For future reference, I've posted my code on [Pastebin](https://pastebin.com/tJLqTx74).
https://anixe.pl/ I mostly develop cli apps which either convert data from one format to another or do some heavy calculations. In the first case we benefit a lot from rust type system, no nulls etc. We also have c# (mono) and Ruby apps and we spend a lot less time on the maintenance / bug fixing in rust apps. Computation heavy apps benefit ofc from the rust speed. We use rust for more or less 2 years.
https://anixe.pl/ I mostly develop cli apps which either convert data from one format to another or do some heavy calculations. In the first case we benefit a lot from rust type system, no nulls etc. We also have c# (mono) and Ruby apps and we spend a lot less time on the maintenance / bug fixing in rust apps. Computation heavy apps benefit ofc from the rust speed. We use rust for more or less 2 years.
Indeed I did mean that. Thank you. Corrected.
We've been spending the last few years building a [product](https://www.schoolbench.com.au/) with rust and it has been great. One issue I have is the hiring of new staff, which is a chicken &amp; egg problem I know, but it would be great if there was a pool of developers with some rust experience, rather than having to spend time training them. The compiler here is a pretty decent teaching tool, as it's very strict!
Try /r/playrust. This subreddit is about the Rust programming language. And sorry to hear your game isn't working!
I... Disagree with every single point made here.
There are 9 people in my company and everyone knows at least a little Rust, with 5 of us writing Rust code as the main thing we do.
All KaiOS ([https://kaiostech.com](https://kaiostech.com)) devices ship with some features written in Rust. We also started using it in our backend services.
Any time something happens there's only one question: "What does Böhmermann know?"
Hmh. MPL licensed as well. Bolting this into other browsers might yield some interesting results.
Here. I have developed C / C++ for decades. Now I use Rust whenever it makes sense. After I made a crucial delivery ( Multithreaded System level software ) with essentially 0 bugs in Rust, there is little discussion on whether Rust is mature for production or not ( except for the async / await )
Nice.
Nice.
As someone who felt similarly to you, I don't feel like any of the design decisions on the path to stabilization have been detrimental to non-I/O use, and indeed many have been a huge improvement. Aside from the awkward turn of phrase you called out, I don't think there are any grounds for concern that the use case is not being fairly weighted.
&gt;It is just an assumption that has been baked into all of the design discussions. This may have been true in the days of futures 0.1, but I think the design that will be stabilized has escaped those issues.
&gt; although I do occasionally miss the fmt::Debug impl. bstr 0.2 retains the BStr/BString types for that reason, but they are now simple wrapper types that implement Deref. What about the extension trait having a `.display()` like paths do?
Think you may be on the wrong subreddit friend
Closures don't actually erase any type information; only a dynamic dispatch scheme would do that. There's very little difference between `impl Fn(Input) -&gt; IResult&lt;Input, Output, Error&gt;` and `impl Parser` where `trait Parser { fn parse(&amp;self, x: Input) -&gt; IResult&lt;Input, Output, Error&gt; }`.
Yeah those darn C++ guys, we'll SHOW THEM!!
What inspired you to write a cargo registry when you haven't learnt rust? Are you planning to use the registry for clojure packages or something? (Not criticizing, just curious)
We used a pattern from https://rustacean.net and he did the sewing since he knew how to, I did the stuffing and the cutting out of the materials. Overall, it was a fun activity
Any plans on letting users do something with BAT besides stare at it in their "wallet?"
Yup, since day one. You’ll be able to withdraw it, spend it, redeem rewards with participating network partners, etc. This is the main feature under development right now, essentially codenamed “Gemini”.
Awesome. I was disappointed when the BAT program started and it seemed essentially like a gimmick type feature. To know that it is actually being worked on and seeing this update with Rust is relieving. Thanks for the response!
Nice.
Nice
I work within Microsoft, where there are a growing number of people writing rust professionally. Our IOT PLatform has a significant amount of shipping rust code. [https://github.com/Azure/iotedge/tree/master/edgelet](https://github.com/Azure/iotedge/tree/master/edgelet) I was able to release a tiny part of my project, written in rust, last week. [https://github.com/microsoft/avml](https://github.com/microsoft/avml)
Guessing they might need to be Chromium-based browsers.
It looks pretty generic, shouldn't be too hard to add it into non-chromium browsers.
&gt; This is the main feature under development right now Oh? You guys finally got the licenses cleared?
Hey! A couple of friendly requests. * Use random keys instead of ordered ones. This causes a lot of rebalancing for any sort of balanced tree. * Exclude the destructor from the benchmarks. The destructors on largish data structures are expensive, and are not being run in parallel. Criterion can do batching which excludes destructors * Use something other than rayon. It was not maxing out my CPU (only 400% instead of 800%).
Nice
If you ever want to actually set a String variable to a literal, you can also do `input = "foo".to_owned()` (because a String is the memory-owning-version of a &amp;str).
Please use `file.write_all(&amp;chunk)` and `cnt += chunk.len()`. `Write::write` is allowed to return `Ok` even if it failed to write the whole buffer for some reason (e.g. no disk space left). Not sure how `std` actually does though.
Some colleagues that I can vouch for at my employer are: * [https://jobfinder.amazon.com/job/878088](https://jobfinder.amazon.com/job/878088) * [https://jobfinder.amazon.com/job/635186](https://jobfinder.amazon.com/job/635186)
Heh. 69. Heheh.
Have you ever heard of System76? We use Rust in most of our projects, from firmware to the Pop!_OS desktop. Still looking to hire a Linux kernel engineer.
Another borrow checker question ... sorry &amp;#x200B; I'm trying to implement the delete of a BST and I don't understand exactly why this doesn't compile https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1c54e1c25c130bf1309ffe7884fd5348 &amp;#x200B; I could put the deletion code in the "Equal" matching part and would probably work, but I don't understand why it complains ....
&gt; The very first async/await implementation, that in C#, was motivated by compute workloads (one common example was far simplified dispatching off the UI thread to do processing and then bringing us back onto the UI thread to present the results - without occupying or blocking the UI). Their version of `Future`, `Task&lt;T&gt;`, existed in .NET's version of rayon before the async/await language feature was implemented. It was only later extended to support IO. Assuming C#'s futures are cooperatively scheduled like Rust's, it sounds like it's primarily working while waiting for the UI, which itself is a type of async IO. With compute tasks, it can be more difficult to find meaningful yield points since it always has work. In this example it sounds like the UI thread while it's waiting on I/O is being co-opted to run compute. This would require either preemptive scheduling, or sprinkling the compute task with yield points to check if the UI has work to do. The main idea behind the futures in Rust is to have the CPU always doing something when it would be doing nothing. With compute, the CPU is always doing something, so the design isn't quite optimal. With Rust's `Waker` it's even more annoying since if you don't wake the task up, the scheduler may never run it, and it's not entirely clear what's supposed to happen when a task is woken by itself.
Is that compute? I see timer IO and user IO. In both cases, it's still async IO, just not byte-stream or networking type IO.
Here was an attempt As someone (relatively) new to rust, unsure if this would be considered a very rusty way, but i tried moving the match vector of tuples, and iterate over that [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8ced48c0a9995db6c23c5a366b188749) link
I'm looking forward to trying this! I have a workspace with 5 crates, and I dread the idea of publishing two of them only to find the third one failed to publish. I'd love to have a local private repository to guard against that.
I've never had a problem with wallet staring. Instead I tip my favourite content producers on a daily basis! Web, YouTube, Twitter, Reddit... You are my recipients of BAT love.
Sorry to be a negative nelly (and Chris please correct me if I'm wrong) but this wasn't all about Rust. There was a significant change in algorithm too. Not sure if Brave ever implemented that algorithm in something other than Rust and then converted to Rust so there is an "X percent faster because of Rust!" claim to be made but 69 percent isn't X. It's "with Rust" but not "because of Rust".
&gt; 69 percent True, but it's 69 *times* isn't it?
Yes. Thanks for the correction!
I see the repo has been around for a while and it looks interesting. I cant seem to actually use your site though as both the "get started" and "login" buttons dont do anything for me (on firefox). Is the site functional or is it just me ? Additionally, whats your revenue model for this project? Is it your full time job (if you dont mind me asking) ?
Reminds me a lot of emulating load-link/store-conditional with compare exchange, except there you can cheat by using 128 bit compare exchange to atomically validate the version (ABA) tag and edit the value at the same time without locking.
/r/KarmaRoulette
Is this a spin-off question to the Ibiza-scandal? haha
oh, I did not know that, that makes sense. So that's why compiler errors stay understandable
Company is sentry.io and we build part of our processing pipeline in Rust. Also our CLI tool is written in Rust.
What a gorgeous lil crustacean :D Nicely done.
&gt; from the inventor of JavaScript Is this a good thing?
Thanks, this was super fun to make and although it didn't come out the best, we will try again when I visit him later in the summer break or so
Yes. Guy is a legend. That's the person who was pushing for es4 back in the day but was stopped by microsoft and Google who still wanted to push for their own scripting solutions in browsers. They lost. However they also stopped ES4 spec at the time 2001-2003. As a result features in ES4 only went live with ES6 after end of browser wars.
I _think_ the compiler isn't counting `break;` as ending the borrow of `v`? It's either that or it's counting `node_to_delete` as borrowing from `node_to_delete`, which is preventing other usage. Non-lexical lifetimes is getting closer to having all correct code compiling, but it doesn't understand everything. Unfortunately, the closer we get to "all correct code compiling", the more complicated rules are needed to actually understand the borrow checker's logic. I don't know exactly what rule is being broken here. I played around with it a bit, and the following seems to work: fn delete(&amp;mut self, val: T) -&gt; bool { let mut ptr = &amp;mut self.root; let mut node_to_delete = None; { while let Some(ref mut v) = *ptr { match v.val.cmp(&amp;val) { cmp::Ordering::Less =&gt; { ptr = &amp;mut v.left; } cmp::Ordering::Greater =&gt; { ptr = &amp;mut v.right; } cmp::Ordering::Equal =&gt; { node_to_delete = Some(v); break; } } } } match node_to_delete { Some(n) =&gt; { /*... DELETION CODE HERE ...*/ } None =&gt; {} } return true; } I _think_ this works since we explicitly assign a new variable to the node to delete when we reach it, so the borrow of `ptr` ends. Since `ptr` is never used again, it (and `v`) don't conflict with the new variable?
I just use reqwest, it is a lot easier. You could use it with rayon if you wanted it to be asynchronous.
They hold onto that in almost every post. There trying to get you to look away from the fact that it's a privately ran company that's an actual racket in practice by blocking ads then telling advertisers to use their altcoin if they want to earn money.
Why do you guys keep pushing the "inventor of JavaScript" thing? JavaScript is the worst thing to happen to programming since the invention of NULL.
You're absolutely correct, but I'd give the benefit of the doubt to the OP and say that "the speed up was 100% due to Rust" wasn't implied.
Thanks daboross, that's a very good idea, I think I tried something like this in my experimentations but I might have tried using references instead of values and ... didn't work :P That said is quite frustrating sometimes that the BC seems to be arbitrarily rejecting pieces of codes because of his non-syntactical limitations :-(
I see some of the typical negative comments about the "creator of JavaScript" here. &amp;#x200B; Well, guess what else Brendan Eich did - he made Rust happen. He rarely gets any credit for it, but Rust would not exist without him. &amp;#x200B; Brendan was the CTO of Mozilla in 2009-2010, and was \_the\_ executive who decided to fund Rust. It was terrifying when he left Mozilla, because basically nobody else at the executive level cared at all about Rust. &amp;#x200B; I'm glad he's finally using the language he helped bring to life.
Thank you very much for taking the time and effort for this constructive and informative feedback. I have implemented some of your suggestions and it's way more clear! &amp;#x200B; thanks!
short and sweet! thanks :-)
Making yourself to use rust without unsafe is just setting up artificial boundaries. It is possible but you give up a lot and make thew task miserably difficult in places. People should get better at using unsafe when there are needs - maybe unseen they will see better ways to use and unsafe and new ways to help the language with it. Rust was supposed to be a system language, not an attempt at intellectual purity.
As someone who threw up his hands in frustration with Nom 4 when going back to an old crate trying to port from an earlier version of Nom, I decided to give it another try. I had been using another parser because I found that Nom felt like it should have been simple but i kept running into issues that were head scratchers. Wow, am I glad I gave it another shot. With Nom5, I couldn't be happier. It is just a joy to use. Really amazing work. I feel like it has been a game changer for my latest project and one of my favorite "look what rust can do" crates. One
Yeah well, same argument was made for c++, people should get better at avoiding segfaults and the kind, blablabla ;)
Very cute!
This is exactly right, thanks a lot. I actually hope to use more of cranelift’s code later so we have only one place to maintain it, but Lightbeam will never reuse the codegen system
I think this talk https://www.youtube.com/watch?v=js-e8xAMd1s about the use of a future based API in a HPC context might be an interesting example and shows async compute is a good fit. In essence, in order to have good scaling in parallel code, ideally all your code is parallel. Fork join parallelism introduces fragmentation in the CPU load (nicely shown in the talk), caused by the serial parts of the code. Async code is a naturally fit to avoid that. HPX (https://github.com/STEllAR-GROUP/hpx) is an implementation of that scheme, based on futures and channels, offering a nice API for distributed computing.
I read this all as "Look, brave is using Rust in their adblock and it's super fast now, isn't that cool?" rather than being some kinda evaluation of was rust the best here for performance
I hope this will include a cooling pad as well.
i don't know why all these people choose to write buggy code it's dangerous just don't write code with bugs in it :)
Cool, I'll take a look. Thank you.
Rayon works nicely for one homogeneous tasks. But how would you schedule a bunch of different tasks up front, so your thread pool never starves? In a sync world you have to pause, prepare the next task and then continue with full speed, pause again... From my understanding, with async you can continuously feed your threadpool with different tasks until you need to wait for an result. Such situations happen at least in high performance computing (HPC). The serial parts in a program can lead to a slowdown, as shown for example in the talk I've linked elsewhere in the thread.
As always, thanks for the newsletter, u/nasa42 and contributors! There was a slight mistake with the date of the [Tokyo Rust Meetup - Rust LT #6](https://rust.connpass.com/event/133657/). It says "Jul 7." but the meetup is Jul 3. Could you correct that?
Thanks, we tried to make it cute!
Sorry if I'm missing the point here, but I have to ask how is this connected with the Xi project?
This is fixed now. Thanks for pointing out!
I'm assuming you mean the game, not the compiler for the programming language - in which case you want r/playrust
It would be great if you could write a blog post with some smaller examples on how and when to swap macros to functions, and explain some typical variations of the process. I'm sure the community would love it :D Seriously, right now I would take the commit and read the diff, but I am not that familiar with the code base and I don't have much time.. And I'm sure there are other people would like the same.
Yep, I honestly don't get the appeal of Brave.
Programmers are the worst thing to happen to JavaScript
Huh, alright. I would right now but I do not have time as I'm on vacation in South Korea. Feel free to submit a pull if you have the time though.
Thanks, it looks promising! Do you If I understand correctly, RESSA's goal is to extract a complete AST from JS code while swc and ratel are *just* transpilers? Or do they also provide access to the full AST?
I am trying to change the value inside of an `nalgebra` matrix in an unchecked-fashion. I have the following code: use nalgebra; fn main() { // 1x1 matrix let matrix = nalgebra::Matrix1::&lt;u32&gt;::zeros(); unsafe{ let mut value = matrix.get_unchecked(0); value = &amp;1; }; // Value is not &amp;1 as i would expect assert!{matrix.get(0).unwrap() == &amp;0} } I dont see any `as_mut_ptr()` operations for the indexes, only for the [matrix itself](https://docs.rs/nalgebra/0.18.0/nalgebra/base/struct.Matrix.html#method.as_mut_ptr). How can i go about this?
The btf (bildundtonfabrik) that produces the show also is a pretty capable gamedev studio, so they might have just asked some of their colleagues.
I have to watch the talk you linked, but I'm not saying that there is no reason to write async code, I'm saying that breaking up synchronous streams of instructions by yielding in the middle of them will decrease throughput which is, I think, why most people don't associate async idioms with compute bound tasks. Each individual non-parallelizable portion of work cannot be executed any faster than however long it would take with exclusive access to a single core. If your work load is dominated by tasks like that then it's just overhead to have them yield, or distribute them, or whatever. You may want them to yield to improve the availability of compute resources, which is fine, but it should really be up to the programmer to decide how to balance throughput/availability. Which I think you can do well with futures as it stands in Rust now, so I'm not really sure why this discussion has gone the way it has. `Future` is a trait and if people implement that trait to represent a long running compute bound task in a thread pool somewhere, that's great. That's what `tokio_threadpool::blocking` does. But I'm not sure what is being asked for more than that?
I saw a Rust release note saying \`You can now use alternative registries to crates.io\`, and started writing it. Meuse will only be for Rust packages.
The project is just an HTTP server, no frontend so no javascript.
The BStr type implements Display.
The code will work with just a few tweaks: * declare the matrix as mutable * use `get_unchecked_mut` to get a mutable reference * dereference and change the value And the end result: fn main() { let mut matrix = nalgebra::Matrix1::&lt;u32&gt;::zeros(); unsafe { let value = matrix.get_unchecked_mut(0); *value = 1; }; }
Compile it to wasm and plug it into uBlock Origin... Would that work?
First off, you plan on mutating `matrix`. Thus, declare it as `mut`. The next thing is `get_unchecked` which returns a shared reference, one you cannot use to mutate the matrix. Instead, use `get_unchecked_mut` to retrieve a unique reference. `value` is a reference, with `value = …` you assign a new reference to the binder `value` but don't actually update the underlying value being referenced. Use the DerefMut-operator `*value = …`. Finally, in this case, the temporary `value` is not necessary, see: use nalgebra; fn main() { let mut matrix = nalgebra::Matrix1::&lt;u32&gt;::zeros(); unsafe { *matrix.get_unchecked_mut(0) = 1; } assert_eq!(matrix.get(0), Some(&amp;1)); }
For creating an async closure, I believe the unannotated versions will be identical once they are fully implemented. It makes a difference when you're annotating the closures types though (and the second of these is actually not possible to annotate today, but I would expect this to be supported in the future): ```rust let foo = async |x: u32| -&gt; u32 { x * y }; let foo = |x: u32| -&gt; impl Future&lt;Output = u32&gt; { async { x * y } }; ``` The major issues are around how you write a function that takes in a generic async closure, there's an issue at https://github.com/rustasync/team/issues/19 describing the problems, allowing this at all seems like it needs work on how lifetimes of closure arguments are handled, allowing it _ergonomically_ requires language changes (minimally supporting something like `impl FnOnce(u32) -&gt; impl Future&lt;Output = u32&gt;` as an argument type, more usefully some sugar like `impl async FnOnce(u32) -&gt; u32`).
Thank you!
Do you claim that it's ok to have ..= for the range but ... for the pattern ?
My issue with Brendan is not JavaScript. My issue is the donation and public support he gave to [Prop 8](https://en.wikipedia.org/wiki/2008_California_Proposition_8) against marriage equality.
In certain domains, use of unsafe is sometimes just necessary, and from time to time justified to work around compiler limitations. But it should an escape hatch that is only used when really necessary. &amp;#x200B; A ad-blocker probably shouldn't need unsafe.
Why is await support for Stream considered a long term requirement?
Yes. `..=` more explicitly implies what the operator does - generates a range that will, in some instance, be equal to the last element (i.e: inclusive). To address your other comments: - The `|x| x + 1` closure syntax is already really quite compact. `||` is already a common operator to use when programming, so it's not as if the syntax is alien. `(x) x + 1` would be ambiguous, `x -&gt; x + 1` would be ambiguous, `x: x + 1` would be ambiguous, and other syntaxes I've seen in other languages are bizarre, difficult to remember, or far too wordy. - The `field: value` syntax is very deliberate since it implies binding, not assignment. When you create something like `Foo { x: 1, y: 2 }` you're not "creating a struct and giving it fields" - the struct and the fields are created as one. There's another advantage too: it mirrors the type definition, which makes it easy to see the equivalence between them. - The turbofish syntax is regrettable but understandable. C++'s parser is complicated massively by the fact that the syntax is actually ambiguous with the comparison operators `&lt;` and `&gt;`, and so the parser must understand things like type declarations during the *parsing* stage. This is a really bad idea from a perspective of simplicity and maintenance. Turbofish fixes that, and besides: Rust has HM type inference so you very, very rarely need to actually use turbofish syntax. I think `.collect::&lt;Vec&lt;_&gt;&gt;()` is about the only place I use it often, and even then I could alternatively just put `: Vec&lt;_&gt;` in the variable declaration and leave it as `.collect()`. - I don't know what to make of this one. Sure, perhaps `StrBuf` would *technically* be a better name, but it's also quite a silly suggestion since it totally goes against everything users have learned from other languages for the sake of *technically* being correct. It doesn't take long for users to learn what `String` is and how it differs from `&amp;str`. I've never seen it be a particular sticking point with beginners. Seeing a `String` type in the code is instantly readable, unlike `StrBuf`.
&gt; With the core::alloc library and core::alloc::Alloc unstable trait, it shouldn't be too hard to write containers with selectable allocators. I'm eagerly awaiting [#58457](https://github.com/rust-lang/rust/pull/58457) and [#60703](https://github.com/rust-lang/rust/pull/60703), which will make the standard collections generic over the `Alloc` trait. &gt; I did notice you mentioned async/await at the end and I really want to try implementing as much of a kernel as possible with Futures and, when it's available no_std, async/await. Things like interrupt handlers could be done by just writing to a location in memory and waking up whoever's listening. Yes, I fully agree! I hope that the requirement for thread local storage is removed soon, so that I can introduce (cooperative) multitasking on the blog this way (ideally before introducing threads).
Of course it is. Rust can even run on embedded systems!
/r/KarmaRussianRoulette
Congrats &lt;3 I'm working in a company that has an internal air-gapped network, so we depend on offline repositories such as Nexus or Verdaccio for development. I've been wanting to promote Rust for development within the company, but the lack of a private registry has been a blocker for me; so I'm extra excited about this!
Someone has different views than me, how dare they! Boycott all of his products now!
I've been happy using Firefox for years. I have no need to actively boycott Brave. As for Brendan, I do mind when people donate to causes that intend to deny people their civil right. Your argument that this is all about different views is made whenever someone has similarly bigoted views intending to deny civil rights to various groups of people be it due to transfobia, sexism, or racism. As we progress as a species, certain bigoted behaviors become unacceptable in public over time. You may call it "political correctness", but I think it's a good thing to raise our standards.
As an engineer I'm upset by how political the Rust community is and how much you don't realize that America != World. I'm from Eastern Europe and most people here are not even aware of the ideological battles that you're having over there. Also most people in Eastern Europe are very traditional and the recognition that a marriage is a bond between a Man and a Woman is a majority view. Watching this from a distance seems like zealotry and forcing of your own ideology, it's a big turnoff for me to be honest.
We have just updated the website to make it much more informative. We are currently working with a big luxury french company especially making it work on premise on their servers. It is a full time job, yes and this big first client is paying us to improve the search engine and let us release the code as public source! In the future we will propose a SAAS version of the engine, it is related to the not working login button you saw. We remove it for the moment because our client take us time, the dashboard and SAAS are not ready yet!
&gt; As an engineer [..] What does being an engineer have to do with anything here? &gt; [..] and how much you don't realize that America != World. I'm from Eastern Europe and most people here are not even aware of the ideological battles that you're having over there. I'm not from the US; I'm Swedish and I would be against bigotry wherever it surfaces. &gt; Also most people in Eastern Europe are very traditional and the recognition that a marriage is a bond between a Man and a Woman is a majority view. Being "traditional" is still not an excuse for denying people their rights. A majority of folks in the US or in Western European countries held similarly bigoted views not too long ago.
&gt;What does being an engineer have to do with anything here? Well, I would like my tools to be politically neutral. I suppose your response says it all, "everyone that doesn't share my views is backwards and bigoted" so much for the inclusive tolerance.
&gt; Well, I would like my tools to be politically neutral. And yet it's not okay with you if people have a problem with him openly opposing equal rights?
&gt; I suppose your response says it all, "everyone that doesn't share my views is backwards and bigoted" so much for the inclusive tolerance. There's a difference between not tolerating people for e.g. their taste in music and because they support the oppression of other people.
I just saw a lot of this type of comments from the rust team and couldn't help myself but comment on it.
I think you don't realized how far down the rabbit hole you've gone.
Calling someone crazy is not an argument.
I didn't call you crazy, just that your views are extreme and not represented by most people in the world. If you're saying that around 300 Million people in my part of the world are all just scary bigots, that's far from being tolerant and inclusive.
`HashMap` not implementing `Drop` in itself is not enough: * `HashMap&lt;K, V&gt;` does not implement `Drop`, but contains `hashbrown::HashMap&lt;K, V&gt;` * `hashbrown::HashMap&lt;K, V&gt;` does not implement `Drop`, but contains `hashbrown::raw::RawTable&lt;(K, V)&gt;` * `hashbrown::raw::RawTable&lt;T&gt;` implements `Drop`, but `T` is annotated with `#[may_dangle]` - if it wasn't, then you'd still get the error The idea here is that it is not possible to get away by wrapping stuff in a type that does not implement `Drop` itself - any `Drop` impl that does not allow the reference to dangle will prevent that example from compiling.
A very odd post, also you may want to link a page from an actual jobs site.
I don't understand. Why bring this up in /rust/? Whatever you think of Brendan's donation activities and his support of Prop 8 doesn't have much to do with what we all came here for, which is to talk about rust.
1. The current workaround isn't really that bad: ```rust while let Some(item) = stream.next().await { } ``` 2. Generic associated types (GATs) are probably a prerequisite to being able to have a trait like `IntoIterator` that can also handle async generators (which will be necessary for the `for` loop desugaring). GATs were an RFC accepted a _long_ time ago, but still not implemented, I believe they are blocked on some of the work integrating chalk into the compiler to make implementing them easier/possible. Until that happens I don't think it's even possible to experiment with how streams and for loops could be integrated.
It is relevant to the comment above regarding Brendan leaving Mozilla and it being terrifying.
Tolerance of intolerance is intolerance. Yes, 300 million people in your "part of the world" are bigots if they can't let other people do what they want. Civil rights aren't up for discussion, ever. I'd also like to point out that, since you're European, the ECHR explicitly forbids acting in any way that seeks to limit the rights of others (Article 17): &gt; Nothing in this Convention may be interpreted as implying for any State, group or person any right to engage in any activity or perform any act aimed at the destruction of any of the rights and freedoms set forth herein or at their limitation to a greater extent than is provided for in the Convention. And that both the Freedom of speech article (10) and the freedom of assembly article (11) contain similar clauses: &gt; The exercise of these freedoms, since it carries with it duties and responsibilities, may be subject to such formalities, conditions, restrictions or penalties as are prescribed by law and are necessary in a democratic society, in the interests of national security, territorial integrity or public safety, for the prevention of disorder or crime, for the protection of health or morals, for the protection of the reputation or rights of others, for preventing the disclosure of information received in confidence, or for maintaining the authority and impartiality of the judiciary.
I've updated the post
Being a homofobe isn't a "different view". Liking the beach more than the snow is.
You are being political by complaining about being political. Everything is political. You are just mad because they support different things.
&gt;In general I prefer to be apolitical That's a political position
oh fuck off to YouTube with your political bullshit. The one thing I, along with many others, love about programming is there is no politics involved. You check that shit at the door and just code. (And yea I'm an avid member of t_d but you won't be able to tell unless you specifically go on reddit desktop and accept the notice to enter t_d because apparently we incite violence against police officers (???) -- you know, politics and all).
Not in chrome, after they strip the adblocking capabilities.
&gt; so much for the inclusive tolerance. You don’t get to demand that others tolerate your desire to oppress people. That’s not how it works.
Ah, okay I got you. Thanks for your research and the update!
Any signs of Rust being integrated into Chrome I wonder?
I'm not mad at anyone, just don't like when people bring politics to programming.
At the company I work at (around 50 developers) our code is almost 100% Rust
What company is that?
Are you working remote from Austria or USA?
What company is this?
How do you find these rust developers? Whats your company called?
What companies in Moscow??
&gt; &gt; Well, guess what else Brendan Eich did - he made Rust happen. He rarely gets any credit for it, but Rust would not exist as it is today without his help. Sure, but past good deeds to not erase current bad deeds. (Nor do past bad deeds erase current good deeds) Regardless of what Eich did in the past, right now he's running a tech startup that purports to fight for "privacy" ... and also readily sacrifices those morals to growth-hack. Trying to enforce the GDPR onto others, but when they use personal data to solicit donations it's a "legitimate interest". It's nice that rust exists, but that shouldn't stop people from giving him shit for his current stunts.
What company do you work for?? Thanks for the link
Kaspersky, Group-IB, a bunch of smaller startups. I believe there are teams inside Yandex experimenting with Rust as well.
Post still feels odd.
Actually I am hiring rust developers :) Ping me if you are interested Jobs : https://braiins.com/bca-en
Probably because you can already do `for item in stream.next().await { ... }` so it's not such a pressing issue and other things have higher priority. But I'm just guessing here.
&gt; there is no politics involved lmao, tell that to all the industries silicon valley is pillaging
Enjoyed reading that! Found it funny that of the four topics on the poll, the other three sounded way more interesting to me. Hopefully the author keeps writing.
Well I would argue that you have everything you need to write functional code. You don't need more language constructs, that would mean only Haskell superset can be functional. Rather, it means you have everything you need to write code in a functional style. Maybe some language constructs are not in the present, but you can make up for them - by writing some more code, or abstracting over the code by macros.
I don't know about you but I've never defined a variable or function based on my political views. In code itself there is no politics. If there is any involved in anything else it's because we allow it to happen.
As far as I can tell, that sentence was about Rust future being terribly uncertain, not about Brendan leaving Mozilla being a terrible loss. I might be mistaken, since I'm no native speaker, but to me it looks like the original post was defending the work done by Brendan, not his political persona, and your comment seems a bit off in that context.
So why don’t you want to name the company?
&gt; You are being political by complaining about being political. Disagree entirely. They're not disagreeing about someone being political, they're disagreeing about /r/rust, a subreddit for a specific type of content, being brought into the shit-slinging fest that is politics/etc. Does content type mean nothing to you? I don't want memes here, i don't want music content here, why would i want politics here?
That's like saying being an atheist is a religion.
Because nothing is void of politics, technology is heavily determined by politics, rust and programming are too. From job seeking, to what is being developed, to why it's being developed. Memes are avoidable, politics isn't. As enginners/programmers we have a ethical duty. Programming is a tool but it is also a tool used to make bomber drones, to make investments that crash the stock market, to ellect politicians (bolsonaro's ellection was heavily determined by bots for example). You need to understand that everything you make is a political decision and some are necessarily included here, in programming foruns. Because programming also is political. And your position to remove politics from here is to remove critical thinking and ethics. Removing politics is a political position to enable fucked up things in the name of impartiality.
Thanks, I’m pretty proud of this release! Your understanding is correct, swc, rattle and boa all have a specific task they are trying to perform where ressa is designed to be as general purpose as possible.
In startups or small companies with less than 100 people, there people don't always stick to one language or platform, and have leniency to try to implement something in another language. I work in a small company, and although the main product is written in java, I try to do side work like migrating database data or other non-major tasks in Rust.
You should bring it up more then. Because so far i've not had any idea how much someone's threadsafe map implementation is a political motivation or helping to bomb children.
No it's not, nothing is apolitical. Religion is entirely personal. A apolitical forum would allow ISIS to try hire people to program in rust here, like some companies do.
Would you be ok with ISIS using this forum to recruit programmers to code in rust for them like companies do?
CLang is C family front-end for LLVM. LLVM generally speaking is a close to bare-metal transportable assembly language. Therefore "V -&gt; CLang -&gt; LLVM -&gt; executable" and "V -&gt; GCC -&gt; executable" will be much much less likely to be more optimized for production builds for applications. If you were writing code in C (and not using C as an intermediate representation), then it is possible that GCC might end up being more optimized -- but it would be a case by case basis.
I don't even know where to start with that.
&gt;Tolerance of intolerance is intolerance. Yes, 300 million people in your "part of the world" are bigots if they can't let other people do what they want. Civil rights aren't up for discussion, ever. These statements seem quite prejudiced ...
I'm just showing that programming isn't void of politics in the simpler way. I tried writing some paragraphs to explain but you didn't get, so I figured why not to try the most clear example I could think.
I think you can enforce a set of rules (e.g. subreddit rules) without being political.
It's being used at both Facebook and Google, so some people are getting paid at least in part at two pretyy big tech companies to use it.
How so? How would you ban ISIS without making a political rule? I'm genuinely curious, can you formulate a rule to ban ISIS that's not political?
&gt; *if* Hard of hearing? It's a universal litmus test. I'm from Denmark. Any Dane not in support of equal rights for LGBT people is a bigot.
It would fall under the incitement to violence category. And therefore not allowed. Doesn't have to be a political manifesto.
Most large large projects will come to a point where it is earliest to use unsafe for custom data structures than to accomplish the same thing with all the box types and copying, especially if positive is a returned. Don't hobble yourself
This narrative doesn't exist in every country, most people in Asia, Eastern Europe hold conservative views regarding marriage.
thanks.
So no US military?
Oh so it's ok then
Does that mean a homophobe holds the same view?
Not sure I understand what you mean
Every nation has the right to self-determination, if they want to live like this it's their choice, that's usually how democracy works.
Only if you try to build a graph by hand without the help of crates like slotmap.
I'm not really sure why you are being downvoted so bad. If you look at rust' own Vec implementation is certainly does use unsafe. Custom Data structure will often need it. Just try to make a bianary tree where each child node has a mutable reference to it's parent. I don't even know how that would be possible without unsafe. Would be some crazy rust kung-fu
Aha! Thanks for clarifying.
oh! thanks for clarifying that there's a tactical solution. makes sense
Support discrimination based on sexuality isn't just a "different view", and calling that is so disingenuous. Like, it's just an awful thing to do; it being "political" isn't an excuse (rather, it's why it's so bad).
But that sort of defeats the point of using Rust in the first place, doesn't it? At least from my understanding one of the main selling points of Rust is safety ensured at compile time.
Technology and politics are seperate. They is no reason to associate the two. An evil Nazi and someone donating food can both use airplanes to accomplish their goal. However you feel about his personal choices Leave Rust out of it.
...but why? What's the benefit of Tree Notation over (e.g.) JSON? I mean I can think of a few ways in which it seems worse: * It just seems more error-prone, because you might accidentally have spaces or newlines in keys or values without escaping them, which silently breaks everything. The result is likely still valid in tree notation, but the meaning would be wrong. Similarly, when manually editing tree notation, you could easily have one space too many or too few, which silently changes the meaning of the data. In JSON it's much harder to mess up like that. * You seem to have no spec. How would one even encode whitespace or newlines in keys or values? Is the order of children meaningful? In JSON, it's simple: no for objects, yes for arrays. But tree notation doesn't have arrays. The fact that in your example, you show a package.tree and a package.json which is presumably the equivalent, one would assume that nodes are like JSON objects, so that the order of keys is not relevant, but in that case, how would you encode arrays? * It's whitespace-sensitive. In the age of unicode strings, where you can have all kinds of weird control characters, that is really asking for trouble. Does a non-breaking space count as a space? Does a tab count? In terms of newlines, does \\r count or only \\n? What about \\r\\n? What effect do those weird control characters have, like the one that makes you start writing right-to-left (for Arabian)? Etc etc etc. If you just presented this as a hobby project, I wouldn't have criticized it like this. But you seem to be campaigning for as many people as possible to implement this notation in as many languages as possible. And there I feel like that's a waste of effort. What's wrong with JSON? If it ain't broke don't fix it.
Why isn't inciting wars inciting violence? I can attest you most military in the world incites violence and recruits people to do so. It's just a violence that's socially acceptable nowadays. It's political.
That doesn't make prejudice legitimate.
I saw your par project on github, neat stuff.
Any line drawn would be political. If they were calling for more outwardly hostile political actions, they wouldn't be allowed. The fact that some places in the world have shitty views doesn't mean they should be tolerated. &gt; zealotry and forcing of your own ideology, it's a big turnoff for me to be honest Again, you're not engaging with the fact that you think these ideologies are "wrong" - because you would correctly be seen as a bigot. You literally just want to slow progress for them by never letting the conversation die, in a kind of "it can't be accepted until everywhere accepts it".
Not everyone can give away their company internal secrets.
Maybe their project is confidential?
Yeah, definitely frustrating. I wonder if it'd be worth submitting this bit of code as a rust-lang/rust issue? It looks like it should be able to compile, and maybe someone with more knowledge could classify exactly what kind of thing the borrow checker is missing here.
I'm sorry, but did they just end up using a regular `enum` in the end? So much for an ideal compromise in an entity-component system...
I am withoutboats. Your comment is rather aggressive and I don't really want to respond to it, so sorry if this response leaves you speechless as well. We are thinking about async compute, and we have never made a choice that we thought would hinder people using async for non-IO purposes. We even changed the future trait to not assume errors specifically for this reason. No ones needs are being ignored. But we can also see the numbers and be honest about it. Several major production users are throwing lots of money behind Rust in use cases that need async IO. Using async/await for compute is something hobbyists talk about on Reddit and some of us on the team experiment with solutions for, but no one is actively trying to achieve. It's obvious what people are mostly going to be doing with async/await after it stabilizes. (To be be clear, these are mostly not "web servers," but everyone can please shut up with this castigating tone toward the one of the singular major uses of computing in society period). If I am to believe that its not the case that the significant majority of async/await code will be doing nonblocking IO, people need to do more than complain that I have been honest about who is driving adoption of this feature but actually go out and drive adoption.
As I mentioned below, you can have community rules and guidelines without political manifestos. Ideally one of the rules would be "no political discussions", just as we are discussing politics now, prompted by the rust team member above. The fact that you call them shitty views betrays your aggressive position. The idea that people in country X are not allowed to live the way they want is fundamentally hostile. If 80% of people in my country are religious and have conservative views about marriage who are you to tell them they can't live like this?
But your prejudice towards them is OK?
The very idea of open source is political in nature. The code we write has implications for governments, businesses, and citizens both good and bad. To think otherwise is to just bury your head in the sand.
I don't think you can compare a military - in a democratic country - to a rouge state that prides itself in killing people. Besides, I doubt people on the Rust subreddit are so keen on talking about military and ISIS. These are edge cases.
We have an office in Vienna.
`Arc&lt;Mutex&lt;&gt;&gt;` (and the equivalent `Weak`) allows doing such structures without unsafe. They probably won't be as efficient as more optimized unsafe impls though. But that's beside the point. Most large projects don't make their own data-structures. Some do, sure, but most will just use what's available in either the standard library or in specialized crates. Those crates have more eyes on them, and as such, bugs are found faster. Most code doesn't directly need unsafe. Only specialized, low-level, potentially performance sensitive code might. Most code can rely on existing safe abstractions. That's the entire premise of rust.
I'd have to disagree. I personally use Python/Bash for almost all my basic scripting needs / quick tasks, and Rust for everything else where a compiled language makes sense. Once you've used the same libraries multiple times and don't really fight with the compiler anymore, Rust is pretty fast to write in, with the added bonus of being more robust and speedy than other languages. I also find it is just so much better to look at and read, but that's just my opinion.
Ah nice. I didn't know that
&gt; Only specialized, low-level, potentially performance sensitive code might. Fair point but this is the most common use case for Rust you know. I'm personally studying how to use unsafe rust right now and even if everything you wrote was unsafe it's still better than c.
In this case, isn't it compiled every time the function is called? I'm not too familiar with how lazy_static works.
I'm sure Brendan Eich doesn't hold any hostile views towards LGBT minorities and is a decent person. You are defending an ideological position without realizing it.
I put together a [post](https://www.reddit.com/r/rust/comments/bj3hcb/what_industry_do_you_work_in/) in a hope to find out where Rust was being used across industries, it might be useful for that part of your question. If you can share some more details e.g expected hours, location, possible remote work, compensation, etc. That will likely spur some more interest.
No it's more like people choosing no user templates. Bugs still exist in unsafe rust, just as as they do iin c++ without templates. Both increase your risk of something going wrong, but they are both useful still and even required at times - sometimes they even reduce bugs (unsafe and templates can lead to easier code). Rust is losing its practicality sometimes in favor or being dogmatic. It is lead it to be a niche language that people like but rarely gets user for anything important.
Why not say so then. This really is the weirdest job posting.
&gt; prejudice Do you not understand what the word "prejudice" means? They're not saying that everyone from Eastern Europe and Asia are bigoted, they're saying that the same standards needs to be applied, regardless of nationality. It would be prejudiced if they were saying: "Everyone from Eastern Europe and Asia are bigoted, because a majority doesn't support equal rights for LGBT", as opposed to "The majority of people from Eastern Europe and Asia, who don't support equal rights for LGBT people, are bigoted"
Live like what? Nobody's telling them they have to go marry anyone they don't want to. The issue is when they go and donate money to control how *others* may live their own lives.
I don’t see that pleurplus has expressed any prejudice. You, on the other hand, have claimed that “most people in Asia and Eastern Europe hold conservative views regarding marriage”—i.e., they are homophobic.
&gt; I'm sure Brendan Eich doesn't hold any hostile views towards LGBT minorities and is a decent person. Right, he just gives money to causes that intend to deny LGBT people equality under the law. Just. a decent person supporting the oppression of others.
It's probably London so they're seeking 20 years experience in Rust for 40K GBP
Fast platform-independent resolution independent text rendering seems like the obvious motivation.
Does anyone tried some [fst](https://blog.burntsushi.net/transducers/) instead?
Interesting conclusion
Some people feel the same way about abortion. The problem isn't differing viewpoints, it's the people incapable of operating in spaces with others who have differing viewpoints, even if those people aren't using that space to advocate their views.
The erroneous assumption is that marriage is a universal right, it isn't. It originates from religious practices and is based associated with procreation (i.e. having kids).
I'm pretty sure that calling millions of religious people bigots because they don't agree with you is prejudice.
Still doesn't affect those alleged 80%.
It's a response to someone who wanted to talk about Brendan as a person and talked about some of his actions, as such the comment is completely on topic. I don't understand your objection.
It changes the definition of marriage and is therefore not compatible with the majority view, and since democracies are ruled by majority that is the view that will prevail, and so it should.
And why would you assume that marraige isn't a universal right? Did the Bible tell you? Do you derive it from some other moral system? In either case, I disagree. What gives you the right to force your intolerance on others?
Hi everyone, &amp;#x200B; I made a tool to parallelize shell commands. It is similar GNU Parallel, but you don't have to learn a new syntax and can instead just prepend \`async -s "&lt;your socket&gt;" cmd --\` to your command. For more information, here's the README from Github: &amp;#x200B; \# async &amp;#x200B; \`async\` is a tool to run shell commands in parallel and is designed to be able to quickly parallelize shell scripts with minimal changes. It was inspired by \[GNU Parallel\]([https://www.gnu.org/software/parallel/](https://www.gnu.org/software/parallel/)), with the main difference being that \`async\` retains state between commands by running a server in the background. &amp;#x200B; &amp;#x200B; \## Usage &amp;#x200B; All information about the command line interface is available using \`async --help\`. Below is an example on how to use \`async\` to parallelize commands: &amp;#x200B; \`\`\`bash \#!/bin/bash S="/tmp/example\_socket" &amp;#x200B; async -s="$S" server --start &amp;#x200B; for i in {1..20}; do \# prints command output to stdout async -s="$S" cmd -- bash -c "sleep 1 &amp;&amp; echo test $i" done &amp;#x200B; \# wait until all commands are finished async -s="$S" wait &amp;#x200B; \# configure the server to run four commands in parallel async -s="$S" server -j4 &amp;#x200B; mkdir "/tmp/ex\_dir" for i in {21..40}; do \# redirects command output to /tmp/ex\_dir/file\* async -s="$S" cmd -o "/tmp/ex\_dir/file$i" -- bash -c "sleep 1 &amp;&amp; echo test $i" done &amp;#x200B; async -s="$S" wait &amp;#x200B; \# stops server async -s="$S" server --stop \`\`\` &amp;#x200B; If you encounter an unexpected error or crash, please turn on logging by setting the environment variable \`RUST\_LOG=debug\` and open an issue on the Github repository. &amp;#x200B; &amp;#x200B; \## Installation &amp;#x200B; \`async\` can be installed using cargo with \`cargo install async-cmd\` or from the \[AUR\]([https://aur.archlinux.org/packages/async/](https://aur.archlinux.org/packages/async/)).
 &gt; probably won't be as efficient as more optimized unsafe impls though. One of rusts old selling points was zero cost, as fast a C++.
That's where we started? He supported Prop 8, which bans marraige equality.
That's the whole point, if your country is aligned with those values, all the power to you. But don't call other societies that don't share those views bigoted and evil.
Purity. Rust was overrun by a lot of Haskell people that want it to be as pure and untouched by the dirty masses as their old language. It is a sort of gatekeeping - only people who write the rust system can be trusted with certain concepts.
So, basically, people are not allowed to have an opinion opposite to you and support it in a democratic process? The way Mozilla handled that situation is appalling. As a Socialist Democrat, I find that sort of suffocation of opinions, even if they're diametrically opposite to mine, something that no person that values freedom should tolerate.
There's a chapter in the book on unsafe and they say it gives you super powers. It's useful to use because some people do enjoy writting data structures.
It's reductive to say it's because "they don't agree with you". No, it's because they're in violation of the European Convention on Human Rights. So far the most you have contributed to this debate has been "no you", which isn't really productive. Explain to us why the ECHR is wrong, please.
That's not hostile, it's just a different opinion about marriage.
I'm still stuck on your claim that your 80% are being told how to live (they're not). But wow, you've opened my eyes- I guess it's okay to be told how to live if you're in the minority.
As a socialist, I believe you are accountable for your *actions* when they harm other people. It's not just a matter of opinion. [Being the CEO of Mozilla, an activist organization, is not a right.](https://www.theguardian.com/commentisfree/2014/apr/07/brendan-eich-has-the-right-to-fight-gay-rights-but-not-to-be-mozillas-ceo) I find it rather strange that you as a socialist would to not fight against people who oppress other people.