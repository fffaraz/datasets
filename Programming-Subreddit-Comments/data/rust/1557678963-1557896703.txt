At least a config flag to turn on for debug build would be nice
None that I know; only rigorous manual analysis fits the bill But the author (Nikolay) spent great lengths of effort to fix all of that
Some mobile clients think that Reddit doesn't use a very specific dialect of Markdown, and so they just use regular Markdown. [They look different on desktop](https://i.imgur.com/7tAwaud.png).
But is it manually proven, or rigorously manually analyzed?
I love the idea. I really like it that the macro solution doesn't need any additional variables to work. I would change the syntax in the examples in README. You can use the [2018 edition standard](https://doc.rust-lang.org/edition-guide/rust-2018/) and just write: use debug_tree::{add_leaf, add_branch, default_tree}; instead of: #[macro_use] extern crate debug_tree; use debug_tree::default_tree; I don't understand why you're using `&amp;format!("1.2")` in the second example. I can't compile it because of this error: error: format argument must be a string literal --&gt; src/main.rs:18:15 | 18 | add_leaf!(&amp;format!("1.2")); | ^^^^^^^^^^^^^^^ help: you might be missing a string literal to format with | 18 | add_leaf!("{}", &amp;format!("1.2")); | ^^^^^ I think you pasted the wrong result in the *Line breaks* example. It made me confused because the code looked the same as in the first example but when I checked it, it returned: 1 ‚îî‚ïº 1.1 Next line 1.2 not: 1 ‚îú‚ïº 1.1 ‚îÇ Next line ‚îî‚ïº 1.2 Notice that in both examples the branch gets out of scope before you add the second leaf. In your repo you mentioned that it can be used to visualize results of recursive functions. I think a small example in the README or at least in examples/ dir would look good. Much more interesting than just adding leaves and branches in a simple function. Good luck!
They look identical to me in Firefox with the new design (but not the old design).
Should be on by default at least in debug builds. One might argue that in release builds the default stack trace should give some easier-to-bug-report information: maybe just the line from the most recent frame in the main crate.
Have you read [the book](https://cglab.ca/~abeinges/blah/too-many-lists/book/README.html) yet?
More like 'narrow minded controlling interests don't care about making the wrong choice if it's easier'. The art of good politics is making the wrong choice harder.
&gt;async/await is also finishing what we started, and that's necessary to enable certain kinds of code to be written well, unlike try, the lack of try isn't a major blocker for people writing code. Yeah, i agree. I am also very happy this is coming along very fast now. This is ‚Äì of course ‚Äì the most anticipated feature right now and it makes sense to get it done. &gt; I think try blocks still need some syntax discussions -- there were discussions around the edition about reserving the keyword, but not actual syntax discussions. It also ties into the whole discussion around throws and catch as function decl sugar, so there's a wider set of discussions to b ehad. That is interesting. Do you think try blocks are only coming to stable with a full (throws, catch, function) story? I find try blocks already useful but it makes sense to see them in the broader picture. This is exactly the question i had in mind ‚Äì where are we now. With this in mind it sounds like ok wrapping could also be a question in this field, which broadens the topic further. So just by looking at it, it seemed like it is almost done. There was "just" some minor things to bring it to the finish line. Also the decrease in discussions lead me to the conclusion there is just nothing more to say, "just" get it done.
I'm also on Firefox.
This is a broad topic; here are some thoughts on a slice of it: &amp;#x200B; \- The ability to use the same data structures, functions, and methods for server-side and client-side is nice; prevents errors serializing, and repetitive code. \- The JS ecosystem is a mess. Typescript and ES6 makes it better, but the tooling and setup is still fragmented, and can be a pain. Cargo etc is much nicer. \- Even with TS, the type system and \[trans\]pile error checking isn't that great with JS. \- Rust's safety features (Forced error/missing-value handling) etc is wonderful for complex web apps \- Rust's macro system allows for versatile, customizable Markup syntax. &amp;#x200B; I've built and am actively working on a frontend framework that resembles React and Elm. Looking forward to making my next web app use it in combination with a Rust backend. I'm also working on/maintaining a complex Typescript app - and really wish I had Rust's safety features and type system instead. What I'd really like to see: A high-level ORM like Python's Django, or SQLAlchemy.
After previously being in the favor of postfix macro await, I like this idea a lot.
As cramertj pointed out in that comment, the implementation of async/await is only slow because it's immature and not out of any fundamental difference with combinators. For example, one reason async/await is slower in some benchmarks is that it uses TLS to thread the waker argument through each awaited future, rather than just passing it directly. It does this today because it's piggybacking on generators, which are experimental and unfinished- someone just needs to do the implementation work to generate better code here. Or as another example, that comment you linked pointed out [rust-lang/rust#52924](https://github.com/rust-lang/rust/issues/52924). Async-based futures are currently much bigger than combinators-based futures, because little to no optimization happens on their layout, unlike synchronous stack frames or user-defined struct types. tmandry is doing that implementation work now: [rust-lang/rust#60187](https://github.com/rust-lang/rust/pull/60187). That is to say, everything that is slower about async/await is purely an implementation problem. Async functions don't prescribe different semantics from future combinators, and they don't hide any more information from the optimizer. And further, all the optimizations they need to catch up are already in common use elsewhere- they just need the chance to do their work here. In fact, async/await is going to be faster than future combinators in the long run. It enables borrowing across yield points, which leads to fewer allocations and less synchronization. It flattens whole chains of combinators into single state machines, which leads to less gunk for the optimizer to deal with. The things that might hurt async performance are in libraries, not the language.
Yeah, basically there's a lot to explore and it's on the back burner for now. I think the plan is to come up with a holistic mental model for error handling in rust.
It's not deallocated, it's moved to the caller. If the caller then ignores it, i.e. doesn't assign it to anything, it gets dropped, but if the caller assigns it to something: `let hello = no_dangle()`, the ownership of the value will be moved to the caller and it will be deallocated only when `hello` moves out of scope.
&gt;I think the plan is to come up with a holistic mental model for error handling in rust. That would be more than I had hoped. Rust has a great error handling story today, but its a little bit on the verbose side ‚Äì and its a little bit hard to introduce newcomers to the hole "ecosystem fo error handling" with regards to the many crates that try to help managing errors and reducing some of the boilerplate code. Having functions returning multiple error types is still a lengthy discussion if you want to introduce a newcomer, explaining whats best if you want to write an application or a library etc. in regards to error handling. There is still room for improvement.
You can just set the environment variable permanently to always get backtraces
Sure, but the net use case is the primary one and potentially less confusing than calling it "reactor". If you have other naming ideas, I'm open to them.
Hmm, same here.
What IDE are you using? I think IntelliJ turns them on by default.
I wanted to play it but there is no link to the source :(
There's a PR open which might fix that: https://github.com/pyros2097/rust-embed/pull/59 Would that work for your use case?
It's so messy. But if you don't mind that... here it is the source: https://github.com/AndrewJakubowicz/ggezFlappyCrabby
On the same page in the documentation it is stated: &gt;Because s is created inside dangle, when the code of dangle is finished, s will be deallocated. But we tried to return a reference to it. That means this reference would be pointing to an invalid String. That‚Äôs no good! Rust won‚Äôt let us do this. The solution here is to return the String directly... What I understand from this paragraph that s will be deallocated from memory anyways due to the end of the scope. Then when the documentation refers that "nothing is deallocated", I think it's misleading because there is no "hello" variable in the example of the docs. I think if your reply is added to the official docs it might elaborate better. Let me rephrase what I understood so far and correct me if I am wrong. The problem discussed that we cannot reference s at the end of the scope (with &amp;s) because s will be dropped after the scope is finished and we cannot point to a non-existing location in memory. On the other hand if we return the s itself, we are moving its ownership to the caller and we do not need to reference it because it's in the same function. In other words a reference cannot be returned from the function that created it, because the function that created it will destroy it at the end of its lifecycle (end of scope } ). Correct?
What do you mean by "evil people" and what is the "wrong choice"? I general i don't think there are many "evil people". I do believe "evil people" just think they are doing the "right" thing. I don't think the majority of the people we "think" are "evil" actually just want to see the world burn. Its just an assumption we make ‚Äì in the believe that "we" are on the good side ‚Äì that the "evil" people are thinking that the "wrong" thing is "right" from their point of view. But you could easily turn that perspective around and try to ague that "we" are the ones thinking that the "wrong" choice is "right". &amp;#x200B; So i wonder what exactly do you mean by "evil"? In my world and "evil" person is not the one that acts based on wrong assumptions, believes etc. its a person who just wants to see the world burn.
This is because symbol lookup and resolution is (relatively) very slow, otherwise you'd get only instruction addresses
Correct.
For more than 40 years, what did he espect from Rust ?! Rust community is very big
Thank you K900! :)
Of course the context is wider than programming here, as the original metaphor was. I'm defining 'evil' here as mostly 'apathy to doing good, disdain of rules that prevent the wrong choice, placing singular interest above more collective interest'. They map quite well corporate dysfunction and their further and wider corruption effects i think - among other things.
`...` is my favorite too. I would find it very unusual to want to stack `...`, and if you do, they need to be separated by something, presumably by a space.
I think the flaw in my thinking is(was?) that I'm thinking of `impl X for Y` as something I that is automatically called from a `Y`. For example: trait Animal { fn noise(&amp;self) -&gt; &amp;'static str; } struct Dog; impl Animal for Dog { fn noise(&amp;self) -&gt; &amp;`static str { "Woof" } } In this case, with a `Dog` instance, I can call `noise()`. This comfortably maps to interfaces in C# or Java, but I'm starting to realise that to automatically think this for any trait implementation is a fallacy, and it actually depends on the contracts defined in the trait. So when I see impl Sum&lt;u32&gt; for MyStruct { It is decidedly _wrong_ to think that these are functions defined on an instance of MyStruct. Actually, the Sum trait definition provides contracts for operations that are defined on an instance of Iterator&lt;u32&gt; that _produce_ a MyStruct. Can I just check if my reasoning is right so far? It's pretty mind warping for me and I don't want to go pursuing it if not.
unfortunately no, I only know _of_ Haskell :S
thanks for the playground snippet. I think the fact it was i32 iterator's going into i32 but implemented in a framework that allows anything was confusing me, so that separation of types and followup example usage helped me to concretely map things out.
Seems like a chicken and egg problem.
`...` would have been my favorite if `:` had been chosen instead of `..` for ranges, which in turn probably would have problems with names/type separator being `:`.
Rubble is what you are after: [https://crates.io/crates/rubble](https://crates.io/crates/rubble)
I worked at a railroad company. It cares about safety a lot and makes it a major focus. Likely because caring about safety is how you don't get regulated. But for the rest? It has a natural monopoly because cargo by train is naturally cheaper than by truck and it's prohibitive to enter the market. So as far as it's concerned it can do no wrong because it makes money hand over fist and has no need to improve.
They have [Rust bindings](https://github.com/dmlc/tvm/tree/master/rust).
How about making it the default when you create a new package? Just adding the fields automatically to new Cargo.toml files. Users can easily remove them but the defaults encourage best practices
Every proposed syntax for await is ergonomic. All of them are better than hand-writing async code without any abstraction. People are really arguing over the table scraps here.
[**dmlc/tvm**](https://github.com/dmlc/tvm) repository has been mentioned 6 times over the last 7 days. The last 3 mentions: &gt; Don&amp;#39;t miss it! https://github.com/dmlc/tvm is getting closer and closer to 3333 ‚≠ê üë®‚Äçüíª #GitHub #Python #opensource ^(Date: 2019-05-05 20:12) ^(Source: [twitter.com/gitstartracker](https://twitter.com/gitstartracker/status/1125131057840447488)) &gt; üëÄ https://github.com/dmlc/tvm/commit/4332b0aae3e05ee3bfe2ecf3c0d164ff47ae30bb I ^(Date: 2019-05-09 06:55) ^(Source: [twitter.com/_tkato_](https://twitter.com/_tkato_/status/1126380060343058433)) &gt; AST„Çí„Åü„Å©„Çä„Å™„Åå„ÇâCallNode„ÅÆ‰∏≠Ë∫´„ÇíJIT„Ç≥„É≥„Éë„Ç§„É´„Åó„Å¶„Çã„ÄÇRelay VM„ÅÆ„É¢„ÉÅ„Éô„Éº„Ç∑„Éß„É≥„Åå„Çè„Åã„Å£„Åü„ÄÇ https://github.com/dmlc/tvm/blob/4332b0aae3e05ee3bfe2ecf3c0d164ff47ae30bb/src/relay/backend/interpreter.cc#L435-L463 ^(Date: 2019-05-10 06:15) ^(Source: [twitter.com/_tkato_](https://twitter.com/_tkato_/status/1126732480239693829)) View all [mentions of **dmlc/tvm** repository](https://gitspo.com/mentions/dmlc/tvm). ^(This is an automated message reacting to a mention of a GitHub project. | [Message the bot author](https://np.reddit.com/message/compose/?to=gajus0&amp;subject=GitSpo%20Reddit%20mentions%20bot&amp;message=Hello%20Gajus,))
That would be possible, yes.
&gt;You'd think it would be easier with programming, which has the advantage of being both a technical profession and the 'decision makers' being mostly a different caste of middle managers that worked with some tech at some point of their lives, but i still think it will take a while until C++ et al are the 'harder choice'. You'd think so but it turns out that asking people to try a different language is perceived similarly as asking them to convert to a different religion. The language is seen not as a tool but as an identity with a bunch of mythos and dogmas.
Cool stuff, I love the potential of Rust + WebAssembly. This project deserves more visibility, but I guess people are just too busy bikeshedding await syntax to notice actual productive contributions these days. :p
&gt; It is decidedly wrong to think that these are functions defined on an instance of MyStruct. Correct. Rust makes that `self` parameter explicit -- something like d.noise(); basically maps to &lt;Dog as Animal&gt;::noise(&amp;d); save for auto-defererencing and mutability. However, you can't call the `sum` function on `Sum&lt;A&gt;` using *any* sort of `.functioncall(...)` syntax -- there's no *method receiver* like `self, &amp;self, &amp;mut self`. The only way you can call it is in the universal function call syntax: let s = &lt;MyStruct as Sum&lt;u32&gt;&gt;::sum(some_iterator_that_yields_u32s); This fully qualified syntax `&lt;A as B&gt;::c` means "choose the implementation of `Sum&lt;u32&gt;` for `MyStruct` and call the function `sum` defined in that implementation. Sometimes you can skip some of that and simply write `Sum::sum(some_iterator_that_yields_u32s);` -- if type inference can make it work. Fully qualified syntax is unambiguous. &gt; Actually, the Sum trait definition provides contracts for operations that are defined on an instance of Iterator&lt;u32&gt; This is not 100% correct because, as I hinted at above, you cannot call the `sum` function from the `Sum&lt;A&gt;` trait on that iterator. `Iterator` simply provides another function of the same name that calls `Sum::sum` internally: fn sum&lt;S&gt;(self) -&gt; S where Self: Sized, S: Sum&lt;Self::Item&gt;, { Sum::sum(self) }
Do you get an automatic backtrace when `panic = abort`? Because if your program is going to abort anyway, then performance is a non-issue it seems.
&gt; which is currently endangered because evil people want the wrong choice That is incredibly narrowminded thinking. Dismissing someone as "evil" makes all reasoned argument go out the window including understanding why they act like they do and is also the route to dehumanizing of people and leads to all sorts of atrocities. Please don't.
love the comedic style. Nice work
There's an upfront cost to it: gathering the backtrace, and saving it aside, requires allocating memory for storing the trace, and actually gathering it. This work has to be done regardless of whether the backtrace ends up being printed or not, as the user could catch the panic and throw it away, as long as it could *potentially* be printed. I don't believe in exceptions (which a panic is) as control-flow, so personally I see no issue in doing more upfront work in case of panic, but that's what it is.
Bitesize high quality content, this channel is great. Thanks!
Good talk but the constant "uh"s are a bit frustrating.
All I want is for the meta page that lists them all to be called *Are we there yet?*
I have nothing but contempt for people attempting to 'understand' fascists.
I have a crate for this! [bin2src](https://github.com/timClicks/bin2src/). It is a command-line utility than operate as part of a build pipeline.
Then you'll never learn how to argue against or convince people who would follow fascists. Don't be so black and white.
There are many more uses of profix macro: `an_option.unwrap!()` that shows line numbers and filename on panic, `an_open_file.write!(bytes)` and `serialport.write_fmt!(str)`, where the macro is defined on trait level.
I can relate! I enjoy watching Jon‚Äôs recordings on YouTube. I liked it so much, that I too [started doing YouTube recordings of my own](https://www.youtube.com/channel/UCj00KMrSJjHRL2F75ERgHXA). I‚Äôm far less experienced as Jon is, but it sure as heck is fun to do!
When writing some FFI code, I found myself doing `let res = (|| { ... })();` in order to capture the result before converting it into an FFI friendly status code. It was in doing this that I learned `try` blocks even existed since they seem to do exactly what I was trying to accomplish. I don't think `catch` is terribly necessary since you can just do something like `failure`'s context, or a `map_err`. `finally` should be unnecessary for the same reason C++ doesn't (didn't?) have it: namely RAII. The `?` operator itself is very concise and useful for error propagation such that I'm not sure why you would need `throws` other than to interact with other languages that use exceptions.
Is this related to the video game? Because if it is, then this should be posted on r/playRust. It's a nice picture, though.
While true I do not think this adresses the problem stated by OP. A program should only require you to think about things when it's necessary or for a tradeoff (like performance) and should have sensible defaults. I don't know whether setting the flag can have a performance impact but looking at the other comments there seems to be. As u/richhyd points out this is not a concern for debug builds and it might make sense to make a backtrace default there.
Yeah its related to the game.
First problem: It's a doubly linked list implementation. The first rule of Rust: Don't try to implement a doubly linked list.
Though I still refer to rust by example, I found it very inadequate for teaching me Rust. The book is so much better about explaining why. And rust needs a lot of ‚Äúwhy‚Äù explications
https://wiki.mozilla.org/Areweyet
Super minor stylistic point: I've always seen the field name inside single element structs be "inner" rather than "intern"
Regarding 1, you don‚Äôt think Actix with diesel are mature enough?
Thanks, I never would have picked this up
You can't argue against people who actively deny all arguments and facts to the contrary. If you could, fascists wouldn't exist. It's not like plenty of good well reasoned arguments against it don't already exist, and it's not like there are any *good* arguments for it.
&gt; I have nothing but contempt for people attempting to 'understand' fascists. I hope you reconsider. To make an argument against i highly suggest to take some time to dig into two impressive stories. One about [Derek Black](https://www.washingtonpost.com/national/the-white-flight-of-derek-black/2016/10/15/ed5f906a-8f3b-11e6-a6a3-d50061aa9fae_story.html?noredirect=on&amp;utm_term=.42446f8ddbba) (the son of the White Nationalists founder of the Stormfront) &gt; Matthew decided his best chance to affect Derek‚Äôs thinking was not to ignore him or confront him, but simply to include him. ‚ÄúMaybe he‚Äôd never spent time with a Jewish person before,‚Äù Matthew remembered thinking. &gt; He was taking classes in Jewish scripture and German multiculturalism during his last year at New College, but most of his research was focused on medieval Europe. He learned that Western Europe had begun not as a great society of genetically superior people but as a technologically backward place that lagged behind Islamic culture. He studied the 8th century to the 12th century, trying to trace back the modern concepts of race and whiteness, but he couldn‚Äôt find them anywhere. ‚ÄúWe basically just invented it,‚Äù he concluded. And the wonderful story about [Daryl Davis](http://loveandradio.org/2014/02/the-silver-dollar/) who had an important role in convincing important member of the KKK in Maryland to quit the Klan, which ultimately lead [to its breakup](https://www.washingtonpost.com/wp-srv/style/features/klan.htm??noredirect=on). Both stories are based fundamentally on the aspect of attempting to 'understand'. And i have nothing but respect for those people!
From my experience it's usually personal projects that lead the initial wave of framework and library development. Then after a while you see big companies implementing specific parts of their products with said frameworks and libraries, and in some cases they even create their own. A few years after that when the initial dust starts to settle you will see smaller companies in niche markets getting in on the pie. It's a process that takes many years, but I think that by 2025 or something we'll see a lot more use of rust in the average company for web development. Unless some other language comes along and blows Rust out of the waters.
What you said may be correct but it doesn't apply to the code you shared. In that code s is a value, not a reference, and it's returned not dropped.
True, I shared the code to point on the location inside the documentation. This code example works, and s is returned, it's the solution to the problem.
I was looking through your source code and saw two struct definitions: [this](https://github.com/pietroalbini/areweawaityet/blob/master/src/reddit.rs#L8): pub(crate) struct Reddit; and [this](https://github.com/pietroalbini/areweawaityet/blob/master/src/discourse.rs#L8) pub(crate) struct Discourse; What is the difference between `pub(crate) struct` and `pub struct` ?
Sounds like you might want a struct that contains an enum for the type + additional data.
There should be a repository link. Is it on Github?
There's plenty of "good" (at least from the perspective of those people) reasons for it. Have you talked much with poor rural people?
&gt;Iterators aren't zero-cost either. In some cases, iterator functions like `map()` or `for_each()` outperform `for`\-loops. This sounds paradoxical... What about this makes iterator not zero-cost? Or are you talking about `for` loops in particular not being zero-cost?
&gt; (at least from the perspective of those people) Well thats the rub, isnt it? Just because somebody somewhere thinks something is a good reason, doesnt mean it is. "I dont like them therefore they should die" is not a good argument except to people that already agree with it.
Well I was aware of that example when I posted my question, but there are a few problems with it. First of all it doesn't actually implement Dijkstra, because proper Dijkstra keeps track of the actual path along with its length. This is what I actually need and it's what made me discount the example right off the bat. That example tells you the length of the shortest path - nice to know but not very useful in any meaningful Dijkstra implementation by itself. Second it does a lot of data duplication, /u/belovedeagle noted that before me. I've been looking at this again, and again I can't come up with an actually performant way to implement Dijkstra in Rust because there is no collection in `std` that allows me to quickly get any member by key, quickly get a min or max member, and also allow me to mutate any member. Here are my problems: 1. With a binary heap, I can quickly get the min/max member but I can't quickly get any node I want. 2. With a hash map I can quickly get any node I want but I can't quickly get the min/max member. I've tried using RefCells to mutate data inside these collections but the binary heap doesn't update automatically (which I should have seen coming). So it looks like whatever happens, I'm stuck using two collections that I will have to keep in sync.
As someone who made several services and webapps with actix(-web) and diesel: Diesel has many things figured out at this point. I was first using it pre 1.0, and luckily at that point I was only using Rust for personal projects. Because damn, transitioning to 1.0 was an enormous pain, due to a total rehaul how database versioning and code generation is handled. Mind you, I 100% prefer the current approach, but I would be terrified making a switch like that on a giant webapp. I'm saying that because Actix is still at 0.X, and is already making scary migrations between version bumps. I wouldn't call something behaving like that "mature". I'm looking forward to a clear 1.0 and stability in the future, but at the moment I couldn't in clear conscience recommend it for things larger than 10k SLOC. Also, I couldn't call it mature with half of its user guide being \[WIP\]. I love Actix, use it a lot, and feel like it has the chance to be the go-to framework for web development. But it needs more time in the oven.
I agree that it was a nice talk, and also that it could have been done a bit better. It sounds like she should have practiced it a few more times, but then again, it's tough going through so much detail in a language. I think she should have cut out a bit of the intro. 10 minutes talking about trains in order to use them as imagery was a bit much. Otherwise, nice to see the examples of industry using rust!
Can you delete the post then and move it to the right sub?
If there are no async functions right now and this proposal only applies to them, how can this be an incompatible change?
```pub(crate)``` means that the struct is visible within your crate but is not exported. ```pub```means that struct is exported and available to use from your crate as a dependency.
Agreed in whole.
So the answer is to simply dismiss segments of the population that disagree with you and ignore their viewpoint? What about understanding their viewpoint and then figuring out an alternate solution that isn't so evil but satisfies their problems that made them follow the wrong position? People move as a group and will follow whatever the most popular most visible position is if it satisfies their problems, even if there's drawbacks. People are also self-centered and will dismiss drawbacks that don't directly harm themselves.
Thanks! Just pushed out 0.2.2 with updated examples and using 2018 style imports.
It's possible in rust. I've done something similar in tox [here](https://github.com/Lapz/tox/blob/master/vm/src/object.rs) and [here](https://github.com/Lapz/tox/blob/master/vm/src/value.rs). You could use ```transmute``` instead but clippy will tell you to use pointer casts
A `pub struct` is public and can be seen everywhere, even in other crates importing yours. A `pub(crate) struct` is visible everywhere in your crate, but isn't visible as part of its interface.
Even with your edit this is just all totally unnecessary and pointlessly dangerous. `Vec` already does uninitialized value optimizations. Just use `extend`.
Can you please explain "executing the futures" and "if a future can't make progress"? Thanks
I've built a few web apps/miroservices with Rust, and it's my preferred stack, and I've used almost every language already (except Idris and Prolog), yet Rust is my main choice now. No, you do not need an ORM, I personally dislike ORMs for many reasons, but that's just me, if an ORM is important for you then agreeded it's not as mature as other languages. But if like me you love SQL, then it's a non issue.
Others already explained the difference between the two, but I want to expand a bit on why I actually used `pub(crate)`. It might seem pointless to do so for a toy crate like mine (nobody is going to depend on it so who cares about the external visibility), but a "disadvantage" of `pub` is that it considers the item as part of the public API of the crate, thus suppressing most of the `unused` warnings when nothing in the crate uses the item (since it might be used by other crates), and I want those lints to be shown.
Thanks for the shoutout and all, but... &gt; I can't come up with an actually performant way to implement Dijkstra in Rust &gt; &gt; because there is no collection in std It really makes me sad to see the common sentiment on this sub that "if it's not in `std` then it's impossible", which usually (though not in this case) appears alongside the corollary "the rust devs should implement [description of basically the whole program] for me and if they don't then what good is rust?". I'm sure you mean well but it's not a good look (and ultimately leads to rushed features like async/await based on the false premise that they had to be implemented by the core rust devs).
An option is to implement the `AsRef` and/or `AsRefMut` traits (or some custom trait with a `get_header` method) for the "derived" structs. You could also implement the `Deref` trait but I think it's considered bad practice for that use case?
potentially don't want to ruin benchmarks by having backtraces in by default - already get so many people benchmarking without --release, now they have to benchmark with --release and --no-backtrace
Not incompatible for the language or for libstd, but an incompatibility hazard for libraries in general. The problem is that if I have a function `foo() -&gt; T`, and the `T` crate (not the `foo` crate) later implements `Future` for `T`, that breaks _callers_ of `foo`. The trait system jumps through quite a lot of hoops to avoid this sort of breakage being possible. For example, that's why you can't implement someone else's traits for someone else's type, and it's why "negative impls" (`impl TraitA for T where not T: TraitB`) aren't a thing.
Awesome idea! I tested it out with the typical recursive Fibonacci function. Worked great right out of the box. I think this could be a great teaching tool, in addition to its potential for debugging. fn fib(n: u64) -&gt; u64 { add_branch!("fib({})", n); if n &lt;= 1 { add_leaf!("{}", 1); 1 } else { let x = fib(n-1); let y = fib(n-2); add_leaf!("{}", x + y); x + y } } &amp;#x200B; fib(4) ‚îú‚ïº fib(3) ‚îÇ ‚îú‚ïº fib(2) ‚îÇ ‚îÇ ‚îú‚ïº fib(1) ‚îÇ ‚îÇ ‚îÇ ‚îî‚ïº 1 ‚îÇ ‚îÇ ‚îú‚ïº fib(0) ‚îÇ ‚îÇ ‚îÇ ‚îî‚ïº 1 ‚îÇ ‚îÇ ‚îî‚ïº 2 ‚îÇ ‚îú‚ïº fib(1) ‚îÇ ‚îÇ ‚îî‚ïº 1 ‚îÇ ‚îî‚ïº 3 ‚îú‚ïº fib(2) ‚îÇ ‚îú‚ïº fib(1) ‚îÇ ‚îÇ ‚îî‚ïº 1 ‚îÇ ‚îú‚ïº fib(0) ‚îÇ ‚îÇ ‚îî‚ïº 1 ‚îÇ ‚îî‚ïº 2 ‚îî‚ïº 5
I guess I should have known that a well intentioned discussion about programming languages would quickly devolve into one about good vs. evil and fascism. My God...
This video is really nicely done. Quite enjoyable!
Thank you. On the second point: what would you do in the remove methods when the list is empty? (rng is a leftover from my debugging, apologies)
I like Scopes so much that I befriended paniq before it was conceived, when he used to be a gamedev. IIRC, I'm the reason scopes has naked mode (although our ideas seem to converge a lot, it's hard to tell how much agency I really had in that). Here's to hoping that he can return to being a gamedev again soon because the stuff he used to say about *Nowhere* was very exciting.
Would it be possible to have the `add_branch!()` and `add_leaf!()` macros return the value if it is a single value? I think something like this would be a lot cleaner: fn fib(n: u64) -&gt; u64 { add_branch!("fib({})", n); if n &lt;= 1 { add_leaf!("{}", 1); } else { add_leaf!("{}", fib(n-1) + fib(n-2)); } } But it currently just returns the unit type.
What's the difference between `&amp;MyTrait` and `dyn MyTrait`?
Too bad for you, the simile invites itself to current events. Gilded age corporate abuses on one hand, corporate oligarchy and attempted coup on the other. Can't see any difference. Here, i'll make you a bet. RemindMe! 10 years And, if we're both alive, lets see if you life is better on a right wing dictatorship, if climate change screwed your life, or if we're lucky enough, history agrees the coup was attempted or not shall we?
`yet!?` is the best I've seen so far. We can then do `yet!?!` or `yet?!` or `yet!!!?`
I‚Äôm VERY new to rust but double linked lists and search trees are used a lot. Are there known good solution you can just use with out trying to reinvent them? I still reading the book. I have a goal to write a program and planed to use some form so self balancing search tree, (maybe red -black) to make the searches fast.
I will be messaging you on [**2029-05-12 23:17:23 UTC**](http://www.wolframalpha.com/input/?i=2029-05-12 23:17:23 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/bnp6n1/rust_a_language_for_the_next_40_years_carol/en9j5ed/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/bnp6n1/rust_a_language_for_the_next_40_years_carol/en9j5ed/]%0A%0ARemindMe! 10 years) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! en9kcid) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I think it would be possible, yes. Sure, it would reduce number of lines, but I think it would reduce readability with the macro having different functionality for when there‚Äôs specific number of arguments. Maybe instead I could add a seperate macro that accepts a single value and passes it on, E.g, let x = add_leaf_value!(fib(n-1) + fib(n-2)); Where x would be the result of the argument. Would that cover your use case?
Another great video!
https://rust-unofficial.github.io/too-many-lists/
Or, alternatively, it could return a tuple of references to all format arguments. Then consistency wouldn‚Äôt be lost, e.g `add_leaf!(‚Äú{}‚Äù, 1).0`.
You want r/PlayRust.
You‚Äôre looking for r/PlayRust.
I hate reddit
My guess is that because no system refers to `Health`, then it doesn't get automatically registered. But you then try to create a `Health` in `create_player`.
This is perfect, thank you! It looks like you are using NaN boxing too, that will be a big help.
Assuming that you meant `&amp;dyn MyTrait`: There is no difference (although in Rust 2018 you may be required to add the 'dyn' keyword). It's purely for clarity, because using a trait incurs the overhead of dynamic dispatch.
No, I mean I tried creating a `Vec&lt;&amp;MyTrait&gt;` and it didn't yell at me. No `dyn` keyword.
Why are people's benchmarks raising backtrackes?
Well then you're either using Rust 2015 (look into your Cargo.toml) or I was wrong about it being required - that may have just been a proposal for future editions. In any case it makes no semantic difference.
It says 2018.
New Reddit supports triple backtick, old Reddit and most mobile clients don't.
I don't think I see AsRef used all that often, but this seems like a very good use of it.
Yep, it only takes one person to derail it (heh, apropos), and furthermore, it seems others can't then resist engaging on the point. They could have just ignored it and moved on. They are almost equally culpable.
Please, keep it out of this subreddit. It only causes fighting and negativity.
And if regular RAII usage is not enough, we can always use it to implement something like Go's `defer` (or D's `scope (exit)`): https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=134d3b277c436fb89a3aec95bfd4fb19
Doubly linked lists are nowhere near as common as schools imply. Even random insertion and deletion that linked lists are famous for are slower than with an array backed structure like a `Vec` since copying over the entire array is actually faster than traversing the pointer links. The only real place you'll see linked lists in rust is when you're dealing with intrusive structures that have to allocate themselves or need to be serialized to disk. Singly linked lists aren't as impossible in rust as doubly linked ones. If you're making a tree structure, then it's doable if you don't have parent pointers. When making arbitrary modifications to a tree, you essentially have to treat Rust like a pure-functional language and tear the tree down before rebuilding it. Assuming you're not sitting this tree on disk, I'd suspect a [`BTreeMap`](https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html) (or [`BTreeSet`](https://doc.rust-lang.org/alloc/collections/btree_set/struct.BTreeSet.html)) is more what you're looking for, but it can be hard to offer alternatives if I only know what you were planning on using, but not for what.
This comment gives off an annoyingly smug vibe, to be quite honest, in a way that's made worse by how nonsensical the comparison is despite the wink-nudge implication. Please, tell me all about Zig and Go are somehow similar enough to be competing against each other in any capacity, let alone in a way that pits them simultaneously, directly "against" Rust. Some might even argue there's been *far* better choices versus C and / or C++ than either of those languages for years and years and years, that were even in several cases very popular/widely used at one time, and only aren't now for various social/non-technical historical reasons.
Ops. Good input, will do.
üåü
Does it continue through the iteration on failures and return to retry failed calls? Or does it continually retry the same element on failures?
I like the idea of the `add_leaf_value!()` macro.
This could work, too, but I don't think it would be as clean as `add_leave_value!()`.
Totally good points I really look forward to Actix releasing 1.0 stable. At work I typically do node or PHP for backend web dev but there are some serious speed issues I‚Äôve encountered. I learned with typed languages, became a professional with scripting languages, but recently keep finding myself gravitating towards typed languages. Rust obviously has the type safety of any typed language but it‚Äôs so fast and relatively easy to use once you get over the initial barrier.
What's the difference between a mailing library and an API for a mailing service?
You tell me, I don't know. I would've thought that the API is a lot bigger than a simple mailing library. For instance I don't intend to use half the things that the Google API brings. Seems like a dumb thing to do by adding into my program if all I'm going to is send emails, especially if there is something simpler.
I would think that what you want is a mail lib to integrate into your own service which is different.
No, you tell me. Your last paragraph essentially translates to "is it A or A?". But I'm sleepy so I might be missing something so that's why I'm asking :) As for what to include: you can get the linked Gmail crate without the parent Google API. It's the 1st or 2nd if you type "Gmail" on crates.io. While we're talking about that, if you're looking for a library it's best to check crates.io first, then Google. It's easier than duplicate results from Google.
Well yes, and I'd use the Google API but it seems like overkill. It doesn't need to be through email however, this is a bot, if it sends me messages through any other platform that would be fine. I tried slack and discord already, but bots can only send messages through channels in discord and you need to be registered into a workspace for slack. Got a workspace already but not keen on adding bots to my actual job's workspace. That left email, and I guess there's also telegram.
No you're right after rereading my post that's what it seems like. I will keep that in mind with crates.io.
You might want to look into using SMTP directly. It is a very simple text based protocol (the 'S' literally stands for simple) and is supported not only by gmail but also by most other mail providers. There are a couple SMTP related crates on [crates.io](https://crates.io). I'm not 100% sure how functional/feature complete any of them are, but you could probably also roll your own.
I thought of that but the last time I tried that the gmail account started throwing errors because of not using oauth. I know you can disable that and let "less secure apps" access Gmail through username and password but I kind of wanted to do it the right way with oauth.
I think you mean subject-verb-object? It's more like object-verb in this case though - the thing being awaited is the object, await is the verb.
I fucking hate backtraces unless I really need them. Rust already shows amazing error messages with where they came from and with suggestions. Why do I want a wall of stuff that is mostly irrelevant?
I feel mildly annoyed when people post off-topic content on the wrong subreddit.
Yeah, that's it. As a side note, if you are using nightly and you turn on the nightly feature in specs you will git a more informative version of this error. It'll actually tell you which resource it's having trouble with.
Maybe in 40 years we'll have a cpu fast enough to compile it.
I like the tone of a lute too! https://youtu.be/vD_1Klq63pk
&gt;This comment gives off an annoyingly smug vibe That's entirely in your head.
On Go at least: this community is very strange, to me, in that it's full of people who arguably often *overuse* generics while coding in Rust on a regular basis, but who will also insist that Go is somehow a "modern language" despite entirely lacking them (along with a bunch of other features.)
I strongly disagree, based on many other comments I've seen from them. Lots of jumping head first into discussions that compare Rust to other things without ever seeming to know *quite* enough about the other things.
Nothing you said or implied about go was incorrect. But... and I say this as an expert C++ developer who has been contributing to the language since a few years before the first standard, and as someone who has worked with most of those "superior" alternatives you allude to, including the closest to viable of them (D), extensively over the years... Rust is not "just the newest". It is, in all seriousness, the first completely viable alternative. And it is superior in all but a handful of ways... and hopefully those will be fixed soon. Pinning might end up solving what I consider the biggest architectural flaw in the language, for example...
Very nice. It's... really weird to see all the silly examples people have written for `ggez` shown off. Turns out when you spend two years saying "sure, whatever, but it needs an example to show it off" whenever someone adds a new feature you get some stuff. Also this game is hilarious and amazing. And I love your videos. You just always sound so happy.
&gt; This comment gives off an annoyingly smug vibe Most of is don't know each other here. Feedback like that is hard enough to take from someone you trust. When it comes from a stranger, really all it can do is make people angry. We've all seen it too many times, and we don't want to go though it if we don't have to. And so no one's engaging with you here.
I like D about as much as I like Rust, and at present I don't see what Rust *really* has over D apart from (most likely) higher-quality codegen in the common case. D is certainly still way ahead in areas like metaprogramming, for my money. Personally I don't think Rust macros are really fun to write in any way, and additionally they absolutely *do* in practice already lead to the kind of arcane compiler errors people tend to associate with macros in general, most often when you're using multiple directly-related crates with macros that relate to the same "area" of functionality to some extent.
I really hope you were referring to literal fascists (yeah, okay, MAGAs count) as opposed to people using languages other than your (and currently my) preferred one.
Not my intent there, i was strictly referring to the 'problem of evil' as applied to 'safe' choices in organizations and how it's not enough to promote good practices, but also punish/forbid bad ones, it made me think of current 'politics', thus the aside as a trailer at the end there. I'm easy to rile up by 'centrists' acting oblivious so i probably should have just ignored responses to that segment. (Personal) language choices are free from politics... unless you use brainfuck or malbolge, that's unforgivable.
I would hardly call it "feedback". It's a very straightforward opinion that a given person either can or can't, or at least will or won't address directly.
I'm a real Rust newbie, I'm just getting my feet wet and am still reading the Rust book. Given the thread I posted this in I figured I wouldn't have to point out how green I am but here we are. I think it's important to point out that I'm not saying anything is impossible or that anyone should implement anything. What I said, and you even quoted me, is that *I can't do it* with a single collection of nodes, and I was asking if somebody had an idea that could help me along the path - it wouldn't have been the first time that someone on this sub had a clever solution that taught me a lot. All of this might not be "a good look" for this sub, but consider what you're telling with that remark - am I not supposed to ask beginner questions in this thread because it looks bad? By the way, after posting that comment I was able to get Dijkstra working in a graph of about 3.7 million nodes and 6 million edges, from opposite ends of the graph, in just a few seconds. I just couldn't do it with one collection. I've got a few more ideas for improvement lined up because a few proverbial shower thoughts made me realize I'm not doing this very efficiently at all, even with the improvements.
Rust? Compile times are better than C++, unless you make unspeakable compromises on safety in your C++. That may or may not still be true when C++20 compliant libraries with full modules support start coming out, but for now, it is, and some of the work on making the language definition phase more formal is likely to also improve compilation speed.
The JS needs to produce exactly the same, so: &amp;#x200B; \[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 243, 142, 83, 116, 36, 151, 191, 63, 20, 0, 0, 0, 155, 85, 159, 171, 173, 72, 64, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 116, 101, 115, 116, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\]
D has two problems, and there hasn't been enough movement in fixing either of them. 1) the standard library predates Alexandrescu, and Bright was not initially a fan of RAII. Unfortunately, that means it isn't usable for a lot of systems programming cases. 2) when two parts of the language interact poorly, the language tends to resolve the conflicts by fiat, rather than revisiting the underlying design. This makes for a faster evolution than C++, but it means you cannot always predict what will happen when you put two things together. Rust process you can have that particular cake and eat it too.
We don't need a reason to downvote you for baselessly attacking some imagined smugness
Wrong sub
r/javascript?
Can't you just plug this array in? It isn't that long.
No, I do read a object verb language (Êó•Êú¨Ë™û„ÉªJapanese), the verb goes at the end of the sentence.„Éî„Ç∂ (pizza)„Çí(object marker)È£ü„Åπ„Åæ„Åó„Åü (to eat, past tense, formal) compared to: I ate (to eat, past tense) pizza.
I did some practice project with actix web and diesel. actix web is pretty cool and the 1.0 beta is quite stable already. diesel on the other hand, it's easy to use for sure but the lack of pipeline and async is a problem IMO.
Yeah that work, but I need to convert the Input to that, not just plug the result lol
Really happy the site openly called the debate bikeshedding.
This language started from dynamically typed language that runs on register-based VM and now Jazz is statically typed and compiled programming language :) Jazz got two backends for now: 1. GCCJIT which emits GIMPLE tree and then emits from this tree machine code 2. C++: This backend translates Jazz AST into C++ code. I plan to add Cranelift as the third backend.
That does make sense, come to think of it. After all, how would it know to register Health if it's not mentioned anywhere? Thanks a bunch!
Is there a way for me to do nightly compilations temporarily without having to manually switch back and forth? I'd prefer not to get out of stable.
I think it's necessary to ensure the self expr is evaluated only once but the hack in $expr is not a good smell to me. We can introduce a new macro type $var that accept exactly an evaluated value. One think unclear is how it expresses the mutability of variable.
Thank you so very much for giving the community `ggez`. I went from knowing nothing about ggez to having that game in a day. And it was so very rewarding. Thank you.
Why bincode when you need it cross-language? Instead use CBOR, messagepack, capnproto, protobufs, or any of the other similar serialization formats that already have implementations in both Rust and JS.
You can do `cargo +nightly test` etc. to override the rustup setting.
Wrong sub. This one is about the programming language: [https://www.rust-lang.org/](https://www.rust-lang.org/) not the game: [https://www.reddit.com/r/playrust/](https://www.reddit.com/r/playrust/)
The `remove` methods should return `Option&lt;T&gt;` for that case, but you don't need `Option&lt;T&gt;` in the nodes themselves because the nodes in the list don't need to represent the empty state (if the list is empty, it has no nodes). Use `Box::from_raw` when removing the node from the list. It will take ownership of the `Node`, letting you move `data` out of it, and the `Box` will also free the memory of the `Node` when dropped.
I think ranges `..` and await `...` is used in quite different places so the risk of shooting yourself in the foot by confusing them is rather low. It would just lead to a compilation error, hopefully with a hint to change it into the right one.
The link you provided just works. I tested with an application client created in google developer console. Pass in the `client_id` and `client_secret` into the oauth authenticator parameter.
i've tried messagepack &amp; protobuf, they are both slower at serialization in rust
Of course, I'm not saying it doesn't work. The thing is that the API itself is something really big. It's not just dor sending emails. Which is why I was looking for something smaller. This API seems like overkill for what I want to do which is just sending emails.
&gt; So the answer is to simply dismiss segments of the population that disagree with you and ignore their viewpoint? Uh, fucking yes? Not every fucking viewpoint is valid or worth discussing. Just because someone somewhere can shit out an opinion doesnt make it worth anything. &gt; What about understanding their viewpoint and then figuring out an alternate solution that isn't so evil but satisfies their problems that made them follow the wrong position? There are not two sides to every damn issue. There are no "alternative solutions". The thing with facists is they have "viewpoints" like "this group literally shouldn't exist", and problems like "this group currently exists". Theres no "less evil" solution to that, especially when they actively deny any and all arguments that don't say "kill them all" and any facts that don't say "this group is literally evil satan criminal murderer rapists and deserve it, so we're actually the good guys!" ----- you're like the epitome of /r/ENLIGHTENEDCENTRISM right now. That is not a good thing.
Well then, thank you for making it worth it.
Can second warp - very cool model, and built on top of /u/seanmonstar Hyper which is very solid. &amp;#x200B; I must say I did enjoy Rocket and its documentation, although the shifting nightly documentation plus lack of async counts against it.
Is this landing in the 2019 edition?
k-i-F-F-I-n-g ("kiffen" means smoking weed in German)
Part of the issue is that it is hard to do a even handed comparison - various frameworks have their strengths and weaknesses. It is not the place for \_opinionated\_ comparisons either, because it cannot play favourites. For that, someone has to step in and do a review/critique post..
It's still in development. My guess is once it's finished and market share is sufficient enough they will release separate IDE or limit the plugin to intellij and clion though.
From your previous posts it seems you're really involved into using Meson instead of `cargo` for your code. I suspect you might be one of the Rust Meson "experts" around here, so it might be hard to get answers (since you know more about it than many of us). &gt; I seem to be having a hared time with releasing Rust project templates. Sometimes I like show people a visual representation of a project on GitHub instead of copying to clip board and pasting. Do you mean bad feedback or downvotes? I suspect it's because there's less intereste in using Meson for Rust. For pure Rust code, `cargo` works great, and since I'm not already using Meson for something else, I see no reason to learn it. If I want to link a small bit of C code with Rust, I'll use the `cc` crate. If I want to integrate Rust in an existing project, I'll need to use with my project's build system, be it `make`, `CMake`, `qmake` or anything else. If it's not already using Meson, there no reason why I should care. That said, I would expect integration with other build systems to use [`cargo --build-plan`](https://github.com/rust-lang/cargo/pull/5301), which unfortunately doesn't seem to work for `cargo test`.
Yes, I can see the problem with that. Thanks!
As others have pointed out, there are some crates that provide some support. There aren't currently any certified crates because of the costs, which means they can't be used in commercial products. Doesn't look like the videos are posted yet, but you might find the following interesting: [Bluetooth and Skateboarding: Safety-critical Embedded Rust](https://oxidizeconf.com/sessions/bluetooth-skateboarding/) - Ferdia McKeogh &amp; Jonas Schievink
Compile the rust code to webassembly ?
You need to ensure identical memory layout being used in Rust and Javascript. First, did you declare the type "Input" as '#\[repr(C)\]' to prevent reordering of members? Next: check byte-ordering and alignments, for example the 32bit types. Big Endian or Little Endian? Next: Is field7 a length encoded string (via field6) or a zero-terminated string? Or has field7 a fixed length?
Maybe it's a rust hack made in rust
Do you have anything written about language features? What makes this unique?
Right now I'm working on being able to reflect over the modules and functions exported from an [abi\_stable](https://crates.io/crates/abi_stable) dynamic library.
Since you want to retry why not while let Err(err) = Command::new(response).spawn() { eprintln!("Failed: {:?}"); }
Clion is pretty good
That's a solid idea that is the last option :)
I really do believe Rust is THE language for the next 40 years, even if I don't know anything beyond the basic syntax and principles and haven't written more than like 100 lines. It's just so powerful and so easy (once you understand the borrowing principle).
Adding more to gba-hal
Will that is a shame that you think I do this just for upvotes, and any feedback is better than none at least someone took the time to write a response. My usage of Meson has to do with using one tool for mutable languages for learning, experimentation, and maybe Android. But from what I can tell is none of you guys run fun experiments like the one where I install dependencies using a "PYTHON" program.
to be honest, i think this is kind of a storm on a teacup, i'm not very worried about consistency of a thing that may get turned into a trait later. Indeed i'd rather it was made into a 'special' function now to leave that door open and to overloads.
I didn't say you were doing this for upvotes, I only asked what you meant by "having a hard time", because it wasn't very clear to me. I did notice the lack of comments on your other posts in the meanwhile. &gt; My usage of Meson has to do with using one tool for mutable languages for learning, experimentation, and maybe Android. I'm not sure what you mean by "mutable languages". Non-FP like Haskell, or was it a typo for "multiple"? I don't see why Meson shouldn't be able to compile Haskell code, for example. Anyway, it's fine to experiment with whatever you want, but you shouldn't expect others to have the same interest in Meson. Build systems are a dime a dozen these days, and while I'm sure Meson is nice, it probably has less mindshare than other well-established ones. &gt; But from what I can tell is none of you guys run fun experiments like the one where I install dependencies using a "PYTHON" program. I can't speak for the others, but I wouldn't consider that fun in any way. I'm not really into Python and I've generally had bad experiences with Python programs including (but not only) mine. So for me the language is a downside, since I believe Rust and `cargo` to be more reliable and faster.
I agree. Love Rust at first sight. Although Rust costs me months (I'm not telling you that it took me a year) to understand how the Rust's new concepts works (especially lifetime). You're not gonna take that long, I'm just stupid, but after that time, I rarely fight with the borrow checker, just go writting code straight ahead. My proudest project is a server written on top of tokio, tend to replace Apache (no, i'm kidding, I'm not that good :) ), is more than 2500LOC. So I think I have experiences with Rust enough to say that Rust is not that hard, even when you don't understand what lifetime is, just follow directions from the compiler, then you're fine :) .And somewhere in future you will understand it, or just let the community helps you.
I don't really disagree with you, but : 1. Most language ecosystem weren't really ¬´stable enough nor complete to build a complex web application for production¬ª when they became popular. JavaScript while immensely popular for several year, has never even reached a state of stability and seams to be in perpetual search for novelty. Go became popular way before it could claim to have a complete enough ecosystem (idk if it changed, but 3 years ago if you needed something out of the standard library, you'd only have choice between implementing your own stuff or using an often poorly maintained third-party library. And yet, Go was getting pretty popular at this time). 2. Finding a \*\*good\*\* web developer is the hard part, with Rust at its current stage you avoid a lot of false positive. Also, Rust code tends to be easier to maintain than languages with a weaker type-system (or no type-system at all). 3. This is 100% personal opinion, but I have yet to find a language or framework that is ‚Äúso good it would be a real waste of time not to use it‚Äù. Existing languages and framework (including Rust and its ecosystem) are in a range from ‚ÄúOK-ish‚Äù to ‚Äùfine‚Äù. That's why I'm using Rust right now, because I feel it has the potential to be better than what we already have (more performant while being more ergonomic at the same time). &amp;#x200B; As far as I'm concerned, I would have no issue recommending Rust today to a business if they : * aren't doing too exotic things (or are willing to implement the corner cases by themselves) * have a team lead who is curious about Rust * are building a back-end with a medium load and they don't want to bother with horizontal scaling Which is pretty much why people tried NodeJs circa 2011, and Go in 2014-2016. &amp;#x200B; Having lived through both eras, I don't think Rust in its current state has any reason to be shy.
Given the coverage I'm surprised about having to ask this but, What is the final decision from the lang team regarding async await syntax? I read that they settled on postfix dot but I've also read arguments that it somewhat hides work being done behind what looks like a field access, not that this can't be forced anyways with deref. Is there a viable functional demonstration program of this in action? I don't mind if it's a simple sleep operation as long as it illustrates the delay in computation.
https://www.reddit.com/r/rust/comments/bn942d/snips_tract_neural_network_inference_library_in/
It should work directly if you derive `Serialize` and `Deserialize`. How did you try it? The `rust_decimal` crate has a `serde` feature that is enabled by default.
I played a lot with D (D2) years ago. The language is nice yet has that OO vibe that I, today, dislike very much. So D is a no-go to me. Inheritance (the class idea) is a concept that I loved when I first learned C++, when I was 12. I then discovered Haskell and type systems, and to me, OO paradigms (especially inheritance) are failed concepts on the type level. You can still have that ‚Äúsuper‚Äù relationship with typeclasses and traits and all the benefits from it without the drawbacks (overriding, protected inheritance, virtual wtflollazer inheritance, diamond, etc.). Though, D‚Äôs mixin templates and static if are lovely. :)
Doing the final touches on my master thesis implementation. Researching the possibility of using DeepRL (MCTS + DNN, similarly to AlphaGo) for preventive maintenance planning. Mostly Rust due to performance but a bit of Python to have a nicer interface with Tensorflow
For now, this language "unique" since Jazz can be JITed, AOT compiled and translated into C++ ( I know there are Haxe but it's not a system programming language). There are a few features that I want to add: 1. Const functions 2. Macros 3. Support for memory allocation in const functions 4. Polymorphic types and structs
Remember that zero-costness is always *relative* to some other implementation you are presumed to do by hand. A common optimisation for loops is unrolling them to process a batch of data linearly, making the loop larger and thus reducing of the overhead of book-keeping. This only works if the compiler can prove that such an optimisation is valid. For some cases, it's easier to prove that optimisation valid for iterators. Another such thing is vectorisation.
Tuples are treated the exact same way as C structs. Does that count as "optimized out completely"? I'd say it does. A better example for "zero cost abstractions" is `Option` - you can generally deal with `Option`s the exact same way you deal with a nullable value, and the compiler will optimize it so that `None` is (literally) `null`, and anything that's not `null` is `Some`.
You asked almost exactly the same question here a few days ago. If you didn't get the answers you were hoping for, please respond to the people trying to help you over there rather than making a new thread.
I think as long as the `Deref` implementation isn't exposed in crate API it's only bad practice if it causes internal problems? I don't see the harm in it here, although I may be missing something obvious.
&gt; Obviously, generics, and therefore traits, are zero-cost in rust Unless you use `&amp;dyn Trait`. Then it's a different trade-off than in C++ -- larger pointers, but faster dispatch. &gt; For instance a tuple seems like a good abstraction away from dealing directly with two separate values and keeping track of each one. In C++, however, these are not zero-cost. I wasn't aware of that, can you give an example? &gt; are there actually cases where the overhead of tuples is actually optimized out completely? Possibly, optimization is a tricky business. I know there are some issues with returning large `enum`s from functions, which sounds similar to tuples. Other zero-cost abstractions in Rust: - zero-sized types (C++ can't do that because every value needs to have an address) - enum discriminant optimizations which I hope are done for `Option&lt;NonZeroI8&gt;` and friends (storing `None` as `0`) - chaining iterators can produce pretty fast code, sometimes better than a `for` loop - `await` and `Future`s supposedly require fewer allocations than the C++ proposal has; `await` is not zero-cost yet, but there is hope. - macros, build scripts and `const` initialization can output constructed values (cf. `constexpr`) There might be more, but I can't think of any right now.
&gt; the compiler will optimize it so that None is (literally) null, and anything that's not null is Some. You're probably thinking of `Option&lt;&amp;T&gt;` or `Option&lt;NonZeroI8&gt;`. `Option&lt;*const T&gt;` will be two words in length.
Yes, this only works for types that can't normally be `Some(0)` or `Some(null)`.
Not quite. `Option&lt;T&gt;` costs the size of a boolean plus the size of `T`, with the exception when `T` is known to be non-zero; then and only then is the 0-case considered None. I.e. `Option&lt;&amp;T&gt;` works because a reference must not be null. // Some(0usize as &amp;T) is None assert_eq!(Some(unsafe { &amp;*(0size as *const u8) }), None); Similarly an `Option&lt;NonZeroUsize&gt;` is internally just a `usize` that is `None` when `0`.
Actix is fine, but diesel has a lot of basic sql concepts that are still not supported. Including "group by" ( https://github.com/diesel-rs/diesel/issues/210 )
Thank you for this crate. I'm working on a project of mine and it will be \*heavily\* leveraging this crate. I won't need it for another week or so yet, but when I do, oh man, you will save me soooooooo much time.
Quoting [this](https://boats.gitlab.io/blog/post/await-decision/): "In brief, we intend to make a final decision on May 23, and we currently favor adopting the ‚Äúdot await‚Äù postfix syntax. All of this is elaborated further in this document." &gt; Is there a viable functional demonstration program of this in action? I don't mind if it's a simple sleep operation as long as it illustrates the delay in computation. I'm not sure what exactly you are asking about. But if you want to see an example involving a delay with the new proposed syntax, have a look at [this blog post](https://jsdw.me/posts/rust-asyncawait-preview/) and replace `await!(expression)` with `expression.await`. I havn't tested this new syntax yet but I believe it [should work on a recent nightly version](https://github.com/rust-lang/rust/pull/60586).
VSCode is pretty good
To be clear, that's still zero-cost. Under the assumption that `*const T` being null is a valid value without special meaning, it's still zero cost. You'd need to signal that somehow, even in C. You'd have 3 statements: * None, the thing just isn't there * Some(0), the thing is there, just doesn't carry data * Some(non_null_ptr), the thing is there, and here's the data This _might_ not be super-useful. If you don't want to signal a secondary property of the pointer, you'd just use bare thing :).
Of course. I was talking about the assertion that: &gt; compiler will optimize it so that None is (literally) null, and anything that's not null is Some.
Sublime Text is great
What do you mean by "game server", exactly? The difficult part of writing a game server isn't just accepting 100k connections, it's writing the game logic and storing data and all the other things no one but you can build.
Great example, thanks.
Really cool work! :)
&gt;Less powerful type system, no HKT's, no existentials etc. So more advanced functional programming constructs are hard to express in Rust. Would you mind to give more information about this paragraph and explain it in more details?
What would you recommend for network layer snd database access, something that scales well?
They wouldn't, but the performance cost would still be there.
That depends entirely on what protocol you'll be using, and what database.
It unfortunately doesn't work and the Struct has Serialize and deserialize. It works with all other fields, if I remove the Decimals fields then it works right away.
Generics are a planned feature and originally the lack thereof was a design decision since it was out of scope. Go is a language to solve ‚Äúgoogle types of problems‚Äù so to speak. The intent was for it to be a language to write easily maintainable server programs that are scalable and concurrent. Sure there's plenty of reasons that Go may seem the odd one out when listing modern languages, but it has it's advantages over C++ and Java when writing ***server programs*** which warrants it to be a modern language. But as with programming, having the rights tools for the job can make a world of a difference.
i thought it was \`bike-shedding\`
Yeah, I just got confused by you first saying that iterators aren't zero-cost, and then following it up by saying that some iterators are faster (than `for` loops). So just to be clear, you're saying that `for` loops in some cases aren't zero-cost when you compare them to iterator adaptors, and not the other way around?
Thanks for the reply. After my post I started thinking and realized a couple things. The power of a modern computer to rip through a search ,even an exhaustive one, is such that I really am over thinking the problem. Also that when people start telling you that‚Äôs really not a good idea it‚Äôs best to think about their reasons why it‚Äôs not before thinking ‚ÄúI‚Äôll show them‚Äù. The last time I wrote a similar program It was around 1990. I had a huge half a megabyte of ram computer with a 8 MHz cpu. The data needed to be stored on two different floppy drives so if the power,from a generator, got cut mid write one set would still be good. That was the most fun I ever had at a ham radio field day.
 I can't figure out the lifetime issues with this code: fn assert_call&lt;'a, F&gt;(func: F, _: &amp;str) where F: for&lt;'b&gt; Fn(OutputBuilder&lt;'a&gt;, &amp;'b DebugObject) -&gt; OutputBuilder&lt;'a&gt;, { let mut out = DebugOutput::new(); let me = DebugObject::me(); let ob = out.out(); func(ob, &amp;me); } fn main() { let f = OutputBuilder::a::&lt;DebugObject&gt;; assert_call(f, "xxx"); } [Rust playground](https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=64a82d550249adc9d6cfcb98789d924b) The compiler complains about `out` not living long enough. I solved it in my program by changing the assert\_call function to take a closure instead, but I would really like to know how to fix this without a closure. How should assert\_call be defined for it to work?
I don't need a database, I'll be using firebase, I need something that plays well with websockets and docker, say I need to deploy on multiple servers, stuff like that.
Firebase _is_ a database though. You're still going to need to access it somehow. Also, scaling across multiple servers will require a load balancer or a matchmaker of some sort. Are you building your own? What is your architecture going to be like? It seems to me like you're making low level implementation decisions way too early.
Working on a Rust port for blockstack's [secret sharing library](https://github.com/pawanjay176/secretsharing).
https://areweideyet.com/
Was trying to solve this easy problem in rust: https://leetcode.com/problems/letter-combinations-of-a-phone-number/ I started out okay but quickly tangled myself up trying to resolve compiler warnings one by one. At this point I would appreciate two things: - How to make this code work efficiently? - Is this the best way to solve this problem in rust? impl Solution { pub fn letter_combinations(digits: String) -&gt; Vec&lt;String&gt; { let mut result = Vec::new(); fn get_c(combination: &amp;String, next_digits: Vec&lt;u8&gt;, result: &amp;mut Vec&lt;String&gt;) { let keypad: HashMap&lt;char, Vec&lt;&amp;str&gt;&gt; = [ ('2', vec!["a", "b", "c"]), ('3', vec!["d", "e", "f"]), ('4', vec!["g", "h", "i"]), ('5', vec!["j", "k", "l"]), ('6', vec!["m", "n", "o"]), ('7', vec!["p", "q", "r", "s"]), ('8', vec!["t", "u", "v"]), ('9', vec!["w", "x", "y", "z"]), ].iter().cloned().collect(); if next_digits.len() == 0 { result.push((*combination).clone()); } else { for &amp;letter in keypad[&amp;(next_digits[0] as char)] { get_c( &amp;((*combination).clone() + &amp;(*letter).clone(), next_digits[1..].to_vec(), result); } } } if digits.len() &gt; 0 { get_c(&amp;mut "".to_string(), digits.into_bytes(), &amp;mut result); } result } }
Beyond all the 'clever' things Rust does ‚Äî which have been pointed out in the other comments ‚Äî an important aspect of the zero-cost principle is that basic things like `Vec`, `Box`, and even `for`-loops are zero-cost. That is to say: a `Box` [is just a pointer](https://doc.rust-lang.org/src/alloc/boxed.rs.html#96) with some compile-time checking. A `Vec` [is just a length and](https://doc.rust-lang.org/src/alloc/vec.rs.html#293-296) [a capacity and a pointer](https://contain-rs.github.io/raw-vec/src/raw_vec/src/lib.rs.html#53-56). A `Range` (as in `0..925`) [is just struct with the start and end point](https://doc.rust-lang.org/src/core/ops/range.rs.html#72-79). A `for`loop [is just a loop](https://godbolt.org/). A `mod` is just a compile-time collection of items, etc. In general: when Rust has a feature _F_ which implements a programming aspect _A_, and your program requires implementing aspect _A_, just picking feature _F_ is typically going to be the right choice; reimplementing _A_ yourself (either in Rust or in C or ...) will not yield better performance. Rust's implementation of `Vec` is about as good as an implementation for dynamically-sized linear collections of a single (compile-time monomorphised) data type will get. Of course, special requirements may make it necessary to build custom data structures, but if you just need _a_ vector/box/hashmap/buffered-filereader/loop/thread/tagged-union/callable-code-abstraction/etc., Rust's built-in versions will have zero overhead compared to what you might have coded up yourself.
I‚Äôd add const fn() as a zero cost abstraction, because those functions are not only inlined, but evaluated during compile time.
Yes well I just need http for firebase, regarding the architecture, haven't decided yet
Well, you need to decide before on the architecture before you decide on the tech, don't you think?
Pretty cool man! I like the way the video is presented. It's entertaining to watch as well :)
I made your code compile: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5e1905c947c018a56930c7c5225f4c1d You were mixing up borrowed and owned values, in particular `for &amp;letter in keypad` was screwed up. By iterating over `keypad` directly (instead of `&amp;keypad`) you are already getting owned values out of the HashMap, which you then try to pattern match with a `&amp;letter`, resulting in a compiler error because the iterated value is not a reference and can't be pattern matched this way. If you want to iterate over references to the content of `keypad`, just use `for letter in &amp;keypad`. Other than that I didn't look too closely at the solution, but it seemed to work with the given (very minimal) testcase.
Sounds cool, applied through linkedin, if you don't mind.
I think you're missing some basic info! Is it garbage collected? Memory safe? Compatible with C? Etc.
The way I read it is that ‚Äòa is tied to the caller context and as such the reference on the stack (dropped after the function) can‚Äôt comply to that rule (out through ob through F).
Futures are zero-cost, if only because it requires some external code to implement the parts that actually do take up CPU time.
I'm still working on [issue #92](https://github.com/wahn/rs_pbrt/issues/92) and you can see for the first time some structure in the rendered cloud, but it's still very **different** from the C++ version ...
I figured you did, just given that I frequently have this discussion, I felt like adding it. I should have stated that, sorry.
Thank you. I would definitely appreciate if someone commented on making this idiomatic for this approach. In addition, I saw a couple of people have posted their solutions in rust that look different. [1] https://leetcode.com/problems/letter-combinations-of-a-phone-number/discuss/240270/Rust-solution [2] https://leetcode.com/problems/letter-combinations-of-a-phone-number/discuss/229674/Rust.-0ms
Does someone have a precise explanation of why an array cannot be iterated by value? The \`into\_iter\` method does not consume the array: why that?
That is cool, what about coubase-lite , are any plans for Rust wrapper for it?
While you are probably better of deserializing any other binary format, bincode is rather straightforward to implement in JavaScript (or as I decided to use here, TypeScript) by using parser combinatorics. class Cursor { bytes: DataView position = 0 constructor(bytes: ArrayBuffer) { this.bytes = new DataView(bytes) } } function read( cursor: Cursor, property: { [K in keyof DataView]: DataView[K] extends ( this: DataView, position: number, littleEndian: true, ) =&gt; number ? K : never }[keyof DataView], length: number, ): number { const value = cursor.bytes[property](cursor.position, true) cursor.position += length return value } function u8(cursor: Cursor): number { return read(cursor, 'getUint8', 1) } function u32(cursor: Cursor): number { return read(cursor, 'getUint32', 4) } function u64(cursor: Cursor): Uint32Array { const a = u32(cursor) const b = u32(cursor) return new Uint32Array([a, b]) } function f64(cursor: Cursor): number { return read(cursor, 'getFloat64', 8) } function u8Array(length: number): (cursor: Cursor) =&gt; Uint8Array { return cursor =&gt; { const array = new Uint8Array(cursor.bytes.buffer, cursor.bytes.byteOffset + cursor.position, length) cursor.position += length return array } } function str(cursor: Cursor): string { const longValue = u64(cursor) const a = longValue[1] const b = longValue[0] if (a !== 0) { throw new Error("String too long") } const bytes = u8Array(b)(cursor) return new TextDecoder('utf-8').decode(bytes) } function arrayOf&lt;T&gt;(type: (cursor: Cursor) =&gt; T, length: number): (cursor: Cursor) =&gt; T[] { return cursor =&gt; { const array = [] for (let i = 0; i &lt; length; i++) { array.push(type(cursor)) } return array } } const cursor = new Cursor(new Uint8Array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 243, 142, 83, 116, 36, 151, 191, 63, 20, 0, 0, 0, 155, 85, 159, 171, 173, 72, 64, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 116, 101, 115, 116, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]).buffer) const input = { field1: u8Array(32)(cursor), field2: u8Array(32)(cursor), field3: f64(cursor), field4: u32(cursor), field5: f64(cursor), field6: u8Array(32)(cursor), field7: str(cursor), field8: arrayOf(u64, 8)(cursor), field9: arrayOf(u64, 8)(cursor), } console.log(input)
I'd look into `binwalk` - it can detect a lot more than `file` can, at the cost of being somewhat slower.
The question is too hard to answer without details, also it depends what kind of game you are working on, because each genre has different requirements, from real time to turn based, also it might influence if they are mobile or desktop (you can ignore a bit the latest and not optimize it for power consumption, but the first needs it), also IMHO depends on the game engine you are using, because it‚Äôs bette to use the same engine in both client and server (if you need to run physics simulation in both, so your results will be the same and you don‚Äôt need to write all twice).
See https://docs.rs/mime-sniffer/0.1.2/mime_sniffer/, but if `file` doesn't work, your file is probably more or less corrupted. You can still do an automatic pass to find e.g. valid JPEGs so you have fewer files too look at.
Definitely. This question though is just to know what Rust has to offer in terms of frameworks and things like that.
Well, that depends on what sort of frameworks you want. If you're doing raw TCP/UDP, look into [Tokio](https://tokio.rs/). If you're doing HTTP, check out [Are We Web Yet](https://www.arewewebyet.org/), it lists a bunch of web frameworks you could use.
Cool video! Would love some content in Amethyst. Though, it might be more difficult to fit into a short video. I've struggled learning Amethyst as a non-game programmer. I've debated using GGEZ + Specs. However I keep trying to tough it out with Amethyst haha.
It turns out that arrays don't have iterators at all. The reason for that is that arrays are magical types. Until "const generics" stabilize, no other type besides is allowed to have a number as a type parameter. That makes it hard to have an `IntoIter` type that owns an array. (It might not be impossible, but I think it would at least be very hacky, whereas with const generics it'll be natural.) However, another magical property of arrays is that they coerce to slices in many cases, particular when you call methods on them with the `.` operator. (My understanding is that this isn't literally a "deref coercion", but it's very similar.) So what's actually happening with `my_array.into_iter()` is that it's coercing to a `&amp;[T]` slice and calling `.into_iter()` on that. And since `&amp;[T]` is a shared reference, it's not consumed by iterating over it.
Are you trying to _design_ a protocol or _implement_ one?
This should be your first option IMHO
Go vs Rust has been more a historical coincidence than technical parity. They started buzzing at roughly the same time, Google vs Mozilla, etc. Nevertheless, feature-wise, both boast improvements on multi-threaded programming, memory security for network facing services, and single binary deployment, which deserve comparison. Zig vs Rust is about low level memory management, how they differ in their handling of pointers, and zero-cost abstractions. All told, enough people might want to learn from the different trade-offs the three languages each make. That C/C++ has outlived many of its competitors may have an analogy with how Kosher food comes to disproportionately affect packaged food market. As Nassim Taleb has observed in *Skin in the Game*, the most intolerant participants exert disproportionate influence over the market. C/C++ can run in the most intolerant environments (or business requirements), where other technically superior languages fail one way or another. To that end Rust has fared much better. Reference: https://link.medium.com/AybNjOSMEW
I'm different person than /u/A1oso so I don't know what they exactly meant, but if we compare to super-optimised assembly, neither for loops nor iterators are going to perform as well without optimisation. It depends on the situation what the compiler is able to optimise, so I think that what counts as "zero-cost" is a bit fuzzy? But in most cases designs where the compiler could be "see through" the abstractions; that is, if they readily yield to non-global static analysis, they can be said to be zero-cost.
Both preferably. but my knowledge on the subject is close to zero so I wouldn't mind one or the other. I kept the title broad on purpose to accommodate more interesting stuff.
My guess is once it's finished and market share is sufficient enough they will release separate IDE I've talked to one of the devs in the past, and they said that there were no such plans. Don't know if anything changed since though.
What sort of "stuff"? Your question is very vague right now. What are you actually trying to achieve here?
Check the network category in arewegameyet.com ( http://arewegameyet.com/categories/networking/ ).
Could be that gmail does not allow password login via smtp anymore and also requires an oauth tkn for smtp
Love to see rust positions in Tokyo + not related with cryptocurrency. I took the liberty to tweet it!
Looking for assistance getting inner attributes (doc comments specifically) working in a proc-macro. Given a simple proc-macro lib pmt: extern crate proc_macro; use proc_macro::TokenStream; /// ```rust /// pmt::test! {} /// /// fn main() {} /// ``` #[proc_macro] pub fn test(_input: TokenStream) -&gt; TokenStream { let ts = quote::quote! { //! Inner doc comment. }; ts.into() } running `cargo test` gives the following error: ---- src\lib.rs - test (line 5) stdout ---- error: an inner attribute is not permitted in this context --&gt; src\lib.rs:6:1 | 3 | pmt::test! {} | ^ | = note: inner attributes, like `#![no_std]`, annotate the item enclosing them, and are usually found a t the beginning of source files. Outer attributes, like `#[test]`, annotate the item following them. error: expected item after attributes --&gt; src\lib.rs:6:1 | 3 | pmt::test! {} | ^^^^^^^^^^^^^ thread 'src\lib.rs - test (line 5)' panicked at 'couldn't compile the test', src\librustdoc\test.rs:351:13 Putting a `mod m { ... }` around the proc-macro execution still gives the same error but putting the `mod m { ... }` inside the `quote!` call works.
Sounds very cool. Best of luck.
The array type holds its elements directly. There is no indirection involved. If you wanted to consume an array to produce an iterator, the elements would have to move somwhere which is not free of any cost. And you would have to make a decision about where to move them. You could move them into a Vec and then call into_iter on it. But that requires a heap allocation. You could also move the elements into the iterator. But then you'd end up with a possibly large iterator. Iterators are usually expected to be rather "light-weight". I don't think there is a right or straight-forward way to do this directly. But you could do this: let a = [1,2,3,4,5,6,7,8,9]; // move array into a Vec... let v: Vec&lt;_&gt; = (Box::new(a) as Box&lt;[_]&gt;).into(); for i in v { println!("{}", i); } Or this: let a = [1,2,3,4,5,6,7,8,9]; // move array into an ArrayVec... let mut av: arrayvec::ArrayVec&lt;_&gt; = a.into(); for i in av.drain(..) { println!("{}", i); } The difference between `[T; N]` and `ArrayVec&lt;[T; N]&gt;` is that the latter supports a state where `len() &lt; capacity()` which allows to "drain" it and have it still in a valid state. A "raw array" `[T; N]` on the other hand has *always* `N` valid elements which makes draining it impossible for arbitrary `T`. But `ArrayVec` also doesn't have an `into_iter` probably for the same reason. The elements would have to be moved somwhere and we should probably avoid moving them into an iterator because iterators are expected to be rather leight-weight.
Holy hell, that sounds like a dream job to me O.O I don't feel I'm qualified enough for it (yet!) But i hope to see an opportunity like that again :) (Also, relocation to Japan sounds both awesome and terrifying to me at the same time)
Yes, me too, but how does one solve it? Moving `'a` to `for&lt;'a, 'b&gt;` will make it complain that the provided function and the F type doesn't match, it just want a single lifetime parameter there. Removing `'b` does not help.
Reviewing pull requests for [`uom`](https://github.com/iliekturtles/uom) (Units of measurement -- type-safe zero-cost dimensional analysis) (Thanks dunmatt!) and experimenting with proc macros. Attempting to solve a proc macro doc comment [problem](https://www.reddit.com/r/rust/comments/bo053e/hey_rustaceans_got_an_easy_question_ask_here/enbq4xt/) right now.
Is this going to allow generating threshold secrets without a trusted dealer?
This could really use a complete example project to show how to use it, even if it was a trivial one. Below is a small snippet I wrote in the past to iterate over struct fields. It seems like pegcel is meant to make writing this easier/more readable. Without examples it is tough to say; I'm not familiar enough with Syn to immediately know how to use your crate. if let syn::Item::Struct(mut struct_item) = original_struct { if let syn::Fields::Named(ref mut fields) = struct_item.fields { for field in fields.named.iter_mut() { ... } } }
Maybe "this comment" refers to the comment itself rather than what it's replying too
Unfortunately the downvote-punishments are a thing here now. I recently got the treatment because I wanted people here to be less aggressive. In the beginning it was called out, but that doesn't even make sense anymore now that innocent posts can reach -30 without trouble.
To illustrate non-zero-cost abstraction in a different language: in Java, a ArrayList&lt;Integer&gt; needs to box all primitive integers as Integer objects, leading to higher memory usage and lower performance, so there is an incentive to rewrite a specialized IntegerArrayList manually (I've seen it in enterprise code). In contrast, in Rust, a Vec&lt;i32&gt; is indeed as performant as what you would write yourself, so there is no need to.
Nah, this is the present. The future is [this](https://github.com/rust-lang/rust/issues/46213).
The nRF52 series currently has [pretty good Rust support](https://github.com/nrf-rs/nrf52-hal/) (better than the TI chips AFAIK), and is also [Rubble's ](https://crates.io/crates/rubble) primary target family (although I'd love to add support for other families). Rubble currently allows establishing connections and has rudimentary (G)ATT support. We're currently in need of a better GATT interface that allows declaring services and characteristics, as well as reading/writing them and sending notifications on changes. If you want to help out, this is what we need most right now, and is essential for higher-level protocols. There's an issue filed for it [here](https://github.com/jonas-schievink/rubble/issues/29). Note that Rubble only aims to be a BLE stack, not classic Bluetooth (the hardware you listed only supports BLE in the first place). BLE does not have support for RFComm, there are only proprietary services providing "wireless UART" functionality. I don't mind supporting these in Rubble since they're still pretty useful. BLE does support standardized GATT-based HID services though.
The one zerocosties feature of Rust is borrow checker. Any other languages requires overhead to guarantee memory safety, safe Rust does that in compile time thus zero cost at runtime.
This is about runtime errors, not compiler errors. The only compiler errors that can produce backtraces are ICEs, and they should really be on by default for those since it helps the compiler team debug them.
The default panic hook is what prints the backtrace, and it will fire on every `panic!` call, regardless of whether it will be caught or not, so the trace would always be printed then. The only way to unwind without invoking the hook is by using `panic::resume_unwind`, and that won't cost anything since the backtrace is never generated.
Are we talking about RUST_BACKTRACE? That's what I was referring to. I thought OP was saying that should be on all the time.
&gt; Do you get an automatic backtrace when panic = abort? The backtrace is printed by the default panic hook in libstd, which happens before the actual panic implementation is invoked, so the backtrace-handling code is the same in both cases.
There is no cost if you're not *actually* producing a backtrace by panicking, and panicking is a slow path in any case.
If it is not performance-critical, stick with json over http. If it is performance-critical, chose some binary format which fits your needs, like protobuf. It all depends on what you are trying to achieve...
Maybe have a look at some of the tokio-serde-x implementations?
I'd like to point out that abstractions w/o unnecessary overhead, yet if there is some unavoidable overhead, should not be labeled zero cost. `Vec` requires allocation, so it is not zero cost. I.e. I can't just put values into `Vec` w/o overhead, so I should avoid doing so if I can, for example, put them in array.
Don't you need to allocate and gather the backtrace regardless of when or if you'll panic?
zero-cost does not mean no cost, it means no extra cost over manually writting code that does not use the abstraction, but emulates instead. E.g. the function abstraction adds overhead (function calls, requires a stack, a calling convention, etc.) and you can manually write code without it. However, if you wanted to be able to reuse code in a binary without functions, you'd need some concept of calling convention, how to get there and go back (function call), etc. Functions are a zero-cost abstraction over manually doing that, if and only if, there is no manual way of doing something that's feature-wise the same as functions, but in a faster way.
Yes, but that only governs backtraces on panics, the "Rust already shows amazing error messages with where they came from and with suggestions" is only true for compiler errors, which never print a backtrace.
No, it's currently done by the default panic hook in libstd, which checks `RUST_BACKTRACE` first. All information needed for building a backtrace is already contained in the executable anyways.
Making games isn‚Äôt too difficult in rust, there‚Äôs tons of lovely frameworks out there already to get rid of the annoying stuff and it really helps improve your rust skills. Contributing to open source projects that you enjoy can also be a great way to collaborate with more experienced rust programmers and code something, without having to come up with the idea on your own.
Do not write a network protocol from scratch. Usually you can use existing ones.
Zero-cost abstraction refers to paying performance-wise only on things that **you actually use**. It also means that what abstractions, you **do use** yield the most performant assembly possible without writing the assembly yourself. Or, as Bjarne Stroustrup, the creator of C++ put it: &gt;C++ implementations obey the zero-overhead principle: What you don't use, you don't pay for \[Stroustrup, 1994\]. And further: What you do use, you couldn't hand code any better. &gt; &gt;\-- Stroustrup Now, to answer your question: &gt;For instance a tuple seems like a good abstraction away from dealing directly with two separate values and keeping track of each one. In C++, however, these are not zero-cost. How much does the compiler optimize away in Rust, and are there actually cases where the overhead of tuples is actually optimized out completely? In the case of Rust, this applies even more since **most of the optimization is offloaded to the compiler**. In other words, **in practice** **it is far easier to write slow C++ than slow Rust**. In the case you are describing, tuples are slower because they are implemented above the compiler level and thus **optimizations are left to the programmer**. In Rust on the other hand, tuples are first-class citizens and they are optimized away by the compiler automatically.
Borrowing is sometimes zero-cost, isn't it? AFAIR, if you convert a really long single-liner into a bunch of lines with a bunch of assignments, you don't actually allocate more memory than you would by writing the single-liner. Ie: These should produce the same binaries: ``` let r = 1 + 2 + 3; // VS let x = 1; let y = 2; let z = 3; let r = x + y + z; ```
I will check those crates. Thanks!
`ArrayVec` does implement `IntoIterator` (by moving it into the iterator). &amp;#x200B; Why is it impossible to implement `IntoIterator` for arrays? We could move the array into the iterator like `ArrayVec`, nothing (I know of) states an iterator has to be small and a simple line in the documentation could address this issue. As for the "always valid state", why not just explain the array is consumed even if the iterator is partially consumed or not touched at all like `Vec`'s drain documentation? &amp;#x200B; I read the lack of features for arrays is due to a lack of love, because most of the time when you want an array you can easily get away with a `Vec` or a crate.
I ran into that same issue as well. So I ended up working on a neofetch-like tool in Rust (with help from a couple other people). Try making a Rust variant of a favorite tool that you use.
Come on, you could it better struct FooIter(Foo); impl FooIter { fn into_iter(self) -&gt; impl Iterator&lt;i64&gt; { let inner = self.0; Some(inner.field_1).into_iter() .chain(Some(inner.field_2)) .chain(Some(inner.field_3)) .chain(Some(inner.field_4)) .chain(Some(inner.field_5)) .chain(Some(inner.field_6)) .chain(Some(inner.field_7)) .chain(Some(inner.field_8)) .chain(Some(inner.field_9)) .chain(Some(inner.field_0)) } }
I have been _wanting_ to write such a guide for a long time. Does that count? I never got further than writing the specification of a protocol syntax, [PlainTalk](https://magnushoff.com/plaintalk/introduction-and-definition.html), which can be used for creating application-level protocols. To get some experience, try implementing a few different protocols. It's not too hard to get an HTTP/1.1 implementation up and going. IRC is super easy, and illustrates some protocol design failures :) IMAP is a horrible learning experience :D Knock yourself out :)
Apologies if this is the wrong place to ask this, but I have a bit of a tech support issue. If I should be posting this somewhere else I'd appreciate being directed there. Trying to install Rust for the first time. rustc exits every time with code 0xc0000022. This is making it impossible to do basically anything as far as I can tell.
Ugh. You're getting a `DeserializeAnyNotSupported`, right? I think the issue is that `rust_decimal` can deserialize itself from multiple types (`f64`, `i64`, `u64`, `&amp;str`), but `bincode` can't tag the serialized value (which will always be a string). See the note [here](https://serde.rs/impl-deserialize.html). As a workaround, you can manually implement `Serialize` and `Deserialize` for your struct, or define a newtype wrapper around `Decimal` that does the same thing. See https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=30715b31798f2b2217bdc4273e293242.
If you make a not be a member function but an associated function or a standalone function it works.
Setting the playback speed to 1.25 worked great for me. I *liked* the talk.
I have read rumors here and there that Rust seems to be catching on in Asia faster than in the West. Any truth to that?
Blanket advice like this is seldomly helpful. It seems clear that OP is looking for a learning opportunity. If he wanted to solve a business problem, using an existing protocol is likely a better solution, but this is not universally true.
I couldn't recall the rationale to this so I looked back through the history, and I believe there was no rationale beside whatever was in /u/acrichto's head when he added backtraces to Rust. [Here's the PR that added backtraces to Rust](https://github.com/rust-lang/rust/pull/12602), and a [follow up that added `RUST_BACKTRACE`](https://github.com/rust-lang/rust/pull/12791/commits/0015cab1fd7b4b47030c808a825bb5594cc1d4ac). In the first, backtraces were behind the logger for the rt::backtrace path. The second commit indicates that "for now logging is turned off by default", so he clearly had an idea that it might be flipped on later. That "for now" comment exists to this day. If I were to guess, it was primarily because it was a new feature, so having Rust spewing backtraces suddenly would be an unexpected change in behavior, so the natural thing to do was make backtraces opt-in. Some additional speculation: backtraces are currently printed piecewise to stderr with no buffering. panicks can cascade into more panicks and seeing multiple backtraces interleaved is super-unpleasant. Further speculation: rust was once a lightweight-threaded model where thread panics and recovery was exepected, implying lots of backtracing. Today panicks are uncommon in most codebases, so fewer backtraces would be generated. Another reason is that it just looks ugly to see backtrace spew in a program that can recover from it - imagine seeing your own program outputting nice clean status updates, but every once in a while it is interrupted with 100 lines of garbage that doesn't matter because your program recovers from it fine. There's also the matter others mentioned that backtraces cost, which matters for panick-heavy workloads, which I'd expect to be rare in modern Rust. (PS: I see some post-hoc rationalization in this thread without citation. Read the source friends).
Nice! I think Deno will be as popular as Node.
I would be happy to be wrong about this one. My guess is based on what happened with Go.
Very interesting! Going to star it for now and watch for future updates
Or rewrite in Rust a program that you've written in another language. Also, https://www.reddit.com/r/rust/comments/aofoj1/project_ideas_specifically_for_rust/. /u/Valley6660 so what's next? :-)
I had the same thought, what an amazing experience would be living in Japan, but at the same time completely different to what I'm used to (western). I hope to be able to qualify to this kind of positions.
One of my old colleagues decided to move to South Korea. I prefer the Dutch mindset on the workfloor, haha. I don't think East Asian expectations would fit me well.
Thanks for the explanation. If I understand well: * It is theorically possible to do such a thing with the typenum crate, * When const generics will be a thing, the arrays won't still be consumable (at least with \`into\_iter\`) since it would be a breaking change. That's sad.
I hadn't read your code, but maybe this would be useful to read &amp;#x200B; "The Rustonomicon - The Dark Arts of Advanced and Unsafe Rust Programming" [https://doc.rust-lang.org/nomicon/](https://doc.rust-lang.org/nomicon/) It has a section about FFI. &amp;#x200B; Then there is bindgen - "Automatically generates Rust FFI bindings to C (and some C++) libraries." [User guide](https://rust-lang.github.io/rust-bindgen/), [GitHub repo rust-lang/rust-bindgen](https://github.com/rust-lang/rust-bindgen)
lol "No opportunity for remote work, you'd have to work on-perm." More like you'd *get* to work in Tokyo :P
Interesting, could you elaborate more about it? I'm currently living in The Netherlands and would like to know what's the contrast , or what could I expect there if I decided to move haha. thanks!
After posting this I spent some time searching for subsequent discussion about flipping the behavior but failed. Searching the issue tracker has become quite difficult - pages and pages of issues to wade through. Anybody have links to subsequent discussions of the matter?
That is not how zero-cost should be understood. `Vec` is an abstraction over a manual implementation of a resizable array. It adds no overhead compared to this implementation, so it is zero-cost. If you don't need a resizable array, then there's overhead, but it's the same overhead that would exist in a manual implementation that you don't need.
You want /r/playrust. Actually, you're probably going to get banned from there.
Not a guide per se, but I found that TCP (or at least RFC793) is relatively straightforward to implement. It is pretty detailed, but imho easy to understand.
His experiences are that he's expected to work long days, can't go home until his manager says it's okay for him to leave, if he would say something like "but I have plans for tonight" he can expect to get fired, very strong "the boss is always right"-attitude. He's very happy there and is fine with it, but I would have been unable to handle it.
The implementation was irrelevant. I was discussing that a text editor could make a manual implementation feasible if this was a one-off situation.
Does gccjit allow you to directly emit GIMPLE? The tutorials look like they always have you build a C AST.
I don't know about the second point. In general it's not forbidden for the standard library to implement new traits for existing types, even when that can cause breakage in some circumstances. (By the same token, adding any new method to any type can cause breakage in some circumstances, because it takes priority over trait methods with the same name.) But it might be a question of how much breakage it cause in practice? Not sure. Even if it's not possible to implement `IntoIterator` for breakage reasons, hopefully some helper function of some other name could be defined instead, and so the inconvenience won't be too bad.
Tokio in Tokyo!
‚ô´ No Thread Sleep in Tokio ‚ô´
check out [/u/Jonhoo](https://www.reddit.com/u/Jonhoo) videos: [https://www.youtube.com/watch?v=bzja9fQWzdA](https://www.youtube.com/watch?v=bzja9fQWzdA) [https://www.youtube.com/watch?v=OCpt1I0MWXE](https://www.youtube.com/watch?v=OCpt1I0MWXE) [https://www.youtube.com/watch?v=8GE6ltLRJA4](https://www.youtube.com/watch?v=8GE6ltLRJA4)
Thank you very much! I agree with you, it would be really hard for me to work in that context.
A new helper would be cool, but not as good as an `IntoIterator` implementation, since the array would not fulfill the constraint `IntoIterator&lt;T&gt;`
Looks like gmail actually supports a custom extension of SMTP that lets you combine it with oauth: [https://developers.google.com/gmail/imap/xoauth2-protocol](https://developers.google.com/gmail/imap/xoauth2-protocol)
Thanks
So it would seem. The libraries out there that I have found don't support xoauth however. Perhaps I'm missing something but I don't really understand how oauth works and what happens after authentication. I'm also not against writing my own mailer, but I really wouldn't know where to start.
Ah, gotcha. Makes sense.
Generative art. Lot's of opportunity to play around and experiment. Assuming rust have a readily available canvas to paint on, actually haven't checked that.
For anyone interested, [nannou](https://github.com/nannou-org/nannou) aims to make this kind of thing easy. If you decide to take a look, keep in mind the [v0.9 branch](https://github.com/nannou-org/nannou/pull/240) is about 6 months ahead of master and should stabilise and land in master soon.
I'm not sure I understand what the problem is. I'm not affected by this at all, but can someone give a more detailed exposition for those of us less familiar with the problematic functions?
‚ô´ All night coding a line ‚ô´
I'm not understanding the performance cost. As far as I know, the only time that a performance penalty is paid is when there is a panic, which never happens in normal correctly-operating Rust programs. What am I missing?
It allows casting between unrelated types in safe code.
"on things you actually use" thank you. I read through all of these comments and kept thinking "I don't think anyone here actually understands what zero cost abstraction means" If you have a template (c++), and never use it, that template is never compiled into the binary. When it is used, it works as if you had have coded a whole new function. In contrast, generics in c# compile and exist independently of instantiation. This is critical when using c# as a runtime scripting engine (like in unity) where you may not know all the potential instantiations at initial compile time. The draw back is all generic calculations have to go through the original generic object/function, affecting performance. Both strategies have benefits and problems. But for a systems programming language like Rust, the first is definitely better.
If you implemented `Error::type_id` badly, then calling `Error::downcast_ref` and related functions would act in a similar way to [`std::mem::transmute`](https://doc.rust-lang.org/std/mem/fn.transmute.html), but without the `unsafe` marker. This, in turn, means that without `unsafe`, you can end up doing all the things that you shouldn't be able to do in Safe Rust; see the docs for `transmute` to see quite a few of them.
`Error` types provide a `downcast` function that takes a more generic type and converts it to the type specified by `Error::type_id`. The problem is that you can implement `Error` for your own type and have `type_id` return something different than the actual type. Then, when someone calls `downcast` on your type, it'll get casted to whatever you want, entirely through safe code.
One of the most important aspects of zero-cost abstraction in my mind is that you don't pay for polymorphism. In Haskell, for example, specializing a function's type (without changing to body at all) can sometimes make it faster because the compiler knows that types you're dealing with. In Rust, everything is specialized automatically, so it's as fast as it can be without manual optimization. Specialization also enables a further optimization: higher-order functions can often be used without dynamic dispatch. This means you can use them in far more places without sacrificing performance. For example, using iterator adapters is generally no slower than writing a plain loop.
We should have `yet!`, `yet?` and most of all `yet‚ÄΩ`.
It sounds like what you want isn't a "game server" per se. What you want is a performant WebSockets server. Rust has a bunch of efficient WebSocket frameworks but since you don't need to worry so much about the "web" part (you can let some regular web server deliver your assets for this style of architecture) I recommend this: https://github.com/housleyjk/ws-rs It uses MIO underneath which will use EPOLL behind the scenes when run via a Docker instance. This is pretty much *exactly* the architecture you want for a containerized "game server". Don't worry so much about multi-threading. Let something like Kubernetes worry about keeping enough containers running to handle load and let it distribute them accordingly (containers that gobble up all resources on a server via multithreading are super annoying to Docker admins =). To keep things simple from an architecture standpoint I highly recommend having all your running "game server" containers communicate with each other *through* that database. Unless you need super low latency communications between containers in which case you'll need to setup a P2P architecture of some sort (where containers can talk directly to each other). Instead of a load balancer as someone else suggested just use service discovery... So instead of all your client's requests going through a single load balancer/clustered setup (which complicates global availability of your app considerably) just have each client perform an "election" to figure out which server to connect to (only give clients a random subset--never give them a complete listing of all your servers--unless you only have a few). Typically you provide the clients a list of servers when they load your game (either via a vanilla load balanced web server or immediately after they make a connection to one central, "server of truth" haha).
Well, that wouldn't work since it is part of the test code for OutputBuilder's member functions, its better to keep using closures then. I find it a bit odd that the lifetime can't be properly specified when you can write almost the same thing if the function reference is local: struct MyStruct&lt;'a, T&gt; { field: &amp;'a T, } impl&lt;'a, T: std::fmt::Debug&gt; MyStruct&lt;'a, T&gt; { fn a(self) { println!("field={:?}", self.field); } } fn t(s: &amp;str) { let o = MyStruct{field:&amp;s}; let f = MyStruct::a; f(o); } fn main() { t("Hello"); }
What do you mean by "Compatible with C"? If you mean calling C functions then language is compatible: ```go extern func printf(fmt: *char,...) void; ```
Nope. It assumes that dealer is honest. Its aimed more towards distributing private keys.
As I understand with GCCJIT you emitting GIMPLE, not C. UPD: I just checked the documentation and I don't find any code that emits C AST, library directly emits GIMPLE tree
Here's a playground showing how it can do Bad Things: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0a7cc24ed6a5ba741aae9fdf5917f2dc
Firefox on Ubuntu 19.04... The demo is nothing but a blank web page.
&gt; Unless you use &amp;dyn Trait. Then it's a different trade-off than in C++ -- larger pointers, but faster dispatch. Isnt `&amp;dyn Trait` comparable to C++ virtual inheritance, so the same as C++?
Bold claim! But it looks interesting, and I hope it leads to *something*.
What's the difference? :-) The reason why you can use `Box&lt;T&gt;` instead of `T` is that it implements the `Deref&lt;T&gt;` trait. It's a longer story, but you can implement `Deref` for your own types to get the same behavior.
I suppose it's not entirely unlike virtual inheritance, but the difference is that `&amp;dyn Trait` is a fat pointer -- a pair of a pointer to the value and a pointer to the vtable. It's twice as large, but you avoid a memory access to read the vtable pointer from the object.
In simple terms, that there is no additional cost imposed on your runtime to determine what specific task your abstraction represents at specific instance. Everything is resolved at compile time before the program even runs. Good example of such phenomena would be static vs dynamic dispatch. In short, if you have lets say in interface in other languages which few types conform to, the program has to resolve at run time what at exact moment that interface represents. That's often achieved by runtime reflection, which is, ofc costly to figure out what type of data "hides" under the interface exactly and what kind of method needs to be called. Rust on the other hand, simply (not really all that simply though) compiles to all types of functions required for all of your types which implement that specific "interface" (trait in case of rust) so the program no longer needs to figure out which exact method to call when it calls an virtual (abstracted) method, because, well, there are no virtual methods, all of them are compiled to specific methods which work for specific types.
I am in heavy need for contributors https://github.com/org-rs/org-rs If you are interested hit me on gitter chat
You don't have to specify the struct type: let bar = Foo { a: 10, b: 30 }; or let a = 10; let b = 30; let bar = Foo { a, b };
Isn't it written by the same author?
Zero-cost abstractions, not zero-cost features. Vec adds zero overhead compared to managing the resizing of a array for yourself, so the abstraction is zero-cost.
so how come the move to static typed compiled ?
~~You could first use `split_off`, then `append` the Vec you wish to insert, followed by re-appending the split off Vec. Maybe throw in a `reserve` at the start to avoid possibly double reallocating the initial Vec~~ Edit: I forgot about splice, see the other reply
I for one, think it's pretty awesome that having the *ability* to do unsafe things in safe code is considered a security issue that's taken very seriously. Kudos to the rust team for quickly announcing it and handling it.
If you mean how Jazz changed dynamic typing to static typing: Just added type checker and now I trying to store type of every element with some unique id in "global context" so when compiling the code I don't need to infer the type, I can just type check code and then at compile get type by element id
What is the smart way to make a Rust function called by C code "take over" a struct handed over by a raw pointer? I want to take the data my function got and capsule it into safe Rust as fast as possible. In some functions I need to be able to modify members of the struct, in others I just need it immutable fn foo(bar: *mut my_struct) { I can easily transfer the struct into a Box, but the disadvantage is that the Box is mutable and drops the memory of the struct when going out of scope. At one point I would like to do something like: let new_struct = *bar;
Sorry for answering so late, I didn't see that you asked this: &gt; /u/Valley6660 so what's next? :-) ---- To be honest, I don't know. I'm still working on rsfetch (there are still things that can be made better). After that... maybe I can find a project to contribute to. I'll really need to practice though, I don't think my current skills are good enough for contributing yet.
i mean why, just curious; not asking with any devious intention, just curious why a language evolved that way, i see more dynamic languages trying to add static type systems so i'm just curous why the author of jazz doing the same
&gt; I see only a single value insert in the Vector documents, is there a method for multiple values other than iterating over the insertion? If not, is there an idea on how performance heavy inserting into a vector (With multiple entries, in a large array) is? See https://doc.rust-lang.org/std/vec/struct.Vec.html#method.splice. It's better to avoid it, but it won't hurt once in a while. &gt; Alternatively if anyone knows of a library optimized for that type of operation I'd appreciate knowing about it. Maybe some sort of rope? &gt; Of course if there's a better way of doing what I'm trying to do I'd appreciate it being pointed out, and I'd appreciate any help you guys are able to give. I'm not really familiar with ECSes, but there probably is. Maybe look at `specs`.
Anything other than the `structopt` migration? Or do you want to add more functionality to it?
Have you thought about using rust webassembly target ? &amp;#x200B; The ser/de of u64 are going "not perfect" in js. What is your endianess configuration of bincode? &amp;#x200B; If you care about performance a lot, try to minimize the amount of allocation of js objects you need. Which implies a two passes serialization: 1. Compute size can be O(number of string fields) 2. Then proceed with the encoding into a preallocated TypedArray of right size. What are you required browser list ? &amp;#x200B; I've once written a binary parser ser/de in js, achieving about 100MB/s throughput with careful writing. JS can be quite fast if you write easy to optimize (ie. monomorphic, alloc-free) code. &amp;#x200B; If you are encoding a lot of UTF8 strings, don't use TextEncoder/TextDecoder (at least now) as they are slow (at least 6 months ago they were).
the version with dynamic typing can be said to have been written for learning purposes, that was my first working programming language. Now I develop statically typed version since compiling statically typed language to some IR (LLVM, GCCJIT, etc) is much easier and allows get nice performance for programs written in Jazz.
Depends on what you want out of the word. Most usage of the term zero-cost seems to be about comparing Rust to other languages, or handwritten assembly. If the cost has to be paid no matter the language, it can be omitted in the comparison, which is what people do when they say "Vec is zero cost" - they're just saying "you couldn't hand write it better". Perhaps better terms for the usage you're after would be "free in terms of X", where X could be number of CPU instructions, total memory usage, number of memory allocations, number of cache misses, number of OS syscalls, number of file system accesses, or whatever metric is important for that particular discussion.
Yes I get that, I've even done it. But somehow I kept thinking of Box&lt;T&gt; as a pointer. It's more useful to think of it as a variable on the heap. Also something you can't implement for your own pointers, is move out (let x = \*MyPointer&lt;T&gt;). I'm still trying to understand why Box lets you do that.
Just various little things. * Package counts only work on Arch as it uses pacman, I want to expand it to work with other distros. * Music info calls mpc, when I should be using the mpd crate (or something similar). * I want to add more formatting/customization options. What if people don't want ascii art on the top, but on the side like with neofetch? * I call curl for finding the IP, when I should be using a crate made for web requests. * I feel like I could clean up some of the code a bit. * There were other things I wanted to add, but I forgot to write them down so I have to wait until I can actually remember them.
Fair enough, I guess. You should probably file these as GitHub issues.
Dang. Still though, looks like a great crate!
Good idea. I'll go do that now before I forget.
It sounds like you just want it to be a normal reference? You say "take over", which would be box, but if you want control to be released back into C afterward, then I'd just use a reference. You can make a pointer into a reference with as_ref and as_mut, or I think you might be able to have the parameter just be a Option&lt;&amp;T&gt; and it'll work appropriately (unsafe as always, make sure you're calling it with valid stuff from the C side).
Yeah, the syntax for instantiation of a struct was probably taken from C/C++. In hindsight, using = instead of : would have made a lot of sense, but it is too late now to change it. Edit: see comment below, Sharlinator is right, it's not from C/C++
cool, I'll def be checking Jazz out; I was looking to do something similar for learning purposes, do you have any words of wisdom?
\&gt; do you have any words of wisdom? Firstly create AST and parser and then create backend :D
Why is it even possible to implement `type_id` oneself?
It's a trait method with a default implementation, you can always implement those yourself if you want.
I explain raw pointers, boxes, and smart pointers in a lecture: [http://cs242.stanford.edu/f18/lectures/06-1-smart-pointers.html](http://cs242.stanford.edu/f18/lectures/06-1-smart-pointers.html) If I have a piece of code like this: fn main() { let x: Box&lt;i32&gt; = Box::new(1); println!("{} {}", *x, x); // prints "1 1" } Then `x` is a _variable_ of type `Box&lt;i32&gt;`. Its _value_ is a struct containing a pointer to 4 bytes in memory containing the value `1`. The struct lives on the stack, the int lives on the heap. (Note also the careful usage of "variable" vs "value".) That explains where everything sits in memory. Then to use the box, I can explicitly dereference it like `*x`, or I can rely on the compiler and the `Deref` trait to automatically dereference it in certain situations.
`Box&lt;T&gt;` is magic.
I wasn't going to comment on this, but it's kind of alarming how many people seem to jump at this just because it's Japan. The heyday of Japan being at the forefront of technological innovation passed many years ago. For some context... I used to run a startup in Tokyo, still hold a valid working visa for there, periodically consult with some companies there, and have worked as an engineer both there and in America/EU. You probably don't want to work in Tokyo as an engineer. :) The pay is generally horrible compared to what you'd make elsewhere, engineering in general isn't viewed as the same skillset as it is elsewhere in the world, and the hours aren't worth it. If you have a Japan fetish, or view it as a phase to travel/see something else for a bit, then sure, have fun... but I'd caution anyone against doing it as a career move. It's joked about as a place where your career dies if you're not careful. The startup scene is notably trying to reverse that trend, but they've also been trying to do this since... forever. Doing business there is notably incredibly archaic and enough to drive you insane. Granted, I obviously don't know SE4 personally, but if I were them, I'd really try to note in that job ad how (if at all) they differ from the standard JP working environment. Most of the remarkable engineers I know in Tokyo go well out of their way to ensure they work at a more westernized company. The few who didn't are 100% miserable.
Great work! Thank you for the sharing
Pegcel doesn't help any with runtime manipulation of syn types. It's purely a parser generator item-like macro that helps you generate new grammars for procedural macros, rather than for manipulating the pre-existing Rust grammar. Pegcel itself serves as _a_ example, though not the best one (there were a lot of cut corners to push 0.1 out the door). Given that the point of Pegcel is generating parsers for new combinations of Rust grammar parts, it's kind of hard to come up with a simple example.
Don't know if I can help, but I think you should state which platform you are on. :-)
This is the subreddit for the Rust programming language. You're looking for /r/playrust or /r/playrustservers
Good point.
&gt; Everything is resolved at compile time before the program even runs. Not true, Rust has dynamic dispatch and it works similarly as in other compiled languages (e.g. C++ and so on, utilizing vtables).
Oh yeah sorry misposted :(
Wrong. That's the old futures api, where a future is basically a souped up `Result`. The api that's being stabilized doesn't have that (AFAIK). Though it might work if you use a shim to convert it into an old style future, map it, then convert it back into the new style future. https://doc.rust-lang.org/std/future/trait.Future.html
Sure, but IIRC `Data.Typeable.Typeable` is just a typeclass in Haskell, but you *can't* implement it manually, precisely because it would allow writing unsafe code (you used to be able to, but you can't anymore).
It is!
We also have an `unsafe trait` mechanism, which marks the trait as "unsafe to implement". However, `Error` isn't one of those, and shouldn't really be, since users shouldn't need to worry about memory safety when just building an error type. The fact that manually overriding `type_id` would be unsound was only caught after it was stabilized, or it would have probably been deprecated and removed. We're exploring more favorable solutions for `Error::type_id` in [this issue](https://github.com/rust-lang/rust/issues/60784).
/r/playrust
I will start: fn zerg(players: Vec&lt;String&gt;) -&gt; Game {
This has been brought up before; see https://internals.rust-lang.org/t/pre-rfc-for-struct-construction/7470 as the most recent incarnation of this discussion. Especially see mbrubeck‚Äôs first comment, which links to an RFC from five years ago.
dupe: https://www.reddit.com/r/rust/comments/bo535r/security_advisory_for_the_standard_library_rust/
 unimplemented!() } Man, that was some great zerging. Let's do it again sometime!
Potentially interesting contrast: - `T`: An object on the stack. You can do anything with it, even destroy it. - `&amp;mut T`: A pointer to an object somewhere else. You can do almost anything with it, except destroy it. Because this is a reference, it's bound by its lifetime. - `*mut t`: A pointer to an object somewhere else. You can do anything with it, but only with `unsafe` code, because the compiler isn't helping you with lifetimes or aliasing. - `Box&lt;T&gt;`: A pointer to an object somewhere else. You can do anything with it, even destroy it. Because this owns a heap allocation (the "somewhere else") under the covers, it has no lifetime constraints.
Can you point to cases where auto deref doesn't come into play? I found one - operators: let x = 5; let y = x + 1; let xbox = Box::new(5); let y = xbox + 1; // binary operation `+` cannot be applied to type `std::boxed::Box&lt;{integer}&gt;` let y = xbox.add(1); // OK
This is true of `Any`, but not of `Error`, which is a normal trait.
It‚Äôs not, actually: historically neither C nor C++ have had a syntax for named struct field initialization. C99 added one but it‚Äôs spelled `mystruct { .foo=42, .bar=1.23 }`.
This is off-topic on r/rust. You might have better luck in r/rustjerk.
&gt; are there actually cases where the overhead of tuples is actually optimized out completely? [Tuples can be optimized out](https://rust.godbolt.org/z/VD-NZF). &gt; what all specifically is zero-cost. Zero-cost basically means: if you tried to manually write code that does the same thing as the abstraction, it would use as much memory and CPU time. This is not always the case with Rust, some abstractions are heavy (see: integer Range Iterator and step_by)
Only one line? üòú
Why use float for the offsets into the spritemap? It's an integer number of pixels...
Box is just your normal GC language bare object reference but checked statically. To learners/students who are cognizant of C#/java/python etc, this idea is more than enough, though they need to learn why it's a good idea to use it sometimes and needed sometimes for the type system to prevent typechecking recursion. It's all the other reference types and compositions that makes it hard. Quick, what is RefCell for and can you explain it clearly and cogently the need and how it doesn't violate any of rust guarantees? How to compose it on various situations? Does a RefCell ever need to be boxed? 'Why do i need Rc and Arc if we have Box?'. Etc. Rust doesn't exactly demand you know what you're doing when making complex types because the compiler will stop you making UB, but it sure will create less of a mess if you do.
If you are really fine with sending messages through any other platform, consider using Sendgrid (which got bought by Twilio) or Mailgun. They are essentially email-sending-as-a-service.
Will keep those in mind, thanks. Hope they don't charge though.
What was the point of not using `Any` in the first place? Would it introduce some kind of breaking change? It would have been much cleaner than what we have now.
Yay, you made it, congrats!
&gt;Also something you can't implement for your own pointers, is move out (let x = *MyPointer&lt;T&gt;). I'm still trying to understand why Box lets you do that. Currently, compiler magic. There's been some discussion around a DerefMove trait, but for now only Box&lt;T&gt; allows you to move out of a smart pointer.
Deno's lack of a package manager is a really really bad idea. The whole "just import a URL" thing is clever but what about versioning? What about deduping? What about command line modules?
afaik auto deref only happens on "."
*Technically* you can still do this by manually colliding TypeID's. IIRC it's a u64. But that's a lot harder to do, and solve.
I recently took over maintainership of the [dotenv](https://crates.io/crates/dotenv) crate. I'm currently ramping up on it and then I'll start making some changes to get it stable enough for a 1.0 version.
The term is broadcast channel, but I don't know how you could avoid the copies. You'd need to wait for the items to be processed by every receiver, right? In that case, it seems equivalent to a `Vec&lt;impl Fn(T)&gt;`.
Does the compiler not guarantee that each type has a unique TypeID?
Deref coercion also applies when an &amp;Box&lt;T&gt; is assigned to an &amp;T, as in `let x: &amp;i32 = &amp;Box::new(0);` See here: [https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=371be463659d5ee43ef82e00c72cce33](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=371be463659d5ee43ef82e00c72cce33) To partly answer my own question, deref coercion doesn't come into play here: `let x: i32 = Box::new(0);` \- that is an error.
But why does Box allow for that? What is the use case?
Oh my. Great pickup. I should have used integers.
Ryan Dahl gave a talk last year about what he regrets about Node.js, and wasn‚Äôt sure about Go or Rust for Deno. [https://www.youtube.com/watch?v=M3BM9TB-8yA](https://www.youtube.com/watch?v=M3BM9TB-8yA)
It holds a separate iterator for values that have failed. After normal iteration is finished all mappings that have failed are tried once more and returned even if they fail
To move a value from the heap to the stack. Both pointer types are checked statically so this is possible, sorta. I don't know what happens to self referencial types, and it's probably not pretty. Heap allocation of globals and moving is also something that shouldn't be possible, so it probably isn't.
Indeed. Just look at Go, they realized that and are now finalizing their module support afaik.
Thanks! That's started turning up some results, although most are quite old or copy the data. If one uses a bounded ring queue then one needs to wait for all receivers to be done with a data element before the slot can be made available for writing again. How one would go about it in Rust is beyond me at the moment so I was hoping to eyeball some code or just use an existing library. I'll have a look around some more.
any is also a normal trait, it just has a blanket impl so you can't override it
It allows you to move the value that was in the Box&lt;T&gt; into another location without cloning/copying the value. Most often this needs to happen when you want to partially or fully move out of the item that was contained in the Box. When using dynamic trait objects you'll often find yourself working with things behind boxes, and at certain points you might need to move out of one. See [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2498b53c9dc2a6ff8ae10083aa593fc2) example.
Currently the type ID is just a 64-bit hash of the compiler-internal representation of the type, so collisions can and do happen there (this is tracked in [this issue](https://github.com/rust-lang/rust/issues/10389))
That's [correct](https://github.com/rust-lang/rust/issues/10389). This is still acknowledged as a soundness hole, so we'd like to fix this, however as you said you have to work *really* hard to actually collide TypeIDs like this, so it has pretty low priority. Also the issue is from 2013, when apparently for-loops looked like this: do node.iter_bytes(true) |bytes| { state.input(bytes); true }; amazing :D
Sorry, you're right. I said something stupid (:.
How much effort has been made to support reading from RSS feeds written by people used to writing HTML and not using a proper XML serializer? Currently, my go-to library for parsing both RSS and Atom is Python's [Universal Feed Parser](https://github.com/kurtmckee/feedparser) because, as it used to loudly declare back when it was maintained by its original author, Mark Pilgrim, and he was paying for a whole domain for it, it has a [*very*](https://github.com/kurtmckee/feedparser/tree/develop/tests) comprehensive test suite for proper handling of malformed feeds. (I seem to remember its website claiming over 4000 tests, but the 2200+ files in the [`tests` folder in its repo](https://github.com/kurtmckee/feedparser/tree/develop/tests) is pretty impressive nonetheless.)
Any interest in supporting Atom as well? I hand-wrote the generator for the Rust blog, and would love to just use a library instead.
Tokio from epoll up recording: [https://watch.cloudflarestream.com/3a4f1384005763fc99fa3bfef64c0314](https://watch.cloudflarestream.com/3a4f1384005763fc99fa3bfef64c0314)
[https://watch.cloudflarestream.com/3a4f1384005763fc99fa3bfef64c0314](https://watch.cloudflarestream.com/3a4f1384005763fc99fa3bfef64c0314)
Hi All, I'm still struggling with this. Would anyone be willing to help? I've been able to create the circle and square but I'm not too sure how to implement the ring (I've commented out the ring). How would I go about implementing the the private field colour and public methods getColour and setColour in Shape? &amp;#x200B; use std::f32::consts::PI; &amp;#x200B; \#\[derive(Clone, Copy)\] struct Point { x: f32, y: f32 } &amp;#x200B; &amp;#x200B; enum Shape { Circle(Point, f32), Rectangle(Point, Point), //Ring(Point, f32) } &amp;#x200B; &amp;#x200B; fn area(sh: Shape) -&gt; f32 { match sh { Shape::Circle(\_, size) =&gt; PI \* size \* size, Shape::Rectangle(Point { x, y }, Point { x: x2, y: y2 }) =&gt; (x2 - x) \* (y - y2), //Shape::Ring(\_, size) =&gt; PI \* size \* size } } &amp;#x200B; &amp;#x200B; &amp;#x200B; fn main() { let top\_left = Point { x: 0.0, y: 1.0 }; let bottom\_right = Point { x: 1.0, y: 0.0 }; &amp;#x200B; let my\_circle = Shape::Circle(top\_left, 1.0); let my\_rectangle = Shape::Rectangle(top\_left, bottom\_right); //let my\_ring = Shape::Ring(top\_left, 1.0); let circle\_area: f32 = area(my\_circle); let rectangle\_area: f32 = area(my\_rectangle); //let ring\_area: f32 = area(my\_ring); println!("The area of the Circle is:{}", circle\_area); println!("The area of the Rectangle is:{}", rectangle\_area); //println!("The area of the Ring is:{}", ring\_area); }
That's a good find. If you look at the Rust book, they list out the conditions for [auto deref](https://doc.rust-lang.org/book/ch15-02-deref.html#how-deref-coercion-interacts-with-mutability): * From `&amp;T` to `&amp;U` when `T: Deref&lt;Target=U&gt;` * From `&amp;mut T` to `&amp;mut U` when `T: DerefMut&lt;Target=U&gt;` * From `&amp;mut T` to `&amp;U` when `T: Deref&lt;Target=U&gt;`. So one way to think about that, is any time a function expects `&amp;T` and I give it a `&amp;Box&lt;T&gt;`, it will deref the right way (I think). If you look at the documentation for [Add](https://doc.rust-lang.org/std/ops/trait.Add.html), they have the following impl: ``` impl&lt;'a&gt; Add&lt;&amp;'a i32&gt; for i32 ``` This suggests that the following should work: ``` let x: i32 = 1; let y: Box&lt;i32&gt; = Box::new(2); let z: i32 = x + &amp;y; let w: i32 = x.add(&amp;y); // equivalent to above ``` Because the `add` function expects a `&amp;i32`, it's given a `&amp;Box&lt;i32&gt;`, which should be coerced. However, in that specific case, it seems like there's a weird interaction between deref coercion and trait coercion. Here's a two-year-old bug I found: https://github.com/rust-lang/rust/issues/39801 Go figure!
&gt; We call this a contaminating license, and we quickly understand that this kind of license could scare businesses. And there's your bias showing right there. During their FUD campaign, Microsoft tried very hard to get everyone thinking of GPL-family licenses as "viral". There's a reason people on the FSF's side of the philosophical divide prefer that copyleft licenses be thought of as "hereditary". (ie. Any code your project inherits from someone else also inherits its licensing terms. Simple and reasonable.)
&gt; Also something you can't implement for your own pointers, is move out (let x = *MyPointer&lt;T&gt;). This is incorrect or at least very misstated. You *can* implement move out of smart pointers yourself; it just won't have that exact syntax.
&gt;e a newtype wrapper around &gt; &gt;Decimal &gt; &gt; that does the same thing. See &gt; &gt;https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=30715b31798f2b2217bdc4273e293242 &gt; &gt;. Man you made my day, thank you so much
The thing is that I want to send data (coming originally from C) to another thread, where it will be enqueued and later sent over a socket. If I'd send a reference over a channel, the other thread would not take over ownership but just borrow as well, wouldn't he?
Just nit-picking, but I don't think the term "inlined" really applies. They aren't even evaluated at all at runtime, they're reduced to a single value by the compiler. To me, inlined implies that the body of the function is copied to the call site.
Couldn't you use a supertrait with a blanket impl like this as a fix?: pub trait GetTypeId{ fn type_id(&amp;self) -&gt; TypeId where Self: 'static { TypeId::of::&lt;Self&gt;() } } impl&lt;This&gt; GetTypeId for This where This:?Sized {} pub trait Error:Display+Debug+GetTypeId{ fn description(&amp;self) -&gt; &amp;str { ... } fn cause(&amp;self) -&gt; Option&lt;&amp;dyn Error&gt; { ... } fn source(&amp;self) -&gt; Option&lt;&amp;(dyn Error + 'static)&gt; { ... } } This way people can still access the TypeId in the trait object. Edit:Oh,ubsan mentioned [the same solution](https://github.com/rust-lang/rust/pull/60787#issuecomment-491929505)
Yes exactly. Also how are types converted, e.g. strings. I guess this is documented somewhere - it would just be nice to have an overview in the Readme.
&gt; [Tuples can be optimized out](https://rust.godbolt.org/z/VD-NZF). Nice exactly what I was hoping. &gt; Zero-cost basically means: if you tried to manually write code that does the same thing as the abstraction, it would use as much memory and CPU time. I know what it means, I just wanted to know which abstractions are truly zero-cost.
Surprisingly there are not that much malformed RSS in wildlife. I switched from python's feedparser to a rss crate and found no real issues. Majority of RSS are formed by plug-ins of CMS/Framework/Blogging platform, so they are crafted correctly.
It is already there [https://github.com/rust-syndication/atom](https://github.com/rust-syndication/atom) :)
Why multiple? üòâ
I wish you didn't have to `sonic_spin!` around your items. There's a few similar crates ([extdot](https://crates.io/crates/extdot), [tilde](https://crates.io/crates/tilde)) but the need to `proc_macro!` interferes with convenience.
https://www.reddit.com/r/rust/comments/bn2jd5/implementing_adtsclasses_in_rust_programming/end9l3k?utm_medium=android_app&amp;utm_source=share If anyone would be willing to help, it would be much appreciated.
Ah! A different crate. Cool :)
Any idea how to implement the trait \`std::convert::From&lt;{integer}&gt;\` is not implemented for \`pipeline\_common::DecimalWrapper\` ? Got the same issue with from\_str
It seems the 1.34.1 release test was immediately helpful.
It does sound like you want either box or to pass by value, then. I suppose it depends on what the struct is like and whether you plan to do anything afterward with it in the C code. Do you have some more context for what you're doing? Also, I'm not sure what your problem was with box, it drops when it goes out of scope, but it sounds like you should be passing the box through the thread?
Heh.
[removed]
I worked for 4 different company in Tokyo. This is a good warning . &gt; The pay is generally horrible compared to what you'd make elsewhere, engineering in general isn't viewed as the same skillset as it is elsewhere in the world I believe US is the outlier here. Not Japan. Japan's salary are pretty much aligned with countries like France and Germany. The spread just seems a bit larger.
You can destroy an object pointed at vith `&amp;mut`, but only by overwriting it with another valid value :-)
The mathematical name for the shape of a ring is _torus_. If you search the web for _area torus_, you gonna find a formula immediately. Note that a torus has two radii: An inner and an outer one! &gt; implementing \[‚Ä¶\] colour Instead of adding the field _colour_ to every variant, I'd create ‚Äì and I know that many others would do it as well ‚Äì a struct with the fields _colour_ and _shape_. Possible naming scheme: `Shape` with `InnerShape` or `ColouredShape` with `Shape`. &gt; methods getColour and setColour You make a so-called inherent method impl: impl ColouredShape { pub fn getColour(&amp;self) -&gt; Colour { ‚Ä¶ } } pub fn setColour(&amp;mut self, colour: Colour) { ‚Ä¶ } } You should make `area` a method, too, instead of a free-standing function: /* if you want to impl ColouredShape { pub fn area(&amp;self) -&gt; f32 { self.shape.area() } }*/ impl Shape { pub fn area(&amp;self) -&gt; f32 { match self { ‚Ä¶ } } }
Ok, here's the setup: 3 functions are offered to the C-app: fn init(lots-of-foo) -&gt; service_struct; fn finit(service: service_handler); fn send(service: service_struct, data: *const, len: usize); init returns a struct to C, containing some error flags and especially the send-half of a channel, which is offered to send() by C (it's a library after all, so the central issue is that I have to store all the relevant stuff within the C-program and give it back to Rust when needed). Another thing is the data passed to send() ‚Äì here I get a pointer to data and the amount of data. send() will send this data to a Rust-thread which will deal with the sockets etc. Soooooo here is where the fun begins. I have to move this data into a Rust data structure (I suppose) to deal with it safely and give it to the thread who can put it in a queue etc.
Thank you for the help it is much appreciated.
Well, the lack of existential types in Rust means that for example the Scala type `List[A[_]]`, or if `A` has an associated type `List[A]`, is impossible to express in Rust. [Here's](https://www.reddit.com/r/rust/comments/77fa39/swift_accomplishing_dynamic_dispatch_on_pats/) a discussion about it. Lack of HKT's makes it hard to express concepts like monads, functors etc., but there might be [some workarounds using generic associated types etc.](https://varkor.github.io/blog/2019/03/28/idiomatic-monads-in-rust.html) Note that [Dotty](http://dotty.epfl.ch/docs/reference/overview.html) (Scala 3.0) will have an even more powerful (and more coherent) type system with additions like intersection, union and singleton types, kind polymorphism, dependent function types, type matching (possibly) etc.
How does redox solve this? It seems very unlikely that it will ever become a mainstream general purpose OS. Easy to argue that it's super flawless when nobody uses it.
You can implement them yourself, delegating to the Decimal impl.
I don't quite understand why the Error trait even _has_ an type_id(&amp;self) -&gt; TypeId method. Why can't Error use the Any trait's implementation (where this isn't an issue)?
Sorry for the misunderstanding I was tired. What I meant by having a hard time is that I am having issues with running a simple test case in rust using the tests module/crate. I don't assume everyone is an expert in Meson in fact if there is a way to do it with a command line argument(s) then I will just write a Python program that will run my unit test and can be called from Meson so I may have the same experience as I would have when I run test for C, C++, D and Java. I currently have an example of a [Go program](https://github.com/squidfarts/goexample.git) that uses Meson this should show that I am not just targeting supported languages. It is a prototype so it may be replaced with the release version after I am done testing it. I have no problem using other tools like 'gradle' for Android app development but in the case for Rust I would like to select my tool of choice. Also sorry about your bad experiences with Python. &amp;#x200B; The best for you, in the future.
I didn't say it's flawless or perfect. All I am saying that Rust's main advantage is memory safety. Linux Kernel is no joke. It's probably around 25 million lines of code by now. Many programmers claim that Rust is not needed if you're a good programmer in C++. But safety in the design \*IS\* needed because the human's are error prone. That said, those who work in the Linux kernel are at least, 10 times smarter than me, and many others. They probably know best architecture designs. But, they're still human. According to the link posted, AFAIK the memory was not cleaned properly for some process which opened an exploit. Such memory issues should be detected before compilation with Rust, and therefore are not possible.
Thanks for sharing! I wasn't aware of RON before, it looks like it could be useful for many things. And thanks for the many excellent links throughout!
Idk, I'm not sure why you wouldn't let the macro decide, a match binding and you have a 100% correct, only-once evaluated $expr. This only impacts macro writers, users have no concerns and I imagine as a macro writer you're already aware of this behaviour and have the ability to write it the way you designed it. I'm more interested if a macro would care if it captures the *self* value by ref or by value. Does it even matter? I'm not sure. There is actually an RFC for method macros (I can't find it right now). IIRC it got postponed because there was a desire to flesh out macro system that integrates with types (as I mentioned at the end of my post) instead of hacking it in the current macro_rules syntax.
I tried that too! Nice find on the bug.
"Memory issues" are possible in Rust, with unsafe. Don't act like it's a panacea for vulnerabilities.
Good that you mentioned that, because there is no reason to use unsafe unless you want to program a virus.
[rust-lang/rust](https://github.com/rust-lang/rust) repository has been mentioned **26 times** on Reddit over the last 7 days. The last 3 mentions: |Mention|Source| |---|---| |Working on using the improved C-variadics (PR [ https://github.com/rust-lang/rust/pull/59625 ]) to translate C code using `va_copy` with C2Rust [ https://github.com/immunant/c2rust ]. This means we&amp;#39;ll be able to handle many important C projects without any &amp;quot;massaging&amp;quot;. Very exciting to get closer to feature-complete translation üí™|[/r/rust](https://reddit.com/r/rust/comments/bl7jwe/whats_everyone_working_on_this_week_192019/emopxxi/ "/u/thedataking at 2019-05-06 22:34") | |[..] letter variations. If someone really wanted to keep the await name, they could make an ùñÜùñúùñÜùñéùñô!() macro. Well, as the compiler pointed out when I went to test, maybe someday once #55467 [ https://github.com/rust-lang/rust/issues/55467 ] is resolved.|[/r/rust](https://reddit.com/r/rust/comments/bld06g/a_final_proposal_for_await_syntax/emq49um/ "/u/Uristqwerty at 2019-05-07 09:52") | |https://github.com/rust-lang/rust/issues/54727|[/r/rust](https://reddit.com/r/rust/comments/blow5v/ifmt_v01_why_write_printlnx_x_y_y_x_y_sum_xx_yy/emq84o6/ "/u/nicoburns at 2019-05-07 10:59") | ^([Report an issue](https://np.reddit.com/message/compose/?to=gajus0&amp;subject=GitSpo%20Reddit%20mentions%20bot&amp;message=Hello%20Gajus,)|View all [mentions of rust-lang/rust](https://gitspo.com/mentions/rust-lang/rust))
Something [about 'static bounds](https://github.com/rust-lang/rust/issues/60784#issuecomment-491883232), apparently. It does seem way cleaner in theory.
Thank you, I never thought of that term :) I will add it to the article and try to use this one from now one
Does that makes Redox a virus? Or do you know better than the maintainers?
Yeah, it's pretty awesome that it only took four days after someone reported it for it to be un-stabilized. Very impressed with the rust team treating this issue so seriously.
If you are maintaing Redox and you are using unsafe, thanks for the heads up.
I am primarily a JS developer, know my way around React, Webpack, etc. I also already learned Rust and know enough to be productive. Currently I am interested in WebAssembly. I have a few questions: 1. What is the easiest, least boilerplate setup to start with WebAssembly? 2. I see wasm-bindgen and wasm-pack, are these two stable? 3. Why do I have to use deferred async import when using Webpack? Most of the examples out there show that WASM module can be imported synchronously? 4. What is the proper way to structure WASM with JS files? If JS can call WASM and WASM can call JS I can see it will get messy and have some kind of recursive crazyness going on 5. How do I import a JS function to Rust using wasm-bindgen? I tried this code below but it failed &amp;#x200B; // my_project/src/lib.rs use wasm_bindgen::prelude::*; #[wasm_bindgen] extern "C" { #[wasm_bindgen(module = "../helper", js_name = dumb)] fn js_dumb(); } #[wasm_bindgen] pub fn call_dumb() { js_dumb(); } &amp;#x200B; // my_project/helper.js export function dumb(str) { console.log('You are dumb') } &amp;#x200B; The generated JS file from wasm-bindgen contain no `import { dumb } from './helper'`
No worries. Wanna know another project that uses unsafe a lot? The rust compiler and standard library itself.
Isn't Rust using LLVM?
Ok, now I'm just confused.
If you understand what it means, then it seems more useful to ask what isn't zero-cost, right? Rust is zero-cost by default. Something not being zero-cost is almost treated like a bug.
I am not aware of a lot of details about how Rust works internally but what I am saying that LLVM is used for Rust as well as Swift and other languages as a compiler. The compiler's job is to translate your code. If your code is bugged... so will the translation. But that's why Rust should have an advantage as it tries to prevent unsafe code to be compiled.
I guess the many developers contributing to the standard library were just creating a virus... I'm glad you like Rust, and it does offer a lot of certainty and assistance when using it the "preferred" way. But perhaps leave the evangelism to the people who have a little more experience. In this particular context that would include not just experience with Rust but also operating system development.
You are right. Being excited about a technology and expressing it on Reddit is dangerous and turns out to be very expensive. But coming to evangelism the term "Rastaceans" is used hundreds of times in the official documentation making it seem like a cult. So excuse me if I got a bit over excited on the official reddit page :)
Sounds like an opportunity I would love to take in 2 years once I finish my mechatronics degree :,(
What do you know about the files? Are they all images? Videos? Office documents?
[removed]
This feels a little too much like zealotry to me. There are very strong reasons why people use C based kernels like Linux today, and that is likely to remain true for at least the foreseeable future. Redox is probably billions of dollars of investment away from feature parity with Linux!
I think you misunderstood the title. Highlighting a main disadvantage in an ancient programming language through a real world incident is not an attack on the Linux Kernel or its' developers.
Unsafe code is JUST the ability to dereference raw pointers, access external functions (from C) or to write assembly to call into the kernel. Our computers REQUIRE unsafe code in the kernel, though there are methods to reduce the risks. The core library uses unsafe to implement internal mutability (Cell&lt;T&gt;) and to implement efficient collections (Vec&lt;T&gt;). &amp;#x200B; A 100% safe Rust program can't do any IO or allocations. But it can be imported as a crate/library into something that can do IO and allocations.
Even the formally verified seL4 microkernel is written in C (though first written in Haskell).
Sounds `unsafe`
Turns out they were a cult and just blocked me I'm not worth the brainwashing
See also: [https://github.com/rust-lang/cargo/issues/2179#issuecomment-429337378](https://github.com/rust-lang/cargo/issues/2179#issuecomment-429337378)
huh, couldn't find this when I needed
Is this trolling, like for real ? What the purpose of carggo when cargo already fit the use case ? I don't see your point...
Okay, so I din't know about the existence of cargo-edit until like 5 minutes ago, second of all what's the purpose of Yarn when there's npm? the answer is simple: Just because.
Would an `Arc&lt;T&gt;` sent via a [bus](https://crates.io/crates/bus) channel achieve what you want? It seems to me that avoiding `Arc` would be difficult anyway since the original object needs to stay alive as long as at least one of the recipient holds a reference...
So, what you wanted to do is `cargo add/remove` I did not get this after reading your post first.
Yeah, kind of, I was trying to make something like yarn/npm, so I'll still be finishing this thing, but yes, all I wanted was to have a simple cli to add dependencies for me.
&gt; Just because. You're right here, it's just that I didn't understand what you made by reading your post. So, I thought you rewrote a cargo-like app...
my bad, should've made it more clear
Well it has both but in polymorphic cases dispatch is always dynamic
I know you didn't mean to attack anyone. I guess my point is that we already know that Rust code can't have this specific kind of bug, so pointing it out every time someone runs into it isn't constructive. Comparing Linux and Redox also felt unfair to me, seeing as they operate on such different scales. The entire subsystem containing this particular bug hasn't even been implemented in Redox.
Seems like the type_id stuff could be part of a separate trait that‚Äôs unsafe with a default implementation. Not sure about backwards compatible ways to do that now though.
It's related to how Any requires 'static but Error does not, very unfortunate...
Maybe true, but there are also many other developers who think that world is not in short of another operating system let alone a new programming language. No matter what I (nobody) say here wouldn't matter since most people wouldn't give up what they already know for something they don't know. Just like anything, they're afraid of trying something new. One strange example for this is when you visit Quora and write Rust. You will find that the very early questions asked about Rust by early adopters were shut down by experienced programmers. One of them even claimed "Rust is going to die like D". But here is the interesting thing, The same question asked over the years had an improved and favorable response from the community of Quora developers. This means that the perceptions are changing which is a good thing. One has to know when and why he/she is sticking to the old ways.. is it because the old ways are better, or because they are emotionally attached to the old ways and afraid of the new ways (comfort zone).
I'm working on getting an initial command line version of our workflow daemon ([`ghostflow-director`](https://gitlab.kitware.com/utils/ghostflow-director/)) up to par. It can run checks and do reformatting now. Focusing on documenting that and then I'd like to finish up the `merge` action and then write tests for the CLI part of it.
As @fulmicoton said, the salaries in JP are aligned with those paid in the EU and throughout Asia. The salaries in the states are (only in proportion to the housing markets/terrible health insurance/student loans etc conditions) crazy. &amp;#x200B; So SE4 is run by myself (an Australian), a Russian-Japanese guy and another Aussie. Our working conditions are (proudly) nothing like a JP company -- there's no 9-9-6 at SE4. We don't allow overtime, core hours are 11-4 (so you can work early if that's your thing, or later in the day --whichever you prefer). &amp;#x200B; It's a pretty social office, staff are always getting coffee/lunch/dinner etc together. &amp;#x200B; Lastly, it is most definitely TRUE that JP used to be a technological innovation hub and it's not that anymore. If you come to JP expecting to see the future you'll probably (like I was) be disappointed. Having said that, the robotics scene is alive and well here!
# Tracking lifetime of objects with C FFI I'm writing Rust bindings to [LVGL](https://littlevgl.com/), an embedded GUI library. It allows for creating objects and assigning them a parent. This is all good so far‚Äîhowever, when deleting them, it deletes the object *and all of its children*. So, how do I: 1. Track the lifetime of the children so that parents are not freed before children (I would assume just store the children as a `Vec` within) 2. `Drop` children before parents After some more thought, I considered that the caller needs to be able to keep a reference to a child, so that it can e.g. update label text. How can I do that? --- Edit: now, I've implemented it as each object has a `PhantomData`, and creating a new object requires that its parent lasts as long as the `PhantomData`. The screen has `'static` lifetime.
It's hard to work on/with the robots if you don't have them at home...
&gt;C++ implementations obey the zero-overhead principle: What you don't use, you don't pay for \[Stroustrup, 1994\]. And further: What you do use, you couldn't hand code any better. &gt; &gt;\-- Stroustrup This isn't always true. If I have a function that accepts an `std::tuple` with 3 args, immediately destructure the tuple to references, and only use the references instead of using `std::get`, there is more overhead than just accepting 3 separate arguments.
&gt; Written in Rust &gt; 75% C Hmm...
There are a few rust shops around, notably Tonari ( [https://tonari.no/](https://tonari.no/) ) who hosted an awesome Rust meetup a few months back.
Thank you :)
Feel free to shoot over your CV etc -- Maybe we have other positions coming that you'd feel more comfortable in?
I am actually going to get a wooden block, attach it to a steel chain &amp; hang it in the office, then....
I have a history of tripping over malformed RSS enough that I'm planing to write my own tooling which converts parse errors and other problems (eg. suspicious lulls in updates) into explicit feed entries so I don't miss anything important. It's probably that we visit different kinds of sites. (I tend to follow a lot of stuff that involves home-grown RSS code, like sites that developed their own CMSes before the current ecosystems grew up and then retrofitted RSS onto them.) I suppose, if it matters that much, I could write some kind of fallback that launches a Python process for problem feeds and then merges the results back in.
Personally, I think using `:` for struct initialization was one of the worst design mistakes ever made in Rust. This also poses problems for type ascription, which I would like to see on stable one day. But, there's little to do about `:` at this point.
&gt;I don't know what happens to self referencial types Rust assumes all types to be trivially movable, and therefore self-referential types are not safely representable. (it would require declaring a reference to itself with a lifetime that outlives itself which is somewhat paradoxal). This is one of the reasons why async functions faced big issues, as a borrow over a yield point of a local variable is self-referential. The Pin API intends to mitigate this (by forcing the inner contents to be immovable it can allow for safe self-referentiality.
I can't help but find it ironic how people kept saying syntax highlighting fixed the ambiguity of the new await syntax, yet the official Rust website itself doesn't even use syntax highlighting for code.
I found making a TIS 100 emulator in Rust to be a fun hobby project.
You aren't going to find a lot of Rust skeptics here on r/rust. And even if there were, simply telling them about every minor (yes, a difficult to exploit bug in an obscure part of Linux is minor) security bug in C would do nothing to convince them. Not because they're stupid or afraid, but because they already know about the trade offs and have done an honest cost benefit analysis. Also, the "Rust evangelism strike force" isn't why people on Quora are more positive about Rust now, it is because the language has gained features and adoption. There have been dozens of new languages with cool new features and a bunch of enthusiastic fans that ultimately failed/stagnated. Predicting that the same would happen to Rust was a reasonably safe bet even if it seems overly cynical in hindsight
This is probably the most useful post ive read on the internet when it comes to explaining this to a plebian.
See also: rule 6
Right, I mean that it's not one you can implement manually (in the context of the above comment)
So basically, Pin&lt;T&gt; is disallowed to be moved from a Box or maybe from being in a Box? It's well and good to say 'the internal representation is not allowed to move but if it's trully self-referencial and not some different instance of the same type (like most trees), then there is some inner reference that calls back up into the graph, so just that wouldn't prevent bad things when the bytes were copied from the heap to the stack and freed from the heap.
The main Rust compiler `rustc` transforms Rust code through a series of steps. First, your code is lexed (convert the file to a sequence of tokens that are valid in the language, comments and strings are handled here). Then, your code is parsed into an AST (Abstract Syntax Tree). This is then further lowered and desugared into another AST, which is simpler (HIR, High-level Intermediate Representation). The main type checking is done on HIR. In turn, the HIR is then lowered into HAIR where pattern matching is checked. Finally, HAIR is then lowered into MIR (Mid-level IR) which is a rather simple language in a SSA (Single Static Assignment) form. Borrow checking and optimizations is done on MIR. Finally, using the MIR, monomorphization (e.g. substituting concrete types for generic parameters in generic functions) and code generation is done and LLVM IR is produced. LLVM then converts this IR to assembly code and uses several steps inside it as well. An assembler is finally responsible for converting that to actual machine code. That code is finally linked together with a linker.
&gt; Mac/Windows users, sorry macOS ships with Ruby installed. Homebrew, ‚Äúthe missing package manager for macOS‚Äù makes use of the Ruby binary that ships with macOS for the install process. https://brew.sh/
Ah, I suppose that sounds like you want to make a slice like with `slice::from_raw_parts`.
It would be hard for anyone to work in that context!
&gt; A video of us flying drones in the office... This brought back some ear splitting memories
I know, it's the difference between bash and zsh that I still need to confront
[removed]
Reading stuff like this makes me feel completely inadequete with programming. I broke it down and tried to understand what was going on here and why it was needed but i suppose context is important.
Thanks for clarifying re: your office/environment/etc. Clears up a lot for any prospective applicants. :) Re: the salary, I'll actually still disagree with both of you. I feel comfortable doing so because I had to hire in Japan, so I'm pretty familiar with the data. Furthermore, it's easy to put the rates for American salaries as the outlier, but they exploded because of a war for talent after Facebook &amp; co opted to ignore a wage suppression agreement by the bigger entities. There is no reason Asia/EU should be getting paid less given the same workload, and there's a reason the higher end talent tends to head to the Valley. America simply has a better talent pool; Asia tends to underpay for it, with some exceptions - e.g, it's not unheard of for foreigners in China to find salaries close to their SV counterparts, because the industry there is willing to pay. Same goes for Singapore. Japan, however, isn't. There are nice aspects of living in Japan, sure, but it's not a binary thing... e.g, if you're American and you want to do some investing while residing in Japan, you'll find that the double taxation + IRS business makes it a pain in the ass and nowhere near as beneficial. At this point I'll dip out of the discussion, though - I'm not sure /r/rust is the best place to discuss this in depth.
I don't have much experience, but I'm wonderinq quite the same thing for a project of mine. Personally I guess I would use a mix between 1 and 2. E.g. for difference between game loop and pause I think it might make sense to have the state as a resource and check it in the AI system. On the other hand for something like the main menu it might make more sense to use a different world. For "Generate Map" state I guess I would personally make some systems (or even just functions) that are called manually once (and not part of dispatchers) before setting up dispatchers. I'm not use what you mean by your third solution ? Also I'm really new at this whole ECS/Specs things so I might be totally wrong, I hope there are some answers from people with more experience :)
ggez uses float offsets because thats generally what the graphics card ends up seeing anyway. With floats from 0-1 there's fewer questions to be had about what happens when, say, you scale a sprite.
He also has other videos where he implements an async ZooKeeper protocol client.
Still don't understand the purpose of Box. Why would I want to store an int on the heap?
When making games I've always made a gamestate abstraction to allow switching between different game states. It just that would probably be a struct that implents a update, enter, and exit methods Then I usually use a stack for game states, so they can be pushed and poped. So push the pause state, pop goes back to the previous state. And a swap state function cap be nice too. I personally think it is good to keep something like this completely separate from your ECS. Some engines call these "scenes"
`self` in **case 1** refers to `io` itself. Consider this code example: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4cf9ee6544cb7f1ce9442fdd220b8f2b use std::io::{self, Read}; fn main() -&gt; io::Result&lt;()&gt; { let mut buffer = String::new(); let stdin = io::stdin(); let mut handle = stdin.lock(); handle.read_to_string(&amp;mut buffer)?; Ok(()) } It allows me to refer to `io` without fully qualifying `std::io`. Otherwise, I would have to write this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4510e0ee368feb755f94cd9c03c0c036 use std::io::Read; fn main() -&gt; std::io::Result&lt;()&gt; { let mut buffer = String::new(); let stdin = std::io::stdin(); let mut handle = stdin.lock(); handle.read_to_string(&amp;mut buffer)?; Ok(()) } `self::` in **case 2** refers to the current module's scope. As opposed to `super::` which is the parent module's scope, or `crate::` which is the crate root's module scope. The only reason it is included in this example is to be more explicit: `use self::HelloWorld::*` is equivalent to writing `use HelloWorld::*`. The purpose of the entire statement is so that you can use the `enum` variants without fully qualifying them: That is, you can simply use Connecting(ConnectFuture) Connected(TcpStream, Cursor&lt;Bytes&gt;) instead of having to write HelloWrold::Connecting(ConnectFuture) HelloWrold::Connected(TcpStream, Cursor&lt;Bytes&gt;)
1. The current "path end" up to that point in the `use` statement. So that is equivalent to using `std::io` and `std::io::Cursor` separately. 2. The current module.
Here's an explanation: [https://users.rust-lang.org/t/when-should-i-use-box-t/4411](https://users.rust-lang.org/t/when-should-i-use-box-t/4411)
What prevents you from using one World and multiple Dispatchers?
This would be just general information for any integration project. 1. Go to [Crates.io](crates.io) and search for what you want. In this case *Discord*. Browse through the results and select what you think would be best for your project. 2. Grab and briefly look through the official API/specification for the platform your developing your project for. It'll come in handy when you don't understand something in the library you chose. 3. Start coding what you want to do.
Maybe not an integer, but a `Box&lt;dyn T&gt;` can be pretty useful.
Wait, they actually happen? Shouldn't it be a pretty big deal? Hash collisions of that size are the sort of thing that would ruin a lot of software that assumes it's impossible (git being the most prominent example)
We use `tensorflow-rust` for face detection and recognition in our [product](https://www.schoolbench.com.au/). I've written a blog about [getting started](https://cetra3.github.io/blog/face-detection-with-tensorflow-rust/) with tensorflow-rust. I would love to have a rust only ML framework, but there is so much momentum already behind tensorflow and torch that unless there is a corporate sponsor driving it, it's a moonshot. I remember the leaf framework [gave up](https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb) after tf was released (although now rebranded as [juice](https://github.com/spearow/juice) and mostly active).
I have no idea what you meant.
You can just use '?' as a postfix operator on Result. As for Option I usually use the ok_or method to convert it into a Result then use '?'. This combined with the failure crate to allow for returning a generic Error type.
What's the syntax for the return type? I think that if this propagates result, then it'll only work for certain functions and not all of them, right?
The function must return a Result with the same error type as the result you are using the '?' operator on.
Block Chain
Your article makes a good point and I didn't think your drawing was ugly, but I did notice a typo: &gt; poperty drawers
The most common plan is to turn the failed `Option`s into `Error`s with `Option::ok_or()` or `Option::ok_or_else()`. For example: let value = vec.pop().ok_or(MyError::EmptyVecError)?; Note that all the error returns of a function must match the trait or type of its `Result`. Rust now allows using `?` in the `main()` function by declaring `main()` to return a `Result`, but the program will panic if `main()` returns `Err()`, so it's less useful than it sounds most of the time.
And what about the `Ok` type?
Ok is not a type, it's a varient of the Result enum. I'm not sure exactly what you're ask.
You know I kind of wonder, if you `std::mem::swap` two objects, what does that mean in terms of the memory model? Did they both get moved, or did they both get mutated, or what? Is there even a difference?
Ah got it.
Thanks üôèüëç
Now for you next step. Life time sigils describe the caller/callee relationship. More lifetime parameters, the more the call stack is dictated to you.
on nightly, if you have a function that returns a `Result&lt;_, E&gt; where E: From&lt;std::option::NoneError&gt;`, then you can use the `?` operator on `Option`s. for example: #![feature(try_trait)] use std::option::NoneError; enum MyError { NoneError(NoneError), } impl From&lt;NoneError&gt; for MyError { fn from(none: NoneError) -&gt; MyError { MyError::NoneError(none) } } fn try_first(x: &amp;[usize]) -&gt; Result&lt;usize, MyError&gt; { let &amp;first = x.first()?; Ok(first) }
If compiling to GIMPLE I convert Jazz types into GIMPLE types, struct types converted into GIMPLE structs too: ```rust Type::Basic(basic) =&gt; { let name: &amp;str = &amp;str(basic.name); match name { "u8" =&gt; ctx.new_type::&lt;u8&gt;(), // unsigned byte "i8" =&gt; ctx.new_type::&lt;i8&gt;(), // byte "char" =&gt; ctx.new_type::&lt;char&gt;(), // char "i16" =&gt; ctx.new_type::&lt;i16&gt;(), // short "u16" =&gt; ctx.new_type::&lt;u16&gt;(), // unsigned short "i32" =&gt; ctx.new_type::&lt;i32&gt;(), // int "u32" =&gt; ctx.new_type::&lt;u32&gt;(), // unsigned int "i64" =&gt; ctx.new_type::&lt;i64&gt;(), // long "u64" =&gt; ctx.new_type::&lt;u64&gt;(), // unsigned long "f32" =&gt; ctx.new_type::&lt;f32&gt;(), // float:32 "f64" =&gt; ctx.new_type::&lt;f64&gt;(), // float:64 "bool" =&gt; ctx.new_type::&lt;bool&gt;(), // bool "usize" =&gt; ctx.new_type::&lt;usize&gt;(), // size_t _ =&gt; unreachable!() } } ``` When translating into C++ basic types just converted to C++ types e.g: `i32` becomes `int32_t`
Sorry, I mean the underlying type of `Ok` (i.e. `T` on `Result&lt;T,E&gt;`)
This is true. But it's not hard to find out that it's a keyword (even without reading the docs): if you try to use it as a field name, method name, variable name, etc. you'll get a very loud compiler error. In fact using it *anywhere* outside an `async` fn will trigger a compiler error.
# No.
Oh I see you updated post with video from drone flying around new office, this is just double cool: having enough space to fly it :)
Next-compile discoverability while writing code does not help with readability, though.
I don't think any kernel is feasible without unsafe
x? Is equivalent to: match x { Ok(v) =&gt; v, Err(e) =&gt; { return Err(e); } } On mobile, sorry if formatting is off. Does that answer your question? I'm still not sure what you're asking. If x is Ok(v) then x? gives you v.
The OP link is a discussion thread on a Demoscene site with some people weighing in about their experiences and thoughts on using Rust. There is no grand theme of the thread as a whole beyond being about using Rust for making demos in general but a few of the comments are interesting to read :) Context for anyone unfamiliar with what the Demoscene is: https://en.wikipedia.org/wiki/Demoscene
You should get used to reading Rust docs. https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or &gt; Transforms the `Option&lt;T&gt;` into a `Result&lt;T, E&gt;`, mapping `Some(v)` to `Ok(v)` and `None` to `Err(err)`.
Thanks. It is fixed now.
Git hash is 160 bit. Which is waaaaaaaaay larger than 64 bit type id.
Does Rust support or plan to support Swift like shorthand values? If a function takes an enum. The compiler can know what type of value is required for that argument. If an enum is required, you shouldn't need to provide a fullpath to the enum. `player.moveBy(Direction.East)` // Swift notation `player.moveBy(Direction::East)` // Rust notation `player.moveBy(game::movement::Direction::East)` // Rust notation (if we do not import into scope) `player.moveBy(.East)` // Swift short notation `player.moveBy(::East)` // Rust short notation (what I want) Supporting implicit values like Swift would make writing Rust a lot easier. You do not have to "use" enums to use them. The code becomes cleaner.
Is there a way to mandate that cargo downloads the source of all crates for future enterprise inspection for a project? &amp;#x200B; For example: lets say I download the rand v0.3.14 crate and then use that in my project. When my code gets audited I will need to show the source code of that library and prove that code was used in my finale project. Is this possible or is it pray and trust? &amp;#x200B; Thanks
You could start at the top of the list. Try using piping through ‚Äòless.‚Äô
&gt; I currently have an example of a Go program that uses Meson this should show that I am not just targeting supported languages. It is a prototype so it may be replaced with the release version after I am done testing it. You're literally doing `go build` and moving the output to another directory. You can get the same level of integration for Rust by running `cargo build` or, related to this thread, `cargo test`.
Seems to me that all you need is ability to run regex ops over non-contiguous strings. /u/burntsushi - is such a thing doable? Could https://docs.rs/regex/1.1.6/regex/struct.Regex.html take some `&amp;T where T:StringLike` with default `impl StringLike for str`, but potentially extendable to other types as well? I imagine such use-case is going to be more common, so I think it might be worth bringing to your attention.
Wrapping up some mostly-finished issues with [Rusoto](https://github.com/rusoto/rusoto), the AWS SDK for Rust! One of the bigger issues is getting all 150 or so crates onto Rust 2018 edition. That's close to landing and being available in our next release! Another task is getting clippy happy with our hand written code. I'm hoping this helps with our [initiative to make the project smaller and faster to compile](https://github.com/rusoto/rusoto/issues/1323).
It uses `unsafe`, naturally. It is safe because no panic can happen in between. You can see the implementation details [here](https://doc.rust-lang.org/src/core/ptr.rs.html#354-364).
Thanks for the link. I've always admired the demoscene from afar and it's interesting to see their discussions on rust.
Check out [cargo vendor](https://github.com/alexcrichton/cargo-vendor).
So you want to promote a language in a subredit of a different language? :) Anyway, Mozilla hasn't done a lot of things but the few things they did changed the world every time. So, if I knew about Rust when it started I would probably not use it because it isn't mature yet, but I wouldn't doubt the company that changed the world wide web.
Seconding this. Seems like you should have a dispatcher + world per "scene" (option #1 in the list above) and do something analogous to modal windows. Whatever system is launching a new scene already has all the necessary barriers for the inputs/outputs, and the `dispatch` call for the sub-system is blocking, so I don't see any data flow issues. Edit: For the pause/unpause/etc within a single world/scene case, I don't see anything in the docs that suggests you can't have separate dispatchers for a single world/scene.
That post was the /r/linux X-post. [you meant the /r/rust side](https://www.reddit.com/r/rust/comments/bo9j7f/linux_kernel_memory_leak_vulnerability_now_you/).
A safe programming language does not mean you don't have vulnerabilities. Simple example, imagine you are writing a web application but you've made a mistake in the authentication part (pure logic, no language problem), you have a vulnerability that could have happened from any programming language. Regarding RedoxOS, I haven't seen anything AFAIK.
Nothing maybe? I'm not sure honestly
RedoxOS had vulnerabilities. If I remember correctly, there was at least a privilege escalation. Memory safety is great to prevent a lot of security issues, but there are still other kind of mistake that can cause vulnerabilities.
One probably can use dynamic dispatch. However, the idiomatic way is to use generics or where keyword so it always compiles number of different functions for specific type boundaries rather than one for entire trait. So while it's possible to do this: ``` fn foo(a: Trait) { } ``` You will always do this, use rust function "templating". ``` fn foo&lt;T: trait&gt; (a: T) { } ``` The second will compile into all the possible functions which trait boundary represents so if Trait is implemented for type bar and baz, your abstraction will compile Into two functions which can be inlined by compiler: ``` foo_bar(a: Bar) { } foo_baz(a: Baz) { } ``` which results in static dispatch.
The way systems work, is that they're dispatched on their SystemData, which is a tuple of components. The third solution would basically boil down to having all the different available states be components and the leverage the SystemData for automatic context switching. The issue with doing this, is that nothing would prevent me from creating both a main menu and game loop state, and have both of those be active at the same time, which is an illegal state.
Someone mentioned using one world and multiple dispatchers. Which honestly might solve the issue entirely. The world would hold all the resources common across all the game states, and each dispatcher would then only have a set number of associated systems. It's funny how some things become obvious after having slept!
I have a barcode scanner and I want to write some code that uses the scanned code from stdin. I tried std::Io::stdin with read_line() but sometimes the scanner gives a /n before the whole barcode get scanned in for some reason and the last 2 numbers get left out or added onto the next scan. Now I have this Loop { io::stndin() .Lock() .read_until(b' ', &amp;mut scannedin) .Unwrap(); } So I get everything scanned in fine but the I have to hit space and return to loop again. How could I just hit return and take the input? Should I go about it in a better way? I am thinking to push the codes to a vector and then insert into a spreadsheet eventually, but I need to get this input issue down first. Thanks for any help.
&gt; ArrayVec does implement IntoIterator (by moving it into the iterator). Oh! Thanks for pointing it out. I didn't notice this. Not a choice I would have made as author of arrayvec. &gt; Why is it impossible to implement IntoIterator for arrays? It's impossible to implement it for all array sizes because the language does not yet support const generics. It *is* possible to implement it for a fixed number of sizes (like ArrayVec). But what my initial response was getting at was: There is no obvious way for an IntoIterator implementation that wouldn't surprize anybody because a "lesser of two evils" kind of choice has to be made about where to move the elements because there is no way of getting around having to physically move all the elements from one memory location to another in a linear amount of time with either a heap allocation or a potentially large Iterator that could cause a stack overflow.
Monomorphization is a different concept than dynamic dispatch, and both are idiomatic - there are cases when you cannot avoid dynamic dispach (e.g. behavior configurable at runtime).
In compiler development this problem is called "Cascading Errors". It's difficult to find the right balance between only showing the "true" issues with a piece of source text and giving the programmer enough information for them to fix things. You also don't want to give just a single error for each compilation otherwise the programmer ends in a loop of "fix one thing =&gt; try compiling =&gt; find another error".
Not only should it be possible, but a regex engine optimizer for ropes might be able to cache results over sub-ropes and only re-evaluate if the sub-ropes changed.
Long time ago `Box&lt;T&gt;` used to be written as `~T`, `Deref` trait didn't exist back then and `*` was special-cased for `~T` (along with other types like `&amp;T` and `@T`). The magic allowing moving with `*` unary operator stayed when it was changed into `Box&lt;T&gt;` and then people forgot about this special case and it got stabilized for Rust 1.0. `Box` is special in other ways as well, due to its history as another kind of pointer, on nightly it's possible to use `box` pattern matching and construction syntax, which is a leftover from old `~` syntax. Additionally, until recently `self` was special-cased to allow `Box` as a receiver, such as `self: Box&lt;Self&gt;`, but now you can use most built-in smart pointer types such as `self: Rc&lt;Self&gt;` (it's currently not possible to declare custom receiver types on stable).
Great idea! Will use this on my projects.
Glad to hear that. I‚Äôm going to add custom template support later tomorrow, along with some other niceties so stay tuned!
The method in both traits just call `TypeId::of&lt;T&gt;()`, so duplication the one-line implementation is not a maintenance burden. They are in each trait so that they end up in vtables.
Change the macro engine to the experimental
Nice, thought I wouldn't have put languages and commands on the same plane. What if there's a language called 'list' ?
If there is a language called ‚Äúlist‚Äù you could do `bliss ‚Äúlist‚Äù`. Clap‚Äôs parser does a good job with differentiating the subcommands from inputs .
There are two issues: [https://github.com/rust-lang/rust/issues/27189](https://github.com/rust-lang/rust/issues/27189) [https://github.com/rust-lang/rust/issues/34225](https://github.com/rust-lang/rust/issues/34225) &amp;#x200B; Unfortunately it doesn't seem to have any momentum. There are some suggestions in the comments though.
¬£~~~
Try calling `.as_bytes()` on your `public_key` value first - that will give you the actual _data_ for the key, and you can then print that.
That is a matter of ABI, not language. Certainly if a function is inlined (so that the ABI does not come into play), there is no overhead.
Post your code, your testing methodology and your results. Also, you are building with `--release`, right?
Can I just check if what I'm experiencing this is the state of the art for vscode completion (or completion in general, if other IDEs are recommended) at the moment? Just want to make sure I'm not misconfiguring or misusing it. If I type all my variables I get a [some pretty sweet completions]. However if I leave the compiler to inference it is [less helpful](https://imgur.com/wr7RL5w), and it also limits the amount I can [inline things](https://imgur.com/mG9zdLK). Originally I thought maybe I can just manually type everything, but do so for an expression like `(1..10).map(|x| x)` is already difficult (I don't actually know how to do that). And the other thing is while I get nice completions for trait calls once I've [fully implemented a call](https://imgur.com/laIW7Hl), the hints provided are less useful [when I'm trying to build it](https://imgur.com/f1nMMks) which is really when I want it the most. I appreciate in this case it's not practical to show everything as the sheer number of available calls is overwhelming, but once I've started to hone down a little (eg type 'an' or 'any') I was hoping to get the hint I see for the full implementation.
Wait the graphics card uses floating point values to offset into a integer valued bitmap?
Would that be `bliss '"list"'` in my shell?
I‚Äôd love this. `_::East` is another syntax to consider.
I may be wrong here, but i didn't realise that was a thing. As in, I'm pretty sure it isn't: the command line parses your command input to a list of tokens, which it sends to the started process as the argument list `argv`. The quote symbols only help you to bypass the tokenizer, allowing you to add spaces, do string interpolation, or add another command's output to an argument. The running process shouldn't be able to distinguish `bliss list` from `bliss "list"`.
Thank you. It's semi-working. note: required by \`std::fmt::LowerHex::fmt\` label: the trait \`std::fmt::LowerHex\` is not implemented for \`\[u8; 32\]
What do you mean by "semi-working", exactly? Post your code and the full error you're getting.
&gt;`let mut csprng: ThreadRng = thread_rng();` `let keypair: Keypair = Keypair::generate(&amp;mut csprng);` `let msg: &amp;[u8] = b"";` `let sig: Signature = keypair.sign(msg);` `let public_key: PublicKey = keypair.public;` `let yo = public_key.as_bytes();` `println!("PUBLIC KEY {:x}", yo);` &gt; &gt; `note: required by \`std::fmt::LowerHex::fmt\`` `label: the trait \`std::fmt::LowerHex\` is not implemented for \`[u8; 32]`
Yeah, that's not going to work. `{:x}` only works on a single number; you're trying to give it an entire slice. You have to implement the formatting yourself, or use [`hex::encode`](https://docs.rs/hex/0.3.2/hex/fn.encode.html) (since you said you're already using the `hex` crate).
You can consider Future as some sorta wrapper over task in tokio. AFAIK when you spawn future on tokio, you create task there which will control lifetime of future within tokio. When your future notifies task, tokio poll your future. That happens until your future will not finish. &gt;The docs describe the tasks as "asynchronous goroutines" This is not correct analogy but it is close enough. Basically they mean it is just piece of code that is running on tokio without spawning extra threads and etc. Since it is asynchronous, it runs only when IO is ready. And you can resume execution by notifying event loop
Thank you! It works now. Have a very nice evening.
What happens when I send a slice of read-only memory through a channel? If I'd send a variable or a vector, the ownership would be transfered to the other thread. The slice does not go out of scope in the main thread, somehow, so I guess the new thread gets another reference to the same memory?
I think that `bliss -- list` may do the job, but I agree that there is something wront in the parameters.
If this is a problem, couldn't it be fixed in a future edition?
For anyone unfamiliar, one of the posters in that thread (ferris) has a twitch series where he streams himself building things live. The videos are available on youtube as well: [https://www.youtube.com/channel/UC4mpLlHn0FOekNg05yCnkzQ/videos](https://www.youtube.com/channel/UC4mpLlHn0FOekNg05yCnkzQ/videos) 'Ferris Makes Emulators' is focused on building a Virtual Boy emulator in Rust, and it looks like a lot of his more recent videos are in the 'Ferris Makes Demos' series, which is more relevant to this topic.
I actually didn't even see this one
Yes that seems to fit the bill! Thanks for the link. Arc&lt;T&gt; would be required. In my case the data are long vectors plus some meta-data. The overhead of Arc&lt;T&gt; will be minimal compared to the actual computations involved. Thank you.
Allowing macro author to evaluate the self expr more than once may result in caller-side inconsistency that is hard to debug. Think of this example: ``` do_something().open_file().write_batch!(line1,line2); ``` and ``` let mut handle = do_something(); handle.open_file().write_batch!(line1,line2); ``` If the macro write_batch! mistakenly evaluates the self expr on each batch content, the former do_something will be called twice when the latter won't. If this function has side effect, you can hardly realize that this macro is the source of the problem at the beginning. Ps. I'm also a super fan of UFCS macro.
It could, but then switching to this edition would be very tedious. Also, programmers are used to structs as they are now.
As a workaround, you might look at using an editor/IDE with RLS support. In VSCode for example, you'll see each error folded into one line, appearing in order, in the 'problems' view.
Am I the only one who likes to keep his .gitignore specific? I usually start blank and add things whenever they come up. Most my Python .gitignore files look like this: #Python __pycache__/ dist/ #IDEs /.idea/ /.vscode/
I think in the diagram "my" should be "my\_" and "Simon" should be "\_Simon".
You should keep your IDEs in your gitexcludes file; it is a file meant for your ignores specific to you, not to the project. (E.g., IDE files, or your-OS dependent stuff like OS X's `.DS_Store`.) You drop your IDE's file in it *once*, and it applies to every repo on that machine, so you'll never accidentally commit a `.idea` file or a vim swapfile again. See `man gitignore` and the `core.excludesFile` config in `man git-config`.
Ha, I‚Äôve been a daily Git user for years and TIL about `core.excludesfile`. Thank you!
Although spaces are usually denoted as "‚ê£" rather than "_".
+1. This is what I always do, I have a separate terminal window open where I run the compile (usually just `cargo check`) and I call it as `cargo check 2&gt;&amp;1 | less`.
&gt; `use self::HelloWorld::*` is equivalent to writing `use HelloWorld::*`. This is not strictly true. It is usually true in Rust 2018 that `use self::a;` is equivalent to `use a;`, but not if `a` also exists as an external crate (I think an ambiguity error is reported in that case). In Rust 2015, `use a;` is the same as `use crate::a;`, but is compatible with older rustc versions that don't understand `crate` in paths.
That's why does Amethyst, and this is great IMHO
Rust contains 75% C confirmed.
You are looking for r/playrust
Well, of course it doesn't solve all vulnerabilities, my question focuses more about the vulnerabilities that were solved thanks to Rust
The "Ignore your .gitignore" messaging is really confusing, and I don't understand what you mean by that. From that headline I thought it would be a tool that allows you to deactivate your .gitignore for individual commands and I didn't bother looking at it. Only after the comments here I saw that it's mostly a templating tool that I probably want to use!
It's probably worth knowing how people find and report this issue. It looks like an issue which should ideally be raised during RFC, and maybe knowing how people find it might provide something helps improving the RFC flow?
Off Topic: IN days of old there was a computer called a VAX, which used a high order assembly language called BLISS. It was, if you like, the RUST of it's day. There were arguments between the die-hard Assembler fans and the BLISS supporters over which was best. This culminated with the Assembler protagonists wearing t-shirts with the words "BLISS is Ignorance" at a conference I attended!
Because the contents of the database and the code of Python belong to the company's property, I can only grab the length of the content of curl, and the execution time of using curl to python. 1. Curl to python average execution time: 0.533614 2. Content-Length: 4965028 Rust side(just use `cargo run`): 1. Curl gives rust an average execution time of 2.678472 2. Content-Length: 4965028 3. [rust-code](https://github.com/pili2026/cassandra-rs-driver/blob/master/src/main.rs)
AFAIK `Error::type_id` method wasn't introduced via RFC, it was there since before Rust 1.0. However there *was* [an FCP](https://github.com/rust-lang/rust/issues/27745#issuecomment-373906749), but this issue was subtle enough for nobody on the libs team to notice it in time.
[rust-lang/rust](https://github.com/rust-lang/rust) repository has been mentioned **29 times** on Reddit over the last 7 days. The last 3 mentions: |Mention|Source| |---|---| |[..] letter variations. If someone really wanted to keep the await name, they could make an ùñÜùñúùñÜùñéùñô!() macro. Well, as the compiler pointed out when I went to test, maybe someday once #55467 [ https://github.com/rust-lang/rust/issues/55467 ] is resolved.|[/r/rust](https://reddit.com/r/rust/comments/bld06g/a_final_proposal_for_await_syntax/emq49um/ "/u/Uristqwerty at 2019-05-07 09:52") | |https://github.com/rust-lang/rust/issues/54727|[/r/rust](https://reddit.com/r/rust/comments/blow5v/ifmt_v01_why_write_printlnx_x_y_y_x_y_sum_xx_yy/emq84o6/ "/u/nicoburns at 2019-05-07 10:59") | |Oh, wow, I literally just wrote this but now I don&amp;#39;t have to maintain it :P.FWIW, I also ran into the issue with proc-macro-hack that you describe in the other comment. Maybe comment on the issue [ https://github.com/dtolnay/proc-macro-hack/issues/31 ] that you also ran into it? Or mention here [ https://github.com/rust-lang/rust/issues/54727 ] that you also need expression-position proc macros?|[/r/rust](https://reddit.com/r/rust/comments/blow5v/ifmt_v01_why_write_printlnx_x_y_y_x_y_sum_xx_yy/emr9dcj/ "/u/awygle at 2019-05-07 17:37") | ^([Report an issue](https://np.reddit.com/message/compose/?to=gajus0&amp;subject=GitSpo%20Reddit%20mentions%20bot&amp;message=Hello%20Gajus,)|View all [mentions of rust-lang/rust](https://gitspo.com/mentions/rust-lang/rust))
Use `cargo run --release`, you're benchmarking a debug build.
That's certainly intriguing. What are you using to draw the controls? And is it related to https://crates.io/crates/rpf?
Have you tried using a tool like [GNU stow](https://www.gnu.org/software/stow/) to maintain the symlinks? I've been using it for about a year now for my personal dotfile repo and it's working great for me
&gt;Use &gt; &gt;cargo run --release &gt; &gt;, you're benchmarking a debug build. My benchmark has not been used `--release`, always using only `cargo run`. After the use time is increased to 0.902928, can you tell me the difference?
Let's correct everything that was bikeshed wrong for the next edition :3
&gt; Unsafe code is JUST the ability to dereference raw pointers, access external functions (from C) or to write assembly to call into the kernel. most of all its the ability of a developer to specify when they _don't_ want that and compiler ability to enforce that. &gt; Our computers REQUIRE unsafe code in the kernel They may require some of it, but a lot less then we currently have. &gt; The core library uses unsafe to implement internal mutability (Cell&lt;T&gt;) and to implement efficient collections (Vec&lt;T&gt;). and therefore all programs who use those features do it safely. &gt; A 100% safe Rust program can't do any IO or allocations. Doesn't matter. 100% safe _my_ code can do those things (by using safe wrappers).
The --release flag, `cargo run --release`, compiles it with all optimizations. Without the release flag, it is in debug mode so it compiles quickly for testing but does not optimise for run time. Try with the release flag.
I subscribe to retrogaming/programming, so when I saw this I thought it was a new release of [GEOS](https://en.wikipedia.org/wiki/GEOS_(8-bit_operating_system)) for the Commodore 64!
&gt; but then switching to this edition would be very tedious I don't see why it would. It seems like something that could very trivially be automated with "cargo fix". It already does far more complicated things. And of course, I assume future editions will work the same as now in that code using older editions will continue to compile and be usable with projects using the new edition forever.
This is amazing. The community has been seeking a GUI framework.
&gt;So basically, Pin&lt;T&gt; is disallowed to be moved from a Box or maybe from being in a Box? It's a bit more complicated than that. Basically if you have an &amp;mut T (maybe from the stack or another type that implements Deref&lt;Target=T&gt;) you can put that into a Pin&lt;&amp;mut T&gt;. It can then no longer be moved out of there. This allows you to implement methods on the T which accept a Pin&lt;&amp;mut Self&gt; receiver which can then do self-referential things. It's rather complex how it all works so I'd advice reading the documentation on std::pin.
Debug builds can be up to 100 times slower than release builds in some cases. There is no point in benchmarking them.
Thanks. Took a look at this one. At first glance it doesn‚Äôt look like it can help me just blow through and assign extensions to everything super easily, but I think I should at least be able to sort through the junk files and find the ones that are worth keeping.
There‚Äôs a more general problem, not specific to regexes. In Rust ecosystem, there‚Äôs no trait that represents a sequence of utf8 encoded bytes. For comparison, in Java there‚Äôs CharacterSequence interface which is used heavily throughout IntelliJ. However, designing fast StrSeq trait for Rust is hard: you need to expose underlying slices of bytes representation, and you need to cleverly design associated types for slicing.
Conversely: put IDE files in .gitignore *because* it gets checked in, so you don‚Äôt have to worry about other people having their environments set up right. Some lines in .gitignore are never going to amount to any level of clutter that I care about.
Cool. Didn‚Äôt know about this crate. I did try to open one or two files I confirmed were images in chrome, but they still were downloaded as if they were data blobs rather than images. Not sure what the cause is. My Mac knew these files were images when I opened them, but chrome didn‚Äôt...
I‚Äôm recovering all data I used as a C: drive for a windows installation, so files can be about anything. Could be doc, jpg, dll, exe, bin, temp files, etc. I‚Äôm trying to recover the stuff from the users folder so I only care about the images, videos, and documents. The biggest issue is sorting through the junk and throwing it out.
Thanks Kill\_the\_Mule. Much appreciated. I don't mean to be rude but I was under the impression that Rust was a proper production ready language. The fact that this basic feature is not standard, seems to suggest that it's not as matures as I had thought. Or am I missing something? Perhaps there is an enterprise level service and this is just the limited and crippled free service?
Which pattern do you plan to use for handling interactions between GUI and code?
Oo, I'm happy to hear this. `dotenv` is fantastic for cross-language config, but I had noticed that the Rust version seemed to be unmaintained.
It‚Äôs just a layer I‚Äôd like to skip. Linux is complex enough, convincing everyone to conform to standards helps everyone in the long run.
No, this has nothing to do with the RPF Crate. I haven't published the source code yet. At the moment this is still very chaotic and was more a playground to test. The whole Framework is at a very early stage. I draw everything with Cairo, but the plan is to support different backends.
My guess is that the RPF in the post stands for "Rust Presentation Foundation" as a sort of pun on [WPF](https://en.wikipedia.org/wiki/Windows_Presentation_Foundation)
The main author of this is Pekka Enberg, the first author of the [parakernel paper](https://penberg.org/parakernel-hotos19.pdf). So it seems like this is the prototype mentioned in the conlusion of the paper: &gt; A prototype parakernel written in Rust is currently underdevelopment. It's really great to see Rust used in operating system research!
What about ‚ÄûAdvent of Code‚Äú? There are little daily tasks for a set of different application fields. I know, it is not a full CLI app. I think the tasks are good to handle cause of their sizes. https://adventofcode.com
That's still in the works, the current way is ugly... The whole project is under construction. I just want to know if there is any interest because I can never handle such a big project on my own. At the moment it's still a borrow hell, but in the future it should use an entity component system.
That's right.
Can you use a proc macro attribute as an inner attribute on a module with proc_macro_hygiene? I remember reading about that.
Exactly. It _is_ a project's concern that those files aren't checked in.
Can you elaborate on the "combined with the failure crate" part? My only experience with it was from the mysql_async crate, and I found it more of a PitA than helpful. Maybe I was just using it wrong, since it mostly just forced me to constantly convert my Failures, since the don't impl Into&lt;Error&gt;
The OP links to an issue in which I've written a fair bit about this: https://github.com/rust-lang/regex/issues/425 Some short points: * Matching on streams and matching on non-contiguous strings are different use cases. They might share implementation details, but their APIs are different. Key question: **What is the API that people want?** * Most regex engines don't offer any kind of support for this at all, and require a contiguous region of memory. PCRE2 has some support for this, but only via its "DFA" (actually, NFA, lol) engine. And even then, it has tons of caveats. See `man pcre2partial`. Hyperscan is a notable exception, since (AFAIK) they started out with stream matching as a design constraint. Ask them how they feel about regex matching on streams. It's hard. And even then, it comes with all sorts of caveats. * It's almost certain that a transparent API cannot be provided, and there would have to be some kind of concession made. Either along the lines of "use more memory," or "miss a match," or "impose a limit on the total size of the match." * My [comment here](https://github.com/rust-lang/regex/issues/425#issuecomment-348768742) explains the key difficulties that are _obvious_ to me (read: there may be other difficulties that I don't know about). The TL;DR is that the (slow) PikeVM is amenable to matching on non-contiguous strings, but the DFA requires a backwards scan after a forwards scan to find the start of the match. * There is nothing about the _theory_ of regexes that prohibits stream or non-contiguous matching. There is even nothing about the theory of regexes that prohibits matching on things that aren't actually strings. Arbitrary alphabets are perfectly fine, so long as you can assume some things about them (like an ordering). And this is usually how people construct their mental model of how regex engines _actually work_, leads them to believe that things like this are possible. The problem is that it is not sufficient for a regex engine to merely "work." It must be simultaneously useful and fast. The theory _almost never_ talks about match offsets, capturing groups or other such things. Instead, the literature is almost always limited to "does it match or not?" (i.e., exactly why the only time you see regex derivatives being used is in someone's unmaintained git repository. Nobody has done the work, AFAIK, to turn them into a useful library with all the bells and whistles of a regex API that most folks have come to expect.) My high level long term plan for the regex crate is to design something that is not only amenable to different optimizations, but is easier to maintain. The current design is buckling under its own weight and produces bugs. This is why I've been steadily working my way up the abstraction ladder (memchr rewrite, aho-corasick rewrite, and regex-automata, which exclusively focuses on DFAs) so that I have a [stronger base of primitives to build on top of](https://docs.rs/aho-corasick/0.7.3/aho_corasick/enum.MatchKind.html). A secondary goal as part of this work is to think more carefully about the streaming and non-contiguous match use cases, but I don't currently have a lot of data about this. The obvious primary use case is in a text editor, but I am not someone who has ever delved into the guts of a text editor before. So for example, one thing that would be extremely useful to this whole problem is to explore how established text editors---such as vim and emacs---handle regexes. What kinds of trade offs do they make? Did they have to roll their own regex engine to do it? If one were to install a new regex engine into one of those editors, what API would it need to have to make it work? If you look at https://github.com/rust-lang/regex/issues/425, you can see that someone has tried to split out the NFA engine (PikeVM) to add this sort of incremental matching. But I don't know what kind of progress they've made. Nevertheless, if I _needed_ non-contiguous matching yesterday, this is the approach I'd take.
Have you written any more about what a `StrSeq` trait would look like? And in particular, who would use it, how it would be used and what problems it would solve? I'd be very much interested to hear what you have to say, given how much time you've spent inside text editor environments. :-)
Suppose I have two mutable references to the same RefCell at the same time, obtained by some usage of `unsafe`. The only thing I do with these mutable references is pass them around and access underlying RefCell through `.borrow()` or `.borrow_mut()`. But never through `.take_mut()`, even though the borrow checker technically allows this. There are no threads. Is this memory-safe? Any risk of compiler optimizations incorrectly altering the behavior of the program? Any other concerns?
&gt; did try to open one or two files I confirmed were images in chrome, but they still were downloaded as if they were data blobs rather than images. "detected"? Can you share such an image? It's possible that it's mildly corrupted, and some viewer are more lax in accepting them.
Finally! That NoneError has added so much noise to my code.
I'm still experimenting a lot. I think I'll be releasing the code in a few weeks and hope that more people will be interested and helping with planning and developing.
But when does it stop? Are you going to try to preemptively add other editor config files? Just the most popular? What about ctags etc? If you open source your project and someone uses a niche editor with files you didn't add, it should probably be caught in code review anyway and that person instructed to remove them. It's on them whether they manually remove them every time or add them to their personal gitignore.
You usually have to fix compile errors one by one anyway, in my experience. The effort from figuring out if the follow on messages are real errors or just cascading errors make it not worth it in most cases. I wonder if there's a safe/sane way to store partial results on failed compiles, to speed up recompilation.
Your program won't panic, but it will print out the debug representation of the error: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=75599b9c90bad82ef29a75725f992159 (I usually want to print out the `Display` representation of an error, so I never use `main() -&gt; Result`.
&gt; I imagine such use-case is going to be more common Beyond text editors and DPI, could you say where else you'd expect this use case to be critical? (I realize one could just say, "any place where you can't fit the thing you're searching for into contiguous memory," but I'm looking for more specifics than that. :-))
Yes, because usually it has to do some interpolation in the process and there's specialized hardware for doing it. See [here](https://www.khronos.org/opengl/wiki/Sampler_(GLSL)#Texture_coordinates) for an idea of what it looks like in shader code. Generally if you want "a bitmap" then you tell the GPU to use the "linear" filter mode; otherwise it's going to do some sort of smoothing between pixels. Having all the numbers be floating point is USUALLY no problem if you only deal with power-of-2 image sizes. It is possible to use "pixel coordinates" (what that document calls a "texel-space texture coordinate") but I've never actually seen it done, presumably 'cause it just makes the shader code more complicated without any real benefit. DirectX doesn't offer that ability at all, from what I can tell. Modern graphics programming is VERY FAR from "just put pixels on the screen".
Something like this is desperately needed in Rust. Not too sure about the template syntax though. I'd take inspiration from Angular and Vue or even QML (even though it's not XML based) for ease of use rather than from the typical desktop frameworks.
As a guy who uses WPF in his full-time job but is learning rust on the side... I would 1000% be interested in this. Is there a link to the repo? I may be able to help out in some way
This is great. In terms of format the best imho would be to design the rust structs then let people decide how to serialize it, either with serde or any other framework.
As someone who writes WPF MVVM applications professionally, oh yes please!
I appreciate that you asked, since I faced the same problem :)
I have used XAML a couple of times and found it not that bad but I didn't enjoy my experience with C#. Will definitely check your project out.
This might be controversial here, but I don't know if Rust will ever be a good choice for a lot of machine learning workflows -- the design of the language doesn't quite line up with the needs of, for example, iterative prototyping. If you look at the scientific computing powerhouses (Python, R, Matlab, etc), none of them look anything like Rust: no sophisticated type system, nary a compilation step, etc. That's not to say anything is better than anything else, just that Rust necessarily made different design choices and that makes it a tougher fit for a lot of scientific computing work. Where Rust fits into the picture, imo, is the engine behind the scenes. If we want to be advocates for Rust, we should do what we can to make sure the next xgboost or LIBSVM or whatever is a Rust codebase.
&gt; Note that all the error returns of a function must match the trait or type of its `Result` They don't have to _match_ that type - the `?` is quite liberal and requires that given error type is `impl From&lt;TheOtherErrorType&gt;` (e.g. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4096dd4973a05d202e2c50a601f91ceb). It's a small difference, but a very handy one.
It's almost every other day that someone posts a benchmark comparison on this subreddit without using the release flag and saying Rust is slow. Just use `cargo run --release` when you need performance and/or are testing for speed please.
What are the goals here over [cargo-readme](https://github.com/livioribeiro/cargo-readme)?
The Rust executables are not signed, and Windows displays the SmartScreen warning if it doesn't know about them.
Just include your dot files, editor, terminal, and essential plug-ins in the repository. Problem solved.
That happens for any program not many people have installed. SmartScreen doesn't do anything more complicated than warning you if you're running an unpopular program.
It‚Äôs similar but uses a slightly different mechanism. `cargo-readme` uses a `.tpl` template file while `cargo-sync-readme` uses the output file directly by using inline markers.
thanks for the information
thanks for the information
The basis is XAML, but I can well imagine that the format will change in the future and be improved with own developments from the Rust community. With features for tablet, mobile etc.
No Repo at the moment, I post the link in 2 or 3 weeks. Any help is welcome. :)
Yes, but he has specifically stated that it's a very niche tool and if you're not an "experienced enthusiast" you should just keep using node, which has its issues but all things considered, is still a good tool.
Shameless self promotion of the Rust Language Cheat Sheet [cheats.rs](https://cheats.rs) which I created for this purpose. I tried to document every _sigilic_ and _keywordic_ language construct Rust has on a single page, including all uses of `self`. Feel free to file an issue if anything is unclear or missing.
I'm working on making my software rasterizer for the CLI render to the web: https://ecumene.xyz/sloth-demo https://github.com/ecumene-software/rust-sloth/tree/webify
Is there a particular reason you are using the cassandra-cpp-sys crate instead of the safe cassandra-cpp wrapper?
I got really detailed here, perhaps more than you need. I also don't know Go, so I can't relate it to that. Hopefully this helps anyways. It's also pretty poorly organized, so sorry about that. The lazy function is itself a Future to be run within the engine (`tokio::run`). The return value (`Ok(())`) needs to be `IntoFuture`, meaning it can be converted to a Future trivially. In this case, the future that `Ok(())` corresponds to is just an empty future that does nothing and always succeeds. The only reason you need it is because Rust function overloading is very limited, so there's no option to simply return nothing. In another scenario, you might return a future from the closure within `lazy`, and this will just spawn that future just like `tokio::spawn` would. So you need to learn threading, which is just going to be a bit hard, but I'll ignore that because tokio can run an event loop in a single-threaded environment, which you'll already understand without knowing threading. Imagine you have a collection of closures which can be thought of as conceptual "tasks", in that they're things you want to do at some point and in some order, but the point and the order is not necessarily that relevant. What you might do is - Iterate through all the closures - Run each one - Quit the program This would be a form of an engine for a task queue. However, real task queues have much more flexible requirements. For example, - You need to be able to spawn a new task from within a task - You need to be able to do things "asynchronously" (at a different time). For example, you need to be able to say "Don't add a task right now, but don't quit the program, and 5 seconds from now, add &lt;task&gt; to the task queue" In this case, what you might do is make the task queue globally accessible and allow the closures to add new tasks (or potentially even remove tasks, such as canceling things you no longer need to do). Then, your engine might look a little more like this - Loop - Iterate through the closures, running each one in turn - Sleep a bit maybe to avoid busy waiting Because now you need to check to make sure no new closures have been added. However, if you want to add a task to the task queue 5 seconds from now, the naiive approach would be to simply sleep for 5 seconds and then add the task. This won't work, because it will block the loop above. So if you have two tasks: - Sleep 5 seconds then add a task to print "goodbye world" - Print "hello world" The following actions will occur: - Sleep 5 seconds - Add a task to print "goodbye world" - Print "hello world" - "goodbye world" But if you're writing a normal application, this is a pretty weird thing, and what you *probably* meant to do was: - Print hello world - Sleep ~5 seconds (really 5 seconds from the start of the program, not the end of "hello world") - "goodbye world" (notice "hello world" is printed 5 seconds after you wanted it to be) This pattern of deferred execution is very useful for asynchronous programming, because it allows you to just "throw up" a task to the queue and move on with the program execution, avoiding long waits for things like IO. A more practical example might be "request some data from a server and print it out when it comes back, but *don't* wait for it to complete before moving on to already scheduled tasks". However, in order to do this, you need to be able to essentially defer asynchronous/non-blocking tasks (such as sleeping). The way this is accomplished is using polling and tasks, which generally rely on complex topics like operating system primitives and processor features. **Generally speaking**, you do not need to understand how tasks are implemented to successfully work with Tokio and Futures. I personally have used Tokio a number of times in professional contexts and I don't think I've ever actually committed code that referenced `Poll` for example. The loop above is pretty similar to an actual event loop, minus these considerations. These considerations are too complex for simple closures, which is why Futures exist to represent conceptual tasks in an asynchronous context. Rather than running through a list of closures, Tokio runs through a list of Futures, and actually running a Future is dependent on a number of considerations you might have, all of which would be options to modify on Tokio. A Future can simply represent what might be referred to as a "synchronous" closure. That's generally what `lazy` does: it creates a closure that just runs within the event loop. One little thing `lazy` also does (which inspires the name "lazy") is allows you to return a Future to spawn on the event loop as well. I think the original idea behind `lazy` was primarily to construct this future (it's a lazily-evaluated future, and lazy evaluation has a lot of benefits normally), but I mostly see it being used as I described above: just a way to run the closure in the context of the engine. In this context, there's probably no final single future that you want to run, so you can just pass `Ok(())` to spawn an extremely lightweight and irrelevant Future which effectively does nothing (and might literally do nothing given a sufficiently advanced implementation of Tokio), essentially just to satisfy the type system. Generally, `lazy` is something of a "last resort" breakout function which helps you do more complex logic. There are all kinds of helpers and ergonomics to help you avoid it to make clearer code. `lazy` is mostly used when you want to spawn a bunch of futures but don't really care when they end and you want to use relatively non-trivial logic such as a for loop. So, to bring it back to your example, within `lazy`, you're using `tokio::spawn` within a loop. This might be the conceptual equivalent of `task_queue.push(|| println!("Hello world")`, though again it's using Futures rather than closures. To do the 5 seconds thing, rather than using `sleep(5000); println!("hello world");`, you would pass in a `tokio::timer::Delay`, which the tokio engine "magically" knows how to execute properly. Unlike calling `sleep` within `lazy`, this would *not* block the execution environment, meaning it would allow other Futures that have already Among the more interesting things worth noting, please note the data/logical model is separate from the engine. Futures can be run by executors that are not Tokio, and you can also implement your own Futures that Tokio can run. Tokio is simply one implementation of the event loop, and if you find that you'd like to execute Futures in a way that Tokio can't support (like maybe running multiple Futures across multiple computers? I don't think this would ever make sense given Rust; Tokio happens to be quite feature-complete as far as I know), Futures are the data, and Tokio is the verb. I hope this clarifies things. I'm definitely not an expert in Tokio, asynchronous, or Rust, but I think everything I said has been conceptually correct.
It is *always* UB to have more than one mutable references to the same type in rust. When rust compiles its internal representation to llvm IR, it uses the `noalias` attribute for any and all mutable references. Those are used by llvm to perform some optimizations. If you now break the noalias-property by having more than one mutable reference, it'll result in UB.
Why not store the whole build operating system
I think it would be worthwhile splitting up the discussion of the stream based matching, and non-contiguous matching while remaining in RAM. They do share some characteristics, but the non-contiguous case doesn't offer as many challenges in API design and tradeoffs. I imagine the non-contiguous case will come up more often with scatter/gather I/O support recently added to the standard library, and cases like this, of people using rope like data structures to reduce the amount of copying done.
Thats how you get another emacs
I prefer to make mine as explicit as possible because I've had very confusing issues to debug caused by hapless engineers putting something like `commondirname` instead of `/commondirname/` leading to some directory deep in a vendored package being ignored by mistake.
I'm pretty sure calling `to_async` is incorrect here, since the handler blocks on Diesel and so isn't actually async. You might need to use `to` here, but the Actix docs don't make this clear at all.
Great, I wasn't fully aware of that, thanks!
Memory safety seems like a really good thing for protecting us from skynet.
You're pretty close. Since `File` is an always-open file and you want to open it lazily, you can use `Option&lt;File&gt;` to represent a file that might not be open yet. The types pretty much follow from there: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=18874b06f951fcf688d7be28afb72b93. Of course, you could store the `Path` inside your struct, but it's hard to tell from your code sample.
A task in Tokio is basically a future that is stuck onto a queue to be processed by an event loop. Usually one task causes the loop to terminate when it completes. IMO biggest issue with tokio is trying fathom where compile errors lie because usually it's a long way from where the error is, usually when chaining futures together and mapping return types.
I don't understand your complaint. If cargo vendor can do what you need, what is the issue? It's a Rust pattern in general that if something doesn't absolutely need to be a part of the core language or tooling, then it should be delivered as a separate package.
very nice! perhaps I might be able to finally port that ancient legacy codebase I have for a very old client, and still re-use the XAML, and finally make it moral...
Sounds good, I shall eagerly await it!
Hi
Hello felixrabe!
That looks really good already! Windows had the best GUI tooling I've used so far (a looong time ago though), so reusing it seems like a good idea. We'd get a graphical GUI designer for free, and it makes porting WPF apps easier as well.
Correct. But that will take time for a working GUI designer.
Dude, awesome, quick response :) I've actually used similar for a buffer, I should have know. Rust is way different than other languages I've used, C, C++, python, Java, Erlang, Lisp, etc... Seems like it borrows concepts and constructs from all over as well as introduce new layers for protection and validation. You have to be a lot more concise with declarations up front, but I can see where it saves time and helps prevent mistakes later in the game. Very interesting language. Thanks for the input!
Always appreciate a thorough roadmap.
I think you‚Äôre describing a hypothetical concern that isn‚Äôt a problem in practice. Someone tries (bad word, it‚Äôs usually an accident) to check in one of these files, you point it out and it gets added to .gitignore, and that file is never a problem again for the project. It‚Äôs really not a big deal.
I mean that the Visual Studio one already seems to work, so there's no need for one in Rust to get started
How about using an existing UI framework like GTK instead ?
A lot of the time I have several similar errors to fix (type signature of fn changed for instance). When that happens the cascading errors are very useful to give you the spots where you need to fix stuff. (Although, I normally fix these in groups because line numbers tend to change after a few things.
PhotoRec might be your best choice for recovering files on a corrupt filesystem: [https://www.cgsecurity.org/wiki/PhotoRec](https://www.cgsecurity.org/wiki/PhotoRec)
I always recommend trying to duplicate coreutils as a way to learn your language's CLI. Try making your own grep!
 use Direction::*;
So where is the RFC for this feature?
Only ‚Äúmajor‚Äù features need RFCs; this was a small one.
Would certainly have appreciated something like this for [my latest project](https://i.imgur.com/R2nBOAQ.png) :)
You can use it to implement `mem::transmute` using safe Rust.
&gt; It's impossible to implement it for all array sizes Yes of course, I was just talking about size &lt;= 32 like all traits implementation for arrays. I didn't think of heap allocated arrays moved to the stack. Now I understand why this is a problem, thanks.
This is worse than the standard way. You still have to import it to your scope and this clutters it as well. The Swift version knows an argument is of of type Direction, so it lets you use a relative value.
Unless wrapping arithmetic is explicitly used for `TypeID`s, wouldn't that actually panic?
I'm a big fan of Rust but I can't say that you will find better luck getting a job with it. If your first priority is a job with a static language you are better off with the Java path. I'd also say don't rule out Kotlin as a better Java without the challenge of the smaller market for Scala. Our services layer guys recently switched to Kotlin with no Android in sight and are loving it. It can take time to find the right opportunity and you have to learn to get what you can out of where you are while doing that. Sometimes learning and using the fun languages has to be on personal time and work using what will pay the bills. All that said keep looking, could get lucky!
"Text file busy" is the error you get on Linux when you try to modify a running program. Instead you need to make a copy, remove the original, then rename the copy. &gt; My motivation for this was originally wanting somewhere to store a u8 (high score) for a simple game Umm.. there are "better" ways to do that, but they depend on the structures of the executables on your platform. Another one would be to make it a static (global) variable and try to find it in the file on disk.
This is exactly what I envisioned in a former discussion about a rust abi. Even though my thoughts weren't that well received. IMO a great way to export rust specific concepts without having to stabilize it in the core language. A great step for exploring how abi would be possible.
https://github.com/rust-lang/cargo/pull/6869
Maybe all features should need RFCs. The number of "check boxes" required to FCP minor library features appears to be 5. The surprising thing is not that a soundness hole was introduced by 5 experts, but that only one hole has been discovered.
It would be a lot of busy work for not more improvement.
I think this feature (as part of everything surrounding the `Any` trait) predates the RFC process
Many nightly features predate Rust 1.0 and the RFC process. That's no excuse for merging them without proper peer-review.
Rust used to have default imports for enum, but people didn't like its lack of expressiveness, because we don't know were the value comes from. Also there is no `.East` short notation. If you want you can import only once at the top of your file.
If the feature is not worth reviewing properly, then maybe it shouldn't be part of the language.
It's possible but very much undesirable. It is also unsafe. Iirc execve mmaps the file as rx so you can not write to it. You're writing an arbitrary ascii value to the end of the file, which can invalidate non-ELF binaries. If you're a beginner programmer I strongly suggest you stay out of this hornets nest and instead just dump your stuff into a file. If you want that to be persistent across runs from various locations you can store the score in `~/.config/myprogram`, or something along those lines.
Cool but- I'm not looking at/onto entirely different ecosystems because I want to do more microsoft anything.
I started using cassandra-cpp, but I found a bug. While waiting for the bug fix. I tried to use cassandra-cpp-sys and built the company's project.
I hadn't thought about Windows but I guess yeah it wouldn't be platform specific ideally. So if I made a `static mut HIGH_SCORE: u8 = 0;` in my game, and I mutate it at the end of a game, would that affect the program on disk? Otherwise I'd be stuck with the same problem of modifying a running program like before right? &amp;#x200B; Thanks!
Although the efficiency is improved, python is still better. Maybe this is my code problem.
I tried this out and it actually works rather well within Rust (what surprises me. The compiler is really a beast) With C, however, this does not work. I guess I will just transmit a vector
What specifically do you think an RFC would have some to improve things here?
Thanks for the detail, that's useful. I'd guessed that appending random data to the end of a program probably wasn't a good idea in practice but as a learning exercise it's proving fruitfull!
It wasn't intended to be. You asked for the underlying RFC. I said that there is none.
I work under Linux and macOS and only run Windows in a virtual machine. One of my goals is to have a own visual designer that runs on all platforms. So everyone can use the platform that he likes and offer applications for other platforms as well.
XAML is certainly one of the best, if not the best, UI framework I've used. But as someone who uses Linux nowadays, I have to ask if you plan to support multiple platforms?
Thanks! I hadn't thought about Windows but I guess yeah it wouldn't be platform specific ideally. Assuming I had a static variable and I could find that exact offset in the executable no problem, wouldn't I have the same problem I started out with, which is that I would be trying to write to that location before the game ends and so would be trying to modify a running program?
I don't think I want a default import for enums. I want Rust to let me use a relative value when the argument type is already known for only that specific context. ``` // file animal.rs pub enum Animal { Lion, Cow, Dog } pub fn makeSound(animal: Animal) { ... } // file main.rs mod animal; animal::makeSound(::Lion) // ::Lion is valid only in this context. The argument type is Animal, so we should be able to use a relative value. ```
That's easy, as I said. You can make a copy of the program, remove the original while running and rename the copy.
\&gt; "I'm a big fan of Rust but I can't say that you will find better luck getting a job with it." &amp;#x200B; I saw three Rust jobs on Dice in the Silicon Valley area: [https://www.dice.com/jobs/advancedResult?q=%28Rust%29&amp;l=94063&amp;radius=30#dice](https://www.dice.com/jobs/advancedResult?q=%28Rust%29&amp;l=94063&amp;radius=30#dice) &amp;#x200B; I just applied to all three, but yeah, that's a lot less than Scala. The issue with Scala is that like 90%+ of the jobs aren't backend, and recruiters keep calling you and asking "Hadoop"? To be honest, I don't care if I'm coding in Scala, Rust, or F#, I just naturally minimize mutability and I hate writing "const \* const \* const \* const". Kotlin would be an acceptable replacement of Java, but it would be a compromise choice rather than my first pick. &amp;#x200B; \&gt; "you are better off with the Java path" &amp;#x200B; But I dislike Java! Can people compromise by picking [Kotlin on Spring Boot](https://i.imgur.com/1WFnyUQ.png), like with [https://start.spring.io/](https://start.spring.io/)? &amp;#x200B; \&gt; "Sometimes learning and using the fun languages has to be on personal time and work using what will pay the bills" &amp;#x200B; Yeah, I know that feeling. I've done Scala + Java codebases and it's not too hard to do Kotlin + Java codebases. It's probably easier to find a paying job in one of those. Also, with IntelliJ, the tooling for Kotlin and Scala are pretty good, and I typically use IntelliJ. &amp;#x200B; \&gt; "All that said keep looking, could get lucky!" &amp;#x200B; Thanks!
Ah sorry, I didn't quite understand that in your first comment as I just assumed if you can't modify a running executable you wouldn't be able to remove one either!
Yes, at the moment I tested it on Linux, macOS, Windows and RedoxOS. There will be different render backends. E.g. Framebuffer. So any system that can run Rust compiled applications and has a display can work with it.
Responded in https://github.com/rust-analyzer/rust-analyzer/pull/1275.
What problem are you running into from the C side?
Even though I hate XAML with a burning passion I wish you good luck. :)
I don't know why compilers haven't adopted showing errors in 'reverse' order long ago. I mean, they're used in cmd lines, so obviously ???
Fun fact: git supports a global gitignore! If you have editor or system specific things to ignore, like `~` files, `.DS_Store`, etc, put them in `$XDG_CONFIG/git/ignore` (usually `~/.config/git/ignore`) to keep your project gitignores clean!
Fair enough Your point about standards makes sense; my response was intended more to your last bit about maintaining the symlinks, which I think these kinds of tools make a lot easier
It would be interesting if it uses compile typechecking like rust. parse xaml during build.rs run, or introduce DSL via macros or something like this.
For Example... This is an older screenshot on RedoxOS. \[Imgur\]([https://i.imgur.com/ej5s5Sw.png](https://i.imgur.com/ej5s5Sw.png))
I get it. Here's my _feeling_: every second I spend in MS-related tech is another second I'm not learning the future. I still have wpf apps I work on but I won't be making any new ones for this reason, and if I wasn't on a win box for work, I wouldn't be doing any MS-related code. MS have thrown up the white flag and if you're not on azure, they ultimately don't care about you.
Yeah, sounds like a good idea, thanks.
I absolutely understand the desire to use regular expressions, since doing so means a pretty high assurance that the parsing is done the same between org-rs and the emacs org-mode. But since it seems that there's a known set of regexes in play for parsing, if they aren't *too* too complicated, I wonder if it might be worth investigating translating them to a parsing framework that is designed for streaming or for being restartable, as I believe nom is. Or would that be too slow?
Thank you. What exactly do you dislike about XAML? Maybe this will help me to do something better. :)
You're right. I should have brought up these cases. Thank you for adding them.
This is a nice cheat sheet. I wasn't aware of it. &amp;#x200B; Why is does the section on lifetimes not have an entry for `&lt;'a, 'b: 'a&gt;`. This was always the situation when I wish I did have a cheat sheet.
Is there a XAML designer on Linux?
Wow, awesome! Can't wait to check it out!
The goals of rust are inherently against the design of GTK.... I mean if a backend can support it sure, but I'd be appalled if it were the only option.
You can try cargo flamegraph to visualize where execution is spending time. https://github.com/ferrous-systems/flamegraph
Yes, the beginning is based on XAML, but later the community will decide if it will be something like a "XAML fork" or maybe something completely new. Could be exciting...Thanks for your feedback. :)
First mentions rust around the 8 minute mark for those who don't want the long intro https://youtu.be/pRlh8LX4kQI?t=485
Do patches normally have a release announcement or is this just because it was a security concern?
Sry, not yet :/
I did not know that nom can do streaming. I will chek it out. If there is a chance to leave the rope - i will take it
Great work! XAML is pretty awesome for specifying ui's. Widgets are kinda ugly, but the proof of concept looks great. If you want a crossplatform XAML form designer thing, checkout avalon studio from the avalonia project
Thank you so much, that did the trick! &amp;#x200B; I've got one more question: Can you explain how the lifetime bound on the next function affects the way it can be called in a loop?
Yes, so far every release, including patch releases, have had an announcement post associated with them.
Yeah, there are established tools for this. It doesn't really make sense to use rust unless you want to write a new tool.
Text editing (of any kind) was all that I was thinking about. :)
Thanks. Good to know that they work on such a designer. :D I'll definitely try it out.
Rust wants a life time parameter, which it can not obtain, as it can not know if and when C is deallocating the data. I think one just has to live with this and copy the data in this case
Structs have an inherent impl, like the one you posted in your example. But access to fields is entirely controlled by reference. In your write(&amp;mut self) example, the access is allowed because that function had a mutable reference to the file struct. If you were to look at the implementation of File, it's methods would also take an &amp;mut self, so write(&amp;mut self) is borrowing against the reference it's given. This is really important to think about in Rust code. If you are given say - an &amp;mut self, and you want to borrow against that and return, you need to explain in your function signature the lifetime of the returned borrow (which would show up as 'mylifetime, in a generic parameter or &amp;'a mut Type). Access comes from references. &amp;#x200B; (Also, when you get more into Rust, impls can be conditional! You can only define functions on a generic struct if the generic type implements Copy, or Ord, or Eq) &amp;#x200B; Rust also supports visibility, with pub and related modifiers. You can access this\_file directly from a Test instance (my\_test.this\_file.write()... ) if you mark the field with pub. I do this with 'options' structs, YAML/JSON binding structs, or other simple data types. The same ownership/lifetime/reference rules apply... You can't borrow an &amp;mut self against an &amp;self, etc. &amp;#x200B; Trait implementations have access to private struct fields (impl MyTrait for Test {}). But callers must have the trait in scope to use the implementation! use somecrate::MyTrait;
Usually for me it's the shower that provides instant answers for the programming challenges I face
How does one get another fix into a patch release? For example, a fix for [this issue](https://github.com/rust-lang/rls/issues/1390)?
I don't think this depends on MS. It uses the same file format, but that's it.
another at 13:00
&gt; I draw everything with Cairo, but the plan is to support different backends. You may be interested in piet, which is designed to be a 2D drawing abstraction over the various different platform backends (including cairo, and potentially a rust-native one at some point). It's aiming at usage in GUI libraries. It's probably not mature enough to be useful yet, but one to watch!
Maybe it's just because I'm inexperienced with it, but every time I tried to create a custom style in my UWP apps I wanted to rip my hair out. Like, just removing a button animation was like 50+ lines of code. Everything I did ended up being \*\*very\*\* verbose. With CSS it would have been done in like 1 line. I also strongly dislike mixing content structure with content styling. With HTML and CSS you can separate the two, whereas with XAML it seems like you're supposed to set styling on the actual element tags, which would be considered bad practice for HTML and CSS due to how maintainable it tends to get.
Anybody else loved the cat and baby photo at the end? That was one of the best touches I ever saw in a talk.
It could be made more portable (I'm only handling Linux systems) and more efficient (I should `mmap` the executable), but here's a [sketch](https://github.com/lnicola/self-modify) for it. Note that you'll have to compile it and run the executable from the `target` folder, otherwise `cargo build` will rebuild it each time.
Whereas in C++ the vtable pointer is stored inline in the struct itself. Rust uses a fat pointer for other reasons, but I wonder how much of an impact there is on performance, in the case where the method being called has to read the data in the struct anyway, and the second read would be in cache.
You ask the release team. The bar is quite high.
If I understand you correctly it should have a number of separate items for that: * `'a`- A lifetime parameter, duration of a flow in static analysis. * `S&lt;'a&gt;` - Signals `S` will contain address with lifetime `'a`. Creator of `S` decides `'a`. * `'b: 'a` - Lifetime `'b` must live at least as long as (i.e., outlive) `'a` bound. Do you mean there should be one entry that does the combined `&lt;'a, 'b: 'a&gt;`? I could probably add this, but I generally try to avoid entries that compound too much.
Might be a small slip-up, but I want to point this out: around 8:15 he says that Rust eliminates integer overflows, which is not true if your application is compiled in release mode. Hopefully they still take appropriate precautions since this can be a dangerous misunderstanding to rely on in this context.
It's in the title... üôÑ
Hopefully Google engineers are worth their money too. ü§ì
References to slices (like \`&amp;\[u8\]\`) implement \`Copy\`, since they're references. When you send one through a channel, it is moved, and since all \`Copy\` types are simply copied on move and the original is left untouched, that's what happens, which is why your existing slice ref is still usable.
But you could say the same for the other workflow ("it's not a big deal, just point it out when someone checks it in"). I'm not saying it's a terrible idea (I even used to do it myself), just that it feels slightly less messy to use the various ignore files for their intended purposes.
oh wow it is. I guess I didn't read after ChromeOs uses rust before clicking it
I find it confusing too but I think that the message behind it is "Delegate your .gitignore management"
Someone from the Rust team has to apply the `stable-nominated` to it (in the rustc repo), and then both the team responsible for that area of the codebase and the release team have to agree that PR can be included in a point release. As a member of the release team, that PR today has no chance of getting into a point release, since 1.35.0 will be released next week. We wouldn't have done this point release that close to another release either, but it was for a security vulnerability so we had to.
For people who criticize XML without using it first, I recommend try to open your mind and review JavaFX FXML, the now defunc Flash XML or hey how about that HTML? Whenever someone criticizes XML you need to understand that it is mostly toward the use of XML for RPC/IPC (called SOAP). Yes, for that usage, it is much verbose and nastier than JSON or binary format. For everything else: configuration, UI markup, etc... XML is more superior due to schema validation, comment support, raw string literal support and auto-completion from a decent IDE with a schema. Try to do all that with JSON.
&gt; Suppose I have two mutable references UB. Period. From the book: "No, you're not special." But more constructively, *why* would you need two `&amp;mut RefCell`? The whole point of `RefCell` is that that's unnecessary...
You can turn the overflow checks on in release mode as described [here](https://stackoverflow.com/questions/34054669/how-to-compile-and-run-an-optimized-rust-program-with-overflow-checking-enabled). I recommend this in any code that is not critically affected by integer performance: honestly, I think it should have been the default. This [article](http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/) has a nice discussion of overflow checks in Rust.
Why would it matter? I understand the complaint in general when the tool itself may need to be audited but there's no reason to ever audit `cargo vendor` because the results are trivially auditable themselves.
I've offered the rust team to help out with this on GitHub when it was marked as a critical issue but never heard back.
Thanks, I'll keep an eye on it.
I mean yeah, [Azul already does this](https://github.com/maps4print/azul/tree/d261233e7b2f002593f977b5784b8a0e38fcdf6e/examples/xml) to some extent, although for the purpose of hot-reloading, not for the final UI. Also very good [for testing](https://github.com/maps4print/azul/wiki/Unit-testing). Look like this: &lt;component name="Invoice" args="dueDate: String"&gt; &lt;p&gt;Your invoice is due at {dueDate}&lt;/p&gt; &lt;/component&gt; &lt;app&gt; &lt;Invoice dueDate="02.03.2019" /&gt; &lt;/app&gt; I don't like visual designers, I like to just have the application and my code side-by-side and rather have live-refreshing and a code editor than edit things via clicking. I can also be sure that my app looks exactly like I prototyped it (for example, in your video, the Visual Studio preview looks very different from what ends up in the app, I know it's just a theme but still). Paired with live refreshing, live coding can be easier than navigating menus and property editors. I also don't like XAML because it's so verbose and no visual XAML editors exist for Linux (I do like XML for UIs, but not the whole `xmlns` stuff, it's just ugly boilerplate). But I mean, to each his own.
You could, but then you‚Äôre linear in the number of contributors rather than the number of file types. And generally the number of file types is &lt; the number of contributors. Git‚Äôs an open source project, all of these various config files are scratching some contributor‚Äôs personal itch, not fulfilling some holy prophecy of the one true repository management scheme. So do what works for your project; in my experience, .gitignore is usually the most practical choice.
Yes, the idea is an own visual designer, but also the possibility to write the XML(XAML) yourself and see the result live. Then you can see the right themes. :) Using Visual Studio is only the first step. Later you can choose between Visual Studio or the new designer, which will offer more possibilities adapted to the framework.
Adding that I just found this: https://github.com/pest-parser - this looks like a great project and one I think I'm going to research and look into. Just wanted to link it here for anyone else.
*Linear in the number of developers who don't already exclude in their personal .gitignore, which could be minimal with promotion of this practice. Whatever you choose for any individual project you create, as a responsible dev you should certainly be doing this since there are projects where adding these files to the project .gitignore is disallowed. At that point, the "add to project . gitignore" version is linear in the number of projects you create + number of editors.
It's a start. Is there a way to keep the colors with less?
Rather than finding a balance, maybe we could make this more configurable? Have a flag to tell the compiler end after fewer error messages?
Today there are certainly more people who don‚Äôt follow this practice than do, and I anticipate that will continue to be true regardless of how many reddit posts beg otherwise. And while I‚Äôm sure they probably exist I‚Äôve never worked on a project that won‚Äôt let you update a .gitignore file. I admire your commitment to purity but from a practical perspective you‚Äôre prioritizing these things backwards.
Nobody `beta-nominated` it either ([pr59894](https://github.com/rust-lang/rust/pull/59894)), so currently this fix will only reach 1.36.0.
I am interested in your thoughts, especially if piet is missing stuff that you need. I think it will take a while for it to fully mature, but I believe the light at the end of the tunnel is industry-dominating performance and rendering quality.
[rust-lang/rust](https://github.com/rust-lang/rust) repository has been mentioned **28 times** on Reddit over the last 7 days. The last 3 mentions: |Mention|Source| |---|---| |[..] behavior. Rust now tells LLVM to trap unreachable, which at least contains the UB, so your &amp;quot;illegal instruction&amp;quot; comes from the ud2 instruction it generates there.See also: https://github.com/rust-lang/rust/issues/28728|[/r/rust](https://reddit.com/r/rust/comments/blv6fn/rustc_optimization_sadness/emrvvqj/ "/u/CUViper at 2019-05-07 21:20") | |These would seem to be related:https://github.com/rust-lang/rust/issues/59281https://github.com/rust-lang/rust/issues/57517|[/r/rust](https://reddit.com/r/rust/comments/blv6fn/rustc_optimization_sadness/emrwgho/ "/u/jianershi at 2019-05-07 21:26") | |You can always file an issue at https://github.com/rust-lang/rust/, they would really appreciate that :)|[/r/rust](https://reddit.com/r/rust/comments/blv6fn/rustc_optimization_sadness/emrwkj6/ "/u/tim_vermeulen at 2019-05-07 21:27") | ^([Report an issue](https://np.reddit.com/message/compose/?to=gajus0&amp;subject=GitSpo%20Reddit%20mentions%20bot&amp;message=Hello%20Gajus,)|View all [mentions of rust-lang/rust](https://gitspo.com/mentions/rust-lang/rust))
Yeah good point, copying the data would be most safe, and the least convoluted. Assuming it's not a performance issue, that's probably the best approach.
That is exactly what `gcc` does. It has a `-fmax-errors=n` command line flag to control how many errors are emitted before it gives up entirely. In this case you could set it to 1 to just see the first error.
By pure chance I found your project today when searching for a Glacier API. It seems to be very nice, but I was wondering if you will provide a Futures API? Right now everything seems to be sync / blocking.
Thank you, I'll definitely take a look. That's so true, the performance and rendering quality is very important.
It's worth mentioning that [AWS Firecracker](https://firecracker-microvm.github.io/) (used for implementing AWS Lambda) is a fork of crosvm. AIUI [rust-vmm](https://github.com/rust-vmm) is a project aimed at extracting the commonality in these. (Not involved with either project but I saw some talks about them last week.)
Yeah that's fair, that's honestly my biggest systemic personality flaw.
To clarify a bit,this is only for Rust-to-Rust ffi.
What it means is that the type can only borrow things with a \`'static\` lifetime (or not borrow anything).
Ok I see. Rust doesn't have this. Maybe some day!
https://chromium.googlesource.com/chromiumos/platform/crosvm/+/refs/heads/master/Cargo.toml#9 ``` [profile.release] panic = 'abort' overflow-checks = true ```
That's sweet. Glad the perf hit is not significant enough for them to turn it on all the time.
For future reference though you can deep link directly to that time code as that commenter did https://youtu.be/pRlh8LX4kQI?t=480
I don't think it matters that the designer is written in XAML as long as optionally you could convert it directly to code... (so you don't end up with an XML parser in your GUI). XAML provides a mostly good experience on .net though as far as I've used it at work.
Yeah. I'm planning to use Pest for some exploratory development in writing a parser for the syntax I habitually have used for my notes since high school. It also has a [website](https://pest.rs/) which is a nicer starting point. ...though I wish it wouldn't sell itself short by only showing a performance comparison against two other fast Rust parsing libraries and not against other popular options in other languages, like ANTLR, Parsec, and Happy. (Serde wouldn't be useful for DDL, since it's a serialization/deserialization framework, but [Nom](https://github.com/Geal/nom) would... it's just got poorer error messages, not yet having completed its plans to switch from macros-by-example to procedural macros.)
At the moment when starting the application the XAML is transformed into a tree with Structs. But this will change. I'm currently working on using a Entity Component System, to escape the "borrowing hell".
I'm working on a Windows GUI app to replace [CompactGUI](https://github.com/ImminentFate/CompactGUI), using [web-view](https://github.com/Boscop/web-view), and [winapi](https://github.com/retep998/winapi-rs). It's currently about half the size (1,700 lines of Rust, 300 lines of JS vs 4,000 lines of Visual Basic), but *much* faster and more responsive, and scalable to [much larger directories](https://i.imgur.com/8neYfzg.png). To give an idea of the savings, my `D:\Games` is about 1.5TB, and Compactor has shaved off 330GB. With 1.7 million files, it's using 266MB of memory, and I'm confident I can shave a good whack off that. Current focus is on persistence - saving settings, and a database of known-incompressible paths. Then it'll be on to tidying some of the nastier bits and giving the UI a style pass. Vaguely tempted to see about shoving it on Steam for a quid a pop. Been a while since anyone paid me to program something..
I don't understand why anyone would buy a Chromebook for development. They all appear to have this super slow 32GB-64GB eMMC storage. Most of the are running on like 4GB or RAM and a Celeron CPU as well. Maybe it's usable for someone, but I wouldn't want to develop on that laptop.
This won't address overflows in the stdlib though.
Thanks for your reply and the link to Nom! I'm essentially just trying to write a util for the command line, in rust (so that I may learn some more about the language and "consume"/use the language in my day-to-day as an ETL guy; my current method of learning more about this new-to-me language that I'm fast falling in love with is via [project-euler](http://projecteuler.net) and of course the book). In short: I'm spending some time *now* to be lazy later; [there's an xkcd for that.](https://xkcd.com/1205/) While I do have my main target DB as Netezza, I figured, "hey I do this step_x a lot when I'm asked to get data from MS SQL. I want to make it easier/lazier."
I've seen games in dosbox doing that when writing their config ('Hook' the adventure game if you're wondering) but that's probably a case of dosbox loading the executable on its own JIT and the file not being technically open. It's a terrible terrible thing, you shouldn't ever do obviously, but i suppose it can be 'helpful' on a platform without a filesystem.
that's right- but I'm still using/learning a DSL by MS... I _feel_ I'd do better to learn more about the internals of Electron or QT or something... That's my take.
Adding: Downstream from the Nom link you gave me is [nom-sql](https://github.com/ms705/nom-sql) which, at first glance, looks like a step in the right direction. Time to get reading. Thanks again!
Knowing Google, and Bazel. They likely recompile std themselves. Or at least it wouldn't surprise me.
iirc: cargo check --color=always 2&gt;&amp;1 | less -R
Yes, I understand that. But even though it's not strictly specified, you have to represent rust in a compiler independent format, don't you? I find that interesting, even if the lowest common denominator becomes the abi crate instead of the compiler.
error: no method named \`as\_bytes\` found for type \`ed25519::Signature Apparently this strategy just work for the pubkey
IMO we want a richness from variety of approaches and this is an approach that should be represented
I see the normal amount of colors in both links.
Agreed, but I wonder if being able to use if for things like development is a prerequisite before coming out with a higher end model. Who knows though.
This paves the way for fuchsia.
I was quite happy sshing to a desktop from a chromebook. :)
&gt;you have to represent rust in a compiler independent format, don't you? What I do is ensure that is ensure that types are `repr(C)` all the way down (with some caveats), and with a compatible: * kind of datatype(enum/struct/union). * type name. * package name. * package version. * layout for every field,recursively checking all the things in this list. * size. * alignment. * ammount of lifetime parameters. * lifetimes referenced by fields. * tag (a json-like datastructure associated with a type). This is very specifically designed with Rust in mind,even treating `#[repr(transparent)]` types as being different than their only non-zero-sized field,keeping Rust semantics at runtime as much as possible.
Do you have links to those talks? I've been interested in the rust vmm project since it was announced.
Yes, but I was more talking about actually developing on the Chromebook. :) They demo running VS Code on it and so on.
It might be the case. But I think it will be hard to get third party manufacturers to release high end chromebooks. The market is probably very small. And based on the cost of Google's Pixelbook laptops it won't be worth it.
Same. IMO chromebooks less powerful than a pixel are really only useful as a cheap, lightweight terminal to a more powerful server / desktop. You can't get the same kind of battery life on a dedicated development laptop. Though, with the lower end models, the sluggishness of having multiple tabs of google searches and docs open can make it a bit of a pain. And, always needing a decent internet connection to do any development can be restricting.
I don't really need two &amp;muts (especially since it's not allowed), I think I've figured out how to get by. I'm trying to come up with a safe-ish abstraction around global application state and window proc reentrancy on Windows. Window proc is a user callback that gets called for every event your window receives. All application logic is inside this callback. If you want to persist application state between events, you put it in user data associated with the window. But that's details, the state could be in mutable static for all that matter. At the beginning of your window proc you obtain a pointer to the application state. Window proc reads and sometimes modifies the state. Now the problem. There is only one thread, but window proc should be reentrant. Some WinAPI calls that you make in window proc can send messages to your window (that is, call window proc themselves). So uncontrollable access to the application state in window proc is memory unsafe. For example, you are iterating over a vector and make a call that ends up in another invocation of window proc reallocating this vector. This can be solved by wrapping application state in RefCell. If there are conflicting accesses the program will explicitly panic. But that's inconvenient because one still has to remember to release RefCell borrows before making potentially message-sending WinAPI calls. It would be nice to check for that statically. So I'm thinking of wrapping &amp;RefCell in a struct, let's call it Token. Token instance is created at the beginning of window proc (always from the same &amp;RefCell). WinAPI calls that are known to send messages should be wrapped in functions that take unused &amp;mut Token argument (the original idea was to simply require &amp;mut RefCell argument, but that would result in multiple &amp;muts coexisting). This will make it impossible to call them if you are holding RefCell borrow. Note that it's impossible to rely on static analysis alone and get rid of RefCell runtime checks, because I can't hope to correctly annotate all message-sending WinAPI functions. I don't even know if they are exhaustively documented anywhere. By any chance, is there better way?
To be fair, I _didn't_ ask for the bug in clippy I found to be fixed in a patch release, I just assumed it would come out on the next stable. It was half of the 1.34.1 release, however. So presumably just if _someone_ relatively high up thinks it's of importance to get out ASAP.
hex::encode doesn't work for the signature tho &amp;#x200B; error: the trait bound \`\[u8; 64\]: std::convert::AsRef&lt;\[u8\]&gt;\` is not satisfied label: the trait \`std::convert::AsRef&lt;\[u8\]&gt;\` is not implemented for \`\[u8; 64\]
This is my **first** Rust project for learning purposes. If you have any questions, please feel free to ask. &amp;#x200B; The logic of the work is quite simple: `nmap` command is running at given intervals and comparing with the previous result. If there is a change in status, sending notifications and adds them to a DB file. &amp;#x200B; **P.S:** I have written all the detailed information in the `README` file. &amp;#x200B; Moreover, I want to connect with the plugin for the [MagicMirror2](https://magicmirror.builders/) project. We will be able to see the network status changes from smart mirror. What do you think? Worth to effort?
Unfortunately they didn't get recorded, but they were [this](https://talks.cam.ac.uk/talk/index/119491) and [this](https://talks.cam.ac.uk/talk/index/121069).
Ah, okay. Thanks!
\*chuckle\* I know that feeling. At the moment, I'm working on a custom TODO list tool because the existing options have enough friction or unneeded complexity that it's demotivating when I'm tired and I've got a list of other similar "spend time now to be lazy later" projects on said TODO list.
For anyone else reading this thread, it is `beta-nominated` now so it should in fact hit 1.35.0 if I understand it correctly: https://github.com/rust-lang/rust/pull/59894#issuecomment-492397040
Assuming the compiler team accepts it, yes, we should be able to backport it in time.
True, although `std` receives quite a lot of scrutiny and the likelihood of an integer overflow bug there seems low. I assume someone has turned overflow checking on and run the `std` tests once in a while‚Ä¶
Hmmmm interesting. Now that I‚Äôm on mobile I do as well. But I can‚Äôt find any setting that would cause this on my end. ü§îü§î
Actually, it seems like that was a red herring, and [a version without lifetimes works just as well](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=12da98a203bb01ead017dfb6d28d0f7d). I think the secret is not using `'a` since that's the lifetime of the mutable borrow of the wrapped Vec. By using a different lifetime, or just using the implicit one, it can choose to use a shorter lifetime when calling `iter.next()`, leaving `iter` free to be mutably borrowed on the next iteration.
Thanks. I‚Äôll look into the different ways I could change the syntax. Maybe `‚Äîlist` and add search functionality. We‚Äôll see!
&gt; I just assumed if you can't modify a running executable you wouldn't be able to remove one either! You can because removing a file on Linux (or any `unix`) is really an `unlink`, where the underlying space will only be reclaimed when all links are gone. The running process will keep the old data alive in its own memory mapping, while your new file takes its place at that filesystem path. IIRC Windows does not play such games...
People were also used to feet and pounds before the world introduced the metric system. Change can happen, but it is some work
Oh ok thanks, was just curious as I don't really actively follow Rust updates
Good plan! Have you checked out taskwarrior? It‚Äôs not rust but I like it. Been using it years. However it has some things I think could be better and I might use it as a springboard to write my own todo cli app in rust. I‚Äôve contributed some to the project though so I have a soft spot for it in my heart. :)
There was a overflow bug on java binary search for [about two decades.](https://thebittheories.com/the-curious-case-of-binary-search-the-famous-bug-that-remained-undetected-for-20-years-973e89fc212)
[The official book](https://doc.rust-lang.org/book/) is a good place to start.
The thing which might be getting in the way is your attitude. And to some people who been working in the industry for past few years at least, lack of experience really shows with projected imaginations of how things should be you put forth. I'm not sure if this comes out in the interviews or communications, but if it does, when you leave out an impression of very annoying type of beginner/junior who probably gonna be resistant to learning anything. \&gt; Bank employees just sort of want the technology to be braindead, simple, and obvious, and people there just want the technology to do the thing that they want it to do when they click the button. I think this highlights it in particular. Provided it showed up in somewhat generally condescending context. It appears that instead of thinking that there is a reason for it, you write it off as something stupid. It's to late to go deep into this one, even if I could. But .. there are a lot of competing theories and practices. Which all promise to solve something or be better than x. This is common in any hard to test / put in practice domains. And the more difficult it is to put in practice the more theories and priests of high knowledge surround it. This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work. And people already have tried it numerous times. Now that doesn't mean it's useless in all possible use-cases. But being fixated on being dogmatically correct over being effective is generally not a good quality of a software developer. &amp;#x200B; You will realize this sooner or later. But the sooner you do so, the better off your chances will be on the long run. And even if you end up in R n D department of some sort, realizing that your mission is to provide value to others first will get you there faster.
When should I be using panic like operations, versus returning a Result? I come from Scala and Haskell. I trained myself out of ever ever throwing an exception, because I wanted to capture this stuff in the type system. But I see a lot of unwraps and expects in Rust code. What is the consensus?
You can think of `'static` as meaning that the value *could* live for as long as the entire program. The reason for `'static` on `Any` is because `Any` can't handle lifetimes properly, so it requires `'static` so that there is only 1 type of reference (that with `'static` lifetime). The only things with `'static` lifetime are string and slice literals, values with no references in them, references to `static` values. One easy way to check if it has `'static` lifetime is by sticking it in a `static`. (note that if you can't put it in a `static` does not mean that it doesn't have `'static` lifetime because it may just not be `const`-constructible) all of these things have static lifetime static FOO: i32 = 0; static BAR: &amp;i32 = &amp;FOO; static BUK: &amp;i32 = &amp;0; static QOK: &amp;[i32; 1]= &amp;[0]; static WAQ: &amp;str= "hello"; static OOP: &amp;[u8] = b"hello";
Well, the 1.34.1 point release was a bit unique: we needed to test a few things in the release process and we didn't want to do that on a full release, so we asked other teams if there was some vaguely important stuff that could safely be backported to stable. To be fair we should have clarified that in the blog post but hey, it's in the past now. Y'all shouldn't expect other point releases as lightweight as 1.34.1 unless there are other changes in the release process we need to test.
Even with code coverage, fuzzers, and extensive focused testing there are likely lots of bugs left in `std`. There's no real way to get rid of them short of proving `std` correct, which would be a Sisyphean task. There's no formal specification for Rust (working on it) or the library, so it's not entirely clear what a proof would look like. My (perhaps mistaken) belief is that `std` is well enough tested that integer overflow bugs aren't dramatically more likely than other kinds. That said, I hope somebody has run what `std` tests and fuzzing we do have with the overflow checks turned on.
Not talking about 'static value lifetimes, those are pretty self-explanatory, but 'static type parameter lifetimes remove 'static from Self definition and compiler would complain about: `the parameter type \`Self\` may not live long enough` How can type parameter live not long enough? Calling `from_value` on any non-static value still works.
What if you passed a `&amp;'a i32` to it, `&amp;'a i32: 'static` does not hold in general
That definitely makes sense. I was wondering why such (relatively) small issues made a point release necessary.
[https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9f18350b02bfbae83e701aaa1bdb0e77](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9f18350b02bfbae83e701aaa1bdb0e77) &amp;#x200B; `value` is by no means 'static, yet you can pass it safely
`value` *is* `'static`. It could live for the entire life of the program. `'static` does **not** mean that a value *will* live for the entire life of the program, only that it *can*.
Yeah, I've been using this for some time now. Especially the cheat sheet for containers is amazing. Thanks
I have a same-length `vec` of `bool`s that I want to compare to a slice of `&amp;bool`s. I thought that some deref magic might make this work, but I haven't found any combination of `*`, `&amp;`, or `&amp;*` to make the compiler happy. Is creating an iterator, mapping, and recollecting into references the *right* way to do this? I'll be using it in a loop (yes, I'm still working on Advent of Code) so performance may be relevant. fn main() { dbg!(vec![true, false, true] == &amp;[&amp;true, &amp;false, &amp;true]); } [Playground Link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1dd37eeabbe90aeaa20f7c75fdc08268)
See this thread: [https://www.reddit.com/r/rust/comments/7mif9i/how\_to\_compile\_binaries\_without\_dependencies\_on/](https://www.reddit.com/r/rust/comments/7mif9i/how_to_compile_binaries_without_dependencies_on/)
I personally come from C# and am currently working more and more with F#. F# has algebraic datatypes, let, match etc. but it also has a more StandardML or OCAML style syntax. So white space is important and ; and {} are pretty rare. Does rust offer a way of providing an alternative syntax for rust? How would you think one could start with creating an alternative Syntax. I dont want this to replace the already established syntax. I just want to create a more comfortable way for people coming from F#, StandardML and OCAML to use rust while still keeping it clean and not as cluttered. In the end I guess I would have to whip up a transpiler from rsml to rs...
Some functions are marked with `#[rustc_inherit_overflow_checks]` to respect the user's choice.
Any word on when others can see and play with this? I recognize you want to avoid putting it out before a minimal viable product is available -and you are still experimenting- but let me say: you are causing some excitement here. This could end up producing a viable UI framework for at least simple cases. Sure, we all want a professional internationalization ready UI framework with robust support. But not being able to knock out even simple UI's without digging deep on documents which have only roughly been translated for rust...that sucks. This looks awesome, and the fact you have it cross platform working already screams that it's awesome.
[Rust in Action](https://www.manning.com/books/rust-in-action) is really excellent. It's not free though (or 100% finished yet but not much missing). I followed it from pretty early on and I find it really well written. I would particularly mention the very exciting code examples used which made it fun to read.
I'd probably use `Iterator::eq`. However, I'm struggling to think of a scenario I'd end up with `&amp;[&amp;bool]`. Where's it coming from?
Sorry to get back to you so late. Here is what I'm trying to say: &amp;#x200B; Yes, you have a case for `'b: 'a`; but this case is under the **Generics &amp; Constraints** section. &amp;#x200B; Now, this makes sense: it is a constraint on a lifetime. However, as a first-time user of your web page, the first place that I chose to look for `'b: 'a` was in the **A Guide to Reading Lifetimes** section. &amp;#x200B; I think that it would be worthwhile to put `'b: 'a` in that section, in addition to where it already exists. &amp;#x200B; If I were brand new to Rust, using your cheat sheet, I imagine this is how my thought process would go: * (*looking at code* `'b: 'a`), "What the heck is that? Let me look at the cheat sheet." * "This must be under the reading lifetimes section..." * "Damn, I don't see it." * "Let me do a Ctr-F to try and find it." * "Oh, there it is." &amp;#x200B; I just thin it would be less confusing to list it in both sections for people like me who would gravitate to the fact that it deals with lifetimes before the fact that it is also a constraint.
It's actually one of the things I want to replace. I found that... 1. It seems to be inherent that it performs too poorly when you want to stick a PyQt GUI on top of it to interface it with things like libnotify notifications, tray icon popups, and other nice stuff like that. (I tried both of the Python API wrappers I found, neither performed acceptably, and I think a large part of that is simply the overhead of having to launch the process anew each time I perform an action.) 2. I can never remember how to manipulate the recurrence rules properly and I just generally find myself slipping into an "It works. Don't touch it." mindset while working with the recurring tasks I've already got in it. Both of those stopped my interest in it before I determined whether it supports things like recurring tasks which don't stack up and, instead, recur based on the interval since the time you marked the previous recurrence done. I also want the ability to manually trigger "start of a new day" recurrences early because I'm trying to fix a messed-up sleep cycle and that means that starting each day earlier is an indicator of *success*.
I just tried `.eq` and it gave me the same error. Maybe I did something wrong? The `&amp;[&amp;bool]` is coming from a `VecDeque&lt;bool&gt;.iter().collect::&lt;Vec&lt;_&gt;&gt;().windows(5)` (obviously different length than my example code). The `VecDeque` will be reused, so I don't want to `.intoiter()`.
Ideally, panics should only be used for quick prototyping (later removed) and something that is never expected to happen. There's a grey area around things that are reasonable to expect but you can't recover from and you'll want to exit the program when they happen. On one hand, panics work pretty well for that, since you just want to exit. However, they aren't very user friendly, and it can be better to propagate an Err up through your call stack.
The zeo disappears, because you reserve space for 16 hex chars only, but u require 64 hex chars. Please also verify if sha256 has can really be stored in an u64 integer!
Sounds very interesting. Would love to contribute if/when you open source it
If I'm understanding correctly, the issue is that the barcode scanner itself sometimes interjects newlines in codes? I have an idea, but only if you expect each barcode to be the same number of digits. You can get an iterator over the characters of stdin, filter out non-digits, and then group every X digits.
At a glance: Format pads to 16, whereas this outputs a string of length 63
Thanks, I'm confused on how to fix it tho.
Yes, apparently it can (it's 256 bytes) U64;4 Thanks, I'm confused on how to fix it tho.
Ah, since `bool` is `Copy`, you can just use `cloned` to adapt the iterator with no performance cost: VecDeque&lt;bool&gt;.iter().cloned().collect::&lt;Vec&lt;_&gt;&gt;().windows(5) `.cloned()` is identical to `.map(|x| x.clone())`, or in this case `.map(|x| *x)`.
Thanks for the reply. Yes the scanner is supposed to end the barcode with a newline but for some reason there is a newline before the end and then the scan doesn't get all the numbers because read_line() takes input until it sees a newline. I don't have a problem getting rid of the newlines in the code. What I am trying to find is what to set EOF to if I want to make sure I get all the barcode before going to the next loop. I hope that makes since. I have only tried one scanner so I'm not sure if this is a problem with my scanner or all are like this.
&gt;return format!("{:016x}", ByteBuf(self.as\_ref())); should become return format!("{:064x}", ByteBuf(self.as\_ref()));
From the look of it it uses quick-xml which can read HTML instead of XML if necessary thus it shouldn't be too hard to adapt it if needed.
/u/frehberg's answer is :+1:
I'd be kinda surprised but idk
I think you're either looking for r/playrust or r/rustservers (not sure which)
Oh, neat. I didn't know that.
All great points! There could be some ‚Äúfreshness‚Äù to the customization of the toolset. I‚Äôve found that recurring is definitely one of those ‚Äúset and ... forget right away how to do it.‚Äù It‚Äôs also definitely *only* a command line app. I think you have a good use case for a solid rust written toolset for tasks. :)
You'll love rust. You may not find a perfect job just yet. Things are moving pretty fast. Good luck!
Hmm. Can you elaborate?
That works, thanks!
I would be *Thrilled* for this to come to fruition. I have spent a significant amount of time working on WPF applications over the last 6 years, to have a rust backend that could be cross compiled would be a dream come true!
GTK's implementation in C is not great, but PyGTK seems to do well on safety, so I think Rust also can use GTK safely.
Thanks! The container cheat sheet is made by /u/raphlinus though, I'm just linking to it :)
There are a lot of tricks to create nice, abstract, reusable, styles. However, in my experience, it can be pretty verbose at times, I don't have a ton of experience with other UI frameworks, but I would be interested in seeing one which offers the same flexibility with less verbosity. However, if you ever get into a position where you need to override a default style/template to make it do something a little different (menu's and menu items are notorious for this), you do occasionally have to copy in a hundred line default template from microsoft just to make some small changes to it. That is mostly to do with microsoft not creating them to be flexible enough in the first place though.
This is fantastic. Thanks for your work.
Nope, don't change anything. It's fine as it is.
I wonder what happened to the ML model those guys built to classify posts as /r/rust or /r/PlayRust.
\&gt;Why would it matter? &amp;#x200B; It's a good question. Rust is being developed by Mozilla. This gives it credibility. Let's take the following scenario: An enthusiastic developer wants to use Rust in their enterprise environment. They make their pitch, and a low level boss gives it the go ahead. The main reason for the go ahead, is not any technical reason, but that it's developed by Mozilla, a respected member of the IT community. ie it's a safe bet that wont get him fired. The same mentality that spawned the saying "No one got fired for buying big blue (IBM)" 2 years later the auditors find out about the project, which has grown to be a part of the business. He asks to see the source code of the dependencies and the dependencies dependencies, which are now very numerous. Of course the default does not do this so you are now talking about a project to find and download the code to do due diligence. Dependency hell. The middle tier bosses are not happy that they have to apply for another cost code for this unforeseen project. After all money is tight, it always is. The question is asked at the highest level, between golf swings, "What is this Rust? and why are we using it anyway?" Now here is the exciting bit. The auditor asks "is it possible for rust/cargo to download the source of the dependencies"? Obviously they will roll the change out to all Rust users, a simple change to a config file. There should be no problem getting authorization, after all these changes happens all the time. If the answer is yes, then the matter is dropped. Everyone is happy. Everyone will just think the original developer was incompetent for not making the change at the start. If the answer is no, but you can do it if we download the following software from a guy called Repi who has a picture of a frog on a human body on his bio. The answer is going to be no. His recommendation may be "Remove Rust and never let it darken my door again". After all the auditor is probably not a Rust convert. Why should he stick his neck out?
\&gt;because it‚Äôs so easy to just install it Grin. I once had to wait six months to install an insignificant piece of software on my work system and the paper work was a nightmare. I appreciate that in your world it's easy. But in every enterprise environment I have worked in things are locked down.
Sure. That‚Äôs a great reason to finally include it! Rust hasn‚Äôt historically had a lot of those kinds of enterprises interested in using it, and so that‚Äôs why there wasn‚Äôt pressure. That‚Äôs changing :)
&gt;I don't understand your complaint. I am not complaining. Rust is an excellent piece of software. &gt;If cargo vendor can do what you need, what is the issue? credibility. &gt;It's a Rust pattern in general that if something doesn't absolutely need to be a part of the core language or tooling, then it should be delivered as a separate package. And I love the idea. Low bloat.
&gt;That‚Äôs changing :) I hope it does. Rust is an awesome concept. Which I hope takes off.
Thanks, I will give that a shot. If this were something more expensive to clone (that still was `PartialEq`), is there an idiomatic alternative that comes to mind? Perhaps zipping the two and comparing item to item (with an extra deref on one of them)?
Unfortunately, since there are no suitable Qt bindings for Rust yet, it'll probably stay stuck at the "prototype in Python" stage for the near future. I came to Rust for the stronger compile-time guarantees and a hybrid Rust-C++ project is less appealing to me than a pure Python project.
In practice, writable binaries are a huge security risk because an attacker can hypothetically replace a "known safe" binary with malicious code.
I think you have an opportunity for a solid backend in rust and with a ‚Äúclean‚Äù API layer you can front end in your most nimble and favorite ways. Heck, with a good library / backend you can also write something with rust + clap for a quick command line front end that uses the same backend as the Qt side you write. Anyway that‚Äôs just rambles. I too hope to see some front end progress with this language. :)
Gee, maybe there should be a panic-on-overflow multilib config distributed for `libstd` (like presumably for most targets we build it both with and without PIC, e.g.). And that way you could opt in without having to rebuild it yourself.
Zipping them won't check for if the iterators are the same length, which `Iterator::eq` does. The reason `eq` didn't work for you when you tried it is because the left iterator is `&amp;bool` and the right is `&amp;&amp;bool`. You could just run `.cloned()` on the right iterator to remove a level of reference for free, regardless of whether the type is copyable.
Whoa, really? I hadn't realized that `.cloned()` on `Vec&lt;&amp;&amp;foo&gt;` gave you `&amp;foo` as opposed to removing both levels of referencing, which totally makes sense now that I think about it. Thanks!
Why not a Rust-based scripting language?
Certainly. The issue is that, to make it worth *my* time, I have to do the RAD prototyping in Python and, once I've got it implemented, I have much more pressing needs than rewriting the backend in Rust. Hence "once I've cleared out more of my TODO stack and the design has stabilized enough, I might split out the backend and rewrite it in Rust."
I enjoyed meeting Carol and discussing Rust innards at the conference. I'm glad she made it out. The Zig shout out at the end of her talk was incredibly classy - setting the bar for "sportsmanship" if you will. I definitely think I could have done better in my talk to show the same kind of respect.
So Rust has a High Level Representation (HIR) and a Mid-Level Representation (MIR) both of which you could target. I don't think there are any stability guarantees, so it could be a moving target. You can read more about it here: https://blog.rust-lang.org/2016/04/19/MIR.html If it's just surface syntax you're wanting to change, I would target HIR.
In that version yes but with my version I am using persistent files to store the location of the Go compiler and other tools for Go natively. But for test in Rust can I run the test in main function? I am trying to replicate a [version of this](https://github.com/squidfarts/cproject.git) example.
You can't be more safe than what you build on top of...
Just letting you know, I've now published this feature in 0.2.3.
This is completely false. Rust standard library is built on top of less safe libc.
It isn't false at all... safety must be implemented at all levels for maximum effect... and often exploits have been in the c library.... etc... Making the application code safer mitigates some attacks on lower level libraries but not all. Also there is rusl libc which is implementing libc in rust... partly for this very reason.
All the terminology seems like it was in C to me... The examples of what they were translating were C functions and the gccjit calls were referring to lvalues vs rvalues which are C concepts.
Rust does not eliminate integer overflows, but at least it defines their behavior. Signed integer overflow in C++ is undefined behavior with all the associated nasty effects (UB is more likely to lead to memory unsafety than defined overflow).
&gt; **blazing fast** speeds Is there any particular reason printing out a gitignore template would be slow? :)
&gt;They all appear to have this super slow 32GB-64GB eMMC storage s/all/most [https://store.google.com/us/product/google\_pixelbook\_specs](https://store.google.com/us/product/google_pixelbook_specs) &amp;#x200B; Apparently the Pixelbook offers up to an i7, 16 GB RAM, and a 512 GB NVMe SSD.
I'm currently building https://github.com/ethanhs/abserde a tool to generate fast, strongly typed JSON parsers from Python type stubs. It's still mostly an experiment, but it should basically be usable.
AppArmor