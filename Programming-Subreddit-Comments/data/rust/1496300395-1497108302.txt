I personally register domains with [EUnet](https://www.eunethosting.com/en) and then use Digital Ocean for hosting. The .rs domain currently is 18.69 EUR (21 USD).
That's true, so I had tried removing `clone` from `impl&lt;T&gt; PtrMarker&lt;T&gt; for BoxMarker` and it failed to compile (including many variations of it). So it doesn't really matter where that bound is specified.
&gt; The IRC guys told me to wait for this video. I tried posting my example, but got stuck with [this](http://play.integer32.com/?gist=9fa93907f022dee9a9d95f418a6c5283&amp;version=stable) and couldn't figure out what's going on. I took a stab at your problem and I think I managed to achieve what you were trying to do. [Try it out!](http://play.integer32.com/?gist=ed526d5973f4b03c6c06b81bd1d68e25&amp;version=stable) Mapping the parsed slices to the struct members can be done with macros like nom::map_res or similar I believe. I simply did it directly because why the hell not. If you want to return a struct in `do_parse!`, you'll have to wrap the return expression in `()` or else nom gets confused syntactically. It's just macros after all. I'm no nom pro either. **Edit**: See /u/geaal's [answer](https://www.reddit.com/r/rust/comments/6efmov/rust_toronto_meetup_introduction_to_parsing_using/dib63xx/) below. He posted a better solution that leverages Nom's syntax more.
you can easily parse this with nom and get a reference to the data slice instead of copying it: #[macro_use] extern crate nom; use nom::{IResult, be_u32}; struct Packet&lt;'a&gt; { header: u32, data: &amp;'a [u8], } fn packet_parser&lt;'a&gt;(input: &amp;[u8]) -&gt; IResult&lt;&amp;[u8], Packet&lt;'a&gt;&gt; { do_parse!(input, // assuming you want to parse those as big endian numbers header: be_u32 &gt;&gt; length: be_u32 &gt;&gt; data: take!(length) &gt;&gt; (Packet { header: header, data: data }) } 
What's with the writing to /dev/random?
I just stumbled upon [one of the threads](https://internals.rust-lang.org/t/borrow-visualizer-for-the-rust-language-service/4187) about visualizing borrows again in case it's helpful or interesting to you.
Another great article, thank you very much for your work :) I was planning to create a small alarm clock and the board employed there seems to suit well with my purpose: since I need to communicate via i2c or serial bus to peripherals (such as RTC and 7-segments display), is any of you aware of a library to manage bus communication in Rust? 
Oh yeah I didn't realize it was just one parameter, I thought we were talking generally.
Thanks, I will certainly give it a look ;)
It also creates /dev/random if it doesn't already exist. o_O
What do you mean? It doesn't matter if it's a protocol bug or not, every client still has to follow the same buggy rules. If you make a client that "fixes" a protocol bug in the consensus rules, you shut yourself out of the network.
That crate binds to libbitcoinconsensus used by the bitcoin core reference implementation (I think?), so any Rust implementation of Bitcoin using this will use the same consensus rules. The alternative is re-implementing that part, but doing it correctly is next to impossible, as you have to be bug-for-bug compatible.
UPDATE: This is apparently impossible. See the [stackoverflow answer](https://stackoverflow.com/questions/44303258/accessing-event-loop-via-mutex/44304227?noredirect=1#comment-75614778) by [E_net4](https://stackoverflow.com/users/1233251/e-net4) &gt; I don't understand what you mean with that. The only safe way to call &amp;mut self methods concurrently is with synchronization mechanisms such as Mutex So I HAVE to use a mutex for the entirety of that event. So the solution would be to see if discord-rs can be updated to not take a mutable reference. Well, it's probably possible in some way using channels, [like /u/eddy_afk said](https://www.reddit.com/r/rust/comments/6e6nwu/accessing_event_loop_via_mutex/di83thq/). Except that would be hard to deal with return values.
Consensus bug means that your implementation of the consensus rules is not the same as everyone else's. Bug here means being incompatible.
Are we reading the same thing? How does a crate which does bindings avoid consensus bugs?
It allows you to use the bindings to the widely used consensus rules in Rust Bitcoin implementations instead of reimplementing the consensus rules in Rust, which is bound to be incompatible.
I think /u/wummm explained it pretty well above, but I'll try to summarise: * Bitcoin Core has a function for verifying that a transaction correctly spends the output of a previous transaction (i.e. it is entitled to spend the funds, based on the key the transaction is signed with and the script of the earlier transaction that produced the output the transaction is spending). * All nodes agreeing on the output of that function is called "consensus". * If any node has an incompatibility in the output of that function for some input (even if it implemented the same specification, subtle incompatibilities are likely to exist due to the complexity of the transaction scripts), that is referred to as a "consensus failure" (I called it "consensus bug", possibly a bad choice of words). * A transaction that was accepted by some nodes and not by others would cause a partition (fork) in the network. * Nothing about the fact that this crate is written in Rust prevents consensus bugs. The bugs are prevented by the fact that it is a way to make sure you use _exactly the same implementation_ of consensus rules as Bitcoin Core when writing Rust code that interacts with the Bitcoin blockchain, rather than writing a "hopefully compatible but probably subtly not" implementation of the consensus rules. I hope that made sense!
Why does the following compile? let mut a = vec![1,2]; let b = a.push(3); println!("{:?}", b); println!("{:?}", a); I would expect that when a new element is added to a and assigned to b, then a has moved and it should not allow the second println. 
:D :D :D
Yeah. I frequently have to deal with more obscure and complex scripts (with crazy ligatures and diacritics, mixing RTL and LTR, etc.), and I've found XeTeX to be more reliable for my specific needs, though, admittedly, I've not spent much time with LuaTeX.
[removed]
Supposedly `/dev/random` is a bit more reliable because some systems (e.g. Linux) ignore all writes to `/dev/null`. https://stackoverflow.com/a/4611930
oh that would be really nice! 
I don't really get why there's a trait called `Trait`
&gt; Of course this can be prevented by carefully reviewing your code and all your dependencies to make sure that they don't use anything from std::io. But some compiler help would probably be welcome here. I think a great starting point would be "recipes" in some semi-official documentation for using existing profiling tools to track down this sort of problem. I'd make more specific suggestions, e.g. about what tools would be useful here, but I'm afraid I have very little experience in the area. In fact, I'd be one of the first happy customers of this sort of documentation! My hypothesis is that if you start by showing people _a_ way to do something like this, then some people will use it, and then some of those people will slowly build the tools to make a _better_ way to do it that might be accessible to many more people.
Actually, handling escaping is just as simple. Simply add an ESCAPE bit flag, toggle the flag when the escape character is detected, and don't perform a match for the next character's value when escaping is enabled.
&gt; Is there a reason I should not want this? I tend to view optional/default parameters as a code smell. While they require less code at the call site, I'd argue they also make it less clear what's going on at the call site and inhibit local reasoning, while also adding a trivial but non-zero implementation cost. For example, look at a fresh code base, or one you haven't seen in a while. Find a method call. How do you know if you're passing only required values? Did you choose to override only some of the defaults? You have to look at the definition to understand all the implications and, in the worst case, judge based on other call sites. I value clarity in my code and less code does not always mean clearer code. Sometimes I touch of explicitness and verbosity helps. To that end I think a separate, well-named method that provides default values is _usually_ more useful than a default/optional parameter. In this case you could have `process_datetime`, with one parameter, and `process_now`, with no parameters. In more complex cases I think it's clearer to make thinks _easily defaultable_ rather than default/optional. Then you can use things like `DateTime::now()` or `DateTime::default()` at call sites and see precisely what's happening. If there are many parameters then a simple struct can be used to allow something like `Params { foo: bar, baz: qux, ..Default::() }`. which again keeps implementations clean and call sites clearer by having information available at the point where it's most relevant, in this example the information being what is and isn't defaulted. One man's clarity is another man's noise, so try to find a good balance.
A Vec would require copying, which OP wants to avoid.
This excites me! JSON API is great. I don't know anything about Iron, but will this (with moderate ease) work with Rocket?
I know you wanted it in Firefox, but you could see what WebRender renders in Servo: https://download.servo.org/
I tried Tokio a while ago when I was perhaps a bit too new to Rust. I found it very hard to learn. There are way too many concepts to understand and I'm not sure if it is worth it. My working code using tokio-curl turned out to be ugly as hell (closures within closures), whereas simply using the curl crate came out quite nice. I'm avoiding that whole futures/tokio stuff because I find that closure heavy code way too hard to integrate with the rest of my logic (and the compiler errors are horrible). mio however is great and I use it all over. Without await Rust will continue to have a sub-par server story. I absolutely adore Rust. But given the task of writing something sitting behind a http server, I will continue to use Erlang for the foreseeable future.
Tokio is very cumbersome - terrible error messages, unintuitive program flow. Async/await or even better efficient coroutines would help the rust on the server story for me a ton! 1st class gRPC support would help rolling it out fine grained for my use cases.
- [Repo](https://github.com/cargonauts-rs/cargonauts) - [Book](https://cargonauts-rs.github.io/cargonauts/) (very incomplete) - [Api docs](https://cargonauts-rs.github.io/cargonauts/api/cargonauts/) (also incomplete)
Examples are probably important! [Here's an app in a single file](https://github.com/cargonauts-rs/cargonauts/blob/master/examples/echo.rs). I don't recommend writing an app in a single file of course, and the cargonauts CLI will structure your app in a way that IMO is good, but this lets you see all the parts in one place. [Here's a simple server side rendered app](https://github.com/cargonauts-rs/cargonauts/tree/master/demo/colors). It just generates a random color square, but shows handlebars working. [Here's an ember app.](https://github.com/cargonauts-rs/cargonauts/tree/master/demo/todomvc) It interacts with redis and builds the ember app as a part of the build.rs pipeline, so you get a single binary in the outcome. TBH I'm still learning how to explain cargonauts (docs are really hard!), so probably if this announcement is bafflingly vague you should just ask questions and I can answer them.
Hmm, you're not the first one to recommend it to me :) Hm, I see Rust like a more modern and popular OCaml maybe? WDYT?
Great post, thanks for sharing!
Right.
No. Rust is meant to scale down to embedded systems which may be too memory constrained to even allocate a buffer. Also there are instances where you want direct IO, e.g. when you do a single write from your own buffer. I do agree that this default will surprise people new to the language but we cannot invert the default without giving up performance or control for unbuffered IO, which is not an acceptable tradeoff for a systems language.
Is there an article or can you elaborate on the mistakes go made? We're starting a go project at work and want to know as much as possible to avoid mistakes. If it's dramatic enough maybe not even use go.
This will probably be supported in the future, but it will require a new `IndexSet` trait or something similar: https://github.com/rust-lang/rfcs/issues/997
Well, I'm confused.. [std::io::stdout](https://doc.rust-lang.org/std/io/fn.stdout.html) says "Each handle returned is a reference to a shared global buffer whose access is synchronized via a mutex." - this gives an impression that stdout is buffered. What does calling `.flush()` on stdout does, if not flushing its buffer?
I like to do this: struct Packet&lt;'a&gt; { data: &amp;'a [u8] } impl &lt;'a&gt; Packet&lt;'a&gt; { fn get_data_length(&amp;self) -&gt; u32 { // get data length using byteorder lib } fn get_data(&amp;self) -&gt; &amp;'a [u8] { self.data[8..self.get_data_length() as usize] } } Then you just wrap your incoming data in a Packet, and off you go.
It looks like it, and one example app uses `conservative_impl_trait`.
Ah cool, makes me think of a Lightroom-esc sort of thing where you organise your photo collections in disk based on some file meta. Restructuring a directory based on some file meta is a neat example.
It's a different buffer. You can think of the buffer being flushed as the OS-level buffer. You will notice that this buffer automatically flushes when it reads the `\n` character. Buffering your writes to stdout ensures that this does not happen.
What other language than Go would you consider building it in? I think GP meant that some API's in the stdlib are badly designed, which means that often times you still have to use third party dependencies to make things work well. You can't just generally claim that Go would be unfit for starting new projects, it is obviously hugely successful and effective. If you're starting a new project on a new tech stack, and just one comment on reddit can make you doubt your decision, maybe you haven't done enough research.. Also, if the decision of the implementation language is so important, it also feels to me it's a little too big of a project to implement in Go. Though I'm aware some people claim you can do large projects in Go, I'm not entirely convinced. If it's a big project, why not pick a language that was designed to build large projects in?
I haven't really taken a look at Rocket, and I'm not sure what exactly it would entail to add support for it. I've done my best to keep the iron-specific stuff relatively compartmentalised within Rustiful, and in case it's possible to support Rocket it will still likely take a bit of work to implement. Looking into the feasibility of Rocket is definitely on the roadmap though! 
I appreciate that we're all passionate about Rust, but...what exactly makes Go a bad fit for large projects? My experience says otherwise, and there are plenty of large Go code bases out there as well.
Oh I wouldn't recommend Rust. I don't think you should use Rust unless you either need it or you're really good at it already. When I'm thinking languages that are designed for building larger projects I'm thinking C# or Java or Ruby, maybe Haskell if you're living in the future. You can build really big projects in C also, and they exist too. That doesn't mean it's a particularly good idea to use C. That's how I view Go, maybe not as bad as C for large projects, but certainly not as good as some other languages.
You often can't use `std` on embedded system, so no `std::io` for you. If you want IO, you need e.g. `genio` crate.
An idea: the first time `cargo build` or `cargo run` runs display this message: &gt; Note: Unoptimized (debug) build. This will be slow. Run with --release to enable more optimizations. So newcomers will immediately know it and it wouldn't be too annoying.
It does say `[unoptimized + debuginfo]` right in front of us for `cargo check`, `cargo build`, `cargo run` and others. I think that's a pretty good indicator already. 
Agreed. Still, my other point stands – we sometimes have a custom buffer, which would be duplicate if we had to use the `std` one by default.
&gt; If it's dramatic enough maybe not even use go. * The standard log interface and errors leave a lot to be desired. You'll likely want to use *I think its Davey Cheney* Error handling library. * There aren't many good kafka libraries you'll be handling partition management, partition balancing, and broker re-connection yourself. These are two of our *large* pain points kind of things we *assumed* would work but ended up requiring a lot more time then expected. Also heavy concurrency is a slight myth. You can *ab*use it and it *may* bite you. --- I'm just a random internet. Honestly Go is a fine language for a project. You'll type a lot of boiler plate, but you will get the job done. 
Probably not since the performance of file operations will be I/O bound anyway. However Rust can be useful for applications where low latency (i.e. no GC pauses), efficient memory utilization or maximum CPU performance is crucial. For these types of applications Java, C# and JavaScript are not as well suited.
Great post! The fact that IO isn't buffered surprised me at first, but once I realized that every call to `read`/`write` was a system call, it felt like the right thing for Rust to be doing. After all, why would Rust presume I want to use a `BufRead`?
This is better design. I thought the new content will overwrite existing line if it is shorter than the buffer.
Oh hmm. So like since node is single threaded any CPU intensive task could block the event loop. So maybe handing the operation off to rust would be an option?
Ok, so I think I'm finally able to ask this. And this one goes directly to /u/llogiq I created a Rust (**LANGUAGE**) Discord server a while ago. I've been maintaining it for a while, and there's quite a few users there already (currently at 357). I think that the main advantages of it is that it's very easy to use, especially for people that aren't used to IRC, and that there's voice channels, so you can voice chat with other rustaceans. I was wondering if it could be included in the sidebar/OP/etc. If you agree with it, I'll send the link over. :) (PS: Yes, the Discord server has Rust emojis and a bot with a Rust eval command)
I'm leaning towards you in your concerns. I assume this will be using nightly like clippy. I try to run both rustfmt and clippy in my CI. Nightly sporadically fails because of clippy/nightly version mismatches and I don't want another dimension to the problem. I could solve it by having a locked version of nightly that I know is compatible with a given rustfmt/clippy version (how would I match these up?) but I've not been able to convince the TravisCI guys why being able to control nightly versions is useful. They think running against nightly is only good for canary builds and have ignored my pleas regarding the clippy use case.
I'm well aware that being nightly only is a pain and its not something I take lightly. There really is no benefit and the costs are real. However, since Syntex is not maintained stable Rustfmt is slowly getting buggier and less complete compared to Rust. That is also pretty bad. I think you are right that having rustfmt-nightly as a crate is a good idea, at least until the 0.8 branch of rustfmt gets really bad (by which time I hope we'll have Rustup support). So I'll plan on doing that, thanks!
That's not my understanding. According to the blog post, the upcoming 0.9 release will only be able to compile on nightly; `cargo install` will attempt to compile 0.9 once it's released. Unless I'm missing something here.
Thanks for listening! if things do get really bad, then it would make sense to move the "rustfmt" crate over to the nightly-only version for sure!
You are correct, and it seems the author is confusing some issues. Stdout is explicitly (line) buffered: https://github.com/rust-lang/rust/blob/4ed2edaafe82fb8d44e81e00ca3e4f7659855ba2/src/libstd/io/stdio.rs#L346 . However, `File` handles etc. are not buffered: they are more like a raw file descriptor in C, rather than `FILE*`. Of course, it's still true that line buffering may still be a penalty that is nice to avoid.
No, stdout is line buffered by Rust: https://github.com/rust-lang/rust/blob/4ed2edaafe82fb8d44e81e00ca3e4f7659855ba2/src/libstd/io/stdio.rs#L346
Is `syn` an option for rustfmt to do its parsing? (asked naively, having barely dabbled in this area at all.)
It would be. However, it would be a huge effort to move Rustfmt to using a new parser and AST, so its not really feasible to implement. (I expect we would need to make some changes to Syn too make this work, like more span information, etc, but this is just a guess since I've not tried to plan this work).
Author of the etcd crate here. v3 support seems like it would require gRPC for Rust. Are there any other specific things you don't like about the current version that could be improved?
`Path` is equivalent to `str`, it's always behind a pointer, like `&amp;str` or `Box&lt;str&gt;`. You almost always see `Path` as `&amp;Path`, which means it's usually borrowed from something (often converted from `&amp;str`). For a growable, owned path buffer, you want `PathBuf`.
Hey, thanks for working on this! It would be nice if the examples had some comments on parts that the framework does. I had a look at the first example and was confused by some things: 1. Where does the `AllCaps` type come from? 2. What does `in Debug` mean? 3. Where is `routes` coming from?
Does being on nightly just mean installation is going to be `cargo +nightly install rustfmt`? Or is the usage affected as well?
usage would be affected too
Strings always append new data. The clear function just sets len to 0 so that appending starts from scratch rather than at the end of prior data.
I think using the compiler's own libsytex module really is the way to go here and will help stabilize both rustfmt as well as find bugs in the compiler. Other libraries, like the RLS, depend on that module, so having more libs use it is a great idea. Being on nightly is a necessary stepping stone, and I approve of the path you've chosen (making the rustfmt-nightly crate). Great work and thanks for rustfmt. A+ tool, looking forward to it being A++
True, simple straightforward Rust is often slow. For example: *map.entry(key.to_owned()).or_insert(0) += 1; to make this code faster, you have to write this horrible monstrosity: let flag; if let Some(v) = map.get_mut(key) { *v += 1; flag = false; } else { flag = true; } if flag { map.insert(String::from(key), 1); } 
So many people say that Rust's big thing is safety, and when discussing this they almost always focus on memory safety. "Rust has memory safety like languages with GC, but without the overheard." This is true, but Rust's safety runs deeper than this. At my day job, we had a HTTP service written in Java/Scala. Periodically, this application would completely freeze up, not just itself, but the entire server it was running on. Not only was HTTP not working, we couldn't even SSH in. What was wrong? Well, this service would open connection to other HTTP servers, and a previous developer had not bothered to invoke `.close()` on the connections when they were no longer needed. The JVM would close the connections down eventually when GCing, but this would only happen when GC ran. In the meantime, the server could consume every single file handle that the kernel had available, until there weren't any left, not even for SSH to use to service incoming connections. This would not have happened with Rust. Rust's RAII pattern means that resources are guaranteed to be destroyed when they are no longer "owned", most often when the function (enclosing scope, really) that created them ends. This covers memory safety, i.e. freeing memory when it is no longer needed, but can also close file handles, return DB connections to their pool, commit transactions, unlock mutexes, destroy encryption keys, delete temporary directories, etc. This prevents any kind of resources leakage, and helps to guarantee predictable behavior. Rust could make writing reliable applications much easier.
Your code will not compile :( We need to have non-lexical borrows for this to work.
That's true. Still, newcomers seem to miss it...
Simple Rust is still order of magnitude faster than many other languages. Regarding your example, there is an RFC to improve entry API performance but I'm not sure if it'd make difference.
If we could invent something that can account for its users not reading or paying attention, we'd have the holy grail of development, and everything else.
how much faster is the second version?
Yeah. There's actually a project for writing Node modules in Rust which you might want to check out: https://www.neon-bindings.com/ Be aware, though, that it *is* a [work in progress](https://github.com/neon-bindings/neon/issues/144) at the moment.
This is something I've been concerned about for a while: that the canonical static analysis tool for Rust, clippy, only works with a nightly version of the compiler that occasionally breaks. This combination really seems like it's at cross purposes. I want more robust and stable code, hence the use of clippy, but I can't use a stable compiler. rustfmt-nightly will have the same problem until Rustup distribution arrives. I know there are good technical reasons for all this, but it's pretty terrible from a user perspective.
Once I got a ticket from a user, saying a tool was putting errors in his shell. I asked for the error, and it was literally the program saying: "process successful" English was their only language. Some people just don't read.
It depends on how large your keys are and how often do you query for the same key. In any case doing extra `malloc + memcpy + free` on each access to the map is not good for performance.
The context/Environment/"bag of Any" pattern is, in my opinion, an anti-pattern. It makes the functions opaque, dynamic, and hard to test. My preferred approach is for the endpoint to simply declare its dependencies, in the form of function arguments with types, and it is the framework's job to provide them. So, the endpoint can ask for such things as: the request body, a specific request header, a specific query param, all of the headers, all of the query params, all of the request object, cookies, access to the DB service, access to the template service, a logger, the current time, a configuration setting..., just any external thing the endpoint depends it. This is usually called "dependency injection". This may evoke "enterprise Java" feeling in some people, but actually I think it's a good, straightforward idea. It's also related to "object capabilities" if you are familiar with those. There are many framework which do this in various languages. I recently saw a very simple, stripped down, direct implementation of the idea in a Python framework, I think reading the README will drive the point across: https://github.com/tomchristie/apistar. The idea is useful not only on the server, but also on the client, see e.g. Angular for web, Dagger2 for Android, etc. An ideal implementation in rust will be completely static. So, will probably require some annotation processors. Since rust does not have the convenience of a GC, lifetime/borrow checker/thread safety issues will certainly arise when trying to implement DI. I haven't thought about it. I hope some web framework in Rust, maybe not this one, will try it some time :) (Actually, IIRC Rocket is doing something somewhat like that).
FWIW while `tokio-proto` is heavily centered around request/response, everything else (e.g. `tokio-core`, `futures`, etc) don't require this! I've set up a number of data streaming pipelines with just tokio-core and it should be up to the task!
By finite sequence I mean `.next()` requires 1 bound, `.next().unwrap().next()` 2 bounds etc. The first definition of `count` is using the trait in the parent comment, hence "becomes" after it. You can't switch it to my trait because you then need an infinite number of bounds - which was the point made before. What the second definition does is recover the fixed-size definition *given my trait* by using `impl` polymorphism. And I wasn't talking about inductive/coinductive *data types* - but rather, type class instances / trait impls. You can use basic induction (think an impl for `()` and another for `Box&lt;T&gt;` where `T: Trait`) but coinduction is not allowed/implemented due to soundness and complexity concerns.
Thanks for this feedback, even though I disagree with a lot of it. I agree that `TypeMap`s can be problematic (though I think the term "anti-pattern" is overly reductive) for the reason that you essentially cite - they create dependencies that are not declared in the type signature of the function. That said, none of the interfaces in cargonauts that take an Environment are intended to be unit test boundaries (they're too far out, only really good for an integration test), and I would strongly discourage users from pushing the entire environment further inside of their system, and instead that they extract everything they need from it immediately. (And also even if these dependencies are dynamically checked, its not like they `panic!` if they're not met.) But I actually have explored ways to replace the typemap here with a static declaration of your environmental dependencies, and I have a design that would work with an extension to trait specialization called intersection impls. As soon as that's available I'll explore the trade offs around that at greater length. However, I think where I disagree with you more strongly is your suggestion that "the endpoint to simply declare its dependencies, in the form of function arguments with types." This suggests a functional conception of endpoints, which I really dislike. In cargonauts there is no "endpoint function," instead that role has been decomposed into domain logic and presentation logic. In my opinion this is an order of magnitude more important than whether or not the environmental dependencies are statically or dynamically checked. But I think rocket does exactly what you want, and is built around this concept of an endpoint function.
I think the „systems“ in „systems programming“ may be a bit confusing. It doesn't mean its suited to write only an OS (you could use Rust for that, but it doesn't end there). What it actually means is it let's you go low-level if you want/have to. So you can specify the memory layout, when and how things happen, etc. This is needed when you write a driver, sure. But it is also handy if you want your program run fast or with less memory. It doesn't depend on what the language allows you to do, but on how much effort you're willing to invest in optimising it (it starts being reasonable fast already, though). With filesystem operations you're likely limited by the FS or disk below. But if you wanted to process data streams at speeds of gigabytes per second, then you'd have a better chance of doing so in Rust than in node. If you never need the performance benefits (which might or might not be the case), you still might like the syntax more or find handy libraries.
I was working on this (yet unreleased) 'find' like recursive iterator, before hearing about walkdir: https://github.com/stevedonovan/easy-shortcuts/blob/master/src/lib.rs#L567 I'm wondering if it's better just to build this on top of walkdir, now that I know it exists! But anyway, have a look at the interface. (The crate blitz is certainly useful for raising awareness of basic useful crates!) 
That would leave potentially invalid utf-8 in the string. 
Is there a way to iterate over input lines using buffered I/O without forgetting to clear the line? 
&gt; Hm, I see Rust like a more modern and popular OCaml maybe? WDYT? "More modern" is debatable, it's more recent but it tries for slightly different concerns. I remember quotes from the devteam saying Rust generally tries not to be too modern, and indeed it has rolled back "innovations" in pre-1.0 time, the only somewhat modern feature is probably affine types (which are pretty rare in production languages to this day). OCaml has a runtime (and still has a GIL I believe, sadly), and the syntax is a bit odd (it's an ML, an it's not the prettiest one), but that aside it has structural object types, sum types, *extensible* sum types (which is a very interesting one), functors, first-class modules, … I don't know that the ecosystem is great, but it could really work for you. FWIW a few years back the 0install lead had a series [on trying to replace Python](http://roscidus.com/blog/blog/2013/06/09/choosing-a-python-replacement-for-0install/), this was pre Rust 1.0, but [he did end up picking OCaml](http://roscidus.com/blog/blog/2014/06/06/python-to-ocaml-retrospective/), then started working with Mirage (the OCaml unikernel system), and got acquihired by Docker. He also used OCaml to build a web application (via js_of_ocaml) so he really was quite taken with the language.
Tokio+futures already works fairly well for "server workloads", but it's a completely different story if you consider the average micro-service. Without some proper async support Rust has *zero chance to compete in the mainstream*, it's just way too cumbersome compared to the alternatives and rust other strengths aren't appealing enough in these projects. This is coming from a person that put the effort to understand mio, rotor and tokio+futures. Tokio+futures works, performs and allows reasonable composition but it's still way off what people expect these days. Maybe Rust shouldn't strive to compete in those, but since the decision was already made... This is the very minimum needed, if/once it happens the rest will just follow (gRPC, http libs, ...).
&gt; Performance. cargonauts is single threaded right now for simplicity :-\ But you say it is async so supposedly you will have very high performance on a single core right now. Most users who are intrested in threads will look into dispatching tasks to other threads themselves to speed up parallel processing of each request. With that I mean that a lot of systems work best with a single main thread that can handle requests as they come in, and if a request does multiple things they can use threads to do those things in parallel (something that for example NodeJS and PHP can't do!). Doing things within one request in parallel means faster response times for the visitor. Remember that NodeJS grew fast even though it is still single-threaded. And they can't even offload to other threads in an easy way! So. Focus on developer ergonomics for now. Processing requests in multiple threads is not something most people will ask for. Offloading tasks within each request might be but people can do that themselves already.
Don't you by chance know about some good read about mem allocation and some good practices?
It doesn't exactly answer your question, since it isn't local, but you can get builds, tests, and binary releases for many platforms using trust: https://github.com/japaric/trust Once set up, it will build and test your crate for most unix platforms using travis, and windows platforms using appveyor. When you push a tag to github, it will also build and upload binaries on all configured platforms. So it isn't local, and it isn't instant, since you'll have to push tags and wait for the CI builds to finish, but it might be good enough!
What about rustfmt packaged by distributions (it's in Arch Linux, for example)?
The same story can be told about Ada. I mean the takeoff part.
Alright, I don't think you can go very wrong with Go. In the worst case, programmer comfort might suffer a little, but at any point your team will be productive (almost regardless of Go programming experience), and the end result will be technically sound and performant (if you consider your tech choices well of course, don't go blindly use goroutines or other Go features if you don't know their performance characteristics).
I'm writing an impl From, it is getting complicated so I was dividing the code into different functions inside that same impl, but when calling them I get "not found in this scope". They seem to work outside the impl.
Ada is a much less "open" and more "enterprisey" language though. Erlang might be a better comparison point.
Thank you, I will definitely take another look! :)
[removed]
What module is Try in? Can someone post a link to its API documentation?
I'm not sure I understand your comment. The revised Entry API should reach mostly the same performance as what?
If you are Web developer, a more appropriate example would be this: You're working on some web that needs to process large amount of data on the backend. Rust would help you with performance a lot. Especially if the task can be parallelised.
&gt; resources are guaranteed to be destroyed This is actually not true. You can `std::mem::forget()` them or leak via reference cycle. Of course, it's less likely than in Java/Scala though.
&gt;&gt; Feature gated but unimplemented. ..the idea is the community would follow on and implement; many people are interested in this. I'm sure there would be multiple attempts because there are many variations possible on the details. there would be a phase where conflicting ideas exist in branches. I know some people wanted to go further with *named* keywords, and I'm sure some people would suggest explicit separation between currying &amp; defaults
Here's something i've been thinking about: use std::error::Error; use std::convert::From; use std::ops::{Deref, Try}; use std::result::Result; struct ForcedResult&lt;T&gt;(T); impl&lt;T&gt; Try for ForcedResult&lt;T&gt; { type Ok = T; type Error = Forcer; fn into_result(self) -&gt; Result&lt;T, Forcer&gt; { Result::Ok(self.0) } fn from_ok(t: T) -&gt; Self { ForcedResult(t) } fn from_error(_: Forcer) -&gt; Self { unreachable!(); } } impl&lt;T&gt; Deref for ForcedResult&lt;T&gt; { type Target = T; fn deref(&amp;self) -&gt; &amp;T { &amp;self.0 } } struct Forcer; impl&lt;T: Error&gt; From&lt;T&gt; for Forcer { fn from(e: T) -&gt; Forcer { panic!("{:?}", e); } } So, like a result, but instead of returning the error case, it bombs out immediately. This lets you write: pub fn main() { let sum = parse_and_add(); report(&amp;sum); } fn report(sum: &amp;u32) { println!("{}", sum); } fn parse_and_add() -&gt; ForcedResult&lt;u32&gt; { let a = might_fail()?; let b = also_might_fail()?; ForcedResult(a + b) } fn might_fail() -&gt; Result&lt;u32, ParseIntError&gt; { "11".parse() } fn also_might_fail() -&gt; Result&lt;u32, ParseIntError&gt; { "eleven".parse() } Which kinda sorta lets you use ? as a shorthand for unwrap(). In my programs, there are areas where any error is fatal; usually when doing things like reading a config file. They tend to have a lot of .unwrap() going on. A construction like this might make them a bit more readable. It's probably not worth it, though. Apologies if anyone's gone blind from eye bleeding induced by this code. 
The edit proposal experience is broken for me. I get html code in the textarea instead of the markdown :/
YAS - I cannot wait.
Yes but the difference between unoptimised and optimised C/C++ code is much less than with Rust. Just saying it is "unoptimised" doesn't tell the used that it will be *so* much slower.
another question: I currently use Xmonad which, as you may know, is not configured as much as it is programmed: configuring Xmonad is actually writing the `main` function, which means there are absolutely no limit to what you can change — you can turn it into a completely different program if you wish (that would be a strange idea, but the point is that you can, not should) I wonder if that would be possible with way-cooler: instead of the Lua/dbus interface, just use way cooler as a library upon which you could build your own WM. I'm not asking for an implementation, just wondering if the project in a way that could allow this. Thanks! 
Any plan on extending this to support the `fn name(&amp;self) -&gt; &amp;Name`, `fn name_mut(&amp;mut self) -&gt; &amp;mut Name` and `fn into_name(self) -&gt; Name` alternative standards for getters and setters in rust?
Why the `b` prefix to the character literal? I am somewhat new to Rust.
The basic idea is that, from a performance standpoint, managing memory on the heap is slow, so you want to avoid it. Everything on the stack (local variables, etc) is super fast and is not usually counted as "allocation", as it does not really require any additional work to manage. However, managing objects on the heap requires calling into the memory allocator, which is much, much slower. You want to avoid dealing with things on the heap if possible when performance matters. The stack is also usually cached by the CPU and the compiler can ensure fast access patterns and keep stuff in CPU registers as much as possible. With the heap, you need to access data via pointers/references, which adds a layer of indirection, which prevents many compiler optimisations and makes it more difficult for the CPU to cache the data. If you try to profile large pieces of software (or look at articles written by people doing it and analysing the performance) such as the Rust compiler or curl or chromium/firefox, you will see that a very significant chunk of the CPU time is spent in the memory allocator. Hence, finding ways to reduce the overall number of memory allocations is a fairly good way to gain additional performance. This is particularly true for freshly-written software that nobody has yet worked on optimising, where you can usually score massive performance gains that way. Generally speaking, when you want to improve performance, the first thing you look at is whether you are using good algorithms and data structures that are well-suited to the problems you are trying to solve. This is true for any programming language. Then, once you are sure you are approaching the problem the best way with a good algorithm and you start getting into the realm of actually optimising your code/implementation, memory management is usually the first thing you look at -- reducing allocations. Here is a [crazy example from the curl project](https://daniel.haxx.se/blog/2017/04/22/fewer-mallocs-in-curl/). I remember reading some time ago about a similar thing that was done in the Rust compiler (can't find a link right now). In terms of articles to read, the first thing that comes to mind for Rust specifically is [this guide](https://gist.github.com/jFransham/369a86eff00e5f280ed25121454acec1) which was posted on this subreddit some time ago. For more generic info, there is also this famous (warning: very long read) [article about memory](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf), which is not really language-specific (but more focused on C) and understanding how your code interacts with the underlying hardware. It is somewhat-outdated, but still very relevant.
ugh can someone PM me when the style stabilizes? gofmt doesnt break itself
It's short for "byte." That is, `'a'` is a *character literal* and has type `char` while `b'a'` is a *byte literal* and has type `u8`. A character literal corresponds to a Unicode scalar value (which is represented by a `u32` under the covers), so you can do things like let c = '☃'; But this will result in a compile error: let c = b'☃'; In particular, a character literal must be a valid UTF-8 encoding of a Unicode scalar value while a byte literal must fit into a single byte. The above shows something that is a character literal but not a byte literal. Similarly, we can write a byte literal that is not a character literal! let c = b'\xFF'; The above works, but this will result in a compile error: let c = '\xFF'; Why? Because the single byte `\xFF` is invalid UTF-8 and therefore has no valid Unicode scalar representation and therefore in turn is not a valid inhabitant of `char`.
Thank you. I knew that Rust chars and strings are unicode, but was not aware that Rust also has a syntax for byte literals (like C chars).
Ah yup! It also has byte strings as well, where `"blah"` is an `&amp;'static str` and `b"blah"` is an `&amp;'static [u8; 4]`.
Is the (trivial) getter / setter pattern really necessary in Rust? After all, the borrow checker guarantees that only one entity will mutate data at a time.
The same performance as in fast example (the one with boolean flag). I think this is the RFC we need: https://github.com/rust-lang/rfcs/pull/1769
Many folks are against having `pub` fields. I'm not one of them, but I see their reasoning.
That would be a non-trivial case. I mean to say getters / setters of the form: struct Foo { bar: Bar, } impl Foo { fn bar(&amp;self) -&gt; &amp;Bar { &amp;self.bar } fn set_bar(&amp;mut self, bar: Bar) { self.bar = bar; } }
Yeah, that's what I had in mind!
Getters interfere with the borrow checker. This works: let a = &amp;mut foo.bar; let b = &amp;foo.baz; This doesn't: let a = &amp;mut foo.bar; let b = foo.baz(); 
So I ended up needing `name_mut`, so this feature was added. :)
I'm a C# dev at my day job. There are a few areas in which Rust is beneficial to me: 1. Better package management. I mean, *loads* better. 2. More convenient dev experience. 3. Somewhat better cross-platform support. (C# has it pretty good lately, but you're still limited in the libraries you can choose on dotnet core.) 4. More expressive type system. You can say things about a type in Rust that you just can't say in a lot of the languages application developers are used to. 5. Better performance by default. You can make C# plenty fast, but a lot of libraries really aren't written with performance in mind, and most of the code I write ignores performance concerns in favor of maintainability. In contrast, maintainable rust is generally performant rust. Of course, I think writing rust still takes like 50% longer than writing C#.
Probably the biggest issue is many people have different ideas for what default args would look like; without at least a bit of consensus, I don't see it getting implemented in the compiler.
Hello, I'm new to Rust, I read through the first 3 chapters of the Rust [book] (https://doc.rust-lang.org/stable/book/) earlier this week and I have a comment, both about the book and the docs too I guess. I'm not sure if this'll get seen by anyone who has input into the book or the docs but.... "Wtf is an Arc" was a question I had for what seemed like a non trivial period of time. I don't know if it first appeared after the first struct named Point appeared, but I kept thinking it was geometry related. Once I looked up and read about Arc (and later there's mentions of Rc, and again, I was wondering wtf an Rc is) the part of the book i was reading made way more sense. My comment is, if there's going to be some module with some acronym for a name, could it at least be introduced with a sentence or two (i.e., 'To help illustrate whatever point we're trying to make about the language, we're going to use the Arc module, Arc is short for Atomic(?) Reference Counter and can be useful for blah blah blah'). Even the documentation page for [Arc](https://doc.rust-lang.org/std/sync/struct.Arc.html) doesn't come out and say Arc is actually an acronym in that's presented in camel case. The first line describing it is 'A thread-safe reference-counting pointer' - further reading is what lead me to believe the 'A' stands for Atomic. Unless 'arc' happens to be some term in programming language design that I'm not aware of? There's just a lot of cognitive load when trying to learn a new language, getting sucked into 'wtf is X' kind of interrupts the learning process, for me at least. edit: link for the Arc page
the syntax and details could change sure. My idea is to spur on experiment. experiment will help develop consensus. I can understand why this was contraversial back before 1.0, but not now. There's an obvious, common way to do the basics.. easily discovered. dedicated keyword syntax could be layered over the top IMO,if that refinement was also desired. i know details r.e type inference and so on are more complex.. but the basic trailing defaults should be easy, via transparent arity-overload (which isn't real overload.. imagine if the number of arguments was silently added to the function name foo(x,y)==&gt;foo2(x,y) foo(x,y,z)==&gt;foo3(x,y,z). then trailing defaults would be like a function with defaults automatically rolling a series of arity overloads
Awesome, thanks!
What are the differences between the current rustfmt style and the RFC style? Is there any way to answer that question mechanically? If not, what are the subjectively biggest changes?
There's no reason why you can't test your code with clippy on nightly, but still support stable. 
I'd say the biggest is the move away from aligned indentation. As for mechanical, if you'd like an in-the-wild comparison you could take a complex Rust file and run it through `rustfmt` without any config and then with the [rfc-rustfmt.toml](https://github.com/rust-lang-nursery/rustfmt/blob/master/rfc-rustfmt.toml) and do a diff. A less manual version of an overview might be taking the above `rfc-rustfmt.toml` and look up the explanations in the [Configuration document](https://github.com/rust-lang-nursery/rustfmt/blob/master/Configurations.md) that gives examples.
&gt; From downcast\_ref, I should get `Option&lt;T&gt;` You get `Option&lt;&amp;T&gt;`, that's why it's called downcast\_*ref* :) So, maybe you just want a `Vec` of references to players? fn get_objects_of_type&lt;T&gt;(&amp;self) -&gt; Vec&lt;&amp;T&gt; With that new signature, just remove .map(|&amp;unboxed_obj| Box::new(unboxed_obj)) and it should work.
There is overlap between systems and applications; gamedev is a field with aspects of both. Writing 'applications' that run efficiently helps the world - i.e. allowing applications to run on lesser hardware that consumes less energy to perform the same work. As such, I think there is really a sliding scale , despite the fact that at the moment we have radically different languages for both. The world will benefit from more progress along this scale for the reason I give above. 
What about: wait 1/10th of a second and respawn? If you enter a crash loop, it won't put the system on its knees, and the user will still be able to reach to another tty to perform a clean reboot. 
It is extremely surprising that Rust doesn't have implicit setters. I.e. foo.bar = 1 // actually calls the Foo::set_bar method
I've been running nest.pijul.com entirely on tokio for about two months now. That server uses Rustls for HTTPS, Thrussh for SSH, and mostly custom-made stuff for HTTP and Postgres. I've really enjoyed working with Tokio. The only problem so far is error handling: my HTTP crate passes a `(Request, Response)` to a handler, which is supposed to fill the `Response` and return both. But this makes `try!` quite unsuable, because errors cannot return these types. The code for my custom-made things is available there: - https://nest.pijul.com/pmeunier/httpserver : HTTP server (and client). - https://nest.pijul.com/pijul_org/thrussh : SSH server and client. - https://nest.pijul.com/pmeunier/pleingres : PostgreSQL in pure Rust. 
Note that "line-buffered" means that it does one write operation each time you use `println!` (or potentially even more, if it breaks inputs on new lines). If you have lots of small lines, you'll still be locking/syscalling/unlocking a *lot*.
The performance of unoptimised C++ code is inversely proportional to your use of templates. Leaning strongly on `std`... or `boost` will quickly dilute the performance. It's never been too much of an issue for me, but it's something game developers face regularly.
An impl can have private functions. A trait-impl may only contain the items declared in the trait definition. If you want to have a private function you can declare it in a regular (non-trait) impl.
Rust originally looked and worked quite like OCaml and had significant influences. Since then it became a lot more low level, shedding the GC and other things.
The issue is the getter method requires "locking" the entire structure as Immutable, because the method is a black box that could do anything to the struct. This means it can't infer that you are doing a partial borrow of the struct. This could be "solved" by having getters / setters be something the borrow checker is aware of, however that is almost certainly not worth it. 
Most of the popular libraries like `std` are largely using getters and setters already. This is partially why this crate exists. It makes doing that work easy for trivial bits and let you write harder ones on your own. Also keeps the experience consistent.
&gt; But this makes try! quite unsuable, because errors cannot return these types. would https://github.com/rust-lang/rfcs/pull/1859 help?
That would be cool indeed. Not sure it would help.
I'd say it's about half lifetimes and half the necessity to consistently dig into libraries and try to understand how they work. That's not something I've had to do in C# in the past... Five years or so. Edit: I should note that, if I *don't* know how to do something, it's not necessarily going to take longer in rust. If it means learning a new library or pattern or whatever either way, maybe things are more even. Like, I just wrote some image manipulation stuff. Doubtful I could have done that much faster in C#, since most of my time was spent trying to understand the image manipulation libraries themselves.
&gt; Rust is a computer language, not a policital group The CoC is not for the "computer language" but for the _community_. The CoC represents what the Rust _community_ values.
&gt; Everything they say "don't do X" I've yet to ever see an example of it occurring. That might be because the Code of Conduct is there, and people who violated are usually quickly removed from the community. &gt; The biggest thing is phrases like "We will exclude you from interaction". That says "we are not welcoming of others" all over. It's not "we are not welcoming of others", it is "we are not welcoming of people who violate the code of conduct" . The code of conduct essentially just says "don't be an asshole". If you are being an asshole, you're probably not welcome in the community anyway.
&gt; That says "we are not welcoming" all over. That's the point. The code of conduct is there to state that the community will *not* welcome conduct that is not friendly, safe, and free of discrimination. &gt; Everything they say "don't do X" I've yet to ever see an example of it occurring. Great! Maybe this works then?
&gt; That might be because the Code of Conduct is there, and people who violated are usually quickly removed from the community. &gt; Sorry, I wasn't specific, I meant that in reference to other computer language communities. &gt; It's not "we are not welcoming of others", it is "we are not welcoming of people who violate the code of conduct" . The code of conduct essentially just says "don't be an asshole". If you are being an asshole, you're probably not welcome in the community anyway. I see. The phrasing sounds very much like high school cliques that "shun" everyone they disagree with. This is why I'm not a fan of it.
The phrasing is &gt;We will exclude you from interaction if you insult, demean or harass anyone. Can you help me understand what about this implies shunning over a disagreement? Or high school clique-iness?
My worry is that those words can be extended to mean anything. If I'm passionate about something someone could say I'm harassing them by being insistent on something I care about. They're weasel words.
Yep. That's exactly my point. "Don't be an asshole" is just a shorthand, and the Code of Conduct is specifically there to define exactly what is disallowed.
I guess I'm against the entire concept of codes of conduct? I like a free society with free association.
Does that also apply to (non-illegal) conduct outside of the community? I disagree with the concept of excluding those who act fine among the community but not otherwise. Though I don't disagree with any of those personally.
It makes me emotionally queasy, for some reason. It doesn't feel right or good. I haven't encountered any issues butting up against it personally.
A free society has rules. And consequences for when those rules are violated. Who makes the rules? Who interprets them? Who enforces them? Who enforces the enforcers? These are questions that have plagued humanity since time immemorial---from monarchs to democracies to even hypothetical "free societies" of all lefts and rights---and we aren't going to solve them in this thread.
I personally have some views that the hive mind probably doesn't approve of. I don't discuss them here. This is a programming language subreddit, not a political or religious one, so I refrain on expressing my political and religious views here. I have no problem with doing so. If people were bringing politics and religion into this subreddit regularly and stopping me from expressing my views, then I would have a problem. I don't approve of thought police. I do approve of trying to be nice to each other.
Thanks for this. This makes me feel much better. If conduct here is actually as you say then I'm fine with the rules.
This isn't much of a problem since rebinding the value from a getter rarely happens and temporary borrows are dropped immediately. For everything else, we have braces.
Throwaway because the topic at hand toes the line of appropriateness for this forum: The way I see the Code of Conduct is that it asks everyone to set aside any intolerant views that might be part of the rest of their life, during the time they spend in the Rust community. This can feel unfair because it asks you to censor yourself when your views are intolerant: If I think a given programming language is pretty useful, it's fine for me to talk about my opinion on it, but if I think it's a flaming pile of garbage that should be thrown out a window, I cannot discuss my opinion on it in Rust forums. To someone whose job or hobby is describing systems precisely enough for computers to understand them, it seems pretty inconsistent to draw the line right there: Why is it OK for someone who holds the former opinion to talk about it, but not the latter? The answer is that the whole point of Rust having a community at all is to bring a bunch of diverse humans together to build a tool and a bunch of tools around it. Based on their observations of other groups of people trying to build tools, the Rust leaders decided that the Code of Conduct represents a useful place to draw the line between having it so people can make friends with each other and build community, versus letting people behave in a way that detracts and distracts from the ultimate goal of getting the software built. People who are okay with censoring their intolerant views in the context of building software tend to thrive in the Rust community; people who consider that an unacceptable tradeoff tend to find other groups of people to work on software with. It seems to be working out OK for the language so far. And it's OK if you decide that you would prefer not to be part of a community with rules like the CoC.
If a person harasses a community member on an outside venue, they will be excluded from the community. If a person posts sexually explicit material outside of the community (assuming it's posted in a place for it, not sent unsolicited to community members -- that would be harassment), that's totally ok. 
The word "excluded" gets to me as well. Can't we just call it what it is without using euphemisms?
/u/nasa42 QOTW?
We considered it, but it doesn't seem like an optimal long-term solution (it also seems much harder than it did at first because of libsytax's dependent crates): it doesn't help Clippy, it means Rustfmt can never use more data than just parsing, it means tools get broken every time the crate gets updated, and there is overhead for someone in updating the crate. For bindgen, I'd hope we could move to using the proc macro libraries rather than continuing to use libsyntax/Syntex, since these should be stable. I appreciate that is a little way off and will be a big change.
If you use integer32's playground - http://play.integer32.com/ - you can format code using both styles and see how the code changes
Gotcha. Thanks for the reply!
Let me put it this way: As we know, GMail is not run by Rust, so an email isn't "inside the scope of community activities." But what happens if someone meets you at a Rust conf, digs your email out of the git history, and starts emailing you a bunch of copies of the goatse graphic? Would kicking the sender out of the conf be a reasonable action?
Yeah that's exactly the one of the types of abuse I'm worried about. Edit: I hadn't seen that article. That article makes me quite angry. Hopefully I never have to see anything like that as part of the Rust community. Doxxing is not okay.
Well, I wrote the initial CoC and put the "We will exclude you from interaction" phrase in there, so maybe I'll mention the impetus and meaning. I was given the opportunity to start a language project by my employer, Mozilla corp. I'd had the experience of working -- both professionally and on volunteer time -- with many PL communities in the past. Communities that were prone to several norms of discourse that I found extremely difficult to deal with, that would have prevented me, and several people I knew and wanted to work with, from bothering to work on a language at all. In other words: I would not have built the language, nor participated in a project of building the language, if I had to subject myself to the kind of discourse normally surrounding language-building communities. In other other words: the norms of _other_ communities were already excluding _me_. So I wrote down the norms and behaviours that I knew chase people away (including myself) and said look, in this community I'm setting up, on these servers that my employer is paying for and paying me to moderate, this behaviour is not welcome. It's a big internet and we can't prevent people from behaving how they like in their own spaces, but we can control who we interact with in online spaces we set up. So these are the ground rules for those spaces. I was careful to chose the phrase "exclude from interaction" because, in practice, that's all one can control on the internet, and it's silly to pretend one has more control over a situation than one does. I can't control what you do on your time, on your own servers, on your corner of the internet. I can only control _who I interact with_. As it's happened, lots of people felt the same way: the rust community has attracted and retained a lot of people who _did_ feel they were repelled from other PL communities because they're so aggressive, so abusive, so full of flaming and trolling and insults and generally awful behaviour, that they had given up even participating. Many people have found a home in the rust community that they had not been able to find elsewhere. Some people, naturally, feel that the norms spelled out in the rust CoC makes _them_ feel excluded. To which all I can say is, yes, it's true: the rust CoC focuses on behaviour, not people, but if there's a person who _cannot_ give up those behaviours, then implicitly it excludes such a person. If someone just can't get their work done effectively or can't enjoy themselves without stalking or harassing someone, or cracking a sexist or racist joke, or getting into a flame war, or insulting their colleagues, I suggest they go enjoy the numerous other totally viable language communities. Or heck, fork the community if you like. Make the "rust, but with more yelling" community. Big internet. Knock yourself out.
Free association means the freedom to choose who you associate with, and who you exclude. You can't have freedom of association if someone can barge in and impose themselves on you and your group. The Rust CoC outlines the terms of association for this group.
This is actually what libpnet does, but accessors are generated automatically (using annotations)
&gt; In other other words: the norms of other communities were already excluding me. &gt; This is something I've been curious about for a long time. I, personally, have a hard time trying to understand how language used can exclude people. This seems like something that is obvious to many people but not at all obvious to me. The old phrase "sticks and stones will break my bones but words will never hurt me" is something I've always found personally for me. If people are getting directly attacked its one thing (which is quite rare anyway?) but the third party overhearing aspect I find interesting. Thank you for the well written response.
What if you want read-only access to some fields and mutable access to others?
&gt;I don't think you should use Rust unless you either need it or you're really good at it already. Huh? First, every server needs safety, otherwise you get security problems. Also, I found Rust reasonably easy to get in to. Not my first choice for web by any means, but there are select projects where I'd reach for rust. 
It's a matter of just realizing that what may work for you doesn't work for everyone. You don't have to understand it per se, but as long as you acknowledge it and go "Okay I won't say X to you because you don't like it" then I think personal interactions between people can go a long way. Some people don't think like that. They think "Well I'm not offended so why does it matter what I say?" In those cases the self centered approach tends to exclude others who are offended or feel personally attacked by language used (i.e. misgendering, sexist comments against your identity, etc.) . If someone says something sexist or belligerent or exclusionary it leaves a bad taste in a lot of people's mouth. Why would you want to hang out in a place that makes you feel worse? As graydon said this is why sometimes you need to be exclusionary. Not every viewpoint has to be catered to and that's up to the community to decide. I guess the main point I want to get across is that even if you personally don't feel some way about something there might be a lot who do. Talk and listen to them, maybe you'll come to understand even better why they feel the way they do :) Humans are a diverse bunch.
Many people are more sensitive than that. And even if it is tolerable, I don't want to spend time being exposed to it when I can choose to do something else with my time. While stuff has very rarely been directed at me, I feel the need to defend others, which can be time consuming and draining. 
I believe that the forced "niceness"' that the speech codes like the one you wrote demand is likely to promote hypocrisy and mean intrigues hidden by the façade of forced civility. Consider, for instance, this part: "if someone takes issue with something you said or did, resist the urge to be defensive. Just stop doing what it was they complained about and apologize." That is preceded by "Remarks that moderators find inappropriate, whether listed in the code of conduct or not, are also not allowed." All that boils down to: "don't question any arbitrary decision by moderators. Don't try to defend yourself, just bow down and humble yourself." Maybe such demands are appropriate in a religious group that believes in abasing oneself to purify the spirit, but in a technical forum rules like that are offensive. 
Btw the code that sends emails for confirmation is broken. The email I got was blank. (That being said, thanks for making this! It looks really cool.)
Published as [pool_barrier](https://crates.io/crates/pool_barrier). Let me know if you have any issues.
What is the reason for distributing through rustup instead of cargo? I am getting a bit uncomfortable about cargo vs rustup. To me rustup should be to cargo and rust what gradle wrapper is to gradle. Obviously the direction taken is different and I don't really get it.
No, you're mixing the two statements there. The "someone" in the first is not for when a mod asks you to stop, it's for normal community members. And, even then, you are free to flag the discussion for clarification from the mods. You are free to question a decision of the moderators. In the interest of not derailing regular conversations, this is better done by emailing the mod team and/or core team, but there's nothing against criticizing or questioning a moderation decision. ---------- Regarding "façade of forced civility", IME the moment a discussion gets abrasive it starts losing technical merit. Folks stop truly understanding what the other is saying and respond to the tone instead of the argument. I've rarely seen such discussions be productive. Civility is not the antithesis of technical decision, it is its foundation.
**TL;DR:** CoCs exist because jerks are real &amp; can hurt you more than you might assume if you have a hard time understanding marginalization (a very broad term that covers things like "language excluding people"), it's usually a sign that you've never experienced it. so i'll do my best to explain it from the perspective of someone who has, and who's seen it happen countless times to people they know. the sad fact is, people get attacked all the time for all sorts of reasons, especially for things like race or gender identity; it's far from "quite rare", and people literally have had their lives damaged or even destroyed due to abuse. "exclusionary" (or, as it could better be described, _abusive_) language is harmful to a person's psyche in its own right -- take as example the litany of instant celebrities who got ripped to shreds by a sudden rush of meaningless hate even though _intellectually_ they knew it was meaningless, because that's how awful brains are -- but even more insidiously it's often used as an entry point into more serious forms of abuse like stalking or doxxing (or worse). the mechanics of this are worth exploring &amp; i encourage further reading if this interests you, but put simply, someone who uses abusive/"exclusionary" language hurts people &amp; is almost guaranteed to escalate to higher forms of abuse. sadly, PL spaces aren't immune to this, which means we (as in developers) need safeguards to keep this behavior out. thanks for reading &amp; i hope you got something out of it :)
&gt; but the third party overhearing aspect I find interesting. It really depends on the context. Even though lots of people will make sexist/racist jokes ironically with absolutely no harm intended, you have to realise that there are also many people who are completely serious when they say the same things. It's all about context. Some of the things you joke about in private with your friends should just stay between you and your friends. As a newcomer to a community, there's no way to tell whether such jokes are actually jokes or if they're really serious. It would be nice to be able to assume that it's always a joke, but that's not how real life works and so anyone who is the subject of a sexist/racist/whatever joke is going to be wary of participating in communities that allow that sort of behaviour. Why would they be wary? Well, if they've encountered sexist/racist people before (which they no doubt have - we're on the internet after all), they would almost certainly have been harassed by them to some degree. Depending on the severity of said harassment, they may not want to risk participating in any community where they see racist/sexist comments being made (ironic or not - they can't tell because they're new). The end result is a lot of people that would've made great contributions to the project and/or community, never give the community a chance. Therefore, if there is such a way to make those people feel welcome without alienating other people (excluding assholes who don't belong in the community anyway), then such a method should be implemented. Furthermore, if the method (in this case the Code of Conduct) has its merits despite being abused in other communities (which CoCs certainly have), why not use it as an opportunity to show why a Code of Conduct can be good? ^^Disclaimer: ^^I'm ^^a ^^straight ^^white ^^male ^^so ^^I'm ^^unable ^^to ^^speak ^^from ^^personal ^^experience ^^about ^^being ^^harassed, ^^but ^^I've ^^done ^^my ^^best ^^to ^^explain ^^what ^^I've ^^observed ^^and ^^been ^^told ^^by ^^other ^^people ^^who ^^have.
There's an objection against `pub` fields regarding API evolution. Changing a `pub` field is a breaking change and, per semver, this requires a new major version. Hiding the field makes the code more flexible for the library developer. But (IMO) that's usually not important enough to hassle the users with the use of getters and setters. But, getters/setters to private fields are essential for maintaining invariants, such as invariants that could violate memory safety in unsafe code.
Uhm. That looks like an usability issue. I think it fits the [roadmap for 2017](https://github.com/aturon/rfcs/blob/roadmap-2017/text/0000-roadmap-2017.md) (under "Rust should have a lower learning curve").
I'm still in the process of discovering my own views. I like some of the concepts of that movement but am unsure exactly on how much I like them so no I wouldn't call myself a Voluntaryist.
I will refrain from getting into the weeds, but on some things, I will say that our minds bend in similar directions. &gt; They claim things are better now with the advent of a dedicated moderation team, but I haven't seen any evidence for it. You'll definitely see us chiming in now and again when a discussion on github or the forums gets heated or very off topic, but we do speak to people in private as well. Public evidence of the latter tends to undermine the objective. As a moderator (although, I am not a mod on reddit, so perhaps it's different here), I'm not especially active, and I think that's a decent reflection of the entire team. I am cautiously optimistic that that's a good thing, and that, for the most part, the community moderates itself. &gt; the CoC rings pretty hollow I think the CoC is a codification of our community norms. I've seen plenty of anecdotes that express appreciation for how friendly, welcoming and helpful we are. To me, that is praise of our community norms. I think the most interesting challenges for our community (and the CoC) will be how well they scale with the number of people in it. Time will tell, but I've seen size---while perhaps an indicator of success---destroy many things.
FWIW, the mod team [explicitly operates on a policy on deescalation](https://github.com/rust-lang/rfcs/blob/master/text/1068-rust-governance.md#moderation-team). Banning is extremely rare, aside from spammers and such.
Reading political violence into the Rust code of conduct makes me think you're coming into this with an agenda.
You're twisting what I'm saying. Please don't misconstrue things not based upon the line of the conversation.
The main problem of introducing more deps is that it would cause some touble if a big project (like servo) wants to avoid duplicate crates in dependency. But I guess as Serde gets stablized on 1.x, it is less likely in the future that crates depend on a lower version than that, so this specific dependency may not be that big problem.
&gt; When you're constantly being made to feel like an outsider, trying to participate in a community becomes more draining and less energizing. This line specifically made me think. I am white and male and probably one of the reasons I made this post is because I see the current sentiment behind these things rather than being a defense of those marginalized ends up being an attack on the race and gender of those who often do the marginalizing. This is something that often makes me feel as an outsider and often is a draining feeling upon me. Edit: Lots of people are apparently reading this post incorrectly and assuming the worst. Sigh. This is me describing my personal emotions and realizations. This is not me making any kind of objective claims or anything of the sort. The fact that people are jumping out of their skin about me being white and male actually reaffirms exactly what I was thinking.
Generally when something makes someone feel "unsafe" it would be handled on a case by case basis. There are plenty of legitimate ways someone may be made to feel unsafe in a community, and there are plenty of ways one can use a proclamation of "unsafe" to do harm. There's a lot of discretion involved here; we can't provide rigid rules for everything. You're giving a pretty specific situation, but you can't make a decision on such a situation without any context. In such situations you need a lot of context on that person's prior behavior within the community, for example, among other bits of context. In general, there _are_ cases where a person's activity outside of the community that leads to people within the community feeling unsafe with that person will lead to that person being asked to leave. Not all such cases, but some. These things would be determined on a case by case basis, however.
The only way I see of not having to care about cleaning up the String manually would be to initialize the mut variable *inside* the loop and let it go out of scope through reaching the end of the loop body but that would negate the desired effect of not having an allocation per iteration... Or, if you are absolutely sure that your input will be relatively small you could use [`read_to_string()`](https://is.gd/XxzAdO) on stdin and split into &amp;str 's on newlines. IIRC that should limit the whole "process" to only one allocation as well, albeit a potentially gigantic one.
Basically, [this](https://github.com/ralfholly/mlog) handles the straightforward cases (I haven't used this implementation but it's the idea). The printf bit is a bit more complicated and honestly I haven't implemented it myself.. I'll have to take a look and see what was done. But it's basically the same idea - device-side symbol, log it + arguments to the host, host looks up a format string in the map file that's associated with the symbol, host calls printf with the arguments and the format string.
Very true.
&gt; the knowledge from python def foo(a, b=[]): b+=a print(b) foo([1]) foo([7]) im not sure looking to python for default arguments is the way to go.
&gt; As far as I can tell, Haskell folk seem to do okay without one. [Not everyone has had the same experience unfortunately.](https://www.youtube.com/watch?v=wewAC5X_CZ8&amp;feature=youtu.be&amp;t=17m29s) (section on Haskell lasts for about 2 minutes)
&gt; For example one of the top contributors pre-1.0 was someone who constantly turned technical disagreements into personal attacks, and otherwise acted in a toxic way that drove away many other potential contributors. Yes, and you're pulling the same toxic demagoguery against the phantasmic "core clique" that he would pull to get influence in the community - here and a few weeks ago. If you have a problem with someone address it directly &amp; respectfully, don't go around with this back-talking schismatic BS. Be a kind person and an adult.
In the most practical sense, if you want to talk about this subreddit specifically, reddit.com is a website designed around regular everyday people creating subreddits and then determining their own rules (within reason) for how to behave on those subreddits. This is free, and easy. So nobody is determining "what the Rust community thinks". What they are determining is the rules for the Rust subreddit, and then the reddit community then gets to vote with their feet on whether these rules are ok or not. I really can't imagine a better system. Can you?
I'm not sure how relevant the CoC is to that incident. If you don't have a CoC you can still become the target of Twitter mob pressure — maybe it's even more likely. btw, LambdaConf had the same issue with the same speaker, they put a [ton of thought](http://degoes.net/articles/lambdaconf-inclusion) into the decision to allow him to speak, and they still got attacked mercilessly. If you google "lambdaconf moldbug" the first link is a well known tech feminist publication accusing them of "white supremacy". Also a bunch of people boycotted the conference, which of course is their right. I would much rather have that outcome than have the conference itself give in to the pressure tactics. No space can be safe for everyone. Not every space should be made safe for the "most marginalized" people (a misreading of intersectional theory, anyway) at the expense of everyone else. Now, I have no interest in safe spaces for racists and won't fight for them. But the Moldbug incident goes way beyond that. Social justice mobs are not exactly known for stopping at a reasonable set of demands. Will they also ban speakers who think that evidence matters in sexual assault cases? How about people who think building housing is a good response to a housing shortage, a position that a "progressive" publication recently characterized as "alt-right"? It would definitely make me think twice about applying to speak at such a conference, because you can always dig up some statement from someone's past which is insufficiently social-justice-y. (Not at all hard in my case.) I'd also just like to say, it's my belief that sexual harassment and worse against women at tech conferences is both more common and more damaging than these social media blow-ups. That's terrible and something worth fighting against. It's possible to care about two different bad things without thinking they're equally bad. I tend to talk about the issues that are taboo in the local subculture, not because I think they're the most important in an absolute sense, but because other people already have the non-taboo issues covered. For all that's said about the responsibility to speak up against sexism, I rarely get the opportunity. I guess I have the luck/privilege to avoid interacting with people who espouse sexist attitudes. Anyway this is getting to be a tangent. If you got this far, thanks for reading my rant :)
What do you mean by "1st class"? Doesn't this work for you? https://github.com/stepancheg/grpc-rust/ It also supports futures. 
Well, I have addressed it with them directly as well. I didn't realize that discussing community issues in public was forbidden. btw the last person who told me to "grow up" got an official warning from a /r/rust mod so you might want to control your own tone. I don't see what's disrespectful about saying there might be a clique. Or that one *might* arise in the future. It's a valid concern in any community. Your disdain for "schismatic" statements is really a call for conformity and blind obedience. Basically you are doing exactly this: &gt; Using the CoC to label any criticism of the community as having "inappropriate tone" is just another way to perpetuate that bubble.
Thanks!
I'm working through some of the problems on codewars and I ran into this problem. http://www.codewars.com/kata/whats-up-next/train/rust The problem is simply to return the next element of the array. In Javascript, I would just do a findIndex() on the array and return the next element. I am however having trouble finding the correct way of doing this in rust. The boilerplate they give for the function is : fn next_item&lt;T: PartialEq&lt;T&gt; + Clone&gt;(slice: &amp;[T], find: T) -&gt; Option&lt;T&gt; { } next_item(&amp;["Joe", "Bob", "Sally"], "Bob"); It seems that the lifetime(?) information is giving me problems. Thought I don't think it's lifetime information as it's not using the 'name syntax. When I try to use something like: slice.iter().find(|x| x == find) It says &gt; the trait `std::cmp::PartialEq&lt;T&gt;` is not implemented for `&amp;T`. consider adding a `where &amp;T: std::cmp::PartialEq&lt;T&gt;` bound. Any help would be greatly appreciated! 
Very much agree with your last point. If Rust is truly successful, there will not be a single "Rust community" any more than there's a single C++ community. The number of people who, say, post in /r/cpp or visit Freenode `##c++` is a vanishingly small percentage of all people who use C++ worldwide. At some point we'll have to accept that these rules and the accompanying happy feelings only apply to the venues officially managed by the Rust project. Graydon make the same point elsewhere in this thread and I do take it to heart.
&gt; Civility is not the antithesis of technical decision, it is its foundation. Wow, Manish, this is the most succinct and beautiful formulation of our community's core value I've seen yet. Thank you!
Thanks so far, but I'm having essentially the same problem still. I've got this as a result of your changes and some minor refactors to isolate the issue: fn get_objects_of_type&lt;T&gt;(&amp;self) -&gt; Vec&lt;&amp;T&gt; { self.game_objects .into_iter() .filter_map(|box_obj| box_obj.as_any().downcast_ref::&lt;T&gt;()) .collect::&lt;Vec&lt;_&gt;&gt;() } Which still complains about the lifetime. Seems the culprit is this line: .map(|ref_obj| ref_obj.downcast_ref::&lt;T&gt;())
This is a valid point, legacy Java and Java 8 are very different languages. In the story though, it really was pure mediocrity.
I don't think this is an effective way to address others' concerns. Your comment seems to be trivializing the OP's concerns (whether you perceive them to be reasonable or not) by making a comparison with things that are worse. But the comparison isn't really relevant. What's relevant is how the OP feels/perceives, even if it's inconvenient or "not as bad" as what others might be going through.
The question and statement in my post were both made in earnest and in good faith as well. I don't think it is an inaccurate representation of what's going on in this thread in at least a few places. However, it is rather direct and the other replies were better anyway, so I'll strike-through it.
Thanks for the series! I have a small request: it'd be great if you could adjust Mailchimp's settings to allow users to receive plain text emails. I much rather receive plain text, as reading html emails is quite painful with my setup.
So listen op, at the expense of perhaps being a jerk... So I'm also a cis white dude. A few years ago, I was a part of a community full of people I respected. I found out all of those people had a particular modus operandi that I felt was a bit exclusionary towards me, as a man (I thought, based on their behavior, that they were women who didn't like men). But again, these were people I respected and I believed them on *other* topics, so I decided it was important to me that I figure out why I was having so much trouble agreeing with them *now*. Upon reflection​ &gt;... the current sentiment behind these things ... ends up being an attack on the race and gender of those who often do the marginalizing. I realized I was in a similar mindset. But once I opened my mind to the idea that even ***I***, enlightened though I was, could be a racist/sexist doofus without noticing, I started paying attention to what these people were saying without becoming defensive and it really helped me understand a group of people I didn't connect with before. And also, it made me realize that my subconscious thoughts that made me feel like the "don't be an asshole" sentiments were personally targeting me were **my** problem, and it was a problem to be solved by not being an asshole. I wouldn't call you names, because you've been mostly friendly and open to discussion. I *will* say that your responses here lead me to believe that you might hold some opinions or beliefs that could use a second, hard, critical look.
thanks, I have been looking at fireplace. I use openbox now but would like to leave X at some point.
&gt; I see Rust like a more modern and popular OCaml maybe? Not really. OCaml is functional, and it bears the influence of category theory. Rust is more focused on making manual memory management palatable. 
I see getters and setters as future proofing. If you start out allowing direct field access and later need to wrap access in some logic to uphold some invariant, you have to make a breaking API change. If everything uses getters and setters from the start, you're free to insert arbitrary logic at any time, and the external interface remains the same. In short, encapsulation.
&gt;There aren't many good kafka libraries you'll be handling partition management, partition balancing, and broker re-connection yourself. Is Sarama any good? I used it a few times (albeit for a simple usecase).
The `type X = y` does not create a new type, it's just an alias. You cannot impl a trait not from your crate for a type not in your crate, and because `type` does not create a new type, both the trait and the target are in std.* If you want, you can use the newtype pattern: struct MyType(BTreeMap&lt;String, String&gt;); `*` Better explanation: When implementing a trait, either the trait or the type you're implementing for has to be in your crate
You made type aliases, which as far as the compiler is concerned are exactly the same as the types they alias; they're purely alternate names. What you want is a newtype, which is done with a single-field struct. struct MyType(BTreeMap&lt;String, String&gt;); These have the same in-memory representation as the type they wrap, but it's your type so you can implement whatever you want.
Thanks!
Why there is no .each method in Rust? I have this code: let methods = google_spec.resources .values() .flat_map(|resource| resource.methods.values()) .cloned(); let mut spec_paths: BTreeMap&lt;String, openapi::Operations&gt; = BTreeMap::new(); for method in methods { let operations = openapi::Operations::from(&amp;method); spec_paths.insert(method.path.to_string(), operations); } It would be amazing if I could instead just add .each after .cloned and avoid looping again in the for loop. I'm aware I could .fold but .fold always becomes more difficult to read IMHO. 
Yes, Rust is not trying to make lame programmers write good code. It tries to make some problems unlikely.
Suppressing dissent also hurts the community. Some people clearly base their assessment of what's "kind" language largely on whether someone is agreeing or disagreeing with the dominant narrative. For example you are not being kind to me at all, but people will support you anyway because it reinforces the good feelings about the community. If the mods have a problem with my behavior they can tell me so. This happened before, I deleted my comments and apologized in several places. I think that's the "adult" thing to do. I don't think that "adults" should be expected to silence all criticism of community norms, in a thread that is explicitly about community norms. Anyway we don't all have to like each other, we just need to be respectful. I really am trying and I hope you will too.
I have &gt; 15 years of C++ experience with an [open source project](http://widelands.org) written in it with ~1e downloads. I also have a [fair bit of Python](https://github.com/SirVer/ultisnips) experience. Also, I am currently a senior engineer at Google having done quite some backend work there. Maybe I come from a different direction than the people who work on Tokio, having no experience with Finagle. For example I had trouble expressing non RPC like systems (for example an IRC client) and I had lots of trouble expressing things like: next, expect either this type of packet or this packet, but not this. But after the first, you can expect either. I found it quite cumbersome to express timeouts and regular pings which is mixed into the protocol. Generally speaking coroutines make concurrent programming way more intuitive for me - I really enjoy that aspect of Go, though I really prefer everything else about Rust. Chaining futures makes sharing and passing state harder and error handling more difficult, IMHO.
I've wanted this from time to time too. The [last RFC](https://github.com/rust-lang/rfcs/pull/582) I know of for it was rejected. However there is [`Itertools::foreach`](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.foreach) available in a crate. In this case though you probably want [`Iterator::collect`](https://doc.rust-lang.org/core/iter/trait.Iterator.html#method.collect). It'll be something like let spec_paths = google_spec.resources .values() .flat_map(|r| r.methods.values()) .map(|m| (m.path.to_string(), openapi::Operations::from(m))) .collect::&lt;BTreeMap&lt;_, _&gt;&gt;() ;
I personally find default arguments difficult to reason about, but your idea sounds interesting.
Hmm, I'd have thought that background would have been amenable to it, My mix of tech is similar, Mainly C++, though recently python (writing some replacement event loops and porting greenlet code to python 3.4+'s async was particularly relevant experience) The only major difference (other than only having been at it for ~10 years) is I've also done a fair bit of Haskell, so maybe that's where the intuition for "building up the shape of a computation, then letting something else execute it" comes from.
I believe that with enough plug-ins and a good enough language server, editors like VSCode can become more than well aware of Rust's syntax. 
&gt; Some people, naturally, feel that the norms spelled out in the rust CoC makes them feel excluded. To which all I can say is, yes, it's true: the rust CoC focuses on behaviour, not people, but if there's a person who cannot give up those behaviours, then implicitly it excludes such a person. Indeed. And I'd like to add: this is how I wish we could look upon these people - they are people, not trolls (which is a very dehumanizing term, IMO). From my view / experience, somewhat over-simplified - sensitive people will have a hard time getting work done when faced with insensitive behaviour, OTOH insensitive people will have a hard time getting work done if they have to spend a significant portion of cognitive load always adjusting to a world not allowing insensitive behaviour. That we can't work together is an unfortunate consequence of us being different. It does not make us better than them, just different. Edit: and to over-simplify a little less; it's not even us and them, we're all on this sensitivity scale where adjusting to a more sensitive world is taking cognitive load and adjusting to a less sensitive world also takes cognitive load.
Yes, that should work just as well.
You should consider the case in which you destructure a type in function argument position and then give default values to fields fully or partially, or to the whole object to see why an RFC about default arguments is not as straightforward as you think :) 
(i) note that this is not an RFC on default arguments :) it's an RFC on facilitating experimentation (ii) I'm sure all corner cases can be solved.. if destructuring really was a problem then we could say 'no destructuring of arguments with defaults' (destructure internally for convenience, the argument has to have one name to make it useable like a keyword ) ; I also envisage experiments working in layers , e.g. simple trailing defaults first, then the named stuff etc (its possible a destructuring scenario relates to why you might want a separate keyword syntax but personally i think the gap between 'no defaults' and 'some sort of defaults' is much bigger than 'defaults with some restrictions' and 'every case everyone wants handled' I know there would be debate on what syntax to use .. foo(arg2=...) or foo(arg2=&gt;...) or whatever. the fact that rust already closed of 'partial assignments' frees up the plain '=' nicely IMO.
Don't let this discourage you. Just start building your IDE. Even if you don't finish it, you are bound to learn something and create some code that might be useful for other projects!
Are you aware of the [Xi editor](https://github.com/google/xi-editor) and the [Rust Language Server](https://github.com/rust-lang-nursery/rls)? They are not exactly what you are looking for, but they are written in Rust, and both look to move the state of the art forward. Perhaps the Language Server protocol will have to be expanded to fit Rust's abstractions well. If that's the outcome, I think the entire editor ecosystem will be better for it :) That's my optimistic view, anyway :)
Bikeshedding about CoC's is just the *worst*.
Hi, please take your hate and bigotry elsewhere.
&gt; For the point of view of Rust compiler and crate, it's a single project. Then they're *not* separate packages, and they can't have different dependencies. If they're separate packages, then they each have their own `Cargo.toml`, and can have different dependencies.
Thank you for this. This is exactly what I mean.
Thanks for the response. I'm actually a relatively recent software developer and have yet to see what these industry conferences are like. I went to my first conference only a few months ago (RSA conference).
You could [write Emacs plugins in Haskell](https://github.com/knupfer/haskell-emacs) :D
How did I read it wrong? You explicitly stated that being white and male made you feel like an outsider in the presence of a CoC, and I tried to reassure you that wasn't the case.
Thanks, it works! So much nicer now!
&gt; Simple Rust is still order of magnitude faster than many other languages. While I'm sure you can find some really slow languages I think the languages of interest (OCaml, F#, Haskell, Scala etc.) are about as fast as simple Rust. In some cases I've been able to beat them with Rust but it requires a huge amount of effort. 
On the installation slide, you have this: Arch Linux: pacman -S rustup cargo But rustup and cargo can't actually be installed at the same time – rustup will install its own cargo wrapper and install different cargo versions alongside compiler versions, so the two packages conflict.
Nice! Have you heard of RedoxOS?
Running it over a small codebase i work on, the only difference is indeed the change in function arguments and parameters. I strongly prefer 'visual' style, so i'll be configuring that back!
&gt; The question and statement in my post were both made in earnest and in good faith as well. I don't think it is an inaccurate representation of what's going on in this thread in at least a few places. *"if someone takes issue with something you said or did, resist the urge to be defensive. Just stop doing what it was they complained about and apologize."* 
&gt; Aside from all the subjective pros and cons, I'm pretty sure that LLVM does not target all the architectures that Linux is currently available on, so replacing any important bit of the kernel with Rust would break those architectures. Would the effort required to make LLVM support these architectures be great even compared to the effort required to rewrite Linux?
When reading the headline I thought you were proposing to rewrite the whole kernel in Rust ;)
Rust evangelism strike force - assemble!
it doesn't.
The main scenario you need double casts in unsafe code is when you need a `*const u8` from some reference `&amp;T`. An `&amp;T` can only be converted to `*const T` - but then a `*const T` may be cast to `*const U` for any `U` (making sure there is correct alignment!). So you would see something like unsafe { call_my_c_function(&amp;t as *const _ as *const u8); }
I'm wondering what's Linus' take on Rust now, did he express his opinion on the language itself ?
http://cfp.rustconf.com/events announces that the CFP is closed, when 3 days ago you announced there was one week left. Could you clarify whether it's open or closed?
Reporting in.
You can look at existing code. I did some procedural macros recently, you can find it in the `shred-derive` folder of https://github.com/slide-rs/shred
probably yeah :p
Sarama is pretty bad. If you use Kafka as RabbitMQ then Sarama is _fine_. If you have a 5+ node Kafka cluster Sarama has really no builtins to deal with brokers dying, or partition group management, rebalancing, etc. Which these are regular events in a larger Kafka cluster so this is bad. To add insult to injury Sarama only lets you append a single kind of packet to itself. Umm Kafka's wireformat lets you batch dozens of read/metadata/status requests into a single packet. Sarama'a API doesn't. There is a fork of Sarama that has more Group Focused primatives/API calls. It is still in active development *and yes we're using it* 😑 --- There are _no_ good libraries. Most just wrap Sarama. One is wrapping Apache C library except the author quit part way though and never bound partition management, or broke death interfaces. --- Kafka changes its wire protocol and the semantics how _most things_ work with every major version. The policy is only to use OFFICIAL project libraries (Java, C, Python, Ruby) as any 3rd party library really starts falling behind quickly.
 &gt; That assumes that they are indeed sensitive, rather than manipulative Let met get this straight: I'm supposed to treat your concerns as though they're stated in good faith (rather than time-wasting, trolling or sealioning) but you're not going to treat the concerns of people who want a CoC as though they're stated in good faith? &gt; That means that you view your community as a sick ward or kindergarten that needs to be pacified and calmed down by the clique of "responsible adults". See, now you're really straining the "good faith" assumption I'm making by continuing this conversation by (somewhat egregiously) misrepresenting the analogy I made. The analogy I made was about "whether to argue with the person you hurt when you learn that you hurt them". The analogy was to put _yourself_ (i.e. the person-being-moderated) in the mental stance of _visiting_ someone sick in the hospital or _taking care of_ a child (or being on a date or trying to impress new friends at a party). I.e. context in which _you_ are the "responsible adult" in the context of someone who's maybe a bit more sensitive than you, and some _other_ responsible adult has just told you that you hurt the person you ostensibly care about. Not because your other community members are analogies for any of those things -- indeed the CoC asks you _not_ to try to hit on other community members, explicitly -- but because _those are environments in which you are actively concerned with being on your best behaviour_, in which you'll treat new information about having-hurt-someone as a thing you actively want to correct in your behaviour, not a crime you're being charged with that you have to argue a defense over. That's the point of the analogy. Not that you should patronize your peers, but that you should at least consider this community as a context for good behaviour on your part, consideration-of your peers. &gt; I have in mind the way the managers responsible for Firefox development alienate and drive away the extension writers. I haven't the slightest idea what this refers to. I haven't worked for Mozilla for years, and there's basically zero overlap between the extension review process and the folks working on Rust (certainly those of us who started Rust and set up the CoC had never worked with extension writers). As in: I don't even _know_ what concerns extension writers have related to Firefox (something to do with XUL and/or review times?) Anyways this is just pure hyperbole: Rust's community management stance and CoC was regularly considered _too strong_ for Mozilla. While I was there, the best they could adopt was a very watered down 1.0 version of "community participation guidelines" in which all forms of "exclusion" were considered equivalent; IOW the Rust CoC was a point of contention _because_ it included criteria for excluding people. They've very gradually moved to a more-standard acknowledgement that (say) social oppression and protected classes are actual things, but they had to be dragged there. It was never their initial stance. &gt; That assumes the complaint is genuine and not a way to bully people for their political views by claiming that their views "hurt your feelings". The "whispering" part of it is positively creepy. Given how far from the point your responses are getting, and the number of insinuations of bad-faith on the part of the moderators you seem unable to resist throwing into the conversation, I can't help feeling you're having this discussion in bad faith yourself, so I'm unlikely to continue it. As a parting suggestion: since your objections centre on the notion of a conspiracy theory in which "creepy" people "manipulate" you into "political views", I suggest reflecting on what it would take to convince you that the people involved are acting in good faith: that we really do just want to not-be-hurt and not-have-friends-hurt when going about our daily lives. And similarly, what type of feedback you would believe, and in which contexts, from someone who directly says they've been hurt. Are there any? Do you always and immediately switch to cross-examination and doubt, assumption of bad faith?
I'll be happier if he just doesn't comment. 
/u/aturon, do you know what's going on here?
for what it's worth new deadline on the CfP site has always been Friday (yesterday). not sure if that was intentional or not
It'd be a pretty cool project to have people choose a small chunk of the linux kernel, convert it to Rust, and keep that small chunk maintained with changes in the "real" linux kernel. It would probably be a pretty useless project for a long time, but hey. Maybe people can find bugs in the "real" linux kernel this way?
The second example on the page is exactly what you want. Is there something about it that you don't understand?
It's a sans-serif font … EDIT: my bad, doublehyphen is right.
&gt; &gt; That assumes that they are indeed sensitive, rather than manipulative &gt; &gt; Let met get this straight: I'm supposed to treat your concerns as though they're stated in good faith (rather than time-wasting, trolling or sealioning) but you're not going to treat the concerns of people who want a CoC as though they're stated in good faith? I am not asking to silence other people, so the burden of proof is not on me. Similarly, you are mistaken if you believe that I am trying to get you to treat my concerns in any particular way. My comments are not addressed to you, because people who exercise power, no matter how petty, are unlikely to be swayed by suggestion that their power is harmful and morally wrong. &gt; I.e. context in which you are the "responsible adult" in the context of someone who's maybe a bit more sensitive than you, and some other responsible adult has just told you that you hurt the person you ostensibly care about. I do not view other readers of this forum as children or mentally sick, and I do not consider myself more of an adult then they are. I suggest that the moderators have an obligation to do likewise. &gt; As a parting suggestion: since your objections centre on the notion of a conspiracy theory in which "creepy" people "manipulate" you into "political views", Thank you for that bit of gross misinterpretation. Let me assure you that I never assumed a tiny bit of good faith on your part, and persuading you has never been my goal. It's more along the line of exposing quasi-religious hypocrisy of unelected censors who claim to know better. To clarify your misinterpretation, my objection "centers" on the very explicit and entirely non-conspiratorial code of conduct that expressly forbids questioning the judgment of moderators and allows to ban people for their expressions elsewhere. &gt; I suggest reflecting on what it would take to convince you that the people involved are acting in good faith No reflection is needed to answer that question - they must refrain from arrogating the right to silence people they find objectionable. 
Looks like serif to me: http://imgur.com/a/QfnYW
The font is "Liberation Serif" here.
... done right :3
&gt; Why is it even useful to "meaningfully challenge" a moderator in the very venue they're moderating? For the same reason it is useful to challenge any other unelected censor in the venue they have power to silence you - because you can and should. &gt; It is completely possible to work out disagreements, even with moderators, without breaking the CoC. Not quite. *"if someone takes issue with something you said or did, resist the urge to be defensive. Just stop doing what it was they complained about and apologize."*
Thanks for sharing! This has been really helpful!
Thanks. Sounds like syn's docs need some love.
&gt;Has anyone considered trying to build an IDE entirely in Rust, e.g. using a Rust GUI toolkit I assume many have thought about it. It's just that building an IDE is a lot more work than beginners seem to assume. &gt;Perhaps syntax highlighting could do more (showing some hidden but useful information, lifetimes? inferred types? 'make identifiers that are similar types similar hues' .. You could probably do this one effectively with a vim plugin.
What I mean is that there is a lot of bugs that cause panic (so usually a crash) in Rust that are just undefined behaviors in unsafe languages that could be unnoticed, because they often does not cause a crash. So memory safety does prevent bugs to become vulnerabilities, but it does not prevent all crashes, it can even cause them.
Thanks, got what you meant now.
You're assuming I have a hidden agenda when I have nothing of the sort. I was explaining my own rational reasoning for a plausible explanation the emotions I was having, in response to /u/notyetawizard.
I knew that that wasn't the case. I know that many people here would think what you say. My point is that these things often end up not doing that however in the line of explaining why I have the emotions toward it I did. Basically the post was a statement, not something that needed any kind of reply so I'm confused why people are replying with reassurances.
How do you have this much free time?
Well if a moderator asks you to stop something, of course you're supposed to listen. But you are free to question that decision on the mailing list later. In fact, if someone else asks you to stop, you are also free to ask for clarification from the mods, in private. I don't really consider that to be a "rule" in the first place, it's more of a suggestion on how best to act to avoid conflict. It's a way of self-moderation -- instead of figuring out the rules to a T, just behave your best, and if someone -- anyone -- feels you're behaving inappropriately, assume they are correct. Even if it were a rule, it does not demand that you accede to it completely. Like I said, you are free to flag and wait for clarification (or email the mods for clarification), what it asks is that you do not immediately go on the defensive and make the situation _worse_. And "takes issue" is not about technical correctness -- if someone says you're wrong, you don't need to do anything. It's if you made someone feel attacked. (Yes, this can be abused, which is why I said you can always ask the mods for clarification). &gt; Foundation of a technical and scientific discussion is dedication to the truth. You are confusing them with the political discussion. Lack of civility is not necessary for truth. But, lack of civility does tend to muddy the waters in any technical discussion, so it does end up making it less technical.
&gt;The reason we _have_ terms in the CoC about this is _because this sort of argument happens_: it wastes everyone's time and at worst only authorizes people acting badly to continue acting badly. The only stance that works is to refuse to interact with the argument. You are right, it is much safer and comfortable to demand that no one dares to question your opinions and demands. After all, you are the responsible adult here, taking care of a roomful of children and mentally ill. 
I do plan to build a 100% rust IDE. I'm currently developing a rust GUI framework and I want to create a big project to be sure that it is production ready.
I think I've complained about this before -- but the problem with rewriting many such old C codebases is that these codebases don't have tests. Linux is a prime example of this; it has very few tests. In general this seems be indicative of a larger attitude amongst older C codebases. It depends on whether you're optimizing _writing_ or _modifying_ code. Tests slow down the process of writing code, but they make major modifications much easier. In general the benefit of Rust is also similar -- I do think that it's possible to write "reasonably safe" C, provided you write it _on your own_ (from scratch), and then never poke the code ever. It's the modification (and also collaboration with others) that gets tricky. Rust leaves you free to modify your code; C ... less so. Just like tests. 
 pub fn asm_syscall(ptr : *mut Syscall) { unsafe { } } and pub unsafe fn asm_syscall(ptr : *mut Syscall) { } aren't equivalent. `fn { unsafe {}}` encapsulates the unsafe code, meaning that you're assuring the programmer what will be using that function later that you were careful and code inside does work correctly, and can be called from safe code, while `unsafe fn {}` propagates the unsafetiness and can only be called from unsafe code.
&gt; I am not asking to silence other people You are asking to be allowed to yell loudly, which causes those unwilling or unable to yell equally loudly to shut up, if not leave. Yeah, sure, they chose to do so of their own free will and not because you directly said shut up or get out, but indirection doesn't make it less of a faux pas. ---- &gt;people who exercise power, no matter how petty, are unlikely to be swayed by suggestion that their power is harmful and morally wrong. You are attempting to exercise the informal power of an unfettered voice and willingness to linguistically brawl, for petty reasons, and attempts to suggest to you that you are being morally wrong and harmful isn't working. So, uh, yeah. You are correct.
One thing that I'd really like would be impl stubs: if I write `impl Foo for Bar`, it'd fill the function headers.
You are like AlexKryton.exe of Rust graphic libraries.
that would be pretty neat. It would be interesting even if it was instantiated by a dedicated dialog from a trait &amp; type browser .. but keeping your focus in the editor and having 'impl completion' would be awesome. imagine if they were ghosted, and you just navigate the cursor to the ones you actually want to implement (if there are defaults) 
Another idea - writing: #[derive(Debug)] struct Foo { //... } Could suggest: impl Foo { fn new() -&gt; Self { Default::default() } } Same could go for manual implementation of `Default`
&gt;&gt; I am not asking to silence other people &gt; &gt;You are asking to be allowed to yell loudly, Nope. I am neither more nor less loud than anyone else. I do not autopost nor do I rely on like-minded shills to create echo chamber the way /r/rust moderators do. I did not create the speech code, that explicitely silences people whose views moderators find objectionable, even when they are expressed elsewhere. &gt;which causes those unwilling or unable to yell equally loudly to shut up, if not leave. Expressing own views does not cause other people to act. &gt;Yeah, sure, they chose to do so of their own free will Quite so. &gt; and not because you directly said shut up or get out, Nor implied, demanded, suggested or desired, either. &gt; but indirection doesn't make it less of a faux pas. It is a form of aggression to blame other people for your own free choice. That's every bully's and abuser's war cry - "look what you've made me to do". &gt;&gt;people who exercise power, no matter how petty, are unlikely to be swayed by suggestion that their power is harmful and morally wrong. &gt; &gt;You are attempting to exercise the informal power of an unfettered voice No, I am not. You are exhibiting a sort of magical thinking, when you assert that reading things"makes" anyone to do anything. People are not computers programmed by what they hear. That kind of argument is routinely used to silence undesirable political views by all sorts of authoritarians. A bit like the author of the rust speech code, who thinks he is entitled to treat the rest as mentally incompetents and children. &gt; and willingness to linguistically brawl, for petty reasons, and attempts to suggest to you that you are being morally wrong and harmful isn't working. It is not morally wrong to express own political views, even if you happen to find them objectionable. It is, however, morally wrong to expect and enforce the specific set of philosophical and political opinions as a condition of participating in technical discussion. &gt;So, uh, yeah. You are correct. Quite so. 
"Or else"
You're very good at deliberately interpreting things in the way you find most useful to press your point. As I do not wish to try to lawyer my way through speaking with you, I am going to voluntarily withdraw. Congratulations on being louder than me.
This seems to work let tmp = ::core::mem::replace(self, &amp;mut []); *self = &amp;mut tmp[buf.len()..];
I would pay you a shiny halfpenny a month in exchange for writing a wrapper for every software library in existence. No need to thank me for my immense generosity
&gt;One is wrapping Apache C library except the author quit part way though and never bound partition management, or broke death interfaces. That is the one you mention. 
Regarding "Memory safe (no crashes)": There can be crashes for other reasons, like panic. Regarding "No runtime, no GC (runs everywhere)": A language with no runtime support creates a 1 KB executable program for an empty source program. Rustc creates a much larger file. So, there is a runtime support, it's the standard library. You can exclude it, though. It does not runs everywhere; it runs only on the supported platforms. Stack overflow is not prevented. Just run this: fn main() { main(); } Among the advantages, I think you should add: * No memory leak * No undefined behavior
Well I already called Moldbug a racist (by implication) and said I don't agree with his politics. I'm not sure what additional speaking up you would want to see. I didn't know anything about his writings on gender issues, although I'm not surprised in the least. I agree it would be *possible* to enforce a reasonable ban, but I'm not too hopeful it would actually happen. When you bow to the pressure tactics, the mob will see their power and push for more and more extreme demands. In other words, I feel the slippery slope is a very real concern, from what I've seen of these activist groups — and I have been paying plenty of attention. But ultimately this is about a chilling effect and a feeling of fear, not something that can be objectively quantified, and we may simply disagree on the degree to which it's real. I admire LambdaConf for taking a thorough and thoughtful approach to the issue, including talking to people from the groups that such a ban is supposed to protect. I'm not going to say they made the right call, but I'm glad they didn't simply choose the politically expedient route. I really don't want to see it as a fence between "social justice" and "not social justice" people. I care about these issues too and I have done various concrete things to help. At the same time, I find the activist communities toxic and try to keep my distance. It's not like participating in the daily yelling would help anyone anyway. It's a tricky thing that has no perfect resolution.
Actually, for the book, I think you can reuse some of the content in the slides [here](https://github.com/dtolnay/talks#macros-11--syn--quote). When I wanted to learn more about custom-derive, I started with watching the presentation. And it was enough to get me going. I found syn's documentation more than adequate afterwards.
I guess I'm more curious about the T definition of `&lt;T: PartialEq&lt;T&gt; + Clone&gt;`
&gt; That's the point. The code of conduct is there to state that the community will not welcome conduct that is not friendly, safe, and free of discrimination. While discriminating against whole ideologies and religions enforicing it. Let's be honest "no discrimination" means "don't discriminate against the people we like". The CoC for instance has some things against nudity; how do you think a nudist is going to feel reading the how-manieth piece on the internet subtly telling them their lifestyle is wrong and indecent? It's picking a couple of arbitrary ideals and making them sound more universal than they are and it just oozes "this was written by an American" all over it. It's the that-manieth example of American monoculture ignoring the rest of the world and acting like outside of their own culture and subjective standards is an irrelevant black void that needs no consideration.
I have put up [an implementation](https://docs.rs/stlog/0.1.0/stlog/) on crates.io.
(FYI: The Dreamwidth post is protected and requires a login to view. Not sure if you intended this.)
Thanks, updated.
With this module, configuration is just a few lines on top of the other TLS configuration: https://github.com/alex/ct-tools/blob/master/src/main.rs#L212-L224
What you're describing is an instance of [transference](https://en.wikipedia.org/wiki/Transference), which, in its general meaning, is redirecting strong feelings toward an individual or group towards other unrelated individuals or groups who may share similar characteristics. Some other contemporary examples from the news: * Some liberals are antifa protesters who will hit people on the head with a bike lock, therefore liberals support violence. * Some Trump supporters are literal Nazis who will cut the throats of those who stand up to them, therefore Trump supporters are Nazis. * Some Muslims are terrorists who like to blow people up, therefore Muslims are terrorists. * Some men rape women they barely know, therefore men are rapists. * Some startup founders are greedy sociopaths who will happily ignore every law they come across, therefore startups are scams. All of these statements are not only wrong, they are nonsensical: if you think about them on a logical level, they aren't even a valid syllogism. But *emotionally*, many people believe them. And there's a good reason why emotionally people believe them, because the emotional systems in our brain are meant to make snap judgments and assess threats based on limited information. The solution to this is to paint with a narrower brush. You (and really everybody, this is a massive epidemic in the world today) need to be aware of this dynamic, and explicitly make space in your brain for "I don't know, and I have no opinion", and then only form that opinion when you have personal experience with the *specific* situation you're looking at. That's why people here are asking you to be specific about instances where you have observed things *in the Rust community* that make you uncomfortable with how the CoC is applied. If it actually is used as a cudgel to silence reasonable people who have reasonable opinions that they express in a reasonable way, that's a problem. But you can't assume that because you have seen similar language in other communities that are filled with unreasonable people, it will apply to *this* community.
You cannot directly do this, as far as I know. Sometimes with traits, you can't know in advance where a function's implementation lives. You might already know this, but you can see the source code for any trait or struct by clicking on the `[src]` link that's on the right of a RustDoc. From there, you can use your browser's find-in-page tool to find where the function is implemented. This doesn't work 100% of the time, but for ordinary cases it will work.
[Update link](https://github.com/Kixunil/fast_fmt/blob/03f0adca10ef13b92501d59bc72d56f69963a232/src/lib.rs#L187-L189), since the link in the OP now links to the fixed version. if buf.len() &lt;= self.len() { self[0..buf.len()].copy_from_slice(buf); unsafe { *self = ::core::slice::from_raw_parts_mut(self.as_mut_ptr().offset(buf.len() as isize), self.len() - buf.len()); } Ok(())
&gt; Look, people have been making this "if you don't tolerate my intolerance, then you're the real intolerant one!" Yes, because that's what it comes down to; you arbitrarily pick the things you feel should not be tolerated and call the other side "intolerant" while saying that whatever you do is some-how better. You have rules against nudity, you're intolerant towards nudist and your rules are probably sexist (are they or not?); but that's arbitrarily fine. What swear words can and cannot be used is always arbitrary. You can go to a lot of places where you can't say "faggot" because it comes from a homophobic slur. Okay I get that but 95% of the time you _can_ say "bastard" some-how which comes from a slur against people who were born out of wedlock. This is completely arbitrary and purely comes down to "be like me and mind the things I arbitrarily mind" there is no rhyme nor reason to it. &gt; The CoC is extremely clear on what is welcome behaviour and what is not. I think there's no reading comprehension problem here, no "selling a lie". I never said it was unclear; I said it was pretentious acting like it is accepting to all people while it's basically mostly accepting towards mainstream American ideals it says: "We are committed to providing a friendly, safe and welcoming environment for all" You are doing no such thing; you are essentially excluding entire cultures where the norm is to be more direct than the US because those people are uncomfortable with that kind of level of communication. Linus Torvalds has often talked about the difference between US and Finnish business etiquette and from my experience with Finns he is right; what Americans often call "friendly" Finns will tend to perceive as disrespectful and dishonest and as a consequence become uncomfortable with it and stay out. &gt; So yes: the document welcome all kinds of people, but rejects certain behaviours. That's another way of saying it's not welcoming to all kinds of people. Behaviour and culture is what we are. People are essentially excluded based on their cultural background. &gt; if you're a "kind of person" to which those behaviours are unavoidable, then I guess it implicitly rejects you. If you'd like to file a bug against the moderation team to have them put both those points under a footnote and attach an asterisk to the word "all" in the first paragraph, go for it. I'm sure they'll oblige. "the kind of person" is like 90% of Finland and 75% of Wetern Europe in general. This is like me as a Dutch person making a CoC that says "We don't welcome people who ask how others are doing and don't mean it and don't want a ral answer." I mean I'm still welcoming to all right? Just not to people who are from a culture where that is common. &gt; I think calling this some kind of deception or hypocrisy is absurd. You can easily change your behaviour. People cannot easily change their skin colour, nor should they feel they have to. If you can't understand that difference, maybe go start a "rust, but with more bigotry" community. The CoC lists it wants to be anyone regardless of ethnicity and religion; it isn't. There are flat out things expected of people there which stroke against certain ethnicities and religions and I quite frankly think such a claim is impossible on its own. You _cannot_ be welcoming to all people because by being welcoming to one group you are automatically not welcoming to another. Being welcoming to homosexuals means being unwelcoming to fundamentalist Abrahamics. You can't escape this problem so just _say_ to whom you are welcoming and to whom you are not. You cannot make a place that is both welcoming to fundamentalist Christians and to homosexuals. So just be honest about whom you pick. &gt; (Also: I am not especially involved in the rust community anymore. I barely participate, except periodically in threads like this, wherein I burn a perfectly nice weekend defending the community's right to articulate its own norms.) &gt; Well, I'm Canadian, but whatever. Most criticisms of American norms of civility seem to imply that Canadian norms are even worse, so that probably won't get me far. Depends, obviously the whole Christian morality isn't as big in Canada but apart from that the usual criticisms Europeans have on US civility being over the top to the point of being fake applies to Canada as well. I was being perfetly clear that you have the prerogative to set your own norms but that I think it's pretentious that you claim it is something it is not. It is not welcoming to all people it is welcoming to people who are like you and in the end most communities do that. Some just act like they don't and some do.
[I made xvf, a small tool to extract archives on the command line.](https://github.com/g2p/xvf) It uses libseccomp to limit the attack surface (though there's still a lot; it's a shame this is not supported directly by tar &amp;co). It is inspired by dtrx (it won't create more than one file in the current directory), and uses some Linux-specific magic to make sure it can't overwrite existing files. Testers welcome!
There was one a LONG time ago but it's nothing like modern rust.
I will preface this entire post with this up front; I thought about deleting the entire post and just keeping this but I kept it, but really this is the core of my argument and the rest down there is just repeating much of the same: My point is not that this CoC is per se bad in and of itself fostering a community, my point is that it is pretentious in its claim of being "welcoming to all", it is very unwelcoming to a lot of people while being welcoming to other people and it remains to be seen which group is larger; that is all. ----- &gt; Sure. This does not exclude people who consider niceness to be something else. This excludes people incapable of acting nice in this way. The two are very different. While it is true that you do not ban people who have a different view on it you make it _unwelcoming_ for them in the same way tolerating homophobic remarks is often unwelcoming for homosexuals. &gt; The rules are pretty basic here. The core of them doesn't really differ across cultures. A lot of details may, but as I said we're more than willing to help people when it comes to that. I do not mean that the interpretation of it differs but that the acceptance of it does. People wil feel unwelcome due to a lot of the rules. I know perfectly well when I read "overtly sexual nickname" what that is going to mean and I also know that standard will 99% of the time be sexist but as someone who does not come from a culture that is phobic to the female nipple that alone makes me feel unwelcome. &gt; Sure, there are cultures where frankness is valued, but frankness and niceness are on orthogonal axes. You can be frank while being nice. You may not be used to that, but that is the expectation here. That's what people often say but in practice it comes down to watering down your opinion &gt; I don't see how this kind of bias is a problem; provided the mods are understanding of the fact that some folks may not know the expectations a priori. The mods are. We don't ban for non-blatant first offenses, we just tell people to "stop that", and help them understand what is considered ok. This has happened before. Banning is exceedingly rare here, aside from spammers and such. I don't see it as a problem to building a community either. Like I said it's your prerogative and it will attract a lot of people who would otherwise stay away and in reverse and it depends on where the large dev pool is. Linus has managed to build a very large dev community around opposite ideas and that also works well for him. Who knows, maybe the dev pool who likes this is larger and thus it becomes strategic to do it? My problem as I said is the _pretentiousness_ of saying the intention is to build a welcoming community "for all" while it's just for people like you. &gt; That wasn't one. I consider your argument to be projecting a lot of meaning into stuff that was never said. That's not what a personal attack is. That's not what the psychological phrase "projecting" means though; it means accusing others of something you do yourself because people are more likely to see flaws in others they themselves have. For instance it's been found that cheating spouses are more likely to expect their own spouse of cheating; that's an example of psychological projection. But fair enough; it's just a semantics thing really though maybe the word "extrapolation" is a better fit for what you mean.
Ownership and borrowing are a bit too deep for a Reddit comment. The Rust book has articles about these topics: https://doc.rust-lang.org/book/ownership.html https://doc.rust-lang.org/book/references-and-borrowing.html To briefly answer your question about the `'a` stuff, it's a way to indicate a "lifetime". In Rust, how long something is going to be valid memory for is part of its type. The `'a` in `Whatever&lt;'a&gt;` works a lot like the `T` in `LoremIpsum&lt;T&gt;`. Usually, you don't need to tell the compiler about lifetimes, because the compiler can guess by looking at your code. When the compiler can't do that, you have to explicitly tell the compiler about lifetimes, and the `'a` syntax is how you do that.
&gt; While it is true that you do not ban people who have a different view on it you make it unwelcoming for them in the same way tolerating homophobic remarks is often unwelcoming for homosexuals. That's a false equivalence. Being asked to behave in a slightly more constrained fashion is not the same as being asked to tolerate rejection of your identity. And no, the rules here are not rejection of identity, any more than the rules of a library are a rejection of talkative people. &gt; That's what people often say but in practice it comes down to watering down your opinion I disagree. In my experience the moment civility goes out the window the discussion tends to get muddied, not improved. People start misinterpreting things more when they're feeling attacked, and nothing good comes out of it. I have very rarely seen good technical discussions happen when civility is lost. I said this elsewhere in the thread, "Civility is not the antithesis of technical decision, it is its foundation". &gt; My problem as I said is the pretentiousness of saying the intention is to build a welcoming community "for all" while it's just for people like you. Again, it's not just for people like us. It's for people who are willing to behave that way within the confines of this community. That is not a big ask. Like I said that's something that happens in most social contexts anyway; your default behavior and the behavior the social context asks of you are different, and people adapt their behavior within the confines of that context. Yes, this excludes people incapable of interacting in the way we set out. It _does not exclude_ people who usually do not interact that way. This is an explicit tradeoff being made, and is the same tradeoff graydon was talking about. We're not sidestepping that, we own that. Where do we say "we include all people" anyway? We do say we try to be inclusive, but we're quite upfront about the behaviors we do not allow here. &gt; That's not what the psychological phrase "projecting" means though; Sorry, I didn't meant to use it that way. Apologies. Extrapolation is indeed what I meant; or "ascription of additional meaning".
One minor nitpick, obj is not the lightwave 3d format. It's more closely related to Maya (wavefront becoming alias wavefront and eventually bought by Autodesk) But otherwise this is really interesting!
&gt; Sorry, which of the behaviours listed in the CoC is unavoidable to 75% of Western Europe? I never said anything was unavoidable; I said it makes them feel _unwelcome_. There is a difference. THe CoC says it's welcoming to all and that's simply an impossibility. To be welcoming to some people you need to be unwelcoming to others as everyone is different. What in one culture is considered proper another considers improper. &gt; I disagree, at least in broad brush-strokes, as I know several of each who can tolerate the presence of the other. Tolerating is something else than feeling welcome. A fundamentalist Christian will feel unwelcome simply by stating that homosexuality is not a sin and wrong just as much as most people feel unwelcome when they see others state that slavery is not wrong. In their subjective morality homosexual acts are as immoral as murder. I don't think you are arguing about "being welcoming" to be honest given that you use phrases like "tolerating" and "unavoidable"
Any available code for the framework yet? 
You can use `where R: Read` and let the library user decide where the file comes from. At least that's how I do it. But thanks, I wanted to get into writing parsers with nom, obj is a much more simpler file format than the current examples.
I seriously don't know what you think could be written there that would make it clearer. Yes, there's a form of symmetry-of-welcoming-feelings baked into the list of ways in which people vary, while still expecting to feel welcomed in the rust community. No, if you happen to be unable to welcome (say) gay people into your community, then you're not welcome to hang around the space making them feel unwelcome. Because "being unwelcoming to gay people" is not a thing we're explicitly saying we welcome. Maybe you thought it was implied by "all", but it's not. Only "all" in the sense of kinds-of-person, not "all" in the sense of general attitudes-towards-welcoming-ness. Indeed, being welcoming _in general_ is an important symmetry in the list: the rude Linus-Torvalds example you bring up is a fine case in point. He'd probably not feel welcome here, because he feels like the _very idea_ of being welcoming by default is offensive. That's actually not a Finnish thing, regardless of what Linus claims (I've met plenty of Finns who are happy to be polite, and plenty of jerks who don't like being welcoming who aren't Finns) but yes, that symmetry exists. If you look at a phrase that starts with "we welcome all" and think "pfft, welcoming is for chumps, what smarmy american garbage!" then you'd be better off somewhere else. Definitely. I reject (on the basis of meeting lots of exceptions to the rule) the idea that the _broad_ categories of people to whom welcome-extending is listed are mutually exclusive with welcoming of one another; certainly all nationalities and major religions have substantial groups of people happy to be welcoming to more-or-less all others. I accept that there are probably some _narrow_ sub-categories within each who are mutually incompatible with extending-welcome-to-one-another, just as there are individuals who scoff at the idea, but they can all probably tell just by looking a the list (and by knowledge of their own strict views) that they'll be unable to participate in good faith. I don't know that trying to isolate-and-enumerate all those subgroups or individuals would be terribly fruitful (and it would make the CoC dramatically longer, for .. unclear utility). Would more asterisks and caveats to this extent make you feel better / less like the aspiration of the CoC is hypocritical? I'm sure you could petition the mods to clarify the language a bit. That portion hasn't been changed / updated in a while, I think.
You could let the user supply named mtl datasets alongside the obj data.
&gt; Is there (or could there be) a means of enforcing completion in the builder pattern use case.. I think something similar also appears in iterator chaining (blah blah blah .collect()) Apply a `#[must_use = "explanation"]` annotation to the struct that represents an un-completed builder. Here's [a playground example](https://is.gd/YUeBjA) of the message you get when you forget to consume an iterator adapter, thanks to that annotation, combined with a `deny(...)` to change it from a warning to a compiler error. The idea behind it being that, if you really do want to discard a `must_use` thing, like a `Result`, you explicitly discard it by prefixing the complaining line with `let _ =`. &amp;nbsp; &gt; I seem to remember talk of 'linear types', but I wasn't sure if this refered to 'types used at most once', or 'types that MUST be used once'. https://en.wikipedia.org/wiki/Substructural_type_system#Linear_type_systems Affine types are the "at most once" kind (what Rust has) and linear types are the "exactly once" kind. From your link: &gt; Affine types are a version of linear types allowing to discard (i.e. not use) a resource, corresponding to affine logic. An affine resource can only be used once, while a linear one must be used once. &amp;nbsp; The problem with linear types is that real, full-blown linear types would be painful to have in Rust. Here's a post that [showed up](https://www.reddit.com/r/rust/comments/6a3ac4/the_pain_of_real_linear_types_in_rust/) in this subreddit just under a month ago about why linear types in Rust [would be a pain to implement at the compiler level](https://gankro.github.io/blah/linear-rust/). &amp;nbsp; I'm in favour of [this RFC](https://github.com/rust-lang/rfcs/pull/1940), which would extend the `#[must_use]` annotation to work on functions, so you don't have to return a custom type just to hang a `#[must_use]` off a function where it would be natural to return something else.
While this is achievable with `#[must_use]`, I can't imagine a case where one would accidentally forget to use it. Think about it: let file = OpenOptions::new().read(true).write(true).create(true); // Now we will use that file. Why would we create it otherwise? file.write(&amp;[1, 2, 3]).unwrap(); If you write this code, you get type mismatch or unimplemented method error. `#[must_use]` would be useless here. Do you have any example where this wouldn't be the case?
No, but the moderation should not be political.
You don't have to accept the equivalence, only that it also exists. The heart of this problem lies in insensitive people sensitive people not understanding each other. Of course, sensitive people suffer more from it, but that does not mean that we can trivialize the problems for insensitive people. Doing so will alienate these people, which is the exact opposite of what we are trying to achieve. False equivalences is a serious problem, but dealing with them must involve first acknowledging the second problem before pointing out why it is not equivalent.
Rust is not meant to eliminate unsafe code. It is meant to put unsafe code in specifically delimited blocks, to 1) limit the use of unsafe code to the minimum amount necessary, and 2) if/when memory safety bugs occur, it can always be traced back to an unsafe block. Because of Rust's safety rules, many structures and patterns can't be implemented using purely safe code. The idiomatic way to use Rust is to implement these using unsafe blocks, and provide a safe API that wraps the unsafe code. Box is an example of this. Because it manually allocates and handles raw pointers, it requires the use of unsafe to implement. However, the external API that Box provides is safe to use, so this means that you can use Box without worrying about memory safety. This is idiomatic systems programming in Rust. Don't avoid unsafe, instead write patterns and structures that require unsafe to implement, then wrap them in a safe API so that the unsafe is all inside the internal implementation and not exposed to whomever uses the external API.
So basically you're saying that Rust claims to be safe, but that's invalid because memory allocations are using `unsafe`? It's true that not everything is possible in safe Rust, but very much is. The standard library is of course using `unsafe`, but that's a good thing, because it builds safe abstractions around it. There are many crates working without `unsafe`, and even if you need it: It's just a few lines and the good thing is that you're sort-of warned: "Please read the docs for these items twice and double-check what you're doing is indeed free of data races, memory leaks and other UB". I think a great example of how much you can do is Redox. From https://doc.redox-os.org/book/introduction/unsafes.html : &gt; A quick grep gives us some stats: the kernel has about 70 invocations of unsafe in about 4500 lines of code overall. I mean, this is an OS, which definitely has to deal with low-level stuff a lot, so I'd call this a win, having 4430 lines covered by the Rust compiler. Another thing I noticed after learning Rust is that by studying the errors the compiler is giving you, it's much clearer what is safe and what is not. So even if you need `unsafe` to get the maximum speed occasionally, you know what you should and what you should not do (as opposed to writing code in C, at least that applies for me). It's okay to criticize, but don't use "lies about safety" in the title, because that's just wrong. It's the same as calling Java not safe because it uses a GC, thus sacrifices performance for safety.
"In C/C++, you cannot write an API that exposes pointers or references (or one which is not thread-safe) and which cannot be misused." It seems that the same argument could be made for Rust considering the existence of unsafe block though... right ? As far as I know in C++ you could easily write an API that only exposes shared or uniq pointers and, if good ownership semantics are needed, you could cut that down to "only exposes uniq pointers". Obviously people could break the implicit contract with the API and cast/use these to raw pointers and constant cast the values they hold (if the API returns values which shouldn't be modified), but those types of actions are bad practice and you can compile code in such a way that it warns you or refuses to compile if you try to do things like const_cast. So in a sense it seems to me like you are in a similar situation, only that C++ places you in the "unsafe" block by default and you have to make sure you make the code safe yourself. Which seems closer to a philosophical&amp;legacy-based decision which could be easily overwriten with a compiler that break backward compatibility and adds safe/unsafe blocks to C++. I would probably be harder in the case of C, since C hasn't standardized abstractions like shared pointers, but the same principle would apply. 
Okay, I think I understand better. As other have mentioned, `unsafe` is not to be avoided at all costs: it's to be avoided unless necessary. It may be necessary to use `unsafe` when talking to hardware, for performance reasons, ... In general, good programming practices will favor *modularity* of design, also known as *high cohesion/low-coupling*. Well, *modularity* is also a good programming practice in Rust, and also applies to `unsafe`! In particular, *modularity* mean that the amount of `unsafe` code should (1) be minimal and (2) tucked away behind a safe interface^1 . It's paramount to understand that Rust is *pragmatic*. There has been no successful language in the industry that was both 100% safe and matching C and C++ speed. Rust does not reverse this, but it makes serious inroads and tries to tend toward 100% safety as much as *practical*. The morale is simple: don't throw away the baby with the bathwater! Just because 100% safety has not been achieved for a systems programming language doesn't mean we cannot raise the bar to 99% safety. ^1 *The benefits of tucking away `unsafe` behind a safe interface is that it's much easier to exhaustively check a small amount of code (and fuzz it), than it is to exhaustively check an entire program.*
I wish that `unsafe` should have been named something like `i_think_this_block_is_safe`. And maybe in the future we can have something like: `i_proved_this_block_is_safe`
Rust is in many ways similar to Modern c++ and there are many c++-features that help a lot in building reliable software, but c++ lacks a borrow-checker and some thread-safety features. For example rust can prevent you from sharing non-threadsafe type across threads, it prevents you from modifing a collection while iterating over the content and prevents you from accessing the content of a mutex after calling unlock.
Well. A similar idea exists in language like C++, that use the exception mechanism to allow isolation of unsafe code and provide fallback in case of errors, can have compiler can throw warnings or errors for unsafe behavior (e.g. const_casting, creating raw pointers, implicit casting) can mark functions noexcept and const... etc. But this makes rust seem more like syntactic sugar over the problem rather than a solution. Maybe 99.99% of the code written in RUST around the word will be outside of unsafe blocks, but if the truly complex code is inside unsafe blocks than you aren't accomplishing that much when it comes to improving the design of complex systems. I mean, I agree that, if I could change the world we live in I would make C/C++ require mut ahead of a variable to allow you to modify it instead of const to make it immutable, but is this kind of syntactic sugar worth the amount of re-write you'd have to do in order to port systems over or make old systems compatible with the new ones ?
And would these kind of checks be impossible if someone with enough know-how in writing parsers, semantic analyzers and other such esoteric tools for understanding code would implement them in one of the many open source compilers ? It seems that many of these mechanisms aren't enforced or enabled in modern C++ because they would break backwards compatibility or because nobody has bothered to actually write them or standardize them, possibly because things like multi-threading are quickly evolving problems and the way we thing about these sort of problems now might not be the way we think about them in 10 years when hardware that exposes hundreds of processors might be commonplace.
&gt; Sadly enough the same can't be said about things like "Box" in RUST. This is something that has always struck me a bit odd, that a language which is designed to write-systems wouldn't allow you to very easily re-write a version of the fundamental mechanisms it uses for dynamic memory allocation. In a language, 'safety' means preventing the programmer from doing certain things. The safer a language is, the more things they are prevented from doing. Mostly, they are prevented from doing undesirable things, but, unfortunately, they are also prevented from doing some desirable things. Therefore, the safer a language, the more desirable things there are that have to be implemented as unsafe code. For example, consider the JVM languages. Anything running on top of the JVM is really quite safe (well, as long as you don't use threads) - but to achieve that, the JVM itself has to contain a lot of highly unsafe code. Much more so than in Rust's standard library. 
 &gt; Would people prefer to see the dependencies kept as minimal as possible, to the point of ditching error-chain, As the maintainer of dbus-rs, I feel a bit silly if I'm just depending on libc, and then have to bring in 10+ other crates just for compilation, so I guess I prefer this approach - but I'm not sure how big serde is and how many crates that means...? Btw, I assume there is no way to break dependencies between toml and serde via features? Would such a feature be feasible to add to the new toml parser version?
It's possible, but hard and has a lot of other costs. A lot of code has to be adjusted or annotated in a way, that allows tracking of lifetimes. Existing code often has to be restructured in a way that and allows static checks. c++ is very complex, has lots of traps, and adding more changes is not just hard, but also makes the total even more complex. The total cost of applying such a tool may be in about the same range as switching to rust. Rust has also a lot more to offer than just safety. Of course it is not feasible to port existing, large projects to rust, but using rust for a new project or gradually porting critical software may be quite useful. &gt; possibly because things like multi-threading are quickly evolving problems and the way we thing about these sort of problems now might not be the way we think about them in 10 years when hardware that exposes hundreds of processors might be commonplace. Threading is not directly built into the language. Rusts core language does little more than tracking aliasing of references, so that code may not accidentally access other threads' data in a unsafe way. The other high-level abstractions are implemented in libraries by using generics. This is very similar to c++, that uses templates for these abstractions.
Well, that was and still is the advantage of C++ over C, that and the fact that as a C programmer you can ease into C++ rather than learn all of it at once. Yet the industries that could really use the added safety and human-readable abstractions in their code (e.g. aerospace, automotive, medical devices, networking... etc) seem to stick to C mainly due to myths and the fact that they feel more at home with the language. You can get mounds of comments from programmers that refuse to accept RAII because constructors&amp;destructors might generate instructions that are not easy to spot without disassembling the code or because "you should always be explicit when releasing a certain resource". I mean, you will have people argue that they prefer macros to templates and other mechanism of compile-time code generation and checking such as constexprs. Mind you I haven't talked much with people from those communities but there are various talks and posts and even papers on the subject, a great on being [this](https://www.youtube.com/watch?v=D7Sd8A6_fYU) Further more when the industries that do program the kind of systems where making assertions about safety of code is needed but garbage collection and virtual machine might get in the way to code that is efficient enough will switch to a language it will likely be C++, not Rust, due to the fact that once the old guard retire and/or dies the remaining programmers will likely want to switch to the language they are familiar with. But at this point we get more into a social argument or a discussion about weather or not it would be better to improve the tools that are and will be used or create tools and hope that people will switch to them. To the extent that is now visible, it does seem that Rust has gained enough attention to be considered more than a toy language, but currently I'm yet to see any large projects that have reached the 1. version and are written in Rust, then again, there is still time and I do hope to be proven wrong when it comes to my previous assumption.
&gt; Well, that was and still is the advantage of C++ over C, that and the fact that as a C programmer you can ease into C++ rather than learn all of it at once. I'm not sure what you're referring to. (eg. I find C and C++ more or less equally stressful to audit for safety, so I avoid both as "too unsafe".) &gt; To the extent that is now visible, it does seem that Rust has gained enough attention to be considered more than a toy language, but currently I'm yet to see any large projects that have reached the 1. version and are written in Rust, then again, there is still time and I do hope to be proven wrong when it comes to my previous assumption. Bear in mind that Rust as a stable programming language is very young. Rust 1.0 just had its second birthday less than a month ago and, while they're not releasing publicly, companies like Dropbox do use Rust in production in their storage backends.
Yes, of course. For example, this program prints an unpredictable number: fn main() { unsafe { print!("{}", std::mem::uninitialized::&lt;u32&gt;()); } } I should have written: No undefined behavior in code not marked as "unsafe". 
&gt; Maybe 99.99% of the code written in RUST around the word will be outside of unsafe blocks, but if the truly complex code is inside unsafe blocks than you aren't accomplishing that much when it comes to improving the design of complex systems. I think you underestimate the amount of errors happen in normal/glue-ing (non-complex) code. 99% of memory error happens outside of core complex logic (since the complex one will be carefully reviewed/verified/fuzzed/proved). &gt; I mean, I agree that, if I could change the world we live in I would make C/C++ require mut ahead of a variable to allow you to modify it instead of const to make it immutable, but is this kind of syntactic sugar worth the amount of re-write you'd have to do in order to port systems over or make old systems compatible with the new ones ? I don't think it worth, but you can do that incrementally using FFI.
Indeed it works great now. I never would think of that especially it worked on Chrome. Thanks!
Have a read of [this](http://blog.japaric.io/quickstart/). It goes over how you would use Rust to control hardware, starting with the most basic thing possible, using `unsafe` and raw pointers, and then introducing a library `svd2rust` which uses manufacturer supplied documentation to generate a safe zero-cost wrapper around raw reads/writes to IO addresses. It can generate enums and methods such that it isn't possible to write an invalid value to an IO register, and this too will compile down to the same as if you had written it manually, but just removes the possibility of making low-level mistakes.
My pleasure :)
It doesn't matter that you can follow some rules (although in practice we have use-after-free after use-after-free getting assigned CVEs). It only matters if *the compiler can catch mistakes*. I can't give you any examples that are still a problem to a hypothetical superhuman. You've "invalidated" my argument by shifting the burden of correct use of abstraction to the programmer - I can't "win" under those conditions, since they form a world I assumed as not being the same one I inhabit.
Just because something uses the `unsafe` keyword doesn't mean that it is unsafe. Unless you can calling an `unsafe fn`, then you can rest assured that any `unsafe` keyword usage within a safe function is safe. The keyword exists merely to provide caution when using the function. If your usage is safe, then you don't have to mark your function as unsafe. Collections making use of unsafe doesn't mean they are unsafe, just that they have been optimized with unsafe functions that are proven safe through extensive unit tests. As for memory allocations, there is no such thing as safe I/O operations, and so there is no such thing as a safe memory allocation. There's always a potential for an error such as out of memory errors. You should throw away that notion completely.
Maybe you misunderstood my proposition. I didn't propose to you: "Given the same requirements I can write safe C++ code that does the same as Rust" but rather, "given the requirements for an interface through which one can access a structure, e.g. hashtable, I could probably write a similar interface in C++ as the one which is currently used by Rust". You assumption, as I understood it, was that you can't write a HashMap in C++ so that it provides the same safety features it does in Rust. However to understand exactly what you think those safety features are, I asked for a few examples of "wrong" and "right" ussage that I would quickly be able to test against, since I'm not that good at reading dozens of pages of language specifications. My assumption here being that compile time checks could probably catch a lot of the errors rust compiler catches if people were to write interfaces similar to rust's over more fundamental data structures.
consider posting this to /r/playrust/ you have a wider audience over there. this subreddit is for the people enjoying the rust programming language. have a nice day :)
Borrow checking (no overlapping mutation aka iterator invalidation): vector&lt;int&gt; v; v.push_back(123); int &amp;r = v.at(0); // Can also clear &amp; shrink_to_fit etc. // In Rust this step doesn't compile because r borrows v. v.reserve(v.capacity() + 1); // Use dangling pointer. r++; The `Entry` API is a harder version of this because it's more flexible than just "reference to existing element".
Every single safe construct has unsafe foundations, that's not even limited to programming languages. Pretty all cryptography relies on the fact that the hardware and the underlying OS is safe. The idea is that by concentrating all the unsafe parts, it becomes easier to ensure the safety of the entire system. For example by having much stricter peer review requirements for those parts, or proofs of correctness. And you're right, it _is_ possible to write safe and reliable C++ code. The language has plenty of construct to help developers by now. And on top of that, the are "good practices", such as _Aliasing XOR Mutability_, which should help as well. C++ doesn't enforce these practices though, and programmers really shouldn't trust themselves to follow those rules themselves. Rust has received criticism from some respected developers exactly because they felt _they_ should be allowed to violate aliasing XOR mutability -- since that's what their current C implementation does. I cannot recommend [this](https://web.stanford.edu/~engler/BLOC-coverity.pdf) paper enough. There are a lot of C developers who think their experience is enough to write reliable software. And only a fraction of them are even aware that undefined behaviors exist -- even though they claim to "know" C. A few weeks after reading that paper, I had a job interview at a particular company whose service routers power about 25% of the internet's backbone. They were adamant that Coverity has lots of false positives on their code base, they had never heard of undefined behavior and were convinced it was something academic after I explained it to them. If you think the same, I recommend [this](https://people.csail.mit.edu/nickolai/papers/wang-undef-2012-08-21.pdf) paper as well. What I'm trying to say is, the security features in C and C++ aren't any good if its users _think_ they don't need it. Rust isn't perfect yet either, but code written in Rust is a lot less likely to silently break. The Rust compiler prefers to shout instead. Edit: I just read one of your other comments, it probably is possible to do provide some of Rust's safety to C and C++ through analysis tools. But as Coverity's paper discusses, people tend to ignore the results of an analysis tool -- sometimes even convincing themselves that it's a false positive. 
"Yes" as in there's something you don't understand? Can you explain in more detail?
If you are writing most of the code yourself without external dependencies, I personally would go Rust (unless you are already pro-efficient in C++), specially if you plan to multithread code extensively. If you need extensive library support (ie. using TensorFlow) I would go C++ and this still is very inmature in Rust (even binding), but then again I would just do it in a GC language in this case. * Difficult to write data structures with cyclic references like graphs. Is not more difficult than in C++, for complex cases, if you care about multi-threading etc. you want to use smart pointers most likely, or have to use unsafe code, which is what you would be doing in C++ (or using std smart pointers too). As for employability concerns, maybe, but I think to show off you know about the issue (algorithm and data type design) is more important in this case than the language you are using. You can always work on C++ projects if you need in the future if you want to learn or build up resume. 
Ok. I will admit that I expected to find a compiler flag that would specifically warn against using behavior that move the vector from memory, this behavior to being with and I'm rather disappointed I couldn't find one for either clang or g++. I'm actually curios if these type of errors could be triggered in rust and if there's a way better than smart pointers to stop them in C++, without re-writing or wrapping functions like reserver.
[yes](https://www.reddit.com/r/rust/comments/6alh8k/nwg_a_gui_library_for_windows/)
Are you claiming that having to audit/test exhaustively 0.01% of the code is as daunting a prospect as having to audit/test exhaustively 100% of it, even though there's literally a 10.000 factor? Also, you seem to be assuming that all code is born equal, but it's not. In C++, any little bit of code has to be audited and cross-checked for safety; lest the whole process dies in flame for something as stupid as a dangling reference or a datarace. In Rust, those checks are concentrated in the 0.01% of the code that is clearly delineated with the `unsafe` keyword. This lets you: - ensure that only experts/seniors are allowed to stamp a commit with a modification in `unsafe` code, - raise the bar for test coverage on `unsafe` code, - ... Will this catch all bugs? Of course not. However it leads to stories like [Fuzzing is magic - Or how I found a panic in Rust's regex library](https://www.nibor.org/blog/fuzzing-is-magic---or-how-i-found-a-panic-in-rusts-regex-library/). In most C or C++ regex libraries, [fuzzing would uncover memory corruptions, exploits, etc...](https://blog.fuzzing-project.org/29-Heap-Overflow-in-PCRE.html) in Rust it discovers a panic, which is unpleasant, but **safe**. So, clearly, it seems to working rather well in practice.
In my observation (3 years), the moderation has not been political. Of course there may have been things going on behind the scenes, but I think I would have heard of them. With that said, I think it is fair to say that the CoC has an ideological tilt, and with different moderator behavior, things could become hostile to people with certain political/ideological beliefs, even if those people behaved perfectly well towards every member of the community. That's because moderators have power. Every healthy community has to have mechanisms to hold people in power accountable (to the whole community, not just the founders). So far it seems that the Rust moderators have exercised their power responsibly and the community has avoided any schismatic crisis. I honestly haven't investigated how the Rust moderators are selected and held to account (it's not something I'm really worried about). That may be a topic open to constructive dialog. At the end of the day, by virtue of freedom of association, private communities have the absolute right to establish rules of participation. I certainly suspect that I have views at odds with some prominent members of the community. That's fine, because those views are in areas wildly off-topic for a software project. I'm happy to accede to the behavioral norms of the community to enjoy the benefits of participation. I suspect that by this point the community is too large and probably too diverse to try to enforce an ideological agenda completely divorced from particpant's inter-personal behavior.
Rust is ***fearless concurrency***, your post is irrelevant here.
Maybe if Rust was written in Rust, it would be better optimized for lower end machines.
Hi, I suggest this chapter of the Nomicon: [Meet Safe and Unsafe](https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html), and perhaps other chapters too, like [How Safe and Unsafe Interact](https://doc.rust-lang.org/nomicon/safe-unsafe-meaning.html). The thing is, every safe language is built upon unsafe abstractions. On any language (even safe ones), the code that implements features such as memory allocation and FFI is "unsafe" because an error on them may lead to undefined behavior. For example, a bug in CPython, or in a Cython extension, or in a C dependency such as OpenSSL may cause a Python program to trigger undefined behavior. But we still don't say Python is unsafe: the bug in each case was in a code written in C, and it's never, ever acceptable to burden safe code with ensuring that safety invariants aren't broken. I mean, we wouldn't write a Python function whose documentation says that it may cause UB if it's called with wrong parameters; we should check whether the parameters are right and throw a Python exception if they are not. Rust combines the safe and unsafe languages: its safe subset is safe like Python and its unsafe superset is unsafe like C (well UB in Rust is more delimited than in C but that's not important). And if there is ever undefined behavior, it's always possible to pinpoint to a (hopefully small) unsafe block that caused it. With Rust, you can program a very large portion of a kernel in safe code, that is, code that doesn't need to care about memory safety (check the Redox and Tock projects for example). That is amazing. It's as if you could write kernels in Python (with a handful of low level C libraries underneath) but without needing a GC. &gt; Notice something here ? unsafe, unsafe, unsafe, unsafe, unsafe... I don't believe there is one basic collection in the rust stdlib that doesn't contain several unsafe blocks. Data structures in Rust are supposed to use `unsafe` whenever necessary for performance, yeah. It's not a big deal if they need `unsafe` because you tend to write a data structure once and use it many times; the users of the structure will hopefully need no unsafe code. However, if a data structure can get away with having no `unsafe` blocks in their own code, they should. It's a plus. For example, here is an interesting book: [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/). The author implements many linked lists; he begins with no unsafe code, using `Box` to manage his memory. Now, we know that `Box` uses unsafe code underneath, but this is an implementation detail; it's just like memory allocation in Python (or Java or Go) which is implemented with an unsafe code underneath (generally in C). If this unsafe code is correct, there is no problem. Some years ago, when Rust was a different language than it is today, `Box` was built in the compiler (you wrote `~T` instead of `Box&lt;T&gt;`). That way, the compiler handled the unsafe abstraction, not some `unsafe` block in Rust code. But you would still need to check that compiler is handling this right, just like you need to check the `unsafe` block is right today. The stdlib is full of unsafe code because it's supposed to provide abstractions for the entire Rust ecosystem, and many such abstractions encapsulate unsafe details in safe interfaces. It has `unsafe` blocks so that your own code won't need to have them. This is a good thing.
Cool! As a suggestion, could this link be put somewhere into the README? https://wiki.gnome.org/Projects/GtkSourceView
Good suggestion! Adding it.
Hmm first I'd heard of the Ion shell. Shame it looks like it replicates most of the mistakes of every other shell out there (except Powershell).
This isn't my post! The author is /u/lloydmeta.
They offer a path from public struct fields if you need to deprecate/rename/move something without breaking code. If the compiler can be updated to fix the issues with borrows taking the whole struct, it'll be an alternative to getters and setters.
&gt; I do not represent the community. I got a contemptuous feel from your comment, and not an invitation for discussion. So I was just curious about what your thoughts were. May be it's just me. (Though, yeah, I was also being disrespectful towards you; for which I apologize.) I am also sorry in this case. But you have to recognize that the standard community response when someone challenges the "let's rewrite x in Rust" is in tone with yours. Actually you can replace Rust with any other language in that sentence. 
&gt; There are certain things about being a programmer that you don't get to experience until you have to work on a consistent basis on a medium or large project. While you can learn a programming language (or two or more) without being a CS major or working as a programmer... (I'll quote myself) &gt; There are certain things about being a programmer that you don't get to experience until you have to work on a consistent basis on a medium or large project. So I tend to dismiss any proposal of changing something to be more in line with what's hot at the moment when it comes from these people. As I said: what about keeping up with the new features and bug fixes that are added? What about testing? What about actually redesigning the system? These are not trivial things, and if we want to talk about rewriting a large project (or only parts of it) in another language we must talk about these things. 
Regarding WFI, would core go to sleep if there is a pending interrupt? Shouldn't it just treat WFI as NOP in such case?
Well the ARM manual doesn't make it sound like that to me: &gt; WFI is a hint instruction that suspends execution until one of the following events occurs: ... "that suspends execution" sound definitive to me but maybe the word "hint" is the fine print in the contract because I tested and, yes, WFI doesn't suspend execution if there's an interrupt pending. EDIT: Updated the blog post to point out this.
You can actually use https://github.com/dtolnay/proc-macro-hack to make this work on stable!
&gt; Depends on what you are using it for. I believe there might be problems for which GC is much better. GC is much better for basically everything except ultra low latency or extremely memory constrained and in both cases GC is the least of your worries. &gt; Not needing GC doesn't mean not having GC, though! But it may mean not having a decent GC. &gt; While Rust doesn't have GC right now, there are some people who want to introduce Gc&lt;T&gt;. That'd be cool, I think. I disagree. I assume a `Gc&lt;T&gt;` will be kept alive until the end of scope by Rust's own memory management, in which case you aren't benefitting from the results of liveness analysis to recycle values before the end of scope which all production GCs do. Another problem is stack walking. How can you identify all global roots including those on thread stacks efficiently? I don't see how that can be done within the current confines of Rust. Finally, I read some of the blog posts about GC work in Rust and it is insanely complicated compared to writing a GC from scratch. &gt; Well, in Rust I almost don't allocate. If I allocate, it's almost guaranteed to live for a long time. I think the key here is unboxing. Look at this OCaml/F# example: Array.fold (fun (x0, x1) x -&gt; min x0 x, max x x1) (infinity, -infinity) xs That loops over the floating point elements of an array `xs` and returns a pair of the smallest and largest element. In those languages every pair is heap allocated, the vast majority of which live only for one iteration of the inner loop (just a few instructions). In OCaml, each of the two floating point numbers in every pair are also heap allocated individually. This leads to insane allocation rates. The OCaml community even boast about their insane allocation rates. The run-times are optimised for this using generational garbage collection so all these short-lived objects can be collected efficiently. The problem here is that "efficiently" collecting values that were needlessly allocated is actually really inefficient. Objectively, this is insane. If you gave that program specification to any half decent C programmer they would trivially solve the problem with zero allocations. Furthermore, C would require only marginally more code to do this. However, my perspective is not that GC is bad but, rather, that data representations that lead to insane allocation rates are bad. Everything should be stored unboxed whenever possible. Discarding GC because of this problem is throwing the baby out with the bath water. &gt; But even then, having short pauses more often is better than having long pauses less often in real time systems. In real time systems shorter pause times are great, of course. The question is how to get short pause times. Rust's approach does not naturally lead to short pause times and, in fact, I doubt it even reduces pause times over many GCs because it defers collection to the end of scope and those deallocations can avalanche so worst case pause times are unbounded with Rust which is certainly worse than any decent tracing GC. &gt; RAII solves another important problem: it manages other resources like open files, connections, locks... True but RAII is a highly invasive solution to that problem and particularly bad when combined with OOP. Class hierarchies end up requiring virtual destructors everywhere. Callers cannot tell which destructors are no-ops at compile time so they call all virtual destructors at the end of scope. So those are all expensive virtual calls to no-op functions. Using RAII for all deallocation means garbage is always leaked to the end of scope which means lots of floating garbage, increased memory allocation and increased register pressure because references to all objects must be kept alive even if liveness analysis has proven that the objects cannot be used again. And exceptions are much slower because rather than `longjmp`ing up the stack you must unwind every stack frame in order to call all the destructors (most of which are probably no-ops!). Last time I tested it exceptions in C++ were ~6x slower than in OCaml. A typical solution in functional languages to use a higher-order function called something like `doWith` that does wraps the body in two function calls: let doWith allocateIt useIt freeIt = let x = allocateIt() try useIt x finally freeIt x For example to lock before incrementing something and then unlock after: doWith lock increment unlock In F#, .NET provides an `IDisposable` interface for resources that require predictable collection and F# adds `use` bindings. So the above example looks more like: use lock = takeLock() increment() The `Dispose` function on the `lock` value returned by `takeLock()` is automatically invoked when it falls out of scope. I never use locks in real code any more so a better example is reading lines from a file via a file handle. For example, accumulating the number of characters in a file: System.IO.File.ReadLines path |&gt; Seq.sumBy String.length The `System.IO.File.ReadLines` function returns an `IEnumerable` which implements the `IDisposable` interface. The `Seq.sumBy` function begins enumeration (opening the file), enumerates until the job is done and then disposes of the enumerable which closes the file handle. Note that you never see the file handle and, in fact, I cannot remember the last time I used raw file handles. The result is much clearer because it is at a higher level of abstraction than the equivalent RAII code that uses file handles directly. 
https://github.com/dtolnay/proc-macro-hack/blob/master/src/lib.rs#L296-L298 That's a clever trick. My first impression was to use struct attributes, but I don't think you can use `stringify!`within them which was why I thought literals were needed.
The most common way of doing things now (I render you the object and you'll figure out) has the problem that forces logic to be in all the consumers. Let's say I have user and it can be deleted or not depending on if he paid all the bills. Right now, anyone dealing with deletion will need to have some logic to handle this which probably means you need also to talk to the billing service. Then read that response, parse it, find the data you want, do a conditional on that. All that logic needs to be redone here and there. Or the hypermedia way which renders you the link to deletion if you need to, the problem with this approach is that the billing service may be slow and you need to do this even if 99.99% of the time when retrieving a user you do not care about billing. 
Yeah, I've heard of that coding language and it looks pretty decent
ah thank you 
Neat—looks a lot like [Bincode](https://github.com/TyOverby/bincode). In fact as far as I can tell, Bincode serializes all of the types supported by raw\_serde into exactly the same binary representation. Do you know any tradeoffs compared to implementing this as a real Serde data format?
Thanks for the info. I didn't know that the ITM could *also* log sleep events. It seems that the ITM can log everything. &gt; every 256 cycles like the sleep counter event is Can that be scaled somehow? That sounds like too many events (too much SWO bandwidth required). &gt; You could do it all via the debugger then no extra code is needed. You mean GDB or a SWD debugger + some software. I'd like the CPU monitor to work without requiring a SWD debugger or GDB to use it "in production" without requiring extra hardware components.
I think you've stumbled into the wrong subreddit :) Try /r/playrust
&gt; These components will seamlessly integrate and leverage existing VM infrastructure (e.g., HotSpot). ...thats because you can't write those parts in java. So no.
I understand the advantages of building something from scratch, however, it seems that all of the listed features are language-agnostic and thus it would be better to implement them for existing IDEs. (Preferably some that have rich framework behind them, like Eclipse; specifically [RustDT](https://github.com/RustDT/RustDT)). If I am not mistaken, if you really want to code in Rust, even in the case of Eclipse, I believe there are mechanisms to combine JVM and rust.
Could be really useful for the basis of a Rust IDE.
It's worth understanding that at the low level the hardware itself is 'unsafe'. Rust at some point has to talk to the operating system's api's which are normally written in 'unsafe' C. But even if you implement an operating system in Rust, you need 'unsafe' code because the processors execute unsafe machine code. Also things talking GPIO to some attached chip isn't going to be safe. So could always turn the wrong pins on and tell the chip to access an invalid address, etc... &gt; and ta-da you've just understood how a shitty version malloc is implemented. Yep, which is why most people shouldn't implement their own malloc. Instead they should use the ones that have been written by professionals that are checked for safety, optimised and possibly take advantage of architecture specific functionality. &gt; lets go take a look at a codebase which could really teach me how some experts would write rust, I know just the place to start: https://github.com/rust-lang/rust/tree/master/src Using the compiler as an example of good Rust code is probably a terrible idea. A compiler is a performance heavy application for starters. It's also quite complex. &gt; So am I missing something here ? Am I making an obvious mistake or wrong assumption ? I think you are misunderstanding how often 'unsafe' is actually used. Personally, there has been only a few things I have written in Rust myself that I actually needed to use the 'unsafe' keyword. * For some custom threadsafe singleton initialised thing (this was actually in an effort to make code safer to ensure appropriate thread-safe, initialisation of a C library). * For loading a function form a dynamic library. It was 3 lines of code, most of which was error checking. The only real failure scenario for that would be if the external dynamic library was corrupt. I guess you could check the hashes on a release build, and/or parse the debug symbols to ensure the types match (but your binary itself could be corrupt, or the hardware failing...). Any library that wraps a C library will need 'unsafe' because C itself is 'unsafe'. But you can wrap those libraries in safe Rust that ensures users don't do things like raw pointer arithmetic, passing in invalid data and so on. Other than that, it will only be specific, high performance things where you need some custom data structure like a thread-safe lockfree something.
Random aside: Using Arc&lt;RefCell&lt;&gt;&gt; won't provide any benefit over Rc&lt;RefCell&lt;&gt;&gt;. Arc&lt;Mutex&lt;&gt;&gt; might be what you are thinking, though for graphs it's quite difficult to work with a graph through multithreading without potentially reaching deadlock, so maybe you also meant Rc&lt;RefCell&lt;&gt;&gt;, but then again the Arc&lt;Mutex&lt;&gt;&gt; can also be operated on outside of the graph context just fine as well while also existing in the graph. Also, that doesn't eliminate the static type checking, just the static lifetime/borrow checking. Though checking still happens at runtime (RefCell::borrow() and Mutex::lock()).
Also consider that people making RESTful APIs with your framework will want to document them as well. If you can make it possible to generate documentation for these APIs using annotations, that would make your framework even more powerful.
Why not just have a separate 'ObjectBuilder' that implements the builder pattern without doing any of the actual work, instead just taking in the arguments but then you call a function that 'finalises' it, validating and constructing the real object and returning it. Pseudo-Rust: fn Example::Object::new() -&gt; ObjectBuilder; // The new() function doesn't actually need to return the same type that it is associated with fn Example::ObjectBuilder::foo(&amp;mut self, ...) -&gt; &amp;mut ObjectBuilder; fn Example::ObjectBuilder::bar(&amp;mut self, ...) -&gt; &amp;mut ObjectBuilder; fn Example::ObjectBuilder::finalise(&amp;mut self) -&gt; Result&lt;Object, Error&gt;; If you did get halfway though the build process on the ObjectBuilder, it shouldn't matter because it hasn't actually done anything and since it's not the actual object and you can't use it as such.
There are a lot of small tasks on various libraries needed for the [libz blitz](https://internals.rust-lang.org/t/rust-libz-blitz/5184).
&gt; Why don't you rewrite your comment in Rust. I heard it helps with off by one errors. Ha! Touché
Sorry, that's what I meant. I started by saying Rc&lt;RefCell&gt;, then changed it to Arc without changing the mutex. And yes, I know there is still static type checking, it's just that you have a lot less being checked at compile time than normal.
well actually, rust is a systems programming language with a focus on safety, performance and interop with existing codebases. 
There's a separation of concerns here that needs to be addressed. In your example you are talking about two different services that shouldn't care about each other. Changing a user account is (normally) something done with authorization: the user themselves changes some data, an administrator disables an account, or an automated task checks billing status and updates the user accounts to be deleted. In either case, it's an authenticated and authorized action, via some kind of user interface, or a particular automated task. Now, to bring this a bit closer to what you're asking. If an account is protected from deletion (say an administrator account), is there some what to represent that as an API 'trait'? The only way I could see that is if the request has some kind of authorization token on the request, which allows the request to take specified actions, and that tokens given back in the response give authorization for certain actions. It's a model called Capability Based Security, and it's a lot of work to do, but the major benefit of it is that is you prevent the user, external task, or whatever from getting into an inconsistent state. I've seen discussion of the approach, but I'm not sure of real-world working examples. ~~(Heck, the ultimate version of this is that your URIs become ```http://some.server.com/service-name/{token for action, data structure, authorization}``` -- essentially the token becomes an instance of a trait).~~ I think choosing a function at run-time from a token is a little too far out there. An authorization check is probably a better model to work with. 
Unfortunately the sleep counter is fixed at 256 cycles, only the cycle counter can be configured (from 64 to 16k cycles). Another option is to just enable periodic PC sampling which has the same frequency as the cycle counter overflow (side note: actually it *becomes* the cycle counter overflow event when PC sampling is enabled to avoid outputting an extra overflow event packet in the trace stream). The PC sample either shows an actual PC or a special value if sleeping (actually there is another special value "prohibited" but you can just ignore those ones). You can then use the ratio of (real pc samples) / ( sleeping + real pc samples) as a statistical interpretation of the CPU usage. I mean GDB, but you can configure it in the code too if you want. Note: if you are not using a debugger at all you may need to do some additional configuration that I think is normally handled by the debugger. Notably, setting the TRACENA bit in DEMCR and configuring the TPIU, although maybe the TPIU defaults are fine for your usecase. Feel free to message me if want to discuss in more detail.
I know a lot of quants in the City of London use F#, which has some decent numerics support. UBS and Goldman are two off the top of my head. It might be useful to benchmark F# against Rust on a toy problem, such as clustering the Reuters news dataset, to see how they stand, particularly when using F#'s Math.net numerics package which generates SIMD code. There is also decent CUDA support for F#, which has also been developed by folks in the industry. As yet, Rust doesn't really have a clean numerics library, particularly one exposing Lapack functionality like various decompositions. It's important for you to consider which is more important to your project: a novel method or a novel implementation. If it's the former then you maximise your chances of success by choosing a language which already has decent support for the basics. That means scientific Python, Julia, or at a push, F#. If it's a novel implementation, then Rust may be good. It'll certainly be easier to code and maintain than C++. However the lack of library support will lead to more work for you. My advice is to make a conservative choice for your work (ie not Rust), and keep Rust around for some weekend hacking. 
There is "[TWiR] Call for Participation" [topic](https://users.rust-lang.org/t/twir-call-for-participation/4821/63) on users forum. Also you can contribute to RustCrypto by writing cryptographic [hash functions](https://github.com/RustCrypto/hashes/issues/1) or [block ciphers](https://github.com/RustCrypto/block-ciphers).
yes the autogenerated documentation for rust is rather good. my tool used to generate a web-based view of the actual source code. http://dobkeratops.github.io/rftest/libcore/option.rs.html#n86243 it would have been nice to link that to and from the official documentation view, but once the language server works and people have 'jump-to-definition' in their code editors... that would be superior
Sounds like what you want is GraphQL instead of REST.
I'm not an expert on GC internals, so I won't comment that. I had very bad experiences with programs written in GCed languages. E.g. recently I closed one messaging application which took 4.5 GiB... (That's more than Bitcoin Core!) So that's source of my high scepticism towards GC langs. Rust defers deallocations to the end of scope *by default*, but there are two easy ways to drop values sooner if it ever becomes a problem. &gt; Class hierarchies end up requiring virtual destructors everywhere. Are we still talking Rust? Rust doesn't use inheritance and has no exceptions (in case of panics, there is possibility to compile with panic=abort). Yeah, all those `with`, `doWith`, `try`, `finally` are quite a boilerplate. If it can be forgotten easily, then you have probable resource leak. If the compiler can ensure it's not forgotten, it may simply insert the calls to destructors - which is RAII. That `use lock` in F# looks cool, if it's compiler-enforced. The other example looks good too.
Hi You can contribute to these simple projects Stack based VM and language for the same.( https://github.com/NishanthSpShetty/stack-langc &amp; https://github.com/NishanthSpShetty/stack-VM) C/C++ to Rust transpiler Crust : https://github.com/NishanthSpShetty/crust
If you like to write generic code and libraries, [`fast_fmt`](https://crates.io/crates/fast_fmt) and [`genio`](https://crates.io/crates/genio) might be a good start.
It's awesome that someone is trying to do this!
This guy seeker256 should work on or with Hyper project and make it better
Yes, but it will become safe if we use functional approach, there wont be any side effects and it would completely avoids ill affects of mutation i guess.
Nice project! Consider using [`genio`](https://crates.io/crates/genio) for IO. It enables you to return unreachable errors when reading from memory. (Unfortunately, there's no direct implementation for `std::fs::File` right now but that could be added later.)
It's not bad but they are on V4 of the API, they change their minds often, I would not give GraphQl a long life as their API either
great work!
&gt; function for collections/iterators that acts like filter and produces two new collections You probably want [`Iterator::partition`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.partition) or [`Itertools::partition_map`](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.partition_map)
I'm writing a game server and I didn't bother with tokio proto and I use tokio directly. I'm using both UDP and TCP, and a message on one could trigger a message to everyone. My basic run loop is this: struct MyCodec; // TODO: decide what the data looks like; for now, however, copying data is good enough impl UdpCodec for MyCodec { type In = (SocketAddr, Vec&lt;u8&gt;); type Out = (SocketAddr, Vec&lt;u8&gt;); fn decode(&amp;mut self, src: &amp;SocketAddr, buf: &amp;[u8]) -&gt; io::Result&lt;Self::In&gt; { Ok((*src, buf.to_vec())) } fn encode(&amp;mut self, msg: Self::Out, buf: &amp;mut Vec&lt;u8&gt;) -&gt; SocketAddr { let (addr, mut data) = msg; buf.append(&amp;mut data); addr } } let clients = Arc::new(Mutex::new(vec![])); let handle = core.handle(); // Pull out a stream of sockets for incoming connections let tcp_fut = self.tcp_sock.incoming().for_each(move |(sock, _)| { sock.set_nodelay(true)?; // Split up the reading and writing parts of the socket let (writer, reader) = sock.framed(MyCodec{}).split(); let list = clients.clone(); { list.lock().unwrap().push(writer); } let handle_conn = reader.map(move |data| { println!("received tcp packet: {:?}", data); // do stuff with the TCP packet }).map_err(|err| println!("error with tcp stream: {}", err)); handle.spawn(handle_conn.collect().then(|_| Ok(()))); Ok(()) }); let udp_fut = self.udp_sock.framed(MyCodec{}).for_each(|(addr, data)| { println!("udp packet received from {}: {}", addr, data.len()); // do stuff with the UDP packet Ok(()) }); core.run(tcp_fut.join(udp_fut)).unwrap(); I basically went with this approach because I couldn't quite figure out tokio-proto, and I wasn't sure if it could do what I wanted. I'm not trying to tell you to give up or anything, I'm just trying to give an alternate approach that you could use. If you're only doing UDP, then this becomes a bit simpler (ignore that entire `tcp_fut` block and no join at the end): let handle = core.handle(); let udp_fut = self.udp_sock.framed(MyCodec{}).for_each(|(addr, data)| { println!("udp packet received from {}: {}", addr, data.len()); // handle udp packet Ok(()) }); core.run(udp_fut).unwrap(); For a STUN server, you'd just hold onto the details of the first packet and send it to the second. It should be pretty simple.
A few tips for doing this kind of unsafe trickery: If you're planning to access C structs using rust you should really `#[repr(C)]` the types you're using, and before reinterpreting the `&amp;[u8]` you should also ensure that the alignment matches the expected alignment of the Record struct.
If you're into computer graphics: I'm looking for contributors for the [`gltf`](https://github.com/alteous/gltf) crate.
You may be interested in a discussion I was involved in just a week or so ago in which it was repeatedly stated that a user was banned expressly for "being a nazi." I can't imagine anything more political.
Slices always count with "number of elements", same with DSTs which end with a slice. The fat pointer is a pointer to your struct + the length of the slice at the end. Since there's no "official" way to construct DSTs, I tend the best way to create references to these types is this: Get a pointer to the base struct as a pointer to elements of the slice (here `*const u8`). Construct the slice with `slice::from_raw_parts` with the `len` parameter set to the number of elements in the slice then unsafely transmute the result to `&amp;Header`. This is of course assuming the representation of custom DSTs ending in a slice are the same as that of a slice itself (with some data prefixed to it).
I think you'd want to wrap [ClientService](https://tokio-rs.github.io/tokio-proto/tokio_proto/pipeline/struct.ClientService.html). At least, that's what the Tokio redis client does.
I guess it would mostly be about making hyper work inside the unikernel. But given that the network card cannot receive packets yet and there's no IP stack either, I would guess it's a bit early for that step :)
Of course I'm doing `#[repr(C)]`! I omitted it due to simplicity. Alignment shouldn't be a problem, because in fact, the slice always points to beginning of `Vec`, but good point anyway. (I should probably check the code again, since that monster is nested...)
Yup, they must have meant http://www.scala-lang.org/blog/2017/05/26/whats-new-scala-native.html. Actually, I think there is a decent interoperability story due to both languages having macros to simplify the glue (though top level item macros w/out experimental annotations don't work well IIRC, see existing type provider work). Having said that, I feel the use cases are lacking. Usually the only use cases for these things is someone from one language wants something from another that their language doesn't have. I sure wouldn't want to spend the time on an interop support lib that, for example, maps Scala traits to Rust traits via an external C interface. ROI doesn't seem to be there.
&gt; This could be a burnden to bear in performance critical applications but when it comes to reliability we require the app to never crash. From the perspective of reliability, panics are still a problem here. Have you taken any measures to minimize this, or are panics just a much smaller problem that you don't consider to be a major issue?
&gt; I realize I'm speaking blasphemy, of course. :p &gt; Maybe some consideration should be given for the fact that those people are, therefore, underrepresented in that process. Indeed, which is the very reason why we are hoping that the actual participants consider those which are underrepresented and at the very least attempt to cater to their point of views. There are a few people in the Community subteam who are working with outreach programs, hopefully they can bring valuable insight to avoid the rest of us blindly flailing in the dark.
To be honest I'm not sure why you got this error. However, I figuredm out a workaround for you. Since implementing `From` implies `Into` you can just implement that. Here's the code: use std::marker::PhantomData; struct It&lt;'a, T&gt; { pub it: T, _ph: PhantomData&lt;&amp;'a ()&gt; } impl&lt;'a, T&gt; It&lt;'a, T&gt; { pub fn new(it: T) -&gt; It&lt;'a, T&gt; { It { it, _ph: PhantomData } } } impl&lt;'a, T&gt; From&lt;T&gt; for It&lt;'a, T&gt; { fn from(it: T) -&gt; It&lt;'a, T&gt; { It::new(it) } } pub fn main() { let test: It&lt;&amp;str&gt; = "hello".into(); } Let me know if that works for you or if I need to explain any of it!
For something as simple as a STUN server, it really doesn't matter as you're only working with a given socket once or twice while you set up the connection. You could potentially get some win with super high load, but that's exactly what a STUN server is trying to avoid. I think working with the standard lib UDPSocket would be good enough for now. Just do something like: loop { // grab socket and read data // check if you need to send the data to another client // if so, send the appropriate data, and throw away the data // if not, store the socket's data for later } Since it's UDP, there's no socket to hold onto, so just store the remote address info and you're golden. A single thread is probably good enough, so no need to worry about event loops or threads. However, if your server does other stuff (e.g. like a TURN server as a fallback), then using an event loop may be a worthwhile choice, in which case my last example in my previous post should hopefully be helpful.
Cool :) Might play around with it at some point when I've gotten better with Rust. One could make an equivalent of virt-manager and the like via your crate and a UI toolkit?
There's a blanket impl in std that says something like `impl T, U Into U for T where U: From T` Or something to that effect. That's what the parent meant by "impl'ing From implies Into." I'm on mobile right now, ~~~~otherwise I'd link to the actual impl.~~~~ Edit: Reddit doesn't like my formatting :( Edit 2: ok, forget formatting, [bottom of this page for the impl](https://doc.rust-lang.org/std/convert/trait.Into.html) ;)
Have you posted this to upstream Libvirt? Sounds like the sort of project which would be easier to maintain if it was eventually in tree.
Unfortunately I also use Linux and dont have a windows set up so I'm afraid I won't be able to help here, however it is an interesting project
Hello this is definitely interesting and something I can work on. However I have some questions about the stackvm crate. First of all there is an a.out file in the main directory. Is this intentional or something you should add to .gitignore? And also there are a bunch of print lines in your library, which is usually a bad idea. If you would like to print for debugging purposes then. If you want I can create a pull request with these changes. edit: Something like this can also work macro_rules! debug { ($($p:tt)*) =&gt; (if cfg!(debug_assertions) {println!($($p)*)} else { () }) }
I think the problem is that `impl&lt;'a&gt; From&lt;It&lt;'a, Foo&gt;&gt; for Foo` *might* exist in some crate depending on you, and then the generic `impl&lt;T, U&gt; Into&lt;U&gt; for T where U: From&lt;T&gt;` would apply and collide with your `Into` implementation. The compiler chooses to stop that at your level so that adding trait implementations isn't a breaking change. Otherwise you could have the situation where you started without your `Into`, and a crate below you wrote their own `From` just fine. Then when you add your `Into`, if the compiler allowed it, the other crate would suddenly be the one to see conflicting implementations.
Yeah, the performance guarantee is the only downside. It looks like a Copy (or pointer copy) would occur but actually executes validation. &gt; What if set_bar wrote to disk or something? I'd be pretty surprised if a setter ever wrote to disc. It would break all my assumptions about the abstraction I was using. This is a code review / best practice regardless of implicit setters. I think for either of your cases, its a documentation thing. Know the abstraction you choose to use.
Apologies if i've missed things which are in the documentation. To be clear, by "the users guide", do you mean [this](https://servo.github.io/rust-bindgen)? I had read that, although i skipped the bit about build.rs for now. It didn't really help me with the problems i encountered, i'm afraid, perhaps because i know almost nothing about C++. There's no mention of cursors, dependent types, or std::string, so i didn't realise that the list of troublemakers in the section in C++ were relevant. Thanks for the clarification! Although the user guide mentions whitelisting, it doesn't describe what the argument to the flag should be. If i try generating a binding for [a header file containing two functions](https://github.com/coin-or/CoinUtils/blob/master/CoinUtils/src/CoinDistance.hpp) with this command: bindgen --whitelist-function coinDistance /usr/include/coin/CoinDistance.hpp -o CoinDistance.rs bindgen generates a file that's empty apart from the header comment. So, i assume it's more than just the name of the function, but i don't know what. Or is this a problem due to the functions being overloads? Thanks for taking the time to respond, by the way. I don't want to waste your time with really basic questions; if there's anything beyond the user guide i could read (including examples in real use), i'd be happy to go off and study that first. 
This ticks the "web UI framework" checkbox, but this looks extremely far away from React. There is not even a vdom, it's more like JQuery + template engine. It's probably sufficient for simple needs, though.
&gt; I'm pretty sure that LLVM does not target all the architectures that Linux is currently available on And Rust's vendored LLVM supports a subset of LLVM targets: I'd really like to use Rust on SPARCv8, for instance, which LLVM kinda has but rustc does not, last I checked. I think I accidentally talked japaric into supporting SPARCv9 for me, but I haven't seen SPARCv8 land in ours.
Only if you include a magic number in the `Syscall` struct that is unlikely to show up in random memory.
Thanks for the reply. I understand that I can't change the method signature of next to fn next(&amp;'a mut self) -&gt; Option&lt;Self::Item&gt;. However, would being able to do this solve the issue?
I believe so, yes.
Hmmm, that is looking like a possibility. The items are actually stored in a Vec&lt;Vec&lt;T&gt;&gt;. And the implementation is shown here: https://github.com/bpglaser/red-mountain-resize/blob/master/src/grid.rs#L103
In general, while using `bindgen` on C libraries should just work out of the box, C++ libraries require understanding a little more of the compilation model and what does and doesn't have a Rust equivalent. &gt; To be clear, by "the users guide", do you mean this? Yep. The "Customizing Generated Bindings" and "Generating Bindings to C++" sections are relevant. Ok, I see now that the `coinDistance` function is a template function. Template functions require a C++ compiler to instantiate their code for the generic parameters provided at a given call site. That is, the function itself doesn't even really exist until instantiated with concrete template arguments, so we have nothing to link to. Unfortunately, that also means we can't generate bindings to them because we can't generate new instantiations on the fly like a C++ compiler can. We have an issue on file to generate bindings to any explicit instantiations that might exist, but it isn't implemented. https://github.com/servo/rust-bindgen/issues/492 Overloaded functions, on the other hand, *are* supported; we just append an increasing number to the end of the name for each new overload. I need to add this information to the C++ section of the users guide. I'll also add some examples of names passed to the whitelisting. Does this library have a C API? You'll probably get further binding to that, if it exists. Cheers
If you're comfortable using GDB, you could try using `rr` to repro it and then debug it: http://rr-project.org/
Most people will tell you visual studio code https://code.visualstudio.com/ with the Rust plugin. It works as you expect.
 self.grid.get_mut(x, y) The issue is that there's a hidden reborrowing going on here. `self` is defined as: fn next&lt;'b&gt;(&amp;'b mut self) -&gt; Option&lt;Self::Item&gt; { Because `self` is restricted to `'b` and `self.grid` is derived from `self`, the lifetime of `self.grid` in `next()` *cannot* exceed `'b`, even though `grid` was declared `&amp;'a mut Grid&lt;T&gt;`. Effectively you don't have `&amp;'a mut Grid&lt;T&gt;` but instead `&amp;'b mut Grid`. More concretely, the borrow checker is complaining that `next()` could potentially return `&amp;mut T` referring to the *same item* in the array, in which case it'd be easy to abuse your iterator to get aliased `&amp;mut T`. This can be accomplished simply by omitting `self.y += 1`! That's why it's unsafe.
I'm able to compile it if I give the type alias a lifetime parameter... type Iter&lt;'a&gt; = Iterator&lt;Item=i64&gt; + 'a; I don't fully understand why, though
The problem is that you'd have to reimplement pretty much every CLI tool to support structured data. It's just not worth it.
The only thing I can think of from my own usage is an example on how to wrap the use of `filter_entry`/ `skip_current_dir` in a custom iterator without using `Box`.
It's a new OS though. I assume they are going to reimplement a lot of command line tools anyway. May as well do it right!
The `--files` flag was new to me. I read about `rg` using threads but did not know how to have it print without doing matching. Below you see a comparison from my machine. Lister is quite a bit faster for a cold cache. At least part of the file cache is usually cold so this will make a difference in practice. The number of threads that are used scale with the slowness of the responses: when the main thread has to wait too long (20ms atm) for a response, it fires up another waiter thread. Even the 100th thread can make a difference. For spinning disks this should be obvious: when you do 100 requests one request at a time, the io scheduler has no information and moves the head to the desired point. When the io scheduler gets the 100 requests at once, it plots an efficient route. A hard problem is to have good speed and sort the files. The `rg` manual says that parallelism is turned of when `--sort-files` is used, so you've come across this too. &gt; I wonder whether there is a race between the value of jobs and whether a worker is still trying to read from a directory? `lsof` shows no open directories when the program hangs. `jobs` is only modified by the main thread. $ sudo sh -c 'echo 3 &gt; /proc/sys/vm/drop_caches' $ time target/release/lister /home &gt; /dev/null 2&gt;&amp;1 real 0m2.886s user 0m2.894s sys 0m3.995s $ time target/release/lister /home &gt; /dev/null 2&gt;&amp;1 real 0m1.782s user 0m2.530s sys 0m1.933s $ sudo sh -c 'echo 3 &gt; /proc/sys/vm/drop_caches' $ time rg -uu --files /home &gt; /dev/null 2&gt;&amp;1 real 0m5.160s user 0m3.986s sys 0m4.895s $ time rg -uu --files /home &gt; /dev/null 2&gt;&amp;1 real 0m1.937s user 0m4.101s sys 0m2.449s $ sudo sh -c 'echo 3 &gt; /proc/sys/vm/drop_caches' $ time find /home -type f &gt; /dev/null 2&gt;&amp;1 real 0m9.304s user 0m0.800s sys 0m2.741s $ time find /home -type f &gt; /dev/null 2&gt;&amp;1 real 0m1.484s user 0m0.458s sys 0m1.016s &gt; I'm somewhat skeptical that something like this belongs in walkdir. ... There may also be complexities---I think---with spawning threads in a library like this behind your back, since I don't think all targets support threading. I would encourage you to release this as a separate crate. Using so many threads is certainly unusual. Even libev does not have many in its pool by default. The advantage is large, yet the threads are mostly sleeping. Using many threads is something to consider when making an AIO library for the filesystem (perhaps on top of mio). 
Exciting. :-) I hope you find your bug. &gt; jobs is only modified by the main thread. Sure, but that doesn't mean there isn't a race. If for example you observe an `Err(_)` that causes a new waiter to fire up but then immediately see a `DirDone` from a previous waiter that causes your `jobs` to decrement to `0`, then you'll break out of your loop and return `None` before the waiter you fired up has a chance to send a `DirEntry` and therefore increase the number of jobs. You might need to make your termination conditional on the number of outstanding waiters as well. Of course, this argument would be consistent with observing termination before listing all of the files rather than hanging.
When you specify a type `&amp;mut Trait`, this is a shorthand, due to lifetime elision, for `&amp;'a mut (Trait + 'a)`. The rules say that your `read_all` function expanded is: fn read_all&lt;'a&gt;(foo: &amp;'a mut (Iterator&lt;Item=i64&gt; + 'a)) { read_some(&amp;mut foo); } The `'a` in this context refers to the *implementing type* - that is, the type implementing `Iterator` cannot contain references shorter than `'a`. When you specify a type alias, such as `type T = Trait`, there is no generic lifetime parameter `'a` to add, so it must be inferred to be `'static`; i.e. `type T = Trait + 'static`. This means, that the implementing type must not contain any references shorter than the `'static` lifetime. In this case, you have: type Iter = Iterator&lt;Item=i64&gt; + 'static; To call `read_some` therefore, the implementing type must outlive the `'static` lifetime; but `read_all` cannot guarantee this with `&amp;mut foo`. Its contents are only guaranteed to outlive `'a`, not `'static` - so you get a lifetime error.
That is a very powerful tool. As I understand it, I can run the program a number of times until it hangs and then debug that run that failed. 
Thats pretty wild
The waiter will end on any error, but it reports that it ends which leads to a decrement of `jobs`. Still, if a Clone fails this also leads to a decrement of `jobs`, which is a bug (although it does not lead to a hang, but premature end of the iterator). I had explicit termination on the waiter threads. I'll put it back with different message for the different termination reasons. `receiving_channel.to_iter()` is nice. Pleased to learn about this elegant method. &gt; send "EOF" messages N times I had this in a `Drop` implementation for the iterator, but removed it figuring that Rust would sort it out or me. &gt; I'd do some form of batching in the return channel I'll keep that in mind. I figured the allocations for a `Vec&lt;_&gt;` might be a problem and the channel is a buffer anyway.
&gt; catch the output from all threads and sort the entries before printing Sorted output from `fd` would be very useful in many use-cases. It's not an easy problem to solve. Unless... You have a normal main thread that reads directories in sorted order like [WalkDir::sort_by](https://docs.rs/walkdir/1.0.7/walkdir/struct.WalkDir.html#method.sort_by), but you pass each directory that you find to a pool of threads that read those directories and do nothing with the result. That way, even though you are iterating with just a main thread, the directories that you will be reading are likely to already be in the cache when the main thread gets to them. Now that I think about it, such a caching pool could be done by simply wrapping the WalkDir iterator. 
The problem with that approach in this context is matching the `.gitignore` rules. Depending on how many and how big your `.gitignore`s are, they can take significant CPU time. (And that's even with a big ol' bag of tricks to make it fast.) I did a short write up on this a couple months ago: https://github.com/BurntSushi/ripgrep/issues/152#issuecomment-290590036 --- The rest of that thread contains some interesting ideas.
Of course trivial getters get optimized, the problem is that there's no indication whether the getter is trivial at the call-site, and that the access can silently change from trivial to not. I'm not comfortable making blanket statements like the one you made, but I can at least say I think that's a decently reasonable stance to take in languages like Scala/Java/C# etc. I think Rust is different in that it's lower-level, meaning it's more important for costs to be more explicit, and in that it has such a strong concept of ownership which takes care of at least some of the reasons you want mediated access in the other languages. But: this is all beside the point. The point is that it's needlessly hyperbolic to express 'extreme surprise' that this feature isn't in the language, when it matches the behavior of most other languages in its class.
Have you considered using AFL to find values to test? AFL-directed fuzzing is pretty fast.
PowerShell did it just fine. Everything is a typed object, and programs don't accept arguments of wrong type.
I keep reading *fd* as *file descriptor*, haha, but maybe that's just me. :) This is pretty cool. Cheers, mate.
Rust beginner here, and I'm attempting to learn by doing. For a mini project, I'm working with the `git2` crate. I want to push a repository to its remote, but I found that the `RemoteCallbacks::credentials()` method in the API docs, quite confusing. This is what I have so far: let mut cb = RemoteCallbacks::new(); cb.credentials(|user, pass, _ | { return Cred::userpass_plaintext(user, pass.unwrap()); }); let mut opts = PushOptions::new(); opts.remote_callbacks(cb); remote.connect(Direction::Push)?; remote.push(&amp;["refs/heads/master"], Some(&amp;mut opts)) ... This snippet of code represents a helper function I am writing that connects to the remote, and pushes to the remote URL. However, I am running into problems with authentication, and I am befuddled on how the `credentials()` method works.
I wanted to try writing my own custom derive, so I wrote a small library that allows structs to be populated by environment variables. It will attempt to convert the string from the environment variable into the field's target type via the parse function. It can also handle optional fields. It was an enjoyable experience and managed to write a small utility for my own project. I'm thinking of expanding it out into a more fully featured library for loading configuration from various sources at runtime, including the ability to layer and override the sources.
Same, would have preffered fnd. But whatever.
Hey, no love for Bay Area peasants? :( 
Will it be recorded?
**NEVER** (but see https://www.meetup.com/Rust-Bay-Area/ :D )
I'm very unsure of the details, so presume it's not and I'll let you know if it is.
Thanks, that was it! It's working now :) Now, is it possible to hide the `-&gt; Result&lt;(), std::num::ParseIntError&gt;` from this code somehow? It makes it very verbose in some actual code I'm writing.
Ordered and deterministic output seems like it should be the default, but a flag that unleashes the parallel beast would be awesome. Haven't looked at the code so I don't know how easy it'd be to have both. Might count against your "simple" and "user friendly" quotas.
I'm continuing work on my [fat-rs](https://gitlab.com/susurrus/fat-rs) FAT32 driver library. I have single-cluster (&lt;4kB) read-only access working, so now I'm going to get multiple-cluster access going. That'll make the read-only version of this library complete. It already has automated testing on Linux, so feel free to check it out and submit feedback. Also continuing to shrink the PR queue for [nix](https://github.com/nix-rust/nix). We just landed Tier 1 support for `x86_64-freebsd` so there should be no more breakage there. Still need to get proper cross support landed but there some upstream work to do for that, which I might try and tackle.
See, most other languages (except C# and Objective-C) use hacks and non-native stuff, too. C++ has QT which is non-native. JavaFX is non-native. Other languages have these problems, too. Most people do not dislike custom UIs (proof: Electron is popular), if they are designed well. The question is if you want to make your stuff portable or not. Many people have C# for GUI and Rust in the backend for performant stuff. That said, there isn't really a good toolkit for Rust either. You can do your UI in OpenGL and be sure that it runs pretty much everywhere, however the problem are toolkits. `conrod` is OK, but I don't think it's a long-term solution. What we need is something like a CSS to Rust compiler / code-generator, which makes layout easy to write, but at the same time safe and compile-time checked. Such a solution doesn't exist yet. Plus, it should only do layout and not concern itself with the rendering. This would be a "good" solution in my opinion, when combined with an OpenGL toolkit.
Is there an easy way to tell if a given type has `Send` or `Sync` autoderived; say, from a crate's `rustdoc`? It doesn't seem like those traits show up as implemented on a type's documentation page if they were automatically implemented by the compiler.
I feel like having the letters next to each other, being able to just tap my index finger and my middle finger is a real usability plus.
_Please_ stop thinking that everyone that gives you advice has read your post wrong. Wouldn't it be more constructive - in your view - to be open to the idea that your post(s) resonate in a certain way with many people because they sense a certain lack of perspective? 
&gt;"if someone takes issue with something you said or did, resist the urge to be defensive. Just stop doing what it was they complained about and apologize." That seems to be a very general blanket statement which - if put into practice - would render any discussion, friendly and welcoming or not, rather useless. 
If you believe that being open to the fact that you might harbor privileges, perspectives or prejudices that you aren't consciously aware of "betrays a sort of self-defeatism and self hate", and that considering such possibilities is somehow damaging to one's self, I'm not sure what to say other than that I find that a rather immature perspective. We all have prejudices, privileges and perspectives that we take into all encounters with others. Trying to figure out what they are, trying to find out what they are based on, trying to find out how they color our interactions is an important part of growing up and maturing as a human being. 
It works now, though its still considered to be in alpha. We really need incremental compilation on by default though for it to really shine, otherwise it can take several seconds to reanalyze, which isn't so helpful. Right now RLS also plugs into racer (when a query takes too long with the compiler) to give faster, though often inaccurate or incomplete, results.
Looks neat! Typing `fd` by itself starts doing a recursive listing of the current directory. That's kind of surprising. I can already do a recursive listing with `ls -R` so having `fd` do it is probably not very useful. Much more useful would be a short message showing me the common usage and pointing me at `fd -h` for more info.
Can the "target_feature" "crt-static" be set in the global cargo config? Can the feature be used with cargo? The feature: https://github.com/rust-lang/rfcs/blob/master/text/1721-crt-static.md Config: http://doc.crates.io/config.html Related PR: https://github.com/rust-lang/rust/pull/37545 EDIT: This works on my windows machine, but only on unstable: [target.x86_64-pc-windows-msvc] rustflags = ["-C", "target-feature=+crt-static"] *Follow-up question: When will this feature be available on stable?* 
not sure what you are trying to do. but just so you know there is a function String::as_bytes() 
As a side note: Reddit only understand links if they start with http/https, so yours didn't get formatted into a link.
I'm not sure if it would be appropriate, docs mention the protocol is not supposed to be used directly.
Doesn't Context run on LuaTeX, though?
Yeah, that's what made me think of it. It's not part of the public API, so they'll potentially break you frequently. If I were you I'd at least announce your project on the Libvirt mailing list. You might get some interest, or at least some advice on direction.
I doubt they'll change the protocol completely (as it will break older C clients), but I'll think about it when my library matures.
what about a type alias? fn main() { type Ret = Result&lt;(), std::num::ParseIntError&gt;; let clojure = |value: String| -&gt; Ret { let temp = value.parse::&lt;u8&gt;()?; Ok(()) }; } 
I feel like I'm finally pleased with the base functionality of [pq](https://github.com/sevagh/pq). I switched from docopt to clap to eliminate my dependency on `rustc-serialize`. I've considered adding more stream options. For now I only support Kafka (aside from stdin). Is anybody out there using any other messaging service to pass protobufs to each other? SQS, RabbitMQ? I also started working on a new crate called surge (doesn't do anything yet). I want to make a shell/cli streaming music player (probably with the `youtube-dl`-backend). Most of my workflow is keyboard-based (i3wm, tmux, etc.) so I'd like it if I could listen to music the same way (ctrl+r reverse search artists, etc.).
I would like to know what's the most ideomatic way to create a zero-copy parser with possibly support for the *Iterator* ? I saw [this thread](https://www.reddit.com/r/rust/comments/2i6xry/can_i_write_zerocopy_parsers_with_iterator_it/) but it does really give any solution using current rust version (it uses *str.slice* function which was removed I think). The only way I see how to implement something as descripted above is to use [slice_unchecked](https://doc.rust-lang.org/std/primitive.str.html#method.slice_unchecked). Is there another way which has already a safe wrapper around it ? If not, is it a good solution to implement a zero-copy parser ?
&gt; On the other hand, an unsorted output is maybe not too bad... I need to try it :-) Honestly I wouldn't mind that as a default if it means even better performance.
Also there is a [crate called fd](https://crates.io/crates/fd) which contains file descriptor utilities. So `cargo install fd` won't be possible for this utility.
Yes, it reads like a rule of a sect, where you're not supposed to question the elders or disrespect the holy 🐄
AFL helps find things that might crash a program but that's not really property based testing.
I think generating values with a genetic algorithm and using branch instrumentation to find interesting values would also help with property based testing. A small wrapper that aborts once the property fails should be enough to bridge the tools.
If all you want is to slice a string, you can just use the index operator. For example `mystr[0..4]` will give you the first 4 bytes of `mystr`. (unless the fourth byte isn't actually the last byte of its codepoint, but that doesn't really happen when writing a parser, where you calculate the byte extents of the slice you want yourself)
&gt; I'd be very much interested in why you wrote your own crate termcolor instead of using term? [...] I wish there was a de-facto standard, easy to use, cross platform library It started here, before I ever released ripgrep: https://github.com/Stebalien/term/issues/64 It's not a de facto standard, but `termcolor` is intended to be easy to use and cross platform, with an additional focus on handling multithreaded command line programs. Are you familiar with how coloring works on Windows? In order to truly appreciate what it means to make a cross platform library, it's important to understand the differences between the mechanisms: * With ANSI coloring, all you need to do is embed some magical byte sequences into the bytes that you write to stdout. Done. Simple. Ven, vidi, vici. Well, errm, that's a lie. Because actually, there are a bunch of different terminals and they all have subtly different support for things. And sometimes, there [are bugs](https://github.com/BurntSushi/ripgrep/issues/37). * With Windows coloring in a Windows console (that is, not a MSYS2 terminal like mintty), it works completely differently. There are no magical byte sequences. Instead, you must make *synchronous API calls to exactly the console you're writing to*. Now take ripgrep's architecture: it spawns a bunch of worker threads and each thread is responsible for searching one file at a time. Each worker writes the results of a search to an in-memory buffer. Once a worker is done searching a file, it acquires a mutex that controls access to stdout. It then dumps the contents of its buffer to stdout and moves on to the next file. Simple, right? Errm, nope! How in the world would that even work on Windows? At what point do you communicate with the console? Certainly, it can't be when you're writing the search results to an in memory buffer, well, because, you're writing to memory and not to the console. Nevermind the fact that having multiple threads control the console simultaneously would lead to bad bad things. [Enter `termcolor`](https://docs.rs/termcolor/0.3.2/termcolor/struct.Buffer.html). `termcolor` provides an in-memory `Buffer` that is a simple `Vec&lt;u8&gt;` when using ANSI coloring, but is actually something else when writing colors with the Windows console: struct WindowsBuffer { buf: Vec&lt;u8&gt;, // just like for ANSI coloring // A list of positions into `buf` and a color specification // to apply at that position. colors: Vec&lt;(usize, Option&lt;ColorSpec&gt;)&gt;, } It should be a bit clearer now how we do colors. When the above buffer is printed, it simply alternates between printing the actual data to the console and issuing API calls to the console in accordance with `ColorSpec`. (An alternative would be to write an ANSI interpreter, which I've seen some people do, but this seemed simpler and more deliberate.) I actually found a way to do this with the `term` library, but it required piles of hacks. On top of all of that, the `term` library made it very difficult to control the logic that determines what kinds of colors are printed. It was, in particular, tightly wedded to detection of the various terminfo libraries. I chose a simpler path: * Provide a way to always pick exactly which color strategy you want. (Obviously, choosing the Windows console when the console isn't availably just Won't Work.) This means you can do `--color ansi` anywhere and always get ANSI coloring. This also meant that I could do things like "try the Windows console, but fall back to ANSI coloring." * *Completely ignore the terminfo database.* I can get away with this because all I care about are very simple styles that are supported across multiple platforms. The `term` crate, on the other hand, supports many different options that I didn't bother with. That means `termcolor` offers strictly less functionality than `term`, which may be a deal breaker. But the `terminfo` database was causing all sorts of headaches: https://github.com/BurntSushi/ripgrep/issues/37 and https://github.com/BurntSushi/ripgrep/issues/182 --- The nail in the coffin, for me at least, is that this is exactly what GNU grep does and it works in a lot of places. &gt; super awkward/verbose to use I care somewhat less about this. I don't find myself annoyed by it because it tends to be code that is written once and maybe tweaked over time. But there's not much of it. If you were making very heavy use of coloring, then yeah, maybe it's worth writing a helper wrapper that you find more convenient. But `termcolor` is itself probably more verbose than `term`. With all this said, one could easily make the case that my use is pretty niche and that others could find work arounds that they are happy with. :-)
What are you actually writing?
Yeah that's what I was thinking. I think that would be really interesting to see. Let!
Yeah that would be really cool!
I am working on finishing [`toornament`](https://github.com/vityafx/toornament-rs) rust api bindings. In plans writing a mdbook about it and it's usage, finaliazing and finishing as 1.0 crate. Never published crates with version &gt;= 1.0 so it will be the first one for me.
I would like to know what does `tokio` give? I am C++ developer and yes, I used `std::future` but very few times. I have used `poll/epoll`s too. But I don't quite understand what `tokio` is made for. Really. I feel myself as a dumb. The only thing I understood is that it may combine some futures and poll them somehow. Am I right? Could someone be soooo kind to me to explain all of this? Excuse me for such an easy question :(
Hmm, my instinct would be to do it the other way around. Usually, you're trying to look for something that will match just one or a few files, and so the sorting of the output doesn't matter too much, while the speed does. If you're looking for a longer list where sorting does matter and speed not as much, then passing a flag to get it sorted or just `fd foo | sort` would work. But maybe I'm just too used to using `du -sk | sort -n` that the `| sort` part comes automatically to me.
Thanks. Is there bindings for qt?
Quoting [this issue](https://github.com/rust-lang-nursery/log/issues/116): &gt; We probably want to have the construction go through builders to ensure that we can flexibly add more fields in the future. What does builder means here? Using another example, is `String::from` a builder for String? Or does this mean it needs a `RecordBuilder` (I don't think so!)? Or just a namespaced function? Something else? Where can I found good (and easy for a beginner like me) examples of builders in Rust?
Nice shortcut, thank you!
Unless you are using Dvorak like me, and then it's two taps of the right index finger: one for the top row, and another for the middle row.
A quick search results in [qmlrs](https://github.com/cyndis/qmlrs). I don't know how feature-complete / easy to use it is though.
I'm not sure that TIOBE is meaningful at all :-/
Do you think rg will include a mode that can restrict matches based on file names, perhaps based on the code from this crate? I've occasionally wanted that. Before rg, I always used find | xargs grep and restricted the file type using find's `-name` option, but I could not find functionality like that in rg's help when I looked for it recently.
The code in this crate is using the same crates that ripgrep uses. ;-) The `-g/--glob` flag sounds like what you're looking for... -g, --glob &lt;GLOB&gt;... Include or exclude files/directories for searching that match the given glob. This always overrides any other ignore logic. Multiple glob flags may be used. Globbing rules match .gitignore globs. Precede a glob with a ! to exclude it. You can also do things like `rg -trust 'fn wat'` to only search in Rust source files. Check out `rg --type-list` for the full set of file types supported.
This reminds me that I should probably wrap up all my experiments around this stuff into something worth looking at... Not going to lie, probably won't happen too soon...
I have a slight problem with my appveyor badge for crates.io. It doesn't really show the status anymore (it is "unknown") but from my github page and if you click on the badge from crates.io you land on the correct build (and shows the correct build outcome) I am not a 100% sure what causes this, but i noticed this behavior after i transferred the github-project from my personal account over to an organization. Appveyor handles this a bit weird so i don't really know if the problem is on crates.io or appveyor. I just wanted to ask whats the problem here and i need to start somewhere. At the Appveyor or on the Rust side. https://crates.io/crates/enigo is the one i am talking about. If you look at the badges section in the toml you'll notice the difference in naming travis-ci = { repository = "enigo-rs/enigo" } appveyor = { repository = "pythoneer/enigo-85xiy" } (i transferred from my account `pythoneer` over to `enigo-rs` but appveyor keeps it to my account and renames the project) ... its working but on crates.io the badge is broken (only shows unknown) 
The TIOBE is another signal, like the benchmarks game. It provides feedback for the hype-cycle (actually important). Doubling every year, that puts Rust at 20% TIOBE in 5 years. Could be faster if it got direct C++ interop.
What should we do based on this information?
I did some work in [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) on floating point [fractional](https://github.com/iliekturtles/uom/commit/af5368d4d6c13368037a5e1dd2e41a91a5e0a9a0) and [classification](https://github.com/iliekturtles/uom/commit/d2cd8f7b1a941469fe27790054a2d96beef494b8) methods. This week will probably be light. Vacation!
Considering I just moved to a new state for a new job yesterday and was exhausted from my first day yesterday... I totally missed that the thread I posted in was last week's thread, here's a repost of what I wrote here last night: I wanted to try writing my own custom derive, so I wrote a small library that allows structs to be populated by environment variables. It will attempt to convert the string from the environment variable into the field's target type via the parse function. It can also handle optional fields. It was an enjoyable experience and managed to write a small utility for my own project. I'm thinking of expanding it out into a more fully featured library for loading configuration from various sources at runtime, including the ability to layer and override the sources.
If you have a long list, sorting with `| sort` will be memory hungry and slow. If the tool supports sorting, use that. `walkdir ~` 0m1.736s 5.204kb `walkdir ~ --sort` 0m2.182s 12.652kb `walkdir ~ | sort` 0m2.490s 5.252 + 14.812 = 20.064kb 
Here's a tutorial for it that showed up in here a few months ago: https://www.vandenoever.info/blog/2017/02/17/a-simple-rust-gui-with-qml.html
No, but you need to consciously make that choice each time and also ensure none of the libraries you're using are using panicky versions.
&gt; Doubling every year, that puts Rust at 20% TIOBE in 5 years. And 640% in 10 years! Or maybe extrapolating the growth of a proportion as if it were a metric doesn’t make sense.
As others have pointed out, you can't. What's most idiomatic in this situation is, I believe, to instead just have this: impl&lt;'a, T&gt; It&lt;'a, T&gt; { fn into_inner(self) -&gt; T { self.it } } 
Which is kind of bad, cause I'm barely using google when I'm working with Rust, as I find all the necessary information in the Rust books, the standard library documentation, crates.io, docs.rs, the individual GitHub repos (which I get to from crates.io or docs.rs), the Rust IRC, the Rust Subreddit or the Rust Discord (slighty off-topic: if a mod is reading this, can we have the Discord in the sidebar?).
Yeah, the lazy approach bit me in the foot.
Interesting, I hadn't considered doing it this way. Are there any examples you can point to?
I don't think it's a good idea.
Thanks! Great! It's clear now! &gt; What does builder means here? Using another example, is String::from a builder for String? Or does this mean it needs a RecordBuilder (I don't think so!)? Or just a namespaced function? Something else? So it was "Something else" :) 
&gt; Excuse me for such an easy question :( No need, this is exactly the right place for easy questions :) &gt; I would like to know what does tokio give? To understand tokio, you need to understand its two major components: ## Futures A future is a way of representing a *computation* as a *value*. What does that mean? Well, let's look at the Future trait: pub trait Future { type Item; type Error; fn poll(&amp;mut self) -&gt; Poll&lt;Self::Item, Self::Error&gt;; } A Future has a single required function, `poll`, that returns either an `Item` or an `Error`. This is very similar to `Result` in the standard library. There's a difference, though: see how it returns a `Poll`, not a `Result`? `Poll` looks like this: type Poll&lt;T, E&gt; = Result&lt;Async&lt;T&gt;, E&gt;; And Async looks like this: pub enum Async&lt;T&gt; { Ready(T), NotReady, } Putting it together, this means that `Poll` can be one of three things: * `Ok(Async::Ready(Item))`: this state means "hey, the computation has completed, here's the result." * `Ok(Async::NotReady)` is "hey, I'm still working on it, come back later" * `Err(Error)` means "this computation has failed, here's the error" The `Asyc` bit is really the big difference; with `Result`, you'd write a function with this kind of signature: fn do_something() -&gt; Result&lt;Item, Error&gt; In this case, `do_something` must perform the entire computation before it returns. The only two possible states are "succeed" and "fail". But with poll... fn poll(&amp;mut self) -&gt; Poll&lt;Item, Error&gt; the signature looks very similar, except that the `Ok` state is split into two: done, and not yet done. What does that buy us? Asynchronicity! We can call `poll` and it will not block. It always returns very quickly, either with a "hey not done" or "here's your answer." A particular future can do work in the background, and it won't be blocking. Futhermore, now that we have a value to represent our computation, we can *combine computations*. So for example, imagine we had a future that fetches something from the network. Afterwards, we want to use a future that does some processing on the result. We can use *combinator methods* to combine these futures fetch_from_network.and_then(do_processing) The result of `and_then` is to return another Future, so now we've combined two individual futures into a larger future. We can call `poll` on that future to drive the entire computation, and if the first future fails, the whole computation will fail. And it's all asynchronous. Note that nothing here has anything to do with IO, specifically. It's a way of modeling computations as values. This is the core of the Futures library, but there's a lot of other useful stuff in there. ## mio Mio is a wrapper around epoll, kqueue, and IOCP. The tricky bit is that IOCP has a fundamentally different model than epoll and kqueue, so there's some code to adapt it so that it presents one model. Mio lets you interface with your operating system to do IO in a non-blocking way. But operating systems are very low-level, and so are their interfaces. So mio is also low-level, as it's trying to be a no-overhead wrapper. Being low level means that it's a bit hard to use. Which brings us to... ## Tokio Tokio is best summed up as "using futures to make Mio easier to use." It takes the general futures mechanism and uses it to do non-blocking IO with mio, but in a way that (hopefully) is easier to understand than mio itself. It also provides interfaces for higher-level networking concepts, such as "this is a frame", stuff like that, that matters when you're implementing a protocol. Random developers will learn Futures, mostly, and have to worry less about Tokio and mio. They're more relevant for people who are actually implementing said network protocols than for the users of them. But since the interface to those protocols is a future, a good understanding of working with futures is useful for working with libraries on top of tokio. Hope that helps!
What's the reason for maintaining another clone of `coreutils`? Isn't there [`uutils/coreutils`](https://github.com/uutils/coreutils) already? From [`redox-os/coreutils`](https://github.com/redox-os/coreutils): &gt; These are based on BSD coreutils rather than GNU coreutils as these tools should be as minimal as possible. Is minimalism really the reason for re-implementing a whole bunch tools _once again_ in Rust?
&gt;&gt; This isn't true is it? It is confirmed to be true &gt;This code of conduct and its related procedures also applies to unacceptable behavior occuring outside the scope of community activities when such behavior has the potential to adversely affect the safety and well-being of community members. *[I would expect](https://www.reddit.com/r/rust/comments/6ewjt5/question_about_rusts_odd_code_of_conduct/didmmjl/) someone who constantly vomits sexist jokes publicly to be excluded regardless of how they act in the Rust community, because their presence in the Rust community will make members of a group of other people feel uncomfortable.* 
&gt; It is about search engine requests. No, it's about search engine results.
While I think it's fair to say that Tiobe's data appears to be measuring *something* (i.e. it's not entirely random noise), whatever they're measuring isn't market share, and their measurements are still tremendously fickle and unreliable. Position 37 with a rating of 0.479% isn't much cause for celebration; if Rust breaks into the top 20, then we'll talk. :P
Instead of C++ interop, think about being as easy to use as C++ currently is across Apple, Google and Microsoft stacks, including their approaches to app development. Being slower at producing builds, requiring manual FFI work, lack of mixed debugging, no support for binary dependencies on cargo, no integration with the GUI toolkits, are all bigger issues than direct C++ interop. Not easy to advertise Rust if it requires more work with less productivity than current workflows.
So last week I opened a pull request for rust-nix to improve the ptrace API they expose. It hasn't been merged in yet but I'll be making any required tweaks and hopefully getting that in by the end of the week. With tarpaulin my code coverage tool I managed to improve the stability, unfortunately I've had to undo the initial implementation and rebuild parts to handle threads in rust test executables. So I'll be figuring out ptrace and how it handles process and thread IDs because that's one area woefully underdocumented.
So kind of like QML, but controlled with native code?
Where Rust *could* be, not will be. We all have to push it there. Of course doubling of an infinitesimally small number isn't a big deal. The next doublings will be.
Everything you said is true. And .... C++ codebases are where the majority of developers who care about the things that Rust solves. Smooth integration with C++ will allow Rust to slipstream into existing systems.
I have a need to keep a set of values and dish out references to them. Now in the C++ world, `std::list` is the way to go, since references don't get invalidated. Do we have the same guarantee for `LinkedList` - I recall some optimizations that might interfere with this. Another way of putting this: can one split the borrows across each element of a list?
Well, I program in C since 30 years ago, and I always named "runtime library" the routines that the linker includes into the executable even when they are not invoked explicitly by my code. How does most people name such code?
What! No! It would be 50% longer! &lt;/sarcasm&gt;
On Windows COM interoperability is more relevant than plain C++, specially for UWP, user space device drivers and all major Win32 APIs introduced since Vista. On Apple platforms Objective-C(++) and Swift interoperability are more relevant than C++, because C++ is only used on IO Kit, Metal Shaders and LLVM. On Android devices, JNI is actually C based, what is needed is a more productive way than the current pain of using something like Djinni or SafeJNI. Betting on C++ interoperating to cover those scenarios, which are just some basic examples, means yet another layer between Rust code and the platform APIs. On my specific case, we are mostly a Apple/Java/.NET shop which only makes use of C++ when uses cases so require. For those devs to welcome Rust instead of C++, they need to feel using Rust across the IDEs and debuggers is just as easy as C++ and not that it requires extra development time.
How about `Vec&lt;Rc&lt;T&gt;&gt;`?
The `xi-editor` is taking the second approach. I think it's nice that way, although it's more work.
I tried changing it to `String` but got the same error.
So, Rust won't let you invalidate a `Vec&lt;T&gt;`, so just taking references to different items may work for you. It really depends; since you're worried about invalidation, do you need to modify the list while references are held?
You can take a look at http://blog.japaric.io/quickstart/.
You are already do amazing things for increasing Rust's popularity. Stackoverflow, conferences and meetups all increase Rust's exposure. Popularity definitely builds more popularity. Getting synchronized with what drives the hype/marketing cycle will allow for more organic growth. Rust evangelizes well, as other posters have mentioned, what niches could Rust grab ahold of? Increasing Rust adoption is a balance between social and technical, usually balanced with small technical challenges unlock larger social blockers. Lots of technically superior solutions failure to gain adequate mindshare to survive. https://en.wikipedia.org/wiki/Measuring_programming_language_popularity
I wasn't really sure how to phrase it, Tiobe themselves are deliberately vague about what they're measuring. Whatever it is, it's real-word data showing that Rust is gaining traction outside our little bubble. Even if the data itself isn't too useful, I hoped it would be motivating to all the people contributing to the Rust ecosystem.
Hmmm, I've re-implemented my grid data structure just using a flat Vec&lt;T&gt; and it is almost 18x slower. I'm investigating why. However, I wouldn't think that the math operations would be slowing it down that much.
Just use mio? 
You can newtype the vec, only add the add method, and an unsafe `get` that returns a reference with a static lifetime. The only problem is what if the vec itself gets dropped. You can actually solve this using Rc's and reference cycles
I don't think we should recommend communication mechanisms unless the mod team is involved.
Sorry to reply to a post so old...but these instructions no longer seem to hold (for Win at least); the archive binaries step is gone. Anywhere else I can download binaries of the wasm builds?
Just put the x and y fields into your Grid, get rid of the IterMut structure, and implement Iterator directly on Grid. Now Grid is an Iterator too.
&gt; Many of your questions I can't answer. Esp when the signals from Java/C++/C# swamp the results. And that's why I don't find TIOBE useful :)
One thing that I would like to suggest we do is for when there are newbie questions about rust, to try and ask them to ask them on stack overflow so that the answer is archived, searchable, and *exposed*. This will help the newbie experience (SO is a popular place to go for questions) as well as increase exposure for things like tiobe. 
You can use `from` instead `into` to resolve ambiguity. match value { x if x == &lt;&amp;str&gt;::from(Version200) =&gt; Ok(Version200), x if x == &lt;&amp;str&gt;::from(Version310) =&gt; Ok(Version310), _ =&gt; Err("error"), } Note: Usually you write `Type::from(...)`, but since writing `&amp;str::from(...)` would be ambiguous, you have to put the type in angle brackets. I think this syntax is called "reverse turbofish" :)
Good point, thank you. I'll try to make them consistent.
What would be the rationale behind that? I have never heard of it before, but if there are more than hundred people on it...
My rationale is that mediums that are recommended by the community should be upheld to the community code of conduct, which means the moderation team should be involved.
I have to unfortunately caution against nuklear. I've tried to make it work with a fair amount of effort and digging, but it is really not a solid library. Lots of things don't seem to work at all and there is ZERO documentation that I've found.
It might also be a good idea to use a faster, non-cryptographic hash function for the initial comparison. Murmurhash comes to mind. The SHA family of hashes have computational complexity built into them which is unnecessary unless you are after that.
Oh, I'm well aware of that. `| sort` is just a fallback if the tool doesn't have a `--sort` mode built in.
Agreed. Regardless of how people personally feel about SO, I do agree that in terms of *surfacing* answers to those seeking them it's leaps and bounds ahead of any other venue. We have a weekly "easy question" thread stickied on top of the subreddit, and I always hope that some kind soul with too much time on their hands will go through and convert all of those into SO answers.
They should be there, I'll check when I get back to my desk.
I made a future-aware single producer multiple receiver channel: [rs-futures-spmc](https://github.com/mredlek/rs-futures-spmc). It looks now stable enough to continue with by main target: a program to get keystrokes from xinput and send and receive command to Kodi with a websocket protocol. This way I want to control Kodi without it ever receiving focus. The application will use tokio for network communication. I will use the channel such that multiple parts of my program can receive the same notifications.
&gt; The first problem I see here are collisions, it's possible (although very unlikely) to have two different files of the same size with the same hash. You can always run a full byte-for-byte comparison for each found match, just to be sure. &gt; &gt; The other thing is that getting a hash of a file is a slow operation, as it has to read the entire file, as well as actually compute the hash. You could speed this part up by hashing only a part of the file (some continuous chunks at predefined intervals would probably be best), and/or using a simpler hash. For my initial use case the minuscule probability of collisions was entirely irrelevant. But it's true that for a more general-purpose utility correctness should be preferred. And when a byte-for-byte comparison is necessary anyway, you're right that hashing only parts should be sufficient for larger files. I think that, in comparison with the non-cryptographic hash, should be a nice strategy for the next version. **EDIT:** published v1.1.0 with the discussed changes. Didn't have much success with murmur3, but reduced the overall hashing to a fraction of the file, and introduced byte-by-byte comparison for same-hash files. As expected, this made searching in a set of large files much faster. It did not lead to slowdowns in sets of many small files. And of course it's more correct, so yay and thanks for the comments! (Of course, now we're at ~160 LOC...)
I hope everyone remembers their `#![feature(asm)]` to get in.
My right-little-finger was overworked when I tried Dvorak. Plus the Ctrl+Z/X/C/V shortcuts were messed up. Colemak has better hand balance and is overall more comfortable; being easier to learn from Qwerty is just a bonus.
No. Market share includes existing users. If there are lots of new users, but very few stay with the language, that shows a very real problem, but just looking at search statistics would hide that. For example, consider languages like LOLCODE, malbolge and other esoteric languages, which will have a much higher number of searches than current users (or more "practical" languages like golfscript, which is used in code golf competitions). So no, it isn't a strong measure of market share, but it is a good indicator of healthy uptake.
I don't see stack overflow in the sidebar.
The official weekly "easy questions" thread explicitly directs people to SO. So it's not in the sidebar, it's merely among the two or three sticky threads that permanently adorn the top of this subreddit. 
&gt; What's the problem with a byte for byte comparison? A hash algorithm is O(n) and can't be short circuited. So you hash both files, two O(n) operations. Then you compare. Well yes, but you need to know *which* files to compare against each other. The hash basically has the same function as checking the size, to find among the large search space small groups of elements that *might* be duplicate. Otherwise for m files you have to do O(m²) comparisons.
Oh, hm. The waterfall seems to have been failing for a while, so there haven't been any archived binaries. You can explore the binaries that have been uploaded by using: http://gsdview.appspot.com/wasm-llvm/builds/. Hope that helps!
I published [a bugfix release of Claxon](https://github.com/ruuda/claxon/blob/master/changelog.md#031), my FLAC decoder. This release is the result of three months of fuzzing with [cargo-fuzz](https://github.com/rust-fuzz/cargo-fuzz), and it includes several other bugfixes. It has also been verified against the reference decoder on more than 11000 real-world FLAC files.
blake2/skein should be the fastest of the cryptographic hash functions: http://bench.cr.yp.to/results-sha3.html
A possible alternative to full byte for byte comparison would be to use two different cryptographic hashes e.g. SHA2 and RIPEMD160.
Ah ok. That makes sense.
I'd be very interested in a crate like that
I meant duplicate files, not hash collisions. If you have two duplicate files and use a non-cryptographic hash function, you need to scan over them again to be sure they are equal. If you use a secure cryptographic hash function you only need to scan the files once and then just compare the hash.
Cool, thank you!
Does RedoxOS have support for FAT? I don't really know. Maybe it could benefit from your work?
[removed]
I think [this](https://www.reddit.com/r/playrust/) is the subreddit you are looking for. This subreddit is for the programming language Rust
Virtual Dom will be tough with in the near future, the API between web assembly and the DOM is pretty limited.
Everything I use is in the official docs or the book but I still use Google to find the exact page I'm looking for.
Once you have a 'collision' it's just worth it to compare both since false positives (actual collisions) will be far fewer then duplication 'collisions'. The few being removed from collision will be more expensive than the ones being removed *and* compared for correctness. tl;dr; if you have a collision for one, it's probably a dupe, check that, it's cheaper then collision checking again then dupe checking.
So I take it that string is like a torrent magnet link? Is anyone who has access to that link able to download the file? What is the use case for this? Is there any benefit above and beyond something like FTP?
The best low-level libs I know are based are [sdl2](https://crates.io/crates/sdl2), [gfk-rs](https://crates.io/crates/gfx), and [vulkano](https://crates.io/crates/vulkano). These are listed in order of how difficult they are to start a project with. For higher level stuff there is [piston_window](https://crates.io/crates/piston_window), or my contribution [Lattice](https://crates.io/crates/Lattice).
Not that I'm a huge SO answerer, but I think the point is that it's better to have it on SO which has better SEO than on some GitHub issues page, or in some IM box. And it's actually easier for me as a question-asker, because I can make a StackOverflow question that has all the relevant information, and then send that link to my normal network (people I'd ask in real life, emailing product support if it's a library, or forums/Slack channels if I get super desperate). Then I don't need to type it out a bunch of times in a bunch of media or update people individually if I make progress/resolved the issue, and it gets the most visibility to search engines you're going to get.
In this case an `if .. else if ..` makes more sense Though really it should be a match with literals.
A function implements FnOnce. But with a function you can't pass state over to the function, which is what you often need to do. So you use a closure. Generally if you're using a closure once it's better to put it inline. The "idiomatic" solution to deeply-indented code there is to factor out the contents of the closure into function(s). (Of course, if you're not transferring any state, just use a function directly, just that that's pretty rare)
Would recommend the discord.
Or just how much you need to Google to understand stuff? Posix Shell would be on top of the list if invented today just because you need to Google like a madman to understand all the obscure interactions.
&gt; I've always felt that apps built on top of web technology like VSCode just "feel" really heavy, so despite the awesome features I keep running back to pluma (MATE's fork of gedit) for its snappiness. I totally agree, I just kinda wish it weren't so (one way or the other).
Agreed. I currently resort to limited DOM patching via morphdom.js. I do look forward to eventually seeing [WASM native Web APIs](https://github.com/WebAssembly/design/blob/master/GC.md).
It looks like you're using the same nonce for every file part. To my understanding, this is bad. Increment the nonce every part at least. EDIT: https://security.stackexchange.com/questions/136739/aes-use-same-nonce-security-risk/136740
That is not the encryption nonce, it is the link nonce... I don't know if it is technically a nonce, might be more accurately a salt. It is used as the link password for the encryption, and salting the the part hashes. Edit: the AES nonce is generated here: https://github.com/cedenday/rshare/blob/a166b8f6be42b285029c208f860cd81bd49f5827/src/server.rs#L221-L225
Is using the `let` keyword to replace variables different in speed from using `mut`? For example, is: let x = 100; let x = operation(x); let x = x + 5; any faster/slower than: let mut x = 100; x = operation(x); x += 5; ? 
*oops* thanks, fixed!
I just implemented a vector based deque in C++ after discovering that std::deque is an inefficient trap. Not Rust related except for the fact that this is yet another thing that isn't an issue in Rust. I'm so glad that Rust took the opportunity to provide a sensible standard collections library that does the right thing out of the box.
It seems to me like this specific case of UB can easily be detected statically by some control flow analysis. Couldn't rustc run a "verify" pass between each MIR transformation to detect any invalid use of storage annotations ? These should only be enabled behind a flag or in debug builds of rustc of course. This only works for this specific case, not in general. Your work on miri is very interesting.
It is, thanks! I'm now using blake2 in v1.2.0, which is a bit faster still (as /u/lederp's link also suggests). Although I don't like the API as much: * the multitude of traits is quite confusing: why is there both Input/FixedOutput and Digest, with differently called methods? Especially since the `Digest` impl is not listed on [the struct doc page](https://docs.rs/sha-1/0.3.4/sha_1/struct.Sha1.html) (I realize that is a rustdoc limitation, but might be nice to link to it manually). * the returned GenericArray can't be `Hash`ed, so I have to call `to_vec`. Also, to write the type is pretty unwieldy. Is it really necessary to use this instead of an `Output` associated type on each digest?
Now there are two dozen!
Yes, I was actually moving in that direction, then I wondered if these guarantees already existed. But (as you point out) they are not part of the contract of LinkedList. Besides, such a pool of objects only grows, and items are not deleted.
1) Reason behind this is that there is three types of hash functions: with fixed size output, variable size output (see e.g. Groestl or Skein) and extendable output functions (XOF). But in the most cases you need only the first one, so I've created a convenience trait wrapper `Digest=Input+FixedOutput`. But you are right and this moment should be clarified more clearly, I will probably add a section into each crate docs with the short description of `digest` traits. 2) It's a limitation of `generic-array` v0.7, I will move to 0.8 in the next iteration of `digest` traits. In 0.8 `GenericArray` now implements `Hash` trait. I think using arrays as associated type will make it harder to write generic code, also do not forget that traits for arrays are implemented only for lengths up to 32, so `[u8; 64]` can't be `Hash`ed. If one uses only one hash size he can just create a type alias, something like: `type Hash = GenericArray&lt;u8, U64&gt;;`.
&gt; At this point, I ended up in a lengthy discussion with @eddyb and @arielb1 Can you link this discussion? Your (2) option seems the most sensible choice to me. In fact, I'd take it further and say that killing a value twice or resurrecting a dead value should also be forbidden. If you want to "reuse" space, that should be something the implementation (in this case, LLVM) decides, not an artefact of making questionably-sensible statements at the MIR level which happen to turn out ok.
Duh. I guess I missed that because I was looking for something more like `--files` or `--name`, or something? In terms of UX (and I'm clearly nitting here), `--glob` is nicely specific but also a bit too much about the means rather than the goal.
Looks pretty nice! Some feedback if you want (first on the project itself!): If you'd be willing to make one, I think a CONTRIBUTING.md document which outlines what needs to be done to add support for another language could be super useful - or even if it just outlined the project structure / where to look to find functionality to modify, that'd be nice. A known working nightly version to compile on too would be great - even if it works on the latest nightly now, things can break and having a known version to fall back to is good. On that note, I think the dependency on `#![feature(test)]` could _probably_ be removed, at least for non-bench builds. Using `#![cfg_attr(test, feature(test))]` and `#[cfg(test)]` on `mod test;` would let it compile without unstable features, then you could ride the next beta out to stable support if that's something you would want. ---- Besides project stuff, this is also a pretty awesome utility! I've tried it out a few times, and here are some of the user-side things I would say: Initially, more clarity on what exactly is displayed for `sniff ar` would be good. I get a list of files/directories and byte sizes, but it's not at all clear what `sniff` thinks is a build artifact, and what it's just including because it's a parent directory? For example, on one of the projects I've cloned, I get the output 639 b ./rustfmt/bootstrap.sh For a regular non-compiled bootstrap file - and `sniff` gives no indication whether it thinks this is a binary, or if this is in a directory that is binary? For targets deep into directories, I have one listing for each parent (like `1.0gb J/B/A/target` `1.0gb J/B/A` `1.0gb J/B` `1.0gb J`). This itself isn't a problem, but it would be nice if these could be colored or somehow distinguished so that they don't clutter the output of actual build files. When the project fails to parse a `.gitignore` file, it gives no indication _which_ gitignore it failed to parse. This could definitely be helpful for improving the project, but it's not helpful when I'm running `sniff` on a parent dir with 20+ different checkouts. Language support: it would be a nice thing (but not at all essential) to have support for C projects which generate build output in the same directory as the source files. Right now it will pick up every `.o` file correctly as a binary, but it just outputs them all as single lines. If you would be interested, combining a multitude of individual small files that are in the same directory into one `*.o` listing might be nice (especially if `*.o` is listed in .gitignore). Alright - hope that wasn't too much of a wall of text. The project's pretty nice as is, but just thought it would be nice to also give some feedback, in case you wanted it!
There is also [conrod](https://github.com/PistonDevelopers/conrod) from the Piston developers for 2D GUIs.
Found this on Planet KDE.
In case you're only watching your replies, keep [this comment I just posted](https://www.reddit.com/r/rust/comments/6fihe4/direct_vs_indirect_gui_toolkit_bindings/dikkbq0/) in mind. TL;DR: If you support running in a non-Windows, non-OSX context where you're not delegating to either GTK+ 3.x or Qt 5, you'll want to check whether you're running inside a Flatpak sandbox and prefer the Flatpak [org.freedesktop.portal.FileChooser](http://flatpak.org/xdg-desktop-portal/portal-docs.html#gdbus-org.freedesktop.portal.FileChooser) D-Bus API over whatever fallback you'd otherwise provide.
This should work: https://wiki.archlinux.org/index.php/Rust#Official_Rustup_Installation TBH I don't really do anything on arch, but if it's something like other systems, rustup should usually be preferred if there is no reason not to use it.
&gt; support LLVM prefetch intrinsic, speedier binary search I think the binary search was not modified.
also: https://github.com/Gekkio/imgui-rs https://github.com/gabdube/native-windows-gui https://github.com/pcwalton/libui-rs 
I don't have a Windows machine to test on, so I'm loathe to make a PR, but it's simple to solve using [conditional compilation](https://doc.rust-lang.org/book/conditional-compilation.html). Apply `#[cfg(unix)]` to your `use` and `is_executable` and add a `#[cfg(not(unix))]` with a dummy `is_executable`. If you really want to get it right, add a `#[cfg(windows)]` implementation which highlights based on extensions and put the dummy under `#[cfg(not(any(unix, windows)))]` instead. It's been a while since I started a new project in Rust, so I can't remember whether you can apply conditional compilation directly to a `use` or whether you'll have to put both of them into a module and apply `cfg` to that. ...and add [AppVeyor](http://appveyor.com/) alongside Travis CI so future changes don't break Windows compatibility again. (Building on those two, [japaric/trust](https://github.com/japaric/trust) will then let you automate generation of release builds for many different platforms.)
jetbrains is kind of unique in that they have a team of people who have written language parsers a dozen times and can crank them out pretty quick. probably have a suite of tools for the job ready to go. for almost any other team, an RLS would make the task many many times easier (if it were complete) 
Some people really like features that can auto-fill boilerplate. In Rust I can imagine you say `match foo` and then the ide could spew out all the cases to give you a template, same for traits. Not sure if that is what she means. 
At that point, why not use something like [typed-arena](https://crates.io/crates/typed-arena)? And if you're going to hand out the unsafe references you might as well do `Vec&lt;Box&lt;T&gt;&gt;` instead of `Vec&lt;Rc&lt;T&gt;&gt;` (the refcount is only ever going to be 1 anyway).
Good point
&gt;Is there a better way to achieve this goal would you consider using `const`s? const V200_STR: &amp;'static str = "2.00"; const V310_STR: &amp;'static str = "3.10"; impl From&lt;LayoutVersion&gt; for &amp;'static str { fn from(original: LayoutVersion) -&gt; &amp;'static str { use self::LayoutVersion::*; match original { Version200 =&gt; V200_STR, Version310 =&gt; V310_STR, } } } impl TryFrom&lt;&amp;'static str&gt; for LayoutVersion { type Error = &amp;'static str; fn try_from(value: &amp;'static str) -&gt; Result&lt;Self, &amp;'static str&gt; { use self::LayoutVersion::*; match value { V200_STR =&gt; Ok(Version200), V310_STR =&gt; Ok(Version310), _ =&gt; Err("error"), } } }
Certainly... The question is, how do you make RLS something good enough that someone like, say, jetbrains, would choose to use it and perhaps contribute to it, *instead* of just rolling with the standard intellij plugin / GrammarKit solution. We don't want RLS to end being the crappy 2nd class free IDE environment if jetbrains / google / microsoft / whoever decides they do want to come along and create a commercial IDE for rust. I mean, if that's not the goal for RLS, ie. to be good enough to compete with commercial rust IDEs when/if they exist, we're wasting our time with it. If all RLS is, is a 'stop gap until someone comes along and makes a real one', we've lost before we've even started. I think the situation with go-code is pretty spot on; it was active and thriving, getting better with contributions... and.... now people are drifting away, because gogland doesn't use it, and it seems like the not-as-good free alternative to a 'real' IDE. It's not good enough to just be 'better than nothing'; it has to actually be *good*; and that absolutely means listening to feedback like this.
&gt; Ok, I see now that the coinDistance function is a template function. Aha! Indeed it is, and i should have noticed that. Of course, it makes perfect sense that bindgen isn't in a position to deal with generic functions. Okay, it seems that this API is more tricky than i had thought. I'll keep poking at it with bindgen, but i may need a different approach. Thanks again for showing me the path. [There is a C API](https://github.com/coin-or/Clp/blob/master/Clp/src/Clp_C_Interface.h), but it covers a limited subset of what the library can do. I'm also interested in using a sister project, [Cbc](https://projects.coin-or.org/Cbc), and the C API there is even more limited - the heart of the beast is customising the way the solver splits the solution space into a tree, and that can't be done through the C API. Hopefully, i will be able to write a minimal amount of C++ to exploit the C++ API, and interface to that. 
What is more important for me, that it now allow to setting `RUSTDOCFLAGS` which allows for nice math in documentation like https://github.com/rust-num/num/pull/226
Unfortunately so. Each iteration of the algorithm selects a path to remove based on a calculated energy value. Then it proceeds to either remove or duplicate depending on if the image is to be grown or shrunk. Thus each iteration does a lot of shifting elements. To be honest, this might be an actual use-case for a linked list.
When is it possible to use the `obj.method()` method call syntax instead of `Type::method(obj)`, *exactly*? I thought that only `self`, `&amp;self`, and `&amp;mut self` were allowed as the first argument in an `impl` function if convenient methods calls like above were to be allowed, but recently I came across the following snippet in `crossbeam` (edited to focus on the relevant parts): trait FnBox { fn call_box(self: Box&lt;Self&gt;); } impl&lt;F: FnOnce()&gt; FnBox for F { fn call_box(self: Box&lt;Self&gt;) { (*self)() } } unsafe fn spawn_unsafe(f: FnOnce()) { ... let closure: Box&lt;FnBox&gt; = Box::new(f); closure.call_box(); // !!!!! ... } The method is being defined and called with `self` as a Box containing the `impl`d type. 1. What other types are allowed in the first parameter of a dot-callable method which contain `Self`? 1. Is there documentation I can reference about what the exact prerequisites are for the dot-call syntax to be valid for a given method? 1. Are `self`, `&amp;self`, and `&amp;mut self` as standalone parameters simply syntactic sugar for `self: Self`, `self: &amp;Self`, and `self: &amp;mut Self`, respectively? (That is, is `fn foo(&amp;mut self) { ... }` the same thing as `fn foo(self: &amp;mut Self) { ... }`?)
When i wrote a tool to do this, i found that so few files had the same size that the hash didn't add any value. I just went straight to byte-to-byte comparisons. However, this is very sensitive to the input. It might be that a typical population of files have varying lengths, and lots of differences in the first few bytes. That was certainly the case for merged collections of MP3 files, for example. But particular populations might be very different. Imagine a network traffic capture, where there is a file per packet: there will be large numbers of MTU-sized files, and lots of DNS / ARP / NTP / etc packets which are identical apart from a few bytes here and there.
Hmm, maybe instead of shrinking it, just mark the column as unused (an probably reuse if adding is needed)? This would eat more memory of course but it could be cleaned up at appropriate moment by physically removing all unused columns. I don't know the algorithm in depth, but since it's image processing algorithm, I think it should be doable. Resize the array only after you computed everything (if that's even needed - you could save the image directly from what you've computed and then throw away whole thing). Edit: another idea would be to make `Vec&lt;Vec&lt;Patch&gt;&gt;` where `Patch` is `n*m` matrix that fits nicely into CPU cache.
Not only that, I think that you may even be able to pass a rogue Syscall object that allows exploitation. 
&gt; "Also, Rust's type system is inspired by the Hindley-Milner type inference algorithm. :D No way am I missing the opportunity to implement type inference. After all, Google Summer of Code is an opportunity for me to learn more about things I find interesting." I don't think this is true, though I've heard it repeated a few times. ~~Rust does not have anything like hindley-milner type inference and it's a bit of a stretch to say it's even inspired by it.~~ Rust has local type inference. Hindley-Milner is a globally decidable type inference. They are two completely different things. Edit: well, i'll be damned.
If anyone is curious this is from IntelliJ Rust FAQ: &gt; Are you going to use racer or RLS? &gt; &gt; No, we plan to implement most of the language analysis from scratch. This is a lot of work, but the benefits are substantial. We would be able to leverage IntelliJ Platform infrastructure for incremental analysis and indexing. With our own analysis we can provide more flexible quick fixes, intentions and typing assistance. &gt; &gt;The same applies to the formatter (that is also from scratch, but we plan to support running rustfmt as an action). It is necessary for proper working of almost any feature which is modifying source code. - https://intellij-rust.github.io/docs/faq.html
You're right. The references to HM type inference I saw were outdated. I referenced it because I wanted to put a name to the algorithm, but the point I was trying to make was that type inference is interesting to me and I'd like to implement it (and I've done HM before for a simpler language).
&gt; Could you also say when should I use it and when it is overkill? It really just depends. Most things don't need the absolute maximum performance. &gt; Here is a case for asking this question. For making the outbound networking calls, you mean?
Corrected. Thank you and Thank you. 
That makes sense, but at the same time I find it unlikely that the devs will rewrite the entire language from scratch. Also, considering that RLS is maintained by the rust devs, it doesn't seem like that much of a hassle to keep it in sync feature-wise. RLS doesn't need to expose the raw AST, some details can be stripped away and it would still be useful for IDEs.
I'm having some difficulty with sending a POST request using [hyper](https://hyper.rs/). Specifically, I'm trying to extract a specific shader's source code from [Shadertoy](https://www.shadertoy.com/), and while I've managed to write a small Python script to do it (using the [requests](http://docs.python-requests.org/en/master/) library), I can't seem to get hyper to cooperate. For reference, the Python code is: #!/usr/bin/env python3 import requests import json # Request components url = "https://www.shadertoy.com/shadertoy/" headers = {"Referer": "https://www.shadertoy.com/" data = {"s": '{"shaders": ["Ms2SD1"]}'} # POST request res = requests.post(url, headers=headers, data=data) # Response data (includes source code) print() print("Status code:\n\t", res.status_code) print("Headers:") for header in headers: print("\t"+header+":", res.headers[header]) print("Data: ") print(json.dumps(res.json(), indent=2)) And the analogous Rust code (using hyper 0.7) is: extern crate hyper; use std::io::Read; use hyper::Client; use hyper::header::Referer; fn main() { let client = Client::new(); let mut res = client.post("https://shadertoy.com/shadertoy/") .header(Referer("https://www.shadertoy.com/".to_string()) .body("s={\"shaders\": [\"Ms2SD1\"]}") .send().unwrap(); println!("Status: '{}'", res.status); println!("URL: '{}'", res.url); println!("Headers:\n'{}'", res.headers); let mut buf = String::new(); let bytes_read = res.read_to_string(&amp;mut buf).unwrap(); println!("Read {} bytes", bytes_read); println!("Response: \n'{}'", buf); } While I'm able to extract the source code (and other response data) from shader `Ms2SD1` with the Python script, the Rust code's response always includes an empty body. I tried URL-encoding the data too and that didn't seem to work either. Any ideas?
Another argument in favour of RLS: GSOC lasts only a limited time, so adopting RLS might have a more lasting benefit than implementing everything yourself as Rust changes stuff and adds features. However, you'll probably learn far more by implementing it yourself, and that's (I think?) more of the point of a GSOC.
&gt; That makes sense, but at the same time I find it unlikely that the devs will rewrite the entire language from scratch. It's not always clear how much a new language feature changes the AST. Also having the option to rewrite the AST to make it more performant, use less memory, is a nice thing to have. &gt; Also, considering that RLS is maintained by the rust devs, it doesn't seem like that much of a hassle to keep it in sync feature-wise. But that's just one application - every application using the RLS gets the update for free - and the teams developing the compiler and the RLS are quite close, so updates should be bit smoother. &gt; RLS doesn't need to expose the raw AST, some details can be stripped away and it would still be useful for IDEs. That's true, but someone has to maintain this reduced AST and having to keep the reduced AST with the real AST in sync, can also become quite a bit of work. 
[Here comes another one](https://www.youtube.com/watch?v=zpv5kFMcq8I).
Ah, no worries! :)
I see. Generating skeleton trait impls and matches would be extremely useful indeed.
I found this, which is what /u/Leshow might have been referring to: https://github.com/rust-lang/rust/pull/15955
I meant it's a problem in a small number of use cases, not that the problem is small.
Hello, I want to create a hashmap where keys have type Rc&lt;T&gt; and they are equivalent iff they point to the same object. - Is the following implementation correct? - Is there a more elegant way how to implement this? Thank you use std::rc::Rc; use std::hash::{Hash, Hasher}; use std::collections::HashMap; use std::cmp::Eq; struct PtrWrap&lt;T&gt; { data: Rc&lt;T&gt;, } impl&lt;T&gt; PtrWrap&lt;T&gt; { fn new(data: Rc&lt;T&gt;) -&gt; PtrWrap&lt;T&gt; { PtrWrap { data: data } } } impl&lt;T&gt; Hash for PtrWrap&lt;T&gt; { fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) { let ptr = &amp;*self.data as *const T; ptr.hash(state); } } impl&lt;T&gt; PartialEq for PtrWrap&lt;T&gt; { fn eq(&amp;self, other: &amp;PtrWrap&lt;T&gt;) -&gt; bool { Rc::ptr_eq(&amp;self.data, &amp;other.data) } } impl&lt;T&gt; Eq for PtrWrap&lt;T&gt; {} impl&lt;T&gt; From&lt;Rc&lt;T&gt;&gt; for PtrWrap&lt;T&gt; { fn from(s: Rc&lt;T&gt;) -&gt; Self { PtrWrap::new(s) } } struct S {} fn main() { let mut m: HashMap&lt;PtrWrap&lt;S&gt;, i32&gt; = HashMap::new(); let x = Rc::new(S {}); let x2 = x.clone(); let y = Rc::new(S {}); m.insert(x.into(), 12); m.insert(y.into(), 24); assert!(12 == *m.get(&amp;x2.into()).unwrap()); } 
Could you satisfy my curiosity by explaining how can I create a `futures::stream` which simply returns incrementing numbers in some range?
 extern crate futures; use futures::*; fn main() { let mut stream = stream::unfold(0, |state| { if state &lt; 5 { let res: Result&lt;_,()&gt; = Ok((state, state + 1)); Some(res) } else { None } }); assert_eq!(Async::Ready(Some(0)), stream.poll().unwrap()); assert_eq!(Async::Ready(Some(1)), stream.poll().unwrap()); assert_eq!(Async::Ready(Some(2)), stream.poll().unwrap()); assert_eq!(Async::Ready(Some(3)), stream.poll().unwrap()); assert_eq!(Async::Ready(Some(4)), stream.poll().unwrap()); assert_eq!(Async::Ready(None), stream.poll().unwrap()); } https://docs.rs/futures/0.1.14/futures/stream/fn.unfold.html
That's why he said to generate your own
Sure, there's more rustc could do to find UB. A static analysis will never be complete though (as in, it will always miss some UB) -- and currently, we don't even know *what* should be UB and what not. A static analysis, because it is incomplete, is not suited to define UB.
From what I know, compiler currently emits save-analysis data (hidden behind a flag) that is basically all metadata that was required during whole process of compilation, which has all kinds of information (not sure about exact format or if it does expose AST). Currently RLS consumes data that is processed by rls-analysis (which aims to provide stable API iirc) and operates using that. There is work being done for query API on the compiler side, which would provide more streamlined and stable way to query all the required metadata for parts of the code, but again, I'm not sure about the details and take what I'm saying with a grain of salt.
That's true, I missed updating the commit comment when I removed the binary_search optimization.
That's actually a pretty reasonable build process. It might be nice to have an automated builder for that. 
All of this discussion reinforces my dislike of languages that fundamentally rely on using IDEs. Eg. Java with its omnipresent context-dependence ("does this symbol come from local scope, class scope, parent class scope, namespace?"), ridiculously long namespaces (`org.ourorg.ourproductx.scheduler.subsystem.encryption.util.aes.AesFactory`), elaborated, deep class hierarchies, etc. is just a pain to work with. When creating language it is very important to assume the developer has only Notepad and maybe shell available, and not that it has sufficiently awesome IDE that costs million dollars per license, and took 30 years of thousand people to develop. Sure, if you can get such IDE, I am happy for you, but it must not be a requirement to comfortably work with such a basic tool as a programming language. I am happy that RLS is being worked on, but in the meantime, I'm even happier that Vim with a couple of plugins and tools is already very productive development environment for Rust. :)
[Link to RFC \#1859](https://github.com/rust-lang/rfcs/blob/9c14315070678e71c01f82a41d50b2489747b62c/text/1859-try-trait.md)
No, we have not moved to that, and we still use unification throughout. These days, the hope is to move *closer* to HM, by separating out subtyping (for lifetimes) concerns entirely.
SipHash is not a cryptographic hash but is suitable as a message authentication code. See https://en.wikipedia.org/wiki/SipHash
Love the support for embeding! Very cool project!
Both [The Rust Programming Language](https://www.nostarch.com/rust) and [Programming Rust](http://shop.oreilly.com/product/0636920040385.do) are available in early release forms as ebooks from their respective publishers. Programming Rust has more chapters available, but neither are complete or totally edited. As mentioned in another chapter, though, you can print to PDF from the online view of TRPL.
Wow, /u/perplexinglyemma, the comments on your first post are, uh... wow. Not from any official Rust team members, let's say that. I'm not sure why they're trying to convince you to abandon your GSOC project?!?!? I'm excited to see what you create! I love the overview you've given in this post about what the LSP is and is not capable of currently, and how your KDevelop plugin could work. Best of luck!
That's a good blog post, right there. These criticisms of the LSP are compelling.
Co-creator of RLS here. Definitely some good points raised here. I'd *love* to see some of the features you mention available. I think part of the current state of affairs is a bit of a snapshot in time, so let me see if I can talk to that, though there may be lots of areas that can be improved by taking more nuanced approaches. Onto specific points: * LSP isn't extensible Yes, this is true in the sense that if you write a plugin that's LSP-focused that you will get the LSP experience and not light up the additional functionality that the LS provides. Yeah, this is unfortunate in a way, especially since so much stuff a Rust IDE would want is pretty specific to Rust (give me all implementations of this trait, etc) LSP's basic commands are a little helpful in that you can use some of them to make more complex commands. Then again, that only works for some things. Other commands like "to go the definition of the type of this expression" are natural extensions of what the LS is already doing behind the scenes. I'm *hoping* that the base features of the LSP let people bootstrap basic support more easily, and then they can add more RLS-specific features after they have the basic ones implemented. * Completion isn't so great True. We've been working on getting the compiler ready to serve the RLS for many moons, with the hopes the compiler could drive completions, too. Currently, we're still using Racer. It's heuristic approach definitely has some limitations. One of the bits of a completion that is tricky with Rust is that the completion engine has to understand the trait system. The example in the blog post points out you can't dot off a number, which is an example of needing that trait information handy. There may be space between the racer approach and the full-on compiler approach. If so, I'm sure RLS could switch to this new approach if it worked better than Racer, while waiting for the full compiler approach to be finished. There's also the rls-analysis crate, which could also use more help. As more features get added there, they could get lit up in IDE support. All that to say there are a lot of ways to help out! Whether improving the completion approach, improving RLS, improving the crates the RLS uses so both it and other IDE tools improve as well. There's also the dev tools team, which I'm sure would be another good resource for information. 
Likewise. One of the most comfortable ways to make my various originally-for-Linux Python scripts useful to Windows-using friends is to slap a frontend on them using [EasyDialogs for Windows](http://www.averdevelopment.com/python/EasyDialogs.html) and then pack them up using [py2exe](http://py2exe.org/). It'd be nice to have a similar option for Rust that has broader utility than just Windows.
Worth adding that I'm an incrementalist at heart, but don't let that discourage you from aiming big! I'm sure Nick, myself, or some of the other dev tools folks would be happy to be a sounding board.
You're definitely not overreacting :) &lt;3 People out there reading this, if someone wants to try and do something, let them! Geez.
Just to clarify: all I am saying is that language that works OK will simple text editors, does not hinder users of IDEs, but languages that rely on IDEs hinder working with a text editor. On a completely separate, flame inducing comment, in my humble opinion, IDEs are a typical idea that sounds great in theory and fails miserably in practice. Ideas like that typically start with assumptions that are simply not true. In case of IDEs the assumption is that something as complex as feature-full IDE is already available and working reliably without introducing problems on it's own, portable, supporting any development environment that developer might need to work in, any programming language that the product components might be written in, integrates well with other components that might be need, in ever-changing world. It assumes all developers have the same opinion on which OS and IDE to use and are willing to invest their time to learn it well and so on... As a good example I could point to Scala. It is somewhat similiar to Rust but inherited all bagedge of IDE-first thinking from Java. and boy working with Scala sucks so much comparing with Rust despite 20 years of head-start. And I can totally see how "text-editor and shell"-first culture shapped a much more pragmatic, flexible and productive programming language culture. Joke: The reason why C overtook the world when clearly supperior languages were already available at the time, was that non-C developers were still configuring their IDEs, while C developers were already productive in text editor of their choosing.
I break backward compatibility in my crates whenever I find a better way to do something that requires breaking backward compatibility. I've found that it's often easier to give small amounts of assistance to people affected by the breaking change than it would be to do the extra work of maintaining backward compatibility. Maintaining backward compatibility means your crate's code is worse than it could be and also the code in the crates using your crate is worse than it could be. Based on my experience, there seems to be a negative correlation between people complaining about breaking changes and people contributing (submitting patches, filing issues, productive criticism, building interesting things, etc.) to my projects—people who complain don't contribute, and people who contribute don't complain. I've also not had anybody ask for backward compatibility even in the context of discussing possibilities of paid work. Therefore I see spending any effort to maintain backward compatibility to be purely counterproductive.
This is what you can use an `Arena` for (a simple crate is typed-arena). In contrast to other collections, they don't allow removal and reallocation so that giving out pointers for the lifetime of the arena can be mixed with adding new pointers.
Looks good to me.
Unfortunately, `save-analysis` only emits data on a small subset of the analysis done by the compiler. And getting more of this data out of the compiler is not trivial. The analysis code was not all written to be easy to get metadata from.
Here's the schedule: http://cppnow.org/program-2017/ Two other days open with talks about other languages (Haskell and D). Maybe the idea is to get some perspectives from other approaches?
You probably didn't see [Mike Acton's keynote](https://www.youtube.com/watch?v=rX0ItVEVjHc) at the first CppCon telling that everything in C++ beyond C99 is useless. This is a good tradition of taking people from their language bubble and shocking them a bit.
Pretty sure DConf also has C++ talks. This isn't super abnormal. Pycon had a rust talk. Most big language conferences are willing to hear about another language, so long as it relates to the language the conference is about.
&gt; Do the results make sense to you? Absolutely. When I develop a new library (in any language), I try to iterate often to make it as good as it can be. But I can imagine people being out there who don't want to change so fast. If Rust (or any other language) wants to achieve wide adoption, it has to fulfill needs of as many people as it can, not just those who embrace the change.
Tracked here: https://github.com/sharkdp/fd/issues/29
Three things I had to add to make it work: * address is missing a `www.` * add a Content-Type header with application/x-www-form-urlencoded * properly URL-encode the body 
I'd like to raise some more attention on this. While I'm open for discussion, I don't find the reasoning in the RFC convincing at all.
What concept am I missing related to iterators with this program? It counts stdin like `sort | uniq -c | sort -n` will... just a lot faster as long as the unique keys fit in ram. use std::collections::HashMap; use std::io::{self, BufRead, BufWriter}; use std::io::Write; fn count(max_rows: usize, reverse: bool) -&gt; Result&lt;(), io::Error&gt; { let stdin = io::stdin(); let mut counts = HashMap::new(); for line in stdin.lock().lines() { let l = line.unwrap(); let stat = counts.entry(l).or_insert(0); *stat += 1; } let mut pop: Vec&lt;_&gt; = counts.iter().map(|(k, &amp;v)| (k, v)).collect(); //pop.sort_by(|&amp;(_, c1), &amp;(_, c2)| c2.cmp(&amp;c1)); pop.sort_by_key(|t| t.1); let results = pop.iter(); let n = if max_rows &gt; results.len() { 0 } else { results.len() - max_rows }; let final_results = results.skip(n); let final_results = if reverse { final_results.rev() } else { final_results }; let mut writer = BufWriter::new(io::stdout()); for &amp;(k, v) in final_results { writer.write(k.as_bytes())?; writer.write(b"\t")?; writer.write(v.to_string().as_bytes())?; writer.write(b"\n")?; } Ok(()) } fn main() { count(10, true).unwrap(); } It works fine aside from the let final_results = if reverse { final_results.rev() } else { final_results }; line. I had a similar issue with conditionally calling `results.skip()`, but was able to solve that by always calling `.skip`. The error I get is error[E0308]: if and else have incompatible types --&gt; src/main.rs:22:25 | 22 | let final_results = if reverse { final_results.rev() } else { final_results }; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected struct `std::iter::Rev`, found struct `std::iter::Skip` | = note: expected type `std::iter::Rev&lt;std::iter::Skip&lt;std::slice::Iter&lt;'_, (&amp;std::string::String, {integer})&gt;&gt;&gt;` found type `std::iter::Skip&lt;std::slice::Iter&lt;'_, (&amp;std::string::String, {integer})&gt;&gt;` Which I don't really understand what the issue is or what exactly it wants me to do about it. I have a feeling it's something like let final_results: generic iterator type expression = if reverse { final_results.rev() } else { final_results }; 
For many years a feature of DjangoCon was a keynote to the effect of "Why Django Sucks". We had everyone from core devs of competing frameworks to large websites which didn't use Django give those talks, and they were always a highlight of the conference :-)
It depends on the popularity of your library. The larger the library is, the more likely your contributors are to be negatively impacted by breaking changes. The effects of breaking changes are very much mitigated by versioning, which Rust makes really easy with cargo. Because of this, I think the community can bear quite a bit more breakage than other communities as you can upgrade dependencies relatively independently.
Anybody know of a filesystem database for Rust? I want to store some cached info for my command-line application, just locally for the user, like `~/.myapp/cache.txt`. But I'm concerned about performance for processing the text file. Wondering if there's a good alternative.
What is that ?
Wrong subreddit, you want r/playrust
He's messin with ya. This is rust the programming language, not rust the game. Try /r/playrust.
Lol ty
Oh my mistake, I see my misunderstanding, thanks for clarifying. I think I might just replace my comment or delete it, to avoid confusing others
Deleting would make *my* comment confusing though :P I hope Rust gains some syntax for specifying "out" type variables explictly, if only for pedagogic reasons
Thanks for the thoughtful post! I'm keen to see what you come up with in KDevelop. So, a proper response probably needs a blog post of its own, but let me try to reply. First off, the RLS is work in progress. There is a lot missing and I hope we can improve it a lot (contribution very, very welcome, of course). IMO, adding features to RLS is easier than starting again from scratch, but of course working from first principles is more fun and you'll learn more. I think that there is probably more working than you think - try the VSCode plugin - https://github.com/jonathandturner/rls_vscode - certainly some things that don't work in the blog post do work there (and some don't - contextual completions is a great example of something I want to add). The LSP is also work in progress - it has only been around for a year or two and there is a huge history of IDE work to catch up with. MS are adding features and I'm confident that it will get better as time goes by. They are developing mostly in the open and are pretty good at listening to feedback. Then there are larger points about the architecture of IDEs - using a language server is a somewhat newer approach than using a plugin framework. IMO, it gives a better separation of concerns. I agree that an IDE should do more than just editing and goto def, but I think a lot of what an IDE does is language-specific, and it is better to share code between IDEs (the language server approach) than it is to share code between languages in a single IDE (the more traditional approach). Thinking like this I think that sentiments like "language servers is that they take all of that information away from the IDE" don't really make sense - what does "away from the IDE" mean? Why is the language server not considered part of the IDE? I mean, I think reasonable people can disagree about the best architecture, and if you are in the 'large' IDE camp, then language servers don't offer you much. But I believe that the language server architecture is a great alternative to that and long term will be a better model. I really don't agree that "[the] LSP is inextensible" - the argument that IDEs will ignore a language server's extensions ignores the fact that the alternative is to support the entire language directly in the IDE. To put it another way, IDE plugins that use the LSP are lightweight, but they are not trivial. "No way am I missing the opportunity to implement type inference" - a statement I heartily agree with - this would be a really fun thing to implement. However, I would caution that this is a *huge* amount of work. To do get enough information to do jump to def/completion you would need to reimplement parsing, macro expansion, name resolution, type inference, trait selection, and resolving associated types. That assumes that you can effectively erase all lifetime information and skip checking of anything lifetime related. Even then, you'd miss a whole bunch of errors (e.g., coherence errors, type errors due to lifetimes, borrow checking) so you'd still need to run the compiler to give complete error/warning info. IntelliJ do take this approach - they do their own parsing and name resolution and are working on type inference. However, their analysis is incomplete and has taken them years of work.
&gt; Out of all applications that had some kind of memory leaks or what I consider unreasonable memory usage, I can remember only a single which wasn't written in GCed language. Maybe coincidence, maybe not. I'm not saying that's the problem of GC. Maybe it's just that GC encourages careless code? Or maybe those particular GCs were shitty? Again, unless there is some evidence or logical reason to attribute the problem to GC I wouldn't. I actually just upgraded to a 32GB desktop precisely because I kept running out of memory. The problem applications are Google Chrome, Microsoft's OneDrive and OpenSCAD which are, I think, all C++. &gt; You don't have to unless you have to do it sooner than end of the scope. Maybe you'll get luckily if you leak everything to the end of scope. I found I wasn't that lucky so I had to manually `drop` values to plug leaks in my Rust code. Another alternative is to constrain the style of coding to make scopes convey tighter bounds on liveness but, coming from languages where this is a no-brainer, that is the tail wagging the dog. Also, it is objectively worse than liveness analysis because scopes must nest. I find it amazing that people are still making languages with broken support for recursion when it was originally fixed by Scheme in the 1970s, over 40 years ago. &gt; The other way is using {} to create manual scopes. Oh, ok. But collection is still at the end of scope, just a different scope? &gt; Anyway, I think most reasonable functions are short enough, so this shouldn't be a problem. Are recursive functions unreasonable? &gt; I guess in some cases this is impossible due to lifetimes. I think I've seen someone suggesting it but any such change is blocked by borrowck not being ported to MIR yet. Also, I guess that could break unsafe code: Basically every garbage collected language ever already solved that problem in order to get a working FFI. I find it disturbing that Rust also managed to get that wrong. &gt; Rust is a young language, remember? Is it? I've been [pointing out](https://twitter.com/jonharrop/status/247069155818364928) the flaws in Rust's memory management for over 5 years. I even pointed them to the pre-existing correct solution I wrote for HLVM in 2008 and gave away under a BSD license 9 years ago... 
I love this project. Great to see a Forth-ish extension language.
I agree this is an issue with `chrono` using the deprecated `time` crate. Unfortunately I don't think we could really add a feature flag for `chrono` date types to `walkdir` because the metadata type comes from `std`, and isn't defined by `walkdir`. `chrono` is coming up for libz blitz review in the future though, so converting between `std` time and `chrono` time will definitely come up then.
Hm interesting, do you have an example of where you're doing this you can point me to?
Scala is definitely *not* designed with IDEs in mind. The type inference and implicit resolution etc. are incredibly hard for IDEs to deal with.
Cool. I thought a requirement of HM was global decideability. Perhaps, that's just Haskell's requirement
While on the one hand this does introduce some magic into a language that has traditionally shunned it, I've been thinking about giving a mini tutorial on the specific topic of patterns in Rust and it's almost embarrassing how much nicer this rule makes many code examples look.
It's all [Rusoto](https://github.com/rusoto/rusoto), all the time over here! Been reviewing PRs to clean up leftovers from shattering the crate and helping groom github issues. I've also gotten around to fixing an issue for www.rusoto.org which is [our gitbook for Rusoto](https://github.com/rusoto/rusoto.github.io) so we can push changes to the web site faster. Actually I have done some work outside of Rusoto. I've updated [release-party-br](https://github.com/matthewkmayer/release-party-BR), a tool we use at $day_job for smoothing out our (at least) biweekly production deploys. I've converted it to use clap for command line arguments. In flight: supporting `--yolo` when you can't be bothered to actually review what's going to production. More of a joke feature but an excuse to work on a smaller project. :)
If he thinks destructors are useless, then he is the one in the bubble, however I've watched the whole presentation, loved it, and don't remember those claims. 
I've taken a few baby steps in Rust previously but have not yet done anything of significance so several key concepts of Rust are still vague to me. This keynote is absolutely stellar thus far at 26:28 into the video. Very nicely explained. So much so that at this point I would have liked to just lock myself up in my room for the duration of the summer and write code in Rust all day erryday. Unfortunately I can't do that, what with my summer job and all that. But if I could I would.
&gt; It seems like the mostly just makes the language more complicated for little gain. Complicated in some senses, easier in others. Consider closures and their inference; `|x| x + 1` is much nicer than `|x: i32| -&gt; i32 { x + 1 }` IMO, even if it's "more complicated" in some other senses.
Yes, the plan is to transition from save-analysis to that API, but that's really an implementation detail, basically.
I like the moderators note: &gt; EDIT #2: I like how this thread is mostly novel-length comments.
True, C++ borrows from everything. This makes me wonder, would it be possible to have "safe" C++ in the way rust is by default. That is, you declare a module or function as safe, in the same way rust might declare a function unsafe in rust. Then the C++ compiler ensures that only memory safe parts of the language are used in that part of the code, with the same level of safety as rust. It would require new additions to C++, I would image such as ownership and borrowing. But is there any fundamental reason it couldn't be done while still being backwards compatible?
At my work I'm the 'translator guy'. I turn whatever one machine speaks into the stuff our products speak. Parsers out the wazoo! Doing this year after year, you *definitely* build tools help you to do this. That, or you become a heavy drinker.
We certainly want it to but I think it was punted out of the first pass RFC.
In addition to what /u/zzyzzyxx said, in general you can in such cases move the code using `final_results` into a generic function and call it twice (once in the if branch, once in the else branch). That allows Rust to instantiate (and later optimize) the generic function twice, with different iterator types.
Probably an even better example though is how complicated capture is. `|x| x + y` Just Works without you having to specify how `y` was captured (sometimes you have to say `move`).
IIRC this is how rust first started. Initially, what was tried were compiler plugins to promise safety but ended up being impossible or unideal.
In general, I don't think so. Unsafe code in rust still has to obey some borrowing rules at the boundary with safe code. It's just that those rules are not actually statically checked. You're basically saying to the compiler "don't worry, this is all fine, I just can't really prove it to you." But current c++ is way worse than even this. The problem isn't just an inability to generate a proof, it's that there are very few places to draw the boundary such that the code inside actually does obey the rules!
use [safaribooksonline](https://www.safaribooksonline.com/search/?query=rust) . It has 10 days trial :)
Thanks! A lot of the discussion seems to be revolving around figuring out exactly what LLVM is even doing (and what it says it's doing and whether these two even align). Admittedly, LLVM is necessary at this point, so that sort of discussion does need to happen, but none the less, I would caution against letting it influence your actual design semantics. Get a mathematical model (even if it's not formalised in code) so you can answer with confidence what is valid and what is not, and then worry about translating valid constructions to LLVM. Designing your semantics should not be bottom-up determined by whatever silliness LLVM decided to drop into their repository, especially given that all indications are that they're basically flying blind on this.
&gt; Google Chrome I guess that may be because of JS under the hood? Anyway, I admit that proper research would help. From what you write, I assume you use recursion often. I myself intentionally avoid recursion because it makes it harder to reason about stack consumption. I can see now why this is an issue for you and not for me. The resources for improving Rust are limited, so people have to choose priorities. Obviously most developers chose other things before solving recursion-induced memory leaks.
Exactly! Like I said, in my initial comment, for one person, it's doable. I feel reasonably confident I could manage this on my own; I have a decent idea of a consistent "ethic" to use when writing C++ code. It's not the same as the (often equally valid) ethic used by other folks, but it works! It's when folks get together, or when you need to be able to make major refactors to large codebases (which is an inevitable thing in large codebases), that it gets really hard or impossible.
I am a Java/.NET/C++ programmer, that adopted C++ as next favorite language after Turbo Pascal, still in the MS-DOS days, as I was never convinced about C. My comment history is a proof (here and HN) that I also wish for Rust's success in the long run. The adoption of every programming language that decreases the amount of existing C code in the world is a good thing.
The example you showed is (almost) fine and does not affect readability. But the thing I don't like is 1. When different magic rules are applied to different arms of the same match block. Consider for example: match res { // res: &amp;Result&lt;T, E&gt; &amp;Ok(x) =&gt; { ... } // x is copied out Err(y) =&gt; { ... } // y is ref-ed } 2. Unless I keep track of the type of `opt` in the following example, I can't be sure of the type of `x`. This is almost fine since in most cases the type would be easily deductible. match opt { // opt: ??Option&lt;T&gt; Some(x) =&gt; { ... } // x is ref? None =&gt; { ... } } Also, this is not a problem when you're writing code. The confusion arises only when reading code.
Hmm... How is this better than just statically linking Rustls? I assume it is to do with it's unaudited state?
I think the first point is solid (I'm not sold on the aspect of this proposal that allows different arms to follow different behaviors), and you should post the concern on the thread to try to stir some more discussion of the trade offs with that choice. The second seems no different than `for` loops though..
destructors are from before C99 though ;)
Towards the end there's a shot of the audience, and I'm sad to see that the room is mostly empty.
Selects in rusqlite are insanely ugly. I went so far as to use the sqlite-sys crate directly. All you need are a couple of utility functions and things are way easier and clear. The problem with rusqlite is once you have an issue you have no idea where the error comes from and what to do about it. 
The compiler can not deduce the type solely from its usage in comparison to `u32`. Many types can implement `PartialEq&lt;u32&gt;`, it is not 1-to-1 mapping. As for unwrap, have you tried the question mark operator? As for annoying passing of an empty argument slice, you can implement your own helper method in a trait: trait QueryRowNoParams { fn query_row_no_params&lt;T, F&gt;(&amp;self, sql: &amp;str, f: F) -&gt; rusqlite::Result&lt;T&gt; where F: FnOnce(&amp;rusqlite::Row) -&gt; T; } impl QueryRowNoParams for rusqlite::Connection { fn query_row_no_params&lt;T, F&gt;(&amp;self, sql: &amp;str, f: F) -&gt; rusqlite::Result&lt;T&gt; where F: FnOnce(&amp;rusqlite::Row) -&gt; T { self.query_row(sql, &amp;[], f) } } It is then usable as `conn.query_row_no_params("SELECT 1", |r| r.get(0));` As you seem to be using a transaction, you would need to implement this on the `Transaction` type as well.
I get what you're saying, but the override method has its problems, too - now the user has to know that it has to have a sound, and which sound to play (parent or child class?), etc. The way to go about this is this: trait HasVoice { // the trait that other types have to implement // simply returns the VoiceSound fn&lt;'a&gt; get_sound(&amp;self) -&gt; &amp;'a VoiceSound; } impl Voice { pub fn render_next_block(voice_to_render: &amp;T) where T: HasVoice { voice_to_render.get_sound().render(); } } I would really think about if this is really necessary. Usually stuff like this is a hint of bad design, making stuff dependent on fields. The Rust-y way to go about this, would simply be: impl Voice { pub fn render_next_block(voice: VoiceSound) { voice.render(); } } This way you are forcing library users to supply a VoiceSound to your function and you don't hide it in a trait. Where they get the VoiceSound from is up to the user. Think simpler. 
Really, I would much prefer if there was a separate file for metadata like this, and things like documentation links, etc., that could be updated without having to release a new version of your package.
Look for the libz blitz thread on the user forum: The lib team evaluates crates and opens a bunch of issues to make them better. These issues are usually "follow this guideline" and most of them are fixable by beginners. (Some of them are linked by This Week in Rust.)
It also depends on whether you intend your library to be used directly, or indirectly through an abstracting library. E.g. I have written crates to decode ogg/vorbis files, using them directly is possible, but most people use them through crates that unify multiple decoders for formats like flac or wav. So I rather break without hesitation. Also, I expect that the code inside codebases that actually uses my library is fairly small: its only to interface with existing code. On the other hand, if you have a library that is used throughout the codebase, a breaking change a bigger problem. E.g. iterator libraries, or libraries for custom stack vec containers, etc.
You can use the GNU version on Windows, which doesn't require MSVC. When running rustup-init.exe type in stable-x86_64-pc-windows-gnu to get it.
This is an excellent "Rust for C++ developers".
That reminds me of the series of "Linux sucks" talks by Bryan Lunduke at various Linux meetings/conferences. The speaker would point out weak spots and things that don't yet work and often have not been working for a long time to the frustration of many. :-)
Thanks a lot! I've installed it via `rustup toolchain install stable-x86_64-pc-windows-gnu` and it compiled my scripts without any problems. Does the use of a different toolchain in any way limit the libraries I can use (e.g. if they contain something platform-specific)?
This might be trivial. In Java, if I don't want to commit to a data structure, but I know what the contents should be, I can do this. public void example(Iterable&lt;DesiredType&gt; c) { for (DesiredType d : c) { /* do stuff */ } } Is there an equivalent in Rust? It seems like there ought to be, but I'm having trouble with the syntax.
I don't think you're remembering rust. Rust began as a fairly different language written in ML.
I love their open-mindedness, proglangs are not religions and letting Rust person talk at their opening. This is very good for our industry.
I'll try that out. I think I'll first benchmark just writing a HashMap to a text file, and do some cargo benchmarks with millions of rows.
Thanks, worked like a charm!
Are there crates that implement collection traits? For example, something that can be used to abstract over vector/deque/linked_list?
I did, because withoutboats responded on my comment. They said that we cannot revert the decision, but given that it's feature flagged it's more about trying it out than a final decision.
Churchill was a LONG time ago.
What kind of abstraction are you looking for? Is it iteration? `Iterator` Is it indexing? `Index` Is it fallback to slice? `AsRef&lt;[T]&gt;`
Okay, but the usual protocol when responding to an unrelated comment is to latch on to one of the top comments, not one of the bottom comments;)
If it's not part of a trait, then you can't generically constrain on that trait, you have to concretely accept a single type, which is not necessarily what you want. It's nice to be able to accept any object that implements HasVoice.
&gt; You can use the GNU version on Windows Misread that as `of` and thought I heard screaming from beyond the void.
&gt; vcvarsall.bat Actually, I've tried to directly execute this file instead of rewriting %PATH% manually and it worked! Now the MSVC version also works! I've found it in `...\MSVCBuildTools\2017\VC\Auxiliary\Build\vcvarsall.bat`.
Nice! BTW, you might want to look at [reqwest](https://crates.io/crates/reqwest) which aims to be the equivalent to `requests` on the Rust side.
Some might like to throw macros at this particular boiler-plate problem ;) I feel a little uneasy about that, coming from a C++ background.
Obligatory: http://robert.ocallahan.org/2016/06/safe-c-subset-is-vapourware.html It's said they started work again last month. https://github.com/isocpp/CppCoreGuidelines/issues/523#issuecomment-301570219 Maybe there's more recent comment elsewhere, but AFAIK they've never said what the plan is to resolve the issue. (I think there is a way to have memory safety and Rc without the Refcell requirement - because Rc cycles are generally not a good idea anyway. Enforce guidelines like the ones [here](https://github.com/CppCon/CppCon2016/blob/master/Presentations/Lifetime%20Safety%20By%20Default%20-%20Making%20Code%20Leak-Free%20by%20Construction/Lifetime%20Safety%20By%20Default%20-%20Making%20Code%20Leak-Free%20by%20Construction%20-%20Herb%20Sutter%20-%20CppCon%202016.pdf). Keep track of _depth_, like an additional parameter on your Rc type. But this is just my own handwaving. EDIT: the rust project made several attempts at this [and did not succeed in making it humanly usable](https://mail.mozilla.org/pipermail/rust-dev/2013-June/004411.html)).
Yes it does. Here's the example: // create a Sha512 object let mut hasher = Sha512::default(); // write input message hasher.input(b"hello world"); // read hash digest and consume hasher let output = hasher.result(); // output[..] The first line preps the hash, the second hashes and the third gets the result. The last line (commented out in my example, in an assert in the original) shows how to slice. That's exactly what your Python code does. If you have a specific question, I'm sure someone would be happy to help, but we don't understand where you're getting stuck.
Not OP, but my background is fairly mixed, but more recently I'm coming from Go, which uses coroutines instead of futures. I also come from node.js, so tokio isn't super foreign, but it can still be better with some syntax sugar to make it feel closer to Go.
Can confirm, I use tokio-core for my game server, which is more pub sub than request response.
If he meant C++ features, why wouldn't he say C++03 or whatever that standard was? 
Macros in Rust are a lot less dangerous, so I wouldn't be afraid of using them. The main thing to keep in mind is that macros can obscure what's actually happening, so for public APIs it's best to use them sparingly, and even internally, it's good to make sure that what the macro does is clear.
Honestly I feel `for` loops are a bit too magical too. I still do `.iter()` and `.iter_mut()` etc. explicitly a lot unless I'm having a "I wonder if this works" moment which it sometimes does and sometimes doesn't.
Why has nobody linked this?^1 It is _the_ Rust book. https://doc.rust-lang.org/book/ ---- ^1 Maybe because OP doesn't seem to know what they're looking for
Churchill is the worst person to quote, except for all the others.
Well, in a team the CI server checks all the things you mentioned. :)
Because `&amp;cb`. In `iterate::&lt;F&gt;`, `cb` is of type `&amp;F`. So `&amp;cb` is of type `&amp;&amp;F`. Which means it's calling `iterate::&lt;&amp;F&gt;`. In `iterate::&lt;&amp;F&gt;`, `cb` is of type `&amp;&amp;F`. So `&amp;cb` is of type `&amp;&amp;&amp;F`. Which means it's calling `iterate::&lt;&amp;&amp;F&gt;`. In `iterate::&lt;&amp;&amp;F&gt;`, `cb` is of type `&amp;&amp;&amp;F`. So `&amp;cb` is of type `&amp;&amp;&amp;&amp;F`. Which means it's calling `iterate::&lt;&amp;&amp;&amp;F&gt;`. Repeat ad stackoverflinitum. &amp;nbsp; Use `cb` instead.
A better-formatted example for those whose eyes glaze over: let text = Text::new( "assets/Macondo-Regular.ttf", "paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified paragraph justified"); let element = text .color([0.4, 0.4, 1.0, 1.0]) .shadow([-3,-3,3,3],[1.0,1.0,1.0,1.0]) .scale(2.0, "em") .width(25.0, "%") .align("justify") .translate_x(150.0, "px") .translate_y(150.0, "px"); v.append(element); 
First one needs to convince the team, management and IT guys that a CI server is needed. Ah and most probably explain what it is good for! I am not joking, many enterprises still do IDE/Editor based development, moving zip files around.
Good luck convincing them on Rust though ;)
&gt; I've managed to install MS Build Tools 2017 (from here) Support for MSVC 2017 landed [very recently](https://github.com/rust-lang/rust/pull/42225), and so will happen in Rust 1.19. Until then, you need to run `vcvars` or use MSVC 2015. I'd encourage you to use it over the GNU target.
Yeah sorry about that, Medium doesn't support good code formatting.
He said that the only advantages C++ has over C99 for the work they're doing are Visual Studio support and talent pool.
Very cool. I think something like this should be in std/the compiler though. PS: as Lokathor has mentioned - you were going for s-cat aka string-cat, I assume. Scat can also mean something quite different: https://en.oxforddictionaries.com/definition/scat
It's time to update! The pub new syntax is really cool.
Very nice, have to play around with `pub(crate)` now. The section regarding struct layout could use a mention of `#[repr(C)]`.
&gt; The section regarding struct layout could use a mention of #[repr(C)]. I'd be happy to take a PR if you'd like to send one in!
I'm not sure why you are trying to introduce `Indexable` since `IndexMut` is already defined as `IndexMut&lt;Idx&gt;: Index&lt;Idx&gt;`. `Index` + `IndexMut` *is* `IndexMut`, so you can use `IndexMut` anywhere you want `Indexable`. I'm also not sure what is the purpose of `where Vec2d&lt;T&gt;:ops::Index&lt;(i32,i32), Output=T&gt;`, that you want to get rid of. It seems to me that it is redundant: `IndexMut` requires `Index`, so this where clause is already covered. FYI, this would be typical: struct Grid&lt;T&gt; { data: Vec&lt;T&gt;, size: usize, } impl&lt;T&gt; Index&lt;(usize, usize)&gt; for Grid&lt;T&gt; { type Output = T; fn index(&amp;self, (i, j): (usize, usize)) -&gt; &amp;Self::Output { &amp;self.data[i * self.size + j] } } impl&lt;T&gt; IndexMut&lt;(usize, usize)&gt; for Grid&lt;T&gt; { fn index_mut(&amp;mut self, (i, j): (usize, usize)) -&gt; &amp;mut Self::Output { &amp;mut self.data[i * self.size + j] } }
Ah yeah. While I'm at it I should also use `~/.config/myapp/` instead of `~/myapp.conf`.
It's not the worst thing in the world, no.
It's on a cron job, so whenever that fires. Within a day.
&gt; I'm sure more experienced C++ coders would be more comfortable doing this, so I can see where folks come from when they say "I can write safe C++". I am fairly experienced in C++, and I am afraid you are optimistic. Retrofitting multi-threading in a C++ codebase is a *nightmare*.
I would guess it's like everything on Internet: the most virulent opponents are the loudest, and therefore their opinion seems to be the opinion of the majority.
Yep, forgot about that one, yet another example of plain infrastructure code.
Never heard of the `windows_subsystem`attribute until now. This is great. 
**Great stuff! Thanks everyone who made it happen!** And speaking of those people... What I loved about the old way of listing all contributors manually is that it was on the "front page" so to speak. With thanks.rust-lang.org, the contributors are hidden behind a link, and I find that in practice I don't follow the link. I expect others don't as well. But I always got really good feelies when I saw the big list of contributors right there. Is there anyway we can put the contributors back on the "front page" instead of behind a link? I understand the original motivation was to automate this list making so it was both easier and more correct, and am not suggesting we undo that. Perhaps embed an iframe? Or make some XHR fetch? Who should I talk to about this?
Wrong village, your village belongs in the /r/playrust country. 
yeah since i posted this i discovered the 'where' isn't needed, so it is a little easier than I thought. it seems I erroneously added it, but it didn't work.. asking for assistance in a forum (EDIT actually the IRC channel) , instead of 'get rid of the where' .. someone told me how to get it to compile *with* the where :) The idea of indexable (or something else) would be to combine the read &amp; write into one trait, so there's less traits to specify
Ah sorry didn't realize I was posting it incorrectly. Should I remove?
Awesome! Regarding Android build support, is there a document where I can get more details? I can build and run rust code on Android but I'm particularly interested in OpenSSL integration which was mentioned in the original PR.
Unsure what kind of lightweight/heavy you mean specifically, but if it is implementation effort and maintainability, an `&lt;iframe&gt;` with some styling to hide borders doesn't seem too egregious: https://usercontent.irccloud-cdn.com/file/a27b8nba/iframe.png
&gt; Will there be any efforts to make it easier to install? Yup! And there already is; you don't need node. The vscode-rust instructions are out of date. Today: $ rustup component add rls --toolchain nightly $ rustup component add rust-analysis --toolchain nightly $ rustup component add rust-src --toolchain nightly &gt; And what is with rls_vscode vs vscode-rust? Do they compete? I don't know what rls_vscode does that vscode-rust doesn't, to be honest.
I somewhat agree. On the other hand, I feel like it is still worth considering LLVM semantics, because ultimately, we want to have an efficient translation to LLVM. The more important consideration is that we want to test the semantics against the MIR that rustc actually produces. If I pick something too conservative -- more conservative than what rustc implements -- all tests will just fail, which is not very helpful.
Yes please. It will save the mods some work.
&gt; Many people came together to create Rust 1.18. We couldn’t have done it without all of you. [Thanks](https://thanks.rust-lang.org/rust/1.18.0)! Does this list also include people who've contributed to other core components like cargo and rustdoc?
Just a point I would like to add, many of IntelliJ's non-JVM langs are implemented using their tools not because of manpower but because it keeps it local and conforms to their project/AST. Same reason Scala support doesn't use Ensime and Rust support [doesn't use Racer/RLS](https://intellij-rust.github.io/docs/faq.html#racer). So there is a bit of anti-community NIH there with a lot of langs they support.
Pretty sad that it was added without the `crate` shortcut. `pub(crate)` is ugly. It was mentioned in the RFC and people liked it.
rustdoc yes, cargo no. It's for `rust-lang/rust` only. The plan is to expand it to Cargo and other repos, but I haven't had the time to implement that yet.
Ah! I somehow eclipsed the single-person in one-go! Reminds me of the saying: &gt; Walking on water and developing software from a specification are easy if both are frozen.
You could `split_mut` the things to the left of the agent, then `split_mut` the things to the right of the agent, then pass the left and right neighborhoods as two `&amp;[Agent]` arguments: Pseudocode: Vec&lt;Agent&gt; arr; // Let's update arr[i] let (left, agent_and_right) = arr.split_mut(i-1); let (agent_only, right) = agent_and_right.split_mut(1); let agent = agent_only[0]; agent.update(left, right); // Passing &amp;mut in even though we just need &amp;
Sure, you can't know everything. Maybe someone else does. Very helpful answers, thank you!
No problem!
`for` loops basically just call `into_iter` on the thing they're iterating over. `&amp;Vec` implements this differently than `Vec` does, etc.
I always thought patterns were one of the things "flash baked" into a finished form in Rust 1.0 with too little thought. Maybe this is a step forward; I don't know, but likely worth experimenting with. Hopefully we can get less weird pattern rules (also `a..=b` ranges vs `a...b` patterns) for Rust 2.0?
We want to get more user reports from stable before we add any sugar. EDIT: Well if you had a PR that implemented behind a feature flag there's a pretty good chance we'd accept that I think.
It's all good! Happens more often than you'd think :P
I just wish the people working to develop new standards hadn't changed their mind about the `seamless` attribute and started considering something based on technologies which require JavaScript instead. Seamless `iframe`s would be a perfect way to carve a page up into mutually-isolated security domains without them devolving into a mess of scrollbars.
It can probably be done with a div that has a limited height and scrollbars automatic.
I've had a (very small) personal project hang indefinitely when compiling. FreeBSD was being run in a VM but it had 4 GB of RAM - is that insufficient? I figured it was just that nightly rust wouldn't work with it.
&gt; what i still wish you could do is place all the impls in one place Not really sure what the pb is. You have 2 behaviors to express so you need 2 traits. Just impl them next to each other. &gt; I'm not a fan of the fact that the trait is part of the function name. What do you mean? I totally understand the frustration with large bounds and types. That's a know and recognized bad side to Rust. Types can get very long and bounds complicated. In some cases, you need to write macros, use closures, meta traits or forgo genericity. It can be a bit of a PITA. I've sometimes wished the compiler could auto complete bounds or return types since it should know what is needed. Regarding `lerp`, the `num` crate provides numerical traits like `Num` and `NumOps` that could probably help. Numerical traits aren't in the standard library in Rust, unlike in some other langs like Haskell...
I think I worked out why it came easily to me. The first couple of times I used it I used an explicit, strongly typed state machine for the protocol, with a new enum variant for each state the protocol can be in and methods impl'd on those controlling tranitions. It worked very well amd everything just fell into place. A few days ago I tried writing a more implicit version where the protocol was encoded in the structure of the program a'la go/async/await and it really wasn't pleasant. I had to fight the whole way to get anything to compile. So I think tokio's futures may strongly favour the explicit state machine model of protocol definition, I should really do a blog post...
&gt;&gt; I find that formatting extremely hard to read hehe .. I had to format it like that to match the nested anglebrackets.. I couldn't follow them otherwise. I wondered if there's a way to label and re-use the intermediate types. I suppose I could go further and make a 'mul_add(base, offset,scale_factor) .. I'm not adverse to doing that as I've had to for other reasons int he past
Scaladays also had Aaron Turon as a keynote speaker about Rust. It makes perfect sense, keynotes are there for the look to the horizons.
&gt; Unfortunately I can't do that, what with my summer job and all that. But if I could I would. Next summer, we try to have more summer jobs involving Rust :).
The same could be said about the align property and any other enumerable str field. The "safety" concern here is no more than it is for the rgba field which expects float values in the range of 0 to 1 inclusive. If Rust turns to support dependent types, then this issue would be moot, until then I will prefer the more legible version for front facing types. There are already runtime exceptions if someone tries to use an invalid unit, so the safety and sanity is still not so bad.
I was recently to ruby_c after not attending Ruby conferences for a while and frankly got a little sad of the amount of talks that either 1) don't talk ruby or 2) bash the language into the ground. There was a crystal talk that was mostly "here's crystal, it looks like ruby, but isn't ruby, because ruby is shit" for 30 minutes. Another one was straight-forward "MRI core doesn't know what they are doing, but I do" for another 30. The negativity in the Ruby world towards their own language now baffles me a lot.
Copy and paste.
https://internals.rust-lang.org/t/rust-libz-blitz/5184/
next attempt .. trying to write a Lerp trait for a lerp generic member-function, e.g. impl lerp blah blah to get 'a.lerp(b,f)' trait Lerp&lt;F&gt; : Copy + Sub+ Add&lt; &lt; &lt;Self as Sub&lt;Self&gt; &gt;::Output as Mul&lt;F&gt; &gt;::Output &gt; where &lt;Self as Sub&lt;Self&gt; &gt;::Output : Mul&lt;F&gt;, &lt;&lt;Self as std::ops::Sub&gt;::Output as std::ops::Mul&lt;F&gt;&gt;::Output: std::ops::Add&lt;Self&gt; { fn lerp(self, b:Self, f:F)-&gt; &lt; &lt; &lt;Self as Sub&lt;Self&gt;&gt;::Output as Mul&lt;F&gt; &gt;::Output as Add&lt;Self&gt; &gt;::Output { (b-self)*f+self } } that then seems to let me do this to get a.lerp(b,f) , that seems to work on f32,f64, if that automatically works for anything else with 'add''sub' etc that might be rather nice impl&lt;T,F&gt; Lerp&lt;F&gt; for T where T: Copy, T: Mul&lt;F&gt;, T: Sub&lt;T&gt;, T: Add&lt; &lt; &lt;T as Sub&lt;T&gt;&gt;::Output as Mul&lt;F&gt; &gt;::Output &gt;, &lt;T as Sub&lt;T&gt;&gt;::Output : Mul&lt;F&gt;, &lt;&lt;T as std::ops::Sub&gt;::Output as std::ops::Mul&lt;F&gt;&gt;::Output: std::ops::Add&lt;T&gt; {} 
I have a question about the mentioned automatic reordering of struct and enum variant fields: Today I've wrote a [program](https://gist.github.com/anonymous/eaff5a0ae9d0396f4f1008a0511a323a) for the [challenge 317](https://www.reddit.com/r/dailyprogrammer/comments/6eublu/20170602_challenge_317_hard_poker_odds/) on /r/dailyprogrammer. To have a simple and semantically meaningful ordering of poker hands I created the following type: #[derive(Debug, PartialEq, Eq, PartialOrd, Ord)] enum Ranking { HighCard(Card, Card, Card, Card, Card), // 5 kickers OnePair(Value, Card, Card, Card), // pair, 3 kickers TwoPair(Value, Value, Card), // top pair, lower pair, kicker ThreeOfAKind(Value, Card, Card), // triplet, 2 kickers Straight(Value), // highest card of the straight Flush(Card, Card, Card, Card, Card), // 5 kickers of the same color FullHouse(Value, Value), // triplet, doublet FourOfAKind(Value, Card), // quadruplet, kicker StraightFlush(Value) // highest card of the straight flush // RoyalFlush := StraigthFlush(Ace) } I made use of the derived implementations of `PartialOrd` and `Ord` in order to be able to easily say which poker hand is better than or equal to another hand. Basically every enum variant written beneath another is higher. But if comparing the same enum variants one embedded value after another is checked. So in the case of a `FourOfAKind` the `Value` field would be compared, followed by the `Card` field. Doesn't this mean that any kind of reordering such fields would inherently break my code? If the kicker card (here a 16 bit field) would get priority over the quadruplet value (here an 8 bit field) just to save 8 bits by not having to use padding this wouldn't correctly evaluate a Four of a Kind anymore. I kind of like the way `Ord` works with this data structure. I don't want to have to implement it manually with many lines of code just to be sure that values compare the way that I want. Am I overlooking something? Or is there a possibility to not choose to use the introduced optimization?
&gt; Am I overlooking something? It depends if the derived code depends on source order or not. This is a good question, I don't know. EDIT: I am told that it operates on the source, so you're good. &gt; Or is there a possibility to not choose to use the introduced optimization? `#[repr(C)]` is the way out.
&gt; Doesn't this mean that any kind of reordering such fields would inherently break my code? Nope. The derive plugins operate on the AST, which is not reordered. The reordering happens after the `Ord` implementation is generated.
&gt; I should find out who a 'meta trait' is. By meta traits, I mean traits like your `Iterate`, that don't have any method and just wrap a bunch of other traits together. &gt; I just wish they gave the option of whole-program inference Not gonna happen. [This](https://www.reddit.com/r/rust/comments/2bcof3/rust_type_inference_question_functions_vs_closures/) is one explanation but you'll find others if you look around. &gt; is it going to be possible to do the 'dimension-checking' stuff that C++ can do? Yes. This has been in the workings for a long time. It's a lot of work, mostly because it's a much larger undertaking than just type-level integers. Efforts should be bearing fruits within a year. (see [update post](https://internals.rust-lang.org/t/lang-team-minutes-const-generics/5090) and [draft rfc](https://github.com/withoutboats/rfcs/blob/const-generics/text/0000-const-generics.md)) &gt; 'Cowboy::draw and Renderable::draw' are two different functions This is clean. Renaming stuff is a breaking change for library authors, and not doable in a large ecosystem that relies a lot on dependencies, like in Rust. You can disambiguate between similarly named function using [UFCS](https://doc.rust-lang.org/book/first-edition/ufcs.html).
The compiler infers the type of the closure parameter as `&amp;i32`, the function type is explicitly `i32`. You can check this by specifying the closure type like this: let is_div = |&amp;n, p: i32| n % p == zero; And you will get the same error.
Something like this? struct HasIter&lt;I: std::iter::Iterator&gt; { iter: I } fn main() { let v = vec![1u8, 2, 3]; let h = HasIter { iter: v.iter() }; } 
My reservation is purely against extra syntax as a personal preference. After thinking about it for a while it would be possible to support both interfaces with a trait to convert units from str to ViewUnit for each method. That way you can use either interface to your preference.
Did you look at [Rayon](https://github.com/nikomatsakis/rayon)? Seems like you may be able to even parallelize the average computation in that way (maybe?)
I've gotten stumped using that. I feel the biggest problem is with the threading, I think I am confused with threads and jobs. I believe I need 12 jobs, as I have 12 cores. This means nesting the pool.execute inside another for loop which has the number of jobs I want to execute. However, I get an error about "value captured after move" and I don't believe it's possible to implement copy for this type
I'm no lawyer either, but from the sources I've read, simply translating code from one language to another is analogous to translating books from one language to another, and therefore needs the permission of the original copyright holder. Maybe you are right. If so, it would be great, but I didn't want to risk the entire project over this or give it a shady connotation of some sort. In any case, I don't really want to start future projects from scratch because such formats are often very contrived. That I have learned.
!!! I just had like... a revelation and now I understand. I love when that happens with programming languages haha. Thanks again!
I'm thinking that I should really, actually learn about how strings work now. To begin with, is it correct that `str` is a part of the language, whereas `String` is a library thing?
Yep. I did a [funny post](https://llogiq.github.io/2015/07/10/cow-redux.html) on this a while ago.
Hey! Thanks for the comments! Your thoughts quite closely mirror mine. My idea is to use `libsyntax` to be able to start working with an AST directly rather than raw source code, though I agree that the AST produced by the compiler is not particularly suited to IDEs. My plan is to convert it to a more generic tree and work with that, in a way similar to what `libclang` exposes (the KDevelop C++ plugin actually uses `libclang`). `libsyntax` also keeps text ranges of the nodes, so that shouldn't be a problem. I'd like to avoid parsing for now mainly because of the short time span of the GSoC project. `libsyntax` offers a good short-term solution, though there is [effort to make it a stable crate](https://github.com/rust-lang/rust/issues/41732) which I think would make it feasible in the longer term as well. A simple parse tree isn't enough, though, since the IDE needs to be able to query information about the types of different expressions, locals, etc. Macros are, of course, a pain to IDEs. IIRC, the KDevelop C++ plugin keeps track of both the pre- and post-expanded ASTs. Rust's macros are especially powerful, but look like a nightmare for an IDE, but I'm looking into leveraging `libsyntax` to at least expand those so as not to miss declarations and such. I also did have a look at Dart's analysis server after someone else mentioned it on this thread and it's roughly what I had in mind about the features the language server protocol needs to add to be more useful for IDEs in my blog post. I really appreciate you sharing your experience with the IntelliJ Rust plugin! I'm aiming to write a blog post every week, so if you're interested, you can keep track of my progress there. Thank you again for the comments!
in some ways c++ is the easiest language. but it.has the.most painful results when you screw.up. but yeah, the language.never is.in your way. whatever you imagine in your head that you want to happen with the data in memory you may do it, no friction
Yeah, everyone's using Churchill++ these days.
Can you use `top` or `ps` to find out whether the indefinitely-hung processes are in the `D` state (waiting for disk I/O)? What does `strace` say they're doing? At the time of the hang, is all your RAM actually used? If it really is a case of not-enough-RAM-descending-into-swapping-hell, the processes will be in the `D` state, strace won't have anything to say, all the RAM will be used, and you may see the 'swapfile used' counter ticking up. If any of those is *not* the case, then no, more memory probably won't help.
C++ don't just borrow from everything; on occasion, C++ has pursued other languages down alleyways to beat them unconscious and rifle their pockets for new features. The problem with trying to borrow safety from Rust, is that it would be the wrong default. A critical reason why safe code in Rust is safe is because folks are very careful when writing unsafe code, so as to keep the unsafety contained. (There's almost certainly going to exist some crates that inadvertently expose that unsafety, though they are probably/hopefully a minority.) In C++ on the other hand, *none* of the existing libraries were written with any effort to preserve the safely of the as-of-yet-nonexistent safe parts of the language. Worse yet, it's pretty common to come across C/C++ code that doesn't even have a defined behavior. It just happens to work on whatever language implementation the programmer was using at the time...
[removed]
yes i've got another example where I've tried that aswell, I do like the fact that seems to be able to instantiate a generic member function automatically (I might post that in a bit but didn't want to confuse this post ). this lerp does have the same sort of issues. This is just one function. I write loads of helpers to clarify code. These are things which I've done for x years, the real point is 'what's it going to be like when I'm working on something new where the correct pattern isn't yet clear' this language has some amazing features, but then you throw in some pieces of dogma like that ruin the experience. Surely there are viable compromises that would suit everyone... 'single expression functions' ... 'private functions' (so they will never be in APIs), whatever.
So this was my attempt at making it a trait i.e. a.lerp(b,f). I did like the fact this seems to enable it to 'any type that has Sub, Add, Mul' automatically EDIT... ahh, does that let me do the 'labelling' with associated types (Lerp::Output..)? (EDIT x2 ... maybe it's work in progress, the compiler tells me 'associated type defaults are unstable', that will certainly be a nice way to to it eventually) trait Lerp&lt;F&gt; : Copy + Sub+ Add&lt; &lt; &lt;Self as Sub&lt;Self&gt; &gt;::Output as Mul&lt;F&gt; &gt;::Output &gt; where &lt;Self as Sub&lt;Self&gt; &gt;::Output : Mul&lt;F&gt;, &lt;&lt;Self as std::ops::Sub&gt;::Output as std::ops::Mul&lt;F&gt;&gt;::Output: std::ops::Add&lt;Self&gt; { fn lerp(self, b:Self, f:F)-&gt; &lt; &lt; &lt;Self as Sub&lt;Self&gt;&gt;::Output as Mul&lt;F&gt; &gt;::Output as Add&lt;Self&gt; &gt;::Output { (b-self)*f+self } } impl&lt;T,F&gt; Lerp&lt;F&gt; for T where T: Copy, T: Mul&lt;F&gt;, T: Sub&lt;T&gt;, T: Add&lt; &lt; &lt;T as Sub&lt;T&gt;&gt;::Output as Mul&lt;F&gt; &gt;::Output &gt;, &lt;T as Sub&lt;T&gt;&gt;::Output : Mul&lt;F&gt;, &lt;&lt;T as std::ops::Sub&gt;::Output as std::ops::Mul&lt;F&gt;&gt;::Output: std::ops::Add&lt;T&gt; {} 
I meant more along these lines: pub trait Lerp&lt;F&gt; { type Output; fn lerp(self, other: Self, frac: F) -&gt; Self::Output; } impl&lt;T, F, A, B, C&gt; Lerp&lt;F&gt; for T where T: Clone + Sub&lt;T, Output=A&gt;, A: Mul&lt;F, Output=B&gt;, T: Add&lt;B, Output=C&gt;, { type Output = C; fn lerp(self, other: Self, frac: F) -&gt; Self::Output { self.clone() + (other-self)*frac } }
If I understand this correctly in the end the derived Ord implementation would also end up in binary code modified in the same way as the data itself. That's a big relief, thanks.
Yep thats exactly what I need. Thanks
But that hasn't necessarily have to be on the core subject. Conferences often involve community introspection and having a look outside can help with that.
In general, you should avoid these `update()` methods. Not only they are impossible parallelize, but they contain like all the behavior. You may be able to split this up into multiple functions. One way to solve this could be to not have all this directly on the struct, but instead some function which just gets indices together with the `Vec`. Maybe you could also utilize an ECS for this, but I'm not sure yet.
I do not understand this error, schema::Method is my struct, even if this structs lacks something why Iterator would not work on a BTreeMap? error[E0599]: no method named `map` found for type `std::collections::BTreeMap&lt;&amp;std::string::String, std::vec::Vec&lt;schema::Method&gt;&gt;` in the current scope --&gt; src/lib.rs:221:14 = note: the method `map` exists but the following trait bounds were not satisfied:`std::collections::BTreeMap&lt;&amp;std::string::String, std::vec::Vec&lt;schema::Method&gt;&gt; : std::iter::Iterator`
https://www.youtube.com/watch?v=Hy8kmNEo1i8
Shut up and take my money!
I have a large squishable ([this cutie](http://www.squishable.com/pc/squish_shiba_inu_15/Big_Animals/Squishable+Red+Shiba+Inu)) on my desk at work and he's by far the most popular plushie on the desk, even though there is stark competition. I am hyped, ordered two!
On FreeBSD the utility that traces system calls like `strace` does on Linux is called `truss`. (There exists a port of `strace` as well but `truss` is in the base system.) First I clean like always `./mach clean` `git clean -xf` Then trace the syscalls of an attempted build, including those of descendants by using the `-f` flag to `truss`. `truss -f ./mach build -d &gt;log 2&gt;&amp;1` In a separate terminal I watch the log `tail -F log` After it stopped outputting anything new, I uploaded the log file to https://gist.github.com/eriknstr/9948009dd94cb7eb3eba663de3a23d6c/raw/5dd3438a9642cbe9083f539d1ec1d15443070d8f/log. The log file is about 47MB in size at this point. I check `top` for amount of RAM and swap used. `top` last pid: 70571; load averages: 1.94, 1.01, 0.66 up 6+13:32:57 08:07:25 104 processes: 2 running, 100 sleeping, 2 zombie Mem: 2210M Active, 372M Inact, 5093M Wired, 211M Free ARC: 2997M Total, 1136M MFU, 790M MRU, 1031K Anon, 43M Header, 1027M Other Swap: 8192M Total, 1005M Used, 7187M Free, 12% Inuse PID USERNAME THR PRI NICE SIZE RES STATE C TIME WCPU COMMAND 70570 erikn 6 52 0 262M 109M uwait 2 0:01 58.74% rustc 69998 erikn 4 52 0 571M 340M select 1 1:51 47.36% terminolo 70533 erikn 1 52 0 10556K 2688K wait 2 1:01 42.09% truss 70565 erikn 6 52 0 244M 86288K uwait 0 0:00 27.59% rustc 70546 erikn 5 52 0 376M 269M uwait 3 0:06 25.88% cargo 70562 erikn 6 52 0 196M 61400K uwait 3 0:00 16.31% rustc 70537 erikn 1 27 0 8320K 2152K kqread 2 0:18 15.19% tail 69932 erikn 1 52 19 65872K 12744K select 0 5:21 11.28% efreetd 70082 erikn 4 23 0 287M 63612K CPU0 0 0:18 5.18% terminolo 19468 erikn 60 20 0 4002M 1622M select 2 594:58 1.56% firefox 1221 root 1 20 0 12538M 57388K select 3 465:34 0.00% Xorg 33689 erikn 5 20 0 202M 4004K select 0 15:33 0.00% pulseaudi 1465 erikn 3 20 0 230M 7352K select 1 6:07 0.00% mate-volu 829 root 1 20 0 12692K 1300K select 0 3:58 0.00% moused 1356 haldaemon 2 20 0 61188K 4120K select 0 2:46 0.00% hald 1385 erikn 6 20 0 309M 8620K select 1 2:18 0.00% mate-sett 1387 erikn 4 20 0 246M 10312K select 2 1:57 0.00% marco 1383 root 3 20 0 48856K 3896K select 2 1:54 0.00% upowerd ~~The amount of wired memory is really high. I don't remember if it has been this high before. Maybe /u/floatboth *was* right that it's an issue of insufficient amounts of RAM? I'm not sure. I never quite understood wired memory, even after reading about it online. Some amount is still inactive and some amount is free.~~ *See edit at bottom.* Note that in the above output, WCPU has not yet dropped to 0% but that's just because I ran `top` so soon after it had hung that the weighted CPU percentage had not yet fallen down. Next I use `htop` to see the state of the hanging `rustc` processes since `htop` makes it easy to filter. `htop` 1 [|||| 7.3%] Tasks: 108, 0 thr; 2 running 2 [|||||||||| 25.7%] Load average: 0.41 0.71 0.59 3 [|| 2.6%] Uptime: 6 days, 13:35:14 4 [|| 4.7%] Mem[|||||||||||||||||||4.28G/7.92G] Swp[|||| 1000M/8.00G] PID USER PRI NI VIRT RES S CPU% MEM% TIME+ Command 70570 erikn 52 0 261M 93904 S 0.0 1.1 0:00.77 rustc --crate-name xi_u 70557 erikn 52 0 247M 95104 S 0.0 1.1 0:00.53 rustc --crate-name same 70565 erikn 52 0 243M 86288 S 0.0 1.0 0:00.34 rustc --crate-name thre 70562 erikn 52 0 196M 61400 S 0.0 0.7 0:00.24 rustc --crate-name fore Part of the reason that the memory usage count is different in `htop` from in `top` is that I was writing this comment while checking each of them so some time passed between but even so they are showing different counts. `htop` is the one I look at usually but with `htop` being ported from Linux I don't know if the memory accounting of `htop` is "correct" or not. My inital guess would be that it does not count wired memory? But even so there is still a difference in the count. Next, the output of `ps` for these processes as well as for the cargo process. `ps wwwaux -p 70546,70557,70562,70565,70570` USER PID %CPU %MEM VSZ RSS TT STAT STARTED TIME COMMAND erikn 70546 0.0 3.3 384964 275928 0 IX+ 08:06 0:06.12 cargo build erikn 70557 0.0 1.1 253544 95104 0 IX+ 08:07 0:00.53 rustc --crate-name same_file /usr/home/erikn/src/github.com/eriknstr/fork/servo/.cargo/registry/src/github.com-1ecc6299db9ec823/same-file-0.1.3/src/lib.rs --crate-type lib --emit=dep-info,link -C codegen-units=4 -C debuginfo=2 -C metadata=747905cfaa6ce3a1 -C extra-filename=-747905cfaa6ce3a1 --out-dir /usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps -L dependency=/usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps --cap-lints allow -C link-args=-fuse-ld=gold -W unused-extern-crates erikn 70562 0.0 0.7 201128 61400 0 IX+ 08:07 0:00.24 rustc --crate-name foreign_types /usr/home/erikn/src/github.com/eriknstr/fork/servo/.cargo/registry/src/github.com-1ecc6299db9ec823/foreign-types-0.2.0/src/lib.rs --crate-type lib --emit=dep-info,link -C codegen-units=4 -C debuginfo=2 -C metadata=85cd4233933259fd -C extra-filename=-85cd4233933259fd --out-dir /usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps -L dependency=/usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps --cap-lints allow -C link-args=-fuse-ld=gold -W unused-extern-crates erikn 70565 0.0 1.0 249448 86288 0 IX+ 08:07 0:00.34 rustc --crate-name thread_profiler /usr/home/erikn/src/github.com/eriknstr/fork/servo/.cargo/registry/src/github.com-1ecc6299db9ec823/thread_profiler-0.1.3/src/lib.rs --crate-type lib --emit=dep-info,link -C codegen-units=4 -C debuginfo=2 -C metadata=1a18e5a273fbf4a0 -C extra-filename=-1a18e5a273fbf4a0 --out-dir /usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps -L dependency=/usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps --cap-lints allow -C link-args=-fuse-ld=gold -W unused-extern-crates erikn 70570 0.0 1.1 267880 93904 0 IX+ 08:07 0:00.77 rustc --crate-name xi_unicode /usr/home/erikn/src/github.com/eriknstr/fork/servo/.cargo/registry/src/github.com-1ecc6299db9ec823/xi-unicode-0.1.0/src/lib.rs --crate-type lib --emit=dep-info,link -C codegen-units=4 -C debuginfo=2 -C metadata=d613e2e55c392115 -C extra-filename=-d613e2e55c392115 --out-dir /usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps -L dependency=/usr/home/erikn/src/github.com/eriknstr/fork/servo/target/debug/deps --cap-lints allow -C link-args=-fuse-ld=gold -W unused-extern-crates And finally I kill the processes with a single \^C. --- Edit: Rebooted my machine and tried again. This time it's hanging while there is almost 4GB of free RAM available and no swap is in use.
What is the typical use case for this crate?
Yep, that is how it goes, you need to open a console handle yourself.
My partner (/u/elle_es) made me a Rustacean based on Emily's design a while back. I love him! He sits on my desk. I brought him to RustConf last year. If you were there you might have seen him: https://www.instagram.com/p/BKMkkEOBtQC/ I'm pleased to see this campaign!
There is an ongoing effort to switch to a CommonMark-based renderer. I think you can find a link in the 1.18 announcement post.
Interesting idea, but the name is problematic. May I suggest "cats" instead?
Malware analysis, [according to this](https://www.sstic.org/2017/presentation/binacle_indexation_full-bin_de_fichiers_binaires/).
Out of curiosity, why not even consider [PrinceXML](https://www.princexml.com/) which would have seemed the ideal tool for the job?
&gt; and generating from HTML ourselves did not yield very nice documents 
Pijul intrigues me, but (category theory paper I did not read aside) it seems to describe very little of what makes it better in concrete, practical terms (the [Model](https://pijul.org/documentation/model/) page doesn't really say much of interest). Are there any concrete examples of merge conflicts that it's able to handle better than git (and why) or something? The "patches are more intuitive than snapshots" argument doesn't sway me I'm afraid, nor does fast blaming.
I think the main difference is that prince is based on html/web technologies while papers relies on latex for styling. From what i understand, the stack is tera (jinja templates) -&gt; generated tex -&gt; xelatex -&gt; pdf Might be just personal preference of the author. But this is just a quick guess :)
It's in [the reference](https://doc.rust-lang.org/reference/attributes.html#crate-only-attributes).
Also, writing CSS for print is a PITA compared to writing a basic LaTeX document.
Ah ok. It is there somewhere, but just a bit buried is all. All good!
Oops, should be fixed now.
&gt; My inital guess would be that it does not count wired memory? ZFS ARC is part of "wired" but is available to processes, so htop [subtracts it from wired](https://github.com/hishamhm/htop/blob/89d15399c543b9a5bc0ea3503b55fbec1b54a0fd/freebsd/FreeBSDProcessList.c#L320-L328). htop does everything correctly. Also yeah, your processes end up in a different state than mine, when I had that freeze because of low RAM, the processes' RSS dropped to zero.
Just pub(crate) since crate is a reserved word.
More interestingly, it seems to hang indefinitely
Where does your thread pool come from? Rayon manages its own threads, so for now I would not mix multiple concurrency libraries. Otherwise, we probably can't help you without a self contained minimal example. (The actual rendering doesn't have to do much.)
I initiate the pool just before the thread with. let pool = ThreadPool::new(12); However, even if I use std::thread::spawn, the same happens.
As I said, with Rayon there is no need to initiate any threads yourself. Otherwise, please provide a more complete example.
That is the entire example, all else in my main just contains scene creation. The example /u/cedenday attached shows thread initiation, and inside a par_iter(). Here is the rendering and image saving functions anyway: fn render_image&lt;T: Hitable&gt;(width: &amp;u32, height: &amp;u32, samples: &amp;u32, cam: &amp;Camera, world: &amp;hitable_list&lt;T&gt;) -&gt; Vec&lt;vec3&gt;{ let mut pixels: Vec&lt;vec3&gt; = Vec::new(); for y in 0..*height { println!("{}", y); for x in 0..*width { let mut colour = vec3::new(0.0, 0.0, 0.0); for s in 0..*samples { let u = (x as f64 + drand48()) / (*width as f64); let v = (((height - y) as f64 + drand48()) / *height as f64); let r = cam.get_ray(u, v); colour = colour + color(&amp;r, &amp;world, 0); } pixels.push(colour / (*samples as f64)); } } println!("{}", pixels[0].x); return pixels; } fn save(image: Vec&lt;vec3&gt;, width: u32, height: u32){ let mut out = DynamicImage::new_rgb8(width as u32, height as u32); let ref mut fout = File::create(&amp;Path::new("light_test.png")).unwrap(); for y in 0..height{ for x in 0..width{ let colour = image[x as usize*width as usize + y as usize]; out.put_pixel(x as u32, y as u32, Rgba::from_channels((f64::powf(f64::min(colour.x, 1.0), GAMMA.recip()) * 255.0) as u8, (f64::powf(f64::min(colour.y, 1.0), GAMMA.recip()) * 255.0) as u8, (f64::powf(f64::min(colour.z, 1.0), GAMMA.recip()) * 255.0) as u8, 255)); } } let _ = out.save(fout, image::PNG).unwrap(); } 
Yes, moving values between threads is done by move. Other occasions where a move is necessary is when the value passed in has to be destructed (e.g. various `into_*` or `unwrap*` methods where you pass in a wrapper and get the wrapped thing back). As for the syntax question, keep in mind that the default is not only used for moves, but also for copies with `Copy` values. If a borrow were the default, you'd either have to write `a: %int` for each integer/float/copy-struct argument (with a hypothetical move sigil `%`) or pass around unnecessary pointers to primitive values all the time. I would say "move a value", it conveys the effect very accurately. Still, "moving ownership" is basically the same and actually closer to what you do, since in practice the value is either copied or not moved at all :)
I agree.
How could it be in Rust?
Don't get me wrong (this is no serious reply), but, as a beekeeper, the Rust mascot reminds me always of a [varroa mite](https://en.wikipedia.org/wiki/Varroa_destructor). Nevertheless, I love Rust. :)
[removed]
Note that this is how actually inheritance is implemented under the hood (at least in C++). The advantage of this approach is that you don't worry about multiple inheritance and also you can hide some traits by not implementing them.
Highjacking the top comment. This is not what you want . ( Probably ) With these simulations you normally want to be deterministic no matter in what order you process your cells. I've never encountered a simulation where you want cell[i].update(cell[i-1] , cell[i+1] ); cell[i+1].update(cell[i] , cell[i+2] ); To be different then doing cell[i+1].update(cell[i] , cell[i+2] ); cell[i].update(cell[i-1] , cell[i+1] ); AKA : A update where one of your neighbors has already been updated , and the other neighbors have not been updated. just use Agent::Update(&amp;self, &amp;[agent] ) -&gt; Agent 
I like that one more...
Nice to see Tera used like that!
I find it oddly heartwarming that no one has bothered with the $1 pledge. 
Doc team lead here! Today, rustdoc uses hoedown by default. There are some minor patches, but nothing really that changes much, if anything, I can't quite remember. You can also pass `--enable-commonmark` to get a CommonMark compliant parser instead. We're adding some tooling to help you figure out if there are any differences between the two, but it hasn't landed quite yet. Eventually, CommonMark will be the default. Hope that helps!
Thank you a ton for this detailed explanation! Really helped me to understand your decision. :)
There is something special about the upvote button of this post! /u/kibwen, is that you?
Haha that's great!!! I was having trouble thinking of an example of code that maps to this directly (there are different pieces of this in a few places, serde is one that has traits for users to implement), but I'm glad that the explanation was helpful!!
What you linked has nothing to do with what I was saying. 
Whoa, that is so cool! Great work!
Pants is a build system designed for codebases that: Are large and/or growing rapidly. Consist of many subprojects that share a significant amount of code. Have complex dependencies on third-party libraries. Use a variety of languages, code generators and frameworks Pants supports Java, Scala, Python, C/C++, Go, Javascript/Node, Thrift, Protobuf and Android code. Adding support for other languages, frameworks and code generators is straightforward. Pants is a collaborative open-source project, built and used by Twitter, Foursquare, Square, Medium and other companies. For those who were unaware what this is, like me. 
One thing you *could* do is compile the compiler yourself and git-bisect your way to finding which commit introduced the segfaulting. Unfortunately the compiler is pretty hefty to compile, so this would be a bit of a pain to do.
&gt; "unofficial" in the sense that it's a mark that does not represent any official rust thing. The Rust logo OTOH is trademarked and thus restricts its use because trademark law sucks (https://www.rust-lang.org/en-US/legal.html). The restriction is, to my knowledge, intentional. It ensures that only the Rust team can distribute Rust as "Rust". (The same as with Firefox)
Clarified that this was a rhetorical question, I did my share of java and while memory safety helps a little, many concurrency bugs are not about memory safety.
Have you made sure Y has `extern X` and `use X::BigInt`, and also made sure `BigInt` and associated things are marked `pub` in X?
I added `extern X` but `cargo build` doesn't reach my code, so it makes no difference what I write in the `main.rs` file. Also I never use `BigInt`, it is not a part of `X`, it is a part of `num-rational` which is not an explicit dependency of either `X` or `Y` 
Is there a way to make something like a "derived value" of a struct that is only evaluated once? For instance in Scala, I have a choice of making an attribute of a class evaluate-exacly-once (`val`), at-most-once (`lazy val`), or every-time-used (`def`) case class Circle(origin: (Double, Double), radius: Double) { lazy val area: Double = pi * r * r val area2: Double = pi * r * r def area3: Double = pi * r * r } But in Rust, implementations on Structs can't take value assignments, for instance impl Circle { let radius = ... }
Small note on point (4): all browsers block "active" mixed content by default, where active means JS, CSS, and fonts IIRC. This is compared to "passive" mixed content, which is images and video.
&gt; *convert-to-string* Oh god... I guess that's the "naive" solution, but the idea of allocating memory, doing all that formatting, etc... makes me shudder :(
Even before compiling rustc, it'd be helpful to know _which_ nightly it regressed on. Basically just keep going back in time with `rustup default nightly-&lt;date&gt;` until you find a working version
TBH it looks better without CSS on my screen (Firefox). Maybe your default fonts are ugly.
There is https://github.com/Mark-Simulacrum/bisect-rust.
Ah, right-on. I wasn't sure what your goal was and kinda skimmed the output at the end and just asked "the dumb questions" that people forget to ask themselves in the moment. 
How large is the index in best (I assume very regular data) / worst (random data) / average cases? How does it compare with some kind of self-index?
No, I just find the following characteristics ugly: * The layout of the unstyled stuff above the post title and below "View All 13 Articles →" * The lack of left and right margins
Point, but not strictly relevant, given that it's CSS that's under discussion.
&gt; Only to assert that validity of rustc, I hope! &gt; Well, or you're finding bugs in rustc! Sure, that's the plan. :) And eventually, I also hope to do something more formal as part of RustBelt [1][2]. I fully agree with what you said about getting proper mathematical foundations. However, for the coming 3 months, I'm an intern with Mozilla and will work on this from the more practical side -- and think this work needs to happen first, because really we don't have a clear idea yet what the final model will look like, so we have to be able to iterate on it fast, and to easily validate the properties of our candidate models. We feel that an implementation in an interpreter is much more suited for this purpose than a full mathematical formalization. (And actually, the mathematical work we did so far has already found a bug: &lt;https://github.com/rust-lang/rust/issues/41622&gt;). [1] &lt;http://plv.mpi-sws.org/rustbelt/&gt; [2] &lt;https://www.ralfj.de/blog/2015/10/12/formalizing-rust.html&gt;
There is also [KLEE](https://klee.github.io/) which is a symbolic virtual machine for LLVM, so should in theory be able to handle any language that can compile to LLVM bitcode. Actually, I think that for symbolic execution, fiddling with "raw memory" is exactly what's easiest. Raw memory is just a sequence of boolean variables, and symbolic execution is using a SAT-solver to find a set of values for those variables that satisfies the different constraints imposed by the various conditionals in the program.
Here's the conspiracy theory about `popcount` and the NSA the article mentioned. * http://web.archive.org/web/20070922021934/http://www.moyogo.com:80/blog/2005/09/secret-opcodes.html * https://www.reddit.com/r/programming/comments/22p5v/popcount_the_nsa_instruction_missing_from_modern/
Right now the symbolic execution + fuzzer combo is the hot thing.
One of the changes that came with the move to a Travis based CI system is that the compiler built for testing each merged pull request is saved and so one can theoretically bisect without having to manually build!
&gt; whatever you imagine in your head that you want to happen with the data in memory you may do it, no friction Well, it'll compile at least... but I must warn you that it may not execute that well. Between aliasing and alignment optimizations, you really have to be careful when doing any type punning. I've seen both blow up in my face.
A [delta debugging](http://delta.tigris.org/) solution for the rust ecosystem would be a nice project and helpful for situations like this.
Cool! I was thinking exactly about this. My [`fast_fmt`](https://crates.io/crates/fast_fmt) crate aims to achieve similar results but little bit more generically. Would you mind providing `impl Fmt for CatMany`? Also, why do you use so much `unsafe`? I believe it should be possible to write it using only safe code.
Don't forget one for the car, one for a dear friend, one for the backpack, one for the dog, and a few more as backups.
`thrussh` is a library, not a full ssh client. It's also (I believe) not feature complete, and uses Ring for crypto, which requires at least some C code.
fast ain't easy 
If agents are just a few values that all are `Copy`, you can also consider using `Cell`, e g: struct Agent { position: Cell&lt;(f32, f32)&gt;, speed: Cell&lt;(f32, f32)&gt;, } That way, `update` will no longer require a `&amp;mut self`, only `&amp;self`. (That said, I agree with asdffdsa231's point about cell processing order)
you're looking for r/playrust
&gt; So why can't some tools have a rust implementation? What's missig in rust to have ssh clients and daemons be implemented in rust? "Because nobody has done it yet." and "The willpower." Nothing technical prevents rewriting the world in Rust, but, as with open-source as a whole, Rust's ecosystem is mostly hobby projects and personal itch-scratching.
`fast_fmt` looks good too! However I'm not familiar with `Fmt`, and currently I'm a little busy so I can't do that myself. I would probably accept a PR if it is an optional feature so that it doesn't add a dependency unless explicitly requested by the user. About `unsafe`, I'm used to C++, so I think in pointers :). Joking aside, I allocate space all in one go which leaves uninitialized memory, then I copy the bytes to that uninitialized memory. You shouldn't have uninitialized memory in safe code. I could maybe just use the `Vec&lt;u8&gt;` differently: reserve capacity, and then just extend it with slices, but that does not cover the case where a `String` which is not the first concatenation operand has enough capacity, its contents are shifted to the right and then other stuff is copied to the left. I'm wary of shifting the contents beyond the vector's length, as `Vec` does not guarantee it won't touch allocated memory beyond its length, thought it would be fine with the current implementation. In summary, I don't really see a way to remove `unsafe` without losing runtime efficiency. Maybe there is a way, but I don't see it.
Some nice comment about Rust - &gt; rusts’ struct/enum/trait model strikes a very good balance of allowing for expressive generic programming, while avoiding hidden dynamic calls and maximizing stack allocation. Additionally, the existence of good generic programming facilities has already lead to excellent type-and-resource-safe concurrency frameworks such as futures-rs. &gt; ... the upshot of the compiler’s strict static checks is that the code is extremely likely to be safe once it compiles. During the development of the prototype (approximately 2000 lines of rust code), exactly one segfault occurred, and it was due to CFFI’s (admittedly deprecated) callback API. &gt; ... The platform-native implementation in rust has proven to be very performant, and incredibly error resistant. Together with the rust community/platform having very healthy trajectories, it should be relatively easy to get new contributors involved while continuing to achieve our performance objectives. I know nothing about the Pants project but the new engine sounds like a beautiful demonstration of the best things about Rust.
it makes sense when you are used to languages that don't have a handy built in function for this, bit flipping is a lost art. kids these days! 
I think this is about as close as you'll get: https://is.gd/nFnL4D
As a user of Pants at work I have to object to some of the statements in this self description though: Yes, it supports Protobuf, but only for Java. Other support is also spotty - for example c++ seems less feature rich than Go support. It has broad support for Thrift. It also has features that are mutually exclusive - for example automatic build file generation does not play well with code generation. Oh, and it lacks rust support :(. Extending it is difficult - but possible, see below - since the code is very Javaish Python - a bit unidiomatic, quite complex and not well documented, with frequent abstract base classes. It is also fairly slow - but hopefully that improves with the Rust kernel. IMHO, despite these complains it is still the best mono-repo build system of the bunch, because it found a sane way of dealing with third-party dependencies, i.e. pinnend, unique versions throughout the whole code base. Without pants this is a huge hassle - especially with Go. It also provides a plugin system that allows to add functionality in code that is residing in the same repository that you want to build. 
To add to /u/zzyzzyxx 's answer, you can mimic lazy evaluation using `Cell`: https://is.gd/1HTTMO
I never read the RFC and did not follow the feature. `pub(crate)` seems very readable and convey the semantics perfectly. Ugly is also a poor design attribution for a language, imho. My experience is that rust looked ugly to me at the beginning - mainly for its verboseness - but that it grew quickly on me when I understand how the semantics helped me model my thoughts better. I think `pub(crate)` will be similar.
&gt; I would probably accept a PR if it is an optional feature so that it doesn't add a dependency unless explicitly requested by the user. I'll consider it. `String` has `reserve` method too! In `String::from` you could just call `reserve` and then append everything. No need to work with raw `Vec&lt;u8&gt;! I have basically the same optimization in `fast_fmt` too: // This should get inlined and elided if $crate::Write::uses_size_hint($writer) { // This actually calls `reserve()` in case of string. $crate::Write::size_hint($writer, chain.size_hint(&amp;$crate::consts::DISPLAY)); } // Everything is appended to the string While I admit reuse of RHS is interesting, I doubt that it's encountered often. Do you have any evidence of it being faster?
I actually like how simple it looks. :)
Wrong subreddit. You are looking for /r/playrust
I just backed to the tune of 10 plushy Ferris crabs (after debugging the kickstarter site b/c I got a timeout the first ~10 times). Yay!
Yes, that'd be good :) Gonna try to do that next week.
Give it some margins and hide the stuff that's supposed to form a site header, sidebar, and footer and I'd agree with you. As-is, having no margins really gets to me and, as a UI/UX-oriented guy, I have trouble ignoring the unstyled header/sidebar/footer boilerplate when making my assessment.
Any plans to extend it beyond Rust? I've been meaning for a while to implement the algorithm described in [Automatic Exploit Generation](http://security.ece.cmu.edu/aeg/aeg-current.pdf) but it seems that you've beat me to the punch, at least for Rust :)
There is also a fork of KLEE which uses QEMU to analyze unmodified binaries. &gt; Actually, I think that for symbolic execution, fiddling with "raw memory" is exactly what's easiest. Raw memory is just a sequence of boolean variables, and symbolic execution is using a SAT-solver to find a set of values for those variables that satisfies the different constraints imposed by the various conditionals in the program. Yeah, Z3 (as a SMT solver and not just a SAT solver) has a built in theory of bitvectors, which is used extensively in program analysis.
Well, that's the tricky part, there's no safe way to create such an object, because you cannot allocate one on the stack. But you can directly allocate the right `[u8; n]`, initialize the fields as needed, then construct a fat pointer with the right contents (by using transmute). Needless to say this is 100% `unsafe` code. I thought I had an example on hand but it's gone. Let me know if this helps.
Right, sorry, SMT. And yeah, an SMT solver operating on bitvectors will be a lot more efficient than a SAT-solver working on individual boolean variables.
wrong subreddit, you want /r/playrust
If the auto trait is safe, unsafe code must not rely on it actually having a particular meaning. That's just like unsafe code cannot rely on `Eq` to implement an equivalence relation. An example of a safe auto trait is UnwindSafe: &lt;https://doc.rust-lang.org/beta/std/panic/trait.UnwindSafe.html&gt;. Even if you incorrectly assert your type to be unwind safe, the worst that happens is some unexpected behavior. You cannot get segfaults or races from that.
[This](https://github.com/warricksothr/Perceptual-Image-Hashing/pull/1) is the PR I made for that fix/optimization. Before I used `u64::count_ones()` for this purpose I didn't even know of its existence and when I saw the positively HUGE performance delta I looked for the implementation, couldn't find it at first but discovered the use of the intrinsic a while later.
creduce works quite well on Rust files already, e.g. https://github.com/rust-lang/rust/search?q=creduce&amp;type=Issues&amp;utf8=%E2%9C%93 .
I'm particularly excited about the potential to formally verify properties of programs. Like, imagine writing a quickcheck-style or cargo-fuzz-style testcase, running Seer on it, and then after a bunch of computation Seer tells you "congratulations, it's impossible for that code to panic". [Proofs from tests](https://www.microsoft.com/en-us/research/publication/proofs-from-tests/) describes how this might be possible with a technique that combines symbolic execution and _counterexample guided abstraction refinement_.
Having dealt with some concurrency issues recently (at the intersection of Tokio futures and regular threads), I can confirm that the ascription of `Send` and `Sync` traits to types is incredibly opaque. I've actually seen some crates use something like an `assert_sync!()` macro (presumably expanding to a no-op function invocation which a `T: Sync` constraint) just to ensure they get their invariants correctly. The problem is that the automatic derivation of `Send`/`Sync` doesn't really have a good answer. You cannot really disable it at this point and e.g. require `#[derive(Sync)]` going forward, because it would break a ton of code. And even if we had that since the beginning, it would be another convenient/necessary trait that library authors often forget to derive (like `Debug` or `PartialEq`). I know Rust isn't really doing compiler switches/extension that change language semantics (in stable), but perhaps this is something to consider: a flag to make all types thread-*un*safe by default, with an explicit opt-in via `#[derive]` (checked by the compiler using current rules) in addition to the current `unsafe impl` assertion.
I suspect a "NoAutoTrait" marker is perfect for this. Definers of auto traits implement `impl !Foo for NoAutoTrait {}`, and this works as a "here be dragons" signal
If you want to convince yourself it's not magic, try using it to invert a sha256 hash! You might need to wait a while before it terminates...
chalk only handles trait selection, not the rest of type inference, so it could help, but not a lot. It is also destined to end up in the compiler, so there is no benefit of using it directly vs using the compiler
Except that this means we can still get unsafety without unsafe code, if someone writes a "unsafe auto trait" and forgets to neg-impl it for `NoAutoTrait`.
Send and Sync are auto traits because we want them to also be implemented for closures. `#[derive]` is not really an option, unfortunately.
I believe they do: it is included in symbols.
I'm happy this stabilized too, especially after I bump it's relevant rfc when I realized I needed it and the dev team responded very quickly after realizing it slipped through the cracks 
You're right, this makes much more sense this way. Thanks!
Could this not be done via something like `#![deny(auto_send, auto_sync)]` with it defaulting to `#![allow(..)]`? Then one could at least use that on crates where explicit is better.
~/.cargo/registry/src/github.com-*/[pkgname]-[version]
**Note**: [`cargo clone`](https://crates.io/crates/cargo-clone) is a third-party crate, and can be installed by running `cargo install cargo-clone`.
Even macro rules `$crate` is locally empty, e.g. `$crate::foo` expands to just `::foo`.
thank you all for your help i like cargo clone but i want to grab everything in my Cargo.toml at one time not to use cargo clone for each crate 
This is excellent! I've been finding myself on more slow connections whenever I feel like updating so this compression is perfect! I'm looking forward to more updates like this! :D
I thought GFM is what introduced code fences?
No need to apologize. Even as-is, it's already better than many sites I've seen. You seem to have pretty good intuition for the principle that the content should be front and center, with a minimal, un-cluttered site template serving primarily to make said content as readable as possible.
I'm still a bit of a rust newbie, and this isn't anything groundbreaking. However, recently, I switched over from atom to vim, and today, I wrote a cli client to [hastebin](https://hastebin.com) in Rust. I hooked it into VIM using a custom command, and now, typing `:haste` in my VIM window uploads the entire buffer and opens the uploaded code in a new browser window using `xdg-open`. Not anything crazy, but cool to be using Rust for something practical.
OTOH, a full ssh client almost definitely isn't needed, so it should be easy to build the necessary functionality in an app. In fact, the ThruSSH developers have already done it for their own projects, so you can probably copy-paste a lot of what they did.
Yep, this is real important to keep in mind. This isn't a grand soundness hole or flaw in the language. It's just that we wrote some unsafe code and forgot to write a guard. Same as leaving off a bounds check when using `slice::get_unchecked` or `ptr::offset`. Anyway, GG Ralf! You got us good! 🙀😻
I'm getting back to cracking away on my Keras-inspired Neural Network Library for Rust. I managed to get it completely modular during my capstone project, but my weak custom matrix struct I made initially is slowing it down and keeping me from doing convolutional layers right. I'm about to take a serious look at [ndarray](https://github.com/bluss/rust-ndarray). Also, does anyone know if [Collenchyma](https://github.com/autumnai/collenchyma) is stable enough to use in projects?
There are none, not even paid.
Yeh I see your problem. Because `IterFilterEntry` is generic over the predicate it's difficult to describe its type without resorting to a trait object, like you've got with `Box&lt;Iterator&gt;`. This is `Box`'s bread-and-butter though; encapsulating arbitrarily-sized things; so if the allocation isn't actually an issue for you then you've done the best thing already. But this is also the kind of use-case the Impl Trait feature is designed to solve. On the `nightly` channel you could do something this: #![feature(conservative_impl_trait)] pub struct FilesIterator&lt;'a, I&gt; { inner: I, _marker: PhantomData&lt;&amp;'a ()&gt;, } impl&lt;'a&gt; FilesIterator&lt;'a, ()&gt; { fn new(files: &amp;'a Files) -&gt; FilesIterator&lt;'a, impl Iterator&lt;Item = PathBuf&gt; + 'a&gt; { let walker = WalkDir::new(files.root_dir.as_path()) .min_depth(1) .follow_links(false) .into_iter() .filter_entry(move |e| files.includes_entry(e)) .filter_map(|e| e.ok()) .filter(|e| e.file_type().is_file()) .filter_map(move |e| { e.path() .strip_prefix(files.root_dir.as_path()) .ok() .map(|p| p.to_path_buf()) }); FilesIterator { inner: walker, _marker: PhantomData } } } impl&lt;'a, I: Iterator&lt;Item = PathBuf&gt; + 'a&gt; Iterator for FilesIterator&lt;'a, I&gt; { type Item = PathBuf; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { self.inner.next() } } But now you would have to carry the `&lt;'a, I: Iterator&lt;Item = PathBuf&gt; + 'a&gt;` bound everywhere you wanted to use `FilesIterator`.
That's what makes it fun :)
The HTML pages of the docs package are pretty similar to each other. I guess its greater window size allows xz to find patterns that are larger than what gz can find, thus eliminating much of the repeated markup.
It was the first Markdown implementation to have them, but isn't the only one.
I'm trying to use a peekable iterator to peek at each character in a string, then consume some number of the following characters. This is the simplest example I could come up with that shows the problem I'm having: fn main() { let mut iter = "hello world".chars().peekable(); loop { match iter.peek() { Some(val) =&gt; { println!("found {}", val); iter.next(); }, None =&gt; break, } } } But this causes the error: error[E0499]: cannot borrow `iter` as mutable more than once at a time It says I've already borrowed iter for iter.peek() and can't borrow it a second time for the iter.next(). How should I structure this to avoid the problem? 
LZMA is *way* better than gzip, and repetitive text like is in the docs HTML gets even better better with it. I’m going to assume ultra compression has been employed, which uses a 64MB dictionary, which is ideal for something like the help docs. That it should compress four times as well as gzip (even on its highest compression level) doesn’t surprise me. LZMA is really, *really* good at that sort of thing. (Look into the underlying algorithms and you’ll understand why it’s really good for the docs.)
Video linked by /u/Ran4: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Dan Callahan - My Python's a little Rust-y - PyCon 2015](https://youtube.com/watch?v=3CwJ0MH-4MA))|PyCon 2015|2015-04-11|0:29:18|244+ (99%)|18,832 &gt; "Speaker: Dan Callahan Rust is a new systems programming... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/Ran4 ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dippc6s\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.1b
That person is a hero. I tried but it was a daunting codebase for me.
This may be an oversimplification of the problem you have, but it solves the specific example: https://is.gd/w0W4am You essentially need to end the borrow at iter.peek() one way or another.
I think its because .wait() expects the Future to register the thread that it was called from and notify it when it may have made progress. So it only calls poll once and then hangs because its never going to get notified.
rustup is definitely the correct answer. I don't know if the one in the arch community repo is up to date. It's super easy to just grab it from the website.
`Box` is probably fine but I know I can do better, even without nightly. The iterator I expose has a fixed size; the problem is that I need a closure which means I can't easily declare a type that describes the size. Since `filter_entry` is built on `skip_current_dir`, I suspect that I could fork `filter_entry`/`IterFilterEntry` to contain the state I need in a declarable way so I can avoid a `Box`. Its just not been the most pressing thing for me to work on. btw what was `_marker` for in your example?
It is up-to-date, it was updated just today. Also, rustup is endorsed by the [Arch Wiki](https://wiki.archlinux.org/index.php/Rust#Installation).
I'm sure it has been said here before but number-of-questions-on-SO is a pretty meaningless measure of language popularity because there are too many unknowns... Let PL X be the most popular PL "in the wild" but it also has documentation that covers just about anything there is to know =&gt; less questions on SO so not really a popular language. Let PL Y be a pretty much unknown PL but as it has insufficient documentation, tons of questions are asked about it on SO by its small userbase =&gt; according to this measure apparently a really popular programming language. Another problem is that tags are not always assigned correctly which also falsifies this measure even further.
I used to ask lots of SO questions about C++ because I didn't know where else to ask. With rust, I quickly learned that I could ask on IRC or this subreddit and get great, helpful responses, even for my silly beginner questions (SO is far more intimidating, since it has very different goals). Between that and my DuckDuckGo '!rust &lt;search term&gt;' for the excellent rust documentation, I never look at SO for rust.
&gt; 2017 crapified Haha, nice word!
For very basic things like trying Rust or running/installing a software built in Rust and distributed on cargo, the package manager's version is probably fine. For actually programming in Rust and doing Rust development, you'll likely want to learn and use rustup. It's a great tool with a lot of useful features. 
I'm continuing my development on https://gitlab.com/tglman/persy following my 0.2 roadmap, preparing as well the first hotfix for the 0.1 for some issue discovered during development and trying to make the whole project more contributor friendly (suggestion welcome), in the free time (of my free time) i'm studying around tree structure for indexing, hoping to come out with something cool in 2/3 months