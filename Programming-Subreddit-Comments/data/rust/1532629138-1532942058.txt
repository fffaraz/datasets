psuedo-consensus model -&gt; pseudo-consensus model langauge-agnostic -&gt; language-agnostic ;-) 
dang it, thanks
Another case worth studying is Haskell’s [Hackage](https://hackage.haskell.org/)/[Stackage](https://www.stackage.org/) model. Hackage is a package repository where anybody can publish packages at any time, like crates.io. Packages can specify upper and lower bounds on their dependencies. You can use it with any version selection scheme you like. Then there is Stackage, a “global lockfile” that picks one particular version for every package it includes, and it specifies the compiler version. All of the packages in a Stackage snapshot are built and tested together. (A [commercial sponsor](https://www.fpcomplete.com/) maintains CI for this, much like Mozilla pays for Crater runs.) Stackage has LTS as well as nightly releases, similar to the release train model of Rust; at some point a nightly becomes a new LTS. LTS versions do receive updates: new point releases of packages that were published to Hackage get included, and as incompatibilities are resolved, more packages are added. Upgrading to a newer point release of an LTS snapshot is generally painless. Upgrading to a newer major LTS can be more difficult, because it could imply a new compiler version, new major versions of packages can be included, or packages could have been removed altogether. Fortunately you can upgrade at your own pace, multiple LTSes are maintained side by side for a while. Finally, it is possible to take a Stackage snapshot as base, but for specific packages to take a different version from Hackage. Stackage is not free of package incompatibilities or trade-offs. [It is a human effort, maintained by a team of curators with help of the community.](https://github.com/commercialhaskell/stackage/blob/683b968d200884f9c4b7e382c6aa248471eb018e/MAINTAINERS.md) Often a library author is also responsible for its listing in Stackage. Just like in the Rust ecosystem there is a tension between including newer major releases of “core libraries”, but having few dependent libraries because the authors haven’t upgraded yet, and having a large set of (possibly outdated) packages that build together. The way the curators deal with this is by being conservative about updating core libraries, until just after an LTS. At that point nightly moves to newer versions of the core libraries, and drops packages that are incompatible with them. These packages get added back over time when their authors fix compatibility, and at some point there is another LTS release. As an application developer, Stackage is absolutely wonderful. You specify only the LTS version, and everything just works. Upgrading to LTS point releases is painless. Often there are one or two packages that you want to use, which are not in the snapshot, and depending on a specific version from Hackage solves that. I don’t maintain any Haskell libraries so I don’t know how well it works for library authors.
[removed]
This is a pretty cool read. I imagined Wasm to be more of a hacky, bloated creature, but now I'm cautiously optimistic of what it'll be used for. Rust is still a long way from being usable for most web development tasks though, right? Are there any projects cool projects that currently use Rust and Wasm to do something that wouldn't be as cool in Javascript? Found a small typo by the way, in "langauge-agnostic.".
I admire the Redox project, but for the usual linux distro most are accustomed to, it will probably continue to be a mixture of languages. As pointed out in thread, lots of devhours, and not always good fit for the use case. I figure over time, programs that are always needing to be hardened will transition to Rust. (So SSH, webservers, other servers, Xorg.) I'd also like to see Rust in the microcontroller space more. I've been itching to tinker with my Arduino again, but with Rust. I also think Redox would be sweet on a Pi running hobby programs also written in Rust. Technically, one could maybe make a Rust distro by wrapping tons of C and C++ code in unsafe blocks? lol That'd be a chuckle to see.
Market speculation like stocks? I mean c'mon at least cite a reliable source with claims like this. The #1 currency used for illegitimate goodsis the USD, but nobody complains about that. It's okay to not like block chain but to make up claims and spread them in a technology subreddit espousung how a device uses rust is a bit far. 
The backticks work on new desktop reddit, but not mobile and old reddit. 
Shoot, this is so much work...
Maybe `impl ToString for Arguments`? Shouldn't be hard - [`std::fmt::format`](https://doc.rust-lang.org/std/fmt/fn.format.html) already does that. (that's a function - not the macro `format!`). If `$""` would return a `String` it will have to allocate, which is something Rust usually wants to make explicit.
Rust can already set literals based on expected type, and functions too. The main downside of having them both is that the `$""` literal could allocate memory without any sign in the code that it's going to allocate.
Isn't that what Google Docs does?
[removed]
[removed]
&gt;&gt; IE, if it compiles and runs on nightly without issue, will it definitely do the same on beta and stable? &gt; Not if you're using unstable nightly-only features. Not even if you're using features which have just been stabilized in nightly.
I'm certain some people are going to try to do just that. A second-order [inner-platform effect](https://en.wikipedia.org/wiki/Inner-platform_effect).
Very cool, great to see Rust' s abstractions put to use in creating safe APIs. I think this is one of Rust' s most underrated selling points: the fact that the ownership system lets you rule out a lot of API footguns (as opposed to just providing safe memory access).
I imagine the RTT taking a lot longer that doing the calculations on the client though.
also, "collary"
Wouldn't that utterly kill their SEO though? They may not care about accessibility, but surely they actually want ad impressions.
&gt;shadowing might cause this student\_number variable to change! That's not what shadowing does. Anything that has used \`student\_number\` before it was shadowed, or even has a reference to it after it was shadowed, still has the same guarantees about it being immutable. Shadowing rebinds that name to a new value, making the original inaccessible from that point on. But it's still a new variable; the old one still exists and does not change, it's simply no longer accessible by its original name. If you consider the variable itself as a memory location, and the name as a binding to that variable/location, then the behavior becomes clearer. Shadowing is binding the name to a new location without changing any values at the old location.
I fixed the one in a heading but not the body, oops. Thanks.
I feel that you're making a tempest in a teapot here. 
Try updating your versions of everything; nightly had some breakage but I believe it’s all been fixed.
&gt; The idea is pretty awful and would make the web a mess, but I wouldn't put it past a lot of developers considering how bad the web already can be. I agree. Outside of some very niche uses, I just don't see it working. About 5 years ago or so, some developers started throwing out sscrollbars and building their own. It was terrible. Simple UI elements, like a scrollbar, are *HAAAAARD!* to get right. Further no matter how great it might be, I expect the scrollbar my OS provides. This idea of throwing out the DOM and rendering to a canvas is going back to that type of stuff.
What is weird about the term is that in mathematics, isomorphic means means that a transformation is reversible. I can get from A to B, and also from B to A. An isomorphism is a weak form of equality. This isn't really about reversibility.
Oh how I'd love a more performant/stable replacement for elasticsearch (although most of the time it's related pieces of the ELK stack, like logstash/kibana that explode horribly rather than the core elasticsearch system). Bulk ingestion numbers are nice, but what I'd be really curious about is the resource requirement for continuous intake. IE: If I have a 16GB machine with 8 cores, how many messages per second can I index? That's still a pretty fuzzy question, but one that more directly corresponds to the way I'd normally usually use elasticsearch. And bulk numbers usually are higher IIRC because they don't have an existing index to contend with. &gt; Toshi is a three year old Shiba Inu. He is a very good boy and is the official mascot of this project. :)
This is already possible with WebGL. You could use canvas elements and GLSL shaders on the client GPU to implement a custom renderer for your own custom document model within the existing DOM. There are even js libraries that can dynamically compile some well-structured js functions into shaders at runtime. To be clear, this is still a fucking nightmarish idea, but wasm isn't holding the gate shut, so to speak.
I see you put a https://deps.rs badge on your project -- have you seen [`dependabot`](https://dependabot.com/)? It works wonderfully and can automate even more of the dependency updating effort for you. :)
oh that is really nice, I'm going to have to make use of that.
I honestly love this post. It seems like every time WebAssembly is mentioned all anyone wants to talk about is whether it's going to replace JavaScript. After reading through the spec though, the thing that really excites me is just how well it's been designed. I've been writing a toy compiler (in Rust of course ;) targeting wasm and the experience has been impressively nice. In about 1000 LOC I've been able to implement a language that will run on pretty much any machine with a browser updated in the past year
My work is full of C++ developers that want to escape for all the reasons you mentioned. You aren't missing anything and it's not FUD. When it takes 10 developers months to modify a huge C++ code base to do something a JS dev could do in a few weeks, you know shits bad. Dependency management hell is real and change one thing (just upgrade one library) and you better be ready for bugs to surface everywhere. Nobody uses semver. It is truly a wasteland.
&gt; It seems like every time WebAssembly is mentioned all anyone wants to talk about is whether it's going to replace JavaScript. After reading through the spec though, the thing that really excites me is just how well it's been designed. It's like you've read my mind :)
From the best of what I can tell the throughput on these kinds of things can be rather high. Tantivy does a really good job of offloading it's secondary actions to other threads in order to keep indexes live. That being said Elasticsearch benchmarks estimate it can do about 1500 docs a second, it would seem like beating that mark would be pretty easy with rust control. My benchmark while bad and probably not meaningfully comparable puts Toshi at around 55k docs a second, which in comparison sounds absurd. Currently the bulk ingest streams the request body so it makes an effort to be as memory efficient with super large requests as it can be. I think I can make it even a bit faster and better on memory by using the bytes crate instead of Vec&lt;u8&gt; like I have currently, but I would also love to play with the idea of a "streaming" ingest pathway.
I recommend doing what other commenters are saying, but also make sure to focus on fearless concurrency. That is literally the reason Rust exists (for FireFox). Rayon is literally how I parallelize everything these days...and it's so easy parallelizing is generally something I do as an afterthought on the hot spots that usually takes just a few minutes. My god, please don't even try to do that in C++. There isnt even functional code to parallelize in the first place! The async story in Rust is going through some growing pains right now, but we will see stabalization and community support over the next year. Rust developers are comitted to keeping up with these things.
I'm going to tell that to my ML coworkers tomorrow and see how they respond.
Reading this makes me very curious to see how wasm is going to affect the Javascript ecosystem. The language itself develops at its own pace and a huge amount of libraries, frameworks, tools, and languages have been created to work around its shortcomings. I think wasm will be a much more interesting compilation target than Javascript in the long run, and we'll probably see a large number of new languages in the coming years as a result. 
Now if only actual development wouldn't be just nightly and bunch of external hacks via cargo-web ;)
I think this is why some people, realizing this, try to use the label "ssr" (server side rendering) instead.
According to [the docs](https://docs.rs/ructe), you're supposed to write the template in a separate file, use a build script, include it as a Rust module, then use it as a writer: // template.rs is the compiled version. include!(concat!(env!("OUT_DIR"), "/template.rs")) fn main() { // Usage: let mut buf = Vec::new(); template::some_template(&amp;mut buf, /* parameters */).unwrap(); // buf contains the rendered template as a byte-string // convert to a string with: String::from_utf8(buf) } Also, for your use case, people have been recommending this really good framework called [yew](https://github.com/DenisKolodin/yew) which handles setting up a web server for you. You can embed your HTML inside Rust using a macro and make it call out to Rust. As for client side, why not use [wasm-bindgen](https://github.com/rustwasm/wasm-bindgen) and pass a struct containing the node information to JS, where you can construct it much more easily?
Ash is the best library for direct Vulkan calls at the moment. If you are learning Vulkan you can easily follow along with Ash's nice Rust bindings as most of the calls are 1 to 1 but with quality of life changes. While it's still quite low level and unsafe you can get by quite easily if your knowledge of Vulkan is sufficient. Aka don't destroy resources that are in-flight, etc.
Nobody ever considers what the tree thinks.
Web apps often don't care about either
Btw, there is one nitpick I have about your post. I don't know that it's really fair to call wasm language-agnostic. Honestly, I'm not sure what it would mean for a compiler target to be language-agnostic. The target has its own semantics, and the closer the source is to those semantics, the easier compiling will be. WebAssembly is actually quite Pascal-like IMO, and languages more like that (imperative/procedural) can be almost trivially translated to wasm. I think the real reason wasm is better than e.g. Java bytecode is that it's similar enough to common assembly languages that compilers are already targeting. So compiling Haskell to WebAssembly might be hard, but easier since it's similar to compiling to x86 (as GHC is already doing)
After reading more about how the lock file works, yes, I suppose this is pretty much how Cargo works today. Given this I don't really see the utility of minimum version selection in Cargo.
That's totally the very long term goal of WASM (although yes not Rust alone, it will be a variety of languages depending on your requirements). No one is admitting because they don't want the stockholm syndrome wielding JS devs to lose their marbles. 
I think I lean much further into the "shared policy" than the "stated version." Here's my experience, as Minimum Supported Rustc Version (MSRV) has been a major concern for me, and at times a major headache. I feel conflicted between two camps. On the one hand I want to use the newest and shiniest features, some of which have direct impacts on the ergonomics or performance of my crates. However, my crates are nothing without their users. And many users simply cannot update their Rustc at will to the latest and greatest stable version. I personally work in an environment with \*incredibly\* lethargic update processes due to having to use "certified" (via internal audit) versions of software and libraries. Once something has been certified for use, you have to have a very good reason to increase that version to something new (which spawns a whole new audit phase). So I \*very much\* get the pain of not being able to update your Rustc like you'd want. I \*also\* understand the core team's desire to have everyone on coherent Rust story. This is why I'd like it acknowledged that there are places where updating stable every 6 weeks simply can't happen (Government, public service, high security, etc, etc.) and there should be some tooling or guidelines to deal with these areas that aren't going away. For my own crates I've adopted a policy of, "I officially support the latest stable, minus two releases" pulled arbitrarily from rust-lang-nursery guidelines. However, in practice I've been \*much\* more conservative as \`clap\` currently requires 1.21 which was released in Oct 2017. But maintaining this has been hard, especially when having to manage deeply nested dependencies without official policies (or those with "latest stable" only policies). Here's how/why I've come to using older versions, even when I as a library author want to use new features: Originally, I wanted to support whatever stable Rustc Debian packages because it's one of the more conservative distributions (and parent distribution to so many Linux variants). Since \`clap\` and related crates are meant to be key for command line applications, having those applications packagable with major Linux distributions is important. So why not just let Debian (or any other system which requires older Rustc versions) package an older version of the application (which in turn requires an older \`clap\`) and always use the latest stable for the latest clap? Sure that's possible (what does already happen to an extent) although what this leads to is users on old Rustc verisons requesting bug fixes which are already fixed in newer versions of \`clap\`. I'm a single person, working on these projects in my spare time. As much as I'd love to, I can't maintain bugfixes on multiple branches backported to old versions which support older Rustc's. It's just not feasible for me. I'd try to make exceptions for security related bugs, but beyond that I just don't have the bandwidth. So I'm left with the choice of sticking with an old Rustc which is \*hopefully\* a common denominator between as many \`clap\` users as possible at the expense of some ergonomics (typically just internal ergonomics though), or sticking with a newer stable Rustc and potentially isolating or losing users who can't update. I pick the former without hesitation. I'm hopeful for the LTS discussion, as having a single concrete version to target would be a dramatic improvement (even for my auditing reviewers at work, having a single version to look at every 6-12 months).
Thanks, I'll try again and do that. It is at least calming that /u/Eh2406 and /u/ehuss have pretty much mentioned the same way to proceed that you have. * FWIW the amount of time I invested was ~15 hours during 2 days, which isn't as much as the other mention, but was probably not enough.
You're doing the lord's work. If I get some spare time I might try to make some contributions
I'm afraid you forgot to set you repo to public, pal :)
&gt; so I'll send you a link privately. May I have one too, please?
I plan on talking about this in a future post.
Mind rule #4, please.
Also "It spec includes instructions on how to do validation. This stuff is quite useful!" I think it should be "Its spec"
&gt; That's totally the very long term goal of WASM It is an explicit non-goal. &gt; No one is admitting Please don't invent conspiracy theories to reaffirm your bias. Also, please see rule #4.
We're working on it!
Got a simple question about Rust conventions. Let's assume I have this function: fn my_func(foo: &amp;mut SomeStruct) { // do stuff } And now I want to call it. Is there any practical difference between this: let mut a = SomeStruct::new(); my_func(&amp;mut a); ...or this: let a = &amp;mut SomeStruct::new(); my_func(a); If I'm understanding things correctly, either way the calling scope will own that new instance of SomeStruct. The only difference is that, in the second one, I'm doing an inline mutable borrow on some struct I'm making on the stack, and then binding that to 'a', right? And in the first one, the borrow occurs when the function is called. Are there any downsides to either one? Any reason I shouldn't do one or the other?
1. Just because JS is source-available, it's not Open Source. You can't (legally) copy-paste code you find online to your website. 2. Even if you could, the 90s are long gone. If I wanted to see how to write a menu, I wouldn't look at reddit's source. I'd just find a blog describing how to do it. 3. With compile-to-JS (and auto-polyfill) becoming a big thing these days, the days of hand written clear JS are going away anyways. Try figuring out how Docs works by looking at source.
I'd say I'm not being a zealot. I never said which languages I thought would take over, I just resent JS and everything it has done. 
Personally, I understand that this is not a goal of wasm, but it is what I fully expect the future to hold. Regardless of wasm's states goals, I think people will be attracted to it to the point that anything you'd do in JS can be done in wasm.
&gt; It is an explicit non-goal. &gt; Please don't invent conspiracy theories to reaffirm your bias. Ok I should have phrased that differently, it's not necessarily a goal of the WASM team itself, maybe it is a non-goal. But imo it's an inevitability as people who compile various languages to WASM continue to ask for more and more features until JS is completely unneeded, at which point I think very many developers will ditch JS for their web needs. &gt; Also, please see rule #4. I wouldn't say it's zealotry (I'm not arguing in favor of some specific language) so much as JS resentment due to all the bad things it has done. 
If I were writing in JavaScript, I'd just use [the `innerHTML` method](https://developer.mozilla.org/en-US/docs/Web/API/Element/innerHTML). But the [`Element` API](https://developer.mozilla.org/en-US/docs/Web/API/Element) is still incomplete in `stdweb` -- so setting things via string may or may not be out of the question at the moment. I'm not familiar with this chunk of the ecosystem, so I don't know what crates could help you with `stdweb` specifically, but using a templating engine probably won't be viable until something like [this PR](https://github.com/koute/stdweb/pull/64) to get merged into `stdweb` upstream. Perhaps you could use something like [the `yew` crate](https://github.com/DenisKolodin/yew) instead?
The use case for SSR is to speed up the initial render -- if you can serve a fully-formed page to the user the first time and then let the client (which has the same logic as what the server used to render stuff for you before you ever received the page), then you have less time where the user idles. That said, I think you're right -- it'd be weird to just have server-side rendering all the way. It's usually used as an optimization in the case of initial loads!
Good to hear, I'm looking forward to it!
[removed]
[removed]
Well, if you do it the second way, you can *never* move the struct (except using `mem::replace`, but then you need another one to replace it with). So that could be an issue. I think the first way is more common. 
Suggesting that all developers of a language have Stockholm syndrome is absolutely zealotry. You can express preferences without degrading others.
You have called all JS devs as having "Stockholme syndrome" and losing their marbles.
Ah alright sorry, was just taking the piss. I do genuinely think it has had a nontrivial net negative effect on software dev though. 
Fair enough, was just taking the piss. 
Hi, first of all: good luck in your project! I think it's an interesting one. As someone who used Elasticsearch since 0.9.0 and still makes most of his money by maintaining huge clusters, I have a couple of comments. &gt;That being said Elasticsearch benchmarks estimate it can do about 1500 docs a second, it would seem like beating that mark would be pretty easy with rust control. "Document" doesn't mean much in ES terms. A document can be of any size and - depending on the analysis pipeline in use - of different complexity in importing. In general, ES systems are benchmarked in MB/s of ingest. On most consumer disk, ES can easily exhaust disk I/O, so I would search for bugs if you get anything faster. Also, take into account that ES writes write-ahead-logs (for resilience) and has a background process optimising the (write-only) index on the side, which takes some I/O, but is useful. Also, ES and Lucene are extremely tuned nowadays for constant disk I/O, so you should take care during benchmarking that you simulate a real-world setting (for example by not bulking large chunks). Given the roadmap of your project, I would also note a couple of things: Elasticsearchs whole query model is built to be distributed from the ground up. That's was its competitive advantage over SOLR, which had to be painfully refactored to allow for it. Refactoring towards distributed is hard. Raft will also only bring you half-way there, dealing with splitting and merging queries is also important. If you really want to build a replacement for ES, I'd recommend starting with distribution. Second, reimplementing the ES query DSL might be hard. It's basically a way to express Lucene queries \_plus\_ some special handling, which makes it very tied to Lucene. That's not bad, but trying to reimplement it would tie you to whatever Lucene does. Also, it's not fully stable, it changes regularly (while staying backwards compatible). Finally, I don't quite understand what "single node parity" would entail. Is this the \_full\_ api of a single node?
I think it would be really really useful if you'd be able to reflect on this experience write about it somewhere or suggest some specific ways to improve the on boarding experience. What have you tied to do during the previous attempts? Also, if you are stuck for a significant amount of time (and 15 hours is very much significant), feel free to ping folks on the issue tracker, discord https://discordapp.com/channels/442252698964721669/459149260232065034 or (I think it is still active, though I've personally switched 100% to discord) IRC https://kiwiirc.com/nextclient/irc.mozilla.org/cargo.
&gt;And bulk numbers usually are higher IIRC because they don't have an existing index to contend with. How would bulk numbers be higher without a pre-existing index? Lucene is a write-once format, new indexed data is literally written to the end, with cold caches and new indices. The only degradation in performance comes from Lucene starting to merge segments, costing disk I/O, but on a running system, there's probably always one of these jobs running.
I think i will test with yew, in some example i just found some usage of stdweb. You put me on the right path. Thanks ! 
I took the 1500 number from the elasticsearch benchmark site that elastic posts. I appreciate all your feedback, I don't think I necessarily intended to replace or even do better than ES although I'm sure comparisons will be drawn. The only reason I used it was because it was the most obvious. No doubt though such a significant amount of work has been put in to ES no alternative implementation will be done soon. I think though what I mean for my roadmap, which I kinda just threw together to keep my mental model was I'd try my best to be like ES in functionality, but go my own way in what I thought might be a chance to make a better interface. I Don't know if that makes sense, but I'm interested in your opinions on that idea. I also manage large clusters of ES for a living so my day to day touching of ES is good, but I am always interested in more implementation details of it.
And then we can continue about the misuse of the word "rendering" ;)
Could you explain how `web-sys` and `js-sys` are different from `stdweb` apart from being two different crates?
Wonderful! Can't wait to try it out ✨
I ran into this problem multiple times now. How can I use a value which (or a part of it) is matched in a `match` expression. Like in [this playground](http://play.rust-lang.org/?gist=f3249d9533032b391c4fb419668639ac&amp;version=stable&amp;mode=debug&amp;edition=2015). I understand why the problem occurs, but how can I solve it? I tried using a reference to the `peek` return and dropping it, but the error still occurs.
&gt;It is an explicit non-goal. Well, but it's a sentiment shared by many, who strongly *hope* that one day in not so distant future they will be able to not see a single line of JS code, while developing for web or other platforms. (Gnome I am looking at you!) In other words, the hope is for JS to become COBOL of the web.
To be fair, if the stock market was as volatile as BTC, the world would be a much scarier place. It's not that uncommon of a criticism to say that stocks are already too speculative. But I digress; this is the Rust subreddit.
&gt; this is still a fucking nightmarish idea Why do you think it's so bad? If you do everything from scratch, then the end result will be bad. But, if there's sufficiently advanced middleware, then you can make webdev much easier/faster. And it's not an outlandish idea - videogames are a lot more complex than a typical website, but there are game engines that let you do very complex stuff with graphics/physics/networking. Right now you don't have direct control over what gets drawn. You have html/css/js specs, but you're still at browser vendors' mercy. By using good middleware, you can force an implementation on users, except you don't need to keep any backwards-compatibility guarantees that make specs/browsers slower than they could've been if they were written today.
You also get to share types/validators/serialization and you can use some kind of overloading to use same methods to do a db query on the server and an api call on the client. In the context of Rust, for example, you can easily and safely communicate with the server in a compressed binary format.
In the context of an application, why would it be a bad thing to throw away the DOM ? Honest question, I'm having trouble figuring out the implications.
Rust macros are far far more powerful
It’s shared by many people, but not by any of the people who work on webassembly.
&gt;That being said Elasticsearch benchmarks estimate it can do about 1500 docs a second, (tantivy main developer here) Let's be very careful with benchmarks. I have never published a comparison benchmark at this point, and the reason I want it to be fair and reproducible. For the moment, people interested in performance should test tantivy on their own corpus (and I'd be happy to help if they want to know which knobs they should tune.) Also, I will publish a good search-time comparison benchmark next month with tantivy 0.7.
First of all, a browser already implemented all the things like accessibility, text selection, OS native UI elements, right clicking, ... If people start implementing these manually they're both gonna have one hell of a task, resulting in a lot of things being sub par (janky text select and copy paste anybody?) or flat not implemented due to browser sandboxing (good luck connecting to screen readers)... And that's not even to talk about user scripts, custom style sheets... 
As someone who works with game engines a modest amount, unless you put huge amounts of OS-specific work into it there's a LOT of stuff you lose with that kind of approach. Stuff like copy-paste. Or the ability to save a web page or print it as a PDF. Or the ability for screen readers to read your text for blind people. Or the ability to control sound volumes or resize text for people with poor eyesight or have keyboard-based controls for people who can't use a mouse or... These are things that don't matter 90% of the time but are UTTERLY VITAL for the 10% case. Most users (and application developers, and project managers...) are only going to be interested in the 90% case, so we as people have some amount of collective responsibility to care for everything in general, if we want to make the world suck less. Currently, these are things that web browsers generally handle for you, so the end-user doesn't need to bother. I suppose that if everyone is using what you call "middleware" (I'd call them "GUI toolkits") that do these things for you, that would be acceptable, and we'd be in a different form of the state we're in anyway: The Web is a cross-platform, networked application platform. But doing those things well is a huge amount of work: see KDE, or Qt, or, well, what the internals of web browsers look like today.
Something tells me that such an advanced Middleware will just end up reinventing DOM, for the most part. 
Because there's literally no point to using a browser if you do this. The browser is the advanced middleware you're describing. 
blink.wasm as a middleware then? :p no more need to support Safari or Firefox! Then again, this might be "resolved" by Chrome's ever growing market share...
I edited my comment to remove that so we don't have any misconceptions about benchmarks. Sorry about that
Pretty much yes. But more standardized.
The amount of memory here is not a requirement. It makes it possible to create larger segments and avoid losing too much time in merge. In my experience on my hardware pure injection time is actually faster with around 300MB per thread = 2.4GB.
It's a nitpick, but have you asked every single one of them to make such definitive statement? "Explicit non-goal of the project" does not say anything about everyone related sentiments. Plus community moves to this goal bit by bit regardless of the official stance, so for some (lucky) developers JS can become effectively dead in the following decade.
I had a look at the implementation. [https://github.com/hntd187/Toshi/blob/master/src/handlers/index.rs#L74](https://github.com/hntd187/Toshi/blob/master/src/handlers/index.rs#L74) It seems like you create an indexwriter and commit after every single document. Am I missing something? I am surprised you managed to index 5M docs that fast...
You want the bulk implementation in bulk.rs that’s for adding a single document, I have to rework that commit on every addition. 
[removed]
Could this be used to pass a JS function callback into a Rust program? If so, are there any examples?
And truth be told the way I did this here was mostly based off the way you did it in the tantivy-cli
I have not spoken with literally everyone, but I’ve spoken to many, including the biggest ones, and not one of them has ever even come close to hinting that they think it’s a thing.
Maybe one day, when most people view websites by having them rendered in the cloud because a single computer can't render them smoothly enough, when the offshore farms that power these clouds cover entire oceans, when each website visit requires enough computational power to simulate a human consciousness as well as it's immediate surroundings for an entire lifetime, when AGI agents that have more mental capacity than millions of humans are churning out new frameworks at a faster frequency than the inverse of the planck length, when these frameworks are being adopted by even more AGI agents onto the websites, when all of this technological progress still causes websites to render in the seconds to multiple seconds range, people might realize that this was a mistake. But maybe those people are just looking at the problem from the wrong angle. Maybe we need to cover the moon with computers, then we'll have finally found a formula to render websites that render quickly and fast.
Thank you. Now I'm starting to understand why Rust is starting to get popular. 
Oh I see, that makes sense :). Ideally you want to keep the same `index_writer`. There can be only one per-index at the same time, so right now you cannot handle two indexing queries concurrently. In my experience serde is amazing and 8 threads is probably overkill fo JSON deserialization. Also would it bad practise to use bounded queues here : https://github.com/hntd187/Toshi/blob/master/src/handlers/bulk.rs#L49 ?
No problem! And again, good luck with your project! :)
I'm almost hesitant to learn C++ now. 
That works for x86 because your application owns its own memory space and the rust compiler understands all your code. None of those things are true in the case of Yew. It doesn't control the DOM, and it has no concept of what you're writing, even insude your own code, let alone in anything you wrap.
More useful yes. Maybe not in the computer science sense of computational power. CPP is more or less Turing complete and can (at least in theory) accept arguments that don't parse. I don't know why you'd need that feature but Rust doesn't have it. Procedural macros are certainly Turing complete, the template ones might be.
It is, but the developer is not the one choosing it, which is my whole point.
I have the # of threads ripped out into a config value I just haven’t checked it in yet. I assume bounded queries are faster due to having a limit ahead of time? I’d have to experiment with it I’m not sure what a good bound would be for it. 
&gt; but you're still at browser vendors' mercy now you're at the mercy of the mystical advanced middleware that totally isnt a browser™ &gt; except you don't need to keep any backwards-compatibility guarantees you do if you expect other people to use it, since your entire point was it's only bad if you do it from scratch, but not if someone makes a *good middleware* and then everyone else uses it. forgetting for a moment that the middleware you're describing is called a browser.
that explains it. it sure feels like it does, thats for sure.
[At least render is already a minefield.](https://www.merriam-webster.com/dictionary/render) 
Rust macros too are Turing comolete. Look at the [implementation of Ook (Turing complete esolang similar to brainfuck) at compile time rust macros]( https://github.com/codeworm96/ook). On a similar note, even Rust's ztype system* is Turing complete. I don't see how being able to produce that doesn't compute because of dummy arguments is any more powerful considering y'know, it doesn't compute. 
No, the point is to naturally throttle your client throughput and prevent you from exploding in memory. So I would need to check gotham docs to be sure about that, but my understanding is with bounded queues... If the client has a bandwidth larger than tantivy ingestion throughput, your bounded queue will be saturated, and \`.send\` will start to block from time to time. gotham will be a tad slower consuming its socket. You process stays bounded in memory. With unbounded queues, if the client has a bandwidth larger than tantivy ingestion throughput, your process will just have an ever growing buffer to accept the incoming payload. Your process might eventually start swapping.
Simplest would be to to clone the string, so it's no longer borrowed. Change match args.peek() { To match args.peek().cloned() { If you're on nightly enable non lexical borrows, will allow the code to compile as well #![feature(nll)] For this example I would suggest just using one of the crates for dealing with arguments. I tend to use [structopt](https://github.com/TeXitoi/structopt)
WASM isn't going to replace JS for the majority of client-side JS's use case. And we shouldn't hope that it does - that's a terrible idea that will only lead to needless fragmentation. If you write your React successor in C++ (*why* even), I write the next Webpack in Go and someone writes the next "vanilla" carousel widget in Rust, we're all going to have a hell of a time trying to integrate our moving parts together. Pointless. But where it shines is in areas where performance is paramount, and interoperability with existing frontend libraries isn't - games and what not. 
What is the problem with this? This is something that I, as a non frontend developer, would consider.
&gt; there's a LOT of stuff you lose with that kind of approach Game engines aren't intended to be used for the web, which is why they don't address any of those concerns. The most basic "web engine" would be aware of these issues and will be able to do a much better job. * In the current browser ecosystem, a saved webpage is at best a static view of something dynamic, at worst it just doesn't work, service workers is kind of an attempt to mitigate that. * PDF printing works okay in only the simplest of cases, unless specifically addressed by the developer, you can't even print reddit passably. * ARIA attributes for screen readers aren't standardised, they're just a convention, a "web engine" has an option of having its own domain-aware screen reader, something a regular browser page realistically can not. &gt; The Web is a cross-platform, networked application platform True, but we're talking about WebGL + wasm, which are already sufficiently standardised. Which means it's one platform, and a very limited one at that (which is a good thing). KDE, Qt, gtk, wxWidgets, etc indeed have to adapt to wildly varying platforms, which makes them very complex, but it's not the same. It's more like Unity3d targets a whole bunch of platforms, but its UI implementation only targets Unity. &lt;rant&gt; It's also a lot easier to use than html/css/js, it's insane how much better it is if you really think about it. I've spent maybe 40 or 50 hours doing html/css layout for a spare time freelance project and I still couldn't get it right, it doesn't matter if it was due to a technical limitation or ineptitude. At the same time, I've cranked out crazy multi-layer menus and interfaces in Unity during a game jam, all in the span of a few hours, and it's not something I deal with on a daily basis. And Unity's UI is only a part of a proper game engine, it's far from perfect but it's already lightyears ahead of the conventional web stack in every possible metric. &lt;/rant&gt;
How so? Developers choose to make a web app (HTML/CSS/JS or WebGL) instead of making a Qt or GTK or even native application.
Or figure out a way to accelerate the heat death of the universe. Management can't request more features when all the bits are 0!
If by "the most part" you mean "a hierarchy of boxes with content" then sure, but there's no reason to do markup, styling and event handling in a similar way.
&gt; now you're at the mercy of the mystical advanced middleware that totally isnt a browser™ As I said in the other reply, it totally is a browser, except it's controlled by the developer. &gt; except you don't need to keep any backwards-compatibility guarantees &gt; you do if you expect other people to use it, since your entire point was it's only bad if you do it from scratch, but not if someone makes a good middleware and then everyone else uses it. By backwards compatibility I mean browsers have to be backwards compatible to render websites written for older versions of the spec (or at least as much as possible), but if you're making/using a "web engine" middleware then you don't need to worry about anything except the website you're currently making. As a browser vendor, you can't expect users to use your browser if existing websites stop working, so whenever there's deprecation in the spec, it takes years for a critical mass of websites to update and a critical amount of users to upgrade, potentially forever if a feature was widely used (more likely the feature just doesn't get deprecated, even if it's harmful). As a middleware vendor, it's not that big a deal if a developer's project stops working, they can just revert to an older version or fix the code. For example, `Date.prototype.getYear` has been deprecated since 1997 (ECMA 1), `&lt;center&gt; ... &lt;/center&gt;` since 1999 (HTML 4), but all major browsers support these (and probably many more).
&gt; How so? If you're making a web thing, you don't really have a choice to go for Qt/GTK/native. HTML/CSS/JS aren't consistently implemented across browsers and you can't control what browser does your user have Anybody working with any non-trivial web stuff is familiar with chrome/ff weirdness, and that's not taking into account ie/Edge/etc. It was even worse before, when ie held a large share and you'd have to both severely limit features you can safely use and sometimes have weird workarounds for cross-browsers.
I'd love to see Rust to JS transpiler myself (no webm).
&gt; The most basic "web engine" would be aware of these issues and will be able to do a much better job. The word you're looking for is "browser." &gt; It's also a lot easier to use than html/css/js, it's insane how much better it is if you really think about it. I've spent maybe 40 or 50 hours doing html/css layout for a spare time freelance project and I still couldn't get it right, it doesn't matter if it was due to a technical limitation or ineptitude. At the same time, I've cranked out crazy multi-layer menus and interfaces in Unity during a game jam, all in the span of a few hours, and it's not something I deal with on a daily basis. And Unity's UI is only a part of a proper game engine, it's far from perfect but it's already lightyears ahead of the conventional web stack in every possible metric. "Because the popular tools don't fit my background, we should replace all those technologies with something I find easier."
Thank you very much. Finally I understand what is called the learning curve steep in struggling with 'lifetime'. Anyway, I think I just climbed the cliff.
&gt; The word you're looking for is "browser." What I'm describing is similar in function, but it would be a thing running inside a browser, and it wouldn't really be "browsing", more like providing an interface to my particular website/app. &gt; "Because the popular tools don't fit my background, we should replace all those technologies with something I find easier." I find tools outside my background (which is 90% web stuff) be significantly more convenient than stuff I use every day. Also I don't think it's only me finding it easier, and it's not by a small margin either, otherwise I wouldn't be so adamantly defending my position.
Wow, didn't know things were getting this official! I love it how you can explicitly specify your target platform in dependencies. No more panics for unimplemented features. Is something like a `node-sys` or `nodejs-sys` coming too at some point?
Confirming this. Multiple changes to which macro features you need to add. If still having trouble, try deleting your target folder, and cargo.lock. What happens if you run `rustup update nightly` ?
[removed]
I'm not sure I get your point, since you say that the most basic "web engine" would be able to do a much better job than a game engine, and then point out all the points where the current web fails at them. My point is more that all of these features are necessary to make life better than normal, webgl+wasm doesn't actually get you them, and so you have a huge amount of work to do building All That Stuff anyway. webgl+wasm alone is very low level and far, far from all you need. Definitely would be nice to have something better though, yes. HTML is over-complicated for what we really need it to do and CSS is frankly bonkers. It would be nice to turn things inside-out and have a dedicated presentation/styling system, a separate semantic-ish document format, and wasm-based scripting to manipulate it.
&gt; Also this seems like a kind of tedious way about writing this wrapper. Agreed. Keep it simple to start and refactor as necessary.
Impressive. Speaking of isomorphic APIs (percy), an interesting experiment might be to make it so this same API can be used to create bindings native-Rust to an embedded Javascript engine.
when will this stuff stop requiring nightly?
There's the asmjs-unknown-emscripten target still in rustc. You can try it, but installing emscripten is far from a breeze.
I would never be in favor of obliterator the JavaScript ecosystem or the language itself. What I'd rather see is JavaScript compiling to WASM and playing on an equal field with all other languages that can target WASM. Rather than getting rid of it entirely, just removing JS interpreters and having it run as compiled, optimized WASM instead.
I think you shouldn’t conform to the REST API blindly. I suggest you design an API according to how you want to use it first, then implement that. 
Try the radix_trie crate
Arguably it's more about the weak equality than the reversibility per se. Isomorphism is transitive, which is probably the most applicable interpretation here: one representation can be mapped to both client and server side unambiguously and completely.
If your list is large enough, the HashSet will be faster. If your list is not that large, Judy arrays might outperform HashSets.
Promises are a part of the ES spec, so I imagine they’d have some way to support them.
Thank you all. Because the traversal progress consumes segments one by one, I implemented the Iterator initializing on demand. \-------------------- use std::**str**::Split; **pub** **struct** Sprig&lt;**'a**\&gt; { string: &amp;**'a** **str**, segments: **Option**&lt;Split&lt;**'a**, **char**\&gt;&gt;, } **impl**&lt;**'a**\&gt; Sprig&lt;**'a**\&gt; { **pub** fn new(string: &amp;**'a** **str**) -&gt; **Self** { Sprig { string, segments: None, } } **pub** fn rewind(&amp;**mut** self) { self.segments = None; } **pub** fn get\_raw(&amp;self) -&gt; &amp;**str** { self.string } } **impl**&lt;**'a**\&gt; Iterator **for** Sprig**&lt;'**a&gt; { **type** Item = &amp;**'a** **str**; fn next(&amp;**mut** self) -&gt; **Option**&lt;**Self**::Item&gt; { if self.segments.is\_none() { self.segments = Some(self.string.split('/')); } match self.segments.as\_mut() { Some(parts) =&gt; (\*parts).next(), None =&gt; None, } } } \----------------------------
Here is the playground hyperlink: [http://play.rust-lang.org/?gist=f389c480e62fea4507c16bd6c6875a4e&amp;version=stable&amp;mode=debug&amp;edition=2015](http://play.rust-lang.org/?gist=f389c480e62fea4507c16bd6c6875a4e&amp;version=stable&amp;mode=debug&amp;edition=2015)
Generators are not used in a user-visible way for futures. While futures might be stabilized "soon", generators will remain unstable for a while. I don't know much about this myself, but [here's what I type-puzzled together](https://play.rust-lang.org/?gist=2fc0214fba2829a3001b77d2d553caf3&amp;version=nightly&amp;mode=debug&amp;edition=2018). Note that the executor and waker in this example doesn't do anything, so you have to repeatedly poll the futures you're interested in.
As other commenters have pointed out, Trie's may be worth trying out, also check out /u/burntsushi's fst crate.
And [here's a version which uses async functions + await!](https://play.rust-lang.org/?gist=210794e9f6bb285d4d22631448e46bf3&amp;version=nightly&amp;mode=debug&amp;edition=2018)
Looks like `js-sys` and `web-sys` work using `wasm-bindgen` which only works on `wasm32-unknown-unknown` target, and only on nightly compiler currently, while `stdweb` has its own runtime, relies on `cargo-web` and also works on stable with emscripten targets (but it also works on `wasm32-unknown-unknown` with nightly).
What legit use does a SYN flooder have? As far as I am aware, it is useful only as a denial-of-service attack tool.
Well, if you're running *that* kind of web app, there's a good chance you're *already* using `&lt;canvas&gt;` or WebGL for your rendering, WASM or not.
You might find [this blog post](https://mgattozzi.com/refactor-rust) on the design of the `github-rs` crate interesting.
stdweb has a promise type that implements "Future" and is able to represent Futures as Promises in JS land. So, it's possible, but I don't know if it is in scope for js-sys.
Whenever the features required land on stable.
Yeah, fuck screen-readers and other accessibility programs
You lose all the benefits of the browser ecosystem provides. Accessibility, font rendering, copy/paste UI (that even works on mobile browsers), history navigation, whatever extensions people have, the ability to edit the page with dev tools, platform specific form controls (do you really want to confuse the tech unsavvy more?), etc. etc.
if you know how you build one its easier to protrct your software against one.
I don't see why we can't do that *eventually*, but we need to get the basics right first :)
There appears to be some precedent of sharing syn flood tools on github. There’s also a rustic mitigation tool https://github.com/LTD-Beget/syncookied. 
Can you give some more details which installation instructions you followed and how it is failing now?
Some more information regarding the current state of future: http://rust-lang-nursery.github.io/futures-rs/blog/2018/07/19/futures-0.3.0-alpha.1.html
No winit ;_;
WebSocket's are going to bottleneck the diff algo too much. VDOM is on its way out anyway.
Can it be converted to the use of crate [faster](https://crates.io/crates/faster)? At least it exposes safe API to the outside, so we'd have a single common unsafe block for many SIMD crates. That cuts down on the amount of code to audit.
Don't do this to me, man! If you keep creating awesome tutorials I'm going to start more projects, and my life can't handle that right now! All joking asside, this is really awesome. I like your writing style, though I can't really say how easy this will be for C/C++ devs to keep up as I have been immersed in Rust too long. At any rate, keep it up!
Why? There's tons of apps out there for timetracking, administrative tasks, calendars, so much more. None of them require SEO.
&gt; Could this be used to pass a JS function callback into a Rust program? If your Rust program is compiled into wasm and is running on a browser, this is already possible (using the library in question, or stdweb). Your example is an http server though, so it's highly doubtful it's supposed to be running inside a web browser. If you want to use js as a scripting language for your server, you'd have to use some kind of interpreter for it. The library in this post is intended for client-side only, afaik.
Last I checked that'd be absolutely impossible because `faster` was insufficiently powerful. It assumes big slices of data that can be worked on in direct batches, but image rendering needs to work per-channel 4 or 8 pixels at a time, not per-pixel. I didn't see a good way to work that into things. I've also got specialized code for the sse2 and avx2 versions of things which properly handles the alignment and masking issues, as well as stride issues. Basically, `faster`, and the similar crate `simdeez`, only work out well in the very obvious cases.
It really depends, but... This is a memory bound problem and Vec&lt;String&gt; + brute force is faster enough. 1000000 x 10byte string = 10 MB. Easy to fit in you CPU L3 cacahe. No hash function costs. If you want to search mutil times, just sort\_unstable + binary\_search, and thats all.
Amazing job! In a few weeks in my roadmap was search engine for my web applications based on tantivy. Now I think you will save me a good amount of time :) Going to integrate it into my library with audiobooks with 1M users per month.
Have you considered Vulkan tutorials? I would very much like to see C++ tutorials ported for Rust bindings, or even better for `vulkano`.
Btw, why did you chose gotham as web engine? The news aren't very "clear" about it. I'd prefer actix-web, it's fast, works on stable and based on actors.
I am in the same boat. Real dick move. No time to read all this awesome stuff. :(
You put a lot of work into this! I've read some lessons and skimmed through others, but overall they are very understandable! I particularly like the procedural macro for attribute binding automation , as I am about to attempt something similar. I second [https://www.reddit.com/user/newpavlov](u/newpavlov)s for a vulkano tutorial.
Glad I could help :) One note though: I cobbled this post together while I was on mobile. So the best thing is probably reading up a bit more on the official docs and trying out stuff. Once you made the step, the other stuff is much easier to understand, and it will make you have a much better understanding of it
I meant dangling or unaligned. Or maybe not properly initialized, though that part is still open.
&gt; For example, we can invoke JavaScript Function callbacks and time how long they take to execute with Date.now() `Date.now()` is not monotonic and should not be used to measure elapsed time.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Rust and OpenGL from scratch, a blog post series where we learn how to build OpenGL renderer with Rust (by u\/nercury)](https://www.reddit.com/r/rust_gamedev/comments/92axd9/rust_and_opengl_from_scratch_a_blog_post_series/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
A single hashset yes, but here they're talking about a tree of hashsets, so essentially reimplementing a trie on top of hashsets.
FWIW depending on the amount of data and ratio of positive/negative matches it might be worth looking at bloom filter (if inputs are mostly expected to not match it gives a fast "definitely no"). A tree of hashset&lt;char&gt; will definitely be slower than a hashset&lt;string&gt; but as /u/Verdonne noted a proper trie (rather than an ad-hoc one) might edge out.
Is `wasm32-unknown-unknown` target only for wasm in web environment or for wasm in any environment? Its name implies that it is not specifically for web but the fact that crates like `js-sys` target it suggests the opposite.
I suppose I've just never seen a company making things like that which would willingly reinvent everything they currently get by depending on kit like Twitter Bootstrap, which itself is smart enough to realize what a gargantuan task it is to reinvent all of the things that are to be had for free via the DOM. (layout, responsive reflow, focus cycling, etc. etc. etc.)
Great, last time i stop at read obj file and put vertex data to a dynamic array. Need some help really 
It's not worth the investment to learn it. I would estimate it takes about 5-10 years to become an expert at C++, and even then you will occasionally write code that has undefined or plain incorrect behavior at runtime. If you can use a more modern language to solve a problem, choose that instead. With Rust you can be productive and write guaranteed well behaved code after studying it for a few days.
Looks like a nice tutorial. Just quickly looked through, but I noticed couple things: I don't really understand why `[repr(C, packed)]` is needed for the `Vertex`. I [did a similar thing](https://github.com/kuviman/ugli) and, ordering and gaps between fields should not matter other than maybe some wasted space in vertex buffers. The way I did it is creating an `mem::uninitialized()` vertex, getting pointers to the fields, and subtracting them from pointer to the vertex itself to get offsets. `mem::forget` this uninitialized vertex after. Instead of `vertex_attrib_pointer` associated method for custom types like `f32_f32_f32` you can create `unsafe trait VertexAttribute` that you can implement for `[f32; 3]` or any custom type of your own, maybe even for types from `nalgebra` if their repr is the same. Same for vertex, creating a `VertexData` trait and implementing it in proc macro should be better than just an associated method. This way, end user's code should be cleaner, I think.
Finally I solved the self-referential struct problem by late-binding, make self-reference at run-time rather than compile-time. And take a hint from you by using Split iterator.
I don't know when I'll have the throughput to write something more detailed, but I've pm'ed you the issue that I tried to solve without arriving anywhere - I sent a PR with a test case which is the only useful thing that came out of it, but that was it.
Great! Can you share a linkt to your code?
The `[repr(C, packed)]` - I think I did it because it is easier to explain it that way (where the data does not have gaps). Same for traits, I found that they were not necessary, so I did not add them. One reason was that a trait may eventually be moved into a separate crate (and then on crates.io), so a developer would not be able to implement it for another custom type from arbitrary crate anyways (without creating a newtype). I agree about having a concrete trait for proc-macro though - if only to get proper autocompletion. I appreciate the feedback, hopefully this is not the last version of this tutorial.
Yes, I did, but I have started with what I know.
Strictly speaking, features can still change between that moment and stable, they are just not gated anymore.
True. The problem being that ActiveX was a desktop components framework like KDE's KParts that supported remote installation via Internet Explorer. Not exactly the best security model for use on the web. (As demonstrated by how Microsoft development products from the period treated ActiveX controls as a cross-language successor to Visual Basic's VBX controls.)
&gt; By backwards compatibility I mean browsers have to be backwards compatible to render websites written for older versions of the spec (or at least as much as possible), but if you're making/using a "web engine" middleware then you don't need to worry about anything except the website you're currently making. &gt; &gt; As a browser vendor, you can't expect users to use your browser if existing websites stop working, so whenever there's deprecation in the spec, it takes years for a critical mass of websites to update and a critical amount of users to upgrade, potentially forever if a feature was widely used (more likely the feature just doesn't get deprecated, even if it's harmful). As a middleware vendor, it's not that big a deal if a developer's project stops working, they can just revert to an older version or fix the code. &gt; &gt; For example, Date.prototype.getYear has been deprecated since 1997 (ECMA 1), &lt;center&gt; ... &lt;/center&gt; since 1999 (HTML 4), but all major How does throwing out the browser's implementations of things and reinventing the wheel improve this in any way? Set an HTML 5 doctype to opt out of quirks-mode rendering and don't use the deprecated bits.
If you actually research the history and details of what you're asking for, you'll see that it's inherently a return to "Designed for Internet Explorer" except that it would be something like "Designed for Desktop Browsers" or "Designed for HiDPI displays" or some other thing where the middleware developers ran out of motivation to catch up with everything the browser provides out of the box.
At the time when I started this there was that whole unsafe usage panic with actix so I chose Gotham at the time. I’ve investigated what it would take to move to actix and it’s probably something I’ll do down the line. 
To be honest, it sounds like you're ignorant of the old saying which explains why nobody manages to supplant Microsoft Office. "80% of the users only use 20% of the features, but nobody uses the same 20%"
Are all your strings 8-character-long? If yes, I guess the fastest way would be to convert them to `[u8; 8]` (or perhaps `u64`) and store them in `HashSet&lt;[u8; 8]&gt;`. That would get rid of heap allocation and indirection, that would exist if you have `HashSet&lt;String&gt;`.
Testing your SYN flood mitigation processes.
Let's rephrase it: What nightly features does it depend on, and when are those features expected to land on stable?
Problem is, that if user forgets to put `repr`, you will be referring to wrong location in memory when binding attributes, which will most likely lead to rendering artifacts, and is not memory safe (although, maybe it still is since `repr(C, packed)` should be smaller in size than `repr(Rust)`). The reason I suggest traits is that these associated methods do semantically same thing for different types, which can also be read as: *these types implement this trait*. You can then also use these types in generic contexts, which you can not do with associated types. You can put bounds on things like `ArrayBuffer&lt;T: VertexData&gt;` so you don't put random data in buffers. And with traits you get better error messages.
Hey! I came across this series recently via some Googling. I worked through the whole thing. It was really well done and very informative. Thanks for writing it! 
The backend equivalent would be implementing a database inside Postgres by storing everything in a single table with a single JSONB column. Or, indeed, [implementing an ad-hoc Lisp DSL inside Rust and then writing your app in that.](https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule) These are examples of the [inner-platform effect](https://en.wikipedia.org/wiki/Inner-platform_effect).
I think it depends on the referential context, i.e. the type system is what makes the difference. A pointer plus an offset can be degraded into an (unsigned, probably) integer, but the compiler treats it as a different kind of thing. If you set, say, `int* p` equal to an integer whose value is the same as the `int *y`, it will be treated as an alias for `y`. 
I mean don't get me wrong I'm not defending companies that would do such a thing. However if you look at what happened when flash and java applets were hip, I can guarantee that there will be (high profile) companies doing that shit!
&gt; I'm not sure I get your point, since you say that the most basic "web engine" would be able to do a much better job than a game engine, and then point out all the points where the current web fails at them. My point is that these features are indeed important and browsers fail at them, but since you as a developer can't force a browser on users - you can't really ensure that these features work in a satisfactory manner. But, you can use middleware that performs all these features, and since you as a developer have full control over it - you can ensure that it performs them exactly right. And provided the middleware is decent, it won't require much extra work from you as a developer.
&gt; How does throwing out the browser's implementations of things and reinventing the wheel improve this in any way? Because it's trivial to come up with a better way to have nested boxes with content than html/css/js. There are good bits of browsers that are valuable and that a "web engine" would have to reimplement (like scrollbars), but there's also a lot of cruft. &gt; Set an HTML 5 doctype to opt out of quirks-mode rendering and don't use the deprecated bits. The code to render and run the deprecated bits is in the browser, which makes the browser slower, more complex, hinders development of newer/faster/better browsers, etc etc. &gt; If anything, I want *more* browser-defined stuff You're basically asking for faster horses . Do you think that html/css/js is the pinnacle of web layout evolution and we'll be using it in a more or less unchanged way 10 or 20 years from now? Also, most browsers expose their OS, already you can write such an element as a library, except you'll be in control and won't have to put faith in browser vendors to implement the spec correctly (or at all).
Great tutorials, thanks! There is one little mistake about nalgebra though: &gt;Vector is simply a Matrix with one row. To resize, we use matrix resize function fixed\_resize with generic parameters na::U4 and na::U1, which mean 4 columns and 1 row, respectively. Vectors on nalgebra are column vectors, that is, a matrix with only one column. Thus `Vector3` has three rows and one column and the `.fixed_resize&lt;U4, U1&gt;(...)` actually resizes it to have four rows and one column. So the line cited above should be: *Vector is simply a Matrix with one* ***column****. To resize, we use matrix resize function fixed\_resize with generic parameters na::U4 and na::U1, which mean 4* ***rows*** *and 1* ***column****, respectively.*
&gt; The code to render and run the deprecated bits is in the browser, which makes the browser slower, more complex, hinders development of newer/faster/better browsers, etc etc. ...and WASM also runs inside that same browser. I still don't get your point. &gt; The code to render and run the deprecated bits is in the browser, which makes the browser slower, more complex, hinders development of newer/faster/better browsers, etc etc. Again, adding WASM to a browser just means it has to support WASM *and* the deprecated bits. &gt; You're basically asking for faster horses . Do you think that html/css/js is the pinnacle of web layout evolution and we'll be using it in a more or less unchanged way 10 or 20 years from now? Also, most browsers expose their OS, already you can write such an element as a library, except you'll be in control and won't have to put faith in browser vendors to implement the spec correctly (or at all). OK, let me rephrase that. I run Linux. The choice between following the Windows or MacOS dialog button order is a function of a boolean preference specified by the Qt or GTK+ theme the user has selected. The browser does not currently expose this information and it cannot be derived from the information exposed via mechanisms like the User-Agent string. Beyond that, most developers don't care to replicate it, while a built-in element would make it simpler to do so. I won't even get started on other Linux features they wouldn't bother to match platform behaviour on, such as: * Should scroll wheel events get sent to the focused widget (Windows) or the widget under the cursor (Linux)? * Does middle-click trigger autoscroll (Windows) or paste the contents of a special secondary clipboard populated by the selected text? * etc. All of these just work in DOM-based UIs.
Thanks!
This is a great analysis and I share the concerns laid out. Initially being a huge fan of in-band lifetimes, after using them I've come to believe that they're the wrong solution for a problem worth solving. Lifetime elision, the first step in making lifetimes more ergonomic, was an elegant solution that eliminated something like 95% of lifetime declarations in functions. Then we got anonymous lifetimes in the form of `'_`, which I really like and find useful. The final step is eliminating lifetime declarations, but I fear the drawbacks outweigh the benefits. The main drawback is that by reading a method signature it's not obvious where lifetimes come from. When reading code, in-band lifetimes *disrupt my flow*, which is the opposite of being ergonomic. My feeling is that *instead of eliminating lifetime declarations, we should extend lifetime elision*. For example, let's consider an example from the blog post: impl&lt;'a, 'b, 'gcx, 'tcx&gt; TypeOutlivesDelegate&lt;'tcx&gt; for &amp;'a mut ConstraintConversion&lt;'b, 'gcx, 'tcx&gt; Lifetimes `'a` and `'b` are simply noise so we can make them anonymous: impl&lt;'gcx, 'tcx&gt; TypeOutlivesDelegate&lt;'tcx&gt; for &amp;mut ConstraintConversion&lt;'_, 'gcx, 'tcx&gt; This is much better. Unimportant lifetimes are removed. And the fact that `'gcx` and `'tcx` were actually declared here tells us that they (probably) bind some references together. This is useful information when reading code, and it's not terribly annoying to type either. Here's another example that I recently used in `crossbeam-utils`: unsafe impl&lt;'scope, T&gt; Send for ScopedJoinHandle&lt;'scope, T&gt; {} Lifetime `'scope` doesn't tie any references together (i.e. it's unimportant) so we can just make it anonymous: unsafe impl&lt;T&gt; Send for ScopedJoinHandle&lt;'_, T&gt; {} This is still very readable (I'd say even more so) and quite a bit easier to type. Recently I've been [fixing soundness issues](https://github.com/crossbeam-rs/crossbeam-utils/pull/36) in `crossbeam::scope` due to incorrect lifetime bindings. Here's a corrected version of the declarations that used to be the problem: pub fn spawn&lt;'scope, F, T&gt;(&amp;'scope self, f: F) -&gt; ScopedJoinHandle&lt;'scope, T&gt; where F: FnOnce() -&gt; T, F: Send + 'env, T: Send + 'env, { // ... } There's a lot of stuff going in here, but we can immediately see that `'scope` is declared here (used only in `spawn`), while `'env` is coming from the `impl` above. After fighting with very tricky bugs in this relatively small file, I appreciate explicit lifetime declarations very much (but only declarations of important lifetimes that tie references together). **TL;DR:** In-band lifetimes disrupt the flow of the reader. The best balance of ergonomic improvements (both for readers and writers of code) would be achieved by extending lifetime elision and allowing anonymous lifetimes in more places. 
I agree, basically reworking the procedural macro to not depend on `repr` and instead subtracting pointers would be the best.
It does control the DOM if you aren't running other scripts on the page. Which is the same guarantees Rust gives you. As soon as you call a C function in your Rust program, anything can happen. 
Great work! I found a little error in part 3. "create \[...\] It is called using Shader::create syntax and acts as a constructor. ", but the function is called from\_source. 
\&gt; the loaded webassembly module does not contain the definition for the "greet" function as I expect Your issue sounds similar to this: [https://github.com/rustwasm/wasm-bindgen/issues/563](https://github.com/rustwasm/wasm-bindgen/issues/563), which popped for me yesterday as well. If it's the same issue for you then it's actually about the JS binding to wasm, not the generated wasm itself.
You don't need wasm-bindgen if you're not on the web - it's job is to generate glue code between rust and js. On another platform, you would need to use whatever method that platform defines to communicate with the environment.
Thanks! This copy-pasting adds up.
Some differences: - web-sys generates bindings from webidl files, whereas host bindings for stdweb are hand coded (I believe). - stdweb uses the `js` macro to allow inline JavaScript in rust (as long as your JS is a valid stream of rust tokens), which wasm-bindgen does not - it encourages you to keep your js and rust in separate files. I think the web-sys/js-sys should be seen as a kind of libc for the web, low level and complete, and wasm-bindgen as something that integrates into the rust build system, with just a single binary to run to generate your rust and js.
Once node supports was (if it doesn't already) I don't see why not :)
would it make sense to look at something like this https://github.com/servo/rust-mozjs ?
It does, even in LTS!
It says you *can*, not that you *should* :p
(from `wasm-bindgen/src/lib.rs`) #![feature(use_extern_macros, unsize)] - [`use_extern_macros`](https://github.com/rust-lang/rust/issues/35896) - [`unsize`](https://github.com/rust-lang/rust/issues/27732)
I wish there was something to auto-gen a type safe client from api specs. The we could have the equivalents of "-sys" crates except for apis... That said, my basic approach would be to write the thinnest wrapper possible as a base, and then dress that up with a nicer wrapper.
The biggest and most important for `wasm-bindgen` is procedural macros; that's on its way to stability. It has `#![feature(use_extern_macros, unsize)]` in its `lib.rs`; the latter is https://github.com/rust-lang/rust/issues/27732? Hm. `js-sys` has `#![feature(use_extern_macros)]`, which is part of Rust 2018, so should be coming quite soon.
wasm in any environment. that `js-sys` is separate from the target itself implies that this is true, not that it's the opposite; you can use the target without `js-sys`.
Does node have WebIDL files for describing their interfaces?
I used https://bitbucket.org/velizarx/pkt-gen to test syncookied. It can generate and send about ~14Mpps.
&gt; Your example is an http server though, so it's highly doubtful it's supposed to be running inside a web browser. You can actually do this with service workers...
I don’t believe so.
Whooo gitlab!
Because once it has changed it is given back to main. Then it is changed again. It is always changed by one function at a time. Not multiple functions simultaneously. Thats the good thing about rust.
&gt;I know it is a little stingy to count megabytes on a modern workstation, but at this rate it feels like if I add a few more dependencies and maybe a few hundred more lines of code my tiny little project is going to take up a gigabyte on my machine! it is the other way round. Rust has all the basic stuff in the executable and when you add code it just adds a little bit of size to the executable. You can actually strip the debug symbols from the executable. Just google it. I'm not an expert on it either. But as a demo just run: strip &lt;executable&gt; And you should see a difference. For more info: https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html
Your "200loc" program is *actually* 200loc + loc(serde) + loc(serde_json) + loc(chrono) + loc(clap) + loc(all transitive dependencies) + loc(std). Rust is like C++ in that it has no stable ABI, so it also has to link and distribute all of your dependencies (including the standard library). `grep` only needs to worry about `grep`, since it can dynamically link to its dependencies (which are C, and probably already installed on the system). Rust binaries are as small as they are because the compiler aggressively throws away anything not actively being used. The largest contributor to tiny programs tends to be the memory allocator, and the IO bits of the standard library, since those are usually unavoidable. On the other hand, if you force Rust to use dynamic linking, and do a release build (which does not contain large amounts of debugging symbols), `rustc` *can* produce executables of a comparable size to C. All that said, Cargo could *definitely* stand to go on a diet. Cargo wastes quite a bit of space for things like repeatedly storing the source code to C libraries over and over again, or the uncompressed code to every dependency you've compiled, or the entire history of the crate index.
You only have one mutable reference at any given time. the first `&amp;mut s1` is a temporary that only lasts for the call to `change_once`, and the second one is a temporary that only lasts for the time of `change_again`.
Because the mutable reference taken in change_once is returned when it is done. The function doesn't take permanent ownership of the mutable reference. 
don't forget `loc(jemalloc)`!
sadface.
Well, really, that's covered by both loc(std) and loc(all transitive dependencies).
~.cargo/registry/index contains a list of all versions of all crates on crates.io, that makes it big. Bit it won't grow as you create more projects yourself. Rust executables are quite bloated in general. This is due to a mix of debug information, monomorphized generics (one copy for each combination of generic arguments) and macros/code-generation (e.g. serde generating serialization code). &gt; having my 200loc code That argument is a bit silly. Your dependencies are far more than 200 lines of code. 
yeah, i guess that's fair. i'd almost call it out separately but you're also not wrong :)
So a problem I've run into a few times with my work on mscorlib-safe, is that I need similar but distinct implementations for interfaces that deref to IDispatch vs interfaces that deref to IUnknown (COM interfaces). IDispatch derefs to IUnknown. For example [_Assembly](https://github.com/ZerothLaw/mscorlib-rs-sys/blob/master/src/source/system/reflection/cominterfaces.rs#L512) vs [_Type](https://github.com/ZerothLaw/mscorlib-rs-sys/blob/master/src/source/system/reflection/cominterfaces.rs#L47). How do I write generic code for both at once? Something like: impl&lt;T&gt; From&lt;NewType&lt;T&gt;&gt; for *mut SAFEARRAY where T: Deref&lt;Target=IDispatch&gt; {} impl&lt;S&gt; From&lt;NewType&lt;S&gt;&gt; for *mut SAFEARRAY where S: Deref&lt;Target=IUnknown&gt;{} Even though the trait bounds are different, Rust treats these as identical implementations. Does the Rust compiler do double deref checks to decide these are identical?
Thanks. I wonder why the book doesn't make this point clear...
Thanks.
Thank you.
Are stable procedural macros considered a part of Macros 2.0? Or does Macros 2.0 only refer to the declarative macro changes?
Thanks for this comment! Would you be willing to post a copy of it to [the tracking issue](https://github.com/rust-lang/rust/issues/44524) as well?
Try \`cargo clean\` and then rebuild your code. As you're working and changing your code, cargo doesn't overwrite or delete previous compilations, so it can build up fast. \`cargo clean\` cleans up these old builds nicely for you.
If you have suggestions, I'm all ears! (I'm one of the authors of the book.)
okay so, the full procedural macros are "macros 2.0", but just like we shipped only custom derive as "macros 1.1", we're shipping only attribute-like procedural macros as "macros 1.2". that's what's coming soon. Still more work to do!
Cool, thanks for clearing that up for me!
Thank you for such a clear explanation! That definitely helps me understand why the binary is so large. Maybe the other confusion is just due to my inexperience with using big and sophisticated software projects, but surely the size of raw git clones of serde+serde\_json+clap+chrono would not be anywhere near the 120MB size of \~/.cargo, would they? I can definitely live with a 10MB binary and a big \~/.cargo, but having my project directory be 100MB is a little more surprising. If you don't mind a personal question, considering that you probably work on big projects with big dependencies, what do your project directories look like? If you work on five projects that have five dependencies, presumably you have gigabytes of stuff sitting around? As a final note, I recognize that maybe this is normal. It is just a bit of a shock coming from writing numerical code in C, where the footprints are pretty small.
Yes, I see what you mean about the 200loc comment. I didn't realize that I was getting a binary that also contained all of std+serde+... and so on. Thanks for the note! 
Yeah, I have tried that, although after the next compilation my project directory is still quite large. I'll keep messing around with it, though! Thank you for the suggestion.
Oh wow! Thanks. Perhaps this point could be made clearer in 4.2 References and Borrowing. It doesn't touch on this issue at all.
Next stable you should be able to shrink it by using global alloc and you can optimise for size. You could also run strip on your exe.
All bits at 0 is a very low entropy state, so it would imply that the heat death of the universe had not yet been reached.
Ah, that makes sense, thank you. Though as others have pointed out... if the browser provides these features the user is free to choose which one they want, that is satisfactory for their purposes. If the developer chooses them by using a GUI toolkit ("middleware" is a terrible and incredibly vague term, call it what it is), then it may do what the developer wants, which may not do what the user wants... such as, have scrollbars that work in the same style as the rest of their operating system. It's a tradeoff, and the tradeoff is "who gets the power".
Thanks, these examples really helped me.
Every call to the DOM is JavaScript interop. Every value receive from a fork or push into an element is, was or will be JS typed. The network access methods are JS interop. Service workers use JS interop. The HTML will use JS interop to communicate. The libraries you will inevitably need because they already exist in JS and don't in webasm are JS interop and probably doing DOM manipulation. The services he's already wrapped are JS interop. A lot of it doesn't run on mobile at all, or runs differently on platforms. You're sticking a veneer of Rust on JS interop with much poorer tooling, a minute fraction of the community and significantly less maturity. You have almost all the pain and horror of JS, with all the extra pain of interop, and all you're getting is an illusion you're writing better code. 
Nice! That is exciting to hear. Thank you for the comment.
Just curious, what is your programming background? I find a lot of people here have several years of programming experience in other languages before coming to Rust, so there may be assumptions we're making that may not be clear to new developers. It's a little hard to notice the air you breathe after all. 
&gt; [...] considering that you probably work on big projects with big dependencies [...] *Oooh, you are so big. So absolutely huge. Gosh, we're all really impressed down here, I can tell you!* &gt; [...] what do your project directories look like? Well, let's see. The `target` directory for a simulator I'm working on (minus `doc`) is... 13GB. The final executable is ~18MB for a debug build, *6.5MB* for release. Actually, `target/debug` alone is ~12.5GB of that. 6.4GB for `debug/incremental`, and 5.4GB for `debug/deps`. On the other hand, my `.cargo` is a *comparatively svelte* 2GB. ~1.8GB of that is `registry`, with ~100MB for `git`. Of `registry`, it's about a 50/50 split between the decompressed source code and the index itself. Oh, this is fun: so, the top three folders in `src` are `exonum_librocksdb-sys-0.5.2` (133MB), `winapi-x86_64-pc-windows-gnu-0.4.0` (50MB) and `winapi-i686-pc-windows-gnu-0.4.0` (48MB). Which is funny, because I have *no idea* what that first one is for, and the other two are both `winapi` (which will probably make WindowsBunny happy). The `librocksdb` thing is so huge because it bundles the *complete repository of librocksdb, including its `.git` folder its entire history*. But, hey, if it's *someone else's* disk space... As for `index`, about 65% of that is the git history of all previous versions of the index. Which is, of course, *totally useless* for someone using Cargo. But that's the cost of using `git` for synchronising the index. So, on the whole, you'll probably get more space back by clearing out old `target` directories than anything else.
I found myself a couple of times running out of disk space because of the Rust target folder sizes. One thing that doesn't help is that after upgrading the compiler, your old build files will still be there. In the C and C++ world, you upgrade the compiler and dependencies much less often, you're often not using an IDE with good fidelity (not that `rls` is feature-complete, but it builds the project again), and you don't always have separate build folders for debug/release configurations. Also, Rust tends to generate more stuff (metadata maybe) when compiling crates. So yes, you have a valid concern, but I don't expect things to change soon.
Python, mostly.
Mother of god. Those are some very large files and directories. Your somebody else must have disk for days. Thanks for that breakdown! Forgive my memory toadying. I'll try to keep lean target directories as much as possible.
Forgive me if I'm wrong, I'm on mobile and can't check. It does reference scopes during the borrowing section right? Isn't there an example where they do something like: { let a = 5; } printers!("{}", a); //ERROR You can think of function calls as new scopes. Do you think adding a mutable reference example in the same vein as this would clarify the issue?
But how would I know what platform am I on? Other platforms can be distinguished by targets, e.g.: [target.'cfg(target_os = "windows")'.dependencies] winapi = "0.3.5" [target.'cfg(target_os = "macos")'.dependencies] cocoa = "0.15" If some other popular platform which uses wasm appears how do I distinguish it from the web? E.g. if I want to target both [nebulet](https://github.com/nebulet/nebulet) and web and want to use `js-sys` only when targeting the web what do I put in the `cfg`?
&gt; Do you think adding a mutable reference example in the same vein as this would clarify the issue? Oh yes that's a proper way of putting it.
Sounds like great excuse to play around with [criterion](https://japaric.github.io/criterion.rs/book/index.html) for an hour and get real numbers (and pretty graphs)!
Can I ask how many years? And I love Python, it was my first language too. Still use it for a lot of stuff, especially work-related infrastructure that needs to Just Work. 
Is there a link to the rationale for yanking it? Besides being able to run on all platforms.
Many many years I think. Around 8?
&gt; Your somebody else must have disk for days. Actually, that was a sarcastic remark said from the hypothetical perspective of the person who packaged `exonum_librocksdb`. It's *my* disk, and this sort of thing is *quite* vexing.
I don't think this is possible currently, you could use features to split the code up.
&gt; you can use the target without `js-sys` But how would I know if `js-sys` is available or not? For example for the `winapi` crate I can use `cfg(target_os = "windows")` to conditionally compile code that depends on it. What do I put in `cfg` if I want to use `js-sys` but only when targeting web? 
Looks like it's just a general, Rust can't tell different implementations of generic traits from each other if you use only trait bounded generic types. 
Are there alternatives to `tunapanel`? `tunapanel` seems too minimal, in my opinion. I need its "runtime parameter adjustment" on some easy to use interface, e.g. the browser. Thanks.
And what exactly about some standard middleware will remove those weird incompatibilities? The browser provides an \_enormous\_ amount of content features to web developers, all of which would have to be ported into this middleware layer. It's not just DOM rendering, it's things like reader mode, accessibility features (which rely on the content on page being actual text), DPI adjustment, even something as basic as text layout. It'd become HUGE, and it would become so big that it would start to have different, weird bugs of its own, and the subset of bugs on each browser where it were implemented would become different. Furthermore, it wouldn't really give devs much of a choice. This middleware layer would be so complicated that there would necessarily be only two or three of them, so you'd just have to pick one. And if you, as a dev, wanted more control over the rendering than that, well... if you take my example as well (using OpenGL to accelerate drawing), then not only do you have to account for browser differences, you have to account for OpenGL DRIVER BUGS, which I assure you: if you think browser bugs are weird, just you wait until the utter hell of web devs having to dig through undocumented bugs in AMD and NVIDIA OpenGL drivers, then having to account for Mesa implementations on Linux, and ARM/Qualcomm chips on mobile, which are the WORST implementors of OpenGL in the universe...
One of my project's target dir is [41.7 GB](https://i.imgur.com/slFWN2U.png) but I think that's mostly because I haven't run `cargo clean` in over a year. So whenever I update my nightly, it created new build artifacts, which accumulated over time.. I hadn't had a problem with disk space yet, otherwise I'd have run `cargo clean` already..
Just curious, what are you using exonum for? :)
Providing ballast to reduce vibrations in the disk and reduce system noise.
You need a DOS tool to test the protection against DOS.
[removed]
http://vulkano.rs/guide/introduction
http://vulkano.rs/guide/introduction
Ah, that's a good point.
Awesome! I've been doing something similar for the Stripe API. My goal being to take advantage of conformity to REST patterns to write only minimal amounts of code. https://github.com/spotlease/stripe-rust/tree/master/src I wrote some macros to reduce repetitive boilerplate code. https://github.com/spotlease/resx
[removed]
Ah; I'm not sure.
To summarize, your recommendation seems to be to stabilize underscore lifetimes but not in-band, is that right? Or are you proposing more elision than underscore lifetimes can currently do? 
Why on earth does it even remotely matter (in a negative sense) that there is JavaScript in the rand crate? it’s for compatibility with WASM. it serves a purpose! It doesn’t do anything on other platform targets.
As you see in the module declaration, it is for the wasm32 target: #[cfg(all(target_arch = "wasm32", not(target_os = "emscripten"), feature = "stdweb"))] It is used to implement rand functionality in the browser.
Uh, are you also aware that `repr(packed)` can cause UB? You introduce it very lightly and offhand in the tutorial, but you should actually use it as absolutely infrequently as possible. https://github.com/rust-lang/rust/issues/27060
I think the formatting of your block quote at the start is messed up. Looks like the number 2018 started a line and the markdown parser thought you wanted to start a numbered list.
&gt; We can also turn some warnings into hard errors. Does this have to be done before the first Rust 2018 release? (1.31.0) If I understand correctly, then after that initial release warnings into hard errors would be a breaking change.
I think the title you chose is quite rude towards the Rand contributors. You could have just written "Why does the rand crate contain JS code?" or similar. Also, what exactly is the problem? Yes, there is JS code in the rand crate, but you don't say why it is a problem.
The big thing is that `js-sys` and `web-sys` are built on top of `wasm-bindgen`. `wasm-bindgen` has been designed and built with an eye towards leveraging the ["host bindings" proposal](https://github.com/WebAssembly/host-bindings/blob/master/proposals/host-bindings/Overview.md) to eventually get even-faster-than-JS DOM performance, because DOM calls can be validated at wasm compile time rather than dynamically type checked on every call. `wasm-bindgen`'s other focus is to enable you to only pay for what you use. If you only use `js_sys::Array::new` and `js_sys::Array::push`, then you won't entrench bindings to `js_sys::Object::freeze` in your binary. Finally, as mentioned in sibling comments, `js-sys` and `web-sys` are meant to be `libc`-style crates that just provide the raw bindings and building blocks. We want to get this layer rock solid so that no one else has to put in the effort to do the same, and can instead focus on higher level abstractions and libraries.
I believe there are typescript definitions for node APIs, and we have a WIP typescript frontend to wasm-bindgen. It needs some love though, so if this is something you care about, consider contributing to it!
I think it didn't have a clear path to stabilization. The lower-level bindings were stabilized and the best higher-level bindings can be developed independently or Rust.
Yep; I pushed a fix, thank you!
Yes, that's my understanding as well.
Yes, my suggestion is to stabilize everything in Rust 2018 related to lifetimes besides in-band lifetimes. Consider [this example from the edition guide](https://rust-lang-nursery.github.io/edition-guide/2018/transitioning/ownership-and-lifetimes/lifetime-elision-in-impl.html#lifetime-elision-in-impl): impl&lt;'a&gt; Iterator for MyIter&lt;'a&gt; { ... } impl&lt;'a, 'b&gt; SomeTrait&lt;'a&gt; for SomeType&lt;'a, 'b&gt; { ... } I'd like the following to be possible in Rust 2018: impl Iterator for MyIter&lt;'_&gt; { ... } impl&lt;'a&gt; SomeTrait&lt;'a&gt; for SomeType&lt;'a, '_&gt; { ... } However, when implementing `Iterator` here, one would probably want to bind the lifetime to the item `type Item = &amp;'a T` so we'd still need an explicit `&lt;'a&gt;`. This is unfortunate but I think the right solution is [this proposal](https://internals.rust-lang.org/t/lifetime-elision-for-associated-types-unbaked-idea/7997), not in-band lifetimes.
Yes, I am aware, the tutorial should also make reader aware too. Good point :)
I think incremental compilation is also consumes a lot of storage.
You can define your own features: [features] web = ["js-sys", "web-sys"] node = ["js-sys"] nebulet = ["nebulet-sys"] and then do #[cfg(all(target_arch = "wasm32", feature = "web"))] mod imp_web; #[cfg(all(target_arch = "wasm32", feature = "node"))] mod imp_node; #[cfg(all(target_arch = "wasm32", feature = "nebulet"))] mod imp_nebulet;
Thank you, updating wasm-bindgen and wasm-bindgen-cli did the job. I thought I tried that but apparently not :)
Thank you, updating wasm-bindgen and wasm-bindgen-cli did the job. I thought I tried that but apparently not :) /u/firefrommoonlight that was actually what caused the issue for me ;) but thanks for the help!
Thanks a lot!
&gt; I didn't realize that I was getting a binary that also contained all of std+serde+... and so on. You binary only contains what you actually use (mostly). But you still have to build all the other crates before you can link your binary.
Probably better to make them aware of it and then also not even use repr(packed) at all. Just eat the very mild space "loss" if you happen to use something smaller than f32 in your vertex format. I'm not a GL guru, but I've only ever used f32 vertex data anyway.
One mitigation of the issues I've liked to think about using (but I haven't because time issues) is using `'Lifetime` for type/impl level lifetimes and `'lifetime` for fn level lifetimes. This creates a clear distinction between the two levels when nested. Another somewhat stupid idea: allow in-band lifetimes for top-level only. Removes confusion, adds location dependence, yeah that's a bad idea.
One mitigation of the issues I've liked to think about using (but I haven't because time issues) is using `'Lifetime` for type/impl level lifetimes and `'lifetime` for fn level lifetimes. This creates a clear distinction between the two levels when nested. Another somewhat stupid idea: allow in-band lifetimes for top-level only. Removes confusion, adds location dependence, yeah that's a bad idea.
Have there been any proposed language changes that would prevent the compiler from being able to use the same internal representation as earlier editions?
Not seriously proposed ones. But there are infinite programming features; a Rust 2.0 could do *anything*, like say, add a tracing GC by default. Editions cannot do that.
[removed]
It's the same way an app that works on Windows XP will work on Windows 10, but not necessarily the other way round. For example, [num] is [set up] to test in 1.15.0, and they declare that it works on 1.15.0 *and newer*. A newer version of rustc should not break apps that worked on the older ones (there are exceptions; they are rare and necessary). Some libraries don't advertise a minimum version of Rust like that. They are not production ready. [rust-num]: https://github.com/rust-num/num [set up]: https://github.com/rust-num/num/blob/d37ca5d7a662212abfc47bd94032c7c7d2bba6ab/.travis.yml#L3
That sadly is not too informative, although still a nice start.
I find this comment needlessly harsh. There's been recent security problems with other communities' source and package hosting, where unexpected code showed up in trusted dependencies. If you don't know what all is going on, finding a higher level language in a low-level building block can be unexpected. I'd rather people speak up when they're surprised by something than just assume everything is fine. Anything else just makes community reviews less likely. It would be a great opportunity to find out where the confusion lies, where to put code comments to increase the chance that even reviewers unfamiliar with the full context know why stuff is there.
Well, what do you want to be informed about particularly? Or, just the whole Vulkan book in rust?
&gt; Also, Rust uses named arguments on types. Rust generics have two different kind of "arguments": * Type parameters are positional, not named. * Associated types are named, not positional. It's weird, but it has "named arguments on types" to distinguish between these two things.
It is not completely catastrophic though: if we try to modify a mutably borrowed packed value, at least we get a warning: let r = &amp;mut data.number; *r = 44; Warns: warning: borrow of packed field requires unsafe function or block (error E0133) --&gt; src/main.rs:9:13 | 9 | let r = &amp;mut data.number; | ^^^^^^^^^^^^^^^^ | = note: #[warn(safe_packed_borrows)] on by default = warning: this was previously accepted by the compiler but is being phased out; it will become a hard error in a future release! = note: for more information, see issue #46043 &lt;https://github.com/rust-lang/rust/issues/46043&gt; [Link to playground](https://play.rust-lang.org/?gist=a4d48b9409e5ce70400eeb36f5ad66d1&amp;version=stable&amp;mode=debug&amp;edition=2015)
Well I mean it's not a tutorial for making a renderer lol, and it also doesn't help much for understanding the complex examples.
Not with the standard library we have at the moment. There is forum discussion towards having fallible allocation stuff become part of `std` one day.
&gt; Is it possible to recover gracefully from an OOM error in rust yet? Not if you're using allocations from the standard library. You need to directly use [`std::alloc`](https://doc.rust-lang.org/std/alloc/index.html), which has allocation methods that handle errors with return values instead of panics. Although it looks like there's an unstable lang item ([`alloc::oom`](https://doc.rust-lang.org/src/alloc/alloc.rs.html#181)) that allows for changing the behavior of failed allocations, but the function is required to not return so abort, panic, and infinite loop are the only options there.
WASM is not the browser. There are legitimate uses of it outside of a browser, where a JS run-time is not available.
Do you have a website with more information? I'd like to know exactly what sort of medical software you're planning to work with. I'm a former developer for Epic Systems Corp, so if it's an EMR or integrating with one this might be right up my alley.
Are you developing on windows? If not, the `winapi-&lt;target&gt;` packages were downloaded most likely by some overeager cargo command like `cargo clippy` or `cargo fetch`. They are useless on linux. In any way, you shouldn't have both unless you're compiling for both targets.
Would you consider a library that uses `unwrap()` to be a "badly designed library"? I wanted to do some graphics stuff and wanted to play with vulcan, so got `vulkano`. After getting it setup, getting drivers OK for my intel card, and building the example it crashes because of `unwrap()` used in the library itself (not the example). Searching the repo gave 90+ unwraps. I went to `vulcan` because it seems the popular GL libraries require you to use `unsafe` and I wanted to make my app crash tolerant, but this is making me question if `vulkano` would really do that.
If you click the Graphics Pipeline part of the tutorial, and then the "putting it all together" sub-section, you can see that the tutorial leads up to having a triangle on screen same as this one. From there, normal 3d graphics concepts like matrix transforms and such all apply pretty equally to vulkan and opengl. You can even write GLSL shaders and complie that into your vulkan shaders.
Did you respond to the wrong person? To be clear, I don't care either way about whether wasm will replace Javascript
In the recent RFC about [fixing the Error trait](https://github.com/rust-lang/rfcs/pull/2504), the "cause" function is given a better definition under the new "source" name. The issue came up that it's unfortunate to lose the current name to get a better definition: https://github.com/rust-lang/rfcs/pull/2504#issuecomment-406275967 I wonder if there's a way to "have your cake and eat it too" with editions here somehow. Something like (just spitballing) a "cause_new" function that's named just "cause" in the next edition. Has there been any existing discussion on something like this?
2018 -&gt; 9018 Solves the "2018 sounds old" problem.
Yeah I realise that, and that's pretty much also what I've been doing!
&gt; That’s the point! From an engineering perspective, this is great. But from a user-facing perspective, it’s harder to keep track of what’s going on in Rust unless you pay close attention every six weeks. That's an interesting point. Perhaps right before/after the edition release, it's worth compiling an edition to edition diff/changelog, like a list of major features introduced. That could be useful for someone who may have stopped using Rust to take a glimpse to see what major things have changed.
I've only read the tutorial myself, i ended up deciding against vulkan because i already had an opengl version and I'd lose mac support if i switched to vulkan. Some day gfx-hal will be released and I'll use that. If you really wanted to, I think a good way to learn Vulkan itself would be to go through the learnopengl.com tutorial and convert each lesson into vulkano code. That way you're at least approaching the 3d Graphics part of things in an order that makes sense (blank screen, flat triangle, quad, box, spinning box, etc).
but the cfg has feature = "stdweb", so this will only be included que targeting web specifically
We have that; it's https://github.com/rust-lang-nursery/edition-guide
Really? What's the situation with devices without an operating system? As I understand it it's not as mature as C.
You should write a whitepaper about it and do an ICO ;) Using a byzantine fault tolerant blockchain to reduce disk vibrations and reduce system noise by leveraging POB (Proof Of Bloat)..
Yes; it's impossible. The standard library cannot change per edition like this.
I'm a Rust superfan. I closely and religiously follow Rust updates. I read every TWiR, read through RFCs when I can, and unnecessarily update my personal Rust projects with the new features as they hit stable for fun whether I need them or not. Despite all that, I'm still having trouble following exactly what changes are expected in the 2018 Edition, or what 1.XX release it corresponds to. It's very unclear what *concretely* is 2018 Edition besides "it will be easier to update to it"
So `stdweb` could eventually be rewritten to be a higher level abstraction over the "libc for the web" (`js-sys` and `web-sys`), while `wasm-bindgen` acts like the linker, right?
&gt; what changes are expected in the 2018 Edition, This wasn't in the post because it's a high-level explanation of the concept; we'll be doing more messaging about exactly that in the future. Until then, check out the edition guide I linked elsewhere in the thread. &gt; what 1.XX release it corresponds to. The initial release will be Rust 1.31, described in the post. Additional features may land in the future too; for example, `async`/`await` is not going to be ready for the initial launch, but will happen in the future. (pun intended)
That is my understanding as well but allowing OOM errors seems like a bigger interface change considering we are past 1.0.0.
I get the impression the edition guide won't cover the changes for intermediate versions. I know there are a lot of things I saw on TWIR that aren't in that edition guide.
I would, generally, consider a library that uses `unwrap()` to be a "badly designed library.", but there are cases where it is safe to do so, like when you're using `matches.is_present` (from Clap) with `matches.value_of.unwrap`, because `matches.is_present` asserts, given that the argument takes a value, that `matches.value_of` is a `Some`: ```rust fn main() { let matches = /* ... */ .get_matches(); // Imagine NUM takes a value if matches.is_present("NUM") { // Safe to unwrap let num = matches.value_of("NUM").unwrap(); } } ``` But any library with those kinds of cases should propagate the result back to the user, so they can decide whether they should `unwrap()` it or not. Has `vulkano` undergone fuzzing? If so, it would probably crash a lot, which is not good for a _library_, not an application.
Try using some kind of reactive JS framework with Rust compiled to WASM. [Vue.js](https://vuejs.org) could change the size, width, color, etc. of elements using JS-passed WASM messages.
\&gt; The meetup will likely be held in German Seriously, in German? Why?...
That is certainly conceivable! It is, of course, the `stdweb` developers' decision to make :)
Ah I think that guide is exactly what I'm after. In particular, https://github.com/rust-lang-nursery/edition-guide/blob/master/src/2018/status.md looks very helpful
Haha this post reads like someone from the Rust Evangelism Strike Force managed to annoy SQLite maintainers (Hipp?) enough to write a blog post. 
It's not a heavy focus, but there are some really convenient things available already. There's a divide between the "core" standard library and the normal one, with everything that works with no OS support (threads, memory allocation, file handling) split out and usable separately. So you can still use convenient functions like `cmp::min` even if you can't use `collections::Vec`. As far as platform support, Rust works for anything that LLVM targets, which is pretty broad but doesn't cover every platform that has a C compiler for it.
I didn't really flesh out my specific idea, and I'm definitely way out of my depth suggesting language changes. So, bearing that in mind... :) Would this be outright impossible? The Error trait could change exactly as proposed in the RFC, only source would be cause_new instead. In Rust 20XX, the trait definition is still the same, only you refer to "cause_new" now by just writing "cause", with the difference only being at the syntax level. What was called "cause" in the previous edition could be called "cause_old" in the new edition, if you still needed to refer to the deprecated version for some reason. Essentially, allowing a function to define which name it should be referred to by, according to edition.
I've switched to GitLab for all my new projects, though some of my old ones are still on [GitHub](https://github.com/anirudhb). I did this not because MS bought GitHub (that is partially why), but also because GitLab has _vastly better_ CI features. It has it built in and it is completely integrated, unlike GitHub, where you need to add Travis or something.
It doesn't today, but I'd like to push for that to be a thing. We've been focusing on the *new* stuff, but I think going all the way back to 1.0 is a good idea.
Your ~/.cargo is small. Mine is 1.5GB right now. And my Rust projects use 10GB total, max space used by a single project is 2.5GB. And I think it was once around 30GB before I cleaned it. So Rust actually used more space than all other things in my system combined. I don't know if cargo can clean ~/.cargo itself, but `cargo clean` can be used to get rid of old artifacts in project dir.
I don't remember the specific details, but in general, the standard library has to remain the exact same for all editions. We can't change or remove things per-edition, period.
That makes a lot of sense. Thanks.
Thanks, never heard of the inner-platform effect.
(Responded in private.)
I know that all of this information isn't particularly difficult to capture yourself with `env!` macros, but why bother? Now it's all here as regular Rust constants!
&gt; it is possible that SQLite might one day be recoded in Rust Looks like it may have worked, though.
&gt; First of all, to help in choosing between different alternatives, it'd be great to remove crates from `rust-lang-nursery` when there are not maintained by the core Rust devs anymore. In the same vein, we should probably write something in the readme and crates.io, because when we see "The Rust Project Developers" as the authors and the Rust logo and some core devs in the owners section, we'd think it's still actively maintained by their original maintainer, which could lead a company to think that the library is bound to remain of top quality, which might not always be the case. **I disagree** The community of contributors to Rust is by *necessity* expanding; this is the whole reason that Working Groups have been created. As a result, it is to be expected that new users will be empowered to drive initiatives beyond the core developers. The nursery contains `regex`, which is maintained by /u/BurntSushi, who is not a "core" developer. You are here advocating for pushing `regex` out of the nursery since no Rust core developer maintains it; and we'll all be the poorer for it. Ultimately, the nursery is not about the "pet" crates of the core Rust developers, it's about core crates for the Rust ecosystem, which is a vastly different thing. The crates here are expected to be rallying points (best-in-class), and their maintainers are chosen with care. The presence of JS in a Rust *might* be surprising, if you are unaware of WASM being a goal of the year, but I find your tone of place and wish you'd edit your post to stick to the (technical) point rather than imply that the current maintainers are not trustworthy/incapable.
I use winit, glium, glutin and am happy with it.
The page has existed for a long time; the Rust section, of course, has not ;)
Yes, that's my point, this tutorial series uses sdl2 for some ungiven reason.
&gt; I have picked the SDL2 crate for window creation and events. My thinking was that many existing game developers are familiar with SDL2, and SDL2 is a good example of a well-done Rust C API wrapper. I still would have chosen the winit, glium, glutin stack though. But glium's own tutorials already explain how to use it very well (even if you've never used OpenGL in C/C++ before).
**TL;DR: I don't see (A) being met any time soon; Rust is not meant to stall.** --- &gt; A. Rust needs to mature a little more, stop changing so fast, and move further toward being old and boring. Not going to happen anytime soon, and possibly never. &gt; B. Rust needs to demonstrate that it can be used to create general-purpose libraries that are callable from all other programming languages. Rust can export a C ABI, so anything that can call into C can also call into Rust. There are also crates to make FFI with Python, Ruby or JavaScript as painless as possible. &gt; C. Rust needs to demonstrate that it can produce object code that works on obscure embedded devices, including devices that lack an operating system. This has been demonstrated... *on nightly*. There is a WG-Embedded working on making embedded a first-class citizen in the Rust ecosystem, but there's still quite a few features which will need to be stabilized before this is supported fully on stable. Also, for now, rustc is bound to LLVM for target support. &gt; D. Rust needs to pick up the necessary tooling that enables one to do 100% branch coverage testing of the compiled binaries. I am unclear on the tooling that Rust misses here; I suppose this has to do with instrumentation of the binaries, but wish the author had given an example of what they meant. &gt; E. Rust needs a mechanism to recover gracefully from OOM errors. Rust the language is agnostic to the OOM handling strategy; it's the `std` which brings in the current OOM =&gt; abort paradigm and builds upon it. I find the OOM situation interesting, seeing as C++ is actually heading toward the opposite direction (making OOM abort instead of throw) for performance reasons. &gt; F. Rust needs to demonstrate that it can do the kinds of work that C does in SQLite without a significant speed penalty. I think Rust has already demonstrated that it can work at the same (or better) speed than C. Doing it for SQLite workloads would imply rewriting (part of) SQLite.
Oh silly me. I skipped right to reading the articles XD
They could always add a full set of `fn try_*() -&gt; Result&lt;*, OomError&gt;` methods to the different collections.
&gt; The meetup will likely be held in German, we will however reevaluate this at the beginning of the evening and may switch to English if needed. Isn't that reasonable? :)
It's what the majority of people in Cologne, Gemany speak. If you want to join us and don't speak German we have no problem switching to English! (I *think* Matthias will give the talk in English in any case, as it will be recorded.)
&gt;I am unclear on the tooling that Rust misses here; I suppose this has to do with instrumentation of the binaries, but wish the author had given an example of what they meant. Look at [this]( https://sqlite.org/assert.html) article for the kind of instrumentation they're talking about. The `testcase(X)` macro especially looks like its designed for code coverage testing.
Wouldn't it make more sense to preallocate memory in embedded systems? Recovering from a real OOM condition in any meaningful way seems pretty tough even in C
I'm really curious about the maintenance of 2015 edition. 1. The post states, that codebases in both flavors will be able to cooperate. But if 2018 introduces something affecting libraries' public interfaces, let's say anonymous lifetimes, how will 2015 code express its usage? 2. Will there be maintained 2 compiler front-ends? And since 2021 3?
Glium is not abandoned! &gt; Glium is no longer actively developed by its original author. That said, PRs are still welcome and maintenance is continued by the surrounding community. It's still being maintained and I'd still use it for new projects, until something similarly high-level exists for vulkan :)
You mean like vulkano? Or like gfx-hal someday?
Well, Rust supports macros too so I guess it's good to go :)
No, I mean as high-level / convenient as glium. &gt; What does vulkano do? Provides a low-levelish API around Vulkan.
&gt; The post states, that codebases in both flavors will be able to cooperate. But if 2018 introduces something affecting libraries' public interfaces, let's say anonymous lifetimes, how will 2015 code express its usage? They compile to the same MIR, so you'd call it like anything else. Anonymous lifetimes only affect definition, not usage. You'd call it like any other function. &gt; Will there be maintained 2 compiler front-ends? And since 2021 3? One front-end with some switches to de-sugar things differently based on edition.
Would it not be possible with some kind of annotation on the functions? For all the linker has to know, nothing changed, but new names could be used in the language itself.
I think what /u/skiippy might be referring to is a feature akin to what Swift did with Swift 3, where the new syntax would be a syntactic shim around the old one: https://github.com/apple/swift-evolution/blob/master/proposals/0005-objective-c-name-translation.md All the new “fake” names would be translated to the “real” ones before doing any actual semantic work. No actual APIs would have to change for that. It maps from Swift to Objective-C. In /u/skiippy’s case it would map from Rust 2018 to Rust 2015. 
[removed]
That's what swagger/OpenAPI aims to do, there's already a codegen for Rust (server and client): https://github.com/swagger-api/swagger-codegen/pull/6613 You just describe the API as yaml and it generates the client / server code for you: http://editor2.swagger.io/ (you can edit the example API, it typechecks it for you) https://www.openapis.org/ https://swagger.io/solutions/getting-started-with-oas/
JavaScript is what it its, not the best but we have to live with it. As long as Rust doesn't depend on NPM/node in anyway I'm fine. That product is disaster on many fronts tho. 
Hi I was wondering if these are any other tutorials on ARM microcontrollers with Rust (below seems pretty good): http://blog.japaric.io/quickstart/
[removed]
Maybe? I’m not sure. There’s no way this is possible for 2018 though; maybe for 2021 :) your have to write an RFC, get it accepted, and get it stabilized. I don’t think there’s enough time, even with the most aggressive possible schedule.
In C you can check every `malloc` return value and then either report that the operation could not be completed or complete it in a way that does not require extra memory - see C++'s [stable_sort](https://en.cppreference.com/w/cpp/algorithm/stable_sort), which has different time complexity depending on whether or not it is able to allocate extra memory. In memory-constrained systems, yeah, you do usually want to avoid dynamic allocations as much as possible. I've worked with embedded systems that were high-spec enough that that wasn't necessary, though. Then you get Linux, which typically tells the process that it can have all the memory it wants and then kills it if it takes too much. [Overcommit](http://engineering.pivotal.io/post/virtual_memory_settings_in_linux_-_the_problem_with_overcommit/) makes handling OOM terrible.
Small question. What would happen if a 2015 crate exports a 2018 reserved word and you want to use it in 2018 edition rust? Like say if `catch` would be a reserved word in 2018 rust, and a 2015 rust module has a public struct or function called `catch`? How would you reference it?
There’s special syntax, “raw identifiers”, that lets you do that. r#catch(); To call a function named “catch”.
What's the difference between printing to stdout (since you can't even open a file anymore) and just aborting?
The funny thing is that the browser is already an archetypal example of the inner-platform effect: a hypertext-browsing application has been generalized to the point that it can host *other applications* inside it, written using APIs, and executed via mechanisms completely distinct from what the operating system already provides. So going even deeper and using the browser just as a canvas would be an example of a higher-order inner-platform effect—an inner-platform inception if you will.
Yeah, that does look akin to what I was thinking, thanks for linking that! So it wouldn't be changing or removing things in actuality, just making it look like you did. I'm sure my specific idea is not great for lots of reasons... this really isn't my area. But I keep seeing the Rust devs come up with amazing "have your cake and eat it too" solutions, so I'm interested to see if they'll get some of the "we can't fix this, even in an edition" desired changes in some clever way in the future. :)
A bit off topic for this subreddit, but what's the difference between `assert` and func assert(what bool, message string){ if what { panic(string) } }
Thanks
No problem!
Printing to stderr can fail too, or you may be running in an environment where nothing is listening. Sometimes you have no choice but to abort.
https://github.com/rust-lang-nursery/rand/pull/336#issuecomment-376142026
I'll definitely check your link out. Thanks
I'll have to study that crate some more. I think I'm going to reach out to the developer and see if he can answer my questions
Sorry, I was mostly thinking out loud on this. I definitely didn't mean to imply this was a change I thought should be brought forward, and definitely not for the edition coming right up! :)
Its cool!
Thanks for the advice :) I will give Ash a go.
That link is probably where you should start. 
Wow! That is a very nice offer, but I don't think I will ask you to do it considering that I'd mostly be doing so out of morbid curiosity. 42GB is nuts.
&gt;SQLite reads and writes small blobs (for example, thumbnail images) 35% faster¹ than the same blobs can be read from or written to individual files on disk using fread() or fwrite(). &gt;Furthermore, a single SQLite database holding 10-kilobyte blobs uses about 20% less disk space than storing the blobs in individual files. So, has anyone implemented a kernel sqlite database driver to use as filesystem?
&gt; 2018 -&gt; 9018 Yes it does! did you mean 2019? 
Wow that sounds awesome! These systems really need to be brought into this century. I'm very interested in!
&gt; and I'd lose mac support if i switched to vulkan you can use [MoltenVk](https://moltengl.com/moltenvk/)(which is free and open source) for Vulkan support on Mac and iOS
I guess they could make a standard library fork that puts the equivalent of a `NEVER(X)` macro on every bounds check's failure path.
Neat. But I don't own a mac, so I'll just write the more normal thing against opengl 3.3 and then pray hard that it works on mac (at least until they take out opengl entirely).
[removed]
I just did a dance with openssl recently, I wish I'd had this article then! I ended up just dropping down to hyper instead of using reqwest and using rusttls instead of openssl. I wonder how hard it would be to add a feature to reqwest that does the same.
No but 9019 would work too.
Well in the kernel you don't need to call syscalls anyways?
The regex crate _was_ pushed out of the nursery a long time ago. It just happened to land in `rust-lang`. :-) (Affectionate nits aside, of course I agree with you!)
I thought that you can name type parameters too, and apply them out of order. Otherwise Niko's rationale for HKT type inference being untractable (unlike in Haskell) doesn't make sense.
Oh my, it's OVER 9000!
Perhaps we should start at 9000. Then we'll always be higher and better than e.g. C++11.
So... building readable tests by reinventing [`derive_builder`](https://docs.rs/derive_builder/)?
TIL about musl. Thanks for that note.
On its way out for what exactly? Genuinely curious?
If one reads the linked thread it becomes quite clear, though, as /u/tomaka brings up some valid concerns with the PR. 
`assert` in C is macro which does not generate any code, if you define `NDEBUG` symbol.
A Rust SQLite would need to be `no_std` anyway as the standard library won't run on toasters.
Because AFAIK `assert` is not supposed to be enabled in a release build, only in a debug one. At least, that's the practice I am most familiar with. And since we are digressing, the author writes at one point &gt;Recoding SQLite in Go is unlikely since Go hates assert(). This is explicitly not true. [The Go FAQ entry](https://golang.org/doc/faq#assertions) about assertions explains, why `assert` isn't a part of the language or the stdlib. Quote: &gt;\[Assertions\] are undeniably convenient, but our experience has been that programmers use them as a crutch to avoid thinking about proper error handling and reporting. Saying that Go "hates" assertions is kinda like that "Go hates generics" meme.
String formatting
I got an hello world running on my vape mod some two years ago or so, while needing nightly it was actually straight forward, piggybacking on a couple of C device drivers.
I mocked out how I would put that example and I don't like it. It's too implicit. I think using function calls like your OP does a better job of showing how ownership is 'returned' rather than faking out a scope example.
C Fundamentalist Counterstrike Squad, anyone?
I don't know of any rust shops in STL, but I know for a fact that there are at least like three of us that use rust for fun, so I figured I'd set up a get-together for us to share our work, get feedback, and just talk rust. If you're in STL and are interested in rust, we'd love to have you. Also, if you'd like to give a talk or offer up a venue, let us know. _bax
You want /r/playrust.
&gt; It is a well-understood language Haha, right.
I always love these posts, thank you!
But the thing is, exonum_lobrocksdb on your machine isn’t just a package. It’s the source of the package and everything needed to build it. And now I’m just guessing, I didn’t check, but likely it’s using bindgen, which is regularly used to generate binding from c code at build time. So yeah, it would actually need the source for rocksdb. Now if only git had —depth=1 that also worked with tags and branches...
I wrote [this post](https://deterministic.space/elegant-apis-in-rust.html) some time ago, linking to some examples, but I think it could use some updates. I'll check back on this threat in a bit :)
I love how rust really takes things like this seriously. There are many projects where the answer would be „tough luck“. 
Thanks for reading! I agree, a "rusttls" feature for reqwest would be great if there were a way to share the same API with `native-tls`. I mistakenly thought I had several crates which relied on OpenSSL when I started this article, but it turns out I only need it for outbound web requests. So there's probably several workarounds I can try, but even if I can avoid OpenSSL now, I expect I'll need to link against Postgres or other shared library sooner or later.
You're welcome! Compiling Rust against musl is an awesome developer experience, more like compiling binaries with `go` where they can be run on any Linux platform. If your project meets its requirements :)
"inserts additional machine branches" feels misleading here. If it's actually ensured that the access is never out of bounds, the branch ends up optimized away by the compiler.
assert in C is typically only enabled for debug builds
In case of indexing slices that’s already kinda a thing: https://github.com/Kixunil/dont_panic/tree/master/slice
[removed]
Seconded :)
&gt; &gt; C. Rust needs to demonstrate that it can produce object code that works on obscure embedded devices, including devices that lack an operating system. &gt; This has been demonstrated... on nightly. &gt; There is a WG-Embedded working on making embedded a first-class citizen in the Rust ecosystem, but there's still quite a few features which will need to be stabilized before this is supported fully on stable. Also, for now, rustc is bound to LLVM for target support. It's worth mentioning that there are C compilers for practically every platform that exists. But there aren't LLVM targets for some of them (VxWorks is the one that's a pain point for me). So I don't think that sqlite would ever rewrite purely for that reason alone.
Could a contraption of this kind help: https://github.com/JuliaComputing/llvm-cbe ?
True, and [go](https://godbolt.org/g/bo5VWn) does generate an (empty) function call. It's a pity it doesn't optimize out empty function calls. Maybe gccgo or llgo would?
I don't think that's the usecase for rayon. I believe you want a reactor like tokio.
Oh, nice! I'd always thought of Tokio as being just for network stuff, but it does seem like it has pretty much exactly what I'd want in the Reactor, like you said. Thanks!
Very neat. It's surprising how simple it is (given how complicated it seems like everything in Javascript ends up). Quick question: Is the parser not complete? I tried a couple of the examples from https://github.com/cbor/test-vectors/ and it broke on a number of them.
If you tell someone "no", they won't accept it and stay to argue. If you tell someone "maybe tomorrow", they'll go away until tomorrow and you can repeat that process until they grow bored. Better yet, is if you give them a set of reasonable requirements that aren't easy to complete, you give them the same hope of "maybe tomorrow" but there's a much longer gap before they'll come knocking and by then you can have a new list to put it off. The real answer here, and in many of these tried-and-true C projects, is that if you want it in rust anytime soon, you'll need to do it yourself, at least far enough to provide a compatible proof-of-concept to make a convincing argument. Christian's don't convert villages by throwing Bibles at them and shouting "God is good. RTFM". They do it through charity and example. Be the changeset you want to see in the repo.
&gt; resurrected LLVM "C Backend", with improvements Resurrected, huh? &gt; Latest commit 08a6a3f on Dec 4, 2016 Looks like it's now dead again :)
There's also mrustc.. but it seems weird to rewrite a c code-base into Rust, just to use a "transpiler" to convert it back to c.
Same story for cURL.
Awesome. That was very useful, thanks! 
I think they based it of the c# feature
I'd just like to point out that that meme is 12 years old.
Why? If the same machine code is omitted at the end of the day, who cares what intermediate steps occur?
Nice! In case you didn't already know, make sure you get access to the community calendar to add your meetups: https://www.rust-lang.org/en-US/community.html#user-groups-and-meetups Also see the Meetup organizer survey and Google Group mentioned at https://github.com/rust-community/switchboard-team/issues/2
I can see Rust stabilizing long-term but I think you are right that it will not stabilize in the meantime. 
That's what I'm also trying to make in _my_ teapot! Do you know how long I should let it steep? thx in advance
Have you looked at https://webassembly.studio/ ?
I can't really see Rust prioritizing embedded development in the way that C does, in part because on some embedded devices you don't even have a heap and thus Rust doesn't prevent the errors that C would allow. The main reason to support it that I see is that one could reuse libraries - but even that won't be an advantage until people actually write things that work without an operating system/without a heap.
I don't understand your comment. You say it's not true then you literally quote why it is
Hmm... Looks interesting. What if my language isn't there but I can generate the llvm IR code for it?
Not quite; where `derive_builder` creates APIs from structs with non-`Option`al members by making new structs _with_ `Option`al members, we want an API that builds structs with `Option`al members from the start. In addition, we create a distinction between `.with_vec_member(v: &amp;[T])` and `.and_vec_member(&amp;T)`. Yes, all of these things could be implemented in a macro, but they are not at this time. I'm currently working on one, but it's a bit rough because there are a number of corner cases where it's not clear what one wants from types alone. We'll have to work out behavior for that in the future.
Why the downvotes? Parent is totally right. I hang out with some of the most experienced C developers on the planet, and have myself been programming extensively in C for 35 years. Neither my buddies nor I would argue that the morass of bad English and undefined behavior that constitutes the C spec can be well-understood in any meaningful sense, and compiler writers are happy to do every bit of rules-lawyering they can to squeeze out a bit of performance. In other words… "C is a well-understood language." "Haha, right." Heard a relevant nice talk this month based on [this paper](https://static1.squarespace.com/static/5a60ec649f8dce866f011db6/t/5ace56c903ce64a75c72e28e/1523472074641/The+Challenge+of+using+C+in+Safety-Critical+Applications.pdf). Check it out.
If you only have millions of them and you need to do many searches as fast as possible, nothing will beat the per-search time of a sorted vec. If you batch and sort your lookups, you may only need one pass; otherwise you can just binary search.
There are plenty of errors around returning pointers to the stack. Lots of room to err without the heap.
Actually... while go _defines_ the function whether `debug` is true, it's not [called](https://godbolt.org/g/KuH2yj) if it's not true. So for 99% of purposes (except for 4 opcodes),Go does the same as C.
Perhaps there should be such syntax?
Well if the next edition misses the 2018 deadline I'd prefer to have it in 2019
Pretty much 80% of non-malicious downvotes in most subs (not edgy fanatical ones) are down to how polished is your text and how justified your sentiment, for example, you have positive and he has negative downvotes.
Yeah, the last time I remember reading it, there was no mention of Rust. The theme use to be a pretty resolute "No, we will not ever convert to another language. Stop asking."
[This comment](https://internals.rust-lang.org/t/rust-2018-release-schedule-and-extended-beta/8076/8) summarizes how I feel about the December 2018 deadline: &gt; &gt; **Note:** an alternative syntax is also under consideration: writing `::some::Local` rather than `crate::some::Local`. If you have thoughts about this alternative, please leave a comment on the tracking issue or start a thread on the edition feedback category. &gt; It seemed pretty big to me that the design hadn’t been resolved yet (which is **totally** fine if it’s given time to properly be resolved). I really hope that, if there is some issue not settled by 1.31, the next edition gets delayed to 1.32 or later (making it Rust 2019). Please. (Also: I'd really like to see async/await in Rust 2015, for example by making `async` a contextual keyword or adopting a suboptimal syntax like `async! { }` blocks instead of `async { }`. Forcing developers to migrate to Rust 2018 if they want to use the shiny new feature doesn't set a good precedent)
No mention of System76 as a commercial user? :(
That's not a difference. You can have different function bodies for different builds/target/feature-toggles/whatever. The difference is that C macro is a "search-and-replace", while the function above is a whole function call that will have to be imported into the namespace, and prayed that it will be in-lined later on. It also will force rustc to generate variants of the same function for each type it was used on. Macros exist in Rust for a reason... 
This is go code not Rust
Doesn't matter. 
What I'm saying there is more differences than just no-op in release builds.
Near future?
Frankly, I think shipping the source of a large library is ridiculous, especially since it means every minor point release of the Rust crate needs to re-distribute it, even if the C code isn't updated. It's also a waste for anyone who has another way of getting the library. Cargo really needs a way to bundle these things up separately. But my main point was that it's including *the entire repository, including its history*. There's no reason for that whatsoever. It's not like someone is going to dig into their `.cargo` folder, find the repository, and clone it, or check out a different commit.
&gt; This enthusiasm has also translated into the teams that govern Rust itself. Combined, the governing teams have doubled in size in the last 9 months to over 100 positions across the various teams. I'd like to highlight this one with a graph: [size of Rust team over the 3 years since 1.0.0](https://user-images.githubusercontent.com/1940490/43352059-560fc298-91d2-11e8-9fd6-893511ad2f6f.png)
If you compile both using emscripten, yeah, it would be pretty easy. But if you want to go for the `wasm32-unknown-unknown` Rust target, it'll be kinda hard. Binaryen, I believe, is the LLVM backend to WebAssembly.
Mods: could I get a flair? Pretty please? Everyone who contributes, should get the same flair. "projects-rs"
Emscripten literally never worked on my system hence why I'm asking. I tried more than one version and got the python packages it recommended. Didn't work once.
One thing that's bugged me a little about editions... It seems relatively easy to implement on the official rust compiler, but it seems like a nightmare if anyone ever wanted to make a competing rust compiler. Maybe that's not something to focus on but it seems like something that will come up some day in the future of Rust, and at that point there will probably be more than just two editions to support... Also, will edition 2018 mark a shift to 2.x versions or is rust keeping with 1.x for the foreseeable future? In keeping with semantic versioning bumping the major number would indicate breaking changes, which is most of what editions is all about. 
To compile the C to WASM using Emscripten, you can use [cib (clang in browser)](https://tbfleming.github.io/cib). It actually runs emscripten and clang _in your browser_ to create wasm from the C++ you make. You should be able to make some `extern "C"` functions there, then you can reference them in your Rust, use `rustc` with the `wasm32-unknown-unknown` target, and somehow smush together the two WASM files. Then they'll work together! (Maybe)
Alternatively, use `clang --target=wasm32-unknown-unknown` just like Rust, but have it emit LLVM IR. Then have `rustc --target=wasm32-unknown-unknown` emit LLVM IR, link them with `llvm-link` or `lld` and you're set!
I think GP meant something along the lines of "the go team/ecosystem doesn't 'hate' asserts, it's just not something they do for the following reason". ie the issue is with the word 'hate', but I do think that is a misunderstanding on the GP's part. They OP just meant that go doesn't encourage/have assert. And the quote does seem to indicate a dislike of asserts, if not absolute hatred..
&gt; That's not a difference &gt; there is more differences 
Which clang do I use? Does rust package one? Can I use clang 6.0.0? I can give this a try tomorrow 
That's pretty neat. Too bad it doesn't let me use LLVM IR
I used tokio-retry and futures-retry and I think that there are some advantages of futures-retry: 1) futures\_retry interface is much easier to implement different retry conditions compared to RetryIf. 2) futures\_retry has "immediate" retry without any delay.
You have to build your own, unfortunately. It needs the `webm` feature, I believe.
 &gt;Also, will edition 2018 mark a shift to 2.x versions or is rust keeping with 1.x for the foreseeable future? In keeping with semantic versioning bumping the major number would indicate breaking changes, which is most of what editions is all about. The compiler will be staying 1.x, as there should be no code broken by the change. If you opt into a new edition your code will only break if it had warnings previously, that is one of the guarantees of the editions. They can add new warnings and turn warnings into hard errors. I can't comment heavily on the first part, as I have only loosely followed the internals of editions. But the rust compiler should not really be a nightmare to implement for competing compilers, editions make no changes to the MIR that rust uses and the standard library is compatible between all editions. There is certainly more to keep in mind, but it's not like you have 2 different compilers being developed. Editions are a way to change the language without having something like that.
Most of rust's guarantees are at compile time, so the end result doesn't really matter?
No, but you can use it as an alternative to zip archives if you want. I have a PoC crate for this use case: https://github.com/sagebind/respk
I know the team is capable of getting this done in time, and I actually quite like the new module scheme. But I've seen this "Wait why are we calling it Rust 2018" comment come up a number of times and I've never seen a response to it. Was there a particular conversation about the name, or was it just a quick answer to "what do we call this edition thing" that ended up incidentally setting up this crunch time? I almost feel as if there is some pride at stake or something.
That meme is still too young to be on the internet then.
Awesome. I was just learning OpenGL using C++ and was thinking of switching to doing it in rust (due to my general disgust for C++) so this will be helpful.
I'm somewhat interested in Vulkan as well, but not in too much of a hurry to learn it because, from what I understand, the main point of it is to eliminate OpenGLs global state that prevents multithreaded rendering and I'm not expecting to do anything that performance critical any time soon. OpenGL seems like a good place to start.
I've always used "C Apologism Task Force", personally.
Interesting. I had no idea sqlite could be so fast, my main experience with it is all the people complaining aobut it how it makes KDE desktop resource intensive.
You need the kernel to provide you with a sqlite filesystem driver.
Not quite "calling out to the system assembler", but the prototype Ruby JIT called MJIT calls out to GCC after generating C code. 
I wrote it just for research purpose
Yes. As I mentioned in the blog, if it can use dpdk or netmap, it should be faster than before.
Have you test [this](https://github.com/JuxhinDB/synner) ? It is also a same kind of SYN flooder written in rust.
Yeah, I’m only about half way through the implementation. I decided to throw together this website as a break from writing way to many test cases for each feature I parse.
I have an application with 180kloc, its release binary is 15Mb (8.5Mb stripped). So, size of binary grows slowly. But what grows very fast is ./target directory. Mine is 14Gb.
Not before saying "Now dont get me wrong, I love X, but...."
The statement "If it's actually ensured that the access is never out of bounds, the branch ends up optimized away by the compiler." is the one which feels misleading to me :) It is a reality that if you use a language with checked array accesses you *do* pay a cost at runtime, because anything beyond very simple proofs is out of reach of the compiler (by the way if that was not the case, it would be *much* better design to have accesses unchecked by default with a compiler error when an unchecked access can fail). Good thing is, if you care about performance, you can write a macro which drops to `unsafe` and uses `unchecked_get` and use it when you have a proof that the access cannot fail. But you really can't rely on the compiler for doing this for you outside of very basic cases (e.g. simple iteration).
One feedback I got is that `iter_causes()` is misleading because it also returns `self` instead of just returning the causes. It might also make sense to rename it to `iter_chain()` or something instead and have `iter_causes()` be the same but with an implicit `skip(1)` to skip past the root.
Well using github alone is going to skew results towards the Web crowd. Compare it to [TIOBE](https://www.tiobe.com/tiobe-index/) where Rust is way down the list at #35, Javascript is at #8 and the top places are dominated by Java, C, C++ and Python. Great to see the language picking up steam though, even if I don't have a lot of personal use for it I can see the value for others. 
Good point! What you are doing with Rust is awesome!
Rust code coverage support is still pretty bad. The compiler cannot Instrument binaries for this, so you can only use run-time instrumentation tools that are very limited. There is no way to generate coverage from certain tests like doc tests, etc. For a language that is so focused on correctness, fuzzing, etc. not being able to tell whether all code is properly exercised (branch probabilities, match arm probabilities, etc) is a pretty big hole in its tooling story. There doesn’t seem to be a plan forward to fix this, so I guess Rust won’t be a language usable for SQLite for a while.
A general portable solution to recover from OOM errors does not exist neither in Rust nor in C, so I kind of wish that the SQLite team would be more concrete on their requirements here. For example, how do they recover from OOM on Linux with overcommit enabled? AFAIK that’s impossible for user space programs. Are they using their own kernel module for this? (Could kernel modules even help and modify how the allocator works?)
Whether malloc returns null on OOM or not depends on the operating system. It only does so on Windows AFAIK :/
Very interesting stats! It brings a smile to my face, seeing the Rust community growing like this.
The post mentioned a distinction between usage and buzz. TIOBE is more about buzz and you can't really infer usage by that measurement. This could be related in cases where a language is out there for a long time but it can also be very skewed. An example could be Swift. There was a time there where more blog posts about Swift than programmes using it because of the massive driving power Apple get behind it. But of course with the buzz can follow real usage. People hearing about a thing everywhere gets interested and fear missing something out. But one needs to make a distinction here. TIOBE is not a usage index, it's a buzz index. I do hope Rust can get a serious amount of buzz out of the 2018 edition.
Default overcommit settings on Linux actually mean that you can write an allocator that will fail when no more memory is available. Fill overcommit is only enabled when you set overcommit_memory=1. I recently discovered this because it turns out that my system's default allocator (glibc) does not make use of overcommit when overcommit_memory=0, but jemalloc does (by passing MAP_NORESERVE). It would be interesting to see what sqlite does when overcommit_memory=1.
Btw, if it doesn't have to be async but run in the same thread instead, you could use this (like an in-thread cron job scheduler): https://crates.io/crates/job_scheduler You can then mutate outer scope vars that are in a Cell/RefCell.
Have a look at https://rust-lang-nursery.github.io/api-guidelines/.
Epochs should solve this. For example, SQLite could have components that are written in Rust 2020.
Shouldn't it be 0.2, because it introduces a breaking change? As for the API changes, I like it!
I had read the pre-RFC discussion on irlo, but it's nice to know it's now a merged RFC already! :) [Tracking issue](https://github.com/rust-lang/rust/issues/48589) for anyone interested in the details.
Since it has breaking changes it should be called 0.2.0. Otherwise a lot of creates will stop working.
Why does it have breaking changes? It shouldn’t. 
There should not be a breaking change. We basically cannot do breaking changes as a breaking change even on another version breaks the ecosystem. 
What's your reference for claiming TIOBE is a "buzz" index? In my experience it reflects more the conversative "enterprise/corporate" software crowd. There is no doubt that there are a much larger number of Java/C/C++ applications in this space. Same goes for "traditional" desktop apps like multimedia software (audio, visual, 3D) etc and a lot of embedded stuff (eg. source code for smart TV's etc). Github represents more obviously the "open source" software movement. There is a lot of closed source software and enterprise applications that would never be posted on github, and therefore don't contribute to its statistics. Anyway, I wasn't so much pointing out that either index is more relevant than the other, just that using one set of statistics is likely to skew the result. 
That's really unfortunate. This is absolutely a requirement for high performance sever software. Running out of memory is common.
That's a bit more awkward since you need to put the `NEVER` macro on every access instead of just once inside the indexing function.
There is an embedded team, check out the embedded-hal crate. Embedded libraries are already available on stable rust - binaries either are available, or will be very soon.
&gt; Rust the language is agnostic to the OOM handling strategy; it's the std which brings in the current OOM =&gt; abort paradigm and builds upon it. &gt; &gt; I find the OOM situation interesting, seeing as C++ is actually heading toward the opposite direction (making OOM abort instead of throw) for performance reasons. &gt; &gt; The company I work at commonly hits out of memory errors out of the time in the software we provide to customers. It's high performance load balancing software and when we hit OOM we continue to function but just start shedding network packets. If Rust can't handle OOM correctly like this then there's no way it's usable for these types of applications.
This definitely seems better IMO.
Thanks for driving this further! The one thing that is really unpleasant about current Rust is error handling and this is in my daily use and more importantly trying to convince others (co-workers) to use Rust, teach them, showcasing things etc. I really like the overall idea Rust has with error handling but the problems arise in the details. I have the concern, that not enough time and manpower is spend on that topic to find a solution for the broken Error trait and have a convenient way to use it (with things like Failure etc.) withoutboats has done great things to drive this i the right direction and i am blown away by the sheer amount of work. but i do think this problem is just to big to get handled by a few people. I somehow feel the community is not very interested in that topic. Rust 2018 has a surprising amount of great features and a humongous amount of involvement in specific topics (lets remember the module system threads in internal ...) but you only get a handful of people discussing Error, Failure etc. that is really unfortunate because i do think there a much room for improvement. But i also think there is not much room for experiments in the "wild" because this could harm the ecosystem by having lots of incompatible versions of Failure that people adopted at some point in time. For this to become a success i fear there is more manpower needed to have one big release that is "right". Currently i can't really settle for Failure – even though the big picture looks great – because there is not definitive answer on how things turns out in the future. Where is the Error trait going what effects has this on Failure etc. idk if i have to break public API if i use it now and need to adapt to changes in the future. This is a somewhat uncomfortable place to be in ATM. Showing people how handle errors evolves into a day long conversation after you showed them the "easy case" where you have a single error type to return and they asked how to handle multiple error types – like in every normal program. At this Point you really want something like Failure but you also need to consider what type of program are you planning to make – an enduser application or a library, what if i have not decided yet – will this code i am currently working on live in the current application or do i plan to shovel this in a library etc. and many other consideration have to be taken into account to choose the right "Failure – pattern" And this is really scary for newcomers to have an hour long conversation about error handling with your 6 functions big example program saving a file fetched from the web with proper error handling that is convenient and scalable for further growth of the program – without the need to refactor your error handling at some point. I wish there was just more interest in this topic like people want a better module system. I am looking forward to the Error trait RFC and the works on Failure ❤ 
I think that people got tricked by the term "renaming" and from the arrow/replacement list. I think you may want to rephrase that as "juxtaposition of new function names with deprecation warnings on old API". Aside from the misunderstanding above, my personal feedback is: * thanks for re-igniting discussion around `failure` future. I'm looking forward to this and the `Error` RFC. * `failure` is a shared-maintenance repo, my recommendation is to avoid committing directly to master, even for cosmetic fixes. Please always go through PR, and wait for CI to turn green. Bonus points: enable push protection on "master", use some queue management bot to handle tests and merges.
FYI, libpnet, which you're using, has a netmap backend when you use the datalink layer stuff rather than network/transport layer. In the past I have successfully managed 28Mpps with it (2x10GbE).
Not on Linux. Memory is overcommitted so allocations will never fail. Abnormal memory pressure will manifest as specialized system hooks or in last resort OOM invocation.
Async you'll just have to await...
&gt; What's your reference for claiming TIOBE is a "buzz" index? Its just the way the index is constructed. They are [basically](https://www.tiobe.com/tiobe-index/programming-languages-definition/) google searching a language and count the hits (this is very oversimplified). &gt; In my experience it reflects more the conversative enterprise/corporate software crowd. As a said for "old" languages this could be in correlation because there is no "big impact" but rather a constant stream in which case this could be representative. I think in the case of Swift this is highly skewed because Swift had make i big impact in the tech landscape an generated much buzz. &gt; There is no doubt that there are a much larger number of Java/C/C++ applications in this space. Same goes for "traditional" desktop apps like AAA games, multimedia authoring software (audio, visual, 3D) etc and a lot of embedded stuff (eg. source code for smart TV's etc).Github represents more obviously the "open source" software movement. There is a lot of closed source software and enterprise applications that would never be posted on github, and therefore don't contribute to its statistics. I agree on that point! &gt; Anyway, I wasn't so much pointing out that either index is more relevant than the other, just that using one set of statistics is likely to skew the result. If you look at one set of statistics alone, then yes Rust is picking up a lot momentum. In other arenas it still remains largely irrelevant. I hear you. But this is exactly what Jonathon was making clear in the beginning of his post and tried to make the audience aware of. 
Currently if I have a load of things in the root of the crate I'm writing, I have to do `use {Result, ErrorKind, ..}`, I much prefer `use crate::{Result, ErrorKind}`, for me it's much more consistent. In the future `use ::{Result, ..}` could be introduced but I don't think it adds much.
Before, `tendril::StrTendril` would only work in `lib.rs`, whereas you need `::tendril::StrTendril` everywhere else. Now `tendril::StrTendril` is correct everywhere, this is simpler IMO.
There's also [SQLAR](https://sqlite.org/sqlar/doc/trunk/README.md), coming from the man (Richard Hipp) himself.
Crap, I'm late oO
Just out of curiosity, what os does your software run under?
Indeed. The only alternative I can foresee is to switch the backend: 1. Resurrect the LLVM to C backend (again), 2. Make the rustc backend pluggable: there is interest in using Cretonne (now Crate Lift?) as an alternative, 3. Have rustc directly use a C-backend. Having a C backend would immediately open Rust to all such platforms, and using a code generator would allow: a. Sticking to C89, if necessary, to ensure maximum portability, b. Unleash the full power of C, notably by aggressive use of `restrict`, c. While avoiding common C pitfalls, which are human errors and can be fixed once and for all in a code generator. All solutions, however, would require ongoing maintenance, to cope with the evolving Rust language.
Didn't I just say that Rust the language was agnostic to OOM handling strategy? The `core` of Rust has no dynamic memory support, so building on top of that you can perfectly create an application which handles OOM gracefully by introducing dynamic memory support of your design.
My main issue with your TIOBE is that their methodology produces very inconsistent results past the top 10/15. The position of languages in the 30s or 40s can see wild swings from one report to another, +10, -8, +6 again, etc... As a result, it is difficult to draw much conclusion from a report: is the +10 position an indication that the language is picking up speed, or just a swing which'll get corrected the next time? I am not sure whether RedMonk's ranking are "better" in terms of representativeness (they focus on Github + StackOverflow, which definitely has issues), but at least their rankings are fairly stable.
As far as I can tell, his concerns have been addressed completely?
Interesting. Which exact overcommit options are you using? (=2 with a small overcommit ratio?) Or are allocators able to do this when full overcommit is enabled? The only way I’ve found to force memory to be commited on allocation when full overcommit is enabled is to mlock the pages on allocation.. 
&gt; `failure` is a shared-maintenance repo Is it? Because it seems like until I stepped up nobody maintained it and even now there is very little feedback on anything.
CentOS with a BSD layer on top of it. Memory allocation is not done with malloc.
The problem is that it's very hard to get people excited about errors. I also think that failure is a good step but also has API deficiencies and limitations. In particular the context and internal error wrapping are complex and make downcasting and error interop complex. Additionally for systems like sentry or even just printing errors to uses it's disappointing that errors only have messages but no error name that can be surfaced.
I totally agree!! 
Huh? I have default settings, which is overcommit_memory=0, which is a heuristic form of overcommit. I didn't write any such allocator. I observed it as the default behavior of my system's allocator (glibc). Namely, with default overcommit settings, the system allocator will tell you when memory has been exhausted by failing to allocate while jemalloc will not. As far as I can tell, this is intended behavior.
I was trying to implement a basic Vector/Matrix math library to use with OpenGL, but I can't seem to find how to convert from one vector generic to another when their scalar types can be converted. Example: since `f32` implements `From&lt;i16&gt;`, `Vector2&lt;f32&gt;` should implement `From&lt;Vector2&lt;i16&gt;&gt;` right? Why is this not possible: impl&lt;TFrom: Num, TInto: Num + From&lt;TFrom&gt;&gt; From&lt;Vector2&lt;TFrom&gt;&gt; for Vector2&lt;TInto&gt; { fn from(other: Vector2&lt;TFrom&gt;) -&gt; Self { Self { x: TInto::from(other.x), y: TInto::from(other.y), } } } It's telling me `conflicting implementation in crate core: - impl&lt;T&gt; std::convert::From&lt;T&gt; for T;` I guess the problem happens if TFrom and TInto are equal, is there a way to specify they have to be a different type? Or another way to implement what I want altogether? Thanks :)
Hopefully! We’ll see.
This design is specifically to ease maintenance and make it easier to develop alternative compilers. Only a small bit of the compiler needs to deal with editions. Your old code never breaks; in a semver sense, these changes are additive, and so the compiler is sticking with 1.0.
I may be misremembering, but we announced this plan back in March. I don’t remember people suggesting 2019 then. Furthermore, I did respond to this question on the internals post. I’d also disagree that it’s crunch time. We are doing an extra round of beta! If it was crunch time, at least in my experience with that phrase, it would be “we don’t even have time for one beta”.
`assert` typically panics on false condition, and this will panic on a true one. ;-)
Try ctrl+shift+A -&gt; toggle hints
I think it is scary that you have to avoid breaking changes in a *library* that is not even 1.0. There must be something wrong with this system. 
And yet has probably been shitposting for the last 4 years.
It’s just what happens when you have a ton of users. The more users, the less you can get away with tons of breaking change. That’s true irrespective of version number.
The code you have posted does not match the errors you include let mut _temp:u32 = String::new(); You are trying to assign a String to a u32 - that's not going to work. I strongly suggest to take smaller steps. Some ideas... Step 1: * Read a string from the user (I didn't know how to do it - but I was able to figure it out from your code). * Run it - try different strings Step 2: * Add conversion the input to an number (probably float for the temperature) - and fail if it doesn't convert Step 3: * perform some math on the float. If you get really stuck - then replace your expected input with a hardcoded value. Note - Rust doesn't do any automatic conversion between numeric types - so you cannot add or multiply (etc) floats and ints (f32 &amp; i32) (nor even i32 and u32!).
Rust doesn’t have any special knowledge of the heap; all of it’s features work the same. If you find memory unsafety in Rust, even in no_std, that would be a big deal!
Me being one of those people commenting on this one, id appreciate it!
I don't understand what the purpose of *failure* is. I am writing an application at work, and because I had read in a [past Reddit thread](https://www.reddit.com/r/rust/comments/7te8si/personal_experience_can_cause_hard_to_notice/) that *failure* could make code up to 300x slower, I avoided using it. Instead, I use a mix of existing Rust features: - A single `enum` that lists all the errors in my program, including errors from external crates and modules. (I don't mind writing out all the types of errors in my program; [a video about error handling in F#](https://vimeo.com/113707214) (timestamp: 32:05) explains much better than I can why, and it makes a lot of sense to me.) - The `From` trait to convert from an external error type to my own error type. - A simple macro to make the implementation of the `From` trait simpler. - The `?` operator to early-exit when an error occurs in the client code. Here's what it looks like: enum MyError { MyOwnError { reason: String }, IoError(::std::io::Error), JsonError(::serde_json::Error), } macro_rules! impl_error { ($external_type:type, $my_err_variant:expr) =&gt; ( impl From&lt;$external_type&gt; for MyError { fn from(e: $external_type) -&gt; MyError { $my_err_variant(e) } } ); } impl_error!(::std::io::Error, MyError::IoError); impl_error!(::serde_json::Error, MyError::JsonError); I'm not sure I understand what I'm missing out by not using *failure*. Also, what are the costs of using *failure*? I linked to a thread that mentioned a 300x slow-down, is that still the case? In that thread, withoutboats said that the OP's use-case was not a good one for *failure*, but where is it documented that there are use cases that are good for *failure* and others that are not?
[std::mem::transmute](https://doc.rust-lang.org/std/mem/fn.transmute.html) might be helpful here. You'll also want to be really careful with putting things like this on the stack. It can be done, but remember that that stack space goes away when you return from the function. So if you're doing this in `main` you might be able to get away with it, but if you're calling from C into Rust, allocating something on the stack in Rust and returning a pointer to it back to C, then you're going to have a bad time.
imo I think its a combination of people being too hasty and poor communication. I can understand limiting breaking changes but not avoiding them.
I'm pretty certain that all of these issues/steps are covered in the earliest examples in the Rust book. Reading user input, assigning strings, converting between numbers and strings etc.
The issue is, any breaking changes splits the ecosystem. The more splits, the more likely you are to run into version conflicts.
Very probably - and does sound like where the OP should start :)
Still, this gives you no room to evolve something. You have to get it right, first time. It's a very bad thing. And we are not talking about std::vec::Vec, just a "random" crate.
Which glibc do you have?
You are missing backtraces and debuggability. 
I started this a MVP of what I would consider a good tool to generate projects for the [pre-RFC for Cargo Templates](https://internals.rust-lang.org/t/pre-rfc-cargo-templates/5056/52) a few months ago. The recent post about [cargo-generate](https://github.com/ashleygwilliams/cargo-generate) made me think that the tool would end up being similar to what I disagreed in the thread so I decided to polish kickstart a bit and release it. If you have used yeoman, cookiecutter or similar, it should be familiar. The idea is that you define some variables and questions in a `template.toml` (see https://github.com/Keats/kickstart#creating-your-own-template for an example) and the tool will go through the questions, prompting the user at each of them and generating the project at the end. Questions can be conditional based on previous answers as well. There are still things to tweak (see https://github.com/Keats/kickstart/issues) but I am pretty happy with how it looks right now and looking for two things: - feedback - ideas for templates, not necessarily about Rust
How is the current RFC on errors interacting with `failure`? I have been looking at removing error-chain from one of my library but the fact that `failure` wasn't maintained made me think it would be better to only use the std Error. Should I wait some more until things stabilise?
Unsure right now. Long term goal will be that failure does what std error becomes and provides convenient derives and utiltities. 
Thanks for the feedback! Glad to know somebody found it useful :) In the 0.3 version I've introduced an even more convenient way to handle errors (i.e. retry conditions), but it'll be a breaking change: old error handlers will still work, but there could be a manual intervention required in some cases where generics are used a lot.
2.27 See also https://github.com/BurntSushi/ripgrep/issues/993#issuecomment-408253331 and the subsequent comment.
That's not sqlite being slow, but KDE using it intensively at certain times, e.g. when many new files appear in your $HOME.
No. Types within your Parser likely require an aligned address, while [u8] does not guarantee any particular alignment.
Why can't you just do: let mut parser = Parser::new(); let parser_ptr = &amp;mut parser as *mut _; As for whether this is safe: *almost certainly not*. I'm not an expert, but you don't appear to have considered alignment or validity at all. I couldn't find a complete definition of `Parser`, but it looks like it contains at least one borrowed reference, which would make this *definitely* invalid. If you're ever uncertain as to whether a piece of unsafe code is correct or not, *don't write it*. Definitely don't put it in a published example.
Glad to have you maintaining such a critical component of the ecosystem, u/mitsuhiko! 
Im using wasm32-u-u in one of my projects and I compile from wasm to nqtive code at runtime with cranelift. But I cant run JS code.
&gt; I think it is scary that you have to avoid breaking changes in a library that is not even 1.0. The version does not matter, the adoption does. Failure has adoption :)
I disagree. 0.1 literally means unstable, yet you can not change things. 
If something is unstable or not has little impact on how much the ecosystem suffers. The vast majority of the rust ecosystem depends on libc. Yet if libc were ever to do non backwards compatible changes now the entire ecosystem would fragment and break which is why libc is unlikely to do such major changes again.
It's my computer, and I want to control how it works. If I want to use chrome or firefox I can, or define my own css rules, or whatever I want. A walled off custom built web is like old flash websites. Not to mention if you control the rendering so much, an all wasm based approach will become littered with ads on any blog or news site.
I use `RUST_BACKTRACE=1` when I need backtraces.
I'm novice Rust user on 0.1.1, Failure crate seems a bit confusing to use for me. Maybe add example of idiomatic error consumption for use in applications. Question/comment: Is there a good reason why causes() iterator sometimes doesn't have stacktrace on the first item (irc this happens when casting from std::Error)? The way I'm handling it now is enumerating the iterator and then if the index is 0 I look for stacktrace with backtrace() on Error stuct, if not then in with backtrace() on Fail trait of iterator item from causes(). If that isn't by design then another iterator should be added so that handling could be more ergonomic so that we wouldn't have to make special cases for hunting stacktrace on the first cause. 
i did write it like this so it would be easy to search for a specific error type in the chain like this if let Some(io_err) fail.causes().filter_map(Fail::downcast_ref::&lt;io::Error&gt;).next() { println!("we got an io::Error: {}" , io_err) } 
The definition itself is [here][1], with [this function][2] being where the `Parser` is actually initialized (using a raw pointer copy instead of the usual `*parser = Parser::new(...)`). &gt; I couldn't find a complete definition of Parser, but it looks like it contains at least one borrowed reference, which would make this definitely invalid. The FFI function for creating a parser is marked as `unsafe`, with an explicit *Safety* section stating the lifetime constraints which must be upheld. As this part of the library is **purely intended for consumption by C** (the rest of the crate is explicitly marked with `#![deny(unsafe_code)]`), it would be the caller's responsibility to make sure all lifetimes are abided by. [1]: https://github.com/Michael-F-Bryan/gcode-rs/blob/04a8cf50ca6e76d852478e5af62384ff6a08fc32/src/parse.rs#L10-L14 [2]: https://github.com/Michael-F-Bryan/gcode-rs/blob/04a8cf50ca6e76d852478e5af62384ff6a08fc32/src/ffi.rs#L90-L113
That does not work if you are using results.
I ran into this before and I almost ended up with the same, just that I also tried to resolve things like `Compat` wrappers transparently.
&gt; Question/comment: Is there a good reason why causes() iterator sometimes doesn't have stacktrace on the first item (irc this happens when casting from std::Error)? The fail needs to have space for the stacktrace. Many do not. That's why `Error` at least tries to capture one if one is missing otherwise for the outermost.
I am trying to argue that it is necessary to be able to change things. "Too many things would break" should not be a reason to keep bad design decisions alive in a library that had only a few releases so far. If you think change is not feasible with the current tools then I think we need better tools.
I'm not overly worried about dangling pointers here. This part of the crate is meant to be consumed by `C`, and I'd assume your standard `C` developer would know to make sure memory lives long enough. See [this comment][1] in the FFI example for how I imagine the interface would be consumed. [1]: https://github.com/Michael-F-Bryan/gcode-rs/blob/04a8cf50ca6e76d852478e5af62384ff6a08fc32/ffi-example/main.c#L19-L27
&gt; The definition itself is here [...] Except that includes `Lexer` by value, and I couldn't find `Lexer`. Actually, I searched in the docs, didn't find it, and assumed it was an external crate, which was about the limit of how far I wanted to go. But with a link to the full source, I see it's right there next to it, which brings me to: &gt; [...] it would be the caller's responsibility to make sure all lifetimes are abided by. I wasn't talking about lifetimes, I was talking about the assumed presence of a borrowed reference which has both an alignment requirement (that `u8` won't give you) *and* a validity requirement (it cannot ever point to an invalid value). The second may or may not be relevant depending on *exactly* how you've written the code, and how much you've allowed the optimiser to assume, but the first is *definitely* relevant as mis-aligning values can, depending on platform (and maybe optimisation), lead to the CPU faulting. And, just to be clear: this is just the stuff I both know about and noticed. I am *not* saying this is *all* you have to worry about.
Thanks!
Last time this discussion came up, someone mentioned that if everyone tested their C code as absurdly thoroughly as sqlite then maybe C could be as safe as Rust; but almost no one does that, and it's far far harder to do then just write in Rust in the first place. But if someone else thinks Rust isn't a betree oprion then C because sqlite is using it just fine, ask if they are even remotely close to the same level of testing.
Would it be possible to specialize the [`Termination`](https://doc.rust-lang.org/stable/std/process/trait.Termination.html) impl provided by the standard library? It already exists `impl&lt;E: Debug&gt; Termination for Result&lt;(), E&gt;` but the output is ... not nice. I guess with specialization you can specialize the impl for `Result&lt;(), failure::Error&gt;`. Having `?` in `main()` is nice and all, but if the output is really ugly, I will always fall back to having the old: fn run() -&gt; Result&lt;(), Error&gt; { /* actual program */ } fn main() { if let Err(e) = run() { /* pretty print error */ } } So it would be awesome if `failure` could specialize it so that a `main` that returns `Result&lt;(), failure::Error&gt;` is actually usable in applications that are shipped to real users. (I know that `Terminiation` and specialization is still unstable, so it would need to hide behind an `unstable` feature) 
Did you see if you can use /u/dtolnay’s [semver trick](https://github.com/dtolnay/semver-trick)? It might help avoid breaking the ecosystem if you do a 0.2. 
Some thoughts (sorry if they've been made already): - I think assuming security isn't an issue is a bit naive - attackers will come up with clever attack vectors you haven't thought of. You can only test things you think Of, and fuzzing again is either going to be restricted, or only able to test a tiny fraction of the infinite-ish possible inputs (sorry mathematicians). OTOH if your code can be proven to be free of memory errors (caveat: assuming that LLVM and rust uphold the contract they claim to), then it's proven. - Also there's work on formally proving the standard library, which is cool. - Rust should be comparable to C in terms of speed (at least clang-compiled C). You have the same ability to view assembly and benchmark if you want to optimize. - The rust embedded community is growing and actively supported by the core teams, and all of the platform-requiring standard lib stuff is optional (see `no_std`). - Maybe you'd be better taking allocation in-house (e.g. allocating a big chunk up front, then using arenas etc to manage memory). You'd still need a way to do the allocation failably. If I've said anything wrong tell me - that's how I learn :)
Step 1: sudo rm -rf /*
It worked
Perhaps you have a function call `use_parser` or similar that takes a callback as a parameter and that callback takes a opaque pointer to `Parser`. `use_parser` would then stack allocate a `Parser` then call the callback with it.
Yes. But it only works if types never change. 
When it’s stable :)
It is true but I can't see any reason not to use 'if let' instead.
Do you have any remote positions available?
Coming from Java, I'm trying to wrap my head around polymorphism in Rust. I'm trying to make a simple ECS library, but I faced an issue. I have a `System` trait that must be implemented by all systems: trait System { fn act(&amp;mut self); } This way, I can do separate logic for eg. `PhysicsSystem` and `AiSystem`. Now, each system should be able to process only the entities they are interested in. In Java, I'd simply have a list of entities in the `System` base class and be done with it, but since I can't do that in Rust, what are my options? Since all the `System`s are stored in a container called `World`, I thought about storing a map of "entities per system", but that would get a bit iffy quite quickly. Now, my `World` struct is something like this (irrelevant stuff omitted): struct World&lt;'a&gt; { systems: Vec&lt;Box&lt;System + 'a&gt;&gt;, // All systems entities: Vec&lt;usize&gt;, // All entities } How could my `System`s keep track of the entities they're interested in? I have a separate logic set using bit sets that handle the "does system care about this entity?" part, I'm just stuck with this Java mindset when it comes to storing relevant data per system.
&gt; - Rust should be comparable to C in terms of speed (at least clang-compiled C). You have the same ability to view assembly and benchmark if you want to optimize. Not necessarily. Bounds checking comes at a cost, especially when it comes to optimizing loops to use simd instructions. You have to manually unroll the loops and use the simd crate to do it in Rust, Clang however will do it (mostly) for free in C. 
Isn't the rust compiler capable of spotting where looping is safe to unroll? My understanding is that it is able to do that at least some of the time. If not you should see it during optimization pass and manually unroll/vectorize it. I know that floats don't unroll because it can change the answer slightly.
The provided `impl From&lt;T&gt; for T` is often a source of friction when doing stuff like this. The compiler is essentially saying "Hey, what if `TFrom` and `TInto` are the same?!", because then it wouldn't know whether to use your impl or [this one](https://doc.rust-lang.org/src/core/convert.rs.html#400-404) (nevermind that they'd do the same thing in this case). 
Would you *like* it to be more collaborative? If so, then I would suggest going through the motions to invite participation, even if you're still just approving your own PRs in the meantime.
&gt; Would you like it to be more collaborative? Error handling or failure? Right now I think because the discussion is no longer just failure but also std::error evolution i'm not sure what the best approach here is. For a long time I felt like it would be interesting to have some collaboration on failure to evolve the API but I think it's not my decision to do this now. Boats wants to drive the Error trait itself forward so I assume at least part of that conversation will take place there. At the moment I mostly just want to make sure failure gets the obvious issues ironed out. For larger changes on it I want to observe a little bit what happens in std land.
It's not really the unrolling that gets you. For example say you're iterating across a slice of floats of length N. In C you can split this into a head loop to iterate N/4 times with an unrolled loop of 4 iterations to make use of SIMD, then a tail loop to catch the difference. You can do this without any extra legwork, LLVM will compile some gorgeous SIMD for you there. In Rust if you try the same thing, your inner loop that unrolls 4 iterations will perform a bounds check for each iteration. I'm not 100% on this but I believe that's the reason that LLVM won't compile nice SIMD for you. If you want the equivalent you can use the SIMD crate, but that has trade-offs since platform agnostic simd is not stable yet. You can also use an unsafe block and manual pointer arithmetic but iirc last time I tried that on godbolt it didn't emit SIMD.
There is: multiple versions of a library aren't supported at once by cargo. Failure is a perfect example of a crate where being able to have 0.1 and 0.2 in the same project simultaneously would be concretely useful. The straightforward workaround is to pull the API version into the name. So then you'd have failure1 and failure2 crates.
So, is there any workaround I can use?
Is this something that the compiler could do for you somewhere? Could the compiler be taught to do these kinds of optimizations, at least for simple loops/iterators?
I think the only way is to make your own `Vector2::from_vector` function instead of implementing the `From` trait. There's a sneaky way to make the original code work using a unstable feature (auto traits) on nightly, but according to core devs it's a bug and shouldn't work. 
Maybe, since the only bounds check that needs to happen in an unrolled loop body is the largest index. But my point is that at the moment, rustc will generate code that is slower than C that does the same thing, since memory safety is not free. 
Just pushed an update that adds indefinite arrays and definite + indefinite maps, those are likely to be features used in a lot of those tests. Only features left unimplemented are semantic tagging and floating point 😄 (and actually useful error messages).
If it is POD (plain-old-data) you can try [zero](https://github.com/nrc/zero).
You can either - start with code that is fast and possibly incorrect (C) and then check it, or - start with code that is correct but slow (Rust) and then drop to unsafe to make it faster, making sure you uphold the required invariants when you write unsafe code. I guess I'm arguing that the latter approach has a smaller surface area for mistakes, since you only optimize where it makes a difference, and you explicitally mark where you can break invariants (of course you can create invariants of your own that you must uphold elsewhere)
&gt; The problem is that it's very hard to get people excited about errors. There was and is interest. A couple of problems - People adopting it too quickly, causing maintainers to be averse to breaking changes, making interested parties (at least me) get push back for improvements, making us feel like it can't be improved - When `failure` was introduced, I had the impression it was being treated as a bit of an extended RFC for the future of how to handle errors in the Rust ecosystem but development wasn't treated that way. When discussing what the API should be in issues, the maintainer would make unilateral decisions without any tracking of alternatives like I'd expect an RFC. This made me feel disenfranchised from the process and give up.
I think part of the problem with `failure` is it combines three things - A new, improved trait (moving to standard) - macros to help implement the trait - Quick and dirty error reporting API (`failure::error`) I'll not discuss use cases for `failure::Fail` since that is moving to standard. I'll leave my comments for `failure::Error` What it isn't good for - Inner loop performance - A library - Because it doesn't implement `trait Error`, it is hard for your clients to interop with it unless they also use `failure::Error` - If you care about having well documented errors from your crate for clients to be able to respond to. Its too easy to let random implementation-detail errors through So what does that leave it for? - Rapid prototyping. I found it a big help when I was getting the feel for how I wanted several of my crates designed without having to worry about details like non-architectural performance or exact error types - End-user applications I do think `failure` should be more explicit about these trade-offs.
I'm not against breaking changes. I can understand batching them up, like waiting for the `trait Error` RFC. This is also why I opened an issue (before `trait Error` RFC) about splitting up the crate to decouple the different layers of compatibility in it (`Fail`, helpers, `failure::Error`).
TBH, C# is a pretty nifty language. I never could use it seriously because it was not seriously cross-platform until very recently, and not for the GUI part; but I'd have loved to.
Offtopic: I checked cargo-generate and was disappointed with its use of emojis. Does anyone else find them appalling/infantile/unprofessional in the context of software? If you are the type of person that enjoys and uses them all the time that is completely fine, I sometimes use emojis as well, but I think there are contexts in which they shouldn't be used. Formal setting is one example, software in my opinion should be the other. Firstly because their meaning isn't universal, even if I looked in emoji dictionary I wouldn't get immediately what "wrench" or "shrug" mean in context of cargo-generate. There's a reason we went off pictographic to phonetic writing. Secondly, I like my software to be pure engineering artefacts that try to follow the optimum path unencumbered by unnecessary and subjective opinions of their authors, regardless of whether I agree with them on the peripheral matter or not. If you push emojis in your software then the impression I get in my head, and I realise this is subjective, but I can't shrug it off, is that what you want to say and would want me believe is that you are cool, hip, young, quirky and definitely not a corporate square and I think that this is a dishonest and bad for of marketing. Stop it. I get triggered when I see frowny face on Windows 10 BSOD and I'd hate to start seeing it in Rust. Sorry for the rant. 
If `failure 0.2` were released tomorrow, you would indeed see crates including both `failure 0.1` and `failure 0.2` in their transitive dependency chain because Cargo _does_ allow for multiple semver incompatible crates to be compiled into the same binary. Normally, this isn't an issue. For example, for `regex`, the only real bad thing that happens here is your compilation times get worse. But for public dependencies like `failure` (where you expose implementations of the `Fail` trait in your library crate), you end up being cornered into incompatible situations because the `Fail` trait from `failure 0.1` is treated as a different trait than the `Fail` trait from `failure 0.2`.
I agree with this because I felt the same way. However I also did extensive tests with alternative error solutions and what I keep running into is that you can make the best possible error system but in isolation it's pretty useless as you need to interop with the rest of the ecosystem and the language is not expressive enough to deal with all that. I think the main reason error-chain and failure got any traction was precisely because it was just one person running ahead making some sort of solution and that's what got traction. I'm not sure what the solution here is. Currently I'm planning on just making failure work and then in parallel do some experiments what else might be possible. My only hope is that we're not rushing into changing the std error trait without much consideration now.
The strings that /u/gnuvince is using are likely unique to each error location, so a simple grep will show where the error came from, exactly. It won’t show the exact backtrace, but there usually aren’t too many code paths that lead to the same function. Backtraces are nice sometimes, but I’m not sure they’re worth the headache of using a 3rd party dependency that can’t even bump its own version number without worrying about breaking the ecosystem. Really, if the data types were moved into a separate failure-types crate, and a new 0.1 was released that pointed to failure-types, I don’t see any reason why new versions of failure would be unable to be released. Regardless, cost vs benefit of using failure is just kind of murky for me.
&gt; It won’t show the exact backtrace, but there usually aren’t too many code paths that lead to the same function. I strongly disagree with this assessment from extensive experience in writing applications in Rust. IO errors in particular are really tricky to track down if they are passed down the system. For instance I cannot count how many times I was absolutely lost where an IO error came from because it was just absolutely impossible to determine the location in the code where it happened. &gt; but I’m not sure they’re worth the headache of using a 3rd party dependency that can’t even bump its own version number without worrying about breaking the ecosystem. I fail to see how the version number bumping is relevant here. The worst case failure ecosystem breaking is still superior to not using failure/std error at all. A broken failure interoperability degrades to what you have out of the box.
This is off topic for the sub and this thread, but &gt; Christian's don't convert villages by throwing Bibles at them and shouting "God is good. RTFM". They do it through charity and example. They don't convert them by "charity" and "example" either. Historically conversion has been a violent and racist process.
Could you write a [custom allocator](https://doc.rust-lang.org/1.9.0/book/custom-allocators.html) that is used when your target doesn't have one? 
I am troubled by this perception, because there is no doubt that Mono was very serious.
&gt; There is: multiple versions of a library aren't supported at once by cargo. This is not correct. The issue is that rust *does* support this, but if you try to pass something from 0.1 that expects 0.2, it fails with a type error, as it should.
Is there a way to provide a conversion between Fail (v0.1) and Fail (v0.2)?
I was specifically talking about String errors, not IO errors. I also think that simply including the current file and line number in the error value would go 95% of the way to a solution even for more generic errors like IO.
&gt; I also think that simply including the current file and line number in the error value would go 95% of the way to a solution even for more generic errors like IO. That would be incredibly space inefficient compared to a good backtrace implementation.
It would be the size of a pointer... that string would be generated at compile time and it would be a simple &amp;’static str.
It was very serious, but there was no GUI component, and the ambient fear of MS pulling up an “Oracle” from their sleeve.
&gt; It would be the size of a pointer... that string would be generated at compile time and it would be a simple &amp;’static str. It's the size of a pointer and a u32 at least. Additionally you now duplicated the filenames. Compared to a single pointer for the instruction pointer that is needed for doing this via DWARF data.
When would an application be able to do anything with the line number? Unless you’re shipping self modifying code that can use the line number to fix the problem, then it’s just going to be logged, so there’s not much reason to keep it separate. A macro at the place where the error is created could create a string at compile time containing the file name and line number. This would not occur at every level of the stack, since this is not trying to be a backtrace. This is just a record of where the error occurred. It would be much higher performance than creating the backtrace, and I don’t think the additional binary size would matter at all. “wherever.rs:32” is not exactly a huge string.
It's a pretty obvious feature, even so. LaTeX escapes identifiers, so it isn't like it's a new idea, even for C#.
Nope, because you can only depend on different versions transitively.
&gt; When would an application be able to do anything with the line number? I'm not entirely sure I understand your question. The purpose of having debug info is to be able to fix issues. For that I want to know *where* the error originates. &gt; It would be much higher performance than creating the backtrace For a start most people do not want to compile in debug info into their executables but still get the stacktraces to be sent to services or get crashdumps. Unwinding info is already in the executable and generating the backtrace itself is pretty cheap as a result of that (you need that already to walk up the stack to clean up on panic). More importantly though you do not need to walk very far up the stack to get useful info. That's more useful than statically compiling in some information I cannot do anything with (purely the line number for instance). &gt; I’m sure that full backtraces are useful, I’m not arguing against that. But they do have a cost. I do not see how a backtrace is expensive at all, especially if it's not fully produced. To only walk the stack to the point of a single frame which is sufficient by your standard is likely to be barely noticeable particularly on x86_64. In any case if you do not want backtraces, they disappear automatically anyways. Disable the backtrace feature in failure and they are gone.
The repository says "Vulkano is still in heavy development and doesn't yet meet its goals of being very robust.", so you're probably seein `unwrap()`s that are just part of the development process. Their errors might be handled gracefully later, or they might just be cases of "will always succeed".
That's not how I interpreted his comment at first, but upon rereading and looking at the surrounding OS and feature specific code, I guess you may be right.
Had this question to. Could not figure out how to get I back haha.
Yeah, but we all know that the word "but" is an instruction to ignore any previous qualifiers and assume the following is the singular gospel of an angry belligerent.
I agree with all of your points about emoji. (Note: it's a Japanese loanword, so the same form is both singular and plural. Also, adding "s" to the end kills the cue that the terminal 'i' makes an 'ee' sound.) 1. Emoji lend a very informal tone to conversation, while these are contexts where a certain degree of formality is apropriate. (Not necessarily as much so as an academic paper, but it's a good comparison.) 2. Emoji are imprecise. (eg. Does a thumbs up on GitHub mean "You make a very good point", "I like this", or "I agree"? ...because they may be three different degrees of the same sentiment, but the distinction is very important.) 3. Abuse of smiley/frowny faces and the like can come across as patronizing. Treat me like an equal whose skills may be disjoint, not a child. (I actually recently raised this point on the Firefox bug tracker over the use of terminal exclamation marks in the new status messages they're adding. I ended one of my points with something like "I *want* it to feel out of place if you add 'Yay!' to the end of confirmation messages."
&gt; IO errors in particular are really tricky to track down I agree that a propagated plain io::Error in a context other than a call to do IO in the standard library, does not provide enough information, if that's what you're saying. The rest of your reply I can't quite agree with, at all. What I prefer to do with io::Error is to wrap them together with the related path that the operation failed for when it's available. That usually helps to point out the error site but I also try to provide unique error enum variants for each io::Error in my wrapper Error impls with some descriptive name for each variant. In my somewhat limited Rust experience that is enough. The pattern described above for io::Error works well in other cases to, providing some context, could be a simple string together with the wrapped error and/or a unique Error enum variant is simple, easy and gets the job done, all while depending only on the standard library.
I agree and would like to add something that I think usually gets lost when discussing "what is a breaking change". Build time errors, are not that bad. It's actually a good thing. You get to see what assumptions went to shit since the last dependency update, when you build, no harm done. Significant changes in runtime behavior on the other hand is what actually matters. Don't be afraid to cause build errors, they are an excellent way to communicate API changes.
&gt; breaking the ecosystem Causing build errors for projects that have opted in to use experimental error handling is not breaking a ecosystem. It's a minor extra maintenance task that everyone depending on 0.x should expect.
Can Fail (v0.1) and Fail (v0.2) both implement the same trait (say, FailBox) from an external crate that then uses a second external crate to wrap it back as a Fail (v0.2) (FailBoxFailure contains a FailBox, is a Fail v0.2)?
Having also bounced off of contributing to Cargo in the past, I think a 10,000ft overview (a la the rustc book) would be *extremely* valuable for getting more people in to help with Cargo.
&gt; I think the main reason error-chain and failure got any traction was precisely because it was just one person running ahead making some sort of solution and that's what got traction. The reason I got interested in first error-chain and later Failure was that I had not done my homework and hadn't read all of the chapters related to error handling in the Rust book. I suspect other may have similar reasons for not using the tools available in the Rust standard library. A combination of `Error` enums, the `From` trait and `.map_err` goes a long way.
Since we are already off-topic I will join in. &gt; Does anyone else find them appalling/infantile/unprofessional in the context of software? I kind of get it, but my particular types of grympyness resides in other places though and I actually adore that we can have emoji in our terminals nowadays :D The first time I saw it was when trying the Rocket web framework and I just fell in love. I think we will be seeing more of emoji in terminals. Perhaps even custom images and other graphics at some point?
I just meant for the way you handle the failure repo. The larger discussion is definitely for the community to decide.
I've handled this (somewhat) with my [exitfailure](https://crates.io/crates/exitfailure) crate. 
&gt; In my opinion, the problem is education Education does not solve interoperability. Without a trait you cannot reason about complex error setups. For instance a system like [sentry](https://sentry.io/) depends on being able to look at an error and extract information in absence of concrete knowledge. You can argue that systems like sentry are useless for you but as someone who works at that company I can tell you that customers love the product ;)
&gt; The rest of your reply I can't quite agree with, at all. Which part do you disagree with?
&gt; I just meant for the way you handle the failure repo. Whatever the community wants.
&gt; Does anyone else find them appalling/infantile/unprofessional in the context of software? Nope.
I would love to see an example of this working with specs-rs https://github.com/slide-rs/specs
Please *don't* include build timestamps; doing so breaks reproducible builds. See https://reproducible-builds.org/ for details; people want to ensure that building the same source produces the same binary, and timestamps break that. If you absolutely *have* to include a timestamp, please respect the `$SOURCE_DATE_EPOCH` environment variable. However, I would suggest simply not supporting timestamps at all; there's always a better alternative, such as version numbers.
Wrong subreddit, you want /r/playrust.
Yup, talk will be in English, no worries. :-) Everyone is welcome and we'll happily switch to English - although you'd have to deal with my Bavarian accent in this case, sorry. ;)
Well, sounds like failure is in good hands :) In case you hadn't read it before, you can see what my [previous efforts in experimenting with failure and other error approaches](https://epage.github.io/blog/2018/03/redefining-failure/). Seems like with the above listed changes plus `cause` -&gt; `chain`, a lot of my concerns have been addressed. Trying to remember what other concerns I had. Here is a rough sketch: - I feel like `Context`s name is misleading. I've slowly gotten the impression that it serves as (1) a quick and dirty error or (2) additional information that works within a chain - When I first saw the name and description, I thought it was meant to augment the existing error - Instead it serves as (1) a quick and dirty error or (2) additional information that works within a chain - Rarely can I pass my own types into `Context`, taking advantage of `T: Display` and instead have to call `format!`. - If it really is just for `String` and `impl std::error::Error`, maybe finding a way to clarify its role in the documentation - How can we help with the `Termination` trait - *sigh* I forgot they put an `impl` on `Result` in a way that makes it impossible for our errors to declare their own exit code. The more I see of this RFC, the more I feel its a complete mistake; its us adding a whole language feature specialized just for documentation examples and is unusable in any other context - Possibly hack it up so our `Debug` forwards to `Display` so the user gets a reasonable message in case someone actually uses `Termination` (or maybe a wrapper error type `TerminationError`?) - Ensure documentation is clear on the role and trade offs (see the other thread in here) - Some of the `no_std` behavior is surprising. Its been a while. I think its how `context` wipes out the `cause`? If thats the case, then that is either ok-ish (context stands on its own) or bad (need original error passed up rather than context)
Such code is possible, you can write such trait on your own and implement it for these data structures. About why there aren’t such in `std::collections`? I have no idea, try to write RFC and see if it will be welcomed. 
Oh, interesting! I tried and failed (heh) to write a human-failure crate at RustFest that can be used in main in place of failure::Error. I'll need to check yours out :)
I agree with the context concerns. It's especially weird because it is used as a getting an error on the spot as well as for the "build your own error with backtrace" situation. I have no idea yet about the termination situation. As far as I can see the termination is in a similarly stupid situation as std::error itself :(
I love the git2-rs API as an example of how to expose a C library in a safe way; git2-rs was one of the things that got me into Rust in the first place. Also, most people tend to describe idiomatic Rust code as "Rustic" rather than "Rusty". :)
The most recent discussion around collections traits I've found: https://internals.rust-lang.org/t/collection-traits-take-2/1272
I'd argue that there are two reasons that emoji come across as unprofessional compared to glyphs which have always either existed or been approximatable, like the checkmark. 1. "Emoji" are used in a more informal way, like a more graphical version of the "u" and "4" in "I'll go with u 4 lunch", while people generally have no problem with using glyphs like a ballot checkmark, ballot X, lightbulb, etc. as bullet points. 2. Glyphs intended as emoji tend to not limit themselves to the base font colour, which makes them more attention-grabbing and less professional-feeling.
&gt; I strongly disagree with this assessment from extensive experience in writing applications in Rust. IO errors in particular are really tricky to track down if they are passed down the system. For instance I cannot count how many times I was absolutely lost where an IO error came from because it was just absolutely impossible to determine the location in the code where it happened. I can see backtraces being helpful in the absence of anything else but whats even better is, for lack of a better term, "logical backtraces" or "user backtraces". For example, in my static site generator, cobalt, I chain errors all the way up the stack to provide a user-meaningful backtrace. A fuzzy approximation of it would be: - Failed to build site - cause: Failed when processing `post/foo.liquid` - cause: Invalid liquid - cause: &lt;some liquid error showing the liquid backtrace&gt; These are rich, user meaningful errors that help them understand the context of the root error with the added benefit of helping me know an approximation of the call stack for the root cause. In this case, I just don't bother capturing a `Backtrace`.
Thanks! We should considering pulling this into a unified story on how to handle errors. A remaining problem to solve is how do we get custom exist codes.
Ahh. I look forward to seeing how that macro turns out. It sounds like it'll be quite useful.
Misread the title, thought it was about which rust books to read, good article though
I agree with all of your points. Also, it's also harder to visually parse emoji compared to emoticons because they are rendered differently by every font. And harder to use for expressing emotions/reactions than emoticons because they can't be typed easily. So I never use emoji and they also distract from the text they occur in, when other people use them for communication. Also, the unicode standard is getting bloated by emoji for every niche, which is unnecessary. Every interest group wants their own emoji set included in the unicode standard. This goes against the spirit of the web (modularity, orthogonality, decentralization). Just use inline gifs if oldschool emoticons aren't enough, instead of bloating the unicode standard.. ;)
Not expected where my comment would be picked apart. :) &gt; Nope. Categorically? Another reply seem to share my sentiment. I was hoping a few others would reply that they agree, not that I'm weird and nobody else on earth shares my opinion. &gt; This is impossible To be in some sense pure or that it is impossible to try? For the former - is there a sociological issue specific to software engineering? Academia doesn't lade artefacts they produce with similar content. If you meant the later, perhaps not all software have well defined optimum paths (but can have arbitrary ad hoc ones) but at least there exist partial ordering for all ad hoc problems. Resource usage being equal a solution that that requires less human effort to use could be said to be closer to optimum. &gt; cloud your ability to pay attention to only the engineering. Because I have a cynical view of tech. Too much /r/netsec perhaps. I can't trust people who have compulsions they cannot manage. If I'm not mistaken you are partial to emoji, but say if I were a stuck up, old school catholic and left a few hints to that fact in my software, perhaps asking people not to use my software for sinful purposes and adding a quote from the old testament to not leave any doubts, would you still be able to focus only on the engineering or would you have doubts about me, not because of my faith, but because I felt the need to push it on others and at the same time think there is a better approach?
&gt;Is there a good reason why Rust designers choose not to do what I suggested? As [the eclectic crate](https://crates.io/crates/eclectic) (which does exactly what you're describing) [notes](http://apasel422.github.io/eclectic/eclectic/#a-note-on-trait-objects), the interfaces are suboptimal for now because of a lack of Higher Kinded Types. Because we don't want to break backwards compatibility or have a bunch of deprecated APIs in the standard library indefinitely, these traits probably won't be added until we have HKTs
As the other other comment observed, the code and errors you posted do not match. To get your code working you should recompile your code and then fix the errors one by one by figuring out what they are saying and then making the appropriate changes. For instance, the first error is complaining because the function to convert an integer to a string is called \`to\_string\` not \`to.string\`. A bunch of the other errors/bugs in your code relate to mixing incompatible types, so you might want to read up on type conversions.
For those who don't want to click through to the parent link, here's the executive summary of the new features: * impl Trait * ? in main/tests * dyn Traits * Bijection from URFACE to URAS * Non-lexical lifetimes (not ready for prod, but available) * In-band lifetimes now support groupies * Anonymous lifetimes * Refreshing mint flavor * SIMD instructions * Cargo will offer high-fives for clever crate names * As part of ongoing usability efforts, fighting with borrower checker will be made easier for users by providing them with swords
The best way to do what you describe, if the core developers didn't add your suggestion, would be to have a type at the top of your file describing what collection it uses: ``` type Collection&lt;T&gt; = VecDeque&lt;T&gt;; ``` Later, you can change it to: ``` type Collection&lt;T&gt; = LinkedList&lt;T&gt;; ``` In every place you use VecDeque, consider using Collection instead.
Have you considered dropping the `cursive` dependency and just going straight to `termion`?
Codegen in general is kind of a mess. Using `--emit asm` when building a ~30 line Rust application in release mode will regularly result in a ~200,000 line assembly listing, which is hugely more than what you'd get in most languages. That's the thing people need to keep in mind, I'd say: Rust is an extremely, extremely verbose language that exposes itself to programmers in a non-verbose way. Even things as simple as `println!` expand to very long chained function calls. It's not magic. There's a ton going on behind the scenes.
I should have thought about that, but didn't. I assumed that it would have been built the correct way (handling the errors) the first time and didn't think about `unwrap` to get it working and then flesh it out later. Makes sense since most of the graphics libraries I found are still very young and under development. 
&gt; as it should Assuming that the definition is identical, what is the reason for treating them differently?
That’s a big assumption; the whole point is that they have incompatible version numbers.
I might have misunderstood the conversation but I thought grandparent was initially talking about go. You can easily have an assert function in go so that when you define NDEBUG, uses an assert function that just returns true. The optimiser will optimise it out, making the assert truly no-op.
"Oh no! Firefox crashed! By the grace of our Lord, your session was not lost. Click OK to pick up where you left off, and God bless."
This reply is surprisingly dismissive and condescending coming from a Rust leader.
why not? stdlib in C just normal code that everyone could have written; including it would mean you don't have to implement your own memory management. (only the sbrk function) The C runtime however is a different thing, it could cause some problems.
&gt; because you want software to be more formal in presentation. I don't care for formality, in fact I prefer relaxed voice. I appreciate steve's work. I think there is a difference between informality and pushing on others how informal you are. Either you are overdoing it and you don't know it or there's dishonest reason where you want to sell someone an image of yourself (as in the case of Microsoft). Or I'm out of my mind. Remember how ascii emoji were considered bad form and you'd feel guilty for being lazy using them to express your feelings. Somehow unicode emoji don't have this connotation. Is that because ascii emoji are too leet? This brings me to a new question - if you hold that emoji are tasteful would you say that a more broadly understood subset of leetspeak for use in software targeting tech users is tasteful as well? If not, what is the difference?
I think that implying emoji means you’re bad at engineering to be dismissive and condescending.
I typically use Vec for sequential data and HashMap for tabular data. Once I have the structure built I rely on iterators more than the collection methods. I know there are good reasons for other collection types, but I rarely need it.
I mean, obviously some people think so; you’re one of them! I meant me personally. In some pure sense; there is no pure objectivity. Everything is filtered through human experience. There are only degrees of objectivity, you can never be purely objective. I’m not the one claiming to ignore subjective aspects, you are. You’re totally free to have these opinions! I don’t hold them myself.
You’re welcome &lt;3
“Libraries written in C++ or Java can generally only be used by applications written in the same language. It is difficult to get an application written in Haskell or Java to invoke a library written in C++. On the other hand, libraries written in C are callable from any programming language.” Why are libraries written in C callable from any programming language? Is it an intrinsic quality of C or is it just by consensus. COULD it be another language just as easily if this other language had become as ubiquitous as C ? 
I suspect not enough to satisfy the SQLite developers.
I misspoke. Have a look at the code [here](https://www.arduino.cc/en/Tutorial/Sample#toc6). What would be the advantage or Rust? As far as I can tell, there is nothing here that could go awry that Rust would prevent.
Thank you very much for your respond
How does it compare to [project_init](https://github.com/vmchale/project-init)?
after some work i manage to cut it down to one error //use std::fs::read; //use std::ptr::read; fn main() { let mut _temp:f32 = 0.0; let mut result_temp:f32 = 0.0; let mut menu_num = 0; fn Userinput() -&gt; { let mut user_input() = String::new(); } println!("Welcome to the world greatest temperature converter."); println!("Please choose one of the two formulas to convert/"); println!("1/From Fahrenheit to Celsius."); println!("2/From Celsius to Fahrenheit."); if menu_num == 1 { result_temp = _temp -32.0*0.5556 } else {result_temp = _temp +32.0*1.8 } println!("The result is/",result_temp); } but it show this error Compiling playground v0.0.1 (file:///playground) error: expected type, found `{` --&gt; src/main.rs:11:20 | 11 | fn Userinput() -&gt; { | ^ error: aborting due to previous error error: Could not compile `playground`. To learn more, run the command again with --verbose. any thoughts?
I wouldn't say that. And perhaps I could've been nicer as well. Sorry all. I get triggered if I see emoji in things I really like. I share /u/ssokolow's aversion to exclamation marks as well.
It's not very often that you come across players like this. His fake accent didn't fool us, nor did his lies. Eventually he realized we weren't leaving, but instead of fighting us he just unlocks his base, takes off his doors, and completely surrenders. 
Termion has major bugs with multi-threading 
I guess I could, but isn't that a little overkill for a small utility library mainly targeted at Rust users? The FFI bindings are purely so this can be reused from other languages and are hidden behind a feature flag by default, in which case I think having a private static `Parser` for use via FFI would easiest. It would mean it's the caller's responsibility to look after lifetimes and make sure things are done in the correct order, but I don't see how that's any different from every other C program...
Another idea, you could create a static global instance hidden behind a feature for those particular targets. 
I never implied that, so again, you're being dismissive and attacking me through a straw man. There were people who agreed with him, so you were factually incorrect in your original reply. I have no opinion on emojis in engineering. My opinion was strictly on the content of your comment.
You have wrong impression what he meant. He meant I made implications, which I did, which were unfounded, because I'm loopy and got worked up imagining things. I thought emoji were low effort communication for tweens and thought all people know that, now I think some people might just understand them differently. He was justified in tone and in pointing it out, which made realise I was in the wrong. 
C ubiquity is definitely part of the reason, but it's also partly the because the ABI is relatively simple, at least when compared to other languages like C++. 
The C standard library doesn't include anything that allocates on the heap. Rust does. Vectors, HashMaps, etc.
Remove the 'fn' and braces - you have a syntax error and i cant see that helping you in the long run.
As far as I know, `transmute` can only make life worse for this kind of cast. A pointer cast with `as` works just fine, and transmute can cast other sorts of things as well, making typos for example more perilous than they need to be.
Wonderful talk. Solved many questions.
Still Didnt work I really start to wonder how all these people get to learn rust?.
Yeah- I think it's pretty common for crates doing large new undertakings without a proof-of-concept. For instance, [sled](https://github.com/spacejam/sled), a relatively new embedded database, didn't even have error handling with Result until last year. Unwrapping is easier to write and you can see exactly where your invariants are failing. Once there's some confidence that the library will only fail when there's actually bad data, and not because of abundant bugs, converting many unwraps/panics into catchable errors makes sense.
[this](http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/) [four](http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/) [part](http://smallcultfollowing.com/babysteps/blog/2016/11/04/associated-type-constructors-part-3-what-higher-kinded-types-might-look-like/) [series](http://smallcultfollowing.com/babysteps/blog/2016/11/09/associated-type-constructors-part-4-unifying-atc-and-hkt/) explains every detail why it is not in ‘std‘ when it goes into it and what the current unfulfilled are to do so
about:mozilla has religious undertones and is a part of Firefox.
I'm a scrub that uses extensive doctests and println debugging.
I hadn't thought it at first, but this looks like it should be allowed! It isn't, but it would be sound to allow it. There's a check for competing implementations that would be like this: trait Xxx {} trait Yyy {} trait Zzz {} impl&lt;T&gt; Zzz for T where T: Xxx {} impl&lt;T&gt; Zzz for T where T: Yyy {} This is disallowed because it would make adding a `Yyy` implementation to a type which already implements `Xxx` a backwards-incompatible operation. I'm guessing that your code fails because this part of the compiler doesn't know that a type can't implement both `Deref&lt;Target=IDispatch&gt;` and `Deref&lt;Target=IUnknown&gt;` at the same time. I imagine this will be fixed and allowed once we have the new [chalk](https://github.com/rust-lang-nursery/chalk) type checking engine in rustc. Chalk should do much better at negative reasoning (a type can't implement `Deref&lt;Target=IDispatch&gt;` if it implements `Deref&lt;Target=IUnknown&gt;`) than the current resolution engine.
What extensions do you use in vscode for debugging? 
I tried both the c/c++ extension and the CodeLLDB extension.
I use CLion. Debugger works. 
I might have to try that. Is the debugger included in the community version of CLion?
`gdb` and `rr` work fine for me. Doesn't seem to be any need for the `rust-gdb` wrapper even.
Isn't gdb on macOS wrapper over lldb?
share your launch and task .json and lets see what you might be missing
Not sure, last time I owned a mac was something like 10 years ago, well before I was programming in rust.
Debugging works just fine, however placing breakpoints on functions is slightly more involved, because of Rust’s name mangling. Setting line breakpoints (`breakpoint set -f &lt;file&gt; -l &lt;lineno&gt;`, provided you compiled with debug info) and regex breakpoints (`rbr`) definitely work, and so many other methods to set breakpoints work just fine, but they are slightly more involved. Can’t say anything about the quality of `rust-lldb`, though, as I use plain `lldb`.
Cool crate! I wonder if you could do `join_to(w: io::Write, s: &amp;str) -&gt; io::Result&lt;()&gt;` or something similar. This would make it easier to do common use cases where you want to "build it" onto a string. The alternative (I assume) is to build up a `String` to only throw it away.
I did not try using plain lldb, it works surprisingly well, the only thing I am having problems with is printing out rust types like Vec and Enums with value in them. But it does work!
Just edited the OP with my task.json 
Feels like something to consider for standard.
I don't observe this at all. Rust is just as capable of generating a heavily optimized SIMD loop as C: C: https://godbolt.org/g/nEe51q Rust: https://godbolt.org/g/Brd2Kg I don't claim to be an expert on assembly or SIMD, and it's clear that the Rust compiler has generated more code than the C compiler has, but in both cases the heart of the loop appears to be a series of SIMD loads (movdqu) and packed integer additions (paddd) followed by a single branch-predictor-friendly jump-if-not-done (jne) back to the start of the SIMD loop. It doesn't look like there is any unnecessary bounds checking going on in Rust compared to C, so I don't think your complaint is relevant, at least for this simple test.
There is no community version of CLion, only the commercial one. It's like $80/year with perpetual fallback license on whatever version you purchase, totally worth it.
I always used the c/c++ extension and for me the launch.json contains "type": "cppvsdbg" I presume you modified it when you tested the c/c++ extension? task.json specifies how the build should be done. I am on windows and there i think it is required to specify how the build task should be run. Given that you run from the debug folder i presume you got the required symbols as well, could you check whether console output says: Symbols Loaded for your .exe?
It won't emit SIMD when you use [floats](https://godbolt.org/g/wwXQ6P), but it will in [C](https://godbolt.org/g/yUZmNv). 
I am running this on macOS so I think it's different here? But I don't have any errors reported on the lldb console when I start rust-lldb by passing it the binary in the deps folder, where the debug symbols directory is also present.
oke, no clue then, sorry
Thanks, that command makes me able to find whatever actions in IDEA
Why not simply return struct Parser by value, on the stack. If you want the C side not to know about the internals of struct Parser, define it there as struct Parser { char opaque\[64\]; } .
This looks surprisingly easy! I didn't know Rust libraries for recommendation were mature enough for use, I shouldn't have underestimated them. Thanks for making this and presenting it so well!
But you do not need neither of ATC nor HKT to support such construct. This is just plain trait. 
Rust has: * zero-cost abstractions * move semantics * guaranteed memory safety * threads without data races * trait-based generics * pattern matching * type inference * minimal runtime * efficient C bindings Nah, but for real: It feels a bit like a streamlined Haskel without a forced GC. 
As MadRedHatter already said the C stdlib doesn't do heap allocations, but it is also otherwise much smaller than Rusts's: `open` and much else having to do with files is not contained in it, for example, those are POSIX functions. Often the C compilers manufacturers ship with their toasters are stripped even further down, you can't generally assume full C98 compliance. Hence why SQLite depends, in minimal configuration, on basically only `memcpy` and `strncmp`... which is really depending on nothing as those can be implemented portably in pure C, but you can rely on compilers having fast implementations for them.
For standard what? Library? Wouldn't that be a bit premature? I thought the default approach was to allow some experimentation in the crates.io ecosystem first, and if it's taken this long for a string-join crate to appear, I'm inclined to conclude that there isn't really a need for it. Hypothetically, if the code to be added to the standard library is to be inspired by the code in this crate, Nathan should fix the license before he gets more contributors.
What stuck out more to me was how un-constructive it is. (ie. Responses like "Nope." serve to shut down conversation.)
Both code samples are using the same floating point add instruction and not checking bounds in the loop. They should have very similar performance. GCC has chosen to use SIMD mov instructions and LLVM is doing direct memory loads in the addss instruction, but this has nothing to do with Rust vs C (in fact if you [compile with clang 6.0.0](https://godbolt.org/g/UT7KY7) you'll see it emit almost identical assembly as the Rust example).
Looks very cool! Any thoughts about having a deterministic fixed-point mode? It could be great for enabling networked physics ([see this blog post](https://developer.oculus.com/blog/networked-physics-in-virtual-reality-networking-a-stack-of-cubes-with-unity-and-physx/) for a hands-on-example of why) and there doesn't seem to be a good open-source solution out there yet.
How similar is rust to Haskell? 
The itertools crate provides similar functionality with its [join](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.join) method.
Yes, a very nice talk indeed! It would be interesting to know what features are missing or would be nice to have for rules based macros. He talked about the trace-feature that is not in stable yet, but what else ? I'm sure that there are some (wish) lists out there, if s.o. could point to them that would be nice!
Wait, do you mean that (1) the stdlib doesn't contain any function to allocate memory on the heap (probably not, since there's malloc) or that (2) none of the C std lib methods rely on dynamic memory allocation? (so that none of them call malloc in their execution) Okay, nice to know 
First step would be implementing a fixed point library. Adding support for it to nphysics should be fairly easy.
TBH, not very. It has algebraic data types and traits, which are quite similar to Haskell's type classes.
Number 2. Of course, an actual implementation might for some reason rely on malloc to implement printf or sort, I don't think there's hard rules against it, but such behaviour would be considered, if not right-out broken then at least... *unaesthetic*.
Linux's handling of OOM is insane, will make your life hell when working on microcontrollers and similar low spec devices, and is pretty much incompatible with critical systems that can't afford to kill processes at random.
No, I haven't. What's the reason behind that? It's interesting. Could you elaborate? 
It's not silly; coming from C where dynamic linking is the norm people don't simply expect that almost everything is static by default here.
[This](https://github.com/thiolliere/airjump-multi) was posted to /r/rust some time ago.
I'd say the biggest thing Rust has which C++ can't replicate is the ability for methods to take ownership of values passed into them, so you can write state machine APIs which verify, at compile time, that you're not trying to hold a handle to a previous state and manipulate it. (I always like to point to Hyper catching attempts to set HTTP headers after the request body has begun.)
The executor doesn't just busy-loop polling futures - it's still event based, the future can tell the executor "poll me when X happens", and the executor will wait for that event and then poll the future once.
If you're "constantly" polling a future you're doing it wrong. Futures in Rust don't work *that* much differently, it's just a matter of structure. The simplest way to implement futures is to have every future be a separately allocated object. That's how it is in JavaScript. Then when a future needs to wait, you just make a note in some datastructure of the runtime that that specific future needs to be woken up when something happens (i.e. a file descriptor becomes readable). In Rust though we want zero-cost abstractions, so having a separate allocation for every future is a no-go. We want to be able to compose them like we do with iterators, and allow the compiler to optimize the composed future into something that we couldn't have written more efficiently ourselves. This presents a problem though, since this new composed future can be suspended in many different states for many different reasons. We need some way to resume the future in the right spot without having to restrict the optimizer in what it can optimize away in the internals of the future. The answer is to give futures a generic "poll" method, and make the future itself responsible for keeping track of what it was doing and knowing why it might have been woken up at this point. Then when you compose futures, each future's poll method just looks at its own state and delegates to the poll method of the right subfuture. The compiler can ideally flatten this down to a single switch statement for the entire composed cluster of futures. So when a future needs to wait, it registers its top-level future (the one that was spawned as a task on the reactor) to be woken up on the event it wants (e.g. a file becoming readable). When the event happens, the reactor calls the poll method on the top-level future and delegates to the right substate of the future.
I haven't seen that before but it looks like it doesn't ask questions? That makes it a completely different tool imo since you can't really customise templates.
I don't think it would be premature. It's one of those oddly missing things in Rust. Or rather, the functionality exists, but [it's only limited to slices for some reason](https://doc.rust-lang.org/std/slice/trait.SliceConcatExt.html#tymethod.join) when there is no reason to not have it for all iterators.
Awesome! :-) One small nitpick: you can write `Leaf::is_leaf` (it would be more fair to call it a `Node` though) as `self.left_child.is_none() &amp;&amp; self.right_child.is_none()`. There are other bits that could be cleaned up, like `get_room` and sorting the coordinates in `create_corridors`.
I'm a beginner too, so forgive me if this is incorrect: `fn Userinput() -&gt; Datatype of the thing you're returning {` `your code` `}` An example: `fn main() {` `fn square_number(x:u32) -&gt; u32{` `x * x` `}` `square_number(33);` `}` Don't give up!
Is this not true on Linux? Or are you simply referring to the os killing your process when the system is low on memory? As those are slightly different things. https://linux.die.net/man/3/malloc 
&gt; Determining what a lifetime’s “scope” is &gt; &gt; The problem here lies in 'tcx-like lifetimes which are named repeatedly, e.g. the 'tcx lifetime below is distinct from the 'tcx lifetime in the parent. Isn't this just a consequence of shadowing ? I mean, if one were to use different names, the problem would at least partially go away?
lol no generics
Amazing! Don't stop, please. We need more blogposts about this subject :)
Very good package manager, easy build system and the knowledge that your external libraries are not likely to crash your entire app. Those things alone make the price of admission worth it.
Swap `LED_BUILTIN` and `OUTPUT`.
I'm in the same position as yourself. As far as I can tell, Rust has few features outside of the borrow checker that c++ lacks, all of them minute (e.g. easier iteration in macros). What Rust does have going for it, is a lack of many bad features c++ has and an ease of using the good features (e.g. move semantics). A good example of this is rust lacking runtime polymorphism (I hope too good it stays that way), opting instead to just have compile-time composition aided by powerful generics. The nicest thing rust has over c++ is better (read: faster and easier to use) abstractions for option and variant.
Instead of: let entries: Vec&lt;WishlistEntry&gt; = reader.deserialize() .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?; Ok(entries) can't one just write: reader.deserialize().collect() 
As someone else from a C++ background, new to rust Rust seems to have everything nice about what you'd probably call modern C++, references, RAII, move semantics, but by default and unburdened by years of cruft and legacy. As well as much more open to development. What you can do in Rust or C++ seems more or less the same, but *how* you do it and what kind of code you're encouraged to write is different. Rust is safer by default, preventing an entire class of errors at compile time. Rust is also infinitely easier to set up and use than C++, and it's actually possible to use libraries in rust, unlike C++(well, it's possible it's just not worth it)
Sum types, which enable the use of `Result` which makes for totally nice error handling. Not sure if you'd consider that "modern", though :)
Hello, what's a TA?
std::option and std::variant are new in C++17 in addition to being quite ugly, so I feel that's a bit of an understatement.
I'm using CodeLLDB on Mac, and it works fine for me with the following launch.json: { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 "version": "0.2.0", "configurations": [ { "type": "lldb", "request": "launch", "name": "Debug vtes-clips", "cargo": { "args": [ "build", "--bin=vtes-clips" ] }, "args": [], "cwd": "${workspaceFolder}", "sourceLanguages": [ "rust", "c" ] } ] }
When you use `?` you can convert from anything that implements `Try` to anything else that implements `Try`. Therefore, the compiler can't know what you want to collect to, as there might be another type that implements both `FromIterator&lt;Result&lt;_, _&gt;&gt;` and `Try`. However, annotation for `Vec` is duplicated both on local variable and `collect` type parameter - having it in only one place is sufficient.
Let's say that Rust is more similar to Haskell than C/C++.
I just use plain lldb, about setting break points, I do so by specifying file and line.
That's actually the primary thing that rust-lldb solves (it invokes lldb and adds pretty-printers for these types).
&gt; Remember how ascii emoji were considered bad form and you'd feel guilty for being lazy using them to express your feelings. No, I don't remember that at all. Maybe I'm just too young. Also, it's quite hard to express emotion in text, and while emoji don't perfectly solve that problem, in combination with text, they can reduce ambiguity. For example, "I hope you will reconsider." sounds a bit stern/cold, and "I hope you will reconsider. :)" reads as much more friendly. Sure, it's possible to reword it to have the appropriate meaning in context, but that's much harder than just adding ":)". &gt; This brings me to a new question - if you hold that emoji are tasteful would you say that a more broadly understood subset of leetspeak for use in software targeting tech users is tasteful as well? If not, what is the difference? Emoji communicate a specific object or sentiment which is much wordier to express otherwise. e.g. the aforementioned usage of ":)". This is especially true if you don't want to explicitly describe your sentiment, for example by saying "This makes me happy." I think the gain in communication is an objective fact, not a matter of taste. It's also usually quite easy to read emoji, since they are visually distinct from normal text and image/image-like by design. (This might not be as true for the visually impaired, unfortunately... But maybe not a big loss if emoji are used frequently enough to associate a discrete set of emoji with certain sentiments.) Leetspeak is literally just the replacement of specific letters with numbers or non-alphanumeric characters, sometimes with slightly modified spellings, so in general there is no increase in communication efficiency. If anything, by using nonstandard symbols/spellings, words become harder to read overall.
I believe that LLVM doesn't vectorize floats because it produces a slightly different answer.
&gt; I somehow feel the community is not very interested in that topic. Error handling, due to its diversity, is one of the hardest topics in programming. It's also one of the least well-explored topics, in my opinion, because it impedes your goal--it's secondary, and in danger of being ignored completely. While I don't want to say that the community is not very interested, I do agree that error handling hasn't received as much attention as it deserves. When I read community threads, they're more likely to talk about how rust prevents mistakes through the lifetime and type system, the two most highly visible "fault correction" mechanisms. Discussion of the "unexpected event" side of fault handling is rarely expressed. That said, while it may be small, the segment of the community confronting this topic is incredibly passionate. We had a great deal of discussion about it in May, but suffered from poor timing. We agreed to table the discussion until the 2018 edition winds down, so that the core developers can focus on the edition. I've planned a series digging into error handling, first giving a survey of the topic, then segueing into Rust in particular. My original plan was to start in June, but that also fell prey to poor timing. I changed jobs this past month, and decided to delay the series while I find my footing (late September). My hope is that the series, which I'll post to /r/rust and the users board, will stir up interest in the topic, and we'll be able to crowdsource lived experiences from the comments 🤞. Those experiences can then provide a solid foundation for Rust's error story.
For quick and dirty debugging I use `panic` and `Debug` implementations to crash out and view the values of any variables I'm interested in. Also, `debug_assert` is cool for checking invariants that would be too expensive in release mode.
It is more about breaking changes to the language. New features can be added without causing issues but changing the way something works or removing a feature will break existing applications. Rust editions are a way to do this and let the language evolve while still being able to compile and use crates written for older editions. The rust compiler as of 1.31 will not stop working with the 2015 edition (ie code written for it will still work post 1.31) but it will allow people to build crates with the new syntax and features that the 2018 edition supports. See the [Editions guide](https://rust-lang-nursery.github.io/edition-guide/2018/index.html) for a breakdown on everything that is changing but in short: - dyn trait syntax (this is currently implicit, 2018 is making it explicit) - the module system is changing (no longer need extern crate or mod.rs) - async/await syntax - various changes to lifetimes, - slice patterns - main will allow usage of `?` - raw identifiers None of these will be supported by a crate unless it opts into the 2018 syntax. But the compiler will be able to build crates in both the 2015 and 2018 syntax (even projects that use libraries using both editions).
[This official blog](https://blog.rust-lang.org/2018/07/27/what-is-rust-2018.html) post was just published two days ago to answer to you questions ;)
I'm really sorry, I've somehow got a wrong impression that it's a global international event, but after a second read I realize that's more of a local event, so yep it's just natural to have it in German. Now I feel kinda ashamed, sorry again :(
Yes, it is! Sorry, it's just that I've just got a wrong impression on the first read..
It's quick enough to do with `fold` to not complain about it, but it's definitely something everyone has needed at least once. Should be a standard
Not to mention it is, well, way simpler :)
&gt; While I don't want to say that the community is not very interested, I do agree that error handling hasn't received as much attention as it deserves. Yes, maybe my wording was just off and unfair towards the people working hard on it! "Interest" is maybe the wrong word in general but i don't really know how to express this better. I am very eager to read your posts!
There is, though rustc doesn't expose it. -ffast-math works on both clang and gcc, it just happens to include some options that are default-true for GCC and default-false for LLVM. https://godbolt.org/g/xQGwr2
Actually most of those features are available in Rust 2015, according to that link. If it's about breaking changes, ok, I understand that. I guess my critique at this point then is, why try to make editions seem like it's about something else? People's ability to keep up, celebrating progress, idk what but it doesn't matter. I still think it's weird that they keep adding features after the release though, it seems that way editions doesn't serve much of a purpose beyond what versions already do. So what about 1.32, can they add a breaking change for Rust 2018 in that release? That would doubly defeat the purpose of editions it seems.. so are they forced to make all breaking changes now in this one release?
This is the best explanation of the futures.rs polling mechanism I've read. Thank you!
Well, the `Join` type already implements the `Display` trait, so the following works just as expected: ``` extern crate joinery; #[cfg(test)] mod tests { use joinery::Joinable; use std::io::Write; #[test] fn it_works() { let result = [1, 2, 3, 4].iter().join_with(", "); let mut output = Vec::new(); write!(output, "{}", result); assert_eq!("1, 2, 3, 4".as_bytes(), &amp;output[..]); } } ```
Thanks for you work! It is really convenient to have a universal `join_with` method which doesn't imply any bounds neither on an iterator (or better said on its items) nor on a separator. But I wouldn't call it easy by any means :) [`Itertools::join`](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.join) is easy. Because of `joinery`'s highly generic nature it might be hard to understand what exactly is possible and how, so IMHO it would be great if you could add more sophisticated and/or closer-to-real-life examples (just have a look at this comment https://www.reddit.com/r/rust/comments/92spol/new_library_joinery_easy_generic_string_iterator/e384h8d/)
&gt;Actually most of those features are available in Rust 2015, according to that link. No, they are not available in 2015 edition, they have been worked over the past 3 years but none have fully made it into the stable release. It is not about marking a milestone, there are changes to the rust syntax that will not compile on the current version. &gt;If it's about breaking changes, ok, I understand that. I guess my critique at this point then is, why try to make editions seem like it's about something else? People's ability to keep up, celebrating progress, idk what but it doesn't matter. People are celebrating it because of what it brings with it, all of the changes mentioned above and big steps forward in terms of usability of the language that are not possible to do without breaking some existing crates. 2018 edition will finally allow their use in stable rust. &gt;I still think it's weird that they keep adding features after the release though, it seems that way editions doesn't serve much of a purpose beyond what versions already do. Why? The language will never be finished and you can never really call an edition of it completed. It will continue to evolve forward and as long as a new feature does not break something then it can be added to an existing edition of the language without issue. Editions are orthogonal to versions, rust 1.32 will support both the 2015 and 2018 syntax and which gets used is chosen by the crate being compiled. It will even compile each crate in the same project under different editions if required so that 2015 and 2018 crates can coexist. It this were done with normal versions (like python did with 3) then you cannot mix versions and it would take a decade for people to start widely supporting it and would create a fracture in the ecosystem, just like what happened with python. &gt;So what about 1.32, can they add a breaking change for Rust 2018 in that release? No, breaking changes cannot be added to an edition, instead they will build up in nightly until there are enough to warrant a new edition. 1.32 is not the same as 2018 and will be able to compile both 2018 and 2015 code. No new version of the compiler will introduce a breaking change to these editions.
If I ever find the time this looks like I could use for a game I had my mind for a long time. Thanks for all your spent effort, the guide looks superb. :)
It was removed in https://github.com/rust-lang/rust/pull/52535 without the removal being even mentioned in the PR title or description :/
Did it really not? https://github.com/rust-lang/rfcs/pull/2366 looks a lot like a path to stabilization.
What /u/Holy_City said and you can pay monthly so there's no big commitment + there's 30 day trial. There are also a few discounts for students and such. Definitely worth checking it out. 
&gt; No, they are not available in 2015 edition, they have been worked over the past 3 years but none have fully made it into the stable release. It is not about marking a milestone, there are changes to the rust syntax that will not compile on the current version. Sorry, this is wrong. Per the Book: &gt; While some of these features are already available in Rust 2015, they are tracked here because they are being promoted as part of the Rust 2018 edition. Accordingly, they will be discussed in subsequent sections of this guide book. The features marked as "Shipped" are all available today in stable Rust, so you can start using them right now! If you read the table, you can see that the majority of these features are or will be available in Rust 2015. For example, `?` in `main` shipped already in 1.26, and `dyn Trait` shipped in 1.27 - you can use both of those in stable Rust right now.
/u/rebootyourbrainstem has a great explanation but here's the talk version by Alex Crichton: https://www.youtube.com/watch?v=4QZ0-vIIFug
Ok, thank you. Basically it's all about adding breaking changes, while allowing old code to compile with newer compiler versions. It's adding a dimension to the question of what version is required. You can no longer say "this code require rust 1.30", but you need to say "this code require rust 1.30 of edition 2015."
Note that there already is a client library for Gitlab: [https://crates.io/crates/gitlab](https://crates.io/crates/gitlab)
println debugging FTW! sample: https://play.rust-lang.org/?gist=2d80e9b32d1878056e3659ab60bc4387&amp;version=stable
Rust does have runtime polymorphism; that's what trait objects are for. It's just not the default.
Good explanation. But if there are more than one subfutures pending, a future often has no idea which one is the right spot. So when they are polled, they have to poll all of the subfutures one by one. e.g. future::Join, future::Select So when we future::Select on many sub-futures, I don't think it is such efficient.
My understanding: Point release are like sprints which if all you look at is sprints it can be hard to see the big epic stories. The editions allow the community to demonstrate the epics completed and possibly pivot some of the languages idioms. Sorta like having a checkpoint where you make sure everyone’s on the same page and all the documentation is accurate etc. My 0.02
I wonder if some of those features could be brought back to 2015 as well, when they're only incompatible on new keywords. Something like k# as a counterpart to r#, e.g. k#async.
What's great about it is that 2015 will still be the default so you can keep saying "this code require rust 1.30". There is no impact, you can mix and match crates of different editions however you want. 
That would be quite amazing. Hopefully someone will create an RFC for this :)
It sounds like asking "what features are supported in which versions". Rather, for any piece of code the question is "what version will compile this code". If I write code that compiles with 2015, it will continue to compile with 2015. New features may be added to 2015 but that does not matter to my code. My code might compile with 2018 as well. However, it might not. If Rust wants to add a new feature or change in syntax that would cause my old code to break, Rust would need to add a new edition. So, to add changes that break 2015 code, Rust 2018 must be introduced. Version 2018 cannot be used to compile my old code but 2015 can. If my 2015 code implements a crate, it can be used in 2018 projects because the compiler knows to compile my crate as 2015 version code. New features might continue to be added to the 2018 version of Rust after I complete my 2018 project. My project will not use those features but it will still compile. If a breaking change is added to Rust, it will not be added to the 2018 version. A new version would be introduced to do that.
Yeah I though so, but for some reason it cannot find the symbols while plan lldb can. 
I‘m not sure why this was downvoted. You CAN make them work today if you don‘t require construction with an arbitrary T to be part of the trait, however even that is for the most part possible in today‘s Rust. It‘s just less ergonomic and has problems around lifetimes so at least std would want to wait on GAT.
I finally have a chance to build a small tools and use Linestring::simplifyvw, it really works good for me :)
That's true, and I think this should be made clearer in the documentation for those functions. Overall I think the current design is still the right trade-off for the default case. If you have a lot of subfutures that you want to select over, it's probably a better idea to turn each one into a separate task and have them communicate with the parent over an mpsc channel. With the core of the futures ecosystem being in flux right now I think there's not a lot of focus yet on optimizing such combinators, but I think there's a lot that can be done.
I don't think we have the same definition for a microcontroller. They are too small to run Linux.
Actually, it stated as an stdlib addition! However, as it grew in complexity (in particular, when \`Join\` and \`JoinIter\` became separate types), I decided it would be better as a separate crate for now. I'd definitely be open to merging it in to the stdlib at some point, though!
Why does design of futures allow sprouts wake-ups, though? If poll() is supposed to be called on event only, why have the NotReady option at all?
Seems like it's time for a bug report!
- Cargo &amp; crates (modules) w/ static linking &amp; LTOing of all your deps - Algebraic data types and pattern matching on them - Sum types: `Result&lt;T, E&gt;` and `Option&lt;T&gt;`-based error handling - Trait-based generics as compared to template metaprogramming - A functional paradigm, with iterator &amp; sum type adapters. - Move semantics by default, by behavior. - Send + Sync traits to check if values you move across thread boundaries are safe. - Channels, Atomics, Mutexes, RwLocks, etc. are simpler to use in comparison. - The standard library covers most of your bases, without legacy cruft. - `String` from std is UTF8, and provides a large number of methods. Strings in all Rust crates are typically working with the standard String type. - Rather than a spec, we have an official implementation of the Rust core + std + compiler that is supported on all platforms. So the days of being forced to use a different compiler &amp; stdlib on a different platform is no more. - The Rust language, rather than being driven purely by a spec, is driven by a spec + implementation to prove the spec in practice, in an open forum. See the RFC process.
Which repo should I create the issue in?
In general no, this is not true on Linux. Malloc can return a pointer to memory, and that memory actually gets allocated when you read or write you it.
It does if you don't have a `~/.pi.toml`, yes. Most of the customization takes place there.
This is the subreddit for the Rust programming language. I believe you're looking for /r/playrust
How else is the execution of a future supposed to stop? The future has to tell the executor that it isn't ready with its value yet so that it can go poll other futures.
Not sure I understand "sprouts wake ups"? And it's possible to get multiple events and still not be ready. For example, you get notified of new data on a socket multiple times (probably each time making the lowest level future of your task ready) but you still don't have a full HTTP response received, so the top level future still returns NotReady every time.
Crazy guy in /r/rust.
No significant adoption because people are stupid and can barely handle Python scripting.
Because the underlying event loops can have spurious wake ups; if you ask the OS if a file descriptor is ready for reading, it is allowed to wake you up and say "this file descriptor is ready to read" even if something else has read the data on that file descriptor already. That, in turn, will trigger the runtime for futures to wake you up.
I think there is a trial though...
I think the more important note is that rust uses the Option type in a lot of its api's. std::option is still very new in C++, hence many api's still use other mechanisms. For example: a pop on a vec in rust returns an Option, while in C++ you first have to get the last element and afterwards pop it, which also means you can't pop on an empty vec (undefined behavior). This means in C++ you need probably 3 lines of code which can be done in one line of code in rust. Such things probably won't change any time soon for C+ due to its backward compatibility guarantees.
Like others have said, it's a way to remove old deprecated stuff without breaking code. You'll specify in your Cargo.toml the edition you'll build with, which means the deprecated stuff you depend on. Personally, I'd prefer that they just bump the major version and reset the minor version and implement Rust versioning on Cargo. That's really all that's happening IMO, but there's a stigma against major version bumps or something. This is their way of getting major version bumps without bumping the major version number. So yeah, just how Java 9 can compile Java 8 with deprecation warnings, Rust 2018 will compile Rust 2015 with deprecation warnings, and Rust 2021 or whatever can hard error on Rust 2018 warnings unless the crate specifies 2018 support.
It does not feel premature to *consider* it for the standard library.
I'd say the official rust repository
This was actually one of the more interesting parts of the design. Originally, \`join\_with\` simply created an iterator. However, because \`Display\` requires and \`&amp;self\`, it was necessary to introduce a new, stateless type (\`Join\`) which could be continuously reused.
Fair enough, but that method writes the entire iterator and separators to a String, which is rarely necessary. My design captures the iterator and separator, and provides implementations of various traits to do whatever you want (iterate, convert to string, `write!` to stream) without extra unnecessary allocations or conversions
Same. I do a lot of concurrent stuff, so printlns are the most effective IMO. Breakpoints mess up the execution flow, which makes it hard to reproduce the types of errors that unit tests and static analysis don't catch.
Perhaps in implementation, but I'll point out that converting joins to strings in my library is as simple as: ```rust let content = &amp;[1, 2, 3, 4, 5] let result = content.join_with(", ").to_string(); ```
Thanks for the advice! I'll put some better examples of writing to streams and iterating on the docs front page.
I strongly disagree. Let's wait and see how many downloads this crate has in a few months, and *then* consider, *iff* many people are using it.
5 PM ET happens when this comment is 3 hours and 33 minutes old. You can find the live countdown here: https://countle.com/kU22297870 --- I'm a bot, if you want to send feedback, please comment below or send a PM.
Does that mean that before generating a template you need to go through it manually to see the variables used and then define them in a `pi.toml` by hand before running the command? What would be the steps needed for me to create a new project based on the https://github.com/Keats/kickstart/tree/master/examples/complex template for example? In kickstart that could just be `kickstart https://github.com/Keats/kickstart-sample` and then you are prompted to fille the variables from https://github.com/Keats/kickstart/blob/master/examples/complex/template.toml#L14
That's just an implementation detail. As far as I'm concerned it is documented as returning null on failure. Most operating systems will probably just reserve the pages requested by the user mode memory manager and commit them only when they are accessed, but from the point of view of a malloc user that is not important. Sure, the OS may fail to commit a page if it is running low on memory, but that's not malloc's fault. 
Thanks I'll take a look! And rustic does sound way better than rusty.
no, default debugger with macOS Command Line Tools are lldb, but you can get gdb easily with homebrew. I've noticed it often breaks when they have a new release for macOS though.
I'm a woodworker and coder. I think a great name for this library would be Dovetail. Cheers
Actually, never mind. `cursive` has swappable backends, one of which are `termion`, so you could consider changing the `cursive` backend to `pdcurses` on Windows and changing it to `termion` on Unix, so we avoid the `curses` dependency.
&gt; This means in C++ you need probably 3 lines of code which can be done in one line of code in rust. Other than the safety guarantees, this is probably one of the bigger differences between Rust and C++. C++ often has a simple way which you shouldn't use because of safety or code maintenance issues, and a better way which is great but a lot more verbose. With Rust the best way is often the easy way :)
I'm no fan of the 2018 changes, but I don't understand your argument. Could you elaborate a bit? How does Python scripting relate to adoption of the 2018 edition?
&gt; maybe my wording was just off and unfair towards the people working hard on it! That, or I'm overly cautious with mine 😄 &gt; I am very eager to read your posts! Thank you! I'm eager to write them! (At present, all I have is a heap of research and a rough outline 😅.)
The syntax for function/closure parameters and for loops uses patterns, *not* variable names, e.g. `|(a, b)| a + b` and `for (k, v) in map {...}` are perfectly valid. So it's the same as `|item| { let &amp;item = item; item == 2048 }`. The `&amp;` pattern does the opposite thing as the `&amp;` expression, which means it "removes" a reference (by dereferencing). That is, you could also write `|item| *item == 2048`. There's a reason to prefer `&amp;variable` in the pattern over `*variable` at use sites: if you have more than one use of the variable, the former requires less effort/noise than the latter.
I searched real quick for sdl ttf rust and some results did come up. Is this not what you're looking for?
This is incomplete. Simpler combinators may poll all of their subfutures for simplicity, but larger ones need not do so. The key is that it is not the top-level future that gets registered for an event, the way /u/rebootyourbrainstem describes, but a `Waker` object passed down from the top-level future. Any future can create new `Waker`s to pass down to its subfutures, such that when it is re-polled it can tell which one it needs to delegate to.
About as similar as Python and Haskell are (plus static typing but minus GC). In my mind, not very similar. But Rust certainly does support some nice functional idioms.
Isn't the Futures Unordered suppose to prevent this? 
Are you compiling your project with debugging symbols? If you are doing a release build you could try building with `RUSTFLAGS='-g' cargo build`. I got CodeLLBD working yesterday and I thought that it worked really well.
Just using the debug builds for now. Haven't actually been able to work on this since the morning, but I'm going to try changing my launch.json to try it once again. 
The documentation of the `bus` crate links to a blog post by Ross Bencina (“Some notes on lock-free and wait-free algorithms”), but it looks like the WordPress install is broken. Does anyone have a copy of that post?
For those counting along, timezone_bot is 24 hours off ;)
Tracking which sub Future is ready takes significant (relatively speaking) overhead. In most cases it’s actually much faster to scan. With many sub futures (probably in the order of xx+), you can reach for the heavier combinators that specifically track which sub Future is ready, for example FuturesUnordered. They key point is that the heavier tracking strategy can be layered on top of the polling strategy, so you can opt in as needed instead of imposing the cost everywhere even when it is a net loss. 
Thank you that’s perfect! I don’t know how I didn’t find that before! I swear I did plenty of googling, though I must have tunnel visioned 😅. 
This seems rather complicated in the new futures design. From what I can tell you need to create a struct which implements the `Wake` trait, and whose `wake()` implementation stashes the information about which future was woken up somewhere and then delegates to the original waker. Then, you create a `Waker` from that struct, and then create a new `Context` with that waker which you then pass to your subfuture's `poll()`. The `Context` can be shared between all subfutures since it's only used for the duration of the `poll()` call, but you do need a dedicated `Wake` instance per subfuture and since there's no way to modify the waker of an existing Context it looks like you're still stuk recreating the context for every poll call.
No, some variables are asked for if you don't set them in `~/.pi.toml`, e.g. name and email. Using `project_init` you would do ``` pi git vmchale/haskell-ats ``` to pull a project template from github. The main difference relative to `kickstart` is that you use mustache templates rather than tera.
Awesome!
First, to whoever is downvoting my answers it's not really helping. I installed the vmchale/haskell-ats and it asked me for my name and email, which are not in https://github.com/vmchale/haskell-ats/blob/master/template.toml . How would I modify the template to ask the user some arbitrary thing, like the max length of https://github.com/vmchale/haskell-ats/blob/master/.stylish-haskell.yaml#L22 ? If it's easily doable then yeah they're not that different.
Less similar than to OCaml, which may not have typeclasses but is, as Rust, strict and supports imperative programming and side-effects without jumping through type hoops. The type systems of all three languages are practically identical at the core. Rust is the one meant for systems programming (as in "can implement its own RTS and OS kernels", not just "suitable to program grep in").
`let () = element;`
 .map(|element: ()| element.compute())
Yes, I agree! However, so far I have not seen a proposal that looks even remotely acceptable. If you have any idea, please let me know :)
rls can show the type on hover (message `textDocument/hover`), you just have to configure it to work in your editor. In LanguageClient-neovim the command is `:call LanguageClient_textDocument_hover()`.
It doesn't remove deprecated stuff really, for the same compiler will compiler both editions.
I was also kinda bummed to see the link was broken, but I did find a copy on [archive.org](https://web.archive.org/web/20170810002649/http://www.rossbencina.com/code/lockfree)
Do you use rust at work
&gt;Same. I do a lot of concurrent stuff, so printlns are the most effective IMO What's the word on an address sanitize? Or any hope for something like the google sanitizers? CLion's integration with those is a dream for debugging concurrency in C++, would love something similar in rust. 
Why does join_with allow a separator of another type?
You have to explicitly declare the "types" of the function arguments and return values in rust. Review https://doc.rust-lang.org/book/second-edition/ch03-03-how-functions-work.html for examples of functions with and without arguments and return values.
That's a fairly good argument to remove timestamps from the default.
It's a convenience method for sure :) If low-level control is needed, itertools provides [interleave](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.interleave). I think that itertools and your crate follow different philosophies: itertools provides generic building blocks for higher-level functionality, while your crate offers a complete and economic solution to one very specific problem. I really like the efficiency you achieve while still being very terse.
I don't think implementing `Clone`/`Copy` is sound here.
Right, but a new edition *will* remove deprecated stuff. I don't see a material difference between calling them "editions" or "major version bumps" except you don't get a few of the nice features of a major version bump, namely that it's obvious how long it has been since the version bump. You can bundle older compilers with a new compiler the same way editions work. The only difference is in marketing so you can say "there will never be a Rust 2.0". You could instead say "Rust 1.x will be maintained indefinitely". I'm in the same camp as Linus Torvalds: I don't like large numbers. I wish "editions" would be implemented with a major version bump because it's nicer (IMO) to deal with smaller numbers (e.g. an edition every 30 releases could be equivalently 1.90 and 4.0, and I prefer the 4.0 moniker). I don't want to have to remember which Rust version equates to a given release, it should be part of the version number. It really just comes down to marketing.
A new edition cannot remove things from the standard library, I think that’s what your parent means.
This is a great description!
Most of the things those tools detect are not a concern in safe Rust, so I think those tools would be of very limited utility in Rust. I'm far more concerned with race conditions (which Google *does* have a solution for), and I don't know of a better way to detect data races then instrumentation (e.g. Go's race detector) and printlns. Instrumentation can't catch everything and can't be done in production without a huge performance hit, so I just put lots of print statements that I can enable/disable at runtime. So yeah, I'd be interested in a race detector for Rust, though I haven't done much research into it since I'm able to solve most of my problems with safe Rust and judicious printlns.
You might check out Pathfinder and font.rs. I'm not overly familiar with either but they've popped up a couple times in this sub.
I guess, but it *can* change syntax after a deprecation warning for an edition or two. I'm aware that syntax isn't all that significant (it compiles down to the same stuff), but I could see a case for removing something from the standard library provided it's still available in older editions and that removal doesn't break newer editions interacting with code from older editions that use the old standard lib (as in, you get the union of the current standard lib + old standard lib when linking with older code). In any case, I still don't see a material difference between editions and major release versions aside from marketing. You don't *have* to be backwards incompatible when bumping the major version, but you *do* need to bump the major version when introducing a backwards incompatible change. So yeah, I'm mildly annoyed at the decision to never bump the major version, but instead get the same effect by creating a *new* versioning scheme based on years. I'm not annoyed enough to go through the RFC process, but I *am* annoyed enough to complain politely on Reddit. :)
It's totally unsound, simply calling `&lt;::slot::Slot&lt;&amp;i32&gt; as Default&gt;::default().clone();` will read from an uninitialized value :-)
Sadly, at the moment we do not have remote positions available. This *might* change in the future. For now, we only have onsite openings in the three mentioned cities.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/watchpeoplecode] [Live-coding an asynchronous ZooKeeper client library in Rust (part 3) \[x-post r\/rust\]](https://www.reddit.com/r/WatchPeopleCode/comments/92ygls/livecoding_an_asynchronous_zookeeper_client/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
It's not really clear to me what you are trying to do. Could you give some example data that you would want to store, and why?
Waaait, I thought everything related to traits (e.g. checking if something has a trait or impl a trait for something) was compile time work only ? Is this not so ? When does anything trait related get decided during runtime ? I'm obviously in the wrong here, judging by the votes, but I don't know where.
I think it depends on what's being unwrapped. Unwrapping an IO result is almost always bad form. But I often unwrap options if I know they're not None. For example, I might be popping off an internal list, and I know the list is never empty when a certain flag is set, so I just unwrap the pop.
I find them unwelcome largely for practical reasons: 1. They're useless clutter. My terminal font is fairly small, and while fully readable for text, your tiny little rocket ship is literally just an ugly little smudge unless my face is 3 inches from the display. 2. Many terminal fonts won't bother implementing most/any of them. Nobody wants their terminal cluttered with "�". 3. Rendering isn't flawless in every environment - e.g. my tmux borders go wonky with Rocket.
The new `dyn` trait syntax should help spot the difference between static dispatch, and dynamic dispatch (aka compile time vs runtime method calls). Before `dyn` / `impl` trait it was harder to figure out which one was used. E.g. if you return multiple different structs that implement the same trait you perform a dynamic dispatch. Now the method signature should reflect that too :D
Do you think we'd ever see specific deprecated methods become error-by-default on newer editions? A "stronger" deprecation without actually removing anything, that could be used on a targeted basis. The discussions I've been watching around mem::uninitialized() make me wonder if that one might benefit from error-by-default in some future Rust edition.
I doubt I, but it’s not impossible. We can’t remove it, so absolutely forbidding people from using it doesn’t make a lot of sense to me.
If I have a table like: id, name 1, hello 2, world the values are encoded as columns: id = 1, 2 name = hello, world but I need a way to allow to read it by rows, so I need to turn this in scans: 1, hello or even better, to work on row batches: 1, hello 2, world 
You can't instantiate `Vec&lt;Value&gt;`, because `Value` is not a sized type. I mean, that's what the error message clearly states, so it helps to drill down into what that means. Traits do not define a memory layout. Traits define a set of related method signatures (not necessarily implementations, but method signatures), which are related in some way specified by the trait's designer. It's just meaningless to instantiate `Value`. For similar reasons, what would the following code even *mean*? let v : Value = ...; You can't instantiate `Value` because its memory layout is not known. It's not the right *category* of type. Ask yourself this question: What would the memory layout of `Vec&lt;Value&gt;` be? Clearly there's the `Vec` data (the allocation size, content length, and memory pointer), but what I'm talking about is the actual array data. What's the *size* of each element in that array? The answer is that it's not knowable, so any program that uses `Vec&lt;Value&gt;` is meaningless and can't be compiled. "Heterogeneous array" is a contradiction; arrays (by definition) contain a *homogeneous* sequence of items. The items in the array all have the same type. However, the items *individually* can have varying contents. For example, in an array of enum values, each individual value can use a different enum variant. Or, you could have `Vec&lt;Box&lt;Value&gt;&gt;`, because the size of `Box&lt;T&gt;` *is* known, even when the size of `T` is *not* known, because `Box&lt;T&gt;` is an indirect pointer (points into the heap). What are you really trying to do? If you frame this in terms of goals, rather than "how do I make this code compile", then we can give you much more targeted guidance. 
Author of CodeLLDB here. I've seen a similar bug report [before](https://github.com/vadimcn/vscode-lldb/issues/108), but breakpoints started working for the reporter before we got to the root of the problem. Is your code available on GitHub? Can the problem be reproduced on other Macs? If you'd like, open a new issue in CodeLLDB repo with relevant details and I'll try to look into it.
Yeah, that makes sense. There'd have to be some kind of #allow escape hatch even on the newer edition I imagine. I think the whole edition concept is really freaking cool btw, I can't wait to see how it all plays out long term. :) I've become a little obsessed thinking about the possibilities lately!
Right, well the `Value` trait thing isn't going to work because you can't store a naked trait object, you need indirection such as `Box&lt;Value&gt;` or `&amp;Value`, and even then you can't easily find out what the actual value is. So your enum based approach seems best for now. You can't really do it much better with your `Column` enum, because you can't statically tell what type a column contains.
You can just keep installing new trials every month forever without ever paying, though.
Don’t know if someone’s already doing it, but I always like the idea of porting old games as learning projects. Is UT99 open source like the older id-techs? Quick google only brought up leaked stuff, nothing official.
You can just keep installing new trials every month forever without ever paying, though (which I'm pretty sure is intentional on the part of JetBrains)
I'm unable to install a local copy of the std docs: $ rustup toolchain list stable-aarch64-unknown-linux-gnu (default) $ rustup component add rust-docs error: toolchain 'stable-aarch64-unknown-linux-gnu' does not contain component 'rust-docs' for target 'aarch64-unknown-linux-gnu'
Not officially sanctioned but the next thing I build at work will be in Rust. Currently in the planning phase ATM.
Is a continuation of https://www.reddit.com/r/rust/comments/90lwe4/emulating_japlkdb_with_struct_bytes_for_flexible/. I'm looking in how encode the data for a relational language. The challenge is that is necessary both a by-column and by-row layout. But if columnar layout is the default, the row layout is only for iteration/scanning.
Is everyone else comfortable that the code could be maintained/improved by other people besides you? It would be great if there's an emerging interest and expertise in Rust among your colleagues.
The git2 dep (or rather, its libssh2-sys dep) is breaking the build on my FreeBSD box :( Instead of filling up the dependency tree I'd be tempted to just call out to `git clone` directly.
Super cool to hear y'all are using Rust. I used to work at thoughtbot down the hall from you a few years back
I don’t think so, however, I believe it’s Epic who made the engine back then. They seem really open minded about open sourcing their current engine, maybe we can start a petition or something. What could they lose by open sourcing it almost 20 years later?
How can I change the systemtime by a rust server? Should I just spawn a command? On Linux that would be `date --set="23 June 1988 10:00:00"` but maybe there is a more elegant solution?
That's pretty good for age 10. New rust book cover?
Other people have noted the alignment issue, but not the solution. For C clients, you could use a second constant, `ALIGN_OF_PARSER`; then you could say alignas(ALIGN_OF_PARSER) char parser_buf[SIZE_OF_PARSER]; However, for ease of use, I'd suggest using a wrapper struct: struct Parser { alignas(ALIGN_OF_PARSER) char buf[SIZE_OF_PARSER]; }; In Rust, you can tag structs with, say, `#[repr(align(32))]`, but this doesn't seem to allow arbitrary constant expressions, so you'd have to hard code it… In any case, getting the required alignment is `align_of&lt;Foo&gt;()` in Rust and `alignof(Foo)` in C. (Note that both `alignas` and `alignof` require including `stdalign.h`, or you can use `_Alignas` and `_Alignof` instead.)
There might be good reasons UE1 would be closed source. I know id had to remove and replace third party software for the open source releases. Considering UE4 is the first „open“ release (even then you need to register with them) I don‘t think you‘d have much luck. Why not go for something like Quake instead?
&gt; They seem really open minded about open sourcing their current engine My understanding is that it's "source available", not "open source".
Yep. Need to register on the UE forums and link your Github account. Obviously even then there are parts of the engine only available to devs under NDA or licensees.
It looks all right to me. The only things one can do with `Slot` from safe code are: - Create an uninitialized slot: `Slot::new`, `Default`. - Create a slot holding a given value: `From&lt;T&gt;`. - Duplicates the bits of one slot creating a second slot: `Clone`, `Copy`. None of these would lead to memory unsafety or other undefined behavior as long as unsafe code also interacting with the slot is responsibly behaved. The one problem I see is if T is an uninhabited type, like in `Slot&lt;!&gt;`. Things would generally go wrong in all the ways that `mem::uninitialized::&lt;!&gt;` goes wrong.
&gt; *Hat less at less point at star,* &gt; *back brace double base pound space bar.* &gt; *Dash at cash and slash base rate,* &gt; *Wow, open tab at bar is great!* &gt; *Semi back quote plus cash huh del,* &gt; *Comma pound double tilde bar close bel.* (Sung to the tune of "Twinkle, Twinkle, Little Star") &gt; It certainly looks like it ought to do something more than just print out the contents of `sing!{...}`, but that's all it did for me I'm not sure why you'd think that. The macro only does two things: invoke `log_syntax!` and repeat. There's not room to do much of anything.
I guess what I was missing was that I had never heard of [Hatless Atlas](http://alumnus.caltech.edu/~dzobel/hatless.html) before. I could see that there was structure in the `sing!{...}` block, but I couldn't figure out its purpose. The `sing!` macro itself doesn't have much room to do anything, I agree, but the input to the macro certainly looked like it was hiding something. Thanks for clearing up the mystery.
Why not? I use an enum to distinguish between separators and elements when iterating, and if you have a `Vec&lt;isize&gt;`, there's no reason to prevent you from separating with `", "`. I use trait constraints (`Display`, `Clone`, etc) to ensure that all the relevant operations are available.
Not to steal the thread, but is `cargo check` sufficient to ensure that the code will compile on a given toolchain? What about debug builds vs release builds? I mostly want to know the minimum for CI to make sure I maintain compatibility with older Rust versions.
There's [`stime(2)`](https://linux.die.net/man/2/stime) or [`settimeofday(2)`](https://linux.die.net/man/2/settimeofday), which you could call with C FFI.
Thank you so much for your help. I'm it right now so I'll create an issue with the exact details of my issue and let you know so that this can be documented. 
maybe `let x: *mut T = *mut y.z` to mean the same as `let x: *mut T = &amp;mut y.z as *mut T`
&gt; "Heterogeneous array" Yeah, this is poorly worded. So, even if not for this case, how implement a List like in python: [1, true, "hello"]?
[There is at the very least these 1996/1997 pre-release leaks available](https://www.betaarchive.com/forum/viewtopic.php?t=31878)
why do you want to use LLVM IR? you keep mentioning that, but... a. LLVM IR is not portable / retargetable. It is specific to an exact combination of OS, architecture, etc. for unfortunate reasons... so, there isn't any way this would work anyways b. you have only mentioned C and Rust, both of which are supported by WebAssembly Studio (linked elsewhere in this thread)
Check what subreddit you're posting to.
"The ironing is delicious." You meant to post this in /r/playrust (about the game), not /r/rust (about the programming language). But please don't re-post it; they don't want it there, either.
You are mistaken. All LLVM based languages (C, Rust, Swift, etc) compiles into IR. The optimizers understand and work on that code.
Why is it that `Vec::with_capacity` allocates exactly the requested capacity, but `Vec::reserve_exact` might allocate more? Is there an implementation detail of the underlying allocator showing through here?
Yes
I am not mistaken. The only LLVM IR that is useful is LLVM IR that was generated with WASM in mind. You can't just compile Swift code for macOS and then use that LLVM IR for WASM. The Swift compiler has to support targeting WASM, and in which case, it's no longer necessary to save the IR for some other purpose. Each language also has nuances that make it so just mashing a bunch of LLVM IR together is unlikely to "just work."
The docs note that it is the allocator that can provide more memory than needed. Presumably, there's code to minimise waste between the different allocator abstractions; if you're getting more memory than you asked for no matter what, why waste it?
&gt; My code might compile with 2018 as well. However, it might not. but isnt an explicit goal of 2018 for 2015 code to compile just fine too? There shouldnt be any "might not compile"?
The best solution when you can get away with it is to store indexes/offsets instead of a slice, like /u/kazagistar mentioned. This avoids tricky situations like if you need to `.push()` new elements into your vec. That might cause the vec to reallocate, which would invalidate any existing slices or references, and so the compiler won't let you do it (because it doesn't let you have a `&amp;mut Vec` while the vec is borrowed). Keeping track of indexes avoids this problem entirely, as would e.g. keeping track of keys in a `HashMap`. In more interesting cases, you could consider looking at crates like `rental` or `owning_ref`. I think those are really a last resort in production code, but learning about them is a good way to build up your intuition about Rust's ownership model.
Why are Futures so hard (unergonomic)? Are there any examples from the web which uses Futures extensively so as to see how they are used and how I may learn a lesson from them?
You're confused. I used the SAME LLVM IR on linux and windows and compiled an exe out of it. Maybe you're thinking bitcode or something else? an example of how to generate it is `clang -S -emit-llvm foo.c`
Glium github says &gt; Note to current and future Glium users: &gt; Glium is no longer actively developed by its original author. That said, PRs are still welcome and maintenance is continued by the surrounding community.
That makes sense, but in that case why not also allow `Vec::with_capacity` to over-allocate if it wants to?
That I don't know.
I checked out vulcano and rendered a mandelbrot on my GPU! That's still hard though and people smarter than me are working on gfx and piston/graphics, so I'll probably just keep working on my toy language project. ([demo of the parser so far, built using pest running on wasm](cad97.com/nafi))
Basically: Carry propagation time is longer for larger bit widths. It's not necessarily linear, though, as one might naively expect -- see https://en.wikipedia.org/wiki/Adder_(electronics)
**Adder (electronics)** An adder is a digital circuit that performs addition of numbers. In many computers and other kinds of processors adders are used in the arithmetic logic units or ALU. They are also utilized in other parts of the processor, where they are used to calculate addresses, table indices, increment and decrement operators, and similar operations. Although adders can be constructed for many number representations, such as binary-coded decimal or excess-3, the most common adders operate on binary numbers. In cases where two's complement or ones' complement is being used to represent negative numbers, it is trivial to modify an adder into an adder–subtractor. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
**[Adder (electronics)](https://en.wikipedia.org/wiki/Adder_(electronics))** &gt;An adder is a digital circuit that performs addition of numbers. In many computers and other kinds of processors adders are used in the arithmetic logic units or ALU. They are also utilized in other parts of the processor, where they are used to calculate addresses, table indices, increment and decrement operators, and similar operations. ***** ^[About](https://www.reddit.com/user/ultimatewikibot/comments/90r969/about) ^| ^[Leave](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) ^[me](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) ^[alone](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) 
bitcode is the same as IR, just a different representation. Just because something works in a trivial case doesn't prove that it works for more general/complicated stuff. Languages like C encourage library authors to use platform-specific \`#ifdef\`s, so the code that gets compiled can completely change depending on the target platform, but more fundamentally, the types are all decided at the time IR is generated. For instance, WASM is currently a 32-bit target. If you try to use pointers or arrays or anything more complicated like that, the LLVM IR will contain 64-bit pointers, and attempt to use 64-bit array offsets, etc., and that will explode when it gets compiled into a 32-bit WASM file. WASM also doesn't support the concept of deallocation at this point. It can only allocate memory. If your code tries to deallocate memory, it would explode. WebAssembly doesn't properly support the idea of a \`goto\`, it focuses on function calls, so if your code directly or indirectly (through some kind of exception mechanism) uses LLVM IR that represents a \`goto\`, then your code explodes. Going a step further, Clang will autovectorize code. If your code has AVX intrinsics in the LLVM IR, LLVM will not be able to compile that IR into WASM, and this will happen automatically if Clang sees a pattern it can exploit, since it thinks it is targeting x86\_64... and WASM doesn't support any of the SIMD intrinsics at this time. If your C code for some reason uses a \`long double\` (an 80-bit float on x86\_64), it will naturally explode. Writing just Rust means you don't have to worry about any of these things. The compiler has been adapted, so it will properly produce 32-bit WASM output (even on 64-bit platforms) and it will avoid all of the things WASM doesn't support. C compilers like Clang also support WASM, but with more footguns than Rust. Swift does not support WASM. Crystal does not (yet) WASM. If the code you depend on tries to use files, or network sockets, or use syscalls... it will explode. What other languages use LLVM IR that you actually care about? There really aren't many. Kotlin Native is still mostly hypothetical, and really, Swift isn't worth talking about outside of macOS. It only supports Linux in the loosest definition imaginable, and it doesn't even pretend to support Windows. Arbitrary Swift code isn't going to just work on WASM. I'm rambling at this point, and I'm really sorry for that, but LLVM IR is not a magic bullet. There is a reason that \*no one\* distributes libraries in LLVM IR format so that they just magically work with all LLVM programming languages... because it doesn't work.
I don't think this question makes sense without some context: why are you asking? I say that because `i32`s *aren't* the fastest, in general, e.g. if `i8` fits the data, then that may be faster because one can operate on 4 times as many values using SIMD vectors than with `i32` (e.g. a single instruction on 128-bit vectors can do 16 `i8` additions, versus 4 for `i32`), or, if `i64` is needed, using that directly will likely be faster than reimplementing 64-bit arithmetic with `i32`.
... or maybe you're on a 16-bit architecture where `i32`s are emulated.
Such a great answer! Thanks so much for your helps.
I’m asking out out straight curiosity.
I want to open a PR with the [RIIR of an internal Clippy python script](https://github.com/rust-lang-nursery/rust-clippy/issues/2882), which is about 250 lines long. Might also write a blog post to compare the two 'final' versions.
This explains a lot of things. How do you know all of this? TBH I was hoping I can write some C and maybe Jai when it's publicly released and run some code on Android. I'm VERY interested in getting some basic C running on wasm. Maybe I should try more rust.
If you are comparing i32 and u32 on a 64bit machine with C/C++, that could be because overflow on i32 is undefined behavior while on u32 is not, so compiler can ignore wrapping when using i32. I'm not sure whether this applies to Rust as well.
I've just spent way too much time learning about this stuff over the years. If you just want to run some C inside WASM, WebAssembly Studio is a great way to get started if you can't get your local toolchain working. I might also suggest trying the Windows Subsystem for Linux and see if you can get clang working properly under that. No idea what Jonathon Blow thinks of WASM. I have long wished he would make Jai accessible even just as a toy to play with, but he can do whatever he wants with his language. I think Rust would be a great way to go for playing with WASM. "cargo web", "stdweb", and "yew" are all really interesting Rust projects related to WASM.
I wish I could get people interested in stuff like this at my work. It's hard enough getting people to use python3 let alone a whole new language.
Please do!
`rustc --explain E0367` says: &gt; it is not possible to specialize `Drop` to a subset of implementations of a generic type. This limitation means that for example an `ArrayVec&lt;[i32; _]&gt;` can't implement `Copy`, because for other item types it needs to implement `Drop`, and so it always implements `Drop`. Is there a fundamental reason the `Drop` impl couldn't be made conditional on the item type?
Still un-`quote!`ing [mutagen](https://github.com/llogiq/mutagen). This is going slowly as I just returned from vacation to find the building crew wasn't finished as promised and now we have to juggle three kids through a building site...
Why do you think they are? It all depends on what you are calculating, your CPU and what you do with the result, so you have to test and meassure. You can read the manuals for the target CPU to see how many clock cycles each instruction takes, how many that can be issued in parallell etc, but it quickly becomes really complicated so it is usually faster to just tweak and meassure. Memory is often a limiting factor for bigger calculations, then a smaller datatype (ie i32/f32 compared to i64/f64) is usually faster than a larger due to less pressure on the memory system. In CPUs there are hardware parts called ALUs (Arithmetic Logical Units) that does the actual calculations. It used to be that the CPU had only a few for integers and software or microcode converted floating points to integers, used the integer ALUs and then software or microcode converted them back. That was obviously slow, making integers faster. Nowdays faster CPUs have both integer and floating point ALUs and it is common for them to have more floating point ALUs than integer dito, making it possible to perform more floating point calculations in parallell compared to integer dito.
It does not. Rust only permits wrapping and trapping on overflow, it's not UB. This applies to both signed and unsigned integers, though of course the definition of overflow differs.
It seems like the "last week's thread" link hasn't been updated? It's pointing to a 14-day-old post.
This is indeed an architecture thing. i32 is usually fast on x86 an x86_64, but it depend of the calculation. For instance from my micro benchmarks, there is not much difference between i32 and i64 for addition, but division is significantly slower. Smaller types may be better too for better auto-vectorisation or consuming less space in cache but it.
He showed you two options: &gt; For example, in an array of enum value &gt; Or, you could have Vec&lt;Box&lt;Value&gt;&gt;
I can malloc 1 Tb of memory on a Linux system with 8 Gb of RAM. Then I tried to zero that memory and at some point, after a lot of swapping, my process crashes. I have code around malloc to handle the OOM case, but that code never triggers because malloc never Reports OOM.
That looks interesting! Thank you for the article, I'll think about it.
Exactly. Well, you could make a wrapper over malloc that simply accesses a byte in each allocated page, forcing the OS to commit the pages at that moment, but it won't be of much help. One could argue that if the system is low on memory there is no point in trying to do some cleanup (close connections, files, etc) in your process. Now, on smaller, embedded systems the reality is another. On the other hand, Windows gives you the chance to register a custom exception handler and will let your process handle the commit failure. I don't know if you can handle something similar on Linux. As far as my knowledge goes the OS may simply decides to kill your process when the system is low on memory even if no fault happened in your process.
Curiousity is great and important, but I was looking for something a little more specific: what made you think they are fastest?
How is this different from just including some examples folders in your project, with their own Cargo.toml files, and then running them with `cd examples/example &amp;&amp; cargo test`?
This is simpler, more graceful and able to save compile time using incremental compiling as well.
So you could, with the RFC, do something like: cargo --example bench to run all benchmarks on the examples projects?
I'm not OP, but the reason I might ask a similar question is that I notice int in C (on x86 at least) and the default integer type in rust are both signed 32 bit. Is that because that's the fastest type to do basic math on? Or is there some other reason language/compiler designers converge on that type?
They aren't, at least not in general. Signed integers _can_ be faster than unsigned ones in C and C++ programs when used as loop indices because signed integer overflow is undefined behavior and therefore the optimizer can assume that it does not happen. This means that the optimizer can assume that `for`-loops terminate, and that overflow conditions do not need to be handled. OTOH, `unsigned` integers wrap around on overflow in C and C++, and those cases need to be handled.
Writing a game! (sdl2, gl, liquidfun). In a long time from now when the game is more developed, I'll do a write up. So far I will say that [notify](https://crates.io/crates/notify) has been a boon for live editing!
I started working on a Python package wrapping my [point process library](https://github.com/ManifoldFR/point-process-rust/tree/master/pylib) using Pyo3 and setuptools-rust. I was a bit confused at first as to how to wrap my custom types to cast them into PyObjects, and how library produced by setuptools-rust was structured. But setuptools-rust provided some nice abstractions to get stuff like renaming files and copying them out of the way. I'm still working on it and need to figure out how interoperable this is with `ndarray` and NumPy, but I'm hopeful I can get a working package on PyPi soon enough.
Stop playing rust and start programming rust You'll be happier that way, I guarantee it. 
If you access a byte and memory fails to commit the process crashes while malloc should instead have reported an error.
Not exactly. You may run `cargo bench --example &lt;NAME&gt;` to benchmark one example. I haven't provided a way to benchmark all example projects yet. It might be up to the Rust developers to decide whether benchmarking all examples at once is useful or not.
It's also worth noting that you may want to compile examples with a different rust version. For example run benchmarks on nightly.
Thank you for noticing me. I think folder-based examples are the same as what we have for single-file examples, thus which rust our example depend on is the same as what our root project does. I’ll mark out as well.
I always wonder how it's possible to overlook that this sub is not about the game.
&gt; even then you can't easily find out what the actual value is. There's always [Any](https://doc.rust-lang.org/std/any/trait.Any.html), but it's not necessarily the most convenient.
The guessing game example in the rust book has an example that looks very much like yours. https://doc.rust-lang.org/book/second-edition/ch02-00-guessing-game-tutorial.html#processing-a-guess Try to remove the following in your example fn Userinput() -&gt; { let mut user_input() = String::new(); } And add the following instead let mut user_input = String::new(); io::stdin().read_line(&amp;mut user_input) .expect("Failed to read line"); println!("The user input was: {}", user_input); But also read the chapter in the rust book. It covers most of the problems that you had in your original code.
Fantastic explanation, thanks!