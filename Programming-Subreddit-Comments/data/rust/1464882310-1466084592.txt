Well done and thanks a lot for writing this!
Great post, well written and very insightful :D
Thanks a lot! Just started to learn Rust some days ago and the `try!` macro was somewhat confusing to me.
Wow, this is really well written and researched, much better than most posts see on Reddit.
Is it possible to print the address of a built-in type? e.g. in C I can just &amp; the var and print out the address.
What if it's a separate file, but still a child module of the one with the struct? 
That should work too; it's identical as far as the compiler is concerned.
Someone please correct me if I'm wrong: &gt;So are most operating systems expected to have things like libc installed? Yes, you're expected to have libc installed. You can compile a rust binary [without the libc dependency](https://doc.rust-lang.org/book/no-stdlib.html), but you can't use the standard library. &gt; I know on a debian system I get most of that stuff through build-essential package. This installs the essentials for general development. e.g. `libc-dev`, `g++`, `gcc`, and `make` to name a few. This are all required for *building* a binary, but not running. Notably, `libc-dev` installs some headers and other things for *development* purposes. &gt;What happens if i were to run a hello world compiled binary on a fresh install of windows 10? Does it come packaged with those systems, or do i need to provide it? `libc` is packaged with the system. Any application written with C that uses `libc` functions and dynamically links to `libc` (which is most C applications) will need the library to be provided at runtime. If it wasn't provided by default on the system then your shell, and probably most of your daemons would not work. &gt; I know when running games I will sometimes see an install run for Visual C++ Redistributable. This I think is to ensure that the version they build against is installed on the system.
There is a static linux project around started by the guy who did tinyc (last i checked it had a shell and a few of the standard tools). I believe it still provides libc for dynamically linked stuff, but you could conceivably remove it and still have an OS
Nice post! I was planning to write about this as well but you beat me to it. Some comments: IMO, the best way to figure out where you are expending your binary size budget is to use the command `nm --size-sort -C $BINARY`. You get a list of symbols along with their sizes. Here's is the (partial) output of that command on the LTOed, `panic=abort`ed hello binary: 00000000000009eb t std::panicking::rust_panic_with_hook::h587239a80cad02d2 0000000000000cf5 t elf_add 0000000000001341 T main 0000000000001387 t std::sys_common::backtrace::output::h850e7761036af99f 00000000000015df t _$LT$$RF$$u27$a$u20$T$u20$as$u20$core..fmt..Debug$GT$::fmt::h92e5b758dfba57eb Those are the biggest symbols in the binary. One can shave ~60KB off the binary by totally removing the backtrace functionality (i.e. `RUST_BACKTRACE=1`). But, currently, this is not easy to do as you need to [patch](https://github.com/japaric/rust/commits/cfg-backtrace) the Rust repository and recompile `std`. Yet another way to reduce the binary size is to set `opt-level` to `s` or `z`. Those optimizations levels optimize for binary size rather than for speed. I don't know if you can set these optimizations levels via `Cargo.toml` but you can use them via RUSTFLAGS as in `RUSTFLAGS="-C opt-level=z" cargo buid`. On hello world this doesn't provide much gain: ~100 bytes smaller (~0.2% of 49KB), but on a program that does a single hyper http request the reduction is ~50KB (~4% of 1MB).
Awesome I'm glad that helped you out! If there's other topics you're having trouble with let me know so I can write more posts in the future aimed at problems new users are having
Use the [byteorder](https://github.com/BurntSushi/byteorder) crate. extern crate byteorder; use byteorder::*; use std::io; use std::io::Read; use std::fs::File; use std::io::Seek; use std::io::SeekFrom; fn main() { let file = File::open("example").unwrap(); let mut string = String::new(); file.read_to_string(&amp;mut string).unwrap(); file.seek(SeekFrom::Start(40)).unwrap(); let float = file.read_f32().unwrap(); } `
To be clear, you're referring to the gc-sections thing? (To be clear, I believe C compilers make sections for entire *files*, meaning --gc-sections is ineffective if every file is used a little bit)
Different binaries running on the same system *could* share all of their dynamic dependencies with suitable alignment specified in the ELF file (+/- a few pages of slack at the start and end), mapped from the page cache into those processes. I don't know how well this works on Linux in practice.
Makes sense. Never thought about it before really, but it sure is handy when you can depend on a machine having x library installed. Thanks for the reply
I say it's a red-herring because the explanation you gave implies LTO should be killing basically several MB (libstd is big!), but you only trimmed ~30k (and your binary was already under a MB). It's also not clear how much LTO is killing from Rust stuff and not e.g. libunwind/jemalloc/debuginfo -- LTO was visited before you addressed the "big" offenders, and never re-evaluated afterwards.
`println!("{:p}", &amp;var)` should do it.
You need to clone the Arc outside the closure, and only refer to the clone within the closure, so the original one doesn't get captured (which would defeat the purpose of cloning). I wrote [a macro](https://crates.io/crates/closet) to use if you do this a lot.
Note that UPX compressed programs will often show up as false positives for antivirus scans, because quite a few viruses have used UPX in an attempt to obfuscate their binaries.
You're right, I was being overly simplistic in trying to describe the difference between FnOnce and FnMut.
Yeah, seems good :)
Enums would be a great topic. * How to convert an enum to a `String`. * How to get all enum values of an enum. * Comparing enums. In Java there is a `values()` method to get an array containing all enum-values. Haskell has another elegant way to do the same, just derive your enum from `Bounded` and you can get a list form the minBound to maxBound enum-values. I would like to know an elegant Rust way to do the same. On the web I found the code below, but I don't like it much: pub fn iterator() -&gt; Iter&lt;'static, Dist&gt; { static DIST: [Dist; 3] = [ Dist::Debian, Dist::Suse, Dist::Ubuntu]; DIST.into_iter() } Another topic I haven't looked up til now is how `map`, `filter`, `reduce`... can be used in Rust. Edit: [Another reddit post](https://www.reddit.com/r/rust/comments/29sk5d/iterating_over_static_enum_values/) about the topic of creating an enum-iterator.
The mnemonic here is "pointer".
Cheers that solved the issue, only had to pass a reference to make it a `FnMut`.
I believe you can dynamically link musl. At least the musl makefiles build a dynamic/shared library...but I haven't tried it.
&gt; all in one file when doing black-box testing. White-box testing. Black-box testing is when you *can't* see the private members.
I might be missing something, but $ git clone git@github.com:enjoyscuriosity/rust_libposix.git $ cd rust_libposix/ $ rustup override add nightly $ rustup target add x86_64-unknown-linux-musl $ cargo build --target=x86_64-unknown-linux-musl $ ldd target/x86_64-unknown-linux-musl/debug/librust_libposix.a not a dynamic executable Seems fine over here?
An extra note: Rust links that differently depending on whether you use the GNU or MSVC version of Rust. The GNU linker likes to ignore the potential DLL-hell and (against warnings not to) links to the MSVCRT included in windows, while the MSVC toolchain will link to the dynamic vcruntime associated with the MSVC toolchain you have installed on your system (either 2015 or 2013 iirc). Just something you need to keep in mind!
Actually, it's not that smart. The closure returned by `f` is a single type. See this https://is.gd/4SAZ3j
Yeah, it has always been this smart. If only it were just a tiny bit smarter, perhaps it could infer the `fn(...) -&gt; something` type for closures that don't capture anything :)
Not like this is of any importance but 650711 ~= 635 KB (not 650). Next time, you should *instinctively type* `ls -alh` :P
I agree with /u/Sean1708 that having `A` _own_ its contents is a lot more flexible, and a good idea if you can get away with it. But if you really want to hold references, then I suppose you could move `a` to a new binding with a shorter lifetime to make it work: let b = B { }; let mut a = A { b: vec![&amp;b] }; let d = B { }; let mut a = a; // this moves `a` to a new binding that gets destroyed sooner a.b.push(&amp;d); That solves the immediate `error: d does not live long enough` problem that you were running into. (Though it might've been easier to just move the declaration of `d` higher up, next to `b`?) However, if you want to actually _mutate_ these `B` instances while `A` is holding a shared reference to them, you'll have to wrap them in an "internal mutability" type like `RefCell` or `Mutex`. Otherwise the shared reference guarantees they'll never be mutated.
Just calling `take` _will_ leave the iterator unchanged because it creates an iterator adaptor named `Take` which is lazy and does nothing until it's consumed. It's the same for most adaptors. Using the for loop consumes the adaptor which in turn advances the original iterator.
Thanks. I tried {:?} with &amp;var at {:p} with var, not sure why I didn't try that. Probably because I associate address with that symbol rather than a reference. It seems that Rust defaults to using the value even when provided the extra '&amp;' symbol.
This is a great writeup and I enjoyed reading mostly things that I would have explained to people asking this but never had the time to do a comprehensive answer--but yours is great. I think the real problem here is the way people are expect a compiler to work by default. I think that Rust in general will do a much better job at teaching people about the details about compilers than C or C++ ever will, by simply being explicit.
Not on x86_16 (a platform I regularly write C for) :P
I have another question to testing, is not possible to use the following command for tests in the /tests directory? `cargo test -- --ignored`
&gt; Those starting with backtrace_ and DW_. These are yet another names from libbacktrace, a library to produce stack trace. Rust uses it to print a helpful backtrace on panic (available with RUST_BACKTRACE=1 environment). We don’t panic however. This is incorrect, this program can indeed panic. Take a look at the docs for `println!`: http://doc.rust-lang.org/std/macro.println!.html &gt; Panics if writing to io::stdout() fails. `println!` is the fast-and-easy macro for small code examples and println-debugging, and so it forgoes robust error handling. The robust, non-panicking macro for writing to a buffer is `writeln!`: http://doc.rust-lang.org/std/macro.writeln!.html
Yeah but that's like... a speed bump at best. That's C-tier type safety.
No it's 635 KiB, 650 KB was correct.
I have an issue with the lifetime of an associated type. The code [looks like this](https://is.gd/DJkILl). Is there perhaps a trait bound for `Index` that would make this compile? I tried making it `Copy` but that didn't work.
Do unit tests need to be performant? I can understand needing absolute control for performance reasons for code thats actually running on real devices or on a production machine, but for just running unit tests I would imagine that the performance hit shouldn't be a concern since you're just testing for correctness, not speed.
You're confusing abstractions for names of abstractions. For instance: &gt; Having the same operation named differently on different entities is not consistent. In mathematics, the statement "x = 1" gives two different names to the same abstraction. This is not inconsistent, it is powerful. &gt;Also, it does matter what you call them, a lot. It matters *pedagogically*. It does not matter *intrinsically*, nor should it matter to someone who thoroughly understands the abstraction, as you claim to. &gt;Good abstractions are intuitive (that's the case with flat_map = map+flatten). No, that's not intuitive. Maybe `for_each` would be intuitive, but `map` is distinctly mathematical jargon, and `flat_map` even more so. But why not call it `morphism`, since that's probably the least ambiguous? &gt;You can "sort of get what's going on" even without knowing these abstractions. That's a contradiction. Knowing the abstraction is the same thing as "sort of getting what's going on."
Well the unit tests need to not be slow, but you're right that they don't need to be as fast as the actual code. That's not the issue though. If you use trait objects to mock your code, then you will always have that overhead in the actual code even when you're not unit testing. Slowing things down just so you can unit test is very undesirable.
in memory (the size of the executable)
Making `mopafy!` work with `custom_derive!` is a good idea as an option, for people who use the latter already as it is semi-pseudo-kinda-standard.
This is a short, novice-orientend article where I'm explaining the difference between `&amp;` and `ref` when used in `match` patterns. It was something I had some difficulty understanding myself, and I think it may be useful for other people learning Rust.
For reference on Scala, the Either is completly unbiased so you have to first project to the side you want and then map it. For example with val x = Either[Err, Value] x.right.map { ... } x.left.map { ... } This can be bothersome when doing stuff like going over a bunch of Results with flatMap as you have to always project the right side. Fortunetly there are libraries like scalaz or cats. In cats we have the Xor[Err, Value] that is right biased.
I take some small issue with "not a part of the pattern itself." It is part of a pattern, but controls how that pattern binds things, rather than changing what the pattern matches. But, overall, great post, and that is a nitpick. `ref` is counterintuitive at first, we get a lot of questions about it in `#rust-beginners`.
You can explicitly say that `D` lives at least as long as `'a`. trait Data { type Index; //... } struct View&lt;'a, D: Data + 'a&gt; { data: D, indices: &amp;'a [D::Index], } fn main() {} 
Bingo. In the grand scheme of things 640kb just isn't that much. For example, on of my Java distributables is 50mb big. The only place this matters is in limited space embedded systems. And those are starting to erode to nothing.
Yeah based on the other responses (or lack thereof) it seems like the only way to unit test stuff is to write wrapper traits and use generics. This is unfortunate since with the standard library it actually isn't always possible (without adding a layer of indirection).
&gt; This is unfortunate since with the standard library it actually isn't always possible (without adding a layer of indirection). What specifically are you thinking of here? There aren't many std types that have direct dependencies on other types.
Thank you! I guess the error message confused me a bit, but it makes sense now.
you can build the cargo stuff just fine. But please read to the bottom, as you can see, if you cd to src/test, and then type make you should get the compile error I'm talking about
&gt; This is incorrect, this program can indeed panic. Should I have written "we don’t panic *ourselves*"? :) (I'm going to change the text in any case, just to be sure.) You are technically right, but that does not matter much in this example.
[removed]
There's also https://github.com/tedsta/deeplearn-rs.
I mean by better than C++, shorter.
More things should be "novice-oriented", because more often than you'd think it only takes a little tweaking to be helpful to people who just need to refresh their understanding. Nice work.
Being the original questioner, thanks for the write up :D It actually answered a lot of important questions I have about rust. But it also raises more. Let's say I want to dynamically link everything. Where do all those compiled artifacts go? Is there something like a .jar format in rust to hold everything? Does it all go live in /usr/lib where newer versions overwrite older versions?
Sure, but your comment seems to me to say that there is something different about the standard library compared to your own code - I'm trying to understand what that difference would be. The layer of indirection is the same layer of indirection you need to mock at all.
Thanks, great post. That was really confusing me, but I think I get it now.
&gt; So instead I would have to make a trait and struct implementation that wraps the existing standard library types. You can implement traits for other library's types. This is one of the big advantages of Rust's traits over interfaces in other languages, eg: https://is.gd/lmoVeG
Yes you can, but that doesn't help us. The trait implementation would need to call methods on the struct. There's no way to just say "all these methods are already implemented, so just use those": https://is.gd/YFIppG This is actually a case where interfaces (like in Go and TypeScript) would be more useful. Though it's really only because A) the standard library is pretty incomplete and B) Rust has really strict rules on implementing traits - rules that we might be able to change later.
Listened to this today, really enjoyed it. This podcast is great for listeners of all skill levels!
I consider having to provide a one line delegation method to be _a lot less_ boilerplate than having to wrap std types in new types. You just have to write a line of pretty simple code for each method you want, as opposed to having to wrap/unwrap the type at all the boundaries to your system. I doubt Rust will ever infer implicit implementation based on inherent methods matching the signature of a trait, but I could see there being some sort of delegation sugar (e.g. perhaps if you're missing a required item, it looks for a matching item in the inherent impl of the type). I personally don't find it to be a problem, though. EDIT: this idea seems like its worth pursuing - using the inherent item of the same name and signature if its missing from a trait impl, then you could just do `impl MyUdpSocket for UdpSocket { }`
You are looking for /r/playrust
It's actually almost the same amount of boilerplate, just slightly more complicated: https://is.gd/fLmcCE I agree that the first impl is simpler, but it's still really annoying boilerplate that should be avoidable. This is definitely a case where the less code someone has to write, the less likely they are to introduce bugs. I think Rust will definitely have a way to avoid this situation in the future. I didn't mean to say that Rust will start inferring implicit implementations - that would be terrible! - but maybe we'll add the option to say it's okay in certain circumstances in the future. Anyway, it's sad that there's no way to deal with this ATM.
&gt; map is distinctly mathematical jargon True, and `flat_map` is consistent with it, but that's my personal taste. Bind is okay. `for_each` is ambiguous, because it could also mean `map`. But which source on mathematical concept of monads does use anything close to `and_then`if a user wants to refer to? &gt; why not call it morphism because it's too ambiguous &gt; It matters pedagogically &gt; thoroughly understands the abstraction, as you claim to For any sizable software, it is safe to assume that people in the team do not thoroughly understand every single matter in a project, especially as they come and go. I'd argue that pedagogical matter is very important for continued development and support. Otherwise [things like that](http://jimplush.com/talk/2015/12/19/moving-a-team-from-scala-to-golang/) happen. Abstractions and their implementations are not only performance-costly, they also have a cognitive cost, measured in very down-to-earth bucks. The matter being discussed here is not about abstractions at all - we somehow all agree that monads are ok - but rather about API in general. Good APIs should be intuitive ([set you on a right track](https://blog.codinghorror.com/falling-into-the-pit-of-success/)), abstractions or not, whether you write new code or read existing one, and they should definitely not become confusing just because you *do* know a few more concepts. `expect` is strictly counter-intuitive, and `and_then` is not nice too, at least for me the first thing that comes to mind is function composition.
What's the difference between ' for x in foo' and 'for x in foo.iter()'? Also, can you use &amp; for x? Or is it already a reference? Or is that determined by iter vs iter_mut? 
When I can buy a [BBC micro:bit](https://en.wikipedia.org/wiki/Micro_Bit) (or three) I’d like to get some Rust code running on it. It has a 16 MHz ARM CPU with 256 KB flash memory and 16 KB RAM. **But** this is definitely not a default scenario for Rust: there’s a limited instruction set and no operating system. I’ll likely take the time to define a custom compiler target, use `libcore` without `libstd`, use a custom panic implementation that does `loop { }` without unwinding, etc. And it’s great that I *can* do all that (even if only on Nigthly for now) to support exotic scenarios.
Most of these low-memory, bare metal embedded systems run programs that don't do dynamic memory allocation though, no? (All memory is allocated at program start.) For Rust, this would mean running with #![no_std] and no jemalloc linked in the executable, then. So much smaller base executable size...
"Type tetris" is a nice descriptive term I picked up from the haskell community for the feeling if trying to piece togeather how a library works from the type signatures alone due to lacking docs.
[removed]
No. The backtrace consists of two things, unwound list of stack frames *and* resolved symbol names. The former is handled by libunwind and the latter is by libbacktrace; stripping debug symbols disable the symbol resolution but not stack tracing (only dependent of ABI). I hadn't checked at the time of writing, but it indeed seems to be a libbacktrace problem; the nightly libbacktrace is fine with stripped executable. thread '&lt;main&gt;' panicked at 'Hello, world!', src/main.rs:2 stack backtrace: 1: 0x7ff056adb6f8 - &lt;unknown&gt; 2: 0x7ff056adb51e - &lt;unknown&gt; 3: 0x7ff056ad72aa - &lt;unknown&gt; 4: 0x7ff056ad519e - &lt;unknown&gt; 5: 0x7ff056ad5155 - &lt;unknown&gt; 6: 0x7ff056ade478 - &lt;unknown&gt; 7: 0x7ff056ade4ab - &lt;unknown&gt; 8: 0x7ff056ad5c20 - &lt;unknown&gt; 9: 0x7ff055eccf44 - __libc_start_main 10: 0x7ff056ad5048 - &lt;unknown&gt; 11: 0x0 - &lt;unknown&gt; 
I'd probably go one step further and [use Rust's type system to compile-time check the correct use of the underlying state machine](https://insanitybit.github.io/2016/05/30/beyond-memory-safety-with-types) the way crates like [hyper](https://github.com/hyperium/hyper/) do. (If it's good enough for things like "Can't add a header after you've sent the HTTP request", it's good enough for things like "Data chunks have no meaning until we've read the framing metadata from the stream header".)
Thanks to all who answered me. It may be off topic. Is there books on how to use any language to implement any algorithm? Or is it something I've to figure out on my own?
Every value constructor needs a dual "pattern destructor". They are generally written the same -- `(a, b)` vs `match e { (a, b) =&gt; { ... } }`. However, since pattern matching with a variable does a *move* of the value at that location by default, and we still need to enable pattern matching on values you can't move from, we need to add a way to indicate that a value should be bound to by-reference instead of by-move. Thus, adding `ref` when you want to refer to the value at that location, instead of move from it.
In what situations would one prefer `let ref` to `let` with `&amp;` and vice versa?
I merged it thanks !
When you do `for x in foo` Rust calls the `into_iter` method on `foo` to get an iterator, and then it basically just uses a while loop to iterate through all the values. `into_iter` turns the thing you call it on into an iterator ie. it actually moves the values, so after calling it `foo` will no longer be available (it got broken apart and passed in to the for loop). If you call `iter` instead then `foo` will construct an iterator that returns references ie. it won't consume `foo`, so you can still use it later, but you won't be working with the actual data, only references to them. Rust actually then calls `into_iter` on the result of `iter`, but `into_iter` just returns the object it was called on when called on an iterator. Take a look at https://doc.rust-lang.org/std/iter/index.html#for-loops-and-intoiterator for more. In summary: if you want to keep using the collection later, use `iter`, otherwise use `into_iter`. If you use `for &amp;x in foo` you'll get a type error. In this case, `foo.into_iter` is giving you actual objects, not references, so `&amp;x` doesn't match. If you do `foo.into` then it works because you're getting references. You can't make something a reference by doing `&amp;x` there - instead, it sort of acts like a pattern match. `iter_mut` is like `iter` but it gives you mutable references to the data in `foo`. This also means you can't do anything else to `foo` until the for loop is complete because you need to take a mutable reference of `foo` in order to call `iter_mut`, and that mutable reference doesn't go out of scope until after the for loop.
Thank you for your explanation. I will try to change my code accordingly.
But sadly `ref mut` would become `* mut` and it would be confusing because there is actually no relation to the `*mut T` type.
Because gdbm is not going to be found, that stopped you from seeing the error come back. I've tried it with musl-gcc without -lgdbm and that didn't work.
I find Clippy to be a big help when it comes to "Is this idiomatic". But more to your point - Rust is a weird language. On the one hand, it feels functional, but certainly not pure - unchecked side effects exist, and are even encouraged at times. There definitely is a focus on performance. In most FP languages you simply accept copying, whereas many rust libraries have a focus on 0 or 1 copy approaches. So when do you choose ownership over references? Return values over mutation? I think it takes a bit of getting used to and some amount of internalization of what 'moving' means for your API. If a consumer of your API should not have access, or does not need access, to the data being given to the API - enforce it, move semantics are great here for this. However, sometimes that's not viable for performance reasons - the parameter/ structure may be huge, so any chance of a copy would be too costly, a mutable reference is necessary. Or maybe, semantically, a reference/ mutable reference just makes more sense - multiple borrows are expected for the use case. The std::io library is an interesting case to look at, in my opinion. std::io::Read takes mutable references to a buffer, and fills the buffer. But the operation can fail: fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; Result&lt;usize&gt;; I can ignore that result by simply assigning it to _. And then I've got a buffer that's potentially in some weird, invalid, unexpected state. The choice was made to take a mutable reference despite this because if you implement this with a move instead of a mut ref, there's a performance hit. Or at least, I'm assuming that's why - in my tests the performance hit is definitely there when you implement Read using move semantics and return values. The point is that someone had to make a choice here, and you'll likely have to make your own choices in a similar vein. Sometimes it's clear cut, sometimes it's not. I don't think there's really consensus for what's idiomatic so much as you're given the responsibility of choosing your priorities. tl;dr - Purity is a tool in rust, and not a constraint. Use it when it makes sense to enforce aspects of your API, but know that rust has a totally different core approach to safety than FP languages.
I'm attempting to match a command line with optional parameters using regex. The pattern I have is: ^!file(?:\s(?P&lt;name&gt;[:word:]+))?(?:\s(?P&lt;dest&gt;[:word:]+))?$ The command line would look like one of these three alternatives: !file !file filename !file filename destination The thing is, I always get 3 matches regardless of usage (as long as the line starts with !file). When inputting a filename, it correctly retrieves it when using .name("name"). When there's no filename, .name("name") returns None (as it should), so it doesn't seem like it's erroneously capturing something else.
That's what I ended up doing here https://users.rust-lang.org/t/artisanal-mocks-locally-sourced-organic-unit-tests/5890 . It's not "pretty", but it got the job done.
The idea that statically linking msvc runtime is unstable needs to be put to rest. You can't allocate and free memory across DLL boundaries for the same reason - it might have been done with a different heap function. Static linking just requires you know what you are putting in and how you are using it.
From their kickstarter page: "There are two components to Imageflow: imageflow-server and libimageflow. libimageflow is built with Rust and C, and imageflow-server will use Rust exclusively. "
Note that a while back, that was moved in-tree: http://doc.rust-lang.org/stable/style/ That said, it still hasn't really been touched in a very long time.
I will send you a PR.
Just to help you understand, you are being downvotes for lack of content or reasoning behind your statement.
You can use the `Iterator::count()` in the `fitness` function: target.chars().zip(sentence.chars()) .filter(|&amp;(c1, c2)| c1 != c2) .count() Also, the whole algorithm could be changed to use `Vec&lt;u8&gt;` instead of `String`. It will be faster, and imo more idiomatic, since you're using the string as an array of chars rather than text. In addition, it would make it easier to refactor if you decide you need random acces at some point. Rust allows you to write `b"abc"` and `b'a'`, so using such bytestrings is quite convenient. (And if you want to go beyond ascii, I'd go with `Vec&lt;char&gt;`, unless you really care for memory usage.)
I've found it interesting and would love to see few more features (mainly animated gifs - processing them without threads is dead slow). I am not affiliated with this project. 
Maybe it's something to do with my box. I'll try and see if that's what is going on.
Here are a couple of suggestions I can give after a quick look. In **parser.rs** I would change `is_id_char`to use a `match` fn is_id_char(c: u8) -&gt; bool { match c { // 0-9 A-Z a-z hypen (-) 48...57 | 65...90 | 97...122 | 45 =&gt; true, _ =&gt; false, } } If you want to space it out more vertically you can do one branch per range too. I am not absolutely certain this is more idiomatic (other opinions needed) but it is how I would write it in Rust. There exists a method for this `0 == remainder.len()` special case: [`is_empty()`](https://doc.rust-lang.org/std/primitive.slice.html#method.is_empty). You seem to use it in other parts of the code, is there a reason for not using it here? Otherwise I don't have a lot to say. Your code is clear, well formatted and well documented. Good job! :)
I haven't seen any Rust file and their README contains this unchecked point: &gt; Begin porting the most complex bits to Rust. They have a branch called "rust", but... the couple of rust files present contain mostly C code. Strange...
You might also wish to include something on how much memory the programs use while running. I don't recall, do the debug sections actually get loaded? Then there's the whole shared vs. resident numbers. A program dynamically linking against libc is going to be big if you count libc, but should you count libc, since all the other programs are sharing it?
&gt; Although in Haskell it's just &lt;&gt; or V.++ assuming import qualified Data.Vector as V And similarly in OCaml. This is what I mean to do in Rust, however because of how data is manipulated in Rust, this approach just seems to fall into a number of issues with moves and borrow lifetimes that are hidden and handled implicitly in a GC'ed language where every value is boxed.
Good points on both suggestions. The only reason I can think of for not using `is_empty()` is me being inconsistent. Thanks for the pointers!
Thank you for writing semver! I heavily used your library as a reference for handling parsing. With my near non-existent experience with nom I wasn't able to find much room for improvement. Just wrapping my mind around how nom works at all was also a fun learning experience. Is the new parser you're working on in the same repo as semver? I found several branches in the repo and wasn't sure which would it would be in.
That sounds very interesting! Is there a place where these patterns are documented with easily accesible, standalone examples? As a Rust newbie, I think this would help a lot - specific, small pieces of problematic code in other languages that can't happen in Rust.
With the caveat that only the stack items are copied -- as opposed to many FP idioms where a deep/heap copy (which may be a partial deep copy with a persistent data structure) is performed instead of mutation in place.
True... perhaps raw pointers should have gone with `^mut T` instead to avoid that ambiguity. :P
I actually took over maintenance, so don't give me _too much_ credit; though I am slowly re-writing most of it. https://github.com/steveklabnik/semver-parser/blob/master/src/range.rs#L673-L682 is what's failing right now, and what's preventing me from fully replacing the existing parsing in `semver` with `semver-parser`. Basically, I haven't figured out a good way to reject bad output. My current strategy is too nice, and allows too much junk.
Interesting, I wasn't aware of that. So if I pass a Vec allocated on the stack, pointing to the heap, into a function via 'move' only the pointer/ size/ capacity will be copied? Not the data behind the pointer?
Yeah, I understood *that* part - and now that I'm properly awake I also understand what I wasn't getting earlier. I read the snippet I quoted as referring to the previous section about `&amp;`, rather than prefacing the discussion of `ref`. It seemed written as if it contradicts something said previously, which is just not the case. I was (or am?) clearly confused about *something*, not but not about the syntax and semantics of the code.
Isn't leaf defunct in favor of TensorFlow?
Its not defunct. Its no longer developed by its original authors, but it doesn't mean its not usable. 
Rust 1.9 (released 7 days ago) fixed our biggest blocker. We intend to port the entirety of imageflow-server to Rust. We're also just wrapping up the libimageflow API design for use from host languages, and, well, it's easier to design/test C ABIs from C, initially. The part I'm least confident we can complete in 12 months is a rust port of the jpeg codec (although nwin already started work! https://github.com/nwin/rust-jpeg). So it may end up a hybrid C/Rust binary in version 1. 
Actually, rustdoc search does support searching by type signature. It's not as good as hoogle, but it gets the job done.
We've been testing core algorithms ever 45 days or so against the rust releases (diff. repo). 1.9 fixed our biggest blocker, so you'll see a lot more Rust soon (assuming our Kickstarter doesn't flop, which looks increasingly likely).
It is for personal information management, so it is for inidividuals. Multi-user is not planned. What it does: It aims for covering every aspect of personal information management, but it does not want to reimplement tools. You use taskwarrior for your personal todo management? Fine, we provide an interface for it (not yet, but planned and WIP). You have a personal wiki? Nice, we want to interface with it. What imag wants to provide you at its very core is to _link_ the information inside your wiki, your todo manager, your mail application, your &lt;insert tool here&gt;, so you can easily reason about data which belongs to eachother. The originial problem I had was that I have (for example) a mail "Buy some eggs", send from one of my contacts. I create a task in taskwarrior "Buy eggs", also I set it onto my buying list and I have a wiki entry in my personal wiki on which eggs to buy and which kind you shouldn't buy. I also add a calendar entry in my personal calendar when I want to go shopping. I had no possibility to link this data in any way. Imag wants to fill this gap. With imag, you can link: ``` contact &lt;-&gt; email &lt;-&gt; task &lt;-&gt; shopping list &lt;-&gt; calendar entry &lt;-&gt; wiki ``` (and more, the markup does not provide me a way to visualise this properly. In the end you will get a _net_ of data points) `imag` is CLI only. We do not have much covered yet, taskwarrior is the first external tool which will be interfaced with, but I aim for a bunch of tools to interact with. If required, one can easily swap backends of imag interfaces. Don't like taskwarrior? We have the necessary infrastructure to just add another todo-tool backend and provide a functionality to use your other tool for "todolist management" interfacing. Disclaimer: There's really not that much implemented yet, also because it is a _huge_ bunch of work. But the infrastructure we have by now is very good IMHO and I'd really welcome PRs (always seeking for new contributors of course).
&gt; I always get 3 matches regardless of usage What _specifically_ do you mean by this? Later, you said it returns `None`, so I'm not totally understanding. Maybe some code?
(except with types with interior mutability)
May I just say, those errors messages are fantastic.
There's also this one: FileOpened o = f.open("…"); o.close(); o.close(); which is essentially a double free.
&gt; This is definitely one benefit of affine types, and a very cool pattern to make use of them. And to explain/expand on the pattern: linear and affine types make multi-type and statically-safe state machines work. If you're writing a state machine you've got two choices: * you can have a "big type" state machine which handles all states and transition internally (often as a gnarly mess), and any state transition is statically callable even when invalid for the current state (the transition will fail at runtime due to invalid preconditions) * the alternative is that each state is its own (visible) static type, each of these states statically provides only the transitions which actually make sense for the current state[0], and transitioning the state machine returns the new type. The issue being that without affine or linear types you can keep the old state around[1] and essentially fork the state machine (which can be useful or really really bad depending on what the SM is being used for) [0] for the example here you can only open a closed file, and close an open file [1] which is what TFA's examples amount to
Given that it will likely be a hybrid codebase, I'm not comfortable guaranteeing a certain percentage of Rust usage within libimageflow until we have more code ported. We're porting imageflow-server from Ruby, and that seems more straightforward (less likely to hit compiler optimization bugs like we do every day with gcc). 
I think this could definitely help. Thanks.
Looks like this is correct behavior. A `Captures` always has a fixed number of captured groups, and `len` will return the same value no matter *which* capturing groups actually matched. To actually count the number of non-`None` groups in a particular match, you'll need to use either [`iter`](https://doc.rust-lang.org/regex/regex/struct.Captures.html#method.iter) or [`iter_pos`](https://doc.rust-lang.org/regex/regex/struct.Captures.html#method.iter_pos) to count them. Looks like the `len` method could use some clarifying docs! N.B. If you want to test whether a particular capturing group matched, then any of `pos`, `at` or `name` will work since they all return `Option`s.
From their Readme: &gt; The pragmatic language choice for the core routines is C14. Rust is extremely attractive, and would make the solution far more secure (there are already safe Rust codecs!). However, given that we often resort to assembly or manual unrolling in C, it may be unrealistic to assume we wouldn't also periodically run into perf issues with the results of the Rust compiler. Long-term, Rust would be the ideal choice, as we get a C ABI, no runtime, yet great safety and concurrency possibilities. However, the development timeline with Rust would be nearly impossible to predict.
Ah thanks :) I didn't read the whole thing, so I missed that part. It's weird though that their kickstarter states that it is implemented in Rust and C. Unless their Readme is outdated and they recently took the decision to add Rust anyway. I guess everyone expected to see some Rust code.. :)
Removing this, as it's difficult to see why this link is relevant to Rust. It would be one thing if there existed some proof-of-concept Rust implementation, or if the authors were well-known and trusted in the community, but for now I don't want to set the precedent of having the subreddit be a platform for Kickstarter advertisements.
another update: I'm going to do something like this: http://stackoverflow.com/questions/37606035/pass-generic-function-as-argument to clean this code up, in case anyone is watching this post
Will do! Looks neat. Thanks!
That's clever, I'm really enjoying flexibility of the pattern matching. I still think that `||` and `&amp;&amp;` would a a good addition to it though, if only for expressiveness.
Please submit this to [rust-rosetta](https://github.com/Hoverbear/rust-rosetta)!
Fair enough---hope your KS goes well! You'd probably get a significant amount of free goodwill from this community if you did have that code up somewhere.
Some recommendations I'd make: # Relicense under dual MIT/Apache-2.0 See [here](https://github.com/sfackler/rust-postgres-macros/issues/19) for some reasons why the rust ecosystem is largely licensed as MIT/Apache # Rely a little less on macros Idiomatic rust tends to only use macros where necessary. Some of your macros could (and should) be simple functions, or offer little benefit. * [This join macro](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/version.rs#L216-L228) could be better written as a function, especially since it's only ever used on vectors of `Identifier` fn write_joined&lt;T: Display&gt;(f: &amp;mut fmt::Formatter, idents: &amp;[T]) -&gt; fmt::Result { // only ever called with at least one item try!(write!(f, "{:?}", idents[0])); for ident in &amp;idents[1..] { try!(write!(f, ".{}", ident)); } Ok(()) } if !self.pre.is_empty() { try!(write_joined(f, &amp;self.pre)); } * [This id macro](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/version.rs#L133-135) has questionable use: `Identifier::from`already exists, and `x.into()` will also work. If the user wants a shorter name, they can `use Identifier::from as id`, and use it as `id(20)` * [This version macro](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/version.rs#L400-L437) seems overkill. I'd use separate functions (`Version::new(major, minor, patch)`, `Version::with_pre(major, minor, patch, pre)`, and `Version::with_pre_and_build(major, minor, patch, pre, build)`). * [This constraints macro](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/resolve.rs#L153-L165) could do less: I'd prefer to call it as `Constraints::All(constraints![Exactly(..), Exactly(..)])`. macro_rules! constraints { ( $($a:expr),* ) =&gt; { vec![ $( ::std::boxed::Box::new($a) as ::std::boxed::Box&lt;Constraint&gt; ),* ] } } # Prefer to take `&amp;[T]` as a parameter over `&amp;Vec&lt;T&gt;` `&amp;[T]` is more general, and because of deref coercions, can be called in the same way * [This function](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/resolve.rs#L257) should take a `&amp;[Version]` instead of a `&amp;Vec&lt;Version&gt;` # Preallocate when creating a vector which will have a known size * In [this function](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/parser.rs#L28-L36), the size of parsed is known: create it with `Vec::with_capacity`, or in this case, iterators are better: fn parse_ids(identifiers: Vec&lt;&amp;str&gt;) -&gt; Vec&lt;Identifier&gt; { identifiers.into_iter().map(Identifier::from).collect() } # Other Notes * [This function](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/resolve.rs#L257) could be rewritten to use iterators: pub fn resolve(versions: &amp;[Version], constraints: &amp;Constraints) -&gt; Vec&lt;Version&gt; { versions.iter().filter(|version| constraints.allows(version)).cloned().collect() } * In [`Version::clear_build`](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/version.rs#L285-287) and [`Version::clear_pre`](https://github.com/kherge/recital/blob/3d99e8ff1a58d7bfd0ecbac625c9f4e55360660b/src/version.rs#L296-298), you should use the [`Vec::clear`](http://doc.rust-lang.org/stable/collections/vec/struct.Vec.html#method.clear) method * You have a lot of `#[allow(dead_code)]` items. Try to remove as many of these as possible.
That part of README.md **IS** outdated (by a year), and was also only talking about libimageflow, not imageflow-server. We never ruled it out, though, and Rust 1.9 (last week) opened the door for our use case.
We have 5 specialists who work on different aspects of the project. Can take ten years to build the required domain knowledge, so we work with existing experts when possible. I'm personally working on it full-time, as my only employment.
We will certainly be supporting animated gifs. I'm interested in exploring how Rust can help with concurrency, particularly given how frame delta encoding complicates it. giflib *must* go, it can't stay in imageflow. 
It'll be great when this project doesn't ship and it tarnishes Rust's otherwise spotless record. Also, no rust https://github.com/imazen/imageflow/search?utf8=%E2%9C%93&amp;q=.rs Also, what makes you qualified to say this will not be as insecure as the current implementations? Do you work with the servo crew? The iron crew? Are you a core-dev? Frankly I don't know who you are or why I should care about giving you money so you can make money. I'm all for making money but it seems your trying to cash in on rust guarantees in lieu of your own competence here.
You're running into a well known limitation of Iterators. See here for more details: https://users.rust-lang.org/t/returning-borrowed-values-from-an-iterator/1096/2 The short version is that the Iterator trait doesn't have any way of expressing "my associated type will only live this long". Search for StreamingIterators for alternatives.
So if I'm trying to decide between learning how to use GDB or LLDB, is this reason enough to learn GDB first? Or are they basically the same? I've not used either for more than 30 seconds...
I wanted to add a couple of clarifications. First, Rust technically has affine types, not linear types. (Affine types must be used at most once, while linear types must be used exactly once.) Second, Rust prevents data races, but it does not prevent all race conditions. It is still possible to things like acquire locks in an inconsistent order, leading to the possibility of a deadlock if a context switch happens at just the wrong time. Finally, while automatic frees is definitely an advantage over C, putting it as an advantage over C++ seems dubious, since RAII is the recommended way to manage resources in C++.
Is there a way to convert a reference `&amp;T` to a slice `&amp;[T]` of length 1 without using `std::slice::from_raw_parts`? It's technically a safe operation, isn't it?
Well at the very least the current lldb solution (the rust-lldb script) isn't working so well right now. https://github.com/rust-lang/rust/issues/33062 (note the issue also applies to OS X) I can't remember off the top of my head whether rust-gdb had the same issue. edit: Just to note, michaelwoerister has updated the issue noting that a temporary fix is now in the open-source version of lldb, so if you install using, eg, `brew install llvm --with-lldb`, and put it on your path, things should work.
I remember writing [an rfc](https://github.com/rust-lang/rfcs/pull/742) about that and I realized that when chaning `ref` to `*`, swapping the meaning of mut would be more intuitive: `ref mut x` would become `mut *x`, which means „dereference of x is mutable”. The `*(mut x)` would mean mutable pointer to immutable value, which is rarer case.
There are a lot of closed-source software projects on Kickstarter. Why is AGPL lol?
As I've stated before, we're not piggybacking on Rust in an way, and none of the authors/contributors to imageflow were responsible for posting this to /r/rust. We simply listed that we're using both C and Rust for libimageflow in our tech specs, and subsequently found these posts on reddit. I've found and fixed security vulnerabilities in many image processing libraries, read the source code to nearly all of them, and my current-gen image processing software process terabytes of images every day for companies like eBay (sweden/denmark sites), for which I was paid $249. Google a bit. I've been doing this for ten years. Look at my Github (imazen, nathanaeljones). I can't find your Github handle, so my best guess about your credibility is that you get off on trolling and don't actually write software. 
Yes, that's what I was thinking when I said, "ways around it." If there's another rope handy, you can `swap` it in and out also, avoiding even the cost of the new. But I don't consider any of this to be better than just making mutations `&amp;mut self` to begin with.
Sorry, you just don't get it. http://www.gnu.org/philosophy/free-sw.en.html
We've been burned by Kickstarters in the past, so for now I'm issuing an executive fiat against advertising Kickstarter campaigns unless the authors are well-established members of the Rust community, to ensure that there are social disincentives to running off with the funds.
That's lldb only
I like the Rusty Radio guys; I actually thought for a while that they'd stopped, because their original RSS feed died. Glad to hear they're still going, and I'll mention them on the next episode!
I really regret that /r/rust posted about our project. I would have strongly advised against it until we have actual deliverables in Rust as we currently do in C. 
Syntax extensions operate upon the compiler-internal AST, not the emitted LLVM IR. It sounds to me like what you want is to write a custom LLVM pass, which can be done without (AFAIK) patching the compiler at all: http://llvm.org/docs/WritingAnLLVMPass.html#registering-dynamically-loaded-passes Alternatively, if your idea is the sort of thing that *should* be a part of the language itself, then I would encourage you to write up and submit an RFC for adding functionality to the language/compiler.
[Seems that way.](https://github.com/tromey/gdb/commit/386017504c2ede9d2a4d35a5584faa8e8a2c3f0e#diff-f076a68ed78b8c4e1bf20febfdf5b98dR63)
Yep. You can even use `.1` and things to access fields!
Awesome, thanks for the link. I still am not sure if GPU support is really appropriate at the language level and not as an extension of some sort, but patching the language may still be the cleanest route.
And this is without our GDB pretty-printers? What subset of expressions does it support?
Very interesting :) One nit: `.as_str`. You just want `&amp;` :). Deref coercions for the win!
Interesting. I'm making a Personal Assistant _(quite literally, personal intention, but it will be OSS)_, and plan on implementing some of these features. How well do you think your PIM could integrate with something like a PA Bot? I of course was going to roll my own implementation, wiki, searching, etc. But perhaps it's wasted effort? **edit**: With that said, i do plan on having few dependencies. So things like requiring "Task Warrior" for a todo, is a no-go for my reqs
Yeah I agree. I think the focus was on matching OCaml's abilities but there are plenty of features we could add later.
Just a random note, wouldn't `for x in a.iter()` be the same as `for x in a`? IIRC for uses `IntoIter` to convert things to iterators.
I don't think this is quite what you're looking for, but you could follow [nadeko](https://github.com/klutzy/nadeko/)'s approach to converting functions to assembly, and then use `asm!` directives. According to [the book](https://doc.rust-lang.org/book/inline-assembly.html), the `asm!` macro is a direct binding to LLVM's inline assembler expressions.
I believe it's to avoid method clashes: `Rc` derefs to the type it wraps, and impling methods itself would prevent certain types -- namely, those that impl methods of the same names as `Rc`'s -- from being used ergonomically in an `Rc`.
You can use any GDB gui like Nemiver 
Thanks for your reply. This totally makes sense to me now, and since `Weak` does not `impl Deref` (for obvious reasons), that also explains why `Weak::upgrade` could be written the other, usual, way. 
&gt; How well do you think your PIM could integrate with something like a PA Bot? The bot could learn from the database imag has (or rather: will have). As I do a lot of interfacing with other tools, one has only to interface with imag to get a huge amount of data out of it. I do not duplicate data, but I collect references to it and for this I need libraries to parse all the stuff (think of taskwarrior data, ical, vcard, wiki markups, etc etc) - imag only creates metadata for linking to the actual content, but the libraries could be reused to parse the actual data. So here's what I think: A bot could use imag (the imag store) as data source to find the data it wants to parse and use additional parsing libraries to get the information it wants from the actual data. --- &gt; So things like requiring "Task Warrior" for a todo, is a no-go for my reqs That's also my spirit! I want to provide an architecture where you are tool-agnostic as much as possible. I, personally, use taskwarrior, so I want the `imag-todo` tool to use taskwarrior in the background. Other people use other tools for todo - if you can write a imag backend for it, there's no point in _not_ integrating it in imag. As said: Imag does not manage content, but links between content.
Not sure about rust, but I used to do my C++ programming in vim and then use Qt Creator as a gdb gui for debugging. Worked pretty well!
Thanks, I'll have a look.
In this case you really should create a separate type (even just newtyped) that wraps the discriminant. `HashSet&lt;Prop&gt;` conceptually stores `Prop` instances, not just its discriminant. An integer (perhaps newtyped) should be used to represent its discriminants. To keep things stable you pretty much have to create your own `discriminant_value` but if you match the underlying internal value it'll get optimized away (in Release builds only though).
[removed]
The VS Code gdb extension works extremely well with Rust. I think I tried the atom one too, but I never had any luck with it.
This is the wrong subreddit. You wanted r/playrust
(I'm not OP I just saw this linked in &lt;https://github.com/tailhook/quick-error/pull/24&gt;)
You probably want r/playrust
Yup, I pulled it into a crate when we removed it.
Thank you! One beginner question: Why are there multiple sections - the bindings mostly - in main() wrapped in blocks? 
Couldn't this be dangerous though? In C Arrays need to make sure that an additional next element is valid too, so that when looping over the array, the pointer can be over the additional next element and still be valid. Otherwise it would be Undefined Behavior. Doesn't this need to be true in Rust as well? Especially when passing that slice back into some C code through FFI? Seems like it would cause Undefined Behavior then. 
There's no raw pointers here at all, so I'm not sure what you're asking. The only thing making this function unsafe is that Rust can't know if the length of the slice is valid, but since a `&amp;T` can't be null, we know we have one valid element, so no problems here. &gt; specially when passing that slice back into some C code through FFI? C doesn't have slices, so you can't pass slices directly to C. Need to pass the pointer and length separately.
You are welcomed! The binding is wrapped in blocks because I want to re-use variable names, if you don't wrap it, there would be a lot of variable names like `map1`, `state1`, etc. Somes are just wrapped so that the locked `mutex` can go out of scope as soon as possible, which will unlock them for other uses.
Rust is implemented in Rust, but you probably know that. Something like [Dyon](https://github.com/PistonDevelopers/dyon) is probably more in the scope of what you are looking for.
I know of two scripting languages implemented (or being implemented) in Rust: [Dyon](https://github.com/PistonDevelopers/dyon) and [embed_lang](https://github.com/Marwes/embed_lang) I suppose there are more :)
Yeah, I forgot it. Libraries could be checked too. I think they are stored somewhere on disk. But libraries shouldn't use panics instead of results in the first place.
Off the top of my head: - [Dyon](https://github.com/PistonDevelopers/dyon) - [Rhai](https://github.com/jonathandturner/rhai) IIRC there is at least one Scheme(-ish) PL implemented in Rust out there but I can't remember its name. I think all these are dynamic, as in not compiled AOT. EDIT: Schemes: [oxischeme](https://github.com/fitzgen/oxischeme) (seems to not have been updated in quite some time), and [rusty_scheme](https://github.com/kenpratt/rusty_scheme).
I believe [typenum](https://crates.io/crates/typenum) and [generic-array](https://crates.io/crates/generic-array) do what you're asking for.
&gt; Need to pass the pointer and length separately. Yeah, but if you turn this slice into a pointer and a length, then that pointer would not be a valid pointer to an array in C, as it would cause Undefined Behavior. So I doubt one could argue that the slice is fully valid, if it breaks when it touches any C code. Here's some code to back up my claim: This is how iterating over a slice works in Rust: https://github.com/rust-lang/rust/blob/master/src/libcore/slice.rs#L821 The slice offset macro is defined here: https://github.com/rust-lang/rust/blob/master/src/libcore/slice.rs#L167-L176 It makes use of ptr.offset, which needs to be within the valid range of the array: http://doc.rust-lang.org/std/primitive.pointer.html#safety-1 Since we are not working on an actual Array, the "one-byte-past-the-end" does not hold and something that is supposedly safe (according to the documentation), isn't actually safe anymore. This should obviously never cause problems, but *technically* this could still be Undefined Behaviour.
Thanks!
I wanted to create my own math lib (learning purposes). #[derive(Debug)] pub struct Vec3&lt;T&gt;{ pub x: T, pub y: T, pub z: T, } impl&lt;T&gt; Vec3&lt;T&gt;{ pub fn new( x: T, y: T, z: T) -&gt; Vec3&lt;T&gt;{ Vec3 {x : x, y: y, z: z} } pub fn add(self, other: Vec3&lt;T&gt;) -&gt; Vec3&lt;T&gt;{ Vec3::new(self.x+other.x, self.y+other.y, self.z+other.z) } } Basically I tried to do some operator overloading. When I did this, I run into the error of error: binary operation `+` cannot be applied to type `T` Now I know that I need to do define that T implements the ops::Add trait somewhere in the code. But no luck on getting it to work.
I'm not sure I completely follow, could you give an example? All in all I want to access the whole stored variant object by just something along the lines of `.get(Prop::A)` instead of having to create an object every time, since later the variants will be more complex than just containing an `i64`. If the hasher uses `core_intrinsics` or a custom stable version in the end doesn't matter much for now, I'm fine with unstable and internals like that can always be swapped out later. I'm more interested about the conceptual approach.
The risk of technical debt is close to zero with feature gates. It's not like the feature is a wind-mill-slam instant stabilization. It'd take forever for it to get out of nightly.
You need to restrict the type of `T` to those that implement `Add`. You can write impl&lt;T: Add&lt;T, Output=T&gt;&gt; Vec3&lt;T&gt;
We have recently revised our views about proprietary software in Redox OS. For security and freedom, we have decided to remove and prevent the inclusion of any proprietary software in Redox OS, and will from now on comply with the [GNU Free System Distribution Guidelines](http://www.gnu.org/distros/free-system-distribution-guidelines.html)
Okay, Thanks!
That's fair, I don't blame you.
Have you tried [generic-array](https://crates.io/crates/generic-array)? It uses type-level numbers, but they're encoded in binary and not peano numbers, so perform much better.
Does anyone have any pointers to example code where this problem exists? I'm having trouble visualizing it
&gt;Ok so if I understand correctly, your HashSet will only contain at most one variant of your enum? And then you wish to retrieve the complete enum by just mentioning the variant? Yes, exactly. &gt;But that can't be right as your example shows you stuff two Prop::A in it. This would make the second Prop::A(2) inaccessible? It's a test [that the behavior works](https://is.gd/foBOoh). I call insert with a second Prop::A, but that one doesn't get stored because there's already another Prop::A in the set. This is achieved through hashing the discriminant instead of the underlying value. The println! at the bottom shows that there's correctly only the first one stored. &gt;can you elaborate more on what you want to achieve? I want to have a struct with a set of "properties". The struct should contain at most one of each property, regardless of the underlying value of the property. Say if the struct should be e.g. "traversable", it should only contain one property traversable regardless of what the underlying values of traversable are. An alternate implementation with a similar result, albeit with less flexibility, could be akin to something like the following: struct Test { propA: Option&lt;A&gt;, propB: Option&lt;B&gt;, propTraversable: Option&lt;Traversable&gt; } My intention however is getting something like this: struct Test { props: Set&lt;Prop&gt; } edit: This would work fine if there was a way to access the discriminant_value without creating an object first.
That's a user, not a subreddit
There's been talk of re-implementing parts of Ruby or it's C-extensions in Rust. Apparently, steveklabnik even started to rewrite the Array class in Rust. It would be nice to see Rust improve the memory safety of traditional dynamic typed scripting languages.
[removed]
To verify the system you are running you only need to be able to read the source code and build it from source yourself. The FSF definition of 'free software' includes the right to redistribute copies of the original and your modified versions to qualify as 'free', but this is clearly not a necessity for security, so why would Redox use their overly restrictive definition if their goal is security? From the so called 'four freedoms' you only need the first two for security. In practice the difference is mostly theoretical because almost nobody bothers to read the source code of the programs and systems they run (and most people don't read the license either). And bugs can and do linger for a long time that way. If Redox values security I think they would be better served by attempting formal verification than by restricting themselves to the FSF definition of free software.
Lol whoops
Additional freedom may make it more likely for people to be inspired to actually look at your source and help. &gt;If Redox values security I think they would be better served by attempting formal verification than by restricting themselves to the FSF definition of free software. Can't they do both? 
Will they? As far as I'm aware Redox was already free software, and has been from the start. This announcement appears to be a random page of the Redox book, and of all the pages in the book appears to be among those with the least technical content. The page would have been literally identical had Redox been written in any other language than Rust. While this virtue signaling might attract some people, it may also make others question the priorities of the Redox project, so I'm not convinced it will help them get more developers.
This is one facet of a secure system. - Free software puts more eyes on the code, and allows fixes to be propagated - Rust, if used correctly, catches many potential security errors. Heartbleed, as an example, was caused by a missing bounds check, which would not be allowed in Rust under most circumstances - Microkernel design lets drivers be sandboxed and given fewer privileges - Potential formal verification may allow some components to be provably secure. These put together form the basis of Redox security 
&gt; I think heartbleed proves that there is nothing inherently more secure about open source (or 'free') software. No, it doesn't. Microsoft found a similar bug in its code that was in there for *19 years*. Heartbleed was only there for 2 years. If anything this proves the point that open source is "more" secure than proprietary software. But I think you took it to mean that it's *unhackable* or something, which is obviously not true for any software. The thing about Heartbleed is that OpenSSL is much more used than any proprietary implementation and it was also highly mediatized - it got its own logo and name and everything. The people who discovered it also *wanted* it to be mediatized. Microsoft on the other hand hid its 19 year old bug with a name like KBF3545235 whatever, so almost no one wrote about it. http://www.cnet.com/news/microsoft-patches-19-year-old-windows-bug/
Read the post please 
yeah, it's just jackpot being hungry for karma /s About formal verification, there is an issue opened for it: https://github.com/redox-os/redox/issues/521 There was some chit-chat about it today too, I think that it's going to come *soon*. I'm not really the person to rate that.
That is awesome, and in my opinion something about those plans would have made a much more interesting post, especially as formal verification of rust code is relevant to the community in general. 
**[Shellshock (software bug)](https://en.wikipedia.org/wiki/Shellshock_\(software_bug\))** --- &gt;Shellshock, also known as Bashdoor, is a family of security bugs in the widely used Unix Bash shell, the first of which was disclosed on 24 September 2014. Many Internet-facing services, such as some web server deployments, use Bash to process certain requests, allowing an attacker to cause vulnerable versions of Bash to execute arbitrary commands. This can allow an attacker to gain unauthorized access to a computer system. &gt;Stéphane Chazelas contacted Bash's maintainer, Chet Ramey, on 12 September 2014 telling Ramey about his discovery of the original bug, which he called "Bashdoor". Working together with security experts, he soon had a patch as well. The bug was assigned the CVE identifier CVE-2014-6271. It was announced to the public on 24 September 2014 when Bash updates with the fix were ready for distribution. --- ^I ^am ^a ^bot. ^Please ^contact ^[/u/GregMartinez](https://www.reddit.com/user/GregMartinez) ^with ^any ^questions ^or ^feedback.
`Vec&lt;u8&gt;` indeed implements only `Write`, but it derefs to `&amp;[u8]`, which implements `Read` (as you can see at the bottom of [this page](https://static.rust-lang.org/doc/master/std/io/trait.Read.html)). It seems that you need to use [`lz4::EncoderBuilder`](https://bozaro.github.io/lz4-rs/lz4/struct.EncoderBuilder.html). And the, since you have a `Writer`, you can eg. write the compressed vec to a `File` (the `[..]` is just used to convert `&amp;Vec&lt;u8&gt;` to `&amp;[u8]`): let mut writer = EncoderBuilder::new().build(a_file).unwrap(); std::io::copy(&amp;mut vector[..], &amp;mut writer); writer.finish().unwrap(); Or eg. write the compressed to a new vector (you also don't need to use `io::copy` (the copy function is handy if your input is not a simple slice)): let mut compressed = Vec::new(); let mut writer = EncoderBuilder::new().build(&amp;mut compressed).unwrap(); writer.write_all(&amp;vector).unwrap(); writer.finish().unwrap() **edit**: Noticed that the `Encoder` doesn't automatically finish on drop, so you need to do it manually.
&gt; The FSF definition of 'free software' includes the right to redistribute copies of the original and your modified versions to qualify as 'free', but this is clearly not a necessity for security, so why would Redox use their overly restrictive definition if their goal is security? *In practice, software have bugs*. It's extremely important that anyone should have the right to fix bugs and redistribute the fixes. And without the possibility to fork a software if things go wrong, there is no way to trust the development process of any software. Security is not just a property of a given software in a given version, but also of the way it is developed. We should adopt development practices that facilitate the development of secure software. (Likewise, without the assurance that *every fix can be merged back*, it's harder to depend on a software in the long term. That is, we should have the right to fork, but also the right to merge too. Therefore, copyleft licenses should be employed whenever possible, barring practical concerns)
Not really, maybe the ubuntu fonts we had counted,this is just a promise that we will not allow proprietary software in our distribution 
I'm currently using peg for a project and I can confirm, it's quite enjoyable 
The structure is basically that the Console has-a camera. And the camera needs information about the object that has it; it does not actually need the object itself. I would guess the natural way to do that is to pass the information to the Camera during setup or the method call. Could you make a separate struct with the information? Something like: struct Console_params { width: i32, height: i32, } struct Console { params: Console_params, camera: Camera, } Then pass the Console_params as a parameter in ```center_on```? 
I don't know whether this question is appropriate, but are there any useful ideas and lessons from the L4 microkernel family that Redox is taking? I know Redox is inspired by Minix, but I am just curious on what the developers think.
According to the Rust's document, `clone()` creates a new owned handle. It's just a handle, not the data. Have a look here: https://doc.rust-lang.org/book/concurrency.html
Can you elaborate on what that means please?
 for x in &amp;arr { ... } Oh wait, I want to iterate in reverse now for x in &amp;arr.rev() --- NO for x in (&amp;arr).rev() --- NO for x in (&amp;arr).into_iter().rev() --- OK or start here: for x in arr.iter() and then: for x in arr.iter().rev() --- OK
Can't verify this, but I'm guessing you want the gen function on the pkey struct. http://sfackler.github.io/rust-openssl/doc/v0.7.13/openssl/crypto/pkey/struct.PKey.html The root of the documentation is here http://sfackler.github.io/rust-openssl/doc/v0.7.13/openssl/crypto/index.html
Ahh, I missed/forgot that state was declared as an Arc of the State struct. Now it makes sense. 
Well I agree that more systems-y stuff would be nice to have in Rust, using the argument "is not cool at all" wouldn't be the way I'd try to explain it to people. This sounds a little demanding and the whole issue is very offputting. If he wanted better Rust support it'd be good to have a use case in mind, which no one presents. There's some initial discussion, but this is something that should be an RFC if it's in stdlib or the libraries can be further developed, both of which he could help with even in a non-programming capacity.
That sounds like you might get tail recursion modulo cons for free out of that.
Trustworthy and secure are quite different things. Proprietary software is untrustworthy, but not neccessarily insecure.
The logic for finding the center of the console should be in the console. You can dress it up a bit like [this](https://is.gd/lkBvTK) if you want the camera to change its own state. Also added operator overloading for fun.
I had not considered the nightly test-bed, true (I tend to look at the language from a corporate point of view, where nightly features cannot be used).
I've done a fair bit of SIMD code in the past and I was rather disappointed at the state of SIMD in Rust. The SIMD crate has basic vector types, but they feel a bit bolted on to the Rust type system. In particular, it should be possible to write generic code that can operate with different vector widths. For example, the code for sin(2 x double) and sin(4 x double) should not have to be repeated. You should be able to write a function to compute the sine function that works for any vector width. This won't be possible without making SIMD vectors a first class type (family of types) in the language proper. Enumerating all the possible combinations as separate types (like the SIMD crate) makes the types unrelated to each other so that you can't write generic code that works on any vector width. I did discuss this a little with huonw (author of SIMD crate) on IRC but this is not something that can be solved in a library, the language and the compiler would need changes.
Yes, integral type parameters are a requirement to implement the kind of SIMD types I'm after. As far as I know, LLVM should be fine with any vector width. At least I've written C code (with vector extensions) that uses vectors wider than my CPU supports and the compiler (clang and GCC) could split them and emit efficient code.
Makes sense. Thanks.
Does this mean that we can have: #[repr(C)] struct Hello; impl Drop for Hello { ... } without a warning that the `Drop` implementation will add some state to `Hello`?
Ah! That's good to know, as integral generic parameter support without complicated `where` conditions is probably much easier.
Note that if you try to *read* the `inner` it prevents you from doing so. But writing to a field it’s not complaining about. Odd. It feels like a scary-looking but ultimately harmless bug. Or maybe not a bug? See also [E0383](https://doc.rust-lang.org/error-index.html#E0383) which I came across when trying something [a little more fancy](https://is.gd/uaC20F). I think it actually might not be a bug, merely surprising.
There is no such thing as an objective truth. If you cannot observe a thing regarding its attributes you cannot make statements about that attributes. therefore there is no objective security. You can say something is secure and **AFTER** you verify that you can be right, but there was no way to be sure about that statement in the first place you had just the luck to win the 50/50 outcome. Saying an electron is at this exact position without looking at it cannot be objectively decided. You need to measure the position and that position can by coincidence be the same as you said, but there is no way to say you can be sure about that without measure it. Proprietary software can be secure by coincidence after proofing it, but you cannot objectively say it is before that. And that is making it insecure – for **ME** .. if i cannot decide it one way or another i had to assume the worse, if it regards security.
Hmm, yes, that's a good theory. Seems like it should still fail, though - I'd have thought that optimizations like removing unused variables would happen *after* the borrow checker has done its work.
I would have thought so too, but I am not knowledgeable enough about the compiler to say anything for sure. It could be that they do a first round of simplification and dead code removal to simplify subsequent passes. This would explain why you don't get the error. But this is all speculation, so don't believe anything I say until someone can confirm ;)
I think I asked about this in IRC a while ago, and iirc the added state goes at the end of the struct, so you can safely pass a pointer to it across FFI bounds. But that's an implementation detail and not guaranteed on all platforms, or any of them. It'll be nice once this feature lands and we can stop worrying about it!
Yep, I will. Going to bed now; if a compiler expert wants to weigh in, great, otherwise I'll file a bug in the morning.
If you do file an issue please post it here. I'm curious about why this works too since I also believe the value should have been moved. 
 &gt; Newlib C library, which is GPLv2 Is this really correct (I tried to look it up but found no references to GPLv2) and if so, what does that mean for running proprietary C programs on Redox?
You seem to have found a nugget of information I'm interested in. Would you please elaborate on: "Lead me to realize that reverse tracing the functions that I need back to their rust api will resolve the need for an overview of how the wrapper api is structured" Do you mean simply to ctrl+f through the code or that there is some kind of debugger or program that lets you see the overall structure of a library? Disregard if it takes too much effort or I'm up the wrong tree.
This is not a bug. You're not accessing a moved out value, but initializing part of one. What you moved out was the value, not the variable holding it, so to say. The same way you can write `inner = Inner::new()`, except that also lets you use `inner` as a whole. Actually, for now, you can't even read the field you just wrote, although that is expected to eventually improve.
This is exciting! This solves the performance of LLVM optimizations with MIR trans, which was the main blocker for MIR-by-default, seconded by [overflow checks](https://github.com/rust-lang/rust/pull/33905).
Should a moved out variable be treated as an uninitialized variable? Like, let x = Inner::new(); consume(x); x = Inner::new(); consume(x); Be like let x = Inner::new(); consume(x); let x; // x was consumed so it's like it's uninitialized x = Inner::new(); consume(x); This sounds.. confusing. If you want to reuse a moved-out variable, you can make the `let x;` part explicit perhaps?
A moved out variable *is* an uninitialized variable. That's what moving out of a variable means. There is no semantic distinction between those two concepts in Rust.
&gt; the added state goes at the end of the struct, so you can safely pass a pointer to it across FFI bounds I don't see how this is possible in every case, e.g. for nested structs.
That's.. astonishing. So, we can't really use a moved out variable like a regular uninitialized variable just because the borrow checker is too conservative?
This is intended behavior, it has to do with how non-Drop structs work. Observe what happens when I add a Drop impl: https://is.gd/lg106C Structs without a drop impl are basically a bundle of local variables, namespaced under the struct variable name. So this isn't actually an Inner, it's just one `inner.public_field` local variable (one that isn't `Copy`, even though it's `u64`) And Rust already lets you re-initialize moved variable names without using `let`; `let x = ..; move(x); x = ..` works fine. So, here, what happened was effectively this: - the non-`Copy` `inner.public_field` variable was initialzied - it was moved out, leaving an unreadable local variable - `inner.public_field` was reinitialized This is no different from https://is.gd/58f3mz, really, just that the local variable isn't directly addressible. Once you add a Drop impl, the struct is considered to be a single unit (it wouldn't do for `Drop::drop()` to have a partially-moved struct as a receiver). Now, it is no longer possible to move out individual fields and reinitialize individual fields.
Didn't I just say the opposite? Everything you can do with an uninitialized variable you can do with a variable after it has been moved out, and vice-versa. Not sure what you're implying about the borrow-checker or why you negated the conclusion.
To give you an example where this is very useful: `x = process(x);` in a loop is not an uncommon pattern and it's idiomatic where mutation is needlessly complex or impossible.
That's exactly what happens if you [do the same thing to an uninitialized variable](https://play.rust-lang.org/?gist=0cab6d542a9aae85631ded1673367c9a&amp;version=stable&amp;backtrace=0).
This is https://github.com/rust-lang/rust/issues/21232
My mistake, newlib has a number of licenses. I had referred to this file: https://github.com/bminor/newlib/blob/master/COPYING It seems the c library code is a set of licenses, mostly BSD: https://github.com/bminor/newlib/blob/master/COPYING.NEWLIB
Perhaps you want a custom datastructure, e.g. something like [this](https://play.rust-lang.org/?gist=c41e14d9eecaca9a05b156d7bc20cfc0&amp;version=nightly&amp;backtrace=0)?
&gt; It's extremely important that anyone should have the right to fix bugs and redistribute the fixes. This is far more important in theory than in practice. Yes, in theory, that's the best way to ensure security. But redistribution of source happens very rarely in practice. In practice, one of three things happens: a) The buggy source is patched and vendored, and there is no upstream merge or redistribution. b) A patch is made and merged, and projects don't get the fix until the next release. c) The buggy source is patched and vendored, and the bugfix is merged upstream. Of course, this only applies to open source software. And of course closed-source software would be better served as open source (quality-wise, not financially). But also in practice, copyleft licenses largely prevent use/modification of the software, resulting in a much smaller likelihood that bugs will be found, let alone fixed.
AFAIU destructors should no longer require secret state to be stuffed into the structs themselves. That state lives on the stack now (in cases where it can't be determined statically, that is, which should be the vast majority of cases).
Nice, I've been watching this PR every day for weeks now. :) It feels so good to have such an old, *old* bug be fixed. Even better, this is the harbinger of MIR!
Or arrays.
I have to say I was also misled by this documentation when I was looking for how to do RSA signing and verification. Just by clicking through the docs, I ended up in the rsa module with the low-level primitives, whereas using the PKey code was actually what I needed.
Yes, that's the problem I had, which is I suppose the root of the warning...
Ok, here's what I found: I'm my definitions are split into files. This is, somehow, breaking things. If I put everything into a single file everything works fine. edit: It seems like only the doc-test don't work, test blocks work fine, I was making a mistake before.
You can always check out how I have implemented Rust in my projects. They should be relatively simple to comprehend. * [TV Renamer](https://github.com/mmstick/tv-renamer) * [Systemd Manager](https://github.com/mmstick/systemd-manager) I also have a few snippets of code that are re-usable: * [Obtaining a List of Video Extensions on Linux](https://gist.github.com/mmstick/0f7c08b4a26db822ffad2d542b3509b6) * [Using That To Obtain a List of Videos In a Directory](https://gist.github.com/mmstick/1d249f12555dd33df38f37da744c249b) * [Printing a Numbered List of URLs From a Webpage](https://gist.github.com/mmstick/0ee543ddb2f0a384c663c65890414d6d)
The ones I used may not be the best in general - they were tailored heavily towards scientific computing. I think any library with solid documentation and comments should be easy enough to learn from. Anyway: - [stdlib](https://github.com/rust-lang/rust/tree/master/src/libstd). More specifically I regularly turn to the data structures to see how they are implemented. This is probably the best choice because of the great API docs, inline comments, lots of examples online, and it was written by the people who know best! - [num](https://github.com/rust-num/num). Similar reasons to above. A bit more domain specific for what I wanted. - [ndarray](https://github.com/bluss/rust-ndarray). Written by /u/neutralinostar . Again - good docs and example code. But I could also bother the author to explain things to me (and he let me steal bits of his code). I think the last one highlights something great about the community. People are really happy to answer questions - about their own work or more generally. You should check out the #rust-beginners irc, there are always a lot of people happy to help. And finally feel free to check my library out, [rusty-machine](https://github.com/AtheMathmo/rusty-machine). It's pretty niche but may provide some help.
This may sound stupid, but having some sample results somewhere would definitely attract more people.
We still check the drop flags on `drop`. We just don't zero things when we move them.
mirpocalypse
Armirgeddon
&gt; This is no different from https://is.gd/58f3mz, really, just that the local variable isn't directly addressible. These two examples are _quite_ different. Reading from the field that's been set will result in a compiler error in the original example. https://is.gd/6N46QB https://is.gd/a7GyGN I'm surprised that you say this is "intended behavior." It seems to me like the confusing but otherwise harmless result of the confluence of other sound decisions.
It's a MIRacle!
Huh, I didn't expect that error. I know what it happens (any non borrowing mention of `inner` is a move) I partially feel that the second example should work, however (no reason for it not to aside from possible confusingness) So I see it more as a special case of intended behavior, where roughness in another part of the compiler doesn't let this case work.
&gt; Actually, for now, you can't even read the field you just wrote, although that is expected to eventually improve. This doesn't sound like an improvement to me. It seems to mean one of two things: * Allow users to read from the initialized part of a partially initialized struct. * Determine that a struct is fully initialized when all of its fields are set. Neither of these seem like they encourage good practice to me. Just because its safe doesn't mean Rust should let you do it.
Please, I can't take any mir of this
`?` is a particularly good example of why this RFC is important. I read that whole `?` RFC pretty thoroughly a while back, and then I saw it was merged, but then I discovered through the RFC's comments that it was implemented pretty differently than what's described in the RFC. And there is no other documentation that I've been able to find that actually clearly describes how the `?` operator and its accompanying features will work once they land in stable and I actually get to use them.
But they're stack flags now, right? So `std::ptr::read_and_drop` doesn't have access to the flags.
[I would definitely organize this code like this.](https://is.gd/DinxIs) Set the state of the Camera in the Camera's methods, but perform the calculation based on Console in the Console's methods. [Here's another way](https://is.gd/cnowxG), which is more robust if the Camera can be related to the width/height tuple (which I have named Screen, though that may not be appropriate) in a different way than both being owned by Console. The fundamental issue in your code that by passing Console to Camera you were passing a reference to Camera to itself while trying to mutate it.
[removed]
http://rustbyexample.com/custom_types/enum/enum_use.html Great examples all throughout this website. They actually introduce use right next to enums. 
Thanks
Well, I guess you could say that this pun thread is adMIRable. Or that this patch is MIRely about dropping. Or that drop flags are no longer a quagMIRe.
Good point. I guess its a very C-like thing (and not-really-Rust-like? It makes sense to me, but that could be my inner C programmer) to treat a (non Drop) struct as a bundle of local vars, even though that's how it works internally. I don't see ways to shoot yourself in the foot with this (doesnt mean they don't exist!), but it will still lead to confusing code and really isn't useful.
Yeah, I don't think this is a footgun as much as a readability issue. You should just construct a struct again to reuse the variable, not set its members.
Very basic language I started writing some months ago, still extremely incomplete, but if the code can help you: https://github.com/BurningMind/ion
I don't think it is.
You can `use ns::Sign::*`, it'll bring the constructors into the parent namespace.
&gt; For some reason, the JVM API is not invoked using functions directly, but rather by calling functions stored in the JNIEnv function table. To be layout compatible with C++ vtable. So that env-&gt;NewStringUTF("Hello from JNI !"); can be used instead of (*env)-&gt;NewStringUTF(env, "Hello from JNI !");
Couple of points: * Your `uoe`and `uoe_node` functions can be replaced with [`Option::expect`](https://doc.rust-lang.org/std/option/enum.Option.html). * You can do `writeln!(std::io::stderr(), "Error message goes here")` to write to `stderr`. * What's the purpose of returning a `Result&lt;()&gt;` in `parse_line` since you're always aborting if the input is malformed? * Here's how I'd roughly write the "parsing" part of `run`: let reader = BufReader::new(f); let mut iter = reader.lines(); let header = try!(iter.next() .ok_or(Error::new(ErrorKind::Other, "Invalid input"))); let mut grid = Grid::new(header); for line in iter { let line = try!(line); try!(grid.parse_line(line)); } * Instead of storing the nodes in a hash map, why not store them into a `Vec` and use indices in `Link` to refer to them? All you need is a temporary hash map from strings to `usize` while parsing the header and you can build it by roughly doing the following: let mut mapping = HashMap::new(); for label in header.split_whitespace() { let next_id = mapping.size(); mapping.entry(label).or_insert(next_id); }
I think we agree on the overall concept, but just using different words. What you've described as security I've described (in my other comment that you replied to) as trustworthiness. If someone gave me some software without source I would not claim that it was secure, but I would disagree if you said it was insecure (without having the source). Until sufficient evidence is available, its security is simply unknown (which I would then refer to as untrustworthy).
&gt; These are just mutable pointers to opaque structures. In rust, we define opaque structures as empty enums. I believe the best practice is to avoid using pointers to empty types and either type alias or newtype `c_void`. pub type JNIEnv = c_void; // or pub struct JNIEnv(c_void);
Luckily, `read_and_drop` is unstable, so if it breaks, it can't block shipping this.
I find parsing text in general to be fun! `peg` does look mighty nice. Thanks for that!
`none_of!` seems more appropriate. If you want to match a single character, it might be `take!(none_of!(atom_specials), 1)`.
I work with the author of this post, Paul LaCrosse. This project came together very quickly and we're looking for any and all feedback. Let us know what you think!
For sure. I just wonder what will happen to that family of functions, since it can be useful in certain depraved situations.
Why is it odd ? Isn't it the goal of match to be faster than if/else when we already know all the possibilities ?
nice apps comrade
I will once I will have added all the modifications I have been suggested :)
I never claimed a struct is not just the bundle of its fields. 1. Initializing a struct by setting its fields individually leaves room for doubt for the reader whether and when you have set all of the struct fields, forcing the reader to evaluate your code much more closely (including learning the definition of the struct). 2. It reads like mutating a moved or uninitialized value, whereas the struct definition form reads clearly as initializing or reinitializing. 3. You can only initialize a mutable struct this way (currently) and you can't read the initialized value (currently). The aspects of this which compile right now feel like an oversight, not a feature, and it countervails against the way we teach and discuss the language. 4. `foo = Foo { ... }` has the syntactic appearance of constructing a `Foo`, `foo.bar =` does not have that appearance. One is much harder to understand than the other in my opinion.
Well, not really. By that logic `Drop` structs are also just bundles of fields. They're not, they're a single unit that cannot/should not be taken apart. Non-Drop structs are just product types.
If you need to nest a *lot*, you can copy from Clippy: https://github.com/Manishearth/rust-clippy/blob/master/clippy_lints/src/utils/mod.rs#L31
So, how am I going to use my WLAN chip, GPU, etc?
I don't know how to make main.rs smaller. I had it split into 3 functions (handle_events, update, render), but that wasn't so nice when the function signatures were becoming too large with about 10 parameters, and the need to edit the signature and call site when I wanted to add some more variables to work with
Proprietary software can be audited. The source code can be useful, but it is not strictly necessary. I don't think free software is automatically more secure. How much penetration testing has been performed makes a bigger difference IMHO.
I'm going to the Cologne Save the Date Rust Meetup today (hope to see some of you there). Also trying to write the [overflower](https://github.com/llogiq/overflower) plugin and trait/method/function lookup for [metacollect](https://github.com/llogiq/metacollect).
Still waiting for more feedback (both IRL and on the PR) on https://github.com/Keats/tera/pull/33 If i have time, I will also start trying to change the lexer+parser to be done using [pest](https://github.com/dragostis/pest)
One thing that I never understood is the need to rename main.rs to something else. It's quite frustrating having to go through the files (when you haven't downloaded them), to find the main function. Imho main.rs is any new person's entry point. This is where people are introduced, they can see how you set up an environment, what functions you run, and where control flow goes. Unless I'm ignorant of something here, I suggest you change the name to main.rs.
Working on a v0.2.0 release of [pest](http://github.com/dragostis/pest). Currently improving documentation and excited to help [tera](https://github.com/Keats/tera) out.
Will that help Rust to rule the smartWatch ? :-p
[Handlebars-rust](https://github.com/sunng87/handlebars-rust), the templating library, had a release last week with improved JSON literal support, better helper API and detailed render error reporting. 
Started building the IMAP parser for typesafe-imap (I keep changing the name) in Nom. It's pretty cool, but outside of that one datetime parser blog I haven't found a lot of "how to use nom" out there. If I manage to get it done I'll definitely try to fix that. If anyone is familiar with nom, imap, or both, and is interested in working on this, let me know. I only ever get to work on it for a few hours a month lately.
Still working on my UI framework inspired by Elm, when I have the time, which lately I have not had much of, so progress has been a bit slow. Currently working on the hardware accelerated backend.
I like elm. Is there have any source code opened?
Of all the possible reasons to standardize a language, the threat of "SJWs" is the least convincing one I can possibly imagine.
Thanks a lot Steve and /u/llogiq ! And sorry for responding so late, I have been quite busy lately.
I've never had any code break when following semantic versioning rules and this community has been the most helpful I've ever seen for a programming language. I also don't think insulting people whom you're asking a question is the best way to go. 
Thanks. Yeah, I mean I've noticed this trend with Mozilla projects. It very much encourages this hivemind of "say nice things or go fuck yourself" within the community. I'm not really a progressive person (obviously), I am really more interested in getting work done than saying nice things and so it just comes to me as an unfortunate but ultimately probably unavoidable obstacle that Rust is developed largely by Mozilla. Like I said, I really enjoy Rust **the language**, it's adopted a lot of forward-thinking features in the PLT sense, and with more work it could be useful for real-life systems programming, but without a standard of some sort I'm just calling into question the scalability of a bunch of people with nose rings and dyed hair and a github repo all working at the same organization, telling 'mean people' to fuck off. EDIT: just to make this as clear as possible: if I just wanted to come in and bash Rust developers like "haha u all suck" I would've just done that. I am genuinely interested to find out if the Rust developers and the greater Rust communities would benefit from a standardized language, maybe later on when Rust approaches some determined point/release/version number/feature/etc
&gt; It very much encourages this hivemind of "say nice things or go fuck yourself" Well, I can see how this is a problem for you, being encouraged to say nice things and all. &gt; I am really more interested in getting work done than saying nice things These two things, they are not mutually exclusive. &gt; I'm just calling into question the scalability of a bunch of people with nose rings and dyed hair and a github repo all working at the same organization, telling 'mean people' to fuck off. That a) makes no sense b) is a non sequiteur. _can_, in fact, fuck off. 
Right, so this is exactly my point. If I wanted my product to rely on the work of a crew of people who at this point have literally told me to fuck off, I'd start re-writing it into Rust. I never implied that those two things were mutually exclusive, and in fact that they aren't is exactly the point I made. I can get a lot of work done without saying nice things to people, and making a conscious decision to do so. It's not a requirement of productivity that people aren't offended by what someone else does. I don't think it's a non-sequitr at all. I mean, there's people showing up to work in jeans and t-shirts, people that have facial piercings and tattoos and blue hair and things. If was a product lead for a Fortune 500 company or something (I'm not obviously, but bear with me) how could I go to my team and say "Hey, these guys made this really great tool that we can use to make our product even better." That person would be laughed out of the conference room entirely, whereas I could go pitch, "Hey, let's just use C++ for this because that's what we do everything else in" there'd be little to no resistance to that.
Do you consider yourself to represent the whole of the Rust community? It's all you? Just because something is shitty doesn't mean that every single person that has ever touched it is by extension, shitty. If my neighbor builds a shitty fence in his yard, I'm going to say to him, "Man, that's a shitty fence" and he would understand the difference between that and saying "Hey man, you are shitty and I hate your fence, too."
Currently working on an SSH library. The transport layer works, but I'm more focused on good API design for both low- and high-level parts so it's been taking a while. Current prototype uses nom for parsing and sodiumoxide for crypto, but [ring](https://github.com/briansmith/ring) looks really promising.
Well no. Your neighbour isn't a part of your fence. If you insult my community, you insult me. If you insult my family, you insult me. If you insult my country, you insult me. But that's not the point, you can insult me if you like. My point is that these people have worked and are working very hard to have a helpful community, with the irc and weekly question threads and then you go and insult that community. I cannot accept that, personally.
No, I'm am a hardly existant part of it, in fact. You didn't call your neighbours fence shitty, though. You called your neighbours family shitty. Or their friends, or their croquet club. A community is not a product, it is a collection of people and the relations between them. Calling that shitty is, by extension, calling a large part of those people and their relations shitty. I am not at all surprised that you fail to grasp this, however. 
I was talking about large, successful, profitable companies in that example.
I don't feel that way. It was not my intention that you feel this way, but I don't feel responsible for your choice. 
No. Taking other peoples' reactions into account, grasping the concepts of basic social interactions or taking responsibility for what you communicate does not seem to be your forte. 
Well, then, that changes everything. Wait, no, actually, it doesn't change anything. 
&gt; is there a way to 'unborrow' it after cpu.run() completes? Not really, the borrow is probably held by `Cpu`'s type (the lifetime `'a` there). Maybe [non-lexical-lifetimes](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/) would help here, but I'm not sure. For now, I see the following solutions: 1. You can wrap the bus in a `RefCell`. You'd need to call `.borrow()` though and it will have some performance penalty. 2. You can remove the `Bus` from `Cpu` and leave only the registers, etc. And then create separate struct: struct RunningCpu&lt;'a&gt; { cpu: &amp;mut Cpu, bus: &amp;mut Bus, } And define all your methods on that struct instead, then use it like that: loop { cpu.running_on(&amp;mut bus).run() ... } You can even define `DerefMut` on `RunningCpu`, so you don't have to change the code at all. 3. Make all your registers `Cell` types. Cpu would have shared reference to bus, which won't prevent to use `Gpu` simultaneously. I'd go with solution 2., because since everything is onwed, manipulating state is easier (I mean cloning state, saving it, making e vector of emulators etc.).
Yeah I was thinking of non-`Drop` structs.
Thank you for posting this, from the author...
I was a salesman in a gun shop for several years, and have over a million dollars of sales under my belt. Communicating is what I do best, I think what you meant to say was "I don't agree with you and I do not like you." Which is fine. 
3: Yeah, bugs should be fixed. 1, 2, 4: The same range of possibilities exist when setting (the fields of) an initialized struct, and I don't see a strong justification for the language having arbitrarily different rules for the uninitialized case. As far as stylistic preferences go, sure, maybe one of them is better. But that kind of thing is *at most* lint-worthy imho.
People have approached me before about this exact issue when it's brought up (the community, not the standardization part) and many of them agree with me, but don't want to be crucified by the community. I'm willing to do it, because it's the right thing to do, so yeah. If I went to other systems programming language subreddits, I think I might find that the vast majority of them already have ANSI/ISO standards which is the crux of the original issue, imo.
This, however, I wasn't aware of it at all. I'll take a look. Thanks!
So what is this all about? https://www.reddit.com/r/rust/comments/4merw3/gdb_now_supports_debugging_programs_written_in/
I haven't had the time to dig into your code, but a common way I've seen this handled is to create some kind of structure that holds all this state, and then pass it around, rather than individually.
I looked around your course website and it looks awesome! The slides and exercises are really well done and introduce the language features in a way that makes sense to me. I'm not a UPenn student, but is it alright if I work through your course material?
My working theory is that it's related to generics and bounds, which isn't too prevalent in the emulator project. Do the projects you've noticed in which you've noticed a slow compile happen to use those? 
You could also do that, but either way works.
Always a great read,- thanks!
You missed http://ticki.github.io/blog/lambda_crabs_1/
&gt; Avoid deadlock by double-locking RWLock/Mutix Should be &gt;Avoid deadlock by double-locking RWLock/Mut**e**x
yes, I was thinking the same thing; the emulator as you say doesn't really use those, but my other projects (that have slow compile times) do.
TWiR is more like _Last Week Tonight in Rust_. Since you posted it on a Monday, it will be available in next issue!
It can happen for a generic datatype where you happen to fill in () for a type parameter for some reason. But indeed, it's a special case and it's better to assert against the ZST case than to leave it broken or untested!
There's nothing wrong with long functions that have to execute many things in sequence. ([read this](http://number-none.com/blow/john_carmack_on_inlined_code.html)) You could have "logical" sections in it by using blocks (Rust has lexical scope =), thankfully): // handle events { ... } // update { ... } // render { ... } 
Unforunately, I won't be able to attend RustFest, but I'm sure I'll have another opportunity to hold the talk. :)
snazzy
Of course! The class is meant to be used by anyone. We have a Google Group (linked on the site) for everyone who is following along online. It isn't very active, but there are a number of subscribers and we are sometimes available to answer questions as well. 
Not all proprietary software can. Often it is in fact illegal to disassemble, inspect, dtrace, and audit the software.
Yep! I, personally, am a big fan of L4-like microkernels, and we do certainly take inspiraton for that.
No, this won't change anything, just our policy regarding non-free software in our official distribution.
Don't feed the troll :(
I would love to see more resources about nom too! If you figure it out, I'm interested in reading your blog post ;)
I try not to.
This is a great writeup. Thinking about lifetimes as a `Scope` trait is useful for teaching people this concept.
Actually this is incorrect, what the PR is doing is ensuring that double-locking *will* deadlock, since it can otherwise result in unsafety.
For example, the next post has `'a + 'b` which needs the poset to form a join semi-lattice. You have `+` defined as the lub/join, but that it even exists is a bit subtle. Maybe worth pointing out there?
Well, it really depends on how you interpret things. If you interpret the region as starting after the initialization (such a rule makes sense since it allows initialization analysis to be done under the region analysis), it is very much possible to do today.
I'm afraid I don't have cycles to spare, but I did this in Scala not too long ago [0] if any of that code is of any help. 0 - https://github.com/cretz/smail/tree/master/src/main/scala/smail/imap
Btw, the [second part](http://ticki.github.io/blog/lambda_crabs_2/) covers lattice theory briefly.
Thanks a lot.
At least his ideas are good.
Nice! Would be cool to see some kind of rustbridge thing for Postgres. What happens if it panics within the extension?
Yeah, it should actually read "Avoid double-locking RWLock/Mutex by deadlock. My mistake.
I'm working on [modesetting-rs](https://gitlab.com/slabity/modesetting-rs). A crate for accessing libdrm, kms, and rendering on-screen directly without any display server.
Great article! These articles are helping me wrap my head around why we need to include lifetimes in some of our struct definitions, and what exactly the syntax of it means. By the way, I think there's a typo in the line: &gt;We know to additional facts about our operator: I believe you meant to use two?
On my system the displayed memory usage looks too low. Looking at your sysinfo crate, shouldn't mem_used be called mem_available instead? https://github.com/GuillaumeGomez/sysinfo/blob/master/src/system.rs#L59
Awesome! A solid metrics reporting framework is an important building block for production ready services. Like with logging, having the entire language ecosystem buy in to the same metrics framework makes everything much smoother. If everyone uses the same framework it makes it feasible for low level libraries to start exposing metrics (e.g. core libraries like serde and mio). Hopefully this can be the one!
Another option is to make the reporters opt-in via cargo features.
Fixed.
This is exactly the plan. Prometheus is hugely heavy weight. I should already have an issue for this.
Please yes halp! I want to do something a bit different than codahale and I need lots of help with docs.
I think the Rustfest badges just got more work intensive... No, get that thought out of my head!
Will you have childcare available at Rustfest? If so, you can make the kids fold them for you! :)
So then should we rename it to Last Week Tonight in Rust and then invite John Oliver to write part of it? :P
Since the "This Week in XYZ"s all come out on Mondays (or at least Servo's does...), perhaps we should be dead linking to the one that will come out (after asking if there will be one?), or would that take too much coordination?
[removed]
There is [log](https://crates.io/crates/log) which is basically just a trait for logging, but it allows one to switch it out with any crate implementing it.
If we could get John Oliver involved, that would be amazing. Do it!
I din't test it, but does this interface work well in practice? I mean, the metric gets moved into the registry. How do you access it after?
Or, we publish TWiR on Tuesdays instead? /cc /u/llogiq, /u/brson, /u/cmrx64
The language is now roughly where I want it to be: A simple language that is easy to type, no garbage collector, and good at 4D vectors, colors, text and problem solving. I have fun programming in it, and despite only complaining when it can prove types are wrong, it feels rather solid. PRs are welcome!
I think this strategy will quickly prove itself to be worth the effort.
The implementation differ, but the interpretation, from a theoretical point of view, can be done as this. Internally, initialization analysis and region analysis are two different passes, but one could extend it beyond Rust's implementation. This blog series isn't strictly limited to Rust. In any case, my example was for showing that the outlives relation is _not_ a total order over L, an example without partial overlaps is: 'a I----------I 'b I-------------I As you can see, neither 'a: 'b, 'b: 'a, or 'a = 'b is true. Edit: Also, you can in fact get partial overlaps in erroring programs. The graph traversal detects that.
Not that you should use it, but one thing you might be interested in is that [timely](https://github.com/frankmcsherry/timely-dataflow) has its own [logging infrastructure](https://github.com/frankmcsherry/timely-dataflow/blob/master/src/logging.rs) that comes out as timely streams, so you can push them directly into other timely computations (we mostly write to files at the moment, but you can send them to any `W: Write`, and we've done e.g. TCP connections to timely instances on other machines). It's all [Abomonation](https://github.com/frankmcsherry/abomonation) friendly so it's relatively high throughput (and meant to be low overhead). Again, probably not something you should buy into just yet, but as part of the tire-kicking process, if you see something obviously good/bad/ugly, let us know.
Sorry, nevermind, seems I got confused, and thought this would actually compile if Inner doesn't implement Copy: let x = Inner::new(); consume(x); x = Inner::new(); consume(x); But it seems it doesn't, so everything's ok.
Could be named "Dyon is getting serious" ;)
There'll be a new thread tomorrow. I've held off so there's more novelty in the 'what's everyone working on?' thread, as that's not stickied until then because of the survey post.
Dyon is seriously fun!
when do i use which orm?
Iterators might be added later, but I would like to keep indices because they are very practical in game programming. I think I've used Dyon for too long to see it how new people see it. However, I remember that the mathematical loops were strange in the beginning. It did not took long time to get used to it, and now I am convinced there is another benefit: The math equations used to describe physics etc. does not look that scary anymore. Such mathematics is very useful in game programming, because it is a compact way of representing knowledge of the kind used to describe processes in the real world. There is a lot of overlap between what games are doing and describing physical systems. This kind of paradigm has a lot do with processing of data, and very little to do with type abstractions. So Dyon has few features for type abstractions, and more features for processing data. These features are in the language to help productivity, and they don't take long time to learn. It doesn't lessen usability, it improves it. Current objects are better than globals, because they have a scope and you can organize the code in a more flexible way. They are perfect for assets, because you can have nested game loops and just reload the game/player state. It takes shorter time to develop prototypes, it is easy to fit in a ECS programming pattern, and it helps the modularity since you can depend on a module using a current object that is not declared in that module. I think game designers will understand these things, because they are often painful to do in many languages. While you might find current object unfamiliar, [other people disagree](https://www.reddit.com/r/rust_gamedev/comments/4kvdpb/dyon_gets_current_objects/d3kbv8w) (quote): &gt; I love this. It's a feature I wish every language had. Secrets is a very new feature, but it was added to unify the mathematical loops, and it seems very useful in some situations. They are very practical and straight forward once you get used to it. I know that Dyon is different than many programming languages, but I love using it. Thanks for the feedback!
Are these talks recorded and will be available? 
Surely keeping a list of free items has upsides and downsides; the main downside being that if you add 10000 elements and then remove the first 9500, you have still allocated memory for 10000 elements instead of just the remaining 500. [Petgraph](https://crates.io/crates/petgraph) (which I think is Rust's main graph library, unless there's a gem I haven't found?) has the strategy that when something is removed, the last one gets moved into its place. I e, just one element shifts index instead of many.
There's also the petgraph [stable_graph](https://github.com/bluss/petgraph/issues/67) feature flag.
Well thank you! The instructions from archaelus/teensyr surprisingly worked without a hitch (with small substitutions of brew -&gt; apt-get, etc). It's pinned to a fairly recent nightly, but I'm not sure if that's required by zinc or not. Moreover, it looks like teensy_loader_cli loads its own bootloader, but it is possible to go back to the shiny/annoying Arduino IDE, you just have to press the reset button a few times as it's not able to auto-reboot the Teensy while the Rust code is running. I would love to port the current code from Arduino-C++ (not sure what to call that dialect exactly) to Rust. But the problem is that the current code works so the port isn't productive. I'll try to do it in my spare time.
This doesn't seem to be a big problem in the real word, at least for situations I can imagine. I mean, even Vec doesn't downsize automatically. My use case isn't actually graphs, it's the [half-edge mesh](https://en.wikipedia.org/wiki/Doubly_connected_edge_list). I know there's already an existing implementation, but I wanted to see if I could do it without reference counting. 
If you like, you can think of rust-lang as a deep strategy game where you have to find the right incantations to pass the boss fights with (level 1) the *type checker* and (level 2) the *borrow checker*, along with some smaller bosses called lints, orphan rules and such.
This looks like almost exactly what I need. However, It seems that it's written as an allocator instead of a container. This wouldn't be a problem, but Insert returning a result instead of the index where the object was inserted and manual capacity management are rather unergonomic.
Recently [grow](http://rust-doc.s3-website-us-east-1.amazonaws.com/slab/master/slab/struct.Slab.html#method.grow) functionality was added to slab. Shrinking is a little more problematic, since the slab may get fragmented.
This sounds like "We do not support this. You'll have to work that out yourself, proprietary hardware peasant." Issues like these are (at least for me) reasons not to use or even try an OS. Unless GNU takes over the world, the assumption that your system will run OSS-only is wrong and far away from reality. Sorry, but this has to be said.
Conversions don't automatically "stack" that way but you can be more explicit. let foo: Foo = Bar::from(x).into();
Wrong subreddit. This one is about Rust the programming language.
Look, we all know borrows and ownership are difficult, no need to be so morbid as to die from it!
As a side note, how long is the "last chance" going to last? I remember I kept receiving emails about a "last chance" to purchase my college graduation photos for at least three years.
It kinda looks like you just want to wrap VecMap&lt;T&gt; as a (VecMap&lt;T&gt;, Vec&lt;usize&gt;) with new insert and remove methods. Do you need to re-implement all the iterators and everything?
You may be able to get away with a generic implementation. impl &lt;T: Into&lt;Bar&gt;&gt; From&lt;T&gt; for Foo { fn from(t: T) -&gt; Self { Foo::Bar(t.into()) } } // no more impl From&lt;Bar&gt; because it's covered by the above let foo: Foo = x.into(); // works
That's an interesting perspective! I wonder if people will talk about "the Zen of Dyon" some time in the future... My hope is that if I can type mathematics and see it runs then perhaps when reading a paper I also can imagine it running. I think a bit differently about loops in Dyon than in normal programming since indices must follow same order as the loops. This is also the same order which is efficient, which is a good thing. When I see a packed loop `for i, j, k { ... }` I wish the computer could just do it all in parallel so the whole loop counted as one time step.
I tried to go to the homepage from crates.io and I'm getting sent here: https://github.com/rust-lang-nursery/rustup.rs
The source is [in that repo](https://github.com/rust-lang-nursery/rustup.rs/tree/master/src/error-chain).
Ah, ok, that makes more sense then :P thanks
Haha sounds complicated
What are you really trying to do? "How to downcast?" sounds to me like an [XY Problem](http://xyproblem.info/).
There isn't a similar idiomatic way in the standard library. https://github.com/AndyBarron/app-dirs-rs is probably the closest, but it doesn't support windows (yet).
I found this discussion on the topic: https://github.com/rust-lang/rfcs/issues/1159
There is no particular reason, I was just interested in what exactly was meant by "nested destructuring". Google does not seem to have any results and I was wondering if this was some feature I was unaware of. Thank you for the response.
No problem!
My pleasure :)
After some cursory googling, and this may be outdated, it looks like LLVM does not have a SPARC target for code generation.
Here are some crates for this: * https://crates.io/crates/app_dirs * https://crates.io/crates/dirs
At the risk of sounding really obvious; this might be due to it being difficult getting commodity access to, and/or distribution of, SPARC hardware.
Fine with me.
Thats great! I have a question though: https://github.com/rust-lang-nursery/rustup.rs/blob/master/src/rustup-cli/common.rs#L344 Show backtrace is inside the scope of report_error, is that so its only internally and not used by anything else? Also the show_backtrace function is pretty static, not all people use -v or --verbose in their apps to declare more information. There is a variety of ways to do this. All together, I like errors and backtraces, just hope it wont clutter programs. I believe this is one step to the next level or async and futures/promises, being able to have a better error and backtrace system.
I believe the problem is roughly that calling `send_port_data_command(tx, v)` inside the closure extends the borrow of `global` too far. The compiler can't prove the `tx` reference in the closure will be valid whenever that closure is eventually invoked. I _think_ you can call `tx.clone()` outside the closure and move that into the closure just fine.
Enum variants are not types. It’s as simple as that. People have talked about making them types, and [anonymous sum types](https://github.com/rust-lang/rust/issues/8277) which would work really well with that, and other things like that, but nothing has ever happened with it. It’s still possible, but it won’t happen any time soon.
Typically manufacturer make some hardware available for this type of effort.
&gt; Also the show_backtrace function is pretty static, not all people use -v or --verbose in their apps to declare more information. There is a variety of ways to do this. `show_backtrace` is part of rustup not part of error-chain, so it can be implemented however you want.
I don't know anything for rust, but I would be interested in having one.
What sort of servers are these? Last time I saw a SPARC-based computer was a workstation from the 90s.
Yeah, there are downsides. If you're not careful, you can end up with dangling indices. For some use cases, the risk is not worth it. 
Hey! That's me! I don't have a Windows machine to dev/test on. :C But PRs welcome ofc...!
Do you know something like Seq (for reading structured logs), but free software / open source?
Did you consider installing the Win 10 preview in a VM? https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewadvanced
The Hip Thing™ in the Rust community is to use the .rs TLD, so you should probably just keep it.
Using channels is a really convenient way of communicating data from inside of a thread to the code that spawned it: https://is.gd/kilQ8x
Because it isn't stable yet. It's only on nightly and could potentially still change before stabilization. The maintainers of the doc (mainly /u/steveklabnik1) have pointed out that they have lots of other things to document and improve before they can justify writing docs for features that might (or might not) change in the near future. Of course, if someone else contributed to the documentation of this (or other) unstable feature, I am pretty sure it would be wholeheartedly appreciated :)
Thanks.
Thanks. I hope when it becomes stable, it'd be excellent.
Just one thing, the dirs library that was cited in another comment [support Windows](https://github.com/tbu-/dirs/blob/master/src/windows/sys.rs). And [the other OSes too](https://github.com/tbu-/dirs/blob/master/src/lib.rs#L54).
So if square was actually something complicated enough to not be inlined (but still pure), the code wouldn't be optimized, am I right? I've seen that you can mark function volatile. Also, in case of gcc, you can mark function pure (via attribute). Are there any plans to allow such things in Rust?
*(disclaimer: I don't know what rustc does exactly in its internal machinery, this is a theoretical answer)* If I'm not mistaking, wat you are describing is a "pure function" / "impure function" dichotomy (stealing the Haskell names). A pure function only takes immutable arguments, computes something with them, and returns the result, while an impure function can have side-effects (IO, mutating its arguments, etc...). Interestingly, most of the time the rust compiler could infer wether a function is pure or not (again, I don't know if it does it or not, but my guess is that all function are treated as impure by rustc, and that llvm does its magic afterwards). An approximation of the rules to finding that out could be: - A function with `&amp;mut` arguments is impure - A function with unsafe contents is impure (dereferencing raw pointers, calling FFI, executing a system call...) - A function calling an impure function is impure - Other functions are pure This is an overly conservative definition, and some pure functions would be treated as impure following it, but this is a general idea.
They are SUN/Oracle servers, not sure about the models. The ones I checked the processor (thought it might be important for cross compilation) were T2 and T3, so from 2007 and 2010. There are newer generation, T5 from 2011. FWIW, I've never been a fan of Solaris, my background is more AIX and Linux, but for some reason I thought rust was as ubiquitous as C.
I believe that your rules would break when calling function on trait object. Or at least Rust wouldn't know. It might help improve optimizations if we could explicitly mark functions as pure. (Especially, in case of trait functions.)
I think, he ask for something similiar to Serilog.
An implementation of http://opentracing.io/ would be a huge plus for the community, and fairly easy to implement. 
Yes, this is accurate. If you'd like to contribute docs for nightly features, I'd love to accept them! But I can't justify spending my time there right now.
I have never heard of volatile function. On the other hand I have seen pure attribute used at varous places. Searching for volatile functions finds http://stackoverflow.com/questions/15283223/volatile-function
Well, enum instances are behind the scenes structs in the form `(discriminant, content)`: tagged unions. This intrinsic just reads the value of `discriminant` and gives it to you. So yes, it's a runtime computation.
Since I dualboot Windows and Linux this could be useful for me so I'll see if I can't have a PR in sometime this week. If you aren't already working on it :)
A bit off-topic, but did someone figure out a way to do the same kind of API for middlewares as rouille (https://github.com/tomaka/rouille/blob/master/examples/hello_world.rs#L7) using hyper async api? The code is spread around quite a bit (https://github.com/Keats/sylph/blob/master/src/request.rs#L61-L173 for my own framework) which makes it tricky. In short a somehow sync API on top of the async API would be nice, I don't see how to have a closure from the start to the end of the request.
in the comparison between the parser libraries, what do you mean by "separated" or "mixed" in the "code" category? Also, nom does not have a generation step, it uses macros to build the parser :)
pest is looking pretty damn good, currently moving Tera to it (https://github.com/Keats/tera/pull/37) with (lots) of help from dragostis and it works very well up to now!
Oh, I just realized, I meant method, not function. Method marked volatile is actually marking `this` pointer as volatile, of course. http://stackoverflow.com/questions/9006693/c-const-volatile-methods
Copy-pasting is *bad*. Sorry for the mistake. :D By separated I mean that you can mix the grammar with code, which is possible in nom, but you don't have to do it. Any other ideas worth comparing, you name it. :D
The difficulty you'll encounter is that `Enum::Variant` is not a type, it's either a value or a function (constructor of the value). So you can't pass it to an intrinsic without instantiating the enum to the variant you want. So... What you ask would most likely require actually changing the semantic of something in the language, no just creating a new intrinsic function.
Not really. I'm trying to do things like: struct Foo { data: String, first_word: &amp;str, last_word: &amp;str, } ...where `first_word` and `last_word` both point to somewhere inside `data`. You can't do that with owning_ref (at least not without `Rc`).
Have you tried this code locally? The playground might have low memory limits and since both `main` and `sum_array` store it on their stack then disregarding optimisation you will have a total stack size of 2 * 1000 * 1000 * 4 bytes.
What do you mean by "specialized" grammar in nom? Also the links to nom and LALRPOP are broken. Also you could probably compare with [combine](https://github.com/Marwes/combine) as wellk (but perhaps this is redundant; combine is a parser combinator in the style of parsec)
Remember that the Vulkan example isn't just about string references, and the lifetimes (or `Arc` reference counters) are actually needed to expose a safe API.
I see. I guess that performance of the parsers created from a generator will be better than parsers based on combinators.
If I understood correctly, the first code block (containing the `error_chain!` macro) is the "new boilerplate." The second code block is the "old boilerplate" equivalent, i.e. approximately what the macro call expands to.
I think it really depends on the case, grammar and file that you're parsing. Generators have the added benefit of being able to inline a lot of stuff. At the same time, parsing large files with a combinator may benefit from runtime optimizations, or even static optimizations in the case of Rust and Haskell.
Well, nom goes further than normal parsers by providing a lot more tests that you can use inside of the grammar.
Packrat actually helps you define rules nicely and in a lazy manner inside PEGs without worrying at all about performance. :D
const-fn is exactly purity -- it asserts that the function can be evaluated at compile time, and reproducibly so.
Note that the fact that this segfaults is a bug, tracked here: https://github.com/rust-lang/rust/issues/16012 . Ideally this would instead result in the same sort of controlled termination as e.g. `fn main() { main() }` .
Yes, it's clear that values aren't qualified to be passed as arguments or template parameters. That there's currently no way to ask for the underlying even though it exists was the motivation I originally posted this topic. Looking back I have to admit that I haven't made that entirely clear. I have no experience with procedural macros, but as far as I see it they are Rusts way of introducing new / exposing internal functionality, analog to keywords in certain other languages, correct? If yes then that's pretty much exactly what I'm looking for.
Well, it bothers me enough to try to find a solution to it, at least :-)
What about an arena?
This could affect crates.io (yay buildscripts!) AFAICT. However there are some important caveats with cargo. For one thing, dependencies are added by editing a file, and CLI tools for including deps are third-party. IME, I and others are more careful with typos in an editor than on the command line. Further, my usual practice is to copy/paste the toml line from the crates.io page, and then remove the patch version. But maybe that's not typical? Regardless, there's no tool for system-wide installation like pip or npm has, so it seems to me like there's likely to be more intention behind adding a crate dependency. Also, crates don't execute buildscripts when you add them to your Cargo.toml (whether or not you use a tool like cargo edit), buildscripts run when you actually build your project, so there's more chance you'll find the typo in between typing it and when malicious code could run. Anyway, there are three potential mitigations listed in the post: "**Prevent Direct Code Execution on Installations** This one is easy. Make sure that the software that unpacks and installs a third party package (pip or npm) does not allow the execution of code that originates from the package itself. Only when the user explicitly loads the package, the library code should be executed. **Generate a List of Potential Typo Candidates** Generate Levenshtein distance candidates for the most downloaded N packages of the repository and alarm administrators on registration of such a candidate. **Analyze 404 logfiles and prevent registration of often shadow installed packages** Whenever a user makes a typo by installing a package and the package is not registered yet, a 404 logfile entry on the repository server is created (because the install HTTP requests targets a non-existent resource). Parse these failed installations and prevent all such names that are shadow-installed more than a reasonable threshold per month." The first doesn't seem practical because a) cargo supports arbitrary code execution in tests/benches anyways (duh) b) it'd be crappy to deprecate and c) it's really important for FFI crates and stable alternatives to compiler plugins. The second seems possible, but that raises the question of what criteria to use. How many edits from an existing crate title should be flagged? Who on the already busy tools/infra team(s?) should be responsible for whitelisting false positives of the filter? The third is nice because it's passive, but then you still have to have a threshold which is responsive to the overall traffic for a crate name. For example, a reasonable threshold for PyPI is going to be a lot higher than for crates.io, the same way a threshold for my crate which is only ever built by crater won't be suitable for winapi, nor vice versa. How many mis-typers need to be protected from themselves to justify the inconvenience to legitimate crate authors and the rust teams? Which raises another question of priority -- I'd argue that there are many worse ways to mess with crates.io than "typo attacks," and that many of those are yet still lower priority than other features and bugfixes which don't have engineering resources dedicated to them.
Have typo'd my pip installs 10000x. Would definitely have been owned by this. In terms of defenses: &gt; Prevent Direct Code Execution on Installations This one is easy. Make sure that the software that unpacks and installs a third party package (pip or npm) does not allow the execution of code that originates from the package itself. Only when the user explicitly loads the package, the library code should be executed. Cargo lets packages run arbitrary code on startup. This is pretty useful and important. I wonder if we can use a sandbox model for this - don't let cargo scripts touch anything outside of the code directory. Still dangerous but at least you don't have arbitrary read/write access. I would imagine it is not idiomatic to install dependency packages for cargo scripts. &gt; Generate a List of Potential Typo Candidates Generate Levenshtein distance candidates for the most downloaded N packages of the repository and alarm administrators on registration of such a candidate. Crates.io could do this as part of publishing. This might get annoying if you're doing something like: packagename packagename-rs But then again, do we want that naming scheme? &gt; Analyze 404 logfiles and prevent registration of often shadow installed packages This seems easy enough to implement entirely on crates.io and an easy win. However, watering hole attacks would potentially bypass this - I know COMPANY uses some lesser used package, so I target that package. Since it's less used, it's less likely to have met the malicious threshold. Apparently the thesis goes into other defenses but I just read the blog post :P
I don't like auto-exec'ing buildscripts. But buildscripts are incredibly useful. For `cargo`, we could simply stop automatically executing the buildscripts. At the same time, provide a switch called `--dangerously-exec-buildscript` or something else equally instructive. Then, if I'm sure I know what I'm doing, I can do `cargo install foo --dangerously-exec-buildscript`
It's supposed to be possible to get community access to AIX on some IBM cloud IIRC. Anyone with an interest, is well advised to look into that.
Ah, excellent. Thank you.
Malicious code can be put into crate source code itself, not into buildscript.
You can probe the type of something like this: let _ : () = something; This will fail with a message like "something doesn't have type (), type so and so is expected" The problem is that this has some interference with the borrow checker (it's a move). I think that type ascription (writing `(expression : type)` where `expression` is expected - like `expression :: type` of Haskell) is still unstable, but I'm not sure. And if you don't want to write the value of something, you can write `unimplemented!()` on its place. It's like Haskell's `undefined`.
I don't think this a problem that can or should be addresses at the package manger level. What we really need are sandboxed dev environments from the OS vendors so that your dev environment can't steal credentials from your keystore etc.
Eh, I don't see it. What if some-bin always executes a build script anyways? To the user it will be expected behavior. Besides, warning fatigue is a real issue, and warning for something that is benign 99.99% of the time is a great way to get everyone to click through while still touting that the tool is "still secure".
Yes, definitely - I built Seq so I'm perhaps a bit biased in preferring it :-). An Elasticsearch collector is in the works (https://github.com/emit-rs/emit/issues/11) and there are a bunch of other options of varying sophistication. The model is designed to work with pretty much any structured event collector.
Is there a 'proper' way to structure/layout binding crates? E.g. I split out the bindings into two crates ([nfc](https://github.com/dsgriffin/nfc) and [nfc-sys](https://github.com/dsgriffin/nfc)) - should it have been split in two? apart from fixing warnings + tests/doc how can these be improved? (brand new to Rust/systems prog)
In Linux, you can remove your stack limit. Run this in your shell, then run the command from the same shell. $ ulimit -s unlimited Use this to see all your process limits. $ ulimit -a 
interesting. What I have in mind would go a little further, e.g. using _ as a function name or field index; '''{blah blah; let foo= _(baz); ... ;foo}''' .. and it would from forward &amp; backward inference figure out (a) the required signature of the identifier _, and (b) actually give a list of functions that fits. it could be like 'autocomplete on steroids' (by virtue of having superior type information.. e.g. letting return expressions compile and work backwards) 
Macro expansion occurs before type resolution. That kind of thing just isn’t going to work in general.
How would package signing solve this problem? I don't see it.
I do really like the idea of a sandbox but I think we also have to ask what the threat here is. The *assumption* in a sandbox is that your attacker can execute code local to the sandbox. At that point, they have access to your code, binaries, some networking (though you could limit this to some extent). It isn't hard to come up with ways in which you can leverage those to be very dangerous. So they couldn't get your keystore but they could patch your binaries and suddenly you're deploying backdoors for them. That said, least privilege is always a good idea. More software should be built this way.
I think it's the whitelist which would actually solve the problem -- the package signatures would just allow the whitelist to be enforced.
Set up build server. Create whitelist of package signing keys for the builds. Package abab key is on this list. Some dev fat fingers package abba into the application? Build fails. Package signing key is not in the whitelist. I only trust packages signed by keys on the whitelist. edit: Wow. Congratulations guys. Modding down because you dislike the truth. I love this community and its passive aggressive code of censorship. You like being owned regularly in the news? Keep that up, you'll have no problem maintaining your bad reputations.
&gt; host malicious packages You make it sound like the hosted packages were dangerous or intended to be, which isn't true. I understand you can have ethical concerns regardless, but there's a vast gulf between them. This is roughly equivalent to having the PyPI server log specific typo'd requests. I wouldn't particularly mind if crates.io started to do that.
One thing I worry about is how cargo statically compiles rust code together by default. This makes sense for portability, but not so much for package management. Even if you published an updated crate that fixed said vulnerability, all developers would have to update and re-build their binaries that included your crate, and then get end-users to install the new binaries. Traditionally, *nix has solved this problem by shipping dynamically linked binaries with symbolic links to the ABI version families (ex: `/usr/lib64/libfoo.so`, `/usr/lib64/libfoo.so.1`, `/usr/lib64/libfoo.so.1.2`, `/usr/lib64/libfoo.so.1.2.3`). By installing each dependency separately, a package manager can easily update one shared library, and ensure every program that linked to that library would also get the update; once restarted, of course.
I ran into the same problem with solving this problem using nesting just last week. My solution was the same as your first solution, and I decided to skip trying to figure out how to do "nested destructuring" and forge on ahead. I'm glad you took the time to ask the question. 
'The type defined for this error' contains a typo. The `types` block defines multiple types. It's defining 4 types. The conventions described are established by this library as suggestions for users of the library, though the names `Error` and `Result` are conventional across Rust. They must be repeated here because Rust macros are hygienic and can't generate those type names themselves - they must be provided as input. You would want to define additional ErrorKind variants because they allow callers to dispatch on the error type. If callers might want to distinguish e.g. an error downloading a file from any other error, you would want to provide them a variant to do that with. Thanks for the feedback. Docs can definitely be improved.
rustdoc has type driven search as well, its not quiet as advanced as hoogle though. The major piece missing is a central doc registry. It would be really nice if crates.io would host docs as well, so we can get that feature. As a hack, you could probably make a 'hoogle' crate that depends on all of crates.io and generate the docs for everything.
Linking isn't relevant here. Cargo won't update each crate's dependencies without you telling it to for that specific crate. This is extremely important for reproducibility.
I'm hoping you improve the docs on Dyon/Piston!! I'm really hyped for this but as my programming skills(especially Rust) is limited to some game scripting and recreational programming, learning about Piston(conrod and the graphics libs) was awesome. Sadly the blogposts where all about WIPs and plans and nothing as detailed as for example ArcadeRS. I get that it's all in early stages so basically I'm saying that I'm looking forward to it!
Oh. Yeah this would only solve the problem in the case where you have a build server that you can configure in such a way. In the end it's just a whitelist that you use keys for, and I can't see this really addressing the root issue.
I'm working on an Asteroids demo for the release of Dyon v0.8: https://github.com/pistondevelopers/dyon_asteroids The final version will have 3D objects. I've made a simple spaceship model in Blender and have managed to prepare all triangles of same material, attach it to the spacheship coordinates. Next step is to show two different materials, then add lighting to the shader. Then I will try some 3D for the asteroids. Not sure what to do about explosions yet. Do you have any experience with sound effects?
Just the basics with implementing them, nothing with making my own effects( /r/gamedev kinda spoiled me with their resources on audio). 
So you're using keys as a proxy for author names -- why not just whitelist package owner names (which are part of the crate's metadata, and globally unique)
Can we expect an intermediate course? Or something like "Automate the boring stuff with Python", where during a course you'll make small programs? As for the beginner one on Pluralsight, I'm liking it! Not far in it but you explain this clear and concise.
The part that makes it malicious to me is the information gathering the author did. He wasn't just checking to see how many downloads his packages got, after the package was downloaded it would run code to search the user's history to find other packages they had downloaded, whether the user was an admin or not, and queried their hardware information before sending everything back to his university over HTTP. Eventually one of the PyPi admins told him to stop querying hardware information and said that just searching for "pip" in the user's history could return sensitive information like passwords, or internal IP addresses. None of the information gathering was even necessary for the research project. If you check the thread over in /r/netsec you'll see that what the student did is actually illegal in multiple countries; he was using the misspelled packages to gather information off people's computers without their consent.
How would this work? The OS has to allocate some number of pages for the stack Edit: There is an environment variable that controls how much stack a Rust program starts with, called RUST_MIN_STACK. It's in bytes
This is enforced by policy rather than cryptographic means though. There is nothing stopping Crates.io from allowing anyone to change any crate as the necessary credentials are all in one party's control. I wish we can adopt google's way of doing things and have developers sign their crates.
&gt;why not just whitelist package owner names (which are part of the crate's metadata, and globally unique) Because crates.io could become compromised, social engineered, MITMed, zero dayed, NSLed, etc. A cryptographic signature addresses all of these problems, because you can verify that the package was signed by someone in control of a key you trust. I can't answer your questions any faster. Reddit won't let me. See https://www.coursera.org/learn/crypto for more info if you're genuinely interested.
What is rusts back story 
I'm familiar with how digital signatures work. But fundamentally you're just building a whitelist that happens to use crypto. Whitelisting works in a situation where you can build your whitelist, but that hardly seems ergonomic - I open up a new cargo project, I try to add a dependency, it says "hey you haven't trusted this key yet" and I go "oh ok ill trust it then" and yeah back in the same position.
`rsut-lang-nursery/log`. done.
Yes, this is exactly as I suggested. Your pet issue has nothing to do with the question at hand though, which is what to do when the person in charge of a (silently broken) package disappears.
I actually had a weird dream about this happening on Haskell's Hackage package archive a few years ago. It ended with me and a well-known figure in the Haskell community trying to destroy viruses in someone's back garden. It was a weird dream.
I take back what I said. I barely read the code and assumed that it was collecting much more coarse-grained data than it is. (eg. I assumed the command history was only used locally.)
Crates.io has supported namespaces since basically day one. I can register gankro-log, and Steve can register steveklabnik-log. They can even be imported into the same project without conflicts.
We are speaking past each other. I understand the facts you are bringing up, but they aren't relevant. cargo locks your build to a specific version of each crate, that will only change when you run cargo update or change the version you depend on in your Cargo.toml. You seem to be suggesting that cargo should not use a lock file and just use the latest version of every dependency.
&gt; cargo locks your build to a specific version of each crate, that will only change when you run cargo update or change the version you depend on in your Cargo.toml. That what worries me. The lock file and distributing static binaries that include specific versions of other crates is a security patching nightmare waiting to happen. With dynamically linked binaries, you can do patch-level updates to the libraries, without having to build a new binary or update the lock file.
This does nothing for Windows, Android, iOS, and most users of OSX, where one needs to vendor libraries even if they're dynamically linking them, and therefore needs to build and distribute new versions anyway. This does nothing for packages distributed by a Linux distro, where the maintainers can (and do) tell the package to prefer dynamic linking. So basically you're saying cargo should default to dynamic linking and force people to figure out headers and 17 package managers to make system maintenance a bit easier for linux users who don't want to install something via their package manager?
Again, static/dynamic is not the issue. Cargo could dynamically link the libraries and still have the same behavior if it dynamically linked according to the versioning in the lock file. Automatically updating dependencies is what sounds to me like an absolute nightmare of broken builds and dll hell. In contrast, upgrading nokogiri and rails and so on as CVEs are announced has not been much of a nightmare in my experience.
Nice. I'll take a look. BTW. Shouldn't you add some "logging" tag or in description? I did not find your package when looking on crates.io so I believe other people might miss it too.
Could I register gankro-foo? If so, that's not what people generally mean when they say Cargo should have namespaces. They mean "first class" namespaces that have metadata for access control attached.
I'm assuming that's in jest, but it would be straightforward to reserve some likely names and require admin approval to use them.
Yes, this has nothing to do with green threads. Objects on the heap can be moved off the heap. Rust has affine types, it doesn't distinguish between the stack and the heap here. You need something like an arena to self-borrow structs on the heap. Maybe not the stdlib arena, but a new permaarena that allows construction on the arena itself, but not moving out. Note that there are nuances when it comes to constructing such objects. IIRC you can actually make objects borrow themselves, they just become immovable after.
welcome :))
About handling path names as strings: [`if !name.ends_with("/") { name.push_str(".rs") }`](https://github.com/ChasingLogic/cargo-mod/blob/175dca1e5a3c85a197207aad608e043e99fdf1c3/src/module.rs#L16) [`for dir in name.split("/") {`](https://github.com/ChasingLogic/cargo-mod/blob/175dca1e5a3c85a197207aad608e043e99fdf1c3/src/module.rs#L28) What about using [`std::path`](https://doc.rust-lang.org/std/path/)? It would make Windows compatibility easier too. I think that `for dir in Path::new(name) {` works for example (because paths implement an iterator over their components) PS: you might not need it, but keep in mind [walkdir](https://github.com/BurntSushi/walkdir) if you ever need to walk a directory recursively.
Now you're no longer addressing the typosquatting attack. Also, assuming that because someone disagrees with you they don't understand basic crypto concepts is frankly not a great way to comport oneself.
&gt; They must be repeated here because Rust macros are hygienic and can't generate those type names themselves - they must be provided as input. Hygiene does not apply to type names, only local bindings. So I think you could have defaults, if you wanted to.
The OS can lazily allocate the stack. In fact, [Linux does that even when the stack is finite](http://unix.stackexchange.com/a/145563).
Thank you for great link! It sounds reasonable to me now.
Idris has a very extensive holes workflow + a language server helping out with that. https://www.youtube.com/watch?v=vkIlW797JN8 (coding part starts a bit in) I would definitely like to see something like that for Rust :).
I was the one who raised the vecmap github issue and I also was not aware of the slab crate. And yep, had the same thoughts about the api being not nice. Even against error handling guidelines.. Returning Result for something that would only fail if the programmer did a mistake, panicking seems like the better choice. 
It's [still unstable](https://github.com/rust-lang/rust/issues/24111).
I know this is sounding a bit like "just fix it yourself", but work input is very appreciated there :). rustdoc needs more friends and doc publishing to crates can also help a lot! We're very open to these things, as long as it maintains well (especially on the operational side).
Looks like it's back up
Two testing related questions: 1. I can access private struct fields in a nested tests module, but not when I put the tests in a `tests/` directory? 2. For `dev-dependencies` I need to put my tests into the `tests/` directory? There's no way `extern crate ...` works with a nested tests module? 
Normal users will still take whichever keys crates.io gives them, so this won't help them any. If you care about these sort of things, you should run your own vendored server and verify the repositories you clone.
RUST_MIN_STACK is for thread stacks. The Rust runtime allocates those. The main thread's stack is created and allocated by the kernel.
For 1, that's correct. I think in-same-file tests are kind of meant for unit tests, while tests/ is meant for integration tests. For 2, you should be able to do something like your root file (lib.rs) to use dev-dependencies in same-file tests: #[cfg(test)] extern crate ...; I haven't confirmed this as I'm not on a computer but it should work to allow dev dependencies outside of the tests/ directory.
&gt; `UnsafeCell` is a special type known to the compiler Oh boy, I don't like that :-( Where can I read more about that? And about other types the compiler knows about?
It actually *is* possible to emulate existential references: pub trait LifetimeFamily&lt;'a&gt;: 'static { type Output; } pub struct Existential&lt;I&gt; where for&lt;'a&gt; I: LifetimeFamily&lt;'a&gt; { data: Box&lt;&lt;I as LifetimeFamily&lt;'static&gt;&gt;::Output&gt; } impl&lt;I&gt; Existential&lt;I&gt; where for&lt;'a&gt; I: LifetimeFamily&lt;'a&gt; { pub fn enter&lt;T, F&gt;(&amp;mut self, f: F) -&gt; T where F: for&lt;'a&gt; FnOnce(&amp;'a mut &lt;I as LifetimeFamily&lt;'a&gt;&gt;::Output) -&gt; T { let data : *mut _ = &amp;mut *self.data; let data = unsafe { &amp;mut *(data as *mut &lt;I as LifetimeFamily&gt;::Output) }; f(data) } pub fn new(s: &lt;I as LifetimeFamily&lt;'static&gt;&gt;::Output) -&gt; Self { Existential { data: Box::new(s) } } } pub struct S&lt;'a&gt; { s: String, inner: &amp;'a str } impl&lt;'a&gt; LifetimeFamily&lt;'a&gt; for S&lt;'static&gt; { type Output = S&lt;'a&gt;; } fn main() { let mut i : Existential&lt;S&gt; = Existential::new(S { s: String::new(), inner: "" }); i.enter(|i| { i.s = "hello".to_string(); }); i.enter(|i| { i.inner = &amp;i.s[1..4]; }); i.enter(|i| { println!("{}", i.inner); }); } This is unsound in the presence of destructors unless you leak the interior, but sound otherwise. Unfortunately, this causes an ICE on newer versions of rustc (https://github.com/rust-lang/rust/issues/33364) - hopefully we will get lazy normalization soon enough.
I'm no expert on the compiler internals, but there are some that it obviously knows about: `Copy`, `Sized`, all the [primitive types](https://doc.rust-lang.org/nightly/std/#primitives), all the [operation traits](https://doc.rust-lang.org/nightly/std/ops/), `Result` (for `?`), ...
Actually, I believe with `UnsafeCell` the team managed to create a good primitive, it is the common denominator used to build `Rc`, `Cell`, `RefCell`, `Arc`, `Mutex`, `RwLock`, en probably a few others. So, they managed to keep the compiler magic quite minimal.
Transmuting a `&amp;` to `*mut` is not, but derefencing that new pointer will likely be UB.
WWWWWWWWWWWWWWWWWWWWWWWWWrrrrrrrrrrrrrrrrrrrrrrrroooooooooooooooooooooonnnnnnnnnnnnnnnnnnnnnnnnnnggggggggggggggggggggggg sssssssssssssssssssssssssssuuuuuuuuuuuuuuuubbbbbbbbbbbbbbbbbrrrrrrrrrrrrrrrrreeeeeeeeeeeeeeeeddddddddddddddddddddddddddddddddddddddddddddddddddddddddiiiiiiiiiiiiiiiiiiiiiiiiitttttttttttttttt https://www.reddit.com/r/playrust/
The video was lost, though I gave an updated version at the ACM's conference last week, and there will be video. &gt; what was the "Great Netsplit"? Like a week before the talk, Mozilla's IRC had a huge netsplit, and a lot of idle users didn't immediately come back. So we went from like a thousand people to 450 or something.
I don't feel like that's a large problem for normal users, as the workflow usually goes: 1. User wants to run `some-bin` 2. User runs `cargo install some-bin` 3. User runs `some-bin` I'm not so sure how stopping `some-bin` from executing code at stage 2 help, especially since cargo doesn't require root or anything. 
Yes, I'm waiting to do any rust work for my distro until offline cargo support is available (Debian folks have patched cargo to do these things of things though, iirc).
Great post! &gt; Neither are safe to be directly used in a multi-threaded environment and should be wrapped in a Mutex or RwLock It is better to state: "Neither are safe to be used in a multi-threaded environment and Mutex or RwLock should be used instead." `RwLock` is the multi-threaded equivalent of `RefCell`, but `Cell` has no such equivalent (`AtomicUsize` comes close to `Cell&lt;usize&gt;`).
And then everyone needs to write `extern crate gankro_log as log;` in lib.rs. And there's not a good way to search for "gankro-*" on crates.io, or to have cargo swap the namespace of dependency. And what /u/Meyermagic said below -- likely it'd want to be tied to some other form of identity as well. That's not support, it is the opposite of support. And not supporting namespaces was an explicit decision -- some people think it was the wrong decision, but we shouldn't pretend it went the other way.
Eventually, you should be able to write `box [...]` but that's still unstable.
It works in every other open source ecosystem. Take Rubygems for example; they have even less people running the show than we do.
To be clear, I would like to see improvements here myself, but our current state is the exact same as at least the Python, Ruby, and Node ecosystems.
The sentences "Neither are safe to be directly used in a multi-threaded environment and should be wrapped in a Mutex or RwLock" and "This aspect makes RefCell unsuitable to be used in a parallel scenario without additional protection" sound like it is possible to use RefCells from multiple threads, which isn't possible anyway. Please rewrite them to clarify this.
I don't feel like you've addressed my objection though. I'm claiming that most of the usages of binary cargo packages should be thought of as `cargo install foo &amp;&amp; foo`, and treat *that* as the threat for typos. I don't think adding a flag to cargo to restrict build script would help in that case at all, as you are about to run the binary anyways. Make sense? Also a lot of my projects have `build.rs` files as I do a fair amount of interfacing with C, and getting headers automatically compiled. I do not want to have to add another flag to cargo each time I call `cargo build` (which is what looks in `Cargo.toml` and fetches and compiles the dependencies). I don't think there is any additional security there, as you are going to run the binary you built, with the libs linked in. If it's malicious, then you are still screwed. 
Oh, good point. Thank you, I have updated the post.
Thanks! Like Luthaf and levansfg point out in other replies, both `Cell` and `RefCell` contain an `UnsafeCell` inside, and that is one of the few primitives that get special treatment by the compiler. I decided to make this a more practical article, so this bit about `UnsafeCell` had to be left out, but I might explore how it works in another post, as you suggest. :)
The problem in the paper is not about the binary - it's about the build. I was considering the flag to address something like `sudo -u admin cargo install soem-bin &amp;&amp; some-bin`, where the installing user is not necessarily the running user and the execution of the binary is not necessarily run immediately afterwards. That sort of thing happens when you have administrators setting up environments for other people to use. But even if it were your example `cargo install soem-bin &amp;&amp; some-bin` there is still a threat that `soem-bin` does something malicious during the build but produces a benign `some-bin` binary, perhaps even identical to the actual `some-bin` (imagine a cloned repo where only the build script is changed). That threat is compounded if there's an escalation path to a user with higher permissions. I believe the flag still helps in that situation. You can make an argument that just by running cargo you are implicitly assuming responsibility that the command you have executed was vetted for correctness. That's totally fair and rational. Running a binary has the same implicit assumption. The difference in my mind is that you _must_ have that assumption for the binary but you don't for the build. &gt; I do not want to have to add another flag to cargo each time It is for that reason I suggested additional config to disable the check. It could probably be done per package name, or even file system path dependent. Plus you could always write a small wrapper to add the flag. Or just `alias cargo-build='cargo build --no-buildscript-warning'`. That way you opt out of the security rather than opt in.
Also pypi. The necessity of package takeover tends to be pretty rare so it's not something which actively requires scaling.
&gt;Now you're no longer addressing the typosquatting attack. Your response strains credibility. Please explain to me how author names are immune to typos while package names are not. I don't mention it, because I assume it is implicit. You know what doesn't have a typosquatting problem? Public key hashes. They are essentially immune to typos, because generating a second key with a hash with a small edit distance is computationally hard to the point of being impossible. If you have a typo in the hash, it's almost certain that you will get no key at all. &gt;Also, assuming that because someone disagrees with you they don't understand basic crypto concepts is frankly not a great way to comport oneself. I didn't see Gankro disagree with me. Gankro asked a question and I answered it. I assume s/he sincerely wants to know an answer. Only you assume Gankro disagrees.
We shall see how it goes. Course production is contingent on demand, and Rust is a very young language. Need to see how well the Fundamentals course does first, and take it from there.
Are there examples of this happening in rubygems as a result of a security issue?
Awesome, tyvm. Community leaders like you are why I'm glad that I've chosen to spend time learning Rust :)
I might be understanding this wrong, but shouldn't [this](https://github.com/ChasingLogic/cargo-mod/blob/master/src/utils/mod.rs#L13) pub fn are_in_project() -&gt; bool { let mut cwd = env::current_dir().unwrap(); loop { cwd.push("Cargo.toml"); if cwd.exists() { return true } if !cwd.pop() { return false } } } be this pub fn are_in_project() -&gt; bool { let mut cwd = env::current_dir().unwrap(); loop { cwd.push("Cargo.toml"); if cwd.exists() { return true } cwd.pop(); // &lt;-------- if !cwd.pop() { return false } } } [The first pop would only remove the "Cargo.toml" component.](https://is.gd/ow2Lkf)
Once the packages were made aware to me I removed them. The individual involved reached out to me and told me what he was doing. I informed him that the information he was collection wasn't acceptable and said if he wanted to continue his experiment he would need to remove any PII from what he was sending, which caused him to trim it down to just: * The typoed name of the package they installed. * The name of the package they presumably meant to install. * The string "pip". * The return value of platform.platform(). * Whether or not it was being invoked with admin rights. All but the last one are present in the user agent of pip or request line (or inferable via that) and a boolean of admin/not is not nearly enough bits of information for it to be PII.
Thanks, and also for the very nice post!
A nice article about Cell and RefCell? Beginning by quoting me? Cool. :-) Btw. I'd suggest using Atomic types for threadsafe interior mutability on primitive (copy) types, e.g. AtomicUsize.
That graph of MagicPoint seems to imply that Cell and/or RefCell store their wrapped value somewhere else, e.g. on the heap/in a Box. Is that true? I thought it would be stored inline.
It isn't so unique to Rust. In Java: final Long foo = 1L; //immutable final AtomicLong foo = new AtomicLong(1L); //internally mutable But, granted, a lot of people have trouble w/ the concept in Java as well.
I think that's kind of different, because final doesn't mean immutable. It just means non-re-assignable.
No, though I was at a Ruby conf a few years ago where this attack was demonstrated. They printed out business card with "gem install conf_name" and then the talk was about how many people actually ran it. This was 3, 4 years ago?
As useful as interior mutability can be I think its worth mentioning that `RefCell` and `Cell` are extremely infectious since they don't implement `Sync`. Once you add one of them into a structure, that structure and any which contain it will lose their `Sync` implementation which can be really painful. Even if you don't think `Sync` matter right now, it may be important in the future, and refactoring is not necessarily straightforward as `Mutex` and `RwLock` have more severe performance penalties. Basically, just make sure interior mutability is the correct choice instead of bolting it on to make to borrow checker happy :) (I know I have made that mistake a few times).
`Long` is an immutable type, that's as relevant to the point as `final`. The biggest difference in my mind between Rust vs. Java on this particular axis is that in Rust the owner determines mutability except when the object is internally mutable, while in Java the object itself always determines its own mutability.
Can [splitting borrows](https://doc.rust-lang.org/nomicon/borrow-splitting.html) fill the same role in some cases? 
TIL. Thanks for the hint!
At least in the case of a left_pad-like incident, [crates.io has no "unpublish"](http://edunham.net/2016/03/24/could_rust_have_a_left_pad_incident.html).
In general, "offline cargo support" is here; it's only the initial fetch of packages from crates.io that needs to be online, and that's because, well, it has to be.
Thanks for showing up and clarifying.
You can of course manage your local repository and use that instead of crates.io. And since you already have to trust rustc if you want to compile Rust code, it's not a leap to trust cargo, too. They're made by the same people after all. The last year had &gt;95% crates working on 1.0 to 1.9 (one version every 6 weeks), so the ecosystem enjoys good stability. So, why *shouldn't* you trust cargo and crates.io?
I've got a struct that wraps a FFI raw pointer and I'm having a heck of time implementing Deref for it. Any tips? https://is.gd/HxAieM
The nice thing about GFX would be that you get Vulkan support as soon as they add it to GFX. You wouldn't have to change anything right?
It is inline. It looks like `struct UnsafeCell&lt;T&gt; { value: T }`. 
My solution in the upcoming Rustful update is to let the user set a callback that is called whenever any body data may be read. This allows them to keep their own buffer, and I have added a few variants for things like reading the whole body at once. I don't have a good solution for multipart/formdata, though, but I'm sure something will present itself soon enough. The library I'm using requires something that implements `Read`, so my current workaround is to spawn a new thread and send body data to it. An other tricky problem I have encountered is how to deal with blocking resources, such as reading files or using blocking database connections.
All my data is accessible through my use account though, including my UI interaction (since X11 security is non existent). Also all my bandwidth and computing resources. The only useful thing a malware without root can't do is to evade detection - unless it uses an exploit. But by the time the malware is detected the malware already had chance to do its thing. [Relevant xkcd](https://xkcd.com/1200/).
[Image](http://imgs.xkcd.com/comics/authorization.png) [Mobile](https://m.xkcd.com/1200/) **Title:** Authorization **Title-text:** Before you say anything, no, I know not to leave my computer sitting out logged in to all my accounts\. I have it set up so after a few minutes of inactivity it automatically switches to my brother's\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1200#Explanation) **Stats:** This comic has been referenced 83 times, representing 0.0728% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d42y98x)
I will make an example if in case I am failing to communicate my intention: If I have an `enum E { V { foo: sometype },}`, I want to be able to compare an instance `let inst = E::V{foo:"bar}` with the variant `E::V` and have this comparison yield `true` if `inst` is of variant `E::V`. A means to achieve this already exists in the language - the discriminant of the variant. But as it stands one can only extract this discriminant from an instanced variant `inst`, not from the variant definition `E::V`. The only missing feature here is a way to get the discriminant from the variant without instancing it. And I am completely open to how this feature would manifest, all I gave were naive suggestions.
In theory someone could do a [zero-knowledge proof](https://en.wikipedia.org/wiki/Zero-knowledge_proof) that would establish the security of their closed system to whatever standard you'd hold an open system. So there is no actual need to inspect the source to know it's secure, you just need to formalize what 'secure' means to you and put in enough effort. 
Wrong subreddit. You want /r/playrust.
On the other hand, if you're interested in learning the Rust programming language, we'll all be happy to help out. :)
about using blocking resources, you can refer https://github.com/hyperium/hyper/issues/766#issuecomment-219826342
This works. pub trait Visitor {} pub struct Escort&lt;'a, V: 'a&gt; where V: Visitor { _visitor: &amp;'a V, } This does not work, and I understand why. pub trait Visitor&lt;E&gt; {} pub struct Escort&lt;'a, V, E&gt; where V: Visitor&lt;E&gt; { _visitor: &amp;'a V, } `error: the parameter type 'V' may not live long enough` [\[E0309\]](https://doc.rust-lang.org/error-index.html#E0309) This also does not work, and the error message baffles me. pub trait Visitor&lt;E&gt; {} pub struct Escort&lt;'a, V: 'a, E&gt; where V: Visitor&lt;E&gt; { _visitor: &amp;'a V, } [Playground link.](https://play.rust-lang.org/?gist=9e3a8f054accfc506fe88dfb885adb93&amp;version=stable&amp;backtrace=0) `error: parameter 'E' is never used` [\[E0392\]](https://doc.rust-lang.org/error-index.html#E0392) What am I doing wrong? It is legitimate to parameterize traits, isn't it? **Update:** I found the [PhantomData](https://doc.rust-lang.org/std/marker/struct.PhantomData.html#unused-type-parameters) documentation. It looks like this is a known thing.
don't known how to read it on mobile (no arrow keys). 
`std::Shared` has the same functionality (it's used slightly differently). See the Rustonomicon for more information.
If you make your own wrapper around vulkan, then you probably want a struct like this: struct MyGraphicsLibrary&lt;'a&gt; { context: Context, program: Program&lt;'a&gt;, commandbuffers: Vec&lt;CommandBuffer&lt;'a&gt;&gt;, } ....where the command buffers point to the program and the program points to the context. This is impossible in current Rust (unless you use unsafe, or the [self-lock trick that makes the struct permanently borrowed](https://www.rust-lang.org/faq.html#how-can-i-define-a-struct-that-contains-a-reference-to-one-of-its-own-fields)).
I don't know if he was confused about the async/await question, but he definitely misrepresented it. The rest looks pretty great. The future is bright!
Another, more simple strategy: download the crates you want, and then depend on them with a path dependency, rather than trying to depend on them through crates.io. This more directly states what you're doing: "I want to use this package on disk here."
Just like they'd search for and find the older namespace, without knowing about the newer one.
Thanks, that's very interesting! As arielby points out, it's not a safe abstraction right now (just add another assignment to `S::s` *after* your assignment to `S::inner` and you'll have a dangling reference in `S::inner`), but combined with other safety measures it might work. If MIR or ICEs won't break it, that is :-/
My company gave up on that and has POWER hardware now. I've actually thought about trying to port rust to AIX since I have hardware access, but there's more than the codegen (binary file formats in llvm, and the rust stdlib are the big ones). It'd be months of effort for a small team, and easily a year+ for one person
&gt; Cargo lets packages run arbitrary code on startup. This is pretty useful and important. I wonder if we can use a sandbox model for this - don't let cargo scripts touch anything outside of the code directory. Still dangerous but at least you don't have arbitrary read/write access. Sandboxes are a good idea, yes. The problem is that restricting file access to specific directories is probably not nearly enough security. and sandbox mechanisms are often very platform-specific (e.g., Linux cgroups vs. BSD jails) or that *and* excessively bleeding-edge (goshdarn you to heck, Docker). The idea then would be to do privilege separation: run the safe build steps on the host, but launch the potentially unsafe ones inside a container that has limited filesystem and no network access. Haskell Stack's Docker support is worth looking at, but I don't think it does any privilege separation, and of course it only works on Linux: * https://www.fpcomplete.com/blog/2015/08/stack-docker * http://docs.haskellstack.org/en/stable/docker_integration/
If you fear large dependency trees, you should work on embedded code, where you have next to no dependencies ;-) Joking aside, with larger projects you will have large dependency trees, whether you program in Java, C, Python, Ruby, JavaScript or Rust. So don't fear, but embrace them!
I think /u/acrichto mentioned https://github.com/carllerche/eventual and https://github.com/dwrensha/gj as current efforts on implementing a Future/Promise abstraction, but I haven't seen an official-looking crate yet. I assume there'll be a huge RFC first!
So the use case I'm looking at is using [Mock](https://fedoraproject.org/wiki/Mock) to build rust projects that are then packaged by my distribution. So having an internal mirror (as the build system has no external network access) of the tarballed crates that then get extracted into the source path of the package being built sounds possible (I am confused about how this doesn't need to touch the crates.io github to create the Cargo.lock file though). I'll have to try and see how that works in practice, thanks =).
&gt; (I am confused about how this doesn't need to touch the crates.io github to create the Cargo.lock file though). Well, if you don't have "`foo = "1.2.3"` in your `[dependencies]` and instead, have `foo = { path = "/path/to/foo" }`, it isn't going to need to check crates.io, as you're not asking for the dependencies from there. That said, regardless of all this, an internal mirror would still be a very useful thing. All of the bits are there, it's just not particularly easy at the moment.
I agree that that's what /u/tomaka was trying to do in his article; what I don't understand is *why*. The semantics of your `MyGraphicsLibrary` clearly state that your `Program` has a longer lifetime than your `Context`. That's not correct -- I wouldn't compile that struct either! My example that I linked expresses the opposite: the existence of a `Program` only makes sense to discuss when it is bound to an existing `Context`. Watch me translate these structs to English: ``` struct Program&lt;a'&gt; { context:&amp;'a Context, ... } ``` This says that you may only talk about a `p : Program` in the scope of a `Context`, but that it's possible to talk about that context both before and after the `p : Program` exists. In contrast, ``` struct Program { context:Context, gpuId:i32 } ``` states that a `p : Program` *consumes* a `Context` -- you will not be allowed to use this `Context` for anything outside the scope of this `Program`, and when my `p : Program` is no longer needed and removed the `context` will also be removed. This is almost certainly not what you intend to say, since it doesn't accurately model the GPU api. But this *same ownership logic* is used for the second field, `gpuId`, and that ownership logic is appropriate here -- it is correct to say that you cannot talk about a `Program` without a `gpuId`, and that when the `Program` is no longer needed and discarded, it is no longer valid to talk about that `gpuId`. The above sentences are not documentation: they are literally the English translation of what was written in the types, and Rust understands and enforces these rules.
A little nit: "An immutable Point can __bee__ seen as an immutable memory chunk". Great post otherwise!
Still learning Rust. Working on a compiler for qmlrs (https://github.com/cyndis/qmlrs), that will compile the qml file into the compiled binary. https://github.com/dtoebe/qmlrs-compiler. Still very early, and many parts of the code I have commented that it looks ugly. Any suggestions or guidance is appreciated.
Hello! In addition to the repos [pointed out by](https://www.reddit.com/r/rust/comments/4ncrzh/recordings_from_rust_meetup_cologne_featuring/d43cpgk) /u/killercup the in-progress transition of eventual can be found at https://github.com/alexcrichton/futures-rs. Note though that it's *severly* lacking in documentation which I hope to fix soon! I'd love to chat about how futures could mioco or integrate with mioco, there was a question at the Berlin meetup the other night about how the two systems might interoperate, and if they work out of the box that'd be even better! The plan moving forward is still in development, but we're a **long** way away from moving into the standard library. I suspect that there will be quite a bit of discussion before it moves even into the nursery (if ever) and we'll want to work on community consensus before that. Looking forward to see how these two crates work together!
If you can set up a build slave on one of the machines and have it pull and build as part of Rust CI, it could help those who want to work on a port. I'd suggest to offer it publicly, if that's something you would like to do.
&gt; I think that `Rc&lt;RefCell&lt;Struct&gt;&gt;` is usually an antipattern. I think that it's better to wrap appropriate fields in `Cell` or `RefCell` instead. That's a good point, but the semantics would be different. In your version, `RefCell` wraps only the vector of adjacent nodes, which makes sense if you intend to change only that. If, on the other hand, you might want to change a node's value in the future, you would need to either also wrap the node's inner value or do it like in my example and wrap the entire node. Right? &gt; `adjacent: RefCell&lt;Vec&lt;Rc&lt;T&gt;&gt;&gt;,` I think you meant `RefCell&lt;Vec&lt;Rc&lt;Node&lt;T&gt;&gt;&gt;`, right? Otherwise a node couldn't point to other nodes. &gt; You'll see that this change would simplify the rest of code, as the .borrow_mut() would be needed only inside a body of add_adjacent(). In the [clean version](https://play.rust-lang.org/?gist=9ccf40fae2347519fcae7dd42ddf5ed6) linked a little below that example, `.borrow_mut()` is used only in the body of `.add_adjacent()`. :) Maybe it would be better to leave only the link to the ugly version and show the cleaner version instead. &gt; Also, I agree with u/looneysquash that the graph of MagicPoint is confusing. It suggests that cells use pointer indirection, which is not true. Quite right. I was going for a more intuitive "this logical block can't be changed, while this other one can" instead of an illustration of the actual allocated memory. Since you're not the only one pointing this out, I'll change it. &gt; The Mutex and RwLock are threadsafe equivalent of RefCell. But I think that the multithreaded analog of Cell are the Atomic* types, which are worth mentioning too. Indeed! I was planning going into that in a later article, instead of making this one even longer. &gt; It's weird and a little bit confusing for me to read about mutating using immutable reference. Maybe it would be better to explain clearly at the beginning that "immutable" reference is actually shared reference, which just usually means immutable access; and then stick to the phrase "shared reference"? That's a good idea, I'll probably do it. Thank you so much for the feedback, I really appreciate it. &lt;3
Thanks, that's an excellent point! I'll update the article with those remarks later. :)
Heh, that's what I get for asking a bee to proofread my writing. Thank you.
Thank you for the article!
Thank you. That quote is comedy gold and an excellent analogy. :) &gt; Btw. I'd suggest using Atomic types for threadsafe interior mutability on primitive (copy) types, e.g. AtomicUsize. Good point. I was planning on leaving the threadsafe stuff for a later article, instead of making this one huge.
Is it possible to force a struct implementing a trait to have a certain field? For example: trait A { fn a(&amp;self) -&gt; bool { self.a } } I want all implementing structs to have the field `a` and the only way to enforce that seems by having the above function, but the above is AFAIK not possible because traits can not have associated fields? Right now I have to redefine the `a` field in every struct and then write the same function in every struct again. Is there any way to make this easier? Perhaps a macro could do, but it's still a lot of code duplication).
Great! Watching it right now! If anybody has trouble playing the webms like I do -- I guess my mplayer / vlc / libavcodec is too old to handle an Opus audio stream -- try the MP4 version.
Out of curiosity: What distribution are you using? I know this is an issue on Ubuntu 14.04 LTS. However, Firefox itself will happily play them on that platform since it is updated somewhat independently.
Right now the only approach is to have the trait method. If you define it as `fn a(&amp;self) -&gt; &amp;bool` then it links the lifetimes of `self` and the return value, making it very difficult to return anything _other_ than a reference to a field. There is [an RFC for fields in traits](https://github.com/rust-lang/rfcs/pull/1546) that is pending and would add exactly the functionality you want, if only we could decide on a syntax.
That lifetime trick is pretty neat! Thanks for the suggestion.
Oh yea, I completely forgot Cargo can do [dependencies] as paths. Thanks again! I think setting up the mirror once is pretty reasonable to do (not one step and done easy but that's okay) and I can script checking crates.io for when packages get updated (though I wish all projects would git tag their releases too) and auto insert the .cargo configuration at build time for rust packages to use the mirror. My real goal is to not need to touch the Cargo.toml files per project and just be able to insert the static cargo config for the mirror for all projects. The pain point for the mirror seems to be mostly maintaining the active fork for the crates.io index but I'll have to try it and see how it all works out.
Still on Xubuntu 14.04 LTS :) -- Good to know!
A reference is a value! `Iterator` is implemented for `&amp;mut I` where `I` is any `Iterator` (*), so it works fine. (*) You can see this impl in the documentation of `Iterator`: impl&lt;'a, I&gt; Iterator for &amp;'a mut I where I: Iterator + ?Sized
Looks like someone had a lot of fun :D
Gah, I knew they must have a proper name but google failed me!
&gt; Watching my talk made me realize I emm-ed and err-ed more than usual. For what it's worth, I certainly didn't notice this.
If anyone wanted to support Rust on Sparc/Linux and Sparc/Solaris I'd be happy to personally donate access and power to a T2000 or T3-1B (I'd have to acquire this one but it would be faster and more usable).
Is there a simple way to set the `LC_ID_DYLIB` value when building a dylib using cargo? I'd like to set it to a relative name (` @loader_path/liblonlat_bng.dylib`), and `install_name_tool` is broken on the Travis OSX XCode 7.3 image, so I can't do it after I build. Essentially, I want to pass `-Wl,-install_name,@rpath/liblonlat_bng.dylib` to the linker.
How about `RUSTFLAGS="-C link-args=-Wl,-install_name,@rpath/liblonlat_bng.dylib" cargo build`? Or if that doesn't work `cargo rustc -- -C link-args=-Wl,-install_name,@rpath/liblonlat_bng.dylib`?
I'm going to chalk it up on my English being somewhat...Rusty. I've worked as dubbing actor in the past, so I usually just pause instead.
I think this sentence is confusing: &gt; However, in this case you don’t need to change the content of y, only the destination of that magical pointer, i.e., the other memory chunk, and that one is mutable! I would explain this as "You can't change the value of the magical pointer to point to somewhere else, but you can change the number in the chunk of memory it points to."
Just a question, was the meetup entirely in English?
I don't see why not. How would sqlite help here? I don't know a lot about these specifics.
About 95%. The other 5% were private conversations while getting drinks :)
I think a build slave implies at the very least an existing partial port...
You may look at this: https://crates.io/crates/bodyparser
I see he mentions cargo without reference to [Issue 75](https://github.com/rust-lang/crates.io/issues/75). Can Red Hat really use rust with their STIGs, FIPS-140-2 certifications, EAL-4 etc? Seems like a stillborn effort while packages are unsigned.
AFAICT if I want my content to get picked up by a distro and not just crates.io, I probably "have to touch autoconf/libtool again". But, hey, we could probably evolve to no longer need it. Anyways, we agree -- rust is pretty awesome. 
I have long advocated for a `cargo deb` or `cargo rpm` command to make some of this easier, but have not had the time to try to write it myself.
To be clear, this is not about kernel development, but about userland tools. I doubt you'll get any Rust code in the actual kernel anytime soon or ever. 
Indeed. In a type-and-effect system (which is what /u/levansfg is describing), function types need to carry effects. So you need something like a distinction between FnPure and FnImpure traits.
The idea of the "yield" keyword is that it does pretty much what you're proposing, except the "yield" keyword lets the reader know exactly what its happening without having to rely on calling/naming conventions or knowing the type of a particular object
&gt; You'd need some sort of Stack primitive built into the language for that, where the order of the fields is significant and field2 may contain references to field1. Yeah, that's sort of what I'm trying to implement, but not as a language feature, rather as some sort of macro.
There are a lot of high profile Go projects that have very loose dependencies. By that I mean directly using a github url in the source, no vendoring. It would be so easy for someone to introduce vulnerabilities. For instance LXD, a linux container hypervisor has its [dependencies setup like this](https://github.com/lxc/lxd/blob/master/lxd/certificates.go#L12). And this is a project sponsored by Canonical, for Ubuntu! 
You're absolutely correct I have since fixed that
Working on an experimental C to Rust transpiler. So far I'll be happy if I can successfully translate to unsafe raw pointer using code. I already got all the C syntax converted to Rust equivalents, but there are a lot of little issues that are hard to deal with, like how "if x" has to be translated to completely different things depending on whether x is boolean, integral, a pointer, or a function pointer. It doesn't help that I'm also completely new to Rust.
I would just want something that can install into a fake root tree. Like with automake: make DESTDIR=/tmp/package install As well as a a way to know what permissions each file needs. (All without sudo) 
Well, you can usually pass `Copy` types by value. For other types, it depends – if you don't need the value afterwards, you may as well pass by value. If you don't intend to mutate, a plain ref will nicely document that, if you intend to mutate, you need `&amp;mut`.
IMHO, this is a some flaw in hyper design **as HTTP library**: it does not provides any access to POST form fields, nor some URI-request API; on the other hand it provides (or assumes) some thread-pool via Server class. I.e. it mixes high-level HTTP protocol access and some server-side model of processing HTTP requests. 
Flaw or not, I know that hyper is meant to be quite low level, and the next major release will make it even more so. The thread pool will be gone, for example.
Author of [`multipart`](https://github.com/cybergeek94/multipart) here. Thanks for the mention /u/Manishearth! `multipart` is designed to be a backend-agnostic handler for POST requests that contain files or streams, i.e. `multipart/form-data` requests. It integrates with many different crates already, including Iron, tiny_http, Nickel, and Hyper--Hyper was, in fact, the original integration for `multipart` before I decided to make it generic over HTTP requests. I have some sample projects courtesy of some volunteer contributors but unfortunately I don't have one yet for Hyper on the server side. I just haven't had the time to do it and haven't had any more takers on the sample projects. The sample project for Hyper server APIs is available for someone to take on, though, if anyone's interested: https://github.com/cybergeek94/multipart/issues/29 It's really pretty straightforward; you can basically just take one of the existing sample projects, and switch it to use the types from Hyper. I haven't gotten around to implementing support for the new async APIs but it's high on my list.
 &gt; 3rd party plugins (w/o compiling everything... more link-time) I don't know about Swift, but Rust does not have a stable ABI, so you're, in practice, limited to using the C ABI to communicate - even if both host and plugin sides are written in Rust.
I have very bad experiences with mmaping files. It works fine until it doesn't and your process dies in a surprising way. This is probably not what you wanted to hear though:) 
Like said in the OP, I want to be able to do this without matching. Matching requires me to compare every single variant by hand, if I could just store the discriminant I could later compare generically. For example, to be used in a Map that uses the discriminant as the key, to discriminate between instances of the different variants. I'm not asking for a solution or workaround for a specific problem, I am simply requesting a feature to "get the discriminant from the variant without instancing it". A simple language addition to expose this existing property. /u/levansfg suggested implementation via procedural macro, that you objected to because macros don't have access to type information. Great if we could continue from that point of the conversation... 
great post
 If you need to process the string as UTF8 code units, Swift.String offers a utf8 character view which lets you iterate over the string as UTF8, regardless of the underlying storage. This is what I consider the downside - non-canonical in-memory representation (and more bloated for european languages). If one is processing millions of strings in a tight loop, I want to be able to treat them essentially as bytes.
I wrote a CloudFoundry buildpack for Rust [here](https://github.com/amsantavicca/cloudfoundry-buildpack-rust). It's a bit rough around the edges and could use some love. It *was* working just fine a few months ago, but someone is currently experiencing an issue. I'm working with them to resolve it.
Swift is not made for systems programming and its type system is weak sauce.
Just did this talk at Pittsburgh Tech Fest about my experience rewriting the [Zopfli compression library](https://github.com/google/zopfli) from C to Rust ([my Rust version is in my fork](https://github.com/carols10cents/zopfli))-- I tried to add enough speaker notes to make my slides make sense on their own. I'd love to hear your thoughts and suggestions for other things I should try, things you'd like to know, or critiques/pull requests to the code (it's definitely not "done")!
&gt; nicer (and easier) syntax. &gt; I've personally come to a point where I simply have to disagree. I'm glad to hear it. I'm coming from much less experience, and looking at the code of both from a non-experts eyes, rust had a lot more noise. But I'm hoping that the preference will go away if/when I learn more rust. It's difficult trying to figure how much time to spend becoming an expert in one language or another before you decide to just commit to one for a while. Life is short. It's apparent from looking that your response that I don't yet know enough to even evaluate some of your points :-( &gt; 99.9% of the Swift libraries you'll find out there depend on Apple's Cocoa/Foundation frameworks. I think it will be used much more for server side stuff as time goes on, but it does make comparisons (like language popularity rankings) somewhat misleading. In some respects (like tooling) all those users and code are still good. In other respects (attracting great contributors and committers) it matters much less. &gt; That's incorrect. Swift is (amongst Rust and few others) one of the only true Unicode-compatible languages. Note that I'm using utf8 literally (I want to be able to know that the underlying representation of a string is just a sequence of bytes). From what I understand of swift, it may be utf16 under the covers with views that give you utf8 if you want it. Thanks for your feedback!
Just curious, can you share more about your database project? 
[Cellular automata are comonadic](http://blog.sigfpe.com/2006/12/evaluating-cellular-automata-is.html?m=1) I have implemented a couple different cellular automata with this method and it's awesome! 
I believe you are looking for /r/playrust.
There is [`withCString`](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_String_Structure/index.html#//apple_ref/swift/structm/String/s:FSS11withCStringurFzFzGSPVs4Int8_xx) and [`fromCString`](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_String_Structure/index.html#//apple_ref/swift/structcm/String/s:ZFSS11fromCStringFGSPVs4Int8_GSqSS_). 😉 Example usage: let string = "¯\_(ツ)_/¯" string.withCString { int8Ptr in // do with the bare Int8 pointer whatever you please. // The point is only valid inside this closure though. // the C-string is null-terminated. Just like you'd expect. } Keep in mind though that it internally calls [`nulTerminatedUTF8 `](https://github.com/apple/swift/blob/19f7c3c27cc09bad3f4a608c586292779b140a85/stdlib/public/core/StringUTF8.swift#L378) [sic!], which looks like this: public var nulTerminatedUTF8: ContiguousArray&lt;UTF8.CodeUnit&gt; { var result = ContiguousArray&lt;UTF8.CodeUnit&gt;() result.reserveCapacity(utf8.count + 1) result += utf8 result.append(0) return result } So it does alloc/copy on each call.
Hi! Does somebody know a good crate to solve nonlinear least squares problems? Something like a levmar implementation? Couldn't find anything with google. Thanks in advance!
I enjoyed reading the talk, and seeing your method. Thanks.
This looks really awesome! Does it use cgroups + namespaces + seccomp itself or does it actually produce a Docker container?
Regarding copy iterators, you can certainly do this in Rust with the `collect` function, like so: let vec1 = vec![1, 2, 3]; let vec2: Vec&lt;_&gt; = vec1.into_iter().collect(); Note that `into_iter` consumes the first vector. To avoid this, you can use the `.cloned()` iterator adaptor. This is often necessary because most iterators in Rust code yield references, so if you want to collect them you've gotta clone them.
Without heap allocations?
&gt; if you want to treat a buffer as bytes, not characters, then complaining about Swift.String (whose purpose is to manage characters according to Unicode conventions) seems misguided. It just seems to introduce a slightly bigger impedance mismatch if you have a core high performance core that treats everything as bytes / byte slices but have to worry about that not being the case with incoming strings.
Not at this time, it needs to stay stealth. I've done the open source thing before though - I'm the author of a large existing open source project written in Java.
Good stuff!
Hmmm, yeah. I remember hangs in unix utils working on files on NFS mounts back in the day. Of course I plan on making persistence (or rather the style of persistence) pluggable/configurable. The key is if one can do that and have a majority of the code not care.
&gt;What error did you get? You need to use #[derive(Copy, Clone)]. src/main.rs:13:10: 13:14 error: the trait `Copy` may not be implemented for this type; field `data` does not implement `Copy` [E0204] src/main.rs:13 #[derive(Copy, Clone, Debug)] Even though http://fizyk20.github.io/generic-array/generic_array/struct.GenericArray.html seems to implement Copy. &gt;It's coming. Is it this one? https://github.com/rust-lang/rfcs/pull/1398 
&gt; Even though http://fizyk20.github.io/generic-array/generic_array/struct.GenericArray.html seems to implement Copy. &gt; Note that `GenericArray&lt;T, N&gt;` only implements `Copy` if `T: Copy`. You'll need to constrain `T` in your `Vector` to also be `Copy`: change `struct Vector&lt;T , N: ArrayLength&lt;T&gt;&gt;` to `struct Vector&lt;T: Copy , N: ArrayLength&lt;T&gt;&gt;` (and update the rest of the code where necessary).
For something small like this library, wouldn't a better approach be to study the compression algorithm and do your own implementation of it in Rust instead of converting a C implementation?
Vec's backing store is always heap allocated, without type level numerics I don't think there's a way around that :-/
The source code isn't very idiomatic. Do you accept pull requests?
Oh, I'm sorry, the solutions for fixed-length arrays are ugly. For GenericArray (or ArrayVec) there might be an `extend`-like function, but I expect without looking that the semantics of that are gross. I had a bit of a brainfart, I thought you were worried about `cloned` allocating, which it does not, but I think `collect` does at least for all the stdlib collections.
I echo what annodomini said: I liked seeing the description of the incremental approach.
Should I default to passing by value then, unless I'm planning on mutating it in which case I should pass a mutable reference? Thanks for the response!
Yes, that one. Ish.
You're welcome! This is a small conference so the talks weren't recorded, but I do want to talk about these ideas/techniques with a wider audience, so I did put more work into the speaker notes to hopefully make them useful. I'm glad you enjoyed them! I hadn't thought about trying `Cell` for this case-- that'd be an interesting thing to try!! Thank you for the idea-- I'll report back on results when I get a chance to try it! :) 
YOU GET ME!!! 😻😻😻
&gt; Rust is a memory safe language but once in a while you may find yourself writing unsafe code, or using a library you don’t trust, or executing code over FFI. In these situations the type safety normally provided may not be enough for your requirements. Essentially, if an attacker gains control over your code you don't want them to gain control over your entire process or system.
Submitted a pull request. One reason why you may not be seeing C performance is because indexing in Rust performs a bounds check whereas indexing in C does not. To eliminate the performance cost of bounds checking indexes, at the cost of safety, you can use the `get_unchecked()` method. This array[index] becomes unsafe { array.get_unchecked(index) }
At least we can create Linux kernel modules in Rust, even if Linux upstream will not yet accept it.
Mm, Rust thinks that if Foo takes N then there must be an N in it somewhere. If GenericArray didn't contain the N you'd have to add a p:PhantomData&lt;N&gt; or rust would not allow N as a template parameter.
Hold on let me get this formatted. Edit: done
When I try to compile (with nightly) It errors with: /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15:29: 15:42 error: mismatched types [E0308] /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15 serde_codegen::register(&amp;mut registry); ^~~~~~~~~~~~~ /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15:29: 15:42 help: run `rustc --explain E0308` to see a detailed explanation /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15:29: 15:42 note: expected type `&amp;mut syntex::Registry` /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15:29: 15:42 note: found type `&amp;mut syntex::Registry` /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15:29: 15:42 note: Perhaps two different versions of crate `syntex` are being used? /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/tokei-3.0.0/src/lib/build.rs:15 serde_codegen::register(&amp;mut registry); It does look like cargo compiled two versions of syntex: Compiling syntex_syntax v0.35.0 Compiling syntex_syntax v0.33.0 Do I need to compile with stable?
Because packaging requirements change as the distro develops. Packaging tools gain new features, but “cargo deb” would need to work everywhere. This means either that “cargo deb” gets out of date, or needs to provide an implementation of any new features itself. This also fundamentally misunderstands the relationship between distributions and developers. Distros are system integrators; is not necessarily possible or desirable for developers to provide their own integration.
I'm having a lot of trouble with Cargo. I want to create a project with 3 separate executable files which all import from some other files within the same project. How should I set up my Cargo.toml/package structure to accommodate this? Specifically, where do the `mod` declarations go? (I know about the `bin` attribute in Cargo.toml files, but that doesn't really help me with Cargo's seemingly mysterious namespacing rules.)
You can simply use wiredtiger for the start.
/u/steveklabnik1, not sure if this is the best thread to get response on, but I remember you posted somewhen on Reddit, that it would be a good idea to have descriptions in docs collapsed by default due to the growth of docs' sizes. Will this be implemented or is it not really agreed on? Also, is there any work on improving readability of long trait implementations' lists such as maybe having each implementations' functions collapsed into a header: impl Trait for Struct fn one() fn two() vs [+] impl Trait for Struct
Did you try to run [afl](http://lcamtuf.coredump.cx/afl/) or some other tools (valgrind or something) against the C implementation to see if it actually has any (memory) safety issues? It would have been neat if the safety benefits of Rust could have been actually demonstrated somehow. The performance story is still bit sad, 50% slower than C is imho quite significant regression. At least we get the reduction in sloc count as a tradeoff. I hope to see a follow-up post if/when you improve the metrics further. 
`cargo deb` can be just like `db_python`, a tool that is maintained by the distro community. Cargo allows you to create subcommands without modifying cargo source. I presume `cargo deb` would be something similar; an external binary maintained by Debian. Though the Rust community could initiate the work.
The automata I meant are actually finite automata that are used in string matching (among other things), which is a bit different from cellular automata I think ;)
I see you referenced my crate (RsGenetic) as "similar" and they seem to be. I like that you allow for parallel execution, which I wanted to implement but never got around to. Looks good overall, including documentation. Nice job! One small issue: it's 'fitness', not 'fittness'.
&gt; skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/5.3.1/../../../libm.so when searching for -lm It's hard to help; you posted an error that depends on the details of your environment, but you didn't share any details of your environment. You could have incompatible toolchains installed. Try simplifying the situation to see if you can narrow in on the problem: * Does the problem happen if you use simpler and simpler cargo projects? * Does the problem happen if you use only `rustc`, (not cargo) ? * Does the problem happen if you ignore Rust and compile a simple C program? (That is: is your `cc` toolchain working?)
That's only for iron though right?
I have no use for this personally, but I can see its usefulness, especially in the context of a language like Rust, which allows performance optimizations without introducing dangers. My understanding of Option/Result is that you use Option when the "not available" case is natural, e.g. when traversing a list or reading a file. In that case, you don't need any error information, since you expect the list or the file to finish at one point. It's like returning a NULL pointer in C, or undefined. Result is used when the outcome of a call is unwanted and you want to inform something or somebody (such as the user) about it. This happens often during transformations (e.g. division by 0) or interaction with an external interface that has an inner state (like a file handle). So I'd say that your encode() and decode() should indeed return a Result. And partial_cmp seems a good candidate for Option.
It makes sense. I looked at Monotone, and it seems appropriate to generate an error when the input is not monotone. Now that you mention it, decode() seems less apropriate. Perhaps OP can add the conditions for the error Result to the docs.
Would be nice if someone could tell whats wrong with [this code](https://is.gd/voPhHt). The first assertion works, the second doesn't.
Still working on the openvr binding, I almost finished the Camera interface https://github.com/rust-openvr/rust-openvr
This crate looks really useful to me, I can see myself using it in the future. The API mostly looks fine. The biggest thing missing for how I'd use this is being able to decode into a provided vector. Right now it unconditionally allocates a new vector. That's pretty egregious if the goal is to work in-cache. This fits in the same niche as blosc, yeah? &gt; As a general rule, you should not decode or access objects of the Uniform, Monotone or Unimodal types from untrusted sources. If there is *any* situation in which safe code could cause unsafety, decode shouldn't be safe. Which is fine, if doing otherwise would severely impact performance! Potential violations of safety in safe code is a big no-no. ----- This crate seems like a good candidate for some testing with [quickcheck](https://github.com/BurntSushi/quickcheck), fuzzing with [afl](https://github.com/frewsxcv/afl.rs), and more exhaustive testing with [KLEE](https://klee.github.io/), in that order. A full audit of this crate would take some time, after a quick peekaboo at the source, but being able to run tests with those tools would give me a lot more confidence in its correctness. The implementation doesn't look too scary, but somewhat intricate, and there's a lot of unsafe code in there. You should consider using the community-standard [MIT/Apache-2.0 dual license](https://github.com/cmr/relicense-assistant/blob/master/issue-template.txt). Regardless, good work, and thanks for releasing it!
Indeed :) [This was my favorite find of clippy's](https://github.com/carols10cents/zopfli/commit/4b01dad0a35e17206e641a4f960c16c4d5fdff0f), I would have never recognized that constant as A Thing otherwise!! [This is the whole series where I took a lot of clippy's awesome suggestions](https://github.com/carols10cents/zopfli/compare/253cd784b7dbe5f885a57518ec8973a8608a33a4...4b01dad0a35e17206e641a4f960c16c4d5fdff0f), it was super helpful in pointing out places that could be more idiomatic!!
I don't really follow at all. The purpose of the subcommand is precisely so that they can package the project in the way that they want, even if that is providing an extra section in the Cargo.toml file that contains the information needed by Debian packages, or even automating the process of detecting dependencies by using ldd.
That doesn't prevent them from updating their `cargo deb` tool as packaging requirements change.
I have not tried fuzzing, I ran out of time, but it is something I'd like to do!!! I really wanted to find/fix a segfault too, but I think I might have started with a C library that was too good ;) I might have to try a messier one next (suggestions welcome!) I will follow up if I find anything interesting!!
&gt; We have to tell Rust not to mangle the function name so that the C code can link to the symbol. Rust also isn’t going to be happy about the non snake case name, but we’re going to leave it this way for now, so turn off the warning about the naming convention for this function. Seems like something that could be improved in the lint maybe... maybe it should just ignore the `no_mangle` items?
Thank you! So given that I have a `src/bin` directory, where do all of my `mod` and `extern crate` declarations go? (Keeping in mind that the executables will use some of the same modules from other files.)
&gt; I looked at Monotone, and it seems appropriate to generate an error when the input is not monotone. I would guess that checking for this would slow down encoding considerably. The current implementation actually does still encode the input, but without any compression at all. &gt; Now that you mention it, decode() seems less apropriate. Good catch. I set the interface at an early stage in the design, and then didn't think about it again. But going over the code now, there is no condition for which decoding returns an error. Will try to update the interface and the docs in the next day or so.
&gt; I would first ask, can `encode` and `decode` produce an error? `encode` produces an error if your input is longer than some implementation defined maximum (around 2^37 entries). This seemed like a more reasonable approach than simply failing. `decode` does not ever return an error though, at least right now. My thoughts while code were to get a version working and then insert proper error handling at some later point. But I can't think of a situation where returning an error would make sense. If decoding fails, that points to a bug in the implementation. Thanks for pointing this out!
What's wrong with AVX?
Does anyone know why `test1` compiles, but `test2` fails? The trait is certainly implemented and in scope; and why does it work with the `Box`, but not if the `Box` is in a `Result`? I'm baffled. fn test1(path : &amp;Path) -&gt; Box&lt;Write&gt; { File::create(path).map(|x| Box::new(x)).unwrap() } fn test2(path : &amp;Path) -&gt; Result&lt;Box&lt;Write&gt;, Error&gt; { File::create(path).map(|x| Box::new(x)) } error message: mismatched types: expected `std::result::Result&lt;Box&lt;std::io::Write + 'static&gt;, std::io::Error&gt;`, found `std::result::Result&lt;Box&lt;std::fs::File&gt;, std::io::Error&gt;` (expected trait std::io::Write, found struct `std::fs::File`) [E0308] 
Certainly, but is worth a warning? Warnings are heuristics, and false-positives really dent their values. If it is common enough to have to specify a departure from Rust's naming conventions on `no_mangle` functions, then I would contend it is NOT worth emitting the warning.
Ah, think I've (partially) answered my own question: a `Box&lt;T&gt;` can be coerced to a `Box&lt;U&gt;` if `T : U`, but the same doesn't apply to `Result`. ~~I think this is deref coercions in action?~~ **EDIT:** Okay after a bit more digging, it looks like it's independent of `Deref`, must be some other functionality of `Box`. Anyone know what? :-)
It's a recent regression, there's an issue https://github.com/rust-lang/rust/issues/33985. It doesn't appear on all Windows setups, only on some. The last time Windows backtraces regressed they stood unfixed for months, so If you really need them I recommend to start fixing it yourself :)
Yup, I've also ran clippy and rustfmt but decided to merge your PR since you're using some more (and nicer) idioms. So thanks a lot!
&gt; The last time Windows backtraces regressed they stood unfixed for months, so If you really need them I recommend to start fixing it yourself :) That's sad. I think I will just use 1.8 for now.
If you notice in the issue, there's an issue with reproducing it. Maybe you could chime in? Also, it seems like this only affects the GNU version, not the MSVC one, maybe that can help?
Great writeup! I have been taking a crack at the the same thing and tried a [few](https://github.com/mattico/rlibc) [different](https://github.com/mattico/relibc) [approaches](https://github.com/mattico/rusl), though you've gotten much further than I have in any case. &gt; Weak linker arguments for function symbols You probably know this but the way to do this is `#[linkage = "extern_weak"]`. The only documentation I've found for this feature is [the stabilization issue](https://github.com/rust-lang/rust/issues/29603). I've also found [a bug](https://github.com/rust-lang/rust/issues/33992) with this which I still haven't figured out how to fix (though I haven't had much time).
I'm running a 64-bit installation of Fedora 23. This happens with rustc on a hello world program. Just tried to cc a helloworld.c program. Fatal error: gnu/stubs-64.h: No such file or directory. Checking /usr/include/gnu/, libnames-32.h and stubs-32.h are there along with lib-names.h and stubs.h
&gt;Fwiw that definitely requires benching as the compiler can optimise out bounds check. Last time I tried to convert a small project (with lots of indexing) to get_unchecked it made no difference at all. Elsewhere I've suggested the idea of adding two new standard library functions: get_verified() get_verified_mut(). They allow you to access the array without run-time bound tests, but they give a compilation error if the compiler isn't statically able to verify that the index will never perform an out of bounds access at runtime. So they are always safe and always fast, if they compile.
Thank you for the slides with speaker notes that you I can download freely. I have converted lot of (often C) code to D language with a step-by-step strategy like you (on average D isn't as safe as Rust, but idiomatic D code is rather safer than average C code). But after creating the test dataset (or unittests) of the original code, I modify the original code so its semantics is compatible (and as close as possible) to the target language semantics. And then I start translating the modified original code one piece at a time into the target language as you have done. The extra step of adapting the original code allows me to minimize the semantic jump between the two languages. With original C tricky code this avoids me lot of bugs and troubles in the conversion (and the resulting code is a bit closer to being idiomatic to the target language). Later I try to make the converted code more idiomatic. After using Rust for some months, now I find a little disgusting the "type soup" that's typical of your average C program. Regarding Rust as a target language for conversion from C programs, Rust code is usually safe, but safe code isn't always correct. Rust language tries to offer you several means to write correct code, but there are few design-for-correctness lessons from older languages (like Ada) that I think Rust language is still missing. I'd like few more optional for-correctness features in Rust (they probably need to be optional to keep compatibility with Rust 1.0, and to avoid too much code verbosity in several situations).
&gt; I modify the original code so its semantics is compatible (and as close as possible) to the target language semantics. Yes, I probably should have used that method more often, but I typically only did when I got stuck with code I moved over that didn't pass the tests! It was especially useful to convert C `for` loops into `while` loops where Rust wouldn't be able to express it-- for example, [this commit](https://github.com/carols10cents/zopfli/commit/ae8b25ac9fedd7c97aaedc334f181d14c0c68768) -- note that it can't be converted to an iterator over items easily since the functions it's calling take `i`, not the value, [and there's a place inside the `for` loop that was calling `i++` to skip an iteration!!](https://github.com/carols10cents/zopfli/commit/ae8b25ac9fedd7c97aaedc334f181d14c0c68768#diff-5fd097c3169c36de683d37cd122a0a99R272) Changing the C to be more like Rust first was definitely helpful in that situation. &gt; After using Rust for some months, now I find a little disgusting the "type soup" that's typical of your average C program. UGH YES just casting and comparing different types all over the place! I don't know how C developers remember what type everything is without the help that rustc gives you!! &gt; Regarding Rust as a target language for conversion from C programs, Rust code is usually safe, but safe code isn't always correct. Rust language tries to offer you several means to write correct code, but there are few design-for-correctness lessons from older languages (like Ada) that I think Rust language is still missing. I'd like few more optional for-correctness features in Rust (they probably need to be optional to keep compatibility with Rust 1.0, and to avoid too much code verbosity in several situations). I'd love to hear more about your thoughts on this! What kinds of for-correctness features do you wish Rust had? Would they be able to be implemented in a crate? 
You can keep the name, your project is further a long than any of mine.
I'm honored that my slides inspired you to write up your thoughts too, and I enjoyed reading about your experiences!! Especially this part: &gt;However, I do think that rewriting targeted portions of a system in Rust is definitely possible (hell, if I can do it…), and in some cases may be desirable. The talk slides I linked above talk about using a “Golden Master” set of files for testing regressions during rewriting, but I think that I personally wouldn’t be very comfortable with doing a C-to-Rust rewrite without either having or building a pretty big regression test suite. Which is of course a catch-22, because if you have a great test suite you may not be writing C code that would benefit as much from a Rust rewrite as other projects. Alas… The level of risk tolerance on a particular project is a huge factor for deciding between the many ways a rewrite could be tackled. I'd love for us, as a community, to continue exploring ways to make full or partial rewrites safer. I wrote a few unit tests along the way, mostly for the [boundary package merge algorithm part of zopfli](https://github.com/carols10cents/zopfli/blob/master/src/katajainen.rs#L205) that was pretty standalone. For particularly risk-averse situations, doing something like this might be worthwhile: - Pick a C function to port - Write unit tests in Rust that exercise the C function - THEN port the C function to Rust - Then refactor the function to be more idiomatic Rust, and update the unit tests as necessary And I very much wanted to be able to get one whole library into Rust to be able to say interesting things about the end state in the talk, but in The Real World I could definitely see a case for only ever porting the parts of C to Rust that crash the most, or change the most (use code churn metrics to find them?), or are the most security-critical pieces. Or just setting up the C+Rust interface so that new functionality could be written in Rust, but the older code stays in C until a good reason prompts it to move. Thank you for your article!!
Thanks for the kind words and for helping get me off my butt! Last year I attended a talk about https://github.com/agroce/tstl, which uses a graph-ish DSL for defining test conditions for a given library or tool. I've been thinking about maybe using it or something like it to have a low-activation-energy way to expand on the tests in the musl libc-test suite. Now that I think about it, I wonder if there's anything similar for Rust... I like your idea for testing in Rust first, especially because I trust tests in Rust to not have UB, and in this case I have frankly zero idea whether the libc-test suite is kosher wrt UB.
I had to run dnf provides '/usr/include/gnu/stubs-64.h' to find the neccesary package and install it. I have a different issue now though. Rust and cargo are installed but it's looking for them in .cargo/bin/rustc and .cargo/bin/cargo. They're installed to /usr/local/bin/. I tried to just copy them to .cargo/bin/ but now rust cant find the standard library. Any ideas? Edit: Never mind the issue was only a problem with one terminal. 
Not necessarily. Something that is absolutely broken now but automatically checks whatever is worked on in a special branch is still useful.
A knee-jerk reaction on musl's strlen is some disappointment in the coding style. `for (; (uintptr_t)s % ALIGN; s++) if (!*s) return s-a;` This tells me that it was more important to use less lines than to write readable, maintainable code. Using { } and whitespace does not hurt. Same when using `;` as for loop bodies.
According to the book, constants are inlined. Given this example: pub struct Name { name: &amp;'static str } pub const MY_NAME: &amp;'static Name = &amp;Name { name: "alpha" }; pub const YOUR_NAME: Name = Name { name: "bravo" }; I have these questions: 1. Does inlining of `YOUR_NAME` mean that a new `Name` instance is allocated on the stack? 2. With how `MY_NAME` is declared is that effectively putting the `Name` instance in "static space" (global) and the const is the reference to the object -- therefore only the reference to the instance is inlined? Last part of question, assume this instead: pub struct Name { name: &amp;'static str } pub static MY_NAME: &amp;'static Name = &amp;Name { name: "alpha" }; pub struct Person { name: &amp;'static Name } pub static ME: &amp;Person = &amp;Person { name: &amp;MY_NAME } This fails to compile with: error: cannot refer to other statics by value, use the address-of operator or a constant instead [E0394] Points to the use of `&amp;MY_NAME` within the `ME` declaration. Am I not already using the address-of operator `&amp;` to the static? Changing `MY_NAME` to be const instead of static is allowable however. Why is this the case? Edit: It seems that changing declaration of `MY_NAME` static to be `Name` and not `&amp;'static Name` fixes this last issue, allowing `ME` to reference `Name` while both are static and not const.
I can't definitively answer all of this, but here's what I've got: &gt;I use GLFW with C and C++ so should I use that in rust as well? glium hides me too much of the actual APIs. It feels weird to me to not programme with actual OpenGL API calls. I like to know what I'm calling. That's why I use LWJGL for Java as well. There are two "parts" to creating an OpenGL application - there's the OpenGL part, and the part that deals with this OS (creating the window and receiving input, and probably other stuff too). gl-rs is the former, and GLFW is the latter. `gl-rs` is basically just the bindings - it will give you the OpenGL you know and love. The [examples](https://github.com/bjz/gl-rs/tree/master/gl/examples) might give you a sense of what to use it with. FWIW you can also see how [I do it](https://github.com/bfops/playform/blob/master/client/lib/src/view_thread.rs) with sdl2, but it's not exactly pristine. &gt; So, what else is there? gl-rs? Does that include a loader? Can I use that with a glium window? I believe with gl-rs you use `gl::load_with`, and the closure you provide depends on the framework you're using (GLFW, SDL2, etc.). In my case, it's something like `gl::load_with(|s| sdl.video().unwrap().gl_get_proc_address(s) as *const _ );`. IIRC glium is the OpenGL wrapper part, while glutin is the OS part. I _think_ you can use glutin with an arbitrary OpenGL backend, but I might be wrong.
I don't really anticipate finishing, to be honest. Even if I do, musl is available on a large number of platforms (some of which don't yet have good Rust support), and I'm only working on x86_64.
The [FLIF](https://github.com/FLIF-hub/FLIF) project could really use some help. The last time I tried it, it had a segmentation fault when attempting to decode an image.
If you want to enforce call order, instead of using lifetimes, maybe you should use a witness instead? In The Witness Pattern, you have object type B that can only be constructed by calling function A, so if function C needs function A to have already been called, you can prove that by having function C accept a parameter of type B. In your case, something like this? // This pattern creates a zero-size type that still has a private member. // You'll need to enforce the existence of only one Clock for this to work. struct Clock(()); // This will cause `make_current_epoch` to borrow the clock, so only one // current epoch can exist at a time struct Epoch&lt;'a&gt;(PhantomData&lt;&amp;'a mut Clock&gt;); // Whatever create_value_in_current_epoch is supposed to do. // Value may or may not want to borrow Epoch, depending on // whether you're allowed to have values from different epochs coexist. struct Value(()); impl Clock { fn start_epoch(&amp;mut self) -&gt; Epoch { Epoch(PhantomData) } } impl CurrentEpoch { fn create_value(&amp;self) { Value(()) } } fn main() { let clock = Clock(()); // this is valid { let current_epoch = clock.start_epoch(); let value = current_epoch.create_value(); f(&amp;value, &amp;current_epoch); } // this obviously isn't. //{ // let value = current_epoch.create_value(); // let current_epoch = clock.start_epoch(); // f(&amp;value, &amp;current_epoch); //} }
The context required to make a good package might be "the current state of the cest of the Debian archive", and it's not feasible to squeeze that into Cargo.toml. Or it might include temporary workarounds for known bugs in other packages, or a new packaging policy. and those can't really be encoded in Cargo.toml either.
That looks like a good alternative. I'm concerned though about the `'b: 'a` constraint that I tried first - I suspected it would work, and it would be easy to be misled about the guarantees its actually providing. fn use_ref&lt;'a, 'b&gt;(a: &amp;'a i32, b: &amp;'b i32) where 'b : 'a { } When are these constraints actually effective? How could we identify mistaken attempts at using them (as a lint, or compiler warning)? Meanwhile, I'm curious if the "capture entire value lifetime" trickery via invariant lifetimes is generally useful; it seems like sometimes the programmer's intent is to capture a value's entire lifetime, and that `'a:'b` constraints are much more useful when one or both are captured in that way.
Writing to the cursor moves its position. You can set it back to the start with `to.set_position(0)`. Or you can create a new cursor for the contents of `to` using either `Cursor::new(to.get_ref())` or `Cursor::new(to.into_inner())`, depending on whether you want to keep the old cursor around.
Differential fuzzing could definitely be used to attack code with fewer tests (i.e., create a random input, run it against both implementations, see if they agree), especially in some form of white-box fuzzing (whether the relative grayness of afl or something more complex). Of course, that's far more viable for libraries with relatively few entry points.
Seccomp is definitely my favorite sandbox solution right now for several reasons. I'll have a look at gaol sometime this week perhaps and start thinking about how I can leverage seccomp.
This changes the order of macro expansion, which raises the question -- is macro expansion idempotent? I imagine it might have implications in edge cases of hygiene or whatever. (Same question came up in [#34010](https://github.com/rust-lang/rust/pull/34010).)
Maybe I should look for help understanding lifetime resolution in /r/playrust and see what responses I get :) 
So, one argument I've seen trotted out against rewriting libc in rust is that the design is inherently anti-safety: you can't really write a safe `strlen`, even in rust, because there can be no defense against passing the wrong pointer or the wrong length. Do you have opinions about this?
I would love to see that post.
Many architectures are a lot faster when working aligned on the size of the integer you're working with. For instance, if you're using 32 bit integers, you want all your integers to be aligned on 4 byte boundaries. If you're working with 64 bit integers, you want everything on 8 byte boundaries. There's some bitwise fuckery that lets you check if any of the bytes in a machine word sized integer are zero a lot faster than the naive way. But it's only actually fast if your string is aligned on a machine word. Which as often as not, it isn't, because strings don't really need to be aligned, because an 8 bit character is always aligned. But you can use that method anyway; you have just have to preprocess the first 0-7 bytes, (on 64 bit archs) until the remainder of the string is aligned, and then use the fast method for the remainder of the string. That snippet performs the preprocessing step. First of all, variable names. `s` is a pointer to the string, and is updated by the loop. `a` is a pointer to the original string, and is never updated. The variables are already set up before that line of code is executed, so the for loop initializes nothing. `ALIGN` is a macro to `sizeof(size_t)`. So it will be 8 on x86_64. The test is checking to ensure `s` is pointing to unaligned memory. If it points to aligned memory, we want to go on to the fast test that relies on being aligned. So `s%ALIGN` is 1-7 (`true` in C) if `s` is unaligned, and 0 (`false`) if `s` is aligned. `s++` ... you get the idea. Loop body. `!*s` does a logical NOT of whatever `s` points to. If `*s` is a NULL character, we found the end of the string, so we return `s-a`, which is the length of the string. The line taken by itself is incomprehensible, but when you look at the macro definitions and the whole function it's not *that* bad. If it were noticeably more than 4 lines of macros and 6 lines of code, or if it wasn't a standard library function that everyone should recognize, I would say it's bad form, but since it's so small and the purpose of the function is so obvious... mheh. It ought to have comments explaining the `HASZERO(x)` macro, and the motivation for the non-naive `strlen()` algorithm though.
An easy way to deal with this would be to have Early/Late plugins, which would deal with pre-/post-macros expanded code. Otherwise one has to work on raw token trees. Fun times, e.g. with subtraction vs. negation.
There is not-- it was a small conference. That's why I put some work into my speakers notes though! 
As far as I can tell, a constraint on lifetimes like that _shouldn't_ work without an explicit witness, or some other parameter-based solution. Because, from the _user of the function_'s point of view, the behavior you describe is unintuitive: why would a safe rust function behave differently depending on when I declare my variables? From the user's point of view, if there's a lifetime issue, then the compiler will warn about it. It's not the library's job to check lifetimes, it's the compiler's. If your code would fail if one constructor came before another, then make sure it's a reference error, or something else that the compiler can check. Else, panic with a detailed error when it does happen. I can see lifetime enforcement like this might be necessary in *unsafe* code. You might want to look up solutions to lifetime management in unsafe code, or maybe make a feature request for better lifetime management if there isn't enough. Something like this pseudocode: unsafe { if 'b : a' {} { // The reference is safe. } else { // The reference might not point to valid memory. panic!("Error: Reference may be accessed after lifetime expires!"); } } I'm still rather new to rust, and haven't taken the full dive on lifetimes, so I don't know if such a check is possible.
Rust, of course!
Also, in case you didn't know, you have a name collision with [Niko's blog](http://smallcultfollowing.com/babysteps/).
Rule no 3 violated? I need some pitchfork /s
As someone working on [implementing](https://github.com/oyvindln/deflate-rs/tree/dev) the deflate algorithm in rust from scratch rather than porting a c library (though of course still using zlib and other deflate encoders as references) I can second this. While the format itself is well described, I didn't find as much information about the implementations themselves, so you have to dig in to C code in either case. There are of course trade-offs with each method, but looking back I have the feeling porting one of the c libraries would be much faster. On the other hand, one disadvantage of doing it the porting way is that you are limited by the licence of the original project. 
Answering my own question. The compression method is described here https://harharkh.github.io/mayda/mayda/index.html and (might not be the best one for my specific use case).
Maybe I misunderstand what you expect “cargo deb” to do. dh_python doesn't take a Python source tree and produce a deb, it takes part in the build of a Debian source package and uses some metadata in the Debian component to do some processing; mainly setting up the hooks for byte compilation on install and versioning data. There are some similar tasks an analogous dh_rust could do - ensuring a dependency on the exact compiler version, setting the Built-Using field appropriately (as my understanding is that monomorphisation results in code being copied from the library into the binary), maybe some other things. I would expect a “cargo deb” command to take a Rust source tree and build a deb using metadata from cargo.toml. This is unlikely to be what distro maintainers want.
Oh, OK, makes sense :)
I started working on a 3D game but got stuck in a C++ mindset, it needs a rework to work better with Rust.
&gt; Hmm...what about indexing into a Vec then? Unsafe code could call set_len, and then an iterator in safe code would walk right into unallocated memory. The situation that I am warning about is essentially the same. As long as you don't call any unsafe methods (like mut_storage) everything should be fine. As I understand, `unsafe` means that the compiler won't check invariants for you, kicking that responsibility back on the programmer. In your example, a bare call to `set_len` can easily break safe code because it assumes that the programmer will ensure the invariant `length &lt;= capacity` is restored before returning to safe code. As long as your API can't break things without calling unsafe functions, you should be fine.
I wish I could upvote this more. When you start to have two implementations of a thing, fuzz testing to make sure they agree is a cheap and great way to go. Tools in the tradition of QuickCheck are able to test on fine granularity too. For some commercial versions of QuickCheck (I think the Erlang version) you can test stateful functions (with some setup). I'm sure most the ideas behind that will be in scientific publications. 
I had somewhat come on under the, what I now think is false, impression that I essentially had to make a clone for every time the closure was used. What I figured should've solved it was: let pool = build_pool(); let mut router = Router::new(); { let mut db = pool.clone(); router.get("/search", move |req: &amp;mut Request| { search(&amp;mut db, req) }); } However, this results in this error: src/main.rs:95:31: 98:10 error: expected a closure that implements the `Fn` trait, but this closure only implements `FnMut` [E0525] src/main.rs:95 router.get("/search", move |req: &amp;mut Request| { ^ src/main.rs:95:16: 95:19 note: the requirement to implement `Fn` derives from here src/main.rs:95 router.get("/search", move |req: &amp;mut Request| { which I just have no idea how to solve. rustc --explain E0525 just gives "no exnteded information" and a google search turns up pretty much nothing. I also tried making a new clone with different names, i.e. "let dbsearch = ..." instead of using the scopes, but it resulted in the same error.
Thanks a lot. I spend a good amount of time trying to understand why my code didn't work.
At this point; initializing static arrays is still a pain, unfortunately. You can write `None, ` 26 times (or write a macro that outputs `None, ` 26 times). However, knowing that `Option&lt;x&gt;` is always zero for a `None` value I believe you can also write `unsafe { std::mem::zeroed() }`, although that could be considered cheating :-) . &gt; Maybe implement a Copy trait for &lt;Box&lt;Trie&gt;&gt; that simply panics? I don't think this is possible, and even if it is, it does not sound like a good idea.
Nice. maybe I'll build it into a sandbox descriptor. This looks pretty cool.
I'm making a JSON-to-Xliff utility - I'm working on a project which needs all the strings translated, and already has a utility which can pull them all out as JSON; Xliff is the XML standard for a lot of translation software. Basically opening a lot of files, reading JSON in as structs, then transforming to the correct format and writing out again.
Runtime x86-64 assembler (jit assembler) with a nasm like macro interface supporting up to AVX512. Hoping to get the first version out the door before going on vacation next week.
I guess I misunderstood the warning. If the only way to cause unsafety is by going through `mut_storage`, there shouldn't be anything to worry about, like DarkNeutron mentioned. I understood the warning to mean that decoding arbitrary data could cause memory unsafety.
I'm certain that you didn't have any ill-intent, but I wanted to address two points: &gt; He's a hockey player. Not exactly the type of person that would enjoy discussing programming language internals. This is a logical fallacy that the Rust community has been fairly good at avoiding. If you replaced "hockey player" with a suite of other nouns, it's likely to sound absurd. For example, what about ["supermodel"](http://techcrunch.com/2016/04/01/supermodel-karlie-kloss-chats-with-us-about-the-launch-of-kode-with-klossy-a-coding-camp-for-girls/)? Just because someone is an X doesn't mean that they can't also be interested in Y. Unless there is someone who has the job title "professional Rust hater" \^_\^. &gt; programming language internals I don't believe the conference is **limited** to internals of Rust. This is important to note for all the people who might wish to attend the conference but think to themselves "but I'm not a compiler hacker so I won't be interested". Indeed, there are sessions aimed at getting people up to speed with Rust and there will even be a Rust Bridge preceding the conference. We want people of all sorts to attend!
Hey guys I didn't want to double post but I have uploaded the next two vids. https://youtu.be/E8ec1aMTLlI
I assume that at some point you could change it use mostly safe rust (making a library just for the rust compiler, with the features of c std), but then you could only use it from rust.
I'll look into glium later but right now I really can't be bothered fighting with the API. For a bigger project, I'll look into it.
Well, you'd still have to go for GLSL &lt; 1.50 for true legacy support. But that sounds rather nice. I'll look into that later. Thanks.
Thanks I'll check all of those out when I need OpenGL for a bigger project. Right now I go with gl-rs since it's the least amount of effort for such a small project. I've read somewhere that glutin doesn't really take user input events? What's up with that?
Not sure where you heard that... glutin has a `Window::poll_events` function that returns an iterator of the polled events.
Nim looks simple. It's like looking at elm code. As pointed out, rust indeed has trait like this impl&lt;K, V, S&gt; FromIterator&lt;(K, V)&gt; for HashMap&lt;K, V, S&gt; where K: Eq + Hash, S: BuildHasher + Default which I afraid may become the new [AbstractSingletonProxyFactoryBean](https://docs.spring.io/spring/docs/2.5.x/javadoc-api/org/springframework/aop/framework/AbstractSingletonProxyFactoryBean.html) I have been using rust for my personal projects but thankfully never have to dig deep with the generic traits of generic objects. I have also been using elm recently and was amazed on how much it can do. Sometimes, I wonder why very simple languages like elm can do so much on a very limited set of language construct. 
Well, at least it's not called `AbstractFactoryHashMapBarbecue`. I like Rust's aesthetics. It's not complex for complexity's sake, but to express invariants. I love invariants that are expressed in code (even complex code) and whose violation is caught at compile time. I dislike invariants that are maintained informally, and never checked by a machine. Rust's type system enables us to have more of the former (much more than Java's) and that's great.
I'm still having some problems with macro expansion on [overflower](https://github.com/llogiq/overflower). And I still want to do function/method/op trait lookup in [metacollect](https://github.com/llogiq/metacollect). Also a lot of $work and $private_obligations. :-/
How do you add [libui-rs](https://github.com/pcwalton/libui-rs) as a dependency? I get the error: /usr/bin/ld: cannot find -lui collect2: error: ld returned 1 exit status 
I have been using `eventual`: http://carllerche.github.io/eventual/eventual/struct.Timer.html for a timer in an application I'm writing. Basically it looks like this: extern crate eventual; use eventual::Timer; use std::sync::mpsc::Sender; pub fn listen(tx: Sender&lt;()&gt;) { let timer = Timer::new(); let ticks = timer.interval_ms(1000).iter(); for _ in ticks { // execute code once a second, send results via `tx` } } I spin this up in it's own thread from the main thread, which passes it the `tx` part of a `std::sync::mpsc::channel`.
Looks like I have some interesting research ahead of me, thank you!!!
Something not yet mentioned here: [yaglw](https://github.com/bfops/yaglw) aims to be closer to bare GL than `glium`, so might fit your needs better.
Different people and projects have different coding style and standards. I don't see anything particularly wrong with that line. All this tells me is the author thought this way of writing it was easier to read. If there's a tricky part to this, IMO, it's the `(uintptr_t)s % ALIGN` part, since there's not an explicit `== 0` and even if there was, you have to remember what modulus is and why that's significant.
That's true for simpler things, but for something complicated like DNS resolution, there would just be a small unsafe portion to handle the arguments, with nearly all of it written in safe Rust.
Still working on my emulator, [Pyrite](https://github.com/ExPixel/pyrite). I have finally gotten all of the sound channels working. Now I just need to improve mixing. Also wrote a thin wrapper around imgui (can be found [here](https://github.com/ExPixel/rust-imgui)) in order to make debugging easier.
Yeah, very true.
Even though mine was only a minor contribution, I'm very happy to have helped. One day I hope to make a larger contribution!
So really you have impl&lt;K, V, S&gt; FromIterator&lt;(K, V)&gt; for HashMap&lt;K, V, S&gt; where K: Eq + Hash, S: BuildHasher + Default { fn from_iter&lt;T: IntoIterator&lt;Item=(K, V)&gt;&gt;(iter: T) -&gt; HashMap&lt;K, V, S&gt; { ... } } A simpler syntax might be like def FromIter.from_iter(iter: IntoIter[(Key, Val)]) -&gt; HashMap[Key, Val, State] { ... } where `Key`, `Val` and `State` are reusable predefined type bounds: type Key: Eq + Hash; type Val; type State: BuildHasher + Default; 
In my perception Rust and Nim are very different languages with very different core ideas (and subsequent design choices). I don't think there is much value in a Rust vs. Nim shootout or whatever. The fact that there are multiple different approaches to modern low level programming is great.
I can see the lure of the predeclaration, although I still prefer having the declaration be explicit in what are type parameters and what aren't. The problem I see with unnamed output parameters is clashes with input parameter defaults. Would The `P` in `Add[P]` refer to the `Self` defaulted `RHS` input or the `Output`? Also, how would output parameters be declared in your scheme?
Thanks, will do. The documentation is a little sparse right now as the project is still in it's early stages, just trying to gauge whether or not there were any glaring issues. 
You just wouldn't write `Add` the same way it's done in current Rust. Personally I think an `Add` trait shouldn't really have a `Self` anyway; it should just be `Add[Left, Right, Out]`. If you want a shortcut for `Add[Foo, Foo, Bar]` or `Add[Foo, Foo, Foo]`, you could allow overloads and write type Add[Type, Out] = Add[Type, Type, Out] type Add[Type] = Add[Type, Type, Type] and maybe even type Add[Self] = Add[Self, Self, Self] The main problem with this strategy is when you have a ton of associated types, but I've not seen such a circumstance. Defaults (like with `HashMap`s) would be type HashMap[Key, Val] = HashMap[Key, Val, RandomState] Traits with output types would be declared trait Index[Self, type Elem] { ... } and output types could be inferred with an overload type Index[Self] = Index[Self, type Elem] I haven't thought through the full ramifications of this, but it looks fine for the common cases.
You and Ferris inspired me to start working on my own Rust GBA emulator :), though exams have made progress slow this month. It's really difficult to prevent myself from 'cheating' and looking at your source code... Especially since I figured out that the cycle timings are apparently rather important. I'm still wrapping my head around the prefetching: the documentation of the arm7tdmi suggest that the cycle types of an instruction are defined by the instruction itself, but [this](https://mgba.io/2015/06/27/cycle-counting-prefetch/) suggests that the memory controller can change a N-cycle to a S-cycle. Kinda stuck on the best way to implement this :/.
I don't have time to look at this right now, but you might be interested in what `cargo clippy`suggested: https://gist.github.com/killercup/8f619358c4c881d869bf628005ba3921 (I'm pretty sure clippy has better suggestions than me anyway :))
Many of those single-char names could be standard symbols used in the mathematical formulae though. I would `#![allow]` it.
I think I'd have to think about this more. These changes would be quite significant, so it's hard for me to form a fair judgement via isolated examples. I believe this all might come down to what one prefers to be explicit vs. implicit (and "prefers" here could of course be read in a language-philosophical sense).
not a rust programmer by any means but can you not just pass the struct itself around as a parameter of those functions?
Note that I'm not saying that Rust's syntax is bad. I think it optimizes for a valid use-case, and simplicity is just one aspect you can prioritize.
Woops. Thanks! You’re right. I'm silly. Just been looking at it too long.
Ohhh ok, I guess my lack of familiarity with the thread/channel mechanism was to blame here. Thanks a lot!
Seems like a good use case for the chan crate. You can do what you just did, but on stable Rust.
The std::ops::Deref trait is defined like: pub trait Deref { type Target: ?Sized; fn deref(&amp;self) -&gt; &amp;Self::Target; } i.e returing a reference, is it possible to use '*' as a unary operator but not return a reference but a value type? 
I think there could be valuable insights in such a comparison, but probably only if the comparison is done by someone who is an expert in both languages.
That makes it a bit simpler for this example. #[macro_use] extern crate chan; fn main() { let tick = chan::tick_ms(1000); let tock = chan::tick_ms(3000); loop { chan_select! { tick.recv() =&gt; println!("tick"), tock.recv() =&gt; println!("tock"), } } }
Thanks! I'll take a look. Much appreciated
Currently, only if the `Target` type is copyable. At some point in the future, there's at least a fighting chance that we'll agree on a design for `DerefMove`, which would allow the functionality you want. The most recent RFC for that is [here](https://github.com/rust-lang/rfcs/pull/1646).
&gt; It seems like a really good choice for garbage collected languages since it &gt; not only makes the concurrency simpler but also reduces the amount of objects &gt; that need to be scanned for each collection. Indeed, there's no need for pausing all threads and in general the logic for the GC is greatly simplified. Of course copying memory between processes is expensive but it's easy to work around (= don't send large objects between processes). In case of Aeon there _are_ global objects stored in a global heap, these are used for objects that always stick around (e.g. named classes). These are synchronized on Rust level (using Arc&lt;RwLock&lt;T&gt;&gt;) and aren't GC'd (maybe I'll change this to use reference counting on language level at some point). &gt; Isn't the call frame's current location (program counter?) stored in the old &gt; frame when adding a new call frame? Currently a call frame is added whenever a new call site is entered, mostly due to the way I implemented things. To clarify this, consider the following pseudo program: # file: test.foo 1: foo() { 2: something 3: } 4: 5: foo() Currently the call stack would be: test.foo line 1 test.foo line 2 This is because just the foo() call itself doesn't add a new call frame just yet. What I want instead is: test.foo line 1 test.foo line 5 test.foo line 2
Currently working on a 2d/3d lib [rust-3d](https://github.com/I3ck/rust-3d)
&gt; Ooh, that's quite clever. What happens if A spawns B and B then mutates some object from A (if this is even possible)? Would it copy the object to B before mutating it? Yep, it copies. Currently the only types which perform mutation is a reference type and a channel (sender/receiver) and those check which thread a value belongs to before mutating. (I might add mutable record fields at some point but its the same idea there). &gt; Also what happens if A triggers a garbage collection Hence the "not rock solid" ;). But yes A needs to lock and scan B's roots as well. Hopefully collections in A (parent threads) should be rare though. This is not currently the case as passing a value between, say B and C, in my example involves copying to A first before it can be transferred to C. I think it is possible to be a bit more clever in the channel type I have however to avoid copying until the value is read out of it (at which point the reading thread can allocate it into its own heap).
For one thing, Rust could in theory allow inferring trait bounds on generics from types mentioned in the declaration. E.g., `struct HashMap&lt;K, V, S&gt;` could have `where K: Eq + Hash, S: BuildHasher + Default` (in reality it doesn't, the constraints are only on the `impl`, presumably because Rust used to not allow constraints on structs, but handwaving away backwards compatibility issues for a minute...), and then in the `FromIter` declaration the entire `where` clause would be removed. Leaving us with: impl&lt;K, V, S&gt; FromIterator&lt;(K, V)&gt; for HashMap&lt;K, V, S&gt; Not sure if that will ever actually be added to Rust or whether it's needed or a good idea, but to me it seems at least *plausible* within the bounds of the language design, nothing too magical. Another plausible-seeming extension is omitting unneeded parameters. This impl doesn't really need `S` (it's mentioned once in the body of the original, in `libstd/collections/hash/map.rs`, only to declare `from_iter` as `-&gt; HashMap&lt;K, V, S&gt;`, but Rust would already allow changing that to `Self`). So, as something of an analog to the recently-discussed generic shorthand for fns, perhaps Rust could allow writing: impl&lt;K, V&gt; FromIterator&lt;(K, V)&gt; for HashMap&lt;K, V, _&gt; To me that seems much much more straightforward. To ignore plausibility for a moment, Haskell-based languages typically allow using generic parameters without an upfront introduction; if Rust allowed that you could write impl FromIterator&lt;(K, V)&gt; for HashMap&lt;K, V, _&gt; but that would be backward incompatible and probably wouldn't be particularly helpful. /u/Veedrac/mentioned that the line following also looks pretty noisy: fn from_iter&lt;T: IntoIterator&lt;Item=(K, V)&gt;&gt;(iter: T) -&gt; HashMap&lt;K, V, S&gt; As I said, we can already shorten this in today's Rust: fn from_iter&lt;T: IntoIterator&lt;Item=(K, V)&gt;&gt;(iter: T) -&gt; Self With the aforementioned generic shorthand proposal, which seems to have reached the point where some form of it is very likely to be added to Rust in the medium term, it'd look like this (pending exact syntax): fn from_iter(iter: impl IntoIterator&lt;Item=(K, V)&gt;) -&gt; Self That's somewhat better at least. Again, ignoring plausibility, since impl methods must exactly match the signature of the original trait declaration, we *could* just leave off all the types without creating ambiguity: fn from_iter(iter) -&gt; _ ...but that doesn't feel right. I suppose it's not really that different from existing type inference - the issue would be that you have to look at some random library to tell what the type of your variable is, but the exact same thing happens when you say `let x = foo.bar();`, or even `x.foo(|x| blah)... but it doesn't feel right. Dunno. 
Well, I used glium now and it is indeed surprisingly easy. Though, something that I'm not used to yet is that you don't need to explicitly define a type so it took me a while to figure out how to pass around the display to not do everything in the main function. Apart from that, really easy!
&gt; `type LiaAny = Rc&lt;RefCell&lt;Rc&lt;RefCell&lt;Box&lt;Any&gt;&gt;&gt;&gt;&gt;;` That's a lot of indirection. :) I'm curious whether LLVM will be capable of grinding that down into something more efficient.
It is, and it's not ideal since it slows the program and compilcates the translation logic. I hope LLVM can help out. I justify why I use that type in the bottom of the README, but I'm far from a Rust expert so if anyone has an idea for reducing the overhead, I'm all ears!
I posted this yesterday and it ended up in last week's thread, copying for a bit more visibility in this week. According to the book, constants are inlined. Given this example: pub struct Name { name: &amp;'static str } pub const MY_NAME: &amp;'static Name = &amp;Name { name: "alpha" }; pub const YOUR_NAME: Name = Name { name: "bravo" }; I have these questions: 1. Does inlining of `YOUR_NAME` mean that a new `Name` instance is allocated on the stack? 2. With how `MY_NAME` is declared is that effectively putting the `Name` instance in "static space" (global) and the const is the reference to the object -- therefore only the reference to the instance is inlined? Last part of question, assume this instead: pub struct Name { name: &amp;'static str } pub static MY_NAME: &amp;'static Name = &amp;Name { name: "alpha" }; pub struct Person { name: &amp;'static Name } pub static ME: &amp;Person = &amp;Person { name: &amp;MY_NAME } This fails to compile with: error: cannot refer to other statics by value, use the address-of operator or a constant instead [E0394] Points to the use of `&amp;MY_NAME` within the `ME` declaration. Am I not already using the address-of operator `&amp;` to the static? Changing `MY_NAME` to be const instead of static is allowable however. Why is this the case? It seems that changing declaration of `MY_NAME` static to be `Name` and not `&amp;'static Name` fixes this last issue, allowing `ME` to reference `Name` while both are static and not const.
For somebody who isn't familiar with compilers or writing static analysis tools, what sets a micro grammar apart from a regular grammar? Is it simply the size?
I was thinking the same thing, but what put me off gl-rs is that Racer seems to have a lot of trouble with anything that is generated. Admittedly this is a Racer failing and I'm sure it'll improve over time, but having auto-completion (which appears to work for glium) is helpful when learning a library. I don't think anyone has mentioned this yet but I don't think glutin has the same level of support for gamepads as SDL/GLFW. Maybe in 1-2 years though? And being pure Rust is nice. Edit: To clarify, my interest with raw gl-rs is that it's ugly but basically just OpenGL and not likely to change, documentation is available, etc.
Thanks!
They aren't implementing the full language spec, just enough to find the problem you are looking for. So, for example, clippy relies on the compiler implementation in order to lint. Perhaps it could instead use a microgrammar which would simplify the implementation and eliminate the need to use the rust compiler. It may also be faster.
Um, I think this is spam
There's also [gleam](https://github.com/servo/gleam) which is used by servo webrender, it's a thin wrapper around OpenGL calls, because with gl-rs you need to use unsafe alot. I'd still recommend glium or gfx tho. I've tried both, they are really easy to work with and still low level enough for most projects.
To answer your questions: 1. Yes, inlining means that every `YOUR_NAME` ends up on the stack (it may end up inside of other object or in registers too). What's important is that every `YOUR_NAME` can be somewhere else. Note that this struct contains only a reference to the string. The `str` itself will always end up in `.rodata` (the read-only section of your binary, which gets mapped to ram at the program startup). 2. That's a good question! Your interpretation is right – it implicitely creates a static `Name`. [It's documented here](https://github.com/rust-lang/rfcs/blob/master/text/0246-const-vs-static.md#const--const). I couldn't find another place where this behaviour was documented. u/steveklabnik1, ping. And your second question: `&amp;MY_NAME` has a type `&amp;&amp;Name` (and a struct field expects just a `&amp;Name`). That means that reference-eating deref-coercion rules do apply, and one layer of `&amp;`s is removed. So the error is actually about `MY_NAME` itself. That's also why your fix works. I think you can file a bug about that, the compiler should at least note that deref-coercion is used here.
Love the name. Even some Chinese could not pronounce it currently.
[Porting handlebars' custom parser to pest](https://github.com/sunng87/handlebars-rust/pull/82). 
What Rust really suffers from is insufficient type inference to cut the syntactic noise created by type parameters and trait bounds. If you look at the type system, it's not too different from what Haskell or ML have, with two important additions: * Lifetimes, which may be higher-ranked. * Nominal object types, with possibly colliding method names. It's known that inference for higher-ranked (more precisely, rank-N, for N &gt;= 3) types is undecidable. However, in practice, most types are *not* higher-ranked, and from the experience with GHC Haskell, we know that requiring explicit type annotations only for rank-2 types and above is a very practical solution. However, unrelated nominal types having methods with the same name is more problematic. It makes non-static method calls (`x.foo()`) useless as a source of information about the object's type. It's a little bit of Java in Rust. I blame this fact for single-handedly making Rust's surface syntax more verbose and less approachable.
 type LiaAny = Rc&lt;RefCell&lt;Rc&lt;RefCell&lt;Box&lt;Any&gt;&gt;&gt;&gt;&gt;; I almost choked on something!
The AST matching is really the least involved part of clippy. Even if we replaced that with microparsers, we'd still need type-, trait- and item lookup, all of which are decidedly nontrivial to reimplement. This is one place where inference, overloading, deref coercion and all that magic hurt us. It makes for great UX, but we need more work just to find stuff.
It can also refer to these concepts: https://doc.rust-lang.org/nomicon/subtyping.html
I've been trying to create a generic trait that has a .iter() method to return an iterator over references to a generic type (I'm writing a collection with a few different implementations, and I'd like to make clients generic over the implementation). Can't seem to find a way to do this in the type system, does anybody know any examples of generic traits that define .iter()?
An explanation _and_ a solution, great work!
It's not specifically described, but falls out from the rules.
Actually, Piston has 3 backends for 2D graphics: - [gfx_graphics](https://github.com/pistondevelopers/gfx_graphics) - [glium_graphics](https://github.com/pistondevelopers/glium_graphics) - [opengl_graphics](https://github.com/pistondevelopers/opengl_graphics) So you can use gl-rs with Piston if you want. There are also 3 backends for window - [glutin_window](https://github.com/pistondevelopers/glutin_window) - [glfw_window](https://github.com/pistondevelopers/glfw_window) - [sdl2_window](https://github.com/pistondevelopers/sdl2_window) [piston_window](https://github.com/pistondevelopers/piston_window) reexports the [Piston](https://github.com/pistondevelopers/piston) core, [Piston-Graphics](https://github.com/pistondevelopers/graphics) and sets up Gfx. By default it uses Glutin as window backend, but you can swap it to any OpenGL window by changing a generic parameter.
Is it just me or do those blog posts become better and better? Look at this sweet post: https://ricardomartins.cc/2016/06/08/interior-mutability Just candy for the eye and knowledge for the brain. Perfect. Then we got error-chain https://crates.io/crates/error-chain which was a good step forward. Keep up the good work!
Thanks I'll check it out! I'm actually using the `rand` crate for rng and I've been using the distributions for guidance on coding style but I'll look into their sampling algorithms too.
I was curious about the name. As a beginning learner of Chinese, I know *liang* of course, but have never heard *lia* before. They have similar meanings; is *liang* derived from *lia*? Is it a contraction like "na yi ge" -&gt; "neige"?
In a perfect world, we'd have really good incremental compilation, which could help out a lot here. It would also help big Rust projects in general. But ours is not a perfect world, so JITing's probably realistically the way to go.
I think you missed one of the biggest advantages of dynamic languages: less incidental complexity. And Lia delivers here. Rust's explicit type, ownership, and lifetime semantics are essential for reliable high performance software, but they get in the way in more casual code. If Lia acquires a garbage collector, it could become a useful part of Rust. We just all need to remember that "compiles to Rust" is not a sprinkle of holy water that blesses all code with extra speed. 
From my point of view, in the context of clippy this solves either a non-problem or the wrong problem. Clippy is fast enough for me – if it isn't for you, please file an issue. Also it spends very little time in parsing – and that time is amortized over all (as of yet 152) lints. Most time we spend in looking up types, impls, methods, etc. And we take extra care to keep the lint-less path (as in: usually the majority of code) fast.
Convert everything o Rust types as soon as possible: * buffer pointers are converted to slices * structures are checked for null right at the interface, then only Rust object afterwards. Passing a null results in an error * use opaque structures and accessors instead of letting C code access attributes directly
To add to what /u/geaal said, make sure you wrap all your C facing functions in a wrapper that will catch panics (and probably convert them to `abort`s). The regex library exposes a C interface. [Here's the Rust](https://github.com/rust-lang-nursery/regex/blob/master/regex-capi/src/lib.rs) and the [C header file that goes with it](https://github.com/rust-lang-nursery/regex/blob/master/regex-capi/include/rure.h).
What about the case where you have to be compatible with an existing ABI? I guess you just set the c layout attribute on the structs and hope they are C compatible?
Wow, was eddyb on a roll this past week? The sheer number of MIR fixes he authored is amazing.
[IntoIterator](http://doc.rust-lang.org/beta/std/iter/trait.IntoIterator.html) is an example of a trait that has a method that returns an iterator (maybe you can just have your trait require IntoIterator).
There is a class of emerging flaw, in that lots of stuff runs are nobody/nogroup and a comp in one app say `nginx` could allow one to break into other applications running as nobody on the same machine. What we need are unique `nobody/nogroups` on demand, and we need to allow non-users to drop privileges. 
Frankly, I don't think this'll buy us anything, as the cost of parsing is already borne by all the other lints. With deadlock detection, it's mostly about following the data dependencies, AFAIR.
Lia is used in the context of two people. (According to my Taiwanese Girlfriend)
I had the same problem - I downloaded the necessary certificates (right now I cannot remember, where I found them. Maybe you can extract them from a desktop browser? Or google. But they were multiple, not only one), copy them onto the bb10 device and import them manually.
The rust community is pretty awesome. I've been in the fence about learning Rust for a while now but looking at the subreddit and language goals gave me motivation. 
I'm trying to provide a safe abstraction for self-referencing structs. After some help [here](https://www.reddit.com/r/rust/comments/4n5ab2/a_take_on_selfreferencing_structs/) I think I got something that should be safe, but trying to make a macro that would work for arbitrary structs is not exactly easy: right now I'm trying to make the part of a macro which would replace every lifetime in a type, e g, `&amp; '_ Vec&lt;Foo&lt;'_&gt;&gt;` =&gt; `&amp; 'a Vec&lt;Foo&lt;'a&gt;&gt;`, but I'm not sure if this is possible. I don't even know how to make the macro output a `'`. :-/ And then probably I have to resort to things like [this](https://danielkeep.github.io/tlborm/book/pat-push-down-accumulation.html) and [this](https://danielkeep.github.io/tlborm/book/pat-tt-bundling.html) to make it work, which is something I have yet to master...
If you use `[repr(C)]` then it will be compatible (unless there's a bug in the compiler, but that problem never goes away). I think geaal was suggesting the use of opaque structures because if you have any references, non-copy types, or enums in the struct then it will be difficult for C code to access it correctly, so it's much easier to just provide functions for that purpose. But that's not always an option.
The only other reasonable option I've seen is having a "binary-or-lib-name.rs" with a `[[bin]]` or `[[lib]]` section in `Cargo.toml` and `name = "binary-or-lib-name"`. I happen to prefer the default convention as I think it makes for a well-known entry point when looking at a new project versus making the indirection through `Cargo.toml`.
Thanks! Great explanation.
A question on enums: the elementary bindings have enums like this: pub enum Elm_Policy { ELM_POLICY_QUIT = 0, ELM_POLICY_EXIT = 1, ELM_POLICY_THROTTLE = 2, ELM_POLICY_LAST = 3, } However, it seems more modern to do: pub enum Policy { Quit } So then, specifying the enum would look like: `elementary::Policy::Quit` Does this look better to Rust programmers? Is there a clever way to do this conversion? An existing macro? Otherwise my plan is to just write a script that modifies the output of bindgen. 
Question on Cargo's [*-sys packages](http://doc.crates.io/build-script.html#-sys-packages) This seems like something I want to do, but I have a number of libraries to link to. So should I break my project up into multiple crates? This seems like a pain. **bindgen** already links with `#[link(name = "elementary", kind = "dylib")]` So what is the -sys Cargo feature doing that the #[link] attribute doesn't do?
Thanks for the tip, will do.
Maybe multiple crates is the way to go? That's what [gtk-rs](https://github.com/gtk-rs/sys) does.
IMO, would be a great interview for any of the Rust podcasts! cc /u/chriskrycho
Some questions on using Rust in production: - What other languages did you consider trying? Why did you reject them in favor of Rust? - What was the team environment like when you introduced the idea of Rust? Was it hard to make the case for it? - How did training up the team go? How long did it take? - How did you find testing in Rust? How did you tackle things like mocking?
I could, but I don't have enough experience with Rust, bindgen, and Rust library design to know the roles for each of the components. In this case, Slabity suggested it's best to not modify bindgen output at all. So I may just create a script that creates new versions of enums in the alternate style. Maybe the Rust community could use a bindgen-tools project that helps generate idiomatic Rust based on the low-level code from bindgen?
Can you use that to put multiple binaries in a single crate?
What tooling are you using? Are most of the developers doing the same? When you say 'refactoring experience' do you mean porting from another language, or something else?
If anyone who works on this each week reads this, I absolutely love seeing screenshots and even if the screenshot is pretty simple it's still really cool to see.
At Spaceshitter noted, I've most often heard the phrase in the context 他们俩 (tāmen liǎ). It's just a slang version of liang that's primarily used for people. Also FWIW, I don't believe "neige" is a contraction of "nayige". Nà and nèi are both ways of pronouncing 那, usually depending on where you come from in China. 
While *liang* means the number Two, *lia* typically means two people or two items. In other words, *lia* == *liang ge*
Author here. sanya-jit is a toy Scheme template-style JIT (i.e. generating assembly code directly from AST at runtime) with no optimization (no register allocation - temporary operands are placed on the stack and a top-of-stack cache register is used for slightly better code) and limited functionalties. It has a simple precise copying GC and does TCO. I'm currently reading about the sea of nodes IR and will try using that in the compiler.
I am perhaps unjustifiably excited about the work going into MIR. Aside from the usual wish list items like non-lexical borrow scopes, I'm also just plain curious to see what kind of clever optimisations MIR could open up.
Further note that `IntoIterator` is often implemented for `&amp;Collection` to return an `Iterator&lt;&amp;Elem&gt;` (as well as for `Collection` to return an `Iterator&lt;Elem&gt;`).
&gt; &gt; &gt; This seems like something I want to do, but I have a number of libraries to link to. So should I break my project up into multiple crates? This seems like a pain. If this is for your eyes only, do it the way you like. :-) If you want to publish your "-sys" crates on crates.io, I believe the convention is to have many small crates; it makes it easier for other people to pick what they need to link to and skip the rest.
I began to add exactly that, but I had some issues so I stopped ^ ^ `--remove-prefix` is case insensitive. I'm not sure for the `QUIT -&gt; Quit part`, it would be cool though. You can open an issue!
Happy to!
Absolutely we will be talking about it on the Chef blog.
I'm curious as to what your biggest difficult was using rust. Any specific things about the language or ecosystem you would like to see improved?
Could you elaborate on the 'testing is hard in rust'?
`src/main.rs` is the primary binary, `src/bin` are secondary ones.
Care to elaborate on how making direct system calls in Erlang is not as nice as Rust? I'm a beginner in both languages and your perspective is very helpful.
I don't *totally* agree. I can't tell you whether it's hard for a Java dev or some other kind of dev, but I can tell you that I learned rust knowing mostly just C++. It took me about a day to get a project done, with clones all over the place. It took about a week to understand the borrow checker enough to avoid errors without .clone everywhere, it probably took about another two weeks to really get my head around lifetime parameters and I think it took so long only because I didn't run into a use case for them due to rust's data structures/ containers being so helpful. (Note that I am not an expert rust developer, nor an expert C++ developer, and my education in rust is continuing - but it did not take particularly long to go from hacking things together to being productive and idiomatic and I attribute that very much to previous C++ knowledge). Why? Because I knew C++. And more importantly, I knew *modern* C++. When you say "C++ developer" it's hard to know what that means, because C++ is very old and in the last few years it has changed quite a lot. &gt; The problem is, C++ programmers know "C++ memory management", not "memory management". They're not so different. C++ lacks a lot of what rust has, especially in terms of enforcement and constraints due to backwards compatibility. But fundamentally C++ has a fairly similar model (in an ideal world). You have move semantics, which are encouraged. You have unique and shared pointers. If, however, you're coming from older C++, which is where I started (because they didn't teach us the modern stuff in school), you might be more confused. You won't understand move semantics, and that's a big one, and you won't understand ownership concepts that C++ has. So going from old pre 11 C++ to rust would be a bit harder. But you still understand the difference between the stack and the heap, which is fairly important to understanding the borrow checker. So I think right off the bat that puts you ahead of a Java developer who doesn't have to think about where their data lives. idk I think if there's any 'group' of programmers who are going to pick up rust more easily it's the modern C++ developers. That is based mostly on my experience and where I've seen the C++ community going.
As another datapoint I had a similar experience. If you're a modern C++ dev who understands move semantics, uses RAII by default and is comfortable with generics, it should be a pretty natural transition to Rust. For the trickiest concepts, there are one-to-one mappings between concepts in C++ and those in Rust. This includes lifetimes which are, granted, a fuzzier concept in C++, but still exist---if you get them wrong you get UB so you need to be well aware of them. Even trait bounds, I'd argue, match up to a mental mix of abstract classes and 'duck-typed-concepts-by-convention' (like `ForwardIterator`). Enum-s and pattern matching might be unfamiliar, but I don't think these are the issues which cause frustration with C++-experts-Rust-newbies.
I think the biggest barrier for me coming from C++ was going "I'll just write a linked list implementation to learn the language, that should be easy enough". With C++ when I wanted to learn a new concept I built a data structure and tried to make use of that concept within that data structure. That did *not* carry over well to rust.
This is an interesting take---I guess you're right that I reached for metaprogramming starting out and I was frustrated at the lack of the programmer-compiler "gentlemen's agreement"* you get accustomed to in C++: generic duck-typing and not having to re-order my code to satisfy borrowck. *Apologies for gendered term---if my vocabulary were more developed I'm sure I could avoid it.
Yeah---it still makes me sad how tricky it is to implement basic data structures in safe Rust. I understand that this comes ultimately from the fact that Rust requires you to prove your data structure is correct. After all, writing a 'correct' (especially exception-safe) linked list in C++ is far from easy. Still, I can't shake the feeling that some magical changes in the language could make this simpler.
Hi! This is a place for the programming language called Rust. For the video game, see /r/playrust instead.
One way to mock is to create your main application with generic parameters. During real runtime, you can provide the concrete implementations of the external service callers you use. During testing, you can provide the mocking implementations. Another (dirtier) way to do it is via conditional compilation, where during cfg(test) you're application will refer to a mock implementation. There's also two libraries that might be worth looking into. Here are two posts that might interest you https://users.rust-lang.org/t/a-mock-injection-strategy-for-rust/5714 https://users.rust-lang.org/t/artisanal-mocks-locally-sourced-organic-unit-tests/5890
Yeah I'd seen that---still a great resource!
That's all true. Worst-case scenario, you can use std::ptr::{read, write} instead.
Question: what would you like to do with C++ templates (or other features) but are unable to do with Rust? Two big features I can think of is having numbers as template arguments and constexpr. But I don't miss the full generality of C++ templates.
`-sys` is a convention more so than a feature. Please do _not_ use `#[link]` because it prevents people from using build script overrides. Instead you should use a build script to inform Rust which libraries to link and set some sort of `links = "foo"` thing in your `Cargo.toml`, so that people can override it easily if they want to link in the library in some other way. You should always use `links = "foo"` for crates that link in non-Rust libraries, except in the case of system libraries that are always guaranteed to be provided in a certain way (otherwise [this](https://github.com/retep998/winapi-rs/issues/238) might happen). Note that you can have a single `-sys` crate covering multiple libraries if you really want. You can use cargo features to let people select which of the libraries they actually want for example.
I feel most comfortable in Java and I felt like Rust was super easy. I never liked C++ and C always felt weird. Rust gave me a fun version of C where I don't have to worry about memory. In Java, if shit gets out of scope, the GC eats it. And in Rust I also only have to keep track of the scope. I'm not sure how to explain it but Rust feels much better to me. All of a sudden I want to do more low level stuff because now I have a language that I don't hate and that doesn't hate me. It's kind of like Objective-C. Like, if you had a C syntax, Rust would feel to me like "C with Objects". I have C but I can also give a struct a method. Which is basically all that bare Objective-C is. Objective-C still hates you, though. 
Wrong sub. Try /r/playrust
Having learned Rust after using Go and Erlang for many years prior, C++ many many years prior to that... I found it pretty easy to learn after a few days of really using it. The only real snag I ran into a few too many times was that memory borrows are contextual, which broke with how my mind was expecting things to work versus reality.
Which is more efficient? enum MyType { Type1(u64), Type2(u64), // ... Typen(u64), } or struct MyStruct { value: u64, type: MyType, } enum MyType { Type1, Type2, // ... Typen, } I prefer that in the first case, the user is forced to do pattern matching. My guess is that this is implemented similarly to a union in C, i.e. only 64 bits are needed for the actual value in the first case. So am I correct to assume that the first case is more memory efficient?
It's tty.js and reveal.js
&gt; HKTs, type safe variadics, type-level integers These are what I'd like to see most in Rust generics, though my order is the reverse of this list. I don't know if there are RFCs covering them yet. &gt; and better meta-programming in general could still use some love By this I guess you mean macros rather than C++/D style template metaprogramming, right? I think the Rust devs are against C++ style Turing complete templates. &gt; but rather than trying to emulate these features in Rust it is more idiomatic &gt; to just find alternative solutions that do not require them. I consider the omission of these features a deficiency that will hopefully be rectified in a future Rust. No point in making a virtue of necessity here.
The devs want to run some tests on all crates on crates.io to make sure there aren't any glaring performance/correctness regressions. See https://internals.rust-lang.org/t/enabling-mir-by-default/3555/ for a discussion.
I think templates in Rust are already Turing-complete?
It's also true that there are different definitions of "learning" that can be talked about in the same way. For example, to go from "expert" in Java to "expert" in Rust might take the same amount of time as going from "expert" in C++ to "expert" in Rust, while going from "good" in Java" to "good" in Rust might be harder than the C++ equivalent.
The concept is RAII regardless of the language. *Good* Java programmers should tie everything to the "stack" using try-with-resources blocks and AutoClosable. *Good* C++ developers should know and use RAII pervasively. I find that many seasoned developers still don't get RAII concepts, regardless of the language.
Thanks for the feedback /u/hot2. I'm interested in how the community and the coc made you feel unwelcome. Personally, I'm often uncomfortable with the overt politics in Rust, and recognize that it turns off some segment of potential users. And I'm frustrated that it seems impossible to even talk about the negatives of this aspect of Rust culture since people get really heated about it (on both sides).
They mean that Rust has [a code of conduct](https://www.rust-lang.org/conduct.html)
Yet Cargo is secure for definitions of "secure" that include usability as a requirement. One of the core Cargo devs could maybe poison a package, but trust is always required at some point. It is impossible to have a useful shared secure system with no concept of trust. It's not like the crates are being downloaded over HTTP, or like anyone can push malicious code into any crate. If your concern is so great with typosquatting, you can always go manually retrieve packages and be certain that you're downloading them from the author's repository of choice. There are options. There is also an acceptable level of risk. You don't know the package authors personally, and most authors likely only produce one or two packages for Crates.io. Each of those packages will have a dependency tree that contains a dozen or more packages. Are you going to individually track down each package maintainer and have them verbally verify that the key signature on those packages correspond to their personal key? No. Not likely. The keysigning would amount to security theater. The best protection it would provide would be against the maintainers of Crates.io themselves, and if they turned evil, keysigning would not save us. I agree that excessive sensitivity to inclusiveness amounts to censorship at some point, but I've never witnessed it here in r/rust. It sounds to me like you're pushing unfounded ideas and expecting them to be popularly received.
Ah. Thanks
I'm used to doing some shell, Python and SQL, but I would not consider myself a polyglot because of those. Being able to bang a simple script in a language does not mean much...
Nah, I'm pretty sure the big focus of this work week is changing Rust to have significant whitespace, and removing all sigils from the language. MIR's a pretty clear dead-end; doesn't solve any of the *real* problems Rust devs have. Just dumb stuff about compilation time and borrow checking.
Much like other C++ developers (versed into C++11 onward), Rust has felt quite natural to me. If anything, I would say the "Aliasing XOR Mutability" has finally put a concept and an explanation on why my guts were telling me that some pieces of code were funky but I could not always articulate it clearly.
Thank you for you polite and detailed reply!
I'm going to jump on the "I knew C++11 and learning rust was trivial" bandwagon, I've also used F#, and Haskell in anger so picking up rust for me really was a case of "oh my god all my favorite things in one place". So, i'd refine the argument in the OP to something more like "People who are unfamiliar with move semantics, type classes and sum types will have a lot to learn, if you know those concepts you'll basically start fluent."
Man, today is a hard day to follow the "no memes" rule, guess I'll just disconnect the company's internet gateway.
I did a similar transition on my free-time projects, (Java|Scala)-&gt;Rust. Although off the ground is easy(-ish), there are a lot of concepts that are required to understand to proceed to "level 2". Some of it is because the articles being written for Rust are aimed at the C/C++ crowd. I think this is a barrier for this particular transition (Java-&gt;Rust): Rust can be a high-level language too, but the articles focus on the low-level details of it, because it's the focus of the language and advocacy at the moment. I think this will change over time. Libraries and frameworks will provide higher-level abstractions, and the documentation and articles will follow. 
Many GC languages (I know Python, C#, and Java) have a sort of explicit scope guard construct that acts like RAII. The biggest difference is that you need to opt in to having the destructor run at scope exit.
Hey! brand new to Rust, just wondering if anyone with C lib-to-Rust binding experience would be able to help get [these bindings](https://github.com/dsgriffin/nfc/blob/master/src/lib.rs) working/using more Rust-like features. Any tips/help is greatly appreciated, thanks! 
The blog post doesn't give a lot away, you can find source code and examples here: https://github.com/polydraw/polydraw
The documentation is usually quite good. However, anything missing is considered to be a bug and should be submitted at https://github.com/rust-lang/rust/issues. Also, the IRC channel is very active for questions like your example.
&gt; I think the Rust devs are against C++ style Turing complete templates. The issue with C++ templates that Rust wants to avoid is that they are untyped until monorphization, which can lead to bad error messages and (iirc) really bad compile times. Any extension to Rust's type parameterization needs to be well typed. Being Turing complete is not really a big issue, though it means you can write programs for which well-typedness is undecidable.
Oh yeh, that's the thing it's really hard to say what's right and wrong because we only get to learn all this stuff once, once you have a good handle on the concepts then learning it again anywhere else is much easier. I think it's probably impossible to give the "correct" advice here because there is no "one true path"
I seeing that Habitat and Chef are open source projects, is there any closed-source "sauce" or you just [offer services](https://www.chef.io/pricing/) like hosting and consulting?
What exactly? Specializing types? You write a generic type, e.g., in rust syntax: struct Vec&lt;T&gt; { ... } and then you write how the type looks like for a specific value of T: struct Vec&lt;bool&gt; { ... } and/or for a subset of Ts struct Vec&lt;T: !Sized&gt; { ... } and then you can implement methods for each: impl Vec&lt;T&gt; { ... } impl Vec&lt;bool&gt; { ...add some bit manipulation algorithms here... } impl Vec&lt;!Sized&gt; { ... } And the HKT part just means that in generics you can have type constructors instead of only types: struct Foo&lt;T&gt; { ... } // specialization of Vec for Foo's struct Vec&lt;Foo&lt;T&gt;&gt; { ... } // specialization of Vec for any T that takes an U: struct Vec&lt;T&lt;U&gt;&gt; { ... } In the specialization of Vec for Foo above, Foo is not a type, it is a type constructor. You need to pass it a T to get an actual type, e.g., Foo&lt;i32&gt; is a type, but Foo&lt;T&gt; is not. Basically that specialization will only trigger if the types actually "pattern matches" correctly. And finally variadics are just a sequence of types: struct Bar&lt;Ts...&gt; { ... } // here Ts is a list of types You can use them to write variadic functions: fn foo&lt;Ts...&gt;(ts: Ts...) { } The important thing is that all the parameters of the variadic function have an actual type. You can then use algorithms for operating on type lists or tuples to traverse them. This allows you to implement a type-safe variadic print function in the language: fn print&lt;Ts...&gt;(s: &amp;str, ts: Ts...) { // traverse s and count the number of `{}` // check that it matches the number of arguments passed // for each `{x}` check the type that its corresponding element in ts should have // if types mismatch, compilation error // interpolate the ts in the string s }
I mean, how do you specialize types *in C++*? (you gave Rust pseudocode, or rather I don't remember the `impl` C++ keyword)
In C++ you do it like this: template &lt;typename T&gt; struct Foo {}; struct Bar {}; template&lt;&gt; struct Foo&lt;Bar&gt; { ... } // specialization of Foo for Bar It is the same way as it is done for functions, but types also support partial specializations (functions must be fully specialized).
Definitely go for rust. I went from python/js/erlang to rust. I could code in lower level languages, but I never really *understood* them until I put a decent amount of time in rust. It was like having a nice set of training wheels and a guidebook so I wouldn't shoot myself in the foot doing bad practices. It also throws in your face concepts that you won't find in dynamically typed languages. Read this thread a bit and you'll immediately see people throwing around terms like HKTs, specialization, type safety, etc.
Huh, that's crazy. Thanks. And it is on C++98!
&gt; Personally, I'm often uncomfortable with the overt politics in Rust That's fascinating; I had the sense that the mozilla folks were more aligned about that. I also find the politics offputting. People claim that the code of conduct amounts to "just don't be a jerk", but the rust CoC and citizen CoC are very specifically constructed from a particular political point of view in order to achieve specific political goals. In particular, they have politicized notion of "welcoming" that means being more sensitive to the concerns of specifically delineated groups, and less sensitive to the concerns of people who aren't a member of those groups. I don't agree with that; it should be possible to have a welcoming and inclusive technical discussion without having to have a fight over who deserves the most consideration by virtue of how oppressed they are. The rust CoC commits to "providing a friendly, safe and welcoming environment for all" but then lays out a specific list of groups to be welcoming to. So everyone is welcome, but some people are *extra welcome*. That's unnecessarily political.
Yeah so it's basically "Don't be a dick" for official means of communication. I really don't see anything wrong with that.
Yes and this is the issue I'm having: I can't find a way to implement IntoIterator&lt;&amp;Elem&gt; for Collection, which is what I'd like to do, without passing lifetime arguments everywhere, which I'd like to avoid (the &amp;Elems should live as long as the collection). I've seen for&lt;'a&gt; syntax around, but can't find a doc for it?
Debugging tarpc-on-mio issues. Sometimes tests hang on Windows, and for some reason TCP round-trip latency on Linux is ridiculously bad -- tens of ms -- whereas it's good on my MacBook -- ~50us.
You don't want `for&lt;'a&gt;`; that says your code works for *any* lifetime, which you can't really fulfil. I imagine the problem you're facing is that `IntoIterator::into_iter` takes `self`, so the stuff you're referencing has the unknown lifetime of the produced iterator. Rather, you want `&amp;self` so you can get the lifetime of the struct. You do this something like struct Repeat&lt;T&gt;(T); struct RepeatIter&lt;'a, T: 'a&gt;(&amp;'a T); impl&lt;'a, T&gt; IntoIterator for &amp;'a Repeat&lt;T&gt; { type Item = &amp;'a T; type IntoIter = RepeatIter&lt;'a, T&gt;; fn into_iter(self) -&gt; Self::IntoIter { RepeatIter(&amp;self.0) } } impl&lt;'a, T&gt; Iterator for RepeatIter&lt;'a, T&gt; { type Item = &amp;'a T; fn next(&amp;mut self) -&gt; Option&lt;&amp;'a T&gt; { Some(self.0) } } 
Yes but from the outside (and maybe even the inside) it just looks like a hobby project. 
[removed]
I don't think increasing whitespace is the way to go. They should change from encouraging spaces to making tabs mandatory. That could lead to a 4x improvement on some code bases. ^^^/s
Thanks. It looks like [`Box&lt;T&gt;`](https://doc.rust-lang.org/std/boxed/struct.Box.html) is what I'm looking for. But what you're saying is that assigning one `String` to another (or returning a `String` from a function) does not involve actually allocating a new buffer for the character contents? Let's say I had the entire works of Wikipedia in a single `String` - and then I tried returning that `String` from a function - this would be just as efficient as using `Box&lt;String&gt;`?
What is the difference between a Generic Type and an Associate Type for a struct? When would I use one vs the other?
https://www.polydraw.com/urgent-call An... interesting juxtaposition.
I feel like the CoC is an attempt to make the details of "don't be a jerk" explicit. In many places online people from certain groups are marginalized and made to feel unwelcome; so if being explicit is your goal, having an explicitly codified rule about being welcoming to marginalized people just makes sense. In my view having a CoC is less about trying to force "political correctness" on people and more about preventing a toxic culture from developing. 
This is also easily fixed (assuming function_call_that_may_run_for_days() doesn't actually need some_variable) is to make the scopes reflect that: { { let some_variable = allocate_many_important_resources(); ... } function_call_that_may_run_for_days(); } (And if function_call_that_may_run_for_days() really does need the some_variable resources, then there's no problem with what you wrote - they shouldn't be freed until the function is done).
&gt; changing Rust to have significant whitespace What? That's ridiculous, that doesn't improve performance at all! We should instead minify our code so it can load faster! I'll go ahead and reserve `uglify-rs` on crates.io right now!
I've written [a Stack Overflow answer](http://stackoverflow.com/a/31171431/1763356) that covers what assignment does in Rust. You might find it answers a lot of your questions. Returning a `String` won't be *exactly* as fast as returning a `Box&lt;String&gt;`. A `String` needs three values (pointer to data, size and capacity), whereas a `Box` only needs one (to the three `String` words it stores on the heap), so the first needs to return three pointers and the second only one. So in theory returning a `Box&lt;String&gt;` will be (a tiny, tiny bit) faster. However, the costs of allocating space for those three values and of dereferencing the pointer to get those values back once you want to use the string will make `Box&lt;String&gt;` a lot slower than `String` in practice. (You can think of `String` as a `Box&lt;str&gt;` (note the lowercase `str`) that may reserve some space to make adding data to the end fast.)
&gt; You could've also replied and explained why it was misinformation? I have done but it is a waste of time. Any software developer still citing Java as the be-all and end-all of garbage collection is 20 years out of date. I cannot drag them into the 21st century. 
Have you already read [the Book chapter](https://doc.rust-lang.org/book/associated-types.html)?
&gt; Because accidentally using un-initialized values is a problem even in GC languages. Wow. I forgot about uninitialised variables. Haven't had that problem since the 20th century. Thanks for the flashback. ;-) &gt; Only for types that need special handling anyway. In most cases, it does none of the above. The whole point of RAII is that it applies to all types. So you get these deficiencies (and more) with all types. If it doesn't apply to all types then it isn't RAII. It is `unwind-protect` (which predates RAII). 
&gt; IMO the whole point of RAII is that code gets executed deterministically on destruction...In Java you would have to wait till the garbage collector runs and destroys the objects You're conflating destructors and finalizers. &gt; a valuable garbage collection strategy is to actually never collect any garbage, which is very efficient if you are not generating new garbage Actually that's very inefficient because all fresh allocations are cache misses. That's why all production GCs recycle aggressively in a nursery generation that is about the size of a CPU cache. &gt; So if you actually need to release a "valuable" resource you are kind of forced to releasing it manually (e.g. on a finally block) You're talking specifically about Java (1996)? That certainly isn't true in F#, for example. &gt; the chances that they will run in a language with deterministic memory management and the fact that one can reason about when exactly will they run is what makes something like RAII useful. If you need to know when a finalizer will run you're doing it wrong. 
Indeed, Nim metaprogramming rocks. I really hope that Nim takes off. Rust and Nim are both really bright spots in recent PL design space.
You can't match or output `'` on its own, though a lifetime `'a` is a `tt`. The lang team ~~is stalling on~~ finally approved (!!) [this RFC](https://github.com/rust-lang/rfcs/pull/1590) which would add a `$l:life` matcher.
I've been using [`expectest`](https://crates.io/crates/expectest) for assertions which is quite nice. Mocking seems to be easier in dynamic/OO langs - not sure how idiomatic it would be in Rust. But it would be good to have an answer to it on hand, especially when trying to introduce Rust into unit-test-heavy environments, like rails/ruby shops. I would be interested in what Haskellers do - it's is often where I look for inspiration when doing new Rust stuff because the type system is so similar. 
My initial reaction to the whole "extra welcome" thing was similar to yours, but I have since changed my mind. It's not so much about making a big deal over minority groups getting into the rust community. It seems to be more about emphasizing that 'everyone' includes them - something that isn't neccessarily the case for all projects on the internet. If you've been abused over your race/religion/gender/whatever in previous community projects to the point where you left, you're not going to want to waste your time on any new ones unless you have some sort of guarantee that it's not going to happen again. And sure, you might be able to tell just by lurking and observing how the community works, but being explicit always helps (this is rust after all). Or at least, that's how I've seen it be interpreted. I could be wrong about it, but I'm going to reserve my pitchforks and torches until there's actually a case of the CoC being abused.
If you want to use a language designed around using GC, then why are you here on a subreddit for a language designed around not needing GC?
[removed]
&gt; Java has try-with-resources, C# has using and various warnings if you let a disposable object go out of scope: it seems to me that both language acknowledge the usefulness of RAII, even if you do not. That isn't RAII. That's `unwind-protect` from Lisp. If it was RAII then everything would implement the `IDisposable` interface on .NET, for example. Some people actually wanted that back in the day... &gt; It seems to me that the tail-call problem can be mostly solved by introducing an additional scope that contains the whole function body except for the tail call. In practice an optimizing compiler might also be able to reorder destructors if it can prove that behavior is unchanged. Aren't you assuming static calls? I think in the general case you need to pass all the destructors to the tail callee. &gt; Exceptions should be exceptional so their performance isn't very important I've only heard people with slow exceptions say that. Exceptions are ~6x faster in OCaml than C++ due to the lack of RAII and they are used everywhere for control flow. &gt; Upward funargs are solved by closures? Not if you're using scope-based memory management. If you return a closure then locals captured in its environment need to outlive the scope they were allocated in. That's the main reason why all functional languages are garbage collected. &gt; As for the purely functional collections, I personally haven't really felt a need for them. I imagine they could be implemented in Rust using Rc. That would be [~10x slower than necessary](http://flyingfrogblog.blogspot.co.uk/2011/01/boosts-sharedptr-up-to-10-slower-than.html). &gt; Those languages don't really use destructors so the comparison doesn't make sense My point was that languages that don't rely on destructors often use design patterns that you cannot do if you rely on destructors. &gt; What happens if you don't explicitly close a file handle in those languages? It may be closed, eventually. Or never. You abstract away the concept of a file handle. Consider this F# program that finds the length of the longest line in a file: System.IO.File.ReadLines path |&gt; Seq.maxBy String.length The first line returns an enumerable sequence that begins by opening the file and ends by closing it. The second line consumes the sequence. When it completes the file handle is closed but you never actually see the file handle. In point of fact, I don't remember the last time I saw a file handle. If (big if) you were to wrap a file handle in a finaliser in OCaml so the GC would clean it up for you and if you were to forget to close it yourself then the GC would actually close it for you quite aggressively. Although Java can apparently never clean things up, OCaml often cleans things up before they fall out of scope. &gt; For the same reason people use try-with-resources and using. But the difference between RAII and those concepts is that RAII is ubiquitous. 
&gt; I like that ... macros are written in Nim itself I don't know nim, but I assume this means nim's macros are procedural? Does it also have pattern macros?
Rust is a general purpose language. As such, it can operate effectively in most applications. If you were to put it on a scale in terms of abstractness, where Assembly is lowest and a language like Haskell is highest, it would be above C++ by a small amount. In terms of what it's used for, The Rust Community has begun to develop software such as OSes, web servers, and everything in between. Due to this, it is hard to place Rust on a scale where it is best applicable. Because tools such as Cargo and Rustup integrate so well with the language, it has the ergonomics of a web language such as Ruby. It also features abstractions found mainly in these kinds of languages, such as pattern matching. However, Rust's greater verbosity and enhanced control, combined with its statically compiled GC-free nature, make for a significantly lower-level language.
First of all, it is a compiled language, and its speed is on par with C++ and the like. Since it is a compiled language, it also has a compiler, which is _great_ at doing his job of compiling. Rust is aimed at : * concurrency * memory safety * speed via 0 cost abstractions Now as a language it has a ton of good features such as pattern matching (exactely like you would do ins haskell or OCaml), type inference, ... The thing that is really great is that you will never have to worry about memory safety if you use 100% Rust (because you can bind C with Rust and C is of course unsafe and can have memory vulnerabilities), because every memory issue is handled at compile time and the Rust compiler will always prevent you from compiling if there is a potential error in your code. Sometimes you will be wanting features that other OO languages have (such as inheritance), but you will often find that it can be avoided, and that is often for your safety. The only problem that beginners that with Rust is their fight with the borrow checker ... Think of every variable as a file : either 1 dude can write in it, or multiple ones can read it at the same time. Rust has this same principle : either you take a mutable reference of a variable somewhere, or you take multiple read-only references of a variable at several places. Both at the same time and you'll get a compile-time error. That's the borrow checker. But to be honest, once you have fought the borrow checker enough, you learn to accept it and you get used to it. After that coding in Rust is a breeze. The real breeze in Rust is cargo, a package manager on steroids if you'd like. (think npm, ...). cargo can of course build and run your projects, but has also a built-in test suite, a documentation generator ( like [this one](https://tomaka.github.io/glium/glium/) ) that can be executed in a single command (you can generate documentation for any package _yourself_ !), a bench suite, and it will (soon I hope) include a cross-compiling suite.
[removed]
IIRC, it's "unsafe extern fn". [Here's](https://github.com/rust-lang/rust/issues/10025) the github issue in question.
Do you enjoy writing software that actually works? Software that doesn't require boundless hours of debugging and specialized tools? Rust gives you that with it's strong static type system. Do you hate having to design build scripts, manually defining header files, and having to manually track down development libraries? Rust gives you cargo which automates the build process, provides automatic markdown-based code generation, and a massive Crates.io community of packages to pull from. You simply type the name of the depency you want to use with your Rust project in the Cargo.toml file, specificy the version and simply execute `cargo build` or `cargo run`.
Rust is an amazing language for writing OS kernels, drivers, file systems, etc.
MIR-by-default is great, It will be a milestone for rust dev.
Rust's design didn't stop after the first draft. Rust is *currently* designed to not need a GC. Thus, it *was* (clearly) designed to not need a GC, as it does not need a GC.
&gt;lay­out will be powered by a geo­met­ric solv­er Awesome. Relationship solvers are an extremely flexible, natural way of specifying layouts. You can try such things on the web with https://gridstylesheets.org/, although it doesn't seem to have gotten much adoption (is javascript too slow? Is it just very rare that people want to go further than flex?).
I have found that I almost never need to take moderator action to enforce the code of conduct (an exception being e.g. the time we were brigaded by white supremacists). Unless a commenter surpasses the threshold of obvious trolling, I prefer to engage with people rather than remove comments.
I've held my tongue so far because I know I'll just be wasting my breath. However nobody is calling bs, so I will. &gt;Yet Cargo is secure for definitions of "secure" that include usability as a requirement. 2.2 million signed Android apps. 2 million signed iOS apps. Chrome developers have to sign their apps and extensions. Java developers have to sign their artifacts before pushing them to maven central. Yet, I'm expected to believe signing crates is going to be a completely unusable process. Did rust programmers fall off the short bus? &gt;It is impossible to have a useful shared secure system with no concept of trust. This is the one thing we can agree on. But it's worse than this really. Not only can I not trust crates due to lack of signing. I cannot trust **any software** written in rust for the same reason. That fancy new Habitat thing written in rust by chef? Dead to me. It's a worm riddled security nightmare full of competing exploits from Russian and Chinese hackers... I have to automatically assume that. &gt;It's not like ... anyone can push malicious code into any crate. crates.io is impervious to hackers? I'm astounded. That's incredible. I had no idea that the crates.io team was the best security team on the whole planet. Based on this key fact alone, I'll hire them all for twice whatever they're making right now and make eleventy bajillion dollars in government contracts with those never before seen computer security skills. But wait, there's more. How do I know that they haven't received a National Security Letter and are expected to turn over their encryption keys to the NSA just like Lavabit? I see they're hosted on Amazon, in the US. I don't see a warrant canary anywhere... hmmm, already compromised. &gt;Are you going to individually track down each package maintainer and have them verbally verify that the key signature on those packages correspond to their personal key? Straw man. Indicates ignorance of key verification processes. &gt;It sounds to me like you're pushing unfounded ideas and expecting them to be popularly received. The fact that you are highly upvoted is the part that worries me most. If everyone working on rust is this belligerently ignorant about computer security, what is the state of the code I should expect to find on crates.io, signed or otherwise? This is key to why I leave. People coming here to make a contribution are belittled and shouted down by fanatics who are unable to deal with objective criticism. 
Ok, thanks for the info. Omitting the `--link` argument to bindgen prevents the `#[link]` attribute from being used.
IMHO, not the right place for such initiatives. I was wondering for a moment if that project is legit or some super-sophisticated scam.
What do you mean by outside/inside? As I said, I'm not a Rust developer and it looks very good to me. It's been a year and there are already computers running it with graphical interface and it has good documentation on how to get started. Very impressive.
It seems like a lot of the functions start with a common prefix, like the `initiator_*` and `target_*` functions. Since Rust has proper namespacing, it might be best to separate these functions into their own modules and drop the prefix. You also seem to have a lot of raw pointers; depending on how high-level the binding will be, it might be best to wrap them in Rust references and/or structs (especially since null pointers can cause issues).
Just read though the chapter. It seems that the names for Associated Types defined are in Traits, and 'pinned down' for a particular implementation for a Trait. Hmm, so let's see how well I understand this. * Associated types seem to be for when you have types that 'come along for the ride' for implementations for a trait (they are determined in the implementation, not when a value of the implementation is created. * Generic types are determined when an actual instance of the implementation is created. So it really depends on how much flexibility you need. If you're not expecting to use different types with the trait much, and you're willing to create a struct when you do need new types, then you can use Associated Types. If you need to many different types work with the trait, you can use Generic Types instead. How is my understanding?
I'd like to second the "rule out entire classes of bugs using the type system" part. Rust's type system is versatile enough that you can use it to [compile-time enforce correct use of any API that can be represented as a state machine](https://insanitybit.github.io/2016/05/30/beyond-memory-safety-with-types). (The link uses the IMAP protocol as an example and the [hyper](https://github.com/hyperium/hyper/) library uses this trick to ensure that you can never accidentally try to set HTTP headers after the request/response has already been sent, as plagues the PHP world.) The TL;DR explanation is that, via the borrow checker's ability to enforce that only one reference is usable at any given time, you have any method which changes states take ownership of the old object and return a new one with a different set of implemented methods. Then, it's a simple matter of "Request&lt;Sent&gt; has no set_header method!" at compile time. (hyper is still on my list of "neat, but no need yet" libraries, so I don't remember the actual names)
The harm caused by having to avoid making sexist jokes **is not comparable** to the harm caused by sexist jokes. The way in which you flatten this difference is ignorant and unpleasant to engage with.
While package signing won't solve all problems, it does reduce those you need to trust to only those who signed the packages. Is that not a benefit? Combined with whitelisting, this lets you control who you trust. Yes, all code should be treated with equal suspicion. But once you decide you want to trust some code, package signing lets you enforce that without needing to trust everyone.
Both Rust and C++ closures can be returned from their defining function without safety problems and obviously without a GC. Garbage collection is totally orthogonal to escaping closures.
I accidently mistyped None as NONE but did not get compile time error. I thought that NONE was somehow aliased to None, but it seems any kind of identifier works, how come? fn main() { let foo: Option&lt;i32&gt; = Some(4); // let foo: Option&lt;i32&gt; = None; match foo { None =&gt; { println!("None"); }, Some(i) =&gt; { println!("{}", i); }, } match foo { Some(i) =&gt; { println!("{}", i); }, None =&gt; { println!("None"); }, } match foo { Some(i) =&gt; { println!("{}", i); }, Bogus =&gt; { println!("Bogus"); }, // Bogus is not a valid variant for Option, no? } match foo { Bogus =&gt; { println!("Bogus"); }, // error unreachable patterns // None =&gt; { println!("None"); }, // Some(i) =&gt; { println!("{}", i); }, } } Also how are the Some and None variants for Option created as aliases to Option::Some and Option::None? 
&gt; &gt; Actually that's very inefficient because all fresh allocations are cache misses. &gt; &gt; How so? If you don't recycle unreachable heap blocks then every new heap block is a bit of memory you have never seen before so it is a cache miss. &gt; Doesn't a garbage collector grow in chunks? There are many different GC algorithms and they all do different things. The most popular current algorithm is generational. So you have a nursery generation where fresh allocations are made using a pointer bump allocation. The nursery is about the size of your L2 cache and it tends to stay in cache so every fresh allocation is warm in the cache. When it is full the heap blocks in it are marked, survivors are evacuated to the next generation and pointers to them are updated. &gt; I would expect that every now and then it needs to allocate more memory from the OS, but most of the time it just allocates on memory that it already owns. So you would get cache misses every now and then, but not most of the time, and certainly not on every new allocation. Just because the memory has been allocated from the OS doesn't mean it is in cache though. &gt; &gt; That certainly isn't true in F#, for example. &gt; &gt; I only know Java and not F#. How does F# run destructors before the garbage collector collects the memory? If you write code that explicitly owns some external resource like a file handle then you use something that looks a bit like RAII: let myFunction n = ... use writer = new System.IO.StreamWriter(stream) ... n+1 The `use` binding gets the compiler to insert a call to `writer.Dispose()` at the end of scope (because `StreamWriter` implements `IDisposable`). In practice it is more common to abstract that away. For example, to find the length of the longest line in a file: System.IO.File.ReadLines path |&gt; Seq.maxBy String.length The first line returns an `IEnumerable` that opens the file, streams out lines of text and then closes the file. So the second line automatically opens and closes the file for you. &gt; Does it run destructors at the end of each scope independently of the memory gets collected? Exactly, yes. The GC handles memory. For scarce resources like file handles you use `IDisposable`. &gt; That would make RAII useful for resources that are not memory. Yes but it isn't RAII because it doesn't apply to every type. RAII would be making every object implement `IDisposable` just as every object has a destructor in C++. &gt; &gt; If you need to know when a finalizer will run you're doing it wrong. &gt; &gt; My point was rather that in a language with deterministic object destruction you don't need finalizers since you can easily rely on RAII, while on a language without deterministic object destruction one does need finalizers. Not really. Every language has "deterministic object destruction" because that just means running a function (the destructor) at the end of scope. And you cannot always rely on RAII because it only works in limited circumstances. In the general case you need to identify unreachable subgraphs and, therefore, need a garbage collector. Whether you inherit one from your language or not you'll probably end up writing one in some form. 
Ah nice, I didn't know they had gotten GUI to work. Still, from an industry pov it is too far away from being used in production/any "serious" manner. Servo is much better in this regard since when it is stable it will prove to run great on tons of computers. 
[removed]
Hey @rozaliev: any news? Or did it get deprioritised? :) In the meantime, I am learning C++ and seastar myself, learning how buildling C++ is a pain: https://github.com/jkozlowski/seastar-dns
I saw expectest but haven't tried it yet. I will have to give it a shot! Rust has pretty good tools for some of the base layers of mocking--trait bounds make it easy to be generic over a concrete implementation, and the production code compiles down to what you would get even without generics, which is great. I think it would be straightforward to write a mock library that works like Google Mock, where you have to explicitly declare all the methods you're mocking. I agree that we probably can't have something like Python's mock library, where `MagicMock` just works for everything because of dynamic typing, but it'd be great to at least have something in the middle where you could declare a mock object given only a set of traits that you want it to mock, like maybe: trait X { fn foo() -&gt; u32; } fn f&lt;T: X&gt;(t: T) -&gt; u32 { t.foo() } #[test] fn test() { let mock_x = mock!(X); mock_x.foo.will_once().return(1); assert_eq!(1, f(mock_x)); } I don't know if this is possible, perhaps with a compiler plugin.
Agreed. Security isn't a Boolean attribute. Layering independent security measures is an effective strategy. A github (&lt;-) or tls vulnerability won't endanger or compromises the entirety of the rust ecosystem if packages are signed by an independent party, even if the keys are poorly handled (like being kept on an on-line, network-connected system for example). Furthermore, assuming that most developers don't take package security, some of them do. I work at a company that maintains an air-gaped, physically-secure system that is exclusively delegated to signing software (despite the fact that we produce mundane, non-security-critical software). Developers who need or want this level of security will limit the packages they use to those that can meet their requirements. I do this and many do so too.
It is for a good cause - rescuing people from forced organ harvesting. I also do not intend to keep that information there forever, since as things are progressing now, the people involved in organ harvesting are being arrested for corruption charges one by one and it will not be too long when this all ends. Also there is the time factor involved - I am quite busy with the development of the library (having a regular full-time daily job as well). We spent months on the website itself since it is all done from scratch. So even if I want to take personal action for a similar initiative in another form, unfortunately I really do not have the time or place to do it. I know it is unusual, but it is just because people are not used to seeing these things mixed together. If you think about it, people even watch TV movies and sports events while all sorts of ads are running in front of their eyes. Here you may read that kind of information if you like, close the bar with the X button, and it will not bother you anymore, nor somebody would want something from you. When you use the engine itself, it will not show ads in your application or game - now that would have been a super-sophisticated scam :)
I see, thanks.
 You should have gotten a warning that you have an uppercase binding name. I did, but I usually get so much of them that I ignore them. =)
Thanks to /u/Kbknapp for suggesting it—that *does* sound awesome. I'll be in touch for New Rustacean, /u/adamhjk!
Are you using VIM? Yes, it's extremely weird, but the authors free choice.
This made my day: https://rust.libhunt.com/categories/1517-ides Thanks a lot for sharing.
Nice!, Simply Awesome!
I feel like it has a major advantage over c++ in that hindsight is 20/20. Yoi wouldn't think there is too much of a difference, but if you look at projects, most rust ones are relatively easy to jump into, but c++ can be a nightmare at times. - No mess of platform independent ifdefs, as the standard library is feature rich - less macro abuse. - Better style, as RAII is enforced - build system is worry free - no manual dependencies - Some say Documentation is a bit ambiguous, but I think it is Excellent. (Try polkit) - Because of the std, there are not tons of libraries like boost, sdl, so you don't have to learn a million. - compiler errors make sense - explicit; c is very hard to understand in the fact that it common to use short names, and more so that pointers are utilized for a lot of things. Containers like Vecs, Arcs, and boxes are immediately recognizable. - generics and traits, although complicated, are excellent
Yet, it could be even better. There could be a bit more packages. I believe the community will help extending the lists over time...
Thanks! Just looking how best to wrap the pointers now
That's your problem right there. rustc tries its best to help you. You don't get to complain if you ignore it... :-D Seriously, try to get warning-free. Ask here or on IRC if you need help. Once you're done, get a nightly Rust and `cargo install clippy`. Then try to get your code clippy-clean (that is, run `cargo clippy` and fix your code until it no longer complains). Again, ask for help whenever you need it. You'll find that not only your code becomes much clearer, you will become a much better Rust programmer.
~~Is this based off the https://github.com/kud1ing/awesome-rust repo?~~ EDIT: Nevermind, saw this on the "About" page: &gt; The primary listings are based on the official Awesome Rust list at GitHub I do think you should link back to the repo, though.