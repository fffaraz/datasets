One of Rust's prestige projects, ripgrep ([https://github.com/BurntSushi/ripgrep](https://github.com/BurntSushi/ripgrep)), uses mmap for top performance when searching a single file. It appears to use this library: [https://docs.rs/mmap/0.1.1/mmap/](https://docs.rs/mmap/0.1.1/mmap/). I'd start there.
Big if.
That seems about right :) (but I'm only like 99% sure about this all...)
`failure` helps mostly with composing different errors. You still have to write the explicit `Result` return type and use `?`. I'm not saying this is good or bad -- just a statement.
You can always encapsulate a pointer in your own type. E.g. if you have a memory buffer that you want to read and write to from multiple threads and really don't care about race conditions, just make sure it's only accessible through a pointer and make a type that wraps the pointer and performs the required operations. For passing data around you should look at the various options Rust offers for loosening the restrictions around mutability (Cow, Cell, RefCell, atomic, Mutex, RwLock etc). 
I stand corrected. At least it panics with debug assertions... 
This is *fantastic* news. I’m so glad /u/burntsushi is in our community.
You can get the effect you want using UnsafeCell. It won't be as pretty, though, and there's probably a better way to structure your algorithm so it isn't needed.
I mean, impl declarations are as nonlocal as lifetimes can be brought into scope.
Right. The problem with removing the angle brackets is you lose context in situations where a lifetime could come from multiple places. impl SomeStruct&lt;'a&gt; { // [ten screens-worth of code] fn foo(&amp;self, &amp;'a str, &amp;'b i32) -&gt; &amp;'a Foo { ... } // quick, do 'a and 'b belong to the fn or the impl? } In Rust 2015, you can answer that question quickly because the information is all on the same line (you'd see `fn foo&lt;'b&gt;` and know that `'b` is local but `'a` must come from the impl). 
If you look at the dependencies, you can see it actually uses [memmap](https://crates.io/crates/memmap).
If you don't mind living dangerously.. use std::ptr; #[derive(Debug)] struct St { x:usize, y:String, } // Use a 2nd mutable static so that we have a reference to mutable memory static mut DUMMY:usize = 0; static ST:&amp;'static St = unsafe { Transmute { from:&amp;DUMMY }.to }; union Transmute&lt;T:Copy, U:Copy&gt; { from:T, to:U, } fn main() { unsafe { ptr::write(ST as *const _ as *mut _, St { x:9, y:"foo".to_string() }) }; println!("{:?}", ST); } 
&gt; UPDATE: I see that it's described later, but why even show the wrong way in the first place? Unless you have fantastically limited storage, the size of your containers is often irrelevant. Having access to dependencies which can't be statically linked, and having access to a more complete runtime environment can both be valuable things. It absolutely isn't "the wrong way". I've actually seen MUSL bugs cause segfaults in production, which is scary stuff. glibc is much more reliable.
It's cheap enough to exhaustively check: https://play.rust-lang.org/?gist=fcf792cb00a64dd695eedb2af0b3fbda&amp;version=stable&amp;mode=release&amp;edition=2015
Yeah, that indeed worries me. I do take some solace in the fact that it could only come from one place.
But what I don't know is what would go in ```[crate name here]```. Would it be the module? Would it be ```lib```?
No. It would be the name of the crate itself. For example, take a look at [this repo](https://github.com/durka/cellsplit). The name of the crate is "cellsplit", which is set [in `Cargo.toml`](https://github.com/durka/cellsplit/blob/master/Cargo.toml#L2). Therefore, `main.rs` can [import](https://github.com/durka/cellsplit/blob/master/src/main.rs#L8) stuff from `lib.rs` by writing `extern crate cellsplit`. 
Why not? The original ref in the OP's example is a shared reference, so there's effectively no difference between making a raw pointer from the reference and reading from it vs simply making another shared reference and reading from that.
ohhhh and it makes sense too 
Thank you! I get this wrong all the time. Now if only https://docs.rs/serde-derive would work... 
&gt; `debug_assert!()` is not sufficient, you need it to never happen in release builds. The probability of triggering it on valid inputs in debug mode is basically zero. Of course, using `assert!` is safer; there's no disputing that. My point, however, was that if an `assert!` is not strictly necessary (right now, it is proven never to happen) and may not be desirable (if it worsens performance) then a `debug_assert!` should still be introduced since it is Zero-Cost in Release and can only help for development. &gt; Fun fact: the asserts I've added to that function after the if have actually improved performance by at about 2% instead of regressing it, probably by providing hints to LLVM optimizer. So, an `assert!` introduces a branch with an exception (`panic!` uses exception-propagation mechanisms). Since exceptions are costly when thrown, optimizers indeed deduce that the branch is unlikely to ever be taken, and therefore: 1. Optimize for it to not be taken: the code throwing the exception can be moved out of the hot path, for example. 2. Deduce that the condition which would lead to the branch being taken is unlikely, and from there on can deduce things such as value-range, etc... So, yes, sometimes `assert!` improve performance. What would be interesting when `panic!` are undesirable would be a mechanism to pass those hints to the optimizer as pure compile-time constructs. 
I don't understand the reasoning why CTFE cannot read files. The compiler can already include arbitrary files compile time with the include macros. What's the difference? I think this limitation is just way too forced and does not really make sense.
Well, definitely for than my -5% before :D Thanks again!
I'd argue afl in stdin mode is point and click, but not libfuzzer because it requires source code changes. And in a C project that I see for the first time in my life I just have no idea where to start or how to perform those changes, and the compiler will not stop me when I wire something up horribly wrong. Not to mention pretty much all build systems in C are a pain, except maybe meson but that's kinda niche.
Oh yeah, I thought I've heard something about such a tool, but could not locate it. Thank you for making it! However, after fuzzing actual projects I'm less concerned about panics (which can be isolated into a thread if you really want) than I am about memory leaks, unbounded allocations and stack overflows, that crash the entire program and cannot be reasonably handled on the language level. A linter for that would be rad, although making one is probably going to be pretty hard.
Well what if the file changes between two invocations of the compiler, while the source code is unchanged? Now your binary behaves differently. More to the point, the binary now depends on which computer it was compiled on. And the `include!` macro adds files to the "source code" of your project, which is different from reading a random file. 
&gt; A large design constraint lies in the protocol itself. Wayland is spoken by binary messages over an unix socket. It is an object oriented protocol, where each message is associated to an object which defines its interface. &gt; Which means that, to parse a message, you must know the type of the object that sent it. Which means a large part of the work of the implementation is actually to keep track of the map of which object exists and what their types are. And given a message can create or destroy objects, you need to have at least partially processed a message to be able to even parse the next one! Talk about being stateful. Could you expand on this? Do you mean that a message only contains an object ID, and no type ID, forcing you to keep a map (object -&gt; type) to be able to reason about the messages? In most binary protocols I've interacted with, each message contains a header which announces both its type (to know how to interpret it) and its length (so that you can skip unknown messages easily, as well as backward compatibly add new fields at the end of existing messages). For example, one of the state-of-the-art binary protocols is SBE (Simple Binary Encoding). Very simple, with full backward compatibility. Does the wayland protocol diverge much from this?
Thanks, I needed that functionality, but I started to implement it on my own, because I didn't really trust the crate, because it was last updated 3 years ago. But I think ill give it a shot now.
`UnsafeCell` is the mechanism by which you "dig down and do whatever you were gonna do in C++" in this particular case. Rust just makes you mark the places where shared mutability can occur, whereas in C++ the situation is reversed and everything is in an `UnsafeCell` by default.
You really did not make it clearer:/ I still feel like that there is no real difference and it is just a semi random rule from the past. I'm sure eventually it will be changed because it makes no sense..
&gt; Install a handler for `SIGBUS` Yikes! &gt; Is it even worth using mmap in the first place? For the use cases where it matters, IMO they should have a specific `mmap` usage behind `unsafe`.
Thank you, when I lookee for mmap/VirtualAlloc I only found the crate mmap at first and I didn't want to use it because it wasn't updated in 3 years.
If you could give us a Playground link or just a code file that we could actually run, it would be super helpful for figuring out a safe way to do what you want to do.
I already figured out a safe way, it's more just about the actual mechanics of the compiler at this point, I wasn't aware of the aliasing rule stuff
Can/does `cargo` have a safety-audit feature? e.g. `cargo show-me-all-of-my-deps-that-have-unsafe`? Maybe it would be handy to have a crate configuration option that states `rely-only-on-pure-safe-crates`? This would work well in conjunction with an `#[cfg(pure_safe)]` for crates to provide alternative implementations. Does any of this exist already? If not, has it already been considered and ruled out?
Indeed, a wayland message has a header that contains its length, an object ID, an opcode (id of the message among the possible messages of the object's type), but not the type of the object itself, so it is required to keep a map ID -&gt; Object type. Add to that that the wayland model supports protocol extensions, which are described by XML files. Meaning there is no exhaustive list of all the objects you might one day encounter. With that, your map actually becomes a map ID -&gt; (Object type description including the list and signature of all possible messages)... It certainly would already simplify things a lot if a wayland message embedded its signature, but on the other hand, most messages are so small (3-4 words), that I guess it'd have a significant overhead...
The borrow checker is not the problem. Your proposed code is the problem, and it is wrong. Yes, you can force the borrow checker to allow you to write incorrect code but that won't suddenly make your code correct.
&gt; You can have APIs that return *mut pointers though if you don't want UnsafeCell in particular to leak through the API, but of course most anything you do with the returned pointers then requires unsafe. This isn't correct. It's not enough that the data happen to live inside an UnsafeCell: *all* accesses to the data must go through that UnsafeCell. Otherwise it's UB.
**TL;DR: It can be made safe (with some effort) in terms of soundness, but it'd be a big security flaw.** --- It is actually possible to safely read external files, query external servers, etc... However, in order for it to be safe, then it must be guaranteed that such operations behave as *pure functions*: if called with the same arguments, they must return the same result. This could be implemented, for example, by simply building a huge cache, in which the result of each such query - arguments pair is stored until end of computation, and any subsequent query simply reuse the result from the cache rather than performing a "live" read. This is more difficult, implementation-wise, but still quite feasible. --- Beyond safety, it's also an additional hurdle for incremental compilation. In essence, each result of a read/query is its own source file, and therefore should it change then there are ripple effects: some stuff need be re-compiled. This requires that for incremental compilation, the cache that I mentioned above must be saved as part of the incremental meta-data. Wholly. Then, each time the compiler is invoked, it must first perform *all* queries again and compare their output with the cached ones to know whether they changed or not. Still feasible. --- At this point, however, we have to question whether it is *useful*, whether it could be *surprising* and what would be the *priority* of such a feature: - **Useful**: possibly. - **Surprising**: in some instances, extremely. Reading `/dev/random` multiple times in the same compilation process always returns the same result. Yet it most likely changes across each invocation of the compiler (causing incremental compilation to recompile all dependencies). - **Priority**: extremely low; it enables nothing that `build.rs` cannot do. --- And then we need to talk about good engineering practices and security. In terms of **engineering practices**, I would put out there a reminder that *reproducible builds rock*, and any kind of input that is *NOT* committed prevents them. Therefore, I would argue for a two-steps build process if such a thing is necessary: 1. Read whatever you need from network/disk/... and write that to a file committed in the repository (or several), 2. Build from those files. And at this point, simply ensuring that the file is valid Rust code is sufficient to NOT need to read files during the compilation. In terms of **security**, including arbitrary I/O in the compiler opens up a huge attack surface. You could literally have "innocent" looking Rust code reads files of your disk (hint: `~/.ssh/id_rsa`?) and upload them to a random webserver. It's already possible today as part of `build.rs`, however it's also trivial to check whether a crate has a `build.rs` or not^1 whereas auditing arbitrary Rust code to check for file/network access would be a huge pain. ^1 *Note: Is there a cargo feature to explicit whitelist which crate - version pair is allowed to execute a `build.rs` script as part of its build? If not, we need one before this is exploited.*
Then why won't you listen to everyone telling you that this won't work?
That is awesome news and I will re-evaluate artifact for [imag](https://imag-pim.org) development as soon as possible!
Y a y !
While I have your attention, would people mind chiming in and saying what exactly they want to use multiline search for? I guess a lot of people want it, and I know VS Code users expect it, and I can think of some use cases myself. But I honestly never really come up with much reason to actually use it.
&gt; However, in order for it to be safe, then it must be guaranteed that such operations behave as pure functions: if called with the same arguments, they must return the same result. First of all, what do you mean by "safe" here? Memory safety (what safe usually means in rust context) seems unlikely. But more importantly, *why* would I/O need to be pure to be "safe"? What would be the issue in reading for example /dev/random or whatever?
I mean safe as in *sound*. Imagine the following: - The caller compiles `fn fun(t: &amp;[T; random()])` with `random() == 4`, and therefore allows the call to `fun(&amp;[0, 1, 2, 3])`. - The callee is compiled `fn fun(t: &amp;[T; random()])` with `random() == 8`, and therefore optimizes out the bounds check on `t[7]`. **BOOM**, reading past the end of the array in ~~safe~~ not-so-safe Rust! Therefore, it is critical to ensure that all usages of `random()` within a specific context (here determining the size of the argument of `fun`) always yield the same result. Since the link between the call site of `random()` and its actual use can be arbitrarily complicated in the presence of CTFE; it is simpler to have a *single* context. This imposes that `random()` behaves as a pure function.
Ok, let's simplify. There should be no fundamental reason that you can't invoke `include!` inside a `const` context (if the file doesn't exist, then you should get a compile error). However, what you can't do is something like this: ``` File::open("path_to_file"); ``` This is a dynamic operation that depends on the file-system contents, and the compiler has no way of statically enforcing the result of this.
Hey, if I have a function that returns an Option and I have 20 arms in my match. Do I have to wrap the return values in Some() 20 times or is there a better way of writing this? fn match\_to\_color(number: u32) -&gt; Option&lt;Color&gt; { match number { 1 =&gt; Some(Color::Blue), 2 =&gt; Some(Color::Red), //..20 more of these arms \_ =&gt; None, } }
No, it just means once the compiler has created a definition of fun it sticks with it. It should still be an error at link time if it finds two different definitions of fun.
I sometimes want a quick and dirty way to search for when a given function is called with a certain argument. But when that function takes a bunch of arguments, and some of the callsites spread the arguments out over multiple lines, that's hard to grep.
&gt; However, in order for it to be safe, then it must be guaranteed that such operations behave as pure functions: if called with the same arguments, they must return the same result. If the operation is deterministic, then the result cannot be dynamic, which really hamstrings the utility of this functionality. If this is not the case, compiling this on different machines which might or might not have the file would result in binaries which do different things, as opposed to the current system, where the binaries would be functionally identical (as you point out in your example). Succinctly, allowing network/fs operations to be invoked in a `const` context would violate const safety as defined in the OP. 
What if you write a code generator in python, and it pulls information from an external server? Now your build depends on network connectivity. You can't prevent people from doing this. You can however insert arbitrary restrictions in your language which will require you to take on the impossible task of trying to anticipate everyone's use cases. More seriously -- let me depend on network connectivity or local files if I want to. Just make it easy for me to enforce that I don't if I don't want to (and make that the default).
Is your name german by accident or intention?
&gt; It's already possible today as part of build.rs, however it's also trivial to check whether a crate has a build.rs or not1 whereas auditing arbitrary Rust code to check for file/network access would be a huge pain. Does rustc guarantee that the include macro can't read from files not in the source code repository? Does it also refuse to read symbolic links that point outside the source repository? That said. This seems sort of on the paranoid end of security considerations.
I'm not sure what you mean, in order to mutate the data inside `UnsafeCell`, you call `UnsafeCell::get`, which returns a *mut. What do you mean "go through that UnsafeCell"? I might be missing some subtlety, but I thought that UnsafeCell just prevents rust from emitting noalias attributes to llvm if you're accessing an immutable reference? A *mut or *const isn't an immutable reference, so there's no problem right? I didn't think rust did any alias analysis with pointers?
You are right. We completely forgot to include that. I’ll make sure to add that later. For now: You can reach the community team via email at community@rust-lang.org Or you can open an issue: https://github.com/rust-community/content-o-tron/issues
This is probably what OP needs. As the [example in their docs shows](https://github.com/rust-lang-nursery/lazy-static.rs#example), you can put an arbitrary block of initialization code inside a `lazy_static`.
It's a malapropism of a name and would translate into: "Steve Nothing Works" Stief - Steve klappt - functional / works nix - nothing
My exact meaning is found at the UnsafeCell docs but my point was that if OP followed your advice without further study, inevitably OP would have turned around and made two &amp;mut and that would be UB. UnsafeCell isn't a panacea.
[Done.](https://medium.com/@shnatsel/auditing-popular-rust-crates-how-a-one-line-unsafe-has-nearly-ruined-everything-fab2d837ebb1) But I'm not so sure that my particular workflow should be encouraged - it only gets you the low-hanging fruit. I would much rather have people refactor unsafe code into safe without having to understand how a particular unsafe could go wrong. Alas, there is no documentation on doing that, even though the building blocks for it such as LLVM flags `-Rpass-missed` and `-Rpass-analysis` are there.
I've added a mention of Rustig to the post. Control flow analysis is actually really impressive. I wonder what else it could be used for.
That's what "huge cache" means. People keep using array lengths directly as a problem but remember you can compute arbitrary types from such constants with associated types *and those are not cached across crates*, but non-deterministic CTFE could break the typesystem if *any* query ever executed isn't cached and reused If you have a conflict between sibling crates you *must* deny linking them, otherwise they could interpret the same associated type as different types.
I agree completely, making two &amp;mut is unsafe, but passing around a *mut pointer is not intrinsically unsound. I mean, yes you *shouldn't* do it, but it's not UB, and if it was interfacing with C would be.. impossible? I understand what you're getting at, though. I definitely wasn't suggesting that the OP actually do this, I thought it was pretty clear I was suggesting it was a bad idea and a really poor rust API, and really really hard to get right.
You are welcome!
&gt; miri’s floating point implementation is perfectly sane and should be standards compliant, LLVM and the particularities of x87 rounding are the sources of uncertainty here. I don't think x87 is used that much these days. One source of uncertainty is the standard itself which lefts many things unspecified. E.g. `sign(sqrt(-1.0))` is different on ARM and x86, both are standards compliant.
Beyond what is said in the other replies, it also breaks either CTFE correctness or CTFE determinism: Either reading `/dev/urandom` twice produces the same result due to some huge cache (deterministic, but incorrect -- at run-time, it would produce a different result the second time), or it actually reads the file twice (correct, but non-deterministic and hence breaks the compiler). `include!` is somewhat different because it only reads a particular file *once* and then treats it as source code. That's much weaker than allowing arbitrary operations. Also, why stop at *reading* files? What about CTFE writing to files? Or reading files and sending them to the internet? We surely don't want that.
They are easy to get anywhere. Just look at the link I posted.
You could use if number == 0 || number &gt; 22 { return None; } let color = match number { .... }; Some(color) 
Well, use alpine if you're afraid. Using ubuntu as the base image is for people who don't understand what docker and k8s are for. 
Something like this: ``` match option { Some(x) =&gt; x, None =&gt; unsafe { ::std::hint::unreachable_unchecked() } } ```
Check out the recently released [cargo-geiger](https://crates.io/crates/cargo-geiger). 
Alpine is still static linking, and still MUSL, which comes with a heap of problems. If *you* don't understand why the Ubuntu image is useful, that doesn't mean you should go around insulting people who use it, or denigrating the hard work of the team who spent months working on the 18.04-minimal Docker image to reduce its size.
I think the difference is that one of the possible types is expected, and therefore the api is more ergonomic for that case. Methods like `value` and `operator *` don't exist on `std::variant`.
&gt; let me depend on network connectivity or local files if I want to Please propose a way to actually implement that such that, e.g. linking two sibling crates together will not cause random link failures because they evaluate a function differently. Crate A: ``` const fn get_size() -&gt; usize { /* read it from the network */ } ``` Create B: // compile this while the network service returns "0" ``` fn foo(_ : [u32; get_size()]) { ... } ``` Crate C: // compile this while the network service returns "5" ``` static FOO : [u32; get_size()] := [0; 5] ``` Crate D: ``` B::foo(C::FOO) // explosion, fireworks ``` CTFE absolutely needs to be deterministic. This is not an arbitrary restriction to make some things harder, it is fundamental to how CTFE works. This is also entirely unrelated to the fact that you can codegen based on network requests -- that's external to the compiler and just producing source code, so all the usual mechanisms (e.g., the type system) apply to make sure that everything fits together. The *output* of codegen is the *input* of the type system, while CTFE works during typechecking itself.
It was my understanding (but I am just relying information here) that x87 is still used on 32bit platforms, where you cannot always rely on SSE and friends being available. &gt; E.g. sign(sqrt(-1.0)) is different on ARM and x86, both are standards compliant. Oh, interesting. That's certainly not helping, either. (Not sure what CTFE would do.)
Libraries with dependencies picking a certain version is indeed the larger problem :/
Or even better: Some(match x { .. _ =&gt; return None })
Not sure if it is possible. But multiline xml search I need ever so often as our logs have tons of xml requests/responses. A small example would be like ` &lt;Body&gt; &lt;DeviceType operation="query"&gt; &lt;ID value="Audiocode-600"/&gt; &lt;/DeviceType&gt; &lt;/Body&gt; ` Here searching any single line is not much useful but 2 or more lines will make it lot more useful search.
Cool, thanks!
Because i wanted to know why, and everyone was just telling me what I already found in the book
How are you even defining 'correct'
That's a lot harder than typing "FROM ubuntu" Edit: And more to the point: It's distracting from what the blog post is trying to teach. 
&gt; TL;DR: It can be made safe (with some effort) in terms of soundness, but it'd be a big security flaw. &gt; &gt; It's already possible today as part of build.rs, however it's also trivial to check whether a crate has a build.rs or not1 whereas auditing arbitrary Rust code to check for file/network access would be a huge pain. 1) Procedural macros can do the same already (connect to the internet, download malware, link it with your project). 2) Pretty much every single Rust project out there depends on this happening on many forms: `cargo` downloading code from the internet, the Rust std library getting `libc`, `stdsimd`, ... from the nursery, `jemalloc-sys` checking out `jemalloc`'s github repository, compiling it, and linking it with your project... So... if this is where you want to set the bar, I really do hope that you are inspecting every single procedural macro and every build.rs throughout your dependency tree down to `libstd`, `liballoc`, and `libcore`, in particular if you are recompiling those your self. But if this is already the case, inspecting `const fn`s aren't really that much extra work.
I said nightly and not stable because this was only merged 3 days ago, and presumably won't be in stable for a while... but other than that, I guess we agree :)
Perfect, that's what I needed :)
Hi, how do I instantiate a value of `Thing::A` in the playground link below? https://play.rust-lang.org/?gist=5ec1b01e597fd8c9e3aace94d65e71e1&amp;version=nightly&amp;mode=debug&amp;edition=2015 I started with a simple `type ThingT = Thing&lt;f64&gt;`, hoping that I could instantiate `ThingT::A`, then I realised that isn't possible, which you can learn about here: https://github.com/rust-lang/rust/pull/31179 Then I was like "okay, I'll just write the full type directly in-line wherever I use it then change it when the type alias problem is solved." Then I learned I have no idea how to do it that way either. I've tried `Thing&lt;f64&gt;::A{...}` and `Thing::&lt;f64&gt;::A{...}`.
You can do it like [this](https://play.rust-lang.org/?gist=b499be8516a57471f5716c1779637c4f&amp;version=nightly&amp;mode=debug&amp;edition=2015). I'm actually surprised this works without requiring `T: Debug` in the enum definition. Nice! (e) Oh yeah, by shear force of "Hit random things on the keyboard" I could make your original desire come true: https://play.rust-lang.org/?gist=8519ffc1884cf3e0daba80a5726fe044&amp;version=nightly&amp;mode=debug&amp;edition=2015.
How did u go about deploying?
Thanks, that's good. I also just realised that the inline syntax is `Thing::A::&lt;f64&gt;{...}`, because `A` is the function with the generic arguments, not `Thing`.
``` (?m)fn .*something.*\(-&gt;\s+Foo.*{ ``` i.e. a function called `something` that returns `Foo` Other such uses: - If an equality can be split `let something = \nfoo_bar_is_long()` - Searching all uses of multi-line strings (in python) `""".*"""` - Generic parameters: `Foo&lt;A, B&gt;` -- you can't be guaranteed it won't be split over multiple lines. - I don't know, plenty of other cases :)
Haven't read through yet but will probably be useful to me. I have an actix backend ready but not much experience deploying other than node to heroku.
I don't understand. What exactly do you mean?
Ha, thanks for that explanation, makes sense actually!
Was just curious if it was dockerized andor using some service(heroku ect). Or just thrown up on a vps, or what.
unfortunately not yet. For one thing you need `mdbook` and `cargo-web` installed to compile -- for another thing it has sub crates and I haven't yet figured out a decent way of maintaining all of that. If you can't download the linux binary, you can check out the master branch and compile it locally, then copy the binary into `~/.cargo/bin`. Sorry for the inconvenience, but I haven't gotten the cross-platform build system fully working yet!
I'm unsure if any memory safety issues were found in `std`, though `std::mem::forget` being marked safe just before Rust 1.0 was an unexpected design flaw. (Is a memory leak unsafe? Not by Rust's definition, it was decided) Remote code execution implies there would be a CVE issued, and Rust (actually rustdoc) [earned its first CVE the other day (congratulations!)](https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=rust). But that's only for local code execution.
cloud root access server. Probably virualized, but to me as user it looks like a normal root access server. I did not use docker on the machine, I had running a privoxy and an ad blocker proxy in a docker once with jwilder/nginx proxy. Super easy.
Do you know which is preferred when naming a new crate?
Ah yeah, sure ^_^
There have been what are known as [soundness bugs](https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22); that is, bugs in which it would be possible to create a memory safety issue if you used the API in the right way, and the typechecker and borrow checker wouldn't catch it. Some of those bugs have been in the [standard library](https://github.com/rust-lang/rust/issues?q=is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22+label%3AT-libs), but more of them have been in the [compiler](https://github.com/rust-lang/rust/issues?q=is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22+label%3AT-compiler), where the compiler was failing to check things properly in safe code. Note that these issues wouldn't necessarily be exploitable directly, but only if APIs were used in certain ways, or certain code patterns were used. Some of them are more likely to happen, some of them very unlikely without very contrived code. A [few of these bugs](https://www.ralfj.de/blog/2018/07/13/arc-synchronization.html) have been [found while developing formal models of Rust](https://www.ralfj.de/blog/2017/06/09/mutexguard-sync.html); as of Rust 1.0, there was no formal framework for reasoning about the safety of interfaces provided on top of unsafe code, but now there is a framework built on top of a formal language that models a small subset of Rust. This work has been good enough to catch some real bugs, and it has demonstrated that the core idea of providing safe interfaces on top of unsafe code is sound, which is a really good step. There are also some soundness problems [caused by LLVM optimizations that can affect safe code](http://sf.snu.ac.kr/publications/llvmtwin.pdf), so not all such problems are even in the Rust compiler or standard library itself, but in LLVM that it's built on. So just writing safe code doesn't guarantee that there won't be any memory safety bugs that could be remotely exploited, but it substantially reduces your chances, and many of these issues require writing code that goes out of its way to cause memory safety issues. I don't know of any of these soundness issues in the compiler or standard library that have actually caused remotely exploitable vulnerabilities. [None of the vulnerabilities in the RustSec database](https://github.com/RustSec/advisory-db) were due to soundness issues in the compiler or standard library; they are all either panics that could cause denial of service, logic bugs affecting network protocols or filesystem access, or use of unsafe code in third party crates that was incorrect.
The [dereference operator on shared_ptr](https://en.cppreference.com/w/cpp/memory/shared_ptr/operator*) is the same.
Ah, okay. I'm not in a hurry as I'm on a sabbatical anyways and cannot test it properly right now (and for quite some time tbh) ... Just wanted to know. :-)
SSE was introduced in the Pentium III and Athlon XP. Anything older is pretty much completely irrelevant for modern software. A 32-bit x86 platform these days is way more likely to be "someone accidentally installed 32-bit windows on a 64-bit box" than a Pentium II.
Reading through some of the linked issues, it seems like this bug in `VecDeque` should qualify as something that could credibly cause a remote code execution vulnerability: https://github.com/rust-lang/rust/issues/44800 In fact, it's bad enough that I think some kind security advisory *should* have been issued, unless I'm missing something.
Sure! Four mi(slot map only) presented in 4 minutes at C++Now: [The Slot Map Data Structure](https://www.youtube.com/watch?v=SHaAR7XPtNU) The long version (includes other containers as well)
&gt; denigrating the hard work of the team who spent months working on the 18.04-minimal Docker Not as hard to made ubuntu image bloated by default... Makings something small isn't exactly a hard task. Maintaining image based on OS that glorifies having buggy and outdated packages for sake of "stability" (stable crashes in many cases) with random 3rd party repositories - not so much. &gt; If you don't understand why the Ubuntu image is useful, that doesn't mean you should go around insulting people Did I hurt your feelings? Sorry. &gt; Unless you have fantastically limited storage, the size of your containers is often irrelevant. You don't care about maintaining it? I don't want to have an image with tons of trash it that I don't need and is very opinionated. 
You use the term "type variable" and distinguish it from a "type parameter". But the `T` in a generic is not variable -- it can never change. Also, it is used as a parameter: it is passed in from the instantiating code. So the term "type parameter" is to be preferred.
&gt; That's what "huge cache" means I don't think "huge cache" would be exactly the same as what /u/tending suggested. "Huge cache", if I understand correctly, would imply that the following would have the same type signatures: ``` fn f(t: &amp;[T; random()]) fn g(t: &amp;[T; random()]) ``` Whereas I would interpret /u/tending such as they would have different type signatures. I think the disconnect here comes from that people (including me) would have expected that each type declaration is evaluated exactly once during compilation, but apparently that is not the case?
That's because the book explains why: it's undefined behavior. That's it. That's the reason. Asking "why is it UB" doesn't lead to deeper meaning that you're looking for because there is no deeper meaning; only to motivations: it's UB because this allows the compiler to make optimizations it couldn't make otherwise. You can disable these optimizations through *careful* use of UnsafeCell or its safe interfaces Cell, RefCell, Mutex. Even with these you cannot have &amp;mut overlapping other references.
http://blog.dustinkirkland.com/2018/02/rfc-ubuntu-1804-lts-minimal-images.html At least know what you're talking about before you talk about it.
Your post improved my understanding of unconstrained type parameters. I missed the "problems with impl blocks" though, could you elaborate?
What issues are you trying to solve by catching `SIGBUS`? Another process truncating a file used by a shared mapping? Just tested that out with `ripgrep`, which does mmap files, and yes, your process is killed by `SIGBUS`. In the case of `ripgrep`, that behavior is acceptable; it stops the process, because there's nothing left to search, just like you'd get a `SIGPIPE` if it's piping output to `less` but you kill `less` before all of the data has been written. In a longer running process, where it's not OK to terminate on `SIGBUS`, if you wanted to map a shared file, then yes, you'd need to implement a signal handler to do something in case the portion of the file you mapped no longer exists by the time it's read. There are some alternatives, depending on what your need is. You could do your mmaping in a separate process, if it's possible to send any results back by IPC. You could have a pool of worker processes, which can be restarted if one is killed. On Linux, if you're using mmap for IPC between processes, you could use `memfd_create(..., MFD_ALLOW_SEALING)` and `fcntl(..., F_ADD_SEALS, ...)` to create a sealed memfd, which is a memory buffer that can be guaranteed to not be alterable in certain ways (like modifying it or truncating it), so it can be safely used for IPC between processes. But in the general case on POSIX-like platforms, if you mmap a file and don't want to be killed by `SIGBUS` if the region of the file you access no longer exists, you're going to have to handle `SIGBUS` somehow.
That's a ridiculous, troll-y question, but here's the answer anyways: Code is correct if all compilers conforming to the (hypothetical) spec would/must compile the code to some target form which is (a) correct and (b) has the intended semantics. Of course the correctness (a) of the target depends in the same way on the specs of other things like the OS or the processor. Really (a) just makes (b) a well defined concept so we can simplify the definition to: Code is correct if the results of all conforming compilers have the intended semantics. Your proposed code is incorrect because the spec, insofar as it's currently understood, does not constrain a conforming compiler to produce target code with your intended semantics.
 This is our initial problem. As you can see here, the impl block has two variables: T and E. T here means that we’re implementing methods for all the Ts – i.e. Ɐ. However, we’re not implementing it for all the E. We would like to state that we need a E to exist, which means that there exists an E – i.e. ∃. The current syntax doesn’t support this. There is a perfectly sensible resolution. This is burdened by the syntax in Rust (and is only marginally better in Haskell). Consider this alternative perspective: impl&lt;T, E&gt; OrderedList&lt;T&gt; where T: Foo&lt;E&gt; { fn invoke_foo(&amp;self, e: E) { for t in self { t.foo(e); } } } This block *does* universally quantify over *both* `T` and `E`. But, it also requires an additional parameter (and thus, imposes an additional assumption). The `where T: Foo&lt;E&gt;` part acts like a *third* parameter, the value of whom is passed implicitly. It is a witness to the fact that `T` implements `Foo&lt;E&gt;`. Cf [Curry-Howard](https://en.wikipedia.org/wiki/Curry–Howard_correspondence). In Haskell, it would translate roughly as: forall e, t. Foo t e =&gt; OrderedList t The notation is cleaner in a dependently-typed language like Idris or Agda, where it might be something close to this: {E : Type} -&gt; {T : Type} -&gt; {Foo T E} -&gt; OrderedList T Here, the curly braces indicate the parameters are implicit. You can see that the `E` and `T` types are parameters, and thus are universally quantified, since you can pass any type without restriction. However, you run into trouble once you try to construct a witness to pass in as the third argument, as `Foo T E` will be an *empty* type except in the very special situation where `T` implements `Foo&lt;E&gt;`. It's much like Henry Ford's famous quote: "You can have any color you like as long as it's black" This quote universally quantifies over colors. But the additional assumption (the color must be equal to black) is a very strict stipulation, indeed.
Yes, I've said this before - visibility for soundness issues/ unsafety is not at the place it should be. [rust-lang.org](https://rust-lang.org) still says "guaranteed memory safety" when that isn't true (in any practical sense - even if Rust The Language is memory safe, it's irrelevant to everyone who writes rust). You have to explicitly search for soundness holes to find them (and you must independently discover that they exist). There is no concept of advisories in third party crates or even the stdlib as far as I am aware. There have been multiple problems found in the stdlib that you wouldn't know about unless you happen to read a blog post by whoever found it, or search the issues. I would like to see progress made here.
[removed]
Ah, thanks. I hadn't actually dug through all of them, I was just going off my memory. Yes, you're right, I think that could have warranted an advisory.
There's one thing I sometimes want to do that I currently have no solution for that would be solved by this: Some entries in a log file are spread over multiple lines for some reason, for instance a stack trace. If I want to search for a stack trace containing multiple things I cannot do that. The way I work around this now is by doing something like this: "rg thing1 -A 10 -B 10 | rg thing2 -A 10 -B 10" 
&gt; The problem with that last block is that E is not constrained on OrderedList&lt;T&gt; and is. It seems like an important word got left out at the end of that sentence, but I'm not sure which!
If the language spec said that addition resulting in a number over 1000 was UB, you wouldn't say 'okay, guess i'm just avoiding that' - you'd ask 'why is that UB', because every other language seems to be totally fine with it People don't just read the language spec, ingest it like a machine, and just produce code that conforms to it, you know that right?
Leaking is safe partly because it is intractable to check at compile time. Reference cycles can be arbitrarily complex and are only created at Sun-Times, where rust avoids overhead by minimizing checks
You were rejecting valid answers because they didn't fit a troll-quality reductionist view. If you want to program in a language where overlapping mutable references is not UB, then you're free to do that. The noalias thing was actually not being passed to llvm for several releases (not sure of the current status) but multiple mutable references was still UB - for no reason except that *that's just how it be*. That's a valid answer. Likewise, cache coherency on x86 is a lot stronger than on arm but incorrect concurrent Rust code is just as undefined when targeting x86 as it is on arm.
It is six times larger than Alpine and 15x larger than busybox. Now, tell me how big those images become after one `apt-get upgrade` + install dependencies. It still has 95 packages left. A little bit too much for container that at least need libc and openssl (libressl if you don't use python and care about security) + CAs at most. At least they got rid of init system that's a relief. 
What about Vulkan?
That sounds like an interesting approach. It took quite a bit of engineering to make it usable, and P2P sounds like it will take even more, so I'd go with donation funded if I were you. Thanks, I thought I had fixed the certificate earlier but now it works!
Thank you very much!
&gt; troll-quality reductionist view What a friendly community
Could anyone link me some reading on the use cases for CTFE and why const propagation alone is insufficient for them?
One of the hard parts here is probably finding the right level of nuance. The issue I cited is probably near the top of the severity scale (only exceeded by something that is proven to be exploitable in real crates), but at the bottom you have cases where rustc accepts some extremely contrived and unrealistic unsound code or even where it is not clear that soundness can be violated. There is this for security advisories in crates: https://github.com/RustSec There should probably be some similar initiative to publish unsoundness bugs. Also I'm kind of missing some information like "if your crate still compiles with the updated version of rustc and std your application was not affected", which is useful to know for people trying to figure out if they need to redeploy applications, push updates, or even possibly issue an advisory to their own downstream users.
I suggest `lazy_satic` and get downvoted, though it addresses the question posed, another person (eddyb) suggests `lazy_static` and gets upvoted. How is it fair?
I really hope that changes. Embedding WASM has the potential to be a much more general alternative to the "Rust to Rust binding generator, via the C ABI" idea I had for supporting runtime plugin loading without waiting for a stable Rust ABI.
Isn't that what build.rs is for?
Sign me up!
&gt; but at the bottom you have cases where rustc accepts some extremely contrived and unrealistic unsound code or even where it is not clear that soundness can be violated. It might not be helpful to treat them all the same. Agree, you need some kind of system here. These system already exist, adopting/ slightly changing an existing framework seems reasonable. Plenty of the soundness issues, for what it's worth, are not contrived at all and I have seen them in real code. &gt; Overall Rust does seem to take unsoundness bugs very seriously and the issue category on GitHub appears to be well maintained so it's not like the information is not being tracked. What's "very seriously" ? There are tickets. They have been open for years. Their priority is unclear. In some cases, their state is unclear. There are maybe valid reasons - priorities are unclear, a framework for severity does not exist, a clear way to respond does not exist (eg: is it ok to add a hack in to prevent the common case, while something like mir borrowcheck lands? is that viable?). Given these things, a metric for "very serious" or any criteria of success is really hard to derive. Starting to come up with these processes seems like a fine place to start.
Have you checked out the documentation? Specifically [this](https://docs.rs/hyper/0.12.1/hyper/struct.HeaderMap.html#method.insert) details the `HeaderMap` insertion, and [this](https://docs.rs/hyper/0.12.1/hyper/struct.Request.html#examples) provides an example of setting a header on a request. 
I actually discovered one of these soundness holes by accident a while ago. At first I thought it was \[a bug in \`httparse\`\]([https://github.com/seanmonstar/httparse/issues/34](https://github.com/seanmonstar/httparse/issues/34)) but after trying to create a minimal repro case it turned out to be \[a bug in the compiler\]([https://github.com/rust-lang/rust/issues/40288](https://github.com/rust-lang/rust/issues/40288)).
Can you be more explicit about what you are trying to do? What is the problem with just using mmap?
https://github.com/RustSec as it is now is useless. The only way to check a crate for vulnerabilities is to manually run a cargo subcommand that you've never heard about and doesn't come installed by default on all of your crates every single day. Nobody does that, and nobody should be expected to do that either. Instead, crates.io should pull that database and alert maintainers of crates that depend on a vulnerable version automatically. Alas, this is not being done.
Yeah, that *definitely* warrants a CVE. I suspect Debian Stable ships with the vulnerable stdlib version, although I cannot check because their package index website is down for maintenance. Should I poke the security team about this? Looking for exploits went under the radar was actually on my TODO, but I've only had time to look through still-open issues and so far only found [one](https://github.com/servo/rust-smallvec/issues/96).
I think the problem is that the block can only deduce it's parameters from the types, and not from the methods. So, if we have a concrete type `OrderedList&lt;u32&gt;`, Rust needs to know whether or not that block applies to it - but it can't, because it doesn't know what `E` is. I can only know what `E` is once we call `invoke_foo` on an instance of that type - which is why putting `E` on the `fn` works. So, it's not enough for the entire block to be injective - the blocks "signature" by itself should be injective.
&gt;Bytes Any info in how use this? I look with google and see sparce information. BTW, have you thinking in move with this kind of library? For what I read in other threads you know about this. My dream is have a relational language (like [http://www.try-alf.org/](http://www.try-alf.org/)) that not only have "dataframes" but allow to integrate with others RDBMs as easy as possible.
&gt; Yeah, but &gt; I'm special;) Hmm...
[removed]
Video proof.
you meant this for r/playrust
Wrong Rust. This subreddit is for the programming language.
I don't think it makes any sense to talk about "injective" anything here (or in Haskell, for that matter -- but I have opinions)... But, I do see your point. If you were to translate this into a dependently typed language, it would effectively force you to keep a reference to the type `E` in a dependent pair: OrderedList : (T : Type) -&gt; Exists (E: Type) (T -&gt; E -&gt; IO ()) Where the function tyhpe `T -&gt; E -&gt; IO ()` is the function `invoke_foo` with `self` having type `T` and `e` having the existential type `E`. In this context, the analog of an existential type in Rust would be an associated type. I would think that since `E` is "captured" in the scope of the block, you should ideally be required to write this instead: impl&lt;T, E&gt; OrderedList&lt;T&gt; where T: Foo&lt;E&gt; { type E; fn invoke_foo(&amp;self, e: E) { for t in self { t.foo(e); } } } Looking at the problem again, I'm actually a bit surprised this isn't required. It seems to be implicit.
I don't know of an emerging standard.
As someone who was considering moving to rust, this is.. not good to hear. among other things that attracted me to rust were it's promise of memory safety by default, compared to C/C++'s unsafe by default. Not the most important thing by any means, but still a big feature.(Higher up is the amazing tooling and ease of use) To hear this is less than true bordering on lying, well, sucks.
&gt; The only way to check a crate for vulnerabilities is to manually run a cargo subcommand that you've never heard about and doesn't come installed by default on all of your crates every single day. So, what command is that?
Let's just have the compiler not assume such function to always return the same value? \`B::foo\`, when compiled, would have as signature \`fn(\[u32; 0\]) -&gt; ()\`, and \`C:FOO\` would be of type \`\[u32; 5\]\`, rather than both using a seemingly-similar \`\[u32; get\_size()\]\`? This way, crate \`D\` would just get a type mismatch compilation error.
https://github.com/RustSec/cargo-audit
I feel pretty strongly that while rust does not truly guarantee memory safety (because bugs in the compiler and std exist) that this should be weighed against \*other\* languages with the same issues. As an example, Go is not memory safe in the presence of race conditions. I don't think this is a well advertised fact. Another example - how many Python libraries are really C? How well does CPython protect that code? The answer leads me to believe that Python has a worse security story than appears. I believe that you can be very successful writing rust. But there should be better communication around the pitfalls, and a better system in place for addressing them.
Say there are two trait `impl`s: impl Foo&lt;f64&gt; for OrderedList&lt;u32&gt; { /* ... */ } impl Foo&lt;String&gt; for OrderedList&lt;u32&gt; { /* ... */ } Should `OrderedList&lt;u32&gt;::E` be `f64` or `String`?
Map will change one item to another immediately. In your case, it will change the `Request` into a `Concat2`. However, that concat type is itself a future. The body may not have arrived yet, so that represents a future of the entire body. Finally, in your and_then, you just try to print the debug output of the future (which will just tell you it's a Concat, not the actually full body). You use map and map_err when converting an immediate value into another immediate value. You use and_then and or_else to convert an immediate value into a new future. Since you want the Concat future to resolve, you should use `and_then(|res| res.into_body(). concat2())`. ---- The actual compiler error though is because in your final call to `and_then`, which wants you to return a new future, you returned nothing (that's the `()`).
&gt; Ok / Cancel button placement (its reversed on windows / mac!) And switchable on X11. GTK+ defaults to following Mac but themes or your `.gtkrc` can reverse it, while KDE themes typically follow Windows conventions unless they were developed with an intent to allow some kind of unified theming between Qt and GTK+ apps. (eg. QGtkStyle, QtCurve, etc.) That said, there is an [objective reason](http://uxmovement.com/buttons/why-ok-buttons-in-dialog-boxes-work-best-on-the-right/) to prefer the Mac order. (Not surprising, really. Apple in that era put a *lot* of work into doing the R&amp;D to design objectively better interfaces. The detached menu bars are to take advantage of Fitts's Law.)
That's not the kind of function we're worried about (we can actually make those cases work, they're not much worse than `include_str!` etc.), think more: fn f&lt;T&gt;(t: &amp;[T; random() % size_of::&lt;T&gt;()]) That is, the call is evaluated from application of generics. There's an even worse one based on associated types, but I don't have the link on hand (maybe I should go find it before confusion spreads further).
In real-life C/C++ projects these issues go unfixed for years, and not announced as security issues when fixed. This leaves production systems vulnerable for years to come. I've recently written a [post](https://www.reddit.com/r/rust/comments/8zpp5f) on the state of Rust libraries and pointed out some issues, but it is still *worlds* better than the situation in C and C++ ecosystems. Rust also has more strict memory safety guarantees than Go or any other high-level language. Is Rust perfect? No. Is it dramatically better than C/C++? Yes. Is it better than Go/Python/Ruby/...? Depends on your use case.
I wish Ralf had linked to https://internals.rust-lang.org/t/mir-constant-evaluation/3143/47?u=eddyb which describes the *real* problem with non-determinism: no matter how much information you record, you'll always be able to break coherence (you can maybe prevent crates from being used together, which is closer to what I think Haskell without at-instance-definition-time typeclass coherence checks does, but it's not great by any measure - assuming it even works).
By the way, there’s a second legal option: you can unsafely cast `&amp;mut Foo` to either `&amp;UnsafeCell&lt;Foo&gt;` or, to allow access without `unsafe`, `&amp;Cell&lt;Foo&gt;`. This is okay because Rust doesn’t have C’s type-based aliasing restrictions, and `Foo`, `UnsafeCell&lt;Foo&gt;`, and `Cell&lt;Foo&gt;` (but not `RefCell&lt;Foo&gt;`) all have the same memory layout (guaranteed since `UnsafeCell` and `Cell` are marked `#[repr(transparent)]`). Thus, you can take advantage of the Cell types without them ‘infecting’ the rest of the code. If you do this, just make sure to be careful with lifetimes, since with unsafe casts it’s easy to get an unbounded lifetime that gets inferred to something longer than it should be. Also, FWIW, I’m not impressed with how many downvotes you’ve received on some of your posts. It’s like people think they can banish the UB by downvoting it, even though receiving downvotes is the last thing that would motivate most people to change their code; if anything, it would more likely motivate them to quit Rust. Better to explain the reasons for the unsoundness, its precise boundaries, and as many potential alternatives as possible.
Ralf is missing one (crucial) detail, for the full picture see https://internals.rust-lang.org/t/mir-constant-evaluation/3143/47?u=eddyb.
That did it! I just added an `Ok(())` to the end of my second `and_then`, and it all worked. Thanks!
Anything where the constant is used in the typesystem, e.g. `[u8; size_of::&lt;String&gt;()]` (try it, it works today!).
oof let me do this myself.. r/lostredditors
HELL YEAH AT LAST I can dehardcode some magic bitfield-related constants now! Yay!
Other languages are definitely not totally fine with this. The book says it is undefined behavior, and that's really the end of it unless you want to dig into compiler internals and figure out how LLVM and Rust interact with respect to every potential optimization that could be done. LLVM &amp; Rust optimizations need to make assumptions, and when they are violated, you get UB and your program is invalid. If we're just spit-balling, you could imagine that the compiler sees an immutable value behind a reference in a single thread and it decides "hey, why deref the value at all? Why don't I just generate this code so as to *copy* the value when the function is called?" And boom. You cast to *&amp;mut* and all of a sudden you're mutating a copy and not the original and your code no longer does anything.
Unless I am mistake (see my EDIT), neither works because the `impl&lt;T, E&gt; OrderedList&lt;T&gt; where T: Foo&lt;E&gt;` doesn't compile in the first place.
I don't think it's lying to state what software is supposed to do in absence of bugs. Otherwise every software feature description would have to include asterisks (* except if feature is buggy). There are compiler bugs in every compiler, library bugs in every library. That said, making these bugs (and their being fixed) more visible is a good thing. It is not a shame for Rust.
Is it ok to call it a guarantee? This is not just "there may be bugs" it is "there are bugs, they have existed for years, we know about them". It isn't some long shot theory that rust has soundness holes, there are dozens of examples. I get wanting to call memory safety a goal, and a goal that Rust does an impressive job at reaching for. A guarantee though? 
Fix in documentation (often python, rst files). I see a mistake/misphrasing in a rendered html file. I'll copy the most-likely sequence of word to be unique and rip-grep it in the source tree. Is is likely for this sequence to be over 2 lines. Multiline would thus help.
The way the memory guarantees were described, as "irrelevant to everyone who writes rust", doesn't inspire confidence, compiler bugs or not.
Heh, amusing that the fix to `insert_many` also speeds up its associated benchmark by 40%. Normally one is supposed to worry that fixing soundness issues will regress performance. :P
&gt; In real-life C/C++ projects these issues go unfixed for years, and not announced as security issues when fixed. Isn't that what this thread is saying also happens for rust? &gt; Rust also has more strict memory safety guarantees which the thread says is "irrelevant to everyone who writes rust"..
exactly what i needed! thank you!!
[RustSec advisory](https://github.com/RustSec/advisory-db/pull/30/files) Yesterday I've fired a few quick github searches to see if there are any security bugs that are already discovered, but not yet fixed. This often happens due to security bugs not being recognized as such. This is the only one I've found during my cursory inspection. Kudos to Vurich who has discovered the issue, and to the crate maintainers for a very prompt fix once I've pointed it out.
Yes, I agree. The guarantees are over stated given that we have known, current exceptions to those guarantees.
Sure, it is ok. Unless... you know a meteor could fly down and kill us all, so the word 'guarantee' is strictly referring to an impossibility and nobody has a right to guarantee anything. Basically, it is the *design* that has this guarantee of memory safety, even if the implementation is not exactly there. 
No one is building services with the design of rust, they are building services with rustc. 
I leave it to others to judge the wording inappropriate. In general, as engineers we often fall into the trap of wanting to communicate only "court-room truth" (as in, nothing false, nothing left out), at a cost to conciseness, abstraction, and getting the point across. For me, the important thing is that these are *bugs*, not "well, yeah, this is a wart in the language, don't do that, then you'll be safe".
I came here to comment on this and yes this is the official position AFAIK. We use "type variable" only inside the compiler to mean "(type) inference variable" i.e. what each `_` (including implied by not specifying types) creates, eventually resolved to a type without any remaining inference variables in it (or errors are emitted).
I agree. It's easy to optimize for objectivity and over expressiveness.
The Rust website doesn't even mention rustc.
Probably because no one ever talks about rustc, because the term "rust" encompasses its build / toolchain.
Yes, absolutely. [`VecDeque` is fairly widely used](https://sourcegraph.com/search?q=repogroup:crates+VecDeque+count:1000), and while browsing a few of those examples I didn't find any examples of the problematic code path (`reserve` or `reserve_exact` followed by pushing more items) in attacker controlled input, a lot of the places where `VecDeque` is used are parsers and protocols. I did find at least [one use of `reserve_exact` in Xi](https://sourcegraph.com/github.com/google/xi-editor/-/blob/rust/trace/src/fixed_lifo_deque.rs).
To clarify a bit, I think the "safety by default" part is very effective in practice. If you write code without the unsafe keyword, it's very difficult to trigger memory unsafety. (As folks were mentioning above, it's possible using certain compiler bugs, but it usually requires code carefully designed to hit the bug.) What's more likely than falling down an unsoundness hole in the compiler, is relying on an external library that uses unsafe code and contains a bug of its own. That's what's going on in the VecDeque example above -- that container uses unsafe code internally, and that unsafe code was buggy.
Big milestone, congratulations! &gt; if you’re interested in getting involved in this space, reach out on #wg-net on Discord. Could we please communicate asynchronously through issues? I've peeked in once in a while, and really wish the conversations there were captured in issues instead, so others can comment when they have time (or can at least *understand* why decisions are made).
[removed]
Sure, no one is building anything with specification of any language, they are building it with (flowed) implementations. Rust is no exception. And rustc does provide better memory safety guaranties, even if they aren't absolute. You can't get absolute guaranties anyway.
The story with Vulkan is pretty much the same as for OpenGL. You need to provide pointers coming from the C wayland libs to your graphics stack.
a minor improvement in the solution: you can get rid of the extra clone by changing foo to accept an &amp;E and changing the .clone() inside the loop to &amp;e. [playground link](https://play.rust-lang.org/?gist=2be87d5d36dbdbd809fac28e47c70a59&amp;version=stable&amp;mode=debug&amp;edition=2015)
The difference is that unsoundness is considered a bug, whereas in C++ it's part of the deal.
Sure. But very emphatically, this is not a decision that the app developer should make. Apps must always obey the conventions of the system on which they run. Any cross-platform application system needs to understand and respect the local convention, whatever it is.
&gt; Yeah, the problem with unsafecell is that it just pollutes everything, now I need to write unsafecell everywhere and import unsafecell everywhere, which is a shame Well yeah, since it's non-idiomatic code, it makes sense it's more verbose. It's probably still less verbose than regular modern C++ though :-) In any case, you shouldn't need to use `UnsafeCell` _all over the place_. Typically it is used in restricted areas of code that absolutely need it and the rest is written in idiomatic Rust. `UnsafeCell` is also typically wrapped in custom abstractions to make working with it easier. There's stuff like `Deref` and `DerefMut` to help with that... If you're worried about performance, benchmark first, then design. If you're looking for a design based on assumptions about performance, you're gonna have a bad time :-) &gt; I have a safe solution, and there is a safe solution fairly often, it's just annoying that there's no option to do it the 'unsafe way' without it being UB Not sure what you mean, sure there is a way to do it without UB. 
If anyone is interested, here is a small header only [maybe::Result](https://github.com/trafi/maybe-result-cpp) library I wrote 2 years ago, that somewhat mimics Rust's Result type. Here is a quick summary of my experience of writing and using it: It is running in production now on Android and iOS, and gives a lot of confidence that all errors on certain app paths are handled. The `expected` type is tied to exceptions, the `maybe::Result` is not; I did not like the magic inside that requires the error to be an exception; I prefer a simple value. We use exceptions in our app for one thing: panics, where the error is logged and the app shuts down. Otherwise the error has to be handled. Wherever we don't need full `result` with `E` (pretty much everywhere), we get away with using optional. Sadly, the optional in C++ standard library still does not link properly in iOS (new C++17 uses modified allocator function, or something like that), so we are using [another optional implementation](https://github.com/akrzemi1/Optional). Not to mention that `optional` in standard library is more bare-bones. I have spend way too much time trying to correctly implement `Result` using unions in a way where the space for `T` and `E` is shared. In the end, I scraped it and switched to two optional&lt;T&gt; and optional&lt;E&gt; types. The templating magic required here is hairy. Maybe in future we can switch to the `variant` type inside, whenever Apple and Google updates their own forks of C++ standard libraries. Final note: sum types. I think the `variant` type in C++ was a mistake, and anything else similar like `optional` and `expected` in standard library should not be done using templating. Instead, C++ needs sum types, which would make implementation of these primitives __trivial__.
Shouldn't the versions &lt; 0.6.3 be yanked on crates.io? It doesn't look like they were, and I did not really think this through, but that feels like the thing to do.
I'm excited to see work being done here, but I find that version number really funny. `0.3.0-alpha.1` The first alpha of the third pre-release version? That's some intense versioning.
Hey, it’s that issue I discovered writing [this post](http://troubles.md/posts/improving-smallvec/)
I am confused by this feedback, the issues list is pretty thorough and changes are discussed there: https://github.com/rust-lang-nursery/futures-rs/issues The call for action is literally just "hey, this is how you get in touch with us", which issues aren't a good place for. 
"disenchanted"
Some changes aren't discussed there, but rather in the Discord channel, and then pull requests appear without any of the context. In the couple times I've checked out the Discord channel, I noticed an increase in that sort of discussion there since the announcement on internals. So, I'm actually afraid that this sort of call to action just results in *more* of that. Instead, anyone wanting to get involved can comment on issues, or start filing pull requests for improvements. Chat isn't required to do that. And it allows more people to participate.
&gt; That's the... first alpha of the third pre-release version? Some rather verbose versioning. This happens with big projects and important projects that have a lot of users; when you want to get something right before release, sometimes you need multiple pre-releases. &gt; Sounds like it really would have benefited from being 1.0, by SemVer standards. 1.0 means "production ready" not "maintained".
I don't feel qualified to comment on pretty much anything of real importance, but man—that logo. It's boss.
&gt; It's not a question of "wrong solution for the problem" it's a question of mindset, and the mindset of he designers and users of C++ is that performance primes over most other considerations, especially safety. What I tried to say - and I'm a C++ programmer writing high performance applications - is that you're only getting high performance if you design a fitting solution for your problem at hand. So caring for the check in `value()` seems off, because if you have a lot of these `expected` values that it starts to matter, then also the memory overhead of `expected` will start to matter. So it starts to make a lot more sense to encode the valid/invalid values in an other way. It's not the mindset per se, but IMHO a wrongly applied mindset which at the end results into unsafe APIs without even getting the desired properties. 
&gt; It requires a nightly compiler, and works with rustc’s new support for async/await notation. Is it still planned to make the futures 0.3 release work with nightly *and* stable, providing the same API (except for async/await obviously)? &gt; Futures 0.1 continues to be maintained and is the primary way to write production async code today. Is the same true for the 0.2 release? Compared to 0.1 it offered many improvements, which is why it was used for gtk-rs' futures support. I'd be fine with porting to 0.3 but only if it would compile with a stable compiler
I would agree. If they've been doing the "kind of semver" most rust crates seem to follow pre-1.0, yanking and releasing a 0.3.x, 0.4.x, 0.5.x, with the bug fixed would be the correct way about it.
Thanks for the examples, they are good food for thought
Pretty printed program outputs.
Note: I’m not part of the networking WG, but this is my understanding. I believe the plan is to release 0.3 once futures in the stdlib stabilize, yes. 0.2 is not, that’s why it was yanked. Stable users and those not interested in helping shake out bugs should stick with 0.1 until 0.3 is released. 
The standard library absolutely has security advisories; they go through CVEs. We have a whole page at www.rust-lang.org/security.html about this. The security reporting email got an email about this thread and this bug. We don’t support older Rusts, and this particular bug was never escalated like one, so we didn’t put out one then. As such, we aren’t issuing one at this time, but given that it’s in Debian stable, we might; I’ve put it on the agenda for the next core team meeting.
It’s not even that, defining “leak” is hard, because it relies on programmer intention. Is a variable going out of scope at the end of the block and not after the last use a “leak”? 
Off-Topic: The [logo](https://rust-lang-nursery.github.io/futures-rs/assets/images/futures-rs-logo.svg) is pretty rad!
That's what I understood, but the question is more about whether 0.3 will be compileable with a stable compiler anytime soon just like 0.2 was. Previously it was communicated that this would be the case.
&gt; unless you want to dig into compiler internals and figure out how LLVM and Rust interact with respect to every potential optimization that could be done ... and re-do all of that work every single time you update your compiler. 
What feature flags do you need to test out these features?
&gt; While we had originally hoped to ship async/await notation as part of Rust 2018, there’s no chance at this point of having adequate feedback and confidence to do so in time. It's a bit sad, but I appreciate the “Ship when it's ready, not when the planning said it should ship” mindset.
Ah, so, we also originally thought async/await was going to be ready for the launch of Rust 2018, but it's not. Given that all of it is tied together, I'm guessing that that will also take slightly longer. That said, it's not going to take forever either. It really depends on how this next work goes, as far as I can tell. If major issues are hit, then it's gonna take longer than if everything goes super smoothly, you know?
&gt;In real-life C/C++ projects these issues go unfixed for years, and not announced as security issues when fixed. &gt; &gt;Isn't that what this thread is saying also happens for rust? If you're really concerned you can look at the list [here](https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+label%3A%22I-unsound+%F0%9F%92%A5%22+). Currently there are 34 issues in the tracker, but some of these only apply to nightly features, some of these are bugs in LLVM, some of these are waiting on new features like NLL, and some are *extremely* obscure or only apply to tier-2 or tier-3 targets. You should read through some of the older ones to get an idea of what people are talking about here, and to see how seriously the rust devs actually take soundness issues. Saying that rust has more strict memory safety guarantees is "irrelevant to everyone who writes rust" is *really* making perfect the enemy of the good. You said above: &gt;among other things that attracted me to rust were it's promise of memory safety by default, compared to C/C++'s unsafe by default. Not the most important thing by any means, but still a big feature.(Higher up is the amazing tooling and ease of use) &gt; &gt;To hear this is less than true bordering on lying, well, sucks. I think you're taking this a bit too far, the advertised statements about Rust are not "borderline lying", it's just that the guarantees are sometimes kind of hard to explain in "bumper sticker" length. Nobody says that Haskell lies about type safety because you can use `unsafePerformIO` to violate it, and nobody says that Java lies about memory safety because the JVM has had crash bugs or code generation bugs, nor should they. I really feel bad that you might have gotten such a bad impression from reading this thread, when this is just not the impression you should get as a newcomer. The fact that you can write unsafe rust with UB and give it a safe interface is an unavoidable reality of what rust is trying to be, but rather than looking at it as undermining the promise of memory safety in rust, you should look at it as kind of being the whole point to begin with. The REAL benefit is that it makes it possible to reason about memory safety *locally* rather than *globally*, and gives you an actual fighting chance at making something safe rather than it more or less being impossible like in memory unsafe languages, but the nuances of this can get lost when trying to give somebody a quick idea of what the language is about. The larger point though -- that we need to work on how to communicate things better and to keep everyone up to date on any current practical soundness holes and the efforts to fix them either in rustc itself or in commonly used crates -- is definitely one worth talking about and trying to improve.
Will there be further breaking changes after 0.3 is finalized?
E-mail bounce messages where the reason (e.g., "File too large") may be arbitrarily split across lines, depending on how the reporting MTA
Fair enough, but can we guarantee that LLVM will never use x87? (I also don't know what the default architecture for Rust in 32bit is, i.e, which extensions it will assume.)
 &gt;A solution to this would be to set len = index before iterating. Obviously this would cause leaks but we're already leaking data. That's pragmatic.
At my job we use XML a lot. I used to use grep a lot to find stuff, but of course it's always hard because you can't actually parse XML/HTML with regular expressions, there is no reasonable way to deal with namespaces, etc. I can *highly* recommend hacking together a tool with a grep-like command line interface that uses XPATH instead of regular expressions.
Sure thing, nice to noticing it out, but that was not the aim of the snippet. (:
Finally, a futures/async announcement that lays out a reasonable plan without any unrealistic timelines.
So no compiler should claim to implement C (because they all have known bugs that make them non-standards-compliant)? No browser may claim to be compliant with HTML/JS/CSS standards, and they also should remove any mention of the word "safety" from their website (empirically, no release of a browser ever was free of security vulnerabilities)? I think you are putting the bar way too high here.
No argument there. I certainly find it very irritating when I run into an application that is ignoring my efforts to configure my KDE/LXDE hybrid desktop to universally follow the Mac-style button ordering.
Recruit some people from StackOverflow and tell them to leave "Chats are not for extended discussion" everywhere. And maybe give them mod rights to temporarily ban participants in such discussions until issues documenting everything relevant in those discussions are created. Can a bot do this?
I would say safe Rust is safe in practice against users and not safe in practice against adversaries.
It's a shame it's not going to ship for 2018, but with my (limited) experience of futures that's the right decision. I need to be careful how I put this and I want to make it clear that my intention isn't to upset someone or doubt the work of anyone who contributes to Rust. However, it feels like a lot of the goals for 2017 weren't achieved by 2017 and some don't feel completed now. Perhaps a less broad plan might be helpful next year, or even just phrasing the roadmap a bit more as goals rather than saying certain features will be in.
Sure, but from what I understood the plan was to have 0.3 work on stable (without async/await obviously) before all the new fancy stuff is stabilized. Just like 0.1 and 0.2 worked on stable and had opt-in support for nightly features.
That's not possible. 1. 0.1 was the initial design, so it worked on stable 2. 0.2 was the second iteration of the design, so it worked on stable 3. Then, we put futures in the standard library, which need to be unstable for now 4. 0.3 builds on top of those, so it inherits the instability That's why 0.3 hasn't been released yet. When 0.3 is released, it will work on stable; until then, there's the unstable preview.
I personally think that it would be much better if edition were tied to a set of features, on completion of which edition will be released, and not some strict date.
It's a variable in the math sense. In a function such as `f(x) : x ↦ y` the symbol `x` is a variable because it can *vary* between calls (but not in the mutable state sense).
Why can't we replicate the stuff that wayland C lib does? Or is it varies between platforms?
It's not going to ship *for the initial release of rust 2018*.
So, the core API is in the stdlib now, so they will not get more breaking changes. The futures library adds more combinations and stuff, and the intention is for 0.3 to be the stable foundation for a long time. We’ll see!
Do you mean like, the adversary gives you safe Rust code, and you compile it into your own process? In that case, for sure, Rust doesn't provide that kind of safety. Not until every possible soundness hole in the compiler has been plugged at least? (Would it be safe even then? libstd is enough to let you run arbitrary commands on the machine, but maybe if the code was compiled against libcore it could in theory maybe kinda sorta be safe?)
Oops. :D
I think I should rename that part because it’s a more meta and thought process than a real problem. `impl` blocks are Rust constructs to factor some functions on a type and label them _methods_, providing automatic importing, for instance. This creates new problem (i.e. you cannot have two crates defining those, otherwise, you end up with the problem of [orphan instances](https://wiki.haskell.org/Orphan_instance) – you have the same problem if you try to implement a trait for a type you’re not the writer of. I truly think some guidelines are hidden there, like “Do not put trait bounds on `impl` blocks”, but they were also designed for this (some people on IRC told me they enjoy them to gather methods for `T: Clone`, for instance. I truly think it’s a mistake because I personally don’t read the documentation like “Oh, let’s see what methods are available if `T: Clone`, but I can get the point of this argument.
I use the term *type variable* as I would do in Haskell and it’s a bit more general than *generics*. &gt; But the T in a generic is not variable This is quite interesting. If you’ve gotten introduced to the concept of [*free* and *bound* variables](https://en.wikipedia.org/wiki/Free_variables_and_bound_variables), you know that a free variable might get bound at some time. What you’re refering to is the bound version, but really, `OrderedList&lt;T&gt;` has a (free) type variable, and when substitution (instanciation) happens, `T` gets bound to a specific type.
Looks like you posted a wikipedia article, let me summarize it for you... Click [here](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) if you'd like me to stop bugging you. ***** **[Free variables and bound variables](https://en.wikipedia.org/wiki/Free_variables_and_bound_variables)** &gt;In mathematics, and in other disciplines involving formal languages, including mathematical logic and computer science, a free variable is a notation that specifies places in an expression where substitution may take place. Some older books use the terms real variable and apparent variable for free variable and bound variable. The idea is related to a placeholder, or a wildcard character that stands for an unspecified symbol. ***** **^([)** ^([About](https://np.reddit.com/r/ultimatewikibot/wiki/index)) **^(|)** ^([Source code](https://github.com/brrm/ultimatewikibot)) **^(|)** ^(Downvote to remove) **^(])** 
I know. I'm not sure what you're getting at, sorry. To be more direct I'm worried that a lot of the things that are listed in the yearly roadmaps quite often aren't on stable by the end of that year. This year's roadmap muddies the waters a bit as it's more to do with the edition, but I assumed that it was referring to the first release.
Ah; I am not sure, but I'm pretty sure it's still going to end up being stable this year.
Okay, ta! :) 
I have to search log files a lot, especially finding sequences or “one right after another” situations and multi-line search lets me do that. 
Part of the reason I learned Python first was for data analysis. I will probably continue to use Python for that since the libraries are great (I love you pandas). I am actually okay with the fact that Rust and Python are geared towards different things. I feel that having those two languages under my belt will get me pretty far in projects I want to do. Rust is also useful to learn now because of Web Assembly. I can't wait to give that a try.
If there are still users of the 0.{3,4,5}.x versions, it'd be cool to backport the patch as well.
Great. Next should be a faster JavaScript minifier, which is the bottleneck of Webpack production builds.
That of course is even better, but more work. I'm always wary of suggesting work that should be done by others :)
Talk is cheap, show me the code! Hi, I'm going through the book those days, but having a more hand-on approach can anyone suggest some good-written Rust repo? Looking for idiomatic Rust, best practices applied and well structured code to learn from. Thanks!
It's this one: [https://carllerche.github.io/bytes/bytes/struct.Bytes.html](https://carllerche.github.io/bytes/bytes/struct.Bytes.html)
&gt; 1.0 means "production ready" not "maintained". semver has always been about stability, from semver.org, emphasis mine: &gt; How do I know when to release 1.0.0? &gt; If your software is being used in production, it should probably already be 1.0.0. If you have a stable API on which users have come to depend, you should be 1.0.0. *If you’re worrying a lot about backwards compatibility, you should probably already be 1.0.0.* Of coure cargo considers 0.x versions to be incompatible with each other which gives rust users a bit more flexibility 
An unmaintained library is very stable. Many actively maintained libraries are not stable. I don’t see how these things conflict.
WASM?
It seems like the futures team is going to extraordinary lengths to maintain 0.1.0, that should have been a 1.0 release. Also 0.3.0 as I understand it is going to depended on by the async ecosystem (tokio, etc) and should also be a new major version to reflect that. &gt; An unmaintained library is very stable. Many actively maintained libraries are not stable. I don’t see how these things conflict. Because semver is often the *only* signal the ecosystem has for api stability. I’ve seen a ton of messaging on this subreddit that tokio and futures 0.1 are stable and if you want async today, that you should continue to use them. This wouldn’t have to be explained if they were a 1.0 release. 
Would this bring in non-Rust dependencies? ie, Rust lib wrapping a C lib; does the C lib get installed?
&gt; Note: Is there a cargo feature to explicit whitelist which crate - version pair is allowed to execute a `build.rs` script as part of its build? If not, we need one before this is exploited. I'm not convinced this is the right solution. If you compile arbitrary code, you kind of have to trust the source anyway. I don't think linkers are hardened against adversarial input, so just compiling seems as dangerous as executing `build.rs`. Even seemingly harmless commands like `ldd` are dangerous. I think the right solution is to compile code in a sandbox. This is something that cargo could support!
The thing is that mesa expects you to provide pointers that it will then give to the C wayland lib that it links against, which will use as if they were its own. So the way to have it would be to provide a re-implementation of the C ABI and ensure that mesa uses it rather than the system lib. I have no idea if it is actually feasible. My ideas about it are dumped on this issue: https://github.com/Smithay/wayland-rs/issues/189
I'm curious to hear from people who have large JS applications: Is the *bundling* part that slow? I have a few TypeScript code bases and the compile times dwarf every other part of the build. (This is probably why I enjoy it, just like Rust) 
What about it? WebAssembly is not meant to be a full replacement for all JavaScript out there. I don't expect to see today's big JavaScript web applications being rewritten and compiled to WebAssembly. Therefore there's still a need for bundlers and minifiers for JavaScript.
running webpack on our moderately sized javascript at work is incredibly slow. it breaks my mind, because it should take less than a second but takes \~1 minute
Hm, I am barely familiar with the inner workings of this stack, but shouldn't it be fixed on Mesa side, so it will pass pointer to client first and then client will pass it further down?
When there are lots of steps involved, like TS, SASS, ESX compilation, builds can easily take a few seconds or more, which gets annoying quickly. I'm not sure if the web dev world will adopt Rust code though, since it's a hard language to learn.
I do mention sum types and how they apply; the problem is sum types give equal importance to the component types, whereas in an expected type there's asymmetry: one is overt and the other is covert. So the API comes out different. (A sum type is of course the implementation device of choice.)
Stack traces in massive logs. That's probably the only time I ever want for multiline search
I was referring to your suggested syntax, which would require `type E` inside the `impl` block. I was under the impression that explicitness was supposed to resolve the ambiguity?
I feel like it's explictly good to have more roadmap than you actually achieve. It allows you to look ahead better. Otherwise the details to get punted until later. Having it on the roadmap means it gets seriously considerss even if it's not actually achieved.
&gt; Of coure cargo considers 0.x versions to be incompatible with each other which gives rust users a bit more flexibility Just to be clear, I think you've made a typo (or I'm not understanding you). Cargo differs from true semver in that it considers 0.x.y and 0.x.z to be _compatible_ with each other.
From what I understood the plan was (initially at least) to have a drop-in implementation for the relevant parts from std if building not with the nightly compiler.
Maybe that’s true and I missed it.
From the perspective of someone using the tool, it doesn't matter if they know the language that the tool is written in if the tool solves a problem they have. Whether or not the tool requires additional software dependencies could be a barrier, but fortunately Rust binaries are pretty easy to distribute.
Thanks. I guess I should have looked harder. It kind of felt like a festival and I think that's what made me ask.
This looks cool, but can we get some benchmarks against existing bundlers so that we can substantiate the claim of it being the fastes, and get a handle on the magnitude of the performance difference?
If you're doing SSL termination at the application, you're doing it wrong. I mean, its fine for hobbyist stuff, but put a load balancer in front of it. 
If you don't parse all the code, it could be pretty hard to accurately bundle it because a require could be inside of a function, but a require could also be a local variable inside of a function, and if you think this is an edge case, [this module I wrote](https://github.com/calvinmetcalf/derequire) only exists because dojo's bundler got it wrong. That being said, there are really 2 things that make bundling slow - traversing long dependency trees and then parsing a ton of files which could very much be sped up by this - having a ton of plugins and whatnot that all individually re-parse your code which would be difficult to fix because the plugins and transforms are a big part of what makes blunders good
That’s what I meant, this gives crate authors more flexibility to version in 0.x releases because cargo doesn’t consider 0.1 and 0.3 to be compatible unlike say npm. Which in turn means there’s less pressure to release 1.0s in rust. 
Do you know how big the ecosystem around webpack is? Of course the language matters. No build tool solves everyone's problems, that's why they're extensible. Although I'm not sure what the plans for this project are going forward, it could simply be used under the hood by webpack-like tools.
Executor is a trait, you have to implement it yourself if you don't want to use crates. Then you call spawn_obj on that type you implemented it for. Also, you have to call `run` by changing it to `run()`
I have honestly felt the same thing but in regards to irc. I don't use irc, so it seems like whatever you don't use people are making active discussion and changes. Because issues arent good for the type of discussion discord and irc are. But at least discord has search and logs.
Again, this is not "some bugs may exist" it is "there are long standing bugs, and we choose not to tell anyone about these, making it easier for people to run into them". First and foremost my issue is with communication of these issues.
Cool, glad to hear about std having advisories.
If you can't get guarantees, why call it a guarantee? 
Why would you need to learn a programming language in order to use a tool written in that language? Did you learn C++ to use nodeJS?
Because there's no such thing as the absolute guarantee. You can have an error in mathematical proof, but mathematics still guarantee that 2+2=4.
Yes, ~30s for a 100kLOC codebase.
Also know as the [PPYP pattern](http://cglab.ca/~abeinges/blah/everyone-poops/).
I understand how you feel. But, in practice, floating release dates with feature goals have issues : - What if one of your most wanted feature in the edition is hard, and takes forever to ship because you didn't realized how hard it was before it's too late. Should you wait more, hoping that it will eventually ship at some point ? Or should you drop it, even though it was the flagship feature of your edition ? Think about the aborted PHP 6 with Unicode support. - Even if the feature is not that hard. What happensif async/await isn't ready before spring 2019 ? Will your “Rust 2018” edition be released in mid-2019 ? Or do you rename it “Rust 2019”, ruining all the marketing you did in the previous months ? Or you name it Rust 201x in the first place (like C++0x) ? - What if, by the time you get async/await ready, you have another huge feature being almost ready (let say, const generics) that will only need a few weeks of maturation. Wouldn't it be cool to delay the release a few more weeks to be able to add the new cool feature to the new edition ? What if you do it, and by the time you get there, you have another gorgeous feature almost ready (macro 2.0 for instance), what do you do ? This kind of _quest for the perfect release_ has hurt a lot of software companies before.
Install plug-ins via your program 
&gt; This creates new problem (i.e. you cannot have two crates defining those, otherwise, you end up with the problem of [orphan instances](https://wiki.haskell.org/Orphan_instance) – you have the same problem if you try to implement a trait for a type you’re not the writer of. I'm having trouble understanding exactly what you mean. Could you construct an example in Rust that demonstrates this problem? If I do understand correctly, isn't it nice that when you see `x.sort()` knowing `x: std::vec::Vec` you don't have to go through all imports to see what traits having `fn sort(&amp;mut self)` are implemented for `std::vec::Vec`? &gt; I truly think some guidelines are hidden there, like “Do not put trait bounds on impl blocks”, but they were also designed for this (some people on IRC told me they enjoy them to gather methods for T: Clone, for instance. I truly think it’s a mistake because I personally don’t read the documentation like “Oh, let’s see what methods are available if T: Clone, but I can get the point of this argument. I never even realized you could put a trait bound on a function for type parameter declared in an impl block. Are you saying ... ```rust impl&lt;T&gt; [T] { fn sort(&amp;mut self) where T: Ord { // ... } } ``` ... should be preferred over ... ```rust impl&lt;T&gt; [T] where T: Ord { fn sort(&amp;mut self) { // ... } } ``` ... because the documentation looks nicer?
I don't believe that vks\_ was suggesting that there is no need for bundlers and minifiers for javascript, I certainly don't see how one could infer that from their question. Wouldn't it be just as likely that the question was in fact: "does you bundler support wasm"? As for what wasm is meant for, it's too early to tell, but the day I don't have to write a single line of JS, should it ever come, would be a happy one indeed.
The core API in std is unstable, and it's not agreed or known whether this version would stay the same. In fact, the RFC mentions several parts that would be expected to change once the language allows it. So, I **definitely** expect breaking changes between 0.3 and being stable.
Yes, this is a good distinction, sorry. I meant that futures will end up stabilizing first. You’re totally right that I misspoke here, thanks :) &lt;3
https://play.rust-lang.org/?gist=64948b551d024a89d88cdaee65371a05&amp;version=nightly&amp;mode=debug was written by /u/desiringmachines a bit ago, seems like it still works!
You are simultaneously telling me that a guarantee is impossible and that it is also ok to make guarantees?
One thing that has sped it up for us is passing this flag to Node --max-old-space-size=6144 Of course it uses more memory on your machine, but builds are much faster. Our project is massive, so we were forced to do something or have to split it up
I swear people are going to ignore the big unsound disclaimer and just create uninitialized contexts ;___;
Sure, everyone does it, I guarantee.
Yes, with bundling (basically module import/export rewriting) and doing es6 to es5 compilation and JSX compilation, takes about 30 seconds.
A lot of times, adding hacks to fix such issues would either be intractable or would take up a lot of scarce developer time that would otherwise be spent working on real solutions; e.g. Chalk, or NLL. I don't want us to get into a situation in which every soundness bug is "4-alarm fire, drop everything and fix it", or else we could be spending a lot of time chasing small short-term wins instead of making needed long-term changes.
Yeah we gotta get some good docs...
OK. I think that's bad and gives a false impression. I think that you can write Rust for years without realizing the extent of the soundness holes that exist. I think that the right thing to do is help people discover these issues so they know how to write code that avoids them.
thanks, I'll give it a try 
Is it OK for \*any\* implementation of a language to talk about guarantees?
I agree. All synchronous chat has that problem. Ideally, asynchronous options would always be used. It allows people to follow along even if they're busy when you are ready to write something (especially timezones differences!). And it makes the information archived and searchable, and changes can usually link directly to associated conversation.
Well, an alternative way would be to completely decouple Mesa from the windowing protocol. The client could create an headless context, do its rendering on it, and then manually export the buffers via the dmabuf wayland protocol to the server. This would work (if mesa exposes the necessary APIs, I don't know), but would add a significant amount of boilerplate. But in a typical graphics setup, the need for mesa is that it needs to be able to send messages to the wayland server too (it notably uses its own internal protocol extention to negociate capabilities with the server). To do that, it currently links to `libwayland-client.so` and requires the user to provide a few pointers to wayland objects. Not sure how it could be done in any other way, except by having mesa accept a large array of function pointers and use it instead of the functions from `libwayland-client.so`...
I agree that every soundness bug should not be made a priority above all other work. It is hard to answer the question "Is it ok that this one, particular soundness hole has existed since 1.0?" for a given issue. I think sometimes that answer is probably yes for very hard to fix bugs that probably have low impact (where "very hard" and "impact" are better defined). Is the answer ever no?
&gt; Do existing C compilers advertise that they guarantee standards compliance? I think you're reading too much into the word choice here. The reason why we say "guarantee" is that otherwise people don't understand what memory safety means. I've been in a lot of discussions like: A: "C++ is not memory safe." B: "But I've never had any memory safety problems in C++." A shows an example of non-memory safe code in C++. B: "I've never written that in my programs. How is C++ not memory-safe?" "Guarantee" is a more precise way to communicate the idea that it shouldn't matter what specific code you write, the language enforces memory safety. This makes the concept make sense to people who aren't used to it.
&gt;Should you wait more, hoping that it will eventually ship at some point ? Or should you drop it, even though it was the flagship feature of your edition ? &gt; &gt;What if you do it, and by the time you get there, you have another gorgeous feature almost ready (macro 2.0 for instance), what do you do ? It's up to the team discretion. It's tough decisions, but IMO it's better that corner yourself with fixed dates. &gt;Or you name it Rust 201x in the first place (like C++0x) ? This one. &gt;ruining all the marketing you did in the previous months And imagine this "great" marketing: "oh, we've released the glorious Rust 2018! Yeah, we know that we've promised futures, but they will be ready in 2-3 months for Rust 2018.2 release! Maybe in year you'll also get const generics for Rust 2018.3!". I think it defeats one of the main goals of editions to ship coherent snapshot of the language and loudly announce it as a single package, not as "wait a bit longer" early-access style letdown.
Not unless they're upholding them. But I don't interact with other language communities and I'm considerably more invested in rust - I also have a lot more faith in rust as a language to be better than others in these areas. But let's take a step back - yes, I believe that the word "guarantee" should not be used (instead, the list should probably just be "Goals" with "memory safety" in there, but this is more a 'nit' than anything else, and I think people are overfocusing on it. More importantly, knowledge of soundness issues should be better disseminated through the community. I have talked to rust developers who are unaware of soundness issues. They are not new developers. I have seen real rust code hit soundness issues (float -&gt; int cast). This is the problem I would like to solve. Bugs will always exist, we will find new ones in the future - making people aware of them so they can try to avoid them seems reasonable to me.
I understand. I believe that there are better ways to phrase it. As I mentioned in my other post, the "guarantee" bit is probably the least significant issue to me.
Yes, it is! Thanks for discovering it!
First, note that projects using older versions are not automatically affected. While this bug does *allow* one to write vulnerable code that should not be possible safe Rust, it's not necessarily the case that any applications contain such vulnerable code in practice. Of the published code that depends on smallvec, I don't think a single project even calls the `insert_many` method. (It's somewhat obscure because it's one of the few methods implemented for SmallVec but not for Vec.) Even if an program does call the method, it's only unsound if `Iterator::size_hint` and `Iterator::next` behave in specific ways. I don't think yanking would provide very much additional security. Applications built with the yanked versions would silently continue using them; yanking would primarily affect new applications, which would typically use the latest version anyway. Meanwhile, yanking (say) 0.4.4 without publishing a 0.4.5 would break the build for library crates still using that version, even if most or all are unaffected by the bug. This could cause a significant hassle with little or no benefit. That said, if someone wants to submit PRs to backport the fix to older versions, I'd be happy to publish patches to the 0.3/0.4/0.5 releases, and then yank the affected versions.
@ninjanano: Great work. You should submit your crate to https://github.com/rust-embedded/awesome-embedded-rust!
What about when you make outbound requests?
&gt; I don't believe that vks_ was suggesting that there is no need for bundlers and minifiers for javascript, I certainly don't see how one could infer that from their question I don't want to overanalyze something that really shouldn't be overanalyzed, but your interpretation makes a lot of sense if it's not a response to the comment it's a response to. What does "Does your bundler support wasm?" have anything to do with someone who is not part of the project suggesting minification is the bottleneck of Webpack right now?
I agree with you, but these tools tend to need community support. Webpack has over 400 contributors, presumably all of whom use it.
&gt; I get that the compile does optimisations given guarantees that stuff is not aliased, but surely this is on a local basis (i.e. can't I just say 'yeah there's gonna be some aliasing but only for this section of code)? Have I just misunderstood this? That's exactly what [`UnsafeCell`](https://doc.rust-lang.org/std/cell/struct.UnsafeCell.html) is for. It allows you to provide what is known as "interior mutability", in which you can have a value inside the `UnsafeCell`, and can have as many `&amp;` references to the `UnsafeCell` as you want, and you can extract a `*mut T` from it that you can cast to either an `&amp;T` or an `&amp;mut T`, as long as you follow the rule that if an `&amp;mut T` exists, there will never be any other live `&amp;T` or `&amp;mut T` references to the same value at the same time. This gives you aliasing and mutability; the `&amp;` references to the `UnsafeCell` (or struct containing an unsafe cell) are aliased. You can modify the value through them, or extract `&amp;` or `&amp;mut` references to the underlying value. But you're not allowed to extract an `&amp;mut` reference to the underlying value at the same time as any other references to the underlying value are live. The thing is, you shouldn't have to use `UnsafeCell` very often. Because it is tricky to reason about, and could cause UB if used incorrectly, it's better to use it in very small, well defined types that provide a safe abstraction over some unsafe pattern, in which there's a very small amount of code you have to reason about to make sure there isn't any UB. The standard library already provides a lot of such abstractions, and there are crates that provide more. Part of the point of the design of Rust and its standard libraries is that you should be able to do just about everything you need with the compiler built in reference system, along with some abstractions built in libraries, without having to write unsafe code except in very special circumstances. So you should first decide if you are in such very special circumstances, and see if there is a way to solve your problem without needing multiple live references to the same location, or if there's already an abstraction in the standard library or a third party crate that does what you need. To understand UB, it might be good to [read this post](https://blog.regehr.org/archives/213), which brings up a good analogy: &gt; Somebody once told me that in basketball you can’t hold the ball and run. I got a basketball and tried it and it worked just fine. He obviously didn’t understand basketball. UB is anything that's against "the rules of the game." Yes, it's physically possible to break the rules, and sometimes you will get away with it. But because those are the rules, those are what compiler developers depend on to determine what optimizations are OK, and what optimizations are not. The rules also determine what synchronization model is safe to use with multicore code; processors do most of their work from cache, not from RAM, but if you didn't have rules on what was UB, every write would have to require full synchronization between caches on all cores, defeating much of the value of the cache. In addition, optimizations don't even always need to be in play for invoking UB to cause problems. If you have an `&amp;` reference to a value live at the same time you have an `&amp;mut` reference, that makes it possible for you to make a programming error that could dereference memory that had been freed, such as an iterator invalidation issue; there's a [good blog post](https://manishearth.github.io/blog/2015/05/03/where-rust-really-shines/) on how Rust's aliasing rules make it so much easier to safely refactor code, because you be sure that you won't have iterator invalidation issues. So the rules that Rust imposes, to make it both impossible to make those kinds of refactoring errors (which become exponentially more likely as codebases get bigger), and to allow for optimizations and running on multi-core systems safely, are that you can never have an `&amp;mut` reference that aliases with an other reference, either `&amp;` or `&amp;mut`. This is the contract that is implied by `&amp;` and `&amp;mut`. However, to allow for implementing things like `Rc`, `Mutex`, and may `Vec` methods in the standard library, Rust gives you a way to tell it that you know what you are doing and disable any optimizations that rely on references not aliasing, by using `unsafe` and `UnsafeCell`. Because this requires following rules that the compiler can't check for you, it has to be done in an `unsafe` block. Ad if your question is "why can't the compiler check these rules if I'm just doing this in one local section of code," the compiler uses a fairly simple uniform model for checking safety which allows it to use only local reasoning; anything else would be intractible, and possibly undecidable. Even if you know that there's only this one section of code in which there are aliasing `&amp;` and `&amp;mut` references, the compiler does't know that; if one of them were passed in from somewhere, or they are passed in to other functions, then local reasoning no longer applies. So the reasoning applies consistently everywhere; there is a simple rule, that you can't have aliased `&amp;mut` references, the compiler is able to depend on this for optimizations, the compiler checks this so you can't shoot yourself in the foot like you could in C or C++, the compiler provides an opt-out in the form of `UnsafeCell` which allows you to have multiple references and mutate through them using just `&amp;` but you have to use an unsafe block and uphold the invariants the compiler expects yourself in those blocks.
I'm concerned about the real-life usefulness of this. Webpack isn't just good because it bundles. One of the best things about Webpack is how extensible it is. This appears to offer almost no configuration options. Stuff like custom resolvers and middleware are core to the usefulness of Webpack. I'd be willing to bet a bundler with this small featureset written in JS wouldn't be that much slower, as the primary cost is file reading/watching and string concatenation.
As someone who is bad at Photoshop and who once tried to make their own version of the BTTF logo: I appreciate what went into that, but am slightly disappointed that it's not perfect.
[removed]
// NOTE: THIS IS VERY BAD, completely unsound behavior, don't do this! Can I get an example that... doesn't do this?
Does it mean async/await can't be stabilized until the next edition ? I remember reading that the `async` and `await` keywords were reserved for Rust 2018 already, but I'm not sure what the stabilization process will look like.
I am very confused by the way editions work at the moment. Does the edition include everything *prior* to its release or everything *after* its release up until the next edition?
You're looking for an example of an executor and a waker. The existing ones are complex (because making good ones is complex)! You could look in LocalPool in the futures crate. If you just wanted to compile something, then you could make a type that implements Wake by just panicking when wake is called, and then don't call wake in your example.
The Rust compiler will support whatever map size you want to use? Oh, you weren't interested in the Rust programming language? Try r/playrust
Visit /r/playrust - you're on a subreddit about a programming language
+1. Generalizing slightly: cases where you want to find matching entries, not search for a match that might span half the file. The divider between entries is not simply `\n`. I think ideally the searcher would know how to correctly divide the file into entries (paragraphs, whatever). It might have to be a program specific to that format that uses libripgrep. The second best thing would be to restrict the multiline match to being no more than X bytes or Y lines long. That's what you're approximating with the `rg thing1 -A 10 -B 10 | rg thing2 -A 10 -B 10`.
I think they will add features to the edition, but it just won't be in the initial release.
As the post forgets to mention it: there were a couple of community members involved in the final days of the build, especially making the background builds services run well and putting finishing touches on many things.
Link failures are fine. The only danger is if you **don't** get link failures. As long as you do everything is sound -- you never get a binary with two different definitions of the same function. It's up to people who are defining things via external resources at compile time to make sure that the same answer is consistently arrived at. If they fail to do that they get an error. If they succeed in doing it great, they get the functionality they wanted.
At the time that fun with a specific instantiation makes it into the binary at link time you enforce that all other definitions that show up are the same. This is exactly how it works in C plus plus with templates, because of everything being based on include files and not having a module system -- many different translation units can define the same function or the same function template -- but there can only ever be one version of a function at link time, so modern linker is giving an error if there are multiple definitions that are not identical. And once a function template is monomorphized it is a function and the same rules apply.
Editions are part being able to change some syntax rules, and part marketing. Many things coming in the edition we actually already have in recent stable releases, but being able to announce something big every couple years is healthy for a project. Async/await have been reserved, such that in 2018 edition, code won't be broken when they stabilize. Not stabilizing for the edition is mostly just a marketing bummer, but doesn't mean we can't have it a few months later.
I'm just an observer, but the impression I've been getting is that there will be Rust 2018 "breaking" syntax-level changes, and that can only be done once. Aside from that, all sorts of new functionality can be added under the 2018 umbrella over time, in the same sense that everything added to Rust since 1.0 is part of the 2015 edition. There isn't a 2015.1 edition currently, so I wouldn't imagine there'd need to be a 2018.1 edition either. I'm not sure if this understanding is correct, though... I follow along but don't actually use Rust.
That will let me invoke whatever external code generator I want, but external code generators won't be as tightly integrated that's just allowing me to write compile time executed functions next to my regular code.
Pretty much both. Editions include everything that comes out until the next edition (and even then they may get features even afterwards if they are compatible with that edition. So most things will work in Rust 2015). But marketing wise the features will be announced as part of the next edition. So async await will be announced as part of Rust 2020 / 2021 (or whatever it will be).
&gt; Rust 2018.2 release! There will never be a point release in editions, that's not how it works. There will be subsequent Rust releases 1.29, 1.30, 1.50, etc. and both Rust 2015 and Rust 2018 Editions will be usable in those. AFAIK , there have never been a C++11.2 …
I believe 0.2 is dead, and 0.3 on stable won't happen as soon as initially proposed. Basically the options are use 0.1 to ship things, try out 0.3 to help work out kinks while enduring instability of nightly.
I don't believe so, so this behavior means that the whole process will be killed if a single file hits such an error. But I don't think you'll hit the SIGBUS case unless the file disappears for one of these reasons after it has been opened and mmaped; I think you'd get an I/O error when trying to open the file for read if it was already offline. For a command line tool, that behavior is generally OK; you can just run it again in the fairly unlikely case that this happens.
Is it *only* marketing? I thought there was going to be some commitment to long term support in terms of serious bug/security issues.
I believe the LTS RFC was postponed.
I was speaking about Rust 2018.2 in a marketing contexts, not a technical one. Not shipping important long-awaited features as part of the big package will makes edition release significantly less impactful. It's like "here early-access Rust 2018, but you'll have to wait for updates to experience Rust 2018 fully".
Pretty sure it won't. Especially if arbitrary self types are still needed.
Not quite, unfortunately (for me), two motivations were mixed to editions mechanism: - technical: to allow limited "breaking" changes while keeping backward compatibility for crates which haven't migrated - marketing: to provide coherent language snapshots and widely announce them, according to the team members should help with Rust promotion Plea not to mix both those motivations into editions was quite noticeable in the editions RFC discussion, but to no avail.
I took the question to be: What about using existing tooling, but using a Web assemby implementation of the javascript minification process. Admittedly, that's probaby a poor interpretation. It is a pretty ambiguous question. 
I read it as, "the Rust 2018 release is the end of new features being added to 2015." So Rust 2015 will never have async/await if not ready in time.
It's not only about async/await, topic is somewhat bigger, see this internals [thread](https://internals.rust-lang.org/t/concerned-about-rust-2018-stability/7932) for example.
It's a suboptimal example, you can move the type from the signature to the body then it becomes much harder to check. And even if you can check it (which I think is plausible with enough engineering work) it's still *incoherent*, as explained in https://internals.rust-lang.org/t/mir-constant-evaluation/3143/47?u=eddyb I don't have any links on hand but it's equivalent to Haskell orphan/overlapping instances (Rust impls) and Rust has a much stronger check than Haskell's default (AFAIK), called "trait coherence", to *completely rule out* anything like link-time errors.
Is there any chance we can make aliasing &amp;muts defined in small sections of code in the future, or is this just something that would be impossible to do? I don't understand how the compiler checks this stuff / what this noalias stuff is in LLVM enough to reason about this
&gt; Meanwhile, yanking (say) 0.4.4 without publishing a 0.4.5 would break the build for library crates I don't understand that. Wasn't the point of yanking that everyone who's already using the old version can keep on doing so, but adding it as a new dependency won't work? Which is basically what you're saying at first: &gt;Applications built with the yanked versions would silently continue using them; yanking would primarily affect new applications, which would typically use the latest version anyway. just that new applications would get a prett "hard" nudge towards the new version (think c&amp;p imho). So if I understood correctly, the hassle wouldn't be there. Of course, backports would be nice, but are orthogonal to yanking affected versions, right?
&gt; Wasn't the point of yanking that everyone who's already using the old version can keep on doing so, but adding it as a new dependency won't work? Anyone with the yanked version in their Cargo.lock can keep using it. But if the Cargo.lock isn't present (which is the case for fresh checkouts of most library crates) and all compatible versions are yanked, the project won't build. This would break things like CI builds for library crates using old versions of smallvec, or newly-created applications that use those library crates. It wouldn't affect existing local checkouts of the library crates, or existing applications that include a Cargo.lock with their source.
Mods come in waves. Don't take it personally. I believe moderation to be fair on average.
If you want to reply to this comment, please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
If you want to reply to this comment, please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
If what you say is correct, then it's safe to say that all contributors are users, not the opposite, so it shouldn't stop JS devs to use this tool freely, without contributing
For that particular purpose, try xmlstarlet, which lets you do XPATH queries on XML.
Rust 2018 won't be «full» until the eve of the release of Rust 2021 though. Think how much was «missing» in Rust 1.0 if you compare to what we have now. Async/await is a cool feature, which may be a blocker for you to use Rust professionally, but it's not everybody's case: for instance, as far as I'm concerned, I'd rather have const generics ready ASAP, and newcomers probably care more about NLL or the `dyn` keyword for trait objects. Having a Rust 2018 edition is a good way to market how much progress have been made since Rust 1.0, and it remains true even if **_insert your favorite feature here_** is missing in the announcement. Delaying such milestone because one specific feature reveals itself hard to implement would be a bad signal sent to the world IMHO.
There is a very big complexity difference, however, between: 1. Writing a `build.rs` which reads `~/.ssh/id_rsa` and sends the content to a server (or even pastebin), which is **trivial**, 2. Exploiting a zero-day in a compiler/linker to achieve the same. A paramount mantra of security is **defense in depth**; blocking all trivial attacks to raise the bar for exploits is definitely worth it. --- As for sandboxing, it brings considerable hassles: 1. `cargo build`, by default, attempts to connect to the Internet to check if new versions of dependencies are available, and download them, 2. `cargo publish` will use keys to publish crates. Therefore, executing `cargo` in its default mode requires access to keys and access to Internet; using a sandbox to circumvent the `build.rs` issue means shunning all that. It's probably worth for larger organizations, but for an individual it's not very appealing.
Yeah, I'm not saying people are less likely to use it because it's written in Rust. I'm saying people are less likely to contribute to it, as the users are all JS devs (who may also write Rust, but they're less likely to be proficient). Fewer contributors generally = worse product generally = fewer users. To get the most contribution, it just needs to be written in JS. The counterargument might be if the bundler came with Rust -&gt; wasm generation (which it appears it does not) so a bundler that supports browser-side Rust might be written for and by Rust programmers.
If you want to reply to this comment, please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
If you want to reply to this comment, please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
Congratulations! Do you have any expectations for the time that will be needed for futures 0.3 to be integrated with other projects like Tokio? I'd love to experiment with this. 
&gt; Procedural macros Indeed; they should probably be vetted too. &gt; Reproducing Builds vs Adaptability I would argue that you are attacking a strawman. The point of reproducing builds is NOT to prevent you from pulling in external data and merging it into your build; it's to ensure that whatever gets pulled in the build is known so that rebuilding the same application is possible. It's useful for verifying builds sanity, as well as for debugging. There's no issue with reading from data-base, recompiling assets or shaders. Just ensure that whatever gets pulled in is committed (either in source form or already transformed). &gt; Compile-time I/O already 1. Binaries have a Lock file, versions of dependencies do not shift unexpectedly, 2. The Rust `std` library is fetched once, when updating `rustc`, and never changes until the next upgrade. So... there's not much shifting. Not really. &gt; Auditing Trust has to start somewhere. By default, I would tend to trust official libraries (`libstd`, `liballoc` and `libcore`, thus), placing my trust in the vigilance of the community maintaining it. It may be misplaced, but the bar between placing an exploit in `libstd` is **much** higher than that of placing one in a `build.rs` for a crate you maintain. As a result, there's a **very** small subset of things to manually audit as a user: - a handful of `build.rs`, - a handful of procedural macros. You don't even need to understand them perfectly. If they don't use `unsafe`, don't bind directly to `C` and don't use Rust I/O facilities... then they don't do I/O, no matter what else they do. So they may overheat your computer or hang the compiler, but they should not steal your data... at least, not *easily*. &gt; We could probably add those lints for build.rs scripts as well and procedural macros. But then the subset of the ecosystem that you can actually use would shrink significantly. I like the idea of having lints; however I wonder if it'd be possible to have an *endorsement* system, to crowd-source the verification. It'd be useful for crates in general, not just `build.rs` and procedural macros; imagine instructing cargo: 1. Only download new versions if endorsement &gt; 90% approval rate, 2. Only download new versions of crate containing `build.rs` or procedural macros if endorsed by 3 out of &lt;insert list of trusted security experts here&gt;. It would be more powerful that whitelisting; certainly. **Perfect is the enemy of Good**, however, so I'd argue for a stop-gap measure today (white-listing), while we wait for a better solution.
&gt; That said. This seems sort of on the paranoid end of security considerations. Just a week or so ago there was an uproar on the NPM community because a popular NPM module had been subverted to exfiltrate NPM keys. You'd build your code, as usual, and in the background the `npm` utility would download the new version of this module, which would exfiltrate your NPM keys and publish them on 3rd party server. This is not paranoia for the sake of paranoia; just learning from (recent) history.
Sorry, but security is a distraction from typesystem soundness. `include_str!` (not to mention custom proc macros) is not much better than `const fn`. Please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
&gt; WebAssembly is not meant to be a full replacement for all JavaScript out there. Not _yet._ There is only IO missing.
My point is just that attacking the build machine seems small potatoes compared to attacking a production server or an end-user.
This is starting to be fatiguing. I used to look forward to the minor releases of Rust, because they'd rarely need to release a patch and actually have meaningful things come down the pipeline. Now though the patches are either small changes (which are welcome, but boring and should maybe be held off to reduce churn) or changes that are big and cause problems because they should have been done correctly (it was mentioned here and else where that this feature maybe should have been done with the borrowchecker rewrite for NLL). Has the Rust team been considering changing their release schedule? 6 weeks is nice and consistent, but if the slew of features that need to be implemented don't fit within that timeframe it would be better to hold off. Churn for the sake of churn makes me feel like the language is less stable, especially with all these point releases
No. Let's take a look at your example: // Update entities that collide. for (e0, pos0, coll0) in (&amp;*entities_s, &amp;pos_s, &amp;coll0_s).join() { for (e1, pos1, coll1) in (&amp;*entities_s, &amp;pos_s, &amp;coll1_s).join() { // Make sure we don't check for collisions with ourself if e1 == e0 { continue; } // Find the vector we need to push ourselves in to resolve the collision let res = coll0.resolve(coll1, pos0.to_vec(), pos1.to_vec()); // Some bullshit transmuting to mutate pos. This is *probably* // fine because in this function we have a mut ref, and we're // just holding non-mut refs to some values? unsafe { // Get a mut ref then resolve the collision let pos0_ptr : *mut Pos = mem::transmute(pos0); (*pos0_ptr).x += res.x; (*pos0_ptr).y += res.y; } } } You are iterating over `&amp;` references that were passed in to your function. As far as Rust is concerned, there could be other references to these objects being stored elsewhere; being accessed in another thread, stored in globals, stored in one of the other objects you have references to. And so other code that is interleaved with this code could also be reading from those `&amp;` references. It could be happening in another thread, it could be that whatever is calling this function is expecting these values to be stable, it could be the case that some function like `coll0.resolve(...)` is reading from these. So you can see that there isn't a local analysis that could tell you that this code is correct. In fact, in this case using `specs`, there really could be other threads reading from these values. `specs` [explicitly allows `Dispatcher` to run multiple systems in parallel](https://slide-rs.github.io/specs/03_dispatcher.html); it can tell what is safe to run in parallel and what is not safe based on whether it needs read-only or mutable access to different components. So if there really is another system accessing the same component at the same time, Rust not allowing you to transmute `&amp;` to `&amp;mut` has just saved you from shooting yourself in the foot by having one thread write to values while another is reading from them.
Something which is still unclear to me, is whether the bugs are only discovered now, or if they are due to the introduction of match ergonomics. 
&gt; My point is just that attacking the build machine seems small potatoes compared to attacking a production server or an end-user. Yes... and no. Exfiltrating the `cargo` credentials means that you can now publish updates of any of the crates the author has access to. The viral behavior of replicating the exploit to gather credentials is not that useful in itself; once you have the credentials, however, you can publish updates on any crate of your choice and *then* have code run on production servers. This is trojan-horse attack, in essence. Imagine: 1. Check out burntsushi's week-end projects, 2. Publish a crate to help solve one of the problems he's complaining about, 3. Do a PR on his week-end project which uses your new crate to solve the problem, 4. Wait until integrated, 5. Publish an update to your crate, which can steal credentials, 6. Wait until burntsushi rebuilds his week-end project =&gt; **credentials in**, 7. Publish a minor update to the `regex` crate, or maybe to `ripgrep` (now distributed in VS code), which includes code that steal CC numbers or install bitcoin miners in the background, 8. Profit. Exploiting `build.rs` or a procedural macro is about getting your foot in on a popular crate's author's machine. Your PR on `regex` or `ripgrep` would never be integrated otherwise, severely limited your target audience.
The keywords are still reserved, just not implemented, i.e. using the keywords will prevent successful builds as though it were implemented.
i sysadmin a Mastodon instance. mastodon is a large Rails + React app, with a metric fucktonne of frontend code bundled with webpack. running webpack is _the_ limiting factor during instance upgrades. it's not unusual for it to take ~10min on a decent server + eat up ~3-4GiB RSS.
Sorry, but security is a distraction from typesystem soundness. `include_str!` (not to mention custom proc macros) is not much better than `const fn`. Please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
Sorry, but security is a distraction from typesystem soundness. `include_str!` (not to mention custom proc macros) is not much better than `const fn`. Please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
Avoiding link errors (and avoiding to check everything at link-time either) is pretty much the only reason Rust has trait coherence checks (disallowing orphan and overlapping impls). Please also refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/
Except its future plans, I also concern about its *reliability* without enough testing. Maybe I can have a test in my project which is using google closure compiler now :)
Please refer to https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2pdqnt/ instead
I agree that security is unrelated to type-system soundness, however I still think it warrants consideration. I hadn't intended to hijack the thread :/ I also disagree that arbitrary reads are OK in the absence of writes at compile-time. It *may* be OK for `const fn` (unclear to me), however code-generators such as `build.rs` do write (source code) and therefore have a ready medium to exfiltrate data: read at compile-time, embed in binary, publish at run-time.
I guess! What a weird vector for spearfishing though!
The 6 week release cycle is supposed to prevent this sort of rushing to ship; the idea being that if the thing isn't ready it's never more than another 6 weeks to the next release. I agree with your points, and I'm hoping a core team member can comment on why this doesn't appear to be working lately.
AFAIK: Both. They are due to the introduction of match ergonomics which do not play well with the current implementation of the borrow checker, and have only been discovered now-ish.
I don't think this has anything to do with the 6 weeks schedule. On the contrary the purpose of the 6 weeks schedule is to *avoid rushing*: it doesn't matter if you miss the cut-off for the release, the next one is only 6 weeks later, so you can take your time and ensure proper testing/validation. The issue with match ergonomics may be due, in part, to the incoming Rust 2018 edition. This one does imposes a tight deadline, and there is pressure in having the nice features ready for it, which may have contributed to early stabilization. On the other hand, one could also argue that the issue is one of lack of testing. I personally feel somewhat responsible here since I haven't use a nightly/beta compiler in *ages*, I may not be the only one.
Ok. Offhand, it seems like 80% (90%?) of the benefit is from 1 in terms of reading some file with "configuration" values for a bunch of types so you can populate said configuration in some simple mechanical way (as opposed to generating a Rust source file to get const's). The sort of thing I'm thinking of is building a parameter tuned version of a program and testing dozens/hundreds of versions. Or maybe building some hardcoded version of a binary that can only run in a given security context. Is that the wrong intuition?
How long does Kessel run takes ?
&gt; Instead, crates.io should pull that database and alert maintainers of crates that depend on a vulnerable version automatically. Alas, this is not being done. Alerting the end-user would be better, I think, seeing as a library author has little say on which version of a dependency is used (beyond specifying a minimum). On the other hand, in the case of *distributions*, their maintainers should certainly be alerted. I'd expect the current CVE process to cover that though.
I'd distinguish between Rust the language and `rustc` the implementation, though. The website says that the language should have no soundness issue, and I think that even if it does it is certainly very close to NOT having any. Implementations, however, nearly always have bugs. Except maybe CompCert.
This has been done now.
FWIW if you just want to read a config file into a `&amp;'static str`, *just* use `include_str!`. *Unless* you mean the `read(Self::PATH)` example, but you could just do something with macros. &gt; The sort of thing I'm thinking of is building a parameter tuned version of a program and testing dozens/hundreds of versions. I'm not sure I understand. "thinking of" in terms of what? As a usecase for constants computed from "input side-effects" (like reading a file)? Do you mean having a lot of tunable constants that are read from files or env vars? Because you can use `include_str!` for files and `env!` for env vars, in that case. All you're missing is `.parse::&lt;i32&gt;()` or something being made a `const fn` so you're not stuck with a `&amp;'static mut`.
`include_str!` and proc macros exist, you didn't have to bring up build scripts. `const fn read` would like proc macros but less dangerous because the compiler *starts* with a sandbox, whereas with proc macros (and build scripts, of course, but proc macros are closer to `const fn`) you need to *introduce* a sandbox *to even hear about* what that code is doing.
PLEASE. Especially after the (small amount of) drama that happened with [`alacritty`](https://github.com/jwilm/alacritty/issues/289)'s claim to be the fastest terminal emulator, it'd be great if one could lead their marketing with at least cursory benchmarks. We're not ALWAYS going to avoid things like users on HN looking for ways to criticize whatever gets noticed, but we can at least do a defensible amount of homework before making claims of superiority!
&gt; **UPDATE:** I have published versions 0.3.4, 0.4.5, and 0.5.1 with the fix backported, and yanked all versions affected by the soundness bug. **Thank you for caring** I know it's dull and unrewarding work, so I am grateful that you cared enough to power through it :) 
Why is it that rust projects (using cargo) don't specify a specific version of Rust that they compile with i.e. rust_version = "1.27.2" Coming from scala, every project specifies exactly which version they're compiling with, but Rust projects seem to only very granularly specify between editions and nightly/stable. What are you supposed to do if you have multiple projects you work with, which compile with different versions of rust? Is the idea that Rust is supposed to be so backwards compatible that there's no point to compiling with an older version? 
Thanks, do you know what's currently being worked on? I assume NLL should have a major impact on how the borrow checker works.
Note: mbrubeck has backported the patch, released a new version, and yanked the affected crates.
That's how C++0x became C++11. It was originally planned for 2008, maybe 2009, but as features did not come in time it was pushed back again and again until it had slipped the date by 2/3 years. Users awaiting features that were already ready in 2008 were, understandably, not very happy about it. They largely would have preferred a C++08 version with those features. Which is why for C++1y a new direction was taken which emphasized shipping whatever is ready every 3 years, so that C++1y became C++14 and C++1z became C++17. The next standard is scheduled to be C++20, and despite early enthusiasm that it would be **the** standard with modules, and coroutines, and concepts (2 of which were originally scheduled for C++0x...), it's already acknowledged that not all will make the cut-off. So, taking a page from C++, would you really wait 15 years (2023 - 2008) for a "scheduled" feature? Or would you rather get some of the goodies *now*? I'm firmly in the latter camp :D
&gt; should maybe be held off to reduce churn Please no. It takes us one line of bash to upgrade. You can still skip it if you want to stay on older version for some reason. 
No, I have write access to the data, I just need 2 pointers to that data simultaneously - I know that I have the only access to the data in this system at this point, I imagine specs uses a Mutex somewhere along the line. The issue people are bringing up is the noalias stuff in LLVM which has to do with whether the CPU can avoid extra reads due to dirty caches I think, normally this is a performance improvement, it just means you can't alias pointers. I was asking whether we could switch that off locally whilst I have the only access to the data, I don't really understand how it works.
I find your feedback interesting since one issue raised with large numbers of comments on RFCs was that it became daunting to participate in the RFC process, and hard to fathom the state of the RFC in the absence of summary. I am not sure, myself, where discussions should take place. I'm not sure there's an ideal format, though personally I'd expect Discord to cater more to near-synchronous discussions (to hash out an idea) and git comments to more asynchronous ones (with care being taken to formulate high-quality/well thought-out comments). That being said, regardless of where discussions take place, I do wish that the RFC/PR would be updated to reflect the current state, and how we got there. An important part of design work is documenting which approaches didn't pan out, *and why*, after all, and this information needs to be captured for future maintainers.
I don't see what's wrong with having link time errors. C++ has them so pretty much every linker used in practice must detect conflicting definitions of symbols nowadays. It may be desirable to do this anyway just to guard against accidental nondeterminism in the compiler, bad RAM causing bit flips when compiling different translation units, or inadvertent compile time behavior changes in the compiler across versions when you're mixing translation units from different versions.
I don't think anyone actually is rushing features for the record (this is the only one where maybe it is), and I think the actual issue this patch fixes is rather minor (how impactful was this bug really?). I'm mostly complaining about how often releases are from a package maintainer's perspective. Most crates seen to target the latest stable, which not all distros can support. If you couple that constant churn with the recent patch versions, it seems like Rust still isn't ready from an outsiders perspective. You can explain _why_ the patches are more numerous (old borrow checker, awkward timing with Rust 2018) but most don't care to investigate that much. Especially because these problems aren't technical at all, they are perceived problems of the process. Maybe Rust 2018 will ameliorate these issues. I will wait and see. I don't think the guarantees it promises are strong enough for that though. A standard sounds like a better solution (but that is a whole other argument) 
I think it's good to have *stretch* goals, however it's bad to have *farfetched* goals. For setting the direction, a vision is sufficient, it's not necessary to set known unachievable goals.
I would expect it, even if it is not intended. This is what 0.x means, after all: in terms of SemVer, any move from 0.x to 0.y is a major change (equivalent to a move from x.a to y.b when x &gt; 0). If you wish to avoid further breaking changes, you'd have to wait for 1.0.
&gt; one line of bash And a total recompile of all your crates and binaries because there's no stable ABI. I'm looking at this from a distro maintainers standpoint. Debian cannot keep up with this level of changes. You can argue that "oh they'll just target older versions". But most crates either: * don't have an official lowest version they support, meaning the latest is your best bet (I'm guilty of this) * require nightly (a no go) * actually have a process in place for this (AFAIK only burntsushi's crates do) So that means most Rust programs cannot be packaged in slower release models. 
I would note that one of the trick to being fastest might well be `--watch`. If the bundler starts immediately upon the file being changed, it has quite the headstart on a bundler which waits for a human to prompt it ;)
&gt; Is it only marketing? No. `async` is a keyword in 2018 but not in 2015, for example.
&gt;This means that traits are surjective. I think you really mean that traits aren't injective. You're obviously interested more about the case of &gt; 1 mappings onto an element rather than &gt;= 1 mappings (which surjectivity gives you). And it's kinda meaningless to call something surjective without naming a codomain.
You can make that distinction but it is \*unclear\* for someone new to the language that it is being made. \*Regardless\* of wording, the fact remains that soundness bugs exist and they have low visibility/ discoverability. It is my opinion that discoverability and visibility should be raised, that expectations should be clarified, and that by improving in these areas developers will be less likely to run into soundness holes, to the benefit of the community.
&gt; but have all the recent point releases been a result of the aging borrow checker? Yes. I wrote a comment last time here: https://www.reddit.com/r/rust/comments/8ygygg/patch_testing_for_1272_announcements/e2bot6q/
It is indeed NLL, and more specifically the fact that borrow-checking is moving from the current borrow checker (operating on HIR) to the new MIR borrow checker (operating on MIR). It is expected to be simpler to work on MIR than HIR, which should in turn lower the chances of such bugs slipping in (though I expect that bugs will slip in, they always do). In turn, the MIR borrow checker will enable NLL.
IIUC, Pax doesn't do any compiling steps, which are usually much slower than parsing and concatenating. That's why I'm asking for benchmarks.
`env!` and `include_str!` and *every proc macro invocation ever* are expanded *before* the typesystem, therefore they're like 5. in my list but even simpler because you never type-check or interpret the invocation, it's expanded away before it has a chance to touch the type-system. `fn foo() -&gt; &amp;'static str { include_str!("foo.data") }` has *very different* semantics from a version which used `std::fs::read_to_string` - the `include_str!` is expanded once *into the source of `foo`*, but the in-language IO from `std::fs` *has to* happen on every call to `foo`.
Webpack does a whole bunch of things. IIUC, Pax seems do only do module resolution and bundling. So I'm still very unsure how much of them 10min you could actually trim. (But please report back if you have tried it!)
http://play.rust-lang.org/?gist=970d3788031f4f1e49d5f3fe9e8a6969&amp;version=nightly&amp;mode=debug&amp;edition=2015
Aren't patch releases for compilers fairly typical? I don't see why it would be fatiguing. I'd be fine having more patch releases if it meant serious bugs get patched sooner.
&gt; A standard sounds like a better solution (but that is a whole other argument) I have worked daily with C++ for the past 11 years^1 . It seems harder to have a more standard Standard than C or C++: it's an ISO Standard! And yet, C and C++ compilers have bugs. The company I currently work at couldn't use gcc 7.0, 7.1 or 7.2 because they did not manage to compile our successfully. We finally manage to upgrade to gcc 7.3 when it came out, and yet not a month ago I ran into [this codegen bug](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=86314) which silently miscompiles `atomic_fetch_or`; the bug was stamped out immediately, and will come out in gcc 7.4... at some point (I'm not clear on gcc's point releases schedule, to be honest). So: - I don't see how a Standard helps with patch releases, - If codebases as mature as gcc still have bugs, I don't reasonably expects other open source compilers not to. As for package maintainers, I am not sure I understand the issue: - they are certainly not obliged to upgrade to new minor releases, and when they do, I hope for their sake that the process is automated as much as possible, - isn't it better to have a patch release which fixes a known issue, rather than a known issue which remains unfixed? ^1 *Crap, time flies!*
Debian's bundled Rust is used to build the Rust programs that come with Debian; they're not intended to be for general development.
Constant version bumps for compilers are fine. Constant version bumps for languages are less fine. But this gets into the standardization argument. 
&gt; C++ has them so pretty much every linker used in practice must detect conflicting definitions of symbols nowadays. What exactly do you mean by "conflicting definitions"? Just the signature? That's the least of our worries (although it is one way to weaponize the problem). (for more information relevant to Rust please refer to "link-time errors" in Haskell &amp; the ML family, rather than C++) By "link-time error" we also refer to a Rust crate "linking" against another, or more accurately using another crate as a dependency. In my example, the error arises where trying to compile `d` causes the compiler to load dependencies `b` and `c` and a mismatch would be detected between *something in the history of everything that happened* when compiling `b` vs `c`. Even if it may be possible to nail it down perfectly, imagine having to check *every single type/trait query ever executed, no matter how small*, between *each pair* of dependencies *of each crate you ever compile*. You could optimize it a bit, by doing taint tracking instead, but if you don't do that *perfectly*, you're *instantly screwed* (unsoundness aka typesystem UB).
&gt; It is my opinion that discoverability and visibility should be raised, that expectations should be clarified, and that by improving in these areas developers will be less likely to run into soundness holes, to the benefit of the community. I fully agree with that.
&gt; This is also entirely unrelated to the fact that you can codegen based on network requests -- that's external to the compiler and just producing source code, so all the usual mechanisms (e.g., the type system) apply to make sure that everything fits together. Hmm… I claim this is a bit of an example of looking at the world through "compiler-colored glasses", in the sense of Raymond Chen's ["kernel-colored glasses"](https://blogs.msdn.microsoft.com/oldnewthing/20110512-00/?p=10683). Suppose that, as part of my build process, I try to access a network source which returns nondeterministic results – as a relatively plausible example, perhaps I spawn `git clone https://github.com/foo/bar` (using the latest master rather than any specific revision) and then load data from within the cloned repository. Compare two scenarios: 1. I do this within `build.rs` or a compiler plugin. No problem for the compiler, but if I run an incremental `cargo build`, it won't redo the git clone, so I can get a stale output – forcing me to run `cargo clean` to get a correct output. 2. I do this within some CTFE code. a. Chances are, I'll design the code in a way that doesn't fit the 'diamond' dependency pattern that you and eddyb mentioned: after all, fetching the same data over the network multiple times during the build process is slow, creating a strong motivation to avoid it even without coherence issues. If so, the result will be the same as 1: compiler doesn't complain, but stale output. b. However, if the code *does* happen to fit that pattern, then the compiler will (hopefully) detect the incoherence when compiling `D`, and produce an error. The cure is the same as in the other cases: running `cargo clean`. From the compiler's perspective, only 2b causes any problem. But from my perspective as a code author, stale outputs are already a problem, violating the precept that incremental builds should produce the same result as building from scratch. They can obviously produce unexpected behavior at runtime – and they can also mask any build failures that only occur with newer data than what I have cached. (So someone who downloads my source code won't be able to build the program, and if I run `cargo clean` myself to try to diagnose their issue, suddenly I won't be able to build it either, with no way to go back! :) Thus, getting a stale output is often just as bad as getting an error; in fact, it's usually *worse*, since it's a silent failure rather than a noisy failure. So, as I said, the immediate cure for stale outputs and link failures is the same, `cargo clean`. The proper fix is also the same: I need to restructure my code to avoid nondeterminism in the build process. In my scenario, the easiest fix would be to explicitly name a Git revision. For other scenarios where the data is coming from a local file or environment variable, the fix should instead be to mark the file or variable as a build dependency of A, so Cargo knows to rebuild everything if it changes. Thus, I think that even though the two issues look very different from the compiler's perspective, they should be considered closely related, and treated as essentially equally bad. From that perspective, since nondeterminism is allowed in `build.rs`, there's no reason it couldn't be allowed in CTFE, too. However… If there's not enough *benefit* from allowing nondeterminism in CTFE, then I suppose it would make sense to ban it, even accepting my assessment above. In CTFE as currently designed, that may be the case. Personally, I've long dreamed that Rust will someday remove rigid boundaries between compilation phases. For example, I'd love to be able to have a compiler plugin that inspects type information (requiring the compiler to parse and typecheck the bits of code I'm looking at), and then emits arbitrary new code based on that. D and Nim are two examples of languages that already have support for something like this, and it's been [proposed for C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0633r0.pdf). Supporting that in Rust would make it totally impossible to enforce determinism in CTFE or the type system, beyond 'best effort'. However, I think it would have so many benefits, enabling so many use cases for compiler plugins that today are either impossible or possible in a hacky, half-broken way, that we should enthusiastically bite that bullet. But I suppose that even if you agree with me, any restrictions on CTFE could always be lifted in the future; there's no real need to consider that now. It's just that it affects my view of how important purity is as a goal.
&gt; Debian cannot keep up with this level of changes. It's been less than one point release on average. They have to do it for security upgrades anyway. If they don't have infrastructure I'd rather see they admit that and not support it than Rust having to steer from the most optimal path. Debian is big target but it is flawed (start with nix) so why should rust suffer for their problems? Where does it end, should rust bend backwards and be like Java with meaningful changes every 10 years to appease some other third party (the enterprise)? I like my Rust the way it is and not catering to some other people's problems. Fix up Debian first. 
The current release of ripgrep targets a version of Rust that was released *last year*. It wasn't until the other day that I just updated the minimum Rust version to 1.23, which was the first release of 2018. So no, Rust programs absolutely can have a shower release cycle, and I've been employing said strategy for quite some time now. Distros like Debian live in an entirely different world. Saying they can't keep up with a 6 week release cycle is like saying my 2007 ford five hundred can't keep up with a formula 1 racecar. All that being said, there is definitely a desire for an LTS release. Folks have already begun thinking about how this would work. The RFC for it appears to be getting postponed because of the incredible amount of work that the edition requires, but it looks like something that will be addressed eventually.
Not singling out you in particular here, but what's fatiguing to *me* is that every time (yes, absolutely every time) that a bugfix version is released, people start complaining - or even worse, "being concerned", seeing the sky falling and Rust crashing and burning. As a former release manager of Python, I can tell you that this sort of reaction would have made me quit after a short while. This kind of unwarranted backlash to making progress and fixing bugs is bound to make the core team dread releases. I'll let you decide if that's a good thing.
&gt; The current borrow checker has been around for years now, and is beginning to show its age. The work on a better, more precise borrow checker is underway, and it has detected all of these bugs. This work is planned to be stabilized in the next few releases, so expect to hear more about it soon. &gt; &gt; Together, the lack of good maintenance on the current borrow checker and an increased capacity for releases make it feasible for us to ship patch releases on a more rapid and frequent basis. I think there's a good question to ask after this much churn: should the match ergonomics feature actually be considered stable? It has been said that match ergonomics can't be disabled now because it has been stabilized; but each one of these fixes now forbids code that the compiler used to pass, and which may have, by chance, worked. So each one of these fixes is a breaking change, but one that's allowed due to the policy of allowing breaking changes that fix soundness issues. If another soundness issue is discovered in match ergonomics, then disabling the match ergonomics feature, and re-stabilizing it once NLL is ready and can check this properly, is another breaking change that would address a soundness issue. Yes, the scope is larger, but given the sheer number of point releases with breaking changes already done due to these issues, it may warrant the somewhat more disruptive change.
&gt; "there are long standing bugs, and we choose not to tell anyone about these, making it easier for people to run into them". So which organization/application chooses to prominently put something like "oldest critical open bug" on their website? We're not *hiding* these bugs, we even have a category for them on GitHub to make them easy to find. Nobody should be surprised by the fact that there are bugs, and pretty much all software releases with *known* bugs. Nothing would ever get released if all bugs were blockers. For example, https://bugs.llvm.org/show_bug.cgi?id=965 against LLVM is from 2006. This miscompiles C code (by applying the C++ rules for infinite loops against C, which has different rules). I am not against clearer communication, but I also feel you are being unfair towards Rust here.
&gt; 6 weeks is nice and consistent, but if the slew of features that need to be implemented don't fit within that timeframe it would be better to hold off. Most of these features aren't implemented within a 6 week window; many of them take much longer to implement behind a feature gate, and once it feels like they are stable enough, the decision to stabilize them can be made and the feature gate removed. At that point, it can take 6-12 weeks for it to go through nightly and beta, during which the feature can be used ungated, before it arrives in stable. Part of the problem with a feature like this is that it doesn't get used unless someone actually rewrites their code to take advantage of it. So just testing with nightly and beta compilers wouldn't catch it; you need to write new code using the new feature. But because this is mostly an ergonomic issue, it's likely that most people weren't opting into nightly-only builds just for ergonomics, so it probably got a little lest testing by real people trying to use it to write real code than it probably ought to have.
Why do I have to link wsock32 and friends for the following FFI setup, and how can I prevent this from happening? Embedding a Rust library into an C++ application: src/lib.rs: #[no_mangle] pub extern fn initialize() { println!("Success!"); } src/ffi.cc extern "C" { extern void initialize(); } int main() { initialize(); return 0; } Platform is i686-windows-msvc and MSVC. Standard setup fails with lots of missing external symbol errors regarding Winsock libs and such. Everything works fine when I add "wsock32 ws2_32 userenv" to the list of libraries to be linked.
What happens when you use `env!` with incremental compilation?
The only problem for me is the download size because I have slow internet. Now, I was wondering how Flatpak works (it doesn't need to download the whole binaries on every minor update)
I don't understand complains. The language is rapidly growing, what is great, and the patches are really small. Bugs will always happen so it is better to see them fixed than fight them until next major version released.
&gt; So no, Rust programs absolutely can have a slower release cycle, and I've been employing said strategy for quite some time now. Absolutely! My comment was made quickly (damn I should not make brash statements just before I go off for lunch...) and I totally did not mean to put you and your work in a group of "bad" decisions. I think your commitment to using older versions is commendable and should be emulated. Unfortunately that is not the current practice for most crates. An LTS version could work, as would a slower release cycle. I'm not sure which (if either) is the correct solution, the slower release cycle just seems the most obvious to me.
I think /u/eddyb answered this (at least partially?) in https://www.reddit.com/r/rust/comments/907a6d/thoughts_on_compiletime_function_evaluation_and/e2qoa6w. Reliably checking coherence would be incredibly expensive, given how powerful CTFE is.
&gt; they're not intended to be for general development. Right, but if my crate doesn't build on their system I can't package it there, based on their requirements correct? It's true that it will take a while until anything gets to that point (I think there was a post here a while back about the first crate to do so), but I want to be prepared for that. Way Cooler should be able to be shipped in Debian eventually, but I can't do that if my dependencies are always chasing the latest stable Rust version. &gt;They're not worried about it. Or at least, that's what they've told me when I've talked to them.
oh, yes, certainly. i don't disagree with webpack doing a lot of things. i _don't_ think it's doing 3-4 GiB RAM worth of things, though 😃 
Don't make claims like this without reproducible benchmarks and feature parity
In retrospect my comment did seem like it was trying to start a fight, apologies. This particular patch, and all the other patches, are fine. I think the underlying issue they fix is not something that was damaging, but at the same time I think it's great a fix was able to happen so quickly. When something big _does_ come up (like the bug with that method that broke the mutability rules and required an immediate patch release) it's fixed quickly. I love that about the Rust team and something that should be done everywhere else too. Patches, especially soundness and security patches, should be quickly doled out. There's been a lot, but it has been explained very well why that's the case: the old borrow checker code is showing its age, a fix is on the way. But it seems like there's a _lot_ of big things coming down the pipeline that will take a while because they are big (macros 2.0, futures, NLL, const fn) and I'm starting to dislike the "always chasing latest stable" that is so prevalent. The latest stable releases are, for the most part, not necessary for 90% of crates. That's great! That means Rust is featureful to not need them. However they have some niceties (like the new import syntax, or `impl Trait` syntax) that makes it seem logical to upgrade to them. My project is maturing to the point I want to consider getting it packaged with major Linux distributions, but that's not possible if my dependencies will require a high Rust version. The first immediate solution to me is to simply have fewer, bigger releases. Obviously no one here wants that, but even though I think that's a good solution I think this issue should be addressed when it feels like it's just being swept under the rug. It's not a technical problem, it's a cultural one. Rust makes it really easy to upgrade things, which is good in a vacuum but not when you have to work with a slow distribution (for example). /u/burntsushi has done a very good job making sure he targets a relatively early minimum version. That's awesome, but not something that's do-able when you have lots of dependencies (and lots of crates have lots of dependencies). Maybe this cultural problem can't be solved technically, but I think a conversation about this problem should be had.
Compilers do have bugs! And they should be fixed, like this patch. I like this patch! I think I didn't make that clear :\. The reason this bug existed to be released in a point version is what's fatiguing me, not that there was a quick fix. It has been said by /u/steveklabnik1 that this feature maybe should have been pushed out a bit until NLL was ready, because that new borrow checker is better. It seems like to me that for some reason features are being pushed out quickly to the compiler because we need to add it to the language quickly. This seems to happen because, essentially, they are one and the same right now. If there was a Rust standard, there would just be a "Rust 2018 Standard" released and then the compiler can worry about catching up and actually implementing it. If there's a bug in the standard, then the standard was rushed not the compiler which is a different problem altogether. Coding against the Rust compiler usually isn't a big deal though. It only _really_ becomes a problem when you write a lot of unsafe Rust code, which I have been doing with wlroots-rs. Then you need to code against a standard that has well defined semantics, because right now too much is up in the air in the Rust compiler when it comes to unsafe Rust (how does `*mut` and `&amp;mut` interact? What's the best way to represent an opaque pointer that won't be optimized out? What about all those non stablizied nicieties like `NonZero` and `Unique`?). I've started drafting a blog post to argue some of these points, but I'm thinking I shouldn't post it because it could be seen as complaining and doing nothing when really I think this is something that should have whole team buy in. 
\&gt; Nobody should be surprised by the fact that there are bugs They are surprised. That's just how it is, whether you think that's reasonable or not, people are surprised. I don't think it's strange at all that people expect soundness holes to be extremely uncommon, given the way the language is marketed, and don't look further than that. I have not said that these should be blockers. At most I have advocated for a clearer process for determining why they are or are not. As I said, I'm primarily advocating for clearer communication. I don't think I'm being unfair to rust - I posted earlier that I see these problems in other languages (or worse), and the reason that I point them out here is because I think Rust is in a position to do better than them, and I generally care more about Rust than those other languages. This is not "picking on rust" it is me expressing an opinion about a language that I like more than any other.
No clear timeline yet, but this is *the* major next priority. Expect to see much more frequent blog posts as we make progress.
Oh the readme on Github actually has some "benchmarks": https://github.com/nathan/pax/tree/8a1d15dc355ca1c777731c7f8fbfbe24e7d6ee96#is-it-fast (I put "benchmarks" in quotes because: Input files are not specified, number of runs is very low or not specified, hardware is not specified, version of packages are not specified, …)
&gt; ut if the Cargo.lock isn't present (which is the case for fresh checkouts of most library crates) Uh ok, I wasn't aware of this at all, I thought the Cargo.lock is pretty much a part of a crate. Ok, yeah, then this would be breaking indeed, and would not have been appropriate for the issue at hand, you're right. Thanks for clearing that up :)
&gt; I think there's a good question to ask after this much churn: should the match ergonomics feature actually be considered stable? When you have a patch release fixing a bug introduced by a previous patch release for the same feature, the answer has to be no. It seems like versions of the compiler between when match ergonomics was stabilized, and the future one when NLL is on by default, are hard to trust. 
[An RFC for LTS releases](https://github.com/rust-lang/rfcs/pull/2483) was posted a few weeks ago. It's currently postponed because we don't have the bandwidth to implement that with the 2018 edition close to its release, but it's sure something we'll look into after that.
I've seen several projects with their CI set for a specific Rust version, so it's being tested on older releases most of the time, and many projects (like yours) make an effort to maintain compatibility with older Rust versions to make packaging easier. So yeah, it's not really a problem IMO. I try to target my projects at the oldest Rust version supported by a major Linux distribution that my dependencies support. Unfortunately, this is 1.26 or so for some projects.
Could you post samples of actual physical coins with other designs? It's unclear what the final result would be otherwise.
I have nothing in particular in mind, but burntsushi's code has always been outstanding.
https://www.huberusa.com/products/coins/custom-coins/ This is the site I'm considering to use, they have pictures of coins they've made.
This thread seems to be about people complaining or being concerned about patch releases. I hope my comment (the parent to the one you linked) didn't come across that way. My intent at the time was definitely neither to complain nor express concern, because I had none! I only wanted to note the correlations I saw and suggest that taken together they point toward an area of improvement, not imply that the state of things was bad or the patches themselves were omens of doom.
I'm not sure why hyper is involved at all in a minimal example, but your root issue is that `Stream::into_future` does not do what you think it does. You want `for_each`.
If the bindings written in Rust are LGPL then I would think that it is viral?
Which purposes does HIR still serve after borrowck is moved to MIR? Would it make sense to try to move those parts into MIR as well in order to simplify the compilation process?
What about Rust logo on one side and ferris on the other side? I live in the UK, how much would be the shipping cost? 
I edited my example to use `for_each`, and removed hyper, but the same error is still present.
That's what I'm asking everyone for. What do you guys think would be best? Will clarify in post. Given it's a small coin, shipping would be just a letter. USPS says $1.15
Capnp-rust enforces rust 1.15 and has a discussion going on about turning off clippy lints that require newer versions
On the other hand, asynchronous medium are more difficult to get onboard as a beginner. Maybe that's because every single word you write has more impact: it's gonna be read and commented by everybody, which puts a lot of pressure on your back. Or maybe it's because it tends to have a stronger formalism, with unspoken social rules you can feel when reading but you can't be sure you won't break some of those rules when speaking.
&gt; ave all the recent point releases been a result of the aging borrow checker No! This is the story that's being pushed but it's ridiculous; do we think the borrow checker has gone senile or something? All of the recent point releases have been due to a poorly thought-out, poorly implemented, and untested feature rushed to stabilization before it was ready — probably because it was pretty unpopular.
&gt; Is the idea that Rust is supposed to be so backwards compatible that there's no point to compiling with an older version? Yes, essentially. It's generally assumed that you're building with the latest stable release. Some crates do try to support a minimum Rust version, though. My `multipart` crate works all the way back to 1.22.1, which I have guaranteed by testing in [its Travis-CI config](https://github.com/abonander/multipart/blob/master/.travis.yml#L7). This was previously 1.17 but some new dependencies needed a newer version.
Out of curiosity, is there a place I can read about the current status of the new borrow checker? I enjoy following that kind of stuff.
Get an artist to add a lot more detail. These look too plain to spend money on.
The [BeeWare Project](https://pybee.org/) has [challenge coins](https://pybee.org/contributing/challenge-coins/) like this and they're quite wonderful.
`tokio::run` accepts `F` such that `F` implements `Future&lt;Item = (), Error = ()&gt;` (and some more irrelevant constraints). It won't accept anything else. You want to specify the associated types of the `impl Future` you are using in return position on `send_every_30s` (i.e. `impl Future&lt;Item = (), Error = ()&gt;`) as `futures` doesn't use default associated types (it's unstable and therefore nightly-only). This means you also have to use `&lt;Future as FutureExt&gt;::map_err` to transform your `ForEach&lt;Interval, _, _&gt;` to something that fits `impl Future&lt;Item = (), Error = ()&gt;`, because you currently return something that fits `impl Future&lt;Item = (), Error = tokio_timer::Error&gt;`. Working example [here](https://play.rust-lang.org/?gist=fec74f8133ea005132f1e48770b64af2&amp;version=stable&amp;mode=debug&amp;edition=2015).
HIR is an an abstraction between the Abstract Syntax Tree of the code and MIR. It allows code parsing and compiler steps before MIR (one of which is type checking), to be worked on independently.
This is level headed criticism without insults. The fact that it's being down voted to hell is frustrating.
&gt; My project is maturing to the point I want to consider getting it packaged with major Linux distributions, but that's not possible if my dependencies will require a high Rust version. It is possible! In Debian, Package inclusions / non-security updates all get done on Debian [*unstable*](https://wiki.debian.org/DebianUnstable) and then usually get automatically uplifted to Debian [*testing*](https://wiki.debian.org/DebianTesting). These are the two rolling-release channels of Debian. For stable releases, Debian testing gets forked off and its packages get maintained for a while. If/When way-cooler or ripgrep or whatever software you have gets packaged by Debian, it only has to be compileable by the rustc version that Debian testing currently has *at that point in time*. As Debian *testing* is rolling release, this is usually the latest release, maybe 1-2 releases back, depending on how well the rust team of Debian is keeping up or how many bugs the latest rustc introduced that Debian cares about (I recall a few build failures on exotic arches). This is entirely possible, and also includes updates. There are a few exceptions obviously. E.g. when your package needs security updates. Then those can be shipped to stable Debian as well. Or when there is an exception to the stable policy. At least on Ubuntu (no idea about Debian), Firefox gets always shipped in the latest version. Firefox does require the newest rustc though at time of branching from mozilla-central (actually [two weeks prior to that](https://wiki.mozilla.org/Rust_Update_Policy_for_Firefox)). So while there are some constraints, in general the requirement on a very current Rust version does not mean big issues for inclusion into non-rolling Linux distros. Now, this doesn't mean that LTS releases or requiring older rustc versions wouldn't be very good ideas. LTS releases will most likely come one way or another because rustc is made by Mozilla which also uses it in Firefox, and Firefox has LTS branches. Not requiring the newest rustc version is a good idea because then people contributing to your project do not have to update their rustc as often, or might even ditch rustup entirely and use the distro provided rustc. I actually do want to manage most of the software that I install through my non-rolling release distro's package manager, because it is more convenient, allows updates on a central place, and so on. Just imagine, when every technology always required the latest compiler version... Rust is a bad citizen here, as are many node.js projects which require the latest and greatest node.
Anyone is free to contribute, coins aren't really the most detailed stuff. I'm not going to try to pay an artist to make a coin that might never even be bought. I'm just doing this for fun
Those look nice
Sure, also, coins are incredibly details! Look at your change in pocket. what could be fun is a kickstarter for this so you could get money to an artist (and yourself for the effort!)
Ah OK. So `map_err` wraps it's returned value in an error? That makes more sense. I had tried setting the item and error to `()`, but that just changed which line the error was on. That also explains why my `Err(())` didn't work. I have to say, it's confusing (to me at least) that the success combinators require the `Ok` wrapper, but `map_err` doesn't. Maybe I'm missing something though.
The success combinator is actually \`map\`, not \`for\_each\`.
How does one translate "fearless concurrency" to latin?
That would be awesome, might go that route
Something I'm curious about: is HIR still valid Rust code that could be compiled? It's just fully desugared?
For what it's worth, I do generally agree that folks can be too quick to adopt new features in crates. On the other hand, it's a double edge sword because it's important to get real experience with new features, which we already aren't doing enough of because so many folks stick to stable Rust. In the grand scheme of things it's a good problem to have and I'm not sure there is a one size fits all solution. I kind of expect foundational crates to become more conservative over time (or at least, adopt new Rust features without leaving older versions of Rust in the dust), which I hope will mitigate this solution somewhat. It just takes time to mature the ecosystem, but I am pretty confident we are on the right track.
Thank you for the detailed reply! That does comfort me slightly, but I agree Rust should consider some sort of LTS option (which I was hoping epochs was going to be). 
&gt; That's awesome, but not something that's do-able when you have lots of dependencies This is a good point. I am generally fairly conservative about adding new crate dependencies, because they have to be balanced against the amount of extra work they entail. The balancing act is complex and I don't want to get into it here, but yeah, if I'm using fewer crates then it is much easier for me to manage things like the minimum Rust version. (Which is definitely a thing I have spent time managing. But it had gotten much better since most of my dependencies are now explicitly tracking a minimum Rust version.)
I mean, it’s years before releases. I agree it would be awesome for Way Cooler to be packaged, but then there’s some work to do. They don’t just package anything. Someone has to champion it.
I mean that breaking the documentation flow between two methods makes things harder to read, because you have to “remember” what trait bounds are there on which variables. That kind of *stateful* documentation is a bit boring to me, yep.
It’s totally a reasonable thing to ask!
I think the idea here is that a conservative distro like Debian might just need to package an older release of Way Cooler itself, e.g., the most recent release that compiles on their version of Rust. This should be possible since you control the exact version of every dependency that gets compiled into your program. For me personally, updating my Carho.lock is a careful and methodical process. I rarely run a naked `cargo update` for example, and almost always specify explicit crates to update.
Hmm... I'm not sure. Are you familiar with ASTs? (for those who aren't [https://en.wikipedia.org/wiki/Abstract\_syntax\_tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree) ) 
 fn main() { let in1 = 5; let in2 = "foo"; let mut generator = { enum __Generator { Start(u64, &amp;'static str, f64, u64, usize, &amp;str), }
Well.. I knew what the acronym stood for, if that counts. ;) I just found this and will do some reading: https://rust-lang-nursery.github.io/rustc-guide/hir.html
Maybe"fearless currency"
Oh yes I'm (roughly) aware of the rather arduous process. I was worried versioning would be a bigger problem , but if you've spoken to them and it's not an issue perhaps my fears are misplaced.
I mean, we’ll also see; for the current release of Debian stable, it missed 1.15 by two days, which was the release of custom derive. I asked them to make an exception and they were like “it’s fine”. As the package base grows, maybe it’ll be more complex, we’ll see.
concurrentia intrepidus /killgissning
By the way, I should also commend the release team for getting soundness fixes out with such short turnaround. I think it's really good that getting these fixes out is being prioritized, and with this kind of turnaround, along with the new borrowck around the corner, the work being done on RustBelt and LLVM soundness fixes, I feel like we're pretty close to being as sound as generally expected. I just bring up this issue because I think it's worth thinking about the policy for features like this that may land a bit before they're ready, and where it could turn out to be less disruptive to disable the feature and re-enable once it's been vetted a little further.
For ripgrep at least, aborting on SIGBUS is actually not desirable. It's more like a tolerable bug that probably isn't worth fixing. Namely, if ripgrep is searching a single file, then aborting is probably OKish, but if you're searching a bunch of files, then aborting before searching other files is definitely not desirable. Normal I/O errors are generally just printed to stderr and ripgrep otherwise continues on its merry way. All that said, this is mitigated somewhat by the fact that memory maps aren't typically used when crawling directories and usually more so used for searching a single file or two, so the bug (which is already pretty rare) isn't too bad. With that said... I do think the general problem trying to be resolved here is worth investigating. What I'd really like to know is how to abstract over memory maps inside a library without imposing extra costs and without requiring users of the library to invoke `unsafe` or otherwise know that files are being memory mapped. As far as I know, this just isn't possible, which is kind of a bummer. For example, in my upcoming libripgrep library, I want to expose a high level routine for searching a file. Internally, the searcher _may_ choose to memory map the file. But the interface it exposes is the same regardless of the internal strategy. e.g., "Here is the matching line as a `&amp;[u8]` and the line number, do what you want." If that `&amp;[u8]` is actually backed by a memory mapped file, then that becomes a leaky abstraction because it's not even clear (to me) what you're allowed to do with a `&amp;[u8]` that is backed by a memory map. Namely, let's say you do a `str::from_utf8(bytes)` where `bytes` is valid UTF-8 from a memory map, and then the underlying file is mutated to contain invalid UTF-8. Have you just landed into UB? And of course this is just one variant of the problem. Basically, I'm just not sure how to encapsulate this particular use of `unsafe`. It doesn't seem possible without shooting yourself in the foot in some way.
Thanks everyone for the feedback! It was very helpful.
Thanks everyone for the feedback! It was very helpful.
&gt; because so many folks stick to stable Rust Really? Not long ago too many people were using nightly. :-D
Just FYI, `pax` is already the name of a POSIX standard tool, a `tar` and `cpio` replacement to be precise. You may want to consider a name change.
That's because it's still an alpha ;)
Not necessarily. The LGPL just requires that users be able to swap out the LGPLed code with a patched version. 1. If the bindings use dynamic linking and a stable ABI (eg. `crate-type = ["cdylib"]`, `#[repr(C)]` and` extern "C"`), it doesn't matter what language they're written in. 2. If the bindings use dynamic linking and an unstable ABI, you might be legally required to provide users with the compiler version you used on request. I haven't checked that. 3. If you statically link the bindings into your program, then you'll be required to provide users with a means to swap them out. Traditionally, this was accomplished for C or C++ code by providing a compiled object file for the closed-source code, plus instructions on how to redo the final linking phase.
Great post u/Jeb_Jenky \- I know that a lot of people just starting with Rust feel the same exact way. A lot of people just getting introduced to systems-level programming (C, C++, Rust, etc.) sometimes have a hard time with it, and unfortunately drop it (I did this with C++ ;) ). For me, I find it helpful to surround myself in rust community-based settings (sub-reddits &amp; slack channel) as well as read general posts/PDFs/Books regarding generalized systems-level programming. Hope you're having fun thus far with Rust!
I appreciate the example, I think maybe it makes sense now. I'll have to see how things are structured in mine.
Sounds like you might want to look into [Rust build scripts](https://doc.rust-lang.org/cargo/reference/build-scripts.html)
I often laser cut Rust logos out of acrylic, may bring a bunch to RustConf this year
What about an approach similar to [diesel's CLI](https://github.com/diesel-rs/diesel/tree/master/diesel_cli). Instead of downloading plugins separately, users could specify plugins with feature flags: cargo install project --features project-plugin-foo Diesel uses this to specify what kinds of databases it talks to. I'm not sure how diesel manages this, but I found it nifty. If your users want another plugin, they might have to re-install everything (never had to do that with diesel, yet, so not sure how it works).
The default crate template for library crates (but not for binary crates) has \`Cargo.lock\` in the \`.gitignore\`.
I'm not sure what the right way forward is with this stuff... I don't think its easy to simply roll back an entire feature once it's out in the wild, like, woops... ah, just pretend that never happened. ...but this patch cadence definitely feels off-kilter with rusts stability guarantees; it \*is\* a breaking change, even if it is a soundness fix. Its important to promptly fix that sort of stuff... but I agree that maybe this wasn't ready when it was moved over to stable. The nightly / beta channels are supposed to stop this stuff before it rolls into stable, and I think maybe we need to look at why that's not working. 
The only Rust coin that I need: https://github.com/mimblewimble/grin ;P
Also, match_default_bindings has other problems, like not being able to cancel by writing &amp; before individual constituents: https://github.com/rust-lang/rust/issues/50008 I think match_default_bindings should be completely revised..
Minor nitpick- once it starts interacting with terminal I call them TUI - text user interface. Cli is when you enter command and you get an output. 
Oh right thank you for your explanation!
Since actix\_web 0.7.0 just released now, You'd better make a upgrade...
My experiments showed that frames bigger than 512-1024 rows don't bring any benefit and even have negative effect. I think it's about a frame fitting in the L2 CPU cache. So my suggestion is to explore this kind of frames that are columnar but the whole data set is composed by multiples of them. Regarding the swappable representations row/col, I think the serialization/deserialization will add overhead and prevent the compiler to optimize the code. BTW, this is how on the JVM it's usually done (e.g. Spark, Flink) but the motivation is to store the data in direct memory so that it is not subject to the GC.
Ahaha, yeah, good eye... luckily the changes don't look too significant with all of this, so I'll take a look at it after dinner tonight.
I *think* you could build a reasonably-sensible compiler pass to take `Result&lt;T, E&gt;`-based code and transform all the `Error` paths to exception-based code. You'd expose this as a `#[slow_path]` repr on an enum variant or something like that. That would be an interesting experiment. IIRC, the Midori research OS was *all about* the exceptions, and one of the lead Midori devs said that typical code would be 5% faster on the happy path with exceptions versus inline branching.
I just grab anything written to write c and c++ and do it in rust instead. ray tracer in a weekend was a good easy book. 
@dbrgn good point, embedded weekly news too, but I dont have my login details for the next 9 days (travelling) so it has to wait a bit longer.
I'm not a C++ expert but I know Python has quite a bit to teach in terms of making usable APIs. I haven't used any other language which hits the trifecta of usability, capability and discoverability so well. Rust is getting there, but we could still learn a lot. Having the usability of python without the safety and speed costs would be amazing.
I can't see any con in that.
Knowing C++, I think Rust already learned what was worth learning. Copy by value semantics (actually copy by move, which is an improvement), interoperability with C (and the OS apis), deterministic destructors, zero-cost abstractions, low-level control. It also learned what doesn't work in C++: memory unsafety, UB, lack of modern conveniences, type promotion, exceptions, terrible compiler errors, templates. I think Rust is a nice balance between many languages. What I love about Rust is that it's a universal language. It is **at least** 80% as good as the other language in any area. 80% FP as Ocaml/Haskell, 80% expressivity of Python/Node, 80% of control of C, 80% of networking of Go, etc. At least for me. I could imagine doing a whole business, full stack, everything in Rust. It wouldn't always be the best tool for any particular job, but code reuse, uniformity and other synergies, would more than makeup for it. 
Well, see if you can play around with this code: https://play.rust-lang.org/?gist=fc8e39f2c9b5f3c22a1bc76c690d7ec0&amp;version=nightly&amp;mode=debug&amp;edition=2015
Nothing. Rust on it's own teaches and guides you to much better implementations of interfacus and designs than C or C++ ever could. And this is for the most part due to the ownership mechanic. Achieving the same in C or C++ takes a good amout of experience and awareness of the various pitfalls. These languages don't safeguard you from foot guns, which so very often leads you to incorrect programs that "work". You're better off learning and writing Rust and then replicating those logical constructs in C or C++. Disclaimer: I'm a C/C++ dev with a bit over 10 years of experience, and honestly, I find Rust to be a better teacher of logically sound programing than the other two, even though I haven't written that much of it.
I'm wondering, what's the easiest (any?) way for me to implement a method just for a single value of an enum? Example would be: ``` pub enum Opcode { Halt, Out(u8), Noop } impl Opcode { pub fn code(&amp;self) -&gt; u8 { match *self { Opcode::Halt =&gt; 0, Opcode::Out(..) =&gt; 19, Opcode::Noop =&gt; 21, } } // how to do so that only Opcode::Out has a method returning it's passed argument? I.e. // Opcode::Out(90).first_arg(); } ```
You can't, and I don't see this ever being possible.
Since you can't create values of (hypothetical) type `Opcode::Out`, only of type `Opcode`, you'll have to select what to do if the value isn't `Out`. Depending on the complexity involved (i.e. probably not for this example), it may be beneficial to do something like this: enum Opcode { Halt, Noop, Out(Out), } struct Out { ... members ... } I.e. make it possibly to whittle down the `Opcode` to `Out`, and then implement the unique methods on `Out`.
Hmmm, seems 0.7.0 and co haven't made it up to crates.io yet. I'll keep an eye on them and update it when they do - would rather target those releases than a git rev.
Some things C++ has that Rust hasn't: * &lt;h1&gt;**CONST GENERICS**&lt;/h1&gt; * A much larger community * Stability. 3 years since the stable release, and the Rust language already has breaking changes. This coin has two sides: one is that you can't rely on features that your language provides, second is that it allows ppl to remove old stuff from modern codebases... something C++ struggles with. * Most C++ projects don't depend on the newest and most recently released C++ compiler out there or at least have fallbacks for older ones. This allows you to update your compiler at your own pace. * Multiple independent compilers * More projects using it * Language development upheld by a diversity of sources. Development of the Rust language on the other hand is very much dependent on Mozilla employees and Mozilla contractors, short, on Mozilla money. That being said, Rust has learned a ton of lessons from C++. Other comments laid out that very nicely, not going to repeat it here.
I always find it interesting to see people who find Python very usable, since I always program very slowly in Python as I have a really hard time navigating things without a static type system. Sometimes I just wonder how you guys manage that.
Just use Parcel, it's so much faster than anything else I've used
Whatever bundler you use the minification is still going to be slow.
I love reading those language-love-letters :)
Yeah, I've got no more idea what the difference is. I mean I rely on the same things I do in rust mostly. I use autocompletion w/ documentation pop-ups, searching documentation and searching online. I don't see not having a static type system as much of a problem except for the maintainability aspect. PyCharm works just as well at figuring out what types things are, and I'll annotate method documentation with types. Not having static types does hurt maintainability, that's when I miss Rust. But it doesn't seem to be a problem for me when discovering things nor when prototyping.
I remember a post containing info how to help testing, but can't find it. Can anyone help out, I'd run my crate through it to see what happens ;)
I've been wanting to beef up some of the utilities I wrote for myself in Python and I actually find that rust has nicer libraries for making CLI apps. I am so pleased that I honestly think I will be making all of my future scripts in Rust instead (with only minimal overhead once I have atrong familiarity with the mentioned libraries). I was wondering if anyone else had been considering the same and would share their experience or useful tips? Most scripts of mine involve basic subprocess shelling and JSON, csv, or simple text processing. JSON is mostly done with jq, but there are actually a few crates that have JSON query language implementations out there.
Is there any particular reason you chose to store session data in Redis rather than use a Rust data structure? I ask because one of the reasons I would choose to implement a web project in Rust is because it gives me the ability to maintain all data structures within the language, without having to layer on other services such as Redis.
If you are an application (rather than system) developer, type promotion and exceptions can be preferred. Some love and others hate them, but they are not universally considered to be better or worse.
Without going through the footguns, you may not have the foundational knowledge to understand *why* the borrow checker is so strict. You may learn how to appease it, but it could end up as cargo cult programming, with you writing the code "just so it compiles" rather than understanding the reason.
Your number 3 example is what I was trying to hint at. The bindings used for QT looks like they need to be statically linked into the application Rust code and those bindings looks like they are using the QT style dual GPL/LGPL but I'm not sure about that last part.
Futures don't use channels to communicate, unless you use them yourself, it's more like a generator, but i don't believe that terminology is useful in this case. It's just a concept from different playing field (see functional programming). There are also streams for iterating over asynchronous data, so coroutines don't solve any particular problem that couldn't be solved otherwise.
I think that generally coroutine is more general thing (generator is a special case of coroutine). See https://en.wikipedia.org/wiki/Coroutine
**Coroutine** Coroutines are computer-program components that generalize subroutines for non-preemptive multitasking, by allowing multiple entry points for suspending and resuming execution at certain locations. Coroutines are well-suited for implementing familiar program components such as cooperative tasks, exceptions, event loops, iterators, infinite lists and pipes. According to Donald Knuth, Melvin Conway coined the term coroutine in 1958 when he applied it to construction of an assembly program. The first published explanation of the coroutine appeared later, in 1963. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Cool stuff! 
That is inevitable consequence of gaining knowledge from someone with more experience than you have. You either repeat all the previous mistakes to verify that given knowledge is correct or you take it for granted - neither is without consequences.
One common reason is that one (distributed) Redis can service multiple hosts. So if, god forbid, you need to scale your Rust web server, you can just add a second machine that accesses the same Redis, and put a load balancer in front of it. This is much more difficult if the sessions only exist in your process' memory. &gt; I ask because one of the reasons I would choose to implement a web project in Rust is because it gives me the ability to maintain all data structures within the language Interesting. Would you also not use a database?
Please write more!
Yes, this is true. However, I would not attach the knowledge and understanding of these concepts strictly to C or C++. I see this rather as a general programming concepts. C and C++ just so happen to be good at demonstrating these, but not exclusively. Maybe because I've been through these foot guns from day one, it's lessons I've learned regardless of Rust. I guess those are definitely lessons you do learn. Mind you, I'm not saying you shouldn't learn C or C++ - these languages will teach you a thing or two whether you like it or not, but somehow, I feel you can do the same with Rust and probably save yourself some frustration while the tools (read: compiler) will be more friends than dismissing and cryptic gatekeepers. That is, if your goal is to learn to write correct programs.
The [edition guide](https://rust-lang-nursery.github.io/edition-guide/) has a bunch of info, incl. [how to transition to Rust 2018](https://rust-lang-nursery.github.io/edition-guide/editions/transitioning.html).
Is multiple independent compilers actually a plus? I get that competition can be a good thing but it seems like you frequently run into problems where different compilers have different levels of support for features. Take how MSVC almost always lags behind gcc / clang. They’re getting better, but it seems like if everyone is using the same compiler across platforms, everyone is more in sync.
He I'm sure I rememebered something else, but this will do nicely (and has the additional advantage that I can "test the docs", so to speak). Thanks!
Pretty cool idea, but I think the design ideas look a bit too simplistic. Consider giving these a look: [https://gitlab.com/jstpcs/lnxpcs/blob/master/cards/black/rust-card-black.png](https://gitlab.com/jstpcs/lnxpcs/blob/master/cards/black/rust-card-black.png) [https://gitlab.com/jstpcs/lnxpcs/blob/master/cards/classic/rust-card.png](https://gitlab.com/jstpcs/lnxpcs/blob/master/cards/classic/rust-card.png)
&gt; one is that you can't rely on features that your language provides as a future edition may remove them any time Crates are interoperable even when using different editions of Rust! 
Sorry. I slept terribly and was a bit muddled there. (Ironic that I recognize it now, when I'm possibly even more tired) #3 is actually wrong. What it's supposed to say is "If you statically link your program to the bindings and statically link the bindings to Qt or GTK+". If you're talking about [rust-qt](https://github.com/rust-qt), it's not a problem. 1. The bindings are MIT-licensed, so they doesn't impose any restrictions on the Rust code you statically link them into. 2. The [cpp_to_rust_generator](https://github.com/rust-qt/cpp_to_rust/tree/master/cpp_to_rust/cpp_to_rust_generator) README has this to say: &gt; If Rust crates and C++ wrapper libraries are all built statically, the linker only runs once for the final executable that uses the crates. It should be able to eliminate all unused wrapper functions and produce a reasonably small file that will only depend on original C++ libraries. If the "all built statically" case produces binaries that "only" depend on the original C++ libraries, then that means it's using dynamic linking for the connection between the bindings and Qt.
Multiple compilers isn't by itself all that important, but it helps a lot with keeping the language well-defined and self consistent when you have multiple different code bases trying to implement it. With only one compiler it is easy to start to conflate what makes sense for the compiler with what makes sense for the language.
One plus is that it forces a proper specification, rather than just "the compiler is the specification". So when you find [a function where the implementation is wrong](https://internals.rust-lang.org/t/deprecate-or-break-fix-std-env-home-dir/7315) you can actually fix it rather than just deprecating it.
Well, aside from the pain of finding obscure memory bugs... I would say class inheritance. It is very useful for GUIs and I don't think Rust has a good solution yet.
Looks good to me! :) I followed the video link and found this: https://www.vandenoever.info/blog/2017/09/04/rust_qt_binding_generator.html Is it the same project?
What interacting with terminal means? Color output, redrawing (progress bars), interacting with user? Is your package manager CLI or TUI? IMO TUI is when you pretend that console is a window and draw widgets in it like in a GUI (e.g. Midnight Commander), so I think CLI is more appropriate here :)
Very cool.
Yea, I don't write Python anymore. I've reimplemented some of my scripts in Rust, and the best thing about it is that I actually handle and log errors now. For working with JSON, I use serde, its awesome.
There is one more post in my blog if you're interested. Or do you mean more than 2? :)
Most application developers have good reason to choose languages other than C++.
The translation from - to _ was added because it was decided that - should be more idiomatic; it’s not a super strongly held idiom though.
No. * `rust-qt` is about writing Rust applications which use Qt. * Rust Qt Binding Generator is about writing Qt/C++ applications which incorporate Rust components. (With Rust Qt Binding Generator, as far as I can tell, you'll need to write some C++ glue code and it expects something like CMake to be the top-level build system.)
Probably nick cameron’s blog; im on mobile so it’s a bit harder to find, but maybe that’s it?
&gt; cargo cult programming Heh.
Yep, that's it: https://www.ncameron.org/blog/how-to-help-test-the-2018-edition/ Thanks, but I'll go along the edition guide, testing official doc seems a worthwhile endeavor.
Webpack is also working on integrating rust code into it, via wasm. Like, as part of Webpack itself, not using rust + wasm as part of your app (though that’s a thing too)
Large projects inevitably involve Redis or Memcached down the line, just how it always ends up working. Redis is also probably one of the most battle tested things out there, I see no reason to avoid it, and generally just lead with it so scaling is less of a headache down the road. Also entirely possible you’d want to, say, access existing sessions from some other install in Redis. *shrug*
I agree with the perspective on errors. I'm very good at writing bash/fish scripts, but the ability (or lack thereof) to handle errors gives me palpitations. Even just being able to use `?` to propagate errors and see a backtrace is streets ahead. And the lack of ability to use typing in Python made me hesitate to expand my utilities with confidence. I was actually trying to find a new go-to scripting language with strong typing (there are some written in Rust that are interesting like gluon/dyon), but haven't found anything more compelling than Rust itself so far. And the truly amazing thing is the crates allow us to package and distribute a skeleton without much work. In case you weren't aware, there's a project called `quicli` that does this. [Here's a demonstration](https://killercup.github.io/quicli/thumbnails.html). It packages `structopt`, `env_logger`, `glob`, and some other things and puts a `main!` macro to make it easier.
Very good points. There is progress being made towards many of them, so I'll post a few links and explanations for people who haven't seen/heard about them yet :) &gt; CONST GENERICS http://rust-lang.github.io/rfcs/2000-const-generics.html &gt; A much larger community Some of the effects of a larger community: Libraries, many answered stack overflow questions, more people pushing for cool niche use cases. I think we're moving in a pretty good direction in all of these regards. (I'd actually _not_ want the Rust community size to double every months because communities are super hard to scale!) &gt; Stability. 3 years since the stable release, and the Rust language already has breaking changes. You mean the edition? I actually consider this to be very much like C++11 vs C++14, as you will continue to be able to compile Rust 2015 code. &gt; Most C++ projects don't depend on the newest and most recently released C++ compiler out there or at least have fallbacks for older ones. This allows you to update your compiler at your own pace. I kind of hope we can continue to get away with requiring people to update their compilers regularly. I know some folks are uncomfortable with this. Also cf. https://github.com/rust-lang/regex/tree/991ae1a4c69cd81ecf989119b9205a3204088e83#minimum-rust-version-policy &gt; Multiple independent compilers There is https://github.com/thepowersgang/mrustc &gt; More projects using it See "community size" above. I'd love to see "More [well-known enterprise production] projects using it" and talking about it publicly, though :) &gt; Language development upheld by a diversity of sources. Yes. Also: http://aturon.github.io/sponsor/
Ehm, don't forget the difference between C++ and Rust, in the latter case features will be released with editions or without them, ofc if they are not blocked on breaking changes. (and even if they do there is possibility of using flags to enable certain keywords on crate-level) So in this regard C++ example is invalid, users will not have to wait for the next edition for features implemented and stabilized in say 2019.
I read the book twice, and then when I tried to write some code got completely stuck, despite good familiarity with a lot of other languages. Definitely feels like some good example projects as you read would help!
Well, I'd say that as long as you can interact with the cli fully via just args and pipes, it's a CLI. I'm not sure what happens if I'd try to pipe stdout of glitchcat to a file but I'd imagine some ecape codes and such would end up there? 
Thanks. I can see the point about making it easier for other servers to access the session information if more than one server is necessary. You don't have to use Redis to address that need, but it's certainly a common approach. I just like to keep the stack on every server as simple as possible. I certainly wouldn't avoid a general database program for a content-driven site, but I think that's a different kind of need.
There's no question that Redis is both very reliable and very fast. As I mentioned in a separate reply in this thread, I just like to keep the software stack on servers as simple as possible, 
I noticed the edition guide talks about `impl trait`, but that is also on rust 2015. Why is it in the guide?
Thanks for the clarification! I just assumed that both Qt bindings projects were for writing Rust applications which use Qt.
I guess so, I think I should fix that. Like an option to output glitched text without animation.
what would be really cool: actual Rust logo chainrings for a bicycle
You might also be interested in this project: [https://github.com/cswinter/LocustDB](https://github.com/cswinter/LocustDB) The author recently wrote a long article about it: [https://clemenswinter.com/2018/07/09/how-to-analyze-billions-of-records-per-second-on-a-single-desktop-pc/](https://clemenswinter.com/2018/07/09/how-to-analyze-billions-of-records-per-second-on-a-single-desktop-pc/)
It's rare, but I sometimes need it. Now I replace \\n with e.g. @ (or some other character not in the file) and do my search. Recently there was a csv file in which I wanted to find two subsequent lines with a specific pattern. I could have written an awk script to do it, but multi-line search (in Emacs) was easier. In Emacs, you've got to write something like `pat1\(^J.*\)*pat2`, by the way. I don't know any other way, but it does allow decent control.
&gt; So in this regard C++ example is invalid, users will not have to wait for the next edition for features implemented and stabilized in say 2019. Unlike Rust, features are **not** stabilized ahead of the Standard in C++. Experimental features can indeed be used ahead of time, but there is no stability guarantee (at all), and history has proven that a number of features are adjusted, sometimes multiple times, until they finally make it into the standard. As a result, all the companies I worked for or heard about would never enable such experimental features in production because they were not willing to have to go back and revisit every use site should the feature change.
*Disclaimer: the following is a parallel with my knowledge of compilers in general, and I may be putting my foot in my mouth...* The traditional compiler frontend's passes: - Lexing: going from raw text to tokens, - Parsing: going from a stream of tokens to an Abstract Syntax Tree, - Type-Checking: going from an AST to a decorated AST (name look-up, type inference, etc...), - Path-Checking: going from decorated AST to Control-Flow Graph, - Hand-over to LLVM/backend. I would expect HIR to be the decorated AST (sometimes called Abstract Binding Tree) and MIR to be the CFG.
I disagree. I’d call this a CLI.
&gt; I've started drafting a blog post to argue some of these points, but I'm thinking I shouldn't post it because it could be seen as complaining and doing nothing when really I think this is something that should have whole team buy in. I, for one, would love to see this blog post. I do think however that the whole team is well aware of the issue. Indeed, this issue is the very motivation behind the RustBelt project and Ralf Jung's work! There is a strong desire to settle the semantics of unsafe Rust, you are far from the only one worrying about what is legal and what is not, what could be optimized and what should not, ... Unfortunately in order to ensure soundness it has to be done properly and this requires work. Hence RustBelt. 
Not everyone keeps up to date with every single update to Rust. It's a really nice feature that allows things that were impossible, so it's reasonable to put it into the spotlight for those that haven't seen it yet :) It also came quite late in the 2015 edition.
 $ cargo cult programming error: no such subcommand: `cult` Did you mean `build`? 
Does rustup integration into cargo mean that I will be able to install and update toolchains with cargo?
&gt; libm ported to Rust: https://crates.io/crates/libm Wow that was fast! The call for action was only last week!
I think the main benefit of a second compiler is **cross-checking**. Imagine that you have some sample code, it compiles and you get behavior A. Behavior A may or may not make sense to you, but that's what it is. Now, compile it with another compiler. If you get A too, it might be the right behavior. If you get B != A instead, however, then there's something astray! If you look at C++ compilers, there are many questions (and bug reports) of the form: "I get this behavior with gcc and this behavior with Clang, what's wrong?" and often times it turns out that one (if not both!) of the compilers was doing something silly. John Regehr is even famous in the C++ community for creating CSmith (a program which generates random bits of C code), and throwing its output at various compilers to see if he gets different answers, then opening bug reports to those compilers if it seems they're doing it wrong. This means you don't need any Oracle to verify that a compiler behaves sanely, just a multitude of compilers :)
&gt; I would choose to implement a web project in Rust is because it gives me the ability to maintain all data structures within the language May I ask why? Or in other words, why do you think you can't do that in other languages? 
Not really. I learned C/C++ before in university but never do anything serious with it (just do some competitive programming tasks), but only after learning Rust I understand the art of manual memory management. Rust forced me to learn all the whys 
&gt; **CONST GENERICS** Indeed. This is the last missing feature (now that we have SIMD) which prevents me from advocating Rust for low-latency systems. I don't even need anything that fancy to start with: I just need the ability to parameterize a type with an integral literal (and then pass it unmodified to other types). &gt; Stability [...] one is that you can't rely on features that your language provides as a future edition may remove them any time [...] I would not that even C++ has been breaking stability with new standards: - `auto` changed meaning between C++98 and C++11, - Trigraphs (and digraphs?) were deprecated, - Contextual keywords were introduced (`override`, `final`, ...), - `std` APIs were deprecated and removed. Given that it is NOT possible to include a C++11 incompatible header in a C++11 source file, I would argue that Rust is **more stable** than C++, since at least the design of editions makes it possible to keep using a 2015 edition dependency without migrating, or start using a 2018 edition dependency in your 2015 code without migrating. &gt; Most C++ projects don't depend on the newest and most recently released C++ compiler out there or at least have fallbacks for older ones. This allows you to update your compiler at your own pace. For better and worse. When I started at my previous company (2007), they had started the migration from gcc 3.4.2 to gcc 4.3.2. When I left (2016), there were talks about migrating to a more recent release (gcc 4.3.2 was not fully C++11 compliant), however the middleware teams opposed the notion until the use of gcc 3.4.2 was fully deprecated before a new compiler was introduced. One of the greatest issues with upgrading was, of course, that new optimizations could suddenly start exploiting until now benign Undefined Behavior in the various teams codebases so flipping the switch regularly led to mysterious crashes which had to be investigated, costing a lot of time^1 . In the sense, on the one hand I think that large companies will naturally lead to projects that stick to older compiler versions, and the other hand I hope that Rust's safety will make it *nigh painless* to upgrade, meaning that even large companies will not lag behind *that much*. ^1 *The code was overall of rather mediocre quality; which is damning in C++.* &gt; Multiple independent compilers I agree that this would nice to cross-check them against each others, however given the effort required to implement *one* compiler, I am afraid it'll require a much larger community for a portion of it to decide it's worth a shot. &gt; More projects using it I'm actually pretty amazed that a language only 3 years old (starting from 1.0) is already (1) so well known and (2) used in so many different places. I would also note that as a C++ developer, I rarely benefit from others C++ projects. Most C++ projects I've worked on depended on Boost (or a subset of it), and that's it, for two reasons: 1. Integration of 3rd party C++ code is just downright **painful**, 2. Undefined Behavior is downright scary, and I'm not that trustful. I still remember chasing a bug in Oracle's C client library (company was using Oracle databases), and frankly diagnosing memory corruption in 3rd party code is not my idea of fun (and years after reporting the bug, I still hadn't heard anything about it past the acknowledgement it existed). On the other hand, in Rust it's so painless that even though the ecosystem is much smaller, I'm using *more* 3rd party libraries. 
The large amounts of coincidental complexity in C++ make it bad for learning foundational knowledge. When learning as you go, you have to wonder for every non-obvious design choice whether it's done for some deeper, fundamental reason or whether it's just a fault of the language. C++ being C++, it introduces a lot of noise into the learning process from bad design. Noise, which in turn takes up time that could be spend on more productive learning.
Rust could learn the value of keeping the language spec simple, from C. But...maybe too late for that!
Maybe you should try out [mypy](http://mypy-lang.org) some time. You could compare it to Flow/Typescript for JS, in that you write type annotations that will be statically checked for correctness.
Don't forget move constructors, the reason we can't have self-referential structs.
imo I don't think inheritance is the challenge with guis in rust but - most gui object hierarchies are written as bidirectional graphs - use a lot of call backs and mutable state And the borrow checker points out how hard it is to get this right. As for inheritance, I have much preferred working with PyGTK to PyQT because I never had to use inheritance for writing my apps, instead I could use composition.
Another way to do this with similar behaviour would be to have a `trait Opcode` and have each variant as its own type.
&gt; 80% FP as Ocaml/Haskell Not true at all.
&gt; So my suggestion is to explore this kind of frames that are columnar but the whole data set is composed by multiples of them This mean introduce something like Pages? But now I need to manage the memory much more. What I could use, a btree for it?
They’re actually not necessary for self-referential types. The real problem for self-referential types is you want to disable moving, &amp;mut almost gets you there but for its mem::swap capability. So as part of the async/await infrastructure a new Pin type is being introduced that allows self-referentiality. There’s even been talk of promoting Pin as a first class &amp;pin reference type. 
So it would've been a different story in Rust case, no? Feature stabilization has nothing to do with edition release, so even if initially planned "Rust 200x" gets released in 2011, users and companies will be able to use features which are ready (as in stabilized) by 2008/2009.
The problem is this feature was marketed as part of the edition release. And now message "here is Rust 2018, but without async/await" will be heard as "Rust progress is not as fast as was promised".
Rust has a similar type system with both of those, (modified HM), ADTs, referential transparency (sort of, you can write code without `mut` but it's much harder), higher order functions, `match` and more. However Rust is missing HKT, composition with `fn-traits` don't seem to be able to be stabilised in the near future and Rust is still fundamentally an imperative language with functional programming features. 80% sounds about right, maybe a bit hugh when you consider the features most users end up using.
I did not actually say that. I said the feature has had no bugs with NLL, but not that it should have been delayed.
\`std::env::real\_home\_dir\`
What alternative to Redis would you choose?
I am aware of some gradual type systems for Python in some shape or another, but the issue is most libraries are not typed, and the standard library itself is not either. Kind of the case with Racket vs. Typed Racket. The thing that bugs me the most and kills my momentum in the last proper Python project I had was that I always have to read the documentation very carefully to know what to pass where and when. Doesn't help that you can do \`None\` whenever(i.e. no proper \`Option\` type). After a while it felt like I had to keep my entire project in mind in great details to be productive, which I'm terrible at. I absolutely admire people who create and maintain very large Python(or any other dynamically typed languages) projects, cause my mind just simply can't catch up with what's going on in that environment.
Ok, I tried it, looking at both [the edition guide](https://rust-lang-nursery.github.io/edition-guide/editions/transitioning.html) and [nrc's blog post](https://www.ncameron.org/blog/how-to-help-test-the-2018-edition/). I've manually added `#![feature(rust_2018_preview)]` wherever appropriated, and changed `Cargo.toml`. Now, of course, the project doesn't compile anymore. My `use` statements don't work. I could find out how they work now for sure, but using `rustfix` was suggested, so I tried it. Here's the question though: Should just running `cargo +nightly fix --prepare-for 2018` or `cargo +nightly fix` fix stuff? Because it very much looks like the first thing rustfix tries to do is compile my project, and of course that fails. Or is that just a case that rustfix can't fix? If so, I'd open an issue because the error message that tells me "doesn't compile, but rustfix can't fix it" is nowhere to be seen.
It looks interesting, specially because document the ideas behind. Still, like most project about data stores are concerned by how manipulate gigabytes of data. I'm looking to be the sqlite of that kind of software. 
Please do! I'd be happy to buy one or a few 
&gt; A much larger community It seems that Rust is light years away from C++ or even Go. https://trends.google.com/trends/explore?q=%2Fm%2F0dsbpg6,%2Fm%2F0jgqg,%2Fm%2F09gbxjr
Indeed, it is a different story specifically because editions are not tied to features-sets. There are tentative schedules, but for example `async`/`await` which was originally planned will not make it for the opening and will arrive later (hopefully still this year). So, in Rust, editions are less about new features and more about deprecation/removals. That is, the only thing that a Rust edition really does *mechanically* is breaking backward compatibility syntax-wise. It has other benefits, of course, marketing/coarse-grain references for example, but those are more about communicating and less about writing code. 
Hey! I have been working with this language for about a month now, and although it has a steep learning curve, I'm enjoying it. This is my first functional program, criticism would be appreciated, check it out [here](https://github.com/NerdyPepper/taizen). It uses a wrapper for curses called [Cursive](https://github.com/Gyscos/Cursive) (really well documented, kudos to gyscos). I am looking to write GUIs in rust in the near future. Any pointers?
This is bad b/c writing shit like 100*MS * 200*MS will typecheck, but is completely nonsensical in terms of units.
&gt; referential transparency IO? Random numbers? &gt; Rust has a similar type system with both of those [..] In some ways (HKT for example), Rust doesn't have features from Haskell 98. I like Rust but one would have to ignore all that has happened in Haskell over the past 20 years to say that Rust has 80% of the FP features of Haskell. I presume something similar can be said of OCaml but I'm not as familiar with it as I am with Haskell. Yes, Rust has borrowing and ownership which are decidedly not FP features so unfortunately those don't count, even though they are very powerful features. &gt; Rust is still fundamentally an imperative language with functional programming features Yes, I agree! Let's not try to paint a picture of what it's not :). &gt; 80% sounds about right, maybe a bit hugh when you consider the features most users end up using. I suppose the OP meant that 80% of code written in Haskell/OCaml can be written in Rust with small modifications while preserving semantics (although I confess I don't understand what the "At least for me" bit means), which is far from true of the Haskell code I've read and written :D. For example, higher-rank polymorphism is used frequently in Haskell but you don't (and IIUC you can't without implementing _major_ changes) have it in Rust.
&gt; I am looking to write GUIs in rust in the near future. Any pointers? big open area.. seems to me GUIs are heavily tied to languages, so making Rust bindings to C++ Qt or whatever is always going to be a bit messy. Rust is born in the internet age, as such it might make sense to focus on web-interfaces? https://users.rust-lang.org/t/current-state-of-gui-development-in-rust/11643/7 there's efforts to make gui's natively in rust (eg [conrod](https://github.com/PistonDevelopers/conrod)),but I haven't checked how those are theses days r.e. "taizen", nice idea by the way, great to have minimalistic tools to run on low power computers etc 
Well another reason you might want a different service to handle sessions (or other cached data) is so that when you redeploy your Rust service, you don't lose all active sessions which might be a bad user experience.
No, it will not, because there is no `impl Mul&lt;Duration&gt; for Duration`.
Economically speaking it still makes good sense to learn C and/or C++ (I don't like mentioning them together since they grew apart substantially over the years), because the rust job market is still very small.
I'm going through the book atm and I plan on writing my own data structures: stacks, lists, trees etc. 
This is exactly the sort of thing I was looking for! Thanks!
I would try out this wrapper crate for libui https://github.com/pcwalton/libui-rs
I haven't seen anyone complain. I have seen people raise question about why there's suddenly so many minor releases compared to before. Without the given explanation it's not strange that someone might think that the recent rust releases have more issues that need immediate fixing opposed to before. edit: well i just saw the last comment here in this chain disproving nobody complaining. That said I think it's good that the rust team gave this one time explanation about being able to dish out releases faster.
I’m not sure if you’ve seen the [Rust Cookbook](https://rust-lang-nursery.github.io/rust-cookbook/) yet, but there are a lot of things in there that might give you ideas for easy projects like small command-line utilities. Hope it helps!
Hopefully for Rust 2021 or so we can start looking into having a more simplified language again.
I don't believe that's the avenue of advice OP was looking for.
`MINUTE` and `HOUR` definitely need to be included. `DAY` should probably be included. I don't want to see `60 * 60 * 24` scattered through code, with the expected number of typos and miscalculations, for the rest of Rust history. The `SI_` prefix is fine if you're a purist, but everybody is going to know what is meant anyhow. Yes, people will forget that there are leap seconds and DST changes. They'll do that anyhow: omitting an important convenience isn't helping.
Anything less than 2 would be sad :P
Happy cake day.
I second the idea for a Kickstarter for an artist. It absolutely must say "in borrowck we trust" on it.
I believe that the most important thing Rust learned from C++ is: don't be backward compatible with C, instead give users a way to safely interoperate with C.
Your disagreement is immaterial because ncirses underneath does the same thing as this program.
I'm kinda curious if we could implement a parser for a subset of ISO8601 durations as a `const fn` in `Duration::from_str`
This is very out of date and libui is basic to the point of uselesness.
&gt;I saw someone recently describe Rust as a nice balance between C++ and Python.. Actually IMHO, Rust is between C and C++. I believe (pray actually) that in the long run many C and most C++ will be replaced with Rust. Leaving C only for the most lower level stuff (kernels, drivers, etc) and C++ for, well almost nothing. IMHO, Go is the one between C++ and Python, because Go is a garbage collected language.
Placement new. We almost got it.
I've heard a lot of good about [relm](https://github.com/antoyo/relm), but haven't had the chance to try it yet.
&gt; If another soundness issue is discovered in match ergonomics, then disabling the match ergonomics feature, and re-stabilizing it once NLL is ready Why "if another one"? This same comment could've been made at any one of the three previous point releases. But we all know this won't happen. *Ergonomics* is at stake, man! What I think should be high-priority is a clippy lint that could warn about any usage of default match bindings. You could scan your own crate and dependencies. More radically, we could run it over crater to see how bad a rollback would be (but I think it would be pointless). Is anyone working on such a lint (edit: looks like [this](https://github.com/rust-lang-nursery/rust-clippy/issues/2850) perhaps)? I'd help. 
It can be implemented via existing [`FromStr`](https://doc.rust-lang.org/std/str/trait.FromStr.html) trait. You can create PR if you are interested in this approach! But the problem with this will be that `FromStr::from_str` is not `const fn`.
Thanks for the thoughtful reply. I actually agree with many points, I'd especially like to see a "minimum Rust version" tag added to Cargo.toml in oder to better quantify how many crates require what stable Rust version.
Disabling moving is not a problem, it is a potential solution that has distinct requirements and benefits compared to move constructors. Last discussion I saw on move constructors the negative voice were concerned about having non-trivial moves, ie wanting to keep moves at the level of `Copy` and not `Clone`. Does the async/await pin solution support user-created referential structs yet? How do they handle the issue of moving into a non-movable location (whether a `Box` or out of a `new` method and into the pinned stack variable)? It seems like it'd need in-place construction as well.
Let's just say it starts in downvote territory and pulls itself out afterwards, but attention spans being what they are... :)
It's sad but true. The bindings are in a very basic state and have had any commits in two years. Even hello world crashes when exciting on macOS
That’s not correct. Everything goes in 2015 edition unless it cannot, due to compatibility reasons. It will still continue to get features forever.
You’d still need a crate like rental to construct self-referential types, but it can now expose a safe api over them via Pin* types. Safe construction was punted on because the async/await self references will be largely constrained to compiler generated code, or a handful of places in low level futures combinators. 
It's only a selling point in comparison to the constructors discussed here if it's `const fn`. BRB bugging Oli about this ;)
/r/playrust
FutureObj is just a stopgap until Pin is object safe, right?
Modern web services, especially those using Docker or run as “serverless” processes (e.g. Lambda), need to not only be performant and scalable, but memory efficient, low binary size, only consume resources when in use, and be able to move very fast from a dormant to an active state or vice versa. Traditional managed web languages like Java or ASP, while reasonably passing “hot” performance when fully spun up, fail at dynamic scalability, low cost containerization, very fast spin up times, or low memory usage. And scripting languages like Python just don’t pass the performance bar to begin with. Low **fixed** costs are particularly important. I don’t care as much if an operation takes 4 CPU cycles instead of 2, provided I actually need it. What I can’t afford to pay is many megabytes of RAM and hundreds of ms delay just to start a process that should usually finish in 10-20 ms and only process a few hundred kb of data. Not when I want to be able to run them by the thousands, quickly spinning up and down to meet elastic demand, and paying the hosting provider by the CPU hour, RAM and disk usage, rather than for dedicated servers. In fact, the ideal scenario is that the service starts with the start of the request, and terminates with the end of the request. When there are no requests, nothing is running and nothing is paid to the hosting provider; conversely, when lots of requests are happening, an arbitrary number of services can be spun up in an instant. For this to work, the service boot time needs to be very low (milliseconds), far quicker than the warmup time of most web frameworks on the first request. The service also needs to only use the minimum resources needed, with fixed RAM and disk costs being very low, or else they they will overshadow the load-based costs, since most requests are small and quick. But C++ is just too dangerous to build modern web services with. Rust is theoretically the best fit, combining safety and modern patterns with zero overhead design, low fixed cost memory and fast spin up due to no VM that makes for sustainable and scalable containerized/serverless architectute. Golang probably comes second, but Rust is still better. A GC may not be a dealbreaker, but a hungry VM is. Except that as a web service developer, things like manual upcasting, type tetris, and associated verbosity do make it harder to work with the code at the level I need. A systems programmer may need those explicit constructs, but as a web service developer I don’t care, I need macro scalability and low-fixed-cost model much more than manual memory management and micro-optimization down to the CPU cycle. 
I'm not sure I'd agree with you on that. For me, Rust feels quite similar to Python. I'm not sure how to describe it, but it feels like they're both quite natural to write - I don't have to think terribly hard to translate my thoughts into either Python or Rust. OTOH, I've tried to write a little bit of Go once or twice, and it's not felt nearly as easy or fun, because the language is much less featureful.
really? Discoverability is horrendous in python from my experience because there are no static types and there is no compiler helping at all.
The page is SUPER basic (we're open to anyone who wants to do some community web design!), but it's got the essentials. :) We're grateful for InsidesSales.com lending their IT expertise and allowing us to record everything so easily!
https://github.com/LeoTindall/libui-rs This is the up to date version
Noted! I think there's something to that viewpoint for sure. :)
If I may ask, for what?
And that tell a lot about how well done the language is, because it's a non garbage collected language, statically and strongly typed language, with performance similar to C, yet you have a very high level, abstract, duck typed, garbage collected "feel" to it. I was comparing it to C and C++ in terms of runtime performance and applicability to systems programming.
Just as way to learn the language better. It's a go-to non-original project I've used for every language I've learned that helps me get a better grasp of how to construct things using that language. First I wrote all the major data structures in Java. Then I wrote them in Bash (yes - it can be done if you are creative). Then in C++. Then in C (which made me really appreciate Java). Also, to be honest, I don't like the syntax a lot of data structure implementations have - like vectors in C++. Sometimes very general data structures are useful. Sometimes very specific data structures are needed. I also discovered if I threw built-in inheritance out the window in Java I could write much more interesting data structures that have multi-way inheritance by using dependency injection. And then once you have them and they're thoroughly tested, you have them for life. Just some home-made tools for the tool kit.
Just to clarify, rental does not (and will not) use the `Pin` APIs, as the semantics just don't line up right for what rental is trying to accomplish. See [this post](https://users.rust-lang.org/t/rental-0-5-released/17247/3?u=jpernst) for a more detailed explanation of why. You're right about move-constructors though, they wouldn't actually fix this problem. The root of the problem is the borrow checker just isn't capable of expressing the necessary invariants when accessing the fields. One feature that really would make this better is generative existential lifetimes, which I'm pretty sure is something C++ doesn't have either :)
Ah that’s unfortunate last I’d heard they would help rental. 
 trait SiTimeUnits { fn h(hours: u32) -&gt; Duration; fn m(minutes: u32) -&gt; Duration; fn s(seconds: u32) -&gt; Duration; } impl SiTimeUnits for u32 { ... } // Enjoy: 4.h() + 2.m() + 39.s()
Ah, my apologies. I probably misread it / added my interpretation to my words. Thanks for clarifying. 
&gt; we're open to anyone who wants to do some community web design! Would you be interested in the style of [rust.cologne](http://rust.cologne)? I might make it a Jekyll theme
&gt; Stability. 3 years since the stable release, and the Rust language already has breaking changes. This coin has two sides: one is that you can't rely on features that your language provides as a future edition may remove them any time, second is that it allows the modern language to live without cruft... something C++ struggles with greatly. It probably all depends on what you regard some property of your language as: feature or cruft :). Oh come on, this is FUD. Yes, there are breaking changes in the edition and I don't like all of them either, but the whole point of editions is they get phased in slowly in a way that doesn't break backward compatibility. And the [policy](http://rust-lang.github.io/rfcs/2052-epochs.html#the-basic-idea) is that things can't be removed if they weren't deprecated in the previous edition. Check your facts. 
if shipping is this cheap, I'd love to buy some
I’d really like to be a part of this. I have no knowledge of data structures though.
Most of what you mentioned aren't "learnable things". You're comparing a decades old language to a three years old language. Adoption is nothing we can "learn" from C++, we know and do quite alot of things around that and all of the points are being worked on in some form or the other.
I guess when I get started I can make a github repo and send you an invite.
The C++ community is large, but it's also fragmented quite a lot, so the benefits of a large community aren't really there except for the basics.
There is no real overhead to calling C functions from Rust, but there may be overhead associated with converting the data between the two.
There's some documentation on this [here](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir/transform/generator/index.html). The example you give ends up something like this fn main() { let in1 = 5; let in2 = "foo"; let mut generator = { // Actually just a u32 #[repr(u32)] enum __State { Start = 0, Completed = 1, Panicked = 2, Yield1, Yield2, Yield3, } struct __Generator { // As with closures the capture mode is inferred, here it's by shared borrow in1: &amp;i32, in2: &amp;&amp;str, state: __State, local1: f64, // local2 isn't live across a yield, so doesn't need storing. local3: usize, local4: &amp;str, } let __generator: __Generator; // Borrow check has already run, so there's no one to tell us that __generator is uninitialized. __generator.in1 = &amp;in1; __generator.in2 = &amp;in2; __generator.state = __State::Start; __generator }; }
I think that constants are much easier to find and explain. And instead of such ad-hoc trait IMO we better push for custom literals functionality.
If I were you, I'd use a real HTTP parser instead. Real world HTTP is _very_ weird at times.
You can do it, of course, in other languages. But doing it in Rust keeps the server stack simple, may cut down on resource requirements, and reduces the number of different programs and languages your developers and sysadmins have to be familiar with.
Pretty sure it’s a learning exercise 
I don't have anything off-the-shelf in mind. My thinking was that I'd have a broader user management service to be hosted on a several hubs for redundancy, and the service would include session management. There'd be clients at each POP, with caching. I have nothing against Redis. Quite the opposite. It's just that, with Rust, I know I can do just about anything, and I can do it fast and without hogging up a lot of memory.
Would this work for other websites built with mediawiki?
Might be cleaner to make an `arguments()` method that returns an empty list for `Halt` and `Noop` and a singleton list for `Out`.
Couldn't you create a list of the colors and index into it, with some handling for out of bound numbers? 
I’d really appreciate that, thanks!
&gt; (The nightly is always broken to some extent, so I expect a lot of people just shrug problems there off, and I doubt many people use beta at this point; where as, practically, no one except core developers should actually be using nightly) I don't think this is right. A lot of people are using nightly because it's only place you can try out unstable features. For example, everyone writing Rocket-based web apps. 
There's no overhead, since Rust works at the same level as C. There's some struct layout differences, but you can get rid of those by adding `#[repr(C)]` to a struct declaration. The really big, huge, gotcha is that when you are calling C code you are responsible for ensuring that all Rust's invariants are upheld, because Rust has no idea what the C code is doing. You can basically think of the C code as a big `unsafe` block from Rust's point of view. So if the C code can send data you passed in to another thread, make sure that you only pass in data that is Send or Sync. And if it modifies data you pass in, make sure you had exclusive ownership of the data before passing it in. And if you get some data back, make sure you have exclusive ownership of it and know how long it will live before turning it into a form where you can create Rust references to it. Another thing is that Rust doesn't necessarily use the libc allocator. You can change this through a compile option, but this means that if you're writing a library you should not assume that the allocator used by the C code is the same one as the one used by Rust (since which allocator is used will be decided by the author of the Rust binary your library is included in). This just means that if you need to free something allocated by C you should call `free()` in libc to do it, and that if you pass anything to C that it will be freeing later you need to call `malloc()` in libc to allocate it. Of course a nice C api shouldn't be making any assumptions about the allocator either, but many still just assume everyone uses malloc().
On the other hand, *runtime* discoverability in Python is really good. You can `dir(foo)` and see what attributes foo has.
Not that excited about doing someone's homework for them. That said, here's some hints: * Why is `split[0]` never mentioned in the code? It seems like it might be important. * What will the `split` vector look like if there's one or more blank lines in the request body? Is there some better method than `split()` to be using to guillotine the request?
I, and I expect most people, don't write their projects at runtime.
This is a great idea! I’m going to try this out a bit later.
But I expect most pythonistas *debug* their programs at runtime.
I really don't understand fully the point you are trying to make with: &gt; there's a very small subset of things to manually audit as a user: a handful of build.rs, a handful of procedural macros. Both `build.rs` and proc macros are not self contained, they use libraries, often pulling tens of thousands of lines of code (pretty much every proc macro out there does this, pulling `proc_macro`, `syn`, `quote`, and often many others, and build.rs pull `cc`, and often also other libraries). Given that most Rust projects use proc macros or dependencies that use them, and many Rust projects use `build.rs` while almost all Rust projects use dependencies with `build.rs`, I don't think anybody could reasonably audit them for a small to medium size project. Probably not even a tiny project given that tiny Rust projects can often involve dozens of dependencies.
well yes. Most bugs are discovered at runtime. But I don't call an error in writting a property or method name a bug. I call that a typing mistake. 
I remember seeing discussion about this a little while back and it seemed imminent. By "We almost got it" (as opposed to "we've almost got it"), do you mean that it was decided against and is not being worked on / planned for near release anymore?
PyCharm definitely makes up for any compiler errors for me. It's almost the best IDE experience I've had next to writing Java in IntelliJ. I've found documentation just as easily searchable as it is for Rust, and libraries like `request` have everything just named what I expect them to be. Not sure how to say it.
yeah but that is not discoverability of the python language. That is discoverability if you use a whole slew of extra tooling. By that standard any language with enough tooling is equally discoverable.
Hm, that's fair. Still something from the python community I feel like we could do better at! When you put it that way it seems much more achievable, though.
If you include tooling nothing beats visual studio + C#. It can literally auto detect when you use classes and methods from a package you haven't even installed yet. And ask you do you want to add this package to your project? It's amazing.
I've tried mypy, and I wouldn't recommend it. It's trying to force a paradigm that doesn't fit python onto python. It supports maybe 90% of what you want to do in any project, but then you'll hit something that is just not representable in their type system. Even if it's something that makes perfect sense to do design wise, and works perfectly in regular python, it could just not be supported. I'd much rather work in a language like Rust with a type system designed from the bottom up to work with the language than with python and a tacked-on semi-finished typing system.
No one is currently working on it, and the last syntax which was planned was reverted since it ended up being really unreliable. I think right now it's either blocked on other things or just not high priority enough. It isn't trivial to implement in the current rust compiler.
This is pretty neat! I definitely do not need to be enabled like this.
I wonder if you could use Servo as a library to make UIs and not have it as expensive as Electron. Would using its Rust API be significantly faster than feeding it HTML/JS/CSS text files?
I've been working on this project for the last few weekends, and wanted to share it in order to see what others thought. I've recently been working with Go's `net/http` in order to build a simple web service, and have been really impressed at how simple its API is, and yet how widely adopted it has become. I created aitch as an attempt to recreate some of this API in Rust. aitch aims to build on top of the `http` crate to provide a set of types for describing HTTP handlers, middlewares and request/response bodies. It provides two different back-ends: hyper (which allows handlers to process requests asynchronously) and tiny_http (which only supports sychronous requests). The project has grown a little in scope since starting as a `net/http` clone, as I deviated from the Go API in order to provide conveniences like a `Json&lt;T&gt;` body type. It still aims to be simple and light-weight, and hopefully it succeeds at that!
Great article! It's wonderful to see GPU work in Rust and I definitely have a soft spot for ray tracing. One note about the sampling, however. The correction /u/anderslanglands brought up is an important one for using cosine weighted importance sampling, but as far as I can tell, you actually aren't using cosine weighted sampling. The samples you are generating are in fact uniformly distributed across the hemisphere. See also [MathWorld](http://mathworld.wolfram.com/SpherePointPicking.html), whose equations 6, 7, and 8 describe your sampling method. That said, switching from uniform sampling to cosine weighted sampling is quite simple, having very similar code (which is probably where the confusion comes from). Instead of generating `cos(elevation)` uniformly and calculating `sin(elevation)` from that, you generate `cos^2(elevation)` uniformly and calculate `sin(elevation)` (and `cos(elevation)`) from that: let y_squared = random_float(random_seed); let y = sqrt(y_squared); let sin_elevation = sqrt(1 - y_squared); See for example [smallpt](http://www.kevinbeason.com/smallpt/) lines 57 and 59, which I believe are doing cosine weighted sampling roughly this way. In that code, `r1` is the azimuthal angle, `r2` is `sin^2(elevation) = 1 - cos^2(elevation)`, and `r2s` is `sin(elevation)`. Another way to look at this approach is as picking a point uniformly on a disk and projecting it upward to the sphere (see also Handmade Hero's fairly approachable discussion ([1](https://guide.handmadehero.org/code/day438/#4208), [2](https://guide.handmadehero.org/code/day439/#1029)) of cosine weighted sampling, which more directly takes this approach). When sampling the unit disk (i.e. `x` and `z`) with a polar method, the radius (i.e. `sin(elevation)`) should be distributed as the square root of a uniform variable ([MathWorld](http://mathworld.wolfram.com/DiskPointPicking.html)). Then, you can calculate `y` by upward projection, by finding `y = cos(elevation) = sqrt(1 - sin^2(elevation))`.
Currently it is an optimization boundary, eg. function calls are never inlined. Other than that, it's the same as any other function call. JNI issues usually stem from marshaling or copying method parameters, which isn't an issue here.
I think vector/stream of frames will be better, no need for btrees.
Modern linkers catch ODR violations, regardless of whether the standard requires it. Only weak symbols (templates and inline functions) can have multiple definitions appear at all (the linker will complain if there is more than one in a translation unit and if a definition of the same function appears in multiple translation units), and for those it will complain if the definitions are different. Two functions have the same symbol if they same monomorphized signature and name.
Yes it's terrible to be able to do 2s * 1s but not 2 * 1s, but that's Go not Rust.
&gt;it's not strange It's not just strange. It's ridiculous. This isn't the 70s. Everyone with any experience in this industry knows this is ordinary behavior for a young, successful, and well-managed software project. Fixing problems is not a problem. If no one knew to complain about the bug until it appeared in the fix patch notes then it really can't be that bad.
I have no experience with rust (other than following this sub and twitter), but I think this is going to be really cool for people who muck around with HTTP based services in both languages, since it greatly reduces the cognitive load when you switch back and forth. Go really nailed the HTTP API, so this is a win for both sides. My suggestion here, should you have the time and interest in such a project, and should such a thing be feasible, is to get a full fledged router (a la https://github.com/valyala/fasthttprouter ) that works using aitch APIs. That would give you a very thorough test case for aitch, plus a router which can blow everthing out of the water performance wise. This is in my opinion the only failure of go's net/http package: not providing a usable router (i.e. one which supports parametric resources out of the box). I'm rooting for the rust ecosystem, because we need a fallback for that 1% of jobs where go feels a bit awkward :). Upvoted.
I like the trait idea, but would prefer proper names for the methods. Like `4.hours()` etc.
&gt;I think that constants are much easier to find and explain. Scala use that approach (like `10.seconds`), and it feels pretty natural. Maybe for people coming from Go the multiplication is more natural, but for some others it looks a bit hacky. &gt;And instead of such ad-hoc trait IMO we better push for custom literals functionality. `sleep(10s)` is pretty nice, but I'm not sure if the extra complexity in the language is too big for this. 
Fixing DAY to denote 86400\*SECOND is probably fine for Duration. But if Duration should ever be used to represent a time *interval* then that is going to break horribly on DST changes. There is a difference between a duration and an interval even if naively both appear to represent a time delta.
If anyone wants to live in the unsafe world, I actually put together an attempt at Mac apps in Rust using the ObjC layer: [https://github.com/ryanmcgrath/shinekit](https://github.com/ryanmcgrath/shinekit). (Beware dragons)
Haha oops didn’t know that. To clarify, I meant I feel it’s a TUI when it *takes over the whole screen*, which is something that some `ncurses` programs do.
More people could learn Rust, then the community and adoption grows. Definitely learnable :). But yeah I get your point, this was partially just a collection of things that I like about C++ that Rust hasn't.
I recently set out to use libui to build a simple dashboard and came to this conclusion too. I ended up switching to [tether](https://crates.io/crates/tether) (a simple binding to the system web view component) which worked well for this purpose. 
As someone that has been working with Futures heavily since the first release, I’d just like to add that I’ve been consistently impressed with not only the quality and readability of what is essentially experimental code, but clear and consistent updates on what must be a very rapidly moving feast. Hat tip to Alex and the rest of the team for an excellent job. Keep up the great work!
&gt; the whole point of editions is they get phased in slowly in a way that doesn't break backward compatibility. The *whole point* of editions is to conduct breaking changes in an orderly fashion in the first place. Yes, there is also a marketing aspect and a "tooling/docs are consistent" aspect, but those two aspects are minor, at least for me, compared to the breaking changes. You can market new releases or make docs consistent without editions as well. Quoting the linked document (emphasis me): &gt; When opting in to a new epoch, existing **deprecations may turn into hard errors**, and the compiler may take advantage of that fact to **repurpose existing usage, e.g. by introducing a new keyword**. This is **the only kind of breaking change** a epoch opt-in can make. So that document says that stuff may only be removed if there was a deprecation warning in the prior edition. So applying the wording of that document, to my most disliked edition change, for the `try {}` RFC that means that usage of the `try!` macro on the 2015 edition must give you a deprecation warning, only then the existing usage can be repurposed and only then `try!` may become an error on the 2018 edition. I don't see such a deprecation warning. It's not decided yet whether `try!` shall become a hard error or whether it shall still be recognized, by a dedicated feature for it in the parser. So maybe that will resolve itself. That being said, *right now as it seems*, the 2015 → 2018 breaking change in Rust is managed much better than the Python 2 → 3 breaking change. I'm saying "right now as it seems" as the 2018 edition isn't finished yet so you always have to *assume* some resolution of the currently open discussions.
&gt; Multiple independent compilers Besides cross-checking the compiler implemention I don't see the appeal. Some implementions of the C++ compiler were likely born out of necessity to support other platforms, like MSVC on Windows. While the Rust compiler solves cross-platform within the same implemention.
And the program could easily just use cargo install under the hood.
Yes, yes, please yes. This is basically the most practical approach these days as far as I can tell. Servo is still basically an experiment as far as I know but I bet they'd love a user with a practical purpose.
Rust doesn't use a VM the way Java does. It might incur some penalty relative to C because the compiler isn't aware of certain optimizations, but that's to be expected in any FFI.
&gt; You can basically think of the C code as a big `unsafe` block from Rust's point of view. You don't even have to imagine this, the language forces you to put any calls to C code in `unsafe` blocks.
A look at [the source](https://github.com/NerdyPepper/taizen/blob/0ad9e725683eda9a76b5ba75bbc9a4f4bf7ab29b/src/content.rs#L16) suggests that if you replace the Wikipedia URLs with another MediaWiki instance then it should work.
[Thanks!](https://github.com/utah-rust/utah-rust.github.io/pull/11) We're using cobalt (I might be a little biased) but it wasn't too hard to adapt from jekyll. One day I'll move on from CLI-WG stuff and get back to adding features (like themes) to cobalt. 
In that case I don't expect it to catch anything: 1. If a Rust function is neither inline nor generic (you're not using "weak symbol" the same way linkers do AFAICT), *it can't possible have* multiple definitions (unlike C++, you can't get the same Rust symbol from *different* source definitions - we're much more in the camp of "compilation creates normative identities de novo"), so where would traditional ODR help? 2. A generic function in `a` can already be instantiated in `b` and `c` today and we don't have to check the two instantiations *because we know* `d` can use `b` and `c` together (through trait coherence &amp; whatnot). 3. If we did want to apply something like ODR between instantiations at link time we would need to be able to check definitions for equivalence, which AFAIK linkers can't do. 4. You don't need *any code generation* in `a`, `b` or `c`, only type-level choices that were recorded (maybe something like a computed constant array), you could be combining incompatible types entirely within `d` and not realize it unless you checked *everything* `b` and `c` did for compatibility.
So how is the model? struct Frame { kind: DataType, layout: Layout, data: Vec&lt;Vec&lt;BytesMut&gt;Vec&gt;, }
I dispute this is a use case we should support. Regardless, my point is that broken stuff in nightly isn't really meaningful, because well... its nightly. The beta is much more valuable in terms of preventing regressions.
Yes.
&gt; I kind of hope we can continue to get away with requiring people to update their compilers regularly. I know some folks are uncomfortable with this. While there's a *lot* less of it these days, I still see people talking about crates that only work on nightly and this makes me sad.
If you want to go straight to working code: https://gitlab.com/mrman/rust-component-pattern-example/
From the amount of discussion on the PR, it seems like this should go through an RFC instead.
Also see: https://doc.rust-lang.org/nomicon/ffi.html The answers to your questions really depend on the C library you're interfacing. For example I'm putting the finishing touches on a FFI for Duktape (a JavaScript engine written in C) and it has not been straightforward. For me the biggest hurdle was figuring out error management. Specifically, Duktape uses `setjmp`/`longjmp` which is a huge issue since "it's undefined to unwind past an FFI boundary such as a `pub extern "C" fn`" (see [this thread](https://internals.rust-lang.org/t/support-c-apis-designed-for-safe-unwinding/7212) for more info). [I shamelessly stole `rlua`'s solution](https://github.com/SkylerLipthay/ducc/blob/d53a9df/ducc/src/util.rs#L47). I don't expect anyone to understand the code but note that performance suffers in the name of safety. So while there is *ideally* no overhead in writing an FFI, in safe practice there is indeed overhead. And after all of this there still remain some open questions about the safety of my crate and how things will pan out with future versions of Duktape. Anyway there are innumerable "gotchas" and I'm convinced you need to be an experienced C developer to write a sizeable FFI. There are steps that Rust can take to make coding an FFI a safer, easier, more performant experience (these are known by the team of course), but ultimately there will always be friction when trying to map one language's paradigms to another's.
The point was more that it's not really idiomatic Rust to hang a ton of functionality off primitive numeric types like that.
&gt; As for inheritance, I have much preferred working with PyGTK to PyQT because I never had to use inheritance for writing my apps, instead I could use composition. Huh. I don't really have a strong preference, so I much preferred PyQt for Qt being more "batteries included" over the mild irritation of occasionally having to subclass rather than `.connect()` to handle an event. For example: * Toolbars and panels come with drag handles and a context menu for hiding/showing them right out of the box (With support for declaratively specifying which edges of the window a given panel or toolbar may reside and whether they're allowed to float.) * The main window class can serialize or restore its state with two function calls (one for top-level geometry, one for panels and toolbars) * It comes with a key-value config file store with deferred/batched commit that automatically puts the config files wherever is platform-appropriate and supports system/user and vendor/product precedence overlaying. * I don't have to reinvent seemingly fundamental bits of the MVC system, such as "When I click on a checkbox inside a list widget, the default behaviour should be to toggle it" * List widget multi-select is just an option to select in PyQt while, in PyGTK, there are blog posts with non-trivial code snippets dedicated to reinventing it. * GTK+ arbitrarily splits up the different types of views used for a file manager's main widget (and other things which ape the design) across multiple widgets, while Qt makes them selectable modes on the same "list view" widget (ie. list of icons, list of items, list of rows), which is still distinct from the full-blown table widget in that a list view may have multiple fields to each row, but it's still semantically a list and you're just displaying different subsets of each record in different ways. These are just a few of the things I had to reinvent while working with PyGTK... not to mention that, for all the complaints about Qt's MVC APIs needing better documentation, having corporate backing has lent Qt much better API documentation than GTK+. (As in "Qt's MVC APIs may be more poorly documented than the rest of Qt... but GTK+'s MVC APIs are proportionately more poorly documented than the rest of GTK+... and, yes, I *have* actually used both.)
&gt; That being said, right now as it seems, the 2015 → 2018 breaking change in Rust is managed much better than the Python 2 → 3 breaking change. It's a design goal that you'll be able to link Rust 2018 and 2015 crates against each other, so there's no comparison there.
Cool! Jekyll is of course just an implementation detail. The really important piece is the animated logo! :)
/r/playrustservers
Won't be inlined normally, but BOLT may be able to inline them.
Just curious why `-E` is not the default? I think allowing require should need a flag.
Reminds me of the Sneakers (1992) decryption effect described and implemented by someone at https://medium.com/@bartobri/the-movie-based-terminal-effect-not-yet-recreated-by-hackers-46e9ca241bc9. Cool effect; it’s great seeing that writing CLIs can be quick and with great success in Rust!
Thank you. I was on my phone and a little lazy, so thanks for taking the time to look through the source for me/us. Pretty cool, this means that you can use it for the Arch wiki etc. Or your own personal wiki if you use MediaWiki. Makes the usecase quite a bit more spread.
Reddit doesn't support fenced code blocks, so your code is *really* hard to read.
The word you're looking for is "variant", not "value". Individual variants are not types, and so you can't do this directly, as others mentioned.
There's been talk of this, but no total design has come up. https://github.com/rust-lang/rfcs/pull/2495 is the latest possible design. We'll see! &gt; What are you supposed to do if you have multiple projects you work with, which compile with different versions of rust? `rustup` makes it really easy to switch when you need to; I use overrides liberally to set stable vs nightly on a per-project basis, for example.
&gt; In some ways (HKT for example), Rust doesn't have features from Haskell 98. One interesting thing about Rust, and I don't know *that* much about the history of Haskell, is that (in my understanding) we're gaining type system features in the complete opposite order Haskell did. We got typeclasses, then GATs, then (maybe) HKT, and Haskell did the opposite. &gt; Yes, Rust has borrowing and ownership which are decidedly not FP features so unfortunately those don't count SPJ said last week that Rust was the first language to make linear types usable. I don't know if linear types count as "functional" to you, but a lot of functional languages sure want them...
&gt; It's not decided yet whether try! shall become a hard error or whether it shall still be recognized, by a dedicated feature for it in the parser. I'm not aware of any desire to do this by the team; it's not in the plans for Rust 2018 at all as far as I can tell.
When in doubt, open an issue. We always prefer too many issues to too few. (I think this is a case that rustfix can't handle yet)
Sorry haven't read the full article yet, I just wanted to mention that so much bold text made me overwrite your CSS with `strong, b { font-weight: 400; }` before I even started reading the second paragraph.
Yes, /u/e-matteson, please indent your code with four spaces
Are you planning to open source your query language? I use Rust and kdb+ on a daily basis and would love to use an open source query language with the ergonomics of q for ad-hoc data analysis. I'd be up for helping to test and/or contributing in the future.
I have not given it much thought. It will definitely work for different languages, by replacing [`en.wikipedia.org`](https://en.wikipedia.org) with say, `sv.wikipedia.org`. I can see it being really useful to view arch wikis!
Hey thanks a lot for letting me know! I thought bolding stuff was helping people who wanted to skim but maybe it's just more noise than anything else. [EDIT] - I edited the article to remove a lot of the unnecessary emphasis... If anyone knows a good Hugo theme with less noise (I'd love something more minimal), please let me know and I'll see if I can switch to it.
I have tried the following libs so far: gtk-rs: too vast, pretty hard to understand for a newbie like me, lacks a widget to display walls of text kiss-ui: probably the best among the ones I tried, lacks a widget to display walls of text. conrod: it lacks documentation, outdated webview bindings for rust: not exactly a GUI libui-rs: as mentioned by u/frequentlywrong, its basic to the point of uselessness
There are no good options. Building a gui library is a giant task and requires a team of people. Many lone stars have attempted it and all are far off or have given up. 
I love terminal apps and would love to see more in the future! Please dont forget us terminal-lovers! :)
&gt; Rust has a similar type system with both of those, (modified HM), ADTs ADTs are not a functional programming feature. &gt; referential transparency (sort of, you can write code without mut but it's much harder), Not distinguished by types/monads in the way that typical code in Haskell is. &gt; iterators Also not a functional programming feature. &gt; 80% sounds about right, maybe a bit high when you consider the features most users end up using. Not true at all. I use recursion schemes and first-class support for linked lists all the time in Haskell/GHC. The former is as far as I know completely impossible in Rust (as of writing). 
&gt; I don't know if linear types count as "functional" to you They are not.
This subreddit is the right place to find other people interested in rust. However, you will probably need to provide more details about the project. What does your server do? Why is the reimplementation in rust necessary? Why do you want to use rocket (Keep in mind rocket currently only compiles on rust nightly, which sometimes has breaking changes. This might be a problem so maybe actix-web would be better.)? Do you have a link to your running service or a github repository ?
&gt; And instead of such ad-hoc trait IMO we better push for custom literals functionality. We'll have to agree to disagree then. Given that the functionality can be achieved quite elegantly with extension traits, I see no compelling reason to add custom literals to the language: 1. There's a cost to features, in terms of complexity of the language and the implementation, and I don't see eliding `()` as sufficient justification for a whole new functionality. 2. Custom literals are very limited in scope, limited as they are to operate on literals, while extension traits can already do all that and more, operating on any value. The only thing that extension traits do not allow (yet) is compile-time computation. I'd rather we push toward conditionally `const` traits which would be widely applicable rather than introduce a niche feature like custom literals to "plug the gap" in the mean time.
Iterator is the Rust way of doing folds; I think itertools might have other recursion schemes. It can also do map and other high-order operations typically used in functional programming.
:(
Just as an FYI, [radix-router](https://github.com/SunDoge/radix-router) is an initial attempt to port the Go router [HttpRouter](https://github.com/julienschmidt/httprouter), which is the basis for fasthttprouter fork you linked to.
You are probably looking for the /r/playrust subreddit.
Wrong sub! You're looking for /r/playrust 
Is there a work in progress branch of hyper/tokio that is being ported to 0.3?
Great, thanks for the quick response, I just wanted to be sure here is the right place.
Since `try` will become a keyword (unfortunately; I liked `catch { }` better myself) `try!` will not parse as a macro invocation, unless developers add a hack to the grammar.
That is essentially dead though.
&gt; I don't know that much about the history of Haskell, is that (in my understanding) we're gaining type system features in the complete opposite order Haskell did. We got typeclasses, then GATs, then (maybe) HKT, and Haskell did the opposite. So Haskell 98 had both type classes and HKT (at least in some form, they've added several more kinds since then). Type families have been relatively recent (2008 - ...). &gt; SPJ said last week that Rust was the first language to make linear types usable. I don't know if linear types count as "functional" to you, but a lot of functional languages sure want them... SPJ is very kind :). Have you had the chance to read the [Linear Haskell](https://arxiv.org/abs/1710.09756) paper? They do offer a comparison with Rust and they talk about how Haskell needs something different because they're concerned with optimizations related to stream fusion instead of in-place mutation. They also offer a way to emulate borrowing within that system, although I confess I don't quite understand that bit. There is a Linear Haskell PR submitted to GHC right now. There was also a paper related to RAII in OCaml which I understand is closest to C++ style RAII ([Resource Polymoprhism](https://arxiv.org/abs/1803.02796)) although I'm not sure how far that has come along in implementation.
Weird that Gtk lacks such a widget. Are you sure you can't use a Gtk Label or a Gtk Text box?
Writing an efficient and usable router is definitely something I'd like to do for aitch. There's currently a poor imitation of net/http's ServeMux included in the crate, but I don't expect it's usable by more than the simplest applications. I wasn't aware of fasthttprouter or radix-router, but I'll take a look and see whether they could be adapted! My hope with aitch was that these kinds of extensions could be added in thirdparty crates.
As suggested in the comment above, I'll give some details on the project here on Reddit. So last year I participated in the Google Summer of Code to tackle the problem of outdated firmware running on routers. While this is easy if everyone runs exactly the same image, it's far more complicated for customized images. So I created an "upgrade" server for OpenWrt, an operating system for internet facing embedded devices like routers. Problem is you can't simply run \`apt update\` to install new software as the entire operating system is [squashed](https://en.wikipedia.org/wiki/SquashFS) to fit in the tiny storage chips, often 4-8MB, an upgrade therefore requires to reflash the image. A possible solution is to let the client (router) request device specific images from the server containing all desired packages and flash the resulting firmware. While this may sounds easy, I had to solve various unforeseen challenges which eventually resulted in a working but far from optimal version. Eventually I hope this project is officially accepted by OpenWrt to offer convenient updates for everyone. To reach this state it need plenty of refactoring which I'm currently working on. The other week I saw a [great talk](https://www.youtube.com/watch?v=QS8mrbAPLJc) about Rocket and as I want to learn Rust anyway, I though that might be a good project to start with. So the server side basically access a PostgreSQL database and requests images which are then build build. Once created, a download link is responded to the client. Some validation and caching is done to check if the request can be handled. That's all, easy. A currently active server can be seen [here](https://ledeupdate.planetexpress.cc/), however the more recent changes are in [this](https://github.com/aparcar/attendedsysupgrade-server/tree/meta-builder) unfinished branch focusing the worker. I've honestly been a bit overwhelmed by the complexity of last years project as it introduced so many new topics. For sure various parts are poorly designed, I'm happy for any comments or collaboration on that.
&gt; The parser is intentionally quite permissive in the input it accepts, skipping over any erroneous bits and trying to soldier on instead of stopping at the first error. I've found this approach works pretty well in practice because most gcode programs are computer-generated and handling parser/syntax errors on an embedded device is hard. This seems dangerous, if anyone might use it in something that will actually control moving hardware. (Edit: okay I get it people, I probably misinterpreted what this meant. Read on if you want something that I thought was an interesting solution to a problem that may not in fact exist.) Have you considered an approach where you make the error handling pluggable, so you can use the same code on the embedded device (with fail-fast error handling) and then have a separate tool (or website, if you compile the Rust code to Webassembly) that uses the same code but provides feedback on the errors? This is a technique seen frequently in web development, where the frontend does validation and gives users immediate high-quality feedback, and the backend performs the same validation but doesn't attempt to provide good errors or recover after the first error (because the frontend should already have caught any incorrect input, except in cases of bugs or malicious users).
&gt; ADTs are not a functional programming feature. I know. But it is commonly associated by people not in the functional programming community to be. &gt; Not distinguished by types/monads in the way that typical code in Haskell is. True. And to be honest, when people refer to FP in Rust, they are more just referring to OCaml like code than Haskell like code. &gt; Not true at all. I use recursion schemes and first-class support for linked lists all the time in Haskell/GHC. The former is as far as I know completely impossible in Rust (as of writing). Most Rust users. **Not** most Haskell users. I think we agree mostly. My original comment was quite poorly written so it may have caused some confusion. See my reply to the other reply.
I think we agree, and that we are just saying the same thing from 2 different perspectives. What I thought OP said about 80% as FP was about the feature set Rust users ended up using, not really about how much of Haskell is in Rust. Regarding referential transparency, I suppose Rust is more like OCaml than Haskell in this regard, where if it was to be considered a functional language, it won't be a pure one. There are obvious practical reasons for this and Rust is an imperative language at its core. 
&gt; WOuld it even be possible to automate parts of the porting? https://github.com/immunant/c2rust
GTK is actually rather easy to use with Rust. The widgets you're looking for are ScrolledWindow and TextView.
By "permissive" I mean it can be quite forgiving syntax-wise, so if you include invalid characters they'll be ignored, and a `X.5` argument will be interpreted as `X` followed by the number `0.5`. Internally there's a proper lexer which breaks input up into tokens (e.g. `G`, `M`, and numbers) and the parser will follow the gcode grammar. The major problem with trying to "validate" `gcode` is that the programming language is only semi-defined, with different manufacturers creating their own variants and assigning different meanings to different g- or m-codes and arguments. This library just gives you the tools for turning a bunch of text into more structured data, you can think of the `gcode` crate as handling the *syntax* side of things while leaving actual semantics and interpretation for the user. &gt; This seems dangerous, if anyone might use it in something that will actually control moving hardware. I actually disagree. The company I work at builds CNC machines and you always have physical measures in place to ensure nothing bad can happen. Typically these are things like limit switches to prevent travelling past the end of an axis. When interpreting gcode programs, you'll also apply your own basic validation logic to ensure things (e.g. feed rate or spindle speed) stay within pre-defined "safe" thresholds.
The general tone of the responses to these types of questions is disappointing. While it's great to suggest safer alternatives, many seem to refuse to provide an unsafe solution for which OP was asking simply because "if you don't already know, then you shouldn't doing it". Not everyone puts the same value on safe code. Some people really do care about squeezing out that last bit of performance and couldn't care less about the dangers of unsafe code. There's no need for the insults from the safety zealots.
Any takeaways that might apply to other embedded parsers?
Cool idea, there is no better way to learn a new programming language than spending time with it
Your link to stuartsierra/component is broken, and without that, I'm not sure exactly what you mean by component in this context. Do you mean something like an actor ala actix?
To the best of my understanding you are indeed supposed to use `.context()` on every `Result`. However, the inner `fmt!()` should ideally be replaced by an `Error` and `ErrorKind` pair. Setting that up requires a bit of boilerplate, but there's talks on improving that through macros. The resulting code would look something like this: ``` fn foo() -&gt; Result&lt;(), MyError&gt; { do_task()?.context(MyErrorKind::TaskError); Ok(()) } ```
[removed]
If you want to add examples of projects using your crate you can put in https://github.com/etrombly/sandbox . It's firmware for a mechanical zen garden sandbox.
The typical way you write a parser is to generate an Abstract Syntax Tree, but that's not really feasible in an embedded environment because you can't guarantee the presence of an allocator. It took a bit of experimenting before I managed to change my way of thinking and write a parser that'll generate things on the fly (streaming) and can work entirely on the stack with borrowed data. The biggest issue I found was having limited memory to work with. The gcode language is really easy to parse because it's (mainly) line-based and each instruction is effectively independent from the others, making it really easy to create a streaming parser. On the other hand, parsing a full programming language would require recording lots of metadata and either dynamically allocating memory to store the AST or continually recalculating things.
That's quite impressive, it's nice to see other people using my library for their own projects! I'd consider this version to be a massive improvement over my previous approach. After working on firmware for a CNC machine at work I've got a much better idea for how you consume gcode. If you ever use the `0.3` version of `gcode` in your projects, let me know how it goes and if there are any things which could be improved.
Hey sorry I just fixed the link -- by component I mean literally any big piece of your code that can handle it's own problem domain -- it's a super vague concept, but in general components start, and run, and do various things... A component *can be* an actor, but it doesn't have to be. The term "actor" is much more loaded, and generally means communicating relatively-lightweight processes that share memory by communicating in my own mind. A component *could* be an actor, or it *could* run in a process, or it *could* run in a green thread or whatever, or as part of an entity-component system (as is used in game systems). I guess what I'm trying to say is that the component is just a chunk of related code in your program -- "actor" isn't the right term because it prescribes too much (at least when I hear it). Like think of all the code you might have in a system that's related to sending emails. If you're in a language where OOP is discouraged, then all those functions would likely find their way to the same module. If OOP is encouraged, they might find their way to the same class. "component" in the way I mean it is a way of bundling that same functionality under an object (I guess a class, necessarily), that runs and takes care of all those related functions in one "spot", persay -- A `Mailer` component for example. I like this tiny dash of abstraction because it's usually easier to think of things in terms of "is the mailer running" or "is the mailer configured correctly" or "did the mailer log the failed retry" rather than "did I pass the right configuration to that one function call that one time from the web handler". It can of course go wrong and then you end up with ComponentFactoryInitializationBeans.
I'll work on updating it soon. I'm on a business trip, so can't test on the hardware until I get back. Thanks for the work on the library.
Nice work. Looks great.
If there is, I don't know about about it.
I don't remember ever seeing this get posted here. It's simple advice for how to deduce whether various type of optimizations are getting applied without actually being able to understand what the assembly is doing.
Likely the issue is that the `Client` isn't dropped when you are done with all your requests, so it's kept-alive sockets keep the runtime going.
Who can I drop the client when I am done? Even if I turn keep alive off, I have the same problem. Also, do you see any glaring issues with the code above? I'm trying to get it ready for a proof of concept for something I have written in node.js that isn't performant enough, so I'd like to not make large foundational errors when converting parts of the codebase. Also, can you show me how to pass client to a function in a reusable way? I had a hell of a time getting it to work due to the HttpsConnector and boxing and implied types or something like that.
The main problem I found with error kind pattern is that, the enum ErrorKind will grow fast for a typical app. I was then experimenting with one Error and ErrorKind per function. So e.g. for login() I will have Login and LoginErrorKind and for signUp SignUpError and SignUpErrorKind. What this allowed me is to exactly know types of failures in the login and to covert every underlying error as a LoginErrorKind. However with this you will end up writing lot of boilerplate code for each Error and Errorkind. I have written some macros manage this. I have not yet written big size apps to know if this works, just something I was playing with. Also this probably more suitable for web applications where you want give proper error feedback. 
Dropping a value in Rust is either implicit, by having a function which owns it in a local variable to return, or explicit, such as `drop(client)`. You don't normally need to explicitly drop things, *unless* you need a value dropped before the function ends. If you declare a new `Client` in a function, and in the same function are calling `tokio::run`, you'll get a hang. `run` will block (keep the function from returning) until the runtime has all registered items complete. The `Client` contains things preventing that, but once dropped will kill its resources. But since run won't finish, the client isn't implicitly dropped. You could call `drop(client)` before calling run. Or, if you look in hyper's client examples, you may also notice the client is constructed in a lazy future, giving it a different function scope.
Yes, that is the idea. And look like somebody else is interested and plan to help a bit. You can mail me at info@elmalabarista.com. 
That's odd, it renders correctly for me in desktop reddit but looks broken on mobile. I guess fenced code blocks are partially supported? Switched to spaces.
Fixed, thanks.
I'm not aware of anything readymade that would get you what you want, but you could write a macro that would do what you suggested: wrap everything in a closure and execute it immediately with context. Kinda like a decorator. Actually I think having a way to "annotate" functions with error context is a really cool idea in general, and could be a nice contribution to `failure`, or maybe a separate crate.
Congrats to all alexcrichtons involved in this, botsrights! — For real, congrats to everybody involved, whoever you are :)
Is it recommended to have this apply itself as you're writing similar to cargo fmt?
The TextView widget is gives me and editable multiline buffer. The labels dont handle things like text wrapping etc.
You have to do cost benefit analysis, like # pros - helps me learn the language - I know I have avoided a class of memory bugs - I can provide a richer API in rust's type system # cons - it already works so I'd be spending time and have the same thing at the end - the C code is simple, so I can be pretty sure it's bug free anyway - my microcontroller has a C compiler, but no llvm backend, so I have to use C These are all made up hypothetical examples, but they give you the idea
Getting the C code written as unsafe Rust code is _easy_. Adjusting that Rust code to be safe and rusty is _not so easy_. So sayeth the dude who did 140 days of Handmade Hero in rust.
What does it fix?
Curious here: did you end up exposing a single Error + ErrorKind pair at the top level, or did you expose multiple different ones? Also I'm curious: do you by any chance still have those macros? I'm super curious how you ended up managing! :D The way I was thinking I'd structure this is having 1 Error + ErrorKind pair per submodule, where each method has 1 member in the ErrorKind. It's still a lot of boilerplate, but should probably be a bit more managable.
[Done](https://github.com/rust-lang/cargo/issues/5767), thanks.
I'd love if someone threw an unsafety audit at my [retro-pixel](https://crates.io/crates/retro-pixel) crate and filed issues/PRs about it, but I can also tell you ahead of time that very little of the unsafe can be eliminated because all the heavy work happens with explicit SIMD.
https://github.com/rust-lang-nursery/rustfix
I sort of disagree with the title, but the advice within article itself is sound – you can intuit many answers from the assembly even without knowing the target architecture or having mnemonics in your head. Beware, however, that intuition will sometimes mislead you for more complicated questions (e.g. does this atomic operation work the way I expect it to) or non-traditional features in some platforms (e.g. delay slots). Tooling may help here or there, but it is prudent to not accept the intuition as absolute truth :)
If gcode were an official spec then yeah, you could perform strict validation but since every dammed printer/CNC has their own little codes/extensions/features you can't just throw errors because a value doesn't match what you expect (e.g. `.5` instead of `0.5`). I've seen gcode files that have things in them like `G1 X.origin` (which is meant to send the X axis to the origin point which is actually a different place than `X0.0`).
Oh man I feel your pain (no allocator, limited memory), haha. I want to point out that stream parsers are pretty much *always* a chore to write... Even if you have a supercomputer at your disposal.
Well, we need people to try out new features on nightly, to find bugs and see if the features are good or bad. This is relatively easy to convince people to do because, well, they're shiny new features. We *also* need people to try beta to find regressions, and this is harder to motivate, because it's basically stable-but-might-have-more-bugs. Personally I try to use beta whenever I don't need nightly. 
&gt;In that case I don't expect it to catch anything: &gt; &gt;1. If a Rust function is neither inline nor generic (you're not using "weak symbol" the same way linkers do AFAICT), *it can't possible have* multiple definitions (unlike C++, you can't get the same Rust symbol from *different* source definitions - we're much more in the camp of "compilation creates normative identities de novo"), so where would traditional ODR help? I think you're confused. To be thorough I was explaining that modern linkers catch *both* defining the same regular symbol in multiple translation units *and* defining a weak symbol differently in multiple translation units. It maybe true Rust doesn't have to worry about the former at all, but the latter is what this discussion is about. As long as your language has monomorphized generics the linker must have the smarts at the very least to throw out duplicate definitions (two crates both invoke a generic method with the same compile time arguments). Modern linkers due to C++ support go further and compare equivalence in order to catch mismatches. I may not be aware enough of how Rust changes the compilation process but I don't see how it can avoid needing this anyway. I have a crate C with a generic method foo used by crates A and B with the same compile time arguments. I compile A, change the definition of foo inside C, then compile B. When I use A and B in my final binary something needs to catch that A and B have different monomorphized copies of foo and give an error. G++ and Clang both catch this today. Does Rust? If so, how can it do it without comparing definitions?
The best small project for learning a new language I know is to write a small [ray tracer](https://en.wikipedia.org/wiki/Ray_tracing_(graphics)). I don't know about a good tutorial for ray tracing, but I've heard good things about http://in1weekend.blogspot.com/2016/01/ray-tracing-in-one-weekend.html.
Importantly, you can use it to [automatically transition your code to the 2018 Edition of Rust](https://rust-lang-nursery.github.io/edition-guide/editions/transitioning.html).
From the readme : &gt; The goal of this tool is to read and apply the suggestions made by rustc. &gt; he magic of rustfix is entirely dependent on the diagnostics implement in the Rust compiler (and external lints, like clippy). How does rustfix (and the stabilized `cargo fix`) interact with clippy ?
Raw pointers are unsafe. Use references instead. 😛
I'm not so sure, for two reasons: 1. Spec bugs happen just as implementation bugs do. `gets()` in C is just not fixable: the spec itself is broken. 2. Specs don't magically allow breaking changes. On the Web, the rule is that if the spec differs from what sites rely on in practice, it is the *spec* that is wrong and must change. This rule frequently makes people unhappy, but it must be this way for the spec to have any meaning. Otherwise you get into a situation (like, say, TrueType) where the spec has absolutely no bearing to reality.
&gt; How does rustfix (and the stabilized cargo fix) interact with clippy ? FYI, `cargo fix` is the cargo-aware version of the tool, rustfix is only a library for reading JSON and replacing things in files. Clippy, as a compiler plugin, emits regular "diagnostics", just like rustc. Recently, the suggestion diagnostics gained a new property: Applicability. If a lint emits a suggestion marked as "machine applicable", rustfix can pick it up. Relatedly: https://github.com/rust-lang-nursery/rust-clippy/pull/2943
We are currently only focussing on the lints necessary to migrate to the Rust 2018 edition, so many of the warnings you get you'll still have to fix yourself. Additionally, the RLS and other editor plugins can also pick up these suggestions -- you might already see some of the little yellow lightbulbs in you Rust code in VSCode if you look carefully :)
&gt; Also, can you show me how to pass client to a function in a reusable way? Edit: for anybody else, I was able to achieve it like this `fn fetch_json(client: &amp;hyper::Client&lt;hyper_tls::HttpsConnector&lt;hyper::client::HttpConnector&gt;&gt;, url: hyper::Uri, request_body: String) -&gt; impl Future&lt;Item=Value, Error=FetchError&gt; {` and, you were right. drop(client) worked.
If using nightly, you might be able to setup a "decorator"-style solution using [adorn](https://github.com/Manishearth/rust-adorn)
I am trying to iterate over a vector and modify each element in place let mut input: Vec&lt;char&gt; = place\_holder.chars().collect(); for mut c in &amp;input { c = 'k'; } print!("{:?}\n",input); `mut c` because I need to change `c`, and `&amp;input` because I don't want to move `input` because I need to use it again. This gives me the error --&gt; src/main.rs:33:13 | 33 | c = 'k'; | ^^^ | | | expected &amp;char, found char | help: consider borrowing here: `&amp;'k'` | = note: expected type `&amp;char` found type `char` So I try that, even though it feels wrong `c = &amp;'k';` and it compiles, but when I print out `input` it is unchanged.
&gt;So sayeth the dude who did 140 days of Handmade Hero in rust. O_o Tell us more.
Well, I mean what do you want to know?
For calling Rust from C, you need to be aware of - and properly handle - that the Rust function may panic. On a modern laptop CPU, a call to `catch_unwind` is not many nanoseconds though.
Just did a `rustup update` and ran `cargo fix` in a project. It warned me that all files/directories were dirty that are in gitignore. Does anyone else see that, or do I have a weirdly configured git?
Checking the 5 year trend and seeing that it matches \_none\_ of the other metrics (e.g. our own growth numbers, package statistics or metics like redmonk) makes me doubt the usability of Google Trends as a metric a little. [https://trends.google.com/trends/explore?date=today%205-y&amp;q=%2Fm%2F0dsbpg6,%2Fm%2F0jgqg,%2Fm%2F09gbxjr,%2Fm%2F010sd4y3](https://trends.google.com/trends/explore?date=today%205-y&amp;q=%2Fm%2F0dsbpg6,%2Fm%2F0jgqg,%2Fm%2F09gbxjr,%2Fm%2F010sd4y3) Love how C++ has that noticable bump around christmas every year, though. &lt;3
When you marked `c` as `mut`, you thought it meant "`c` is a reference that can change the pointed-to value", but what it really meant is "`c` is a reference that can be later changed to point to different locations". What you really want to do is to borrow the vector mutably so that the references will be mutable: ``` let mut a = vec![1,2,3,4,5]; for c in &amp;mut a { *c += 1; } ``` In your code, the type of `c` is `mut &amp;char`, in mine it's `&amp;mut char`. Edit: My code uses integers, but whatever.
You need to do it like this: for c in &amp;mut input { *c = 'k'; } Your current code iterates over `input` immutably. In each iteration you get an immutable reference to the current char, and you just reassign that reference to point to a different char, instead of modifying existing string.
As another commenter already said, there is not "one gcode", there are many and the difference can be huge.
I'm trying to understand this code, and this seems weird: pub trait Component { fn get_name(&amp;self) -&gt; &amp;str; fn start(&amp;mut self) -&gt; !; fn stop(&amp;mut self) -&gt; Result&lt;(), ComponentError&gt;; } Because `start` borrows `Component` mutably for life (it does never return...), there is no way to call `stop` (or `get_name`) on a started `Component`...?
Awesome, I could really use this! I already thought about doing this myself. I will check it out!
It seems the *"dirty"* terminology is used with files that are not tracked by git, regardless of whether they are in `.gitignore` or not. Maybe *"or has untracked files"* should be appended to the message.
GTK widgets are configurable. If you don't want an editable text view, then set the editable parameter to false\[0\]. If you want a label to wrap, then set that parameter, too\[2\]. \[0\] [https://gtk-rs.org/docs/gtk/trait.TextViewExt.html#tymethod.set\_editable](https://gtk-rs.org/docs/gtk/trait.TextViewExt.html#tymethod.set_editable) \[1\] [https://gtk-rs.org/docs/gtk/trait.LabelExt.html#tymethod.set\_line\_wrap](https://gtk-rs.org/docs/gtk/trait.LabelExt.html#tymethod.set_line_wrap)
Thank you for spelling that out so clearly. That really helps!
 &gt; Moreover I was trying to use lazy_static!, which, based on my reading of the docs, internally creates a Mutex for access. I'm trying to read those docs too, and can't find where lazy_static! would use a Mutex for access?
But the files aren't untracked as far as git is concerned; `git status` doesn't list them. If this is really intended behavior, it will trip up almost everyone as soon as the project has been built once (`target/` exists) and I don't understand the reasoning.
How does anything check for equivalence when all you have is machine code? I'm genuinely curious, everyone I asked said no in-depth checks actually happen. As for your hypothetical example, you could try it out. You should get errors when trying to use A even without B ever existing because the C your A was compiled against is nowhere to be found (IIRC we hash everything in the crate so changing it *at all* and recompiling it will not result in a compatible artifact, despite having the same name). So in a sense Rust does have link-time errors but they amount to *you replaced one of the dependencies* (and didn't recompile dependents), you can't get them by compiling each crate once. And it's checking one integer value, not thousands/millions of queries in the history of each crate.
I really liked "Too Many Linked Lists", though it has nothing to do with distributed systems.
Yeeaaaah, sucks but it's the same with most programming forums, reminds me of the JS community &gt; How do I do X with JQuery? &gt; Well you shouldn't be using jquery, it's very outdated, try ....
any plans for adding gcode _emission_?
There is project to translate llvm-ir to C, so last point is possible to overcome
No this sounds like a bug for sure.
May be looking for std init once?
Sorry, I was imprecise with my words. Specifically, from the docs ``` The Deref implementation uses a hidden static variable that is guarded by a atomic check on each access. On stable Rust, the macro may need to allocate each static on the heap. ``` That, combined with every example I've seen of mutable `lazy_static!` wraps the object in a Mutex.
Why would you want to? Apart from await/async.
I have a type I that implements `iter()` (it has such a method to iterate over references, but I can't find a trait for that). I need a function that takes a `&amp;mut I` and returns a `Vec&lt;I::Item&gt;`. Functionally, that means I iterate over references, clone their contents and stick them into a `Vec`. No problem. How should that function be called? I don't like `into_vec` since it's not consuming, I don't like `as_vec` since it's not a conversion... setting `function_that_makes_a_mut_ref_into_a_vec` aside, I'm fresh out of ideas. Help, please!
Reddit mobile and Reddit's old mode don't support fenced code blocks. Reddit's new design supports it just fine. I think it was poor planning on their part to not backport the fenced blocks, imo... Especially to mobile.
Apparently gold complains if the type or size is different, and address sanitizer has a more detailed mode: https://github.com/google/sanitizers/wiki/AddressSanitizerOneDefinitionRuleViolation I don't see why just having machine code is a problem though. If the machine code isn't identical for a given symbol, it's a violation. I think gold only checks the size and type for better performance. Inline functions could be tricky -- I guess you'd always have to emit a non-inline version for comparing, but I imagine that's usually done anyway?
`join_all` returns a Future. It creates a Future that drives all the futures in the slice you passed to it to completion. So remove the `rt.spawn(fut)` line. And change the `join_all` line to `rt.spawn(join_all(futs))`. Now, that may _not_ be what you want. Your code doesn't seem to use the results of any of the futures in `futs`. `join_all` should only be used when you want to wait until all those futures are done and then do something with all their outputs. If you don't care about their results, just spawn all the futures. You don't need the join_all. Tokio will run until all Futures on the Runtime are done. At which point the line `rt.shutdown_on_idle().wait()` will finish and your program will exit.
Ah ha! I forgot about that. Thank you.
Haskell existed before 98 though :) SPJ is very nice, it’s true. I know the paper exists but haven’t had the time to read it yet!
Why would you want to manually do something a computer can do for you? 
Thanks for the quick reply! I find it odd that hyper maintainers are not in the loop, that core team hasn't opened a ticket for futures 0.3 support, there's not even a toy example, etc. At first I thought I'm simply looking for it in the wrong place, but maybe it's just not at that stage yet?
It’s all good :) seems like you’ve got some answers by now.
How annoying Medium is! One dialog that has to be clicked away (on the close button; just clicking outside it doesn't work), and then two thick banners permanently taking up space. PS: The "reader view" in Firefox works well for this page and gets rid of the banners.
No, I mean, why would you want to use the 2018 edition? As someone who's been around since 2013, I've gotten used to the way the module system currently works, the paths currently work, I like explicitness of `extern crate`... The `?` operator never really appealed to me, and I think in-band lifetimes are just plain weird and confusing. I suppose I And since you actually have to put extra annotations in Cargo.toml to get the 2018 edition and all existing code is in 2015, I suspect that 2015 will remain the default anyway. So it seems to me that 2018 has very little to offer me. The only carrot is `async`/`await`, but according to the Rust edition guide that doesn't work yet, and most programs don't benefit from those anyway :) So I get that many changes have been made to make stuff easier to learn (although I remain unconvinced whether 2018 is really easier), but what incentive do people who have already learned the 2015 edition to switch? How will the Python 2 vs 3 scenario be avoided?
I think the question was more about "Why would you want to transition any old code to Rust 2018 Edition". That's a fair question, and not that easy to answer since there are both pros/cons involved that might be different from project to project. While right now there might not be anything in Rust 2018 that your project really needs, that can change in the future, and at that point, you'll be very happy that migrating to Rust 2018 is just a `cargo fix` away.
&gt; How will the Python 2 vs 3 scenario be avoided? The Python 2 vs 3 scenario happened because you couldn't use Python 2 libraries in Python 3 code. That's not an issue here.
&gt; The only carrot is async/await For you, and right now. The future might bring better, bigger, and brighter carrots. You don't have to switch right now, you might never have to switch. But if you ever want to, knowing that it can be done automatically in zero time by a tool that makes no mistakes should give you quite some peace of mind. Without `cargo fix`, an argument for switching right now would be that if you don't do so, and ever need to, that might involve a lot of work, while right now it isn't that much. `cargo fix` actually gives you the freedom to not have to worry about this, which is kind of great. Switch whenever you think its worth it, if ever. It's up to you.
A file in gitignore is not untracked. Untracked files are only those that are not in gitignore and are not committed or not staged. 
Is what you did in a public repo? I thought about doing the same thing and I'm interested to see what it looks like.
Python 2 vs 3 was a core part of the design of editions, and so is not an issue. If you don’t find those features compelling, sure, then don’t use 2018 stuff. That’s fine. Many people do though. I just misunderstood your question :) 
No. You will need to load the file into memory. However, you can stream it, meaning you only need small chunks of data in memory at a time, not the entire file. You can also take advantage of the OS's buffering and blocking
http://cglab.ca/~abeinges/blah/too-many-lists/book/
It is not. Handmade Hero isn't public domain yet. Casey is still going strong on day four hundred and something. The C++ code is not public domain until 2 years after the project completes, and so I can't release my rust code based on the C++ code until that happens. If you pay the $15 to sign up for the github group you can see [the rust version](https://github.com/HandmadeHero/rust) as a repo there. I got side tracked by the roguelike coding summer jam, but I think I'll get back to handmade hero stuff eventually. Most rust coders would be deeply disappointed in my handmade hero project. I make absolutely zero attempt to install safety over top of the code. Here are some things that would make you cringe off the top of my head * There's essentially no references or mutable references. `pub type p&lt;T&gt; = *mut T;` defines my only pointer type, and just don't even think about the lifetimes (because if the lifetimes were right in the C++ version they'll automatically be right in my rust version). * Accordingly, I mark every single new function as `unsafe` out of habit and rust _rarely_ tells me that it was unnecessary by the time I'm done filling it in. `(*(*Every).Field).Access` is an ugly mess too (the rust core team doesn't place high priority on an `UnsafeDeref` trait or a `-&gt;` operator). * I accidentally wrote the entire thread pool worker system with a bunch of stuff that wasn't `Send` (particularly all those raw pointers) and I didn't even realize it until weeks later because my threads run directly through the `winapi` system calls so there's no checking for `Send` or `Sync` or `'static` or other things you might expect to be checked. * The whole thing is done in the C++-ish naming convention that Casey uses, not a single snake_case name to be found.
The atomic check itself isn't a mutex, and your use case of "set at program setup and never setup again" does not seem to require a Mutex either, as long as the expression/function that initializes the lazy static is what sets up the hashmap with all handlers in it.
Or perhaps an `Option&lt;Arg&gt;`? That's what Option is for isn't it? Something that may or may not be there.
I meant untracked as in modifications in them are not tracked by git, and thus un-revertable. A fix shouldn't change this behavior, only the error message. Do you actually have `.rs` files or `Cargo.toml` in `.gitignore`? The tool can also become smarter and not complain if the untracked files are not going to be touched by it, with an option to restore the old behavior of failing early.
I'm really enjoying ***Programming Rust***. Expensive, but I like the approach and how everything is explained really well.
&gt; ndeed. This is the last missing feature (now that we have SIMD) which prevents me from advocating Rust for low-latency systems. I don't even need anything that fancy to start with: I just need the ability to parameterize a type with an integral literal (and then pass it unmodified to other types). The main thing I want from it, above all else is generic code that operates on fixed-size arrays, so you don't have to duplicate your implementation for every size. And then an ecosystem built on that, so you can have a "fixed_chunks()" function that returns fixed-size arrays, a "fixed_split_at_mut()" method on fixed-size arrays that returns references to smaller fixed-size arrays, etc
`io.Copy` is your friend: file, err := os.File(filename) if err != nil { log.Fatal(err) } io.Copy(os.Stdout, file)
While rust does have a copy function, this is a go example :).
Hi, I couldn't find anyone else asking this question, which probably means it's embarrassingly easy, but why does Rust require GCC to be installed? I understand that it's used for linking, but why can't Rust do it by itself? Is it simply a feature that's not implemented yet? If so, do we have an ETA? Additionally, why is GCC used over Clang? I imagine using Clang could be more efficient/easier since it uses LLVM as well.
The rust compiler and stdlib take backwards compatibility quite seriously, and the language design helps a ton with that. There aren't many ways things could break, and the ways that could happen are carefully laid out. [RFC 1122](https://github.com/rust-lang/rfcs/blob/master/text/1122-language-semver.md) sets out the exact guidelines for backwards compatibility. There are ways the rust language can break, but they are few, far between, and must always have a way to fix the code which doesn't require the new version. It's pretty much unheardof to have a project which compiles on stable rust and requires a specific version. Even if there are tiny breaking changes as described in RFC1122, they require at most 1-2 line fixes and will always be incorporated into maintained projects. With that in mind, Rust will eventually have breaking changes, and those will be at specific Epoch-points. [RFC 2052](https://github.com/rust-lang/rfcs/blob/master/text/2052-epochs.md) describes this. It will have a syntax similar to what you describe, but for epochs rather than compilers. The latest compiler will always be able to compile all epochs. epoch = "2015"
Probably the best way to do this is to create a list of features to be implemented in rust, in the github issue tracker, then start work on each one in a branch. You can delegate and discuss it with other contributors in order to make some progress that way.
Above all, the language wants to be consistent. Plain copyable numbers, and specifically allocated numbers like BigInt, should be moved rather than passed by reference. It would be very inefficient to be capturing every intermediate BigInt by reference and allocating a lot more if the operations could be done inline. For this reason, `Mul` takes `self` rather than `&amp;self`. This is why you need to specify the references, because inferring whether or not you want to borrow would be inconsistent, and it would mean missing one implementation `impl Mul&lt;BigInt&gt; for u8` while having `impl Mul&lt;&amp;BigInt&gt; for u8` would silently make code much slower rather than erroring outright.
Thank you for the helpful context.
I'd forgotten about reader mode; the freaking medium banners take up about half of an 11" screen. Thank you for this comment.
With all that, why did you go with Rust anyway, and not just stayed with C++?
AFAIK there's also a project to translate Rust to C directly.
Rust has a simpler build system, better documentation ability, better unit testing built in, and i like the function signature style and data declaration style of rust more than C++. Here's a hot question reversal that'll land me on /r/programmingcirclejerk for sure: _If you're doing it all from scratch anyway, why would you use C++ over Rust?_
You're right, it is a little confusing -- What I should have made more clear was that it depends on what communication mechanisms you set up *before* you start the component. This code is what I expect a Component would look like strictly based on what it I thought it *ought* to do. In the [example code's `main.rs`](https://gitlab.com/mrman/rust-component-pattern-example/blob/master/src/main.rs#L12), there's a more practical example -- [setting up the component itself involves creating a communication channel](https://gitlab.com/mrman/rust-component-pattern-example/blob/master/src/components/clock.rs#L108), which is how you communicate with the component for the rest of the time. How you do it depends but it's hard to do it any other way without prescribing the concurrency/parallelism mechanism to whoever is using the pattern. If you know a better way please feel free to share/point me in the way of some reading I could do! I'm going to update the post to include the code from the example that sets up communication. [EDIT] - Just updated the post, feel free to check it out https://vadosware.io/post/a-pattern-for-component-based-program-architecture-in-rust/#addendum-approach-code-clarification 
Listed in [my special crates list](https://users.rust-lang.org/t/list-of-crates-that-improves-or-experiments-with-rust-but-may-be-hard-to-find/17806).
i'm convinced
Thats why i have my adblock delete those elements. for a second i didnt know what you were talking about because i havnt seen them for so long.
There is no top level Error. What I have is more a mix Error per functionality and error per module. Yes a lot of boilerplate. Repo below has some of that experiments. https://github.com/mmrath/fina-server 
I think a fix is underway: https://github.com/rust-lang/cargo/pull/5770
After taking a quick look at the stuff, I felt that I may learn how to build data structures idiomatically by reading it, thanks. BTW, the [rust-unofficial](https://github.com/rust-unofficial) organization has lots of helpful readings!
Do you have any technical writing needs? 
I've had a bash at doing this and a mix of other ideas &lt;SPOILER - it doesn't compile&gt; I thought one of the plans here could work:r/https://play.rust-lang.org/?gist=347e7b0d12409fc1df5dc19ed38514f2&amp;version=stable&amp;mode=debug&amp;edition=2015 but no dice. If anybody can help, I'd be very grateful!
I have no idea what your project is about, but it sounded like it's strongly dependent on preexisting large C++ codebase. One would think that integrating Rust toolchain with that would be a lot of work, if you reject borrow checking, there's not much benefit to using Rust over C++. I was just wondering what made you decide that going Rust is worth it despite the extra work it requires (because simpler build system doesn't apply anymore). But maybe I'm mistaken about how much C++ is in this pure Rust project.
Oh no friend! We don't use any libraries or dependencies in the land of handmade hero! Learn to program your own video game, one hour at a time, from as scratch as can be. My Cargo file has `winapi` and the rest is built up during each lesson. Most of the time the code is even borderline no_std The _actual_ project is in C++, my own version is in Rust, but all parts are just as "from scratch" as the C++ version does it. If you've ever tried to follow a long series, you may know that even small deviations early on can make things difficult to match later on, so I actually prize minimal deviance a lot more than any normal project would.
Which is a shame because it sounds much cooler :(
What is "raw array"?
 error[E0271]: type mismatch resolving `&lt;tokio::prelude::future::JoinAll&lt;std::vec::Vec&lt;tokio::prelude::future::MapErr&lt;tokio::prelude::future::Map&lt;impl hyper::rt::Future, [closure@src/main.rs:76:10: 78:6]&gt;, [closure@src/main.rs:79:14: 84:6]&gt;&gt;&gt; as hyper::rt::Future&gt;::Item == ()` --&gt; src/main.rs:89:6 | 89 | rt.spawn(join_all(futs)); | ^^^^^ expected struct `std::vec::Vec`, found () | = note: expected type `std::vec::Vec&lt;()&gt;` found type `()` error: aborting due to previous error 
This is both true and (at least on Linux) false. Yes, the data need to go through RAM at some point. But, no, it doesn't need to go through *your application's* memory. If you *really* want to, you can get the kernel to do all the work for you with `splice()` and/or `sendfile()` calls. This is almost never worth the hassle. It's not even necessarily a performance improvement - zero-copy can require more book keeping and expensive checks, so it tends to be an optimisation only for large chunks of data.
Ah I see. That means npm doesn't follow semver either, since it essentially that all 0.x.y versions are incompatible with each other, even, say, 0.1.2 and 0.1.3: &gt; 4\. Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable.
Technically, I'm on vacation, but this was too much fun to work on ;)
&gt; why does Rust require GCC to be installed? I understand that it's used for linking, but why can't Rust do it by itself? Because rewriting things from scratch when you don't need to is a mug's game. Why would the Rust devs waste a *collossal* amount of time and effort writing a new linker (which could instead be spent on the language itself) when there are already linkers available that they could use instead? &gt; Additionally, why is GCC used over Clang? Dunno. Because it's more widely available? It was the first thing that came to mind when someone thought "hey, we need a linker"? It just happened to be installed on the original dev's machine, and clang wasn't? Because it's quicker to type? I mean, it doesn't really matter either way. Besides which, clang isn't a linker. Then again, neither is gcc; ld is. gcc just typically invokes it for you. LLVM's equivalent, lld, hasn't generally been considered "production ready" from what I understand. So there's that, too. &gt; I imagine using Clang could be more efficient/easier since it uses LLVM as well. Well, by the time the linker sees the object files, they've already been turned into machine code, so it being based on LLVM is probably mostly irrelevant. Even *if* lld ends up being usable and shipping with rustc by default, Rust will still need to be designed to use a non-LLVM linker, because it needs to use LINK on Windows for MSVC compatibility.
&gt; Can anyone confirm it? That would be much easier with compiling, runnable code, and an explanation of what you expected. Otherwise, anyone who wants to help you first has to try and reproduce the problem you're having.
It looks like the repository link at https://crates.io/crates/containers points to an old repo. What is the URL of the current code base?
Yeah. Medium was the first thing I reported via [this extension](https://addons.mozilla.org/en-US/firefox/addon/in-page-pop-up-reporter/). (There's a Mozilla developer working on a blocker for in-page popups and that extension is to help him crowdsource test URLs.) They're also on a "Never subscribe/buy from these sites to penalize them for their irritating attempts at 'growth hacking'" list I maintain in my note-taking tool.
`rt.spawn` wants a Future that produces a `()`. `join_all` is going to produce a `Vec` with the results from all the futures it joined. Quick fix should be: `rt.spawn(join_all(futs).map(|_| ()));`
They wrap it in Mutex to make it mutable. Otherwise, because it's global, it could only be constant. The fact that it's global forces this because there's no way to track mutability ownership. Any and every piece of code in scope can modify it.
&gt; Is there a way to determine if a file is executable on Windows? That depends a lot on how you define "executable". There's a security permission for "Read &amp; Execute", but I have no idea how you'd read that from Rust,^† and it's set on basically *everything*. If you mean "you can type the name in a command prompt without the file extension", that's what the `PATHEXT` environment variable is for. If you mean "is loaded by the system itself", I suppose you could examine the file associations in the registry to see what the `shell\open` handler is... but I have no idea if that'd even be accurate on Windows 10 any more. But that also excludes things like Python scripts which, as far as the system is concerned, are no different to a cat picture. --- †: I know I did it once at university, but all I remember is that it was an experience I'm not enthusiastic to repeat.
Well, this already kinda exists as [`cloned`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.cloned). If you implement Iterator/IntoIterator for your type you will be able to leverage this.
Both pulldown-cmark and comrak are great.
Is commonmark more strict version of Markdown?
It’s a more strictly defined version. “Markdown” is “whatever markdown.pl does”; common mark attempts to specify things. There’s also GitHub Flavored Markdown and all kinds of other markdowns. Rust docs use CommonMark.
ok which of those 2 libraries is better?
You could use something like HDF5...however...depending on how you are 'derezing' - I think it would be pretty cool to make a custom solution using something like a [BTreeMap](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html) \*if you go with the latter route HMU 
I really like comrak. It has great configuration options and it seems to be fast, according to benchmarks from the blog I am working on. Really to use too.
[removed]
The vp9 encoder is not that bad, its main problem is that it's not well threaded. Which isn't a problem for Google encoding videos for Youtube; they just achieve parallelism by encoding a lot of videos simultaneously.
I can highly recommend this book, too. It covers everything one needs for _really_ understanding all the more unique features of Rust. While *The Rust Programming Langauge* often feels more like a documentation (a well-written one, though), *Programming Rust* aims to teach you the language. Both books complete each other (imo).
[Here you go](https://github.com/rust-unofficial/patterns)
&gt; AV1 isn't just repeating `VP9`, it's [doubling down](https://code.fb.com/wp-content/uploads/2018/04/av1_pic7.jpg). Yes, it's 500-700 times slower than VP9. Every codec was slow as fuck when it initially released. Including H.264, H.265 and VP9. The AV1 specification has only just been finalised recently. It **will** get much faster. Will it be faster than VP9? Well, maybe. I think there's more effort going into parallelism of AV1 encoding than there was for VP9, which could counteract the extra complexity. It probably won't be as fast as x264, but it should come close enough to be worth using (if it ends up half as fast, I think that's good enough).
It's not written in Rust, but Graphite works really well. It's also extremely simple to integrate into an application; all the application has to do is send its metrics via UDP to Graphite which does all the aggregation and writes the data to disk.
Hopefully OP can clarify, but it sounds like they might be asking whether it's possible to stream a file to stdout, rather that allocating enough memory to hold the whole thing? If so, yes of course! Take a look at std::io::stdout and std::io::copy.
This is great. Thanks for posting. I'm in the same boat of not really liking javascript nor really having any UI "skills". This is very motivational. I tried to get started with yew a few months ago, but had trouble getting it bootstrapped. I shall have to try again. 
Definitely read that text if it is an area that you are interested in. I've read /u/aturon's thesis and he is a very good writer.
There are links to lots of good materials in [this repo](https://github.com/ctjhoa/rust-learning)
I tried to [clarify](https://docs.rs/containers/0.8.2/containers/collections/struct.RawVec.html) in the latest docs; is it helpful?
It's [here](https://github.com/strake/containers.rs). I modified the metadata on crates.io to point there now.
I guess. What I don't understand now is, why would I need it.
Wow, not op but this repo sure will help!
&gt; Would it suffice just to check the file extension and look for common executable file types? It probably would. If you are checking before executing a file it is better to check what [output()](https://doc.rust-lang.org/std/process/struct.Command.html#method.output) returned as even on Linux with unix permissions for execution enabled on file you can still get denied by SELinux/AppArmor. Windows has ACLs, I think relevant API is [AccessCheck](https://msdn.microsoft.com/en-us/library/windows/desktop/aa374815%28v=vs.85%29.aspx), [in winapi crate](https://docs.rs/winapi/0.3.5/x86_64-pc-windows-msvc/winapi/um/securitybaseapi/fn.AccessCheck.html), but I would avoid it as access can still get denied by antivirus or something else so again it's better to just properly handle output function (no unwrap). You will be avoiding unsafes as well if you don't use winapi crate. 
I should try out yew. Anyone that has used it before - are \[gzipped\] sizes of produced webasm files competitive with minified javascript?
I always thought of generators as coroutines from which data can be sequentially read from (e.g. using `for .. in` and such), while coroutines, in general, are async sequential task runners that either do stuff in the background or result in a fulfilled future/promise. I'm not versed in async programming so my thinking might be a bit wrong.
Both are good. As its docs say, conrak also supports the syntax extensions known from github, so it can do a bit more. 
There is no Rust-based time-series DB yet. The most full-featured one right now is Go-based InfluxDB. But InfluxDB consumes RAM much, so I'm looking forward to Postgres-based TimescaleDB, which still lacks "downsampling" feature.
Not exactly architecture patterns but maybe also interesting: https://deterministic.space/elegant-apis-in-rust.html
I was thinking something more like this, where each variant is its own type and use it as a trait object. https://play.rust-lang.org/?gist=bd7a87c85d1318084014ed3d149196ec&amp;version=stable&amp;mode=debug&amp;edition=2015
\- Simple GTK app with much comments: [https://gitlab.com/mmstick/fontfinder](https://gitlab.com/mmstick/fontfinder) \- Debian repository builder w/ Clap CLI arg parsing &amp; fern logger: [https://github.com/pop-os/debrepbuild](https://github.com/pop-os/debrepbuild) \- GTK app with a lot of async action: [https://github.com/pop-os/popsicle/tree/reflashing](https://github.com/pop-os/popsicle/tree/reflashing) \- Next gen system shell w/ 17K LoC: [https://gitlab.redox-os.org/redox-os/ion/](https://gitlab.redox-os.org/redox-os/ion/) \- Distribution installer w/ 12K LoC: [https://github.com/pop-os/distinst](https://github.com/pop-os/distinst)
Patterns are missing language features, rust is quite ok.
Well the documentation is fairly complete in my opinion. Unless you think about documenting the API itself (which might be better suited for the original api server) Obviously there are little bits missing here and there and PRs are welcome, but I don't think you'll find too much to add.
Thanks for an interesting post. Normally you don't need to write a closure just to call a function. I mean, |a|function_name(a) can be replaced with just function_name. Is this another trick because of the limitations of the html! macro?
 Continue Working on my wxPython Rendertree which computes all performance critic parts with a RUST cdylib. In this case currently used for fractals, heighmap generation and software rendering. 
You can also wrap it in a Cell/RefCell if you don't need the Sync/Send behavior, no ?
Anyway, my intention was to understand if this is still planned or not. Apparently not :) So for the futures support in gtk-rs we'll have to either stay with 0.2 for now or go to nightly (probably 0.2 for the next release and then 0.3). I'm not going to reimplement it in terms of the 0.1 API, it's requiring too many weird hacks.
Thanks for taking the time to spell it out for me :) I think I understand this approach. Is the drawback that you lose the ability to ensure only certain Opcodes (i.e. the three from the example: Out, Halt and Noop) are passed to a function by type checking the enum? - I believe I've seen this referred to as dynamic dispatch and can actually be seen as a benefit of you are writing a library and don't know all the "ops" that might be made by other crates I've tried to add a function to your playground that takes an argument that is an Opcode -&gt; that implements the Opcode trait: ``` fn any_opcode(op: Opcode) { ``` ``` fn any_opcode&lt;T&gt;(op: T) where T: Opcode, ``` Neither compiles (the fn includes a match), best seen in the playground: https://play.rust-lang.org/?gist=9f0f361e7b40e87d18b8b54144827155&amp;version=stable&amp;mode=debug&amp;edition=2015 Am I misunderstanding the features of traits or just bungling the syntax?
&gt; Well, this already kinda exists as cloned. Thanks for that hint. But as I tried to elaborate, it's not the implementation that gives me trouble (elements are all copy, so I don't strictly need to clone). I need a good name for that method!
I've [posted this in the old thread](https://www.reddit.com/r/rust/comments/8z5zlz/hey_rustaceans_got_an_easy_question_ask_here/e2uh89b/) just yesterday evening, and while I got an answer, it wasn't the one I'd hoped for, so I just want to ask again here. Let me just point out that I don't need help implementing the function, but I need a good name. It's a method on a struct of signature `&amp;self -&gt; Vec(u64, u64, T)` for some type `T` (it's not a generic parameter, but it doesn't really matter what it is now, I think). So here's the c&amp;p: &gt;I have a type I that implements `iter()` (it has such a method to iterate over references, but I can't find a trait for that). I need a function that takes a `&amp;mut I` and returns a `Vec&lt;I::Item&gt;`. Functionally, that means I iterate over references, clone their contents and stick them into a `Vec`. No problem. &gt;How should that function be called? I don't like `into_vec` since it's not consuming, I don't like `as_vec` since it's not a conversion... setting `function_that_makes_a_mut_ref_into_a_vec` aside, I'm fresh out of ideas. Help, please!
100% this, Java is a big offender which probably stems from OO all the way down: https://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html
Maybe there should be a reset button :D I deleted a little to much people, now the page is broken and I'm left with just a title. Only way to fix it is to delete Local Storage.
As someone who has been doing both web development and embedded I can see why this is useful to know that it can be done. On the other hand for any web developer charged with maintaining even static pages would be a huge challenge. I’ve recently been looking at Parity which is written in Rust and serves its browser UI for the Ethereum Network in a similar way - but I cannot help feeling that maintenance in any meaningful and rapid way is completely beyond most web developers these days if this is going to be the way forward. Maybe I’m missing something?
No, `lazy_static` is like normal global variables in that it requires `Sync`. Anything else would be horribly unsafe, since you can't statically associate accesses with specific threads.
and in terms of performance?
If you care about this, please write benchmarks for your specific use cases! (I expect both to be _very_ fast, but pulldown-cmark implements a streaming API and doesn't construct an AST, so it's probably faster.)
I recommend reading other people's Rust code on GitHub to get familiar with common patterns and commonly used crates.
Oh, I didn't know Mozilla considered it to be their business to block such things! I wonder if it could also block those "we are using cookies" messages that are on every page, at least for users in countries that are members of the European Union, and maybe it is the same for the USA. I presume that people neither want to see nor show them, and that they are there just because the law requires it. I've been thinking that we could settle on a convention for how to tag them, so that browsers could easily filter them out.
I have not (yet) tried it, so I'll try analyzing this app. We have: - 29.44 KB (6.64 KB gzipped) of uncompressed JS, which can be compressed to rouhly 15 KB (~5 KB gzipped) - 552.73 KB (135.79 KB gzipped) of WASM; I don't know if this can be minified further, or the size of additional dependencies (this app has `serde`, `serde_derive`, `serde_json`, `stdweb` and `yew`, i.e. the bare minimum) I would say the output is nearly twice as big as what we can do with JS frameworks like Vue and React. Keep in mind this is for a trivial app, though — it would be more interesting to build a medium-sized one both with Yew and a JS/TS framework.
*potentially* missing language features. Not every pattern deserves to be a language feature. The cost of the pattern has to outweigh the cost of the feature.
&gt; There are two traits Component and Renderable. Component implements all of the functions around creating and updating the component. Renderable implements the functions for rendering the component, view. It’s not yet clear to me why these two are separate traits and not just one, there’s possibly a good reason, but it’s not obvious to me yet. I've been wondering why this is, too! Does someone have an answer? I'd prefer if they get merged into one trait. In other frameworks (e.g. [Halogen (PureScript)](https://github.com/slamdata/purescript-halogen)), [every component](https://github.com/Boscop/web-view/blob/master/examples/todo-ps/src/Component/Todo.purs#L46-L47) has a `render`/`view` and `eval`/`update` function.
Btw, if you have no backend server, how can the browser's `LocalStorage` identify your site across sessions?
Fun thing is, many Java patterns stem from it *not* being OO all the way down. Many so-called shortcomings of Java were introduced for good reasons, yet those who decry its 'offenses' rarely cite them.
Executable on Windows is determined by extension, so answer is yes. If you need something more sophisticated then checkout `file` Unix command for Windows [here](http://gnuwin32.sourceforge.net/packages/file.htm).
Sorry for the late reply. By invariant I mean a property that is the same for all isomorphic graphs. For example the number of different labels, if two graphs are isomorphic, they must have the same number. But two non-isomorphic graph will probably have a different number. If you take a number of these properties together you could have a decent hash function. In the worst case your time is the same as now. I think if not all graphs are nearly isomorphic you can get 
&gt; Oh, I didn't know Mozilla considered it to be their business to block such things! Well, Mozilla Suite popularized the popup blocker back in the day and in-page popups are basically an attempt to circumvent that. &gt; I wonder if it could also block those "we are using cookies" messages that are on every page, at least for users in countries that are members of the European Union, and maybe it is the same for the USA. I presume that people neither want to see nor show them, and that they are there just because the law requires it. I've been thinking that we could settle on a convention for how to tag them, so that browsers could easily filter them out. Why not just write a browser extension which... 1. Checks whether the page has anything that's set to `position:fixed` (The CSS rule that causes things to not scroll with the page) 2. Hides them 3. Displays a page action (icon in the address bar) which indicates that it happened and provides something you can click to toggle them on or off for the current domain, in case the blocking caught something you actually need. I'd try my hand at that if I weren't already elbows-deep in an effort to clear out a big backlog of other projects. (At the moment, I just finished working around `serde_json` bug [#464](https://github.com/serde-rs/json/issues/464) and I'm now gearing up to work around [#465](https://github.com/serde-rs/json/issues/465) so I can write a helper for my nightly incremental backups.)
I wanted to contribute a [`From` impl to msgpack-rust](https://github.com/3Hren/msgpack-rust/issues/167), but I've hit a problem. You could read the issue, but I'll give a summary that should show what's bugging me: We need to convert to a type called `Value`, which isn't particularly problematic, except when converting a `Vec&lt;u8&gt;`. The problem is that the msgpack specification allows 2 ways to encode this, namely as a `Binary string` or a `Vec of Integers`. Which one to use is what the caller should decide, it's a question of semantics. As things stand now, you can do (in pseudo notation) `Value::From(Vec&lt;u8&gt;)` to get it sent as a Binary String, and `Value::From(Vec&lt;Value::from(u8)&gt;)` to send it as a a Vec of integers. Now what I want to provide is a blanket impl `Value::from(Vec&lt;T&gt;)` where `T: Into&lt;Value&gt;`, so we can recursively convert `Vec`s. But of course at some point we will hit a `Vec&lt;u8&gt;` and need to disambiguate. The `From` trait does not allow additional parameters to let the caller decide how to disambiguate, unfortunately. I don't see a way out of it, but before I close the issue, I figured I'd ask around. Is there a way to do this? Any hint welcome :)
Do you have examples?
My bad !
Note, if you're rendering user provided markdown such as comments you will want to be sanitizing the input to avoid stuff like ```html &lt;script&gt;alert('hahaha')&lt;/script&gt; ``` (markdown is a super-set of HTML). [`ammonia`](https://crates.io/crates/ammonia) is a decent library I've used in the past for that, and you can see it recommended in the [`comrak` readme](https://github.com/kivikakk/comrak#security).
I'm looking for something similar but could't find a solution that is small enough / written in Rust to embed it into a simple executable. My current solution is to write plain CSV files. I create a new file every 24h. I know, it's primitive but it's a super easy handling (you can use whatever libs/CLIs to process CSV). Here is a example implementation (~200 LOC): https://github.com/slowtec/msr-recorder/blob/master/src/lib.rs
The best idea I have is to provide two extra types that do either one of two things, depending on how you want the user to encounter them: * Have the types both wrap `Vec&lt;T: Into&lt;Value&gt;&gt;` and provide the `From` impl on each of those two types with the disambiguated semantics so the usage might look something like this (throwing out some type names): BytesAsString(my_vec).into::&lt;Value&gt;() BytesAsInts(my_vec).into::&lt;Value&gt;() * Have both types wrap a `Value` and implement `From&lt;Vec&lt;T: Into&lt;Value&gt;&gt;()` so the usage might look like this: my_vec.into::&lt;BytesAsString&gt;() my_vec.into::&lt;BytesAsInts&gt;() However it might be better to just provide one `From` impl and just pick which semantics you want to be default, and provide a function to perform the other explicitly.
`collect_to_vec`, perhaps?
I don’t know the answer to this. In the browser dev tools you can view the LocalStorage data. I believe it’s tracked against the file location, but I haven’t investigated that. When loaded from the web, it works as expected, with the domain of the site location.
I had some issues with doing that in the html! macro, and didn’t really have time to investigate. If it can be improved, I’d do it.
Feature requests already! :)
I didn’t do anything to minify size, gzip or anything. I read in another post someone shrinking it down significantly, if I have some time I’ll try and fix that.
I don't see why not, generating the output is quite trivial. The only annoying bit would be that you'd need the `Write` trait, which isn't available in a `no_std` environment.
Ah, the beauty of feeling dumb. :-) 
I do a lot of analysis on time series and I tried all the 'specialized' DBs but I prefer Postgresql, because I always need some features they are lacking. "Lowering the resolution" aka aggregation: I tend to do with materialized views, but you are maybe surprised with the raw performance of GROUP BY CUBE and the like, when good indices are present (i.e. partial indices for tables with more then 100 million rows) Also trigger/deferred trigger come in handy for miscellaneous read optimizations. Keep in mind, that you want an OLAP (on-line analytical processing) rather then OLTP (transaction processing) schema design, i.e. one truth table (your time series) as center and then the various aggregations and queries around it. 
Yep. Luckily the `gcode` language has a simple grammar so it was quite easy to implement a streaming [tokenizer] and [parser] using the `Iterator` trait, with a single token/character of lookahead. [tokenizer]: https://github.com/Michael-F-Bryan/gcode-rs/blob/944deb655f37c8ae6eed3dd9f6caeeea0eaf66e6/src/lexer.rs#L104-L114 [parser]: https://github.com/Michael-F-Bryan/gcode-rs/blob/944deb655f37c8ae6eed3dd9f6caeeea0eaf66e6/src/parse.rs#L33-L60
Can you keep materialized views and discard the original data to save space?
I wouldn't say dumb more not enough Experience inside given Topics ;). I recommend to join the GFX Programming Community with focus of procedural content ;)
LLVM doesn't support 8051: https://stackoverflow.com/a/35061913. There may be [some](http://www.colecovision.eu/llvm+sdcc/) [workarounds](https://github.com/thepowersgang/mrustc), but I wouldn't hold my breath for it. Even the popular AVR architecture is poorly supported by Rust right now.
Do not worry, I particularly enjoy feeling clueless in many topics! Re: GFX Programming Community -- is that a particular sub-reddit that I may join?
that's what I get for checking both r/rust and r/golang together
What i mean depend GFX Programming Community was feeling the passion and results of selfmade Image synthesis and so on. But yes there is a Place you can start : [gfxProgramming - Reddit](https://www.reddit.com/r/GraphicsProgramming+imageprocessing+algorithms+computervision/)
For example Java did not get value objects so far because it was feared (and rightly so) that the required monomorphization would bloat the byte code. On the other hand, testing early (pre-1) versions showed that boxed arithmetic was too slow, so primitives were introduced as a compromise.
Still vacationing, so most time spent with the family. Trying to un-`quote!` mutagen, slowly.
I think there are two points here worth discussing, is an SPA/static site worth the added complexity? And is Rust more complex than a JS/TS framework? The second one is easy. For those of us that like Rust this is better than JS and even TS. Is it something you would want to bank on if you were building a company (ignoring the danger of such unstable tools), that’s a hiring question. JS will win that for a long time to come, but I wouldn’t be happy. At the end of the day, if I’m building something, then I want to be happy... As to the first part of the question. I’m not sure, but one thing this showed is that it is possible to build a web app without any backend, and to me that’s huge for two reasons. One is that it makes the set of tools involved and needing to be run very small, no need for multiple components to run and test the site. The second is it shows that there can be a clean separation of concerns in regards to frontend work and backend work. At no point in this process would you fall back to dynamically rendering on the server side. All of that is a static site, making releases simpler for both your backend and frontend. Now to make this a really useful application, you would want a backend service that you could use over REST, the other post I linked to even used cap’n proto for extremely low serialization costs (though, I would have concerns about API versioning with that, bson might be a more manageable choice). A cool thing though, is that the frontend can be easily developed in the SPA style independently from the backend, making teams more scalable. To me this is a huge organizational benefit, similar to microservices. And the SPA is really no more complex than other options. (Some people are now thinking about SEO and prerendering, those are some optimizations that already have some decent answers available). Also, one reason I wanted to use LocalStorage for this example, was to see what it would be like to use that for more persistent caching. Frontends often require huge amounts of data synced to the client. The tooling of Yew intrigues me in that we can now add timers and such that could run in the background keep client data in sync with server data. This would be pretty spectacular for data rich applications improving user experience. Yes, I would need to teach some JS people Rust, but honestly, modern JS is pretty complex at this point, I think it wouldn’t be that big of a problem. Compilers are more help than hindrance. 
Assuming this is similar to the standard library’s `src/liballoc/raw_vec.rs` you’d probably only use it as a building block for another collection type. `RawVec` is basically the parts that std’s `Vec` and `VecDeque` have in common, refactored into a separate type with its own API in order to reduce code duplication. The added abstraction also helps make the rest of the code easier to reason about. Now it’s also used in rustc’s `TypedArena`, and in `Box&lt;str&gt;` and `Box&lt;[T]&gt;` conversions.
You can, but there's a really good chance you'll get unmaintainable garbage code. Even if it's annoying I'd probably take the [remacs] approach, using FFI bindings to call into the original code and then replace things one chunk at a time. [remacs]: https://github.com/Wilfred/remacs
MDN page on `LocalStorage`[0] &gt; The read-only localStorage property allows you to access a Storage object for the Document's origin; the stored data is saved across browser sessions [0] https://developer.mozilla.org/en-US/docs/Web/API/window/localStorage
Are you loading your page through a `file://` URL? Browsers keep a separate `LocalStorage` for each "origin", but unfortunately how origins work for `file://` is largely unspecified, undocumented, and not interoperable between browsers. If you run into issues related to stuff being cross-origin, consider running a local HTTP server that you’d access at something like `http://localhost:8000/`
In lot of cases you can group arguments in structure and get names. Not that this is better than named arguments, or better workaround than builder pattern, but alternative.
PostgreSQL
Still working on thumbcloud a file-sharing server built with actix-web. It slowly becomes useable. This week I will implement uploading files and some other minor improvements. www.github.com/flofriday/thumbcloud
Your first example is "penny-wise, pound-foolish". Java don't want to bloat the bytecode but most of Java code is bloated. I'm not familiar with the builder pattern, I just had a quick look at it, for me a language with tagged unions / sum types wouldn't need it.
I don’t know assembly well (certainly not well enough to write it), but I’ve several times found the root cause of mysterious bugs by reading assembly code. (Sometimes because it seemed easier than rebuilding `std` with debug info, though maybe that wasn’t the case…)
I experimented with this, but it wouldn’t be something I’d rely on, no. I was just surprised it worked at all, when loading from a file:// location.
FWIW, almost every Rust crate I've published has the "builder pattern" in it somewhere. I don't think the existence of sum types has an impact here. I'm not sure I would use named function arguments in lieu of the "builder pattern," but that's a separate issue. :-)
Gzipping is done by the server — in your case, GitHub already does it. Minifying is done as a deploy step — you just add a command to your build process. A popular JS minifier is UglifyJS. But your JS is quite small already compared to the WASM binary, so you don't really have to bother. TL; DR: it's already fine.
nitpick: in Rust the term most commonly used for these is collections. &gt; it returns an error if it can't allocate memory, I am looking at the code, and I don't see how this is true.
&gt; For example Java did not get value objects so far because it was feared (and rightly so) that the required monomorphization would bloat the byte code. I think C# showed this to be a premature "optimisation". A lack of value types is probably the single worst design descision of Java... 
As said before, this isn't a direct target. I'd try to compile the Rust code with Mutabah's Rust Compiler to C code. And if 51 MCU's Compiler accepts it, you have possibility. I think you could add I/O or specific stuff at C level.
You still get the typechecker maintaining that only those types are allowed, if the trait isn't `pub`. With methods that you would normally use as part of `impl Enum`, you would then add it to the trait as a trait method, and implement it there. It has pretty much the same behaviour.
Probably because even if you update the component it might be necessary to check if something else needs to happen before rendering the changes to the screen. I know React does it, you update the state, but it doesn't render the changes immediately, runs first other algorithms to know if something else needs to be done before ultimately rendering what changed.
Working on panini &amp; gearley crates: a general purpose context-free parser generator.
I mean, java 8 has method references and lambdas. And ruby has its fair share of .run() methods. Also a lot of patterns are just solutions that naturally appear frequently and where a common naming scheme can help people reading the code base. Builder pattern comes up in most languages including functional ones like haskell, for instance. 