It makes sense logically, as a reversal of a c-style declaration of `string a, b, c, d`, but in practice I feel that without the leading type to provide context, the relative precedence of the commas seems wrong without knowing that types aren't optional, and even knowing that now, I feel I'd have to make a conscious effort to properly associate the leading variables with the type. Maybe that would change with a month or two of regular use, maybe it's a consequence of the languages I've used most. Whatever the cause, it's a point of confusion that seems to affect a number of people new to the language.
Sure, if it was worth the cost. IIRC array bounds checks *are* enforced all the time, unless you specifically avoid it. Rust gives you the option to choose, and the safer option is the default. Same with integer overflow/underflow checks. It would be great if it were feasible to have them present all the time, not just in debug code. The Rust spec allows that option, and hopefully it will be cheap enough someday that we can enable it in release mode by default.
Does this monomorphize? &amp;#x200B;
seems like some of the friction I have is with the values of *large scale* software development, eg. claims that default values make later maintenance hard and so on (the debates over keyword args/defaults, ...)
I doubt it. Other methods that refer to `Self`, even behind a type like `Rc&lt;Self&gt;`, don't.
Oooh that is real neat!
I completely understand. I would argue that simplicity does have a cost, of expressiveness. Rust's generics, for example, let you tell the compiler more about what you want the program to actually do, and allow it generate code to do that and only that. If you wrote something with generic types in C it would probably end up involving void pointers, letting the compiler to just shrug and say "whatever you want, boss" instead of actually understanding what you intend. Simplicity also has a cost, is the thing. The complexity of a system is not only how many features it has but also how they fit together. Power also depends on this. A successful simple system has the *right* few features that can combine in extremely powerful ways. A poor selection of those just results in something simple but anemic or awkward, such as early Pascal or JavaScript. We lovers of minimalism can use this as a learning experience. Rust is complex, and powerful, and becoming more of both. As it does, perhaps we can use it as an exercise in trying to find new combinations of features that may make some of the complexity unnecessary. Rust isn't the last programming language in the world, after all.
&gt;&gt; and often an OOP-like gravitation toward less-holistic solutions. Could you elaborate more on what you mean here?
wow, that is a good recommendation. I did some preliminary searching before coming up with the bash line I replaced and `pidof` didn't come up. Thanks for the tip!
Your project looks dope, I also used BLAKE2 but for a fast way to split AB test groups, it's a great hashing function. That one's written in Go, but if you'd like to gander at it it's here https://github.com/luizberti/abby
I didn't look up your solution, but thank you for the link of the challange. I've played with dart a few months ago and this is a good way to get some practice with it. 
Sooo, we might no longer need inner structs for worker functions? 
I never actually got around to extending Python with Rust, but I saw [this video once](https://www.youtube.com/watch?v=-ylbuEzkG4M) and it gave me good insight on how I might do that if I ever needed to. As for autocompletion I feel your pain, VSCode's popup shows a lot of completions with the same name, and I never know which one is the one I want. That being said, I don't think the whole extension is awful, since error mesages are usually on point. I also think that the fact that I'm also in Rust's beginner stages and that I am constantly going back and forth to the documentation anyways, makes the productivity boost of having a good autocomplete less significant.
I don't know for sure, but I don't think so.
In C, when subtracting two pointers, the result is a [`ptrdiff_t`](https://en.cppreference.com/w/cpp/types/ptrdiff_t), which is a signed integer-type. This tends to be a 32-bit integer on 32-bit platforms. So it doesn't make sense to have objects that are larger than `PTRDIFF_MAX`, because then you can't really subtract pointers anymore. [LLVM also has this limitation](https://groups.google.com/forum/#!topic/llvm-dev/jV3XBe4oi7o). And since Rust uses LLVM, it also has to deal with this.
The other suggestion I'd make is `pgrep wiredforge` which gives you the PID by default.
wow again! My google-foo is apparently not as good as I had thought
Currently Drop will be called at the end of the stack frame I believe. With lexical lifetimes, this may change.
Congrats on finishing. I'll second the usefulness of these challenges for learning a new language. I've linked my progress below, but I'll probably not get around to finishing the full series. https://github.com/JoshMcguigan/cryptopals
Sweet! I've heard of Citybound before, but I didn't know it was written in Rust!
An oft-criticized phenomenon in OOP is that people will kind of "zoom in" on individual classes, which are decomposed via the single-responsibility principle, and wind up with a design where "everything happens somewhere else." The same thing can happen with generic functions and types, where people will try to solve too-general of a problem and in the process atomize their actual program into lots of generic pieces. The other end of the spectrum here is things like ECS systems (if you watched the RustConf closing keynote, for example). The application's specific problem is solved in one place, where it's much easier to just do the specific things you need rather than trying to fit everything into an ideological framework.
Because otherwise clear code such as `let &amp;mut mut a = &amp;mut 5;` would just look plain confusing ;) Also where would you put the lifetime? `mut &amp;'a x`? :)
I'm of two minds about this kind of expressiveness: First, it's not always what you want- "just using `void*`" is often mimicking the Rust approach in C-land, and then you can rightly lament the loss of information and optimization. I'd often rather just write a different, simpler program to begin with- the way we often tell Rust newcomers not to use OOP in Rust. But on the other hand it's precisely one of the places I wish we had more exploration. For example, imagine C with `void*` replaced by type variables, just required to be behind pointers or whatever else allows you to avoid pulling in monomorphization or inventing a new object model. Maybe this is thin enough to avoid the C++ approach. So I think you're exactly right- there needs to be the right (small) set of (thin) features to successfully improve on the C++ approach in C-land, and this is a very hard problem. (Some other specific wild ideas: some use of row polymorphism for a better `offsetof` and intrusive data structures; maybe some variation on linear types to replace RAII's auto-generated control flow with more purpose-built error handling; etc.)
So it would seem :)
Great, I hated that pattern so much!
This is the subreddit for the Rust programming language. You're probably looking for /r/playrust 
Am I just vastly underestimating the cost of buildbots? If they're 1k each, and ~40 is what it would take to implement fuzztesting/ have meaningful coverage impact, that sounds to me like somewhere around 40k. Naturally Rust does not soak up all of those hundreds of millions of dollars, but we're talking about the cost of an intern for a summer. Maybe there isn't a strong belief that it would be high impact?
I \_love\_ your website design
Indeed!
I have not seen that written anywhere, so I don't buy it :P. If you disobey convention, rustc typically gives you warnings (e.g. for style), not errors. GHC emits a warning if top level declarations do not have type signatures.
No. I'm waiting for async await to finish a web service.
I just watched your talk a few days ago. Impressive! =)
gdb has had rust support since version 7.12. The built-in rust support includes an expression parser, which can parse a subset of Rust expressions. It isn't exactly Rust, though... mainly because I was just trying to get something reasonable-enough off the ground, but also because there are things missing from the debug info that make some things impossible. gdb's Rust parser also has one or two small extensions which are handy for debugging. These are documented [in the manual](https://sourceware.org/gdb/onlinedocs/gdb/Rust.html). If you have specific missing needs with gdb, please file a bug in gdb bugzilla. There's a "rust" component in the gdb product. Unfortunately, due to spam, it's a bit of a pain to make an account there, so you can also just send me email and I can file a bug. The rust-enabled lldb is in roughly the same state. I wrote an expression parser for it as well. It's less tested, since it essentially has no users (AFAIK), and I think currently has one or two more missing things than gdb. I'm working on getting this lldb into rustup for macOS and I will announce it when it is ready there. If you use the rust-enabled lldb and run into problems, file a bug in the [lldb project in rust-lang-nursery](https://github.com/rust-lang-nursery/lldb). I have a roadmap for debug info improvements but I haven't made it very public. I'll publish it somewhere soon -- I really should have done this sooner. One idea is to also ship a gdb via rustup so we can ship gdb changes more easily. The other things on the list are mainly specific debug info problems, e.g., making it possible to call trait methods by exposing traits in the DWARF. A long-term idea that keeps coming up is to change the debuggers to use the real Rust compiler. I'm not sure if I'll attempt this or not.
Seriously? This is already considered an anti-pattern in C, why even support it?
Iâ€™d enjoy hearing how itâ€™s an antipattern
No. I have no major complaints about Rust for command-line applications. For web use, I won't be ditching Python for a while as I rely on Django's apps ecosystem for rapidly putting together high-level stuff and, for GUI apps, I rely on `rust-cpython` to turn Python into a QML analogue for the QWidget API as a workaround for Rust not having mature Qt bindings with all the features I need to write native-feeling KDE apps.
Wait, it was *you* who wrote to_bits/from_bits? I've used those just yesterday on an unrelated project, and was really glad they exist. What a coincidence! Sadly they don't seem to work with the asm.js target, but that's a nightly-only tier-something thing anyway, so I'm not really surprised. I've only observed the issue with those functions, but haven't isolated it yet, so that might be due to something unrelated. But back to lewton. It's nice to see all these fixes shipping to users, and even nicer to see some decoding mismatches solved! With existing decoders for binary formats being notoriously exploit-ridden, we sorely need more memory safety in this space. Thank you for writing lewton and then actually maintaining it too - that's no small feat! I'm looking forward to fixes for the remaining memory exhaustion issues in lewton. I can't expose lewton to untrusted input as long as it's that easy to DoS, and not being able to handle untrusted input kind of defeats the point of using a memory-safe implementation instead of the most common and well-tested one.
One thing I prefer in Go over Rust is that all methods restate their impl every time. This is repetition, sure, but every time you look up a function, you have the information there, rather than having to scroll back up to find the impl block.
So far I think I've only encountered one and it was trivial to isolate simply by putting a part of a function into its own block. Do you actually run into cases where not having NLL is a deal-breaker?
While I understand your point in isolation, I fail to see how it applies to inference of function signatures ðŸ˜….
Wow. Today I learned that such parsers exist. Thank you! This might come in handy.
(maybe not so) nitpick - `tap` in Ruby does not return the result of the block, it returns the original object: [1] pry(main)&gt; 1.tap do|x| [1] pry(main)* puts "Is #{x}" [1] pry(main)* x + 1 # Block returns 2 [1] pry(main)* end # `tap` returns original object - 1 Is 1 =&gt; 1 
You can use it on beta today. Itâ€™ll be in 1.31 stable; the 1.30 beta is working a bit different than normal. That said, Iâ€™ve only ever needed NLL once in my five years with rust. Itâ€™ll be nice, but Iâ€™ve never needed it.
Nightly? When stable? 
&gt; Not sure why Rust only got a 4/5. Not sure if that's the reasoning of the author, but Rust is currently in the process of changing the module system. This is not some esoteric change in some rarely used feature - this is a breaking change in the very way you split your code across multiple files and the way you use third party code! Editions should smooth this out - without this mechanism, Rust would have deserved 0/5 in stability - but this editions are a new thing too and may have their quirks to work out, so a smooth backward compatibility is not guaranteed, so it's not enough to bring Rust all the way back to 5/5.
Yeah, recent discovery for me as well. 
It is generally confusing (like the small debate here showed), but in C specifically: int *a, b; Is `b` an integer or a pointer? int* a, b; What about now? Obviously it's the same code, only difference is in whitespace, but the association of `*` looks quite difference, right? Go has the same problem: var a, b[] int var a, b []int Is `a` an integer or an array? The answer, BTW: in C the `*` is associated with the identifier, so `b` is an integer. In Go, on the other hand, the `[]` is associated with the type - so `a` is an array.
So you have any details in a form of a list or something? I like having my rust code compile fast. 
Fascinating!
It looks like it might be a while: https://github.com/rust-lang/rust/issues/44874
Unfortunately this isn't that useful for me; Rust would have to start using this to find VSTools instead of whatever method it's using currently (likely VSWhere) to make a difference. I don't use Visual Studio or use VSTools directly, just through Rust. This just happened to me again (and I literally got to see it happen, as one `cargo check` compiled code and succeeded, then the next failed to `link.exe`). And it literally disappears from Visual Studio Installer, so good luck upgrading or modifying your installation. 
[https://github.com/rust-fuzz/libfuzzer-sys/blob/master/example\_arbitrary/src/main.rs](https://github.com/rust-fuzz/libfuzzer-sys/blob/master/example_arbitrary/src/main.rs) &amp;#x200B; &amp;#x200B; you can put any type in after \`data\`. &amp;#x200B; It's not properly documented
And `pkill` to just kill processes that match the same way as pgrep. Still an awesome thorough implementation of a useful command, thanks for sharing!
I think that people should stop anthropomorphizing Rust and ascribe their own philosophies to the language.
Rust beginners worrying about lifetimes is like kids worrying about quicksand. Both turn out to be a non issue in life.
Oh, wow! Thanks!!!!!
"I wish we had more exploration" is a great statement I wholeheartedly agree with! A fair amount of programming language research gets done, but not a lot (it seems) on the implementation details and design trade-offs compared to the "turning pure math theory into things that are useful to run on silicon" kind. Exploring those ideas was partially what my [recent thread](https://www.reddit.com/r/rust/comments/9ha73q/what_would_you_remove_from_rust/) was about, and it [inspired me to noodle around with further vague ideas](https://wiki.alopex.li/BetterThanC). Though probably not any that will ever go anywhere.
In fact, GHC offers a warning if you don't (with `-Wall`).
It's a warning in GHC with `-Wall`. Also GHC follows the Haskell standard. I get that type inference is harder in an imperative language but saying that this is good design seems silly.
&gt; I suppose I'm thinking more of Rust's rejection that "good programmers" always get things right In this case it's more a case of "GHC follows the Haskell2010 standard" while Rust has no standard as of writing. Like it or not, there's 20 years of compatibility choices.
Partly due to type inference in a functional language being an easier problem, but yes, GHC's error messages are quite nice.
What do you think about actor system vs ecs like specs?
&gt; Make sure to copy the data once for each core complex (unless it's small enough to fit into the local cache, in which case it won't matter) Maybe a dumb question, but how do you go about doing that? And can you detect that in some practical way as an optimization/alternative/conditional logic so it runs on that hardware but doesn't impact perf on majority of non-NUMA systems? 
&gt; I'm not saying the Rust/C++ approach is wrong or bad, but I reject the idea that the Go/C approach is lacking or something people settle for C has its advantages (namely, an ABI), but I can't think of anything Go has over e.g. Nim.
It's not nearly as obvious as you might think. Rather, there are some rough and mostly unstated guidelines that the language team adheres to roughly. Mostly, it is a matter of the least common denominator among the members (e.g. consensus) and this changes over time. Still, there are some areas which one could perhaps say constitute a philosophy such as "unsoundness is bad and should go away". However, statements like "explicit is better", "there should be one way to do it", "preserve the ability to reason about your code without looking elsewhere", and "compiler errors over convention" do not hold generally. I don't even think a principle of uniformity generally holds because folks disagree on what this means.
Very cool. I was able to try it out and get some buildings to pop up. 
I've royally messed up my rustup install (Windows) while switching from `-msvc` to `-gnu`. C:\Users\cad97&gt;rustup update info: syncing channel updates for 'stable-x86_64-pc-windows-msvc' info: latest update on 2018-09-13, rust version 1.29.0 (aa3ca1994 2018-09-11) info: downloading component 'rustc' info: downloading component 'rust-std' info: downloading component 'cargo' info: downloading component 'rust-docs' info: installing component 'rustc' info: rolling back changes error: failed to install component: 'rustc-x86_64-pc-windows-msvc', detected conflict: '"share/doc/rust/LICENSE-APACHE"' info: syncing channel updates for 'beta-x86_64-pc-windows-gnu' info: syncing channel updates for 'beta-x86_64-pc-windows-msvc' info: latest update on 2018-09-22, rust version 1.30.0-beta.6 (cb9c85aa1 2018-09-21) info: checking for self-updates stable-x86_64-pc-windows-msvc update failed - (rustc does not exist) beta-x86_64-pc-windows-gnu unchanged - rustc 1.30.0-beta.6 (cb9c85aa1 2018-09-21) beta-x86_64-pc-windows-msvc unchanged - rustc 1.30.0-beta.6 (cb9c85aa1 2018-09-21) C:\Users\cad97&gt;rustup toolchain uninstall stable-msvc info: uninstalling toolchain 'stable-x86_64-pc-windows-msvc' error: could not remove 'update hash' file: 'D:\usr\.rustup\update-hashes\stable-x86_64-pc-windows-msvc' info: caused by: The system cannot find the file specified. (os error 2) C:\Users\cad97&gt;rustup toolchain uninstall beta-msvc info: uninstalling toolchain 'beta-x86_64-pc-windows-msvc' error: could not remove 'update hash' file: 'D:\usr\.rustup\update-hashes\beta-x86_64-pc-windows-msvc' info: caused by: The system cannot find the file specified. (os error 2) How do I clean this up?
Oh right! I forgot, yeah that's an important point. Not sure what the right name for the method would be then.
If it was like Swift where to use a new version of the language, you had to migrate but there was a tool to do so, I'd more understand a lower rating. I can understand also a "editions are untested" drop in rating. &gt; this is a breaking change in the very way you split your code across multiple files and the way you use third party code! I'm a bit unsure on this. From what I understand of the module changes - You can do only what `cargo fix` changes and be happy (syntax, no file re-org) - there is no impact to your clients or those you consume regardless of how you use the module system and whichever edition they are using.
Did you check out the in game tutorial?
Very nice!
Yes, I agree. I'm just pointing out the amount of push-back on this sort of thing that is mostly out of not truly understanding the issues
Use the rust playground. It will show llvm, mir, and asm
Rust playground or [Godbolt compiler explorer](https://rust.godbolt.org/).
Also note that Citybound has its own subreddit: https://www.reddit.com/r/Citybound/
Does every discussion about Rust need to wax philosophic about Haskell?
Always happy to see unsafe code patterns getting pulled out of libs and into std where they'll have more eyes on them. :) Great work!
Agreed that Cargo definitely has room to grow, especially in the area of deeply customizing compilation and linking options. Iâ€™ve been using rustup just fine on ARM. What architecture are you having issues with?
Yes, I did.
At the lowest level, `rustc` can be passed `--emit=asm` (or something like that, I'm not at a computer to check). For local cargo projects, there is https://crates.io/crates/cargo-asm (which has worked well for me), and for short snippets there are the websites others have mentioned.
I think thereâ€™s a really big emphasis on surfacing complexity/cost of actions. Eg, requiring explicit type casting for numeric types to prevent data loss, explicit .clone() , forced error handling with results. Iâ€™m sure others can come up with a much better list lol. But when you do something in rust, it usually seems to have a pretty clear cost, and Iâ€™m rarely wondering about hidden complexities. 
On mac, sysctl. On linux, procfs. On windows, ???
On Linux atm. Ubuntu 18.04 LTS, GNOME desktop
Thanks for the offer! My immediate plans are to fix the remaining 5 broken files. Then I want to talk to Wikipedia about their media archive. Their content is freely licensed and due to their policy to only allow vorbis,wav and flac, they have a ton of vorbis files.
Finally it happened, apart of rewriting libs and existing tools, rust lovers got to bash scripts. 
Wow, that was quite an extensive hunt. Thanks for writing it up in such detail. &gt; But, Iâ€™m not sure why adding a lifetime to the Capstone struct fixed the error. I don't think adding the lifetime to the `Capstone` struct fixed the error. Rather, I think splitting your method chain into multiple lines fixed it by extending the scope and lifetime of `insns_backing`. I think the proper way to fix it would be to add a lifetime to the `Insn` struct referring back to the `Instructions` struct. Though that's just a guess.
&gt; Go has the same problem It has the same problem until you use `gofmt`. The recommended style makes it clear.
How do you mean?
&gt; lldb project in rust-lang-nursery Is there any interest in this moving upstream? I already regularly build LLDB and I'd love to try out using LLDB with Rust. If there's something that I could do to help that, I wouldn't mind. I've committed to upstream LLDB before.
One thing I would love to see is something similar to [turtle](http://hackage.haskell.org/package/turtle) for Rust. Turtle is a Haskell DSL that lets you write shell-esque scripts that are totally typesafe ([example](https://github.com/Gabriel439/Haskell-Turtle-Library/blob/master/examples/restoreBackup.hs)). Not sure how well the idioms would translate to Rust as `turtle` leans on full-program type-inference, custom operators, do-notation and other Haskell goodies, but macros and generics can go a long way too. While I'm making a wishlist, a port of [propellor](https://propellor.branchable.com/) (type-safe configuration management) would be nice too :)
You imagine correctly (in at least 1 case).
I honestly don't know in Rust. Commonly this is done using multiple processes, each pinned to a set of cores in the same NUMA node, and using the core interconnects more as a high bandwidth message bus than a memory bridge. It differs so much per system but on Linux you can query the NUMA layout using procfs or sysfs, I believe. But I'm no expert on this.
I'm not sure what you're saying here. I haven't written much Go. Can you give an example?
Thank you for the feedback, you are absolutely right stating that there needs to be much better documentation, I will work on that. For a start, I created a [basic example](https://github.com/sscdotopen/recoreco/blob/master/src/usage_tests.rs) (with some explanations) on how to programmatically use the library. Hope that helps. 
Check out [hyper-tls](https://docs.rs/hyper-tls/0.3.0/hyper_tls/).
Awesome work! I've been following Citybound for a little while now. What tools are you using for the continuous delivery?
You're going to need a certificate, which you can get for free from [Let's Encrypt](https://letsencrypt.org). Unfortunately I can't help you with hyper because I've never used it, but in general you'd tell your server to enable TLS and point it to your certificates. [This](https://github.com/hyperium/hyper-tls) might just be what you need.
I encountered the same problem a while ago, so I wrote a crate that can be used with hyper to serve TLS requests. It works, but I never uploaded it to [crates.io](https://crates.io) because I switched to actix-web for the particular project I needed it for, and actix has built-in TLS supports. It's available on github though: [hyper-tls-hack](https://github.com/miquels/hyper-tls-hack) . 
/r/rustjerk
```rust struct x {} imp x { fn y() -&gt; x { } // a thousand lines later... fn z() -&gt; x { } } ``` ```go type X struct { } func (x *X) y { } // a thousand lines later... func (x *X) z { } ```
Yes, just wanna join guys recommending `pgrep` and `pkill`. They were made to do what they do. You only need to know they exist :)
&gt; For a start, I created a basic example (with some explanations) on how to programmatically use the library. Hope that helps. I notice that you're still using `/** ... */` for module docstrings. (That documents whatever comes next in the file. To document the module, use `/*! .. */` or, if you don't want it to show up in the rustdoc output, use `/* ... */`.) Hopefully this will explain the relationship between the forms /*! Documentation for the module */ /* Just a comment */ /** Documentation for main() */ fn main() { /*! Also documentation for main() */ println!("Hello, world!"); } Also, `cooccurrences` looks like a typo. I'd use the `co-occurrences` form instead.
A common pattern these days is not to do TLS on the backend side, but do it on reverse proxy instead. The benefit of this is two-fold: 1) SSL certs are usually managed by DevOps people. It is much easier for them to set up certs for software they know (like nginx for example), then figure out your custom backend configuration 2) reverse proxies can protect your backend from attacks, like slowloris or file descriptor exhaustion. They can be configured to limit connection count, rate, caching and much more. If you're not in production environment, I'd recommend putting something like https://caddyserver.com in front of your backend. An additional benefit is that connections between the proxy and backend are not encrypted and easier to debug with tcpdump or what have you.
[cargo-asm](https://github.com/gnzlbg/cargo-asm) is another option.
Unfortunately, the hyper-tls crate just provides a connector, i.e. is client-only.
Your advice is sound. I would however take care that prod and dev environments don't differ much. If you use Nginx in production, you should do so in development. As developer you don't want to spend much time on webserver configuration. Work with your Ops people to automate things. Ansible is very handy for that.
Your username is a pretty solid pun.
Thanks. :) And yes, I also think that learning something about the building blocks of modern cryptography while experimenting with a new language is a great combination.
I think what /u/spaceman_ says is that it maybe goes faster if you give this function ownership over the products vector: https://github.com/luizberti/vek/blob/master/src/main.rs#L124 Eg you clone it with each call in the map above. I think this is correct after reading: https://www.kernel.org/doc/Documentation/vm/numa Physical distance from a core does matter in access time, if each processor (cluster) gets it's own copy it can be placed closer to it.
Did you use a reverse proxy in front of your actix project? Do you know if actix includes out of the box mitigations for DoS attacks (such as slowloris)? 
I was using nightly already for unrelated reasons when NLL arrived. There never was anything I didn't manage to write even before, but a lot of cases got a bit easier with NLL and a few would have been really hard to read without NLL. Now with NLL all over my code, it's the only thing keeping me on nightly, that I couldn't easily work around, so I look forward to it hitting stable.
If you do write a thousand line impl block, you should probably refactor...
Hmm. I think that in the case of `Rc&lt;T&gt;` this would be object-safe, but the problem is that the compiler can't properly determine that `Rc&lt;T&gt;` is object safe. For example, it's possible to create a another type that derefs to `T` yet holds the type in a way that isn't object safe.
I have been trying to do similar sort of stuff for a while. Realized proc wonâ€™t work for Mac and abandoned my project in middle! I guess I can start again ! Thank you!
Hello! i'm reading Rust book [https://doc.rust-lang.org/book/2018-edition/ch04-02-references-and-borrowing.html](https://doc.rust-lang.org/book/2018-edition/ch04-02-references-and-borrowing.html) Book said that this code should cause errors: let mut s = String::from("hello"); let r1 = &amp;mut s; let r2 = &amp;mut s; error[E0499]: cannot borrow `s` as mutable more than once at a time --&gt; borrow_twice.rs:5:19 | 4 | let r1 = &amp;mut s; | - first mutable borrow occurs here 5 | let r2 = &amp;mut s; | ^ second mutable borrow occurs here 6 | } | - first borrow ends here But it compiles ok to my suprise, no errors. Then i noticed that i'm using **rustc 1.30.0-nightly** toolchain. I switched to **rustc 1.29.0 stable** and expected error appeared. Question: what changed in 1.30 that code starts compiling? should i continue reading rust programmin language book or wait until rust update and text will be fixed?
I believe that 2018 includes support for non-lexical lifetimes. In the older edition, the compiler relies on lexical structure to determine lifetimes (so you'd have to enclose one of those mut refs in a block for it to work.)
Rustup supports far, far more than just x86.
I don't think I've ever seen someone use that syntax on functions. The syntax makes sense as a matter of principle though since it matches the rest of the language. The same attribute syntax (`#[...]` for the next item, `#![...]` for the containing item) applies to modules and crates. Inner attributes are necessary for crate level attributes and applying attributes to the root module since there is no place to put outer attributes. Both syntaxes are useful for all other modules depending on context.
For AES you can use `aes` crate and `block-modes`crates, which are part of [RustCrypto/block-ciphers](https://github.com/RustCrypto/block-ciphers). And for SRP there is also [`srp`](https://github.com/RustCrypto/PAKEs) crate. :)
Thanks. I had tried making self.parent mutable, but I used `&lt;&amp;mut 'a Logger&lt;'a&gt;&gt;` which didn't work.
Mainly the fact that it uses an `npm` approach instead of just using the dependency solver to enforce a unique version of any package. It makes it really difficult to share data structures between libraries. Not to mention, the compile times everyone likes to complain about are not exactly *helped* by having three versions of a library to build a package.
Didn't work the last time I tried it on Raspberry Pi, which was a few months ago. It might have been fixed in the meantime, but it's clear it's not as well supported as `gcc`.
Upstream doesn't want it yet. There are some links to the discussion in [the wiki](https://github.com/rust-lang-nursery/lldb/wiki).
Pattern matches have to match the structure of the variable - matching a `&amp;mut Option&lt;T&gt;` as `Some(t)` (which auto-derefs to `&amp;mut Some(T)`, I think) implies that you're trying to take out `t: T`, so you need to hint that you only need a mutable reference. You can skip the whole thing by doing: ``` match self.log_file.as_mut() { Some(inner2) =&gt; ..., } ```
"just using a dependency solver" is one of the harder remaining problems This is a problem that would be alleviated by libraries moving out of 0.x and by dependents using broader constraints so that the dependency solver in Cargo has room to work
&gt; This is a problem that would be alleviated by libraries moving out of 0.x and by dependents using broader constraints so that the dependency solver in Cargo has room to work True. It's definitely a process.
/r/rustjerk/
If you check the docs for the crate you linked to, the `digest_reader` method indeed does not exist for the `Digest` trait.
[cbindgen](https://github.com/eqrion/cbindgen/), used by webrender, supports generics and C++ output using ``enum class`` and ``template specialization``
Interestingly, the same is true for doc comments. With inner doc comments, you can write your doc in Python-docstring-style: fn my_function(arg: String) -&gt; String { //! Do something interesting. arg.replace("foo", "bar") } Not that I think it's a particulary nice fit for a braces language.
Ah, indeed. You have to enable `std` feature for `digest` crate as was written in the [readme](https://github.com/RustCrypto/hashes#hashing-readable-objects). In the next version `std` feature will be enabled by default, so I forgot to mention it.
- **Safety:** This is Rust's whole reason for existing, having a language that is safer. The end-users are the main beneficiaries: Rust's ownership system and other safety features (e.g., bound checks) make it less likely that someone's machine is compromised because of an exploitable bug. This imposes an extra burden on the developers (i.e., getting ownership right and re-learning how to design data structures), but I think the end goal is worth it. - **Performance:** If we only cared about safety, languages like OCaml, Java, or Python would be good enough. Rust imposes no costs for its abstractions and allows the programmer to organize data to get the maximal performance out of a modern computer. This is essential to allow Rust to be used in places where other high-level languages would not be suitable. - **Practical simplicity:** Rust is not a simple language when compared to the likes of Forth, Scheme, C, or even Go. However, I think Rust has _practical simplicity_: there are many concepts to learn (data ownership, shared vs. mutable borrows, traits and trait bounds, etc.), but it would be hard to remove some of these features without crippling the language. It's not simple that `&amp;my_vec` can be sent to a function expecting a `&amp;[T]`, but it makes code more generic. It's not simple to have a reference in a data structure, but if you don't have that, you can't be safe. APIs organized around traits are, IMO, more complex, but they can offer zero-cost abstractions whereas a `struct` that tried to cater to every need couldn't. 
Ahh I forgot it would be impossible to apply any attributes to the root module without this way. Thanks!
Subscribed.
This is great for me! Thank you for doing this work!
r/google
Well, go is a Google language and uses it https://github.com/golang/dep/blob/master/docs/Gopkg.toml.md
When I created an application that needed TLS a while ago, I decided to not bother about certificates at application level and tasked nginx to do it. This has proven as a good idea, since I gained nice flexibility: I'm now able to run several different applications on the same server, all pretending to use port 443. I even used nginx to handle simple HTTP authentication.
&gt; If they're 1k each Note that the price of a build bot (or cluster) is negligible when compared with their running costs.
I paused development on my Gameboy emulator because I'm already at my limit of learning and then the additional friction of things that could be figured out by the compiler but aren't pushed me over the edge to just wait for NLL
&gt; Also, why test / fuzz all of libstd? We only need to focus on the core components with unsafe, right? At least, that seems like the most meaningful target. Since this is a bit offtopic, I'm replying in a different comment. Pretty much all of `libstd` uses `unsafe`, to either interface with C, or to offer the most efficient implementation possible (so that people can rely on std and don't have to roll their own things).
Any plans about the road map for NLL? Will it be part of Rust 2018?
But if your language can properly encode bit-widths into the numeric types, you've strayed pretty far from the problem you're trying to solve. There's nothing *wrong* per-se, with modular arithmetic semantics. The problem is that the modulus is so large, and so rarely part of the semantics we care about that we forget to handle it.
C is the one that's surprising/inconsistent, Go's type syntax while different is very much consistent 
Digging through the code a bit, it looks like they did just that - individual `Insn`s now have their lifetimes tied to the backing `Instructions` instance, which must not outlive the original `Capstone` instance. I'd be interested in experimenting with removing the explicit lifetime of the `Capstone` struct, since I don't think it's actually doing anything significant here.
Yeah, so you'd use procfs, or `/proc`, which is what tools like `ps` use. As for getting the apps with an X window, that would be a little bit more complicated. Consult the X docs?
Good introduction to traits and trait objects. I wouldn't really call it a "deep" dive but there's only so much you can do if you start from 0 and have only 20 minutes. I found the example code to explain trait bounds a bit weird. `Elvish` is just a marker trait and `speak_elvish()` a static function taking a `T: Elvish`. It's much more natural for `speak_elvish` to be a function of the trait instead of a static function. Why not just reuse the `Constitution` trait from the previous example and implement like a `roll_for_constitution()` function or something?
Well, syn _is_ a Rust parser, not a kinda-like-Rust-but-a-little-different parser. So you should just fork it and call it kinda syn!
In addition to this, anyone claiming "well that's insecure", it's easy enough to chain enough proxies together. In fact most modern architectures on things like Kubernetes expects this. As long as the proxy and the software are on the same host it doesn't matter about https. So just bundle your application with a reverse proxy on every host :)
With 0.15, syn is taking a (slightly) more general position in that it's intended to be used for functionlike proc macros, so ideally it should be able to handle anything that the proc macro API will tokenize. I think I'm going to see if I can write a more general \`CustomToken\` (or \`custom\_token!\`) in analog to \`custom\_keyword!\` and see if I can get that merged.
It's not only about type inference. "Being able to reason about code locally" applies to many aspects of Rust, like lifetime analysis, drop analysis, validity of references, etc. 
&gt;If the type signatures of functions would be globally inferred, then so would be lifetimes and consts. Meaning that changing code far away could break a lot of code "by accident". As I've written elsewhere, this can be a warning instead of an error, like it is for top-level declarations in Haskell. It only breaks things if you're actively not following best practices. That's true for many things (e.g. using a lot of wildcards in pattern matching).
I've used Rust more as a toy than a tool for getting work done so far, so ensuring compatibility and using nightly builds was not as much of a concern. For long term projects, how do you decide which version of Rust to target? Do you pick the stable version and lock it there for the duration of the project, or upgrade with each new stable release, or do keep pace with nightly builds?
Oh snap. That's \*amazing\*, and is a solution to what in my head I call "The nalgebra Problem" that I had not considered before! (This problem isn't limited to nalgebra though, naturally.) Though I'm a little sad that it seems the maintenance burden for the entire Rust math ecosystem has fallen to you...
I'm using Yew in hobby projects but it's not as nice to use as [PureScript/Halogen](https://github.com/slamdata/purescript-halogen), mostly because of [this](https://www.reddit.com/r/rust/comments/99hr4j/yew_ideas_for_typesafe_childquerying_and/) [issue](https://github.com/DenisKolodin/yew/issues/350), so in production I'm still using PureScript/Halogen. Also, Yew's performance is [still slow](https://github.com/DenisKolodin/yew/issues/5#issuecomment-411253134) compared to others. I also wish that Yew was as production-ready and convenient to use and performant as PureScript/Halogen but unfortunately it isn't (yet).
I'm afraid I don't understand your point. That'll silently create an error IF you omit the type signature for some top level declaration (which means you are ignoring a warning). If your code compiles without warnings (in the hypothetical future Rust I'm proposing), then it will indistinguishable from the Rust code you write today.
So maybe we are talking past each other, but if you are editing a single crate, and change some code, and as a consequence the signature of a function is inferred differently, and that function happens to be on the public API of the crate, then you just performed an API breaking change.
I did worry about quicksand as a kid... ðŸ¤”
There's also [`#[derive(FromPrimitive, ToPrimitive)]`](https://github.com/rust-num/num-derive) available.
&gt; if you are editing a single crate, and change some code somewhere, and as a consequence the signature of a function is inferred differently, So far so good. &gt; and that function happens to be on the public API of the crate, then you just performed an API breaking change. There are two cases here: 1. The function already had a type signature (like Rust today) - This either results in a type error (because the new inferred type is incompatible with the old signature) or compiles with no error (because the new implementation can still be type-checked with the old signature). 2. The function doesn't have a type signature (so you'll get a warning "Hey you didn't document this exported function!" which you're actively ignoring) - and the new inferred type is not more general than the old inferred type (meaning that some code that relies on your public API might break). I'm saying the second case is not a problem in practice in languages like Haskell because everyone adds type signatures for functions that are a part of the public API.
This is not the sub your looking for. You want r/playrust
Do you know how to read sidebars?
It's simplistic, not simple. 
Worth to add: Ruby _appears_ to not use any copying when passing its strings to C functions. Ruby uses a `char *` to store strings, but it doesn't rely on NULL terminating them. I _think_ Ruby requires you to NULL terminate the string yourself, but I haven't been able to verify this yet.
`new` indeed optimizes to a no-op but returns a different type. If the type you need is a non-optional `NonZero`, not only youâ€™d need `unwrap_unchecked` which doesnâ€™t exist but this would also be less convenient IMO.
Ah sure, for crate internal functions, I don't think it is a problem.
Upon further digging, it seems Ruby _does_ append a NULL byte to every String, but conveniently ignores it. This in turn allows it to just pass a pointer to the string, instead of having to perform any copying.
Just to let you know, you were correct! I was passing the wrong AppState and got really confused with the error.
I added `Token![~]` in 0.15.6.
Thanks! This definitely cleans up my (working but messy) hack.
Thanks for the tip! I am not much of a bash developer and it always helps to get some pointers!
I'm not trying to take away anyone's iteration protocol.
Glad to hear it was helpful!
Rust quote of the week? ( yup - I remember being a bit worried about quicksand)
Interesting, I will have to check those out.
Full disclosure, I have been a bash hater far longer than I have been a rust lover.
I think [build.rs](https://doc.rust-lang.org/cargo/reference/build-scripts.html) is what your looking for and maybe [cargo-make](https://github.com/sagiegurari/cargo-make/blob/master/README.md) if you want a make like tool in rust
Excited to try this!
You can check out this series about porting a C library to Rust: https://people.gnome.org/~federico/blog/librsvg-posts.html. As for the build system, you can start either with a Rust static library that gets linked to the C code, or the other way around. In the first case, you'll have a make target that calls cargo, and you pass it to the compiler or linker. There's no single way to structure Makefiles, so the rest will be specific to your project. You'll also need to familiarise yourself with make. Your boss seems cool :-D.
Wait. Looking at yours and /u/AopicieR solutions. You're allowed to use the OpenSSL crate? I just finished implementing the AES decryption algorithm for set 1 challenge 7 but I guess I didn't have to?
The nuclear option is to `rustup self uninstall` and start over...
I'm working from the leafs inward, which means make needs to be in control of calling cargo rather than cargo calling make. Both of these tools assume rust is the controller and the other systems are slaved to it.
Looking at the instructions for that challenge again, I read it as they wanted you to use a library, they just didn't want you to manually use the command line tool. https://cryptopals.com/sets/1/challenges/7
The last week's thread link isn't working properly. On the new reddit, it doesn't show up as a link at all, and on the old reddit, it's showing as \[blah\]\(blah\) stuff. You need to make the link into an actual link: &gt;https://reddit.com/r/rust/comments/9ghwuv/hey_rustaceans_got_an_easy_question_ask_here Instead of &gt;r/rust/comments/9ghwuv/hey_rustaceans_got_an_easy_question_ask_here Even though the second one technically works as a link if you leave it all by itself, it doesn't work at the actual endpoint of a link. I just noticed this and wanted to point it out. :)
For concurrency and resource management, it makes sense that programmers cannot always be trusted because even the best ones end up writing bugs. So you've got a "track record of bugs" there. However, I don't see a "track record of bugs" due to people skimping out on type signatures, in languages where they're allowed to do so, so I'm not sure why you aren't willing to trust programmers to do the right thing there ðŸ˜ƒ If quality of crates is a concern, then crates.io could have a policy of not allowing submissions for projects that emit XYZ warnings on compilation.
Larger stack frames aren't generally a big performance problem (unless they're so large they cause cache coherency issues: we're talking many KB). On virtually all systems, allocating extra space on the stack effectively has zero cost since it just means incrementing the stack pointer by a large value. Zeroing the values is another issue, but Rust + LLVM is more than smart though to elide that in virtually all cases you'd encounter in the wild.
You can't just straight up pass `string.as_ptr()` to C, because it's not NULL terminated by default.
I'm pushing forward on the sudoku solver that's using human strategies for my sudoku crate. I need to find out how best to report the results of a strategy and for that I need to think about what information a GUI writer needs to explain it to a user. Whatever mechanism I have needs to be extensible to every strategy. For that, I'm writing a GUI myself to be the testbed. A Qt GUI hooked up to the Rust library via manual C bindings (ugh..). I've avoided this for a long time because of how annoying GUI development is. It's currently looking like [this](https://raw.githubusercontent.com/Emerentius/sudoku-gui/master/GUI.png).
Did it turn out to be an issue in life?
So far, all good. Regular sand has been more of an issue.
The key part here is "and a Len" I think. The C code should accept the length as well as the pointer then use the lengnh instead of checking for null termination.
Your best bet is probably to have a cargo project independent of the C project, and have the C project search your Rust project for one header file and one static archive. You can create a Make rule that will check mtimes of all your Rust files against the mtime of the Rust artifact, and execute "cargo build" as needed. Since you say you're "starting from the leaf functions" and working up, this should be a general guide for having Make run cargo and consume a static archive for the main project's linkage. Your Rust project will need three things: - the Rust code itself, which should do its best to follow Rust idioms wherever possible - an FFI module, which contains `#[no_mangle] pub extern "C"` functions which consume and emit C types, and manage calls into the Rust code - a header file, either manual or made by `cbindgen`, for your C project to reference. For now, I would *suggest* having your Rust code refuse to perform allocations, and make C own all the memory and pass in pointers to the FFI boundary. Now that 1.28 has the system allocator on stable, this advice is outdated for technical reasons, but keeping track of which side owns what is hard enough. I, personally, would recommend keeping Rust unowning until you're ready to move the entire lifecycle management of some objects into Rust, and have C borrow them. Anyway, to answer your original question, a Make target that depends on all .rs files and calls cargo build to make a static archive is a good start, and then have the primary Make target depend on *that* and solely add the Rust archive to linkage and FFI header to the include path.
It actually [looks like](https://github.com/rust-lang-nursery/rustup.rs/issues/304) I only need to wait until I can update [rustup to 1.14](https://github.com/rust-lang-nursery/rustup.rs/issues/1513), which [should be able to fix (at least part of) the issue](https://github.com/rust-lang-nursery/rustup.rs/pull/1472).
I love how detailed and clearly written the instructions are. Thanks for all your hard work.
No real need to copy, just be dependent on the files and headers directly; the rust code target should also do the build to prevent multiple cargo build if there are multiple rust lib targets. In general, since bindgen and cargo workspaces should probably be assumed, It may be better to have header file targets which would run their own bindgen and depend on the library files themselves depending on a rustcode target that runs cargo build on a workspace. That way, both headers and libs should have proper dependency management.
Nice!
Im having trouble accessing a marcro from another module. in [lib.rs](https://lib.rs) I have ``` pub mod macros; pub mod foo; ``` in macros.rs: ``` #[macro_export] macro_rules! point { // rules for point } ``` in foo.rs: ``` use macros::*; //code let p = point!(args); ``` for which I get the error ``` error: cannot find macro `point!` in this scope --&gt; src/stl.rs:9:9 | 9 | point!(vert.x(), vert.y(), vert.z()) | ^^^^^ | = help: have you added the `#[macro_use]` on the module/import? ``` I feel like I've tried every combination of `#[macro_use]` and use statements. Whats the correct way to handle this? 
I've done Go almost exclusively for the past few years but recently decided to give Rust another try! I've done a ton of networking and systems related projects in Go, but now I'm thinking about implementing something totally new in Rust. I was thinking that something like a virtual Ethernet switch or a small virtual machine could be fun!
`CString` does nothing to change the encoding. There's nothing in the standard library for handling conversion to whatever codepage C is using.
Create a top level cargo workspace in the same directory as your makefile. In your makefile, have a cargobuild target that runs the right cargo command, you can do the same for cargo test, install, clean. If you want the make behavior that if a file doesn't change, then the rebuild doesn't happen, you'll have to know your resulting library files and have a target for each that depends on the cargobuild target. Then what about the header files? Cbindgen should be your friend, but you have to make sure that they are only generated if there are changes to the rust source and create targets similar to the libraries (again if you want that behavior). There are ways in make (Gnu make, at least) to have all these targets be created with patterns, look it up if this creates too many targets. In your c compiler targets, you add the header files as dependencies and in the c linker targets, you add the libraries as dependencies.
This is a great guide for getting cargo working from Xcode!! I am working (slowly) on an app with the core written in rust with bindings for swift and kotlin. I have been writing everything by hand, I really wish there was something like djinni for rust because it saves a ton of time. 
I heard best practices were considered harmful
Plugin managers like vim-plug or vundle help a lot, but bigger things like YCM are still a headache to get working, and you still have to care about what flags vim was compiled with.
BTW, if the cargo workspace is setup to output to a rusttarget directory and the header files are generated on a cargo build, the new rules could be as simple as: cargobuild ; cargo build rusttarget/%.so rusttarget/%.h : cargobuild Obviously you still have to add the right headers and libs (including the rusttarget directory) to the compile and link targets. For example: ccode.o : ccode.c ccode.h rusttarget/someheader.h ; cc... finalexec : ccode.o rusttarget/somelib.s o ; ld... Good luck!
I don't understand what you mean (sorry if you're trying to crack a joke).
Be careful, the cp will change the file mtime even if cargo build did not have to do a recompile. If there are multiple libraries (cargo workspaces) the cargo build command should be run by the RUST_SOURCE rule to prevent running the cargo build command for every rust libraries.
I bought access to the video series! Thank you guys for making excellent learning materials. I appreciate the work you have done :)
Hello! Not been active (onthisthread) lately, but... Going to write a text editor to add to my projects list! As always, 80% of my development will be off-Git, and then I push one commit saying "Code fixes, cleanup, added text editor"
Just pushed the first version of [redis-protocol](https://github.com/aembke/redis-protocol.rs) to crates.io and will probably add some benchmarks later this week. This was my first experience with [nom](https://github.com/Geal/nom) and it's been great. That library is just fantastic.
Well, it's not object-safe but you can do `fn foo&lt;T: Deref&lt;Target=Self&gt;&gt;(self: T)`. Not sure how useful it is though
Itâ€™s not the only way it could be handled; you could, for example, make this work: /// Document the module itself with this phoney item: mod; /// Then document other items: struct Foo { }
is there any reason to be concerned about a performance penalty (compared to cgmath or similar) owing to the very generalised struct and function definitions? and if so, would it be feasible to improve with something like specialised procedure implementations for 'common' (Vec3, Vec4, Mat4, etc) types?
perhaps a `Cow&lt;CStr&gt;` would work well for your usecase?
Excellent! If you have any feedback or any ways of doing things that you've discovered that have worked better for you, don't hesitate to reach out. I've never used djinni, but \`cbindgen\` (and bindgen for that matter) alleviates some of the work of writing bindings. I'm thinking \`javah\` and \`bindgen\` might work together on android to generate some bindings. Not gonna be as pretty as djinni I'd guess.
map can already do this val.map(Result::&lt;_, ErrType&gt;::Ok)
 map(Result::&lt;_, ErrorType&gt;::Ok)
I was about 30% sure the title was a typo of "few real use cases" =D
That is exactly what I thought. Thanks!
Not on my PC right now but don't you need to have `#[macro_use]` above `pub mod macros` in lib.rs?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustcryptofin] [\[Video\] Portland Rust Meetup - Rust &amp; blockchain development](https://www.reddit.com/r/rustcryptofin/comments/9ieuja/video_portland_rust_meetup_rust_blockchain/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
thank you! now it works. that makes sense too.
I'm hoping on continuing my [SASS](https://sass-lang.com) library/CLI. The versions listed on the site all require runtimes (Ruby, Dart/npm, etc) so I think a native application with no dependencies would be a welcome change.
Your title is "how I decreased WebAssembly bundle size by 90%" but I read the whole post and feel like I missed something because it doesn't really explain *how* you did that. The only thing I could find is that you used "LLVM settings and `wasm-opt`". But which LLVM settings? I'm curious because I'm making a wasm application too but I haven't really looked into optimizing anything yet.
You are looking for /r/playrust, which is about the game.
You're not going to get much out of an FFI if it only works with functions that demand a `size_t` alongside every single `char *`
I know Meson supports both C and Rust, so converting the build system to Meson might be a viable path forward. I've only ever used it with C, though, and don't know if building Rust code with Meson is practical, or whether it would even provide any benefit.
[Link to the documentation](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip) &gt;'Zips up' two iterators into a single iterator of pairs ... Is there anything specifically that needs to be cleared up?
ahhh, I kept looking at the wrong documentation, its been a long day. Thank you so much for the quick reply. 
Youâ€™re going to get exactly what you want: be able to bridge $langage code and C. 
I'm currently in the progress of implementing a quite complex boardgame in Rust with Rocket (backend) + Yew (frontend). So far, the codebase is 100% Rust and I have almost no JavaScript on the frontend side. Interaction between js and Rust is really hard (which is also a reason why I dont have any js-code yet). Performance wise I dont have any problems yet. I only update the ui if the player actually does something (clicking a button, moving the mouse over the map). However, to be fair, so far I havent done much graphical stuff yet. I'm only implementing the logic and dump all necessary ui elements without much styling, etc. in the DOM. I also dont interact with any third party js library (yet?). Also, I havent tested my application on anything else than my dev machine (Arch with Firefox) yet. Unfortunately, I cannot link the repo yet because I still need to wait for clarification whether this project is a copyright infringement or not and what I need to change so that it is not breaking any laws..
No problem!
I would not swear on it but IIRC CPython will also ensure strings are nul-terminated internally but not use that property itself, you may want to check that. As others have noted you could also define your ffi as using length-specified buffers rather than nul-terminates. Thatâ€™s pretty much what Rust does after all. 
Why not? Every c std string function has variants where you specify the size and those are the ones you should be using anyway as they are safer.
I am going to continue working on [Thumbcloud](https://www.github.com/flofriday/thumbcloud) since I wasn't active there the last three weeks. Thumbcloud makes it easy to share files on the same network. Since the project already does everything I need, I will try to just implement the most important features and call it a day. If there is a community interest, I will keep adding new adding new features.
I made a logging library for the `log` crate that's designed for TUI applications. You run `tail -f log` in another shell, and put a `log_to_fifo("log")` at the start of your Rust code, and tada, you get pretty colourful logs for when you're already using stdout.
Ahhh I got paid to do just this. Writing the solver was one of the rewarding professional things I've ever done. The GUI... less so :). If you're able/willing to make it public I'd love to see it!
I suspect the most usable version of this idea is a `ConstCString` wrapper around `String` that mirrors the full string API while maintaining (and ignoring) the null terminator, and provides `as_cstr` and `fn into_cstr(self) -&gt; *const c_char` (That name is just a random idea off the top of my head, and is designed to contrast to `CString` which allows mutable access to the bytes via C, which means it can write a null terminator anywhere in the string, which would break any type that stores the length separately like Rust's `String` does.)
As someone listening to a D&amp;D podcast right now, this is 100% saved for watching tomorrow.
This is something that I've come across with very well-documented code, like std. Sometimes, even just reading the documentation, I have to scroll up a few screens to see the context for which the method is defined.
Unfortunately, Rust doesn't have that locality property when lifetime variance (or invariance) comes into play. See: https://www.reddit.com/r/rust/comments/9ha73q/what_would_you_remove_from_rust/e6bwv8a
`std` is sort of special here hehe; but I was mainly referring to code without documentation; ostensibly, you should be able to fold the documentation (if only VSCode and GitHub did this...) and then it is as if it didn't exist in terms of clutter. A thousand line impl block *after stripping all the comments* is something problematic however which should be avoided.
I'm using it for a RIIR of a React app of a hobby project. Loving it so far, despite it's warts (Spent hour trying to figure out that I needed to `&lt;div&gt;{ "string litetal"}&lt;/div&gt;` instead of `&lt;div&gt;string literal&lt;/div&gt;`). Didn't do any performance testing though. Last release is 0.4.0 from May, last commit is 20 days ago; I would call that project is active :)
Clickbait ftw
Thank you for sharing your experience with Yew. I think I'll try it for some hobby projects too. Then I'll be able to follow the development of this framework a bit closer
I think a good IDE can do a lot more. For example, show the context in the gutter next to the each definition.
Yeah, true; that makes it more tolerable; but I'm still opposed to files which are thousands of LOCs because usually that is a sign that there needs to be more separation of concerns.
The turbofish for example means `(a &lt; b, c &gt; d (e + f))` will (might?) parse differently than it does today.
Sure, but how is "there's already lots of chance for breakage" a good reason for adding more breakage? With imports for example I mean I only import traits into scope inside `fn`s to minimitze chance of conflicts. I'd love a solution where that breakage is zero. But I have to admit that changing a languages' syntax feels like heavier breakage than API breakage to me.
I, like, find trying to, like, read the, like, "Valley Girl", like, expressions, like, mentally, like, taxing, to the, like, point of, like, making my, like, pre-frontal cortex, like explode in a, like, bloody smash-up of, like, grey matter against, like, the ceiling.
Your question is honestly quite difficult to answer precisely without being able to see the actual C API that you need to call. Firstly, do _you_ control the C API? If so, then great, the problem is easily solved: don't use null terminated strings. Instead, pass a pointer to the string along with its length in bytes. This is quite standard. If you don't control the API, then your choices have been made for you, by virtue of the API. If the API _only_ accepts C style NUL terminated strings, then you must provide those. Unless you can make a trick work (like in Ruby) that permit transparently carrying the NUL terminator, you'll need to do an explicit copy and validation step. In particular, the trick isn't just about making sure you have a NUL terminator, but that the _first_ NUL byte is the actual desired terminator. Namely, `foo\x00bar` is a valid UTF-8 encoded string, but could cause problems for you. If you _really_ need to avoid the copy and _must_ provide a C style NUL terminated string, then I'd probably start thinking about solutions that involve building your own string type. With that said, any C API should be providing functions that operate on strings defined by a pointer and a length, perhaps _in addition_ to functions that operate on standard C style NUL terminated strings. If that's the case, then just use the ptr+len variants.
https://rustwasm.github.io/book/game-of-life/code-size.html
Good effort, seems to be easy to use at first glance. It would be nice to have support for middleware. A few things are missing from the docs or not clear how to use, like post body and other request fields. It would be nice to have a compete example in the docs.
My experience is that the ecosystem is still completely unusable. There are so many completely broken libraries, and I don't know how to track down the 1% that actually work as advertised.
What would you advise then ? What language / framework do you like ?
So Iâ€™ve been using cbindgen and the jni crate to generate headers and allow me to implement the jni glue in rust. Cbindgen works great but the downside is you still have the write the c compatible ffi manually in rust. I want to try generating it automatically from a procedural macro when I have time. The jni crate also works great but you have to reimplement every ffi function you made again to be jni compatible. Then you have to write the swift and kotlin wrappers manually which is super easy but takes some time. Djinni basically takes an IDL input and generates all the bindings and glue code for you. So I guess my goal is to provide the same (but simpler) for rust. Thereâ€™s a crate called swig for rust that does the java side but itâ€™s wayyyyy to complicated to use compared to cbindgen (needs like a 100 line build file) so I moved on from it at least from now.
Well, very simply, it's not necessarily an issue, only if you have multiple targets that have cargo build commands in their commands/recipes, it may be possible to end up running cargo build multiple times for the same make execution. I think, in general, you just want one target containing a cargo build command per makefile; this would also prevent parallel make (i.e. make -j) to run cargo multiple times and mess things up.
I started learning Rust only a few weeks ago. Currently I'm working on a game around space-exploration/colonization. It's very early stage and I'm just trying to get Amethyst going to work on some procedural generation. First I loved C for it's simplicity (compared to C++) and performance, then I loved Python for it's high-level abstractions. Now I think I fell in love with Rust &lt;3
I find it weirder than a 'output' has a iterator? Isn't the whole point of 'outputting' , to a file, stdout or whatever that you _don't_ hold on to the stuff in memory and that you're continuously pushing it out? 
The code in question is not iterating through an output, it's iterating through all possible output**s** (e.g both channels in stereo).
You have to see make as a dependency manager where each file is an independent dependency (including source code!); and also where you have to define each dependency manually, including how to create each file. Autotools exists to generate the dependencies automatically, but that's another story. Unless OP is dealing with autotools... Dun dun dun!
Thanks, I have an example here [https://github.com/alleycat-at-git/http\_router/tree/master/examples/hyper\_example](https://github.com/alleycat-at-git/http_router/tree/master/examples/hyper_example) and I'll add a link to example to docs. Also I'll check how it can be integrated with the middleware
I would love to see something like that. Do you already have a repo where you play with that?
I'm debugging the input code and fleshing out the systems code for the TicTacToe UR-ECS.
`map` is defined for a handful of types like Iterator, Option, etc to transform the *contents* of those values. Unless I'm misunderstanding something I don't think that helps in this situation because we're talking about ways of using a method call to wrap an arbitrary value with function that operates on the whole value, not its contents.
I started writing a Scheme-&gt;amd64 JIT last night. Most of my time was spent testing machine code and segfaulting but I think I've experimented enough now to write the compiler. I'm hoping to get it functional by the end of this week.
Even more so if he writes JavaScript
Interesting, thanks!
Sort of. Here is the repo I am working on [https://github.com/mpiannucci/buoyfinder-v3](https://github.com/mpiannucci/buoyfinder-v3) So far I have created the most basic working prototype, so I can now start to work on generating code that matches at least the same idea as what I have written by hand. Any input would be great!
I donâ€™t know what that is.
I wonder why it doesn't work when trying to import it directly into the test though
Yeah, this is the approach I'm currently going with since I have no control over the C APIs that are used. Thanks for the comment!
In this case I have no control over the C APIs, so passing the pointer + length would only work if the APIs in question supported that.
`#[macro_Use]` just wasn't designed to work that way. It's strange that the compiler suggested that usage, but `#[macro_use]` is going away in the 2018 edition, instead you would just `use super::cond::cond` like the macro was any other item.
That's a lot more useful tbh.
Yeah I think that's what I said... :-)
You might want to check out the Iridium tutorial for inspiration/ideas: [https://blog.subnetzero.io/project/iridium-vm/index.html](https://blog.subnetzero.io/project/iridium-vm/index.html)
Out of curiosity, has this been tried for targeting Apple Watch or Apple TV? I believe those are the two platforms that require LLVM bitcode on submission. Thereâ€™s an old discussion here related to this: https://github.com/rust-lang/rust/issues/35968 I worry Apple will make this a requirement for all apps in the future, and could be a big problem for Rust on iOS, on this specific devices.
just added some requests in \[issue 2\]([https://github.com/flofriday/thumbcloud/issues/2](https://github.com/flofriday/thumbcloud/issues/2)) :)
This is something I've been wanting to dive into for a while now. I currently have a couple of apps partly written in C++ for performance sensitive stuff. I've been wanting to move to Rust. Thanks for posting your project. 
You still need macro_use within your own crate for macro_rules macros 
Sorry, I don't have any recommendations. I just avoid webdev altogether. A month ago I tried to limit myself to _only_ using libraries written in TS (no JS allowed), but the quality level of libraries was still unacceptably low. I don't know of any language/framework for webdev with a usable ecosystem, but I'd be interested to hear about it if such a thing sprung into existence.
Er, because you want to be able to neatly interface with bog-standard common functions that look like: int open(const char *path, int flags, ...); int sysctlnametomib(const char *name, int *mibp, size_t *sizep); gdImagePtr gdImageCreateFromFile(const char *filename); int sqlite3_open(const char *filename, sqlite3 **ppDb); PGconn *PQconnectdb(const char *conninfo); Why is everyone so focused on APIs that accept a length? These are relatively rare and are usually string manipulation functions, which would be a spectacularly awful thing to use on an immutable shared String.
I haven't kept up with the new implementation, but I believe it produces the same errors as any other duplicate names for items, e.g. pub mod cond; use self::cond::cond; would not compile.
I've benchmarked, \*very non-rigorously\*, and in my experiment basic vector/matrix math was basically the same for all major Rust math libraries (nalgebra, cgmath, euclid). Didn't try fancier things. &amp;#x200B; The main performance penalty you get with nalgebra is compile times. :-P
You need `macro_use` *within your own crate*, but not for macros external to it.
What are the most popular rust web frameworks, which one is your favorite among them, and why?
That's a weird corner case, I assumed that would have been smoothed out by now.
That's a beautiful thing.
Working on my [Prattle](https://crates.io/crates/prattle) crate, which offers a general-purpose configurable Pratt/TDOP parser. 
I had a very pleasurable experience with nom last weekend, this week I'm going to expand my work and try to build some visualization tool for another team here. 
&gt; Copying is something I want to avoid because it's not efficient. For example, if we have a 1GB string, copying it (just so we can pass it to C) would require at least 2 GB of space. Other folks have given good practical advice, so I just want to add a question. Are you sure that efficiency is really a problem for you here? Unless you're calling a C function in a really tight, high-performance loop, there's a good chance that copying the string would be cheap compared to whatever you're about to do with it. You might've already measured this, but if not, there's a chance that it could turn out to be a non-problem. &gt; This also poses a bit of a problem: who owns the `CString`? Do we drop it right after we pass it to C, do we forget it using `mem::forget`? This is indeed a very thorny problem. Hopefully the C interfaces you're calling have clear documentation about what they're doing with the strings you give them. That said, even if you find a no-copying solution, you still have this problem :( Unless you `mem::forget` one of your `Arc` pointers, it's possible for your Rust code to free a string that C is still using.
Syntax or the API? Syntax is pretty standard and intuitive. 
.... *looks over at weird default value and hashing enums like `Varient1(_) =&gt; 1` code* Well, that is a cool thing.
Rust's syntax is fine. I find it a good mix of keywords and symbols that's reasonably easy to scan without being too verbose. If I could wave a magic wand, I'd change lifetimes to use something *other* than `'` (purely because it upsets some editors), and... that's about it, really. Turbofish is a bit odd, but serves an important function and makes sense once you know what it's for. As an aside, I really don't understand the "it ruins the language" complaints about it. Of all the things you have to learn about a language in order to use it, the syntax is almost certainly the easiest. In Rust's case, the only part that I think is non-trivial to learn is `macro_rules!`, but that's basically a symbolic substitution DSL embedded inside Rust, so it's hardly surprising. In terms of complain-worthy syntax, I'd point to C with it's awful Spiral Of Doom type syntax. 
I donâ€™t have many issues with the syntax. What do you have in mind?
This writeup is fantastic; thanks so much for taking the time to do this! :D
&gt; I can't help but feel that Rust's features and language could have been implemented in a much cleaner fashion that would be easier to learn and more amenable to coming-of-age developers. How do you define a 'coming-of-age' developer? I hope you're not suggesting more C-like type declarations? Do you have an example of what this much cleaner syntax might look like?
&gt;The syntax makes me want to drop Rust and start writing C again. I'm surprised you so strongly prefer C's syntax over Rust, I always thought they were similar. Which additions or changes rub you the wrong way? Personally I've never really been bothered by syntax of any language, other than the brief period where I'm trying to learn the new syntax and trying to shake off old habits. I can think of a couple examples across languages that bothered me but it's rare and easy enough to look past. That being said, I *mostly* work with C style languages imperative so all the syntax is pretty similar.
I'm fine with it, except for the semicolons.
Yes
What part of Rust's syntax feels off? The only syntactical hiccup I had with Rust is the separation of `struct` from `impl`, as I was coming from languages where you write _everything_ in the declaration. Playing with Swift was a breath of fresh air in that you could separate protocol (trait) implementations from base data. Rust was just taking that to the logical next step of actually fully decoupling state from behavior. Compared to C, though? I _really_ don't see the complaint. I _still_ barely understand the order in which to read a C type, and _really_ don't like that `int32_t* a, b` is `a: *i32; b: i32`. Method call syntax is a huge improvement as well over C, meaning that my data actually goes forwards instead of out. Maybe the expression-oriented grammar takes some getting used to. But I really like it, personally. Any nits I have about Rust is not in syntax, but how it's used by the language (`as`, mainly). Syntax is super surface level, though, and I'd put up with most any somewhat logical textual syntax if it gave me Rust's semantics, which have made me so much more confident in my code, while retaining the productivity of a mixed prededural-functional style. My language of choice if Rust is off the table is Kotlin. Take that how you will. (I'd use Swift more, but I both lack an Apple machine and loathe their lack of a module/namespace system.)
Released [brokkr](https://github.com/lirsacc/brokkr) over the weekend. It has some rough edges / not very idiomatic parts, but it's usable and I plan on ironing out the trait bounds and improving the error handling this week.
I continue my work on envconfig ([https://github.com/greyblake/envconfig-rs](https://github.com/greyblake/envconfig-rs)). It's getting closer to "done" state. I would appreciate if someone tried to use it against real life project and tell if there is something missing.
For me, the really trivial thing that the `windows-gnu` (MinGW) toolchain on Windows "just works". I've had some issues with MSVC recently, so seeing `-gnu` just work, even if it feels like the toolchain takes a bit longer to install, is awesome. More and more I'm transitioning to more OS-agnostic software. But for now, I'm stuck on Windows as my main driver, and it's great that Rust was able to trivially paper over the most recent in a series of papercuts Windows has given me. (I still like Windows 10. It's just that its flaws become harder to ignore as I do more dev work.)
The speed of copying isn't my biggest concern, because modern systems can move memory around pretty quickly. I'm more concerned about the memory usage that results from having to temporarily keep data around twice.
Itâ€™s never going to be; macro_rules is on its way out, so thereâ€™s little incentive to mess with it.
Happy it helps! 
You don't say what you object to in Rust's syntax, so I can't speak to what you find objectionable. For my own tastes, Rust could have kept more of the beauty, simplicity, and elegance of OCaml/Haskell rather than bringing it so much from curly-brace languages, which is an annoying unforced error IMHO. While I find it a bit cluttered because of that it's a fairly minor complaint of mine, and I have similar complaints for most other languages. But for coming-of-age developers? Rust's syntax isn't going to be any harder than other popular languages for newish devs who aren't yet set in their ways.
Please don't do this, but [here's an automatic semicolon insertion macro](https://play.rust-lang.org/?gist=af2344b32841efc18e029c6635d62c16&amp;version=stable&amp;mode=debug&amp;edition=2015)
I cross compiled to an Apple Mach-O on my ArchLinux machine. Cross compiling is getting so easy now. Unfortunately one of the crates I was using depended on a C library. So I had to grab a special linker. Not too bad though. 
Assuming I don't want to use the nightly compiler, is there a prevailing method for "pattern matching" against boxed values? I've racked my brain trying to find a good general approach and unfortunately have come up short. But I'm still fairly new to the language so I'm hoping I just overlooked a decent solution.
It's fine. I don't like the `?` business and I find its use of semi-colons to be too cute, but that turns out not to bother me as much as I thought it would. It's a hell of a lot better than C++ or Perl, but that's damning with faint praise. It's not the prettiest language out there, but it's okay. I'm not sure that if it were redesigned from scratch that it would be very different because I think that by-and-large the designers are happy with most of the choices they made.
I have an editor plugin that (mostly) takes care of it for me.
I am currently working on improving tooling for [rlsl](https://github.com/MaikKlein/rlsl) It is hard to read spir-v in textual form if it has tons of branches. https://i.imgur.com/G5u6FTl.jpg Although in retrospect I should probably output 1 image per function, even imgur can't handle the resolution.
Which crate, if I may ask? 
That's interesting. It sounds like you really do have 1GB strings in memory? In that case I wonder if `String` is going to cause issues for you too. (If you're getting 1GB from somewhere on the filesystem, is it really guaranteed to be valid UTF-8? Is checking its validity going to slow you down?) It might make more sense to just hold onto a `Vec&lt;u8&gt;` and manually append a null byte as necessary, as I think someone else suggested. Or maybe the underlying C library can accept some kind of stream or file handle, and you can avoid this problem entirely? I'd be surprised if a C library forced you to keep a large file entirely in memory.
It turns out `TryFrom` is implemented between integer types that aren't guaranteed to losslessly cast. Unfortunately it's nightly-only for now.
Whats happening to macro_rules?
Yes. The syntax is _really_ simple bar few exceptions. First year computer science students with no programming background can understand the syntax easily (lifetimes do give trouble but that's not a matter of syntax).
libusb
Syntax has a weird place in our brains. If you make it too generic, all the important concepts have nothing to attach themselves to, and you muddle up one language with the next. If you make it too hairy (Perl!) it gets hard to remember the syntax you need to do a particular thing. Anyway, as others have said, as an exercise you could make a preprocessor to convert your ideal syntax to Rust, and see if you can find a happier compromise, and then let us know.
Really nicely written account of a useful approach. Thanks!
You can also put a `.cargo/config` in the project directory if you want local settings.
Coming from C++, the Rust syntax feels familiar. It is a good mix of symbols and keywords. I like types at the end, I like match statements, I like the compact lambda syntax. I especially like that you explicitelly pass self (or &amp;self, or &amp;mut self) to a function, since this always confusing in C++. The only thing I dislike is the lack of a ternary operator. Since x?y:z feels much shorter than if x {y} else {z}.
C's syntax is an abomination, really. Mistakes were made. The failed experiment of type declaration by example, the just plain wrong precedence level of some of the operators (for that matter, the weird operator syntax), and a whole host of minor issues. That said, C has become familiar to an awful lot of people, and some of C's choices have become *de facto* standards for new programming languages. Rust (like our [Nickle](http://nickle.org) programming language) has done a reasonable job of picking the stuff that's OK from C and ditching the worst of it. Once you get used to the Rust syntax, C's will feel quite painful to you. Give it time.
Interesting! For example, u128 -&gt; u64? 
I think the syntax is fine. Very explicit and all the braces and semicolons are noisy but ok. I would prefer a more ML/Haskell like syntax but being C like has its benefits for adoption and familiarity which I think are more important.
&gt; Is there any... "reasonable" use-case where wrap on overflow is desired? My comment was an attempt to illustrate why this might be desired, or why people coming from other languages like C might want or expect this feature. I share your opinion that explicitly stating this in code is preferable. If I remember correctly though, wrapping_add returns the value, so instead of: nonce += 1; you will have: nonce = nonce.wrapping_add(1); 
The languages I write the most of, in descending order, are currently Go, Elm, Rust and Python. In terms of which languages I think have the cleanest and most appealing syntax, Iâ€™d rank them Elm, Rust, Go, Python. With a lovely language like Python at the end of the list, I hope itâ€™s clear I have a high opinion of all these languages. Elm is a much simpler language than Rust, so itâ€™s no surprise it would have clean, elegant syntax. However while Rust has the most unique features of the bunch, I think itâ€™s actually a really elegant language considering how powerful it is. There are plenty of ergonomic things that can, have been and are being improved, such as pattern matching on references, but I find everything from declaring functions, types, traits and so on to have pleasingly consistent syntax. Pattern matching is very consistent with how we write literals. When youâ€™re just writing plain, baseline Rust code, I think the language is about as simple as it can be. Unlike in Go, for example, which has special syntax for things like looping that you canâ€™t directly reuse yourself (as you can in Rust by implementing Iterator), everything Rust has available to it is also available to the programmer. There arenâ€™t really any standout special cases where Iâ€™ve had to remember some convention I should follow instead of doing something Iâ€™d expect to be able to do naturally. Rust does definitely get hairy when you start doing crazy things with macros and lots of genetics/lifetimes, but there is only so much you can do about that without being a Lisp dialect. I think once you get familiar with Rust, one is likely to find the language is very cohesive and simple, if not necessarily very easy to use all the time. Rust makes difficult things simple, but they are still a bit difficult.
You easily convert from an `Iterator&lt;Result&lt;X, Y&gt;&gt;` to `Result&lt;Vec&lt;X&gt;, Y&gt;` simply by calling `collect()` with the right turbofish argument. This will lazily evaluate the iterator and return `Err(Y)`if it hits an error or `Ok(Vec&lt;X&gt;)` if there are no errors. All because Result implements FromIterator. It is such an elegant dance of the type system, the trait system, and functional programming,
what macro keyword? Whats happening to macros?
Yes, I should have been more clear about target vs. archival, as itâ€™s the latter thatâ€™s the issue. Itâ€™s a super annoying requirement from Apple, and as far as I can tell, offers very minimal benefit.
&gt; Sure, but how is "there's already lots of chance for breakage" a good reason for adding more breakage? That wasn't my point. My point is that this change is "as breaking" as all other breaking changes that we are continuously doing. As long as these changes do not break anybody's code, those seems to be ok. So why wouldn't this particular change be ok? 
I agree, but the typescript ecosystem is the best of the bunch for javascript flavours. 
I personally dislike the lifetime syntax due to the use of a single quote. Every time I try to type `'a` Vim (and probably pretty much every other editor) will complete it to `'a'`. It's a minor thing, but it's annoying nevertheless.
Oh neat! 
The syntax is all about familiarity. When I started, I thought Rust syntax is a bit odd, now I think everything that is not Rust is odd.
What? That's awesome! We should have this kind of threats more often.
https://words.steveklabnik.com/an-overview-of-macros-in-rust
The only thing that really bugs me is the required curlies on if/else blocks.
And it works for any type that implements `FromIterator`, not just `Vec`. So you could just as easily collection into a HashMap, HashSet, or a crate data structure.
Ah, sorry, yes. I mean it will evaluate _only_ until it hits an error or the end of the iterator. If your iterator has 1000 elements, but the first one is an error, it will not evaluate the remaining 999.
Related: [https://bzim.gitlab.io/blog/posts/incinerator-the-aba-problem-and-concurrent-reclamation.html](https://bzim.gitlab.io/blog/posts/incinerator-the-aba-problem-and-concurrent-reclamation.html)
I really like the syntax. The most important things for me are: That different concepts have sufficiently different syntax that you can scan the code quickly, which Rust's use of keywords accomplishes. That big problematic constructs have big in-your-face syntax, and that the more insignificant parts of the code have small syntax that you can easily glance over - I think `unsafe` and `?` are good examples of this. Also, when learning it it was useful for me that new Rust-specific concepts have Rust-specific syntax. Having to write the very foreign syntax `'a` to express a lifetime really drives home the point that lifetimes are a new, foreign concept. It is very C-like, but corrects all the stupidity that C has. It's consistent, terse, and familiar. It's great.
Did you try running the cross-compiled binary on MacOS?
As someone with a codebase of 80k+ Typescript LOC, this has not been my experience. Sure, you find libraries with outdated Typescript definitions, but that's easily fixable (preferably by a pull request), and more and more libraries are either written in Typescript or ship with their own definitions. The type system is extremely powerful, especially if you switch `strict` on in tsconfig.json. This is not always going to save you from Javascript weirdness, but it is by and large an extremely pleasing experience.
[Yep.](https://doc.rust-lang.org/std/primitive.u64.html#impl-TryFrom%3Cu128%3E) Also, there's a `From` impl in the other direction.
I can offer experience with actix-web. I created a REST-service for managing specific docker containers and also wrote a web site with minimal CMS functionality as an executable. The framework is fairly popular, in active development and also [fast enough](https://www.techempower.com/benchmarks) for most purposes. Not #1 except for "Plaintext", but still in a different league than the usual LAMP stack. I like that it supports using Futures but also can be used writing completely synchronous handlers. You can focus on getting things done and keeping control flow simple and then, if the need arises, convert parts to asynchronous code. Since actix-web is based on an actor framework (called actix), the same can be used to build other parts of your software, so that one way of handling events and passing (type-checked!) events applies everywhere. Using Futures will most probably become at least an order of magnitude more comfortable when `await` arrives. Request handlers can be made to extract parameters from the URL, form data, JSON bodies and more, making it easy to build services and process client-supplied data. Actix-web also includes an HTTP client, which I used to query and control dockerd in response to REST requests.
&gt; I've used an extensive amount of [...] C++ [...]. The syntax makes me want to drop Rust So which Rust syntax is not C++-like ? I came from C++, and Rust uses pretty much the same syntax. The only new things in Rust are three different types of generic kinds, but C++ already has two generic kinds (types and values) and they use different syntax anyways. 
https://doc.rust-lang.org/nomicon/phantom-data.html#table-of-phantomdata-patterns and here some info about varience https://doc.rust-lang.org/nomicon/subtyping.html#variance
Can you give some examples of what you're having trouble matching? If it's an owned Box, you can just `match *b` to deref to the contents.
I do not overly trust my brains capacity for keeping too much finicky stuff in memory, so I love being explicit at function boundaries. Also like the \`var: type\` construct, since it is unambiguous on first glance. There is nothing particularly bad about the syntax IMHO, but if it were anything but extremely annoying, I'd probably pay the price to get Rusts functionality.
It's also listed [here](https://doc.rust-lang.org/rust-by-example/error/iter_result.html#fail-the-entire-operation-with-collect)
Thanks. I'll go through the whole chapter!
If you have a list of idioms like that, that would be very helpful!
It can be mildly annoying sometimes, but I'd argue it's worth not being bit by the problems you get in C if you accidentally omit the braces in a multi-line `if` statement.
Currently I am really enjoying HashMap and HashSet. They come in really handy for a few things and are so well designed.
gets job done
Not if it's different names? Things like this should work, and are much more complicated to resolve with `use`ing macros rather than `#[macro_use]`: mod a { macro_rules! import_macro_b { () =&gt; { use a::macro_b; } } macro_rules! macro_b { () =&gt; { fn main() { println!("hello, world!") } } } } use a::import_macro_b; // 'use' statements now need to be processed both before and after this macro expansion, and before // the expansion of macro_b!(). import_macro_b!(); macro_b!(); With `#[macro_use]` something like the above is not a possible scenario since the directive is only ever specified once on the module defining the macros itself. Things like this is why we haven't had `use super::cond::cond` until now.
Looking forward to this since Yew seems to be pretty unmaintained.
I'm working on implementing an [ext2 filesystem](https://github.com/jcdyer/ext2/). Currently it can find and read small files in a small filesystem. Soon it should be able to find and read large files in a large filesystem. Eventually, I'll start looking at making the filesystem writeable, and supporting various extensions. Interesting side note. I discovered that you can create a filesystem in a regular file by doing mkfs.ext2 ~/filesystem-file.ext2 128M. Mounting and unmounting work the same as if you're mounting a block device, but you can move your "filesystem" from one place, upload it to github, email it to friends, etc.
I never published it, but I wrote an [include_dir!()](https://github.com/jcdyer/include-dir-macro) procedural macro a while back that sounds like a barebones example of what you're trying to accomplish. Feel free to take a look. Using a proc_macro was the only way I could find to do it without a build script. Simple usage in the examples: https://github.com/jcdyer/include-dir-macro/blob/master/examples/poems.rs 
There's no way to know for sure it won't break any code anywhere. The more of these syntax changes you make, the higher the chance that something breaks for someone. Funneling them together into editions minimizes the impact.
Oh man. Omitted curlies are one of my least favorite things about reading other people's code.
Yeah, I looked into that but I didn't find a way to do it on stable rust - which was a goal. There's a proc macro hack crate, but it can't have 2 macro calls in the same scope. I'm looking forward to being able to turn it into a function macro on stable rust though. Thanks for the link
Default vim doesn't do that. You can probably fix that without too much trouble. VSCode also won't do that to you. I'm also not a big fan of the syntax, but it gets the job done. I actually have a bigger issue with the community practice of naming all lifetimes `'a`. I think we'd have a much easier time teaching lifetimes if we gave them meaningful names like we do with every other variable.
Everything's on Github. [sudoku crate](https://github.com/emerentius/sudoku/tree/strategy_solver) | [bindings](https://github.com/emerentius/sudoku-ffi/tree/strategy_solver) | [gui](https://github.com/emerentius/sudoku-gui) It's all very much WIP so the code's quite hacky and literally everything can change. So far, I have a few simple strategies: naked &amp; hidden singles, naked &amp; hidden subsets (pairs, triples, quads), x-wing, swordfish, jellyfish, locked candidates and singles chain but the GUI is still barebones.
Great post! &gt; To do that, I would expect us to replace the directory with a HashMap mapping from kind of service name to a Sender for that service. This also might be a good use of https://crates.io/crates/anymap
On the subject of "Who owns the data in GC'ed languages": For myself, I have determined that the best way to think of it is that the Garbage Collector owns the objects. Everything else just references them. When the Garbage Collector determines that no-one is currently referencing an object, it throws it in the garbage. But, the owner is always the Garbage Collector (or the HEAP MANAGER if you prefer).
Right, if you have something with the same name as the macro defined in the same place, it isn't possible to import the macro without importing the other thing as well.
It's fine. Something ML-y would probably be nicer. It basically *is* OCaml to a large extent: everything except assignments are expressions, the value at the end of each block is implicitly returned, etc. Any programming language's syntax is a matter of training your brain, to one extent or another; there's nothing "intuitive" about any of it. I think the part that irked me most was that `-&gt;` and `=&gt;` were separate things.
Yeah. Time was you had to do a lot of irritating stuff with loopback devices to make that work right, but at some point apparently it got much more streamlined. If you write a command-line program that can manipulate qcow2 disk images nicely in this fashion, I will love you. ;-)
I'm not sure if this is intentional, but the design did remind me immediately of Servo design with its [Constellation](https://github.com/servo/servo/blob/master/components/constellation/constellation.rs#L158), which contains the various ends of all the different channels in the engine.
I've just pushed an example crate with a mail viewer application. It should compile with 'crate build' and links to Qt. The bindings were generated with Rust Qt Binding Generator. Surely that's more convenient than writing bindings in C. https://crates.io/crates/mailmodel https://www.vandenoever.info/blog/2018/09/16/mailmodel.png 
This is very neat. On micro-benchmarks the contention on the PAUSED_COUNT will probably show but it should perform well in real world programs.
It's always kinda fun to consume a json-api. You'll learn to use several important crates in the process.
Yup statically linked. Worked fine
&gt;I've been trying to learn Rust. The syntax makes me want to drop Rust and start writing C again. Then drop and go write C? Each language has own quirks and features, you cannot just expect it all go smoothly once you start. Language like Go and C has simple syntax just because they lack complex language features, while C++ has sad inheritance from C. I'm not even mentioning that languages such as Java are verbosity cancers. In the end it seems to be personal preference rather than objective complaint, right?
Why today am I suddenly having Disconnection Time Out issues with all server? Wired and WiFi. Checked game files, reinstalled, nothing. Months of flawless (albeit laggy) play and now I canâ€™t play for more than 10 seconds before time out.
I do personally believe an explicit return is more clear. But other than that and the weird lifetime ' syntax, I think the language is fine :)
Mailmodel doesn't work for me because it requires QtQuick.Dialogs version 1.3 which in turn needs Qt 5.10. But apart from that, I don't see how I can do what I need with the Rust Qt Binding Generator. It seems very inflexible. The types I can define in `binding.json` seem to be limited to integers, floats, booleans, byte vecs and strings and some QAbstractItemModels. What I need is the ability to call into Rust code with arbitrary arguments and get arbitrary results back. The data may be ephemeral and therefore getters and setters don't make sense. I also don't see how I could make fallible operations with them. IIUC, QObjects are used for signals and slots. I don't need that. The Rust code is there for the game logic, not the control of the GUI and can be fully synchronous. I suppose it would be nice to write as much as possible in Rust but the necessary upkeep of the bindings doesn't seem worth it.
wrote a HRTB for the first time in my life this week!
&gt; Why is it a template parameter? I like to think of the stuff between `&lt;` and `&gt;` as generics, not template parameters, and then it makes perfect sense (to me): the `struct` / `enum` / `fn` is generic in the lifetime.
It's basic Rust (I just started), but pattern matching. At a time when you see a lot of languages waking up to the power of pattern matching [[1]][[2]], it's built right in to Rust. I appreciate it. [1]: https://www.chriskrycho.com/2018/why-we-want-pattern-matching-in-javascript.html [2]: https://bugs.ruby-lang.org/issues/14709
The power of Rust's type system + zero cost abstractions never fails to amaze me
Yeah... Just feels weird.
Mostly fine, but it could do without the curly braces.
I have happily used this pattern in a tokio-based application, using futures channels and streams as communication primitives. Really sturdy and great to test if you make most components generic over \`Stream\` types.
Given your interesting side note, you might find my FAT32 implementation interesting: [fat-rs](https://gitlab.com/susurrus/fat-rs). It has CI testing (on Linux only) for exactly what you describe. I designed mine to work in `no_st` so it could be used in microcontrollers for reading SD cards. I'd be curious see what your API looks like as I'm not certain mine is an ideal one. I'd love to get to the point where my lib and somebody else's filesystem are essentially drop-in replacements for each other post-initialization.
Thanks for testing. I've published a new version that works with Qt 5.9 by reducing the required version of QtQuick.Dialogs to 1.2. The supported types in RQBG are what you say. You can use them with synchronous functions if you want. See e.g. https://cgit.kde.org/rust-qt-binding-generator.git/tree/tests/test_functions.json The idea of RQBG is that state resides on the Rust side and that the GUI gets notified of changes in the state and adapts accordingly. QObjects are for signals and slots but also simply for properties. When a property changes, a signal is emitted. In QML, you do not handle these signals and slots directly. You just assign values from the QObject to you GUI and when something changes, the GUI updates automagically. 
While the package might be great, it is a bit strange to see the author taking potshots at languages with poor/no compile time checks at the very beginning of the Readme.
You're probably using some weird ready-made vim setup since you think that's the default. Don't: it's much better to slowly build your own setup.
I'm not, I have been slowly building my own Vim setup over the past 8 years :) Vim might not do it by default, but I'm sure other editors might.
I've had to be careful using it (well, collect in general) with large HashSet/HashMaps - I was using it a lot recently and it turns out that the HashMap/HashSet isn't preallocated using with_capacity (I guess the size isn't always known in advance), so you can end up with a lot of reallocations as the containers grow!
If you need more CPU than memory it is better to use C5 machines. R4 is ideal for the opposite case. 
The worst part of the `'` being used for lifetime is that I have to press space, or I get `Ã¡`, instead of the intended `'a`. I'm getting used to writing `'x, 'y` to avoid this issue, but every bit of documentation using `'a` doesn't help. Obviously this is a pretty minor complaint to have, just a little annoyance that's all.
Just ensure that there can't be a null byte in the middle of the string and that the c api actually uses the same byte encoding. Very often, Unicode is not well tested when passing from one system to another and leads to weird behaviors since different encodings can be very similar; especially in English.
I find that working in rust helps you think better about the problem than the language. In such a case, your solution to said problem is most likely to be different from the traditional way of solving the problem. Case in point, I was working on a problem on CodeFights recently and decided to take a shot at it in rust and I was really fascinated how easy the solution was just by utilizing rust powerful std library. Here's the problem: `// Given a matrix, find its submatrix obtained by deleting the specified rows and columns.` `// Example` `// matrix = [[1, 0, 0, 2],` `// [0, 5, 0, 1],` `// [0, 0, 3, 5]]` `// rowsToDelete = [1] and columnsToDelete = [0, 2], the output should be` `// [[0 2]` `// [0 5]]` Here's my solution: fn constructSubmatrix(matrix: Vec&lt;Vec&lt;i32&gt;&gt;, rowsToDelete: Vec&lt;i32&gt;, columnsToDelete: Vec&lt;i32&gt;) -&gt; Vec&lt;Vec&lt;i32&gt;&gt; { if &amp;rowsToDelete.len() == &amp;0 &amp;&amp; &amp;columnsToDelete.len() == &amp;0 { return matrix } let mut m:Vec&lt;Vec&lt;i32&gt;&gt; = matrix; let mut r:Vec&lt;i32&gt; = rowsToDelete; let mut c:Vec&lt;i32&gt; = columnsToDelete; r.sort_unstable();//faster than normal sort. has a caveat. c.sort_unstable(); //delete row(s) match &amp;r.len() == &amp;0 { true =&gt; {}, false =&gt; { match &amp;r.len() == &amp;1 { true =&gt; { m.remove(r[0] as usize); }, false =&gt; { //casting may not be necessary with latest compiler m.remove(r[0] as usize); let r2 = r.split_off(1); for i in r2 { m.remove((i-1) as usize); } }, } }, } //delete column(s) match &amp;c.len() == &amp;0 { true =&gt; {}, false =&gt; { match &amp;c.len() == &amp;1 { true =&gt; { for mut x in &amp;mut m { x.remove(c[0] as usize); } }, //there's more than one item false =&gt; { for mut x in &amp;mut m { x.remove(c[0] as usize); } let c2 = c.split_off(1); for i in c2 { for mut x in &amp;mut m { x.remove((i-1) as usize); } } }, } } } m } Perhaps there's a better algorithm, but it was really exciting thinking differently and thinking in rust.
So, I will add something here. I donâ€™t know the origins of the OPs opinions but I can say that the syntax is rough for me. I personally think this is mostly because I am dyslexic. There are a lot of characters that are not common in other languages and definitely not natural languages. It takes a considerable amount of repetition and focus to build the proper context to undo what my brain does. Conversely I do not have this problem with something like Ruby or Elixir. There are other languages that give me trouble syntactically too like JavaScript and C. I think Rust can be a little worse than those because the syntax is very dense with characters that are distinctly foreign to me.
I don't know how and why, but your mobile site tries to reimplement scrolling and it's completely jarring. It doesn't behave like iOS scrolling, stopping as soon as movement of the finger ends.
Lldb doesn't appear appear to work for 64bit on Windows?
Trying to get good at Arc&lt;Mutex&lt;Struct&gt;&gt;. I may even write about it in my secret blog no one reads.
I really like the Rust's syntax precisely because it's explicit in intent, and easy to grep. Operators have a clear defined meaning, so there's less context to think about. I can instantly know that `Type::foo()` is calling a static method, and `var.foo()` is calling an instanced method. I really hate having to search through C or Vala code, since it's difficult to find a function signature without IDE support. Rust prefixes every function with `fn`, so a quick search for `fn name_of_func` will get a precise result compared to `name_of_func` and sifting through results to find the function. Likewise, when you're looking for every function that returns a specific type, it's easier to type `-&gt; T` than to type `T` and sift through every declaration ever made with that type...
That is a bummer!!! I'm on OSX, haven't really looked into the windows world but I assume there's an analagous solution?
The usage of `||` for lambdas is very much meh for me. I couldn't care less what it *actually* is once I learned it, but it's just so needlessly foreign from what any other language uses, and to redefine the `or` operator to boot....
I thought this was going to be about an organized RIIR effort. :P
Wrong subreddit mate: /r/playrust
Better try /r/playrust instead
Ruby and Smalltalk both use ||.
/r/playrustservers
/r/playrust 
It's organized we are just starting out adding website pics soon.
That's true of anything, iterators don't have a known size in general
Sorry, I do not have iOS to test it on iOS. I do not really reimplement scrolling, however. The only thing that could cause this is: `overflow: auto;` is set to a specific div and the scroll is not over the whole page.
Love it, what are the major things left to do? How are your metrics faster than hyper if you use hyper?
I'm excited to get it out as well :)
The Phoenix benchmark result from the readme looks suspicious. 3x less throughput than cowboy?? Is the source of the benchmark published somewhere?
Depends. Time between first seriously picking up the language to where I wasn't constantly fighting the borrow checker? Two months? Maybe three? Time spent learning all the things that I'd otherwise have to learn when I went to pick up Rust? My whole programming life, more or less.
Could I see where you used it, just out of curiosity?
So not enough XML templates? What about convention over configuration? Or internationalisation of keywords! What about translation of comments...
Here are a few things you could change to your code, making it more readable while not changing anything to what the code does: Every time you're doing \`&amp;x.len() == &amp;value\`, you can do \`x.len() == value\` instead. But in fact, you don't need those comparisons at all: you're using \`match\` like you would use \`if\`, while you could actually benefit from pattern matching, like: \`\`\` match r.len() { 0 =&gt; {} 1 =&gt; { m.remove(r\[0\] as usize); } \_ =&gt; { m.remove(r\[0\] as usize); let r2 = ... } } \`\`\` &amp;#x200B;
Spiral of doom syntax?
Trying to get good? What do you mean? (Genuine question)
You might want to piece together the information from rustc's MIR (highly unstable, use _one_ version of rustc to maintain consistency) and the names parsed from syn (a Rust parser written in Rust using nom). That seems to be a good place to start. syn (or the MIR comments) would help you find the name, and the MIR will give you the rest of the information, such as scopes, etc.
https://cdecl.org - spiral of doom converter
I think two of the examples have copy-paste errors, where "...1" appears twice and the second 1 should be a 2.
Thanks!
The generalized struct and function definitions don't have performance penalty in release mode. There are places where some functions have specialized implementations for lower dimensions: this is for example the case for matrix inverse. There are also some specialized code (for example for the dot product) in order to improve the quality of auto-vectorization performed by the compiler. The two drawback of generalized structs would be compile time (but rustc got much better since a couple of years, and is still getting better) and slightly worse performance in debug mode (because some runtime dimension checks and bound checks are not automatically removed). But this comes with a significant gain in versatility!
Glad this is useful!
 The pretty print debug format `{:#?}` https://play.rust-lang.org/?gist=044463a80ba8b25c0016edc80413715e&amp;version=stable&amp;mode=debug&amp;edition=2015
&gt; Oh snap. That's *amazing*, and is a solution to what in my head I call "The nalgebra Problem" that I had not considered before! Thanks! I try to use feedbacks from the community in order to improve. &gt; Though I'm a little sad that it seems the maintenance burden for the entire Rust math ecosystem has fallen to you... I wouldn't say the entire math ecosystem since my work on nalgebra does not go beyond low-level linear algebra for vectors and matrices: it does not cover tensors of dimensions higher than 2, and does not define higher-level operators more specific to other fields, like PCA for machine learning for example. So there is still a lot of math stuffs to be built! &gt; the maintenance burden I don't take it as a "burden" since I actually love working on those math tools, and it's always a pleasure to seem them being actually used! If that's affordable, my goal/hope is still to end up working on nalgebra/ncollide/nphysics full-time at some point in the future.
The ' is one of the aspects I find off-putting. I would rather write out static.
Great that seems like a good start! Do you know if cargo can be used as a library so I don't have to handle cargo configuration myself but just get directory trees out?
You need rustfmt-preview.
&gt; When the thread exits, the local queue is cleaned up and all destructors are run. It's not mentioned, but you do this _after_ spinning until the pause counter becomes zero, right? Otherwise a thread exiting may delete a pointer still in use by another thread. I feel like epoch based reclaimation is a similar idea but more broadly applicable. They are both obstruction-free for successfully reclaiming, but epochs work under high contention, whereas this doesn't (and is likely more expensive too because of the two extra writes the the pause counter). Still, neat idea. Thanks for sharing
Zpallin.github.io It's not actually secret but it's not advertised. It's just my source of ventilation. I'm not really used to the Arc and Mutex design pattern so I happened on an interesting way to practice shared data over threads by making a small web app with actix-web and storing all of the data in AppState. It's not a preferable way to build an app but it's helping me wrap my head around how all the Struct methods and Impls work.
Yes, indeed, it spins if necessary, but only at thread exit. Sorry, I think I should have mentioned that. But still the incinerator doesn't block the thread execution.
I agree for the most part. Part of the art of designing language is designing its syntax just as part of writing poetry requires tone, structure, literary devices, etc. Writing that off as arbitrary doesn't give credit to the designers where credit is due. There is a fairly large volume of languages that exist and a fairly small number in comparison that are widely adopted, so there is a lot of data there on what syntax appeals to developers. I think that's important to consider as a part of trying to get a language adopted by a wider audience. As for clean vs familiar, I wrote tens of thousands of lines of code in Java and other imperative languages before I moved on to functional languages and I found languages like Clojure and Haskell fairly easy to learn even though they were a completely different programming paradigm. Not familiar, but simple to adopt. I don't think familiarity is the issue that I'm having. Part of 'clean' code is that it's important that a line of code does actually what you think it does. If small variations can have a huge impact on the statement, then it works against developers as it makes the code much harder to recognize, understand, and debug. For example, the fact that the inclusion or exclusion of a semicolon changes the value of an expression.
Rust syntax is fine. And I love the `fn` keyword because it makes finding function definitions trivial; I greatly miss it when I code in C++.
&gt;Does not use unsafe Is this new benchmark of quality?
To be honest never cross compiled myself, but you could look into tool named cross that simplifies this stuff, if you're planning to cross compile on Travis
I don't know what that is. I ran `rustup component add rustfmt-preview`, something downloaded, and code formatting in VS:Code still doesn't work.
Sorry for the late reply, new job amd I was mostly commenting from the bathroom, but i finally remembered to reply. First a few questions: - the new syntax is interesting! i like it, but i also don't mind the old one. However, I can see how it would make much more sense if selects can operate on send as well. - would sending on a vec only fail if all the senders are closed? Overall, I think it makes sense since the default behavior of ignoring whether a send fails is still basically valid. would you only be able to send in a select then (i imagine not but i'm just checking). Also, I know it was probably for succinctness in the example, but now I'm curious about an example where one would want to send and recv at the same time. Overall, +1 and thank you for your work! I'd love to be able to use them with futures, but I've been watching the issues and I know it's tricky so I'll just be waiting patiently. Especially since the libusb crate isn't Futures ready so I'd probably have to write my own modifications to that anyway, haha. I'm currently using them with a usb process to send small image frames and data to a stream deck, and while I haven't tested other channel libraries extensively, yours has been very useful (in fact the cornerstone) of my little daemon. I'll probably ask your advice later on cleaning up my code. It's mostly responding to handlers for each key.
The syntax is unimportant to me. So long as it makes as many new developers as happy as possible, I am happy.
They do if they're [TrustedLen](https://doc.rust-lang.org/std/iter/trait.TrustedLen.html)
&gt; At a time when you see a lot of languages waking up to the power of pattern matching It's been around awhile. Standard ML is 35 years old.
Looks interesting, but it would be useful to know start this robot is built to do. I understand the current year's challenge is not out yet, but you could roughly describe what it used to be. Just that we get the feeling what is even the idea behind it's construction and multiple motors. 
Maybe expressed a bit bluntly, but fact remains that if you are learning a new notation you have to persist. It's possible to waste energy fighting the fact of notation 
I really need to find some time to read all that nomicon.
rr doesn't work in MacOS, though it does work in a Linux VMWare guest with MacOS host.
If that's more work than using a debugger, why wouldn't you use a debugger?
If you don't really like something, then don't force it on yourself. That's what I believe
Would be nice to support deserializing query strings: \`\`\` GET /users/{user\_id: usize}/transactions?{filter: TransactionFilter} =&gt; get\_transactions, \`\`\` &amp;#x200B; I am using \[serde\_qs\]([https://docs.rs/serde\_qs/0.4.1/serde\_qs/](https://docs.rs/serde_qs/0.4.1/serde_qs/)) personally. Works well for me but there may be alternatives.
Nice post indeed. Thanks
Found a solution here: [https://play.rust-lang.org/?gist=a92dfc15fb49be1d1fc73ffa30a81173&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=a92dfc15fb49be1d1fc73ffa30a81173&amp;version=stable&amp;mode=debug&amp;edition=2015) Two problems: * You need to temporarily store `pop_front().unwrap()` into a variable with a lifetime until the end of the function. This is since `item` is going to hold a reference to it. I believe this nuisance will go away when NLL-support arrives. * You don't want to return an `R` that is `Cloneable`. You want to return an R that is `Clone`. The `.clone()` call in your code did not clone the `R` but the reference to the `R`. (References are always `Clone`.) Additionally, this seems like a somewhat conflated solution. Have you tried just define a `trait AnyClone: Clone + Any` and then store `Box&lt;AnyClone&gt;` in your collection? (Not sure, and don't have the time to test right now, just throwing it out there)
Looks similar to https://github.com/chris-morgan/anymap yet itâ€™s a vector instead of a map. Did you already look at that crate?
&gt; There's no way to know for sure it won't break any code anywhere. The same thing is true for any bug fix, unsoundness fix, adding a new function to `std`, etc. Again, how is this change any different? &gt; Funneling them together into editions minimizes the impact. While we could do this for this particular change, as I mentioned, I don't understand yet why is it more breaking than all other breaking changes that we are continuously doing. Particularly, because Rust code across editions has to use the same `std` library, so we cannot really have one version of std for one edition, and a different one for another, and if that isn't a problem, why should this ? Even if we broke somebody's code that was using explicitly this syntax, I would at least mention in the discussion that the code "deserved" to be broken, as in, whoever wrote it should have used parenthesis to make things more clearer. Adding parentheses would fix their code, and is a smaller change than the ones required to fix all other breakage that we are doing (type annotations, UFCS, etc.).
A simple game using the sdl2-rs crate. Wonderful crate and youâ€™ll learn a lot 
This might provoke controversy. I'd personally move away from C styles, i.e get rid of curly braces, and semi colons and adopt a pythonic style, to make it look more cleaner. Also change the syntax of the lifetime to something other than '. But I don't what.
See https://rustwasm.github.io/book/game-of-life/code-size.html#avoid-string-formatting for a one paragraph about the why. See https://kripken.github.io/blog/binaryen/2018/04/18/rust-emscripten.html to read a nice blog post about optimizing a Rust Hello World compiled to wasm. 
Dangit, I will have to remake. Thank you!
I love it, and I always have! After being exposed to Standard ML in university, I was really happy to get into a language with noticeable ML influence. Perhaps you are missing the sense of familiarity that would come with this background?
Thanks for the feedback. In my experience query string has some optional params and therefore should not be the part of route matching. What do you think?
I agree ! The subject is now out ! You can check it out [here](http://www.eurobot.org/images/2019/Eurobot2019_Rules_Cup_BETA_EN.pdf). I will add it to the blog post.
https://steamcommunity.com/sharedfiles/filedetails/?id=1520656912
Whereas I personally avoid whitespace sensitive languages like the plague. Too many tools mess up whitespace terribly and it's too easy to mess them up yourself when editing. Sure, it's less noisy looking, but it becomes harder to edit. Especially with things like macros and whatnot.
For convenience, [here](https://play.rust-lang.org/?gist=dd89a2e6e35e8ca887abdb77146363a2&amp;version=stable&amp;mode=debug&amp;edition=2015) is a link to your code snippet in an online playground that can run it and easily show the LLVM IR and assembly outputs.
I wish the docs had at least a "practical" summary of the nomicon page. `PhantomData` is something that pretty much every Rust programmer has to know and understand once they start dealing with generics. It is not "super-advanced dangerous Rust".
I made a [KTLS wrapper](https://github.com/quininer/ktls) that allowed TLS to support zero-copy system calls like sendfile and splice.
Well, I think it's a reference to the recent Actix fixes since there was a lot of unnecessary unsafe code. 
Agreed. QS should be viewed as optional request specifier and not part of the routing. 
Yeah but only now some mainstream languages start to adopt it (again?) 
You might be looking for https://www.reddit.com/r/rust/comments/3gzskk/video_the_dark_arts_of_unsafe_rust_programming_by/ but Mozilla Air seems to no longer work for me?
If you don't need collision resistance and have integer keys, I can highly recommend the [fnv](https://www.crates.io/crates/fnv) crate. It can be quite a lot faster than the default implementation.
Was able to click through and accept the popup to see the video. Looks good but isn't the one I was looking for (doesn't contain the `AsRef` example I remember). Looks more like a general introduction to Rust and unsafe. Thanks, though!
Thank you!
Rust doesn't let you implement foreign traits on foreign types, where "foreign" in this context refers to "outside the current crate". I'm not completely sure about this bit, but I think the reason why is because allowing it could result in a similar situation to the [diamond problem](https://en.wikipedia.org/wiki/Multiple_inheritance#The_diamond_problem). Basically, if you implement a trait from crate A in your crate for `T`, someone else implements the same trait for `T` in their crate, B, and then a third person tries to write crate C which is dependent on both your crate *and* crate B, which implementation of the trait from A should get called, the one in your crate, or the one in B? This does raise the question of why it wouldn't work for the tuple `(T, Taint)` though, since `Taint` is local to your crate. It might be that, if `Taint` is a public type, then someone else might try to implement the trait for `(T, Taint)`. Someone more knowledgeable than me will have to chime in here.
Excellent question! The biggest similarity between my particular flavour of actor system and ECS is that they are both patterns that allow for efficient storage and iteration over game entity data in data-flow-oriented fashions (mostly focusing on optimising cache localities and executing similar code in loops). The big difference in general and the kind of the defining feature of actor systems is that actors are even more self-contained than entities in ECS and can influence/mutate each other **only through message passing.** That makes some simple interactions a bit more inefficient due to additional copying of values instead of reference-passing, but it allows for fully transparent multithreading and even networking across arbitrary actor-divisions. Because self-contained actors with message-passing is such a simple model and makes very few assumptions, it is possible (I did it several times already) to quite significantly change the underlying execution, communication and storage models of the engine, apply deep-cutting optimisations and add completely new features (such as networking) to the game engine, almost without touching the "business-logic" of the game as implemented in actor message handlers. Said simply, the actors really don't care where they are, where their communication partners are and how they receive and send messages, as long as it works. Many things that are modelled as "Systems" in ECS (such as the physics system), that update one aspect of many entities at once, are implemented as "broadcast messages" in my actor model, where many actors receive the same "please update physics message" and then I optimise the hell out of the fact that the actors lay sequentially in memory and just run the same message handler for all of them in a loop. It might turn out worthwhile to actually separate actor state into aspects and define for each message handler which aspects are affected by it - which would fully bring the ECS "component" idea into the actor system world :) Let me know if you have further questions!
I'm using Travis for Mac and Linux builds and AppVeyor for Windows. Because the project setup is quite complicated (essentially a native backend part, some shared code and then frontend JS code with Rust that compiles to WebAssembly), I wrote some npm scripts that first ensure correct versions of Rust and components are installed and then build all the sub-targets in the right fashion. This allows easy set-up and repeatability across developer machines and made it very straight forward to write CI scripts for the aforementioned services. Once a build completes, the resulting self-contained executable is simply uploaded to an S3 bucket.
I use nightlies and pin them manually, because I have to make sure that all dependencies currently work with them. The trickiest bit is usually `cargo-web` for WebAssembly, which frequently breaks in different nightlies.
Have you installed Stable and Nightly, and if so, which one is set to default? When you run `rustup component list`, is `rls-preview` in that list?
I think it's to do with the fact that the tuple itself is a type `(A, B)`. Think of it as a tuple struct where the name just happens to be empty. And since tuples are defined in the standard library, you can't just implement traits also present in the standard library for it. If I define a `struct T&lt;A&gt;(A, Taint)` it all works fine.
I've made a branch to use the gcc crate (now called cc) and published a crate with the mail viewer that should build with just 'cargo build' if Qt and OpenSSL are installed. https://crates.io/crates/mailmodel
Hi all, I'm deadlocked on this problem. I'm trying to write a parser which reads from a COM port into a buffer and re-constructs data from bytes. Is this approach ([https://play.rust-lang.org/?gist=f3ed230aec033c807ee7790b519e5081&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=f3ed230aec033c807ee7790b519e5081&amp;version=stable&amp;mode=debug&amp;edition=2015)) fundamentally bad? &amp;#x200B; I can't figure out how to construct the iterator.
I love how reminiscent of Koa this feels, feels like home :)
For reference I think this also covers the question fairly well: [https://github.com/japaric/rust-cross#cross-compiling-with-cargo](https://github.com/japaric/rust-cross#cross-compiling-with-cargo)
...because otherwise people using **old** reddit cannot read it.
I think you wan't /u/tomaka17's "Mistakes to avoid when writing a wrapper around a C library" talk from RustFest Zurich: [https://youtu.be/LLde-PJJZQA?t=24m20s](https://youtu.be/LLde-PJJZQA?t=24m20s) (coin flip example)
The â€œpaladiumâ€ link in â€œBelow is a list of changes made this week in Iridium and Palladiumâ€ returns a 404
Can you change your keyboard language in your IDE? It's not enabled by default, but in Windows and Gnome, at least, you can have per-window (or thread) input languages.
Or mobile apps
Good hint! Will check it out!
That's it! Thanks so much! I wasn't including C or wrapper in my search... Maybe those would have helped, but I think I forgot that context since it was also a useful exercise/eye-opener for me about writing unsafe code in general. ðŸ‘
That's it! Thanks so much! I wasn't including C or wrapper in my search... Maybe those would have helped, but I think I forgot that context since it was also a useful exercise/eye-opener for me about writing unsafe code in general. ðŸ‘ (Note: I'm also /u/scooter-dangle but switched devices and browsers recently and hadn't realized I was using an old username on the new device until after posting.)
I can't find the forum post at the moment, but there was also a great post about how they present unrealistic results based on thread pools. TLDR; the pool that's most resilient and you'd probably prefer for most real world applications is about 20-30% slower than a more simple and unrealistic approach. I just find those benchmarks to be a good rough indicator of performance.
Because unsoundness fixes and aesthetic adjustments are a whole different level of necessity. If Rust doesn't want to guarantee backwards compatibility as you say, they should at least stop telling people that it does. Really, telling me that the often talked about backwards compatibility is even more non-existing doesn't make the situation any better. I get that you don't care. Please allow me to care.
Is there a reason why unused generic parameters are a hard error in Rust while unused variables or function parameters are just a lint? To me those seem like very similar things, and that the compiler should easily be able to insert the phantomdata itself if you tell it to ignore the lint.
But introduce such an opportunity for parsing ambiguity?
How?
I mean, closure without arguments needs `||` in the very beginning -- the very same character sequence which denotes `or` boolean operator.
Right, but those concepts are never valid in the same position, so thereâ€™s no ambiguity here, as far as I know.
Thanks for the reply. I don't think I explained the problem very well. I really ought to have just included a code sample from the outset -- sorry for wasting time by not having done so. What I'm looking to do is along the lines of: ``` if let Exp::Ex(ir::Exp::Mem(box(location)) = simple_var(access, level) { // Do something with location } else { assert!(false); } ``` The boxed value is nested in the expression tree and there are usually multiple boxed values in the expression. I'd prefer to avoid switching to `match` expressions and inspecting each level of my data structure because that's going to get ugly real fast. Am I overlooking something obvious?
6 to 16 seems to be the important stuff, 1 to 5 is the strack trace building function calls. And bellow 17 also tells a story (namely that the OS created a thread that runs a tokio thread pool that runs a tokio executor/reactor which itself calls into tokio timer that ends up calling a worker function that creates a task to run your futures). Also, the future itself is not that complex, but just like with tokio your code is asking the future to execute other futures, which are asking other futures which are asking other futures to run your code. All that being said, I guess the trace is not too bad and actually exposes all the stuff that the OS, the standard library, tokio (and its many friends), futures and the failure/backtrace libraries are doing for you.
Rust's syntax is not even that different than C++ or Java. Sure, the keywords are different and where you put the types in a function declaration is different, but that's really not huge. &amp;#x200B; You say you've learned dozens of languages- have you learned ObjC, a Lisp, Erlang, Haskell? *Those* languages have really different syntax from C/Rust/Java.
Static means something else, though. The languages you mentioned have no (explicit) concept of lifetimes, so they'd have to invent some weird new syntax, too.
Why `unsafe{}`?
I have a lot of experience compiling Rust for the Pi Zero for work. For the Pi Zero you need to use the armv6 toolchain which I believe is unknown-linux-unknown-armhf in rustup or something similar. Also make sure you have a linker that works and visible to Rust. Alternatively there is a docker based GitHub repository that will take your code and compile it in docker and spit out the binary for the Pi Zero. 
Looks like he tried to use the markdown equivalent without realizing it
It does the job. Some things are really convenient and readable while others are not. It's not really about the syntax though. If Rust offered the same memory safety guarantees and provided all the stuff that helps encode constraints and business logic clearly, like traits and fat enums, I'd still use it. There's just nothing else like it (outside of really immature languages in academia).
To be fair, there *is* a [smart way to do comment syntax](https://www.youtube.com/watch?v=Txf7swrcLYs) (and surprise, Haskell made the *wrong* choice!)
Exciting!
Trying to write a Touchstone file parser (application specific filetype containing data on RF networks) in support of my attempt to port scikit-rf to rust for fun. Having little experience with working parsers, nom is both fantastic
It parses text in posts differentlyâ€½ Ugh, this redesign.
`Clone` is not object safe, so you can't have `Box&lt;AnyClone&gt;`..
So cool, really want an REPL for Rust! 
I'm not sure about that. static only makes sense in the context of OOP. If we were to see static variables with no relation to a Class, that would be distinct enough for developers to recognize that static has other meaning which can be a great introduction into lifetimes.
I definitely agree that's awful. I've never gotten to that point with C. I do really like that types are moved to the right hand side. It makes them seem more like an annotation which I think is more intuitive since types are meta data.
Oh, I didn't realize markdown is broken here. Is there a quick way to do 4 spaces for many lines?
That's awesome, thank you!!
No, you aren't. It's a known issue. First of all, if you accept going _nightly_, there's [`box_patterns`](https://github.com/rust-lang/rust/issues/29641): #![feature(box_patterns)] fn f() { if let Exp::Ex(ir::Exp::Mem(box location)) = simple_var(access, level) { } else { unreachable!() } } There's a twist with Box Patterns: It's not general enough, there are many more smart pointers like `Rc`, `Arc`. [See this GitHub comment](https://github.com/rust-lang/rfcs/pull/2005#issuecomment-307935415). This leads to [this open issue/proposal](https://github.com/rust-lang/rfcs/issues/2099): Let the `&amp;` in patterns deref. if let Exp::Ex(ir::Exp::Mem(&amp;location)) = â€¦ { â€¦ } I personally don't know how actively Box Patterns and other solutions are discussed. In the meantime, you have to stick with this: if let Exp::Ex(ir::Exp::Mem(loc)) = simple_var(access, level) { let location = *loc; â€¦ } and: let x = MyType::Variant(Box::new(Some(10))); if let MyType::Variant(boxed) = x { if let Some(x) = *boxed { â€¦ } } **Far future** (but maybe before the stabilisation of those other solutions): The latter could be written more concisely as soon as [if-let-chains](https://github.com/rust-lang/rfcs/blob/master/text/2497-if-let-chains.md) is implemented: if let MyType::Variant(boxed) &amp;&amp; let Some(x) = *boxed { â€¦ } Cheers.
Sorry for taking so long to reply, I wanted to have a proper response instead of a fast response. To answer your question: if there are other safety options other than Data Ownership, I would LIKE to add them; the difficulty arises when things require runtime evaluation etc. For your concrete example of array bounds checks, the majority of dynamic array access would require runtime checking each access, which doubles the amount of work in Big O terms. However for fixed size arrays or access using const evaluation, safety can sometimes be proven at compile time allowing checks to be optimised away. A large part of Rust's Data Ownership power exists in its move and lifetime semantics which are able to be checked at compile time, putting no load on the runtime. Affecting the optimisation of the runtime negatively is something that the developer pro/cons for there use case as it is not something the compiler can necessarily evaluate. In summary, I want all the safety possible but when it comes to sacrificing convenience for safety I am all for the compiler taking more time running checks and I would like runtime safety checks to be optional in release builds at the developers discretion.
Jupyter Dev here, super cool, feel free to announce on the mailing list, we also have a list of kernels on the GitHub wiki, feel free to add yours. I've just started to play with rust, and will likely give it a try. 
No, it just happens to work there, apparently. Doesn't work in *Reddit is Fun* or *Sync*.
My strategy is that the Ext2 struct wraps a `T: Read + Write + Seek`, and then allows you to open files on it. Those file handles then implement `Read + Seek +` (soon) `Write`. let fs = File::open("/dev/sd1").and_then(Ext2::new).unwrap(); let mut handle = fs.open("/path/to/hello.txt"); let mut buf = [0;20]; handle.read(&amp;mut buf).unwrap() assert_eq!(&amp;buf[..], b"Hello world!\n\0\0\0\0\0\0\0")
I'm currently in academia which provides the flexibility that I need to learn new technologies while at the same time requires that I be able to teach those technologies to students, so, to be more clear, a 'coming-of-age' developer is a college student or other developer who is in the process of learning their first 3 languages. Many universities teach Python, C++, and JavaScript as the first 3. We teaching Java...just Java. We're currently moving to Python, Java, and ... (hopefully major dependent 3rd language, but not-clear). Many students teach themselves C as a third language, and some courses require that you learn it on your own without being taught the language by anyone. As someone who teaches languages such as Java, C, Python, and JavaScript, I look for languages that allow me to write programs that require as little hand-waving as possible. Java breaks this rule with the discipline of a black-belt because you can't even execute "Hello, World!" without introducing Classes. I also look for languages that don't introduce non-intuitive behavior. If I introduce syntax, ask the students what the result is, and no-one can guess it: that's non-intuitive. For example, `int i = 2; int j = ++i/i++`; That's non-intuitive. Also, JavaScript before ES6 was fairly non-intuitive because of concepts such as Hoisting, and the fact that it doesn't have block-level scope. These are just a few things that I find important in teaching a language to other developers. &amp;#x200B; I'm not suggesting more C-like type declarations. I would be far more interested in seeing more languages take concepts from languages such as Ruby, Crystal, Python, and TypeScript. &amp;#x200B; For clean syntax. First, Rust has three distinct kinds of variable declarations: `const x: i32`, `let x,` and `let mut x`. Each of these can have a type, but the only one that requires a type is the const declaration. Also, const is the only declaration that doesn't use the let. My proposal would be to use JavaScript declarations or to push const and mut into the type annotation like so. let x = 5 // immutable variable declaration with optional type var x = 5 // mutable variable declaration with optional type const x = 5 // const declaration with optional type or let x = 5 // immutable variable declaration with optional type let x: mut i32 = 5 // mutable variable declaration with required type let x: const i32 = 5 // const declaration with required type This allows the concepts of mutability and const to be introduced slowly and consistently. This also leads easily into pointers because we can introduce pointers like this: let x: mut i32 = 5; let y: &amp;mut i32 = &amp;x; but this is how it currently is: let mut x: i32 = 5; let y: &amp;mut i32 = &amp;x; // the mut switches side for some reason In Rust, all statements can be used as expressions if they exclude a semi-colon. Why? Why not just have all statements resolve to expressions and allow semi-colons to be optional if developers want to include it? The use of the `'` operator for a static lifetime. We have to declare mutability with `mut` and constant-hood with `const`. `static` is already a keyword in many other languages. I would just use `static` so that you can do this: `&amp;static a`. The use of `fn` is easy to miss. It also isn't used to declare functions, it's used to declare a procedural block. Languages such as Python and Ruby declare procedural blocks with `def` which seems to be well-liked. The use of `def` is also consistent with what the block is: the definition of a procedure. Types look like variables. I would move back to `int32` and `float64` syntax for declaring ints and doubles. I also really like that LLVM languages have been bringing back `end`. Rust didn't do that and opted for curly braces, but I wouldn't mind seeing those go. Intermediate blocks could be declared with `begin`...`end` and procedures would use `def`...`end`. Braces for intermediate blocks is 6 one-way and half-a-dozen the other though. fn main() { let x = 5; let y = { let x = 3; x + 1 }; println!("The value of y is: {}", y); } Could be def main() let x = 5 let y = begin let x = 3 x + 1 end println!("The value of y is: {}", y) end or def main() let x = 5 let y = { let x = 3 x + 1 } // or let y = { let x = 3; x + 1 } println!("The value of y is: {}", y) end The use of `for` shouldn't be for anything other than loops same with `while` and same with `loop`. WDYT?
My understanding is that generic parameters influence variance, whereas the others do not.
I'm always happy to take PRs to expand the docs.
awesome!
It looks like you are trying to create a method `parse_buffer(&amp;self) -&gt; Option&lt;T&gt;`, which allows the caller to choose the output type. This is almost exactly like the standard libary method [str::parse](https://doc.rust-lang.org/std/primitive.str.html#method.parse): `parse(&amp;self) -&gt; Result&lt;T, Err&gt; where T: FromStr`. The standard library solves this by implementing `FromStr` for all types that are able to be parsed from a string. You can create your own trait that parses from your buffer type and implement the trait for each packet type.
If I do `rustup target add unknown-linux-unknown-armhf`, then it gives me `error: toolchain 'stable-x86_64-unknown-linux-gnu' does not contain component 'rust-std' for target 'unknown-linux-unknown-armhf'`. If I do `rustup override add nightly` and then run the same command, I still get the same error; only with `'nightly-x86_64-unknown-linux-gnu'`.
Can you please include a description of what `wasm-pack` does? The website says "ðŸ“¦âœ¨ your favorite rust -&gt; wasm workflow tool!". And if I go to the documentation, I see something about the prerequisites, setting up a project, and a deprecated `init` command. If it's deprecated and equivalent to `build`, why is it still in the docs? And the tutorial says something about a template, but.. I'm still not sure what it is. Is `wasm-pack` a helper for publishing things to `npm`? I thought so, but now it seems to have some `--no-modules` support. Is it also a scaffolding tool for new WASM projects? Say I have a small WASM app, built using `wasm-bindgen`. `wasm-pack` seems to include that. Should I switch? Will it make builds easier?
You lost me when you said you don't want to type `;`, but *do* want to type `begin` and `end` instead of `{` and `}`. `const` does not declare a variable, `static` does. In addition, there is but one form of let: `let &lt;pattern&gt;`. There is *nothing* special about `let mut`, you can also do `let (mut a, b) = (1, 2)`. How is `fn` easy to miss? There are fairly few contexts where it may occur, and it is usually followed by `(args) -&gt; result`, so you really have to be trying to accidentally miss a function declaration. I think "intuition" is overrated when it comes to programming language syntax, it's not like people are born with an innate understanding of (certain) programming languages. What you call "intuition" I call "familiarity". I do think it's important for syntax to be consistent. Your suggestion of using `static` instead of `'static` for the static lifetime is a good example of something that in my opinion would make Rusts syntax less consistent.
Update: I managed to cross-compile, look at the edited post.
Not really, no. A parser *is not enough* for most things.
If I have a `&amp;[u8]`, whats the best way to get a `u16` from the first 2 bytes of the array, assuming the bytes are in big endian order?
I meant that `\`static` is already a thing in Rust. And not all lifetimes are static.
This (still ongoing!) discussion has continued in the issue tracker, check it out: https://github.com/crossbeam-rs/crossbeam-channel/issues/61 &gt; would sending on a vec only fail if all the senders are closed? No, it fails if any sender is closed. Think of sending on a vec as just a compact way of enumerating a long list of cases. That's all it is. &gt; would you only be able to send in a select then (i imagine not but i'm just checking). No, you can still do `sender.send(message)` (which returns a `Result` like in `std::sync::mpsc`). &gt; but now I'm curious about an example where one would want to send and recv at the same time. Suppose you have a producer thread. It might want to send a produced message to another thread into a bounded channel, but also listen for a shutdown signal that is passed through another channel: ``` loop { let message = produce(); select! { send(message_sender, message) =&gt; {} recv(shutdown_receiver, shutdown_reason) =&gt; { debug!("shutting down: {:?}", shutdown_reason); break; } } } ``` &gt; I'd love to be able to use them with futures, but I've been watching the issues and I know it's tricky so I'll just be waiting patiently. It's going to happen sometime, but we'll probably have to do it from scratch. I think the threading model `crossbeam-channel` uses and the task model futures use are simply way too different. And I'm happy to hear the crate has been useful to you! Thank you ^^
&gt; \[`fn`] isn't used to declare functions, it's used to declare a procedural block. What's the difference? A function is a procedure that has a name and a well defined entrance and exit. A _method_ is a function in the context of some object.
&gt; Design a language that compiles to Rust and uses a different syntax. It would probably be quite simple if you just wanted to desugar things.
Done
I'm not entirely sure why [https://docs.rs/redbpf/0.1.0/redbpf/](https://docs.rs/redbpf/0.1.0/redbpf/) doesn't work. Is this because the library is targeting Rust 2018?
You want rls-analysis, I think.
A small, and not too complicatet project could be to rewrite iotop from python to rust. I have noticed a few bugs in the current versions, so if you can make a more robust version of this tool, that could spur adaptation. 
The [query_interface](https://docs.rs/query_interface/0.3.5/query_interface/index.html) crate has an object-safe variant of it, and other stuff for solving similar problems.
In IDEA at least, IntelliJ-Rust (the Rust plugin) has an action to reformat the file with rustfmt. It's not bound to a key combination by default (ctrl-alt-L has a custom more forgiving formatter), but you can find it with "Do Anything" (ctrl-shift-A) and I've bound it to ctrl-alt-K personally. Just make sure you've saved the file first.
Please indent the edit by 4 spaces rather than using triple backquotes. Many of us prefer to stay on the old Reddit design for as long as it remains available and it doesn't support fenced code blocks.
Using the almost stablized from bytes: fn read_u16(data: &amp;[u8]) -&gt; u16 { u16::from_be_bytes([data[0], data[1]]) } But as long as that is not done yet, just manually will do fn read_u16(data: &amp;[u8]) -&gt; u16 { data[0] as u16 * 256 + data[1] as u16 }
Cool, thank you. I'll give it a shot and let you know how it goes.
It's functional programming, but implemented with an imperative state machine. (note: due to how ISA works, all functional programming implementations are imperative underneath). What this __isn't__ is pure functional programming like Haskell. It's functional programming like in Scheme and ML. See [this poster](https://www.info.ucl.ac.be/~pvr/paradigms.html) from CTMCP. Rust supports higher order functional programming (that is, with first class functions) just fine. That's because Rust really is a ML in C++'s clothings. Fewer people would doubt its functional capabilities if Rust opted for a ML syntax like ATS did.
Your debugger session today, won't make debugging (or anything else) faster tomorrow. Your new tests and logging will. With time it compounds. 
Hmm. What is a "fenced code block"? I just used MarkDown, instead of the "Fancy Pants Editor", because I find it easy to type backticks than go and click on the buttons. I don't understand - what problems could I have with the current GCC build?
All the examples given here look almost exactly the same to me. How about something more ML inspired? ``` main = x = 5 y = ( x = 3 x + 1 ) println! "The value of y is: {}" y ```
Thanks! It's supposed to be a static link, and it looks like that paths are off on [docs.rs](https://docs.rs). I'll try and repro this locally.
Aye! Iâ€™m an org member and maintainer (not intended to self-promote)!
It definately seems to be fun ... should I directly jump onto the documentation or is there a nice tutorial to start with ?
Hey fucker, just a quick heads-up. *"definately"* is actually spelled *"definitely"*. You can actually remember it by remembering it. Unless you have Alzheimers, then youll probably forget to breath anyways.
...
&gt; Hmm. What is a "fenced code block"? I just used MarkDown, instead of the "Fancy Pants Editor", because I find it easy to type backticks than go and click on the buttons. "Fenced code block" is the name GitHub chose when they invented support for using triple backquotes rather than indentation to indicate code in "GitHub Flavoured Markdown". (New Reddit uses the CommonMark standard, which attempts to unify the best elements of the various different markdown dialects. Old Reddit doesn't.) &gt; Anyway - I updated it with four spaces. Also, I'm still seeing it using a fenced code block --&gt; https://imgur.com/a/1oE878d I don't understand - what problems could I have with the current GCC build? There's nothing wrong with the current GCC build itself. Rather, I'm concerned that Rust's definition of "armhf" might follow Debian's lead in also specifying that it's OK to assume CPU features not present in the Pi Zero. (In which case, you'd be sitting on a time-bomb similar to a dynamically typed programming language, where it would seem to be fine as long as you didn't actually execute the problem piece of code. Then, if you did, the kernel would kill your program with `SIGILL` (Illegal Instruction)) If that *is* the case, then you'd want to grab the non-`hf` GCC from the same repo where you got the `hf` one and then use Rust's non-`hf` ARM profile.
Worst time is O(n^2) but that only happens when all points are on the same circle.
You know, I am a real noob in Rust and I am trying to learn everything. But I really think it's nice that people create such quality code that also focusses on performance and stuff.
I havenâ€™t had the chance to take Thruster for a spin but I was surprised to se a router included :) I honestly just skimmed through the source.
That's fucked up.
They rewrote it in Rust though!
&gt; Because unsoundness fixes and aesthetic adjustments are a whole different level of necessity. Adding a new method to `Iterator` is also a whole different level of necessity.
Oh this annoys me so little that I never even searched for a solution. Thank you for taking the time to show me one. Yes, it's an anagram.
Every now and then when I pass a generic type parameter I only use associated consts, or an associated type, or just it to pass functionality (e.g. use it inside the implementation of the type methods), without actually having to store it.
Did you install cargo fmt? rustup component add rustfmt-preview 
"Nicer" is such a weird word to use here. Using iterators doesn't make it inherently nicer. The "uglier" implementation is stating "more directly" what the intent is. The issue with the iterator code is not only the functional overhead that the compiler has a more difficult time optimizing, but also that the matrix is being collected, rather than in-place modification like the first example. In many cases, mutability will be faster than an immutable counter-part. In fact, this is why there are so many claims to Rust's speed as moving memory's ownership and modifying it is more efficient than cloning and modifying if taking ownership is a possibility.
Looks to me like the two snippets are doing totally different things. The loop version mutates the matrix in-place, the iterator version filters the existing matrix, allocates a new matrix and copies the data across. Allocations are slow, so no surprise the latter is slower. To make the iterator version faster, it has to be transformed to remove the allocation. But you can't pop rows or columns from the matrix while iterating over it, that violates the borrow check. So you'll eventually realise that a loop is the only way to do it. Side note, not sure why you think is so good about the 'nicer' version. The loop seems clearer and more succinct to me.
/r/playrust ?
Hmm, to hit this you would need code that wants to make 1 billion contiguous copies of a string, then call that code with an input string which is 18 gigabytes. Or code that wants to make 1 million copies, and call it with an input that is 18 terabytes. It would be good to call out that just using str::repeat is not cause for concern, only if the repeat count comes from untrusted input.
Two Ashley Williamses (Ashleys Williams?) in the contributors list :)
This is actually a good reminder for me that I've been meaning to port [gridly](https://github.com/lucretiel/gridly) to Rust for a while now. Gridly is a library I originally wrote in Python, and later (started to) port to [C++](https://github.com/Lucretiel/LibGridly). It's a library for 2D grid manipulation with a focus on simplicity and spatial usage, intended originally to support things like games. It's specifically NOT meant to be a mathematics library, but rather a simple, literal 2D grid. It's designed to support any kind of backing storage, defaulting to a dense 1D array. I mostly made it so that I'd have an intuitive way of expressing concepts like "below" and "above", as well as having the library help with detecting literal edge cases.
You could always just host the docs on Github pages and use a Travis build to automatically update it. 
The numbers are less absurd on 32-bit targets, but still probably not something you'd actually encounter in trusted inputs.
As the `chacha20_encrypt` docs note themselves: &gt; This does not provide any data integrity. If you need data integrity, you should be using a ChaCha20_Poly1305 construct instead. In most cases you would want data integrity. See RFC for more information. If you're making a distinction between primitives and high level interfaces, it's a little weird to provide unauthenticated encryption as a high level interface. It's pretty rare that an application wouldn't need authenticity, but its common for folks without a lot of crypto experience to search for an "encryption function" without understanding that authenticity is important to them.
`for_each` doesn't count!
I mean, *technically* it is an iterator :P
I am new to coding and have tested the waters of many a language. I prefer those with clear line endings like ; and proper syntax for blocks like { }. I don't really understand the appeal of anything being less defined *especially* in a programming language where you must account for everything or get hit with unexpected bugs.
Awesome. Rust seems like a great fit for this sort of thing.
How does one match on a specific error variant to handle it?
No... If your memory bandwidth is 1 TB/s, that test would take 7 months to run.
So you're saying there's a chance.
That would be exactly a big problem that futures have. When working with async stuff on Node.js I see it all the time. I don't know if there are any good tools. I think coroutines-like futures (there was a library like that posted here recently), in code that is not perf. critical could be a good compromise. Do generators help with stacktracers? I guess they could if compiler emitted some helpful symbols...
I was writing a trait where a Serde trait was a supertrait; the Serde trait had a lifetime parameter and a HRTB allowed my trait to be written. it _worked_, but ended up not being really the best solution, and i replaced it with something else, haha
EVCXR doesn't exactly roll off the tongue.
Sorry, I looked to `std::mem::align_of` docs (the first Google result for `rust align_to`) by mistake.
Agreed. Sorry about that. I did have a different name early on, but then I found that there was a software company with that name. I've been pronouncing it like Evic-ser if that helps. 
I know nothing of the topic, but for the casual peruser, I'm going to put my copy and paste skills to good use taking a select paragraph: &gt; `wasm-pack` **is a tool for assembling and packaging Rust crates that target WebAssembly. These packages can be published to the npm Registry and used alongside other packages. This means you can use them side-by-side with JS and other packages, and in many kind of applications,** be it a Node.js server side app, a client-side application bundled by Webpack, or any other sort of application that uses npm dependencies. You can find `wasm-pack` on [crates.io](https://crates.io/crates/wasm-pack) and [GitHub](https://github.com/ashleygwilliams/wasm-pack).
The thing with futures is that it's not your code that gets executed, in this case it's even worse because the point where the stack trace is recorded and the point where the stack trace is printed are not even the same.
Thanks for that reply. Could you explain how to use all these nice iterator functions like `filter`, `map`,... In terms of performance? Couldn't such things get resolved by compiler optimizations? 
Yes, but still a whole different level of usefulness than "not writing `::`".
I've been meaning to write a blog post about this, but I had a great experience contributing to [clippy](https://github.com/rust-lang-nursery/rust-clippy). The short of it is I picked issues with 'good first issue' and 'l-bug' tags and I was able to get [two pull requests merged](https://github.com/rust-lang-nursery/rust-clippy/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+author%3AJoshMcguigan+), while improving my Rust skills and contributing to the community. I found the contributors to the clippy project to be especially helpful and welcoming to new contributors. 
they work perfectly fine and very efficiently, they just don't do what OP wants to do, which is an in-place modification that avoids iterating over every row and column. If you use a filter, you're asking it to iterate over every element. I use maps and filters all the time, but in such cases I would be doing the same amount of work in a for loop.
When I started this project I was a real noob too, and now I'm a real noob who pretends to write rust :) &amp;#x200B; Thanks a lot for your kind words though, much appreciated!!
A command-line simple fund management application I am calling [fundwarrior](https://gitlab.com/leggettc18/fundwarrior). Currently in a pretty rough state, probably could be doing some aspects of this in a better way. Feedback is appreciated!
To add to the spice: Evic-ser sounds like E-wichser, which is German for E-wanker
No, the bug was that `str::repeat` would *not* try to allocate a huge amount of memory. For example, if you called `"xx".repeat(0x8000_0001)` on a 32-bit system, then instead of trying to allocate `0x1\_0000\_0002` bytes of memory, it would wrap around and allocate only 2 bytes. The allocation succeeds! But then the function would write more than 2 bytes to the allocated buffer, causing a buffer overflow and undefined behavior.
Personally, I think the risk of losing people because backwards compatibility isn't real is bigger.
They're computationally equivalent but I think left-shifting the high byte by 8 makes it a bit clearer what you're doing than multiplying by 256.
https://crates.io/crates/derive_more might be useful
How do you teach the intro to architecture class without C...
On the up side, it's unique so should be easy to Google for evcxr related things
Great, thanks for the tip :-D
Thanks for linking to that. Also possibly of interest is that all variable get stored in a HashMap&lt;String, Box&lt;Any + static&gt;&gt; and get moved out of the map before each execution, then back in after
I asked a similar question here: [https://users.rust-lang.org/t/non-allocating-c-string-getters/19849](https://users.rust-lang.org/t/non-allocating-c-string-getters/19849) &amp;#x200B; The \[terminated crate\]([https://crates.io/crates/terminated](https://crates.io/crates/terminated)) came up, though for my use case (and I believe yours) what we really want is an owned version.
As /u/mbrubeck pointed out above, the security issue is that str::repeat doesn't actually allocate the gigantic amount of memory. So what should've been a memory exhaustion / DOS issue (and is, in the fixed version) turned into undefined writes out of bounds.
So given the following error enum: enum SpecialError { OutcomeA, OutcomeB(i64), OutcomeC{ node: Node, result: Node} } Then assuming you're using Result&lt;Success, SpecialError&gt; as your return type: match strct.possibly_error_return(values) { Ok(s) =&gt; do_success(), Err(SpecialError::OutcomeA) =&gt; handle_a(), Err(SpecialError::OutcomeB(v)) =&gt; handle_b(v), Err(SpecialError::OutcomeC { node: n, result: r } =&gt; handle_c(n, r), } And done. Now you could match on specific values for the tuple enum disciminant or the struct enum discriminant and the match machinery will prompt you to handle all possible variants of those nested values. 
Conveniently enough if you are matching on a struct named field (either in an enum discriminant or a direct struct), you can do this: Err(SpecialError::OutcomeC { mut node, mut result } =&gt; handle_c(node, result) And Rust automatically destructures the discriminant/struct and assigns those values to the names of the fields like here. Skips extra boilerplate such as { node: mut node }. 
I wrote a small crate a while back called [`c_utf8`](https://docs.rs/c_utf8/). It seems as though this may fit your use case exactly.
My architecture classes used assembly.
How about just rust_jupyter or similar?
Normally I would too, but it runs into an unfortunate problem: Some(hi as u16 &lt;&lt; 8 + lo as u16) Is interpreted as a generic argument to `u16` requiring parenthesis to disambiguate. This happens fairly often in bit twiddling code (casting integer types &amp; shifting) that I've started to use multiply more often I guess.
Let's say I have traits A and B as follows: ``` trait A { type Inner: B; } trait B { type Inner2; } ``` If I have a type `Foo` that implements A, then is the only way to access `Foo::Inner::Inner2` to write `&lt;Foo::Inner as B&gt;::Inner2`? Are there any tricks I can use to tell the compiler that I want to treat `Foo::Inner` only as a `B`?
It doesn't use MIRI. Two reasons that come to mind are: * I wanted code to execute quickly once compiled. Code is even compiled with optimizations turned on. * I'm not aware of a way to use MIRI on stable rust. I hadn't heard of xeus, thanks for pointing that out. Implementing the Jupyter protocol did take a little bit to get working, but now it is working, it probably makes sense to keep a mostly Rust native solution. It's not completely native, since I'm using the zmq crate, which is a wrapper around a C library.
Yeah that is unfortunate but I still personally prefer the bitshift for clarity.
I... don't know, sorry. Supposedly there are these awesome wasm tools but I just run with `--target=wasm32-unknown-unknown` and write my own bind glue to call stuff from js. But my background is in C++/reverse engineering so I'm familiar with how these details work under the hood. My understanding of these things comes from experience and it's just applying this knowledge to a new area. Google and a lot of trial and error later and I manage to make things work, but I've no idea how to teach this stuff or point you to specific places where you can learn. I can fill in a bit more details about the overall picture, let's say implementing a simple game tic-tac-toe: * Implement the game state and logic in Rust, wrap it up and expose only methods required after UI input. * Wrap this up in wasm, follow guides on how to interact with wasm modules in JS. I just created a local index.html file and opened it in the browser (not running any local web servers or anything, just plain html files). Here I heavily rely on the Mozilla Developer Network. * Host it on Github Pages! This is seriously cool and definitely worth checking out! Github provides free hosting for static files. This took me way to long to understand, but after consulting Google and reading the docs over and over I finally have somewhat of a grasp on it. * When you need a bit more handling on the clientside JS side for rendering, I've come to enjoy Vue.js. Mostly because it lets me play without a deep dive into the insanity that is the NPM ecosystem which I find a total clusterfuck. My only dependency is Vue.js which is as simple as dropping a single script tag in my index.html. I do recommend you use _something_ to manage the game UI, but build it up gradually as you realize you need something more to manage the complexity. * Post it on this subreddit! I guess :P That seems like a reasonable start, enough to wet the appetite without becoming too overwhelming (perhaps this is already overwhelming, depends on your experience). If you have any more questions, let me know and I'll happily help you get started.
Use a macro. You can see instances of that in the source for â€˜stdâ€™ for creating the [implementations](https://doc.rust-lang.org/src/core/num/mod.rs.html#4260) for things like â€˜TryFromâ€™ over multiple types, only in this case youâ€™ll abstract to something like â€˜impl_op(Add, add, +)â€™ or similar.
Does your code work? Code formatting only works for syntactically correct programs
In fairness, I'm suspect she did contribute more than twice as much as anyone else.
In a similar vein, I've also found that when the time comes to add a feature to a small personal project like this, I have a much easier time with my Rust projects than projects in other languages. 
Algebraic data types (i.e., Rust's `enum`) are _amazing_ for specifying ASTs. A major perk of using them is that anywhere you `match` on an ast value, the compiler performs an exhaustivity check to ensure you've covered every variant. So, when you go and modify your AST and try to compile your interpreter, the compiler will spit out the complete list of places you need to update your code to accomodate the changes. I don't reach for `Any` except as a last resort. 
Depends on whether you want to lean on Rust's semantics or define your own. Also depends on whether you actually know what types you are dealing with. \`Any\`'s runtime checking is pretty limited. &amp;#x200B; From your example code I'd use an enum, though in the \`Data\` type both \`kind\` and \`len\` seem redundant.
It wouldn't be too bad. But most people design their grammars around their experiences with other languages, and that is made more evident when you try to Frankenstein a new grammar that is supposedly 'better' than another one.
&gt; `Data` type both `kind` and `len` seem redundant. I have a columnar storage that can nest and (will)have more types than the basics here
Instead of having your own glue stuff, one can easily start with `cargo-web` + `stdweb`. A hello world is as simple as this: #[macro_use] extern crate stdweb; fn main() { let s = "Hello, World!"; js! { alert(@{s}); } } Compile, start server and open browser with `cargo web start --open`
It took me a little bit to figure out what you meant, so to give anyone else a head-start who comes along, the challenge is to modify the `where` bound of `bar` so that this code compiles, _without_ making it (too) much uglier: use std::fmt::Debug; trait A { type Inner: B; } trait B { type Inner2; } struct Foo; struct Bar; impl A for Foo { type Inner = Bar; } impl B for Bar { type Inner2 = (); } fn bar&lt;T: A&gt;(a: T) where T::Inner::Inner2: Debug { } Is the associated type _actually_ ambiguous, or is the compiler just being overly conservative?
Also note the previous discussion from the original security announcement a few days ago: https://www.reddit.com/r/rust/comments/9hssab/security_announcement_for_strrepeat/
It is surprisingly easy to type on a QWERTY keyboard, though.
Any plans on making rustup work with alpine? I do all my development on Alpine, and it appears that rustup has no musl builds. Without rustup I can't get the rust language server (there's also no packaged nightly), which is a nonstarter for me as far as using Rust goes.
Yup, exactly. Youâ€™re welcome!
&gt; If you were removing many rows and columns, this "efficient" version would be just as inefficient as your for-loop version. For cases where you expect to only keep a few rows and columns, it would be more efficient to allocate new vectors and only copy over what you're keeping. Each `remove` call has to shift all subsequent elements to the left, and that's obviously a waste of time if you're going to end up deleting everything. I'm not sure if there's a way to do this with the public safe API, but you can avoid multiple backshifts by using the same strategy that `Vec::drain` does. Instead of moving every element one space over with every removal, you can move each element or run of elements multiple spaces at once depending on how many of the preceding elements have been removed.
I think the thing that helped me most, to be honest, was picking a project and going all in with it. Most projects that you would reasonably want to use will encounter enough problems that you can get a decent feel for a language. By reasonable, I mean the project shouldn't just be the webapp equivalent of a Todo app. Beyond that, this reddit community has been a huge boon, as well as the various gitter channels associated with open source projects in the space. Above all, I have to admit, being persistent and making sure I at least touched my Rust projects on a weekly basis was a great help.
Adding lifetime to \`Capstone\` type is WRONG. The problem basically, is because \`disasm\_all\` method returns something that indirectly refer to the \`Capstone\` data, so the return type must explicitly include a lifetime that bind to the \`Capstone\` type. &amp;#x200B; Making \`Capstone\` type lifetimes, is not very ergonomic. It require anyone that needed only those methods do not leak references still need to specify a lifetime. &amp;#x200B; Looking at the following commit before the final fix: &amp;#x200B; [https://github.com/capstone-rust/capstone-rs/commit/a02fc099a11603589db041f568d4126dc164cc06#diff-519c1cf04d5b64620d3fa58fc0125420](https://github.com/capstone-rust/capstone-rs/commit/a02fc099a11603589db041f568d4126dc164cc06#diff-519c1cf04d5b64620d3fa58fc0125420) &amp;#x200B; We can see that before introducing lifetime to \`Capstone\`, the lifetime was introduced to \` Instructions\` first. However, as an explicit lifetime was introduced as a generic parameter, Rust didn't tie the output lifetime to any of the two input lifetimes: the \`&amp;mut self\` and \`code: &amp;\[u8\]\` with both lifetimes elided. &amp;#x200B; So, the proper fix here, is to specify the \`'a\` lifetime being the lifetime of \`&amp;mut self\`: \`&amp;'a mut self\`. Then there is no need to add lifetime to \`Capstone\` type. &amp;#x200B;
yeah, I was surprised that there isn't a `remove_all` function of some kind.
Yeah we did too, we learned both. For instance one of our projects was an implementation of malloc in C and so forth. Idk maybe im off base here
Oh yeah, that makes sense; the type `(T, Taint)` isn't local to your crate, but `struct A&lt;T&gt;(T, Taint)` is. 
remove takes an index, so I was hoping there was a remove_all that takes a list of indices to remove, but true! retain could be used to remove matching elements.
They could still check the size hint. If it's too small or nonexistent, you can always reallocate. If the hint is good, then you save on allocations.
`retain` takes a `FnMut`, so you can keep a counter in the closure.
This has been bike-shedded to death in multiple threads, RFC's, etc. (for exampe: [https://internals.rust-lang.org/t/pre-rfc-another-take-at-clarifying-unsafe-semantics/704](https://internals.rust-lang.org/t/pre-rfc-another-take-at-clarifying-unsafe-semantics/7041)). There is no possibility at this point that it will change. It wouldn't be backwards compatible. &amp;#x200B; That being said, it would've been nice had a different word been chosen, but, it wasn't.
Attention there would mean what for the rest, no attention needed?
Yeah, it's probably too much to hope for the compiler to recognize that the pattern is `while x &lt; threshold { x += 1; }` and go straight to `x = threshold;`.
Thanks for the quick turnaround. Could we add some additional recommended actions for users on these announcements? I had to click through a few times to find the list of affected versions (1.26+) and it might seem obvious but we should communicate users should both upgrade and re-compile projects (via `clean` and then `build`) if possible. Not everyone may be able to do both but this announcement could be more direct for those who are not keen on the workings of compilers. The announcement has a lot of wording around "if you're affected", which I would guess many of those affected wouldn't know it due to being used in dependencies. I don't know how to tell if I'm affected. I suggest we specify something similar to, "If you manage projects that have been compiled with 1.26+ these projects are affected. You should upgrade rust to 1.29.1, run `cargo clean` and then `cargo build` all affected projects to resolve the problem"
Can you see the code properly now?
Feel free to complain publicly or privately about the things that we could make easier in the Jupyter Protocol, We already got some feedback from the Xeus folks and will take that into account. Sidenote, if you push that to something you are really proud of and want to announce broadly at some point, I can give you access to [blog.jupyter.org](https://blog.jupyter.org)... but I guess your employer might have some highly visible tech blog as well. 
Yeah that's true. I know I've seen one byte buffer overflows where the developers said it was impossible to exploit, and some genius figured out how to make 100% reliable code execution.
Keep with it, it only gets better! My journey was Python -&gt; C (*very* briefly) -&gt; Rust... zero regrets. Rust initially piqued my interest because I wanted Python-esque abstraction with C-like performance. Rust ended up being so much more though; this language is offensively fun.
&gt; the list of static checks turned off by unsafe I thought that `unsafe` very explicitly didnt turn anything off, it only allows you slightly more, namely the "unsafe superpowers" of 1. Dereferencing pointers 2. Calling other unsafe stuff 3. Accessing/modifying mutable statics 4. Implementing unsafe traits It shouldnt be turning anything off?
Yes. Thanks.
Is there any `#[no_std]` (without `alloc`) way to break a recursive type definition with an owned pointer? Specifically I'm trying to do something like: ```rust struct LinkedWrapper&lt;T&gt; where T: Recycleable, { pub value: Option&lt;T&gt;, pub next_wrapper: Option&lt;LinkedWrapper&lt;T&gt;&gt; } ``` ...but the type definition blows up. I'd like to avoid using the nightly `alloc` crate as simply a challenge to myself, but there doesn't seem to be a way to prove ownership without relying on either `Box` or `Rc`.
Semantics, I guess. Turns off a bunch of restrictions. 
I wouldnt really call that a bunch of restrictions, and i certainly don't see how any of that is turning "off static checks that are known to catch common and hard-to-find bugs". None of that stuff is checked, for one. Unless you mean it being outright forbidden is the check?
No, because - memory is either on the stack or the heap - you ruled out the heap, because you want no_std and no alloc - you ruled out the stack, because you can't own things on the stack, at least not through a pointer. 
Functions are first class citizens. Procedures and methods aren't. The only exception being a block which is a special exception that a few languages such as Rust allow. Rust has blocks, not functions. JavaScript has functions. 
I wouldnt really call that a check..
Yeah, so if you use the standard library traits like that it can't be used in a `no_std` context. That's why I avoided it in my lib. I'm wondering if I should replicate your API and only have it implemented if `std` is being used and I can use my custom API if it's built for `no_std`.
Well, it does check whether the rule was broken.
I don't mind typing ; . The point I was making is that the use of semicolon shouldn't be to make an expression void. I was was recommending that curly braces be removed from procedures, but curly braces are also being used for blocks. For those that would like either all braces or no braces, there is the begin end syntax, but for those who don't care, curly braces can still be used for blocks. With that said, clarity isn't about having to type as little as possible. It's about having your code be as a readable as possible. Operators tend to gunk up readability. Even curly braces. Replacing operators with English can be a good way to increase readability. Lastly, languages are intuitive to people. When you learn a language, spoken or programming, what you're actually learning is a way to express ideas. As you're learning the language, your brain begins to adopt the syntax and form internal rules for how to map ideas to syntax. You begin to structure your ideas in terms of that language and form expressions. As you do so, you inevitably form expressions that you haven't learned yet by applying the internal rules that you've formed from what you have learned. If these new expressions don't match the language, then it's not intuitive. It means that there is inconsistency in the rules behind the syntax or there is inconsistency in how they are applied.
I definitely agree.
I don't think so. I've used a number of functional languages including Lisp, Clojure, and Haskell. I went ahead and read over ML and it seems pretty straightforward to me. Maybe there are some skeletons hanging around ML that I haven't seen before, but the apparent influence that's present in Rust I would say is an overall positive. The only exception I would have to that is the use of fn. Go did this too and it had influences from Haskell, but the problem is that ML and Haskell are functional languages so they actually have functions. Rust could have functions, but I don't see any. All I see are procedures and I think procedures should use def.
`unchecked` is the best I can think of, but maybe that's too similar to checked/unchecked exceptions.
No, you're absolutely right. I hadn't been introduced to this part of Rust yet. So how does this interact with Rust's scoping rules. If I declare variables and then a Closure and pass the Closure around, are the variables prohibited from being deallocated until the Closure is deallocated?
About constant time functions, I've always thought it would be a good idea to abstract out those unsafe functions as minimal primitives that are so small that they are "obviously" safe and can be easily verified. Does such a crate already exist?
`const` and `mut` are not opposites; they're totally unrelated (other than being mutually exclusive). In fact `const` means what other languages might call `const static`: even when used inside a function it always declares an item whose lifetime is not a single call of that function (in fact the only thing this does is constrain its *lexical scope* to that function). So the fact that they're not declared the same way is a *good* thing serving the goal of demonstrating that they're not related. By arguing that they ought to look the same you kind of missed the point... Where are `while` and `loop` used for something other than a loop? `for` is, of course, used for universal quantification of lifetimes but, uh, I don't think the beginner needs to worry about that.
That's really interesting. I'd have to look at JavaScript again, but it sounds like that's a far more efficient and safe use of a Closure than what JavaScript has defined (or most other procedural languages for that matter).
Rust already has variable backtrace support with `RUST_BACKTRACE=1` and `RUST_BACKTRACE=full`. Would a function/method attribute that allowed library authors to hide stack frames in the minimal backtrace case be useful? 
It's still variable declaration which is why I had suggested using the let, var, const approach. The sytactic rules for that would also be easier. While and loop aren't used for anything else. I just mentioned them because like for, they're always used for loops.
And it's just the normal borrowck that you have everywhere, and why Rust is such a great language to work with. All references follow the same rules, where the reference statically is not allowed to outlive the data it borrows. And in the same breath you get mutability XOR aliasing, meaning that if you have `&amp;mut _` you're the only one looking at a value, and if you have `&amp;_` the value is guaranteed not to change while you have it. The same system _also_ prevents Iterator invalidation, which even Java has to worry about. The borrow checker is the centerpiece of Rust, and what basically everything else exists to support.
It definitely requires thinking about operators in a new way. It seems like most of the operators need to be framed in the context of borrowing.
Mine was in MIPS.
No worries!
Coincidentally, while messing with Haskell recently I was thinking about how much I like Rust's notation for anonymous function compared to Haskell and other alternatives. That's the issue with syntax; everyone has their own preferences. To me, `|x| x+1` just looks a bit better and seems easier to read than `\x -&gt; x+1`, and other notations tend to be longer. Of course, it is different from many other languages, but that isn't itself an issue. Though, I've used Rust more than Haskell, so maybe I'll warm up to their syntax at some point. Haskell syntax generally seems quite elegant, and this isn't a major issue to me. I can't comment on what the implications are as far as implement the parser; but as far human parsing, I can't think of any code I've seen where I would be uncertain whether or not something is a lambda.
In what way? Only in as much as most functions borrow the data they work on -- operators are just (trait) function calls, anyway. Since Rust is pass-by-move, `let x = ...; foo(x);` means that you _cannot_ use `x` anymore, as it's been moved into `foo` (unless `x` is `Copy`). And unless you want your operators irrevocably taking ownership of your values, the functions they represent should borrow. That _said_, most operator trait impls you'll see/use _will_ take by value, as they're typically on `Copy` types. There's no "extra" data associated to `u32` the way there is with `Box`, so the `memcpy` move is duplicating the data.
You're still missing the point: `const` is not used in variable declarations. `let` declares a variable. A variable is &gt; a component of a stack frame, either a named function parameter, an anonymous temporary, or a named local variable. `const` declares a constant item; that is, &gt; a named constant value which is not associated with a specific memory location in the program. Constants are essentially inlined wherever they are used, meaning that they are copied directly into the relevant context when used. References to the same constant are not necessarily guaranteed to refer to the same memory address. `const` items aren't variables. `mut`, being a property of *variables* (and references, in a related but different meaning), is inapplicable to items. `const`, being a kind of item, is inapplicable to variables. They have nothing to do with each other and therefore I don't see why they'd have the same or even similar syntax. Lo, they do not. Kudos to the language designers for having different syntax for different things, because the opposite would be confusing.
Fair enough. Like I said before, semantics.
I was thinking maybe `danger`, which might imply "might well be broken; can't tell". It's moot, really.
Yeah, but how to get all IDEs and text editors to refuse copy pasting that phrase or accepting macros replicating it... ;-)
FYI: [Unbounded lifetimes from Nomicon](https://doc.rust-lang.org/nomicon/unbounded-lifetimes.html) This is a classic example of unbounded lifetimes, so worth reading.
Java, C, and C++ all use "static" to mean a place[0] or function which exists just once in the entire program[1] instead of once per instance of the containing *thing*, where *thing* might mean function, class, compilation/translation unit, or some combination of these. In C when qualifying a function it makes the symbol local to the translation unit, but let's call that an unrelated additional use of the same keyword since I have such a succinct definition above. ;) Python lacks the keyword AFAIK but as a concept it means the same as in Java. In C# it means the same as Java. Haskell, Coq, Agda, common lisp, scheme, various shells all lack the keyword and concept. Rust is similar in two regards: the already-mentioned likelihood of encountering this keyword at an item definition, corresponding to C/C++/Java static variables, and the tie to the concept of "existing for the entire program". But it's significantly different in that C/C++/Java `static` qualifies variables and functions; whereas Rust's `'static` does not qualify items but rather references (and types and other lifetimes, as an outlives specifier). At that point the concepts just become completely incomparable. [0] where "place" is defined appropriately for the given language; but basically, a memory location [1] Java: for the ClassLoader instance, I guess? â€” it's been a decade â€” but... yeah, let's just say "program".
Yeah, but the bike shed is not worth the hassle of doing that.
Small nit: your matrix multiplication link should point to https://vorner.github.io/2018/05/12/Mat-perf.html instead.
Have they finally buffed the AK? 
Instead of NLL, I think the following would be more important (unordered) at least to me: * async/await/generator - essential for concurrent programming * unsized rvalues - big improvements and makes using trait objects easier * HRTB on associate types - big improvements on meta-programming and type hacks * `!` type - logical and powerful extension to express unreachable in safe code * Specialization - another big meta-programming jump * ...
Thanks. Will do. I might wait a few days to see if we can iron out a few issues first. Perhaps see if we can at least get it working on Mac
Thank you very much for taking the time to look through the project and post. &gt; If you're making a distinction between primitives and high level interfaces, it's a little weird to provide unauthenticated encryption as a high level interface. Indeed it's somewhat unconventional. I decided to do this because I haven't implemented the Poly1305 algorithm yet. This meant either not having an "high-level" function for ChaCha20, only leaving the lower-level function available, which also lets the user control the nonces or having a "high-level" function that handles nonces for the user, until the Poly1305 algorithm has been added. I tried to make it clear in the Security section of the docs, that you would in most cases want integrity. The function has also been explicitly named `chacha20_*` to try and indicate the missing `poly1305` part. I plan on renaming the functions `encrypt/decrypt` when Poly1305 has been added. It's not an optimal solution. &gt; In general I think there's a continuum from "uses literally no unsafe code" (almost impossible unless you're a math library) to "uses no unsafe code outside of the standard library" to "depends on crates that includes unsafe code" to "uses unsafe code itself". I see how I have been somewhat wrongfully advertising `orion` here. My current explanation could create some misunderstanding. What would you think about writing in the Cons section "Even though `orion` itself doesn't use unsafe code, some of it's dependencies do."? Maybe you have a better solution in mind?
I'm not entirely sure about what you mean, but crates that exist only to provide constant-time operations exist. One of those is [subtle](https://crates.io/crates/subtle).
I will get started with my mrtparser soon then. :) Thanks for all the info!
&gt; I think, in general, you just want one target containing a cargo build command per makefile; this would also prevent parallel make (i.e. make -j) to run cargo multiple times and mess things up. That was the whole idea. `rust_code.so: RUST_SOURCE` is the one target (one `[lib]` allowed per crate, remember) and any C code depends on it.
What other languages, out of curiosity?
This is pretty amazing, how long did it take you to get this done? Donâ€™t mean to sound rude but why did you do this, is it out of your love for the community or is this something you do on a day to day basis. 
It looks great! Maybe you can adjust to program such that users can set the karma threshold themselves?
My first thought was that this was about Windows Assembly hahaha. I guess I must look more into Webassembly I guess :)
Looks really cool! I am looking forward to seeing more things like this. I think Rust can really be the next-gen penetration testing language.
Thanks for posting that blog post, it was an interesting read. &amp;#x200B; This is a curious goto project for learning new programming languages ;) I am listening to music just like you: offline, with a big playlist of mp3s and shuffle, but it would never occurred to me writing such a thing. I am using VLC and I have no complaints about bloat. But I liked how it worked out and it matches with my own experience: I am still slower to implement stuff in Rust than in some other languages, but when you are done you have a strong feeling of confidence.
Unsafe is a good choice for the keyword. &gt; The term "unsafe" has been used incorrectly and often refereed to as something that takes the literal English definition of unsafe This is wrong, in the context of Rust (and many other programming languages), it refers to memory safety. &gt; The term "unsafe" has a negative connotation - Yes, I agree with this and I think it's a very good thing to discourage unsafe code in a programming language that has memory safety as a primary selling point. &gt; Labeling a code block "unsafe" does not necessarily mean the code is literally "unsafe" It means the code block __could__ break memory safety and that the compiler can't fully verify if it does or not. If the programmer __knows__ something will break memory safety, that code should be written in a different way, always (unless your intention is break things). &gt; a new word should be chosen such as "attention" or "attn" to signify that the code should be closely reviewed instead I disagree. Unsafe is very clear and well understood to refer to memory safety and that it unlocks parts of the programming language that can't be as well verified by the compiler for memory safety and therefor is more likely to break memory safety, causing undefined behavior.
This is wonderful and super useful! For those interested I started developing a emacs mode to support it. Still need to spend more time on it but has rudimentary support for: C-c c -&gt; Eval Buffer C-c l -&gt; Eval Line C-c r -&gt; Eval Region https://github.com/SerialDev/evcxr-mode
You might be interested in [some of this discussion](https://internals.rust-lang.org/t/pre-rfc-allowing-async-await-in-no-std/8460/4) which includes extending the `Generator` trait to take arguments for better `async`/`await` support; and [here's a playground](https://play.rust-lang.org/?gist=4497700667146f836f60d81952861b2a&amp;version=nightly&amp;mode=debug&amp;edition=2018) with a full manual implementation of an argument taking generator.
The part that lets me return a specific type. With enums I can't do fn foo() -&gt; Clean&lt;i32&gt; { ... } because `Clean&lt;A&gt;` isn't a type, it's a constructor in `Taint&lt;A&gt;`
I think the problem here is using `trait` when you should be using `enum`: https://play.rust-lang.org/?gist=694f8f8efd2c8273623790dce69b2c41&amp;version=stable&amp;mode=debug&amp;edition=2015
wrapping a trait around an enum seems to be very unergonomic for the end user though. I can see the benefit of it, but it's real awkward to write `Clean(Clean(x))` I actually did think of just leveraging `Result` for this, having `Ok(Clean(x))` and `Err(Dirty(x))`, thus using the built in methods to their advantage
In scala it is ```sealed trait Trait[A]``` and someday, perhaps, it will be replaced by \\\ enum Trait\[A\] { case class Clean\[A\](data: A) extends Taint\[A\] case class Dirty\[A\](data: A) extends Taint\[A\] } ``` ([http://dotty.epfl.ch/docs/reference/enums/enums.html](http://dotty.epfl.ch/docs/reference/enums/enums.html)), which already looks similar to how it is done in rust. Anyhow you must know the size in bits of an entity which you return - that is an intuition I personally use. And two options which come to my mind are either `enum` or `Box`.
Sad day. I would've loved to see `Taint::Clean&lt;A&gt;` as a type
You could try `mpd`. It idles at 20-30 MB RAM and can be controlled remotely.
I guess it's not an usual thing to do in a new language to learn and it's not like I think everybody should do to learn something. It kind of happened for me for no specific reason that the ritual developed. But I also think others might have *some* personal project that they rewrote in 10 different languages over the years and like to return to it. However, it *does* have some properties of being a good learning toy project. On one side, it is quite small. On the other, it is non-trivial. It needs some OS integration (pipes, starting other processes), it needs some kind of asynchronous stuff, network communication (OK, unix-domain sockets are not over network, but they work the same way), it needs some simple data structures and logic you have to slow down and think about. So it gives me some taste about the language and other real projects are not necessarily more complex, only bigger, in principle.
Could you clarify what action should be taken by crate maintainers to mitigate this?
A few exist: https://crates.io/crates/safemem https://fuchsia.googlesource.com/garnet/+/master/public/rust/crates/zerocopy - open-source but not on crates.io yet, used interally by Google [Fixed-capacity vector](https://internals.rust-lang.org/t/pre-rfc-fixed-capacity-view-of-vec/8413) in prototype stage, although that's kinda niche
&gt; It would probably come with some performance hit, but would be more comfortable to use â€’ but still with the strict type system and preventing all the bugs. Rust was supposed to allow a garbage collector for easier use with a performance hit, but that seems to be gone now. 
It took me a few months to be confident enough to produce useful and usable things but my code quality got much better after ~1 year. I'm much more comfortable with writing Rust now, and enjoy it even more.
&gt; These links are broken. They should be fixed now, we have to do a quick bait-and-swap every post (we post with "null" links), so we can share the post on multiple sites, then update the links. The update should be live now. &gt; can we do something to get stm32f103xx-hal back on track I know that /u/japaric is pretty slammed with other stuff at the moment. Not sure if he would be open to pulling in some other maintainers of that crate to keep it moving.
&gt; is pretty slammed with other stuff at the moment. Yeah, his blog/Patreon have also been pretty quiet for a while now. I hope he's all right, and just busy.
why can I do this: let mut a = 1; let &amp;mut b: &amp;mut i32 = &amp;mut a; and also this: let mut a = 1; let b: &amp;mut i32 = &amp;mut a; and also this: let mut a = 1; let b = &amp;mut a; ? Are these the same thing? Or do they have some subtle different meaning. Also, why specifically do we need the "let mut a" syntax when we can just do "let a:mut whatever" and have it mean the same thing? It seems to me like there are multiple ways of doing this. Coming from Python (have only one way to do a thing) it seems excessive.
As a heavy Cython user for physics simulation, I'm not impressed with your arguments. Most of my concerns stem from 'extension of what exactly'? If you write an CPU-heavy number-crunching extension for a high-level language project, chances are that most Rust's features won't really shine there. If you're writing CPU-heavy logic code, well, you'd have to take a sizable chunk of your problem's domain across the language border, at which point a full Rust rewrite could seem simpler. For Python, I doubt that even the basic data structure, numpy arrays, is easy to carry over to Rust code. But I'd love to be wrong here =) Finally, I doubt that many high-level languages will easily integrate Rust in their packaging ecosystem. Looking back, maybe my definition of extension mismatches yours or something?
How should I use [`try_fold`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.try_fold) if not returning Some(\_) or None? I'm having problems in this easy exercise from [exercism.io](https://exercism.io): r/https://play.rust-lang.org/?gist=3415bedb996684b06a37c523772c778c&amp;version=stable&amp;mode=debug&amp;edition=2015 &amp;#x200B; &amp;#x200B;
`start` must return `GeneratorState&lt;Self::Yield, Self::Return&gt;` as well.
I understand how enum make the code more type safe. I could use traits for recover some of it. I wonder if the performance or other considerations can be added as argument. Truly, the main thing I see is the amount of extra code, like I ask in https://www.reddit.com/r/rust/comments/9ivuig/best_way_to_implement_many_traits_for_custom/ and how eventually give the lang some FFI capabilities.
Why, you can. Use `Any`. `trait Trait&lt;A&gt;: Any`. But you really should use enums. If you don't like writing `Clean(Clean(42))` (I don't as well) then implement `From&lt;Clean&lt;A&gt;&gt;` and write `Clean(42).into()`.
They are currently in the phase where they are trying to introduce cargo to the build system so the codebase can be oxidized slowly. They ran into an issue that I'm not able to help with (involves libc++ on OSX): https://github.com/newsboat/newsboat/issues/287 If somebody is able to help there (or interested in supporting the migration in general) please do! Pointers to different approaches to oxidize a codebase are appreciated as well.
&gt; If you write an CPU-heavy number-crunching extension for a high-level language project, chances are that most Rust's features won't really shine there. I concur. While highly-optimized C code is as fast as Rust, with Rust it's just easier to get good performance. - [Rayon](https://github.com/rayon-rs/rayon) makes writing data-parallel algorithms easy. - We also have various crates for [easy](https://github.com/AdamNiederer/faster) and [portable](https://github.com/rust-lang-nursery/packed_simd) SIMD. - See Bryan Cantrill's [blog post](http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/), specifically item 9: &gt; my naive Rust was ~32% faster than my carefully implemented C
&gt;So, the proper fix here, is to specify the `'a` lifetime being the lifetime of `&amp;mut self`: `&amp;'a mut self`. Then there is no need to add lifetime to Capstone type. I ran into an issue where `Capstone` is mutably borrowed with `disasm_all()`, so subsequent methods on `Capstone` cannot be called on the instructions. error[E0502]: cannot borrow `cs` as immutable because `*cs` is also borrowed as mutable --&gt; src/test.rs:411:41 | 402 | let insns = cs | -- mutable borrow occurs here ... 411 | test_instruction_detail_helper(&amp;cs, insn, info, has_default_syntax) | ^^ immutable borrow occurs here 412 | } 413 | } | - mutable borrow ends here
thanks for your reply. i was looking for something like that. 
&gt; This is still not ideal though - it does not necessarily make sense for the closure arguments to be the same as the yielded ones. Do you have an example use-case that requires different argument types? The primary use for implementing `async`/`await` requires the same argument on all calls to `resume` so is fine with just a single type for this.
That's... a good point, that sadly kind of breaks my suggestion. Because `start()` needs to also return the pinned generator: fn start&lt;'a&gt;(self) -&gt; (Pin&lt;'a, Self::Started&gt;, GeneratorState&lt;Self::Yield, Self::Return&gt;); Or, if we decide we don't need the pinned generator if it returns right away: fn start&lt;'a&gt;(self) -&gt; GeneratorState&lt;(Pin&lt;'a, Self::Started&gt;, Self::Yield), Self::Return&gt;; But this would mean we can't directly move the pinned generator to it's final position: let (generator, state) = generator.start(/*...*/); match state { // ... } dispatcher.add(generator); // moved here It also makes things a bit too complicated...
This posts has one of the links from "serious production use" pointing to an article about holyjit -- but as I understand it that project is not running in production at all. It's more like a research project from someone on the Mozilla JavaScript team.
Newsboat seems to be a "RSS/Atom feed reader for text terminals".
&gt; Rayon makes writing data-parallel algorithms easy. Huh, that's really cool. But, well, Cython has `prange` and Numba goes a step further with autoparallelization. &gt; So if you're interested in writing fast Python plugins which don't take months to optimize and tune, Rust is a nice alternative. To GIL-free subset of Cython? Well, maybe. To Numba? Sorry, but I still doubt that.
Can you link to the source of that stackoverflow code? There are some pretty sketchy things in there (and some very strong assumptions about what the C code is going to do with `cb_ptr`). Also, what is the actual problem that you're experiencing? Is there a compiler error?
You're welcome! By the way, don't make the same mistake I did: don't keep coding alone. Read code from others, try to make small contributions to other projects. The reason I tell you this is I recently got out of my lonesome coder cave and discovered a lot of idioms I would have had a hard time to discover otherwise. I'm sure it is possible to progress a lot faster than I did.
Would you prefer "brave"?
It looks like he's just working on other stuff. There's still activity on his other repos. Hopefully he'll add some more maintainers though, I haven't worked on embedded stuff in a while since RTFM is broken currently.
In my case I was passing data from sensor "driver" to python, so I wasn't using slicing. But usually I think, you'll first convert numpy array to `ndarray` type and will work with it.
It would be interesting to see some documentation (blog posts) of the progress as the rewrite happens, because this is a non-trivial undertaking!
How can `start` return a pinned generator anyway? It's taking `self` by value, so where is the returned reference supposed to point to?
Wasn't `Pin` (or more specifically - `!Unpin`) magic for something the compiler can't move?
Which internet channels? I've only listened to Spotify and YouTube channels, but I don't like either's interface. I don't care too much about big names, I mostly want: * podcasts * relaxing music (for reading documentation and whatnot) * aggressive, uptempo music (for banging out code) Is there a good index or whatever of popular online music?
That sounds cool. Is it on Github or something?
This is the [Stack Overflow question where I got the code from](https://stackoverflow.com/questions/32270030/how-do-i-convert-a-rust-closure-to-a-c-style-callback/42587849). Currently, it won't work because of the 'static lifetime requirement. I tried adding a lifetime parameter 'server, but there are other compiler errors, that that causes in some other modules, such as the following: error[E0106]: missing lifetime specifier --&gt; src\server.rs:18:28 | 18 | pub fn new() -&gt; Result&lt;Server&gt; { | ^^^^^^ expected lifetime parameter | = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from = help: consider giving it a 'static lifetime pub struct Server&lt;'server&gt; { pub(crate) handle: LavHandle, block_callback: Option&lt;Box&lt;Box&lt;'server + FnMut(f64)&gt;&gt;&gt;, } impl&lt;'server&gt; Server&lt;'server&gt; { pub fn construct(sampling_rate: u32, block_size: u32) -&gt; Result&lt;Server&gt; { let mut handle: ffi::LavHandle = 0; check(unsafe { ffi::Lav_createServer(sampling_rate, block_size, &amp;mut handle) })?; Ok(Server { handle, block_callback: None }) } Another error: error[E0106]: missing lifetime specifier --&gt; src\nodes\pull_node.rs:33:75 | 33 | pub fn new(server: &amp;server::Server, sr: u32, channels: u32) -&gt; Result&lt;PullNode&gt; { | ^^^^^^^^ expected lifetime parameter | = help: this function's return type contains a borrowed value, but the signature does not say which one of `server`'s 2 lifetimes it is borrowed from The pull node also has a callback that can be set for c to call when more audio is needed, and uses the same implementation pattern. pub struct PullNode&lt;'node&gt; { handle: LavHandle, audio_callback: Option&lt;Box&lt;Box&lt;'node + FnMut(&amp;PullNode, i32, i32, &amp;mut [f32])&gt;&gt;&gt;, } impl&lt;'node&gt; PullNode&lt;'node&gt; { /// Creates a new Pull node. pub fn new(server: &amp;server::Server, sr: u32, channels: u32) -&gt; Result&lt;PullNode&gt; { let mut node_handle: LavHandle = 0; check(unsafe { Lav_createPullNode(server.handle, sr, channels, &amp;mut node_handle) })?; Ok(PullNode { handle: node_handle, audio_callback: None, }) }
Nope, no magic at all. `Pin` is simply a wrapper type for reference types (including owning "smart" references such as `Box`/`Arc`) that requires some extra invariants of those references. So you need to pick a reference type for this function to return, and safely implement it so that those invariants are upheld. `fn start(self: Box&lt;Self&gt;) -&gt; Pin&lt;Box&lt;Self::Started&gt;&gt;` is probably possible, but I'm not sure if there's any safe way to implement this without heap allocation. The simplest solution to removing the `unsafe` from `resume` is to update the `Generator` trait to use the pinning API, as far as I know it just hasn't been touched since that was implemented. Change the trait to: ```rust trait Generator { type Yield; type Return; fn resume(self: Pin&lt;&amp;mut Self&gt;) -&gt; GeneratorState&lt;Self::Yield, Self::Return&gt;; } ``` and have `impl Unpin for &lt;GeneratedGeneratorType&gt;` injected in for non-self-borrowing generators to allow calling them unpinned.
I'm definitely not your target demographic for Binaryum, but congrats anyway.
Well done!
This looks pretty nice, any plans for SPIR-V? I assume it might be too niche. I always found it hard to read SPIR-V code with a lot of branches, so I created a small tool that displays the SPIR-V in a graph https://i.imgur.com/WhlwvYb.png. It is quite usable, but a real editor would probably be better.
Are `environment`, `source`, or `i` used anywhere else after the callback is set? Could you move those into the callback instead of taking them by reference? Like: ``` let block_callback = move |_: f64| { ... // do stuff }; ```
Really excited about the ["Or patterns" RFC](https://github.com/rust-lang/rfcs/pull/2535). This would fix [one of my oldest feature requests](https://github.com/rust-lang/rust/issues/17180). Also good to see [`MaybeUninit`](https://github.com/rust-lang/rust/pull/53508) in nightly since it will allow easy fixes for some [tricky soundness bugs](https://github.com/servo/rust-smallvec/issues/126) in generic code that uses `mem::uninitialized`.
You should use `core::intrinsics::unreachable()` after this `asm!()` block since it jumps elsewhere. Don't know if that is sufficient to solve the issue.
Woohoo, congrats to the wasm working group! I just wish I had been able to contribute more.
You probably will need to add a lifetime to `Server` and fix the errors that arise as a consequence (which look annoying but straightforward, just parameterize everything that uses `Server` over its lifetime). The issue is ultimately that you need to ensure your callback closures' references outlive the `Server` object. As asymmetrikon suggests, you could use a `move` closure instead which may make it easier to get your lifetimes straight. You could also put `Arc&lt;Mutex&lt;T&gt;&gt;`s into the closure which would get you a `static`-lifetime reference to the things you need to mutate, though that's not very ergonomic. Having said that, there are some serious issues with the code you've posted (which I don't think appear in the SO post). For example, you assign your callback to `self.block_callback` inside a new Box. A Box owns its data, but you have another pointer to this data stored in whatever internal structure `Lav_serverSetBlockCallback`. If you ever obtain a `&amp;mut` pointer to the insides of this box, which the borrowck will allow you to do, this violates the assumptions on `&amp;mut` and that's UB. If you ever reassign to the variable, it will free the Box and now your callback points to uninitialized memory, which is also UB and almost certainly exploitable. For example, you do this in your own code -- when you call `set_block_callback`, you assign to `self.block_callback`, freeing whatever used to live there. Can you guarantee that nothing is going to try to use that memory? (Because you have a `&amp;mut self`, you are telling the compiler that you can make this guarantee, but I suspect you can't because I suspect that LAV has some other thread that triggers this callback function.) Even if you can make this guarantee, what happens if the subsequent `check` fails? 
The audience for this post is people who currently lack the confidence to write any extension modules. They have been told that they're not skilled enough to get it right. I believe that scientific computing &amp; HPC workflows are sufficiently different than what I intended. There are only critical paths. Cython was addressed directly in the post in an earlier draft, but I ended up removing it because I didn't want to appear to be too Python-centric. In the general case, I would stick with Cython. Especially if your deployment environment is well understood. Rust can perform well in scientific computing, but there are already good tools with a longer track record. One example: NumPy is very copy heavy, whereas Rust can mutate in place much more easily. 
How do I turn the synthesizer off???? ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚
This is extremely exciting. I had no idea that the whole Rust WASM story had developed to this level of sophistication and completeness. I honestly did not get all the excitement about WASM and really didn't understand the push to WASMify Rust, but, now, seeing all this great work, I finally "GET IT"! Call me the idiot! &amp;#x200B; Wow! Thanks to all those who've worked on this wonderful project. What an exciting day for Rust!
In case of async, isn't that type `()` for both? The usecase I had in mind is inverted iterations. Instead of calling `next()` on an iterator to get the next value, the iteration will call `resume()` to push the value to the generator. This allows some new patterns. Consider, for example, [`unzip()`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.unzip). Unlike the lazy `zip()`, `unzip()` is eager. It can't produce two iteartors, because then you could advance one - consuming the source - without advancing the other. But - if we iverted the iteration we could hhave created this: fn unzip_collect&lt;T1, T2, I, G1, G2&gt;(pairs: I, consumer1: G1, consumer2: G2&gt;) -&gt; (G1::Return, G2::Return) where I : Iterator&lt;Item = (T1, T2)&gt;, G1: UnstartedGenerator&lt;Start = (), Resume = Option&lt;T1&gt;, Yield = ()&gt;, G2: UnstartedGenerator&lt;Start = (), Resume = Option&lt;T2&gt;, Yield = ()&gt; { let (g1, ()) = g1.start(()); let (g2, ()) = g2.start(()); for (v1, v2) in pairs { g1.resume(Some(v1)).expect_yielded(); g2.resume(Some(v2)).expect_yielded(); } (g1.resume(None).expect_complete(), g2.resume(None).expect_complete()) } /// [(a1, b1), (a2, b2), ...] -&gt; (a1+a2+a3+..., b1*b2*b3*...) fn foo(pairs: impl Iterator&lt;Item = (u32, u32)&gt;) -&gt; (u32, u32) { unzip_collect(pairs, |()| { let mut sum = 0; while let Some(n) = yield { sum += n; } sum }, |()| { let mut prod = 1; while let Some(n) = yield { prod *= n; } prod }) } `unzip_collect` has 2 generators. It iterates over the source once, splits each item, and pushes it to the generators. And of course - these are simple generators, but we could write combinators for them... If `start()` and `resume()` had to have the same arguments - or, for the simplicity, if there was no split between `start()` and `resume()` and the first call to `resume()` would pass the arguments to the closure - this example would look like this: fn unzip_collect&lt;T1, T2, I, G1, G2&gt;(pairs: I, consumer1: G1, consumer2: G2&gt;) -&gt; (G1::Return, G2::Return) where I : Iterator&lt;Item = (T1, T2)&gt;, G1: Pin&lt;Generator&lt;Resume = Option&lt;T1&gt;&gt;, Yield = ()&gt;, G2: Pin&lt;Generator&lt;Resume = Option&lt;T2&gt;&gt;, Yield = ()&gt; { for (v1, v2) in pairs { g1.resume(Some(v1)).expect_yielded(); g2.resume(Some(v2)).expect_yielded(); } (g1.resume(None).expect_complete(), g2.resume(None).expect_complete()) } /// [(a1, b1), (a2, b2), ...] -&gt; (a1+a2+a3+..., b1*b2*b3*...) fn foo(pairs: impl Iterator&lt;Item = (u32, u32)&gt;) -&gt; (u32, u32) { unzip_collect(pairs, |n| { let mut sum = if let Some(n) { n } else { return 0; }; while let Some(n) = yield { sum += n; } sum }, |n| { let mut prod = if let Some(n) { n } else { return 1; }; while let Some(n) = yield { prod *= n; } prod }) } Now, at first glance this looks simpler, and it is simpler for `unzip_collect` - but not for the generators, because now they need to handle the first value specially. 
&gt; The audience for this post is people who currently lack the confidence to write any extension modules. Got it. And I'm probably closed-minded enough to equate extensions to HPC by default =) &gt; NumPy is very copy heavy, and at the same time not copy-heavy enough to prevent views biting newbies in the ass occasionally =D 
It's not. There is actually not much difference using unreachable() or not. Mostly is changing the retn instruction on the bottom of the function with an ud2. Considering that the retn will be never reached it's a useless change. (Now I'm testing in debug, I don't know if in release the istruction will still be compiled). &amp;#x200B;
you could do a cross platform gui with opengl and gfx-rs + conrod or something
I just want to say that you are an inspiration to me.
Interesting, I was just investigating [stdweb](https://github.com/koute/stdweb) yesterday for a possible project. If I understand correctly, web-sys accomplishes much of the same goals, but has a bit more of an official backing from the Rust team?
Woah, that's a tremendous accomplishment! I remember when we just started talking about this at the end of last year. You really managed to push this well into the realms of "no longer just an obscure niche thing" in less than a year :) I can't wait to see what people build with this!
Here's a version I got to pass your tests. https://play.rust-lang.org/?gist=20e06f30fbd5208a79d49ff666407a32&amp;version=stable&amp;mode=debug&amp;edition=2015 You were returning `Some(())` from your function, so I had to fix that to return either `None` or `Some(acc)`. Then you get an `Option` back from `try_fold` so I converted that to an empty vector just to make it align with the rest of your code. Also marked `acc` as mutable so that it could be modified. I think you don't actually want `try_fold` here. You can do all your filtering in `filter_map` and not create the intermediate `Vec`. code.chars() .rev() .filter_map(|c| if c.is_numeric() || c == ' ' { c.to_digit(10) } else { None } ) .collect();
Hello dear Rustaceans, I am looking for a talk, probably from RustConf, where the presenter discussed how they handled content security policy messages with Rust. If you could find it (I had no luck), please drop me a link. Thanks!
Super glad to hear this, I've been getting fairly regular SEGFAULTs when opening a feed while refreshing.
Thanks ! I don't plan to add support for SPIR-V in a near future. But I'll add it to my list of ideas :) 
Thank you !
This is actually the approach I ended up with, as I couldn't reproduce the build failure using a [docs.rs](https://docs.rs) vagrant sandbox from master. Docs are now online at [https://redsift.github.io/rust/redbpf/doc/redbpf/](https://redsift.github.io/rust/redbpf/doc/redbpf/) . Thanks for the tip.
`trustme`
The difference with `let a = &amp;mut ...` and `let mut b = ...` is that `a` can only ever be a mutable reference, which would mean that "nothing" owns the data. The only other thing you can do is make an immutable reference from it. Meanwhile, with `b`, it's clearer that the current scope owns that `b` and can make and pass references however it wants, if at all. ```rust let a = &amp;mut SomeFancyStruct::new();``` Type of `a` is `&amp;mut SomeFancyStruct`. ```rust let mut b = SomeFancyStruct::new();``` Type of `b` is `SomeFancyStruct`, from which you can mutably OR immutably borrow.
Is it possible to use this without NodeJS? That's pretty much the most important reason that's keeping me from using wasm. At least being able to use this without webpack would be *absolutely fantastic*.
Might have originated from https://wiki.mozilla.org/Oxidation.
Long term, `stdweb` is intended to be more idiomatic Rust API around `web-sys`: https://github.com/rustwasm/team/issues/226#issuecomment-418475778
There was a discussion about this [here](https://github.com/rustwasm/team/issues/226) and hopefully it answers any questions you might have about the relationship between the projects.
I checked your site and the UI looks pretty neat. If I had one remark, it was not clear to me whether code-folding is supported. When working on complex pieces of code, I like to use code folding to hide the irrelevant portions of the code so I can squeeze the relevant parts in as little screens as possible (hopefully one, to see all the code without scrolling).
For now you can refresh -- I'll whip up a patch to add the ability to turn it off again. Sorry!
See https://github.com/rustwasm/team/issues/226.
I'm not sure about this, take what I say with a grain of salt. I think that web-sys does more - it exposes pretty much *all* the web APIs, not just *a whole suite of* them. Also, it compiles to WebAssembly, not JS. Again - I may very well be wrong, feel free to correct me...
Congratulations! But I have a question: I know close to nothing about disassemblers - would I be able to use such a tool to compile rust code to assembly? Because a google search said disassemblers convert high-level code to assembly.
`web-sys` is specifically for the Web so it won't ever really work with Node.js, and it doesn't even really make sense since the Web APIs don't exist in Node.js. You can, however, use `js-sys` (ECMAScript APIs) just fine on Node.js since those APIs exist in every JS environment. It is possible that there could be a `node-sys` crate at some point that provides bindings to Node.js-specific APIs. Regarding webpack: you can tell wasm-bindgen/wasm-pack to target common js modules instead of ES modules, and it should work with Node.js's defaults.
How is it you have the `servo` flair? Is it something moderators can add?
Mostly unrelated but.. I'd like to work an a small, self-hosted feed reader with a web interface and maybe pluggable front-ends (like `mpd`). But I don't really do web, and I'm only learning the language. Is there anyone else around these parts who's just starting with Rust and maybe a tiny bit of front-end experience? Would you consider working on something like this?
&gt;`web-sys` is specifically for the Web so it won't ever really work with Node.js, and it doesn't even really make sense since the Web APIs don't exist in Node.js. Noo - that's not what I meant, what I meant is to be able to use the wasm files in a webpage without using webpack, which requires NodeJS. Your second answer seems to answer that. So, if I compile to common js modules, will I be able to use the result wasm files with a rust framework like rocket or a python framework like Flask?
Cross-post from https://www.reddit.com/r/rust/comments/9j2702/newsboat_is_rewriting_from_c_to_rust/e6ol6yg/ --- I'd like to work an a small, self-hosted feed reader with a web interface and maybe pluggable front-ends (like `mpd`). But I don't really do web, and I'm only learning the language. Is there anyone else around these parts who's just starting with Rust and maybe a tiny bit of front-end experience? Would you consider working on something like this?
Thanks! That discussion thread clarified things completely for me. And thank you to /u/bspeice and /u/WellMakeItSomehow who responded with the same thread at nearly the same time.
so is there a reason I would ever want to do let a = &amp;mut ...?
That's perfect, actually. Let's go back in timeâ€¦
I had a use case where it worked out great. Python webgame server that does collision detection between many objects. Try as I could, the python collision detection code was too slow due to Interpreter costs. I moved the collision detection to a quadtree implementation in Rust and it worked great. Was about 50x faster and solved the bottleneck.
I just ran into an amusing series of those problems while trying write a driver. First I picked an i2c sensor, and needed to use the fork with [i2c support](https://github.com/japaric/stm32f103xx-hal/pull/50). Then I switched to a UART interface, but found there was [no way to recover](https://github.com/japaric/stm32f103xx-hal/issues/62) from an overrun error. Next I tried to just read an analog output from the sensor, but the embedded-hal has [no API](https://github.com/rust-embedded/embedded-hal/issues/10) for that yet. Finally I gave up and used only GPIOs for a different project, but neither input pullups nor [open drain outputs](https://github.com/japaric/stm32f103xx-hal/pull/51) were supported - but I was able to use [burrbull's fork](https://github.com/burrbull/stm32f103xx-hal) to make it work. I hope there's a way we can help out with that work. 
Terrible marketing. Nobody wants to write `unsafe` code. *Everybody* wants to write `brave` code. "Hold my beerâ€¦"
As someone with ~30 years of experience with C/C++ syntax, whenever I spend time writing Rust code, and then I go *back* to C/C++ code, I hate my life. Overall, I really enjoy Rust's syntax. It's clean and consistent, and it makes working with the type system easy and obvious. Unlike C++, where you have to apply 30 rules to understand what a one-line statement even *means*. About `const`. `const` means it's a compile-time constant, which is *not* the same thing as an immutable `let` binding. Totally different animals. In C/C++, `const` means something different -- and it does *not* mean compile-time constant, which is something the language didn't even have until recently (when it got `constexpr`). The syntax around `const` vs. `let` vs. `let mut` is, to me, nearly ideal. And `static` means something different, again. It is a `variable` binding that has global scope, which is *not* the same thing as `const`! `&amp;foo` gives a unique address when `foo` is a static declaration. `&amp;foo` is not guaranteed to give a unique address for a `const` declaration. `begin` and `end` are terrible, and should go away. Curly braces serve the purpose, here. Why type 5 or 3 characters, when you can type 1? Also, go-to-matching-character in editors would break if we switched to `begin` and `end`. Bad idea. There's a *reason* that semi-colons are required, except as the last statement of a value-oriented compound statement. Semi-colons separate statements in Rust. Without the semi-colon, it would be difficult to know when a statement ended. (And we're *not* going to go the Python route of using newlines to terminate statements.) But you need to be able to distinguish a statement that completes with no result value from a statement whose value is intended to be used. When you think of semicolon as *separating* statements and not *terminating* statements, then the value semantics of compound statements such as `if` and `loop` make a lot more sense. I like `i32` and `f32`. I have to type these things all day long, I'm happy that I can type 3 characters rather than 5 or 7. Clear and concise. Your statement about lifetime syntax (`'a` and such) is confusing. I don't understand what you're asking for. 
Not really. As mentioned elsewhere, it is more idiomatic to use `let mut` and then borrow from that, just so that it's clear what your code is doing. On the other hand, if you're absolutely certain that you *only* need a mutable reference to pass somewhere, then there's nothing wrong with an inline borrow. For me personally, if I read someone else's code and see `let a = ...`, then the first thing my brain assumes is "`a` is immutable"... until I read further, that is.
Fantastic. I use newsbeuter and wondered if it was dead.
I think I found an explanation that supports yours: https://www.reddit.com/r/rust/comments/6q4xq9/let_mut_x_vs_let_x_mut/dkuw0zg/
The All Hands? Hah! WASM was old news by then! I'm talking abouht the time around JS Kongress 2017 when Jan-Erik and I wrote [this stuff](https://github.com/killercup/wasm-experiments/commit/2a5d4fc1faf5ec9758a8ae918c2d6425753076c3)!
Hm ok, then you weren't talking to me, since I wasn't there, and I'm pretty sure we didn't have WebIDL codegen plans back then ;-p
Hi, you might want to share that over on /r/playrust.
heh I also just wrote a very similar crate https://crates.io/crates/keymatrix that take a slightly different approach (mainly I don't treat each input as separate)
By the way, there's a super-good reason to have `struct` and `impl` be separate. Your `struct` definition should have the *fewest* number of constraints that are necessary, on type parameters. Then your `impl` blocks can specify the type constraints that are necessary for those associated functions. For example: struct Point&lt;T&gt; { x: T, y: T } This generic type defines a Point, but it doesn't impose any constraints on the type. `T` is not even required to be `Clone` or `Copy`! Then, in your `impl` blocks, you can specify the requirements that you have: impl&lt;T: Clone + Copy + std::ops::Add&lt;T, Output=T + std::ops::Mul&lt;T, Output=T&gt;&gt; { pub fn new(x: T, y: T) -&gt; Point&lt;T&gt; { ... } pub fn dot(&amp;self, other: &amp;Point&lt;T&gt;) -&gt; T { self.x * other.x + self.y * other.y } } Maybe this isn't a great example, because you could just as easily specify those type constraints on each associated function. But I find it easier to group together related associated functions into a single `impl` block, where that block specifies the type constraints that are needed by that group of functions. Also, you can put `impl` blocks for a single type in multiple files (modules), so long as they're in the same crate. These give you a lot of flexibility in how you organize your code. I also really, *really* like the separation of data structures from algorithms. *Also*, you can write an `impl` block for *any* type defined in your crate, not just structs. For example: enum Thing { Foo(i32), Bar(String) } impl Thing { pub fn do_something(&amp;self) -&gt; fmt::Result&lt;String&gt; { match self { Thing::Foo(x) =&gt; format!("hey, it's a foo {}", x)?, Thing::Bar(s) =&gt; format!("oh, check it out, a bar {}", s)? } Ok(()) } } `impl` blocks can be applied to `struct`, `enum`, etc. type definitions. 
Glad for you! I never argued that this approach won't work, merely that it won't be easy (esp. packaging). May I still ask why did you skip all the approaches popular in Pythonland (C extensions, Cython, numba, opencl...) and went straight for Rust?
I think it might be worth looking into the possibility of using a `Cell` over a `RefCell`. Having `yield` return a value would be ideal, but `Cell` might be more performant over a `RefCell` in the short term. It would need to be benchmarked though.
Arguably having dependencies use unsafe is worse than your library using unsafe in this case. For a crypto library, I would expect all uses of unsafe to be carefully audited, and it seems harder to do that for dependencies. Maybe a statement about which dependencies you are using use unsafe, and why you trust them.
website says: \&gt; We do not have access to the payment processing and so we don't keep any sensitive informations. This should be: \&gt; We do not have access to payment processing so we don't keep any sensitive information.
Aha no i don't think it should be possible to turn it off, it's too cool to ever stop ðŸ˜ðŸ˜Ž
Assembling is taking assembly and making machine code out of it. Disassembly does the reverse. This is basically to inspect a binary file to see what it does.
The `Geolocation` interface doesn't have an exposed interface object; that is, its constructor and prototype are not visible unless you already have an instance and can reflect on its prototype chain. Right now, our code generator skips these interfaces because it isn't 100% clear how to generate bindings to them. I've filed https://github.com/rustwasm/wasm-bindgen/issues/893 to track support.
If you look at the source for web_sys you will see a big list of webidl files. All the bindings are generated from there, and the webidl files come from the Firefox source code. If you search there for the api you want, if it's there that means it's not being generated yet (I'd be surprised if every webidl feature is working in the first release). If not it means it's not part of Firefox webidl. Also worth noting that every feature has to be manually enabled, since enabling everything by default takes generates 100000+ lines of code and then compiles it, taking about 5 mins on my (quite performant) computer ðŸ˜.
the Song Of Rust is neverending!
Woah, that was fast, it feels like the announcement of the [`js-sys`](https://rustwasm.github.io/2018/07/26/announcing-the-js-sys-crate.html) crate was yesterday! Congrats to the team! Also, you talk about [the host binding proposal](https://github.com/WebAssembly/host-bindings/blob/master/proposals/host-bindings/Overview.md), what's the status? It looks like there is no activity since 8 months. Does the discussion happens elsewhere? 
A great project that I enjoyed hacking on. I highly recommend new contributors get involved, understanding the code base teaches you loads about ASTs and compiling from one language to another. Also the people involved are nice, and *extremely* clever.
That's an easy one: I would remove the long compile times. I would remove at least 90% of them. 
Alright, so how soon until I can write react-like components *and* do Node-less server side rendering, all in Rust?
Question that I'm unable to find any help on: When I try to use the futures 0.3 (preview) version, when I run `cargo +nightly build`, Rust tells me `error[E0432]: unresolved import \`core::pin::PinMut\`.` I installed `nightly-x86_64-pc-windows-msvc`, ran rustup update, but I still get the error. Any ideas?
You can do `cargo web deploy` without Node.js. 
Just the other refactors to the stdlib because they caused some performance regressions. The type itself will remain available.
(In Java/Kotlin, you can have member functions of enums as well as classes, it's just a not-obvious-without-knowing syntax to switch from case mode to method mode. And sealed classes in Kotlin, the equivalent sum type, are definitely able to have members as they are regular (data) classes.) And this is where I express the dissenting opinion. The `struct` definition _should_ be minimally constrained, that I agree with. But I disagree with the conventional wisdom (don't constrain it unless a member type requires it); instead, I prefer to constrain the struct based on the _minimal intersection_ of impl bounds. If you have `struct Vec2&lt;T&gt;(T, T);` but only `&lt;T: Math&gt; fn Vec&lt;T&gt;::new(T, T);`, and no other way of constructing a `Vec2`, you don't have any reason to have a `Vec&lt;T&gt; where T: ?Math`. You can't construct it nor do anything with it. (For the derivable traits, though, I _fully_ agree, they shouldn't be part of the requirements unless they're part of the identity of your type. The derives add the necessary bounds as necessary (or they're bugged).) I disagree with the stdlib here. We have `struct HashMap&lt;K, V, S&gt;`, but the only ways of creating a `HashMap` have `&lt;K: Eq + Hash, V, S: BuildHasher&gt;`. In fact, the only (not auto trait) impl that _doesn't_ have those bounds is `impl Clone`. If I have a `HashMap&lt;K, V, S&gt;` in my struct, the only way I can derive `Debug`, `(Partial)Eq`, or `Default` is to bound `K` and `S`. A `HashMap` cannot exist let alone have meaning without these bounds. I would argue that this means that the type should have had these bounds intrinsic to the structure itself rather than just its impl blocks. The never type makes things a _little_ more complicated, but the intent is for it to satisfy most traits anyway. (All that it can trivially and soundly fulfill, as you can't call a method on it.) Other than that, though, I fully agree.
Thank you!
&gt; * Idiomatic Rust is faster than (un)idiomatic C. See Bryan Cantrill's blog post, specifically item 9: &gt; my naive Rust was ~32% faster than my carefully implemented C In *that specific* case. I wouldn't generalize that statement, at all.
can someone explain what packed\_simd is exactly? how does it relate to stdsimd? &amp;#x200B;
How come performance regressed?
It seems that https://rustwasm.github.io/wasm-bindgen/exbuild/webaudio/ does not work in Safari in Mac. It works in Firefox though.
Your Manager struct requires its type parameter to implement Component, but `Box&lt;dyn Component&gt;` doesn't itself implement Component. You can either leave the Manager as is and do `impl Component for Box&lt;T&gt; where T: Component`, or you can change the struct to require a different parameter.
Great suggestion, I've changed the implementation to use a `Cell` and this are the results: ``` # RefCell (old) test tests::bench_large_normal ... bench: 1,317,526 ns/iter (+/- 318,654) test tests::bench_large_rec ... bench: 4,295,042 ns/iter (+/- 110,120) test tests::bench_medium_normal ... bench: 73,901 ns/iter (+/- 6,572) test tests::bench_medium_rec ... bench: 206,235 ns/iter (+/- 31,714) test tests::bench_small_normal ... bench: 724 ns/iter (+/- 28) test tests::bench_small_rec ... bench: 2,437 ns/iter (+/- 134) # Cell (new) test tests::bench_large_normal ... bench: 1,318,512 ns/iter (+/- 273,401) test tests::bench_large_rec ... bench: 4,178,556 ns/iter (+/- 359,039) test tests::bench_medium_normal ... bench: 72,942 ns/iter (+/- 8,474) test tests::bench_medium_rec ... bench: 188,996 ns/iter (+/- 4,249) test tests::bench_small_normal ... bench: 687 ns/iter (+/- 17) test tests::bench_small_rec ... bench: 2,270 ns/iter (+/- 91) ``` There is a small speedup but it seems that the `RefCell` borrow checking is not the main bottleneck as I first thought. It could be that the non-locality of the `RefCell`/`Cell` has a big effect on the speed. Or the generator state matching on resume, or the compiler better optimizes the regular recursion... I think I really need to profile it and not just wildly guess :)
Oh cool! Yours looks a little more general purpose and extendable. I like the built-in debouncing. Also GenericArray is a good crate to think about in these situations...
Node? Pshuh! You should be using [Vanilla.js](http://vanilla-js.com/).
Arguably yes. On the other side I think it's also good to use other libraries, those that have been around for a little while longer, been used by other projects and have received more testing. Interesting idea, where would you have such a comparison listed? I assume not in the README directly. An addition to the post?
That's unfortunately a browser-only framework.
&gt; instead, I prefer to constrain the struct based on the minimal intersection of impl bounds. Yes, agreed. I was only pointing out that the constraints on data *can* be different from the constraints on algorithms. In many languages, especially C / C++ / Java / C#, these two are so entangled that it's hard to see that they can be independent. 
My guess is that they're going to investigate that by swapping `mem::uninitialized()` for `MaybeUninit` incrementally instead of doing it all at once.
This looks cool! I'm also writing a cross platform gui app, but didn't want to learn web tech. Gtk+ works.... ok. Sometimes documentation was tricky, and it's kinda verbose, but it works ok. What was you experience learning react and using electron specifically like?
Yes, [dm the moderators](https://reddit.com/message/compose?to=/r/rust) to set your flair.
So, \`EntityManager\` manages multiple Component storages, each storage is a generic storage that stores a hashmap of exactly any one type that implements \`Component\` with the key being a string.
My goto project for trying any new language is writing a cli calculator. Start simple with just parsing `1+1`, then add support for parentheses like in `1+(1+1)`, then add more operations like `1*1`, maybe add functions next such as `sin(1+1)`, add constants like `pi` and `e`, etc, etc, etc. Before you know it you have basically implemented lambda calculus inside the language.
&gt; compile rust code to assembly rustc --emit=asm yourfile.rs or for a cargo project: cargo rustc -- --emit=asm
Probably some misoptimization by LLVM, possibly due to `MaybeUninit` presenting different aliasing characteristics by its nature of being a union rather than producing a `T` out of the void but then allowing it to be used normal.
This is pretty cool. &amp;#x200B; Any thoughts on why this is using GPLv3+ rather than something more library-friendly like LGPLv3 or Apache2?
true, but numba is hardly the good choice for anything. I have repeated experienced longer develop time (read: time wasted on) for numba functions then similar functions if I just did it in cython or c python. The main problem is the horrible debugging. At least in c you know exactly what you are doing and the compiler gives you useful information.
Oh did that change? I thought host bindings was a way *around* the GC stuff...
stdweb has wasm-unknown-emscripten and wasm-unknown-unknown for quite some time as well.
You need to be able to talk about GC'd things: for example, if you want to append one DOM node as a child to another, you need to have a way to reference those ndoes.
Why does \`Box\` need to implement the trait?
Yep!
The definition of Manager is: ``` struct Manager&lt;Comp: Component&gt; where Comp: Component, {...} ``` You are trying to get a value of: ``` Manager&lt;Box&lt;dyn Component&gt;&gt; ``` The `Comp` type parameter maps to `Box&lt;dyn Component&gt;`. You require that `Comp` implements `Component`; therefore, because you want a `Manager` where `Comp` is a `Box&lt;dyn Component&gt;`, you require that `Box&lt;dyn Component&gt;` implements `Component`, which it doesn't.
Cool cool, thanks :)
The byteorder crate can help with this, if you don't mind taking the dependency.
Could it be that its linux only?
Nope, I build my stuff on Debian stable (with a more recent Rust added to it) and the version of node which ships with Debian stable is too old to run webpacker last I checked. Currently I use Ruby's Sprockets to build my assets.
Yep. I make a note of that in the readme.
The documentation is also tricky if you use relm as has you have to switch back and forth between the relm and the gtk-rs documentation and you have to know what you'll find where, but I found it in general more comfortable for a small simple GUI.
On the contrary, regarding packaging, I actually found it exceptionally easy to build the extension in Rust. Build it as a dynlib, put the .so file in your project, done. I'd never written a Python extension before, and yet I had the entire quadtree working in Python within about 8 hours. I used this project: r/https://github.com/PyO3/pyo3 To answer your questions: C extension: Why would I write C when I could write Rust? I would much rather write Rust than C any day. Cython: I looked into it and read the documentation, and found it overly complex and ugly in how it worked. It was difficult to set up the build pipeline. It also didn't have the bare-metal performance I wanted. Numba: Hadn't heard of it. Opencl: Not doing any parallel computing here due to architecture constraints. 
As far as I understand it *is* stdsimd. More precisely the code that was for a while available in Nightly under `std::simd` has moved to https://crates.io/crates/packed_simd, and will likely move back once itâ€™s more stable.
Maybe the `ðŸŽˆðŸŽ‰ ... ðŸŽ‰ðŸŽˆ` decoration should be omitted for point `1.x.nonzero` releases, as reason such releases typically happen because of something bad?
I'm not familiar with web dev, so what does that mean? 
`key.push_back(KeyPosition::Body(item.clone()));` that one is definitely unnecessary because it's the last usage of that item.
Scala?
Just a side comment... &gt;Nobody wants to write 'unsafe' code This common phrase above gives the wrong sense of what the code actually does. Everyone should ask themselves, what you think of when you read this phrase? Does the rust definition of unsafe comes to mind? or does it trigger an idea that the code is completely dangerous and should not be used. (If that's the case then I should mention that unsafe is in the compiler...hmmmm).
The idea of using actual rustdoc for the show notes is *amazing*. I love it!
How can I add a i64 to a u64? I'm working on implementing a spec that starts with an initial value, and then keeps using offsets. 
I will try. I'm noticing howver that when using godbolt the asm output with the problematic code is "correct". Maybe this is a issue that is present only on Windows targetting 32bit msvc as me (It's a code replacer for a game that override the failsafe path when the game search for a voicefile, but found nothing, and it's a 32bit game TES4:Oblivion , so I can't actually test on other platforms). &amp;#x200B; By the way what are the meaning of these =\*m, +\*m , \*m that you used? I found very little documantation. &amp;#x200B; P.S I have a deep and partially irrational hate of AT&amp;T syntax.
[Since several months already](https://github.com/DenisKolodin/yew). It uses stdweb instead of web-sys, but they're pretty similar. There may be other react-like libraries out there, I haven't looked.
WebAsesembly is a technology that lets you run Rust code in the browser. These releases give rust bindings to browser and JavaScript APIs, which are pretty important for building real things.
I would have hoped that it can support \`Deref\` for the inheriting chain before this is published. Needing to cast stuff is the most annoying part to me for using web-sys currently, and requiring that for upcasting seems to be completely unnecessary.
`=` means output, `+` means input/output, and `*m` means indirect memory operand. You can find [more info in the documentation](https://llvm.org/docs/LangRef.html#indirect-inputs-and-outputs)
GTK is cross platform.
`Index` isn't sugar for `Deref`; the indexing *operation* is sugar for calling the `index` method of some value (which requires it to implement the `Index` trait) and then dereferencing the result. Not every `Index` implementer is able to implement `Deref`, and only collection-like `Deref` implementers can implement `Index`.
Actually, `stack_vec[index]` is syntactic sugar for `stack_vec.deref().index(index)` - anything in-between is just half-desugaring: https://play.rust-lang.org/?gist=fdbd12b81732106da58892a52c3efd3a&amp;version=stable&amp;mode=debug&amp;edition=2015 In Rust, all operators (except assignment) are actually traits from `std::ops` - `Deref` is the `*` operator and `Index` is the `[]` operator. So `*stack_vec` dereferences to a slice - but that slice itself implements `Index`. So `Index` is needed for slices to work, whether you deref to them or just have them directly. Without `Index`, only builtin types could have the `[]` operator - so [`VecDeque`](https://doc.rust-lang.org/std/collections/vec_deque/struct.VecDeque.html), for example, couldn't have `[]` and you would have to access its elements using an explicit methods. `VecDeque` can't use `Deref` to its internal buffer, because it uses a cyclic buffer and needs to process the index to get the correct ordering (also - the used part of that buffer may not be continuous).
Thank you!
Bug - bad. Team proactively fixed it - good! Never miss an opportunity to celebrate! ðŸŽ‰ðŸŽˆ
The question is whether you think your API is good enough to warrant a 1.0.0 release. It may be complete in your vision, but you may not have predicted all the patterns and use cases that your users might want to use. Once you make the 1.0.0 release, there's no going back, besides soon after moving to 2.0.0.
That looks like exactly what I wanted, and not dependent on nightly either! Thanks for the suggestion.
Fixed.
I would have hoped that it can support \`Deref\` for the inheriting chain before this is published. Needing to cast stuff is the most annoying part to me for using web-sys currently, and requiring that for upcasting seems to be completely unnecessary.
Thing is, depending on the package, this is kind of a good thing. When I see an X.Y.Z go to X+1.0.0, I know the API changed. When I see a 0.Y.Z go to 0.Y+1.0, I don't actually know. That could be new features, or it could be breaking changes. To me, semver isn't a promise. If I install 1.6.5, I may have no idea whether the next release will be 2.0.0, 1.6.6, or 1.7.0. It could be buggy and flawed and the next version is 2.0 and much better and completely breaks the API. The only promise is that it won't be either of the latter two with breaking changes. By choosing to stick with 0.Y.Z, you're doing two things: 1. being shy and humble by telling the users it's not really public, and 2. getting rid of *the most important signal* you can give to your developers, which is whether upgrading will break their application. I kind of feel as though no public, published repository (say, on crates.io) should be a 0 version. Maybe even emit a warning or something (no, this is not practical given the state of the ecosystem at the moment).
And after compressing it with brotli, it looks like the wasm goes down to 38K ðŸ™Œ
[There is a way around re-export hell](https://github.com/dtolnay/semver-trick) but I wish it was more obvious
I *can* use NodeJS, I *do* have it on my system. But, when making a website, not everybody *uses* NodeJS; there are many other good languages which you can use as well - take Rust for example. There is rocket, yew, and all these things that I could use for my website, but if I need to use webpack, I'm stuck with NodeJS. Not just that, I can't use NodeJS *without* webpack and get away with it (if it's necessary), I have to use *webpack and NodeJS*.
You're looking for /r/playrust, which is about the game Rust, while /r/rust is about the [programming language Rust](https://www.rust-lang.org/en-US/).
While most of that is correct, using "the payment processing" rather than "payment processing" is more correct in my eyes. "We do not have access to payment processing" sounds like it's saying "Something about our situation means we cannot enter into business with payment processing services". "We do not have access to **the** payment processing" sounds like "Processing your payment happens beyond our reach".
Refusing to use node tools is like refusing to use Python tools. Doesn't make much sense to me
You can't pass a closure that will take both arguments of type `i64` and `i32`; those are two different closure types. You could pass values as trait objects, but then you wouldn't be able to guarantee that the output of the closure is the same concrete type as the input. You need some way of expressing that `apply` is able to operate on different types; so your best bet would probably to create a trait: ``` trait NatBinExpr { fn apply&lt;T: TMath&gt;(&amp;T, &amp;T) -&gt; T; } ``` ...and take that as an argument: ``` fn bin_op&lt;F&gt;(apply: F, x: &amp;Scalar, y: &amp;Scalar) -&gt; Scalar { ... } ``` However, given your definition of `TMath`, you can't do this, because the `Add` method doesn't return the same type as its input, but whatever associated type you want. You'd need to either specify more concretely that `TMath` is a trait that has an `add(T, T) -&gt; T` function (+ a `mul` function and whatever else you want), or make the NatBinExpr trait explicitly handle each type in your Scalar.
I liked this very much for getting into the nitty gritty of lifetimes: http://cglab.ca/~abeinges/blah/too-many-lists/book/
On that note would you also be willing to add RISC-V to the list of ideas?
Aka literally the reason for server. I'm guilty, at times, but 0.x.y is a copout - "I don't want to stabilize my API". Own it. Have a user study. Open an Issue threatening 1.0 and see what happens... Etc...
Hmm. I don't really see the problem here. The Node ecosystem of JS tooling is built to be pluggable with all sorts of things. The Closure Compiler doesn't run on Node, but you can use it in a Gulp task or a Webpack plugin or whatever just as if it were. The same is true of Cargo and whatever scripts your framework wants you to run to build for it. When developing something for the Web, I always prefer to use a Node-based build system to keep my directories in line and the responsibilities of the various tools involved clear, even if those tools aren't actually JS-based. It's just sort of _what you do_ as far as I'm concerned. And if you really wanted to, you could probably do it the other way around and tell Cargo how to run Webpack as part of your build process. Are Rocket and Yew really hairy enough to preclude this sort of cooperation between the ecosystems?
&gt; Build it, include the .so file in your project, done. This is not even packaging! Packaging is 'automate building from a source checkout to installable packages', that is, for python, from .py/.pyx to pypi-ready .whl's for different platforms. What you did was merely 'making it work on your PC'. As for a writeup on other methods: thanks, I got why you skipped them, but let me comment on your comments: &gt; C extension: Why would I write C when I can write Rust? I'm much happier writing Rust over C any day. It's a phenomenally inefficient way, but it was a historical default and I couldn't omit it in such a list. &gt; Cython: I spent a few hours reading the docs and found it overly complex &amp; ugly. It was hard setting up the build pipeline for it as well. Oh yeah, packaging Cython is quite bad. Using pbr helps somewhat, but still. &gt; It also wasn't close enough to the bare-metal performance I wanted. You probably missed a type hint or something, annotated code is your friend. But yeah, I have to agree, Cython is complex and a few hours are quite a short time to fight it for the first time and win. &gt; Numba: Hadn't heard of it. And that's quite a pity, because Numba's interface is slapping a decorator on top of a Python function. A day and night compared to Cython's entry barrier. &gt; â€‹OpenCl: Not doing any parallel processing here. It can output single-threaded CPU code as well.
This looks like an LLVM bug. It's ignoring the `[]` around the address and is instead generating a direct jump. If you use AT&amp;T syntax instead, it should work: asm!( r" cmpw $$0, _GeneralSubtitle je NoChange1 jmp JumpBack1 NoChange1: .byte 0x80, 0x3D, 0x08, 0x32, 0xB1, 0x00, 0x00 JumpBack1: movw $$0, _DialogSubtitle movw $$0, _GeneralSubtitle jmp *_GeneralSubtitleHookRetnAddr " : : : : "volatile" ); _GeneralSubtitleHookRetnAddr itself is probably correct; it's just that IDA is interpreting those bytes as code instead of data because _GeneralSubtitlesHook jumped to it, so you get some nonsensical instructions. (You can force it to interpret as data by pressing the D key.)
i like this post. 
Ideally the impact is lessened because there are fewer using 1.0 crates as the ecosystem matures. e.g. I used `failure` in prototypes and applications but once a prototype has matured, I've removed the dependency from my API.
I don't understand that example. Why bother using it if you're just going to remove it?
You can use `as` with integral types: let ival: i64 = 32; let uval: u64 = 10; let total = uval + ival as u64; Note that this will just silently overflow if you were to cast a variable with a negative value as a `u64`.
&gt;In my experience query string has some optional params and therefore should not be the part of route matching &amp;#x200B; I understood this crate was more about reducing boilerplate than just routing. I see you POV though. &amp;#x200B;
&gt; 0.x.y can change the api as much as it likes, it makes no guarantees. You can't know from the version number whether you can safely upgrade. *This is not true*. Every leading zero just pushes the "major" version down. 0.2.(x+1) is compatible with 0.2.x, but not 0.1.y.
Thats cool &amp;#x200B;
At a glance it looks like you're cloning things when you need to store a copy of them. Nothing wrong with that. Profile and see if it's a performance problem.
Even better would simply be "Transactions are handled by a third party and we don't store any sensitive information." Even though the application's target audience is engineers the people paying for it usually aren't.
&gt;I choose Electron (it might disappoints some of you ?) and React to make my user interface. Use the right tool for the job. If Electron made you more productive and helped you deliver faster then there's nothing wrong with that.
If its a breaking change shouldnt it be a major release? I thought that was the whole point of semver
I think most project should just have a clear definition for 1.0.0 beforehand ie. a list of usecases, other requirements and a statement saying that once the API can satisfy these, 1.0.0 will be released.
For those who are not familiar: semver does not specify how this works before 0.1.0, but this is the convention in Rust which cargo assumes. See https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html for reference.
I don't know if this helps but I've come to enjoy [global_asm!](https://doc.rust-lang.org/nightly/unstable-book/language-features/global-asm.html) for my declspec(naked) needs. It also avoids any unnecessary codegen and gives you complete control over the function. Further you can actually have 'global asm' in stable Rust: #[link_section = ".text"] static MY_CODE: [u8; X] = [/* paste output raw assembled bytes here */]; Then reinterpret a pointer to MY_CODE as an unsafe fn and call it :)
I haven't taken a look yet, but let me guess: the right way is ml-ish comments: (* hello (* it is nested *) voila *) Am I guessed?
I believe wasm-bindgen is using [https://github.com/serde-rs/serde](https://github.com/serde-rs/serde) to clone them.
After thinking what you need to do here, I feel like adding lifetime bound on `self` is not enough. The point is: are you going to disasm lazily or eargly? I was assumed later. but in your case it seems the former. If you disasm eargly, mutably borrowed shall not be a problem, because the resulting `Instructions` shall only need immutable reference to execute, if my assumption on that all mutable access finish within `disasm_all` is correct. However, if you disasm lazily, your resulting iterator will need access not just to `self`, but also the bytes to disasm. So you need lifetime for those bytes as well. Because reference lifetimes are covariant, you can simply assign the same `'a` to the bytes. This would not be enough to solve the mutable problem though. I would try to look at your code and make it working without unnecessary lifetimes. 
I think 1.0.0 should only be released when there is some confidence that the API is somehow stable. If for example I see a crate with1.0.0, 2.0.0 and 3.0.0 released in quick succession, I see them exactly like I would see 0.1.0, 0.2.0 and 0.3.0: 2.0.0 is incompatible with the latest version and no longer maintained, just like 0.2.0.
Of course but if the code isnâ€™t performance critical you shouldnâ€™t spend too much time prematurely optimizing.
A major blocker for me right now is depending on unstable compiler/core features. `const fn` in particular should allow stabilizing many of my crates.
Unfortunately that won't work if ival is negative: total = 10u64 + (-32i64) as u64; will panic in debug builds because u64 overflow. In fact this is something I've come to miss in Rust, mixing unsigned and signed integer arithmetic where it makes sense (such as here).
https://play.rust-lang.org/?gist=fdc9c0206069e4ab9e0faf76326dd7aa&amp;version=stable&amp;mode=debug&amp;edition=2015 I was able to remove a few
I would suggest not just reading those libraries, but also try to change them. If you have some bug or enhancement you'd like for yourself, then scratch that itch. Otherwise, see if they have an existing issue that you think you understand at least a little, and then dig into it.
IMO, a package's semver is primarily a communication tool for doing _upgrades_, and not that interesting otherwise. I publish 1.0 as soon as something's "usable" enough for the one or two use cases I initially set out to satisfy. integers are cheap; you can do a lot of major releases before running out, and 2.0 (or 17.0 for that matter) is not that big a deal.
I just noticed my `~/.rustup/toolchains` directory is 1.6Gb. Is that normal or is there older installations still stored? is there a way to clean them if so?
1.0.0 indicates some degree of production readiness, even if your library has some no liability license that's not going to stop someone bitching on Reddit or GitHub issues when production has gone down based off a bug in your code causes their systems to go down. Most people want to have the protection of "it's in active development, shit can break'
Wrong subreddit buddy.
This is the subreddit for Rust, the programming language. You want to visit /r/playrust for Rust, the game.
Nope
Came to say exactly this. Thank you :)
What are the more informative signals you look for?
There is *nothing* wrong with immediately releasing another major version. At all. The alternative of not indicating this in version number and staying at 0.x is far worse for the consumer. Where I work we have a simple test for libraries being &gt;=1.0: is anyone using it. If they are it far better to communicate breaking changes in the version number rather than stay at 0.x forever. 
To address a point that's been made a bit too often for my taste: &gt; It is no problem to release 2.0 shortly after 1.0 But actually, it is. You're going to lose users with every breaking release because, as you could read in the comments here as well, keeping up with the releases is busywork. Chances are people don't care enough about your crate to invest the time. I have the impression that the breaking-change-happy amongst you are missing one half of the API stability thing, and that would be the promise that the API *stays this way* for a while.
This is not always good advice. Bad architecture can make optimization down the road much harder.
I think publishing it already implies some degree of production readiness.
I think folks should release Release Candidates for their 1.0.0 versions. This way they can gather input on the public API in a good way, and let folks know that this 1.0.0 is happening soon and now is the time to test it and let the author know of any mistakes and oddities. If you don't join the RC testing and feedback loop, then you forfeit your right to get annoyed in case 1.0.0 breaks something or misses some features.
Been wondering about the same. Now I've been rewriting my program and I'm trying to keep the `clone` calls to a minimum. `to_owned` has been popping up quite much lately though, not sure if that is good or bad.
`use taint::Clean;` at the start of the example works for me fine with your example code. Not sure why it's failing for youâ€¦
I Do Advent of Code atm and it really teaches you how to write things and use crates for your purpose. Give it a try, it is amazing! 
This is all I get when I try to add the `use` failures: ---- src\taint.rs - taint::Clean&lt;T&gt;::map (line 19) stdout ---- error[E0432]: unresolved import `taint` --&gt; src\taint.rs:20:5 | 3 | use taint::Clean; | ^^^^^ Maybe a missing `extern crate taint;`? thread 'src\taint.rs - taint::Clean&lt;T&gt;::map (line 19)' panicked at 'couldn't compile the test', librustdoc\test.rs:332:13 note: Run with `RUST_BACKTRACE=1` for a backtrace.
... for some definition of cross platform.
If I understood your problem correctly this code should work: fn bin_op&lt;T&gt;(op: impl FnOnce(T, T) -&gt; T, a: T, b: T) -&gt; T { op(a, b) } let r1 = bin_op(Add::add, 1i32, 2i32); let r2 = bin_op(Add::add, 1f32, 2.5f32);
It's the empty default one. I haven't added anything to it for this project. Only the standard name, version, and authors field is filled out
Ah of course, I should have picked a better negative number: [playground](https://play.rust-lang.org/?gist=a7793772fdc1d52d5df30966cfa855df&amp;version=stable&amp;mode=debug&amp;edition=2015) let total = 10u64 + (-5i64) as u64; This is a compile time error in const evaluation, if you extract them to variables and do the same you get a runtime panic.
I haven't modified my toml file yet. It's just the default
&gt; In case of async, isn't that type `()` for both? Nope, it's `&amp;'a LocalWaker` (where the generator bound needs to be `for&lt;'a&gt;`). &gt; but not for the generators, because now they need to handle the first value specially. That's a consequence of the syntax you've chosen, not the trait API. Using the same trait and `unzip_collect` implementation from your second example, but the syntax for generator arguments that was in the original PR (a `gen arg` key-phrase to refer to the resumption argument) you can write `foo` like this: ```rust /// [(a1, b1), (a2, b2), ...] -&gt; (a1+a2+a3+..., b1*b2*b3*...) fn foo(pairs: impl Iterator&lt;Item = (u32, u32)&gt;) -&gt; (u32, u32) { unzip_collect(pairs, || { let mut sum = 0; while let Some(n) = gen arg { sum += n; yield; } sum }, || { let mut prod = 1; while let Some(n) = gen arg { prod *= n; yield; } prod }) } ```
Anyway, bedtime. &lt;http://gitlab.com/BartMassey/taint&gt; has example code that passes the doctest for me.
Oh yeah, you're right. I named my library something else. Thanks!
Unless I'm unaware of something, the Rust ecosystem uses [SemVer](https://semver.org/) which places no constraints on 0.x releases: &gt; 4 . Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable. The key here is that 0.x for initial development ie you don't expect anyone to be using it. If that's truly the case then it's fine. The issue comes around when there *are* people using your library. Now you have consumers, the empathetic action is to start communicating breaking changes to them by going 1.0 and incrementing the major version. Sure, you can "hide the churn" in 0.x, but the **churn is still there** and has real effects on your real users. Just they don't have immediate visibility into it. Eventually there will be stability as development settles down. This is the point where people will start to expect long term support and it will be shown by you getting to `major.&lt;large minor&gt;.patch` such as `5.89.0` or so. Few people will really care about the early major increments at this stage, but your early users will thank you for being explicit about it.
&gt; This is not true. Every leading zero just pushes the "major" version down. 0.2.(x+1) is compatible with 0.2.x, but not 0.1.y. ***This is blatantly not true.*** Every leading zero is explicitly invalid as per semver, `A normal version number MUST take the form X.Y.Z where X, Y, and Z are non-negative integers, and MUST NOT contain leading zeroes.` and as per semver &gt; Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable. Read the [spec](https://semver.org/). It exists for a reason.
Why not? Because the prototype might not eventually mature? 
&gt; In the Rust ecosystem, 0.x to 0.y does indicate a breaking change. It is the same as 1.x.y to 2.x.y. So, you're saying, despite what every single source on rust claims, we are *not* using semantic versioning, but rather doing the very thing it sets out to prevent. To quote semver "Why Use Semantic Versioning?", &gt; This is not a new or revolutionary idea. In fact, you probably do something close to this already. The problem is that â€œcloseâ€ isnâ€™t good enough. Without compliance to some sort of formal specification, version numbers are essentially useless for dependency management. Kind of defeats the purpose here dontcha think? And all justto move the version number to the right a bit for no reason because 1.0 is evil or something, but it turns out having the stability guarantee that is the entire point of 1.0 is useful, but we can't *actually* use 1.0 because EVILLL, or something. If true, then rust needs to stop lying about semver. Semver is very clear on what 0.x.y means.
Wow! THANKS &lt;3 Well, no, I think I need it and I'll explain: if !c.is\_numeric() &amp;&amp; c != ' ' I should return false from my is\_valid function! I can now avoid the first for cycle and just use this try\_fold because now, thanks to the .unwrap\_or\_else(Vec::new) if there's an error the Vec will have len() &lt; 2 so my function will return false... Even if it's not so clear... &amp;#x200B; Or I should return interrupt the concatenation and return false directly there...
Yes, code-folding is something I have already started to implement but haven't finish yet. It will be available in a next release. Thanks !
In that case i fail to see how not being 1.0 changes anything. People still use the crate, and it will still have breaking releases, you just won't know about it because the version number is lying.
I like it, and [nobody has lied](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#caret-requirements). Otherwise, I don't see much point in continuing the bombastic style of discussion that you seem keen on having.
&gt; ***This is blatantly not true***. Every leading zero is explicitly invalid as per semver [...] # This is even more super blatantly totally not true with sugar on top. To quote [Cargo's documentation on the subject](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html): &gt; This compatibility convention is different from SemVer in the way it treats versions before 1.0.0. While SemVer says there is no compatibility before 1.0.0, Cargo considers 0.x.y to be compatible with 0.x.z, where y â‰¥ z and x &gt; 0. That spec is irrelevant, because it's not what Cargo uses.
Surprisingly enough, this is already how we develop Pijul! Indeed, nothing in our license prevents you from using Git to prepare your patches before sending them to the Nest! Obviously, since I started Pijul with the goal of making something easier to use, more flexible and sound than Git, I prefer to use Pijul to prepare my patches, but feel free to contribute in any way you want (including setting up a mirror on GitHub). More seriously, given that many people have been able to contribute using Pijul and the Nest, I wonder whether this is a serious blocker or just trolling. Also, if you prefer Git anyway, why would you want to contribute to Pijul? If you don't use Pijul, what sort of contributions could you make? What bugs would you discover? What features would you miss? These are not rethorical questions, btw.
Just because cargo says it lies doesn't make it not a lie. Since apparently you need it explained, here is how it is a lie. 1. Rust claims to use semantic versioning. 2. Rust has changed it's version numbers in a way explicitly counter to semantic versioning. 3. Rust is therefore not using semantic versioning. 4. Rust is therefore lying.
Yes, we use semver, but with the tweak I mentioned. It's in the docs and other commenters have mentioned it in this thread: https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#caret-requirements I basically just don't agree with anything you said. I'm not looking to hide any churn. I'm saying that churn is a negative quality, and that saying folks can just release new major versions all the time is actually problematic in many cases, and we shouldn't pretend otherwise. At least in my own style, I do try to use 1.0 as a signal that I don't expect there to be any remaining frequent churn. If others want to employ a different style then that's great, but I see absolutely zero reason to change what I'm doing and what I perceive that others do as well.
This style of discussion isn't welcome here. Please stop it.
If by "this style of discussion" you mean highlighting the facts, then no. Those are the facts. Semantic Versioning is a standard and has a spec that must be followed. Claiming otherwise is disingenuous. If something says it is doing X, but intentionally doesn't do X and actually does Y instead, that is the *very definition* of a lie. Rust says it uses semantic versioning. You've pointed out that Rust *says* it's using Semantic Versioning, but intentionally doesn't actually follow the spec and does it's own Rust Versioning instead, which is similar to Semantic Versioning but with different requirements.
&gt; Resolve references to extern crate root in paths without extern crate item for 2018 edition ðŸŽ‰ðŸŽ‰ðŸŽ‰
The spec *is* irrelevant because Cargo is consciously not following it. Thus, it doesn't matter what the spec says, because Cargo isn't doing that. You can absolutely make the case that Cargo should either follow the spec or stop saying it uses semver, or maybe clarify that it uses "modified semver" or something. But I'm 90% certain that it will continue to work in the way it currently does, making arguing about this kinda pointless.
I didn't understand, what does this language have, that Rust doesn't?
Please do not use personal attacks like "since obviously you need it explained". 
But you openly state "BREAKING CHANGES POSSIBLE AT EVERY TURN", and users may proceed at their own risk. The version number is not lying, because the *entire point of 0.x* is to be able to iterate quickly without looking back. The reason for libcpocalypse and what have you is not pre-1.0 software but the fact that people decided to build an entire ecosystem on top of stuff that screams "DO NOT USE IN PRODUCTION". Give it time, an ecosystem cannot grow overnight.
&gt; When Skip's type system can prove the absence of side effects at a given function boundary, developers can opt-in to safely memoizing that computation, with the runtime ensuring that previously cached values are invalidated when underlying data changes. Interesting.
The docs state, that rust uses semver compatible versioning that differs from the semver specs.
Thats kind of my point. If people are depending on the public api, it should be 1.0. That or they shouldnt be using it. There shouldnt be anything wrong with then releasing 2.0 if need be, as the comment i was replying to states. In the case of "You're going to lose users with every breaking release", people still use pre-1.0 crates all the time and don't seem to care about the breaking releases.
[No it doesnt.](https://doc.rust-lang.org/cargo/reference/manifest.html#the-version-field) &gt; Cargo bakes in the concept of [Semantic Versioning](http://semver.org/), so make sure you follow some basic rules: It explicitly claims to follow Semantic Versioning, and links to the spec. And then goes on to contradict itself by saying it follows semver, and that major version zero anything goes, except if you make breaking changes? &gt; Before you reach 1.0.0, anything goes, but if you make breaking changes, increment the minor version. In Rust, breaking changes include adding fields to structs or variants to enums. Which is both contradictory and a violation of the spec.
&gt; If people are depending on the public api, it should be 1.0. Wrong way around. If it is not 1.0, people shouldn't be depending on the public APIâ€”except for exploratory/testing purposes maybe. &gt; people still use pre-1.0 crates all the time and don't seem to care about the breaking releases Those are not the people you lose. You probably haven't even *gotten* them to begin with, because if you tell them you have an ecosystem made out of pre-release software, they'll just leave.
&gt; Cargo bakes in the concept of [Semantic Versioning](http://semver.org/) It says it follows the concept and not it follows the spec. [This](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html) documentation is better in my opinion.
Move statement up/down is a gamechanger. Not having this and coming from using IntelliJ with Java was frustrating! 
Long story short: I think people are scared of having to go to 2.0, and this is what makes them scared from making the step to 1.0. However, don't. I see two scenarios: 1. You only have a few users, and are scared someone finds a missing feature that only can be added in a backwards-incompatible way. No problem! Those few users can easily change over to 2.0, because they are only few. 2. You have many users already. Now, the chance of someone finding something that means a backwards-incompatible change is a lot lower, so there also is no reason to be scared of going to 1.0.
No don't get me wrong. I was trying to suggest something since you seemed like you were open to contributions and some well behaved people had the same concern as the misbehaving person. Unfortunately I am not even in a position to contribute right now so I wasn't asking from that perspective. It's a great tool and you're doing a great job. Good luck .
What does squatting in this sense mean, please? 
All I/O in Rust is *synchronous* by default so if you call `fs::copy()` it won't return until the copy is complete. Similarly, you don't have to set a timeout, you can just suspend the thread with `thread::sleep()`: use std::time::Duration; use std::thread; // this will block until the time has elapsed thread::sleep(Duration::from_secs(3)); 
Thanks for talking about this! And good luck getting better :)
Reserving names without the intention of using it, maybe even selling it, would be my guess. 
Thank you :) 
&gt; Apologies if I came off as too perscriptive, at the end of the day it is up to you to decide how you want to work. I just wanted to share my experience with dealing with the "uncommunicated breaking changes in 0.x" at my work, where we have 100s of libraries across nearly 1000 devs and it is a huge problem. Your experience may vary. Gotya. Yes. Uncommunicated breaking changes _suck_. That we can agree on. :-) It's just critical to recognize that 0.x -&gt; 0.y in the Rust ecosystem is not an uncommunicated breaking change, and this is enforced by our tooling and interpretation of version numbers. &gt; do feel a little sad that SemVer was supposed to be unifying standard but is now fragmenting (everyone seems to tweak it). I guess I might agree that it's sad in the most abstract sense of the world, I don't really think that we should just follow some spec if it has obvious downsides or can be improved upon. In particular, the semver spec is _quite_ vague, so there is no real way to follow it in one particular way that everyone agrees on. Firstly, semver says that _anything_ goes in 0.x versions. "anything goes" includes a more restrictive policy. Any given project can adopt semver and say, "instead of our 0.x -&gt; 0.y releases being meaningless, we're going to say that they communicate this additional thing because it's useful and for $reasons we don't want to hit 1.0 yet." Secondly, semver doesn't---and really can't---actually specify what exactly a "breaking change" actually is. Reality is messy, and everyone is going to have their own idea of what constitutes a breaking change. Leaving this up to interpretation practically _guarantees_ that everyone will have their own interpretation of semver. It seems like a feature to me, not a bug. In the Rust ecosystem, at least for the standard library, we have our own notions of "acceptable breakage" where a change is _technically_ breaking, but we don't consider it a breaking change with respect to semver. Most other languages have similar policies. Even the most conservative among them have allowances for making breaking changes in response to exploits, if necessary. semver says nothing about what to do in the case of exploits, but if you read the semver FAQ, IMO at least, the answer is pretty clearly "use your best judgment" (based on the answers to other questions). The [FAQ discusses churn as well](https://semver.org/#if-even-the-tiniest-backwards-incompatible-changes-to-the-public-api-require-a-major-version-bump-wont-i-end-up-at-version-4200-very-rapidly): &gt;&gt; If even the tiniest backwards incompatible changes to the public API require a major version bump, wonâ€™t I end up at version 42.0.0 very rapidly? &gt; &gt; This is a question of responsible development and foresight. Incompatible changes should not be introduced lightly to software that has a lot of dependent code. The cost that must be incurred to upgrade can be significant. Having to bump major versions to release incompatible changes means youâ€™ll think through the impact of your changes, and evaluate the cost/benefit ratio involved. So that's what we all do. We use our best judgment. There ain't no one single specification that's going to change that. semver is one of many ways to manage complexity, but it is not incidental. It is manifest in a large decentralized ecosystem of folks building software in an uncoordinated manner. Things get messy at the edges.
This was brought up on the forums [16 days ago](https://users.rust-lang.org/t/placeholder-crates/20345), linking to when this was brought up [a year and a half ago](https://users.rust-lang.org/t/should-people-be-allowed-to-reserve-crate-names/8360), plus a [discussion from April](https://users.rust-lang.org/t/bus-factor-1-for-crates/17046), which doesn't count all [the](https://www.reddit.com/r/rust/comments/9dole9/proposal_crate_squatting_on_cratesio/) [numerous](https://www.reddit.com/r/rust/comments/86yr2x/python_pep_regarding_package_names_abandoned/) [other](https://www.reddit.com/r/rust/comments/6u52po/name_squating_on_cratesio/) [times](https://www.reddit.com/r/rust/comments/6j0g9o/squatting/) it's come up on Reddit. Search is your friend.
I am working on a prototype compiler/interpreter for a research language. It's going alright, but I'm not really sure if there are good libraries I should be making use of. At the moment I've written everything from scratch. Lexer (no regexes), recursive-descent/pratt parser, bytecode generation, bytecode interpreter. It's been a fun learning exercise though.
Many in the community disagree with the official policy (it's come up regularly here and on other forums). However, the policy will probably only change after someone starts mass-registering crates with random names in a much larger scale.
Looking at the method \`\`\`rust fn disasm&lt;'a&gt;(&amp;'a mut self, code: &amp;'a \[u8\], addr: u64, count: usize) -&gt; CsResult&lt;Instructions&lt;'a&gt;&gt; { let mut ptr: \*mut cs\_insn = unsafe { mem::zeroed() }; let insn\_count = unsafe { cs\_disasm( self.csh(), code.as\_ptr(), code.len() as usize, addr, count as usize, &amp;mut ptr, ) }; if insn\_count == 0 { match self.error\_result() { Ok(\_) =&gt; Ok(Instructions::new\_empty()), Err(err) =&gt; Err(err), } } else { Ok(unsafe { Instructions::from\_raw\_parts(ptr, insn\_count) }) } } \`\`\` I didn't see a reason why \`self\` have to be \`mut\`. After all, the only use of \`self\` is \`self.csh()\` and \`error\_result\`. They all only need immutable reference. So a quick fix would be to remove the \`mut\` from \`disasm\` methods?
It's a good question. It's hard to answer concisely because it's super nuanced! I'll do my best to give a first approximation. Basically, I think the strength of a signal is directly tied to how well it predicts the value add of a library. A version number has almost no signal there; I use plenty of 0.1 crates that add lots of value, but I also use plenty of 1.x or even 2.x crates that also add a lot of value. This is in part because there is no unifying consensus opinion on _when_ to migrate from 0.x to 1.0, in part because folks have different styles and in part because there may be mitigating concerns (e.g., the reason that libc is at 0.2 and not 1.0). The value add is of course also going to be subjective to the particular problem you're working on. For example, if you're working in an embedded system, you'll probably have a different ranking of signals than someone like me, who does not work with embedded systems. So roughly speaking, the signals I look for: 1. How many other people are using the library? There is safety in numbers. The maintenance burden of any problems that may arise in that library is probably fairly distributed, or at least, problems will be detected very quickly. Moreover, because of its wide use, it probably has _fewer_ problems. This principle doesn't just apply to numbers. I just bought a Camry, for example. Why? In part, because everyone else has one too. 2. Documentation quality. If it doesn't exist, then I probably need to go read the code. When it does exist, and it's high quality, I've almost universally found that to be a very strong predictor of the quality of the implementation itself. For example, take a look at the docs for [`signal-hook`](https://docs.rs/signal-hook/0.1.5/signal_hook/). It's a 0.1 library, but I have zero problems using it. The documentation clearly indicates that the topic has been thoroughly researched. At that point, if I need the advertised functionality, I'm pretty sure it's going to be a good value add. _Someone else did the thinking for me, and I'm pretty confident that I couldn't have done it better._ 3. Issue tracker, commits, CI. If a library isn't widely used, then it's useful to know what its maintenance schedule is like. Library authors (starting with me) should document what the maintenance status is, but for some reason (again, pointing the finger squarely at me first) this is hard to do. So I look for other signals like the issue tracker, recent commits, PRs, whether CI is setup, etc. No one thing can really be used to unambiguously determine the maintenance status, but if you look at everything, you can probably get an idea. Maintenance status isn't just about trying to determine whether someone else will fix your problems for you, but whether if _you_ fix a problem and submit a PR, will that actually get merged into a new crates.io release in a reasonable time frame? If not, you're now spending more time just dealing with unmaintained dependencies. That might still be worth it! But it impacts the value-add. 4. Number of dependencies. When I pick a dependency to rely on, I can't just follow the steps above for that one crate, especially if it isn't widely used. I also need to go and look at all of its transitive dependencies as well. Bugs aren't just going to appear in your direct dependencies; they'll appear in other places too. So your ability to fix problems in your dependencies is not just a function of your direct dependencies, but a function of _all_ dependencies. That's where I start, anyway. There's a long tail of other things that cross my mind, but they tend to be more situation specific. I think the really awesome thing about the Rust ecosystem is that there are actually lots of choices that hit all of my above points! That's a really strong indicator of the health of the ecosystem IMO. I can actually afford to have high standards.
I'm not sure, what is special about Skiplang. The documentation suggested it had some sort of borrow checking, but the following code compiles. mutable class Nasty(mutable x: String) { readonly fun capture_this(): readonly Nasty { this } } fun main(): void { mnasty = mutable Nasty("a"); immutable_nasty = mnasty.capture_this(); mnasty.!x = "b"; // changes immutable_nasty!!! print_raw(immutable_nasty.x) } It's possible however I don't understand the language however.
What would be missing from rust to do this today with a function attribute? Wasn't there a function purity proposal at one point?
The correct way would be let total = (uval as i64 + ival) as u64; or (if you care about the one bit) let total = if ival &gt;= 0 { uval + (ival as u64) } else { uval - (-ival as u64) };
You can probably do this with `const fn`s which are required to be pure.
A garbage collector. Not like you'd want one, though
What? The language can optimize (pre compute or cache) functions cals without side effects? Is that what they are saying? Isn't that something every modern compiled language, including rust, does?
While Cargo's docs could be a bit more clear about how it only follows a variation of semver instead of following the spec literally, I think almost *every* package system uses this variation. I know npm does it, and npm is by most metrics the largest package index in the world. It's well worth reading these 3 comments from the author of node-semver, the library that controls how npm interprets version numbers: [1](https://github.com/semver/semver/issues/221#issuecomment-54862988), [2](https://github.com/semver/semver/issues/221#issuecomment-56202038) and [3](https://github.com/semver/semver/issues/221#issuecomment-56129144)). But sentence that summarizes the whole thing is this one: &gt; **If the spec is intended to be descriptive here, it is incorrect; if the spec is intended to be prescriptive, then it is failing.** But really, read all 3 comments if you're still unconvinced that semver is wrong, not cargo or npm. The meaning that the vast majority of programmers ascribe to version `0.x.y` is `0.MAJOR.MINOR`, not `0.MAJOR.MAJOR`. The spec saying otherwise has been - and will continue to be - very ineffective at changing that. We should just change the spec.
I didn't notice this but it is in fact amazing. Thanks for calling it out.
Wow, this is bad. There should be an option to report crates &amp; users... Correct me if such an option already exists
But say I had a package at version 0.5.7 that hasn't had any breaking changes in a while, won't have any in the near future, and could reasonably be considered "stable". Should I do a 1.0.0 release just for the sake of doing a 1.0.0 release, without there being any breaking changes? A major version bump without breaking changes feels wrong.
Will those [Promises](https://rustwasm.github.io/wasm-bindgen/api/js_sys/struct.Promise.html) interoperate with usual Rust futures and async/await?
At least there can be only one of those two characters for point releases, marking only half-hearted celebration.
Because there is an endless supply of titles for crates and you can't squat them all.
Yeah, I'm not sure. I feel kind of compelled to squat every name I possibly can and build a new (name-only) registry site to hand them out, with restrictions on the number of crates a user is allowed to register over a given period of time and heuristics to flag users that seem to be abusing the system. It seems pretty clear that `crates.io`'s policy currently allows this, so hopefully it would push them to alter their policy and release some of the crate names that are currently squatted. 
could there be a medium-long minimum character count with names, reserving short-medium names for community consensus on popular crates? squatting on long specific names would be ok
As as a Mac user I guess that if you install Rust via `rustup` there is not much difference?
It's 95% the same on all platforms. It really depends on what kind of program you want to write and how familiar you are with the os.
My crate is at 0.4 (with 0.5 in dev) and basically my attitude is that I'll call it 1.0 when it's ready and stable. Up until then I'll just bump version nrs in the 0.x range. That doesn't mean what I've written isn't usable, but it isn't a complete, minimum viable product by my own criteria. I think in general though avoiding 1.0 of commercial software is a good idea though. And things like phones, cars etc. Things with a lot of complex things going on where there is zero chance it went out error free.
I wasn't sure if it was specifically an osx issue but I had a problem with cargo install cargo-clone which I think was a Xcode induced linker error. 
I've not gotten started with Rust yet (there's a couple languages I'm looking into picking up), but I was wondering if there's a fairly straightforward way to build simple GUI's / 2D visualisations? Similar to something like this [double pendulum simulation](http://www.physicsandbox.com/projects/double-pendulum-sim.html). If not, is it perhaps possible to do the heavy lifting in rust and pipe that back to another program handling the interface?
Please write that sentence again without using any of the words you already used.
That is how I, and I think many other rust programmers, feel about this. But that's not what the semver spec says, which is why I think we need our own spec.
Better option: &gt; I feel kind of compelled to squat every name I possibly can do that and stop there. Creating a new registry on top of crates.io does not solve the problem. To prevent the problem, the crate names must be hierarchical so we can have both `swmon/bash`, `ar-pharazon/bash` and `KindaAgrees/bash` without cousin collisions. But that would not happen until the problem gets out of hand (via namesquatting every single name for example)
Just naming it \`immutable\_nasty\` doesn't make it immutable. You need to "freeze" it to make the object itself immutable. [http://www.skiplang.com/playground/#bXV0YWJsZSBjbGFzcyBOYXN0eShtdXRhYmxlIHg6IFN0cmluZykgewogIHJlYWRvbmx5IGZ1biBjYXB0dXJlX3RoaXMoKTogcmVhZG9ubHkgTmFzdHkgewogICAgdGhpcwogIH0KfQoKZnVuIG1haW4oKTogdm9pZCB7CiAgbW5hc3R5ID0gbXV0YWJsZSBOYXN0eSgiYSIpOwogIG90aGVyX3JlZl9uYXN0eSA9IG1uYXN0eS5jYXB0dXJlX3RoaXMoKTsKICBpbW11dGFibGVfbmFzdHkgPSBmcmVlemUob3RoZXJfcmVmX25hc3R5KTsKICBtbmFzdHkuIXggPSAiYiI7IC8vIHRyaWVzIHRvIGNoYW5nZSBpbW11dGFibGVfbmFzdHkgYnV0IGl0IGRvZXNuJ3QKICBwcmludF9yYXcoaW1tdXRhYmxlX25hc3R5LngpCn0=](http://www.skiplang.com/playground/#bXV0YWJsZSBjbGFzcyBOYXN0eShtdXRhYmxlIHg6IFN0cmluZykgewogIHJlYWRvbmx5IGZ1biBjYXB0dXJlX3RoaXMoKTogcmVhZG9ubHkgTmFzdHkgewogICAgdGhpcwogIH0KfQoKZnVuIG1haW4oKTogdm9pZCB7CiAgbW5hc3R5ID0gbXV0YWJsZSBOYXN0eSgiYSIpOwogIG90aGVyX3JlZl9uYXN0eSA9IG1uYXN0eS5jYXB0dXJlX3RoaXMoKTsKICBpbW11dGFibGVfbmFzdHkgPSBmcmVlemUob3RoZXJfcmVmX25hc3R5KTsKICBtbmFzdHkuIXggPSAiYiI7IC8vIHRyaWVzIHRvIGNoYW5nZSBpbW11dGFibGVfbmFzdHkgYnV0IGl0IGRvZXNuJ3QKICBwcmludF9yYXcoaW1tdXRhYmxlX25hc3R5LngpCn0=)
I have no experience with OSX, but there *is* one bit of advice I can give from researching my options for targeting it: If you want to target OSX or iOS, use OSX. People agree pretty consistently that cross-building toolchains for Apple platforms are incomplete. (eg. If I remember correctly, the signing tool is OSX-only and the most usable cross-building linker is buggy at best.)
Due to the package names having a limitless number it cannot come to be that none are left.\ That was fun :)
It's been discussed, and crates.io thinks that namespaces are not an improvement. I totally understand their argumentation and I think they have good points.
So, the first `gen arg` can be before the first yield - and then it'll immediately take the data moved by the first `resume` - or it can be after it and then `resume` will store that data somewhere and that `gen arg` will only be able to access it after the second `resume`?
&gt; Freezing will create an immutable clone of your mutable object, by recursively copying all its mutable fields. So it's like explicitly calling `.clone()` in Rust? Doesn't solve any particular issue, I feel like.
&gt;1. In the official spec, version `0.x.y` and `0.x.z` are considered not compatible. Wrong. It doesn't guarantee that they will be compatible, not guarantee that they're incompatible. There is a difference. &gt;2. The spec says that version `0.x.y` is for initial development only and is not considered stable. The spec's FAQ says that if it's used in production or depended on by others, it should be at version &gt;`1.0.0` already. But despite our past efforts to push crates to version `1.0.0`, we still have many stable, production-quality crates depended on by many people that are at version `0.x.y` (15 of the 20 most-downloaded crates on crates.io are version `0.x.y`). I fail to see how this is an issue with the specification and not the author(s). Or for that matter, the users that are aware of the potential issues and still opt to ignore them. &gt;If we make such a spec, the github RFC about it will presumably get a million comments, so I don't want to be the one who writes it. This tells me you can't defend your own arguments, in which case - why did you even write this, if you're not gonna do any of the work?
There was some discussion a while back about making the next version of the semver spec. It hasnâ€™t gone forward yet, but if it does, Iâ€™ll be involved. (I maintain the semver crate.) Cargo already does what the most popular implementations of semver actually do. Itâ€™s such a minor difference, and is actually compatible with the spec, so I think that deviating would be *more* harmful, not less.
Serde is only used if you explicitly choose to serialize and deserialize instead of working with handles. If we always serialized across the just and wasn't boundary then it wouldn't be compatible with the host bindings proposal and it would also be generally slower to boot. See https://rustwasm.github.io/wasm-bindgen/contributing/design/js-objects-in-rust.html for more details.