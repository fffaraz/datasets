There's a comparison paragraph, which lists may. May tries to do a similar thing, but differently. It wants to introduce a whole new async world and compete with tokio. Corona tries to extend tokio. Also, may migrates coroutines (stacks with potentially not-Send data on it) between threads. Which will just explode to the user's face sooner or later, unless the code is really trivial. Corona doesn't do the migration, avoiding the whole can of worms. Crates.io doesn't seem to list coio, so I don't really know.
Thanks for clarification! The thing is that I want to loop over the receiver (using futures-await) so unwrapping is not really an option. I think I need to use map_err().
Not much. I guess you could call it fibers, but as I understand it, fibers are kind of coroutines. To cite [wikipedia](https://en.wikipedia.org/wiki/Fiber_(computer_science)): &gt; Fibers describe essentially the same concept as coroutines. The distinction, if there is any, is that coroutines are a language-level construct, a form of control flow, while fibers are a systems-level construct, viewed as threads that happen to not run in parallel. Priority is contentious; fibers may be viewed as an implementation of coroutines,[1] or as a substrate on which to implement coroutines.[2] I guess it depends where you come from and what terminology you're used to.
Is there a difference between these two kind of iteration? let map = HashMap::new(); for (key, value) in &amp;map { ... } for (key, value) in map.iter() { ... }
Coroutine is the concept; whether it's stackful (fiber) or stackless (async/await) is a design choice.
This seems supercool! :)
Implementing impl From&lt;()&gt; for Error { fn from(_: ()) -&gt; Self { unreachable!() } } by hand did the trick!
Possibly dumb question, but: what's the motivation for this over threads and blocking I/O? (My impression was that the main motivation for async I/O was to minimize memory usage vs. threads; the drawback of this vs. other async I/O solutions is increased memory usage; ...hence the question.)
Async io's main purpose is to minimize context swirching. 
For multiplication [stabilization](https://github.com/rust-lang/rfcs/pull/2325) of SIMD should help, but what solutions do we have for carry flag, except of using inline assembly? AFAIK compiler is not smart enough to compile sequences of `overflowing_add`s into optimized `add`/`adc` assembly.
These are frameworks that make async io easier. Personally I think they add more complexity then remove.
Structopt is only sugar over clap. Thus your question should be asked to clap. As far as I know, that's not the case but there is an issue about such problematic. https://github.com/TeXitoi/structopt/issues/32
Huh, I hadn't realized it was blocked on impl work; I was under the impression that there were still unresolved questions and they hadn't experimented with it enough. Neat.
Didn't see the FAQ. That's not going to work, sorry. It's not about the wording, it's the fact that it's essentially a public domain license, which is ambiguous enough to prevent me from using it.
Cool! I've needed something like [before](https://github.com/killercup/rust-docstrings/blob/194540ea3c9df4292f82f627997d37e4840790b9/src/to_md.rs) :) Looks like it produces quite pretty Markdown, tool?
Coroutines yield directly to their caller. Fibers yield to whoever started the fiber.
I would say it's optimized to be close to the input, while being faithful to markdown: https://github.com/Byron/pulldown-cmark-to-cmark/blob/master/tests/fixtures/snapshots/stupicat-output Also I hope it will prove useful to a whole bunch of mdbook preprocessors, which right now mean quite some effort, still.
No, they are interchangeable. The first makes use of the fact that `&amp;HashMap&lt;..&gt;` implements `IntoIterator`, the second is just a method of `HashMap` that returns an iterator while immutably borrowing the map.
IANAL but as I understand it, public domain as a concept does not exist everywhere. Licenses like MIT retain copyright while granting use to others with very little restriction. Here's an example of Google saying that they don't allow WTFPL software: https://opensource.google.com/docs/thirdparty/licenses/#wtfpl-not-allowed
In Rust (and C), there is no way to specify that data is secret and shouldn't remain in a CPU register. Any confidentiality or constant-time guarantees are implementation-dependant. Period.
Do you find it not printing the proper help messages after upgrading to this pattern? The doc strings in particular no longer seem to get printed out as help text when runnings things like `--help`
Sounds like a pretty shallow and meaningless distinction.
BSD 0-clause is another option to consider. https://landley.net/toybox/license.html I will understand if you decide to retain the current license, but I'm hopeful that you can get what you want with a license that's accepted more broadly as well.
Hm, the new version has worse performance: LLVM 6 (nightly, 2018-02-11): real 5m21,779s user 18m15,224s sys 0m16,260s LLVM 4 (1.23 stable 766bd11c8 2018-01-01): real 4m57,585s user 11m37,152s sys 0m12,348s I'll stick to the old version for now, I hope the performance improves.
Years ago I was assigned a legacy C# project where every method looked something like this: public void Foo(/*...*/) { try { // ... do stuff ... } catch (Exception e) { throw new Exception("Exception in Foo", e); } } That was a real pain to work with, because: * If I ran the application without a debugger, I had to dig in the message box to find the root cause. (add to it the fact that it was PDAish device from before the age of smartphones and tablets, running Windows CE 5.0 - which is basically Windows XP but everything is tiny...) * If I ran it with a debugger, the debugger would stop on the `throw` statement in the top-most `try`...`catch` block, when all the context already got popped away. * With all the copy-pasting and refactoring, too often the text in the exception did not match the name of the function. To this very day I still can't understand **why** he did this. I can only assume he somehow got into his head that "_no exception should be left unhandled_" or some other similar best practice mantra. The problem with these mantras is that they "block" the easy and straightforward solution, claiming that it's "wrong" or "evil", but leave other solutions that are also easy but much more wrong. There is no known best practice that says "don't catch and rethrow everything in every single method" because it's so stupid that no one in their right mind will even think about it, so having to warn against it is like having to warn against eating Tide Pods. However, while manually propagating these exceptions is much more work than letting the stack unwinding propagate them, it still takes less cognitive work than figuring out which calls can throw what and how it should be handled. [In one of the comments in the forum thread](https://users.rust-lang.org/t/unwrap-in-libraries/15558/12), the OP suggested to replace an `unwrap()` with returning `None`. This is an easy solution, because the function signature is already an `Option`, but it's also a wrong solution because `None` indicates the end of the URL query - **not** a bug in Rust's standard library! But there is a mantra for "thou shalt not `panic!`" and there is not mantra for "thou shalt not return wrong result" (because it should be obvious), so returning `None` is more dogma-compliant than `unwrap()`ing. A "proper" solution would have been to change the return type from `Option&lt;Self::Item&gt;` to `Result&lt;Option&lt;Self::Item&gt;, BugInStandardLibrary&gt;` - but that would be a big change, much harder than returning `None`, so it's clearly an overkill if all you want to do is apply your mantra. Also, when you change the return type to indicate the possibility of a bug, forcing the caller to somehow handle it, it highlights the idea that you really should have `panic!`ed there, which kind of contradicts the mantra...
The lifecycle of a given value, the distinction between primitives and objects, recursion,...
The WTFPL exist explicitly because public domain is not a thing in Europe. That's a readable version of the CC0 without the guaranty clause. http://www.wtfpl.net/faq/ If someone doesn't what to use structopt because that's under the WTFPL, I don't care. You can relicence the software, thus just change it to use it if you want. This also allow structopt to be included in any project in the future without asking each contributors for relicensing. And that the final goal: to be included in clap, and even be included in any other thing.
Ok best of luck with the inclusion into clap. Thanks for listening.
This is a really interesting question that caused me to take a step back. Given by [the commit that introduced this], this question indicates a really interesting interaction with temporary values and lifetimes. I also started experimenting on [the playground] and it made me realize I know very little about what's going on in the `match` clause. If someone can outline a complete answer, I'd really appreciate it! [the commit that introduced this]: https://github.com/rust-lang/rust/commit/d3c831ba4a4 [the playground]: https://play.rust-lang.org/?gist=3e103c5eac005189947a868cd9ec5174&amp;version=stable
In what threat model are you afraid of data remaining in a CPU register? The threat model where someone owns the operating system and is able to read out your process registers? If someone has that kind of access to your computer you're basically screwed anyway. In any normal use of your computer the registers would be overwritten soon enough and if you're afraid of spilling registers to memory you're screwed anyway since you don't have any say in when the operating system decides to context switch your process. As for constant-time guarantees no modern compiler would replace something like ARX-operations with non-constant time operations. For high security uses the compiled assembly code would of course need to be verified, but that doesn't stop you from actually using a compiler.
I am the immortal Iron Rust.
Put the help message on the corresponding struct, it should work.
That distinction is pretty meaningful. With coroutines you have to mark every function that can block as `async` and call it with `await` (or use feature chaining). If you want to block somewhere down the call stack, you have to do it with the entire call chain, all the way up - otherwise you will block the reactor. With fibers, the library function that does the blocking can do the yielding, and the functions that call it do not need to be aware of it and do not need to change their signatures. That's a pretty big difference if you ask me!
Also see: - [tracker for 0.5 release](https://github.com/rust-lang-nursery/rand/issues/232) - [planning issues](https://github.com/dhardy/rand/issues)
Is that the performance of rustc or an output of rustc?
Ring uses rust code + c/assembly algorithms from BoringSSL which is a fork of OpenSSL which is a fork of SSLeay. - Apache2 or MIT: rings rust code. This combo is the standard license for rust code since the compiler uses it. The rationale is to have the patent grant of Apache2 and the GPL compatibility of MIT. - Google CLA: contributors to BoringSSL have to sign a Google CLA, I don't think this effects ring at all. - ISC: New code in BoringSSL. - SSLeay + OpenSSL: most of OpenSSL is dual licensed because of the fork. Both are BSD-style. - Intel: from `third_party/` OpenSSL includes code from Intel, I assume an optimized implementation of some algorithm for Intel processors. BSD-style + Intel endorsement disclaimer. - MIT: from `third_party/` OpenSSL includes code which is under MIT.
`match (&amp;left, &amp;right)` evaluates the `left` and `right` expressions, then immediately borrows the result. This pins the evaluation result, but does not give the *result* a name. `(left_val, right_val)` names the two borrowed *results*, not the expressions themselves. `if !(*left_val == *right_val)` peers into the evaluation results to compare for equality, and if that check fails, again uses those results for the panic. This way, evaluation of the source expressions only happens once, at the beginning of the block. It could be rewritten as { let (left_val, right_val): (&amp;LeftType, &amp;RightType) = (&amp;left, &amp;right); if !(*left_val == *right_val) { panic!() } } since that's essentially what the match becomes. With a single, universal, arm, there are no branches in the output other than "if neq panic"
It can't be rewritten like that. The use of `match` here is `let-in`-like, which Rust doesn't have (imperative `let` is different in its temporary lifetimes). Also see [my SO comment](https://stackoverflow.com/questions/48732263/why-is-rusts-assert-eq-implemented-this-way#comment84465322_48732525). 
Man SO does not make replies discoverable. Interesting, thanks!
[Well,](https://twitter.com/stephentyrone/status/947221117302984704)
That's an interesting and constructing reading. Thanks. You were lucky in your relicensing. My experience was much more painful https://github.com/rust-lang/rust/issues/14248 I doubt I'll have the courage do redo that again knowing that I've used this license because I can then relicense if I need. You may reopen https://github.com/kbknapp/clap-derive/issues/8
Are we not affected by annoying compiler optimisations, where (for example) the optimiser translates a mask operation to a branch? https://twitter.com/volatile_void/status/957899300322840576
https://github.com/zonyitoo/coio-rs From what it looks like coio is more or less the same thing like May.
Well this is weird...I can successfully add help messages to the examples in StructOpt, but if I copy paste that to a binary which uses structopt 0.2.0, the help messages don't show up. [Here's](https://github.com/TeXitoi/structopt/blob/master/examples/enum_tuple.rs) the example I copied, and [here's](https://github.com/bschwind/structopt-help-msg) a repo demonstrating the issue.
If you have a threat model where you can be hacked by an adversary and whatever you have been protecting for the past million cycles is much more important than whatever you're doing at the moment then by all means try to protect against that threat. I'd argue that it's game over for you at that point however. You use forward secrecy to protect past secrets, e.g. old connections that occurred before you were compromised. The difference between being compromised from time T and being compromised from time T-a couple of milliseconds is academical at best. But by all means, you know best what threat model applies to you.
The question is of course valid and you need to consider what you want to build. The only problem with threads is not memory, it's scheduler costs/context switches as well. If you start 10k threads, you'll get pretty bad performance. Having 10k stacks, each with 20 pages (as an example) is 800MB, so that probably isn't that big pain on a server. I'm not sure what your OS will do if you try starting 100k threads, but 8GB of memory for 100k coroutines still seems *possible*. Also, while Rust helps you writing multi-threaded code correctly, it only helps by saying â€žyou're doing it wrongâ€œ. You still need to do the locking correctly, accessing objects that are not `Send` needs special care, etc. But if threads solve your problem better, then why not.
You don't have to be compromised to be running a program that periodically peeks at the extension registers; you just have to be a multi-tenant machine.
You need some imbalance to balance out all that balance. Anyways, I'm in favor of any best practice that forces you to think and against any best practice that makes you blindly fulfill some criteria.
Yea, that's true now you say it. Probably symmetric crypto will be all right, because most of the time (if anything) we would only xor the key with the state. I'm wondering. Curve25519 not have a cswap operation, right? Isn't that one in danger for aggressive optimizations?
The save/restore ABI doesn't zero them, and afaik they're not even included in the ABI specs about save/restore
 /// Help message for Foo #[derive(Debug, StructOpt)] pub struct Foo { pub bar: Option&lt;String&gt;, } Does it fix your problem?
Thanks! I will take a closer look at this. Config-rs does a great work maybe there is a chance to integrate it with clap.
Sorry, I should have mentioned that in my previous post, but adding the docstring to the corresponding struct doesn't work, either.
OK thanks, I left a comment.
[llvm.uadd.with.overflow](https://llvm.org/docs/LangRef.html#llvm-uadd-with-overflow-intrinsics) for additions. For multiplications I believe that we need to zero-extend from i64 to i128 before the multiplication in LLVM. There was some discussion on the issue in [this RFC](https://github.com/rust-lang/rfcs/issues/521).
Thanks! So if I understand correctly: the memory overhead is greater than stackless coroutines but still substantially lower than threads, and also there's less context switching overhead. (Tbc I don't have any problem, just trying to understand the problem space better.)
whats the point for this if it only uses 1 thread? cant really use it for much. just sugar syntax for tokio?
Yeah, it ended up a bit on the long side, but there's just a lot to get through. I also didn't find a natural cutting point in the middle. If you find good places to cut or pause, please do let me know and I'll put those in the video description (and maybe even try highlighting them in some way). Part 2 will hopefully be a little shorter :)
I believe they're making the stackless vs stackful distinction. Which isn't really the difference, because there are stackful coroutines, but it's not meaningless either.
seems soundness problems with specialization get resolved, so pyo3 may compile on stable later this year.
You want /r/playrust
Then why'd you post to /r/rust, which is about the Rust Programming Language?
Calculation may take longer, that's why I use `call_fut` and don't want to block, waiting for the response, else nothing else could be handled.
Just spawn your future instead of wait, something like Arbiter::handle().spawn_fn(|| addr.call_fit(...); Ok(()));
It's not just operating systems you have to worry about, but also virtual machines and hypervisors; there was a [vulnerability in older versions of Xen](https://nvd.nist.gov/vuln/detail/CVE-2015-8555) which allowed guests to access information from each other.
If you donâ€™t know the difference between the call stack and the heap, then you donâ€™t really understand these things.
Hm, again, facing the very same problem as before, but maybe still doing it wrong? arbiter.spawn_fn(|| { supervisor.call_fut(IrcMessage::Private(message.to_string())).then(|res| { match res { Ok(Ok(Answer)) =&gt; println!("Got an answer, yeay!"), _ =&gt; println!("Nooooooooo") } }); Ok(())} );
I personally still have a bunch of [concerns](https://github.com/rust-lang/rust/issues/27779#issuecomment-358025344) with placement new and am considering a proposal to delete the whole feature to motivate a new design - the current design just doesn't seem sufficient.
Nice! I particularly admire decision to not try repeating Go mistakes and keep coroutines in the starting thread. Example looks pretty elegant too.
That's my point, I'm saying that in rust, you need to understand the difference, because by default everything is stack allocated
Not necessarily. You can configure the stack size of both threads and coroutines â€’ so you could fit into the same memory with threads (they'd still need some in-kernel accounting data, but this is probably small). Just, by default, the coroutine stack is smaller.
Then that further begs the question of why Rust lacks a `let ... in` construction.
Nice! Here's hoping. :)
You can run multiple independent tokios, each one in its own thread, with corona on top of each. It just doesn't balance the load for you. If your tasks are about the same size, it's fine. And you can start 2*numcpus threads to help balancing the load further, for example. Furthermore, if you have a heavy (sync) computation, you can run that one in futures-cpupool and one thread to do the IO might be enough.
Is there a reason why `let` and `match` behave differently with reference of temporaries? Is this an artificial constraint? // fails let x = String::from("hi").trim(); // works match String::from("hi").trim() { x =&gt; {} }
Statements break apart temporaries' lifetimes, and `let` is a statement. This was a pragmatic decision. See also [one of the old blog posts](http://smallcultfollowing.com/babysteps/blog/2014/01/09/rvalue-lifetimes-in-rust/) about temporaries.
Probably it'd be deemed too confusing given that the `let` *statement* form also exists.
NLL is specifically backwards-compatible because it doesn't change (syntactically-determined) `Drop` scopes of variables or temporaries, *at all*, only the "shapes" of borrow "scopes".
I'm not worried about dependency problems. I'm worried everybody will end up pointlessly needing to learn 4+ ways to do the same thing, because everybody will do it differently but end up maintaining each other's code.
This is great, thanks for sharing! Co-incidentally, I've been helping out on Rusoto a lot in the past weeks, and have started thinking about how we can improve our documentation (https://github.com/rusoto/rusoto/issues/904). You walking through the steps of integrating Rusoto and running into all these roadblocks doesn't seem like an entirely delightful process (apologies for that!), but it does provide a lot of great insight into what we need to work on and improve!
Youâ€™ve asserted that point, but you havenâ€™t really supported it. One can get things to compile by feeling around in the dark, adding a &amp; here &amp; there, without really thinking about it in rust, too. I know because Iâ€™ve done it myself. People exaggerate how difficult rust is, by a lot. 
I love criterion! Thank you for working on it. Memory stats would definitely be valuable, especially in combination with a quick-iteration mode so I can set up warnings when I regress on memory.
Yeah, but they'll never understand stack alloc b/c there's too much in the way, understanding stack alloc in C comes very quickly b/c that's basically all there is, no constructors, no funny iterators, no extra shit on top that's hard to comprehend how it works other than 'magic' 'Feeling around' and adding removing &amp; here and there isn't programming to an even beginner level in rust, if you're literally just adding in symbols without understanding - not only that, but that's not going to help when you can't understand why you're getting a stack overflow when allocating a massive object on the stack (which can't really happen in java, you're only reeeaaally gonna get a stack overflow with recursion)
Oh hey, this is neat! I created https://crates.io/crates/prettify-cmark a while back to serve a similar need :)
Well, you can implement it on Nightly using inline assembly, which is equivalent to "not possible" for those who target stable. Intrinsics stabilization could potentially remedy this situation. (see discussion above)
Thatâ€™s the sort of exaggeration I was speaking of. Kudos.
Although there are multiple ways to do the same thing, they all have varying levels of verbosity and performance. So they aren't true 1:1 Enforcement of The One True Way would have trade-offs that some may not want. Although they all have different trade-offs, they all *do* the same thing. So the end result is always the same and thus very few trade-offs in maintaining different versions, because knowledge of one directly translates to other versions.
Fixed in v0.2.1, a cargo update on your repo will make it working as expected
Almost forgot to mention, the code is open source on https://github.com/srijs/deps.rs if anyone is curious!
structopt is a wrapper around clap and thus essentially the same as clap proper. I thought the parent was commenting on the multiple ways to instantiate an instance of `clap::App` (including the clap official ways as well as structopt's way), not on having multiple arg parsing libs.
I'm not sure what the best way to split that file would be, but one way would be to move different related functions into sub-modules. Someone who knows more about what you're doing might be able to offer a better solution, but in the meantime, know that you can have multiple `impl X { }` blocks for the same struct, and those blocks can be in sub-modules of where the struct is defined.
This why I want `const fn` so bad!
~700 lines are not too large for a single file so long as they are all related. Separating files it meant to make things easier to maintain, twisting things too much to fit them into tiny files is just as bad as putting everything in a single 10k long file. Group related things together and separate unrelated things but don't worry too much about the length of files.
Sorry to e a bother, but could you explain what you mean by "primitives" in regards to crypto? I think I understand the concept, but I've not really found a way to validate my understanding.
Does it deal with collisions?
Double word multiplication, i.e. usize*usize -&gt; (usize, usize) and addition with carry. Both really simple in assembly, impossible in pure rust (last I checked) and doable in C with compiler extensions (__u128). Simple intrinsics for those operations would suffice, the more general solution is to add larger native types, e. g. u128, or something like udoublesize (horrible name). For efficient bignum implementation we need to use the largest native word size for each limb in the number, for now we canâ€™t do that (in an efficient way) in pure rust.
&gt; I'm someone who's quite interested in Jonathan Blow's work such as the programming language Jai he's working on to reduce friction and increase the joy of programming. Has that actually gone anywhere? &gt; I'm considering just skipping Rust for it as public release is likely to be this year or next year, but I'm seeing if I should try Rust again due to all the hype in the programming community. Things seems a lot less shitty since I last tried to get into Rust years ago. But you'll only know if you put in the effort yourself. Or you could just sit around making posts like these...
A cryptographic primitive is a building block used to create cryptosystems. AES(128/192/256) are cryptographic primitives, chacha20 is a cryptographic primitive and so on. TLS uses a bunch of cryptographic primitives, but isnâ€™t one.
Ok, it's EMI. But, what laws of physics govern electromagnetic effects? Quantum Electrodynamics, qed.
This is great advice, thanks! 
Ok thank you
This is pretty cool! The thing that actually stood out to me was the code: https://github.com/srijs/deps.rs/blob/master/src/server/mod.rs It looks real nice! And no web framework needed! This looks like a great example to learn from. :)
Don't be too afraid of asm. It's needed to prevent some timing attacks.
I've finally released the first version of tql. I hope you enjoy!
Ah got it, thanks. I was correct in my line of thinking.
Very cool! Looking forward to play with it as i as eagerly reading your posts on "What's everyone working on this week" every now and than. And the SQLite support makes this quite possible as i am planing to write a little toy touch typing trainer for myself. 
I'd also love to use structopt in a large open-source project my company is doing, but I can't because of WTFPL. I also agree with the lawyers on this. Even a dual-license would help a lot.
I was quoting the exact article provided to me to point out that it didnâ€™t say what was claimed. Whether or not itâ€™s a good source, itâ€™s the one the other guy chose.
&gt; Async io's main purpose is to minimize context swirching. Another major goal is to increase the maximum concurrency that can be supported by not requiring a full thread stack per active request/connection/whatever. In some cases, those stacks can be a lot of memory. It's common for stacks to be allocated 4 MiB of address space (+ another 4 KiB for a "guard page"). Some portion of that translates to actual physical memory usage. (To be precise: the pages of that which have actually been used (and not since explicitly released via `madvise(MADV_DONTNEED)` or similar). It can be hard to put a reliable number on this.) corona says it's stack-full coroutines, so it doesn't save this memory for the things you use it for. But it also says it's "possible to mix coroutine code with purely futures-based one on the same thread". So I imagine you could use purely futures-based stuff for idle HTTP keepalive connections, but corona for active requests. Then you don't have to provision so much memory for those idle connections.
The two advantages of `transmute` I can think of: - you can do it by-value, and end up with a value rather than reference if your result type isn't `Copy`. - there's a compile time guarantee that the sizes exactly match up
That's orthogonal. Both futures and generators panic when polled / resumed beyond completion (that's considered a programmer error) -- that's what I mean by panicky. This behavior can't be changed without changing the signature of poll / resume to take `self` instead of `&amp;mut self` but I think that would make the traits not object safe and unusable with e.g. tokio where you need boxed futures. &gt; (I already pinged you there, I don't know if you saw it.) I have no bandwith to look into futures / tokio-like event loop on microcontrollers at the moment so I have nothing useful to add to the discussion. Also it seems an expedite decision has already been made.
This is relevant to my interests. ðŸ™‚
This looks awesome! What are your thoughts in taking this a step further and turning it into a github bot? Its something I am interested in to simplify crate management (see my [rust2018 post](https://epage.github.io/blog/2018/01/crate-management/)) but (1) I'm not as familiar with and (2) I can't do everything myself :). Also, I'm considering making a `crates-ci` github org for consolidating work in that direction (see again my rust2018 post). Would you be interested in putting this under that umbrella?
This is great! I was actually considering taking a stab at something like this recently and you've taken that off my plate and done a much better job than I would. Thank you!
Do you plan on supporting sub-crates that live in the same repository? https://deps.rs/repo/github/ChariotEngine/Chariot is awesome in that it displays multiple result sets but there is only a single badge available.
I'm surprised that mdbook still doesn't allow you to manipulate the Events in a pipeline. My [PR](https://github.com/rust-lang-nursery/mdBook/pull/603/files#diff-39a3257f06953e2c30db410d804dac8a) just hooks into the render_markdown method. It should be relatively easy to have a list of closures that are `Event -&gt; Event` as an injection point, but not if there is plan to have multiple backends for markdown. I'm also surprised that pulldown-cmark doesn't have a `push_md` method like push_html
That sounds reasonable! Would you mind creating an issue on the deps.rs repo to track this?
Could you summarize how TQL compares to Diesel?
Why not Dropbox ?
It would be interesting to try this with an Amazon S3 backing store, though I'm not sure the S3 storage model would map well to a file system.
Done! https://github.com/srijs/deps.rs/issues/19
Spacemacs + layers/rust adds completion via RLS, colors, testing, compiling, and error highlighting.
Seconding @srijs's comments, this is great, thank you! I'm still working my way through the video, but already found plenty of spots we can improve with Rusoto's documentation. One thing I've just completed is removing the old, misleading gitbook that was found. https://rusoto.github.io/ now refers you to the up-to-date version at https://rusoto.org . I'm also seeing it's time for a versioning of our API docs. We're in the middle of going to hyper 0.11 and adding async support. This breaking API change is reflected in the published API docs but the published crates do not yet have this behavior. That's why the `Ec2::simple` call didn't work: it's only on the master branch. Looking forward to implementing changes to make things easier. :)
Here are some links from my collection: - https://zsiciarz.github.io/24daysofrust - http://rust-lang.github.io/book/second-edition - https://stevedonovan.github.io/rust-gentle-intro - GOTO 2017 â€¢ Why is Rust Successful? â€¢ Florian Gilcher https://youtu.be/-Tj8Q12DaEQ - https://rust-lang-nursery.github.io/rust-cookbook - http://stackoverflow.com/documentation/rust/topics - http://rustbyexample.com/ - https://learnxinyminutes.com/docs/rust/ - https://rosettacode.org/wiki/Category:Rust - exercises http://exercism.io/languages/rust/ ## Move In Swift, we have value types (Structs/Enums) and reference types (Classes). They are "on the same level" in the sense that, they are both fundamental types. In Rust, value types are fundamental, and reference types are secondary. They are not on the same level. There is not even any "class" in Rust. If you want a reference type, you must derive it from some underlying value type. We'll see how to do this once we cover the value types. - http://faq.sealedabstract.com/rust/#value-types - https://stackoverflow.com/questions/28800121/use-of-moved-values ## Patern matching - https://doc.rust-lang.org/book/second-edition/ch06-00-enums.html - https://doc.rust-lang.org/book/second-edition/ch18-03-pattern-syntax.html - http://xion.io/post/code/rust-patterns-ref.html ## Video courses - http://intorust.com/ - GOTO 2017 â€¢ Why is Rust Successful? â€¢ Florian Gilcher https://youtu.be/-Tj8Q12DaEQ 
The best place to start is the rust book. I also came from python to rust, and haven't really had to much of an issue. The rust book does a good job explaining a lot of things, but if you run into problems then YouTubeing that issue might help. For example I learn stuff better by hearing someone explain it rather than read about it. So when I ran into problems I YouTubed general ideas. Like what is a stack and how does it compare to the heap. ( Also I'm using second edition of the rust book)
This is exactly what I'm looking for! Diesel is too difficult to use.Thanks for your work!
Ring and problem with dependencies https://github.com/briansmith/ring/issues/535#issuecomment-309839961
I've been putting some time into a reddit API wrapper in rust called [orca](github.com/IntrepidPig/orca). It's the first programming project of mine to have someone else open an issue with it, which made me really happy and motivated to continue working on it.
Working on the second iteration (and mich improved) `barrel` SQL schema migrations crate. Also gonna think a bit about how to then allow integration of the behaviour into Diesel ðŸŽ‰
Hey you might want to look at my project https://github.com/spacekookie/barrel when it comes to migrations 
Possibly a dumb question: how would you set up a test suite for such a project? I wouldn't even know where to begin...
Doesn't dropbox keep all the files locally?
Heh, thatâ€™s funny, since writing such a bot was actually my reason for starting down the path of analyzing crate dependencies. I use greenkeeper.io for many of my Node.js projects, and I would love to have something similar for Rust! Building deps.rs is sort of the first milestone for that, since it hopefully helps in hardening the underlying engine, so that it can be used in a bot later. Thanks for the link to your post, I read through it and find myself aligned with quite a bit of it. If nothing else I might take a stab at implementing some of these ideas :)
My first snippet is intentionally serial as a baseline for discussion. `urls.for_each()` waits until the inner future finishes before yielding the next stream item, so two request features don't even get to exist at the same time. I'd like to know how to accomplish the other extreme: spamming the event loop with tasks. But I couldn't figure it out by looking at the API options.
Yeah, I saw that issue â€” I'm happy you found the video useful. `rusoto` definitely has some rough edges, but I don't blame it too much given the size of the API! Fixing some of the more obvious pain points (like all the `Option`s and the lack of strong error typing) would go a long way towards making the experience more pleasant. Some more elaborate (and easier to find) examples would be great too.
My xinput library will be available on stable as soon as 1.24 is out, so I'll put it up on crates.io then.
Oh, yeah, I realized `Ec2::simple` had to *either* be old or new, but didn't want to spend time tracking down which it was :) One thing I also found tricky was to easily get to the ec2 docs without Googling for them. My first instinct was to go to the docs for rusoto, but I didn't immediately spot them there. Then I went to https://rusoto.org/supported-aws-services.html, but nothing from there links to docs for rusoto_ec2 (it just links to crates.io). The documentation link from crates.io/crates/rusoto_ec2 link to https://rusoto.github.io/rusoto/rusoto_core/index.html, as does clicking "API Documentation" on rusoto.org (I don't know if that's the up to date documentation?). I eventually realized that `rusoto_ec2` was listed under "Crates" on the left-hand side of the `rusoto_core` docs, but that took me a *long* time!
In my experience, rust has an embarassment of riches for beginners when compared to c/c++. Also you'll be better served learning rust first since it forces you to do it the right way by design. That will make more sense in six months or so. 
Wow. Thanks for these. 
Iâ€™m working on a utility to transform delimiter separated values into refined SQL statements. Itâ€™s my hope to create something that is fast, feature packed, and relatively simple to use. The idea is to take naive CSV-like data and make files that can be cleanly loaded into a database server (MySQL, PostgreSQL, MSSQL, etc.). Iâ€™m aware that RDBMSes like MySQL have basic functionality built in, but I believe the concept can be taken further and abstracted to support multiple systems.
https://learning-rust.github.io/ might be helpful to learn the basics, concepts about lifetimes, modules, crate, workspaces and etc quickly.
Jetbrains also has a generous open source license.
One problem I have with Rust is that I regularly don't know what type I have. For example, a few `.and_then`/`.map` chains later, and the signature of my future chain is: &gt; MapErr&lt;AndThen&lt;MapErr&lt;_, _&gt;, FutureResult&lt;_, _&gt;, fn(_) -&gt; FutureResult&lt;Peer, E&gt;&gt;, fn(&lt;AndThen&lt;MapErr&lt;StreamFuture&lt;Lines&gt;, fn((Error, Lines)) -&gt; Error&gt;, FutureResult&lt;Peer, _&gt;, fn((Option&lt;BytesMut&gt;, Lines)) -&gt; FutureResult&lt;Peer, _&gt;&gt; as Future&gt;::Error)&gt; (Copy and pasted) IDEA has been a saving grace with its inline type hints even though it frequently only displays `unknown`. The tooling around Rust is its biggest weakness for me right now as a beginner. It's hard to discover things. But tooling is hard and I can imagine some really cool tools that will be available in a couple years. Like being able to visually show you the lifetime of an identifier on hover and stuff. Or a little flyout menu that shows that `Ok(())` can be passed to this function because it highlights `IntoFuture&lt;Result&gt;`.
Working on a pure-Rust implementation of Lua, [luax](https://github.com/losfair/luax).
And mine for managing those migrations! https://github.com/jaemk/migrant_lib
I'm using [versioneye](https://www.versioneye.com/) for Java projects for this and it's a useful thing to have! Looks like they [also support Rust](https://blog.versioneye.com/2017/05/04/rust-support/). But it's good to have a tool that's specifically made for Rust :)! I love the design of this as well, minimal and clean.
Iâ€™ll try and kick off the CLI working group this week. Ping me if youâ€™re interested in participating!
&gt; Also, may migrates coroutines (stacks with potentially not-Send data on it) between threads. Which will just explode to the user's face sooner or later, unless the code is really trivial. Corona doesn't do the migration, avoiding the whole can of worms. For practical bugs arising from this: Linux namespace handles are bound to threads. https://www.weave.works/blog/linux-namespaces-and-go-don-t-mix
Thereâ€™s actually a number of s3 fuse file systems. S3fs, Goofys, etc. 
Wrong sub, check /r/playrust or call .unwrap() on your door
Have a look at Microsoft's Powershell. Its pipes are streams of typed objects. I prefer Unix pipes, but wish that more tools would use ASCII a bit smarter. I mean, using things like field/record separators instead of spaces, commas, tabs...
This is awesome, thanks! By the way, it would be super cool to integrate this service with https://github.com/RustSec/cargo-audit and display red badge if some of the dependencies have known vulnerabilities. That way it would be much harder to miss.
I would try docker compose or something similar.
Interesting... I've been looking at Rust from a distance for well over a year now, not quite got my feet wet, but once in a while read threads like this. I'm an audio and mobile dev, my framework of choice is currently JUCE. It would be amazing to have a Rust equivalent of JUCE, at least the cross-platform GUI aspect, but seems a little way off for now. My current plan is to port some of my core DSP/logic code to Rust and import it as a library. It would also be cool to do some of the graphics in Rust, via an OpenGL context, but I haven't looked into how that would work with JUCE yet. 
I'm sorry I should clarify, I mean that 'safe rust can be cryptographically unsafe if it allows timing or cache attacks
ooh interesting, might be nice not only for raw photos but also for huge git reposâ€¦ &gt; Those blocks get uploaded So are the files not stored as-is on the server? :(
*A relevant comment in this thread was deleted. You can read it below.* ---- Videos linked by /u/Jonhoo: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Live-coding a Rust crate for running short-lived clusters of EC2 spot instances](https://youtu.be/Zdudg5TV9i4?t=12813)|Jon Gjengset|2018-02-11|4:43:36|2+ (100%)|46 [Live-coding a Rust crate for running short-lived clusters of EC2 spot instances](https://youtu.be/Zdudg5TV9i4?t=12813)|Jon Gjengset|2018-02-11|4:43:36|2+ (100%)|46 [Live-coding a Rust crate for running short-lived clusters of EC2 spot instances](https://youtu.be/Zdudg5TV9i4?t=12813)|Jon Gjengset|2018-02-11|4:43:36|2+ (100%)|46 [Live-coding a Rust crate for running short-lived clusters of EC2 spot instances](https://youtu.be/Zdudg5TV9i4?t=12813)|Jon Gjengset|2018-02-11|4:43:36|2+ (100%)|46 --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/Jonhoo ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;amp;subject=delete\%20comment&amp;amp;message=du36ifx\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0 [[Continued...]](https://www.resavr.com/comment/live-coding-rust-crate-for-10221604) ---- *^The ^username ^of ^the ^original ^author ^has ^been ^hidden ^for ^their ^own ^privacy. ^If ^you ^are ^the ^original ^author ^of ^this ^comment ^and ^want ^it ^removed, ^please [^[Send ^this ^PM]](http://np.reddit.com/message/compose?to=resavr_bot&amp;subject=remove&amp;message=10221604)*
And my Axe! But God damn, that looks cool. I gotta have a look at that :3
Then you're just moving your problem at runtime. You could encode this in the type system using phantom `Openable` and `Unopenable` type parameters `impl Door&lt;Openable&gt;` can then provide `open`. That way calling `open` on a `Door&lt;Unopenable&gt;` will just fail at compile time. Of course, instead, you can always run into the door screaming "FEARLESS CONCURRENCY" and open it anyway, but that is the moral equivalent of `unsafe` so the compiler can't help you with that.
I've restarted my mutation testing efforts by dabbling in AST-based analysis. Will publish something later this week, so stay tuned. Apart from that, looking into criterion benchmarks for bytecount, which currently are too heavy for CI, I should configure them to be shorter. Also TWiR.
Working on my first contribution to Rust itself: https://github.com/rust-lang/rust/issues/48103 Nothing big, but that makes it a good opportunity to learn about the surrounding infrastructure, how to compile rust, testing, how the code is structured, etc. I will also continue with reading through 'Programming Rust' and adding more Anki cards to my collection. I currently have about 30 but want to add at least 20 more this week.
That `Door` setup sounds very complicated. Can you use a crate providing lock-free data structures instead?
Indeed, and I even found it and had a look at it before I started - it really looks like I should change the prefix-handling to be like yours! One difference is that all currently known extensions are supported, including tables, which was important to me. Also I wanted to be sure it really works as expected, and added a whole bunch of tests verifying complex documents via snapshots.
You must also set the `Location` header. (https://docs.rs/hyper/0.11.18/hyper/header/struct.Location.html) 
Personally (coming from a JavaScript background), I found Rust had much better learning resources than C++. In particular, reading The Rust Book was pretty much sufficicent for me to get producrive enough to write a real app (in particular the sections on ownership and stack vs. heap are v. important), whereas for C/C++ I had no idea where to start in terms of writing realistic production code. Things like using libraries are also much more difficult in C++, whereas Rust has a package manager like python. The other resource that you may be underestimating the usefulness of coming from a python background is the compiler itself. `rustc`s error messages are extremely helpful, and often explain what you have done wrong (and are also googleable, where you will find lots of helpful stackoverflow answers). I feel much confident taking on C++ now that Inhave already learnt Rust.
Indeed, the story for preprocessors isn't yet a great as it could be. To me it sounds like another PR is waiting to be made to allow preprocessor plugin-programs, similar to what's already possible for plugin-renderers. My plan is to make my first experience with `termbook` (the thing I am currently working on), and then make a PR to mdbook to make the preprocessor business much easier. Regarding `pulldown-cmark`, I was surprised to see it include `html` rendering at all. But you are right, it would have been very nice to have support for this in the same package.
Well, itâ€™s an `id` hash: it doesnâ€™t do that much thing, but itâ€™s like: `T -&gt; bitfield`
Maybe try creating a FuturesUnordered from the Vec of URLs (you may have to use a result), then using and_then to convert it to the response from hyper.
What I find annoying is that the function interfaces in the crate ecosystem are very low level. It's not "encrypt this piece of data" its "encrypt this block". Which I guess is a lot more useful for library developers. But as someone who "just" wants to encrypt some data, that's really terrifying to use. I might know the difference between CBC and CTR but that doesn't make me an expert *or* secure enough in my own abilities not to fuck it up somehow ðŸ˜‚
Probably the best grep tool available.
I do like that TQL has lesser magic macro than Diesel. However the feature both lacks of is the ability of specify accurate attribute of field. For example nullable Varchar(128) or custom defaultValue. 
What makes you think it's a bad system? I think you might be thinking of implicit _conversions_ (mainly used to implement extension methods, but can be horribly misused). Implicit _parameters_ in Scala, on the other hand, in fact work very well.
It has absolutely nothing to do with hashes. There is no notion of collision. There is no sensible way to swap out the hash function. 
IMHO monads [are not a good way to pass context, because they don't commute (in general)](https://youtu.be/9Wp_riP8LQw?t=1078). This means composing code using different contexts becomes painful very quickly. Implicit parameters are what is really being called for here, but everyone seems too scared by the name to recognize it.
S3 would probably map great as the underlying storage is block by block. So a key/value store is what the backend needs to be. It might make sense to do larger blocks than 4K though.
It can only pass whatâ€™s in scope so itâ€™s not adding anything in value other than saving key strokes. 
I'm starting to write [Learning Rust through Games](https://github.com/shingtaklam1324/rust-through-games) where I **try** to teach Rust through simple CLI Games. First Draft of Chapter 1 (Tic Tac Toe) is complete and any Code review or Text review would be welcome
Worth adding: the reason I don't want to wrap Rust structs too much is because the behaviour of these structs (and changes of it) would directly influence my language. It would also require a lot of plumbing in the VM (e.g. instructions for extracting the year/etc would have to be added), which I'm hoping to avoid as much as possible.
They're not inferior, they're just different. First of all, I'm ignoring the distinction between threads and processes, because it's mostly just down to memory isolation. There are two ways of running multiple things at "the same time": preemptive multitasking and cooperative multitasking. *Colloquially speaking*, "processes" and "threads" mean the former, whilst other words usually mean the latter. Preemptive multitasking is where the scheduler lets a task run for some amount of time before interrupting it and forcibly switching in some other task. If you do this fast enough, it gives the impression of many things running simultaneously when, in reality, there's only ever one thing running at a time. &gt; Aside: I'm also ignoring multicore CPUs and SMP systems, *etc.*. Just pretend a quad-core system is four computers attached to a *really fast* network or something. Cooperative multitasking is where the *task* runs for however long it feels like before explicitly handing control back to the scheduler so that it can switch in a different task. Or not. It's all cool. We're *all* friends here, just sharing the CPU. \**takes a puff*\* Both let you run "thousands of threads" irrespective of how many physical cores you have. The devil is in the details. Preemptive multitasking is good when the things running are *largely* independent of each other. That is, they aren't all trying to access the same resources at the same time. It's also good for when you don't *trust* the tasks to share nicely, or you want all tasks to make constant progress. Where they fall down is when they're all trying to access limited, shared resources, which leads to lots of contention, and lots of wasted work switching back and forth. Cooperative multitasking is good when you want to make maximum use of available resources, since switching only occurs if the current task can't make any further progress *right now*. The issue is that it's trivial for a bad task to hang the whole system. The other advantages of cooperative multitasking usually just comes down to how they're implemented. For example, the reason many people want generators in Rust is that it allows a suspended cooperative task to only consume as much memory as it absolutely *needs*, rather than having to persist an entire call stack. Said stacks would also have to be allocated ahead of time, irrespective of how much each task will actually use. Also, cooperative tasks can move between cores... depending on how they're implemented.
I saw `AtomicBool` in the standard library docs. How is it different from `Arc&lt;bool&gt;`? Iâ€™m guessing that the former isnâ€™t a pointer, but when would you use one over the other?
That's not even true: more elaborate implicits can be synthesized from more basic ones, so the whole system can be used like a very powerful code synthesis tool, greatly reducing boilerplate. But this is beside the point: even simple implicit values inferred from scope are super useful to do dependency injection and avoid API uglification. By the way, what's proposed here with contexts is an ad-hoc and rather inelegant hack to implement this simple kind of implicit parameters.
Added config files -- why not follow [XDG Base Directory Specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html)? ... another one that needs to be "tucked away" manually...
`Arc&lt;T&gt;` is a struct of `{atomic reference counter, data of type T}`. It lets you share an instance between threads, but itself does not let you mutate the data. It also lets the data outlive the scope it was initially created in: `Arc&lt;T&gt;` will only be dropped when the last strong reference to it is dropped. `AtomicBool` is just an actual bool with CPU-level atomic operations implemented on it. This way you can share and mutate it from multiple threads while avoiding data races. But it will not outlive its scope.
Iâ€™ll be getting back to slowly chipping away at the internals of [`relm`](https://github.com/antoyo/relm) this week. I might also work on a documentation generator for something work-related this week. I use a proprietary scripting language at work that doesnâ€™t have any kind of module system, so the program that controls the entire experiment is about 2k lines at this point with little or no documentation, all in one file. I want to write a parser that will pull out documentation comments (the syntax of which Iâ€™ll have to define, thereâ€™s only one type of comment in this language), generate markdown from the extracted comments, and run the markdown through `mdbook` to make some nice documentation for myself and whichever poor soul comes after me.
Mutation testing has always been interesting to me. I donâ€™t have the time to collaborate, but Iâ€™m excited to see what you come up with!
I've personally implemented XDG on more than one occasion, so I'm well aware of it. Unfortunately, XDG is grossly insufficient because ripgrep is not a Unix-only tool. It works on Windows and Mac too. Is XDG appropriate there? I don't think so, certainly not on Windows at least. I started out with the intent of doing whatever is most convenient for each platform, and in particular, thought there would be a crate that did it for me. There are many options out there, and I think I looked at all of them, and they all fell short of my standards for one reason or another. I said more [here](https://github.com/BurntSushi/ripgrep/issues/196#issuecomment-362850321) and [here](https://github.com/BurntSushi/ripgrep/issues/196#issuecomment-362853907). &gt; another one that needs to be "tucked away" manually... $ rg '^\S+=' $HOME/.profile -c 78 Another one isn't going to hurt. Please read the thread I linked above, and please consider the perspective of the maintainer and other end users.
&gt; That's not even true How do you pass data out of scope with scala's implicits?
Of course, any data passed has to be materializable from what's in scope (which is more flexible than just passing what's in scope, which is what you originally wrote), but that's a feature, not a restriction. Dynamic variables are a bad idea in a functional language focused on strong type safety guarantees.
&gt; Of course, any data passed has to be materializable from what's in scope Right. So basically just syntactic sugar and now what is actually needed: async aware TLS. These are just entirely different problems and I *personally* do not see the value in Scala's implicits as a result of that. I also find them very confusing and would not want them in another language if I were to chose.
Ah cool, I'll have to have a look at that library :3 Does `miscreant` provide any utilities for key-generation too? Or should I just provide random data myself?
No, what is needed is to do async _without_ any kind of TLS â€“ read the proposal again. This is done by threading the context parameter through every function call. The proposal is just a way to make this more syntactically pleasing, but it falls short in my opinion. Oh, and yes, most things in programming language design can be reduced to "basically just syntax sugar". That doesn't help the discussion, though.
Working on making API documentation for [gfx-rs](https://github.com/gfx-rs/gfx). Turns out I have a lot to learn about it's internals, which will probably mean learning a lot about Vulkan. But I'll get there! The goal for this month is API docs, and hopefully an introductory tutorial.
Maybe I can make it this year! We will see. Out of curiosity, does anyone know the reason for shifting the date from late summer last year to early summer this year?
&gt; No, what is needed is to do async without any kind of TLS That does not work for many cases I work with on a daily basis. That's my whole point.
You know that you can always use TLS in addition to any implicit parameter mechanism (like the one proposed in the blog post). Those are orthogonal mechanisms. Thus, I don't see your point.
No `miscreant` does not provide key generation utilities. If you want to generate key from password you can use [`argon2rs`](https://github.com/bryant/argon2rs) crate (not part of RustCrypto) or `pbkdf2` if you like older solutions.
You cannot use TLS with async systems â€¦
Fwiw I've use chrono and found it very nice for simple stuff; you just use the `Utc` or `LocalTime` types, depending on your needs, and off you go. If it's complex it's because it's trying to solve a complex problem, and at least being aware of how complex it can be is useful if it keeps you honest. If you look at other time libraries like Python's `datetime` they look very similar. For monotonic time the first thing that occurs to me is `std::duration::Instant`, but I vaguely recall reading it's monotonicity comes with the price of reduced precision; don't recall specifics though.
I am tempted to go, but I don't know any French. Is this a problem in France or can most people speak English?
If you have "Dropbox Professional", you can use [Smart Sync](https://www.dropbox.com/help/desktop-web/smart-sync)
From what I've heard from friends (haven't been in Paris either), it's not a problem at all. As a rule of thumb, it shouldn't be a problem in any big city (especially capitals) with sufficient tourism.
There were two RustFest last year: one early in the year in Kyiv, one later in the year in ZÃ¼rich
The code looks fine. It's a little atypical to use char instead of an enum for cell state, but no big deal. Running clippy on it might be educational, just cause it usually is. It's a little confusing to use the term "CLI" for these since I usually think of that meaning non-interactive programs where all information is specified as command line args, but maybe I'm just being pedantic.
There were two RustFest last year: one early in the year in Kyiv, one later in the year in ZÃ¼rich
The code looks fine. It's a little atypical to use char instead of an enum for cell state, but no big deal. Running clippy on it might be educational, just cause it usually is. It's a little confusing to use the term "CLI" for these since I usually think of that meaning non-interactive programs where all information is specified as command line args, but maybe I'm just being pedantic.
No shift in dates at all. Last year we had [Rustfest Kyiv](http://2017.rustfest.eu/) in April (that's spring) and [Rustfest Zurich](http://zurich.rustfest.eu/) (that's autumn) and we intend to keep it that way, slightly shifting dates due to venue availability.
Not even everyone from the organizer team is fluent in French. Don't worry!
To turn a stream that processes futures one at a time into one that doesn't, you can use [`buffered` and `buffered_unordered`](https://docs.rs/futures/0.1.17/futures/stream/trait.Stream.html#method.buffered). In both cases it will process up to the specified amount of events in parallel. There are a couple of gotchas to be aware of: 1. It wants a `Stream&lt;Item=Future&lt;Item=U, Error=E&gt;, Error=E&gt;` so that it can buffer and unwrap the futures, so, you'll need a unified error type, and you'll need to `map` the stream of URIs to get the futures first. 2. `amt` should be lower than the open file limit of the user/process. You can easily overflow it otherwise.
&gt; Is XDG appropriate there? I don't think so, certainly not on Windows at least. No, `APPDATA` is used on Windows instead. &gt; Another one isn't going to hurt. Eh, death by a thousand papercuts. For me, I have 23 dotfiles symlinked already (i.e., managed by my dotfiles setup) and another 20 which have shown up for various other applications. &gt; If and when someone solves the config file problem with a high quality Rust library in a platform independent way, then I am definitely willing to revisit this. Would something like [this code](https://github.com/mathstuf/rust-abagames-util/blob/master/src/paths.rs) work extracted into a crate and parameterized properly work? Do you have guidelines for what you're looking for here?
I'd agree. CLI is the wrong term. "Console Application" or "Terminal Application" or "Character-Based Application" or "CUI" (Character User-Interface) are better descriptions/categories for this.
/u/srijs just dropping some [inspiration](https://crossclj.info/).
What I mean is that you can wrap a parameter-passing API inside a TLS-based API, as explained [in the github proposal message](https://github.com/rust-lang-nursery/futures-rfcs/pull/2#issuecomment-363923477): &gt; Those of us who dislike it [argument passing], can create patterns on top, like the TLS that exists in 0.1. So I'm not sure what your concern is here.
Doesn't it have some strange limitations if it still follows the 'stream model'? I put in the stream as the last one for a reason; the utility process is 'blocked' there. And it seems t me it can be nasty if you 'forget' to consume a stream.
&gt; Eh, death by a thousand papercuts. For me, I have 23 dotfiles symlinked already (i.e., managed by my dotfiles setup) and another 20 which have shown up for various other applications. I'm not talking about dot files. I'm talking about env vars. You can put your ripgrep config file any place you want. That was why I chose this path for an initial implementation. &gt; Would something like this code work extracted into a crate and parameterized properly work? Do you have guidelines for what you're looking for here? I don't think so. I'm pretty sure Windows is more complicated. I am only vaguely aware of these things. I do not want to solve this problem myself. Someone else needs to do it, and it needs to be well researched and done correctly.
Makes sense -- thank you for clarification! I agree, the multiplatform divergence of conventions is unlikely to be solved anytime soon, if ever. That said, the windows home on the VM that I compile rust binaries for windows is already peppered with .dotfiles of all kinds... So, for what it is worth, I should probably give up on making my $HOME tidy :-) Thank you for an awesome grep tool -- I use it everywhere!
You can easily get by in Paris with only English. That was my experience when I had last visited. I know I'll be going and pretty much everyone at RustFest speaks English. Worse comes to worse make friends with a few of the French people there who can help out if need be :)
&gt; Do you have guidelines for what you're looking for here? To be more explicit about this, I am aware of the following issues in the Rust community that have discussed this topic: * https://github.com/rust-lang/cargo/pull/2127 * https://github.com/rust-lang-nursery/rustup.rs/issues/247 * https://github.com/rust-lang/cargo/issues/1734 * https://github.com/rust-lang/cargo/pull/148 I would expect a solution to this problem to take into account the varied feedback given here. (Some of it of course may not be relevant since there is so much.) The crate itself also needs to be well maintained. And I think this is what would get me to _consider_ this. There is a nice simplicity in just requiring to set `RIPGREP_CONFIG_PATH`, and then you can put the file anywhere, say, `RIPGREP_CONFIG_PATH="$HOME/.config/ripgrep/config"`. The reason why I'm being a stickler on this is because I have learned from past mistakes. Once a particular type of config discovery makes it into a release, you're pretty much committed to that for all eternity. That is why the initial implementation of this was literally as simple as possible while remaining useful.
Oh yes, personally, I agree. I don't give two poops about my untidy `$HOME` directory. Not worth worrying about. But there are **legions** of people who do, and I do not want to be the target of their zeal.
Because the T in TLS means thread. 
looking forward to it!
my work blocks your site as malware
Thanks. Doing this with a procedural macro is a bit tricky, because you have very little information about the types of things. So I'm looking into what things can be changed without rebuilding the complete inference.
&gt; Doesn't it have some strange limitations if it still follows the 'stream model'? I put in the stream as the last one for a reason; the utility process is 'blocked' there in my idea I don't use Powershell, but evaluated it briefly when I got Windows 10 (shortly followed by installing cygwin). I assume it behaves like Unix in that the consumer decides when to block the producer in a pipeline, give or take the small buffer the pipeline itself contains. The consumer can also decide whether to read it all in one go, object-by-object etc. I think the Powershell way of producing the kind of data in your example is to create an object which contains the three header values and a list of objects representing the records that follow, and to produce only a single such object. That, or to produce multiple objects each containing redundant copies of the three header fields along with the record. &gt; And it seems it me it can be nasty if you 'forget' to consume a stream or need types components on a different order. Pipes are always nasty if the ends of it aren't cooperating. At least with structured, hierarchical output you'll get rid of common Unix problems like matching strings and hoping the output won't change and be similar enough on all the target systems. You can get rid of the sed/awk/grep string mangling cruft and use structured transformations of the data instead. My main objection to this model was that the majority of the pipelines I write are relatively simple one-off stories where the brevity afforded by regular expressions on a dumb character based interface typically outweigh the benefits of structured objects, and that structured objects can easily be encoded in unix pipelines as well, for example making each line a JSON object. As a matter of convention, they aren't, but they could be if the need arises, and transformation tools can easily be inserted into a pipeline to accommodate this style.
Was making my way through Rust koans when I stumbled across an exercise with extending traits using inheritance. Looking through the rust book, I replaced the blank with "Some(self.cmp(other))". But I get an error message (pasted below), which itself was bit confusing to me. #[test] fn inheritance() { use std::cmp::Ordering; #[derive(PartialEq)] struct Bawks&lt;T&gt; { thingy: T } impl&lt;T: PartialOrd&gt; PartialOrd for Bawks&lt;T&gt; { fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; { __ } } trait Ordered: PartialOrd { fn is_before(&amp;self, other: &amp;Self) -&gt; bool; } impl&lt;T: PartialOrd&gt; Ordered for Bawks&lt;T&gt; { fn is_before(&amp;self, other: &amp;Self) -&gt; bool { self &lt; other } } let a = Bawks { thingy: 5.0 }; let b = Bawks { thingy: 7.0 }; assert!(a.is_before(&amp;b)); } ----------- Output: error[E0599]: no method named `cmp` found for type `&amp;path_to_enlightenment::inheritance::Bawks&lt;T&gt;` in the current scope --&gt; src/koans/traits.rs:195:23 | 195 | Some(self.cmp(other)) | ^^^ | = note: the method `cmp` exists but the following trait bounds were not satisfied: `&amp;path_to_enlightenment::inheritance::Bawks&lt;T&gt; : std::cmp::Ord` `&amp;mut &amp;path_to_enlightenment::inheritance::Bawks&lt;T&gt; : std::iter::Iterator` `&amp;mut path_to_enlightenment::inheritance::Bawks&lt;T&gt; : std::iter::Iterator` = help: items from traits can only be used if the trait is implemented and in scope = note: the following traits define an item `cmp`, perhaps you need to implement one of them: candidate #1: `std::cmp::Ord` candidate #2: `std::iter::Iterator` ----------- I then tried to implement Ord but that was giving me another error. (I don't want to post that yet, since I'm sure my mistake lies in whatever I've mentioned so far.) Any help is welcome! 
I'd love to be there! I unfortunately don't leave anymore in Paris :(
The day after GDPR kicks in :-) i wish i can go 
I am working on a [Twirp](https://github.com/twitchtv/twirp) code generator for Rust using [prost](https://github.com/danburkert/prost/) and hyper: https://github.com/cretz/prost-twirp. Just about done, just need to finish some docs and tests.
How did you end up implementing search in compressed files?
First comment is a decent approximation: https://github.com/BurntSushi/ripgrep/issues/539
Yes, all of the above. Maybe also video calls for focussed discussions.
There shouldn't be any issue in an event such as this one. Everybody speaks English in the world of computers. As for getting around the city, it's so heavily touristic you shouldn't have any trouble finding people who speak English, just like most big cities.
Hooray, now cpal supercedes linking sdl2 for audio (almost)
So, I'm looking to over the next few months to a year to implement a HPC nonlinear finite element code in Rust. One of the big things I want to accomplish with this code base is for it to be fairly modularized such that one can easily add or change various models. If I were doing this in either C or Fortran I would probably have the necessary variables as either a public or private module variable for Fortran or potentially some form of global variable in C. However, I'm not sure of the best way to accomplish this in Rust, since I really haven't come across anything like this in the rust book. One thought I've had is potentially is something along the lines of a global struct(s) that allows me to pass around necessary references to all of the major variables that I initialize at runtime. This method might also potentially require me to create structs for all of data in the appropriate modules as well. If anyone has any thoughts or could point me to a crate or project that I could either look at or potentially use I'd very much appreciate it.
Thanks for the detailed answer. is there a book you would recommend about this topic?
About platforms other than Linux and *BSD: * On Windows, you would use `%TMP` for temporary files and something like `%APPDATA%\ripgrep` for user data and configuration files. * On macOS, you would use something like `/Library/Application Support/ripgrep` for user data and configuration files.
Thank you so much. This was definitely a "D'oh" moment for me.
https://www.dropbox.com/smartsync Not for free though.
Never say never. If there's a will, there's a way, and someone will do it.
Very nice, will these changes make it into rodio somehow (as rodio is heavily bound to cpal)? rodio is usually my go-to library for sound playback, because it has more sound mixing tools than cpal, which is more "bare-metal". It would be cool if it could do sound recording, too. Of course, that's just my wish.
I'd definitely be interested in being included in the discussion even if I might be a bit too busy with other projects at the moment. I'm really interested in building CLI tools :3 I'm @spacekookie on twitter btw :P
Or mine as well! https://github.com/Keats/dbmigrate
What you are doing isn't cool. Please stop it.
Reads are not the issue, writes are. Using blocks of a standard smallish size makes it much simpler to just have get/put semantics for everything and deduplication for free.
I'm pretty sure this is wrong, which is exactly demonstrating my point. For example, see what the (now seemingly unmaintained) app_dirs crate does: https://github.com/AndyBarron/app-dirs-rs/blob/master/src/imp/platform/windows.rs It is more than just reading an env var.
&gt; Also, cooperative tasks can move between cores... depending on how they're implemented. wink, wink, bang, bang
At this point I'm wondering if it would be useful to have a `rust-database` channel on the Mozilla IRC :P - @ /u/jaemk_ - @ /u/antoyo
Says apache 2 in the toml, but naturally that's not enough, need the license contents in the project. Maybe make a GitHub issue to add it?
This seems a very nice project. I maybe will test it when it will be more mature. There is any plan to also support Windows in the future? I came across to Dokan (dokan-dev.github.io/) a Filesystem in Userspace library for Windows. And froma what I saw it also has a FUSE wrapper.
&gt; However if you put foo_bar in your Cargo.toml and the crate is named foo-bar, it doesn't consider them the same thing. Ugh. This is the biggest problem, not huge but annoying none the less. Considering that you are forced to use `_` in the `extern crate some_crate` and that crates.io treats them the same I would suggest the first step is to allow both in Cargo.toml, or the very least allow `_` in place of `-`.
I'm interested in helping with this effort and have been trying to wrap my ahead the existing conversation, though I think there is a lot of context I am missing. I have two Big Questions I guess: 1) In a parent comment it is said that an important requirement is thread-local rng with thread-global distributions? I know this is common, but is this necessary? I understand that some algorithms pre-compute tables which you wouldn't want to do unnecessarily for each thread, but why couldn't one just clone() everything into each thread? These tables don't tend to be very large. If we're talking long-running Monte Carlo codes, the initialization time isn't going to really matter anyway. (Taking this one step further -- if we make everything thread-local, why not make the Distribution own the Rng so it's just `distribution.sample()`?) 2) It certainly makes sense to think of a distribution as const -- after all, as a mathematical object, it is necessarily invariant under sampling. I am not familiar at all with Rust's "interior mutability", but could this feature be used to mark each distribution as const while allowing various implementations to still cache/pool samples as necessary? This seems like an appropriate application for `Cell`? 
I find it surprising json parsers have streaming capability for R-values. Technically i guess a extension where it's implicit that 'variables need to be read in order, only once and without skipping' would be possible and relatively consistent.
Another way to look at it is that you have a context and some work that needs doing in that context. A thread running sequential blocking code does that, being released to do some work every time the kernel returns from a syscall. A green thread does that by being scheduled in by the user-mode runtime when there is work to do, and also looks like sequential blocking code. (Go's goroutines are green threads that can run in parallel, backed up by Go's user-mode runtime.) An actor does that by being woken up to process a call, again backed up by a user-mode runtime, but with event-driven style code instead of sequential (e.g. see Pony). Also other forms of saved context such as Futures are essentially the same thing just with a different interface and structure. All except threads blocking on syscalls have a user-mode runtime of some form to handle the scheduling. Implementations may be single-threaded or multi-threaded, depending on the priorities of the implementor. Concepts from one form are transferable to others, e.g. actors, green threads and futures are doing essentially the same thing, holding context and allowing work to be done in that context, just in different forms with different structures and different syntax.
I just published a silly little library for doing clever memory things, mostly involving libc. I'm adding new tools to it as I think of them, I don't really have any particular goal in mind. https://github.com/treyzania/haque
Please, when people are incredibly rude to you, don't forget it's just a Paris thing. France and Paris are kinda separate countries sometimes 
&gt; all I want is a tuple of sorts containing the year, month, day, offset, etc as most calculations would be done in the language running on the VM. What kinds of calculations are you going to be doing? The reason I ask is because human calendars are very complex and unless you want to recreate Joda time in your language, there's not a lot you're going to be able to do with a (year, month, day) tuple. Even simple things like "how many days between (2018, 2, 20) and (2018, 3, 2)?" will require access to a calendar so that you can see how many days are in each month and if this is a leap year or not.
I highly suggest [Programming Rust](http://shop.oreilly.com/product/0636920040385.do). It has a great section where it walks through code samples in Rust, Python and (I think) C++ and shows how their memory are laid out and how they are different under the hood. That chapter alone might make the book worth it for you.
This is the real solution. Crates.io already considers the two names equivalent, so let's make cargo do the same. I personally like hyphen-names, but I understand that it's a style thing that people disagree on. The real solution is making it so it doesn't matter, and both styles always work and always resolve to the same thing.
My guess is that the C# programmer came from a java background, where you need a similar pattern to turn checked exceptions into runtime exceptions Since checked exceptions are roughly equivalent to `Result`s, turning them into runtime exception is the Java version of `unwrap`. The C# designers rightly concluded that checked exceptions suck in practice, so the pattern serves no purpose here (Unfortunately their conclusion was to use unchecked exceptions everywhere, instead of the `Result` based approach of Rust). &gt; If I ran it with a debugger, the debugger would stop on the throw statement in the top-most try...catch block There is a debugger setting to break when an exception gets thrown instead of only when the exception is unhandled. It's one of the first things I enable when I install VS. I think it was called "First chance exceptions" in older versions of VS.
&gt; until recently i've had the impression that green threads are inferior to native OS threads, reason being they can't scale to multiple CPU's... That's just not true. &gt; could someone please explain the whole multithreading thing, which threads are better for which cases or just explain multithreading in general Your hardware can do n things at once. Let say n=8 (though you can get hardware which has hundreds or thousands of cores). Your program manages m tasks, like m web requests to handle or m images to process. Usually m &gt;&gt; n. To get it working, "something somehow" has to map m tasks to n hardware units, deciding which task is executed where and when. If one task is being executed, but need to wait for something (IO, some timer, a lock) it needs to be taken aside and another one gets some cpu time. The "something somehow" can be: 1) Developer, managing this manually. Except for some parts of the operating system or maybe some cases of embedded programming, this is just too much for a human to handle. 2) Operating system (often in some cooperation with hardware). This is also called 1:1 model because 1 task is given 1 native thread. The operating system will look at your code, and switch the active threads when one of them is stuck waiting for something. 3) Compiler or runtime, who will look at your code and because it understands it, it can manage the assignment of tasks to native threads. This is called m:n model (and there is nothing stopping the compiler from generating code that utilizes all available cores). I'll skip 1) for not being very practical (or if practical, being tied to very specific conditions), so the choice is between 2) and 3). Both of them have some properties, being good or bad depends on many factors and your specific situation and point of view. 2) is definitely simpler to implement. You can add support for that to any language, essentially throwing a lot of complexity into an operating system and taking it away from other places. If you need to run multiple programs that are not developed in coordination, this is often a much better choice. So the benefits are that it is relatively simple to use, implement and understand, very popular and often well-supported. The cost is that your OS - and your interaction with it - becomes very complex, and since it has limited knowledge of your application, it has to be conservative, consider the worse cases and pass on some optimizations. Main issue here is that switching active tasks is relatively expensive. Another one is that you may not have much control over the OS, so its free to decided what runs when and you have to program around it. 3) Is often believed to be more efficient. Since your compiler knows all of your code, it can make decisions and optimizations an OS can not. It may also give you more control over the whole task scheduling logic. You need however have a language that is designed with this model from day one. You cannot just add this to existing codebase. Given those models you can pick one that is suitable for your usecase, but your hardware, OS and programming language are important factors. While you may conclude that theoretically, one is better for you, if the hardware/OS/language contains significant support for the other, it will be easy choice. 
It really is only cargo that treats them differently. Even tools like [cargo-edit](https://github.com/killercup/cargo-edit) treat them the same but spit out a warning when you get it wrong. This is mostly how I have been dealing with the issue, use cargo edit and don't worry about it, it would be nice if cargo itself did the same.
I am honestly not sure why there is thing in the first place, just having `_` everywhere seems so much more straightforward. Is it really just so you can have (slightly) better-looking url's ? Or as a matter of consistency with the unix package manager tradition ?
Thank you. Seems like a good book to have. I will check it out. 
The complexity is indeed a big concern and is part of the reason why I don't feel very sure about this. Note that the year/month/day thing was just an example, in practise the language would store much more than that. Currently I'm leaning towards adding a few basic instructions that can be used for decomposing time into separate values, creating a new date/time object from those values, and perhaps a few others. This still requires quite a bit of work, but at least I won't have to add an instruction for every field I would want to extract out of a date.
We don't care too much for the results, but we want to ensure that the benchmarks run at all.
An advantage of distributions being stateless is that there is no context to create on first usage or pass around. A thread-local solution with auto-storage might be feasible but could be tricky â€” e.g. it would be incorrect to return a cached result generated via a different RNG, so state should be RNG-specific. Taking it further and making a distribution own the RNG is undesirable because applications may use multiple distributions â€” this would force them to create multiple RNG states too. Using `Cell` should really be a last-resort option. For example a type using `Cell` cannot implement [`Sync`](https://doc.rust-lang.org/std/marker/trait.Sync.html) thus cannot be shared between threads â€” even though apparently it is immutable. The [`cell` docs are a good read](https://doc.rust-lang.org/std/cell/index.html?search=).
&gt; it's not difficult Great! I'm happy to mentor people through the process. If you'd like the file an issue, write a specification, create a new crate, set up a proper maintenance strategy for it, respond to bugs, code review PRs, reconcile all of the existing feedback in the Rust community on config files and make sure it works on all major platforms (Windows, Mac, Linux), and make sure the UX is right and are prepared to support it for the lifetime of ripgrep, then please, by all means, I'm happy to help guide you.
It really depends on what you need. The time crate isn't getting any features anymore, only bug fixes. The chrono crate is even recommend and is probably going to be maintained in the long run. It's fairly easy to set-up and works wellso far on windows. However, for working directly with time zones (e. g. CET), you need additionally the chrono-tz crate. Though, I will probably implement it myself by making a call via WinAPI (winapi crate). I think if you really just need a tiny bit, I would try looking at the system APIs but beware of the complexity.
If there's a way to present a FUSE filesystem to windows then it could work. I use `fuse_mt` for the fuse operations so if that ever supports windows it may become possible. Personally I only care about Linux and won't spend too much time figuring out other platforms, particularly Windows which is so different. I'd accept patches if they weren't too intrusive and someone was willing to maintain the support and support users.
Yes, the tests are as close to fair as I can do right now. Once DataFusion supports partitioning I can start running some more realistic tests.
Initially cargo didn't reject packages named like this, but didn't transform them to `_`. You had to do this: extern crate "rustc-serialize" as rustc_serialize; This was bad, but it meant that `-` crates already existed in the registry. It was changed to the current system for that reason. I agree that just excluding `-` would have been a better choice.
Of course we can't go back in time and nothing prevents a crate author from manually modifying the package name in their manifest but a good way forward may be `cargo` refusing to publish a crate with invalid characters in the name (and of course `crates.io` needs to learn to reject them if it doesn't already). I was initially hesitant to suggest that `cargo` should enforce this rule but cargo and crates.io are pretty heavily tied (in my mind as a user, at least) and if other registries (and package managers) have a way to allow `-` without issues then great.
This is probably the easiest way to get Programming Rust DRM free now that the O'Reilly online storefront is closed. I wonder if HB will handle updates though?
It's also worth noting that algorithms like Metropolis-Hastings or slice-sampling generate samples from a distribution but require an internal state. (These Markov-Chain Monte Carlo techniques don't generate *independent* samples, of course, but with appropriate thinning strategies can be sufficiently decorrelated.) For certain problems, these (relatively expensive!) techniques are the most practical way to generate samples from a specified distribution. There is value in allowing a Distribution trait to wrap the implementations, but it may also muddy the waters sufficiently so as to make the overall trait less useful.
&gt; Maybe make a GitHub issue to add it? Or a pull request!
Better looking package names, not just urls. I believe the reasoning was that `package-name` would be a better style everywhere if possible, but it isn't possible in source code since `x-y` isn't an identifier. Thus, `package-name` is canonicalized into `package_name` in the source.
Handle::spawn() accepts future, .call_fut() returns future. So just pass .call_fut() to the spawn function
As for crates with both `-` and `_`: usually the crate names don't match the package names *anyways*. Like, `piston-gfx_texture` exports the crate `gfx_texture` (*not* `piston_gfx_texture`). Do you see this an explicit problem? I mean, the way I see it crates like these are actually more clear than if it was `piston_gfx_texture` in Cargo.toml and `gfx_texture` in the source.
So, going through the code, and the `P where P: AsRef&lt;Path&gt;` confuses me. Mind giving me an example with the code?
I can easily see a OS being a smartass and having a 'output directory' that when a 'file' is created there and pumped bytes it's actually blocking on reading from another process and doesn't actually consume any appreciable memory or disk.
This book really is invaluable. I did 3 chapters a day for week, and itâ€™s almost too much to absorb. In fact you will need to highlight and reread. Itâ€™s an epic. 
I actually ignore $HOME and moved every single 'actual data' dir outside to another partition. Let the linux registry rot in peace as long as i don't have to look at it. Some applications still insist on putting some user visible directories there but they are few and far between thankfully
What are some best practices on code ordering in Rust (top-down vs bottom-up)? On the one hand, struct definitions and the like feel like they belong on top of the file, but on the other hand top-down ordering of code is more readable. So yeah, what is considered best practice (if such a thing exists for this topic) within the rust community?
Yes, but it's a bit worse in Rust. Simply put, some things never expect to be moved between threads (because they are `!Send`, they asked not to be moved) and take advantage of it. Like `Rc`. Odd things can (and *will*) happen if multiple such things just meet each other and some of them are moved. The fact this can be hidden in some library you call doesn't make it easier. On the other hand, it is *not* a problem (or, not as big one) in Go, because in Go nothing is *allowed* to assume it won't be moved between threads. In Go, everything is always moved around, so everything is ready for it.
Looks like OP is using a free domain name.
So, I was expecting to get the code updated on Saturday, but it is Monday. I did a lot of fixes with Clippy (thanks again for the recommendation), and integrated everything that I could from the suggestions from everyone here.
This. Crate names should be identical to... crate names?
Does it also support compressed files on windows by decompressing with 7z?
How is TQL **more** an ORM than Diesel?
My experience in Paris was that everyone was very friendly, except the hotel maid who pocked my key card. Room theft was a problem in my hotel, and the front desk didn't even confirm my identity when issuing me a new key card.
Huh, my first Rust project was called Orca too. (Mine was an in house project for my company though, so need to worry about a naming clash).
I was gonna post this. Knowing which dependency imports which is surprisingly not so obvious to beginners. 
&gt; I don't quite understand "it would be incorrect to return a cached result &gt; generated via a different RNG, so state should be RNG-specific" though -- &gt; aren't random bits just random bits? Why does it matter what source of &gt; entropy generated them? I guess /u/innovator12 has in mind the situation where a shared distribution is alternatively sampled in different methods with a high quality RNG and a low quality RNG, or worse, by a crypto and a non-crypto RNG, which may deceive the caller using the high quality (or crypto) RNG. I am not sure how important a concern this is in practice, though. &gt; Is that a decent summary of the "problem" of a sound Distribution API? I wouldn't know, but it certainly is a near-perfect summary of how I currently understand the issue ;-) I would just add that, while I would also lean on the side of providing only stateless distributions in the Rand crate, I think it is important not to alienate third parties who may want to use present or future Rand crate facilities with their own stateful distributions.
"Programming Rust" is a marvelous book and getting a copy (albeit digitally) for ~USD15/~EUR12 is an absolute steal. I'll definitely get it even though I own the printed book, just to have something I can easily search through (and to always carry with me on my digital appliances).
Last time I went there I had to go to the US embassy (next to place de la concorde), and took a coffee somewhere. The place was empty, and when I paid the bill we talked a bit but he still sounded unpleasant. Like, I think that's just how the man talked. All of this to say, I think some people there simply don't realize how they sound, which might explain the clichÃ©s about Frenchmen. Anyway, glad you had a good time there! 
Would you recommend that book for people (such as myself) who can get basic things done in Rust but don't understand the type system enough to take advantage of it (and do all the neat tricks that others seem to do)?
Well, just because you can assume people can talk to you in English doesn't mean they are A+ in it...
&gt; I'm sceptical of micro-benchmarks for data-heavy algorithms like both &gt; Ziggurat and ETF Me too ;-) Though table size is not really outrageous for neither Ziggurat or ETF so if cache misses were an issue, I would guess that this is in situations where the distribution is not sampled often, in which case sampling efficiency is unlikely to matter anyway. But to be fair, even if these figures are representative of real use, the "slower" methods for normal distributions are usually fast enough in practical applications. Statelessness is nice though, and the ETF also makes it possible to cheaply sample other distributions that would be otherwise computationally very expensive (if I recall well, the Chi square distribution benchmark in the github repo showed a much larger relative advantage of the ETF implementation). &gt; BTW the link to your Ziggurat implementation is broken. Thanks, fixed!
Why not two traits that a Distribution can implement? E.g. (poorly named): trait StatefulSampler&lt;T&gt; { fn next_sample&lt;R: Rng&gt;(&amp;mut self, entropy: &amp;mut R) -&gt; T; } // Stateless can be thought of as Stateful with a state type of () trait StatelessSampler&lt;T&gt;: StatefulSampler&lt;T&gt; { fn get_sample&lt;R: Rng&gt;(&amp;self, entropy: &amp;mut R) -&gt; T; } This doesn't alleviate the concern of /u/innovator12 about mixing rng's, but unless you're willing to move ownership of the rng to the distribution I'm not sure there is a good fix for that. Maybe marking `StatefulSampler` as unsafe, or documenting it with a big warning that mixing rng's may weaken cryptographic security?
They're providing PDFs directly, therefore I think you're right with your first option: no updates.
No. Just hasn't been done. As long as 7z is a standard CLI too that can do decompression over stdin/stdout, then it should be easy to add with some light refactoring: https://github.com/BurntSushi/ripgrep/blob/master/src/decompressor.rs I'm sure I'll do it myself eventually, but I try to group Windows bugs/features into batches because they come with a very high context switch overhead.
You can still get Oâ€™Reilly products on ebooks.com as soon as they publish, but I doubt if thereâ€™s any updates or errata fixes like the owners site. My Learning Python book still updates from time to time after years of publication, remarkable. 
On macOS it's generally not appropriate to use Cocoa conventions for non-Cocoa things.
We were talking in French 
To handle this you should wrap the rust structs in a newtype and only expose the newtype to your vm. So if you wanted to use chrono you would do: ``` use chrono::{DateTime, Utc}; // note that the internal DateTime is private pub struct DT(DateTime&lt;Utc&gt;); impl DT { ... } ``` Now your VM only ever exposes methods on DT, which means you have full control to swap out the implementation whenever you want, and upgrading your deps is as safe as you can make it.
Under linux, there is usually p7zip (at least as an optional package).
Yup. This is why commercial software often exhibits far nicer behavior in corner cases than open source stuff--someone gets paid eighty bucks an hour to iron out annoyances in the former, but in the latter it's just not interesting.
Thanks I'll keep that in mind!
Personally I'd like to have had the restriction that crate name == package name from the beginning, but it's a bit too late now. The main way I got around the confusion for this stuff was really looking at examples for these crates - how they're used in the README. Luckily most of the ones which do the `xxx-yyy_zzz` pattern are complicated enough that you wouldn't want to use them without looking at examples anyways.
If you need something fast, try rust-coarsetime: https://github.com/jedisct1/rust-coarsetime
You may even get better service by speaking english than non-parisian french. It is a strange city.
Personally, I considered myself in that camp. I got a hard copy and have been reading it intermittently for about a month now. It's been fantastic and I feel a lot more confident in my use of Rust these days. Attempting to write a compiler has helped quite a bit as well lol
I'm also based in Melbourne! This is awesome. ðŸ¦
Whatever is, just make it consistent. When I remember a package name, I don't remember if it's "serde_json" or "serde-json", it's just "serde[some separator]json" in my head and half the time I get it wrong. It's like trying to plug in a USB-A cable too. It seems like you get it wrong *way* more than half the time.
Interestingly, when I ran that I got a stack overflow on that test. Any clues?
I hear "TUI" a lot as well.
@doomsplayer there is this new, still unknown conccurent of spark (because it's new and the README.md is not even in english) But it's in c++ if I remember well, from Baidu (the Google of china) and is made of 171 000 lines of code. I Wonder if it is Faster than Spark (it should be because of C++) Datafusion is still a very interesting project, rust is becoming a better language than C++, especially for Conccurency and security. Anyway don't underestimate (I guess you are the main developper of Datafusion) the potential of code reusing (with bindgen) and of ideas/algorithms reusing that you can take from this project. A good plan would be to integrate a maximum of c++ code for having a Datafusion on par with Spark features wise and beyond, performance wise (if you reach this state, you can probably be funded by big entreprises, even before) and after, peogressivelly replace the bigflow code with full rust code. 
This kind of stings if you just bought this on Amazon. OT: has anyone bought https://www.amazon.com/Rust-Programming-Example-concurrent-applications/dp/1788390636/ The TOC looks great but I have had bad experiences with Packt
Sadly as i have come to expect, people are far too cavalier about unwrap in discussions like these. Panic and unwrap need to be parts of the language but they are highly likely to be abused. Especially as they are generally recognized as OK in tests, they end up in a lot of doctests which may lead beginners to think that they are ok to use in situations they are not. Auditing for panic safety will become very important in the future. Maybe RLS should have an "expression can panic" flag that can be passed to IDEs to aid in this.
I'm seeing what I can do to change [`conrod`'s `TextEdit`](https://github.com/PistonDevelopers/conrod/blob/master/src/widget/text_edit.rs) widget to support password (hidden) and restricted-character inputs. It currently modifies the string in place, so switching it to return a Vec of "text edited" events should allow for any kind of post-processing on text. It seems like a doable task, but since it isn't trivial and I don't have too much time this week, it's what I'm setting out to do.
So, the variables are more like the nodal coordinates, nodal velocities, or various material parameters that could either be located at the nodes or the quadrature points of the element. In my field there are quite a few variables that need to be alive the entire time the simulation is running, since they are required for the updating of the evolution of the material/body. Depending on what the underlying model is to evolve the system, these variables can vary quite a bit. So, I'd like to be able to come up with a nice solution for passing them into the various modules that are used to solve the system. I've dealt with my fare share of nonlinear and linear fem code bases where this was not done compactly/using global/modular variables, and I'd rather not force this upon my users. It really makes introducing new models/code a lot more painful. Overall, I'm just trying to avoid the situation where you might have 10-30 variables being passed into a function. I hope this helps give you a bit better idea of what I'm trying to do. 
Registers don't belong to any process Write any assembly that reads registers without writing them, and let me know what you get Bet it's not zero
They're not another processes' registers when you're running; they're yours. Do the context switch instructions zero the registers?
Programming Rust makes this bundle a steal. I'm buying it despite owning some of these books, it's a good one!
So I've looked through the project's github page and noticed two (for me) rather big issues: No composite primary key support and no non-int primary key support. Since those are open issues I know you are aware of them, but is there any ETA on those features? Also something I've not found anything about: How do you define foreign keys and is it possible to define composite foreign keys (I assume not since composite primary keys don't work). All in all I really like this project though, Diesel never really just worked for me.
I'll be writing posts on a monthly basis. Due to the limited amount of RISC-V hardware available, I may make the kernel/OS 32-bit, so you can run it upon a HiFive1 board (https://www.sifive.com/products/hifive1/). Stay tuned! :)
 self.partial_cmp(other) Is a recursive call you want something more like self.thingy.partial_cmp(&amp;other.thingy)
What do you mean Python 3 did this recently? There isn't a global event loop initialized on import.
By the way, we now have AUR package for cargo-release at: https://aur.archlinux.org/packages/cargo-release 
It's always hard to estimate when a feature will be ready, especially when I only work in my free time on this project, so I cannot really say an estimate (sorry about that).
I seriously think Programming Rust is the best general purpose Rust book out there.
How to unroll an array of values to function arguments? In Python it's easy: ``` a = [1, 2, 3] func (*a) ``` Is there a way to do it in Rust? I've tried with a naive macro but the clippy is complaining about unsequensed reads. Google shows a couple of other ways: [pattern matching](https://stackoverflow.com/a/39879622), [slice patterns](https://stackoverflow.com/a/32325143) and.. that's all, I think. 
How to unroll an array of values to function arguments? In Python it's easy: ``` a = [1, 2, 3] func (*a) ``` Is there a way to do it in Rust? I've tried with a naive macro but the clippy is complaining about unsequensed reads. Google shows a couple of other ways: [pattern matching](https://stackoverflow.com/a/39879622), [slice patterns](https://stackoverflow.com/a/32325143) and.. that's all, I think. 
`AtomicBool` is the Sync-safe cousin of `Cell&lt;bool&gt;` that exposes *all* the tricky technical details of sharing a boolean cell between threads. `Cell&lt;bool&gt;` ignores the details and consequently *anything* could happen if you share it between threads. This is bad but Rust will keep you from doing it. (By complaining about the "Sync trait bound".) 
How do functions like `map`, `take_while` and others take a closure as a parameter? When I try to define a function like this, for example: fn map_in_place(arr: &amp;mut [i32], func: Fn(i32)-&gt;i32) It tells me that `Fn(i32)-&gt;i32` does not have a fixed size at compile time, which makes sense. It also tells me that I can fix it by making the parameter a reference, which makes sense. But then you have to put `&amp;` in front of the closure when calling the function, which is unsightly and seems unnecessary. So how do `map` and friends take a non-reference closure?
It does say "multiple formats"... not sure what those are.
I believe the Cargo team is on board with this approach. It is being tracked in [rust-lang/cargo#2775](https://github.com/rust-lang/cargo/issues/2775).
The available file formats are pdf, epub and mobi.
I am 95% sure the tools needed to compile for Apple are distributed by apple as a part of their developer program, and therefore, only work in macOS land.
Thanks. I'm probably going to buy it at the $15 tier. There's enough there to justify it, even without updates...
Sure! When you write pub fn from_cache(id: &amp;str, cache_path: &amp;Path) -&gt; Result&lt;Chunk, Error&gt; {} You can instead do that: pub fn from_cache&lt;P: AsRef&lt;Path&gt;&gt;(id: &amp;str, cache_path: P) -&gt; Result&lt;Chunk, Error&gt; {} Which avoid having to deal with paths at higher level, just types that you can ref as Path, like `&amp;str`/`String`
They use generics and let the compiler fill in the correct type. Try this: fn map_in_place&lt;F&gt;(arr: &amp;mut [i32], func: F) where F: Fn(i32)-&gt;i32 { ... } This let's you pass in any `Sized` thing that implements the `Fn` trait. A closure satisfies both of those things. The cost is that because of monomorphization you get a separate version of `map_in_place` for every different `F` you pass in, which means one for every distinct lambda or function.
AFAIK they restore the registers, e. g. load the spilled registers from the stack when a context switch occurs, so that you canâ€™t access the contents of another process XMM registers, since the OS overwrites those contents during the context switch. If you have proof of it not being so, then you have found a really serious (and exploitable operating system bug) that doesnâ€™t have anything to do with using assembly for implementing crypto primitives or not. 
No, but Guillaume Gomez is on the docs team here, if that factors into your decision.
Hard to get a concrete answer. Seems like a combination of this and their kernel causing issues for that cross-compile border.
Most of the games I got from their bundles have been downloaded from HB and updates to them have also been available via HB, so it is quite possible they will provide updates as well.
&gt; For something less (?) generic I can easily see a OS being a smartass and having a 'output directory' that when a 'file' is created there and pumped bytes it's actually blocking on reading from another process and doesn't actually consume any appreciable memory or disk. Unix has `mkfifo` which creates a FIFO buffer file, or a so called named pipe, with an arbitrary, small buffer size (at least in Linux it's adjustable with `fcntl`, defaulting to 64k). A program writing to a FIFO will block once the buffer is full, and a program reading from it will be blocked block once the buffer is empty. Not sure this is exactly what you mean. You could of course also implement a user space file system with FUSE that employs these semantics on a directory level. &gt; I suspect it would be prone to accidental errors though. Zero filling files before 'actually writing', temporary files, the reader program needing to rescan the dir for 'new' files after each full read, race conditions etc. Named pipes can't be zero filled because you can't seek through the buffer, so you get out exactly what you put in in the same order. The kind of race condition they are subject to I guess is if multiple files try to write to/read from the same buffer, and the solution is similar to any multiprocessing problem: use locking, multiplexing or some abstraction thereof to make sure that there is only ever a single reader and writer at a time. And you still have the problem of a producer exiting early, while the data is incomplete, if you ever had it.
Iâ€™m not arguing either way here, but I could swear Iâ€™ve heard Sean Griffin say that diesel isnâ€™t really an ORM. I just checked their site and it says itâ€™s an ORM *and* query builder. ðŸ¤·â€â™‚ï¸
Agreed. Going back in time, I probably would have preferred kebab case instead of snake case in Rust itself (looks better), but itâ€™s too late for that now. Consistency is preferable now!
Me too, but that ship has sailed! Better to have consistency now.
It is absolutely possible to be too balanced! Sometimes a heavy-handed approach is the only one that works.
You can't because "some separator" has not been defined... I'm also using crates.io to get the correct syntax...
I know about mkfifo and have used it before when i had to deal with inter-process communication in bash scripts, however it's not really suitable for a 'transparent' extension to producer programmers. The 'problem' - if you can call it that - is that every unix program that outputs multiple files doesn't even try to output to stdout, which is the traditional alternative to writing files out, precisely because the pipe can't deal with cardinality 2+ content without some kind of protocol (which doesn't exist). 
I was talking about it in context of stack-full coroutines with M:N work-stealing scheduler, not in general. In that context, it is impossible to handle it appropriately â€’ because the objects can live on the stack and there's no way to know if the whole stack is Send. This is not the case if the stacks don't move between the threads. And it is not case with futures or generators, because these are â€žjustâ€œ objects with appropriate traits.
So there *isn't* a way to crosscompile macOS in linux without drinking the kool-aid even for something that uses its own build system like cargo? Pretty sad.
Have a look at the RFC, it should provide a pretty comprehensive account: https://github.com/rust-lang-nursery/futures-rfcs/blob/master/futures-02.md
I'm kind of annoyed it's only $15 for the rust book PDF but I prefer a hard copy I guess so I think it was worth the $40 some odd dollars I paid on amazon. I'll probably still get the bundle anyway. 
Yes. I'm a rust beginner and the book is a fantastic reference source. It's even good to just read honestly. It's well written and the examples are very clear. I'm glad I picked up a hard copy but I'll still get the bundle. 
It's not my fault they told me it was safe and then the rug was pulled underneath me. Nuh uh.
This one post will be useful: https://cafbit.com/post/tokio_internals/
And of course, I saw this post 1 minute after ordering "Programming Rust" from Amazon for 50 bucks... But in the end, I wanted the book physically anyways, so nothing lost :)
Well, why don't you open a PR for the warnings? Seem worthwhile to warn the hapless dilettante dev. I've only used them in java on a application, and even then i found the idea of a global cache a bit strange even if it use thread weakreferences or something like that. It's a good idea to warn people if rust as even less guarantees about drop time than a gc language.
But what does it do better than diesel? Why / when should one choose it instead of diesel? 
&gt; but it isn't possible in source code since `x-y` isn't an identifier Coming from the Lisp world, this is the real travesty ;-)
I once tries cross-compiling from Linux to MacOS and found it nigh on impossible. The platform is proprietary and necessary tools like the linker and libraries are only available for a Mac and if you are part of their developer program. It's a sad day when it's easier to cross-compile to M$ (via the gnu toolchain and mingw) than to another *nix variant...
Can't say i'm surprised.
IME many bundles (the older ones anyway) provided a choice of HB or Steam keys.
Yeah, I think you might be right. I'd already been thinking along those lines anyway now that I've finished going through all the examples in the book. I'm probably going to need to prototype a couple different solutions first. Since my goals are to eventually open source this, I'll probably be back on here once I get the chance to really work on it and have an initially working code. I'm just hoping getting the last paper done for my thesis doesn't push back my ability to work on this too much though.
`const fn` is extremely limited in what it can currently do, `macro_rules!` are a beast though.
This paradigm doesn't really map well to Rust because a function that takes several arguments of the same type should just take an array or slice, so there's no need to expand the array at the call site. Otherwise if there is a unique meaning ascribed to each argument, that would be lost if they were all stuck in the same array and so it would actually be worse for readability to support this.
That's some awesome feedback. Thank you. The current row-based code is indeed very naive and I'm still learning Rust. I know that moving to columnar processing makes senses but I don't have experience with that yet so it may take me some time. The specific coding feedback I can start implementing during my next sprint a.k.a. weekend.
There is no reason to go lower level than mio.
Sounds really great. I look forward to using it.
You're probably more interested in the new procedural macro system. Searches for "proc-macro2" should yield good results. The rocket web framework and nrc's async/await crate are based heavily on proc macro 2, so looking at that code should give you examples of what can be done. It's sort of unclear to me how close the feature is to stabilization, it wasn't in the roadmap but I think it's mostly implemented and there are some heavy hitting features that depends on it so... Maybe this year? There are also, I believe, some unresolved hygiene questions, though, so maybe 2022.
So do I, hence my answer. I think it was in one of his podcast.
One is not better than the other: they uses different approach. I'd say that tql gives at convenience at the cost of flexibility.
I like this post https://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/
Especially if you consider that you get a bunch of other oreily books with it. These books are good, instead of that packt bullshit.
[removed]
Love the flair! Cool I will take a look, however, the last example is kind of a sweet cherry on top syntactic gift of this new method. The macro does not include the else it just expands to an if which the else then attaches to because it becomes valid rust code: It is equivalent to the following is the current syntax: unless! { var { expr }} else { expr }
I have taken a look and know I remember, that is exactly what I want
&gt; The macro does not include the else it just expands to an if which the else then attaches to because it becomes valid rust code: Most likely, this will never be supported. A Rust macro **must** expand to a complete, valid construct. You can't have a macro expand to half an `if ... else` block. That's a deliberate design choice so that we never have to deal with the hell of C-style preprocessor macros that are impossible to understand in isolation because they could expand to anything.
Oh, should have mentioned this in the title, these are ebooks, not hardcopies.
Video linked by /u/UtherII: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Reaching const evaluation singularity An introduction into miri and Rust's const evaluation](https://youtube.com/watch?v=Zz863ksXRhA)|FOSDEM|2018-02-05|0:23:29|2+ (100%)|51 $quote by Oliver Schneider At: FOSDEM 2018 Room: H.2214... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/UtherII ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=$comment_id\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
So I would argue that an if statement is a complete valid construct by itself without an else statement. I think that I don't think that making expansion of macros happen before validating the tree would not lead the the C preprocessor hell that you think it might since the macros still have to produce valid code themselves, that is checked before any use of it. So it would be less of not understanding it in isolation but more of augmentation at use, which I think it really cool.
&gt; So I would argue that an if statement is a complete valid construct by itself without an else statement. It is, but an `else` clause is part of the whole, not something separate. The structure of the language would have to change to allow the thing before an `else` to be something other than an `if`. &gt; I think that I don't think that [...] The tree isn't validated in a separate step, parsing macros is literally part of parsing regular Rust code. To put it another way: macro expansion is not a separate phase like in C, it's just a language feature. Macro invocations are part of the AST of the language, so you can't just drop them wherever you want. This is important because it means when a macro invocation appears in expression position, it can **only** expand to an expression. When one appears in item position, it can **only** expand to an item. This radically simplifies reasoning about code involving macros, since they can't be used to "cheat", and it keeps the effects of their expansion contained. It also means things like IDEs, and syntax highlighters, and code formatters have a simpler job, because a macro in expression position can be treated just like any other function call. This is all deliberate, and by-design.
Any updates to "Programming Rust" will come in the form a new version. It is edited and done.
But if parsing macros is part of parsing regular rust code then why would an expansion of an macro to an if statement not then happen before the else clause and then the else would just match up while parsing? From what you just said and my experience with compilers that is what would happen. Also `if` is an expression so it would expand to an expression. Also, I can actually only think that this would/should work with if statements since AFAIK it is the only expression that can tie together with other statements, ie `else if` and `else`.
For OS-level things in C, I am assuming you want to learn about Linux (and POSIX). You should read this: http://beej.us/guide/bgnet/ It is focused on explaining networking and TCP/IP. It first does it using synchronous I/O and forking multiple processes and then explains how to use the OS-level `select` async construct to do it from a single process. It should explain the basic logic and reasoning to you. By the end of it, the fundamentals of async should make sense to you. After that, you should have a look at the `select` and `epoll` man pages to see how `epoll` differs from `select`. `epoll` is the preferred mechanism on modern Linux and what `mio` is built on. `select` is POSIX standard and not Linux-specific, but more inefficient. Other OSs have their own preferred mechanisms for doing things. You can then have a look at `mio`. It is essentially a Rust-y abstraction over the same principle.
I feel like that for someone who is coming from a higher-level background like you, Rust should be a lot easier and more approachable than C/C++. Yes, there is a steep learning curve that you will have to face, but I like to say that the learning curve is for learning low-level systems programming, not learning Rust specifically. In Rust, you will have the compiler spamming you with (often useful) error messages, which might seem annoying, but you should treat them as learning opportunities. A problem with your code found by the compiler is a problem with your code that won't come to haunt you later and force you to spend hours debugging things at runtime. In C/C++, you will have to learn to reason/think about a lot of the same things as in Rust, but they will not be explicit in the language and the compiler will happily let you shoot yourself in the foot if you are not careful.
There are people in the community who plan on doing this. https://internals.rust-lang.org/t/so-you-want-to-hack-on-the-rust-compiler-a-plan-for-a-book/6497
&gt; quicktype generates strongly-typed models and serializers from JSON, JSON Schema, and GraphQL queries, making it a breeze to work with JSON type-safely in any programming language. To check it out head over to https://app.quicktype.io/#l=rs and paste some JSON in the left-most textarea. There is a follow-up ticket currently open to improve some things in the initial implementation which you can view [here](https://github.com/quicktype/quicktype/issues/516).
[I'm taking this course right now on my own time, this lecture (~1hr) in particular covers the topic well IMO.](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-033-computer-system-engineering-spring-2009/video-lectures/lecture-7/)
Oh, is Twitch using Rust in production?
I'm not aware of anything in guide-format, but there is a lot of documentation written about the compiler. https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md covers the basics and links to https://forge.rust-lang.org/ which is a list of out-of-tree docs. There's also documentation in the compiler itself. Much more than there used to be. Niko Matsakis must have spent a lot of time on these READMEs: https://github.com/rust-lang/rust/blob/master/src/librustc/README.md Compiler code is also usually well-documented. It's not uncommon to see a thousand-line comment detailing the design of a module, or a hundred-line comment explaining why these two lines of code are right here. Granted, these resources aren't very good for satiating a casual interest in the design, but they are really good if you want to work on the compiler.
Take a look at [`proc-macro-hack`](https://github.com/dtolnay/proc-macro-hack) if you plan to write your library for stable.
Even using nightly rustc and `--pretty=expanded` the output of just a similar macro as that outputs a valid if block, but for some reason if I add an else it does expand the if but it doesn't recognize that with the preceding if expression. 
What does this framework solves that can not be solved with existing frameworks? 
Lets say you have something like this: { let var = true; unless! var { expr1 } else { expr2 } } Which gets expanded to { { let var = true; if !var { expr1 } else { expr2 } } } This (super roughly) gets parsed as this syntax tree: &lt;block&gt; | |- &lt;let&gt; - var | \ | true | |- &lt;if&gt; - &lt;!&gt; - var | | - expr1 | | - expr2 If I encircle the macro: &lt;block&gt; | |- &lt;let&gt; - var | \ | true | --------------------------- | |- &lt;if&gt; - &lt;!&gt; - var | | | | | | - expr1 | --------------------------- | | - expr2 The macro is not a subtree! And that's a problem, because the requirement is "[Even when Rust code contains un-expanded macros, it can be parsed as a full syntax tree.](https://doc.rust-lang.org/1.7.0/book/macros.html#syntactic-requirements)". This does not hold in the example, because - as can be seen in my diagram - `else { expr2 }` can not be parsed as full syntax tree before expanding the macro. 
whoah, I've never seen this quicktype thing. This looks awesome! It would allow me to delete so much code in my rust/typescript project...
If I may, in the **fast** section, would you consider indenting "Requests" and "Transfer" and putting a separation line between different sections? At the moment, it's not very readable :x *Note: the absolute best would be a table/graph, but we all know it's more difficult :p*
Thanks for your work :)
its express inspired. just like Nickel, which is not async (yet)
great point, I can totally do that!
beating rocket is not that hard, you should compare with plain hyper
In addition to being async (woot!) it also takes the Koa model of middleware being applicable in both directions, i.e. on the way in and out, in order to allow paradigms like route profiling more easily. 
It's such a good application for rust's speed, I'm not surprised! Would love to see your work too for inspiration.
do you use ROCKET_ENV=prod on the rocket benchmark?
You can cross compile to Mac, but you can't sign. I only ever got cli stuff to work, was trying to put together a guide for gtk but couldn't get it to build.
:O Perhaps this would let me sunset https://github.com/Marwes/schemafy (generating rust structs from json schema).
I think any framework with middlewares support works this way
but is this enough to build new framework? what else does it provide that make it more usable that others?
kebab-case is best case!
the goal is to provide a fast framework in Rust that is built upon ideas of proven and popular frameworks. Searching through various other frameworks in Rust, I didn't find one that checked both of those boxes for me.
Please let us know if we're missing any features you need. And please consider contributing ;-)
u/Fylipp u/chicagobearsrocks u/loewenheim u/mitsuhiko u/CornedBee u/cluosh I've created a Meetup group to make it easier to coordinate and organize the next meetup. Please join there and promote it. I've contacted sektor5 about getting a meeting space again. https://www.meetup.com/Rust-Vienna/
I have two `Vec` (of the same type), I want to move the entire contents of one to the other efficiently, dropping the contents of the replacee. Fundamentally, this is: a.clear(); for i in b.drain(..) { a.push(i); } But this should be possible in constant time and no allocations. 
Emphasis on the "dreaming" here, I have it in my head but haven't had the time to actually implement anything.
It would be nice to see a minimal example near the top of the readme.md. The hello_world example is already including JSON responses, I just want to see a tiny piece of what the code I would write when using this library will look like.
bad bot.
Thank you Jonhoo for voting on resavr\_bot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Unsure, I am not affiliated. Their tool is in Go, but I read [this blog post](https://blog.twitch.tv/twirp-a-sweet-new-rpc-framework-for-go-5f2febbf35f) and agree with it. gRPC adds a bit too much complexity for simple web service use.
You definitely cannot do this in constant time, because dropping all elements in a vector takes linear time in the general case. To make it more efficient you can change `for i in b.drain(..) { a.push(i); }` with `std::mem::swap(&amp;mut a, &amp;mut b);`, as the vector `a` is already cleared.
Obviously the drain approach is constant time, but using `mem::swap` answers my question.
Anyone know if the other books in the bundle are any good?
I don't know much, but I'll try to help by looking through the API docs since this is an old-ish question. `ServerConfig::new()` takes a `ClientCertVerifier` which is a trait from `mod verify`. There are 3 `ClientCertVerifier`s there, which I'll describe based on the docs: - NoClientAuth - Doesn't do client auth. - AllowAnyAuthenticatedClient - Requires client auth and validates the client certificate using the given root cert store. I assume that "without any name checking" means that you can't give it a whitelist of Common Names to accept, it'll take any valid client cert. - AllowAnyAnonymousOrAuthenticatedClient - Does client auth if offered, but doesn't require it. The trait isn't exported, so you can't create your own. &gt;How would one do mtls here? Use `AllowAnyAuthenticatedClient` with a root cert store containing your root cert. &gt;If I wanted to get the example working, how would I go about generating my certificate and keys? I expect I need a certificate and then a private key for the server - then I would generate public keys for every session and send those to the client, right? I've never used client auth, but from what I understand you don't need new public keys for every connection. The public keys are used to transmit the symmetric key which is unique per-connection. For generating the keys, I'd suggest using https://github.com/OpenVPN/easy-rsa. It's designed for OpenVPN, but I believe it'll work. Create a CA, then create and sign keys for each client. Add your CA root key to the `RootCertStore` that you pass to `AllowAnyAuthenticatedClient::new()`.
This is just the first step towards producing truly awesome documentation for https://github.com/Byron/share-secrets-safely . The next step is to implement `terminal playback` of pretty-printed markdown documentation, which makes it easy to create reproducible `asciinema` recordings.
The usual way in Rust to support some kind of complex pile of arguments is to have an `Arguments` structure that the caller creates. Combined with `Default` and `Option` this can easily be similar to named arguments in other languages. And a variable number of arguments would be expressed through `IntoIter&lt;Item=&amp;Trait&gt;`, which can be called like `f([&amp;a1, &amp;a2, &amp;a3])`. If they're known to be the same concrete type, you'd use that type, possibly `&amp;[T]` depending on a speed flexibility trade-off. A mixed bag, like the arguments to `printf`, could use the `Any` trait - but that means type errors would only be detected at runtime, like Python. (Rust's string formatter is heavily metaprogrammed, which allows it to do better type checking at compile-time.)
Drain and push in your example *is* non-allocating, but it is linear time. Even a `memcpy` is naturally guaranteed to be linear time. I think you're misunderstanding "constant time". `mem::swap` will actually swap `a` and `b`, which are basically fat pointers to their in-memory buffers, so that should be more efficient than "drain and push" in that regard, but it will still take linear time to drop `b` if `b`'s elements implement `Drop`. If they don't implement `Drop`, then this discussion is largely moot, because the entire allocation can just be deleted at once, with no need to run `Drop`.
I can still see there being a use for a pure-Rust solution, since quicktype is implemented in Typescript and I can imagine projects who wouldn't be keen on adding another language dependency.
I have the body of an HTTP request which implements `std::io::Read` (https://docs.rs/reqwest/0.8.4/reqwest/struct.Body.html). I'm trying to first generate a hash of the content (using `crypto::sha2::Sha256`) as well as write the content to a file (using `io::copy`). The problem I'm running into is that after the hashing function reads through the data there's nothing left for `io::copy`. Is there a way to "rewind" somehow? Or should I be looking at some other datastructure to wrap the response body? Thanks!
Looks very nice indeed.
&gt;What you've described technically already exists. Doesn't that work only for `macro_name! ident {block}` constructs?
can you explain how you created those benchmark results. It looks overly slow in my opinion. a plaintext benchmark looks like this on a low specs machine wrk -t2 -d20s -c100 http://localhost:8080/plain Running 20s test @ http://localhost:8080/plain 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 45.94us 258.41us 37.99ms 99.58% Req/Sec 197.50k 18.64k 214.74k 92.00% 3932146 requests in 20.02s, 22.57GB read Requests/sec: 196387.48 Transfer/sec: 1.13GB
not true, express isn't like this
Did you mean to post this somewhere else?
can you explain how you created those benchmark results. It looks overly slow in my opinion. a plaintext benchmark looks like this on a low specs machine with rocket wrk -t2 -d20s -c100 http://localhost:8080/plain Running 20s test @ http://localhost:8080/plain 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 45.94us 258.41us 37.99ms 99.58% Req/Sec 197.50k 18.64k 214.74k 92.00% 3932146 requests in 20.02s, 22.57GB read Requests/sec: 196387.48 Transfer/sec: 1.13GB
yeah, thanks for your notice!
The easiest thing would be to use `Read::read_to_end` into a buffer, and then do both operations with that. I assumed that there would be a `Tee` adapter in std somewhere. It turns out that there [used to be one](https://doc.rust-lang.org/1.4.0/std/io/trait.Read.html#method.tee), but it wasn't stabilized because if one of the writers returns an error they'll get out of sync. You can still get the same functionality using the `tee` crate from crates.io. &gt; Is there a way to "rewind" somehow? `Body` doesn't implement `Seek`, but if you wrap it in a `BufReader`, you can then `.seek(SeekFrom::start(0))` to go back to the beginning. If you're starting with a `Response`, you could also just call `Response::copy_to` twice.
he probably run rocket in 1 thread. 200k for rocket seems good, i've never able to get such results from rocket.
You are right. I just forgot to mention that it's for ffi glue: incoming arguments come as an array of variant-like types (or json, whatever), and I would like to unpack and transform them to Rust typed arguments. Something like ``` fn convenient (a: bool, b: i32, c: String); extern fn on_event ( args: &amp;[Variant] ) { convenient ( /* magic */ ) } ``` 
The dino book? Thanks for mentioning this, I'm visiting my folks only for a few weeks and almost forgot I wanted to bring that textbook home with me.
I'd rather not load the whole thing in memory if I don't have to. I like the `BufReader` approach since it seems to operate over chunks of the underlying reader, however, it looks like `Seek` is only implemented if the underlying reader is also seekable. Am I misunderstanding? I assume that after reading through the first time, the whole thing ends up buffered somewhere in the OS? Or does the OS only buffer chunk at a time? Maybe it's just impossible to do what I'm attempting w/o loading the whole thing into program memory?
another related idea would be a $self expression? (macros that look like method calls e.g ```foo.something!{...}``` foo=$self) , but something more general like this would be nice. I do find the nesting levels jarring .. I wish I didn't care as much as I do
Another thought: the hash determines the filename which is why I was reading through twice but I'm thinking I'll just read through a single time, updating the hash and writing to a tmp file. Then I'll just move the file into place afterward.
Oh so this would replace `something!(foo, ...)`? I think that the biggest problem with that is what would it mean, would you type check on Trait? so would it be `$self&lt;Trait&gt;`? Because as Quxxy has said, the macro is supposed to be completely self contained. I disagree that it should be that strict always but in this case I agree with him
it wouldn't do any type dispatch - it would purely be a syntactic convenience, to make it visually fit in with method call based code (chain ability, readabilty); however consider that with macros being intended to handle use-cases like variadic args, that might be nice
And truthfully, this isn't perfect, and given example JSON it errors on the side of making values larger than they need and only makes types for what it sees (which is obvious and correct), but if you don't have a good schema (or more accurately the schema no longer *completely* reflects reality), so additional manual steps are warranted. To me Quicktype seems less a build tool, and more an IDE addon or code helper. That's fine though, because it's still really useful in that role.
You could use the [`owning_ref`](https://kimundi.github.io/owning-ref-rs/owning_ref/index.html) crate to construct an `OwningHandle` that does roughly what you're describing. It's _almost_ simple, but you'll need some unsafe code to make it work. There's a comment in the `owning_ref` source about why: // NB: Implementing ToHandle{,Mut} for Mutex and RwLock requires a decision // about which handle creation to use (i.e. read() vs try_read()) as well as // what to do with error results. Doing this sort of thing is Kind Of Black Magic, though, (even apart from the unsafe code) so I wouldn't do it unless you're pretty sure there's not an simpler way to solve your problem.
I understand but `$self` is not currently a designator so I am slightly confused about what it would do asides from maybe replacing an `$ident` of a variable.
Yeah, having an unsafe block is too scary when it's a pretty isolated piece of code. I feel like what I want should really be in std's `Arc` itself.
it would just fit the pattern of declaring a 'receiver' for a method-like macro .. in rust you expect a receiver to be called self
&gt; I'd rather not load the whole thing in memory if I don't have to. I like the BufReader approach since it seems to operate over chunks of the underlying reader, however, it looks like Seek is only implemented if the underlying reader is also seekable. Am I misunderstanding? No, you're right. I missed the seek bound on the impl, sorry. I assumed that `BufReader` would hold the whole thing in memory itself. &gt; I assume that after reading through the first time, the whole thing ends up buffered somewhere in the OS? Or does the OS only buffer chunk at a time? It's my understanding that under normal operation, data for a socket is discarded as soon as you `read` it. (The exception is `MSG_PEEK` for `recv` which I don't think would be useful for this type of thing anyway) The OS will keep buffering data if you wait a while between reads or if you ask it to fill a big buffer, but usually HTTP clients will read a small amount at a time so that they can begin processing the data while more is still incoming. This question got me curious, so I went and looked at how requests implemented the response body. It's just a read wrapper around an async Stream, so I think that calling `copy_to` twice as I suggested earlier wouldn't work because it'd return `Ok(0)` the second time as the stream was already consumed the first time. That was not clear to me from the documentation. &gt; Maybe it's just impossible to do what I'm attempting w/o loading the whole thing into program memory? I wouldn't say impossible, the `tee` crate I mentioned before would work for you. And thinking about it again the issue with a writer returning an error wouldn't matter to you since the hasher would never error, right? Something like this: let mut reader = tee::TeeReader::new(response.body, hash_writer); io::copy(reader, file)?; Also there's probably a way to do this with tokio and have both readers run in parallel, but I don't know enough about it to suggest a solution. 
I think the `owning_ref` crate does a good job of illustrating how general the problem is. Look [at all the implementations](https://kimundi.github.io/owning-ref-rs/owning_ref/trait.StableAddress.html#impl-StableDeref) for `StableAddress`, for example.
It's not possible to pick one style without discussing which style to pick. Better to let this dog sleep, mon frer.
Nah, I feel like this boat's already sailed. :)
It's just that, hmm, it's *too* generic. I want to take the result of `RwLock::read()`, and pass it to a function like `Arc::clone` that also wants its original `Arc`, like `fn Arc::clone_with&lt;T&gt;(&amp;self, other : T) -&gt; Arc&lt;T&gt;`
There's also transform.now.sh
Hmm... looking at it more I might be able to use them _together_ to accomplish what I need.
You could do something with traits to make the call site a little nicer, although it just moves the boilerplate somewhere else: pub trait ExpandArgs { type Ret; fn expand_args(self, args: &amp;[Variant]) -&gt; Ret; } // you could generate this with a macro that takes `A: 0, B: 1, C: 2...` as input // it can also be implemented for closures I guess impl&lt;A, B, C, R&gt; ExpandArgs for fn(A, B, C) -&gt; R where A: From&lt;&amp;Variant&gt;, B: From&lt;&amp;Variant&gt;, C: From&lt;&amp;Variant&gt; { type Ret = R; fn expand_args(self, args: &amp;[Variant]) -&gt; R { (self)((&amp;args[0]).into(), (&amp;args[1]).into(), (&amp;args[2]).into()) } } extern fn on_event(args: &amp;[Variant]) { ExpandArgs::expand_args(convenient, args); }
This is the first Denver/Boulder rust meetup after more than a year without a meetup. We still have room on the agenda for more speakers. First-time speakers are welcome and rust beginners are welcome to speak.
It's not that your idea is not useful, it's that implementing it would break a batshit ton of stuff.
This isnâ€™t possible now in that form, however you can write custom derive that would prepare such structure for you. In Rust it is generally called builder pattern and you can try to search using that term. 
You can do that with derives in Rust (instead of a language/type system built-in like in TypeScript). Searching for "derive option" on crates.io gives me: https://crates.io/crates/optional_struct
Fanta is built on the same thing that Hyper is built off of, Tokio cores and Futures. The reasoning behind not using Hyper was to simply be closer to the action. In the future I can see the framework migrating to Hyper relatively painlessly.
So it's like Rack middleware? While I understand and appreciate extensibility of such frameworks, I think there is nothing better than [webmachne](http://webmachine.github.io/images/http-headers-status-v3.png).
I'm not sure what the exact reasoning is for not having `with_mutex`, but the behavior is very easy to replicate with existing methods: let ret = a_mutex.lock().map(|x| x.some_mut_method()); works exactly like your example, if I understand it correctly. This will block the current thread on the mutex, run the method with it locked, and unlock the mutex afterwards. `ret` will be an `Error` if the mutex is poisoned - in which case the method is not run.
My computer is really old :( Also, since I ran those Rocket has made some solid strides in speed since I ran those. Fanta doesn't blow it out of the water now, but it does beat it by about 10%. Thanks for pointing this out though, I'll have to update those benchmarks and add my methodology! 
Yep.... That's about the size of it. We now have to spend 6 grand on on two Imacs to enable building. More than 4 PC's costed.
There's no plain C target :)
You could always use a cloud provider with details of the instance/provider for a comparison others could have access to and use to compare I guess? AWS has a free tier for one year, and others like Digital Ocean or Vultr I think have some free credit upon signup(Vultr if no active promo might have to wait 2 weeks or so for an e-mail about it, I think it required a deposit(like $5) to avoid bots/misuse, they also give credit for linking to twitter account atm).
I saw the description of quicktype mention GraphQL queries... how exactly does that work? Is that just not one of the examples? I've been looking for a good solution for making nice GraphQL clients in statically typed languages including Rust.
I wish I'd known about this tool before! There have been a lot of times I've wanted to easily convert a json object to another language, this would have been perfect! Definitely keeping this in my back pocket for the future.
So basically what I want is that but through macro_rules 
Definitely. I'm actually working on submitting it to the TechEmpower benchmarks as well!
I disagree that it would break a lot of stuff since currently there is no item that compiles with this. From an implementation standpoint it should not be that hard
[Link to type safe builder crate.](https://crates.io/crates/typed-builder) Also, I haven't had a chance to try it out yet, but maybe [Frunk](https://github.com/lloydmeta/frunk#hlist), the latest attempt at HLists and such, will do what OP is looking for.
It's not about picking one style, it's about how to handle it once it has been picked.
Would you like to contribute one? ;-)
Ah, got it. The where was throwing me off.
Here's a blog about quicktype's GraphQL support with examples: https://blog.quicktype.io/graphql-with-quicktype/
I made the changes as suggested, but I'm running into one function that I can't modify. `pub fn from_path(...)` seems to be the one thing that isn't working, since I can't seem to switch to what you recommended. I've tried the following: `pub fn from_path(path: &amp;Path) -&gt; Result&lt;Bundle, Error&gt; {` -&gt; Works, but doesn't follow what you recommend. `pub fn from_path&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;Bundle&lt;'a&gt;, Error&gt; {` -&gt; Doesn't work. I'm getting the parameter type P may not live long enough when I try to do `path.as_ref()` when building the bundle struct. `pub fn from_path&lt;'a, P&gt;(path: P) -&gt; Result&lt;Bundle&lt;'a&gt;, Error&gt; where P: AsRef&lt;Path&gt; + 'a {` -&gt; Doesn't work. Apparently the 'a is shadowing the 'a for the struct.
The point isn't that it isn't possible, it's that it isn't possible with the current system. The current system guarantees that full syntax trees exist without executing any macros. You'd either have to separate `else` completely from `if` and let it stand on its own, or abandon this ability to have the syntax tree without macro expansion. Both would degrade the quality of tooling, and make maintaining the ast more complicated than it needs to be.
When working with streams from another thread, it sometimes seems like it would be useful to have a certain function run every time the stream sends something to the receiver. Ideally this would work asynchronously on the main thread. I know this is quite simple using callbacks in JavaScript, but was wondering if there is an equivalent in rust. Using methods such as for_each and and_then seems like it would work, but they require continuous polling/block the thread. They also seem to be more of a one time use thing. 
Yesterday I was spending some time on perusing artifact, and I am loving the 'heart' of the project! It seems you are truly behind it, which makes sure it is only the best of the best experiences :)! Also I am wondering if I will ever get to use it myself, it certainly needs some education to make teams work with it. I love the idea of pulling in external files into codeblocks, maybe even with boundary markers to be able to cut only portions of them. That feature I would happily implement, as it's yet another way to keep your code tested. That I happily implement next, it's not a big deal. Regarding the hidden code you are mentioning: that's already possible with the `hide` tag, in conjunction with `prepare` and `use`. Last but not least: The way I see `waltz` (thank for the hint - I perused it and loved the pure-rust CLI testing) it will write codeblocks into files, making the markdown book the authority. Right now I would be hesitant to implement something like it, just because I have trouble seeing the use-case.
If you have any trouble with it, please let us know!
I know this is fairly simple to do with `tokio`, but that's a whole architecture one has to adopt if you aren't already using it. If you want to run it on the main thread, what's the main thread doing otherwise? I mean, to run stuff asynchronously, you generally have to be polling things or have something like `tokio` managing your thread.
That's basically the builder pattern right? I have seen several implementation using rust macros.
Our next release will have every service crates' documentation link to its API documentation: https://github.com/rusoto/rusoto/pull/962 . ðŸ‘
`include-file` is now implemented on master. Needs docs and some more tests, but it's there as a PoC. Please let me know what else you need, and chances are I will implement it for you just because all of this is quite straightforward (and I want artifact docs to be most awesome).
Actix-web all the way! ;)
I sent a PR showing where the problem was, as it's probably more evocative.
Exhaustive? Sadly, it's barebones compare to a full-blown datetime library like [Joda-Time](http://www.joda.org/joda-time/), which can do a lot more than chrono.
But it seems that the handler itself cannot be async, right? That's a lot less useful in the long run.
Please let's all nominate and vote both quote and crate of the week so we'll have something to put there next time, 'kay? Thanks!
&gt; Please let's all nominate and vote both quote and crate of the week so we'll have something to put there next time, 'kay? Thanks! !nominate
There is also https://github.com/projectfluent/fluent-rs which isn't listed on the arewebyet site. I am not able to speak about its quality as I never have used it.
Yes. I was naively hoping we could drop stateful samplers, but apparently it's not that simple. Separation of distribution and algorithm appears a bit pointless; one cannot simply specify distribution and let the compiler pick an algorithm. Besides, algorithms generally only approximate a distribution. Separating out state, on the other hand, may be more useful (e.g. in a simulation you would need to store both stateful distributions and distribution state, but have no need to store stateless distributions anywhere).
Unless I'm confusing things, the update to LLVM 6 seems to have gone much smoother than the update to LLVM 5. Is this accidental, or has their been a change in the way LLVM and/or rustc are structured that eases upgrades to new versions?
This example for [std::sync::CondVar::wait_timeout](https://doc.rust-lang.org/beta/std/sync/struct.WaitTimeoutResult.html) does not do what I expect; the condition does trigger on the signal, but does not timeout. I pushed the time in the thread up to 1000ms, and still did not get 10ms timeouts, only after 1000ms. (It did know that it had timed out). I know that this is not an exact business but would really expect to get a timeout _around_ every 10ms.
example // declaration macro_rules fwrite! {($self:expr,*($x:expr),)=&gt; $(self.fwrite(x))} // use if let Some(my_file)=file_open(..){ my_file.fwrite(a,b,c,d); my_file.fwrite(e,f); my_file.fwrite("foo","bar","baz"); }
You might be interested in [some more falsehoods programmers believe about time.](http://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time) To which I would add: * Timezone offsets are in the range [-12,12] * Ok, *non daylight saving* timezone offsets are in the range [-12,12], right? Time is surprisingly hard if you want to expose something more structured than â€œhere's a counter approximately synchronised to some vibrating piece of quartzâ€.
That was just my first intention. Actually it will execute whatever you put there, so saying `fish` instead of `bash` will do exactly what you need. Anything works there, it just executes the program mentioned and expects it to be in the `PATH`.
It was't smooth at all, see https://github.com/rust-lang/rust/pull/47828 and https://github.com/rust-lang/rust/issues/48116#issuecomment-365493609.
Well, exactly, right? The [first trace of working on LLVM 6-support I find](https://github.com/rust-lang/rust/issues/47683) started 22 days ago, and got closed 4 days ago. In contrast, the [LLVM 5 tracking issue](https://github.com/rust-lang/rust/issues/43370) is half a year old, and apparently even failed to land.
Totally, I get that you can, but why? Is there a performance boost by making an async call from an async call? Are we worried about blocking the other handlers in the single request execution? Honest question
I've been thinking about proposing something like this but for `RefCell`. I had errors a couple of times because I forgot to put `{...}` around my dynamic borrows. I seem to define methods similar to this often these days and have considered making my own `RefCell` wrappers that only provide scoped access.
Woah, unsized rvalues was accepted! This is a hugely important and super interesting feature, imo. Passing trait objects by value on the stack, yeah!
also an interesting tool, but notice that it doesn't actually generate the parsers/serializers for all the language backends. It works for Rust, since it generates the Serde derive attributes, but not for e.g. typescript. For typescript it just generates an interface declaration.
So I think that this would be very cool and would require the following change: 1. Add `:self` as a valid fragment. This would act twofold, one it would map back to `expr` but two it would mark where the item would go. Only one `self` per pattern block
To start with, it seems like unnecessary overhead. Not only in terms of performance, but, as we progressively move to a more async world, in terms of syntax. Having to start a Tokio core just because you want to talk to the database is not my idea of fun. Also, if Tokio eventually gets work-stealing, I imagine it's not going to work with Tokio cores running inside futures.
Because its related to the game?
Waait a sec, its not the game's thread xD?
The subreddit is for the programming language Rust, not the game Rust. The subreddit for the game is /r/playrust.
That would be /r/playrust :p
All valid, there's already an issue open, so I can get a move on. That, thanks!
Any chances to survive there for the persons who are extremely weak at speaking German?
Gettext is very limited if you have to deal with word declinations beyond numerals. English doesn't have this concept, but most European languages have the concept of noun and adjective cases. For example â€The girlsâ€˜ flowers are redâ€. â€Redâ€ and â€girlsâ€˜â€ are going to change for radically from the original if they are parameters for your translation. Gettext doesnâ€™t support that. Project Fluent has the right idea, I'm still waiting to see if they get the adoption.
Huh. Looking at `typed-builder`, I'm wondering how Procedural Macros will provide for compile-time error messages...
At company I work in, we use schema that is synchronized well (I think other teams use it in build process already), so I guess it could be useful for us.
wow, the web framework space is getting so large. This is the first time I've heard about it and it looks really nice
Damn, I wish I understood this stuff. All I can say is that [these lines](https://github.com/Mrowqa/brainfuck-jit/blob/master/src/vm/mod.rs#L96) look redundant and could be put in a single line outside of the match statements.
There are two different concepts: - Blocks of information, be it file data or metadata about files/dirs. These are just sequences of bytes that are hashed with Blake2 and their "name" is just 20 bytes of hash. - Inodes in the filesystem. These are just sequential id's that represent files and dirs. There's a map that points id's to hashes. Id 0 is always the root of the filesystem and directory entries point to others. These are generated in the source laptop and never shared. For blocks the current solution is already enough. Whoever generates the same data will generate the same block info and thus the same hash. That's how we get deduplication for free. Inode to Hash mappings are currently only stored locally. To do read-only slave machines or eventually do full read/write sync these mappings need to be shared over the network and conflicts need to be resolved. I have a [design for read-only slaves](https://github.com/pedrocr/syncer/blob/master/TODO.md#read-only-slaves) but not yet for full read/write sync. That will require something like vector clocks to create partial ordering and some conflict resolution rules. I have a very preliminary idea of how that would be done but it's not a priority right now.
I'm in
I thought, they closed?
The most direct way to do this would be to call read() in a loop. You create an array on the stack (say `[u8; 4096]`), and keep calling read() into that array. After each call, you write the bytes that you got into your hasher, and also into your file handle. Is there any reason that "old school" approach wouldn't work? :)
fixed, thanks!
Awesome, glad to hear you like it! For `hide` I mean that you should be able to do something like the following: --- Next take the file above and edit a single line: ```rust,file=part2/example.toml % my_stuff = [1, 2, 3] % other_thing = "foo bar" edit_this = "to this other thing" ``` And everything after `%` won't show up in the rendered output but WILL be included in the respected code block/file (without the `%` though). This is useful for `cd` as well as lots of other things!
Got it and merged. Thanks again for the help.
Are unsized rvalues a requirement for `dyn trait`?
The change from bare `Trait` to `dyn Trait` syntax is a [completely separate RFC](https://github.com/rust-lang/rfcs/pull/2113). This RFC is just a change in syntax though, and doesn't add any new functionality. So with RFC2113 this would generate a warning: ``` fn with_callback(f: Box&lt;Fn() -&gt; ()&gt;) {} ``` And you should instead write this: ``` fn with_callback(f: Box&lt;dyn Fn() -&gt; ()&gt;) {} ``` With RFC1909 "Unsized rvalue", you will no longer need to use the Box! So you could write this as: ``` fn with_callback(f: dyn Fn() -&gt; ()) {} ``` Where the callback would be allocated on the stack, even if it captures variables from its environment! (And this would of course work for all unsized types, including trait objects, arrays, etc)
I think it's great, we get to have more diverse options
&gt; _ =&gt; {} Makes them necessary.
I'm also not convinced my suggestion for a separated algorithm is useful, *but* one argument in favor is the following: Suppose the `Distribution` trait is actually empty. For continuous distributions, `pdf()` is not guaranteed to exist everywhere on the support. For discrete distributions, `cdf()` may not be easy to compute (for example, evaluating the CDF of a Poisson or a Binomial either requires summing each pdf term or the evaluation of some special functions). It may be the case that only an *unnormalized* `scaledpdf()` is available. Maybe `inversecdf()` is easily implemented. Anyway, one could imagine a set of traits, `trait PDF: Distribution { fn pdf(&amp;self) -&gt; f64 }`, `trait CDF: Distribution { fn cdf(&amp;self) -&gt; f64 }`, and so on. By separating the sampler algorithm, you can have "partial" (but practical) implementations of distributions that throw compiler errors when passed to a sampler that requires more trait implementations. If you need high-quality samples, maybe you pass to an `InverseSampler` (which either requires `trait InverseCDF`, or uses Newton's method on `trait PDF+CDF`). If fast is required and low-quality permissible, just choose a `Ziggurat` sampler. The problematic state then, is of course bundled with the instance of the `Sampler`. This has some precedent: C++11 lets people specify which pseudo-rng to use, and provides a sane default. Rust's HashMap implementation is parameterized over the hash function, again with a sane default. This seems similar in spirit. The downside (which could be overcome with good defaults) is that the average user is exposed to more mathematical detail than they might be comfortable with.
The implementation of this is straightforward: use std::sync::{Mutex, MutexGuard, PoisonError}; fn with_mutex&lt;T, F, O&gt;(mutex: &amp;Mutex&lt;T&gt;, f: F) -&gt; Result&lt;O, PoisonError&lt;MutexGuard&lt;T&gt;&gt;&gt; where F: FnOnce(&amp;mut T) -&gt; O, { mutex.lock().map(|mut x| f(&amp;mut x)) } fn main() { let mutex = Mutex::new(2); with_mutex(&amp;mutex, |&amp;mut x| println!("{}", x + 2)); } Note how simple the actual function code is. Is a separate function for that needed, especially when I cannot think of use cases for it?
For rusqlite you need just take their "select example" here https://jgallagher.github.io/rusqlite/rusqlite/index.html modify for your need, and use `Vec&lt;u8&gt;` type for extracting data and `&amp;[u8]` type for inserting. There is also special blob API to work with huge blobs, but I suppose that not what you need.
isn't this an AOT compiler? it looks to me like you're precompiling the entire program and running it in one shot
Ok, thanks for the fast reply. So it looks like rusqulite is the way to go? Thanks! I'll try it out!
Wait, how does this work? Would this mean dynamically sized stack frames?
What you want to do can already be done, with the benefit of being reusable. &gt; ```bash,from-file=a-lot-of-preamble.sh,prepare=cd,hide &gt; # contains the preamble from file, plus whatever is in here verbatim, and can be referenced with use=cd &gt; cd some-sandbox &gt; ``` Now you can use this preparation in any code block and execute it (without showing it): &gt; ```bash,use=cd,exec &gt; my-program &gt; ``` To me it's just semantics, with the added benefit of providing the author with reusable blocks that can be verbatim or which can be coming from a file. The docs also contain examples on how this works, but it's certainly not perfect yet. 
Yeah, you're right. Thanks. I heard "JIT" many more times than "AOT", so I called it JIT since I'm doing the stuff of compiling it in the memory and then executing it. Compiling it block by block could be also a fun part, especially dealing with loops, cause we have different ways to design this with various drawbacks.
Based on my understanding of your question, the closest thing I can think of would be an `as_ref()` impl for your type where the output type allowed references to the parts of the owning type you were interested in.
I believe that's untrue - the ABI is just passing by pointer, you just take ownership.
Nice, I like how it fixes all of the JSON issues. For some reason I'm not sold on the name RON though :)
rson?
Rust Serialized-Object Notation. Looks good to me.
I think alloca is for returning unsized prvalues, but I don't know if this is supported by the RFC as accepted. That part of it is far more complicated from an implementation standpoint - like basically at the level of near impossible while keeping a C-style ABI.
Sounds like arson though...
Pronounced "arson" 
*"blazingly* fast"
Actually this isn't so hard to understand as it appears to be. Basically it translates one assembly to another. For the simplicity I haven't even programmed the optimization of generated code. If you want to understand it, please read about [Brainfuck commands](https://en.wikipedia.org/wiki/Brainfuck#Commands) in the first place. Then just take a look at [these lines](https://github.com/Mrowqa/brainfuck-jit/blob/master/src/vm/mod.rs#L22-L43). The magic numbers are just the instructions in the comments compiled to machine code. Zeros are places to be patched later. If you don't know assembly, I think you can learn the basics really quickly, in maybe 1-2 hour(s) (look at [registers](https://www.tutorialspoint.com/assembly_programming/assembly_registers.htm), [arithmetic operations](https://www.tutorialspoint.com/assembly_programming/assembly_arithmetic_instructions.htm), [conditions](https://www.tutorialspoint.com/assembly_programming/assembly_conditions.htm) and [procedures](https://www.tutorialspoint.com/assembly_programming/assembly_procedures.htm)). I'm not sure if that's enough of assembly, but I hope it will be :) Having this, the main idea is pretty straightforward: allocate two chunks of memory; one as the memory of VM, the second one for the generated code. We need to remember that memory pages have RWX permissions like the files, so we need make sure that the page where our code will be loaded, has the permission to be executed. Another thing which I learned, and you will understand after learning how to call a function in assembler, is that win64 fastcall convention requires having 4 qwords (32 bytes) of memory allocated on stack which called function can modify (here: getchar and putchar). Otherwise these functions will overwrite some data on stack causing crash. Another important thing is how to handle loops (jumps). You want to know somehow how many bytes of machine code will need body of the loop. I have solved it with recursion. I know this explanation is chaotic. Sorry for this. I just like to explain interesting stuff and it is easier to be done when we talk in person. And if something seems to be a non sense in my code, it could be intentional if it was easier or faster to write. After all, it was "almost one evening" project :)
Alternate solution: create a struct that wraps a reader and hash state machine. Implement Read for it, such that .read delegates to the wrapped reader and then hashes the bytes. Now you have an adapter that hashes everything you pass through it.
Thanks!
Interesting idea to have extensions for a serialization format. My gut reaction is that "flexibility" is not necessarily a benefit for a serialization format. On the other hand, RON is probably never used as an interchange format and it could guard against having a million different incompatible RON++ variants like JSON has (or at least make them easier to write). Don't let me spoil your fun :P
Note that `Fn` may not be the correct trait. `FnOnce` if you call the closure zero or one times. `FnMut` if you call the closure multiple times without overlapping calls. (Typical for iteration items.) `Fn` if you need overlapping or recursive calls within one thread. (Rare) `Fn + Sync` if you need to call at any time from any thread. 
JSON sounds like Jason Â¯\\\_(ãƒ„)_/Â¯ 
I thought the explanation was good :) &gt; I just like to explain interesting stuff If you feel like explaining some more, I'd be really happy to ask questions ;) ---------------------------- &gt; The magic numbers are just the instructions in the comments compiled to machine code. What platform are they generated for currently? &gt; one as the memory of VM What exactly do you mean by VM? Did you write your own bytecode parser? Does the OS just need space to execute it on?
If voting happened on reddit I'd probably vote every time. I never really go to the rust site.
I'm into this.
When would I use RON over something like protobuf or capnp?
Superseded by brson? 
Is this an alternative to https://github.com/actix/actix ?
I can relate to that, but the official site is rust-users, so I don't want to ask them to create a reddit account to vote, and asking both sites introduces its own share of problems.
I like RSON.
You could post a Reddit thread a day or two in advance linking to rust-users to solicit nominations and votes.
Is it data-race free though? 
Ron is the only serialization format featuring native enum support, that I know of. I wonder if it supports sum types in general? If so it would be an ideal candidate to replace yaml within haskell community for example.
Yeah, llvm 5 never landed. skipped from 4 right to 6.
&gt; I wonder if it supports sum types in general? We support all enums you could get in Rust :) Anything concrete you are concerned about?
It's super controversial, I agree. On the other hand, we already had a RON variant branching off the tree: https://crates.io/crates/rson_rs Now we can at least ask them to merge back upstream, as an extension.
&gt; So it looks like rusqlite is the way to go? I never try others. I have choosen the most popular sqlite crate on crates.io rusqlite and have been using even since, and have no reasons to find something different.
`alloca` is used when storing unsized rvalues on the stack, such as `let arr: [u8] = [0; dyn x + y];`
Really, son?
Sounds like a bug to me? Should create an issue on github.
I still think reddit voting would be a better place
I have one targeted at embedded systems that supports some a flavor of tagged unions. It's not widely used, but the union support in a serialization format has been extremely useful. Happy to see it showing up in other places. https://github.com/cauterize-tools/cauterize
I don't have much of an opinion on that, but I note that /r/rust is not the official forum for the Rust language, and some people who don't have a reddit account may be opposed to getting one, what with the rest of reddit not exactly following our CoC.
It depends on what you mean by alternative. Actors a bit different concept. Let's say you have a cache of something. With actors, you'd spawn an actor for the cache and if you wanted to interact with it, you'd send it a message and it would answer back. With coroutines, you'd just have a shared object each coroutine would access directly when it sees fit (eg. a library with or without librarian). But you can probably reach the same goals (eg. handling concurrent connections and switching between them) with them and it depends more on what style you like. 
Those services are upwards of $35USD per month, and not very convenient. The company decided to go with new systems because MacOS and iOS are one of our target markets. Made more sense to have a dedicated machine available locally in the end. I did consider fudging up a system, but that doesn't fit with corporate responsibilities too well :)
Yeah, sure. You can ask more questions if you want to, but I'm not sure if our comments are being considered as a spam. &gt; What platform are they generated for currently? The target architecture is [x64](https://en.wikipedia.org/wiki/X86-64) and the target OS is Windows. Architecture determines instruction set for the CPU. OS determines how we can [change memory page permissions](https://github.com/Mrowqa/brainfuck-jit/blob/master/src/vm/jitmem.rs#L19)* and how we [call functions](https://stackoverflow.com/questions/18135871/calling-convention-on-x64). * for unix you need to call [mprotect](http://man7.org/linux/man-pages/man2/mprotect.2.html) &gt; What exactly do you mean by VM? [Virtual Machine](https://en.wikipedia.org/wiki/Virtual_machine) is anything that emulates something or interprets something. If we think about my BfJitVM struct as a blackbox, it takes source code and executes it. Doesn't matter if I compile it in the meantime to native code. Even Python interpreter is a VM. Another instance - [PS3 emulator](https://rpcs3.net) - they take [PowerPC machine code](https://en.wikipedia.org/wiki/Cell_(microprocessor)) and decompile it to the [LLVM IR](https://en.wikipedia.org/wiki/LLVM#Intermediate_representation), so they can use LLVM to optimize and compile it to many other architectures including x64. If you want to watch how to implement simple VM - [here's a good video](https://www.youtube.com/watch?v=BQRX3owv2JI). Generally, if you like low level stuff and/or security, you will like Gynvael Coldwind. If you speak polish, then there is also a lot of interesting things on his polish channel.
I'm building a bot that takes commands. My question is if there is a decent library I can use to do the routing side. I'm going to pick out Rocket to explain what I'm after. In that you can set an annotation to describe the url for a route. i.e. #[get("/hello/&lt;name&gt;/&lt;age&gt;")] fn hello(name: String, age: u8) -&gt; String { ... } I'd like to do something similar, but this isn't for a web server. I'll be passing the string in from stdin, or another connection. Basically I'm after a library that is like that kind of annotation based routing, but only does the string comparison stuff. Nothing else. Is there a decent library out to do this? Many of the routing libraries I've looked at are heavily tied to whatever framework they are for. I don't want all those dependencies along for the ride. I also don't want to go down the parser route. I had considered a parser library. What puts me off is then I have to build a grammar and all of that shenanigans. I want something where a colleague could easily copy/pasta an existing command to build a new one.
Cool post. Iâ€™m on mobile and very tired, so no elaboration, but nice post. ðŸ‘ 
In the second, don't you need a `?` after the `unwrap_or_else`? Otherwise you can't call a method presumably defined on `T` on a `Result&lt;&gt;`.
I haven't looked at any results in C++ and only have a basic knowledge of the language, but I'm curious: what features does C++ have that can result in a more expressive solution compared to Rust?
[This code](https://github.com/mathstuf/rust-abagames-util/blob/master/src/pool.rs#L134) may be of interest. Basically, you iterate using indices and then use `split_at` to access the left and right sides of the current element. This allows you to mutate a single element while giving it read-only access to the rest of the elements.
I'm not sure what the point of this was. I'd understand it if you reimplemented the challenge in a different way, but just using a crate that parses CSV leaves you with a little bit of boilerplate code, and not much else.
`wait_timeout` will block as long as the mutex is locked in another thread, even if the timeout has expired. That is because it reacquires the lock on the mutex before returning. Do you have the mutex locked in the other thread?
`#[macro_use] extern crate serde_derive` works though?
I'd find this *really* confusing, because it breaks every convention re: `#[whatever]` in the whole language. If the macro use thing is really just that ugly for you, may I recommend sticking them all in one place and putting the doohickey in front of the extern declaration? #[macro_use] extern crate foo; #[macro_use] extern crate bar; extern crate baz;
Shouldnâ€™t the properly namespaces macros 2.0 obviate the need for macro_use altogether?
Right, so if you consider a web request that triggers a query to a database, that takes let's say 60 seconds. Since we are synchronously waiting for the database query to finish all other web requests are effectively blocked.
The intention is that everything about this dies, and that the new macro systems don't need it at all. As such, I wouldn't support this because it's just an extra burden for something that should, by the end of the year, not be needed ever again.
Hmm, thats an interesting approach. Will definitely look into it
I can kind of understand that, but if that's the case, they could simply use a library in C++. This example even would be pretty similar in plain C, assuming a similar library. With all that said, I like the previous version of this pretty well. It was minimal, and clean.
Fair enough, I think I get it a bit more now. It'd be nice if we had some sort of pseudo-reflection in Rust. .NET's (de)serialization abilities would make this quite a bit cleaner than it already is.
`unwrap_or_else` turns this into a concrete `T` already! The types I see: a_mutex.lock() : LockResult&lt;T&gt; poison: PoisonError&lt;T&gt; poison.into_inner(): T unwrap_or_else(Fn(PoisonError&lt;T&gt;) -&gt; T) -&gt; T x: T If you don't agree with this, could you elaborate on which part is misleading and/or incorrect?
The work on LLVM 5 helped toward 6 too though. We were finally at a point where the upgrade to 5 was feasible to complete, but Alex decided we might as well move right on to 6.
Ah, crap. I also forgot to put in an `if` in this one. Doing this with `csv` isn't too terrible; it means you don't use serde.
Oh, it was my brainfart because I forgot that `into_inner` returns the locked T. I think I read it as an error value that you were turning into a type enum.
How do I let modules depend on one another? In my case, I'm making an emulator and I have a module for addressing modes and one for operations, but the operations require an operand of a type specified in the addressing mode module.
Not rusty; it's like writing Python in Rust, right down to forcing your code to be single-threaded. (I know that not all implementations are single-threaded but CPython puts all interpreter state and GC'd objects inside One Big Mutex. )
One important thing to note is that transform.now.sh is just an aggregate of many projects of varying goals and quality. quicktype is a single compiler with one intermediate representation connecting multiple input formats to many target languages. In general, this allows us to raise the bar for quality and validity across all target languages (e.g. our naming mechanism avoids invalid names and conflicts across all target languages, whereas on transform.now.sh it depends on the components imported there.
The two issues with your suggestion is that this misaligns the `extern` (which is the more important part of the statement), and also `rustfmt` would reformat it back into two lines anyway. Fundamentally I read #[macro_use] extern crate bar; as "I want to use macros from a crate called 'bar'", and extern crate foo; #![macro_use] as "I want to use a crate called 'foo'... oh and by the way it has some macros I also want to use" (which is really what `macro_use` means, I think). But I can appreciate it would be confusing, if this could only apply to this use-case and not others.
That's what I was hoping to hear. Thanks!
Ah I wasn't sure. In that case, I'll eagerly await its deprecation.
OTOH it depends on how far extensions go. If extensions are just "syntactic sugar", then you could have the parser simply convert it to "canonical" format and then passed around as such. You'd only need the client/consumer to know how to process it, and then it would send it as canonical to the server (which, unlike the client, the user cannot update if it doesn't recognize an extension). If that's the aim, then it's a cool way to encode "be generous with what you accept (through extensions) but strict with what you generate (always generating canonical forms).
My assumption was that since each request is handled in a new future by tokio's TcpServer, that the query to the database would only block execution within that request, is that not correct? If that's not correct, what is the point of using TcpServer since any request can block the execution of all incoming requests?
i like this, it makes use of the type system well and seems like some cool advanced trickery. definitely gonna fiddle around with this
Ah ok, maybe I just remembered reading someone speculating that it would possible? Oh well :)
I don't mind it being misaligned; I usually put them in entirely different sections, with a line of whitespace between them--but I thought that would look odd here.
I'm confused, what do you think might be possible? Either LLVM can prove it is dead code and optimize it away, or it can't and has to panic (avoiding undefined behavior).
There's an unsafe intrinsic version of it that enables the optimization magic, but I wouldn't use it unless it was performance-critical to do so.
That's a really good idea- thanks!
[Cap'n Proto](https://capnproto.org/) has unions as well.
There's an intrinsic with the same name, but it's unrelated to the macro
How does this differ from serde_json?
Yeah, that's really fair. But I'll probably never remember to vote if it's there. If the goal is more votes I'd suggest hosting on a 3rd party site that doesn't require an account and linking to it here and on rust-users.
I feel like something like this [playground](https://play.rust-lang.org/?gist=a73bfafbb4de26fb9b3afffd78b12357&amp;version=nightly) is much more in the spirit of the challenge which is to use the newest features. I think Failure makes the code much cleaner. And i like how slice_patterns and match_default_bindings come together and make line 11 possible.
$35 a month is pretty nice compared to $6k :P Automated CI builds is all you need, but I can understand depending what you're doing that may not be suitable for you.
I like this too!
No (not that I know of), but, I only mentioned it because Java found some serious backward/forward compatibility constraints that happened due to having a serialization API bound tightly to the language/libraries that was entirely unexpected. I know it is one of the things that has complicated project Valhalla (value types etc) and project Panama (low-level intrinsics and easier cross-language calling) in Java.
[@spacekookie's latest tweet](https://i.imgur.com/taDX6EF.jpg) [@spacekookie on Twitter](https://twitter.com/spacekookie) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
This is a totally reasonable thing to do in Rust, hardly "writing Python." The advantage of Rust here is not so much that it *forces* you to write everything in a way that can be multithreaded (though it may feel like that at times)- it's that it will catch any mistaken attempts to do multithreading without proper synchronization. So by all means use `Cell` without feeling like you're "doing it wrong" or being unidiomatic. Just keep in mind that you'll be able to confidently refactor it to something more complex if you decide to parallelize it later.
You're a weird bot...
&gt; [...] is there any **stable** and safe way to directly allocate on the heap? No.
Yes you can do that, that's how many rust tools work. e.g. clippy is a compiler plugin, while rustfmt links directly to librustc_syntax. I don't know much else about this but that should point you in the right direction.
It's all good - this stuff can get a bit confusing. I've learned to love `unwrap_or_else`'s but I wasn't familiar with it until recently.
If one would drop the **stable**, would`box-syntax`be the best option?
I'm not sure whether LLVM does such sophisticated optimizations.
Yes, but I don't want a compiler plugin, I want a stand-alone tool that can operate completely without the rust compiler being present. clippy uses `rustc_plugin`, which only works if the rust compiler is already installed on the target computer. `rustfmt` just analyzes the syntax. `librustc_syntax` is depreceated, `syn` is what the rust compiler uses. But that doesn't give me any compilation features.
Yes, but I don't want a compiler plugin, I want a stand-alone tool that can operate completely without the rust compiler being present. clippy uses `rustc_plugin`, which only works if the rust compiler is already installed on the target computer. `rustfmt` just analyzes the syntax. `librustc_syntax` is depreceated, `syn` is what the rust compiler uses. But that doesn't give me any compilation features.
Rouille was much easier than anticipated! Since [the most recent commit](https://github.com/HeroicKatora/oxide-auth/commit/370d03db6292abce8ea0039f6ce018a63180ae36) you can check it out in an example on the master branch. After some stabilization and documentation, a proper version will be published. 
If you can work without the stable requirement you could look into the place operator on nightly. https://doc.rust-lang.org/std/ops/trait.Place.html
Awesome! Thanks for the clarification.
I think the best option right now is using the syntax added by https://github.com/rust-lang/rfcs/blob/master/text/1228-placement-left-arrow.md. From what I can tell, it's the most likely be what is eventually stabilized: #![feature(placement_in_syntax, placement_new_protocol, box_heap)] pub fn box_it() -&gt; Box&lt;i32&gt; { use std::boxed::HEAP; let boxed = HEAP &lt;- 3i32; boxed }
Link?
I'm not an expert on reading LLVM output, but godbolt is a good tool to use to see what your Rust code will compile to: [Example](https://godbolt.org/g/ZiHxRE)
Nice work, dude!
Well that is a binary serialization format unlike json/yaml isn't it? but fair enough.
Too late now, but how `Int` and `C` interact is madness. `#[repr(Int)]` means "Uses `Int` for the tag, and is also `#[repr(C)]`", whilst `#[repr(C, Int)]` means "Like `#[repr(Int)]`, except the tag is stored outside the variants.". I can't imagine *anyone* is going to expect that behaviour. I feel like it really should have been `#[repr(Int, unpacked_tag)]` or something.
I wasn't aware of the effects and availability of different repr formats! This is very interesting. It might be worthwhile to document the different repr formats and their effects on structs and enums in a single location for the future.
Cool! what about ADTs? not sure if it would be useful to support [function types](http://chris-taylor.github.io/blog/2013/02/10/the-algebra-of-algebraic-data-types/). but just for the heck of it, would it? ;)
`serde` exists with macros today. Proc-macro-derive _already_ made serialization magical.
It's EXTREMELY weird to me that this takes a mutable string parameter. https://github.com/samrayleung/rspotify/blob/83ad70bca893aa6636f4fae08216c33c5561625b/src/spotify/client.rs#L246 Looking through the implementation, I can see WHY, but I would suggest that the default API (I found this by looking at the examples) doesn't mutate the string. my 02c.
get, I will try to remove the `mut` flag from function signature 
Looks like it would be smart to check the whole library. Sorry I think you did great work, just trying to be helpful. https://github.com/samrayleung/rspotify/blob/83ad70bca893aa6636f4fae08216c33c5561625b/src/spotify/client.rs#L214
It isn't too late: it isn't stable yet.
For me, what is stopping me is the fact that it is in beta. I would rather have a stable window manager that I can rely on to work.
so you havent even tried it?
Thanks, much appreciated. It's hard for anyone with interest in what went down to fill in the blanks, and human to project even if only by accident. ICYMI, https://www.reddit.com/r/BATProject/comments/7rsodt/brendan_eich_proposition_8_controversy_can_it/dt0n04t/
Your very welcome. :) Best practice is to use immutable state everywhere you can.
Excellent article, thank you for that peek into history!
Is there a simple/easier way to generate a sprocket and couple it to the Rust one for (temporary(?)) logos? I can edit SVGs in InkScape well enough that I can copy the R sprocket SVG and remove the R and add in some text, but building an SVG chain to couple two sprockets is a bit beyond my skill level.
Was this discussed fully during the other RFC? Otherwise you can open an amendment PR to fix this, or a second RFC. 
There is this unsafe "unreachable" intrinsic that asserts to LLVM that reaching that instruction is UB, which makes LLVM think it's dead code even if it couldn't prove it before, and might enable some optimizations. 
yep, I haven't even tried it. But given from the feature list that it doesn't support any menu bars (with support for awesome status bar just being added) I don't need to try it to know its not mature enough.
Definitely not considered spam, people love systems programming here :P &gt; even the python interpreter is a VM Yes, but yours is a JIT. So what are you referring to in this case?
This is what serde is no? It adds functions to each serde-annotated type that enable reflection.
Is there a way to do a macro-based match? Something like this: const SPACE: &amp;str = " "; macro_rules! match_builder { ($c:expr) =&gt; (c =&gt; print!("{} {}", type(c), c),); } fn main() { let blah = "hayaya cha cha".to_string(); for character in blah.chars() { match character { match_builder!(SPACE); } } }
&gt; Though, I'm pretty confused as to why anyone needs Yet Another esoteric text-based serialization format regardless. Rust's enum types map awkwardly to formats like TOML or JSON if you want human-readable output. The selling point of RON for me is that I can throw a complex, enum-rich struct at it and it'll serialize as something that looks similar to how you write Rust source instead of a bag full of machine-generated kludges.
No, it doesn't work. https://godbolt.org/g/UxSXf2
One use case I've been throwing around are human-authored complex configurations with many options. These would be structs with many `Option` fields, most of which would be `None` most of the time. I see there's an "implicit Some" extension now that converts "x = 5" to "x = Some(5)", would an "implicit None" that deserializes "Foo()" into `Foo { x: None }` for `struct Foo { x: Option&lt;i32&gt; }` also make sense?
I didn't make any claims of things working, just linking to a tool that is useful for this sort of question.
Sorry, but it doesn't always work. https://godbolt.org/g/68aFi9
Thanks. Code generation is always my favorite part to look at in a compiler
There is, indirectly. It is not possible to build a match branch in a macro, but it's definitely possible to build the entire `match` expression. Here's an answer to a very similar question which might be good: https://www.reddit.com/r/rust/comments/7vwx5e/help_building_large_match_statement_with_a_macro/dtwkqwp/ I can elaborate more on that if needed.
For something as essential to working on a computer as a windows manager, I don't think "it works now" would be a good enough metric. Whether or not I've tried it, I would never use something this beta as the core of my daily work. On a side computer / experimentation partition, maybe, but not for a day-to-day window manager.
I often run into this pattern when removing things from lists. What I read (some time ago, perhaps in rust-by-example), is that it can be easiest to collect the set of things to update (or remove) first, then mutably iterate over the set to perform the operation. Here's my solution to your problem, first finding all attackers, then updating all others to be hurt by them: https://play.rust-lang.org/?gist=75de05e0d6269d4601c131cf83c6cccf&amp;version=undefined The negative of course is the temporary Vec creation for the to be deleted list, but that might not be a horrible thing. What's nice is that this doesn't require any unsafe code. It no bounds checks on element access unlike the indexed option in your second example b/c of the use of iterators, but does have more passes over the vector.
Only in this community :eyeroll:
Technically yes, but you did write a piece of code that I think is misleading, so I had to reply.
There's also a way to do it that allows multiple threads and supports non-Copy objects, as long as you know you never need more than one accessor to any element in the collection at a time: https://github.com/pythonesque/kravanenn/blob/wip/src/util/ghost_cell.rs.
https://doc.rust-lang.org/beta/reference/type-layout.html I'm already writing the PR for this RFC for the reference.
Wow, this looks quite ugly tbh.
Somebody mentioned wanting the `(tag, variants)` form and it was added via combining primitives and `C` without any discussion or feedback on that being a good or bad choice. Having its own name would be useful for documentation where I've currently just made up a name for it. Though I like your name better, so I'm ~~stealing~~ creatively repurposing it.
Yes, one could, but given how specific the code would have to be to the application I think I'll just let projects needing this write their own.
Agreed. Because of this and because of the extra complexity of using state-full distributions I'm tempted to leave out all state-full distributions (assuming we don't decide to add any such algorithms to rand) because the trait can still be defined outside of `rand`.
I've been thinking on it, and what I would do is have `#[repr(C)]` on an `enum` imply `#[repr(C, c_int, packed_tag)]` (for whatever `c_int` happens to be). `#[repr(C, Int)]` then overrides the `c_int` default. `#[repr(C, unpacked_tag)]`, `#[repr(Int, unpacked_tag)]`, and `#[repr(C, Int, unpacked_tag)]` all override the tag packing. `#[repr(i32, packed_tag)]` could be used to make it explicit that the structure uses a packed tag for people who don't want the ambiguity of the default (which I understand from a "good perf default" stance, but still find really weird). So you effectively have three (mostly) independent flags, each of which has a straightforward definition.
&gt; .../reference/... Whaat!? :9 I have been yearning for a Rust reference! Thank you so much for working on this! 
Why do you need it anyway? In release mod LLVM will optimize `Box::new(Foo { ... })` to construct `Foo` on heap anyway.
I really like the fact the rust implementation uses serde and makes it compatible with the rest of json handling (so I can embed it in another struct that uses serde).
Most likely yes, assuming there's a libc on your target system already and you're not counting its size as part of your executable.
Supposedly, but it doesn't necessarily seem to work, cf /u/pftbest's case: https://rust.godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(j:1,lang:rust,source:'//+Type+your+code+here,+or+load+an+example.%0Apub+fn+square()+-%3E+Box%3C%5Bu32%3B+1000000%5D%3E+%7B%0A++let+stack_val+%3D+%5B0u32%3B+1000000%5D%3B%0A++let+heap_value+%3D+Box::new(stack_val)%3B%0A%0A++heap_value%0A%7D%0A'),l:'5',n:'0',o:'Rust+source+%231',t:'0')),k:50,l:'4',n:'0',o:'',s:0,t:'0'),(g:!((h:compiler,i:(compiler:nightly,filters:(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',trim:'1'),lang:rust,libs:!(),options:'-C+opt-level%3D3',source:1),l:'5',n:'0',o:'rustc+nightly+(Editor+%231,+Compiler+%231)+Rust',t:'0')),k:50,l:'4',n:'0',o:'',s:0,t:'0')),l:'2',n:'0',o:'',t:'0')),version:4
That's fair, I wrote the simplest compiling code possible so OP could play around with it.
&gt; Definitely not considered spam, people love systems programming here :P Good to know :) &gt; Yes, but yours is a JIT. So what are you referring to in this case? To the definition of Virtual Machine. Interpreters are also VMs. I should have expressed that more clearly.
Since it is a crate and not an application, I would avoid `eprintln()` and masking Result with an Option in your error paths. I can see that `internal_call` bails out with an `Error`, but in some methods like `artist_top_tracks` the error is printed out and instead an Option is returned. To me, Option implies a completely different thing in this context. The `None` variant could mean that the artist has no top tracks (even though I'm not sure if it's possible in Spotify), but `Err` variant of Result tells me we haven't even communicated with the API correctly.
You don't need any special handling here on RON's side, you can just use the serde default attribute to be able to leave a None value out.
That depends. `alloc_system` means "Use whatever libc provides rather than bundling a separate one into the Rust binary", so it becomes a question of what you mean by "smallest". If you want something small because you want to study it, [wee_alloc](http://fitzgeraldnick.com/2018/02/09/wee-alloc.html) (intended for WebAssembly but with a mmap backend for testing purposes) is explicitly designed to be tiny. If you want to minimize the size of the binary you're distributing, then it depends on whether you're on a platform that provides a libc you don't have to bundle, such as glibc on Linux. If so, `alloc_system` is pretty much guaranteed to be the smallest because your program doesn't actually contain an allocator... just calls to an external library. If not (for example, if you're using a musl libc target for fully-static binaries on Linux), then it becomes a trade-off between the general-purpose allocator provided by the libc and the more special-purpose stuff like `wee_alloc`. Either way, if you want to shrink your binaries, don't forget to set `lto = true`, `strip` them, `sstrip` them if they're in ELF format, and then compress them with UPX. Depending on the requirements of your codebase, you may also be able to specify `opt-level='z'` (requires nightly Rust, optimizes for size) and/or set `panic='abort'` (Prevents `Drop` implementations from being run on panic, but allows LTO to eliminate unwinding-related code.) Also, see these links: * http://www.suspectsemantics.com/blog/2016/12/03/monomorphization-bloat/ * https://clap.rs/2018/01/09/new-years-weight-loss/
Really?
You can use `UnsafeCell` (really, just raw pointers) to avoid changing your algorithm at all. Something like [this](https://play.rust-lang.org/?gist=a28cff673ba746cd2bf38f0068f398ba&amp;version=stable).
Pretty neat code. Thanks for sharing! Also thanks for telling about external libs; I haven't been looking for them when I was writing that code, but it's nice to know about them anyway.
It appears the 'bug' is in the example, I'll open an issue.
It's a noble intention! Since you already use error-chain, it shouldn't be too hard to introduce your own error variants if needed. Just returning, say, a wrapped serde json deserialization error is already a great amount of information. Outputting something unconditionally, without it being asked for, is kind of a no-no for any third party library. Instead, most crate creators will return a descriptive error type. Then, developer is free to do anything: `unwrap()`, `?`, print out a verbose error message, etc. :)
If you can live with representing each record as a `HashMap`, then you can deserialize into that. :)
For me, it's the lack of proprietary Nvidia driver support. This is a complete deal breaker. Nouveau drivers do not support the Vulkan graphics API (and can't until Nvidia releases more information). So sadly, Way Cooler is Way Not Possible for many people in the Gfx-rs(hal)/Vulkanko/Rust game Dev scene. :'( I've tried it out and totally love it and will jump on it as soon as there's Nvidia and portrait monitor support.
Do you mean I should define my `ErrorKind` with `error_chain`, as you mention "return a descriptive error type"
There is [``std::ptr::eq``](https://doc.rust-lang.org/std/ptr/fn.eq.html) for this =).
There are several ways to go about it. You could simply propagate errors from Reqwest like you do for Serde (introducing an error variant with Reqwest's error type wrapped) OR you could map these errors into more semantic errors with different kinds, specifically designed to reflect domain-specific Spotify errors.
For me, it's the lack of proprietary Nvidia driver support. This is a complete deal breaker. Nouveau drivers do not support the Vulkan graphics API (and can't until Nvidia releases more information). So sadly, Way Cooler is Way Not Possible for many people in the Gfx-rs(hal)/Vulkanko/Rust game Dev scene. :'( I've tried it out and totally love it and will jump on it as soon as there's Nvidia and portrait monitor support.
[route-recognizer](https://github.com/conduit-rust/route-recognizer.rs) is a non-framework-specific router. It is still built for URL matching, so who knows if it'll work on other formats, like your space separated one. But it might still give you some ideas. Annotations like Rocket's will likely require a procedural macro.
This would also be very useful for opening files. Instead of doing: let whatever = { let file = File::open('file.ext')?; process(file) }; you could have the (imo) more elegant: let whatever = Fill::with_open('file.ext', process); Note that those two snippets actually do different things when the file opening fails: the first one sends the error back to the overall function, the second one puts an error in whatever (which has type result). You could think of two variants for the type of `with_open`, either it takes a function that returns `Result&lt;T, SomeError&gt;` and returns `Result&lt;T, SomeOtherError&gt;` where `SomeOtherError` has two variants for `SomeError` and `io::Error`, or it takes a function that returns `T` and returns `Result&lt;T, io::Error&gt;`.
well, get. I will take optimizing error-handle into consideration about what's next step to do for this crate. But the first thing is to make it work, then to make it work well. In the end, thanks for your time and suggestions :)
How is this madness? Why would anyone use that feature without reading its documentation, anyway?
http://words.steveklabnik.com/an-overview-of-macros-in-rust sort of lays it all out. TL;DR: with macros 2.0, macros will be more normal, so they'll be namespaced and you can `use` them. No need for `#[macro_rules]`.
&gt; How is this madness? Adding `C` causes the tag to move from inside the variants to outside. I don't know about you, but that's not my first thought when I read "`C`". *Especially* not when it usually denotes "C-compatible layout", and not having `C` in this case *also* means "C-compatible layout", so it comes across as "C-compatible layout + C-compatible layout = tag outside variant". *Madness.* &gt; Why would anyone use that feature without reading its documentation, anyway? *Hahahahahahahhahaha!* No, see, what they do is they roll their faces over the keyboard to write some FFI code, compile it, and when it causes the process to explode and delete their home directory, go on Stack Overflow wondering why they can't pass a `Vec&lt;String&gt;` to a C function expecting `**char`. Reading the documentation is, in depressingly many cases, the literal last thing people do.
&gt; Madness I'm pretty sure there is no "serious mental illness" involved here. Adding `C` causes the tag to be represented as it is traditionally done in C systems emulating enums. Without `C`, it does something that is translatable to C, but not in a way that is ergonomic or even common. &gt; Reading the documentation is, in depressingly many cases, the literal last thing people do. In which case they would still do the wrong thing, wouldn't they? Why would `packed_int` give better intuition to these people? I could even argue that `packed_int` sounds like the field following the tag will not be aligned properly.
https://tokio.rs/blog/2018-02-tokio-reform-shipped/
&gt; Adding C causes the tag to be represented as it is traditionally done in C systems emulating enums. But that's not what `C` does in other contexts: it just sets C-compatible layout. It doesn't normally make judgements about how higher-level concepts are translated. &gt; In which case they would still do the wrong thing, wouldn't they? Having an explicit flag makes it slightly more likely they'll cotton on to what's happening if they look at an example. &gt; I could even argue that packed_int sounds like the field following the tag will not be aligned properly. Except I suggested `packed_tag`, not `packed_int`, which just goes to prove how people really don't like reading. :D
Thanks, I found the link shortly after making this post. One doubt, the breaking change to futures in 0.2, will it affect Tokio?
Hey nice work! I created the scala wrapper for the Spotify web api. Donâ€™t you love some of the odd inconsistencies in the Spotify api? For me it made a lot more random boilerplate to account. 
Was already posted a few days ago.
Why not do this: #[macro_use] extern crate A; extern crate B #[macro_use] extern crate C; [I use it in my projects](https://github.com/Xion/cargo-contribute/blob/master/src/main.rs) and find it very readable.
&gt; Obviously, there is an upcoming breaking change with the futures 0.2 release, but after that, fundamental building blocks will aim to remain stable for at least a year
From the post: &gt; The plan is to let the changes made in this release get some usage before committing to them. Any fixes that require breaking changes will be able to be done at the same time as the release to all the other crates. The goal is for this to happen in 6-8 weeks. So please try out the changes released today and provide feedback.
True.. but I'm not sure there's any *better* alternative. I mean the previous proposal had `let boxed = in(HEAP) 3;` which is.. even less clear what's happening. At least with this one we can see it's placing something directly in something else, and if you don't care *what* you're placing it in `box 3` still works.
Ah alright. Thanks.
It sounds like there's actually three issues going on here: how the struct is arranged, what size the tag is, and whether the tag is in the variants or not. With that much overloaded meaning it's no wonder it gets a bit bonkers. Just make them entirely separate and explicit things instead of overloading `repr()` in funky ways.
&gt; To the definition of Virtual Machine. Interpreters are also VMs. I should have expressed that more clearly. No, I got that, but since brainfuck-jit is a compiler, it doesn't need to be interpreted after it's been compiled, no?
Yes, but `unreachable!` has to be safe.
Here's another approach: (I honestly don't know if the lifetimes are "semantically correct", but it compiles) https://play.rust-lang.org/?gist=54ea2cb1826933e5f5544618751a2b96&amp;version=stable
No, we generate verification functions for TypeScript.
I wouldn't agree there. Let's say you want to use a build system other than Cargo. What then? If we can use a build system that automatically brings in libraries, it wouldn't be too difficult to build one in C++, so it'd be reasonable for C++ to use libraries.
If we make a binary version, would that be /u/brson ?
Can you be more specific please? We support Rust enums. Are you concerned about some particular variant of an enum? Or are you talking about bindings to other languages with richer type systems?
See https://github.com/ron-rs/ron/issues/43
thank you!!
According to [The Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/), `macro_rules!` actually isn't a macro but another type of syntax extension which can't be defined by the user. Thus supporting this would be a little trickier than you say. 
Glad to hear you enjoyed it :D I plan to do a second video on the same crate (documentation, API ergonomics, parallel machine setup (rayon), CI, etc.; see the todo file in the repo) some time late next week, so stay tuned!
I'm not sure what you mean here. There's nothing at all specific about a joint distribution parameterized over each marginal distribution. 
Ah, I misunderstood; you were confused why anyone would think `unreachable!` specifically would enable optimisations. Gotcha.
tokio-minihttp - 1 hyper - 6 [actix](https://github.com/actix/actix-web) - 7
I'm surprised how often I get stack overflows when debugging as a result of this *not* happening, so... There's that, I guess.
(RFC author) `repr(C)` in this RFC was definitely a second-class citizen here, because if you don't have to, you just shouldn't use it. The use case in my mind is you're trying to bind to an *existing* tagged union in C(++) that you can't change the definition of. Regardless I don't think this matters too much because I would *strongly* encourage people to only use this RFC with machine-generated reprs bindings (which e.g. cbindgen has supported for several weeks). This is because it's very easy to get out of sync otherwise (someone adds or removes a case but doesn't know about the repr stuff happening elsewhere -- possibly in a completely different language). As such not knowing how they work "shouldn't" be a problem.
No, it does not. If you are talking about `&amp;mut *(data.get_unchecked_mut(i) as *mut T);` then it's just a trick to circumvent Rust aliasing rules, note lack of `Copy` or `Clone` trait bounds on `T`.
Yay! Congrats everyone! Someday I'd like to build out some more of the examples. Never enough hours in the day...
I would love to see Rocket on this list.
Oh, huh. Didn't occur to me to look into serde side to control special serialization behavior, thanks!
Awesome! Though I have to admit I haven't had a chance to play around with it yet :C
No way. Cargo is the de-facto build system for Rust and as I said, the entire eco-systen is build over this idea. Now, you say that it wouldn't be too difficult to build one for C++? Have you looked around? Sorry, but you've no idea what you're talking about.
Question while the post is here, I'm getting burned by static lifetime requirements in futures and services (i.e. https://github.com/tokio-rs/tokio-service/issues/9). Will the new tokio/futures address this?
extremely fast is relative term
After compilation it runs natively. It's like JVM - it also uses JIT compiler and then run some code natively. It is a matter of definition and how you look at given methods. I'm not an expert in this domain, so maybe it'll be better to ask someone else.
I believe he is referring to transform.now.sh.
This seems like such a trivial case, I wonder why LLVM can't do it.
`Ratio` should be easy to do, given `log (a/b) = log (a) - log (b).
A comment from actix team/designer would be welcomed. It seems they have iterate many times to raise the bar on every tests
I knew that something like this should be possible but I really don't think that someone should have to do this. Could the ownership rules be changed so that a function should be marked as immovable or won't ever cause a move to occur and then we have `iter_immov_mut()` where only immovable functions can be called
Unfortunately, I need to get the log of a prime number and the anti-log of the resulting value. Also, since the antilog is just exponentiation, I figured I can use the [pow](https://rust-num.github.io/num/num/pow/fn.pow.html) method.
What are the current Rust binary shrinking best practices? All of those?
Link is 404â€™ing
Works for me, probably an issue on Github's end.
Along with a few more referral links, so /u/Manishearth removed them and put a non-referral link there instead.
I've been using the python library to work with spotify, but I'd rather write it in rust, so I'll take a deep look at this library this weekend and see how implementation turns out! Thanks for taking the initiative.
I hear the Rust Programming Language is sold out at the publisher, so good to hear we're getting a repr(int).
As for this issue, I think people generally like the "principle of least suprise." As for your broader concern, I think it's never a bad thing to voice your concerns (with good intentions), even if people take it poorly.
&gt;There's a Rust wrapper around GMP, MPFR, and MPC called [rug](https://crates.io/crates/rug) which provides an arbitrary precision Float type which has ln and other log methods. This looks like it'll do the job. Thank you! 
I guess in both cases you'd do the actual `log` in `f64`. For `BigInt` I think you could probably get away with truncating the least significant bits, so you have a\*2^b -&gt; log(a) + b\*log(2). That's basically like floating point mantissa and exponent, so you might even just use `to_f64` as long as it fits in `f64::MAX_EXP = 1024`.
I have found one way around this on stable that seems to work. If the struct implements the `default` trait, you can create a boxed value of it using `Box::default()`, which internally is simply `box Struct::default()`. As it doesn't take an argument, like `Box::new` it generally avoids the extra stack allocation that LLVM has trouble getting rid of. Alternatively, it's possible to allocate arbritrary sized stuff with `libc`. That requires unsafe though. I'm also not sure whether it's safe (as in not undefined behaviour, it's obviously `unsafe`) to cast an allocated block of memory to a rust struct as you would do in C.
I think `let boxed = where(HEAP) 3` would be slightly clearer than `in(HEAP)`, and way better than reserving the `&lt;-` syntax for such a niche use.
I hope something like this gets stabilized soon. The RFC was merged 2.5 years ago.
Good question. I would have to look at an example since I do not know for sure. I assumed that since Tokio is a single event loop, any future blocking in it will block the entire loop.
Generally speaking, non static lifetimes is not really possible the way people want to use it in an async context... today. In theory, async / await should significantly help the situation.
&gt; Rust's enum types map awkwardly to formats like TOML or JSON if you want human-readable output. `#[serde(tag = "type")]` works great for me.
Speaking for the tests section, i know that there are some crates which allow for way more flexible testing, full setup / teardown of test environments etc which is only available on nightly
Another "con" and reason to use protobuf et al is cross-language support.
Ah that's a good point. Still unfrotunate that being the only way to go directly to the heap without initialization. I think what vec used internally aswell could be used to, I mean ultimatively it's great to have such a modern, productive and efficient language as Rust and if you need some more control you can always resort to unsafe. I mean ultimatively through unsafe you're allowed to do the things you can do in C so that's nice. Still, a bit surprised that Rust is such a stack focused language, not that that's bad but yeah just a bit surprised.
I love seeing great libraries get a 1.0 release. Congrats!
I think it might be because they are using `#[bench]` to use the built in benchmarking tools. Benchmarking is only available in nightly right now? Can't remember if it was stabilized yet. In any case, here are some stable examples from the cookbook: https://rust-lang-nursery.github.io/rust-cookbook/concurrency.html
Woooo, aborting when a panic reaches an FFI boundary is something Iâ€™ve been looking forward to. Fantastic work! Should simplify a lot of my FFI code.
The best part of the announce (after incremental compilation) is the best hidden: &gt;these functions may now be used inside a constant expression &gt;memâ€™s size_of and align_of Also, &gt;codegen-units is now set to 16 by default nice footgun for people trying to benchmark Rust in comparison other languages.
Was kind of hoping there was some support for working with threads that produce result objects. I find that incredibly hard to make work with rayon atm. 
&gt; One small note about this change: it makes builds faster, but makes the final binary a bit slower. For maximum speed, setting codegen-units to 1 in your Cargo.toml is needed to eke out every last drop of performance. I don't like the way this is phrased. It only applies for debug builds, not release builds. People like /u/VadimVP are [already getting confused](https://www.reddit.com/r/rust/comments/7xslc1/announcing_rust_124/duaszwp/) by that statement.
&gt; nice footgun for people trying to benchmark Rust in comparison with other languages. My understanding of this was, we expected ThinLTO to make up for it, but then that ran into problems, and it was decided to not back this out. I may be wrong though!
&gt; One small note about this change: it makes builds faster, but makes the final binary a bit slower. For maximum speed, setting codegen-units to 1 in your Cargo.toml is needed to eke out every last drop of performance. I don't like the implication here. Quoting from /u/achriton on the thread that was linked to: &gt; Performance should not be lost due to ThinLTO being on by default as well. People like /u/VadimVP are already getting [unnecessarily concerned](https://www.reddit.com/r/rust/comments/7xslc1/announcing_rust_124/duaszwp/) by that statement.
ThinLTO is also not quite on-par with regular LTO; from the latest status (CppCon 2017) the inter-procedural optimizations were lagging behind. To be honest, though, I still think that parallel build is the right default. It's pretty rare to have to eke out the last 1% of performance.
Please see my reply to them; ThinLTO didn't make it.
Then I think the community would agree this is just a bad thing, and I agree that it serves only to be a footgun, as /u/VadimVP said. I realize this is not your fault by any means, you're just the messenger.
I was just coming here to say the same thing, const size_of is a bfd
Yes. I am not 100% sure how this decision was made, but I also think of it as like regular LTO: We don't have it on by default for `--release`, because the gain is questionable, but the build times get *way* worse. Assuming that the loss isn't a ton, this would basically be the same tradeoff.
Out of interest, what happened before? What steps can you skip now?
https://github.com/cuviper/rayon/blob/rayon-1.0/RELEASES.md#release-rayon-100--rayon-core-140
You can do the same as you would with a standard iterator, [collect to a result](https://play.rust-lang.org/?gist=0cd06747aec924cbd0486fee900a569a&amp;version=stable).
Okay, will do. Thanks for your help this far :)
Rayon's tests require nightly mostly just for [compiletest-rs](https://github.com/laumann/compiletest-rs). The demos need nightly for `#[bench]` as /u/Tritanium mentioned, and also because we use `impl Trait` in a few places. It's possible we could clean that up -- isolate benchmarks to `benches/` and rework it without `impl Trait` -- but nobody has bothered yet.
Might it be worth having a `--fullopt` or similar with 1 codegen unit + full lto? (Or a more general ability to define extra profiles (does this exist already))
However, note that collecting an `Err` won't interrupt any tasks that are already running on other threads. It will just prevent any more tasks from starting.
There needs to be a definitive source to optimize settings for a release. If I have to manually change codegen-units and other items before Rust actually performs well, that would be good to know. It would be even better if this just happened for me from an intuitive command line parameter. Thoughts? 
There's no real way to be "definitive" here, in my understanding. You tweak some knobs, compile, and see what happens. &gt; before Rust actually performs well I think you're over-estimating the performance loss here. Give it a try both ways and see!
Having a cargo plugin that attempts to finagle with flags to find the most optimized output based on benchmarks would be a super interesting project.
Just a question, does it make sense to have the reactor live in rayon? Maybe expand rayon? Seems like a missed opportunity, for Rayon, Tokio, and the community if rayon canâ€™t be utilized for Tokio. What do you think, could rayon could gain Tokioâ€™s use case? Edit: sorry on mobile, large hands tiny screen.
&gt; Incremental compilation This is huge!
Yea, sorry, been desperately trying to get things cleaned up this week. I haven't touched BOLT-11 yet, though, so if you have something to share there (preferably using apoelstra's rust-bitcoin and rust-secp256k1 primitives) then I'd appreciate it greatly. Hopefully I'll just go for the code-dump warts-and-all this weekend (note that there isnt even a networking stack built yet, so things are obviously a long way to go...a bunch of the "core" is there, but actually hooking it all up, let alone debugging it, isnt).
I touched on this in the PR. Tokio &amp; Rayon are fundamentally different use cases with different trade offs. To be clear, assuming Rayon's pool is a futures executor, you can use Tokio's networking types *from* a Rayon pool. It just doesn't make for the right **default**. Could you explain more why you think Tokio should use Rayon's pool?
Can someone give me a short introduction what Rayon is and what it is being used for?
Working on this small wrapper to confirm if you really want to run commands... https://github.com/marceloboeira/confirm-before
There's a good introduction on the readme in the repo here: https://github.com/rayon-rs/rayon TL;DR: if you're doing something using iterators (i.e. using the `.iter()` method and then chaining methods off of that), then just import rayon and change `.iter()` in your code to `.par_iter()` and your program will magically distribute the work to all the cores on your machine, while still providing the same guarantees against data races that Rust normally provides.
wow, yup -- this is pretty awesome!
thanks!
[`bsalloc`](https://crates.io/crates/bsalloc) (the BootStrapping allocator) is under 200 lines of code. It's not really meant as a general-purpose allocator - it's explicitly designed to be used by other, more fully-featured allocators - but technically it is quite small.
[Parallelizing `rustc` using Rayon (internals)](https://internals.rust-lang.org/t/parallelizing-rustc-using-rayon/6606) [rust-lang/rust PR#46564: Parallelize passes using rayon](https://github.com/rust-lang/rust/pull/46564) It's being used for some cool things.
Also since rayon uses a thread pool and work stealing, even if it's not a win in one place but is used elsewhere it will most likely not be significantly slower anyway (at has never been for me so far) since the threads are there anyway.
Is there a place in the book where all this configurations tweaks are explained in a single place ? (codegen units, LTO, target-cpu=native, and maybe others I don't think about)
The detailed Release notes links to the PR [46287](https://github.com/rust-lang/rust/pull/46287)
No, as it's out of scope for the book. It's all in Cargo's docs: https://doc.rust-lang.org/cargo/reference/manifest.html
Does this mean GPU (array/matrix processing) is next on the list?
interrupting threads is essentially impossible to do in a generally useful way. Only if the thread is manually checking a "halt" flag occasionally and cleanly exiting itself, which isn't feasible when you're just running a long CPU-bound black-box function.
That's fair. It would be nice to have. 
Interesting. I would be thrilled to see this become a polished crate, because the underlying library (libui) is a choice candidate for being ported to Rust eventually also: https://github.com/andlabs/libui This would definitely jumpstart some conversations around native GUI bindings to Rust.
I'd note that for variable-length encoding, there must be some degree of space-time tradeoff; Decoding and encoding plain u64 must be simpler than doing anything variable-length. 
Weird. The Windows logic worked. It was freshly installed, as evidenced by that report, but a `remove rustfmt-preview`, followed by `add rustfmt-preview` made it suddenly appear.
Try /r/playrust.
There seems to be something weird going on with iron plaintext benchmark. Only 8.6% performance, and actually some errors too. The latency figures of plaintext benchmarks aren't that great either all across the board, I think that highlights more of a shortcoming in the test, but still would be nice to have rust do better on that side too. Interestingly it seems like actually vertx-web is the real winner in plaintext, considering that it achieves both low latency and high throughput. Could be worthwhile to check out how they are doing that. 
That and it's hyper 0.10 which is not async
We are accepting pull requests ^_^
you can check Iron performance in previous rounds, it was always around 6-8% 
Note that actix is using Diesel synchronously for its database benchmarks.
The use of the postgres crate instead of Diesel is a big chunk of it.
Ah, ok. I guess I didn't know these apart.
For reads? That's extremely surprising. Care to share your results?
&gt; How would you change bench code? 0..num_worlds.map(|random_id| worlds.find(random_id).first(&amp;conn)).collect()
i have partial results only, ## single query pg: 533k diesel: 513k ## multiple queries pg: 530k diesel: 506k
Cool, Iâ€™ll update code
Hm I'll have to profile it. That's really odd.
That might be just bench fluctuation. We should wait full preview run
I think hyper is good and it is fast. I didnâ€™t use hyper for actix because I need greater access to request processing pipeline.
They shouldn't even be close is the thing.
I hope to work on it more, especially if I get good feedback on the API design.
Wow, this is the first I've ever heard of mutation testing -- it looks pretty awesome! Some other ways to mutate rust: - Remove match arms, using `_` if necessary - When matching by value, match on different ones - Flip matches when values are not captured, i.e. `match foo {A =&gt; ..., B =&gt; ...}` becomes `match foo {B =&gt; ..., A =&gt; ...}`
Incremental compilation! Yes! Next stop: fix RLS! Very exciting stuff !
Gotcha. I'm not aware of anything specific in this area; maybe there's been bugs already reported about this.
People (I thought you too) have told me in the past that this would come after incremental compilation since RLS uses racer right now instead of the compiler itself 
Oh, if that's the root of the issue, then sure. I don't know much about RLS internals, just the high-level plan.
It worked for me after I did `rustup self update`
You shouldn't need to change anything. It'll only abort if the panic is not caught before it hits the extern "C" boundary.
Sounds like there's a glitch somewhere, and I had ran `self update` before anything. I didn't remember how I installed the old rustfmt, so I deleted it by hand since there's no `cargo remove` and `rustup component remove` did nothing because it doesn't know about rustfmt. I suspect I had installed rustfmt via `cargo install`.
Excellent change then! Thanks.
Could be. There is actually a `cargo uninstall` which I used though :)
 $ cargo uninstall rustfmt error: package id specification `rustfmt` matched no packages
I don't understand this. If you change the code your tests won't cover those changes... obviously. Would someone provide a real-world use and reason for this type of testing, please?
The goal here is to find code that, according to the tests, "isn't needed." This usually means you have insufficient assertions, because coverage testing finds that all the code gets run, but mutation testing finds that the tests aren't actually *checking* that the code is run (because the code is broken but they still pass). For example, consider this function and test cases: fn frobb(i: i32) -&gt; i32 { if i == 0 { 1 } else { 2 } } #[test] fn frobb_0() { assert!(frobb(0) &gt; 0); } #[test] fn frobb_1() { assert!(frobb(1) &gt; 0); } Mutation testing might transform `frobb(i32)` into this: fn frobb(_: i32) { 1 } ... and all of the tests would still pass, which means your tests are insufficient.
This is so cool; I remember your earlier blog post and been thinking that mutation tests would be nice to have ever since!
Actually, this crate is heavily inspired by [spotipy](https://github.com/plamere/spotipy), and I do look forward for your feedback :) 
Try `cargo install --list` to see what you have already.
Yeah it shows me two versions of rustfmt-nightly and neither can be uninstalled. Going to nuke ~/.multirust and add stuff again.
I'm a big fan of this crate. I like embedded key-value databases and I always reach for bincode for serialization.
we've got a little further to go before we can use incremental compilation for the RLS - currently it is only incremental in the code generation phase, for the RLS we would need it to be incremental for type checking too, which is currently being worked on.
If anyone is interested in playback, there's [librespot](https://github.com/librespot-org/librespot/). It uses the non-documented API (by reverse engineering the official clients), which allows it to support playing audio, as well as Spotify Connect. It has pretty poor support for metadata unfortunately, so it could nicely be used together with rspotify
 fn abs_log(x: &amp;BigInt) -&gt; Result&lt;f64, String&gt; { use std::cmp::Ordering; let zero = BigInt::zero(); let x: BigUint = match x.cmp(&amp;zero) { Ordering::Less =&gt; (-x).to_biguint().unwrap(), Ordering::Greater =&gt; x.to_biguint().unwrap(), Ordering::Equal =&gt; return Err("abs_log(0)".to_string()), }; let x: Vec&lt;u8&gt; = x.to_bytes_le(); use num::Float; const BYTES: usize = 12; let start = if x.len() &lt; BYTES { 0 } else { x.len() - BYTES }; let mut n: f64 = 0.0; // n will accumulate the f64 value as we go. for i in start..x.len() { n = n / 256.0 + (x[i] as f64); } let ln_256: f64 = (256.0).ln(); Ok(n.ln() + ln_256 * ((x.len() - 1) as f64)) } 
Would you add rust nightly support?
The plan for variable-length encoding is to have this be one of the bincode config options. I'll probably use Leb128 and would apply to length fields as well as enum variants. It would look like config().with_var_length().serialize(...) and config().with_var_length().deserialize(...) I'm only interested in maintaining back-compat *with the same configuration settings applied*. I should have made that more clear in the post, but I plan on writing another post on how bincode does config options.
Could you ELI5 this?
So that reference is wrong now, they a value of 16 for codegen?
In addition to different performance numbers due to multiple codegen units, isn't there a significant runtime performance difference between incremental and full compilation? Is the default compilation for a "release" build also incremental? Because it'd make sense for debug to be incremental by default (rapid development), but release be full by default for best runtime performance.
Yup :/
Is there a section in TRPL that talks about this? If not, maybe it would be nice to put in a list of things that one might try to eke out every last bit of performance. Maybe under `Advanced Features`?
AFAIK no, there's no way to do this if the data can't be `Copy`. Rust avoids hidden function calls as much as possible, by design.
That's understandable. I ended up using a macro workaround, but it's a little ugly.
I don't know if this is appropriate for your project, but for my hobby project, I separated my project into multiple subcrate to solve the compile time problem. I was able to take the slow-to-build-but-rarely-changed parts and move it into another crate. It's been a mostly successful approach.
The smallest allocator would have an empty body for `free`
You can add a lifetime parameter to a function like this: fn read_xml&lt;'d&gt;() -&gt; Root&lt;'d&gt; Lifetime parameters generally work like generic type parameters do. But if you just make that change you'll have another problem, which is that you're returning a reference to data that doesn't live long enough. You can tell because the `Root` struct has a lifetime parameter, so it must have a reference to something. Looking at the documentation, `parse()` returns a `Package` which owns the XML data. `as_document()` returns a `Document&lt;'d&gt;` which has a reference into the `Package`. Then `root()` returns a `Root&lt;'d&gt;` which has a reference into the `Document`. The problem is that since the `Package` which owns the data isn't moved outside of `read_xml`, it will be dropped at the end of the function, and then the `Root` has a reference to data which doesn't exist anymore. So the `Package` has to be owned somewhere, and the easiest solution is to change `read_xml` to return the `Package` so that the caller receives ownership.
Thanks for the kind words. Yes, I very much like to have this, too. ðŸ˜Š
&gt; we should honor the original invafiants as much as possible Am I learning a new word or is this a typo? It sure sounds cool!
Ever since people started writing automated tests, the question: 'How many tests are enough?' has plagued developers. So we look at metrics like line coverage, instruction coverage or even branch coverage, but those can only guarantee your code is *executed*, not that it's *tested*. Starting from the point that tests should guard against errors, mutation testing proposes automatically adding small errors to see if they get caught by the test suite. Now we know the tests actually ensure the *current* behavior of the code. (Note that I wrote *current*, not *correct* behavior. In general, we can only check if the code and tests are consistent. The hope is that the tests are so simple that they leave no room for errors.)
It is indeed a typo and should be fixed shortly.
Unfortunately, the often-changed parts are the ones that are slow to build. I basically have a crate for the server, a crate for the client, and a couple crates that are shared (one for DB, one for RPC stuff). Honestly, I suspect it's one of the libraries I'm using. I think either Diesel or Clap are just killing my compile times. I'm leaning towards Diesel, although unfortunately it's much too difficult to actually separate it out.
...which I don't recommend. 1. You don't really gain anything from reinventing that wheel, given cargo's role in both building and dependency handling. (In fact, some of the stuff maintained by the Rust team, which would be in the standard library in other languages, is distributed as separate crates to make maintenance easier.) 2. As someone who's been both an end-user for in-house command-line argument parsers and a reinventor at various points in my life, I'm qualified to say that we always underestimate how much knowledge and effort goes into reinventing them and how much silent frustration occurs when their shortcomings have to be worked around.
[removed]
Sorry, I think you misunderstood. I was asking if Rayon should be expanded to cover Tokio's use case here.
Fair enough.
What is difference between `&amp;[T]` and `[T]`? struct Foo { x: [u8], } struct Bar&lt;'a&gt; { x: &amp;'a [u8], } I found [this](https://www.reddit.com/r/rust/comments/4per6b/eli5_t_and_t/d4khtzp/), but I don't understand what is meant by unsized slice. 
I was just thinking about mutation testing in rust this morning, exciting.
I dunno. I thought it was pretty incremental. ;)
 extern crate sxd_document; use std::fs::File; use std::io::prelude::*; use sxd_document::dom::Root; use sxd_document::Package; fn main() { let package = read_xml(); let root = package.as_document().root(); } fn read_xml&lt;'d&gt;() -&gt;Package{ use sxd_document::parser; let mut file = File::open("some.xml").unwrap(); let mut contents = String::new(); file.read_to_string(&amp;mut contents).expect("Unable to read the file"); let doc = parser::parse(&amp;contents).expect("Failed to parse"); doc } is this what you had in mind?
Cheers mate, this is the _exact_ way I needed it to be described for it to click. Thanks!
The overall API seems good at first sight, but I wonder if it is possible to avoid passing the context on every method. Since there can be only one UI, it seems just boilerplate
This looks like exactly what I've wanted for a while. Unfortunately... When I go to [the documentation](http://sit-it.org/doc/getting_started.md), it takes 15.3 seconds and 97 requests to display an [almost totally blank page](https://i.imgur.com/PA7ATII.png) and a JavaScript error: "TypeError: request.completes is undefined". When people wonder why I loathe the modern web, *this* is why.
It also has long-standing issues like this one https://github.com/rust-lang-nursery/rls/issues/227.
 &gt; Serialized data can not be read if structure changes &gt; **No reordering fields** &gt; No adding / removing fields Shouldn't bincode serialize fields in a canonical order (such as the alphabetical order) so that it will not break on reordering? 
Also, forgot to mention: you can read same exact piece of documentation here https://github.com/sit-it/sit/blob/master/doc/getting_started.md
I love this concept so much. I just have a question regarding the directory structure: why so many .hidden files? I get why the top level .sit begins with a dot, but not why anything under it would. It's just annoying when listing the dirs with ls. Also: in a Git project, I would use this on an `issues` branch (just like github pages are `gh-pages` a branch in the repo). In this case, it makes little sense to have everything inside a .sit directory; I would prefer a top level issues/, web/, reducers/, and config.json. Perhaps this can be supported? Anyway, be sure to regularly post progress reports here! Best of luck.
Is Rayon for Rust what OpenMP is for C/C++? I know that question is broad, but how do they compare?
Then why not apply that thinking and join the project? ðŸ˜‰
&gt; The idea behind dot-names was vaguely around "this is about the item/concern" whereas the regular names are 'this is actual data' This makes sense, but I suppose it will be a focus of bikeshedding. Such as: another way to mark metadata is to have a dir "metadata" (with or without a dot) and put the metadata inside it. :P &gt; I, however, recommend to think about having issues coupled with the actual branches. This would give you per-revision snapshot of the state of issues. Hugely valuable, at least in my books. Hmmmmm you're right, that's kind of awesome. (Same rationale as having the documentation checked in alongside the code, issues are part of the documentation after all. And that's why I dislike centralized issue trackers like Github issues)
Isn't a side effect that you will start writing tests that match your code instead of your use cases?
Closer to parallel versions of [standard algorithms](http://en.cppreference.com/w/cpp/algorithm) that were added in C++17. Was previously known as [Parallelism TS](http://en.cppreference.com/w/cpp/experimental/parallelism)
I might try it. But for adopting it in a project I would need bidirectional mapping to and from Github. That is, a bot that read Github issues and post comments to SIT (maybe adding some metadata such as the URL of the original comment), and reads SIT issues and post comments to Github. Like [GerriBot](https://github.com/golang/go/wiki/GerritBot) but instead of PRs, issues. Btw, I think it would be nice if SIT also handled PRs too (discussion in PRs are also a form of documentation that should be checked in alongside the code IMO)
I'm curious what does work-stealing means in this context? Will it move event-loops from thread to thread, and futures/tasks will stay attached to one event-loop? Or will it move tasks between different event-loops, where event-loops stay on the same thread? I think Netty5 tried something like the first approach. However they have found out that it wasn't really as beneficial as expected, and abandoned that branch. The second approach would require moving future-types between different event loops. That typically isn't super efficient, since the underlying handles need to unregistered and reregistered to an poll/kqueue/etc. instance.
Synchronizers are definitely part of the plan. It's an obvious need. As a part of financing the development of this project, I'm planning to offer commercial services by my non-profit (Etcetera Labs, Inc., it's goal is facilitation of open source development), which will include synchronizing from and to various sources. For open source projects, these services will be free. SIT already handles Merge Requests. If you check out SIT's own issues in sit-web, you'll notice a lot of issues marked with MR. They will have patches inside. Two scripts in ./scripts already facilitate sending and meeting these (doing them manually is a little too involved). Merge Requests in SIT are also kind of SCM agnostic. Basically, SIT knows nothing about them, but the basic reducers plus sit-web know what those are. But the actual preparation and merging is SCM and project specific, and that's why it's handled by separate scripting.
This is also the first version that builds fine on sparc64. I'm currently building a Debian package which I am going to upload into the *unreleased* repository of Debian, so it can be used for compiling *rust_1.24* once it gets uploaded to *unstable*.
Good to know! Will synchronizers be closed source?
I think that open sourcing the synchronizer from the beginning is the best strategy. Either people will pay for your hosted instance, or will host it themselves. It still sounds a good deal for paying customers (I myself would only pay if I had the reassurance that I could run my own instance if I wanted to). If needed, you could later adopt the Gitlab model: label the open source version "community edition" and make a proprietary version called "enterprise edition" with new features, that are scheduled to come to CE at a later date. Since the enterprise edition would only run on your own servers, you don't even need a CLA for this to work (as long as you don't pick a license like Affero GPL).
Thanks! Abomonation looks pretty similar to what i'm doing right now, and just seeing how heavy serde is sounds like a good plan. It might just work out, once I can convince it to run in no_std mode.
One variation I was thinking is to build a limited "synchronizer" product first (GitHub, public projects only) first, as an open source. Offer hosted instances as well. The rest of the features will go to the EE with scheduled release to CE. Another variation was to make the whole product EE first, then do the scheduled open source releases. You can buy EE as a service or as a self-hosted software (so you can still run it yourself). The goal is to figure out which strategy will ultimately bring in more cash as that will allow to spend more on the development of the core product. Something to figure out for sure! P.S. I have an aversion for AGPL, it seems to be understood differently by different people/companies.
https://crates.io/crates/rusty-xinput XInput dynamic loading can be done in stable as of Rust 1.24, so here we go.
You can still add a field that is sorted in the middle of the existing ones.
You're building something on pretty weak foundations. libui is all but abandoned.
Can anyone explain why Travis seems to be trying to run my crate as Ruby? Build Log: https://travis-ci.org/abonander/multipart/builds/342091790 .travis.yml: https://github.com/abonander/multipart/blob/master/.travis.yml
I think you're both right. This change won't affect the performance _much_, but it would still be cool for someone to add some documentation on optimizing a release.
`&amp;[T]` is a fat pointer on the stack; it's a pointer and a length describing a dynamic length array (slice) of `T` somewhere else in memory. `[T]` or a type containing it is the abstract type for that slice. It's not meant to be consumed by-value because the size is unknown at compile time (thus, "unsized"). Traits can also be used as unsized types; the syntax is exactly the same. When an unsized type is used as the type of a field, it makes the containing type, e.g. `Foo` here, unsized as well. That means `&amp;Foo` will be a fat pointer containing the start of the instance in memory and the length of the `x` field; if you take `&amp;foo.x`, you get `&amp;[u8]`. Because Rust only supports double-width fat pointers, a type may contain at most one unsized type (in structs it used to be you could only have it as the last field, I don't know if that's relaxed now that we have field reordering). It's not currently possible to construct `Foo` in safe code as it is defined. Instead, you have a type parameter that is bounded by `?Sized`: struct Foo&lt;T: ?Sized&gt; { x: T, } And then you construct `Foo` with a sized type (here, `[u8; 32]`), then coerce either a reference to it, or a `Box`,`Rc` or `Arc` to the unsized type: let foo: Foo&lt;[u8; 32]&gt; = Foo { x: [0u8; 32] }; // sized let foo_unsized: &amp;Foo&lt;[u8]&gt; = &amp;foo; // unsized let foo_boxed: Box&lt;Foo&lt;[u8]&gt;&gt; = Box::new(Foo { x: [0u8; 32 ]); // unsized (any container that implements `CoerceUnsized` can have this done to it) This works interchangeably with traits as well. // an object-safe trait we can use as a demonstration use std::fmt::Display; let foo: Foo&lt;&amp;'static str&gt; = Foo { x: "Hello, world!" }; let foo_unsized: &amp;Foo&lt;Display&gt; = &amp;foo; println!("{}", foo.x); // println!() args are referenced implicitly
Do you have a real world example at hand where bincode is used in such a manner? Some crate on GitHub? I don't know much about embedded key-value dbs and am curious what that would look like.
I haven't tried it myself yet, but how about multi-window approach? So you'll have two windows, one with 3D visualization and second one for controlling the simulation (e.g. written with `grtk-rs`).
While interrupting a task that is running is not feasible, avoiding starting tasks is a very useful concept, both for "aborting" on errors and for stopping checks when using for example any and all. When implementing such operations, it is of course important to note for users that the short-circuiting is done on a best-effort basis.
Note for the sake of discussion: the first can do what the second does and the second can do what the first does. let whatever = match File::open("file.ext") { Ok(file) -&gt; Ok(process(file)), Err(e) -&gt; Err(e), }; let whatever = file.with_open("file.ext", process)?; I'm not really sure why I decided to write this, but it's late, beware of typos (syntax errors) 
There's a [Cookie header type](https://hyper.rs/hyper/0.8.0/hyper/header/struct.Cookie.html).
&gt; I knew that something like this should be possible but I really don't think that someone should have to do this. Why not? In Rust it's all about [choosing your guarantees](https://doc.rust-lang.org/book/first-edition/choosing-your-guarantees.html). Want multiple mutable references to a resource? Use pointers. Of course then the tradeoff is having to deal with all the dangers of raw pointers. &gt; Could the ownership rules be changed so that a function should be marked as immovable or won't ever cause a move to occur and then we have iter_immov_mut() where only immovable functions can be called It sounds like you are afraid of the actors getting moved whilst being iterated over. That's not a problem, the borrow checker still catches this. Check [this example](https://play.rust-lang.org/?gist=a386a314112b68f8d83e1fa1ebf89e99&amp;version=stable) out. --- However I do think that for OPs example splitting the the borrows is the best choice, since in their example the two loops never have to overlap anyway. 
Actually, I spoke too soon! I got Way Cooler working with proprietary Nvidia drivers! There's no hardware acceleration but.... thanks to this news from a few days ago and yesterday: [XWayland-EGLStreams-Support] (https://www.phoronix.com/scan.php?page=news_item&amp;px=XWayland-EGLStreams-Support) &amp; [GLXVND-Lands-In-Master](https://www.phoronix.com/scan.php?page=news_item&amp;px=GLXVND-Lands-In-Master), the future for proprietary Nvidia support in Way Cooler is looking bright!
&gt; these functions may now be used inside a constant expression: memâ€™s size_of and align_of It saddens me that they didn't (or couldn't) go with the D approach. In D you can run any code that is not unsafe, and where you have the source code available. So no external calls (like into a C library). That's it. There was a blog post about a compile time sort in D and the code is just ... void main() { import std.algorithm, std.stdio; enum a = [ 3, 1, 2, 4, 0 ]; static b = sort(a); writeln(b); } It would have been so cool if standard Rust could could just run at compile time, seamlessly, instead of having to mark functions as `const`.
&gt; I don't want to use any additional crate. This is most likely a bad idea. But anyway, you can try something like this: #[derive(Default)] struct Args { var1: bool, var2: String, var3: i32 } let args = Args::default(); for arg in ::std::env::args().into_iter().skip(1) { if arg == "--var1" { args.var1 = true; } if let Some(var2) = arg.split("--var2=").nth(1) { args.var2 = var2; } if let Some(var3) = arg.split("--var3=").nth(1) { args.var3 = var3.parse().unwrap(); } }
How do I make code of this form prettier? let something : Option&lt;_&gt; = ...; if something.is_none() { return None; } let something = something.unwrap(); ... without putting the entirety of the rest of the function in an `if let` block. Also, what if we generalize the `return None` into `return something_specific`.
I'm sorry to say this (I'm a webdev myself), but I agree with /u/Quxxy. This might be an extreme case, I know, but this is also the post of "first public release" so I'll take this as an opportunity to point it out. This page loads 500kB of stuff (in Chrome!) but the page at first glance contains only the most basic of HTML â€“ text and images, with default link colors no less â€“ *and the file rendered on Github is easier to read*. I know you mean well but I would be *really* annoyed had I opened this over a cellular connection. This is not how you should do doc pages IMHO. Please render stuff like this statically and make this 10x faster. That's an actual number by the wayâ€”I recently wrote a Jekyll theme for the quicli docs and the pages are 5kB. Add a few well-optimized screenshots (only show the actual content not the window's frame and optimize the files with imageoptim or something like that) if you have to and end up at 50kB. Sorry for the rant. I'll go back to work on my 10k line SCSS codebase now.
I agree with the sentiment. But I also have to choose where do I put the limited amount of time I have. Eventually this will be sorted out one way or another. I'm also hoping somebody who's good at this can help with it. As a side note, one of the reasons both sit-web and the documentation are done the way they are is because this requires exactly zero processing build on runtime on the backend. 
If your function returns `Result` then you can do this: let something_opt: Option&lt;_&gt;= ...; let something = something_opt.ok_or(something_specific)?;
I'd advise against upx most times, since (a) slows down start up (which is really crappy for a CLI tool), (b) it'll trigger anti-malware-y things (self-modifying code doesn't look good). Also just `zip`-ing your executable is nice and portable and has same effect really.
Ah cool. This makes sense (but, could be better I guess). I just touched the file rather than editing it and the rebuild goes down to 17s. I've already started to plan out pre-allocating comments regions. ;)
I just tried in Firefox 58 and it is awfully slow to load and use, it loads into a blank page for a second before displaying anything, and then any internal links in the documentation does _exactly_ the same. The user experience is horrendous. I agree with the other users, why do the documentation have to be web components? Simple static pages, just like Rusts documentation both works, are future proof and fast. This is way overkill for really no benefit.
You still need to call customElements.define() to register each component, so it's not static HTML
`const` is an API commitment, though. With the D approach it's possible for a library call in constant position to go from valid to invalid with no conscious thought on the part of the library maintainer. That said, possibly you could get around the issue with an `unmarked_const` lint?
You can always write tests that match your code instead of your use case, mutation testing doesnâ€™t change that. But why would you?
There's rustfmt-nightly, which is only available on nightly (until today!) And was there recommended rustfmt, you might have that.
Same here. What's the expected version ?
I've run into this with certain crates (the image crate springs to mind). If you're only using certain items from them, you can `pub use` them within one of your own crates that rarely changes. This solved some of the worst of my compile time issues - but it really depends on what you're using and where.
Thatâ€™s a very good point I hadnâ€™t considered.
Something strange is happening on my machine (the OS is Darwin 16.7.0). I stumbled upon this when I tried to run [plato](https://github.com/baskerville/plato)'s emulator: - When I run `cargo run --bin plato-emulator --features emulator` under 1.24, I'm getting absurd values and segmentation faults when the fields of the `FtFace` structure defined in `src/font.rs` are being read (more precisely, the `width` and `height` fields of the `(*(*face).glyph).metrics` structure look like pointers). - The same command runs smoothly under 1.23. The puzzling thing is that the bindings to *freetype* and the version of the *freetype* library (2.9) are the same in both cases.
So I saw 'can use Cell in static' and thought: (safe) global variables. A possibly evil thought, but static flag: Cell&lt;bool&gt; = Cell::new(false); can't work anyway because `Cell` is not `Sync`. So what would be the use of `Cell` in a `static`? 
So why don't you just link there then?
Because you can't plan everything in advance. Maybe I'll redirect firefox users there :)
I would still recommend doing that and maybe fitting that into a macro or a function returning an appropriate error. It just makes the disaster case much more predictable, turning a footgun into a safe mistake to make.
which part?
Sure, if you're interested in bubbling up the error to the caller instead of aborting. Some software wants to abort.
I donâ€˜t think you can use it in a static. This mostly just means that const fns can now be used on stable rust (not declared), and that Cell::new can be used in a constant context. So for example in an intermediate calculation of the actual final constant (which youâ€˜d need full on stable const fn for). Additionally you can still use this to declare constants instead of statics, so it has its use, even if atm a very minor one.
They're all listed in Cargo's docs, which I posted upthread.
Or structopt, until it's integrated into clap.
That's the correct version. This isn't the "latest" `rustfmt`, it's the one that rides the trains. This is expected. /u/razrfalcon.
You can use `Cell` in `const` expressions, that doesn't mean that using one in a `static` is safe: error[E0277]: the trait bound `std::cell::Cell&lt;i32&gt;: std::marker::Sync` is not satisfied --&gt; src/main.rs:3:1 | 3 | static c: Cell&lt;i32&gt; = Cell::new(0); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `std::cell::Cell&lt;i32&gt;` cannot be shared between threads safely | = help: the trait `std::marker::Sync` is not implemented for `std::cell::Cell&lt;i32&gt;` = note: shared static variables must have a type that implements `Sync`
What's FlatBuffers about?
/u/llogiq, admit it, you only made this for an even longer Reddit flair :)
False alarm then. Thanks
It's the successor of ProtocolBuffers. Much faster, somewhat more similar to Cap'n Proto, but at the same time much simpler in its wire format than Cap'n Proto. There was [a Rust port](https://crates.io/crates/flatbuffers) in the working, but that seems to be put on hiatus.
The master branch has not been updated since 2016, but there's work happening on other branches: https://github.com/andlabs/libui/tree/utflib-and-attrstr and the maintainer also seems to be active in the issues. 
Please file a bug!
Usually, by "static HTML", people mean "doesn't require a web server." Static HTML can use JavaScript.
I think it's a really good idea. As a Rust beginner I would love to be given a challenge and be able to see other peoples solution, and also get feedback on my own code.
Ok, one more. Let's say I have a function that accepts a HashMap, and I want it to return the keys: fn allkeys&lt;K,V&gt;(object : &amp;HashMap&lt;K,V&gt;) -&gt; Vec&lt;&amp;K&gt; (K: Eq+Hash not written for brevity) if I call it with a u32 as the key, it would become this: fn allkeys&lt;u32,V&gt;(object : &amp;HashMap&lt;u32,V&gt;) -&gt; Vec&lt;&amp;u32&gt; if I call it with a String, I would want it to become the following fn allkeys&lt;String,V&gt;(object : &amp;HashMap&lt;String,V&gt;) -&gt; Vec&lt;&amp;str&gt; There's a non-symmetry here that I'm pretty sure `Borrow` can resolve. How do I change the real function signature to do this? 
I'd prefer that they don't use nightly, to be honest. Nightly Rust isn't really Rust, but a possible future Rust.
It doesn't use hyper for any of that stuff, so that doesn't matter. It itself is not async though.
Yeah this'd be cute, maybe even architectural challenges i.e. create an API &amp; data structures to solve a specific problem? Not sure how this'd work, but for sure playing with lifetimes / mutexes / references etc is the hardest part of rust for me!
Exactly, one week could be implementing search trees and the next could be interfacing with an AWS API.
Ok, I found [some](http://smallcultfollowing.com/babysteps/blog/2014/01/05/dst-take-5/) explanation of DST and fat pointers. I think it is more clear to me now.
http://steamcommunity.com/profiles/76561198053373227/home 
Huh was under the impression it had been using hyper for requests. Guess I'm wrong. Good to know :)
This would be excellent! I'd be willing to contribute to organizing something like this. :)
In my understanding, it only uses the types, for compatibility purposes, but doesn't use it for making requests.
FWIW in Servo we found that compiletest-rsâ€™s passing `"-L target/debug"` to rustc was fragile and would sometimes break. (E.g. if you end up with two `.rlib` files for the same crate with different hashes.) Weâ€™ve replaced it with [`compile_fail` doctests](https://doc.rust-lang.org/nightly/rustdoc/documentation-tests.html#attributes) which happen to work on stable.
&gt; is because this requires exactly zero processing build on runtime on the backend. The pages have to come from somewhere, which requires a nonzero amount of processing. Regardless of all of your other arguments, this is just wrong.
Standard HTML and CSS require "backend processing amounting to zero" as well. The doc page works fine on my copy of Firefox, for whatever reason, but if a substantial percentage of users are experiencing issues with the websites design, I wouldn't just blame my users' browsers. "It works for me" is rarely a satisfying solution. But, this is open source: do whatever you want. No one can force you to do otherwise.
I like it. Maybe take a hint from /r/dailyprogrammer and have an easy challenge suitable for a newbie from another language in addition to one that will challenge Rust regulars.
I'm not blaming them. I'm just stating in various answers that the current situation is the result of limited time I have. It works I'm chrome. It apparently works in your Firefox. It's upsetting to both those commenters and me (I'm very attached to the project!) That it doesn't work perfectly. But, as with any love project, some things are going to work and some won't. With nonzero amount of time, things can be fixed. I'm sorry if I came off as blaming others for their problems somewhere.
I just realized I never informed you here on Reddit -- I made [an issue](https://github.com/ErichDonGubler/not-yet-awesome-rust/issues/20) for this hoping to get your feedback. Would you be willing to look at the PR I'm going to make for this, to make sure I'm not missing something?
Unfortunately there's nothing else that really has the same cross-platform capability within an order of magnitude of the size. Ideally, prior to 1.0, iui will go pure Rust (with "c" bindings to platform libraries only).
That was an interesting read, thanks! Could you explain why `stride = cur_slot * 2 + 1`, how is `PATIENCE` chosen, and why is a stack pointerâ€™s address an appropriate basis for a RNG?
That last example does not catch enum moves though
Or alternate days. So we are not doubling the work.
A challenge could be presented each week, then after a few days we present our solutions and possibly choose the most performant/elegant/creative/etc. A poll could then be created to choose the next one.
Because I want to know the generalized solution
agreed, note the comment I was replying to.
Looks like a syntax error in your travis file (it doesn't like the comment). See: https://lint.travis-ci.org/abonander/multipart
Somewhat off-topic, but you might also give vanilla gRPC a try, a well-supported (but unofficial) crate exists. I can't speak to tarpc or capnproto-rpc, but the gRPC crate is great. Uses Tokio, returns futures. It's a wrapper around the gRPC C Core library so you are getting the true experience. https://github.com/pingcap/grpc-rs
You just gonna leave this up? Lol
Regarding new set of functions that are now const fns, can the rest of the numeric operations be turned into const fns? E.g., functions defined here that don't return results: https://github.com/rust-lang/rust/blob/1670a532dd769763f1d6ad9e5d624ec31361a098/src/libcore/num/mod.rs Could you just s/pub fn/pub const fn/ or is there more to it than that?
AIUI, having Rust build 16 output units instead of one reduces the opportunities for the final stages of compilation to perform optimizations, which may result in larger and/or slower artifacts than when it built one unit that contained everything. On the other hand, it is faster to build 16 smaller pieces and do less transformation work on them, so this speeds up compilation time at some runtime expense. So when people go to compare Rust artifacts against those from other languages/compilers, this may be a handicap to the Rust score.
I think that if possible, beginner/intermediate/advanced would be awesome, so you could do something at a simple level, then grow it so you can circle back with a better understanding as you grow. I'm a beginner, and I love this idea, but I am worried about it starting being either out of reach of the beginner, or too simple for advanced users to seriously participate.
Have a look at dear imgui, worked pretty well when I tried it.
Yes, but you don't need the lifetime on read_xml anymore.
That's not an allocator anymore then, is it
In addition to what /u/Quxxy has said, when you title a post on Reddit, you need to make it understandable as to what you actually want. The name of the subreddit as the name of the post gives zero useful information, except that the post is probably not worth reading. Also, 3,000 hours in a video game? That's a full time job for 18 months!
I too want this so badly I can taste it.
Neither actually. The thing to keep in mind is that, with Tokio, I/O resources (like sockets, i.e. what you register w/ epoll/kqueue/...) and tasks (user code) are separate concepts. The Tokio reactor *only* drives I/O resources. The executor (thread pool) runs user code. Those can be on separate threads. So, the work-stealing bit here only applies to the executor and not epoll. However, part of the reason to introduce a default runtime is that it adds the necessary flexibility to experiment in the future. Tokio has the advantage of decoupling I/O resources w/ user code execution, which allows for some unique setups to experiment with.
Never used Borrow before but I think this is it: fn allkeys&lt;K,V,B&gt;(object : &amp;HashMap&lt;K,V&gt;) -&gt; Vec&lt;&amp;B&gt; where K: Borrow&lt;B&gt; + Eq + Hash { object.keys().map(|x| x.borrow()).collect() }
We had a lengthy discussion with /u/georgerush and there is a plan to improve the situation. Current design is mostly intended to give people a taste of what author had on his mind. Later on, after the dust settles, a proper UI plan will be put in motion. Thanks for input, it's truly awesome that sit flow is getting an interest ! 
A good philosophy. It's gotten better, but the number of times I lost _all_ my work in Way Cooler because of a bug causing a panic has made it really annoying sometimes... On the other hand, every time I suffer through that and fix the bug it makes me happy because that's one less bug a user will run into :)
Ah gotcha; that makes sense. Thanks! For enums, would it not be better to just figure out the needed number of bytes ahead of time since everyone is statically working with the same enum definition?
It's similar to `#pragma openmp parallel for` in that it let's you do parallel iteration with minimal code on your part. The big benefit is that you can basically replace any `.iter()` with `.par_iter()` and everything else works the same. With openmp, you need to worry about what reduction/variable types you want. 
I would love to be able to do this! Unfortunately, it would require that information from Serde. I filed this bug on serde a few months ago: https://github.com/serde-rs/serde/issues/1068
It's not a typo, it's a mutation to test the reader.
If your code doesn't match your use case, the best mutation testing can do is to alert you to the fact because you might feel the mismatch while testing.
So nested enum types are supported? In a way yes, was trying to imagine how RON binding to Haskell would look like, anyways Ignore the bit about function types :)
No, I hadn't even thought of that. But it's a really interesting project.
&gt; Say I'm building a Tokio server and want to do async file io, which do I pick? The answer (at least for now) is *not* tokio-threadpool. It's specifically designed to execute futures, i.e. non-blocking bits of code. IMO, if you are running a bunch of networking related tasks AND a Rayon based computation, you **are** going to want two thread pools. Rayon assumes you can block the thread (and handles it internally). At least for blocking file ops, Tokio will soon have a better answer than "run it on a thread pool".
I agree that rlib dupes are an annoying problem. My hesitation with `compile_fail` doctests is that AFAIK you can't specify *how* it should fail. So if you're trying to test some specific error like "item is not `Send`", but accidentally had a syntax error, you might not be running a useful test after all.
Enum moves? Iâ€˜m not sure, what exactly do you mean?
In addition to what others mentioned, remember that Rust lets you do this *fearlessly*. The usual rules around ownership, borrowing, `Send`, and `Sync` all make sure that your journey into parallel code will be a safe one. https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html https://blog.rust-lang.org/2017/11/14/Fearless-Concurrency-In-Firefox-Quantum.html
Yes, we serialize all the things nicely!
Thatâ€™s fair. Rustdoc supports testing for specific error codes, but only on Nightly.
Let us say that we have the following enum enum Id { Str(String), Id(usize) } If that was added to the `Actor` type and we tried to do an assign within either loop, the compiler will not catch it even though the size of each actor has changed and thus need to be moved
https://github.com/erickt/rust-serialization-benchmarks There was also a paper on serialization performance which I cannot find right now.
Yes, I should have made that more clear. The minimal std is considered a feature, not a bug :)
What is the most "rustic" way to implement something like a B+ tree, where nodes need to have a mutable pointer to the root node? An `Rc&lt;RefCell&lt;T&gt;&gt;`? I've looked over the std BTreeMap code and understand how it works for the most part, but I am curious if there is a way to do it without some of the complexity.
Not directly, but eventually.
There is no need of any configuration for getting imenu to work if you have `rust-mode` installed
Note to self and /u/Veedrac: benchmark bytecount with single vs. 16 codegen units, change release profile if it wins us anything.
I would absolutely love this! Not only would I love to participate, but I would be more than happy to contribute towards making this a reality as well. As an developer who is new to rust and trying to get more comfortable with it, this would be an amazing way to improve my skills. 
I'd hope it doesn't, given we have a small collection of functions that *should* be inlined wrt. each other.