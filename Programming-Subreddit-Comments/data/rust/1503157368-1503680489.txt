I'll be around for sure. 
YES! This was the #1 thing I was hoping for in the crates.io improvements, so I'm really happy to see it shipping so quickly. Thank you to all who worked on this!
FYI you have to add ```readme="README.md"``` to your Cargo.toml and republish for this to work
Small inlined functions are very common in Rust. Trust the compiler to do the right thing in release mode. Exception: Cross-crate calls won't be considered for inlining unless they are generic or annotated `#[inline]` - [this is sometimes surprising](https://github.com/rust-lang/rust/issues/37538) Also, a machine language call is if I understand correctly cheaper than a miss to L3 cache. There is no memory cost to the `struct Newtype { v: Oldtype }` pattern.
They're the same thing. `for ... in` is just a syntactic sugar for using an iterator.
It's a bit premature to be wary of Rust's future just because of brson's departure. We survived Graydon's leaving (the original creator of Rust), and we survived pcwalton moving full-time to Servo. If anything, the only thing it makes me concerned about are who will be maintaining brson's two primary projects: rustup and cargobomb.
[removed]
Here is an example. It looks nice https://crates.io/crates/chroniker
The sidebar makes it seem like somebody died (with a full beard before the age of seven).
Hey Rustaceans, I'm a newbie trying to write a basic String-splitting parser, and I find rather frustrating the amount of nesting I end up having in my code. I've found myself resorting to code that looks like: optionally_a_string .or(Err(parse_error("...")) .and_then(|s| s .split(":") .... (so forth) What I really want is like... `unwrap_or_err`, I guess. The further nested things get, the more unwieldy the code feels, and more I get the impression I'm back in old-school Node.js callback-hellland. Any better approaches you've taken to this problem that don't involve dedenting a lambda?
This is long overdue. Crypto has requirements for seed provenance that are at odds with game/simulation reproducibility.
I don't know anything about the author, but think very carefully before buying anything from Packt, they're the book version of a puppy mill. I've known some talented people who meant well that worked with Packt and it resulted in a book they and their readers weren't happy with because Packt doesn't really support their authors well or edit the books properly before they get released, let alone guide content/design/pedagogy.
Huh, I have not done either of those things and both of my crates have their readme's rendered.
So every time I may want to use an iterator, I can just use `for ... in` instead? Are there situations where this is discouraged or not ideal? Thanks
It's written in C But you'd want GC in Rust same reason you'd want Rc. Also interacting with JS (see Servo interacting with Spidermonkey). &amp; Gc&lt;T&gt; can be cyclic without leaking
Maybe it was already there? I don't think the readme field is new. (At least my crates already had that set.)
There are programs in coreutils that are Redox specific. We *are* helping to improve uutils where it benefits the Redox project. It will likely be that we will carry utilities that are specific to Redox, or require a large amount of platform specific code.
Ah, so it is.
`Cow` also enforces immutability. Also, I have a package `mucow` that implements the mutable borrow counterpart.
Can we add ability to somehow use readme in the crate level documentation? Maybe through something like `#![readme]` which will insert readme file content for `cargo doc`? Otherwise many projects will have to duplicate a lot of documentation between readme and crate documentation.
r/playrust
Everyone else is correct; this is a Higher Rank Trait Bound. But I'd like to aim you at [the much more illuminating answer](https://stackoverflow.com/a/35595491) I got on Stackoverflow a while back... It's surprising difficult to find a concise explanation of why HRTBs are necessary.
Man i have more than 2 years of Rust on my clock!
I second this motion. While the distinction between the two is meaningful in general, I found that crate-level documentation and the contents of the readme file tend to be effectively identical for most of my crate repositories. Having a way to include the readme (or a general `include!()` for documentation) would be nice. It can be immensely useful for deduplicating documentation that must appear on multiple language items as well.
`for` is the special case of an iterator driving procedural actions: for each element, take these steps. There are a bunch of iterator combinators that do cool things like "replace each element with zero or more elements according to this rule" or "start with this value and combine it with each element in turn." Those are methods of `Iterator` and don't have special syntax.
Well, given that I'm only exporting a custom derive, the only place I **can** put the doc is on the module itself. That, or put it on the `derive_smart_default` function - which makes zero sense since no one should be using it by name... Usually custom derive crates are companions to another crate that defines the trait, but in my case there is no `SmartDefault` trait and I can't put the doc on the `Default` trait. So... the only reasons my documentation is so straightforward are that I have very little to document and that I can't utilize the module's hierarchy for documentation navigation. I'm not so sure whether or not it's a good thing...
Fixed. Travis should be publishing the new docs soon.
Put a gun against his head
??????????????? I'm confused by this sentiment. what eggs. what basket. brson does good work, and is an amazing person, but is hardly irreplaceable?
Just wish him have fun going forward! And come back for a visit once in a while!
This is something we've wanted for a long time, but nobody pushed it across the finish line. I'm on my phone or else I'd point out some stuff, there's a few RFCs, the new edition of rustdoc has big plans here, and a few half-finished PRs.
Latest big one should be [#1990](https://github.com/rust-lang/rfcs/pull/1990), right?
Are you using the try operator `?` with `ok_or`? I would also look at the `nom` crate. 
[removed]
Not really sure how do you make it nested too much. Can you post a bigger example? Then it would be easier for me to see how to restructure the code.
Yeah make it black and white to achieve full obituary status? Just kidding, but probably is worth it to make it a little more explicit?
I wouldn't worry about `std::mem::transmute(())`. If the user needs to use `unsafe` to get around your guarantees, I'd say your API is safe enough.
Until this is a builtin feature in `cargo`, there is the plugin [cargo-readme](https://github.com/livioribeiro/cargo-readme), which I'm currently using. **tl;dr** what it does: - You write a template for your `README.md`, which defines which content goes where and adds other things like license terms, contributing info, and what else not. - You run `cargo readme &gt; ./README.md` *(or modify your `build.rs` to do that)*. - This command will extract your module documentation of `lib.rs` or `main.rs`, fill it into your template, and thus generate a `README.md` that is always consistent with your documentation given in source code.
Most language leads seem to enjoy the position pretty much for life. C, C++, Go, Python, Ruby, Scala, PHP. On the other hand, Java or Swift. For some definitions of lead, seem and enjoy, anyway. :)
I had to change `readme=./README.md` to `readme=README.md` for this to work for me. Exciting hearing about this live at RustConf :D
Oh, cool! That's also a good benefit ^_^
Thank you for the quick response! I can see this becoming a commonly used library, especially with the good documentation, and simplicity of code and use.
Thanks /u/brson for all you've done! Honestly, I've been expecting to see exits from the core team for a while now. The pace of development has been very rapid for the last 3 years, this fast for so long can burn out anyone. I hope Rust can survive this.
Nice catch, good to know!
(sidebar updated, you dweebs)
Interesting choice to use procedural derives. I sorta feel like it's somewhat weird with using attributes to resolve to expressions (as there is double quoting with strings), so I wanted to see how it does look with `macro_rules!` which make it easier for a macro to accept expressions. This doesn't handle generic structs/enums however, and I'm not entirely sure how it could be changed to support those however, which is an advantage of procedural macro approach. I mean, your implementation currently doesn't handle those (I think), but I don't think there is anything stopping you from supporting those, unlike my `macro_rules` implementation. Either way, good job on the procedural macro implementation :). macro_rules! default { ($name:ident $($rest:tt)*) =&gt; { impl ::std::default::Default for $name { fn default() -&gt; Self { $name $($rest)* } } } } #[derive(Debug)] pub enum Foo { Bar, Baz { a: i32, b: i32, c: &amp;'static str }, Qux(i32), } default!(Foo::Baz { a: 12, b: 0, c: "hello", }); fn main() { println!("{:?}", Foo::default()); } 
The `?` operator sounds like exactly what I want -- but running `cargo run` gives me an error about it not being stable. Does it just need to be enabled, or...? EDIT: looks like it became stable but my rust is too old. I didn't realize my package manager doesn't update rust for me -- had to run `rustup update`!
Where would I see the output of this? In the terminal window where I launched `RUST_LOG=rls_analysis=info code .` or in a window inside VS Code? Or a log file? Thanks! edit: (That invocation of VS Code doesn't seem to produce ANY output to the terminal where I launched it. It seems to fork itself or something) edit2: If I do this, then VS Code dumps output, but I'm still not seeing anything related to RLS: ``` export RUST_LOG=rls_analysis=info code --verbose . ``` --- edit3: I ran `rustup update`, it pulled a newer nightly and things are working. I should've thought do that...
&gt; All the software engineers I know, myself included, generally change projects after a couple years (say, 3 to 5). At some point you need a change of scenery, you wish to explore new challenges, ... While this is true of most developers, I feel like in some of the bigger, broader reaching projects, core developers tend to stay on for a long time. Linus Torvalds has been involved in Linux for more than 25 years. Larry Wall and Perl. Guido van Rossum and Python. Matz and Ruby. Bjarne Stroustrup and C++. With Rust now having lost two former project leaders, Graydon and Brian, I wonder a bit about whether something about the project structure and community is more prone to burnout than other projects. Of course, the project is in [plenty good hands](https://www.rust-lang.org/en-US/team.html); I just hope that the project can continue to retain, and attract new, contributors as welcoming and inspiring as they have been.
To be clear, Brian was only the project lead in the immediate wake of Graydon's departure, back in 2013. I believe it was only a few months until Aaron Turon took over as project lead, with some of the technical responsibilities of that role being split off into a new "Technical Lead" position which was assumed by Niko Matsakis. &gt; I wonder a bit about whether something about the project structure and community is more prone to burnout than other projects. I personally doubt it. When there is a widely-acknowledged "BDFL", like Perl and Python and Ruby all have, then it's easy for someone to stick around for years even if it's only a figurehead or managerial role (in fact, once you've been around long enough, it's hard to *leave*, because there's so much pressure from the community not to; imagine the message it would send if Guido *did* want to move on from Python (and Python development isn't even Guido's full-time job!)). A lot of us coming from these dynamic languages really *did* want Graydon to be a BDFL for Rust (myself included), but he was *really* not into that prospect (downright uncomfortable, in fact). After Graydon left I was very uncertain about Rust's future, but in truth our project governance today is way clearer and healthier than it was back then (that's not Graydon's fault, though; young projects have growing pains) and the interaction between the core devs and the community is top-notch. The fact that we've endured losses of longtime core developers in the past has made us pretty resilient to turnover (our bus factor is way lower than most OSS projects (though it could still be better)). But finally, *every* project loses developers over time; we're blessed with a lot of well-liked prolific developers, so there's no way this is going to be the last time it happens, and the dev team is very transparent about interfacing with the community, so when it happens it's always going to be high-profile. :P Doesn't make it less sad, of course!
I think this is the right sub for it (in addition to the others you linked), because non-moving, high performance GCs are a point of interest of the Rust community. However, it should be wrapped in a self post, as the sidebar says &gt; All submitted posts must explicitly reference Rust or link to repositories written in Rust. If you have a link that does not mention Rust but you believe would be of interest to the community, then please wrap the link in a self-post that explains its relevance. We prefer this approach over linking directly to the material and leaving an explanatory comment.
Sending results back from worker threads to a master thread is one basic way to use it. To create a simple protocol, just make an enum of the message types. But you're right that the standard library doesn't include much policy.
Does this field work with paths? `../README.md` for workspace crates does not seem to do the trick. EDIT: This problem seems to be happening with the [openssl crate](https://crates.io/crates/openssl) too, even though it has the correct [path](https://github.com/sfackler/rust-openssl/blob/master/openssl/Cargo.toml#L9).
lol, amazing. 
The badges that make sense in the GitHub repo readme make less sense rendered on the crates.io page. I guess I could solve this by duplicating the file to `CRATESIO_README.md`, clean it a little, and update my `Cargo.toml`s?
Agreed. Macros let us experiment without committing to a syntax.
https://www.reddit.com/r/rust/comments/6uplsn/cratesio_is_now_rendering_crate_readme_files/dluosla/ I needed to remove the path.
Good catch about Generics! Totally forgot about them... I'll add support in the next version. Not supporting generic types is bad enough, but seeing how lifetimes are generics this really limits the usability of smart-default... [My original implementation with `macro_rules!`](https://www.reddit.com/r/rust/comments/6i6cfl/macro_rules_make_it_hard_to_destruct_rust_structs/dj3z0kz/) had nice syntax, but had hard time dealing with visibility modifiers and with attributes on the fields. The biggest advantage IMO of procedural macros over `macro_rules!` is that you don't have to deconstruct and reconstruct everything. This gives you the option to not care about syntax you don't need to handle. At any rate, the main problem I'm trying to solve here is not the extra glue syntax but the need to maintain two different lists that need to be synchronized - the list of fields and the list of default values. Even if the lists should be short, and even if the items are named, and even if they are located close to each other, and even if the compiler yells at you when they are not in sync - I still find it suboptimal maintainability-wise.
Sure, but removing it only works as long as your README.md is in the same path. In my case, I have a workspace, so the README.md file is on directory up.
Thanks for the explanation! You had a lot of fun with those fours, didn't you?
So it seems that this is specifically for traits. Is there a way to use this or something similar to elide lifetime bounds for concrete types?
Why not split package manager into two repos, official with signed names, and unofficial, where you have to add username or other namespace before package name. 
There's a pile of crypto use cases for reproducability too though (e.g the ChaCha/Salsa RNGs were originally designed to be stream ciphers, for which reproducability is required).
This is a great change, the old `crates.io` felt like it was just an index, and not really a hub to find crates. Having the docs, code, and readme all behind links to external sites really made it annoying to shop around for crates if all you had was a keyword. As a consequence, `crates.io` was often the *last* place I went when I was looking for a crate, just to check the most recent version before I used it. This change makes it so that `crates.io` feels like the hub of rust crates that it should be, and now it will be the first place I look for crates that I have no knowledge about.
I'm not sure if this is the best place to ask, but I'm looking for some help on debugging memory usage and I'm a little confused about the best way to do so. I'll try to keep the backstory as short as possible. The project I'm working on is taking a large amount of text and making [ngrams](https://en.wikipedia.org/wiki/N-gram) out of each sentence. In order to cut memory usage, I ended up storing each text file in a `String`. Each individual ngram generated is stored in this struct, which I assume indexes into the original `String` for each word: struct NgramData&lt;'a&gt; { p_prev: &amp;'a str, prev: &amp;'a str, current: &amp;'a str, } All the sentences for each text file are stored in another struct that looks like this: struct Ngrams&lt;'a&gt; { source: &amp;'a str, // The text file name data: Vec&lt;NgramData&lt;'a&gt;&gt;, // All the ngrams generated for each line content: &amp;'a str, // The original text } With this setup it is currently turning 31MB of text into 330MB. This is where my question comes in though. I feel like this can be a lot lower, but I am unsure of the sizes of objects or if there are more efficient ways to store things. As far as I'm aware, the absolute minimum usage I could expect is somewhere around 31MB for the text, plus ~5MB for roughly 203,000 `NgramData` structs assuming 8 byte pointers for the strs. Of course I'm nowhere near that and don't know if I'm missing something. Edit: It turns out I was doing my calculations wrong. The 203k number came from a smaller test run, and there are actually 6,304,670 `NgramData` instances total. Multiply that by 48 bytes each and you end up with 302MB, and that number plus the 31MB original size adds up to roughly my 330MB number. So it turns out I'm doing the best I can as far as I know. (Although if I'm not, feel free to let me know!)
~~just curious: why would it need libuv if we already have mio? does it have any advantage over it?~~ my mistake! i clicked on https://h2o.examp1e.net/ and thought this was the official homepage... sorry!
Mike Pall made a luajit 3.0? Aw no, he only wrote up a plan.
Sorry -- misspoke. Usually this debate centers around keygen rather than stream ciphers.
True, wonder if it's easy to add a PR to fix that.
I honestly don't like it. I always liked how stripped down and structured crates.io was. I am very afraid that with the existence of this feature a lot of crates will adopt SYNOPSIS style READMEs, which I loathe.
I don't know them offhand, but there's reasons why Cargo doesn't use namespacing in packages. It wasn't exactly a new concept when it was being planned out.
Having a separate README.md for GitHub and for crates.io kind of defeats the purpose...
Is that a form of fork-join parallelism? What about where the producers are long-running threads (they run indefinitely instead of producing a single 'result') sending messages to another long-running thread that does something with them, I guess the simplest example I could think of is something like a logging thread. Maybe this is such a simple concept there's not really a name for it.
Yes. This was the main reason I wanted to write it. Smaller crates documentation might only need a README file so including it at the crate root for offline docs would be great.
I ended up envisioning adding so much stuff to surge that I wasn't enjoying working on it anymore. Someone told me to commit to a single vision of the project, so I deleted [almost 1000 lines](https://github.com/sevagh/surge/commit/f8ce9a5b1511756ef9c08dea2d9989fb7af8d143). Now it's just a raw text/cli interface to YouTube + MPV.
I use one for sending websocket messages from multi threaded code. I've previously used one as an email sending worker too, they're super handy.
Pulled my trigger, now he's dead
Edit: If you mean to include a file as a string, the [include_str](https://doc.rust-lang.org/std/macro.include_str.html) macro is exactly what you're looking for There is no way to directly do that in rust, but if your file is in your src folder is laid out like this src |-&gt; main.rs |-&gt; other.rs then you can do the following in main.rs: mod other; then anywhere you want to import from other you can do: use other; For a more in depth explanation, [this](https://rustbyexample.com/mod.html) will be a good resource 
Mama, life had just begun
&gt;1. Inlining across the C/C++ Rust boundary using Link-Time-Optimization You'd need the C/C++ to be built using Clang, because LLVM doesn't understand MSVC's LTCG bytecode. &gt;2. Better cross compilation to Windows from other platforms You still need all the various system libraries and CRT runtime bits, which aren't exactly free to redistribute.
Oh, I hate the idea. But I don't want those badges in the crates.io rendering either.
Yes, logging is one possible example. Every worker (or any other thread you wish) is a producer, and the logger is the single consumer.
Just curious but why would you want to do this?
I highly recommend [Far Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) for an entirely applied approaching to learning rust fundamentals. I found it the best thing for really learning the mechanics in the language as the author repeatedly gives you "bad code" as a means to explain why it's bad before giving code that works as a progressive lesson that results in one of the multiple implementations of linked lists. The rust programming language book is also very good as it has it's own two large-ish projects, in particular the last one as you implement the multithreaded server. I found it useful but believe the commentary in TMLL was a bit more thorough and insightful because of the author's applied approach. I like to use the rust programming book as a better documented standard library in terms of explanations and examples of key features and types for Rust.
Hello and welcome! Understandable that you might be having some issues, especially if you skipped the book, but it's pretty cool to see you getting this far! :) You can check out the [examples on the Rust cookbook](https://rust-lang-nursery.github.io/rust-cookbook/net.html) for some basic HTTP stuff. They are using [reqwest](https://docs.rs/reqwest/), which is like a synchronous version of Hyper. You can read more about [`Result`-specific error handling in the book](https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html). It's kind of like Go's `(value, error)` thing, but has a bunch of handy methods and the `?` operator to get rid of the annoying boilerplate. If click to expand expand the (non-obvious) arrows in the top left of the example snippets, you'll see that most of these are using [error-chain](https://docs.rs/error-chain) to compose error types from multiple libraries together.
If you want help with this, you will need to show the code you're having trouble with and the complete error message. This includes the `Cargo.toml` file. Ideally, you should provide enough code for someone else to try and compile it on their machine. It is easier for someone to help if they can see the error and try to fix it. Also, I suspect there might not be any spanish speakers here. ---- Si desea ayuda con esto, tendr치 que mostrar el c칩digo con el que tiene problemas y el mensaje de error completo. Esto incluye el archivo `Cargo.toml`. Idealmente, debe proporcionar suficiente c칩digo para que otra persona intente compilarlo en su m치quina. Es m치s f치cil para alguien ayudar si pueden ver el error y tratar de arreglarlo. Adem치s, sospecho que puede que no haya hablantes de espa침ol aqu칤. (via Google Translate)
For main reason I personally don't see a lot of focus on it in your proposal. And do we really need external documentation for items? I think ideally we want something less general and focused on linking readme as a whole or just parts of it. So we could link usage and description, and not e.g. license information or links to documentation. Other detail is that sub-headers (##Usage) are often used for sections in readme, but in crate documentation it's preferred to use headers (#Usage) instead. Also we probably don't want to duplicate project name or badges in the crate documentation.
It was my reason but not necessarily for the proposal is all :) maybe! I think a lot of people have wanted the more general proposal and I'd like to give people the flexibility to choose how they structure the docs
People still there tonight and/or heading anywhere else? I had to do some stuff but might join if people are still going.
Agreed. Once you know how to use error-chain, Handling errors using `Result` feels like what Java's checked exceptions aspired to be. (And `?` is easier to type than `.unwrap()`, which encourages doing the right thing, even in throwaway scripts.) Also, I highly recommend the [clap](https://clap.rs/) argument parser over rolling your own. If you want to see an example of both of them working together, I've shared the boilerplate I use to start my own "small scripts or hobby projects": https://github.com/ssokolow/rust-cli-boilerplate
You, and your beard, will be missed 游븺
We've got linguists in the computer language sub again. Get the shwah out of here! /s
I'll have to act as the opposing opinion. 1. If I already know what I want, I rely on the AwesomeBar to call it back up quickly. 2. If I don't know what I want, then the first thing I'm going to check is the README. I always groan when I encounter a link to crates.io because it means I have to wait for my Firefox (bogged down with extensions and too many tabs) to load the (in my mind unnecessarily) JS-based design, then go to the links and identify which of them means "GitHub/GitLab/etc." in this particular author's mind in order to find the information I actually care about. In its current state, the only thing I actually value about Crates.io is as a search engine. Once I've found candidates, it just slows down my day. While it's possible it could make READMEs worse, crates.io has a right to seek greater relevance.
I'm not a huge fan of having a manual step to keep the authoritative copy and the copy GitHub displays in sync. There's a reason why, with the Python projects where I'm eventually going to give in and use Sphinx, I'll import the `README.rst`into the manual (which can happen automatically when the ReadTheDocs push hook runs Sphinx) rather than the other way around. (I say "give in and use Sphinx" because it's clear to anyone who looks that it's a "LaTeX for the web" replacement with bolted-on apidoc functionality written by people who don't really understand the problem domain. ePyDoc is actually one of the reasons I ensure my codebases are Py2/3 compatible if at all possible.)
Far too many linked list is the best programming text that's been written since why's (poignant) Guide to Ruby. It transcends language teaching with incredibly insightful sidesteps and prose approaching that of great rapmasters.
Glad I'm not the only sysadmin dipping into rust. Like you python was part of my standard tools, so rust has been bewildering thus far. Best of luck :)
I get where you are coming from as my workflow isn't much different, but I don't see this changing much. Before, I opened the "Repository" and "Documentation" links, and looked at those. Now I'll look at the crates.io page instead of the "Repository" link, hope that the author has set the "readme" field, and if they haven't I'll go to the repo link. I think the existing means of description/tags/categories are enough to establish relevance. I'm not saying that this change in itself is the end of the world for README quality, but combined with things like [an auto generated README](https://github.com/rust-lang/cargo/issues/3506), the quality could significantly drop over time.
Thank goodness for the format option on the playground...
I have a situation where I have to read in a lot of "events" from files on disk. I then take each event and do some number crunching with it. I use the build in mpsc to load the next event while I still crunch the previous one. It also comes with a build in FIFO.
Whaaaat! OMG, brson has made so many wonderful contributions to Rust. Thank You! I can't imagine what kind of mental/emotional energy it takes to do what he did.
This is the third time *in a row* you've posted to the wrong subreddit.
Am on mobile, so I can't test atm. Does this also generate documentation attributes, e.g. `#[doc = "The default value for this field is ..."] ` on fields or `#[doc = " This is the default variant"]` on default enum variants?
I have an example here: https://github.com/cedenday/bitcoin-donation/blob/fea447f53df030a542e9551ece4958e70596b975/src/rpc_run/mod.rs#L34 `'static` won't work for some reason.
Vulkano and Glium's developer has a patreon. https://www.patreon.com/tomaka
So can crates.io now be used an a linkfarm using Readme.MD files filled with links? :p
I found a number of design patterns here http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html and a book of the same name, looks like I will find more examples.
Assuming the N in gram is constant and you know which str the NgramData refers to you can just store the index of the first part of the data. struct NgramData&lt;'a&gt; { p_prev: u32, prev: u32, current: u32, } oldcurrent = content[current..current+n] If your string can exceed 4GB then you'll need u64 (or maybe usize to save memory on 32bit platforms). If content is below 2^16 bytes you could use u16s. If you're string contains characters that may exceed 1byte in the utf-8 encoding then the slice may panic if you split a string in that case you could work around with something like. content[current..].take(3) If you only have single byte characters then just working directly with bytes might by better since it'll avoid the utf-8 checks when slicing strings. Assuming u32 works this would cut the size from 48 to 12 bytes. I'm unsure what the p_prev and prev are used but there maybe ways to drop those as well.
Funny, it seems to be already working for docs.rs, e.g. for [runner](https://docs.rs/crate/runner/0.2.1). Maybe because this is not a library crate?
Thanks a lot for all those great comments, i feel like i conceive a lot about programming languages and IDEs now. ^-^ Secondly: This here might be a nice approach, it seems like independent support for all IDEs for a specific language. For such huge monsters like Rust and OCaml maybe exactly the right thing, while OCaml is much more suitable for IDE support. https://opam.ocaml.org/blog/turn-your-editor-into-an-ocaml-ide/
Great post! I especially like the intro to writing macros.
No, it doesn't. Another thing to add to version 0.2.0... I don't think I can add documentation on the variants/fields themselves with custom derive. I can, though, add them on the `Default` trait implementation, or on the `::default()` method.
My suggestion would be to steal some ideas from https://github.com/alkis/decimal/blob/master/src/dec128.rs wrt. the API design (implementing `Hash`, making `serde` support optional and so on). That crate also has an extensive test suite that you might want to ~~use~~ take inspiration from. Of course, implementing something like `decNumber` would be a large undertaking and is not really the scope of your project.
Suppose I have enum Expr { Num(i32), Plus(Box&lt;Expr&gt;, Box&lt;Expr&gt;), } and given `&amp;mut Expr` I want to simplify the expression by changing all `$expr + 0` and `0 + $expr` to `$expr`. I would like to write it like this: fn simplify(expr: &amp;mut Expr) { match *expr { Expr::Num(_) =&gt; {} Expr::Plus(ref mut a, ref mut b) =&gt; { simplify(&amp;mut **a); simplify(&amp;mut **b); if **a == Expr::Num(0) { *expr = **b; } else if **b == Expr::Num(0) { *expr = **a; } } } } Of course, this does not work, because I can't move `a` or `b` out, and I cannot mutate `expr` while it is borrowed. Workaround involves either cloning or swapping a placeholder into `a` or `b` to allow moving the value out and then using it to overwrite `expr`. Can anyone suggest a nicer solution? [Playground link](https://play.rust-lang.org/?gist=c2cbd29e161f19ad88f5ce154b9b0e6f&amp;version=stable)
My reasoning is behind automatic generation of paths for a web server from the tree structure on the files
I don't really get what you're trying to do, but if you want to include an arbitrary file as a module, you can do: #[path = "path/to/file"] mod foo; [Link to reference](https://doc.rust-lang.org/reference/attributes.html#module-only-attributes)
I've heard of TMLL before in passing, but it wasn't really on my radar until now, thanks. Should I know or at skim The Book before embarking on TMLL?
Doing a similar thing myself, I have found it much easier for simplify to just take ownership of Expr rather than a mutable reference. I appreciate that that may not be possible in your case though!
But can that be done with a non - static string in a variable? 
This. So much.
When I try to format the number it gives me zero instead let a = Decimal::new(100, 2); let b = Decimal::new(300, 2); let c = a / b; println!("{}", c); println!("{:.2}", c); prints: 0.3333333333333333333333333333 0.
Depending on your dialect of Spanish, the word *aliado* may feature that cluster
Still working on an eCAD tool in rust. Trying to figure out the best approach for graphics: https://www.reddit.com/r/rust/comments/6uvqrj/what_libraries_should_i_use_for_a_vector_graphics/
consider posting this to /r/playrust this is the subreddit about the programming language Rust
Reddit really, really needs to fix their posting UI
No, the full String object requires runtime to make, so it can't be resolved at compile.
One could always `transmute` to a binary string and set variables that way. Or if you prevent use of `mem::transmute` they can always reach directly into the program's memory using kernel APIs and set them that way. Once you're no longer using safe code all bets are off.
then you might be interested in our pre-alpha official cookbook effort :) https://github.com/rust-lang-nursery/rust-cookbook
Have you tried conrod? It may do some of the immediate mode optimizations you mentioned.
It already explicitly warns people about this specific case. There's only so much you can do when people just won't read warnings or do even cursory research. You can lead a horse to water, but you can't force it to drink. At least, not without a pump and some tubing, but at that point I'm pretty sure you'd be violating at least *some* laws...
Webrender?
Is this the release before hitting 1.0 or 3.x (to mimic the GTK+ versions)? It would be great having a stable gtk-rs. But this release comes handy, I will try it out next weekend.
I kinda liked the idea so I ended up implementing a version as well: [gist](https://gist.github.com/Gustorn/4758c12464e0ec3b67ccd65535145ec6). I also welcome any and all criticism. As for OP, I have three suggestions, one of which you already thought of: 1. Error handling. You have a *lot* of unwraps in the code, some of which might hide valuable information (specifically the `Result` from the `transfer.perform()` call. That one is potentially really useful for the user and communicating it as a panic might not be the best idea) 2. I think using the `curl` crate was an unfortunate decision: it doesn't really promote idiomatic Rust code (in my opinion at least). 3. And finally a small tip. Since you already have a `serde_json::Value`, in the last `println!` call you could just do `println!("{:#}", json)` to get the pretty-printed value. This avoids an additional `unwrap`. 
It's a pretty easy-to-miss warning on desktop and nothing at all on mobile (at least on the official app, don't know about the alternative reddit readers). /r/rust is doing everything it can, reddit just needs to help out.
I doubt it'll ever reach 1.0 (or at least not right now, maybe next year?).
Perhaps this is a bug with the way the format counts characters? i.e. you said you want 2 digits, but instead it gave you 2 characters
Lyon is a great library for turning 2d vector drawing into geometry that can be rendered with any graphics library (gfx-rs, glium). You still have to cache the resulting meshes yourself though. ggez uses it for it's 2D drawing primitives, if you want to experiment.
If you can't have the path at compile-time, you need to dynamically load it at runtime: https://crates.io/crates/libloading
you sound insufferable E: inb4 "please give me a formal peer-reviewed definition of 'insufferable'"
I'd have a look at the official rust forums 
Yes, it will be very beneficial for the ecosystem
Also whether calling it 1.0 or 0.3 or 3.0 or anything else does not really mean anything. It's just numbers, and independent of the actual number this works very well. There are probably minor API changes in the future still, but calling it 1.0 would also not protect you from that. If a change is necessary it will have to happen
Those are actually some really nice ideas, but unfortunately I'm not working with constant size strings. The best alternative I can think of would be doing something like this, which would drop the size of the struct to 9 bytes. #[derive(Debug, Deserialize, Serialize, HeapSizeOf)] pub struct NgramData&lt;'a&gt; { // Previous, previous string p_prev: u16, p_prev_len: u8, // Previous string prev: u16, prev_len: u8, // Current string (ngrams start with ("", "", "Word")) current: u16, current_len: u8, } This runs into another problem though, which is I'm not sure how to actually get the indexes into the original string from a slice in an efficient way. I currently generate the ngrams with this (using the ngrams crate) which can finish 31MB of text in roughly 2-3 seconds on my machine. let lines = content .split('\n') .filter(|s| !s.is_empty()) .collect::&lt;Vec&lt;&amp;str&gt;&gt;(); for line in lines { let ngs = Ngrams::new(line.split_whitespace(), 3) .pad() // Pads front and end spaces with \u{2060} .collect::&lt;Vec&lt;Vec&lt;&amp;str&gt;&gt;&gt;(); for ng in ngs { // Only add if it's not the last one // i.e., ("end.", "\u{2060}, "\u{2060}") if !(ng[1] == "\u{2060}" &amp;&amp; ng[2] == "\u{2060}") { data.push(NgramData { current: ng[2], prev: ng[1], p_prev: ng[0], }); } } } However, when changing over to numerical indexes I feel like I'm forced to use `str.find` to get the indexes which is incredibly slow. The original implementation with just `str.find` in the `NgramData` initializer took several minutes and didn't even finish the first book. I then changed it to use a `HashMap` to avoid looking up the same value several times, but that still took it over a minute to index all the text. I can say though that when it did finish, the final memory footprint was only 94MB. If there isn't a better way to get indexes then I guess I'll have to decide on speed vs memory. Thanks for the ideas by the way! I didn't think about using indexes at all, and they clearly save a ton of space. I just wish my string sizes were constant so I could take full advantage of it. Edit: So I was looking for a way to find a pointer since that would give me the index with just subtraction, and it turns out that is possible. Changing the whole string searching thing to using `str.as_ptr` and `ptr.offset_to` makes the entire thing take less than a second to run! I also verified that the offsets and lengths were correct, and they are pretty much perfect; just need to manually fix the \u{2060} entries. Thanks again for the idea!
We already have two core team alumnus; Huon and Patrick.
This is somewhat tangential to /r/rust - the emulator described is written in Rust, and it discusses a couple of things related to the Rust language but is not itself about the language.
FYI: This subreddit is about rust the programming language, not rust the game
I believe that this is very close to what I want but I from reading its documentation I gather it is more for loading external shared library's and what I would like is dynamic loading of local modules by the path to the file that it is defined in. Leading to something that you can set to a variable by doing something like `use from "path/to/file"::get::init as init;` which I know is not possible directly 
So - you want to have all the files in compile time, but pick and use the one you want by path at runtime?
Thank you; I'll take a look to see what concepts may make sense translating. 
[removed]
Thanks for trying it out! That is what appears to be happening. Currently the display logic converts the decimal into a string and uses `pad` to allow for formatting. Looks like I'll need to extend that function a bit further to allow for further formatting instructions.
There is a trick to it and it's called `mem::replace`. I've written a [Rust idiom](https://github.com/rust-unofficial/patterns/blob/master/idioms/mem-replace.md) about it
Interesting shortcoming of current custom derive. I'd have thought this should work, but I must admit that I haven't used it yet. Adding a `Debug` representation to the docs of the derived `default()` method might be helpful as well, though.
Sweet! I'll eventually need to use glib for my library, nice to see it getting some improvements. Cairo as well 
Oh I'm used to the N in ngram referring to characters and not words. Where in ASCII the N would be a constant byte size. Due to alignment your structure is really 10bytes and not 9, assuming rust reorders the fields, in C it would be 12 bytes without hand reordering. This is because the u16's need to start on an address divisible by two, so the u8's will have padding added to them. If you only have ascii characters you could take content.bytes().enumerate() and build the ngrams by hand with the offsets. Alternatively you could store the words and the indices to the words like let content = r#"one two three four five six seven eight"#; let mut ngram_idxs = Vec::new(); let mut words = Vec::new(); let lines = content.split('\n').filter(|s| !s.is_empty()); let mut word_idx = 0; let mut line_words = 0; for line in lines { for word in line.split_whitespace() { words.push(word); if line_words &gt; 1 { ngram_idxs.push(word_idx); } word_idx += 1; line_words += 1; } line_words = 0; } for (i, ng) in ngram_idxs.iter().enumerate() { println!("ngram: {}", i); println!("current: {}", words[*ng]); println!("prev: {}", words[*ng - 1]); println!("p_prev: {}", words[*ng - 2]); } You could change the integer type stored in ngram_idxs depending on the maximum number of words you'll have. Right now it's a usize but likely could be smaller and cast up to a usize.
Sort of yes
You can do this with a macro.
So what is the idiomatic way to express that a Future may take multiple paths? I'm reading data from a local on disk/ram _cache_ (in LDMB), so my future _may_ return the item, or it _may_ require I make a network request and phone home for this item. I get I can return an `enum` from the DB check future, which can either return immediately, or do the inner remote-request stuff. But this feels _sloppy_ as my possible paths/states increase I end up writing _a lot_ of enum states, and I have to encode a ton of `panic!("This state should be illegal");` logic. --- In reality the DB requires a lock-future that does an in-ram check for if the request has version information/side effects from business logic. Another state is if the request for the ID is already live on the network.
It looks like that brson was doing most of the work to maintain this list, but anyone privy to future stabilizations can contribute to it.
Why?
I would note that Rust doesn't try very hard to be OO. Polymorphism is more about plugging in different implementations of a desired behaviour. One good (and not excessively complex) example in the standard library is Hashable and Hasher. There's no `class` keyword that tries to structure data and associate methods and define interface and provide encapsulation. Instead there's `struct`, `impl`, `trait`, `mod`.
[removed]
Yeah, I remembered that I can use that instead of `mem::swap`. However, because I am trying to replace a value with one that it owns, it still requires jumping through hoops in the same way as my `mem::swap` solution. I ended up extracting that hoop jumping into a function and using that (still a bit ugly, because you need to have a dummy value, and it does not make sense for `Expr` to implement `Default`). fn replace_with_inner&lt;T, F&gt;(value: &amp;mut T, dummy: T, select: F) where F: FnOnce(&amp;mut T) -&gt; Option&lt;&amp;mut T&gt; { use std::mem::replace; if let Some(v) = select(value).map(|r| replace(r, dummy)) { *value = v; } } fn simplify(expr: &amp;mut Expr) { replace_with_inner(expr, Expr::Num(0), |e| match *e { Expr::Num(_) =&gt; None, Expr::Plus(ref mut a, ref mut b) =&gt; { simplify(&amp;mut **a); simplify(&amp;mut **b); if **a == Expr::Num(0) { Some(b) } else if **b == Expr::Num(0) { Some(a) } else { None } } }); } Edit: I've read your examples, they are indeed nicer than my code. Thank you.
/r/playrust
Because we're "just" (a bit more but still) a binding over a C library. It seems difficult to have ever something that we could say is 100% safe. From this statement, how can we be 1.0? Also, as `sdroege_` said, it's not really an issue or anything, the version numbers don't mean much.
I'd like to have a 1.0 meaning of "We've figured out how things should work for the most parts, you can use this now".
1.0 does not mean "100% safe". It means the API is stable, as in "not changing every day". After you go 1.0, you have to stay backwards compatible with every new release, or up the major version number if you need to break backwards compatibility. 1.0 means that programs can finally start using the library without worrying that the API will have a breaking change tomorrow.
Cargo assumes version numbers follow semver. That means that after 1.0, every 1.x version will be backwards compatible with the previous version, i.e. not make any breaking API changes.
Looks like a case for polymorphism! Make a trait with the common API of the different files, and create a function that returns a [Trait Object](https://doc.rust-lang.org/book/first-edition/trait-objects.html) based on the path you provide. Or any other key - just because NodeJS does it with paths doesn't mean you have to! Maybe something else would make more sense... The main problem is resolving the keys into trait objects. Rust does not have "static constructors", so you can't have them fill a registry before `main` is called. Depending on how many such files you have and how often you add new ones, you could either: * Write them all manually. Register them into a map, write a big `match` expression that creates them, or create a macro that'll do it - the main property of this choice is that you have to maintain the list of files in your code somewhere. * Use a [build.rs script](http://doc.crates.io/build-script.html) to generate that list. Your build.rs could scan the files for a pattern that indicates a file should be part of the list, and generate code that implements the previous option and you can use with `include!`. It's more difficult to implement, but once you do it you won't have to worry about maintaining the list when you add new files.
&gt; That means that after 1.0, every 1.x version will be backwards compatible with the previous version, i.e. not make any breaking API changes. So call it 2.x? Semver expects you to move past 1.x eventually...
I don't see it as a shortcoming of custom derive. Rust macros are powerful not because of the power of the macro system - but because of how well they interact with the orthogonality of the language. Same here - the macro system is unable to put documentation on the type itself, but the language allows you to put it on the trait implementation. And, from my short time with Rust, I've already learned that whenever I encounter a hurdle and need to find a workaround, the solution Rust forces me to take usually turns out better than my original idea. Same here - putting the documentation on the trait implementation makes more sense, because we are documenting the default value of the new type. So... I can say this `#[doc = "..."]` attribute symbolizes quite well my experience with Rust so far.
For anyone thinking of experimenting one step further [this](http://andrewkelley.me/post/jamulator.html) blogpost might be of interest.
According to semver 2.0, there is actually no compatibility guarantee before 1.0. So there IS a difference betwen 1.0 and 0.3. But I have been using the versions differently, and it seems to me that the majority of the community has. I am always keeping 0.3.1 backwards compatible with 0.3.2 etc., bumping the minor version with API changes. I am sure I saw this documented somewhere and before checking I thought SemVer behaves this way. How does Cargo treat versions before 1.0.0?
What's the motivation for boxing `T`, or is it an implementation detail of being for a linked list?
I don't get why this guy is being downvoted. He sees 1.0 as meaning safe and reliable. As being high grade. He wants 1.0 to actually mean something meaningful rather than being a random number. Since when is that a negative?
1.0 in semver generally is about API stability. The fact that a library uses unsafe doesn't imply anything about stability either. Unsafe is necessary for FFI, and in other situations, it doesn't imply that the code itself is unsafe, only that the developer is taking over for the compiler in a special situation which it can't reason about. It should be used rarely though. 
Looks like the VS 2017 item is already done?
[Rust 1.19 added support for Visual Studio 2017](https://blog.rust-lang.org/2017/07/20/Rust-1.19.html). Is that it?
This sounds like a possible use for [the `or_else()` combinator](https://docs.rs/futures/0.1.14/futures/future/trait.Future.html#method.or_else), though you might have problems if you want to write it into a return type since it takes a closure. If you can use nightly then you have access to the `impl Trait` syntax which would come in handy here.
Really sad too see him go. Rust just got hit really hard.
I believe so -- looks like the linked issue is closed too (#38584). EDIT: I'd totally make the edit myself, but mobile. :(
Updated :-) Let me know if I can clarify anything else in particular.
It's definitely pretty close to covering all the areas I'm interested in for my GUI project. There's still some API awkwardness (like [this](https://github.com/gtk-rs/gtk/issues/439) and [this](https://github.com/gtk-rs/gtk/issues/468)), but overall it's pretty comprehensive. I think there's still a few things missing, but hopefully these ergonomics issues will start to be addressed over the next couple of releases and then a 1.0 can be issued. I'd love for this to hit 1.0 before the end of the year. I see way too many posts about what GUI framework to use, and I think pointing them to GTK+ as an example would be awesome. Now if only GTK+ was better supported on Windows!
Thanks you. You will be missed
That's what /u/IDidntChooseUsername was saying. any point release should be backward compatible within the same major release. 
looks better now :). Maybe will try it out when I decide to update my website for a new rocket version :)
 pub trait Generator { fn try_fill(&amp;self, dest: &amp;mut [u8]) -&gt; Result&lt;(), Error&gt;; } To be clear, this interface assumes that we are running in an environment where there is something like an operating system that provides an autonomous random number generator that client code is not at all responsible for seeding or supplying entropy to. Compare this to, for example, the sort of interface that would be implied by [NIST SP 800-90A](http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-90Ar1.pdf), something like: pub trait Generator { fn try_fill(&amp;self, dest: &amp;mut [u8], additional_input: &amp;[u8]) -&gt; Result&lt;(), Error&gt;; } ...where `additional_input` is client-supplied data, which could be secret or public, that the generator will use to perturb its state (see section 8.7.2 of the link). This is generally not useful in a full-blown computer with a full-featured operating system that provides a reliable RNG whose randomness the operating system takes full responsibility for, but it is so in an embedded/IoT setting where the application needs to cooperate with the RNG to supply it with environmental randomness or values that are likely to distinguish one device's instantiation of the RNG from others'. This isn't necessarily a criticism of the trait as proposed, as much as an invitation to define its scope more clearly달s it meant to also be of use to embedded/IoT applications? And maybe the name needs to be tweaked`OsGen` is the name of a type that implements the `Generator` trait, but the trait itself seems to be designed for an OS-like environment.
Yes that was what I was thinking of too, 0.x.0 being backwards compatible will all 0.x.y. Just like 1.0.0 with 1.x.y. Good to know that that is actually not part of semver.
I don't think there will be any major API changes anytime soon, and 0.3.x will be backwards compatible with 0.3.y. If that helps you anything. Even with 1.0 there could always be a 2.0 with breaking changes.
&gt; 1.0 means that programs can finally start using the library without worrying that the API will have a breaking change tomorrow. That's not what 1.0 means. You could release 2.0 tomorrow, and it would be a breaking change. Semver only talks about how to communicate breaking changes, not about whether breaking changes occur or not. And if you don't want people to use your code, don't put it onto crates.io. If you need to share it with a select group of people to get feedback, push it to github *without putting it on crates.io*.
It would be far nicer if code that is not considered by its authors to be mature and usable by others wouldn't be on crates.io the first place.
Wrong sub, this is the Rust programming language, not Rust the game. You probably want: r/playrust/
Thunderbird is based on Firefox ESR (currently 52). I don't remember if 52 has any Rust code in it. The next ESR is next year with 59, which will definitely have Rust code in it, though with the significant changes in Firefox 57 I'm uncertain if Thunderbird can keep the same cadence. **** I say "based on Firefox" but technically it is based on the same technologies I suppose. Might be considered based on Gecko or XULRunner (unsure if that's still considered a thing). **** edit: Sorry, didn't mean to seem dismissive. :) [It looks like](https://wiki.mozilla.org/Oxidation#Rust_components_in_Firefox) Firefox 48 [shipped with](https://bugzilla.mozilla.org/show_bug.cgi?id=1161350) a Rust-based MP4 metadata parser, so this code should be in the current version of Thunderbird.
[easycurses](https://crates.io/crates/easycurses) gets a version bump, you can now check the position of the cursor if you care to, among other things. I think this ends most of the work to do on it until the next pancurses update.
Neo4J is (was?) excellent at "documentation is code" idea. All samples in the docs were ran against the version they were documenting and unit tested, so failed documentation tests would fail the build.
gonna try my hand at learning rust, finally. I'm a complete programming novice, so i'm still in the process of setting up my environment. Anyone know any requisite emacs plugins for rust?
That's a Cargo/Rust convention, not Semver (although compatible with Semver as it only adds restrictions to the developer).
Yeah, doctests rock in any implementation.
I am primarily a Java dev. For learning rust I was converting a data structure from java to rust last week. I almost was able to do it, the code looked similar. Then I was asking a query on that code here. That when I come to know that in Rust you can do much more and enforce much more at compile time using types and ownership rules. It was an awesome feeling to know that. So I think with practice and reviews/feedback from more experienced guys we can learn more. 
What is the future of Rust? (serious question). Do you see any trends in the industry picking up Rust? Do you expect Rust to be used more in the industry? Basically, do you envision a future where we can earn a living coding Rust?
I'm working on CGI WordPress-clone-ish [blogging engine](https://github.com/agraven/amandag), which is intended to be used on [my website](https://amandag.net). I just got reCAPTCHA verification working, and I'm currently building an authentication system, so I can edit stuff without directly messing with the database.
If we had to wait for crates to be mature and usable by others, `crates.io` would be empty. Also, `gtk-rs` is usable, but breaking changes have to expected. Not putting it on `crates.io` would mean that no project using `gtk-rs` would be able to be put on `crates.io`, which seems like something we don't want.
Just the obvious one: [emacs-racer](https://github.com/racer-rust/emacs-racer) I also use toml-mode, but thatis frankly not a requisite.
Continuing to hack away at my gameboy emulator. Almost at a place where I'm willing to link it here, but once I get the bootstrap rom fully running, going to do some massive refactoring. I've probably added over 100 opcodes this past week. Unfortunately, there are a good 500 opcodes in the z80 architecture.
Like I said above, it's very unlikely that `gtk-rs` will be released as 1.0 before long. And before the end of the year is just absolutely impossible haha (we need to sleep you know? :p).
Good luck! I just checked my opcode count and I'm at 243 in the standard set and 90 in the extended. I know there is alot more to go!
Continuing into week 4 of [my Gameboy emulator](https://github.com/simon-whitehead/chemboy). It can play Tetris now until the Game Over screen before it crashes. This week I'll be working on finalizing the CPU implementation and hopefully get all of the instructions implemented.
Good point about embedded usage  but does `additional_input` need to be passed in via the same method? We already have [`SeedableRng`](https://docs.rs/rand/0.3.15/rand/trait.SeedableRng.html) and had some discussion of [`FeedableRng`](https://github.com/rust-lang/rfcs/pull/2106#issuecomment-322414869).
Just got around to checking out your repo. How do you write so much code haha. You have 4000 additions in the past 3 days. I thought my 1000 in a week was a lot.
Haha. I don't know where you got those stats (the GH Insights area I guess?), but I have done quite a bit of cleanup. But also, as I implement the opcodes they include the mnemonic, cycles, length, etc. So each opcode takes up 8 lines. That contributes to a lot of changes I guess. I spent the last week running the blarggs CPU tests and making them pass. So that involves a lot of repetitive instructions being implemented (`AND A`, `AND B`, `AND C`, etc).
I see a lot of gradual drop-in replacement of C libraries: Rust is just plain safer, especially in the IO department. The internet is getting ever more treacherous, and the cost of messing up your IO calls is getting hacked.
was?
On a related note, I noticed you are adding a method for each opcode instead of grouping them (AND r instead of AND A, AND B, etc.). Why not?
Working on an internal tool for the company I work for - first bit of Rust in the codebase! It's a replacement for a bash script which needs to check every JS file in the repo from an array of glob patterns, then scan each file to see if they're ES5 or ES6 so we can see how we're progressing with refactoring. So far the Rust version can check ~1000 files in under half a second, which is a nice speed improvement.
Maybe we should communicate that there won't be likely any application visible API changes apart from fixes to existing API that is wrongly autogenerated currently or accidentally unsafe. I don't think there were even other API changes this release, but I'm not sure. All API changes I can remember affect only other bindings, but not applications. There's only so much you can change, the C libraries API defines your API quite a lot already. I think gtk-rs is "ready" (as in what people believe 1.0 means) under that point of view, but it was already last release. You can use it successfully for writing applications and more than all the basics are there. The main missing thing is support for writing new GObject subclasses in safe code, but even that should later, if at all, only require API additions and changes in the plumbing and thus most likely not affect applications.
MPSC channels are the basic building block for an actor model, where actors run on their own threads and have a message queue where other actors can send requests to them. The actor is the single consumer of the queue, and all actors that send requests are the multiple producers.
I have a feeling nobody will want to use the official logo once it's out and will keep on using the doge one.
I first saw that a bunch of years ago at a Vancouver graph database meetup, but I wasn't following neo4j development, so I don't know of it's still the case. Probably is, but I'm not 100% certain.
Fair point. If they aren't used outside function signatures, and perhaps type declarations, then they should be easy to recognise as not being expressions.
As long as it's not complete, I don't intend to release a 1.0. However we should definitely say that it's stable already to avoid all this fuss about it.
Mostly for my own brain at the start. I had a lot of duplicate logic and it was becoming a mess. However, I have [recently started refactoring them so the logic is all in one method](https://github.com/simon-whitehead/chemboy/commit/f3200d29d169939c8d1362341e9783d50ef7f721), but keeping the individual functions. I prefer it this way for readability/organising, but also because it gives me nice places to put debug/tracing logic rather than shoving it all into the big `match`. To each their own I guess. I'm still a long way off refactoring it all but this is the route I'm taking. If you're interested, you should join the EmuDev slack. The Gameboy channel is quite active and we're all talking in there most days. Team is here: https://emudev.slack.com/ EDIT: Gameboy channel is #gmb - you'll figure it out I imagine but just correcting myself :) EDIT 2: I should probably mention that _I didn't_ start this Slack group. I found it whilst researching Emulator Development and the people are super nice and friendly. The chats we have in there are quite good/nerdy too so its fun and figured its worth advertising :)
That is what 1.0 means with semantic versioning: there will be no breaking changes in anything labelled 1.0. It doesn't matter if v2.0 or v6.0 is released tomorrow, v1.0 is still stable and unbroken.
Well, it is a solution for a people who don't have ideas, but not the other way. The official forum is not a solution for people with ideas, also I think there should be some kind of voting option so good ideas get more visibility than not so clever ideas. Currently, the only thing I can do is create a new post on the official forum "is there a project like this created already?" and get an answer "no, you can implement it".
https://feedback.unity3d.com/ Good implementation of a website with feedback, we could do something simple with GitHub/G+ auth for people to easily add some idea or vote.
It's been a few weeks. I'm still building a First Order SMT solver. The core solver is done and works. I implemented a SAT front-end. I started on BCSAT so I can check the more complicated propositional formulas. The interesting technology is done. I'm going to optimise it, the heuristics are pathological for my current benchmark set. minisat has &lt;1s, fosmt &gt; 1h, fully random heuristic is ~20m. I actually spend a week bug-hunting after two logic errors. The first I fixed the first hour and didn't mark solved, the second was a printing bug. But at least my logic was sound!
Hardly a simple question, since humans are notoriously bad at predicting the future. You can look at several sources, which consistently show that Rust is growing at a steady pace (e.g. Redmonk, TIOBE, crates.io-index commits, friends page), but none of them allows for reliable extrapolation across years. What I can only say for certain is that Rust is ready for industry adoption in a board range of domains, whether that actually happens is another matter. I am in fact quite optimistic about the future, but without a time machine, no one knows for sure.
That's what I mean, yes. And making sure that people understand that API is not going to fall apart every other day but is really quite stable already for the application facing parts.
I'm also working on a wrapper around an API using hyper and tokio-core. Thanks for sharing! Having similar code to read really helps as a beginner, for example it took me some time figure out that future.boxed() doesn't work with the hyper types as they don't implement send. Box::new(future) does work.
I'm trying to work on a typesafe and (hopefully) sane EMBL library. To avoid licensing issues I'm working solely off the spec and not looking at the existing libebml at all, so my API surface is probably really weird and requires a lot of thought on my part. Since ebml is similar to XML in that it's a "meta-format" where applications write a "document type definition", my goal is to use that definition and procedural macros to define types and make sure that obvious mistakes (like putting a container inside a container that doesn't support it) are prevented at compile-time. However, I'm having trouble getting this to work - this is one scenario where associated type constructors and `const fn`'s that can be evaluated at compile time would be extremely useful. 
Working on a tool to make it easy to call Rust code from Qt and KDE projects. In Qt nearly everything is a QObject or a QAbstractItemModel. The tool generates C++ code and Rust code from a simple JSON description. Then all that's needed to use the Rust code is to implement the generated trait. It's working fine for simple objects, lists and trees. Now I'm working on documentation and demo code. https://cgit.kde.org/scratch/vandenoever/rust_qt_binding_generator.git/
I remember reading about a proposal to make Thunderbird rely more on web technologies (JS mostly) instead of native code, so it might go into the opposite direction and eventually become an electron/servo embedded (once that takes off xD) app or something.
Hidiho. I'm an experienced dev, but haven't been doing Rust long. I seem to keep running into little design problems. Can anyone give me a hand with this particular one and maybe give me some good resources on how to approach this kind of thing? struct Creator {} impl Creator { pub fn create_thing(&amp;self) -&gt; Thing { Thing { creator: self } } } struct Thing&lt;'a&gt; { creator: &amp;'a Creator, } struct Container&lt;'a&gt; { creator: Creator, thing: Thing&lt;'a&gt;, } fn main() { let creator = Creator {}; let thing = creator.create_thing(); let container = Container { creator: creator, // Error here. thing: thing, }; } &gt; error[E0505]: cannot move out of `creator` because it is borrowed In the full code the Creator and Thing are SDL2's TextureCreator and Texture, so out of my hands. I want to put my Creator and Thing elsewhere so as to keep it clean and not have objects lying around. I understand why I can't move the creator, but what am I supposed to do? If I create the Thing after the Container then the Container's Thing type would have to be an Option or a reference. But surely usage and types shouldn't be influenced by how it's created. It's not Optional in design. I don't even want the Creator anymore, but I'm coupled to it now.
I you are interested in writing idiomatic Rust, I can strongly recommend the [clippy](https://github.com/rust-lang-nursery/rust-clippy) linter.
Rust does not have a [stable ABI](https://github.com/rust-lang/rfcs/issues/600).
TMLL goes into great detail about how to implement data structures in Rust (which differs from other languages due to lifetimes). The Book is a lot less specific and more general/basic.
I personally greatly prefer external files for module level documentation. A giant `/*! !*/` comment may be inline, but it's all green and not Markdown syntax highlit, and isn't directly coupled to the code ANYWAY. So I'm much more in favor of README.md as the root doc and docs/paths.md matching src/paths.md for more docs.
It is stable if it's a C ABI, though? And the OP claim of stable ABI in the same rustc version is correct?
Filed https://github.com/rust-lang/crates.io/issues/998 for this.
The proposal is in FCP so part you thoughts there so they're heard!
The same is true for 0.3.x and a future 0.4.x though. 0.3.x continues to stay backwards compatible and continues to stay around and become outdated. Just like with 1.x and 2.x.
With semver, 0.x means the API is unfinished so could have breaking changes between point releases. Only once it gets to 1.0 is it supposed to be backwards-compatible.
This example from the rust docs: let guess = "42".parse().expect("Not a number!"); gives " consider giving `guess` a type cannot infer type for `_`" I tried to expand it to a match, but got a very different error message. let guess = match "42".parse() { Ok(num) =&gt; num, Err(_) =&gt; println!("Not a number!"), }; gives let guess = match "42".parse() { | ^^^^^ the trait `std::str::FromStr` is not implemented for `()` why the different error messages? what am I missing?
That's not how cargo works though, see elsewhere in the comments here. Cargo in addition to semver assumes that 0.x.y is backwards compatible to 0.x.0.
I can't say it's *the* pattern, but I think I'd refactor to a retry loop or trampoline. These patterns are about designing the flow control so that it has the ability to pick up where you left off. - Let's say I'm implementing a compression algorithm that can be used via the `std::io::Write` interface. This algorithm works in blocks, something like this: - fill a buffer with an entire block - compute some statistics - decide whether to adjust codebooks, output codebook - encode data and output - repeat - special case for terminating a block early The two problems are that calls to `write` aren't going to align with my block boundaries, and I need to allow for output flow control. I might store output into a user-provided buffer (like zlib does). I might call `Write::write` on another object. I might want to deal with asynchronous io (but not yet). So I'd organize my `write` function like this: - break the algorithm into chunks at points where a return may be necessary. Factor those into their own functions. *Comment well*. - keep track of "what needs to happen" in local variables of `write` or in attributes of the compression context `struct` as appropriate. - then the skeleton looks like this (your coding style may vary) 'write_retry: loop { if ... { ... } else if ... { ... } else { break 'write_retry; } } return if is_full { Ok(0) } else { assert!(bytes_read != 0); Ok(bytes_read) }; } Each branch makes *some* progress on the overall task and updates the state to reflect it. Then if there is (possibly) more that can be done, it continues. Once an early return is called for (with break) or the branch conditions don't detect the opportunity to do more work, control flows out of the function. This allows you to make decisions like "`write` should return incomplete once I've tried to output some data and gotten an incomplete, only return full after seeing full." It also allows each branch to only focus on making progress in one small area: filing or emptying a buffer, subtasks of the compression, etc. - A retry loop is procedural style with state mutation. The functional implementation is a trampoline. Here you return: - a Ok variant - an Error variant - a TryAgain variant containing a closure to call And a function that repeatedly calls the closure within TryAgain until it gets an Ok or Error to return. This works really well if you are comfortable writing in recursive style and is a total nightmare otherwise. However, it might fit your use case. ------ With either pattern, the only difference writing a future is that you may return `NotReady`. Your problem sounds fairly simple to do in a retry loop. List the steps in order and use the `if` statements to skip the steps already taken: "Have I checked in memory? Have I found what I need in memory or submitted a network request? Has the request been submitted and returned? ... " Local `bool` variables to keep the repetition under control. Find one thing to do, loop to find another, return NotReady when you need to wait, Ready when you have an answer.
The `cannot infer type` error occurs because [`parse`](https://doc.rust-lang.org/std/primitive.str.html#method.parse) is a generic method with many possible return types. The compiler needs to know what type you want to parse into; To do that, annotate the variable with the type you want. let guess: u32 = "42".parse().expect("Not a number!"); Now, let's also do the same thing with your second try using a match expression, annotating with the type: let guess: u32 = match "42".parse() { Ok(num) =&gt; num, Err(_) =&gt; println!("Not a number!"), }; Now the error message makes much more sense: error[E0308]: match arms have incompatible types --&gt; src/main.rs:3:22 | 3 | let guess: u32 = match "42".parse() { | ______________________^ 4 | | Ok(num) =&gt; num, 5 | | Err(_) =&gt; println!("Not a number!"), 6 | | }; | |_____^ expected u32, found () | = note: expected type `u32` found type `()` note: match arm with an incompatible type --&gt; src/main.rs:5:19 | 5 | Err(_) =&gt; println!("Not a number!"), | ^^^^^^^^^^^^^^^^^^^^^^^^^ As the compiler points out, the two match arms return values of different types. While the Ok match arm returns a `u32`, the Err match arm has a statement, which always returns a `()`. To fix this, you can change this arm to `panic!` instead of `println!`, to ensure that the program doesn't continue after this point. In fact, this match expression is (almost) exactly how `expect` is defined in the standard library.
If you write your code to be callable from C then, yes, that makes a stable ABI. It's something of a pain, but entirely doable. People have also experimented with making plugins as DLL's and loading them crates such as `dylib` or `sharedlib`. It works, as far as I know, it's just not really a feature built in to Rust in any fashion. It also requires, again, making your plugin API all use the C ABI. As far as I know, the same version of rustc called with the same settings will always produce the same code. That's not the same as having an ABI though, since the point of an ABI is to make sure the code is callable from an external source. As it is, rustc is free to do things like inline functions into oblivion, or split functions apart into specialized variants, or other fun things; you can't really trust that it will ever do what you want.
You can use libloading[0] (crossplatform) or the raw libc dlopen/dlsym (unix) to load symbols from shared libraries. The ABI compatibility might be a problem. Right now, the Rust ABI is unstable. There are wishes to change this[1], but I doubt it'll come in the forseeable future. I can imagine two ways to side-step it. You can have API boundaries use the C ABI. Depending on how big your API surface needs to be, that might be "just enough". I think for most apps, this is the best approach. You can make an FFI wrapper for the plugin authors to use, to provide them an idiomatic API. The more bleeding edge idea, as you suggest, is to distribute your app with a specific version of rustc (say, stable 1.19), and everyone compiling plugins will have to target this version as well. The idea is sound until you want to update to a newer version of rustc for your app. When you update your version of rustc, it will break ABI compatibility, so plugins will have to be recompiled as well. If you expect different version of your software to have API/ABI breakage anyway, that might not be too much of a problem. But if you want to keep your API/ABI stable across versions of your app, you'll be stuck with a specific version of rustc. Depending on how open your plugin ecosystem is, you could imagine having the compiling of plugins done on the client-side, and as such not be as much of a problem ^^. [0] https://docs.rs/libloading/0.4.0/libloading/ [1] https://github.com/rust-lang/rfcs/issues/600
Gods, I hope not. 
I was thinking about a Rust library that installs Rustup (or uses it as a library if possible) in some sandbox directory, installs the stable compiler then builds shared libraries to load as plugins. Then the program can manage keeping the rustc version the same across plugins. If you update the compiler version it can go in and rebuild all the plugins.
So I built a contrived TCP protocol (in Rust) to demonstrate the Wireshark dissector: https://github.com/sevagh/wireshark-dissector-rs Still pretty far from complete. I think my tasks remain: 1. Make the Lua dissector work (? don't want to waste too much time on this and I find the syntax of Lua obtuse) 2. Write a C dissector 3. Write a Rust dissector with some FFI glue in C 3 is actually the only exciting point.
So, not to dissuade you in any way (I really mean this!), but if you're a programming novice and you've never programmed before and you find yourself struggling you might check out an easier first language like Python then coming back and picking up Rust. This coming from someone who has been programming for about 9 years finding Rust to be one of the coolest, but also trickiest to learn the ins and outs of. edit: Realize that since you're using emacs you probably have done some other programming before...
We have some applications which react to events which arrive over the network. They can come in on several different sockets: one which receives a stream of background data (eg the current temperature and wind speed), one which receives specific events (eg plane took off, plane landed), and one which receives control messages (eg schedule departure, schedule arrival). On each socket, we have a thread reading the packets, parsing the protocol, and then sending a message to an MPSC queue, which is picked up by a central control thread which makes decisions, and then issues instructions back over the network. The advantage of this structure is that all the decisions are made in one thread, which can own and use mutable data without having to worry about sharing and locking. It's more or less an actor model, but less formal. Oh, and we don't actually do air traffic control, that's just an analogy!
Failing that, You could use some sort of IPC
Using a scripting language using one of Rust's high-quality binding libraries like [PyO3](https://github.com/PyO3/pyo3), [Helix](http://usehelix.com/), [Neon](https://www.neon-bindings.com/) or [hlua](https://github.com/tomaka/hlua) is probably your best bet. You can load Rust as a dynamic library as long as you use `extern "C"` functions but it's not ergonomic right now. Maybe in the future it will be.
1.0 in semver provides a signal to your users, the spec is actually very clear on when 1.0 should be released: http://semver.org/#how-do-i-know-when-to-release-100
clippy is generally happy about that code :) Of course in pedantic mode it complains about missing docs and all the unwrap()s.
While I was looking through your code I noticed that you're instantiating an assembler for every code block that you analyze. Is there any reason you do this (annoyance with the Assembler/Executor API maybe)? Because this way of using it limits you from encoding static jumps between different blocks while using unnecessarily large amounts of memory as every block will have its own mmap this way, instead of sharing one between all blocks.
XUL is dead and there aren't a ton of viable options floating around. I would love to see Servo to take the torch, but that would need significant push from Servo side
Neat. Certainly looks cleaner than mine. I think when I wrote my version I wouldn't even have understood your code, I'm a bit further along with my learning now. :) As to the suggestions: 1. I didn't know much about error handling when I wrote that. I was aware that `unwrap()` was the easy but *bad* way but I had to look into the better ways first. The `curl` crate being a C wrapper didn't make that any easier since the conversion in the error case is a bit dense for a noob. :) 2. You're right. At that point I didn't yet know how to find the crates I wanted for a particular problem, much less how to evaluate their quality. I found `hyper`, but their readme starts out with a treatise on async, futures, etc... way over my head. When I found `curl`I thought to myself "at least libcurl is widely used and I *know* it does what I want", it also had a short example that was close to what I wanted. 3. I didn't even know about `{:#}` before. Language supported, built-in pretty printing, how cool is that!
I updated [relm](https://github.com/antoyo/relm), an idiomatic Rust GUI library and some of its dependencies to work with the newest gtk-rs release. I plan to release a new version of the webkit crates so that it works with this new release. I also want to use this new version to fix a bug and improve the performance of [titanium](https://github.com/antoyo/titanium), a keyboard-driven web browser.
Honestly, I think on the face of it Go is the better *sysadmin* language. Compared to Python it's almost as easy to write/read and the deploy story is just world better. Write, compile, scp, done. No virtualenvs, no dependency management outside the dev machine and with just 2 env vars you can target a dozen platforms. Compared to Rust, for sysadmins, Go easily wins on the easier code and not caring about memory at all. Also, Go compile times are just insane. There's just one thing... For some reason Go code rubs me the wrong way. There's always something that doesn't feel *quite* right, but I can't put my finger on it. I don't really care about generics, don't need them in my simple support tools. But there's things like the `if err` idiom that just **screams** for being abstracted by a macro. There's leaking goroutines when they *could* be garbage collected 95% of the time. (Proposals in that direction have been rejected because it's not 100%). Lots of tiny little things. It's like when you've painted a wall and a week later you notice a tiny spot that you've missed. Nobody's ever gonna see it, it's completely inconsequential, but you can't stop staring at it.
Thanks. I'm certainly having a blast. Reading a ton and throwing code at a wall until something sticks. :)
Notably this is how [xi-editor](https://github.com/google/xi-editor) is handling plugins. That also opens up plugins to be in different languages.
can you link me to where expect is defined? That would probably best answer what I am trying to ask, but not communicating clearly.
Blogging: quick recap of the excellent RustConf 2017. Rusoto: * Give a long-awaited streaming downloads from various services, such as S3, a good workout and testing. https://github.com/rusoto/rusoto/pull/627 * Land "Custom" region to allow use of non-AWS services, such as Ceph, Minio, local DynamoDB, etc.. https://github.com/rusoto/rusoto/pull/759 * Get a PR full of bug fixes for various services rebased and merged: https://github.com/rusoto/rusoto/pull/756 Personal projects: collect the list of ideas from RustConf somewhere so I don't forget them. There's quite a few!
Sure, here it is: https://doc.rust-lang.org/src/core/result.rs.html#759-765 And `unwrap_failed` is defined here: https://doc.rust-lang.org/src/core/result.rs.html#859-861 And [here](https://doc.rust-lang.org/book/second-edition/ch19-04-advanced-types.html#the-never-type--that-never-returns) is the explanation for the bottom type `!`.
Nice! Any plans to support other formats, like AsciiDoc or reStructuredText? I am not a big Markdown fan myself.
use vscode with plugin
what was the bash speed?
&gt; Rust's future is not contingent on the lifetime involvement of any one person People own their own lives. Having them working on Rust is merely a borrow, and all borrows must expire at the end of some scope. 
Let me reach for my crystal ball...ah, there it is! I see...projects written mostly in scripting languages with some parts in Rust for speed. I see Rust crypto libraries taking off, because we are collectively burned by unreliable C code. I see...the vision is getting a bit blurry here...Rust making its way into FinTech, working in harmony with tiny kernels of C. I see merry Rustaceans around the globe working tirelessly to build our better future, for pay or for love. Truly, the future is bright!
I'm writing my own media management software. I have plenty of series, movies and music on one of my computers, and most things I've found are either ad-heavy or don't offer the features I want to have the most. 
Is there a set of builtin constants, like compiler version, that you can access in your program? I want to, for example, output which rustc version my source was built with when executed.
[removed]
You can use `tut` in Scala for this, too: https://github.com/tpolecat/tut
It might be "dangerous" if you want to constantly build your application with the newest nightlies. However, if you "pin" your app to a nightly version that you can successfully build your app with, you should be fine. Here are the `rustup` instructions to set a project to a specific nightly version: https://github.com/rust-lang-nursery/rustup.rs#toolchain-specification So, if today's nightly works for you, you would run rustup install nightly-2017-08-21-x86_64-unknown-linux-gnu and cd project_dir rustup override add nightly-2017-08-21-x86_64-unknown-linux-gnu to set the project directory to use that version.
Yet more TWiR, clippy, bytecount and preparing my RustFest Zurich talk.
It's not dangerous to use. You can expect anything that you build to work on nightly. It's pretty rare for a nightly build to break things in unexpected ways, but even if that does happen, it's easy to roll back to a previous, known working version of nightly. Rocket will work perfectly fine, as would Gotham. Main benefit of stable is for open source software that you're sharing with others, and want your downstream users to be able to compile your project without having to reach for Rustup to get a nightly copy of Rust.
I wonder if such a "big" library/framework is the right decision here. This sounds like a job for `std::net::TcpListener`, `std::net::TcpStream` and its friends. I don't even know how and if Rocket/Gothom/X can handle raw sockets etc. (they're build around Http handling) for a quick and insightful rundown, please take a look at the [Rust Books Web Server learning project](https://doc.rust-lang.org/book/second-edition/ch20-00-final-project-a-web-server.html) i think this is enough to get something running :)
Okay, thanks for the link. I'm using this project as a way to learn Rust, so that is very helpful. I was mainly considering the framework because I'm also going to need to be serving JSON on endpoints, serving data through sockets to web clients, interact with databases, etc.
Ok, great, thanks! So I don't need to be concerned with unstable features that Rocket uses to have kinks/undefined behavior? This is probably going to be installed on a docker image then left alone unless something breaks.
Ok, great! So I'll just have to configure the docker image with rustup (nightly toolchain) correctly then. Thank you!
Funny. I was about to post the same thing. I managed to start a Pep-8 recompiler, but didn't have much in the way to test applications. I would like to try making a CHIP-8 one. Now if only rust had some good, idiomatic, and supported LLVM bindings.
Once compiled you're usually fine. The only problem i see is  if there is an immediate need to fix something in your code, you updated the compiler and it is broken and you can't compile anymore. But already compiled programs usually just work  forever. It doesn't start to suddenly break because a compilerupdate, your program does not rely on the compiler to run. That being said i use nightly most of the time since the last 1,5 years and never encountered a problem. This does not mean there was no problem in that time period but i don't update my compiler every day. But that gives you no grantee that you will be fine, i am just saying that i had never a problem on nightly. 
if it's in a docker container, you could also just run `rustup default nightly-2017-08-21-x86_64-unknown-linux-gnu` and not have to worry about which directory you're running it out of
This sounds weird. Are you sure your task is not to use more like a "rest-like" API over HTTP? Yes HTTP uses sockets but from the OP it sounds like you want to use raw sockets for communication. 
Unstable just means the API could theoretically change. From your point of view, you are not effected. You only have to worry about Rocket / Gotham making breaking changes to their APIs because they aren't stable yet. Even then, you can lock dependencies at a specific version by just keeping your Cargo.lock file as is.
It was fun! Thanks! 
Without having the real code to see I don't know if this will work for your use case, but https://play.rust-lang.org/?gist=953bf6e7b43395193324ccfc59f1137d&amp;version=stable compiles
It's totally on-topic, IMOI learned about dynasm-rs, which is really cool.
From the way my boss explained it to me it should be able to have a client connect through a web socket to display real time data on the front end without refreshing as well as make GET requests to an API endpoint and get a json response
This is a very valuable information! You definitely need to check out how far the progress with web sockets your desired lib/framework is. GET requests and JSON is pretty easy with many currently available. I have one running with Rocket. But i don't know how the progress with web sockets is, because web sockets is a little bit different than ordinary sockets and GET requests. You could however just run rocket and a websocket server in parallel and maybe transfer information via channels .. etc. 
Great! I think I will give it a try after researching a bit more about the websockets as asmx85 suggested. Thanks :)
Have you seen [this](http://arewegameyet.com/)? Are we game yet list a few resources.
Good question! The main difference I can see at the moment is the framework they're build on. `websocket` uses tokio (if you like to do async. i/o) and `ws` uses `mio`. You can find a very basic overview here: https://github.com/flosse/rust-web-framework-comparison#websocket-libraries
Wow....such an qualified answer! Thank you so much! The rust community is just awesome :) Actually it seems like tokio is a bit too complicated for such a simple task ;-) Nevertheless I'll try to create an example with your input :)
Just got the update to 56.0Beta3 today and saw this: &gt; Thunderbird now uses the latest Mozilla technology based on Rust for encoding messages https://www.mozilla.org/en-US/thunderbird/56.0beta/releasenotes/
It's more a long-term concern. If there's a update to a dependency (like rocket or serde), you may have to spend some setting up a new compiler version to make things work.
I don't know what this means exactly, but https://www.mozilla.org/en-US/thunderbird/56.0beta/releasenotes/ mentions Rust...
&gt; To fix this, you can change this arm to `panic!` instead of `println!`, to ensure that the program doesn't continue after this point. Why not just return the function, or break the loop, or whatever that doesn't involve a panic?
I very much agree with avoiding panics in general. However, given the context, I would consider such a suggestion out of the scope of the original question. But yes, these are generally good ideas, and is indeed what is done by the end of the chapter in the book.
I've implemented a simple listener for GDAX (cryptocurrency exchange) using websocket. Both options are extremely verbose compared to websockets in other languages and will require some getting used to. I found it websocket the most usable of the 2 and I think Tokio is the way to go with regards to async I/O. Note that it does pull in some extra dependencies.
Huh. So Thunderbird beta just follows Firefox beta (while release is ESR)? Interesting. Wonder if that will keep up with 57.
If it's only one-way streaming you can take a look at EventSource API - it's simpler than WebSockets and don't need any dedicated support on the server side.
Version 0.2.0 is out: * Support generics(both types and lifetime) - thanks /u/MysteryManEusine! * Automatically generate docs for the `impl Default` section - thanks /u/llogiq!
Does Rust prevent buffer overflows?
Ok, thanks for the concrete example, I'm thinking it through.
You can also use SimpleFrame to parse websocket packets. I wrote a little toy websocket package that provides a Tokio service (is that the right word? See here: https://tokio-rs.github.io/tokio-proto/tokio_proto/index.html) and uses SimpleFrame to parse packets here: https://github.com/davidko/tokio-ws Please note that this was mostly written as a test; I wouldn't consider it production quality code, so use at your own risk :)
Yes, either by bound-checking, or by proving at compile time the access is valid.
If it is open source, would like to have a look.
Thanks for putting your work :) but I put these two as the only alternatives to something well tested/maintained and production ready.
tokio seems to be based or using mio?
In the C library DestroyRenderer also frees the associated textures. I think the author of rust-sdl2 was trying to prevent use after free. Cool. But it's the wrong approach. *Just do reference counting.* It's in the standard library! That library is broken (in my not completely educated opinion) and you can't fix it without abusing `unsafe`. I'll look closer at fixing it when I get a chance. Maybe tomorrow.
So, I guess compile-time prevention works using iterators and stuff, right? When writing ` let x: &amp;[i32] = ...; println!("{}", x[20]); ` it requires run-time overhead with bound-checking am I right?
Yes it is, but at a higher level. So in theory it should be easier to use - even if the async story is not perfect yet in rust.
Thanks I will look into this
I don't know the exact super-powers of rustc. I guess that if you have an &amp;[T] of unknown origin, indexing it would undoubtfully emit *a* bound check, but I don't know which. Speculation: fn do_stuff(data: &amp;[u8]) { println!("{}", data[0] + data[20] + data[40]); } Maybe the compiler is smart enough to check once that: assert!(data.len() &gt;= 40); If you have a specific example you wanna try, you can look at the generated assembly at the [playground](https://play.rust-lang.org/).
&gt; Maybe the compiler is smart enough to check once that No, it isn't, because it generally won't move panics around or merge them. So that code has 3 bound checks. But if you were to do this: fn do_stuff(mut data: &amp;[u8]) { data = &amp;data[0..41]; println!("{}", data[0] + data[20] + data[40]); } ... then you would get only a single bound check when you compile with optimizations. See [here](https://godbolt.org/g/YqQ6qL). Note that this is not a guarantee of the language, it is entirely at the whim of LLVM's optimization passes. But for cases like this they're pretty reliable.
The implementation itself looks reasonable, but I have a couple of criticisms! :-) 1. Your `ErrorKind::Regex` variant embeds the error type from the `regex` crate, which makes it a public dependency. I'm not sure if that was intentional or not, but unless I have a good reason for doing that, I usually just convert the error to a string. 2. You should probably use [`where` clauses when there are an abundance of generic types](https://docs.rs/reset-router/0.2.2/reset_router/struct.RouterBuilder.html) at the very least because it should get [formatted nicely](https://docs.rs/reset-router/0.2.2/reset_router/trait.CaptureExtraction.html). 3. I'm not sure about implementing `Deref` for your `Request` type. It seems like `into_inner` is probably enough? I guess it depends on how you expect callers to use your `Request` type.
Maybe that's what a 1.0 version could mean for gtk-rs (API stability). And maybe later shift to 3.2x versions (or the relevant GTK version) when the API coverage is done.
You're looking for /r/playrust, my friend.
I work on HTTP client for Poloniex API: https://github.com/greyblake/poloniex-rs
Try and get cobertura.xml reports working with codecov.io in [tarpaulin](https://github.com/xd009642/tarpaulin), so far I'm a bit stuck but that might be a general user error and codecov isn't providing useful diagnostics. Also finish my PR in nix-rust for improved ptrace capabilities.
Oh, neat
Yes it is, LLVM is great. It also works when you add in the "correct" order, so `data[40] + data[20] + data[0]` and `data[40] + data[0] + data[20]` also compile to a single bound check. You just have to nudge it a bit in the right direction.
no, you're not mistaken. i'm pretty newb, i've done some lame scripting with python before, but i'm kinda just diving in head first.
What aboud a loop going over 0..60? Would a down-counting loop optimize better?
Thanks so much for your criticisms! 1. Good point, users probably don't need access to the actual regex error. But it seems like users don't *have* to pull in `regex` to handle errors here unless they are specifically extracting the Regex variant. 2. Thanks, I'll reformat these! 3. That's a really good question, but I do think both are necessary. I like being able to do (with `Deref`) for example, `req.path()` (from Hyper), but to use the request body one must consume the request, which makes the `into_inner` necessary. Also, I'm sure people tell you this all the time, but thanks for regex and csv (and walkdir, etc.)!
&gt; Good point, users probably don't need access to the actual regex error. But it seems like users don't have to pull in regex to handle errors here unless they are specifically extracting the Regex variant. It's not about having to pull in the regex crate, it's about connecting your public API with the public API of another crate. It makes sense for you to do this with hyper since you're specifically targeting hyper's public API, but you don't need to do it with regex (unless you care about your users accessing the regex error). The key difference here is that if regex is a public dependency and does a semver version bump, then the only way for you to upgrade (properly) is to do a semver version bump yourself. Basically, public dependencies limit your options. You should use them when it makes sense to, but it should always be intentional and with acknowledgment of the trade offs involved. &gt; That's a really good question, but I do think both are necessary. I like being able to do (with Deref) for example, req.path() (from Hyper), but to use the request body one must consume the request, which makes the into_inner necessary. Basically, `Deref` is meant to be used for custom pointer types, and not for arbitrary type conversions. There's some [discussion here](https://github.com/rust-unofficial/patterns/blob/master/anti_patterns/deref.md). I'm not saying you should or shouldn't use `Deref` here because it seems to me like this particular anti-pattern is pretty convenient, but rather, pointing out that there's a design choice here. &gt; Also, I'm sure people tell you this all the time, but thanks for regex and csv (and walkdir, etc.)! :-)
It might, although sometimes you have to alter the code until the optimizer does "the right thing". E.g. [here](https://godbolt.org/g/Cx2ETF) you can see that `do_stuff2` performs only a single bounds check, but `do_stuff` performs it for every iteration. I couldn't get it to work with an iterator, but maybe I just needed to massage it some more. In general it's easiest to simply take a slice of the length you intend to iterate over, that is a hint the optimizer usually understands. Edit: it seems I overlooked something and both functions in the godbolt link do indeed only perform a single bounds check.
Depending on how much extra work and/or waiting you want to do, you might also take a look at [Pathfinder](https://github.com/pcwalton/pathfinder), which takes a different approach to rasterizing that greatly reduces the amount of data sent to the GPU, and [should be quite a bit faster](http://pcwalton.github.io/blog/2017/02/14/pathfinder/). The downside is that it's currently based entirely around fonts. There are some vague ideas floating around about [making it more general](https://github.com/pcwalton/pathfinder/issues/17), which is what I mean by "extra work."
The only thing the front end should have to do is add jobs to a queue. Which that should be able to be done with a POST request, so I think one-way should be enough. Thanks for the info!
Ah, my misunderstanding!
Doesn't rustc use llvm? 
Yes, but it essentially uses a direct mapping to the C-library, so it's full of unsafe and isn't rustic.
What's the difference between String::from("Hello") and "Hello".to_owned(), and when should I prefer one over the other?
What I'd really like to see is some kind of analogue to those binding libraries which implements "Rust bindings for Rust" so I can write my plugins in Rust, with Rust's strong type system, and have code written by someone who actually knows how to write C properly generate symmetric marshal/unmarshal code for the C ABI. (ie. Building an ABI on top of the C ABI where crate semver defines compatibility rather than compiler version and it's understood that, since it's not the ABI for the entire language, it can be useful before it supports all the features the unstable compiler ABI does.) As-is, I've just been procrastinating having a plugin system and made my "plugins" a compile-time feature rather than a runtime one.
I agree entirely on if err. It feels like it precedes every statement. I understand needing to be thorough about handling error conditions, but there has to be a better way. On the flip side I've never written anything with as much involvement with memory management as rust so that's challenging for me. But I can see that rust types will give me more expressiveness than golang. 
Don't forget: https://github.com/snapview/tungstenite-rs and https://github.com/snapview/tokio-tungstenite
Are you sure? Both versions only perform one bounds check, if I read the assembly correctly.
Do you have any suggestions for doing that without having to roll my own JSON-RPC variant like Xi did? I can imagine using Serde to marshal/unmarshal the data structures, but I have very little experience with the RPC part aside from D-Bus and, in my current projects, I'd want something more comfortable for porting to non-XDG environments than requiring a D-Bus daemon or reinventing the network bits. ...or, for that matter, given that some of these will have to be long-running and it'd be nice to have a way to interact with them more like threads with channels and less like a series of one-shot function calls, perhaps something abstractly similar to Python's `multiprocessing` module, which works on stable rust and provides simplified abstractions for building microservices and a client which handles run control. (eg. My current main "Plugins would be nice" project would use plugins as a way to walk the filesystem and gather entries for a launcher, so it'd be nice to send "Here's a new source to inspect." event to the plugin host and have the frontend receive "New launcher entry found. Here's the metadata." events.)
I went to the morning training at RustConf last week and am now hellbent on Rust being my primary language. To help learn, I've been writing a Sudoku Solver. I've completed the easy parts; reading in the board and checking a board's correctedness. The next part will be the actual solving of the puzzle, which I believe will be significantly more challenging. I was trying to write tests for my current functionality, but that exposed that I don't actually understand how to write tests for Rust code at all. So I've been researching that.
I'm having lots of problems understanding `mod` and generally how file imports work. My understanding: `mod x;` will search the filesystem for `x.rs` or `x/mod.rs` and "import" it (I don't know if Import is the right word). `mod x {}` is where you'd define a module's contents. Is this correct? But I'm having trouble understanding where to use `mod x` and where to use `use`. Are they similar at all? Have I just totally misunderstood? Also, do I have to "export" a module? As in, `pub mod x` will mean that it can be imported into other files, yes? As in, `pub mod x {}` in `x/mod.rs` and then in a `main.rs` I do `mod x` to import? Or `use x`?
I admit the actor model should have occurred to me sooner, since I've even played with actor-like prototypes in Rust, but I say "actor-like" because the channels have more guarantees than the "Actor Model" and I tend to see process calculi used more in describing communication protocols where channels are usually first-class and point-to-point. One thing I have been considering is how to expose different interfaces to different other "actors" or peers? Say two actors send to a third actor, but only messages that are of a specific type for each of the two actors with no overlap. With a single endpoint, the channel has a single message type that is a simple tagged enum for the two types of messages. This isn't really a problem for the receiver (it should be prepared to deal with both message types), but this type is somewhat weak from the sender's point of view: there's nothing at compile time to prevent one or the other from sending a message of the wrong inner type (besides maybe some proper module scoping to prevent "accidentally" sending the wrong message). I was considering making all channels point to point which would solve this problem (further straining the actor model analogy by removing the "single endpoint" or "mailbox" concept), but unfortunately the ["select" statement (macro)](https://doc.rust-lang.org/stable/std/macro.select.html) is unstable and (possibly?) slated for removal, and in any case it doesn't provide any kind of "fairness"
You can do this: 1. In your build script, use [the `rustc_version` crate](https://crates.io/crates/rustc_version) to get the version. 2. Have the build script output that information; probably the easiest way is through an environment variable: `println!("cargo:rustc-env=COMPILER_VERSION={}", rustc_version::version().unwrap());` (or `foreman::env_var("COMPILER_VERSION", rustc_version::version().unwrap());` with [my crate](https://crates.io/crates/foreman)). 3. Retrieve the version string in your main code via `env!("COMPILER_VERSION")`.
Hey, pcwalton! SprocketNES was a big help when I was building this originally, thanks for that.
&gt; I couldn't get it to work with an iterator, but maybe I just needed to massage it some more. Really? Unless my x86-foo has failed me, simply doing [this](https://godbolt.org/g/DrGzMW) has only one place where it jumps to a panic: right at the start when it will jump to a `slice_index_len_fail` call if `n+1` is greater than `data.len()`. It then looks like it's vectorised it. The result of which is that it's about twice as fast. I ran this benchmark: #[cfg(test)] mod tests { use super::*; use test::Bencher; #[bench] fn iter_test(b: &amp;mut Bencher) { let nums = (0..1_000_001).collect::&lt;Vec&lt;_&gt;&gt;(); b.iter(|| { let v = test::black_box(&amp;nums); test::black_box(do_stuff3(v, 1_000_000)); }); } #[bench] fn loop_test(b: &amp;mut Bencher) { let nums = (0..1_000_001).collect::&lt;Vec&lt;_&gt;&gt;(); b.iter(|| { let v = test::black_box(&amp;nums); test::black_box(do_stuff2(v, 1_000_000)); }); } } And got this result: PS D:\Programming\Rust\RustProjects\test_project&gt; cargo bench Compiling test_project v0.1.0 (file:///D:/Programming/Rust/RustProjects/test_project) Finished release [optimized] target(s) in 0.77 secs Running target\release\deps\test_project-00ea2c25c07a019b.exe running 2 tests test tests::iter_test ... bench: 236,711 ns/iter (+/- 16,041) test tests::loop_test ... bench: 473,997 ns/iter (+/- 20,610) test result: ok. 0 passed; 0 failed; 0 ignored; 2 measured; 0 filtered out [Edit] Hidden my dumbassery of not blackboxing the function call. Got sane results. However the bad results did show the compiler is better able to optimise away an iterator call. [Edit2] The plot thickens. When you give them known data, like [this](https://godbolt.org/g/nbi9Sm) both vectorise. Optimizing compilers are tricky beasts.
Well, mostly because it never occurred to me to try doing it any other way. Now I think about it, that does seem like a good idea. I'm not sure how the interface for editing an existing code block works though. Does dynasm-rs guarantee that the buffer won't be moved while it's being modified? If it doesn't, then one would need to make sure there are no stack frames pointing into the buffer when it's modified.
I'm personally just going for the C ABI for plugin support in the Ion shell via the libloading crate. You can write the plugins in Rust -- just export your functions with a C interface (very easy), then import them on the other end through the C interface. Enables users to use any programming language they want, so long as it can export a C interface. There's several approaches that you can take for communicating with dynamic libraries though. The most complex being using the recently-announced RON to transfer complex Rust type information, or using a simple method like designating one C function to list all the functions that the library provides, and loading all the symbols accordingly. I'd personally like to see good support for importing Rust natively though, myself, just to ensure that downstream plugins are all written in Rust. Fatal issues in C plugins can be catastrophic.
Check out https://github.com/mehcode/salt-rs/blob/master/examples/proxy.rs , https://github.com/mehcode/salt-rs/blob/master/examples/state.rs , and https://github.com/mehcode/salt-rs/blob/master/examples/time.rs for some interesting examples of what Salt is capable of.
&gt;Does dynasm-rs guarantee that the buffer won't be moved while it's being modified? Yep. The API itself is completely safe, and even supports assembling in one thread while executing in multiple other threads. How stuff works internally is that the assembler actually assembles to a temporary buffer (just a Vec&lt;u8&gt;). In addition to this, it has a executable mmap guarded by a RWLock. Any Executor needs to acquire a read lock on it to get a reference to the buffer inside. When you use Assembler::commit(), the assembler evaluates the labels, acquires a write lock, flips protection of the mmap to read/write, copies the temporary buffer into it after the previously committed data, and sets the permission back (or if the buffer is too small, it allocates a larger one and copies stuff over without acquiring the lock, only acquiring it once the buffers have to be swapped). The modifiers use the same internals, where to access the committed assembly happens inside the acquired lock, while access to uncommitted changes is lockless. So basically, as long as you don't store raw pointers to the inside of the Executors you'll be fine (and you need unsafe{} blocks to do anything with those anyway). Just store offsets, acquire an Executor lock and execute away.
I have my rocket app running without an update for about 4 months now. If you are worried maybe go with iron, I heard its quite stable.
&gt; My understanding: ... Is this correct? Yes, though when you have a file `x.rs` or `x/mod.rs` you don't need to put a `mod {}` block in the file, since the whole file is the module already. &gt; But I'm having trouble understanding where to use mod x and where to use use. Are they similar at all? Have I just totally misunderstood? They do different things. `use` is for importing items. `mod` is for declaring modules. You also have to (I'll call it) "forward declare" modules in your crate root (`main.rs` or `lib.rs`). If the compiler can't get to a module from the crate root, it won't be used. So when a rust file has mod foo; mod bar; you're telling the compiler "go find these modules, they're defined somewhere else." It seems like an unnecessary step (and it can be), but it's helpful for e.g. conditional compilation: #[cfg(unix)] mod unix; #[cfg(windows)] mod windows; &gt; Also, do I have to "export" a module? As in, pub mod x will mean that it can be imported into other files, yes? As in, pub mod x {} in x/mod.rs and then in a main.rs I do mod x to import? Or use x? Sort of. Don't need `pub mod x {}` in `x/mod.rs` since `mod.rs` is already a module, as I've mentioned. You can use something at the scope it's declared without it being pub, but if you want to use it outside that scope it needs to be pub. [See this example](https://play.rust-lang.org/?gist=bcbe93a6310859817eea986bfd867460&amp;version=stable). You can use private::Bam inside foo, since private is declared inside foo. You can't use private::Bam at crate scope since it isn't public to the world outside foo. What this means in practice is that if you have a module `x.rs` that you want to be private to the crate you add `mod x;` to the crate root. If you have a module that you want to be public outside the crate you add `pub mod x;` to the crate root. Does that make sense? 
matching versions is cool in theory but it may be a mess with patches and changing api only in rust bindings.
They're essentially identical. Use whichever one you like more. I think specialization also made "Hello".to_string() to be just as performant as the other two, so you can use that as well now. On old compilers it was quite a bit slower since it had to go through the string formatting code.
Have you considered [cap'n'proto](https://github.com/capnproto/capnproto-rust)? I don't have much experience with it personally, but it seems to be a mature option for RPC in Rust as well as other languages 
Or you can just hyper with plain old stable. For such a simple API hyper may suffice. 
Update: Project maintainers are actively developing that area of the API and have been for the last several months. If you're feeling more positive about rust-sdl than I am, you might want to hop on the discussion (issue #667) I'm staying out of it because the "just use Rc" solution has been proposed already. I don't think I'd add much. Because you're new to Rust, I'll outline how `Rc` is implemented - For any type T (even dynamically sized types) there are types RcBox&lt;T&gt; (private to the standard allocation library) and Rc&lt;T&gt; and Weak&lt;T&gt;. RcBox is the same as T plus two `usize` counters. Rc and Weak are smart pointers to RcBox. When you ask for a new Rc, the library heap-allocates the `RcBox` and initializes it with the value provided. The two counters are (number of Rc pointers) and (number of Weak pointers plus one if there are any Rc pointers). Both start at 1 and the library returns an Rc pointing to the RcBox. Then it pretty much does the obvious. Cloning and dropping smart pointers adjusts the counters. Threadsafety is enforced as "single thread only" (!Sync !Send). When a counter drops to zero, the RcBox is destroyed in two steps. - no strong Rc pointers: drop_in_place to run the drop method of T - no pointers: free the memory allocated for the RcBox. 
A while back I tried several of the websocket crates, some had problems like you couldn't split the sender and receiver but I don't remember which ones. I then ended up using tokio-tungstenite but after that I realized ws-rs would work for my use case I switched to that and it works well. (My use case is using websockets to communicate between my Rust application and its web UI.) Btw, according to the benchmark on https://ws-rs.org/ ws-rs is faster than rust-websocket. &gt;You don't need to use this library to the exclusion of other WebSocket libraries, in Rust or other languages, but if you find yourself considering which library to use: choose the one that has the API you like the most. The API is generally more important than performance. The library API is what you will have to deal with as you build your WebSocket application. The design of WS-RS aims to provide a clean, consistent API. If you identify possible improvements please make a feature request. &gt;However, if performance is what you value most and you want a WebSocket library in Rust please consider WS-RS. Here is how it stacks up against some other common frameworks using the example benchmark tool to open 10,000 simultaneous connections and send 10 messages. These results are not reliable as a serious benchmark:
Yeah, I'm not aware of anything that does this for you. I think setting up a shared pipe would work well, it's basically a channel and is very fast (with long running processes as you mention). However, I'm not sure how well that would work on Windows. You can also always use a local tcp socket. There's lots of infrastructure for those, and they definitely work cross platform.
What structures should **not** derive Debug? #[derive(Debug)] // When not to do this? And if the answer is rarely or never, why is it not opt out?
I saw this recently https://twitter.com/paulcbetts/status/899134986862739456 It's just debugging but maybe profiling tools work too? I haven't tried it myself yet.
Got the recap done! https://matthewkmayer.github.io/blag/public/post/rustconf-2017-recap/
True, but I already knew about all of those options from my time working in Python. What I'm looking for is something low-effort... comparable to the monstrosity I'm contemplating where the backend would have no plugin support beyond a function to register plugins and it'd be each frontend's job to wrap both the backend AND plugins so they can be loaded using something like the Python Yapsy package. (The project uses a PyQt+rust-cpython frontend and a Rust backend.)
I tried Very Sleepy, and this: https://github.com/xwlan/dprofiler Both work, and the AMD profiler apparently works too: https://dev.to/martincerny/profiling-rust-code-on-windows-using-codexl
No, but I'll look into it. That said, the more I think about it, the more I realize that it'd probably be easiest to do this if I do some other refactoring first, winding up with a precursor to a plugin system that operates purely at compile time but a plugin-ready architecture.
I've read the generated Assembly from both fynctions, and although it isn't exactly the same, the main loop, in my eyes, is equivalent. Both loops are essentially the same length and has the same logical order: - Sum (1 instruction) - Loop condition - break (2 instructions) - inc/dec (1 instruction) - some kind of bound check
There's a shit ton of functions that make the conversion from &amp;str to String. (almost) all of them are from some trait that defines a relationship between the two, and they're all equivalent. For example: * `from` is the From trait, impled [here](https://doc.rust-lang.org/src/collections/string.rs.html#2074) * So is `into`, by association. * `to_owned` is from the trait [ToOwned](https://doc.rust-lang.org/std/borrow/trait.ToOwned.html) * `to_string` is from [ToString](https://doc.rust-lang.org/std/string/trait.ToString.html) * `from_str` impled [here](https://doc.rust-lang.org/src/collections/string.rs.html#1950) And so on
Might get confused with https://github.com/saltstack/salt
As a side note, Thunderbird has been the only email client I've ever enjoyed using, thank you.
If you're using the MSVC build of Rust then Visual Studio's own profiling tools are decent. 
Definitely open to discussing a better name on GitHub if you have any ideas. Naming is definitely a challenge. Salt has grown on me though. And I think python system configuration and rust web server are different enough spaces. A lot of names I considered are "squatted" on cargo which is a bit frustrating. Edit: I'm not tied to the name "Salt" or anything that means salt. In my opinion a good name for a framework is something that is easy to say, is 4-8 characters, and is reasonably opaque (has no inherent meaning when in the context of programming). Edit: Thanks to /u/xav_19 I've decided to rename the project to "Shio".
Hi everyone. I am posting this because I think smarter people than me can help TJ add Rust support to his Up "serverless" framework. He already has an issue created for it, but it has seen no progress since it was posted in June.
Not to mention NaCl/libsodium and NaCl [Google Chrome]. It's already a fairly overloaded name. Edit: And [saltpack](https://saltpack.org/), named because it's built on NaCl/libsodium.
You're welcome. Always glad to help.
You're looking for /r/playrust
I fear my enthusiasm is limited. I don't want another 'move quickly and break things' web framework for rust; I want a 'works and will continue to work' one. 
I'm really sorry, as I'm sure you spent considerable effort on this, but this is literally like the sixth or seventh async Rust web framework. I think at this point, effort would be better spent improving and/or stabilizing one of the existing ones.
May want to put the best examples in the README, so it's on the front page.
I apologize if I gave off the wrong feeling. I'm fully committed to "works and will continue to work". If you take a look at the [Roadmap](https://github.com/mehcode/salt-rs/issues/1) you'll notice that only the Router and Middleware interface have any plans of changing soon and we're at 0.0.x. One large issue for asynchronous web frameworks is ergonomics. My current plan is to get to a working example for a dozen or so common cases (and additionally a couple of small applications) and focus on doing what we can to make these cases as clean as possible. This is going to be a slow process that'll probably involve pushing PRs into several libraries that deal (and currently don't deal) with tokio.
Not offended at all. I'm only aware of a few async web frameworks and only one that has any momentum. It's hard to go into a framework that has momentum and attempt to change some underlying architecture. It's also hard to go into a web framework that is mostly abandoned and go "hey I see you have this sitting here". I'm hesitant to go into why "Salt" is doing things "better" but if you look at https://github.com/mehcode/salt-rs/blob/master/examples/proxy.rs#L14 and https://github.com/mehcode/salt-rs/blob/master/examples/state.rs you'll see a couple things that are uniquely possible in Salt (due to how it uses tokio). Some architectural things to point out: - A thread-local event loop allows each handler to have directly access the event loop handle. This is crucial as client libraries that are async require a tokio Handle and in other web frameworks it's convoluted or impossible to get access to one. - Handlers are not cloned and are shared across threads. This allows for handler state when needed. My goal is not to make the best, most all inclusive async web framework ever. My goal is to iterate on async workflows from a web framework perspective to improve ergonomics. This should hopefully improve the situation for all async web frameworks. For example, using serde-json and tokio results in some very [verbose code](https://github.com/mehcode/salt-rs/blob/master/examples/json.rs#L40-L51) at the moment. I'm currently exploring options to make this more ergonomic not necessarily in Salt but across the board.
Yes, that's a great idea! Generating the wrappers would be trivial since you don't need to convert data, only the ABI, and you can use `*const c_void`, forgetting it on the caller side and `ptr::read`ing it on the callee side EDIT: I guess as far as API goes you would create a trait that represents the API of your plugin and do `#[derive(Plugin)]`, which would make an implementation of some `load` fn that returns a boxed trait (or even just an `impl Trait`, since I don't think it actually needs dynamic dispatch).
How about MSG?
It's nice to see so much experimentation with Rust web frameworks, and let's hope we can consolidate these ideas into something great.
Nice to see C ecosystem around PHP get little rusty. &gt; The standard way to run PHP is to use nginx + php_fpm. Not only is this a pain to setup, but FastCGI is not very fast. Any notes of achieved speedups?
How about "garam", which is Malay translation of "salt"?
I tried Very Sleepy a while ago and didn't get anything sensible out of it. It seemed like all the function names were swapped around. I couldn't take rust profiling results seriously until I had a linux box set up. Does anyone know if there is a list of modifications from default release settings that have to be turned on to get sensible results?
Sad to see the first comments to be so critical. This really looks like a very clean asynchronous web framework that doesn't use advanced rust language features and still looks clean and approachable. I think it's great to see how much using impl trait improves the ergonomics of coding these sort of asynchronous services. I haven't delved too deep into salt, but it left a good first impression with me.
Thanks, this is all very informative. I didn't want to consider that the problem was with the library as I had enough complexity dealing with my own.
"swapped around" how?
I was thinking about shio, which is salt in japanese as a refererence to tokio and as a free bonus it has io in its name ;)
Converting the data may not be necessary, but being very pedantic about what form it must be in would *certainly* be. For example, we've already seen an example of why `#[repr(C)]` is necessary for compatibility of structs across compiler versions. Maybe a `build.rs` that adds `#[repr(C)]`, `#[no_mangle]`, `extern "C"` and the like and bails out with an explanation if it can't massage the API into an acceptable state. That said, it *would* be necessary to convert things like enums into something natively representable in C since, otherwise, you'd be relying on internal implementation details never changing. (Conversely, a supported subset not much bigger than what JSON can represent would be very comfortable and useful indeed. Enums, OsStr/OsString, and Path/PathBuf mainly.)
Or you could marshall across the boundary, which would mean you could keep the same API for an in-process plugin or an IPC- or even TCP-based plugin. I definitely don't think that a `build.rs` is the right solution, since it's extremely magical behaviour. You don't need to add `#[no_mangle]` and suchlike, you can add the "proper" names as automatically-generated metadata. `#[no_mangle]` means you can only ever have one of each name per binary artefact.
I have previously used opengl (with the "gl" crate) and glutin and was able to draw thousands of lines per frame (into a dynamic vertex buffer, using gl 3.3) while maintaining 60 fps. I guess this might be a bit low-level for you, but from what I have found its the best way of avoiding unnecesary overhead.
We don't intend to match versions anyway.
There's no point in releasing something incomplete in 1.0...
Are you saying that the mangling algorithm is guaranteed to be unchanging across Rust compiler versions? As for the `build.rs`, my thoughts turned to it because we don't have full procedural macro support yet and I'm having trouble envisioning the degree of frictionlessness I desire with anything less than that.
No, but it doesn't need to be. You can generate a `cdylib` and store the "real" names in some metadata file, they're going to be mangled but they're still always going to have _some_ externally accessible symbol. If we know that, we can access it with `libloading` or something in the same way we'd access a `no_mangle` symbol. I'm not against using a `build.rs`, but that should be an implementation detail of using proc macros (i.e. using syntex or something) rather than a way to do whole-crate rewriting without the explicit use of macros.
Hi, Did you found this [link](https://bitbucket.org/chromiumembedded/cef/wiki/GeneralUsage#markdown-header-message-loop-integration)? If you read point 1 and 2, you see that calling c.tick() to often will harm the performance. Maybe that solves your problem :)
&gt; No, but it doesn't need to be. You can generate a cdylib and store the "real" names in some metadata file, they're going to be mangled but they're still always going to have some externally accessible symbol. If we know that, we can access it with libloading or something in the same way we'd access a no_mangle symbol. In that case, it'd be better to embed the metadata inside the library file itself so there can't be accidental version mismatches. &gt; I'm not against using a build.rs, but that should be an implementation detail of using proc macros (i.e. using syntex or something) rather than a way to do whole-crate rewriting without the explicit use of macros. Ahh, then we most likely agree and there was confusion over whether `build.rs` was merely a side-effect of proc macros not yet being ready.
thanks.
Because the compiler can shorten borrows. There's no safety issue in a borrow period being shrunk; you only get issues if a borrow period were to be extended.
I think because of how subtyping works for lifetimes, references can be used as if they were references they outlive, so `k` gets implicitly coerced to a reference with a lifetime, say `'c`, artifically restricted to `'a: 'c`. I'm gonna assume the rationale is that you can't break anything with it so it only makes things more convenient?
Generally I feel like it's best to not think of lifetimes as a feature you can use to *do* anything, you can only use them at best to win arguments with the compiler about how your code is really memory-safe, promise.
I think it is a good idea to have more options, especially if the new solution is different than existing one. A new approach is always a good idea, it may inspire other frameworks.
Cool. Try to write some simple web app with it and put the code on GitHub :). Something bigger than examples. It will show people that the framework is usable and you will get some insights from the user perspective
Though if you check the source for them, you'll see this: * `from` just calls `to_owned` * `to_string` just calls `from` So once they pass through the optimizer, they should all be doing the same thing.
&gt; I want a 'works and will continue to work' one. The only way this happens is if people know how to build something that works reasonably well. To do that, people have to build shit, experiment with things and *learn*. Takes time.
Experimentation and competition is good. I think it's just easy to get a bit burned out on the recurring news of Yet Another Web Framework especially when you're not actively involved in the space and don't know what's the great thing about the new one or the shortcomings of the last. Motivations for developing it are often short or omitted entirely probably to avoid being overly negative about other projects. That does make these announcements all the more opaque though. Felt similarly with the parser combinator libraries. 
I think we have a winner
Very strongly disagreed. Async Rust is barely even a thing yet, and it's still very early days. If there were any ideal time for rapid experimentation, it's now. (And I'm pretty sure there aren't six or seven of them...)
Very nice
/r/playrust
I don't disagree, but for what it's worth, the developers are aware of these problems and I think a complete rewrite of the docs is on the cards - see https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676/7 
The bash version was just using `find` and `grep`, so far more basic than the Rust version which is reading two config files, expanding the paths from the config with glob, then also scanning all those files. Using `time` to benchmark: Bash version : 0.25s Rust: 0.05s
I think it might conflict with your custom Debug. Not necessary for completely trivial private types. Depends on fmt, so embedded software can't use it and doesn't want it.
Yes have some good points. I also think another reason may be that people have a chance create a new, shinier framework cause there is no clear winner. Rust have similrities to javascript - lets make new framework, lets create something new! It is great but noone wants to maintain other person project. I think the problem should be discussed openly.
In my opinion, this is not going to be run for speed, but for safety. The fpm part is security critical, since it is present in *every* single app, site and request that uses modern php. It's very unlikely to have a speed impact when correctly configured, but it will always have attack surface. Rust is certainly a welcome addition to this area. To give you an idea, I'd say 99-99.99% of the time is spent inside php, not php-fpm
Or NaCl, the crypto stuff
&gt; And I think python system configuration and rust web server are different enough spaces. The biggest problem is google-ability. "salt tutorial" "salt resources" "salt web" "install salt" etc etc are all likely to return hits for the python code, not yours. Which greatly effects how easy it is for new people to find or learn about it.
"bash probably bout 25 seconds? no way, rust is not that fast" was my thought before u replied but i was right xd
know japanese, confirm good name
what about rust tutorial? try google it :p
do this. just not too much, but a few small examples would be great idea
At this point there's very little consensus at to what an async Rust web framework looks or feels like. You're right that it's hard to contribute to existing frameworks, but in many cases there's not much to contribute to, especially if the architectural goals are different. I'm glad the OP is experimenting, and I wish them all the best.
This looks really nice!
Hmm. I wonder what I was doing wrong. I just created a `main.rs` that imported a `pub struct` from a different file, and all worked as expected. Yesterday when I was playing around with it, it was not working well. I'm wondering if I wasn't doing `mod x` and `use x::Thing`? Anyway. So, from `main.rs`, I did: `mod goo;` `use goo::Alex;` (Alex being my name and a pub struct I made in `goo/mod.rs`) So what the above code is saying: - `mod goo` - Go find a module named goo, either in `goo.rs` or `goo/mod.rs` - `use goo::Alex` - Once found, import these specific things from `goo`, specifically `Alex` Is this a correct (albeit laymen's) understanding?
The thread isn't about a programming language called rust, it's about a web framework currently called salt.
I tried that, I also tried calling it independently from winit's event loop in a different thread in a regular interval, that also didn't work :/
The Rust introduction is anything but deep and only scratches the surface, mostly syntax. No word on traits, ownership, borrowing, lifetimes ... but pages 6-9 are about what C++ subset allows memory safety. Havn't checked the details yet. But I thought this might interest some around here.
`rustdoc` only documents public things. Well, actually, it strips out non-public things as one of the default passes (which you can control with the `--passes` option; not sure how to pass it from `cargo doc`, though).
Uhhh ok, I did not notice that yet. Thanks!
I know, but given the number of these that have popped up, my enthusiasm for trying it is pretty much zero. There's something else you need too to build something that works: users to try it, test it, give you feedback. So why should I be enthusiastic about this? ...its hard to work up enthusiasm to engage with that process when anything you build is broken next week. /shrug
Good luck then~ When you hit 1.0.0 and commit to a stable API, I'll definitely give it a try~
Hey, I'd love to see some of you there! And I *know* a lot of you would give great presentations about your favorite RFCs! Too many RFCs and all of them are good? I know, right? Here are some of my favorites (excluding ones written by me)! - [cargo workspaces](https://github.com/rust-lang/rfcs/blob/master/text/1525-cargo-workspace.md) - [TryFrom and TryInto](https://github.com/rust-lang/rfcs/blob/master/text/1542-try-from.md) - and good ol' [associated items](https://github.com/rust-lang/rfcs/blob/master/text/0195-associated-items.md)!
Hi! I'm newcomer to rust and I don't how to run examples. "rustc examples/hello.rs" can't find salt crate and cargo run have no target available. I can change Cargo.toml to add a run target, but I'm sure that a simpler maner exists. Can someone help me?
Well the bash version took a quarter of a second, and the Rust version is still five times faster, so I'm pretty impressed!
&gt; This one is weird. The example below shows how to return a value from a function: &gt; &gt; fn add_one(x: i32) -&gt; i32 { &gt; x + 1 &gt; } &gt; &gt; No semicolon, no return keyword... And a strange-looking arrow. It doesn뗪 look very friendly at first sight. Next time someone complains that Rust should have used `[...]` instead of `&lt;...&gt;` for generic parameters, just remind them that some people find *any* deviation from their expected syntax scary. (Though personally, I feel such people should be dropped into a pit with nothing but Prolog and Lisp to use for a few weeks, which will either cure them of that ridiculous phobia, or drive them to become folk songwriters.)
Yup. The arrow is not even that strange for a C++ programmer. C++ *does* have the "trailing return type"-syntax since 2011: auto add_one(int x) -&gt; int { return x + 1; } :-)
Not everyone needs to be enthusiastic.
I think, apart from API completeness, being able to create GObject subclasses from safe Rust would be a good 1.0 goal. Missing API seems less important, it could always be added later when someone actually needs it. And there are quite a few things that can't be exposed from safe bindings anyway.
Should probably write a complete example for that some time next week, with virtual methods, properties and signals. So that we have a baseline with unsafe Rust to safe Rust, reusing existing glib-rs infrastructure. And then could make the gnome-class macro stuff step by step be able to generate exactly that.
There's plugins for VS Code and IntelliJ, which can be installed from their respective plugin stores, more info here: https://forge.rust-lang.org/ides.html I've tried both VS Code and IntelliJ, and I would personally recommend IntelliJ.
I would just like to say that this is pretty close to what I would expect an async web framework to look like in Rust. Much less verbose than Gotham. Especially your in-progress [example here](https://github.com/mehcode/salt-rs/blob/tokio-serde-json/examples/json.rs#L22) looks very promising! If you could work out how to make handlers using [tokio-postgres](https://docs.rs/tokio-postgres/0.2.1/tokio_postgres/) as ergonomic as that example, then I think you might be onto a winner!
You want 'cargo run --example &lt;name&gt;' where name is the filename of the example you want to run without the .rs extension
The way I've come to understand the module system is that `mod` acts as to say "compile this rust source as part of the project" and `use` is creating a local alias to access the name more easily without having to type the fully qualified name. Whereas in other languages you either define the files to compile by passing them to the compiler explicitly or specifying them in a separate project file. Rust modules let you define the list of source files in the source itself with the `mod` keyword.
Here's some feedback: - I found Context to be a confusing name, it took me about a minute to realize that this was the Request data. Is there a reason it isn't just called Request? - I don't see route syntax specified anywhere, does it support parameters, and if so how are they specified? - How does global application state, such as a database url work? I think that using the `HandlerWithState` interface for this would be annoying as you probably want to pass it to all parameters. In my opinion global state should be first-class, I can't think of a web application that doesn't use global state. - If you haven't, write a few small applications with some common libraries (Handlebars, Diesel, maybe tokio-postgres). Not only does this give you really concrete examples to show off your framework, it will help you find bugs and needed features. I wrote a forum and a git server when I did this, but the best things to write are things that are useful for you. - Consider adding some useful macros. This is the type of thing that you find useful when you start writing projects of a few thousand loc. It's hard to say what you should write, but just look for things that you find annoying or that you copy paste a lot. E.g. I found that I was copy-pasting the exact same function signature for all of my handlers, so I wrote a macro to simplify it. It's hard to say more than that without a more complex example to look at, but Salt looks pretty simple which is a big plus! I forgot to say that I understand that this post is kind of testing the water, my list is just meant as things to consider for the future.
Thanks! Is there any chance I could see the code to get an idea of how you did it? I'm still learning how to do all this stuff! :)
Yes, but for me debugging doesn't work now (22.08.2017) in CLION. Also you have to create project in IDEA, Clion can't create new rust project now. https://github.com/intellij-rust/intellij-rust/issues/1643
Can you point me to any recommended reading to understand how Pathfinder works? It looks amazing but I have no idea what magic it's working to be faster. Does it have something to do with using OpenGL 4?
Turns out Rust FFI with C is exceedingly easy. It actually worked in one shot (copied https://github.com/alexcrichton/rust-ffi-examples/tree/master/c-to-rust)
Agreed, it would be nice to have some sort of clear winner for some common problem categories, so you can just say "I want to build a web app that does X" without worrying too much about infrastructure, instead of saying "I want to build a web app using framework Y".
pcwalton's blog post I linked above goes pretty deep into how it works, and also links to some documentation on stb_truetype and font-rs, which use similar algorithms on the CPU. The basic idea is that it sends the actual curve data from the font to the GPU, does the tessellation there, and then uses a trick with coverage deltas to make filling really fast.
Well, its around 18K lines of code at the moment, so you can't really just look at the code. If you have never done "raw" opengl before you probably should look into something else. There have been a lot of sugestions in this thread which probably are good. If you really want to do opengl though you can look into [`glutin`](https://crates.io/crates/glutin), [`gl`](https://crates.io/crates/gl), and [learnopengl.com](https://learnopengl.com/) for instructions on getting things drawn in opengl. To draw lines, I put triplets of vertices (such as `struct Vert { pos, color }`) into a `Vec`, where each triplet creates one triangle. To create a line I just use a stretched rectangle made of two triangles. I then upload the complete `Vec&lt;Vert&gt;` to opengl with `gl::BufferSubData` and render it. If you really are serious about trying this out I might be able to create a short minimal working demo for you.
That article explains it in so much depth I feel stupid for even asking. :facepalm:
But now I've gone and thrown it all away
Yes, that'd be awesome!
I'm pretty sure that only two other async web frameworks have been announced; one was announced a few weeks ago, and the other only has one user. Regardless, if we look at existing and popular frameworks, we have Iron and Rocket. IIRC Iron was having problems with crate access (?) so development has slowed down recently. Rocket is kind of complex and when I used it I felt that it was restrictive. If we consider Gotham, which was recently announced, it looked extremely complex to me. So there is definitely room for other frameworks, especially simple ones.
Ahhh, the infamous Self-Borrowing Struct. I feel your pain. If you're a C or C++ programmer, you can consider the koan of why this is difficult. How would you write a move constructor for `Container` in C++? Or in C terms, what happens if you `memmove()` a `Container` and free the old one?
Yes. On top of that, from some conversations I had at RustConf, it also looks like more attention will be put into Tokio-core, with that being renamed to Tokio, and many of the others will be deprecated. I never actually leveraged the Tokio-proto or Tokio-service stuff, but if you did, and you care to see it all preserved, you may want to reach out to the core devs.
Wow. I should take C++ off my resum칠...
Thanks!!
Perhaps that's all that's needed. Make it look less foreign, and perhaps people will be interested in checking it out on their own.
Mama, ooh, didn't mean to make you cry
Too bad [sh.io](http://sh.io) is squatted, and unlikely to be on the cheap side. On the plus side, [shio.rs](http://shio.rs) is still free.
i used an analogy
This guy seems to have something working: [https://github.com/intellij-rust/intellij-rust/issues/535#issuecomment-320866757] It looks like the usability of the plugin is really immature/lacking.. but maybe it'll at least work.
You could use `Option&lt;NameScheme&gt;` and implement `Default` for `NameScheme`. Then, if you want to require a non-default value, check if it's `Some(scheme)`. If you just want to use a default if nothing was specified, use `o_scheme.unwrap_or_else(Default::default)`.
I'd use 2 enums, one that's Default or Actual, and one that's A or B. And you put the second one inside the first one. 
Generally you use the `Default` trait to provide default instances. enum NameScheme { A(u32), B, } impl Default for NameScheme { fn default() -&gt; Self { NameScheme::A(123) } } If you want to know if a given instance is equal to the default, you could add a method `is_default()` or simply compare with `NameScheme::default()` inline. Or perhaps implement the Debug trait manually so it prints 'NameScheme::Default' if that's what you're after.
&gt; and I would personally recommend IntelliJ. Should be mentioned that you cannot debug with IntelliJ but you can with VS Code. I use IntelliJ myself and switch over to VS Code for debugging. 
Maybe it is much easier to list what syntax is *not* supported by C++. (I'm sorry for the zealotry)
Does it complain if you actually use k after that nested scope so that the lifetime of k actually goes beyond the block?
The impl for `T` is unsound, it's perfectly legal to have private fields of a struct (or the temporary value of a public field that is reinitialised before returning, although that's not a problem in this case) be uninitialised but because this reads all fields (by essentially `mem::transmute`ing to `*const c_void`) it's possible to read uninitialised data and cause undefined behaviour.
The analogy doesn't hold, as there isn't another more-popular tech/programming related project called "rust" than the one this subreddit is about, that would analogously overshadow search results.
The officially supported plugin for the VS Code can be found [here](https://github.com/rust-lang-nursery/rls-vscode#rust-support-for-visual-studio-code) (which uses RLS). There's a link to the [extension](https://marketplace.visualstudio.com/items?itemName=rust-lang.rust) on the Marketplace, along with instructions how to set it up and configure it.
Unless you create your data with `mem:: uninitialized`, the compiler prevents you from reading an entire struct until all members are initialized. You can't have some readable `T` that's uninitialized unless you make calls to `unsafe` code. I'm not sure I entirely understand your point. Would you mind elaborating further please?
I've found C++11/14 to be completely different beasts compared to what I had been learning and using. And I figure if I have to essentially relearn C++, I may as well go for Rust instead ;)
OK, stay tuned :) I have some awesome ideas, you'll like it. You just need to wait until next Tuesday when I got time for writing all that plus a blog post.
"Many of the others will be deprecated" is not correct. The Tokio name is going to be used for what is tokio-core &amp; tokio-io today. Tokio Service will be renamed to not include "tokio". The goal is to reduce what "tokio" is to something simpler. i never intended tokio-proto to be a major component. It was always just a glue layer between transports &amp; service. Yet the guides start with it.
At its Kanji is only one character, which is nice: 蘿
This came from Alex. I may have misunderstood him, it was over a few beers ;)
I think processing/producing JSON, processing forms and/or serving static files would be welcome to get a feel for how things work. That covers the majority of my needs, and if the code is fairly terse, it's a big sell for the framework.
On the gitter you said "tokio-service has a bright future". Does this refer to any specific plans or is it more a belief in the general idea?
I'm enthusiastic because we don't yet have a solid "works and will continue to work" solution for web services on Rust, so every new project is another chance that we'll get a good solution sooner. You don't have to use it now, but it may be interesting to check back now and then to see how things are progressing.
Great work as always :)! I'm wondering if the fix https://github.com/pingcap/tikv/pull/2165 is sound. The proposal will surely prevent most of the panics but I think the right thing to do would be to check `abs(now - prev) &lt; accepted drift ` and return the max `max(now, prev)`
Worth noting that this page seems out of date - it still recommends saviourisdead's vscode plugin for example. http://areweideyet.com is a more up to date resource that also allows easy comparison of features available for different editors. I found setting up debugging with vscode was simple enough for macOS or Linux using lldb or gdb in vscode. Windows was more of a pain, http://www.brycevandyk.com/debug-rust-on-windows-with-visual-studio-code-and-the-msvc-debugger/ was useful when dealing with that.
Rust actually helps a lot at learning the concepts behind mem safety, so Rust helps learning modern C++ regardless.
"rust tutorial" might be a bad example, but I think the person was referring to the game called Rust, which often foils my googling.
I just made a release so you can even wait two more weeks if you want. No hurry! :)
The Archlinux AUR has a similar problem with how anyone can claim and upload any name, but you can flag either abandoned or fraudulent repos and the AUR trusted users will act on it. It isn't something I think can be fully automatic, but the AUR has run well for years like this.
It won't be part of the Tokio project and moved to live as a dedicated project. In practice, this is just a question of renaming the crate and moving the docs out of https://tokio.rs/
What about struct padding? e.g. `(u8, u16)` is 4 bytes with 1 byte of padding, which you can't reasonably compare.
[No](http://play.integer32.com/?gist=0077490bfe8aa7c0fec7947174518c1e&amp;version=stable), strangely. 
Depending on how padding bytes are handled, and *guaranteed* to be handled, this may or may not work properly. 1. I see no guarantee that padding bytes are always initialized; rustc, like C compilers, can get away with using `memcpy` on uninitialized data in a way users of Rust or C cannot, 2. I see no guarantee that padding bytes are always initialized to a specific value, 3. I see no guarantee that padding bytes are always overwritten with a specific value when assigning to an existing value. For example, I would expect that given: enum Option&lt;T&gt; { None, Some(T), } fn main() { let mut option = Some(42); option = None; } In the second assignment, the compiler would be allowed to only touch the *tag*, and leave `42` as is. Meaning that two `None` would have different value based on the value they *used* to have. **EDIT:** (1) used to be *Due to Rust using `memcpy`, I would assume that padding bytes are guaranteed to be initialized; otherwise I would expected `ptr::read` and `ptr::write` to have undefined behavior*, but dbaupp corrected this assumption: Rust works like C in this regard.
That works very nicely, thanks.
`mod` defines a namespace. `mod name;` includes its definition from another file or subdirectory. The units of compilation and linking are `crate`s, which may be subdivided into a tree of `mod`s. `use` introduces an alias into the current scope. `pub` causes a name to be visible from outside its module. Visible names in the top of a crate are exported to other crates. The trickiest part is that crates/modules have a separate (one per crate) hierarchal namespace. `use` imports from that namespace into the current scope. Without `use` you may name an item from the crate-wide namespace by starting with `::` and naming the full path. There's a blog post here about the current system and how it will likely change for beginner-friendliness.
Coming from Python where they are the same thing, I was kinda tripped up on the fact that `()` and `None` are distinct values. Is my understanding correct here? - `None` can only be returned as `Option` while `()` can stand on its own (or be wrapped in some enum like in`Ok(())`) Semantically: - An expression that returns `None` could have returned something else but didn't. - An expression that returns `()` is the equivalent of a 'void' function - An expression that returns `()` wrapped in some enum means that the caller should only care about which variant was returned, rather than what was wrapped in it.
FWIW, padding isn't initialised and it's fine for (the compiler generated) memcpys to read uninitialised data. The compiler can do whatever it wants internally as long as it isn't going to miscompile something, which includes things that are undefined for user code but the compiler knows that they're okay (or uses the right annotations etc to ensure it).
Is it legal? My impression is that that (or similar things) is one of the fundamental questions the unsafe guidelines/RustBelt is trying to nail down. (E.g. the work in https://www.ralfj.de/blog/2017/08/11/types-as-contracts-evaluation.html doesn't like uninitialised memory, see section 1.2.) (Also, I believe another thing that hasn't been decided is whether purely reading uninitialised data is undefined, rather than certain operations that use such loaded uninitialised data.) That said, I think your point is still a good one, in that it hasn't been decided and so it is better to be defensive.
But I _like_ Prolog and Lisp. When I was 20, syntax was a major concern. Now it is literally in last place.
But I'm excited to do it :p it does not need any new API BTW, but I have some API items on my to do list.
https://github.com/apex/up/blob/master/Readme.md#pricing How much does a merged pull request pay?
&gt; or uses the right annotations etc to ensure it I was wondering about it, specifically about how LLVM would handle it. Well, then in this case.. the idea of a memory compare just doesn't pan out.
Yes, that's essentially correct. `()` is actually a specific case of Rust's support for tuples, which has the same syntax as Python. In this case, `()` is a tuple of 0 things, and has type `()`, just like a tuple of 2 `i32`, e.g. `(0,1)` has the type `(i32, i32)`. Since there's only one way to have 0 things, `()` is the _only_ instance of the type `()`, and therefore any function which has that return type (which includes all functions which don't specify a return type) essentially returns "nothing useful" (not `None`) because there's only possible thing the signature allows it to return. [Here's a demo.](http://play.integer32.com/?gist=171df304eaa5434007d64c2859c58a2e&amp;version=stable) This means that `()` is essentially performing the same role as Python's `None`, in that it is the single value of its type (called `NoneType` in Python, IIRC) which is the return value/type of any function which don't explicitly return a value. (Because Rust is strongly typed, returning `()` requires your signature be `-&gt; ()`... but this is implied by not giving any return type, so it all works out.) It effectively has nothing to do with Rust's `None`, despite the similar names. There's no functional reason that Python couldn't have used `()` in the same way - in some ways it is more structurally elegant, because the idea of a 0-tuple naturally follows from having tuples at all rather than having to explicitly invent `NoneType`. That's not what Guido wrote into the interpreter though, so we've got `None` in that role instead. That said, in Rust, there is special magic associated with `()` values. (And other zero-sized types) Because it has only one possible value, the compiler knows that any write of a `()` value would be redundant, and whenever it would need to read a `()` value, it can just conjure the one and only possibility out of the aether. This means that all manipulations of values of type `()` can be elided at compile-time. This makes sense for functions that return nothing, but it also means optimisations in terms of, e.g. `HashSet&lt;T&gt;` is defined simply as `HashMap&lt;T, ()&gt;`, because the compiler removes all the value assignments automatically. 
Damn, I can't wait to see all of it. :D
This writeup is amazing! I love how clear the story is and the illustrations are both fun and helpful. It's also an interesting read although I didn't find any of the described techniques surprising. Then again, a difficult to find and implement solution usually seems quite natural in retrospect \^\^'
Cool! What features of OpenGL do you use that require 3.0? Would it be possible to get things working on 2.1+ instead?
&gt; Thanks for any pointers But pointers are unsafe :( *(Sorry for making a joke, couldn't resist)*
OpenGL 3.0 is almost 10 years old and seems to be fairly well supported. I suppose I just like new things! A 2.1 version is probably possible though, the shaders for the glyph textures are pretty simple. I'd also like to support other APIs, vulkan etc. Pull requests are always welcome! 
I have an older computer where I've been doing some opengl development and I can't remember if I got 3.x working but I know it supports 2.1 just fine. Hence my question. I'm not normally living so far in the past :)
There's a step-by-step tutorial here, though it is a bit outdated: https://intellij-rust.github.io/docs/quick-start.html
Insightful! Thank you.
That's nice to hear. Because with docs today it gives you an impression that tokio-service and tokio-proto is the main libraries.
Thanks for this great tool. However, it does not work in my case. Neither for nvim nor for vim. How can I check what is wrong? How can I debug?
Neat. Is there any more detail timeline for tokio project or 3 months period is all we know right now? Also, is there any reason why futures-rs don't have method like `execute_on(&amp;executor)` where &amp;executor can be Remote, Handle, cpu_pool etc?
Thanks for the awesome name. Decided to go with this.
Finally got to a point where I'm happy with the design, so I'm plunging ahead in making the library that will empower Way Cooler to act as a drop in Wayland replacement for AwesomeWM. I'm basically just reimplementing the C code in Rust by hand for now, fixing any mutable aliasing as I go if I can, otherwise punting it for later. I need to finish up the object construction code before I tackle the real issue which is rewriting the code to use Wayland / Way Cooler instead of X11 / xcb. That will be tricky, since that's exposed via Lua so I'll need some way to mock / transform into those objects. 
Glad i could help! 
It does have a system: https://docs.rs/futures/0.1.14/futures/future/trait.Executor.html So, you would do: `MyExecutor::execute(future)` Re timeline: just refocusing the emphasis on -core is not trivial work, so that's where the current work is happening.
So the `description` field is not shown at all? 
I came here expecting to redirect you to /r/playrust. Never heard of a library called pandas till now.
https://github.com/bluss/rust-ndarray Personally I just smash out some pandas or numpy and move on.
You misunderstood me. I mean instead of submitting future to executor `Executor#execute(Future)` you tell future to run on specific executor `Future#execute_on(Executor)` and make it composable  You start request on single threaded even loop, grab some data from database, then you have to do some CPU-intense work and on another thread, return to event loop and server request to client. 
This sounds great. Will future versions of hyper still use tokio-service?
First I tried to remove that speck* from my monitor, then I saw that it was a botched smiley. \^\^' ^(* The one at the end of your comment.)
Not what you asked for, but there actually is a project to use Rust to speed up pandas. (Not pandas-like, actual pandas.) Link [here](https://weld-project.github.io/). (They don't advertise it's Rust in the homepage, but it is.)
There's even a method Option::unwrap_or_default which does exactly that
Very cool, thanks!
Yes, tokio-service is around to stay.
maybe this: https://docs.rs/futures/0.1.14/futures/sync/oneshot/fn.spawn.html Moving data across event loops requires buffering / concurrency, so there is a sync &amp; unsync version.
This was so great to follow along! Thanks for you patient, hard work! 
Ah, this is actually one of the things I was look for. But everywhere I looked used their own wrapper to do so. 
If you run into performance issues with numpy, you will probably have to use native code, and then you might as well use Rust IMHO.
I really enjoyed following along your progress. Amazing work and congratulations on completing your GSoC.
Numpy mainly stays in C or Fortran code. If its not enough its because you're probably out of core so you could use Spark (or [scalapack](http://www.netlib.org/scalapack/) - but I'm not sure if there are Rust bindings for it). If you can take the hit of working with a less developed ecosystem, then use Rust by all means. And blog about it. And release the serde impls that write out to Parquet and Arrow and Orc files as FLOSS software (I would personally love to have access to these file formats from Rust).
&gt; Numpy mainly stays in C or Fortran code. This only works if your code can be expressed in terms of Numpy operations. Once it is more complicated and you need to implement a tight loop, you kind of hit a wall.
This is very relevant to my interests. Thanks! Interestingly, [Matei Zaharia](https://github.com/mateiz) is a major contributor. He's the first author on [the original Spark paper](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf).
Very recent `smart-default` crate can help you specify default values for enums with no boilerplate: https://www.reddit.com/r/rust/comments/6uj9xs/my_first_crate_smartdefault_a_default_derive_with/
True. Then you do need to drop into Cython, Rust, C, etc.
&gt; That said, in Rust, there is special magic associated with () values. To elaborate slightly, this is for anything that is "zero sized", not specific to `()`. struct Foo; This struct has no data, and therefore, has the same properties.
&gt; Depends on fmt, so embedded software can't use it and doesn't want it. `fmt` is part of core; I use `#[derive(Debug)]` in my OS with no problems! It doesn't even require allocation.
Others have given you answers, but I'd be interested in learning more about how you tried to learn this; what did you read, what made sense or didn't, etc!
I think a good analogy here is Scala's netty and finagle. tokio will be more like netty, and tokio-service will be part of a new project thats more like finagle.
HI there. So I'm just going through the docs/tutorial for tokio for the first time now. Normally I'd just open a PR (or few) for the small improvements I think could be made to the docs. I was wondering, with a rewrite of the docs/tutorial in the near future, would it be more productive for me to still make the PRs or would it better for me to simply provide feedback in some other manner?
This could be useful for ggez. How does it integrate with other graphics pipelines?
You're probably not scared by that arrow then.
Hey there /u/huntiep. I'd really like to understand where you felt the extreme complexity was with [Gotham](https://gotham.rs) so that we could address it. We've really invested a lot of effort in making Gotham ergonomic and understandable with absolutely no magic. Have you seen our basic [Hello World](https://github.com/gotham-rs/hello-world/blob/master/src/main.rs) example app for simple use cases? It is under 50 LOC. Perhaps you felt the Gotham Router was the extremely complex piece? We deliberately launched with the more verbose API there to get something out the door. Our next release will [address this](https://github.com/gotham-rs/gotham/issues/24) making that setup much more like you'd of experienced in Rails or Phoenix.
I agree. A big problem I've had with crates is that there isn't any immediate distinction between different options for a package to solve a problem, and it's not uncommon for packages to be out of date or incomplete. Unless there's some major innovation or paradigm shift to something, I'm always happier to see someone putting the finish on an existing crate. https://xkcd.com/927/
Hey there /u/nicoburns. I'd really like to understand where you felt the verbosity was with [Gotham](https://gotham.rs) so that we could address it. We've really invested a lot of effort in making Gotham ergonomic and understandable with absolutely no magic. Have you seen our basic [Hello World](https://github.com/gotham-rs/hello-world/blob/master/src/main.rs) example app for simple use cases? It is under 50 LOC. Perhaps you felt the Gotham Router was the verbose piece? We deliberately launched with the more verbose API there to get something out the door. Our next release will [address this](https://github.com/gotham-rs/gotham/issues/24) making that setup much more like you'd of seen in Rails or Phoenix.
You build a `GlyphBrush` with a gfx factory, then pass in encoder &amp; render target references to draw. So it the brush manages it's own pipeline for text vertices &amp; the GPU cache texture, but integrates fine with other OpenGL gfx usage.
Very nice 
I've never been a fan of TJ. Not for any personal reasons, but because he refuses to put semicolons at the end of statements. It bugs me to no end. EDIT: Although it isn't important in Go, but JavaScript on the other hand...
When initializing the `u8` in this case, would there be a move with zero extension? I didn't consider this case. Should the methods be marked `unsafe` as a result?
You can debug using CLion and the rust add-in. It's exactly the same as IntelliJ.
I was actually talking to hjr3 at RustConf this past weekend. This was purely for speed and ergonomics. NGINX was slow for this and it would be better to have this program handle the PHP rather than NGINX. The thinking being that hey I just want to run some PHP but NGINX is just too much for the solution and setting it up is a pain. It had nothing to do with safety, but for speed and simplicity.
[removed]
Hi /u/mehcode, just wanted to drop in and say congratulations on launching this! Both /u/smangels and I know just how much work there is in creating an async Rust web framework [from scratch](https://www.reddit.com/r/rust/comments/6t07dv/announcing_gotham/). If you're up for a chat at some point that would be great. I'd like to figure out how the projects might be able to help each other to make web development for the Rust community a really great experience. Perhaps there is even some way we could join forces in the future so we're not duplicating effort on things like project management, documentation, outreach etc. Again, congratulations!
I did push a bug fix for textDocument/didChange. Please try the latest master. Feel free to file issues in github. Also make sure you have followed the rls instructions correctly.
Probably about as much as other GPLv3 projects: https://github.com/apex/up/blob/master/LICENSE
https://github.com/servo/html5ever/tree/master/xml5ever should be what you need.
Does this serve things directly to the end user or do you put it behind nginx or similar like you normally do with uWSGI and the likes? Is it possible to use as an application server on a unix socket?
I'm also thinking about how Rust can fit into etl as a complement/replacement to pandas. There's no framework that I'm aware of that comes close to the abilities of pandas. But I've rolled my own rust prototypes of some of my company's etl, and it's fairly ergonomic even without the help of a framework. And, it's much faster than pandas (5x-30x faster depending on how parallelizable it is). It's a pretty simple etl, though, with melting as the main operation, so more complex reshaping might be a lot less fun in Rust. I'm already fairly invested in Rust, so I'm also thinking about how helper libraries can be written for etl and dataframes type operations. I'm just not sure how much the flexibility of of Python can be replicated in Rust.
Remember that dereferencing is just following a pointer to a memory location to the contents of memory at that location. A trait object is a reference to a type like any other reference, so it can be dereferenced. The difference is that the concrete type is unknown. When a function is called, memory is initialized on the stack to hold each value used in the function, and so such values either need to be sized types or references. Hence, you _can_ dereference a trait object like any other reference, but you cannot assign dereferenced memory to a local variable on the stack. It needs to stay behind some sort of indirection like a reference, a box, etc. This is why you're able to dereference a trait object and immediately take a reference to it again, but not _only_ dereference it.
Cool. I have to admit the intermeshed polymorphism has scared me away from studying it in detail so far. But everything being allocated ahead of time, that's really neat.
Yes, `&amp;Foo` is a reference to a type, with `Foo` being the type of the trait object itself (I think, since the actual concrete type is unknown as mentioned in a different comment). Trait objects work pretty similarly to slices, which also have to be manipulated behind a pointer (`&amp;[T]` rather than `[T]`, `&amp;str` rather than `str`), and will also give a compile error if you try to dereference the pointer and assign the resulting value to a variable. Trait objects and slices also share the property where references to them are "fat pointers" that contain a pointer to the raw type data plus extra information that makes the types actually useful. For slice references, that extra info is the length of the slice. Trait object references have the data pointer and a pointer to a vtable that implements the trait object's virtual dispatch functionality. So yeah, the end result is that pointers or references to unsized types are generally more useful than the dereferenced types themselves, but it's still useful to be able to talk about things like `[T]` and `Foo` on the type level. 
Hacking around with binary prefix codes (aka Huffman codes) trying to get a good feel for them. I don't yet understand the "Package-Merge" algorithm well enough to implement it but the quick and dirty greedy algorithm I wrote to do the same thing is doing it better than expected: about 4.4 bits per letter. (English text.) Next I think I'll implement Huffman's algorithm because it's a known baseline. Thanks to Rust, this "dirty hack" is only about ten lines: a `binary_heap` feeding a `while let` loop. *Nice.* 
Not that I'm aware of, but something like that would be very welcome...
_Not that I'm aware_ _Of, but something like that would_ _Be very welcome..._ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^shadowmint ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
Good bot. ___ ^I ^am ^a ^bot. ^This ^action ^was ^performed ^automatically.
Thank you Good\_Bot\_Bot for voting on haikubot-1911. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Good bot. ___ ^I ^am ^a ^bot. ^This ^action ^was ^performed ^automatically.
Is there any resources for understanding how futures and other concurrency stuff used in tokio works? I found that the docs didn't explain things very well
You might try adding `RUN cargo install cargo-watch` to your Dockerfile and then use `cargo watch -x test` to see if test on save improves your flow. An example here: Docker: https://github.com/ghotiphud/rust-web-starter/blob/master/api_server/Dockerfile Compose: https://github.com/ghotiphud/rust-web-starter/blob/master/docker-compose.yml
Thanks, I'll probably use this one
Cheers for the suggestions, I'll try them out to compare to the visual studio profiler
I'm curious what the main use cases are for this kind of thing? For example, could this be used by the `xi` editor to render text to the screen? Could this be used by a native Rust GUI framework? I'm just ignorant and am curious. I'm really hoping that enough of the pieces will start to come together for some solid UI frameworks in Rust and am wondering if this would be a jig step in that direction.
Is this what Reddit has become?
For a trait object reference like `&amp;Foo` the `&amp;*` syntax isn't useful, but it is useful for other fat pointers that point at trait objects. For example, if you have a `Box&lt;Foo&gt;`, using `&amp;*` will borrow from it giving you a `&amp;Foo`.
Hey Steve! I was actually in your training last friday at RustConf. It's been a mixture of [this](https://rustbyexample.com/mod/split.html),[this](https://doc.rust-lang.org/book/second-edition/ch07-01-mod-and-the-filesystem.html) trying to find "real" source examples on Github, and asking questions in IRC. Part of the problem may be the way that I'm going about things. I like to kind of dive in and figure stuff out as I go, rather than just reading documentation in advance. Specifically in reference to what did and did not make sense: I'm noticing that sometimes things look totally different? Like, I look through others' source code and things make even less sense before. As an example, I wanted to see the `mod`/`use` thing in action, so I went to the Rocket source to see what a real file looked like. Maybe I'm still fundamentally misunderstanding, but I would've expected [this rust file](https://github.com/SergioBenitez/Rocket/blob/master/lib/src/rocket.rs) to have lots of `mod` references, but it actually has 0? What I've noticed is there aren't very many "beginnger" projects to look through? Or I couldn't find them. But, things are either pretty complex such that I get lost, or a single `main.rs` file that does one or two things as examples. I haven't found much in between. Does that make sense? I might be getting off topic.
Please make a comparison post when you tried them all :)
/u/garagedragon got at this already, but I think it's worth emphasizing. If I have an array of 100 `()` values (that is, an instance of the type `[(); 100]`), that array is *zero bytes in size*. There's simply no state to represent -- nothing about that array can ever change. That's very different from an array of `None` values. Let's say they're of type `Option&lt;u8&gt;`. Each one of those takes two bytes: one to flag whether it's `None` or `Some`, and another to hold the value if it's `Some`. That means our `[Option&lt;u8&gt;; 100]` comes out to be 200 bytes, *regardless* of whether all the values are `None` or not. That reflects the fact that you can always do this: // Yeah, it starts out with only None's in there, but... let mut my_array: [Option&lt;u8&gt;; 100] = [None; 100]; // ...let's insert a Some. my_array[0] = Some(0xff); `my_array` isn't allowed to allocate more space for itself when you try to assign to its elements. It has to have a constant size, all allocated in advance. So the space for `Some(0xff)` is already there. (These examples would work just fine with single `()` and `Option&lt;u8&gt;` variables, without bothering to put them in arrays, but somehow multiplying by 100 makes it feel more concrete to me.)
I think what's happening is that when you call `x.do_something(k)`, the compiler doesn't use k's lifetime for `'b`, but only the lifetime from k's declaration to the end of the inner block because that's where `'a` ends, so it can be unified with that. So `'a: 'b` checks out, but if you try to return that value into the outer scope, it can't unify that because `'b` necessarily outlives `'a`.
I had the same question about two weeks ago, then I simply tossed the coin and picked ws-rs. :) The usage of ws-rs is very similar to how websocket is used in nodejs land. You need to implement three or four callbacks, such on_message, on_error, it's quite straightforward. The only problem I have is the composition of several websocket clients, then I found it's not that easy, the basic model is for each websocket client, create a new thread, but in my case, there are about 9 websocket clients, and I don't really want to create 9 threads... Probably rust-websocket is stronger at this part, but I haven't had time to check out that yet.
i am simple man, i see redox, i upvote
Elon Musk warned us, but as we failed to listen our fate is as thus.
In your edit: &gt; using memcpy on uninitialized data in a way users of Rust or C cannot I think this is also safe in C: e.g. people `memcpy` arrays of structs all the time. I believe the model is something like: it is fine to load/copy uninitialized memory, but it leaves the target also uninitialized, meaning dereferencing it as a pointer, or using it in a branch is UB. &gt; Well, then in this case.. the idea of a memory compare just doesn't pan out. Indeed.
as a python convert to rust who barely uses python anymore, unless it's an extremely intensive data wrangling task you're probably better off sticking with the pandas/numpy stack. the thing about data wrangling is it tends to involve a lot of one-offs, prototypes, etc. rust takes a lot longer to build something in but when you're done it's blazing fast and rock solid. 
You probably don't want to be calling it in the events loop anyway, since you'll get no iterations while the user isn't interacting with the window, and a huge burst of them when e.g. the window is resized.
Haha, thanks for letting me know, I'll fix it. Reddit always trips me up with the caret. 
very interesting. but I think the response content type should follow Accept header of request, not request's content type.
Great work! However, I'm afraid that rusttype is lacking maintenance. Should we request (or even fork) to move it to the piston organization, which has more reviewers?
Yes. Basically everything.
Besides the fact that it is not Intellj ;P ... i don't wanna start a fight here but CLion is a different product and we're talking about IntellJ ... i love working with CLino, IntellJ and Android-Studio and they'er basically the same build upon IntellJ .. but you just cannot debug with IntellJ for a fact.
Can pest be used for parsing binary formats/protocols too, like nom? E.g. parsing MIDI, WAV, MP3, TLS, etc.
Unfortunately, pest is currently made for UTF-8-friendly parsing only. But I would consider binary parsing for a 2.0 release given a good enough extension proposal.
That would be very useful!
Great work! Btw, are there plans to make it work with glium too? :) The rendering and create_texture/update_texture could be abstracted into a Backend trait.
You췂re welcome!
Ok. I did an update, but it still does not work. I filed a github issue.
Thx, for your great work!!!
Wait, Servo's logo is doge?
I'm starting to work on theme support for [gutenberg](https://github.com/Keats/gutenberg). I have a pretty good idea on how to do things, time to see if it works in practice! I've also started a RFC for i18n support: https://github.com/Keats/gutenberg/pull/111 and hoping to get some comments!
Unofficially, but yes.
That's nice, thanks. Doesn't apply to my case though, since none of the enum variants carry data around (yet?).
The scope of gfx_glyph is text rendering using gfx. So no glium. Rusttype is the lower level project that will work with glium. Check out the GPU cache example there if you're interested in glium usage, I actually recently raised a [PR to update it to the latest glium](https://github.com/dylanede/rusttype/pull/51).
Yes it does seem that way, I'm already relying on an unmerged fix for the rusttype GPU cache code. See [issue](https://github.com/dylanede/rusttype/issues/52). It would be nice to get confirmation from dylanede about the status of the project.
Thanks for the feedback, it's much appreciated. &gt; I found Context to be a confusing name [...] Handlers need more than _just_ the request unfortunately. I _could_ extend the meaning of "Request" to be "HTTP Request + other stuff". Context currently contains: * HTTP Request * Thread-local handle to the event loop Context will contain: * Type-map to access global state If you would take a look at [Gotham](https://github.com/gotham-rs/hello-world/blob/00bd3e094473e94f8c4f2dcc62a62e22be0b2e17/src/main.rs#L69-L80), notice they solve this by sending two parameters to the Handler. &gt; I don't see route syntax specified anywhere [...] Currently this is very basic and doesn't support parameters. There is an entry in the [Roadmap](https://github.com/mehcode/salt-rs/issues/1) for that. Routes can currently match URLs exactly and that's about it. &gt; How does global application state, such as a database url work? [...] I definitely agree with you that global or shared state should not be passed into each handler. I also agree that we should have something to handle this in a simple way. I added an entry to the roadmap for this. &gt; If you haven't, write a few small applications with some common libraries [...] Definitely planned after the roadmap gets more addressed. &gt; Consider adding some useful macros. [...] I won't rule out macros but I have them in a "last resort" bucket at the moment. 
Thank you for the kind words. "impl Trait" is definitely amazing for this kind of application.
Thanks for the kind words. I'll be slowly trying to get these kinds of examples as ergonomic as possible.
Current nightly has doge instead of the fox too. Used to be a cool blue 
You can create super-tiny docker images by statically compiling your rust application for the -musl target, and then you can actually base your dockerfile on the "scratch" image. I use this at work and our images are frequently under 10mb uncompressed.
I'm not going to comment on your threading code except to note that you should split your producer and consumer up into two types that implement Send but not Sync if you want SPSC to work safely and correctly, you can then use Arc to share the atomics with interior mutability. You don't need to share your key vector at all, either, so KeyCell can be removed entirely, and your keys can be a Vec of KeyHolder&lt;T&gt; (which is more of a KeyOption&lt;T&gt;.) However, this is never going to work right the way you're handling memory. The Java version of this thing will feed the consumer a duplicate under certain situations - where firstWrite is moved by the consumer after the producer begins iterating across the array, but is yet to retrieve the value being updated (line 102, 107 in the java) - this value is re-added after compaction anyway. In Java this is just fine if you can live with duplicates. With a c memory model, though, you need exactly one owner to re-box and drop each pointer. Receiving a duplicate will lead to a double free or something equally segv-inducing. You could make this work correctly, if not necessarily performantly, by wrapping each value in an Arc which wraps a custom Drop type that wraps an AtomicPtr. When you collect in fill(), you move the pointer out of the AtomicPtr and into a box passed back to the caller; the custom type (which would implement Drop) would then free nothing when your last Arc went out of scope. The drop type would be responsible for freeing all the memory based on the enclosing Arcs' reference counts. This also fixes the memory leak on drop you have at the moment. I imagine doing this would probably do an end run around the performance you're looking for, though. In Java, you pay the GC cost regardless of the potential for extra duplicates; with the approach outlined above you're introducing so much bookkeeping you may be better off with explicit locking, although I can't back this up. Let me know if you'd like to see code for any of the above; I've got a mostly working example based on your GitHub. 
Sigh. I have hundreds of unread email notifications in the Epochs/Checkpoints RFC thread, and today I learned that it뗩 been in FCP for 19 days. I뗬e opened https://github.com/rust-lang/rfcs/issues/2122 about adding some kind of notification mechanism, though I뗤 not sure what it should be.
To be honest, the typename following the variable name was harder for me to get used to than the borrow checker when I learned rust.
iirc, GTK+ has some CSS infrastructure that you can use from within your code, but I don't know how flexible it is.
https://rusty-dash.com/fcp
`smart-default` solves a different problem. The problem here is not the boilerplate of `impl Default`. The problem here is how to distinguish between value from `::default()` and value from `::new()`(or c'tor. or anything else that creates a value from parameters) that happens to have the same enum variant and the same data as the default value.
It was great reading about your progress and congrats on a very impressive list of PRs.
The link for "forbid non-standard literal patterns" is incorrect -- it's the same link as the next item, "cleanup for LLVM-less build, second attempt".
[removed]
Why this code use std::io; fn main() { let mut string_var = String::new(); while true { let mut vector_var: Vec&lt;&amp;str&gt;; io::stdin().read_line(&amp;mut string_var) .expect("error"); vector_var = string_var.split_whitespace().collect(); } } will compile but this use std::io; fn main() { let mut string_var = String::new(); let mut vector_var: Vec&lt;&amp;str&gt;; while true { io::stdin().read_line(&amp;mut string_var) .expect("error"); vector_var = string_var.split_whitespace().collect(); } } gives this? error[E0502]: cannot borrow `string_var` as mutable because it is also borrowed as immutable --&gt; src/main.rs:6:36 | 6 | io::stdin().read_line(&amp;mut string_var) | ^^^^^^^^^^ mutable borrow occurs here 7 | .expect("error"); 8 | vector_var = string_var.split_whitespace().collect(); | ---------- immutable borrow occurs here 9 | } 10 | } | - immutable borrow ends here
The Glow Fox is back in today뗩 Nightly.
The root of a library source is `src/lib.rs`, ton of `mod` statements there. `src/rocket.rs` contains `local::rocket` (local from the new syntax refers to the root of the current crate), which isn't exported except for `local::rocket::Rocket` by the last `pub use` statement in `lib.rs`.
Actually, my package does apply to enums with empty variants, because you still need to implement a `::default()` that picks the variant you want: impl Default for NameScheme { fn default() -&gt; Self { NamedScheme::B } } With my crate you can do this by strapping `#[default]` on the default variant: #[derive(SmartDefault)] enum NameScheme { A, #[default] B, } Still, like I said in the other comment, that glue syntax does not seem to be the issue here...
The Numba project is helping to optimize loops over numpy arrays, it may be worth investigating. 
It also makes you hate writing C++ once you've spent some time with Rust. At least that's what it does to me.
Idk. I learned C++ in school after having used Rust for over a year and it felt like I shot myself in the foot and using it was a god awful experience because I was used to Rust. Rust may help with learning memory safety but transferring and thinking about it in C++ is mentally taxing and harder to get right as a result in my experience.
I do not like the proposals in that RFC about the `local` and `priv` keywords. I like Rust's assumption of module private declarations default, and while this RFC does not want to change that both `lcoal` and `priv` sound like they should be more private than the default of writing nothing. Personally I do not see that much wrong with the current `pub` keyword other than the question if re-exporting is a bad thing or not. Also it may have been nice if exporting to a crates public API was a bit more explicit, but I do not think that is a too big deal.
Thank you so much for the response. &gt;you should split your producer and consumer up into two types that implement Send but not Sync if you want SPSC to work safely and correctly I think I am getting there. I have written some [sample code](https://play.rust-lang.org/?gist=c454440854a60cb9aaf96ff7ee94ca1a&amp;version=nightly) along that line. Do you think this looks OK? yes, there is a possibility of duplicate. I would be interested to see your modified code if I can. Thanks again. 
Now that's chutzpah. Post a comment ostensibly to say to the original poster that you'd like to explore ways to "help each other". Then use the comment to promote and do search engine optimization (hyperlinking the text "async Rust web framework") for your own framework, which competes with the OP's. I guess a response like that should make it easy for /u/mehcode to figure out how serious the offer to "help each other" is. And for what it's worth, I'm impressed with what I see so far of Salt (Shio). It looks like a very promising [async Rust web framework](https://github.com/mehcode/shio-rs).
Because the borrow of string_var to split it lives as long as the scope of vector_var. (Lexical lifetime.) I suspect this can be fixed with `vector_var = { ... };` or similar. However, I prefer the first version. You're getting a new Vec every iteration, so put it in a new variable.
Cool - Amazon's using Rust I guess?
Yup! Somebody else pointed that out to me, I'm working on fixing that now.
1. The only place where you mention Fedora is title. I don't see how it's relevant that you are using this distro. 2. It would be much lighter (in size) and more readable if instead of screenshots you would provide source code as text.
At the end of [this](http://gtk-rs.org/tuto/cross) tutorial I show how to set the theme and set a custom application icon. edit: it shows how to set a windows 10 theme, but you can just replace it with whatever theme you want
I am almost certain that /u/sanxiyn didn't write this article. You might want to post your comments on the blog itself instead.
Any plans on releasing a version/fork of glutin with vulkano support? (Unless I've completely missed the event/io handling in vulkano)
thanks!
I see, thank you very much!
Glutin is heavily tied to OpenGL (the "gl" in "glutin" means "opengl"). Instead the window handling is done by the winit library, which is a fork of glutin. Contrary to OpenGL, windowing in Vulkan is not as core. You can perfectly use Vulkan without creating any window. Therefore the event handling is done in another library named vulkano-win, which already exists. You can read the triangle example for more info: https://github.com/vulkano-rs/vulkano/blob/2f2b97e5d5ecfa934fb3be3bb8fe131a4e2bce95/examples/src/bin/triangle.rs 
that is actually a great idea for a project
游녨
Awesome! This is my first time hearing about `cargo-watch`, I'll definitely give it a try. 
I wish we could stop trying to overhaul things that aren't broken and work on things that are actually important. In over 50,000 lines of Rust code I've written in the past year, I haven't had a single problem with the module system that wasn't solved by restricted pub or simply rethinking my design to organize it better. In fact, the current module system is better than almost any other out there in other languages. The current module system is one of the main selling points of Rust in my opinion.
It's about barrier to entry. Tons of people drop rust before they write much code. Starting with those initial hurdles will hopefully help get more people invested earlier.
It's almost the exact same level of complexity as Python. Instead of \_\_init\_\_.py we have mod.rs. The only difficulty people might face is if they come from C/C++ without any module system experience at all. In which case I highly doubt any additional keywords or changes proposed would help that. Better documentation and tutorials would be easier and more effective.
Yeah I'm not really disagreeing that the module system is ok as is. But it's worth noting that it is definitely an early barrier that a lot of people run into and while you doubt additional keywords would impact this it's probably worth exploring.
IMHO this rfc doesn't make anything easier, but declaring modules. It's also adding two new keywords to "solve" what most would consider papercuts (if anything). 
I mean, I remember having issues with the module system a couple years ago when I was learning Rust, but that wasn't because the module system was _hard_, it was because the documentation for it sucked. In fact, when I get home from work today I might work on rewriting that myself.
It may be the case that this is an issue best solved by docs. Just trying to explain why it's worth considering options and why this is an important problem to solve.
A teeny tiny bit. Rust support at Amazon is "community maintained" meaning any work done on stuff like build integration, package imports, etc. is volunteered free time or funded "as needed" on a project by project basis. The community is small but growing. I'm on the team that this job is for. We just shipped some Rust to production last Wednesday! I'm looking into getting approval to be on the friends page *fingers crossed* I'm not aware of any other production uses right now though I believe people have made some operational tools with Rust. It's a small part of our overall system (we are very polyglot) but I'm hoping it'll be a stepping stone to driving more Rust adoption.
I'm also now supporting you on Patreon. Great work on the docs! The clean art style and graphical explanations are something other libraries should aspire to match.
This is basically what I meant by using native code. You could also uses Cython or PyPy or Rust. How does it compare to PyPy?
[Cross-posting](https://github.com/rust-lang/rfcs/pull/2121#issuecomment-324395155): Thanks, @withoutboats, for your tireless effort on this. To the broader community: I know fatigue is setting in with the number of iterations here, but these iterations reflect a best effort to incorporate new constraints that people have brought up, while trying to retain the benefits and constraints of the original design. I want to take a step back and re-iterate what I see as the main goals and benefits of this work. **Benefit 1: first steps with Rust** When you're first stepping beyond a single file in an application, the story with this RFC is: - Write code in files under `src/` - Items are file-private by default; you can write `local` to make them visible to the whole crate - To get items from another file, write `use local::path::to::the::file::ItemName;` And that's it! Similarly, to bring items in from another crate, just add them to Cargo.toml (which we should automate with `cargo add`), and write `use cratename::path;` to import items. The goal here, which I believe this RFC (and its predecessors) accomplish, is that in the early phases of learning Rust, there's very little you need to learn about the module system in order to be productive, freeing you to focus more on learning other aspects of Rust. (For additional motivation here, please make sure to read the evidence in the [motivation section](https://github.com/withoutboats/rfcs/blob/modules/0000-modules/motivation.md#evidence-of-a-problem), including the [detailed list](https://gist.github.com/aturon/2f10f19f084f39330cfe2ee028b2ea0c) I assembled of people tripping up on these points early on.) Only later, when you start writing libraries, do you need to learn about `pub` and eventually `export`. **Benefit 2: Clarity around paths** The story with paths in `use` statements today is confusing for two key reasons: - The fact that in general, external crates and the contents of your root module are dumped into a single namespace. Thus, when looking at a `use` statement you can't tell offhand whether its from your own crate or an external one, which in turn has led to the idiom of visually grouping these cases. This RFC clarifies matters by having absolute paths *always* start with a crate name, where `local` refers to your own crate. - The fact that today, absolute and relative paths in the root module coincide, which leads to confusion when moving code outside of the root module (which *happened* to work because of this coincidence, but won't work elsewhere). Again, `local` resolves these questions. **Benefit 3: Clarity around visibility** Visibility has been one of the most complained about issues in the module system for those more expert in Rust. In particular, it's very common to use `pub` within items in private modules that are not, in fact, exported publicly; you have to trace the full path to the root and all re-exports to know this. This RFC addresses the problem in two ways: - Making it more ergonomic to get `pub(crate)` visibility - Checking that when you do write `pub`, the item is actually publicly exported. A smaller benefit with the `local` keyword is that `pub` *always* means "public to the external world" whereas `local` *always* means "local to the current crate". **And more** There are other, smaller benefits for ergonomics, but the above encompass the major goals of the RFC around clarifying and streamlining the module system, particularly for the early stages of learning Rust. **General thoughts** I recognize that there are downsides to this proposal, and that when you've already learned the current module system, changes like this can seem like a waste of time. But please keep an open mind to the idea that **people are bouncing off Rust altogether** because of confusion around modules, and that **by far the biggest complaint in the 2016 and 2017 surveys was learning curve**. It is also a **primary goal of the community's 2017 roadmap**. Improving the learning curve in a language like Rust is not easy, and we need to be sanding down rough edges whereever we can find them. It's clear that the module system is a significantly rough edge for some people who have managed to stick it out and stay within the Rust community; it's harder to know how many people have struggled with it that we don't hear from. I said at the outset, this latest proposal is an attempt to achieve the goals initially set out while accommodating concerns and constraints brought up along the way. As we continue to discuss and iterate, I would only ask that people **genuinely engage with the initial goals and constraints as well**.
I was hoping someone more qualified would jump in first &gt;&lt; but here goes (these are all _my_ opinions :) ): The functional style you mention tends to work best when supported by a language with a _strong type system_. The more logic you can encode directly in the type, the better. You then end up with small pieces of well described values moving through your code. These small pieces tend to be quite lightweight, which in turn favours an _immutable_ approach to your code. If the bits and pieces of data are small enough, then the overhead of copying/cloning all over the place is mostly negated. And even if it isn't, the advantages of immutable structures tends to _greatly_ outweigh the cost especially once you start to deal with debugging larger codebases, multiple threads, etc. In regards to your project it comes down to whether or not you can reduce the essence of your data to these small, well described structures that can be 'passed around'. This is not always the case - sometimes you just have to have a decently sized struct with `Box`es and `Vec`s and a bunch of `impl` functions and so on. In which case forcing a functional approach (`getDistanceBetween(pointA, pointB)` over good old OO (`pointA.to(pointB)`) might not be the way to deal with it. TL;DR - Immutable (and functional) whenever possible, but its not **The Law**. 
The RFC doesn't propose `priv`. FWIW, I struggle to understand the rest of your comment. Is the issue just the particular choice of keyword here?
mit :(
Thanks whoever added gfx-rs to "Call for Participation"! Now is exactly a good time to get your hands dirty with our CoreLL integration process. Reach out on Gitter/IRC/here for details, if interested.
Functional programming in games is hard. (Far from impossible, but hard.) A game is represented by a pile of state, and a bunch of functions/systems that create new state from the old one. For efficiency reasons, that usually happens via modifying the existing state rather than creating an entirely new one. In Rust you can do either, but mutation is often less of a pain in the butt than cloning structures. Not always, of course. And it blurs the lines a little because a lot of the nasty features of mutation go away when you limit aliasing like Rust does. But in general, do what works. That's it, just do what works. Look at existing games to see what works. Don't sweat the details too much if it makes the game works. More guidance can be had in /r/rust_gamedev and #rust-gamedev
+1 for slog; it's quiet pleasant to work with and the terminal back-end produces appealing output. It even supports global loggers if you prefer that to passing them everywhere.
&gt; These examples would work just fine with single () and Option&lt;u8&gt; variables... ...unless the compiler can prove that only `Some` is used, if I'm reading [this assembly](https://godbolt.org/g/Sa2Bpd) correctly, or if the value type is `(mut) &amp;T`. (Which IIRC is still magic because the attribute's not stable?) In that case, the tag's space disappears and you're left with the raw value, in this case `u32`. I believe (though it's hard to test) that if the compiler proves that only `None` is used, it can just make the whole use vanish, exactly as in the `()` case. So yeah - `None` is not at all like Python's `None`, because the type it's a part of can have other values that are not `None`, and so we have to do all the normal reading and writing... _unless_ we can prove by static analysis that our allegedly-`Option&lt;T&gt;` value is actually always an `Option&lt;T&gt;::None`, which comes under the rules of zero-sized types. (And AFAIK the compiler is not smart enough to handle this with an array of them, where it would have to prove that for _all_ of them simultaneously to get the indexing to work out) Also, as a tangential interesting thing, TIL that the compiler is smart enough to treat the combined tag+payload in an `Option&lt;u32&gt;` as [a single 64-bit word](https://godbolt.org/g/B4zCzg), meaning it doesn't have to explicitly check for the value being `Some` at all. 
This is the kind of quality discussion I come here for.
&gt; Hey Steve! I was actually in your training last friday at RustConf. Oh hey! :D Anyway, thanks for this, it's helpful. We're trying to work on the module system to make it easier to understand; hearing about this stuff is useful. &gt; Maybe I'm still fundamentally misunderstanding, but I would've expected this rust file to have lots of mod references, but it actually has 0? This module has no submodules, and therefore, no `mod` statements. Is there a reason you'd have expected it to have submodules? &gt; What I've noticed is there aren't very many "beginnger" projects to look through? I'm not sure of a good, canonical one; there are lots of Rust projects at every size, but that doesn't mean that it's easy to say "here is a small program."
Someday any thought you could possibly formulate will have its own Unicode representation
Yeah I noticed as part of playing with this, that the size of `Option&lt;T&gt;` is often bigger than just sizeof(T)+1. All the integer option types seem to be double their regular size, like you mentioned with `Option&lt;u32&gt;`. Is that something to do with memory alignment?
Pypy is usually not useful in these tasks because the program is done before pypy has even warmed up. And it's competing with c, Fortran, or some python code which is trivially optimized with cython or numba.
Are you looking for contributors? 
Wow its so cool to see my name on the "awesome people" list (completely undeservedly) among the rust heavy hitters :). It's an awesome and exceptionally welcoming community where you can trivially find meaningful work from day one 游눕. Thanks guys! But seriously more recognition should go to **really** awesome people like /u/dtolnay, /u/kodraus and /u/vitalyd !
...and then we're back to hieroglyphics.
One relatively simple solution is that you can use a `Cell` to wrap the mutable portions to provide *interior mutability*, and avoid needing mutable references. https://doc.rust-lang.org/std/cell/ There are certainly other approaches, and I hope other people will come explain them, but I'm too tired today to be of much help.
One strategy is to change the signature of `run_instruction` so that instead of taking the whole interpreter as a parameter, it only takes what is needed; in this case presumably the stack. Of course, having standalone functions operating on `Vec&lt;Value&gt;` can get unwieldy, in which case you can define a new struct: struct Stack { inner: Vec&lt;Value&gt;, } impl Stack { fn run_instruction(&amp;mut self, _i: &amp;Instruction) { ... } } Now, after changing the struct definition accordingly, the `step` function will now look like this: fn step(&amp;mut self) { let instruction = &amp;self.code[self.ip]; self.ip += 1; self.stack.run_instruction(instruction); } And it works! Since the compiler can once again prove that the borrowed contents are disjoint, and every interpreter lived happily after. Here's everything in the playground: https://play.rust-lang.org/?gist=c8aed86df49d8c2848600f094bd5ab02&amp;version=stable
游녨
Darn I have noticed this post only today. Thanks for the (undeserved) praise /u/kodraus :) While my contribution somewhat dwindled due to me having less free time ATM you have grown into a real pillar of the community. Way to go man!!!
I think non-lexical lifetimes might solve this.
It already does. With the small caveat that you sometimes need to use more than one grapheme cluster.
[removed]
游꺊勇游游댮游돗勇
So what? Here are projects that are MIT licensed, from https://en.wikipedia.org/wiki/Category:Software_using_the_MIT_license: - Angular - Atom - Bitcoin - CURL - Expat - Gitlab - JQuery - Libxml2 - Lua - Mesa - Mono - Ncurses - Node.js - Nouveau - PyPy - Ruby on Rails - Rust - Sass - Transmission - Travis CI - Wayland - X11
The MIT licensing of Redox isn't a bad thing. It simply means that this is fully 100% free and open source software with no strings attached. No restrictions on what the user can do with Redox and it's source code. It's a perfectly valid license for system-critical software, such as display servers and kernels. Can you elaborate on why you think MIT is a bad choice?
驕뮗눨국驕
My phone doesn't support whichever character you put on the right.
[removed]
I would like to see Rust in really important infrastructure projects like systemd or D-Bus. At least they are porting libsvg, which is great!
Same here. We know that people complain about module system, but we don't know if any overhaul will help at all. Phasing out the old model might actually confuse newcomers even more, just like the old documentation and articles were haunting Rust 1.0 for a while. Because of this, I am personally just looking for some real gains for existing and future long-term users.
Biohazard.
&gt; So now I have to clone it, which defeats a bit the purpose. Does it really? The struct looks pretty small, am I missing some deep copies?
Would Amazon be interested in sponsoring Rust Belt Rust to do some recruiting? :) http://www.rust-belt-rust.com/assets/rust-belt-rust-2017-sponsorship-prospectus.pdf
I haven't really followed this series. Was the part about making `extern crate` optional dropped?
It's a separate RFC than all of this.
While all of this is certainly an enormous effort to scope out and try to please everyone, I worry that the people who the solution is really aimed at won't really be part of this process anyways. Would it be possible to build an external compiler plugin that parses this stuff, and rewrites internally to current system so the compiler can compile it? Then go and ask newcomers to try this out, to see if it all makes sense, or if pieces turn out to still be just as or nearly as confusing as normal? I'd hate for any of these large changes to get a ton of compiler support and possibly stabilize, only to find it didn't help the target audience much. I get the impression from these RFCs that the `pub(scope)` kind of had that exact outcome.
I can't but agree with this. With the recent addition of the fine grained pub(...) declarations, I don't really see the problem this RFC is trying to solve, aside from adding 100 ways of doing the same thing.
I'm so glad "Rust, but verify" made quote of the week. :)
If I do fn clone_raw_rc(a: *mut T) -&gt; *const T { let b = Rc::from_raw(a); let c = Rc::into_raw(Rc::clone(b)); let d = Rc::into_raw(b); c } is it the case that a = c = d? ie Can I clone a raw Rc and keep using the original Rc elsewhere?
Look very simple, clone should be cheap https://doc.rust-lang.org/src/core/fmt/mod.rs.html#388-398 Author has any benchmarks? It would be interesting to see.
I assure you that my reply was genuine. I have no idea about, nor have any desire to game anything to do with "SEO". So that anyone who sees this in the future understands the context, my reply above initially had the following line: &gt; Both /u/smangels and I know just how much work there is in creating an async Rust web framework from scratch. With "async Rust web framework" as a link to our Reddit announcement. I used that as link text at the time given this thread is discussing async Rust. I'm about to edit that however because this allegation has no basis in fact what so ever.
Coming from Java, the bits I struggled/disliked are 1. You have declare every extern crate 2. Writing a mod file in every directory 3. Declare `public mod` Does this revision of the RFC has a way to do local import by relative path? Update: added point 3. If we remove the above three, in my opinion the current system would be good enough. It might be possible do it without too much of breaking change. 
This is the subtlest joke I've ever read.
Not actively but if you want to contribute there is plenty to do and I'd love the help. It's always great to be able to bounce ideas around. Feel free to ping me on https://kiwiirc.com/client/irc.mozilla.org/#shio or open an issue https://github.com/mehcode/shio-rs Be sure to check out the roadmap: https://github.com/mehcode/shio-rs/issues/1 We already have someone who is working on adding catch_unwind as a recover middleware: https://github.com/mehcode/shio-rs/pull/7
I like of both ideas. Since for my current applications final states are mostly about cleaning stuff up, I use the `Drop` trait as intended, but give the user the option to explicitly opt into error handling during destruction.
Yes, it is very much the choice of word. The word `local` in my mind means something else, and the word `pub` always had a very obvious meaning to me. It was the `extern crate`, `mod`, and `use` declarations which confused me when at first when I started using Rust a few weeks ago. Now that I have coded my first real application in Rust I find the current system logical, except for the paths.
Neat library. Why did the name change from salt to shio-rs in less than a day?
We have tried the "redo the docs" approach multiple times; nobody has produced docs that have solved the issue yet. I find the re-do of our docs with this new system to be significantly better; as stated in the various discussions, right now for every project you need to learn everything at once. In this new system, you can learn it much more gradually.
The name is "Shio" ( I just have a habit of doing -rs after rust libraries on github ). It changed because I was never really into "Salt" as a name. It's overloaded with meaning in programming. Simply there would never be any hope of someone being able to search for "deploy salt" and finding this library. /u/xav_19 suggested Shio. Shio is unique and still a short, opaque name. Also Shio sort of "fits in" with the async library naming in Rust: mio, tokio, etc.
&gt; To get items from another file, write use local::path::to::the::file::ItemName; I think this part is really important. Not the specific syntax, but the fact that you can move code to another file, which may wherever you like in the filesystem (or at least anywhere that anywhere below the current file), and use the code from with a single import (use) statement. At the moment if you code in `lib.rs`, you can't do something like `modules/module1.rs`, `modules/module2.rs` without having a `modules/mod.rs` (or using attributes to specify a custom module path). This still feels a bit convoluted to me, and I think it's because there's no 1:1 mapping between modules and the filesystem. In javascript-land a module is a file, and is referred to by a path which makes things super-simple. Under the proposed system `local::path::to::item` is somewhat ambiguous between being a file `path.rs` containing an inline module `to`, or a file `path/to.rs`.
Shio is a good choice.
I'm not sure that this is a good situation for using `Cell`. It's better used for mutability that the caller doesn't need to know about, whereas in this case the caller certainly expects that running an instruction will modify the interpreter state.
`&amp;mut` is really just about having a unique reference more than anything else. `Cell` is a tool that allows you to prevent pointer aliasing while still providing mutability. I'm not sure that `Cell` is the *best* approach here, but it's a valid one.
Unicode points 65-122 are particularly expressive...
Numba uses LLVM JIT to optimize loops over numpy data structures. It has a rather narrow use case - versus PyPy which is designed as a general Python JIT. Numba also has experimental CUDA kernel generation, which is pretty exciting. From the user's perspective, it's all Python with the `@jit` decorator. We're using it in a project at my school, and while experimental, Numba has saved us from needing to write C or Fortran for some parts. 
Yeah, should be six words.
[removed]
So...radioactive turds are a subset of biohazards?
mit gives ultimate freedom to the individuals and companies, but overall freedom of humanity is better on the gpl, mit gives freedom to you gpl gives freedom to all of us. Also i dont want my code to be whored by big companies, like bsd etc
I don't know about you, but I think radioactive turds certainly qualify as biohazards. It was mostly an attempt to form a complete sentence from my favorite ridiculous Unicode characters.
What's the reasoning for write needing to consume it instead of taking a reference to begin with? I don't really see why you couldn't call write with the same arguments twice to write the same thing twice?
For non-zero constants one could use a bound like `T: From&lt;u32&gt;` and then do `42.into()` or `T::from(42)` as needed. *edit*: But it would still be a pita if `T` is anything greater than 32-bit sized.
&gt; but overall freedom of humanity is better on the gpl Why is that? &gt; mit gives freedom to you gpl gives freedom to all of us You're contradicting the first phrase that you made: "mit gives ultimate freedom to the individuals and companies" &gt; Also i dont want my code to be whored by big companies, like bsd etc So you're opposed to allowing humanity to have access to better software.
First, this function should be marked `unsafe` because it relies on the caller to provide a valid pointer (and it calls unsafe functions, so it won't compile as written anyway). Otherwise, I *think* you are OK as long as that whatever you pass as `a` was created by `Rc::into_raw`. The pointers aren't dangling because you didn't let `b` get dropped (I think `mem::forget(b);` would also suffice for the second-to-last line). I'd like a second opinion though... But why are you doing this instead of just using the `Rc`?
Yes, it's automatically inserted padding to fix up the alignment.
It generates more code for LLVM to translate, which takes up time, memory and binary size. But generally all public types should `#[derive(Debug)]` to be kind to your users.
&gt; But why are you doing this instead of just using the Rc? Interfacing with C++. There are a bunch of C++ objects that need access to a common rust struct, so I create a Rc then do `Rc::into_raw` and store that pointer in the C++ object. When the C++ object destructs, it calls a rust function that in turn calls `Rc::from_raw` on that objects reference.
Yet if you do that, then you will eliminate the consistency of the desktop (one of the great things about Linux desktops compared to Windows desktop soup).
I don't know these internals that well tbh.
[From assumption 2 in this RFC](https://github.com/rust-lang/rfcs/blob/master/text/1951-expand-impl-trait.md#assumption-2-treating-all-type-variables-as-in-scope-for-impl-trait-suffices-for-the-vast-majority-of-cases) what does it mean when it says "Treating type variables as in scope..."?
like linux? what better? mit gives INDIVIDUAL, as few people gpl gives FREEDOM to everyone
I am struggling to work with ownership and the `hash_map` collection. What is the correct way to do something like this: use std::collections::{HashMap}; fn main() { let mut hash_map = HashMap::new(); let key = 10; hash_map.insert(key, vec!(1, 2, 3, 4)); let mut vector1 = hash_map.get_mut(&amp;key).unwrap(); let mut remove = false; match vector1[0] { 1 =&gt; { remove = true; } n =&gt; { println!("{:?}", n); } } if remove { hash_map.remove(&amp;10); } } Mostly: how do I use a mutable value from a `hash_map` in order to determine whether or not to remove something from the same `hash_map` ? [edit] I should note the above code does not compile, although I feel like it should.
Who overrides who? So if my `Cargo.toml` has an `lto = false` but I pass `-C lto` to `cargo build --release` will I have lto or not?
Nice! Don't hesitate to ask if you have any questions.
The profiling data was attached to the wrong functions. Empty methods that were never called were reported as substantial portions of the run time, etc. The numbers themselves seemed a bit off but it was hard to really tell.
In reference to why I'd think there'd be submodules - I was kind of assuming that file would be something of a composition root or entrypoint file where all submodules would be connected in one main module? So I expected to find every module used by the API pulled into that file. But again, it could be me totally misunderstanding Rust modules. 
&gt; It's better used for mutability that the caller doesn't need to know about Ideally, I'd agree, but it's hard to hold up this bargain. In particular, `Cell` is not `Sync`, so if you use `Cell` in your data structure, then the caller all of a sudden can't put that data type directly into an `Arc`, which means they could become aware of it. You could add internal synchronization if you want to make your type `Sync`, but now you might be paying a cost that you didn't want to.
Feel free to suggest questions here! Don't feel obligated to do it on the user forum.
I'm not sure they do, actually. Typical biohazard containment assumes that it can't harm anyone if it doesn't touch them (or release particles or gasses that touch them). Radioactive doodoo is dangerous at a distance and through barriers. Unless it's safe to assume that any radiation source that the person survived ingesting long enough to shit out isn't too dangerous externally?
You apparently aren't very well educated on software licenses. 1. The MIT license doesn't give 'individual freedom'. See the following quote from the MIT license: &gt; Permission is hereby granted, free of charge, to any person... Any person means everyone. So, burned. 2. The GPL imposes restrictions on the usage of the software and it's source code. By definition, this is the anti-thesis of freedom. Go pick up a dictionary. &gt; freedom: The condition of being free of restraints. The GPL is not free of restraints, and therefore does not offer freedom. So, double burned.
Cool! Although it seems a little odd to list Imposter Syndrome as a preferred qualification.
Noob question: It seems like you'd want the padding to be more...situational than that? Like in an array, it makes sense to me that an `Option&lt;u32&gt;` needs to be 8 bytes, to get each `u32` 4-byte-aligned. But if I have a structure like this ([playground](https://play.rust-lang.org/?gist=602ec4c693ffb38edf04dc44b2468b05&amp;version=undefined)): struct Foo { a: Option&lt;u32&gt;, b: u8, c: u8, d: u8, } It seems like the we'd want the `Option&lt;u32&gt;` in there to be only 5 bytes? Then with the other three fields in some order, there'd be a way to guarantee that the `u32` buried in there stays 4-byte aligned without wasting space? But instead the size of `Foo` is apparently 12. Are there constraints in other situations that force `Option&lt;u32&gt;` to be 8 bytes all the time? How...does any of this work? :)
So when a company locks down a mit project ? An then lets die it's free counter part, you call that freedom?
They want an employee that thinks they're worth less than the value they actually create... sounds like every other company but they're ahead of the curve in admitting it ;)
Honestly I love the imposter syndrome thing. Many of the smartest people I know have it, and yet huge numbers of people don't even know that it is a common experience. In my experience, people who find out about it for the first time get another small tool for dealing with it. So, hopefully this job posting exposes another [lucky 10,000](https://www.xkcd.com/1053/). Anecdotally it is also directly correlated with kindness and humbleness, so screening for it suggests that they have have a good work environment on a few levels.
I am all for recognizing and de-stigmatizing imposter syndrome. But listing it as a preferred qualification seems icky. It pressures applicants to divulge mental health information.
Huh, I did not even *consider* thinking of it that way. I read it as a "ha ha only serious" joke in line with several of their other qualifications.
Thinking more about it, there may actually be a legal concern here. IANAL, but it's my understanding that in many jurisdictions it is illegal for potential employers to ask about a potential hire's medical history or status. Anyone here who could shed on some light on whether this particular instance is of concern? 
For an interpreter, I usually make separate `run_instruction` functions for each opcode and match on the opcode in `step`. Aside from that, maybe pass the instruction, or parts of the instruction, in by value.
Yeah, agreed. I was also kinda perturbed by the Mickens and @rustevangelism comment. Don't get me wrong; I _love_ Mickens' writings^1. And I _am_ @rustevangelism (among others), and I do think I'm a pretty great guy too, if I do say so myself 游땍 The problem is that this kind of creates an "in the know" sphere, and folks with different backgrounds who may not have encountered these things in the past may be put off from applying because they feel that this job posting that talks about weird stuff they never knew of is not for them. It highly reminds me of "feigning surprise", which is when someone goes "you don't know what X is?" in a voice of mock surprise^2, making folks feel like they're not "part of the club". Like, I get that it's a joke, I snickered too when reading it. I also get the _intent_ of the impostor syndrome comment is to be a positive thing helping shore up people's confidence whilst applying. But I can't help but feel that for some these points folks may get turned away (or cause other problems as mentioned in your comment). Maybe I'm just a bit serious about what should go in a job posting. I'm really fine with humor, I'm just super wary of humor causing misunderstandings that turn people away. ^1: If you don't know who that is, read everything on https://mickens.seas.harvard.edu/wisdom-james-mickens . Budget for a couple hours of uncontrollable laughter. ^2: My preferred alternative is to go "You don't know what X is? It's awesome let me tell you you're going to love this omgomgomgomg" or something along those lines.
&gt; So when a company locks down a mit project? No company has the ability to 'lock down a MIT project'. That's not how it works. What's licensed as MIT will always be MIT -- it will always be open source. No one can suddenly claim ownership of an upstream repository, convert the license to closed source, and wipe the project off the map. &gt; An then lets die it's free counter part, you call that freedom? If a company chooses to create their own closed source fork that relies on parts of MIT source code, that is their prerogative. It has zero effect on us as contributors to the project. The original upstream repository isn't a 'free counterpart' either. Furthermore, there is no incentive for forking a project just to create a 'non-free counterpart'. How could a 'non-free counterpart' hope to compete against the original free project? Fun fact but, chances are that a theoretical closed source fork would be incompatible with the vision of upstream. And if this company wants to retain the ability to stay in sync with upstream, they're going to open source any enhancements that they've made so that they can remove the burden of maintenance from themselves. Otherwise, they'll quickly find themselves in a situation where their version of the project isn't compatible at all, and they'll have to maintain all of the code themselves without our support. For example. Say if someone forked the Redox kernel and then modified it to use as a base for their gaming console. Does this negatively affect the Redox desktop OS? No, why would it? News Flash: A company that wants to create a proprietary platform is going to do so regardless. If Redox was GPL'd, they would just not base their OS on it and choose something else that is permissively licensed. Such as the BSD kernels. Yet because Redox is MIT licensed, that means we've opened doors that were otherwise closed to begin with! Companies that would have had no interest in the project, now might choose to donate and contribute to it. Why do you think gaming consoles aren't based on Linux? Because basing on Linux would force the company to release their trade secrets to their competitors. That is not how you operate a business.
upstream repository, Well said. Companies can outmuscle any efforts from the open project, keep it in sync while keeping their changes and leeching the community work, or complely take the code away, and never see a patch from the company. Companies do not care about community people lifes anything just money, GPL is one of the few ways i can see my code liberating more people. And i dont have consoles, if you would like your game being played on many platforms why lock it on a singles platform and let it rot away when supports stops?.., thats why shit like EA exists why you cant really "own" your PS4, why microsoft was trying so insanely hard to kill linux
&gt; Companies can outmuscle any efforts from the open project, keep it in sync while keeping their changes and leeching the community work, or complely take the code away, and never see a patch from the company. Companies do not care about community people lifes anything just money, GPL is one of the few ways i can see my code liberating more people. Actually, given their track record, this isn't true at all. Most companies struggle so much to keep in sync with GPL / MIT / BSD software that their platforms largely go un-updated and are littered with security vulnerabilities. Companies have been waking up to the fact that it's better if all their system critical components are open source and built on open source platforms. Very few companies can make a business selling software these days. Furthermore, being GPL doesn't prevent a company from taking that GPL'd software and creating a superior fork. Did you not realize that any company can take a GPL codebase, integrate it into their proprietary projects, and not give a single patch back, all the while selling their copy? And I see how well the GPL has protected Linux from being abused by the Android market. Hint hint: not at all. There are ways of circumventing the GPL without violating the GPL if a company truly wants to make use of the software some way or another. Furthermore, even if a company could theoretically create a proprietary Redox-based desktop operating system, the thing you're forgetting here is that the amount of effort that would be required in order to produce a better alternative would not only be ridiculously costly (not financially viable), but entirely infeasible in the market at large (incredibly risky for zero financial gain). Nobody is going to pay for an operating system anymore, and they certainly aren't going to pay for an operating that isn't Windows, nor are they going to pay for something that's free (ahem, Redox). And as a bonus for our project being open source, if a company does make a few proprietary contributions, we can study and reverse engineer their changes to incorporate a better version of their feature in our codebase. We get the better deal in the long term. They waste their money on R&amp;D for us.
Right know i am running lineage OS is better than the full lockedown that ios is bastard bsd. GPLV3 fixes this "Did you not realize that any company can take a GPL codebase, integrate it into their proprietary projects, and not give a single patch back, all the while selling their copy?" 100% wrong if you want to sell a binary copy of a GPL software program, you must include either its complete source code or a written, formal offer valid at least three years to provide it to whoever possesses the binary. In more detail, you have to provide: a copy of the complete sources for a price no more than your reasonable cost of physically delivering them, or "access to copy [the complete sources] from a network server at no charge" Of course, all users of free software enjoy these same freedoms. The people to whom you sold copies of GPL software are just as free as you are to make copies and sell them for whatever price they feel is right, including a price equal to zero. So like all the BSDs, all bsd are dying redox is probably popular because it is riding the rust wave, but have you looked how many comments are on this post? lol, people just upvote they dont really care
I'm on mobile, so I cannot check right now, but what does adding `-v` to the cargo command line say?
I address this issue [here](https://docs.rs/mem_cmp/0.1.3/mem_cmp/#safety). If a library user chooses to do memory comparisons over padded types, they're choosing to do an unsafe operation.
I added info about this issue to the documentation [here](https://docs.rs/mem_cmp/0.1.3/mem_cmp/#safety).
Argh, I always get one of them wrong. I should write a Rust program that parses the markdown, extracts the links and warns me of duplicates... Thank you for noticing.
A couple of comments in no particular order: - we were going for a light-hearted post and hoping to attract kind and humble people as someone else mentioned. If anyone knows of a better way to achieve the same effect, I'd love to hear about it. - Imposter syndrome is not a medical diagnosis according to the APA, and self-doubt is something just about everyone experiences from time to time (I certainly do). - We would *never* ask an applicant for his/her medical status; much less use that to make hiring decisions. It has been very informative to read everyone's comments. Thanks!
The link is fixed now. :)
The code doesn't compile, because hash_map is still borrowed when you try to remove the element. To make it compile, you have to scope out the borrow, so hash_map could be borrowed again. use std::collections::{HashMap}; fn main() { let mut hash_map = HashMap::new(); let key = 10; hash_map.insert(key, vec!(1, 2, 3, 4)); let mut remove = false; { let mut vector1 = hash_map.get_mut(&amp;key).unwrap(); match vector1[0] { 1 =&gt; { remove = true; } n =&gt; { println!("{:?}", n); } } } // The vector1 binding goes out of scope, releasing the borrow if remove { hash_map.remove(&amp;10); } }
Really impressive, indeed.
Now that I think about it, it's a bit weird that I concluded I should avoid that clone, I should test it out again
This is basically the same solution as splitting struct into two parts - one that is mutable, and the other which is meant to be immutable. With you suggestion, I basically drop immutable context in some places, and only get parts that are passed by parameters. For example, if in `run_instruction` I need to access `code` again for some reason, I will have to pass it through parameters. What I would like is like giving compiler a hint - some parts of `self` will never be mutably borrowed, so that I can keep a mutable borrow of `self` together with immutable borrows to those parts of `self`. And it seems that it is possible by putting that part behind an immutable reference. However, this has double indirection, and a bit awkward split in `Interpreter`. https://play.rust-lang.org/?gist=a55b54be2d0bc38cac973aa84616bc76&amp;version=stable
I'm really happy to see Rust jobs starting to appear!
I noticed that you are using hoedown, which is a c-wrapped library. There is already a pure rust implemented markdown renderer such as https://github.com/kivikakk/comrak and https://github.com/google/pulldown-cmark I am using comrak personall for my own project http://ivanceras.github.io/spongedown-editor/
Working on interactive [Spongedown editor](http://ivanceras.github.io/spongedown-editor/). Performance issues is still a problem for many people in [HN](https://news.ycombinator.com/item?id=15083648). I think rendering on the client side might not be a path to take, instead rendering should be done on the server side.
&gt; What I would like is like giving compiler a hint - some parts of self will never be mutably borrowed If you'd like to see a feature like this in the future, voice your usecase at https://github.com/rust-lang/rfcs/issues/1215
Hmm....here I got stuck core.run(loop1.zip(loop2).for_each(|_| ())); ^^^^^^^^ the trait `futures::Future` is not implemented for `()` What does it mean?
Hi, I've been trying to compile titanium but the dependency version of gdk or gtk in my machine is always not met. Requested 'gdk-3.0 &gt;= 3.22' but version of GDK is 3.18.9 I'm using Ubuntu 16. I'm curios what distro are you using the desktop environment?
I personally don't have very much experience with this, but there have been some quite nice ideas passed around in /r/rust_gamedev. I can't offer much general advice on what's best, but I can offer one good strategy I've come across. If you haven't seen it, [this set of slides on game-dev in Scala](http://michaelshaw.io/game_talk/game.html) outlines one person's functional game engine, and design for that. It's obviously not in Rust, but the design would apply very well to rust programs as well if you wanted to adopt it. I don't know if that talk's method is the one you want to choose, but it almost directly answers your question with at least _one_ concrete way of doing it. Hope it helps!
Oh yeah, so `.for_each()` wants the closure to return a `Future` too. Fortunately, it's an easy fix because `Result` works for this: core.run(loop1.zip(loop2).for_each(|_| Ok(()))) ;
So I got this code ([Playground](https://play.rust-lang.org/?gist=5c45f443f0d7040fc8b92e2c426feabb&amp;version=nightly)): fn main() { let input: &amp;str = "ls /home/test"; let (cmd, tgt) = input.split_at(2); match cmd { "ls" =&gt; println!("ls {}", tgt), _ =&gt; println!("something else"), } } After reading [this](http://xion.io/post/code/rust-patterns-ref.html) blog post on `match` patterns, I expected that I'd have to write the `"ls"` match arm as `&amp;"ls"` instead, because [`str::split_at()`](https://doc.rust-lang.org/std/primitive.str.html#method.split_at) returns string slices. Why does `match` work with the "normal" strings here? Edit: Alright, I think I found the answer myself: String literals are already borrowed references to a certain memory location within the compiled binary, so the type of `"ls"` is `&amp;'static str`, right?
Too bad you're in US::CA and this job isn't remote. I would have loved to send you an application.
&gt; ~~libsvg~~ [librsvg](https://github.com/GNOME/librsvg) FTFY ;)
A common problem with fluent APIs is that I forget to call the terminating function. In the case of some builder, it is easy (but annoying) to get the compiler to complain about it by only returning the proper type from the terminating function, but what about the cases where you don't need any new type, ie from a logging interface? In C++ you can then perform the actual work in the destructor of the returned object, but in Rust the drop function is called too late for that. Is there some other clever way?
I've updated my "stuff" :-) to resolve the issue as reported by a user in https://github.com/joerg-krause/rust-cross-libs/issues/6. The issue is, that Rust already provides some targets by default, e.g. armv5te-unknown-linux-gnueabi. To allow using a custom ARMv5TE glibc-based target configuration it's necessary to use a different triple name: armv5te-rcross-linux-gnueabi.
There is this project: https://github.com/tomaka/android-rs-glue If you want to support development, /u/tomaka has a [patreon page](https://www.patreon.com/tomaka).
At least it's not 'F' :-/ 
anyone got oauth with google plus or facebook running on rocket? need example
A common thing to do in e.g. C# (also other languages) is have iterator transforming functions with signatures like `IEnumerable&lt;U&gt; Foo&lt;T, U&gt;(IEnumerable&lt;T&gt;)`. This seems to currently be quite painful in Rust because you can't write the return type without leaking way too much info about the implementation of `Foo`. AIUI this will get better if `impl Trait` ever stabilises, but until then I'll probably keep running into it. I'm sure I'm not the only one, so a workaround in the FAQ would probably be useful :-)
I am in the middle of deciding what project should I go with... How do you people have time for side projects?...
Some questions I have asked myself (or this reddit :D) in my Rust experience. Not sure all of them are relevant to the FAQ, but maybe some are? Cargo: * Can cargo be used for applications, not libraries? (Yes, there is cargo install, and it can be useful to publish your app on crates.io, at least I think so) * Can cargo include non-code resources? (I don't think there is currently a way to do that, at least there wasn't last time I checked. The best workaround is to include them in the binary if you can) Multiplatform: * Is there an easy way to make binaries for my Rust app for major OSes? (https://github.com/japaric/trust) Rust for non-english speakers/programs: * How can I handle internationalisation in Rust? (Currently, not great answer for that, but I think it could be nice to acknowledge it in the FAQ) * Is there Rust resources available in xxx language? (would be nice to point to some underway translations, or maybe if there are places that centralize Rust resources in other languages? Acknowledge that there are currently some lacks in that regard but invite people to contribute) Nightly/Rust features: * Unstable feature XXX looks nice, when can I hope to see it in stable? * Some Rustup questions? Also, I suppose it's already planned in the update, but some questions about the `?` operator would be nice (I guess the error handling part was written before it existed).
I see... now it works :) And of course I did not understand all I'd like :( E.g. how to run those loops in combination with let's say a http server? let addr = "127.0.0.1:3000".parse().unwrap(); let listener = TcpListener::bind(&amp;addr, &amp;handle).unwrap(); let http = Http::new(); let server = listener.incoming().for_each(move |(sock, addr)|{ let s = MainService; http.bind_connection(&amp;handle, sock, addr, s); Ok(()) }); let handle = core.handle(); handle.spawn(server.map_err(|_|())); core.run(loop1.merge(loop2).for_each(|_| Ok(()))).unwrap(); Now `loop1` and `loop2` are running as expected but a HTTP-Request has no chance to get processed :( Why? And how can I tell the event loop that it can poll a loop only once a second? **edit**: I could manage the poll with `tokio_time`: let timer1 = Timer::default(); let timer2 = Timer::default(); let duration1 = std::time::Duration::new(1, 0); let duration2 = std::time::Duration::new(3, 0); let interval1 = timer1.interval(duration1); let interval2 = timer2.interval(duration2); let x1 = interval1.for_each(|_|{ println!("hello from interval 1"); Ok(()) }).map_err(|_|()); let x2 = interval2.for_each(|_|{ println!("hello from interval 2"); Ok(()) }).map_err(|_|()); let x = x.join(server);
yes
correct: if you write a test function such as fn foo() { match () { "ls" =&gt; {}, _ =&gt; {}, } } then you'll get an error clarifying that `()` doesn't match `&amp;'static str`, thus explaining the type of `"ls"`. I find `()` pretty useful for type experiments like this when something's unclear.
Right, so I just noticed that I linked to the thread on /r/firefox instead of linking directly to the newsletter, how I managed that I do not know but there you have it. It's been 2 hours and this is the top post on /r/rust so I'm just going to leave it and not bother resubmitting it.
`xml5ever` author here. While xml5ever could do theoretically do it, the second request probably isn't done by any XML parser that I know of. XML parsers generally don't store non-significant whitespaces. Storing such info takes valuable space and processor time.
Oh, that's nifty, thanks! The one thing I'm consistenly missing from my current Vim-RLS setup is type introspection, so this is going to be very useful.
[This old post](https://blogs.gnome.org/mclasen/2014/05/06/tweaking-a-the-gtk-theme-using-css/) (2014) by one of the GTK+ maintainers has useful information on how to tweak a theme and may be what you're looking for. Also, since 2014 the CSS support in GTK+ and "parasite" (inspector) has improved a lot. 
Me too, I just wish there were more remote Rust jobs..
They don't call it unicode for nothing.
&gt; What I'm wondering is, can you do anything at all with *foo other than immediately dereference it again? Nothing comes to mind that wouldn't be possible without dereferencing. You could write `(*foo).some_method()` but `foo.some_method()` should work, too. It may be useful if you as a programmer want to make it obvious to whoever reads the code that `foo` is in fact a reference. &gt; is &amp;Foo actually a reference type, that we can do normal reference-type stuff with? Yes. Similar to how `Box&lt;Foo&gt;`, `Rc&lt;Foo&gt;` and `Arc&lt;Foo&gt;` are kinds of boxes. &gt; Is Foo as a type, rather than a trait, something we can work with? It is both a type and a trait depending on the context. However, there's an [RFC](https://github.com/rust-lang/rfcs/pull/2113) that wants to end this confusion. Currently, in the context of where a type is expected, the name of a trait can be used as an unsized type. 
That's what I'm waiting for, too. It'll happen eventually, if not soon.
That should work providing you *haven't* put a `mod goo {...}` block in `goo/mod.rs`. The file itself already creates a boundary, adding that block would create another namespace inside it, e.g.: //main.rs mod goo; use goo::Alex; use goo::car::Brent; fn thingy(a : Alex) -&gt; Brent { unimplemented!(); } and //goo/mod.rs (or equivalently just goo.rs) pub struct Alex {} mod car { pub struct Brent {} } 
Be sure not to miss the fascinating counterblast from Alex Crichton about how [monomorphisation is bad actually](https://github.com/rust-lang/rfcs/pull/2113#issuecomment-323223369). Okay, i'm exaggerating slightly, but this is a perspective i hadn't heard before, and i think is worth thinking about. 
Another example is that you can replace that last file with: //goo/mod.rs pub struct Alex {} mod car; plus the separate file //goo/car.rs pub struct Brent {} Note that the `mod car {}` block isn't written anymore; the `goo/car.rs` file is _itself_ the submodule boundary!
I use ArchLinux which has the most recent versions. Is it `titanium` or `titanium-web-extension` that you cannot compile? I'll try to compile on this version of Ubuntu, but I use fairly recent APIs, so that might not work yet.
Specifically, it searches downward based on the `mod` statements given in the root file (`main.rs` or `lib.rs`); it doesn't search every last file for `mod` statements. :-) 
The problem is references, what happens if you take a reference to `Foo.a`? At that point the "contextual" information about how the option is encoded in the struct is lost. This is a huge bummer since options tend to cause very inefficient representations for anything non trivial. Perhaps an attribute of some sort to indicate that it's invalid to take a reference to this member could help (except then you can't actually call any methods on that type accepting `&amp;self`...)
You can use that trick when e.g. you're not sure exactly what type some complex expression is trying to become. `let foo : () = some().complex().expression();` Now the compiler error will tell you what sort of wacky `&amp;'a mut Foo&lt;Bar&lt;'a, Baz&gt;, Qux&lt;Option&lt;Crunch&gt;, Baz&gt;&gt;` it couldn't match with `()` ;-) EDIT: similarly if you write `let foo : Vec&lt;()&gt; = some_sort_of_vec_just_not_sure_what();` then the error message should actually narrow down to just the part it couldn't match, i.e. the `Vec` type parameter
Thanks for the fix, although it feels sortof hacky. Is there a cleaner way to be doing something like this? I feel like I'm not structuring my code in a rust-like manner if I have to be scoping things like that.
I save you one click: https://mozillagfx.wordpress.com/2017/08/21/webrender-newsletter-2/
&gt; I could get the same 'works out of the box' experience (well, excluding debugging I guess) for a Rust NDK library that a C++ NDK library gets? There is example flying around, several lines of groovy code from here: https://github.com/Dushistov/rust_swig/blob/master/android-example/app/build.gradle and you can build and run your android+java+rust in the same way as ordinary only java android project. Just press build or run and that's all. Also you can install rust plugin for android studio and work with java and rust in the same IDE. The only tricky part that you need crate standalone toolchain from ndk compiler to get working linker. But for this you can detailed instruction from article about building servo for android.
Could we get away with a rule like "Option&lt;T&gt; is always T followed by one flag byte"? Then structs would be free to do something efficient, but arrays and vecs would have to be smart enough to insert padding bytes, and to account for them in the indexing operation. Is that asking too much of arrays and vecs?
You could put the immutable parts behind an Arc? Then the compiler would gladly let you clone the Arc, even while the whole struct is mutably borrowed.
Here https://github.com/nikomatsakis/nll-rfc/blob/master/0000-nonlexical-lifetimes.md nice summary of problems of lexical lifetimes and how it is possible to solve them.
It makes way more sense to look at them both together. For example considering dropping extern crate in favour of use extern::foo or similar formulation.
I was trying to compile `titanium`. Compiling `titanium-web-extension` works out just fine after installing some dev dependencies on my machine.
I'm not really experienced enough in programming for that to be helpful ;)
What's the story behind the name "Rain of Rust"? At first i thought it might be a reference to [one of the best bad movies ever made](https://en.wikipedia.org/wiki/Reign_of_Fire_(film\)), but then i realised that it was started in India, and a month-long event starting in late May roughly aligns with the start of the [monsoon season](https://en.wikipedia.org/wiki/Monsoon_of_South_Asia) there. 
Comment on the paper, after having just read the first page: it uses the acronym "DRF" without defining it. I had to Google to figure out to expand it to "data race free".
Hey I did the exact same thing (though probably much less in depth on my website (which is down right now)
You're looking for /r/playrust.
Install and run clippy before all: `cargo +nightly install clippy &amp;&amp; cargo +nightly clippy` 
What do you mean "internationalisation in Rust"? If you write GUI, then I suppose Qt / gtk+ has it own mechanizm for internationalisation, so if you use Qt / gtk+ you should use standard techinique that provide GUI library. If you write console/server application then you can use `gettext`. Of course I mean rust wrapper around qt, gtk+, gettext. &gt; Can cargo include non-code resources? (I don't think there is currently a way to do that, Why not `std::include_bytes!` and `build.rs`?
Yes, that's why this RFC assumes that RFC is accepted. It's still a separate RFC.
Ah yeah, that file isn't a root; since `Cargo.toml` has no `[lib]` section, that means that `src/lib.rs` is the entry point, and you will find many modules there: https://github.com/SergioBenitez/Rocket/blob/master/lib/src/lib.rs#L122-L138
There was a major overhaul of the compiler error messages last year, to make them easier to read: https://github.com/rust-lang/rust/pull/32756#issuecomment-206042850 Also, not a language change, but the official Rust book is being rewritten entirely: https://doc.rust-lang.org/book/second-edition/
I had not considered the binary size impact. For some reason I assumed if the Debug feature wasn't used in that program then it would be dropped from compilation. But this can't be true for libraries since usage is not defined. Thanks for your input!
There was a recent article about VS Code on windows here, https://fungos.github.io/blog/2017/08/12/setting-up-a-rust-environment-on-windows/ 
You could give your intermediate type the `#[must_use]` attribute, so that callers will get a warning if they drop it on the ground. The `Result` type has this annotation, so that we don't forget to handle errors. I used it in [my `duct` library's builders](https://github.com/oconnor663/duct.rs/) also. &gt; in Rust the drop function is called too late for that I'm not sure what you mean here. If you create a temporary value as part of a statement, that value gets dropped at the end of the statement. Here's an example, where you can see that the printed lines come out in the right order, because drop happens quickly (it also demos `#[must_use]`): https://play.rust-lang.org/?gist=b5900992937b81fea5874d45ec684680&amp;version=stable
This sort of hack is considered the Right Rusty Thing To Do for now, but there's a *ton* of work and discussion going on with "nonlexical lifetimes" to fix these annoying issues: https://github.com/rust-lang/rfcs/pull/2094 The short version is that, when it comes to types with destructors (types that implement `Drop`, like `Vec` or `Arc`), the compiler isn't allowed to monkey around with where those destructors get called (usually at the end of the function), because they have side effects, and the order of side effects is important. But plain references don't have destructors, and the compiler's perfectly within its rights to decide that your `vector1` reference gets "dropped" after the match is done, making your original code legal. The compiler is going to get the smarts to do that, but it's taken a long time to figure out all the corner cases that come up (loops, reborrows, other wacky stuff).
Good to know. Thanks!
shorter version of the trick: let () = some().complex().expression(); 
I think tomaka/android-rs-glue is probably the most advanced toolchain for Rust on Android. There are a couple other projects that demonstrate Android and iOS as well. It would be nice to expand the tools that tomaka built to iOS. https://github.com/kennytm/rust-ios-android https://github.com/Geal/rust_on_mobile On a side note: Why do people insist on going the JNI route for FFI? JNA works on Android and is so much simpler to use. 
Also some relevant discussion here : https://www.reddit.com/r/rust/comments/67qlsj/has_anyone_developed_an_app_for_both_ios_and/
it's Copy, it's just a value, don't need to think of it as being consumed
I'll mention the Rust Language Ergonomics Initiative in addition to the other things that have been linked: https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html and the related rfcs: https://github.com/rust-lang/rfcs/pulls?q=is%3Apr+is%3Aopen+label%3A%22Ergonomics+Initiative%22
I have been working on this for over a year now. CurrySearch is based on [perlin](https://github.com/CurrySoftware/perlin) which is a free and open-source information retrieval library. It has been a pleasure working with rust. Thanks to all people involved for creating such a great language.
&gt; In C++ you can then perform the actual work in the destructor of the returned object, but in Rust the drop function is called too late for that. Is there some other clever way? Can you expand on this? You can do work in drop in Rust, and it's useful for working around lifetimes sometimes. See [`Vec::splice`](https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html#method.splice), which does the splicing in `drop()` so that it can also return the data which is going to be removed. You can control when things are dropped by calling `drop()` manually or by using blocks `{ }`.
That's a bit surprising... what would that do if it were to compile?
Ahh. I'm not aware of the differences between `lib.rs` and `main.rs`. Another thing to look into. Thanks!
I (finally) published my [first crate](https://crates.io/crates/itchy)! It's a parser for the NASDAQ ITCH protocol. OK, pretty obscure, but it was fun to make and I wanted to try out going through the whole process of testing, packaging, uploading etc (it was seamless, of course). I'm actually amazed how fast it turned out to be, it chews through 7M messages per second on my not-powerful laptop. All hail [nom](https://github.com/geal/nom)!
It sounds like this is a professional project, and you've been working on it for over a year now, you say. - How/why did your company choose to use Rust? - What have been the main benefits and drawbacks of using Rust? I'm a huge proponent of Rust, and this kind of information is very useful.
By convention, `lib.rs` is the entry point to a library crate, and `main.rs` is the entry point into a binary crate. They can be configured to something else in the `Cargo.toml`.
&gt; Why do people insist on going the JNI route for FFI? here short summary of existing techonologies to bind java and rust, including jni and jna https://stackoverflow.com/questions/38118501/how-to-automate-java-bindings-for-rust-code
`let` uses pattern matching to determine bindings. In this case, it matches the expression against an empty tuple. In both of our examples, this will compile if the type is `()`; the only difference is that you will have a `foo` of type `()` in scope, and I will not.
Or just remotely close to where I live...
I'm currently reading the second edition Rust book and it has been very easy to follow with clear code examples.
Is it possible to have custom crates.io mirror? Use case: host project dependency crates in-house in case e.g. crates.io is down which would prevent clean build. Similarly as e.g. Yocto allows pre-fetch mirrors.
The choice of language was based on the premise, that garbage collection is poison for large multi-tenant search systems. Most of these systems use elasticsearch, which itself is based on lucene, which is Java and thus garbage collected. Many blogposts circle around the topic of how to scale such systems. Back then, I was using D privately and C# professionaly. Both garbage collected. From my little experience with C++ I knew how hard manual memory management is. So I tried Rust and it felt like handmade for the task. Rusts main benefit for the use in CurrySearch is definitely the way it handles resource management. It entails predictably good performance and power over details. Alas, I had quite of a struggle when starting with Rust because important aspects of metaprogramming are not currently in the language. In D, for example you have compile-time reflection. Combine this with compile-time programming and templates and you can create wonderfully simple and abstract interfaces for complex libraries. In rust when you try to go too abstract it starts to feel painful. Macros 1.1 helped a little bit but in my opinion they are still very unstatisfying.
I think the problem (as hinted at in the assembly I linked, AIUI) is that enums have to put the tag first, which then in turn implies that e.g. you can't have `struct { Option&lt;u16&gt;, u8 }` have a different tag size than `[Option&lt;u16&gt;; 2]`, because if I handed you the `Option&lt;u16&gt;` from the front of that, where does the tag end? EDIT: Although I can't immediately think of a reason that the tag can't be after the value, since you statically know the length of the enum. Maybe it's something to do with different alignments of the same value. 
You should read the 2017 roadmap, usability is an entire category that is being tracked.
This is the third major text search project in Rust. As far as I know.
Thanks for all that! I would love to see CTFE on Stable Rust, and Macros 2.0 should help a lot with the macro situation, but we'll see. Does Curry Software have a business model/business plan? "Consulting" seems to be the main answer the website gives, but I don't think that consulting work would have paid to have an open source search system built, so I'm just trying to understand how all of this fits together.
What are the other two? I only know about [tantivy](https://github.com/tantivy-search/tantivy).
CurrySearch is going to have paid plans in future releases. This is planned to be the main source of income. On the german market there is currently a void for cheap SaaS On-Site Search Systems. CurrySearch is not open source by the way. Only its basis (perlin) is. About 20% of the code is in CurrySearch. If you are interested in the actual businessplan (in german) I can send it to you via E-Mail.
https://github.com/kaedroho/rusticsearch 
I am aware. I haven't tried comrak yet, but pulldown doesn't support as much syntax as hoedown.
CurrySearch is 80% Perlin and 20% closed source "management code". That includes the HTTP API, the process of distributing tenants on servers, logging, statistics, fallback strategies etc.
It's also pretty trivial to construct a new one wrapping the existing one with `format_args!("{}", existing_args)` or `write!(out, "{}", existing_args)` - this is what I do in [fern](https://crates.io/crates/fern/) for allocation-free formatting.
You can just build the lib with cargo, copy it with cmake. And use [javacpp](https://github.com/bytedeco/javacpp) to autogenerate JNI bindings. https://github.com/myfreeweb/freepass/blob/861dce124353e51908d8bd98b2b7c64e16822eb9/android/app/CMakeLists.txt
This is tied to wordpress? Do you think it would be hard to move it to trac?
Yeah, it's short, to the point and a good reminder that Rust doesn't absolve us of working diligently to ensure correctness.
Ah, the tuple in yours is the analogue of e.g. the tuple of identifiers in `let (foo, bar) = get_pair();`. That makes more sense, I thought it was trying to rebind the symbol `()` or something bizarre....
You could probably expand these a bit into answers for the new FAQs then :-P
The underlying api is simple. If someone wanted to write a plugin for any other system it should be a manageable amount of work. But keep in mind, that the current API is not yet stable (and not officially released) and in future releases paid plans will appear. CurrySoftware cannot develop and maintain a plugin for every cms, but I could imagine partnerships: Someone builds and maintains a plugin for a system and gets 30% of the revenue. If you would be willing to develop a plugin for trac let me know. 
I, for one, love to see job postings by real people having fun. Even if I disagree with the content (in this case I don't), as a job hunter it's nice to know that I won't be working with a bunch of automatons in a soulless machine. 
How do you use `bindgen` on stable Rust?
The terminology is explained [further up in the RFC](https://github.com/rust-lang/rfcs/blob/master/text/1951-expand-impl-trait.md#scoping-for-lifetime-and-type-parameters). If a type parameter is "in scope", the return type can depend on it.
&gt; If you write GUI, then I suppose Qt / gtk+ has it own mechanizm for internationalisation I don't know for Qt and It's been a while since I didn't program for Gtk+ but I think it used gettext too. &gt; If you write console/server application then you can use gettext Meh. I mean, yeah, there are gettext bindings (though I don't know if the gettext tools to extract strings from source code files work for Rust code), if you're OK having to deal with printf-style "%d" mixed with your rusty "{}" formats; plus it's only check at runtime and Rust can do better than that. (I ended doing a macro-heavy hack for my project, not sure if there are other translated apps, I wrote an article at the time there http://lise-henry.github.io/articles/localization.html). Plus I think (not sure though) gettext requires reading the files at runtime, which is connected to the other "question" you quoted :) so well, not sure it's the best suited solution for Rust. To take another example of intl than translating, the `Char` documentation mentions that `to_uppercase` isn't language dependent but leaves you wondering how to find a `to_uppercase` that works with your language; there's the same problem for sorting strings (they won't be sorted the same way in all languages, and while I remember seeing the warning "sorting strings is more complex since it depends on the language" I don't remember seeing a pointer to how to do it this way). (Maybe there are some libs/bindings for that, I'm not sure, I know at least some people wanted to work on this subject.) &gt; Why not std::include_bytes! and build.rs? This is why I meant by including it in the binary, which works for many usages, but I don't think there is a way to say to Cargo "this file is not code but it should go somewhere there so the program can use it". I mean, it makes sense somehow, while there is a way to `cargo install` programs it's not a replacement for .deb or .rpm or whatever, but naively I thought there was an option for that.
Completion-based futures can be created with [oneshot channels](https://docs.rs/futures/0.1.15/futures/sync/oneshot/fn.channel.html).
Interesting, I'll see what I can do with it Edit: I don't seem to be able to integrate them properly with Javascript. I'm going to stick with callbacks... Edit 2: After tearing my hair out trying to use callbacks, I figured out how to pass move closures that can send on the channel between JS and Rust. fn do_it_caller&lt;F: FnOnce()&gt;(f: *mut F) { unsafe { Box::from_raw(f)() } } fn do_it&lt;F: FnOnce()&gt;(f: F) { let f = Box::into_raw(Box::new(f)) as i32; let f_caller = do_it_caller::&lt;F&gt; as *const libc::c_void; js! { (f, f_caller) b"\ Runtime.dynCall('vi', $1, [$0]);\ \0"}; } fn main() { use futures::sync::oneshot; use futures::*; init(); let (c, p) = oneshot::channel(); do_it(|| c.send(1).unwrap()); p.map(|i| { println!("got: {}", i); }).wait(); } Thanks for the help
To preview documentation, you can run `cargo doc` locally.
&gt; I don't know for Qt Qt has its own translation stack from `tr` function to get translation string to qtlinguist GUI tool for translator. I'm also worked long time ago with `gtk+`, and I thought they moved to something else from `gettext`. But looks like nothing has changed since then. &gt; if you're OK having to deal with printf-style "%d" mixed with your rusty "{}" formats `gettext` supports many programming language, and their format technique as well, so I suppose this is the problem with `gettext` rust binding, not with `gettext` by itself, if `gettext-rs` not allow to deal with `format!` like strings. &gt; This is why I meant by including it in the binary As I understand `cargo` is tool to build rust code, and that is all. `cargo install` exists to install tools for developing with rust, not for real deploy. I doubt that even if you or somebody else implement functionality to build rpm/deb/apk/setup.exe then such functionality would be included into `cargo`. &gt; I wrote an article at the time thanks
Hi, thanks, I'm already using it! I meant things like properties set in Cargo.toml - license, repository etc.
I've thought that you can only use procedural macros for custom derives for now. When did the extended functionality arrive?
This looks great. Can it handle tests with multiple parameters? I guess I can just bundle all of them into a tuple and use that.
There aren't any features of bindgen that require nightly as far as I can tell. You either [use it in build.rs](https://rust-lang-nursery.github.io/rust-bindgen/library-usage.html) or [as a command-line utility](https://rust-lang-nursery.github.io/rust-bindgen/command-line-usage.html). Is there a specific problem that you had?
It was in nightly for a long time - it's just not stable yet.
Oh, so this crate is nightly only.
&gt; Why can뗪 we mark these scripts and execute them all at the end, after the parsing is done? This is because of an old, ill-thought out Document API function called document.write(). This function is a pain point for many developers who work on browsers, as it is a real headache implementing it well enough, while working around the many idiosyncrasies which surround it. Are there any stats to determine whether `document.write` is actually used in practice, on modern high-traffic sites that actually demand performance? If not, perhaps an implementation could act as though the function doesn't exist, and then, once the page is parsed and you've gotten into Javascript, you could bail out and re-do the page if `document.write` is encountered. It would penalize pages for using it, but if no pages actually use it then that may not be a problem, especially if it's a huge win for every other page on the web.
(Somewhat unrelated) Would it be okay if I PM'd you? It is not at all about Rust syntactic/learning Rust type stuff.
Any crate that tells you do add `#![feature(...)]` is nightly only.
I'm one of the lucky 10,000 today. The link was great. I've felt it most of my life.
This is a pretty sweet project. I'm just checking out your earlier commits now. It's cool to see the project start from scratch and evolve in such a short period of time.
Sure thing; I probably won't get back to you until tomorrow though.
That sounds like what they do. They just keep parsing while spinning off the javascript, and if the javascript calls document.write, then they can cancel the speculative thread.
we put off implementing document.write for so long and IIRC it was necessary for some _major_ JS heavy sites, including google docs.
Thanks! It has certainly been a very fun and challenging experience so far. I think I'm currently about 5% of the way through the overall product. I'm still pretty invested in making it a proper emulator. I'd like to _not_ be one of those emulators that sits on GitHub that is half-finished. I'm glad you've found it interesting :)
This is what I get for making a comment before reading the entire post (...and also getting distracted by YouTube videos after making the comment and forgetting to read the rest of the post...). :P
lazy_static lets you do it as a global, if thats the sort of thing you're after.
Wow really jealous of this. Come to Seattle!
Sounds like it might be worth adding an opt-out. Perhaps as an attribute on the script tag, like the async attribute. If 'nodocwrite=true', then document.write throws...
I see a couple of problems. I believe the initial error is raised because Rust cannot determine if all the lifetimes in the signature of `collect_groups_recursive` are the same. This fixes the first error: ``` groups: &amp;'a mut HashSet&lt;&amp;'a FixGroup&gt; // additional 'a lifetime on FixGroup ``` The next big problem (which will eventually crop up as you resolve other errors) is that the signature of `collect_groups_recursive` ties the lifetime of the input iterator to the values it emits - this falls over as rust determines that the iterator is dropped before those values. The fix is to add another lifetime parameter `'iter` for the boxed iterator: ``` fn collect_groups_recursive&lt;'iter, 'a, T: FixComposite&gt;( source: &amp;'iter mut Iterator&lt;Item=&amp;'a T&gt;, groups: &amp;'a mut HashSet&lt;&amp;'a FixGroup&gt; ) -&gt; () { ... } ``` This allows the iterator's lifetime to be shorter than the values it iterates over. There are a few other issues with this snippet you will need to resolve - (missing trait implementation, need to call `.iter()` on `messages`), but hopefully this will get you moving in the right direction. **Edit:** Another possibility for the signature of `collect_groups_recursive` is to just omit the lifetime declarations for `source` and `groups` - You only need to tell rust about the lifetime of the data: ``` fn collect_groups_recursive&lt;'a, T: FixComposite&gt;( source: &amp;mut Iterator&lt;Item=&amp;'a T&gt;, groups: &amp;mut HashSet&lt;&amp;'a FixGroup&gt; ) -&gt; () ```
/r/playrust
These are good points. I too would like to see crates link to changelogs.
Ok that's 5 months later but I just finished adding themes to Gutenberg. Still as a PR: https://github.com/Keats/gutenberg/pull/114 but it's fairly stable. I've only made one theme so far: https://github.com/Keats/hyde You can overwrite any of the file of a theme or extend them and just replace the content of Tera `block`s.
...and if not, perhaps some kind of `console` message indicating that the page is being parsed in the slow, legacy mode and to add `nodocwrite=true` if `document.write` isn't being used... possibly with a link to docs explaining the problem and teaching the alternative. Heck, if every browser did that, I suspect that the combination of education (for those who don't know any better) and peer pressure (calling it "slow" and "legacy" every time the page loads with the console open) should help to provide a strong encouragement to retire `document.write`.
there is a Seattle Meetup, listed in this week in rust 
Might I recommend [Keep a Changelog](http://keepachangelog.com/en/1.0.0/) as a de facto standard to follow? See an example in [Shio](https://github.com/mehcode/shio-rs/blob/master/CHANGELOG.md).
Wow, that article is brilliant! I've never considered having an Unreleased section but now I might. Thank you!
I want to create Ranges on new types and I have two main points that are confusing me. First: I get error[E0277]: the trait bound `for&lt;'a&gt; &amp;'a main::NewType: std::ops::Add` is not satisfied. I've tried implementing `std::ops::Add`, but I don't understand what the `for&lt;'a&gt; &amp;'a` is about and my Google foo isn't yielding any explanations. error[E0277]: the trait bound `for&lt;'a&gt; &amp;'a main::NewType: std::ops::Add` is not satisfied --&gt; src/main.rs:106:5 | 106 | / for i in a..b { 107 | | println!("{:?}", i); 108 | | } | |_____^ no implementation for `&amp;'a main::NewType + &amp;'a main::NewType` | = help: the trait `for&lt;'a&gt; std::ops::Add` is not implemented for `&amp;'a main::NewType` = note: required because of the requirements on the impl of `std::iter::Iterator` for `std::ops::Range&lt;main::NewType&gt;` Second: I get error[E0277]: the trait bound `main::NewType: std::iter::Step` is not satisfied. But this is marked nightly-only and so generates "error: use of unstable library feature 'step_trait': ..." when I try to implement it. Yet I can use other Ranges (e.g. just doing `1..5`) that also must've implemented this trait, right? How come those are allowed? Does this mean Ranges, outside of those that come built-in, can't be used in stable Rust yet? The code I'm using is: #[derive(Debug, PartialEq, Eq, PartialOrd, Ord)] struct NewType(u32); impl std::ops::Add for NewType { type Output = NewType; fn add(self, other: NewType) -&gt; NewType { NewType(self.0 + other.0) } } impl std::iter::Step for NewType { // ... } let a = NewType(10); let b = NewType(20); for i in a..b { println!("{:?}", i); } 
Isn't `async` such an opt-out?
Is Perlin similar to Tantivy/Lucene in that it's an inverted index? Or does it use a different method.
The std and core libraries are compiled using nightly rustc, and they use tons of nightly features.
Perfect! It's working! Seems so obvious after someone points out the problems :-) Love this language! Thanks!
Async is too broad. There are other aspects of what it does which I've seen breaking scripts that have no `document.write`.
Big +1 on this from me. I use GitHub's releases page instead of a CHANGELOG.md file in the repository, but in either form, detailed release notes for every tagged release are one of the most important forms of documentation a project can have.
Yes, you can and you don't need a tuple. Sample from documentation: #[test_case(None, None =&gt; 0 :: "treats none as 0")] #[test_case(Some(2), Some(3) =&gt; 5)] #[test_case(Some(2 + 3), Some(4) =&gt; 2 + 3 + 4)] fn fancy_addition(x: Option&lt;i8&gt;, y: Option&lt;i8&gt;) -&gt; i8 { x.unwrap_or(0) + y.unwrap_or(0) } 
And we have 8 different web frameworks. Duplication of work seems to be happening a lot more in Rust than any other language I'm familiar with. Any idea why this might be?
I think we can do a bit better than plain `CHANGELOG.md`. I've commented my ideas in the relevant cargo [issue](https://github.com/rust-lang/cargo/issues/2188#issuecomment-321607758). Also one year ago we had a similar [thread](https://www.reddit.com/r/rust/comments/3v1ndl/rustaceans_please_keep_a_changelog/).
I like this approach in general. There's so much nonsense in the CSS spec as well. I hope I don't have to pay for it just because the possibility to use it exists.
Cool! I might try playing around with it this weekend :)
sorry ,it is from a Chinese pinyin input. I saw it good in my phone. 
Unfortunately arrays are at the moment kind of a second class citizen in Rust. They are hard to initialize, because they must be initialized in one go (containing uninitialized slots would be unsound). Some better APIs for initializing them will be available in the future once we will have const generics. If you don't mind using unsafe code, having an array of unions would be one possibility. I'd imagine that you could even transmute the array of unions into a normal array, once it would be initialized. (Sounds like a easy way to shoot yourself in the foot, though.)
 #[must_use] is perfect for that, I had read about it before but forgotten about it. Thanks! I thought the type's lifetime was until the end of the scope, just like it would have been if it had been bound to an unused variable. Then drop works really well.
I thought the returned type's lifetime was until the end of the scope, like it is if you bind the value. I see know my assumption was wrong. Thanks!
You might try the Option&lt;Rc&gt; first, it'll likely have smaller overhead than you think. There's no space overhead (None is just NULL from C here) and if you want to initialize on the value's first use, you need the condition anyway.
I know, it's actually what I was waiting for before trying Rust again, I also think it's awesome that this is an actual feature to be added into the roadmap rather then just something talked about, by adding it as a feature it's making the commitment more concrete. The reason I'm asking this question was that I wanted to know exactly how much had been done to make rust easier to use. That way I had something a bit more quantifiable to use to make my decision of when to start learning it again. Plus I thought it was be interesting to others as well to have all usability improvements (or as many as can be found) in one place.
You have never worked with JavaScript, clearly. Duplication is fine and healthy for the ecosystem (within reason). I don't agree that Rust suffers from overduplication any more than any other language. 
&gt; Some projects, like Serde, use GitHub's releases feature, as seen here. This is a good alternative to a single change log file. Nooooo! Changelogs are an integral part of a repository and should not rely upon some third-party website. The Github feature should only be used as a place to put a copy of the authoritative release notes, side-by-side with the binary/source archives. Please put your changelogs in the repo people!
Nevermind, I just saw it's a debug log and not a panic. I need extra coffe.
Because the ecosystem is inmature and API design and idioms are still being iterated a lot yet, amongst other reasons. Also because people enjoy writing in Rust ;)
Nit: Your website has a typo: "CurrySearch is a could-based On-Site Search"
What's up with that explosion-backed subreddit image?
I haven't used futures in Rust. I had assumed that [.then](https://docs.rs/futures/0.1.15/futures/future/trait.Future.html#method.then) worked like [its JavaScript namesake](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/then), and ran the attached closure on the completing thread, at the moment of completion. Is that not the case? Does it instead run on the waiting thread? If so, it's kind of useless. 
don't be stuck up, a little bit of humour makes the community better. nobody likes a humourless envrionment. it actually helps bond the community. if you don't like it, create a rival sub, see how many people use it.
As an aside, we do have /r/rustjerk for those that want ALL THE MEMES.
I wouldn't say /r/golang is any more of a streamlined and formal subreddit than /r/rust, considering that at the moment, the top 5 posts of all time in /r/golang are in fact, all memes.
thanks!
I fundamentally disagree with making the subreddit any more regimented. I believe the content of the sub is more than sufficient for new visitors to orient themselves and the current sidebar already enforces quite a lot of (very sensible) rules, compared to most places. Introducing some levity via the css and general presentation makes it a much more inviting, amusing and informal place to regularly visit and the occasional innocent in joke (The occasional joke rule in the side bar, etc) makes the place feel like an existing community rather than a sterile notice board. The official site and internals forums are official platforms. This place has always had more of an enthusiast's community vibe to it (not that the official channels are particularly stuffy)
Perlin uses inverted indizes with posting lists as well. It tries to model everything as posting lists. Not only term-document relations but also taxonomies, metadata etc. [perlin-core](https://github.com/CurrySoftware/perlin-core) is just an abstraction over inverted indizes. perlin tries to be a bit more... allowing language and query processing, multiple fields, taxonomies etc. Alas, perlin is currently not documented... I hope that someday I find the time to do that.
I have been (perhaps somewhat obsessively :P) browsing this subreddit since 1.0. There is informal stuff occasionally (and memes... memes!) but for important stuff, it's pretty formal. With posts regarding things like a new release or a new feature or whatever, the discussion is formal and often in-depth. I mean if you're gonna compare this subreddit to the ones you mention... /r/rust comes out looking pretty good.
Even just some simple examples would be good to get a start. I had a quick look at the source and got a bit lost. With libraries like tantivy they have a [quick snippet](https://fulmicoton.com/tantivy-examples/simple_search.html) to get you up and running.
Im not sure what your going for but this might help. If you don't want to overhead of having to init every instance if its not used then perhaps you could use a HashMap&lt;(Int,Int),Rc&lt;Value&gt;&gt; if you first get the overall size , and then want to generate all instances. The overhead for Vec&lt;Vec&lt;Rc&lt;Value&gt;&gt;&gt; is incomprehensibly low, especially if you can use Vec::with_capacity(x) . ( Posting this post will likely use magnitudes more cycles then your code ever will ) Probably the most important thing worth considering is that you could drop the Rc and simply pass along a copy of the index and a reference to your storage. 
javacpp in spite of name supports rust? But why use `cmake` if possible to use `cargo` directly from gradle?
I think this is very important, yet underestimated. Part of the reason I would say that "Rust community is friendly".
I think it's better to report an issue for this crates/repos. A reddit post doesn't change much. The absence of tags is a bigger problem, imo. Most of my crates has a changelog and tags/releases.
I regret that I have only one upvote to give.
 just like Firefox at least does with scroll-linked effects.
AFAIK the address and thread sanitizers report errors at runtime, so you can still have undetected bugs after running them. In Rust, this is all done at compile time and it provides you with an algorithmic guarantee that it is safe (except for the `unsafe` parts). If you really want to do C++ and write "safe" code, I recommend checking out the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines), but even then, you will not have all the guarantees provided by Rust. Other nice resources: Clang Static Analyzer and clang-tidy.
I like that Rust has a much smaller vocabulary of concepts than C++. I also find that it's easier to write code that is correct the first time it compiles - a trait that's shared with Scala. Take *any* career advice I give with a grain of salt because I'm pretty strongly decided against programming professionally. I'm much happier as a hobbyist who can pick and choose my own standards, which upstream dependencies to include, and which pull requests to accept. A big problem in programming is other people's code. Start working in a well-established language and, yes, there are jobs - there are jobs maintaining other people's code. COBOL job opportunities are great, for example. Java, sure. But the catch is you'll have to read code written by COBOL and Java programmers. If you are just writing C++ for assignment, that's a different experience from *reading* C++ for a living. The first gives you the luxury of only mastering enough of the C++ concepts to express yourself. The second, you need to be comfortable with everything the language can throw at you. Don't like inheritance? That puts you in good company. But the programmers who came before probably loved it and now you have to live with it. But, like I said, huge grain of salt. Neurotypical people often feel good about getting a paycheck; I've got ADHD-PI and delayed gratification is so emotionally bland that I need to be happy in the moment of whatever I do at work. The best advice I *can* give is to job shadow as much as possible before choosing a career path. Also, don't feel that the language you use in school is the one you'll use at work - everyone who is making a living off of a new language like Rust or Scala now had to educate themselves into it.
Thanks for this, yeah I've not had to read anyone else's code yet and maybe this should be the deciding factor in choosing a language. I can only imagine what pre-C++11 code bases look like. My main language is Scala and I definitely enjoy that a lot more than writing C++.
Yeah I wasn't sure if ASAN/TSAN exercised all code paths, so maybe it will always be a question mark. Thanks for that link.
I think the point is that it could be nice to have some way to incite to use changelogs. I agree that adding a changelog file (directory?) to Cargo.toml that can be rendered to crates.io would be gread. It could also be added it in the default template when you run `cargo new` so you're like "oh yeah I should fill this file too".
It supports anything with C ABI, and Rust supports that with `extern`. You just have to write a C header. (IIRC there was a tool to automate that) For me, cmake builds javacpp's generated code + copies libsodium + copies my rust library. I don't invoke the cargo build from gradle because it happens on a different machine :D (cargo on FreeBSD, gradle on Windows)
After RustConf, several Rustaceans headed south of Portland to catch the eclipse in its totality. Manish took this photo of me wearing eclipse glasses. Last night as a joke he photoshopped it on top of an explosion. Why is it on the subreddit? I guess the mods think it's funny.
I started keeping change logs as a result of a reddit post.
You can combine a sanitizer with a fuzzer and run it until all code paths have been executed. That still doesn't necessarily mean that your code is 100% safe, but it should get you very close. I should also point out that sanitizers and fuzzers are useful on Rust code as well. Sanitizers can insert assertions that you don't do dumb things in unsafe blocks, and fuzzers can check if any of these assertions (or regular panics, for that matter) are reachable at run-time. Additionally, Rust doesn't actually prevent resource leaks any better than modern C++ does, so leak sanitizers are equally useful for both languages. 
&gt; To be clear, I don't believe these images are root of the problem. They are symptom of the broader issue of this subreddit being excessively relaxed. Huh. I wouldn't characterize it that way at all. For the most part, I see pertinent, on-topic, reasonable discussion on the sub. Where else but the mods occasionally having fun with the CSS do you see it being "excessively relaxed"? I think that the sub, as a whole, does a good job of being a place for good, on-topic discussion and content, with the occasional letting off of steam (end-of-year holidays break, April 1st, and the occasional small joke prompted by some thread). I would say, however, that the current image is a bit meme-y and in-jokey. I might argue that it's going a bit far in the casual direction, so while I don't think that there's a general problem, I'd maybe push back a bit about this particular image.
In my experience most of the projects with high quality changelogs keep an "unreleased" section. The only exception I can think of right now is PostgreSQL but they have a couple of contributors who take compiling the release notes very seriously and involve the mailing list in correcting and improving the draft release notes.
As /u/my_two_pence mentioned in the sibling comment, you might want to look at fuzzers. If your (part of your) program reads a byte stream/string and does things with it, you can easily fuzz it. There is `cargo-fuzz` and &lt;https://github.com/rust-fuzz/targets&gt; has a bunch of fuzzers for common crates you can use as examples. I know for a fact that it uses ASAN and does clever coverage analysis.
Speaking of the CSS, I wouldn't mind a new one that looks a little less dated. I mean, most of the programming subreddits linked by OP don't even have custom CSS, but I don't see any reason why it should be that way.
There is normally no completing thread. In JS, it's a single threaded environment where one asks the vm (node or browser) to do an operation and get back to them once the task is completed. So for things like HTTP requests it's single thread and the OS will know when the socket is ready to be read and the VM will then continue that computation. In rust you can spawn a thread to do some heavy computation and get back to the main thread when the computation is done using Futures, but it's still one main thread. The way most Socket connections work is that one has a lot of idle time on the main thread, because the OS is handling it and therefore it is possible to continue computation on the main thread.
Why isn't `type` called `alias`? I'd expect a `type` to be real type!!?
Futures.rs is basically single threaded, unless you do something fancy with a thread pool. The waiting thread calls poll() in a loop, and that function call does all the work right there. If there's waiting IO involved, I think the IO futures are responsible for arranging that IO events will wake up the waiting thread.
Pretty much all major ad-serving networks use `document.write` to inject ads. DoubleClick's code was written in the 90's before modern DOM manipulation code even existed, and they've never bothered to refactor it. Other ad networks may or may not have similarly legitimate excuses, but it's still common.
"I would say, however, that the current image is a bit meme-y and in-jokey." I must admit like I am "hum I might be missing some reference here" (which isn't very rusty and might be unsafe if I try to derefence it?). More generally, I understand the OP's point, as I think too much relaxed and injokey spaces can be very nice for people who are already in, but quite excluding for newcomers; at the opposite though, I think having something a bit relaxed can help someone to start posting (I mean if some people sometimes post less serious stuff I personally feel less anxious that my post won't be seen as "serious/well-constructed enough"). I think globally this subreddit has a good balance between the two. But if there is a hidden meaning behind this picture I wouldn't mind someone explaining it :p
This sub's ratio of humor/on-topic discussion is superb. I don't mean to insult anyone with this, it's just an observation and my opinion: The quality (and levelheadedness) of posts as well as comments on /r/rust is _way_ higher than the ones I see on other programming-related subreddits. Add some good natured humor here and there, and you can see why I'm here so often. (Another way to read this: My expectations of subreddits are just really low :P) PS: Current image, which I've dubbed "Segfault Steve" would be more approachable to "non-insiders" (ppl who don't follow Manish on twitter) with a caption and an exception in rule 3 ;)
Having `document.write` unimplemented in Servo was a great ad-blocker :)
How can I sign up for this? The page is marked as immutable for me.
Even better!
Don't forget https://crates.io/crates/init_with too
Address Sanitizer and Thread Sanitizer work fairly differently. * They work at runtime, so you generally run them with your tests * They rely on test coverage - if you don't hit a path with a bug, you won't find that bug, with or without ASAN * They find a subset of memory safety bugs Rust: * Find *all* memory safety bugs at compile time * Coverage is everywhere by default, opt out (for certain aspects of analysis) in unsafe blocks So, regarding those unsafe blocks, you could write tests around them and use ASAN etc: https://github.com/japaric/rust-san As for what's worth learning in the short term, there are more C++ jobs, so if that's your goal learn C++.
I presume the keyword was selected to match languages like Haskell, where `type T = U` creates a type alias, and nothing more. You can create a single-element struct if you want to use the new type pattern, e.g. struct Names(Vec&lt;String&gt;); 
Sorry you can't make it! We will be live streaming the talks. The link isn't up yet, but you'll be able to find it at https://air.mozilla.org/channels/rust/. I'll also post it here on Thursday. 
If your goal is to exhaust all code paths, a fuzzer is unnecessary - you can just exhaust all of the code paths. A fuzzer is generally meant to reduce the number of code paths necessary to check in order to find a bug - or to test randomly, or by some other less straightforward means. If you *were* to exhaust all code paths, it *would* mean that your code is 100% safe, since no given input can cause a memory error.
This seems good for handling when there are old different branches that get patch updates too. Just a bit messy to make sure all the changeling files are merged into master eventually. Do you have a good system for that?
If we're gonna complain about how this subreddit is handled I guess I do have a very small complaint. I've noticed that if there's some discussion somewhere at users.rust-lang.org or github, there's a push to have people comment there instead of here to keep things 'all in one place'. I and probably many others prefer reddit, so I feel like reading comments here. More importantly, it can be useful to have a discussion at different places if the type of discussion is different which I think is the case. You can get people's feedback with stuff like the Rust Survey but reddit is a bit more informal, and it's possible the type of feedback you get is different. There was a big complaint thread on reddit a while back and it seems to me people are more willing to say certain things here that they might not say or say differently with a survey or discussion on the users forum or github. In comparison, on reddit, people might worry less about whether a complaint is useful or not. That's valuable because if people feel they have to *really* explain stuff in detail they might not say anything at all and then, whatever displeasure or frustration exists might worsen. This might seem like it results in low quality feedback, but I don't think so. I think of it as user feedback from a different angle. I do understand that it would be a mess to have to collect feedback from different places but I'm not sure if it's really necessary to 'collect' feedback here. You could think of reddit comments as a giant garbage pile from which you can find nuggets of useful information. It's not completely necessary to sift through all of it. So I would like the team to treat this subreddit a little bit more as something that's useful on its own, in its own way, and a little bit less as something that's redundant for certain discussions. Other than that I have no complaints. :) I'd like to see 'what are your complaints' threads on /r/rust more often, although now might be awkward timing because the Rust Survey results are due.
init_with is exactly what I was looking for, thanks. 
There is a link in the sidebar to a [twitter thread](https://twitter.com/edefic/status/900890123574882304), and it seems to be a reference to a meme about [the future's so bright, I gotta wear shades](https://www.google.com/search?q=future+so+bright+meme&amp;safe=off&amp;tbm=isch&amp;tbo=u&amp;source=univ&amp;sa=X&amp;ved=0ahUKEwiB_PbJzPLVAhVl6IMKHWpIBYgQsAQIJw&amp;biw=1440&amp;bih=770&amp;dpr=2), which is [apparently an 80's song lyric](https://www.youtube.com/watch?v=8qrriKcwvlY). And the picture is of /u/steveklabnik1, a prominent Rustacean who does a lot of work on docs and education, wearing safety glasses presumably to look at the recent eclipse. Anyhow, with that much explanation needed, I think that the meme and in-joke level is a bit high here.
Say something in #rust on gimpnet (irc.gnome.org) and someone will add you.
Oh, thanks. I got that this was Steve Klabnik, but with the explosion I thought I had missed some kind of big announce such as "going to scrap TRPL book 2nd edition to start a 3rd" or something like that.
Agreed. What I meant was that if they can't bother making a changelog, they're doing the next best thing. A changelog is definitely far more preferable.
&gt; Find *all* bugs at compile time Did you mean it finds all memory errors at compile time? Rust certainly does not prevent all bugs (even though it does eliminate certain classes of bugs).
&gt; wearing safety glasses presumably to look at the recent eclipse. As a prominent Rustacean it is his duty to be the epitome of safety. He wears safety eclipse glasses 24/7, of course. As should everyone else. &gt; it seems to be a reference to a meme about the future's so bright, I gotta wear shades It's actually [just a reference to nuke-elmo](http://knowyourmeme.com/photos/1151933-sesame-street) with eclipse steve instead of elmo.
This is kinda why we're not in-jokes 24/7 (see: twitter); letting the sub go crazy for a few days is a fun way that avoids excluding folks. There's no hidden meaning, it's just [a reference to nuke elmo](http://knowyourmeme.com/photos/1151933-sesame-street) with eclipse steve instead of elmo. However the community (on twitter) has run with it and made a million spinoff memes. It's great.
Yes, I meant all memory safety related bugs. I'll update my post.
"Apparently an 80s song lyric" The fact youngins didna know this means I am old.
I assumed it was something about North Korea. Kind of off-topic. Maybe a disguised political statement? Edit: Hey downvoters! It had a nuclear explosion / mushroom cloud on it when I commented. (Right now it's something from LoTR.)
Hm, I haven't thought about such use case. One solution will be to add subcommand like `cargo changelog pull` which will pull missing change files from published crates. (using larger versions for conflict resolution, so `0.1.7.md` will be pulled say from `v0.1.10` and not from `v0.1.9` or earlier)
While I thinking having a change log as part of the default template would be nice, one argument against it is, "readmes aren't part of the template, why should change logs be?" You would need to have a solid argument for it to be included.
&gt; If your goal is to exhaust all code paths, a fuzzer is unnecessary - you can just exhaust all of the code paths. What exactly do you mean by "just exhaust all of the code paths"? Manually figuring out thousands of test inputs to make sure that all branches are taken by at least one of them? Isn't generating interesting test inputs exactly what the fuzzer is designed to do? How is the fuzzer unnecessary? &gt; A fuzzer is generally meant to reduce the number of code paths necessary to check in order to find a bug This sounds like automated input minimization, which happens *after* fuzzing has found an interesting input. It is sometimes integrated into the fuzzer, but it's not the main purpose of the fuzzer. &gt; If you *were* to exhaust all code paths, it *would* mean that your code is 100% safe, since no given input can cause a memory error. This seems incorrect, unless you mean something else by "code paths" than I do. Just because a particular path through the code has executed fine a thousand times, doesn't mean that it wouldn't segfault the thousand-and-first time because a particular pointer is suddenly out-of-bounds. The only way to be 100% sure is if you've tested every code path *in every reachable program state*. And given that the typical program has a theoretically infinite number of reachable states, you can never fulfil this condition by exhaustive search. 
As the author of the original meme, I assure you there was nothing political about it. Steve's eclipse photo just matched the regular nuclear Elmo meme. 'course, death of the author and all that, feel free to ascribe your own political meaning to it. (There are a large chunk of spinoff memes about Posadism though)
I do wish we could make the Ferris icon a link back to /r/rust instead of the link to the reddit homepage. I disagree with pretty much everything else though. Sorry OP. Having a bit of fun is fine. Don't forget what happens to this place on April Fools.
By "all code paths" I was referring to: &gt; and run it until all code paths have been executed Which I thought you meant was 'exhaust all inputs' - not hit every branch - but I see what you mean now, my mistake.
Sorry, I am not up to date on memes, e.g. "Nuclear Elmo meme". Maybe we need a meta-site like XKCD has to explain the jokes.
I liked these points enough that the `master` branch in [`adhesion-rs`](https://github.com/erichdongubler/adhesion-rs) now has a changelog a la [Keep a Changelog](http://keepachangelog.com), as suggested by /u/mehcode. Thanks for the feedback to the community! :)
I'm excited to see so much collaboration ongoing between Rust and GNOME. On top of them working to integrate Rust as a 1st-class citizen in the GNOME ecosystem, I'd love for them to evaluate [relm](https://crates.io/crates/relm) as the canonical way to use GTK+ from Rust given the annoyances of working with global state.
Yes. CSS could use a fresher more official-project style look. I think the /r/haskell is probably the best of the mentioned ones... Also nice is /r/elm
[removed]
Yeah, and they're pretty trivial to implement. They're both just color variants of a popular CSS theme found all across reddit. But I wouldn't mind at least something like /r/python. It's not more complex than here, but it's definitely more tasteful in my opinion. I don't think we should ditch the "rusty" aesthetic going on with the colors on our sub, but the implementation definitely looks aged. Square blocks with solid colors don't take much effort, and it shows.
&gt; When a thread stores a value to an address, a message with the stored value is added to the address; when a thread loads from an address, the value of a message of the address is returned. It has two implications: (1) threads may be able to concurrently read different values from the same address; but (2) at least, it is guaranteed that there is 랍ome global order (namely the timestamp) of the writes to the same address. We call this the 띾oherence order (or 랈odification order in the C/C++ standards lingo). is that naturally true even on NUMA boxes with ARM (or other) CPUs? Or do compilers have to work to make this happen? 
This all reminds me of Discordianism for some reason, which I couldn't see the point of either, where the whole point is to make no sense. Or Zen koans, i.e. Steve with a nuclear blast could mean very many (infinite?) things but actually none of them are intended, and you'd be better off just going to have a lie down in a darkened room.
I just remembered, you should probably include: [profile.release] debug = true In your Cargo.toml so VS can read the debug symbols. 
A more extreme option is to have the intermediate type panic if it gets dropped. Then the builder function would use `mem::forget` to avoid that. This all-but-guarantees that the program will crash unless the correct function is called, however, you don't get any compile-time help to avoid it. I don't necessarily recommend this approach but it's worth mentioning as it is used in the compiler (perhaps you've seen "ICE: error constructed but not emitted").
Just saw this post. I'm maintainer of 32 crates on this list (all "imag-*" crates and the "imag" crate) - but I'm in 0.y.z and I clearly state that my project is alpha quality at best - far from usable and production ready. Actually, I'm preparing a release (0.3.0) right now which will update dependencies... but generally I disapprove of simple updating for the sake of updating, for reasons others have expressed in this article better than I could.
[removed]
Ah, I see what you mean.