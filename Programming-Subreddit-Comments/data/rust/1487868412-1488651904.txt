It seems like you're proposing type-aware macros like in D? Something like this could exist. Not on the books for now, but it could. &gt; And to what extent does Rust follow the "compiler as a library" paradigm? It seems most the hard code for a limited version of this already exist. Take dtolnay's quote and syn, feed that to the compiler, and you're already most of the way there. We have these, they're called compiler plugins, and they're more powerful than what quote and syn do. They're just not stable, because stabilizing internal APIs is annoying.
&gt; message the mods and we can do it for you That's an idea.
Yes, it will
This is one way of correcting yourself and avoid edits I guess...
The intrinsics all need to be implemented, yes, but that is part of the "mir -&gt; llvm" pass. I was more thinking of places that use LLVM that aren't part of the direct conversion-to-LLVM stage, e.g. currently `librustc_trans` (the mir to LLVM *trans*lation), `librustc_metadata` (for reading/writing the Rust-metadata into a compiled crate), `librustc_driver` (parses options/drives the various passes) and `librustc` (catch-all for everything that doesn't fit/can't be extracted into other libraries) all depend on LLVM, but only `librustc_trans` does the conversion. Also note that `link_llvm_intrinsics` is defending against something that is a natural consequence of how LLVM implements the intrinsics, and so it is feature *gated* exactly because this isn't a feature. Previously, linking to the intrinsics would work completely fine, and so I added the gate to hopefully make introducing alternate back-ends easier: it is more difficult/impossible for the crates.io ecosystem to depend on LLVM implementation details (and the only uses internal to rustc are in a few tests).
Good point. When I started learning Rust, I found dealing with Deref/Borrow easier than dealing with AsRef. It depends on the use-case, I guess.
This library is initially based on a module written by Alex Crichton which I found in the source of a Rust project a while back while looking for a solution to a problem I had. I liked the simplicity of the solution so much I packaged it and made it into a library. I hope it helps some of you! [Example usage](http://indiv0.github.io/lazycell/lazycell/#example) [API docs](http://indiv0.github.io/lazycell/lazycell) ### Why would I need this? For example, this library lets you mimic the following C# pattern: private string _foo; public string Foo =&gt; _foo ?? _foo = CreateFoo(); without requiring the equivalent Rust struct be mutable.
Are you using a nightly version of Rust? Benchmarking is unstable... https://doc.rust-lang.org/book/benchmark-tests.html
That was my conclusion as well, thanks for the answer. I'm with phayzfaustyn, MPL2 seems a worthwhile alternative to LGPL.
I don't really know, although I suspect you would lose some precision with this approach. It probably works, although I would test it with some sample values from that range.
There are plenty of contexts where it is seen as very rude to make assumptions about the knowledge of your audience. If you start your talk/request for input with the implicit assumption that your audience knows about a certain topic, and that if you then expand on it without ever actually bringing everyone to the same page, then you shouldn't be surprised if your audience might think that you are very *arrogant* in your implicit claim that everyone should know what you know. It might be construed as you wasting your audiences time and thinking their knowledge beneath yours. While it is admirable of you to react ‚Äúin a friendly manner rather than an oppositional one‚Äù, the adverse reaction can be perfectly justified - even though I definitely agree that we should strive for the former (even if it's just to keep our blood pressure low). I think that you should keep this other view in mind, in particular if the person offers a (one-time!) snarky yet not outright insulting (‚Äúad hominem‚Äù) comment. Else you very quickly run into the accusation of being overly patronizing.
`lazy_static` is intended for lazily-evaluated static variables, while `lazycell` is intended to function as a lazily-filled `Cell`. So for one, it's static vs. non-static, and two, it has the same ergonomics as a `Cell`, instead of a static variable. There's also the difference of lazily-evaluated vs lazily-filled.
Looks great so far hopefully when I log on it's not 200 ping from EU üëç edit: the first server I seen was one that I was kinda looking for
I have no idea what that subreddit is about. This subreddit is for the Rust programming language, not the game Rust. /r/playrust is the main subreddit for the game Rust.
Cheers!
Damn it‚Äôs been a while since I‚Äôve messed with C++. Is that what C++17 has become? Or am I looking at C#? XD
My apologies, I meant to write C# :P
I could see the value in a WebRender-like compositor. I.e. allow multiple processes to contribute to the same layout-tree but have the OS itself be responsible for updating and rendering the layout. The more "stuff" you can bake into the layout (like animations, fades, scrolling etc.) the more things can be robust to application-level hitching (it kinda sucks when an app does a synchronous IO operation and the whole window freezes up.. if most of the stuff that moves inside an app is managed by a higher level composition engine then that wouldn't happen). 
It‚Äôs technically not `sort`‚Äôs fault for wiping your data. It‚Äôs more to do with how the shell sets up the redirections before the `sort` program even has a chance to look at the data. In particular, `&gt;` causes the file to be truncated immediately upon opening.
Ohhh sorry about that I'll remove it
The author did a [postmortem](https://users.rust-lang.org/t/glium-post-mortem/7063) about half a year ago. Note that this just means that there won't be any major updates (unless there is a rewrite) in the future.
You're right. I routinely run into cases where `some chain | tee inputfile.txt &gt; /dev/null` also results in lost data, however. 
Thanks. Sadly Vulkan is stuck at the moment because a certain vendor refuses to support it :(
any smart pointer like that is going to do a heap allocation, it's sort of assumed. you can also see the RC docs say T: ?Sized. unsized types have to live on the heap
For what it's worth I've decided to more or less stop writing code and answering questions/issues for all my libraries for an undeterminate period of time, except for vulkano or unless it's code that I personnally need. EDIT: It may look like I'm abandonning the ship, but that's more or less already what I was doing for many of them in the past year or two. I'll come back to open source when things settle down a bit for me.
Nuance or tldr? Maybe somewhere in-between is more appropriate. Consider it meta-nuance.
In that particular case, it is indeed `tee` that opens `inputfile.txt` and immediately truncates it, in parallel to whatever is happening upstream in `some chain`. I think if the upstream is lucky, they might get to read a few bytes before noticing the file is empty!
Is there anything BurntSushi can't do?
Sushi?
You should try tamago. It's a great entry, and there's no fish in it!
https://users.rust-lang.org/t/glium-post-mortem/7063 Actually its just not actively supported, community still uses it and bugfixes and improvements still going.
&gt; even though I definitely agree that we should strive for the former Which is my point here. I understand why the person had such a reaction. I would prefer if such reactions were kept off this subreddit.
Thank you for your contributions. I always assumed you were some kind of robot based on the number and scale of your open source rust libraries. I am glad to hear you are, in fact, human and have limits :). Enjoy your break.
Sorry, not an answer to your question, but you may enjoy the [Ferris Makes Emulators](https://www.youtube.com/playlist?list=PL-sXmdrqqYYcL2Pvx9j7dwmdLqY7Mx8VY) series on youtube. It's an N64 enumlator though. Edit: To better answer your question, I find macros help to things that would be super tedious in regular Rust. Things such as implementing traits for multiple types, etc. Or other codegen like aspects. Macros are also very useful for expressing things `println!()` which would otherwise be very tedious/ergonomically impossible in regular Rust. I will also say that using macros does indeed make it significantly harder to debug, and even sometimes read/maintain. I also like to stay away from too many "magical" macros which do something outside the typical Rust syntax because they require knowing exactly what the macro is doing and it's almost like reading another embedded language.
xsv is so good, we made a similar suite of c executables about 15 years ago for in house use 
Could this be made a part of [Mitochondria](https://github.com/nox/mitochondria) as a wrapper around [OnceCell](https://docs.rs/mitochondria/1.1.2/mitochondria/struct.OnceCell.html)?
FWIW I tried submitting a PR for this exact thing a few weeks ago and you can see the failures on travis yourself: https://github.com/rust-lang/rust/pull/39397
Sorry, was busy with work. I want what you could think of as runtime macros, basically. You generate the code, and can execute it as described in the OP, either as a function known return and argument types (which implies no ability to generate types) or or an exec (in the fork/exec sense) which would allow for the generation of arbitrary code to be executed, including new types. My question is twofold. Can this be added to the language without overhead when not used, and how feasible is it from an implementation standpoint?
Would it be even more amusing to know the csv crate (xsv uses this) isn't even the fastest rust csv parser?
I guess he is talking about Apple.
Technically Microsoft also refuses to support it, you can just backdoor it onto Windows thanks to the open platform.
Yeah I was thinking about that as well. It's why I linked the [example](http://indiv0.github.io/lazycell/lazycell/#example) as a stop-gap measure.
I try not to use single characters as names for macro inputs, especially for public-facing macros. It's frustrating to come across an undocumented macro with a signature like `$i:ident, $k:expr`
&gt; Since I mainly use scripting languages which don't have Macro programming, the code seems a bit magical to me. I'm worried whether the code linked is too "clever" or if it is rather common among larger Rust applications and simply a paradigm I should adapt too. The way I see it, macros are actually used to do stuff which is easy in scripting languages but would otherwise be impossible in Rust due to the constraints of the language and static typing. 
On a side note, you may want to consider using [easy_strings](https://github.com/Storyyeller/easy_strings). It provides a string type that is designed to be as easy to use as possible with a slight performance cost. Basically, it lets you use strings the way you would in Python, Java, etc.
Yup. From the Chromium bug tracker: &gt; This situation was unusual, PII was actively being downloaded by crawlers and users during normal usage, they just didn't understand what they were seeing. ... &gt; We fetched a few live samples, and we observed encryption keys, cookies, passwords, chunks of POST data and even HTTPS requests for other major cloudflare-hosted sites from other users. ... &gt; We've discovered (and purged) cached pages that contain private messages from well-known services, PII from major sites that use cloudflare, and even plaintext API requests from a popular password manager that were sent over https (!!). ... &gt; I'm finding private messages from major dating sites, full messages from a well-known chat service, online password manager data, frames from adult video sites, hotel bookings. We're talking full https requests, client IP addresses, full responses, cookies, passwords, keys, data, everything.
bug tracker reference: https://bugs.chromium.org/p/project-zero/issues/detail?id=1139
Should make a ticket on github about it
These are good points. But to be clear, Python's CSV reader/writer really can't compare here. The amount of allocation you need to do just to interact with the reader/writer at all is going to kill you. `xsv` was specifically built around using the CSV parser without allocating as much as possible. This is critical to performance on large CSV files and is really not something you can do in Python easily. With all that said, the OP specifically called out the `xsv stats` vs. `csvstat` programs. I don't think I've ever looked at how `csvstat` works, but I can imagine how slow it might be if it were implemented naively. Many of the stats can be computed in an online fashion, e.g., mean and standard deviation. `xsv` can even parallelize it if you built an index on the CSV file before hand. (Building an index takes about as long as parsing the file, i.e., it's fast.) I'd say the perf gain here is a combination of Rust and attention to costs. (Which is really all you're saying too I think, so we're in agreement, but I like talking up Rust, so hear I am. :-))
Yes, validation isn't perfect. Thanks for the specificity. I meant to put the return true in the upper block, thanks for that call out. You are right about the CIDR function taking incorrect arguments, I had deferred the evaluation to the caller, but that leaves it unsafe. The biggest validation I want to fix is when the host is returned as a possible gateway (ie `gateway 192.168.0.1/24`)
Ugh. This is a really interesting bug to analyze in the Rust context, I think. First off, safe Rust would have prevented the leakage of that memory. But imho that falls way short to address the issue completely. The underlying problem, that cloudflare gets to see supposedly encrypted content without the user knowing about that and handling that unencrypted traffic for many different customers on the same machines is something that depends more on architecture and would be an issue even with Rust. It allows all kinds of attacks to get at that data that have nothing to do with the safety of the used technology (think legal orders, compromised admin logins, network infiltration (TAO, insecure networking equipment), etc). Additionally, this highlights a big issue we're having with Rust's security. Cargo is pervasively used within the Rust ecosystem and commonly praised as a big enabler for Rust productivity and ease of deployment. Its security properties used to be abysmal at launch and - even though there has been improvement - still are problematic. The entire Rust ecosystem heavily relies on https being secure and infrastructure that serves content to not be infiltrated. Showing how willingly so many big websites entrust cloudflare with their data, allow it to filter and change the content that they serve to their customers, shows how dangerous it is to rely on https as a security measure for an ecosystem. This isn't even scratching the surface of the issues with the ssl ecosystem, the above is problematic even if none of the CAs are misbehaving and all the software does exactly what it is supposed to. This is a world of tradeoffs, but I'm more and more convinced relying on https and thinking it'll be good enough will lead to much sadness in the future.
Apple. They are backing their own horse.
It is building and will be available here: https://github.com/redox-os/redox/releases/tag/0.1.0
I think Rust might be a decent environment for this, since you already have the lifetime discipline and a procedural-macros escape hatch for quoting token trees and splicing them. We intentionally held $ aside from the rest of the syntax to let people define splicing forms (as in macro_rules) though there are probably many wrinkles around hygiene and name-freshness to iron out. You'd probably also want to treat each stage as its own nested lifetime (i.e. each stage becomes something like 'static for the next stage), and you'd need a library API to invoke the compiler in a JIT mode, maybe ORC when it's sufficiently mature. It'd be quite a lot of work, but it's within reason. I was certainly aware of (and fond of!) MetaOcaml when writing early versions of Rust.
What a surprise. 
That's really cool to hear! (I worked on Thandy, a TUF predecessor)
Fixing the performance gotchas can very easily put your code in nonsense write-only land, too. Some of the things that are slow (like method calls, of all things; the solution? *Cache the method in a local variable* which is fast to access) require obscure or nonsense workarounds, and you'll end up with Python that's harder to read and still slower than if you'd just buckled down and written it in C or something.
Thanks for the reply! Sorry, I had my terminology mixed up a bit. I mean't to say "setup packet" (not header). I'm all good with the Ogg container parsing and picking out the comment, setup, and data packets. I'm basically just unsure about decoding the setup packet, and codebook setup. Specifically this part: https://xiph.org/vorbis/doc/Vorbis_I_spec.html#x1-470003 I'm not having any particular problems parsing this data, but it would be reassuring to compare the values I'm getting with known accurate values. I'll try what you suggest with lewton and see how it goes. Thanks!
Some of this is a bit over my head, but as for your first example, what exactly is `x` representing?
dang, well i applaud you for kicking ass at it and then giving other people that same ability to kickass at it. I haven't had to parse csv for years... so its good to know if i do you've got my back ;p
&gt; Oh, whoops, typo: it should be cell Alright, that's what I figured. I just tested your example and you're right, the `reference` is dangling. I'll add the `assert!` in, thanks for that! As for your comments on `Sync + Send` I *think* I understand what you're saying but unfortunately my knowledge of `Sync` and `Send` isn't sufficient enough to be sure whether or not the `Sync` impl is necessary.
Egg? (From what little I remember of the little bit of Japanese I learned while I was into anime as a teenager, omelette is "tamagoyaki" and literally translates to "egg, fried")
Crunch, crunch, crunch. [Instructions unclear](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPvUbQercLQHfiP4hN4fKtehnJHiwDc_IkaeCxbkEYfBFiekLM).
Or Korean kimbap, which has all sorts of yummy stuff, though most have imitation crab (but you can get varieties without it). They're also pretty good battered, fried and eaten with spicy ramen or saucy, spicy Korean dishes.
It has begun...
I haven't for a while, and typically it's a one off project for me, but I occasionally process datasets from the government which end up being in the megabyte range. I typically stuff it into an sqlite database, run an operation on it to grab the data I want, then put the interesting data somewhere more permanent (like Postgres or something). However, I might just have to try xsv the next time I do it (maybe later this year).
I agree 100% with what you said. In fact crates.io actually already requires a license to be specified in `Cargo.toml`. A nice addition would be to check the license of dependencies, though I don't think it'd be possible to hard-code that checking automatically. I do think you should be required to confirm that if you add a new dependency that it tells you its license and you agree that it's suitable for your project. Having said that, a developer who doesn't think about this is very concerning. It's equivalent to being in academia and not knowing how to attribute quotes and work to previous authors, which would be a fire-able and banish-able offense. If you're at a company and you're not a junior developer I'd be very concerned that you didn't know that you can't just take anything that's published on the internet without checking *how* it can be used.
Someone please tell me this isn't how the name "Tamagotchi" came about. 
Are passwords like this fine? Should people change them? &gt; sWsGAQHvqDx95k2w &gt; VALSHzUFU4kAd2gR &gt; ZaFmwMLTsZ97nwuX
Exposed password is no longer safe no matter how you have made one. If you have generated it randomly (recommended to use password managers' local generator) using a _new_ one is safe.
No, passwords like that need to be changed; because what's leaked is also context saying that it's a password.
And now "toki tori" makes sense. This is a real learning experience
Sorry to comment on this, but I just got mine all working. It's actually super easy, you just distribute the DLLs with your app. The question is automating that process.
&gt; The root cause of the bug was that reaching the end of a buffer was checked using the equality operator and a pointer was able to step past the end of the buffer. This is known as a buffer overrun. Had the check been done using &gt;= instead of == jumping over the buffer end would have been caught. I find this reasoning scary, seeing as simply incrementing a pointer past the end of an array is undefined behavior. Using &gt;= might have "worked", but it'd still be UB! 
Why not? What's the alternative? Ok, there's JSON, which offers more structure. But the kicker is that most people don't know how to use that structure. What do you do when the cell in row "Proto-AA" and column "Initial est." suddenly contains an array? Or when column "Property" has fields "start", "end" and "avg.exp"? Most people flatten them out, leading to such monstrosities as the spreadsheet for institutions of higher education with 1729 columns. So yes, csv is still a thing.
&gt;the name is a portmanteau combining the Japanese word tamago („Åü„Åæ„Åî?), which means "egg", and the English word "watch". wikipedia
1: Port has never ever sounded like a rewrite to me am I missing something? I always thought of it as tweaking it to work somewhere else... 2: That sounds like the exact definition of rewriting...
Is it? I would have thought UB would only be invoked on access. Then again, if you go past the end of the buffer, you might have overflow, which definitely is UB.
Came here right after reading about the leak. And people say, "why should we re-write things in rust.." ...this is why. Maybe more companies will wake up after this and take it more seriously. It's 2017... how does this happen... 
There's a small mistake here: mv sorted.txt &gt; words.txt You might want to remove the `&gt;`.
I think the conflict is what you said in your first sentence: &gt; This is a classic C bug, there is nothing special or interesting about it vs. what /u/tiny_fishbowl said: &gt; This is a really interesting bug to analyze in the Rust context Your comment sounded more dismissive about the interesting-ness of the bug.
I would encourage you to switch to `T: Sync + Send` for `LazyCell&lt;T&gt;: Sync`: it is a safe default (one should be able to remove the `+ Send` bound if it is unnecessary, without breaking code) and it's not that restrictive in practice (essentially all types that are `Sync` are also `Send`). Also, I'm fairly sure it is actually needed.
Size hardly matters. You can store that all in whatever way you like and the garbage collector will hardly notice it. 10MB is peanuts on a modern machine. Anyway, my file is 86M.
This is relevant to my interests. :)
Have you considered custom number parsers? I don't think anyone puts scientific notation in their csv, so that's a lot of wasted code paths. I forget if you did this already.
Is your parser available? I would like to add it to the [csv-game](https://bitbucket.org/ewanhiggs/csv-game).
No, sorry. There are discussions about making part of our software open source one day, but for the moment I can't share it.
At 100m rows?
The Rust program took 1.8 s the 4 min number is from the Python one. Also it calculated some (basic) stats about the rows too.
If you were to try and make the word "watch" into japanese, it would be something like "wa-chi". Hence tamago + chi = tamagochi. Not that that proves anything because I made it up on the spot with my rudimentary understanding of Japanese. 
It's not just parsing the data, but also running stats on it.
At 100m rows, I get the following based on [this test](https://bitbucket.org/ewanhiggs/csv-game): rust,csvreader,fieldcount,10.603 rust,csvreader,fieldcount,10.291 rust,csvreader,fieldcount,11.710 rust,csvreader,fieldcount,11.363 rust,csvreader,fieldcount,10.316 rust,csvreader,fieldcount,10.427 rust,csvreader,fieldcount,10.314 rust,csvreader,fieldcount,10.431 rust,csvreader,fieldcount,10.356 rust,csvreader,fieldcount,10.507 rust,quick-reader,fieldcount,9.565 rust,quick-reader,fieldcount,8.957 rust,quick-reader,fieldcount,9.203 rust,quick-reader,fieldcount,9.040 rust,quick-reader,fieldcount,8.974 rust,quick-reader,fieldcount,9.112 rust,quick-reader,fieldcount,9.005 rust,quick-reader,fieldcount,9.045 rust,quick-reader,fieldcount,8.980 rust,quick-reader,fieldcount,9.052
Btw sponge in moreutils does the same thing.
A little update now VS is more viable then the Atom variant for Rust. Newest update of the rust extension added a lot of things that are missing in atom and also filled the gaps with linting.
Using the phrase "leaking memory" like this is actually standard in computer security. I wouldn't call the title "misleading", but I can definitely see how that can be misinterpreted in a subreddit where memory allocations are a common topic :p
Thanks. However, I meant including a headless version in your releases as well. Instead of just `livedisk.iso` how about `livedisk-min.iso` (headless) and `livedisk-gui.iso` or something like that?
Thanks for the code review! Really appreciate having someone more experienced diving into the codebase. I'll implement your tips over the next few days.
So that's why you burned it!?
&gt; Wait: a 30k by 400 columns file takes 4m16s? Yes, `csvstat` is *ridiculously* slow, even for a Python script. On my machine, it can barely process 100 Kb/s.
If I've done my math correctly, the averages are: cvsreader: 10.6318 quick-reader: 9.0933 Making for a difference of 1.5385 I think this works out to cvsreader taking 16.9% longer.
Yes it's the best way to comparably transport large untyped datasets. Less verbose then json and high compatibility. 
I wonder whether they tried the Pandas CSV parser. I bet it isn't as fast as xsv, but I seem to recall Wes McKinney spent a significant chunk of time [writing a highly-optimised C parser](http://wesmckinney.com/blog/a-new-high-performance-memory-efficient-file-parser-engine-for-pandas/).
The actual handle came from a small piece of graffiti I found in a booth at [Coney Island (not the island)](https://www.coneyislandlunch.com/), which serves the best hot dogs in the world. And that's a fact. Here's another: I once ate 16 hot dogs in that booth in one sitting. Being a young'in, I thought "burnt sushi" was a clever oxymoron and adopted it. Since then, I've been told by several highly educated individuals that not all sushi is raw. :P At Coney Island, it's actually encouraged to write or carve things into the booths. It's always fun reading through them all.
Could you elaborate? I'm not sure I understand. (CSV itself doesn't know anything about numbers...)
It should be better suited for a testing tool like a fuzzer. The idea I have in mind: the fuzzer allocates its data at the edge of a memory page. If the parser goes further than that, there's a segfault and the fuzzer detects it.
Because the virtual address still is a number, a (sized) type still has a size of bytes it takes, and so I‚Äôve always taken for granted that you can basically do whatever you want with the pointer and its underlying address expressed as a number.
&gt; Of course Rust could have prevented this obviously, any memory safe language could have Wrong, it's still possible to reuse buffers across connections and if you get length and indexing wrong, you will be leaking data. Just using memory-safe languages is not enough.
"Watch" is spelled (as Romanized) more like "wotchi". &gt; tamago + wotchi = tamagotchi („Åü„Åæ„Åî„Å£„Å°) 
Why would you do that? OnceCell and LazyCell are identical.
Oh yes. Our system at work loads like 500GB of CSV files daily. You can't really tell the vendor to change something they have been delivering for 20 years. Of course a well documented binary format would be nice, but good luck actually getting someone to make one of those in a way that's actually workable.
The core difference is that in Rust, pointer arithmetic, and more importantly dereferencing of pointers is unsafe, meaning you need to opt into it. When people say "Rust is a memory safe language" they actually mean that the safe subset of Rust is memory safe. The unsafe subset is not memory safe, but you can write almost anything in safe Rust, which is the great power of it. For some things like interfacing with C or low level primitives you will need unsafe though.
Well, for instance, all x86 and x64 chips boot in 16-bits real-mode, and in this mode pointers consist of *two* numbers: a segment and an offset. The pointer in RAM is then calculated as `(segment &lt;&lt; 4) + offset)`. One consequence of this addressing scheme is that many locations in memory actually have multiple possible pointers. In protected mode and long mode the situation is a bit different, but the segment registers are still there. However, afaik all operating systems choose to provide a flat memory model by making the segments start at memory position '0' and making the segment span the entire address space, so all information resides in the "offset" bit of pointers. Anyway, in real-mode, when an object ends at position 0x0000 : 0xfffe, you can still go "one beyond" to 0x0000 : 0xffff. But what would it mean to offset one further? Do we wrap to 0x0000 : 0x0000? Do we automagically adjust the segment part so that we get some more space in the offset? Many parts of the C/C++ standard make sense when you think about the weird architectures that they must support. One thing that I find pretty inexcusable is that not ending your source files in a newline is *undefined behavior*...
I think using SIMD/SSE to quickly eliminate blocks of data that only contain ASCII data and verifying those that do using traditional code would be a nice improvement over Rust's current string validation, at least for long strings.
Sorry I am confused: is it normal that CloudFlare processeses decrypted HTTPS traffic? Does that mean that CloudFlare controls the SSL certificate for websites that use its services? I have been under the impression that CloudFare merely proxied/routed/relayed encrypted HTTPS, and never saw plaintext. 
We can come up with plenty of scenarios where rust would have security vulnerabilities, but the fact is that this error, an OOB read, would not have happened.
I don't get this. Is csvkit a native Python library? If so, that explains it. Most performance intensive libraries are written in C with Python bindings. So, really one should compare calling the Rust library in Rust versus calling the same (compiled) library from Python. 
&gt; Sorry I am confused: is it normal that CloudFlare processeses decrypted HTTPS traffic? Does that mean that CloudFlare controls the SSL certificate for websites that use its services? yes and yes. CloudFlare terminates the SSL traffic itself.
Try again in /r/playrust.
Rust allows you to operate at a higher level of abstraction, meaning there is less boilerplate and bugs are less likely. In the example, they duplicated some code, but forgot to include one line, which is something that abstraction prevents. Apart from that, if you don't use unsafe, you don't have to worry, assuming there are no bugs in the underlying library, which there weren't in this case.
You could try Clang's sanitizers (ASAN and friends).
[removed]
Yikes. Don''t write parsers in C in the first place, perhaps? There are so many better choices on that front (obviously rust if speed is a concern).
&gt; And can be expensive. So is losing 2/3 of your market capital overnight. 
Firstly, you'd need an LLVM backend: http://llvm.org/docs/WritingAnLLVMBackend.html
This really isn't surprising. Running a program in an interpreted language is always going to be significantly slower compared to a compiled one. And if csvkit was poorly optimized, well there you go. I mean, the comparison isn't en fair. It's like comparing a golf cart to a sedan.
LazyCell has a different API. Same underlying behavior, and you can build LazyCell using OnceCell.
They weren't using C *directly*, right? It was generated code.
Ah, well, that's a very unfortunate overlap between the security community and the programming community (I feel like the confusion extends to anywhere with more "normal" programmers than security experts).
Documentation is great, for when you know what you want to do. It's less great when you're trying to learn the idiomatic way to e.g. implement some algorithm. 
Could you combine that with `find_iter` from the `regex` crate? I think it's been described as "absurdly, almost irrationally fast". Though you'd have to come up with a regex for doubles.
Why does it support `decltype`? I thought `decltype` meant "dear compiler, please figure out the type here before you finish compiling". How is it useful if you still don't know the type by link time?
Genuinely curious why you want this .. retro sega consoles ?
https://xkcd.com/1656/ ?
[Image](http://imgs.xkcd.com/comics/it_begins.png) [Mobile](https://m.xkcd.com/1656/) **Title:** It Begins **Title-text:** You can also try 'Yikes\.' [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1656#Explanation) **Stats:** This comic has been referenced 81 times, representing 0.0540% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_de63g9i)
It's not buffering in memory, a temporary file is used. The plan is to buffer in memory for x bytes then switch to a temporary file in a future version as a performance optimization. 
Regarding package distribution: what more can you really do? The best I can come up with is have cargo verify the certificate itself rather than just https-ing and trusting the CA.
The design of Rust doesn't deal with memory leaks in any way. While leaks are a memory problem, it isn't actually unsafe to leak memory, since leaking memory can not cause any memory unsafety bugs. Furthermore, leaking memory is easy in safe Rust. Just create a cycle of `Rc`s and let it go out of scope, or call `mem::forget` on a heap-allocated object. Those are two simple ways to leak memory in safe Rust code. In fact, a while back `mem::forget` used to be marked unsafe, because memory leaks were thought of as a memory unsafety issue. However, people later realized that memory leaks can not be eliminated from safe code in Rust, like other memory problems can, so they decided that leaking memory should not be marked "unsafe" in the language.
That's true, but right above the example is the following text: " This crate provides a LazyCell struct which acts as a lazily filled Cell, but with frozen contents. With a RefCell, the inner contents cannot be borrowed for the lifetime of the entire object, but only of the borrows returned. A LazyCell is a variation on RefCell which allows borrows to be tied to the lifetime of the outer object. The limitation of a LazyCell is that after it is initialized, it can never be modified. " I guess that's more of a "what" than a "why", but I feel like the uses of this library are kind of obvious if you read that and you *know* where you could personally use it. I'll see if I can't find some more specific examples on why it is useful though.
Making sure that `unsafe` is as limited in scope as possible, and has its invariants well-documented is a good start. 
Because if CloudFlare doesn't terminate the SSL at its own edge servers, it can't provide many of its services.
&gt; The visitor pattern is used pretty heavily in certain kinds of Rust programs, like the compiler. Well yes but it comes natural to the language, you don't need a pattern for it (I haven't looked at the compiler code, though, they might put some additional smarts on top of that). [c2 has a good, short, explanation](http://wiki.c2.com/?ExpressionProblem).
&gt; l yes but it comes natural to the language, you don't need a pattern for it Hm, maybe we are meaning something different by "pattern." What I mean is "hey my code has this structure, so I've given it this name."
&gt; In my mind "pattern" is a term OOP people give to techniques that allow their languages to express non-native concepts. Yes, agreed. Is there language support for Visitor somewhere? Anyway, thanks for elaborating, generally :)
So I'm attempting to reimplement a programming project I created for a C++ class into Rust, and I'm having issues getting the item I need out of an Option&lt;Box&lt;String&gt;&gt;. An example: pub fn get_server(&amp;self) -&gt; String { self.server_name } Here, 'server_name' is of the type Option&lt;Box&lt;String&gt;&gt;, but I need it to return as a String. How do I get at that, exactly? I've read through several sources, but this isn't getting any less confusing to me.
It's missing `$c` in the middle
This port is not very stable (source: http://lists.j-core.org/pipermail/j-core/2017-February/000509.html) . There are sometimes problems but you can contact the author of you want to contribute. Also the J-core mailing list may be a better place for discussions about SuperH and open source. 
I've ended up using a custom parser for detecting number length and then putting it into `f64::from_str`. I don't think that regex will be faster. And adding a new crate just to perform one simple job is too much.
`rg '^pub extern'` I guess
[This post](https://eev.ee/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/) does a really amazing job of describing my views regarding object oriented programming. OOP isn't about classes. It isn't about inheritance. It isn't about polymorphism. It isn't about the Liskov Substitutability Principle. OOP is about objects, and objects are bundles of state and behavior. And anything that only has one is a poorly-designed object. Inheritance, meanwhile, tends to encourage creating classes which describe poorly-designed objects - ones with no state at all and only behavior (comparator classes are a plague), or only state and no behavior to be seen (having one class per `Job` type, as described in the post.) "Rust &amp; OOP", to me, thus means "the tools Rust gives me for smithing state and behavior into nice, coherent little bundles" - and for this, traits/typeclasses are the single best OOP tool I've used. (Rust introduced me to them, but there are some fascinating things you can do with nullary typeclasses, or partially-applied typeclasses, which Rust does not support). (I also posted this on [the linked u.r-l.o thread](https://users.rust-lang.org/t/what-does-is-rust-oop-mean-to-you/9633/22))
As burkadurka said, Box&lt;String&gt; is pretty useless since all Strings use heap store anyway, but. An `Option&lt;T&gt;` is one of two things: `Some(t_val)` or `None`. You can get at the `t_val` two ways. 1. Unwrap it with `self.server_name.unwrap()` If you call `.unwrap()` on ` Some(t_val)`, it will return `t_val`. If you call `.unwrap()` on a `None`, your thread will `panic!` and crash. 2. Match it with `match self.server_name { /* ... */ }`. let myname = match self.server_name { Some(name) =&gt; name, None =&gt; String::from("localhost"), }; If `self.server_name` is `Some(thing)`, then `myname` will be assigned to be the `thing` within it. If `self.server_name` is `None`, then `myname` will be assigned to be a new String containing the phrase "localhost". 
For most OOP type tasks people want *Dynamic Dispatch* which is really well covered in the current book. You have a trait, and you have types that implement that trait in a trait object. For *inheritance* there really is no good model to explain it in Rust. Rust just has *no system* that models Inheritance well. I get there is a lot of flak against Inheritance, and I'm one of the first person to argue this. I hit this problem last weekend. So story time: I was attempting to make an assembler, and working with an enum left me with a &gt;1000 case match statement. My next attempt was to make each Op a Type, and build a trait object to abstract over all internal behavior. But then defining the *2 dozen* or so methods to encode all the behaviors really could use inheritance to prevent me from typing out the `fn weirdly_specific_behavior(&amp;self) -&gt; Option&lt;BehaviorEnum&gt; { None }` a couple dozen times for *every class*. Then breaking into a &gt;15 deep match for all the different AMD64 address modes, that behave differently, or are/are not allowed. Ended up with this weird system where I have 8 intermediate traits, which build ~20 different *trait objects*, which all implement the same trait, so everything can fit into 1 trait object. It felt like a horrible hack and I just got way too discouraged to continue as now I still had to type out _every_ opcode. [Here is a ugly sample that likely won't compile/isn't correct](https://play.rust-lang.org/?gist=99169050df151433f49083a98e2298b2&amp;version=stable&amp;backtrace=0)
The nice thing about the LLVM project is that `rustc` doesn't need to be terribly aware of the physical machine on which its code will eventually run; it just needs to make informative LLVM IR and then LLVM will do &lt;black magic&gt; to it. `rustc` can make LLVM's job harder or easier depending on the quality of IR produced, and so the compiler team strives to give LLVM all the information it needs to make good decisions without flooding it, but ultimately the actual machine code is entirely LLVM's bailiwick.
Two problems here. One, `Table::set_timer()` is defined as taking an `&amp;self` first reference, which means you need to call it either using method syntax `table_instance.set_timer(duration);` or fully-qualified syntax `Table::set_timer(&amp;table_instance, duration);` Even when you're inside an `impl StructName` block, free functions still have to be qualified as `StructName::function`. Example from my code: impl Frame { pub fn collect&lt;I&gt;(src: I) -&gt; Vec&lt;FrameBuilder&gt; where I: Iterator&lt;Item=u8&gt; { let mut ret = Vec::new(); // free function requires Struct::fn() scoping let mut tmp: FrameBuilder = Frame::start_blank(); for b in src { // instance method does not if tmp.is_full() { ret.push(tmp); tmp = Frame::start_blank(); } tmp.append(b); } if ! tmp.is_empty() { ret.push(tmp); } ret } pub fn start_blank() -&gt; FrameBuilder { /* ... */ } } impl FrameBuilder { pub fn is_empty(&amp;self) -&gt; bool { /* ... */ } pub fn append(&amp;mut self, byte: u8) { /* ... */ } }
I worked with Smalltalk and Delphi a lot, and never found any problem with OOP. The most common cases that I use it for in Delphi (Object Pascal) is: 1) printing data and reports. 2) storage (read/write), also read/write of lists and links. 3) internal hyperlinks. (text and images that link to internal data). 4) drawing diagram elements. 5) translation. The nice thing is that if one thing works, it all works (most of the time ;-). A part of this seems hard with Rust's memory system, because a lot of the links are to mutable records. I manage the records/objects with a global delete or update function. I do not know how I can implement this in rust yet. The main way I use OOP is to declare a dynamic interface on a specific behaviour. This allows different implementations and use cases of that behaviour. What I don't use: - multiple levels of inheritance. - "private" or any other protection of data. - setX / getX In some cases I could not use OOP without severe dependency injection. Like: find certain types of items. In Smalltalk this might be easier, with the use of closures and duck types. Maybe someone else knows if that gives problems. In Delphi I used conditions (if then else/ case-statements) to test every possibility for those cases. Generally it is a good idea to separate behaviour and model. Which is something Smalltalk already had thought of, and implemented in the Model-View-Controller pattern. In a functional language like ELM we see this pattern again. I think that object oriented design can be used to describe a certain architecture. It means for me that we separate our program in different layers and sub-systems. OOP can work if we use it to describe behaviour (like: read/write). But not if we use it to hide state everywhere in our program. Change of state often needs some management on global level. 
Objects are a poor man's closure, and closures are a poor man's object.
Thanks again! Now it seems I have some "cannot move out of borrowed content" errors, as well as "cannot borrow immutable Box content as mutable". These functions produce "cannot move out of borrowed content" //get server name pub fn get_server(&amp;mut self) -&gt; String { self.server_name.unwrap() } //get timer pub fn get_timer(&amp;mut self) -&gt; u32 { self.party.unwrap().get_time() } //get the party seated at a table pub fn get_party(&amp;mut self) -&gt; Box&lt;Party&gt; { self.party.unwrap() } And this function produces the "cannot borrow immutable `Box` content `*new_party` as mutable" error: //seats a party at a table pub fn seat_party(&amp;mut self, new_party: Box&lt;Party&gt;) { self.set_timer(new_party.get_time()); self.party = Some(new_party); } Apologies if I've missed anything in your code that could lead me to a solution. I'm quite tired at the moment, but still chuggin'. 
e.g. lambdas have unnamable types, but you can still decltype them, and when generating the object files the compiler has to give them some type name so that they can be linked. Plus they can also decay to function pointers when they are not closures.
&gt;&gt; And can be expensive. **This is a trade-off between performance and functionality,** &gt; &gt; So is losing 2/3 of your market capital overnight. The cost of zeroing memory is negligible, until you multiply it by a supercomputer scale, or google/facebook scale, and then realize that fuck, that second actually costs a lot of $$$.
&gt;When I said the set was closed, I didn't mean the instruction stream - I mean the kinds of instructions that can occur in it. This is really the problem and you aren't acknowledging or understanding it. So RFC1450 still requires I implement ~5-6 traits (which if I have 10 platforms, so 50-60 traits with *specialties*) for all 1000 enum variants. This is no different in the slightest then implementing 50-60 traits (5-6 traits, 10 platforms) for 1000 types. The only different is the `enum` declaration requires you really can't run intermediate tests until you finish pounding out an entire subsection of execution. Because if you make a mistake of declaring a whole enum you get compiler errors until *everything* in the subsection is well formed. This is where inheritance is useful (*I begrudgingly admit*). As I can just define super classes, and selective over load co-variant return types, for different implementations and promises. :.:.: Actual you maybe right. I'll dig into this thanks for the suggestion. 
`OnceCell` isn't `Sync`. Does that prevent you from building `AtomicLazyCell` out of it?
&gt; I wrote a Ruby lexer in Ragel and I'm pretty sure there are some states I've missed still, even though it parses more or less all Ruby code in existence. I am pretty sure MRI's parser still has vestigial rules that don't even work, so... yeah. It's tough!
Wrong subreddit /r/playrust
Yeah, that would have to be implemented from-scratch.
Reading this thread, I am reminded of a famous [anecdote](http://physicshead.blogspot.com/2007/09/feynman-vs-essential-objects.html). Is a brick an object? :)
Heh, I'm actually pretty into process philosophy, though more Deleuzian than Whitehead... I argue OOP is a failure because Plato's essentialism is a failure, but that's neither here nor there. (This is of course an extremely brief and kinda dumb summary, whatever...) Thanks for the link; I hadn't heard this story.
Whereas algebraic datatypes (`enum`, `struct`) map to [initial F-algebras](https://en.wikipedia.org/wiki/F-algebra), objects map to [terminal F-coalgebras](http://www.cs.ru.nl/B.Jacobs/CLG/JacobsCoalgebraIntro.pdf). In laymen's terms, and as /u/vitnokanla discusses, this means that objects are essentially state machines.
Thanks again! Looks like, with your help, I've managed to fix all my issues. Hat's off to you, sir.
I wish you luck, but C definitely isn't the easiest place to start writing parsers. Wikipedia's [The lexer hack](https://en.wikipedia.org/wiki/The_lexer_hack) page is a good example of its most famous tricky bit.
Wouldn't Nom qualify as "lexerless parsing", therefore avoiding that altogether?
This looks like a great chapter. Perhaps it could be named "Rust for OOP users" or "OOP patterns". Here are some ideas * Pros and cons of enums in comparison with boxed traits (and perhaps long lived references) * Structs containing enums (as an alternative to wrapping). * "Can objects contain references to eachother without causing borrow checker problems?" (Use refcell or a custom container or store indexes instead of references or restructure the code) * Implementing a method on a field of a struct rather than on the struct itself to avoid borrow checker problems. Example let Foo { ref mut bar, ref mut baz} = foo; bar.do_stuff(baz); EDIT: Perhaps a part the chapter could be structured around user stories * I want to write a general function that can be applied to any object implementing a trait. (Generics?) * I want to create a container of objects implementing a trait. (Enums/Trait objects) * I want to downcast an object to its parent (Enums/Trait objects?/Rethink the code) * I want to delegate a method to a parent (specialized trait/custom_enum_derive/structs with enum fields) * The borrow checker complains about my OOP patterns (RecCells/Restructure the code/visitor pattern/implement traits on fields) 
If you're only doing statically analysis, you could write a [Dyon](https://github.com/pistondevelopers/dyon) script to do the analysis and code generation. If you are familiar with Javascript and Rust, it will not take a long time to learn Dyon. [Link to tutorial](http://www.piston.rs/dyon-tutorial/). Dyon has built-in support for meta syntax (use [load__meta_file](https://github.com/PistonDevelopers/dyon/blob/master/src/lib.dyon#L255)). Dyon has mathematical loops that make analysis and problem solving easier. You can also use the link data type and loop to generate code in a readable way. The meta language is [Piston-Meta](https://github.com/PistonDevelopers/meta) which is a PEG-like language but with high-level grammar blocks such as found in JSON. An advanced example of using Piston-Meta is [Dyon's own syntax](https://github.com/PistonDevelopers/dyon/blob/master/assets/syntax.txt). 1. Call `load(meta: syntax_file, file: shader_file)`. This gives you an array of data. 2. Transform from the array of data into an AST. 3. You can look at the [functor example](https://github.com/PistonDevelopers/dyon/blob/master/source/functor.dyon) for a way to save code when doing AST transformations. 4. Print out with `str(link {"void main() {"body"}"})` or `str(link i {lines[i]})`. Once you have a working script and want something more robust, you can rewrite it in Rust. Use the [read_token](https://github.com/PistonDevelopers/read_token) library if you prefer hand writing a parser. Or, you can just use the [Piston-Meta](https://github.com/PistonDevelopers/meta) library. Even if you do not choose to go with Dyon, learning Piston-Meta helps you think about the complexity of shader code and what stuff you need to write in your own parser.
&gt; &gt; &gt; &gt; &gt; Is there a way to put guards in the source code that will detect compiler version, so that the benchmarking code will be ignored when seen by the stable compiler but activated when seen by nightly? I prefer to use cargo's support for benchmarks directly; put your benchmark tests in `benches/`, and then only run `cargo bench` on nightly. `cargo test` and `cargo build` won't ever see the benchmarks, so they work fine on stable.
You're moving out position_tex into the struct field at last, invalidating the reference. I'm not sure with an easy way to deal with this, since Rust barely allows a field in struct referencing another field.
Which reference? Is it where I create the prepass_fb? That's the only reference I see. Are you saying that prepass_fb has a reference to position_tex that gets invalidated on return? I'm not sure how MultiOutputFrameBuffer::with_depth_buffer() works, but I need to keep the texture and the framebuffer around for later use.
If you don't have references or a preprocessor it shouldn't be so bad. C-like isn't hard to parse, C is
&gt; nullary typeclasses I'm not familiar with Haskell, but can't you achieve the same effect in Rust by defining a trait with only static methods and impling it on a dummy type? The syntax isn't particularly nice, but you can certainly do it.
Yup and I can't make it to that one either... 
&gt; I find inheritance is more useful to take advantage of as a client, than as an implementor. Don't you mean "polymorphism"? (I.e. "interface inheritance") &gt; I find it kind of incredible how very poorly encapsulated data really can end up in Java and C++. I don't disagree, but I think "encapsulation" is the wrong way to look at things. Sure, if you have some real *external* stateful thing, then encapsulating data pertaining to talking to that thing into a-different-thing-with-methods-only seems like an obvious win. (Even so, you can get all the same benefits by just having an abstract/non-exported type and having functions operate on that type. That's also encapsulation and doesn't come with all the same baggage as OOP.) However, the *vast* majority of the time, the value of data is that **it is data**. Data doesn't need encapsulation, it just needs a sensible (type) *definition. So far (Generalized) Algebraic Data Types seem, to me, like the best way to do that. TL;DR: Implementation inheritance is overrated, as is encapsulation. There are better approaches to achieving the same goals.
The lack of self-borrowing structs is a common problem of Rust. However in this situation glium caches the framebuffers and creating a framebuffer object will load an existing framebuffer if possible. Therefore you shouldn't hesitate to destroy and recreate your framebuffer object every time instead of storing it in the struct. 
Yes you can! You can actually do that to any number of arguments, but it's not useful except in this one particular corner case.
I think saying "you need to be very comfortable with Ragel to build an HTML parser that could run on a large fraction of the web's traffic" is pretty sensible. If you're not familiar enough with the tool, reuse something that's existing (and that's what they did for a long time). The fact that Ragel allows that kind of bug to appear is the debatable point for me. Like, in nom, you can very easily make your own parser with very unsafe behaviour: just write your own function `fn unsafe_parser(input: &amp;[u8]) -&gt; IResult&lt;&amp;[u8],&amp;[u8]&gt;`. And it feels ok to me, because sometimes you need that unsafe behaviour, and the library should allow it. But when you're writing that kind of function, you're explicitely not using nom's combinators, that are designed for safe data consumption.
&gt; I suppose I could have been more accurate to say that design patterns were entirely native to OOP programmers. Ah, I see what you mean. Agreed.
you can take some inspiration from [rust-cexpr](https://github.com/jethrogb/rust-cexpr) which uses an old version of nom. Making a nom parser from an EBNF grammar is usually straightforward, you make one parser for each subpart, and combine them as larger and larger parsers. Keep a lot of code examples for the parts each parser covers, and test them independently: it's much easier to debug small expressions.
You could look at using like llvm to parse c for you. And extract the ast from that
Ah, I must have misread then. Great :D
Write a small pub fn that just returns it or uses it somehow. Sucks but should work I think.
Scala is the result of wanting to marry parametric with subtype polymorphism, and they've created a monster. I don't know F# at all.
You can dot with plain old C too.
In a trivial test, adding `#[no_mangle]` worked for me. I guess rustc thinks that if you leave the precise name up to rustc's whims, you can't expect to find your constant again.
Is there a function to turn `Vec&lt;Result&lt;PathBuf, String&gt;&gt;` into `Result&lt;Vec&lt;PathBuf&gt;, String&gt;`? In Haskell there is that handy function called sequence which does that kind of conversion`Monad m =&gt; [m a] -&gt; m [a]`. Right now I use a fold function, is there some better way in Rust?
I wrote this (working) code, but I feel it's not very idiomatic. Here's a condensed pseudo-version: let width: usize = 5; let length: usize = 20; let index: usize = some number from 0..length (this is in a loop) match index { 0 =&gt; { // top-left corner indices.push(index + 1); indices.push(index + width); indices.push(index + width + 1); } index if index == (width - 1) =&gt; { // top-right corner indices.push(width - 2); indices.push(2 * width - 2); indices.push(2 * width - 1); } index if index == (length - width) =&gt; { // bottom-left corner indices.push((length - width) - width); indices.push((length - width) - width + 1); indices.push(index + 1); } ... _ =&gt; { // It's a well-behaved index // and push the surrounding 8 indices into a Vec } } Basically, I've got a `Vec&lt;usize&gt;` that corresponds to indices within a different `Vec`. This is the code that deals with all the edge cases, and it's really ugly. In particular, I don't feel good about the `index if index == ... =&gt;` stuff that's going on here, but I don't know how to get it to match the edge case without doing that. Writing this: match index { 0 =&gt; {} (width - 1) =&gt; {} (length - width) =&gt; {} ... _ =&gt; {} } doesn't compile like I expect it would. What's the more correct way to do this? Just a long `if`-`else` chain? 
Type inference falls apart in F# once you start using objects. In that way, objects are second class citizens in F#.
Also, if you reuse buffers like [CloudFlare does in Go](https://blog.cloudflare.com/recycling-memory-buffers-in-go/), you can potentially still leak data.
Looks good. When is version 11 coming with the new ui changes? Screenshots on GitHub need updating btw, those seem really old.
That depends on where you draw the line for "simple". I don't have experience with Lisp or Forth and it tends to be the [little things](http://blog.reverberate.org/2013/08/parsing-c-is-literally-undecidable.html) that are difficult to recognize at a glance which make grammars difficult to parse, so all I can say is that Lisp looks like a good candidate for "simple to parse".
Wow, how did you manage to offer the student ticket at that price? Previous RustFest's price was at 100‚Ç¨ IIRC
Wrong sub
Right, let's try something concrete and solid (pun intended). The vast majority of inheritance uses are in various helpers. In such cases, inheritance can be replaced by composition fairly easily. Consider the following example, where calculating the "count" of items is CPU intensive operation, so we want to keep pre-calculated value in the class. We also want anyone who extends the class to change the items, but this method should not be public. class Base { private int itemCount; private Container items; protected void setItemsInternal(Container items) { // this is protected so that only those who inherit this class can set this! this.items = items; itemCount = items.count(); } public int getItemCount() { return itemCount; } } class Pub : Base { public void setItems(Container items) { this.setItemsInternal(items); } } We can achieve the same goals with composition. First, we extract the logic to precalculate count from the base class into a separate class: class PrecalculatedCount { private int itemCount; private Container items; public void setItems(Container items) { this.items = items; itemCount = items.count(); } public int getItemCount() { return itemCount; } } And use composition to encapsulate precalculation in Pub class: class Pub { PrecalculatedCount items; public void setItems(Container items) { this.items.setItems(items); } public int getItemCount() { return this.items.getItemCount(); } } We now have a bit of more code, however: * Both classes now are more testable * They have better names * They do one thing ("S" letter in SOLID), better responsibility separation * Base class logic is now more reusable and does not require inheritance! You may be reluctant to do this in other languages, because: * More objects sometimes means slower code, because of the allocation overhead. Not a concern in Rust, because the structs are _inlined_ into a single memory block, and the same is true for small methods. * In some languages more objects means more files. Again, not a concern in Rust. * Delegating to inner object may be annoying. However, Rust deref coercions might help here. And really, if there is nothing besides the delegation, maybe the wrapper class is not needed _at all_? Extracting the logic this way in real code might not be easy, because in such object hierarchies tend to be way messier than in the example above. The other use of inheritance is what is sometimes called "yo-yo" case. It's when base class methods can be overriden by anyone in the object hierarchy. I consider this to be super evil, because it introduces unpredictably shared mutable scopes by design. I do not know how to explain it other than say that uses of this kind of inheritance usually violate Liskov substitution principle and makes logic very hard to follow. See, I can't even think of any reasonable example other than some kind of hack. The problem is, OO teachers usually tell that being able to override any method is _the whole point of OO_. However, we can see that good industry practice disagrees with that, with the recommended avoidance of virtual methods and "final" keywords.
If you're real terrible, you can even invoke method syntax in C If you do this, I hate you, but you *can*.
Not for students tickets. Full tickets were &gt;100 Euro, Students were less. That was already a personal loss for me, as 100 Euro is a magical barrier for me. I want confs to be cheaper then that for 2 days. First of all: Kiev is much cheaper when it comes to venue lease and catering. Second: for any supporter ticket we can sell, we can sell reduced tickets or add other perks. In general, the conferences I help with are calculated so that the whole conference can be covered by ticket sales in a bare bones fashion (lunch and drinks, venue for a day, no party, no alcohol). This makes us independent of sponsors. Obviously, if we do have sponsors, the thing will just be better. In Berlin, given more time and preparation, we could have made &lt;100 happen, but I'm quite okay with what we ended up with. 
Thanks for the answer. FWIW I didn't think of the RustFest 2016 ticket prices as expensive, but also didn't think that the location (and the difference between Berlin and Kiew) would affect them so much.
Yes
Which is why I'm asking why or how csvkit being slow matters at all. I just looked at the source and its pure Python. Of course using a lower level language is going to be faster. What I'm saying is that if you just expose Python bindings, then now Python is just as fast. Comparisons like this just totally miss the point.
To me, Rust isn't object oriented. For me, it feels like the defining characteristic of an OO language is inheritance and that's kinda the prevailing opinion I see on the internet. I know that isn't the most correct description of OO, but it might be an exercise in futility to convince people over by trying to brand Rust as OO when inheritance is the thing they're really looking for. At the end of the day, they actually can't build programs in the same way because Rust decided not to support that and that's okay. "Rust &amp; OOP" sends the wrong message to me but that doesn't help you bridge a gap :p I tend to view programming as operations over data. I have a set of data objects and a set of functions that I can apply to them. Objects and inheritance are one way I can describe which functions accept what data and what objects have common interfaces. I tell the object what abstraction it belongs to. In Rust, you tell the abstraction what objects belong to it. You actually even get a bit more than that because the level of granularity is at functions instead of groups of functions. When I inherit IFoo, I've committed that data object to all of IFoo's functionality even if that's not desirable. In Rust, when I add a data object to a trait, I've only committed to that trait. I can selectively commit to IFoo instead of having to accept all of it.
Good to know. Thank you!!! Also, thanks for writing such a simple (to use) GL library! Can't wait to use Vulkano once it matures a bit (and I get a new laptop).
Nice post. I want to get into Rust development as well, but I mainly do web development right now, so it's hard to find projects I can use it for.
Yes
 rustc 1.15.1 (021bd294c 2017-02-08) sha1: 06af88802e219f254ecb2ebf8b4e5b410937be10 cargo 0.16.0-nightly (6e0c18c 2017-01-27) sha1: 06af88802e219f254ecb2ebf8b4e5b410937be10 I presume cargo and rustc just change their behaviour based on the invocation, because they definitely have the same hashes and filesize.
You're actually getting the hash of the rustup proxy binary rather than rustc and cargo themselves. You need to look in `toolchains\nightly-x86_64-pc-windows-msvc\bin` (or whatever your host toolchain is) to find the actual binaries to get their hashes. I strongly recommend avoiding any third party AV. Just stick with Windows Defender and follow general safe practices like not installing flash or Java and you'll be fine.
ha, i knew there was an overlap between rust and elm users! you wrote you could not be happier with rust, have you had a look at [domafic](https://github.com/cramertj/domafic-rs)? it seems that right now any http requests (therefore communication with the server) is in development, so it would not cover your usecase yet, but maybe you can give some feedback/guidance on how to do things and reduce frontend/backend missmatch and stuff!
 cargo 0.16.0-nightly (6e0c18c 2017-01-27) sha1: 8CF6D005C074D69297D5E6D2813DDDBE67599166 rustc 1.15.1 (021bd294c 2017-02-08) sha1: 4B2844412B9A535F6CE20B7A1015873E1F2540CA
For the first snippet you can use `and_then`. You'll find it's pretty common in Rust code: let extension = Path::new("foo.bar").extension().and_then(|e| e.to_str()).unwrap(); For the second one you should use `.values()` instead of `.iter()`, but in general you could use `map()` to transform the values you get from the iterator. See https://is.gd/kDNUb3 for both ways. And finally, you can format stuff as code on Reddit by wrapping it with backticks: `like this`
Does this return the first error it encounters?
Some of this is out dated but it's a great resource none the less. It's the [Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/README.html) and it might be a great start to learning them. The way I look at macros is it reduces boiler plate code that I might reuse constantly but isn't suited for a function. They can be magical but the idea is that it reduces the bed to write everything it over and over again. If you start to understand them you'll have a very powerful tool in your arsenal that you'll find missing in other languages. Best of luck!
Mark it `pub` recursively? I've faced similar problems here: https://github.com/purpleposeidon/v11/blob/master/src/constructor.rs#L44
[Yes.](https://github.com/rust-lang/rust/blob/master/src/libcore/result.rs#L1090)
Forgive me if I've missed something obvious, but could you put something in the docs that explain how the tool works? It looks like it analyzes code to look for the tags defined in that TOML file, but is that the only way? Can you mark progress manually, rather than needing to pepper your whole codebase with these tags? Are languages other than Python supported? Is it only in doc comments? Which ones? What is the specific format it looks for?
Glancing at it it looks great! Very elm like, which is good :) I don't think I know enough about asm.js to give much comment, but I like where it is going. Frontend development in rust would be AWESOME and probably really fast :) 
Yup! And I'm much more into that style. You're right that this was a bit too glib ;)
The primary goal is to be able to write your design docs, link them together and then link where they are implemented in source code (and be self documenting while doing so). The hope is that the links aren't "litering" your source code, they are helping to document how your source fits into your design! It works with any unicode text file. It literally just searches for #ART-name like things and links them. I opened an issue for your concern, I would love your thoughts! https://github.com/vitiral/artifact/issues/66 I'll try to improve the docs too, specific feedback is always nice to get.
Note that the venue in Berlin was sponsored by Microsoft. Usually, a venue in Berlin costs you easily 8.000-15.000 Euros per day without catering, with a downpayment of at least 50% immediately after the day of signing. And that's no fancy hotel, I'm speaking theatres and such here. eurucamp, the conference I ran before, was a three days event usually run at universities(!). It had a production price of 70.000 euros for a 300-500 person event with 20 speakers, single track. This is the price when you do all venue services except cleaning and catering yourself (spelling: for free, with lots of time and love)! Also note that things like video production and similar are easily in the range of 5 figures, too. So, if anyone every wants a good suggestion on when to sponsor a conf: very early, before the first downpayment happens. The production team will be eternally grateful and recommend you in every corner of the world. Have I mentioned that I love Microsoft for understanding that and just letting us in their venue?
&gt;The primary goal is to be able to write your design docs, link them together and then link where they are implemented in source code (and be self documenting while doing so). The hope is that the links aren't "litering" your source code, they are helping to document how your source fits into your design! Right, this totally makes sense, though there will likely be people who want to use this tool without needing to couple it very closely with the source code, especially if they're just trying it out to see if it would work well for their project. Also, if people want to use artifact for large, existing codebases, the prospect of retroactively tracking down everywhere these tags go could be daunting. 
&gt; Comparisons like this just totally miss the point. No, actually, they really don't. From an end user's perspective, they mostly don't care what language a tool is written in. All they know is that `xsv` is a lot faster than `csvkit`. Rust is a big part of that. Nobody is missing any points here. &gt; What I'm saying is that if you just expose Python bindings, then now Python is just as fast. Actually, that's not at all obviously true to me. If your Python bindings are converting from/to Python objects, then that overhead alone is going to hurt.
Shout out for the IRC channel. I had a basic question about pass by value vs reference and someone set me straight about 10 seconds after I asked the question, and in the most helpful and friendly way. 
whoa, thanks. It's funny because I use Vimium too but I never noticed that. I actually just recently have the ability to embed an entire link, but then use custom click logic to keep everything single page. https://github.com/vitiral/artifact/issues/67
because it's old and needs to be updated. There was a time where you needed elm to install through cargo. I'll update that now. Thanks. Edit: should be fixed
Nothing wrong with Java, as long as you keep it away from the browser.
Doesn't matter if you have a separate lexer stage or not, parsing a context sensitive grammar is parsing a context sensitive grammar.
Wow, thanks for the pointers. I'll definitely try it out on my next project.
I think the important part is gonna be not how to approximate some OOP programs using traits and stuff, but to spell out clearly the fundamental differences between what is natural/trivial in an OOP design and what is natural in Rust. Just teaching people how to transliterate some class hierarchies into Rust is gonna leave them fucked when they realize they actually needed some weird downcasting, shared ownership scheme that doesn't work out nicely at all or something. I'm hoping for some stuff like "here's the Gtk widget class tree, they use OOP to achieve these goals here, and this is how you'd let people do the same thing in Rust", but maybe actual case studies are a bit out of scope.
You could also just put a `CondVar` from the stdlib around the queue, I guess.
/r/playrust
As soon as they have entered the public domain for even the shortest amount of time with the context of being a password (like /u/isHavvy) mentioned; they probably get immediately thrown into a giant word list somewhere by someone.
It looks like you're trying to mention another user, which only works if it's done in the comments like this (otherwise they don't receive a notification): - /u/bjzaba --- ^I'm ^a ^bot. ^Bleep. ^Bloop. ^| ^Visit ^/r/mentionhelper ^for ^discussion/feedback ^| ^Want ^to ^be ^left ^alone? ^Reply ^to ^this ^message ^with ^"stop"
&gt; which sometimes breaks your https Just recently a group [released research](http://www.zdnet.com/article/google-and-mozillas-message-to-av-and-security-firms-stop-trashing-https/) grading and showing how pretty well every AV is breaking HTTPS.
Sometimes you have to be able to test your code on Windows as well.
[removed]
thanks
It needs to be pub and accessible from the outside -- pub use it from the toplevel lib, if it's pub but in a priv lib it may still not work.
So it won't work if inside the scope of a function?
No.
No, you can keep the data if it is publicly exported. Don't use unsafe to make this work. You don't need it. Just publicly export the static somewhere. You don't need to use it, just define it in a way that it can be accessed by dependent crates. Sticking it in lib.rs is one idea, or you can put it in a private module but then publicly export it from lib.rs.
Ah, well, then. There's not much you can do since you can't make anything publicly accessible there. One trick that might work is just writing `drop(YOUR_STATIC)` in the code. If that doesn't work; `#[inline(never)] fn use&lt;T&gt;(x: T) {} use(YOUR_STATIC)`.
Thanks for the first answer, LGTM. About the second question, maybe I did not express myself correctly, if I were to do this in Ruby (I assume Ruby is very readable), I'd do this: `my_hash = { 1 =&gt; [1, 2], 2 =&gt; [10, 20]}` `hash_with_good_data = my_hash.select{ |key, value| value.include?(10) } ` And now I can do anything with `hash_with_good_data`. In my case I want to get the key. Said in other way, how can I get the key of a HashMap which value fulfill certain condition? Using a map seems very inefficient. 
It seems to work in debug, but not in release
&gt; I'm curious, is there any kind of indication in the type of the framebuffer objects which would indicate that they're cached in this manner? I'm new to using glium and this is news to me. No, I think it's only written in the docs. 
[removed]
https://reddit.com/r/playrust is what you want
Neat! Currently all my server side stuff is written in node, and although I love it, I have been itching to learn a new language as well get into systems programming. I am still not sure what my main use of rust will be, but I will figure it out as I learn more. 
You can also disable it via group policy! The easiest way IMO: http://m.windowscentral.com/how-permanently-disable-windows-defender-windows-10 Be aware though, in recent versions of Windows the group policy entry isn't necessarily named "Windows Defender" anymore but "Endpoint Protection".
_Really?_
`find` is just what I needed, thanks!
While I agree with the comments so far, this does need a real fix at some point. How am I supposed to explain this to an angry customer?
Nice, but why is perlin implemented and used in the example while simplex isn't? Simplex noise is its successor, is faster, scales better, has gradients, ‚Ä¶
Probably to curtail spam. Making it work in titles/posts is a backburnered issue for the Reddit devs.
True - spam is just the justification/reasoning I've seen, though the real reason may be technical. Reddit's messaging system apparently made comment-based mentions simple, whereas it's very different for titles and posts. This is sometimes [brought up in /r/ideasfortheadmins](https://www.reddit.com/r/ideasfortheadmins/comments/3ru60o/receive_a_username_notification_from_mentions_in/).
This might be a personal solution, but some companies mandate AV and from the point of view of the Rust project, this is not very helpful.
And yet there is absolutely nothing Rust can do about it. You're much better off complaining to the AV company, since they can at least fix the false positives.
Go complain to the company that made the AV software. They're the ones responsible for the false positive and only they can fix it. Rust can't do shit about it.
Short answer: it isn't! 
I made a video on YouTube about Redox, go to view it: https://youtu.be/0w3zSEOiOcY
That's cool! There will be another release soon with major changes
Are we allowed to have a long answer? The Pumpkin documentation doesn't seem to describe what an "event sourcing database" is or what problems I can solve by using one.
Slightly off topic, but there are ways of running Windows in VM on Linux with performance close to bare metal. Google KVM or XEN with GPU passthrough. It allows to assign a physical graphics card to the VM directly, achieving excellent performance. It can also be done with USB ports and other hardware... Thought you may find it useful. 
Oracle's Java installer is borderline malware.
Thanks for pointing me to nom. Well, I thought since I want to write this in rust I should post it here. Do you think [/r/nginx](https://www.reddit.com/r/nginx/) would be better?
Sure, but it still requires you to boot up what is essentially another system, whereas if I just build it on Windows I double click a file.
I see. That's awkward.
Wrong subreddit, you want /r/playrust 
Awesome, thanks! I actually use arch for my OS, although I'll probably stay on the debug build of artifact myself :) 
[removed]
Well, a quick https://crates.io/search?q=nginx suggests that nothing that specific exists for Rust, so you'd probably be better off breaking it up into two questions: 1. Asking /r/nginx whether their grammar is close enough to some other kind of grammar to substitute another kind of parser. 2. If that fails or crates.io also lacks that other kind of parser, *then* research writing parsers in Rust. (An answer you already got with the mention of nom.)
Or add a feature that people can activate of they don't care about some other country's parent laws.
/r/playrust/
So I guess this is like the journalling part of a journalling filesystem..?
&gt; I support the "core RFC (v2)" part, but what's the point of submitting the 2nd and 3rd parts now, given that they are 100% going to be postponed in accordance with the decision from the previous iteration (RFC 1657)? I would say it serves the purposes of design and documentation. By actually breaking them out into separate RFCs now, the Rust community can get early feedback on the proposals and work on the designs independently. Also it helps show the author's intent with regards to the evolution of the feature, so that as the language continues to evolve, these ideas are considered when working on other RFCs that might interact with them, and vice versa, like the referenced case of HKP. 
Ooh. Great idea, what if we built a virus that would actively go and convert all C code with Corrode to Rust, and then automatically commit those changes to the SCM? We need to fix a few bugs in Corrode so that it would work in all cases, but this would be a great way to increase Rust adoption...
I am so happy about this line &gt; PumpkinScript is a minimalistic concatenative, stack-based language inspired by Forth. Forth is one of my most favorite languages and is still listed on my CV. I would love to see its ideas to make a limited comeback.
Well `Some(mut node) =&gt;` unwraps the node and takes it out of the heap, making it a local. Therefore any assignments you make to it aren't reflected in the actual tree. `Some(node).take()` this also creates a local then destroys it. You want to change the match to `Some(mut ref node)` so you are operating on it in the heap. Then assignments should take the form `*node = ...`
Just to check, are you using `#![feature(test)]` and `extern crate test;`? While test is built in, it is still an external crate when used in your code - you'll need to get it via `extern crate`. You don't need to depend on it in cargo or anything, but it does need to be imported. See https://doc.rust-lang.org/book/benchmark-tests.html.
thanks, fixed
thanks for the reply. I will give this a go
Ok, that explains it a bit better, thank you! Are there any plans in serde to allow customation points for specific features that may be only available for a certain format? So that `Deserializer`/`Serializer` implement a common subset, but if you're writing a `Deserialize` implementation, you can take advantage of some format-specific features as well?
This is already supported. For example it is how the `toml` crate supports deserializing Datetime objects from a TOML-specific datetime representation even though datetime is not part of Serde's interfaces. #[macro_use] extern crate serde_derive; extern crate toml; #[derive(Deserialize, Debug)] struct Doc { timestamp: toml::value::Datetime, } fn main() { let doc = "timestamp = 1979-05-27T07:32:00"; println!("{:?}", toml::from_str::&lt;Doc&gt;(doc).unwrap()); } The general idea is that the Deserializer impl is responsible for mapping whatever input into Serde's data model and the Deserialize impl is responsible for mapping Serde's data model into the corresponding type. So by owning both of these impls, the crate can establish a protocol for transferring format-specific information from one to the other. Same thing in the reverse direction as well - a Serialize impl is responsible for mapping the type into Serde's data model and a Serializer impl is responsible for mapping Serde's data model into the output format - so format-specific functionality is supported there as well.
Thanks for this Ticki. I don't actually have a personal use case for the feature right now but I'm pretty interested in type systems and I love watching one evolve in such a fundamental, careful, and thoughtful way. The first RFC was a joy to read. Same goes for all your work on Redox.
Temporal is as fast as you can get with writes since it is append only. The only issue is updating the index which is most likely a hash lookup.
How can I use dependencies of dependencies? I'm using Iron, and would like to use https, as in their [example](https://github.com/iron/iron/blob/master/examples/https.rs). I've added the feature for "native-tls-example", and *hyper-native-tls* appears in Cargo.lock. However, I'm still getting "can't find crate" when I do extern crate hyper_native_tls; Am I missing something, or is this just not possible? Should I just hyper-native-tls to my own Cargo.toml? I suppose it would work, but in some threads regarding this people seem to have a lot of issues with version mismatches, so I'd rather avoid it if at all possible.
What's a pi type? I haven't been following rust too closely.
Try /r/playrust .
oh sorry, thank you.
&gt; Should I just hyper-native-tls to my own Cargo.toml? Yes, that's the solution. Cargo will only let you explicitly link against crates that have been explicitly declared in the toml. The version mismatch thing is basically that if you update hyper you may also have to update this crate's version. Often `cargo update` will figure out the right combination for you, but in the presence of breaking changes (major version bumps) you may need to manually pick a version that matches. It would be interesting to propose a "{version_from_crate = "hyper"}" key that makes the version an alias for the version spec in hyper.
Alright, thanks for your answer.
Wrong sub, mate.
You want /r/playrust
That would prevent the AV from suffering memory corruption or a segfault. It wouldn't fix the bad design.
That would be perfect, and someone to bounce ideas off and guide me along the path of learning and applying Rust in a real world application.
Ah makes me happy to see `RegexSet` getting usage in routers. Nice work. :-)
Thanks, it didn't occur to me that "KB" might mean memory usage. Intuitively, "KB" is size in kilobytes and "gz" is size gzipped. On mobile and 1366x768 display it shows "KB", not "memory-use KB". Perhaps this could be made more obvious somehow?
I'm not a rust expert, but if Miri is more or less a depth-limited Turing complete subset, then unification will not be _nearly_ as simple as the proposal seems to imply.
Ah, good call. ^^ Thanks bud. :)
We get such mis-posts a lot, so we've learned to spot them. You're welcome.
OK, so that's as I suspected but didn't say before: even though the features were in _nightly_ cargo as of 2017-01-18, they aren't in _stable_ cargo yet (and this is made more confusing by all cargo versions claiming to be nightly). You need to use the cargo distributed with beta or nightly to publish your crate, then the badge and category will show up.
I fixed the compilation (currently only tested on Linux) to compile with stable Rust and a segfault (ah, ffi code) in my [web browser called titanium](https://github.com/antoyo/titanium). I plan to work on [`relm`](https://github.com/antoyo/relm) this week, which is an asynchronous GTK+- and futures-based GUI library inspired by Elm.
Nice. Regarding this required feature for 1.0: &gt; Static files support I'm writing a [pair of crates](https://github.com/scottlamb/http-entity) currently called `http-entity` and `http-file` to do static file serving, including conditional GET and byte range serving. There's a branch for the future hyper 0.11.x interface. My crates are intended to be useful for projects like this; if they're not, please file an issue. (Also, let me know if you have better names. `http-entity` and `http-file` seem too generic, but naming is hard.)
Goodness. Let's see... I need to clean up my tutorial for [gfx-rs](https://wiki.alopex.li/LearningGfx)... I need to actually use it to make [ggez](http://ggez.rs/) drawing better and it's been pointed out some refactoring could happen there... and then I can go back to fixing all the *other* things that need fixing in ggez. Then maybe I can actually use it to make a game?
ermergherd if this works out how it's supposed to it will be *so cool*. Ada-like bounded integers and such, defined as a side-effect of the type system just being that metal? Compile-time type checking of any type constraint that can be expressed numerically? Maybe even actual constexpr's? Heck yeah! ...this is going to send compile times through the roof, isn't it. XD
Creating a Box or Vec, converting into an unsafe pointer, and converting back to destroy, is effectively the same thing, and is the standard way to do it today.
My question isn't about switching out allocators, it's about getting a reference to the malloc function.
Oh damn sorry!
&gt; The only concern I can think of is you will need to keep track of the capacity in order to call from_raw again. Right, that's what I suggested. Unless I'm implementing another data structure to keep track of all the sizes of my allocations (which could be my safest option at this point) I'm stuck with shoving the capacity into the contents of the vector itself. &gt; So it would be better to use the types you are actually storing. Unfortunately not an option since as mentioned these are bindings to external API's.
Would you please open an issue discussing this on my repo? We can discuss how to integrate your crates and how to modify the configuration format to easily support this. One of the biggest services I intend this project to do is to provide a place for the best crates in the HTTP/asynchronous I/O space to be integrated into a (hopefully) useful project, so I'd be glad to pick up your crates. 
Fighting with FFI and LLDB build a crate to power up NodeJS applications, especially for sending/receiving multithreaded HTTP requests.
Hey /u/quarterq11, glad to hear it! An important thing that factored into my decision making is that what I‚Äôm working on isn‚Äôt a side-project, it‚Äôs for my business. Using Rust at all for that is something a lot of sensible people would recommend against because it's web frameworks are still lacking* in some areas as previously mentioned. As I‚Äôve said, I adore Rust and want to see it on the Web which means sooner or later it‚Äôs going to have to be used in production though. I‚Äôm willing to deal with any eventual problems to try and help push that forwards a bit. If you're using it for anything that isn't a side-project, you have to make sure you are too though. Having made my choice, I needed to be careful about which framework I chose. The three most important factors to me were longevity, repo activity and documentation. Rocket has been around since late December 2016, Iron has been around since late November 2014. Both are very actively developed, but many more issues can be found and fixed in 2 and a bit years rather than 2 and a bit months. As for documentation, last time I looked Iron beat all of the others hands-down on that front. 2 and a bit years is also a lot longer for users to write about their trials and tribulations with a framework on their blogs and indeed, the only framework that comes close to the number of blog posts that have been written about Iron seems to be Nickel. As for limitations, Olivier Jensen‚Äôs [blog post](https://ojensen5115.github.io/rust/helloweb) lists some of Rocket's fairly big ones. They may not all still be true, but those plus Rocket‚Äôs lack of real documentation and newness were enough for me to rule it fairly easily at the time of research. I'm looking forward to seeing where it will be 2 years down the road. I expect it will become one of the ‚Äúbig players‚Äù given time. I‚Äôll close by saying that a big part of the future of the web is coming down the pipes in the form of Web Assembly. When it hits production in evergreen browsers, being intimately familiar with a language that supports it, like Rust for instance, can only be a good thing. I hope some of that was helpful. Should you be interested, I keep a [blog](https://elliotekj.com/) about what I'm working on which will certainly have more Rust related writing in time. If you have any questions, reach out. I'll do what I can to help out. --- *: There is currently an [in-progress PR](https://github.com/iron/iron/pull/523) to add async to Iron‚Äîcurrently it's biggest downside (a downside that all of Rust's other web frameworks share as it happens).
Thanks, that's great!
Working on [pest](https://github.com/dragostis/pest) 1.0. There is still quite a bit of work left to do, but this mostly involves [procedural macros](https://github.com/dragostis/pest/pull/88) and [streams](https://github.com/dragostis/pest/pull/102).
Behave as ransomware. ‚Äúpay X BTC for the authors to fix your unsound code and give you back a rust version‚Äù
I gave a three days course about Rust 2 weeks ago. The course material was intended to be free and accessible for everyone who wants to do the same: https://github.com/skade/rust-three-days-course As those things go, a lot of the stuff was finished right before the course and is still in german, so this week is cleanup, documentation and translation week :). Proper announcement coming.
You should probably audit `unsafe` blocks in your code. Maybe there is undefined behavior somewhere.
Do Markdown files in `doc/` get processed by `rustdoc` and/or `cargo doc` for HTML generation, or just by `cargo test` for testing? Also, is there a way to tell whether my code is on the parent or child side of a `std::process::Command::spawn` call, or should I just have the parent instance pass a message to the child instance to carry that information?
Splitting my side project for work from a single executable into a library, CLI client, and Tokio-powered server. Library and thin client are done. I'm ... not looking forward to the server. I *think* I have an okay-enough grasp of Tokio to do what I want, maybe, but I'm not at all confident in firing up a daemon, especially since it has to run cross-platform. I also need to figure out a way to improve my work, since this project requires working with potentially large data sets, and has to know their entire length before starting work. It turns out the "just try to stuff it all in a Vec" approach causes problems when I pass the 2GiB line, so I need to rethink either my use case (should be mostly files, so, grab the size beforehand and then pretend I can work on a stream?) or use something other than a Vec for the backing store. But my competition is written in C&amp;#9839;, and so far I'm kicking its ass, so that's pretty cool.
AFAIK, only the GPL is the kind of infectiously viral license where if you have a strict dependency on GPL code you must also become GPL. Since you are publishing your source, and your source includes (via `Cargo.toml`) a direct link to their source, that should satisfy any possible licensing concerns. Dependency projects (that aren't GPL'd) can't force their license on a dependent; your license applies only to your code. To my knowledge, there is no reason you can't choose MIT+Apache for your own project. And technically (I think), since crates.io is a source repository, the `Cargo.toml` file qualifies as an indirect means of distributing their source including and under their license without requiring any further effort on your part.
Should we try and do the same for clippy? Some changes (and removal of hacks for cargo-clippy) would need to be made, and we can start prepping for that now.
I told friends at Bitdefender about it, they are working on it.
Since we are on this topic already, what is the reason/advantage to use MIT/AL2.0 over either one of them as individual licenses?
Unification would simply not try to work on value equivalence, but rather compare the computation itself.
"[The Apache license includes important protection against patent aggression](https://www.rust-lang.org/en-US/faq.html#why-a-dual-mit-asl2-license)." (AFAIK [MPL](https://en.wikipedia.org/wiki/Mozilla_Public_License) has a similar mechanism.) MIT (or more exactly, [MIT/X11](https://www.gnu.org/licenses/license-list.html#X11License)) license is required for GPLv2 compatibility.
I take strong issue with the concept that "linking against" constitutes "deriving from" for the GPL's purposes, unless I've forgotten how the GPL works specifically which is more than possible.
&gt; AFAIK, only the GPL is the kind of infectiously viral license where if you have a strict dependency on GPL code you must also become GPL. No. That's a common misconception. The GPL has expectations about the _final artifact_, namely, that if you distribute it, the recipient must have some way of access to the exact code the artifact was built from and have the full rights to modify and republish it. The "virality" of the GPL stems from the fact that you are _not_ allowed to restrict any of that in any of the components linked into the software. (For example, a "non-commercial" clause for your software would be a GPL violation) You can happily ship MIT code that includes GPL code, as long as you ship the full source along with it. But the MIT license allows you to close the code, but shipping GPL code along with it, would bar you from it. Still, anyone could grab your code, replace the GPL parts and ship it as a closed product and be well withing their right. The GPL doesn't relicense code. The beautiful (and sadly misunderstood) thing about the GPL is that it protects the right of inspection and modification transitively. It isn't a perfect license, but I think a very good one for projects of the infrastructural kind. Now, that's all unwieldy in a commercial setting, but in a public, citizen engagement setting, the GPL is a good license. 
Or you could to this: let vector = vec![0u64; num_elements]; // u64 should align with most structures let boxed = vector.into_boxed_slice(); let pointer = Box::into_raw(boxed); Now you can free it again by doing let _ = unsafe { Box::from_raw(pointer) }; This way, you can free it without needing to remember the capacity. EDIT: This gives you a slice pointer, which may not be what you want. To extract a pointer to the first element, you must use unsafe { &amp;mut (*pointer)[0] as *mut u64 } You'll need to keep the original fat pointer around to free it though. 
The `pointer` there is a fat pointer (in this case a pointer and the size of the slice I think), so it's not really like `malloc`. It's like passing a `(*mut T, usize)` around.
~~No, the `pointer` in this case has type `*mut u64`. It is not a fat pointer.~~
Hi guys. I'm trying to get RLS up and running on Windows (https://github.com/rust-lang-nursery/rls), I checked it out and built it via "rustup run nightly cargo install" and it builds successfully. It copies rls.exe to \.cargo\bin which is in my path, but running rls only yields errors of missing DLL's: The program can't start because rustc_driver-670f3616ef677c35.dll is missing from your computer. However that exact file (and all the others it errors with) is located in my \.rustup\toolchains\nightly-x86_64-pc-windows-msvc\bin folder. Do I manually need to add this directory to PATH for RLS to work?
Converting my markov chain IRC bot from Go to Rust, as I'm just beginning to experiment in the language. 
Constructing tooling for my blog, if I have time. Not sure what form that'll take yet. Probably something that converts Markdown to an HTML fragment, and then embeds that in a template. But since it's a static site, I'll also want to be able to do things like automatically update links for consistency. 
Nope, it's `*mut [u64]`. Here's your code (corrected to compile) on the [playground](https://is.gd/Fczeyh): fn main() { let vector = vec![0u64; 100]; // u64 should align with most structures let slice_box = vector.into_boxed_slice(); // Remove type annotation to compile correctly, otherwise, fails with [1] let pointer: () = Box::into_raw(slice_box); // Prints `16` or size of two pointers on x64. println!("{}", std::mem::size_of_val(&amp;pointer)); } Fails with: rustc 1.15.1 (021bd294c 2017-02-08) error[E0308]: mismatched types --&gt; &lt;anon&gt;:4:23 | 4 | let pointer: () = Box::into_raw(slice_box); | ^^^^^^^^^^^^^^^^^^^^^^^^ expected (), found *-ptr | = note: expected type `()` = note: found type `*mut [u64]` error: aborting due to previous error Removing the type annotation, it prints `16` which is the size of a fat pointer.
What is RLS? (thanks for your work!)
Yes, he mentions it in the post. The reason why he uses prime numbers by default, is that powers-of-two hash tables working correctly typically relies on a good hash function. He considers having to ask on every hash table "is this hash function good for my inputs" to be a bad user experience (at least, for himself), since most of the time, he doesn't really care: &gt; [on storing pointers in a hash table:] The reason is heap allocations in my program were sixteen byte aligned and I used a hash function that just reinterpret_casted the pointer to a size_t. Because of that only one out of sixteen slots in my table was ever used. You would run into the same problem if you use the power of two version of my new hashtable. &gt; &gt; **All of these problems are solvable if you‚Äôre careful about choosing a hash function that‚Äôs appropriate for your inputs. But that‚Äôs not a good user experience**: You now always have to be vigilant when using hashtables. Sometimes that‚Äôs OK, but sometimes you just want to not have to think too much about this. You just want something that works and doesn‚Äôt randomly get slow. That‚Äôs why I decided to make my hashtable use prime number sizes by default and to only give an option for using powers of two. He then goes on to explain how prime numbers help, discuss security issues (how to make this hash table impractical to attack), and at the end recommends what you just mentioned: &gt; If you know that your hash function returns a good distribution of values, you can get a significant speed up by using the power_of_two version of my hashtable. But that is an opt-in optimization for when you need the speed, and want to go through the trouble of making sure that you have a good hash function. Arguably powers-of-two played a key role on Rust's hash-table becoming accidentally quadratic on reinsertion, and also is why google's `dense_hash_map` blows up on sequential input...
This looks great !
Got back to hacking on [hdf5-rs](https://github.com/aldanor/hdf5-rs/tree/feature/types) after almost of year of stalling (there were a few things I waited to land like the removal of drop flags, and the proc-macro-derive), hoping to get a stable version in a few months.
AFAIK `read_to_string()` tries to read from the `Read`-er until the end. That is, if you have a long-lived TCP connection that doesn't end after sending one message to the client, `read_to_string()` will hang until the TCP connection closes.
Wrong sub
CoachDB
Looks like they missed Rust.
Okay, so how can I read without having to close the connection ?
I really hope the next cargo version comes soonish, so I can release the next version of imag. I ran into a bug with the latest cargo, ... So I have to wait.
Finally published the work I've been doing on my dimensional analysis crate [uom](https://github.com/iliekturtles/uom) to [crates.io](https://crates.io/crates/uom)! Review and feedback is very welcome.
Second that :)
I've done a little on that same blog, but not to the same extent. It's been less than a year since I started elm! 
Is there a good guide to the attributes of a modern "polished crate"? * rustfmt formatted code * clippy validated code * custom tomls for both, if necessary * travis integration * doc/etc links in Cargo.toml * ???
Related: http://www.integer32.com/2016/12/27/how-to-make-your-crate-awesome.html
Three weeks until the next stable version!
is there a simple example showing what they could do beyond the use familiar to C++ users? 
To complete your list: * CI: Travis on Linux &amp; OSX, appveyor on Windows * examples! (If applicable) * README! Badges, license link, setup, example * CONTRIBUTE.md * Cargo.toml badges, keywords, etc. * tests ‚Äì doctests, etc. * benchmarks using [bencher](https://github.com/bluss/bencher) (if applicable)
Yay!
This hashmap doesn't store hashes which is a different trade-off than std makes (this is especially bad for string keys which the article doesn't look at, specifically because "you're just comparing the speed of the hash function"---not if you store the hashes!). The "hard limit probe count to avoid bound checks" is a really cool idea though, and I think we should totally try it!
I've been working on a Tokio based actor library with a supervisor. It's going.... slowly. Not a ton of time to work on it lately and I find tokio very complicated. But I'm making progress. Also building an interpreter in Rust - based on the book that does this in Golang, though I've diverged a bit and intend to go a lot further than the book (adding a type system for example). Giving a presentation on Rust at work this week as well.
(Maybe I missed it) You said you drew by lot, but was the lot determined by a prior nomination or purely by scanning the entire crates.io index? I only ask because it seems that for maximum effect it'd be very handy to have the crate owners knowledge prior to this push in order to either be expecting a PRs, or be available to give insight with any subjective decisions/general questions about the crate. It's a really cool idea to get more crates with the extra polish!
The article does cover that, and an optimisation to make it more efficient.
I personally use `Box::(from|into)_raw`. As said, you could use Vec for multiple allocations. Just pay attention to the fact that zero-sized Box&lt;struct&gt; all use the same address 1. It may break the C code.
Search the post for `switch(prime_index)` to see the optimization he does for this. He only uses a set of 187 primes and then hard-codes the modulus with a constant for each of them so that the compiler can optimize it and avoid the modulus completely.
I had no clue that `RegexSet` was a thing, but this is exactly what I need for a project I'm working on. This is great!
&gt; Now, that's all unwieldy in a commercial setting, but in a public, citizen engagement setting, the GPL is a good license. I strongly disagree with the idea that the GPL is good license in the absence of a commercial setting. The GPL locks you into a corner that you cannot walk out of. There are plenty of people that learned this the hard way because they wanted to distribute their app in a place with a GPL incompatible distribution license. Pretty much all copyright holders that eventually lost the copyright to GPL code came to regret it.
One could say that this is an issue of the distribution channel, not the License. There's not many ways to provide the guarantees that the GPL gives and be compatible to e.g. the App store guidelines. I'd prefer a better license there, but it doesn't seem that there are a lot of people working on that problem. &gt; There are plenty of people that learned this the hard way because they wanted to distribute their app in a place with a GPL incompatible distribution license. Pretty much all copyright holders that eventually lost the copyright to GPL code came to regret it. [citation needed] Also, what would "lost to GPL code" be? They contributed the code to a GPL project. Otherwise, they can still take their code and use it somewhere else.
I'm not an expert in this area. But there seem to be similarities between the approach described in this article and the approach /u/Jonhoo has taken in the [evmap] (https://github.com/jonhoo/rust-evmap) crate, which was discussed in [this recent Reddit post](https://www.reddit.com/r/rust/comments/5saw4z/evmap_another_efficient_concurrent_hashmap/). Or are the approaches more different than it seems to me? In any case, I'm glad this was posted and that it's sparking discussion.
Is there a flag to make Debug print all integers as Hex? Like ```{:#X}``` does, but in general for all Debug prints?
Looks like there is only one crate in the DB so far. How is it being constructed?
&gt; One could say that this is an issue of the distribution channel, not the License. Trust me, the distribution channel does not care. Nobody cares. &gt; [citation needed] Maria after it split from Oracle's MySQL, Xapian after the new copyright holder (Orange?) no longer cared about it, RethinkDB regretted their license after the insolvency (though they were AGPL), Ogre3D (though it was LGPL), many more. &gt; Also, what would "lost to GPL code" be? It means their contributions ended up in a mess of other GPL code and no central copyright holder could be found that had the power to relicense. This typically happens if you build your stuff under the GPL but then your company is acquired or becomes insolvent and the copyright goes to someone who just sits on it.
Writing the backend for our new alerting service at work. I have a 2 week time-box to verify the viability of using Rust in our environment but so far it's looking pretty good. Hoping to pull out various components as open source when I get a bit further along.
As I start building the UI in unity, my rust programming came to a slowdown in STRATIS: https://github.com/viperscape/stratis Once things are where they need to be for a first pass on the chat system, I'll pick back up and start working on Regions, Tradeposts, and probably travel within rust
I'm still trying to get the entire thing setup on windows. Got the extension for Visual Studio Code running now (https://github.com/editor-rs/vscode-rust) with Rust Language Server running behind it. Now comes debugging. What are the options for debugging on the -msvc target for Rust? I see it emits a PDB file so something must be possible, however no recent results on google shows any way to debug using either Visual Studio or an extension to Visual Studio Code. Is it still not possible? If not, is it time to bite the bullet and learn GDB?
"A description of Forth Query Language. Using the power of Forth as a DSL to make SQL simpler, and in some cases, faster than SQL alone." http://www.complang.tuwien.ac.at/anton/euroforth/ef13/papers/nelson.pdf https://www.youtube.com/watch?v=mD4GJ36Npqk http://hub.darcs.net/pointfree/forthql
Right now via pull requests to: https://github.com/RustSec/advisory-db Here's an example: https://github.com/RustSec/advisory-db/pull/4 Short term improvements: more documentation on how to file advisories and a real web site: https://rustsec.org Long term a CLI tool will be available to file advisories: https://github.com/RustSec/cargo-advisory
Oh well im doing a big project for school( it was a personal project but I found out that my school will pay for it and give me marks). Essentially it's a way to triangulate my phone and then use HID codes to unlock a PC if it detects my phone. I plan on using rust for the micro controllers for speed. Python for the rest.
Working on my new project: [smithay](https://github.com/vberger/smithay), a toolbox for writing wayland compositors in Rust, built on top of my [wayland-server](https://crates.io/crates/wayland_server) crate, with the help of u/Drakulix (many thanks to him for his interest !). I'm also in the process of writing a big tutorial about wayland, focused around my two crates wayland-client and wayland-server. I really like [mdbook](https://crates.io/crates/mdbook) so far!
I'd sure love me some hash after reading this
http://opensource.stackexchange.com/questions/1881/against-what-does-the-apache-2-0-patent-clause-protect
It's fairly similar though: part of the difficulty in the "switching allocator" work is to define the API those allocators should have. Without a defined API, there's no stable way to access the underlying allocators.
&gt; Do Markdown files in doc/ get processed by rustdoc and/or cargo doc for HTML generation, or just by cargo test for testing? What `doc` folder are you talking about?
Oh, totally. But if this lets you generalize lengths on array types more easily, it seems a safe bet it's going to get used a fair amount in many code-bases for that or similar things. And how much work LLVM has to do to optimize is affected by the code generated, so. If this generates more code, or harder-to-optimize code, LLVM will have to spend more time on it. I'm not complaining, since I don't actually spend a lot of time waiting on compiles most of the time. But I am pretty excited about incremental compilation.
&gt;we made a huge mistake cheers :D
Any idea why using generics results in such an explosion in code gen times?
/r/playrust
What's keeping floating point types from implementing Ord and Eq?
Nice! It's great finding and fixing bugs that would otherwise have been near impossible to discover without being bitten by it in production :) /me adds mental TODO to try `cargo fuzz` and compare it against afl.rs
/u/georgerush, have you considered Sanakirja as a pure-Rust alternative to LMDB?
I'm working on my last-weekend project, Hyproxy. Going to start adding features and documentation, and probably a large refactor sometime soon to make it testable. 
Hacking on [a tool](https://github.com/KodrAus/nuget-rs) to package simple cargo libs as Nuget packages for easy consumption in .NET. I _just_ got it to produce working packages last night so this week is cleanups, tests, features then an initial cargo tool release. I'm also working on getting trust CI added to tantivy's CLI tool so we can manage binary releases easily.
This is a good question. `if let` is just a shorthand for a specific case of `match` - so the generalization of this question is performing derefs/refs in patterns. The reason it doesn't work here is that currently we don't do any sorts of automatic derefs/refs in patterns. The idea of doing something along these lines was raised in the RustConf keynote last year, and is probably in the roadmap for 2017. But today we don't. EDIT: [This issue](https://github.com/rust-lang/rust-roadmap/issues/24) tracks work similar to you're talking about.
I mostly used Go as a silver bullet language to handle application programming and web development. The large majority of my development is hobbyist and pertains to the web dev space. As a consequence of Go's... community I guess, they are violently opposed to anything that resembles Django, Rails, or even Rust's Rocket, largely in favour of sticky taping bits together from disparate authors and hoping a lot. I ended up moving back to Ruby. I still wanted to learn a systems language for anything that wasn't a web application and I played around with Rust in the 0.7 days so I figured I'd give it another shot. What's good is Cargo and Crates. They are, in my opinion, vastly superior to the Go methodology. It's the best of ideas taken from npm/rubygems and it works very well. The compiler is also considerably better in my opinion in terms of explaining errors. I haven't dived deep into borrowing and such yet so time will tell there. The only thing I really miss from Go is automated dependency importing (no need to manually add to App.toml), and some elements of the Go toolchain (e.g., go fmt). 
As far as I know, yes.
It doesn't really make sense to ask whether a single value can implement a trait.
This is great! Probably the first `unsafe` bug found by cargo-fuzz. Also, I love that this helped find a bug in the original C++ code too :) &gt; For a long time I had been meaning to try out afl.rs, a similar fuzz-testing tool about which I had heard lots of good things, but its nontrivial setup costs were enough to deter me. This is _exactly_ why I made cargo-fuzz :) Over at rust-fuzz we do want to make it possible to use afl via cargo-fuzz (with similarly minimal setup), though. Btw, you should check in the fuzz targets you write, so that others can run them too.
https://en.wikipedia.org/wiki/NaN#Operations_generating_NaN: * Operations with `NaN` as an operand (of course) * Zero divided by zero and infinity divided by infinity (positive or negative) * Zero times infinity / infinity times zero (positive or negative) * Adding infinity and negative infinity (vice versa and subtraction equivalent) * Using `powr()`(which Rust doesn't expose) to compute 1^INF , 0^0 , INF^0 * Taking the square root or logarithm of a negative number * Taking the inverse sine or cosine of a number outside [-1, +1] All of these (except `powr()`) demonstrated here: https://is.gd/jWpvT2 
Sounds like a good question for a laywer. (Sorry, I don't mean to be glib here, it's just that handing out this kind of advice is fraught with danger. I am happy to link to things that add context, but generally try to not give advice directly myself.)
Perhaps. Devil's in the details. Easy to do `Result&lt;BoundedInt&lt;n&gt;, usize&gt;` (or hey, while we're at these weird compile time states, `Result&lt;AtMost&lt;n&gt;, AtLeast&lt;n+1&gt;&gt;`)
AIUI, the codegen process has to occur in each instance of monomorphization, doing all the checking and generation from scratch for each new type. I think?
Is it for sure or is it just a possibility?
That makes some sense, but alone doesn't explain the kind of slow down I see. I don't have access to the codebase at the moment to get full details, but I have a a couple hundred line project where a lot of functions use generics but are only actually instantiated with one or two types. It started taking ~5 seconds to compile in debug mode but has only been getting worse, currently taking ~14 seconds. I haven't really tried to debug what's going on beside checking the `time-passes`, and it's like 80% in codegen. When I compare my stuff to other code bases that are twice the size but take less than half the time the most glaring difference is my use of generics.
Ah, too bad...
If your program was written in Python to begin with, and you made a rational decision in choosing that language, I would contend that the overhead associated with inter-layer object conversions is not material your program. If it was, then you made a poor choice by going with Python in the first place. CSV processing is done quite frequently in Python, and I wouldn't at all be surprised if there are a number of substitute libraries for csvkit which compare more favorably versus xsv. Did OP try the built-in module, which you mentioned was written in C? Or Pandas? Both of which I am pretty sure are more widely used options for CSV parsing in Python than csvkit. But instead, OP chose a library written in pure Python versus a library written in Rust (i.e. LLVM). I've seen these comparisons time and time again. Using Python as Python for computationally intensive applications is asking for trouble. The whole point of Python is to interface to libraries written in other languages for those kinds of tasks. But I'm sure things like this are great fodder for creating catchy headlines showing language X is a thousand times faster than Python. 
Oh, also, I've set up a dedicated machine for fuzzing. Open offer to fuzz your (anyone's) crates for a few days if you write targets for it.
You can build this with limited copying in safe code using `Vec::swap_remove()`: https://is.gd/Or7Kju This does rearrange the original vector but it doesn't do any more copying than necessary, as opposed to using `Vec::remove()` which will copy down all the elements after the one that's removed for every call so that the vector remains contiguous. If having an extra allocation isn't a problem, you can just use `Iterator::partition()`: let (kept, removed): (Vec&lt;Foo&gt;, Vec&lt;Foo&gt;) = my_foos.into_iter().partition(|foo| foo.is_kept());
Each of those `case` statements obviously generates different assembly (duh, one is using modulo with a different number), but the cool fact here is that these case statements generate completely different assembly than the others in some cases. It seems that GCC knows a lot of tricks to modulo something by each particular compile-time integer to avoid the cost of the modulo operation. I wonder whether LLVM can also do this but haven't checked.
The issue is that `to_string` is transitive. https://doc.rust-lang.org/stable/std/string/trait.ToString.html impl&lt;T&gt; ToString for T where T: Display + ?Sized Anything that implements `Display` implements `ToString` and therefore gets a `to_string` method. But because it's generic and transitive like this, it won't pop up.
csvkit uses Python's standard CSV reader. Python's standard CSV parser is quite a bit slower than Rust's CSV parser despite the fact that Python's is written in C. This was literally the reason why I even wrote a CSV parser in Rust in the first place. I was sick of how slow Python was at basic data munging tasks. I don't know about Pandas. Never used it. I think you're barking up the wrong tree and I would be quite surprised to see a Python equivalent to xsv that compared favorably in performance (with a non-trivial portion of it written in Python). xsv gets its speed through careful control of allocation and parallelism, both of which are annoying-bordering-on-impossible if your CLI program has a non-trivial portion of it in Python. &gt; OP chose a library written in pure Python The OP didn't choose any Python libraries. They chose a command line tool to do analysis on their CSV data. csvkit is a CLI program. &gt; But I'm sure things like this are great fodder for creating catchy headlines showing language X is a thousand times faster than Python. I'm not sure what your beef is. People get excited when they get a huge gain for low effort. That Python is slow is unsurprising, but that isn't really the point of the OP. The point of the OP is, "OMG LOOK AT THIS AWESOME TOOL THAT YOU SHOULD TOTALLY TRY!" There's nothing wrong with that. We should encourage folks to share their successes.
I actually want to switch to servo when it's ready, but for now, too many websites are unusable with it. I also want that less browser are based on Webkit. As to work on Servo to improve it, well‚Ä¶ a web browser is already a lot of work and I'm also working a some GUI libraries built in Rust that I want to use to simplify my work on titanium.
Ah okay, this makes perfect sense, thank you! I just derived `Clone` for a struct, and the docs indeed show the two implemented methods I get. So the point for `Display` is that there is a layer of indirection (sort of) between this trait and the to_string() method, in this case the `ToString` trait. This is how I understand it at least. So, I think I have to go back to my custom to_string() implementation on my struct directly to have it documented for now. Too sad, I just discovered how using the built-in traits for my own stuff could be really cool. :(
&gt; Mentions Rusty Radio No! Now I actually have to make new episodes! Please
Haven't seen one of these in a while, haha.
I'll allow it. If you're even in NYC, hit me up and I'll buy you a beer. My email is associated with my github. 4x throughput is pretty impressive. Sorry for the delay in this. Haven't checked reddit in a while...
It's extremely difficult to reason about the performance of robin hood hashing without a good hash function. The run time blows up in pretty terrifying ways if your hash doesn't actually distribute data uniformly between buckets. Note that good doesn't necessarily mean secure. Bob Jenkins' 32-bit hash is an example of one. It's also extremely fast. I think the rust hash table keeps track of the maximum probe distance already. I'm not sure if we use that to drive resizing. I don't consider it a particularly important optimization. It just turns a time-leak into a space-leak, and is irrelevant if the hash function is good. Prime slots doesn't seem useful either, because good hash function.
Or use [libdivide](http://libdivide.com/) :) AFAIK this is a common knowledge, and I believe LLVM also does this (but there are considerable variations of this common idea).
I wonder what's the chances of these alternative implementations which have the same API than std::unordered_map will eventually substitute the implementation in std?
Try /r/playrust
Wrong sub
This is excellent, thanks for sharing! I may look in to building a serial- or USB-based test runner, since the Teensy doesn't expose real debug pins. This largely depends if I ever use Rust for something "real" that requires tests, instead of just goofing around.
Why? What is the advantage of this over just using "format!" 
The same thing I do every week: ~~try to take over the world~~ my embedded Rust blog. I've been struggling with how to introduce interrupts (really just exceptions in this post, to catch Faults), but may finally be on a good track there. Everything except interrupt handling is in good shape and ready to go, so fingers crossed it won't be too much longer until post 3 is up. Post 4 is actually much better formed in my head - it deals with real-world interactions and hardware stuff again, instead of focusing on safety and abstractions like 3 has ended up being. Physical things are easier to write about than concepts.
I don't see the actual assembly in the article. I wonder how it compares to [this technique](http://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/): 128-bit multiplication followed by a shift, which doesn't require a constant divisor.
Just in case: [`include_bytes!`](https://doc.rust-lang.org/std/macro.include_bytes.html) is a thing and probably better for larger files.
Agreed. If you have the file available on your filesystem and just want to include it as a byte string at compile time, use `include_bytes!`.
I feel your pain. Some ideas: - in docs, below example macro usage, have a link "show macro expanded code" - in IDE (via RLS), right-click on a macro, then "show macro expanded code" 
I actually feel like having `error!()` exactly for this reason. I want to detect and present users what really went wrong, not how it went wrong. Additionally, if we could insert the check *during* the Earley parser [1] it would result in much better usability. [1] The current macro parser will look at possible candidates and detect ambiguities, but the list of candidates is less useful for users; if we can somehow amend the list of candidates with a custom error to be presented when ambiguous...
What are the requirements for this? I'd like to fuzz my HTTP reverse proxy (as it makes use of many big HTTP/asynchronous I/O crates). 
Cool always on the lookout for developer related podcasts. Subscribed! 
Hmm, seems like it would be better to run this on Hyper or native-tls than my proxy directly. 
Hahah damn, sorry guys
The known max probe dist does make the lookup loop simpler. So even if you set it to 64 or something super high, you could make lookups faster due to not having to check for wrap.
I hate macros with a passion, also because errors are hard to trace. I accept them for stuff like `println!` and begrudgingly use them for `derive` with serde and through `error_chain`. Just today, I hit one unusable error message when updating `error_chain!` and when trying to port non-trivial struct over to `derive_builder` I received a number of errors I had such a hard time to track down that I just removed that approach again. For me, Macros break one of the nicest things about Rust: the ability to find out all details about the context you are in at a glance. I understand why they are there (to cut down the resulting verbosity), but I avoid them where I can.
None. What they mean by "the same API" is that the functions to do similar operations have the same signature and name. The `std::` hash tables and red-black trees are very safe. For example, the standard guarantees that iterators are never invalidated on insertion/erasure. The price for guarantees like this is fine. They are not slow per se; I don't think there is a faster way to provide the guarantees that `std::` requires in a faster way than currently standard library implementations. What people mean by "slow" is when compared against hash tables that do not provide these guarantees. But that's a bit like comparing apples to oranges.
&gt; libdivide I didn't knew about this :)
Awesome program! Spread the word if you know a potential participant or a sponsor
Thanks, will do! (once it gets a tad closer to a stable state) // In a nutshell, it's a de-facto standard ndarray/table-oriented hierarchical storage format for scientific data, and an extremely efficient one at that. 
Yes. https://github.com/libpnet/libpnet/pull/250
I think it won't be that hard because servo is supposed to implement the [Chromium Embedded Framework (CEF) API](https://en.wikipedia.org/wiki/Chromium_Embedded_Framework). But the web process extension will probably cause some issues.
i finally attained at least some proficiency in writing macros and really appreciate the opportunity they provide to reduce boilerplate. when debugging my own macros, using `--pretty=expanded` is helpful, but i found myself wishing there was a way to expand just my macros, or a way to specify a certain set of macros only to be expanded
I personally love macros and the opportunity they present for writing cleaner, DRYer code. "cargo expand" can be helpful for understanding when things go wrong with a macro, but the Rust compiler gives much better macro error messages than any other compiler I've used.
To be fair, there's this gem buried in the error-chain docs: an example of the generated structs: https://docs.rs/error-chain/0.10.0/error_chain/example_generated/index.html error-chain is _deceptively_ easy-looking, but needs a little exploration before serious use (i.e. write little programs and go 'WTF' and 'a-ha') 
&gt;The Free Software Foundation (which holds the copyright of several notable GPL-licensed software products and of the license text itself) asserts that an executable which uses a dynamically linked library is indeed a derivative work. Yeah, so, if the GPL authors argue that using `glibc` requires me to be GPL if I want my program to ever leave my computer, I think I'm perfectly justified here.
I wonder if the pendulum towards compile-time code generation has swung a little far? That is, a yacc like approach where the specialized input is ruthlessly checked for errors, and then generates nice Rust code. More awkward, but build awkwardness is easier to handle that compile-time awkwardness.
Nice!
It is hard for writers of procedural macros to present good errors to their users. We don't have the tools and libraries for this yet. The `syn` crate is a good, but we still need better error handling to catch errors earlier when going from `TokenStream-&gt;AST`, and better error reporting utilities so that we can easily provide errors with spans like rustc when the user feeds the macro broken input. It would also be nice to have utilities to catch panics inside a macro that can report what the macro was "more exactly" doing when something panicked, but this information is not going to be useful for macro users. My point being, the best we can do is to have macros emit good errors when fed bad input. We are not there yet, but we are never going to be able to do much more. For example, if a user feeds a macro good input that triggers a bug in the macro itself, the user is screwed. It is too far conceptually from what the macro is doing and how to be able to quickly fix it. This situation is much like running into a compiler bug. The best you can hope for is to get an ICE with a back trace, some dump files and scripts to reproduce it, and a link to where you can fill the bug as quickly as possible, and hope for the best.
..who's making you use glibc? And this isn't unreasonable, either. If you use glibc, then you are using code written by others. You need their permission, that's just how copyright on code works. They have chosen (reasonable) terms for that permission, but you don't have to accept. You could use musl, for example. Or you could sign a EULA and use Microsoft's equivalent. It's your choice. So, where does it become "viral" or "infectious", again?
&gt; The first is, sometimes I want to see the source code for a type when familiarizing myself with a crate and when the type is constructed through elaborate macro use, I can't really do that. You can, cargo expand will show you source after macros are expanded &gt;If the type is constructed using a complicated undocumented internal only macro it feels needlessly difficult to get the information I'm after. That could perhaps be mitigated by having an option to see source with macros expanded, though it still could be hard to read sometimes. &gt;quite complicated and look very arcane to somebody with my level of familiarity/understanding with macros in rust. Do not expect source created without them (or expanded from them) to be easy. "Not using macros" is not a cure that magically removes complexity from software. &gt; When creating libraries, what level of expectations is reasonable to have of our users and their understanding of some of the powerful but more complicated features of rust like macros? I expect libraries to be easy to create and maintain (for their authors) and easy to use (for others). Making them easy to understand is sometimes against those goals, and in my opinion is less important. Still valuable, but not as much. 
ah right, because they don't have an ending 'ch' syllable
&gt; For example, if a user feeds a macro good input that triggers a bug in the macro itself, the user is screwed. Same for bugs in libraries - just report it to author and expect them to fix it. Having some form for macro debugger would be nice to have though.
I plan to develop a crate that should work both with and without std. I remember that there was a discussion on which of the following was the best: * use a `no_std` feature * use a `std` feature enabled by default I couldn't find this discussion. My question is which one should I use ?
A library author sometimes has to put in the work to make it easier for others. Tests, docs, general packaging. As for 'easy to understand', I'm thinking of the Fred Brooks idea of 'accidental' vs 'real' complexity of a software solution.If the library interface is significantly harder to understand than the actual problem it solves, then that complexity is accidental. Then users either push back &amp; contribute, or Darwinian selection happens ;)
Nothing makes me use `glibc` on my own, but if I ship a binary that expects to dynamically link against a system `libc`, and it finds `glibc`, is it now in violation? "You're free to use me or to fuck off" isn't freedom if there are limited substitution choices, such as for a dynamically linked `libc`. Ironically, that's the kind of non freedom that sparked GNU in the first place.
/u/antoyo: as promised, here's my Elm-inspired library for Cocoa/Appkit.
Cool
I really like the system that `error_chain` defines in the background and I can very much understand why it is written as a macro. But it needs tons more documentation for all standard and advanced uses.
Site timing out. Mirror?
It uses cocoa, so I guess it only works on macOS for now. Have some screenshots: http://imgur.com/a/K7jDL
I agree some screenshots would be nice. The documentation in general is very lacking right now as it's still more-or-less in an overall design phase. The design is intended to be "backend-agnostic", even supporting a "headless" mode (eventually). Currently, the crate has a backend implementation using Cocoa.
I was trying to implement a simple [`struct`] (https://github.com/lawliet89/fusionner/blob/master/src/lib.rs#L89) to wrap around a password `String` so that users won't leak it when they try to do some print or debug (by implementing `fmt::Display` and `fmt::Debug`). Then, to minimise code changes, I implemented `Deref&lt;Target = str&gt;` for the struct, and I got a huge amount of `Methods from Deref&lt;Target=str&gt;` in the [generated documentation](https://lawliet89.github.io/fusionner/fusionner/struct.Password.html). How does this work? Is this because I have turned on `deref coercison` to `str`?
Thanks for writing this all up. I really enjoy reading about your process and how you are working through it. 
If I find a bug in a library, I can typically open it, find it, fix it, and send a PR, because I am working "at a similar level" than the library. A macro is just a program that reads rust source code, parses it into an AST, transforms the AST, and then spits rust source code out. If I am my self not working on a Rust compiler, that typically means that just to barely understand what is going on I have to switch mindset to a completely different domain. Doable, but time consuming.
Cargo features are supposed to be additive, so the latter is preferred.
Thanks. The purpose of the struct wasn't to prevent access but to prevent accidental printing when you do something innocuous like `println!("{:?}", something_with_password)`.
&gt; (e.g., go fmt). There's [rustfmt](https://github.com/rust-lang-nursery/rustfmt). I use it extensively to format my code.
It is often hard to make things 'as simple as possible, but no simpler' as Einstein said. And if it's _simple enough_ then pursuing the goal of simplicity becomes unproductive. So yes, I agree.
Isn't it possible to just have a array like this: struct MultiDimArray&lt;T&gt; { indexer : Indexer, data: T } And then generalize over it using something like the borrow trait? I don't quite see why HKT would be necessary here.
It sounds a lot like Chocolatey.
Can't try this myself yet, being a Windows user, but that API looks gorgeous.
Thanks! I actually haven't read the elm source code. I played around with the examples for a while and then just tried to get something working with rust. The [initial commit](https://github.com/jtomschroeder/cedar/blob/b2f9e1bd6efbe7e1d56fc8e90b8d1e390eb6f06d/examples/buttons.rs) of the `buttons` examples is pretty telling of how I worked through the implementation. Once I had a working example that was *somewhat* declarative and reactive, I refactored it into something that's cleaner and easier to use (hopefully).
Nice read! You mention a couple of times that you had to implement various structures using pointers so they don't take up more space than the C equivalent. Could you expand a bit on why alternative implementations would take up more memory?
For inter-linking data structures, say an edge that links to its faces, and faces that link to their edges - there isn't an obvious ownership which Rust's borrow checker needs to reason about lifetimes. In this case Rc's https://doc.rust-lang.org/std/rc/ are typically used. I'm not sure of the details but they count references so this information needs to be stored somewhere. High poly meshes can already strain memory usage, so I rather not store extra data if its at all possible. The library that I used didn't suffer from use-after-freed memory problems, so I didn't mind using its logic as-is. ---- Edit, this adds `sizeof(usize) * 2` to each element thats referenced (for strong-count and weak count). The reference to data its self is the same size as a pointer however.
I love both of these ideas. What's the best way to open a ticket to propose something like this? An RFC on the rust language server? On rustdoc?
Thanks for sharing. It's comforting to know even burntsushi experiences some of the same struggles =)
Yeah, for sure. Good call.
Have you considered building this on top of libui and libui-rs?
What we really want is debug-assert mode, so that it's fast but all the asserts are still in place. Easy to do, just not done yet.
No, I wasn't aware of `libui`. That seems like a great idea! One idea I've been toying with is providing platform-specific extensions to allow use of the unique features of each framework. `libui` would be great as a *default* backend.
Thanks for the links! Only had time to read the first one now and very quickly but I've got them both bookmarked plan to take a bit more time to really digest the content later.
[removed]
glibc is LGPL
Probably, if your library never explicitly mentions a particular implementation of libc, then the burden of copyright compliance falls upon the person who launches the app. This is probably one of the edge cases that inform the "GPL isn't as bad as y'all think" discussion. If you clearly reference or handle glibc in your code, then that's clearly on you, and complaining about it is just entitled.
Mea culpa. Haven't looked at it in detail in some time
What about GCC extensions in code, then? If I write proprietary C that uses a `char varw[0];` am I in violation?
That's beginning to sound like "Does copyright apply to APIs", which virtually everyone (GNU included) agrees is not the case (but which the US judicial system is thoroughly confused about right now).
I've made a slight change that may help -- but of course you can't un-know what you learned so we'll have to see how others make sense of it.
&gt; Part of this was also my interest to learn Rust, and not pull in code which I barely understood, to avoid writing some ~20 line function. I don't think this is part of the conventional community wisdom. This is certainly true for unsafe code, but I've seen tons of duplication and folks are largely okay with it. Use crates.io liberally, but you don't need to go down the hole of left_pad. &gt; I have the impression Rust is aimed for developing high performance web-services This is far from the truth :) If anything, the use case of webservices came much later. It's designed exactly for low level systems programming. &gt; While Rust‚Äôs ecosystem is new, when trying to solve problems that I‚Äôd assumed would have been easy, or at least possible... I would be linked to an RFC or a discussion in the issue tracker. Some of those examples seem to me like they sprout from designing code as if it were C++. They are common things you do in C++, but less common in Rust. For example, the first one -- you just call `drop()` or in some cases `ptr::drop_in_place`and it's a no-op for non-drop types. `intrinsics::needs_drop` is an internal API that may never stabilize (though you can push for this). Also the enum one -- Rust has exhaustive enums so you don't need the "number of elements" query as often. These are not "features for writing low level code", they are "features for writing low level code in C++". They're pretty niche things so I'm not sure how to improve our docs and encourage a more Rusty style when it comes to this -- it's evident that you tried pretty hard to program in a Rusty style and only fell back (if you did indeed do this) to C++ concepts when trying some more complex things. There's no easy way to teach this (usually when someone "uses it wrong" I try to figure out how to better teach it to avoid that issue happening again), but it will probably improve for you with experience :)
Can't access the link. Is the resource still online?
Good to know This entire topic is merely one entry among many of why I am not a lawyer. I don't particularly like being forced to do the "right thing", but I acknowledge that it is at times necessary. The GPL has worked well, I think, at requiring people behave well. However, I would like to think I behave well on my own, and am optimistic about others doing so as well, so I favor the MIT class of licensing. I'll abide by the GPL family where required to the best of my ability, *obviously*, but this is one among many cases where Stallman is right but man does it grate. I'm already Catholic; I don't need more ways to be guilt tripped into moral behavior. ^(I've even picked up the habit of calling it GNU/Linux where appropriate, ugh)
&gt; I don't think this is part of the conventional community wisdom. I got this impression (quite strongly) from people in the #rust IRC channel. To point to an example, I wanted to decode a single utf8 character: - Q&amp;A http://stackoverflow.com/questions/41469686 - working C code: https://developer.blender.org/diffusion/B/browse/master/source/blender/blenlib/intern/string_utf8.c;c1012c6c3a271746ee59a0d2ffc76b0d6f976352$490 &gt; This is far from the truth :) If anything, the use case of webservices came much later. It's designed exactly for low level systems programming. Even if it came later, it's still a focus. Of course its even a good focus and not complaining, but if you like to do other things they may not be quite as well supported. &gt; `ptr::drop_in_place` and it's a no-op for non-drop types. Right, I was aware of this when asking the question (it's noted already). There are cases where visiting all the elements to `drop` **isn't** a no-op. &gt; They're pretty niche things so I'm not sure how to improve our docs and encourage a more Rusty style when it comes to this. Sure, its not that I expected every corner case to be outlined in detail in the docs, its just that in an effort to write a small application, I ran into an unexpectedly large number of miscellaneous problems. This took me a little by surprise, since Rust is *stable*, on the other hand it makes sense too - being relatively new.
Should procedural macros be usable on musl target? I'm encountering an error: "error[E0463]: can't find crate for `proc_macro`". On normal GNU target it builds without a hitch. Is it a know problem? Are there workarounds?
Thanks for publishing all this! Minor nitpick: "Have Flexible Cource Material" =&gt; I think you meant "Course", unless I am missing a joke :x
looks like a less verbose variant of: https://github.com/antoyo/relm
It's not the nicest looking solution, but I was able to piece this together from types in the stdlib: https://is.gd/Fdx9Wh
Saving. Thanks.
Thank you!
Perhaps it is, but what's then the meaning of a `MultiDimArray&lt;i32&gt;`? I like my operations to flow naturally from the chosen types.
Right, unsafe pointers in this case. Although I ended up using a zero-cost pointer wrapper, since `*(*(*foo).bar).baz` is just *way* too annoying to type out. See: Q&amp;A: [Convenient access to members of raw pointers?](http://stackoverflow.com/questions/40302760)
Why would you need to support Json? Surely the first order of business of efficient json handling is to get rid of the json.
I think the whole realisation as an adult, that not everyone can be "not a jerk" without compulsion or social pressure, is always kinda awful.. because I wish there were no need for the GPL, too. FWIW I don't think the GPL is always appropriate. For example, when some legacy company who think they *need* their code to be proprietary see GPL, they just walk. And sometimes that's a case of "good riddance", other times it isn't. With network protocols we generally want everyone to use the same thing, so supporting libs being Apache makes perfect sense. But our Kernels should probably be GPLv3 or later to prevent customers being turned into serfs, as they thoroughly have thanks to Linus rejecting the GPLv3 and BSD eschewing it entirely. This "tivoisation" and lock-out was one reason I wished Redox would go GPL, but they didn't. And because Redox is Rust, we won't have as many jailbreaks if it ever becomes widely adopted and we get locked out.
Composing views isn't supported, as I'm still scratching my head on it. While composition would provide modularity, I'm concerned about the added complexity and the type of modularity that it advocates. As for purely declaring views in views, that is definitely planned, just a matter of designing a nice auto-layout mechanism.
My primary crate `winapi` has almost every definition wrapped in a macro call to minimize boilerplate and ensure consistency. However, the actual docs generated by rustdoc are understandable and you can't even tell that macros were used unless you look at the source code.
Have you considered to use Qt instead of GTK? Qt has better platform support.
I don't understand the licensing we do here, esp since I'm unclassified. But we avoid GPL like the plague "just in case", pretty much.
Having the first crates.io dependency in tree is probably one of my favorite things about this! This is all exciting stuff!
&gt; Are you sure? Also, are you sure that as you add functionality, you aren't going to accidentally add something that may be patented? Do you have sources on the "accidentally" part? AFAIU (but IANAL) it is about people contributing code covered by patents they themselves hold. Unless you mean "accidentally accept patented functionality from their holders," then I'd agree.
&gt; when debugging my own macros, using --pretty=expanded is helpful, but i found myself wishing there was a way to expand just my macros, or a way to specify a certain set of macros only to be expanded Yes, 100% yes! 
&gt; Unless you mean "accidentally accept patented functionality from their holders," then I'd agree. Yes, that's what I mean.
I work for [a company that releases most core business logic as open source](https://scrapinghub.com), and even "we" avoid using GPL code for internal projects.. which I argue against, because I think it's silly. If the usage is internal, then the GPL is irrelevant. And if it weren't.. well, who cares? We can just share the code under GPL if required, we're not exactly covetous. But, companies be companies. :shrug:
In addition to the possibility of this rustdoc bug being fixed, if having to_string visible on the doc page is a requirement, you could just implement ToString (rather than Display). If you're in nightly I think you could also implement both Display and ToString with `#![feature(specialization)]`. Specialization, overriding a larger trait implementation, is not stable, and not really _needed_ here, but it could be used to work around this bug. Example of this: http://play.integer32.com/?gist=95d6d03935a55b89e8adbb49930c1020&amp;version=nightly (documentation correctly shows both Display and ToString implementations).
Nice work! Is there a reason, why the update function/trait takes the Model by reference instead of consuming it? It seems like the old Model is overwritten anyway in the main loop (application::run), and consuming the model seems somehow more intuitive to me at this place.
very cool, as a writer of a few Elm/purescript applications and many many redux apps I love to see this paradigm move into the desktop application space. Shame it's only for OSX though.
Admittedly I haven't read everything in detail it your post, but where did you find the need to call drop() _at all_? In the many projects I've written in rust, I have never called drop() manually, always just letting Rust drop things naturally when they go out of scope. Could you speak to where you found the need to do dropping?
It dies on VMware complaing that the CPU got disabled, which I assume is the consequence of reaching some *HLT* opcode.
When Servo gets ported over, I can see people using Redox instead of Linux.
Hacking in the last couple of bits required to make the example planet in [PlanetKit](https://github.com/jeffparsons/planetkit) real Earth scale. I just landed the (surprisingly simple) hierarchical co-ordinate system that will let me have universe scale game worlds, so it's now just a matter of fixing one silly bug and dynamically unloading chunks that aren't needed anymore.
i'm on windows and i thought cool :(
Yeah, Rust doesn't try too hard to make unsafe code ergonomic. It's not against this, it's just overlooked.
&gt; To point to an example, I wanted to decode a single utf8 character: I mean, yeah, the answer there is "here's a library". It doesn't mean that you shouldn't implement it yourself. You can. It's what you would do in C. It's fine here too. There being a library for it doesn't mean that the community strongly prefers you add dependency bloat. &gt; Even if it came later, it's still a focus. Of course its even a good focus and not complaining, but if you like to do other things they may not be quite as well supported. No, I mean that low level programming was and still is the main focus. Web programming is a more recent focus that is not eclipsed by low level programming. &gt; There are cases where visiting all the elements to drop isn't a no-op. Yeah, I saw that question, the idea is that it should get optimized out for stuff like a vec, and if it doesn't that's a bug in the optimizer. But yes, practically speaking it's quite possible that the optimizer would not elide the loop.
The backend module is declared like so: #[cfg(target_os = "macos")] #[path = "cocoa/mod.rs"] mod backend; So anyone not on macos should get those errors.
Oh, I see.
I think implementing or using a graph structure makes sense in this case. 
Good stuff! I have opened a feature request for auto-closing sidebar on mobile. Thanks a lot, /u/steveklabnik1!
Indeed! This issue is actually something that I want to fix in `relm`. But I'll probably choose another approach. I plan to use (procedural) macros because creating functions for every widget on GTK+ will be a pain. I mostly focused on combining `futures` with `GTK+` which is the hardest part in my opinion.
Steve: I saw http://confreaks.tv/videos/rmr2015-rust-for-rubyists at Rocky Mountain. Thanks for giving these presentations to bring exposure of the language. Think: I've been writing for the web (almost exclusively) for 20 years. I've enjoyed learning Rust, and I haven't written anything for the web with it. It was actually pretty hard for me to think of anything to write with it because it wasn't web, but having some exposure to systems programming has been enjoyable and beneficial.
&gt; Rust sounds like it's more lower level than most other high level languages. While it can be used to do low-level things (as opposed to many other languages who can not), there is nothing preventing anyone from using it on higher level (beside smaller community and availability of existing modules). It seems that python covers most of what you need. It will cover GUI as well. Here is what Rust can bring that python doesn't have: 1. Better understanding of low-level programming. This may let you use python more efficiently 2. High performance for cpu-bound tasks 3. Faster path from "it works for me" to "I'm confident to run it on production" 4. More confidence that your program does not do something dangerous or easily exploitable. Its up to you to decide if those things are relevant for your work.
I don't think Rust is very useful for learning what happens at a lower level. There are too many abstractions for that. The "interesting" low level stuff is hidden behind the unsafe keyword, which you won't use very often as a beginner since it is discouraged so often. For a reason, of course. I'm not saying everyone should write a lot of unsafe code. But if you wan't to understand low level code better, getting into C is a much better choice, imo.
It depends on what you want to apply it to how you value your time. For example, web frontends; although you can use Rust, they're not one of its stellar points at the moment, although progress is being made (see [arewewebyet](http://www.arewewebyet.org/)). Additionally GUIs are annoying, but you can create them using things like [gtk-rs](http://gtk-rs.org/) or [conrod](https://github.com/pistondevelopers). Command line utilities are a place where rust shines. Philosophically, I would encourage exploring Rust, as I find learning other languages really helps develop all your programming skills, especially when learning languages with markedly different programming models than the ones you currently use. Rust is good if you're used to Python, but want to explore more lower-level concepts, as it can be more approachable than C or C++. Nevertheless, it will still be a jump, as explicit memory management, while useful for understanding's sake, is tricky. One of Rust's hardest aspects to learn is consistently the borrow checker. If you wish to dive in, see [The Book](https://doc.rust-lang.org/book/), [The (New) Book](https://doc.rust-lang.org/nightly/book/), and [Rust by Example](http://rustbyexample.com/).
That's not true. Lifetimes themselves are low level: you have to think about where your memory lives. Other rust constructs are fairly easy to convert into their low level implementation in your head (iterators become while loops, functions get inclined, etc) 
Is xi going to get ported? A text editor and a browser is 99% of what I need in a computer.
'T.clone()' a 'Cow&lt;'a, B&gt;'
For web stuff Go/JS/Java/C#/Python, because you don't have to deal with low level annoying stuff, ready to go, ready to be productive, and lot of jobs
Since it runs linux binaries I'd imagine you can run chrome and firefox now. You'll probably need to do the legwork of tracking down glibc and related DSOs.
If Rust seems interesting to you, and you want to write network servers, maybe [Elixir](https://reddit/r/elixir) will match your needs better? It shares a lot of Rust's function-oriented featureset: variables are immutable by default*, pattern matching is the preferred way to do flow control, and classical OOP is nowhere to be found. About performance: Since GC passes are process-local, the world is never stopped, ever. Short lived processes might not even have a collection pass. \* Syntactically, variables are always immutable in Elixir, but message passing is stateful and you can easily use that to provide interior mutability. The standard library includes an implementation of this, called Agent. Shadowing also works, just like Rust.
Wow nice. Would a vdom library like Vue get performance benefits if written in rust webassembly? Anyone working on something like this?
Hi! If you haven't already found it there's a Tokio chat room at gitter.im/tokio-rs/tokio that might be of some use :-) 
Ok, so the Rust book goes over Stack vs Heap allocation, but doesn't really cover accessing/mutating values on the Stack vs the Heap. Would accessing/mutating values on the heap be just as fast as accessing/mutating values on the stack? let ref mut a = .. let b: Box&lt;i32&gt; = ..; *a = 1; *b = 1;
https://www.reddit.com/r/rust/comments/3mw67c/i_am_jackpot51_the_writer_of_redox_a_rust/cvjawfi/ EDIT: that said, programs like chrome and firefox are huge in scope and are much more likely to find bugs or feature gaps in the compatibility.
Wouldn't this always add some overhead compared to raw pointers? In this case, since the user doesn't often manipulate the pointers directly, It isn't such a stretch to say the mesh structure *is* a graph structure, with an API to manipulate it.
Non-js version: https://webcache.googleusercontent.com/search?q=cache:https%3A%2F%2Fusers.rust-lang.org%2Ft%2Fthe-bookshelf-is-largely-implemented-please-check-out-the-new-docs%2F9715
Well rust has Rocket and it looks good.
I haven't worked in the lower level things, but from what I've read in the past, I would agree with you: getting lower level functions stabilized has not beet a priority. However, I don't think this is because the rust team is focusing on the potential for web development, but rather because the focus has been on stabilizing other aspects of the language. Admittedly we are well past Rust 1.0, but that marker was really just committing to backwards compatibility, and that everything that _couldn't be done in a backwards compatible way_ was done. The language was far from complete then, and there are still large parts of the language that are incomplete today. The lower level thing aren't all completed because rust is committed to getting the design right, and not rushing stabilization of features that have not had a lot of community feedback and design focus. It is also true that there is a lon of activity around web services, but it is my understanding that the majority of this has been from the community. I'm glad that people have started using Rust for this kind of thing, and there are a lot of awesome projects happening, but a portion of the community is focusing on that does not mean it is the main long-term goal for the Rust language, or that it is a focus of the core team. I look forward to when more low level functions become stabilized, and if they have as much time to steep and community input as the rest of the language has had, I'm sure they will end up well!
Thank you for clarifying this! That makes complete sense, I hadn't ever considered building that type of partially-free data structure. I can see the use case of having drop data available for that, thanks!
Servo is a loooong way from being ported. What's the status of the network adapters? 
One suggestion. Consider using a standard RPC protocol for this, such as grpc.io. It would be very nice to have an actor framework/protocol that can plug in different languages, each with it's own benefits.
Yay! I was planning to enter, but forgot. Thanks for the second chance. Plus, providing a pre written server should save a lot of time.
Have you considered just using Vec&lt;Option&lt;T&gt;&gt;? Then you don't have to worry about drop, and there's less unsafe code required.
If you do this, looking up the next-free-element needs to search the vector... or you need to store ranges of used indices. While not _that_ bad, its some extra book-keeping which can be avoided. Currently elements in this pool have a trait defined so they can be part of a single-linked list free-chain. [See BLI_mempool.c for an example of C code that does this](https://developer.blender.org/diffusion/B/browse/master/source/blender/blenlib/intern/BLI_mempool.c;d733826708f9b562687b78424e5c0835cba8c3c9) - its used for storing all mesh geometry for editing, also attributes such as color, UV's, shape-keys. ---- Note, an Enum might work well in this case, it would need to be able to re-assign value of the enum to be freed or used, using a pointer to the vector element.
Thanks for the answer!
It seems that Redox rolls it's own GUI stack, is that correct? IMO the project would be much more interesting if it used Servo for that. Something like Chrome OS (preferably with Rust instead of JavaScript, or both). Author said somewhere on GitHub that porting Servo would be massive operation, but so is making custom GUI tooling. Ideally you would have an Servo-based app that runs on Linux and Redox, but on Redox it's x% faster because of some clever optimisations, etc.
In that case, your best bet is to not `Deref`, but allow a `borrow(&amp;self) -&gt; &amp;str` method that returns the string slice.
You may want to complain at /r/playrust instead.
ChromeOS only has relativ success in US schools. I am glad that the Redox guys are going with a proper native UI.
With NoScript blocking font-face the line height seems too low which hurts legibility. Perhaps it would be possible to use a fallback font that works better with the chosen line height (unfortunately I don't think CSS supports font specific line heights). One can always turn off NoScript for these sites of course, but not everyone might realize that it leads to an improvement. Great work by the way!
The answer is... complicated, because of hardware implementation details and some funky things the compiler can do. The short answer is, "generally, the stack is faster than the heap, but it really depends on a lot of things." Strictly speaking, there's nothing special that makes heap access slower than the stack. They're both stored in main memory in the same address space. But you might already know that the CPU avoids accessing RAM directly if it can, because accessing RAM is so horrendously slow compared to everything else the CPU can do. Processor core designers paper over this by having cache memory on the CPU die. These caches are small but very fast, and they're managed automatically by the CPU; it's entirely transparent to code running on the CPU. To keep things simple, when you dereference a memory address the CPU first checks if it's in-cache (hit); if not(miss), it fetches it from main memory, usually going through a few more layers of progressively larger and slower caches first. Note also that the CPU will fetch and cache multiple bytes at a time for efficiency; this is called a cache line. It's architecture- (and sometimes CPU-) dependent but on x86 it's 64 bytes. Of course, with a cache comes the need for eviction: when your cache is full and you need to store something new, you have to make space for it. Values that haven't been recently accessed or have not historically been accessed frequently will be evicted first, which is the first bit that starts to distinguish stack vs heap as far as access performance goes. The stack is accessed extremely frequently, so it's generally safe to assume that at least the top handful of bytes will always be in the fastest cache, whereas a value in a heap allocation may or may not be in *any* cache because it could have been evicted. However, you can also have a value that's at the very bottom of the stack and hasn't been accessed in a while, so it's not in-cache, or a heap value that's been accessed recently and/or frequently and so it *is* in-cache. So access latency is really governed by cache-friendliness more than a stack-or-heap thing. Making your code cache-friendly involves keeping your memory accesses close together, both spatially and temporally. Preferring the stack makes this easier because all allocations are sequential, whereas individual allocations in the heap can be anywhere in the address space, but heap allocations *can* be made cache-friendly. In practice, this means using, e.g., `Vec` (elements allocated sequentially) instead of `LinkedList` (elements allocated arbitrarily), or using an arena instead of `Box` (same concept), and deduplicating data where possible so you have more references pointing to the same places. There is one *gotcha* for your specific example, though: the performance of writes without previous accesses is basically the same between stack and heap, because the CPU (generally) writes directly to the most immediate cache--then subsequent accesses will come directly from that cache unless the value has been evicted in the meantime. And, to keep the conclusion simple, there's a lot the compiler can do to mess with your assumptions, like keeping stuff in registers and never touching the stack, completely eliding heap allocations, etc. etc. It's really too in-depth and full of asterisks to try and explain everything in one answer--believe me, I tried. There's also a lot in this area I still don't understand and I had trouble reproducing my assumptions in the playground in simple examples, so I figured I'd just stop before I spent all night researching for a response *too* far out of proportion to the answer you were expecting. I hope I at least shed some light on the situation, and gave you enough keywords to continue researching for yourself if you want.
On the other hand, Electron apps are very popular. What's the point of reinventing the UI wheel, if people would spend most of their time in browser or web-based apps anyway.
&gt; My argument was that you are not Yeah, I think you are right _too_. Like if I hit a bug in libc, or the kernel, I might be too far away from what the library is doing to try to fix it. I can still run a debugger and maybe see how things break and why. But if I am working way up the stack, I might have no clue what is a component even supposed to do. However, my point was that with a macro I can never even try. I cannot even open a debugger. Things broke, inside the compiler, while compiling rust code. Unless I am working on rustc or the syn crate I am always too far conceptually from that. I have to switch from writing "run time code" to "oh gosh, what was Rust's AST like again?..." That's such a conceptual big jump to me every single time that I feel hopeless: "Do I really want to even attempt to fix this? If so, it's going to take some time to get there, and come back with a solution". I feel hopeless. But I don't really think one can do better. To me, if I hit an ICE as a Rust user (created by a macro or not), its game over. If a library triggers an assertion, a segfault, or similar, I might have a fighting chance.
The `tx` is from the futures mpsc which has a buffer size of 64: ``` let (tx, rx) = futures::sync::mpsc::channel(64); ``` I have assumed (probably incorrectly) that it would only wait if the channel was full. If that's the case, is there a way to send until the channel is full, then block until the channel is ready? 
I've got something cooking right now and it seems to work fine. I'll post a reply here when I have it fully figured out. Thanks for the help!
This is so cool! I haven't done any GUI development (unless you count websites). I'm not interested in using JavaScript and a web stack with Electron to build cross platform desktop apps, but I could see spending some time on it with something like this. I just tried out the code in the readme. Writing some simple Rust code and seeing a native Cocoa window is very exciting.
Because X11 is a dumpster fire with 30+ years of backward compatibility baked in. It has its own kernel, C compiler, networking stack, and depreciated SSL suite. Your silently exchanging 1000+ packets across a Unix socket just to drag a window 1pixel to the right/left. There is a lot of room for improvement in this space. 
Minor complaint: I think having the reference in a single page is better. It is more convenient, faster to navigate, and you can use Ctrl-F. Maybe the book tool can have a single-page mode, like gnu docs have (e.g. [Make](https://www.gnu.org/software/make/manual/))?
I think just calling send without the wait will have this behavior.
I was confused by your explanation of Copy types. From what I understand Copy types are type that are safe to semantically memcopy (which is a shallow copy). The reason that String (or any other type that owns a resource) can't be copy is because it would cause a double free. In the case of String what would be copied with a shallow copy would be the pointer to the buffer,the length,and the capacity.
&gt;New Contributors: Tom Anderson ...the MySpace founder?
This will get better over time though. Afaik `rustc` currently don't passes the optimization flags down to emscripten and thus the actual output is not optimized (which can reduce size quite significantly)
I've always had an ambivalent view of macros. I recognize their power, but I've had the sense that: * Sometimes as a community we reach too quickly for macros * Macros add another layer of cognitive overload; not only do you have to understand the macro language and the macro, but you've got to understand the generated code I lean towards avoiding macros to simplify maintainability.
What would be an idiomatic way to read structured data from a text file/standard input? Here's a (simplistic) example of what I want in C++. struct S { int a; int b; }; istream&amp; operator&gt;&gt;(istream&amp; in, S&amp; s) { in &gt;&gt; s.a &gt;&gt; s.b; return in; }
It does, this was fixed recently. Also a ton more flags are now automatically passed too, so `cargo build --release` is all you need now :)
The idiomatic way would be to use the [byteorder](https://github.com/BurntSushi/byteorder) crate or leave the whole encoding to a binary serializer like [bincode](https://github.com/TyOverby/bincode). But if you want or have to do it the C/C++ way, you can do it like: use std::mem; use std::fs::File; use std::io::Read; #[repr(C)] struct Foo { x: i32, y: i32, } fn main() { // data.bin = b"\x01\x00\x00\x00\x02\x00\x00\x00" let mut file = File::open("data.bin").unwrap(); let mut data = [0u8; 8]; file.read_exact(&amp;mut data).unwrap(); let value: Foo = unsafe { mem::transmute(data) }; println!("{:?}, {:?}", value.x, value.y); } 
Wicked.
At the moment...?
I think mostly just that it can be used for rust debugging? there's even a rust example
Sent an issue: https://github.com/rust-lang/rust/issues/40174 If somebody knows how linking `proc_macro` etc. "internal" crates works, their knowledge would surely help with the problem.
&gt; There is a lot of room for improvement in this space. Yes, and IMO the best improvement would be using the same code for native and web UI.
Interesting, thanks!
Now to integrate with RR.
No longer true! That was a very long time ago - we have broken ABI compatibility on some syscalls like `open` to have a more secure ABI. We do not use C strings for paths, for example, preferring to pass a pointer and a length
Porting Servo does not magically give us a GUI. Servo cannot even be ported without a lot of the work I have been doing on the GUI.
new video on Redox 0.11! https://www.youtube.com/watch?v=pBxVX-gFVW4
My very first MySpace friend, not to brag or anything.
&gt; so I figured I'd just stop before I spent all night researching for a response too far out of proportion to the answer you were expecting. I was screaming "nooooo" inside my head because I wanted you to keep going :-) &gt; I hope I at least shed some light on the situation, and gave you enough keywords to continue researching for yourself if you want. You sure did! Thank you! 
It kinda irks me that `format_args!` is a compiler built-in. In my opinion, it shows that Rust is not expressive enough when it comes to compile-time metaprogramming. I'm hopeful that in the future, it will actually be possible to implement it in *stable* Rust. I also find it impressive that Zig doesn't use any metalanguage, like macros for this. I much prefer finer-grained tools than the unconstrained power, and sometimes hard to understand error messages that come with macros. I consider macros (and especially procedural macros/custom derive) as something of a last resort, when there are no better tools available for the job.
Very popular for web developers you mean? Besides Visual Studio Code due to its Rust support, I don't have any other Electron based app on my computers. Nor do I know anyone that uses Electron based apps.
I will try that, as I used the default size.
Unless you're considering contributing to the upstream `libui-rs` or even `libui` itself, I wouldn't recommend spending time on porting your crate to use it. It's extremely unstable and even the basic "hello world" app crashes on exit on macos. 
You format is basically CSV, so you could alternatively use [a crate](https://crates.io/crates/csv).
There's also the `scan-rules` crate which was posted as an answer to another question this week.
This code works for me, so can you show yours to see what's different? extern crate clap; extern crate rayon; fn main() { let matches = clap::App::new("foo") .arg(clap::Arg::with_name("num_threads").short("n").takes_value(true)) .get_matches(); let num = matches.value_of("num_threads").unwrap().parse::&lt;usize&gt;().unwrap(); rayon::initialize(rayon::Configuration::new().set_num_threads(num)).unwrap(); } 
it annoys me too, but I _don't_ think it shows that Rust is not expressive enough. It's just a decision that was made once upon a time. Maybe it should be revisited, and implemented as a normal macro.
I'm not sure I agree. You need a translation layer from VDOM to DOM, but the benefits of the VDOM code is primarily the diffing service and the memory footprint. For both of those WASM will be a win. My only thoughts on where it might be slower is, mentioned in the article, the overhead of calling WASM from javascript.
I don't think it's possible to do the format string parsing and type checking against it with the current macro system. It would have to be written as an unstable compiler plugin, which is pretty much how it's implemented right now, except it's built-in.
Yeah, I'm disputing the "need functionality" bit here (once the stdlib is using unstable _anyway_ of course it will use other unstable stuff, question is if it really needed to). But you really should open rfcs or rfc issues for the things you felt were missing
VS Code and Atom are the only 2 popular electron apps. Code is pretty good though.
Webrender does not provide graphics acceleration, webrender relies on it being implemented in the window manager. Orbital will not support graphics acceleration for a while, with a port of mesa being the likely route to gain acceleration on AMD and Intel graphics devices.
Oh nice to know. The current web browser in Redox crashes every time when I try launching. Is that a problem with virtualbox or something else?
Any reasons/ideas why tokio/hyper speed is not as good as the C alternative?
I don't think format_args! needs any type information. It uses traits to enforce that arguments are compatible with the format string. It probably could be implemented as a procedural macro now (as of Rust 1.15), but of course, it predates that.
I always love reading Niko's blog posts because I always learn something new and he explains these complex topics in a straight forward way. I'm looking forward to what rules are eventually settled on for non lexical lifetimes
I think once we have stable *const fn*: https://github.com/rust-lang/rfcs/blob/master/text/0911-const-fn.md And *variadic generics*: https://github.com/rust-lang/rfcs/issues/376 https://github.com/cramertj/rfcs/blob/variadic-generics/text/0000-variadic-generics.md Or s.th. similar to the above, Rust should be able to do this without macros. I think macros are not *that* bad. Rust had to stabilize for 1.0 and in order to provide a flexible *print* functionality macros were a good trade off.
&gt; Yes, and IMO the best improvement would be using the same code for native and web UI. That is about 8-10 levels of abstraction above the actual window/display manager. Something has to allocate frame buffer space for the render to display your HTML/CSS/JS this is what Orbital/X11 does. Your whining about something way higher on the stack. 
I just tried with nightly, and empty main with rustc -O is 87k. I took a look at the output to see what's in it, and a nontrivial fraction is pthread stuff. (ironic, isn't it?) Using cargo instead of rustc yielded empty outputs. Again, I think this is fantastic stuff, but the hello experience needs to be much better before people will start seriously considering using it.
It's 10 levels of abstraction on current systems. My entire point is about squashing them. Your whining about something way higher on the stack. It was not my intention to whine. Just wanted to check if anybody else considered this a cool idea. 
Per our relevancy rule, please explain what this has to do with Rust.
You're probably right. I forgot the issue with users.rust-lang.org is that it relies on third party javascript to render (namely discourse). If third party js is not loaded, the page is blank. At least that's what I get. Edit: Disabling all js doesn't seem to improve the situation; Still a blank page.
Make sure you selected Intel ethernet
Zig looks really cool. I like the types as values. Rust should get a lot of these features with upcoming `const fn` support.
It... is a procedural macro. Just not in a plugin.
IDK, but the tokio/hyper stack is large and immature. This seems like fertile ground for those who like to optimize. There's no reason to think we can't catch C.
I don't use any of them with exception of VS Code, nor do people at my company, or customer sites. And even VS Code wouldn't be on my computers if it wasn't for its Rust support, the day Rust gets better IDE support than VS Code, VS Code takes the boot. 
If it wasn't for Rust support on VS Code, it wouldn't be on my computers. The day IDE support improves, it will be purged from them.
You're correct; I may have conveyed the wrong thing (because I got the relationship of `Copy` and `Clone` slightly wrong, despite messing with it a *bunch*)! I'll add a note to the show notes to that effect!
You're looking for r/playrust.
Have you tried Rust plugin for IntelliJ?
cargo is another reason. Or that testing is a first class citizen and that your code documentation gets tested as well. Everthing is about correctness.
As a rule of thumb, anyone making such bold claims by themselves is just being a sensationalist. There has been no uproar in the open source community that I've seen, so I can say pretty confidently that whatever TOS changes GitHub made, they don't actually affect most people. Many people misinterpret the legalese inside of TOSes and EULAs because they don't _understand_ legalese, and I would guess that's what happened here. So, to answer your question: no, probably not. I don't have time right now to review the TOS changes themselves, but I've seen this type of sky-is-falling article many times before.
And you don't need clunky 3rd party tools to generate your documentation ;)
Rust having an ecosystem-wide unified build tool and unified package manager and documentation and testing tool in the form of Cargo makes it _incredibly_ appealing, since you can actually reuse code with very little effort. This makes it almost pythonic in the ease of tackling different tasks, whereas in C++ you must download a tarball of source code and figure out not only where to stick it, but which build tool it uses, and what dependencies it has that are not currently present on your system. It's a royal pain, as I have experienced in the past, which incentivizes people to reinvent the wheel for everything. Linguistically, Rust is more strongly typed than C++. You can't just pass a signed integer to a function expecting an unsigned number or vice versa. You must explicitly state the conversion, taking responsibility for what's happening. [Macros are also hygenic](https://doc.rust-lang.org/beta/book/macros.html#hygiene), which is a big step up from what C++ offers. Rust also offers [native support for tuple-types](https://doc.rust-lang.org/book/primitive-types.html#tuples), which makes the syntax much less bulky than the bolted-on C++ tuple. I also absolutely love Rust's "algebraic sum types" aka. enums/tagged unions. You can model different application states and force invalid states to be a compile time error. If you have a `Message`, you can't access the `x` and `y` values unless the current variant is `Move`, in [this example](https://doc.rust-lang.org/book/enums.html). The compiler verifies this. There's no easy way to do that in C++. Those are just a few objective things that aren't related to memory safety.
That webpage isn't loading for me.
&gt; Use crates.io! I think this is probably a misunderstanding. The community understands well that dependencies have their cost and tradeoffs have to be made. A recent example that comes to mind is [this pull reques](https://github.com/steveklabnik/semver-parser/pull/12) that rolls a hand made parser to get rid of a [heavyweight dependency (regex)](https://github.com/steveklabnik/semver-parser/issues/7) in a crate in the semver-parser crate. The crate is a dependency of cargo, so rather central for rust. Both the author and the reviewer are well known figures in the rust community, so this is no fringe example.
EDIT: This now works on OSX. Thanks to this being open source, another contributor replaced epoll with select. I developed it on Linux, so unfortunately it may not work on Mac or Windows. I am hoping someone makes a PR, but if not I will get to it someday. 
I don't think it is possible to get a value of the constant variable inside of a macro because macros are expanded at earlier stage of compilation, before compiler has the ability to resolve variables.
There's a quite confusing typo in the second code block containing this: /* 0 */ tmp0 = &amp;mut vec; // mutable borrow created here.. /* 1 */ tmp1 = &amp;vec; // &lt;-- shared borrow overlaps here | /* 2 */ tmp2 = Vec::len(tmp1); // | /* 3 */ Vec::push(tmp0, tmp1); // ..but not used until here! In line three `tmp1` is used instead of `tmp2`. In the first code snippet with almost the same code this is done correctly.
Right? It's like they may as well close down shop and go home, because they'd run out of customers.
Sweet! It would also be cool to hook up https://github.com/devtools-html/debugger.html/ to gdb/lldb/rr and Rust
How does the type system prove that the arguments are consistent with the format string? (Which is something that is done today.)
Calling WebAssembly modules as functions from JavaScript might give performance boost for your future web applications. Rust is more than capable tool for creating such modules. A good intro for understanding the gist of WebAssembly (also known as wasm) can be found from Lin Clarks [six part series of blog posts](https://hacks.mozilla.org/2017/02/a-cartoon-intro-to-webassembly/). She works as an engineer at Mozilla.
Seems to me that the discontinuous read/write solution is superior, and I think in fact is easier to explain since it matches most (my?) people's mental model of what *should* be happening more closely. The explanation (I think) is simply "immutable references are invalidated after you use a function/operation with a mutable reference."
The discontinous model would also mean **re**validating previously invalidated references, which would need a place in the explanation.
The only antivirus you need is backups.
I set virtual box to use bridged adapter, and Intel PRO/1000 MT Desktop. The browser now doesn't crash on launch, but only says loading... Can't close it afterwards either.
Even though I use Vim I love seeing little get the tools they need. This is great stuff!
Wouldn't the separate read and write life times allow for more compiler optimizations? Once you know there are no more writes each processor can have its own copy and not try to sync. You can also ignore locks once you know there are no more writes. Seems like it provides richer information to a compiler. 
Except that, from a layering perspective, I want `format_args!` to become a procedural macro in `std` someday, and code generation in a MIR pass seems like asking for trouble.
I've updated the code by refactoring the Initial consumer thread to implement a Stream to clean up the code a bit. I've also removed the `producer` function from the application, and timed it. It takes 1 second to iterate through a 285866 log file if it's not performing regex or sending to postgres. I'm assuming most of that time is just buffering the file, rather than synchronisation overhead. I've also added option to run the thing in serial or parallel. Running in serial: time cargo run --release -- -m s Finished release [optimized] target(s) in 0.0 secs Running `target/release/apache_log -m s` Processing 'access_log' in serial real 2m59.259s user 1m22.424s sys 0m8.816s Running in parallel: time cargo run --release -- -m p Finished release [optimized] target(s) in 0.0 secs Running `target/release/apache_log -m p` Processing 'access_log' in parallel Number of entries:285866 real 0m44.470s user 2m48.449s sys 0m23.350s Running with the `producer` function commented out (i.e, just with the futures overhead): time cargo run --release -- -m p Finished release [optimized] target(s) in 0.0 secs Running `target/release/apache_log -m p` Processing 'access_log' in parallel Number of entries:285866 real 0m0.900s user 0m0.899s sys 0m1.128s To me the bottleneck is not the futures or the thread pool synchronisation. It's actually a combination of the Regex Parsing &amp; Postgres submission. I think replacing regex with nom would increase performance. 
https://github.com/tjdevries/nvim-langserver-shim ;) (I haven't tried it yet)
:D god I love this community for doing things like this.
&gt; mocking This is an under-explored area in Rust; I expect more will happen once compiler plugins happen.
This is really exciting! :) Has anyone gotten autocompletion to work on Emacs using company-mode? Manually calling `completion-at-point` will get the candidates in standard capf-mode, but company itself doesn't seem to trigger. Is `company-capf` not sufficient as a backend?
Are you suggesting mocking via syntax transformations? How do you feel about that from a design perspective? Personally, I feel more comfortable building mocks using traits and types (e.g. `trait Http {...}` and implementing it for concrete types `struct RealHttp` and `struct MockHttp`). I tend to think that approach encourages more thoughtful design and abstraction, but it definitely adds to code bloat by having to add `&lt;H: Http&gt;` on all of your impls.
&gt; But there's nothing requiring b to be revalidated after the mutable borrow is there? But then where's the discontinuity?
Wrong sub -&gt; r/playrust
Here is [an actual lawyer who also understands programming](https://writing.kemitchell.com/2017/02/16/Against-Legislating-the-Nonobvious.html) talking about the github ToS.
There's also this experimental one (which I also haven't tried) that supports the async APIs from Vim 8.x in addition to NeoVim. https://github.com/prabirshrestha/vim-lsp
...... This is a really cool language. 
I've been hoping to do that someday.
I remember investigating that. I am the author of `mioco` which is async coroutine library and I was doing comparison on how `tokio` and `mioco` are different in their reactor code. I might have some details wrong, but I think it's the following problem. The problem is with the fact that when having multiple threads, the io object can be registered in one execution loop, on one thread only. There are 3 low level primitives for any `fd` (file desriptor) to get notification about readiness : register, reregister, unregister. In mioco only when io turned out to be not ready, and code needs to block on it, it would get registered on current thread and unregistered right before returning to user code. This is two syscalls on every blocked IO operation which is a cost you pay all the time. But thanks to this any io object in mioco is never registered in the loop, when user is operating on it, so when it moves to different thread, and something blocks on it there, it will just register, wait, unregister again. In `tokio` every io will register to the loop/thread it was created on, and use edge-triggered notifications from there on. So it never needs to do any syscall about it's registration again. But if the object is moved to different thread, it will be the original thread, that gets notifications about it being ready for io. Which are then forwarded to the thread that is currently handling it. That adds latency if your io object is used on a different thread than it was created on. Also, since `tokio` has a way to split any two directional `io` into reader and writer which are separate objects, and thus moved between threads separately, the approach I used in `mioco` wouldn't be able to handle it anyway. Maybe some optimization or API could be introduced where io objects could change thread/even loop that keeps track of their readiness to the one it is actually being used on. Type system, manual approach of some kind is possible to: In early versions of mioco I had a wrapper type, that would make a given `io` `!Send`, and only when `io` is wrapped in that wrapper, it can be used. If user wanted to send it to another thread, it would have to manually (via a wrapper method) get the sendable version, so the `unregister` could be performed.
Yes I am. The existing gdb variable objects have worked just fine in my (limited) testing with rust. gdgbui uses this api: https://sourceware.org/gdb/onlinedocs/gdb/GDB_002fMI-Variable-Objects.html#GDB_002fMI-Variable-Objects
I use `std::variant` + `std::visit` + `std::overload`/`first_overload` almost every day on C++ at work and they are not even close to Rust's ADT + pattern matching + destructuring + everything is an expression. What in Rust is an ergonomic one liner can take dozens of lines of C++ with multiple horrible nested lambdas containing SFINAE and `constexpr if` tricks, and references to references to references... In a nutshell, C++17 has structured bindings for destructuring tuples, but it cannot even destructure tuples properly (e.g. `auto [x, y] = pair;` works but `auto [x&amp;, y const&amp;] = pair` does not..). Imagine you could destructure not only tuples properly, but also structs and variants, and also nested combinations of those (e.g. struct containing a tuple and a variant). Something like that would come close in terms of power to what Rust has, but Rust solves all of this with few language features that play very well together. To get a taste of what I mean, check out , for example, the implementation of [fold_expr](https://github.com/dtolnay/syn/blob/master/src/fold.rs#L608) of the syn crate, which basically allows you to transform the expressions of a Rust AST into other kinds of expressions. If I had to write this kind of code in C++ I would kill myself. I mean, because of Rust's grammar, one can even destructure structs in function arguments _in place_. 
You have to squint and tilt your head to the left to see it, but using streams and futures you can construct something like that. You probably also want to bring in Tokio as an event loop to execute your self-made "actors."
&gt;Could someone provide a rough comparison of Rust with modern C++, aside from safety issues? That's a big reason on its own. Not a month or two goes by without a huge security issue caused by an improperly vetted/tested C/C++ codebase. &gt;Why would someone choose to learn and use Rust in a project as opposed to, say C++14/17? Is safety the main reason? (Safety is a good reason, I'm just wondering about other reasons.) * Cargo for package/build management is extremely nice. Letting you add/remove/roll back libraries on a whim. * The `build.rs` system is crazy good too. Your build scripts for orchestrating C/C++ builds, as well as linking system libraries is Rust. * Rustdoc is a highly underrated features. Comments are documentation. Comments which are code *are tests*, so if you write bad example code... you can't compile. It'll even generate searchable HTML/CSS/Javascript for you. So your docs/example code is guaranteed to be able to *cntrl+c*/*cntrl-v* into your editor and compile. * Tests are first class citizens. While whitebox testing isn't an *amazing* strategy it helps you mock workable code quickly and give you some confidence you are writing usable code. * Fuzzing/Benchmarking tools can easily be integrated into `cargo test` so generating higher level integration tests doesn't require a full secondary suite. * Cargo is *really really nice* everything I've said so far is just cargo, or cargo plugins. * Rustup is *awesome* for rolling back compiler versions, or rolling forward to (ab)use nightly/beta features. &gt;What can Rust do C++ doesn't * Enums are Unions which lets you have type safe *type variance* without falling back to dynamic dispatch, manually-re-implementing dynamic dispatch, or weird OOP tricks. `std::variant` isn't checked at compile time, so you can freely violate it. * Enums can also be strongly typed integer constants, similar to C's. * Move semantics. `std::move` *seems* simple, but as you read up on all the things it interacts, it spirals out of control really quickly. In Rust there isn't a lot of ambiguity about L vs R values. Or all the legacy cruft `std::move` attempts to encapsulate (renamings interaction with `std::move` is really weird). This isn't a matter of safety, it is more of matter of *reasoning about your program*. * Strong Types. C++ types are nowhere as strong as Rust's. This makes reasoning about the code fairly easy as even pointer state is encoded into types `str` vs `String` or `Path` vs `PathBuf`. * First Class Generics. Rust has *generics* which *to a degree* are like Template-Contracts. Without turning complete-ness. * Multiple-Returns is part of the core language not part of `std::tuple` or `boost::tuple` which is nice. So you can use it *without* the standard library. * Semi-Sane macro system: Rust macros are fully sanitized and guaranteed to exit. At times they can be kind of bulky to work with. Their error messages aren't *horrible*. The system can be kind of clunky, but abstracting away whole implementation details is really liberating. * `#[cfg(..)]` is way easier to reason about then `#ifdef` pre-processor tricks. While more restrictive it frees you up to think about other things. Also OS/Platform support is first class in it, so you don't have to think about *how BSD tells you the build is targetting ARMv7 vs ARMv8*
Conversion between static and dynamic dispatch in generic code doesn't require redesigning your entire class hierarchy! Most of the times you just have to fix up a couple of return types and you're on your way.
I think all current actor libraries use operating system threads, none of them have any kind of event loop support. There's no supervisors or fancy things like that right now.
now ask again in /r/cpp just as an exercise of curiosity 
`std::variant`'s interface is atrocious. `visit` needs an instance of a struct with overloaded `operator()`s, and if you want to use lambdas you need to pull off a great deal of wizardry and black-magic with template metaprogramming. No thanks. C++ is approaching its limits. Technically *it can do anything* but that doesn't mean the interface is readable or usable in any way, shape, or form. Things like `variant` belong in the language.
The _normal_ flow of code is to use `std::visit`, which is always safe (barring the special moved-from state).
You can set up mocking in any language with any form of polymorphism whatsoever.
Code is now available: https://github.com/Storyyeller/fnv-collider/blob/10fd4d28abe7fb6c5428df8fe309dbfb0094530b/collision_generator/src/main.rs#L419
Once RLS is ready for widespread use, I think the plan is to include it with the compiler, just like rustdoc (and it's also planned that clippy will be distributed this way). Like the compiler and standard lib, this means it can be compiled with unstable features even when being included on the stable channel.
Doesn't rust's aliasing model guarantee that, after calling `let b = &amp;a;`, the value of `*b` can only be modified through an `UnsafeCell` until `b` goes out of scope?
Rust has: * sum types * extremely good error handling * much better macros * other nice features
All the good features get the good syntax, instead of the C++ situation where pass-by-move is noisier than pass-by-copy and std::visit feels like a pre-closures listener in Java. There's also the possibility of you influencing the direction Rust goes in. The chance for you to do that with C++ is long passed. Cargo's also pretty cool, but there are C++ vendors offering similar systems. It's vendor-lock-in, but so is relying on Rust, a language with one implementation. It's also newer, and therefore cooler. People are unfamiliar with it, so they haven't had a chance to build up contempt for it. Most of Rust's design choices can be traced back to grievances against C++. The syntax seems weird? It's to avoid The Lexer Hack, so IDEs and the compiler's error reporter can parse broken code more easily. Why isn't there inheritance? Because implementation inheritance introduces way stronger coupling than most people realize. Why is the whole crate one big compilation unit? The optimizer.
What's the relationship between this and [procedural-masquarade](https://crates.io/crates/procedural-masquerade/0.1.0) [sic]?
They were specifically asking about Rust libraries
"If you think you understand quantum mechanics, you don't understand quantum mechanics." - Richard Feynman It's better to just know that I don't understand Type Theory.
This is developed by myself, TOML is mostly used in Rust world, so the web app useful for Rust programmers.
They are based on the same trick but proc-macro-hack is much more complete in its support for macros that expand to an expression rather than an item (fn, const, struct etc). The procedural-masquerade crate supports expression macros but only ones where the result can be wrapped up in a const, like in the example in their readme. This is sufficient for the Servo cssparser use case it was designed for. True expression macros like the add\_one example from the proc-macro-hack readme would not be possible to implement with procedural-masquerade because the result of something like `add_one!(x)` cannot be shuffled through a dummy const.
That's "Proposal 1" in [this thread](https://internals.rust-lang.org/t/accepting-nested-method-calls-with-an-mut-self-receiver/4588).
While tokio (and mio) is great, the code get's soooo much more verbose and ugly than with a nice actor system, apart from needing a lot of work on top to compare to something like Erlang or Akka.
I think the fact that its not Mozilla is what makes it so cool.
This is a clojure library.
&gt; Which part do you consider bad design? The part where every executable produced by rustc is considered malware.
Do you have a write-up on how this (ab)uses macros 1.1 to make all this possible? A blog post discussing the unintended consequences of the macros 1.1 design would be very interesting, and a lot more fun to read than the source to this crate.
oh lord sorry i just realized, lack of sleep.....
Spawn a dummy struct with unexpanded tokens in its definition, invoke custom derive against it (this happens before macro expansion AFAIK), collect tokens and do whatever you want. To my knowledge, the [`namedarg`](https://github.com/comex/namedarg) crate was first to use this technique. `proc-macro-hack` went further by returning `macro_rules!` from macros---oh, [so meta](https://xkcd.com/917/).
[Image](http://imgs.xkcd.com/comics/hofstadter.png) [Mobile](https://m.xkcd.com/917/) **Title:** Hofstadter **Title-text:** "This is the reference implementation of the self\-referential joke\." [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/917#Explanation) **Stats:** This comic has been referenced 1045 times, representing 0.6921% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_deeh2to)
But it's much harder to see the tangible results than in something like a search function right in the most used (maybe, dont quote me) "ide" for rust! But I feel like there is a really exciting aspect to have Microsoft-backed (although it's open source!) editor use Rust! 
Rust won't really help you learn assembly-type "low level", but more academic "low level". It's great for learning how to teach the compiler about your code, but not for learning how computers process code. It's a pretty big jump to go from iterators to jump statements, but not as far from pointer arithmetic in a for loop to jump statements. I think Rust's version of "low level" is ultimately more useful, but there's more than one type of "low level".
&gt; aspects of Django which Rust probably won't have for a while. With Rocket and Diesel, you're pretty much there today :) &gt; GTK+'s less featureful APIs Good thing we have crates.io for the missing batteries :) &gt; For command-line utilities, I use rust Interesting, this is actually one area where I prefer Python. Well, until it gets large enough to have performance issues. My web projects are far more performance intensive than CLI tools. I also am not familiar with Python, so I'm usually torn between Go and Rust for web projects.
Of course you are right, my point is that the abstraction isn't very far away. And if you DO do *array arithmetic* (I know, not pointer... but that isn't even best practice in C...) in rust it's really the same thing. The abstractions are available, but you can always go back to "metal" layer when you need to. And it all gets compiled to the same thing, so it is *useful* to do so (unlike most other languages) 
I've been working professionally in Rust for 2 years. Ownership / lifetimes / affine types / immutability were the main reason I switched to Rust. Without these language features it's astronomically difficult to grow large complicated code bases without winding up with a frightening / unknown amount of complexity. I agree with a lot of what others have said about Cargo, testing, documentation, and other language features. 
Wow. Why did Rust standardise such an unusual evaluation order?
This is cool! I wonder why there's not more tooling like this. It's fairly easy now to write code to pipe CLI output to a nice formatted view in the browser. Or even exposing an API to write out to custom templates or something would be cool for a lot of command line based apps.
This example: println!("{}", { println!("A"); 1 }.lt({ println("B"); &amp;2})); Would become: let t1 = { println!("A"); 1 }; let t2 = { println("B"); &amp;amp;2}; let t3 = t1.lt(t2); println!("{}", t3); And yes that has to be desugared more, but it's kind of hard on a phone to type out. The point is that you're laying out the subexpressions in that statement left to right. And yes, this would mean that: { println!("A"); vec }.push(vec.len()); Would still error with conflicting borrows, but you can't rewrite that by simply breaking that line up. The correct way to write that would be: { println!("A"); vec.push(vec.len()) }; But this is also very different but consider taking a mutex lock in that scope would also clearly state at which point the mutex is locked in relation to the other subexpressions being evaluated.
Care to share that wish list somewhere?
I see thanks. Is this the only reason? I mean I am (quite) fine using racer and being blocked.
Yes, that command will only work on the nightly compiler currently. I'll update the docs to reflect that. We hope to remove that restriction as the rls matures.
I'm afraid you're in the wrong castle.
Excellent summary! /u/carols10cents /u/steveklabnik1 a section covering what the above two posters covered would be a nice addition to the already amazing Rust book :)
I mentioned in the GitHub issue, but it worked for me by temporarily setting `rustup default nightly`.
Quite a [few (experimental) actor libraries](https://github.com/search?o=desc&amp;q=actor+language%3Arust&amp;ref=searchresults&amp;s=updated&amp;type=Repositories&amp;utf8=‚úì).. I've yet to come across any v1.0 actor crates.
Sorry for my uninformed comment, but could this be used for linking directly against C++ code from Rust?
Could you provide a minimal example that exhibits your problem on [the playground](https://play.rust-lang.org/)?
You used to, but this struct has been removed in favour of `as_*_ptr`/`from_raw_parts`. 
Discord
In c++, there are two ways to achieve mocks: 1) Abstract classes, 2) Templates. Traitscan achieve the same result and are more or less the best of both worlds. All of these require dependency injection. It would be awesome to be able to use mocks in a style more similar to the way it is achieved in Python where specific functions can be replaced without instrumenting the lib itself. This would probably require some linking magic.
[Here's the working playground version](https://play.rust-lang.org/?gist=992c67707d432230722a512752428c2e&amp;version=nightly&amp;backtrace=0). I've changed the definition of `ClosureType`, annotated the closure and *removed* annotation of the closure's parameters. What you're doing here is (I'm simplifying a little bit here) putting a reference to `Foo` into a vector of `&amp;Foo`. For this to work, Rust has to know that the lifetimes of references inside the vector is the same (or shorter) than the lifetime of `Foo` you're just putting. If you write: FnMut(&amp;Foo, &amp;mut Vec&lt;&amp;Foo&gt;) // or |f: &amp;Foo, v: &amp;mut Vec&lt;&amp;Foo&gt;| { ... } Rust assumes that each of these references can have totally different lifetime. You want to tell Rust about how the references inside the vec relate to lifetime of `f`: for &lt;'a&gt; FnMut(&amp;'a Foo, &amp;mut Vec&lt;&amp;'a Foo&gt;) (the `for &lt;'a&gt;` syntax is basically the same thing as `fn&lt;'a&gt;` for functions, but for closures). Unfortunately, you can't use this syntax for annotating the actual's closure parameters, so it's better not to annotate the closure itself at all.
This seems to be the problem: let closure = Box::new(|f: &amp;mut rx_thread::Foo, v: &amp;mut Vec&lt;rx_thread::Bar&gt;| { let bar_ref = f.return_ref(); v.push(bar_ref); }); which can be simplified to the following code: fn foo(f: &amp;i32, v: &amp;mut Vec&lt;&amp;i32&gt;) { v.push(f); } The problem here is that we just can't store arbitrary references inside some other `Vec`. We need to make sure that the references we want to store outlive the `Vec` itself. The compiler will not accept this code like this because the function's signature does not enforce this. First approach: fn foo&lt;'v, 'f : 'v&gt;(f: &amp;'f i32, v: &amp;mut Vec&lt;&amp;'v i32&gt;) { v.push(f); } Here, `'v` basically represents an upper bound of the `Vec`'s lifetime. `'f` represents a lower bound on the lifetime of `*f`. With `'f : 'v` we say that `'f` needs to outlive `'v`. This is the important constraint that makes the call to push safe and avoids dangling pointers inside the `Vec`. The `Vec`'s `push` method takes a `&amp;'v i32`. Our `f` is of type `&amp;'f i32`. So, this requires a conversion from `&amp;'f i32` into `&amp;'v i32` which is OK due to the constraint `'f : 'v`. This can be further simplified to fn foo&lt;'a&gt;(f: &amp;'a i32, v: &amp;mut Vec&lt;&amp;'a i32&gt;) { v.push(f); } Sometimes we don't need as many lifetime variables and things get simpler with fewer. HTH
Yes I am aware, and I am using the second one :). The features are mostly working, it's that I can't seem to make the completion play nice with company-mode.
I didn't know discord was made with electron. Makes sense how they got the web interface to look like the desktop client.
Since writing this post it seems there are many in the Rust community who aren't so single minded about taking on deps *(with the assumption that adding deps is _near_ zero cost)*. I got this impression from various discussions on #rust IRC channel, perhaps it's just that people who feel strongly about this are more opinionated on IRC.
This is just a small utility crate I originally created for my own purposes. Recently I made an updated version that works on stable using /u/dtolnay's `proc-macro-hack` crate (kudos!), and I figured it might be helpful for someone else too. The public API is is unlikely to change in the future. (Possibly adding an eager expansion of macros that are found in the input, if that becomes possible with Macros 2.0, but no other public changes are planned.)
`rg` seems top notch to me. I guess I have already saved few hrs in last 2 weeks after installing it.
Really cool stuff. Thanks for sharing. I'm now very glad that I asked a question that I thought was unfair. :-)
&gt; It also becomes important for the implementation to resize based on max dislocation rather than element count, as otherwise inserting elements in-order causes quadratic misery. Hey no worries. I'll for sure let you know. :) I'm doing a bunch of stuff at the moment with RHH; liking it more and more the more I use it: https://github.com/frankmcsherry/blog/blob/master/posts/2017-02-21.md
You can further simplify the explicit type annotation by referring to `rx_thread::ClosureType`, like so: let closure: rx_thread::ClosureType = Box::new(|f, v| { let bar_ref = f.return_ref(); v.push(bar_ref); });
Just an aside: `rg` is great and I've been using it productively for months now. Thanks /u/burntsushi !
Second peteyy_cz. The fact that language server stays in a separate process brings several significant benefits. For one, the language server can spend quite some time without blocking editor to get whole project information, and report back these diagnostics information back to the editor, so one will see compiler and/or linter errors as one is typing.
That's understandable üëç
[rustup](https://www.rustup.rs) might be able to install the GNU version to a thumb drive without admin. Let me spin up a VM and test real quick.
Interesting results. It's faster in wall time with the parallelism, so there's clearly some benefit to offloading the work (as written now; replacing regex with nom sounds promising). But the parallel one uses way more CPU time, so handing off work in units larger than one line might be a lot better. But I don't know why `serial + futures_overhead_only &lt;&lt;&lt; parallel`; that's a pretty dramatic difference. A CPU profile might show something interesting. A lot of contention while doing the work? Here's one idea: You could look into not creating a separate `String` for each line, instead using an interface that returns slices into a larger buffer. I'm not as familiar with jemalloc, but with tcmalloc, allocating a bunch of stuff and sending it to another thread to be freed is a worst-case; it causes the per-thread caches to be ineffective. I wouldn't be surprised if the same were true of jemalloc. 
You can likely use [rustup](https://www.rustup.rs) for this, it doesn't require admin rights. If you really want to avoid keeping Rust on the school machine, then after installing rustup you can move the Rust toolchain it just installed from that machine to a memory stick. Installed toolchains can be found in `.rustup/toolchains/` in your home directory. Then you can use [rustup toolchain link](https://github.com/rust-lang-nursery/rustup.rs/#working-with-custom-toolchains-and-local-builds) to make rustup use the installation of Rust from the memory stick.
Also there is the alternative playground at http://play.integer32.com/ that dos sport cargo. As a stop gap.
... completely missed that part. Apparently I fail at reading comprehension.
Yeah I have a linux livecd on my USB as well, but I got threatened with expulsion when I booted into it once School only has software-side Windows permissions, so in a Linux livecd you can do anything you want to the machines. I imagine they don't like that Okay, in fairness the lessons are unsupervised so I could probably do this, but I'd rather not risk it
The GNU toolchain runs on Windows too. The reason. I suggested it is the msvc version requires Visual Studio compilers be installed, though that shouldn't be a problem in your case
That all sounds correct. I'm going to create a branch in pygdbmi using select. See issue https://github.com/cs01/pygdbmi/issues/5. Thanks for feedback.
I think the only fix is changing your username to joshaber. Being called "Josh" for the rest of your life is one of the sacrifices that you make for being able to use the Rust Language Server.
Rack is not what you describe. Rack is an interface standard. Ruby is a general purpose language and on the interfacing side, I've seen it used for almost anything I can imagine Rust being used for.
Agreed, it is one of the best summaries I've ever read of this though. The authors should write some blog posts!
&gt; Is there anywhere that tracks this? It's always every six weeks, so you can know exactly when the next release is by looking at the last release and adding six weeks.
On Windows, rustc can either use MSVC or GNU [ABIs](https://en.wikipedia.org/wiki/Application_binary_interface). What ABIs are isn't super important. The takeaway is the GNU version of rustc doesn't need anything else installed, but has some trade-offs (e.g. it won't debug with Visual Studio as easily) and the MSVC version needs Visual Studio.
Second this, if this is a thing we end up needing, it should not just be a copy of Rack for many reasons.
If you want I can give you a .7z of the .cargo and . rustup folders with stable and nightly versions of MSVC and GNU toolchains (seems to be about 100MB compressed, 1GB uncompressed). That should be all that rustup downloads. Downside is you have to trust that I'm not loading it with malware. Edit: most of that 1 GB may or may not be temp files as rustup is updating everything right now. Edit edit: nope, it's really 1 GB uncompressed, if you need smaller I can delete some of the toolchains. Also comes out to about 200MB compressed
Indeed. I've been a heavy user of `git grep` and `grep -r`, and `rg` has quickly replaced that for me on all machines I've installed it on.
I know its an interface. But its one which often marks the line where Ruby ends and something else begins, so having well defined interface is desirable. Without such distinction, the need for such interface may exists, but is much weaker.
Nevermind, just read in the comments about https://github.com/tjdevries/nvim-langserver-shim
A [‚Äòtoolchain‚Äô](https://en.wikipedia.org/wiki/Toolchain) is a set (a ‚Äòchain‚Äô) of tools used to compile your code and make it executable (verify its correctness, compile to machine code, resolve symbols in different compiled files and link them together into an executable). Thus typically a toolchain includes at least a compiler and linker, sometimes (as is the case with rust) a package manager, sometimes some code editor etc. With a Windows rust toolchain, you‚Äôll get `rustc.exe`, `cargo.exe`, standard rust library, some linker, some other stuff. You‚Äôll be able to compile your code using `rustc` or `cargo` from `cmd` (or other terminal) by hand, or perhaps to configure your IDE (VSCode, Visual Studio, IntelliJ Idea) or editor with IDE features (Atom, Vim, Emacs, Kate‚Ä¶) to use the toolchain to compile, run and debug your code for you. How to do that depends on the IDE/editor (and it will probably require some Rust plugin) and the toolchain version (especially on Windows it depends on whether you have the MSVC toolchain or GNU toolchain, as they use some other standards for linking, compiling with debug symbols etc.).
Right, and how do I make rustup install onto the USB, such that I could then take it out and use rustc on another computer with no setup? this isn't *as* important because I only use one computer...same classroom, same seating plan, etc, but it would be nice. But overall, as long as it works on the one computer, that would be fine. Also, how can I tell rustup to use a proxy to DL the bootstrapping requirements? It fails because of that I believe, not because of anything to do with admin requirements.
This sounds pretty useful! I've often wanted to test the RLS like this whilst developing it. Keep us posted on development and let us know when its ready for a broader audience!
Could you file an issue on the RLS repo please? (https://github.com/rust-lang-nursery/rls/issues/new) We can try and help you debug this. The best way to start is to set debug mode in the VSCode plugin by changing the `DEV_MODE` variable to `true`, then you should see some error messages in the 'output' window when running the plugin.
These computers are absolute trash. They can often lag with one Explorer and one Chrome window open. Don't think they'll react well to a VM
&gt; On a Windows machine you own and on a network that isn't doing this, install Rustup, and any Rust toolchains (stable, beta, nightly) you want and any components (I recommend rust-src and rust-docs) and targets (you shouldn't need to add any, but it can't hurt to have {x86_64,i686}-pc-windows-{msvc,gnu}). Copy the `.rustup' folder from your user directory to a flash drive. If I can do this, do you still need to provide that zipped file? I have an install of Windows which is capable of doing this. p.s. why do you recommend src?
Some things that might cause you to notice a big difference: * The corpus you're searching is truly large. * You have non-trivial gitignore rules. You might find ripgrep does a better job at respecting them. * You like to use complex regexes. * You are inside a VM.
Racer needs the source to work, if you choose to use it. No, but I've already PM'd you the link, so do whatever you want lol
It's only a 5min download, so I guess I'll go for it. Thanks!
I wouldn't do this. Plugging in a flashdrive with an exe is technically installing executables onto your school's network. While you're likely not getting in a lot of trouble for it, but I definitely had to write up a good long page apology letter for similar things. If you have one, your best bet is to pre-install rustc on a personal/family laptop, and explain to your teacher you want to work on that, seeing as the school's computers are "trash".
If you try presenting it there's a "speaker view" that should show the notes to you.
You're probably right, and the agreement they make us sign every year *does* tell us not to do that, but I've been doing similar things (back from when they forced us to use IE on computers and I got chrome off a USB) for about 3 years now without being punished. Granted, nobody from the IT department has ever had a close look at what I'm doing, nor are they likely to care (they're pretty...relaxed). Given the low profile of rustc (not a GUI or anything) I think it should be fine. If I do get apprehended over this though I will definitely stop doing it. I unfortunately do not have a laptop that would be suitable for this purpose.
I've certainly noticed that rg is better at ignoring (and not ignoring!) correctly than ag and pt. What's with the VM thing though?
Do you know what the proxy settings are, because rustup does support HTTP proxies? Basically you'll want to run set http_proxy=http://[proxy goes here] set RUSTUP_HOME=[flash drive]:\.rustup set CARGO_HOME=[flash drive]:\.cargo rustup-init.exe -y --no-modify-path
Should be able to get those, yeah. Someone provided me a rust keychain already, but if you could tell me how to configure it that'd still be great in the event that the provided keychain fails to work.
Agreed, I would recommend a RPi for pretty much any CS student, just to have a nice, cheap platform to work on. It just seemed like OP was looking for something free to me. But you're right, it could just be a class time thing.
Wow, what a fantastically detailed and easy to follow write-up! I'll share this around internally :)
Hey, follow-up question as the toolchain you provided works great. Slightly off-topic, but how can I configure VS Code to be drive-letter agnostic in using a run command? Currently I need to access cargo.exe in my run command, but that involves using a drive letter. It uses shell commands with cmd.exe so I guess it's more of a question about that rather than VSCode per se.
`rg` has replaced `ag` as my main source code search tool in my editor too! I currently use it with [vim grepper](https://github.com/mhinz/vim-grepper), but it also works pretty well with [ack.vim](https://github.com/mileszs/ack.vim#can-i-use-ag-the-silver-searcher-with-this)
I just realized I didn't give you the .cargo folder so, uh, crap. You should be able to run `D:\.rustup\toolchains\stable-x86_64-pc-windows-msvc\{cargo,rustc,rustdoc}.exe` directly. Or make a folder `.cargo\bin` and copy those executables to it. If you use the Rust VSC extension, by KalitaAlexey, it will have options for absolute paths to various Rust tools, and you can paste those in there in your settings. Both PowerShell and CMD.exe support absolute paths with drive letters for finding commands. In order to not need an absolute path every time, you'd need to put the .rustup and .cargo folders on C: and somehow add .cargo\bin to your %PATH%, and that's done by Rustup. I don't know how to offhand.
I'm using the Insiders build of vscode. Seems the colour theme is "Quiet Light". Though trying it out this morning the colours seem just a little different from the screenshot, but hopefully that helps.
I assigned a permanent drive letter to it with disk management, but is this a solution local to my own PC?
But isn't mmap supposed to make everything much faster and better? :)
For your own PC, you should really install Rustup properly and then the rust tools will have a stable location in C:\Users\you\.cargo and the resources is C:\Users\you\.rustup (`rustc --print sysroot` will give the full path). I'm not sure how it'll cope with a half-baked install.
I have an old macbook (ca. 2011) that I could repurpose, but it's quite heavy and seeing as it's a macbook I think it's liable to get stolen. Even if a prospective thief would later find out they could probably get about ¬£40 for it, the aluminium chassis and light-up apple logo don't necessarily tell them that If my PC which I dualboot Arch and Windows on can qualify as a 'linux box' then I may try that
Yeah unfortunately my free time belongs to Breath of the Wild as of friday :P Just want something productive to do in those lessons, as I'm pretty much already at the level I need to be for the whole course w/ regard to C#. edit: fuck you amazon my shit got delayed
Hmm. I thought the rust tools worked even when deep inside a project folder. Idk though.
It's not the rust tools that don't work, it's accessing them that doesn't. If I'm an unknown level of directories deep, there's no easy way to directly access the cargo exe file without using drive letters, right? I can make the assumption that I follow a strict directory tree, but I don't have faith in myself to do that.
I like rd because its both __r__ust__d__oc and __r__ea__d__
Thank you so much!
Yeah, you should definitely set up your arch install as an SSH server. It's probably easier than getting a standalone Rust tool chain set up. Then again, I'm not super familiar with Rust (I just dabble and follow it in the news), so I could be totally wrong about that. 
Things might get complicated with the network proxies and port forwarding, since I won't be on the local network with arch, but I'll look into it. Thanks.
My eyes bleed...
This is very nice! In particular the beginning because there are not many blogs about futures without tokio
I solved it, that error was due to me symlinking `/Applications/Visual Studio Code.app/Contents/MacOS/Electron` to `/usr/local/bin/code` which caused those error messages. How did you guys create the `code` shortcut?
Perfect. Thank you!
Is there anywhere a nice into to Futures without Tokio (maybe about advanced features too)? I like reading about different projects - that's how I discover interesting crates as beginner (the Tokio code looks interesting). Some time ago I took a short look at futures and failed. The documentation was to bound to Tokio, in the end it was like, hey have a look at Tokio and see how to use futures. For me it was too much. At that point they wanted me to learn about Tokio to figure out how to use Futures -&gt; I was still fighting with the borrow checker and tried to learn Futures. All I wanted is to execute some code in a thread pool. Finally I settled with rayon.
Idk I love ripgrep being rg
I'm only really waiting for Hyper on Tokio to ship. Then I can consider using Rust, writing server stuff, which I think Rust will really shine at!
I think in this case you should use normal `spawn` to create static threads, and implement custom `Drop` behavior for your struct.
Yeah, fair, I don't feel strongly either way.
Yeah, the name was only temporary. I was definitely going to change it, or let it be part of cargo if it's ever integrated.
Loving ripgrep!! Could ripgrep get a flag to not use a regex, just do a regular old search?
OK, I'll try the Arc approach, thanks.
I don't understand this answer. What do interpreted languages have to do with this? What scenarios are you referring to that make Rack unneeded in Rust?
slog has a port of `env_logger` https://crates.io/crates/slog-envlogger . Being composable, slog allows you to use `env_logger` logic with any kind of output(s), so you can log to stdout, file, syslog, whatever... . Ping us on gitter in case you need help.
I am not saying it has no use at all, just that there is less pressure for it. Interpreted languages often interface with non-interpreted code, so they want to have some well-defined interface between. If you go all-Rust (or all-C/C++), this need is less important. Also there are many people who intentionally don't want any abstraction, because the details are important for their code - more then in interpreted languages. There are certainly people that would find rack useful, but their number is smaller comparing to Ruby world. Also, Rust doesn't have many different HTTP frameworks/implementations: nearly all existing ones use Hyper or are planning to do so.
The dependency on recent clang has so far stopped me from using bindgen. I'm interested to see what you end up doing. My program uses rusqlite, so I'll likely follow your lead. That is, if you require bindgen at my build time, I might as well take advantage of it also. I hope this gets fixed for everyone in some way. I wouldn't mind if it got distributed with rustup. Or, in an earlier thread, comex [suggested](https://www.reddit.com/r/rust/comments/5sg9d3/rusts_2017_roadmap/ddfo5e0/) bindgen build all its dependencies, but cargo have a cache of precompiled binaries so this is pleasant instead of horrible. But ignoring bindgen problems, how would a C/C++ program solve this? I think there are three common cases based on how it's distributed: * distribute as source. Do whatever. * distribute as a package that runs on a given platform (e.g., Linux distribution) with explicit dependencies (such as `.rpm` or `.dpkg`). The package manager will guarantee it has the minimum version specified in the manifest, and the shared library creator is responsible for ensuring future versions are ABI-compatible (or bump the major version of the library). * distribute as a binary that runs anywhere. I think this stuff generally gets statically linked (as with your `bundled` feature). I think all of these situations avoid running on an older library than it was built with. Is there a specific situation you're worried about? fwiw, I'm thinking of using `bundled` for when distributing binaries that run anywhere. Older versions of SQLite are slower anyway, so using the system library on my inherently-slow Raspberry Pi 2 (running Raspbian Jessie, SQLite3 3.8.7.1) is a double whammy. I'd rather use the very newest version. Even the one you have bundled now is older than I'd like; the sqlite3 [release page](http://sqlite.org/changes.html) describes noticeable performance improvements since 3.13.0.
New keywords introduced: inout root = &amp;tree.root shared elements = self.queue for owned employee in company.employees { newCompany.employees.append(employee) } for shared employee in company.employees { if !employee.respected { throw CatastrophicHRFailure() } } for inout employee in company.employees { employee.respected = true } * owned = value * shared = &amp;value * inout = &amp;mut value If `inout` were not a legacy keyword, `rented` can be used. Using this approach, is it a benefit to lose the ability of specifying lifetime parameters? 
You use [the `gcc` crate](https://crates.io/crates/gcc) from a build script which invokes the right C compiler for your platform. It's really straightforward (using the example on the repo): Cargo.toml: [package] # ... build = "build.rs" [build-dependencies] gcc = "0.3" build.rs: extern crate gcc; fn main() { gcc::compile_library("libfoo.a", &amp;["foo.c", "bar.c"]); }
I am also waiting! :)
Thank you! :)
Rack isn't an abstraction. A huge part of Rack (the spec) is a list of important field names and stream behaviors. Rust is currently at the state of pre-Rack Ruby - (1.8.0-1.8.5 roughly). Many web applications used 1-2 custom adapters on top of webrick and mongrel back then. That doesn't quite scale.
In the article we use a CPU pool to do some tasks. :) The examples are just thread sleeps because I didn't feel like trying to introduce prime number factoring or something. You're definitely able to set up whatever job you want.
Yeah I really struggled with that too, even the futures tutorial just links to Tokio right now! :(
The blog post contains an example without tokio? I'm a bit confused. I use Futures without tokio-core and haven't had any issues. A general rule of thumb with futures: you might need a lot of 'static, as almost nothing can be guaranteed to live on the same stack.
Yeah I'm familiar with these, had to fix a broken install way too many times. Like I said though, they really hate me doing that and the different WM makes it obvious. It's because the only protections against the C:\ drive (which is supposed to be untouchable to prevent damage; we use a network drive instead) are software-side on Windows only.
Personally, I'd be in favor of `rsi` as a name: - It's short and easy to type - Googling both `"rsi(1)"` and `"rsi" command` gives no results - Just as `ri` is `Ruby Info`, `rsi` is `Rust Info` - Let's be real: I, at least, will type it often enough to justify the joke :P
I may want to hook this up into rustbot somehow, so providing a JSON output for other tools (including IDEs?) to use would be helpful. It'd be nice to do `!fn std::mem::forget` to get quick docs on said function, for example. Though I'd also prefer to be able to not have to put in the `std` and just do `!fn mem::forget` and have it give me all the `::mem::forget`s.
I actually find these keywords are ugly and the benefit is quite questionable by being optional.
What about rudo? (for RUst DOcs)
I love the Rust community! I hope this makes it! &lt;3 Awesome idea!
&gt; Some time ago I took a short look at futures and failed. That text wasn't about now. The blog post is fine, especially the first section that explains Futures. &gt; I'm a bit confused. I use Futures without tokio-core and haven't had any issues. For sure that is possible, but when grasping the concept it is somewhat difficult, because the documentation hasn't much more text than [this](https://github.com/alexcrichton/futures-rs): For more information about how you can use futures with async I/O you can take a look at https://tokio.rs which is an introduction to both the Tokio stack and also futures.` ... which doesn't really help a rust beginner to understand the concept behind Futures.
This is so sad to me, you are obviously very smart and talented, and you feel forced to break the "rules" to learn more stuff, in school. Anyway, I have another solution for you that might be the wisest option. Install teamviewer on your local machine with rust installed and set it up for remote access with a password. Since you can access playpen, I'm assuming teamviewer.com is available from the school network. Teamviewer provides a web interface for remoting by logging in and pressing connect and then a link to the web interface. This process involves no installation on the school computers and will work just fine for programming. Obviously you will have to leave your computer running but that shoukd be fine.
I put a note into the doc channel, linking to this discussion.
&gt; Renamed to "oxidoc". I like the new name! Awesome project :)
Futures are like burritos...
I see you've encountered the [less flattering side of SI](https://github.com/paholg/dimensioned/blob/master/src/build/ucum.rs)! For the uninitiated, the unit of length is the meter, the unit of time is the second, and the unit of mass is the gr... wait what? the *kilogram?!* But... now if I prefix it, is it the millikilogram? or the kilokilogram? Oh no, the linguistic prefixes magically apply *as if* the real unit was the gram, even though we're magically hardcoding the real base unit to be *kilogram*. Temperature is the best part. Let's say I have `1 meter + 1 meter`, that gives me `2 meters`, right? And if I convert them to centimeters, `100 cm + 100 cm = 200 cm = 2 meters`. Great! Now `1 celsius + 1 celsius = 2 celsius`, but if we convert to kelvin, `274 k + 274 k = 548 k = 275 celsius`. Oh dear. And it never really gets any better. Ok, so we can prefix units right? Like meter -&gt; kilometer and meter -&gt; centimeter, or Byte -&gt; kilobyte and Byte -&gt; centiby... wait, wtf is a centibyte? That makes no semantic sense! But... how am I supposed to make the centi prefix type check for meters but not for bytes? And bytes are far from the only exception: I can have megapixels, but not centipixels. Ugh. In my experience, writing a units library is as much about wanting to burn the scientific world to the ground and rebuild it from scratch as it is about writing code.
Celsius isn't SI, and for this reason.
After you've deployed the entire system, it's probably too late.
There have been a lot of discussions about crate ownership, and the general answer is no, we can't/won't take a crate.io package/name away from somebody due to abandonment. That said, I am very curious about the state of rust-crypto, and if it actually is abandoned, a fork should emerge under a new name.
I think you are looking for https://www.reddit.com/r/playrust/. This sub is for Rust the programming language. Don't worry, it happens all the time. ;) 
It is controversial for this reason, yes, [but accepted enough to be listed on the official table as a derived SI unit](https://en.wikipedia.org/wiki/International_System_of_Units#Derived_units). It's also accepted enough that if you try to explain why it's not in your units library people will ignore your library rather than listen to your explanation!
This reminds me about Anders Hejlsberg's comments on "simplexity". Anders is the man behind Turbo Pascal, Borland Delphi and Microsoft C#. It was a term he invented to criticise dynamic typing. Dynamic types promises to make code simple. You don't need to bother with types, people say, the language just works. Sample code is immensely readable. But then you realise the necessary coercion under the hood means that equality doesn't work in an intuitive way, so you need to learn the difference between === and ==. Then you realise that either you can't use polymorphic operators (PHP and +/.) or you _can_ use them but they get incredibly strange results depending on whether a string was coerced to an integer or not at some point in the call chain (JavaScript). Once this bug bites, you end up having to educate yourself not only about types, but additionally about how the language _interprets_ types, and defend using third-party annotation tools, or if you're a JavaScript library, parseNumber calls. All of which is much more intellectually complex than just writing `int a = 2`. Yet you still pay the performance penalty for the dynamism. Swift's memory model seems similar to me. At first it's easy: you just don't worry about memory. But almost immediately there's the problem that you have to decide whether an object is allocated on the stack (struct) or heap (class), and determine it permanently for all instances. Next you encounter your first leak (likely in a closure), and now you need to worry about reference-cycles, and the `@unowned(self)` and `@weak(self)` annotations, and the subtle differences between them. And then to hit performance, you need to know the difference between `owned`, `unowned`, `shared`, `inout` and `weak`. All of this is arguably more complex than Rust's approach, where RefCounting is almost never used. Yet you still don't have data-race detection. I get why they did it, and perhaps with the Objective-C legacy it was unavoidable. But it's still noticeably more cumbersome and complex. 
Does it type-check arbitrary complex unix like Boost.Units? let length = 20.72 * si::meter; let time = 12.39 * si::second); // Some weird unit let some_stuff0 = length * length * length * length / (time * time * time); // Do some work on weird unit let some_stuff1 = length * length * length * length / (time * time * time); let some_stuff2 = some_stuff0 + some_stuff1; // Is this si::meter / si::second ? let velocity = some_stuff2 / ( length * length * length) * time * time;
Happy to. For what it's worth it went over quite well. This was to a group of mostly Java developers. I'll probably write a blog post about what I found most resonated/ confused the group and that'll be on /r/rust eventually.
For a practical application, multiplying your centibytes, you'll see that you can pack 5 values with 3 options each into a byte `(5*19.8 &lt; 100)`, i.e.: `a+3*(b+3*(c+3*(d+3*e)))`, range 0-242 inclusive.
What do you mean by "system"? If you're writing driver-level code, you'd use memory management from the start. If you're writing a desktop app, you'd push an update.
I thought spotify used electron in some capacity? Am I crazy? Edit: I see that they implemented their own version of the same idea.
[According to semver](http://semver.org/#spec-item-4), releases prior to v1 are used for "initial development", which implies that the package is not ready for use in a production environment, aka. the logic inside the crate is unstable, and the API is unstable. I'm arguing that the logic seems to be sound, _plus_ there hasn't been much in the way of API breakage lately either. I dunno.
&gt; Yeah, definitely do not run bindgen at compile time. That's interesting, and I'm starting to agree, but bindgen [specifically recommends](https://github.com/servo/rust-bindgen#library-usage-with-buildrs) exactly that: &gt; Library usage with build.rs &gt; &gt; üí° This is the recommended way to use bindgen. üí° --- &gt; put a package on cargo you can depend on that ships specific sqlite sources I do have a `bundled` option that includes source, and adding prebuilt bindgen for that would be easy. I would still like to allow people to dynamically link with their system's SQLite lib, though. Leaning towards shipping bindgen for the min required version(s) and picking the right one at build time based on feature selection.
&gt; Probably a strange way to talk about it though Well yes, that's kinda what I'm getting at: we've allowed social convention to pollute our way of thinking about these things to the point where we're discussing centibytes instead of the underlying mathematical concept that not all data types "fill" a whole number of bits.
Jim just finished writing the penultimate chapter and is working on the final one now
Yes it does.
Pro tip: `rustup run nightly cargo install clippy` can be written as `cargo +nightly install clippy` Edit: Also, Rusty Code is not maintained anymore IIRC, you should just install the extension called "Rust".
I guess it depends on what you mean by "system". If it's a desktop app, then you'd write the whole thing without memory management. Find parts that are too slow, then drop down to memory management for those parts. It's like writing an app in Python then dropping in to C when needed.
Note that structs in swift aren't necessarily stack allocated or stored inline in other types. By default the language reserves the right to box them for performance reasons or to make code more resilient to changes (it's ABI-stable to add, remove\*, and reorder stored fields by default). Classes vs structs in swift are primarily about whether you want reference or value semantics. \* must provide an equivalent computed property 
&gt;All of which is much more intellectually complex than just writing `int a = 2`. Or `let a = 2` in a type-inferred language :3
but if you have sane coercion rules, it‚Äôs all OK. python has no automatic string coercion, so you can‚Äôt accidentally do `1 + '2'` and get `'12'`. don‚Äôt get me wrong, i love static typing, but python‚Äôs dynamic type system really didn‚Äôt cost me much (if any) time.
Let‚Äôs not? I commented on github: &gt; I‚Äôm very opposed to making a 1.0 release just because. Upgrading from 0.1 to 0.2 was a huge pain. In Servo we had to coordinate upgrades of 52 dependencies: https://github.com/servo/servo/issues/8608. Upgrading only some dependency but not others would cause build errors because they typically use some libc type (like `c_void`) in their public API. &gt; &gt; And wasn‚Äôt just Servo. crates.io lists 1210 reverse dependencies for libc now. &gt; &gt; I think that a much better justification than just getting a nicer-looking version number should be needed to force the ecosystem to go through that again.
and I responded &gt; &gt; I'm very opposed to making a 1.0 release just because. &gt; It's on the official Rust Roadmap. It's _very_ hard to argue that _`libc` isn't essential_. The reasoning is detailed on [the issue here.](https://github.com/rust-lang/rust-roadmap/issues/11) That alone should be reasoning enough to do the upgrade. &gt; However, @lambda has pointed out that issue #180 needs to be resolved. If #180 were resolved, that would be a significant change, and that should warrant a big upgrade, should it not? So, one way or another, this needs to happen in 2017, and maybe we can make a significant fix to the `c_void` type at the same time, which would be nice to have. &gt; It makes a lot of people nervous to depend on libraries that declare themselves unstable, yet `libc` has definitely reached maturity and should be considered stable. Updating the version number is an important symbolic step, and is not a trifling thing done "just because". However, I would agree that it should only be done when major issues like #180 are resolved. I think we need a roadmap for fixing that issue.
You might as well learn rust at that point!
HÃõÕûÕ¢ÃôÕéÃñÕàÃØÕçÕàÃñÃ±ÕçÕàÕéÕáEÕ¢ÃßÃπÃ´ÕàÃùÃ∞ÃôÃóÃªÕïÃû Õ¢Õ†ÕòÃ•Ã•Ã™ÃªÃ≥ÃºÃ§Ã±Ã£Ã†Ã•ÃùÃûÃóÃ∞Ã¶CÃ°Õ¢ÕôÃ§Ã¶ÃºÃ≥ÕôÃúÕàÃùÃØÃÆÃ≥ÃñÕçOÃ∏Ã¥ÕüÃ∏ÕûÃºÕôÃñÃñÃóÃÆÕçÃ≥Ã≤ÕöÃùÃªÃ¨Ã™ÃØÕöMÕòÕ°ÃπÕìÃôÕÖÃπÕéÃñÃªÃ≤ÃüÃ≥ÃüÃ¨Ã≤ÃóÃ∞Ã™ÕöEÃ∑ÕùÕîÕáÃ´Ã©ÕÖÃ±ÃôÃ∫ÃòÕéÃúÃ¶ÃØSÕèÃßÃòÕìÃ±ÃªÕâÃò
&gt; Upgrading only some dependency but not others would cause build errors because they typically use some libc type (like c_void) in their public API. I'd like to see some sort of general answer to this, especially because the Futures ecosystem looks like it is going to encourage the same version interdependence. Edit: The discussion below suggests the version interdependence for libc is due to system linking rather than using the types in public interfaces of other crates. There's a similarity, though, in that either creates a situation where dependencies need to use the same version of some crate. And afaik Cargo, and maybe semver in general, doesn't have a great answer for that. 
So it seems most people believe that a "1.0 quality" release should be made, but the question is whether there should actually be a code breaking 1.0 release. Is that a correct assessment?
&gt; We need to start showing confidence in these packages and release v1.0 versions. Big +1. I know the libs team is working on it for stuff in the nursery.
No. You cannot take ownership of a crate on crates.io. You can instead fork the crate, create a new one under a different name, and maintain that. Or, of course, you can also always get in touch with the existing maintainer and see if they are interested in transferring control or adding someone else as a co-maintainer. As far as rust-crypto goes, I wonder if it really should have so many dependent crates. As a relatively new, un-reviewed crypto library, there's a good chance of vulnerabilities in its implementation, especially timing, cache timing, or other sidechannel attacks.
I had a longer point by point reply but the short version is that &lt; 1.0 in this instance means "no long term support" not "doesn't work". 0.2 -&gt; 1.0 is a potential solution but there are a few things that they were planning on doing before 1.0, the question is should those be done now or wait until after (which makes those changes 2.0 changes since they are breaking)
I think budgefranky is mistaking the static &lt;-&gt; dynamic difference with the weak &lt;-&gt; strong difference. Python is dynamically strongly typed.
&gt; While I could define it for the second meaning I'd be surprised if you could! At first glance it seems that we just need to get rid of the silliness of putting the zero at some place other than, well, zero, and that will solve our problem. Just use kelvin amirite! But it doesn't. The problem is that temperature is not a dimension and kelvin is not, at least in the same sense of any other use of this word, a unit. Kinetic energy is a unit, and number of a particular particle is a unit, but *average* amount of kinetic energy in a group of particles is no more a unit than average age of a population is! Time is a unit, and you can add and multiply seconds, but you cannot add and multiply *averages* of time over a population: if the average age of boys is 22 and the average age of girls is 24, the average age of everybody is *not* 46. Likewise, if you take two cups of water at 50 degrees and put them together, you do not get a cup of steam! Hence, Kelvin is *not* the same kind of mathematical object that meter/unit/byte/pixel/second etc. are. Putting it on the same category and in the same charts as them is horrendously misleading. EDIT: I need to rethink this; there's definitely a valid plus op somewhere, but it's also definitely not valid in the above examples. Hmm.
I should have mentioned weak typing but its deficiencies are magnified by dynamic type-systems due to the difficulty of knowing the concrete type chosen at the runtime. Hence why JavaScript is so much worse than Python. To be clear, this isn't about typing, I was just quoting Anders example. That said, I'm not a fan of either dynamic or weak typing. I don't think the tradeoff is justified. Languages which support generics (or structural typing) and type inference such as F-Sharp and Elm show that one doesn't need to sacrifice compile-time type checking &amp;amp; optimisation to gain terse, flexible code. 
&gt; &lt; 1.0 in this instance means "no long term support" not "doesn't work". But isn't this willfully ignoring the semver contract? As I understand it, semver's version 1.0 doesn't imply long-term support, only a promise not break APIs in 1.x versions.
It is pollution: it applies the concept of scaling to the *unit* rather than to the value being scaled. This then primes you to think in terms where values are arbitrarily scalable and that this is somehow tied to the concept of thinking in units, and that is not true: it is perfectly sensible to say 1 car in a way that it is not sensible to say 100 centicars.
Is there a reason to recommend source $HOME/.cargo/env As opposed to adding the following to .bashrc? export $PATH=$PATH:$HOME/.cargo/env
Generics is the one place where dynamic typing does seem to win you something, IMO. Statically-typed generics require a lot more type system knowledge than `int a = 2` or a function dynamically calling named methods on its arguments.
Ok thanks.
That's a weird comment. Care to explain?
&gt; Doesn't cargo guarantee that updating a major version number will not break existing packages? Maybe I'm out of the loop, but what kind of apocalypse is going to happen if you just take the current version and re-release it as 1.0? When you link to a system library, you're only allowed to have one such link in your crate. `libc` links to, well, libc, so in this case, you can only have one version of `libc` in your graph. &gt; Also, why is this crate at version 0.2 to begin with? Semver says that major version zero is for "initial development". That seems to imply to me that versions below 1.0 are not intended for any serious use whatsoever. Yet libc is the most used crate. What does this mean? It means that Rust is young. People use pre-1.0 crates because most things are still pre-1.0.
I just did start a (Rust-focused) blog the day before yesterday, so I'd like to encourage you to do the same! Just use something like Hugo and host the blog on GH pages -- the setup is great for developers, having to ever only deal with your IDE and git CLI in order to create &amp; publish posts :) (Instead of going through an authoring GUI like with medium.com, WordPress etc!)
Someone cared about what you wrote here! (And more than one, it seems.)
It's not just that we can't, but this will happen for any similar package. `libc` is brutal because of its universal-ness, but openssl was tough too. Anything widely used will have this issue. Smaller stuff will too, but it's less of a pain.
More competition for rust, Swift is easy to learn has readable syntax, has same features, and is not limited to FP :p
Cheers!
I usually prefer Result&lt;Option&lt;&gt;&gt; because otherwise the outer None would imply that no operations that can fail even took place
Yes, you absolutely should - unless you're actually asking about the programming language.
We're looking for Rust stuff, yes! :)
The name for `MyStruct { field: value, .. &lt;expr-of-type-MyStruct&gt; }` is *Functional Update* or just [*Update*](https://doc.rust-lang.org/book/structs.html#update-syntax). 
Another options is to convert `Option` into `Result` via `ok_or` and have a single plain `Result`
rustc will error, because types are different.
I hope this all gets implemented :-) Except for the fn use_map&lt;K, V&gt;(map: HashMap&lt;K, V&gt;) { ... } Which I hope we skip altogether and instead going all the way to fn use_map(map: HashMap) { ... } ...because of the many cases where `K` and `V` are never referenced inside the fn body.
At the same time, I think too much implication is a bad thing.
I believe this is the difference between thermodynamic temperature (It is 30 degrees outside) and temperature (temperature difference?) (it is 5 degrees warmer than yesterday).
And my RFC was cited as careful extension *blushes*. That said, I'm not too keen on the `use_map` example ‚Äì ADTs mean we deal with a good number of types, not all of them as well-known as `HashMap`.
If I remember correctly the only outside dependency in the RustCrypto project is `generic-array`, so it makes a bit easier to keep all versions in sync. (there is some problems with it right now, but I will fix them soon) Though propagation of new versions could be definitely a bit tedious sometimes, especially if breaking change is near the bottom of the dependency graph. (even more if changed crate contains public traits) But I think this additional workload is not useless, as it allows users to use only that they need and nothing more. After stabilization of the trait APIs I think it will be a bit easier to manage crate versions, as most of the changes will be either addition of new algorithms or internal changes with patch version bumps.
So, those two things are different. `source` will run that file, whereas the latter puts that file on your PATH. You don't want to put that file on the path. cat $HOME/.cargo/env you'd want to add this, that is, the _contents_ of this, to your .bashrc. Personally I can never remember if it's supposed to be .bashrc or .bash_profile or something else.
I would like to see less repetition for trait bounds. In a module the same or similar trait bounds are often repeated over various functions. Why not allow us to write type T: Clone + Copy + Eq; and then refer to T in the rest of the module? type T: Clone + Copy + Eq; fn foo&lt;T&gt;(t: T) { ... } fn bar&lt;U: T + Default&gt;(u: U) { ... } Would become a shorthand for fn foo&lt;T: Clone + Copy + Eq&gt;(t: T) { ... } fn bar&lt;T: Clone + Copy + Eq + Default&gt;(t: T) { ... } 
These videos are always good. But this one is particularly great. Thanks so much for the effort that goes into getting them online, they are very appreciated by the Rust diaspora.
Oh, that's right. I guess what I'm confused about is. We only are asked to run the following from the command line. Even in the official instructions this is the same. source $HOME/.cargo/env Shouldn't we be instructed to add that to the bashrc anyways? Otherwise we have to source that in every time we spawn a new top level shell.
Unfortunately there‚Äôs only one way to completely avoid this problem: don‚Äôt make breaking changes. The creator of Clojure gave [a 76 minutes talk](https://www.youtube.com/watch?v=oyLBGkS5ICk) about SemVer that sums up to: if you want to make a breaking change to a function, don‚Äôt. Make a new function instead. Document the old one as deprecated if you‚Äôd like, but don‚Äôt remove it.
What I really want to see is lifetime elision in structs, at least in simple cases like where there is only reference. If I have, for example, a struct with one reference in it: struct Bla { a: &amp;str } impl Bla { fn new(a: &amp;str) -&gt; Bla { Bla {a: a} } } Unless I use a special lifetime like 'static, which is a rare case, I literally only have one way to add a lifetime: struct Bla&lt;'a&gt; { a: &amp;'a str } impl&lt;'a&gt; Bla&lt;'a&gt; { fn new(a: &amp;str) -&gt; Bla { Bla {a: a} } } And for this simple example 4 changes were needed. Since there is only one way to fill it it's just ceremony, and it answers all categories - Applicability - structs that contain references are incredibly common in rust because of the strong ownership gurantees. Power - since in the simple cases there is only one way to fill it anyways, it doesn't change anything. Context-dependence - if there is only one lifetime, all 'a tells you is "this reference has a lifetime", which is no information at all, so not having it doesn't really change anything. You won't forget that references have lifetimes without it, otherwise elided lifetimes in functions won't work. And yet, I haven't seen any push for this anywhere. For me it just makes it a pain to add a reference field to a struct, which is bad since in rust it's actually safe and efficient to do.
&gt; Semver says that major version zero is for "initial development". That seems to imply to me that versions below 1.0 are not intended for any serious use whatsoever. In practice, almost everyone ignores that part of SemVer.
For the "discarding ownership" example: wouldn't it be better for functions to generally ~~take `AsRef` and `AsMut`~~ take `Borrow` and `BorrowMut` arguments instead of `&amp;` and `&amp;mut` arguments?
The second one is not even an option really, since it can't distinguish between the column not existing and the value being null (which is perfectly valid). Go with the first choice.
FYI, Scott Olson and I have got a draft (just an outline) RFC on more or less exactly this topic: https://github.com/nikomatsakis/rfc-elision-2.0 
Ah cheers. I had already had it manually setup on personal machine before rustup hit 1.0. But I noticed I had to manually source it on another server. Which led me to believe the installer wasn't doing it at all. But I guess there was a permissions issue and the installer wasn't able to set it. I wonder if a warning note could be issued to inform the user to do so manually.
&gt; Docstrings are absent because they are not included in Rust's AST at the moment, but that could be a future improvement. Does the AST have attributes? Doc strings are promoted to attributes with [is_sugared_doc = true](https://github.com/rust-lang/rust/blob/0648517faf1e2cf37c8b6770cbd0180a816ed9a0/src/libsyntax/ast.rs#L1672).
rust is a expression oriented language. The `;` is very significant. NOT having it signals that you are returning to an outer block
Something I've been thinking about with rust ergonomics is pattern matching. I'm not sure if macros can solve this problem, but something like Haskell's `PatternSynonyms` or `ViewPatterns` could be useful in Rust. This particularly comes up with references. If you have a struct/enum and you want to wrap up the values in the fields with some reference type (say Box, Rc, Gc, etc) then you pay a bit of a price when you pattern match on your type. With better support for powerful pattern matching a lot of the syntactic noise in these cases could be hidden in the pattern match syntax. Like the proposed `box` keyword but a more general mechanism that can be used for any user supplied type. This feature would come with the obvious downside that it could be abused to write obtuse code, but I think it would probably worth it in spite of that risk.
1. "hard to learn" and "unreadable syntax" are not synonyms. 1. How is Rust limited to functional programming? That's not true in any way. You're probably mistaken about what FP is. Though it borrows quite a bit of ideas from fucnyional languages, you're not limited in any way. You can write code directly equivalent to a C program, it's just disencouraged since that'd defeat the goals of the language.
The example for implied bounds is `HashMap`. However, the definition in std doesn't actually have any bounds on the struct, only on the impl. This is a common pattern in std. Would this convention be changed, or is there some other way to decide which bounds to carry from impls to functions? You could inspect the function body and see which methods are called, but that would violate the principle that Rust doesn't look in function bodies while typechecking their signatures. Also, this breaks down in the case of things like `Cell`, which now has an `impl&lt;T&gt;` and an `impl&lt;T: Copy&gt;`.
I don't know Scala, so I just searched for information about semicolons in that language, and the very first result was about a [confusing situation](http://stackoverflow.com/questions/10656799/when-are-scala-semicolons-required) caused by semicolon elision.
AsRef and AsMut aren't implemented for &amp;T and &amp;mut T. 
This almost but not quite addresses my biggest annoyance with Rust. Modules should be namespaced by default. Just barfing random names into the root namespace should be something that you can do if you really want to, but you are discouraged from doing. Python, Go, and ES6+ get this right. C, Ruby, and bazillion other languages get this wrong.
but can it memory safe + no GC. 
You could do that, but "30 degrees warmer" is a different type of temperature than "0 degrees." Pounds-force and pounds-mass is a good analog. In normal speech we equate the two when dealing with gravity because on the surface of the earth they are equal. Go to the moon and things fall apart. Temperature is similar if you think about situations when the delta is negative: "The temperature has changed by -5 degrees." Thermodynamic temperature can't go below 0 degrees Kelvin (absolute zero). Temperature difference can however.
If you're already familiar with Rust to an intermediate level, then I think it could be a great experience. LALRPOP is a very nice tool for building your parser, which should be very easy to implement, assuming they're giving you the grammar in BN-style notation. I'm not familiar with libraries that implement a lexer, but building your own DFA-based lexer is an extremely straightforward process.
Which also supports the RLS. And I think it asks you if it should install rustfmt and racer, if you haven't already.
of course if path = &amp;other_path already then it doesn't take ownership. Honestly, rust already has implied copy. I kind of want it to just have implied borrows as well. If you are owner and you are passing a value to something that takes a reference -- just pass on the reference. I don't see what the big deal is...
it is very nice when I write something like let x = foo.iter() .filter(|x| x &lt; bar) .map(...) .collect(); That whitespace is not significant. Coming from python, this is WAY more readable than having to put parentheseis around everything (or worse, ending your line in `\` and praying you don't have a space acterwards.)
Yeah but you can do that in Scala too because it just figures out that a the `.` means 'oh no semi colons there' (I have no idea how it works, but most of the time it just works, or good ergonomics if you will).
That's probably an unpopular opinion, but I still want to provide an alternative one. As a beginner still learning the language, I'm not overly enthusiastic about the one million and one ways rustc will inference stuff looking at some (but not all!) of these changes. When building a mental structure of the language it's sometimes very helpful when compiler is being strict and by doing so straightens your mental image of what's going on. Each inference rule (which will sometimes inevitably fail) increases the complexity of predicting how a piece of code may be understood by the compiler. I'm already doing bets in my head on whether rustc will coerce stuff in my code or not. If you are too liberal with adding such rules, you will get stuff that now happens with JavaScript. Someone decided in the 90s that js will be very "ergonomic" for beginners and will do all kinds of coercions. What you have today is an infinite amount of fabulously obscure questions on stackoverflow about why a piece of weird js code does what it does. That is not to say that I disapprove of the initiative, but I just want people involved to keep downsides in mind and not think everyone wants their code to compile at all costs.
I have wondered if there is a clever way to combine the 2 builder patterns into one. Specifically, I kinda wish I could just always use the borrowing builder pattern, but still "lift" the final return type into something I can own if the finalizer needs to consume it (assuming the owned value is in scope). e.g. assume `bar(&amp;mut self)` and `baz(&amp;mut self)`, but a consuming `build(self)`: let mut foo = Foo::new().bar(); if flag { foo.baz(); } foo.build() (disclaimer: I haven't thought enough about the problems this creates or how badly it breaks the mental model of borrowing/owning. I've just had to explain the 2 builder patterns too many times.)
I prefer structured logging on principle. Determining whether the implementation `slog` provides is sufficient is one of the things I still need to evaluate.
I have a question that i haven't seen an answer to anywhere: Why is the syntax for borrowing a field inside a match "ref" instead of "&amp;" like it is everywhere else? Is there something I'm not understanding here?
&gt; You are probably downvoted for your language. childish
This one was great! Btw. is it you Manishearth doing the M.C. at the beginning?
Thanks! Yeah, it was. I forgot to introduce myself.
Oh yeah, I'm very much in favor of the 1.0.
Seems good, yeah :)
I suppose this is the opposite of the implicit borrows scenario: implicitly retaking ownership, but only for `&amp;mut` references when the owned value is in scope and never used again.
Good catch; looking at the docs and the relevant [section](https://doc.rust-lang.org/book/borrow-and-asref.html) of the book, it seems I meant Borrow and BorrowMut.
Of course, trait impl's already do this when methods have `&amp;mut self` -- so it's not like this is a new concept. I think if you care about a Mutex drop you should either be using a context or calling `drop` manually. I would support making it "easier by default" but having two lints: * `implicit_mutable_ref` * `implicit_immutable_ref` That way library authors who were concerned about this could still have the lint guarantees. Different kind of applications will care much more than others about these kind of issues. 
In an expression `&amp;` makes a borrow, but in a pattern it destructures a borrow. So, `let &amp;x = &amp;5;` assigns `5` to `x`.
&gt; could you please remove `;` Categorically opposed. Significant whitespace is perhaps my second-least-favorite Python language feature. Indentation and line breaking is conventional, which means that by definition there are cases where the convention should be eschewed; whitespace is not preserved on passing through a *wide* variety of textual media, including most of the Internet (like the newline, eighteen spaces and tab between these arrows: ‚Üí ‚Üê); and Rust's semicolon carries nontrivial semantics, which are not, even in principle, replicated by newline. (Also, though this is entirely on me, people arguing for semicolon elision always put me in mind of [this particular cringe-inducing exchange](https://github.com/twbs/bootstrap/issues/3057). Simpler syntax rules are always, always preferable.)
Thanks for the link, putting it in my queue. I always enjoy Rich Hickey's talks and didn't know he had one on this topic. 
I'm struggling with lifetimes in callbacks using tokio-core + promises: fn host&lt;D: Store&lt;Query = Vec&lt;Bytes&gt;&gt;&gt;(db: Arc&lt;D&gt;) -&gt; io::Result&lt;()&gt; { let mut core = Core::new()?; let handle = core.handle(); let address = "0.0.0.0:5748".parse().unwrap(); let listener = TcpListener::bind(&amp;address, &amp;handle)?; let connections = listener.incoming(); let server = connections.for_each(move |(socket, _peer_addr)| { let (writer, reader) = socket.framed(LineCodec).split(); let results = reader.and_then(move |req| { some_db_func(Arc::get_mut(&amp;mut db).unwrap()); Ok(req) }); handle.spawn(writer.send_all(results).then(|_| Ok(()))); Ok(()) }); core.run(server) } The compiler says my `db` reference won't last long enough in the `handle.spawn` call. It suggests I make the db reference `'static` - though that sounds like a mistake. How should I be structuring this code?
What if there was a compiler flag to disable elisions? Tutorials could leverage it to give examples of what code with/without elisions looks like. 
Yes please!
I feel like `ref` should have been something like `^&amp;` (unborrow?) since it is kind of the inverse of borrowing. 
I come from C# and I am consistently annoyed that a compiler that infers tons and tons of crap refuses to infer those same things in function definitions. I don't *think* that it would have bothered me when I was first starting out, either, primarily because the compiler is very *clearly* picky about its types, so it would be difficult to imagine that `HashMap` is suddenly not generic just because I can leave off the type arguments.
The difference is we're not pattern matching in this case: x is a plain value, and &amp;x is the borrowing of the value (adding a layer of borrowing). In the pattern matching context however, when &amp;x matches a (shared borrow) value, then x itself must hold the dereference of the borrow (that's how &amp;x would match the borrow). So matching a value with &amp;x amounts to pealing one layer of borrow to land in "x" itself. Hope that makes some sense.
Offtopic: how not to love the Rust design/dev team and the Rust community? The design, research, and articles/essays are such high of quality - it really impresses me...
Lifetime elision does indeed look like a successful example to me. I think what makes it work is that it's not glossed over in the book and instead described pretty thoroughly. If such features are prominently mentioned in the tutorial, it's probably going to be good with regards to learning. Maybe even devote a page to a recap of all kinds of implicit elisions, then it would be much harder to get confused.
That does make sense thanks. I feel like the ```ref``` syntax should have been something like ```*``` instead, to match with other instances of the "opposite of borrowing". It feels weird to me to have the ```ref``` keyword only used in matches. Or can you use it elsewhere?
In other words, writing python means you have to handle the constraints of strong typing yourself, without the tools of static typing to help you.
Python still has coercion for your 'extend', 'append', 'index' operations, which is where things get tricky. It's quite hard to ensure a given dictionary or list matches some particular type schema, which makes deeply nested dicts a nightmare to work with.
could just tell me wrong area to post i stead of be an ass
The submission page already points this out already however: &gt; The Rust programming language. For the Rust video game, see /r/playrust
oh, yes! I must have overlooked it in the help!
Well you can write it anywhere there is a pattern, which includes `let` bindings and function arguments. You don't usually see `ref` there because it's not useful at the top level (e.g. `let ref x = y;` is the same as `let x = &amp;y;` but there's no advantage). For me, the key is that `ref`/`ref mut` is attached to the _binding_, not really the pattern. Once you get to the point of deciding whether to write `x` vs `ref x`, you've finished destructuring -- you found the value. The keyword only affects how the value is bound.
this was really just a honest question, i did not try to insult you in any way
Try again in /r/playrust
What do you mean? Python is about protocols, so there's no coercion going on. `extend` just accepts iterables, `append` just adds any passed object as new list element, and `index` finds an element that `__eq__`s the passed one.
Sure, but if I have an `&amp;mut Thagomizer`, I don't need to check whether its `Thorns` parameter satisfies `Eq + Copy` in order to know whether I can call `thagomize`, since `thagomize` accepts all possible instances of `&amp;mut Thagomizer`. The information simply isn't useful for the caller.
The originator of the Rust language, /u/graydon2 said in Twitter not too long ago: "As you all know * is the correct choice there. It's just that actual human brains refuse to parse it." https://twitter.com/graydon_pub/status/826915150770761729 And I agree, if you think hard about it, `*` makes totally sense. But intuitively, it doesn't.
Chapters are being released as they go, and so far are outstanding. All signs point to slow and steady progress towards the greatest work of computing literature ever written. Preorder a copy now. Preorder ten!
How would you define things like `macro_use` or the `#[cfg()]` without having the `extern crate`? Put that information in `Cargo.toml`? My own number 1 wish is having some kind of kwargs/default args, which would go a very long way to improve ergonomics. I know there was tons of discussion on the last pre-RFC about that but no progress on that apparently.
alright no need for hyperbole
Then you'd be undoing an undo... (*brain explodes*). `&amp;` is reversible constructor, while `ref` is a binding modifier, like `mut`. 
Nice - I have been meaning to do something similar for my group of C# devs.
I think the notion that every feature will end up like that is misguided. And I think it doesnt stand in fair comparison to features like the "implicit borrow" where you spare only one character but at the great cost for beginners and non beginners who read the code to not know whether that function takes a reference or by value. I'm equally opposed to other suggestions (like that implicit modules proposal). And the saddest thing of them all is, clippy won't get a lint to turn off that thing, to make your program use a simpler subset. On the contrary, it will get a lint to remind you to use that sugar thing.
I made an alternative suggestion regarding the implied bounds here: https://internals.rust-lang.org/t/lang-team-minutes-implied-bounds/4905/3 It would have the property that you would expect: in return type position the constraints cannot be obtained, but in argument position the constraints can be inferred, but requires manually unpacking those constraints.
The source is `Thagomizer&lt;Thorns&gt;`, and if you want to know what the constraint on that param is, you just have to visit the documentation for `Thagomizer`.
I believe the issue of concern is always importing the modules compiled in, even if the code in the current file should never use anything from another module.
Also a great idea. 
&gt; The results are still not published on the benchmarksgame. The author's result required modifications to the `khash` library, so I would guess it is not eligible for the benchmarks game (if the modified version is considered a [custom hash table](http://benchmarksgame.alioth.debian.org/u64q/knucleotide-description.html#knucleotide)).
I have implemented an interpreter in Rust and found it to be a great language for writing an interpreter/compiler. Pattern matching and enums (ADTs) are really nice to work with when building and walking an AST. 
Cool, I may try to mimic that. &gt; I don't always (obviously) keep up with new SQLite versions, so in the future if you want a newer bundled version please file an issue! Why would I do that when casually complaining on reddit works so well? ;-) No, I would have eventually, but it wasn't quite at the top of my list. Thanks for the upgrade!
&gt; When you link to a system library, you're only allowed to have one such link in your crate. Why is this the case? Also, could `libc 1.0.0` just depend on `libc 0.2` while people upgrade libc dependencies to `&gt; 1`, then publish `libc 1.0.1` which is the same as `libc 0.2`? Not sure if cargo can handle a nearly-cyclic dependency like that.
You're confusing weak typing and dynamic typing. Dynamic typing just means that the "types" are part of the runtime values. Weak typing means that operations will do a lot of implicit coercions. You can have one or the other or both or neither. For example, Python is dynamic, but also relatively strongly typed. If you do str + int in Python, you get an error, not random gibberish like in JS or PHP. Likewise, Python doesn't have the ==/=== nonsense.
So, take this with a grain of salt, since I tend to be resistent to change. I liked nearly all the proposals in this list, excluding the removal of the explicit external crate declarations. While the crate declarations are declared in the Cargo.toml file, I would strongly prefer the explicit crate references stay in the language itself. As someone who works in a massive codebase (not rust -- a mix of older languages), with engineers split across disjointed programs, the explicit reference to the crate saying "hey! I'm being used here!" is an etremely useful auditing tool, and much easier to catch in code review and later baseline audits. I've stumbled across issues all over the place where people, not realizing what's going on, or what's actually part of the current project, have imported code that duplicates local functions, or worse, nearly duplicates local functions, from a different part of the baseline. I guarentee that if we were to bring in rust (as I dream one day), we would not be using cargo, and we'd be subject to the issues above in however we would tie rustc to our codebase. (copied from my post on the programming thread, rather than the rust thread where it was intended to go)
I know about newlib. I'm mostly interested in the primitive C type aliases provided by libc.
Are you the author? Could you contribute the changes to the khash library? So everybody can profit from it.
Ok, Ok. I'm just trying to be funny. No disrespect for the person running alioth benchmarks or anyone else intended. Promise. :) In all seriousness, I really don't understand what are the *exact* rules. Quote from http://benchmarksgame.alioth.debian.org/u64q/knucleotide-description.html#knucleotide: Please don't implement your own custom "hash table" - it will not be accepted. The key thing seems to be the quotes. Sounds to me that custom hash tables implementations will be accepted, even for C, if they are real, proper hash tables, and not `"hash tables"` made just to make the solution fast. Just like orderedmap that made Rust the fastest. Which would mean /u/mbrubeck comment is wrong, which means he might get told that he's "spreading lies" [like many people before him](https://www.reddit.com/r/rust/comments/5urar1/is_rust_likely_the_next_fastest_language_after_c/ddwoaed/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=rust). :D . I'm doing it again... Sorry. I just find it really funny.
There is however the Option (pun intended) of using `Into&lt;Option&lt;T&gt;&gt;` arguments, which allows interfaces like `new(1, None)` / `new(1, "I am an Option" )`.
What's the history/reasoning behind this restriction?
I've never had the problem of logs for passing tests being printed, but I only initialize the logger for integration tests so maybe it works differently. The problem is that you have to initialize the logger at the start of every test. The test-logger crate just provides a macro for declaring a test function that initializes the logger at the beginning. I wrote that crate, and even I don't really recommend it. Cleaner, I think, to just call the init method as the first line of every test.
I benchmarked the performances of Mutex, RwLock and Atomic types in multi-threads on Linux. I noticed the performance of Mutex built in release-mode is drastically improved comparing to one in built in debug-mode while the performance of RwLock isn't improved so much. Does anyone know why only Mutex is so optimized? https://www.slideshare.net/mitsunorikomatsu/performance-comparison-of-mutex-rwlock-and-atomic-types-in-rust#12 https://www.slideshare.net/mitsunorikomatsu/performance-comparison-of-mutex-rwlock-and-atomic-types-in-rust#13 
I love Rust, but for the specific case of compilers I have to agree, simply because I am not sure if there is a language nicer for compilers then Haskell. It's certainly one of its strengths.
Just put everything in whichever of these files you want and source it from the other files if it wasn't sourced in the session already.
The implied bounds idea sounds very good to me and would make specifying bounds on the type instead of the methods actually useful. I would like to see this for type definitions as well, together with some form of lifetime elision as discussed in a sibling comment. There may be a lot of subtlety involved in specifying it to be keep independent compilation of functions possible. I'm personally conflicted about both the automatic borrowing ideas. I wouldn't mind the `extern crate` idea going either way because: * Pro: it's mostly redundant. It's not as frequent for me to particularly care about and external crates have to be provided by the environment anyway, so providing actual names. * Con: You can import the crate into some deeper part of the module hierarchy and do `pub extern crate` if that's what you want. I am *strongly* opposed to the idea of making `mod` optional, not only because it makes the module tree more implicit, but because it may make compiler errors less obvious (?) and encourage highly nested source tree like in Java projects (I hate those, navigating them is a pain). I don't think we should be doing things just because ‚ÄúPython and Java are doing it too!!1!!!‚Äù
[removed]
Nope. I scanned over the reverse dependencies. Tried to convert [flate2-rs](https://github.com/alexcrichton/flate2-rs). No size_t in std::os::raw
To be honest, that sort of recommendation is why, in Python, I always use the `unittest.TestCase` class, despite my preferred test runner (Nose, historically. Probably py.test for new projects) not requiring it. I'm used to having a mechanism for having `setUp` and `tearDown` methods that'll get called once for each test defined within the class and I find it ugly to have to wrap the body of each test in a `with_setup(|| ...)` equivalent (as an alternative to footgun-y manually-paired calls to `setUp()` and `tearDown()` in each test). ...well, that and the pretty-printing asserts that it provides. If it were *just* `setUp` and `tearDown`, I could write a decorator like `@with_setup` (syntax equivalent to `#[with_setup]` in Rust).
You should try /r/playrust instead.
ooops sorry, thanks :)
What about you take random people who doesn't know rust, and ask them to learn it, and during the 1st month, you talk to them and ask them some questions, what they didn't understand, what was hard to learn, what could be improved, instead of just guessing what could be wrong and improved?
I agree with implicit borrow. A perfect example today is how people get confused with closures (which borrow mutably or immutably implicitly). On the other hand, I do wish I did not have to type `ref` and `ref mut` left and right when matching patterns. *shrug*
It's important to note that in a number of cases you *will* need to actually specify the lifetime when using this struct (because there are several to choose from). I do love Niko's proposal of using `'` without any name when we don't care about it though!
And easy question (well, not for me): let reg = ::regex::Regex::new.... let reg2 = ::regex::Regex::new.... get_many_titles() .map(|title| reg.replace_all(title, "")) .map(|title| reg2.replace_all(title, "")) .map(|title| title.to_string()) .collect() I'd like the following to work but when I add the second map with `reg2` it refuses to compile. It seems that `replace_all` returns a `std::borrow::Cow` (which is surprising, why replacing a string do not bring me back a string?) which I've tried to work with but I always get a `temporary value dropped here while still borrowed` somewhere (depending on where I try to hack this to work). How can this be solved?
&gt; I think the notion that every feature will end up like that is misguided. I do not think that every feature will end up like that. Only that we have some experience with this happening.
Huh. [PR made](https://github.com/alexcrichton/flate2-rs/pull/63)
&gt; Basically, adding a magical happy path doesn't always make something easier to understand. The union of a complex system and a simple system is a more complex system. Wholeheartedly agree.
In a strict sense, that's true. Figuring out what issues 1.0 needs and making the changes to ship it is globally better, IMHO.
libc 1.0.0 can not depend on libc 0.2 Gonna answer the other bit over here: https://www.reddit.com/r/rust/comments/5xb0d5/rust_roadmap_libc_v10_release/degx3mv/?st=izvdeuwj&amp;sh=92e46ff9
Or just `HashMap&lt;&gt;`, you're already eliding the `HashBuilder` parameter anyway so let's go all the way.
He makes the call and there is some arbitrariness to it. It's how it is, life is open ended and we all choose if we want to participate in that game or not.
Python isn't even the worst offender here. At least it's consistent. (Though, I wish 'pass' was mandatory as a block terminator). I dislike languages where semicolon is sometimes needed and sometimes not (Javascript -- jslint to the rescue, ... not sure about Scala). ASI is not a good thing. Either make the grammar work without semicolons, or require/use them consistently.
Yeah, all the options for this have a fair amount of boilerplate. Which is why optional/named args being a part of the language is nice, since their job is to *reduce* boilerplate. I find this one to be a reasonable compromise for my purposes though.
In semver 0.x.y versions are intended for initial development, but that is not what 0.x.y means. What 0.x.y means is that "_any_ new version might break the API". Nothing more, nothing less. You now have to put semver in the context of cargo and crates.io, where you can say "my crate relies on version `1.2.*` of this other crate". Semver allows you to replace that by `1.*` because `1.*` versions have no API breaking changes. So how are people able to rely on `0.x.y` in production? That's easy, you just rely on concrete values of x and y. That is, my crate needs `0.2.0` of libc to work, and nothing else. That version of libc is available _forever_ so if you don't change platforms, your crate works there forever. According to semver, a `0.2.1` release might completely break the API, so you cannot change that to `0.2.*`. Going from `0.x.y` to `1.x.y` or higher brings two main things to the table semver wise. First, it gives authors the ability to update a crate with new features and bugfixes without breaking their users. Second, it introduces flexibility while resolving dependency chains. For example, you can find a common version of a crate for two libraries requiring different features set (one requires 1.1, the other 1.2, your crate that uses both requires 1.3, all of them can be combined into one using 1.3). Now we put this in the context of libc, where new features do not make sense, and where 0.2.0 is close to bug free, and since no new features are added, it just stays like that. So... yeah, one can do a symbolic 1.0.0 release, to "convey" that the crate is stable, but beyond that, doings so doesn't really add that much value, and it will introduce lots of headaches about who is able to update, since there will be a transition period where some libraries will have switched to 1.0.0, but others will remain on 0.2.0. That's basically what people are complaining about. The crate has some design issues but it mostly just works as is. Its a pain to upgrade it _to any API breaking version_ because so many people rely on it. This will always be true for libc, independently of upgrading from 0.x.y to 1.0.0, or from 1.x.y to 2.0.0. What people are rightfully arguing is, that this headaches should not be all "for nothing", but rather, they should add value. Fixing the design issues with `c_void` would make breaking the world for a while worth it, but "liking the number 1.0.0 more than 0.2.0" is not a reason enough. 
IDE's, in my mind, would also show the type of an implicitly typed variable. I agree there is such a thing as too much implicitness. There has to be a good compromise done here, and this initiative is all about finding and implementing that compromise. As such, IDEs would be a teaching tool, to reveal some of the implications of the code (lifetime of variables, implied types and constraints) that already exist today, but aren't present in the code.
Have you tried cargo edit? I think it can do this already.
I think a good compromise might be "only add weird compiler flags to *my* crate, and compile foreign source normally" And/or permit crates to specify compiler flags in their Cargo.toml
You already get this in Rust, no? Conditional conformance means an explicit `T: A` bound might not be met because `T = Vec&lt;Foo&lt;U&gt;&gt;&gt;`, and `Vec&lt;Foo&lt;U&gt;&gt;: A where Foo&lt;U&gt;: A`, and `Foo&lt;U&gt;: A where U: A`, and finally the compiler finds that `U: !A`. Real world example: https://github.com/rust-lang/rust/issues/21793#issuecomment-139882441
I know I've recently become interested in type inference and found this a while back too. It's some really cool work, though I'd go ahead and guess that adapting something like this to the rust compiler would be a huge amount of work, and I'm not sure how well it would deal with things like associated types.
This is for the programming language. 
Really cool work
An example of code that hasn't been working for me, or an example of what sort of thing I'm looking for?
is there a rust language server package for Atom editor? I looked but I can't find anything.
The former.
Waiting on an example to help you diagnose your issue, but I want to make sure you've read the actual documentation for `std::process::Command`? There's example code there that should be enough to get you started. 
In that proposal, I don't like `'` having different meaning between generics and uses, and I am not sure saving the one character on `'` vs. `'a` is important enough to get special syntax. OTOH, "output-parameter" style lifetime elision for structs, especially if someone would come up with a nice enough syntax for a method-style "elision 'self" (not to be confused with "existential 'self"). If you could do: struct Foo&lt;'_ /* magic '_ */, 'tcx&gt; { tcx: TyCtxt&lt;'_, 'tcx, 'tcx&gt;, // '_ inferred to 'self? foo: &amp;Foo, bar: &amp;Bar&lt;'tcx&gt;, it: Iter&lt;Ty&lt;'tcx&gt;&gt;, }
Done! In the above comment
That doesn't segfault for me (on macOS). Perhaps something is wrong with your Rust installation?
Just start writing something. I've wrapped a C library, and written a FDTD wave simulation.
Ah, guess I've been lucky until now... or I am just so used to it from C++ that it didn't even register.
Oh cool. I'll do some reading.
I think this could work for *binaries*. Those are final artifacts, anyway. For libraries, I'd be afraid of them getting released as is on crates.io.