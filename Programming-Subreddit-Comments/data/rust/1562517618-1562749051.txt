The DPI settings are whatever you want them to be - they simply indicate how screen pixels relate to real world distances. A DPI-aware application that is targeting a 1080p screen can use 1920x1080 "virtual pixels" in its layout, and when you run it on a 4K screen, GTK will automatically translate your "virtual pixels" to 2 real pixels instead of 1 at 1080p.
&gt;If cryptographic, are there any additional properties that must hold? Yes. I want do implement an (EC)DSA. I need the two primes (p, q) of length (N, L) where p-1 is a multiple of q. that I need to multiply: // prime (q, p) of lentgh (N, L) const LOW: (u16, u16) = (1024, 160); // (N, L) const MODERATE: (u16, u16) = (2048, 224); const STRONG: (u16, u16) = (2048, 256); const VERY_STRONG: (u16, u16) = (3072, 256); then I need a *g.* Not sure yet, what that is :)
 none
Seconded. The /r/ProgrammingLanguages folks are also super nice as well. There's significant overlap with /r/Compilers, which is a super helpful group with some very knowledgeable people.
Macs should work directly with Bonjour. Windows may be trickier but Bonjour could be used on it too.
A year is probably too optimistic—unless you are working on it full time. But writing a compiler is a little like writing a book. Your questions are analogous to, "How long does it take to write a story? What if the story is a mystery, but it has a romantic subplot?" The answer is, well, it depends on the sophistication, the quality, the author, and on and on. Most toy compilers gloss over any meaningful semantic analysis. It might take a bit of time to get up to speed on the theory and implementation of the type systems required to implement Rust. On the other hand, you could also just copy an algorithm out of a book or paper without needing to understand it... there are just too many variables to give you a solid estimate of the effort involved. But I don't think you should worry about it. Just do it and have fun.
For learning and fun only I hope? Expect you've already heard "don't roll your own crypto" enough times already. Why ECDSA? Why not use an established curve that meets all the safety tests and has been reviewed? -- If I may recommend differently, use the Ristretto255 group from https://dalek.rs / https://ristretto.group which implements a prime order group using a thin extension on top of curve25519. If you need signatures, Schnorr is good - as is what EdDSA uses (ed25519, ed448) - also https://docs.rs/schnorrkel may be of interest. EDDSA is a more expensive hack to get around the patent on Schnorr which has expired.
An interesting approach might be to *start* with rustc and reimplement it component by component. ("My father replaced the head, and I replaced the handle, but it's grandfather's ax.")
On a scale of implementation complexity of a statically typed language I would put something like Go running on the JVM/CLR on the least complex end, probably doable in a man month (very simple type system, reuse existing GC and standard library), and something like Rust on the most complex end, requiring many man years of work (complex type system with borrow checker/lifetimes etc., native compilation (using LLVM helps though), standard library written from scratch). So, you haven't chosen an easy task, but good luck! :-)
&gt; Lexing and parsing is essencially a nonproblem, existing tools automate this part into non-entity. It's also one of the funnest parts to implement. And we can always justify doing it "by hand," because there *are* good technical reasons to do so. (So what if those reasons don't matter in our case!)
The only practical option is something browser based.
Also there are still 7 files in the repo that are are exact copies of files found in askama master. &amp;#x200B; The whole thing, including creating a new repo etc, just seems rather odd. Why not just add a "This was originally a fork of xxx" notice .
Heh. Missed your last line somehow. `g` is the generator. The basepoint, which when raised to the power of all exponents will generate the set of all points on the curve (or a large portion of them if not all). If you use a bad generator, then `g^a mod p` (or whatever the curve specific formula is) may yield a small group. A small group can reduce your 256 bits to something significantly smaller and enable many attacks.
So, `xterm -fs 14` can set font size. Making a TUI might be the easiest approach.
This is repetitive code: fn get_hostname() -&gt; String{ match fs::read_to_string("/proc/sys/kernel/hostname") { Ok(hostname) =&gt; String::from(hostname.trim_end()), _ =&gt; String::from("null") } } fn get_kernelv() -&gt; String{ match fs::read_to_string("/proc/sys/kernel/osrelease") { Ok(kern_v) =&gt; String::from(kern_v.trim_end()), _ =&gt; String::from("null") } } I would use an enum as argument in a single *fn get(prop: Property)..* and match the prop then, use the the lib *strum* to use the Property Variant (ie: Property::OsRelease) as a lowercase string ("osrelease"), to be used as the path.
You can install Bonjour on Windows, but I do not want to install any software on the client laptops.
Seriously surprised that this wasn't posted go give this repo some love y'all.
That makes sense. But isn't Rust pretty good for writing a language with gc? I remember reading that implementing a language with gc with another one with gc isn't a good idea because it becomes too hard to debug issues.
What you are describing sounds similar to the idea behind [wheel factorization](https://en.wikipedia.org/wiki/Wheel_factorization). Though one thing you have to watch out for with your method is because you pick only one coprime value instead of all of them, you have the issue that the larger \`A\` is the fewer bits of entropy can fit in \`k\`. Consequently you really don't want to multiply together more than the first handful of primes. The product grows so fast that a couple dozen would be enough to take basically all the output bits so an attacker could just enumerate all possible values of k when trying to find your random prime.
So, it was the model loading from tobj... even though the vertices are already indexed, you need to load the vertex array using the indices. &amp;#x200B; Now, why is it upside down in wgpu but right side up on glium?
It depends on what your interests are; if you use Rust to implement a language with a GC then you'll need to implement that GC somehow. If instead you rely on the host's GC you can skip that work which seems smart if you e.g. want to research some type theory. But if GC performance and such is important to you and you want to build something industrial grade then using Rust is probably better. For example, GHC implements its runtime in C.
I don't get it, they asked a question, you answered it well and politely... :S
You can get a prototype going by yourself if you have the drive and lot of time. The vast amount of work poured into Rust and the number of people required is there because it takes all that to get from a prototype to: * a much, much better design than the starting design * optimizations in the compiler, tools, and compiler output * implementing the standard library * optimizing the standard library * designing and implementing community processes for responding to bug reports and suggestions * reading bug reports and suggestions * fixing bugs and implementing suggestions * reading up on what other languages and projects are doing (for example, we now have hashbrown as the default to speed up HashMaps) If you want to, use the tools that are out there to gain the benefits of lots of people's work. For example, if you use LLVM, you get some compiler optimizations for free as well as support for various kinds of CPUs and OSes.
Thank you for the explanation! :)
You forgot the bang after the hash for the feature. `#![feature(specialization)]`
Thank a lot! Lots of great advice. Completely forgot about enums. I see how your code structure makes more sense and I think I'm gonna steal it :) Thanks for your time again.
This is the direct continuation of my hello world in rust from 2017. I was looking at mutt's source code back then so when I started reading the rust book I was already in a mail mode. All in all Rust has been incredibly easy to work with in this, and I've had zero problems or obstacles other than the gdb support I mention in the article. I spent a week some time ago trying to expose my structs' Debug printing to gdb by passing a pointer to an object to an ffi lib in rust using gdb's python API and returning a CString, but I blocked on reading the inferior's memory properly.
Reducing a test space that won't be done for longer than the age of the universe by a third is still way too long.
I'm pretty sure [ramhorns](https://github.com/maciejhirsz/ramhorns) is the fastest, although the GNU GPL licensing makes it incompatible with any project that isn't also GPL.
you are welcome. Instead of get\_hostname get\_osrelease I tried this and it works. I actually thought it wouldn't but it does: fn get(prop: SystemProperty) -&gt; String { let mut path = String::from("/proc/sys/kernel/"); path.push_str( match prop { SystemProperty::Hostname =&gt; "hostname", SystemProperty::OsRelease =&gt; "osrelease", _ =&gt; "null" } ); path }
My scheme still generates all the possible primes: all integers can be written uniquely as `Ak + C (where C &lt; A)` for a constant A. From there, I am only eliminating integers where A and C are not coprime: if they are not coprime, then by definition, `Ak + C` is not prime, and so I am only eliminating non-primes, and so there should be nothing exploitable in my choice of prime.
As I understand it, the original repository root (the first commit) has been reset more than once since the project originally surfaced, obscuring the provenance of the code. It used to be *very* similar to Askama.
The intent was that you would pick an N and generate a list of all possible values of C for that N ahead of time, and then pick one at random each time you need to generate a random prime. It's trading space for time.
Woah, that’s impressive!
Flutter, but that isn't dart. Would be cool if we could use Flutter in the front end and write pub packages in Rust... I'll keep dreaming.
&gt;Reducing a test space that won't be done for longer than the age of the universe by a third is still way too long. Large primes are actually surprisingly common. Of the numbers below 2^(256), about 1 in 177 are prime. (In general, the probability that a random number between 0 and *n* is prime is around 1 / ln *n*.) So if you only need a single prime, this algorithm is likely to complete quite quickly.
Could your triangles be culled for back faces? Try capturing with Renderdoc, it will show you all the geometry and states.
As I understand it (also not a lawyer) the Apache and MIT licenses require attribution. The way I usually see this done is to mention an original author in the license or near where the license is declared. Additionally, since this would hardly cost the author anything, I really don't see the downside of them coming in compliance through this request. However, since they've turned down chances to do so at several points now, I can't believe they're acting in good faith. Apparently they're [getting in trouble with the law](https://www.reddit.com/r/rust/comments/c7sj2x/yarte_continues_to_be_maintained_after_the/) for other reasons, too.
Nice! Please, You can update these [benchmarks](https://gitlab.com/botika/template-benchmarks-rs) with [ramhorns](https://github.com/maciejhirsz/ramhorns) .
That's nice, but for testing a prime for primality, you can't stop partway like you can with composite numbers, you have to test all the way up to the square root of the prime. Reducing that by a sixth, you still have about 2^125 divisions to accomplish to prove the primality of a prime. That actually takes a long time, regardless of how common primes are.
figured that your conv may not check division by 0 . It crashes the program. so you should check if the divisor is not 0 before the division.
There is this crate: [https://github.com/gliheng/flutter-rs](https://github.com/gliheng/flutter-rs)
Very cool! Looking forward to seeing this project *blossom*. ;)
Yeah I don't really like that solution. Would rather have official support from the Flutter/Dart team directly.
Great to see an update on the project!
You will need to do something about how you store your image to make multiple mutation free of data races. This could involve using atomics, locking, tiling etc. As long as you cannot prove your image buffer is free of data races, your code will be unsound when mutated by multiple threads.
So, sharing data across threads like this is incredibly tricky. You have several options, - Use a Mutex/RwLock. What happens here is is that while one thread is changing the image data, no other threads can access it. This prevents weird data races/image corruption, but it also means only 1 thread can work on this image at one time, thus kind of 'negating' the benefits of multithreading - Divide the image. This is the 'simplest' solution but can also be hard to actually implement with rust's borrowing rules. With dividing, say you have 8 threads, you divide the image into 8 neat 'references', ensuring the references don't overlap, and then you give one to each thread doing processing.
Yup, thanks for the catch!
&gt;For testing a prime for primality, you can't stop partway like you can with composite numbers, you have to test all possible divisors up to the square root of the prime, True, but /u/hukumk proposed to use the Miller–Rabin primality test instead of trial division. This test will generally be much quicker for large numbers, since it runs in log time instead of polynomial time. My proposed search space optimization was to limit which numbers to plug into Miller-Rabin, not which divisors to check.
Well I was thinking about letting each thread process every n-th pixel, so with 8 cores, each core would process every 8th pixel. Then they wouldn't need write access to all other pixels, but they would need read access, because each pixel's processing depends on it's neighbors.
Can you just generate a new image, so sharing multiple non-mutable slices of the original data, and getting a new image at the end? That leaves you open to more concurrency options, even distributing load across machines!
what?
Would you like me to clarify something? I'm talking about generating a new pixel buffer, assembled from tiles that have been worked on independently, without multiple threads sharing mutable date
your LICENSE is probably wrong, Google Inc. angularjs?
ahhh... So split the original image into a few pieces, then give each thread write access to their piece, and read access to the whole original image. Yeah I think that would work! Do you have any ideas how could I do the splitting and merging back with the [image crate](https://docs.rs/image/0.21.0/image/)?
Not really, only while capturing
Added filtering, check it out!
I see - my bad.
&gt;I know my gpu isnt great but is this solely the reason why fps is a struggle for me on this game? Yes it is way to weak. Also: Please post more infos if you need help: Whats your current fps? Resolution? Settings? And last but not least: This is the wrong subreddit. Please read before posting and don't just blindly post something like you did here.
But if a thread reads an adjacent pixel, the result of this operation would change depending on whether that pixel was already calculated or not. You absolutely need a source and a destination image for this. Also, this sounds a lot like it could be done on the GPU, which would be much faster. The GPU API (OpenGL, Vulkan or whatever) already solves all of those problems for you.
Try with --release
Can you explain more what you mean by translate? What's an example input path and the output you're trying to get?
Great job so far!
I have never done any GPU programming, and I'm really scared after looking at examples... Is there any introductory, how it all works, how it's different from CPU programming?
How do you find ECS structure work for UI? Was thinking about building my UI lib for my game in ecs style or something like it (separate from game code though).
I forked the repo and push the changes to my repository. &amp;#x200B; If you like you can take a look at [https://github.com/aspera-non-spernit/rustop](https://github.com/aspera-non-spernit/rustop)
Ooh I'll have to take a look - I'm also working on a terminal MUA but I haven't got around to making it public...
Microsoft and Apple being what they are, there is no single protocol to enable service discovery for both. (Standards are great. Everybody should invent one). However, you might get away with simply announcing your service (Web UI) on both mDNS (for OSX) and UPnP/SSDP (for Windows) to cover both.
Just a couple weeks ago another terminal-based client called aerc launched. It's still pretty unstable but I love how uncomplicated it is to setup and everything's based on Vim bindings by default. Nice to see new stuff in that area, I could never get used to mutt.
I've found it's not a bottleneck, and I haven't even done optimisations for message passing; for example events get passed to all components recursively, whereas with specialization or ID addressing in events they could pass immediately. Of course the tree depth doesn't reach a length more than 8-10 for now and usually the recursion doesn't do backtracks. Wrt game dev, it's going to be more performance intensive so your standards may well be different that a terminal app.
Yup, fixed it.
You don't need most of it for this kind of code. Just draw two triangles as a rectangle between -1 and +1 in X and Y and do the rest in the fragment shader. I'm afraid that I don't know any tutorial for this specific kind of thing, since I've been doing this for about a decade now. Back then I used [this tutorial](http://nehe.gamedev.net/tutorial/lessons_01__05/22004/), but I don't know how well it has kept up with the times. Also, it's more general than you need. However, it's not a general introduction, but [here](https://software.intel.com/en-us/blogs/2014/07/15/an-investigation-of-fast-real-time-gpu-based-image-blur-algorithms) is a nice example on how to do something very similar to what you need using OpenGL.
A lot of people don't know about split\_at\_mut in [https://doc.rust-lang.org/std/primitive.slice.html#method.split\_at\_mut](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) .
It was a copy error, fixed in the post.
I made something vaguely similar to this called [print perf](https://crates.io/crates/print_perf) that you can have a look at. The macro doesn’t do all the things you want to but I guess it’s not too hard to expand on the few lines of code to take the method name and arguments and print that out as well.
Then just use the same hardware to run both? AFAIK, pihole isn't very resource intensive.
If you can get access to your image as an array of pixels then just use rayon's par_iter() to parallelize the computation
Blimey I envy those people for whom the file browser is the slowest part of their workflow.
You need to switch to a tiling window manager friend it is a game changer.
For .env-files this hardly matters, but generally worth remembering; the upper limit on optimal buffer sizes can often be way less than available memory. For data from disk, effects from CPU-cache is usually neglible (this can be relevant in other buffer management), but you can still suffer from missed opportunity of read-ahead and parallelism. In short, while reading a file of some megabytes from disk, reading "the right" amount of data at a time will allow you to process it while the next buffer is read from disk to read-ahead buffer. Reading the entire file will have you first blocked by I/O, and THEN blocked on parsing. My experiments from a few years back puts 32-64k being a good size for buffered reads from spinning disks. After that, gains of bigger buffers are small, and reading blocks bigger than 512k brought performance way down. Might have to be re-tested with SSD and newer spinning disks. Remember to test on both hot and cold disk caches.
Usually, the BufRead or mmap is the way to go. For the .env, my guess is the small amount of data will mean the overhead of setting up the mmap will eat any possible gains of the reduced cache copies. I would go for BufRead here for it's simplicity.
Very nice! I love a good TUI.
I'm a SWE at Standard Cognition ([https://standard.ai](https://standard.ai)) We're a YC-backed startup changing how retail stores works, and we use a \_lot\_ of Rust. &amp;#x200B; If you're interested in visiting the office and/or grabbing coffee, let me know. My email is [bernardo@standard.ai](mailto:bernardo@standard.ai) &amp;#x200B; Cheers!
I'd prefer to have each of the Pis running identical software, so I can image the SD card and easily create new playback decks. I don't think you want to end up with multiple NAS servers.
Wait how come you think he isn't using a tiling WM?
Cause he would have ran into this or ranger otherwise.
I read his comment as meaning "I'm surprised people would want a highly optimised file browser" (i.e. one rewritten in Rust with a focus on speed). How did you interpret it?
Sorry I don't have a whole lot of love, mostly deep concerns. I'm working on a PR to address some of them. Originally I was just going to complain about how this project compiles with an old nightly and bumping to the latest nightly produces this warning: warning: use of deprecated item 'std::os::unix::process::CommandExt::before_exec': should be unsafe, use `pre_exec` instead --&gt; src/proclist.rs:275:14 | 275 | .before_exec(|| unsafe { libc::dup2(1, 2); Ok(()) }) | ^^^^^^^^^^^ Then I noticed the little unsafe block and grepped for `unsafe` and found this: unsafe impl Sync for FsCache {} Seriously???? There isn't even a comment as to why this is safe. `FsCache` directly owns a `std::sync::mpsc::Sender` which sends a type that directly owns a `Mutex`. The stdlib has this to say: // The send port can be sent from place to place, so long as it // is not used to send non-sendable things. #[stable(feature = "rust1", since = "1.0.0")] unsafe impl&lt;T: Send&gt; Send for Sender&lt;T&gt; { } #[stable(feature = "rust1", since = "1.0.0")] impl&lt;T&gt; !Sync for Sender&lt;T&gt; { }
Not like you I guess.
Absolutely wonderful welcome to the project. I am actively working on cleaning up documentation and making things more clear. I am not the developer though.
Maybe something interesting for you. I have refactored the Uptime part. &amp;#x200B; 1. I created a *struct Uptime { first: f64, second: f64 }* // where second isn't really used as before 2. I implemented the trait *From&lt;String&gt; for Uptime* and moved the string parsing into the *fn from(string: String)* // you can create an Uptime::from("12344.44 3234.33".to\_string()) or from what you get from the */proc/uptime* 3. I implemented the trait *Into&lt;String&gt;* with the *fn into(self) -&gt; String* // it utilizes your conv\_t(f64) function and returns the uptime in hours, minutes, seconds as string [https://github.com/aspera-non-spernit/rustop/blob/eac762d65c643548301a848151698bd175ea5df3/src/lib.rs#L107](https://github.com/aspera-non-spernit/rustop/blob/eac762d65c643548301a848151698bd175ea5df3/src/lib.rs#L107) If you learn how to implement Traits you are going to ace very quickly.
The design of this site just speaks to me
LLVM helps with the native compiling.
By posting on r/playrust
Straight /r/playrust content
Askama is dual licensed under MIT/Apache. From the MIT license: &gt; The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. From the Apache license: &gt; (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and &gt; (b) You must cause any modified files to carry prominent notices stating that You changed the files; and The short version is that any portion of the software that is directly copied from, or derived from Askama needs to retain the original license file, including the copyright notice, with the name of the copyright owner. Stating what is/isn't a derivative work would be too close to legal advice for my taste.
&gt; Naively, I would think that the repository is now complying with the request, since it explicitly mentions Askama among its source of inspiration. &gt; &gt; What I do not know is whether doing so is sufficient, or if further effort is needed. The key context that you're missing is that only the copyright owner can enforce that copyright. What's been done is not what is legally required to comply with the license of Askama. That doesn't matter if the copyright owner is happy. They're the only ones who can say whether or not that is the case.
How much of the repo is an exact copy isn't even relevant anymore, you can prove that the author has seen the code of Askama before any changes from that codebase were made, which gives you a strong argument that this is a derivative work no matter how much it changes from the original code. This is similar to the issues with copyleft licensed code being contributed back to permissive licensed projects. The code can't be included, and the act of opening the PR in the first place means the authors can't reasonably implement their own solution without violating the copyright of the copyleft project.
&gt; 127 dependencies is... A lot. I'm not so sure that's true when you factor in tokio, which I believe is where the majority of those deps come from. tokio is a pretty beefy dependency, anything that pulls it in is going to have a higher than average dep count (partially because the tokio ecosystem seems to lean more towards breaking things into much smaller libraries). But it's getting harder to avoid these days, especially since libraries that are still doing sync IO get a lot of complaints about it (in my experience)
I use a tiling WM and I've never heard of ranger.
Yes, I'm aware. I still think it's a lot. Especially when I don't care whether I'm using async I/O or not. Regardless, the dependency count is high enough for me to balk and look elsewhere when I get a chance. And yes, I am part of this as well. I've been trying hard to stop the increase in dependencies in even my own crates, but it's super difficult to avoid. I've found it effectively impossible to resist the urge to break things down into more and more crates. I think this is a serious problem, for a variety of reasons, and it might be a while before we really appreciate the consequences of regularly incurring hundreds of dependencies. I don't have any good ideas on how to fix it, other than to continue to remain vigilant and encourage others to do the same.
I believe that the blender export file needs to be flipped. I exported another object and it was upside down also :) So it all may be good. I didn't think there was anything with wgpu itself causing the issue, just how I was configuring it since it obviously works on other things. I was a bit perplexed about the indices though. I'll put out wireframe once I fix the loader for multiple models. Thanks!
My standards for terminal apps have become very high since rg and friends. Way higher than what I expect for games... but that shows more my non-gaming side than my cli usage side, I guess.
Faster compilation, smaller libcore binary, much better docs - an all-around improvement.
Hey, just started working with actix web. This is definitely not spam, and very helpful for me. Thanks for sharing
Very interesting! For me personally the mention of both IMAP and notmuch especially pique my interest. I absolutely love notmuch but in the end I had to give it up as whichever system I used for syncing maildir to IMAP ended up leading to synchronisation issues. I have to have IMAP for mobile. An actual IMAP client that could include the search and tagging capabilities of notmuch would be tremendous. Aside from that I like the design in general too.
Because web\_sys uses with f32.
Can you explain more what you're trying to do? Maybe something like the [[bin]] sections in Cargo.toml would help with your use case: https://doc.rust-lang.org/cargo/reference/manifest.html#target-auto-discovery I have some projects where there is a library binary. To run the binary I do: cargo run --bin my_bin --release
Tuple docs next??
This doesn't sound like an ECS to me&amp;mdash;it seems like you've designed a widget-based UI, called widgets `Component`s, and called your state store (`Context`) a system. You conceptually merged entities with components because component instances have unique ids. I don't have a problem with the design decisions here&amp;mdash;they make total sense for building a UI&amp;mdash;but this isn't ECS. ECS means that: - There is a set of unique ids&amp;mdash;these are your entities (in your case, widget instances). They are *just* ids&amp;mdash;no behavior, no data. - Components are pieces of data that are attached (many-to-one) to entities. Components have no associated behavior. - Systems describe the behavior for entities that have some required set of components.
I [added safe bindings for some of the libusb async API](https://github.com/dcuddeback/libusb-rs/compare/master...kevinmehall:async2) to libusb-rs awhile back. Never got it merged because the API I implemented isn't great and libusb-rs isn't really maintained. It might worth revisiting now that the Rust async API is starting to stabilize. However, libusb is showing its age and I think it would be a great project to build an async-first cross-platform USB abstraction layer in Rust. Libusb's callback-based event loop isn't a good fit for Rust's async model, and largely duplicates what Tokio can do better. On Linux, it would quite possibly be easier to make Tokio interoperate with `usbfs` directly than with libusb, and someone has [begun implementing that](https://github.com/usb-rs/usbfs-device). Windows WinUSB could be supported through Tokio's support for IOCP. macOS IOKit would be a little trickier, probably requiring a futures executor to be built on top of CFRunLoop. Anyway, if you're just trying to get something done right now, check out my `libusb-rs` fork linked above, but otherwise writing unsafe code against `libusb-sys` is probably your best option.
thank you. i meant however the default behaviour of cargo. it should create a bin folder instead of an examples folder. cargo build &gt; should take a file from bin/project_name.rs no need to state a [[bin]] folder in the Cargo.toml. If have have multiple executables like client.rs server.rs for a project "web" then cargo build client or cargo bulld server should be sufficient. Anything else should be optional like cargo --example example_with_extras with an [[examples]] section in the Cargo.toml. that's what I think would be better.
I've been using actix 1.0 on a side project to evaluate its potential in using it in larger applications and so far it's been pretty decent. The thing I've struggled with so far has been writing tests around it with a diesel backed Postgres DB, and a lot of the documentation and guides that tend to turn up in search results being super out of date.
Someone posted this presentation a few days ago, which I thought was excellent. https://www.youtube.com/watch?v=k7nAtrwPhR8&amp;feature=youtu.be
If you look at the OpenSSL or PGP code, you can see how they generate prime numbers. I've looked at it before, and the algorithm roughly goes like this: 1. Generate a X-bit number, by filling in the first bit as a 1, and the rest of the bits with random 1's and 0's. 2. Test for primality with Miller-Rabin. 3. If it fails, increment the number, go to #2. Of course you can make this a little faster by making sure the original number is odd, and incrementing by 2.
That would require variadic generics since tuples are heterogeneous.
My own experience with wrapping USB in Rust was frustrating, but you're welcome to offer ideas. I quickly gave up on wrapping libUSB; there are so many ways for things to subtly break using it (for example, there is physically no way of making Linux USB thread safe; if multiple threads listen on the same device, you have a race condition). Since I was testing on Linux, I have to resort to binding `libudev`, except the `libudev` crate is unmaintained and I actually needed the `udev` crate. Except that anything that depends on `libudev` (the C library) is not thread safe because a `libudev` context is (to use Rust terminology) `!Send` and that leaks into your API. (If you wonder why you can't sidestep `libudev` like you could for `libusb`, the answer is that trying to use the netlink kernel API that udev uses results in your code having a race condition between it and udev, which is bad.) So now I have a `libudev` listener that monitors for devices and reports it on a future. Now I need to bind the Linux kernel USB interface, which has outdated documentation. Whenever you try to do something with USB, there's the potential of it failing for some obscure reason because USB hates you, and the kernel interface (which has such enjoyable features as the USBDEVFS_IOCTL ioctl, so you can fit extra system calls inside the "extra system calls" system call) requires you to do things like manually clear endpoint stalls, and handle running out of memory. The next least painful operating system to port to is Mac OS X, though this is a very relative term. Mac OS X maintains its own event loop (`CFRunLoop`) that you have to massage into whatever Tokio or whatever your backend of choice wants. It also has multiple USB APIs that you _must_ support, because if you run your program as a daemon you can race the HID kernel driver for a device, and depending on whether you win the race you have to control the device directly or through the kernel driver. And then there's Windows. The reason that most USB host stacks get abandoned is because USB is very difficult to get right.
Yikes
`${PROJECT}/examples/` and `${PROJECT}/src/bin/` are two different folders with different purposes. While by default, the library entrypoint has to be `${PROJECT}/src/lib.rs`, you could have everything else be in modules so no other files live at the top level and the executables you want to install all live in the `${PROJECT}/src/bin/` hierarchy and can either start at `${PROJECT}/src/bin/${BIN}.rs` or `${PROJECT}/src/bin/${BIN}/main.rs`, so your binaries can be separated from each other. `examples` is entirely for providing examples to library users, not to place binaries to be installed.
I don’t wish to use web render technology as it’s not a proper way for native software GUI. But you mentioned I should build lots of custom widgets, which framework allow me to create custom widgets with very high flexibility ( I mean less limitation )
It might be easier to work with the underlying buffer of pixels here. It looks like you can construct an ImageBuffer from a Vec&lt;Pixel&gt; with [ImageBuffer::from_vec][0], and vice versa with [buffer.into_vec()][1]. From there, [rayon][2] has a [par_chunks_mut][3] method that might work for you. In my path tracer, I use that to distribute write access to each row across threads. If you need to maintain read access to the original, though, you'll probably have to clone the original image and write into a copy. [0]: https://docs.rs/image/0.21.2/image/struct.ImageBuffer.html#method.from_vec [1]: https://docs.rs/image/0.21.2/image/struct.ImageBuffer.html#method.into_vec [2]: https://github.com/rayon-rs/rayon [3]: https://docs.rs/rayon/1.1.0/rayon/slice/trait.ParallelSliceMut.html#method.par_chunks_mut
yeah!! variadic generics!!
Note that you can't `#[derive(Display)]`. Additionally, this allocates multiple times, so I would either use this for less repeated code: #[derive(Debug)] enum SystemProperty { Hostname, OsRelease } fn get(prop: SystemProperty) -&gt; String { let file = match prop { SystemProperty::Hostname =&gt; "hostname", SystemProperty::OsRelease =&gt; "osrelease", }; format!("/proc/sys/kernel/{}", file) } or for better performance: #[derive(Debug)] enum SystemProperty { Hostname, OsRelease } fn get(prop: SystemProperty) -&gt; &amp;'static str { match prop { SystemProperty::Hostname =&gt; "/proc/sys/kernel/hostname", SystemProperty::OsRelease =&gt; "/proc/sys/kernel/osrelease", } }
Imagine that literally everything you could ever possibly think of explicitly required heap allocation.
&gt;macOS IOKit would be a little trickier, probably requiring a futures executor to be built on top of CFRunLoop. I'm guessing an off the shelf executor would be fine; the platform-specific part is usually the reactor, which is responsible for translating external events into futures wakeups.
Well there we have it, the justification for variadic generics - improve docs.
Awesome! I gave mutt a try, but it is not very user friendly. I tend to prefer the shell for at least as many activities as a GUI, so I'd consider myself pretty comfortable in the shell, but mutt and alpine both feel very much like they haven't been improved very much in decades. I'll be keeping an eye on this. Speaking of which, you mention you have a Mastodon, but don't give a link or a user name in your blog post. I found you eventually, but a link or a user name might help others.
\&gt; **Rust like** Is the keyword here? right? So, is almost like 90% rust? Without any feature that depart so much from what rust have/is? &amp;#x200B; Then you can get it MUCH easier with a transpiler. Say, for example, you wanna rust but with more fun. So, you replace "fn" with "fun". &amp;#x200B; This is incredible easy to do.---- &amp;#x200B; \----- &gt;100,000 from many programmers over many years &amp;#x200B; A lof of that is because "nobody" know what will be the final form of rust... until many many tries and experiments. If you see rust of early day you will not recognize big parts of it. &amp;#x200B; Now, with rust more "settled" you can skip so many intermediate steps because are DONE. This another big plus. &amp;#x200B; \---- I'm [building one](http://tablam.org), and certainly I'm not the most suited for this. But also I have a bet that the relational model could make MY life easier if I turn that into a lang. I accept not amazing performance and many other stuff if only can build a lua-alike nice data language. Bet that rust give me a good foundation if that bet works and later get more ambitious. &amp;#x200B; So, is one o 2 things that you truly dream? Focus on that instead and left the other stuff aside for a while. For example, I barely pay attention to parser because I need to nail the internal stuff as DSLs. Because if that not work, is pointless to do the rest! \---- However, rust is a BEAST of language. I can see build a "swift" as more possible than a "rust". However, consider that some certainly advacend languages are made by (or almost) one single guy: &amp;#x200B; * [https://nim-lang.org](https://nim-lang.org) * [https://elixir-lang.org](https://elixir-lang.org) * [https://luajit.org](https://luajit.org) &amp;#x200B; So if you have the raw talent and determination is possible to lift up to a solid 1 version? Yeah I can think is possible. "Finish" it and put the other extra necessary stuff must need more people but if you have a solid sketch of what you have then I think is possible to get a chance.
The defining characteristic of a wiki is that it's communally editable through the web browser. The closest you can get to that without either using GitHub's wiki system or running wiki software on a separate web server is to put a folder full of raw markdown files in your Git repository, which use relative hyperlinks to reference each other, and then let people use Git's in-browser code editor to submit pull requests by editing the raw markdown. Why do you specifically want this? If it's just a matter of being able to back it up and edit it offline, GitHub does use Git as their backend for their wiki offering and the pages have a "Clone this wiki locally" URL in the sidebar.
I prototype my own lang in python, swift, f#. Later I set on rust but now I get a more solid vision of what I want. &amp;#x200B; Certainly my life could MUCH easier using swift.
So you want your cake and eat it too. &gt; I don’t wish to use web render technology as it’s not a proper way for native software GUI. Then you have cocoa crate for macos, gtk for linux, winapi-rs for windows. If you want native you must build it in native tookits. &gt; But you mentioned I should build lots of custom widgets, which framework allow me to create custom widgets with very high flexibility ( I mean less limitation ) Without going insane web based GUI. Now you know why everyone uses electron.
Dokuwiki
Assuming the library brings it's own eventloop and isn't thread-safe, you need to wrap it with a custom executor instead of another one. Both of these properties should apply to the diverse macOS queue frameworks.
Thanks for sharing your thoughts. i need to do it because its easier to edit offline/while working on the project, rather than opening the web page etc. secondly i can keep track of it and always can be up do date cuz i remember when i modify a file(for example) update its doc too and then commit-push. You mentioned about github that can do what i need almost, but im a GitLab user and not sure they provide this kind of feature yet?
Thanks. i totally hate electron as its not a proper way. it's like sort of hacking. do you have any experience making gui in GTK, OrbTk, Azul or conrod?
Thank you for your nice blog! A little question: the `identity` module which used to live in `actix_web::middleware::identity` (in `actix_web` 1.0.0) has moved to `actix_web::identity` in the latest version(actix_web 1.0.3), so if it's better to use `acitx_identity` instead? and update the tutorial to use `actix_web` 1.0.3 :)
Just a heads-up: The bindings are not safe: Dropping a `Transfer` while it is in progress will cause memory unsafety (since the operation doesn't get synchronously cancelled). These kinds of APIs are unfortunately the ones which currently don't fit very well into Rusts async model since it's readiness and not completion oriented. You can work around it by copying all data into library-managed buffers and also managing lifetime of the operations and deferred cancellations inside the library. The Tokio/mio for windows which you mentioned actually does something similar: Instead of requiring the user to hold onto the original buffer for the whole duration of the transaction (like a real IO completion model would be) it copies data into another buffer and uses the library-owned buffer for interacting with system APIs.
GTK is usable on linux only and even there half the population is not going to like it for not being QT. The rest of them are far from ready. There are no good solutions and Electron at least allows you to create something nice looking without an unreasonable amount of effort.
&gt; JavaScript does not have native integers. For correctness, I must mention that the language specification will soon have a native integer type, `BigInt`; it’s a stage 3 proposal (see https://tc39.es/process-document/ for what that means), and Chromium has shipped an implementation.
You joke but nautilus is a serious impediment to some of my colleagues getting work done, on account of its sometimes-absurd CPU usage.
I think Rocket is a pretty solid choice, especially if you just want a RESTFUL API without too many bells and whistles. If you're familiar with Python, it is similar to Flask. It has nice integration with Diesel if you need to work with database as well.
`AsyncGroup::submit` takes ownership of the `Transfer`, and `wait_any` gives you a completed `Transfer` back, so you don't have a `Transfer` to be able to drop while it is pending. If you drop the `AsyncGroup` with pending transfers, it blocks waiting for them to cancel. But yes, this would be concern for anything wrapping these kinds of APIs with the `Future` trait.
Getting async await and const generics is better than Christmas
Don't `Cargo` binaries already work almost exactly like this? If you create `src/bin/client.rs` and `src/bin/server.rs`, you can run them both as binaries. They'll be built when you do `cargo build`, or `cargo build --bin client` / `cargo build --bin server`. There's no need for an explicit `[[bin]]` section to do this. The only difference I see is that the current syntax is slightly more explicit. I would argue that this explicitness is good, since it differentiates very clearly between binaries (`--bin x`), libraries (`--lib`), and tests (`--test x`)?
Sounds like you don't want a wiki since you want it to be in the git history. It sounds like you want something like mdbook
If you want binaries that aren't examples, then that exists! If you put files into `src/bin/app_name.rs`, then the binary will be runnable with `cargo run --bin app_name`. In addition, when you `cargo install` the package, that binary will be installed (while examples aren't). I'd argue examples should stay as they are, because they're useful - as examples, not as end-user binaries. They serve two different purposes?
Looks interesting! I could certainly make use of a lightweight binary parser. One question: I couldn't exactly figure out what`bind` means. So, when reading, the input **must** have exactly the specified byte value, and when writing, the writer will always write the specified byte value - is that correct? And can `bind` be use for fields larger than 1 byte?
I'm building a image geotagger and processor for large batches of images. Once finished I'm going to compare it to my fairly non-performant Python implementation.
Const generics aren't stable, but they can be used for implementation in the compiler.
You could probably use [`std::path::PathBuf::push`](https://doc.rust-lang.org/std/path/struct.PathBuf.html#method.push) and [`std::path::Path::join`](https://doc.rust-lang.org/std/path/struct.Path.html#method.join). Then you can use that path or maybe simplify it using [`std::path::Path::canonicalize`](https://doc.rust-lang.org/std/path/struct.Path.html#method.canonicalize) (Note that the `canonicalize` function will fail if the path does not exist). Here is a [playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=cfebb15eaea68d5ef4d2cd63213d95f0) where I tested using the `push` and `join` methods to handle relative paths.
What do you use for a file browser? vifm? NNN?
Wow, this is what I've waited for. In the post, you mention a mastodon account, but neither is it a link, nor could I find any other information about it on the page. I would love to follow your updates on the fediverse, would you care to link it?
That would require geriatrics
With const generics, associated constants, and variadic generics I'll finally be able to reimplement type traits from C++ templates in Rust! Not sure if that's going to be an antipattern yet.
I … don't? Very occasionally I'll use `find-file-in-project`, which is not even really the same thing. (A version of which that respected `.gitignore`, though, that would be great.)
i think that's what im looking for but need to read more about it. i couldn't get the sense only by reading the description ...
Read up on the [C++ core guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) and talk about which suggestions are formally enforced by Rust's semantics.
Regarding the libusb API: In practice anything cross-platform integrates libusb by running its event loop on its own thread; the pollfd integration doesn't work on Windows, and integrating its polling in a multi-threaded event loop is [quite tricky to do safely](http://libusb.sourceforge.net/api-1.0/libusb_mtasync.html) (more of an indictment of C than libusb). The Linux-centrism is mainly in that the platform USB APIs are different in how they approach things like device discovery, opening interfaces vs full devices, and pipes vs individual transfers for cancellation. Rather than being designed around the functionality they have in common, it goes way out of its way to simulate the Linux semantics on all platforms, without providing a way to drop down to the platform-specific APIs when necessary.
I like it. I'm using vifm at the moment but would rather use something written in rust. Libmagic isn't in Arch Linux. Does that mean image preview doesn't work?
You should check out fzf then. I use it as often as I do vifm now to find stuff. It integrates find or ripgrep or whatever you want.
I find Actix-web pretty similar to Express. Rocket still requires nightly Rust. If you're just playing around, that's probably no big deal. If you're planning on using this in production, be aware that you might have to be extra careful upgrading the framework and your compiler versions, so that you don't end up with a new compiler breaking one of the nightly features that Rocket relies on.
Or you could just develop on nightly ; ) Though currently `#![feature(const_generics)]` comes with a built in scary warning about "this feature is only half implemented and might crash the compiler" (paraphrased).
You can't have a GUI that both looks like that and looks native. Pick one.
good point. thanks
Cool! I've been looking forward to the updated Neomutt for a while. Would love to give your client a try in the meantime. If you're planning on adding POP and IMAP support, I'd be very happy to help and collaborate on it.
Isn't that a breaking change? That's breaking semver on the first point release after 1.0
[mdbook](https://github.com/rust-lang-nursery/mdBook) might be a good option, that's how the "The Rust programming language" book is written and maintained.
Because you said in the other comment that pixels are depended on neighbours, I would suggest: Have two image buffers, one input and one output. Split output buffer for the threads. Threads read from input buffer and write to their part of output buffer.
Making small improvements to stuff in [abi\_stable](https://github.com/rodrimati1992/abi_stable_crates/tree/nonexhaustive/),starting by improving the error message of dynamic-library type-layout-checking errors .
Be prepared that developers often get unreasonably emotionally attached to their chosen technology and can very quickly get salty when you say something else is better in some way.
Dude old use pastebin or something next time. Also items is not a Vec&lt;String&gt; but a Vec of some other structured type. The error message says line 5 where in the paste line 5 is where a JSON object starts (a map) in the array of items, which your struct says should be an array of strings.
How much faster compilation are we taking about? Will it be noticable for most people? I'm new to rust, but the benchmark I saw in that GitHub issue only shows at most a 2.4% speedup. Maybe that is larger than it sounds on paper?
Updating [compact_arena](https://github.com/llogiq/compact_arena) to use the newly stabilized `MaybeUninit`. I must have introduced some UB, one test is reliably failing with stack overflow when it shouldn't.
I ended up with actix-web after using hyper and I really enjoy it. I also tried Rocket and had trouble but that's probably more to do with my immaturity with Rust at the time than anything Rocket specific.
Very nice! Is it possible to use this type in a `#[wasm_bindgen]` interface, or do you have to convert it manually?
You're welcome :)
A single 2.4% speedup; not really noticeable. A few 2.4% speedups would be noticeable, and they do happen from time to time.
One PR causing a 2.4% speedup sounds pretty big to me, but I'm just some guy
Lol
Yes it’s a breaking change, the new tutorial uses the identity module 👍🏼
Building a media server for storing images, audio, and video files across a network &amp;#x200B; [https://github.com/00benallen/medioxide](https://github.com/00benallen/medioxide)
&gt; Speaking of which, you mention you have a Mastodon, but don't give a link or a user name in your blog post. Oof, it got lost in a quick text restructure. Thank you! For posterity, it's [@epilys@chaos.social](https://chaos.social/@epilys)
Sorry for that, there was a link but it got lost in a quick edit I did [@epilys@chaos.social](https://chaos.social/@epilys)
No, there is not, unfortunately. The Copy trait is not just an implicit call to Clone::clone(), but actually means that the compiler will do a bitwise copy. For this reason, it is not possible to customize its behavior. My question would be, why do you want to do that?
Agreed, I’m guessing a lot of the easy work to reduce compile times has already been done, and its PR’s like this where we get 2% here and there that make the difference.
&gt; Note that you can't #[derive(Display)] That's an artifact from the strum macro derive of the strum crate I added, but didn't use in the code. I'll add the second example maybe. thank you very much.
Thanks a lot!
`Copy` has no extra functionality over `Clone`, it's really only there to mark "this is a very cheap copy". If you need to `Copy` something, and it's not cheap, there should ideally be no reason you can't use `.clone()` instead. It is possible to do a stack-based vector, but it'd be of limited size and come with its own downsides. Something like [arrayvec](https://crates.io/crates/arrayvec), but it'd need to be slightly different from the one that crate implements (see [arrayvec#32](https://github.com/bluss/arrayvec/issues/32)).
Several years later: *C++ is now a valid subset of Rust.*
How are you targetting the STM32 ?
hey, that looks fun. You should also check out the [cookie factory crate](https://github.com/rust-bakery/cookie-factory), that works with the same design as nom, but for the serializing side. I explored a bit generating both parser and serializer from the same code, but saw some issues with handling branches (`alt` in nom) and tag/length/value based formats. If you want to work on that i'd be happy to chat about it.
wtf ive never heard of it
Oh My. My initial thought was Copy just copies the pointer to the data unlike Clone. Thank you for educating me [/u/simonask_](https://www.reddit.com/user/simonask_)
That would be hilariously unsafe, leaving one of the copies with a dangling pointer when the other goes out of scope. Preventing that is one of the key goals of the Rust ownership system.
I hope there'll be many reusable crates for mail handling. My [demo mail application](https://www.vandenoever.info/blog/2018/09/16/browsing_your_mail_with_rust_and_qt.html) uses mailparse, imap-proto, imap. I've also used lettre and lettre_email.
Yes, you're correct. Though it isn't exactly the same, the similarities I saw made sense to me for me to call it that. I see it is confusing though.
In general yes. But there is still the in-progress CraneLift backend, which promises 30%+ speedups for debug builds https://github.com/bjorn3/rustc_codegen_cranelift/milestone/1
Add in the fact that the author of the derivative work was a contributor to the original project, and it's a *very* big stretch to claim that they didn't fork the original project.
That is a very nice demo. Wouldn't you be interested in developing it for actual use? &gt; I hope there'll be many reusable crates for mail handling. For now I've bundled all the mail handling stuff into a separate crate, instead of splitting parsing, types, protocols. I'd like to use it for a mailing list server and other stuff in the future :)
&gt; Libmagic isn't in Arch Linux. Actually: ``` $ pkgfile libmagic.so core/file ```
&gt; That is a very nice demo. Wouldn't you be interested in developing it for actual use? I've done work in that direction. The current next step is to be able to send mails. I've a compositor UI, but some connecting it up needs work. So yes, but not my main priority at the moment.
I'm writing a wrapper for [libgoa](https://wiki.gnome.org/Projects/GnomeOnlineAccounts): that's my first time doing some FFI with Rust, and that's a real pleasure, so far. Currently highly WIP: [https://gitlab.com/Boiethios/goa-rs](https://gitlab.com/Boiethios/goa-rs)
&gt; If you're planning on adding POP and IMAP support, I'd be very happy to help and collaborate on it. I've started an IMAP implementation instead of using an existing library. It's in an early stage because I lack familiarity with the protocol. I'd love to collaborate, send me a PM to discuss it on XMPP or the meli-devel mailing list!
Nice to see that people use this better API. It is great and smart, BTW.
QtCreator can import from Photoshop. https://doc.qt.io/qtcreator/quick-export-to-qml.html You can build a Rust UI with Qt with Rust Qt Binding Generator.
Yeah, the compiler actually explicitly forbids `impl Copy for Foo {}` unless all fields of `Foo` also implement `Copy`. This is a special case in the compiler (together with various other marker traits).
I don't have any experience with wasm_bindgen and would assume that js_int is not compatible right now, but I'll look into it.
I've seen this as well, and it's very strange. I mean, one can think that a technology is not as thorny as religion or political related discussions, but nope, people are very trenchant. I had an interview for a Rust position in which the C++ expert was attacking me all the long, saying blatant lies about Rust in front of his boss. I didn’t know how to react, and eventually the boss reconsidered the choice to use Rust in the new project. Not sure if that change was related to my "prestation", but it was not a nice experience.
GitHub opensourced their wiki system called gollum and gitlab uses it for their wiki. You can clone the wiki repo and edit locally and push. This is the same as editing the wiki via the browser. The only thing is it's a different got repo to your actual code repo
Thank you
very good. thank you
Ok I managed to get this working, but now I have another question. &amp;#x200B; In my original script I was printing the status of the processing to the stdout using `print!` macro. I had 2 variables: `TOTAL_ITERATIONS` and `iterations_done`. I was using them to make a progress bar. After processing each pixel I was incrementing `iterations_done` and then updating the progress bar. &amp;#x200B; How can I achieve the same with this threading? As I understand, threads won't be able to write to the same `iterations_done`, so how can I find out how many iterations are done by total? &amp;#x200B; I was thinking about making `iterations_done` a vector of size of the amount of threads instead of an integer. Can I give each thread write access only to 1 item of the vector somehow? What do you think?
I mean, that's what it would do. Vector's ownership semantics mean that it explicitly won't allow you to do that. If you want shared pointers to something, maybe look at an `Rc&lt;[T]&gt;`?
Oh, I remember you. You were the one who deleted the last repo with all of the extensive discussion (with receipts) of your license violations.
Any reason you choose to reimplement these things instead of using an existing library? I'll drop you a PM soon about this.
Check out their comment history, too: https://www.reddit.com/user/botttika/
The number of changed SLOC is irrelevant. Unless he rewrote it from scratch- which I doubt he did- this would be considered a "derivative work" and be subject to the terms covering derivative works.
In fact, here's the comment thread from the last time he posted this project: https://www.reddit.com/r/rust/comments/asenye/yarte_yet_another_rust_template_engine_is_the/eh16lqt/?context=10
Congratulations on the release! Have you corrected your ongoing issues with refusing to properly license this as a fork of Askama? It's hard to tell since you deleted the github repo and discussion thread concerning this issue. For everyone arriving at this page: yarte is a fork of [Askama](https://github.com/djc/askama/) for which the author is refusing to properly follow the License terms, calling it a waste of time, which is especially egregious because Askana is MIT licensed and properly forking an MIT project is the easiest thing in the world. More in the reddit comments of previous posts: - https://www.reddit.com/r/rust/comments/au9o3m/the_more_fastest_template_engine_fork_more_than/eh6uecs/?context=3 - https://www.reddit.com/r/rust/comments/asenye/yarte_yet_another_rust_template_engine_is_the/
It's not that hard to create a basic compiler. A lot of universities have that as one of the projects that students do either solo or in small groups in matter of months. But getting from that to something like rust is a lot of work. I am not just talking language features. (Ans some of them are no picnic) - standard lib, that maybe looks small in rusts case, but when you have to implement it yourself its not that small - not so standard lib, do you need database connectors, json parser, email parser, SSL and other crypto, jpeg image, zip import? you need to write them yourself - good errors - rust spoiled me - debugger is always nice to have - need to figure out libraries and linking - some other support app like cargo, rustfmt etc. - your lang support in you favorite editor, maybe even completion - concurrency - here be dragons Of course then its all testing/debugging and edge cases. And since it's just you you have to do every itty bitty thing yourself. That said, people did manage to do all or most of that so it's doable, just make sure you realize how much work it is.
Tbh, Rust Evangelism Strike Team is a meme for a reason, parts of Rust community are also sometimes a bit extreme in their RIIR suggestions and praising Rust a bit too much.
ah. didn't know that. Will try that out . thanks.
Didn't know that. I will try that out. thanks.
Just redefine tuple type semantics so `(a, b, c) == (a, (b, c))`
I'm making an image processing tool, and I'm parallelizing the work using the [rayon crate](https://crates.io/crates/rayon). I want to have a status bar in the terminal, but for that I need to know an integer `iterations_done`. How can I give multiple threads access to increment that integer? My code: fn process(img: image::ImageBuffer&lt;image::Rgba&lt;u8&gt;) { let mut buffer = img.clone().into_vec(); let mut iterations_done = 0; buffer.par_chunks_mut(img.width() as usize * 4usize) .enumerate() .for_each(|(y, row)| { for x in 0..img.width() { // Do some work on the pixel // .... // Increment the iterations_done // ??? } } }
Yes, that exactly what it does. And yes it can work with any writer/reader (even more compicated ones such as seq) just pass what you want as a parameter! Thanks, I'm going to expand the documentation on that side as I was already thinking it was lacking different examples that show this kind of features.
Not spam at all. It's always good to see how people are using libraries. Thanks for writing this and updating it with the latest actix version :)
Last week was pretty busy with the 4th. This week I'm mostly working on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) documentation and PR reviews including one to add 6 new thermodynamic quantities!
If you wonder if something can be put on the stack, ask you this question : has the element a size which is known at compile-time or not ? If the answer is yes, then you can create a slice in the stack ! But if you need something able to grow/shrink, then you need to use a vector. Other Rustaceans mentioned `Clon`ing the vector, which helps most of the time, but is often not the best solution. If you just want to be able to access it, then you may prefer use a reference (which is `Copy` by the way).
Woohoo! However, I'm wondering why they still constrain impls to lengths of at most 32. Could implementing a trait for a type somehow be a breaking change?
They're being conservative with this until the const generics feature is ready and stabilised (just in case something goes wrong and it needs to be reverted). This restriction will be removed at that point :)
I'm using Actix. It's pretty sweet and doesn't require Nightly.
If you use an [AtomicUsize][1], you can increment it from several threads using the `fetch_add` method. [1]: https://doc.rust-lang.org/std/sync/atomic/struct.AtomicUsize.html
Oh god that *is* a scary warning.
NO! OH GOD PLEASE NO!
Is anyone else finding the 'Rust (rls)' extension on VS Code to be running awfully slowly since the last release? I recently ran rustup for the first time in a while and the extension is now painful to use. I also get an 'unknown RLS configuration: 'mode', 'rustup' error but I cannot find any reference to that anywhere in the VS Code settings or elsewhere.
GTK can work on not-Linux, you just would have to package the theme with the program when you ship it to make it look ok. I highly suggest using gtk-rs. The world needs more not-Electron wallets.
Is there any way to remove the `'static` bound on the given code? Like, the tasks are all destroyed when the `Runner` is dropped. ```rust use std::sync::{Arc, Mutex}; use std::thread; use std::time::Instant; pub struct Runner&lt;T&gt; { tasks: Arc&lt;Mutex&lt;Vec&lt;(T, Instant)&gt;&gt;&gt;, } impl&lt;T: Send + 'static&gt; Runner&lt;T&gt; { pub fn new() -&gt; Self { let tasks = Arc::new(Mutex::new(Vec::new())); { let tasks = tasks.clone(); thread::spawn(move || { loop { let mut tasks = match tasks.lock() { Ok(x) =&gt; x, Err(_) =&gt; break, }; tasks.pop(); } }); } Self { tasks } } pub fn add(&amp;mut self, task: T, end: Instant) { self.tasks.lock().unwrap().push((task, end)); } } fn main() {} ```
The tone has its importance, also, in this case. I can handle a fanboy, but that's hard to manage someone who is passive-aggressive.
Trying to get an RTFM project running on an ST Nucleo board to play around with it and potentially using it as an audio DSP platform.
Change iterations_done to be an atomic variable, i.e. AtomicUsize.
Can I use AtomicU64 instead? The numbers may be big
If you're interested in shallow cloning, wrap the data in an `Arc` (combined with `Mutex` or `RwLock` if you need mutability). You still need to use `Clone` instead of `Copy` there, since copying those type isn't just a memcopy. Or just share an immutable reference `&amp;Vec&lt;T&gt;` or `&amp;[T]` if you don't need to share ownership.
Ah wow, that's a pretty impressive improvement .
Wow, this looks super good! Can't really use it yet since it doesn't support the `mbox` format, but I'm definitely going to follow the project closely. I noticed the GUI was a bit broken by various calls to `std::dbg!()` messing the UI. One small technical issue: I tried registering to the mailing lists, but I haven't received any confirmation. Are they working?
https://github.com/actix/actix-web/commit/546a8a58db0e9f985310ae1ed56878a089f7ba09#commitcomment-33982351
&gt; Is there any way to remove the 'static bound on the given code? Like, the tasks are all destroyed when the Runner is dropped. Right now, the they are not necessarily destroyed when the Runner is dropped. Your spawned thread might still be busy locking and popping your array of tasks. Your spawned thread is independent from your Runner object which requires T to be unconstrained w.r.t. lifetimes. But there *is* the concept of "scoped threads" which are guaranteed to terminate at the end of some scope. There are third party crates like [crossbeam](https://docs.rs/crossbeam/0.7.1/crossbeam/thread/index.html) that give you safe scoped threads. But your design still wouldn't work because you try to launch a thread in `new` and immediately return which terminates that scope. Instead of a custom type, you sould be able to turn this into a generic function (`runner_scope`) which you could use like this: runner_scope(|runner| { runner.add(some_task, some_instant); // ... }).unwrap(); which is similar to how you launch a scoped thread in the first place: crossbeam::thread::scoped(|scope| { scope.spawn(...); // ... }).unwrap();
These are all really good points. I'll try to address some thing I don't think I'll need right away * std is going to be a huge pain, I definitely agree. I do of course want to work basic data structures and strings and numeric computations and I'll have to implement these by hand, myself. * Other things like networking and file libs I have very high confidence that I can do over a few weekends. I kid you not. I've done it many MANY times in past. Open up the RFC, build a generalized parser generator, codec and a few state machines and you basically have a working lib. Getting it to be fast and secure is another story. * Errors in Rust and a helpful compiler is one of the things I truly love about Rust. I think with that motivation I can handle this. * Debugger. I'm rarely in the debugger. I believe I can go without it for a while. * Not having package management from the get go is going to be a drag. * I just recently wrote my own vim support for Rust. With the community scripts not currently highlighting type parameters, I went and just parsed Rust using syn and applied it to my own color scheme. I've done this way too many times in the past for vim. So this will be easy. * Concurrency. This one is going to suck. No two ways about it.
I giggled
Thank you! Great community, I initially checked out r/compilers and the people there seem really nice and helpful but the community was small. This one is big and smart and everyone knows what they are talking about and therefor kinda intimidating. But will check it out nonetheless.
Sure :)
I wouldn't say it's the slowest, but ranger is kinda slow, so I prefer not to use it when I can. And what is the slowest part of your workflow?
&gt; [RFC #1582](https://github.com/rust-lang/unsafe-code-guidelines/blob/master/reference/src/layout/structs-and-tuples.md) proposed that tuple structs should have a "nested layout", where e.g. (T1, T2, T3) would in fact be laid out as (T1, (T2, T3)). The purpose of this was to permit variadic matching and so forth against some suffix of the struct. This RFC was not accepted, however. This layout requires extra padding and seems somewhat surprising: it means that the layout of tuples and tuple structs would diverge significantly from structs with named fields. from the unsafe code guidelines' section [layout of tuples](https://github.com/rust-lang/unsafe-code-guidelines/blob/master/reference/src/layout/structs-and-tuples.md)
I think it's going to be Actix Web then! Similarities with Express won me over.
Thank you OP. I love to read that kind of experiments
Working into improving my personal syntax sugar macros crate
I already knew about cookie factory and that's what ultimatly made me create my own library. My main problem was that I had to write double code for encoders and decoders, and since they are different libraries the functions are mostly different, so I decided to make a less powerful library, but one that could handle both at the same time. As for `alt` it would be very difficult to implement with my current design, but I'm planning on implementing something more like a switch/match. Also tag and lenght/value is currently supported (check out the documentation for `bind` and `count` respectively) but you have to initialize length fields manually (or else it'll panic), wich I want to avoid in the future.
It looks to be like `concat!` works fine without a global allocator? The following code compiles, at least: #![no_std] pub const S: &amp;'static str = concat!("hello", "\0"); ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ce61d3c9f2ffbcdc1f0e2b77e357e1d0))
The Redox parallel currently links to an empty repository. Otherwise great update!
Oops, fixed.
transmute question: if I have a `&amp;[u8]` of exactly the right length and alignment can I transmute that directly to a repr(C) struct reference or do I need to call `as_ptr` on the slice and transmute that? Both seem to work but is one the correct way to do it? [playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=28295a175f043e887b7c246ead45ef99)
You need GATs as well to implement certain C++ type traits (but AFAIK nothing in `&lt;type_traits&gt;` itself.) You'll also need specialization to implement many of the traits.
exactly, i hate electron technique also i hate the hybrid mobile app techniques... .anyway, How about conrod by piston? its written in Rust entirely.
You don't need transmute at all. You can just cast the pointer (so only the dereference is unsafe)
When I search for it I get libmagick6, so I wasn't sure it was the same. Thanks though.
Hey :) the debug build prints to stderr, yes. I redirect it to a file like this cargo run 2&gt; /dev/null You should run the release profile though, it's faster. I'm changing some mail server settings at the moment, I will send you a pm when it should be ready.
&gt;And what is the slowest part of your workflow? My brain and it's (in)ability to think clearly, no doubt about it.
True. I've try to use a GTK app build for Windows, it was basically unusable. GTK is prefect for GNOME, and I like its style, but it is not made for other desktops.
Thanks, just installed pkgfile
I remember reading a post about a very similar approach here, but very nice work! With u/aturon being available again, I really hope that GATs are not all that far off.
What's the type of `row`? If it's polymorphic, that's why you need an annotation (which you may be able to put on `get`, depending on the type. You can combine the two statements by filtering the option: ``` if let Some(userfullname) = row.get(0).filter(|x| x.trim() != "") { .... } ``` Unfortunately, you can't combine `if let` and other conditions at the moment (until `let_chains` is stabilized.)
You can combine lines 2 and 3 with a match (if let can't do this let): match row.get(0) { Some(userfullname) if userfullname.trim() != "" =&gt; { ... }, _ =&gt; { ... } } I'm not sure if this will also solve your type inference problem.
Hmm, some insight: Your playground example has an error, to get a slice you need to do: let slice = &amp;data[..]; Otherwise the type of slice will be `&amp;[i8; 1]`, ie. a reference to an array of a single element. Now when you try your example you get a compile error: error[E0512]: cannot transmute between types of different sizes, or dependently-sized types --&gt; src/main.rs:18:61 | 18 | let foreign1 : &amp;SomeBindgenGeneratedCppClass = unsafe { transmute(slice) }; | ^^^^^^^^^ | = note: source type: `&amp;[i8]` (128 bits) = note: target type: `&amp;SomeBindgenGeneratedCppClass` (64 bits) error: aborting due to previous error What is happening is that `&amp;[_]` is a fat pointer and you cannot transmute that to a non-fat pointer. You must use `as_ptr()` to get the raw pointer to the first element. Next you can reinterpret cast raw pointers with a regular `as` cast and then use unsafe to dereference that: let ptr = slice.as_ptr() as *const SomeBindgenGeneratedCppClass; let foreign2 = unsafe { &amp;*ptr }; Finally you claim that you have a `&amp;[u8]` of exactly the right length and alignment? Your example shows anything but... 1. You actually create an `&amp;[i8]`, not that it matters much in this case. 2. The size is right but your example has no checks at all, I'll assume that was for the sake of example. 3. The alignment in the example will be `1` because you create it from a slice of i8. If your SomeBindgenGeneratedCppClass was more complex this is instant UB. Here's my version of your example cleaned up: [playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=3501cfbf9ed7bbbeb944f20a810ad7c4) #[derive(Debug)] #[repr(C)] struct SomeBindgenGeneratedCppClass { a: i8, } pub fn main() { let data = [1i8]; let slice = &amp;data[..]; let ptr = slice.as_ptr() as *const SomeBindgenGeneratedCppClass; let foreign = unsafe { &amp;*ptr }; println!("{:p}: &amp;{:?}", ptr, foreign); }
&gt;mem::forget the AsyncGroup with transfers pending, they aren't cancelled, but libusb may still complete those transfers and write to the buffers from another thread. Isn't that so safe? Forget leaks the memory, it doesn't deallocate it.
Can someone share is method to read function declaration ? I find my messy when there is generics and lifetimes. I think I not fully understand what's between &lt;&gt;, in general. If you have any pointer to this, i'll take it. Thanks.
I haven't noticed any particular decrease, but it's always been slow. In my case the problem is that for every change RLS tries to check all examples, tests and whatnot and tends to get stuck on checking tests (as the status bar indicates). It's just way faster to run `cargo check` myself. Unfortunately this isn't going to be fixed any time soon. The current RLS just isn't designed for IDE use and tries to reuse rustc as much as possible. Not that I blame RLS! this is a huge task. There are plans for a 'RLS v2' which addresses these design constraints in the form of rust_analyzer for a true incremental rust compiler for IDE but it is 'work in progress'.
&gt; there is physically no way of making Linux USB thread safe; if multiple threads listen on the same device, you have a race condition Race conditions in general aren't unsafe, only *data races* are, so maybe this isn't actually a problem. [source](https://doc.rust-lang.org/nomicon/races.html)
What error is showing? I think it may not work becouse in your struct you define field as String, but you're passing string slice. Try "192.168.0.1".to_string()
`row` is this type: https://docs.rs/tiberius/0.3.2/tiberius/query/struct.QueryRow.html If I try to do `row.get::&lt;Option&lt;&amp;str&gt;&gt;(0)`, I get several weird errors: error[E0107]: wrong number of type arguments: expected 2, found 1 --&gt; src\main.rs:160:48 | 160 | let userfullname_option: Option&lt;&amp;str&gt; = row.get::&lt;Option&lt;&amp;str&gt;&gt;(0); | ^^^ expected 2 type arguments error[E0277]: the trait bound `std::option::Option&lt;&amp;str&gt;: tiberius::query::QueryIdx` is not satisfied --&gt; src\main.rs:160:48 | 160 | let userfullname_option: Option&lt;&amp;str&gt; = row.get::&lt;Option&lt;&amp;str&gt;&gt;(0); | ^^^ the trait `tiberius::query::QueryIdx` is not implemented for `std::option::Option&lt;&amp;str&gt;` error[E0308]: mismatched types --&gt; src\main.rs:160:68 | 160 | let userfullname_option: Option&lt;&amp;str&gt; = row.get::&lt;Option&lt;&amp;str&gt;&gt;(0); | ^ expected enum `std::option::Option`, found integer | = note: expected type `std::option::Option&lt;&amp;str&gt;` found type `{integer}`
Still working on actix boilerplate. Simple web server for microservices with usual suspects. Async, Postgres, File IO,... Looking to add streaming files to s3 and file io from the client. Looking for PRs and collaborators. https://github.com/mattlockyer/actix-json
I've been working on a boilerplate with examples of various topics. Thanks for posting this is awesome!!! https://github.com/mattlockyer/actix-json
Can the listen function take a mutable reference to the clients list? That's probably your easiest way to do this, rather than making it a global variable. Of course, if listen is going to be called from multiple threads (if this is a server,) you'll need to stick the list behind some kind of lock, like a `RwLock`: ``` fn listen(ip: String, clients: &amp;mut Vec&lt;Client&gt;) { clients.push(Client { ip }); } // in your main function let clients = RwLock::new(Vec::new()); ... listen(ip, clients.write()?); ``` If you really need to, as a last resort you could make it a static variable. ``` #[macro_use] extern crate lazy_static; lazy_static! { static ref CLIENTS: RwLock&lt;Vec&lt;Client&gt;&gt; = RwLock::new(Vec::new()); } // in your listen function; CLIENTS.write()?.push(Client { ip }); ```
`row` takes the index type as a parameter; calling `row.get::&lt;_, Option&lt;&amp;str&gt;&gt;(0)` may work.
I'd like to be able to treat \`foo\\bar\\baz\` on windows and \`foo/bar/baz\` on linux as the "same path". I realize there are corner cases where this doesn't work, but in general there should be something that I can do to go from one to the other. I looked into it more and found that paths in rust just wrap an OS string, so maybe I'm barking up the wrong tree?
Have you tried `row.get::&lt;_, Option&lt;&amp;str&gt;&gt;(0)` ?
The Redox Parallel project will soon be replacing the current `parallel` crate on Crates.io. It was originally intended to use Ion as a library for shell executions, as soon as it became possible to do so. With this complete, I will soon be pulling the repos for the previous project, making this the successor. By embedding the Ion shell within Parallel, execution times are vastly improved for tasks which would normally spawn a shell for every job, eliminating a majority of the process forking and initialization required to execute each task. This could potentially shave seconds, even minutes, for certain kinds of workloads, and reduce the memory requirement of spawning a shell for every job. The flexible feature set of Ion additionally gives great power to the kinds of commands that can be naturally constructed. Ion's simplified syntax is less-awkward than Bash, and opens a few doors that weren't possible to achieve with human-readable incantations. First-class arrays, array slicing, array/string methods, array/string subprocesses, and typed assignments, to name a few. A large number of optimizations are also employed to parsing and execution, because Rust makes it easy to do so safely.
I’ve updated my sample code. Please talk a look again on the line which I define the variable.
If it's global variable then it will not work, becouse in rust only constants (const, let is immutable variable) are allowed to be global. Try to define it in function.
I heard that global variable doesn’t exists in Rust, is that true ? Where can I read more about that rwlock technique? Any link please?
Have you considered just.. installing xterm?
So I'm trying this out by putting an array in a struct (because this is a thing I've needed before) and I can't quite figure out what's wrong. Is this simply not supported or am I and idiot? https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=a435b059cc214042f05641bf456afa6e
It sounds like you are describing a "global variable". Indeed, other languages may make it easier to create such a variable, but that doesn't make it a good idea. Python and PHP are effectively single-threaded languages, but Rust supports multithreading. Thus global variables must also be thread-safe. Global variables have a lot of pitfalls and dangers, and Rust makes that explicit, unlike Python which doesn't have as many pitfalls (due to the virtual environment) and Go which protects you from them, and Java which lets you shoot yourself in the foot. I would rethink your design to pass around the vector of a reference to the vector though all the functions that need access to it. If you *really* need a global variable (99% of the time you don't) then check out the lazy_static crate. Be sure to wrap the vector in a mutex.
But I need to use this Vector in multiple functions not only in one function. Also this is a server that registers the clients connection. Imagine that the listen() is on multithreaded system and try to register into the vector once got a call from the client. Another hand the variable must define once and reuse later on. How can I define it in a function and not redefine by calling the function? I’m a bit blur on this
I mention it in the post: &gt; I have also tried to avoid adding dependencies when I could. I find it scary to install something and get hundreds of packages pulled. But there's also the element of fun of designing and making things, which is the primary motivation for me.
It depends on whether you define USB data packets going to whichever thread wakes up first, potentially causing data loss, to be a "data race" or not. I do, and whether you agree with me or not, I think we can agree they're undesirable at the very least.
Global variables definitely exist in Rust; you can have them be `const` (meaning they have to be computed at compile time and are baked into your program) or `static` (meaning they can only be accessed through `&amp;'static T`. It's generally a good idea to avoid global mutable variables; Rust makes it a bit hard to work with them (having to use something like `RwLock`) because of how easy it is to introduce data races. The `RwLock` documentation is [here](https://doc.rust-lang.org/std/sync/struct.RwLock.html).
Is there any easier solution to keep the connected client into a list temporary and call it from other function? Haven’t test but , (impl) Method technique can do the job?
Why do you have multiple threads listening to the same USB endpoint anyway?
It depends on the architecture of your program - I'd need to see in what context these functions that need to have access to the clients list are getting called.
That’s true. As I said I’m new in rust and trying to learn in Rust way. For sure I’m not gonna use the lazy_static. So how would be the Rust approach for this case? A multithreaded server that needs to keep track of connected clients temporary(not writing into fb or file-just keep it on the memory) .
You should replace `impl&lt;const X:usize&gt; ArrayHolder&lt;const X: usize&gt; {` with `impl&lt;const X:usize&gt; ArrayHolder&lt;X&gt; {`. If this is done, it gives a very weird error: error[E0573]: expected type, found const parameter `X` --&gt; src/main.rs:7:33 | 7 | impl&lt;const X:usize&gt; ArrayHolder&lt;X&gt; { | ^ | | | not a type | help: try using the variant's enum: `regex_syntax::ast::HexLiteralKind` This is a bug in the compiler. You should report it to github: https://github.com/rust-lang/rust/issues/new
I'd stick it behind Nginx, mainly because it makes it convenient to be able to host other things at the same time (for example, on other subdomains). Though my experience is only with my small personal website; I have only theoretical knowledge of scaling up to deal with very large numbers of requests with load balancing and such. I would also expect that Nginx can serve static content more efficiently, at least without making a non-trivial effort to implement similar techniques to those used in Nginx. (Though it would be neat to see a powerful web server and load balancer that compares to Nginx written in Rust).
Tokio has pool of blocking threads to handle blocking I/O. If you have enough time, you can implement io_uring for mio, and use async I/O for files also.
There is no architecture yet as I’m trying to prototype the simple networking and all are in main.rs but separated in few functions. Main() // listen will call via multithread Listen() // get the request and IP, pass the IP to Register(IP) Register(IP) // need to keep the client detail in a variable Send() // send to specific client by getting the detail from the client_list variable. It’s not the final style/architecture for sure but for now I have these functions in the main.rs
Here's some code that I wrote for testing with rocket/diesel/postgres to be called to get an environment at the start of each test, you might be able to repurpose it. The main idea is that we run each test in it's own database schema - obviously this will cause issues if you use schema's inside your actual application. pub struct TestEnv { schema: String, client: Client, } pub fn rocket_integration(test_name: &amp;str) -&gt; TestEnv { let mut database_config = HashMap::new(); let mut databases = HashMap::new(); let schema = format!("tmp_schema_{}_{}", test_name, rand::random::&lt;u128&gt;()); let db_url = format!( // "%3d" is '=' "postgres://topper:topper@localhost/topper?options=-csearch_path%3D{}", schema); // Create rocket database_config.insert("url", Value::from(db_url)); databases.insert("diesel_postgres_pool", Value::from(database_config)); let config = rocket::Config::build(rocket::config::Environment::Development) .extra("databases", databases) .finalize() .expect("Failed to build rocket config"); let rocket = crate::fuel(Some(config)); // Setup db let db = crate::MainDb::get_one(&amp;rocket).expect("Faild to get db"); diesel::sql_query(format!("CREATE SCHEMA {}", schema)) .execute(&amp;*db) .expect("Failed to create schema"); for migration in embedded_migrations::ALL_MIGRATIONS { // Doing this instead of `embedded_migrations::run` // to verify that all migrations are actually running // and thus we aren't somehow ignoring the search_path // and schema argument passed at the start of the test... migration.run(&amp;*db).expect("Failed to run migration"); } let client = Client::new(rocket).expect("Failed to create client"); TestEnv { schema, client } } impl Drop for TestEnv { fn drop(&amp;mut self) { let db = crate::MainDb::get_one(self.client.rocket()) .expect("Failed to get db\n\n\nFAILED TO CLEANUP AFTER TEST\n\n\n"); diesel::sql_query(format!("DROP SCHEMA {} CASCADE", self.schema)) .execute(&amp;*db) .expect("Failed to drop scehma\n\n\nFAILED TO CLEANUP AFTER TEST\n\n\n"); } }
So once again, it's both a limitation *and* I'm an idiot. Thanks!
What did it say? :)
I'm referring to my past experiences with [ckb-next](https://github.com/ckb-next/ckb-next), written in C, where I found and fixed this bug. It's safe to use multiple threads to listen for different transfer types on Linux, and the original code was written to use interrupts for HID packets and controls for proprietary communication. In a later protocol revision, the protocol switched to using interrupts for proprietary packets, and we got a spate of bug reports about failures that nobody could reproduce; this threading issue was the cause.
Even though it is fairly naughty, i love that you can fairly comprehensively emulate operator overloading in Rust with clever use of traits.
To be clear web render is not election/node. It's just a dom/style rendering engine not an entire web browser. No js engine, not html parser, or any of the other browser bits. Just rendering.
[playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9dc59c9188c3a00e969050eebfeb0b05) Here I protected global vector by mutex, so no data races can occur. It can be replaced by other sync primitive, or fitting lock free datastructure.
You can try to define a struct with field holding clients and multiple methods instead of global variable with free functions.
Wow thanks you deserved the silver
Could you let us know what learning material have you been using? It would be useful to know which section you got stuck on. in case you are not aware, the Rust book contains a very good [chapter](https://doc.rust-lang.org/book/ch10-00-generics.html) explaining both generics and lifetime declarations.
Rust doesn't have higher kinds, so understanding them in Rust wouldn't really be possible. I learned them coming from Haskell. A higher kinded type is basically a partially applied type. By that I mean, consider that if a parametric T could **take another generic type as an argument**. For instance, imagine if you have a function that takes a Vec&lt;T&gt;, but you really want to be generic over not just T but 'things that have a .map operation'. What you want is an F&lt;T&gt;, where F is some F: T -&gt; F&lt;T&gt;. I'm not sure if any of that makes sense, but here is the best resource I've found on the topic of kinds. It's in Haskell, but I think you may still get something out of it. https://diogocastro.com/blog/2018/10/17/haskells-kind-system-a-primer/
&gt; emulate operator overloading in Rust I may be misunderstanding your comment but Rust already supports operator overloading via Traits such as `std::ops::Add`. Did you mean it in a different way?
Seems like a good bridge crate for someone thinking in Haskell!
I need help exporting/importing a macro! My project has the following structure: . ├── Cargo.lock ├── Cargo.toml └── src ├── linalg │ ├── mod.rs │ └── _vec3.rs ├── main.rs ├── objects │ ├── base.rs │ ├── mod.rs │ ├── primitives.rs │ └── transformations.rs └── render.rs I have a macro in src/linalg/\_vec3.rs named \`vec3\` with a \`macro\_export\` annotation on it. My src/linalg/mod.rs looks as follows: pub mod _vec3; pub use _vec3::Vec3; With \`pub mod linalg\` in src/main.rs, I've been able to use the macro there. Now I want to use the macro in other files, e.g. src/objects/primitives.rs or other, yet-to-be-created files under linalg (src/linalg/\_vec4.rs, for instance). Is this possible? If so, how?
I keep thinking about an overloaded syntax of `;` (to introduce monads in Rust). It would just purely amazing, but it would require some kind of visual hints. Like do { let x = Some(3); let y = None; return x; // would yield None } Of course, the problem with that is that it would confuse the hella most people who don’t have a strong FPL background (especially Haskell). To me, it would be a perfect world, because it would allow people to do something very powerful that is doable in Haskell but not in Rust. It would unlock so many cool things. Think about parsec, how it would make our persing experience in Rust more suitable to enjoy the syntax. Maybe the `return` keyword should be called `pure` as in Haskell in a `do` block, etc. In the end, I do not push that kind of initiatives too much because I know I will get a refrain from the Rust community — I got discarded when I proposed to write an RFC for type operators and overloaded operators. Yet, I still think I will write such an RFC, because damn I want those two features!
Ah yeah, meant function overloading :).
Cheers thanks for this 👌
Great thinking thanks 😊
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5c5e9a4903e0b570bee21272c228c6d5 I’m not even ashamed. :D
While Rust2018 has normalized importing of macros _across crates_ using the `use` statements this is not the case for sharing macro_rules macros within a crate. Within a single crate Rust still uses the old lexical scoping rules of macro_rules: apply `#[macro_use]` attribute to the `mod linalg;` statement. You must also ensure that your `mod objects;` statement appears lexically _after_ the linalg module. You do not need to import the macro, it will be available. I found this answer on [this stackoverflow post](https://stackoverflow.com/questions/26731243/how-do-i-use-a-macro-across-module-files).
So you're also on one of the best Mastodon instances out there :-)
I'd show off the nicest things that distinguish Rust from C++. * Ownership+ move semantics / borrow checker =&gt; reduce allocations, prevent leaks and unsafety * Traits instead of classes and inheritance * Cargo and the crate ecosystem =&gt; standard build system, no fiddling with cmake, trivially use other libraries, ... * Unsafe : is there if you need it, but tightly scoped. Only worry about undefined behaviour inside unsafe blocks! ( * Standard tooling: rustfmt, clippy * Relatively easy to integrate into existing code bases via C imterop * relatively easy cross compilation ) To be fair you can also mention the drawbacks: * Less mature (much smaller and younger ecosystem ecosystem, language itself still evolving,... ) * Missing HKT make some nice template patterns hard/impossible * Const generics (but they are coming soon!) * ...
Haha, yeah. I installed it. I was just trying to keep the footprint of this smaller.
As someone who has no idea what’s going on in this example, what’s going on?
Thanks, I'll check it.
That link talks about "type constructors", among other things, and that's more or less what generic types and functions are (I may be wrong regarding the finer details). Generics are often (and officially for Rust, I think) be called "type parameters", and they can be seen as the function parameters of the type world. The type `Vec&lt;T&gt;` is a type producing function (i.e. a type constructor) that produces variants of the `Vec` type, just like how `fn make_thing(x: u8) -&gt; Thing` produces variants of `Thing` data. "Functionifying" `Vec&lt;T&gt;` could look something like `fn make_vec_type(item_type: Type) -&gt; VecType`. It's a mental model that has been quite helpful for me, at least.
This is a server-side application, and my intention here is to capture unusual performance drops. The ideia is to log the performance problem based on the time and have another application generating performance reports. All of that in production. Maybe for my problem, the overhead isn't that much of a problem.
If you are dead-set on a desktop app, your best bet is definitely Qt/QML. (although some things in that mockup may not be doable) This project would definitely work better as a web app accessed through a browser, and even then it would still be a lot of work to make all those custom widgets, depending on what you want them to do. (it seems clear to me that some are meant to be animated) You could do the backend in Rust, and the frontend in something like React.
Looks promising, I'll check that, thanks.
AWESOME use of drop! I'll also try this!
Rust's great for FP: Nice lambda syntax and chaining, and no tail call issues (Unlike Python), but doesn't force you into a functional style that's not appropriate in all cases (unlike Haskell).
This should work great as long as the work done per pixel takes much longer than the overhead of updating an atomic integer. Otherwise you might want to batch updates--say, every 10 pixels or something.
This is awesome. Thanks!
Various learning material from blog posts to rust by examples, but I just no feel confident yet. I'll reread the chapter you link. Thanks.
a type constructor in haskell is literally just the thing you write to create a type: i.e. ``` data TypeConstructor type_param_a type_param_b = DataConstructor type_param_a type_param_b ``` Rust doesn't have a distinction between a type constructor and a data constructor, you declare them both with: ``` struct Constructor&lt;A, B&gt;(A, B);) ```
Everything in `&lt;&gt;` is introducing a parameter and optionally a restriction on that parameter. Everything in the `where` clause is a restriction on those parameters. [For example](https://doc.rust-lang.org/std/fs/fn.read.html), `pub fn read&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;Vec&lt;u8&gt;&gt;` `P: AsRef&lt;Path&gt;(path: P)` means that it takes a single paremeter of any type that implements `AsRef&lt;Path&gt;`. If you go to the [`AsRef` page](https://doc.rust-lang.org/std/convert/trait.AsRef.html) and search "path", you get this list: impl AsRef&lt;Path&gt; for str impl AsRef&lt;Path&gt; for OsStr impl AsRef&lt;Path&gt; for OsString impl AsRef&lt;Path&gt; for Path impl AsRef&lt;Path&gt; for PathBuf impl AsRef&lt;Path&gt; for String so `read` takes any of those types, as well as anything that another crate introduces that also implements that trait.
I work for a company that develops deep packet inspection solutions. So basically network anomaly detection. The "main" program was gradually transformed to use Rust and replace C. We noticed a steep increase in all-around usability for programmers because manually allocated stuff is just gone and we don't have to worry about memory allocations anymore (e.g. going from a fixed "hashmap" of always 2GB to just using Rusts Hashmap (with the previous hashing algo to keep things backwards compatible)). Also, when rewriting most network protocol detectors, we noticed more often than not, that the original C detector did actually not work correctly or at all, or it was flawed with off by one memory access and such things. All this went away by using honggfuzz and basic unit tests (which were just not there in C before... urgh). Off to a new product we're developing. I can't say much about it but let's just say it allows for swarms-monitoring. So basically our first product but smaller and a separate collector unit, that gathers data from all nodes. Right from the start: Rust. Every component can be run separately in a docker container and everything runs blazingly fast even on smaller hardware and is just fun to develop. The main component though is really nice. We're basically allowing on-the-fly policy exchange/updates on the swarm nodes by using WebAssembly. Such a policy can contain stuff like "we saw 5 bad ssh logins, what do we do?" And them being WebAssembly allows so much more than just pushing a config file. We can actually push real-time code updates and such and it's just amazing to do this so easily. Anyway. That's just a small insight in what I use Rust for. Additionally I'd like to mention clippy, rustfmt and all the other wonderful tools being developed. They help keep code consistent and clean. The C mess we had before was just a nightmare when I started but now visiting C land has me saying all the time "I'm going to replace you, and you - and yes don't you worry over there, you too!" And no matter how bad the "translation" to Rust, we have only seen performance increases. (Funny side story: after slowly converting everything to Rust the separate web interface, written in Go, could not keep up with the back end anymore (we went from C: 280 Mbps to 1100 Mbps) and we're having problems with not being able to aggregate and store data fast enough.) I'm sure there are hurdles when transitioning but once you overcome - or automate - the early problems, things are so much easier. If you have any more questions, ask away, but I can't be too specific. I'm not even sure if the newest product is even public yet haha.
May I suggest you read the entire book from the beginning? Not everyone prefers to read it that way, but if learning from examples is giving you trouble, the structured approach of the book sounds like the next thing to try.
Yay, more macro improvements.
Yes I think this is the best thing to do.
I created an issue: https://github.com/jplatte/js_int/issues/9
Very cool! Thanks for the response. I glad to hear your migration to Rust is going well. If you don't mind, I just have a few questions I'd like to ask. * How did your coworkers respond when Rust was first proposed? Was there push back? * Did you encounter any objections or push back from management or higher ups? * Did you encounter any difficulties or obstacles within your development process as a result of moving to Rust? * Did you find anything missing from Rust's standard library or third party libraries for what you were working on? * Overall, how did you find the Rust landscape in terms development tooling and infrastructure? * How did you find Rust's API &amp; BPI compatibility with C and C++? Sorry to bombard you with questions. I just want to learn from others about their experience moving to Rust. Thanks!
Note that rocket's dependence on nightly has gotten better over time. It used to depend on esoteric parts of nightly that would change frequently, and cause applications to only work with a small window of nightly builds. More recently, the only parts of nightly it depends on are features that aren't changing much, and are on track to eventual stabilization, so changing nightly versions is less likely to break a build on account of rocket than it used to be.
A terminal text editor with windows-styled hotkeys (there are a ton of these out here but this is mostly for Rust practice).
Not to downplay this (because it's great, nice work!) but [the benchmark comparisons from the PR](https://perf.rust-lang.org/compare.html?start=254f2014954bd66da206232490824975c0c662f1&amp;end=a32e9743bda96ce085688c3e5819c6bb7d7c7dd3) show a 1-2% win for running `cargo check` on the crates that are included in the benchmark suite. The improvements are smaller on other benchmarks that do full compilation presumably because the codegen time dominates and this patch doesn't change that.
&gt; purely amazing Hehe
The [libudev crate is being used in Firefox](https://searchfox.org/mozilla-central/source/third_party/rust/libudev/Cargo.toml) for U2F support, FWIW. Firefox does have [a fork of libudev-sys](https://github.com/dcuddeback/libudev-sys/issues/1) to support loading it at runtime though.
Looks interesting! I think Rust still has room to grow in the binary parsing/serialization space. Have you looked at [scroll](https://github.com/m4b/scroll/)? It's my current favorite for doing this kind of thing (parsing/serializing binary data by writing out struct definitions derived from C structs).
Big table/Yarte time: \[209.95 us 210.40 us 210.87 us\] Big table/ramhorns time: \[240.64 ns 241.13 ns 241.61 ns\] &amp;#x200B; Teams/Yarte time: \[304.56 ns 309.07 ns 314.69 ns\] Teams/ramhorns time: \[685.72 ns 691.43 ns 699.43 ns\] &amp;#x200B; It is faster and in all cases. I comment your Merge Request, please update.
I'm *pretty sure* the release profile also prints `dbg!`s. I used `cargo install` which does a release build by default, I believe. I'm still having trouble with the mailing list. I'll DM you the details :).
So I'm basically on the right track, with the parameters/constructor distinction. :) To my untrained eye it looks like Rust has both limited(?) type constructors (the `type` items and maybe also `trait`? Or do traits fall into another category?) and various combined type and data constructors (`struct`, `enum`, `fn`) where the same syntax is used for defining both type of constructors. `Constructor&lt;A, B&gt;` produces a specific data type and also a specific function type for producing the data of that data type (loosely speaking, I guess, as the exact syntax and output depends on the context). Adding on the `(A, B)` part defines the data constructor parameters. Three in one! Or maybe even four in one, as Rust types can also function as modules (or name spaces) and pass their parameters on to their associated items. So comparing to Haskell it looks to me like Rust has a handful of specialized items for specific use cases, while Haskell seems more generic or abstract. I guess. I know almost nothing about Haskell.
Nah! An ICE in summer is always welcome ;) *Joking aside, I much prefer a compiler erroneously rejecting code, or crashing, to a compiler silently miscompiling code. THAT is scary.*
&gt; Forget leaks the memory, it doesn't deallocate it. Which difference do you make between *leaking* and *not deallocating*? I've always used the two terms interchangeably.
I'll just answer them in order if that's fine. \- the transition to Rust was already started when I started working there. It was my colleague who convinced the team and with the swarm project being Rust-only, even the Go people started learning Rust and it's always nice to see them getting better and better with each merge-request. Same situation for me when I had to edit Go code :D \- After Rust was used in the main project and management saw the resulting development speedup and performance improvements, there was basically no hesitation left for the new project. In the conference room when asked what language to use, they basically all looked at us back end guys and nodded :P \- I don't quite understand this question. The main project is still transitioning to Rust but all development related tools have been rewritten in Rust and even the C code is managed and compiled by Rust. It all feels like one huge toolbox and makes stuff very easy to work with. Of course this did not happen over night but the previous situation was much worse so I would not call this difficult or an obsticale at all. \- Luckily the area we're working on (backend, low level network inspection and such) is pretty good supported in the Rust ecosystem. Of course there are still things we'd love to use (e.g. Rust async instead of having to rely on things like Tokio) but things are improving daily and there is no Monday meeting in which I'm not suggesting some cool crates I found. Or I just open a new MR and show test results of improvements by using some crate. Thing is, you don't want to rely on too many crates. But that really depends on what you're doing. \- Development tools and infrastructure is a great topic and there's only one thing to say about it: for what we're doing, setting up our pipeline including docker container generation, Debian packages, rustfmt checks, clippy, fuzzing and long term testing was set up in about 4 hours. This should make it clear how easy this is to use. Of course we copied stuff from the main project but that's just one more positive point for Rust. Once you set everything up, using a similar pipeline for other projects is just copy&amp;paste and some tweaking. \- I can only talk about C as I have not used C++ before, but I'm assuming it is a similar situation. I have not done this before when I started in that company and it was a thing of beauty when moving code to Rust. At first we moved the logic, removed .c files and copied the functions in .h files to the corresponding Rust file that already has the logic. Now all that remains is basic functions setup and you're done. For example the main project had config parsing completely written from the ground up. We transfered that logic to Rust, replaced it with serde and all that remained were two functions, one reading the config and returning a pointer to store in C and the other one to free it again later. Then some more config specific functions that take that pointer and return whatever you wanted from within the "Rust-internal" struct. After fully transitioning everything all that C saw was a pointer and how to get data thanks to it. On the Rust side was all the logic that used the pointer, dereferenced it into a struct it can work with and then did its work, returning config values back to C. Oh and yes there's of course the C representation when moving C structs to Rust and vice-versa. Simply slap the annotation above the Rust-struct and have it look the same in C and you can seamlessly move it to both languages without having to worry too much. Of course you have to watch out when using Strings and other Rust-specific things but that's fine and part of having this dual-language approach. But it was such a nice feeling seeing MRs with +200 and -1300 lines and like 5 C related files being deleted while just one new Rust file was created. And I read somewhere, that this also works with Python I believe. There might even be a crate especially made for that purpose. And if not, I'm sure Python can talk to C, which then allows Rust to directly talk to Python by using that nice C-function approach I just described. I'm really sorry if I can't tell you too much about all this, as Rust has basically been all that I've ever written. (When I started in that company I have not written or even seen a single line of C but still translating it was easy :D)
honestly i don't see the point... as a way to learn "functional programming" you'd be much better served using another language. and doing pure functional programming (haskell style) in rust means denying it from most of its strong points while pressing on its weak points. If you're into that kind of stuff maybe look into ATS? ps: i put "functional programming" because the term is so overloaded these days...
Wrong subreddit
This library does not work as expected, the returned Strings are not correct, check your coverage.
&gt; fn functor_test&lt;F: Functor,A,B,C&gt;( &gt; functor: F, &gt; fun: impl Fn(A) -&gt; B, &gt; fun2: impl Fn(B) -&gt; C &gt; ) -&gt; &lt;F as Plug&lt;C&gt;&gt;::result_t &gt; where &gt; F: Plug&lt;A&gt; + Plug&lt;B&gt; + Plug&lt;C&gt; + Unplug&lt;A=A&gt;, &gt; &lt;F as Unplug&gt;::F: Plug&lt;A&gt; + Plug&lt;B&gt; + Plug&lt;C&gt; &gt; { &gt; let cmp = |x| fun2(fun(x)); &gt; Functor::map(cmp, functor) &gt; } &gt; &gt; [...] The function signature is a bit unwieldy again [...] Oh, really? --- Jokes aside, the Plug/Unplug/Concrete triad is genius. I also appreciate how simple the traits are!
Really? Do you have an example?
None. Those are synonyms. I think you misinterpreted my comment, which I just clarified.
Today, a programmer must develop a level of self-sufficiency with Rust that may not have been required with Python. The open source ecosystem doesn't have as much breadth nor depth as that of Python, so one must address the gaps. Also, single-author projects are common. You cannot expect an author to help answer anything more than basic questions. Consequently, you're going to need to know more about lower-level details than what may have come up in your workflow before.
Thanks for the answers! They are very helpful. I know everyone's experience is different, but your experience switching to Rust feels very reassuring.
I've been working on a quantum Monte Carlo library to practice my rust, see how well rust does in computational physics, and to improve my own understanding of QMC since in all likelihood it will be the subject of my thesis. This past week I introduced parallelism to variational optimization, which was \*incredibly\* easy using rayon. I'd expected it to take a few days to get it all working, instead it took me just an hour or two. Writing rust has been a joy; I just know that if I'd gone with C++ or Fortran I would have burnt out months ago.
Ask /r/playrust.
At my last job I replaced a very simple status/health check service for a data ingestion pipeline that was pinged a few 100k/s by a millions of IoT devices. It was originally written in Python and the bill alone for it was...a lot. Basically I just cribbed from the actix-web techempower "hello world" example and the infrastructure bill went down by ~80%. Didn't even get a raise at review time, smh.
&gt;Add initial completion inside macro calls Nice, the lack of that was annoying when I started learning Rust last week. My long delay to actually try it has paid off
I have a `Vec&lt;Vec&lt;usize&gt;&gt;`, and in a test I want to construct a `HashSet&lt;Vec&lt;usize&gt;&gt;` to check that there are no duplicate `Vec&lt;usize&gt;`s in the `Vec&lt;Vec&lt;usize&gt;&gt;`. My current method is to use `HashSet::from_iter(vec_of_vecs)`, but this appears to be slow. Is there a faster way to do this? I've tried allocating the `HashSet` up front with the approximate number of elements, then inserting the elements one by one, but that didn't seem to help.
Found a few of my packages (like 5 of them). Looks like a part of packaging the `resvg`. Which did not get into this release.
Oh gosh: "CP.9: Whenever feasible use tools to validate your concurrent code". &amp;#x200B; That would sell it for me if I was still doing full time C++ code. &amp;#x200B; [https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#cp9-whenever-feasible-use-tools-to-validate-your-concurrent-code](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#cp9-whenever-feasible-use-tools-to-validate-your-concurrent-code)
What is your work flow?
If I'm not mistaken, Haskell's `Void` type is the same as Rust's `!` (never) type. For some of the others: fn constant&lt;T, V&gt;(val: T) -&gt; impl FnOnce(V) -&gt; T { move |_| val } /// From what I can tell, Alternative is just a special case of Monoid /// (except for the some and many methods) /// The `alga` crate actually has a declaration of Monoid that could be used instead. trait Monoid { fn mappend(self, rhs: Self) -&gt; Self; fn identity() -&gt; Self; } Unfortunately, Rust's lack of higher kinded types or generic associated types make `Functor` and `Bifunctor` a bit more complex or less strict. A complete implementation of `Alternative` would suffer the same problems. trait Functor&lt;A, B&gt; { type Output; fn fmap(self, f: impl FnMut(A)-&gt;B) -&gt; Self::Output; fn substitute(self, val: B) -&gt; Self::Output where B: Clone { self.fmap(|_| val.clone()) } } trait Bifunctor&lt;A1, A2, B1, B2&gt; { type Output; fn bimap(self, f: impl FnMut(A1, A2) -&gt; (B1, B2)) -&gt; Self::Output; } There's also the question of how to handle `Fn` vs `FnMut` vs `FnOnce`.
Probably creating a `Arc&lt;Mutex&lt;Vec&lt;_&gt;&gt;` and passing clones of it to each thread? The `Arc` will reference count for ownership, and the `Mutex` will handle locking for concurrent access. If you have many more reads than writes, maybe `RwLock` instead of `Mutex`.
Looks like it’s in 1.35?
New to Rust and parsing in general. Been handwriting a parser over the last few weeks for the newly RFC’ed Concise Data Definition Language (CDDL). [spec](https://tools.ietf.org/html/rfc8610) ... https://github.com/anweiss/cddl. Also building a JSON validator into the library.
Nice job with the refactoring! Too bad you didn't get a raise or any recognition for it. You should have just refactored it without telling anyone and then used the other 80% of your infrastructure spending running crypto miners. Haha. Glad to hear it went well.
It was added in 1.35 (if you scroll up a little bit you would see the version it was released for).
Tidying up and adding documentation to my [bitap crate](https://github.com/heyimalex/bitap), which I just published last night. For those who don't know, [bitap](https://en.wikipedia.org/wiki/Bitap_algorithm) is an algorithm for fuzzy string search. Also, doing more research on highlighting matches appropriately.
Yeah it only got renamed in 1.36
AFAIK, 1.36 included some important fixes for the target and renamed it to `wasm32-wasi` from `wasm32-unknown-wasi`.
Hexyl is great !
With Ubuntu LTS shipping Rust 1.32 and Debian Stable shipping Rust 1.34.2, this unblocks a great deal of new safe abstractions like `as_bytes`/`from_bytes` even for people who want maximum compatibility. Yay!
This is really nice. I took a look at fd and I would imagine I'm gonna use it instead of find now. I always disliked find syntax, so fd feels like it's meant for me. Also the benchmarks are insanely (absurdly) impressive!
So, added or stabilized? Will I be able to use it on stable Rust? Given how experimental WASI is so far, it doesn't look that way.
I would stick with serving static files with nginx just because it had years of optimizations already.
I was so happy when I discovered pkgfile. It probably saved me countless hours of searching.
Nah. This is not idiomatic Rust, and you'd need to learn Rust first to be able to deal with the borrow checker, which is a large investment. Plus Rust doesn't even have tail recursion optimization. For learning FP in general I highly recommend learning Erlang. That's the language that's functional not "because we can", like Haskell, but because its brand of FP with extremely powerful pattern matching is actually way better for this particular domain. https://learnyousomeerlang.com/ is pretty great and it's free.
You could also sort the vector, de-duplicate it (via `Vec::dedup`) and compare lengths. If any vector got thrown out, there was a duplicate. Of course this is rather useless if you want to find out which vector was duplicated and I'm not 100% sure this is faster than a HashSet - it probably depends on the data.
If you're on GNOME and want a fast file manager that still meshes well with the desktop, try Pantheon Files from elementary OS: https://github.com/elementary/files
Are we trying to steal the JVM's "compile once run everywhere" concept?
I assume somebody was working towards packaging resvg if you found some crates of it's dependency tree. Probably it didn't get finished before the freeze in January. Whenever a new package gets added to the repository, it needs to be approved by the ftpmasters team, because they take a closer look to ensure a certain level of quality. This can of course take some time. The same is valid if an existing package gets an update that builds an additional binary package that wasn't present before. This is the case when a feature gets added to a crate. So these may be the reasons why it wasn't finished before the freeze. I am sure whoever of the team members started working on it, will continue to do so. We have several packages that we would have loved to finish, but didn't get ready in time.
Perhaps use a `BTreeSet` instead of a `HashSet`? With a `HashSet`, you might be spending a lot of time hashing each `Vec`. A `BTreeSet` uses `Ord` to compare elements. For `Vec`s/slices, it [first compares lengths, and then elements until it finds a mismatch](https://doc.rust-lang.org/src/core/slice/mod.rs.html#5278). If you expect the `Vec`s to usually be different, and of a variety of lengths, this might be more efficient.
I have several questions about WASI target: - WASI is defined in terms of [Core API](https://github.com/WebAssembly/WASI/blob/master/design/WASI-core.md), but I don't quite understand the part about "wasi_unstable". Does it mean that it's not recommended to link to functions directly like it's [done](https://github.com/rust-lang/libc/blob/master/src/wasi.rs#L1054) in `libc`? - Why Core API is defined in `libc` instead of a separate crate, like `cloudabi` or Fuchsia crates? It's a bit strange to use `libc` for a target which, well, is not defined in terms of libc. - Do we have good examples of integrating WASI runtime into applications?
This is a wonderful little thing! Thank you for sharing :)
Working example: [https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=de0d89c5c419530dfa0e5d15727de119](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=de0d89c5c419530dfa0e5d15727de119)
With a name like this expected a cute-but-weird logo!
Haha. That’s still a WIP. ;)
Note, it's only initial version. It should work better when experimental macro expansion engine is enabled. And it will work even better after [https://github.com/intellij-rust/intellij-rust/pull/4094](https://github.com/intellij-rust/intellij-rust/pull/4094)
I really appreciate the suggestion, I'll try to point this out to IT.
This worked like a charm, thanks for reminding me about `dedup`.
That’s a good point. I assumed things added to stable are “stabilized” but maybe that’s not the case for compiler targets. If I’m wrong about that someone please fix the topic title in case people get the wrong idea...
Working on cloning a certain game using vulkano, glfw, and Rust. I've been working on it over weekends for about a month now. Next steps are moving the view around (for which I've already done most of the legwork), and drawing sprites to the screen efficiently. Oh, and adding layers to maps, but that's super easy. https://streamable.com/66ck9
Ahh, I originally found it from its mention here: https://github.com/CraneStation/wasi
I continue to be blown away by the performance of ripgrep, and I have used it daily for months. RIP grep indeed.
100% agree. i should set up aliases to these tools b/c i almost always prefer them nowadays
Pan-fried ground beef?
[https://doc.rust-lang.org/std/fs/fn.write.html](https://doc.rust-lang.org/std/fs/fn.write.html) The first parameter can be anything implementing `AsRef&lt;Path&gt;`, which includes `str`, `String`, `OsStr`, `Path`, and `PathBuf`. The second parameter can be anything implementing `AsRef&lt;[u8]&gt;`, which includes `[u8]`, `[u8; n]`, `Vec&lt;u8&gt;`, `str` and `String`. You can use a similar hack to achieve something resembling a variadic function call. Have the caller provide some of its arguments as a tuple, and then implement a trait (say, `IntoAdditionalArguments`) for tuples of various sizes. The only language feature we'd need for true variadic functions would be the ability to pack any number of trailing arguments into a tuple.
Yes, but I wouldn't call it “stealing”, since this concept isn't unique to the JVM, AFAIK.
No, we just borrow it mutably.
So now Java has to stop development? That seems kind of rude.
I don't think the number of dependencies is good metric. Total lines of code of dependencies would be better.
I like that, but I"m concerned about battle-testing. I'm going to try it out in some medium-importance projects next time. :)
Good god, no! They just need to leave their "compile once run everywhere" concept as it is for a while. Trust us, it's for the best...
Is this used for `rustc` binaries from rustup?
It’s embarrassing that I just now realized that `ripgrep` = RIP grep.
Most languages have already picked up the useful parts of functional programming (lambda, immutability, first class functions, partial application) and shed the non useful things (recursion as the main way to do things, lists as the main data structure, unusably dense type level concepts). I just don't see the point in making an FPL crate.
It is a good metric, because each dependency comes with its own set of overhead. Maintenance status, documentation quality, MSRV policy and more.
Note that that was not why I named it: https://github.com/BurntSushi/ripgrep/blob/master/FAQ.md#intentcountsforsomething
Voting this exchange as quote of the week for TWiR.
It's really interesting and I've never heard of it, but still it isn't exactly what I was looking for, because it isn't as flexible as a parser combinator, and I needed that kind of flexibility.
Isn't it all abstracted away? As a user of X, I don't necessarily care about documentation of a dependency of X. That's the X's maintainer problem (in theory at least). I only care if X is doing it's job, and if I can trust it. Which is kind of a LoC thing if I was to review it. I guess ... in practice it's not exactly like that, but especially if the maintainer would be the same, then I don't care. I guess both of these metrics are useful.
I wonder how does that work (?) how are they compiling the compiler with const\_generics if the compiler is not stable with them yet?
I'm trying to be terse here, because I just don't see how much we're going to get out of this. Quality documentation is, in my experience, a strong signal that is heavily correlated with quality of implementation, among other things. Besides, docs aren't the only thing I mentioned. I've had to go out and file issues against transitive dependencies several times. That's much easier to do when the maintenance status of the crate is favorable.
been using exa on Ubuntu for a while, love it!
[removed]
It's rust programming language reddit not rust game's.
Oh god dammit XD I’ll remove it
You should not ever do anything that blocks a task (future). You should hand off anything blocking to a threadpool, or, if you're using the default tokio runtime (not the single threaded runtime) simply wrap anything that can block in a `blocking` call. use tokio; use tokio_threadpool::blocking; use std::thread; use std::time::Duration; use futures::future::{Future, poll_fn}; fn main() { let fut1 = poll_fn(move || { blocking(|| { thread::sleep(Duration::from_millis(500)); println!("fut1 done"); Ok(()) }) }).then(|res| res.expect("the threadpool shut down")); let fut2 = poll_fn(move || { blocking(|| { thread::sleep(Duration::from_millis(1000)); println!("fut2 done"); Ok(()) }) }).then(|res| res.expect("the threadpool shut down")); let joined = fut1.join(fut2).map(|_| ()); tokio::run(joined); }
Not true at all. Maybe pure functional point free style is pointless, but the best Rust code I see is using filters and maps and other functional style
r/playrust
&gt; And them being WebAssembly allows so much more than just pushing a config file. We can actually push real-time code updates and such and it's just amazing to do this so easily. Would you be so kind to elaborate on this? This sounds extremely useful, and something I've been looking into for a project of mine that will have "plugins" which needs to be both added (new ones) and updated very frequently. However, I haven't found a suitable solution to this problem yet but your comment intrigued me, as it describes pretty much exactly what I need.
You can also use arp (address resolution protocol) and the arp command to lookup the ip address by mac address. arp -a | grep -i "your:mac:address"
This is really wonderful, but it seems there must be more to it than what is in this post, as `rustc` doesn't accept it: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=da53bdb23fb15774ad2f72c175d74a8d
I also find it ironic that the year the JDK drops applet support is the year browsers gain WASM support. Same sh-dubious concept if you ask me...
You are wrong on more than 1 level.
This time it's running in a VM that has had decades of security fixes, though.
yes, actix-web 1.0.2 (or 1.0.3?) was a breaking change lol
Ah, interesting. Why is this allowed but not the way I have it implemented (after fixing the errors, obv)?
Firstly, the 'type' keyword in Rust just creates an alias (in it's implementation the compiler literally just replaces one with the other). And traits declare constraints, basically, like if I say: ``` trait Foo { fn baz(); } ``` and &lt;T: Foo&gt; I'm saying that my type param T is bounded by Foo (T must implement Foo). You can't use a trait name in place of a type in most cases, it's not a constructor for types, it's a constructor for a constraint. In Haskell this is synonymous with typeclasses. &gt; and various combined type and data constructors (struct, enum, fn) fn is a keyword for declaring a function, it's not a type or data constructor. &gt; So comparing to Haskell it looks to me like Rust has a handful of specialized items for specific use cases, while Haskell seems more generic or abstract. Haskell does indeed enable more generic representations in it's type language. It's a great language to learn in that once you get the majority of features available in Haskell, there will be almost no language feature you can encounter that will surprise you. You'll have seen some variation of almost everything before, with the exception of perhaps the borrow checker (which Haskell is now getting in the form of linear types).
I haven't used it but I imagine it's more oriented for games. I suppose it's worth a try but theming it is going to be much more difficult compared to GTK, especially given the hundreds of high quality GTK themes there are out there. Also it won't look native *even on* Linux.
I mean, you’re not wrong, but javascript is also a dubious bytecode that runs in a vm. WASM doesn’t make the situation worse since it doesn’t give the VM any new superpowers that js doesn’t have.
I'm really sorry that I can't tell you more about this. I did not work on that part of the project so far and have not seen the code for it. I'm working on the data collector. But, as far as I know, the base policies get compiled at the same time as the node controller itself to deliver "baseline policies". I imagine all you need is a WebAssembly executor? I'll look it up right now and if I find something useful, I'll report back. Though I do not think that WebAssembly is that good for plugins. WebAssembly has some severe limits.
So I quickly looked at our policy engine and yes, we're using an executor: [https://crates.io/crates/wasmi](https://crates.io/crates/wasmi) I wish you all the best in your endeavour, but I also highly suggest looking at some scripting engines or embedding languages for Rust. For example [Dyon](https://crates.io/crates/dyon) or [Gluon](https://crates.io/crates/gluon).
Aren't we using it as just **rg** ?
The forge lists `wasm32-wasi` as Tier 2: https://forge.rust-lang.org/platform-support.html
I'm not really into Pokemon. ;-) This is really cool! What motivated your choice of libraries?
Is there a "standard" library for doing geospatial work with Rust? Specifically I'm looking for the ability to find the distance between two WGS84 points and other information such as the heading angle between them. In Python I've used [geopy](https://pypi.org/project/geopy/) and [geographiclib](https://pypi.org/project/geographiclib/). For Rust I found [google\_geocoding](https://docs.rs/crate/google_geocoding/0.1.1) which would probably work but I don't want to add an external API dependency to my program. There's also [geo](https://docs.rs/geo/0.12.2/geo/) and [geo-types](https://crates.io/crates/geo-types) which seem too low-level for what I'd like to do. Any other suggestions?
Thank you for getting back to me! I've only briefly looked into this subject, since this is far down the pipeline for this project and I don't want to spend too much time researching it right now. I've looked at embedded languages for Rust, but unfortunately they incur some limitations that I'm not comfortable adding. I'm going to do some thorough research and testing down the line, and hopefully share the experience and results. [Wasmer](https://github.com/wasmerio/wasmer), the [WASI extension](https://github.com/CraneStation/wasmtime/blob/master/docs/WASI-overview.md) and the ever-growing [list of languages/runtimes compiled to WebAssembly](https://github.com/appcypher/awesome-wasm-langs) looks interesting though!
lib.rs is the entry point to a library, which is implicitly a module. Mod is the keyword that declares a module. Modules can be sub modules of other modules.
Is it like in the matrix? You can connect a wire to my neck and then I can get up and say "I know Rust"? [Very nice, how much?](https://www.youtube.com/watch?v=7QT7bhJTkAs)
Right - my idea was that Runner's \`Drop\` impl could acquire the lock and clear the \`Vec\`, making it safe to share with the background thread. But I'm guessing there's still something horribly unsafe about that.
thanks for the pointers! I’m working with shared memory that’s being written to by a C++ application as a ring buffer so i’m pretty sure everything is laid out as i need. My only worry at this point is with bindgen itself as i found an error in its output (non-zero constants being set to zero instead). thanks again!
&gt; This restriction will be removed at that point :) So the [new docs](https://doc.rust-lang.org/nightly/std/primitive.array.html#implementations) would get even smaller? (All that extra `LengthAtMost32` near the bottom wouldn't be relevant?)
&gt;lib.rs is the entry point to a library so i should have it only one and add my modules into it? does my sample code valid? src/lib.rs ``` use MyModA; ``` src/Mods/MyModA ``` fn hi() { println!("hi"); } ```
 /src/MyModA.rs (And idiomatically it would be my_mod_a) Also, in main, you need the name of the library first; my_name::MyModA::hi();
where the "my\_name" comes from?
The name of your package
Scaling lichess.org, by [building a websocket server](https://github.com/niklasf/lila-websocket) that can handle a subset of responsibilities without hitting the (currently monolithic) main server.
you mean when i do cargo \`cargo new my\_name\` ?
&gt; on account of its sometimes-absurd CPU usage. While using it to navigate or just being open? How does the CPU usage impact the user here? Is it slowing something else down that is running or is nautilus itself not very responsive to user input/navigation? I haven't used it in years, having switched to KDE and enjoying Dolphin(which also has an embedded terminal pane you can bring up which syncs with the UI view, if you navigate in either pane the other ones location updates with it which is neat).
When is a terminal based file browser useful?(apart from when you're already in a terminal window and want to remain there, often because you're using other terminal tools such as vim for writing your code too). Is the main reason that it's fast and doesn't require a mouse?(not that you necessarily need to use a mouse with a GUI browser) I tend to just bring up a terminal window from the GUI browser(Dolphin in my case) and rarely need to navigate elsewhere in the terminal, else it's just a short `cd` command.
Yep!
The last chapter of *The Rust Programming Language* walks you through the [implementation of a multithreaded HTTP server](https://doc.rust-lang.org/book/ch20-00-final-project-a-web-server.html); have you looked at that? It might give you some insight into how you can build your server in an idiomatic way.
can we use \`use\` keyword to import it instead of starting with the package name? its very ugly if we must start with package name though
Absolutely!
correct me if im wrong main.rs ``` use MyModA; fn main() { MyModA::hi(); } ```
Im building a C interpreter as a way of learning rust and interpreters at the same time! https://github.com/Am3ra/C-Interpreter Honestly though, i'm a bit stuck. I need a way of creating a static set to check if an identifier is a reserved keyword or not, and the packages im seeing, i frankly either havent understood or liked, hahaha.
Hey! just as new to rust and to parsing in general, but i've been working on a C interpreter! What kind of problems have you run into? ([Check Out my interpreter so far if you want!](https://github.com/Am3ra/C-Interpreter))
Holy shit, really? I'm literally playing a match on there as we speak! Honestly, i've been looking for a way to contribute, but hadn't found the right page, love the service! omw to the irc, hahaha
do you mean this section ? [https://doc.rust-lang.org/book/ch20-02-multithreaded.html#a-worker-struct-responsible-for-sending-code-from-the-threadpool-to-a-thread](https://doc.rust-lang.org/book/ch20-02-multithreaded.html#a-worker-struct-responsible-for-sending-code-from-the-threadpool-to-a-thread)
Looking at all the issues described in this thread, is there any benefit to having something like libusb ported to Rust?(just needs to export an equivalent C API to be compatible replacement like other projects have done?) Or is libusb by itself not enough?
 use my_name::MyModA; But otherwise yes.
oh sorry, yea, i meant with the package name in use :) . thanks a lot
That I agree with.
The compiler cheats, basically. It’s allowed to, because it’s the compiler.
Is there a curated list somewhere for these kind of JS focused crates? I've seen a few around lately but unless I note them down I don't know if I'll remember how to find them again. Your crate for example doesn't have any keywords assigned that'd really link it to javascript.
&gt; positions on a discrete grid This is a really good one, but... if you assume up-front that all coordinates must be within range of an i32 or an i64, or in fact any other *a priori* bounded set (i.e., it's not an infinite grid), then you can just start in the middle with 2^31 or 2^63 or whatever and use unsigned. And the condition indeed holds for games. Now, I think coordinate *offsets* are a use case, if you're using them for something other than distance calculation (where sign doesn't matter).
&gt; I just don't see how much we're going to get out of this I'm specifically thinking about `cargo-crev` here and how to use this to help people to make decisions about which dependencies to use, so I appreciate your input. Just to make sure we're still talking about the same thing: I'm talking about "number of dependencies" vs "number of lines of code of dependencies (recursively)" (`LoCR`?) as a metric. Just because code from a dependency was inlined into a crate (or opposite: split into a separate crate) does not change that much, IMO - that's my argument. Just because someone used `hex` crate, instead of rolling their own `to_hex` is not decreasing quality - quite the opposite, very often it means having more, less-tested code. That's why I don't think metrics should punish crates that reuse other crates and therefore have more dependencies. On the other hand - any code - no matter if from dependency, transitive dependency or from our own crate is more directly corresponding to complexity and general... "burden" we (as a developer) have to deal with. That's why it seems to me that for very rough estimation of what are we really pulling in by including a given crate, it would be better to talk about total lines of code of it and all its dependencies. It's better to 10 small (lets say 50-lines each) dependencies, than 2 but 20k LoC each. Generally. Obviously both metrics are blind to all the important nuances like code quality, documentation, ownership etc. But LoCR But when I think about `cargo-crev`: it's actually really easy to review 200-lines utility/quality of life crates . So LoCR seems a better metric, and I think I'm going to eventually add it to the user interface. I might add a whole new feature that would compare alternative crates by their sheer "weight" (in LoCR), maybe even discounting lines of code from dependencies that we already have reviewed or something.
Right, sorry, here are the impls for `Concrete`: impl&lt;M:Plug&lt;A&gt;+Plug&lt;B&gt;+Unplug,A,B&gt; Plug&lt;B&gt; for Concrete&lt;M,A&gt; { type result_t = Concrete&lt;M,B&gt;; } impl&lt;M:Plug&lt;A&gt;+Unplug,A&gt; Unplug for Concrete&lt;M,A&gt; { type F = M; type A = A; }
All statically typed languages with expressive type systems have this "feature": rust, Haskell, Scala, ocaml, f#, etc. I'm currently in the middle of a large Scala refactor and had to comment to coworkers just how much the compile static types and compiler act as a warm blanket, letting me know that I haven't missed anything. And, even better is when I start to refactor, make a change, and get an error in a completely unexpected place in the code base I hadn't yet been exposed to that stops me in my tracks and makes me start to rethink the refactor.
Fast for sure, uses less memory. Less distracting for me. I just have a bunch of terminals open in my wm and I try to do as much as possible with those. The only non terminal I have open normally is Firefox.
 trait OverloadedCreate&lt;A,B&gt; { fn overloaded_create(&amp;self, first_arg:A, second_arg:B); } In your implementation just call this trait. impl MyStuct { fn create&lt;A,B&gt;(&amp;self, first_arg:A, second_arg:B) where Self: OverloadedCreate&lt;A,B&gt; { self.overloaded_create(first_arg, second_arg) } } Then just implement that trait for whatever overloading you want. i.e. impl OverloadedCreate&lt;f64,f64&gt; for MyStruct { fn overloaded_create(&amp;self, first_arg: f64, second_argument: f64) { // foo(f64, f64) will call this } } impl OverloadedCreate&lt;i32, &amp;Vec&lt;u8&gt;&gt; for MyStruct { fn overloaded_create(&amp;self, first_arg: i32, second_argument: &amp;Vec&lt;u8&gt;) { // foo(i32, &amp;Vec&lt;u8&gt;) will call this instead } }
[Warp](https://github.com/seanmonstar/warp) is worth checking out. The `Filter` system can be used quite decoratively. [todo example](https://github.com/seanmonstar/warp/blob/master/examples/todos.rs)
[Warp](https://github.com/seanmonstar/warp) is worth checking out. The `Filter` system can be used quite declaratively. [todo example](https://github.com/seanmonstar/warp/blob/master/examples/todos.rs)
that's a pretty low bar for functional programming.
as far as i know, rust doesn't do TCO
Well, that's probably the part that is the most relevant to the specific questions you're asking here, but I really meant the entirety of chapter 20. It sounds like the issues you're having are because you're trying to translate another language's solutions into Rust, which is going to cause you pain because Rust disallows (or makes very difficult) lots of patterns that other languages support. (See [Learn Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/) for example. A doubly-linked list is super easy in most languages, but in Rust you either have to "fight the borrow checker" with `Rc&lt;RefCell&lt;_&gt;&gt;` or dive into `unsafe`.) It's going to be much easier in the long run to do things in a more Rust-y way so that you don't have to bend over backwards to satisfy the compiler. That's why I suggested that chapter. The book does a good job showing idiomatic code and explaining why it's good to write it that way; if you use their server as a starting place for yours, it will probably go a lot smoother.
Elm. Haskell. Probably OCaml as well. Golang is all-right, but nowhere near the level of type-assistance you can get from the other languages.
and then some C++ senior in says: "show me"
&gt; Veloren is a multiplayer voxel RPG written in Rust. It is inspired by games such as Cube World, Legend of Zelda: Breath of the Wild, Dwarf Fortress and Minecraft. - [Veloren: An Owner's Manual](https://book.veloren.net/introduction/index.html)
Would you consider dual licensing under MIT/ASL2? That way it would more closely match the rest of the Rust ecosystem.
&gt; you're trying to translate another language's solutions into Rust, yes because i am new to Rust. &gt; It's going to be much easier in the long run to do things in a more Rust-y way that's why im asking for this, coz i wanna learn Rust in Rust-y way &gt; That's why I suggested that chapter Thanks i will read the chapter. i think it does what i need..
I find refactoring to work out nicest in statically typed languages with great IDE support. C#, Java and Kotlin would be the first picks here. Renaming things and moving things around via IDE support can save a lot of time and avoid errors. The most important non-language feature which enables refactoring is that the project needs to have the right amount of tests. None or not enough and new errors can easily be introduced. Too many or too low-level tests and fixing the test-suite will take most of the time.
Rust seems like it will always be fairly clunky compared to languages like Haskell for pure functional style programming, even if it can be done. But I'm definitely interested to see any efforts in this direction. There are a lot of neat features in Haskell. Seeing these things implemented in Rust would at least be a neat demonstration of Rust's capabilities, and perhaps certain concepts could be integrated with idiomatic Rust in some useful manner.
It sounds like what you're looking for is a variant of the "phantom type" trick where you have a type associated with a datatype that contains no values of that type. It also sounds like you would like to use what in Haskell would be type level literals. I suspect that declaring zero-size structs to represent each server a node can talk to and then parameterizing your node type by those struct types will work, but I can't test it out right now. Also, another use for this kind of technique is when dealing with multiple currencies in your code.
Yup, that _and_ fewer bounds in the impls that are still there.
Thanks, I'm familiar with phantom types, and believe that if this were to be implemented as syntactic sugar of some sort they would certainly play a part, in fact here's a half implementation of the feature provided by a friend of mine, the issue being that new "Marker" structs can't be created on calls to new, and also you sort of have to manually keep track of them to use libraries which use this feature. use std::marker::PhantomData; #[derive(Debug)] struct Graph&lt;N&gt; { _p: PhantomData&lt;N&gt;, } impl&lt;N&gt; Graph&lt;N&gt; { fn new() -&gt; Graph&lt;N&gt; { Graph { _p: PhantomData } } fn clone(&amp;self) -&gt; Graph&lt;N&gt; { Graph { _p: PhantomData } } fn add(&amp;self, _other: Graph&lt;N&gt;) -&gt; Graph&lt;N&gt; { Graph { _p: PhantomData } } } struct Marker1; struct Marker2; // ideally these would be automatically generated for each call to `new` fn main() { let g1 = &lt;Graph&lt;Marker1&gt;&gt;::new(); let g2 = &lt;Graph&lt;Marker2&gt;&gt;::new(); // g1.add(g2); -- error g1.add(g1.clone()); // ok g2.add(g2.clone()); // ok } Yes, currencies and physical units would be a good use case, I hadn't considered that!
That happens because Vulkan and OpenGL have inverted Y-axes. You need to invert the Y coordinate when using wgpu.
Wow! Not only the wrong subreddit - also _against the ToS_! Classy.
Electron has some issues I'll admit, but I wouldn't say it deserves hatred. Just because it allows you to build software using web technologies doesn't mean it's not a good solution. In fact, Visual Studio Code, Spotify, GitHub Desktop, Skype, Discord, Slack, and more are all Electron apps. Atom is also and Electron app yet is far slower than Code despite Code being written in JavaScript. Code is the Pinnacle of Electron Typescript applications and shows you that it all comes down to knowing how to code for performance. GitHub Atom is where Electron originated from, and remains far slower than Microsoft's Visual Studio Code. Electron, when done correctly is a proper way vastly superior to other methods involving web technologies. And with GraphQL, React, Angular, and other web technologies taking the top, it's reasonable to build with Electron. These technologies were built with a purpose. Speed, configuration, and simplicity. We're constantly iterating because we're focused on our users. Unlike software, our solutions require internet, and not everyone has fast internet. So we're the best at squeezing performance out of our code unlike native solutions who, despite catching up with the times, still lack decent documentation, have a steep learning curve, and a very wide range of standards depending on the platform being developed. We do have many ways of doing things, but most of us follow the same standards and stay up to date.
Why do you keep saying it's not proper? Electron is hugely popular, so it must be doing something right... although I'd never use it. Why must the gui of an app use the native apis? I have always written my using opengl so they look the same on every platform.
This seems like it could be unsound - what if I were to do this on a `Vec`, or an `Arc`? Or is that alright since I have to own that value?
Pushrod 0.3.7 was released, which is the last release in the 0.3.x branch. I'm working on 0.4.x, which will be the beginnings of another awesome project, using the Pushrod lib. Things are about to get "real" :D
Try asking /r/playrust
Then please nominate it on [rust-users](https://users.rust-lang.org/t/twir-quote-of-the-week/328/663).
You can certainly use JavaFX. Check projects like NativeFX and OpenJFX for cases.
thanks for posting. one question I have is: my understanding is, "futures" and "async/await" are just concepts, and you need to bring your own executor (e.x. tokio) to actually have an engine that will dispatch and poll futures and do lots of work. so what I'm wondering is, what if I don't supply/specify one, and I invoke "await" on an async future. what happens, who is doing the polling? I think I'm missing a big piece of the puzzle that will be very obvious and make me say "duh". Hopefully someone here can give it to me :)
I work on embedded devices, and recently wrote a non-trivial component in Rust. Less than a year ago, a similar component for another device was written (not by me) in C++ and it was plagued with problems for a long time. The Rust one has been far superior in every way. I suspect all new code will be written in Rust, and in time, old code will get ported. As for challenges, getting risk averse team members to use Rust can prove difficult unless they believe the benefits will out-weigh the risks - learning curve, new language, etc... Many crates that you may want to use have not reached 1.0 yet, which means they could break their APIs in the future. But in practice this isn't a big issue because Cargo gives you granular control of dependency versions. Compile/link times can be ridiculously slow, especially if you have link-time optimizations on. IDEA/IntelliJ based editors have pretty good Rust support. All other editors rely on RLS and/or Rust-Analyzer for their language support, and they're mediocre at best, but improving. Also, some common architectural designs don't translate well into Rust. This is part of the learning curve and can take some time to learn new approaches. I don't recall any real technical obstacles. Rust has proven itself as a great asset to us.
You need this trick from haskell's ST monad. It is not possible without HKT though.
It looks like the `ManuallyDrop` type in the crate doesn't impede `Drop`, and combined with `MaybeUninit::uninit()` not requiring `unsafe`, I believe it'd be UB in "safe rust" if the user wrote `MaybeUninit::&lt;Vec&lt;u8&gt;&gt;::uninit()`.
Typo: the inherent method example is missing the self argument.
I think of Rust as an alternative to FP. FP looks at mutability, shudders, and decides to forbid it, finding other ways to express solutions to problems. Rust looks at mutability, digs in, and makes it safe. It borrows many of the powerful idioms from FP, like iterator chains, pattern matching, and a reasonably complete type system, and permits mutability, safely, even across threads. Rust is different. It doesn’t need to be Haskell. It’s Rust.
A while ago I had worked on a similar project in Java + Slick2D. It didn't perform very well, and needed access to shaders for certain effects. I played around with some ideas on ShaderToy and realized I knew enough about rendering that I could probably write a simple rendering engine for this project. I've been playing around with Rust quite a bit in the past year and I've loved it, so that was a natural choice. I experimented with a bunch of game and windowing libraries, but most had some critical flaw. - `gtk-rs` doesn't yet support OpenGL contexts. - `winit` doesn't render the window correctly on Wayland (Gnome at least) - Amethyst and Piston use `winit` - `glutin`, I don't remember what was "wrong" with it. It might also use `winit`. I think `glfw-rs` was the only one I was happy with. Then I picked Vulkan over OpenGL because I like shiny things. Vulkano was the natural choice for that. There were no guides for getting those two working together, and only one [out of date library](https://crates.io/crates/vulkano-glfw) for using them together. I dug through the source code of that to see how it worked, and got it working on the latest vulkano release. From there it's been pretty smooth sailing.
I'll need to read HKT more closely, and ST as well. I may follow up later. Thanks!
the problem here is im not looking for a solution, i am looking for GUI framework which obviously electron is not GUI framework but some how some people are suggesting it, idk why
It's visible in one of the examples and obvious to those involved, but one thing that's being enabled is having async non-static methods (or, more generally, lifetime parameters). While one could use combinators before, it sometimes required a lot of cloning or otherwise awkward code.
one of the reason i choose Rust is its running speed if i look for any solution without concern about the performance, i never even start system programming and do the web programming with web technologies, right? Also, i never asked for any solution which is easier and faster and painless in the market, rather i asked for GUI framework in the title. Anyway thanks for sharing your thoughts though
Sorry for the long explanation. As far as GUIs go, React and Angular are your best choice for simplicity sake. Using NPM you'll find hundreds of libraries allowing you to quickly build up the GUIs you'd like. Especially with Bootstrap I'd look into that. Material UI is also interesting. We normally use these for building dashboards for administration portals, but I believe it's similar to what you're looking for. CSS will allow you to add the cool gradient effects and text colors with literally 4 simple lines of code.
I know almost nothing about rust futures, but intuitively I would think that only async functions can use await, and main can't be async, so it's not really possible to express the weird thing.
"I make the rules. This is my world, you just live in it." -- Rust Compiler
That's right. Using `.await` in a non `async` fn will just produce an error. And using `await` in an `async fn` will just work. Calling that function from somewhere else then produces a `Future` which must be polled and/or `.await`ed.
I don't know of a way of impeding Drop without using ManuallyDrop. If you know of one, please tell me :). As for exposing UB in safe Rust, you definitely have a point :). Not sure how to fix it.
Thanks for your reply, but this doesn't really solve my problem. What I was asking about was how to do inter-task communication properly, I provided blocking as a theoretical example of "if something goes wrong". It really might be the case, because my web service has to send tons of data, on my machine it takes roughly ~60-150 milliseconds for some routes to respond. And yes, I tried benchmarking, streamed response body is not a solution - in fact, it makes the whole thing significantly slower.
Try it :p. I think too many people are looking at the Future trait as language magic and assume that there are strict rules to be followed and it must be done a certain way. But if there is a use case for it, just wrap the poll function in a loop and break when it returns `Poll::Ready`, no 'executor' needed. However for most use cases that is not what you want. You're looking to maximize performance of the system by sleeping the task until the future, when polled, will return with Ready. But how is this done? Well it's neither the task or executor who can figure out when the future will return ready, it's the object that implements the Future trait that does this. So the executor sets up a waker, essentially just a function that wakes the task doing the polling, and provides it as part of the passed context of the poll function. Now await can be used to poll the future. Await acts very similar to the basic loop I mentioned early, but it now can yeild (sleep) the task when the poll function returns `Poll::Pending` tanks to the executor. The object that implemented the future will call the wake function (that was implemented by the executor) to wake the task when its ready. The await will loop back again *and should be gaurenteed to receive `Poll::Ready`* from calling the poll method.
I can't test it, but can you use a closure as an unique marker type?
The futures package does provide a couple of executors, eg ThreadPool. But Tokio provides the most functional executor with all the extra bells and whistles, eg timers.
Last time I checked, hyper with futures-fs had better throughput than nginx at serving large files.
At least at first it looks like that works... [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9eac45147db0d82d540133d68b23600c) I'm going to make sure this works for my use cases, but it's promising given the note: &gt; = note: expected type Graph&lt;[closure@src/main.rs:23:25: 23:30]&gt; &gt; found type Graph&lt;[closure@src/main.rs:24:25: 24:30]&gt; &gt; &gt; = note: no two closures, even if identical, have the same type I remembered hearing that this is sort of how lambdas worked in C++ but forgot it could apply to rust too. Thanks!
By some definitions of FP, C++ can be used for functional programming.
Yeah, I think I first saw this idiom in C++. If course, you can use a macro to avoid having to write the closures every time you create a value.
I have a program that evaluates trees, and I'm caching the results of functions in a hash map so I don't end up re-evaluating the same sub-trees over and over. I'd also like to not have to hash the same tree every time I want to look it up in the map. If I get a tree's hash value once when it's created, set that as a field on the tree, and manually implement the Hash trait so that it just returns that field without doing any calculating, will that get me the behavior I'm looking for or am I setting up a footgun? Do I also need to make a dummy type that implements Hasher that just does nothing? Thanks for any help.
TLDR Serving assets using your "Rust Only Server" is not a problem at scale if it has a proper Http header, and a good packaging. -- Static files should have http caching (Cache-Control header), and be behind a reverse proxy/cache such as varnish. (Nginx can also be used) Cached assets have a hash in the name to avoid caching invalidation. So the tool you need is an "asset packager", like this: https://github.com/sindresorhus/gulp-rev/blob/master/readme.md Others tools exists, maybe in rust too... See also: https://12factor.net/processes
If it counts for anything, I assumed that rip was as in fast and, not as in rest in peace.
I think you need to properly think about why you consider something "not a proper way".
Nautilus is not being used to navigate, and there are no obvious windows that would be using it open but a nautilus process is running. Nautilus is consuming up to 70% of an older desktop's CPU (sample duration 1s), and its spikes in CPU are tightly correlated with UI lag in data visualization software. It could totally be that Nautilus isn't the root cause, but _a file browser_ shouldn't be causing that level of CPU usage.
This is called existential types, generative types, or just generativity. It is possible to do this in rust but not recommend. There is only one construct in rust which allows for type generativity: higher ranked trait bounds. You can see this in action [here] (https://github.com/Gankro/thesis/blob/master/thesis.pdfl)
I work in a hedge fund and we are moving most of our computation intensive algorithms from python to rust. **The company is very small** so it was very easy to convince people to have a try with rust. Basically, I rewrote one of those tool and it went from 15min to 70ms. This is a game changer: instead of relying on bask testing data, we can just generate said data on the fly (after wrapping all of it for python using py03)! It allows traders to test much more different scenarii than before. Granted, even if some time has been spent on optimizing the python code it could still be made faster. One the other hand I didn't spend much time in optimizing the rust part (is it not even multithreaded!). Today, developers are using rust for backend intensive work and traders want to learn it too.
I think this is sometimes called "generativity" and it is possible with lifetimes and higher-ranked trait bounds. For instance, https://docs.rs/indexing uses it to tag that in-bounds indices are associated with a specific slice, and so allow indexing without bounds checks. This doesn't work with closures as well as with lifetimes, because one can create multiple instances of a specific closure type via a loop or recursion. This allows "crossing" unrelated values, incorrectly. The key that makes lifetimes work is that they're supported in higher-ranked trait bounds (basically what Haskell's `ST` uses), but types are not.
BigInt is also available in Firefox: https://wingolog.org/archives/2019/05/23/bigint-shipping-in-firefox.
The ST type uses higher-ranked types, not higher-kinded ones, which Rust does support for lifetimes. Specifically, HKT is needed for the monadic abstraction, but not for the core `forall s.` that keeps the state contained.
Using closures doesn't really work: [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=08ac01833153406671d604554dbe8f99)
On nightly so far.
&gt;Electron is hugely popular, so it must be doing something right... Keeping RAM manufacturers in the green.
My definition of FP is basically what Haskell is doing (pure functional programming, basically). Nevertheless, I disagree with this: &gt; Maybe pure functional point free style is pointless Point free style helps on chaining computations and eases seeing how things compose without too much noise (i.e. lambda notation, mostly).
The `Fn` vs. `FnMut` vs. `FnOnce` is a real issue, and I wish we had a way to manipulate mutability in a more controlled way; I completely agree!
Yeah, this seems to be entirely bypassing the compiler's enforcement that `drop` must be run. Seems like it should require `unsafe` to use at the very least.
In Rust, Hashes can be randomized, meaning that the same object will have different hashes depending on where it is used. So yes, it's a footgun. If you know that your tree is immutable, you could assign a globally unique id to each node. The hash of a node could just be the result of hashing that id. If you hash only the globally unique id, you have to be careful not to modify the underlying data, otherwise you might get incorrect results. If your data is mutable in any way, you will have to hash the entire tree each time to make sure the data is correct. If you know you have to evaluate every node in the tree, you could create a `map` function that returns a tree with the same structure as the original, but contains the results of evaluation for each node. You could then access the results of any node using that same way you access it in the original tree.
Wow, gtk-rs crates, process-viewer and sysinfo. That's quite a lot of crates of mine. I'm (positively) surprised. :)
How to get started with async-await syntax on nightly?
&gt; As for exposing UB in safe Rust, you definitely have a point :). Not sure how to fix it. You can require `T: Default`, and use it inside `uninit` instead for Rust versions that can't do better.
&gt; The compiler's enforcement that `drop` must be run There is no such thing, right?
Basically, Haskell has that stuff called _monads_ that get everyone not used to pure functional programming scared. The idea is that a monad allows you to explains what happens when: 1. You want to wrap a value into a type. For instance, `Option&lt;u32&gt;`. Think about the single function that allows you to lift a `u32` into `Option&lt;u32&gt;`. It’s `Some`, for `Option&lt;_&gt;`. In Haskell, that operation is called `pure`. 2. You sequence two `Option&lt;A&gt;` and `Option&lt;B&gt;` by unwrapping the first `A` and creating a new `Option&lt;B&gt;`. In Haskell, that allows you to handle some kind of implicit state (handled by the implementation of that sequencing) while operating on a pure value. In Haskell, that operation is called `&gt;&gt;=` (pronounced _bind_). Haskell has the `do` notation to provide some sugar above those two operations. Basically: let x = Just 3 -- same as Some(3) in Rust let y = x &gt;&gt;= \contentOfX -&gt; x * 10 The last line will just multiply the content of `x` by 10. Now consider: let x = Nothing -- same as None in Rust let y = x &gt;&gt;= \contentOfX -&gt; x * 10 The last line will do nothing, because the implementation of `&gt;&gt;=` for `Maybe T` (same as `Option&lt;T&gt;` in Rust) doesn’t even use the function at the right side of `&gt;&gt;=` if the left part is `Nothing` (i.e. `None`). This is akin to `Option::and_then` in Rust. Now, the Haskell sugar: do contentOfX &lt;- Just 3 pure (contentOfX * 10) The whole thing has type `Maybe Integer`, but each line allows you to manipulate the data directly inside the `Maybe`. The `x` here still exists, but its _structure_ is hidden in the background (it’s a monad!). Now, as you might expect: do contentOfX &lt;- Nothing pure (contentOfX * 10) Here, the magic occurs. The line `contentOfX &lt;- Nothing` will not bind, because of the implementation of `Monad` for `Maybe T`. So, we could write anything after that, we would still get `Nothing` at the end. --- So that was just `Maybe` / `Option` considered as a monad, but you can consider others, too. Haskell has a very cool package called [parsec](http://hackage.haskell.org/package/parsec) which is a parser combinators library (IIRC, nom is based on it). It provides several ways to parse and… `Parser` is a `Monad`, so you can sequence your parser and lets the `Parser` type handles the parsing state in the background. I hope that has helped you get your finger wet! &lt;3
I assume you mean well, but I feel that advertising a crate like this when it doesn’t actually have the documented semantics is harmful, especially for such a fundamental building block of unsafe code. The worst of it may be running destructors or not depending on the compiler version. This is not a bonus “staged guarantee”, it definitely changes the behavior and validity of programs. Please consider using https://crates.io/crates/nodrop or adapting some of its code. However, the trade-off of keeping an explicit inline drop flag is that `maybe_uninit::MaybeUninit&lt;T&gt;` no longer has the same memory layout as `T`. This is a documented guarantee of `std::mem::MaybeUninit&lt;T&gt;` (allowing for example to transmute between `Vec&lt;T&gt;` and `Vec&lt;MaybeUninit&lt;T&gt;&gt;`). Please also consider renaming your crate and type, to make it clear that it doesn’t have all of the same guarantees as `std::mem::MaybeUninit`. Saying “MaybeUninit to all versions of Rust” sounds great, but it gives false confidence.
&gt; I think too many people are looking at the Future trait as language magic and assume that there are strict rules to be followed and it must be done a certain way. But if there is a use case for it, just wrap the poll function in a loop and break when it returns Poll::Ready, no 'executor' needed. AFAIK this can be tricky to get off the ground. The poll function requires a Waker/Context, and you can just null it out to demonstrate a simple timer future "if elapsed &gt; time { ready } else { pending } ", but that's not exactly a "correct" future, since futures have to call waker.wake() to be polled again, though for this example it can be adequate to explain the way futures work. Along with that uses of .await WILL fail since it clones the waker or something, so unfortunately async fns are hard to demonstrate too. But all of this still helped me understand futures a lot better when I wrote a 'dumb' executor like this one.
I'm pretty new to performance analysis and could use some advice on my current application. It's a web server that accepts GET requests, deserializes query parameters, then passes the result to a C++ library, then serializes its response to return to the user. It uses actix-web and futures. I've run `cargo flamegraph` and already see some opportunities, but the requests are split all over the place. It seems like futures end up pushing the functions I'm interested to various stack levels. If we say the `handle_request` stack level is 0 then I have multiple other flames with `handle_request` in it but at levels 3, 7, 13, and 14. Should I be running flamegraph differently or somehow munging the resulting `perf.data` somehow?
You'll end up with too many variations of apply_one, apply_two, etc. Since Rust doesn't have them built in and you might need different Fn types as well Not pointless in general, but pointless in Rust
I just wanted to give a huge thumbs up for having mentoring issues, that makes it so much easier for people to get engaged in contributing and I understand that it requires a fair bit of extra work to make them.
Most languages have picked up partial application? Is there a way to do that (without getting cancer) in Rust, Python, C# etc.? (I'd already consider having to use pythons partial to be cancer (doesn't mean it's not useful but it's not what I'd want if I was doing FP))
You don't need immutability in Rust, since it can do efficient in place mutation. But my FizzBuzz is plenty functional: https://bitbucket.org/iopq/fizzbuzz-in-rust/src/master/src/lib.rs It uses monoids and iter tools.
I’ll consider this. Is there a specific reason why dual licensing would be preferred? Why do most crate publishers choose this approach?
Correct. Leaking memory is totally safe.
Generally taking it out of Rust gives you more flexibility. Other people are familiar with Nginx and it comes with numerous features that will be hard to replicate (and train people to use even if you do it). You can put static files into S3 or other cloud service. Same with TLS - there are existing solutions that do it better than you can.
\&gt; You don't need immutability in Rust, since it can do efficient in place mutation. this makes no sense...
You mark the struct definition, not the value. So you couldn't add it to a \`Vec\` or \`Arc\`.
If you can invoke `await` on a future, you're inside an `async fn`, and those always returns a Future. The one doing the polling is the one polling the future returned by the `async fn`. If you throw away the return value of the `async fn`, the thing you called `await` on is never polled.
Okay, I found the solution myself. I don't want to adapt my application code into a complete example, so I'll just provide core parts of my solution: 1. Initialize the `tokio` runtime manually, we'll need it later: ``` let mut runtime = tokio::runtime::Runtime::new().expect("failed to start new Runtime"); ``` 2. Create `futures::sync::oneshot` channels for each concurrent task, for example: ``` let (server_shutdown_send, server_shutdown_recv) = oneshot::channel::&lt;()&gt;(); ``` 3. Spawn futures of your tasks using `futures::sync::oneshot::spawn`, this gives you simple inter-task communication: ``` let server_future: oneshot::SpawnHandle&lt;(), ()&gt; = oneshot::spawn(start_server(), &amp;runtime.executor()); ``` 4. Perform `select` on `SpawnHandle`s (`tracker_future` is similar to `server_future`): ``` let shutdown_result: Result&lt;(), ()&gt; = runtime.block_on( server_future.select(tracker_future) .then(|result| { if !server_shutdown_send.is_canceled() { server_shutdown_send.send(()).unwrap(); } if !tracker_shutdown_send.is_canceled() { tracker_shutdown_send.send(()).unwrap(); } result }) .then(|result| -&gt; Box&lt;dyn Future&lt;Item = (), Error = ()&gt; + Send&gt; { match result { Ok(((), unfinished_future)) =&gt; { Box::new(unfinished_future.then(move |_| Ok(()))) } Err(((), unfinished_future)) =&gt; { Box::new(unfinished_future.then(move |_| Err(()))) } } }), ); ``` 5. Ensure that all work is done with `Runtime.shutdown_on_idle`: ``` runtime.shutdown_on_idle().wait().unwrap(); ``` 6. (Optional) Finish process with exit code 1 on errors: ``` if shutdown_result.is_err() { std::process::exit(1); } ```
It prevents you from the dangers of mutability and aliasing done together. You don't need to restrict yourself from using mutation when it's the best way of doing something. In Haskell it's actually more annoying to do a lot of mutation
Glad to see supporting documentation is being emphasized when async-await goes live. Not to mention what the community pulls together, very exciting times ahead.
Thanks for replying. Will check it out and let you know.
Thanks for the solution, will check it out and will you know.
Coming form web as well I have to say that Typescript allows you to do this kind of aggressive refactorings as well, presumed your project is well typed of course. While it has been quite a pain to adopt, in the end it was 1000% worth it and today writing plain Javascript feels dirty to me. I can't stress enough how comfortable it is to have the compiler yell at you when rewriting some part of your app and break a thousand things you'd never have given a thought to otherwise. Recently I also got the chance to work with an older codebase without any TS and introduce it in some components (we use React). While we make heavy use of the any type, it was reasonably easy to get going. Converting old components to TS is pretty straight forward, which I wouldn't have expected. I was astonished by how many bugs I able to find by simply converting. Furthermore IDE support is great, especially for VSCode (if Microsoft does something well it's IDEs) and 90% of the packages you need will have complete typings available which is super nice.
&gt; so what I'm wondering is, what if I don't supply/specify one, and I invoke "await" on an async future. what happens, who is doing the polling? Nobody. You call async functions from other async functions, and the outermost one just returns a future. You can actually poll that future manually if you want, or pass it to an executor that polls it for you. If you don't do anything with that future, nothing is ever polled.
No it does not - first it compares first `l` elements, where `l` is the length of the shorter slice, and only after that it checks which slice is longer. This is because `Ord` implementation for slices implements lexicographic ordering.
Thanks for the feedback. I definitely don't want to mislead anyone. As you rightfully point out, some uses of `maybe_uninit::MaybeUninit` lead to UB on older versions of Rust while they are fine on newer versions. I think you are right, I need to communicate this better. As for your hint to use nodrop, I think it's a great idea. It pains me too that I had to disable drop avoidance on older rustcs. I'll definitely try adapting its code, thanks for the suggestion. Note that most of the scenarios that lead to UB with `maybe_uninit::MaybeUninit` occur with `std::mem::uninitialized` as well. Right now crates like serde are [silencing](https://github.com/serde-rs/serde/commit/ce89adecc12b909e32548b1b929d443d62647029) the deprecation warnings instead of actually addressing them. Serde supports rust down to 1.13.0, it's not able to depend on `std::mem::MaybeUninit`. These crates have no way out. The main goal of this crate is to give crates like Serde a helpful alternative to silencing `std::mem::uninitialized` warnings.
I don't think you're hearing me. Every time I add a new dependency, that's potentially another maintainer that I have to interface with, along with their own maintenance status and roadmap. For example, let's say I want to maintain a MSRV policy. I have been successful in convincing some people that this is worthwhile, or to at minimum, document the MSRV in their CI configuration. But if I bring in a crate with hundreds of dependencies, then that pretty much becomes intractable. It takes too much time for me to track down and convince each maintainer of each dependency. So in that case, I have no choice but to give up on my MSRV policy. Maybe that's not such a bad thing, but it removes choices. An MSRV policy is not the only thing here, so let's please not make it about that. For example, the maintainers of the `rand` crates completely refuse to put a minimal version check into their CI configuration, which in practice means their `Cargo.toml` files frequently lie about the supported versions of dependencies. This means dependents, such as `regex`, can't add their own minimal version check because `rand` automatically fails it. This in turn leads to bugs like this: https://github.com/rust-lang/regex/issues/593 Every new dependency introduces a new opportunity to break something or introduce bugs or introduce subtly difference policies than the ones you want. Personally, comparing LoC to number dependencies just seems weird to me. I'm not interested in saying that one is "better" than the other. I don't even know what you gain by establishing an ordinal relationship between them. Personally, I've rarely looked at LoC. It's certainly _a_ signal, but it's not one I think about that often. Certainly not as often as bringing in a new crate dependency. There are other problems that come with a micro-crate ecosystem. Look at our Unicode crates, for example. Combined, they solve a decent chunk of tasks, but they are almost impossible to discover and their documentation, frankly, leaves a lot to be desired. There's really nobody steering that ship, and both the UNIC folks and myself came to the same conclusion: it's easier to just go off and build that stuff yourself than to get involved with the myriad of Unicode crates and improve them. This is why the `bstr` crate duplicates some of that functionality and makes it part of a *cohesive hole*. There's a clear sense of code ownership, and as long as someone finds `bstr`, discovering those additional Unicode operations should be much easier. I wrote a little about this here: https://github.com/BurntSushi/bstr#high-level-motivation There will _always_ be examples where a "micro" crate makes sense. `hex` might be one of them. `base64` is perhaps another, along similar lines. This is why this problem is so hard because reasonable people can disagree about the appropriate granularity of crate dependencies. I try really hard to keep crate dependencies to a minimum, and even I see myself as failing in this regard. But when I go and bring in a crate to do HTTP requests and I see my `Cargo.lock` file balloon to &gt;100 dependencies, then something, IMO, has gone wrong.
I'm currently refactoring couple of thousand lines of Javascript. Pls send help. I wish we were using another language, or at least Typescript.
I've been learning Rust by reading the book, and this part kinda confused me: &gt; Several rules determine what a package can contain. A package must contain zero or one library crates, and no more. It can contain as many binary crates as you’d like, but it must contain at least one crate (either library or binary). 1. While creating an application, are we not supposed to pull more than 1 library dependencies? -- What is a binary crate and library crate exactly? 2. Also I did not quite *get* the relationship between packages, crates and modules. I though each file is a module, is this not the case?
Right, I understand that “just don’t do this” is not practical advice. I do think there’s a place for something like this that uses `MaybeUninit` when available, and falls back to something similar to what its users would have done before when not.
&gt; While creating an application, are we not supposed to pull more than 1 library dependencies? -- What are binary and library crates exactly? I think you're confusing libraries _used_ and libraries _contained_ by a package here? If I make a binary crate "mycrate", I can depend on any number of crates, each probably having exactly 1 library package. For the most part I personally never differentiate between packages and crates when thinking of these. But then I can also have one, two, or more packages in my own crate. If I create a `src/lib.rs` file, then I've defined a library package. If I create `src/main.rs`, or `src/bin/mybin.rs`, then I've created a binary package. This binary package can depend on my library package by using `use mycrate::module_name_from_lib`. Both `lib.rs` and `main.rs` are considered "package roots", and can pull in modules from other files with `mod xxx;`. Generally, you only want one package to do this, though, so that modules only ever exist in one concrete location. --- The simplest binary crate will only ever define `src/main.rs`, and then declare all its modules from there. If you want more testability, then you can first define `src/lib.rs`, create all your functionality there and publicly export it, and then use that functionality from `src/main.rs`. Having an `src/lib.rs` file also allows you to use it elsewhere, like in integration tests (`tests/xxx.rs`), which could now test the functionality of your crate without having to manually execute a binary.
Get a [Rust frontend for GCC](https://github.com/redbrain/gccrs) operational so that more platforms can experience the wonders of Rust, especially embedded systems that LLVM has no support for. I imagine you’ll be able to program it in Rust since the Ada frontend is programmed in Ada and not C++ like the rest of GCC.
A GUI framework, as far as you're requesting, is what? A set of tools and utilities for drawing and managing interconnected components visually as those in the photos? If that's what you're after than Qt is what I would go for because it's got a pretty good kick and, if need be, can get _very_ low level with OpenGL and even Vulkan in the latest release. I work in the VFX industry where most artistic apps are Qt (Nuke, Maya) however we almost never start a new app in it. Typically we either use the python bindings for it (PySide2) and whip up a POC or slide to something like electron and small js libs for testing. CSS is a powerful (and "dangerous") thing so coming up with a style and feel is extremely easy. Qt makes it relatively painless to transition with stylesheets and raw painting. At a full app design level, you may want to provide a better design spec. Drawing widgets like those you've shown can be done on a great number of frameworks but how the data interacts and is manipulated/stored can greatly impact what I would constitute a "good decision"
A while ago I searched through the most frequently used packages on npm for things that I thought would be good candidates to be ported to rust and compiled to wasm, and fuse.js stuck out at me; computationally heavy, some gripes about performance in the tracker, but small enough for me to re-write in a couple of weeks. wafu is the result of that work! Translation was surprisingly straight-forward, and rust has really been a pleasure to work with. When I first finished this project, I was kinda sad to see only a 2x performance increase over fuse, but it's a testament to everyone working on wasm support in browser that it's become closer to 5x (at least in FF 69.0b2) without me doing much at all. After a couple of weeks deep in the fuse source I... think fuse could have done a lot of things better, but having the goal of being a drop-in replacement gave me focus, so a _better_ fuzzy search library is a project for another day. Anyway, thanks for taking a look! Note: For the timers on the demo page to give you an accurate picture, you probably need to disable spectre/meltdown mitigations that reduce timer precision. It's `about:config` &gt; `privacy.reducerTimerPrecision` in firefox, I'm not sure about chrome.
I gotta say, this is the sort of work that really scares me. Every language has a mental complexity budget, I feel that Rust is just about at its limit, and adding higher-kinded types to Rust (either in the language or as a library) would just push Rust way past that budget. I get that people like the very high level abstraction of Haskell, but anyone who's done some Rust knows that the patterns of effective Haskell just don't work in Rust. Rust does not have to be a refugee center for Haskell programmers.
Which app are these screenshots from
I don't actually know what other crates you're talking about. This crate is only very loosely linked to JS, and can be useful even outside of interoperating with JS (according to the matrix spec at least, some JSON parsers that one might want to be compatible with limit their integers to JS's / `f64`s safe integer range)
&gt; I don't actually know what other crates you're talking about. IIRC, I have seen at least 2 others over the past month or so. I can't recall what they actually did other than something related to working with JS.
Doubt you'll gain much speed with multithreading when you're already at 70ms. Concurrency/MT has an overhead.
Even primitives? And you can always use object pools if you want to avoid specific explicit allocations, right? So they're still in the heap but you can avoid allocating e.g. request objects on every request. I also have a lot of trouble believing this is worse than Ruby (or any interpreted language). When building a scalable web server, I don't think this level of performance is typically necessary. I know it's Twitter, but the amount of time to load stuff from the database, memory store, or wherever they're going for the information is probably going to be an order of magnitude worse than any issues they have with heap indirections.
Distro packagers: the unsung heroes of the development world. As someone who just upgraded to Debian 10, thank you!
Flutter! Wait, wrong sub.
It's almost like having information about the structure of the program heavily embedded into the syntax make it easier to reason about and modify.
but the rust compiler is compiled with the previous rust compiler, isn't it? so the rust compiler isn't compiled with the latest stable? I imagine this is done through a custom build of the compiler, which was compiled with the stable one. My mind is inceptioning itself many times already.
It is with the stable compiler. It has a way of configuring itself to cheat. It’s not supposed to be used by anyone else so that’s why I’m being vague but you can figure it out if you poke around :)
The Fn/FnMut/FnOnce distinction among other things makes dealing with first-class functions and partial application very cumbersome in Rust. For other reasons most other major languages do not make it easy to deal with them either, compared to say OCaml or Haskell. I don't think your statement is true wrt these two points.
1. Use a parser library for command line arguments. In `src/bin/rustop.rs` you manually parse. Not a good idea. 2. You should run `cargo fmt` on your project, there's a case where you have `enum SysProperty {CpuInfo...`. This isn't a huge deal but it adds up in readability to run cargo fmt on the project. 3. Testing. Use unit testing, fuzz testing, and quickcheck together with a CI so that your program is of high quality. 4. It is very unclear what `Lvm` og `VG` means. As an aside, I don't think struct names should be all-caps, even for acronyms. 5. ``` let minor = match lvm[6].parse::&lt;u16&gt;() { Ok(n) =&gt; n, _ =&gt; 0 ``` You can use `ok().map_or(0)` instead of the match, since you have multiple matches this shortens the code considerably.
I really appreciate the isolines of the terrain as seen on top-down screenshots :) One thing that certainly needs to be rewritten is the graphics subsystem. Veloren is one of the few projects that use gfx pre-ll version. Please come [join us](https://gitter.im/gfx-rs/webgpu) in discussion on how to modernize it.
This is really nice! I hadn't used that pattern before, but it feels very Rusty. your PR to the DiceRoller app is great to see it in action: [https://gitlab.gnome.org/NoraCodes/gdiceroller/merge\_requests/2](https://gitlab.gnome.org/NoraCodes/gdiceroller/merge_requests/2)
That's the implementation for `IntoIterator` for `Series&lt;T&gt;`, not `Iterator` (iterator has a `type Item` and a `next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;` method) - the name is incorrect. &gt; But the vector type be default has the iter type. No, a `Vec` can be turned into a `std::vec::IntoIter` (which is what `self.data.into_iter()` is doing.) If a type implements the `Iterator` trait, it is an iterator - it can be iterated over. If a type implements the `IntoIterator` trait, it (probably) isn't an iterator - it just has a method `into_iter` that will get you an iterator over it.
Found it! :P
no lsd?
Yeah, I'd love to figure out a way to make nom+scroll play nice together. I probably just need to sit down and try it out. :)
I don't have an answer for you, but I know that on unices CPython specifically looks for an SO file, so e.g. on OSX you have to remove the library from dylib (the default) to so. Might be the same for windows, it looks for a .so file despite windows normally using the dll extension?
Getting tls properly setup is a non-trivial amount of work. Properly in this case doesn't mean "works" but "works with things like ocsp stapling". I don't think there's a web framework with sufficient support for that.
It might also be looking for `.pyd`. From what I remember (Python 2.5 era), Python on Windows expects compiled modules to use `.pyd` extensions instead of `.dll` extensions.
&gt; I have come to the point where the cargo builds the library but it seems empty. Nothing is there except python dunder methods. Not even the examples from the documentation pages work. Can you pastebin a minimal example which demonstrates the problem using cpython? I only have Linux experience, but I *have* helped people in situations where they *thought* they were doing the same thing but were doing something subtly wrong, so I may be able to help. (eg. One person was getting missing dependency errors from `ld` and it turned out to be because they'd build a `dylib` rather than a `cdylib`, so the Rust dependencies weren't getting statically linked into the `.so`.)
Thank you. This works!!!
I re-exported the object and that fixed it... Thanks a bunch!
I doubt anyone will be able to give you concrete advice based on this very vague description. Please give at least a concrete example of the kind of thing you are trying to achieve, and the solution that you have thus far.
The important thing to understand about the distinction between containers and their iterators is that you don't magically get persistent state for free. An iterator is a struct unto itself, which needs to store a reference to the thing being iterated over, and some means of keeping track of its progress so that calling `next()` on it won't produce the same element each time. `IntoIterator` provides a standard API for getting an iterator from a collection so things like `for` can work. `Iterator` provides a standard API for the iterator that `IntoIterator::into_iter()` returns. (It's possible to use `Iterator` without using `IntoIterator`. For example `String` and `&amp;str` don't implement `IntoIterator` because they have multiple methods which return iterators (byte-wise, character-wise, line-wise, etc.) and choosing any one of them as "the default" that `for` automatically uses would be a footgun.)
See https://rust-lang-nursery.github.io/api-guidelines/necessities.html#c-permissive
Dual licenses increases compatibility. Read more at: https://doc.rust-lang.org/1.5.0/complement-project-faq.html#why-dual-mitasl2-license or more detail: https://github.com/cmr/relicense-assistant/blob/master/issue-template.txt#L14
`[a; X]` with a generic parameter X doesn't work ATM, so you need to pass the array into the function.
Does that mean `Iterator` has to be `IntoIterator` in the code?
I would like to see higher ranked bounds on closures. As far as I can tell, it's primary thing preventing a very nice API for async middleware. Ideally, the middleware would borrow the context, allowing you to seamlessly use \`?\` without losing the context. Instead they need to thread the context ownership through. [https://github.com/rustasync/team/issues/19](https://github.com/rustasync/team/issues/19) [https://github.com/rust-lang/rust/issues/51004](https://github.com/rust-lang/rust/issues/51004)
&gt; memory mapping I'd avoid this whenever possible. Between SEGBUS errors and being unable to safely treat them as `&amp;[u8]`/`&amp;mut [u8]` memory mapped files very annoying to use.
Just tried it and it's really fast! Thank you for this write up.
[gist](https://gist.github.com/rokoatcoffee/b117d13d05f1118adb744f0d4b5d3813) project tree ``` . ├── build.sh ├── Cargo.toml ├── src │ └── lib.rs └── test.py ```
I always find it useful to jump to the documentation, look at the type I am using and go straight to the traits, immediately check iterator and see what functions I can use to get the desired result or if I just need to know I can iterate over a type and what type it returns.
You're using "package" here when you should be using "crate". A package is something defined by a \`Cargo.toml\`; that's why it starts with \`\[package\]\`. \`src/lib.rs\` and \`src/main.rs\` define two different crates. I know you said &gt; For the most part I personally never differentiate between packages and crates when thinking of these. but using different terminology can be very confusing. Later in your comment you switch to saying "crate" instead. Not the most major of things, but I think that the lax use of terminology can really hurt here, to some people. For most, I think it's fine.
Generating a new list from an existing one? Sounds a little like you want `map` and all the functional programming-esque iterator adaptors
Ideally the waker for a spin loop executor would be as simple to implement as: struct NullWaker; impl Wake for NullWaker { fn wake(self: Arc&lt;Self&gt;) { } } let waker = Waker::new(Arc::new(NullWaker) } But this is still out of reach for some silly technical reasons, so instead you have to implement a vtable full of null functions yourself. Of course, implementing a simple toy executor that uses a threadpool and re-enqueue wakers, with some unnecessary overhead, is only 100 lines of code or so. Hopefully someday we will have a good hands on tutorial that walks through writing that.
So, what is a crate comprised of if packages are comprised of crates? It sounds as if each .rs file is a crate. -- .rs files are modules, right? Also, I don't see the reason why would you have more than 1 binaries in a project. What do people use multiple binaries for, generally speaking?
A “crate” is “the thing that rustc compiles at once”. You pass the “crate root” to rustc, and it looks at its contents, and then loads every module defined in it. The whole tree of modules is one crate. They’re not compiled separately. It really depends on the project. Imagine you’re making a game that’s multiplayer; you may have a client, and a server, and a library to share code between them.
Thanks! Edited.
Oh I see -- crates are the compilation units. Thanks, it really helps to understand the organization of a project from the perspective of the compiler.
Yep, exactly. Glad to help.
Enable the `async_await` feature and make use of the [compat extensions](https://rust-lang-nursery.github.io/futures-rs/blog/2019/04/18/compatibility-layer.html) to interact with the 0.1 ecosystem. I've been using it for the last two months in [one of my projects](https://github.com/udoprog/setmod) and it works really well.
I see. I don't necessarily mean `std::sync::Arc`, but rather _an_ atomically counted reference; what happens when I make some data structure that uses its `Drop` impl to enforce some invariant and then use `#[derive(destructure)]` to bypass that? I think it's a useful tool, but it should probably be marked `unsafe` in addition to not being `pub`.
I have a simple actix server, and I want to trigger an action once the server is up and listening. Is there some kind of insertion point for this? Like a callback or something?
thanks, i've edited my post to include more data
Can you elaborate on golang's problems when refactoring? Are the issues inherent in static-duck-typing or due to other issues with go?
Yep, it’s an implementation of the `IntoIterator` trait.
No, `IntoIterator` is only a convenience method for `for` loops.
Java would be way high on my list. IDE support was superb as far back as 2002, and I think it's a bit of a shame that's not considered more of a priority when developing a type system. C# is pretty decent as well, though in practice having Resharper in the mix with Visual Studio makes the whole experience a bit like wading through treacle - and I've seen a couple of failed refactors where it's mangled the code (generally recoverable). I would not rate Scala all that highly. When I was using it maybe 2 years ago, it wasn't unusual have have projects where the IDE couldn't even get the syntax highlighting right, let alone offer a full refactoring suite.
Any language that's part of the ML pedigree will be similarly nice to refactor. Haskell, Purescript, Rust, Ocaml, F# are probably the main ones.
OK. I'm due for bed now, but I'll take a look at it when I wake up if nobody else beat me to an answer.
Looking cool! For what it's worth, looks like the input "Hello there" has a divergence with the original implementation. &amp;#x200B; Excited for more JS library to be ported this way -- some of them are maddeningly slow.
If all of the structs that will implement Message will have no borrows (as it is the case in your example code), then it should be fine to add a `T: 'static` bound as the compiler suggests. pub fn new&lt;T&gt;(msg: T) -&gt; Self where T: Message + 'static, { MessageBox { content: Box::new(msg), } } If there will be messages that make borrows, then there need to be lifetime annotations indicating the boxed content will live long enough. pub struct MessageBox&lt;'a&gt; { content: Box&lt;dyn Message + 'a&gt;, } impl&lt;'a&gt; MessageBox&lt;'a&gt; { pub fn new&lt;T&gt;(msg: T) -&gt; Self where T: Message + 'a, { MessageBox { content: Box::new(msg), } } }
Hi all, if anyone happens to be in London on 24th of July the Rust London User Group is having it's monthly LDN Talks event with a stellar line up. You can check it out here. [https://www.meetup.com/Rust-London-User-Group/events/262999277/?isFirstPublish=true](https://www.meetup.com/Rust-London-User-Group/events/262999277/?isFirstPublish=true) . We're gonna be having special guest speakers @flgilcher and James Munns will be giving a talk on the Sealed Rust project.
You just need to add a `'static` bound to `T` in `MessageBox::new`. where T: Message + 'static, This means that if you try to create a `MessageBox`, the `msg` must be a static reference, or a value. So `MessageBox::new("hello")` will compile because `hello` is a `&amp;'static str`, but let s = String::from("Hi!"); // Will not compile MessageBox::new(&amp;s); will not compile, because `s` will be dropped at the end of the scope. But, you can just pass it by value and it will be moved: let s = String::from("Hi!"); // Will compile MessageBox::new(s);
It looks like most of your methods are creating a new matrix from the old matrix. You can just collect the data using an iterator and you don't need any for loops: ``` pub fn add_scalar(m1: &amp;GhettoTrix, s: f32) -&gt; GhettoTrix { let data = m1 .data .iter() .map(|row| row.iter().map(|x| x + s).collect()) .collect(); GhettoTrix { data, rows: m1.rows, columns: m1.columns, } } ``` Similar things can be done for `mult_scalar`, and `randomix` (with data): ``` let data = (0..r) .map(|_| (0..c).map(|_| rng.gen_range(r_rng.0, r_rng.1)).collect()) .collect(); ``` The ones where you're doing 2 matrices can be done using `zip` on their iterators.
`std::mem::forget` is sound and safe, so other ways of avoiding `Drop` should be too.
Fair enough!
Would be great to blog out any of your learning rust / wasm pains along the way 👌👏
What's the time complexity of slicing a `str`? Does it have to iterate over characters from the start/end of the string to figure out whether the slice is valid, or can it just check the value of the starting/ending bytes?
Amazing as always, they are so motivated and it just makes me love the project even more.
How does performance compare to https://docs.rs/fst-levenshtein/0.2.1/fst_levenshtein/ ?
Last time I looked at pyo3 it still had a lot of work ahead of it in terms of safety, so I would advise against it. Admittedly I haven't looked at rust-cpython.
It is O(1) because the index is in bytes, but it will panic if the start or end is not a character boundary. See [SliceIndex trait](https://doc.rust-lang.org/std/slice/trait.SliceIndex.html#implementors). If you want to slice a string by using the character count as index (give me characters 4 to 10), then that is O(n).
I don't really see the difference in this regard between `#[derive(destructure)]` and for example `#[derive(new)]`. Let's say I'm re-implementing `Vec`. It has a bunch of invariants (like `len &lt;= capacity`), and I make sure that all safe methods that construct a `Vec` ensure that those invariants hold. I could then add `#[derive(new)]` to the definition of my `Vec` and the `new` function that it would derive would be the equivalent of the unsafe function `from_raw_parts`. But this `new` would not be marked unsafe! Uh oh. Should `#[derive(new)]` therefore be unsafe? No, obviously not. The answer is that having any unsafe code in a module means that all code - even the safe code - in that module needs to ensure that it upholds the invariants of the unsafe code. For example, `vec.capacity += 1;` by itself is safe code, but it may violate the invariants of the unsafe code that requires certain things about `vec.capacity`. So if you have a struct that uses unsafe code that maintains some extra invariants besides the memory safety rules of Rust, you need to ensure that every bit of code that could potentially affect those invariants is correct. That includes marking the struct `#[derive(new)]` or `#[derive(destructure)]`. That also includes calling `destructure()` on a struct. The reason why `#[derive(destructure)]` and the function `destructure()` is safe is that (unless I have a bug somewhere) it should be impossible to write Rust code using `destructure` that violates the memory safety rules of Rust. Whatever you make your custom `drop` impl do, whatever weird other things you make your struct do, potentially including `std::mem::replace()` and `std::mem::forget()`, as long as you never write the keyword `unsafe` it should be impossible to write code that compiles but still breaks the memory safety rules. If you find a way to do it anyway, please let me know! Making already-`unsafe` code potentially more dangerous, though, is no reason to mark something `unsafe`. Side note: I get slightly annoyed when people boast about having "only X lines of unsafe code" in their library. By itself that's a pretty meaningless statement, because having even one line of unsafe code in a module makes essentially the entire module that it's part of unsafe. That being said, having fewer lines of actual unsafe code is *usually* better because it *usually* means that it's easier to verify the invariants. But not always.
Just took a quick peek at some files, the one thing I've noticed is that you check for overflows in a way that will panic in debug, eg here: https://github.com/Ryp/chip8-emu-rs/blob/986f780e779e368ce5ae7bb158d0b250c20b9733/src/chip8/memory.rs#L17 Integer overflow causes a panic in debug mode. You should use `overflowing_add` instead.
`u32::from()` and `u8::try_from()` are a good substitute for `as`. The first is infallible while the second checks that the conversion can be performed and lets you handle the case when it can't instead of silently truncating the number.
Some minor (optional) syntax tweaks. You can import multiple items in a single statement like this: using A::{B, C}; Or even using A::{ B::{C, D}, E }; Optional of course, and depends on what you find easiest to read. Struct constructors like this: let a = A { b: b }; Can use the shorthand: let a = A { b }; Primitive conversion isn't done implicitly; if you really need a lot of conversions (which is likely in an emulator), you'll be typing "as" a lot. Maybe you could evaluate if any types would be better off storing the converted form to begin with?
Thanks for all the replies! They have clarified some things I have previously only had a hunch about. And just to clarify what I have been talking about a bit, I understand that Rust doesn't have nearly the same ability to deal with types as Haskell, but what I was trying to say was that the type constructors are there but only during compile time. Then it's all erased after they are done producing their data and function types.
I have been working on a sparse octree structure (basically replacing 3D grids for voxel point clouds). It's getting to the stage where it's usable! I'll be spending the next couple of weeks adding some extra functionality and optimisations, then hopefully will release it as my first crate. It's good to *finally* get to the stage in a side-project where I might actually finish it.
It has to be a fresh closure each time.
 Quality Visual Studio support for Rust never materialized, thus it did not matter that the language was better than C++ since the tooling was so insufficient.
I’m not sure, but I can say performance isn’t great in general; it’s a faster version of fuse, but fuse is just not that fast! I’m honestly not familiar with levenshtein automata and I’m having trouble parsing that crate, but I’ll tell you the algorithm underlying the search is bitap. My cursory understanding is that they’re very different strategies; fst is more offline, you provide a large dictionary and a pattern and it finds words in that dictionary that match, where bitap is more like a regular expression, searching for a compiled pattern in a bunch of very long strings. Also, convenient place to plug that I’m working on a [bitap crate](https://github.com/heyimalex/bitap) :)
&gt; CI is set to fail when any warnings are given on a branch. Can't you just `#![deny(warnings)]`?
Thanks!
Count me in! :)
Without sum types you can easily get into situations where you leave values unrecognized/unhandled. In Rust or Haskell or Elm you would get a compiler error or warning akin to "non-exhaustive matches" found-- which is a red flag that you have a function that doesn't understand all the possible inputs. The other problem I have with refactoring is trying to massage collections of a particular interface which Go doesn't like so much. That was just me trying to be clever without generics and it was painful/did-not-work.
That huge else-if in the execution function isn't going to be super fast. Try to improve on that. Consider match, possibly with ranges. Consider whether you can turn it into something a bit more tree structured (so that its execution speed isn't linear in the number of instructions in the ISA).
It is impossible to write a `nonnull_unique_ptr` in C++, whereas rust has `Box&lt;T&gt;` which is exactly that. IMO that example gives folks a good glimpse of what rust can offer.
You might laugh because of the #lolphp meme, but PHP. It has a solid (not great) native system greatly augmented with several high quality static code analyzers. If you have a decent test suite (backed with mutation tests) and use a high-end IDE like PhpStorm, you can really slap your code around while still keeping it within specific boundaries.
&gt; If you have a decent test suite The nice thing about Rust is that it's nice to refactor even without a test suite.
Nice! Love the visualizations. I did a GA + visualization for a school project last year: [https://github.com/anderspitman/battle\_beetles](https://github.com/anderspitman/battle_beetles)
Rust has safety guarantees C++ can't provide without becoming an entirely different language - which is what Rust already is. Everything else is just nice to haves.
Their argument to this is that "well-formed C++ can do the same things with smart-pointers, etc.". The caveat to that is that (I believe) developers cannot always *guarantee* that their code is always well-formed (esp. after manual refactoring, etc.).
Aye. And personally, I'm not a huge fan of using edit distance for fuzzy searches in most cases. I've found n-gram (with n=3 or n=4) to be much more effective. And you can use that in conjunction with bitap, for example, by using an n-gram index to narrow down your search space. If you like algorithms like bitap, you'll definitely like [Flexible Pattern Matching in Strings](https://www.amazon.com/Flexible-Pattern-Matching-Strings-Line/dp/0521813077/ref=sr_1_1), which covers generalizations of bitaps for regexes themselves, for both Thompson and Glushkov automata.
"Well-formed C++" is entirely up to you, the programmer, to keep in mind. People are generally utterly terrible at keeping things in mind, especially things that are tedious and nitpicky, like making sure to use smart pointers everywhere. Also, smart pointers still don't give you the same compile time guarantees Rust does.
Yeah, I get it, but don't really buy the "types are enough" argument, types will not save you from off by one or similar straight up bugs. You can pretty safely refactor code using the described toolbox in PHP too, but you still need tests to verify the behaviour.
This is horrible for actually writing / refactoring code.
n-grams (especially trigrams) also have the benefit of being more broadly supported, e.g. PG includes an extension for trigram indexes by default
Thank you for the tips! making use of them as i'm writing this :)
&gt; Serde supports rust down to 1.13.0 My view is that Serde should stop insisting on Rust 1.13.0 when doing so causes it to use unsound code: ```rust // This assumes the validity invariant for unsigned integers allows this: // See https://github.com/rust-lang/unsafe-code-guidelines/issues/71 let mut buffer: [u8; $max] = unsafe { mem::uninitialized() }; let mut remaining = &amp;mut buffer[..]; ``` Few people actually need Rust 1.13.0 and most people use the current stable/beta/nightly. At minimum I think people should be warned if they use an older version of Rust.
Although `let minor = lvm[6].parse::&lt;u16&gt;().map_or(0);` doesn't seem to be working :(
This code would probably be a lot clearer if both `Item` and `IntoIter` delegated to the vec impl instead of hard coding what it does. e.g. ``` type Item = &lt;Vec&lt;T&gt; as IntoIterator&gt;::Item; type IntoIter = &lt;Vec&lt;T&gt; as IntoIterator&gt;::IntoIter; ```
main.rs:37-39 let mut rom_file = File::open(&amp;Path::new(&amp;rom_path)).expect("Could not open file"); let mut rom_content = Vec::&lt;u8&gt;::new(); rom_file.read_to_end(&amp;mut rom_content).expect("Unable to read the file"); `Path::new` already returns a `&amp;Path`, you don't need to take the reference. You can just create the `Vec` without the type as it will be infered by the use as byte buffer. All three lines can be changed into... let rom_content = std::fs::read(&amp;rom_path).expect("Unable to read file"); ... because you're reading the entire file in one go anyway.
I don't think this coworker has done his homework, to be honest. Which is his right, but anybody who uses their brain professionally should be aware of the limits of their knowledge &amp; experience and adjust the strength of their opinions accordingly. That and/or they have their head in the sand, and have a vested interest in C++-based job security. Just sayin'.
I'm happy you're positively surprised. Your crates were quite straight-forward to package. The new gtk-rs version is on it's way into bullseye, once my sponsor uploads the packages that received new features. Updating process-viewer will require some special treatment though, because the dependency tree of serde-any has some outdated and apparently unmaintained dependencies. But let's see how it turns out. Thanks for your hard work.
Thank you for your kind words, that gives lots of motivation to continue our work!
Thanks for the links! and also everything else you do :) Re: edit distance, you’re absolutely right, levenshtein tends to produce of a lot of results that are very counter-intuitive. I’ve noticed a real desire for a fuzzy search library in js that just works ™, but so many of the packages I’ve seen are written from an implementing-an-interesting-search-algorithm perspective and not an actually-returns-what-the-user-wants perspective. At least in the front end space, algolia is now being used everywhere, and, while their product is great and it’s cool that people are being paid to work on search, I can’t help wishing oss had something better.
Figured it out! It's: `let minor = lvm[6].parse::&lt;u16&gt;().unwrap_or(0);`
In their defense, we are an extremely small team constantly bringing in new tools for development/devops, and so the thought of supporting a whole new language (and one at that, that has an historically steeper learning curve) probably comes across as intractable. Also, my coworker *does* already know modern C++. "A bird in hand is worth two in the bush". Nevertheless, I am still trying to push it :)
Some time ago there was a kinda similar but not really thread on r/cpp: [what are the advantages of C++ over Rust](https://www.reddit.com/r/cpp/comments/c5bnme/what_are_the_advantages_of_c_over_rust/). It mostly deals with what C++ has and Rust lacks (and how Rust manages without it), but some comment threads go into the ‘can C++ achieve everything Rust has?’ theme where things not possible in C++ are described. TLDR imo is: C++ does not have a borrow checker and function signatures that guarantee memory and thread safety (C++ smart pointers and static analyzers might help you a lot with memory safety, but they cannot reproduce the guarantees Rust type system gives you). Also Rust has sensible standardized error-handling scheme (vs C++’s exceptions, error codes, `errno`, Boost `outcome::result`, and a few more proposed…). Thanks to that, and to the tooling, using external libraries in your project is easy in Rust and can be very cumbersome in C++ (or at least that’s the idea I get, my C++ is also very rusty…).
For me safety wasn't really the main selling point (though it was a significant one), what was a big one was having a different kind of approach to solving architectural problems. Over the years I've become pretty dissatisfied with the standard way of doing OOP with C++. [You could emulate traits in C++](https://dragly.org/2018/04/21/rust-like-traits-in-cpp/) but it's just bulkier and more noisy. For Rust's enums, in C++17, std introduced std::variant, but I still find it nicer to have the full support on language level. Rust's match statement is also pretty darn powerful. All in all, I find that I do write cleaner, more understandable code in Rust. This isn't 100% due to the language, but also due to the practices around it and the kind of programming style that it encourages. To me, this is hugely important. When people can cut corners, when they can make very dubious architectural choices, they sooner or later will. But writing clean, idiomatic Rust is imo much more likely to happen than writing clean, idiomatic C++ is. Plus, if your idea of idiomatic C++ is heavy on OOP, then yeah.. After years of dealing with all kinds of crazy class hierarchies in C++ projects, I've found that approach to create just as many problems for the future than it solves in the now.
Keeping the number of languages floating around down is a fair position, if that's the case they want to make!
Herb Sutter spends 5 minutes in one of his big talks on modern C++ best practices talking about a use-after-free pitfall with shared pointers: https://youtu.be/xnqTKD8uD64?t=1380 The short version is that if you ever dereference anything like a global `shared_ptr`, you have to protect yourself from code that might modify that global while your reference is alive, by making a local copy first and dereferencing that instead. These sorts of problems come up in C++ even in the perfect world where you only ever write code following modern guidelines. In general, I wouldn't be too aggressive with the "Rust &gt; C++" push. Examples like the above can feel nitpicky ("dude, just don't put `shared_ptr` in a global, what were you thinking?"). A lot of the safety issues with C++ can be solved relatively well by an experienced programmer working by themselves under those modern guidelines on a small-to-medium-sized project. And on larger projects with big teams of people, there are more likely to be legacy code issues or missing features that make adopting Rust difficult. So even if you believe that Rust is going to eat the world (I do), it's going to take plenty of time, and not everyone wants to be an early adopter. I do think `cargo build` and no-null-pointers and move-semantics-by-default and `Mutex`-is-a-container should excite any C++ developer, though. Maybe show your colleague some examples of those things? But make space for whatever concerns your colleague might have about the costs of adopting a new language into the codebase; those are real regardless of the language.
To find out the performance problem, you might want to have a look at [this blogpost about rust profiling]https://blog.anp.lol/rust/2016/07/24/profiling-rust-perf-flamegraph/) which has helped me a lot in the past.
I once took a look at it, but what kept me from doing it was this scentense in the installation prerequisites: "Install the patched fonts of powerline nerd-font and/or font-awesome." Once that is available in Debian, we could package lsd. We avoid bundling things like fonts or e.g. js libs with packages that need them, but rather create separate packages for them.
I'm currently doing a coding project in C++ for a job interview. It requires downloading an opensource C++ project and it's also my first time with a full C++ project. Headers and dependencies are nothing short of a nightmare. I had to install Boost from source which installed the libs to a different lib directory to the one the project was looking in (why is there multiple libs folders in Linux?), I've created a new module in the project and have to include a particular header but there's a header inside that header that can't be found...even though it's in the project and I can see it. These problems just keep going on and on. God bless every last person that ever worked on Cargo, I have a new found appreciation for just how good it works and how much easier life is with it.
Rust lacks exceptions and their subtle problems. C++ has many dark corners and sooner or later someone will explore these or take shortcuts with a little pointer arithmetic or a bad cast or the like. Programmer discipline only goes so far.
That is like saying if everyone obeys traffic laws accidents would not happen. While true, it is an entirely pointless statement.
So Rust by far is my favorite programming language and things just click in my brain with it. However, I've been required to program in Python for the past few weeks, and it just *doesn't*. I know this isn't strictly Rust related, but does anyone have any resources for a Rustacean that's being forced to transition to Python? In comparison, Rust is *so* amazing. Amazing docs that are simple, straightforward, easily-understandable, and are well organized. A fantastic and simple package manager, versus one that makes no sense whatsoever. Language features that fit together really well with a fantastic type system versus... that. A fantastic book explaining every concept in a great manner. A philosophy of doing things correctly instead of getting something out there asap with a bunch of bugs. I can't stand Python. I thought that it'd be more like Ruby, but it's actually much more like JavaScript. Ruby's actually statically typed, and makes a lot more sense to me. It's awful and I only want to program in Rust. And no, I can't change to Rust, right now. With what I'm working on, what's important is the tooling and it's not feasible to switch away from it. (Python 3.6 thankfully, though.) So, at a minimum, does anyone know of any Python resources that match the quality of the Rust books? Most Python books tend to be beginner stuff, not 'programmed in everything but Python'. I need something that explains why. What I'd like is for a book about idiomatic Python programming and how to write Python well, in addition to telling me how the whole ecosystem works. I'm just totally lost, and I want to learn Python coming in knowing the Rust perspective (or the ML type system perspective or the functional perspective -- not the pseudo-functional stuff Python has, but OCaml or Haskell with proper pattern matching and what not -- or the traditional Java perspective). If this isn't the right place to ask this question, please let me know where I should ask.
Smart pointers do pretty well for stuff you own. There's tremendous value in being able to borrow safely as well.
I do not have experience either cpython or pyo3, but not long ago i have visited a local python conference where one man made a talk about his and his team experience with pyo3. They use rust's crate for parsing xml and transmit parsed data to the python application. The application is gui client on Qt. And the speaker told that using rust along with python made their app incredible faster than using with lxml was. In other words they use pyo3 in production and they are very happy)
'json' is another input that diverges even more. it's good that there is clear forethought for including those checks. It would be interesting to hear what causes it, if OP gets to the bottom of it
 For me it's not about what C++ has to offer, feature-wise it Rust has about parity. It's about what Rust takes away. Just by using modules, no more: * header files with * bad namespaces * double definitions/undefined functions and classes * template code in header files Borrowchecker, no more: * object slicing when copying/moving as a superclass * iterator invalidation leading to segfaults * returning local reference Regular C++ insanity: * SFINAE,std::enableif * rule of 3/5/0, opt-in automatic destruction * issues with const * https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md many rules are now non-applicable
The most brilliant minds of the standardization committee regularly make mistakes in their efforts of taming C++. If they can't do it flawlessly, your coworkers can't either.
Thanks for yours! Don't hesitate if you need me to update anything on my crates. Doesn't cost much and if it can make your life simpler...
I wanted to make a pithy "I'm a good driver, I don't need seatbelts" type analogy response but not at a top or second tier comment. ;) I find that for *corporate* adoption, there's a lot more to a language than raw features. Labor pool, mentorship/teachability, styling and linting, module and build toolchains, and of course... the technical merits of the language itself. For me Rust doesn't yet satisfy scrutiny for labor pool, but I'd rather teach it than C++ and its lava flow of "do this, not this" that has developed over time. I would feel more confident with junior developers on a Rust codebase than a C/C++ one, basically. Also modularity is better with Rust. Development environments are a nightmare with C/C++, although any shop using those languages is well accustomed to the problem and has consequently boiled the frog already. Anyway, there are absolutely tons of variables, and the weight of those variables differs by organization. Let's not forget that Google created Go primarily because their top two issues with C++ were 1) compile time and 2) ability to train developers to expert levels.
It doesn't look like that is unsound.
&gt; well-formed C++ can do the same things with smart-pointers, etc. * Smart pointer guarantees aren't as robust as Rust's move/borrow semantics. Examples: iterator invalidation. * `std::move` &amp; Copy Constructors require a lot of buy in, and still fall short in cases a lot of cases, also there is a massive world of complexity when it comes how different value classifications are handled. * `std::move` &amp; Copy Constructors require developers _explicitly_ avoid doing a lot things the language fully permits in order to ensure their guarantees are followed, with with Rust this is immediately obvious as `unsafe` will appear.
One can read from hyper's `Request` with `for chunk in req.body_mut().wait() { ... }`. How do I read in terms of lines (that is, separated by b'\n') instead of by arbitrary chunk?
That depends on the question: &gt; does &amp;T have to point to allocated memory (with at least size_of::&lt;T&gt;() bytes being allocated)? If yes, does the memory have to contain data that satisfies the validity invariant of T? (at the point of `let mut buffer = ...;`) At the point of `&amp;mut buffer[..]` this depends in turn on: &gt; is it ever allowed to have an uninitialized bit in an integer or floating point value? And you should assume that the answer 1-2) are "yes" and 3) is "no" until decided otherwise.
I use pyo3 in production. Shuffling gigs of KDB columns to bumpy. No worries since I helped them fix their use after move bug.
While the question remains, these other details also exist: 1. The std library uses this in several `read` implementations. Is std also unsound? Maybe... 2. If it's decided that it's UB, one would assume libstd would need to update, and for versions where it isn't updated, it *seems* reasonable to assume that the compiler wouldn't skip libstd's version, but trigger something bad in other crates.
Small advice, learn not to argue with people who aren't worth arguing with. Some things I appreciate about Rust relative to C++: * First-class slices and views. C++ still does not have library-level slices standardized. * Ranges - not in C++ yet and crazy implementation anyway. * Invalid reference/move checking. C++ doesn't have this. * Proc-macros + include_str ... C++ can't even touch this right now. * Compile-time generic constraints (concepts in C++.. I think not standardized yet?) C++ does have some things Rust doesn't surrounding its generics implementation.
Your coworker is the typical modern c++ delusional, there are many.
A lot of Rust's best features are non-features that it does not have: * Exceptions (as you say) * Constructors * Implementation inheritance * Multiple inheritance * Implicit conversions * Implicit copy construction Instructively, most of these features interact with most of the others to create obtuse corner cases.
&gt; The std library uses this in several read implementations. Is std also unsound? Maybe... The standard library is blessed and can assume implementation details about the `rustc` version it is shipped with e.g. in terms of what optimizations it does and does not exploit. You should *__not__* read the lib{core,alloc,std} sources and assume that you can also do what it does. We are also moving away from `uninitialized` in the standard library as well. &gt; [...] it seems reasonable to assume that the compiler wouldn't skip libstd's version, but trigger something bad in other crates. As aforementioned, the compiler for those versions is already frozen and won't suddenly exploit UB it didn't before. The problem is that future rustc versions may and `uninitialized` in crates that use those rustc versions could suddenly start miscompiling.
Thanks for the balanced opinion. &gt;In general, I wouldn't be too aggressive with the "Rust &gt; C++" push. Yeah, which is why I have been trying to act more like a Rust proponent, rather than an evangelist.
&gt;Rust's match statement is also pretty darn powerful. I love how Rust is basically an ML disguised with curly-braces. That and a whole lot more...
Yeah everybody on the team ends up wearing a lot of hats throughout the day. I took up Rust in my free-time (it was on my list of things to learn), and so I don't blame them for the push-back.
&gt;Headers and dependencies are nothing short of a nightmare. This is why I hate working with C/C++. Heck, even Go has a (mildly) better dependency store than C++. I've gotten too spoiled with package managers.
My apologies, I guess I was confusing the defined nature of when it would run with the idea that it must run. As per the docs: &gt; forget is not marked as unsafe, because Rust's safety guarantees do not include a guarantee that destructors will always run. So yeah, I was wrong. Thanks for letting me know.
&gt; * header files with Well, I am a C developer and I do like header files. They allow to specify the external interface of a dynamic library. If at some point in the future Rust has a stable ABI, and dynamic libraries become a thing in Rust, I would be interested at how it would solve this issue without relying on header files or the code itself. Since linking dynamically to Rust libaries with its ABI is probably difficult, those header files might be binary an generated when compiling...
&gt; Rust lacks exceptions and their subtle problems. This is not quite true, Rust has panics which have all the subtle problems of C++ exceptions. The primary difference is that Rust sidesteps the memory unsafety problems with exceptions because most code isn't in an `unsafe` block, though of course within `unsafe` blocks there be dragons. For example, you can search for uses of `SetLenOnDrop` in the `std::vec::Vec` code. I think in most cases this issue is called unwind safety since it's not the panicking that could be unsafe, it's the unwinding (aborting is always fine).
My favorite explanation of why rust is from this Bryan Cantrill talk about language's values https://youtu.be/2wZ1pCpJUIM
&gt;iterator invalidation I was recently writing some tricky iteration code where I wanted to delete items I am iterating over. “Hmm,” I thought, “will this invalidate my iterators like in C++ or Java?” E.g. in Java you can safely delete through an iterator without invalidation, but would invalidate when manipulating the collection directly. The Rust docs were of course silent on the issue. Then the lightbulb went off: iterator invalidation bugs are **impossible by construction** because the borrow checker outlaws this. Similarly, the C++ “I'm holding a pointer to a vector element but am pushing new items into the vector” maybe-bug. That kind of safety is seriously awesome, with the flip side being lots of boilerplate generics when you need similar safety guarantees for your own types.
Besides anything else, I thought I'd share an anecdote. I maintain a Rust implementation of the liquid template language. I wanted to speed it up by reducing clones. I switch a major trait to return references, updated all of the clients, and was good to go. I could make a similar refactor in C++ (using things like the new `string_view`) but I would consider the code unmaintainable after that because anytime I make a change, I'd have to re-analyze the borrows to make sure I wasn't breaking a previous assumption. A lot of people say "thats solved with static analysis". Maybe for basic cases but I doubt it could help with my whole library and the clients of it.
If you actually allow any form of 'developers can accomplish the same thing by hand', then you're going to be fairly out of luck I think. Suggest any form of turing-complete language instead of C++ as they can all do the same things.
&gt; I also liked being completely free of exceptions in Rust While thankfully the standard library avoids panics for expected errors, Rust still has panics/exceptions. Especially integer-overflow panicking (or even worse silently producing incorrect results) is very difficult to avoid.
Hey everyone, I want to thank everyone that took the time to respond to my question. Over the next few months at work while we refactor, we should have a few opportunities to replace some of the components in our backend with Rust. I'm going to suggest it as we refactor and rearchitect. Hopefully the rest of my team will be open to the idea and agree. I'll post here about my experience and any less learned. Hopefully someone will find it helpful. Thanks again!
Isn't that just on debug. There's also overflowing\_X
As a person learning both cpp and rust, could you explain/provide some examples where this is the case?
Rust offers a safety net for the new guy. I have decades of software development experience, but my only C and C++ was a few semesters at school before my career began. Rust makes me feel like I can do systems programming without some catastrophic accident. Sure, a seasoned C++ programmer might not care about protections from pitfalls, but I want to learn all those lessons at compile time instead of run time.
Well, don't forget that it's still possible to write incorrect code like this: fn foo(buf: &amp;mut Vec&lt;T&gt;) { for i in 0..buf.len() { if cond(&amp;buf[i]) { buf.remove(i); } } }
&gt; but so many of the packages I’ve seen are written from an implementing-an-interesting-search-algorithm perspective and not an actually-returns-what-the-user-wants perspective Indeed. If you really want to knuckle down on this, I'd recommend building an evaluation, [like I did for imdb-rename](https://github.com/BurntSushi/imdb-rename#evaluation). You'll need to build out some [truth data](https://github.com/BurntSushi/imdb-rename/blob/master/data/eval/truth.toml), but it's overall not that much work. And once you have it, it's really nice, because it's like having unit tests, but for the _quality of your fuzzy search algorithm itself_. It makes it much easier to iterate on improvements with confidence that you aren't significantly regressing on the user experience. If you want to talk more about this, I'd be happy to chat!
Built-in memory safety. Ownership model and borrow checker ensures that your values aren't being thrown around all over the place. '''rust fn main() { let mut x = 1; { let mut y = &amp;mut x; let z = &amp;x; } } ''' This program won't compile becuase you are using an immutable variable while there's a mutable variable in the same scope. This is something the C++ compiler doesn't check for, but this feature ensures safety. What if you modify 'y' and then read from 'z' expecting the previous value? Something else that is also amazing in Rust is the multithreading. It is much easier to keep an eye on who's accessing what, instead of using the 'mutex' keyword in C++. There is a full talk about this here: https://youtu.be/k7nAtrwPhR8
A 1:1 comparison is tricky because the languages value different things. Rust values safety, simplicity, and ergonomics. C++ values raw power, expressiveness, and C compatibility. To the three things you mention: * package management is a huge quality of life improvement and makes it easier to start new projects, but is less of an issue in established projects that have already found a way to handle their dependencies. * hygienic macros are great, but does typical C++ code use that extreme macros? Note also that many things where you need macros in Rust can be handled by C++ templates, e.g. variadic arguments. * The lack of templates is both a selling point for and huge point against Rust. Sure, generics are sane, and how they work with traits is great, but they can do so much less than templates. * ADTs make programming easier, but this is also a question of programming style – Rust encourages the functional. Aside from the borrow checker, which is game-changing, the biggest noticeable difference is probably that Rust gets rid of all of the C remnants that bog down C++. Modern C++ avoids all of these C-isms (e.g. smart pointers vs raw pointers), but there are *so* many pitfalls to be aware of. Experts know how to avoid them, but it's too easy to make a mistake. Rust doesn't have these pitfalls. Rust is peace of mind.
Aye, yeah, although PG's trigram searching doesn't take corpus frequencies into account, so it's hard to do solid information retrieval with it. But that's taking the next step past simple fuzzy search. :)
It's possible to write incorrect code in any language, but that code is perfectly *safe* because it will panic.
Good point. Why not write "well-formed" assembly for that matter
Does Rust has union types a la http://dotty.epfl.ch/docs/reference/new-types/union-types.html ?
Literally everywhere from what i heard, but since i don't actually use C++, i can at least point at the most obvious thing. Assignment is (by default) a copy for values in C++. If you accidentally bit-copy a smart pointer instead of moving it, well congrats, you just started a chain reaction that causes a double free(aka undefined behavior). It's all about guarantees. You _can_ write safe C++, but you _can not_ accidentally write unsafe rust.
As someone o frequently bounces from OS to OS been able to use cargo alone is enough for me to never touch C++ ever again, You wouldn't believe how much time I've spent configuring xCode or VS Studio (even when using cmake mind you)
Spot on. The benefit of Rust is that the programs with the flaws of the suggested non-well formed C++ programs are not representable.
The provided snippet contains iterator invalidation bug in a certain sense. Such bugs will not always result in panic, so relying on borrow checker too much is ill-advised. My concern is that claim "iterator invalidation bugs are impossible by construction because the borrow checker outlaws this" can be understood incorrectly. It's like when we talk about preventing (data) races in mutlithreaded contexts, some think that Rust prevents race conditions in general, which in turn plays as a false advertisement.
Gently remind them that allocating small to medium sized objects on the stack and managing references to them is much more efficient that heap allocating any nontrivial value. Also remind them of how tricky managing those references is in C++, and then mention that rust just doesn't allow you to get it wrong. Besides, there is plenty of UB in C++ around aliasing mutable state, which is also not allowed in rust. IIRC, `int foo(int&amp; x, int&amp; y) { ... }` derps out if both references point to the same location in memory.
I liked the idea of this, but Glade was unfortunately essentially unusable on my Mac. Are there any examples of Gtk applications integrating well in the context of MacOS? I'm trying to evaluate its viability for current development. I'd really like to use Rust for GUI application development but so far I have not found any candidates I'd call viable.
It also isn't particularly helpful if you're frequently searching for 1 or 2 character strings because editor plugins are hitting your API every keystroke to auto complete Cargo.toml and the volume is at risk of impacting the stability of the service in the near-ish future. Luckily that's not something anyone will ever lose multiple days to.
Thanks. You bring up some really good points. I really appreciate it. It seems to me that majority of your points are more about ownership distribution: the more parties are involved, the more chance that something goes wrong / some is doing something not as you would expect them to. I'm mostly saying that because maybe a number of newly introduced crate owners would a good metric. Again ... I'm thinking about best metrics for `cargo-crev` to use. My take is ... if you take one of your crates and you split some bits into a sub-crate, it does not lower the quality of the whole. It might add some overhead for you, but for the users it's even better. So it pains me to "lower the score" just because you're doing the right thing (IMO). So maybe instead of counting the dep. count, I can count number of people your bring into into the picture (I do know owners from crates.io, so it's doable). And again - your points are good, but they are specific to your situation and what you care about, while I'm looking for as universally useful metrics as I can find.
I explained to some newer coworkers recently - you don't need programming `class`es or `struct`s. You could just hardcode everything. But that architecture sure makes things a lot easier to manage. Your friend is probably right in one sense about Rust "not having anything" C++ has. You could very likely make anything in C++ that you could make in Rust. And if all he's worried about is having *a* way to do something, C++ will probably fit the bill. But if your friend weren't overly invested in convincing themselves that the way they already do things is the best way (i.e. he is old and set in his ways), they'd realize that Rust offers so many things that make life easier. This is the sense in which Rust "has" something that C++ does not - a better way to do many common programming tasks. And don't worry about modern C++, there's 0% chance that your coworker even understands very modern C++. That's what C++ has become - a language large enough to do anything, and too large to do anything concisely.
The bug in your code is that it skips the item directly after the one it removes, so some items remain that should leave. Nothing else bad happens. Of course, you should use buf.retain(cond); instead.
In that case, just tell this guy that the Rust compiler *enforces* well formed C++, so why the heck is he using a shitty C++ compiler that doesn't do that already?
Yes [https://doc.rust-lang.org/rust-by-example/custom\_types/enum.html](https://doc.rust-lang.org/rust-by-example/custom_types/enum.html) &amp;#x200B; But not anonymous ones. &amp;#x200B; &gt;It seems like with Option&lt;t&gt; you can either assign a value or None but not "a value and None". &amp;#x200B; This doesn't make much sense because \`Option&lt;T&gt;\` means either a \`T\` or nothing. It doesn't make sense to have both something and nothing
I can see rust defining something similar to .pyi files in the future (Python stub files), and exposing them as a build product of a library, but i literally just thought of that so i don't know if anyone in the rust team has thought of this before
Maybe *for your coworker*. For a lot of seasoned devs. it seems "I know how to write good code, what do I need a good Rust code". But for a team or a business, it's much better to rely on tooling than hopping you can always find and hire experienced enough C++ developers. Not to mention just the quality of life improvement, when you can stop worrying that every single line of code can introduce remote execution vulnerability.
What is "safe" technically defined as? Is it just a guarantee against unexpected behavior? I know rust doesn't guarantee leak free programs
I'd argue it's not even true in the case of traffic accidents, but that's mostly irrelevant.
A good programmer would focus on building well-formed code. But any good programmer knows that's not enough. Sell it to them this way: Rust will have the compiler scream at junior devs when they do something wrong or stupid (such as keeping an iterator around after mutating the vector). Well-formed C++ requires that everyone does it, while your friend may be an amazing programmer, and their could would receive very little benefits from Rust, it's the programmers who would otherwise misuse their code, or who do dumb things, that have their code improved. The code that otherwise your friend (being a better programmer) would end up debugging. And not only that. The `unsafe` keyword is basically a way of telling newbie programmers: call someone who actually knows what they're doing. Junior devs shouldn't write unsafe code, it should be left to seniors. C++ will improve, and get a lot of Rust's nice-to-haves. But there's a core difference between the philosophies, and C++ will always allow people to do dumb stuff (unless you make your code very inefficient) if they don't know, and many coworkers are going to be like this. Rust is built on the idea that this is the work environment.
I have made Rust .DLLs and linked to them from C++ and also [from C# code](https://www.reddit.com/r/rust/comments/c0e5yf/i_created_a_rust_chess_ai_for_16x16_variant_4k1w/). It's actually extremely easy to do. Like all situations where C++ code is calling into a DLL, that code requires a header in extern "C" mode. Like all situations where C# is calling into a DLL, you need to use a decorator over a special type of static function.
[This](https://mortoray.com/2014/03/25/the-infernal-loop-iterator/) bug is not possible in Rust.
It does, with [enums](https://doc.rust-lang.org/rust-by-example/custom_types/enum.html), but the unions must be named, you can't define them anonymously inline as you can in Scala.
Haha then you're going to love this https://science.raphael.poss.name/rust-for-functional-programmers.html
Amen. I have never had as painless an experience with C++ builds as I have had using cargo run.
The primary benefit is memory safety (and thread safety, but per the Rust definition freedom from data races is part of memory safety). Modern C++ does not provide memory safety, it _does_ provide freedom from memory leaks which is something the C++ community has focused a lot on, and I've talked to C++ programmers who think that these issues are the same; that they've solved this memory safety thing because they don't have leaks. Modern C++ provides quite a few niceties and in many cases makes memory unsafety bugs marginally harder to write but it does not by any means fix things. For a few examples: [I love this bit from Nicolai Josuttis's 2018 Meeting Cpp talk](https://youtu.be/9-_TLTdLGtc?t=1357). &gt; There are some style guides that say "beware of the range-based for loop." That's strange. This is such a nice invention... and we have to think about when to use and have to use it carefully. [There's also Jason Turner's excellent talk on Surprises in Object Lifetime from CppCon 2018](https://youtu.be/uQyT-5iWUow). I think the title basically says it all. It should be noted that Rust eliminates all the lifetime problems mentioned here; the equivalent examples wouldn't compile if written. There are also other problems with the various other modern C++ features; again while they definitely let one write better C++ code they don't provide memory safety and in most cases make less common the typical mistakes, they open up other nastier and more subtle failure modes. /u/oconnor663 already linked the excellent part of Herb Sutter's talk that outlines the problem with reference-counted pointers in C++. It's been joked that `std::string_view` should be renamed `std::use_after_free` because it's so easy start swapping it in for uses of `std::string` and create use after free because of C++'s subtle lifetime rules. Even worse in my opinion are the rules around `std::optional&lt;T&gt;`; which overloads `operator*` and `operator-&gt;` which are UB if the optional doesn't contain a value, and has a member function `.value()` which throws if there is no value. This is backwards from almost all of Rust's API design where the unsafe or less-safe things are harder to type. And you can't put a reference in a `std::optional` because it couldn't be decided what should happen when assigning to one. Such a question is absurd in Rust, and _that_ is the value you're getting over C++. The language doesn't add features or make you more powerful. Rust is a more restricted language; you don't worry about what the semantics of `=` are or if breaking up a long chain of calls with an assignment to a value creates a use-after-free.
Rust is 5 languages stacked on top of each other, except that instead of ending up like 5 children under a trenchcoat, they end up like the power rangers.
Yes, that's a good point. Number of distinct maintainers is indeed perhaps a better metric for my specific pain points than total number of crates. But it's a fairly opaque thing that's hard to see from a list of dependencies. `crev` making that more transparent would definitely be a concrete benefit. And yeah, splitting crates into more sub-crates is something I've done a lot. There's a constant tension there, for me, because I really want to keep total dependencies down, but there's always a damn good reason to split them apart. For example, if Rust's regex crate were like most regex libraries, it wouldn't have any dependencies at all, sans libc. But Rust's regex crate has several, even though the total combined code roughly approximates what you would find in other regex libraries. &gt; (example: I wouldn't mind MPL subcrate, but it makes me thing that this would be an useful metric as well, and integrating it might make sense too) Sure. Perhaps a "copyleft" metric instead.
And more so, you don't need to be afraid that someone else is going to come along and miss a subtle undocumented restriction which was previously making the C++ code "Safe" that they then go and trample on.
And even if development teams could guarantee their code, that isn't even the whole story. Every dependency needs to be clean as well. That said, the issue same exists in Rust also. The Rust community still relies heavily on software written in C &amp; C++ (libc, libunwind)
If your colleagues like numbers, I love this one: one of the devs of [Servo](https://servo.org/) wrote a [very interesting blog](https://hacks.mozilla.org/2019/02/rewriting-a-browser-component-in-rust/) post about using Rust at Mozilla. She analyzed all the critical bugs that ever occurred in the styling component of Firefox, and found out that 51 out of 69 of them (that's 74%!) would not have been possible, had Rust been used since the beginning.
did you run clippy (https://github.com/rust-lang/rust-clippy) through your code?
Traits and concepts are different tools. They both look similar to each other and try to solve similar issues, but traits are nominal, while concepts are structural (duck typed). So traits let you define much stronger constraints than concepts, but concepts can give you a lot more flexibility than traits (too much when you don't know it's there imo). One of the last "This Week In Rust" linked to a discussion about this topic
&gt; You can write safe C++, but you can not accidentally write unsafe rust. I like that a lot!
Looking at it another way what would you have to change in C++ to make it match rust: * Package manager. This is no small thing. Dependency hell is a place I have spent much time. Entire project timelines have gone to hell because of this over and over. * Package manager. Needs to be said twice because of the 9000 advantages it brings such as making it way easier to keep things up to date vs the usual dependency hell where one upgrade here breaks something else. Also I have often had to make minor tweaks to some library to get it to mesh well and thus just upgrading it won't work without my trying to remember what hell I went through 5 months ago. * Getting rid of the boomers in charge of C++. The people running C++ are just... old. The people around them are old. Recently things have gotten better with faster releases, but C++ is more and more tailored to people who are way too hard core and pedantic about stuff. For instance mention C/C++ and people loose their minds. The reality is that I know a whole lot of embedded programmers who lived and breathed C for decades and when they program in C++ they very much program in C/C++. Defragmenting C++ compilers. Only recently have my favorite C++17 features become fairly universal and I am pretty sure that not all C++ features are really in all the major compilers. Eliminating the need for boost. I'm not saying boost is bad. It's just that the need for it to exist is just awful. Shut up with the templates: Templates are a nightmare for ugly code. Templates have their places such as enabling things like maps. But I see people who pretty much template an int. This is not where the majority of programmers want to go. Performance, threads, microservices, wasm, GUI, etc are areas that people scream for every day. Qt (expensive as hell for commercial use) is pretty much the defacto desktop gui. WTF? Fix this. And finally... The culture. It is vital, vibrant, moving at the speed things in 2019 should move. I don't really want to see another video from CPPcon where the whole thing should have been in a one page blog entry knowing that it is probably way worse at the ISO meetings. You just know the discussions at these places are made up mostly of arguments about how many angels can dance on the head of a pin. Whereas I suspect a rust conference would be a bunch of people showing off the really cool things they did this week.
I'm new to rust so this was news to me. Here's a good page for anyone else wanting to read about it: [https://doc.rust-lang.org/nomicon/leaking.html](https://doc.rust-lang.org/nomicon/leaking.html)
I wrote a similar `IntoIter` implementation last night. I'm totes replacing the hardcoded type with that. It definitely spells out the dependency clearly.
You should check out [tlborm](https://danielkeep.github.io/tlborm/book/README.html), it's invaluable if you want to use macros in general. Specifically what I think you need is a [helper macro to perform replacements](https://danielkeep.github.io/tlborm/book/pat-repetition-replacement.html) with a [counter](https://danielkeep.github.io/tlborm/book/blk-counting.html) built in. I don't know specifically which counter is going to be best for your use case, but those are the 2 concepts I would play around with to try and sus out a solution.
There are some really great points here, so I upvoted them. In general, I love Rust and would prefer to work in it when compared to C++. The amount of time I spend tracking down silly memory issues when programming in C++ is ludicrous (lol maybe I'm bad at programming.) I Just want to add though, that there is something I miss from C++: &amp;#x200B; Template meta programming is just so powerful. Its not perfect certainly, but after using Eigen, I just don't see how I could possibly implement a dimension agnostic, linear algebra heavy data structure in Rust and not compromise on performance characteristics. In general, all of the compile time templating / preprocessing features of C++ represent very powerful tools that are not present in Rust in the same capacity.
C++11 land 17 are good enough I guess. Enough so that it's not worth the debate. If someone insists you can just be "good enough" to not require the borrow checker then let the issue lie. Personally Rust proves itself in action: Servo in the wild for example, internally we just had a guy have a "that's slick" moment one day into working in Rust, and eventually your coworker will do something incorrect with something in C++ and either be professional about it or not. Having more bullet points than the other guy isn't really important in the end.
Not to downplay your work, but you've essentially recreated [cargo search](https://doc.rust-lang.org/cargo/commands/cargo-search.html).
Why not the code itself, or generated from that? My main problem with header files is the pita consistency.
&gt; If you accidentally bit-copy a smart pointer instead of moving it, well congrats, you just started a chain reaction that causes a double free(aka undefined behavior) True, but I can't imagine a situation where you would do that accidentally. I'm with you on the idea of C++ being generally unsafe unless you try to make it safe, but smart pointers are one of the few places where it's pretty hard to fuck up
Another nice aspect of cranelift is that it will make Rust more self-hosting in a sense (no LLVM) since it is implemented in Rust. :tada:
If you include doing multi-point inspection every time you about to start a car then it's true. Majority of car accidents are happening because of dumb people doing dumb things that go against traffic laws. Some happen because of car maintenance was not properly performed and it lead to loss of control in case of accident. Some happen because things that installed at the factory were defective — i.e. rubber disintegrate at speed lower that rubber is rated for or wheel cracks. It's a good analogy IMO.
I wrote about how [rust is making you productive without cutting corners](https://llogiq.github.io/2018/04/03/corners.html) more than a year ago, and I still think that is the main selling point. Or as I said years ago: If C is like playing with knives and C++ is juggling chainsaws, Rust is like parkour suspended from strings and wearing protective gear. It'll look ridiculous at times, but you'll be able to do all sorts of cool moves that would otherwise be damn scary or outright impossible. You'll have so much fun you'll start trying to do it in other languages, too. And many of us never look back. Also you get new improved gear every six weeks, and between this and your newly built muscles, you start feeling like a super hero. This feeling is amplified by the community, which simultaneously does awesome feats and is really humble and open about it (you're by now accustomed to people being good at concurrency, and get slightly annoyed that your snake-charming friends insist on doing everything one step at a time). You also met some folks you wouldn't have expected here, from a number of dynamic languages, braving the learning curve to descend into low-level programming, usually singing Rust's praises with unreal sounding benchmark comparisons. You start looking with pity at your knive- and chainsaw-wielding friends. You see both their bruises and denial about said bruises. You'd want to offer them some of that awesome protective gear (by now you no longer feel the strings, because they seldom get taut), but you know the answer already. Poor folks.
Probably the biggest reason is license compatibility with Rust itself, so that if e.g. the rustc team or any of the dev tools teams like your work, it could feed back into their own work and improve the overall Rust experience. But in the more general case, it increases license compatibility all around. For a project like yours it may not be that big of a deal, because MIT is already fairly unrestrictive, and Hashcow is fairly niche. So it's entirely up to you what you decide to do.
[Hah well I'll be damned...](https://www.youtube.com/watch?v=7qXXWHfJha4)
`C++ doesn't offer anything that x86 assembly doesn't already have`
SGX. No thanks.
Update: It was missing copy elision in debug mode. Ouch.
"Well-formed assembly can do the same things as c++" The point is that the cognitive load for the programmer is reduced. That the requirement that the programmer is knowledgeable and disciplined has been reduced. If he wouldn't accept that argument against c++ and for assembly, why would we accept his argument against rust and for c++?
One of the big pitfalls in `unsafe` Rust code is taking a raw pointer out of a temporary `CString` (since you're often using `unsafe` to call into C) and forgetting that it's about to be destroyed, like this: unsafe { let c_str = CString::new("hello").unwrap().as_ptr(); libc::puts(c_str); // Undefined behavior! } This is exactly the same as the the temporary lifetime issues in the C++ videos you mentioned. It's _really_ easy to do this sort of thing accidentally. Staring at that example for a few minutes makes it clear how incredibly helpful it is that this mistake will never compile in safe code.
What have you done u/steveklabnik1...? =P
Afaik wasn't that the goal of the rust language, originally?
This might be a good nomination for quote of the week
Your colleague sounds more stubborn than learned. I'm a veteran C++ developer - 26 years of professional use, contributions to the standard, talks, etc. I've had heated discussions (arguments) with Bjarne. Admittedly, only twice, but I have. So I'm not coming from nowhere here. I'm also a platform architect who chose to use Rust for my current professional project, and have a team of (mostly) former C++ devs working on Rust. Rust offers three things C++ cannot, beyond the niceties of cargo. 1) Mandatory RAII. While sufficient discipline, some static analysis, and rigorous code reviews can get close to this in C++, it isn't easy to enforce, and a lot of things get constructed into a not-really-valid state, require extra checking (easy to forget) in destructors, etc. 2) Destructive move, invoked by default when passing. This is a lot bigger than your colleague realizes. It's a lot bigger than I realized before I started using rust professionally, some 18 months ago. It's also a massive pain in the ass when you want to have internal references/pointers, but that, too, is rather revealing of a fragility of C++ that has actually bitten me a few times without me ever putting the general cause together in my head... because I've always manually re-addressed the internal pointers on move, just as with a copy, and never thought about how easy that was to mess up without any static detection. 3) Global, pervasive, and uncompromising static ownership analysis. This one is Rust's big advertised claim, but it is more significant than most C++ people think. Make no mistake, this catches and prevents bugs and races that no existing C++ static analyzer can, even using the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md)... Rust also offers some nice to haves. The symmetry between static and dynamic usage of traits, pattern matching, and the safety and reflection capabilities of Rust's macros are a breath of fresh air, and the built-in slices and traits-based operator sugaring are actually nicer than the function overloading model of C++... but Rust generics feel clunky and crippled next to C++ templates, even with associated types, and the lack of a robust constexpr analogue is disappointing.
And some happen because people can be following the laws and have a perfectly well-maintained car, but a small lapse in judgement quickly ends up in a crash. Just like how you can be following every good practice in C++, but at some point you double-free a pointer and your program crashes a few functions later with no clear cause pointing to the faulty line.
I'd struggle to believe anyone sufficiently seasoned in C++ isn't fully aware, great language it may be, of its many shortcomings.
This. This seems like its the real issue, and its a valid one. Of course, if adoption curve was the only criteria we'd probably all still be programming in BASIC :)
&gt; People are generally utterly terrible at keeping things in mind As demonstrated by how often the rust compiler has to yell at you about them.
Thanks. Yes, I already got the callback technique from there. I think that my problem is that any macro will create a single nested group, but really I want to extend a call list with a few more items. So I can't quite see how I can apply those techniques without having something like a "flatten" operation to squash the nested group down into just one list. Maybe there's a way I don't yet see though. I'll have another go later. BTW, the original code does work, although it means introducing temporaries in the calling code in various places. My aim is to tighten things up to simplify things and to aid maintenance.
It's also about what rust calls the fearlessness. Yes, you can keep all those things in your head but wouldn't you rather the compiler does so you can keep more of the problem in your head?
Panics are a good middle ground between expected errors like IO, and undefined behaviour. They should be used to indicate that either an api has been used incorrectly (if this cannot be expressed in the type system), or that a bug has led to a code path being taken that shouldn't have been. Panics are competing with UB, not exceptions. In, say, python, you expect to get exceptions and handle them (you "ask for forgiveness, not permission"). The rust equivalent here is algebraic types (`Result`). One of the key innovations of rust is that you ensure no code paths lead to UB, that they lead to crashes instead. (And in rust a crash is: you neatly close all resources you are using and wind up execution, not abort and leave everything in an inconsistent state). Of course, panics can be misused, but misuse just leads to crashes, not UB/security vulnerabilities.
Taken to the extreme, C++ doesn't offer anything that C doesn't already have.
C++ smart pointer can't provide static guarantees, merely dynamic ones, and that's even only *if* you use them correctly. If you use them in convenient ways (operator -&gt;, etc) they will produce UB in some case of programming error. So much for their safety. You can do vast amount of UB by merely using lambda with refs, or templates with refs (notably rvalue refs), or even just plainly reusing moved-from objects. And so over. C++ is basically UB hell, and it obviously won't be fixed in a sound way, and although it *might* become somehow better in the future I do not expect that to be quick... If by "well-formed" it is meant without bugs then this is a useless tautological statement: if the programmer writes no bug, the resulting program contains no bug; yes, so?
&gt; You can write safe C++ Theoritically. In practice I've yet to see that. That would be quite an interesting thing to witness, actually :)
Have you checked the openssl crate? It has an \`rsa\` module that should support what you're looking for I believe. I've used it to implement public/private key de-/encrypting of messages specifically for use from Node.js actually.
&gt; They allow to specify the external interface of a dynamic library. So do visibility modifiers, which are already a core part of the language, inline with the rest of the code, and easier to maintain in general. &gt; If at some point in the future Rust has a stable ABI, and dynamic libraries become a thing in Rust, I would be interested at how it would solve this issue without relying on header files or the code itself. Rustc emits an `.rmeta` file early in compilation that acts like a header file for dependent crates, so they can query paths and type/borrow check against it without waiting for the object file. &gt; those header files might be binary an generated when compiling... Exactly :)
 auto pouet = std::make_unique&lt;foobar&gt;(); ... yolo(std::move(pouet)); ... pouet-&gt;ub_me_hard(); You might not write that directly, but it's quite easy to end up with that kind of things with e.g. a few loosely documented templates.
Strictly speaking, “safety” in rust means “memory safety.” There are additional things as well, for example, (with the exception of unsafe Rust) there’s no undefined behavior. But the big point is memory safety without a garbage collector.
This is kind of correct but also super wrong; * In C++, a default copy constructor is created for your class if it has no other defined constructors or destructors and it is trivially copyable, meaning that all of the objects it’s composed of are trivially copyable. * One of the standard library smart pointers is unique_ptr. They are a move only type, meaning they can’t be copied because they define a move constructor and don’t define a copy constructor, meaning that they are a non-trivially copied type. * Any class that owns a unique_ptr has to define its own constructors. Of course there’s ways to still have a use-after-free with unique_ptrs, but this is a contrived example to show that C++ offers much more type safety around stuff like this than people think, because they only did a class in it where they got taught C++03 or something.
ELI5? What do you mean Rust still has panics / exceptions? Isn't everything that could produce a panic wrapped in a Result/Option/other thing?
Some of this is coming; const generics is on the roadmap for this year, for example.
No, there are many things in the standard library that can panic, like indexing into a slice. I generally prefer using non-panicking versions, but it's not something that is tracked by the type system.
C++ smart pointers do provide a number of static guarantees. Just... not as many as the borrow checker (and in some cases, at higher cost - think heap vs stack for small types where unique_ptr is the closest counterpart to default move).
Shared pointers have significant runtime cost compared to references. Unique pointers are not as flexible as Box, since you cannot have a virtual deleter.
Ah, interesting... I wonder if there has been any talk about eliminating them by replacing with safe APIs?
Why buy a table-saw with a safety guard built in when I can just not cut my fingers off instead?
The reasoning I used when I decided on Rust was simple. I trust myself to write safe, correct C++ most of the time. At this point, I'm going to make mistakes about as often as I'm going to find ways to do something wrong in Rust that the compiler doesn't prevent, e.g. almost never. I don't trust most senior C++ developers to do the same, and I don't trust any junior C++ developers. I don't want to spend all of my time reviewing in depth every decision one of my devs makes. I can train a suitably intelligent and willing C++ dev to a satisfactory level given a few months. I can train an intelligent Python or even JS developer to a comparably useful level in Rust in a couple of months.
What makes c++ special is variadic templates, as well as tplsye specialization. The lack of these severally hamstrings what you can do in Rust, particularly in numerical computation. Rust shines in robust client code, but often makes development difficult and convoluted.
Well, astonishingly few for my taste. They are nullable &amp; the simplest syntax for deref invokes UB if null. So *of course* in C++ I use them instead of raw ptr + new / delete, and most of the time it's fine because there is no move, no .reset(), etc. That's still not a strong static guarantee. Merely a way to write no bugs when paying attention to write no bug, only this is now somehow more easy.
There are some things that probably should be replaced/augmented with safe APIs (I still don't know why `slice::split_first` returns an option but `slice::split_at` panics on invalid values.) However, there are many situations for which a panic is the only reasonable response - running out of memory, for example - so there's always going to be a possibility of panic.
It is almost this simple now, just implement [`ArcWake`](https://docs.rs/futures-preview/0.3.0-alpha.17/futures/task/trait.ArcWake.html)
&gt; small lapse in judgement quickly ends up in a crash Example of such lapse that isn't related driver or drivers around that isn't breaking traffic law?
Yes, after reading the post my advice was going to be the same - unless there is a good reason, this is not a worthwhile argument. To have an argument would mean to teach this other person both C++ and Rust, as they clearly don't know *either* well enough to have the conversation as is.
&gt; Stabilize support for Profile-guided Optimization 🎉🎉🎉
&gt; Sell it to them this way: Rust will have the compiler scream at junior devs when they do something wrong or stupid (such as keeping an iterator around after mutating the vector). I would go one step further, and point out that rather than "screaming" (PHP actually does scream: look up `T_PAAMAYIM_NEKUDOTAYIM`), the compiler is actually unbelievably helpful at *teaching users how to use the language*. The error messages it prints are light-years better than almost any other language I can think of... although Haskell and friends come closest. With that in mind, you're not just saving the time you'd spend code reviewing/fixing bugs from newbies, you're *also* saving some of the time you'd otherwise spend helping them figure out how to get their code working in the first place.
Hell yeah! It it possible to use this with `cargo`, already, or is there an issue to follow?
I think this is quite rare, and easy to spot, because the problem tends to be local to the function. I would not oversell this as a "key" advantage of Rust
You can also argue that "well-formed assembly" can do the same things. The problem all these different kind of languages try to solve is reducing human efforts and error rate on making things "well-formed". Choosing a language is basically a management problem so arguing that we can do things in x as well with the y trick doesn't really make sense.
In Rust, it's easy to write safe code: Just make sure it compiles. In C++, it's easy to write safe code: Just make sure you don't write unsafe code.
What makes you think they don't know C++ well? In my experience, programmers who work mainly in one language can become completely oblivious to its faults, and solutions to those problems are seen as just unnecessary complications.
Tbh I don't think you are going to win the argument. My advice in office politics on tech would be to ignore him. Win over others with the cool parts of Rust. Teach them. Help them. Show off cool stuff. Get them thinking *"wow this is a great language"*. Either he will end up out voted, or your company is a stubborn C++ shop and that's that.
If you are doing any threading, smart-pointers are no longer straight-forward. Without careful use of atomics, race conditions can lead to problems. &amp;#x200B; Also, "well-formed" is fine on a team of 1 or 2, but if there isn't someone strictly enforcing the style-guide, it will get broken when there is a deadline and "I just need to get this one thing in". With Rust it is effectively \*impossible\* (barring cornercases like unsafe) to abuse memory safety. You don't need a style-guide enforcer, because the language acts as one.
Also, don't smart pointers give a not insignificant amount of overhead, where as Rust's borrow checker is zero cost?
But the funny thing is, as you get more experienced the compiler stops yelling at you because you already takes care of it. I believe a bunch of expert C++ devs already do that, a bunch of them even came to Rust and realized they already were careful enough, but Rust isn't only about them, specially because everybody has a bad day.
C++ concepts have been standardized (and they're more powerful than Traits, as one might expect given that they're built to work with the template system) as part of C++20. Of course, that means it'll be ten years before anyone gets to use it in production... C++ Concepts link: [https://en.cppreference.com/w/cpp/language/constraints](https://en.cppreference.com/w/cpp/language/constraints)
Generics, virtual methods, and RAII smart pointers are pretty huge productivity features. The key advantage to Rust is ownership analysis, and that can take some effort to sell.
...We can dream tho...
The following has a broken link (full stop at the end of href): &gt;[disposition: merge] Tracking issue for the cast method of raw pointers
It's like driving a car without safety belts. It can still do all the same things as a car with safety belts but when things go wrong they can be fatal.
Please correct me if I am wrong, but you cannot have a \`const unique\_ptr&lt;...&gt;\` in a struct and then trying to \`std::move\` such a struct (perhaps you cannot even return it from a functrion). You cannot do a move unless you \`const\_cast\` that \`unique\_ptr\`. If I remember correctly, this is because a move in C++ resets the unique pointer, and you are not allowed to do such an operation on a const object. To me, that looks like move semantics in C++ is not up to par. AFAIK, Rust move semantics allows you to move non mutable objects just fine in every possible situation.
/r/playrust
Yes, most of Rust’s guarantees are static
The reason I discovered Rust was that I was looking if there was some way to prevent use-after-move in C++. But the C++ type system *can't* protect against use-after-move. Rust can. Then after starting to use Rust, and discovering how good enums and cargo are, it makes going back to old C++ projects pretty painful.
oh shit my bad, i just hopped on this sub on my pc
True, and important point. But I appreciated the clarification because the comparison to Java made it sound like that panic-inducing bug was impossible.
By the same logic, well-formed C can do the same things with custom implementations of smart-pointers, etc. If you don't care about portability, then well-formed assembly can do it as well.
Small nit; one could probably implement Eigen in Rust without compromising on performance because Rust also has two or three Turing-complete compile-time languages (types, traits, macro expansion). They're just _even worse_ for this sort of thing than Eigen and using such a library would probably be so difficult with such absurd compile times nobody would bother. The preprocessing features I'm quite happy to go entirely without. The preprocessor is one of the biggest regrets of the standards committee; it does so so little that templates cannot and unlike all the other footguns in C++ also invisibly mangles your source code.
r/playrust
All good, baby girl. ♥️
Unfortunately, zeroing buffers shows up in profiles in networking. I assume that even switching to `MaybeUninit` would have the same theoretical UB if we just cast the pointer to a slice, like `io.read(slice::from_raw_parts_mut(buf.as_mut_ptr(), len))`. Is the correct option to use `libc::read`?
Ill quote linus, because, frankly I agree, and more ever, I think C++ is worse than Java. I have worked with C++ committee members on production applications that are highly difficult to maintain. If the sole fact I will not have to deal with any committee member by switching language, that is my selling point. They are the most ego driven and "lets make it more complex than the theory of god particles". Run, and pray i never have to touch c++ again. &amp;#x200B; "C++ is a horrible language. It's made more horrible by the fact that a lot of substandard programmers use it, to the point where it's much much easier to generate total and utter crap with it. Quite frankly, even if the choice of C were to do \*nothing\* but keep the C++ programmers out, that in itself would be a huge reason to use C."
&gt; However, there are many situations for which a panic is the only reasonable response - running out of memory, for example You can hand control back to the program and give it the opportunity to free memory (e.g. kill caches), once upon a time that was actually a quite common practice. Off-hand I'd say that there should be panic-free versions of *everything*, that the panicking versions then are built upon. Whether panicking or not is the default for any given thing is an orthogonal question... I'm reasonably sure that for most apps, with today's address spaces and not to mention overcommiting operating systems, panic-on-OOM is a sensible default, but the option to do things differently should be there, and not just in no_std. If it's not a power failure or SIGKILL, let me handle it!
Deer or other animal suddenly and unexpectedly running in front of your car. Or, flat tire due to debris on the road.
In either case you would assert that you have a valid `&amp;T` where in fact the data referred to is undef at the point where you do `slice::from_raw_parts_mut(...)` and that would be unsound, yes. This follows directly from what the docs of `.as_mut_ptr()` say, namely: &gt; Reading from this pointer or turning it into a reference is undefined behavior unless the MaybeUninit&lt;T&gt; is initialized. &gt; Is the correct option to use `libc::read`? Feels rather low level but it seems OK? Working on `*mut [u8]` or `&amp;mut [MaybeUninit&lt;u8&gt;]` is probably more rusty?
I hadn't heard of Seed before. Is it front end (compile to wasm) only, or does it also have a backend component? I looked at the site really quick, but I couldn't tell.
I don't see how you can ask the questions they're asking and say the things they're saying if they know C++ very well. For example, it is a common mistake to compare smart pointers to the borrow checker, and demonstrates a misunderstanding of both features.
Right, there's no way to use those with `std::io::Read`, and any adapter would be violating the rules, whereas `libc::read` takes a raw pointer. But my point is that without a realistic API, people will just ignore the claim that it's possibly-UB-someday. And the more code that does that, I imagine it gets harder to actually decide it *is* UB.
I'm pretty sure all of those productivity features can be achieved in pure C, albeit not out-of-the-box. For example, see Cello, APR, NSPR, GObject, etc. But my point is that, provided two languages, it isn't very meaningful to compare them by asking what "new" features they have to offer. I think Rust's strong point is its paradigm of uncompromising safety. Most other languages can only achieve this by disallowing mutability entirely, or by requiring a GC to manage shared memory.
Tell him that there's nothing you can do in C++ that you can't do in assembly.
You want r/playrust
Ohhhhh
I'd distinguish between the *strength* of the constraints and the *kinds* of constraints. (Context: I actually spend most of my time working in TypeScript, which is as structural a type system as you get.) Nominal traits allow you to be *narrower* in what you allow, i.e. that the thing has to be *this specific name* (and the things that go with it); but I don't agree that that's a *stronger* guarantee than that it has a specific set of methods available. They're very difficult to compare in practice, and I use them in fairly different ways, and I often find myself wanting *the other* whichever language I'm in.
I’d be surprised if changing lanes was illegal in your jurisdiction. I’d be surprised if continuing to move your car forward in your lane at the speed limit while you’re vaguely zoned out was illegal in your jurisdiction. But you can definitely hit someone changing into your lane because your attention drifted at the wrong time. I think lapse of judgment wasn’t the right phrasing, but a situation more akin to the above happens in programming. It takes effort to keep things in your head and to remain focused, and it’s easy to let some of that slip while still feeling like you’re doing things correctly.
[https://godbolt.org/z/MXgx--](https://godbolt.org/z/MXgx--) Wanted to be sure that you were right.
There has been some talk about procedure macros to enforce it, like a "no_panic" or something like that. But it's still in the baby steps phase. Some libs try to never panick, [arraystrng](https://github.com/paulocsanz/arraystring) never panicks (except for Index/IndexMut if you choose to use it, which is the intended behavior). The only solution found that actually works was to understand the std APIs used and actually check the binary to see if it doesn't strip panicking branches, but that can change in other compiler versions (although it has a fairly small surface open to those breaking changes, that probably just won't).
Panics are safe.
This quote is not correct. Suppose I want to use a third-party library in a cross platform C++ project. Best case scenario, you drop it in to version control and tell cmake to add that directory. That means when they upgrade to a new version, somebody has to go and upgrade it in version control. Apply patches, extract the zip file, whatever voodoo is required. The more common case is that a significant amount of effort is required to include the library and maintain it. And somebody on the team becomes the owner of that library that knows the secret sauce to make it go. I’ve seen people spend weeks dealing with cmake bullshit. That can make including a third party library infeasible, axing an entire proposal before it starts. With Rust, that’s all handled by Cargo.toml. Let’s also look at code confidence. With C++, you can include some of the same concepts into the type system. You can use std::optional, std::expected, etc. But these are all dependent on the programmer to manually understand and respect the limitations of these. You can dereference a std::optional even if it’s None. With Rust, these things are handled automatically by the compiler, and made much more ergonomic via language features. ?, tagged enums, pattern matching, etc. These are things that C++ lack, and while you can get the same functionality, it requires boilerplate code and a developer manually understanding the pattern you’re following. Let’s look at generics and traits. With C++, type traits are a mess. You have to use std::enable_if and convoluted constructs. If you want to define a “trait”, you have to overload a function or implement specializations. Both of these have head-banging complications and limitations. This makes certain types of modular programming a hassle. With Rust, it’s built into the language and it’s trivial and ergonomic. There’s a first-class trait concept. Let’s look at threading. With C++, you are responsible for keeping track of what needs to be synchronized and what doesn’t. With Rust, it’s built into the language. This also enables things like rayon. And while someone might argue that it’s just like openmp, the big difference is that the compiler understands what’s happening and can automatically detect issues. Let’s look at tooling. With C++, you have a lot of options available. Problem is, a lot of them are partial solutions. The ecosystem is often fragmented and effort is correspondingly spread between multiple projects. Backwards compatibility stunts any effort to modernize the language. With Rust, you have limited options, but they are typically The Tool for the language, so they have a lot of people contributing to them. Most of the time the tooling has the benefit of building on what worked for other languages including C++. Let’s look at learning curve. With C++ it’s easy to get *started*. Where C++ falls down though is mastering it. There are so many different ways to develop C++. Most people only learn a subset of the language before they decide they’re done. With Rust, it’s hard to get started. But the learning curve of ~3 weeks will probably expose you to nearly all the language, instead of a subset like C++. There’s a better defined concept of what’s “idiomatic”. I’m not gonna provide the opposite side, because it sounds like your coworker will do that anyway. But from a business perspective, the main advantage that I see is that there’s more consistency to Rust code quality. It provides a great deal of automated analysis out of the box that would have to be done manually with C++, may require licensing, or isn’t even available.
As in memory safe? I meant safe as in enforcing stability / avoiding panics.
Yes, “safe” has a specific meaning in Rust, and that’s memory safety. It’s really important to be clear about.
Gotcha, thanks!
Any time :)
So you didn't followed the rules and didn't look before changing lines.
The thing is, if you put inexperimented developer on your C++ project, he will easily mess things up and make your program unstable. If you put inexperimented developer on a Rust project, he will take time to do something (or maybe fail to do it) but at least he will not mess up with the program. Rust brings safety by design while C++ forces you to have a strong team with no "weak" developer.
r/playrust ?
Cargo: Not imporant. Or rather, yet another build system - this is not the selling point. Hygienic macros: Great to have them, but can work without it. ADTs: Maybe, not sure. &amp;#x200B; The selling feature here really is the borrow-checker - it's groundbreaking work, for soft real-time applications.
Plus of course, cargo, package manager etc... Which is indeed a "nice thing to have" because you can do the same with C++ but if you think this way, you never evolve. This guy is just lazy to learn something new
No, someone else changed lines while you weren't paying attention. E.g., a biker overtakes you (while signaling and looking) and you fail to notice him merging in front of you, say, because the sun is shining from the wrong angle. And if we're allowing short lapses of judgment, hitting bikers because people carry out a half-assed/rushed three point look on a busy road is extremely common. Far from illegal, but small slip ups because it's bloody hard to be consistently 100% attentive under stress.
I've got to say I'm confused about the proposed `todo` macro. I have the impression that rust has quite a high bar for expanding the standard library, yet apparently adding a second way to do the same thing for no great benefit is acceptable? Don't know, seems inconsistent to me.
Like, how to connect more than one solar panel to a battery.
Wait, what's the issue here?
Thanks for the input! the biggest thing I'm trying to avoid is re-hashing the same key every time I do a lookup, the trees are indeed immutable, so I'll probably go with the global id thing and look into the best way(s) to get constant time lookups from discontinuous integer keys.
Truth. It's frustrating sometimes, but it's far better than getting shot in the foot later on.
I need a static set of reserved keywords to check against in my parser. I've tried using phf crate and simply couldn't, and would rather prefer not to use runtime sets, though it could be done. Is there any other way of doing this? I think i just need the set to be immutable now that i think of it. If any of yall think you wanna help, please reach out! : https://github.com/am3ra/c-interpreter
Took me a moment to realize what you were getting at. The new CString is temporary and gets deleted after the line ends, and you get an invalid pointer. I've definitely tried to do something similar in safe Rust, before, and the borrow checker caught this issue and didn't compile. If I didn't run into that borrow checker error a few times, I would never have realized what was wrong with this code, looking at it. Wow.
If all you're doing is shoveling bytes at an ESP8266 in soft realtime over a home network, I would just write directly to the standard library. IME in-home wifi networks are more than reliable enough for this sort of application, and something like Laminar or Tokio will add considerable complexity for little benefit. On the other hand, this is a project for learning so if you're interested in using either of those libraries going forward by all means use them here too. For a project like this specifically, there was a group working on an ecosystem of Rust libraries to support digital art and multimedia applications including lots of LEDs and micros, but I can't for the life of me find the library they built.
thanks for sharing!!!
Alternatively, the code that builds a new matrix and then iterates over its cells could be placed inside a generic function that takes a closure.
Thanks for sharing! GA + Visualizations also written in Rust! Nice video.
What didn't work for you with `phf`? I've just been added as a maintainer so I might be able to help.
But someone else then broke the rules.
I just read your article, which was fantastic. I would like to add that Rust's iterators are actually simpler and better than Python's, not just similarly simple. Python objects can implement __next__ and __iter__ at the same time or in strange ways, so one object which you think might the equivalent of a rust iter is really an into_iter, and Python docs are mediocre so it's hard to tell if it is or not. This bit me with the built in csv library, and it sucks. I don't want to program in Python anymore; I want to program in Rust, but I can't (work reasons). :(
Because the CString is never assigned to any binding, it's destroyed immediately after the let statement. That means the raw pointer we just got out of it is pointing to freed memory. If we were dealing in safe references, the first line would fail with a lifetime error, but with raw pointers we get UB on the second line instead. Exactly what it means to assign to a binding is a bit flexible (it includes e.g. assigning a reference to a local variable or to a struct field), but it does _not_ include passing anything as an argument to a function or method.
As much as rust is filled with functional elements, I still wouldn't really call it a functional language. It's missing key components
I've written C++ for 15 years professionally. In C++ I always strive to get the compiler to work harder for me (type-safety instead of casting, RAII instead of manual memory management, etc...), but you have to consciously strive for those things. I once told my co-worker that a good C++ developer will rarely suffer from data races. His response was, "That's ok, a beginning Rust developer will *never* have a data race." Until I started using Rust at work, I didn't realize how much energy I was wasting thinking about things in C++ that Rust simply enforces. In addition to the big wins that the compiler enforces, there's also the little things - a strong preference for immutability, algebraic data types, traits, cargo (no more fighting build systems), standard formatter (no more nit-picking about code style in PRs), simple dependency management, extremely useful compiler errors, modules/organization, C ABI compatibility, channels, huge repository of reusable code, etc... Rust has completely ruined me. I don't think I'll ever be able to work on another C++ project without feeling somewhat demoralized.
That's basically the unique feature of Rust. Safety isn't there because developer "X" was diligent, it's there by default.
WTF .. if this was C/C++ you'd have a pointer into the .strings section of the binary (it's not dynamically allocated) .. Rust is weird
Rustdoc is very good, too.
You want /r/playrust.
O sorry
Depending on your use case cargo outdated might also be relevant.
Will try that, thanks!
There is a minimal example demonstrating a wasm client talking to an actix server. One would have to pull in other appropriate libraries as needed for DB etc. Very basic - but seems to be sufficient for an intranet tool I hope to build. https://github.com/David-OConnor/seed/tree/master/examples/server_integration
That's not really true though is it? Preventing shared mutability for instance is not something that cannot be done at compile time in C++, is it?
Yeah I think what I'm gonna do is first implement it with the standard library and then try and use something like tokio or laminar. TBH I have some embedded projects ongoing in C/C++ so I'm kinda using this as a testbed to use for future development. Thanks for the response though, I'll see if I can dig up an relevant rust led/multimedia libraries.
In C++ that would depend on whether you have a `char*` or a `std::string`. This example is more like a `std::string`, which I believe has the same issues. But the string literal `"hello"` is allocated in the data segment of the binary, as a `char*` would be. The reason `CString` needs its own allocation here, is that Rust strings aren't null-terminated, so `CString` needs to copy the source string and add the extra null byte.
I appreciate Python and Rust for different reasons but can understand in part some of your frustration. Check these out, they might help. Package manager - [Poetry](https://github.com/sdispater/poetry) Book - [Fluent Python](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) Type checking - [MyPy](http://mypy-lang.org/)
Indeed.
There lack of both variadic and non-type templates are huge shortcomings in Rust's generics. I've actually discovered a couple of (almost undocumented) tricks involving higher rank trait bounds and associated types that have allowed me a little bit of that missing power, but I've used, as an example, combinations of CRTP and parameter pack expansion to produce an N-rank parameterized dispatch that is almost as expressive as Rust's pattern matching. I might be able to do something comparable with Rust's macros, but that wouldn't really have the same power or flexibility. There have been talks about adding these things to generics in Rust, but I'm not sure when that will happen, and I'm not sure if trait constraints will ever really substitute for CRTP.
FWIW variadic generics are on their way: https://github.com/rust-lang/rfcs/issues/376 And specialization, at least to a certain extent, seems to be possible as of 2016 (with a very interesting discussion): https://github.com/rust-lang/rfcs/pull/1210#issuecomment-187777838
That sounds awesome, does anyone know if there are any benchmarks around which show what sort of impact it can have?
Thanks so much for your reply! I'll definitely check out Poetry and Fluent Python. I'm currently trying my best to use MyPy, but as you might guess, it's not the happy path, which makes things a lot more difficult. (With Rust, good practices are all the happy paths, which is not the case with Python.) And the type system it gives isn't nearly as good as Rust's. I'm trying my best with it, though. :) I'm curious, what do you like about Python in particular, compared to Rust? Maybe reading that will help me understand the value of Python better. From nearly everything I can think of, I like Rust better (personally, but other people like stuff like duck typing which I don't like). The only good advantage I can see is how you don't need to compile it, only have a runtime that's already pre-installed, which works better than compiling on the fly with LLVM and rustc. ¯\\\_(ツ)\_/¯
A couple things I haven't seen mentioned that really drew me in initially: - Standard compiler. No dealing with implementation problems, different versions of the standard library, etc. I was never a serious C++ programmer but the overhead of just getting started is part of what kept me away. Rust has almost no overhead. Install rustup, write a .rs file, invoke rustc. - Standard docs. Automatic and consistent document generation for every single program you write. No other language has an equivalent ecosystem of quality and accessibility when it comes to viewing and maintaining docs. - Standard code format. No fighting over what code should look like. Everyone's code looks the same because the compiler enforces it. None of these are "language features" per say, but they all add something to the experience of using the language and that make using Rust much more enjoyable than other languages.
A lot of people are bringing up various reasons Rust is better than C++. However, no one is talking about is the fact that this is incredibly likely to make you annoy the piss out of all your coworkers. You're in a small shop, that runs C++, and everyone there knows C++. Nothing is broken, nothing is a problem.... why are you trying to shove Rust down their throats? Yes, it offers some good advantages, but C++ offers the advantage of not fragmenting your codebase and screwing your hiring pool. Rust is hard to learn, and it takes time to get off the ground with it, and there's a lot more *excellent* C++ programmers than there are Rust programmers, let alone *good* rust programmers. What exactly is the business case here? How does dropping C++ make your company money? Not to mention you already have a senior dev against the transition- that's nasty. Could you lose him? Lose his experience, his speed and his knowledge? You don't even know C++ well enough to argue Rust is better for the company! While posting here is helpful, I notice you never asked veteran, experienced C++ programmers why C++ could be better than Rust for a given situation- of course someone in this subreddit is going to think Rust is better than C++, if they didn't they wouldn't be here! tl;dr: Rust may be better than C++, but you aren't a senior or lead position. You made your suggestion, it was shot down for valid reasons, and that should be the end of the story. Your choices are leave the company for a place that uses Rust (good luck finding *that*), try to keep shoving it down people's throats, either pissing people off or getting you fired, or finally, work well enough to get promoted to a position that CAN make the decision to implement Rust... by which point I hope you've learned the reasons why a company, ESPECIALLY a small shop, should not swap languages because the kool-aid is tasty. Sincerely, Someone who has to deal with junior level employees thinking that every shiny new language will solve all the worlds ills without actually considering that they work at a business, not a playground.
Fellow clojurist here, spent last year or so in Rust for side projects—agree with most things you said. They both feel like languages from the future, but in such different ways. I really miss the REPL and really fast feedback loop you can get with a lisp language (clojure being the most practical). But if clojure makes me 2x more productive I would say Rust makes me 2x more _effective_. The abstractions are just high enough level to be ergonomic and the gains from the type system makes my free-time projects much easier to jump back into, get it to compile, and know that it mostly works. I have genuine confidence that the language is moving in a good direction and new features will be well considered. It’s a good time to code!
I'm a Rust fanatic, but when the conversation is about whether the language is right for x business, it's a very hard sell. Rust is still not mature to the same extent that C or C++ (or heck even Perl or Java) are. The Rust community is great, the language is even better... but it's not 20+ years old with a library of books and research papers and competing frameworks etc. When it's a question of cost &amp; benefits, you can't ignore the potential costs. Slowdown of development is a huge cost: - learning a new language - becoming productive with it - writing libraries that "just exist" in other languages - encountering bugs in the core language as an early adopter - maintaining a mixed codebase with multiple languages (unless you can somehow instantaneously migrate all your existing code with no impact and no bugs??) and all the context switching that implies... ...all of those amount to a huge drain on time and productivity, and when you *multiply that time spent by dev salaries* it becomes a little less attractive to switch even if the language is objectively better. How many thousands (or millions) of dollars are you proposing to spend to make a switch? How many years does it take for the savings in dev time or ops relief or uptime or whatever take to be seen? Would it be less costly to put off a switch to the future when there are more libraries or tutorials or heck even the next great language better than Rust? Taking on those burdens is maybe worth it, but it's gotta be understood *as an investment* and it does have to be worth it. Pay a lot now for bigger benefits later. Other people have mentioned the benefits of Rust better than I could
If I could recommend an alternative approach, it might be worth discussing the weak points of Rust with coworker. If you hope for them to eventually be on your side you'll have to given them an outlet to disarm from their original stance. Discussing the weak points of Rust would be productive (everyone is working toward a common understanding) and is important because you will want to shift the shared conversation away from "Can Rust do anything that C++ can't do" (what exactly that means isn't clear) and into "Does Rust provide enough value to justify the added maintenance cost of another language". From there you can go into the details laid out in the rest of the thread, while emphasizing the interoperability of C++ and Rust.
Fellow clojurist here, spent last year or so in Rust for side projects—agree with most things you said. They both feel like languages from the future, but in such different ways. I really miss the REPL and really fast feedback loop you can get with a lisp language (clojure being the most practical). But if clojure makes me 2x more productive I would say Rust makes me 2x more _effective_. The abstractions are just high enough level to be ergonomic and the gains from the type system makes my free-time projects much easier to jump back into, get it to compile, and know that it mostly works. I have genuine confidence that the language is moving in a good direction and new features will be well considered. It’s a good time to code!
You were downvoted (probably because of the gatekeeping gist of your comment) But I'll give you my lone upvote because I think the quality of engineers in a language's community is a huge reason to join. Alan Perlis said something to the effect of "Don't learn a language unless it will teach you to think differently." I've found that Rust did this for me, and that at least right now, the caliber of developers in the community is the driving force behind it
I maybe kinda know the answer but hopefully you wouldn't mind answering to the claim of "no undefined behavior?!? The rust compiler source code changes so much that all rust is basically undefined behavior."
I've found myself using unimplemented in todo's fairly often. I imagine it's a common problem, and the semantic distinction has positives. I can't really think of a reason why it wouldn't get merged.
I had one such coworker. He'd been doing C++ for over two decades, had read multiple books on it, stayed reasonably up to date on the ecosystem, etc, etc. He told me several times that I didn't *really* want a different language, I wanted different libraries. Finally I decided to write down all the things I thought could be done better in a new systems language, and while doing so, I googled for languages that already had those design features. And that's how I discovered Rust. After I told my coworker this, and persuaded him to look into Rust, his response was "it solves problems I don't have."
Literally this. You can write the most flawless code, but it's "safety guarantee" is YOUR guarantee; a maintainer is highly likely to break it in the future. The compiler's guarantee persists between maintainers and sleep cycles. The simplest way to demonstrate this is by asking if he'd feel as confident a newly hired junior would be able to write c++ as well-formed(read safely) as they can. With rust, the answer is yes. Also the compiler presents several potential errors to you *before* you spend an hour compiling.
Why not?
I had a big reply typed out but decide against it as I don't want to start a language debate. In short, development speed and language maturity probably come out on top. Despite the obvious 'flaws' I can see while using Python, they were never an issue pre-Rust. It just becomes something I can't un-see lol but both languages have their benefits. Language maturity is something that is improving with Rust and I can see myself using both languages for the foreseeable future. It comes down to who the project is for, as currently, more people can make sense of a Python codebase over one written in Rust. If it's for me, I start with Rust whenever I can.
Hello, I don't know how to cross-post (or if I should), but I wanted to mention this thread from r/haskell: &amp;#x200B; [https://www.reddit.com/r/haskell/comments/cakgdj/functional\_programming\_jargon\_in\_rust/](https://www.reddit.com/r/haskell/comments/cakgdj/functional_programming_jargon_in_rust/) &amp;#x200B; (Sorry if this was redundant.)
peace of mind? 🤔
Folks on Linux can use Filelight (KDE) or Baobab (Gnome) to analyze disk usage. With rls/debug/release, `target` can easily take 1 GB even for the smallest projects.
This. Almost everyone commenting here totally missed the point.
That's not what "undefined behavior" means in C-like languages, and despite the compiler changes, the language semantics are actually stable, and are defined (in the dictionary sense, not the C sense) by the reference documentation.
Small additions are ad hoc, although have to be vetted by the libs team. Larger additions go through the RFC process.
It is perfectly legal to drive into the tree in your yard. It is also perfectly possible to be not paying attention and drive into the tree in your yard. Do not ask me how I know this.
As other answers have said, safety is the core feature, and *lack* of misfeatures is the second most important "feature" of Rust compared to C++. And the tooling (especially Cargo) is far ahead of what I've seen for C++ (with the possible exception of Bazel and its ilk, which look extremely promising but sadly I haven't yet used). There are also several things that C++ "can" do but which aren't actually common practice, whereas in Rust they are the default. Move semantics is the obvious example here; I believe there are *still* some features of the standard library (such as `std::function`) that don't fully support move-only types. Making `mut`, rather than `const`, be opt-in is also more important than C++ programmers may realize. And while it's possible (though awkward) to catch all exceptions in a thread and pass that information to the parent thread while letting the child die, it's pretty awkward, whereas in Rust that's just how panicking in a thread works. But there are also several language features Rust has that C++ really truly does not. Several have already been mentioned, but not all together. Here are the big ones: * enums and pattern matching * narrowing type inference (`collect()` looks like magic coming from C++) * Traits (which let compile-time polymorphism and run-time polymorphism share the same interface definitions, leaving the choice of which to use up to the user; here is an excellent talk about why traits are preferable to traditional inheritance: https://youtu.be/VSlBhAOLtFA) * For generics, C++'s Concepts (when they are finally standardized) should provide some of the same benefits as Traits; but I don't believe they'll interact with run-time polymorphism at all. * Modules and a properly namespaced import system (once C++ has modules, this will fall under the earlier category of things C++ "can" do but which aren't necessarily the default) * `derive` (seriously, this is huge; in particular, show your coworker `serde`) * Macro hygiene and feature-set * Zero-cost moves (moving is never, ever, ever a method call in Rust; it's just a change in ownership, as tracked by the compiler, and there's no need to set pointers to null or anything like that) * It may be cheating to include this, but if all goes according to plan, in about three months, Rust will be the first language I know of to natively support in-thread concurrency (`async`/`await`) without garbage collection. I think the syntax is notably more consistent than C++'s. I also think that syntax matters quite a bit in a programming language, but your coworker may disagree.
This is the sub for the rust programming language
&gt;Despite the obvious 'flaws' I can see while using Python, they were never an issue pre-Rust. Very well stated. It's like how people moved from Java to Python; they were mostly fine before, but didn't want to go back. &gt;Language maturity Yeah, cause I'm stuck with doing some scripting type stuff in conjunction with whatever libraries and tooling. You can't really do that in Rust because that tooling doesn't exist to migrate to. &gt;more people can make sense of a Python codebase over one written in Rust Likely because they're somewhat familiar with Python tooling and what not. I'm not, so it's difficult, and I'd imagine it *might* be similarly difficult to someone new to Rust. Though, it might be easier with Rust, actually, which has a simpler module system. (From my perspective, anyway.) Thanks for your thoughts on this subject! 👍 I know that for any application type stuff, I'm definitely going to try to do Rust in particular.
You should ask your co-worker of they think that *all* C++ developers are capable of following all the good practices all the time. Not all projects are one-man shows and *that* is where I think Rust has the advantage.
Thanks a lot.
This is understandable.
Rust offers better performance and brings memory safety into your application. The C++ -&gt; Rust switch is not that abrupt, anyone experienced in C++ will easily understand the core concepts and syntax. Maybe your colleagues could understand that and perhaps be interested.
On Windows you can use WinDirStat.
You can simply choose json length (2 byte) + json data as packet structure.
Holy cow, the little toy project I've been playing with for a week already has a 300 MB `target/` :O
First of all - that is not true at all. Look at this well formed code: \`\`\` let v = get\_some\_vector(); for(auto &amp;x: v) { if(cond(v)) { v.push(additional\_data(v)); } } \`\`\` This code is: 1) Obviously breaking memory safety 2) 100% well formed, not using manual memory management nor even iterators directly &amp;#x200B; And there is always the argument, that "noone writes so stupid code" which is another lie. It is just simplified example which may fit in single slide, so probably this exact code would not lay on any production, but in my not so long 7yo career as programmer, mostly C++ (but also full time Rust dev) I've seen code which reduces to exactly such a loop. How? It starts with creating class "GoodClass" with vector \`vec\`. In some point method \`foo\` is needed to modify "GoodClass" basing on some arguments, but not touching our \`vec\`. Function is part of public api and used in two specific places. After an year someone found, that function \`foo\` perfectly matches his needs, and adds call in loop over \`vec\`. In the mid time this function becomes used in 50 other places. After another 1.5 years it comes out, that the function \`foo\` almost matches another usage, but in this case it should additionally update the \`vec\` which is actually something like cache. It turns out, that adding this element to vec in \`foo\` is benefitial in most \`foo\` calls, so someone adds this change. The one didn't know about this one very case when it's called in loop over \`vec\`, and there are over 100 calls to \`foo\` in codebase - he just missed it. And this kind of errors doesn't faill everytime. Worse, it gives false result without any exception or crash. There is a pretty smart guy, Catalin Cimpanu, which Tweeted once: [https://twitter.com/campuscodi/status/1094986825041629184](https://twitter.com/campuscodi/status/1094986825041629184). Yes, I am 100% sure, that MS doesn't know about well formed C++, smart pointers, and ranged-for loops. They UT/MT/whatever T coverage is probably \~0%, they don't use CI, and never heard about static analisis. This an only explanation I can find if C++ really provides memory safety if you use it correctly. And I still cannot find any reason, why they finally decided to move critical Azure parts to Rust, its doesn't make sens - C++ is perfectly the same thing :/
I'm confused. Manipulating an iterable while iterating can result in four things, as far as I can tell: 1. Loop works as expected. 2. Loop works in some unexpected way. 3. Loop panics. 4. Loop causes UB. 1 is not a bug. 2 is arguably not an "iterator invalidation" bug: it's just a plain old logic bug. Rust cannot prevent logic bugs, any more than any other Turing Complete programming language can. 3 can be a consequence of a certain kind of iterator invalidation, as in the provided snippet. 4 is not supposed to be possible in safe Rust, but is possible in C++ — if it happens in Rust it's a bug in the compiler. The provided snippet can experience 1 or 3. This seems to me to be the best one could do here.
thanks but that's now what im looking for
Okay, o shouldn't have said laws. Let's replace it with rule from drivers rulebook.
What key components are missing? * Laziness? Surely not an FP requirement? * Higher-Order Types? Maybe. There are untyped functional languages. * Immutability? This keeps Rust from being a *pure* functional language. * Tail-call optimization? Yeah, that's bad if you're trying to write in a functional style. * Other?
Which rule? The "don't drive into trees" rule? That's probably not in a standard rulebook: there's too many such rules to list them all. The "always pay attention" rule? Literally impossible for human beings: they just aren't built that way. I would say we're getting off topic, except that I watch my students drive their programs into trees all the time. Rust tries really hard to tell them this when they're planning their trip, and has really good airbags for the case when it happens anyway.
Fixed now.
And there is no rule about NOT driving in a tree.
Writing `std::memmove(someplace, &amp;my_smart_ptr, sizeof(my_smart_ptr))` is still perfectly valid in c++ and does not have any `unsafe`s around it to even warn you something's gonna explode.
Just ran it worked! It was my bad that in my mind I thought concat! macro doesn't work in no_std in reality it was format! macro ( SO question for format! in no_std - https://stackoverflow.com/questions/50200268/how-can-i-use-the-format-macro-in-a-no-std-environment ).
I mean not unique because GCs generally do the same, but yes, the only gcless
I have a desktop machine basically dedicated to compilation (so there’s not much else there except git clones and build artifacts). The 500 GB SSD regularly gets full. Cargo also keeps separate files for each rustc version that is used. This is good if you’re going back and forth between e.g. Stable and Nightly to compare them or something, so you don’t need to rebuild from scratch every time. But these files can accumulate if you go through multiple compiler upgrades without running `cargo clean`, which can go quickly if you’re tracking Nightly.
Does Baobab's radial view still lack the kind of caching and incremental re-scan that Filelight implemented for drilling down? Last time I tried it, it was practically unusable on rotating media because of that. (Not that Filelight is perfect. ncdu (ncurses) is even better about allowing you to manage your disk I/O.)
You can also install [cargo-sweep](https://github.com/holmgr/cargo-sweep) to recursively clean Rust projects!
Fraught with security problems, and struggling to land any patches in the Kernel, as a lot of people share the view they can be used to store malware that launches attacks against the host with total invisibility https://lwn.net/ml/linux-kernel/CAHk-=wjmT=uC1=18ZYV1CMfP_FBUEjh9_rabH0g+a0z-L0cgHg@mail.gmail.com/.
Sure, but why would you do it? Something being explicitly safe or unsafe doesn’t mean you get to skip understanding why something is done a certain way, or let’s you presume that there’s no programmer errors. If I saw that C++ code in a code review I would question why the author wants to do that - I would hope that Rust developers do the same when they see people doing weird things with transmute, regardless of the ‘safety’ of the surrounding scope?
The first thing I notice is that you are building an extension module (like the second example in the cpython README) but you didn't specify your dependencies like this: [dependencies] rand = "*" [dependencies.cpython] git = "https://github.com/dgrunwald/rust-cpython.git" features = ["extension-module"] Omitting that `extension-module` feature may be your issue since, from what I remember, whether a build works despite it being missing is platform-dependant.
&gt; Fellow clojurist here I thought it was Clojurian.
Rust is such an awesome language. Lack of higher-kinded types is the only thing preventing me from switching.
What I do is to have all projects share the same target directory, and then every time I update Rust I just clean up that directory...
Obviously, it's just an example. Real code is usually much more subtle and breaks in a much less evident way. I'm pretty sure you can find plenty of examples on this very site as well.
...and, if compiled with the default unwind-on-panic behaviour, you can use `std::panic::catch_unwind` to catch panics at unit-of-work granularity so a bad file or malformed request can bring down your entire batch job or server process.
&gt; Your choices are leave the company for a place that uses Rust (good luck finding that) Gets easier every day. Losing a hypercompetent (maybe) senior developer is a major risk to your business today. Losing a smart and enthusiastic junior developer is a major risk to your company's future. Balance carefully. An awful lot of "new language" developers left their C++ shops a decade or so ago, and are now building software that is eating their former employers' lunches. Stagnation is real, and can fatally compromise a business long-term. "You're not wrong" about your basic point that big-bang language switches are incredibly dangerous. Mentor Graphics famously switched from C to C++ in the early 1990s and nearly bankrupted their company in the process. The good news about C++ then and Rust now is that you don't need to do that kind of Flag Day. Starting to deploy small pieces using FFI and small applications in pure code is a proven strategy for maneuvering in the language space. Mozilla is the poster child for the C++ → Rust version of this plan: they have seen almost entirely positive impacts from their slow, careful migration away from C++ as far as I can tell. It might be decades (if ever) before the last C++ leaves their project — and that's OK. In any case, I am quite put off by the blustering tone of your comments. Making technical culture decisions for a business is hard, and thus excellent people often get it wrong. The folks I know that are trusted to make these decisions are careful to consider all viewpoints, careful to weigh pros and cons (including many I would never think of), and constantly revise their views as things evolve. That seems to me a more successful strategy than angry dogmatism. Big changes in programming languages and technologies are coming. They're always coming. The companies that survive them — sometimes thrive from them — are those that are simultaneously careful enough to not get steamrollered and flexible enough to jump on the steamroller and enjoy the ride.
Let’s take both: clojuristian (or is it clojurianist?)
I was using this before just pointing to git for a crate. There was no difference - the dll could not be used. When the dll was built I thought I need to import it differently, so I tried using ctypes to load the library and it still didn't work. I don't know if this will make any difference now when I am renaming the file and am able to use it.
Now that sounds like a religion. Which is not too far from the mark for some users.
The CString is dropped immediately after calling as_ptr
On macOS, I like DaisyDisk (basically a prettier version of Disk Inventory X)
We [@slowtec](https://slowtec.de) are using seed in a customer project to evaluate the potential of WASM and full stack rust projects. My impression so far: * it allows you to build quite complex apps without a single line of JavaScript * it's working with Rust stable (!!!) * using WebSocket &amp; serde to communicate in realtime is currently not part of seed but we made it work with some custom code * creating animated SVGs (in our case to create line charts and custom visualizations) works as expected * seed is still in heavy development so you can't expect that your code will work tomorrow * it's not the cleanest code * two developers are quite active and quickly respond to questions you have So overall we hope that seed will release a more stable version within the next year so that we can ship the customers project into production. And as you might know I created a list of alternatives ([https://github.com/flosse/rust-web-framework-comparison/#frontend-frameworks](https://github.com/flosse/rust-web-framework-comparison/#frontend-frameworks)) to keep track of the rust community projects. So I'm happy to read from other of their experiences with other frameworks :) I hope that helps you to answer your question?
Use WizTree. It’s like 90% faster.
I'm not really familiar with C++. What are the features of templates that Rust is missing?
I program professionally in C++ and wouldn't currently want to switch to Rust. There are three main reasons. 1. In my experience the biggest productivity killer in C++ is compile times. I'd be very reluctant to switch to a language that (at least currently) apparently has even worse compile times than C++. 2. Eigen. Its combination of statically-allocated compile-time-sized matrices with expression-template-powered compile-time fusion of operations gives performance that's unmatched by anything in Rust. While Rust is getting const generics soon, which will help, it's still a long way away from getting variadic templates, which are vital for compile-time-sized tensors of arbitrary dimensionality. 3. Rigid polymorphism. In C++ I can use \`if constexpr\` to arbitrarily specialise any part of a function's behaviour in any way for certain types. I can parameterise a function or class by anything I can think of. I can create higher kinded types, associated types, any kind of type I want without having to even think about theory or syntax. In Rust, there's lots of things I can't do, and for the things I can do they often involve much more boilerplate than C++ (e.g. declaring a trait and making a bunch of things instances of it, compared to in C++ I just call the function/op on the type T and if there's no match it won't compile). In scientific computing and the like, security isn't an issue (nobody can hack code that's not deployed anywhere), crashes are costless, and productivity is key. In this situation I see less value in switching to Rust, especially compared to e.g. something like Julia, which can get close to C++ speeds and actually supports statically sized tensor types (and multi-dispatch via function overloading; achieving equivalent behaviour in Rust requires more boilerplate due to the lack of function overloading).
You would? Doesn't char *cStr = new std::string("hello").cstr(); puts(cStr); Have the exact same problem?
you can use a library but client may need to use the library too example : https://github.com/amethyst/laminar
Why would you wrap it in a std::string? Does rust have something like const char* that points to static string data?
That’s smart, but you can point out flaws in arguments. Rust guarantees things that C++ can’t, and that statically (unlike the overhead of e.g. smart pointers). So in C++ you rely on the (imperfect) discipline and (imperfect) memory of people to get everything right and then get slower results, while in rust you rely on the compiler, full stop.
(Still doesn't work if you create things in a loop.)[https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=32a1dfe449700eba0d9a8074ae60e883] A closure is only as unique as it's position in the source code.
Although I'd probably recommend using `Result` here.
Yes, unfortunately if i add it to my binary it adds an additional 800kb. We want to run this code on microchips so that’s a nono sadly
The accepted best way for constant time lookups of discontinuous integer keys is indeed a hash table. I probably wouldn't implement your own, the library implementations are already very good.
Yes that's the reason why I didn't even tried. There are larger opportunities elsewhere to focus on for the moment.
They weren't breaking the rules simply overtaking. You weren't breaking the rules not seeing them merge. The problem of following rules in the first place still exists, but even when following rules, accidents can happen.
Also see [dua](https://github.com/Byron/dua-cli)
Async functions get compiled to a state machine, meaning a struct containing the state and functions that drive the state to the next non-ready await point. The state contains inside it the state of other things you await. So in this case the state for foo contains the state of a recursive call to foo, which won't work because the nesting is infinite. I'm sure someone can explain this better though :)
Oh, so it's like the compiler is trying to build something like this and fails, because it cannot properly infer recursive `impl Future`? enum Future1 { Step1(impl Future&lt;Item=()&gt;) }
Well, since yesterday’s release!
Yes.
I could not understand how my 500GB harddrive was so short on space when I had no music, movies etc on it. Then one day I decided to check how big my opensource directory was by just right clicking and going into properties...it was still running after about half an hour...Decided to just go into the opensource directory and delete Servo and Rustc since they were the biggest ones and I wasn't doing any work on them. As far as I remember I saved well over 100GB.
&gt; […] non useful things (recursion as the main way to do things This is both so condescending and ignorant at the same time it created a new universe in which the word condescorant exists.
And well-formed Assembly can do anything C++ can do (faster, no less). But do you trust literally anyone to always write Assembly that is well-formed? The same applies upwards. Although well-formed C++ can accomplish anything Rust can accomplish, it's easy to write C++ that is not well-formed. Rust ensures at compile time that your code is safe, rather than trusting humans not to make errors.
Aka. everything that can go wrong, usually does.
The nrf52-hal repository contains a board support crate for the nRF52840-DK: [https://github.com/nrf-rs/nrf52-hal/tree/master/boards/nRF52840-DK](https://github.com/nrf-rs/nrf52-hal/tree/master/boards/nRF52840-DK) That crate has a blinky example: [https://github.com/nrf-rs/nrf52-hal/blob/master/boards/nRF52840-DK/examples/blinky.rs](https://github.com/nrf-rs/nrf52-hal/blob/master/boards/nRF52840-DK/examples/blinky.rs) I haven't tried it (only worked with the nRF52832 so far), but it should be a good starting point. You didn't say what you're using to flash the MCU, but in case you want to go with GDB/OpenOCD, there's configuration you can reuse in the DWM1001 repository ([debug.gdb](https://github.com/braun-embedded/rust-dwm1001/blob/db7afc1561fe78cb40da88df1a63b962ee5412f6/debug.gdb), [openocd.cfg](https://github.com/braun-embedded/rust-dwm1001/blob/db7afc1561fe78cb40da88df1a63b962ee5412f6/openocd.cfg). It's for the nRF52832, but it should be easy to adapt. If you get it working and want to contribute better documentation, starting configuration, etc. to the nrf52-hal repository, we'd appreciate it!
The problem is mostly that if the size of the nested Future is non-zero the total size becomes infinite because it is nested inline, and not behind a pointer. In some cases this could be avoided, if the code after the recursive call doesn't need any state from before the recursive call in theory the compiler could be smart enough to produce a finitely sized state. This is equivalent to the tail call elimination optimization for non-async recursive calls. But it isn't always possible, which leads to code suddenly not compiling anymore when you make a seemingly innocent change.
The repo of the hal also has a few examples (I would recomment starting with the rtfm-demo) [here](https://github.com/nrf-rs/nrf52-hal/tree/master/examples) where you only need to change the default feature to nrf52840 in the cargo.toml. You might also get some faster answers in the embedded rust chat [https://matrix.to/#/#rust-embedded:matrix.org](https://matrix.to/#/#rust-embedded:matrix.org)
Comparing to untyped lambda calculus: * Currying which allows for function composition in a way that Rust can't (e.g. point-free style). * Functions: Rust still has two types: functions and lambdas. The `Fn`-story is still not complete. There is a difference between a lambda and an inner function, w.r.t. generic types. * Related, minor: syntax of functions are more complex with self functions. * Semantics: while Rust depends on operational semantics (though not formally defined), the generally used semantics for functional languages is denotational.
They can’t consult its state while we have it though. I hope you left them a copy!
A big part of this is dependencies, which get built for every project they are used in. Cargo caches crate downloads in `~/.cargo` but not builds — why not?
Thanks. Exactly this and nothing else. I also want to add one other thing: As far as I know (last time I looked that up was late 2018) there is no certified compiler for Rust. The company I work for does SIL-4 stuff on embedded systems, and you need a certified compiler to match the standards. Rust surely would solve _some_ of the problems, but it's simply not even possible to use for use here.
“Well-formed C++” is like saying “just stop including bugs”. You can write clean, correct code in assembly, too.
See https://github.com/rust-lang/rust/pull/56348 where it was discussed at great length.