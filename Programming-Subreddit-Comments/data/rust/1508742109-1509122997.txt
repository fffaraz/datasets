Thanks I'll take a look at it. I usually handle formatting pretty well and I know clap.rs app arguments are a little crazy. Other than that I don't do much. I do enjoy RLS though.
You might be interested in [some tips](https://deterministic.space/rust-cli-tips.html) for writing small CLI tools in Rust :)
Thanks I'll take a look.
Thanks! I'm aware of that and actually planned to use the `Into&lt;String&gt;` thing, but the current code was a quick hack and isn't too refined yet :) There are probably also some allocations that could be avoided.
A [comment](http://bannalia.blogspot.com.au/2015/06/cache-friendly-binary-search.html?showComment=1477469437769#c2274225536536313248) from the author in your first link mentions that levelorder is the same as Eytzinger layout and points to the same paper.
I did this to find what type returns filter. let arr = [1,2,3,4,5,6,7,8,9]; let arr:i32= arr.into_iter().filter(|&amp;&amp;x|x%2==0); And it outputs note: expected type `i32` found type `std::iter::Filter&lt;std::slice::Iter&lt;'_, {integer}&gt;, [closure@main.rs:20:37: 20:48]&gt;` Which is weird to me because I am used to filter returning an array. Is there a way to make that type into an array. 
Individual graphemes are not really a thing you can iterate on in Unicode (they're nowhere in UAX #29), I expect they mean "extended grapheme cluster", which is what a Swift `Chatacter` is, and what you get when you iterate on a Swift string: &gt; Every instance of Swift‚Äôs Character type represents a single extended grapheme cluster. An extended grapheme cluster is a sequence of one or more Unicode scalars that (when combined) produce a single human-readable character.
BTW, CompCert shows an interesting tradeoff: some parts of the compiler have algorithms that aren't proven correct, but are guarded in runtime by verification algorithms that *are* proven correct. So there might be some obscure bug in an optimization pass, but at runtime you'll get an error like "optimization generated incorrect code; please report a bug."
Most iter adapters are lazy, that means that they contain the original iterator (or a reference), and the given closure, and they are executed only when needed. You can use `collect` in order to execute the adapter immediately and collect the results into a Vec, but you cannot collect into an array, as arrays have a statically known length, and the resulting length is not known until the point of execution.
To give an example with what /u/Gilnaa said: let arr = [1,2,3,4,5,6,7,8,9]; let arr = arr.iter().cloned().filter(|&amp;x| x%2==0).collect::&lt;Vec&lt;_&gt;&gt;(); It may be a bit confusing at to why `iter().cloned()` is used. Essentially, you can't move values out of an array, so `into_iter` and `iter` both end up giving you references to ints. But since they're just ints, you can clone them (which is what `cloned()` will do). If you didn't use `cloned`, your return type would be `Vec&lt;&amp;i32&gt;` instead of `Vec&lt;i32&gt;` which is what you want.
Guess who's comment is getting saved.
Hey, have you seen the [Cross](https://github.com/japaric/cross) project before? It's meant to be a framework for using Docker for cross compiling Rust. Right now it only works on linux-x86_64 hosts, but I'm working on a branch that [works on any platform with docker](https://github.com/japaric/cross/pull/131).
This week I implemented neural networks for my diss. Not a great implementation I'm not using a vector library or anything like that, just using Vecs. This week I've got to do some documentation (a project plan) but if I have time I'll try and do [boosting](https://en.wikipedia.org/wiki/AdaBoost) on neural networks and see if it works
if the number of people is greater than 2, the first n-1 people can draw each other forming a circle, and the last one will pick himself. (e.g. 1 draws 2, 2 draws 3 .... N-1 draws 1, leaving N to pick himself)
confession: I did not invent most of the macros tricks in nom. I nerd sniped awesome people with cool parser problems and they came up with a lot of solutions :) Otherwise: https://doc.rust-lang.org/book/first-edition/macros.html https://danielkeep.github.io/tlborm/book/index.html and looking for `macro_rules` in the Rust unit tests: https://github.com/rust-lang/rust/tree/master/src/test (lots of things were hidden there)
I'm working on a simple arcade game to help me and hopefully others to learn [hiragana](https://en.wikipedia.org/wiki/Hiragana). Here is small video of the current progress: https://www.youtube.com/watch?v=1s3jUqAahz4 I'm using ggez engine and nightly.
In addition to CFFI it's worth to remember that Rust code can be (relatively) easily integrated into Python codebase, using e.g. [cpython](https://github.com/dgrunwald/rust-cpython).
Beautiful ‚ù§Ô∏è 
For what it's worth (I'm not sure if you're the author of that article or not) but I followed the tips in that article for my first CLI program and have to say, hats off. It's my first time writing in Rust and found it fairly easy to grasp batting between this article and the Rust book for reference. It's still very unfinished but I'd love to post for a review one of these days. Anyway, thank you!
On the weekend I finished the most basic observable example of networking for [PlanetKit](https://github.com/jeffparsons/planetkit). You can now start a server, have a client connect to it, and then both fight over control of the same character... if you can call three coloured lines representing local X, Y, and Z axes a "character". Next up is to create separate characters per player, and transmit updates to the voxel world (this cell added, that cell removed). After that I might add some kind of weapon and let you kill each other. It's slowly starting to look like an actual game! :) 
Thank you! I'm the author of that article and very happy to hear that. :) Anything you'd add/omit/replace? Feel free to post unfinished projects for review here! I've seen a lot of people do that and usually get good feedback.
I don't know if it is true still, but it definitely used to be true.
Oh, I'd be much too embarrassed as it's not even close to ready yet (writing a macro language/parser, still in the proof-of-concept phase) but sincerely appreciated! I will think about it for the near future. No general feedback (though I can *certainly* appreciate you asking!) A lot of the questions I had reading came from my unfamiliarity with the language, over time it made more and more sense :) 
FYI there exists BufRead trait.
&gt; It's like how [i32] is a valid type I'm not sure i'd call `[i32]` a valid type. You can't use it in the places you can normally use types - variables, function parameters, return types, generics. The only places you can use it are in constructing other types in a couple of particular ways: making the reference `&amp;[i32]`, or as the last member of a dynamically-sized struct `struct A {a: [i32]}`. it's sort of demi-semi-valid. 
No, it's a valid type. It just doesn't implement `Sized`. Like how `Box&lt;i32&gt;` isn't a "demi-semi-valid" type just because it doesn't implement `Copy`. Heck, DSTs aren't even the weirdest types in Rust. That'd be `!`.
Thanks for building this. It might come in handy.
You absolutely can dynamically link Rust code. The ABI situation means that you can‚Äôt do it across compiler versions, which negates some, but not all, of the benefits. It means you recompile the world when you update the compiler, rather than per-project. This is what Linux distros are doing, for example.
&gt; this is never valid is it? The last field of a struct is allowed to be unsized; you're allowed to use traits and naked unsized arrays there: trait Flappable {} struct Flapper { name: String, flap: Flappable } struct NamedBuffer { name: String, bytes: [u8] } Those structs are themselves unsized, as you can see by their fat pointers (this example is from a 64-bit machine): pub fn main() { assert_eq!(std::mem::size_of::&lt;&amp;Flapper&gt;(), 16); assert_eq!(std::mem::size_of::&lt;&amp;NamedBuffer&gt;(), 16); assert_eq!(std::mem::size_of::&lt;&amp;String&gt;(), 8); } However, i don't know how you actually create an instance of an unsized struct like this. I think it all hinges on [CoerceUnsized](https://doc.rust-lang.org/std/ops/trait.CoerceUnsized.html), but i haven't dug into that. This stuff is important for efficiency in certain situations, but it is, IMHO, really unergonomic. The documentation is not good (the [nomicon entry for unsized](https://doc.rust-lang.org/beta/nomicon/exotic-sizes.html) doesn't mention coercion!), and it's easy to stumble, as the OP did, into a situation where you have defined an unsized type and are now in a world of pain.
That analogy makes no sense. You can do all sorts of things with a `Box&lt;i32&gt;`. There is *nothing* you can do with an `[i32]`. `[i32]` is much more like a trait name, which we are at pains to point out is not a type. If, in Rust's terminology, `[i32]` is a valid type, then that is a bug in Rust's terminology. 
Still working on an efficient and convenient way to analyse the [public data](http://opendata.cern.ch/collection/ALICE-Reconstructed-Data) of the CERN base ALICE collaboration (we analyse particle collisions). Its a personal side project and I still hope to present it here in the next week(s). I just got a bit sidetracked lately. Anybody else here working on some CERN stuff?
&gt; There is *nothing* you can do with an `[i32]`. This is true *only* if you limit yourself to direct values *and* the current implementation of the language. That won't necessarily remain true. I didn't touch on it because I didn't want to muddy the water, but there's no reason the compiler *couldn't* allow values of type `[i32]`; it just has to be taught how to allocate and move dynamically sized things around. So I think the analogy is just fine: you're rejecting `[i32]` as a type because it doesn't support an arbitrary subset of functionality, which I think is silly.
I implemented the parser for the [Tiger compiler](https://github.com/antoyo/tiger-rs/tree/master/tiger) I started to work on months ago.
Around half of tiger cubs don‚Äôt live beyond two years of age.
&gt; An old C compiler may do b a c instead. Rust shouldn't have this inconsistency. I don't know about C, but in C++ at least this is implementation-defined as GP says. So while a particular implementation might do one thing, they're allowed to change that behaviour and other compilers might do different things. (MSVC and clang do a b c but GCC does b a c for example). 
Well, indeed, you can also dynamically link C++, but the ABI isn't stable and is compiler-dependent. So the same situation applies, and people somehow cope.
Very interesting. A while ago i did some benchmarks of `ordered Vec + std::binary_search` vs the compiler's internal `FxHashMap` and found it impossible to beat the hashmap lookup speeds even for tiny collection sizes. I wonder if this would perform better.
[My Python version](https://gist.github.com/tomwhoiscontrary/ef888a2875fe2d2dc2002d0c2c8b7713), last updated in 2011 but dating back some time before that. Yes, it's a CGI script. It can't handle people being in multiple santa-exclusion groups, but it can handle multiple people in each group. The one feature it has over Rusty Santa is that it sends mail to tell everyone who to give a present to, which means that the administrator can be included in the festivities without knowing everything. 
&gt; or Tor Browser Speaking of which, didn't they talk about their intention of rewriting it in Rust some time ago?
wrong sub
I prefer `Box`es.
https://www.reddit.com/r/playrust/ is the subreddit you're looking for :)
To add to this, `binary_search` only finds *a* smallest value, so if your slice is `[(Key, Val)]` and you do a `binary_search_by` based on the key, you may find an arbitrary match, not the first one. And many bugs were had.
Finally! A decent comment on the topic! I'm so sick of all those programmers by now, you cannot imagine!
/r/playrust 
I use both tmux and a tiling WM, not sure why you'd think it should be one or the other. For chrome-based browsers, I recommend cVim over vimium, but it's a matter of taste.
I love that description
It sounds like the plan is to eventually define an ABI. Is there a plan when to do this? Wouldn't 1.0 have been appropriate? And even if it needs to change, can't that be done in 2.0?
If u intrested to play just hit me on steam :D maybe i will not be able play today but tomorrow for sure !!!!
Has IntelliJ Rust implemented debugging?
please make it load custom csv and adjust font size so people can use it for other stuff... also do u have code on github?
I've been watching that page for a while and can never tell if it's being updated.
Both for this implementation, and for the original C++ implementation, the compiler is smart enough to use a conditional mov when it sees the final `if` in `find_gte`/`search`. You can only really ensure this by writing the assembly yourself, but inspecting the compiler output (with `--emit asm` or `objdump`) should give you decent confidence that cmovq is indeed being used.
Now that TiDB has reached 1.0, does that imply that TiKV is at the same level of maturity/stability? If so, I'd love to get some benchmarks against other projects (RocksDB?), if you think such comparisons are logical. :)
Polishing my static site generation library! It is called "slime" and is already on crates.io. https://github.com/jaroslaw-weber/slime Why not gutenberg or cobalt? It is not a binary, it is a wrapper for handlebars, json and few other stuff. You can actually manipulate data and write custom html. You can also reuse stuff because it can use partials in templates. So it is more flexible but requires little more work. I am also planning to write a tutorial how to create nice website with bulma and deploy it on github. It is still in early stages but I am open to feedback! Also I will probably discuss about the design of cookbook since I was working on it for a while. Maybe write documentation for the static generator I wrote (and tooling), or replace some of it with "slime". Also gonna rewrite my portfolio page into a static website (with slime) so I can save 2.5usd on my vultr server (currently running on rocket)
https://github.com/rust-lang/rfcs/issues/600 is the tracking issue &gt; Is there a plan when to do this? No immediate plans; there are far more important things Rust needs to tackle in the near term. &gt; Wouldn't 1.0 have been appropriate? 1.0 means "stable" not "feature complete"; attempting to define an ABI as a blocker for Rust 1.0 could have set it back a long, long time. C is closer than C++, but even then, they don't technically have them, and it took *decades* to get to the situation as it exists today. &gt; And even if it needs to change, can't that be done in 2.0? There will be no Rust 2.0. And besides, an ABI that breaks all the time eliminates many of the good things about having an ABI; you're back to the exact same situation as today, but you've decreased the frequency of recompiling the world. 
/u/llogiq - the "last week's thread" link goes to the thread from two weeks ago - [here](https://www.reddit.com/r/rust/comments/76o8rh/hey_rustaceans_got_an_easy_question_ask_here/) is last week's.
Exactly.
The Tor Browser is Firefox, so sure :p If you mean Tor proper, yeah, they've been hacking on some stuff.
If you are familiar with Node.js, give [Neon](https://www.neon-bindings.com/) a try!
Wow, I really enjoyed seeing how much progress has been made with Rust and gstreamer. I've written a [vobsub subtitle decoder](https://docs.rs/vobsub/0.2.3/vobsub/) in Rust (and fuzzed with over a billion iterations). Is this the kind of thing that would be useful to have available in Rust in gstreamer?
Working on implementing MANIAC trees for my flif decoder. Those should be the last major hurdle before I can start working on getting pixel data.
Benchmarking TiDB against RocksDB is like benchmarking cars against spaceships. The former is a distributed transactional kv store, the later is an embedded storage engine (TiDB uses it internally). 
No question, just want to share that I love how inviting the Rust community is for newcomers.
Two main projects: * First, I am working on a web API service for [IPFS](https://ipfs.io/), which is a content-addressed distributed data store. I envision this service as basically as a way to allow users to request a server to "pin" objects, so you can guarantee an object exists on the network without having to always run your own IPFS node. * Second, I really need to buckle down and polish off ggez 0.4; all that's left is basically a pile of not-super-complicated but rather finicky cleanup and refactoring. After that we'll be in the home stretch: review everything, update docs and examples, make sure everything is free of lints, and so on.
Not yet, I find installation not really easy. I'm dreaming of an 'apt install vim-rust-plugin'...
Continuing work on [tarpaulin](https://github.com/xd009642/tarpaulin), this week I'm aiming to get tarpaulin running on tarpaulin which will mean it can work on projects which also use ptrace (provided the writers of those projects don't steal signals meant for tarpaulin). And should generally increase my robustness. Also expecting to do some work on generating HTML coverage reports, currently have someone helping out making a template which is looking pretty good
Definitely! That would be great to wrap in a GStreamer element. It looks however like your API only works on files, which is less than ideal.
Indeed, it would be a problem with any side-effect in general.
I was aware of cache attacks, where the attacker would purposefully set things up to evict only part of the cache and then use the timing difference (generally in table look-ups). Last I saw implementations were attempting to circumvent this by pulling all cache lines of the tables regardless of whether they were needed or not (which I guess works until the CPU becomes smart enough to detect unnecessary reads...). I hadn't heard about branch-prediction priming, I thought branches were nogo to start with?
&gt; As of C++17 it is guaranteed that each argument's sub-expressions will be fully evaluated at once. Oh! I had not noticed that! Nice to know.
I'll top you anytime, no worries ;)
You want your branches to not depend on secret data. Sadly branches are kinda necessary overall.
&gt; Definitely! That would be great to wrap in a GStreamer element. It looks however like your API only works on files, which is less than ideal. Oh, that's just the high-level API, which operates on Rust `Read` objects. There's a whole layered set of APIs underneath for all the layered packet formats, and most of them can be easily converted to work in other environments with minimal fuss. If GStreamer could just give me the Packetized Elementary Stream packets with the right tags, I could turn them into images + metadata.
Then I don't understand the attack :( If there are no branch depending on secret data, what branches is the branch prediction priming attacking? And why does it matter?
lol ^(this comment edit never happened)
I know, I'm on mobile for the whole day, so I simply copied last week's entry. Will fix once I get to my PC.
Maybe it has, but only on CLion (the C++ IDE that, I suppose, has gdb support), I think. I'm using the plugin on PyCharm and I don't see anything related to debugging for Rust files/projects.
If the branch predictor takes the wrong branch, the code being executed isn't really the code you've written anymore because the inputs are all messed up. I can't come up with a good example right now but the person who described this had a really good one that made sense and if I see them again I'll ask.
Is there a simple built-in way to do a `map`/`for_each` on an iterator in parallel? 
Been working on [wlroots-rs](https://github.com/way-cooler/wlroots-rs). Recreated the pointer and simple examples from wlroots in 99% safe Rust code (only one function is stopping it from being completely safe, and that will be fixed once I add sub types for devices). The best part is how simple the library is in terms of what's needed to make the most basic thing appear. [Here](https://github.com/way-cooler/wlroots-rs/blob/master/examples/minimal.rs) is the most minimal example
The problem is that someone who wants an IDE doesn't want to fiddle much with it before he/she starts to program. The main interest is ease of use, because at first the main interest is learning the language, not the environment around it or ways to be more productive or waste less RAM.
No, but the [rayon](https://github.com/rayon-rs/rayon) crate is usually recommended.
&gt; The only wrinkle is using alt-tab + mouse when I need to use the browser (mostly for looking at documentation). You could use `xdotool` and `wmctrl` to make a script that shows/hides the browser window and call it on a global shortcut (Super+B, for example).
(To be clear, since we're in a beginner's thread: the "no" is "not in the standard library", Rayon is very simple. Just not built in.)
Thanks for clarifying!
Thanks for giving a great answer!
Ah that sounds good then :) I'll check your API in detail when I'm back on a proper computer. I was only checking the docs on the phone. There shouldn't be a problem if it works on Read or accepts elementary stream packets in another way.
&gt; &gt; The original version was written in Rust, but the multiple-minute compile times got a bit annoying, especially in CI. I guess another solution is to distribute compiled binaries for {linux-musl, mac, windows}.
/r/playrust
Issues with **v.redd.it**? Try this **Streamable** mirror!&amp;#32;^^[Why?](https://github.com/aquelemiguel/vreddit-mirror-bot/wiki/FAQ)&amp;#32;&amp;#32; * [**MP4** (31.64 MB)](https://streamable.com/gh101) *** ^^vredditmirrorbot&amp;#32;|&amp;#32;[Creator](https://github.com/aquelemiguel)&amp;#32;|&amp;#32;[Keep&amp;#32;this&amp;#32;bot&amp;#32;alive&amp;#32;‚ô•Ô∏è](https://github.com/aquelemiguel/vreddit-mirror-bot/wiki/Donations) 
What about it 
Looks fairly good, some of your loops I'd replace with things like fold, filter or map on the iterator e.g. delta calculation on line 165 I'd use fold and multiply the result by v. Also, for the example in the readme instead of using the array and putting the result as uninitialised I'd use a vector, or derive default for the struct and fill it in. Just because the unsafe code isn't necessary. Congrats on your first crate! If you haven't already, running clippy on it is a good way to find out where there's a more idiomatic rust style
I hope the PEP will be amended before 2020 though‚Ä¶
I would like to see some benchmarks against other similar projects projects like [Zookeeper](https://zookeeper.apache.org/), [Ratis](https://incubator.apache.org/projects/ratis.html), [etcd](https://github.com/coreos/etcd) and others.
I don't foresee that happening. The change is mainly consequential for script shebangs. Python 3 scripts already should link to python3 anyway, not the generic python executable. The biggest lag is Python 2 scripts that were written to run on systems without a python2 executable (it's still the only reliable way to get Python 2). Such systems are dwindling, but definitely exist. Given the far reaching consequences of that change, I don't see a switch over being rushed.
Might need me to export a new entry point or two. I keep my published API small because of semver rules, and only export what people have use cases for.
&gt; some of your loops I'd replace with things like fold, filter or map on the iterator Duly noted! I don't come from a functional background so I almost never think to use those constructs; I'll fool around with them in a branch. &gt; Also, for the example in the readme instead of using the array and putting the result as uninitialised I'd use a vector Yeah using unsafe in the example is pretty silly, I thought it was the "simplest" but I don't want people to think unsafe code is necessary or anything like that. &gt;Congrats on your first crate! If you haven't already, running clippy on it is a good way to find out where there's a more idiomatic rust style Thank you! I did run clippy and rustfmt :)
Sweet! This is awesome üíñ
Is your error type also `Debug`? According to the implementation in the docs, the error type must be `Responder&lt;'r&gt; + Debug`. I can't think of anything else that would cause this, though I haven't used rocket much. https://api.rocket.rs/rocket/response/trait.Responder.html#impl-Responder%3C'r%3E-7
is... this about the video game?
this subreddit is about a programming language.
Except that the ABI is defined and fairly stable on each individual platform and (on most platforms that are not Windows) there are multiple compilers that do interoperate together. It's true that every now and then they make breaking changes but the official stance is that between those ABI stability must work. And looking at things like Debian, it is in fact working fairly well.
I think this belongs in /r/playrust.
An invalid hit, indeed. &amp;rarr; /r/playrust
You probably want /r/playrust/
I checked with `cargo rustc -- -Z unstable-options --pretty=expanded` and it does implement `Debug` 
Well I'd like to make it a complete game for itch.io and probably steam. The game will be free I think. The code is too WIP yet.
);
What happens if Game is not wrapped in a mutex?
/r/playrust
I'm really tickled that the game I'm excited about is also using a language that I'm excited about. Thanks for opening up about this!
This is super exciting! :D can't wait to see this come out!
That's awesome, thanks for sharing with us. Since this is a bit of an AMA, I'd like to ask you: I know console SDKs and what not tend to be under NDA, but any chance that some of the interfaces for working with consoles could become available? Or even your technique for patching std?
Thanks for Starbound, first of all, I really enjoyed it! Re pt 4: Did you consider languages with a GC, like Go? Is 'no GC' an absolute requirement? I ask just because Go is my second-favourite language, and I'm curious whether it's practical for game dev. 
Just released first version of the [actix web framework](https://github.com/actix/actix-web). Now planing to work on http/2 support
I'm pretty sure he has a nintendo switch: https://www.nintendo.com/games/detail/wargroove-switch but I'm not affiliated with chucklefish.
&gt; I feel that rust solves a lot of the problems and matches a lot of the lessons that I learned making Starbound A few of my colleagues and I are curious: can you talk about one or two of the problems that Rust solves for you here?
Regarding choosing rust specifically, not too much honestly. I was pleasantly surprised once I was done with the portability side of things with how much effort it actually was. If anything, at least for me personally, if I was the technical lead of another game project the decision wouldn't be between rust and C++, it would be more between using rust and using an existing engine, and then using whatever language had the least friction with that engine. Obviously if Chucklefish branches out and does some work in 3D, then the equation is going to change haha. I actually DO have one major regret though, and that is that when I was exploring alternatives to C++, I didn't start with rust. I actually built quite a lot of a 2d game engine in Haskell first, before deciding against it for various reasons, and I feel like I wasted a lot of time. Please don't take this as too strong of a criticism of Haskell though, I still love it and kind of miss it. We have our own ECS system that has a few nice properties that I couldn't find in other ECS systems, but I might end up regretting using our own ECS system vs just using specs, time will tell I think. On that note, I sort of regret not using more of the rust gamedev ecosystem libraries, but I knew that I needed to move really fast and was going to be pushing things in a lot of different directions and getting things to run on closed platforms, and I knew I needed to be *opinionated* about APIs so I could eliminate a lot of the work. That may just be an excuse though. There are of course lots of other little technical things that I did the wrong way before figuring out the right way (at least, I think it's the right way?) but I guess that's just development in a nutshell.
One of my favourite devs using one of my favourite languages! I'm curious about how you deal with game logic architecture, basically do you use any sort of scripting? As a hobby game programming tinkerer and a huge fan of your games I'd be interested to know if you write your more specific and less game general logic in the main language (Rust, C++) or implement some engine specific logic systems. I haven't touched Rust in a while, been C++ing for a bit, but I don't remember much in the way of scripting language integration, although I guess that's just an issue of maturity... I'm not really a huge fan of most scripting languages but being a massive architecture nerd I think I'd implement it just for the sake of it. Anyway super duper hyped for Spellbound, if it's anything like an LWA RPG I'll be happy forever. If you get it on the Switch I'll buy it twice!
No, they haven‚Äôt: https://github.com/intellij-rust/intellij-rust/issues/535 And I don‚Äôt even bother trying it out before the debugging is implemented (subscribed to the issue tho). You see... I thought debugging was what every programmer needed, but perhaps many Rustillians are so smart that they just never have bugs?
How are you using Nom?
Given that they mention contributing [rlua](https://crates.io/crates/rlua), I suspect that Lua is a significant part of Starbound.
Sure. It‚Äôs just important to understand exactly what th standard is here.
I really liked playing Starbound. Very exciting to hear that you are making a game in Rust now.
Garbage compilers cause temporary freezes in games from what I understand. You can witness this in Minecraft. If you press F3 while blowing up tnt, you will be able to see that memory usage will go up until the game freezes and then the memory will be freed. It will up again after that.
API seems pretty nice. Reminds me of some Go stuff for some reason.
 I‚Äôm frankly too excited/speechless to really ask a question. Just.... &lt;3
I really really want a way to share the stuff I've done, but I just don't know a practical way to do it. I don't think that console companies have a lot of incentive to help with this sort of thing, and I just don't have a whole lot of time or energy to go deal with the administrative / legal headache of doing so either. It's really a shame, I have a lot of strong opinions about how much better things would be for everyone involved if things were more open, and things ARE starting to extremely slowly move in that direction, but imo it needs to speed up. I can share my technique for patching 'std' though in vague terms. First of all, it's pretty hacky, my goal was not to port 'std' in its entirety, just enough to get things to run. It turns out, there's not THAT much to do anyway, because there are huge swaths of things that just are impossible to port to consoles anyway, like anything to do with the network or spawning processes etc. First, I started with rust-src as downloaded by rustup, and I put it into a private chucklefish repo. Then, I made a branch on which I would do modifications to libc and libstd etc, and then added that branch as a submodule in our project. The reason you do this is so that then you can update rust-src on the master branch, and use git merging to merge in your patch set when you want to upgrade rustc / rust-std in tandem. Then, you need the EXCELLENT 'xargo' tool, and you can make a new platform triple .json that matches the platform you're targetting, and give it a new name. You can then write a build script that uses your fork of libc / libstd etc, and try and build just some very small example static library. Everything will fail, because conditional compilation stuff for your target is missing. You have to go through and everywhere that needs your new target name, change the configuration so that it includes your new target. This sounds MUCH worse than it actually is, the reason being that consoles are.. I have to be careful how I say this.. generally they are close to SOME existing platform, and you basically just copy all the stuff for that platform into a new version for that target, and it will mostly work. If you did it like me, you will end up with a special module in libc for your new platform, and you will end up with a new folder in libstd/sys/ for your new platform that is based on one of the other folders. What will happen is, you'll pretty quickly have something that compiles and links into a static library, but doesn't link into a wrapper project, because you've gotten a lot about the platform wrong. At this point, you can cheat and turn on LTO, and pretty quickly get SOMETHING running. You then just try and keep using APIs that you know you need, and making sure those link correctly and are usable and don't crash, and here's where there is a lot of stuff that I know how to do and would give advice, but I can't because NDAs :/ The kicker is, that most of the stuff that ends up being a problem, it would have also been a problem even if you had some custom C++ engine, because it's the places where the console APIs *differ from some existing platform*. You WILL end up with some magic somewhat hacky code to work around bugs in the console APIs, and you just have to find out what and where it is. A lot of the API, you can just keep writing panic!("not available on XXX"), or just keep relying on LTO to weed out that symbol in its entirety anyway. This sounds like a lot of work, and it sounds really complex, but I can promise you that it's really less bad than it sounds. A while back, as an experiment, I tried to just get some rust that used no_std to run on as many platforms as I could, as quickly as I could, and I was done with all three *in one evening*. The only difference between no_std and std is basically just writing a lot of platform C-like code, so you just fix things one at a time until enough of std works. It definitely takes some skill with low level programming, and it could 100% be easier, but I think that if I could wave a magic wand and make console development open, the rust developers would have those as a tier 2 target within *a week*. If I could make one request that would have made this VASTLY easier, I would request some kind of "generic" platform, where everything was an easy to get at stub implementation that you overrode piecemeal. I know that this is an existing goal, and I know it's not *simple*, but that would have been absolutely brilliant and made everything much easier.
Thank you for this. You have pretty much already answered all the questions i was going to ask :D But i think it's pretty cool, that Spellbound is written in rust and a project like this will also be some good advertising for rust. But i have some questions anyway: * In your crate list you mentioned rlua, so i guess the game will not be 100% rust but rather the engine is rust and all the scripting is done in lua? * What environment/editor do you use? Popular choises are IntelliJ, Atom and Sublime. Or do you use something else? * Do you think that rust will be a strong competitor against C/C++ for game development in the future? Also, how "ready" do you consider rust (especially in the light of game development) to be? Apart from that i have to say that i and my little brother have been quite hyped for this game since the first teaser screenshots. In that regard, do you already have a prospect for when the game will be released? P.S.: As for the name, my brother suggests that you should stick to "Spellbound".
## Indigo UI Framework This past week I got some more work done on Indigo, my UI framework prototype for Rust. (See last week [here](https://www.reddit.com/r/rust/comments/76o9fi/whats_everyone_working_on_this_week_422017/dofjy1r/)) I was feeling under the weather this week so I didn't get much done, but a few cool things did make the cut. Here's what's new: ### Invalidation I implemented invalidation support. There are a few kinds of invalidation: - Restyle - An example of this is a visual state change. Visual states are a closed set of states in the framework. Some examples are Hover, Pressed, Checked, etc. - Relayout - Relayout sometimes runs after a restyle (depending on the properties changed in the resolved style). Layout accepts a tree of primitives and turns this into a positioned tree of primitives (sets bounds on them) - Rerender - A rerender rebuilds the display list based on the last tree of primitives sent to layout. This display list is then sent to WebRender. In Indigo, properties can be registed using the property! macro and you can supply various bits of metadata. This takes the form of a default value for the property, whether or not this property is inherited from parents, and the damage it causes to the UI graph when it is changed (Relayout or Rerender). You can imagine a Width property triggering a Layout when it is changed, where a BackgroundColor property only triggering a rerender. There is also a set_state method which takes a ComponentState type (An open set of types represented using a trait object). This is used for component state which is fairly specific to the component. For example, a Todo component would have a vector of Todo items as the ComponentState, and push items into that vector then call set_state. So invalidation works, and I'm pretty psyched about it. It is very crude at the moment, returning a list of RSX nodes from an expression body of a parent RSX node isn't as clean as it could be. I'm probably going to work on this for next week. fn render(&amp;mut self) -&gt; Option&lt;NodeRef&lt;Box&lt;Component&gt;&gt;&gt; { let stack_panel = ui!(&lt;StackPanel HorizontalAlignment={Alignment::Start} Width=200. /&gt;).unwrap(); for clr in &amp;self.state().colors { stack_panel.append(ui!(&lt;Button Width=50. Height=20. BackgroundColor={clr} /&gt;).unwrap()) } Some(stack_panel) } [Here](http://www.videosprout.com/video?id=2bd000bb-4a47-4cc4-9d05-baf11e58064d) is a video showing invalidation in action. There is a click handler on the root UI component which has a state object defined as a vector of colors, it adds a new color on every click, which runs invalidation and rerenders as necessary. ### Properties I worked a bit on the property macro and got pretty printing of PropertyName: PropertyValue pairs (previously these were opaque K,V pairs of (TypeId, Box&lt;Any&gt;)). I also worked on allowing merging of styles, this will aid me in further fleshing out the restyle code. out before I could move on this anymore. ### Next week A couple of people have asked me about when I'll be open sourcing it, I'm working on cleaning up the code base to allow for that. I've never run an open source project so it is all new territory to me :), but I very much intend to release it to the public soon.
I know this is a bit off topic here, but do you have any kind of writeup with the details of why Haskell wasn't appropriate, or if not, have you considered writing one? I remember having heard of both the attempts and shelving of this, and was curious about the decision process.
I'd love to read blog posts or watch a conference talk about your experiences. This really seems like one of the most interesting projects currently done in rust.
&gt; Thanks for Starbound, first of all, I really enjoyed it! Thank you very much! More people than just me worked on it though of course haha, but we're all super grateful to hear stuff like that! &gt; Re pt 4: Did you consider languages with a GC, like Go? Is 'no GC' an absolute requirement? I ask just because Go is my second-favourite language, and I'm curious whether it's practical for game dev. I think not having a GC is not actually a hard requirement, I shouldn't have put it exactly that way, but I think the language should either have a very low hard upper bound on pauses, have a way to idiomatically program in the language that is easy on the GC, have independent GCs per thread, or preferrably all three. This is one of the things that was a major problem when I was researching haskell and was basically the dealbreaker, so that's why I mentioned it. Anything with a runtime though, I think is much much harder to port to consoles, but I've never actually done it so take what I say with a grain of salt. I don't really want to take hard sides or start language wars or anything, so if you like Go that is 100% fine by me, and it may be that go is absolutely fine for gamedev or at least a significant subset of gamedev. Like anything, it depends on your requirements / skill level / tolerance for frustration haha.
Just for clarity, I'm not currently working on Wargroove, but I might actually be doing some server-side work for Wargroove, not quite sure yet. Wargroove is actually the *other* current in-house project, and is done in C++ and the lead programmer there is the *absolutely excellent and amazing* 'amzeratul' (third row, second column [here](https://blog.chucklefish.org/about/)). Also, just so you know, I'm second row second column :).
I'd like to second this. One of the best things anyone can do today to promote Rust adoption is talking about what they are building. This is doubly important for areas where Rust has little-to-no market share. Thank you Kyren!
I really should do a writeup, but I can give you a pretty quick takeway. These are in roughly descending order of importance: 1) GC pauses are proportional to the working set of memory 2) One GC for all threads, so you can't work around problem 1) 3) Porting a runtime is hard 4) Haskell is not as good as other languages when you have to effectively write a bunch of C. It felt like I was just mostly writing C with mittens on my hands. Caveats on this one, it may just have been me, there may have been better ways to do it, it could have been *me* not Haskell, I'm willing to be convinced otherwise there.
Thanks for taking the time to post this! This is super-exciting to hear. I'm particularly interested in how you were able to patch std/libc/rand. Is the technique fairly reproducible, such that someone else (with the appropriate license, natch) could easily reuse this work? I take it folding it into the regular rust repo is legally impractical, but in a networking setting would it be possible to package up the work to share? (Note that i don't have a license to any platform nor am i actually asking to see it, i'm just curious.)
I don't have any Go experience, can not comment on that :)
Wow, this is amazing! I love your games! Stardew Valley is one of the most relaxing games I've played and I really love it. Someone linked to this on Twitter and I was like "omg omg they're probably making a new game gotta see this", _before_ I realized what sub this was on. Then I opened the link, started reading, and realized that the theming of the subreddit was suspiciously similar to that of ... OH, OMG. :) &gt; We patch 'std', 'libc', and 'rand' to build with custom targets for each console, I understand you can't talk about the details here, but it would be nice if these could be eventually upstreamed somehow (at least, in part?). Rust on consoles is something folks have made work but I don't think it's something that's well documented or "easy" to do, yet. ----- Some questions: - What was the _worst_ thing about using Rust? (i.e, what can we improve upon?) - Not a question, but: OMG OMG OMG - How was the experience ramping up your team on Rust? (again, what can we improve upon?) - It seems like you're doing a nontrivial amount of FFI to existing C++ code. Are you using bindgen? How challenging was building this portion of the codebase? - Do you use clippy? :) - Would you like to be on https://www.rust-lang.org/friends.html ? Once the game is released (pre-release is also fine, "available to consumers" basically), if you follow the instructions at the bottom of the page, you can be! - Also not a question: OMG - We (the Rust [community team](https://www.rust-lang.org/en-US/team.html#Community-team)) often organize chats with "production" users to get an idea of folks' needs, and to help them in any way we can. It should also be possible to do these with an NDA (we haven't had to yet, so I'm not sure) if you wish to more freely discuss things. We've found these very helpful in the past; it helps us get a better picture of things and prioritize. Would you like to at some point set one of these up? If so, please contact us at community-team@rust-lang.org (or talk to me here) 
I'd be interested too. If I had to take a guess dealing with pointers and any low level stuff in Haskell is an absolute pain and it's GC'd which from what was stated above seems to have been a problem.
If you're able and willing, I think the biggest thing you could do to help Rust would be to write up an article talking about how you structured the code in broad terms. The borrow checker makes a lot of common patterns unusable without dropping into `unsafe`, and one of the hardest things to help new Rust programmers with is "so how *do* I write this?" Having an article from a developer with practical experience on a commercial project would probably help a lot. --- Aside: &lt;3 Chucklefish.
I love this approach! I had built something similar in Ruby eons ago, but always wanted something statically typed. I‚Äôll be sure to check it out. 
https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dosnuki/
joshmatthews has it exactly right, Lua is a significant part of Spellbound (and, incidentally, Starbound!). You have it basically right, that the more general purpose stuff goes in Rust, and the more specific stuff goes in Lua. All of our in-house games actually work like this, and it works out pretty well, both because it allows for pretty easy modding (we're big on modding), and also because it actually provides a pretty clean architecture boundary layer. We refer to it internally as the architecture sandwich (we're hardly the first people to come up with this idea, I know). You have 3 layers, engine, scripting, and data, in that order. If you have to put in a hack, you put it at the *lowest possible level*. You know that the engine should always basically be clean and predictable and there should be no surprises, and your messy game specific behavior goes in scripts. This basically serves to reduce complexity on both sides of the boundary, the engine doesn't usually get into the nitty gritty of game logic, and where the complex game specific logic goes doesn't have to worry about how the engine works. This is nothing exactly earth shattering, of course, lots and LOTS of game engines work like this, this is just how we've talked about it before. I think that the 3 layer system is a pretty good way of describing it, but I also think that sometimes 2 of the layers can be the same, you could have layers 1 and 2 be rust, and similarly you can have layers 2 and 3 both be Lua, depending on your tastes.
&gt; GC pauses are proportional to the working set of memory IIRC a cycle collector has pauses proportional to the amount of garbage (as opposed to all memory), so you can avoid this problem if you have relatively small amounts of garbage. But I don't know if you can easily shoehorn a CC into Haskell. &gt; It felt like I was just mostly writing C with mittens on my hands. I love this description :) (This also applies to doing low level pointer-frobbing in Rust)
Thank you so much! Thank you for all you do for the rust community as well, I super super appreciate the kind words, lots of &lt;3 here :D
It's too bad that Microsoft / Sony / Nintendo can't spend the time to get their platforms fully supported as a tier 1 target. I could easily see Rust becoming the next industry standard for game development, if they were to promote it as they are doing with C and C++. I've really liked how convenient it is to eliminate a lot of logic errors by creating APIs with state machines powered by move semantics.
We encountered almost exactly the same issues setting up a toolchain for targeting the 3ds (and Vita) using the homebrew devkitARM toolchain, and xargo ended up being the saving grace. Funny. Modularizing libstd or otherwise providing a better path to implementation of unsupported platforms was talked about back in 2015 due to a number of posts, mine included, on internals and in the blogsphere. Nothing has come of it so far. It would be really nice to get on a path to this in 2018, although xargo being able to override libstd has been okay in the meantime. Would be really neat to see gfx-rs get backend support for e.g. Switch.
Thanks for making this post! I was looking in prototyping a small game engine project in Rust and noticed someone else was doing the same after searching for rust-lua bindings. I'm still in the earlier stages of both Rust and game engine development work so I apologize if the questions seem to generic or technically simple. In trying to reconcile your use of Lua against the desire to avoid a GC, presumably the Lua is there to handle game logic and, like the graphics system, merely interacts with the game state via the central ECS? How do you manage tracking 'what' in the engine the Lua code still needs references to? (Rc's wrapped up in Lua userdata?) Are there any major pitfalls in engine design that you wish you would have known of earlier? Do you have any particular advice on deciding what goes into/how to specify the Lua bindings constituting the 'engine API'? Did issue #38 (panics and aborts) end up being particularly restrictive or challenging to debug in practice? Do you use any IDEs to develop in Rust? Relatedly, how do you manage debugging (Rust code, lua code interacting with Rust, rendering issues, etc.)? Other non-Rust devs are tempted by C++ due to the integrated debugging tools (and, in the case of Visual Studio with DirectX, integrated graphics layer debugging). However, I've been using IntelliJ and it seems OK so far. If you do use an IDE for Rust, do you think it is worth authoring a small plugin that adds your engine bindings to the LUA plugin? The gl crate exposes a fairly 'unsafe' API. Do you have any advice on constructing safer wrappers around that and integrating those with the rest of the engine. (Also curious of your opinion on gfx-rs and how they wrapped up their safe API, albeit targeting Vulkan rather than OpenGL.) For physics, really collision detection, did you end up rolling your own solution or wrapping up something like Box2D, Bullet, etc.?
I can talk about two big ones, both to do with performance. There are others, but these are possibly the two biggest. The first one is simple, and that is parallelism and concurrency is *super hard*, and rust is one of the few languages that really gives you a large amount of confidence that your parallel / concurrent code is anywhere near correct. This was something that I got really wrong in Starbound (it's entirely my fault, I can't lay the blame on anybody else really), and is still painful to this day. The xbox one and ps4 both have shockingly anemic single core performance, and make it up with having multiple cores, and at the end of the day Starbound is just NOT parallel and there's no easy way to make it be so. This is particularly bad because of how CPU intensive Starbound is as opposed to being GPU heavy like most games are, so this was and is still a huge challenge. The second one is related to the first, and that is that I worked extremely long and hard to optimize starbound (partially because of the first problem), and at some point the only optimizations left to me were *structural*. Let me explain a bit what I mean by that, I'm gonna go into detail of one example with Starbound, so sorry in advance for all the unnecessary information. Starbound has a crazy system for dealing with collision geometry of blocks. When you have blocks sitting in the world, they cause collision geometry to be generated where they're placed (if they collide), but the geometry they generate is based on cellular rules, similar to but not exactly like marching squares. The algorithm is pretty complicated, so you need to cache the results of the algorithm inside the storage system for the world you're in. Collidable entities need to go request this collision geometry, and also trigger it to be JIT built if it's not already available, and it works mostly okay. At one point in development, I realized that there was a hot spot in the server-side main loop, and the hot spot was related to collisions. Okay, that's reasonable, I mean the 2d collision response algorithm is not exactly simple, and the generation is certainly not simple, so that's understandable. I look closer though, and I realize that the actual culprit is *copying around polygons*, and the allocations that it triggers are roughly 10x the cost of anything that it's actually *doing*. You're left with a couple of options, you can return pointers / references to the cached geometry, but for complex reasons *that is incredibly terrifying*. LOTS of things can invalidate the cache, or clear the cache, and now you can't be sure that your reference won't be invalidated as you use it. You can try and copy to buffers and re-use buffers inside the code that handles collision, but that's very very very complicated. You can try to use shared_ptr, but now you are pointer chasing because you have a shared_ptr to a vector. What I found after doing this for a while, was that most of my performance problems were like this, *dumb*. I was losing performance because I was invoking copy constructors needlessly, I was losing performance due to allocation, I was losing performance because the easy and safe thing to do was *the slow thing*. I'm sure that C++ is not "at fault" here, and in fact since doing a lot of rust dev I would definitely do a lot of these things differently, but the thing is it was only after using rust for quite a while that my mental model of what I was doing wrong really started to crystallize. There are definitely a lot of factors here as well, it's not ONLY C++, a big part of it also was using and sticking with OO programming patterns that I've since abandoned. I guess I would say that, it's not only important that it be *possible* to do a good design in a given language, but that the language actively encourage it by *making the bad design painful*. I think rust does a FANTASTIC job of this.
Yeah, no kidding. Having the Switch running Rust code is proof that it's really ready for production use basically anywhere.
You might not be able to open source it, but if you're willing you might be able to take MikeZ's approach for his [PS4 USB driver](http://skullheart.com/index.php?threads/looking-for-dualshock-3-driver-help-for-ps4.4164/)-- keep it closed source, but license it for free for those who've signed an NDA for a particular console. This approach seems to have worked out well for LabZero, as MKX and SFV both use the driver. Best of luck getting your stuff out there, hope it works out!
If I could wish an outcome into existence, it would really be that *no* language is the industry standard, and that lots of languages are possibilities. I know that this has practical downsides, but I really think that's the most healthy outcome, and is generally possible with open platforms. Let a thousand flowers bloom!
For a larger example like this it would be nice to have a few comments. Not too many, but just a few. And maybe some 'sample input/ output' ie: "you could curl the server with this, and youd get back this" just to help internalize the control flow. Also, really cool. I'm going to play around with this for sure.
Thanks for sharing, this is an awesome thing to hear about! I'm quite interested hearing about what sort of high level data structure implications Rust's strictness has had, particularly compared with what you were doing in C++ for previous games. Have you run in to any difficulties with the compiler for what I'm assuming is a rather large and stateful application? Do you think the compiler has had an impact on the quality of code you've produced at that scale?
I added comments to complete websocket example [here](https://github.com/actix/actix-web/blob/master/examples/websocket.rs) 
Ooo! I'm currently working on a language based on Haskell, but with memory management similar to Rust. While I doubt it will ever be big enough for any serious users other than myself, it's nice knowing that the niche I'm trying to fill is something that's desired, especially from the creators of Starbound (56 hours personally).
&gt; Oh, I see; this is not something that you can't talk about till the game release, it's because of console NDAs. Oh well :( I can't talk about it *at all*, afaik, even after release. You can't discuss or share information on console APIs, the rules are very strict. I would in a heartbeat if I could, but of course if that was true, rust would already be 100% supported because it is not that hard and other people would already be working on it in the open. Microsoft deserves some kudos here for pushing things forward https://docs.microsoft.com/en-us/windows/uwp/xbox-apps/ I'm going to go through all your questions! &gt; What was the worst thing about using Rust? (i.e, what can we improve upon?) Hmmmmmmm, that's a good question. I'm not sure *exactly* if I would answer this way, but I know exactly what the other two Starbound programmers who are currently part time on Spellbound would say, and I have to say I don't disagree. *Floating point comparisons*. I know that there's not really a good answer here, and we do have *most* of a handle on it now, but it is just super super painful. The thing is, after programming rust for a while, if I go back to another language I'm *terrified* of floats, because I know that it never really *worked* there the language just doesn't *throw the problems in your face*. The absolute 100% killer best feature of rust for me is lack of UB, and floats are like kryptonite for this :(. I don't even know how to solve this or anything, but if I could just wave a magic wand, I think I would go for a NotNan or Finite type that was built into the language or something and was Ord. I'm sure there are problems there I'm not thinking of though. Our current solution is something like the ordered_float crate in combination with something like the ord_subset crate. &gt; Not a question, but: OMG OMG OMG \&gt;:D &gt; How was the experience ramping up your team on Rust? (again, what can we improve upon?) There are two other programmers who are working on both Starbound and Spellbound at the same time, and they've been taking this time to get up to speed with a new project and engine etc. They've honestly not had *too* bad of a time with things, partially because they're really really capable and all around awesome, but also because it's honestly not too bad. I think that a lot of the design pain was more early on, and hopefully it helps to learn coming into an existing project rather than something green field. I think the biggest gripes and confusion have been things that would be solved by NLL, and also again floating point ordering. I think the question of what is the most painful and what is the hardest to learn are really two sides of the same question, they're smart enough to get the *concepts* quickly, it's when all the designs that they would naturally write seem to generate errors and they don't know where to go is where it is really painful. &gt; It seems like you're doing a nontrivial amount of FFI to existing C++ code. Are you using bindgen? How challenging was building this portion of the codebase? I SHOULD be using bindgen, it's actually on my list of things to do. For all three consoles, there are input / rendering / audio APIs that are C that wrap the platform API, but when you look at them they're actually kind of small, so I didn't use bindgen. I SHOULD be using bindgen there though, and if I have to change them again I probably will do that. I'm gonna try and say this without running afoul of NDAs, but most of the consoles have like, a huge chunk of them that are just modifications of some existing platform, and so there's a lot of C functions available, and they're super close. That stuff, generally it's just a matter of modifying 'std' to fit it and mostly working around bad implementations, so that stuff doesn't need bindgen because it just all lives in libc or similar. The rest of the APIs are the rendering / input / audio APIs I mentioned above. &gt; Do you use clippy? :) [Given you've forked the stdlib and clippy is strongly tied to nightly versions I suspect this to be a no] We use clippy! I LOVE clippy, it's especially helpful when learning. We generally do development on the PC version, and just make sure that the console versions still build as we go. In fact, we use CI really heavily at chucklefish, so we can just hit a button and out pops a [REDACTED] file ready to be tested on [REDACTED]. We don't used patched libstd on the PC version or anything, it's just normal everyday rust. &gt; Would you like to be on https://www.rust-lang.org/friends.html ? Once the game is released (pre-release is also fine, "available to consumers" basically), if you follow the instructions at the bottom of the page, you can be! We would love to be on that list! I can't say ANYTHING about how long it will be before pre-release or release, or whether or not there will be a pre-release, but once we do I'll look into that! &gt; Also not a question: OMG &lt;3 &gt; We (the Rust community team) often organize chats with "production" users to get an idea of folks' needs, and to help them in any way we can. It should also be possible to do these with an NDA (we haven't had to yet, so I'm not sure) if you wish to more freely discuss things. We've found these very helpful in the past; it helps us get a better picture of things and prioritize. Would you like to at some point set one of these up? If so, please contact us at community-team@rust-lang.org (or talk to me here) That would be great, actually. What would be the next step to set that up? Also thank you for all the love and support, it means a huge amount to me, and thank you for all your hard work on rust and servo!
&gt; twox-hash "author" of twox-hash here (really, I just ported it directly from the C++ and made sure the speed was comparable) ‚Äî may I ask where it comes into play for a video game? Can't wait to play it!
&gt; In your crate list you mentioned rlua, so i guess the game will not be 100% rust but rather the engine is rust and all the scripting is done in lua? yep! &gt; What environment/editor do you use? Popular choises are IntelliJ, Atom and Sublime. Or do you use something else? Spacemacs &gt;:D &gt; Do you think that rust will be a strong competitor against C/C++ for game development in the future? Also, how "ready" do you consider rust (especially in the light of game development) to be? I hope so, but mostly I just want there to be more options. I would be just as happy for there to be multiple choices than for rust to "win out" over C/C++. I think rust is ready in terms of being a general purpose systems programming language, but being "ready" for any particular domain is kind of a complex question. It just depends on what kind of development you do and what your requirements are, and it may very well be not ready for any given particular project. &gt; P.S.: As for the name, my brother suggests that you should stick to "Spellbound". Spellbound is my favorite name too, but we'll see haha.
I'm gonna look into that actually, that may be a good model of how to do this more in the open. Thank you for that link!
&gt; Garbage compilers :P The trick is to avoid allocation. No allocation, no garbage collection. At least in C#.
garbage compilers, or collectors?
I was actually hoping to find a better link, but all I could manage was that and fighting game news articles which wouldn't have been much help. You should probably send MikeZ a [tweet](https://twitter.com/MikeZSez), maybe he could point you in the right direction or a heads up on some legal issues he encountered.
Not a question, but thank you for open sourcing pieces of your engine! This makes me love you guys even more.
I am the creator of a Rust Operating System called Redox. Is there some way we could work out sharing the engine code, under an NDA even? I would love to port it to Redox!
You mentioned the difficulties of parallelism/concurrency, and the way it's basically required on consoles - have you considered a concurrency-focused language like Erlang/Elixir/LFE? I haven't seen much in that direction, and you seem willing to try new things to see if they're helpful.
I think the animation might be at fault as well. Because it takes a considerable amount of time for the new position to become visible (the square starts small and grows), our perception lags behind by half a square at least. Anyway, this is awesome, and I'll be looking into the code closely. Run Rust in the browser, oh yeah! We need a Piston backend.
The way you frame that specific performance problem is interesting: In the past when I have to generate collision bounds for tiled geometry I cache the tile information necessary to make collision(e.g. there's an addressable LUT of different walls and slopes), but only go further after it hits in the broadphase which just iterates over tiles based on the actor AABB - no polygons get copied because the necessary line segments are generated on demand, and I can customize every algorithm for every tile type if needed. The cost scales with the size of the actor and number of actors colliding, but in the average case it's only a point-equality or AABB test which is about as low as you can go for narrowphase collision, and it will cut down on cache thrashing. If detection doesn't have to return contact points or pushout info, some parts can also be computed branchlessly with an integer counter and bitmasking to ease prediction...and if your tiles are small enough and you aren't going for subpixel precision it can be a straight-up AND of two integers representing pixel perfect masks. I can see where my approach might become more of an issue, though, if there's wide variance in object scales or there's a need to handle dynamic rotations.
It's actually pretty interesting, but you might think it's insane. After designing the rendering API for Starbound and thinking for a long time about how to do a good 2D rendering API, I came up with a pretty solid design that's a bit.. non-traditional. Only half of this has to do with twox-hash, but the two parts are interrelated and.. I want to talk about it anyway :P Sorry for hijacking the comment! There are two key parts to it. One, especially when dealing with older graphics APIs (we are targeting a minimum of OpenGL 3.3), it is actually kind of non-trivial to batch 2d rendering. This problem is especially prevalent in Starbound, where you can have 10k polys on screen and each one uses something that is potentially from a different on-disk texture. Naively, this would batch horribly, because you only could use say a max of maybe 8 or 16 texture units or something, so that translates to maybe 1k batches of polys, and a huge amount of overhead, and it's very complicated to try to use multi-texturing like that to reduce batching, and you also may need multi-texturing for other effects. In order to batch more effectively, you have to put your tiny 2d textures into what's called a texture atlas. Usually, this is done with 2d box packing algorithms and is done offline, and you have to group your textures by some function that associates them because they are related to each other and likely to be drawn together. So far, this is super normal and everybody does this. This involves some friction though, if the answer to the question "what textures should go together" is hard to answer. This is ESPECIALLY hard to answer in Starbound, where you can stick any object near any other object and just generally do whatever you want. This is less of a big deal for Spellbound, but it turns out the solution is so nice that it's just easier to do this even if it's not necessary, and that is dynamic texture atlasing. So, what Starbound does is kind of complicated, it contains a series of very large 2D texture atlases, and constantly pushes texture new texture data into the atlas and then clears out textures from the atlas that haven't been used in a while, while also managing multiple sets of these in case of overflow. Because there are multiple sets, it also has to compact them occasionally so that they don't become sparse, and it's actually a huge headache. In spellbound, there's something vastly simpler that you can do if you limit yourself to &gt;= OpenGL 3. You can basically get away with *one giant texture atlas*, because you can just make a giant 2d texture *array*. Effectively, what you are doing is saying to OpenGL, "hey, all I have are tiny textures, and I have *thousands* of them, just give me a big chunk of memory and give it a single texture, and I will just manage the memory myself". It ends up being very very simple, works everywhere I've tried it, and the number of batches you end up needing become very small, limited only basically by changing shaders / shader parameters, which is what you want. So that's the first part, that texture loading and atlasing is complicated, it's nice if you can do it at runtime but doing it at runtime is complicated, unless you have OpenGL 3 or above at which point it becomes relatively simple again. But, you end up needing to disconnect loading a texture from how the game logically loads / references a texture, and that's where the second part comes in. What Starbound does ended up being super bad, which is if there is something that needs to draw a specific texture or subset of a texture, it references it by its asset path with an optional extra bit for the sub-frame. Until rendering actually happens, the in-memory representation of the drawables is just that, a string reference to an asset. This ends up being *super* slow, because you constantly have to look at a string path and hash it and look it up in string maps etc to get at some internal texture representation. Also, this makes dynamic texturing impossible, because dynamic textures do not have an asset path. What Spellbound does is much simpler, there is simply a type called "TextureImage", which is a shared, *immutable* handle to image bytes, and carries with it its 64 bit unique hash. This handle serves double duty, it lets a system which will need a texture keep it loaded in cpu memory in case it needs to be put back into the texture atlas, and it also serves as a super cheap identifier for texture data because all comparison operations just use the assumed unique 64 bit hash. This also very easily allows for dynamic textures, but stilly nicely limits the per-frame texture upload. But wait, you might say, hashing a texture must be super slow! Nope, twox-hash is plenty fast enough! But wait, 64 bits is not necessarily unique! There aren't going to be more than, say, 10k possible textures, so if you look at [this](https://en.wikipedia.org/wiki/Birthday_attack) chart, you can see that our chances of collision are at least as small as 10^-10 or so, which is 100% fine by me :) So yeah, that's where twox-hash comes in, I use it to hash image data to produce "unique" ids for them.
We're *mostly* using num-traits tbh, and we're using it in the obvious way, when writing generic numeric code.
Can you explain this further? I didn't quite follow. 
Also that quote had a bit of, ‚Äúlet the flowers bloom, so I know who to crush‚Äù deal going on. 
There's absolutely a broadphase part to it, I'm only describing what happens with the collision geometry that has a chance of intersection after the broadphase culling. The rules for Starbound are complex though, so a single tile is allowed to generate geometry.. I can't remember the specific rules but it may generate geometry up to a one tile radius, and may be *affected* by tiles as far as 3 away. The broadphase part was 100% not the slow part, and there was also an additional AABB check during the narrow phase as you describe, because the AABB of the colliding poly was stored along with it during generation. So, I *think* we actually had something very similar to what you had, there was a method and you gave it an AABB that you were interested in, and it (without copying) iterated over all the relevant generated polys while generating them just in time. That's fine, the problem is that often times your collision response is not just one simple loop. What we actually ended up doing is, sometimes, the way our collision response would work is you would need to make multiple passes to try and find a correction, and you'd need to keep multiple polygons at one time so that you could loop over them maybe 2 or three times and do repeat checks after moving to ensure that things were ejected from collision geometry correctly. We solved the copying problem by having a working set of polygons that just basically were a set of N re-usable buffers and that eliminated the expensive allocations, but what I *wanted* was to have a &amp;[Polygon&lt;f32&gt;], and for the type system to ensure it was safe :P
Yeahhhh, I probably need to pick a new quote there.
Not sure how easy it is to do, but could a mod please change the recommended sort to `q&amp;a`?
I think the modern haskell solution to this problem would be compact regions, and it's possible that that makes the gc workable. It's at least a lot easier to try than changing the gc algorithm.
First off, awesome post and super detailed responses. A fantastic read! As the author of rental, I'm very curious to hear about your use cases for it, since the problems that motivated it in the first place were gamedev related.
If it helps, I just grepped for the unsafe keyword in Spellbound. Here are all of the uses for unsafe: * using vorbis_sys / vorbisfile_sys * using gl * implementing an unsafe VertexAttribute trait for our rendering API that returns pointer offsets * an implementation of Hash for floats borrowed from ordered_float * pointer casting for an implementation of a type map for types that implement a trait. * dealing with platform apis for consoles * the entirety of rlua (lua is hard) We have our project organized into several crates, and it is roughly organized so that there's a lib/ folder with a lot of private crates which are not game specific, and then the top level crate is the largest crate and is everything game specific. There is NO unsafe in the top-level crate, and I never felt we used unsafe because of an organizational or borrow checker failure, only when it made sense that what we were writing is unsafe. The one caveat though is that sometimes we needed *self borrows*, and I think the way to do safe self borrows in rust is kind of insane right now, which is to use the 'rental' crate. No negativity towards the rental crate intended, it's amazing, but it's also kind of insane, so that's a necessary solution to a problem that I'm not terribly happy with.
Enlightening post as always Kyren. I am curious given that rust disallows a lot of classic design patterns how you organized your engine internally. Any chance you can share mid level architecture on how you get around some of the more rust driven design challenges. 
[removed]
For someone who's never had console experience, why's everything so secretive? What's the point of an NDA like that?
thanks! btw i tried to search "ruby eons" but couldnt find anything. could you please give some link for reference?
Eon is a metric of time. It‚Äôs like saying ‚Äò... in Ruby a long time ago‚Äô
That's interesting! I didn't know that rental was motivated by challenges in gamedev. So, I mentioned above self-borrows and the rental crate, and I want to clarify that I think the rental crate is *amazing* and after reading the source and documentation you're CLEARLY smarter than me about the issues that go into it. It's amazing you can make something like that that's sound. I did however say that *using* the rental crate is a bit nuts, and.. okay tbh it is, but please don't take that the wrong way. I don't see how you could make it have a better design really, it's just the design can only be *so good* without language support or something similar. Or at least, if it can, I can't see how. I only use rental *once*, but boy howdy is it a big *once*. So, the basic architecture of the game is that there is an Ecs type "World" type, and it has registered in it N types of "Resources" and N types of "Components". Resources are just something that there exists 1 of in the world, and Components are something that may or may not exist for any given entity. Nothing earth shattering so far. Our current design though, is that the World is actually meant to be used in a threaded context, so you can lock a Resource or Component for reading or writing, still nothing earth shattering. Generally this is done by "Systems", which is just something that has an input / update / and render phase, and in each phase can lock different parts of the World and mutate it, pretty classic ECS. So, how would you make it possible to have a lua scripted system? You need lua to be able to somehow lock.. components or resources, but it's not at all a RAII language.. Plus, you can look at the rlua crate for details, but it's *more or less impossible* to safely hand lua any type that is not 'static. This is a *problem*. What we ended up doing is twofold. We have a top-level scripting interface to our World, and you can (in lua) call a 'query' method on it. The query method takes all the components / resources you want to read / write, and then also a lua callback. Then, it locks the relevant parts in the correct way, and stuffs all of that inside a huge rental type, with all the locks inside it. That, in turn, has userdata methods on it (there's a bunch of stuff I'm skipping about how to expose methods on resources / components), and then once the callback is finished the type is actually forcibly cleared, so lua cannot smuggle the type outside of the callback and cause the locks to not be released and cause a deadlock. The key bit is that I just didn't see *any* way, other than the rental crate, to hand a type to Lua that was a shared Arc&lt;RwLock&lt;World&gt;&gt;, the read-only world lock, the read / write component / resource locks, etc. I think it's interesting though that this sort of problem only showed up (so far at least) when interfacing with another language. I tend to think that this sort of thing would probably ONLY show up when you are trying to.. I guess *fight* what rust would normally want you to do, but in this case I think it's unavoidable. You *want* lua to be able to have easy to delineate locks on the World, and thus lua needs to hold onto those locks, and thus you need the rental crate.
How are you collecting licensing information for all the crates you use, so that the appropriate legal notices can be included with your shipping product? Background: I am a full time developer for my company, with a side responsibility for reviewing all uses of third party code used in our products, and developing the license compliance plan for their release process. For a global R&amp;D of probably &gt;4000 employees - this side responsibility takes around 10-20% of my time. We don't use rust in any shipping products from our company yet, but Cargo has a lot of similarities to npm, and npm is an unholy nightmare for this kind of thing (large numbers of small, independent packages, the majority of which are pulled in by indirect dependency rather than direct use, and frequently changing package versions), and I fear rust is going to be nearly as bad. P.S. I totally forgive you if you don't answer this question. If you worked for my company and asked me about how to answer this question I'd say "don't", and then if you were to give me "the look", I'd change my answer to "very carefully", and then when I got "the other look - you know, the one that means you're about to die", I'd say "write something up, and I'll review it, and then I'll run it past our lawyer when I meet with her later this week."
&gt; Enlightening post as always Kyren. I am curious given that rust disallows a lot of classic design patterns how you organized your engine internally. Any chance you can share mid level architecture on how you get around some of the more rust driven design challenges. Hey huhlig, long time no see! I think that there are only a couple of "big ideas" that you need in order to make the mid level architecture work. * Unlearn OO programming. I'm being a bit cheeky, but a lot of the problems I had simply came from spending so long trying to think of OO solutions to problems. Sometimes you just want a function. * ECS is really good, I'm still not sure whether it's good because it's intrinsically good or it just *really really* forces you to abandon OO. It's probably both. I think the one place where I just *couldn't* come up with a good design was in the UI trying to come up with a rust based widget system, and I sort of punted on it. In Starbound, we kept saying over and over how much we *wish* we had just done the entire UI in Lua, and lo and behold, we're doing basically the entire UI in Lua. This is a massive cheat though, because so far we're using gross inheritance architecture for that which is something that I don't think would work in rust. I even *tried* to make the actual widget system in rust first, before giving up and shunting that into the scripting layer. You may also find [this answer](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dosxj0a/) interesting.
Depending on the length of `v`, this will print out either Ok(3) or Ok(4): fn main() { let v = vec![1,2,3,4,5,6,7,8]; let i = &amp;4; println!("{:?}", v.binary_search_by(|k| { let k2 = if k % 2 == 0 { *k } else { *k - 1 }; i.cmp(&amp;k2) })); }
I love your games. I also love Rust. This is pretty neat. I have no experience in game dev though, so this seems like magic to me. Tell me, how much magic is there?
Obviously can't speak for kyrenn, but you might find Firefox's solution interesting: https://dxr.mozilla.org/mozilla-central/rev/87fabdfb091511300f89b0b51d8f472459d4a41c/python/mozbuild/mozbuild/vendor_rust.py#129
We're a very small company, 18 people I think by last count. We don't have a "legal department" or "license compliance department" per se, so I don't really have a person to ask to give me that look. I think if you were to name anybody in the company who had that role it would probably be.. me I guess. I hope that we did an okay job with Starbound. We don't have a *huge* number of open source dependencies in Starbound, but for the ones we do, we include the license text and a description of their use. All except for Qt, which is used by the mod uploader only, are MIT, BSD, zlib, or similar. Interesting side note, if you beat Starbound, there's a "thanks to all our open source friends" part in the credits with a logo for every open source project that we depend on, including backend tools like Aseprite. I think if I were to answer the question "how are you collecting licensing information for all the crates you use", I would say "very carefully, and near the end review all the licenses to double triple check compliance". I think that the situation with rust may be vastly easier, because there is a cultural tendency to provide code under the MIT license or similar. Apparently there is a tool called "cargo-license" which may help. Here's its output: Apache-2.0 (3): gl, gl_generator, khronos_api Apache-2.0/MIT (43): backtrace, backtrace-sys, bitflags, bitflags, cc, cfg-if, deflate, dtoa, either, gcc, itertools, itoa, lazy_static, libc, linked-hash-map, linked-hash-map, log, num, num-integer, num-iter, num-traits, pkg-config, png, procedural-masquerade, quote, rand, regex, regex-syntax, rental, rental- impl, rustc-demangle, serde, serde_derive, serde_derive_internals, serde_json, serde_yaml, stable_deref_trait, syn, synom, thread_local, unicode-xid, unreachable, yaml-rust BSD-3-Clause (3): adler32, fuchsia-zircon, fuchsia-zircon-sys MIT (15): dbghelp-sys, inflate, kernel32-sys, ogg-sys, sdl2, sdl2-sys, strum, strum_macros, twox-hash, void, vorbis-sys, vorbisfile-sys, winapi, winapi- build, xml-rs MIT/Unlicense (4): aho-corasick, byteorder, memchr, utf8-ranges MPL-2.0 (1): smallvec That's missing 'error-chain' which is MIT/Apache-2.0, and some chucklefish libraries. That list looks good, because I had actually been on the lookout for GPL licensed crates when picking dependencies or transitive dependencies. I'm hoping that means that our situation is not too complicated, and will be pretty tractable to manage near the end. IANAL though, and it's possible I have committed some grievous legal sin. I hope not, and to the extent that it matters, I'm trying very hard personally and as a representative of Chucklefish to do right by the open source community that we so heavily rely on. If we can ever do better, let me know.
That's awesome, thanks for the rundown. And believe me, I COMPLETELY understand the mixed feelings on rental. I wrote the thing and even I'm ambivalent about it. I'd love for it to not be necessary, and I hope that rust can eventually achieve that. But until then, there are certain things that are just impossible, and when you need it you need it. The other common motivating use for it is when an upstream API exposes a lifetime parameterized type, thereby preventing you from encapsulating its relationship with its owner in a single opaque type. Naturally this can be fixed by just asking upstream to change their API, or using a different crate, but that's not always practical. In a way rental is a sort of pressure-release-valve for the ecosystem so certain crates can be usable in contexts they wouldn't otherwise be, but greater ecosystem awareness of this issue would probably also help. I'm not sure how to achieve that though. Anyway, let me know if you ever have any questions or troubles with rental and I'd be happy to help.
Built a rather simple CRUD back end for a polling app that allows creating/replying to surveys that are either multiple choice or free response. Not the most technically complex app, but the first instance of Rust being used in "production" at my place of work to gather feedback from employees so it's still exciting to me. 
I don't have any questions, but I fell/jumped/stumbled off of this couch when I read this. Super happy to read about the positive experience you have had!
A quick skim of that python file suggests that they're validating that only approved licenses are used, which is step 1. That assures that compliance is possible, not that you are compliant. Step 2 is to comply with those licenses by distributing the required notices with the product that incorporates them. For MIT, BSD, etc, it's generally sufficient to distribute a copy of the license along with some kind of tag, label, or note identifying the name and version of the component. The Apache license is kind of annoying in that in addition to the license file itself, you have to check for an additional NOTICE file, and because of the manner in which licenses are interpreted, that may not be restricted to just a file literally called "NOTICE" as an experience programmer may want to interpret it, so to cover your bases you wind up looking for files that fulfill a similar role within the project, and it's just not that fun.
&gt; using gl Out of morbid curiousity, what _are_ you using to talk to GL? I've written a few things using [glium](https://github.com/glium/glium), (a) it's unmaintained, and (b) it imposes a fairly specific model of the world on your code if you're using any of its event handling (actually, the underlying [glutin](https://github.com/tomaka/glutin) event handling). It seems like it _might_ be an okay fit for games, and that's clearly tomaka's intention, but I'd love to know where you landed.
Will this mean we can use the system allocator on stable?
&gt; Have you run into any problems due to the notorious use of setlongjmp? Iirc, various other Rust Lua bindings have been abandoned due to being impossible not to trigger UB. Endless problems, but I now believe it is not possible to trigger UB in rlua in the ways your probably thinking. It actually probably IS because bugs, and it probably is if you don't compile with LUA_APICHECK, but I don't believe rlua has the problems that you're describing that other rust / lua bindings have. Namely, everything in Lua marked as [e] is correctly wrapped in a pcall, and everything in Lua marked as [m] doesn't generate longjmps because of policy and wrappers around parts of the Lua std. In the near future, this will become simply that all functions marked either [e] or [m] are protected with pcall, and this should be coming in v0.10. There are some *small* holes left with regards to recursion limits and things of that nature, but we actually have a plan to solve it *all*. &gt; In regards to using Lua as a scripting language, have you run into problems with not being able to parallelize the game engine due to it being single-threaded and requiring mutable borrows? Funnily enough, the engine was actually explicitly designed so that you would be able to run multiple Lua systems in parallel. Each system gets its own individual Lua, and then they simply lock resources / components as normal, if they don't share any mutable locks, then they can run in parallel.
We have a very high level "exactly enough to make Spellbound" graphics API which abstracts over OpenGL / console graphics APIs. The implementation of that API for OpenGL directly uses the gl crate, so I think the answer there is either "nothing" or "our own layer" depending on how you look at it.
Not a console developer, but my understanding is: quality control. The Video Game Crash of 1984 happened, in part, because anybody who make a chip and solder it to a board could publish games for the Atari 2600, and so they [i]did[/i], and the market was flooded with crap games. Nintendo rebuilt the video game market on a model of extreme control, where nobody was allowed to manufacture games but Nintendo, and they had to pass Nintendo's stringent quality-control, and DRM physically prevented anyone else from manufacturing compatible games. Secrecy about devkits makes it harder for third-parties to learn how the platform works, so it's easier for aspiring game creators to buy a legitimate dev kit (and be subject to the platform's standard quality control policies) than to hack something together themselves.
Yes, the solution to garbage collection is manual memory managment. I love it.
I honestly believe everyone would be better off if they were much more open, including the console makers, but the real answer is I don't know. I've speculated about some of the soft reasons why they might do that like platform control and leverage, but it's just speculation.
It's just standard in the industry, mostly based on the idea of keeping competitors from figuring out any tricks too easily. The situation is very similar with graphics cards when you look at how (un)willing IHVs are to open source their drivers.
Thanks so much for rental! I'm so happy to learn about it, and see that you've taken the time to make it no_std compatible. I see this line from the docs. I'm in an AMA mood, so: 1. Have you considered what alterations to Rust it would take to make self-referential structs natively supported by the language? This seems like a potential next step for the borrow checker after NLL. 2. This line from the docs: "This is currently not possible until the trait system refactor lands." What trait system refactor is that?
I'm honestly not too familiar with Erlang family languages, but what I do know from the periphery is impressive, specifically their legendary fault tolerance. If it were *me*, I might very well pick an Erlang-like for doing huge server side game development like matchmaking or similar, but I probably wouldn't choose it for console development. I think it's always going to be challenging when you have a virtual machine and runtime to port, and oh also no JITing. That being said, it would be great if consoles were more open and that was something you *could* do if you wanted.
Follow up-questions: are your difficulties with rlua, or with Lua itself? If the latter, do you think that a scripting language designed to be embedded in Rust, in the way that Lua was designed to be embedded in C, would be a benefit for gamedev?
[More magic](http://www.jargon.net/jargonfile/a/AStoryAboutMagic.html), obviously. :)
&gt; I love your games. I also love Rust. This is pretty neat. Thank you for the kind words! &gt; I have no experience in game dev though, so this seems like magic to me. Tell me, how much magic is there? Chucklefish contains only the most wizened elder sorcerers casting only the highest level dark spells. It is difficult sometimes to contain the intense magical energies, and will them into obedience. So *some* magic.
&gt; Not a question, but thank you for open sourcing pieces of your engine! This makes me love you guys even more. Thank you! We'll try and open source more of it as time goes on, hopefully, it's worked out pretty well so far.
Thanks, I didn't even realize this was a thing!
Ooh, thanks for teaching me about cargo-license! And thanks for being such a good open source citizen. :)
I think so, and I even considered other scripting languages that are better designed to be embedded in rust, but in the end I decided against them. Really, I couldn't justify TWO new languages, and though a lot of the scripting languages looked neat (like dyon!), I just couldn't really justify using a language that had really only one major contributor (like dyon :/). I'm not criticizing at all, it's great in fact, I just *already* was picking an outsider language for the engine, so I decided for the moment to stick with Lua. But boy howdy is there an impedance mismatch. I actually, maybe sooner rather than later, want to write a Lua interpreter in Rust and see if I can't solve the problem that way.
To answer 2 first, I'm referring to the work being done on chalk to improve trait resolution and such. Rental had some very complex bounds involving HRTB and associated types that just break or do nothing under the current compiler, which required a syntax-based hack to get the required type information instead. From my understanding, although I could be wrong, once the chalk-based improvements land this kind of thing will work better. As for 1... yeah, I've been thinking about this off and on for probably a year now. Honestly I just lack the PLT background to envision a comprehensive solution. At first I thought first-class existential lifetimes would help, but unless they can be tied to the specific instance they came from, it's still unsound. Another possible approach is stackful coroutines. Since rust's unit of reasoning wrt borrowing is the stack frame, it could help to make it possible to create stack frames in other ways. A rental struct could then just be a coroutine with the appropriate borrow scoping within it. Still not perfect, since you now need to communicate with the coroutine, probably through some kind of message pump, but it would work. Finally, a rather more radical idea I've had is a notion of a "fat lifetime" analogous to a "fat pointer". It would essentially be a lifetime with both static and runtime components that would need to be enforced. Violation of the runtime portion of the lifetime would panic or abort. It's super half-baked and probably has all kinds of theoretical problems that I can't foresee, but perhaps there's something there, who knows. 
&gt; vorbis_sys / vorbisfile_sys Did you know that [I have written a library](https://github.com/RustAudio/lewton) to decode ogg/vorbis files? You could cut down on the use of unsafe with it, in fact the library itself doesn't contain a single line of unsafe.
Oh wow this is awesome. Haven't played any of the Chucklefish games, but looks like I'll need to give it a try now :). Thanks for making rlua and especially thanks in working with me on adding enough features for me to use it in Way Cooler so that I can add AwesomeWM compatibility.
On behalf of the subreddit mods, thanks for being such a fantastic surprise AMA host! 1. What's your experience with the general quality of the third-party crates you've used (and merely evaluated)? 2. What topics do you wish crates existed for, but don't (or exist, but are of insufficient quality)? 3. How do your compile times compare to your games written in C++? 4. How does overall velocity of development feel compared to C++? Was Jon Blow correct in saying that enforcing memory safety is just a distraction for games development? 5. Do you have any idea how long I've been waiting for a sequel to Advance Wars DS? I need Wargroove!!
I concur. &lt;3
That would be *really* cool, but it needs OpenGL 3.3 or something similar.. maybe a software renderer would work? Oh wait, I seem to remember something I think you mentioned about porting mesa, if that's coming along, I think I might be willing to be a guinea pig for that! I'll ask about maybe sharing the non game specific parts of the engine and look at porting that as an exercise, but I probably *won't* be able to share the game code proper, not because the code is *all that valuable*, but it just leads to a lot of unwelcome speculation about the game before release. Also, again just so nobody gets the wrong idea, it's still pretty early. Also, thank you for Redox! I've been following development for a while and I'm a really big fan. If something that I'm working on can help redox at all I'd really like to make that happen.
What examples can you give of changes to libstd? Is it something that can be upstreamed?
&gt; We have our own ECS system that has a few nice properties that I couldn't find in other ECS systems, but I might end up regretting using our own ECS system vs just using specs, time will tell I think. Do you mind expanding on this? Would be great to see different viewpoints of ECS which could help make specs better.
&gt; In trying to reconcile your use of Lua against the desire to avoid a GC, presumably the Lua is there to handle game logic and, like the graphics system, merely interacts with the game state via the central ECS? How do you manage tracking 'what' in the engine the Lua code still needs references to? (Rc's wrapped up in Lua userdata?) Are there any major pitfalls in engine design that you wish you would have known of earlier? This is a pretty big question, and I'm afraid I don't have enough time at least tonight to give it the answer it deserves. The concern you mentioned about Lua having a GC vs the desire not to program in an engine language with a GC is a good point, and I actually learned a bit about this from Starbound, and that is that several smaller instances of Lua, driving logic with a carefully designed API, means that you can more or less avoid the GC pain that you would feel otherwise. There are some other tricks you can do like ticking the GC for different systems with extra frame time, or even in multiple threads parallel with other systems, and we may run into that as development gets further. &gt; Do you use any IDEs to develop in Rust? Relatedly, how do you manage debugging (Rust code, lua code interacting with Rust, rendering issues, etc.)? Other non-Rust devs are tempted by C++ due to the integrated debugging tools (and, in the case of Visual Studio with DirectX, integrated graphics layer debugging). However, I've been using IntelliJ and it seems OK so far. I think that generally devs come in two flavors, the printf kind and the debugger kind, and I might be the printf kind. I *do* occasionally use debuggers, and gdb seems to do the job well enough. Something I'm really excited about though is rust debugging working inside the visual studio debugger. I remember one of the other Chucklefishes almost had it working the other day, and it seemed pretty close to being usable, and that's really really cool. &gt; The gl crate exposes a fairly 'unsafe' API. Do you have any advice on constructing safer wrappers around that and integrating those with the rest of the engine. (Also curious of your opinion on gfx-rs and how they wrapped up their safe API, albeit targeting Vulkan rather than OpenGL.) We have a safe rendering API, but it's custom built and just exactly enough for spellbound. It has a very simple interface that supports 2d textures, 2d texture arrays, render textures, and just a couple of vertex attribute types and a couple of uniform types. There is an unsafe trait for vertexes to do vertex buffers, and I stole the idea of doing an "implement_vertex" macro from glium. I think if consoles supported a single common gfx api like vulkan, I would not have bothered with any of this, and probably wouldn't even have bothered with our own graphics api or anything like that. The thing I think I'm most excited about right now is the vulkan portability initiative, I really hope that takes off (and spreads to consoles). &gt; For physics, really collision detection, did you end up rolling your own solution or wrapping up something like Box2D, Bullet, etc.? Well, Spellbound is a top down game with traditional RPG style movement, so a physics engine would be overkill. You can get really really really far with just SAT convex polygon separation.
Which CI system do you use? Any recommendations for Rust projects? 
Followup clippy questions: * what's your most / least favorite clippy lint? * Do you activate any of the restriction lints? Do you use any allow-by-default Rust lints? * What lint would you like to see in clippy most?
&gt; That would be great, actually. What would be the next step to set that up? Just send an email to community-team@rust-lang.org, we'll organise the thing from there. It's pretty free-form :).
You said that you didn't use a whole lot of the existing rust gamedev ecosystem. I am curious as to how you structured your project and facilitated compiling. Was it all in one big cargo crate? Multiple sub crates? Completely separate and facilitated by Make?
&gt; On behalf of the subreddit mods, thanks for being such a fantastic surprise AMA host! You're very very welcome, it was a super pleasant experience, sorry for dropping it on you without warning :P &gt; What's your experience with the general quality of the third-party crates you've used (and merely evaluated)? For the ones we ended up using, surprisingly surprisingly high. Usually when we decided not to use a crate it wasn't because the quality wasn't there, but because we needed a solution that was just in a different part of the space. Sometimes, I feel like I could have gotten there with PRs and good open source citizen behavior, but sometimes I just really needed to get it done. &gt; What topics do you wish crates existed for, but don't (or exist, but are of insufficient quality)? (Cheeky answer) Lua bindings :P. Possibly the answer is STILL Lua bindings :P. (Honest answer) I'm not sure I have a great answer to this question. I think it's possible that I have NIH syndrome way too much, but then on the flip side sometimes I think that if the problem space is large enough that having your own solution that does exactly what you need it to do and no more and gives you full control is the better default. I think that when I looked for crates to do something simple and direct, "load png files, load vorbis files, parse arguments" there was usually always something there that was great. When I wanted something complex and that necessarily had to have a lot of tradeoffs and *opinions*, then sometimes I ended up not finding anything that I wanted to use. There are a few examples of where there were just a few missing features or design changes and that were necessary, and mostly I should probably go back and try and work those out with the crates that I ended up not using or had to fork (error_chain, vorbis-rs, ordered_float, ord_subset). If you're wondering about error_chain, I desperately need the Error types to be Sync, it would be amazingly fantastic when the changes land to let you specify Send + Sync bounds. &gt; How do your compile times compare to your games written in C++? Our compile times in C++ were atrocious, even after applying a decent amount of effort to it, so that's a LOW bar to hit. That being said, it's *mostly* better in rust, but I think depending on how large our project gets it might flip over. We started compiling profile.dev with opt-level = 1 so that we could keep using dev by default, we recently set codegen-units to 8 on dev and test (but maybe that's the default now?), I started using CARGO_INCREMENTAL=1 a long time ago, and my counterparts were really really happy when that got fixed for windows. These things together mean it's MOSTLY livable, but it's just livable not great. And, we had stockholm syndrome from C++ anyway, so we weren't that picky to begin with. &gt; How does overall velocity of development feel compared to C++? So, one of the things we decided to do with Spellbound that was different from Starbound was to front load a lot of complexity and "do things right the first time" so that we didn't end up with as much technical debt as Starbound. This is, if you are not careful, a great way to *waste a lot of time*, but I think we may have struck an *okay* balance. For a while, though, it did feel like I had a far too low velocity, but I don't feel that way now at all. It's hard to make a direct comparison because at the start of the last C++ project (Starbound), my situation was so massively different, but if I were to compare two similar things, I could compare the porting work I did on Starbound vs Spellbound and there *even with the disadvantage of using a non-native language*, rust comes out way way ahead. It's a fair criticism to say that a lot of variables have changed though, and I can't *definitively* say what affect rust has over the other changed variables. This is a lot of words to say "it feels massively faster, but I don't want to fool myself so I've convinced myself that maybe I'm wrong, but I don't think I'm wrong." &gt; Was Jon Blow correct in saying that enforcing memory safety is a wash for games development? It's Jonathan Blow, so I'm inclined to say that you should take whatever he says and weigh that much higher than whatever I say. That being said, I really really really disagree. The problem is not that you can write a bug, and then you run your game and your game crashes. The problem is not that you can write a bug, and then if you give your game ridiculous input it can crash. The problem is that you can write a bug, and 99.999% of the time your game works fine, and .001% of the time your game does *something wrong and you don't know why*. The problem is that your game works fine under error condition A, unless some other error B happens, and then your players lose their save because errors A and B are both safe in isolation, but if A happens and then B happens, that causes UB. I remember at least 5 major instances where there were multiple programmers in the office, pouring over some minutia in the C++ standardese, trying to figure out if some corner of a corner case of C++ was UB or not. Can anybody really keep the default / zero / value initialization rules in their head? We thought we knew C++14 backwards and forwards and still managed to have uninitialized value bugs, and they're awful because depending on the situation they will *mostly work*. I can count three or four times in Starbound's history where I was bitten by just the std::unordered_map iterator invalidation rules, that one's awful because you have to trigger a *rehash* often times in order to trigger the bug. I hear people say things to the effect that C++17 "more or less" solves the safety issues, "just use modern C++!", but I promise we were way ahead on that front and that was not our experience at all. We basically used C++17 before there was a C++17 (we had our own Maybe, Variant, Either etc), and UB was still always lurking right there ready to bite. It was HARD to get right. I didn't really mean for this to turn into a C++ bash rant, and I really don't want to be militant about it. It's possible that you don't have these problems in C++, maybe you're a better programmer than me? Seriously, it's possible I'm just not good enough. Certainly maybe Jonathan Blow is better than me! &gt; Do you have any idea how long I've been waiting for a sequel to Advance Wars DS? I need Wargroove!! I'll let Team Wargroove know you're excited :D
Oh I‚Äôm sorry. I used the word ‚Äúeons‚Äù to mean I worked on it a long time ago. I didn‚Äôt ever release the library in the end. It wasn‚Äôt a successful experiment :) My apologies for the misunderstanding. 
oh well okai, I kept an eye on wargroove, but I probably would've missed it since I barley can play my switch (too much programming work, but not as low level as you do, but I love rust as well ;))
I can 100% guarantee you that specs is a better all around ECS than what we are using internally. I want to give you a good answer to why we didn't use specs originally, but it's getting really late and I don't think I can do that before I fall asleep. The short version is that I ended up wanting a bunch of probably goofy requirements (systems are !Send, and still need to be run in parallel, I wanted a bunch of exotic types of component joins), and honestly I think I just needed to implement an ECS before I could really understand it. This was one of the very first things I did in Rust, and there's a reason I mentioned it as a possible regret. It may be still that at some point it becomes worth it for us to switch to specs.
(On mobile here) Do you, by chance, need to specify the error type param (giving your custom `Error` type) for the return `Result` type on your `user_create` function? I‚Äôm not quite sure I see how rocket would know you wanna use that error type.
Multiple crates, with a top level "spellbound" crate and several different internal library crates. We also split out all the binaries (main game, tools, testing samples, etc) into their own crate, but this was only because there are dependencies there that are problematic for consoles. So, we have a main "spellbound" library crate, a lot of internal library crates in "lib/spell-xxx" folders, and a whole mess of tools and stuff in the "spellbound-bin" crate.
gitlab-ci. I spent an embarassingly long time last year looking at CI solutions, and gitlab is the best by miles. That is not to say that gitlab is *good* mind you, just that it was the least terrible that was designed to work on linux / mac / windows. I've forgotten where I've heard it, but this old adage about build systems comes to mind here: "There are two kinds of build systems in the world, useless and terrible."
Ooh, this is exciting! I would love a more Idris/Haskell-like lang to be the next generation of systems lang after Rust. Seems like making composition work nice, as well as currying would be a huge challenge, but I'm excited you're working on it!
&gt; and at the end of the day Starbound is just NOT parallel and there's no easy way to make it be so. As someone who's main base is on a volcano planet and sees their FPS drop into the teens when it rains fire, this makes me sad but I understand that there isn't much you can do.
Author here.. it's not a typo but I personally don't think that it will take that long. The publisher is being conservative as I have a toddler (number 2 due in Jan) and there is quite a lot of technical complexity to the latter chapters. We are hoping to underpromise :)
IIRC that's what stabilization means. "stabilization: 1: to make stable, steadfast, or firm"
Author here. Sorry to be late to the party! If anyone reads this week-old thread and has any questions, do feel free to ask !
If we are all sharing, then here is [my Haskell version](https://github.com/devonhollowood/secret-santa). Like yours, it sends out emails so that the administrator can partake in the festivities.
Very fair point.. I actually decided not to share link when I was notified by the publisher that the deal was live. OP must have received an email update and decided to share. I have tried to be conscientious with updates and actually used modmail to submit the first link. It's a difficult balance because some people really like discount codes!
Uh... you're Harriet Jones, project coordinator?
Great read! I've only dabbled with Rust but am fascinated by the level of (performance free) protection it offers, and often thought it'd be handy for games. I've written a few basic game engines over the years in SDL/OpenGL/DirectX as well as worked on commercial titles on consoles (a while ago, but hey), and have always encountered issues that would have been avoided by Rust's borrowing system. Games really are weird beasts, like you say, a small bug can easily lead to crash way down the line depending on what memory you've clobbered.
Huh, I guess that‚Äôs not the best way of pointing at somebody there, since it‚Äôs different on phone vs pc. I‚Äôm Catherine actually, I was trying to use the about page because it felt a bit weird to use my coworkers real names. Column x row definitely doesn‚Äôt work though!
Well yeah, I had to do "request desktop site" just to get any columns at all :-)
Maybe ping /r/cpp for input as well? They'd be people with experience in creating and using custom allocators and could thus provide pertinent feedback.
Hi @kibwen TiKV has also reached 1.0. Btw, TiKV uses RocksDB as the backend engine, I think it is better to bench TiKV with other distributed key-value stores, not RocksDB.
If what you want is to use the system allocator by default, then I think the global allocator setting in https://github.com/rust-lang/rust/issues/27389 is more relevant, and that's not in FCP yet.
Thank you for taking the time to answer! &gt; and floats are like kryptonite for this :( To be clear, comparing floats isn't UB, it's just really easy to get _wrong_. But totally safe to do. This is why they still implement PartialOrd, just not Ord; things like BTreeMap need Ord because they need reliable comparisons. Note that something falsely implementing Ord will not cause unsafety in BTreeMap (or `sort()`, or whatever), it will only cause the map to perhaps not work the way it's supposed to. (Ord is safe to implement; so no interface can make its safety rely on Ord being correctly implemented. It is 100% safe to implement Ord as something that returns a random answer and then stick that thing inside a map) &gt; I think I would go for a NotNan or Finite type Finite and NotNaN are possible to implement in a crate. These types would have a performance penalty of the NaN/finite check, and you would write snakier code to deal with the error cases, but it's possible to write. Generally the stdlib avoids implementing stuff that's easily done in a crate so I don't think these could make it into the stdlib. &gt; Our current solution is something like the ordered_float crate in combination with something like the ord_subset crate. That's basically the "official" solution. The idea is that needing a total ordering of floats is pretty rare (and it's more commonly a mistake), but if you really need it, explicitly opting in (by using a crate) is great. But yeah, it can be annoying. What is causing your requirement of `Ord` on floats? `.sort()`? `BTreeMap`? &gt; it's when all the designs that they would naturally write seem to generate errors and they don't know where to go is where it is really painful. Yeah, this is _really_ common. I have this problem too when learning new languages, I try to program in it as if it were some-language-I-know and that eventually doesn't work. I kinda would like to look into having tools that detect such newbie pitfalls early and help with them. A kind of guardrail'd tutorial mode for the compiler, basically. Not that I have any time to work on this currently :) &gt; I SHOULD be using bindgen, it's actually on my list of things to do. To be clear, it might not be worth it if it's just a couple dozen C functions. Bindgen becomes _really_ useful when you have a heap of C structs your Rust code needs to understand, and/or lots of functions that may get out of sync. But if not it doesn't really hurt to use bindgen, aside from the extra dependency. In case the C headers are not changing it's also fine to use bindgen as a binary, feed it the right flags, run it once, and check in the bindings (and update it when necessary). &gt; We use clippy! I LOVE clippy Words cannot express how happy I am to hear that y'all use and love clippy, a project I started and continue to maintain (with others) :D :D I apologize in advance for all the nightly-wrangling clippy makes you do; we're working on making it part of rustup so you don't need to worry about this anymore :) &gt; That would be great, actually. What would be the next step to set that up? PM me an email address or just drop an email to community-team@rust-lang.org mentioning who you are and linking to this post for background (though I think most of the team is aware of this post at this point!) &gt; I thought of a good answer to the first question, self borrows, or the lack thereof Whoof. Hard stuff. The design of Rust is kinda fundamentally such that self-borrows can't work, since Rust assumes that anything can be moved willy-nilly, and pointers to oneself make that impossible. That said, it would be interesting if we could work something in such that you can define heap-only types from which you _can_ make self-borrows (or perhaps pointer-offset field types?). Idk. I don't see this coming into rust anytime soon, sadly, but it would be really interesting to see if folks can come up with a solution. Often when you want self-borrows a combination of Rc and Weak can be the solution (not all cases, some of them). This is especially true for patterns from GCd languages. I'm not sure if this applies to your case, or if the allocation/refcounting cost or Rc is prohibitive, but it might be worth trying. Thanks again for responding!
For someone interested in learning gstreamer but not having any knowledge in it yet, would it make sense at this time to start going through the tutorials and try to apply the first bindings to them or do the tutorials on c to get the concepts then move to rust bindings? I've written some rust code before so that part isn't new at least.
I thought it was a library, English is not my native lang :D. Can I ask why you considered it "failed experiment"? Anyways I checked the existing generators but both are binaries so you cannot pass data inside rust code (you need to generate data files for everything).
complete game would be great too! what is your opinion on ggez? have you ever wrote sth with unity3d?
any plans for relm? :)
&gt; I ask just because Go is my second-favourite language, and I'm curious whether it's practical for game dev. sadly it is not. Performance is very very good, the GC is simply amazing but the show stopper is in the cost to call into C. For games you need that because you'll be calling OpenGL thousands of times per frame and you'll see that becoming your bottleneck pretty soon. You can work around the problem by moving as much code as possible to C++ land in order to limit the amount of times you have to call into "C" or by being super hacky with function pointer lists passed over.. at that point tho, it's not "really Go" anymore and you'll start wondering if it all still makes sense. Shame tho, I think the language would be a perfect fit for gamedev if only they could work around this limit.
Have you tried removing the `'static` lifetime in `Responder` implementation? I use a regular `'a` and it works fine for me.
Do you just use the rust layer (is there one? I don‚Äôt use spacemacs) or do you have additional customization to help deal with Rust? Are you using the RLS? 
Take a look at https://github.com/japaric/rust-cross. It mentions adding a linker override to the cargo config file. To me it makes sense that you'd have to do this; I don't know how else rustc would know what linker to use. I think the naming varies by distribution.
Nothing to do with the discussion (though I'm avidly following, love Stardew and am now very interested in both wargroove and spellbound &lt;3), but those small critters are absolutely ace, who's the artist and how were the depiction decided? (walking around in victorian outfits with flasks of bubbly green liquids I can see, but the hologram arms and orbiting planets are somewhat straining credibility)
This is not really a Rust question, but how are you handling scripting? I know you're using Lua, but I was wondering more about the specific API design. What would a standard cutscene look like? Do you have a custom level editor, or are you using something like Tiled?
Just a question that I've wondered: How big does the game (code only) get, in terms of MB? Is space still a problem? Rust is "known" for generating larger binaries because everything is linked statically, is this still a problem on modern consoles / handhelds? Thank you for this AMA.
&gt;using gl What do you think about Vulkan?
Sadly not a bug. You're supposed to give cargo a link to the correct cc and ar in the config (`.cargo/config` next to your `Cargo.toml`) with contents looking like : [target.arm-linux-androideabi] linker = "arm-linux-androideabi-gcc" ar = "arm-linux-androideabi-ar" [target.aarch64-linux-android] linker = "aarch64-linux-android-gcc" ar = "aarch64-linux-android-ar" 
I got back up to answer this. &gt; To be clear, comparing floats isn't UB, it's just really easy to get wrong. But totally safe to do. This is why they still implement PartialOrd, just not Ord; things like BTreeMap need Ord because they need reliable comparisons. Note that something falsely implementing Ord will not cause unsafety in BTreeMap (or sort(), or whatever), it will only cause the map to perhaps not work the way it's supposed to. (Ord is safe to implement; so no interface can make its safety rely on Ord being correctly implemented. It is 100% safe to implement Ord as something that returns a random answer and then stick that thing inside a map) I understand this actually, I don't think I said what I meant very well. I know that floating point behavior is *sound* (modulo bugs around float -&gt; int conversions I guess), I meant something a bit squishier than that. I meant that rust's style is (correctly!) to try to be up front about strange edge case behavior, and floats have a lot of strange edge case behavior. I think what I meant to say actually is more like that rust, in its laudable goal of being up front about sensible vs non-sensible behavior, shows me how complex floats really are and it makes me ~super uncomfortable~. I blame *floats*, not rust. In C++, you can std::sort a std::vector&lt;float&gt; all day, and if one of them is NaNs you will not get UB. However, you will get like "UB-1" aka "unspecified behavior", aka, your list will not be anything you expect and your code will break, but it's not *technically UB*. This is almost exactly the same behavior that you get if you sort with the comparison function as |a, b| a.partial_cmp(b).unwrap_or(Ordering::Equal), it's *sound* and it's not UB, but it *FEELS* like it. Obviously you understand this, I guess I'm just expanding on what I was trying to say, and you even touched on in your explanation. &gt; Finite and NotNaN are possible to implement in a crate. These types would have a performance penalty of the NaN/finite check, and you would write snakier code to deal with the error cases, but it's possible to write. Generally the stdlib avoids implementing stuff that's easily done in a crate so I don't think these could make it into the stdlib. I know, but what I wanted was one that was as simple and easy to use as builtins because I might literally just use it everywhere. Something like "nf32" to go with "f32". It's probably a pipe dream because fp hardware doesn't work like that, and so nobody would want it. &gt; That's basically the "official" solution. The idea is that needing a total ordering of floats is pretty rare (and it's more commonly a mistake), but if you really need it, explicitly opting in (by using a crate) is great. But yeah, it can be annoying. What is causing your requirement of Ord on floats? .sort()? BTreeMap? It doesn't seem that rare for us. Things like NotNan and OrderedFloat are still painful, because it often shows up inside *containers*, and it feels wrong map over a container like that only to change the guarantees enough to get some sort of Ord, especially since in presence of nans it's probably wrong no matter what you do since FP is hard. Sometimes, it is especially *especially* hard when you combine Ord requirements with containers and also generics. If you want to see concrete examples of where FP Ord becomes important, I'm actually just going to show you a file straight from our project: http://sprunge.us/DjTi?rust I know that's kind of a big example, and there's a bunch of irrelevant stuff there, but it's also kind of a good example because a huge portion of it starts to break down without Ord, and starts getting very difficult to write. Specifically take a look at the "convex_hull" and "convex_sat_intersection" methods, they rely pretty fundamentally on ordering, and it's actually quite tricky to try and do "something sensible" when presented with unordered values. The thing is, I'm 100% not criticizing rust here, I realize that this complexity *was there the whole time*, because fp math is just very very hard, it's just that in other languages you can kind of just.. forget it exists and tune it out, and hey your programs will only *rarely* break, right? I don't know whether rust needs to adopt and bless some of the sanctioned solutions, or maybe whether the current situation is actually just fine as it is.
Let's pick your initial misquote and turn it into a thing of its own ;-)
Initially i've read this as "ActiveX". I think humand brains have the tendency to read only a few first and last letters in a word and then guess the meaning.
I'm interested in having a longer conversation about ECS in Haskell, as it's a problem I've tried to solve multiple times and failed. To have it compile-time safe it requires type families, and the whole type-level programming isn't as powerful as in Idris or unholy C++ templates. 
What's your stance on global variables? Do you have the main game state in a global variable that can be accessed from anywhere, or do you require all the game logic code to get the state as a parameter? If it's a global variable, how do you handle borrowing it for mutation? If it's not, what does the the API for threading it everywhere as a parameter look like? How do you split off different sets of operations that need to access and mutate the game state code architecture wise? Free-floating functions in modules, lots and lots of methods on one big GameState type, traits for a GameState type or something else?
Email works in many cases, but not if family members share an e-mail account. That's why I was looking for something simpler :) But e-mail could be implemented on top of rusty-santa.
Chucklefish + Lua + Rust = I'm already interested in this game and I haven't even seen a screenshot yet Glad to see the Chucklefish "Nounword" naming style continues, I feel it gives a subtle thematic link between otherwise unrelated games. By the way, as one of the world's twelve WiiU owners, I would buy it on that if the Switch stuff is compatible at all. ;-)
Hi, this is great! Thank you for that. I indeed have a question here: what does your development cycle look like? Like, minute to minute. I'll give a bit of context to the question: I talked to some game programmers at RustFest and one complaint was that Rust has poor support for a rapid development cycle, especially for reloading components (e.g. through a shared library) while the game is running. Now, they were working on huge beasts, I'm not sure how widespread that problem is. Or is this the area where you are using LUA anyways, mostly? Finally: RustFest Paris CFP is going to open soon, please consider submitting :). It's going to be in Spring next year. We pay all speaker expenses.
&gt; I know, but what I wanted was one that was as simple and easy to use as builtins because I might literally just use it everywhere. Something like "nf32" to go with "f32". It's probably a pipe dream because fp hardware doesn't work like that, and so nobody would want it. I don't know about that, C99 has a [configurable FP environment](http://en.cppreference.com/w/c/numeric/fenv) which lets you "signalify" normally quiet nans. I don't know whether these functions go and configure the FPU though.
Terhe is atuaclly an uabrn mtyh taht syas tihs was prevon by Cagidmbre Uriseitvny. It's not ture tohugh :) http://www.toxicdrums.com/typoglycemia.html
&gt; There are not TOO many languages to choose from though, because for practical reasons, you need a language that can has no runtime, no gc, and can more or less pretend to be C. I'm sorry to barge into the r/rust subreddit like this but I'm curious. (Disclaimer I am one of the core developers of [Nim](https://nim-lang.org)). By the way, I love Starbound and my SO is absolutely in love with Stardew Valley (Myself and her are both excited about your upcoming game). So my question is related to your "no gc" requirement. The Nim programming language itself is a GC language, but despite that it found a little niche for itself in game development. The GC in Nim is rather special as it has been specifically designed for games, you can control when it runs and for how long incredibly easily (https://nim-lang.org/docs/gc.html#realtime-support). I'm basically wondering two things: * have you evaluated Nim for your project? * what is your experience with GCs in games? Have you ever used one with real-time support? I feel that apart from this requirement, Nim would fit your use case perfectly (and perhaps even more so than Rust, as it compiles directly to C/C++). Thanks for taking the time to answer these questions and I hope you have a nice day :) 
Bjarne Stroustrup, the creator of C++, said a very similar thing: &gt; There are only two kinds of languages: the ones people complain about and the ones nobody uses [Source](http://www.stroustrup.com/bs_faq.html#really-say-that)
I'm curious about this as well actually. After having looked at Nim and its realtime GC I can't see why it wouldn't be a very good fit for games indeed (although I have only written small games for fun in it). Seeing why you thought Nim isn't suitable would be very interesting.
&gt; I got back up to answer this. I'm here forever, I can wait :) &gt; It doesn't seem that rare for us. To be clear, I meant "in general". Specific use cases may differ and get an unfortunately large share of the problems. We have similar issues with floating point _equality_ in Servo, where the compiler warns about comparing floats for equality in certain cases but we have to because CSS requires checks like "is the float value the user put in equal to 1?". Fortunately this is just a warning and we ignore it. &gt; I'm actually just going to show you a file straight from our project (This is good rust code! It's interesting to see the use of loop labels; that's very rarely used in Rust and I've never seen two in one place, but I can see why it was necessary here) I think I more clearly understand now; it's not just that floats are hard to work with without wrapping, but also that you actually intend to handle the cases of unorderable floats as well as possible. I had kind of assumed that like most games or other math-heavy software you'd assume things never get to the point of producing NaNs, pepper the code with a couple asserts or something, and be done. Turns out you're better developers than that :) This is an interesting problem to have. Rust doesn't really help solving it, but crates can try, somewhat. All of the current crates (and any approach I can think of) have tradeoffs, however. Sadly I don't really have a magic fix for that, but it's something I'll continue to think about and see if we can eventually get somewhere useful. 
Exposing the APIs would mean also exposing a lot of unannounced projects and detailed information that they don‚Äôt want the public to know. For example: the API might contain references to a new console, and leaking that info could hurt their marketing push for the console. Or it might comtain references to a specific type of chip in the new console, and leaked info could affect that chip manufacturer‚Äôs stock price.
I'll take a look :) Would you be interested in writing a GStreamer element around your decoder (I'll help you with any questions you have of course!), or should I put it somewhere on my list?
signaling NaNs are _cool_. 
We're also working on gluon, but it still needs a bunch more work before it is reliable and useable for a full game. Maybe for your next one! :O
Ah, ye olde reddit [rustaroo](http://reddit.com/r/aww/comments/78asjw/adopted_this_sweet_boy_maybe_2_weeks_ago_and_hes/dot1pdi?context=2)!
Firefox handled this with a bunch of grep commands :) We mostly have MPL, MIT, Apache, BSD-3-Clause, and IIRC one ISC library. The main thing is to ensure there's nothing overly viral in there (Firefox releases all its source code, but it would not be great if Firefox itself had to relicense). We then removed dependencies that are in compile time tools only (bindgen's transitive dependencies, i.e. stuff like terminal handling, as well as some webdriver stuff) and included a copy of the license for each library that was left. We don't really have a method for keeping track of this, but we vendor in crates so new crates being pulled in can be noticed. We do plan on better tooling around this (also better tooling around the trusting of crates).
Yeah. I can understand why some nans default to quiet (kinda) but damn I really wish you could easily set the FPU to "every nan traps damn it". [Same for integer overflows](https://blog.regehr.org/archives/1154).
From my understanding, you're just saying that the returned string has a lifetime &amp;'a. On it's own that doesn't mean much. It makes more sense in a function that takes arguments. fn fun&lt;'a, 'b&gt;(one: &amp;'a str, two: &amp;'b str) -&gt; &amp;'a str Here, you're saying that the string returned has the same lifetime as the first string argument.
But whenever I want to return a &amp;str, I need to mention a lifetime, even if the function doesn't take any argument
I would definitely be interested! Time might be a bit tricky; I've got some heavy Rust lifting to finish at work this week. My Vobsub parser is based on `nom` (which is pretty reasonable for parsing binary packets). The interesting bits are: - [A limited Program Stream header decoder](https://github.com/emk/subtitles-rs/blob/master/vobsub/src/mpeg2/ps.rs). - [A limited Packetized Elementary Stream decoder](https://github.com/emk/subtitles-rs/blob/master/vobsub/src/mpeg2/pes.rs). I'm presuming that GStreamer can already parse PS and PES streams for us. - [The subtitle decoder itself](https://github.com/emk/subtitles-rs/blob/master/vobsub/src/sub.rs). Probably [we would just want to export the `subtitle` function](https://github.com/emk/subtitles-rs/blob/eb5837b332e29c396b98e54d05c37ea3e511cd17/vobsub/src/sub.rs#L348). We might also need to export the code for assembling multiple PES packets into a single subtitle packet. Looking at the code again, a lot of the lower levels run on `&amp;[u8]` byte slices, and not `Read` streams like I remembered. But overall, I'm pretty happy with this code‚Äîit's at least as clear as any of the C implementations of vobsub I've read, and it has been _heavily_ fuzzed, finding nothing worse than a couple of panics which I've fixed. Have you seen `cargo fuzz` yet? It's really pretty amazing once you figure out how to read the output and set it up. Based on writing `vobsub`, I now believe that Rust is a truly first-rate language for writing codecs (at least if you don't need vector float intrisics, which will need to wait). Yes, you _do_ pay for bounds checks when accessing slices. But those bounds checks were also why `vobsub` survived a billion `cargo fuzz` runs without being exploited.
You're using gl-rs! üò± Must dig out the Switch and and buy Stardew Valley! When I started with Rust in gamedev towards the end of 2012 I hoped it'd turn into something like this and it has! I've since drifted into other waters, but it's great to see stuff like this happen. You made my day!
Thanks for the book!
What do you think about the [Immovable types RFC](https://github.com/rust-lang/rfcs/pull/1858)? I'm not super-familiar with the topic, but my understanding is that immovable types (the `Move` trait) pieced with a few language-level additions (the `'self` lifetime) would basically solve the problem of self-borrows.
In that case you could only return a `&amp;'static str`. In other cases, who'd own the string? The way to go would be to return the owned string, rather than a reference to it.
About the terror and cruelty of IEEE-754, aka. floating point numbers: Have you ever considered using fixed point types instead? Would be quite the fitting data type for your kind of games. Even precision across the whole range of values, no weird black magic like infinity or NaN, no signed zero value, no multiple ways to encode the same value, simple and fast to implement, a trivial to parse and stringify format,... Okay, this might have some complications when interfacing with Lua, though. But there is also a nice crate for fixed point numbers. I think 24.8 would be a nice fit for you.
The compiler and whoever is reading your function signature needs to know where your actual memory is stored that you are borrowing from, so that whoever is using that API can ensure that there‚Äôs no use after free happening (with the compiler verifying that). That is ambigous if your function either takes no parameters or more than 1 parameter that could be borrowed from. In case of a single borrowable parameter there‚Äòs an elision rule that says that in this case you do not need to specify the lifetimes explicitly. So if there‚Äòs no parameters, you could for example specify 'static as the lifetime to signify that you are borrowing something that isn‚Äòt limited in how long you use it for.
I think an unconstrained lifetime means that you're promising that it works for *any* lifetime, which implies that can only return effectively `'static` values.
&gt; I don't know how else rustc would know what linker to use. Well, several versions ago it used arm-unknown-linux-gnueabihf-gcc by default for arm-unknown-linux-gnueabihf target, not a cc. 
&gt; a link to the correct cc and ar in the config Thanks. 
There are people working on Rust bindings for Godot 3's GDNative API. So, if one day the choice will be *"gimme an existing engine for 3D stuff"*, then you might also be able to keep using a special less-friction-language by then. =)
If you are returning a `&amp;str` from your function that means you're giving the caller a reference to some string which already exists as a local variable. However all local variables get cleaned up before you exit a function, so you can't give the caller a reference to some local string because by the time they look at the reference it'll be pointing to garbage. Something the compiler explicitly tries to stop you from doing. It sounds like you want to return an owned string (`String`) instead. You can turn a borrowed string (`&amp;str`) into an owned string with the `to_string()` method. This makes a copy of the borrowed string's contents so even if the original goes away you have a valid string.
There is a Rust layer, but it doesn't use rls. 
Glad to see another spacemacs user. I would love to see your config, [mine is pretty terrible](https://github.com/MaikKlein/dotfiles/blob/master/spacemacs/.spacemacs) because I still haven't learned elisp.
This is one of the best and most plausible answer i ever read on this subject.
&gt; I could only find elo, bbt and glicko (not glicko2) implementations in Rust "Only"! That seems like quite a few systems. I suspect it's more than there are in Java.
I'm not sure this argument really holds waterl; PC APIs don't have any NDA and still make [huge amount of money](https://www.tweaktown.com/news/55607/pc-generated-442-more-revenue-consoles-2016/index.html).
&gt; an implementation of Hash for floats Heh, you can probably just use `to_bits` now.
&gt; how (un)willing IHVs are to open source their drivers [Even fscking Broadcom has employees writing open drivers in Mesa](http://anholt.net/papers/xdc-2017-vc4-vc5.pdf) these days though! :)
Considering the heavy console emphasis I'm reading, I'm going to guess multiplayer isn't even on the radar for Spellbound? :(
Sounds like Rust is a great choice, after having to make a similar choice and going for C# (as an ide coder i just couldn't leave the productivity boost of Resharper behind) i've found that indeed GC should not be used in a game :) and paying the price of working around that daily
The nintendo switch supports vulkan, so it shouldn't be very complicated. Homebrew support on the switch is starting to take shape (though it's very very very early still, see https://github.com/reswitched/libtransistor). When it's further along, I might take a look at making gfx-rs work on it.
https://play.rust-lang.org/?gist=cd6bcbfc2ec4d39bab1a1f6bf20bb8e0&amp;version=stable Is there any way to get this to work without introducing a new generic as shown in the commented out version of the function. Currently it seems the compiler isn't seeing `a` and `b` as the same type so it is falling back to the `Mul&lt;V&gt;` impl.
I think Blow's view is mainly that memory is not part of the genuinely hard engineering problems that game developers face and that focusing a language on a "big agenda", like safety in Rust's case, adds a lot of friction in the way of the programmer trying to solve them. His focus on avoiding friction is pretty refreshing, like the minor focus on sane compilation speeds and arbitrary compile-time execution. Mind you Blow and his aficionados tend to take a very dim view of anything to do with the std, OO and "modern" C++ so I expect his use case is a bit different from yours. 
I tried it, same error. But if it is working for a clean project I'll try to rewrite things from scratch until I hit the issue again
`errors::Result&lt;Json&lt;User&gt;&gt;` is an alias for `Result&lt;Json&lt;User&gt;, Error&gt;` as far as I know. Is that what you mean?
That's years later. The console industry is using a model that works for the console makers... and there's not too much competition there.
Found the error, I forgot to derive `Serialize` for my `User` type. I gotta remember to pay attention to every type involved, I don't know why I assumed `Error` was the problem. 
&gt; The idea is that needing a total ordering of floats is pretty rare is extremely not true for games. In my dream world, there'd be something like the `nf32` type /u/kyrenn mentioned, and it would treat _all_ NaNs as UB (just like regular `f32` treats signaling NaNs as UB), making it totally ordered. 
There might also be the expectation that a video game console is an appliance: you expect to when you put in a cartridge/disc that the game will run flawlessly. If many games (perhaps even just one) broke this implicit understanding, I believe it would have an adverse effect on consumer trust and ultimately revenues. On the other hand, we are used to PCs being general purpose machines where half or software is buggy, but since people need to use Word and Excel anyway, lower quality had little effect.
It is not specified which parameters the function takes. If the parameters can be used to obtain string slices in the `'a` lifetime, those can be used to return `&amp;'a str` in addition to `&amp;'static str`. For example: ``` fn substr&lt;'a&gt;(src: &amp;'a str, from: usize, len: usize) -&gt; &amp;'a str { let mut iter = src.char_indices().skip(from); let (byte_start, _) = iter.next().expect("string too small"); let (byte_end, _) = iter.skip(len - 1).next().expect("string too small"); src.get(byte_start..byte_end).unwrap() } ```
Thanks for creating this thread. Having years of experience of developing for consoles, I fully understand how careful you have to be not to talk about anything falling under DNA. However, even just your estimation of "2 weeks of your time" for getting a rust project running on consoles is a HUGE takeaway for me. This information alone might turn rust into a plausible option for some game-dev projects. (Even when starting your project on just the supported platforms, there is the slight "worry" that the game might be successful and you might get asked to port it to consoles... ;) ) As for UI, there is certainly nothing wrong with writing it in a scripting language, especially if you create the layout in code, then fast turn-around times are crucial. For writing a game UI in rust, I have seen a very nice and pleasant to use (C++) multi-pass immediate UI being developed for a project (that I'm not involved in) at our studio, which would work just as well if not better translated into rust. Being multi-pass allows for more complex event handling and offering some auto-layout features at the cost of some performance. Some day, I'd like to take a deeper look into their code and try to do a prototype version of it in rust. ;)
&gt; Specifically take a look at the "convex_hull" and "convex_sat_intersection" methods, they rely pretty fundamentally on ordering, and it's actually quite tricky to try and do "something sensible" when presented with unordered values. The thing is, I'm 100% not criticizing rust here, I realize that this complexity was there the whole time, because fp math is just very very hard, it's just that in other languages you can kind of just.. forget it exists and tune it out, and hey your programs will only rarely break, right? Also, generally speaking, when you're writing float code in game dev, you're kind of fine with a nan poisoning your game state, because they're very rare and you'll see it happen instantly on screen. If you're forced to handle all sorts of nan scenarios, you're going to end up jumping through all these hoops and writing all this convoluted code to basically say "whatever i don't care if this is a nan or not". You migh also pay a performance penality, idk whether you do or not, but if you do it's an even bigger problem, because functions like the one linked here are usually in inner loops, and are in the hot path of the program.
&gt; I'm sorry to barge into the r/rust subreddit like this but I'm curious. (Disclaimer I am one of the core developers of Nim). I think I speak for all of us here when I say that you are quite welcome :) Even as a Rust user, I'm curious to hear more about these constraints!
Well, he said "even if the function doesn't take any argument", which is the case I responded to. Sorry if I did not make that clear enough.
I'm guessing the issue would be twofold: 1. it would be *much, much slower* than fp 2. it would require conversion before heading to the GPU as AFAIK they've got 0 support for fixed-point, and much better support for FP than integer
I felt it was a failure purely because of my inexperience at the time. Mostly it came down to an implementation that used brute force; it would simply rebuild an entire site rather than incrementally. I didn‚Äôt know enough at the time in order to fix it, so I gave up on it. That said, there were many things about it that I thought worked well. - Building it as a library made it easy to build sites that relied on different versions; binary generators make that difficult - It‚Äôs easy to add your own helper functions - it‚Äôs also easy to define your own types - I was able to define my data any way I chose, although it did include a way to load and query YAML files - It didn‚Äôt tie me to building a site in a particular way; so many other generators over-emphasise weblog generation So, I think the idea is a good one, I just didn‚Äôt have the skills at the time to do it well!
I imagine performance would be comparable to that of integers, AKA extremely quick. Addition and subtraction are implemented by simply performing that operation on the backing integers. Multiplication is slightly tricky, as you need to shift the values around while avoiding overflow. Division is the most complicated part, but also entirely doable.
So, looking at the example above, you're modeling handler functions as actors? Am I misunderstanding?
You don't compile your garbage? xD
What problems error_chain is solving? I find it difficult to understand why I should use it and for my current use case (Rocket-based web-app) examples are unclear...
Not for kyren - but for a kind (and more knowledgeable stranger) - what exactly is a "self borrow"? Is it when you attempt to use pieces of a struct simultaneously without assigning it to intermediate variables?
to *bits* you say??
Sad bot
Yeah you can't easily make every NaN trap. If you're only targeting linux, you can use [feenableexcept](https://linux.die.net/man/3/feenableexcept), but that's not platform-independent. In the mean-time, you could use the [noisy_float](https://crates.io/crates/noisy_float) crate, which provides the types `R32` and `R64` that behave pretty much like the built-in integer types: it checks for overflow and NaN in debug mode, and doesn't do anything in release mode.
&gt; I know, but what I wanted was one that was as simple and easy to use as builtins because I might literally just use it everywhere. Something like "nf32" to go with "f32". It's probably a pipe dream because fp hardware doesn't work like that, and so nobody would want it. There is the [noisy_float](https://crates.io/crates/noisy_float) crate, which provides the types `N32` and `N64` for non-NaN floats and `R32`/`R64` for finite floats (not NaN or inf). These are checked only in debug mode, so they don't affect runtime performance. And they implement `Ord`, obviously.
&gt; it would be much, much slower than fp Nope, not neccessarily. For multiplication, you'd e.g. need one integer `MUL` instruction and a shift for fixed point and a simple floating point `MUL` instruction for... well... floating point. There will be widening costs on 32-bit machines with 32-bit fixed point integers, though. Not so much on 64-bit CPUs though, as widening is implicit there. In the latter case, `MUL+SAR` vs. `FMUL` take about the same number of cycles on the CPUs I know. With widening, though, you have your much-much-slower indeed. Converting to floating point for shader code might be too costly or at least unpleasant, or interfacing with Lua. &gt; AFAIK they've got 0 built-in support for fixed-point Last time I checked, which is many years ago, they had support for Q16.16 and Q32 formats, though true, GPUs are very much optimised towards processing 32-bit IEEE-754 instead.
Thanks for the kind words about Dyon! It will take some years before it is mature enough for serious game projects. Also, it has some limitations due to the copy-on-write memory model, which makes it less flexible than e.g. Lua. I badly want a JIT for it now that it works pretty well for my usage, so I'm excited to see projects like HolyJIT that might make this easier.
Yes, but I'm busy these months writing a book about Rust, so I have less time to work on all my projects.
Lessons learned from `/r/cpp`: - a type-erased `Allocator` is a good default since memory allocation is in general "expensive" anyways (one syscall) and the API price of having to carry around an `Allocator` parameter is "large". - memory allocation and element construction are separate problems that should be solved independently - allocators should be composable (e.g. it should be possible to build complex allocators out of simpler ones). - `SmallVec&lt;T, N&gt;` (able to store N elements without allocation) should be implementable as `Vec&lt;T, SmallBufferAllocator&lt;T, N, FallbackAllocator&gt;&gt;` - `TinyVec&lt;T, N&gt;` should be implementable as `Vec&lt;T, SmallBufferAllocator&lt;T, N, NullAllocator&gt;&gt;` - copying/moving `Vec&lt;T, AllocA&gt;` to a `Vec&lt;T, AllocB&gt;` should work without surprises or fail to compile 
&gt; [...] something like the ord_subset crate. Never expected it to be mentioned in such a context. 'Something like' implies that you rolled your own for ordered_float and ord_subset. What are the differences? I see you have a `SemiOrd` trait.
True :) I was just trying to point out glicko2 had not been covered yet. The other choices would also be viable, but I do think that glicko2 is more accurate than either glicko or Elo (at least for my purposes.)
Yeah, things are slowly changing and hopefully someday we'll have more open consoles. There's an awful lot of prerequisites before the actual console makers themselves can do that but here's hoping! :)
I think we should have a clippy lint against unconstrained lifetimes. Use `'static`, as it makes the intention more clear. I find that there are only two interesting cases where lifetimes are needed: 1. When you have a function of multiple argument and return a ref with the lifetime of one of them ‚Äì in this case the lifetime makes it clear which argument is borrowed from. Elision handles trivial cases here. 2. When you have a type that contains borrows, genetics can make the relations between lifetimes clear. A good example for this are the various contexts in the Rust compiler. They are also very well documented.
No mmees pelsae.
Keeping homebrew developers in the dark certainly is something they (and their users!) benefit from, but they could (and do) easily maintain the same control with code signing.
From what little c and c++ experience I have subtle memory bugs can waste a humongous amount of time
&gt;That said, it would be interesting if we could work something in such that you can define heap-only types from which you *can* make self-borrows I'm fairly certain this would satisfy 80% of requests for self-borrows- most uses in C++ aren't the sort that need a custom move constructor to fix up pointers. (The other 20% would be satisfied by immovable types √† la generators with internal pointers.)
It's when you have a struct that contains a field `a`, and simultaneously another field `b` that borrows `a`. This can actually be *done*, it just makes the struct unusable, even though it should be sound in cases where moving `a` doesn't change the address of its contents (e.g. `Box`). What you describe works fine, with the caveat that if you want the borrows to escape the functions they're created in, the compiler only sees them as borrows of the entire struct.
&gt; I think if consoles supported a single common gfx api like vulkan, I would not have bothered with any of this, and probably wouldn't even have bothered with our own graphics api or anything like that. The thing I think I'm most excited about right now is the vulkan portability initiative, I really hope that takes off (and spreads to consoles). This is really inspiring to hear! FYI, a lot, if not most, of the Vulkan Portability progress so far can be attributed to the research done by [gfx-rs](https://github.com/gfx-rs/gfx) team. We are totally on the way of implementing it, even if there is still a lot to do before we can touch the Vulkan conformance test suite.
&gt; I think I would go for a NotNan or Finite type that was built into the language or something and was Ord. Have you considered writing your own ? Rust already does this for integers (e.g. `Wrapped&lt;T&gt;`), so if you write your own and publish it as a library ping us and we consider putting it either in `Num` or in `std` (you are not the first one to complain about this, but nobody was motivated enough to put in the work, it shouldn't be that hard).
[Askama](https://github.com/djc/askama) (full disclosure: I'm the author) allows you to call methods on Rust variables.
Are you guys hiring? I'm a developer for the open source Amethyst engine, and I'd love to work for you, even if you're not using Amethyst to make the game :P here's my GitHub: https://github.com/Xaeroxe 
Seconded. The last two RustFests were fantastic, and I'd love to meet you in person in Paris.
there are two types one handlers, first is simple function `|HttpRequest, Payload, State| -&gt; HttpResponse` and if you need to model complex integration with peer is actor. here is [example of simple chat](https://github.com/actix/actix-web/tree/master/examples/websocket-chat). all interactions are model on top of actors, so it is easy to have different type of chat clients (web socket, tcp) and exchange messages between all of them.
Could cargo spit the license / copyright notice of all dependent crates of a binary ?
as I said in actix comments, you welcome to join :)
So, here was my plan: Port Mesa: - Port swrast or softpipe using OSMesa as a backend - Add Orbital backend - Port llvmpipe Port SDL2: - First Mesa must be ported - Add Orbital backend for graphics and input - Use null audio first, then implement orbaudio Port Spellbound: - Receive the game code and assets under NDA and/or open source - Port remaining items - Discuss potential methods for distribution Some point in the future: - Port Intel graphics driver in Mesa
What are you trying to do exactly? The traits are pretty confusing. You seem to be making conversion factors, but the types involved are always the same, so what is the conversion? I think stepping back a bit might simplify the design, which should have the side effect of making it easier for rustc to understand.
Have you already read this overview? http://brson.github.io/2016/11/30/starting-with-error-chain Basically it abstracts away common patterns that tend to build up: creating an enum for all your error types, implementing `From` all over the place, etc and it doesn't lose the "history" of an error while doing those conversions. With rocket specifically, I don't know how well error-chain integrates, it may depend on your specific situation. In my rocket app I use error-chain and inspect any errors at the end of the routes, so I can return an appropriate HTTP status.
&gt; anybody who make a chip and solder it to a board could publish games for the Atari 2600, and so they *did* It's not like the official games were any better. I think the notion that software quality was the biggest cause for the video game crash is probably overstated. And I sincerely doubt that it's even a primary concern of the major players about why their APIs are secret. Rather, I'm pretty sure it's because they want to make it harder to root the systems easily so they can run pirated code and they know that their implementations are fairly hacky so that they can extract more juice out of the comparatively limited hardware.
&gt; SmallVec&lt;T, N&gt; (able to store N elements without allocation) should be implementable as Vec&lt;T, SmallBufferAllocator&lt;T, N, FallbackAllocator&gt;&gt; &gt; TinyVec&lt;T, N&gt; (able to only construct N elements without allocations; no fallback) should be implementable as Vec&lt;T, SmallBufferAllocator&lt;T, N, NullAllocator&gt;&gt; Could you say more about how inline storage would work with a generic allocator?
&amp;str means "a reference to a String", so who owns the string you're referencing? If you're making a new String you should pass ownership to the caller. The borrow checker won't allow you to return a reference because the String is still owned by your function's local scope, which disappears when you return. 
I've definitely had a rough time determining what my actual problem is when using rocket (and especially diesel). The actual error description is always (obviously) technically correct, but it takes me a while to connect the dots as to what it actually means.
given a function "my_test(a: i32, b: String) -&gt; MyType" in *.rs file, can I call it directly from a template as it is?
Yay, finally we can get rid of jemalloc build issues. The linkage has been weird since it added C++ support (which is disabled for rustup though).
Issue I reported some time ago for this exact feature: &lt;https://github.com/rust-lang-nursery/rust-clippy/issues/1874&gt;.
I'm very happy to find out that this exists now!
Nothing serious in Unity2d. But I have a quite big released on steam project which uses browser's canvas 2d. It's quite similar to ggez. I think it's a really awesome project. The only thing which isn't good enough yet is a mobile support.
I'd imagine you'd at least need to make the allocator `!Move` so that you could keep the pointers from being invalidated, but that seems like it would dramatically reduce the usefulness of such a thing.
I prefer blaze-lib so far. Their benchmarks claim to be faster, but more than that, it allows me to write conditionally enabled SIMD functions for distribution along vectors/matrices, so that I can leverage instruction level parallelism on my own custom operations. I haven't compared sparse implementations, but expression templates and other obscene degrees of template black magic is the biggest reason stopping me from writing more rust. I think Eigen gets more press just because it's used by big players. (And Blaze comes with excellent memory pool and thread pool implementations, so it's really quite easy to take advantage of.) The one thing that is more of an issue for me with blaze, and I imagine Eigen as well, is that it's tough to know how I should use it for maximum performance -- should I prefer row or column major? Should I transpose this array? When do I benefit from preallocating temporary arrays/matrices? Unfortunately, I've always seemed to need to benchmark each application between a variety of choices.
I've tried. I keep putting garbage in but only get garbage out.
This requires a stateful allocator: that is the storage is *part* of the allocator. In this case, `SmallBufferAllocator&lt;T, N, FallbackAllocator&gt;` would be something like: struct SmallBufferAllocator&lt;T, N: usize, FallbackAllocator: Allocator&gt; { inline_storage: [T; N], fallback: FallbackAllocator, } If the request is for less than `N` elements, it's served by `inline_storage`, otherwise it is delegated to the `FallbackAllocator`.
Could someone explain to me about what Rust does to make Floats difficult to deal with? I am new to Rust and just reading this.
I would argue that parameterizing allocators by the type of the element to allocate is a mistake too. If the allocator is to provide raw memory, it should not care about the type of elements, only its alignment. The problem is that in general the user *does not know* the type of the element to be allocated; for example, in `std::map&lt;K, V&gt;` the allocator passed uses `std::pair&lt;const K, V&gt;` as the type of elements to allocate... but that's a lie. To allocate, the element type is swapped for `map_node&lt;K, V&gt;` which contains extra meta-data!
&gt; ... but it may be general purpose if you limit yourself to 2d games I'd be 10,000% ok with that.
You might be interested in checking out [apecs](https://github.com/jonascarpay/apecs).
Immovable types is a great idea and I hope it lands, but unfortunately its impact on rental will be minor. It will allow me to remove the requirement for `StableDeref` on prefix fields, but that's about it. Fields will still need to be accessed via a closure, which is the least ergonomic part of a rental type. The reason is that, from a borrowing perspective, a movable struct and an immovable struct behind a `Box` are essentially the same. The ultimate lifetime of the struct is unknowable and so can't be expressed as a rust lifetime. `'self` or even individual field lifetimes won't do the trick since it's impossible to distinguish them between structs. Ultimately, for self-borrowing to be possible, a lifetime needs to know the exact struct instance that it came from, not just the scope where it's valid to be used. Because this is such a difficult problem, I'm unfortunately not particularly optimistic about it being resolved ever, and I view it as a fundamental weakness of a borrow-checker like system (although, again, I'd love to be wrong). The ecosystem will just have to work around it, particularly as rust matures and brownfield projects become more common.
The playpen is a minimal reproduction of the error I'm getting doing work in [this](https://github.com/iliekturtles/uom/tree/dev-num) branch trying to support different types that implement the `Num` trait. The idea is to do conversions using the underlying type, `V`, instead of converting back and forth between float the desired type. The idea is that each unit (e.g. meter, foot) implements the `UnitConversion&lt;V&gt;` trait for each supported type and returns its conversion factor: impl UnitConversion&lt;f32&gt; for foot { type T = FloatConversionFactor&lt;f32&gt;; fn conversion() -&gt; Self::T { FloatConversionFactor { value: 3.28084 } } } impl UnitConversion&lt;i32&gt; for foot { type T = IntConversionFactor&lt;i32&gt;; fn conversion() -&gt; Self::T { IntConversionFactor { value: Ratio::from_float(3.28084) } // didn't lookup actual from_float method } } For a specific `V` the `ConversionFactor&lt;V&gt;` type will always be the same, but I'm having trouble constraining the `from_base` method to recognize this.
One reason I don't think anybody stated yet is *probably* to prevent emulation. Especially with modern consoles (PS4, Xbox One, ... ) they're pretty much already x86 machines and if the API is exposed then "emulation" is much easier. 
A real world example is, I think the Nintendo Switch actually had a leak a few months back stating that save file transfer/backup or something was planned and that games should support it in advance. 
&gt; In C++, you can `std::sort` a `std::vector&lt;float&gt;` all day, and if one of them is NaNs you will not get UB. Actually, you do get full-on UB :( A couple years ago, I had a crash in `std::sort` because a poorly written comparison function caused it to run out of bounds. Sorry :x
I wonder if the Rust team would want to actually take on the legal work necessary. They might be able to convince the project sponsors to allocate lawyer time to get it taken care of.
I don't actually how heap-only types would work: it's not where the value is that is the issue, it's moving it, and heap-only kinda imply *can move from heap to heap* to me. I think we'd need either: - immovable types, - relative pointers.
Thanks! I appreciate that you took the time to answer.
There are many possible variants, though: - should you panic, or provide a specific behavior? - should you do so when assigning `NaN`, or when comparing specifically? - which specific behavior: smaller/larger than anything (even infinite)? something else? and beyond, there's the runtime representation and overhead to consider.
In that case the inline storage would be next to the usual three (pointer, length, capacity) words, which is quite wasteful compared to having them occupy the same space with down to a single discriminant bit.
&gt; Spacemacs Can you please tell me what your configuration for Rust is like in Spacemacs? I've gotten it customized decently enough for my main work language, but I'm not happy with the Rust setup when last I tried it.
Also, that design would require `SmallVec` to contain a pointer to itself, which is incompatible with Rust‚Äôs ‚Äúmove is always a `memcpy`‚Äù principle regardless of allocator APIs.
Not at all. The current [immovable types RFC](https://github.com/Zoxc/rfcs/blob/static/text/0000-immovable-types.md#allowing-immovable-types-in-container-types) proposes that types like `Box`, `Rc`, and `Arc` prevent their contained object from moving when it is `!Move`. /u/eddyb goes into a little more detail in [the RFC thread](https://github.com/rust-lang/rfcs/pull/1858#issuecomment-282109078). The same mechanism could be applied, but without the perma-borrow aspect of `!Move` types. For a `Box&lt;T&gt;`, borrows of its contained `T` would need to prevent destruction of the box itself, but not moving the box itself.
Yeah, pretty much. I changed the `'static` to `'a` and derived `Serialize` for the `User` type. I also couldn't use `Status::NotModified` because it didn't work with `sized_body`.
Using Rust and SDL on the desktop, along with other things you've said, and Chucklefish's history, I'm assuming that "desktop" includes the three major PC platforms. If this is correct, have there been any interesting complications in making the engine work across those, or has that mostly been trivial?
Floats do not implement the `Ord` trait, because floats do not form a total order. So if you want to use a floating point where you require `Ord`, it won't work.
I think that this is something we'd like, but just don't have the relevant experience or connections. I have no idea how to... what, like, call up Nintendo?
FWIW, from another latency-sensitive domain, I fully agree with your assessment of C++. I've seen lots of C++ developers mentioning that C++11 solved the memory issues, and to just use smart pointers, and I cannot stress how much their (wilful?) ignorance saddens me. There's so much undefined behavior in C++, that I doubt any program of significant size is UB-free. Even "Modern" C++ falls prey to it, be it dangling references/iterators, signed integer overflow, etc... ... and the main issue as you mention is that if something has a 0.001% chance of happening, it'll rarely (if ever) trigger during testing, but somehow happen randomly here and there in production. And when it's a memory corruption/data-race issue, the crash dump is not always that helpful :(
I notice there aren't any LGPL licensed crates in there. After checking my own project, I mostly see Apache, BSD, and MIT, but there were a couple LGPL licensed crates, one of which seems to be an indirect dependency (although I don't see it in the output of `cargo graph`, maybe it is a dev dependency). I think I read in another comment in this thread that Rust statically links libraries into the executable. Does this mean an LGPL dependency, even if indirect, requires a project that uses it to be open sourced?
IINM what we need is "generative" lifetimes (cf. generative modules in MLs): each time the existential lifetime is 'opened' the typechecker represents it as a fresh lifetime variable that's unequal to every other lifetime in the program. This would solve the "separate struct instances" issue, again IINM. I'm not sure if this is a sufficient condition, but I'm pretty sure it's a necessary one.
OMG this is great. I'm also with /u/Manishearth on the community team, and I wanted to also invite you to talk at one of our meetups around the world. Manish and I run the [SF Bay Area meetup](https://www.meetup.com/Rust-Bay-Area/) that can do remote talks, and we have a pretty active group in [London](https://www.meetup.com/Rust-London-User-Group/). Let us know if you're interested! Or maybe one of the conferences next year if they line up with the release for Spellbound? * [RustConf](http://rustconf.com/), usually on the west coast of the US. * [RustFest](http://rustfest.eu) in Europe. * [Rust Belt Rust](https://www.rust-belt-rust.com/) on the east coast of the US.
Ah, well, here we are today in a thread with a game dev who probably can at least *forward* you the contacts of people who could get that ball rolling. Please reply to kyrenn or dm her directly if it's something the Rust project really does want to do.
Totally!
Note: are you aware of the Nim programming language? Araq (its creator) is primarily a game developer AFAIK and the Nim language has a very malleable incremental GC: you can choose between fully autonomous, autonomous with "forced" call and fully controlled, and when "forcing" the GC you can specify a maximum duration for the call (ie, the remainder of the frame time).
You're certainly welcome here :)
Could you give me an example? I'm a bit thickheaded about this.
Okay, let's break out the standardese :D You can look [here](http://en.cppreference.com/w/cpp/concept/Compare) for the C++ "Compare" concept, but the key bit is that any comparison function must be a [strict weak ordering](https://en.wikipedia.org/wiki/Weak_ordering#Strict_weak_orderings). You can kind of argue back and forth about why specifically C++ std::sort requires a *strict weak ordering* and not something else like a total ordering, but I would argue that basically the way it is worded is so that it is *exactly enough* not to crash on floating point inputs. So, strangely enough, if you violate strict weak ordering you risk a *crash*, but if your types are strict weak ordered but not totally ordered, you will get unspecified sorting behavior WITHOUT a crash. I'm probably getting something subtly wrong in the language there, but that's basically it. You can always "sort" floats without a crash, but they may not actually sort or do anything you expect. That's at least how I currently understand it.
Okay fair point, what I was saying basically entails immovable types. It would perhaps be useful to be able to *treat* "heap-only" (bad name) types as immovable without them actually *being* immutable, just when they're in a `Box`/etc. This could probably even be done without exposing `?Move` to the language, just by using the piece of immovable types that disables moving out of `Box` when its value has been borrowed.
But a reputation of buggy software can't kill the PC platform. Users would leave a console platform altogether at the first signs of instability.
The frustrating part is that it would be entirely possible to have real quality control while also being relatively open about development. iOS has reasonably strict quality control for their store, while also providing development docs in the open and allowing people to discuss development. I don't agree with some of their policies, which is why I'll never own an iPhone unless they change them, but they cover "quality control while allowing people to discuss development" reasonably well. Android also has a controlled store by default, but with less restrictive policies on what kinds of things you can develop and the option of side loading. This is about where I find the sweet spot, though I think that they could actually impose greater quality control on the Play Store. A platform which has a quality controlled store by default, but allows open development and side-loading of apps with sufficient amounts of warning and consent from the user, is entirely possible. It looks like of the consoles, XBox is almost there with the UWP and the ability to enable dev mode on an ordinary console, but is still a bit too closed down for my liking.
Ah! Sorry, I though the question was much more high-level than that. &gt; In that case the inline storage would be next to the usual three (pointer, length, capacity) words, which is quite wasteful compared to having them occupy the same space with down to a single discriminant bit. I agree. The only way to get this is by piling up not the allocators but the *whole* storage layer, and ensuring that each layer exposes a "free bit/byte" at a specific offset to be used for tagging when `union` the parts. I've played around with an `instrusive_variant` in this vein, and it's quite painful to ensure that the "tagging space" is always properly aligned :/ &gt; Also, that design would require SmallVec to contain a pointer to itself, which is incompatible with Rust‚Äôs ‚Äúmove is always a memcpy‚Äù principle regardless of allocator APIs. Indeed, I had not thought of that. And putting the allocator or inline storage on the heap is kinda self-defeating :(
No worries! Here's an example with a different, but similar trait: `Eq`: use std::collections::HashMap; fn main() { let map = HashMap::new(); map.insert(1.0f64, "oh no"); } You can't use a float as the key of a HashMap because it doesn't implement `Eq`. The above code will fail to compile. Does that make sense?
The simplest example is trying to sort floats. let mut v = vec![1.0, 2.0]; v.sort(); It fails with `the trait `std::cmp::Ord` is not implemented for {float}` because the `sort` function requires that trait bound. So you end up having to use a wrapper type or `sort_by_key` instead. Another example is trying to key a BTreeMap (an ordered dictionary) with floats. let mut dict = std::collections::BTreeMap::new(); dict.insert(1.0, "foo"); It fails with the same error.
Oh! Thanks for brightening my day! --- Unfortunately I don't have the function/codebase at hand any longer; I seem to remember it was the typical failure to implement lexicographical order in this way: bool operator&lt;(a, b) { return a.0 &lt; b.0 &amp;&amp; a.1 &lt; b.1; } which indeed would not even satisfy the Strict Weak Ordering. 
You know what, I was actually unaware of noisy_float, that actually looks like almost exactly what I wanted. It even implements all the important num_traits traits, including the Float trait. I actually wish I knew about this before, thank you for showing me that!
`'static` is more restrictive than a lifetime parameter in invariant positions, and it also limits inference when combined with the `Fn` traits, i.e. a function which returns `&amp;'static str` can't implement `Fn(...) -&gt; &amp;'a str` for `'a` shorter than `'static` (this is technically a special case of invariance, but one that's not localized to the function signature).
Yep, definitely that could risk a crash. You may already know this, but what you probably want is to use tuples there, so you could do something like `return std::tie(a.0, a.1) &lt; std::tie(b.0, b.1);` for a quick idiomatic and correct way to implement those.
Any plans on adding drivers for wireless cards for people with no Ethernet? I am assuming this won't happen any time soon. Every card would needs its own drivers right?
Yes, I've been advocating tuples ever seen I've been able to use C++11 because it makes things so much easier. At the time, however, the project was still stuck in C++03, and... I'm pretty certain this one was the result of a copy-paste of `operator==` which went wrong. --- Did I note how much I love `#[derive(PartialOrd, Ord, PartialEq, Eq)]` in Rust, compared to recoding the *6* same operators over and over? Oh, and `#[derive(Debug)]` too...
(This has nothing to do with this) Chucklefish made my favourite video games starbound and stardew valley. Is there a chance that starbound will be ported to the consoles 
That does sound distinctly plausible, since the HRTB closure trick in rental is used to produce such a lifetime already. If there were a way to do it outside of a closure that could work. This ventures into type theoretic territory that's over my head though, so I'll leave it to the pros to weigh in.
You're right to call me out on the "no gc" requirement, I was definitely dramatically oversimplifying the situation. I clarified what I meant a bit in another comment, but I'll repeat it here. It seems like if you want a GC for video games, then you probably want a language / gc combination that has the following properties: * Idiomatic ways of being easy on the GC, with the best version of this being something like Rust / C / C++ where types are unpacked by default and product types are big and friendly and contiguous. I'm kind of calling out things like object pools or crazy unpacking techniques in Haskell where you CAN write code that doesn't have huge allocation pressure but it feels like constantly going against the grain of the language. * Soft realtime bounds * Per-thread garbage collection It actually seems like Nim fits that exactly, so I definitely wouldn't want to inadvertently steer someone away from Nim with what I said about garbage collection. What your language is like and how the garbage collection works is certainly a hugely important factor. Also, I think you would be overwhelmingly likely to have a more educated opinion than me on the subject, being a core contributor to Nim, so if you say that it is a GC designed specifically for games, then it at the very least would deserve a second look. &gt; By the way, I love Starbound and my SO is absolutely in love with Stardew Valley (Myself and her are both excited about your upcoming game). That's wonderful to hear, I'm really glad you enjoyed Starbound! It means a lot to everyone at Chucklefish to hear stuff like that. Complete honesty here, Stardew Valley is one of my all time favorite games. I know I'm OBVIOUSLY biased, but it really really is, I'm currently playing through it again on the Switch, and I'm gonna marry Shane and raise chickens and it's gonna be great :D You had some questions though, &gt; have you evaluated Nim for your project? I have not, and honestly I've actually been meaning to try it. It seems like a really cool project, and I hear a lot of people saying positive things about it. I promise I'll try Nim :) &gt; what is your experience with GCs in games? Have you ever used one with real-time support? I spent a long time thinking about how to make Haskell work in a soft realtime context before concluding that it's just really hard to do, and I learned a bit about how modern GCs work in the process. I've never had the pleasure of using a GCd language with a real-time focus, so again I should probably try Nim if only to see what a GC language is like that DOES have this as a focus.
Unfortunately, immovable or heap-only types don't get us very far because of the way lifetime unification works. See [this subthread](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dot0qn5/) for more details.
&gt; the HRTB closure trick in rental is used to produce such a lifetime already. If there were a way to do it outside of a closure that could work Yep, I was just about to add in an edit clarifying that this is what it'd essentially be :) And answering the questionish from my previous comment, we'd also of course need a way to prevent moves of self-borrowing types and distinguish structs from boxes, etc., so it's only a necessary condition.
My exact reaction to the readme: "huh why in the world would I need -- oooooh, neat!" It's basically the Builder or Modifier pattern implemented really simply.
Sure- the immovable types RFC still has some more work to be done but it should be doable with the sort of type work described in that thread.
I'd love to read more about that language! Sounds like a really interesting blend, I'd be curious to see how you pull it off!
Nope.
Yes, Rust statically links by default, and GNU addresses this in their FAQ: https://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic (IANAL) So it doesn't necessarily mean you have to be open source yourself, as you could just provide your unlinked bits that the user can then link to their own modifications of the LGPL part.
If you're doing PS4, are the modifications to std anything you could share on devnet? I know there is some interest in Rust. (May want to check with Sony first.)
I want to add a bit to that "2 week" figure, I think it's accurate but it's a pretty nuanced figure, and I don't want to give people the wrong idea. Here's a rough timeline of how porting work went: * Day 1) We should go ahead and do initial porting work, it's looming over our heads, and if there are any real problems we really should learn what they are ASAP * Day 2) Well, I have cheated and lied and abused static linking and LTO, but I have rust running #[no_std] on every major console, that was massively easier than I thought it was, the hardest part was updating my devkit firmware :/ * Day 3) Okay, I've tried all three consoles now with allocation and the containers crate, and I think I understand how 'xargo' works, so I think I have a rough plan of how to get std working on at least one console. * Day 5) I actually have the game running in "headless mode" on a real actual console already. This is *amazing*... I'm still abusing LTO, but I know now this is 100% doable. * Day 7) Okay, I've cleaned up a bit how I did console #1, and I now also have console #2 running headless. I no longer need LTO as I've cleaned up a lot of the things that were causing linker errors and splattered `panic!("not available on the XXX")` everywhere. * Day 8) Console 3 was actually vastly easier than the others, it's closer to its parent platform. * Days 9 and 10) Everything I thought I knew about the console APIs was a lie, the fact that [directory listing/TLS/threads in general] worked was just a fluke, oh god I think I'm finding bugs in the posix implementation in X, how am I going to work around this, okay I think it ACTUALLY may work now... repeat this a few times. So, I realize that's already like a 10 day timeline, and this is just for solidly getting a project to run "headless" on a console (no graphics, sound, or input). I know that there's a thin smear of extra time following this that was maybe more difficult than it otherwise would be dealing with an extra language boundary or build headaches. The "two week" figure is just a rough estimate, I was moving *really fast* during this 10ish day period, but also some of the work I had to do I wouldn't say was specific to using rust, just stuff you deal with when porting to consoles. I think the "two week" figure is roughly accurate, but maybe I should have said "two weeks including weekends, and I wasn't exactly a slowpoke at the time". If you're uncomfortable with that estimate, you could raise it to 3 weeks.
Good to know, thank you!
Even if I can't break the siren call of IEEE-754, there is *real wisdom* in what this person says.
Maybe! I think after the rust based disruption has settled we can look at changing other parts of the equation, for sure.
I promise it's still being *actively* worked on! Do not lose hope!
&gt; the entirety of rlua I was thinking of making a sort of low-level abstraction to at least reduce the amount of raw FFI rlua has to do, but it turned out pretty complicated and now I don't have much time :( Anyway, keep up the great work!
Having written exactly this kind of code for a toy 2d game as a university project I am curious: why do you go to such far extents to make things as generic as possible (I'm taking about the floating point type T)? In my java code I started trying to be generic, but then figured out I'm only going to be using float anyway, and all the generic syntax would just be additional noise. If not for the weird partial ordering and wrappers discussed above, would you have sticked to just floats, or does this fulfil other roles as well?
I replied to one of the core Nim developers [here](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dot8gr2/?context=3), it may be interesting?
This is kind of a translation of some code in Starbound, but I immediately had a use case in mind for multiple types, because Starbound had exactly those use cases. I guess being generic over f32 / f64 is pretty straightforward, but Starbound actually uses integer polygon methods in the UI quite a bit, to do things like determining whether a click is inside a given polygonal region. You *do* make a fair point though, and I wouldn't fault anybody for *not* writing things as generic as possible.
Servo has heap-only types because of its integration with the spidermonkey GC. We use some lints to enforce this, but something builtin would be nicer.
Specifically looking at `convex_hull`, you have a `SemiOrd` trait, which presumably is just `PartialOrd` plus `is_ord`, `semi_max`, and `semi_min`. You filter out the elements based on `is_ord`, and then `unwrap` the result of `partial_cmp`. Did you consider having `type Ordered: Ord; fn into_ord(self) -&gt; Option&lt;Self::Ordered&gt;;`, which for, say, `f64` would return a `struct OrderedF64(f64);`? That would allow you to `flat_map` instead of `filter`, and then you wouldn't need the `unwrap` later on (it would still exist, but it'd be part of the implementation of `SemiOrd` for `OrderedF64`). After having said this, it sounds potentially even more complicated than what you do already, but I like that it lets you avoid manually checking `is_ord` and `unwrap`ing at the usage sites.
Any refs to Dost? (search is not really helpful here...)
That's basically what I imagined when I read your "2 weeks". I was mostly interested in the time from "let's start porting" to "we can compile rust code with cargo/xargo, link and run it on all three platforms and have demonstrated that we can call all the relevant platform APIs without extreme hacks". Everything after that is basically the same work and problems you would have porting a C(++) code base. (Like what you described for days 9&amp;10.) Maybe with a few % of overhead due to the language boundary, but in the grand scheme of developing a game, that's just a drop in the ocean.
More generally one of the common cases where this comes up is when you have heap allocated struct A which holds pointers that eventually reach heap allocated struct B and you wish for B's methods to be able to get back to the A.
&gt; If you're wondering about error_chain, I desperately need the Error types to be Sync, it will be amazingly fantastic when the changes land to let you customize Send + Sync bounds. /u/desiringmachines is working on an approach to error handling that's basically the successor of error_chain (https://github.com/withoutboats/failure) . It's not done yet but that might suit your needs as well. Because it's early on in its evolution it's possible that it might be able to design for sync-able errors (if it doesn't already) without it being a breaking change. 
It's not so bad haha. Thank you for all your amazing help with rlua :)
Yeah, it sounds like you have it exactly right.
I think so, but it's super awkward because internally we have one 'rust-patched-deps" project that ofc contains API information for all three consoles. I could probably split it out and just like, dump some files on devnet, but that really seems like not the optimal way to do it. I have a feeling if I ask Sony I'm going to get an answer like "what, what are you doing, why aren't you using C++, DIDN'T YOU READ TRC XYZ.W (which I read), etc. I might be being overly pessimistic there though.
&gt; Is there a chance that starbound will be ported to the consoles There's more than a chance, it's (still) being actively worked on! I promise we'll have more info on this soon!
You said basically what I was going to say, which was that you COULD have open development with just as strict closed off quality control, and the open development could simply be for "hobbyist / middleware developers" and onerous for a consumer to try to use. It may simply be that having that door open is just too juicy a target for console hacking, or there's not a way to make hobbyist / middleware development inconvenient *enough*, and they can't justify it.
That's actually a point I hadn't thought of!
Thanks for that link, I learned a bunch about NaNs from reading through this thread actually. I also am really happy I learned about the 'noisy_float' crate.
Your point is entirely valid, but I have to mention a real counter-example to this that I've encountered before. NaN's are no big deal until you accidentally write one inside somebody's save file. Like I said, your point still stands though and probably more so for something like a Polygon.
I was made aware of the 'noisy_float' crate, which might just literally be what I wanted the whole time.
I bet the combat will be the hardest thing to port. 
&gt; I can't talk about it at all, afaik, even after release. You can't discuss or share information on console APIs, the rules are very strict. I would in a heartbeat if I could Boy what a terrible thing it would be if someone happened to put stuff on pastebin anonymously!
„Ç¢„É°„Ç§„Ç∏„É≥„Ç∞! But maybe you also just procrastinate learning Japanese by programming? (I know it has been an actual problem for me learning languages in the past.)
I've spent the last few hours slurping cold coffee while reading everything here. And I'm *still* not done! I can't focus on study until I get through it all though. Fantastic and detailed answers. I (and looks like many others) can't thank you enough for taking the time to do this. I feel like I've had my choice to switch wholly to Rust for any and all future development validated. Question: What is your development environment? A particular IDE? Set of tools and editor? OS (especially curious here as Rust is painless on Linux and I haven't used Windows for many years)?
I would recommend going through the tutorials on the website and follow them with the Rust variants of them that are in the bindings directory. You'll probably also soon get a feeling for how the C code maps to Rust, so that when reading the further (C heavy) docs you can abstract from C and just focus on the concepts. Generally the C API and Rust API are very close, just that the Rust API is more convenient and safer :)
Passing an &amp;[u8] of the individual vobsub elementary stream packets would be the easiest. That's exactly what you get from GStreamer, those plus metadata like timestamps. All the MPEG container and PES handling is generic in other components
Sure, but as I mentioned I had the std library in mind so I would do as the standard library does. Under the definition that: - `Finite`s cannot be `NaN` or `Infinite` then &gt; should you panic, or provide a specific behavior? `panic!` like the standard library types do on debug builds at leat. &gt;should you do so when assigning NaN, or when comparing specifically? Since `Finite`s cannot be `NaN` or `Infinite` by definition this should be checked on assignment and after operations between `Finite`s that can produce a `NaN`. &gt; which specific behavior: smaller/larger than anything (even infinite)? something else? `Finite`s cannot be `infinite`. If the user wants to compare the underlying float of a `Finite` with some infinite value, they should move the value out and do the comparison. IMO the only hard decision is whether to use `assert!` for the panics or `debug_assert!`. Since we want `Finite` to be usable in performance sensitive code, and since violating `Finite`s invariants cannot introduce unsafety (`unsafe` code must guard against this anyways), we should use `debug_assert!` so that those that care about performance can disable the checks in release builds, and those that care about robustness can leave them enabled. 
&gt; I would argue that parameterizing allocators by the type of the element to allocate is a mistake too. I agree, I chose only `Vec` as an example because in this case the user knows. For a list the user doesn't know, and the container wrapper would need to handle this.
This was a goldmine of information... I now have some ideas rattling around in my head to use on my own little hobby engine. Thanks so much!!
&gt; Could you say more about how inline storage would work with a generic allocator? The Allocator is then just a `[u8; M]`. For example, `RawVec` is currently: struct RawVec&lt;T, A: Alloc&gt; { data: *T, cap: usize, a: Alloc, } 
&gt; what's your most / least favorite clippy lint? I think if I tell you my most favorite it will just let you know what I constantly screw up :P Probably my favorites are the ones that stopped some bad patterns while I was more actively learning, like ones about &amp; patterns when matching refs vs dereferencing, or ones that broke bad habits like unnecessary return. Probably my least favorite one is "consider adding a Default implementation", not because it's wrong, but because I'm always too lazy to fix it and I have tons of them. Oh, also the "casting ixx to ixx may become silently lossy if the types change" is an annoying one for 'rlua' right now, but like I said with my current workflow this is not exactly the worst thing in the world. &gt; Do you activate any of the restriction lints? Do you use any allow-by-default Rust lints? I just use the defaults to be honest. Also, we don't have clippy integrated with our build procedure or anything, I just use it manually and fixup the errors that I think are important or obviously better, and leave some of the rest. I think we could use it more tbh. &gt; What lint would you like to see in clippy most? I'm not sure! I don't think I'm probably enough of a clippy power user yet to really give you a good suggestion there, mostly I'm just happy for what suggestions I get out of it. I think a good next step is to use it in a more structured way.
Thank you so much for answering! I have a lot of respect for your work so it really means a lot :) It's exciting to see those 3 properties you've described because Nim really does fit them all well. This is right down to the per-thread garbage collection which I haven't associated as being a plus for games. &gt; Also, I think you would be overwhelmingly likely to have a more educated opinion than me on the subject, being a core contributor to Nim, so if you say that it is a GC designed specifically for games, then it at the very least would deserve a second look. I must admit that my game development experience is rather slim (something that I'd love to change). But I do see a sort of sway towards game development in the population of programmers using Nim. Based on my knowledge, from the tests I've seen and from what I've been told, the GC that Nim sports is pretty great for games. There are certainly no AAA games that make use of it (yet :)), but there are a couple of indie game devs making use of it ([Vektor 2089](https://impbox.itch.io/vektor2089) is one of my favourites). &gt; Complete honesty here, Stardew Valley is one of my all time favorite games. I know I'm OBVIOUSLY biased, but it really really is, I'm currently playing through it again on the Switch, and I'm gonna marry Shane and raise chickens and it's gonna be great :D I actually haven't played all that much Stardew Valley myself. I'll have to give the multiplayer a go with my SO once it comes out on PC/Mac :D &gt; I have not, and honestly I've actually been meaning to try it. It seems like a really cool project, and I hear a lot of people saying positive things about it. I promise I'll try Nim :) Thank you! I'm super happy to hear that. Be sure to pop in to our [IRC/Gitter channel](http://nim-lang.org/community.html) if you've got any questions :) On a side note, the Rust community is awesome and I really want to give Rust another more thorough look as well. &gt; I've never had the pleasure of using a GCd language with a real-time focus, so again I should probably try Nim if only to see what a GC language is like that DOES have this as a focus. If you do end up taking a closer look at Nim, and especially if you evaluate its GC for games, then please please let us know what you've thought of it. We've got a subreddit too (see the already mentioned community page for details) or you can also just email me directly (email's on my website: https://picheta.me). Thanks a lot for your thorough answer once again. I'll be keeping a close eye on ChuckleFish's twitter for the release of Spellbound. :)
The situation here is actually still in flux, but we internally forked 'ordered_float' and 'ord_subset'. I feel pretty guilty about not making an attempt to upstream the improvements we made, but I have some capital O-pinions about how the traits should work, and I just wanted to get that working inside spellbound. For 'ordered_float', there were two problems. One, NotNaN didn't implement the Float trait, and that was 100% the absolutely most critical trait for it to implement. I know *why* it doesn't (there's literally a nan method, it's supposed to return a nan), but I really really needed it to. Our version implements Float and a bunch of other num_traits traits, and NotNan::nan() just.. panics haha. For OrderedFloat, I wanted OrderedFloat to implement numeric types similar to NotNan, so you could choose either as a float type inside a mathematical container like Vector2 or Polygon. We (for better or worse) have a bunch of generic numeric code, and honestly still haven't worked out the best patterns here, but I wanted to try using OrderedFloat like NotNan. For 'ord_subset', again I had some ultimately unimportant capital O-pinions about how it should work, but more importantly needed it to be implemented for anything Ord, so you could depend on SemiOrd and it would work for any old Ord type trivially, but also floats. I tried to implement this actually with specialization, but failed at it and just manually implemented it for the builtin types. The easiest way again, was to internally fork. I'm not proud, we should have been better open source citizens and tried to work with the upstream crates.
For *bounds*, that's a special case, I agree. However, unbounded lifetimes are risky if instantiated and may lead to surprising errors.
As someone who's worked professionally on C++ game engine code which emphatically avoided std/OO/modern C++ and follows the Blow/Muratori/etc crowd's philosophy on software architecture, I strongly agree with kyrenn here. Blow is right about *most* memory bugs being pretty straightforward (especially to someone with his experience), and he's right that frontloading memory safety feels like friction. But he's completely wrong about the last few memory bugs that just absolutely destroy you. They take absurd amounts of time to track down, it's highly likely some will slip through and ship, and they often require some rearchitecting to fix. What I think Blow would find if he spent the time to really write some Rust is that it strongly encourages you to follow the very same style he advocates- no OOP and very straightforward and efficient memory management patterns. After getting over the initial learning curve, the remaining "true" borrow checker errors are all pointing at often-subtle ways in which you've deviated from that style. Rust is certainly still rough around the edges in this area (self-borrows/immovable types, lack of NLL, lack of custom DST formats, etc). Regardless, I think it's a win for people like Blow who are already experienced with this style, as well as for less-experienced people who are able to work in an existing framework.
Hey bartwe, nice to talk to you again! Maybe one day rust will have a giant sexy IDE with refactoring tools and we can drag you over :)
Hello there! Thanks for commenting, but it seems that this isn't quite the right subreddit for you. I would recommend cross-posting to /r/rust_gamedev, /r/gamedev, and possibly /r/programming if you'd like to get more complete answers. Still, I happen to know something about computer graphics, so I'll try my best to help you. Real-time computer graphics is a staggeringly deep and complex topic, and since you are a self-stated novice, I would strongly recommend reading as many books and tutorials as you can. A few books I personally found useful are [_Real-Time Rendering_](https://www.amazon.com/dp/1568814240/), [_Game Engine Architecture_](https://www.amazon.com/dp/1466560010/), and [_Mathematics for 3D Game Programming and Computer Graphics_](https://www.amazon.com/dp/1435458869/). Some nice online tutorials include [open.gl](https://open.gl/) and [vulkan-tutorial.com](https://vulkan-tutorial.com/). Now for the Rust-specific information. At this time of writing, the most robust cross-API abstraction available for Rust is [gfx-rs](https://github.com/gfx-rs/gfx) which is pretty widely used, though it's undergoing something of a rewrite at the moment. If you would like to go with a specific graphics API, I would recommend "pretty" Rust bindings like [Ash](https://github.com/MaikKlein/ash) or [Vulkano](https://github.com/vulkano-rs/vulkano) for Vulkan, or [glium](https://github.com/glium/glium) for OpenGL. If you prefer a more raw approach, simpler crates like [vulkan_rs](https://crates.io/crates/vulkan_rs) and [gl](https://github.com/brendanzab/gl-rs/) should suffice. With all that said, writing a game engine from scratch is a massive undertaking, especially for a lone developer (speaking from experience here). There are already multiple ongoing efforts within the Rust community that aim to write flexible, effective game engines (e.g. [GGEZ](http://ggez.rs/), [Amethyst](https://www.amethyst.rs/), and [Piston](http://www.piston.rs/) being the most notable examples). Why not join forces and reuse their rendering code together with your networking code? It could be very beneficial for all involved.
No global variables really at all, we use a pretty standard ECS architecture where we have a type that can hold type indexed Resources and Components. Interestingly, our flavor of ECS separates the part of ECS that stores data and anything to do with systems, and imo if you want to understand ECS architecture you should just start by thinking about what the data representation is like. We do have a specific pattern of globals that I think is kind of interesting, but they're definitely not *global mutable variables* or anything. We use the term "registry" to describe this pattern. There's a top level global called "REGISTRY", which is initialized with lazy_static. Inside that, are registries for components, resources, systems, and scripting. What these contain more or less is maps from string ids to Box&lt;Trait&gt;, and allows you to get at all the different types of engine side things that are available to the game in a dynamic way. When the REGISTRY is initialized, there are maybe 20 types per category that are inserted into these HashMaps, and that is used for loading scenes, instantiating systems, registering types with our ECS code, and generating appropriate script bindings. Since the REGISTRY is just basically reflection on actual in-code types, there's no reason for it to be variable or loaded from a config or anything like that, and the code is structured so that when you add say a component, you know to add the component module file, add the 'use' declaration for that module, and then right *below* the use declaration add it to the registry init. This pattern has worked out pretty well actually so far.
I'm on spacemacs stable, and my spacemacs config has a lot of workarounds for different spacemacs bugs. I also don't think I can stand neotree anymore, and am chomping at the bit for the treemacs plugin. It will be a very happy day when the new spacemacs stable comes out, or when I give up and just track develop.
what MaikKlein said, I just use basically the stock Rust layer, which doesn't use RLS. It works really well actually, the only complaint I have is that sometimes it's slow, I'm hoping this improves eventually with emacs 26 + time.
[t4rust](https://github.com/ReSpeak/t4rust) (full disclosure: I'm the author) Lets you write template text and rust code completly mixed.
I would actually be worried about performance, particularly anything that triggers integer division.
I'm not the OP, but I can give you my opinion. Even a realtime GC, and even one with Nim's interface for controlling pause times, is not ideal or even helpful for games. GC works fine for relatively small games, and Nim's probably expands that niche, but it's still a compromise and beyond that niche it gets in the way. Generally using a GC means two things. The first is that you're free to allocate individual objects from a general heap at any time. The second is that you have an extra task that has no obvious time to run. Allocating individual objects all over the place is bad for several interrelated reasons. Their lifetime becomes confused so it becomes harder to control memory usage. They are unlikely to be nearby other relevant objects, hurting cache usage. They must be accessed through pointers, or else references to them become larger, or else the GC becomes vastly more complex. Pulling memory freeing into its own extra task obfuscates how much work it actually takes to run any single piece of the game. The size of this extra task is unpredictable and very hard to control as its "input" is essentially "the entire rest of the program." While Nim's realtime interface is nice, at the end of the day it just can't control the rate at which garbage is generated- you have to do the dirty work of trawling through the code and removing allocations. So much for why GC isn't ideal. Going further, it's generally not helpful either because games get huge benefits from specialized memory management patterns. Large, contiguous chunks with tightly controlled lifetimes for static data like assets. Arenas that can be filled and then cleared at virtually no cost for transient per-frame data. Arrays of plain old data, accessed using handles, for entities that must be destroyed at specific times, even if something else still holds a reference. If GC has any place in game dev beyond smaller projects, it's as a specialized tool that can be applied with precision- not a global allocator that anyone can use at any time.
You're very welcome!
Honestly, it's been entirely, blessedly trivial. I can't even think of something to mention that's been a problem really, or even anything I had to actively *do* other than setting up build slaves for multiple OSes. And yeah, when I say "desktop" I generally mean Windows+Mac+Linux, and do in this case as well.
Rust bindings for CNTK (deep learning library from Microsoft).
Interestingly enough, we use Tiled right now and are trying to transition into a custom editor, which is built into the game :D. I don't know how this is going to work out, so don't take this as a *promise* or anything, but if it does work out I'm excited about what that will mean for the modding community.
&gt; By the way, as one of the world's twelve WiiU owners, I would buy it on that if the Switch API stuff is compatible at all. ;-) It's a really good system, and I am one of the other twelve owners, but *probably* it will just be on the Switch.
As another data point, I once spent a similar amount of time (~2 weeks) getting Rust running on the PS4: I took a different approach than Spellbound. After porting libstd (not bad at all), instead of writing the platform-specific code in C, I started hooking up bindgen. It probably would have taken me another few weeks to get everything I used working, and a lot longer to write a Rustic API on top of the bindings, but in that time I was able to port some SDK demos to Rust. Unfortunately I had to move on to other projects and I have since switched jobs, but at some point I'd like to come back and finish what I started.
&gt; allocators should be composable Yes please. I like the approach to composition Andrei Alexandrescu took in [his C++Con 2015 talk](https://www.youtube.com/watch?v=LIb3L4vKZ7U). I still have to catch up on the current design in Rust - hopefully I'll find it's comparable in this regard.
I think the overview you gave in another post explains it pretty well. Just need a lot of people pushing on first parties to develop an official solution in the next 3-4 years I think.
&gt; Question: What is your development environment? A particular IDE? Set of tools and editor? OS (especially curious here as Rust is painless on Linux and I haven't used Windows for many years)? Spacemacs + macos. Other Chucklefishes are different though, and all the other programmers use windows or linux. Rust + windows is not actually *too* bad right now, but sometimes there's the odd feature that is lagging behind like a crate that doesn't build properly without MinGW on windows, or the whole deal with windows CARGO_INCREMENTAL=1 bugs.
So mostly the basic Spacemacs Rust layer? You're hardcore. It was too wonky for me.
"hardcore" is probably slang for "not as good at spacemacs".
Thanks again for your insight! Is very informative to see how ideas end up working out in practice. Your other discussion (on rental at https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dosxj0a/) made it clearer how one might manage multiple smaller Lua interpreters interacting with the rest of the engine. (Just treat them as independent systems in the core ECS framework.)
Screenshot so we can see in what way it's bad? Platform? If you're on Windows, I believe there's an issue with some fonts that people might have installed already which causes them to render incorrectly. See for example: https://github.com/rust-lang/rust/issues/24355 and https://github.com/rust-lang/rust/issues/16372 This has been fixed in newer versions of the font, which the docs use if loading the webfont, but they will use your local install preferably to avoid extra network traffic. If you have the issue, either uninstalling or upgrading your local version is frequently the solution. I actually think some similar issues may have come up with Linux versions of the fonts installed, and likewise either upgrading or uninstalling the packages would fix the issue. If that's not the issue, you might want to provide a little extra information about your platform, how it's bad, check different browsers to see if it's Firefox or all browsers, and check the dev tools to see if you're getting the font locally or from the webfont.
You are telling the compiler "This function returns a reference to a str with an lifetime the caller can choose arbitrary". This seems wrong at the first glance, but the trick is that there is almost nothing you could write in the function body that would make it actually compile.
You might also like https://www.youtube.com/watch?v=GCsxYAxw3JQ, which isn't EXACTLY what you're asking, but related.
Hmm, looks like the issue with Source Code Pro was fixed by not using the local font but always using the remote one. But you mention the issue with the serif font, not the fixed width font, so maybe it's a similar issue with that font?
We have both microservices and CLI tools written in Rust at Faraday.io. &gt; Did you use any special cargo configurations to enable optimized builds? No, just `--release`. &gt; Do you vendor your dependencies or rely directly on crates.io? We rely on crates.io and `Cargo.lock`. This works reasonably in practice. &gt; How do you run unit/integration tests? `cargo test` on our CI server during regular builds. Sometimes we use Docker containers to mock out third-party services. We've recently started relying heavily on the `pact_consumer` crate for API mocking. Pact is awesome. :-) &gt; Do you use clippy or any other lints? We use clippy on a lot of our projects, but usually only when a developer feels like installing nightly Rust and passing `--features clippy`. &gt; How have you been able to profile your code? Standard Linux profiling tools for C/C++ work great. I've also used `cachegrind` and `kcachegrind` quite happily. &gt; Anything else you feel is worth mentioning... Our critical crates are `error-chain` and `log` which we use to get detailed error messages, full backtraces, and fully-tunable logging in production. Overall, Rust is pretty great. There are sometimes rough edges in terms of library support, and some of my coworkers have occasionally called it "intense" to program in Rust. But everybody loves using our in-house Rust tools, and our Rust code is extremely reliable and fast.
Doubtful. I am truly horrendous. Like, I still don't know how to make it not be in emacs mode when you open a diff file.
Not actually using Rust at my job but here's some info: &gt; Did you use any special cargo configurations to enable optimized builds? `cargo build --release` and passing `target-cpu=native` as appropriate gets you 90% of the way there. &gt; How do you run unit/integration tests? This is just `cargo test` &gt; How have you been able to profile your code? Rust outputs native code &amp; debug symbols for your platform so whatever tools you would use to profile C/C++, you can probably use them as well. I've personally used Instruments.app (part of the xcode toolchain) on macOS to profile Rust code and it works very well. I've also used something from the Windows Development Kit, WPT (I think it's called) to profile Rust code on Windows. &gt; I can also easily benchmark You probably want `cargo bench` &gt; coverage profiles I've seen a number of blog posts about this but I don't have any first hand experience. Generally I don't find code coverage numbers to be very useful. 
I've put Rust into production at two different companies so I'll share what I've done. These were all server-side components in fairly busy distributed architectures. (one in Kubernetes, one not) It is by no means "correct" way, but it's worked for me. * Special cargo configurations : If anything at all, it was [profile.release] lto = true but quite frankly these services have gotten nowhere near maxxing out the peak single-thread performance or running into latency issues, so it might be worth deploying a debug build, just to have a nice backtrace/core-dump if something goes wrong. * Vendoring dependencies I'd say it was about 30% of crates we used required some customization or fixes that we hosted in a private git repo until they could get PR'd. Because we rely heavily on gitlab for CI/CD (see below) we made heavy use of submodules rather than trying to get cargo to work with ssh agents. * Testing Cargo test inside of gitlab-ci pipelines. We'd break it up so that unit tests ran by default with `cargo test`. Then we'd annotate integration tests with `#[ignore]` so in the case of a push to master, we'd set up a mini dev environment in docker containers and then run `cargo test -- --ignored` * Clippy / Linting Most of us used a rustfmt related tool (vim or Intellij) - clippy and other such tools were used, but linting was not enforced (hasn't been a problem so far) * Profiling Haven't needed to so far (for production code). There are copious tools for profiling, benchmarking and perf analysis in Rust, so I highly doubt this would be a problem. Last I checked some of the services that we first put into production have an uptime of just about a year. In my completely objective, unbiased opinion. Rust's runtime/production stability has absolutely lived up to its hype. Pain points : * Configuration management / baselining services. In order to deploy in modern systems, a common idiom is to take configuration params from defaults, config files, environment vars, and command line params in increasing order of priority. While there are tools to do all of these things, we've not yet found a good way to create a "base" set of libraries that work with the configuration. One that could automatically connect to all necessary services in its distributed system. This is a bit of an advanced feature, and only becomes relevant when you've got a half dozen or more services.. * Mocking - Testing against custom components pretty much requires you to create traits for everything so that you can impl mock versions of them for testing. This gets old. I know there are crates to help derive impls of traits for the purpose of mocking, but that solves only part of the hassle. For this reason, we rarely mock IO based systems, and instead just isolate the business logic from the IO lib. We test the business logic in unit tests, and test the IO lib in integration tests. 
‚ô• I would love to see some blog posts or even articles on Gamasutra about Rust in game dev (when you have time). I'm especially curious about more details of your ECS implementation and any challenges you had. I'm currently finishing a software engineering degree and whenever I've had free time I've worked on a hobby engine in Rust. I found the ECS style system was the most efficient and easiest way to replace OOP (as you say in another reply I think). But I've also found that some patterns from "Game Programming Patterns" weren't too hard to apply in Rust either with a bit of adjustment - I've not attempted all though.
It can't be upstreamed- the modifications are all just new files that are parallel to (and very similar to) the ones for existing platforms. They could be shared with other console developers relatively easily, though. If the console vendors got to the point where they wanted to support Rust directly, they could even distribute their own libstd.
It wouldn't help much anyway for anyone without the SDKs, and it would cost Chucklefish their license if it ever got traced back to them.
hey buddy, I'm a computer scientist student and passionate for computer graphics. Writing my own engine with Vulkan. Maybe we can do something together. What u think? contact: me@luizotav.io / github.com/Luiz0tavio
Thanks for your answers :) I did look at the links, but my issue seems different. And sorry for not providing more information. I've put up a screenshot at https://imgur.com/a/lOSbI, this is on linux. I'm not sure how to check which font is actually used. I can inspect the elements, but the tabs "Rules" and "Fonts" do not agree about the font used. I can find neither of those in the file system anyways (shoud be /usr/share/fonts, right?).
Try [horrorshow-rs](https://github.com/Stebalien/horrorshow-rs). It's extremely performant as well. Though I'm not sure it can be taken seriously as you have to re-compile at least parts of your application to change the template.
Floats aren't Ordered because (e.g.) NaN is a float, but `3.0 &gt; NaN` and `3.0 &lt; NaN` and `3.0 == NaN` are all false. If the compiler had a way to know that none of your floats were NaN (or infinity), you could sort a list of floats (but it doesn't, so you can't).
&gt; Did you use any special cargo configurations to enable optimized builds? No - Do you vendor your dependencies or rely directly on crates.io? Just crates.io &gt; How do you run unit/integration tests? For unit/component tests, just `cargo test`, for integration tests it varies, but typically would run in the test suite of the client, running against a running server. All of the dependencies of our application (database connection, extermal APIs, etc.) are encapsulated behind traits (and each method on those traits has a default "panic" implementation), and then we have a single "create_app()" function, to which we pass in implementations for all these dependencies. For the component tests, we can simply pass in mock objects to the "create_app" function, which implement the subset of dependency trait methods required for the particular set of tests. This allows us to test "full" execution paths through the application without a complex or fragile test environment. &gt; Do you use clippy or any other lints? Just compiler messages via RLS so far. &gt; How have you been able to profile your code? The rust code has never been a bottleneck, so haven't had to. &gt; Anything else you feel is worth mentioning... We build a fully statically linked musl binary, meaning we can run our rust programs in the "scratch" docker image. This results in sizes of 1-5mb for the entire docker image, uncompressed. Deploys are super fast which makes a huge difference, as any slowness gets magnified when doing rolling deploys across a cluster.
Or, if you use L√ñVE, you can have the 3 layers be Lua :D
Yeah, it's not a very well-known crate. Even when I was deliberately googling for it (I forgot the name) I couldn't find it. I had to go look in the cargo.toml file of a project where I've used it before. But yeah it's a great crate. More people should know about it.
&gt; how does this code ensure that the same block of memory buf is reused on each successive pass through the loop It doesn't, although the compiler likely makes it use the same space, which is fine. I guess there is a possible performance penalty of zeroing buf each iteration (since Rust doesn't like uninitialized memory, which requires unsafe). Otherwise, it is a temporary buffer used in that iteration, so persisting contents isn't necessary. Moving the let statement out of that block (or using `std::mem::uninitialized` might have a small performance increase, but it doesn't matter much for IO bound code like this. And arguably the narrower scope makes the code slightly clearly because it is obvious that the value of `buf` from the previous iteration is not relevant.
&gt; ... will just let you know what I constantly screw up. The way you write that sounds awfully negative. I *wrote* a good part of clippy and I use it a lot, still get warnings on my code. I take it as a sign of humanity. Isn't it great that we can have clippy tell us where we'd use code that can be improved?
Thanks for the response. Am I correct it saying that you authored this program?
Same. I have consistently had cases where a lint _I wrote_ told me how to improve a piece of code I'm writing. It's very nice when computer programs have your back. Also clippy itself has CI ensuring that it emits zero clippy warnings with ALL warnings turned on (not just the default ones) and it's the WORST. I have no idea how we actually get stuff done.
So I did some code-spelunking: https://doc.rust-lang.org/rand/src/rand/rand_impls.rs.html#114 Ends up using https://doc.rust-lang.org/rand/src/rand/lib.rs.html#386 Which just bit-casts a `u64` (While keeping the sign and exponent fixed) to get a random number in `[1,2)`, then substracts 1. This might fit your requirements?
Funny that this comes up. I have actually been thinking about this for months now. I think that after const generics land, Rust will become a fantastic language for fixed point math. I am actually planning to write a crate for generic Q-format fixed-point math, that implements a fixed point type that is generic over both the backing integer type in memory (u32/u64/etc) and the number of bits of precision for the fractional part as a const generic. The idea is to allow the flexibility to compatibly use different precisions for different things if desired and possibly even mix and match them in arithmetic operations. It should be a zero-cost abstraction that is very performant (except maybe division and sqrt/trigonometry) and [almost?] just as easy and ergonomic to use as floats. I was envisioning uses specifically in gamedev and embedded, actually. For gamedev, I've been curious for a long time to experiment with what it would be like to try to write a game engine that works entirely with fixed point math on the cpu (so, except shader/gpu stuff and interfacing with vulkan/opengl). For embedded, many microcontrollers and other small processors do not have hardware floating point units, meaning that floating point is *SLOW*; fixed-point math would perform much better there. I've toyed briefly with both of the above applications, but not having a nice way to abstract away the fact that it's fixed point, it was not very convenient. Especially in C on a microcontroller, as in C you cannot overload operators, so you have to manually write shifts for every multiplication. I am really looking forward to const generics so that I can finally write this abstraction that I've been dreaming of. The generic-ness over the precision and being able to easily use and mix fixed-point numbers of varying precisions with the same type is something I really look forward to be able to do and abstract away.
While this is not games, I have similar experience with Firefox's C++ code. Most memory bugs are ones you write when prototyping and catch immediately (or catch by running the testsuite). Except that _one_ bug that takes you a week to track down. That bug's the worst. I think the larger impact of this isn't really measured however. It forces you to split up your work defensively into chunks that are easier to debug should stuff go wrong. This doesn't necessarily mean logical chunks of changes like the ones you split as commits, just ordering them such that you limit where stuff can go wrong. This becomes a major pain. A large refactoring I was doing in the summer took me around 3 weeks because of this, and I had multiple of those "takes forever to track down" memory safety bugs even after carefully structuring my changes. I had initially estimated that it would take 3-4 days; with a day or two for the gruntwork and then a day or two for tracking down bugs and stuff. This would certainly have been true for pure Rust. 
What's the best way to get into docker and all that devops stuff?
&gt; I tried to implement this actually with specialization, but failed at it and just manually implemented it for the builtin types. Uh-oh, I had always thought I could plug that usability hole that way. But trying right now, I can't get it to compile either. I hope that's just a bug or a limitation of the current implementation as I don't understand how `impl T where T: Ord` is not clearly more generic than `impl f32`. Seems like it doesn't deal well with coherence in combination with specialization, given that it's not actually important whether `f32: Ord` or `f32: !Ord`. Not so sure about the blanket `impl &amp;T where T: OrdSubset` though. 
Reading through this thread, my first thought was that something like this must exist, or be achievable without herculean effort, given that overflow checking is only done in debug builds. To my mind, a well designed system where you've put effort into making sure there *shouldn't* be NaN or Inf floats is similar to a well designed system where you've put effort into making sure there *shouldn't* be overflow of ints. Debug warnings aren't *ideal*, but they let you get past what's a hard problem to handle perfectly.
That libstd repo's a bit old. The one we've been using instead is [here](https://github.com/rust3ds/ctru-rs/tree/master/ctr-std) Reminds me that I need to go through and update stuff again since nightly changes almost certainly broke stuff by now.
&gt; I think the larger impact of this isn't really measured however. Totally agreed. Stuff like Chrome using obscene amounts of memory and time copying `std::string` all over the place where Rust would just use `&amp;str`. It's not just that Rust makes it easier to write correct code- it makes it easier to write *fast* code.
We don't build on the production server and the libc is always a nightmare... So we build with musl and set the right target-cpu (westmere in our case). Also I think we don't strip symbols. 
A "uniform" distributions on floats almost always refers to a (essentially) rounding the output of a true real-number uniform distribution to a float, including in `rand`. A distribution that has a uniform chance of giving any particular float would be some sort of truncated and quantised geometric distribution, and I can't think of how/if it would ever be useful (maybe in quickcheck and similar testing frameworks, I guess?).
I want to add another anecdotal story here. It's not exactly fair, but I think it's illustrative to the extent you trust my oversimplification. At one point during development I refactored spellbound's engine to finally run systems in parallel. I didn't do absolutely everything correctly, there were some logic bugs with systems that I didn't order correctly etc. I still had to write some extra code to ensure that component / resource locking would not deadlock with other systems without having to pay super close attention to the lock order, and this was pretty much expected. But, with those caveats out of the way, it more or less *worked on the first try*.
No pressure. Would love to see an elm/haskell/ml-style scripting lang become more mainstream. Need to get nice types to more folks! &lt;3
You might have more luck setting up traits with associated types so that you can write `V::ConversionFactor`. Or you might not. But that's usually the best way to represent a "function" from `V` to another type.
I'm a contributor. I didn't write that loop, but I did modify to use the pbr crate for the progress bar, so I'm familiar with this code.
&gt; this is now the top post of all time in /r/rust, so that's awesome! you even beat out the Rust 1.0 announcement :P I am *unreasonably* proud of this :D Though, it probably doesn't deserve to beat out the rust 1.0 announcement!
It does make sense that this post beat the Rust 1.0 announcement. Simply, more people have heard of Rust now than when 1.0 was announced, so more people are voting on this post. Also, thank you for this amazing AMA, the awesomeness is part of the reason this is post #1! :)
Have you also had to fork any of the other crates you've been using due to underlying platform differences, or has modifying `libc` and `libstd` generally been sufficient for them to work?
Once you take care of libc, libstd, and rand, everything else falls into place pretty much. There are some caveats here though, we have to depend on the 'rand' crate without default features, because iirc one of the features pulled in rustc_serialize, and I would have had to modify that one as well. This may actually no longer be true with the new version of num, I have to check that out. There's a very useful tool called "cargo-tree" that helps track down transitive dependencies if they're giving you problems. 'rlua' has a special option just for us, which is to allow you to substitute your own Lua static lib instead of the inbuilt one, and we definitely have to use that because Lua itself also requires patching. One extra crate I might have to add to the patched crate set is 'num_cpus', if we end up using rayon for internal parallelism. This will probably mostly be important for world processing that happens occasionally with a loading screen, like during day transitions. That one should be pretty easy though.
I wish I had a better answer for this... For Docker, I kind of just blundered through it while reading the documentation and some blog posts until I got it working. "All that devops stuff" still no real clue as I really just wanted dev environments with minimal fuss. I have yet to work on something that deployed with containers.
Dost doesn't really exist. It was used as a proxy in the talk for languages like Rust, D, etc.
Part of my issue is that I was trying to setup a trait containing associated types that were not parameterized on `V`. See [this struct](https://github.com/iliekturtles/uom/blob/d1feb934d2a5805f45ea2246874926a54a35f830/src/system.rs#L200) where the `D` and `V` end up being repeated as parameters of `U`. I was hoping to avoid the repetition, but I may need to restore the `V` parameter for `U`. Thanks for the comments, I'll do some more experimentation.
You should dive in more, [there's a lot of great non-default lints, built-in and in clippy](https://github.com/diesel-rs/diesel/blob/98d0e989756202259cf62e61661716f7cf0b453d/diesel/src/lib.rs#L16-L30)
[to bits, you say...](https://www.youtube.com/watch?v=gHhOn2hnqmI)
No need for a SQLite database? I'd love to find out that y'all were using Diesel. This thread was fascinating to read, thank you so much for sharing!
It makes a ton of sense that you'd end up at Rust if you were doing a lot with Haskell IMO. For me, Rust is the Haskell I've always wanted.
[But doesn't Haskell have it in Ord?](https://3.bp.blogspot.com/-a2YE8-XFVLw/VHFNjP_cCAI/AAAAAAAAIfc/4KyWz7hdTFA/s400/haskell_type_class_hierarchy.png) 
&gt; we are targeting a minimum of OpenGL 3.3 I'm so jealous... Web/mobile is the worst.
You should be super proud :D You're one of the trail blazers, lighting up the path for others to follow.
Not at the moment. There are other priorities - self hosting, for example.
it took 6 years to get ownership? super interesting. that is almost the defining feature of Rust for me.
Awesome! You might be interested in contributing to derive_builder; you can make the fields public there to do something similar to this.
Yeah the history of it all is neat Steve Klabnik goes into it more in his talk [here](https://youtu.be/79PSagCD_AY) that's worth a watch!
Does [Tera's global functions](https://github.com/Keats/tera/blob/ed04d368403389522b001723d6c17c5c9f3cc8af/docs/content/docs/templates.md#global-functions) get close enough to what you want?
Take my slides with a grain of salt. A lot of these features and syntaxes, especially in the early years, may have only ever been envisioned, never actually implemented. And even though they showcase ownership syntax from 2012, that doesn't mean that ownership (perhaps in a weaker, less pervasive form) doesn't date from earlier. Furthermore this isn't a comprehensive review of the language from that period, only a disorganized expedition; I really wanted to find some examples of argument modes (one of which *was* "take ownership of this value", but applied to values rather than types) but they eluded me.
then why do you suggest that shit?
Thanks to /u/Grodion, I discovered the CHIP-8 CPU/VM. I have implemented an emulator in Rust and am working to integrate it into _Rust in Action_'s chapter on data. Hopefully readers will get to learn what a pointer is/what functions are from the bottom up. They'll follow the example along and then come to a paragraph that says, "oh, and that number is what everyone means when they use the word pointer"
Rust was _very_ different in the past. I wasn't exactly around for this, but Rust's core ideas are relatively new (within Rust that is; they're overall not new ideas) See https://manishearth.github.io/blog/2017/03/18/inhtpinhtpamaa/ Basically, in late 2012, [Niko wrote about interesting ideas about aliasing](http://smallcultfollowing.com/babysteps/blog/2012/11/18/imagine-never-hearing-the-phrase-aliasable/). And then Rust got the aliasing system it has today (ish). A few months later pcwalton and perhaps others realized you could write code without needing a GC and just relying on this stuff, and this started the gradual push towards the current model of Rust. (The GC itself got removed from user code in mid-to-late 2014, and all vestiges of it were ripped out in late 2014 or early 2015) 
Still working [on my Gameboy emulator](https://github.com/simon-whitehead/chemboy). This week I'm learning Conrod so I can get some UI work happening. Specifically, I want a visual debugger of sorts to help me find bugs in the emulator quicker and so I've been fiddling with Conrod to see how far I get with it. Its coming together... here is a progress GIF of a "theme switcher" `DropDownList` which lets you switch between color schemes: https://user-images.githubusercontent.com/2499070/31981720-c0db24ec-b9a0-11e7-9993-528bad3ecc3f.gif This is just me fiddling with Conrod. Now that I've got it working I'll begin making it look a lot nicer then move on to the actual debugger.
You've had that account for a year and that's your first comment? Dope.
Just in case someone doesn't know: If you have a nightly, you can do `cargo clippy` to lint your code without any source modification.
Great Question!!!
Who spit into your soup? Seriously calm down, I've never seen a reaction like this in the Rust community.
I don't know if this will make you feel better about Rust, worse about NaN or both, but sorting a vector of floats in C++ *is* undefined behavior (assuming you use a standard comparison operator, which violates strict weak ordering for floats). What's more, several different STL implementations, particularly libc++ but probably others, use this as an excuse to do out-of-bounds reads *and* writes for your array. They may do it in good faith (as in, the logic of the algorithm happens to assume strict weak ordering, and results in OOB access when that breaks), but the actual result is memory safety violation the moment you put a NaN into a vector. It has caused several crashes in our game which we had to work around by sanitizing NaN inputs to the comparator. Now, as a game developer, it's my professional opinion that this kind of behavior is ridiculous for std::sort (like many other kinds of UB), and also that we need a CPU flush-NaN-to-zero flag which will make much more sense in regular floating point code as seen in games compared to NaN poisoning, but the status quo is that sorting NaNs is really dangerous.
&gt; Did you use any special cargo configurations to enable optimized builds? I use `lto=true` (but, if you're using nightly, try thin-lto instead of the regular one), `CARGO_INCREMENTAL=1` for debug builds and sometimes `debug=true` (release build, but with debug info) to get the line number where the error happened in the stack trace. Without that you don't get the line number (only the file) which isn't very helpful. &gt; Do you vendor your dependencies or rely directly on crates.io? Usually the dependencies are generic enough that nobody can re-make the product without putting in a considerable amount of work. So what we do is to put binaries in a private repo and open-source the libraries. `crates.io` works fine so far, I haven't seen the need to vendor dependencies. &gt; How do you run unit/integration tests? Either CI (Travis / AppVeyor) or just running `cargo test` locally. Since the end result are desktop / CLI apps there are no docker images or such. Integration test do not exist, because there's nothing to integrate it into. Doc tests and unit tests are enough, usually. &gt; Do you use clippy or any other lints? Yes, with a custom set of lints, described [here](http://blog.faraday.io/good-strict-default-warnings-for-rust-code/). Also take a look at `rustfix`, which can automate some of the tedious work. &gt; How have you been able to profile your code? [Hotspot](https://github.com/KDAB/hotspot) is a nice tool for visually seeing what functions are worth optimizing. Usually I just run `perf`, load the result in hotspot (or perf itself) and look at what's worth optimizing. So far I haven't really had much things that I had to optimize because Rust runs fast enough.
My bad, I didn't notice the grandparent.
Okay, so I think I understand it now. You're absolutely correct, floats are NOT strictly weak ordered, they're missing *transitivity of comparability*, that's the part that I was not understanding correctly before. So, in summary, to be partially ordered you have to have irreflexivity, asymmetry, and transitivity, and then *once you add transitivity of comparability* you get to strict weak ordering. Do I have that basically right now? The counter-example is NaN, but specifically the violation would be that 0.0 is incomparable with NaN, and NaN is incomparable with 1.0, but 0.0 is comparable with 1.0. Okay, thanks for the education there, I'll go correct my other post about it. I think I got some bad explanations in the past, and I've never actually *seen* UB with NaNs in an array, but you've now made me *absolutely terrified* of it. You're right that I don't know what exactly to feel about all that. I feel better about rust I guess, but my god *at what cost*. That is massively surprising to me that you can have an accidental NaN lead to memory unsafety, TIL.
Wow, much more churn than I was expecting! We're there any features that were around from the beginning that are still recognizable?
&gt; bump the minimum LLVM to 3.9 &gt; LLVM 3.8 Release Notes &gt; With this release, the minimum Windows version required for running LLVM is Windows 7. Earlier versions, including Windows Vista and XP are no longer supported.
Yes: GHCi, version 7.8.3: http://www.haskell.org/ghc/ :? for help [‚Ä¶] Prelude&gt; let nan = acos(2) Prelude&gt; (3.0 &gt; nan, 3.0 &lt; nan, 3.0 == nan) (False,False,False) every language which implements standard IEEE 754 floats suffers from this issue.
I think the general opinion is that that splitting up libstd is a good thing, we just need someone to finally do it. We even had someone submitting a huge patch, which we couldn't merge as it was so huge and fuzzy that it wasn't reviewable...
I have the idea the same with you. But wasm now doesn't support DOM manipulation, so now it is not easy and effective to build a spreadsheet using Rust and wasm.
Never heard about "Video Game Crash of 1984" but sounds convincing. Reminds me the modern state of software development where the jobs market is flooded by those who absolutely don't match that profession but "hey, they can run Python script copypasted from Github -- why not give them a job?!" Years ago people said that programming is a profession of future but today they only need coders make their grocery store website.
`impl Trait` doesn't have anything to do with dynamic typing. It just hides the name of the type, it doesn't let you use multiple types in that position. If you want dynamic dispatch, use `Box&lt;Trader&gt;`.
This is quite an unhelpful error, you might want to file a bug about that.
I believe rustc already doesn‚Äôt run on less than Windows 7. std still does (as a [Tier 3 platform](https://forge.rust-lang.org/platform-support.html#tier-3)), so binaries that you compile should work on XP.
The reason for bump is that LLVM 3.7 and 3.8 (versions previously supported but now unsupported) started to miscompile rustc. They already miscompiled rustup ([#36023](https://github.com/rust-lang/rust/issues/36023)). It was really just luck that bootstrap succeeded till now, but luck ran out.
Sure it's possible, however outside of scripting I doubt the performance of the language is the issue here. Most of the performance issues will be around the DOM, and interacting with the DOM efficiently. Currently with web assembly the performance may actually be a tad worse. This is because whilst there are DOM APIs for web assembly, they all interact indirectly.
rustup run +nightly....
Two questions: * How would you handle files in multipart? Would you have to implement your own middleware to store these in a temp location? * How would you handle a streaming proxy ala [shio-rs](https://github.com/mehcode/shio-rs/blob/master/examples/proxy/src/main.rs)? 
&gt; Our compile times in C++ were atrocious, even after applying a decent amount of effort to it, so that's a LOW bar to hit. That being said, it's mostly better in rust, but I think depending on how large our project gets it might flip over. We started compiling profile.dev with opt-level = 1 so that we could keep using dev by default, we recently set codegen-units to 8 on dev and test (but maybe that's the default now?), I started using CARGO_INCREMENTAL=1 a long time ago, and my counterparts were really really happy when that got fixed for windows. &gt; &gt; These things together mean it's MOSTLY livable, but it's just livable not great. And, we had stockholm syndrome from C++ anyway, so we weren't that picky to begin with. I don't know what your CI setup looks like exactly, but earlier this year I added support for caching Rust compilation to [sccache](https://github.com/mozilla/sccache/) and we're using it in Firefox automation. It helps a lot if you have ephemeral build machines that wind up building the same crates over and over. It's not quite as effective for local development unless you find yourself doing builds from scratch fairly often.
Hi, thanks for your reply. I wasn't aware that there is /r/rust_gamedev, I'll probably post there in the future. Thanks for your book recommendations, the first one (Real-Time Rendering) sounds most relevant to me from a quick look at what's covered, but it's still a bit longer than I hoped, my problem with such big books is that I usually end up not reading them thoroughly because at some point I start skipping text but I guess I'll give it a try since they have it in the library. I guess the main reason I'm slightly reluctant going with one of the existing engines is that I mostly just need a rendering engine (plus some minor prediction but I guess here performance really matters most, and to be honest I can postpone that for now). I will probably pick either Piston or Amethyst, for now Piston is convincing me more with its very modular approach but I will probably have to try out both of them.
It isn't that useful, because I understand it would need new silicon to be efficient, but I saw a talk about Posits recently and they sounded interesting. See https://www.reddit.com/r/programming/comments/62hu4c/beyond_floating_point_an_implementation_of_john/
For the Rust (rls) extension there's a settings key to choose the toolchain (`rust-client.channel`). I'm not sure about the other extension (`vscode-rust`).
The problem is WASM can't use the DOM API yet, so you need to use JavaScript to do this, unless you use the canvas api to reproduce text components
I think the actual license notice distribution bit is still manual, unfortunately. (Software licensing is hard!) The file that winds up as about:license in Firefox [lives here](https://dxr.mozilla.org/mozilla-central/source/toolkit/content/license.html), and [we did update it](https://bugzilla.mozilla.org/show_bug.cgi?id=1375292) when we pulled in all the new crates from Servo for the Firefox Quantum work, but I don't think any of that was automated.
I love it to_bits :p
&gt; I think that generally devs come in two flavors, the printf kind and the debugger kind, and I might be the printf kind. I do occasionally use debuggers, and gdb seems to do the job well enough. Something I'm really excited about though is rust debugging working inside the visual studio debugger. I remember one of the other Chucklefishes almost had it working the other day, and it seemed pretty close to being usable, and that's really really cool. The Rust folks have done a really great job of both caring about the debugging experience and also considering Windows as a first-class platform (which is pretty rare among open source projects). Debugging Rust code in Visual Studio works really well (probably not quite as well as GDB, where they've been actively submitting patches). Rust 1.21 actually just [shipped a change to embed natvis files for libstd types](https://github.com/rust-lang/rust/pull/43221) into the generated PDB files, which should make debugging in MSVC a bit nicer if you use rustc to link your binaries. (If not, the natvis files are shipped with the compiler and should still be easily usable.)
Webassembly is actually not that fast compared to Js is it ?
Man, I think you really have to stop expecting to get everything on a silver platter, verbally abusing people who suggested you solutions that only cover 99% of your use-case, and creating new accounts to hide your history of this behavior. Back on-topic... There probably is no such thing library for Rust. See, Ruby and Rust give you very different reflection capabilities. Implementing something like this (calling a function with unknown argument types at runtime) in Rust would probably mean either reusing or reimplementing Rust's type checking in the templating language, and all that stuff. Ruby and other dnyamic languages are very different: as everything is an `object`, you can just pass a bunch of objects into the function and hope it does not blow up with a runtime exception.
More importantly, computer graphics is one of the most math-intensive fields in programming, especially linear algebra. You'll have to study that as well if you're not familiar with it.
Huh, now I feel old. @ pointers still feel like a fairly recent removal...
ahahahaahahahaahahahaahahaha
some man did.
it's designed to be substantially faster, but the implantations right now may be a little lacking.
I'm fine with linear algebra (coming from using numerical methods a lot), just haven't used it in practice with computer graphics APIs yet.
It will probably only be faster if canvas is used to render the spreadsheet instead of the DOM.
[removed]
It's perhaps worth noting that there was plenty of prior work on lifetimes and borrow checking before Cyclone too. Work on region inference and region-based memory management starting in the 80s capture a very closely-related idea (albeit with a narrower goal in mind). You can think of unique pointers as single-sized regions. The common example from this line is the Tofte-Talpin region inference work: http://www.irisa.fr/prive/talpin/papers/popl94.pdf
Are you using serde for serialization? Could you upstream your serde SBE implementation ?There is an issue in serde's repo about SBE that you could fix with this!
It seems like haven't been into Rust pre-1.0 unless you gave at least one "Rust History" talk. (Mine was "Rust is all that's left") These are parts I almost don't know, though :). Thanks for giving it! One thing that teased me about Rust when I joined back in 2013 was the willingness to experiment with things, but also aggressively throw ideas away. The road to 1.0 was definitely paved by removing things from the language, not adding!
/u/bjzaba posted about [gluon](https://github.com/gluon-lang/gluon/) elsewhere in this post but I'd like to just mention that 1 and 2 are things I have taken into account for [gluon's GC](https://github.com/gluon-lang/gluon/blob/767260c0ba3f5d4d7c2214a0816375ae635934c1/vm/src/gc.rs#L130-L161) as it is intended for the same niche as Lua. I can't say whether it pans out yet but the idea is that each green thread has their own associated GC + heap and threads can only share data from parent threads. The theory is that heap intensive ephemeral operations can be relegated to child threads with relatively small heaps while more permanent objects can would be in threads higher in the tree which. Thus one would have more control over what and when scans take place. It would even be possible to run operations without any heap scanning at all as long as the thread has a sufficiently large allocation limit for the operation and the thread (with all its allocations) could then be freed in its entirety afterwards. Haven't gotten around to vetting the idea or tried to find some prior art of this yet though as there are still more important problems to fix in the project!
`rustup run nightly cargo clippy` &lt;3
came here to say that! Do all the rendering inside web assembly to solve DOM performance issue. You might still have to use javascript to handle user input though.
FYI to people reading: there are pure canvas and webgl based UIs :)
I'm pretty sure it was possible to use Windows Vista during Rust 1.0.
* here is [multipart example](https://github.com/actix/actix-web/blob/master/examples/multipart/src/main.rs). you get stream of `Field`'s or nested `Multipart` object, then each field is stream of bytes. saving bytes to file should be easy. * handling streaming request is easy as well, `Payload` object is stream of bytes as well, so you can handle it with stream combinators or actix hander. I will add example for strumming request. Actix handler is similar to example in this post, except it works with `PayloadItem` instead of `ws::Message`
For anyone interested in a chat, I'll be staffing the Rust table in the Open Innovation area at MozFest.
It's good that rust took a stand. Perhaps they will come up with a reasonable solution everyone else can adopt. 
It might have been possible but not supported.
I am using the same thing, I had to disable eldoc because it makes emacs hang sometimes and some completions are terrible slow, especially methods on `Vec`.
&gt; If GC has any place in game dev beyond smaller projects, it's as a specialized tool that can be applied with precision- not a global allocator that anyone can use at any time. I have to take issue with this. UDK, Unity, and UE4 all use GC heavily, and as a matter of course in their gameplay implementations. I believe, but do not know for sure, that most other major game engines do so as well. Your points are well taken, but I don't think your conclusion here is supportable on the facts. "Be careful with how you use GCed objects", and maybe even "GC has no place in your render pipeline" I could agree with, but GC as a concept certainly belongs in gamedev, and I would argue belongs there more the larger your project is. This is doubly true if you aren't using a language like Rust, which makes handling complicated lifetimes at least possible to get right in a way that, say, C++ can't. 
I can speak to my two experiences in getting Rust code into production at Mozilla: sccache and the Rust code that's shipping in Firefox. sccache is a standalone build tool, so its development process looks like a standard Rust/Cargo workflow. I have Travis CI / Appveyor jobs configured on the GitHub repo and they build it and run tests. For deployment I was originally just building statically-linked binaries on my development machines and then publishing them in our content store for our CI machines to download and use, but we've since added a feature to our CI where it will build prerequisite tools as part of the task graph, so now sccache binaries get built as needed, and we can just [update the git revision in a script](https://dxr.mozilla.org/mozilla-central/source/taskcluster/scripts/misc/build-sccache.sh) to get binaries from a newer version. We do standard --release builds, we don't vendor dependencies (Mozilla runs the crates.io infra anyway...). I haven't done any serious profiling of sccache, but [acrichto did some a while back](https://github.com/mozilla/sccache/issues/108), I think he just used `perf` on Linux. I do have `[profile.release] debug=true` in Cargo.toml for ease of debugging/profiling, although the downside there is that anyone doing `cargo install sccache` winds up with really large binaries on Linux. I haven't tried out clippy yet. One thing that I do wish the Rust ecosystem had was a good setup for integration tests for commandline tools. Python's [cram](https://bitheap.org/cram/) (originally from Mercurial's test suite) is really nice, and cargo has a bunch of home-grown code for running those types of tests, but there's nothing on crates.io that I've found that's comparable. For Firefox, we obviously have a lot of weird requirements. We're vendoring all our dependencies into the Firefox repo using [cargo-vendor](https://github.com/alexcrichton/cargo-vendor/). We build with [very specific cargo profiles](https://dxr.mozilla.org/mozilla-central/rev/a124f4901430f6db74cfc7fe3b07957a1c691b40/toolkit/library/rust/Cargo.toml#34) including `panic=abort`. Our release builds are built with lto, but we have it disabled by default even for optimized Firefox builds because it makes build times so much slower. (Our release builds in CI are PGO on most platforms anyway so they're already pretty slow.) We didn't actually have a good story for Rust-specific tests in Firefox until recently. We're now running `cargo test` for specific crates of ours as a separate build job in automation. (It takes too much time to rebuild them in the test configuration as part of a normal build, and we don't like running tests in build jobs nowadays because if they fail and you want to re-run them it's nicer if you don't have to rebuild all of Firefox the second time.) I don't think we have clippy hooked up to any of the Rust code in Firefox itself, but a lot of the code comes from the Servo repo and I know they use it there, so we probably get some of that coverage for free. Firefox has built-in profiling tools and AFAIK they all work with Rust code (one of the benefits of Rust generating standard debug info). We do also have code coverage builds of Firefox that don't currently work with Rust code because they use gcov. One of my colleagues added support for that to Rust [but it's awaiting stabilization](https://github.com/rust-lang/rust/issues/42524). If you have a pure-rust project then kcov works well for code coverage in my experience.
Thanks for taking a look. I believe this fits my requirements!
On my system (Arch Linux, Firefox Beta) the serif font also looks pretty crappy. And this wasn't always the case... https://tmp.dbrgn.ch/screenshots/20171025172849-12v4c1em.png Regarding urw fonts, it seems that on Arch these are contained by the `extra/gsfonts` package which is required by both evince and graphviz, so I can't uninstall them.
just wanted to say, my template engine could do this easily, but seems like OP is ignoring my post...
Ooh, this is new to me, thanks for the pointer!
Those examples only serve to prove my points. Unreal (including, I presume, UDK which I'm much less familiar with) only runs GC on `UObject`s. This excludes the vast majority of garbage that is generated in languages where GC is ubiquitous. It also has Unreal-specific behavior and optimizations baked into it beyond anything you could reasonably put into a general purpose language (i.e. Nim)- object clustering, *actor* clustering, network replication, etc. Unity only uses GC in user-written scripts, never in the engine. This is much like the situation in Spellbound with Lua, though I suspect significantly more code is goes into the "user-written" bucket in Unity as it's a general purpose engine. This limits the sorts of games Unity gets used for, and is a large burden on everyone near those limits. So yes, as I said, GC's place in (larger-scale) game dev is as a specialized tool to be used with precision, and not a ubiquitous language-level feature like it is in Nim.
`cargo +nightly clippy` &lt;3 &lt;3 &lt;3
&gt; Tiled Are you talking about https://sourceforge.net/projects/tiled/ ?
Building a spreadsheet involves, 1) Data model - Code to manipulate and manage run time data represnentation of the spread sheet 2) Layout engine - Code to calculate and manage position, size of cell-grids of visible sheet range and other layout elements based on browser screen size 3) Rendering UI - Code to render visual elements that represent grid-cells and its values (based on data model and layout details) and other visual elements. It is possible to leverage Web assembly to code data model and layout engine, rendering of UI elements needs to be handled by DOM/WebGL/Canvas. Rendering UI elements using WebGL/Canvas involves considerable effort as one has to write code to implement styling (Bold, italic, underline), font rendering, copy&amp;paste etc. PS: Have ported a excel engine (ethercalc) to mobile devices - https://github.com/selvan/calc-engine and wrote a react-native based UI layer for viewing specified sheet ranges &amp; calculations - https://medium.com/@morsetree/expose-excel-calculations-within-mobile-apps-and-get-analytics-on-calculation-interaction-662a5b54fc2f 
The [ordermap](https://crates.io/crates/ordermap) crate provides the same functionality as linked-hash-map with better performance.
stupid question: what UB stands for?
Yep, that's it!. It's really really great, but we use it with a good number of hacks since it's not game specific, and we want to move to a more friendly integrated tool. I would still 100% recommend it though.
It's possible to render at native quality in a canvas, for far greater speed than DOM manipulation. [Example](https://medium.com/@evanwallace/easy-scalable-text-rendering-on-the-gpu-c3f4d782c5ac).
Undefined Behaviour
[Undefined Behavior](https://en.wikipedia.org/wiki/Undefined_behavior)
Thanks, this is worth knowing about, particularly as linked-hash-map is mostly inactive. However, the order mangling `remove` limitation isn't an ideal fit for an order preserving set. Having `swap_remove` *and* a `remove` that preserved order would be great. I'll try to keep an eye on this crate for that.
Note that the official Rust binaries already use LLVM 4.0. This minimum LLVM version only matters if you're building rustc yourself, with your own external build of LLVM.
The problem is Cargo is its own build system, so either Meson does nothing but tell `cargo` to do something and maybe we can use the result or Meson reimplements Cargo. Both options suck.
One of the reasons it is slower is because it allocates a node per bucket. Instead it should store the node inline inside the bucket. To do this some API must be added to the standard HashMap so that bucket transfers can relink the buckets. This can be a lot faster than what it is now.
I understand what you're saying, and from what you say here I think we might even agree - GC in support of your gameplay systems is common if not quite universal, and generally works fine. If you're building an engine, you almost certainly can't afford to use GC as part of your render loop. This isn't any different in gamedev than it is in any other performance sensitive code, though. The question would be if it's easier and more ergonomic to use a GC language in general, and use an escape hatch for things like your physics and render loops, or use a non-GC language generally and build your gameplay system out of something else. I don't think I agree that there's a clear answer to this question - it seems very similar to unsafe vs safe by default in the Rust vs C++ debate, for example. "This technique has downsides, and you will need to be prepared to handle them" is a very different statement than "GC has no place in gamedev". As far as I know, unless you get a source license, you can't write non-GC code if you're using Unity. This is certainly a black mark against it and it certainly limits what you can do with the engine. I think it's a pretty far cry to go from there to "You can't make anything but small games in Unity", though.
What exactly happened to the contain-rs project? It seemed like a really good idea.
i think the most fundamental feature that is still around today is structs being value types, rather than boxed automatically like objects in many other languages.
The talk was great. A fun dive into a strange language most of us had never met before! One of these days, we'll get set up to actually record talks.
Working on a little task coordination service at work. The thing itself is not open-source, but two public things fell out of it: a [posix_mq](https://github.com/aprilabank/posix_mq.rs) create for using the Linux kernel's message queues (see `man mq_overview`) and a [CLI tool](https://github.com/aprilabank/mq-cli) for some rudimentary queue administration.
You can hit 60fps with canvas
Almost got me with "elm" given that it's also a programming language! But you're in the wrong sub. Try /r/playrust
I see you forgot about the handy-dandy [`ok_or` function](https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or). I also had a few minutes, and didn't like the idea of holding the entirety of both files in memory at once, so I ~~butchered~~ modified your program [a bit](https://gist.github.com/Measter/2d2c639f32dec94e045a6022652d40ad).
I wrote doc examples for all the combinators to get more familiar with them, and then I still forget, heh! Looks great, thanks!
About to enter the final comment period? [This comment](https://github.com/rust-lang/rust/issues/32838#issuecomment-339046242) was posted less than 48 hours ago: &gt; Haven't really caught up with this thread, but I am *dead set* against stabilizing anything yet. We've not made progress implementing the the hard problems yet
And it probably shouldn't be supported going forward since [Windows Vista has been out of extended support by Microsoft since April this year](https://support.microsoft.com/en-us/help/13853/windows-lifecycle-fact-sheet). There's no sense supporting a product that the manufacturer doesn't support. However, accepting patches to make it work on old systems seems fine, but it should never be officially supported by the project.
My original post was an attempt to address precisely that tradeoff- I think the answer is pretty clear. Using a GC language with escape hatches is the wrong default because it means there's no easy way to control where the GC is used. Using a non-GC language with opt-in GC leads to GC being used only when it's truly beneficial. Further, to the extent that UE4 and Unity do overuse GC, they limit themselves. I don't know how well this part of my argument got across, but engines that use more purpose-built memory management techniques are *more ergonomic than GC* in the end, when you need to factor in workarounds and late-stage modifications. And to be clear, I have never said "GC has no place in gamedev" or "you can't make anything but small games in Unity." I *do* claim that GC has no place in engines and that there are always better alternatives to GC in games from an end-product perspective. :)
whoops my bad 
This has been [reported](https://github.com/rust-lang/cargo/issues/3494) to cargo -- apparently there is no workaround :(
What's the goal? To have equations as objects that can be manipulated, or just to be able to defer computing an expression? If the latter, you can just `|x: f64| 2.0 * x + 3.5` and call it later?
The real code should be using `csv` crate. That an unreachable usability for C++. PS: current Rust code doesn't look expressive for me...
Serde was used for the json portion of the comparison, but not for the other codecs compared (including SBE). I'm afraid the only way to get SBE-for-Rust code generation support right now is to use the main simple-binary-encoding tool to generate Rust code from an SBE schema XML.
&gt; PS: current Rust code doesn't look expressive for me... I don't find the C++ winner that expressive either, personally.
&gt; The real code should be using csv crate. Yup, I wanted to compare with something more "real", but have been super busy lately.
The former, but once created they'd be immutable.
Nope, you need Google. https://github.com/sebcrozet/nalgebra
I still use duolinguo to learn the language.
This is for ODEs though
This is backed by LAPACK, good luck if you need something else.
Rust is eminently suitable for games programming. It is systems programming after all. The benefits I see from it are that any bugs that happen are identified far quicker, by the compiler or at runtime than they'd ever be in C++. In addition, Rust's multithreading is very robust meaning no chance of data races. I haven't written a game in Rust yet (although I have in other languages). But I am writing a complex client / server specification. I'm 10 months in and no code I've written in Rust has ever crashed. The only crash in all that time was an unsafe call out from Rust into OpenSSL with a parameter it didn't like. Now I should say that doesn't mean my code is perfect. Rust kicks my ass up and down the road during compilation and has panicked plenty of times. The net result is bugs get caught more quickly, either before the code even compiles, or soon after. I'd be very keen to play around with games programming in Rust. Yeah it's probably less mature and many of the libs you'd have to call would be implemented in C. But it's still a great way to improve stability without sacrificing performance. I imagine that supporting games is a pain in the ass like any other software. The less time fixing dumb bugs caused by NPEs is more time to spend implementing new features.
Ok, then here's my recommendation: - Make a `struct` for `Var(label)`, `Const(value)` and one for each operation you need to support. - Implement `std::ops::Mul` and others for each of those structs (which just returns the appropriate struct, with the provided contents). - Then make them implement a `Eval` trait with `eval(context)` method, where `context` has bindings from labels to value.
Would it not be simpler to use a enum instead of two structs? Then you can sidestep the entire trait as well.
Well that sucks :/ Hopefully I won't come to a point where this feature is required.
I don't know how much this will help, but you might be interested in a small project I published a few months ago - [ketree](https://github.com/Wulfsta/ketree).
[Rocket](https://github.com/SergioBenitez/Rocket) seems to be the most popular right now. [Iron](https://github.com/iron/iron) is what I've used and am partial to. I think "ready for production" is kind of subjective. Could you use it in production? Yes, definitely, people do already. Is it going to be as easy as something like Ruby/Rails for general web development? Probably not. FWIW I built out an API in Rust using Iron and I thought it was pretty straightforward. I had a better time doing that than using Python/Flask.
Good point. Which one you use largely depends on how you want extensibility to work. Given the OP's requirements an enum would work better.
&gt;But in parsing a math function the only way I can think to create a Rust function to match the mathematical behavior is to use a bunch of composed functions I think a better approach would be to use Rust's types to make a syntax tree for expressions. It shouldn't be too hard, though you'll need boxed data types. 
&gt; Could you clarify the scope of your problem? I need to go from: let system = r#" dy1/dt = -.04 * y1 + 1.e4 * y2 * y3 dy2/dt = .04 * y1 - 1.e4 * y2 * y3 - 3.e7 * y2 * y2 dy3/dt = 3.e7 * y2 * y2 "; to: fn system(y: Vec&lt;f64) -&gt; Vec&lt;f64&gt; { let dy = vec![0f64; y.len()]; dy[0] = -.04 * y[0] + 1.e4 * y[1] * y [2]; dy[1] = .04 * y[0] - 1.e4 * y[1] * y[2] - 3.e7 * y[1] * y [1]; dy[2] = 3.e7 * y[1] * y[1]; return dy; } This is so that I can interface with an ODE solver.
Are you sure that's what you need? I would be surprised if your ODE solver took a function as an argument, especially in Rust. 
Of all the rust web frameworks there are at the moment, I've enjoyed using [`rouille`](https://github.com/tomaka/rouille) the most. `Rocket` is really wonderful, but if I'm introducing something at work I don't want to deal with pinning to nightlies or giving off the impression that stable rust isn't "good enough". I used to use `Iron` for everything, but I've found `rouille` to just be more ergonomic. With `rouille` you don't have to deal with things like `IronResult`. You can just use `error-chain`, have handlers that return a regular old `Result&lt;Response&gt;`, and then match on any errors to return an appropriate http-response.
It's a C library.
There's a PR for that, but it'd have linear complexity. Don't know what /u/neutralinostar 's plans for that are
It will enter the final comment period if all the members of the lang and libs teams sign off on it; that's tracked by the checkboxes in this comment: https://github.com/rust-lang/rust/issues/32838#issuecomment-336980230 , which doesn't include Ericson2314.
Would be great if `HashMap` could be added to this cheatsheet.
Can I see the specialization code that you were using? I'm interested in opening an issue to make sure it's known to the devs.
Wow, props to the rust team for starting with a segfault and working towards the conclusion that LLVM had a bug. That sounds like it would be a really frustrating debug process.
I wanted to see if I could get rid of the temporary allocations while still being "expressive". Also got rid of the panics and here's what I've got: https://gist.github.com/cristicbz/716ae2db680054f083edd0b271bac0cb 
Huh okay. Which one, if I may ask? To my understanding, Rust doesn't actually allow you to define functions whose return value is a function (I may be wrong there). As such, I'd advise writing a macro if this is what you'd want.
I love colored. Been used by it in all my cli‚Äôs at work. 
&gt; I implemented From for everything so I could use ?, but then main just has a ton of unwraps. I normally would remove those too, but the challenge does not include good error handling, so I decided to just stick to the text of the challenge. I'm hopeful that https://github.com/rust-lang/rust/issues/43301 will materialize during the impl period to ameliorate this, though I don't know whether the person who's currently claimed it has much time for it right now...
Awesome, this is the first I'm hearing of this. Is it weird that my initial favorable reaction is based solely on not having an underscore in the name? :P
&gt; **Don't get too excited** Don't tell me how to feel, /u/nikomatsakis!
Here's a [minimal example](https://play.rust-lang.org/?gist=17c7980eb0ee644127a82f2456d8c1f9&amp;version=nightly) [with the actual functions](https://play.rust-lang.org/?gist=79ceb964ac11a63b9d2cce93a3506bba&amp;version=nightly). 
I think the best option would be to have a specific way to import crates and have Cargo have rustc just build just object files and import those as "normal old object files".
One of the main strengths of Rust is how effortlessly you can install third party libraries (/crates) and solve a problem at hand. Your solution does not even use that weapon and yet, it's more expressive. Nice! The mere fact that C++17 doesn't have ranges (and hence, splitters) puts it under disadvantage. 
SUNDIALS. It's possible if you Box the closure: https://godbolt.org/g/6cWdQd
&gt; But if you pass -Znll, you only get an error from the AST borrowck, demonstrating that the integration succeeds So... will the code still fail to compile because of the AST borrowck? Is there a way to test compiling code only using the NLL borrowck? But, seriously, I can't wait for NLL.
I [tackled one of the calls for participation](https://github.com/bluss/arrayvec/pull/78) this week. It was good practice getting involved in a larger Rust project! Thanks for the weekly updates.
Rouille if you aren't willing to go nightly, rocket otherwise
Thanks, I've filed it: https://github.com/rust-lang/rust/issues/45542
Firefox still supports Windows XP, doesn't it? Mozilla needs Rust to work there as well then.
[It looks like that's ending in June](https://blog.mozilla.org/futurereleases/2017/10/04/firefox-support-for-windows-xp-and-vista/) when [Firefox ESR 52 goes EOL](https://www.mozilla.org/en-US/firefox/organizations/faq/). AFAIK, Firefox 52 didn't have any Rust in it, so it's a non issue.
Yeah I have wanted this FOREVER
This looks great, thanks!
Ooooh yaya. One step closer to getting rid of horrors like: fn instantiate_at(&amp;mut self, level: u32, src: &amp;Type&lt;N&gt;) { // Bleh: Running into non-lexical liftetime problems here! // Just so you know that I'm not going completely insane.... // FIXME: ensure that expressions are not bound at the same level *self = match *self { Type::Var(Var::Bound(ref i)) =&gt; if *i == level { src.clone() } else { return; }, Type::Var(Var::Free(_)) | Type::Const(_) =&gt; return, Type::Arrow(ref mut lhs_ty, ref mut rhs_ty) =&gt; { lhs_ty.instantiate_at(level, src); rhs_ty.instantiate_at(level, src); return; } ...
Inlining will mean your "bad" example almost certainly is equivalent to the optimal code you write. In any case, the memory overhead of calling a function is very small.
Thanks so much for having me. :)
i'm sure there's some code in boost or whatever for that 
Rust definitely lets you define functions whose return value is a function, e.g. see [this](https://play.rust-lang.org/?gist=1adcb12bc660584024a19cec3703d9d4&amp;version=stable).
https://play.rust-lang.org/?gist=a69229cb1bf320d0f55da21222747343&amp;version=stable Line 4 gives errors, how would I fix these?
This sounds great! Are you using Rust Nightly? If so, what unstable features do you rely on?
https://play.rust-lang.org/?gist=c403895ac509058c8cd2545479724504&amp;version=stable Borrowck doesn't like this, but I don't understand why. To me, it looks as though the buffer is borrowed immutably twice and should be safe, but rustc seems to think there's an overlap between the implicit mutable borrow of buffer.take_5() and the immutable borrow for buffer.get_position(). What am I missing, and how might I fix this?
https://github.com/sappworks/sapper is perfect too.
[Here's a screenshot](https://imgur.com/a/c4Di3) of a work in progress TodoMvc port for Indigo. As part of open sourcing the project I'd like to have a few example applications. This required implementing drop shadow support, fleshing out text layout some more, fixing bugs in the scrolling code, and fixing some invalidation bugs. Its still not exactly where I want it and I still lack an input control, but we'll see how far I get :) 
You could have a look at existing embedded languages like LUA: good VMs/JIT already exist for it, usually providing better performance than you would get with a simple interpreter.
Where do I see the roadmap for NLL? It seems like bits and pieces of it are being developed in different RFCs, PRs etc. and I don't know where to look to see what nightly will have a working NLL.
ODE?
I just released my first program. It's a temperature converter. [Give it a try!](https://github.com/gkeegan/temp-converter)
Ordinary Differential Equations.
If computer math was perfect, you could get any distribution by sampling a uniform distribution (0,1) and applying the inverse CDF. Computer math is not perfectly precise, however. At locations where the slope of the CDF is near zero, the slope of the iCDF will be large and imprecision of the input sample will be amplified. Any long-tail distribution has this property. To properly sample it, your code must know when to get more random bits. For that reason I think you should be thinking this algorithm through at a deeper level. Fixed precision random floats seem not good enough at first glance. If you have a proof, by all means continue, but if not be careful. You never know who will reuse your code and get you an honorable mention in a CVE.
I think it depends on what your definition of, and requirements for, "production" are. At my last job, I managed to get a Rocket service running in production. We were a small startup so we were relatively flexible with technology, but I was confident that since it produced compiled binaries (and was written in Rust) that I could confidently start the server and just forget about it. As far as I know, it's probably still being used and running fine. I've also written a smaller *technically* in-production service in Iron, but Rocket has been my preferred so far, even if it requires staying up to date with nightlies. To be honest, without having done any research, I'd assume most (popular) Rust web frameworks are pretty much on par with each other in terms of production-readiness; many have been widely used, but I don't know if any have received the scale of use and abuse that some may consider a prerequisite for "production". I'd say go with whatever you think will be easy to update, to maintain, etc‚Äîin my case, I really liked that Rocket's syntax seemed intuitive enough that I assumed someone new to Rust could at least comprehend the logic, as I was the only dev who had experience in it. 
The mutable borrow has the same lifetime as the returned reference. NLL isn't going to change that. When you return a lifetime-limited value from a method it means that the method starts some business that isn't really finished until the lifetime expires. Calling that method starts a transaction. `take` methods typically give ownership. Likely the problem here is that you're lending it - but this is a design issue so I don't have enough information to say for sure what the design should be. You could also `peek_5` and `seek_forward_5` as separate operations.
Yes this is correct, transitivity of incomparability (or lack thereof) is the problem. Here's one example of this happening in practice: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=41448. Note specifically that the crash happens *in the vector destructor* - this is because sort went outside of the vector bounds and corrupted the heap metadata around the allocated block. These aren't just out of bound reads, these are writes that can trigger crashes *after* the sort is done, and most likely are exploitable.
There's [only one RFC](https://github.com/rust-lang/rfcs/pull/2094), and there is a bunch of work being done in pull requests. https://github.com/rust-lang/rust/issues/44928 is the tracking issue. Follow that.
Right, ordermap doesn't have the same functionality. Some of it is the same, some is not 
How would it look with NLL?
Build your equation as a struct containing one or more ASTs with an 'eval' method and pass that method to your solver.
 fn instantiate_at(&amp;mut self, level: u32, src: &amp;Type&lt;N&gt;) { match *self { Type::Var(Var::Bound(ref i)) =&gt; if *i == level { self = src.clone(); }, Type::Var(Var::Free(_)) | Type::Const(_) =&gt; {}, Type::Arrow(ref mut lhs_ty, ref mut rhs_ty) =&gt; { lhs_ty.instantiate_at(level, src); rhs_ty.instantiate_at(level, src); } ... Not sure if I'd need to pop in a `drop(i);` before the assignment of `self` though‚Ä¶
LAPACK does not have any routines for solving systems of differential equations.
Add kelvin support maybe?
And if you just need a simple http server, tiny_http which rouille is based on is great.
Sure but compare installing boost vs installing any Rust library. I can't count how many hours of my life I've wasted trying to install recent boost versions on Travis-ci to test C++ code.
As a newbie, could someone provide a before and after if this gets merged? What kind of differences can we expect to see?
https://github.com/rust-lang/rfcs/blob/master/text/2094-nll.md
Often I can't believe how fast Rust is moving. NLL and async are super interesting (I wish async was generalized to more effects though). Excited!
Can someone tell me what's the behavior of { let _ = some_droppable_struct; // do some other stuff } Will `some_droppable_struct` be dropped when it is assigned to `_` or when `_` reaches the end of the scope (reaches `}`)? If it will be dropped when `_` reaches `}`, what will happen if we introduce another assignment { let _ = some_droppable_struct; let _ = 1; } And what will happen if we use a varialbe name { let a_var = some_droppable_struct; // do some other stuff } And will non-lexical lifetime have effect on any of those behaviours?
There [is this RFC](https://github.com/rust-lang/rfcs/pull/1787) but it sadly got postponed...
&gt; I wish async was generalized to more effects though What do you mean by more effects? Can you elaborate on this?
Also super excited about this. I heard for some people this isn't a big deal, but for me introducing right drift via curly blocks (to open a new scope) just to satisfy the borrow checker in a perfectly valid program was really a bummer. Now I understand this probably won't solve all issues regarding the borrow checker, but I do hope it will improve the situation a lot!
Thanks, subscribed. (it doesn't include the current PR yet though)
The async stuff is just a set of macros on top of coroutines, so there's nothing preventing doing the same thing with other effects.
This should be using `write_all` (or `write!`, but that probably has its own performance issues) instead of `write`, I feel like. Unfortunately, `write` method is a trap that has a shorter method name.
The symbol `_` is not like other variable names; it explicitly means that you want to ignore the value and drop it immediately. So in your examples, `some_droppable_struct` will be dropped immediately when it's bound to `_`, but not when it's bound to `a_var`. `_` can also be bound several times in one pattern, such as: let (_, a, _) = some_tuple_to_deconstruct; This will drop the first and third fields in the tuple. Doing this with a name other than `_` is an error. The symbol `..` has a similar purpose in struct patterns: let SomeStruct { a, .. } = some_struct_to_deconstruct; This will drop everything but the `a` in the struct. 
Ah yes, I knew that and still forgot, thanks! I updated the gist.
Usually boost is packaged by the Linux distribution. If you use a non-default compiler version you might have to compile it yourself though.
If I remember correctly, while Firefox 52 did not have Stylo or WebRender, the MP4 and a URL parser were already in Rust.
I think a canvas solution we be bad though. You'd end up rebuilding your own UI, ground up, with all the existing native UI behaviour. Might as well just get the browser to do all that.
Maybe you can add a link to their implementation (plus the `write_all` fix) to your blog post :)
Following it lets you know when it gets finished, actual progress is something you have to find out some other way.
Thanks a lot. Can you explain the 3rd scenario as well? Where a droppable struct is assigned to a variable but that variable isn‚Äôt used afterwards. In other words, will a value be dropped right after its last appearance, or right before the end of its scope?
Wait, whoa, this is news to me (and I've been doing C++ for years!). I knew that comparing floats by itself isn't UB; I wasn't aware the standard allowed vectors to exhibit UB when sorted.
Exit codes on errors would also be nice or is that handled somewhere I can't see.
Oh no, it seems you accidentally missed out on the opportunity to [go insane with iterators and combinators](https://gist.github.com/Thiez/b3fa48fb0fac2a273ea1f56cc0fd692b)! If javascript taught me anything it's that there is no problem that cannot be solved when you add enough closures.
It will always be dropped at the end of the scope, at the `}`, regardless of when it is actually used. If you have several variables, they will be dropped in the opposite order that they were bound. (The idea that a variable be dropped as soon as it is no longer used is called *eager drop*, and it was decided fairly early on in Rust's life that this is both confusing and not particularly useful.) 
I'm guessing they mean console IO, networking, communicating to a graphics card, panicking, etc. Could allow you to statically enforce and document what effects certain parts of a program can and can't do. See Purescript's, Ocaml, Koka, Idris and F*'s effect systems for examples. Some allow you to intercept the effects with custom 'handlers'. This allows for some kind of 'aspect oriented programming', and can fill the role of mocks. 
Yeah, I'm planning on updating the post today with stuff from this thread :)
This is awesome!
https://en.wikipedia.org/wiki/Effect_system
**Effect system** In computing, an effect system is a formal system which describes the computational effects of computer programs, such as side effects. An effect system can be used to provide a compile-time check of the possible effects of the program. The effect system extends the notion of type to have an "effect" component, which comprises an effect kind and a region. The effect kind describes what is being done, and the region describes with what it is being done. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
As a workaround, can you have two features? E.g., default = ["std"] std = [] std_serde = ["serde/std"]
I didn't think of this. I imagine `std_serde` should probably also enable `std`?
Yeah good point.
I would look into implementing the `From` and `Display` traits on each of the available units. IE: `From&lt;Fahrenheit&gt;`, `From&lt;Celsius&gt;`, `From&lt;Kelvin&gt;`. You can create your types with the struct keyword so that you can use type-checking and implement traits on them, like so: ``` struct Fahrenheit(f64); struct Celsius(f64); struct Kelvin(f64); ```
&gt; I actually built quite a lot of a 2d game engine in Haskell first, before deciding against it for various reasons, and I feel like I wasted a lot of time Could you release what you ended up with at least? We were still waiting, and this is the first we've heard that you scrapped it.
It's not really a framework, but I came to like hyper::server and costum code behind it a lot.
Will NLL be limited to plain references or also include !Drop custom types?
At work (Faraday.io), we're used `iron` in the past, with `rustless` for APIs. But I feel like this stack is getting a bit outdated‚Äîthe last time I looked, some of the pieces depended on much older versions of `hyper` and `openssl`. For a forthcoming production project with a small HTTP API, we're using `shio`. Basically, it's extremely simple to set up, and it works in either sync or async mode. But we have the luxury of picking something simple, because we're only going to have maybe 5 routes. So if we change our minds in the future, it will be trivial to replace `shio` in this project.
Writing a [liberty-file](https://people.eecs.berkeley.edu/~alanmi/publications/other/liberty07_03.pdf) (PDF link) parser. If you're not familiar with liberty files, they're kinda like JSON, both in structure and in how everybody has a slightly-different take on the spec. They're mostly used by electronics design tools. I'm building it as a streaming zero-copy pull parser, which is raising all sorts of borrowck headaches 
It looks like you're right! [Firefox shipped a Rust component in version 48](http://news.softpedia.com/news/mozilla-will-ship-its-first-rust-component-in-firefox-48-506251.shtml). I'm guessing that have a frozen compiler that still works on XP/Vista, or perhaps binaries compiled on 7 and later still work on XP/Vista.
Does anyone have a link to the c++ entries?
I'd like something akin to ?, let's say ¬ø where it will unwrap on ok but an error is an outright panic. let bytes_written = write_to_file(&amp;data)¬ø;
The current state of the program only converts F -&gt; C. https://github.com/gkeegan/temp-converter/blob/master/main.rs#L16
 let filename = args.next().unwrap(); let column_name = args.next().unwrap(); let replacement = args.next().unwrap(); let output_filename = args.next().unwrap(); I feel like this is maybe a missed opportunity to use `expect()` to provide zero-effort, meaningful error messages to the end user, like "CSV file path missing" or something. Obviously, `expect` produces error messages that aren't exactly *nice*, but I think it would be an improvement!
Looks nice! The one comment I have is that when you check the number of arguments, you don't actually stop the execution of the program, so it'll have an index out-of-range error shortly thereafter.
Yeah, thank you for tackling this challenge and writing it up, and I understand about being busy! One big advantage of using `csv`, however, is correctness. Here's a test case for some really basic stuff: ```csv name,address,comment J. Smith, "New York, NY","Goes by ""JS"" online." ``` CSV is a surprisingly complicated format, with multiple official standards. (And worse, a large fraction real-world CSV files are actually corrupt.) u/BurntSushi has done an _amazing_ job with `csv`. I wonder how many of the "expressive" C++ implementations would pass basic test cases. I don't think there's any advantage to being able to write elegant-looking incorrect solutions. The real test is how nice the _correct_ solutions are. :-) Rust knocks CSV out of the park, maybe better than any other language I've ever used. But that's because of Cargo.
Wanted to give it a shot. Not much new here but just alternative style. use std::env; use std::error::Error; use std::fs::File; use std::io::{BufReader, BufWriter, BufRead, Write}; type Result = ::std::result::Result&lt;(), Box&lt;Error&gt;&gt;; fn main() { match read_arguments_and_process_file() { Err(e) =&gt; eprintln!("Error: {:?}", e.description()), Ok(()) =&gt; println!("Finished succesfully!") }; } fn read_arguments_and_process_file() -&gt; Result { let mut args = env::args(); match (args.next(), args.next(), args.next(), args.next(), args.next()) { (_filename, Some(file_in), Some(column_name), Some(replacement_string), Some(file_out)) =&gt; process_file(file_in, file_out, column_name, replacement_string), _ =&gt; Err(err_str("Error parsing command line.")) } } fn process_file(file_in : String, file_out : String, column_str : String, replacement_string : String) -&gt; Result { let mut input_lines = { let f = File::open(&amp;file_in)?; let reader = BufReader::new(f); reader.lines() }; let mut writer = { let f = File::create(&amp;file_out)?; BufWriter::new(f) }; let header_line = input_lines.next().unwrap().unwrap(); let (column_index, _) = header_line .split(',') .enumerate() .find(|&amp;(_i,column)| column.trim() == column_str) .ok_or(err_str("column name doesn‚Äôt exist in the input file"))?; writer.write(header_line.as_bytes())?; writer.write(b"\n")?; for line in input_lines { writer.write(line? .split(',') .enumerate() .map(|(i,line)| if i == column_index { replacement_string.clone() } else { line.to_string() } ) .collect::&lt;Vec&lt;_&gt;&gt;() .join(", ") .as_bytes())?; writer.write(b"\n")?; } Ok(()) } fn err_str(err : &amp;str) -&gt; Box&lt;Error&gt; { From::from(err) } 
You did read it correctly, I didn't actually run the program before creating the gist, apart from checking that it compiled. This oversight can be fixed with a single early `return`, or putting everything after the `if` in an `else`. Apart from that it seems to handle all the error cases correctly.
I'm curious why you had to effectively write a bunch of C for a 2d game. Even if you wanted to use `Ptr`s to avoid GC (if you weren't aware, anything you shove into a `Ptr` in Haskell is outside your working set and so has no effect on GC pause times) there are plenty of ways of quickly returning to idiomatic Haskell style coding pretty quickly. Granted, it takes quite a while to really get comfortable with the language and how to think in it coming from other paradigms.
I know only using std is part of the challenge. If someone is looking for crates that could make this more concise, though, I'd [suggest](https://deterministic.space/rust-cli-tips.html) looking at: - structopt for arg parsing, - csv for, well, csv parsing, - and error-chain for not writing the From impls.
Thank you for the kind words and for your participation in the impl period.
Oops. Guess I need to change that to a 1.
I'm pretty sure it never was *really* possible to *use* Vista during any period. Sorry, I'll see myself out.
If `i` is a `u32` why are you getting a reference to the value in the struct when you can just copy it out? 
that's the behavior of unwrap in general: let bytes_written = write_to_file(&amp;data).unwrap(); it's nice that "proper" error handling can actually be shorter and more visually appealing than the lazy way in Rust, since it encourages developing robust software.
https://www.fluentcpp.com/2017/10/23/results-expressive-cpp17-coding-challenge/
It's not customary to also keep the generated binary in the repository.
I've been working on a [CLI bittorrent client](https://github.com/thiagopnts/raft) and its been really fun. It started mostly as an experiment with the current bencode decoding crates and now its a fun pet project
In the mean time, I've found that I can do this: $ rustup install stable-i686-pc-windows-gnu $ rustup default stable-i686-pc-windows-gnu $ cargo build This succeeds, but is pretty annoying 
Alternatively there are tools to (unsafely) generate some executable trampolines that could allow such a transform (libffi comes to mind).
Someone else can probably help you more, but I will say rather than changing your default toolchain, you can also do this: $ rustup run stable-i686-pc-windows-gnu cargo build
that will help me script it until I can get this figured out, thank you!
Duly note that the sole owner of the Iron crate has been missing in action for a long time, which means Iron has been dead for a long time.
Relevant tweet here: https://twitter.com/steveklabnik/status/920795144034676736
But it is better... in this case, at least. [I know which one I would rather see.](https://i.imgur.com/0QFhqws.png)
If it's a `u32` I agree with you, but maybe it just has an `Eq&lt;u32&gt;` for convenience? Or has a `Deref` to something which does?
Yes, I explicitly asked the authors of the challenge if we had to support `"` in fields, and they said we did not. I agree 1000% that for a real thing, /u/burntsushi has got your back, and with amazing libraries.
panic will return a 101 status code
Right so, later in the thread I pointed out my perspective here; I'm on Windows, and often working in debug, so I have great backtraces. That means that expect is more work for no gain for me. Obviously, if either of those things are false, then the equation changes. Part of why I made such a strong statement was to figure out what important bits of perspective I was missing.
Does Rust have a way of generating a warning if a function on a struct isn't called? I've got some code which writes data to a file using something like: let mut x = Thing::new(); x.write_data("foo"); // can be called any number of times x.write_data("bar"); let bytes_written = x.write_footer(); // must always be called when done writing data If the footer isn't written, then the file on disk isn't valid. My current solution is to track whether the footer has been written, and check for it using `Drop` trait (deleting the partially written file then panicking), but wanted to see if it was possible to move that error to compile rather than runtime. 
Agreed! Thanks for making the time to meet with us.
There's #[must_use], but I'm not sure if it's stable
Nope, wasn't handled, but it is now. 
Ah fair point. Either way, that situation comes up often enough that I'm excited for NLL
But my code didn't panic anymore, so I added explicit process exits just now
Thing have a builder that only returns Thing when you call the function you want called? 
I haven't tried it but I would do something like this: fn closure_to_ptr&lt;A, R, F: FnMut(A) -&gt; R&gt;(f: &amp;mut F) -&gt; (unsafe extern "C" fn(A, *mut ()) -&gt; R, *mut ()) { unsafe extern "C" fn cf&lt;A, R, F: FnMut(A) -&gt; R&gt;(arg: A, data: *mut ()) -&gt; R { let f = data as *mut F; (*f)(arg) } (cf::&lt;A, R, F&gt;, f as *mut F as *mut ()) } This function converts closure with a single argument into a function pointer and an additional data pointer that you need pass to that function. You must make sure that any calls to f are made only while closure is alive.
What happened to the plan of not merging any RFCs during the impl period?
A Rust unboxed closure is two things: an anonymous type that holds any closed-over data, and an implementation of the `Fn` trait(s) which consists of the actual body of the closure. On the C++ side, it looks like you've only made space for the function pointer part. If you left it that way, you could change the `paint` method to accept a `painter_callback` directly rather than a `F: Fn`, but your closures would not be able to use any context. Instead, you need to store two things- the closure data as well as the function pointer. /u/jkleo1's code shows how you can split them apart- then you just need to make sure the lifetimes work out. You can either modify `closure_to_ptr` to return a reference rather than a `*mut ()`, so that its lifetime will be tied to `f`, or you can box the `F` so that `Widget` can own it.
I'm getting: expected type `unsafe extern "C" fn(*mut ffi::qtc_painter)` found type `unsafe extern "C" fn(Painter, *mut ())` How can I translate`()` into a C type? Also, pointer to `Painter` should be extracted.
I doubt if I know enough about GPGPU or linear algebra to contribute (yet), but sounds like a cool project. 
I know that but it's still clutter in unit tests, main functions etc. And in elegant code challenges like here.
 $ cargo +stable-i686-pc-windows-gnu build should work aswell, see [Toolchain override shorthand](https://github.com/rust-lang-nursery/rustup.rs/#toolchain-override-shorthand).
That would be awesome! In fact I'd be all over that. 
I will certainly try to add Kelvin support to it! I have a way in mind to do it. What code should I change to stop rust from panicking? Would that be the .expect part?
I put the executable in there so if people don't want to generate for themselves, they wouldn't have to.
Can you provide a code example? It's hard for me to understand it yet.
I haven't worked in Windodws in a very long time - is there a significant difference between backtraces on Windows vs. Linux/Mac? I've found the latter (Mac) not to have very useful backtraces, although that's more of an issue for `assert` failures rather than `unwrap`s for my use case.
That's being fixed here, it was a bug in crates.io: https://github.com/iron/urlencoded/issues/68 But unless someone steps up to actually release things, I would recommend not using iron :/.
This is what [github releases](https://help.github.com/articles/about-releases/) are for! Versioned binaries can be associated with git releases through github - this will allow you to include a changelog with each binary upload as well, and allow users to download each binary per-version. Including it in the repository is... not very useful in comparison. It also bloats the repository's size - every time anyone clones your repository, they now necessarily need to download *every single binary you've ever included*, which will be much more than an otherwise pure-text repository would be.
How's this compare to existing embedded DBs, like RocksDB?
Not the author, but it is Rust so... We like Rust here right?
What do you mean by "modern"?
Ah, I see. I will remove the binary and fix some other things others have mentioned then upload the binary as a release. Thank you for your help!
No problem! With removing the binary, you may want to do a 'full removal', including removing it from git history. There's a section on 'removing objects' at https://git-scm.com/book/en/v2/Git-Internals-Maintenance-and-Data-Recovery#Removing-Objects that might cover this I think? It isn't strictly necessary, but if you don't, the binary will still be downloaded with each new clone of the repository and kept on every local disk in the git history store. 
I'll certainly add the struct parts to my code.
good intentions. you may want to check out github‚Äôs release feature https://help.github.com/articles/creating-releases/ and read https://opensource.com/life/16/8/how-manage-binary-blobs-git-part-7
&gt; Also gonna rewrite my portfolio page into a static website (with slime) so I can save 2.5usd on my vultr server (currently running on rocket) RemindMe! 30 days 
On the C side you need something like this: typedef void painter_callback(void*, painter*); painter_callback *paint; void *paint_data; paint(paint_data, painter); The `void*` points to the `F: Fn` itself, and the `painter_callback*` points to the wrapper function `cf` from /u/jkleo1's example.
Thanks, I'll try that. I can't express how helpful the rust community is!
I am very interested in a package like that. `arrayfire-rust` looks pretty great, and I've been thinking on working on something like this myself--though my GPU programming experience is very limited. (read: None)
Sounds very cool. My experience is using cuda (via theano) to run code on nvidia gpus, I've never had occasion to use OpenCL. How is the OpenCL experience with nvidia gpus? 
Because you handed `closure_to_ptr` a closure of type `F: Fn(Painter)`, it expects a `Painter`. You invented that type yourself on the Rust side, but you're trying to call the function from the C++ side. If you make `Painter` `#[repr(C)]` and construct one in C++, you can adjust the type of `painter_callback` to match.
Pretty good actually. Obviously Nvidia loves to push CUDA but they have good OpenCL support. 
Honestly arrayfire-rust makes it quite easy!
I taught myself OCaml (using Real World OCaml) after my second attempt at learning rust (shortly pre-1.0). I think it helped immensely when I came back to rust. It gave me a chance to get acquanted with some of the more ML-ish parts of the language separately from having to figure out ownership and the borrow-checker. 
Thanks for the interest! This has been a supportive comment section :)
The GPU part is actually relatively simple! And most of the linear algebra stuff can be studied from nalgebra
The author also maintains the most popular rust rocksdb binding: https://github.com/spacejam/rust-rocksdb
In that case, I'd love to at least take a look. Is the project on GitHub or anything yet? 
Currently it‚Äôs in a private project. Since this thread has gained some traction I‚Äôll probably look into making it public some time before Monday. I‚Äôll update this post by then when I make it public. 
That's good to hear! I'm looking forward to seeing your work so far if/when you share it.
Yeah so apparently Windows has had great backtraces, and Mac has had bad ones. Or at least, recently, I heard nightly gained good backtraces on nightly, so maybe some relief is coming. This is what I get: https://gist.github.com/steveklabnik/27ea712ae3477f8daeaa8d772b6b6de3
ah my bad, lost which thread this was in
It's been a while since I used Boost::Range, but the vast majority of Boost is header-only, so you can usually just vendor it.
Can rust run on 32bit system. The game is on sale and my friend wants to buy it but he has 32bit on his pc
There's a project to generate bindings for Qt. You can use that or look at the code for examples. https://www.vandenoever.info/blog/2017/09/04/rust_qt_binding_generator.html
Yeah, I'm already getting excited, seeing as this has been in discussion a long time! It'll be a while before it's stable, sure, but I'm still excited!
I'd be pretty interested in this, although like many others here my experience is largely with Cuda. I understand that OpenCL makes more sense from a support/porting perspective but I would also love to see a Vulkan linear algebra crate for Rust! Maybe that is something to look into in the future.
Alright, I've now written a small readme on how to get started on the page :)
This sounds cool! GPU-based computations are *very* useful for big data processing. Ideally, I would love a library that uses OpenCL/CUDA and fallbacks to alternative solutions when these are not supported (e.g. to regular shaders or CPU).
Sure, but its easier to understand things sometimes when compared to existing things.
So one of the nice thing about using arrayfire-rust is that it makes it very easy to have the same code run the CPU if, for whatever reason, it could not be run on the GPU.
I'll definitely update the thread over the next few days.
Yes please! I would love to play around with that on our cluster. &lt;3
Wait ... *you* were used by colored? :D
I would love to read a blog post that explains how it works under the hood.
I love the idea. I could use this to replace a bunch of weird ad-hoc solutions I've come up with for the same problem in a few programs of mine. Your code elegantly solves the problem.
I'd recommend reading [Beej's Guide to Network Programming](http://beej.us/guide/bgnet/) which is a great book (IMHO) as an introduction to POSIX sockets API. The concepts are directly applicable in Rust with `libc` crate and some `unsafe {}` blocks :) Secondly, study `select()`, `poll()` and other I/O multiplexers. These are how you handle multiple sockets in a single-threaded app. The guide mentions `select()` but I don't remember how detailed it is. Try to implement your own event loop on top of `poll()` (or some other multiplexer). It's not too hard, it takes about 200 lines of code (I've done it myself, I can show you the code if you want but I don't want to ruin the fun :). For extra credits, add timers and signal handlers to your event loop. Finally study `mio`, see what it does similar to your event loop and what it does differently. `futures` provides an API over thread pools and mio. It's still immature IMHO (programs tend to be really verbose and painful to write and even read), but it's the future of Rust async programming ;-) Study it after learning about event loops and `mio`, otherwise the API may not make much sense. Hope this helps. 
Sure, but Linux distributions don't typically upgrade tool chains for older distribution releases. If you are using Ubuntu LTS you might have a 4 year old distro or older, which means that you need to upgrade your tool chains in some other ways. Recompiling a C++ compiler, updating standard library, other libraries and keeping that up parallel to the ones of your Linux distro requires a lot of work. Rust takes zero work. I can have multiple versions, toolchains, use them with whatever library or project, crosscompile... all automatically and it all works.
OK. So this will teach me how to set up connections/sockets and send/receive arbitrary data over them? If that's the case, I presume that after I learn all of this, using HTTP or JSON-RPC would be just a matter of using the popular rust crates for http requests and json to generate the data to push through the sockets and to handle the responses.
&gt; futures provides an API over thread pools and mio. That's Tokio, not futures. Tokio is mio + futures.
Yes. I saw this, but I'm using Qt from Rust.
&gt; OK. So this will teach me how to set up connections/sockets and send/receive arbitrary data over them? Yes, and also teach you doing that over many sockets in a single threaded app. You'll understand `mio` and even `futures` design much better. &gt; If that's the case, I presume that after I learn all of this, using HTTP or JSON-RPC would be just a matter of using the popular rust crates for http requests and json to generate the data to push through the sockets and to handle the responses. You can use `reqwest` for blocking HTTP requests without knowing any of these, but if you want to understand async network programming in Rust in detail I recommend this path.
Sorry, I meant to talk about futures, not Tokio. Fixed now. 
Is there any reason you couldn't contribute GPU-related improvements to `nalgebra`? I feel like `nalgebra` is already a dependency for several projects, and I don't know if the Rust scientific computing community can support several crates with the same set of functionality. Plus, you'd have a built-in group of devs to look at your code, etc
That... did not answer the question
It is indeed! I'm [using it](https://docs.rs/duct/0.9.2/duct/struct.Expression.html).
&gt; Testing : Cargo test inside of gitlab-ci pipelines. We'd break it up so that unit tests ran by default with cargo test. Then we'd annotate integration tests with #[ignore] so in the case of a push to master, we'd set up a mini dev environment in docker containers and then run cargo test -- --ignored Why not `cargo test --lib` ? 
&gt; If you make Painter #[repr(C)] and construct one in C++, you can adjust the type of painter_callback to match. But C++ side doesn't know anything about rust. It can be done, afaik, only when I link C++ part statically. Then they can invoke each other. But I do not like this solution... And I don't want to make `Painter` C-like.
Yeah, I'd like to learn to understand what is going on, rather than use a ready-made super-high-level solution. Thank you!
noob here...but the exe file is around 230k.Quite big for a simple program.
I'd definitely be interested in using a project like this. Thumbs up.
Well I followed this thread a little and looked at [rouille](https://crates.io/rouille) but it didn't support [serde](https://crates.io/serde) so I've made a branch to try and support it at [cardoe/rouille:serde](https://github.com/cardoe/rouille/tree/serde). Any suggestions welcome. The author has been very receptive of some other small fixes I made today.
Take a look here at one of the callbacks in the GStreamer bindings, or also in gtk. For example: https://github.com/sdroege/gstreamer-rs/blob/a1a841afc809fcf9557928867d420caaee6e8f0d/gstreamer/src/bus.rs#L34 trampoline that is a C function and calls the Rust closure https://github.com/sdroege/gstreamer-rs/blob/a1a841afc809fcf9557928867d420caaee6e8f0d/gstreamer/src/bus.rs#L45 C function used as a callback for when the callback is not needed anymore. This frees the Rust closure https://github.com/sdroege/gstreamer-rs/blob/a1a841afc809fcf9557928867d420caaee6e8f0d/gstreamer/src/bus.rs#L52 Rust function that boxes the closure as a trait object and returns a normal C pointer https://github.com/sdroege/gstreamer-rs/blob/a1a841afc809fcf9557928867d420caaee6e8f0d/gstreamer/src/bus.rs#L84 Rust function for putting all the pieces safely together. It registers the callback in C Hope that helps, but feel free to ask if you have questions
So I have also thought about this. My only concern is that leveraging something like array-fire will require a fundamental change in the internal structure of a Matrix or Vector, and in addition imposes some differences on the API and how you would use the library. I agree there would be some benefits to merging into an existing project, and maybe someday that could happen, but for now I feel there is a large separation between the two libraries.
Well, `Painter` is already inherently a C++-side object underneath since it comes from Qt. You don't have to link the C++ part statically to make it work, either. Your only other option is to just pass the `*mut ffi::qtc_painter` directly like you do currently, and push `Painter` farther into the Rust side.
It's only 50ish lines of code so far... Not sure why it's so big. I'm gonna remove it from the repo and put it in releases
Rust tends to do that. I'm on mobile but there was an amazing blog post somewhere about why it is so large, and how to decrease it. It's mainly so that when it crashes, it doesn't simply output Segfault, but provides a meaningful traceback. Amd optimizations. A lot of them
Adding (actually, added!) support for generating Rust (Hyper) server and client code from Swagger.io/OpenAPI-specified API specifications. Type-safe cross service APIs FTW! https://www.metaswitch.com/the-switch/metaswitch-swagger-codegen-for-rust-accepted-upstream for more information.
&gt; When you return a lifetime-limited value from a method it means that the method starts some business that isn't really finished until the lifetime expires. That would seem to imply that every borrow lasts as long as the lifetime of the thing it borrows. But it doesn't: if you change the example from `let slice = buffer.take_5()` to `let _ = buffer.take_5()` then it passes the borrow checker -- which shows that the problem is not returning a "lifetime-limited value", whatever that means, it's that `take_5` returns a reference to a member of the `buffer` object, and as long as that reference is live, it counts as a borrow of the `buffer` object.
Most definitely! I'd likely make good use of it.
I'm dipping my toe into Rust by writing a library for different election methods, called Condorcet. It's a little tougher than I expected though; I'm not a CS major and I wish I had better intuitions about data structures (particularly HashMaps vs BTreeMaps). It's on Github though and I've made issues about my worries if anyone would be willing to spare me a thought. https://github.com/IohannesArnold/condorcet
Yeah expect is just like unwrap with added flavor text in the consle on panic. https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html
I like https://github.com/mehcode/shio-rs quite a bit. It's async, supports async/await syntax (on https://github.com/mehcode/shio-rs/tree/await this branch), and it uses async hyper. Plus the API is really simple.
Not sure how that helps. Even if you never call "write_footer" it will have still used "write_data", so the check will be satisfied too easily. Only if you combine this with a builder pattern (so each usage of write_data "creates a new copy" and thus must be consumed again will this work.
Post to GitHub ASAP!
I think panic stuff is not a huge part of the binary. Instead it's likely all of the statically linked libs, like jemalloc.
I tried to look through your code, but I really just don't understand what the ballot type is supposed to be. What do the numbers represent?
IIRC it wouldn't matter which one you used as far as the compiler is concerned. The nice part of using `Self::Item` is that it matches the definition in the trait (where `T` doesn't exist).
Hi everyone! Thank you for reading my blog post, hopefully it's informative and engaging. I'm a little new at this, the blog posts, open source programming, etc. I am always looking for feedback, so don't be hesitant to point out any mistakes or ambiguities :)
From the readme, I gather the architecture is optimised for SSD storage vs spinning media, enabling more energy efficient operation. 
Yeah, it's actually a `Named&lt;N, u32&gt;` struct, with an `Eq&lt;u32&gt;` impl.
Binaries produced by Rust/LLVM still run on XP, but you can't run the rustc compiler on XP/Vista. No problemo, what developer would want to use XP/Vista? üòÄ
RemindMe! 1 week
The Ballot type maps candidates to integers because most theoretical voting schemes (although regrettably a small minority of actual voting schemes) involve ranking voters, for example: Jane Doe 1 (best) John Doe 3 Bob Smith 2 And then various voting methods differ on how exactly a winner is supposed to be calculated from this information. Of course, this is not how most ballots look in most actual organizations, but those can be approximated by having one candidate get a value of 1 and everyone else getting 0.
Same! 
There's no difference at all to the compiler. The only difference is emphasis - whether you want to the code to emphases that it's returning one of "Self::Item" and that's related to the trait, or whether to emphasize the actual type.
Congrats! So many years and I still haven't published a single thing :(
Would it be possible to simply add a GPU accelerated implementation to the lapack crate?
&gt; "just not the kind of language Rust is." Agreed; 600 pages feels about right for Rust. Great news, really looking forward to this book!
FYI, I emailed O'Reilly yesterday and got the below response a few hours ago: "This book has faced many delays due to editorial updates and we don't at this time have a solid release date. At present it is thought that it will be pushed back later still even into January of next year. Sorry for any inconvenience this may cause you."
The oxen will never know what hit them.
I'd be interested in something like that, or a library similar to MAGMA where it has the GPU do certain operations and the CPU perform certain operations in tandem with each other.
Many of my coworkers are eagerly awaiting the release of your book. Is there any chance that O'Reilly will put the ebooks on sale again?
I'll definitely keep an eye on Pleco as I work on [Hexe]. While these projects have different goals, there's a lot to potentially learn from yours. I'm looking forward to working on the actual engine bits and comparing our design decisions. I previously worked on a chess library in Swift but I feel that Rust has more to offer in this area as far as performance goes, making it an excellent choice. [Hexe]: https://github.com/hexe-rs/Hexe
I heard an interesting story about EA clean room reverse engineering one of the early consoles (maybe Sega Genesis, can't recall) so that they could release games without needing to go through Sega, and thus not pay anything to release games on the hardware. I don't think they actually did that, but they used it as leverage in getting a better deal our of Sega. So part of the restrictiveness of dealing with console makers is to do with that. Also general not letting the competition know what you're up to.
Does this book include much in the way of best practices, or useful design patterns? I find it's easy to get the basics but need better guides for how to use Rust well.
There's been an increasing amount of Rust based chess engines lately! And it's very lovely to see, I think we can all learn a little from each other's implementations. Rust has really made this project much easier to create and reason with. Hexe seems like it's made very decent progress so far. I particularly admire your organization of files inside the project, its very concise and easy to follow. Pleco is currently lacking in project organization, and I think we might take some inspiration from Hexe. I'm curious as to where you take Hexe, it's got a strong base to build off of. I'll be following it as well. Give Pleco's files a look for some inspiration! Our `Board` implementation is especially well documented, and works great as well. 
So this version of Hexe is a rewrite of a previous closed-source version I wrote. By starting from "scratch", I was able to take advantage of the currently decoupled modules and focus on organization. Some other differences between Hexe and Pleco so far: - Unlike Pleco, Hexe uses tables that are defined at compile-time. Pleco makes use of `lazy_static` to generate its tables at runtime. - Naming convention: "Bitboard" vs "BitBoard" :P - Hexe is split into two crates where `hexe_core` defines the building blocks for `hexe`. Pleco is very opinionated compared to `hexe_core`. - This makes sense. `hexe` will be just as opinionated in its design and usage. - `hexe_core` is designed to be used to implement chess engines outside of Hexe itself. - `hexe_core` aims to be `#[no_std]`-compatible. 
I'd, personally, probably use this in a project. As long as it works without a GPU as well, then all is well :)
Any chance you could show a playground of your suggestion? I've been struggling a lot with methods and self borrows. Alternatively, is there a good resource on this specific subject? Conceptually I feel like I have an ok understanding of lifetimes and borrowing, but I'm having a hard time figuring out the best patterns for methods.
I think the idea is that no new RFCs will be considered after the start of the impl period, but any RFCs that were in final comment period will be allowed to reach the conclusion of the FCP. Also, I get the impression that the idea of the impl period is still being refined (likely becoming a recurring event) so it's possible that they're still ironing out what the rules should be.
Thank you for working so diligently to finish this! I placed an order months ago and eagerly await publication. Rust is a fantastic language that deserves a high bar, especially from the renown O‚ÄôReilly series. As a systems language newbie, I‚Äôm particularly keen to deep dive into smart pointers, but even basic things like rustc compiler flags and Cargo tips should prove to be really insightful. Keep at it, hopefully safe memory management and this book will finally overthrow the C/C++ empire!
no. They've categorically stopped doing this. 
Thank you for this book. It has served me well, and continues to do so. I secretly wish the book keeps getting delayed hoping it'll keep incorporating the latest changes to rust ;) 
Sadly
That would require me structuring the services a bit differently, but that might just be worth doing. Thanks for the suggestnion :)
From reading the description and references, it looks like RocksDB (and LevelDB that it's based on, and HyperLevelDB) are based on [Log Structured Merge Trees](https://en.wikipedia.org/wiki/Log-structured_merge-tree). This involves keeping a small tree in RAM of the most recent entries, and periodically flushing some out to disk to free up space, and merging those flushed out files to disk into progressively larger ones in a kind of on-line merge sort. This provides for very fast insertion, and fast querying once everything is merged, but in the interim queries frequently need to scan all of the different pieces that exist that haven't yet been merged. LMDB (another common entrant in this space, with a mostly BerkeleyDB compatible API but more friendly license and is much easier to use with less tuning) uses [memory mapped B+Trees](https://en.wikipedia.org/wiki/B%2B_tree) using copy-on-write and taking advantage of the kernel to manage simultaneous access from multiple readers while writes are in progress. This allows it to be lock-free in user space, though it's relying on the kernel paging system to actually provide concurrency control. It seems to be more efficient for some queries than something like LevelDB that uses log-structured merge trees, but less efficient at insertion and can't compact the database when records are deleted (though can re-use the space). sled instead used [bw-trees](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/bw-tree-icde2013-final.pdf). bw-trees appear to be designed specifically for modern hardware; multi-core with lock-free algorithms, cache friendly (avoiding cache invalidations), and optimized for SSDs with very fast random reads but very slow random writes. It does this by having an in-memory format that is stored as a kind of log of deltas, so it never actually overwrites old data that other cores may be accessing which would cause cache invalidation, but later consolidates these deltas into more compact pages, all using lock free algorithms. It achieves high performance on flash storage in a similar means; uses a log structured store, which allows it to write out large blocks at a time, but it writes it out as deltas to previous state in the log, reducing how much it needs to write and thus how much garbage collection needs to be done. This takes advantage of the high random read speed of SSDs to be able to reconstruct pages from many parts of the log. It also has a background cleanup that eventually consolidates these. As the "plans" mention, it is intended that this will allow for something that doesn't require as much in the way of tradeoffs between these kinds of structures; the hope is that it will be faster than LSM trees for reading (which they are not very good at due to the number of unmerged pieces which may need to be scanned), and be faster than B+ trees for writing, giving you a single database that will work well for mixed workloads. Anyhow, this is about what I could come up with not knowing much about how any of these systems worked and doing about an hour of Googling, reading Wikipedia, and skimming the introductions of a couple of the linked papers.
**Log-structured merge-tree** In computer science, the log-structured merge-tree (or LSM tree) is a data structure with performance characteristics that make it attractive for providing indexed access to files with high insert volume, such as transactional log data. LSM trees, like other search trees, maintain key-value pairs. LSM trees maintain data in two or more separate structures, each of which is optimized for its respective underlying storage medium; data is synchronized between the two structures efficiently, in batches. One simple version of the LSM tree is a two-level LSM tree. *** **B+ tree** A B+ tree is an N-ary tree with a variable but often large number of children per node. A B+ tree consists of a root, internal nodes and leaves. The root may be either a leaf or a node with two or more children. A B+ tree can be viewed as a B-tree in which each node contains only keys (not key‚Äìvalue pairs), and to which an additional level is added at the bottom with linked leaves. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Good old Lapack. 
Why wouldn't this be a library interface to the large existing code based related to Linear algebra on heterogenous platforms? Trying to replace fftw and lapack when they are so mature seems like a mistake. Moreover for the existing GPU packages. 
Very excited! I don't know how many times I've had to tell people I'm helping out that "NLL will make that better".
You make a valid point here, why completely reinvent the wheel when we can just add on to it. Well the primary reason, at least for myself, is that the project would be fun, interesting, challenging, and potentially still beneficial to someone out there. Now do I have some reservation against the project eventually merging with a more stable one, or the ideas being reincorporated somewhere more mature? Not at all. I will say though, like I mentioned in another comment, the bits I have tried out writing in Rust, pose interesting API challenges that probably wouldn't come up in more "lax" languages. This is why I don't want to start this project as, say, a direct contribution into nalgebra for instance because there is a difference in how the library needs to handle your Matrix when its going back and forth between CPU and GPU. Some patterns that may be easy in nalgebra, I have found to be much more challenging to implement in this OpenCL based library. I hope this a decent answer to your question.
I'm sharing this here not to demotivate anyone but if something can be improved, why we can not start. Rust was the most loved language for two times in Stackoverflow survey and can we do it again?
See the work being done in OCaml: https://github.com/ocamllabs/ocaml-effects-tutorial You declare your own effects and when they are performed execution jumps somewhere else (to effect handler) and then back to where the effect was performed. This allows for very clean code in a variety of situations and is a wonderful alternative to `monads`. Effects are a little bit like exceptions except the computation that performed them can be resumed afterwards. User-defined effects are also nice way to use the `interpreter pattern` while programming in direct style. You can define a clear set of actions that your code is going to use and the gritty bits can be defined somewhere else, in effects handler. More examples here: https://github.com/kayceesrk/effects-examples
&lt;3
[removed]
My two thoughts: a reasonable approach would be to ask the nalgebra maintainers (e.g. by filing a github issue) with your proposal. If they are interested, great. If they aren't, next time someone asks you why you're reinventing the wheel, you know your answer. I've been in the situation of having a codebase that didn't do one thing someone wanted[1] so they rolled their own without talking with me. Then they rolled their own and before long there were two codebases that had a full Venn diagram of functionality. I would have been really happy to work with them to have one awesome codebase. On the other hand, I have to admit I've also rolled my own thing without talking to folks because I felt there were fundamental differences in goals and nothing to be gained from saying "hey, these features other people worked hard on make the one feature I want much harder, so why don't you throw them all away?" [1] - actually, it did do what they wanted, but they didn't realize that, sigh
If it could work with regular shaders, I would love to use it. My specific use case: I want to do video motion detection on a Raspberry Pi 3. Its GPU doesn't support OpenCL. I believe it only does OpenGL ES 2.0. And its CPU is super slow.
But rest assured, it will be safe.
Moderns today usually mean ‚Äî optimized for SSD and not easy to corrupt. If you think it's a buzzword try writing database yourself. You will quickly find funny quirks of SSD.
Just for kicks is a fair answer I suppose. I'm a little on the fence. Reading through the nalgerba syntax it seems a bit onerous when performing matrix calculations. I'm going to betray a bit of na√Øvet√© on Rust here, is there some mechanism like auto in C++ that will infer the type of the result of a matrix computation? That seems to be a weakness of template types? I want to say x=B^-1 * A and it figures out the dimensions of x otherwise it's a bit of a hassle. 
That stinks, I was really looking forward to this... Does O'Reilly have anything like Manning's MEAP program, so I can read it online?
Hmm, if the book is already complete but won't be updated till next year, what are the chances that many things in the book will already be outdated when it comes out?
Why not both?
Here's my [contribution](https://gist.github.com/0bb7cbe590d724f574e2a7b70551d65e ) using clap, csv, and error-chain.
Chuck some more stuff in the readme. Expected usage with examples, short description of what the project does. For inspiration, check out other Rust projects üòä
The same PEP which recommends the "python" default [recommends "python2" as well](https://www.python.org/dev/peps/pep-0394/#recommendation). So it's not much of a justification either way.
At this point I consider all Rust/Go comparisons as clickbait, or if I'm being charitable, written by people who don't understand Rust. It's been long enough that most people should realize the only commonality here is timing of their appearance on the scene and the acceptance that we've got to do something about these newfangled CPUs. Rust is basically a great type system on a systems language. Go is not meant to appeal to people who really care about either of those things‚Äîit's meant to be a maximally convenient approach to an application language. This makes a fundamental paradigmatic split, more fundamental than OO vs. functional vs. procedural, etc. There's not necessarily anything wrong with either choice, but I do object to putting them next to one another like someone is going to have to decide between these two, specifically. Offtopic, but it always comes up: claims about readability are frustratingly insulting when made between languages like these. The author will always betray one group or another by claiming either the more or the less powerful type system is more readable. Personally I like to skip most of the code and just read the types, making Rust, OCaml, Haskell and friends vastly easier to read than Go. (Going in that direction, there's a reason Idris infers *code* and not types.)
For us as developers we can. But for companies, will they keep using both?
I‚Äôve found similar differences between the two programs, alongside some other fascinating ones: * Pleco uses `pub type SQ = u8` to define a square, while Hexe uses an `pub enum Square {‚Ä¶}` (with a #[repr(u8)]) to define a square. The enum representation makes more logical sense, and restricts any square to being in the correct range (Square can only be in 0-63). However, with an enum representation I ran into a lot of boilerplate code and readability issues. I‚Äôd love to revert back to an enum representation myself, hopefully you‚Äôre able to avoid some of the issues experienced by myself. * Similar to square, Pleco has the BitBoard represented as a `type BitBoard = u64`, compared to Hexe‚Äôs Bitboard being a `struct Bitboard(u64)` alongside methods to manipulate it directly. Concerning the tables, it only takes Pleco 0.29s to create them all, an ‚Äúacceptable‚Äù amount of time for a static structure. I‚Äôm risking incorrect generation if the code is incorrect, but I think it‚Äôs beneficial to see exactly what is being computed directly. 
Yes. But you need to subscribe to Safari.
I don't see that it matters here, but in some cases it could matter for template parameter deduction.
Rust is like chess or go. Learn the rules takes five minutes, master the game your hole life. (rust in five minutes... :D you get the idea) 
Indeed this will get outdated, but I have the book and cannot stop recommending it. Most of rust changes are based on how rust is today, so understanding well the current status give you a better position to embrace the new features (for example, NLL extend the valid rust program space, w/out changing the semantic of the language) Rust is a changing language and the introduction of epoch give you the intuition that there will not be a 'definitive' rust book for a long time, so the best approach is take the best available one and join ASAP!
Coming up after I get this database into a more reliable state! I've been intentionally holding back on writing about it because I want to get it more solid before generating lots of attention. But I am definitely looking forward to writing a few blog posts about its underlying architecture!
I mean on one hand you could just have a Matrix type that doesn‚Äôt encode size in the type signature. Nalgebra has a mix of predefined size matrices and arbitrary sized. The nice advantage of what I‚Äôm doing is that I don‚Äôt need to distinguish between the two for performance or efficiency since everything needs to go the the GPU anyway. 
Trying to target the characteristics of SSD's and NVMe: now we can do random reads much faster than with spinning disks, so we don't have to rewrite entire pages at a time as is the case with traditional B+ trees, and we can maintain a single logical tree, which can beat LSM trees for read performance since they may have more read amplification as they access the log of indices for keys they access.
That's an accurate writeup! Nice job! - author of sled
I am very glad I could enjoy the prerelease versions and the updates in ebook format. That was simply awesome.
I like it!
Joined. 10 day free trial
Okay. Than enjoy. Just to be curious. What says the revision history at the front of the book - directly in front of the table of contents? From what date is the latest early release?
!RemindMe 1 week (The bang should come first.)
!RemindMe 1 week
One of your arguments, about code verbosity, is simply false, if you start considering that rust has no generics (or very limited), plus handling erros there is less graceful because the null loonger checks. If I'm not mistaken (my go exposure is very limited), but feel free to correct me.
Because there is only 24h in the day
You can side load for free on iOS these days officially with a Mac. Some emulators provide instructions on how to do just that. I wouldn't be surprised if some people figured out how to do it without a Mac by now.
Ah alright. Thanks. :D
Power to you both for getting this far. Excellent work!
Learning rust by writing RSS to telegram autoposter.
You're right, didn't realise it's only useful for types
Which is also somewhat a problematic view, IMHO. All we do as programmers is wielding huge tech stacks. I‚Äôm not saying this is not to be considered, but I‚Äôd put deploying two different database servers in the same complexity range as two programming languages.
You mean ‚Äúgo has no generics‚Äù?
did you mean "go" when you wrote "rust"? /confused :)
That makes sense, perhaps combining that with `must_use` will do the job, thanks.
I'm currently writing go at work after having written a lot of rust. I have lots of take-aways but the "most annoying all the time" "feature" of go is foo, err := something_that_can_return_an_error() if err != nil { return err } which reduces the readability a bit...
Even as someone with no particular interest in chess engines, this is still a very nice post for discussing how to do things in Rust. I like it! :)
Dropbox is a recent counterexample: go for the majority of their storage system and rust for the memory and performance critical parts. 
Five minutes is perhaps enough for an overview of the borrow checker. Then you fill the other details as an exercise.
Yeah, my bad!
Out of curiosity, when I hear "embedded database" I think SQLite; are they comparable in any way? Also, I like that you have as a goal to use less power; it's one of my personal hopes for using Rust that we can also all become more energy efficient with the hardware we already have :D
&gt; OpenCL driven Have you looked into Vulkan/OpenGL compute shaders? OpenCL is less widely supported‚Ä¶ e.g. AMD OpenCL 2.0 driver is not open source yet.
As not already mentioned, take a look at http://www.arewewebyet.org/
Yeah, this is sort of a difficult philosophical issue for me. :-) I'm not trying to start an argument with you or anything! But this C++ challenge touches a weird nerve in me and it makes me want to try to articulate what's bothering me. There's this whole culture in programming which says that "sorta correct" is good enough. This challenge asks users to show off the elegance of C++17 by implementing a CSV parser, but it's an _elegantly wrong_ CSV parser, which proves exactly zero, except perhaps, "C++ makes it easy to write broken code, but the correct code would be ugly and complicated." Similarly, people still write new networking code in C, even though maybe 95% of it will be remotely exploitable. And worst of all, I own actual programming textbooks which leave out checking `errno` "for simplicity." Basically, my least favorite kind of programming language is one where: 1. *Wrong* code is simple and beautiful. 2. *Correct* code is ugly and complicated. Because given that choice, we all know that people will pick (1). One of the things I deeply admire about the Rust community is that‚Äîboth at the language level and in the culture‚Äîthe correct version of a program is often more beautiful than the wrong one. People take the time to get their APIs correct. Yes, the lack of `Ord` on `f32` is miserable, but it's _real_. `OsString` is ugly, but it also means my programs work in the real world without a bunch of bug reports. So in this particular challenge, I think the philosophically correct thing to do would be to _break the rules proudly_ and use `csv`. üòÑ We have `cargo` and crates.io, and that is a profound advantage over C++17. It gets right down to the most fundamental issues of programming, in my opinion. Anyway, thank you for reading my excessively impassioned rant about CSV quoting!
Rust has a lot of aspects: ownership, lambdas, structs, smart pointers, traits... If someone with no programming experience tried to learn it, it would take a lot more than 5 minutes to learn it.
Very cool! I hope i understand the purpose of you project correctly and is trying to help with data driven development and use more ‚Äì what is commonly known as ‚Äì SOA. If so how is you approach different from like [soa_derive crate](https://crates.io/crates/soa_derive ) ? I hope i can dig a little bit more into it at the weekend ‚Äì i am currently at work and not able to really take the time it deserves.
&gt; and this book would be thick enough to stun an ox Meanwhile, Thinking in Java is about 1100 pgs and is thick enough to kill one.
If that's a problem, just use something like `?` and have a custom preprocessor that generates if err != nil { return err } from it. Bonus points if you use [Canadian Aboriginal Syllabics](https://www.reddit.com/r/rust/comments/5penft/parallelizing_enjarify_in_go_and_rust/dcsgk7n/) instead of the ASCII question mark. 
&gt; e.g. AMD OpenCL 2.0 driver is not open source yet. It should be? https://github.com/RadeonOpenCompute/ROCm-OpenCL-Runtime
I need to wait for a bunch of threads to finish before I stop the main program. I used the `WaitGroup` of the `chan` crate for this, since I used the `chan` channels anyway. However, I recently found a bug, where one of my threads panicked. This makes my program deadlock. Is there a easy synchronisation mechanism that allows for waiting for all threads to finish, but that also allows error reporting: if some of the threads panics, the waiter gets to know that? (I don't care if the master thread will panic too, the main thing is that the program will end and report the error instead of deadlocking.)
Yeah, the Go example literally has no error handling. Rust code does a match always everywhere (except one `unwrap` in main). To be fair, either ignore all errors everywhere (unwrap everything in Rust), or use proper error handling in both cases (`if err != null { return err }` in Go, `?` with `error_chain` in Rust). 
Here, `add_rec` requires a mutable reference of `self`, but the first `if let` creates an immutable reference of `self`. What's the most elegant way of making this work? Intuitively, I'd like to drop the immutable reference created by the `if let` partway through the block, because I don't actually need it anymore. if let Some(existing) = self.records.get(&amp;id) { let derived : Attributes = derive_new(&amp;existing.attributes); let record_key = self.add_rec(Record::new(derived)); record_key } The above is a simplified version of my code for clarity. Below is the actual code, just in case some detail is important: if let Some(bp) = self.bps.get(&amp;bp_id) { let ideal_atts = p.apply_to(&amp;bp.attributes); if let Some(similar_bp_id) = self.find_similar(&amp;ideal_atts) { Ok(similar_bp_id) } else { let mut new_name = String::from(p.prefix()); new_name.push_str(&amp;bp.name); let new_bp = Blueprint { name : new_name, attributes : ideal_atts, }; Ok(self.invent(new_bp)) } } else { Err("No such BPID!") } Thank you :)
As I read through the comments in this thread I get feeling that I should have used play.rust-lang.org :|
Nice to see it here. I've been lurking the repository for a while now.
Thank you for the pointer. It seems to be doing something very similar to what I implemented, probably bit better code quality :) My create also supports tuples, but I personally don't consider that too important. My use case was to use the column-based representation for dataflow-like computations where chunks of data need to be passed from one operator to another. This is also the reason I added a bitmap-filter for collections to provide a non-copy filter function. Some ideas came from [Trill](https://www.microsoft.com/en-us/research/publication/trill-a-high-performance-incremental-query-processor-for-diverse-analytics/).
Are you reusing the capacity and length fields? Or does each column have their own ?
Why doesn't any of these libraries a BitBoard trait? I often want to reuse some algorithms on my u64 bitboards but these libraries force me to convert to their own types. And honestly option&lt;arc&lt;...&gt;&gt; in a bitboard is insane. Popcnt is 1 cycle on a u64 but if I have to get a reference to a u64 via an option-arc we are talking of 200 cycles just to fetch the value... 
Exactly! That's why I thing this: &gt; Another crucial part of writing code is handling errors. Here I think Rust and Go are quite similar. Is a total BS. It seems like the author either intentionally left out `?` operator or didn't learn about Rust enough to be competent to write such article. In either case, it casts huge shadow of doubt at the article.
From the description, it sounds like it's comparable in the sense of being able to easily just link it in with no configuration, point it at a file, and get something that is high performance and reliable with no administration or tuning. It's not comparable since it's just a key-value database and not a full SQL database, but it sounds like global transactions using MVCC are intended to be built on top, and it is possible to build a SQL frontend for such a backend or plug it in as a storage engine for SQLite.
As far as I know it: * is comparable to SQLite in the sense that it's just a file (or directory) in the filesystem, which you access through a library, rather than talking to a server over some sort of socket as you do with PostgreSQL or MySQL * is not comparable to SQLite because what it provides is a key-value store, not an SQL or relational interface.
Thanks for the info. Since tech changes so fast january would mean that it is old ;-)
SQLite has the SQL layer, and the way it accesses data underneath is actually pluggable, so one possible future direction is to use sled as a high performance storage engine fronted by SQLite (or Postgres or MySQL). But both SQLite and sled run in the application process, rather than being accessed over some form of IPC like a socket. My goal is to make sled be a high performance, high reliability iron core that you can build all sorts of interesting other things on top of. You could write your own SQL engine, distributed database, rocksdb clone, timeseries database (targeting the PageCache rather than the Tree struct, with a custom materializer) even a (fragmented) blob store or a more random read optimized Kafka, all on top of the decoupled systems in sled.
It relies on what Vec is doing. Due to laziness I did not try to implement my own. So each column has their own length and capacity but due to how they're used it's (or should be) the same for all in the same columnar layout.
I don't know if you are the author of the article. If you are not, then I suggest you not to spread around deficient articles, as doing that harms your reputation. If you are the author, I suggest you to actually learn Rust and not just look at it or do some toy project. So what are the problems with the article may you ask? Firstly, it completely ignores the most important value proposition of Rust: it guarantees to be fast **and** safe. And while *safe* is mostly about memory safety, it goes beyond that in most cases. (It helps catch a lot of logic errors.) So the article isn't comparing equal languages. I'd have nothing against using something a bit slower than Rust if it had the same correctness guarantees. I'd actually gladly use it! Let's look again at the article. The first two code snippets compare simple HTTP web server. And the article tries to compare length of the code. When you look closely, that comparison is invalid. In Rust case, there's no HTTP library used, but in Go's case, there is! Of course the Rust code is longer than. If I had a time, I could write different code snippets that would show Go code being longer than Rust code simply by using some HTTP crate in Rust and no library in Go. By this method anyone can "prove" any language to be more verbose than the other. Then the article says that multithreading in Go is less effort. Well, Go doesn't guarantee you freedom from data races, that's why! An then the article proceeds comparing another snippets of code. This comparison isn't fair either because in Rust snippet, there's also code for choosing behaviour of the thread when it goes out of scope. In Go case, there's no such code (is it even possible to control that?). It also includes `use` statement, which isn't actually necessary and protects you from name clashes - something Go can't do as far as I remember. Ironically, it also shows Rust strength by using closure example. In Rust you can pass a function into the `spawn` function or a closure, which makes programming easier and can save you two lines of code and effort inventing a name for the function. So actually, Rust code may be considered shorter. Then the error handling part is probably the worst. It leaves out the `?` operator and combinators (like `map`, `and_then`, `ok_or`...) I just wonder if that is intentional, to make Rust look worse or the author really doesn't know Rust well enough. It also completely omits the fact that in Go, if you ignore error, you get "nil pointer exception" with totally meaningless error message. In Rust you can choose to ignore error simply by calling `unwrap()` and in that case at least you get some reasonable message, if you actually go the error. Yes, I did try to write code in Go and the error handling was total nightmare compared to Rust. It's probably #1 reason for me why I dislike Go.
Would the Rust port of this program require less characters? import std.stdio, std.algorithm, std.range; void main(string[] args) { // source change change_with result auto source = File(args[1], "r"); auto output = File(args[4], "w"); size_t change_at; size_t number_of_columns = 0; foreach (column_number, word; source.readln().split(',')) { if (word == args[2]) { change_at = column_number; } ++number_of_columns; } foreach (line; source.byLine()) { foreach (index, word; line.split(',')) { output.writef("%s%s", index == change_at ? args[3] : word, index == number_of_columns - 1 ? "\n\n" : ","); } } }
This JSON doesn't really work with schema-based parsing, so I'd suggest you look at using [Serde-JSON](https://github.com/serde-rs/json)'s [untyped values API](https://github.com/serde-rs/json#operating-on-untyped-json-values) to parse it. After that, you'd have to look through the elements looking for something formatted like an IP address, for which you probably want the [regex crate](https://github.com/rust-lang/regex).
I'll be sure to add some more info to it! Thanks for the input!
Where does this book fit in? Should I check it out after I have gone through either edition of The Rust Book? Or is it at the same level as those two? In that case, if I have already gone thru 2nd edition, would you still recommend going thru this?
Same! This is great.
I'd suggest breaking some of that code apart. You have very large nested match statements with a lot of identical code in a few places.
Clever! So this just generates a Cargo.lock with all available crates, and then cargo adds the dependency info? Or the dependency info is actually not necessary?
Use the associated types. It helps in refactoring or if copying and adapting the code, or in other things that happen to the code in its life.
Split the code into several short functions. I guess you can even de-duplicate something (didn't read deep enough to know for sure). Use wrapper types for units (`Celsius`, `Kelvin`, `Fahrenheit`) and define conversions between them using `From` trait. Implement `Display` and `FromStr` for them too and use it to implement the logic.
[removed]
I'm going to be honest with you...I don't know why this works :)
At what point does does the author use `Option&lt;Arc&lt;BitBoard&gt;&gt;`? They use `Option&lt;Arc&lt;BoardState&gt;&gt;` which is a completely different and justified type. Most of these crates provide `From&lt;u64&gt;` conversations for bitboards so I don't see why a trait is preferable.
Thanks! I was on the right track with trying the untyped values API. Part of my difficulty was that I was storing all of the data in a string (with reqwest), and this line was yelling at me for supplying a String instead of &amp;str. let v: Value = serde_json::from_str(data)?; Sorry, I don't have my code on this workstation to illustrate what I was trying. I'll take another stab at it tonight.
I usually exploit an intermediate boolean to release the borrowed resources: https://play.rust-lang.org/?gist=bad97936a86539474a0cf5a40ef19211&amp;version=undefined I bet you could do better though, and if anyone knows how, please let me know too!
I've actually really wanted something like this for some time now. Having Cargo default to cached files would be great.
That's the best way for now. Non-lexical lifetimes (in progress, finally!) should make the original code work.
The last line in the history says: 2017-07-05: Tenth Early Release 
For simple fetches from HTTP, [reqwest](https://docs.rs/reqwest/0.8.0/reqwest/) is probably your best option. It's built on top of Hyper, but provides a simpler synchronous API; Hyper is designed to be a more general purpose, asynchronous HTTP implementation, while Reqwest is an easy to use synchronous API on top of it. For parsing the JSON, [serde_json](https://docs.serde.rs/serde_json/) is a good option. Using `#[derive(Deserialize)]` on structs can be a good way to do so in a type-safe manner. As /r/redattack34 points out, this schema is not ideally suited to the simplest mapping to a `#[derive(Deserialize)]` struct, so a quick approach might be to use the `serde_json` `Value` API which can be used to represent arbitrary JSON. However, it is possible to do a type-safe schema using `#[derive(Deserialize)]` for this data. I'll walk you through how to build this. We can start from the outside in, adding more specific types as we go. The outer snapshot object seems to have 4 fields; 3 integers, `timestamp`, `total_nodes`, `latest_height`, and then a dict of `nodes` containing a mapping from the node socket addresses to some information on them. We can represent this as a struct with three integer fields, and one map from a string to a vec of JSON values ([playground link](https://play.rust-lang.org/?gist=f4c85a546934be6da163ec4a587c6d9f&amp;version=stable))" ``` #[derive(Deserialize)] struct Snapshot { timestamp: u64, total_nodes: u64, latest_height: u64, nodes: HashMap&lt;String, Vec&lt;Value&gt;&gt;, } ``` This allows us to relatively easily iterate through the nodes, and print out some `serde_json::Value` objects at the appropriate indexes in the list: ``` fn do_it() -&gt; Result&lt;(), Error&gt; { let snapshot: Snapshot = serde_json::from_str(INPUT)?; for (addr, value) in snapshot.nodes.iter() { println!("addr: {}, agent: {}, AS: {}", addr, value[1], value[11]); } Ok(()) } ``` One quick improvement that we should be able to make is to replace the `String` for the address with a [`SocketAddr`](https://doc.rust-lang.org/std/net/enum.SocketAddr.html), which represents an IPv4 or IPv6 address plus port, which is exactly what we have here. This requires just changing that one type, and everything still works ([playground link](https://play.rust-lang.org/?gist=cf8229b8f04677d21670b92f70aff721&amp;version=stable): ``` #[derive(Deserialize)] struct Snapshot { timestamp: u64, total_nodes: u64, latest_height: u64, nodes: HashMap&lt;SocketAddr, Vec&lt;Value&gt;&gt;, } ``` Now, instead of representing each node as a `Vec&lt;Value&gt;`, we can replace it with a `Node` struct, which contains appropriate types for each of the possible keys. If you deserialize from a list into a struct, it will populate the keys of the struct in order. It looks like a few of these can be null, so we need to make sure that we have an `Option` around those ones. I put `Option` around a couple that I saw were frequently null (and one of which was null in my sample data), but for the full data set you may need to wrap that around more of the types, and then handle the `None` case appropriately. Here's what my final version looks like ([playground link](https://play.rust-lang.org/?gist=be779ff18f8681f7f83304651492f370&amp;version=stable)): ``` #[derive(Deserialize)] struct Snapshot { timestamp: u64, total_nodes: u64, latest_height: u64, nodes: HashMap&lt;SocketAddr, Node&gt;, } #[derive(Deserialize)] struct Node { protocol_version: u64, user_agent: String, connected_since: u64, services: u64, height: u64, hostname: String, city: Option&lt;String&gt;, country_code: String, latitude: f64, longitude: f64, timezone: Option&lt;String&gt;, asn: String, organization_name: String, } fn do_it() -&gt; Result&lt;(), Error&gt; { let snapshot: Snapshot = serde_json::from_str(INPUT)?; for (addr, node) in snapshot.nodes.iter() { println!("addr: {}, agent: {}, AS: {}", addr, node.user_agent, node.asn); } Ok(()) } ``` The 24 Days of Rust blog post series has some good easy introductions to [reqwest](http://siciarz.net/24-days-rust-reqwest/) and [serde](http://siciarz.net/24-days-rust-serde/) that should give you a taste of how to use `serde` and `reqwest` together.
This works because you can take a crate with a lockfile and edit the Cargo.toml and Cargo is expected to do a minimal update on that (i.e. not pulling in new packages unless absolutely necessary)
Thanks for such a complete answer. :-)
Wow thank you! That was so much more detailed than I could have hoped for.
All you need here is to add an `&amp;` in front of `data` to turn a `String` into an `&amp;str`: let v: Value = serde_json::from_str(&amp;data)?; But as I point out in [my comment](https://www.reddit.com/r/rust/comments/792xk6/rust_beginner_help_parsing_json/doyubyz/), it's actually not hard at all to use `#[derive(Deserialize)]` to parse this out in a type-safe way rather than using `Value`.
Blocking code is actually very easy and you can already do it with `std`. :)
Because there is not a unique way of storing a bitboard in a u64. So I have tuple structs for the different ways. 
Looks like someone gave you a pull request! You'll be able to use "cargo build" and "cargo run" with those changes.
IIRC there is a way to achieve this, as long as you build a local registry before you go offline. A few months ago I hacked together a fork of Cargo with support for IPFS registries because I was frustrated with the lack of WiFi on German long-distance trains (they are all supposed to have it since the beginning of the year, but they were missing on half of my rides), and also toyed around with alternative registries. Before you go offline on a trip I usually apply [cargo-local-registry](https://github.com/alexcrichton/cargo-local-registry) to the lockfiles of all my recent projects. When I then start a new project that only uses the dependencies in there and point it to the local registry, I can work comfortably offline. With the IPFS fork, I basically do the same thing, but I can specify an IPFS path instead of a local path. I usually add the local registry I've built to IPFS and then pin the registry on the IPFS node on my smartphone, so I can carry over the dependencies of my desktop computer to my laptop.
That's more or less what I am doing in the meantime :) I guess what would be really handy is a way to kinda decouple the scope of the "if" from the "let" somehow. Like if...{ let Some(x){ } //borrow expires //can take mutable borrow here }
I work in an airspaced dev environment, I found that that [cargo-local-registry](https://github.com/alexcrichton/cargo-local-registry) is really helpful here. To make local registry with this tool you essentially just have to do: cargo fetch # generates .lock file cargo local-registry --sync path/to/Cargo.lock path/to/registry for me, I did the following from the project directory: cargo local-registry --sync Cargo.lock ~/.cargo/registry After using the local-registry --sync command, it will inform you to make a config file in your .cargo directory which will inform cargo on where to look for local crate files. I wish this was a little better documented but I was able to successfully build some packages on the airspaced environment. 
Thank you for a really interesting test case for my code generation project (json_typegen). It broke things in multiple interesting ways. :) Currently, large tuples are not very useful, as most traits are not implemented for tuples of arity above 12. But once I disabled that check, and used a configuration feature I'm working on, I got this type: #[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)] struct Nodes { timestamp: i64, total_nodes: i64, latest_height: i64, nodes: ::std::collections::HashMap&lt;String, (i64, String, i64, i64, i64, Option&lt;String&gt;, Option&lt;String&gt;, Option&lt;String&gt;, f64, f64, Option&lt;String&gt;, Option&lt;String&gt;, Option&lt;String&gt;)&gt;, } Of course, a type like what annodomini has written would be much more useful. Have to try to achieve something like that. Had somehow missed that Serde handles list to struct so seamlessly. For my own reference, I used the following config: json_typegen!("Nodes", "https://bitnodes.21.co/api/v1/snapshots/latest/", { "/nodes": { use_type: "map" } });
It would actually be really nice if there was a way to locally store the top 500 say crates on crates.io and then use this in development when one doesn't have an internet connection.
Hey, that's pretty nice! I like that it picks up what should be optional from the actual data, which I was doing by hand, and which is [not documented in the API docs](https://bitnodes.21.co/api/) so you have to either guess based on the actual data or make everything optional. Indeed, it would be nice to see if you can have your generator be configurable to deserialize to a struct instead of a tuple for this case; also would be interested to see if you can deserialize the keys to `SocketAddr` like I did in my manual example. The struct instead of tuple part will likely only work out of the box with `#[derive(Deserialize)]`, since by default I think that `#[derive(Serialize)]` would serialize into a JSON dict; I'm not sure how to get it to serialize appropriately, but for this example, `Deserialize` was all that was needed.
that is interesting! second the suggestion to rename as 'SOA', i've also heard the term 'parallel arrays'
Thanks! You are welcome, keep in mind though that this is an early release and very much incomplete and there may be bugs. But the C/C++ API is complete enough that it's possible to replicate a large subset of the Python API by now with enough work. And any help is welcome off course!
&gt; Offtopic, but it always comes up: claims about readability are frustratingly insulting when made between languages like these. I agree. People mean vastly different things by *readability*. Personally while I appreciate a clean syntax, I still prefer not to use Python because *so much is implicit* (starting from the types). Certainly it makes scripting easy, but it doesn't scale up that well, and since I'm mostly interested in larger programs, for me it's not readable^1 . ^1 *Which actually should probably be "understandable", but people seem to assume that what you can read you can understand, which is silly really.*
&gt; I‚Äôm not saying this is not to be considered, but I‚Äôd put deploying two different database servers in the same complexity range as two programming languages. I agree; which is why I've seen companies attempting to minimize the number of different database softwares they used, even if it meant paying more license fees. Experience does not come cheaply.
I've worked a bit on a projection library. This is by no means complete or even tested (testing floating-point values is a bit of a pain), it works in practice. However, this is just a proof-of-concept library which (in structure) operates more or less exactly like PROJ.4. I did not write the math part, the implementations are so far taken from other repositories (UTM projection is taken from [urbanetic/utm-converter](https://github.com/urbanetic/utm-converter), Mercator projection is taken from the [OSM wiki page](https://wiki.openstreetmap.org/wiki/Mercator)). What this library is, is a framework to add arbitrary coordinate systems - as long as they can be converted to and from LonLat, they can be converted into each other. Plus you can store custom data for each coordinate system (such as zones, height values, weights, whatever). However, according to a stackoverflow question, you cannot project from an ellipsoid A to an ellipsoid B if they are not referenced to each other (rotation, scale, translation). So in order to reproject from ellipsoid A to ellipsoid B, you have to know the metrics of both referenced in one coordinate system. I do not know what the values for the standard ellipsoids are (maybe get them from commonly used PROJ.4 strings?) - plus I don't know how to project between ellipsoids (my math is pretty bad). If anyone can help out on these topics, that'd be great.
I am not sure I would say it's a counterexample. AFAIK Dropbox uses 3 languages to any significant extent: Python, Go and Rust. At their scale (number of developers), 3 languages seems easy enough to manage. From a company which *already* has multiple software stacks, something like Python, Java, C/C++, the choice is somewhat different. Bringing a 4th language is already problematic in terms of experience/talent pool; bringing a 4th *and* 5th languages? That's quite an unpleasant thought.