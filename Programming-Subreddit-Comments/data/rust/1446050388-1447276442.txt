If you just store a pointer (no matter if raw or reference), dropping it will do nothing (well except leak memory if you haven't yet called `heap::deallocate` or whatever the corresponding free function applies). Pointers do not implement drop. If you're storing some kind of smart pointer (you didn't really make it clear), like `Box&lt;&gt;` or whatever, you can use [the nodrop crate](https://crates.io/crates/nodrop) if you want to avoid doing your own unsafe shenanigans.
Not really. If I wanted to optimize, I'd use `read_line(..)` and recycle the `String` instead of `lines()`, which for obvious reasons must reallocate on each line.
A Lisp language for scripting, yeah, that looks pretty similar in concept. I didn't realize Ares existed when I started my project just a couple weeks ago.
Oh thanks!
See also https://github.com/rust-lang/rfcs/pull/197
Thanks! Fixed.
It wasn't offensive; just incorrect.
I would normally write a parser with a parser combinator library like [`nom`](https://github.com/Geal/nom) or [`combine`](https://github.com/Marwes/combine). It isn't entirely clear what's the advantage of Piston-meta: is it ease of development? Making the parsing code clearer / easier to understand? Another thing, it says &gt; Meta parsing is a technique for generating parsing rules at runtime, using a meta language. It was popular in the 60's and early 70's, but was mostly forgotten by mainstream programming until recent years. What's the difference between meta parsing and parser combinators? Does it use parsing expression grammars, like [`rust-peg`](https://github.com/kevinmehall/rust-peg)? (Wikipedia says that OMeta is based on PEG)
Not `Box&lt;Breakfast&gt;`?
Find any bugs in the original as a result of Rust features?
I'm curious, what would you do for tracking who caused the damage in C++?
I feel like Doom has been ported and re-implemented so many times, it might be the most well-understood codebase in existence. If someone told me that one of the later editions/ports of Doom had no bugs, I might actually believe them.
/r/playrust is a subreddit you want.
I'm blind, thankyou.
Link highlighting was fixed in [PR 29264](https://github.com/rust-lang/rust/pull/29264). It should hit the nightly docs within a day or 2 probably I think. Further discussion about whether the styling is still correct should probably go in [issue 29421](https://github.com/rust-lang/rust/issues/29421).
Right, `write!` will produce bytes that happen to be well-formed UTF-8, but to get `&amp;str` out of them you still need either `str::from_utf8` which takes O(n) time or `str::from_utf8_unchecked` which requires `unsafe`. `std::fmt::Write` on the other hand relies on that property to implement for `String` directly.
Here's a thing that frustrates me: Many projects go great length to explain that you should use nightly and there could be regular breakage and you should notify them. https://github.com/cristicbz/rust-doom#build-instructions Guess what: this thing can be compiled with stable Rust 1.3.0. This scares people off and makes them think Rust is not in a usable state yet. Quite the opposite! (safe for triggering https://github.com/rust-lang/cargo/issues/2051, but I don't consider that a rustc issue)
I guess the difference is that Piston-Meta generates parsing rules at runtime
You seem to like heaps of food.
I wrote this. I agree it's annoying. That comment has been there since before rust was stable (I think the commit is October last year); so "I pull rustc every couple of days" was meant to reassure people that it compiled on whatever version they had. In fact, around May 15, I did a pretty big push to make it run on stable, but I forgot to update the comment. Thanks for pointing it out! Edit: Also Travis runs tests on all trains, so I don't even merge changes if they don't work on stable! **Edit the second** Nightly mention now removed from README, thanks again for pointing it out!
I wrote this from scratch, about a year ago when rust was far from being stable. I didn't port it the original source code (in fact I never sat down to read the original source code), I just used the spec. What I recently did was migrate it off raw OpenGL, and banish all uses of unsafe. I'm still in the process of refactoring some of the pre-1.0 cruft.
My understanding: - Reimplementation: you take a specification and design an implementation conforming to it - Port: you read the original source code and rewrite it in another language The port therefore shows much more similitudes with the original source code than the reimplementation, which only has to _behave_ in the same way, but can have a completely different architecture.
Yup, bullet 1 is pretty much exactly how I did this. So I expect bugs galore :P
Web frameworks: there are a few, most notably, I think, [Iron](https://github.com/iron/iron) and [nickel](https://github.com/nickel-org/nickel.rs).
Thanks!
A few things I didn't like (I hope this doesn't sound too evil): 1. Font and images are scaled in a [very bad way](http://i.imgur.com/pIH8aHe.png). This just hurts to read and look at... and I'm pretty sure it's not the fault of my video player 2. Recording a slide show as video might not be the best idea: I'd prefer some proper animations. Things should fly around instead of simple image-by-image animations. I know, it's super time expensive, but it's way more understandable and pleasant for the viewer. 
The artifacting was a side effect of rendering. I'm looking in to what went wrong, as it shouldn't have artifacted that much at the bitrate I set it too. Animations seem to be the general feedback, so those will definitely be more prominant in future theory videos. Thanks :) Edit: If you want a nice crisp slideshow, you can download it [here](https://github.com/SDBlumire/Rust-Tutorial/raw/master/Theory/Stack%20and%20Heap/Stack%20and%20Heap.odp)
This explanation of stack frames reminds me of my computer architecture lectures from some time ago, so I somehow had the impression that every compiled language does this organization into stack frames. And that Rust does on top of this additional checks, that you can not for example reference memory locations in a stack frame which is not guaranteed to exist. So in my opinion this is a good explanation on how a stack works and a preliminary for Rust but nothing very specific to Rust.
If you're working with raw pointers to create your own kind of memory management or smart pointer, you need to set up deallocation manually anyway, so do nothing, and a raw pointer does do anything by itself when it goes out of scope.
Others have said this. I am constructing another rust data type as per description. That data type has a drop implementation that will get called but I have already resolved the issue, thanks.
Oh great. Thanks for the pull requests. That all makes sense. Perhaps I'll do it without the macro.
It's possible to create your own version of RcRefCell with Deref and DerefMut to avoid most of the readability problems. But I agree it's a burden.
I mentioned in my other comment, but I just want to be clear. I agree with you entirely, and I'm always frustrated when people don't use stable for silly reasons. Also, I didn't interpret your comment as agressive at all! The fact the my README doesn't point to the fact the it runs on stable is embarrassing, especially since I went through a great deal of effort to get it running on stable in the first place. Also calling the code "well-documented" and picking literally the only file with comments is very kind :P. I've still got some way to go in terms of documentation, testing and removing old pre-1.0 cruft: the codebase suffers from two illnesses: it was initially written a full 7 months before 1.0 and it was my first Rust project, so I didn't know what the hell I was doing. Some serious refactoring is underway: the move from unsafe and porting to glium was part of this.
Here are already some comments on this https://www.reddit.com/r/rust/comments/3q5zms/good_practices_for_writing_rust_libraries/ ;)
Inspire yourself. The community can help, but being self-reliant is its own reward. &lt;/pessimism&gt; Porting or recreating simple libraries in Rust is a great place to start. If there's any niche programming knowledge you have, you could put it to use in an equally niche library. No matter what, you'll usually end up filling out another corner of the Rust ecosystem. If you search for a library you want to use and find nothing, it might be a good idea to try and create it for yourself. Even if it's bad, it can be improved later once you're better at Rust.
Also: I don't really like the font in that context... How about "Fira Sans". It's created by Mozilla and used a lot associated with Rust, like the Rust website. 
&gt; Also calling the code "well-documented" and picking literally the only file with comments is very kind :P. There's no kindness here, just happy little accidents. *puts on afro and walks away*
Please blog about how you did this.
Yay! And my error handling chapter is now in the [stable docs](https://doc.rust-lang.org/stable/book/error-handling.html). \^_\^
Congrats!
Congrats to the team :) The blog didn't mention it, but was compile times improved in 1.4? Can we expect it to improve in 1.5 or 1.6?
I'm not sure there was any specific testing done, but there's still more improvements on the overall horizon. The HIR/MIR work is still underway, which opens the doors for more stuff, but gotta finish it first.
I think brson searched for concrete improvements but couldn't find a good example. Rustc has been steadily improved, but at the same time had to do some more expensive checks (see RFC 1214 for example), so I think it's adding up to neither improvement nor regression in compilation speed for this release. What I've seen, arielb1 is relentlessly chipping away at the compiler, and I'm super thankful that he's been improving compile time bit by bit. He also made rust development seem quite intellectual to me with the reference to this situation as a [*Red Queen's Race*](https://github.com/rust-lang/rust/pull/27943) (if I had known this expression, I could have felt quite intellectual myself, alas..).
Ha! I'm just at the end of the error handling chapter. Oh well, you cannot have too much of a good thing. ;) Proper error handling is important enough to be read again.
[That bug](https://github.com/rust-lang/rust/issues/28412) still exists on the stable docs, unfortunately.
My handle's arielb1. The "Red Queen's Race" was a reference to rustc's bootstrap time increasing because of the refactoring work we are doing.
Hm, what's the reason for not reintroducing it? Fear of lurking leaks? It's a pretty neat hallmark feature :)
Yes, I agree. It's such a great feature that simplifies threading quite a lot, seems suitable for standard.
What's your intuition for how fast Rust can compile, given all these up-and-coming changes? E.g., twice as fast as now, 10x as fast, etc.? Just curious.
Awesome work guys!!
And many non-guys too. And one bot. Need to get more bots.
Another Symbian C++ suffer?
I was just using that as an example.
Good job, and thank you to give us a wonderful language :)
Not at the moment, though Rust specifically reserves the right to do so in the future (which is why the #[repr(C)] attribute is required for guaranteeing struct layout). Here's the relevant issue: https://github.com/rust-lang/rust/issues/28951
In short: no. Definitely not in terms of appeasing the borrow checker: you should structure your code like that even in languages without a borrowck! For a slightly longer answer: I had unsafe in three places: 1. To parse the WAD file I'd read byte buffers and transmute them to the respective `#[repr(packed)]` structs. * The solution: use `byteorder` to read integer primitives and provide manual implementations for each struct. This is a bit repetitive, but much easier than it might sound, thanks to type inference (basically I just call `field1: reader.wad_read(), field2: reader.wad_read()` with utter disregard for `field1` and `field2`'s types). * The cost: some awkwardness from repetitiveness, ~2x slower in debug mode, none in release mode---code gets optimized to same ops. * If `bincode` supported little endian mode, I could actually get rid of the manual field-by-field reading and just use `serde` and `#[derive(Deserializable)]`. 2. Images in Doom are stored in a weird run-length-encoding-like format. To parse each image, all sorts of byte-at-a-time and offset-through-a-buffer stuff had to be done. I was doing this using unsafe code (with `offset` and deref-ing pointers in a buffer). * Solution: weird pointer magic replaced with weird slice and iterator magic. * Cost: 4x slower in debug mode, none in release mode. Code much more maintainable so a net gain there. 3. And perhaps the biggest was an ad-hoc 'safe' wrapper for raw OpenGL calls. * Solution: migrate to `glium`. * Cost: same perf, productivity net gain. I put 'safe' in quotes, because my wrapper would often hit OpenGL edge cases and crash because it would implicitly rely, despite my best efforts, on OpenGL's subtle global state. Glium is better in every single way and it also allowed me to rip out like 600 lines of code. 
Very good point thanks :)
IIRC, it's just `link.exe`, that's it.
[removed]
It's better in that case semantically to prove it to the compiler. It's barely any work. (This is Scala) myHashMap.get(k).map(v =&gt; doSomething(v)) Unless there are performance reasons to avoid Option combinators like map in Rust.
I'm *sure* that the rest of the compiler isn't as optimised as it could be, too.
On the other hand, the new api is nowhere near as ergonomic. Passing around the scoped handle is significantly more difficult and requires lots of complicated lifetime annotations I think its best waiting to see if its a) safe and b) can be made more ergonomic. Edit: Here's an example of ergonomic and safety problems with the current api. https://github.com/Kimundi/scoped-threadpool-rs/issues/8 That example gets much worse if you want a store a ref to struct containing the pool handle in another struct.
This was a great read!
Hey man, Rust is tough compared to some other languages. With Rust, it really feels like it just makes it really difficult to do something that you feel should be easy. But, after really digging into it and making some projects, it's kind of my favorite language now. I urge you to keep trying and if you want to work on something together or just have questions, let me know! ^(I'm not the greatest programmer and am still fairly new to Rust. Most people on this sub have an intimidating amount of expertise.)
Here you go! TRACE:mio::sys::unix::kqueue: registering; token=Token(11); interests=Readable | Writable | Hup WARN:mob_server::connection: Found message length of 0 bytes WARN:mob_server::server: Read event failed for Token(11): Error { repr: Custom(Custom { kind: InvalidData, error: StringError("Invalid message length") }) } DEBUG:mob_server::connection: Deregistering Token(11) TRACE:mio::poll: deregistering IO with poller DEBUG:mob_server::server: reset connection; token=Token(11) TRACE:mio::event_loop: event loop tick TRACE:mio::event_loop: event=IoEvent { kind: Readable | Writable, token: Token(11) } DEBUG:mob_server::server: events = Readable | Writable TRACE:mob_server::server: Write event for Token(11)
It'd be a shame for prospective Rust users on Windows to be directed to the Visual Studio download page, download 50MB of Visual Studio Code (because it's free), find out it's the wrong thing, the have to download 4GB of Visual Studio Community, all for a 50KB executable.
There are some good news about this: &gt;Visual C++ Build Tools 2015 (Pre-release). If you want to build your C++ projects targeting Windows desktop without having Visual Studio installed on your computer, Microsoft Visual C++ Build Tools 2015 provides the required tools: C++ compilers, libraries, build scripts, Windows SDKs. This Community Technology Preview ships with the same C++ compilers and libraries packaged with Visual Studio 2015 Update 1 RC (2015.1). http://blogs.msdn.com/b/vcblog/archive/2015/10/29/visual-studio-2015-update-1-rc-available.aspx When these Build Tools are released, the download page could link to their download page instead of the whole Visual Studio.
A side note, another great post of this kind in Haskell is [What I wish I knew when learning Haskell](http://dev.stephendiehl.com/hask/), because it also addresses both conventions and some kind of "folk knowledge".
I do not know. 
Thank you for writing that chapter! I had looked multiple times previously for how to properly work with the Error trait, but every example I found assumed that a function would only have to handle a single Error type. I was actually getting turned off from Rust because it seemed like error handling wasn't thought through.
I definitely prefer packing two dimensions into a single vector. The biggest win is probably cache locality since you don't have that extra layer of indirection for each row. As for choosing the strategy for iterating the columns, it really depends on your application. For example, when computing the 2D DCT, which is normally `O(n ^ 4)`, you can instead perform a 1D DCT on the rows and then the columns which is a significantly more palatable `O(n ^ 2)`. Since it seemed easier to just swap the rows and columns, that's what I ended up doing in in [stream-dct](https://github.com/cybergeek94/stream-dct/blob/master/src/lib.rs#L95). However, I might refactor this to just iterate the column values in the original allocation and compare the two in benchmarks. I figured swapping so each column was a contiguous slice would be more cache-friendly but now I'm not sure.
From and Into imply no particular performance characteristics. Deref/DerefMut/AsRef/AsMut generally do, though.
The stdlib does give you the tools to express this in safe code, but it requires a little creativity. It could be made easier, and for all I know some crate out there has extension traits just for this, but you can also hand-roll a solution in just a few lines of code. My recommendation would be to use [`slice::split_at_mut()`](http://doc.rust-lang.org/nightly/std/primitive.slice.html#method.split_at_mut) which will get you two disjoint mutable slices from one. You could wrap that in a function that gets you references to two specific, nonequal indices, as I show here: http://is.gd/i3yx3E As you can see, it's only a little more verbose than the unsafe version, but they should optimize down to the same thing since it's all just pointer arithmetic under the hood. There's another possible solution using `iter_mut()` and `.nth()` but it requires some extra arithmetic and `Option::unwrap()` so it's a good bit more verbose than either of the other two solutions. I wouldn't really recommend it. Edit: in the Playground link, I accidentally made `two_muts_unsafe` take `&amp;mut T` instead of `&amp;mut [T]`. Otherwise, it compiles just fine. 
Very interesting stuff. Now that you've written it out it makes complete sense. I wish I had thought of it myself though! Thanks for the tip :).
Whats the current status of cross-compilation improvements mentioned [here](http://blog.rust-lang.org/2015/08/14/Next-year.html)? Anything to note in 1.4?
Another friendly reminder, we have no nominations for the CotW for this week's TWIR! Please nominate and vote here. Previous crates of the week were: * clap * lazy_static * quickcheck * itertools * conrod * glium * winapi
One thing that I find tricky in various parser is what data structures to use to represent the input. Here httparse simply takes a `&amp;[u8]` byte slice, and can return "partial" if the input ends before the HTTP message is complete. In that case, it’s up to the caller to get more input and **start over** parsing from the beginning. httparse can get away with this since HTTP messages are typically small enough to fit in the first TCP/IP packet, so starting over should be rare. This does not apply in other parsers like HTML. To achieve (near) zero-copy *and* incremental parsing, html5ever uses a fancy reference-counted string type: https://github.com/servo/tendril I’m curious how other projects deal with this.
The problem with `Vec&lt;Vec&lt;T&gt;&gt;` is that it's stored as a vector of pointers to vectors, so performance is terrible. You should use a library that implements the multidimensional array as a flat vector, and provide a `Index&lt;(usize, usize)&gt;` instance - or something similar - like the [`DMat`](http://nalgebra.org/doc/nalgebra/struct.DMat.html) of nalgebra (see example [here](http://siciarz.net/24-days-of-rust-from_fn/)). &gt; extern crate nalgebra; &gt; use nalgebra::DMat; &gt; let mat: DMat&lt;uint&gt; = DMat::from_fn(7, 7, |i, j| if j &lt;= i { 1 } else { 0 }); &gt; println!("{}", mat); I [wrote a `Vec2` type](https://www.reddit.com/r/rust/comments/3l0dau/dynamic_heapallocated_multidimensional_arrays/cv2fn5y) that implements this with an interface I find more ergonomic (but without many helper methods or `Iterator` instances). It's written in such way that instead of indexing with `m[(a, b)]` like `DMat`, you write `m[a][b]`: &gt; let q = vec2![0, 1, 2; &gt; 3, 4, 5; &gt; 6, 7, 8]; &gt; let det = { &gt; let m0 = q[1][1] * q[2][2] - q[1][2] * q[2][1]; &gt; let m1 = q[1][0] * q[2][2] - q[1][2] * q[2][0]; &gt; let m2 = q[1][0] * q[2][1] - q[1][1] * q[2][0]; &gt; q[0][0] * m0 - q[0][1] * m1 + q[0][2] * m2 &gt; }; &gt; println!("q is: {:?}", q); &gt; println!("det(q) is: {:?}", det); But since it's kind of incomplete, I never uploaded to crates.io. I found this `vec2!` macro very neat though.
Great to see this article in the official docs! I had trouble implementing some of the encouraged practices in this article because I have, for example, a lot of different errors that all arise when I get an `io::Result` error. So I ended up manually making my own errors based on the context (failed seek, failed open, failed write, etc.) and returning them. Is there any way around this?
Sadly, no. The compiler was removed from the Windows 8 sdk. A Windows 7 sdk on the other hand still contains everything, so you could use that. Rust doesn't need the newest linker, does it ?
I think it depends on your code. My slowest building project saw a 20% improvement from 1.3 to 1.4 (from 217s to 187s), the new beta seems to hold steady with that, but nightly has a 30% regression (back up to 243s). *shrug*. Just for amusing context: I'm doing "big data" stuff, and it currently takes longer to compile the program to analyze your 1TB graph than it takes to analyze the 1TB graph.
Can't say for rust team, but I don't think so, mingw it widely used to compile software for windows. 
I think it's just a joke
It is. But the crashes are real. :)
*Because*. Seriously, I suspect the reason is just that it's hard-coded into the compiler. `i8` (and the other primitive integer types) are `Copy` because they're *supposed* to be `Copy`, thus they are. As an aside, what the compiler believes doesn't completely align with what's actually possible in the language at the moment. The classic example is that function pointers are `Copy`, but not `Clone`, despite this being *blatantly impossible*. This'll all probably get nailed firmly down at some point or another.
Awesome stuff. Many thanks for this.
I believe function pointers not implementing `Clone` was fixed recently, but I can't test this at the moment. But yeah, that was pretty stupid. 
Also wondering this, as well as the status of a stable plugin API. It would be great if the new version announcement posts included status updates on the various things mentioned in the linked "Rust in 2016" post.
Because if a type implements Copy, then it already has to implement Clone: pub trait Copy: Clone { } http://doc.rust-lang.org/std/marker/trait.Copy.html Therefore, all `T: Copy` are `Clone`.
I was literally _just_ googling this. Turned up [zinc](https://zinc.rs/) pretty quickly. Has anyone used it and wants to chime in? (currently says builds are failing)
Hmm, seems like parsing starts [here](https://mxr.mozilla.org/mozilla-central/source/netwerk/protocol/http/nsHttpTransaction.cpp#1280) and ends [here](http://mxr.mozilla.org/mozilla-central/source/netwerk/protocol/http/nsHttpTransaction.cpp#1546). Not clear that working on replacing that would be a big win.
Much obliged :D
That needs [specialisation](https://github.com/rust-lang/rfcs/pull/1210) to work, because it overlaps with an impl like: impl&lt;T: Clone&gt; Clone for Option&lt;T&gt; If `T: Copy` then `Option&lt;T&gt;` is also `Copy`, and hence the compiler can't know whether to use the blanket impl for `Copy`, or the `Option` one, when looking at `some_copy_option.clone()`.
I'm pretty sure this is a bug, sort of covered by [this issue](https://github.com/rust-lang/rust/issues/22649). To get arround it, you just need to change to `print_to_dim(&amp;*vec)`. Annoying, but at least there's a workaround.
Thats actually not the reason, its perfectly fine to implement traits conditionally in this "wrong" order. The real reason its not done is outlines by dbaupp below.
Need more HIR/MIR work to be finished before plugins can be stable.
There are no plans to un-support MinGW.
Thanks for the workaround, it works.
How about some friendly bovine assistance? use std::borrow::Cow; let mut cache = Cache::new(); let big_cow = if can_use_cache() { Cow::Borrowed(cache.cached()) } else { Cow::Owned(bespoke_big(cache.cached().clone())) }; do_something_with_big_by_ref(&amp;big_cow); 
I see, thanks for your explanation. I guess having to use the `&amp;*vec` workaround or implementing `Dim` for `Vec` is easy enough. I wonder if a more powerful inference capable of coercing on generics would have pitfalls (eg too many possible deref coercions).
The best you can do is create the right impls of `From`/`Error` and use an enum (as described in the error handling chapter). If your errors need more fine grained conversion then that, then it isn't really generic and handling the errors explicitly seems like exactly the right thing to do.
That's pretty neat actually! Especially if `IntoCow` were stabilised then it would just be: do_something_with_big_by_ref(&amp;if can_use_cache() { cache.cached().into_cow() } else { bespoke_big(cached_big.clone()).into_cow() }); It would be nice if borrowck was clever enough to extend the lifetime of a reference in an rvalue block. It might be a bit too hard to define where this would work though, even when MIR trans lands and we get non-lexical borrows.
Not an oversight. It was purposeful. Specialization prevents the ToString impl from using the better performing conversion for str. Using a generic impl for From would have the same downside. When specialization exists, both could exist and still use 1 alloc + memcopy. 
In xml-rs I just read the input stream (i.e. `Read` instance) code point by code point. This is possible because it is by design a pull parser over a state machine, and also because XML grammar is very simple and requires only a small lookahead to be parsed unambiguously. I wouldn't call my method "incremental", it's more like "streaming". I'm not sure whether it can be used to incrementally construct a DOM tree, for example.
I would like to add that `&amp;vec[..]` more clearly describes the intention of taking a slice, than `&amp;*vec`, even though they both work.
When is it going to become possible to bootstrap rustc using the installed compiler binary? Next release perhaps? 
I don't think the stage0 snapshot system has been retired yet so how can you ascertain in advance the correct version is installed? (otherwise it will fail at some stage)
Oh amusing, I knew the situation but did not know it led to an expression :)
Right, you'd need to have exactly that version installed. Maybe I mis-understood your question: I read it as "when can I override stage0". Did you mean something else?
When is it going to be become possible to override stage0 with your system rustc? (1.3, 1.4, nightly, etc) as outlined here: https://internals.rust-lang.org/t/perfecting-rust-packaging-the-plan/2767 
You can compile c code freestanding (no c runtime required). My understanding is they didn't have a lot of c support before since rust was the focus, but they got enough ported to make SDL and the like compile. They probably cross compiled to get the base gcc going and are just recently self-hosting. The osdev wiki goes into decent detail on all these topics.
I called in #rust-internals, as frankly, I'm terrible with our Makefiles. But I thought there was already a flag that let you point to a local Rust. Gonna do some digging to make sure.
Yeah, it will probably be writable soon, thanks to @tedsta.
Not 1.5 (dec 10), since that's already branched for beta. 1.6 is plausible (feb), though of course that code needs to be implemented by dec 10. I haven't thought about priorities for packaging stuff yet. What's your interest in this feature? Are there other packaging-related features you particularly need? The only progress on tasks from that packaging thread is that in 1.5 rustc will be correctly paired with a tagged release of cargo.
Similarly, `[u8; 33]` is `Copy` but not `Clone`.
I'm sorry to disappoint you but ... it's gimped. I made a bunch of images with Redox installed on different devices as an intern joke. It does not yet run on non-standartised hardware.
It's not a stupid question. Tbh, I think many of us don't even know. I think lightweight, modern, easier to maintain, and general purpose[1]. I would like to see it on embedded and mobile platforms one day, but I don't know what jackpot51's plans for this are. I don't think it aims to replace Linux, that would be pretty ambitious. For me, it is a good learning experience and a "let's see if we can build an awesome OS" experiment. [1] although I'm not sure you can get general purpose and still be lightweight. I guess we'll find out.
It's not exactly straight-forward, but not that hard either. I've been blogging about my own learning experience: http://embedded.hannobraun.de/ Here's the repository with my code: https://github.com/hannobraun/embedded
I haven't done much more than run a few drives with it on a home NAS, but I have looked around the ZFS code before and it's not very easy to follow. I'm sure I'll be looking through the rust version when I have more time. I wish you luck on the project, it's a pretty big challenge.
I think the reason to prohibit deref coercions for such a generic function is that it may receive both the original type and the dereffed type, e.g.: http://is.gd/paq1fr To disambiguate such cases there may have to be a priority, which may confuse the user. IIRC C++'s function overloadding has a similar rule and it is fairly confusing.
Yes, and it has an additional nicety that while multiple `*`s may be necessary if the original type is deeply nested (e.g. `&amp;***vec`), `&amp;vec[..]` always works thanks to auto-deref.
&gt; I tried once to set the optimization but then no code was left. Did you see the same thing? I quickly scanned granparent's blog and I see that they are using `*REG_ADDR = value` to write to I/O registers. If you are doing the same, the problem is that LLVM optimizes away that kind of code. The solution is to use the `volatile_*` [intrinsics](https://doc.rust-lang.org/nightly/std/intrinsics/fn.volatile_store.html); e.g. `volatile_store(REG_ADDR, value)`. Once you are using volatile loads/stores, you can turn on optimizations and LLVM won't remove the volatile I/O operations. &gt; it works fine but the generated code seems sub-optimal LLVM does a great job optimizing Rust code, for example, [turning a LED on](https://github.com/japaric/discovery.rs/blob/master/src/app/led.rs) using closures and enums is [32 bytes](https://travis-ci.org/japaric/discovery.rs#L341) for the actual executed code + [144 bytes](https://travis-ci.org/japaric/discovery.rs#L320) for the interrupt table. P.S. The linked code is very old and probably won't compile with a recent compiler.
I love "TODO Player-wall collisions." :)
`IntoCow` might be deprecated in favor of `Into` (which is stable) rather than stabilised. `Into` sometimes needs more type annotations, though.
I am working on [Octavo](https://github.com/libOctavo/octavo) and there is currently primitive RSA support. It is quite of working but there will be a lot of major/breaking changes in near future.
Rust-Crypto maintainer here. Rust-Crypto, in theory, supports everything you need for asymmetric encryption: 1) Create a Curve25519 key-pair on each system that will receive data. Distribute the public keys to the server sending the data. 2) When the system that sends data has some data to send, it generates a Curve25519 key-pair as well. It combines its private key with the target's public key to establish an ephemeral secret key. That secret key is then used with standard symmetric encryption, such as AES-CTR or ChaCha20 and ideally with a MAC, such as HMAC-SHA512 or poly1305, to encrypt and authenticate the message. The system then takes the encrypted message, the MAC, and its Curve25519 public key and sends it to the target system. 3) The target system that combines its private key with the sending system's public key to determine the symmetric key. It can then use that key to decrypt and authenticate the message. In theory, I think that should all work. In practice, I don't think anyone's tried this with Rust-Crypto yet. And, the standard disclaimer: Rust-Crypto hasn't been audited to ensure its security - if you are more interested in security than in experimenting with Rust-only cryptography, this might not be a great way to go. The interfaces are all also a bit under-documented. All that being said, if you do give it a go, I'd love to hear about how it works out for you. If you're primary interest is creating a secure solution, what I'd suggest is to take a look at the Rust bindings to libsodium. This use case is pretty easy to implement with libsodium and that library certain gets quite a few more eyeballs on it than Rust-Crypto at this point. 
I'm going to do it the libsodium way since I'm after security, but I think doing it with rust-crypto is a good weekend project so I may it a shot. I'll let you know.
Here is that in code, roughly. To encrypt, it - Generates a ephemeral secret key (a curve25519 point). - Derives a public key from the secret key. (curve25519 multiplication) - Derives a symmetric key by combining the permanent public key with the ephemeral secret key. (curve25519 multiplication) - Symmetrically encrypts/authenticates the text using chacha20-poly1305. - Packages up the ephemeral public key with the encrypted/integrity-checked text. To decrypt it: - Derives a symmetric key by combining the ephemeral public key with the permanent secret key. (curve25519 multiplication) - Decrypts/integrity-checks the text with chacha20-poly1305 At the end of it all, the secret key holder knows what got encrypted, but has basically no idea who it came from. (Except that they had his public key.) To get the equivalent to happen in libsodium, you'll want to use http://nacl.cr.yp.to/box.html with a sending keypair that you randomly generate, and then send the "boxed" output along with the sending public key. extern crate crypto; extern crate rand; use rand::{Rng, OsRng}; use crypto::curve25519::{curve25519_base, curve25519}; use crypto::chacha20poly1305::ChaCha20Poly1305; use crypto::aead::{AeadEncryptor, AeadDecryptor}; pub enum EncryptError { RngInitializationFailed, } pub fn encrypt(public_key: &amp;[u8; 32], message: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;, EncryptError&gt; { let mut rng = try!(OsRng::new().map_err(|_| EncryptError::RngInitializationFailed)); let mut ephemeral_secret_key = [0u8; 32]; rng.fill_bytes(&amp;mut ephemeral_secret_key[..]); let ephemeral_public_key: [u8; 32] = curve25519_base(&amp;ephemeral_secret_key[..]); let symmetric_key = curve25519(&amp;ephemeral_secret_key[..], &amp;public_key[..]); let mut c = ChaCha20Poly1305::new(&amp;symmetric_key, &amp;[0u8; 8][..], &amp;[]); let mut output = vec![0; 32 + 16 + message.len()]; let mut tag = [0u8; 16]; c.encrypt(message, &amp;mut output[32+16..], &amp;mut tag[..]); for (dest, src) in (&amp;mut output[0..32]).iter_mut().zip( ephemeral_public_key.iter() ) { *dest = *src; } for (dest, src) in (&amp;mut output[32..48]).iter_mut().zip( tag.iter() ) { *dest = *src; } Ok(output) } pub enum DecryptError { Malformed, Invalid, } pub fn decrypt(secret_key: &amp;[u8; 32], message: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;, DecryptError&gt; { if message.len() &lt; 48 { return Err(DecryptError::Malformed); } let ephemeral_public_key = &amp;message[0..32]; let tag = &amp;message[32..48]; let ciphertext = &amp;message[48..]; let mut plaintext = vec![0; ciphertext.len()]; let symmetric_key = curve25519(secret_key, ephemeral_public_key); let mut decrypter = ChaCha20Poly1305::new(&amp;symmetric_key[..], &amp;[0u8; 8][..], &amp;[]); if !decrypter.decrypt(ciphertext, &amp;mut plaintext[..], tag) { return Err(DecryptError::Invalid); } Ok(plaintext) } #[test] fn it_works() { let mut secret_key = [0u8; 32]; OsRng::new().unwrap().fill_bytes(&amp;mut secret_key[..]); let public_key = curve25519_base(&amp;secret_key[..]); let encrypted_message = encrypt(&amp;public_key, b"Just a test").ok().unwrap(); let decrypted_message = decrypt(&amp;secret_key, &amp;encrypted_message[..]).ok().unwrap(); assert_eq!(decrypted_message, b"Just a test".to_vec()); { // Corrupt the ephemeral public key let mut corrupt_1 = encrypted_message.clone(); corrupt_1[3] ^= 1; assert!(decrypt(&amp;secret_key, &amp;corrupt_1[..]).is_err()); } { // Corrupt the tag let mut corrupt_2 = encrypted_message.clone(); corrupt_2[35] ^= 1; assert!(decrypt(&amp;secret_key, &amp;corrupt_2[..]).is_err()); } { // Corrupt the message let mut corrupt_3 = encrypted_message.clone(); corrupt_3[50] ^= 1; assert!(decrypt(&amp;secret_key, &amp;corrupt_3[..]).is_err()); } } 
Ocatvo's implementation of RSA does nothing to mask secret-dependent timing information. You should at least use random blinding. Also: Octavo in general does not appear to be ready for production usage and I think you should call that out a lot more explicitly.
What does libsyntax offer for embedded dev? What does the code generation provide you? What other ways could the same problem be solved?
I did some digging because this question intrigued me. The STM32F1 is an ARM Coretex-M3 processor, which implements the Thumbv7 instruction set. This has pretty good support in LLVM, AFAIK, so it's really just a matter of cross-compiling. As luck would have it, I came across [this example project](https://github.com/JinShil/rust_arm_cortex-m_semihosted_hello_world_libcore) for building Rust (libcore) on the STM32F4. It probably won't compile today but it's not a bad jumping-off point. You'll probably want to start by updating the commit hash in `build_libcore.sh` to the commit hash you get from your installed Rust by running `rustc -V`. This is necessary because libcore and the compiler are closely interconnected, and I doubt that you could build a libcore from 8 months ago on any recent Rust release. This does require nightly Rust so if you're only using stable or beta you're going to want to upgrade either via multirust or an uninstall/reinstall. Depending on the differences between the STM32F1 and STM32F4 (I'm not an embedded developer so I have no idea), you might need to update the `link/link.ld` linker script to make sure that the binary is linked correctly for your processor. With that out of the way, you're probably good to start building your firmware. You'll probably want to see how cleanflight does things. https://zinc.rs/ used to be recommended for any embedded work but development seems to have ground to a standstill. I'm not aware of the alternatives, if any; I've seen a few mentioned recently but I can't remember where I saw them and none of my searches have borne any fruit. 
The STM32F1 is an ARM Coretex-M3 processor, which implements the Thumbv7 instruction set, so it's just a matter of cross-compiling.
Thank you! I knew I had seen this comment, but I couldn't remember where to find it again.
Isn't graydon is working on something similar sounding now? http://graydon2.dreamwidth.org/201698.html https://www.stellar.org/
How does this actually work? Setting a string twice shouldn't make anything crash
Code generation is used extensively in zinc for two cases. First, it [provides a DSL](https://github.com/hackndev/zinc/blob/master/ioreg/src/lib.rs) to define the platform I/O registers to be manipulated in safe way. We build those from vendor-based SVD files where available, so basically one gets a proper API to interact with hardware on low level for free. Second, it provides [high-level platform description](https://github.com/hackndev/zinc/blob/master/examples/blink_pt/src/main.rs), allowing one to define the target hardware mapping right there in the code. The first case is solved easily with rewriting all the things in ruby. The second case, platform tree, is more complex, and it was already a mess when I started to expand on it in zinc. It needs some other way to solve the problem of defining a hardware specification and I'm not yet there.
I can suggest using [VolatileCell](https://github.com/hackndev/zinc/tree/master/volatile_cell) for that, being the only perfectly stable and tested part of zinc it gives you a nice wrapper around volatile and a way to write unit tests for the relevant code.
The string constant "is the end" is stored in the text section of the program, which is usually not writable. The pointer `this` points to this constant, and later the program tries to write a new value to the location `this` points to. As the location is not writable, this leads to a crash.
Absolutely. I have a bunch of arduino boards and I'd like to run some rust on them. I didn't know that avr-llvm got traction again, I guess I need to give it another look
edit: thanks for the lucid response. safe embedded dev is extremely important to me. Are both of these issues from breaking changes to libsyntax? From a user's perspective both look extremely clean. What is it about `platformtree` that is a mess? I not familiar with compile macros or code generation in Rust but could there be a simpler way of piping the body of a macro through an external filter that both enable more languages to be used and to decrease the instability? Is something like [libsyntex](http://erickt.github.io/blog/2015/02/09/syntex-syntex-extensions-for-rust-1-dot-0/) a possible solution? 
&gt; although I'm not sure you can get general purpose and still be lightweight I suppose it depends how much you can manage to delegate out of the kernel, or make optional in the kernel build?
Doesn't that open you up to the possibility of a very low-bandwidth DoS attack, though? A client can connect to the server, send 200KB of an unfinished HTTP request, then start sending one byte at a time.
The tricky part for me is, I think, that the function is being called in a callback, and even when I change it from `a` to `b` from outside of the callback, the callback doesn't read the changed value. fn a(foo: i32) -&gt; f32 { } fn b(foo: i32) -&gt; f32 { } fn main() { let mut selected: fn(i32) -&gt; f32 = a; let callback = Box::new(move | | -&gt; CallbackResult { let val = selected(4); // more stuff ... }); // there's an open stream running the callback and sending data through a channel stream.open(callback) // Loop while the non-blocking stream is active. while let Ok(true) = stream.is_active() { std::thread::sleep_ms(1000); selected = b; // this has no effect on `selected` in the callback } }
Oh, I was not aware you were storing the result of the map. If you do that, it is clearly a better option.
As the state should be with the socket, a web server can keep track of how many times its tried parsing, or how many bytes it's getting at a time, or anything else. 
Did you managed to actually do something useful with it? It doesn't work even for simplest cases: #![feature(optin_builtin_traits)] trait NotSame { } impl NotSame for .. { } impl&lt;A&gt; !NotSame for (A, A) { } fn f&lt;T, U&gt;(_: T, _: U) where (T, U): NotSame {} struct S; struct Z; fn main() { f(S, Z); // error: the trait `NotSame` is not implemented for the type `(_, _)` f(S, S); // error: the trait `NotSame` is not implemented for the type `(_, _)` }
Be careful, default impls are very buggy.
What's the slow step?
Hm.. here's what I did: http://is.gd/kUJlv3 If you comment out the `(S, R): NotSame` it does not compile. edit: perhaps this only works in `impl` where clauses? weird..
[`winapi`](https://github.com/retep998/winapi-rs)
[image](https://github.com/PistonDevelopers/image). It always seems to be the slowest to compile when I'm building dependencies.
This one probably spends a lot of time in the optimizer (LLVM).
The `script` crate for Servo.
It would be interesting to take a tool like csmith and port it to rust.
Oh, brilliant! As usual, it's some simple insight that just... plays cat and mouse with you for an hour when you need it (and may or may not come to you long afterwards) ;)
I figured as much, I only wanted to point out it could've been communicated more clearly.
Oh come on! You've got to admit I could not in any reasonable way figure that out. And since my choice of 'fellow' does work by intent (well, its use in academia is pretty useless in this context but still...), I don't see the problem justifying calling me out on it. Though again, for real this time, I'm just dropping this topic.
Compiling [combine](https://github.com/Marwes/combine) gets very slow once a few types are nested. EDIT: I should add that compile times using only `cargo build` is not that bad as it seems that the types need to actually be instantiated so `cargo test/cargo bench` is needed.
hyper
syntex_syntax
sgrif/yaqb definitely takes a while.
Yep, unfortunately it doesn't. Yeah, I should mark that in README but there always was something more important to do.
Something along these lines was worked on a while back (2012): http://blog.theincredibleholk.org/blog/2012/12/05/compiling-rust-for-gpus/ It would be great to see the work continued or extended to support modern Rust.
It would be interesting to combine something like [Shedskin](https://en.wikipedia.org/wiki/Shed_Skin) and extend it with something like escape analysis to infer lifetimes to convert a subset of Python into Rust. One could use a typed subset that uses function signatures from [PEP 3107](https://www.python.org/dev/peps/pep-3107/) so the whole typing phase doesn't have to be done. * Shedskin Thesis http://mark.dufour.googlepages.com/shedskin.pdf * Iterative Flow Analysis by Plevyak http://plevyak.com/ifa-submit.pdf * Agesen's Cartesian Product http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.663&amp;rep=rep1&amp;type=pdf 
Submitting a new comment so OP will see it: In general, some sort of high-level binding to Vulkan in Rust would be pretty neat, if the API is available by the time you start on your thesis. Rust and Vulkan seem like they would either work really well together or be totally antagonistic. I don't really know. It's an idea either way. /u/tomaka17 expressed interest a while back in doing some Vulkan stuff. I don't know if he's planning anything concrete or not, though. I'm sure #rust-gamedev or #glutin would be great places to discuss Vulkan in Rust.
I know /u/pcwalton is very interested in researching executing css selector matching on the GPU. This is a hard problem since it's basically a tree search algorithm on a very dynamic tree (so flattening it to an array is trouble). In addition you want to minimize CPU &lt;-&gt; GPU traffic, for obvious reasons. Apparently the bleeding-edge (GP?)GPU stuff gives some tools that may work well for this.
Just to comment on Vulkan. This is indeed a non-trivial topic. There are many questions that are hard to solve: - Which subset of Rust can be compiled into SPIR-V? - How do you provide an easy way for the user to compile their Rust code into SPIR-V? Rust plugins are a nice solution, but when will they be stable? - Can the Rust-&gt;SPIR-V compiler provide some reflection about the compiled code that'd be useful for the CPU code? What exactly? - How to handle the "dependencies" between various resources without adding an overhead? See [this](https://gist.github.com/tomaka/da8c374ce407e27d5dac). - When to destroy resources? Should a resource's destructor block until it stops being used by the GPU? Should a resource's destructor move it into some sort of destruction pool that is cleaned from time to time? - When do you create fences? After each operation? The problem is: if you submit another command right after the previous one, you don't need a fence. If you decide to modify a buffer for example, you do need a fence. You often know whether you needed a fence only after you had the chance to create one. - How to handle synchronization between multiple GPU queues? That's a huge unresolved question. Of course I only have access to the Mantle specs, so we have to wait for the Vulkan specs to be released before getting a better overview. 
Could you annotate things for now, as a work-around for your own dev cycle/sanity? (I assume the problem is caused by macro-generated code? so it may only take a few annotations to improve things.)
Why can't lifetimes be infered in struct case? Isn't it a default case that anything that is in the struct as ref needs to live at least as long as struct?
If you have an unbound type parameter, it means your type is implemented for all possible values for the parameter. The actual types and lifetimes are inferred from the scope where your impl is used.
They're there to declare a lifetime variable and a type variable, respectively. Read `impl&lt;'x, Y&gt; MyStruct &lt;'x, Y&gt;` as "for all lifetimes 'x and all types Y, impl MyStruct&lt;'x, Y&gt;".
Especially c++11/14/1z compared to c++98. I don't think I've written a new/malloc call in years, let alone delete/free.
That whole thread on HN discusses this point: https://news.ycombinator.com/item?id=10484568
It's the difference between `impl&lt;T&gt; MyStruct&lt;T&gt;` and `impl MyStruct&lt;u8&gt;`. `impl&lt;T&gt;` means that the impl applies "for all T". You can also introduce bounds there, i.e. `impl&lt;T: Copy&gt;`
For this comment, I was just talking about having a Rust wrapper over the Vulkan C/C++ API when it becomes available. Vulkan sounds like it's going to be a lot more sane WRT error handling so the Rust part would probably mainly involve making it more idiomatic and abstracting over common patterns. Did you mean to reply to my comment about compiling Rust to SPIR-V? Or do I just have a poor understanding about how Vulkan and SPIR-V are meant to interact?
So just to be clear, the `&lt;'x, Y&gt;` on `impl` *designates the impl as generic*, while the `&lt;'x, Y&gt;` on `MyStruct` *passes in type parameters to reify an existing generic type*? Like the type parameter lists in `fn my_fn&lt;T&gt;()` and `let my_var = MyStruct&lt;T&gt; { ... }`, respectively? EDIT: Does the compiler throw an error if there are no valid candidates for `'x` and `Y`, for example because `MyStruct` has a bound on `Y` which is absent in the impl's parameter list? Or does it just not create any impls based on this generic impl?
Okay, a question. We can have affine types without lifetimes (like [in Idris](http://docs.idris-lang.org/en/latest/reference/uniqueness-types.html)). Are them necessarily less expressive than dealing with the lifetimes directly?
Yes. You will have to have some form of elision, which means that certain patterns which are expressed easily in Rust can't be expressed there. C++ is going the same way with its lifetime annotations, they're setting forth some global elision rules.
Who said it isn't? It's not a Tier 1 platform, but we test almost every build on BSD and there is a pkg for rust. We just don't have official tarballs for it.
I routinely have newbies trying to sneak `new`/`delete` calls in the code; it's quite unfortunate that C++ is still mostly taught as C with classes :(
Not enough people willing to maintain it, really, and so far not that much demand. Current focus IIRC is more towards cross compilation builds, which has a lot more demand. For something to be Tier 1 it means that any build/test failure will block a build from happening. We don't have enough Rust contributors using BSD to be able to help fix these test failures. So we file bugs when it breaks and eventually one of the BSD contributors fixes it. However we can't gate builds on it, since the turnaround time isn't small.
I run FreeBSD on an x86 box. As far as I can tell, there is rustc for FreeBSD x86 but no cargo yet. I believe FreeBSD AMD64 does have both rustc and cargo. I there is a rust and a rust-nightly port available. (I don't know if they conflict, I've never run the nightlies.) 
How does C++ do it's memory handling?
Greate work! Are you planning to release the zfs part as standalone crate? I think this could help some other projects that are currently struggling at adding zfs support (thinking of grub and freebsd bootloader). 
BTW, nrc already has a collection of some crates/benchmarks used for tracking performance: https://github.com/nrc/benchmarks , but I'm sure more won't hurt. (Some timings of these are plotted at http://www.ncameron.org/perf-rustc/ )
In a way, much like Rust: a couple user-written types manipulate unsafe primitives to provide a much safer interface. Typically, we are talking about collections (containers) such as `std::vector&lt;T&gt;` or `std::string` as well as so-called smart pointers such as `std::unique_ptr&lt;T&gt;`. Of course, contrary to Rust, while they can reliably address the issues of ownership and double-free, they unfortunately cannot help with use-after-free (dangling pointers/references) which remain under the developer's purview.
I posted my "dream specialization" on [the issue](https://github.com/rust-lang/rust/issues/29499) you filed. It's so close to ad-hoc specialization, it passes coherence, both impls exist, it just doesn't infer the method call to the correct impl..
That makes complete sense, thanks for the insight! Unfortunately it sounds a little like a chicken-and-egg conundrum. I wonder if there's any possibility to surge some BSD as top tier platform for a short time to see if that helps at all, and if not go back to normal? I guess it's not really practical, I'm just thinking out loud.
That's not how the tiers work, but anyway we already test BSD on every merge. We just don't gate on it. Assuming that the turnaround time won't change much if we do gate on it (reasonable given the number of Rust contributors working on BSD), we already know the answer to that.
It does work for static methods perfectly though!
It's only a few weeks old, hence why the link is on nightly. Should be in beta too, I think...
Typically something like `auto ptr = std::make_unique&lt;MyType&gt;(arg0, arg1, ...);` assuming `MyType` has a contructor accepting `arg0, arg1, ...`. Slightly more verbose than `auto ptr = new MyType(arg0, arg1, ...);` but not by much, and you gain a great deal. Of course, even more typically, you wouldn't use dynamic allocation, or you'd use containers like `std::vector` to handle it instead. If I'm programming something in C++ then I'm already working on a performance-conscious project and spreading dynamic allocations all over the place is terrible for performance.
Even if you only have C++11, `make_unique` is trivial to implement yourself to supplement missing library functionality. template &lt;typename T, typename... Args&gt; std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp;... args) { return new T(std::forward&lt;Args&gt;(args)...); }
/u/tomaka17, good points. Did you start something with Mantle? Do you have more links about the subject?
Bookmarked! I'm going to take a look. Thanks for the links.
As someone that only has a uni level education in c++ can you explain how you never use new? I can see how you would rarely use delete but not new.
`self` is already `&amp;mut` (from the receiver), try just `self` on the transmute line.
Oh, that makes sense. And it works! Thanks! I keep thinking of `ref`'s are like references in C++ (where `&amp;R` returns a pointer to the thing the reference refers to) but they really behave more like C++ pointers (where `&amp;P` returns the address of the pointer itself). I guess I should change the immutable version of the function too.
std::make_unique
I still don't get it. In that thread, they liken being generic over lifetimes to being generic over types. But being generic over types has implications of total struct size, code generation, etc, whereas the only requirement for lifetimes in a struct is that they outlive the struct. Why couldn't it just be assumed/enforced that any lifetime in a struct outlives the struct without specifying?
Lifetimes _are_ part of the type, just that all lifetimes are equal after compilation (so the types have the same representation). Lifetime parameters _are_ type parameters. The assumption you mention can be made in simple cases where a struct has a single borrowed piece of data. When there are multiple, you sometimes need to specify how the lifetimes are related. Also, there's the issue about structs having lifetimes being put inside other structs -- if we had that elision, then it wouldn't be clear at all that there's something borrowed; which is something most of us feel we need.
Random example grepped from a random repo: https://github.com/Manishearth/humpty_dumpty/blob/master/src/lib.rs#L60 Here we have things being borrowed from other things, where all the things are stored inside the struct. It can't all be `'a` because that means the lifetimes are equal, and they're not. 
Cool! I think it might be nice to have the option of giving these values explicit names too, especially if you suspect that there are several valid impls, e.g. `impl_bar_via_foo`.
Hm, I'd like to be able to play around with this, but I only have the stable release of Rust. Is there any chance you have an example that's more isolated/doesn't require the newer features? ^^\(and ^^thanks ^^for ^^indulging ^^the ^^noob ^^in ^^me)
Thanks.
Thank you.
In that case it sounds like you've got a chance to take it seriously there. :)
[Here](https://play.rust-lang.org/?gist=a1550b00a284ad743662&amp;version=stable) is my shot at improving it. I changed choosing rule to use match instead of if-clauses. I made rules to edit the String as a buffer. And I simplified the second rule. (Playground doesn't seem to handle inputs so I hardcoded the rules that I apply)
That's cool! I didn't know about `swap` or `clone`; interesting. Definitely made rule II easier. 
Unfortunately that won't help as tuple-structs don't have a guaranteed c representation. One would still rely on undefined behavior. 
Try it: *cell = (new_cell, 0) You forgot to deref it. Also, change the ``for`` loop, removing the ``&amp;mut`` from cell. 
1. The `&amp;mut cell` destructures the `&amp;mut (bool, u8)` assigning storing the `(bool, u8)` in `cell`. Get rid of this. 2. `cell = (new_cell, 0)` modifies the binding `cell`. Once it's a pointer (after changing 1), you'll need to dereference `cell` to change the variable to which `cell` points.
Thank you for the answer and explanation, very informative.
Hey, I've been trying to go down this road as well. I (cross-)compiled binutils, GCC and grub from source. So far so good. What I got stuck on is that building binutils on OS X does not build `ld`. And cursory investigation seemed to indicate it was not possible to build GNU `ld` on OS X. Did you encounter/solve this? Edit: I seem to have confused building a native `ld` with building `x86_64-elf-ld` which works fine. I'm at a point now where it seems I would need a `rustc` capable of cross-compiling the build dependencies, but I've had no luck with this so far. For now I'm just running rustc natively in Linux running in VirtualBox (in a shared folder, so that I can still use my dev environment and run the result in OS X)
By the way, that is the reason why you can easily end up with dangling pointers... There is no borrow or lifetime checker to protect you.
Sorry, we've miscommunicated. When I referred to link time errors I was speaking synecdochally: the higher level concept is a well-typed Rust crate should not be badly typed when linked with any other well-typed Rust crate. The stage of compilation at which these errors become detected is incidental. When you said that "If the error messages are good and libraries are reasonably well-designed, the new orphan instance collisions should be understandable and easily fixable." I interpreted that to mean under current Rust, the errors the orphan rules prevent would be easily fixible, which is not true in nontrivial cases. But you seem to have meant that explicitly importing impl declarations makes it easy to circumvent coherence violations without orphan rules. I don't know if I agree that it is easy. Based on the description of the proposed feature (which isn't a full proposal, I understand), it seems less usable to me than just allowing better set relations on traits through specialization and mutual exclusion. Aside, in the OP, you make this comment: &gt; It's not immediately obvious that the library providing the voxel implementation should be aware of every trait these voxels might be used with, and it's certainly not obvious that the dual contouring library should be aware of every distinct implementation of a voxel. This isn't the implication of orphan rules though. For your two crates, you need to pick which knows about the other, but if you decide that the dual contouring crate knows about the voxel crate, that's not a reason other distinct voxel implementations can't depent on your dual contouring crate. Just as serde provides serialization impls for types in std doesn't mean that I can't impl the serialization traits for the types in my libraries by depending on serde.
Not trivial for the newbies who were supposed to avoid new.
The best way, in my opinion, to fix this undefined behavior, would be struct Vec4&lt;T&gt;([T;4]); fn as_array(&amp;self) -&gt; &amp;[T; 4] { &amp;self.0 } fn as_mut_array(&amp;mut self) -&gt; &amp;mut [T; 4] { &amp;mut self.0 }
Writing `&amp;mut table` is just taking a reference to the value on the stack. When the function returns, the `table` variable is destroyed and the pointer is left dangling. The way to return a pointer to a value you've created locally is to place it on the heap with `Box`, and then ensure that it isn't cleaned up when the function exits (mostly easily via [`into_raw`](http://doc.rust-lang.org/std/boxed/struct.Box.html#method.into_raw)): #[no_mangle] pub extern fn table_new(name: *const libc::c_char) -&gt; *const libc::c_void { unsafe { let name: String = CStr::from_ptr(name).to_string_lossy().into_owned(); let table = Box::new(Table::new(name)); Box::into_raw(table) as *mut libc::c_void } } &gt; let table: &amp;mut Table = unsafe {&amp;mut *(table as *mut Table)}; Incidentally, since the function is taking a `*const`, and there's no mutation, it is probably better to use `&amp;` and `const` here, instead of `mut`: let table: &amp;Table = unsafe {&amp;*(table as *const Table)}; (*e*: I have no idea of your background, or that of others reading this comment, so I'll point you to [some docs exploring the stack vs. heap distinction](http://doc.rust-lang.org/book/the-stack-and-the-heap.html) in more detail in case it is not something you're intimately familiar with.)
simple hello world in iron framework was quite slow to compile even on my nice machine with ssd and i5 cpu
Indeed, I've seen both beautiful and hideous Rust code in my time. I don't think this property is exclusive to Rust though... most languages tend towards hideousness, and only differ in the amount of effort that it takes to write beautiful code. :) Where Rust happens to fall on this spectrum is obviously subjective, but I think that having a strict compiler is a good first line of defense against accidentally sloppy code. IOW, Rust requires more up-front thinking than more permissive languages, and this results in code that tends towards clear and deliberate structure (even if that structure was only arrived at to appease the compiler). Now Rust's syntax, on the other hand... :P Let's say it's an acquired taste!
Understanding the syntax for the type system was a big barrier to entry for me. Once you understand that, you can read code easier and start to learn new things in little chunks. I'm sure a new-comer to C++ would probably be just as confused looking at template syntax, I know I am. I would recommend reading through the Rust book, not just skimming but actually reading and maybe typing out the syntax and running code for the sections you are having trouble with. Also if you can manage getting onto IRC, the #rust or #rust-beginner channels on Mozilla's IRC network are great resources to get real-time interactive answers to questions.
Entries is a Vector of tuples that is a vector of usize and a String. From each receiver, we receive on entry (the tuple). Simple. The only issue here is that we have a case that is in the same family of "Boolean Blindness". That tuple should have been giving a specific type. E.g. `struct ExampleTuple(Vec&lt;usize&gt;, String)` and probably also using `newtypes` for `usize` and `String` so as to say what they are. Basically, it's no different than somebody doing `foo(true, true, 0, 0, 0, false, -1)` in C. And it's not really a problem that a programming language can solve. Rust gives the programmer tools to solve it themselves, but in that case, the programmer eschewed them.
In this case, I don't think the innermost layers could be inferred. And even if they could, it would harm readability even more for that to be the case. You get a vector of..... what exactly from your last code snippet? Without knowing the receiver code, it's impossible to say. See my reply to your parent as for what I see as the real issue. Though using the iter approach on the channel itself is much cleaner. Side question: Wouldn't the `rx.iter()` be an iter for `Option&lt;ReceivedType&gt;`?
FWIW, that module really hasn't been updated since it was written except to keep it compiling and working properly. It works and no one cares because any effort to improve the site would be better spent either improving examples used in it or improving a solution such as [mdBook](https://crates.io/crates/mdbook) so that such an ad hoc solution utilizing gitbook could be migrated away from. Besides, calling out that example in particular is actually a little weird because this repository eschews all standard rust conventions for a normal build setup. It uses 6 custom shell scripts, makefiles, cargo, on top of explicitly calling `rustc` on each code example. Don't take that source code which builds the site as an example to follow.
That's great info, thanks! Yeah that repo would be much appreciated. I actually don't update nightly super often anyways so ~weekly update is perfectly fine.
Just to be accurate: #rust-beginner**s** :)
Almost certainly the inner layer can be inferred. The `tx` is passed to a function which probably specific the exact type (if its generic, there may be an inference problem), so the type of the `rx` is inferred in consequence. And `rx.iter()` returns a `T`, not an `Option&lt;T&gt;`; it blocks until there is content in the channel. If one thinks the type that is received there isn't obvious, I think the right thing to do is to type alias for what's being sent along that channel, because `(Vec&lt;usize&gt;, String)` says nothing about the meaning of the data, and `Vec&lt;(Vec&lt;usize&gt;, String)&gt;` is extremely noisy.
 EdenBSD: { url: "pkg+https://s3-us-west-1.amazonaws.com/freebsd-repos/edenbsd:amd64:10.2" mirror_type: "srv", signature_type: "PUBKEY", pubkey: "/usr/local/etc/ssl/certs/edenbsd.cert", enabled: true } pubkey: -----BEGIN PUBLIC KEY----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAw9aEhuBycMss3bfqml+R qocEDmwe8Y6/K9UiWnmds6ee7y4T1B0Ksq8Pn5jLq/jSji6R5agazKIF42w+rbOV MKYo/tEhsIyD/AF5ie2X+AvGa0wLCmydejnGSgcV6+1zQIb0mMrt51xGF8ipdnKM 0SM0HEVSg2mhbTiM/+nHwcKBx6MBzu6N/wxMiM6KtXQF6TREdM77QWVT8umuGRSK b6CiPkPfJ5lKfCFbUHfnGAxHngDtd91WCVb8fXKlEBoIs3J/MilJZf8LLR3bK1/+ 1xGjdZ/GFDx6vNHqHhCgwvoXSL00OrFU0/KQa6AWcrKCq/RlWtNxVdChKE1zH+0X GwIDAQAB -----END PUBLIC KEY----- There is also 10.1 repo. I'm going to update it tomorrow. 
Thanks, thats fantastic, got it working. Is this the best way to do what I'm doing (store a void pointer to my table within Python and create a binding for each public method that operates on the pointer)?
As others have said, the typical approach for memory management for libraries like this (in pretty much all languages that do it, from C to Rust) is to also expose a clean-up function that then gets called at an appropriate time by the user of the library, e.g. #[no_mangle] pub extern fn table_free(x: *const libc::c_void) { unsafe { drop(Box::from_raw(x as *mut Table)); } } (The `drop` isn't strictly necessary, it just expresses the intention more clearly than writing `Box::from_raw(x as *mut Table);`.)
eh, I don't even know the context and I exactly know what it's doing...
That's typical, yeah. Although, if you have multiple types on the Rust side, you may have an easier time (fewer segfaults/less memory corruption) by avoiding void pointers, e.g.: # one of these for each Rust type class RustTable(ctypes.Structure): pass table_p = ctypes.POINTER(RustTable) qt.table_new.restype = table_p qt.table_new.argtypes = [ctypes.c_char_p] qt.table_name.argtypes = [table_p] It is an error to mix-and-match different pointer types, and hence the Python interpreter will ensure that you don't pass the return value of some function like `notatable_new` (returning a pointer to some `struct NotATable { ... }`) to `table_name`. E.g. &gt;&gt;&gt; qt.table_name(ctypes.pointer(ctypes.c_int(1))) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ctypes.ArgumentError: argument 1: &lt;type 'exceptions.TypeError'&gt;: expected LP_RustTable instance instead of LP_c_int This sort of consideration may be especially helpful if you end up with functions that take multiple pointer types, to avoid mistakes around passing things in the wrong order, etc. --- Also, if you're interested in diving deep with Rust/Python-FFI, I've heard good things about the Python [CFFI](https://cffi.readthedocs.org/en/latest/) library (and I've enjoyed my occasional uses of it). For instance, this case could look something like: from cffi import FFI ffi = FFI() ffi.cdef(""" struct Table* table_new(const char* name); void table_name(const struct Table* table); """) qt = ffi.dlopen("libmything.dylib") table = qt.table_new("Test") qt.table_name(table) This will give type errors for passing the wrong pointers around like the `ctypes` version above, e.g.: &gt;&gt;&gt; qt2.table_name(ffi.new('int*', 1)) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: initializer for ctype 'struct Table *' must be a pointer to same type, not cdata 'int *' That said, using CFFI does mean one needs to translate the Rust definitions into C ones (which [may be automatic in future](https://github.com/rust-lang/rust/issues/10530)), and one doesn't much benefit from the functionality CFFI has for invoking C compilers, so it may just be easier to use the built-in ctypes.
It could look IMHO even better: let mut entries: Vec&lt;_&gt; = (0..nexamples).map(|_| rx.recv().unwrap()).collect();
I've added a usable support for mysql in [rustorm](https://github.com/ivanceras/rustorm)
I haven't used much Haskell, but the implementations of in-place quicksort I've seen rank among the ugliest code I've ever witnessed.
I have to say, i think the ugly example is actually pretty readable. A 30-second scan told me "it's getting some data, spinning up a worker thread for each data item, and writing out the results separated by newlines". Reading code is in large part a language-specific skill; consider that code looking like nonsense could be due to a lack of familiarity with the necessary constructs on the part of the reader, not an inherent issue with the code itself.
What do you mean by that? Type inference in function signatures?
Sorry, not signatures, I think that type annotations in signatures are nice, because they act as documentation. Take this snippet from the other comment: let mut entries = (0..nexamples).map(|_| { rx.recv().unwrap() }).collect::&lt;Vec&lt;(Vec&lt;usize&gt;, String)&gt;&gt;(); Having to tell the compiler that we are collecting `Vec&lt;(Vec&lt;usize&gt;, String)&gt;` is an unnecessary burden because the knowledge should already be there. 
I already had `#[repr(C))]` but just didn't include it in the snippet here. Thanks for pointing it out though. But, as others have pointed out, even that isn't enough, which seems totally silly to me. Anyone know `#[repr(C))]` on tuple-structs don't get the same layout guarantees as regular structs? Side note: even though it's undefined, it seems to be working in my tests.
Thanks for the suggestion. I'll experiment with it. But I also want the members to be public. The original goal was to be able to write things like: let v = Vec4(11, 12, 13, 14); easily without a constructor or anything and enable pattern matching like: let Vec4(x, y, z, w) = v; And making them private would lose that.
What implementation details? You're already handing out a mutable reference to the "internals". BTW: It's possible to implement `AsRef&lt;[T]&gt;` for it. It may be useful in some cases.
That's the idealized implementation, not the in-place one.
True. This kind of destructuring is convenient. Unfortunately, this doesn't work with arrays. You could add a method that returns the values as tuple. I had a go at it: http://is.gd/Ngpmhl
That's not the version that sorts *in place*. For that one, refer to [this](https://wiki.haskell.org/Introduction/Direct_Translation). It's far from the mathematical definition, and actually longer than the C implementation. 
/r/dailyprogrammer challenges and using gnu Emacs I have to say I'm getting very frustrated with the unintuitive standard library, having to unwrap stuff or match stuff and having to deal with the type checker. Really gets in the way of doing what I want by imposing so much boiler plate
Yes, it's an ugly implementation but write this 1:1 in Rust and I don't think that it looks better.
I've added that trick to collect's docs as of last week!
Migrating Octavo to [`bn`](https://github.com/libOctavo/bn). Small and fast, static sized (8192 bits), big numbers library.
Note that unwrap is usually a crutch until you get the time to do some actual error handling. If the type system slows you down, perhaps you're not working with, but against it?
I probably am but I've been working against it for nearly two months now... I feel like I need a CS degree to get why what I'm doing is wrong. 
Could you please link to where it says this? The best thing I can find is in [The Rust Reference - 8.1.5 Structure types](https://doc.rust-lang.org/stable/reference.html#structure-types): &gt; The memory layout of a struct is undefined by default to allow for compiler optimizations like field reordering, but it can be fixed with the #[repr(...)] attribute. &gt; ... &gt; A tuple struct type is just like a structure type, except that the fields are anonymous. Which implies to me that `#[repr(C))]` should work just fine on tuple-structs.
There is already f64::max/min and f32::max/min, which does what you probably expect (if one argument is NaN, return the other argument)
Working on my timeline widget and will hopefully open source it some time this week. [Here's a little vid of it](https://instagram.com/p/9NjrQAFeCn/?taken-by=mitchmindtree) if anyone's interested. I'll probably do a proper screen recording etc once it gets a bit fancier - I think it should make a great 3rd party widget example for conrod.
I actually think the Rust implementation would look very much like the C implementation, which is much better. (If you want to see an ugly sort implementation, look at [the one in the Rust standard library](https://github.com/rust-lang/rust/blob/master/src/libcollections/slice.rs#L961).)
However, with seL4 you can be 100% sure that your unverified binary blobs remain properly isolated, because your kernel can not be compromised. That "can not be" is the new thing: nobody had been able to say something as definitive without being dismissed as a wishful thinker before seL4 got verified.
Have you heard of [ramp](https://crates.io/crates/ramp)?
(FYI, your implementation of multiplication looks incorrect. It seems like 1&lt;&lt;32 multiplied by 1 will give 0, since it is doing elementwise multiplication of the limbs. Nested loops writing to a new array, not `self`, may work better.)
What a nifty tool. Doin' it. Thanks!
I'm now working on a bytecode compiler and interpreter for my as yet unnamed and unreleased Lisp dialect scripting language. I've never done this kind of thing before, so looking at the implementation notes of CLISP has been helpful.
This guy immediately starts talking about locks, race conditions, and libraries from the 80s, and is making the case that it 'too hard' which I have to say is ridiculous. The article is from over 10 years ago though so I wonder if he still feels the same way. It is no doubt more challenging but the failure is in thinking a multi-threaded GUI is just like a single threaded GUI with some locks. To do it right you would have to design around both concurrency and the overhead that it might incur when used at different levels of granularity, but that doesn't mean it can't be done. If we think about an OS that is running multiple programs in multiple window on multiple processes we can see that it is possible. The fact they can communicate at all means that they can work together, so in a sense it has already been done, it is more a matter of architecture than anything.
Yeah. It was completely incorrect and probably still is. There should be kind of improvement, but still it is probably buggy as hell. I will improve it in time.
The [Racket gui toolkit](http://docs.racket-lang.org/gui/) is successfully multithreaded, and manages this despite being implemented on top of existing non-multithreaded and non-thread-safe toolkits. It's hard, but it's certainly not impossible. [Here's a paper](http://www.ccs.neu.edu/racket/pubs/icfp99-ffkf.pdf) about the system, and how it enables cool new stuff
&gt; Any random thread should be able to update the GUI state of buttons, text fields, etc, etc. But why? To enable messed up application architecture and impossible to debug UI errors? seriously? I really don't think there is a need for more than one UI control thread. It's just asking from trouble, and not from a thread safety perspective. I just don't see why it would be useful. UI code should not be complicated. Having one separate UI thread with an event loop is preferable even when you don't have concurrency problems, because there is no reason ever to update elements of the more often then once per frame. Once per frame you collect the processed data from the finished data processor threads, and collect Input events, then proceed to update the UI. Multi threaded rendering is beneficial and a good thing, it's well understood and it's implemented in many places. It's not even too complicated if you have a good UI architecture. You just get immutable state data from the UI thread, you slice it up to tiles and there you go, you've got a multi threaded renderer that cannot possibly have problems with concurrency. The problem is more like that they introduced threading at the wrong place/ level. I don't think that this is a problem that needs to be addressed.
&gt;Updates from Rust Core The link in this section for the list of merged pull requests always 404's on me, is that the same as everyone else?
I usually do this: let mut entries: Vec&lt;_&gt; = (0 .. nexamples) .map(|_| rx.recv().unwrap()) .collect(); Very small change, maybe hairsplitting, but that's what I like the most. Or the iter variant: let mut entries: Vec&lt;_&gt; = rx.iter() .take(nexamples) .collect(); In other languages we have style guidelines that recommend one statement per line and those don't get bloated by the extensive use of fluent interfaces / method chaining. I think writing code like those two examples does resemble that recommendation the most.
Much better, thank you.
I think your second link should be [this](https://github.com/autumnai/cuticula).
Of course, thank you!
The change makes constant evaluation more *greedy*: It now tries to evaluate as far as it can, even when encountering a non-const function as long as no runtime interaction is required. I don't think it will cause trouble with `isize` / `usize`, because their lengths are fixed at compile time – and we don't compile multiplatform binaries AFAIK.
I see. Didn't realize you were one of the Rust contributors. Would making `#[repr(C))]` work with tuple-structs be particularly difficult or problematic? Edit: a quick [search](https://github.com/rust-lang/rust/search?q=repr) of the rust codebase itself reveals several examples of `#[repr(C))]` being used on tuple-structs.
This trick (EDIT: collecting into `Result`) blew my mind. I was writing ugly folds and then my life was changed forever.
 `impl&lt;'c&gt; CanFly for Sheep&lt;'c&gt;` The trait doesn't have any lifetime parameters. And you must introduce lifetime parameters which you are using in an impl within the `impl&lt;...&gt;` part (or in the `fn&lt;..&gt;` part if they're only for one function). They work just like type parameters.
I read the documentation, and I think I summarized it correctly. I'm just having difficulty working with rust since I'm new to the language IMHO. what's that self.0 part right there? I never understood that.
&gt; it seems overly complicated in rust. The feature is [under development](https://internals.rust-lang.org/t/placement-nwbi-faq-new-box-in-left-arrow/2789). Rust **doesn't have** placement new yet, but you can play with some of the already committed, in-development, parts.
&gt; I want to place the ring buffer itself at a certain memory address. So then any emplacement or insertion of any kind should preside within the address range of the shared memory. Okay, I have misunderstood you (honestly walls of text are pretty hard to read). Since you’re mentioning you have address of specific range in memory, you must have already allocated it. Then its a trivial matter of replacing my `struct RingBuffer` with struct RingBuffer{ low_address: *mut u8, // or whatever you want high_address: *mut u8, // or whatever you want head_address: *mut u8 // or whatever you want } and changing `make_place` to something along the lines of fn make_place(self) -&gt; Self::Place { self.head_address = self.head_address.offset(::std::mem::size_of::&lt;T&gt;()); // implementing out_of_bounds is left to the reader if self.out_of_bounds(self.head_address) { self.head_address = self.low_address } RingBufferPlace(self.head_address) }
awesome thanks. let me play with this and I'll post a gist or possibly a merge request against the relevant data structures! :D
It works fine for me (Chrome/Mac). It leads [here](https://github.com/issues?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2015-10-26..2015-11-02) (a search for `is:pr org:rust-lang is:merged merged:2015-10-26..2015-11-02`).
Uhh, I don't want to do self-advertisement but transactional memory may ease the pain of lock based programming, especially because there is a quite complex state that multiple threads may work on and but seldom collide.
Logged in and ya it's working.
That alias crate looks pretty neat. I'm sure there are some lifetime issues in some of my old code that could have been elegantly solved using this, instead of the eventual complete restructuring that I had to do to fix them (don't ask me for examples - this was a while ago; I can't remember details). The slice aliasing looks especially useful.
Consider adding a call to `Vec::with_capacity` instead of `vec![]`, as I wrote [here](https://www.reddit.com/r/rust/comments/3r5qo3/i_cant_decide_if_i_like_rust_or_not/cwm5ddi). edit: oh I think you meant the "collect into `Result`" trick!
&gt; so I'm not sure what it does. It's here: https://github.com/rust-lang/rust/blob/master/src/libcollections/vec.rs#L1215-L1241 Note that the trick I posted *also* uses the `FromIterator` impl for `Result`, which can be found here: https://github.com/rust-lang/rust/blob/master/src/libcore/result.rs#L931
Thank you for that.
Isn't Servo multithreaded in other places besides rendering?
I faced this feeling too. Some code was really nice, whereas other code read like syntactic soup. But sticking with it, reading code from different places, and getting more familiar with the standard library has minimised my feeling of "ugh, isn't there a better way of formatting this?". I think some of it is because common operations and library functions often err on the side of terseness. Until it's second-nature to see the semantic meaning behind those terse symbols, things can look overly dense.
Just published https://github.com/Keats/rust-jwt as my first crate (and first project other than the toy web app I made for an article a couple of weeks ago). Would love to have code reviews as it might not be super idiomatic and feedback on the API. On another note, is there a website that check if dependencies are up to date automatically like https://david-dm.org/ ?
how does it compare to python in terms of implicit structure? is it just the whitespace delimitation that bothers you? user defined operators are definitely a mixed bag
I like the solid theory in rust, but sometimes I agree that it can feel a bit like banging your head against the wall and end up with some really clunky stuff to appease the borrow checker gods. Just today I ran into what would be stupidly simple in any language with the usual mutability free for all rules, or I would've written it differently in a functional language. But in rust, the mutable way seemed reasonable enough until I ran in to an inner loop trying to borrow again on a mutable reference from the outter loop, and me knowing no harm could be done in doing so, but the borrow checker complaining non-the-less. It was a frustrating moment for sure. Then again, maybe if you stick with mostly functional programming methods things are much smoother. I'll be trying to rewrite that chunk in a functional way in the near future and see how it goes since I want to parallelize it anyways.
One workaround might be to use `if let` instead: if let Some(set) = hash_map.get_mut(&amp;key) { set.insert(value); } else { let mut set = HashSet::new(); set.insert(value); hash_map.insert(key, set); } Edit: ahhh this seems to have the same issue. How about this instead: if !hash_map.contains_key(&amp;key) { let mut set = HashSet::new(); set.insert(value); hash_map.insert(key, set); } else if let Some(set) = hash_map.get_mut(&amp;key) { set.insert(value); } If you want the branches to be exhaustive, I guess you could unwrap in the else instead: if !hash_map.contains_key(&amp;key) { let mut set = HashSet::new(); set.insert(value); hash_map.insert(key, set); } else { hash_map.get_mut(&amp;key).unwrap().insert(value); } Final edit: disregard all this and (as /u/ryeguy and /u/annodomini recommend) use [entry](http://static.rust-lang.org/doc/master/std/collections/struct.HashMap.html#method.entry)! Forgot about this heh.
The best way to do this is to use `entry` followed by `or_insert` or `or_insert_with`: - http://static.rust-lang.org/doc/master/std/collections/struct.HashMap.html#method.entry - http://static.rust-lang.org/doc/master/std/collections/hash_map/enum.Entry.html
This is a job for... the [`Entry` API](https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.entry)! An [`Entry`](https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html) represents a place in the `HashMap` that a value could possibly exist for a given key. It may be `Occupied`, in which case there is a value and you can retrieve that, or `Vacant`, in which case there is no value, but you can use that `Vacant` entry to insert one. There are the convenient methods `or_insert` and `or_insert_with` on `Entry` to allow you to place something into a `Vacant` entry and return a mutable reference to it to allow you to then do your modification to the underlying element. The usual way to do solve your problem would be something like: hash_map.entry(&amp;key).or_insert_with(HashSet::new).insert(value) Note that the the oft-requested feature of [non-lexical borrows](https://github.com/rust-lang/rfcs/issues/811) may allow your original code to work (or the `if let` based version proposed by /u/mitchmindtree), but you would still have to do two hash lookups to insert something; along with fixing the problem with the borrow, the `Entry` API allows the `HashMap` to only do a single lookup, keep a reference to the bucket the entry would be stored in if it were found, and insert it directly there.
Probably not useful in this particular case, but has helped me with lifetime issues and match branches: The `matches!` macro (a crates package) and an if-statement. It only works if you know you're never going to need the contents of the match, but if you just want to do different things to a mutable enum based on the kind, it's pretty convenient.
This (referring to the original solution in the parent comment) gives you the same error ([playpen](http://is.gd/zwVOR7)): &lt;anon&gt;:12:9: 12:17 error: cannot borrow `hash_map` as mutable more than once at a time &lt;anon&gt;:12 hash_map.insert(key, set); ^~~~~~~~ While the others may work, they are pretty cumbersome and require multiple lookups compared to the [`Entry` API](https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.entry) (described in some [other](https://www.reddit.com/r/rust/comments/3racik/mutable_lifetimes_are_too_long_when_matching_an/cwmb9vo) [comments](https://www.reddit.com/r/rust/comments/3racik/mutable_lifetimes_are_too_long_when_matching_an/cwmbbp0)).
I don't mind whitespace to delineate blocks, actually (at least not usually, it can be overdone if you have a *lot* of rightward drift and nested blocks). What I'm more frustrated with when trying to read Haskell (and I'm not very good at it, I admit) is that parentheses appear to be anathema to Haskell programmers, and they will omit them at every opportunity even at the expense of structural clarity. It's almost as though it's trying to make up for Lisp. :) (And I don't mean to denigrate Haskell in particular. There's a lot of syntactic decisions in Rust that I disagree with, but I'm personally happy that it generally errs on the side of explicitness rather than implicitness. Different use cases may call for different decisions; there's no single right answer.)
Perfect!
`#[repr(C)]` doesn't work on tuple structs? *Why?* Not only are there already plenty of libraries transmuting references to newtype references (alias and wom, for example), but tuple structs are just syntactic sugar for regular structs, so it's pretty uncontroversial what it should do.
Hmm.. yeah, that's nice. The trouble is that instead of `(0..100)`, you have a large chain of iterators. but one can just do let entries_iter = ... iterator chain; let mut entries = Vec::from_iter(entries_iter);
I made a short comment arguing against unwrapping [here](https://www.reddit.com/r/rust/comments/3q3ui8/learning_is_it_best_practice_to_always_check_an/cwbxxyt) (see also [this comment thread](https://www.reddit.com/r/rust/comments/3r5qo3/i_cant_decide_if_i_like_rust_or_not/cwlbdtm) where I try to do some unusual error handling and /u/burntsushi posted better solutions). It seems that the Rust book [incorporated the article from /u/burntsushi](https://doc.rust-lang.org/book/error-handling.html) so you should just read it I guess. Basically instead of unwrapping you should use `try!` on 95% of cases. This means that instead of returning `T` your function should return `Result&lt;T, ErrorType&gt;` (where `T` is what it would usually return if there's no errors, and `ErrorType` is usually an enum that represents each possible error condition). It isn't *that* much boilerplate if you always implement the proper `From` instances to convert one error type to another (actually.. we could say that having to manually implement `From` is a boilerplate, but at least you do so once for each type)
Comments like this make me feel better. Just knowing Rust syntax gets to be less of a battle the more you deal with it makes it easier to stick with it. 
This is one of those times where I feel like I'm gonna get stuck constantly learning this language. I'm a Go guy right now, and it took maybe an hour for me to completely grasp it's syntax. I feel like it's gonna take a year to grasp Rust's. 
`f64::min` and `f64::max` are just wrappers for the standard C library `fmin`/`fmax` functions, and their behavior is identical to the standard C calls. The `f32` methods are wrappers for `fminf` and `fmaxf`. What is your use case where a function with a weaker contract is better? I assume it's for speed? I'm curious how many instructions you can save by allowing different behavior for NaNs.
I think this was the wrong decision too. But I'm willing to look past syntactical shortcomings, the language has a lot of cool features that work well together.
I would just like to throw out that this is a 10 year old article.... things have changed a bit.
I really don't see any point in updating obsolete versions; I mean, sure, they're interesting from an historical perspective, but they don't really have any practical use. Just seems like a waste of time. ^^^*cough*/r/playrust*cough*
Deleting a single character can fix your problem. Just change fn race(&amp;mut racer: Box&lt;Sprinter&gt;) { racer.sprint(); } Into: fn race(mut racer: Box&lt;Sprinter&gt;) { racer.sprint(); } However, I'm not sure if that's what you're trying to do. It may also be that you want this: fn race(racer: &amp;mut Sprinter) { racer.sprint(); } fn main() { let mut racer: Box&lt;Sprinter&gt; = Box::new(UsainBolt::new()); race(&amp;mut *racer); } The first will just pass ownership of the `Box&lt;Sprinter&gt;` into `race`; now that function is responsible for cleaning up, or passing it along to something else that will do so. The second will pass a mutable reference (borrow) to the `Sprinter` into `race`, without actually transferring ownership. `main` will still own it. I think the confusion you're having is due to a few implicit [coercions](https://doc.rust-lang.org/nomicon/coercions.html), which are there to make it a lot more natural to use different kinds of references without littering the code with a lot of things like `&amp;mut *`, but may make it a bit harder to have a good sense of what to do when they don't apply. One is [`Deref` coercion](https://doc.rust-lang.org/book/deref-coercions.html). `Deref` is a trait to allow implementing smart pointer types; `*foo` actually expands to `foo.deref()` if `foo` implements `Deref`. This is useful if `foo` is a smart pointer, such as a `Box`, `Rc`, `Arc`, or the like, which pass around ownership or shared ownership; most things that operate on something by reference don't actually need to take ownership, so they can take the universal borrowed type `&amp;X` or `&amp;mut X`. But having to do the explicit dereference and borrow of the underlying value would get tiresome, constantly passing `bar(&amp;*foo)`, so there is a coercion known as "`Deref` coercion" which says that if type `T` derefs to type `U`, then you can pass a `T` to a function that expects a `U` and the compiler will figure out that it needs to insert the implicit call to `.deref()` until the types match. In fact, it will insert as many calls to `.deref()` as necessary, and then possibly borrow the result (add an `&amp;`) to get an appropriately borrowed value. The other thing that frequently helps you out is that [method calls](https://doc.rust-lang.org/book/method-syntax.html#method-calls) automatically take the `self` argument as an `&amp;self`, `&amp;mut self`, or as an owned `self`, without having to explicitly add the `&amp;` or `&amp;mut` to produce the reference. This is because it would be very cumbersome to write any methods that needed to borrow `self` otherwise, as `(&amp;foo).method()`, since method calls have higher precedence than the reference operator, so `&amp;foo.method()` means a reference to the value produces by `foo.method()`, not `method()` called on a reference to `foo`. Between these two facts, if you use methods rather than bare functions, you can write things like: struct FooBar; impl FooBar { fn new() -&gt; FooBar { FooBar } } trait Baz { fn quux(&amp;mut self) { } } impl Baz for FooBar {} let mut foo = Box::new(FooBar::new()); foo.quux() The compiler will try out various different combinations of the following until it finds something that typechecks (I may have the order wrong, but the basic idea is the same): Baz::quux(foo) // doesn't typecheck, argument is of type Box&lt;FooBar&gt; rather than &amp;mut Baz Baz::quux(&amp;foo) // doesn't typecheck, argument is of type &amp;Box&lt;FooBar&gt; rather than &amp;mut Baz Baz::quux(&amp;mut foo) // doesn't typecheck, argument is of type &amp;mut Box&lt;FooBar&gt; rather than &amp;mut Baz Baz::quux(*foo) // doesn't typecheck, now argument is of type FooBar rather than &amp;mut Baz Baz::quux(&amp;*foo) // doesn't typecheck, now argument is of type &amp;FooBar rather than &amp;mut Baz Baz::quux(&amp;mut *foo) // typechecks, argument is of type &amp;mut FooBar which coerces to &amp;mut Baz If you use bare functions instead of methods, most of it will work, but it won't do the automatic disambiguation between `self`, `&amp;self`, and `&amp;mut self` for you. This means that you need to do it explicitly yourself; and once you do that explicitly, you also need to explicitly add in the dereference that gives you the `FooBar` out of the `Box&lt;FooBar&gt;`: fn zot(_: &amp;mut Baz) {} zot(&amp;mut *foo) The other thing that is likely catching you up is the distinction between: fn frob(&amp;mut x: T) and fn frob(x: &amp;mut T) The first one is a pattern match. It says "`T` is a reference; automatically derenference it and give me a mutable binding the the value inside of it". This can be useful for unwrapping wrapper types; for instance, if you have a type `Wrapper` but only care about manipulating the value within it in your function, you could write: struct Wrapper&lt;T&gt;(T); fn inc(Wrapper(x): Wrapper&lt;i32&gt;) -&gt; i32 { x+1 } inc(Wrapper(21)) This will take `Wrapper&lt;i32&gt;`, but just bind `x` to the inner `i32`. Likewise, you can do the same thing with references. If you want to take an `&amp;T` reference, but just use the binding to refer to the inner value rather than the `&amp;` reference, you can do so by writing `fn(&amp;x: &amp;T)`. In your example, you were trying to destructure a box as an `&amp;` reference, but they are different things (despite all of the coercions listed above which might appear to make them seem less different); the confusion might have been due to the coercions, or it might be due to confusion over type the use of `&amp;` in a type declaration (after the `:`), vs. in destructuring (before the variable name, before the `:`), vs. in an expression to reference a given object. Whew, that was a lot, and it's late here, so I hope I got all of that right!
No, you're passing a pointer to an array. Just because you borrow an array doesn't automatically make it a slice. Now normally, the compiler would just coerce from `&amp;mut [T; 4]` to `&amp;mut [T]` for you. In this case it *can't* because of your *actual* mistake: `buf` has the wrong type. Specifically, `T::Item` for a slice iterator over `[i32; 10]` is `&amp;i32` **not** `i32`. One solution is to correctly define `buf`: fn main() { let dummy = &amp;0; let data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; let buf = &amp;mut[dummy; 4]; let mut slide = Slide::new(data.iter(), buf); } 
I've never seen any ORMs in Rust before. How does its usage compare to ORMs in other languages?
Can you elaborate on what "metagenomics binning" is, and what makes it so computationally intensive that it needed to be written in C++ to begin with?
Note that if you feel like you're asking stupid questions, there exists a #rust-beginners channel where stupid question are actively encouraged. :)
Ah, I didn't know this was a goal. You need to be copying the data then, if you don't want undefined behavior.
Before I submitted I just realized how long this got. I'm still wrapping my head around all this so apologies if it's a bit rambling. --- I'm just a layman -- I help university researchers wrangle software solutions for their grants but I'm not a domain expert, so take this with a grain of salt. Current gene sequencing machines can produce billions of short strings which need to be quickly matched (sometimes approximately) against reference genomes to identify what organisms are in a mixed sample. This is an increasingly popular research technique for developing new pathogen detection methods, for example. Computationally, this amounts to offline querying of a database (usually 100GB-1TB of strings) with hundreds of millions or billions of queries in the form of these short-ish nucleotide strings, and cataloging every organism in the database where a(n approximate) substring match is found. In the end, this results in assigning each query sequence a list of potential "taxonomic IDs" that they match against (http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi), which can be parsed by other NCBI-aware tools to report on the makeup of a sample. EDIT: "metagenomic" meaning addressing many genomes and looking at the relations between them, not just within them, and "binning" to identify which bins (or taxonomic IDs) can be mapped to an individual read sequence. There's a wikipedia page on the term but it's garbage as far as I can tell. Some context: Basically, gene sequencing has started using biological techniques for pulling apart DNA which result in millions or billions of short (50 bytes/base-pairs to 1000 bytes/base-pairs) strings of DNA or RNA sequence reads that are output by these massively expensive machines. If you've done the legwork in advance to isolate each organism, you already know what organisms are represented by these short "reads" (essentially substrings of the genome). In these situations, there are a series of computational challenges that mostly relate to understanding what genes or strains are present, and producing analyses of the genetic makeup of the organism in that specific sample. A lot of this is done in Python because you're often looking at &lt;5GB of reference sequence to "align" against. If, however, you've just run a brute force sequencing on a random/from-the-wild biological sample (feces, soil, saliva, etc.), then you have no clue what organisms are present. This is useful when you have a tighter turnaround, as it can sometimes takes weeks or months to pull individual types of organisms out of a sample, and that's if they can be lab-cultured at all. This is a situation common when trying to identify emerging pathogen threats in populations -- basically we need to figure out what the heck's DNA ended up in our sample. So there's this need to match these short-ish strings against reference strings that may be millions or billions of bytes long and see if they're present as a substring of that reference. And do so for all "known" genomes (hundreds of GB in a nicely curated database). Thankfully, there's been a lot of quality research in this area of how to do some of this well (if anyone's interested in some slides and materials on the subject, I'd recommend Ben Langmead's teaching resources: http://www.langmead-lab.org/teaching-materials/). Also thankfully, there are a lot of libraries that provide some of the basic building blocks for these data structures and algorithms (SeqAn in C++ land although it's a bit long in the tooth and crusty in places, and rust-bio in Rust land, which while limited I'm enjoying so far). So I'm mostly trying to write high-throughput parallel glue code for the rust-bio library along with some secret sauce that might end up in a paper at some point. We'll see how it goes. Since my awful solution will be in production soon (ugh), I'm mostly experimenting and using this as an excuse for learning more Rust beyond the dining philosophers problem :). EDIT 2: Why not use MapReduce (or whatever massively parallel cloud magic) you ask? Academia. Sigh.
You can do it from the command line...
A question, why is it Iterator-like instead of using actual iterators? The API doesn't match?
There's already an answer on this thread, but I wanted to just comment on the "you can treat a `Box&lt;T&gt;` as if it were `T` and it just works". Refer to [th Deref chapter of the Rust book](https://doc.rust-lang.org/book/deref-coercions.html), specially the section "Deref and method calls". And if you look at the docs for [`Box`](https://doc.rust-lang.org/std/boxed/struct.Box.html).. you see this: &gt; impl&lt;T&gt; Deref for Box&lt;T&gt; where T: ?Sized &gt; type Target = T &gt; fn deref(&amp;self) -&gt; &amp;T This means that `&amp;Box&lt;T&gt;` coerces to `&amp;T` (this is a deref coercion, as explained in that chapter), and because of the method lookup procedure, calling a method on the boxed value that the `Box` itself doesn't implement, ends up calling it on the boxed value (the compiler automatically inserts `*` as needed, to make your code typecheck). Note that this mechanism isn't applied when you pass a value to a function: if the function expects a `T` parameter, you can't pass it a `Box&lt;T&gt;`. (to be more complete, refer to [this Stack Overflow answer](https://stackoverflow.com/questions/28519997/what-are-rusts-exact-auto-dereferencing-rules/28552082#28552082), but it may be a bit confusing)
I was thinking code like match map.get_mut(&amp;key) { None =&gt; {map.insert(&amp;key, default_val); map.get(&amp;key) }, Some(val) =&gt; val } but I just noticed that this wouldn't compile and is actually the original question of the thread! I can't think of any non-trivial code that could replace the usage of `entry` right now. Ignore me for now, /u/llogiq! 😄
I was actually struggling with the same problem as OP and happened on this post completely by accident this morning. For me, it was a case of not knowing what I was looking for. I searched the documentation of `HashMap`for the word "update", "replace" (is there but unstable), etc but found nothing useful and so assumed the API was designed to necessitate removal and then addition of a key for updating. I strongly suspect adding a new example for this sort of behaviour to the top of the `HashMap`/`HashSet` pages would do the trick. I might submit a PR a bit later to do just that, as it certainly would have helped me.
&gt; I don't want to do self-advertisement Do you have an STM crate for Rust? I'd like to check it out of so.
Yes, but it's being actively discussed all over the internet right now.
Same. Would love to see more people try to tackle it, so we can compare/contrast different approaches!
Eh, the Rust type signature isn't so bad in this case (it's certainly not that different to the Haskell one): fn qsort&lt;T: Ord&gt;(array: &amp;mut [T]) { let len = array.len(); if len &gt; 1 { let mut i = 0; { let (pivot, rest) = array.split_at_mut(1); let pivot = &amp;mut pivot[0]; for j in 0..len - 1 { if rest[j] &lt;= *pivot { rest.swap(j, i); i += 1; } } } array.swap(0, i); qsort(&amp;mut array[..i]); qsort(&amp;mut array[i + 1..]); } } (Don't get me wrong, Haskell's type signatures are often nicer, but this one is not such a case.)
It depends. What does your code look like? mod foo; means one of two things: ./foo.rs ./foo/mod.rs That's it. mod foo { mod bar; }; means that `bar` is either ./foo/bar.rs ./foo/bar/mod.rs Repeat for any particular tree structure your module hierarchy is in.
What I want is: ./main.rs ./other.rs ./utils/fib.rs Where // file: ./main.rs mod other; use other; And // file: ./other.rs use utils::fib::{myfunc}; And // file ./utils/fib.rs pub mod utils { pub mod fib { pub fn myfunc() { } } } 
The disconnect here is in `./utils/fib.rs` By saying `mod utils` here, you're saying that the current module, `utils`, has a submodule, `utils`. Remember, `mod` declares a submodule. Add pub mod utils { pub mod fib; }; to `main.rs`, and change `./utils/fib.rs` to say pub fn myfunc() { } and all should be well.
&gt; It actually looks like I have to put all the mod declarations in main.rs You don't strictly have to, but it can be a nice way of doing it.
Can't a module be self-contained? 
&gt; Can't a module be self-contained? I'm not sure what you're asking here, exactly. Could you elaborate a little bit?
rustc is only told where the root .rs file is. All other .rs files have to be found through mod declarations in other .rs files. If you put `mod utils` inside of `utils` how would Rust know to look in the `utils` module order to know to look for the `utils` module? If you want Rust to find your `utils` module, the `mod utils` has to be put in a higher up module. The graph of the module structure is a tree where there are no cycles and every module, aside from the root module, has a single parent module that declares it.
I mean, can't I put all the code that defines a module - the code and the module structure - in one file?
You can, but I think the disconnect is in what /u/retep998 replied with. Just because everything can go _in_ the module doesn't mean that you don't need to tell Rust where that module is, which means some sort of annotation in a parent module. IE, this module _is_ entirely 'self-contained' in the sense you're mentioning. You just need to tell `rustc` where to find it.
Thanks. I think this is my answer. I am used to other languages (e.g. Java or Haskell), where the compiler finds modules via the naming structure used in the `import`, and I was expecting to be able to just `use` a module and have it work as long as the file at the location declared a `pub mod`.
How would you go about effecting this small change? https://internals.rust-lang.org/t/perfecting-rust-packaging-the-plan/2767/12
Servo is just a layout engine. Strictly speaking, it does use threading in more places besides rendering, but IMO Layout can be considered as part of the rendering.
That's a bit unclear for me, I've seen it being described as a browser engine which is more than just layout. so Servo seems to contain a little bit of UI code (which is a necessity for an interactive program).
Yeah, it gives a nice at-a-glance view of the structure of code.
Just some words. The unit of compilation in Rust and the most important building block of large programs is the crate, not the module. Each crate has its own `Cargo.toml` (and only one) and is composed of a number of modules. Those modules are all declared in the root of the crate (your `main.rs`). In order to divide your program in self-contained pieces, you don't create modules - you create more crates. They can live in subdirectories of the same git repository if you want (each one of them will have its own `Cargo.toml`), or in new repositories. When you add dependencies on your `Cargo.toml` (and corresponding `extern crate ..;` on your `main.rs`), you're depending on other crates, not on modules. Modules aren't self-contained because your crate share a namespace - so you can have something on a module refer to something in another module. Each crate is compiled all at once, and each of them produces a binary (unlike, say, C, where each file is compiled separately). Compiling your program consists in compiling each crate separately, and linking all your crates into a single binary. Linking in Rust is usually done statically (except when you link against the libc). [This book chapter](https://doc.rust-lang.org/book/crates-and-modules.html) explains a bit the situation with crates and modules. The [guide on crates.io](http://doc.crates.io/guide.html) also talks about the file layout.
[removed]
Uhm, you can have multiple build targets (such as multiple binaries), is each target its own crate? That seems confusing, because they may otherwise share files. But anyway, normally, when you want to have something that's completely self-contained, you put it in another directory with its own `Crate.toml`. That way you can reuse it in another project easily (just having it as a dependency).
Yes, each binary is a crate. A crate is a compilation unit, so you have one crate per output. &gt; when you want to have something that's completely self-contained, Absolutely. That's why the 'one lib' part is important.
Right. How about matching on `if contains_key { get } else { insert; get }` ([playpen](http://is.gd/CLQanp))? That might be something someone new to Rust might write. (I think better documentation is easier to do and will be more effective, though.)
Another idea I had for a while: a new type of web framework with plenty of compile time checks. One thing Rust is really good in is detecting errors at compile time. I want to have this kind of security in all aspects of my project, but web frameworks today work pretty much the other way around. There are too many things that can go wrong and most of them are only detected at runtime -- if at all (which is the problem with runtime error detection). Even web frameworks in Rust today aren't really helpful. I want a Rust web framework that checks&amp;compiles my HTML, JS^* and CSS/SASS for me. Furthermore I don't actually want to code in JS, but in Rust itself. There are already some small crates with nice ideas, like - [maud](https://github.com/lfairy/maud): Compile time HTML templates - [glassfull](https://github.com/kmcallister/glassful) which let you write shaders in Rust - and of course some projects to compile Rust to JS I don't want a web framework that is about copying and modifying strings. I want an intermediate representation with a lot of semantic information to run checks on. This representation of the website is then compiled into HTML, JS (or web assembly) and CSS -- possibly with a lot of optimizations (minifying code, inlining small images, ...). I hope my explanation is enough to get a rough idea what I'm talking about. Sadly, I never really worked with big web frameworks, so I think I'm really not the person to design a web framework on my own. 
Ah, nice :) I should use Rust much more often. At first I thought Rust needs the same ugly and complex type signature as Haskell - my bad. processArray :: (IArray a e, IArray b e, Ix i) =&gt; (forall s. (STArray s) i e -&gt; ST s ()) -&gt; a i e -&gt; b i e Thank you, [dbaupp](https://www.reddit.com/user/dbaupp) for the example and clarification.
Thanks! By "third-party widget", I just mean a type that implements conrod's `Widget` trait that is developed entirely in an external crate (as opposed to conrod's included widgets). It's just a nice affirmation that we're exposing everything a user might need to compose their own (quite complex) custom `Widget`s (and in turn take advantage of conrod's layout, scrolling, etc).
Thanks for clarifying! It seems that Spidermoney isn't "just" a Javascript engine like I thought.
Yeah, or `if { !s.contains(key) } { s.insert(key) }`.
Theoretically yes, the benefits would be fewer kernel panics, if done properly. The problem is it would take A LOT of work. Even if everybody involved in the linux kernel development was interested and working on it (which, of course, would never happen) I think it would take months or even years to get the type and borrow checkers happy. And that's not counting the redesign phase that would also consume a long long time. My view on it: it's more likely that we see redox or another rust kernel becoming mainstream than the entire linux kernel being rewritten in rust. That isn't to say that a few linux modules won't be implemented in rust, that is plausible and actually quite likely to happen in a few years time.
I mean, rust has a close analog for nearly everything in C, I'm fairly sure that *technically* one could make a tool that automatically translates all but a few edge cases to rust. (Off the top of my head, the only issues that come to mind are logic in preprocessor files, preprocessor macros, and unions) The kernel is huge so those edge cases would take a lot of work, but it *could* be done by a small team in a relatively short period of time. Naturally this approach has absolutely no advantages. You would be trading good C code, for largely unreadable, and completely unsafe (a technical term meaning that we sidestep the normal restrictions the rust compiler places on us, in the process giving up all the advantages of rust), rust code. The other approach that could be taken is hand translating the entire kernel, this is a herculean task that would take many programmers many years. In the end you would end up with not very good rust code (since it was all designed with C in mind), that is relatively untested, and already years out of date compared to the C linux kernel that progressed without you. The benefits of this are... also almost none. I mean you know that any memory issues are because of unsafe code (which should be a small subset)... but at the same time you probably introduced a bunch more bugs in the translation process... so...
Is this still an issue if you use your own `Compound&lt;A, B&gt;` structure instead of the tuple?
My general impression is that it would be easier to go the other way, compile rust into C. It would only be a subset of C that could really compile into safe rust code, and what's the point if we litter unsafe blocks all over the place.
Unfortunately, changing the contract of the existing functions is probably not going to happen at this point, since it could silently break existing code, and there's no good way to know if code relies on the current contract. The faster versions would have to live in an external crate, or have different names if they are in the standard library.
&gt; Yeah, it's not that clear, but there is no UI code in servo. Now that's just not true. Servo's DOM lives in what's called the "script thread," but it is written in Rust and just exposed to SpiderMonkey through bindings. SpiderMonkey is also responsible for garbage collecting it. SpiderMonkey does not include stuff like text entry widgets, or any understanding of turning OS events into DOM events. That's all Servo.
The current implementation may involve an ugly hack, but the idea itself is elegant and should be available in some form.
Sounds good. Optimisers may be able to do it, but it's not guaranteed. I imagine this could generating rather large pre-computing arrays during compilation for example. &gt; as long as no runtime interaction is required. I suppose this means, at least, no memory allocation (and thus, unfortunately, no `String`/`Vec`). Are there other specific limitations you would know of?
I've been trying to do exactly that for the past 2 days, but I can't seem to just coerce the type system to let me get past this one thing. It seems like there's no way to properly model a safe shared memory region across processes in rust, so this is kind of the only way. If I give a pointer I get: cannot move out of dereference of raw pointer when I try to dereference it yield the actual ringbuffer that is not initialized at that address. If I use references, I get: cannot move out of borrowed content
That's awesome! /u/gclichtenberg and I have been working on [Ares](https://github.com/TyOverby/ares) and I'm super interested in bytecode compilation and interpretation. Up until yesterday, Ares' evaluation model was that it was a recursive AST-evaluating interpreter. Dead simple to implement, but not friendly for optimization or further feature work (I want good debugging, stack overflow detection, stack traces, and delimited continuations). Yesterday I merged a commit that changed the evaluator to use a stack of evaluation-states. However, it still interprets the AST in order to modify the evaluation stack. That said, I think it's now possible to add a bytecode interperter. I'd love to chat about this; hopefully we can help each other improve both projects!
The Rust module system/file directory hierarchy is...oddish, and admittedly a little frustrating, but works pretty well when you get a handle on it. The closest I can come to what you want there is: $ find src -type f src/main.rs src/other.rs src/utils/fib.rs src/utils/mod.rs (Note the addition of utils/mod.rs.) The file contents are: // src/main.rs mod other; mod utils; fn main() { println!("Hello, world!"); } Here, the addition is "mod utils;". Rule o' Thumb #1: Every top-level module has to be pointed to by the top level source file. // src/other.rs use utils::fib::{myfunc}; This is the same as yours. // src/utils/fib.rs pub fn myfunc() { } This is changed to remove the "pub mod utils" and "pub mod fib", due to Rule o' Thumb #2: modules can be created by a "mod {...}" in a file or by file system hierarchy. Don't use both. As Steve says below, &gt; By saying mod utils here, you're saying that the current module, utils, has a submodule, utils. Remember, mod declares a submodule. And then, there's one additional file: // src/utils/mod.rs pub mod fib; This is the root file for the utils module and the contents just a) point to the fib module, and b) re-export it as public.
 &gt; return new T(std::forward&lt;Args&gt;(args)...); Aaaahhhhhh! "new"!!! You should never use new! Ever, ever, everevereverever! Evil! EEEVIL! Engage shunning mode now! Begin pod-person intruder alert: "EEEEEEEEIIIIIIIIIIIIIIII...!"
That's true, but I'd still wouldn't consider that UI code, but a part of the UI implementation. This depends on your interpretation of what is UI code, That's why i wrote that it's an oversimplification. 
&gt; Is there any way at all to put a struct at a certain address? This is why `ptr::write()` exists, plus for a few other reasons as well. use std::ptr; initialize_at(p); ptr::write(p as *mut RingBuffer&lt;u64&gt;, RingBuffer::new()); // This re-reffing pattern doesn't move onto the stack; it just reifies the pointer into a Rust reference. let buf_ref: &amp;mut Ringbuffer = &amp;mut *p; However, you're going to run into at least one problem that is going to be rather hard to solve: All Rust collections types use an allocator that is unaware of shared memory. So one of the processes will not be able to access any data in the collection because it will be in the other process' private address space. This will appear as a good old segfault at runtime, I think. I can't tell what `RingBuffer` type you're actually using, but if it uses `Vec` internally, you're going to run into this problem. However, if it can work on a slice, you can give it a slice from some of that shared memory. If you have access to the internals, you can refactor it to use an array. If you've already covered this and I'm lecturing you on stuff you already know, feel free to stop reading here. However, you won't be able to pass anything that uses allocations, so no `str`, `String` or `Vec`. Pure `Copy` data should be fine, but `&amp;'static` anything is a no-no since it also points to a private address space unless you create it from the shared memory. If you restrict it to a specific type that only uses primitive data, you should be fine.
Just to be clear, by far the lion's share of the work on Ares is /u/tyoverby's doing!
Its not a LISP but I have made a [bytecode interpreter](https://github.com/Marwes/embed_lang/blob/master/vm/src/vm.rs) for a [custom language](https://github.com/Marwes/embed_lang). Might be of interest though I will warn you that the handling stackframes could be improved as it is rather easy to mess up right now. Nice explanation of the PR as well, looks like quite intuitive.
I had already been using write; possibly I should have indicated that initialize_at was calling write. The mutable pointer to reference transform that you're doing looks like a viable approach. No, ring buffer is managing data by using a pointer into some field of memory and keeps track of where things are with some atomic usize items. I changed initialize at to write the ring buffers' meta data into the shared memory space, so exactly the runtime segfault that you are talking about is what I am trying to avoid. Let me just try using that dereference to reference trick. Ultimately, I have to pass buf_ref to another type's initialization, effectively managing buf_ref with an atomic reference count; I'll have to dereference even that reference, and in the past that had been giving me trouble. 
In fact, as I had suspected, I get "cannot move out of borrowed content" let buffer : &amp; Buffer&lt;usize&gt; = &amp; (*(p as * mut Buffer&lt;usize&gt;)); let (prod, cons) = new(*buffer); it doesn't matter whether I try and dereference the reference here at the new, or within the "new" function somewhere, because that error is an outcropping of the type. The language designers meant it to be this way. Anyway, I don't know how to continue.
https://github.com/conradkleinespel/rustastic-password
Ah, I misunderstood your needs. In this case, you'll want to do `let buffer = ptr::read(p as *const Buffer&lt;usize&gt;);` which reads a `Buffer&lt;usize&gt;` onto the stack. No need to screw around with references.
For your first question, you can do this: let path = format!("/{}", req.url.path.join("/")); For your second question: let error = status.unwrap_or("unknown error!".to_owned()); let data = if path.starts_with("/users/") { format!("API Error -- {}", error) } else { format!("Other Error -- {}", error) }; By the way, perhaps are you looking for the [`router`](http://ironframework.io/doc/router/index.html) crate to manage routing instead of doing it by hand?
Thanks I'll definitely head there first in future!
yeah I literally just thought about changing the library that I use to accept Arc&lt;&amp; RingBuffer&gt;; then I naturally had to take into consideration the lifetime of the managed resource, and it seems that I can get it compiling and I've moved on to a different source of errors. :D
Well, yes, that's correct. I thought UI code included the underlying toolkit, as well as the client code.
I fixed the whole thing in a different resolution. Thanks for the effort!
Thanks, that was a great idea :)
I don't know if it will fit the bill, but git version of mioco does have manual scheduling on top of async mio primitives. So you should be able to implement any scheduling policy. The problem is: it was requested, and added very recently and some alterations might be needed for real-life applications. Also, I don't know how coroutines and mio compose into your existing stack.
Wow. You're amazing! Can you please self-advertise more frequently? I've read the paper by Simon Marlow on this a while ago, and thought, one day I'll try to port this to Rust. And here it is. This is just great…
Oh I agree in that Go is stupidly simple, but that bit me in the ass in a larger project one too many times where Rust's stronger typing thanks to generics, tendencies towards functional code, no gc, saner dependency management, and a few other things would've been god sends. Go was great until that day that it wasn't. That day was about 10Kloc in of a 100kloc web app. 
(I'm the author of [carboxyl](https://crates.io/crates/carboxyl), a functional reactive programming library for Rust.) Just in this thread I discovered that there is an implementation of software transactional memory (STM) now. As soon as I find the time for that, I am going to start converting the internals of my library to use STM. I actually have an [open issue](https://github.com/aepsil0n/carboxyl/issues/14) for that since January. Once that is done, the event handling foundations at the core of this issue are essentially dealt with. For building higher-level application architecture, André Staltz nicely explains the idea to model [the user as a function](https://youtu.be/1zj7M1LnJV4). This is most prominently featured in [Cycle.js](http://cycle.js.org/), which can be thought of as a functional reactive version of unidirectional dataflow as in Facebook's Flux architecture. Elm (and Elmesque) have been mentioned here to get a purely declarative 2D graphics abstraction. And no matter what UI backend you are using, I'm sure it is possible to create a driver for it to interface with your functional reactive application logic. It should be entirely possible to translate this concept to Rust. There are some Rust-specific issues to be dealt with though. One problem is that I haven't found a way to get rid of the `Send + Sync + Clone + 'static` bound for types used in carboxyl-based programs yet without breaking the abstraction. `Send` and `Sync` are perfectly fine, as we want to do multi-threading, but `Clone` and `'static` feel a bit too restrictive to me. tl;dr multi-threaded UI toolkits not only possible but easy to maintain, modular and testable when using proper abstractions.
If anyone doesn't want to install a whole plugin for just one formatter, I think good old :%! rustfmt Will do the job adequately. It can be bound or executed on write in the same way, of course. On a related note, can I visual-mode format individual rust functions (or smaller code fragments) with rustfmt or does it only work on whole files at a time? 
Just how many lines of code is the linux kernel or the complexity level to the point it would take that much to remake for rust? I mean, rust has many contributors now. 
Good catch! That is indeed even simpler if you're just using one programming language. I was starting off from "why can't vim-autoformat do rustfmt" and never even considered that.
In 1999 Linux 2.2 had 1.8 millions of lines of code, in 2011 it had 15 millions, and in 2015 it has 20 millions (see [here](https://en.wikipedia.org/wiki/Source_lines_of_code)). In 2008, the Linux foundation estimated that developing Linux from scratch [would cost some $1.4 billions](https://www.linuxfoundation.org/sites/main/files/publications/estimatinglinux.html). Other organizations [put some other values](https://en.wikipedia.org/wiki/Linux_kernel#Estimated_cost_to_redevelop) (the European Union estimated $1.14 billions in 2006, and some study put it at $3 billions in 2011). When I said hundreds of millions, I was actually underestimating it by quite a bit.. And just the amount of code doesn't tell the whole story, because some code is easier to test and debug than others. And kernel code can be exceptionally difficult to debug, specially stuff like drivers for obscure platforms. Some platforms are buggy or poorly documented and it's not the role of the kernel to question this - it must support the hardware as is. On the other hand, Rust offers the opportunity of having a clean slate - reduce the scope of what's supported (less obscure peripherals, less obscure architectures). And perhaps some Rust features might make programmers more productive. ^^[citation ^^needed] The problem is, if you make some software that isn't as broadly applicable as Linux, it doesn't actually replace Linux.
`num::One` and `num::Zero` are still in the standard library. However, they are unstable and unusable outside of nightly versions, waiting on associated constants.
I don't know if it's easy to upgrade Mesa, but we can just tell Piston to use a lower OpenGL version. Try adding `.opengl(OpenGL::V3_0)` right after that `WindowSettings::new(....)`.
The Linux kernel's fundamental design wouldn't directly translate to idiomatic Rust, so it require a substantial engineering effort comparable to simply designing a new kernel.
You should use a library to do this, but just fyi this is what is happening (on unix systems, anyway): The terminal exchanges data with the active process using the kernel's tty subsystem. The tty is essentially a bidirectional pipe between the two processes, except that it has attributes, set through what are called termios flags, to modify its behavior. The default setting, called canonical mode, does two things relevant here. First, it buffers input until a newline or end of file character is received, and only then sends it through to the active process (this is why when you read from stdin, you get a line at a time instead of a byte at a time). Second, it echoes each character back to the terminal, so that what the user is typing gets displayed on the screen (because the terminal only displays what is written out to it). These libraries adjust those flags so that the tty does not echo characters other than newline. Windows works completely differently.
But you can just pipe the function code to rustfmt and copy the output; which is doable in `vim`.
Thanks. How can I track this information down, or avoid wasting time when I see things in [doc.rust-lang.org](https://doc.rust-lang.org), to make sure they are actually available?
If you look them up [in the std docs](http://doc.rust-lang.org/std/num/trait.One.html) there is a box saying they are unstable, with a link to the issue about stabilizing them. There are versions of these traits available in the external [`num` crate](https://crates.io/crates/num) which you can use in stable Rust. 
I'm not sure it'll have the proper indentation though.
Oh, right. Perhaps rustfmt should have an argument for that. https://github.com/nrc/rustfmt/issues/561
The last chart is the interesting one for us.
For instance?
https://github.com/tsgates/rust.ko
Was that big spike near the end due to the run up to 1.0?
Do you know what's holding up cargo on the x86?
I haven't followed the organizational changes going on around the non-std libraries managed by rust-lang very closely. Does libc being promoted from the nursery mean that its on a course toward 1.0.0 and stabilization?
Also see [this twitter](https://twitter.com/nick_r_cameron/status/580106932297465856) - we can use `Deref` to implement some kind of poor's main subtyping / inheritance, by manually including the "supertype" as a field of the "subtype", and implementing `Deref` from the subtype to the supertype. That way, we can make the subtype look like the supertype when when making method calls.. the downside is that this would be 1. A terrible abuse that shouldn't be done. 2. Not very complete, because Rust doesn't auto-deref when passing parameters and other stuff (so it isn't really a subtyping relationship, more like faking it) 3. It feels un-Rusty. Anyway, there is a [design patterns book](https://github.com/nrc/patterns/blob/master/README.md) in the making that has a chapter on [Deref polymorphism](https://github.com/nrc/patterns/blob/master/anti_patterns/deref.md), citing it as an "anti-pattern". See [the /r/rust thread](https://www.reddit.com/r/rust/comments/3ptlgq/design_patterns_in_rust_blog_post/).
More than that, it's about to be the one inside rust-lang/rust: https://github.com/rust-lang/rust/pull/29546
I was able to call it on non-crate files, and it would then format them and their submodules.
Well, I mean, it's _always_ been the one inside rust-lang/rust, this makes the setup more regular. The git repo for the libc crate had rustc in a submodule...
oh yeah, that works. I guess I meant that it *could* work on crates. It can also start on arbitrary places, probably limited to items at the moment, but could work down to statements without too much work.
&gt; The first thing I thought about when I saw this graph was that mozilla, chrome and webkit all started out quite high and then it was downhill from there on (in terms of commits/dev). [...] . Maybe most large software projects dig themselves into a hole of complexity, and then get stuck in that hole and die slowly? I think it's more likely that a project starts as a very small group writing a lot of code from scratch (high commit/developer), then as it becomes more popular attracts more minor contributions from a wider audience. e.g. If you started with a few devs committing hundreds of times a day, then introducing new committers who only commit once a day will dramatically reduce your commit/developer rate, regardless of the fact that your core team is still doing the same amount of committing.
The Cargo.tomls were written maybe one year ago and never touched again. Because of OpenGL, several crates pass libc types between one another, which breaks if they use different versions of libc. And the fact that `gl_generator` generates Rust code that uses libc, which forces users to import the correct version of libc, doesn't help. Some types are defined both by gl_generator and by some other crates (like x11 or winapi), and lots of code already works only by casting raw pointers. This whole thing is a huge mess and needs a big cleanup, but nobody has the courage to do it. 
That `size_t` change _just_ landed, IIRC. Fixing the flate2 crate sounds like a good idea regardless of other libraries' existence...
sorry, i’m very new in actually coding rust: what `size_t` change? /edit: and of course i’d like it fixed, i just don’t know how CRC-32 works and therefore only submitted [this PR](https://github.com/alexcrichton/flate2-rs/pull/31) based on guesswork.
Probably referring to [this change](https://www.reddit.com/r/rust/comments/3reo1k/the_libc_crate_is_now_at_v020/) to the `libc` crate. Broke many unexpected crates using the `libc = "*"` requirement (which is, well, not recommended due to exactly this kind of breakages).
oh yeah lol the change was from [Sep 23](https://github.com/rust-lang-nursery/libc/commit/179104605391bdda15c0215c963c797504103d11) and the release containing it was 15 hours ago XD
The fate of `*` constraints was sealed when [this RFC merged](https://github.com/rust-lang/rfcs/pull/1241). That's when I got my butt in gear and removed all `*` constraints in all of my crates!
Oh! Yes, sorry, I didn't realize you were talking about the other code, my bad.
Hey man, I'd totally appreciate that! Thank you so much! When I have more time, I plan to use `clap` with `gar`, so I'll be heading your way :D!
I had implemented my interpreter as AST evaluation at first, too. It was about an order of magnitude slower than CLISP on some trivial benchmarks I threw together. Probably acceptable for many purposes, but I decided to implement a bytecode compiler, anyway. One of the goals of my project will be to allow evaluation of untrusted code by limiting recursion, memory consumption, and time spent processing. Having a bytecode interpreter makes these goals more easily achieveable (I think). Also, I just like taking on projects the likes of which I've never done before, as a learning experience. I don't know how much there is to chat about -- I'm still figuring it out as I go along. But feel free to PM me here or on Mozilla IRC.
&gt; Plan9/Redox by nature will never be completely POSIX compliant if at all. If Plan 9 were ever made POSIX compliant, Rob Pike will be spinning in his grave.
&gt; I'm unsure if I even know what I want. Not me! I want a pony.
Ah yes looks like this was just a minor bug in flate2, thanks for finding it and submitting a PR!
I made https://github.com/Ticki/passwd-rs which: - Memlocks the password. - Makes sure the drop properly done (and not optimized away). - Does byte-by-byte hashing of the password. - Replaces the command line input with `*`'s. - Makes the password unable to be logged to the console.
I think you edit is "most correct": `Box::&lt;[T]&gt;::from_raw` takes a `*mut [T]` fat raw pointer.
Ok! Again, thank you!
But can he answer when I'll be able to run itunes on 9f? ;)
The warnings are mostly error handling which I'm not doing, naughty me. Is note off not working? Do you mind if I ask what controller etc you're using? 
If you're going to say something is factually inaccurate, maybe you could divulge the proper documentation describing the inaccuracy instead of claiming something to be factually wrong and dumping how you justify the differences in nomenclature to call it as such when as far as I can tell the idea is the same with different names. So which part is factually inaccurate? "Redox is based" maybe you'd be happy if I rephrased it as "Redox is inspired by something called Plan9". Seems like we're splitting awfully fine hairs to be claiming factual inaccuracies when the statement gets the point across just fine. If this was an executive level breakdown I would have avoided comparison but to an individual that doesn't know why OSX isn't called Linux or the difference between windows and posix the statement is pretty ok. As far as URL's for fs goes. A URL is an address to a file. A file might have multiple files, this might be called a file system. So please clarify 1) Why it was a good idea to name your new fs after something that already has a widespread and common usage, and 2) how you justify that your URL's aren't simply file systems themselves 3) how your URL is fundamentally different than a systemcall (How the hell do y'all mmap or fork?) You can probably answer all three of them in one go, since neither I nor anybody else outside of the ~20 odd people in IRC can tell the difference. I'm also not allergic to reading if you'd rather link docs/source instead. :) Sorry to upset you but I'm still pretty sure the wording is accurate in context.
My suggestion would probably be to use the [`bytes` or the `chars` iterators](http://doc.rust-lang.org/std/io/struct.Stdin.html) depending on what exactly you need.
~~This won't compile because `char` is a keyword.~~ And anyways, you really don't want to do micro-reads like this on an unlocked stdin.
This won't compile because fn main() isn't found. 
You wouldn't want a `.chars()` iterator on a regular `stdin()` anyways; it'd require a mutex lock with every iteration! If you're not worried about Unicode support, you can read byte-by-byte instead: use std::io; for byte in io::stdin().lock().bytes() { // Do something with bytes. } If you're matching on characters you can use the byte equivalent, like `b'\t'`. I believe this is a compile-time error if you try to use a multibyte character in this literal form.
I've seen https://coveralls.io/ badges on projects here and there. I don't know what support it has for your specific use-case, I've never used it myself.
Thanks. This is making more sense, though I'm not yet fully comfortable with it. I had a slightly more complex example, involving tuples: println!("{:?}", (0..10) .scan( (0,0), |acc, x| { acc.0 = acc.0 + x; acc.1 = x; Some( *acc ) }) .find( |&amp;x| x.0 &gt; 10 ) ); This works, but what I really wanted (and what I started with when I ran into problems and started this thread) was to use destructuring, something like this: println!("{:?}", (0..10) .scan( (0,0), |(a,b), x| { a = a + x; b = x; Some( (a,b) ) }) .find( |&amp;x| x.0 &gt; 10 ) );
And part 3 on hygiene - http://www.ncameron.org/blog/macros-in-rust-pt3/
Not worth it, IMHO. I'm a big fan of C++, but I think one of the best parts of C# was the consolidation of all those dumb operators into just one. It's a fairly simple concept: the dot accesses stuff inside the identifier to the left. The situation described in the OP is so rare that I'd rather just deal with it with proper `using` statements than have dedicated (ugly) operators.
In my experience, I have written code where namespace and instance make sense in both names, but since this was not possible to do in java without the compiler complaining, I resort to appending prefix,suffixes to the variable names. In rust, I don't have to anymore.
I think these are generated by kcov, which is linux-only unfortunately (and also has a few other limitations like branch coverage). In the meantime I have found two rustc bugs which need to be fixed for there to be gcov support, unfortunately... https://github.com/rust-lang/rfcs/issues/689 and https://github.com/rust-lang/rfcs/issues/646
I know that feel &lt;3
I...I am so thrilled :D I agree completely about those projects being hindered by principles. I am so outlandishly thrilled that Redox is a thing and that you came all the way to a day old thread to explain exactly what was going on. You rock. You rock. You rock. Please put this in this weeks Redox update! Just about to step out so I can't read this completely but I sincerely appreciate somebody coming forward and saying what's what.
C++ needs the two separate forms eg A.a vs A::a because this is legal (thanks to C): struct A { int a ; } A; This is not valid in daughter languages so they can get by with the single form.
PSA: I recently landed over a thousand lines of documentation for Iterator, so check nightly for the next 10ish weeks :) http://doc.rust-lang.org/std/iter/trait.Iterator.html
I've added a [solved] flair we can give to posts. Now we just have to use it...
Python uses `.` for both, and it does just fine. If you would have a namespace conflict (which is rare enough,) you can just say `import x as y`, which is actually very clear. Of course, in Python modules are objects, so it's natural.
It's ugly, fix the CSS! Wait no, for god's sake don't look at the CSS!
I believe it's to make the parser grammar simpler over some benefit to the language itself, but I do miss it when I go back to C# et al because it makes code easier to scan.
ugh, my habit of always going to stable betrayed me here, yes, thank you!
Oops, I already have. Is the `padding-left:20px!important;` for `.linkflairlabel` intentional?
I look at `Xxx::Yyy::zzz` and see it as a single "thing", but look at `Xxx.yyy.zzz` as multiple "things".
OP asked for glyph-by-glyph, and you offered byte-by-byte, which isn't the same thing at all. One can never do the work of the other.
The only way that can happen is if you're calling a method on a global (`-&gt;` isn't even in Rust thanks to magic dereference coercion), which is a bit of a code smell anyway.
I don't see anything obviously wrong in your code that *should* cause a segfault. You should report a bug to the gtk binding devs. If I had to guess, I'd say that the gtk bindings are failing to catch a panic in one of your callbacks and you're panicing into c code (undefined behavior). This is a bug in the bindings. -- edit: gtk-rs doesn't catch panics in callbacks. This is probably the bug. -- edit 2: It isn't (it's a bug but not the bug). The following fails: extern crate gtk; use gtk::traits::*; fn main() { //create window let window = gtk::Window::new(gtk::WindowType::Toplevel).unwrap(); window.show_all(); gtk::main(); } 
If I run /lib/libc.so.6 I get "GNU C library stable release version 2.9" I can try the binaries but I'm just a game developer, and I'm busy with nanowrimo this month, so if something goes wrong I won't be much help debugging. Edit: I made an issue on Github.
I am disappointed you didn't go for the contradiction option and tag this post with "unsolved". 
Missing `gtk::init()`, eh?
Is there a reason to not have `init` yield a type that has the methods that depend on it being called?
llogiq is newly-anointed, he hasn't yet embraced the passive trolling that is endemic to /r/rust mods.
Note that I'm not the author, just the submitter. :) Address feedback to the author in the comments section in the OP.
I'm not trying to crucify y'all or anything, I was legitimately wondering if this solves the problem or if other aspects of GTK made this not work (sounds like it does work?). I'm really interested in how well basic Rust idioms can model the constraints of "real" APIs, and GTK is a *very* real API.
Is that something my code needs in order to work?
Yep, the primitive types aren't keywords, so you can write confusing code that uses them as identifiers..
Can I just say how awesome it is that if you're rust code compiles and you get a runtime error w/o calling unwrap or panic! then it's probably a bug. Honestly. 
There is [cargo-outdated](https://github.com/kbknapp/cargo-outdated) to see if dependencies are out of date. 
I'm not sure we can change the hovertext via CSS. Perhaps with some :before and :after trickery...
It's very bad (against the philosophy of Rust) if you require the user to call a specific function not to crash :-/ You should either ensure that `gtk::init()` is called, or mark your whole API as unsafe.
I know quite a few people that generally prefer `String::from("")`, which is clearer, but that's about it. The point here being that Rust wants to make all allocations visible and especially not fixate people on the default `String` type too much. e.g. Servo uses `DomString` everywhere (which is, in it's current implementation, a `String`, but it doesn't have to be.
Yes, there *is* a better way, seeing that the fields are created from `&amp;'static str`s: Define the fields as `std::borrow::Cow&lt;'static, str&gt;` and use `"..".into()`. Or if you are into explicitness, `Cow::Borrowed("..")`. This means one less clone and your code even gets shorter.
It is. For GTK to work, you must `init()` it. This is true in C, but in Rust, too.
That's curious. How would you design the API to still be lightweight then? I'm working on GRPC crate, and one needs to call init function for that one as well, but it looks really troublesome to carry the result of that one around everywhere one can do an RPC call.
Nice to finally get some input from Joe on their work. He kind of went silent since the M# post. I also wonder how System C# looks like. From Herb Sutter's paper on the adoption of lifetimes to C++ tooling there is are some references to it. Which Joe also included on his CppCon twitter posts. 
Is there any reason why (a version of) `fold` couldn't have the same accumulator signature as `scan`? These functions are workhorses for me in functional programming (collections, Rx Observables etc), and it's extremely common for me to change one into the other, as code evolves. It would be very convenient to have a form where I don't need to change the accumulator when doing that.
Eh, yeah it's probably not documented. That said, it was a design constraint when making RawVec. Could probably add a unit test asserting the address doesn't change if you roundtrip a `Box&lt;[T]&gt;` through a Vec like this.
If you omit all the extra newlines and spaces it's only three additional chars. Doesn't seem that bad to me. EDIT: You can also rewrite this with if-let: if let Some(x) = ... { foo(x); } else { bar(); }
Not generall, but in this case, you can move towards the if-let syntax with is in that case a little more brief and maybe more pleasing: if let Some(foo) = a() { frobnicate(foo); } else { shizze_the_nizzle(); } (Semicolons still required) The best option is clearly that both `frobnicate` and `shizze_the_nizzle` return `()` anyways.
Duly noted.
&gt; How would you design the API to still be lightweight then? If you don't want to change the API, you need to make everything unsafe like /u/tomaka17 said. Otherwise you are lying to the users of your library.
Thanks.
glibc 2.9 might be an issue as I'm not even sure if Rust will compile against such an old libc. But I'll give it a shot. Once/If I get something working I'll post some test binaries in the issue on github and you can test them at your leisure. If they work I'll add a soft float build to the automatic build process. Though I may not do nightlies with it and instead focus on only beta and stable builds.
I've seen that one, I meant a service that automatically checks it for you so you can just go on your github page and see if you there are new versions of dependencies. Ie https://github.com/Keats/ng-boilerplate which you can directly see if out of date
aah, `if let`! this sounds useful :D
Thanks! &gt; I guess with haskell experience, you appreciate this cool property Passing the methods by reference instead of using lambdas? Yes, that's nice! Just missing partial application ;)
You know it when you can't see it.
bwa ha ha ha ha, it's working...
Cool! Thanks for your help!
Passive trolling is the best sort of trolling. Keep up the good work.
Sorry for being pedantic.
This won't compile because "May need some error handling. This'll return a u32 sized character, so it'll handle utf-8" isn't valid rust code.
&gt; The combination of memory, type, and concurrency safety gave us a powerful foundation to stand on. Most of all, it delivered a heightened level of developer productivity and let us move fast. This is an interesting quote. I've seen a lot of developers assume that Rust's safety in particular will hurt their productivity. I haven't used C++, and am still a novice Rustacean, but my initial impression is that the safety is a productivity benefit. &gt; Many could read from the same memory at once, and one could write, but multiple could not write at once. A few details were discussed in [our OOPSLA paper](http://research.microsoft.com/apps/pubs/default.aspx?id=170528), and Rust achieved a similar outcome and [documented it nicely](http://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html). It is nice to see him link the Fearless Concurrency article. That is one of my favorite pieces of Rust related writing. I hope he continues the series. It will be interesting to hear more of what they learned.
Some notable highlights and possible topics for discussion: - `#[deny(unsafe_code)]` is used. - 100% code coverage is claimed, but the covered lines don't seem very accurate. For example, I have no test for invalid utf-8 chars in the input, but that case seems to count as covered code. - The size of each sexp node is 5 words, when in theory it could be 4. This seems like something the compiler should optimize better. An atom should be 3 words: top bit of pointer in the `String` set to `1` if it's really an int atom. - I think s-expressions are great! One should use them if there's no special requirements on data format (e.g. performance, memory-density, etc.). I think this library is a great dependency-free addition for small projects that need an interchange format. - I wish this code could run on stable, but `is_char_boundary` and `char_range_at` are on nightly only. I would love it if someone would show me how to rewrite the `peek` function to work on stable. - I'm not totally up to date on the error handling story in rust. Is there a nice way to do this yet? Links to any comprehensive posts about it? How does one compose them nicely?
&gt; The hint lies in these lines: &gt; expected `()`, &gt; found `core::result::Result&lt;_, _&gt;` &gt; Ah, some type mismatch is happening. Maybe the first line "&lt;std macros&gt;:5:8: 6:42 error: **mismatched types**:" is also a hint that a type mismatch is happening :) On a more serious note: &gt; This might be the first time in my life I've ever seen a function in a C-style language that was callable only inside functions of a particular type. It important to note that `try!` is not a function (thus the trailing `!`), but a macro. Very minimal comparable example (in C/C++) in would be: $ cat try.cpp #define try(func) if (func) return -1; int f(int a) { return a; } void test_func() { try(f(-1)); } int main(int,char**) { test_func(); return 0; } $ g++ try.cpp try.cpp: In function ‘void test_func()’: try.cpp:8:2: error: return-statement with a value, in function returning 'void' [-fpermissive] At least in Rust we can generally identify macros with `!`, so there are hopefully bit less surprising stuff like this.
`*` is an opt in to any breaking version upgrade, there is not much that can be done but fixing the crates.
To detail, preservation is not particularly interesting by itself in imperative languages (the equivalent properties are more complicated), while progress just means "the program does not do any action not allowed by the semantics", which is about as vague as you can get, and is equivalent to Rust's "no undefined behaviour in safe code".
I almost always have the opposite problem: I'll merrily write all my `try!`s and then forget to wrap the final expression in `Ok` (or `Some`, etc.). I worries me a little that I mess this up so much.
Many (most?) developers are hostile towards anything that tells them they're wrong, in my experience. http://cacm.acm.org/magazines/2010/2/69354-a-few-billion-lines-of-code-later/fulltext
Not enough JPEG
Huh?
I think his point is that you should consider using a PNG or some other lossless format. JPEG is generally a terrible format for anything but photos.
Make that "most *humans* are hostile..."
What do you mean by, "the namespace returned to the wild"? As I understand it, that is not possible. &gt; One of the major goals of crates.io is to act as a permanent archive of crates that does not change over time, and allowing deletion of a version would go against this goal. Essentially a yank means that all projects with a Cargo.lock will not break, while any future Cargo.lock files generated will not list the yanked version.
There is an "Upload images in high quality." option in imgur's settings. I'm not sure if it will stop the .png from being transcoded to .jpg or not.
Urgh, that's a terrible policy. As written it says crates.io is intended to become a massive graveyard just like PyPI and CPAN before it. There needs to be a policy for allowing libraries to officially deprecate and release their name for alternative use once use dies down.
How about the background, logo, and combined uploaded in high quality (found it based on a comment above in settings): https://imgur.com/a/Rt09F
Cool, I usually upload when I'm not logged in, updated the setting and here's the higher quality version (it looks like it does keep it PNG if higher quality is enabled): https://imgur.com/a/Rt09F
That's a smaller problem than trying to compile an old project and facing "dependency deleted" errors, in my opinion.
Awesome, thanks!
Ah, yes. In that case, I will yank all versions, but that won't release the namespace, meaning it will be frozen for all of eternity (or until the policy is changed). I still think having the possibility of yanking all versions (npm's behaviour) to "delete the crate" would be convenient in this case. Avoiding breakage is a noble goal, though... but it needs to be thought through. Crates.io being an authoritative repository (Cargo has support for other repos or means of fetching source, yes, but crates.io is "first-class"), it is definitely susceptible to becoming a graveyard, or of people grabbing "cool" names in the beginning then doing nothing much with them. An obvious and naive solution would be have a "graveyard" supernamespace where projects are yanked _to_, then having some sort of notice on the page to update the Cargo.lock and perhaps having Cargo automatically check the related graveyard library for one that matches the lock.
Much worse is the prospect of relying on a package to exist on crates.io, only to have that package mysteriously vanish at an unanticipatable future date. The "graveyard" problem can be easily solved by allowing uploaders to mark crates as deprecated. Cargo could even leverage this metadata automatically.
I'd start by getting rid of your error struct and instead using IoError. Other than that, using try! for error handling removes indentation by 2 levels. fn get_input&lt;'a&gt;() -&gt; Result&lt;Vec&lt;Vec&lt;char&gt;&gt;, IoError&lt;'a&gt;&gt; { let mut ret = Vec::new(); let mut temp = Vec::new(); for c in io::stdin().chars() { let c = try!(c); temp.push(c); // is this a bug? do you want the newline in the matrix as well? if c == ('\n') { ret.push(temp); temp = Vec::new() } } if temp.len() &gt; 0 { ret.push(temp) } Ok(ret) }
`and_then` and friends should have you covered. :-)
`walk_dir` is unstable, and /u/burntsushi's crate addresses the reasons why. Since the crate exists, no reason to stabilize the janky stdlib implementation.
Using unmaintained and deprecated crates should be an error, not a warning. You should absolutely be told when your dependencies are defunct and need to be updated, rather than Cargo silently letting you keep using something which is only going to rot over time.
The stdlib function will be dropped, after /u/burntsushi's lib is used for a while, it may or may not end up in the stdlib. I would bet on "yes" in the long term, but you never know... https://github.com/rust-lang/rust/issues/27707 is the tracking issue btw &gt; Something makes me want something like that in the standard crate In general, we are very careful not to make things stable in the standard library unless we really like them. Standard libraries are forever, no need to rush. Cargo means it's basically one line in your TOML file and one line in your crate root, and that's it, compared to being a built-in.
You can always go with `Box&lt;Error&gt;` if you don't care too much about the particulars of the error. I'm surprised if there are libraries out there not using the `Error` trait for errors. It should be a pretty strong convention at this point.
I considered that, but it would mean that they would _have_ to start at version 2.0.0, right? Not quite elegant. But sure, that's a possibility. I'll add a note to that effect on the crate at that point.
&gt; (thanks to the great tutorials by /u/burntsushi[1] ) now in the book! 
Allowing packages to relinquish names would be an anti-feature, because it means that anyone could snap up any name and replace the contents with anything imaginable at any point. It would be an egregious vector for arbitrary code execution on the machine of any developer using a "*" version (or any other automatically-upgradeable version) via any transitive dependency.
No, not elegant at all. :-) It would just have to be considered as a "re-design" of the current crate.
oh ok. Alright let me try those things. This may be a language level bug, from what I'm gathering.
Interesting read. Thanks for that!
Perhaps a method for Cargo to know that the crate has changed? Like keeping a meta version of each crate (name-1, name-2) and having Cargo understand depreciated libraries? When someone tries to build with the old project, inform them that it has been depreciated, tell them where to get the current version, but still have a copy so the project builds? Perhaps include any reason that the project was depreciated as well? There really isn't a great answer.... 
&gt; Converting in the other direction is a little tougher, as Rust can't statically ensure that the conversion is valid. As such, it requires unsafe via unsafe::reinterpret_cast(). Really? I've been doing this in my library just fine. https://github.com/iopq/strenum/blob/master/src/lib.rs it uses the enum_primitive crate https://github.com/andersk/enum_primitive-rs/blob/master/src/lib.rs I don't see `unsafe` anywhere, am I missing something?
For additional context, Walker is a near-copy of what was/is in the stdlib.
Is it possible for me to get a rustfmt and slicebuild flair? My github is https://github.com/sezna
Oh crap I read the version number wrong, I thought 9 &gt; 1, not 9 &lt; 13.
You have to `match`, writing out each value and the variant it maps to; there's no built-in safe way to cast directly the number directly.
Looks nice.
What would Rust bring to an init system that would improve the state of the art? Is it just a matter of starting from scratch and trying to fix issues with systemd, and Rust is a more exciting tool with which to attempt that?
If JWT is something that interests you, check out rust-macaroons as well: https://github.com/cryptosphere/rust-macaroons
Very interesting read. Thanks!
Shouldn't your permissions be `0o444` instead of `0444`? Rust has a different octal syntax compared to C, which means you're actually passing `0o674` for permissions.
Again with that "systemd is monolithic" myth. Please point out the real problems systemd has (and yes, it has) and stop dragging that strawman into the discussion. What *I* would like to see written in Rust is a an extension of libhoare to prove code correctness at compile time.
It helps productivity in the long run (less hidden bugs), but definitely hurts it in the short run (when you need a proof of concept/throwaway right now).
Mods here. We realize that systemd is a contentious topic, so please strive even more than usual to keep the discourse in here civil. :)
If you do any embedded work with Rust, please check out the stabilization issue for libcore/no_std (https://github.com/rust-lang/rust/issues/27701) and consider leaving feedback! :) This API is especially large and fundamental, and could use more scrutiny from folks who have experience with it.
In Rust or any other memory safe systems programming language, _Everything that was once upon a time written in C_.
I don't follow. [`EncodingError`](http://tyoverby.com/bincode/bincode/rustc_serialize/enum.EncodingError.html) impls the `Error` trait? The `EncodingResult` is just a type synonym for `Result&lt;T, EncodingError&gt;`. This is [also explained in the error handling guide](https://doc.rust-lang.org/stable/book/error-handling.html#the-result-type-alias-idiom).
any time
About Truecrypt: Linux has independent implementations that are compatible with the on-disk format of Truecrypt ([dm-crypt](https://wiki.archlinux.org/index.php/Dm-crypt) and [tcplay](https://wiki.archlinux.org/index.php/Tcplay)), meaning that we don't need to use any Truecrypt code. Also, the current status quo of Linux is to use LUKS volumes (also with dm-crypt). It would be incredibly nice to have a safe, in-kernel Rust implementation of dm-crypt (compatible with Truecrypt volumes, LUKS, etc). The crypto algorithms would continue to be [essentially assembly](http://lxr.free-electrons.com/source/arch/x86/crypto/) (the .S files), but the code that deals with other details (such as the placement of values in buffers, etc) should be written in a safe language as much as possible.
I often use ok() to convert a result, and if let Some() instead of matching when I can. slims things down and reduces typing on my part. 
Started tinkering on a new project that is a custom udp protocol that implements authentication and tamper checking. The majority of protocols require all-in encryption to receive these benefits, which is not always desired. I am trying to target iot/m2m which on the average is totally susceptible to these issues. [https://github.com/viperscape/iota](https://github.com/viperscape/iota)
i’d even say “keep it out of here”. there’s no reason to discuss systemd here.
I've been hearing of a pretty big increase in existing companies using Rust, but it's generally existing employees, not new hires. Hopefully as those projects grow, we'll see more like this!
[**@ServoDev**](https://twitter.com/ServoDev/) &gt; [2015-11-05 21:00 UTC](https://twitter.com/ServoDev/status/662373951432036353) &gt; Keep your eyes on https://careers.mozilla.org/en-US/ - we're about to open 3 positions for junior devs ONLY, based in SF, Toronto, or Paris offices! ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I'm still very novice, but I think there's some danger in dropping the std implementations for outside libs. Something being the 'official' representation makes it much easier to standardize to, and almost easier to trust. Minor point but ahwell: People not familiar with a language often judge based on the standard libraries, even though cargo makes it trivial to add another.
Perhaps [byteorder](https://github.com/BurntSushi/byteorder) crate can help
Junior developers, in general. 
Looks great! Though could maybe use a little more contrast? Looks too 'faint' on my screen. 'Cause it's all dark desaturated colors.
So it's just people in SF/Toronto/Paris? 
Presumably people willing to relocate, too. We want the new hires to be co-located with an existing team member. 
We'd prefer someone who could work in or relocate to an office where we have an existing team member, and those three offices are the ones with Servo devs. Since the position requires almost no experience, we expect to be making a significant investment in training and mentoring, and that is easier to do on site. We will consider applicants who can convince us they can do just as well working remotely, although this would probably require some previous experience doing so: working on a remote team in an open source project, some cross-university project where the applicant to learn and get things done with no local support, remote contracting work, etc.
See also https://twitter.com/dddagradi/status/662679052017270784 for a similar kind of comment/question
The avatar has been moved, so the reference from the user is not longer available: http://is.gd/DheiNC Here's a working example where both the world and the user borrow the avatar: http://is.gd/EDKT4I 
If you're reading C structs, couldn't you use FFI? Or make a `#[repr(C)]` version of the input?
What I mean is reproduce the header using `#[repr(C)]` then use a single `mem::transmute` to convert those bytes into the rust struct. (or use `BufReader` and read a raw slice of bytes into the struct.) Then you can manipulate it safely. 
&gt;What fundamental thing am I doing wrong? Not telling us the details :D What operating system are you on? Where did you get your Rust distribution from? "Hello World" is not supposed to crash normally. At the same time, 2.12 MB is expected, because the whole standard library is compiled into your executable by default. You can override it by passing `-C prefer-dynamic` to the compiler.
Also note that pointer casting and transmute things are not portable. If you get the byte array corresponding to the header from another computer (say, over a network), there is a chance of endianness mismatch, and you will read complete garbage. Unfortunately, without a clean definition of endianness (some protocols, for example, explicitly define the byte order of multi-byte numbers), there is nothing you can really do; when your data is defined as a C struct, unfortunately, it becomes dependent on endianness. You should take extra care around it.
I've just tried to recreate on Windows 8.1 64 bit with Rust Stable 1.4.0. Copied and pasted your code into hello.rs. Can you post the result of rustc -V? &gt;rustc -V rustc 1.4.0 (8ab8581f6 2015-10-27) &gt;rustc hello.rs &gt;hello.exe Hello World!
&gt; Not telling us the details :D Fair enough. Thanks for the response. OS =&gt; Windows 7 Enterprise SP1 64Bit Got the 1.4.0 Windows Installer from: https://www.rust-lang.org/ rustc -V =&gt; rustc 1.4.0 (8ab8581f6 2015-10-27) &gt; You can override it by passing -C prefer-dynamic to the compiler. Thanks for the tip.
And finally, you indeed can use `byteorder` crate to read your data. It will be much more verbose than casting pointers or arrays, but in return it allows one to not depend on endianness. This is mostly important for platform-independent protocols, and in your case I think working with `#[repr(C)]` structure will be easier, but anyway there is this option too. You can only read bytes from `std::io::Read` instances. `byteorder` crate provides an extension trait which allows you reading multi-byte numbers in the specified endianness. This can be used to sequentially read the structure field by field: let mut input: &amp;[u8] = ...; let sizeof_hdr = input.read_i32().unwrap(); let mut magic = [0u8; 8]; input.read_exact(&amp;mut magic).unwrap(); let datatype = input.read_i16().unwrap(); // ... Unfortunately, this approach doesn't work well when the C structure uses platform-dependent types (like `int`, `long`, `short`) instead of fixed-sized ones (like `int32_t`, `int64_t`, `uint16_t`). Because on different platforms size of e.g. `long` will be different, the code which compiles on one platform won't compile on another, because `byteorder` does not provide methods like `read_c_int()` or `read_c_long()`. You'd need to use conditional compilation for this if you want to make your program portable.
Thanks for the response. Yeah, I agree. It's something to do with Windows or the Windows distro. I'm trying to see if it's a linker/path problem.
Do you have any antivirus software running? Are you using original Windows or some modified version? Some software on Windows does very dirty things like injecting its dll into every process which can cause some programs to crash, other may modify system at some fundamental level which can also lead to similar problems. Examples: viruses, anti-viruses, custom themes, anti copy protection.
You can drop to [#rust on irc.mozilla.org](https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;channel=%23rust) if you want to chat with someone about this issue, but other than that yeah, you can ask it on Reddit. (Stack Overflow is recommended for programming questions in general, including [Rust questions](https://stackoverflow.com/questions/tagged/rust). But perhaps not questions on how to setup your programming environment, because they tend to be useful only for you) Anyway, to run a hello world and other simple programs there is https://play.rust-lang.org/, like [this](http://is.gd/s7Yffu).
Make sure that the folder containing `rustc.exe` and `cargo.exe` is in your `PATH` environment variable. This also contains several DLLs which your program may depend on especially if you use `-C prefer-dynamic`. You may have to close your terminal and open it again to react to changes to your system `PATH`. You may even have to reboot. If you're sure your `PATH` is correct, but your program is still crashing on startup, this may be due to the console you're running it in. Make sure you're using a plain Windows `cmd.exe` to run the program, as some third party consoles do some hook black magic which can cause things to crash, in particular jemalloc. If you want more help, seek out `WindowsBunny` on the mozilla IRC on any of the Rust related channels.
Didn't realize that there were two installers. However, I was using the GNU installer already. Anyway, I think it might have been a path resolution thing with the linker caused by a bad installation - not the linker itself. After I chose the default paths in the installer my app worked. I'll keep digging to prove to myself that this was 100% the issue but at least for now I've got my app working. Thanks for your response. 
Awesome, thank you!
&gt; I suspect the issue may have been with the Windows Installer (rust-1.4.0-x86_64-pc-windows-gnu.msi) not registering the .dll files correctly if you do an advanced installation and change the base Rust directory. &gt; I uninstalled Rust and re-installed using the defaults in the installer and everything worked. This sounds like a bug, but I'm not sure where you could report it, perhaps opening an issue in github.com/rust-lang/rust. (but in any case the developers will see this thread) Also: Rust now has a build compatible with MSVC, if you use Visual Studio. In this case, there's [this](https://github.com/PistonDevelopers/VisualRust).
I do have anti-virus software - corporate laptop and all. This is interesting. I'll continue to investigate to see how the installer interacts with the anti-virus. Anyway, I've got the environment up and running now. thanks for your response. 
Thanks. I've did much of this without any change to the result. It's only after I re-installed with all default setting that it began to work. 
agh of course this gets posted right after i find a job
The `unsafe { }` block should perhaps be called `trustme { }`. It is used to signal that you're 110% sure that whatever goes inside the block is memory safe, but Rust's type system has no way to verify that it's indeed safe (if you lie, you trigger undefined behavior). So it trusts you. It enables you to use "unsafe" code inside a safe function, and all it asks from you is that you don't lie: what you did should really be safe! See [Meet Safe and Unsafe](https://doc.rust-lang.org/nightly/nomicon/meet-safe-and-unsafe.html): &gt; Unlike C, Undefined Behavior is pretty limited in scope in Rust. All the core language cares about is preventing the following things: &gt; * Dereferencing null or dangling pointers &gt; * Reading uninitialized memory &gt; * Breaking the pointer aliasing rules &gt; * Producing invalid primitive values: &gt; &gt; * dangling/null references &gt; &gt; * a bool that isn't 0 or 1 &gt; &gt; * an undefined enum discriminant &gt; &gt; * a char outside the ranges [0x0, 0xD7FF] and [0xE000, 0x10FFFF] &gt; &gt; * A non-utf8 str &gt; &gt; * Unwinding into another language &gt; &gt; * Causing a data race `std::mem::transmute` is unsafe, since it can be used to violate memory safety, but the byteorder crate uses transmute in a safe way (not meeting any of the above criteria for undefined behavior), so it only needs a "trust me" block.
I'm wondering how much they pay for Paris
I'm not sure when applications for the internships will be open, but we asked for spots for Servo, Rust, and a few other research projects. Keep an eye out!
ah ha, thank you very much!
You might be thinking of gc-sections, which is what's getting us down to the "cozy" 2MB in the first place (std is BIG, and println is a surprisingly complex op!). LTO will do anything and everything it pleases in the name of speed, as far as I know. Optimizing compilers don't by default really care about binary size except for when it affects runtime, or it's "all else equal". That is, the only reason every possible function call isn't inlined (attrocious for binary size) is because it's worse for perf (and doesn't work on recursion).
-gc-sections is a linker feature, which we have on by default. It exactly removes unused code: https://sourceware.org/binutils/docs/ld/Options.html
Looks really good to me! First thing I look for in a CLI tool is error handling and it looks like you got it down pat. :-) You may want to impl `Error` for `BenvError`, but it's probably not too important in such a simple tool. There are a couple unwraps in your `main` function that I think could be eliminated though. e.g., If your `load_file` function fails, then you'll show the error as a panic to the user. It'd probably be nicer to detect the error and just print it.
Cheers. With only repr(C) I had a mysterious 4 bytes hanging around, repr(packed) did the job.
It *would* be nice to have a ML-like module system, but dummy structs are a very small price to pay, comparatively. Consider the syntactic overhead in defining a simple combinator in Rust vs. ML. This adds very little by comparison. Commentary: &gt; There is no value being passed around that carries the implementation with it. Meaning: the distinction here is we get a type instead of an object which stores the implementation objects as values. Is that right? Unless I've missed something, it's not much of a stretch to include this in the DI of languages with type-parameterisation. (It would be a different story if it was essential to DI to change dependency implementations after they are set.) &gt; Because typeclasses/traits are so much more flexible than Interfaces, you have all the added benefits of associated types, multiple dispatch, and being able to put static and dynamic methods in the same module. &gt; You can mix and match traits quite freely, to good effect, whereas with interfaces, this is much harder. This is true composability! I think it would be helpful to see examples of these. By interfaces, I am assuming you are talking about OO interfaces of some kind and not ML modules. &gt; Ultimately, I actually prefer a real module system to dummy structs. As cool as this is, you're right. It's worth observing that ML goes from functions to modules and skips the objects, and OCaml code rarely features objects even though the OO system is nice. My take is we (usually) don't really want objects, but OO is an extremely common local minimum. Would it have made sense to design Rust around modules first and objects as an afterthought? I have doubts but no convictions either way. Presumably objects are needed to attract C++ programmers, but OCaml's object system is a successful afterthought, as is Perl's and arguably CLOS too. I think emphasis on modules might be a bigger turnoff than the state of a late-stage object design ("THE RUST PROGRAMMING LANGUAGE DOES NOT HAVE ~~MONADS~~ FUNCTORS" etc.)
I mean there's nothing stopping you from taking `T: Index&lt;Ouput=U&gt;` or even `&amp;Index&lt;Output=U&gt;` if you want to be exactly like Java
I am inclined to agree with you. However, this sub is for the Rust programming language. I think you might find that the people in /r/playrust would be more sympathetic to your plight. 
As honored as I am for the mention, Gtk-rs or Conrod are probably the most solid solutions. WinGUI doesn't even have a real API yet. KISS-UI is usable but it's missing a lot of features and I'd rather work on the redesign. 
Even so, Mozilla has offices outside SF, Toronto, and Paris.
I don't believe /u/metajack was implying that those three locations were the only ones where Servo team members could be based.
Then ... how did you interpret "We'd prefer someone who could work in or relocate to an office where we have an existing team member, and those three offices are the ones with Servo devs. Since the position requires almost no experience, we expect to be making a significant investment in training and mentoring, and that is easier to do on site."? Because while it doesn't *rule out* that those are the only locations possible, it does suggest it as a reasonably strong preference. /u/steveklabnik1 said something similar on twitter. It makes sense to me; I'm just wondering why this isn't reflected in the job ad.
The first sentence made me flashback to my TI-84 Plus.
I don't really know what those shortcomings are that runit/daemontools don't handle, but I'm very happy with runit (simple unixy model, simple init scripts, logging + rotation, parallel init), and it gets the job done in ~7k lines of C and like 5 binaries. It's possible other people have much more complex needs than me, but 34 binaries and 250k lines of C is pretty gross, whether you call it a monolith or not. I'd be happy to see a daemontools family style init system in rust, though I'm not really sure what about an init system precludes higher level languages. I'd be happy with a Haskell init system too. I'm more interested in seeing really low level stuff like filesystems and driver being written in Rust. Things that can bear GC I think I might be happier to see in Haskell, though to be honest I'm not sure. 
Do you mean a screenshot like this: http://imgur.com/7Qt768p It says: This website does not supply ownership information. Hmm. The page however works in Chrome, but not Firefox with Addons disabled. Weird.
So, it looks like my firefox also confirms no ownership info, but doesn't consider this an error.
https://github.com/rust-lang/rust/issues/29669
In my project (OSX), I used XCode to create the UI(.nib), and then load &amp; control it with the help of `glutin_cocoa` in Rust code. I think "native ui == best user experience". [Tickeys](https://github.com/yingDev/Tickeys)
&gt;It *would* be nice to have a ML-like module system, but dummy structs are a very small price to pay, comparatively. Consider the syntactic overhead in defining a simple combinator in Rust vs. ML. This adds very little by comparison. Oh, I agree. You really do pay for every degree of freedom in ML. The difference between implicit instantiation versus explicit instantiation is abundant when you try grouping together a few functions with different parameterizations. In ML, you now have to parameterize the module over every module you need, even if the function you wanted doesn't use it. So in ML you either pay up by having to come up with modules you weren't thinking about, or make more modules and divide up your code in ways you didn't want to. In Rust, you just organize your functions any way you please as long as you get the bounds right because modules are only an organizational tool, not an abstractive one. So yes, having ugly little structs lying around is not bad at all. It is just closer to Java than I like. &gt;Meaning: the distinction here is we get a type instead of an object which stores the implementation objects as values. Is that right? Unless I've missed something, it's not much of a stretch to include this in the DI of languages with type-parameterisation. You get a type and an object, but the usage only requires specifying the type, not passing in an object. The reason this is not possible in, say, c#, is that interfaces cannot have static methods. This is only recently possible in Java with Java 8, but organizing code this way is probably not idiomatic. Your co-workers would look at you weird. This is possible in c++, but... Too many knobs. ;) &gt;I think it would be helpful to see examples of these. By interfaces, I am assuming you are talking about OO interfaces of some kind and not ML modules. Yeah, I suppose I made a lot of claims here, but that's also beyond the scope of this post. I think it's reasonable to assume that if you've used Rust traits to their full extent, you find that they're far more expressive than interfaces. My point was only "traits are better than interfaces", so if you're using the former instead of the latter for your DI, you've probably got more options at your disposal. &gt;As cool as this is, you're right. It's worth observing that ML goes from functions to modules and skips the objects, and OCaml code rarely features objects even though the OO system is nice. My take is we (usually) don't really want objects, but OO is an extremely common local minimum. Yes, and I think that's worth observing because ML got data abstraction, polymorphism, encapsulation, and reusability right without resorting to an object system as early as the late 70s and early 80s. So it's slightly dissapointing to me that Rust is as close to ML as it is (a mere 2 steps, in my opinion!) and yet people are still considering adding inheritance and subtyping to the language! But the people who are proposing such things are very smart people who have thought hard about a lot of these things. &gt;Would it have made sense to design Rust around modules first and objects as an afterthought? I have doubts but no convictions either way. Presumably objects are needed to attract C++ programmers, but OCaml's object system is a successful afterthought, as is Perl's and arguably CLOS too. I think emphasis on modules might be a bigger turnoff than the state of a late-stage object design ("THE RUST PROGRAMMING LANGUAGE DOES NOT HAVE ~~MONADS~~ FUNCTORS" etc.) Well, I don't think Rust has objects at the moment any more than SML does. I think it's useful to view data types in Rust as structures in ML with a privileged Self type (instead of the usual "t"), functions that take &amp;Self as a first parameter along with functions that do not, and method notation as a way of opening that module and selecting a function, while auto-supplying the first argument. Does Rust need a module system? I don't know, but I do know it would overlap far too much with traits. Someone out there needs to do the hefty thinking and figure out what orthogonal set of features subsumes signatures, traits, and functors. 
The location field doesn't seem to allow complex expressions like "preference to 3 locations, but willing to consider other locations". I would guess that not including more information about the location issues in the body of the job description was an oversight.
I've seen a few listing Rust as [desireable](http://careerssearch.bbc.co.uk/jobs/job/Senior-Software-Engineer-Data-Hacker/13973)
You might be interested in reading this: http://www.tedunangst.com/flak/post/heartbleed-in-rust Basically Rust doesn't protect you against bad programming. Bad Rust code is worst than good (existing) C code.
We used to have container traits but they were removed before 1.0 . I think the reasoning was that we would want a richer type system before committing to any specific traits; I think at the time the nail in the coffin was lack of higher kinded types (and the elusive `Iterable` trait). So the good news is that we'll probably have some traits, the bad news is that it's not clear when as it may require HKTs which are not very high on the list of priorities. All this said, I often find myself taking a `Fn(Key) -&gt; Value` when I want to be generic over lookup: maximum degree of flexibility. Furthermore Rust makes it easy to have single use, tiny traits that encapsulate some bit of behaviour you require.
I'm trying using Rc and everything works except when I add this code: match test_user.get_avatar() { // returns Option&lt;Rc&lt;Avatar&gt;&gt; Some(avatar) =&gt; { match pressed_key{ Some(Key::Up) =&gt; avatar.move_up(), // cannot borrow immutable borrowed content as mutable Some(Key::Down) =&gt; avatar.move_down(), // cannot borrow immutable borrowed content as mutable Some(Key::Left) =&gt; avatar.move_left(), // cannot borrow immutable borrowed content as mutable Some(Key::Right) =&gt;avatar.move_right(), // cannot borrow immutable borrowed content as mutable Some(_) =&gt; println!("{}", avatar.get_x()), //No problem None =&gt;() } }, None =&gt; () }; the get_x method: pub fn get_x(&amp;self) -&gt; i32{ self.x } the move_right method (the other oens look the same): pub fn move_right(&amp;mut self){ self.x+=1; }
Glad to hear it :)
Oh wow, this is up already? I gave this talk on Thursday... This was my first time giving this talk, so it's a little rough. But I also like to have it be a bit conversational. Several people said that it was the best talk they saw at the conf, at least on twitter. But the style might not be for everyone...
~~You need to `mem::forget(_)` the string, otherwise it will still be reclaimed.~~ ~~Note that this leaks the string.~~ Edit: I was wrong.
&gt; talking about unsafe *gets excited* &gt; unsafe let's you do 3 things ;_; no love for [implementing unsafe traits](https://doc.rust-lang.org/nightly/nomicon/meet-safe-and-unsafe.html)
Pardon what is likely a dumb question, but do I return it if it's been forgotten? std::mem::forget(name); name.into_raw()
The core feature of systemd is its dependency system, in which you don't need to explictly list all services that must come before a service, making systemd services more modular. Also, socket activation, that enables services to be started on demand. I'm not sure how daemontools dependencies are processed, so I can't compare. Another important component of systemd is logind: the stuff that Linux programs used before it to handle user sessions seem hacky in comparison. Also, systemd can run user daemons: they run whenever the user logins on their first session, and are stopped when the user log out from their last session. User daemons can also depend on system-wide events (they aren't simply run as a separate instance). I run an Emacs daemon and mpd with this, and it's great. What could be interesting is to verify whether one can build a systemd-compatible interface on top of daemontools or runit. If this isn't possible, then systemd has some feature that they don't. Sometimes it's bad to have too much features, but systemd doesn't accept all kinds of features, only those the authors consider important. There's also an upside for using a project with some features you don't use: it ensures that systemd can be used on a wide range of systems, and therefore receives bug fixes coming from many of its users. That's also the premise behind Linux too. Anyway, I found [this](http://blog.darknedgy.net/technology/2015/10/11/0//) as an recent critique of systemd, &gt; The thrust of my argument, and the positions espoused in this paper, is that this interpretation is wrong, and that in fact almost all commonly given existing definitions of systemd lead to thinking of it in the wrong mental model. It is improper to interpret systemd as an “init system”, as a “service manager”, or as a “software suite for central management and configuration of the GNU/Linux operating system,” (as defined by Wikipedia at present), or even as a low-level userspace middleware. &gt; Instead, these all emerge or are designed on top of what systemd fundamentally provides and is: an object system for encapsulating OS resources alongside a transactional job scheduling engine (itself consisting of such objects) with the intention of providing a uniform interface for controlling and partitioning the units of CPU time, as well as static names and entities, in a GNU/Linux system. Yeah I think that reducing systemd to being an init system is improper, the core of it is scheduling jobs based on dependency constraints (such as: this service should run when the network is on)
As not even a rust beginner, just a casual observer, I enjoy this kind of talk. It worked really well for hooking me on to Golang where they just show "here's this one aspect and how it works" and a bit of the philosophy. I suspect time constraints made it feel a bit limited - I'd have liked to see a longer talk. Nonetheless it did a good job of helping me understand the overview of how you can approach concurrency in rust. I've just been playing with Elixir over the past week so distributed/parallel/concurrent models are on the tip of my brain-tongue which made this talk especially well timed.
So I got it working, the issue was actually on the Python side (it didn't expect a void pointer). The only remaining issue seems to be that I can't seem to free the underlying table. I can call the following function multiple times without it crashing, which seems wrong: #[no_mangle] pub extern fn table_drop(table: *const libc::c_void) { let table: &amp;mut Table = unsafe { &amp;mut *(table as *mut Table) }; println!("Dropping {}", &amp;table.name); drop(&amp;table) } EDIT: Nevermind! #[no_mangle] pub extern fn table_drop(table: *const libc::c_void) { unsafe { drop(Box::from_raw(table as *mut Table)); } }
`vec![ ... ].into_iter().collect()` Is unfortunately the most ergonomic and/or least ineffecient way to do this. I'm sure someone has a macro that properly desugars into the optimal "make a map, call insert a bunch of times", though.
Last that I checked, Go's support for producing a library with a C-compatible ABI was still very limited. I'm not sure what progress has been made since then (and I wager you're going to want to wait until Go 1.6 later this year for support to mature some more). Given that this question is more Go-specific than Rust-specific (on the Rust side, it should be indistinguishable from calling a C library), I recommend that you try asking on /r/golang instead.
&gt; best talk no, _best_ tweetstorm ever
See: https://github.com/rust-lang/rust/issues/25725
I've seen an example of calling these two languages both ways here: https://github.com/lain-dono/go-n-rust
The images doesn't show here. Tip: instead of linking to images on "master", pin a specific commit. (or better, host a copy on redox-os.org)
Made a PR, but incase people are interested in the images before the site is fixed: * https://raw.githubusercontent.com/redox-os/redox/master/img/fun/fancy.png * https://raw.githubusercontent.com/redox-os/redox/master/img/screenshots/Sodium_v1.png 
I wrote one up a while ago: https://github.com/jrick/buildmodes
*mourns for the unloved [`collect!`](https://github.com/DanielKeep/rust-grabbag/blob/master/grabbag_macros/src/lib.rs#L27-L53) macro in `grabbag_macros`*
ZFS 😍👌💕
What? What does Redox have to do with Arch? Where does this post mention arch at all, let alone explicitly support it?
Oh, now it makes sense, thanks!
Thanks. Not a big deal, but the first one still appears broken for me.
These are the kinds of things I'd like to see as crate if the week...I'd never seen this before, awesome!
Thanks! Yeah, I realized that after. Not enough time....
Thanks :) Yeah, I am weird in that I really, really prefer longer talk slots. I did a 75 minute talk once and it was _awesome_.
Thanks :)
I'm curious, and this question isn't just for you, but the larger rust group as well; Is there any plans to do some Rust presentations or talks where the target audience is Rust people? I'm not knocking; these are good intro talks to rust and I typically learn some small tidbit here or there. But what about talks that go into a deep dive about explaining and using Send and Sync? Clone and Copy? Wheres the talk that details the Unsafe Guide? I'd be very interested in some intermediate / advanced rust talks that do a deep dive.
I would check out the talks from the first RustCamp: http://rustcamp.com/schedule.html There absolutely will be, in time. We're at the phase of Rust's development where a lot of the goal is outreach; I can't really pitch a "deep dive into X for Rust" talk just yet, because the number of people attending a conference who know Rust at that level just isn't there. That said, if you run a conference and you want an in-depth Rust talk out of me, please get in touch! I'd love to. I would expect that next year, you'll start to see some of these kinds of talks.
I don't see the Linux kernel ever switching to Rust (well something might emerge, but it probably wouldn't be called 'Linux' any more). FWIW check out devicemapper-rs (I am the author.) for using dm-crypt targets. You could write a Rust version of cryptsetup without too much trouble, just need to parse LUKS headers? algif_skcipher stuff appears to just be socket-based, or just use a userspace cipher lib? (Dunno, not my area)
Would be cool to have something like: for match in src.chars() { 'a' .. 'z' =&gt; { ... }, 'A' .. 'Z' =&gt; { ... }, _ =&gt; { ... }, }
This works quite well for the int, but how do I use it to read the structs? Do I just read a double at a time and put it into a struct? If so, that's fine, I just want to do it the right way.
It has to; the input stream may be ephemeral (like stdin).
You get payed to develop in Haskell on Linux? Lucky you :O
Huh...strange, it's still working for me. It's fixed on the site now though, so pics for all!
No, that's reading as if `match` was the loop variable. Too footgun-y.
Then nominate it (perhaps next week)!
&gt; but now mozilla want to abandon xul because of performance issues and too complex for a render engine I don't think that's the reason (well, perf will improve, agreed, but it's not the reason). What XUL could do in the past is all covered by HTML5 now. I don't see why Servo should try to become a UI framework, that's like a completely orthogonal direction.
What about dropping the `in`? for match src.chars() { 'a' .. 'z' =&gt; { ... }, 'A' .. 'Z' =&gt; { ... }, _ =&gt; { ... }, }
Personally, I like the `split_at` suggestion since `let (head, tail) = v.split_at(1);` is straightforward and gets the point across quickly. I did want to point out though that with a tiny syntax change, using it as a slice, and using nightly your match would work. See here for an example: http://is.gd/djI7h8 . Slice patterns are unstable though, so it's up to you whether you want to use them. One quick thing to point out though is that the `split_at` method will give you two `&amp;[T]`s, but the match will destructure to `(T, &amp;[T])`. Depending on what you want to do with them, it might be nicer to already have head out of the slice.
I'm not sure it's particularly footgunny? I can't really think of a situation where code would accidentally compile/do something unexpected due to `for match in ...`. It might be/is confusing for reading, but it seems reasonably unambiguous/any misuses will give a compile error.
Ok, so perhaps it's not a footgun, but it's still bad for readability.
Why not `while match .. { .. } {}` – that should work today, am I right?
I’ve started working on this library [a while ago](https://www.reddit.com/r/rust/comments/3ie7gp/whats_everyone_working_on_this_week/cug866p), once it was clear in-std dynamic_lib [will get deprecated](https://github.com/rust-lang/rust/issues/27810) at some point. The highlight here is this library preventing programmer from having dangling Symbols after the Library is unloaded [without much loss in convenience](https://nagisa.github.io/rust_libloading/libloading/struct.Symbol.html#examples). This library, however, is not a drop-in replacement for deprecated `dynamic_lib`. Namely, this library does not expose dubious APIs like library search path modification (`prepend_search_path` et al) and the string arguments are replaced with those that match conventions and system APIs better.
Oh right they're /u/neutralinostar or something on here.
Is there someone in the community team who I can talk to about setting up a meetup for rust?
You use the "flair" button. Did it for you.
I had a [pre-RFC](https://internals.rust-lang.org/t/pre-rfc-loop-for-else-match/930) for this (along w/ `loop match` and `else match`) a while back that didn't get any traction.
I made this mostly to practice rust but also because I want to create a wiki for the new SAFE and IPFS networks. The serverless nature of these networks probably is going to make existing wiki technology difficult to use and before search engines are available, wiki link pages can be very helpful. Also, as an added bonus, I added a markdown helper to [handlebars](https://github.com/sunng87/handlebars-rust/pull/47) but haven't used it in wiki2 yet, though I plan to.
That's right. Gotta keep em guessing
You're using an iterator that yields values, which consumes the vector in the process. At the same time you're trying to keep references to these values. That cannot work. The solution is to use an iterator that yields references. let x = vec!["1", "2", "3"]; let mut hm = HashMap::new(); for number in x.iter() { hm.insert(number, name(number)); } 
Done!
As always, please feel free to ask any questions or suggest any comments at the [Github repo](https://github.com/shepmaster/rust-ffi-omnibus) or here and I can transfer them over there as appropriate! Any feedback on the idiomaticness of the new languages is appreciated! Especially C#, as I wrote that all by myself. All the other languages were [contributed by people](http://jakegoulding.com/rust-ffi-omnibus/contributors/) who know what they are doing, and then I added new topics to them. All mistakes are mine, all good ideas are theirs! \^_\^
He could, because array/vec references have an IntoIterator implementation.
Multiple ways, depending on what you want. If you can want to match it against a pattern, and it will always match that pattern (you just want to desctructure) you can add the pattern directly on the for. struct Point(i32, i32) for Point(x, y) in point_list { ... } If you want to run until it cannot match anymore then you want to use a `while let` let mut iter = optional_points.iter() while let Some(Point(x, y)) = iter.next() { ... } Notice this stops as soon as you fine a `None`. Now if we really want to get powerful though we would want to use iterators instead. The really great thing about iterators is that you can actually join the results, handle the errors, and do a lot of really powerful things. let results = list_of_results.mut_iter() .map(|el| match el {...}).collect::&lt;Vec&lt;Result&lt;(), Err&gt;&gt;&gt;(); The above will return to you a list of Result&lt;(), Err&gt; which will show you each and every failure. We can easily make it return only one result showing all errors that happened: let results = list_of_results.mut_iter() .map(|el| match el {...}).collect::&lt;Result&lt;(), Vec&lt;Err&gt;&gt;&gt;(); if we want to stop running when an error happens instead we do: let results = list_of_results.mut_iter() .map(|el| match el {...}).find(|r| r.is_err()).unwrap_or(Ok(()); This only returns a result with the last error or `Ok(())`. Finally there's a small chance that you might be working on an area that uses this pattern a lot and the other solutions aren't quite working for you. You can build your own quick solution to it with a macro. macro_rules! for_match_in{ {$expr:expr; $($pat:pat =&gt; $result:expr,)*} =&gt; { for x in $expr { match x { $($pat =&gt; $result,)* } } } } for_match_in!{list; Some(n) =&gt; println!("{}", n), None =&gt; println!("NOTHING"), } With some tweaking you could change the syntax a bit to something like: `for_match_in!(expr {match_cond =&gt; event, ...})` or any other variation, but the basics are there.
The trouble is, since they take a closure, they won't let you `try!` inside it as easily :(
I would still like `for a in src.chars() match { ..`, in order to be able to refer to `a` if applicable. So this would essentially remove one indentation level. I like it.
I think it should be submitted anyway (and I favored the `for a in src.chars() match {` syntax, but your `for match i in foo.iter() {` also works) But perhaps a macro could implement this?
You can always package it up into a discriminator: http://is.gd/6X4fp8. Too heavy-handed, maybe.
I think that's the idiomatic (and syntactically "cleaner") way to write it.
This is the kind of this I wish had more exposure. I'm not sure if this qualifies as crate of the week, but it perhaps should be.
An example, with as little cruft as I could think of. http://is.gd/hFoEGT You are passing along the type hints. You need to make sure to pass exactly the generic type that was passed in at the top of the function every time you call a subroutine, but that's not tremendously hard. As I said, you could factor it all out by introducing a new dummy struct for your entire codebase, but then you are stuck programming within a single impl, which might feel awkward.
I notice that you suffix `_t` to your C types. Obviously there's nothing stopping you from doing this, but bear in mind that it's [not strictly portable](http://stackoverflow.com/a/12727104/3355169). I have been bitten in the arse by this before. Edit: Also just out of interest, why do you need the `fix_windows_linking` in the integers example?
I think this should become a book chapter *somewhere*, with a clear code example like this. Perhaps on /u/nick29581's ["Rust design patterns"](https://www.reddit.com/r/rust/comments/3ptlgq/design_patterns_in_rust_blog_post/cw9asjq). Because, on a first impression it's too complicated, but on the other hand it's a very clean idiom and addresses a real world need. The solution should be to make it generally accessible to Rust developers, make it part of some kind of "Rust training material". If everyone knows about this idiom, it becomes more usable (you don't need to explain it to other developers, etc).
You can overload operators? You can't overload functions, but operators are trait based and you can have multiple `Add` impls for different operands. Rust, however, has made the choice not to have integer-float Add impls. Not sure why. Probably because there are footguns here depending on where the implicit cast happens; I've certainly had my share of bugs where the cast happens late.
You seem to confuse operator overloading with function overloading. Rust has operator overloading. And while you couldn't implement `Add&lt;RHS=i32&gt; for f43`, you could easily do so for your own types (you can't implement traits for types when both the type and the trait are defined in another crate).
Is it possible to write a library like nom without an interface that depends on macros? What would be the shortcomings, perhaps too much boilerplate? I considered using it, but I feel the macros makes the code harder to understand. Besides this: &gt; **IMPORTANT NOTE**: Rust's macros can be very sensitive to the syntax, so you may encounter an error compiling parsers like this one: &gt; named!(my_function&lt;&amp;[u8], Vec&lt;&amp;[u8]&gt;&gt;, many0!(tag!("abcd"))); &gt; You will get the following error: "error: expected an item keyword". This happens because `&gt;&gt;` is seen as an operator, so the macro parser does not recognize what we want. There is a way to avoid it, by inserting a space: &gt; named!(my_function&lt;&amp;[u8], Vec&lt;&amp;[u8]&gt; &gt;, many0!(tag!("abcd"))); &gt; This will compile correctly. I am very sorry for this inconvenience.
&gt; Rust, however, has made the choice not to have integer-float Add impls. Not sure why. Rust does no implicit type conversions at all. http://is.gd/e8OlCZ : 1i8 + 1i16; error: mismatched types: expected `i8`, found `i16` (expected i8, found i16) [E0308] This causes some tedium for certain kinds of code, but imho is a good decision for a language that tries to cut down on common bugs. It's a good idea to make the dev choose the numerical precision of every operation when both operands are not the same.
I'd never choose markdown for a wiki. Its syntax is too inflexible for things like wiki links, and you end up creating just another incompatibility dialect. /edit: why downvote? this is constructive criticism.
Go does this and, while it's annoying, it has helped me decide on types and has probably eliminated some bugs.
It seems to be a problem that keeps cropping up with the font used, Fira Sans. See [this bug](https://github.com/rust-lang/rust/issues/19257), [this bug](https://github.com/rust-lang/rust/issues/24614), [this bug (slightly different issue, with the font used for code instead)](https://github.com/rust-lang/rust/issues/24355), [this thread](https://www.reddit.com/r/rust/comments/3k5nnr/this_week_in_rust_95/cuuzeif). Most of them boil down to people having a corrupt copy of the fonts installed locally; apparently, some earlier versions of these fonts had trouble rendering in certain browsers. For most people, the solution is uninstalling or updating their local copy of the font. Not sure if that's you're issue, but that's the first thing I'd take a look at. Do you have Fira Sans installed locally? Does removing it help fix the problem?
I actually think that one can use Markdown for a wiki with one observation: the link target named by `[target_name]` or `[link text][target_name]` may not exist. Many Markdown processors (correctly) reject them and render as is, but a wiki processor may turn them into a link to the page which name is same to the target name. &lt;/off-topic&gt;
Oh hell yeah. You should post this in SAFE forums. I am surprised you are preparing the app for safe network. That's awesome! 
So it's all about interpreting MRI data. I get a stream of values (in a type specified in the header) that I want to convert into u8 ranges in order to display them as greyscale intensities. Using what you've said I've got to this : pub fn normalise_data&lt;T: Ord + Sub + Copy + Div&gt;(&amp;mut self, raw: Vec&lt;T&gt;) -&gt; Vec&lt;u8&gt; { let max = raw.iter().max().unwrap(); let min = raw.iter().min().unwrap(); let range = *max - *min; for x in raw { let val = (((x - *min) / range) * 255) as u8; } vec![] //Placeholder } But I run into problems at the end due to 'binary operation /' not being allowed.
You really should specify `CallingConvention = CallingConvention.Cdecl` for all the C# P/Invoke attributes. I do not know what the default is on Mono, but on the .NET Framework it is `Winapi` aka `Stdcall`, which will probably lead to stack imbalances since Rust is probably exposing `Cdecl`.
good thinking, thanks for the heads up
The following compiles, but I didn't check if it actually works. I think that you have to specify output for the operator traits. And you have to work with a reference to raw (as mentioned by others) use std::iter::Iterator; use std::ops::{Div, Mul,Sub}; pub fn normalise_data&lt;T&gt;(raw: &amp;[T]) -&gt; Vec&lt;u8&gt; where T: Div&lt;Output=T&gt;+Mul&lt;u8,Output=T&gt;+Sub&lt;Output=T&gt;+Into&lt;u8&gt;+Copy+Ord { let max = raw.iter().max().unwrap(); let min = raw.iter().min().unwrap(); let range = *max - *min; raw.iter().map(|x| (((*x - *min) / range) * 255).into()).collect() } EDITS: Using `&amp;[T]` as proposed bu sellibitze. Using into to avoid references
Requiring `T: Sub` does not say anything about the result type of `x - *min` or `*x - *min` (if you change `raw` to be a `&amp;[T]` which you probably should). So, the result is of *some* type (not necessarily `T`) which you can't use in the division because you didn't say that the result type of the subtraction should support division. What you probably meant was `T: Sub&lt;Output = T&gt;` which constrains the result type of the subtraction to be `T` itself.
Great resource. [I proposed it to rust-learning](https://github.com/ctjhoa/rust-learning/pull/25). Other more complex examples might use Rust str, slice, String, and Vec types, which have simple representations, instead of the C types. Not sure how much compatibility glue this requires in the other languages, but it could make the interfaces nicer for this type of language-embedded Rust code. 
Chromium is used for UI frameworks and it's doing fairly well at that.
I know the difference between an array and a vector, I was just wondering if there was some reason significant to the example that the change was made.
&gt; sudo cargo run -- --help &gt; &gt; sudo cargo run -- -d ./tests/test1/ -h 0.0.0.0:80 Why is there a sudo in these commands? This is harmful.
ah, so just absolute links like `[Hi!](/sub-folder/)` in your example. what if you put it as `mydomain.it/wiki/...`? all links break!
[Off-topic Question] If I open a database connection pool in rust and call it from a nodejs program, is there a way to retain the connection pool without opening a local port on the machine? 
This week I'm going to give a talk about clippy at the Rhein-Main meetup. Otherwise too much work to get much of anything done.
There are a few shortcomings, yes. Doing the same thing as nom with a typed interface results in longer compilation times, and the borrow checker can get really annoying when you only transmit slices of the input. My first approach with nom was to do it that way, but it made the code unmaintainable. Macros, despite their issues, make the code easy to write, and they leverage the compiler's type inference all the way. By the way, `named!` is just a convenience function, the code you wrote above can be equally written as: fn my_function(input: &amp;[u8]) -&gt; IResult&lt;&amp;[u8], Vec&lt;&amp;[u8]&gt;&gt; { many0!(input, tag!("abcd")) } It is just a lot easier to read when you remove the all the additional syntax.
The right thing to do is completely stop using types from other crates in your function signatures, except if you reexport these types and tell people to use them. For example, this is bad: extern crate libc; pub fn do_something(value: *const libc::c_void) { ... } This is bad because if you want to use `do_something`, you have to pull the same version of `libc` as the library that contains the `do_something` function. However this is fine I think: extern crate cpal; pub use cpal::Endpoint; pub fn do_something(_: &amp;Endpoint) { ... } Because now the user can manipulate a `mycrate::Endpoint` instead of a `cpal::Endpoint`, and doesn't have to pull `cpal` on their own project. There are a lot of projects that have this problem (piston, r2d2, iron plugins, winapi, glium with image/cgmath/nalgebra, etc.), and in my opinion they should just stop and use a proper hierarchical model. 
About the typing, this is not an issue, since the generated code is completely checked by the compiler. Sometimes, you need to think a bit about the result type of a combinator (like, `many0!` returns a `Vec` of the result type of its child parser). The only problem I saw was that sometimes, the type inference cannot decide, so it does not compile, but I fixed those issues with more info in nom. nom needs macros for readability because parsing is hard ;) Writing a parser manually means spending your time handling offset and checking error cases, and this will be the cause of a lot of mistakes and vulnerabilities. A good parser lib should abstract data consumption and error reporting. Also, in nom, you get partial consumption of incomplete data, and zero copy parsing, for free :) About `chain!`, it has grown too complex, but any replacement might follow the same way. In the meantime, I added [`try_parse!`](https://github.com/Geal/nom/blob/master/src/macros.rs#L313-L352), which works a bit like `std::try!`and I'm quite happy with it, it simplifies a lot of code.
I still have a tool similar to [semantic-release](https://github.com/semantic-release/semantic-release) on my todo list. It would auto-bump versions numbers, check if it breaks anything (based on tests) and auto-publish if everything went well. Stop worrying about doing the right release, let the computer figure it out for you.
Haha. It was a few years ago when I was learning C at uni and we were doing the main assignment of the module. Part of it involved benchmarking certain parts of the code so I grouped related timings into a struct which I called `time_t`. My compiler was absolutely fine with it (maybe I wasn't being strict enough with warnings at the time) but my lecturer's compiler was having none of it so I almost lost all the marks for my code since it wouldn't compile. Luckily I showed him that it did compile on my machine and got most of the marks. 
Bring more type-safety to my wayland bindings, hopefully releasing a 0.4 that will mostly look like a final version. Once done, update my wayland utility crates to it, and start working of the wayland *server* bindings.
I'm quite busy this week, but I try to continue the _Writing an OS in Rust_ series. 
- Final libcpocalypse cleanup throughout piston - Remove the elmesque dependency from conrod and expose a nice conrod-specific portable backend. - Finish and open source my timeline crate (something I anticipated getting done last week before the wild libcpocalypse appeared). - Hunt for remote, part-time development work (any suggestions / recommendations appreciated!). ... I was about to write more, but lets be realistic - this will take me at least a week.
Great idea! I've always said you should never let a human do a machine's job. B-) Note that this would need to check all possible versions between the current declared and the newest (possibly starting from newest and stopping once a working version has been found), which may take quite a while.
Nice! It's one of those times when you look at something and thinking "right, *this* is how to do things the Rust way" :-) Just a question: Normally calling an external C function is unsafe. With this API, loading the C function is unsafe, but not calling it. Is that expected?
It is something that I would rather not have to do. I always get a permission problem without sudo. I definitely want to remedy this
Ok so I think I'm getting there slowly. With your example, the function compiles, but if I try to call it on a vector (of T: i16 in this example), I get: the trait `core::ops::Mul&lt;u8&gt;` is not implemented for the type `i16` [E0277]at line 44 col 21 the trait `core::convert::From&lt;i16&gt;` is not implemented for the type `u8` Would this mean I have to implement these traits for all the types I want, or have I got the wrong trait definitions or should I try to cast variables before I do any operations?
I'm really unclear on what exactly cargo's behavior about all of this is and it would be cool if it were documented better. How exactly does cargo handle conflicting version requirements? What versions exactly match a requirement like `0.1.2`?
So, just to be clear, if your crate used libc 0.1 and you moved it to 0.2, AND it doesn't use libc types in public functions signatures, there is no need to mark this as a breaking change and you can only bump the "tiny" version number? That's how I understand it, but I'm not sure I'm right ^^
For the 0.x.y releases, I follow semver's "anything may break at any time" convention. It's a good practice to indicate breaking changes with bumps from 0.x to 0.y, but it's not required. That also means that a crate graduated post 0.x versioning should not have (transitive) dependencies that are still in the pre-stable 0.x phase.
You can run on another port by changing the arguments to the program edit: also, i did not compile with sudo
I noticed this behaviour, and was a little bit surprised by it as well. Apparently, its only external-extern functions that are unsafe to call, following code snippet can easily be called [without any unsafety annotations][play]. [play]: https://play.rust-lang.org/?gist=5ac89bffd2d9ada14069&amp;version=stable extern "C" fn id(u: u8) -&gt; u8 { u } Sadly, you can’t really require returned functions be unsafe in Rust (AFAICT), so you’ll have to do with only `get` being unsafe. That being said, you can easily do let sin: Symbol&lt;unsafe extern fn(f64) -&gt; f64&gt; = unsafe { lib.get(b"sin\0").unwrap() }; to also make the function unsafe too 😊
handlebars-rust author here. Thanks for the helper. It's really nice to see applications using my library.
No usability cost if the scope you want to use the symbols in is statically delimited... what if you want to, say, load the library in a constructor and use the symbols from the type's methods? I think you'd need some kind of reference-counted version of the Symbol type.
&gt; I don't really understand the issues at hand that makes kernel32-sys adopt this behavior, but if your version number bumping includes bumping a crate like that, then incrementing the first non-zero digit in your version might be a good idea The issue is, I believe, difficulties around linking to native libraries successfully, especially if you try to do it multiple times (generally speaking a native lib can only be linked to with one configuration... so which one should be chosen when there's several?). Cargo tries to ensure that there's only one place that controls the linking in any dependency graph, via the [`links`](http://doc.crates.io/build-script.html#the-links-manifest-key) key. Hence, these problems should theoretically be restricted to `-sys` crates, if the naming convention is followed.
`0.1.2 := ^0.1.2 := &gt;=0.1.2 &lt;0.2.0` In general: &gt; Caret requirements allow SemVer compatible updates to a specified version, 0.x and 0.x+1 are not considered compatible, but 1.x and 1.x+1 are. [See the documentation on semver](https://github.com/steveklabnik/semver#requirements) (and http://doc.crates.io/crates-io.html#using-cratesio-based-crates). 
yep, if min and max are adjusted.
First and foremost, it looks like `server_v2.rs` is doing something very different than both `server.rs` and `server_v3.rs`. Unless I'm having a major brain meltdown, it looks like `server_v2.rs` is just doing reads of no more than 4 bytes and printing each read as a new line. In contrast, `server.rs` and `server_v3.rs` are both searching for and allocating memory for each new line it encounters. It's not surprising that this would be slower than a series of 4 byte reads. It would be interesting to try `server_v2.rs` with a `BufReader` and see what happens. It's worth nothing that `std`'s implementation of the `Lines` iterator is not quite as fast as it could be. Two reasons. First is that it allocates memory for every line. Second (AFAIK), it uses a slow loop to find the new line byte, which can be sped up dramatically (sometimes by an order of magnitude) with SSE2 instructions (i.e., use `memchr`). The first problem is solved by using `read_line` directly, which permits control over the allocation. The second (and first) problem is solved by the [`lines`](https://crates.io/crates/lines) crate, although its API is somewhat idiosyncratic. I note that it's hard to actually witness a big performance difference unless you're reading a huge file with lots of lines, and your processing on each line is fast. I don't think this is related to `BufReader` at all. It would be better to first make sure you're doing an apples to apples comparison.
To clarify/correct me if I'm wrong, this designed to solve the problem of `mycrate` using `yourcrate` and `theircrate`, both of which expose `cpal` types in their API but which depend on different versions of `cpal`, so there's no way for `mycrate` to explicitly pull in the two versions of `cpal` that are needed for interop with both. By reexporting, `mycrate` can pull in the right types/functions for each `*crate` from that crate itself. Right? That is, it isn't solving the problem of a version bump to `cpal` requiring a version bump to `yourcrate`/`theircrate`... both are still indelibly tied to the version changes of `cpal` and need to reflect major version bumps to that dependency by major version bumps to themselves.
Currently rustc forbids you from using a private type in a public function signature. It should just be extended to treat `extern crate` as something private (which it is). Unfortunately there are already a lot of bugs in this visibility system, it looks like it is a awfully complex code. 
I had a ton of fun with [Philipp Oppermann's great blog posts about Rust kernels](http://os.phil-opp.com/), and I sort of kept going afterwards. :-) /u/steveklabnik1 encouraged me to write about some of the next steps involved in implementing a kernel, so here's the first one. This one is mostly about using Rust traits to make a nice API around a low-level hardware feature. If people are interested, I can write more about interrupts and keyboard I/O and other stuff like that. :-) And please feel free to ask questions!
I don't think this applies. Cargo uses a (more useful) variant of semver that says that only changes to the first non-zero number are considered breaking, e.g. `0.0.1` to `0.0.2` is breaking, as is `0.1.5` to `0.2.0`, but `0.1.5` to `0.1.8` is not. By having correct version constraints (which are the default, as long as `*` is avoided), you automatically only depend on versions that will work, e.g. if your lib has `foo = "0.1.2"` in its Cargo.toml, then cargo assumes it work with any `0.1.x`, with `x &gt;= 2` which will be true assuming `foo` follows (cargo's variant of) semver. In summary, this means that a 1.0.0 library can use a 0.x library just fine: breaking changes to the 0.x library will be released as 0.(x+1).
I see. I guess I can kind of buy that. One thing at least worth noting is that, at least for the Rust ecosystem, we've adopted a convention where `0.x.y1 -&gt; 0.x.y2` should not include any breaking changes. This makes it possible to depend on `0.x` of a crate with reasonable assurance that things won't break.
In the advertisement, it says "BS in Computer Science or equivalent experience." I have a PhD in Chemistry and have experience in programming in Python and Haskell. Is it worth apply? I am willing to relocate and would love to be working in a position where I can learn (also, I visited the Mozilla office in Taipei last week, it's a pretty sweet working environment they have there.)
Rust's generics are good enough for now (and I'll have no issues once specialisation lands), I just wish the standard library made better use of them.
Arch is particularly annoying here, but the most recent version from the package repositories is reported to work. https://www.archlinux.org/packages/community/any/ttf-fira-sans/
&gt; No usability cost if the scope you want to use the symbols in is statically delimited... That’s true, thank you for your insight. &gt; I think you'd need some kind of reference-counted version of the Symbol type. Reference counting a `Symbol` wouldn’t help in this particular case, while refcounting the `Library` itself (and keeping a reference to library in each symbol) might. That being said, I believe in composition (read: letting people to use the standard library `Rc`/`Arc` types on their own accord) and don’t think imposing something out of the box is the right solution. &gt; what if you want to, say, load the library in a constructor and use the symbols from the type's methods? My initial instinct was to suggest something like the snippet below, however this has a [bunch of non-trivial issues](https://github.com/rust-lang/rfcs/issues/744#issuecomment-134349161) with it. struct DynamicMath { sin: Symbol&lt;'static, extern fn(f64) -&gt; f64&gt;, cos: Symbol&lt;'static, extern fn(f64) -&gt; f64&gt;, library: Box&lt;Library&gt; } impl DynamicMath {…} I’ll ponder on it. Thanks for the insight again!
Suppose you have dependencies like `A -&gt; B -&gt; D` and `A -&gt; C -&gt; D`. `D` comes out in a new backwards incompatible version and `B` is updated to use the new `D`, but `C` isn't. To avoid this causing problems for `A`, cargo/rustc will insert one old `D` and one new `D`. Works great in theory, but in practice, this will still cause problems when: * we depend on there being only one `D`, such as if `D` is the log crate. * in case there is a `D::Struct` that `A` wants to retrieve from `B` and give to `C`. (The compiler will complain that `D::Struct` is not the same type as `D::Struct`.) * you worry about code bloat. I'm not really suggesting any other solution, because I don't have any at the moment, just highlighting that this seems to be a problem.
I understand the problem, I just don't have a full grasp of cargos behavior in the face of conflicting dependencies. Does it always link as many versions as needed, or are there cases in which cargo will not even attempt a build? Not compiling, as in your second point, is the correct solution. That *is* a type error because they are different types. In what way does the log crate depend on there only being one log crate that causes a runtime error?
I can't find where in those docs it says that unadorned versions are treated as caret requirements. That's all I was asking, is it caret or something else.
Hmm; that seems pretty scary to me. Are you saying that you'd want to pass a Rust `String` across the FFI boundary? As far as I know, that isn't guaranteed to work as [it is not `repr(C)`](https://github.com/rust-lang/rust/blob/1.4.0/src/libcollections/string.rs#L32-L37). From [the book section on FFI](http://doc.rust-lang.org/stable/book/ffi.html#interoperability-with-foreign-code): &gt; Rust guarantees that the layout of a struct is compatible with the platform's representation in C only if the `#[repr(C)]` attribute is applied to it I believe the same applies to `Vec`; and I'd err on the same side for `&amp;[T]` and `&amp;str`. Is there some guarantee that these types are guaranteed to pass across the C boundary unchanged that I am unaware of?
Ugh. I guess I'm going to have to bring up a Windows VM and test some things out \^_\^. Any idea how the GNU / MSVC or x86 / x86_64 ABI differences come into play here? Any hints on a piece of code that would definitely *fail* if I get the calling convention wrong? That would allow me to be pretty certain that I got it right.
Not quite, unfortunately. It forbids you from using a *type not declared `pub`* in a public signature. If you put a `pub struct` in a private `mod`, that's allowed. I imagine `crate`s would follow similar logic.
&gt; Why do you need your own text editor? because reasons. &gt; Is it not possible to port a complete text editor into Redox? sure it is, but isn't it possible to port an OS to Rust? Why making a new OS in the first place? Why crafting a new programming language? You see? 
That's an awesome design idea, I was looking for something like that to avoid the "dummy"-trait design. My idea so far was to use an enum to wrap all the possible types, but I think your design is much more elegant and avoids the creation (polution?) of any additional type altogether.
I think there may be multiple ways to break builds here. One I hit going through the `glium` tutorial, which I think would be fixed by tomaka's solution, is as follows: extern crate image; extern crate glium; ... let image = image::load(...).unwrap(); let texture = glium::texture::Texture2d::new(&amp;display, image).unwrap(); This gives a somewhat opaque error message if the explicit `image` dependency and the transitive (through `glium`) become separate crates (due to version mismatch). No `theircrate` necessary, in this case. If it were instead `glium::image::load`, the explicit `image` dependency would not be involved, and I think `mycrate` wouldn't have to care about the version of the transitive `image` dependency.
&gt; where the presenter has used vim without constant errors My personal experience is that this is mostly caused by having to stand up which messes with my muscle memory; maybe standing desks would be good training for giving live coding talks.
Sorry if this is obvious, but did you compile in release mode? I've seen lot's of reports on poor performance that resulted from debug builds.
Nice! Thanks for sharing the existence of feature(const_fn) which I completely missed.
That looks nice! Everything I don't have to build myself is a good thing. 
Do you realize that `BufReader` can wait an arbitrary amout of time in `TcpStream::read` for the OS to fill the buffer? The line iterator will give you a next line if it's already in the buffer, otherwise it'll just sit and wait for the buffer to be filled with some new data. To implement line buffering properly you'd need either a non-blocking socket (because it gives you the guarantee that it will return what it has ASAP and won't block waiting for more data in `read`) or inefficient one-byte reads (example of implementing line buffering with one-byte reads for a very similar problem: https://www.reddit.com/r/rust/comments/2nka2k/interactive_pipe_reading/).
For 32-bit the two primary calling conventions are `stdcall` and `cdecl`. `extern "C"` in Rust uses `cdecl`. `extern "system"` in Rust uses `stdcall`. C code on Windows is typically compiled using `cdecl` by default, although some projects change that. Windows API is almost entirely `stdcall`. There are a few other obscure ones like `fastcall` but you'll rarely run into that. On 64-bit everything is the same. The only calling convention that is different is `vectorcall` which is very rarely used and is never the default.
If you're interested, this seems to be more-or-less the same encoding as used in the paper [ML Modules and Haskell Type Classes: A Constructive Comparison](http://www.stefanwehr.de/publications/Wehr_ML_modules_and_Haskell_type_classes.pdf) ([journal version](http://www.stefanwehr.de/publications/Wehr_ML_modules_and_Haskell_type_classes_SHORT.pdf)) for their ML-&gt;Haskell translation.
it's not the correct way but you could define an empty function which takes the file handler, which would take ownership of the file then immediately go out of scope, calling the destructor :P
You can just call a destructor explicitly by using the [drop](https://doc.rust-lang.org/std/ops/trait.Drop.html) function.
The problem only happens on x86, because there is only one x86_64 calling convention. It might actually happen with Mono too, if you try on 32-bit (I'm not sure). I've been trying to reproduce something in C# that consistently fails, but I can't get something that fails reliably when you `stdcall` a `cdecl` function. Sorry. You can use VS's debugger which will alert you when it detects stack imbalances. 
Yeah, that's why I clarified with "generally speaking". As you say, there are cases where there's no choices at all, and it may be worth seeing if/how cargo can handle duplicates of them gracefully, I don't know.
The only purpose of `links` as far as I can tell is to stop things from building. But my `-sys` crates simply tell the linker to link a system library so there's really no reason to break if I happen to specify a particular system library twice. The linker is totally cool with it. Thus `links` is entirely useless and buys me nothing except pain. I'll be removing it soon unless someone can convince me otherwise.
By the way, I got a `Utf8Error` when I was trying your Strings example. .NET does not pass UTF-8 strings by default, it either passes ANSI or Unicode (UTF-16). I'm not sure how your example worked on Mono..
Note that you linked to `Drop` trait, which is different from [`drop`](https://doc.rust-lang.org/std/mem/fn.drop.html) function. `Drop::drop()` can't be called directly in Rust.
`links` also allows to overwrite linking options generated by build script: http://doc.crates.io/build-script.html#overriding-build-scripts
It can still use `memchr` to find `LF` though? Then look for and trim `CR` afterwards. Maybe that defeats some of the gains of `memchr` though!
No need to apologize. :-) You can't be blamed for doing what is conceivably the right thing!
I just hit a milestone on my project [gar](https://github.com/psyomn/gar)! I'm pretty happy as it is quite usable. You can't query with very complicated requirements, but it should help you enough to find the data you're looking for and go from there. Next step would be to make everything concurrent. That would be pretty cool and fun, but I'm not sure how much time I'll have this week.
Thanks! I knew some of this from my past, but having someone who is in the thick of it today lay it all out is nice. You mind if I copy some of this into the *Omnibus*? I also really appreciated the [title of your bug](https://github.com/retep998/winapi-rs/issues/238) &lt;3.
[Guess who else does this](https://github.com/rust-lang/rust/blob/master/src/libstd/ffi/c_str.rs#L459) and caused breakage because libc 0.2's c_char differed in signedness &gt;.&gt;
Any mention of `unsafe` usually necessitates a very stern warning. There's often a smarter way of going about things, but I just can't think of one for this exact situation. If you find my answer satisfactory, would you mind setting the "solved" flair on your post?
I had a big slump for the last two weeks but picked back up by [bootstrapping the Imp parser](https://github.com/jamii/imp/blob/master/diary.md#parsing). Now working on bootstrapping the compiler too.
That's weird! Perhaps like user flairs, it's restricted to mods only. Oh well! They'll set it when they see this conversation, I guess.
Right, you have to check the previous byte after the call to `memchr` for `CR`. Should be able to just change this line here: http://doc.rust-lang.org/stable/src/std/io/mod.rs.html#1175
Working on the website: particularly the [contributing page](https://github.com/rust-lang/rust-www/pull/199) and the [faq](https://github.com/rust-lang/rust-www/pull/202).
Sounds like a good plan to me. To be honest, in your place I'd just start with implementing ES3 and then add those features of ES5 and ES2015 that cannot be transpiled to ES3 code.
&gt; one person's free time In the open source world you never know who might join you... :3
This might have been fixed just recently as `kernel32-sys` was [just bumped to `0.2.1`](https://crates.io/crates/kernel32-sys). Try running a `cargo update`?
Still working on my raytracer. Here, [have some cuboids](http://qrpth.eu/trace2.png).
No, even integer-only widening can be hairy, because it can be done "too late" and make incorrect code seem correct. Consider let x: u32 = u16a + u16b; Today this doesn't compile. If we add widening coercions, then this will likely become let x: u32 = (u16a + u16b) as u32; but this is less safe than let x: u32 = u16a as u32 + u16b as u32;
I honestly don't think Rust is enough. You probably want to get closer to proving that your code is correct than Rust's memory safety can guarantee. At that point you might as well target C (if you can prove your code correctly implements the specs). Languages with dependent types (like Idris or Agda) might be more interesting, because their type system can prove more than Rust's. (But then, they are probably not efficient enough.)
Great post! A few things I noticed: #### 1. &gt; Well, technically, enums are just advanced version of structs. To be even more technically correct, Rust’s enums are in fact ADTs in disguise. ADT stands for algebraic data type, a pattern that can be often found in functional programming languages, and that allows us to define complex (even recursive) data structures solely within the type system. I think this is a bit misleading, because structs are complementary to enums and I think they are ADTs as well. You want sum types (enum) and product types (structs). Also, ADTs are not specific to functional PLs, you can have ADTs even in C (see [the Wikipedia article](https://en.wikipedia.org/wiki/Abstract_data_type) for examples). #### 2. return match payload_len { PAYLOAD_LEN_U64 =&gt; input.read_u64::&lt;BigEndian&gt;().map(|v| v as usize).map_err(|e| io::Error::from(e)), … } Won't this silently cut off data on 32 bit systems? (I think there are a few other places were a `u64` is cast to a `usize` as well.)
&gt; The speed isn't going to blow anyone's minds, the resources Google, Apple, Mozilla, Microsoft, etc. have to optimize their respective engines is far greater than I, a single person working in their spare time, can compete with. Hmm. Pray to, or recruit (isn't that the same thing?) /u/mikemike? 
Continuing work on my Rust/Elm control panel project, 'oscpad'. Next up is to add shared state so all clients see the same control state - buttons pressed, slider positions. After that, adding touch support to the controls. 
The opposite for me too, because my issues were lack of tooling, libraries and stability. From that perspective, the period following 1.0 has been the most exciting time.
This was an enjoyable read and I always enjoy Andrei's candor. I think I gleaned more knowledge on D here than the others, but that was to be expected. I really see Go as being out of this race. It seems to encroach more on Ruby, Python and Java than the system languages. But even then it's not my cup of tea. Do people no longer talk about Nim? I feel it's prospects are much greater in this realm. It seems to be coming along nicely and their resources seem to be well put together. Nim certainly has some advantages of compiling to C. The prospects of D giving you powerful zero cost abstractions, and powerful generics whilst at the time offering first class C ffi and capable as serving as a scripting languages where memory management is shoved out of sight! That is a tantalizing pitch. I feel I have a much less clear insight into the community and learning resources than rust, which has been a huge help in getting me in the door. This might just be me not looking hard enough. At any case I'd like to give it a try. As for Rust, I've chosen to pick it up really because I've enjoyed C more than any other language. But dread debugging aliasing, use after free, and other race conditions. I really do like to think about memory management, and I really do want to be babysat by the compiler. My favorite thing about Rust though is its type system. For whatever reason I dread the C++ and Java style OO. Templates, interfaces, inheritance. Then composing all that. Ugh. Rust to me actually feels more like giving C an ML-like type system than anything. The nice thing about Rust right now, is that it's getting some serious industry upswing, with success. I know a lot of people want generics and higher kinded types. Hopefully those hit at some point. Even with perhaps the lengthy development cycles of rust. The final results of both safety and concurrency are justifying the upfront budget. The thing I always find myself wondering about the future of rust in being used in real-time infrastructure systems, or massive scientific institutions like Nasa and Cern and other areas of precision research. Both for fault free controllers, or for accurate simulations.
Well, I think that the 1.0 hype bubble was a real thing. For those of us that have been following rust both before and after the 1.0 hype bubble, there's definitely been a marked uptick in interest, in size and quality of the Rust ecosystem, and so on, compared to, say, a year ago. But the [hype bubble was a real thing](https://mo.github.io/assets/git-source-metrics-golang-vs-rust-active-developers.png), so for people on the outside, who may have heard most about Rust during that time, it might appear that interest has dropped off sharply since then. So, I think that in the long term, Rust is doing great at getting out the word, attracting new contributors, and building up an ecosystem. And the post-1.0 stability (libc issues aside) has been a big boon to that. But in the short-term, if you look at peak hype to now, it looks like everyone stopped being interested in Rust after 1.0 was released.
Just to add more information, ES6 like doubles the ECMAScript spec length.
I think stuff like this is a great addition. We're just now figuring all this out, best to write it down now :)
&gt; changing too fast. I'm not saying that you're wrong, but I'd be interested in hearing more about this. Given post-1.0 stability, change shouldn't be a huge problem.
That wouldn't eliminate the issue entirely, but for practical purposes, it would probably be sufficient. The problem with using tuples is that someone might actually be using those to represent data. A type specifically created for the purpose of expressing these types of bounds doesn't have that problem, since you'd basically have to go out of your way to create a type that'll mess up the system. As long as you don't make safety contingent on the correct categorization of type, it should be fine.
While I respect Andrei's opinion a lot, he's evoked the image of a "large borrow checker muscle" in Rust multiple times. I think that's not really an accurate description. I find that the borrow checker, while one of the most _advertised_ parts of Rust, is not the one place Rust spends all its design budget. Certainly the one place Rust does something almost completely new (instead of mixing up random language features from other languages), but D and Go don't have any of that so that's not really on the table anyway. And, in fact, parts of the safety architecture (affine types) is as useful for unrelated things as it is for memory safety. Affine types let you think about data in a very intuitive way. Something I miss tons in C++. But memory safety aside, Rust has plenty of awesome features (exhaustive-matched enums! awesome closures! cool iterators! zero-cost abstractions! tools to build your own! monadic errors! post-parser macros! traits!) which are key features in the language over others (though these have all been borrowed from other languages).
ES5 is scarcely bigger than ES3 if you ignore strict-mode (which is mostly but not quite just static verification), just better defined.
What you've here is a lock-step protocol, so the whole network will be as slow as the slowest peer. Now, I’m not sure why this happens, but with server under BufReader, *both* sides will start taking about 0.03 seconds in read syscall at some point. It is pretty easy to tell who’s to blame by looking whose syscall starts being expensive first: First expensive client syscall: 01:31:50.135759 sendto(4, "\r\n", 2, 0, NULL, 0) = 2 &lt;0.000006&gt; 01:31:50.135779 read(3, "got ", 65536) = 4 &lt;0.038743&gt; 01:31:50.174576 read(3, "\"1\"\r\n", 65536) = 5 &lt;0.039705&gt; 01:31:50.214397 write(1, "got \"1\"\n", 8) = 8 &lt;0.000035&gt; 01:31:50.214493 sendto(4, "2", 1, 0, NULL, 0) = 1 &lt;0.000056&gt; First expensive server syscall: 01:31:50.135671 sendto(4, "\r\n", 2, 0, NULL, 0) = 2 &lt;0.000012&gt; 01:31:50.135698 read(5, "1", 65536) = 1 &lt;0.000047&gt; 01:31:50.135765 read(5, "\r\n", 65536) = 2 &lt;0.038524&gt; 01:31:50.174389 sendto(4, "got ", 4, 0, NULL, 0) = 4 &lt;0.000067&gt; So it looks like its the server who starts making things slow, but as you’ll notice, the reason why this happens is that for some reason `read` syscall becomes slow between 2 read calls. I suspect, you might have to go kernel-land to understand why a packet sent in 6µs on 01:31:50.135759 arrives to the other side a whole lot later at 01:31:50.174289 (add read duration with its start time). I wouldn’t be really surprised it the reason turned out to be scheduling, core migration, waking cpu from deep sleep states or something along the lines. EDIT: Actually the serverv2 also suffers from the same problem, only to a smaller extent. Maybe because request is so small? Not sure.
The past few weeks have led me to believe that /r/golang is not representative of the Go community (somewhat confirmed by what some Go friends of mine have said), whereas /r/rust contains a large number of prominent Rustaceans and is considered pretty eqivalent with the official forums (with many people not even knowing that the subreddit is "unofficial") in terms of types of posts, types of discourse, types of people, and general demeanor.
https://crates.io/crates/mdo uses duck typing though
Um that doesn't matter, that might be the case locally for one checkout, but as soon as a new user clones your repo, pulls down your crate or similar, cargo does a new version resolution for you, and will get the newer version. So avoiding cargo update only makes the author catch breakages later than their users. If you track Cargo.lock, it's different case.
Part of the excitement of Rust pre-1.0 came from the willingness to relentlessly iterate on design decisions to find what worked. There were a lot of frustrations that came along w/ that, and it was a huge barrier to general adoption, but there was an energy to the project unlike any other that I've followed. That specific energy has dissipated a bit, and I think the energy that comes from a large community actually building lots of cool things hasn't quite arrived yet. Don't get me wrong, there are definitely very cool projects being written in Rust. But its not yet the cambrian explosion you see over in go-land. The work being put into Rust and the ecosystem right now is the work that bridges the gap - faster compiler, better tools, foundational libraries, headliner projects (servo, redox), documentation - but it's not as exciting to the casual observer as what came before and what's going to come later. 
&gt;10x better safety than other systems programming languages. Of course that had to be here, we just discussed the cost of that. I think for future proofing systems when codebases get to be 19million odd lines long more than makes up the cost for this, and is why I think Rust is/soon will be the main player when it comes to replacing low level C code. What a great read. &gt;10x better than any other system language at generic and generative programming. D's static introspection, compile-time evaluation, and mixin-driven code generation combine to a powerful cocktail that is very difficult to mix right in other languages Cool, I want to hear more about that.
&gt; using one function opens up a pandora's box of safety problems that programmers have to manually validate Well, typically `unsafe` functions have more precise unsafety conditions than just "everything needs to be 100% perfect", e.g. for the one in the post, I suspect the programmer only needs to be sure that the integer is a valid port.
I don't think you're right here. From the article: &gt; Could we do that with this API? Well, it depends on the port address: Port::new(0x3F8) is used to read and write data on COM1, so it's harmless, but Port::new(0x20) allows us to reprogram the interrupt controller, which can corrupt the stack. So we should mark Port::new as an unsafe API Really the author means that a read or write (which are *safe*) to a port may, for example, cause a device to DMA memory. But by making new unsafe, they can uphold the promise that you cannot break things without using unsafe. I'm not sure that's useful here, you **have** to use unsafe to use this API. I'm not saying this is the case with all uses of unsafe. But the one in this article highlights the Powerball Unsafe Function (which I've come across as well). It just feels like marking one function as unsafe is no better than marking all functions as unsafe.
Rust is great, and I hope to use it in production someday. Basically a clean reimplementation of C++ without all the horribleness + some language features I miss when using C++(traits/enum). But I would not use Rust right now, currently C++ has too many of Andrei's 10x advantages: -Production quality IDE(VS), performance/memory profilers -quality refactoring tool(Visual Assist) -Incremental compilation(Rust will be far more appealing to me once it has this). -SIMD intrinsics widely supported(AVX etc) -And of course.. C++14 interfaces with all the existing C++, Rust does not:( D doesn't really interest me. Go is barf. 
I've read pieces of it and I really don't agree with what I've read. For example, &gt; No matter how completely awful Safe code is, it can't cause Undefined Behaviour. This is misleading or false. The problem is that unsafe code can cause undefined behavior elsewhere (yes, even safe code). So as soon as you use unsafe once, you have to ensure that you can't break things transitively. And that's what is at the heart of the Powerball Unsafe Function - Mark one function unsafe and the issue is now on the developer to use the entire API correctly.
I think you're taking that quote out of context, the nomicon certainly talks a lot about how unsafe code can cause UB somewhere else, even safe code. like http://doc.rust-lang.org/stable/nomicon/working-with-unsafe.html &gt; This program is now unsound, and yet we only modified safe code. This is the fundamental problem of safety: it's non-local. The soundness of our unsafe operations necessarily depends on the state established by otherwise "safe" operations. I believe the sentence you've quoted has an implied "100%" in it.
Oh, true, let me rephase (to what I was really trying to capture by "valid"): the programmer only needs to understand what the port number does, which is kinda fundamental to the domain. This level of API abstracts away things like using the right instructions/argument order/volatility markings when actually interacting with the port. (There's definitely space above the raw `Port&lt;T&gt;` for more precise APIs with more precise `unsafe`ty, that understand the semantics of each port.)
You and I are on IRC a lot of the time and one thing I've noticed here is every day we're seeing a brand new complete projects or rfc's for crates with more and more complex functionality right away. I think we're on the edge of a major boost in numbers as some of the basic tooling comes together. Developers love tools, I feel like things have increased in pace as far as productivity goes. When comparing systems level languages I'd say with extreme bias that we've got the most hype and the most potential to be future proofed. The communities questions have moved from what is lifetimes to implementation concepts in ~6months, we've got a solid tool and the support for newcomers is growing exponentially.
Cargo's behavior dictates what we do here. Cargo considers version 0.x.y + 1 to match a version constraint `"0.x.y"`, while 0.x+1.0 does not match that constraint. Authors should just keep that in mind: “Do I want my users to automatically get this upgrade, or not?”
I just haven't observed a "stark decrease in general interest." That's all i was disagreeing with.
Just sent one with seven commits, check it out!
Can you eli5 "type level integers?"
When it comes to replacing C, garbage collection seems to be the major dividing factor. Sometimes garbage collection just isn't appropriate for the low level high performance problems you want to solve. Go and D are out. Rust seems to be the only new language that has the *ability* to replace C.
I'm thinking of 'general interest' as meaning HN or proggit discussion, and that does seem to have dropped off quite a bit from 1.0 peaks. But I completely agree there's more actual adoption, more code being written, more libraries coming on line or companies starting to use it, etc. The latter is more important, and the former will go back up once that work becomes more prominent.
I built a JSON parser that used static reflection to generate a parsing function that efficiently constructed a class object and populated it with values from the JSON. All this took a few hours and I ended up with a very fast JSON parser. D's templates coupled with CTFE and static reflection are revolutionary. I came from Go with runtime reflection and found that I really didn't miss anything, and the end result was much faster. I would really like to see Rust go more this direction (I know it has some support ala the serialization library), but it has a ways to go before it rivals D's expressiveness and powerful simplicity (someone even made a ray tracer with CTFE!).
Interesting. I want to make games, so of that list, I only really care about C++ integration (don't want to build my own engine and Piston isn't there yet), incremental compilation and SIMD, in that order. I'm still playing with it in the mean time and I'm having a lot of fun. When push comes to shove though, I use whatever language that has the lowest barrier to entry, and for games that's C++.
I'd be interested to see what you come up with. Might be able to use it in [cargo-graph](https://github.com/kbknapp/cargo-graph)
I meant "changing too fast" in the context of building a software for the space shuttle.They need to use a system language that is 100% bug free in order for them to write a 100% bug free software. I don't think rust is 100% bug free.
&gt; Some crates **only updating their tiny version number**, despite the libc update being a breaking change. I caused an issue like this, it was frustrating. I'm not even sure what happened should qualify as a breaking change, here's how I described it [on a cargo issue](https://github.com/rust-lang/cargo/issues/2064): &gt; For example, my objc crate works fine with either libc 0.1 or 0.2. I described the dependency as such in my Cargo.toml and assumed that being more widely compliant would be best so that the dependency doesn't conflict with other libraries that require a specific version. However, what's happened is that cargo always chooses to satisfy that dependency with 0.2, even when the user is using libc 0.1, resulting in a conflict and compiler error. &gt; The result is that, currently, you're forced to choose a specific version for your crate and make the user use it, as well. If a dependency releases a new version, allowing use of it requires dropping support for the old version and publishing a breaking change, splitting your users and meaning the older versions stop receiving updates. This is frustrating for users, because they must ensure all their dependencies use the same version of a crate and they will have to update their dependencies more often as there are more frequent breaking changes. In the end I'm not sure that allowing multiple versions of the same dependencies is worth it... I hadn't been thinking of issues like this because I've never worked with a package manager that allows it before. Sure, it sucks to get a build error when your dependencies conflict on the versions of another library they require, but isn't that effectively what's happening to us here, anyways?
I agree. As someone who enjoys microcontrollers I often programme for systems with kilobytes of RAM and no OS. In C, I can write a programme that's completely statically allocated, meaning everything lives on the stack, which I think is really a requirement for some systems. I know Rust can do this too, but I don't think Go or D can. Also, GC pauses for state-of-the-art systems are still measured in miliseconds AFAIK. Doesn't really work if I need to fill an output buffer several times during that period...
&gt; used vim without constant errors I think you'd probably do well by just recording your intended keystrokes as macros beforehand and playing them one by one.
D 's problem is the library. The core language was developed in a way that combines the speed and determinism of RAII with the ergonomic usage of a garbage collector. It was designed to do everything that is possible with C++. Unfortunately the standard library was developed unter the asumption that there is always a garbage collector, making it a de facto gc'ed language. If D had a library similar to C++'s or rust's, it would be an adequate replacement.
In this case this is a one-version crate, if it makes a difference. Also, Rust itself may, in the future, have `#[deprecated]` or even `#![deprecated]` attributes for external crates, so it might be possible to have that semantic difference then.
For example you can encode the dimensions of a matrix in the type system. This allows to store memory inplace instead of inside an extra allocation and you can also statically detect matrix multiplications that have non matching dimensions.
There were times when passing a lambda vs the function resulted in errors for the latter, presumably because it couldn't deduce the type. So that one only works sometimes.
This code is not useful in most real-world use cases, but shows your example usage of type level integers, D language: import std.stdio, std.string, std.numeric, std.algorithm, std.traits; alias TMMul_helper(M1, M2) = Unqual!(ForeachType!(ForeachType!M1)) [M2.init[0].length][M1.length]; void matrixMul(T, T2, size_t k, size_t m, size_t n) (in ref T[m][k] A, in ref T[n][m] B, /*out*/ ref T2[n][k] result) pure nothrow /*@safe*/ @nogc if (is(T2 == Unqual!T)) { static if (hasIndirections!T) T2[m] aux; else T2[m] aux = void; foreach (immutable j; 0 .. n) { foreach (immutable i, const ref bi; B) aux[i] = bi[j]; foreach (immutable i, const ref ai; A) result[i][j] = dotProduct(ai, aux); // dotProduct is currently unsafe. } } void main() { immutable int[2][3] a = [[1, 2], [3, 4], [3, 6]]; immutable int[3][2] b = [[-3, -8, 3,], [-2, 1, 4]]; enum form = "[%([%(%d, %)],\n %)]]"; writefln("A = \n" ~ form ~ "\n", a); writefln("B = \n" ~ form ~ "\n", b); TMMul_helper!(typeof(a), typeof(b)) result = void; matrixMul(a, b, result); writefln("A * B = \n" ~ form, result); }
It's not too much hard to use D without the run-time.
Usual reminder to all to keep language discussions civil. :)
First is has to offer generics, a proper debugger (not one that rewrites text), REPL, battle proven SQL DB drivers, monitoring tools like VisualVM and Mission Control, IoT like support, ...
Have you ever used the systems from Atego? They have some white papers about their real time JVMs being used to control missile tracking systems. But real-time Java allows for memory regions and better GC control than the desktop version.
For those who don't follow the development closely, this refers to the incremental compilation RFC.
I consciously did not choose that way, because it is dismissive to those people that actually grow the language community. This is rarely done by corporations. It helps as a start, but this is it. I know at least as many cases where company affiliation is actually a hindrance to community growing. Many of the community projects this year happened without Mozilla support and Mozilla is also not set up for managing Rust in the way it manages Firefox. Grassroots movements are much more agile and quick. I want to run OpenCodeTown? I just do. Mozilla will take at least half a year of ramp-up until they decided whether they will a) push Rust, b) on that event. You don't need big names. Ruby, Python and Perl made it without. God, was Ruby in a shitty state when people picked it up. You can grow your own big names. Failure to attract people that want to do that work and are glad to do that is a defect in the language ecosystem that cannot be fixed by cash pools.
Here is the corresponding git-repo. https://github.com/atilaneves/mqtt_rs This line is mention in the post https://github.com/atilaneves/mqtt_rs/blob/master/src/broker.rs#L10
Sure: 8 It's *always* 8. If you're paranoid about a sudden upheaval of spacetime that causes the definition of "8" to suddenly change, you can always use: ::std::mem::size_of::&lt;u8&gt;()*8 But at that point, I suspect it wouldn't be called `u8` anymore, and you'd probably have to use something other than `*8`. Oh well. **Edit**: (There's also [`std::u8::BITS`](http://doc.rust-lang.org/std/u8/constant.BITS.html), but that's unstable.)
&gt; Sure, it sucks to get a build error when your dependencies conflict on the versions of another library they require, but isn't that effectively what's happening to us here, anyways? No. Multiple versions of a crate in one compiled unit is totally fine. The issue in this case was that the crate in question was specifically disallowing this by using Cargo's `links` feature, which says that only one native library can link to the final product at a time. Since multiple crates depended on different versions of `kernel32-sys`, the build was failing. AFAIK, this was fixed by simply removing the `links` feature from the `kernel32-sys` crate because it seems like there aren't actually many issues that arise in practice from linking the same native library more than once. &gt; Particularly, it makes it dangerous to use any types in your public API that are defined by another library. This is definitely true, and is therefore something you should absolutely avoid doing if possible. Traits may help with that.
I wuld be interested in hearing more details about this. Several times, we made the decision to stick with Algol-derived syntaxes over others, so that it would be more familiar...
Articles like this always make me sigh. Some people designed a language with **safe concurrency** (I don't even have words to express how freaking huge this is) and safe zero-cost abstractions. As a (former) C++ programmer I don't even understand how you can't immediately switch to Rust after hearing this. And then they get complaints because there are too many ampersands in the average Rust code, that the word `seconds` is too long to type and should be replaced by `secs`, or that `Arc&lt;Mutex&lt;Foo&gt;&gt;` is too verbose. I usually don't want to criticize articles because of this (also because there are valid points in the article), but this is just beyond my understandings. When I choose a language, the syntax is probably at the bottom of the list of things I care about, right under support for the m68k architecture. 
Another historical note: we rejected syntax for HashMap literal because there are just too many kinds of maps. What if you need a BTreeMap instead of a HashMap? Or a VecMap? Unlike vectors, it's not clear which one you'll "usually" want.
The ownership model also helps with concurrency right?
I don't even use the concurrent side of Rust too much (writing compiler plugins does not lend itself to easy parallelization), but I had a similar reaction when I first approached ATS. People judge by first impression, that's how we puny humans work. That said, I also know there's a good reason for having both `Arc` and `Mutex` as a type, and Manish has [written about it](http://manishearth.github.io/blog/2015/05/27/wrapper-types-in-rust-choosing-your-guarantees/) better than I could. OP seems to be content in D-land, and also be able to afford a GC, so I say, let them be happy using D.
Yeah, and I'm also not sure it's even common enough to warrant it any way. Just in my own code: $ find ./ -name '*.rs' | grep -v target | xargs egrep 'HashMap::new|HashMap::with_capacity' | wc -l 24 $ find ./ -name '*.rs' | grep -v target | xargs egrep 'BTreeMap::new|BTreeMap::with_capacity' | wc -l 5 $ find ./ -name '*.rs' | grep -v target | xargs egrep 'vec!|Vec::new' | wc -l 1336 Of course, most of my code are libraries, so maybe these numbers change a bit more in favor of HashMaps for applications.
How bumping version can fix this issue if it is cased by other crates depending on earlier versions of `kernel32-sys`?
I would probably not switch to Brainfuck if it had safe concurrency and safe zero-cost abstractions with its current syntax. But that's on the extreme edge. The most important aspect of the syntax is being readable and understandable (rather than writeable/typeable). So yeah, I'd say writeability should be at the bottom, but not readability. IMO Rust has a good balance of explicit/implicit syntax, making it readable enough to love the other features.
&gt; [Most transitions should be quite smooth](https://users.rust-lang.org/t/the-libc-crate-is-now-at-v0-2-0/3509) Famous last words.
Sorry, I wasn't clear. The version bump wasn't just a version bump---it also included the removal of the `links` feature. So if you run `cargo update`, two versions of `kernel32-sys` should no longer clash at build time.
&gt;But then, how and why does the rust compiler accept and encode secondClosureBox without issue? `Box::new(|| ())` creates a value of type `Box&lt;anonymous_type&gt;` which is convertible to `Box&lt;Fn()&gt;` because the anonymous type implements `Fn()`.
So here's why I chose to make `read` and `write` safe. :-) First, if I use `unsafe` too aggressively in kernel space, it rapidly results in a situation where tons of critical APIs are marked `unsafe` "just in case", and more or less the entire kernel winds up being `unsafe`. This doesn't actually improve safety any, because it just disables safety checking everywhere. It's better to read the nomicon carefully and try only use `unsafe` only when (a) it's mandatory or (b) it might not be _technically_ necessary, but having `unsafe` makes it substantially easier to reason about undefined behavior (because of "Powerball Unsafe" effects as described above). Second, it's usually pretty easy to reason about the safety of a given I/O port. As far as I can tell, ports generally come in three flavors: 1. **Ports which are trivially safe (in Rust terms).** These include serial data ports, keyboard ports, and any other system peripheral that can't do DMA or mess with memory. 2. **Ports which are safe as long as your don't go out of your way to turn on DMA.** This actually includes quite a few system peripherals. Sure, you could use these in ways that Rust considers `unsafe`, but you can usually only do so deliberately and knowingly, at which point adding new `unsafe` declarations is not burdensome. 3. **Ports which are obviously and horribly unsafe, such as the PIC (Programmable Interrupt Controller).** In this case, you can assume that the first use of `unsafe` hopelessly contaminates the entire module, as described in the nomicon. But this is _accurate_, in a technical sense: once you start remapping I/O interrupts, all Rust can do is say, "Hey, good luck." And thus, that's why I only marked `new` as unsafe: Whoever creates an I/O port already has an obligation to think through the safety considerations, and to decide whether or not that particular port introduces new `unsafe` APIs that will require additional `unsafe` declarations. This is usually a pretty straightforward decision, as described above. The interesting case is actually (2), because it has analogs in user space. For example, Rust considers it safe to write to a file. But what if I open up the currently running executable, and write data to a part of the file that hasn't been paged into memory yet? Boom. Unsafe behavior without using `unsafe`. Similarly, I could use safe APIs to launch an external GDB process and point it back at the currently running Rust program. I think of many hardware APIs in category (2) the same way: They're potentially unsafe, but only if you deliberately do something fairly obvious. Reflexively tagging all of these APIs as `unsafe` is like crying wolf: It just means that `unsafe` loses all warning value. Now, it would also be perfectly reasonable to declare a second `UnsafePort` type with unsafe `read` and `write` functions, and use that for things in category (3). In fact, I should probably consider doing that; it would help distinguish between keyboard ports and PIC ports.
Yes.
Ah I see! I had read through the rust documentation but not rust by example, which seems to exactly explain this: http://rustbyexample.com/fn/closures/anonymity.html Thanks a lot :-)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/golang] [Which language has the brightest future in replacement of C between D, Go and Rust? And Why?](https://np.reddit.com/r/golang/comments/3s9l6n/which_language_has_the_brightest_future_in/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I don't get it. Why not name the macros `btreemap!`, `hashmap!` and `vecmap!`? edit: Okay stupid me: You're talking about a literal ;)
Oh no, I wasn't suggesting actually following the ES3 spec; it's horrible. Just the parts in the ES5 one that are basically what ES3 covers, if that makes any sense…
Yeah, it does, but all languages have product types (e.g. structs in C), so having sum types is the notable thing people are generally talking about when mentioning ADTs.
Don't worry. I grew up on Algol (Algol-68, Simula) and Pascal, and rust is pretty Algol-like in its syntax.
On a Danish keyboard you have to press " ' space a " to write a lifetime. That was slightly annoying in earlier versions of rust, but life time elision solved this problem. 
Oh well, I'm stupid. :) Yeah, a `Vec&lt;u8&gt;` with `u32::MAX` capacity is in fact 4 gigs of memory, totally slipped my mind.
C11 has guaranteed two's complement behaviour in some (optional) places, so you'll have to find something else. :P (http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf "7.17.7.5 The atomic_fetch and modify generic functions", "7.20.1.1 Exact-width integer types")
The `char` type is a Unicode character (Unicode scalar value). It takes 32 bits of memory, but its range is limited to U+0000 to U+D7FF and U+E000 to U+10FFFF. The `u8` type, typically used for I/O, is 8 bits as the name suggests.
But how will Crates.io know which crates are deprecated, by processing their "main" file? What if this file is generated by a build script that do arbitrary computation? I think that even with a `#![deprecated]` tag to inform rustc that this crate is deprecated, we should have a deprecated tag on `Cargo.toml` to inform Cargo (and more importantly, the Crates.io database) that it's deprecated. Not a full yank, but some kind of warning (or even an error that you can bypass with something like `--force-deprecated`), that tells the user another crate to use or some other kind of message.
&gt; 'fn' is an abbreviation for "typing speed". This is actually more of a historical holdout. Ancient, and I mean ancient, Rust had a "no keywords more than 5 characters" rule. And your options are basically `fn`, `fun`, or `function`, and `function` is really long... &gt; I have limited time at the moment. No worries! Like I said, just curious.
What's the difference? 
&gt; Why? So I wouldn’t have to borrow it mutably twice. Because the compiler won’t let me. My code isn’t any safer and it was just annoying. I don't understand this. Allowing to borrow mutably twice would defeat any memory or thread safety guarantees that Rust can give.
["Algebraic data type"](https://en.wikipedia.org/wiki/Algebraic_data_type) encompasses sum types (enums) *and* product types (structs, tuples); so if you're talking about enums specifically, it isn't quite the right term.
Thanks
Syntax highlighting should make that one a non-issue.
It's possibly referring to something like: struct Foo { x: i32, y: i32 } impl Foo { fn x_mut(&amp;mut self) -&gt; &amp;mut i32 { &amp;mut self.x } fn increment_y(&amp;mut self) { self.y += 1 } } fn ok(val: &amp;mut Foo) { let a = &amp;mut val.x; val.y += 1; } fn not_ok(val: &amp;mut Foo) { let a = val.x_mut(); val.increment_y() } `ok` is fine, because the compiler can easily see that the `val.y += 1` isn't touching the memory that `a` points to, so that borrow into `val` can exist even while other parts of `val` are being mutated. On the other hand, `not_ok` isn't fine by the compiler, even though it is memory safe as written (it's equivalent to the first version): &lt;anon&gt;:18:5: 18:8 error: cannot borrow `*val` as mutable more than once at a time &lt;anon&gt;:18 val.increment_y() ^~~ &lt;anon&gt;:17:13: 17:16 note: previous borrow of `*val` occurs here; the mutable borrow prevents subsequent moves, borrows, or modification of `*val` until the borrow ends &lt;anon&gt;:17 let a = val.x_mut(); ^~~ &lt;anon&gt;:19:2: 19:2 note: previous borrow ends here &lt;anon&gt;:16 fn not_ok(val: &amp;mut Foo) { &lt;anon&gt;:17 let a = val.x_mut(); &lt;anon&gt;:18 val.increment_y() &lt;anon&gt;:19 } ^ This is because the compiler cannot tell from `increment_y`'s *signature* that it won't be touching the memory that `x_mut` returns. For function calls, the compiler only reasons with the signature of the function, since, the internal source won't be accessible in general, and, anyway, looking into the source would break the abstraction the signature is meant to provide. There have been some vague discussion in the past about ways to allow putting info into the function signatures to express this sort of disjointness, but nothing particularly concrete.
congrats! Looks pretty solid. A quick comment: in `rand_string`, you'll do a lot of re-allocating. It's not possible to know _exactly_ how long the string will be, but using `String::with_capacity` instead of `"".to_string()` with a bigger initial capacity might be useful.
&gt; As a (former) C++ programmer I don't even understand how you can't immediately switch to Rust after hearing this. From the top of my head: no type level integers, no abstract return types, no HKTs, no C++ interoperability (only via C), powerful but at the same time poor type-safe meta-programming / reflection (requires plugins), verbosity/repetition (no `impl`/`struct` inheritance), no thin-pointer based run-time polymorphism, no specialization, poor compile-time function execution, poor allocator history, no support for abstracting over allocators in the std lib. All of these issues are known. Some are high priority. Some have been worked on in the past. Most of them will be probably solved in one way or another during the next couple of years. Besides having all these issues, Rust is still a GREAT programming language. These issues are however real, and actual reasons for a C++ programmer/project to not switch to Rust right now. Besides this "issues" that Rust has w.r.t. C++, what in my opinion are the big advantages of Rust over C++ (affine types, safe memory/safe concurrency, clean generics, modules, hygienic macros,...) can be nowadays "emulated" to a great degree of success in modern C++ "fairly easily". C++ is obviously way worse at these than Rust, but to a lot of people that is still good enough, such that the value they would get from switching to Rust is further reduced when compared to switching to e.g. modern C++. 
To add the details, this is the result of the magic of the trait `CoerceUnzised`: impl&lt;T, U&gt; CoerceUnsized&lt;Box&lt;U&gt;&gt; for Box&lt;T&gt; where U: ?Sized, T: Unsize&lt;U&gt; + ?Sized Mainly, if `T` can be "unsized" to `U`, then `Box&lt;T&gt;` can coerce to `Box&lt;U&gt;`. And if `U` is a trait implemented by `T`, `T` can be "unzised" to `U`. (I don't know if there are other cases of "unsizing", actually)
The closures chapter https://doc.rust-lang.org/book/closures.html mentions this too: &gt; Because each closure generates its own environment struct and implementation of Fn and friends, these types are anonymous. They exist just solely for this closure. So Rust shows them as closure &lt;anon&gt;, rather than some autogenerated name.
OP here. 2 reasons why I wouldn't immediately switch to Rust: 1. Because D exists 2. It depends on what your particular definition of safe is. Rust brings a lot to the table in this regard, but I still managed to write a deadlock on day 2 or 3. I've written plenty of data races in C++, but never a deadlock. So there's that.
The 1:1 relationship you mention wasn't clear from the docs. In any case, the fact that I had to do a google search and jump through hoops (even though apparently more hoops than necessary) was not appreciated. I got into a habit of calling clone when the compiler complained.
I understand why the compiler won't let me borrow mutably twice. So far however, it's prevented my code from compiling umpteen times and caught 0 bugs.
Personally I find that there are usually better ways than a HashMap in Rust. Coming from a Python background my dictionary/HashMap usage has gone from "at least once per project" in Python to "literally haven't used one yet" in Rust.
&gt; It depends on what your particular definition of safe is. Yeah, we have a very particular one: http://doc.rust-lang.org/reference.html#behavior-considered-undefined And stuff that's specifically safe: http://doc.rust-lang.org/reference.html#behavior-not-considered-unsafe It's important to know exactly what you're talking about, for sure.
&gt; my dictionary/HashMap usage has gone from "at least once per project" in Python to "literally haven't used one yet" in Rust. Same, coming from Ruby, it's even worse, since for the last 20 years we've been using them to paper over a lack of varargs/default args.
Perhaps try to use github or a similar service, so we can see and track you progress!
To accomplish what you are describing, you can put a `tests` folder in your project's root directory and fill it with any number of `.rs` files. This is mainly used to test APIs. Accessing private methods in the `tests`directory is wrong. Instead, you can make a tests submodule in your `src`. Because of how modules work in Rust, you can rip the submodule out into a separate file. It clutters up the source, but individual files are smaller. For more information, see [the testing chapter in the book](https://doc.rust-lang.org/book/testing.html).
Unless you use [GenericArray](https://github.com/fizyk20/generic-array)`&lt;T, N&gt;`, which admittedly is not as nice to write as `[T; n]`.
&gt; When I choose a language, the syntax is probably at the bottom of the list of things I care about In the real world syntax matters, it's the human interface of the machine. Working to make syntax clear, short and nice looking is important. If you reduce your care for syntax you end like in the numerous object design mistakes Donald Norman keeps writing about: http://www.jnd.org/books/design-of-everyday-things-revised.html
The only way Go has any chance to replace Java is if Oracle pulls some stupid greedy move that chases off Java devs. Right now Java is a more powerful language (more features), as fast or faster than Go, has better tooling, and has 10x the already trained devs who will be annoyed by a lack of generics.
&gt; I would probably not switch to Brainfuck if it had safe concurrency and safe zero-cost abstractions with its current syntax. To be fair, Brainfuck's problem isn't the syntax, the language is just too minimalistic. You only have 8 simple commands, so it's cumbersome to write anything meaningful with it. I quite like Rust's syntax though.
In my [unit testing library](https://github.com/atilaneves/unit-threaded). 
That's one of the few things you can trust Oracle on though, they did that already about OpenOffice/LibreOffice.
I didn't mean to imply that. I'm saying that's been my personal experience, which isn't much in the way of real statistics. My point is that Rust makes inroads with respect to writing correct code, but as usual is no panacaea, as evidenced by my deadlock. 
I certainly don't put it outside the realm of possibility that Oracle destroys Java :). I was a Java fanboy until that deal went down and then I decided it probably wasn't worthwhile to swear my loyalty to a language because who knows what's going to happen to it.
We all know how this turned out. OpenOffice is now an Apache project and LibreOffice 5.0 is just great. If that's the future to befall Java, as a Java developer I welcome any greedy move by Oracle. Cannot wait to get my hands on LibreJava 10.0 :-D
minitest in Ruby has done this for the last few years, or at least, randomized the order, which tends to uncover the same kinds of issues.
Turns out there's a lot more to date-time arithmetic than I thought! At least I've got this far: $ cargo run --example current_time The current Unix timestamp is 1447168605. This corresponds to 10 Nov 2015, 15:16:45 in UTC. However, your current timezone is America/Chicago. This currently has an offset of -21600 (called CST). So the actual time is 10 Nov 2015, 9:16:45.
Ah that's awesome! Thanks for the details :) According to the trait documentation, a few other types implement it: https://doc.rust-lang.org/core/ops/trait.CoerceUnsized.html
Actually, the very most of Go happens outside of the community, e.g. the big uptake in China it experiences.
What programs did you use to make these?
I've published the follow-up. Here you go: https://www.reddit.com/r/rust/comments/3s5w9f/rust_in_detail_part_2/ Hope you'll like it. :)
Also Python, really. One of Go's main selling points, the simplicity and ease of use (low start up time, etc) is shared with Python and Go arguably does that better. Python has a lot of _other_ features which keep it going (which Go doesn't have), so Go probably won't replace Python, but it may get some of the mindshare. In fact, when I look at Go, I think less "Java" and more "Python"/"Ruby"
I think another part of this is that the Rust community managed to attract respected people from other, non-C++ fields. Steve from Ruby, Armin/Georg from Python (pocoo), and lots of other known community members. This leads to Rust being mentioned at their conferences, or even being the subject of whole talks. And, of course, blog posts and tweets. Creates a wider community, and a wider net gets cast. I don't think the effect of having these people around has been appreciated enough :) Go has _some_ of this, but not as much. D and Nim don't seem to have this at all (could be just me not knowing about it, though).
When reading about Tensorflow and automatic differentiation, I wondered if one could design an flow graph editor using [Conrod](https://github.com/pistondevelopers/conrod). I have also experimented with [dual numbers](https://en.wikipedia.org/wiki/Dual_number). If you make the code generic over floats, you can implement the trait for dual numbers and get automatic differentiation for free. Love the name!
&gt; If a crate can't use any types defined by another library Well, I didn't say you can't *use* the types. I said exposing a third party type in your public API may not be a good idea. A better idea might be to wrap it. I'm not saying it's a panacea. Dependency resolution is hard. And certainly, at least part of it is making Cargo smarter at choosing dependencies.
No worries! We do have remote streaming capabilities. Or /u/fgilcher might also be interested in hosting you at the Berlin meetup. 
Thanks for the tip! Dual numbers do indeed look interesting, but if I get it right from the quick look I took, this would effectifely double the computations that have to made?
I for one am excited to get an mqtt implementation for rust.
looks like there's a few up on github already.
&gt; Don't use "*" dependencies See, I know everyone says that, but on the other hand, in a binary crate you should be shipping with `Cargo.lock` anyway to guarantee repeatable builds, right? In which case specifying versions for crates in `Cargo.toml` seems a bit superfluous. When I decide to update my deps' versions I can just `cargo update` and deal with breakage.
Regarding `RefCell`, I can't tell whether the author has issues with needing it in the first place, or the syntax. It's needed for memory safety with no GC. I agree the syntax could be made better, and I've made some strawman proposals to that effect (although they hasn't gotten a lot of traction, since most people just prefer avoiding `RefCell` entirely through design, which I can totally sympathize with). The borrow checker is a similar story. Yes, it has false positives. But I don't think you can really do the same thing *without* false positives. From what I've seen, the ISO Core C++ initiative is going to result in lots of false positives as well, with its "points-to" set tracking. So essentially what you're objecting to is compiler-enforced memory safety with no GC, at least as well as we know how to do it.
Sure. What you lose in the mix is the ability to update _without_ breakage if there's a point release as well. We're still young enough that there's not a lot of projects maintaining 1.2.x and 1.3.x versions, but we'll get there.
Ah! I see. It's not that the widening itself it's a problem, it's that it *hides* the problem.
It at least opens the door to it, yes. 
So you meant stuff *under* the microkernel? Well of course it can't protect from that. But that's like saying "oh well, I can't build a nuclear blast resistant house, so why bother with building walls?"
Most of the criticisms seem to be of someone programming in a C++/D style in Rust. Half of my Go criticisms were similar when I tried it. The "borrow checker is too aggressive" points echo the points made by a couple of C++-background acquaintances of mine who were learning Rust, but later learned how to write code "the Rust way" and didn't feel this way anymore. However, none of them are major minus points except for compile time reflection; which is a good thing. Couple of points: &gt; Explicit borrows. I really dislike the fact that I have to tell the compiler that I’m the function I’m calling is borrowing a parameter when the function signature itself only takes borrows. &gt; why do I have to explicitly call .clone on Rc? Rust likes to be explicit about these things. YMMV. &gt; No function overloading. &gt; No Add impl for Vecs, so it’s massive pain. Feature, not bug :) YMMV. &gt; Serialization. There’s no way to do it well without reflection, and Rust is lacking here. [serde](https://github.com/serde-rs/serde) &gt; If you want to create a HashMap with a literal… you can’t. https://github.com/kmcallister/literator https://github.com/DanielKeep/rust-grabbag/blob/master/grabbag_macros/src/lib.rs#L55 Rust tries to keep the stdlib lean. YMMV.
http://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/ Avoiding shared mutability tends to focus on preventing bugs introduced by _future_ changes.
I will say, PyPy is looking really neat. I think it in conjunction with a general shift towards Python 3 (finally!) will keep python in the running for quite some time to come. Additionally we have Julia, which maintains interoperability with both Python and C/C++ world. Of course that means D/Rust come along for the ride too. I don't see Go taking away all of Python's domain. More than anything I see it moving on Ruby and backend web Java domains. Of course Java is leaking to Scala as well. Application Java is already losing to open C# via mono. So I think Go has a lot of opportunity to pick up some of the market that Java loses.
I haven't heard of the RTSJ being used for any actual applications before. Are they able to get sub-millisecond upper bounds on execution time, or do their systems have longer (or less strict) deadlines? How do they handle errors if an allocation fails?
When installing Visual Studio, there is an option to install the C++ tools that needs to be checked. http://i.imgur.com/aW5Ai3d.png
It sounds to me that would require a implementation of all BLAS routines to get somewhat good performance (the 2x slowdown from double computations sound acceptable for those scenarios). We currently focus more on the machine learning side of things than Tensorflow, where you can usually pre-calculate the differentiation, so auto-differentiation isn't really a priority.
Whoa! That's very cool. Well, I think there's a name clash here. I believe that since your project is older and more complete, you deserve to grab the [rjs package name](https://crates.io/search?q=rjs) for yourself, but in either case, one of the two should adopt another name. That's something /u/ctangent should think too, since it affects whether one of the projects can be found through Google, and more. (I was thinking to write a Javascript interpreter myself, loosely inspired by the duktape VM, and I thought about using the `rjs` name too. I guess that if I release something, it will need to have another name!)
`0u8.count_zeros()`
I'm inhaling it right now :) btw: thanks for notifying! 
Actually, the use of session-types might alleviate part of the issue; but in any case in a space shuttle you probably want to prove *everything*. That being said, isn't SPARK about adding extra proof annotations? Wouldn't that be possible in Rust? (although probably quite costly!!)
In case anyone wonders about the gap, U+D800 to U+DFFF, this range is for UTF-16 surrogate pairs. They aren't legal code points on their own.
I liked his article from 2014 better https://atilanevesoncode.wordpress.com/2014/01/08/adding-java-and-c-to-the-mqtt-benchmarks-or-how-i-learned-to-stop-worrying-and-love-the-garbage-collector/
I can't play because it drops so much frames so like anytime I run around im constantly dropping frames so its like a lag, but in the corner it says I have 60 FPS
&gt; I got into a habit of calling clone when the compiler complained. It's a common reflex for newcomers, don't worry. As usual with compilers it takes some time to figure out what a particular error message *really means*. Also, borrowing error messages are quite notorious for not pin-pointing the real issue (because the compiler does not read your mind), making it even more difficult when you have not yet integrated the ownership checks. The good news? If you stick at it, it becomes much easier!
I'm completely happy to change the name of mine! I couldn't think of anything so I picked `rjs` out of simplicity. I won't be publishing on crates.io anytime soon, so /u/Pvginkel can take it if they want it.
(semi-answering /u/erickt, too) Sure! We can also provide video taping if needed. Are you aware of the biweekly Rust Hack and Learn meeting tomorrow, btw?
You could use one of the existing math libraries (cgmath, nalgebra, vecmath)
Also, in embedded programming, you have all the static analysis tools already exist to, notably, check the maximum depth of the stack... all this tooling has to be adapted/re-built for a new language, which is a clear cost.
I am now ;) Already have other plans for tomorrow, but I will try to make it next time!
This is cool! Sorry for the name conflict, I'm happy to change mine to something else. I cloned and built it but it doesn't look like it's building for me on non-windows right now (https://github.com/rust-js/rjs/blob/master/src/gc/os.rs#L10) but you're much farther along than me :) I'm hoping to make mine hostable from Rust so maybe our projects are still a little orthogonal? At any rate, sorry for the conflict, haha.
[Walter Bright](https://en.wikipedia.org/wiki/Walter_Bright). D's creator, he was also the first to write a C++ compiler which did NOT transpile to C, and thus at the time was the fastest C++ compiler (it's now Digital Mars C++ compiler). He's a compiler guru, and so designed D to be fast to compile as a guy with intimidate knowledge of how compilers work internally.
Yes, it's sad it wasn't included in the question :(
I guess you need those kind of deadlines if you are tracking something like missiles and navy battle systems. http://www.nfvessentials.com/news/2010/03/30/4700207.htm http://defenseelectronicsmag.com/news/aonix-supports-french-radar-systems 
That's a good point, didn't really consider the possibility of two simultaneous versions.
Thank you missed that option 
The only benchmark that is heavy in allocation is binary-tree. The others aren't memory-bound at all.
TBH if you're just exposing the same abstraction as Caffe, have you considered just exposing Caffe's C++ interface over FFI (as in https://github.com/ajtulloch/caffe.rs)? Additionally, I think the Purine/Caffe2/TensorFlow approach of constructing and running a computational graph of blobs and operations has some pretty clear benefits, so if you're starting from scratch I'd suggest this approach. 
&gt; Lars changed how the Android build works been looking for the new steps on how to build for android, but can't find it :(. 
We should learn ATS together, then implement prvals as a Rust plugin... ;-)
I plan to update that soon once I optimise the Rust version
Well my explanation is simplistic, but remember that in comparison with C++ at least as far as I know D does not require multiple passes and deep reasoning about the code. Now CTFE (compile time function execution) will naturally slow your code, but as far as I know in D (my experience is a year or so old as I have been playing with other languages) the standard D library phobos takes very very little time to compile from scratch. But I think the best way is to check yourself and maybe try a comparison compile with various pieces of code. I think rust may always be slightly slower here because of the borrow checker adding time (and compile time not being a major target for the language development).
Oh, thanks :)
I take issue with `Arc&lt;Mutex&lt;T&gt;&gt;` "'nuff said". I love that. This makes it very clear which layers are there and each of those is concerning a different thing. Also, it allows better composability. I used precisely such a construct in a beginners course and people grokked quite quickly where the problems lay. The trick to make this less "horrible" is that `Mutex&lt;T&gt;` usually warrants its own type anyways. So in my example, I had something like: ``` struct SyncedThing { data: Mutex&lt;Vec&lt;u8&gt;&gt; } ``` This later gets used as "SyncedThing" or as "Arc&lt;SyncedThing&gt;" in all threaded contexts. This contains both concerns quite nicely and is convenient.
So, no auto-deref? Isn't it inside an `unsafe` block anyway? Also: why doesn't Servo have safe wrappers for those? (I suppose that you can wrap this on a safe API)
That's just stock Firefox. My usual configuration looks like [this](http://i.imgur.com/uCwaOeB.png). If you mean the GTK+ theme, it's Numix Frost.
So it's more like that nobody took time to write a safe wrapper? Would PRs to reduce the number of unsafe blocks be accepted?
The JVM is faster than Go and it's garbage collectors are years ahead of Go's GC. Those are the facts.
You need to have link.exe in your path... You can do that by running vcvarsall.bat before you try to run the compiler... My recommendation is that you find a way to make your cmd shell run it when you open the shell... Keep in mind, that if you have a 64-bit system you need to either run a different version of the batch file, or pass some parameters into the batch file, I can't remember which... I'm afraid you're going to have to look it up. Sorry I can't be of much help, but that's what I had to do. If it's too much trouble for you, just go back to the other Windows version of rustc... that's what I've done on my other machine...
What do you mean "Rust to compile to them?" All you need is an LLVM backend...
And Go doesn't do much optimisation either - statically *or* dynamically - Java has the advantage of at least being able to do that at runtime.
&gt; Rust can do everything D can do at compile time in a plugin You don't have access to types though, which makes things less ergonomic - no need to constantly pass around the types. And D's metaprogramming feels like working in the same language - syntax extensions fell like working in a poorer sub-language. I love D's metaprogramming, and feel like lots of Rust folks could learn something from its ergonomics. It's not something that would get me to switch back though, but it is certainly something that Rust lags behind on.
If you look at https://doc.rust-lang.org/book/trait-objects.html#representation you can see that a trait object (as you have inside your `RefCell&lt;Component&gt;` simply contains a pointer to the object and a pointer to a collection of functions (vtable). In other words, the memory layout of a trait object and of `T: Trait` is completely different so dereferencing the created object is going to trample memory. As a bit of an aside, `mem::transmute` requires that the two types that are transmuting are the same size, which would have caught the error if you'd tried to do `mem::transmute&lt;T&gt;(t)` with `t: &amp;Trait` (technically it would work if`T` wasn't exactly 16 bytes big... but in other cases, the compiler would stop you). In your case, you transmuted between two references, which are always 8 bytes, so you passed the minimal "are they the same size" test and `mem::transmute` and the compiler assumed you knew what you were doing was safe. By digging around in a trait object - specifically, by pulling out the pointer and (`unsafe`-ly) dereferencing it - you can in theory get back to the original object, but you have to be absolutely sure that you've got the right type or the object you create may reference uninitialized/unallocated/aliased memory.
Thanks for the enthusiasm :). Regrettably I don't have time at the moment to work on this, but if you'd like to work on this project, please feel free to send pull requests or I can add you as a contributor. I can tell you that by far the hardest part was to get JavaScript right. Getting the whole ECMA test262 suite to run was hell. I actually had to make quite a few commits to the test suite itself because I found bugs in it. See [https://github.com/tc39/test262/commits?author=pvginkel](https://github.com/tc39/test262/commits?author=pvginkel) for the changes I made to the test suite. Since there now is a fully functional base implementation, the fun starts (i.e. improving the GC; adding a JIT; etc). Maybe it's interesting for you to use this project as a starting point to either get your implementation up and running faster (e.g. using stdlib from this project), or just see if you think you can improve it from its current state.
I didn't. I just did and then hit run, it hangs.
&gt; Would PRs to reduce the number of unsafe blocks be accepted? s/accepted/celebrated !
And an LLVM backend can be more complex than implementing a naive C compiler.
The layout of `&amp;Rc&lt;RefCell&lt;Component&gt;&gt;` is: &amp; Rc RcBox &amp; -----&gt; / data ----------&gt; strong_count /\ vtable weak_count / borrow_count \_ RefCell *mut RcBox&lt;Component&gt; T / Layout of `&amp;Rc&lt;RefCell&lt;T&gt;&gt;` is exactly the same, but without vtable pointer (because `*mut RcBox&lt;T&gt;` is not fat). That's why in your case it works, but please, don't do that. By the way, coertion from `Rc&lt;RefCell&lt;T: Component&gt;&gt;` to `Rc&lt;RefCell&lt;Component&gt;` is safe and it's even happening somewhere in your code! Now, regarding `Rc`s and `RefCell`s. It seems that you don't want to have interior mutability -- just get rid of of both of them! But beware, you could only borrow one component at a time, which is bad. Some ECS work around this problems by providing iterator interface and providing methods to get more than one component per entity. Also notice that you don't really use the fact that hashmap stores `Components` anywhere. So why not store just `*mut ()`? Adding would be just `Box::new(x).into_raw() as *mut ()`, and accessing `ptr as &amp;mut T`. And you will also need to implement drop, so you doesn't leak these boxes. But! There are a crates which does exactly what you want, with a safe interface! Just look for *anymap* and *typemap* on crates.io. And if you want to keep the `Rc&lt;RefCell&lt;X&gt;&gt;`, just insert elements of that types into the typemap.
Cool post! I look forward to part 2. &gt; We’ll see, I guess. Optimising the Rust implementation to be competitive with the D and Java ones is likely to be interesting. Yeah, to me this will be the most interesting. Shouldn't rust be *faster* (or at least consistently lower latency) than Java and D? My understanding was some of the pain OP felt was because rust tries to protect you while still giving you the ability to code lower level without a garbage collector. If the rust program can't be made to perform better than Java and D (since the post makes it sound like their D implementation uses GC)... then what's the point? Seems like you should just use those, no?
&gt; Some people designed a language with safe concurrency (I don't even have words to express how freaking huge this is) and safe zero-cost abstractions. Zero cost for the programmer or zero cost for the computer? 
http://imgur.com/a/Wz9sv
Thanks for the links. They don't provide much technical details -- I wonder if they only use Java for the interface, or if they actually do something with tight timing constraints in Java. Also, I wonder if any of the safety-critical code is in Java. It seems like a JVM is too large and complex to use in a safety-critical context.
Whenever I read a criticism of Go, I feel like some time should be spent mentioning Go's tooling. I wouldn't be surprised if tools of this caliber exist for other languages, but Go's come basically built-in. PPROF has saved me tons of time, for example. 
However, you can cross-compile, so it's not really an issue, right?
Not only can the JVM optimize at runtime, it can *deoptimize* and then profile and *reoptimize* at runtime. No AoT compiler will match this.
Looks like a great Rust project.
They are using the PTC (former Atego) Utra. http://de.ptc.com/developer-tools/perc Real time JVM aren't what you download from Oracle, they require a few KB, offer AOT compilation and fine tuned GC with controls how it should behave, setting latency deadlines and so on.
Sweet, thanks for linking me to that. I found the following quote on the page you linked to: &gt; Impressive deterministic real-time behavior with typical response latency of &lt;1ms on x86 1.6GHz+ I don't think that 1ms is a particularly tight timing constraint, and "typical response latency" doesn't sound useful for hard realtime systems. I presume they aren't using this for their tight deadlines, only for higher-level control. In that case, I'm not really surprised. Keep Java away from the safety-critical code and code with tight deadlines, and the GC and error handling issues become less significant.
For visibility into ASTs you may want to use rustc's `-Z ast-json` command line option, which outputs the AST as JSON. The internal classes (which are used by compiler plugins like clippy) aren't in the official docs, but /u/Manishearth maintains an extended version with all internal APIs. You can also build it yourself (using `configure --enable-compiler-docs &amp;&amp; make docs` in a cloned rust repo), if you have enough time.
Even when I try to run cargo run after cargo build in Rust shell, it just hangs
The syntactical heritage from ML didn't put me off at all, I knew OCaML before looking at ATS (or Rust for that matter). But things like `t@ype` just look weird. I agree about Haskell syntax in general; but Haskell *style* is a mixed bag in my book.
At the moment you have roughly two options: * Compiler plugins that define procedural macros that can be used in Rust code: http://doc.rust-lang.org/book/compiler-plugins.html * "Build scripts" that generate Rust files http://doc.crates.io/build-script.html The former can only be used on Rust Nightly since it uses compiler internals that we’re not ready to stabilize. These internals change occasionally and break existing plugins, which need to be updated. You’ll probably want to update regularly (if you want to maintain this project long term), but track which exact compiler version you’re targeting so that breaking compiler changes don’t block you. If you use Travis-CI, https://nightli.es/ can trigger a new build every ~24h to be notified if the new compiler nightly broke your code. The latter typically don’t manipulate ASTs but write Rust files by concatenating strings. See https://github.com/sfackler/rust-phf/blob/1ce4e9f34f/phf_codegen/src/lib.rs#L241-L277 for example. This is ungly and less convenient, but it works on "stable" Rust, meaning that it’ll keep working on future compiler versions. You can also use compiler internals in a build script or other stand-alone program (without a compiler plugin), but they you’re back in unstable Rust again. See https://github.com/servo/html5ever/blob/master/build.rs and https://github.com/servo/html5ever/tree/master/macros/src for example.
I’d say `Duration` is more idiomatic, and I’d prefer it over bare integers unless memory was very constrained. (And even then, the API could still use `Duration` and the boundary and convert to integers for internal storage.) `Duration` has nice constructors like `from_secs` and `from_millis` to avoid silly mistakes of using the wrong unit. You’d think such mistakes are so silly that they don’t happen, but Servo once scrolled a thousand times too slowly because I divided micro-seconds by 1_000_000_000 instead of 1_000_000 (or something like that, I don’t remember exactly.) Bare numbers with an implicit unit are a common source of bugs. In Servo we have lengths with typed units: https://github.com/servo/euclid/blob/d577618d51/src/length.rs#L21-L36 to deal with the many kinds of "pixels" in presence of CSS transforms, pinch zoom, and high-density displays.
I don't have real life experience with such systems, but as someone that tasted systems programming with Oberon and delved into the worlds of Mesa/Cedar and Modula-3/Spin, I became convinced that such GC use is possible. So I get to learn about those systems on my researches as language/systems programming geek. Just like no one believed in JavaScript before V8 or PHP before HHVM, there just needs to exist a brave company that decides to push the state of art.
There's no stable way to cast a trait to an object? I must be doing something really wrong then, if the language has no support for it.
Right. But "You should Rust 'cos it's thread-safe" sounds to me like all my problems would go away. They don't, and D is thread-safe too by default.
The Windows port works, but there are some dependency issues (libcpocalypse, and other things IIRC) stopping it from getting landed.
Yes, that's exactly why you need some kind of pointer indirection, etc. `Box` or `Rc`. I think your intuition about `RefCell` is right. But play around and find out! Anyway, I think that solution with pure `*mut ()` is not a good idea, as it would be really hard to implement drop. I think that the idiomatic way to do downcasting (if you really, really need it) in Rust is to use [`Any`](https://doc.rust-lang.org/nightly/std/any/trait.Any.html), or one of the crates I mentioned before.
I personally have considered generating Rust libraries to be used from higher-level code. Of course, OP gave a different reason for generating Rust code, but I'm also interested in the responses.
 handles.push(select.handle(receivers.last().unwrap())); When you create a handle to a receiver, you're borrowing that receiver for the lifetime of the handle, which means that this line borrows `receivers` for the lifetime of `handles`. You won't be able to mutate it later when you `push()` another receiver to it. Since you're already using `unsafe` APIs, I'm going to assume you know the dangers so I don't want the community criticizing me for recommending this: I believe you can get around this by converting the reference to the receiver to a raw pointer and then back. This erases the original lifetime of the reference and the fact that it is borrowed from `receivers`: unsafe { &amp; *(receivers.last().unwrap() as *const _) } Obviously you'll need to be careful of where you use this later, such that you don't commit a use-after-free. Since `receivers` and `handles` are in the same scope and never moved or dropped early (if you comment out that unnecessary `let mut receivers = receivers;` line), this *should* be safe. You'll need to do this with `handle` inside that `while` loop as well: let handle = match handles.iter_mut().find(|h| { h.id() == id } ) { Some(h) =&gt; unsafe { &amp;mut *(h as *mut _) }, None =&gt; panic!("error: handle for id {} not found", id), }; By the way, you can get a stable memory location for `Handle` if you put each in a `Box` before adding it to the `Vec`, as that puts the actual struct in its own unique heap allocation. That way, you don't have to worry about the `Vec` resizing (as you don't really ensure that in this version anyways). You'll need to do this with each `Receiver` in `receivers` as well so that you also have stable addressing when the latter resizes (one of the borrow errors was preventing this invalidation and saving you from a segfault). It's not efficient by any means, but the overhead will be dwarfed by that of the blocking operations themselves. Here's a gist that compiles and doesn't segfault: https://gist.github.com/ca263b09d1b4f406f68e The reference-reforging trick I showed above is a little more complicated because of the `Box`es; basically, you need to deref `&amp;(mut) Box&lt;T&gt;` to `&amp;(mut) T` before attempting to cast to `*const(/mut) T`. That's why those extra asterisks and ampersands are needed. 
I don't think Rust has actually taken any syntax from ML other than `'a` (which I also dislike)? &gt; "Things look familiar to people used to C-ish things" is not really an argument. Sure it is. The vast majority of existing programmers, and an even vaster majority of Rust's target audience, are familiar with C-style syntax. I agree that Haskell syntax is nicer in many ways, all else being equal, but it's not. I first encountered Haskell in a university course on functional programming (back then, I was mainly familiar with C++), and it took me several weeks before I more-or-less understood how Haskell's syntax even worked. And more like months or even years before I really understood the precedence of operators versus function application. I can imagine that someone learning on their own would need a lot of motivation to push through that period of incomprehension. The barrier to entry this kind of thing poses is *not* trivial. &gt; As a rule of thumb, if you want a syntax overhaul, I'd say use anything that uses the same syntax for type and value-level parameters: Same syntax for the bloody same concept. Once that's nailed down the rest pretty much follows. Yeah that's my plan for this language I'm currently brainstorming :)
Like /u/krdln mentioned, if you make your `Component` trait inherit from [`Any`](http://doc.rust-lang.org/nightly/std/any/trait.Any.html) then you get the *stable* and *safe* `.downcast_ref()` and `.downcast_mut()` methods for **free**. Basically every nameable (non-closure) type that is `'static` implements `Any`, so you don't really have to do anything special. pub trait Component: Any {} And that's it, really.
I feel like some kind of crucial distinction is missing here. While template *bodies* are only type-checked at instantiation time, that doesn't negate the fact that `template&lt;typename T&gt; class List` *is* a thing that exists at the type level in C++, and generates new types when applied to types. `List&lt;T&gt;` = `List&lt;U&gt;` iff `T` = `U`. And `List` itself is a thing that can be used in a first-class way, corresponding to HKT, with `Foo&lt;List&gt;` and `Foo&lt;Vec&gt;` also being types, and different ones. Either macros are not like this, or I don't really understand macros. Maybe the distinction is that C++ templates are like types at the type level, and like macros at the term level. Or maybe it's that they're type-like for the subset which corresponds to parametric polymorphism (where in Rust you wouldn't need a `trait`; in C++ where there's no overload resolution involving type variables), and macro-like for the subset corresponding to ad-hoc polymorphism (where you'd need a `trait` in Rust, and overload resolution involving template arguments in C++).
Do we have an ordered roadmap somewhere? I dream on Non lexical borrows, seriously.
A couple months ago we switched our Timeout value from microseconds (we thought it made sense to go with the lowest resolution the frameworks we use could handle) to seconds (because the non-technical users didn't like seeing all those ,000,000 when viewing the configuration). Internally, we use a proper duration type, but externally (either in configuration files or in the database) of course it's just a raw number... and we've already had 2 bugs where we had missed something since the switch. Hopefully, by now, everything correctly interprets the raw numbers as seconds, but I am not holding my breath :/
&gt; It might be useful to make MirPasses something we can hook into via plugin_registrar (quite an easy change to make, just maintain a vec of Box&lt;MirPass&gt;). GCC lets people insert GIMPLE/ipa/etc passes. Clang lets you insert clang passes as well as LLVM passes (iirc). &gt; It would also make it easy to work on experimental passes out-of-tree and without long builds. &gt; -- /u/Manisheart It would be nice indeed! However, technically, isn't there a risk for such a pass to break the MIR invariants? I mean, sure you can argue that it's up to the pass to "Do The Right Thing"^tm but it might not be easy.
Can someone explain what MIR is and why we need it for someone who doesn't have a lot of experience with compilers?
I'm on a mission to get keyboard input working, and getting the compiler set up correctly is the next step in that direction. After that, we need to program the PIC, set up an interrupt handler, and then write a simple keyboard driver. Please don't hesitate to ask if you have any questions. And I always appreciate corrections, since I'm not really qualified to do this stuff at all. :-)
The biggest benefit I know of is less fragmentation, and no "allocated with one, free'd with the other" issues. In the case of SpiderMonkey, you probably have the latter anyway because SpiderMonkey is a layer on top with its own allocation semantics. That said, the way Rust manages memory leads me to expect that to not be an issue anyway. Dunno the details on moving. You can definitely root things because C++/Rust needs to work with GC'd objects.
The Compiler could at least check the invariants and direct the blame to the offending plugin (perhaps via a mir-check-invariants option).
Both in progress. They are discussed in https://github.com/servo/servo/issues/1908 and https://github.com/servo/servo/issues/5394
Latest browser.html + Servo status: https://groups.google.com/forum/#!topic/mozilla.dev.servo/eLxDe65dEBM
Rolling back would imply having a copy or switching the MIR to a "persistent data-structure" style I think; so I think that identifying the faulty pass and balking is the easiest solution.
The way GCC passes work is that you can insert them wherever you want in relation to other passes. And you can mess things up as well. You sort of want to be able to mess things up, really.
I haven't had a chance to finish the article but it looks great. Well written, informative, and has a lot of practical info. I do want to point out something about QEMU that I wish I had known when I was developing a toy OS recently. QEMU has some flags to change the triple fault behavior. In particular, you can make it halt or even exit on triple fault. I'm on mobile right now or I'd look up the flag. You can also use -d to get detailed exception info. Look at -d help. Another trick is to get to know the QEMU monitor. I usually run it so that I connect to the emulated machine with vnc, and then set -monitor stdio. This allows me to use the terminal to drop into single step mode. The last bit of advice on triple faults is to try Bochs. I found it to be much slower than QEMU but gives more helpful output in these situations.
Thanks, there doesn't seem to be much difference in binary_trees performance using the standard and no-jemalloc rustc versions on arm. `default 6m.44 21m30 2m.22` `no jemalloc 6m.23 21m45 1m46` edit: There's a small difference in sys time (mostly allocations + some zram swapping) After decreasing the tree depth to eliminate swapping, there's practically no difference: `default 1m28 4m48 0m25` `no jemalloc 1m25 4m56 0m20` Probably means jemalloc was using more memory originally.
Perhaps you have multiple versions of serde being included? That way it's a _different_ trait that's required, but with the same name. Also, you need to have `#![plugin(serde_macros)]` or something.
While I understand MIR and what it'll bring, but I've never seen any sort of discussion on HIR. What's the advantages of going `AST -&gt; HIR -&gt; MIR` and not just `AST -&gt; MIR`? I'm assuming the HIR more closely represents all the constructs of Rust itself which gets desugared into the MIR. Are the certain optimizations and safety checks that can be done at the HIR level, but not the MIR level?
1) The advantages of compiling to Rust rather than assembly is that the bootstrapping process is far easier because Rust is a much higher level of abstraction to work with, while still having high performance and memory layout control. 2) The compiler would have to be sufficiently complete and catch all errors, as well as provably generating correct code for every correct program source.
Absolutely not. The jury is still out on whether monads are the right abstraction. See: Algebraic Effects and Handlers, and compare those to monad transformers. I think adding another trait to the compiler's list of traits it knows about is a bad idea. Also, I think with respect to monads, there might be a potential for novel ways of compiling monadic computation because in Haskell, monads are usually encoded as value transformations, whereas in Rust we have a region tracking system that might be extendable to things other than lifetimes. In C it is common to chain computations but check error flags before continuing. In Haskell you pass optional types. What if you could write the Haskell version but it compiled to the C version?
That makes sense. So in this case the AST will be what more closely reflects the actual language constructs of rust (including things like macros and `if let`) whereas the HIR is an AST where macros and other higher level sugar are expanded out into a representation that's easier to turn into MIR, correct?
Could you show some code examples?
Here's a [function](https://github.com/coeuvre/rust-2048/blob/master/src/board.rs#L128) from literally the first project I looked at.
&gt; it would be even better if instead you could define a trait Voxel, which abstractly defines the interface of a voxel, and implement all of your traits for T: Voxel, that way they can be composed with any voxel implementation. I imagine voxels might be something where the different impls are too radically different from one another for this to make sense This is true! And you're right that different voxels are simply too radically different. What I have is a few interfaces, e.g. one specifically for the extra kinds of things required by dual contouring (an algorithm that doesn't make particular sense for minecraft-style voxels). This is actually _why_ the orphan problem comes up - there isn't one universal voxel interface that can be used for anything and everything; it's fragmented. So the dual contouring crate adds some sub-trait, and some independent crate creates a new voxel type, and now a user wants to use them both. Their only option is a newtype, I guess.
&gt; #![plugin(serde_macros)] That did it. Thank you.
Does anyone have examples of the kind of optimizations rustc could do? I'm excited either way.
Exactly
Or maybe they could submit a pull request to one of those libraries. :) Unintentionally, the orphan rule creates a certain degree of copyleft virality in this way.
&gt;Good point, the impl Trait change definitely helps mitigate some of this horribleness. (Although something I've pointed out elsewhere is that it only helps out with return values - I need to be concrete when storing things in structs, but that's not a huge issue here). It also hadn't occurred to me to use `Deref`, which solves one half of the wrapping/unwrapping churn. The impl Trait proposal solves the other end of the generic function problem. Writing a function or a data type that accepts any type that impls a trait is easy. But writing a function that returns a specific one is hard or impossible. You would just make your structs generic. &gt;In some sense, this is similar to explicitly specifying which impl you mean. In Haskell, there are a handful of newtype wrappers for different applicative instances. It can be nicer here, because you might be able to write several impls on a given newtype (in this case, the voxel newtype might easily implement several new traits), but it can also be a lot more cumbersome: there's no implicit "Underef"ing, so it still means manually wrapping up every created voxel in a newtype. It's easier for some things than for others (things that aren't created very often), but it can easily end up being much more churn than manually specifying the impl in the occasional case where impls collide! Yes, deref + methods are quite the magic trick! 
Basically, yeah, that's correct. HIR is also easier to perform name resolution and typechecking on when compared to the AST, simply because there are fewer special cases to consider. (Typechecking will continue to be done on the HIR, not the MIR, for the foreseeable future, because it's needed to do method resolution among other things, and MIR construction boils away methods into function calls.)
Thanks, im an idiot without context.
This is the kind of response I was hoping for. I wasn't aware that Rust also provided this kind of safety for mutability. That's actually pretty sweet!
Sure, but again, this goes back to my claim that it doesn't make sense in either library, and that it causes improper dependency chains, which come with their own series of headaches. There are definitely reasons for and against.
&gt; You would just make your structs generic. This comes with its own oddities: sometimes it just doesn't make sense to propagate the type information upward. Another case where this comes up is if you want to store a closure: propagating the type up to the toplevel means that a big world-encompassing struct is parameterized over the tiniest of details. It would be nice to have a similar impl Trait feature for structs: "some type goes here, you know what it is, but I can't/don't want to write it out". &gt; Writing a function or a data type that accepts any type that impls a trait is easy I'd actually like this to be easier too. impl Trait is so lightweight, it's very nice. It would be nice if you could write function parameters in a similar "inline" way if the generic parameters were only used in one place, e.g.: `fn foo&lt;T&gt;(t: T) where T: Trait` =&gt; `fn foo(t: Trait)` One of the big headaches with haskell is when your functions end up being parameterized over a huge list of typeclasses/generics, and I sort of see this happening in rust too, especially as more things need Deref to work smoothly.
And if you'd like to get involved, we're always keen to see new contributors, see https://github.com/rust-lang-nursery/rustfmt/blob/master/Contributing.md for details or ping me if there is something you're particularly interested in.
Thanks for the insightful comments. I may have to read through the full RFC. Compilers have always fascinated me (and I've done some work with them when I was in college). I love the very open nature of rust development.
What tools did you use to measure and generate these? Is it an automated process? I believe that nrc is working on isrustcfastyet.com, so he may have be interested in these.
&gt;This comes with its own oddities: sometimes it just doesn't make sense to propagate the type information upward. Another case where this comes up is if you want to store a closure: propagating the type up to the toplevel means that a big world-encompassing struct is parameterized over the tiniest of details. It would be nice to have a similar impl Trait feature for structs: "some type goes here, you know what it is, but I can't/don't want to write it out". You can just keep stacking impl Traits to hide the implementation details. This would become Rust's version of an abstract data type. &gt;I'd actually like this to be easier too. impl Trait is so lightweight, it's very nice. It would be nice if you could write function parameters in a similar "inline" way if the generic parameters were only used in one place, e.g.: `fn foo&lt;T&gt;(t: T) where T: Trait` =&gt; `fn foo(t: Trait)` I thought about this before, too, but then you would not be able to say that two types implementing the same trait are the same, e.g. `fn foo&lt;T: Trait&gt;(t1: T, t2: T)`. Besides, writing a trait in type position currently indicates a trait object. &gt; One of the big headaches with haskell is when your functions end up being parameterized over a huge list of typeclasses/generics, and I sort of see this happening in rust too, especially as more things need Deref to work smoothly. I have thought about this recently, and there's no good solution. I mean, I have a lot of tricks for this, actually, but they're all special cases. In Haskell it's actually easier because there is no overloading of function names, so if you just reference the functions in the typeclass that you want, bounds will be inferred appropriately.
Yes, it's impressive, and needed.
Is there support calling rustfmt from the atom editor?