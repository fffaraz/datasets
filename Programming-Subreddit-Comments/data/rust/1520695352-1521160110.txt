Isn't alacritty scrollback still under development?
This is always shown in Sci-Fi movies as some sort of dystopia. Having "Augmented Reality" everywhere. DON'T WANT.
VR/AR/3D has been something that is the "Next Thing" every 2 or 3 years since about 1980. Remember VRML browsers? 3D (in the AR/VR sense) movies, TV, Video Games, AR, are all a flop. They're "fun" for about 5 minutes until the novelty wears off.
I only subscribe to D&amp;D subs and Rust subs. I was assuming this was posted to /r/dndnext or something until I realized it was going to crates.io... Thanks for the cool utility :)
What I find interesting, is that I knew C++, then learned Rust (which was hard to get into because I was trying to write C++ in Rust), then dabbled with Go. Going the opposite direction of Rust â†’ Go made me feel that Go was clunky and that Rust had much better abstractions, much better syntax, and much better semantics. I had a D' moment in my dabbling with Go where I wanted to go back to Rust.
&gt; thereâ€™s little incentive to work on everything else that makes a browser engine I'm a bit out of the loop these days - is Servo not still a much better candidate for embedding? Is that not considered an important use case any more?
Thanks for the kind words! I decided to get ready for my day before spamming the various D&amp;D subs for karma. ðŸ˜Ž
I've been able to do sudo -E cargo but it's probably not a good idea in general.
Should make some unit tests ;)
As someone trying to build his own UI around a browser engine, this was my big hope. I'd be quite sad if Webkit will remain the only solution.
If servo components are composable outside a framework the work could be remixed. Servo in whatever form the team and the product takes should add to the overall crate ecosystem.
It says so in the article that this is a recursive descent parser. Which basically implies hand-written.
Making a false dichotomy out of it doesn't seem too useful. See the stats in the readme: ggez has an unsafe trait impl. I'd honestly forgotten it was there. It's used in one place and does almost nothing; it's just a marker. I'd consider that a different beast than, say, a crate that uses unsafe for ergonomic or performance purposes, or one that deals with FFI a lot. I consider those the three major applications of unsafe, and they have very different concerns. Alas, this tool is too crude to differentiate them, but maybe it's a start.
In the past (for XML and in Ruby) I've implemented a mix of SAX style streaming parser but that returns full objects instead of just the SAX events. I did that with a single generci serialize/deserialize API that also allowed full in-memory parsing and efficient writing of large files without having to first create the whole structure in memory: https://github.com/pedrocr/xmlcodec Serde will probably allow implementing all this in rust these days. The relevant API for this case was something like this: class MyStreamListener def el_secondelement(el) obj = el.get_object ... do something with obj ... # To remove it from the stream so the parent # doesn't include it and memory is freed. el.consume end end parser = XMLStreamObjectParser.new(MyStreamListener.new) parser.parse(some_string_or_file) That gave you an event on every "&lt;secondelement&gt;" and the "el.consume" line ensured that after that event was processed all the memory was freed. This kind of API worked great to both read and write multi-GB XML files. Even wrote a paper about it at some point.
That assumes everything is crammed into the same application. If the "map a location/thing to an identifier" function can be used by multiple applications, then you get "Wikipedia vs. various Wikias vs. Merriam-Webster vs. ..." rather than the "naive Google search" nightmare you're envisioning.
That or "cheaper, more widely available HUDs" situations. (ie. Look at places like fighter jet cockpits which already use HUDs, then look at where the technology would broaden out to being worth the investment if it could be applied more cheaply and easily. I don't really keep up with car technology, but I remember reading that car-makers want to use it for enhanced-visibility overlays in situations like nighttime or blizzard driving.) I think the Intel Vaunt is more in the vein of what can catch on in the near future... and it'd still probably be as niche as non-FitBit-esque uses of the Apple Watch.
I think the number of uses of `unsafe` is a questionable metric. Whether your unsafe code has undefined behavior or not also depends on the behavior of the code marked as safe. Minimizing this metric would reward code that incorrectly marks functions and traits as safe while punishing more correct and thus safe code! Instead, I believe it is better to list which crates in the dependency graph contain unsafe code directly, so they can be reviewed individually.
While you can get by with a bare `Err&lt;T&gt;`, the value of a common trait is easier interop between libraries With that, I think the value of `failure` is two fold - Fix flaws in the trait - Iterate on ergonomics I agree that ergonomics is the major the selling point for `Error` but if we can successfully solve these problems separately then it unlocks the door for stablizing both earlier. `Error` at that point is a helper and people can implement competing versions like we had with error-chain and friends.
Iâ€™ll just leave this here. https://crates.io/teams/github:servo:cargo-publish?sort=recent-downloads
Not really the only way, but it's a way. Servo as an OSS project should diversify as much as possible. I agree that there's a risk, but with careful management it can be a source of resources for Servo while at the same time not having to be a huge burden. I can't say that will or will not happen.
Thank you for the feedback. I'll definitely take this into account in the future video!
Interesting, but, I do find these kinds of things to be a little counter-productive for new Rust users. It reads like, "Here is this thing that Rust can't do that you need to do and here is how you can hack your way to doing it." I prefer that the decisions that Rust made around not supporting function overloading are upheld for the thoughtful decisions they were. Function overloading (beyond generics) is pretty much an anti-pattern and leads to less readable and understandable code. Just my opinion. But, not to take anything away from your great explanation, etc. I just think that someone new to Rust should think twice before implementing things like this without first understanding why you probably should NOT want to do it this way.
The `diesel` crate is a "ORM" that may be easier to use, and I am pretty sure it has mysql support. Check out http://diesel.rs for docs, and their gittr channel (accessible via the badge on their github readme) is populated with some helpful people.
[removed]
Genuine question: Are there non-toy-related uses for AR/VR that exist? Or is that typical assumption that the applications will emerge only once the technology exists? 
Yeah, a few days ago a project was announced to finally implement scrollback: https://github.com/jwilm/alacritty/projects/2 @thristian99: It is definitely a solution I didn't think about myself. I'm not 100% sure this is best to solve in the terminal. It seems like it could break a lot of current assumptions.
Thank you!
Aren't traits with associated types exactly equivalent to overloaded functions?
Thanks for reading, I find myself in agreement. Using traits for overloading requires quite a lot of boilerplate to set up and making the source code less readable. In my own project this problem came up after I already wrote all the 'overloads' as separate functions but for user convenience I wanted to provide a single interface which lead me to experiment with traits. Hopefully the amount of boilerplate required will make someone consider if they really need to overload a function.
Generally I agree, that function overloading is an anti pattern, *but* I really like it with constructor calls, because it's clear what the constructor does anyway. Since it doesn't have constructors this of course doesn't concern rust.
Make sure you measure, cloning strings is suprisingly fast and Arcs are surprisingly slow (compared to my expectations when I was in a similar spot).
Some advantages of a pager: - Switching between line-wrapping on and off - Searching - Viewing really immense files - Scrolling horizontally in wide tables - Variety of commands at your fingertips, and no mouse use (e.g. half-page advance on 'd') - (other things I've forgotten)
Not to tell you how you should handle your business, but, I think it would be helpful if you added some caveats, and perhaps some links to documentation and/or RFC discussions etc., regarding Rust's intentional decision to NOT support function overloading. So many, when they are new to a language, just Google for something and then come across a well-intentioned and well-written Blog post like yours and then think this is the way to do things. Anything like this can benefit greatly by linking to some documentation and even making it explicit that it is basically implementing, for at least Rust, and Anti-Pattern.
True, an associated type has exactly one value per impl, but it still can be used to allow a trait method with different outputs depending on the inputs.
Tool aside, I've never heard of this house rule before and I do agree with its rationale, I'll definitely use it in my next game. :)
I personally find the trait based solution much more agreeable than plain overloading. With overloading, it is fairly easy to surprise the users of your API (because, say, `foo(X, Y)` is completely different than `foo(Y, X)`), and it makes the right instance of overloaded functions hard to find. With traits, the trait name itself can document the expectations put on a type. Not only makes this the implementation more obvious, it also allows others to extend it with their own types (provided the trait is public).
Is there a super-simple pseudo-random number generator crate or algorithm I can use for my game? It must be a no-std crate.
Global variables are one example. Also perhaps as mutable members of larger, immutable structs wrapped in an Arc.
One case where you might use a Mutex without an Arc is with [crossbeam's scoped threads](https://docs.rs/crossbeam/0.3.2/crossbeam/struct.Scope.html). Also, Mutex can't implement Copy either way, because it owns the underlying OS resource, which can't be copied with memcpy. You might be thinking of Clone.
There's a 3rd-party crate `cargo-update` that provides a command `cargo install-update` which does what you want (and also supports updating *all* installed crates).
There are probably lots of crates, but "super-simple" sounds like what you can get from `man 3 rand`: POSIX.1-2001 gives the following example of an implementation of rand() and srand(), possibly useful when one needs the same sequence on two different machines. static unsigned long next = 1; /* RAND_MAX assumed to be 32767 */ int myrand(void) { next = next * 1103515245 + 12345; return((unsigned)(next/65536) % 32768); } void mysrand(unsigned int seed) { next = seed; } 
Another example is custom memory management, like e.g. arena allocators.
Hey that's a pretty nice name.
It's pretty idiomatic to separate concerns, i.e. shared access (Arc) and interior mutability (Mutex) - it's very easy to combine them afterwards using e.g. `type MyMutex&lt;T&gt; = Arc&lt;Mutex&lt;T&gt;&gt;`, while picking a combined type apart is impossible. (Also, for the concrete case of `i32` you'd in many cases not use a `Mutex&lt;i32&gt;`, but an `AtomicI32`.)
Looks cool! I think `syntex` has been replaced by `syn`, which I found very easy to use, so hopefully porting to it would be straightforward for a motivated person.
Firefox phone 2
The `rand` crate has an `std` default feature that can be turned off: [dependencies] rand = { version = "0.4", default-features = false } All that really turns off is allocation and `ThreadRng`; you can still use all the RNG types. `weak_rng()` is probably suitable for your purposes.
&gt; Re: cookie management. I was sniping on a parenthetical example, as I said I was. I do not think there is a 'trend' of lost features, however.
I think Mutex heap-allocates no matter what. You'd need to use parking_lot or something.
Thank you for that link. Looks exactly like what I might need.
It is indeed terrific... especially if you read this after having read most of "The Book" and still felt like some things weren't explained to the point where you can write more than toy code. This book seem to fill in all the gaps. 
On the other hand, I think it's good to question the inability to do things you might want to do if the language allowed it. There is a big problem in other programming language communities (which I won't name, to avoid the zealotry rule) where people defend language design decisions that probably aren't very good with things like "this was a thoughtful decision by the language creators."
Here's an example: struct Player { id: String, score: AtomicUsize, items: Mutex&lt;Items&gt;, keybindings: Mutex&lt;KeyBindings&gt;, } In a multithread game engine, you might want to make an `Arc&lt;Player&gt;`. The Mutexes protect the inner fields that are able to change. By not having a global mutex lock on the entire player, multiple threads can access `id` concurrently.
You have no idea how much this post helped me 5 months later. Couldn't find *anything* similar to what I was creating. Thank you!!
Python? I get that c++ is broken but python seems to have a fully serviceable inheritance/exception based mechanism Maybe they like to throw a little too often but other then that???
Java checked exceptions are basically unweildy result types
There is a certain cadence to posting here. Either I post a discussion-furthering comment and get discussion-furthering replies, or someone snipes on something immaterial and the children use that as an excuse to bury the comment. So then I have to write a harsh-but-honest reply to rectify the situation and this is where we are now. This is the only sub I use that I have to do this in. I'm not at all happy about it, but your tone guaranteed we'd get here.
100%â€¦ if you donâ€™t count SpiderMonkey, freetype, angle, harfbuzz, etc etc.
yeah, SpiderMonkey is a big part, but all the "browsery" parts and `main()` are Rust, that's what counts :) + Pathfinder will be replacing Freetype, right?
Whats the silver standard?
Sorry I haven't had time to expand the bootimage tool. I'll get to it eventually.
Thanks for the example, I think this puts into words something I realized I was misunderstanding. In C++ I guess normally you think of "const&amp;" as applying to all members recursively, since their is no way to tell the typesystem which members are safe (other than the avoided "mutable" keyword)- so designing types with the intention of mutating data under a immutable reference seems unnatural at first, but is clearly a common pattern and source of power in Rust.
Never need unit tests if you always write bug-free code! =P
[This Reddit post](https://www.reddit.com/r/DnDBehindTheScreen/comments/80f6kt/the_silver_hack_making_money_matter/) explains it better than I will.
Adding lifetimes on a struct that previously didn't have one is the worst! Then you finally get it in place and there's some other reason it won't compile. 
Much obliged
**WEB-SITE HERE:** [Writing an OS in Rust : Philipp Oppermann's blog](https://github.com/phil-opp/blog_os) 
Because unsafe means there are weaker proofs of program correctness applied.
Well, I may have to take my foot out of my mouth for the time being because I too am having difficulty finding links to show how and why the decisions was made as it was in the Rust language. I've started a [discussion thread on Rust Internals](https://internals.rust-lang.org/t/justification-for-rust-not-supporting-function-overloading-directly/7012) to hopefully have the community help to tease it out.
I've [added a commit](https://github.com/assert-rs/assert_cli/pull/91/commits/f6bd91a1c240f7069a5a8ac487ebcb76b8dffd7c) that switches from a `Context` per piece of information to a `Fail` for each grouping of information. This is probably `failure`s sweet spot on ergonomics atm. - `.context` effectively is `chain_err` and `Context`/`Error` take care of all of the `cause` stuff for me, keeping my `Fail`s simple. - Easy to "throw" one of these errors with `bail!` - The two places I couldn't use `bail!` will work with the future `throw!` macro.
From the Rust Internals discussion, someone posted a link to the Blog Post by Aaron Turon: https://blog.rust-lang.org/2015/05/11/traits.html This seems to be something worth linking to from your blog post.
Buddy don't assume that you wrote bug free code, better assume that you did, and write higher quality code. 
Harsh-but-honest is just being an asshole, do not do that. You are not rectifying anything, you are just being ill-mannered. I was simply telling you that your idea that Mozilla just getting rid of features for no reason is wrong in your example. Am I obligated to reply to your main point? No, I am not, and I decided not to. I do not care where Servo goes, because the people working on it are smart, and will do cool research-development either way. Are you happy that I did what you think I should now?
Actually, that's not really the point of unit tests. Unit tests say that in a couple months when you decide to add another feature you can run all the tests and make sure it still works the way it did before. Maybe you refactor into a separate lib, make each currency type it's own struct, and allow arbitrary conversion both ways. If you write your unit tests in a good way, they should require minimal, if any, modification. And if they fail, you know you broke something along the way.
Yes, I know. I was just being facetious. I'm sure that there are small bugs in the program. However, since it's just a small, toy utility, I don't think it's a big deal to leave out test cases. I'll be continuing to work on the program further and as I add additional features, there shall be test cases.
I had trouble figuring out how to do anything in diesel that wasn't spelled out in the guides. i recommend starting off with a simpler driver. easier to make progress that way. you can always check out steeper abstractions when you've got something working imo.
With [scoped threads](https://docs.rs/crossbeam/0.3.2/crossbeam/struct.Scope.html#method.spawn), which are no longer in the standard library but are still available from external crates, you can share things across threads without wrapping them in `Arc`. For example you can send `&amp;Mutex&lt;T&gt;` to multiple threads as long as the Mutex lives longer than the threads' scope.
Say you want to try out some function in the core libraries to see what it does. Is there an easier way of accomplishing this than writing a new test or editing the main function? Ideally I'm looking for something like a REPL, but the only thing I've found is Rusti, which isn't working as easily as I'd hoped.
Minor nitpicking: &gt; `&amp;(*std::begin(vertices))` Since you're using C++17 this should be `std::data(vertices)`. For earlier standards, `std::begin` is fine but doesn't guarantee contiguous underlying data the way `data` does, so this should be accompanied by a static assert or SFINAE to at least assure random-access (since there's no iterator category for contiguous storage :-[ ) if it's in generic code. &gt; And this works because _GLsizeiptr_ is a define of _size_t_, so it promotes automagically. There's nothing to promote â€“ `sizeof` yields a `size_t` directly so everything is already the right type.
You want to be able to access the Core before you run the stream future on it? Here's an example I pulled out of one of my projects at random. I seem to come up with a different way to do it every time, there are just so many objects collaborating. fn main() { let mut core = Core::new().unwrap(); let handle = core.handle(); let client = hyper::Client::configure() .connector(hyper_tls::HttpsConnector::new(4, &amp;handle).unwrap()) .build(&amp;handle); let addr = "127.0.0.1:3000".parse().unwrap(); let http = Http::new(); let listener = tokio_core::net::TcpListener::bind(&amp;addr, &amp;handle).unwrap(); let factory = move || { MyService { client: client.clone() } }; let future = listener.incoming().for_each(move |(socket, _peer)| { let conn = http.serve_connection(socket, factory()) .map(|_| ()) .map_err(|e| eprintln!("server connection error: {}", e)); handle.spawn(conn); Ok(()) }); println!("Listening on http://localhost:3000"); core.run(future).unwrap() }
TBF it's not the only crate with a totally opaque name. Not by a long shot.
Here's a good post I read today on Hacker News: https://news.ycombinator.com/item?id=16557427 &gt;Servo is actually not typically viewed as realistically completable. Even Firefox, which is being developed full-pelt, is behind on web standards (like any other browser is). &gt;So, for Servo to catch up to the current state of Firefox and to then also keep pace with new web standards, it would have to be developed much quicker than Firefox is being developed. So, that would require more than double the development capacity that Mozilla currently has, as they can't drop Firefox development either. &gt;There is some points that could alleviate this: &gt; - A smaller project grows quicker, &gt; - it being written in Rust might speed up development in the long run and &gt; - several components are now shared between Firefox and Servo, meaning that the development and maintenance work is shared as well, &gt; but it still is far away from realistically completable. &gt;Which is also not what the project is meant to be. It's a research project. Trying out new things, creating components that can be used in Firefox, and doing experiments with VR or similar are exactly what it can be used for.
That's correct (which surprised me): #[stable(feature = "rust1", since = "1.0.0")] pub struct Mutex&lt;T: ?Sized&gt; { // Note that this mutex is in a *box*, not inlined into the struct itself. // Once a native mutex has been used once, its address can never change (it // can't be moved). This mutex type can be safely moved at any time, so to // ensure that the native mutex is used correctly we box the inner mutex to // give it a constant address. inner: Box&lt;sys::Mutex&gt;, poison: poison::Flag, data: UnsafeCell&lt;T&gt;, } I suppose that makes sense. There's no other way to make sure that the `sys::Mutex` doesn't move ([yet](https://github.com/rust-lang/rfcs/pull/2349)).
Hi all! I'm wondering about something and am always appreciating hearing the wise words of rust users. Are generics, typeclasses (traits), and function overloading good for anything? The basic point of these all is being able to use the same name (symbol) to point to different functions. I remember being excited when learning all these, but that excitement was more founded in others excitement than in first-principles understanding. The more I think about these it seems they are un-simple (as in simple vs easy). Having a symbol with multiple meanings is less simple than mapping a symbol to a meaning. 
yeah you're allocating the DFA and search info, but not the _entire_ underlying buffer being searched. I think I expressed this wrong 
i find [the rust playground](https://play.rust-lang.org/) to be a great place to write small tests. 
If the function has examples in its documentation (like [these ones](https://doc.rust-lang.org/std/iter/fn.repeat.html#examples)), you can press the "Run" button to open the example on the playground where you can edit it and try it out.
[mmstick](https://www.reddit.com/user/mmstick) has summarized it well. To go from D-&gt;E one needs to master the some patterns in Rust. Suggestion: Master Option and Result first. My biggest hurdle was to write the basic control flow and error checking, which forms a substantial chunk in a non-trivial code. There is a consistent pattern between how to deal with it when it comes to Option and Result. These are achieved using a combinators (like map, and_then, etc). Once you are comfortable with these, you will see that some of the learned patterns also apply to futures. Best way to learn these combinators, in my opinion, is just to use 'match' liberally to begin with. It is important to make the code working without worrying about the verbosity and then re-factor it using the combinators. I used to really enjoy this part. It is like a mini-puzzle with feeling of instant gratification every time you solve it. (I think this merits a separate blog post). After some time you will start to write code using combinators at the first place.
Rust abstractions generally compartmentalize their guarantees. In turn, this makes them easy to [compose](https://manishearth.github.io/blog/2015/05/27/wrapper-types-in-rust-choosing-your-guarantees/), and makes them easy to use individually. I think I've written bare `Mutex&lt;T&gt;` _way_ more than `Arc&lt;Mutex&lt;T&gt;&gt;`, so I dispute that it's the overwhelming majority. More commonly I see code using Arc for shared ownership and eventually reaching a point where they need some localized mutability so they use Mutex for one specific field only.
As far as I know Pathfinder actually uses Freetype (for some platform-specific hinting, or something?)
I think you're conflating "meaning" with "data structure." A concrete type expresses what data structure you're looking at; a trait expresses what you can do with the thing. For example, Hash is a trait signifying a type that can be hashed. The concept of hashability has a meaning independent of the data type actually being hashed. Being able to talk about that concept in our code is useful. As for generics, they're pretty much required for a powerful type system like Rust's. For example, unlike most languages, Rust doesn't have null. Null is a massive source of complexity, because every type implicitly contains null, and it works differently from every other value of that type. And on the other hand, sometimes a type simply *can't* be null but needs to express the concept, and then you have semantically awful sentinel values like -1 for "not found". Instead, Rust has the Option type, which can contain any other type to express the possibility that a value of that type exists or no value exists. It is declared like this: pub enum Option&lt;T&gt; { None, Some(T), } There isn't really a way to express that in a type-safe way without generics.
No. I want to use it from within a tokio (not tokio-core) executed future. I canâ€™t gind a way to do that. 
I'm having trouble figuring out how to call functions across files. Say I have a function in myproject/src/mydir/myfile.rs and I'm trying to call it from myproject/tests/mytestdir/mytestfile.rs. How do I do that?
Do you think you could possibly rate based on how many _modules_ use unsafe? Of all metrics, this seems to me to be the best one. With most unsages of unsafe, unsafe usage in a module usually depends on other safe code in that module acting correctly. I don't think there should be any difference between `unsafe { do_func() }`, `params = calc_params(); unsafe { do_stuff(params) }` and `unsafe { /* calculate params */ do_stuff(params); }`, since all will rely on roughly the same amount of code being *correct*, regardless of how much it is *unsafe*. I say module here rather than crate, because in best practices, everything that could possibly break the unsafety in safe code is kept private, within the module (not even within the crate).
&gt; I would reconsider dropping the requirement that every cpp file has to have a header file and vice versa Sure, I plan to add feature to explicitly mark a header as header-only, so it wouldn't search for c(pp) file. As you said, this is useful. It already doesn't require a header file for "root source" - usually the one containing `int main()`. Can you provide an example of source tree, where it does make sense for more than one c(pp) file to NOT have a header?
You can get access to the tokio Runtime of a Core https://docs.rs/tokio-core/0.1.14/tokio_core/reactor/struct.Core.html#method.runtime So if you use that Runtime as your main runtime, it ought to work together. But I haven't tried this yet.
I'd think less in terms of files, and more in terms of modules. Something exported from `src/mydir/myfile.rs` is going to by `my_project_name::mydir::myfile::&lt;item name&gt;`. Within `mytestfile`, then, you could do something like the following: use my_project_name::mydir::myfile; myfile::the_function(); This would assume `my_project_name` is in the "root" context of the current crate, so whichever file declares `mod mytestdir;` will also want `extern crate my_project_name;`. This is my go-to resource for thinking about module structure in rust: https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/
You can always special case away specific uses of generics via language features. For Option&lt;T&gt;, you can provide a `?` modifier on types. So e.g. `i32` cannot be null, but `i32?` can be. For more examples, hash maps and slices in Go are generic via language features and not general generic types.
Then the stuff inside the `if` and `else` branches should just be a function call to the logic you don't want duplicated every time. But noticing a point when degenericalization happens and making sure not to duplicate that code would be helpful...
Whether TIOBE is bad or not, it IS a problem if almost every post in this thread is basically saying the same thing while the only critical post is being downvoted. This thread is a denialism circlejerk. If people believe that TIOBE is important, which apparently is the case, it needs to be taken seriously. Saying "what you are doing is shit!" right when you enter the community is not a good strategy to grow it. Many metrics can be gamed. Thats why Google keeps its search ranking algorithms so secret. And these gameable metrics that Google uses are highly useful, both for users, who have web searches, and for Google itself, who make billions with ads on their search page.
Hmm, why do you have to have `foo` in `impl Foo` as opposed to just declaring `foo` in the `impl trait`s: struct Foo; struct Bar; trait Overloaded&lt;T&gt; { fn overload(&amp;self, T); } impl Overloaded&lt;i32&gt; for Foo { fn overload(&amp;self, n: i32) { println!("Foo.overload(int): {}", n); } } impl &lt;'a&gt; Overloaded&lt;&amp;'a str&gt; for Foo { fn overload(&amp;self, s: &amp;'a str) { println!("Foo.overload(&amp;str): {}", s); } } impl Overloaded&lt;i32&gt; for Bar { fn overload(&amp;self, n: i32) { println!("Bar.overload(int): {}", n); } } impl &lt;'a&gt; Overloaded&lt;&amp;'a str&gt; for Bar { fn overload(&amp;self, s: &amp;'a str) { println!("Bar.overload(&amp;str): {}", s); } } fn main() { let foo = Foo; let bar = Bar; foo.overload(42); foo.overload("Hello"); bar.overload(72); bar.overload("World"); } I think the same effect is achieved here.
I can't tell from your comment if you're aware that Let's Encrypt started as a joint project between Mozilla and the EFF and that Mozilla continues to be one of its primary sponsors.
I second this. Diesel was nice because it had everything included, but when I got stuck it was more simple to just switch to rust-postgres (similar exist for MySQL) along with r2d2. Less magic is often more simple, ergo easier to learn. 
No worries! Thank you for your invaluable testing and feedback!
I've been writing code from scratch over this past weekend using futures 0.2 already and it's been a breeze. That being said, it's brand new functionality (not porting something existing) and it's something that doesn't require Tokio to run (it's self-contained and doesn't need external io) so your mileage may vary on that. If you can develop your pieces without Tokio, then there's no harm in preparing yourself for the future when Tokio does become ready for it :). Otherwise, I'd wait. 
So far I have never failed to shoot myself in the foot by using a high level interface to something. Using the low level -sys crate is very often much easier, faster and you can use original documentation.
Unless stated otherwise, folks are going to reasonably assume that you're using "normal" hardware where RAM is measured in the "many GBs." In that case, 21MB is nothing. Just state your requirements more explicitly next time and a lot of the initial confusion in this thread would be avoided! :-)
Thank you all! I went with birkenfelds suggestion. The pictures look random enough.
I don't see any hostility personally. I see people making reasonable assumptions based on modern hardware. Just state what your requirements are. Notice that that may indeed include your own preferences. But it definitely wasn't clear from your original post!
I may be a bit touchy around the subject, I've been berated on reddit before for trying to write memory efficient projects (not this subreddit).
The minimalism of std is the only reason. `Arc` is plenty useful by itself and you can put a `Mutex` inside a struct, but the combination is especially useful. Fortunately the ergonomics of `Arc&lt;Mutex&gt;` are pretty good. You can call `.lock` on the `Arc` and it'll deref to the Mutex automatically. It might be helpful to define a constructor function. `fn arc_mutex&lt;T&gt;(x: T) -&gt; Arc&lt;Mutex&lt;T&gt;&gt; { Mutex::new(x).into() } But, there's also an argument for a combined `ArcMutex`. `Mutex`, on most operating systems, needs to keep state variables at a fixed address so that the kernel and other threads can find it. `Arc` needs the same for its reference counts. If they were the same type they could share one memory allocation. 
Good thinking but for lifetime reasons you should also consider `Box&lt;str&gt;`. 
I think the idea is to use traits to "overload" the small differences between the types - not the entire behavior. For example, in your example under "Stretching to the limit" instead of overloading the entire function, writing the `println!` every time, we can create a trait for the parts that change: trait CustomFoo { const TYPE_NAME: &amp;'static str; fn custom_foo_string(self) -&gt; String; } * (Ignoring the fact that you can already make a `String` using `Debug`/`Display`) * (Ignoring the fact that returning a `String` is a needless allocation - returning a formatter will just complicate things...) * (Ignoring the fact you can use the (nightly only) [`std::intrinsics::type_name`](https://doc.rust-lang.org/std/intrinsics/fn.type_name.html) to get the type name as string) Using this, we can implement the `println!` once, making it print the impl Foo { fn foo&lt;T: CustomFoo&gt;(&amp;self, arg: T) { println!("Foo({}) {}: {}", self.0, T::TYPE_NAME, arg.custom_foo_string()); } } (Playground: https://play.rust-lang.org/?gist=dac7808f999ac521c991a5cf2e87e23a&amp;version=stable) The advantage of this approach is that there is only one place where the logic (how to print) is defined, and the `impl`s only define the small details. Code that `impl`ements `CustomFoo` has less chances to mess things up, because the things it needs to decide are more focused. Now, I understand that your example is an example, and that real-life cases are not so trivial, but my point is that if you can't concentrate the differences to such small behavior functions, you should reconsider if overloading is the right thing to do or if separate functions with separate names would be a better fit.
What's the answer? What's the recipe?
Does it have something to do with generics? :)
Yeah, it looks really useful and convenient.
If you're interested, I'll do a part three on Saturday! https://twitter.com/Jonhoo/status/972363153479696384 See also https://www.patreon.com/jonhoo for announcements.
`ZipArchive` is [parametrized over a type that implements `Read` and `Seek`](http://mvdnes.github.io/rust-docs/zip-rs/zip/read/struct.ZipArchive.html) (such as `File`), so that you could also extract files from other I/O sources. In your case, you'd use `Option&lt;zip::ZipArchive&lt;File&gt;&gt;`. But "pre-declaring" variables like this isn't really needed, or idiomatic.
Oh. That clears it up... My original intent was getting a Mutex of a ZipArchive inside a lazy_static block (that aswell is probably not a good idea). This code is just to illustrate my problem. Thanks for your help!
Here a forum cross-reference, in case there's any discussion: https://users.rust-lang.org/t/indexmap-1-0-release-announcement/16104
Thank you!
This is a valuable addition! Thanks for making it and congrats on 1.0
most languages do not have a concept of Rust-style mutability, excepting C++; C++ is one of the only other languages that's even close. Most other languages, a specific (sub-)object is either mutable or immutable, always; or all objects are mutable (Lua)/immutable (Haskell).
If I understand correctly, it's better for use-cases with a lot of removal from the map? In a project I'm working on I implemented a Pool, which is composed of a Vec that owns the elements and a HashMap that maps a key to an index in the Vec. I do a lot of insertions at start, and lots and lots of lookups but never remove anything. After key lookups I store the indexes where they're needed. I think Indexmap would not help me much here, correct?
Congrats on the 1.0, though I can't say I'm enthused by the name change. I found the old name obvious (though my being a Python user as well likely helps), the new one made me think of indices in a DB sense, wonder whether that was about creating index (a b-tree collection useful to implement them?) or having index-type features, and definitely not about a general-purpose hashmap which happens to be ordered/indexable.
I'm trying to use the `crossbeam` crate for creating a simple server. Crossbeam gives me a `tx: Sender&lt;String&gt;` as the send part of a channel. When spawning a thread in `fn main()`, I can clone my sender and pass it to the thread (`thread::spawn(move || { ...`). This works great. However, I want to move my thread spawning to a function and this is proving to be difficult. With a method signature of `fn listen(sender: Sender&lt;String&gt;)` I get `type must satisfy the static lifetime` (E0477) no matter how I pass the sender. Why does the thread closure satisfy the static lifetime when declared in `fn main()`, but not in a new function?
Actually, since removal disrupts indexes, I think it's stronger for cases where you don't remove anything. I really like that you can use a direct `usize` index to retrieve items. For example, I used this to great effect in the pathfinding crate: https://github.com/samueltardieu/pathfinding/pull/82
It's hard to tell without seeing your code. It sounds like you've omitted the `move` on the closure passed to `thread::spawn()`.
That's quite nice! Maybe I'll update learn-opengl-rs with this.
HE'S BACK, BITCHES!
You could have a slow function that's just taking a ton of cycles to compute something 
Using this crate was a speedup on the knucleotide benchmarks game. Maybe because of a better cache locality of the hash vector.
It would be nice to discuss the memory/performance tradeoffs in more detail and pit them against the stdlib's HashMap/HashSet.
[Redbubble has some pullovers](https://www.redbubble.com/de/people/prvs/works/22689023-rust-lang?p=t-shirt&amp;style=mhoodie&amp;body_color=oatmeal_heather&amp;print_location=front), but the site is not in English, sadly. Or are you looking for pullovers for Rust the game?
&gt; I implemented a Pool, which is composed of a Vec that owns the elements and a HashMap that maps a key to an index in the Vec. I do a lot of insertions at start, and lots and lots of lookups but never remove anything. After key lookups I store the indexes. Wow, I literally implemented a structure exactly the same as that this week for a project I'm working on. (Except I use a custom hasher and store hash-index pairs in a BtreeMap, rather than HashMap). I too am wondering if this Indexmap struct might help for my use-case. 
I mean, it WILL eventually be doing IO, however it's more about moving data around within itself (think queues and the like). Since it's a self-contained application, I can apply async IO at the edges and make it one big black box.
[removed]
Crates.io has an automatic mechanism for giving you a line that will pin you to the same API version (Semver says that 0.x versions are more API-unstable than 1.x and beyond.). The docs have to be manually updated, so many authors just use `*` to avoid having to do it.
Another way to sum it up would be: * `struct` defines nouns. * `trait` defines verbs. * `impl` defines how to apply a particular verb to a particular noun. (Which also shows the conceptual flaw in classical inheritance. It refuses to acknowledge that verbs have an existence separate from and on the same level as nouns, so `Foo.frob()` and `Bar.frob()` aren't the same verb, even though they look the same to a human.)
...which got me thinking... maybe Rust should have some kind of FAQ entry providing links to the rationales for omitting features that people are used to from other popular languages or doing them differently. (eg. classical inheritance, function overloading, etc.)
OK. I see. But I'm still confused on what exactly I need to put in my dependencies section of my Cargo.toml file. Right now it looks like this: dotenv = "0.11.0" mysql_async = "0.12.2" dotenv_codegen = "*" So, do I need to add mysql = "*" and futures = "*" and tokio_core = "*". The author of mysql_async uses those crates in his example in the docs.rs page.
/r/playrust
You can use .ok_or() on the options to turn them into results and use the ? operator to do the early out. let a = a.ok_or(some_err)?; let b = b.ok_or(some_err)?; Ok(a+b)
The issue is not lack of optimizations, the issue is that the server crashes when it surpasses the amount of file descriptors allowed.
In your case I would probably try to split the code into multiple functions. If that doesnâ€™t work well Iâ€™d use `unwrap()` or an explicit `return` in the final guard and a return default value at the end of the function.
I don't know about canonical, but you can generally avoid calling `unwrap` on an `Option` by calling `unwrap_or`/`unwrap_or_else`/`unwrap_or_default` (to convert None to a default), `map`/`map_or`/`map_or_else` (for work that doesn't error and itself returns an `Option`) or `ok_or`/`ok_or_else` (when None is an error and a `Result` is returned). `Option` has a bunch of other useful methods (`and`, `or`, etc) as well that can help when dealing with multiple Options.
There's a RFC to have multiple if lets in a single if statement: https://github.com/rust-lang/rfcs/issues/935 That might help deal with the extreme nesting
Would this be a problem if the server was ran behind a reverse proxy? My intuition says that the reverse proxy would limit the amount of connections (given a similar amount of file descriptors available to both processes)
`gen_range()` is a provided method, why are you trying to override it?
`unwrap` can be an indicator of code smell. General consensus is that `unwrap` is fine if it's a situation where it cannot ever be `Err`, it doesn't make a ton of sense to check for `Some` or `None` and then also put a bunch of effort into error handling. There's `unwrap_or_else` for error handling, but even that isn't particularly what you'd need right now. You can accomplish your goal with: ``` fn p(a: Option&lt;i32) -&gt; i32 { match a { None =&gt; -1, Some(val) =&gt; val, } } ```
I'm quite new to rust, but I'd say any function taking lots of option&lt;x&gt; is a bad smell in and of itself. More specifically, a lack in separation of concern; mixing concerns of optionality (is that a word?) with the canonical function itself. Do the function really need to get optional arguments? If so, could it be split into two functions, one for the canonical case, called by one doing all the option arguments? That said, there are other ways of acquiring several options that need handling. I'm not sure if it's canon rust, but I've sometimes used tuple matching; match (a, b, c) { (Some(a), Some(b), Some(c)) =&gt; canon_func(a, b, c), (None, _, _) =&gt; -1, (_, None, _) =&gt; -2, (_, _, None) =&gt; -3, } Has the nice bonus of huge flexibility, with compiler-assistance ensuring coverage.
Interesting thought. Something to live alongside The Book and The Nomicon. Perhaps [this](https://www.rust-lang.org/en-US/faq.html)? Though, I don't think this is yet sufficient.
You can just throw a macro at it, no need to combine multiple `if let` statements, or convert to `Result` and use question mark operators. macro_rules! some_or_ret { ( $opt:expr, $ret:expr ) =&gt; { match $opt { Some(value) =&gt; value, _ =&gt; return $ret } } } fn p(a: Option&lt;i32&gt;)-&gt;i32{ let a = some_or_ret!(a, -1); // ... Do lot's of work with a a }
So that I can have it return predictable values for use in unit testing. I want to be able to input a set of numbers (population) and have it return those indices during my tests. e.g #[cfg(test)] use fake_thread_rng as thread_rng; let rng = thread_rng(); rng.add_pop(2); // Get the 3rd element when gen_range is called. let out = rng.gen_range(10, 15); assert!(out, 12); Normally I would pass a seeded random number generator into the functions, however the code is multi-threaded and uses another persons trait so I couldn't find a nice way to achieve that.
syn and quote are a pleasure to use 
I also looked to buy some rust cups for work, but could not find good ones.
The article starts out with: &gt; Iâ€™m writing a reverse proxy in Rust using Hyper and I want to measure performance a bit to know if Iâ€™m doing something terribly wrong. That doesn't help if you were trying to implement your reverse proxy in Rust using Hyper to begin with.
Perhaps rejecting/closing any RFC should require a new FAQ entry that summarizes the decision and points back to the RFC being rejected and the accompanying discussion.
The FAQ would get cluttered quickly if that were the case. My idea was to have a separate list referenced from the FAQ under a generic name in the vein of "Why doesn't Rust have/Why can't I find feature X?"
My favorite example is Rust's [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html) trait. Let's look at everything you need to implement an iterator: pub trait Iterator { type Item; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;; } That's it. The entirety of required interface is a single function that returns an optional value. Everything you need to know about iterators. Compare this to: - [C++](http://www.cplusplus.com/reference/iterator/iterator/), where you need to overload (!) the increment operator (`++`), deref operator (`*`), and possibly equality (`==` and `!=`). - [Python](https://anandology.com/python-practice-book/iterators.html#the-iteration-protocol), where the end of iteration is communicated with an exception. - [Java](https://docs.oracle.com/javase/7/docs/api/java/util/Iterator.html), where you need to call `hasNext()` before calling next. Note that this will give you troubles if you can't know if there's an item before consuming it with `next()`. - [C#](https://docs.microsoft.com/en-us/dotnet/api/system.collections.ienumerator.movenext?view=netframework-4.7.1#System_Collections_IEnumerator_MoveNext) where current value is stored as iterator property, so it might leak memory.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](http://www.cplusplus.com/reference/iterator/iterator/) - Previous text "C++" [Here is link number 2](https://docs.microsoft.com/en-us/dotnet/api/system.collections.ienumerator.movenext?view=netframework-4.7.1#System_Collections_IEnumerator_MoveNext) - Previous text "C#" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
https://devswag.com/collections/rust-project
`.map()` moves player, you'd have to instead do something like `self.player.as_ref().map(|p| &amp;p.body()) For the second one, that's just how it is; patterns have to match the references on the right hand size. In this case I believe you could instead write: if let (Some(ref player), Some(other)) = (self.player, other) or if let (Some(player), Some(other)) = (self.player.as_ref(), other)
I like thisone. Or maybe just rage?
C++ build systems have to fulfill different tasks. With Rust, your dependencies are all downloaded and there is a central repo. You don't have such a thing for C++ and you normally want rto use the installed versions of the libraries therefore you have to look for them.
&gt; I think it's worth noting that in Python, throwing exceptions for certain types of control for is the norm. Isn't that a problem itself? Exceptions are to be used to communicate *exceptional* situations. Getting to the end of the list is not exceptional. &gt; The dynamic language equivalent of Rust's iterator is Python's iterator. Not quite. The dynamic language equivalent of Rust's iterators is JavaScript's [Iterator Protocol](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#The_iterator_protocol), which returns an object which is dynamic equivalent of `Option&lt;T&gt;`: `{done: bool, value?: any}`.
Thanks, `as_ref` works fine :) if let (Some(ref player), Some(other)) = (self.player, other) don't , but I think it's because it's moving player to a tuple before destructuring.
Thanks, that got it compiling and passing my unit tests! I had to move the function out of the `Rng` trait impl. I'm not experienced enough with Rust to understand the nuances of this decision however I assume if I pass this object into a function expecting an `Rng` trait it will use the old default function? Either way this is good enough for my use cases. Thanks again!
Let's talk about [rayon](https://docs.rs/rayon/1.0.0/rayon/)! I've never seen data parallelism provided more intuitively in any other language. Replace `.iter()` with `.par_iter()`, and now your code runs on multiple threads. How awesome is that?! Oh, and did I mention that thanks to Rust's type system you're safe from data races?
I think it very much depends on what you mean by exceptional. For Python, the case that isn't the happy path is the exceptional path. If you want to convert a string to an int, you should just convert it, and possibly catch the exception of it's in the wrong format. If you want to open a file, you should open it, and possibly catch the exception if it doesn't exist. If you want to iterate through a list, you should ask for the next item, and catch the exception if the item doesn't exist. It eliminates error by forcing you to handle the exceptional case (JS' fake option will not force you in the same way). If you do choose for whatever reason not to handle the exceptional case, you will be told exactly where and when you forgot to correctly handle it. Sure, this happens at runtime, but there is really only so much that a dynamic language can do in this regard. I'd argue that Python handles it in the best possible way for a language that doesn't enforce static typing. It should also be noted that Python is heavily optimised for the situation where an exception is thrown and immediately caught - this is generally not the case in a lot of languages where exceptions should be thrown to indicate extreme situations. This means that using exceptions to handle control flow is a very ideal way of using Python.
I'd say `serde` is my idea of a really well designed rust crate. I mean, it: - provides what it provides - it "just works" for storing data - uses Rust's type system to the fullest to get safety and efficiency: no need for intermediate allocations if you deserialize everything directly to the type it needs to be! - uses custom derives well to provide a really nice interface: just slap `#[derive(Serialize, Deserialize)]` on a type and you can turn it any serde serialization format - is very extensible by the use of rust's type system: anyone can make a serialization format, use serde as the intermediary, and then serialize _any existing Serialize/Deserialize type_ with just as much efficiency as any other serde backend
I'd say that creating a collection trait would limit collections in the language, especially in the implementation part. Either way, if you need collections to implement a certain trait, you can always newtype it and then have that newtype implement the interface. So for example: pub struct Vector&lt;T&gt;(Vec&lt;T&gt;); impl&lt;T&gt; List for Vector&lt;T&gt; { fn push(&amp;mut self, x: T) { self.0.push(x) } } Rust will inline the call and you won't pay for the cost of the indirection. 
Can you provide some more details for what you're trying to do? There are a few problems with passing different collections using dynamic dispatch: 1) This could hinder the implementation of new collections. There are known problems with various collections in Scala specifically because of this. 2) Add a dynamic dispatch overhead. Suddenly, the cost of `x = array[i]` jumps from one-three CPU instructions to a dynamically dispatched function call. This is addressed in Java using JIT, but Rust doesn't have JIT and it cannot optimize away the dynamic dispatch.
There is even [no need for a newtype](https://play.rust-lang.org/?gist=4dc579ad76773e5c313c9ca8a0bd914e&amp;version=stable) in this case: traits you declare yourself can be impl'ed for types from external crates. 
Nothing in the question requires dynamic dispatch? A big point of traits in rust is static dispatch?
Fundamentally this is because rust doesn't have (almost) any form of higher kinded types. The [Generic Associated Types RFC](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md) goes into some detail. I get the impression we're at least a year away from GAT getting into stable, but I'm pretty sure that there's desire to get various collection interfaces (Collection, Map, etc) into std eventually. IIRC there even used to be some implementations pre-1.0 but they were removed because rust isn't expressive enough to make them useful. Yet.
You're right, I misread the question.
The reason is that collection traits can't be described in Rust. Some of the types involved would need to be higher-kinded types, and that feature [hasn't been implemented yet](https://github.com/rust-lang/rust/issues/44265). For more information, see [Niko's blog post about HKT/ATC](http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/) and [the relevant RFC](https://github.com/rust-lang/rfcs/blob/a7cd91048eea3d7ae83bec20446e62bad0c45381/text/1598-generic_associated_types.md).
Wow, this has just kickstarted my desire to learn Rust.
would be nice to have a random access trait, though? unless there already is one for the "vector/array index syntax", I'm not sure
There are Index and IndexMut traits.
It's *possible*, certainly. However, for now, using the new Tokio is more of a preview of how things can work, but it will get much better in a couple weeks, with the new futures release, and then hypers release. To get it working today: - You need to provide a `Connect` for the client to use. The default one creates older tokio-core `TcpStream`s, and so needs an older `Handle`. - The Client also wants a Handle, to use as an executor. A few patches ago, it can now receive a generic Executor instead. - You'll need to use the `current_thread` executor from tokio, not the thread pool, since the Client isn't `Send`. (There's a few reasons why, like holding an optional old `Handle` which isn't `Send`, and some other small things preventing it). The Client will be made `Send` in 0.12, but there's no way without a breaking change. 
I tried for two days now and finally gave up. When a core is running you can get an old handle and you can (as for this PR: https://github.com/tokio-rs/tokio-core/pull/314) use `tokio::spawn` but as you mentioned nothing in hyper is `Send`. Since `current_thread` is not shimmed when started out of the core there is really nothing you can do. I did not try to create a client from an executor yet. I'm effectively going to just hang on now and wait. I was I guess a bit too optimistic from the "tokio-core uses tokio" changelog note.
Does Java have higher kinded types? 
c# has .AsParallel() on enumerable which basically does the same thing (but without the data race protection, which is more about the language than the library), so I wouldn't necessarily say any other language.
[glium](https://github.com/glium/glium) is amazing. It is a safe interface to OpenGL. Rust features are leveraged to encode OpenGL API rules so that no OpenGL errors can be triggered by user code. It is also very fast and pleasant to work with. Doesn't seem to be very actively maintained anymore though.
I'm not following why higher-kinded types are necessary here? I am perfectly happy constructing a specific type of set, but want to be able to pass it to things that just want to do vanilla set operations.
I don't have experience with those particular crates, so I can't answer that question definitively. It depends on whether you need to access them directly from your code. If they're only used by crates you depend on but not by your own code, then having them in the `Cargo.toml` of those crates is good enough. (For example, I have projects which use `clap`. I don't use `bitflags`, so I don't need to add it to my `Cargo.toml`, but `clap` uses `bitflags` as an internal implementation detail, so `bitflags` will automatically get pulled in by cargo.)
Futures and Sink/Streams are really nice after you get them. Some familiarity with functional programming helps.
I agree that a strong static type system is one of Rust's biggest features, and that anyone who hasn't programmed with strong static typing before will likely get a lot of good habits out of it that will transfer to other languages. On the other hand, I'm not very comfortable with anyone who claims that Perl is more likely to yield bug-free programs that Python. :-) The other big feature of Rust that is missed here is simply what you learn about performance. Writing "natural" Rust generally gives programs that run with predictable C-like performance: within a reasonable factor (1.5x?) of bare-metal assembly using the same algorithms and data structures. I'm coming from having written a bit of Haskell. Haskell's type system is really helpful in ensuring correctness (although the community is slowly making it worse in my opinion â€” FTP, lots of higher-kinded stuff, etc conspire to turn mistakes into programs that compile and do surprising things). The performance of my Haskell programs was always noticeably worse than C (2-4x) and was highly unpredictable. I occasionally wrote a program that ran 10-100x slower than equivalent-looking C code, and had no real idea how to fix the problem. Python's performance is also terrible in my experience, but when I have a performance bottleneck it is generally easy to find and fix by changing algorithms and data structures. Rust shares this property, without the large constant-factor performance penalty. So yeah, Rust will help you learn to write correct, efficient programs. Learn it instead of Perl. :-)
While we're mentioning this non-uniqueness, C++ has OpenMP: int main(int argc, char **argv) { int a[100000]; #pragma omp parallel for for (int i = 0; i &lt; 100000; i++) { a[i] = 2 * i; } return 0; } Still love Rayon, though :)
+1 Once I was trying to change a data structure around so that it would serialize in a certain way. I was avoiding manually implementing serialize because I was sure it would be painful. *nope!* even manual serialization has a nice simple API in serde.
That's a perfectly acceptable use of `unwrap` and feels the cleanest to me. Closest runner up would be: fn p(a: Option&lt;i32&gt;)-&gt;i32{ // Unwrap or early return let a = match a { Some(a) =&gt; a, None =&gt; { return -1 }, } // ... Do lot's of work with a return a } (I'm not sure if the Rust style guide calls for the braces around a divergent match branch; mine does.)
Are you looking for [Refutable Let](https://internals.rust-lang.org/t/pre-pre-rfc-reviving-refutable-let-runoff/6672?u=cad97)? I'm working on the new RFC (slowly), I promise!
What sort of an abomination is this?
While your criticism is fair, and we should be taking the negative with the positive, the thing is this particular index doesnâ€™t feel right. It doesnâ€™t jive with what is going on in The Rust community. As far as I can tell every project that I watch has far more activity than just a year ago, in fact I stopped watching some because there was too much activity. For my own project it is getting far more eyeballs and usage. The reports that have felt right are the ones that show this growth as it aligns with what Iâ€™m seeing. And the thing is, Iâ€™m a weekend warrior on my Rust projects, mostly. Again, Tiobe just *feels* wrong.
I recently wrote a raycast in rust, and I've been able to figure out most problems on my own, but this one is really confusing. I applied a fish eye-correction thing, but now it does the opposite somewhat (see the picture) I'll post my code to github and link it here.
Well, it's not really ready to talk about yet. But the jist is that it's an os that only runs wasm in ring 0.
Thank you for writing this! It really solidifies a lot of what I like about rust, but couldn't put into words. I feel like there are many great aspects of rust, but this one, Rust's enforcing of a strict mental model, is one of my favorite. Any language can be fast if you put it on a fast server, but not any language can force you to think about ownership, lifetimes and correct semi-algebraic types at the same time.
This is a really cool idea, glad to see someone going through with execution of the idea How are you intending to do syscalls? My own thoughts are permission levels dictating which syscall functions are allowed to be imported
Prior art may include Clojure's reducers. https://clojure.org/reference/reducers https://www.braveclojure.com/quests/reducers/know-your-reducers/
as amazing as this is for people who need to use it day-to-day... ...it's always seemed so dirty to me. #pragma DO_IT_FASTER for (int i = 0; i &lt; 100000; i++) { ... }
Hello, what is the quickest way of consuming/removing elements from a big Vec?
Scala lets you put `.par` on a collection to turn it into the parallel version, too
Thanks for the answer, very satisfying actually. Good to have a reminder that tech should be in service to the business.
Almost every simple HTTP server is vulnerable to an attack that opens sockets and just keeps them open without sending anything.
No. Java does it using inheritance, which means dynamic dispatch, which doesn't really line up with Rust's zero cost abstractions mantra. It also means less type safety, for instance a function of type collection&lt;T&gt; -&gt; collection&lt;T&gt; the output collection is not necessarily the same as the input collection. (The T is the same though!)
manual deserialization on the other hand... it's a lot less pleasant, in my opinion. Doable, but not pleasant.
I'm going to try to document my process on my [website](https://vaporsoft.net) and post tutorials from things I've learned. I'm by no means an expert but still I think some of this information could be useful :) Backstory: I currently use Ruby on Rails for a production website. Ever since I've used mainly Rust it's been hard to go back, so I started a rewrite. Things I've noticed that could use help: - authentication can use work to make adding it easy. I'm looking at [rowdy](https://github.com/lawliet89/rowdy) which fits my use case, but needs an update to Diesel ^1.0. - multipart uploads built into rocket would be *awesome* - using diesel with Rocket could have some more examples! It was an adventure sifting through Diesel's API docs and 3rd party outdated code to figure out how to do what I needed
yes
The top-voted comment links to [Niko's blog post about the subject](http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/), the main takeaway though, I believe, is that you really want to have an `iterate() -&gt; Iter&lt;'iter, T&gt;` method on collections, and lifetimes are generics. In particular they're generics that are often different at every call-site. So, in a slight modification from that blog post, you want something like: impl&lt;T&gt; Collection&lt;T&gt; for List&lt;T&gt; { fn iterate&lt;'iter&gt;(&amp;'iter self) -&gt; Self::Iter&lt;'iter, T&gt; { self.iter() } type Iter = ListIter&lt;'iter, T&gt;; // ^^^^^ oh, wait, this is not in scope! } The [second blog post in the GAT (ATC) series](http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/) goes into some of the downsides of Collection traits that aren't based on the planned implementation (something more Java-like). So you might want to be able to write: fn floatify&lt;I, F&gt;(ints: &amp;I) -&gt; F where I: Collection&lt;i32&gt;, F: Collection&lt;f32&gt; { ... } but, as in that blog post, that doesn't constrain `I` and `F` to be the *same* type of collection, so you want to be able to express something like: fn floatify_hkt&lt;I&gt;(ints: &amp;I&lt;i32&gt;) -&gt; I&lt;f32&gt; // ^^^^^^ wait up, what is `I` here? &gt; But woah, what is this I thing here? Itâ€™s not a type parameter in the normal sense, since it doesnâ€™t represent a type like Vec&lt;i32&gt; or List&lt;i32&gt;. Instead it represents a kind of â€œpartial typeâ€, like Vec or List, where the the element type is not yet specified. Or, as type theorists like to call it, a â€œhigher-kinded typeâ€ (HKT). The blog series goes into lots more detail about the pros and cons of different implementation strategies, and specifically what they hope to achieve with Generic Associated Types.
I did not use Rust for the web-related side of things (I used PHP + Laravel). So I can't speak for that. Rust has benefits but it has also large drawbacks, mostly maturity of libraries and compilation speed (yes, it's an issue). The reason I picked Rust for my business was not because I was hyped by the language, but because (in hindsight) I think I couldn't have done it in another language (mostly because I needed performance). Maybe I could, who knows. - Performance was my #1 concern. You may not need performance that badly. - I worked alone and knew that I had lots of time / low stress until the MVP. - I hate dev-ops. In Rust, getting stuff to run in production is mostly to copy the binary to the target and switch over the server to the new build. In dynamic languages you often have less problems writing the app and more problems deploying it (packaging it up properly, getting all the config files, etc. to work). Or dependency management, which is nicely handled by cargo. - I knew that once I publish my MVP I can't "maintain" it in full-time, since I work alone. I knew that every error I made up until this point would cost me money. Every segfault meant lost work which means losing large sums of money. In your case a failure may be acceptable, if just a website crashes, who cares, just reload it. So overall I feel that Rust was a nice fit for my use-case (could be stockholm syndrome idk), but I can't speak for yours. What I can give you, however, is what I learned from my steps towards evaluating new libraries and seeing if they are mature enough: 1. Write down all your *absolutely necessary* libraries. All of them. Then google if Rust has libraries for those APIs / algorithms. If there is only *one* library missing, then stick with .NET, seriously. Don't waste your time to rewrite libraries for things if they exist in .NET or $language. As much as I love Rust, but that's not a good business decision if you are short on time or money. 2. If all libraries you need are present then evaluate if they actually do what you need them to do. I usually make a simple "XXXtest" for testing the library "XXX". This also gives me an idea of how much boilerplate the libary needs and how hard the library is to deploy (maybe it turns out you need to install some extra C library to use it which isn't available on your OS, so you just avoided another major risk). If all libraries do pass this test, then Rust is suited for your use-case and you will likely benefit from Rusts ecosystem. Otherwise, you'd waste your time fixing / rewriting other libraries and, given that you have limited money and time, it would not be beneficial. The only hurdle now is to onboard your team members, which is usually the least of your problems, it took me roughly 3 weeks learning on the side to get used to Rust. The language itself was the least of my problems. Of course, ask yourself if you really, really need things like Kafka, Hadoop, etc. I'd stop worrying about "is Rust right for me" until you know the requirements of the thing you're building. What Rust is currently rather mature at is building CLI apps, running simple JSON / HTTP-based servers, low-level graphics / rendering (although no GUI framework yet beyond QT / GTK), high-performance tools / libraries (in competition to C / C++) and where high reliablity is a must. 
There is a difference between voicing unpleasant truths and name-calling. I don't know what your problem is, I even tried explaining the situation. Please do not talk like this to me again.
&gt; Isn't that a problem itself? Exceptions are to be used to communicate exceptional situations. While I subscribe to the "don't use exceptions for normal control flow" camp (mostly because I have done so in the past and while it can be interesting, it's problematic as things grow), "exception" has it's own meaning and it isn't necessarily the same as "exceptional". Many of its possibly meaning lend themselves just as well to this context, if not better. Wanting to use exceptions for exceptional situations is fine. Calling out others for not following this *narrow* definition is just repeating dogma. 
&gt; Rust is martial arts teacher, Perl is a pub brawler. Nicely put. Somehow for me Rust evokes a image of a special forces commando. The training could be grueling but once you acquire skills, you can really kick-ass.
Thanks much for the detailed response! I read Niko's blog post, but couldn't really see the relevance, so I appreciate your help.
[removed]
Have you considered putting the timestamp first? Being able to merge logs from different processes by concatenating and sorting them is pretty great (yes, it doesn't work with multi-line messages, but they're rare and you can always look them up in the original log file). Format changes should definitely be part of the SemVer'd API. Almost universally, people feed log-files through some kind of regex-based pattern matcher to find the things they're interested in, and usually it's the first regex they came up with that worked, i.e. fairly brittle.
On the other hand, I don't think the Iterator trait supports stuff like [rusqlite::Rows](https://jgallagher.github.io/rusqlite/rusqlite/struct.Rows.html) well: * lifetime problems, which I think would be solved with [RFC 198: generic_associated_types](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md). * no ability to return an error at the end of iteration, so you have to (imho awkwardly) check inside the loop: `let row = row?;`. [This pre-RFC](https://internals.rust-lang.org/t/pre-rfc-generator-integration-with-for-loops/6625) might address that by letting you do `for row in rows { ... }?;` with generators.
I had trouble understanding your code, so I googled for 'fish eye distortion raycaster' and found this helpful article: https://gamedev.stackexchange.com/questions/45295/raycasting-fisheye-effect-question It seems like this is a common issue in raycasters. I suspect you're firing the rays out from the player position at regular angles. This causes an effect where the rays that hit the sides of the wall travel farther than the ray perpendicular to the screen, thus the wall is shorter on the sides. Instead, you want to fire the ray in the direction the player is facing but you want the base of the ray to be on a line that is perpendicular to the screen. The article I linked gives a few different ways to think about doing this calculation.
This raycaster is in fact firing at angles coming from the camera. I saw somewhere that it should be fixed if you just use cos on the distance of the angle, however it produced that effect in the image. Iâ€™ll try your solution tomorrow, and see if it works out! About my code, yeah the main.rs file is a mess. All the ray cast code should be in the camera.rs file, and the only thing youâ€™ll need to know is that the camera::calculate_ray function is called for each x every frame.
Indeed, timestamp first is best, so one can "sorted grep" through enormous log files very efficiently.
My vote goes to [itertools](https://docs.rs/itertools/).
I agree that function overloading is often something of a misfeature, but I think this is a pretty great exploration of Rust's type system.
I'm still working at bringing opportunistic mutations to [mutagen](https://github.com/llogiq/mutagen), and gnieto has pushed a PR to do coverage-based testing. Also we just got a PR from a relative Rust newbie I mentored through, which makes me unreasonably happy. In other news, I'll meet some of you folks on Friday at the [Rust Table of Regulars Frankfurt](https://www.meetup.com/Rust-Rhein-Main/events/248326240).
Let's say I have an `Option&lt;u8&gt;`. What would be the idiomatic way to run some code if the option is `None`, OR the inner value satisfies some predicate(Say, if it's smaller than 10)? `if let` doesn't work, and checking `is_none()` ans unwrapping doesn't feel right; matching with guard and an empty arm seems to be the way to go, but the empty arm still kind of bugs me.
Some things that would help improve the readability of your code (for me, at least): * On your functions try to document how the inputs and outputs are related. * On your data structures try to document the purpose and intended use. What are you representing? * Avoid unnamed constants ("magic numbers"). Examples are 3.14 instead of pi or writing 600 instead of height. There are other things I would change, but the above is a good start. Good luck!
`opt.map_or(true, |x| x &lt; 10)` should do what you want.
Thanks for the tips! Iâ€™m new to Rust, coming from a lot of C++, and I usually would have //#defineâ€™d those constants, but I just donâ€™t know how to do it in rust. Iâ€™ll look it up when I have time!
`Iterator` has been summed up already, but I'd like to bring `From` and `Into`, two unsung traits from faraway core-land to your attention. Together, not only do they help you to make things fit, they also let you abstract over conversions in both directions, making libraries much more usable. Also note their younger cousins `TryFrom` and `TryInto`, who do their best to follow in their older cousins' steps, even if they sometimes fail.
At our last meetup, we had a guest who is actually betting his business on Rust, and I can tell you that he's encountered more rough edges in the ecosystem than me, despite working with Rust for less than half as long. He still thinks it's worth it for him. But that's a testimonial of one. I'd agree that it very much depends on your business. If you do embedded stuff like snips or pollen, Rust will certainly give you an edge. If you do web stuff, code with what you know, identify the bottlenecks and see if Rust can help you with them. Otherwise, go the known path â€“ you'll have plenty of unknowns from the business side already.
I believe one is referring to the `core` module within serde, and one referring to `core`, the Rust language crate.
Yes VecDeque is perfect. Thank you 
 const DOG: i32 = 0;
During the last few month I spend a lot of time on the [alice-rs](https://github.com/cbourjau/alice-rs) library itself (bunch of crates to facilitate the analysis of public data from the CERN based ALICE collaboration). Even though I see a few things which I would like to improve, it is at a point where it is very convenient to work with IMHO. So this week (and a few more), I plan to focus on the actual physics-analysis which is using those crates to work towards a publication.
`Option` already has methods for this. `unwrap_or` to fallback to some default. Also it implement `Try` and so it is usable with `?`.
No need for `ok_or` since `Option` implements `Try` as well as `Result` does.
Have you read this PDF? [https://www.rust-lang.org/pdfs/Rust-Tilde-Whitepaper.pdf](https://www.rust-lang.org/pdfs/Rust-Tilde-Whitepaper.pdf)
Oh right, I keep forgetting this is a thing now! How does it know what error to return though? 
Use the best tool for the job. It really depends on your product, but most programming nowadays involves glueing a bunch of libraries together. For this Rust isn't ideal at the moment. Also, if a library does most of the heavy lifting, there's little point in calling it from Rust. If I were doing a start-up, I'd probably use a scripting language like Python (or C# if I knew that) for code that isn't performance-critical, Elixir/Erlang for code that needs to scale to many cores/servers and Rust for the heavy number crunching, where one might otherwise use C/C++.
`cargo install -f ripgrep`
I too find the current way to update non-intuitive, but here we go: cargo install -f ripgrep `-f` stands for `--force`
Thank you, sir!
Thank you, sir!
Thank you, sir!
It returns `None`. It works if function returns `Option`.
At CurrySoftware we use rust for [CurrySearch](https://www.curry-software.com/en/curry_search/) and other projects. CurrySearch is distributed over multiple servers but does not use standard tools like redis. Instead it servers communicate via HTTPS and transfer data with git using client certificates for authentication (described [here](https://www.curry-software.com/en/blog/authenticate_and_encrypt_microservice_communication/) ). The major advantage of rust is IMO its strong compiler. Humans make mistakes. Developing distributed systems humans make many mistakes. Rust can catch some of these (more than .NET at least). For example: Using Rockets request guards bundled with typed [byte arrays](https://github.com/CurrySoftware/byte-sequence) as ApiKeys or SessionIds has been really satisfying. 
Would you bet your business on .NET ? It really depends what your needs are. I would certainly bet on the Rust community being one of the most active in the programming world in the 5 comming years. 
"In 2013, Tilde shipped the first version of the agent, written in Ruby. While the Ruby implementation enabled Skylight to get started, the agent was limited in the data it could collect. Any feature added to the agent would make it use an unacceptable amount of memory. If Skylight wasnâ€™t able to add differentiating features, it wouldnâ€™t be able to compete against the entrenched players in the analytics space. Katz and his team spent time squeezing every drop of performance out of Ruby including removing uses of higher-level features of the language that required more resources. " It seems they bet their business on Ruby, and while they were not exactly right, they managed somehow. Switching to Rust at some point.
Makes sense, thank you! 
May I ask why the BTreeMap specifically? Is it more performant?
&gt; Why do you use self in one, but not the other, for the same core module? It's not the same module: * `use self::core::...` refers to the own module on line 137 that either re-exports `std` or `core`. * `use core::...` refers to the extern crate `core`.
There are 5 more days to [submit](https://cfp.rustfest.eu/events/rustfest-paris) proposals for RustFest Paris and I'll absolutely submit something before the very last day this time!
&gt; Does anyone have experience building large distributed systems and web services in Rust for "enterprise?" How has it been? I would bet my business on rust if the use case was client-side apps. For server side distributed systems there is nothing better than Erlang/Elixir. In my opinion one would be absolutely crazy to use Rust in this area right now. Especially over Erlang. The flexibility and ease of developing distributed systems in Erlang is unmatched.
What is the most idiomatic way to describe the following: ```rust if foo() { return 1; } else if bar() { return 2; } else { // more code } ``` Note different functions. Some ways which came to mind: https://play.rust-lang.org/?gist=a329a122947fb6a3429afe015c205c8c&amp;version=stable
First of all when I say 'Java', what I really mean is 'mainstream' and 'battletested'. Something where there is no risk of having to roll your own. A lot of that risk is with integrations with other products and services. None of them will be providing Rust crates. &gt; I think choosing Rust implies a willingness to sacrify upfront productivity for longer term productivity. Who pays the bills in 3 months? Who pays the bills in 6 months? Who pays in 12 months? Of course you don't want to build a mess. You do however want short term productivity. You do want stuff out the door. &gt; I'd be really scared to hire "i only know Java" people, even if my code base happens to be JVM based. I think you are misunderstanding what I wrote. I'm not saying get a code monkey. Sure, if you find they aren't very experienced then don't hire them. That's why you have interviews. I'm saying you'll find lots of experienced engineers, who have built large successful systems in Java (or some other mainstream language). When you don't have a stable income; you would want them to get as much as possible done as quickly as possible. So why jump ship to a language with no where near as much maturity? Get an MVP out the door, early income and/or a good investment round (or equivalent), good early hires, and having a hiring process as short as possible. In my mind these are higher priorities. Does Rust solve them today? Not right now. I don't think so. tl;dr For me it really comes down to maturity. There isn't a job market, and there isn't a long list of battle tested frameworks and libraries. For a startup that's a real risk.
Apart from front-end code, 100% of our software is written in Rust, apart from some inline assembly and associated glue code that we write in C (since Rust's inline assembly is unstable and we want to compile on stable). I don't think a single person here would consider moving to another language (and we've just started a new major project that will also be 100% Rust). Having said that, we're in a space that tends to have few pre-built libraries no matter which language you use and so Rust's relative immaturity is not the handicap that it might be in another industry.
awesome! I currently use python and flask, but look forward to hosting a website through rust! 
Nice thanks for sharing!
So, I have a stake in Rust business (I consult for it through http://asquera.de), and the answer to you direct question is no. Never bet "your business" on a technology choice. Its the same error that "we do everything in Java" shops do. Find the places where the technology makes sense and where it allows you to iterate and build faster. For me, these are currently definitely the following areas: * Performance-intensive computations * Memory-constrained environments * Areas with parallelism, where Rust is just extremely good, even without any fancy libraries * Areas with need for async programming, Rust makes that very easy * Shared libraries between many environments * Generally as a replacement where "C + stdlib" would be what you reach for * General tooling, Rust is easy to ship When it comes to building APIs and similar, Rust can be useful and I very much like Hyper, but be aware that you have to have good knowledge about potential attack vectors. Not all of the mitigations might be implemented in Rust yet. That still might make the language useful for you, but you have to implement these things yourself then. 
From python perspective exception mechanism is a tool, you can use it as it fits you, and they are used for managing control flow, signaling invalid data, manage db transactions and all kinds of other uses people can come up with. This means that certain APIs expect you to handle some specific exceptions because that's just the way API is signaling something, and python developers are accustomed to do that. 
'for enterprises' doesn't really mean anything, without a meaningfu understanding of what you do it's hard to give an answer. If what you needed can be done in the .NET, you don't need the speed edge rust would give. Maybe having the borrow checker would help you avoid loads of bugs ?...maybe, it depends on the project you're working on (e.g. how much it realys on impure funcs)
Compressing chess games for lichess.org. The database contains almost 700 million games (half of them [available here](https://database.lichess.org/)) and better storage efficiency will let us avoid the complexity that comes with sharding for another couple of years. The scheme is based on generating legal moves for each position, ordering them with some heuristics and then storing the indexes into the legal move lists using Huffman coding. I am using [shakmaty](https://crates.io/crates/shakmaty), [pgn-reader](https://crates.io/crates/pgn-reader) and [huffman-compress](https://crates.io/crates/huffman-compress) to quickly test this with big databases.
To be fair, companies that do go for less established languages all seem to report they have a glut of experienced devs applying, purely for the chance to work in Haskell/Elm/Elixir/Rust/etc. Most likely the same will happen with a company using Rust. Plenty of experienced people who use it for personal projects would love to work with it professionally, and might even be willing to take a pay cut for it. If you are yet another Java shop you have to compete with all other java shops. Which isn't saying that Rust is the right tool for the job in this case, but if it is, i wouldnt worry too much over the availability of good devs.
My rustup says that the latest nightly is `rustc 1.26.0-nightly (2789b067d 2018-03-06)`, there used to be a website where I could check the build status but I can't find it anymore. Is there a problem with my local rustup or it's just a temporary lack of new releases due to breakage?
All of these companies have bet at least a part of their business on Rust: https://www.rust-lang.org/en-US/friends.html Some of them are pretty large, like Dropbox. The core of their business is now in Rust. They recently went public, and one of the major reasons cited for their increased profitability was that project. (It used Go as well.)
I'm working on a detailed article on raycasters, but it's not ready. In the mean time, if you find it helpful, you could watch me [live coding a raycaster](https://www.youtube.com/watch?v=LuUb9Hrl-LQ), explaining the theory as I go along. I recently posted this video [to this sub](https://www.reddit.com/r/rust/comments/82wuxt/live_coding_a_wolfenstein_3d_type_rendering/). Good luck! :)
Awesome! Thanks for sharing. About your licensing notes, just put it under GPL. Which means no one can just copy paste t o use commercially. I guess that's what you want.
I'm just bummed about changing it all over my code. 
my case, i will wait and see. market is not so fast, it will take time to get momentum.
Why am I getting a type error in the following scenario: I've implemented a function in Crate A, which requires a type Foo from an external crate B. In crate B, I import crate A, and impl a trait on Foo, using the function from crate A. But that function now gives me a type mismatch: = note: expected type `geo::types::Point&lt;_&gt;` found type `types::Point&lt;T&gt;` I don't think the `T` is significant here, and I have no idea how to fix it.
Isn't that just a sed away?
I like if foo() { return 1; } else if bar() { return 2; } // more code if applicable, since it makes the whole `if` construct an early bail-out guard thingy.
New job allows me to work on crossbeam, so starting up that again! Working on the settings api I had tried on and off, but discovering that the rapid shift towards async and coroutine style programming doesn't play super well with stack/raii based control flow
Famous last words!
I think you'll need to show more code for this. But a wild guess: Is it possible the expected type is concrete (e.g. `Point&lt;i32&gt;`) while the given one is generic?
(My plan is to edit this comment on Saturday to change "5 days" to "1 month" and "RustFest Paris" to "RustConf Portland")
I agree :)
I wondered about that, but they're both generic: [Attempted trait impl in crate B](https://github.com/urschrei/rust-geo/blob/transform/src/algorithm/reproject.rs#L7-L26) [Function definition in crate A](https://github.com/georust/rust-proj/blob/master/src/proj.rs#L57-L82) 
Yes, I agree that's why Java does it this way and this probably makes sense for java, even if can lead to dozens of thread pools each with dozens or hundrets of threads. It just feels icky. From that perspective, having a "put all your io-bound tasks in here" default threadpool is a much nicer. That's why I like this change in tokio :)
I'm at a fairly large company (fortune 500) and I'm in charge of a project which uses rust with FFI to .net, c++, and python. It's a really good mix, and I would suggest it
I'd like to get a new version of [`generic-array`](https://github.com/fizyk20/generic-array) and [`numeric-array`](https://github.com/novacrazy/numeric-array) out this week, but the former isn't really up to me. I [recently reworked](https://github.com/fizyk20/generic-array/pull/57) how `generic-array` handles some functional-ish methods in a way where they are almost always fully optimized by the compiler, in addition to making it more flexible with generics, all while still ensuring moving elements out of the array is safe and predictable.
[resvg](https://github.com/RazrFalcon/resvg) - an SVG rendering library. And corresponding [test suite](https://razrfalcon.github.io/resvg-test-suite/svg-support-table.html).
Keep at it! As someone with a web background (Node and PHP) more Rust examples like this would be great.
I don't see anything obviously wrong with that code. And I can locally reproduce the weird error. Honestly, I think I'd consider the error message "buggy" since it doesn't seem very helpful.
Yeah, it makes no sense to me, but I wanted to get some more eyes on it before I file a bug against it â€“ it's way more likely that I made a mistake.
Unless they test themselves by regularly getting into bar fights. :)
Easy for me to say, as I'm just talking, not actually making a bet, but yes. I don't see it so much as betting on Rust, than as betting on myself. I've spent a lot of time learning and enjoying Rust over the past few years because I like the language. In the past, trusting my instincts on technology has paid off, and I therefore I would continue to stick with Rust in a business venture. That said, I wouldn't use rust for everything.
Even if, the error could be a lot more helpful. But a bug report for the error would probably be more useful if the root cause is known.
I prefer the Lisp name "condition" for this type of thing.
I'm still working on the [Monero node](https://github.com/xmr-rs/xmr) implementation. During the previous week i have been cleaning up the codebase so I can start writing the syncrhonization code.
Yes, insertion performance must be critical for this benchmark.
Two comments: 1. `ls` is not useless. :P 2. It would probably be worth mentioning [exa](https://github.com/ogham/exa)
By definition, optimizations cannot break semantics. Bugs do happen, however. If you use unsafe correctly, and invoke undefined behavior, things might *seem* like they work in debug, but then break in release. It is accurately optimizing based on semantics-preserving transformations, but you were wrong about the initial semantics! Bugs happen.
Yes, phones, argh. Thanks.
I work for my own startup, and we wrote our web page and MVP using C# as that is what we had the most experience with. But the MVP had a lot of technical debt and was slow/memory hungry. We always had a plan to move everything to C++, but Rust appeared on the scene about 18m ago and we took a chance. It's a computationally intensive, multi-core/multi-gpu simulation application. We haven't completed the migration, but each piece that has worked, has worked very well. One thing we have felt, is the reliability and error handling is a lot stronger than we had with C#. I feel that is an intrinsic property of the language. As we learnt and became more familiar with the language, we started migrating a lot of "write once" python scripts over too; which has resulted in more robust utility tasks. Where we are deficient is GUIs. That is in .NET still, but it would be nice to migrate that to native win32 one day.
Right now it's very early and not used in production yet. I'm trying to replace my current rails site which lives on a small DigitalOcean droplet.
I'm usually hesitant to use GPL but this may be a case where it's limitations are useful.
I might be wrong but I believe Yew targeted webasm. My target audience for the site (musicians) aren't usually on the cutting edge so I needed older support. (Or can one just use asm.js on older browsers? Not sure.)
Rust-fmt style is: if foo() { return 1; } else if bar() { return 2; } // more code I would make a serious argument for this: if foo() { return 1 } if bar() { return 2 } // more code And an entirely non-serious argument for *that*: foo() &amp;&amp; { return 1 } || bar() &amp;&amp; { return 2 } ; Serious argument: First, understand that a `return`, `break`, or `continue` is nearly always the last statement of a block. You can't execute anything after it, so it's only valid to declare an inner `fn` or similar. It doesn't make sense to require a semicolon. This is very similar to a block which evaluates to a result value. You can't use a final semicolon. In both of these circumstances I keep the closing brace on the last line of the block (with two exceptions). This is more like Lisp or Python and draws attention to the unusual nature of these blocks (they're expression-oriented rather than statement-oriented). Notice the similarity to an expression-oriented `if`. let a = if foo() { 1 } else if bar() { 2 } else { return Err(NeitherFooNorBar) } ; // more code using `a` The two exceptions are `match` (the closing brace *always* starts a line) and `fn` (if a branch exists within the function, I use explicit return). Non-serious argument: It looks cool and makes perfect sense in the context of `!` being the bottom type.`!` is a subtype of every possible type, including `bool`. So `foo() &amp;&amp; { return 1}` has type `bool` and in fact cannot evaluate to `true` - it's either `false` or diverges into the `return`.
Ah that's fair. That's correct - it seems initial support for WASM was added in March 2017 in Chrome, Firefox, and Edge. IE still has no support and probably won't receive any (my speculation). If you expect any of your users to use IE I wouldn't touch it. https://developer.mozilla.org/en-US/docs/WebAssembly#Browser_compatibility
It would be cool if this supported configurable output characters like the original [Cowsay](https://en.wikipedia.org/wiki/Cowsay) program.
Hey Reddit, this was originally part of a workshop but I thought it might be interesting on its own. I tried to write a beginner-friendly article, so I don't go too much into details. If you have any ideas about future articles and things you would like to read / learn more about, then I'd be very happy to give it a shot.
Depends on the use case. My company has been using Rust primarily since we started last May, and it's a consensus within the tech team that the bet has paid off
Some of this will be resolved by more crates moving to 1.0. That is, the reason that dependencies won't be unified is that 0.1 and 0.2 are different, breaking versions. Using a wildcard only helps if you don't use different APIs than your dependencies. When crates hit 1.0, then more versions will unify, as 1.1 and 1.2 are *not* breaking. The best way is to send in a PR to update your deps that require older things to newer things. Then everyone benefits.
As the other posters already implied, are you sure you dont want instead: fn p(a: i32)-&gt;i32 { // ... Do lot's of work with a a } some_value.map(p).unwrap_or(-1) This moves the "special -1 handling" to the caller site, which is much cleaner, as such special handling can be "pushed out" to the outermost layer of your function calls. This is something that really nice in rust and really hard in Java or Python to do unless you're _really_ disciplined
There are some really great answers here already, but I'll just put in 2Â¢ by saying as a (past, infrequent) contributor to the `kafka-rust` library, I would not say it is production-ready. Although `rdkafka` may be better; I haven't taken a good look at it.
Same. Rocket is still synchronous so I'm not sure if I'll get any huge gains. I think it'll utilize memory and CPU better than rails, though. If I figure out a way, I'll try to benchmark the two
There is at least one exception in C/C++ world: ffast-math But it looks like rust is working on another way to enable that so that optimizations will not break semantics! I was amused though that one of the open issues on that, the title calls it "imprecise" math, while that is maybe true in some cases the typical scenario with ffast-math will actually lead to increased accuracy...It is just that the result is different which is the danger, and why it is separate from just -O3 or anything. 
I feel like that's different than compiler optimization passes, but the distinction is pretty pedantic, honestly. So, sure :)
The Geo update landed about an hour ago, and this problem is from last night. But just to be on the safe side, I've rebased against Master (PR branch has been pushed back up), and the problem is the same. 
Thanks for the clarification.
Regular GPL will not protect you, as they can use your code and modify it without providing source, because they're not distributing binaries. Affero GPL takes care of this loophole.
Hmm, so this may be a bit more than just version number. My guess is that Rust thinks that published `geo v0.7.4`, dependency of `proj`, is different from local `geo v0.7.4`, that is being compiled.
At Faraday.io, we have a substantial (and growing) amount of key infrastructure written in Rust. We do have a few rules: 1. We won't use async Rust until `#[async]`, `impl Trait`, `futures` and `tokio` have a chance to stabilize and mature. 2. We won't use nightly-only Rust features if at all humanly possible. 3. We try to avoid `unsafe` in our own code (unless there's a ridiculously good reason). 4. We keep as much Rust code as possible in a monorepo because `cargo`'s support for private dependencies is extremely annoying. As far as client libraries go: - `diesel` is wonderful, except for the terrible compiler error messages. We especially like the fact that we can type-check SQL queries used by long-running batch jobs. - `rusoto` has extensive coverage of low-level AWS APIs, but sometimes it's missing convenient higher-level wrappers. - AMQP support is a bit sketchy but it works. - We've had to fork a Rust Docker client and maintain it ourselves. - We've submitted patches upstream to several other client libraries. - We had to write our own BigML client. Overall, it's pretty bearable if you don't mind occasionally working on client libraries for services that you use. Things we like about Rust: - Our Rust code is ridiculously reliable. We have some services that have run for years without needing to be tweaked. - Rust is fast by default. - The `cargo` ecosystem is excellent. It's easy to use third-party libraries, and there are high-quality libraries for many tasks. - Rust is wonderful for CLI tools, especially if you statically link it against musl-libc. - Rust has a very good backwards-compatibility story for source code. We don't need to migrate or update things just to make a 10-line change. - Once Rust code compiles, there's a maybe an 85% chance that it will work correctly on the first try. From a people perspective, Rust is somewhat less accessible to other people within the company than Node.js or Ruby. So _major_ Rust work tends to go through fewer people. And we're not a 100% Rust shop, so if something is obviously a terrible match for Rust, we have alternatives. But overall, we're very happy with our Rust code.
It's using my [ferris-says](https://github.com/mgattozzi/ferris-says) code underneath it that I had made as an example repo for Rustconf last year. I'm open to PRs to extend it's functionality, but I won't be actively working on it otherwise.
elm + rust, top notch combo! 
One time I was refactoring and I hit [Higher Ranked Trait Bounds](https://doc.rust-lang.org/beta/nomicon/hrtb.html) after adding a couple of `'a` on some things and I knew I either was trying something I shouldn't, messed up real bad, or just needed a better design. Luckily it was just the last one and I had no problems.
RLS stopped working for me since end of January. It's project related as it's broken on cobalt.rs project, but it's working on a fresh simple project.
During compilation, Cargo downloads the `geo` from crates.io to compile `proj`, to compile local `geo`. The `geo` that was just downloaded is... different from the `geo` you're trying to compile. Not sure how this 'difference' exactly this works. Maybe it's path on the machine, maybe it's some sort of hash of code, I don't know. Anyways, the two crates have different code, so it isn't quite wrong to consider them different crates in this context. Now, from Rust's point of view, the two `Point` types are as different as `std::net::TcpStream` and `tokio::net::TcpStream`, since, well, they're from different crates. Try to use `std::net::TcpStream` where `tokio::net::TcpStream` is expected, you'll get a type mismatch.
I'm working on [**Vigilant Steel**](https://gitlab.com/remram44/vigilant-steel), a space game using [piston](http://www.piston.rs/) and [specs](https://slide-rs.github.io/specs/) (yes I used the GitHub name generator for that) ([in-browser version](http://remram44.gitlab.io/vigilant-steel/) thanks to Emscripten; WASD/space). I have been working on it for a few months, and I'm actually getting ready to announce it on /r/rust_gamedev. It's at the point where all the physics/collisions/modular ships work, and I can start developing the gameplay and have fun with it. I'm thinking of making it as rogue-like as possible, like FTL, fighting your way through systems while collecting fuels and new modules for your ship. Except I already have some working multiplayer code, so I could make it into an FFA or building game. I could really use feedback (and some help with Emscripten, can get the thing to resize correctly, or the mouse to work with it), but expect a dedicated thread soon.
&gt; Why does the FTP make the typesystem worse? Consider this piece of plausible code: import Data.List (lookup) main :: IO () main = do -- Some two-tuples of integers. let tuples = [(4,3),(6,5),(5,6),(8,7)] -- Given a two-tuple (a, b), return (a + b, (a, b)). -- This sum can be thought of as the "key" of the tuple. let keySum t = (sum t, t) -- Number of tuples with the given key. Data.List.lookup -- returns the list of RHSs of tuples whose LHS matches -- key. let hasKey k = length $ lookup k $ map keySum tuples -- Some test cases. print $ (1, hasKey 7) print $ (0, hasKey 0) print $ (2, hasKey 11) What did you expect it to output? What did it actually output? How long did it take you to find the bug? Is it plausible that someone would write this? Here are more [examples](https://gist.github.com/BartMassey/2bc2da01f077d5af179679a02f58af5a). &gt; `ghc -prof` and `+RTS -p` can help a lot, though. If you can figure out what the profile is actually telling you, you are better than I usually am. &lt;http://dilbert.com/strip/1992-08-03&gt; 
And there's similar traits for slices as well.
Why does `Iterator.all ()` return `true` on empty iterator? It looks completely unexpected. Is there a workaround for this?
Having never touched a line of Rust, I enjoyed the introductory tone of this article. Was the choice to use pattern matching in the `triplet` function solely for demonstration? It does not strike me as the go-to solution.
Last night I got my proof of concept live streaming server server almost working, written purely with my RTMP library (https://github.com/KallDrexx/rust-media-libs). I just have to figure out why VLC is stuttering on playback (I'm pretty sure I had the exact same issue when I implemented it in Elixir so I need to go back and remember what I had to change) and fix an adobe flash handshaking bug, and I'll finally have something to show for the last few months of working on this in my free time.
Implementation wise it's more simple to return true on empty iterator, it's essentially implemented like this (with some abstractions through try_fold): fn all&lt;T: IntoIterator&lt;Item = bool&gt;&gt;(iter: T) -&gt; bool { for el in iter { if !el { return false; } } return true; } As for how to work around it, something like this? fn all&lt;T: IntoIterator&lt;Item = bool&gt;&gt;(iter: T) -&gt; bool { let mut state = false; for el in iter { if el { state = true; } else { return false; } } return state; } 
More than happy to merge things in and do some minor releases. Clippy requested it to print out Clippy for there suggestions as a kind of hidden feature though I don't know the status of it.
Unless you really need memory safety and can't use Go, I don't see why you would use Rust for a production web project. There are some good looking frameworks, but Go is essentially made for backend web stuff. C#, Java, and Node are way more mature than rust, and (in my opinion) you'll write faster with python. I love rust, and I use it every day, but there's not a chance I would use it for a web project with my job on the line. All that being said, it could definitely be done.
Not exactly. Traits are obviously more powerful (they can have multiple possible return types for the same function input, for example), but they miss some ergonomic features. For example, function overloading rules in c++ are explicitly not as powerful as traits so that each expression has an inferred type; there's not (as much) of a need for a unification algorithm for type inference, and you are much less likely to run into problems like `Print( Parse( x ))` being ambiguous. In addition overloaded functions can take different numbers of parameters, which of course can be emulated by a single tuple argument but again there is ergonomic cost. Finally, unconstrained generics combine with overloading to create a new language feature; consider this c++ code: obj.Observe( overloaded { [&amp;](int x) { sum += x; } [&amp;](float x) { sum += floor(x); } [](...) {} } ); In Rust you would probably make Observe pass an enum to a single visitor function but here the dispatch is done immediately inside Observe without necessarily needing to inline the visitors to avoid branching on the enum discriminator.
You may have noticed a subtle change: what was previously called â€œepochsâ€ is now â€œeditions.â€ Lots of great stuff coming this year! As always, happy to answer any questions.
It makes sense to me. If all the items satisfy the property and you remove one, it's still true that all the remaining items do. Therefore, it should still be true if you remove the last one. Similarly, `any` returns false for an empty iterator. 
Yeah, why not. Initially, I wanted to make a pull request on your project but I finally decided to make my own crate for learning purpose. How would you like to proceed?
I would consider making business bets on Rust in several areas. Any solution where C/C++ is an alternative should be a prime candidate for Rust. I would also consider Rust for a very latency-sensitive backend, such as a low-latency stock exchange, or computations where you benefit from utilizing 100s of GBs of heap in a single process, but there are far more productive and mature solutions in garbage-collected languages for general web backends and data pipelines.
There's a single thing in `serde` I don't like: serialization returns `Result` even in cases when it can't fail (e.g. writing to `Vec`). I consider it understandable provided what `serde` is capable of.
With "editions", is the intent that language/library breaking changes can be made without stalling adoption of newer Rust versions?
I think you'll find a lot of very motivated developers who want to work with Rust if you go that route. That's people who like learning new languages, people who stay on top of new developments, people who code in their spare time, etc. This isn't a benefit that's unique to Rust, but I found more rough edges in the Haskell ecosystem than Rust. Like, Cabal just didn't want to work. I'm sure it's better now, but I'm pleased with the care that goes into Cargo and Rustup.
For me, it was how easy it was to cross-compile a static executable targetting musl. When I tried to run other things written in C on the VM, the VM didn't have the correct version of glibc installed. I REALLY don't know how to work with Makefiles or how to cross-compile with GCC or Clang
Looks promising The best of this roadmap is its conciseness and clarity. Less frightening but still full of information.
Try reading it like this: "is condition X true for every element?" This is true for empty sets. In a more formal way it means that `all(x)` is equal to `!any(!x)`. This equivalence isn't easy to state if `all(x)` is false.
So, editions can only do two things: * add keywords * turn lints from warn to deny So that's *some* kinds of breakage, but not all. And yes, to some degree that's true. You can adopt a newer compiler version without being forced to also update the "language version", in a sense.
&gt; Never bet "your business" on a technology choice. This is impossible. You are always building your core in something and as such you are betting your business on it.
&gt; Was the choice to use pattern matching in the triplet function solely for demonstration? It does not strike me as the go-to solution. It's reads pretty nice, there's a symmetry between the patterns and the strings. And if-else construction would likely look more spaghetti-like. In comparison to building up the string from three parts, with `format!()` or similar, it would also avoid allocation if the return type were `&amp;'static str`.
Rust futures basically already provide this, with a bit of extra indirection for flexibility, via the task notification system. A little background: Rust `Future`s are a more general trait than `Generator` that applies to both hand-written and compiler-generated asynchronous programs. The exact mechanism is still up in the air, but it's likely that you will interact with `Generator`s via the `Future` trait. In this system, `Future::poll` corresponds to Kotlin's `Continuation.resume`. The specifics here are going through some changes, but basically the implementation of `poll` is responsible for obtaining a handle for resuming the current task (`Task` in `futures` 0.1, `Waker`in 0.2) and handing it off to something that will poke it when the the future (and thus generator) should be resumed. This is a fancier version of `suspendCoroutine { cont -&gt; ... eventually ... cont.resume() ... }`. The reason `poll` doesn't just *directly* get a reference to the `Future`/`Generator` like `suspendCoroutine` does (other than complications with ownership) is so that whoever pokes the `Waker` doesn't have to actually execute the `Future`/`Generator` directly. Unlike the examples in your blog post, which all execute the coroutine themselves somehow, the `Waker` approach decouples the event sources (e.g. `glib_sleep`, `asyncio`'s event loop) from the "executor," which can then schedule its `Future`s however it likes. As far as I know, the current prototype of async/await in Rust, `futures-await`, does not provide async functions with access to their `Waker`. However, I'm not sure this is actually all that important- generally the APIs that interact directly with `Waker`s can be written more straightforwardly as raw `Future` implementations, and then async functions can just `await!` them. (Incidentally the reason I made that Kotlin comparison thread was mostly because I like their syntax, with no `await` keyword at all, just `suspend fun`s.) Hopefully that makes sense?
This guy did okay: [NSFW] https://www.youtube.com/watch?v=yjRL68yoLh8 
Maybe something like `.map_service(impl Service)`? It could also support `NewService` (not sure if those interfaces are deprecated now, so adjust accordingly)
Neat! Glad to see more resources popping up!
I haven't purchased it yet, but plan to!
I am following along with u/munificent 's [Crafting Interpreters](http://craftinginterpreters.com/contents.html) book and plan on implementing his byte code virtual machine section in Rust as he releases chapters as a learning exercise. I have the 1st chapter complete. It is pretty close to his version although I just use a vec where he implements a growable array from scratch.
&gt; You can use old editions indefinitely on new compilers I still have a flicker of hope that it is some sly marketing statement.
Ha :) I don't think I would be willing to buy a not-quite-halfway draft either, but an impressive number have. I think sales are at 1,200 or so.
With that issue - it is definitely something `serde` is not designed for. Typed, empty sequences could possibly be serialized by overriding `collect_seq` present in the current version, but it would also need to handle some untyped sequences unfortunately. It is fairly opinionated as to what formats need to support, but I don't think that necessarily means it's hard to implement _any_ new format. I guess I'm pretty impressed it's possible to extend it at all, even if it's choices make certain formats impossible to represent.
I'm currently building a bunch of software in rust that I'd like to productionalize for my own business. This is a large distributed system. The primary reason I feel 'safe' doing this is that I'm building the software in such a way that it shouldn't matter. With a microservice approach language matters a lot less. For example, * I use an RPC library (capnproto) that supports Python and C++, and other languages have bindings. So clients of my services can be written in any of those so long as I take the time to write the wrapper libs for those langs (not hard). * I abstract away databases with services. Now we're back to no longer needing to care about the language - I could write that service in Python, but have rust clients. At any given point I should be able to rewrite a service in a supported language without trouble, so I don't worry too much about Rust being the wrong tool. That said, I've ended up rewriting every Python component in Rust at this point. The point is, if you take the right approach choosing a language is not nearly as scary. Carefully consider your requirements, ask yourself what the work involved will be with Rust, and go from there.
&gt; On the other hand, I'm not very comfortable with anyone who claims that Perl is more likely to yield bug-free programs that Python. :-) I might have been a bit unclear there. It might be the other way around for you with Perl vs. Python. With these languages I only claim that my Perl code is usually much better quality than my Python code, for the reasons I described. I don't really recommend you or anybody to learn Perl â€’ not without further explanation, at least. I believe learning Rust will get the benefits of better code more reliably. Same as I wouldn't recommend anybody to learn how to fight by pub brawling. Rust performance is a good thing too, but doesn't help you *learn* too much.
it's there in the post, in the last paragraph
Are you talking about martial *arts* or martial *sports*? The first teaches self-defence, the second how to score points ðŸ˜‡
Will breaking changes only be introduced in edition releases or will they also be released in regular 6-weekly releases?
&gt; Network services. Rustâ€™s reliability and low footprint make it an excellent match for network services and infrastructure, especially at high scale. One thing I want to note for this - Rust has a not-great RPC story. If you're choosing rust you probably want high performance and type safety - RPC is probably the option you want for that over JSON + HTTP. The grpc lib didn't look too well supported last I checked, and capnp has a serious documentation problem (that I intend to help with when I get some more time). Anyways, I'm super excited for 2018. The language changes I've been playing with on nightly (NLL, impl trait, etc) have been wonderful.
I like this! one comment: does let hash = log["key"].as_str().unwrap().to_string(); need the `.to_string()`? I have it compiling without it.
Do you know which new keywords are currently being planned?
It's probably a bit late to bring this up. However, I still don't really get why these editions/epochs were chosen instead of bumping the major version of the language, while saying that each compiler can compile all major versions below it as well. Right now we have a X.Y.Z version where the X will always be 1 and some separate version number related to the release date. This just seems like a very convoluted way of never bumping the major version number. With the only goal (seemingly) being that it shows off that Rust never breaks backwards compatibility.
Please add to [this thread](https://internals.rust-lang.org/t/compiler-diagnostics-improvement-wishlist/6886)! 
We're using Rust and gRPC in Conduit! There is a tower-grpc crate that we support as time permits.
Nice to see a fellow Rust OSDever! :) Interesting to see you going the virtualized OS route. The fact that you seem to be using an existing bytecode and JIT will probably make things a bit easier, but at the same time, it may not have all the instructions you want.
There are really two concerns here; the language, and the compiler. The compiler comes out with a new release every 6 weeks. Each release contains only backwards compatible changes (with the usual caveats about unsoundness issues and possible type inference changes). Even with this change, the compiler will still be backwards compatible with all existing products, because new editions are opt-in. On the other hand, this gives a way of introducing small breaking changes at the language level, like adding new keywords and removing deprecated features. But because the compiler is still compatible with the old code, and the new edition is opt in, the compiler itself is still within the semver 1.x series. Since language level breaking changes are a relatively big deal, you don't want to introduce them on a regular basis along with the normal 6 week compiler releases. Instead, you want to be able to discuss them all at once. So they will happen in batches, no more often than once per year and probably closer to once every 3-5 years. So if you like, you can see editions as different semver numbers for the language; but to distinguish the (breaking) language changes which happen relatively infrequently from the compiler changes which happen once every six weeks, they use an entirely different versioning mechanism based on the year.
I notice that of all the "working groups", the Network Services doesn't have a link describing more. Is this something I should pay attention to?
I agree with this sentiment. I want to say, "it worked for Jet.com", but the jury is probably still out on that, and the blog link on why they chose F# is 404ing at the moment :) In terms of hiring, as with F#, there is a lot of pent-up demand for Rust jobs, and thus there are probably a lot of good candidates in community who would switch jobs to get a chance to work with Rust. 
Is there any plan to eventually deprecate old macros with new editions?
Release can behave quite differently with regards to timings of events because debug in rust is very slow. Echoing the advice to test in debug and release.
The network services WG hasn't gotten kicked off yet because Taylor and I don't have time to do that until after futures 0.2 has shipped. :)
Would it be a bad idea to bump the compiler version to 2.0 when a new edition is released then? Or not? Because I can already foresee that I'll never remember something like "oh, the compiler supports Rust 2018 edition since 1.3x". 
If I understand you correctly you mean that increasing the major version of Rust, wouldn't be correct in the semver sense because the breaking changes are opt-in. What I mean though, is if Rust is never ever going to break non opt-in backwards compatibility (which I think it shouldn't), why is it's version number using semver. That just seems utterly useless. It's not strange to not use semver versioning for things. The Linux kernel also doesn't break compatibility, but increases the major version number for big changes. Another option would be to just drop the 1. prefix and call the current release Rust 24.1, which would allow for the editions/epochs without having some useless clutter in the version number.
Only edition releases, as far as I know. If your code compiles on stable, it has to keep compiling on stable.
In what circumstance would you need to remember such a thing? AFAIU, if you're using a toolchain that supports "Rust 2018", then it will automatically insert the line turning on the new edition when you make a new project via `cargo new`. This pushes the ecosystem forward slowly and automatically without requiring any prior project to experience any pain.
Why do we need editions, why compiler versions wouldn't be enough? Instead of `edition = "2018"` developers could simply write `rust = "1.20"`. That statement would not just specify an edition, but could also check that I don't use API from newer stdlib, and don't use newer but backward compatible language features (like NLL) from newer compiler.
I'm not quite sure what you mean by the ir might not have all the instructions I want. I'm not writing the os in wasm, just the "usermode."
Only if the defaults were changed.
If you can convert the schema to the [OpenAPI](https://swagger.io/specification/) format, you can use [swagger-codegen](https://github.com/swagger-api/swagger-codegen) to generate various things: * A type-safe API trait that represents the protocol in Rust objects * A hyper server wrapper (you need to provide the server business logic) * A hyper client for the protocol You'll probably want to use the `rust-server` generator, as it has various advantages over the older `rust` generator (including async support through Tokio and Futures). Disclosure, the company I work for implemented the `rust-server` code-generator. As a case-study, we use it heavily in production and it's holding up really well - having the compile fail if you try to use the API wrong is a godsend.
It might sound strange at first, but with explicit continuations, it is a _feature_ that you don't need a scheduler to drive or wake up the async function. The bottom-most async function, the one that actually suspends, ensures its resumption by registering a normal (not async) callback with whatever system it is executing in. Continuation-based design is not better than async/await, but it is: * equally powerful - obviously so, since one can be implemented in terms of the other, and vice versa; * a potentially very useful tool when writing callbacks for embedded or foreign environments (think callbacks from C) that do not and cannot have a Rust event loop at the core. &gt; However, I'm not sure [being able to access the `Waker`] is actually all that important- generally the APIs that interact directly with `Waker`s can be written more straightforwardly as raw `Future` implementations, and then async functions can just `await!` them. And that's how the sample code works, with the additional idea of providing _one_ awaitable primitive for all such interactions. This ensures that you don't need to write a different raw future for each different kind of suspension. It also hides the details of the `Waker` from the async function, encapsulating resumption into an abstract continuation object. From the vantage point of an `[async]` function, nothing changes, you still use `await!` to await other async code. It's just that you have the option of also using `suspend()` (itself something you `await!`) to easily connect invocation of an external callback to resumption of the async function and its callers. The proof-of-concept implementation does so without using global (or thread-local) state, but other approaches could be used without changing the overall design.
I think people will still informally disambiguate "edition" with "epoch edition." The thing is though, "epoch editions" are still "editions." It's like an accented beat in a measure. It's still a beat, just a standout one. So Edition="1.24" and Edition="2018" are both edition, just one is an accented one.
I'd actually assume you're talking about the book if you phrased it that way :) "What edition of Rust are you using?" definitely would refer to an answer like "2018". "What version of Rust are you using?" becomes more ambiguous, because we really mean the Rust compiler (1.24) or the language ("2018"). But maybe it's better we start thinking of the Rust compiler version as being distinct?
So the breakage is opt in?
At risk of sounding reductive, all these questions really are answered [in the original epoch thread](https://github.com/rust-lang/rfcs/pull/2052). In this case, Rust crates should not *have* to upgrade editions (i.e. add breaking changes) just to use a newer version of the compiler. When you say `rust = "1.20"`, does that mean the crate has to break keyword compat or remove deprecated code just to add features or load crates from newer Rust versions? It's a balance. I think editions leans that balance in favor of a highly compatible crate ecosystem.
Is it really necessary to make the analogy so complicated? Rust's `Future` is not analogous to Kotlin's continuations - but `Generator` is. A `Generator` can be used to build a `Future`, and I don't know Kotlin but I would be surprised if there aren't some libraries that build futures on top of continuations, and a reactor for scheduling them.
I guess with WASM, any function you need are supposed to be passed in with Javascript, so my concern is invalid. I take it you won't be using Javascript and instead will be passing in the builtin functions directly through cretonne.
Yep! No javascript here! All rust and wasm!
&gt; * a potentially very useful tool when writing callbacks for embedded or foreign environments (think callbacks from C) that do not and cannot have a Rust event loop at the core. This shouldn't actually be an issue; an executor doesn't have to be a full event loop, or schedule multiple tasks, or sit at the core of anything. It could easily be just that callback from C. The benefit of `Waker` is that it allows `Future`s to run on *any* executor, not just the one hard-coded into whatever they `await!`. &gt; It's just that you have the option of also using `suspend()` (itself something you `await!`) to easily connect invocation of an external callback to resumption of the async function and its callers. You could of course add this to `futures-await`; all I said was that the prototype does not do so. It would just provide you with a `Waker` to poke in the callback (or however else) rather than a direct reference to the future. &gt; The proof-of-concept implementation does so without using global (or thread-local) state, but other approaches could be used without changing the overall design. I'm not sure how this is relevant. `futures` doesn't use global or thread-local state either.
`Future` *absolutely* is analogous to Kotlin's `Continuation`, and that's the simpler place to make the comparison. Talking directly about `Generator` leaves out the equivalent of `suspendCoroutine`.
How about this? fn single(mode: u32, bit: u32, out: char) -&gt; char { match mode &amp; bit { 0 =&gt; '-', _ =&gt; out, } } fn triplet(mode: u32, read: u32, write: u32, execute: u32) -&gt; String { [ single(mode, read, 'r'), single(mode, write, 'w'), single(mode, execute, 'x'), ].into_iter().collect() }
Yup! Basically, thereâ€™s a key in Cargo.toml you can set. New projects will default to the latest. If thereâ€™s no key, 2015 is the default. It passes that to rustc, which has a flag, same deal.
Itâ€™s not useless. It communicates that there arenâ€™t breaking changes.
Hm? Why?
Thatâ€™d be a nightmare to maintain. Every compiler would have to remember the exact semantics of every six week release.
I'm very excited for the new edition of the rust programming language. 
If you end up wanting to do a lot of stuff to expand it's functionality send in prs and I'll merge them for now!
It could drop support for old editions in later compilers. I don't think it's planned, but it could turn out that there are some things that are deprecated, and removed in the 2018 epoch or later, which are too much trouble to maintain, and if there is no significant live usage of such features in the wild, it might be considered worth it to just drop support. Alternatively, the the developers could instead not to decide to drop support for earlier editions, but to make a later edition the default, which would be a breaking change although with an easy migration path of adding the appropriate edition to any broken projects. Though I doubt this will happen as it's easier to just add the new default to Cargo for new projects, rather than changing the semantics of projects that haven't opted in to a newer edition. There are also other possibilities for what to do with the compiler version number. For instance, it's possible that some features could get stabilized, but not with as long-term a commitment as the edition system. A few I can think of would be lang items for `#[no_std]` (which would be nice to be able to use outside of a nightly build with no stability guarantee, but are fairly intimately tied to the compiler and so may need to change or differ for different compilers), or possibly a more stable compiler plugin system that doesn't require things like Clippy, rustfmt, or rls to be developed against specific nightly compiler builds and integrated in the compiler release process. I could see this being done by having some of these features stabilized as part of the compiler interface, but not as part of the language Rust (which is covered by the editions system). However, if they need to change, the compiler would be free to release a version 2.0 with breaking changes to these interfaces. It would allow you to use these interfaces with release builds, and the compiler would need to commit to at least a reasonable amount of stability, but they wouldn't be committed to forever and need to be implemented exactly as is in other Rust compilers. Anyhow, all this is to say that I think the issue of whether the `1.x` version numbers is still useful is orthogonal to the introduction of the editions system. The editions system allows the language to grow in slightly backwards incompatible ways while still maintaining ecosystem compatibility, which is important for avoiding some of the issues seen with some languages which just stagnate completely or have to start adding all new features prefixed with `_` because that was reserved in earlier versions of the standard, or with big ecosystem-breaking backwards incompatible changes like Python 2 to Python 3 that take years to migrate past (there's still a ton of Python 2 code running out there a decade after the initial Python 3 release). What to do about the release numbers of the compiler and standard library is a separate question, and is probably better to address later once the dust has settled from the introduction of editions.
Conditional spaghetti was not on my mind either! /u/zokier's snippet is close. 
Thanks, that looks really interesting and I'll definitely keep a note of it. The swagger-codegen and the rust-server example you pointed out might be helpful as a approach to code generation. Unfortunately, I don't think a RESTful API is the right way to model my unusual API, and so OpenAPI is probably a no go. The API I'm dealing with is highly stateful and involves creating, destroying, and modifying objects that represent tables, expressions, variables, lists, and a data model that exist on a session by session basis while interacting with a proprietary server. All interactions take place via websockets with an JSON RPC API.
My own? Yes. Someone else's? No. I love Rust, I think it's made huge strides to being production ready and I'm always excited to see where it goes next. It's a pleasure to develop in and very powerful at the same time-- I couldn't ask for anything more! However, while I feel that way... not every does nor are they willing to invest the time to learn the language. Creating something in a language that so few people understand, let alone can be considered an expert in, is a pretty risky move. Add onto this the fact that even though the crate ecosystem is large, it pales into comparison compared to Maven and NPM, so it's a bit more effort to reach the equivalent end goal. I'm all for making bets with my own wallet, but I'm not going to give any gambling advice to my friends let alone reach into their wallet and play for them.
Because it leads to stagnation? I take backward compatibility as the root of all evil. It is a real horror. Today we have a shiny new language. After 10 years we'll get another C++?
Would you like to merge the macro directly into ferris_says?
&gt;* add keywords Is it expected to add new keywords in 2018 edition? I guess that this is a good opportunity to add as a regular keyword what is now a contextual keyword.
There's no `IntoIterator` implementation for arrays yet (needs const generics). So instead you're getting an auto-deref to a slice, then `IntoIterator` on that, which yields references -- your `Item` will be `&amp;String` in this case.
don't do code metrics by it though. As in, don't show it to your boss. It suddenly will become. "How many lines of code did we write this month!?!?", unless you have a good culture at your company. 
ah that makes sense. changing to vec![] fixed it, thanks!
&gt; Rust performance is a good thing too, but doesn't help you learn too much. I don't entirely agree. Because Rust performance problems are usually easy to understand, the language has helped me to learn to analyze and correct performance issues. Some of this is transferable to other languages and environments.
Integer arithmetic will panic on overflow in debug mode, but will silently wrap as 2's complement in release mode, unless you change `-Coverflow-checks`. So if production encounters an overflow that wasn't covered by your debug test cases, you may get strange results.
Ha, no need to convince me. I write F# code every day at work! It's almost definitely what we'll be using if we decide Rust isn't right for us. In addition to what I mentioned in the initial post, I'm interested in some of the benefits Rust might bring around performance (although, probably would be within the same order of magnitude) and just... Lack of hair pulling? I really love F#, but would love it even more if all the libraries and tooling treated the language as a first class citizen. To get a little more specific, I'm thinking about things like .NET Core support (no FSI, type providers sorta working), web as a first class target (Fable is amazing, but a transpiler will always be a leaky hack relative to proper wasm support. Might be coming with Blazor but who knows), and VS just... Not fully working for F#. Ionide is great, and a freaking Herculean effort on behalf of the dev that heads it up, but on larger code bases I have stability issues. Then there's the whole release cycle thing (there basically isn't one), the regressions (there is heavy use of User Driven Development :) )...I could go on. Not to mention all the headaches that are de rigueur for .NET (MSBuild wrangling, binding redirects, and all that good stuff). Admittedly the past few years have seen a lot of churn in the .NET community as .NET Core adoption continues... But I just feel like I'd like to use a language that is a little more stable, where the community has converged on a tooling effort, and where I don't have to assume that something has DEFINITELY broken whenever I take an update. Don't get me wrong, I LOVE F# and think it's an amazingly productive language. But I do wonder... Could it be even better? Who knows, maybe this is just a case of "the grass is always greener." 
Sorry, I think you mean /r/playrust But not a bad idea
NOooo now I have to reply all that 
Thanks for the kind words. :-)
&gt; [an executor] could easily be just that callback from C, calling poll itself, like your examples. Ok, then you need an executor with a method that invokes `poll`, and a way for the async function to acquire it. That sounds exactly like the kind of code I am describing. Maybe what you're saying that it's completely trivial to write it, but that's not actually obvious to me. &gt; The benefit of Waker is that it allows Futures to run on any executor, not just the one hard-coded into whatever they await!. Having an explicit executor sounds like the kind of indirection provided with what Kotlin calls continuation interceptor. I didn't include one in the prototype because I was mostly interested in "unconfined" continuations, but it would be easy to add it. &gt; `futures` doesn't use global or thread-local state either. How does a raw future get access to its `Waker`?
That's a bit over my head, but I will add this nifty trick to the post when I find some time. Will mention you in the post. Thanks!
It's also quite possible that some of this will go away with good enough LTO. If you're pulling in two versions of a crate, but a bunch of the code hasn't changed between them, LTO might fold a bunch of it together. Of course it'll never be perfect, but it could help somewhat with the binary size.
Your article is very high quality. Informative and straight to the point, thanks for sharing!
Honestly, I think std = "1.24" is something that is easily achievable and may be necessary eventually, as 1.25 might already break everyone's code that used Itertools::flatten (or at least 1.26 will, idk if it made it into 1.25). And that's quite some large breakage imo. So saying your crate safely compiles against 1.24's std would completely get rid of problems like these.
We just need a book every time a Rust edition comes out :D So instead of the second edition of the book, it's the book for the 2018 edition
`catch` is the big one, but yeah.
&gt; I don't think it's planned, It's not. &gt; which are too much trouble to maintain, The design of editions is to make maintenance not a burden, for both humans and compilers.
Yes, that's a big part of editions.
Rust is not the end of programming languages. Someday, there will be a new language to overtake Rust. That's 100% fine and just the way things go.
&gt; [The Waker is] passed in as a parameter, almost as if the entire body of poll were inside of `suspendCoroutine`: https://docs.rs/futures/0.2.0-alpha/futures/prelude/trait.Future.html#tymethod.poll So when an `[async]` awaits the raw `Future`, it passes the `Context` it received? This _does_ sound like how Kotlin works behind the scenes. The difference is that Kotlin passes an internal continuation that can resume executing from that point (and returns up the stack by _calling_ what was preciously its caller). More importantly, it has the `suspendCoroutine` primitive that makes the continuation (or a facade to it) visible. Is there a public interface for retrieving the `Context` inside an `[async]` function?
I'm not sure what difference you're pointing out here. Kotlin passes an internal continuation that may be an interceptor; Rust passes an internal `Waker`. Both suspend by returning a particular value. Both resume at the point they left off. And like I said before, `futures-await` could easily include a `suspendCoroutine`-like way to expose the `Waker` of an async function.
The compiler team should get right on this! C++ has nuttin' on Rust now BOYZ!
The linked docs say: &gt; A suspended coroutine can be stored and passed around as an object that keeps its suspended state and locals. The type of such objects is `Continuation`, and the overall code transformation described here corresponds to the classical Continuation-passing style. Consequently, suspending functions take an extra parameter of type `Continuation` under the hood. Doesn't that mean that `Continuation` is the name of Kotlin's type (or parent type) for coroutines, just like `Generator` is the trait for Rust's coroutines?
Sure. Kotlin doesn't have the split between `Future` and `Generator` that Rust (currently?) does, though, so it's not that simple. The context of this thread necessitates some discussion of `Future` as well.
&gt; I have the 1st chapter complete. I write slow, but all of the code is done. If you'd like to get ahead of the written chapters, the full bytecode interpreter is here: https://github.com/munificent/craftinginterpreters/tree/master/c Thank you for reading!
Great little article, and a great showcase for Rust's elegance.
ahh ok, thanks!
But if you upgrade your crate to a new Rust edition, your code isn't affected at all by any language features that have been removed. That there are still bits in the compiler that support those old features doesn't really affect your current-edition code, does it? So it hopefully shouldn't lead to language stagnation. That's how I'm interpreting this post anyway.
No Iâ€™m saying like if they crashed it off a cliff And into trees a lot 
There was a thread like this a couple weeks ago: https://www.reddit.com/r/rust/comments/7zexrs/programming_language_written_in_rust/
Still wouldn't explode. Hollywood takes a great deal of artistic license.
No problem, it took me a bit to find it again myself. :)
I would see that as problematic for the same reason num traits are problematic: you have to pick a specific API that will no doubt fail to cover the cases many people care about, and there's no clear reason to pick one or the other. For instance, what do you get if you union disjoint sets? `None`? `Result::Err`? `(set1, set2)`? `impl Iterator&lt;Item=Set&gt;`? And how do you justify your choice?
You mean when they face people who trained in better martial arts than they.
I poked a little and it seems like Kotlin has, in a library, something called [`Deferred`](https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines.experimental/-deferred/index.html) which seems to implement the concept of a future...
&gt; Our Rust code is ridiculously reliable. This. No matter the developer experience, the code written in rust is significantly more reliable. In any business size this is very important but probably even more for startups where you can't afford to lose time in support and you're reasonably confident your new joiner won't suddenly break everything unintentionally.
I imagine you're correct, but there are degrees: not being able to accept more connections is almost inevitable (I suppose it could drop connections in keepalive state to go under the limit though). A busy loop is unfortunate. Panicking is worse. It was panicking. Better to not do that anymore.
Hey man, I wasnt trying to help the discussion, I told you exactly what I was replying to, it wasnt some random attack on your person. You took it so personally and felt like 'explaining'. Your explanation was seen by me as just as rude as me saying that you were acting like an asshole. You think you were being diplomatic and explanatory, but it really seemed rude when you said it. You called me a child! Id rather be called an asshole than a child, its just diminutive. 
For how long will compilers be backwards compatible? For example, will `rustc` in 2025 support Rust of 2017 edition?
[removed]
Well itâ€™s a game doesnâ€™t have to be realistic as long as itâ€™s fun 
That is unfortunately not true, as rustc will typecheck and coherence-check the code before handing the result to a linker.
It's hard to make guarantees going terribly far forward, as things can change, different people can take over, or some emergency unsoundness apocalypse could happen that could render everything unsound without some kind of backwards incompatible upgrade. However, yes, the intent is that the rustc in 2025 will still support `edition = "2015"` (that's what current code is assumed to be; there have been no changes requiring a new edition since 1.0 was released in 2015), and `edition = "2018"`, in `rustc` in 2025.
I'd do a `.map(|b| !b).any()`
&gt; root of all evil I think this is a bit overstated. As a professional programmer, I take backwards compatibility quite seriously. I can't afford to rewrite my project every time someone has a bright new idea about how we should be doing things. I need to maintain projects written 10 years ago by someone I've never even met. Python 3 is useless to me for most of the code that I write (I can write occasional small independent programs in Python 3, but nothing that needs to interoperate with my main codebase), 10 years after it was released, because I still have dependencies that are in Python 2 (most have been ported, but some are still missing a lot of features in Python 3), and even once that's fixed, I have to port everything in the codebase I maintain over to Python 3. There is plenty of room for Rust to grow backwards compatibly. I hope it keeps doing so, so I can be confident that anything I build on top of it will continue to be maintainable and interoperate with the ecosystem years down the line, without large boil-the-ocean porting processes in between.
Avoiding stagnation matters, but stability matters, too. The approach Rust is taking actually strikes a really sweet compromise. If you opt into a newer _edition_, then you can't mix in any "old style" code in the same crate. And you don't need to care what _edition_ other crates are using. So the backward-compatibility story in Rust really doesn't look like C++ at all. If you have some specific scenario you're worried about, feel free to provide some details and we can examine whether it's likely to be a problem in practice.
* https://github.com/gluon-lang/gluon * https://github.com/PistonDevelopers/dyon 
I'm currently working on [Pikelet](https://github.com/brendanzab/pikelet), a type checker for a simple dependent type system. Still a WIP though! I kind of play down the goals in the README, but more and more I'm thinking I'd like to push it further. Come chat on [Gitter](https://gitter.im/pikelet-lang/Lobby) if you like!
sometimes I thought April fool came too soon. because you know.. window 95, 98 and so on.. :D
[removed]
`rustup`'s been updated to *not* update to a newer nightly if it doesn't have all the tools installed. Given the [status page](https://rust-lang-nursery.github.io/rust-toolstate/) /u/steveklabnik1 linked, if you have the `rls-preview` component installed, it won't update past the 6th.
https://github.com/google/tarpc
This is a solid write up. I've been trying to catch up with the embedded-wg and this started to clear up a lot of things. I hope to get up to speed soon so I can start contributing myself. 
The features in an edition are not going to come out in a single release of the compiler. They will be delivered continuously. This is analogous to javascript (er..ecmascript) editions, where browsers are constantly implementing features from a set of featured defined in an edition. Also, the browsers are always backwards-compatible.
&gt; I'm not sure what difference you're pointing out here. The difference is in the implementation, not at the conceptual level. If you have a deeply nested stack of suspend invocations, Kotlin's resume will return directly to the execution of the bottom-most `suspend` function. async/await, on the other hand, `resume`s the top-most generator, whose `await!` will in turn `resume` the next one, and so on, until the bottom-most one is reached. For the user code, the effect is the same, but in async/await resumption of deeply nested awaits seems more expensive. This property is not changed by my Python prototype code.
That is not true in general, optimizations may affect stack overflows.
I believe this is true no matter if you have the component installed or not.
3 times in a row
TBQH, I can imagine a future competing compiler that does e.g. only implement 2018 and above. FWIW, I think the edition system is also of advantage there as it gives those compilers a better scale and a proper way to detect if they support a given piece of code or not.
Sure, that'd be their option. I'm speaking for `rustc` only! It's kinda like how mrustc targeted Rust 1.19 or whatever version it was. &gt; FWIW Agreed. :)
And it looks like Rust devs get paid pretty well too :)
When was the rename decided and what were the arguments? I've been following the epoch related threads semi-closely and haven't found any indicator of it.
https://internals.rust-lang.org/t/epoch-vs-era/6941/
+1. You'll be getting a much nicer language if you can start from scratch, with a clean slate. Breaking changes, no matter how big, won't be able to achieve this.
So you speak more about Rust performance *predictability*, I guess? I mean, if Rust was consistently 10x slower than it is now, you'd still be able to learn as much (probably with less satisfaction â€’ the performance may be a good motivation, I at least never tried to optimise a Perl program, Python one only when I needed to, but I tend to try getting more of my Rust programs whenever I get the chance).
Thanks!
&lt;h2&gt; â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€â¤ðŸ¦€ &lt;/h2&gt;
 &gt; you should build it on something boring and uninspiring that lets you spend as little time as possible making tech choices that aren't essential to the purpose of the business There is some wisdom here. Even if its the opposite of "go forth and conquer" bleeding edge type attitude, which *can* lead to great things, but also comes with a lot of risk and potentially a lot of time solving problems because no ones been there before, which as exciting and pioneering as that can be, could well hold you back in actually building a useful product. Guess it depends where your priorities lie. Personally, its taken me over 3 years to get an MVP of a product due to early and exciting tech choices, but the upside of that is I'm now getting contract work in that area. 
Small sample, probably a bit biased
I'm working through Jack Crenshaw's [Let's Build a Compiler](https://compilers.iecc.com/crenshaw/tutor3.txt) series using Rust, except I'm compiling to WebAssembly instead of 68000 assembler. I'm only on chapter 3, but so far so good! Sometimes I have to write some C/Rust code and compile it down to WASM in order to see how certain instructions are used. The official WASM docs aren't very accessible for someone who doesn't already understand low-level programming. This [WebAssembly playground](https://mbebenita.github.io/WasmExplorer/) has been such a life saver.
I think the answer depends on your situation most of all. It sounds to me like you're doing this on your own (going by your phrasing), and not through a school; is that correct? If so, are you doing this for fun, as a hobby, or are you working towards getting a developer job in the near future? If you're going for a job as fast as you can, then betting on JavaScript alone seems to me like [the better option](https://insights.stackoverflow.com/survey/2018/#most-popular-technologies) in the short term at least; then you can always pick up Rust later when the job situation has hopefully settled. On the other hand, if you're doing this for fun and you're not under pressure to get a job here and now, learning Rust is a great opportunity to learn more about programming in general. So even if you don't end up getting a job writing Rust, learning it will still give you a much more solid programming background than only learning JavaScript will, and not just be a waste of time, in my opinion. :)
Does the bincode (de)serialization library support changing struct definitions? Because I might add more fields to my struct in the future and I'm not sure if bincode will support it.
That thing about the job market is certainly true, and i personally don't expect to be hired as a rust developer anytime soon (bringing some Rust to the job seems to be more realistic). But learning Rust can give you a lot of understanding about systems programming, some knowledge how computers work a few abstractions layers down and type systems. Also, it's a lot of fun and the people are nice. Imo learning to think explicitly about ownership of resources alone is extremely helpful when programming in other languages. And i can even imagine that knowledge of Rust and systems programming in general can give you an edge for jobs that are not focused on that. So, my advise is: learn Rust if it brings you joy, but see it as a long term investment that may or may not pay of and don't do it at the expense of the skills you need to pay the bills.
Who would win? - Dozens of languages with decades of development and millions of users - one crabby boi
To be clear: the Panicking happened because of an unwrap() call in the example. So while Hyper bubbles up on IO error it still shuts down the event loop and handling of any other incoming request. That is not how robust server libraries should behave because an attacker can then think about how to craft requests that shut down the server.
Somewhat. If Rust was consistently 10x slower than it is now, you'd have to understand what might be causing that under the hood to understand what the performance impacts of any changes you'd make would be. The ability to look at the assembly output of your Rust program and understand at the machine instruction level what is impacting your performance is an important part of predicting the effect of performance changes. We see people do it here on the Rust Playground all the time. Python, for example, makes this harder. Is your program slow because you have a slow algorithm or badly-chosen data structure? Or is it some garbage-collector or slow hash function or something that's happening behind your back that's hard to see? Understanding performance is hard enough at the machine level. When the performance properties of a complex language implementation and runtime get involved, it gets even harder. Further, these learnings transfer. Once you better understand how the underlying computer works, you can form better hypotheses and eliminate a bunch of bad ones in trying to understand why your Python program is so slow.
Great stuff. I was just about to start working on a driver but am held up with SPI problems on my test platform! I'm very delighted to check out your code and get hacking on networking stuff!
They do this in CMake and it works very well - actually one of the only sane things about CMake. Basically there are a number (in the dozens) of policies that have changed (like is catch a keyword) and seeing the minimum version changes the policy. You only need a table mapping versions to policies. Doesn't seem that difficult.
Is there a recommended way of dealing with errors if I just want to log them and then continue. At the moment I have code like this: ``` for { let blah = some_operation() .expect("failed to get ABC") .expect("failed to get XYZ") .rest_of_processing(); } ``` But what I'd like is instead of crashing if the `expect`s fail, is that I log a message and then continue the loop. Now I guess that I could do something like this: ``` for { let blah = some_operation() .unwrap_or_else(|err| { some_logging_function(err); continue; }) .unwrap_or_else(|err| { some_logging_function(err); continue; }) .rest_of_processing(); } ``` But it looks very ugly and quite repetitive (I'm not even sure if this will compile to be honest). Is there a better way of doing this? Is there a crate somewhere that does logging which has helpers for these sorts of cases?
O(âˆ©_âˆ©)O
It won't compile, because you can't `continue` from inside a lambda (for example, it wouldn't make sense if that function was stored somewhere and then invoked later). If all the errors are the same, or at least convertible to a common error type you could move processing code into other function, something like this: fn loop() { for x in xs { if let Err(e) = process(x) { log(e); } } } fn process(x: X) -&gt; Result&lt;(), Err&gt; { let a = x .foo()? .bar()? .baz()?; do_more(a); Ok(()) } 
What resources can you recommend for someone who wants to get into writing drivers?
Goku? No wait, Harry Blackstone Copperfield Dresden with his anti-technology field would kill Rust dead =[ So, now we need to start a kickstarter/gofundme/whatever to collect money and buy Ferris a hat? (Since Ferris did the hat-trick and all that...) 
You can build on top of [embedded-hal](https://docs.rs/embedded-hal/0.1.2/embedded_hal/) - it's an abstraction that has implementations for both [STM32](https://crates.io/crates/stm32f30x-hal) and [Linux](https://github.com/japaric/linux-embedded-hal). Your driver could even work on other platforms, assuming they implement the embedded-hal traits.
Completely biased even without considering the sample size, I'd say. Projects trying out new technologies are definitely not representative of the rest of the market.
Iâ€™m sure that not every single person is absolutely precise at this level of pedanticism at all times.
CMake only has to deal with a new standard every three years. We release every six weeks. Plus, it would mean keeping duplicates of, for example, every previous iteration of type inference, and updating them for every new release. Itâ€™s not directly comparable.
I see it as a way to decorrelate the language standard version from the compiler version.
Or you can use [resvg](https://github.com/RazrFalcon/resvg#svg-support) which is already better (shameless plug). Also, I have no idea how to contact the author of the librsvg, but I have answers for most of the questions.
[removed]
Well, yeah, if every language data was representative of the market, the pay everywhere would be the same :P
What is really interesting Swift is constantly falling from top 1 in 2015 to top 6 this year.
My point is that the people using rust professionally aren't using it to do the same things as the people using, say, C++ professionally. If you could compare similar projects in different languages, then you'd have useful numbers about how the language affects salary.
This is nothing bad, everyone is human :).
&gt; the output collection is not necessarily the same type as the input collection. (The T is the same though!) &gt; &gt; &gt; &gt; If you did the same thing in Haskell, the collections would have the same type, which is what Rust wants. Why does Rust want that? That seems to me a misuse of an interface (or trait in Rusts case). Isn't the point of using an interface to allow code to return whatever it wants as long as it conforms to the same API? 
What is `catch` for? I have never seen the relevant RFC or whatever that is proposing this. Could you point me towards something I can read to learn about it?
Wow! I'm flattered. Honestly, I was unsure if I should even publish it. My fear was, that the quality would not be sufficient. 
Hi flattered, I'm dad!
Oooh! That will definitely make it into the post. Thank you!
&gt; Also, I have no idea how to contact the author of the librsvg, but I have answers for most of the questions. The main page of his site has the following link: "Federico Mena-Quintero &lt;federico@gnome.org&gt;"
AFAIK, using that may or may not be a good choice. I posted a thread on this subreddit once to ask for advice regarding RPC and the `tarpc` developer responded with [this comment](https://www.reddit.com/r/rust/comments/7xyu88/tarpc_vs_capnprotorpcrust/dud0fqi/?context=3).
I think it is totally worth it to learn Rust. If you are employed writing JavaScript then you are probably ready for another language? The biggest benefit I have experienced while learning rust has been a better understanding of what languages, like js, are built upon. The first Rust â€˜bookâ€™ was the first place to adequately explain for me what the stack and the heap were and why I should care. It sounds like at your job you do more than programming, I bet you could benefit by automating some of the boring stuff you do that isnâ€™t web development. You could write it in Node, which would be fine, but if you write it in rust you can just pass an executable to your coworkers and now you donâ€™t have to worry about if they have the right runtime installed on their computer. The one thing that I will say about learning rust as a js dev, it probably isnâ€™t going to be too easy. Js is like the Wild West, you can do anything anywhere and no one really cares, so long as it doesnâ€™t break while the user is using it. With rust, you going to first bang your head against the strict typing and the borrow checker, these will make your program fail to compile, which is frustrating. Another possible avenue to learning rust is to check out [Elm](http://elm-lang.org/), a lot of the same concepts would apply here that you are going to need to get comfortable with but itâ€™s for web dev so it might be a little more forgiving to start. ...once again I need to stop communicating before Iâ€™ve had my coffee. Sorry about the random smattering of my brain above. 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](http://elm-lang.org/) - Previous text "Elm" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
[This is one way to solve the problem](https://github.com/dtolnay/semver-trick), but unfortunately it requires the developers of your dependencies to do it, and very few do. If you are the maintainer of a popular library crate, it would be nice if you read this, so that you are aware of this trick and maybe consider using it when you think it would be beneficial to your users.
Not true. Take a look at this page: https://cmake.org/cmake/help/latest/manual/cmake-policies.7.html They don't release every 6 weeks, sure but it's not every 3 years either. And you only have to do work when a policy actually changes, not at every release. Also the compiler has to have an option for the old behaviour under both schemes. The *real* reason to do it like C++ is because the *interactions* of different policies could get very complicated. You'd have a lot more different combinations of features to test and it would probably be more code to allow turning on each policy independently rather than in groups.
I'd recommend looking at existing drivers: https://github.com/rust-lang-nursery/embedded-wg/issues/39#issue-289457410
Just finished C/C++ FFI for [Zbox](https://zbox.io/) this week. Also integrated automake tool chain with Rust cargo tool. Interestingly, now I can use the automake tools to build Rust code! ./autogen.sh ./configure make &amp;&amp; make install 
Well deserved! 
I believe [the MAY library](https://github.com/Xudong-Huang/may) is what you are looking for - it implements fibers (calls them "stackful coroutines"), which allow yielding from deep calls.
Hi r/rust... hope you don't mind if I leave a little comment here...? Looks like the guys over at r/emacs are rewriting Emacs in Rust (albeit incrementally...) -- some people sure are crazy, huh? Most loved language, huh? Interesting... I have a hacker friend who told me Rust was "ridiculously hard"... is there some kind of selection bias going on here? I'm not too familiar with statistics so maybe someone can answer that for me. Not that I'm doubting the result here, or anything, since admittedly I am quite new to the Rust world, and I'm kinda hungry at the moment. Congratulations, though! My favorite language is PHP, personally.
I've never noticed any difference in behaviour between debug and release builds, and as long as you're keeping `unsafe` to the bare minimum (which I've found to be trivial unless you're doing FFI) errors due to UB and optimisations shouldn't be an issue. A lot of what I do requires high performance so I often end up compiling in release mode anyway just so the integration tests won't take too long. That said, you should always test your code in both debug and release mode. Not testing with the stuff you want to release is a great way to get paged at 2 in the morning or have an uncomfortable talk with the boss.
It lets you use ? but in a block, rather than the whole function. Iâ€™m on mobile, but itâ€™s in the ?/Try RFC.
Oh, a policy of CMake, not a policy of the C++ that CMake is compiling, my bad.
Yes, but I wish some of that love would turn into jobs. Very few companies use rust in a significant piece of software in production. (And most of the ones that do are in the US.)
If you don't know the type of the return value, you need to box it, and look up in a vtable whenever you call a function on it. That's a significant extra runtime cost, and precludes many many compiler optimizations, which isn't in spirit of Rust: it's an abstraction with a non-zero cost, and what's worse, it's a *hidden* cost. The fact that using Collection&lt;T&gt; is slower than Vec&lt;T&gt; (When the collection is really a vector!) would not be obvious at all, and Rust really wants to make it explicit whenever you pay extra for something (Like requiring Box&lt;T&gt; for dynamic dispatch). This was just one line of reasoning. There is also the general goal of maximizing type information, which was Haskell's reason for doing it this way. I'm sure someone from the Rust team would provide more insight.
it will help me a lot thanks
Have a look at [cretonne](https://github.com/Cretonne/cretonne). It's a compiler backend like LLVM (IR to machine code compilation) rather than a full source code compiler. However I found that the code is very well written and easy to understand.
Thanks for this.
As /u/birkenfeld said, it has to do with formal mathematics. Here's a handy stack overflow link: https://math.stackexchange.com/questions/281735/quantification-over-the-empty-set
Thanks for the reply. I thought I missed something here thinking in Java-terms (where everything is a Box anyway), but wasn't sure what it is.
The compiler version and edition version are separate. Things canâ€™t be removed; theyâ€™re needed because any new compiler will be able to compile old editions.
Yes, Rust is pretty hard -- especially if you don't have a background in either systems or other functional-y languages (Rust makes you learn both). We're working on that! I wouldn't call it "ridiculously hard" -- it took me way longer to get to the same point with C++ -- but it's hard. There could certainly be some selection bias -- the people who stay with Rust will probably have a stronger love of the language :) Bear in mind, though, this is true for all of the languages, and I don't think Rust is unambiguously the hardest in that list.
Good luck. C/C++ don't have a real module system. This means it's impossible to, in the general case, start with a C/C++ program and say "I need to link this to X, Y and Z libraries to make it function properly". The source files just don't contain enough information; all they know about is header files. Hence we end up with humans specifying the dependencies externally, via make/cmake. I laud the attempt, but make it link with Qt without re-inventing cmake and you'll have my attention.
Looks to me like QOTW material!
There's no hard requirement. But when you update your compiler to 1.29 your crates are not moved to the new edition automatically either, so it's _not_ "practically equal to saying that an edition can be used to remove any feature". What would happen is that you'd update to 1.29, notice that it's a new edition, bump your edition key in Cargo.toml, and then get the breakages (Which you won't get if you first run rustfix on the deprecation lint output). But if you don't bump the edition key, things will still work forever.
Sorry for not being clear. What I mean is that as an extreme case, 1.28.0 deprecates feature X. Then edition 2018 (which could be 1.29.0) turns the feature X deprecation into an error. In effect, edition 2018 has removed feature X with some help from version 1.28.0. I know it is unlikely to happen, but what I mean is that as I'm reading it, saying an edition can only 1. introduce keywords and 2. turn any warning into an error, is not a very strong guarantee. It is *almost* like saying that an edition can only 1. introduce keywords, 2. turn any warning into an error, and 3. remove any feature with some help from a previous compiler version.
Edition 2018 != 1.29.0. 1.29.0 (for example, not committing to a version here) could compile both 2015 and 2018 code. You control which you use, via configuration.
Rust is hard because rather than burning CPU cycles holding your hand or letting you write buggy code it actually demands you write the code correctly the first time. It takes longer to get it to compile but when it does compile in my experience the resulting executable is much more reliable.
&gt;I have a hacker friend who told me Rust was "ridiculously hard"... is there some kind of selection bias going on here It just takes some time to click in your head. Compiler enforced RAII, variable aliasing rules, ownership and move semantics and then finally lifetimes. 
I can agree with that. Also, Rust was born open source. Swift is too, but everything around it is still in the process of becoming more open. Docs are mainly found in Xcode and the Apple website; XCTest and other requires frameworks are poorly documented and not totally ported yet; they just got a forum where development and proposals are discussed more openly as opposed to a mailing list with mostly Apple engineers participating; 90% of the online articles and solutions for Swift is for iOS. So yeah, Rust is miles ahead of Swift. And the language, though more sigil heavy, is much more readable for me.
It can be misinterpreted if you don't know what editions _are_, they're not rust releases, they're a parallel thing to rust releases.
400??? lmaoooooooooo
That's exactly what I found confusing. I tried to keep to the model of releases and editions being parallel, but lints in my mind are very release specific: they're introduced in a release not in an edition. But now I'm rereading this thread and I'm reading my own posts as really pedantic. Sorry about that, it wasn't my intention.
Is there a way to push generic types into a Vector? I can't find many informations about that.
Oh, no, you're totally okay here, editions are a tricky concept to get :)
Ah yeah, it would be an impressive feat if any language was harder than C++. :) Wow, systems *and* functional aspects -- sounds unique and totally awesome! I'll check out Rust for sure. Thanks for the kind reply!
I doubt it will work correct with the following: ``` "string".filter (char::is_alphabetic).all (char::is_uppercase) ``` Condition must be true only if string contains only upper case letters. 
I would not bet my business on Rust, simply because the work I do is much more well-suited to a higher-level language like Python. However, I would consider it foolish to write something from scratch using C/C++ IF this something didn't have existing dependencies in one of those languages.
That must be reflected in documentation though. I spent a lot of time struggling with `into_iter` and `cloned`.
Also, if you see the results before the actual poll, there will be less people.
One thing that I'm curious is how do you decide what drivers to write. Is there a wishlist somewhere, or is it based on what you personally need/want or something else?
Trying to turn a wasm32 physic [demo] (https://edwin0cheng.github.io/unrust_demo/) to became a real game engine. There are tons of features needed to be finish for 0.1.1 milestones. (implemented Entry system, Skybox, Basic Lighting, Basic PostProcessing, SceneNodes, Shadow, Skybox etc...)
Editions are opt-in. Even considering your hypothetical example: a feature gets deprecated and a warning is added in 1.28. Then Rust 2018 edition is released, which turns the deprecation into an error. The new edition is released with compiler version 1.29. Compiler version 1.29 will continue compiling your current code and giving you the warning. This is because Rust 2018 edition is *opt-in*. Your code continues to use the old edition of Rust, and continues to compile (with the deprecation warning, *not* error) in 1.29 and all future versions of Rust. That is, until you specify in your Cargo.toml that your project uses edition 2018. Only then, once you have opted in using the configuration, the compiler switches to the new mode and the warning becomes an error. It is just like GCC 7 continues to be able to compile C++ 98, even though it also supports C++ 2014. Your C++98 code won't be affected by any changes due to support for the new edition of the language and you can still compile it with the new version of GCC. You are only affected by the existence of C++14 if you tell the compiler to compile your code in C++14 mode. You can compile your project in C++98 mode and not care at all. It is similar with Rust. Rust 2018 is a new version of the language. New versions of the compiler would support both the Rust2018 and the Rust2015 language versions, and you choose which one you want via a configuration option, the default being 2015. So the new errors will not break your code, until you tell the compiler that your project is written in the Rust2018 language. If you don't do that, you can continue to compile your crate in Rust2015 mode using any future version of the compiler, and you will only get the deprecation warning, no error.
I want to make a 3-D vector and I know the bounds of said vector before hand. I was going to implement this as a vector of vectors of vectors, so ``` Vec&lt;Vec&lt;Vec&lt;Type&gt;&gt;&gt; ``` as the type. This is fine, but is there any way to preallocate these vectors since the size is known? To rephrase, is there any way to use `Vec::with_capacity` with nested vectors? Or perhaps there is a better way to represent this data entirely? I suppose if my 3-D array has bounds `l * w * h` I could always use `Vec::with_capacity(l * w * h)` and then convert 3D coordinates into indices.
What is the idiomatic pattern for, e.g., image filtering in rust? I'm asking about embarrassingly parallel algorithms that set each element of a list to the result of some function of another list. In C++, if you have a source `const vector&lt;vector&lt;Pixel&gt; &gt; old_img` and a pre-initialized `new_img` of the same type except mutable, you can do the following: // suppose we know old_img is the same size as new_img for (size_t i = 0; i &lt; old_img.size(); ++i) { for (size_t j = 0; j &lt; old_img.at(i).size(); ++j) { new_img.at(i).at(j) = foo(old_img, i, j); } } C++'s lack of an `enumerate` function for iterators means we can't use them without manually keeping track of the index anyway. If we suppose `foo` has no side effects, this algorithm is embarrassingly parallel. Just insert a `#pragma omp parallel for collapse(2)` if using OMP. Naively, I'd do it like this in Rust: for (i, row) in new_img.iter_mut().enumerate() { for (j, pix) in row.iter_mut().enumerate() { *pix = foo(&amp;old_img, i,j); } } But there's no way I can see to parallelize that code using, e.g., Rayon because there is no parallel mutable iterator. What is the correct way to do this?
I think that's orthogonal. Would require VA-API, which should be possible but no one has done the work, and according to the bugzilla there were some blocking issues. 
&gt;Yes, but I wish some of that love would turn into jobs. Very few companies use rust in a significant piece of software in production. They will. Keep working those chops. 
I think it mostly comes down to what boards you've got laying around and have some idea of how they work. https://github.com/rust-lang-nursery/embedded-wg/issues/39#issue-289457410
FWIW, I haven't found Rust to be any more difficult to learn than Swift. They seem about the same to me, learning-curve-wise.
Next time someone says C or POSIX is "well designed", or uses the phrase "it's just text, how complex can it be?" unironically, I'm gonna link them this. 
I was wondering what design decisions motivate the fact that `Iterator.Item` is an "associated type" rather than a type parameter? Why is it pub trait Iterator { type Item; ... } rather than pub trait Iterator&lt;Item&gt; { ... } Thanks!
Pfft, systemsy things aren't that hard. THIS is hard: https://stackoverflow.com/questions/39541312/function-returning-a-closure-not-working-inside-my-filter I accepted the answer because it made my code compile, but I still don't understand what it says
Supporting multiple languages is important to me.
This is fantastic. I wonder if it could be abstracted to let someone provide a windows port.
I believe that one of the issues was that they're not rendering onto an OpenGL surface (or something), so copying had to be done from CPU to GPU which makes hardware acceleration useless. Since WebRender will be using the GPU, I thought this might help with the video HW accel as well.
It's not clear if you already have a job or are just learning right now, but if you're looking for a job a more mainstream language should be your first priority, since eating is good and you can't learn anything without that. ;) After that, here are some things you should know: * Betting on Rust for a *career* is not a safe bet at this point, unless you either work at Mozilla or you've got enough influence where you work and a solid use case to justify introducing Rust as a technology. Let's just clear the air right now and let you know that though many of us are hoping for it, we realize that there's a lot of growth Rust needs to go through and a lot of proving before it can approach mainstream adoption. * However, Rust can offer you a lot to help with your desire to learn systems programming languages. It does a fantastic job of teaching you up front what you should know about resource management that before would have required years of trial and error to develop the necessary discipline. * I'm not sure from your post, but it's worth making sure that you understand that WebAssembly is NOT systems programming. :) Using a systems programming language and actually building systems are two different things, though the second usually implies the first. Here's the bottom line for the different scenarios I think you might be in: 1. If you're just wanting to learn all the things and Rust sounds cool, then AWESOME. I would definitely suggest Rust as a way to learn more. 2. If you're wanting to get a systems programming job with Rust, realize that your goal should be systems programming (if that by itself is acceptable), since Rust hasn't started to dominate things (yet). You may very well have to wait a good while before you can get your hands on a Rust position. 3. If you want to stay with higher-level languages, Rust may not enter the domains you'll be working in for a long time, if ever. Rust will still be a valuable learning experience, but you may not have nearly as much opportunity to use what you learn in this situation as you would in places you'd use systems programming languages.
One thing that's nice is that a lot of companies in the cryptocurrency space are using Rust precisely because it's fast and safe. I know that the cryptocurrency space is not everyone's cup of tea, but there's a lot of infrastructural work to be done in the space that has nothing to do with cryptocurrencies.
Mostly on YouTube, Vimeo (not sure with this post), Meetup.com comments and Googling for the rest of the stuff. When I started putting together this digest, Rust Belt Rust videos were not available so I reached out to the organizers and they notified me when it was online. The descriptions are written by or at least had been reviewed by the speakers. Hope you'll find it useful.
Oh! that's annoying. I thought the point of not updating was to let people keep using tools they use... hm.
Thanks! It could definitely be ported to Windows...the terminal recording is basically 3 functions as far as the higher-level code is concerned (get terminal size, do something with terminal output, do something with terminal input) and is already in trait. I just didn't know how to implement those on Windows (and didn't even really implement on Linux/macOS, I am using `pty-shell` for the heavy lifting).
I believe it's mostly so code like this is unambiguous: for x in some_iterator { println!("{}", x); } If iterators had the item as an 'input' type, every for loop would need to either use `x` in a way which constrains the type, or explicitly annotate the type they're iterating over. With Item as an 'output' type, each iterator can only implement `Iterator` for exactly one item type, so it's unambiguous what you're iterating over.
Ah, I see what you were describing. That's interesting! Where is that behavior documented? ("returns up the stack by *calling* what was previously its caller") I believe something similar could also be done transparently for Rust generators (and maybe Python too, if they don't already work like that?). Their call tree is already known, to allow callee generators to be stored by-value in the caller generator's state block, so the generated code could jump directly into the middle of the (potentially nested) callee on resume. This might not actually help performance as much as you suspect once inlining happens (especially MIR inlining before state machine generation, once that's a possibility), but it would certainly be nice to experiment with. &gt; Does this even need to be in `futures-await`? Yes, since `futures-await` is the one that manages the `Waker`. `#[async]` functions never handle it directly. This is no different from Kotlin, where `suspend fun`s don't get direct access to their hidden `Coroutine` argument either, and `suspendCoroutine` is implemented [with a compiler intrinsic](https://github.com/Kotlin/kotlin-coroutines/blob/master/kotlin-coroutines-informal.md#coroutine-intrinsics). Either way, you can already do what you want as long as you stick to direct `Future` implementations for the leaf APIs. All you get out of adding `suspendCoroutine` to `futures-await` is the ability to write those leaf APIs as `#[async]` functions (plus maybe the optimization described above, if it matters).
Yes, you can do a check for compatibility and load asm.js for older browsers. There's a little added cost for that indirection, but it certainly beats having a broken website for old browsers imo.
The behavior /u/hniksic is describing is not stackful coroutines, but a twist on the implementation of stackless coroutines to make resumption of nested coroutines more efficient.
I'm sick of people always mixing the terms, trying to flavor the wrong term instead of using the correct one, saying stuff like "it's futures with OS preemption" because they don't want to say "threads"... These are the various methods for doing-other-things-while-waiting: 1. Threads - the OS manages the scheduling, and it can switch you out any time it wants. When you perform an IO, the OS marks your thread as blocking and will not resume it until the IO is finished. * In Rust: [`std::thread`](https://doc.rust-lang.org/std/thread/index.html) 2. Green Threads - managed by the VM/runtime instead of the OS. May use OS threads behind the scenes to run on multiple processors. Still preemptive, but it is possible to make their interruptions less intrusive and race-prune. * Main difference from threads - the VM/runtime is the one doing the switching. * Rust doesn't have it. I found [the `green` crate](https://doc.rust-lang.org/0.12.0/green/), but I don't think it's still supported (can't find it in crates.io) 3. Fibers - stacks that can be switched in and out. No longer preemptive - the fiber need to yield execution in order to be switched out. * Main difference from green threads: cooperative instead of preemptive. * In Rust: [MAY](https://github.com/Xudong-Huang/may) 4. Coroutines - functions that can "return more than once". Unlike fibers, a coroutine can only yield execution to it's caller - though there are some constructs for easily "bubbling" that up (like Python's `yield from`). Coroutines are special functions - unlike threds/green threads/fibers which are regular functions with something interfering with their stacks. * Main difference from fibers: if you want to yield, the entire stuck up until the reactor must be made of coroutines that _await_ the coroutines they call. * In Rust: [futures-await](https://github.com/alexcrichton/futures-await) 5. Futures - the monadic approach. Unlike the previous methods, where you had code running, yielding (or being forced to yield), and then resuming when the IO is ready - here you have a `Future` (or `Promise` or whatever) that you can register a callback that will be called when the IO is ready. If the callback does an IO, it should return another `Future` which you can register other IOs on. Any code written after the `Future` but outside the callbacks will be executed right after the IO is sent - and **before** it is ready. The idea is to compose your algorithm by registering callbacks on top of callbacks, ending up with a complex `Future`. Once that complex `Future` is ready - your algorithm has finished. * Main difference from coroutines: need to compose the code instead of just writing a regular algorithm. * In Rust: [`futures-rs`](https://github.com/rust-lang-nursery/futures-rs) So, you call MAY "a green thread implementation, with cooperative switching" - but the difference between green threads and fibers is that green threads are preemptive and fibers are cooperative. So MAY is fibers. Also, I don't know Kotlin, but you said &gt; If you have a deeply nested stack of suspend invocations, Kotlin's resume will return directly to the execution of the bottom-most suspend function. But... that's the difference between coroutines and fibers. So Kotlins coroutines are actually fibers. Just like MAY.
`Deferred` isn't a central interface the way `Future` is. It's not the way async tasks are driven, it's just a way for sync code to handle them (including the pieces of `suspend fun`s that don't immediately await their callees).
You can generally trawl https://youtube.com/c/rustvideos where I (re)publish everything I can get my hands on. There's a couple of problems with some Meetup hosts only hosting stuff on Vimeo, as content theft is very common on YouTube :/.
I'm not sure how that's relevant? A linker will just see assembly that looks similar and hopefully fold it together, right?
It's relevant in the sense that your code will be rejected before LTO gets to look at it, so no matter how smart it is, it doesn't get to fold it together.
Yes - because when you have coroutines you don't need to register callbacks on your `Future`s. With [futures-await](https://github.com/alexcrichton/futures-await) it will be similar - you won't be using the monadic combinators of `Future` as much, and it'll be more of a behind-he-scenes type than your main interface.
I'm not talking about consumers of `Future`s- in that context you're right that `Deferred` and `Future` are analogous. I *am* talking about `Future` implementations and event loops. Kotlin coroutines don't compile down to anything involving `Deferred`; Kotlin event callbacks don't touch `Deferred`; Kotlin event loops don't work with `Deferred`. They compile down to/notify/schedule `Continuation` instead, which is in this context analogous to `Future`.
[We are hiring!](https://threatx.com/about/careers#core) But we are in the US and on site only. 
This. Personally, I prefer to use LOC as a metric. Specifically, any module in which `unsafe` appears is considered tainted AFAIC, and I hope that authors don't let `unsafe` leak outside a module without carefully annotating it as such (with a `unsafe` marker on the specific functions).
Nightly isn't stable. If you want stability, use the stable toolchain.
There is at least one other person, /u/xzakox, working on a similar thing for [LoRa and the RPi](https://www.reddit.com/r/rust/comments/7l9a0n/best_rusty_way_to_make_a_background/). The RA-02 is on the list of [drivers wanted](https://github.com/rust-lang-nursery/embedded-wg/issues/39) from the Embedded working Group. The driver initiative [blog series](https://www.reddit.com/r/rust/comments/84183w/weekly_driver_4_enc28j60_ethernet_for_your/) is a solid place to start getting a feel for how things work. The first paragraph of that post links to the others in the series, [the 3rd](http://pramode.in/2018/02/24/an-introduction-to-writing-embedded-hal-based-drivers-in-rust/) being really great at explaining a lot of the steps involved. I am also potentially going to write a driver for the RN2903 in the next few weeks, but I need to find some time. I would really be interested in writing a LoRa/LoRaWAN high level library. Maybe, since there appear to be several of us working on similar things, we could pool our resources/knowledge? 
In the US the rust job landscape is a somewhat better than in europe. Unfortunatly most US companies using rust are startups and rarely do they sponsor H-1B visas.
On the other side you have the issue with Python 2 to Python 3 where it took years for general libraries to get ported. And even though most stuff is ported to Python 3 now, there are still industries that completely rely on Python 2. Even though support ends in 2020 (was originally supposed to end 2016). I find the proposed approach as a nice compromise to make some breaking changes without scaring people off with the possibility that their program might suddenly stop working. Rust's target is close to C and C++ and we have to compete with their stability guarantees as well. Also I don't know the core teams position, but I don't think this prevents going for a Rust 2.0 someday. More like immediate small opt-in breakages, until we got enough for a big breaking change and major version update? But again I don't know what the Rust team is planning.
It's already usable, though surely quite basic at this point. Development is surprisingly rapid, mostly thanks to my awesome co-maintainers and multiple contributors. I want to work out a few more kinks and then I'll publish the next release.
Answering my own question: let new_img = old_img.par_iter().enumerate().map(|(i, row)| -&gt; Vec&lt;Pixel&gt; { row.par_iter().enumerate().map(|(j, pix)| -&gt; Pixel { foo(&amp;old_img, i, j) }).collect() }).collect();
You may be interested in [associated types versus generics](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html#associated-types-versus-generics) and the [original motivation](http://rust-lang.github.io/rfcs/0195-associated-items.html#motivation) for associated items.
[Weekly driver #3](http://pramode.in/2018/02/24/an-introduction-to-writing-embedded-hal-based-drivers-in-rust/) gives an overview of the how all the parts (embedded-hal, driver and application code) fit together. It's more structurured than a driver code base so I would suggest reading that first.
A mixture of need, component availability (do I have the component with me, or do I need to buy / order it first?) and fun factor (have I worked with a device like this before? No means more "fun").
Nevermind, yeah, it's exactly the same. I'm... not sure what I was thinking. Still, it seems right to me that the letters of `"123"` are all upper case. 
&gt; python Would you mind to elaborate more on replacing Python scripts by Rust? How exactly you proceed with this? I mean is it that easy to replace Python ecosystem with Rust?
It's a data parallelism standard for C, based on baking a few common patterns into the compiler.
I would also assume that drivers that connect stuff together are more fun than single ended drivers. ;)
I have been looking forward to using this since your first post in 2016. I have been thinking of a mutation that would really help with improving my tests. I often have code like ``` *ctx = ctx_backup.clone() ``` and I should, but don't always, have test that fail if I use ``` *ctx = ctx_backup.new() ``` Is there a mutation for this already? Is there an issue I should follow?
One thing you might want to use to make your code look better is clippy (https://github.com/rust-lang-nursery/rust-clippy). It has a bunch of lints in it to catch things that beginners and even advanced rust users won't.
Yes, you described problems with C++ very well. I can imagine Rust codebase that would be similarly complicated and difficult to build as C++. Putting `.rs` files at non-standard locations and using bunch of `extern fn`s could do it. So why Rust doesn't have this problem? Because of the culture. Rust community maintains good coding practices from the start. That's what I outlined in my specification: "if convention is followed". My intention is to encourage good coding practice by making it easy to build.
Short aswer is yes, you can. But some code should be write.. i'm not sure about details of your use case. Sorry for a delay but reddit notifications sucks. Hit me on gitter/telegram/hangout/email/github: tymoteusz.jankowski@gmail.com im xliiv almost everywhere
Honestly, if you did that you probably wouldn't find substantial salary differences anyway. A lot of the "higher-paid" languages appear to be such because of common use cases (e.g. data science is high paying, and languages whose industry use is dominated by good data science tools are highly paid as a result). I think they mostly just do it because it's "cute."
&gt; Ah, I see what you were describing. That's interesting! Where is that behavior documented? ("returns up the stack by calling what was previously its caller") I saw it described in [this video](https://www.youtube.com/watch?v=YrrUCSi72E8), say from 8:00 to 12:00. Kotlin's approach to coroutine compilation is CPS all the way. Each call _into_ a suspend function is creating a new continuation that chains back to the continuation of the caller. This is how resume can immediately start from the bottom and work its way up. Of course, a continuation library built on top of async/await would not share this property. :) &gt; &gt; Does this even need to be in futures-await? &gt; Yes, since futures-await is the one that manages the `Waker`. That's clear - but if I were to write a "raw" future that implemented `suspendCoroutine`, then I'd be handed a reference to the `Waker`? &gt; Either way, you can already do what you want as long as you stick to direct `Future` implementations for the leaf APIs. All you get out of adding `suspendCoroutine` to futures-await is the ability to write those leaf APIs as #[async] functions (plus maybe the optimization described above, if it matters). This sounds really close to saying that `suspendCoroutine` can already be written using the current public API. Specifically, let's say: * `suspendCoroutine(fn)` is my function that accepts a `FnOnce` and returns an `impl Future` (this can be done using the current public API) * its `poll()` gets handed the context, which is in fact a `Waker` * the only thing `poll()` does is invoke the function supplied to `suspendCoroutine` with a lambda that, when called, invokes `Waker::wake` Unless I am mistaken, nothing should stop me from writing `await!(suspendCoroutine(...))` which means I can already write "leaf" APIs as `[async]` functions. Am I missing something?
We tried that, and people got real upset when the tool wasn't there, so we're trying this now. :/
&gt; Of course, a continuation library built on top of async/await would not share this property. :) Well, it *could*, in the way I just described. :P &gt; That's clear - but if I were to write a "raw" future that implemented `suspendCoroutine`, then I'd be handed a reference to the Waker? Yes, you could do it that way, but if `futures-await` ever did anything with its `Waker` (e.g. wrapping it) that would stop working. Sorry about the confusion. So it sounds like you're not missing anything from Kotlin but the particular continuation implementation?
This (on hold) project of mine is using Rust with PyQt 5.x and I like it: https://imgur.com/2yQMBZI [rust-cpython](https://github.com/dgrunwald/rust-cpython) makes it quite comfortable and, if you're OK with depending on nightly Rust until the requisite features stabilize, the [PyO3](https://github.com/PyO3/PyO3) fork of it is even more comfortable. Beyond that, [setuptools-rust](https://pypi.python.org/pypi/setuptools-rust) will allow you to integrate Cargo into `setup.py` commands like `build` and `install` and it supports both of those bindings. That said, while rust-cpython and PyO3 support both embedding and extending, I've only tried the "build a compiled Python module using Rust and then import it" approach, because [extend, don't embed](https://twistedmatrix.com/users/glyph/rant/extendit.html). As far as packaging goes, I never had any problems using PyGTK or PyQt with py2exe when I needed to target Windows but I've never bothered trying to package a standalone Python application for Linux because I'm fine with relying on the package manager.
Thanks! :) Yes I have seen the same: vimeo is below 10% in all dev talks but still some organizers choose to upload their talks there. I didn't know it was because of content theft. 
&gt; &gt; Of course, a continuation library built on top of async/await would not share this property. :) &gt; Well, it could, in the way I just described. :P Hey, I completely missed that part! I know about that optimization and Python was actually _supposed_ to have it - it is mentioned [in the original PEP](https://www.python.org/dev/peps/pep-0380/#optimisations) and [later by Guido](https://groups.google.com/d/msg/python-tulip/bmphRrryuFk/BNEOOOuR1j4J), but the optimization [got dropped](https://bugs.python.org/issue14230) for reasons I never fully understood. On the other hand, that optimization is completely independent of continuations, it should apply to any async/await based system. &gt; So it sounds like you're not missing anything from Kotlin but the particular continuation implementation? Correct. I liked the idea of reifying the coroutine's continuation and the ease with it allows you to connect coroutines to callback-based systems. Then I realize it doesn't take all that much to implement that semantics _on top of_ existing async/await coroutines. Python was a nice proof of concept, but it would be even more interesting to do it in Rust, unless it's already been done or there's a reason why it can't be done. I still think continuations are a neat option to have, although they're a bit difficult explain to people versed in async/await style.
The problem is not the organisers, but the venues they run in. They usually sponsor the taping and decide where to put things. I've been trying to talk to some, but they generally want a feed that I don't want to pay.
I'm only asking whether it is theoretical possible... so this answer is completely sufficient! Thank you for writing this! :-)
I'm glad You like it :)
So long as your sample is representative, you don't need a very large number at all to be reasonably confident in the results.
From a non-Rust user, I just want to say congratulations!
Yep, I am coming back next year... Golang it is! 
Just what I was looking for! I underestimated the power of the `vec!` macro. Thanks!
Yes, but you don't want existing connections to get dropped or affected by trying to open new connections when you've hit the limit. Until they patched Hyper with a 10ms wait, Hyper would get stuck in a spin loop trying to open a new connection which would lock up the event loop, affecting everyone. Ideally you'd always be able to respond to and release existing connections even if you cannot open more. Being starved of connections then would be a different issue.
I see, didn't know how it works in those cases. I'm not sure if it would help you with the Rust YouTube channel, but I could share the Google spreadsheets I'm using to collect Rust talks and showcase them to the speakers before publishing. Let me know :)
It's a bald-faced pun, and I love it.
&gt; I mean, going back to my original post, I don't really see how you're implementing anything new or "on top of" here. The Python code provides a working implementation of `suspend` and a launcher that starts execution from blocking code. In Python at least, a generator doesn't get free access to the outermost generator, so that has to be communicated between `suspend` and the launcher. Also, the function passed to `suspend` may choose to invoke the continuation from inside the function, in which case suspension is effectively canceled and the coroutine continues right away. Correctly handling continuation being passed on and quickly invoked in another thread requires some care as well. I don't claim that to be a grand invention, nor do am I set out to _change how things work_. It looks like you are implying that all of the above is trivial and doable in a couple of lines of code. If it is, it's far from obvious to me what they would look like, in either Python or Rust.
A minor nitpick: I think that, following the design principle that the lowest effort solution should be the one that is correct most of the time, to encourage people to do the best thing, the variant that accepts the closure should be the one that is shorter to type. So I'd swap those names around. Might be too late for such a breaking change at this point, though.
If you compiled ripgrep with simd and avx support you can't use cargo-update, iirc, because it doesn't know to use all the special flags to re-enable them. However, this should be a moot issue once runtime detection of such cpu instructions is possible.
If you haven't already, and have a compatible CPU try ripgrep with simd and avx support for even more performance. Normal `cargo install` doesn't do this by default. Use `RUSTFLAGS="-C target-cpu=native" cargo install ripgrep --features 'simd-accel avx-accel'`
This is great! I spend a lot of time commuting, so conference talks are something I consume a lot of. Unfortunately, when searching for Rust videos one has to sift through videos about the video game, and then figure out which presentations aren't just "I rewrote it in Rust" or tech evangelists talking about how great it is.
Did you have this simulation running inside IIS? Rust is going to win in terms of performance any day of the week, but that would widen the gap considerably.
Hm. Well, Rust already gives you access to the outermost generator, or (sort of) the "task" in futures-rs terms, via the `Waker`. That Python requires extra support code to do that is kind of unfortunate. Regardless, the workflow of "grab ~the current continuation~ *the current `Waker`* and stash it somewhere that will poke it when it's time to continue" is already the typical way to implement a leaf `Future` in Rust. Is there some other new capability you want to introduce on top of that?
If you've been programming for a year, then i would recommend continuing to focus your energies on your main language for now. I think there's no substitute for knowing a language and its ecosystem - tools, libraries, idioms, history, philosophy, culture - really deeply. Once you do, you are in a great position to appreciate the ecosystem around another language. If you try to explore without that base of understanding, you won't have a sufficient reference to compare to. That said, feel free to dabble if you fancy - spend an afternoon playing around, but don't plan to invest weeks. As to whether you should learn Rust next, well ... I would say that a well-rounded programmer should know the three main kinds of programming languages: untyped, highly dynamic languages (JavaScript, Python, Ruby, etc); expressive, strongly typed managed languages (Java, C#, Kotlin, Swift, etc), and low-level systems languages (Rust, C++, etc). All three have areas where they shine, and all three have things to teach you. (i would also say that programmers should be familiar with functional programming; once upon a time, you had to learn a functional language to do that, but i think perhaps functional techniques are sufficient present in all three of the above to do so without needing a separate language today - it might still be worth it as a learning exercise, but the sad truth is that there is no functional language whose ecosystem is strong enough to make it practically useful in the way the above languages are) (and of course everyone should learn some LISP and SQL at some point, but i draw the line at Prolog, and leave APL and Forth for the real ascetics) You might find it easier to go from JavaScript to one of the strongly-typed managed languages. That will give you space to learn how to use a powerful type system without also having to learn how to manage ownership and do without dynamism at the same time. You can then go on to a systems language, where the use of types will be pretty familiar. That said, Rust really is good, and the documentation, compiler feedback, tools, and community are fantastic, so it might even be easier to learn Rust than Swift or Kotlin or whatever. 
&gt; Struggle through learning Tokio/Futures [...] ? The struggle has value. The struggle is more w/ Rust than Tokio/Futures IMO. Therefore, if the struggle does not have value to you in this project, then quite possibly Rust doesn't have value to you in this project compared to others. This cost/benefit analysis is one I perform before choosing Rust or Go for any project like this.
Thank you for gracing me with your presence. It's not public yet because it's just a hello world and a broken, poc implementation of my module system. I actually already posted an issue to the bootimage repo asking for support for deterministic builds. Namely, a way to specify an exact url, revision, or directory for the bootloader and support for passing --frozen to cargo. While it's not your tool, it would also be nice to specify the location of the rust source to xargo in case it's installed separately from rustup.
&gt; Is there some other new capability you want to introduce on top of that? I would like to be able to grab the continuation (current `Waker` here) without having to write a raw future for each new case.
Microsoft Research had a test OS project called Singularity a while back for running .NET bytecode like this. It didn't result in anything interesting but there's some blog posts about it.
I'm familiar with Singularity! Super cool project.
Thanks for the info, didn't know about these initiatives! That is awesome! I have Ra-01 boards, however not sure about the differences. I think the driver should work with any SX1278 chips. (Also I will need to implement the embedded-hal traits for my STM32F030, because I could not find any implementation). For now, I realized that I need to order adapters, because the Ra-01 is SMD :P But maybe I will not able to wait, and solder some wire directly to the board... :D We will only use the LoRa, not the LoRaWAN. Actually it will not be a sensor network. So let's join our forces! :D But I cannot promise anything, as it is a pet-project. Do you know any community chat or forum for the embedded rust folks?
Looking nice :-)
On the other hand, Rust's ability to (for example) slice up an array into multiple mutable components, and mutate each of the slices in parallel, is not possible to do safely in Haskell.
You can usually make the error type a `!`, can't you?
...which this isn't 
Yes, we would and do ;-). - Cofounder, [Integer32, LLC](http://integer32.com/).
&gt; Have you considered putting the timestamp first? Good idea! &gt; Format changes should definitely be part of the SemVer'd API. Almost universally, people feed log-files through some kind of regex-based pattern matcher Yeh, one of the motivations for this change is to make the default format a bit better if your only option is grokking text, so we should definitely consider the stability of the format too. Changes to the default format are going to break patterns, and I think that should be enough for us to be careful about changing it, but limiting tweaks to the default format to breaking changes still seems a bit heavy-handed to me. In my opinion, the best thing we can do for terminal log munging out of applications is to emit log records in a more robust, structured format like json and dig through them using a tool like [jq](https://stedolan.github.io/jq/). Having said all that though, maybe instead of trying to bundle these changes into patches, we could think about any other API changes we want to include and just publish a `0.6.0` release of `env_logger`? Since it's basically never a public dependency the reasons for minimising breaking version changes might not apply as much for `env_logger`.
What do you want to do with such a vector? If you have no type constraint on a value (or a vector of values) then you really cannot call any methods or do anything with them. If you wish to switch on the containing type when consuming the data, you can use `Box&lt;Any&gt;` or more idiomatically, a custom `enum` type to wrap the various possible options. If you want to be able to perform some operations over some interface all the items in the collection share, then you specify that operation as a trait, and then store a list of `Box&lt;Trait&gt;` (or `&amp;Trait`) to store them as a shared type.
There is a experimental nightly feature called "catch": ``` #![feature(catch_expr)] fn loop() { for x in xs { if let Err(e) = do catch { let a = x.foo()?.bar()?.baz()? a.doMore() } { log(e); } } } ``` ... but its not exactly that pretty, and it is quite unstable, and it looked like there was going to still be a decent amount of discussion about it and reworking.
&gt; but I've never bothered trying to package a standalone Python application for Linux because I'm fine with relying on the package manager. These days on Linux I guess flatpaks/snaps/etc can make help
Imho, having 20ish longlived threads around is perfectly fine, especially that enables the rest of the code to be neat and clean. I would only go for futures/tokio if you feel that it will improve the overall solution
https://github.com/nrc/r4cppp is pretty good. I'd also recommend reading the Rust book but skimming the first few chapters. There's also an intermediate level Rust book being written somewheres, I can't remember what it's called.
This is interesting. I will try it out. Thank you!
Ah, I was indeed misunderstanding you; you were talking about LTO reducing binary bloat. However, thats not the main problem OP was talking about - he was talking about unifying dependencies and making different versions play together.
This is what I ended up doing. I just read about the `do catch` construct -- which would remove the need for an extra function. Unfortunately it's still experimental so I can't use it. Hopefully it stabilises soon.
You might want to rethink the executable's name. `ag` is [the Silver Searcher](https://github.com/ggreer/the_silver_searcher) - a very popular grep tool. How about `angr`?
Nice :). What did you use for creating the website?
We did it guys. We got the meta QotW!
We got the meta quote *and* uber constants got merged! I'm particularly interested in converting numbers to references in constants, but there's also currently no mutable references in constants and I'd like to convert `0xb8000` to a `&amp;'static mut [u16; 80*25]`. Will that be changed with the merge, or will making it a mutable reference still be restricted to a non-constant function?
can it stream and do some ops for logs which are 100s of megs in size?
Haven't tried...it streams well. No reason why it wouldn't. I haven't benchmarked it but it should be pretty quick.
Seriously, no. If you're not sure you need Rust, then you don't need it.
I had no idea, never used that before. angr could be good.
MIRI is capable of basically anything, but right now anything more than existing const functionality is disabled. (Not sure if it's a feature gate or straight up disabled) There are a bunch of RFCs about allowing various things in const contexts.
&gt; â€œergonomicsâ€, â€œsafetyâ€, and â€œbasic decencyâ€. Today we abandon these goals and just solve the dang problem What's so bad about the sugested API? It doesn't seem that bad to me, am I missing something?
When the entry API was first designed it was a goal that it was impossible to mess up the keys, because it took ownership of the key on lookup (excepting a broken Hash/Ord/Eq impl, but that exception applies to the entire map API). When borrowed key lookup was later brought up as desirable, it seemed "obvious" that it should be as ergonomic as owned key lookup. All previous attempts to solve the problem have been destroyed on those rocks. This design completely abandons those goals, and even adds fun new ways to shoot yourself like letting you mutate the keys in the collection *as you search over them*. (giving conceptually unnecessary mutable access when it's technically legal is another thing we've historically avoided; see Vec::retain's signature)
A handful of long-lived threads sounds like a fine solution to me. Is thread count a meaningful bottleneck or resource contention issue in your project? Threads aren't meaningfully expensive if you're not spawning hundreds of them or repeatedly spawning and then letting them die.
You're probably right! I don't anticipate running this on anything that couldn't handle a few dozen threads. Simple is usually better, isn't it?
&gt; The struggle is more w/ Rust than Tokio/Futures IMO. Kinda? I'm admittedly not a Rust expert, but I've been using the language on and off for a few years, and I had absolutely no problem understanding `mio` (they have great docs!). I just find Tokio's documentation and examples really lacking considering how much stuff is packed into it.
&gt; uber constants You mean "Allow locals and destructuring in const fn"? I haven't been paying close attention, but I'd like to know what to be excited about. :)
I'm referring to Miri. An adorable name for the best rust feature since non lexical lifetimes. The locals and destructuring help though.
Qt is maintaining PySide now. 
Are recursive descent parser generators not possible, or just not something that exist in Rust yet?
Alas, this is likely not something that mutagen can do. Please recall that we don't have type information available, as we're just working on syntax, and we must avoid mutations that break compilation. However, I plan to allow for statement removal in some capacity, which may be able to just get rid of the whole statement.
You might want to open a `hyper` issue.
Yeah - hm. I guess I still disagree about semantics but I can see the problem. (I'd say `""` _does contain only upper case letters_) All I can think of for a functional solution would be a two-part slightly less efficient solution: fn all_and_some_upper(s: &amp;str) -&gt; bool { s.chars().filter(|c| c.is_alphabetic()).all(|c| c.is_uppercase()) &amp;&amp; s.chars().any(|c| c.is_uppercase()) } all_and_some_upper("1234") // false all_and_some_upper("ABCD") // true all_and_some_upper("AB12CD34") // true all_and_some_upper("aBCd") // false
If you're experienced in functional programming, thi scan be useful as a side-resource to the book: http://science.raphael.poss.name/rust-for-functional-programmers.html I'd recommend just skipping around to the later sections of the Book v2. It's aimed at beginners, but it explains everything thoroughly and if you skip ahead to the first interesting-sounding section, it's quite relevant.
`agrind` :)
Is there a stream/iterator in the standard library which lets you append items to it (FIFO, queue-style) while you're iterating over it? This doesn't *seem* like something that would be memory-unsafe (since all you're doing is appending items, you're never altering the item currently being referenced), but a vector can't accomplish this as far as I can tell. Something that would allow this code to compile: for item in queue_iter { if item.some_condition() { queue_iter.append(item.get_other_items()); } } such that you could continue processing the items in `queue_iter` until no more items are being added.
I agree. Being able to easily create self contained static binaries/libraries is also one of the things that make Rust really good if you need to make a closed source binary libraries available to partners. Usually C or C++ is used in this space but rust has as great interaperability capabilities as C. It usually has easier licensing on dependencies (little GPL that makes static linking a problem). Support for musl is also good even though depending on libc usually isn't a problem. 
Ok, I thought you referred to actually writing `suspend` (and correctly handling the ownerships and the corner cases mentioned earlier) as "new capability". I think we are in agreement about it being possible to implement `suspend`, and I'm certainly glad that getting a handle to the waker is easier than the equivalent was Python. The remaining question is what you meant earlier by: &gt; if `futures-await` ever did anything with its Waker (e.g. wrapping it) that would stop working. Sorry about the confusion. Do you mean that the code that assuming anything about the nature of `Context` (such as that it's in fact a `Waker`) is not supported by the `futures-await` API, even if the code is statically correct and compiles now?
No, that part was just about future-proofing.
That's also what the https://youtube.com/c/rustvideos channel is there for. Which tech evangelists do you mean? I rarely see talks that aren't focused on a specific subject.
WTF. 
Sorry if you pulled out your hair over my pun.
Should be noticed that /u/japaric is not the only contributor 
He was!
http://wiki.qt.io/PySide for reference
Great work!
&gt; Rust is hard because it requires your code to be pretty high-quality. I think this is a rather biased way of putting it. It's not entirely that it's hard because it's forcing you to be better, it's at least in large measure hard because many of the ways of solving a problem in other languages are simply not allowed, so you have to approach things with a different mindset. Also, the things that a language gives you control over determine what make a piece of code in that language good. For example, since Rust gives you control over memory layout, your good, idiomatic code will be careful to lay things out in memory appropriately, while in a language that doesn't give you that control, the fact that parts of your structure might be on the stack and parts on the heap won't worry you. So rust is hard because it gives you enough control that you have to worry about lots of things you might not be used to in order to come up with a good solution. The too many list tutorial is a good example of this - in some languages, a linked list implementation is two lines of code and nobody worries about the things the language doesn't give you control over.
Never used any of those libraries, but looking at the `ipnetwork` crate, there seems to be an `IpNetwork` method that returns the `IpAddr` you want. [here is the method](https://docs.rs/ipnetwork/0.12.7/ipnetwork/enum.IpNetwork.html#method.ip), and assuming you're really new, you would probably be using it like `let ipaddr = ip_psql.ip()`
You can't modify something being iterated as the iterator internally contains a pointer and if the container has to reallocate that pointer could become invalid. However, if you do a `while let` loop with a `VecDeque` you can alternating popping and pushing: while let Some(item) = deque.pop_front() { if item.some_condition() { // `.append()` takes `&amp;mut VecDeque&lt;T&gt;' deque.extend(item.get_other_items()); } }
Great overview. Thanks.
Are we close to have [something like this](https://play.rust-lang.org/?gist=dcd3f32eb36572084bf6aede9e6ef075&amp;version=nightly) possible?
Right, it's probably hard differently for you than from me. To this day I didn't have to write any cyclical data structure in Rust simply because I don't write such types of programs. I can understand your experience is different. For me, high-quality code is also fast. Worrying about stack vs heap leads to faster code. So I'd say that's included in what I said before. :)
I'd be surprised if there's *no* way to properly code a pointer for a queue-iterator, but thanks for the option either way
Soâ€¦ does that mean constant evaluation could become turing-complete?
Maybe buffer is too large for stack frame? Linux default is 8 Mb and your buffer is 16 Mb. Try to make smaller buffer or place it on heap.
Yes! That's why I wrote he's leading the working group :) Thanks to all contributors for making these drivers possible.
If you're really attached to the `for` loop you can use channels or do something with one of the `*Cell` types, but all that would do is obscure the intent of the code. And at least with channels, it would also have worse performance.
Not exactly. That is, this foundational work will enable more features. But those features don't have RFCs yet. In my understanding, we'll need RFCs before those new features can exist.
Could, yes.
MIRI stands for "MIR interpreter." Its primary use in the compiler will be to enable more things to be a `const fn`. In the future, it might be able to be used for more things, like an "unsafe grind", that would let you interpret your unsafe code and produce warnings when you invoke undefined behavior. I think you might be able to build a REPL out of it too.
&gt; an unused two or three letter acronym Oh my sweet summer child...
That's a Python library, so there is no executable name collision, but yea - if there is a vacant name that would be better.
Please note this is from 2014 and so contains syntax that doesn't exist in today's Rust.
On top of that, people who actively pursue 'better' technologies and challenge the status quo are in a different salary range no matter what they like. 
&gt; There's also an intermediate level Rust book being written somewheres, I can't remember what it's called. You may be thinking about this year's roadmap, we have "Resources for intermediate Rust programmers" on there, but we haven't started that work yet, so it doesn't exist, so of course you don't know the name :)
Thank you for replying! :) I saw the ip() method and the *IpNetwork* from methods too. Unfortunately, being able to convert them doesn't quite solve the puzzle as I need to pick 1 type for both cases. I've updated the opening post to be clearer and include example code.
As I understand it, this doesnâ€™t actually let any new code compile, right? More of the preparation work for doing constant evaluation right?
Thatâ€™s my understanding as well.
If you haven't already, you should probably ask on https://gitter.im/actix/actix
They have a lot in common, so it's not that hard if you use python as general purpose language. Many Rust crate authors model them after popular Python packages, so often you can apply the same concepts and transfer code almost literally. For some specific domain you may not have the ecosystem yet, but it's easy to mix Rust and Python in various ways.
You've probably rogained people's trust by now.
Okay, cool! In that case I think it makes good sense to look at Rust, but remember that JS and Rust are *very* different, so better go slow and learn it at the pace you need without trying to rush it :)
Like OP, I'm also coming from web. I feel like JavaScript can give you a fairly good understanding of what functional programming is if you want to use it that way, and TypeScript is a good introduction to strongly-typed languages. Those might be ways of using your current job to develop skills that I know have helped me with Rust.
[Quick link to see a few of those RFCs](https://github.com/rust-lang/rfcs/pulls?utf8=âœ“&amp;q=is%3Apr+author%3Aoli-obk+)
Sounds pretty great. A rust REPL would be amazing.
At FOSDEM, Oliver said RFCs were coming, so looking for "RFCs opened by Oliver" seemed like a safe bet :)
`for` loops in particular are tricky because `Iterator::next` is not a `const fn` (and weâ€™re undecided on how `const fn` should work for trait methods), as mentioned in https://github.com/rust-lang/rfcs/pull/2344
I like the sound of this. I've been frustrated in the past by how conservative rust was with keys when using BTreeMap. I want the option to (sometimes) live more dangerously. :)
OK, thank you
The latter; C++ has had libraries for this forever.
Well, you yourself said you want the IP, rather than (ip, port) pair or (range of ips) set so: * For Rocket, drop the port: call `ip()` on `SocketAddr` * For Diesel, drop the subnet info, etc.: call `ip()` on `IpNetwork` * Serde supports `IpAddr`. Hope that helps! 
Is there a reason https://github.com/rust-lang/rfcs/pull/2338 is not listed as FCP?
If you understand mio why not use that?
Trivial reason is performance: If you can do something at compile time, you don't have to do it at runtime. Thus: Faster program.
I agree Vec::retain's API was mostly incidental, but I recall whether it should be "fixed" being a bit more controversial. Certainly this style of thing has been more controversial in the map context because of key validity. :) To be clear, the proposed API gives you `&amp;mut K`, but it's a logic error to mutate it in a way that would change how it hashes/compares (for the same reasons implementing `==` as `rand()` or `false` is a logic error).
The reference to reference part is easy but the lifetimes part reminds me of C++'s std template hell.
&gt;how I would do that in Rust Since the borrow checker doesn't like circularity, use unsafe code or put all the items in a vector and use vector indices instead of pointers.
Thanks for the advice. I'd have to think about it a bit more, but I expect that the vector approach wouldn't be great, because the whole point of using a circularly linked list is so that you can remove values from it and add them back very quickly (the removed node contains all the information it needs to be placed back into the list). This is used by dancing-links to backtrack quickly. I expect that the correct answer is to use unsafe code, but I'm reluctant to start down that path.
&gt; Which means no one can just copy paste to use commercially. GPL code can be definitely used commercially (that's how RedHat and SUSE make their money), it just requires that corresponding source code be provided. If a license doesn't allow commercial use it wouldn't be a free software license, it would be proprietary (and the GPL isn't proprietary).
&gt; In the future, it might be able to be used for more things, like an "unsafe grind", that would let you interpret your unsafe code and produce warnings when you invoke undefined behavior. Wow, jesus, I almost spat out my tea! That sounds amazing!
To be clear, such a thing is a "hey we think we could do this and it'd be neat", no guarantees!
Why is the rust compiler complaining about there being a private field? mod details { #[derive(Copy, Clone, Default)] pub struct Private { pub public: i32, _private: (), } } pub use self::details::Private; fn main() { let s = Private { public: 42, ..Default::default() }; } I am trying to create a struct that can be initialized with struct initializer syntax while reserving the right to extend the struct later. So I try doing this by adding an empty private field to require users to always use the `..Default::default()` to fill in the remainder of the struct. But Rust says this is not allowed... Any other way I can achieve giving users struct initializer syntax while still reserving the right to add new members in a backwards compatible way?
&gt; We require K: Eq + Hash to insert keys, like cowards Worth reading just for the prose.
Nitpick (is it really a nit, though?): Vectors are *not* linked lists, they are arrays internally.
&gt; I think you might be able to build a REPL out of it too. Let's say I'm interested in pitching in for this, though I'm not sure I have the knowledge/experience. Where should I look in the code/read?
You should chat with Oli; I have no idea.
You should really release it May the 4. ^^
MIR is a simplified representation of the Rust code that the compiler uses internally. MIRI is an interpreter that can run this simplified form of Rust, that is able to interpret most Rust, including all kinds of heap allocations, panics, ... By including this interpreter in the compiler and using it to evaluate constant expressions including const fn, this makes the compiler much more powerful, eventually allowing most functions to be called at compile time. So you could imagine building a whole Hash Map at compile time, and then using it at runtime. This will open up a lot of possibilities.
There is a somewhat quiet room on irc.mozilla.org for #rust-embedded (I'm pinkhatbeard). I'd say this subreddit and the github issue tracker I linked to before would be the closest to a forum. We should probably make a list of all this stuff some place. I believe the other person I mentioned in my original comment was also working on just LoRa and not LoRaWAN also, I haven't looked at any of their work in a while so I'm not sure how far it got. Do you have any code up anywhere yet? I'm not an embedded or Rust expert by any means, I've only gotten into both of them in the last couple of years...so don't get your hopes up too high about me. :) I do have an electrical engineer and a couple of LoRa experts at my disposal though. Hopefully we can all stumble forward together. haha.
You don't need to remove a node from vector when you remove it from the list. Just adjust the indices inside neighboring nodes as you would adjust pointers. You can manually delete nodes from the vector when you feel like it (kind of like a garbage collector would) or keep them until the whole vector is deallocated.
Things like compile time compiled regular expressions.
What's the link between regex and Star Wars?
Yes, it's called a [linear bounded automaton](https://en.wikipedia.org/wiki/Linear_bounded_automaton). (And no, it doesn't literally solve the halting problem.) 
I wanted to test my first code by creating a simple calculator. I want the user being able to enter an operation, reading this operation then displaying the result. For that, I wanted to split the string an add results in a vector. The vector contains InputType which is an enum composed of InputType::Operand, which has a generic type because I want it being floats or integers, and InputType::Operator, which is a string slice. Here is the code: https://gist.github.com/Booteille/8d46ab33d5959c4059c969910bf09264
The release date, potentially.
[removed]
No, I suspect not. The whole point of that crate is to be unstable. It is a very explicit decision that `regex` has no public dependency on `regex-syntax`. In other words, the API is the concrete syntax of a regex pattern and nothing else.
Why evaluate at runtime what can be evaluated at compile time?
Excuse me, I am very excited about this but I am not sure about its possibilites. Would it be possible to check if an access in an array will not be out of bound and therefore we don't need to generate assembly code that checks it? array [i32: 10] for i in 0..10 { read array[i] } Will we be able to prevent this code from checking array bounds?
Nowhere is safe from the billion dollar, profit-driven cinematic franchises it seems.
You might be interested in this talk: https://www.youtube.com/watch?v=EnL2mhkyeuE
&gt; It is a very explicit decision that `regex` has no public dependency on `regex-syntax`. Errmm, actually, this isn't technically true. There is a `impl From&lt;regex_syntax::Error&gt; for regex::Error`, which does make `regex-syntax` a public dependency of `regex`. That was an oversight. I added that to the list of breaking changes to make for `regex 1.0`.
Thanks for your answer, I've found a workaround by using enums.
I believe this happens already for arrays (as the length is part of the type), but noy for slices or vectors.
Isn't this the same as http://stevedonovan.github.io/rust-gentle-intro/readme.html 
Oh no, I wasn't suggesting anything so fancy, I already had a solution in mind for what I was trying to accomplish. But a queueable iterator would've made things a lot easier.
&gt;The answer to that question is no. We donâ€™t expect Rust WebAssembly apps to be written completely in Rust. In fact, we expect the bulk of application code will still be JS, even in most Rust WebAssembly applications. What is this cop out? Yes, I absolutely want to *only* write my web app in some decent language and no I don't expect most new things to be written in the abomination that is JS once people can finally chose what they want (most people probably won't chose Rust, but that's besides the point).
*Sure* it does. `Arc&lt;T&gt;` is only six characters while `.clone()` is eight. *Clearly* it prefers `Arc&lt;T&gt;`.
That all makes sense. It might be worth taking a look at what other crates are using `regex-syntax` for, as this could reveal API deficiencies in `regex`. For instance, `fd` only uses it to implement [`pattern_has_uppercase_char()`](https://github.com/sharkdp/fd/blob/87d0ccd4c0d885aee72c88b3ec71f7a78f11a15b/src/internal.rs#L101-L126) for automatic case sensitivity, and IIRC you do something similar in `grep`.
Thanks. found it I think [Reaching const evaluation singularity](https://www.youtube.com/watch?v=Zz863ksXRhA).
Can someone tell me what the fuck is going on? Miri? PR? Succinct? Turing? What evaluation? What does nightly rust mean? Jesus did I just have a stroke? I just play rust 
I think I may be on the wrong subreddit
Yes, I do occasionally look at them from time to time, but I think querying the AST/HIR for certain properties is exactly the intended use of `regex-syntax`, and I'm not sure it belongs in the `regex` crate proper. I mean, there just aren't enough uses of `regex-syntax` in total to form (IMO) a compelling argument that *any* of those use cases deserve a new public API in `regex`. e.g., I am probably personally the biggest consumer of `regex-syntax`. If some significant fraction of users of the `regex` crate started to depend on `regex-syntax` directly too, then of course, I would change my tune. :-) w.r.t. to detecting uppercase characters, that is a good example of a routine that shouldn't be defined over `Hir` but rather, over the `Ast`. You can my implementation (fresh as of last night) here: https://github.com/BurntSushi/ripgrep/blob/master/grep/src/smart_case.rs
Pre-RFC: Deprecate `.clone()` in favour of `.cln()` to improve ergonomics and consistency with prior decisions like `fn` and `i32` and friends.
Glad to see other opinions on that matter. I think i put myself into a little echo chamber (with (programmer)friends and coworkers) that i really want to abandon the javascript ecosystem. I think i am programming in javascript every now and then for like 10 years professionally. This includes mobile apps (titanium, cordova, extJs, ionic, react native) websites (angularJs, angular (&gt;=2), ember, backbone, react, vue.js ... ) and backends (meteorJs, expressJs ... ) and the experience was not really great up to real horror. I don't really know why i still stick to it to some degree, maybe its because it is really easy to access but if your systems grows it really tends to be unmanageable. In my last meteorJs backend i really felt that at around 10k lines of code refactoring and adding new features really becomes somewhat "viscous" and without really good tests everything tends to break apart. And this is just me unable to manage growing JS projects let alone various "hickups" in the npm ecosystem that drove me nuts. I don't want to hate on Js here but i really feel its not the ecosystem i want to be a part of for any longer and i don't think i am making a quick decision here. I am just comparing my experience to other languages i used, especially Java. I am working on a ~1.2 million loc codebase currently and i don't feel the same pain i got from projects in Js nearing the 10k loc. I hadn't much opportunities to write large amounts of Rust code â€“ i think my last project at work was like ~15k loc â€“ and it felt really really good to be honest. If the tooling for "rust web" gets better i think i could easily change to rust "full stack" without thinking about it. 
I'll take the blame for making that use `Hir` -- it was just the most direct way to port from the former code using `Expr`. I believe you that `Ast` is the right way to do this, but it looks more involved. Maybe case-detection is worth an addition to `regex-syntax`?
The [Halting Problem](https://en.wikipedia.org/wiki/Halting_problem) has a long-established conventional definition: "In computability theory, the **halting problem** is the problem of determining, from a description of an arbitrary computer program and an input, whether the program will finish running or continue to run forever." If you restrict the class of programs then you're not longer accepting a description of an *arbitrary* computer program.
&gt; Maybe case-detection is worth an addition to regex-syntax? /shrug I don't know. It is easier to say this as a consumer of the crate rather than as the maintainer. It doesn't really feel right to me, and feels too niche. With that said, I have started adding [predicates, beginning with `is_` to the `Hir` type](https://docs.rs/regex-syntax/0.5.3/regex_syntax/hir/struct.Hir.html) that report various facts of utility about the Hir. It wouldn't be a huge stretch to start doing that for the Ast, but the bang-to-buck ratio isn't as great since you typically _don't_ look at the Ast. The smart case stuff is a special case. It looks more involved because the AST is much larger than the HIR. But the algorithm is the same: structural recursion over a sum. :-)
Inspired by an article I read recently about cache-oblivious data structures, I'm trying to implement a 2,3-tree like that. Because it is backed by a vec, I need to figure out how things shift around as new values are inserted, and am having a lot of fun trying to find useful patterns. 
Truly magical 
It is also conceivable that the `grep` crate could expose its smart case detection more explicitly. It is going to be rewritten at some point to be much more powerful (basically folding all of the search code in ripgrep proper into `grep`), so adding a new public API item for smart case detection feels OK to me.
I'm not fluent in the codebase, but would it be possible to build the regex (Regex::new()) compile-time (using macros) rather than run-time?
Anything's possible. It is nowhere near the top of my priority list.
The `.clone()` war was so much cooler when I didn't know what it was about.
&gt; I don't expect most new things to be written in the abomination that is JS I'm really sad to see this kind of sentiment showing up on Rust forums. JS has a lot of strengths, not least its massive ecosystem. This is not a zero-sum game!
And ofcourse the intention is not to replace JS. But to plugin wasm where you feel that you need higher performance and that cannot be achieved by writing `understandable` JS.
In addition to what others have replied, evaluating things at compile time also means *checking* things at compile time. Regexes are a good example, since it's actually quite easy to get regex syntax wrong.
Why not drop the const keyword and allow running any regular function? If it tries to do something bad, like ffi call or allocation, the compiler can just show the error message.
Heh, I first got involved in Rust in 2011 while at a job using IBM products (RPG on System i, and later PHP on AIX on System i), and I must say that seeing a Rust article on DeveloperWorks feels like a surreal culmination of that time. :P I'll have to forward this to all my old co-workers...
Sometimes people create a special module with just a lot of `pub use` in it and than reference that module from the other modules. Such modules are called preludes. Like this: // prelude.rs pub use tcod::console::*; pub use tcod::colors::*; // and more stuff // mod1.rs use ::prelude::*; // mod2.rs use ::prelude::*; 
https://xkcd.com/1266/
It will actually work as you think in the future, you can try adding `#![feature(nll)]` at the top of your crate to get a preview of a new borrow checker. This requires nightly though. On stable, you'll need to reduce the scope of `histo` with a `{}` block to make it work. Remember, currently the borrow checker looks at the variables, not values, so the mere existence of a variable in scope is considered as a alive borrow.
One of the advantages to rust is being able to catch errors at compile time. We'd be throwing that out when evaluating const fn's. Also there's no reason you couldn't allocate, at least in theory- it's just that the allocation needs to be inaccessible after all the const evaluations, or it needs to be placed in static data section.
I sure hope so. There were some hair-raising responses lat time.
I am trying to allow a clippy lint, `assign_op_pattern`, through in one function in my code. Whenever I write #[deny(assign_op_pattern)], the compiler tells me `error: manual implementation of an assign operation` along with an extensive note that clearly indicates it knows about `assign_op_pattern`. However, in the same compilation, it also says warning: `unknown lint: assign_op_pattern`. When I try #[allow(assign_op_pattern)], it will show both of the above as warnings.
This may be a clippy bug, although it sure sounds strange â€“ do you have a code example to look at?
I found it in [Federico's Mastodon feed](https://mastodon.social/@federicomena), where he is regularly praising Rust :) Here is the Mastodon account of the blogger: https://mastodon.cc/@alatiera Hot tip for recruiters: it says "Looking for a Job"
`use super::*;` is a slightly shorter and more uniform way than naming parent modules every time. Modules serve as "name barriers" by default, but `use super::*;`s allow to explicitly switch the behavior to more "transparent" C++-namespace-like model. (Whether it's idiomatic or not in Rust is a separate question.)
I'm sorrybut as far as I know it also happens with arrays
Hah. I use a condensed version of that quote all the time. The `0.2` release has been out for quite some time now (over a year), so I have some reason to hope. :-)
`const fn` indicates intent that you want this function, and future versions of this function, to only do stuff that can be done at compile-time. Make a `const fn` not `const` in a public API is a breaking change.
Using char_indices() this is the best I've come up with. fn char_slice(string: &amp;str, start: usize, length: usize) -&gt; &amp;str { let mut indices = string.char_indices().skip(start); let byte_start = indices.next().unwrap().0; let mut indices = indices.skip(length); let byte_end = indices.next().unwrap().0; &amp;string[byte_start..byte_end] }
:-) Hope springs eternal ...* * Condensed version. Full version: https://en.wikipedia.org/wiki/Hope_Springs_Eternal
I don't think rust or wasm should aim to completely replace JavaScript. JavaScript has a lot of inertia and won't go easily, regardless of its faults and merits. But I also don't think rust or wasm should actively avoid replacing JavaScript. A lot of people feel that JavaScript is too poorly designed for the the things it is used for today and wish for an alternative to completely replace it with, and I think Rust should not shy away from attempting to provide that alternative for the people who want it. Like, Rust is not as hesitant where it comes to C and C++. When the call for Rust 2018 blogs was issued, and somebody expressed the opinion that we should aim to have Rust basically replace C and C++ by the end of the year as the systems programming language of choice for new projects at least, no one said it was a bad idea or something close to violating the Rust CoC. Instead, it was praised as a great ambition. Why can't JS be seen as another outdated language that Rust might just replace if everything goes right? I think that might be a good long-term ambition of the wasm usecase.
Thank you c0d3g33k for voting on WikiTextBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Could you post an example of code you would want to write, but are not able to because of [E0162](https://doc.rust-lang.org/error-index.html#E0162)? I can imagine code that triggers the error, but not code that I would want to write.
what kind of impact are you expecting from this? Performance ? Simplicity ?
Why would they break with rust conventions in the examples and do newline braces? ``` fn main() { } ```
might be because the original "Hello World" was also written that way
[This](https://play.rust-lang.org/?gist=a90ae11d76120b15fba4631a7642a241&amp;version=stable) example is not as minimal as it could be, but I think it's a good example of when you would want an irrefutable `while let` pattern.
You're right that `if let (x, y) = z` is the same as `{ let (x, y) = z }`, but so is `if true { let (x, y) = x }`, and that last one is allowed. I think that especially in the `while let` case, having the iteration variable(s) be part of the condition is clearer than just having a `let` near the top of the body (where you would put all your other variables). The biggest thing for me here, though, is consistency. `if let` act's like `if`, but it's different in some not obvious ways, such as lacking certain `if true` equivalents, but having others (`if let Some(x) = Some(1)` is allowed, but `if let x = 1` is not).
Mostly compile-time safety? Performance is also nice (but not notable on its own, as you can lazy_load!)
Sounds reasonable then! I'd support turning this into a warning or deny-by-default lint rather than an error, for the sake of consistency.
Older versions of the regex crate had a \`regex!\(\)\` macro that did exactly that, and compile\-time\-written regexes were faster than runtime\-written ones. However, then /[u/burntsushi](/user/burntsushi) did a round of optimisation work on the runtime\-written regex system, making it vastly faster than the \`regex!\(\)\` macro. Rather than do all that work all over again, later versions of the crate just dropped the macro.
`&amp;Gamepad` is a reference to data which _lives inside `Pong`._ This is what's extending the borrow - you still have data inside Pong which is being used, and if someone did removed items from the `Vec&lt;PlayerData&gt;`, or added items to it and caused it to re-allocate, all of those `&amp;Gamepad` references would point to uninitialized memory. Perhaps you meant to be storing a `Rc&lt;Gamepad&gt;` within `Player::Human`, so you could clone the Rc rather than having to make a new Rc with borrowed data?
&gt; Mostly compile-time safety? FWIW, I believe clippy has a lint that will check literal regex patterns for you.
It's probably impossible and/or a pipe dream, but it would be awesome to have a pared-down version of `regex` that supports `no_std` environments, with a dependency on `alloc` if necessary. I found myself looking for regex-like functionality in a bare-metal environment the other day, but I know the current form of your crate has many many deps on `std` features.
I think a warning would be nice, something that you could `#[allow]`, like `dead_code` and `unused_variables`. Consistency is a major factor for me, both in the language and in my code. In that language through the allowance of all forms of `if true`, or none of them, and in my code by not having to break from the `while let` pattern of iteration just because my iterator has some special conditions that I apply to it (here, that it may not end before a certain character is reached).
To be completely clear, I was making a joke :)
Ok, I fixed some unrelated issues and found that #[allow(whatever_clippy_lint)] now works for me, but it still warns me `unknown lint: assign_op_pattern`. For minimal example: in Cargo.toml: [dev-dependencies] clippy = { version = "*" } in lib.rs: #![cfg_attr(test, feature(plugin))] #![cfg_attr(test, plugin(clippy))] #[allow(assign_op_pattern)] pub fn uh() { let mut a = 0u32; a = a + 1; assert_eq!(a, 1); }
I mean, the AST/HIR itself requires `Box&lt;...&gt;`, so, `alloc` would absolutely be required. Writing a regex engine without a dependency on dynamic memory allocation basically requires writing **everything** from scratch with that constraint in mind, and there would be significant ergonomic trade offs. Therefore, the only way I can feasibly see that happening is to maintain two distinct implementations: one that relies on dynamic memory allocation (_all_ the way down to the parser) and another that doesn't. And let me tell you, that certainly ain't happening. ;-) I would think it would be better to write a custom allocator with a fixed allocation amount at startup, and then just the regex crate use that. (Which still qualifies as dynamic memory allocation, at least, I think.) Creating a regex crate with just a dependency on alloc has definitely crossed my mind. Perusing the `std::` imports suggests that very few of them are actually `std`-only. The only one that really sticks out is the `Error` trait, and it seems like that could be worked around. What other `std`-only features did you have in mind? I am toying around with the idea of a `regex-lite` crate too, but not necessarily as something that works in bare metal, but rather, something that compiles more quickly at the expense of reduced runtime performance. In theory, it would be possible to drop the `std` dependency there too though. In any case, none of this stuff should require breaking changes, so I think it's mostly orthogonal to the regex 1.0 release. I also generally avoid working with nightly-only APIs (SIMD being an exception) because I just don't have the bandwidth to do it. I believe `alloc`-only crates require nightly at the moment, so I'm not particularly motivated to work on it.
What's interesting is that they stop this later, and then eventually cite rustfmt...
given that clang can be compiled to wasm, it's only a matter of time before all of rustc, miri or not, can be...
Also, could you say more about your use case? Do you know of other regex engines that can be used in a bare metal context? As my last comment suggests, I am definitely interested in this use case and would love to hear more about it. I just don't know when I'll act on it. :-)
I understand that some people have had negative experiences, but what I'm talking about is referring to other languages as "an abomination" or otherwise making one-sided, unstructured critiques. Every language has its issues, and in the Rust community we strive to treat each other, and other language communities, with respect and empathy.
Same article. "The halting problem is theoretically decidable for linear bounded automata (LBAs) or deterministic machines with finite memory." The program for a linear bounded automaton _can_ be arbitrary. It halts for all programs. It's the _computer_ that's different. You can apply the halting problem to any form of computation.
&gt; Rust is not as hesitant where it comes to C and C++. &gt; Instead, it was praised as a great ambition. I don't think that's true. Our approach to C and C++, just like everywhere else, is to pursue *incremental* adoption, where people use Rust for the components where the cost/benefit ratio is strongest, without having to rewrite their entire code base.
`#[cfg_attr(test, allow(assign_op_pattern))]` should work for you, then.
Use case: research OS implemented in Rust. Could be many others in the embedded world. No, I don't know of other regex engines that have no stdlib dependency.
True, this isn't necessarily a suggestion for v1.0. Yes, nightly use would be required, which is a typical requirement for us in the bare-metal world. A dependency on `alloc` is totally fine, I'm not sure why I even suggested that initially (maybe because some embedded environments are extremely constrained and cannot allocate memory dynamically, but those environments likely would have no need for regex anyway). 
Right, my comment above about `Iterator::next` is on what you should expect in the next few months. Iâ€™m sure weâ€™ll figure something out eventually to enable `for` loop in `const fn`.
Yes, that's why I'm talking about new projects, where incremental adoption is the same as basically adoption. I'm mostly talking here about [this](https://www.reddit.com/r/rust/comments/7p6n90/rust2018_back_to_the_roots/) post that has this kind of quote: &gt; Starting a new systems project in 2019 that uses C or C++ should make everybody raise their eyebrows and not the other way around. When I look at the comments there, I don't feel like this kind of ambition is discouraged in the Rust leadership or community in general. It may not be an explicit goal, but neither is it considered a bad idea. I feel like in the case of Rust replacing JavaScript via wasm, people are suddenly a lot more cautious, which seems strange and somewhat stifling to me.
Thank you that makes sense.
 &gt; 15!! 15!! = 2,027,025 &gt; 1!! 1!! = 1 
How is this different to https://github.com/koute/stdweb ?
This is honestly kind of ridiculous. regex went through the RFC process to establish its 1.0 API. 0.2 has been out and in the wild with that API for over a year now, and there are no outstanding issues that have wanted a change in that API. The very release includes the planned breaking changes, which are all very minor. regex is probably exactly the opposite of being "rushed." I announced a release date because I am fundamentally not perfect, and would like to give everyone a chance to get a word in if I've missed something. &gt; Once you set a specific date as the release date / deadline, you have to stick to it or disappoint people if you don't. I hope, and even expect, that most people couldn't give a hoot about regex 1.0 because there are no planned major changes. The transition should be supremely boring, and the worst thing that's going to happen is that some crates will be compiling multiple versions of regex until everyone moves over to 1.0, which will negatively impact compile times, but not much else. (regex is rarely a public dependency.)
Wrong subreddit, you want /r/playrust 
Thank you for your response. OK, I see, I can agree with you about regex. I perhaps shouldn't have spoken at all, since the regex crate has existed for at least 3x as long as I've been using Rust at all. You have been part of this community for ages and I really respect your work. I am quite dissatisfied with failure though, for the reasons I described (which I can now agree don't apply to regex at all, sorry for accusing you). Seeing a similar headline promising a release date for 1.0 made me naively compare the two and write an emotional response. I should not have done this; the two situations are not the same. I will do my part about my dissatisfaction with failure, though. I have recently come up with a solution that works for me and will probably publish it sometime soon. Maybe others will find it useful. 
well performance was not the prime rationale ofcourse. It is performance with maintainable code. I am a JS dev, I do understand we can make JS work almost in the same speed compared to WASM. But the code will highly likely be difficult to read and maintain. OTOH, with wasm you can get this speed out of the box. 
What issues did you have with React and React-Native? I really enjoyed that with Redux. I got a bit tired of the churn and rate of change with libraries/frameworks and prior to React wasn't having the best of times, there was a bit too many moving parts that would likely not be a useful skill/technology in demand within 3 years time as most move on to something else. I remember there were so many things just to have a modern web stack to begin with, when something in that broke or was to be replaced, that might not be fun. I remember a particular library that provided some websocket support that broke with some update, the maintainer was quite active on Github yet for 6-12 months ignored the issue, they were the only one with commit rights, users had already provided a PR fix and tried to reach the dev via various channels, all they had to do was merge it and make a release or pass on maintainership to someone else.
&gt; Not perfect, but it's going to be years before writing a 100% rust web UI is practical. I guess it doesn't count, but Qt is looking at WASM I think with some sort of streaming UI from server to client? Meant to bring Qt to the browser, well QML perhaps. Perhaps that'd be an option with an existing Rust crate once available?
Thank you! This really motivates the design decision.
From the main page of https://github.com/alexcrichton/futures-await &gt; You can also have async methods: impl Foo { #[async] fn do_work(self) -&gt; io::Result&lt;u32&gt; { // ... } } &gt;You can specify that you actually would prefer a trait object is returned instead, e.g. Box&lt;Future&lt;Item = i32, Error = io::Error&gt;&gt; #[async(boxed)] fn foo() -&gt; io::Result&lt;i32&gt; { // ... } What does this actually mean?
&gt; Is the KDE maintained Rust Qt project not in a good state yet? Here's a presentation on it from last FOSDEM. https://fosdem.org/2018/schedule/event/rust_qt_binding_generator/
Then they might as well release it today on pi day
To be fair no physical computer is Turing complete as all physical computers can't solve any problem which takes a large non infinite memory or time
Certainly not "always", unless you're referring only to Rust libraries.
I had a similar situation when I wrote my SWF parser. The files are made of records. Each record (tag) has a header with a code and length, followed by the tag data. The interpretation of some tags also depends on the SWF version or previous tags: this kind of data does not immediately precede the tag. I solved it by defining a `State` struct holding info that may be used to parse further things. My tag parser is then defined as a normal function (not using macros) that accepts both an input and a state. It has the following signature: ```rust pub fn parse_swf_tag&lt;'a&gt;(input: &amp;'a [u8], state: &amp;mut ParseState) -&gt; IResult&lt;&amp;'a [u8], ast::Tag&gt; ``` I parse the tag header and then use it with the state to either ask for more data or build a sub-slice on input and parse it. I know that there are some macros to help you chaining functions starting with an input but requiring more arguments, you can look it up if you prefer to use the parse macros. [Here is the code in case you're interested](https://github.com/open-flash/swf-parser/blob/349ec981b090f498f3720078b43f90bee5675815/swf-parser.rs/src/parsers/tags.rs#L47)
&gt; In any case, none of this stuff should require breaking changes, so I think it's mostly orthogonal to the regex 1.0 release. If some things will need to be gated by `#[cfg(feature = "std")]`, like implementing the `Error` trait, then this should be done before 1.0. It's a breaking change for `default-features = false` to lose functionality later. You could just crate a default `std` feature that gates the entire crate for now, and then figure out the real `#![no_std]` subset later.
The simple way, and almost certainly the best way: don't do it with nom. Have your `header` parser that returns the header information, then use that to slice up your buffer and then feed it to your nom parser. You're still writing Rust code, you don't need to replace _everything_ with combinator macros.
I'm putting the finishing touches on the "alpha" version of [Inquisitor](https://github.com/George3d6/Inquisitor) a monitoring software package written in rust (except for some web stuff). I'm hoping that before Friday it will be finalized enough so that I can make a stand-alone post in here and share it with some friends in order to get insights as to why it is terrible and how to fix it. Currently I'm using it to monitor some internal infrastructure and it's behaving quite well, so I can't say I'm not pleased with it. Also, doing a piece that places spread-bet orders on Ig.com since I'm not comfortable enough to entrust a .py file with my money :p
[The RFC making irrefutable patterns in `if let` and `while let` a deny-by-default has already been accepted!](https://github.com/rust-lang/rfcs/pull/2086) It just needs to be implemented ([[tracking issue](https://github.com/rust-lang/rust/issues/44495)). The main reason given in the RFC is in macro-generic usage.
Ooooo! Great call! This just made the release announcement totally worth it. :-)
It is built using [Hugo](https://gohugo.io/) (golang static site generator) with this theme https://github.com/matcornic/hugo-theme-learn/
I just feel like maintainer hogging all the progress on all front. Editor extension, nah you are not good enough we'll do it. Webassembly, nah you are not good enough we'll do it. Good interesting cargo packages, nah you are not good enough we'll do it. It'll discourage a lot of people. 
This was [cross-posted to Stack Overflow](https://stackoverflow.com/q/49223801/155423).
What about a `indexmap::IndexSet` and `Vec&lt;Option&lt;usize&gt;&gt;` for accessing by index? Not a perfect solution, but better than `Vec&lt;Option&lt;Item&gt;&gt;` + `HashMap&lt;Item, usize&gt;`.
I know of at least one IBM project that is using Rust. Cool to see a blog post about it!
A [Rust implementation](https://github.com/dstar4138/standardfile) of the [StandardFile REST server API](https://standardfile.org/). I've been trying to find a clean way to provide the user with an option of backend (i.e. sqlite, mysql). I think I finally figured out how to do it in diesel, just had fight with type system a bit. It is still ugly to build and run though.
[`syn`](https://docs.rs/syn) and [`quote`](https://docs.rs/quote) are widely used for reading / generating rust code respectively. They are the go to libraries for any procedural macros - the most common way of modifying or writing rust code I know of. As for expression trees and dynamically creating code at runtime: this does not exist in Rust. You could potentially link the entire rust compiler and compile additional rust code, but there is no infrastructure to do that. Rust doesn't have a runtime to support dynamically created code (it doesn't really have a runtime at all), and so it'll be much harder to do that than in more dynamic languages. I'd say it's also an unexplored area, because doing code generation at compile time with `build.rs` and/or procedural macros is fairly simple in comparison.
&gt; The result is a C-like language that supports multiparadigm programming (imperative, functional, and **object oriented**). ðŸ¤” I definitely would not characterize Rust as fitting into the object-oriented paradigm.
I don't think "default format changes are breaking changes" should be that controversial; there's only a few fields so universally useful that you'd want to include them by default, and only a few possible orders they could appear in. Most of the potential format changes would be adding or removing decorative text like the square brackets in your example, and I'm finding it hard to imagine cosmetic changes so valuable as to outweigh the costs of breakage. Even in a major\-version release I'd think twice about changing the default format. People who are thinking carefully about machine\-consumable logging are probably already using a custom format instead of the default, or even using \`slog\` instead of \`log\` so they wouldn't be using \`env\_logger\` in the first place. Nevertheless, there's always going to be people who got something working, pushed it into production, and then realised they needed monitoring and alerting; those are the people that a change to the default format will frustrate and annoy. Although \`env\_logger\` is not a public dependency in the sense of [https://crates.io](https://crates.io) it's still part of the interface between a program and the rest of the system around it.
You can do OOP in Rust. I don't know why you would... but you can.
Reading through the `wasm-bindgen` docs was really insightful about what some of the challenges with wasm currently are (simple memory model and simple type system) and how you can use code generation to get around them. It seems like once wasm itself matures a little more it could quickly build up an ecosystem of libraries. What's really interesting is that eventually we could have projects written in many different languages that compile to an NPM package and can be used and shared by everyone. I think the ultimate goal of the browser is to become a universal operating system, and wasm is the assembly language for that operating system. We're getting closer and closer to web apps and native apps being the same thing.
And the halting problem can be solved on all physical computers. It might require running the program for ~2^32^32 steps (a rough approximation of the number of different states a computer with 2^32 bytes of memory can access), but eventually the program will either terminate, or all of the computers state will be the same as a previous state and we can say we are definitely in an infinite loop.
This is cool. /u/llogiq - does this have any applications in [mutagen](https://github.com/llogiq/mutagen)?
You can also do OO in C. It still feels distinctly Cish with manual boilerplace, but it's entirely possible. 
Probably with the caveat that this, like any interpreter, wouldn't be guaranteed to catch all instances of undefined behavior. What it'd catch would depend on which code paths are exercised, which data is computed on.
Nice ! Will it work on (current) Linux ?
I think this is a really great work! Love it! It is a major break through in fuzzing and find a good balance between program analysis and execution. Not too black, not too white; the solution is in the middle :-) Moreover, it introduces several ideas that are individually very interesting. Are you planning to release the source code (even partially)?
I've got no clue as to what the segfault is, but I imagine it might have something to do with `gtk` just not liking any locking on its graphics thread. If that's the case (someone else who knows more will need to actually see), you might want to try using a `mpsc::channel()` instead. If `new_eqns` is purely for sending things from one thread to you graphics thread, could it be replaced with a channel of `String` to send over, or a channel of some `enum Event { Add(String), Remove(String), ... }`? I find the channel architecture to be easier to work with overall, which is why I suggest it - but if gtk has a problem with blocking, using channels and not blocking on them could be a good alternative.
My preference is just to import everything in files, and keep that in mind when deciding to split out things into separate modules. Some ideas: 1. 3-5 lines of `use tcod::console::Console;`, etc. is pretty reasonable if you have 200-300 line files. If you have so many files that these lines are nuisance, I would consider rethinking that design choice. Something like this would be usual for almost all files I write: use std::{cmp, fmt}; use rand::Rng; use tcod::{colors, console::Console, colors::Color}; This seems more like explicitly showing people what you use than anything else, to me. 2. Think about whether you're separating files based off of logical separate concerns. Ideally separately-concerned files will need to import a different set of things, so you won't be so much duplicating imports in each file as much as you are importing the specific things each file needs. 3. Possibly use the semi-more-rustic style of importing modules, rather than all objects themselves. If you were using a bunch of generic-named stuff from `std::fmt`, for example, just stick `use std::fmt;` rather than `use std::fmt::X; use std::fmt::Y; ...` or `use std::fmt::*;` Take a look at the following: use std::fmt; impl fmt::Display for X { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { write!(f, "hello") } } This could have been much shorter if we had imported `std::fmt::{Display, Formatter, Result}`, but it wouldn't have necessarily been _clearer_. 4. If you really do want to import everything into every file, and not have to specify it over and over, I'd go with /u/diwic'd solution. Just stick something like this in `main.rs`: mod prelude { pub use tcod::console::*; pub use tcod::colors::*; pub use {object, map}; } and then `use prelude::*;` everywhere else. People reading your code will loose some clarity by not being able to immediately see where all types come from, but I assume you are aware of that trade-off.
Not sure if you'd be into working on solving this but for me the number one blocker at the moment is the lack of a good REPL.
Let's not call it a "workaround". It's the way it works in languages with a strong type system.
But I don't think that application should crash on start. I suppose author should report issue about one of crate that is uses. Something should be marked as `!Sync`.
Too strongly worded I guess. I wasnâ€™t aware of any commonly-used parser generator that generated top-down parsers, but I guess things like Boost.Spirit qualify. Though Iâ€™d classify it as a parser combinator library, like nom in Rust, rather than a traditional parser generator.
&gt; I am quite dissatisfied with failure though, for the reasons I described (which I can now agree don't apply to regex at all, sorry for accusing you). The thing is, this is a "do it, you're doomed, don't do it, you're doomed too" situation. One half of the community is angry about crates eternally hovering in `0.x` version status, waiting for the "perfect API" to go to `1.0`, and signaling "Rust is still very unstable" to people who confer a lot of significance on version numbers. The other half, like you, likes to be more cautious about locking in APIs and thus going to "stable" versions in a finite amount of time. And let's face it, a well-publicized deadline is a good way to get something done with as much community input as possible. It's no different from Rustc's 6-week release schedule, and it's not like failure 2.0 can never happen.
There are many, many things. I listed some of them here https://github.com/not-yet-awesome-rust/not-yet-awesome-rust#machine-learning Basically anything you can think of is either missing or in lackluster state (except maybe matrix multiplication libraries like NdArray and SPRS). Also any more high level library fails to use these as dependencies, which makes matter even worse. Also depending whether you care about tradional or deeplearning, you have two choices: a) tradional - we need good sklearn equivalent. You basically have to start from scratch, both alternatives are unmaintained and suffer from "lets invent our own numpy problem". b) deeplearning - my lowlevel CNTK wrapper exists: https://crates.io/crates/cntk. You might contribute with something more highlevel if you want. Or you can make wrapper for something else (MxNet for example). Tensorflow wrapper would be futile right now, since there is not way to diffentiate RNNs in C API. Or you can build equivalent of Chainer in Rust, but that is massive undertaking (if you also want good CPU support). For bigdata wrangling there is https://www.datafusion.rs/, but it is in early stage. 
Definitely agree with this! I've got no clue what would cause this issue, and it seems like a bug. Blocking isn't generally a great thing to do in UI threads in general, though, which is why I suggest channels. (even if using a mutex is fully valid, it might not be a good idea?)
Yeah, I think I had 'not hand-written' more in mind when I replied than 'parser generator' in particular.
Datafusion addresses or kind of usage I had in mind! Algorithmically I'd say that I am more interested (and I believe it's more fruitful) to contribute to a Rust equivalent of Scikit-learn. Do you believe that two projects you mentioned should be recovered or is it simply better to start from scratch?
I'm not sure about the Rust bindings, but I know GTK+ makes thread-safety somewhat optional for performance reasons. https://developer.gnome.org/gdk3/stable/gdk3-Threads.html
Ah ah! Right!
No. The Halting problem is first of all just a problem statement with two components: a machine and a program. The questions is whether I can decide it for a set of programs (usually all possible ones). We know that it is undecidable for general computation. A common misconception is that the halting problem itself describes a turing-equivalent machine or all programs in the world. It doesn't. It's application to both leads to the classic conclusion that it is generally undecidable. Choosing a machine where I can decide the halting problem for all programs is _not_ a work-around. It is an important application of the halting problem. You can totally call that "solving" it. Proving that the halting problem is decidable in these cases is _crucial_ for the construction of these machines. Another feasible way to make the halting problem decidable is restricting the program. If I restrict myself to programs that always quit after 500ms, the halting program decidable. Also note that the halting for `loop {}` is decidable (it never halts). The halting problem is also not "does every program under inspection halt", but "do I know if it halts or not?". So making the halting problem decidable is not enough for making sure const_fns halt. 
I'm not familiar with gox, but isn't this something similar to what https://crates.io/crates/cross is doing using Docker images?
`if true {}` is not the same as `if let Foo(..) = foo {}`. The former is irrefutable because of the _value_, the latter is irrefutable because of the _type_. If you want to scope your variables, just use a block + `let`.
Very interesting. I love seeing academic work done in Rust, but this by itself stands on its own :D
`const fn` can also be useful for not-so-complex things, for example initializing a `static` item whose type has private fields.
This time, instead of a language tutorial, we're working through a snake game! Enjoy :)
It does, in the sense that some const evaluation bugs are fixed. (For example some cases previously caused an ICE.) But it has explicit check to not (yet) allow language features that are implemented in miri but not AST-based const eval.
I took note of Timely Dataflow, quite impressive on its own, but it's a bit of a "plus" if you are missing the basic building blocks for expressing data preprocessing tasks and ML models.
I second /u/BobTreehugger. TypeScript is an excellent programming language, with great tooling support, and a huge community. It's also backed by Microsoft, with some major projects being built purely in TypeScript (Angular, VS Code) -- which means it isn't going anywhere soon. TypeScript is so good that I flat out refuse to work with plain JS codebases these days, unless I'm forced to. If you can't use TypeScript where you work, you can always sneak in Facebook's Flow, which might be less intrusive.
Really like the format of this. It's not too fast and not too slow, and teaches you to look up stuff instead of just telling you to copy paste some code. Cool tutorial!
Thank you!
From stacktrace looks like you are using `libX11`, it is not thread safe library, so creation of two windows in different thread obviously undefined behaviour. You should call `XInitThreads` before any call and use `XLockDisplay`. Because of you use `libX11` I suppose you have choose another GUI library or create windows in one thread. And do not forget report this issue gui libraries authors. But in fact such scenario buggy for GUI programming. I suggest create and use windows in one thread. And pass information from background threads via event message queues that should be provided by GUI frameworks/libraries.
Since they do not on top of other numerical crates (like NdArray) I would suggest rewrite from scratch. I have a prototype with couple of algos on my machine but do not have enough time to push it into reasonable state.
There was a startup called [Autumn AI](https://github.com/autumnai) who tried to do machine learning in Rust. Sadly, they went out of business. But their technology remains, maybe it's of interest to you.
&gt; We also tested Angora on eight popular, mature open source programs. Angora found 6, 52, 29, 40 and 48 new bugs in file, jhead, nm, objdump and size, respectively. Wow.
I must admit that, even after reading the documentation and the source code, I have no understanding of what this crate does and what problem it solves. Maybe a complete example with a use case showing how it simplifies things would help.
Starting a project in C or C++ means that all the security risks inherent in these languages will be present in the new project. There will be undefined behavior, there might be glaring security holes. Rust would prevent these. JavaScript does not suffer from this problem. Starting a new project in JavaScript just means you're using JavaScript, in all its glory and all its horrors. But JS doesn't have undefined behavior, it doesn't present any security risks that Rust doesn't have too (i.e. logic bugs) - except `eval`-likes, of course.
Well, I'm not sure specifically what you mean by "this," as there's at least two things mentioned in the article. In general, there's a *lot* going on in this space! I see stdweb and wasm-bindgen as having some overlap, but also differences. wasm-bindgen is focused on how to marshall stuff between Rust and JS. stdweb does that as well, but also lets you embed JavaScript code into Rust, is trying to add nice shims for web platform APIs, and other stuff. stdweb and wasm-pack are almost entirely unrelated, as far as I can tell.
I believe many people have a false understanding what object oriented originally meant. And with originally I mean Alan Kay. OO is not so much about classes or inheritance, and neither about representing real world things in code. As I understand it, the core of object orientation is the idea that objects communicate with each other. (Hence the name for Alan Kay's 'Smalltalk' language). Every object encapsulates its own memory (state), which can be changed by sending a message to the object. There is a great talk by Brian Goetz, discussing the relationship of functional and object oriented programming. https://www.youtube.com/watch?v=ROL58LJGNfA
He might have just added that, but from the readme it seems like it adds a wrapping struct around values that are identifiable by some dynamic key. So e.g. you want to store some data in a hashmap, then retrieve it in some function, pass it somewhere and at some point in the program long after, store it back with the same key. This create would allow you to pass it wrapped in "WithIdent" to have the key stored in the variable without an external variable being passed around. You could argue this encourages bad design 1. since the update could happen at the initial call site 2. passing the key with the value is more explicit 2. or the type itself could carry it's ID if it's necessary but I can see the usefulness of this.
Not to be negative, but I wouldn't post every video of yours on /r/programming. Here it's fine, but it gets treated as spam after a while.
I believe traits are still the way to go here. I would have something like this in mind: enum ModifierType { Damage, .... } trait Modifier { fn type(&amp;self) -&gt; ModifierType; fn apply(&amp;self, &amp;mut object: GameObject); } struct DamageBonus(u8); impl Modifier for DamageBonus { fn type(&amp;self) -&gt; ModifierType { ModifierType::Damage } fn apply(&amp;self, &amp;mut object: GameObject) { object.add_damage(self.0) } }
I had a really complicated [make-based integration testing] framework for [reproto](https://reproto.github.io) (using [rayon!]) that I wanted to rewrite into Rust for a number of reasons. This is the work-in-progress result: https://github.com/reproto/reproto/blob/master/tools/it/tests.rs With this in place I'm kicking off adding support for a [slew of additional languages]. Some of which I've never used before, like Swift. Having proper painless integration testing is crucial when doing this, you can work faster and have ability to test more meaningful things like [different configurations]. [make-based integration testing]: https://github.com/reproto/reproto/blob/f07e3f155070f664e53436f56762db3ee75a66b0/tools/Makefile.it [rayon!]: https://github.com/reproto/reproto/blob/master/tools/it/main.rs#L123 [different configurations]: https://github.com/reproto/reproto/blob/master/tools/it/main.rs#L105 [slew of additional languages]: https://github.com/reproto/reproto/issues?q=is%3Aissue+is%3Aopen+label%3Alang-support make projects FILTER="swift codable" cargo run --manifest-path=/home/udoprog/repo/reproto/tools/it/Cargo.toml -- --root /home/udoprog/repo/reproto/it --project swift codable Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs Running `target/debug/it --root /home/udoprog/repo/reproto/it --project swift codable` Finished dev [unoptimized + debuginfo] target(s) in 0.2 secs OK project inner (lang: swift, instance: codable) (961ms) OK project versions (lang: swift, instance: codable) (1.6s) OK project basic (lang: swift, instance: codable) (1.8s) OK project tuple (lang: swift, instance: codable) (1.15s) OK project alltypes (lang: swift, instance: codable) (1.15s) OK project enum (lang: swift, instance: codable) (1.19s) OK project allstructures (lang: swift, instance: codable) (1.38s) OK project swift_keywords (lang: swift, instance: codable) (1.47s) OK project interfaces (lang: swift, instance: codable) (665ms) OK project default_naming (lang: swift, instance: codable) (679ms) OK project code (lang: swift, instance: codable) (701ms) Finished in 1.78s If you are interested in trying to improve the state of the art with JSON schema management, there are a couple of [good first issues] with mentoring instructions available. In particular I would need help outlining the approach with the [Go backend]. [good first issues]: https://github.com/reproto/reproto/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22 [Go backend]: https://github.com/reproto/reproto/issues/21
Thank you for the advice! I'll hold off putting future ones there. Is it ok in this subreddit?
Any idea how I can get started with building a GUI app with Rust?
Yeah, here it's OK. It's just that some folks at /r/programming may see too many Rust posts which makes them think that we're over-evangelizing, so it can get pretty wild in the comments sometimes. /r/programming is mostly for bigger news around all languages - for language-specific things, people usually just visit the languages subreddits if they are interested. Ex. when a new compiler is released, a new company builds a product in Rust, a new algorithm / methodology that works exceptionally well with Rust - that sort of stuff belongs to /r/programming (but that's just my opinion). Maybe post it at /r/learnprogramming or /r/gamedev.
Thank you for the explanation. I agree with your opinions, and am happy you voiced them. I'm quite new to reddit. A snake game is not quite big enough :p I love that you even suggested other subreddits. &lt;3 The rust community is amazing!
Hmm... I feel like it would lead up to scalability issues but I'll give it a go. The other problem I can see with this is that I cannot necessarily refer back to the properties of a GameObject. Say I have a goblin and a plant. The goblin might have an attribute that contains his inventory, but a plant doesn't need that. Would I even be able to manage that with such system? I'm coming from a Java background so my mindset is much more OOP oriented than data oriented (which I believe is more rust-y).
There may be other evils that would justify this attitude, but I can't think of one. Perhaps PHP's cumulative flaws would justify it, but I haven't kept up with its development to tell. Some people I work with tell me that PHP 7 is kind of OK. JavaScript is not a particularly, good language, but AFAIU ES6 isn't so bad that it needs to be avoided. I can't say the same for memory unsafety, though of course that's just my opinion.
I wrote [rustlearn](https://github.com/maciejkula/rustlearn) which, as you say, suffers from the "let's invent our own numpy" problem. This is mainly because `ndarray` wasn't a thing when I wrote `rustlearn`. I'd be very happy to see it migrated, but I don't have the time to do this on my own. Besides, it sees very little use. More recently, I wrote [Wyrm](https://github.com/maciejkula/wyrm), a CPU-only PyTorch/Chainer-like library. It works pretty well, and _is_ based on `ndarray`.
Note that they didn't say anything more about them. Just that they are unique crash. So it doesn't mean they are what a developer would consider a "true bug". Does not take anything out of their achievement though.
Any plans to include the async support for Thrift + Rust?
I'd check out GTK, as it has the best integration. If you're feeling adventurous, look at Relm, which builds on top of it in an interesting way.
Looks like thereâ€™s a presentation coming up, so maybe after that?
1.0 is not the end of development, either. 2.0 is always a thing. 
Okay, fair enough. Personally, I'm of the opinion that JavaScript has just enough uncomfortable gotchas that I wouldn't miss it if it retired, but I guess that's a matter of preference.
Change `Map::new((MAP_WIDTH, MAP_HEIGHT)).generate_with&lt;gen::dungeon::Basic&gt;(MAX_ROOMS,ROOM_MIN_SIZE, ROOM_MAX_SIZE);` to `Map::new((MAP_WIDTH, MAP_HEIGHT)).generate_with::&lt;gen::dungeon::Basic&gt;(MAX_ROOMS,ROOM_MIN_SIZE, ROOM_MAX_SIZE);` This is the so called 'turbofish' syntax. It is required, because `generate_with&lt;gen::dungeon::Basic` is ambiguous to parser: it might be interpreted as a 'lower than' comparison between values `generate_with` and `Basic`. As for the other errors, there is not enough context. Please show the entire code. 
If you choose to work on a rust equivalent of sci-kit learn, please be sure to pm me the repo and Iâ€™ll be sure to help out!
Would be neat if IBM was displayed on the Friends of Rust page :) (That being said, I see that Facebook isn't there yet despite being involve in Mononoke).
Love how they picked the name too: &gt; The Angora rabbit has longer, denser hair than American Fuzzy Lop. We name our fuzzer Angora to signify that it has better program coverage than AFL while crediting AFL for its inspiration.
Thanks, this helped a lot in understanding modules structuring. In the end I've decided to just live with the explicit name-spacing but I'm being a bit better about how I do it which has made it a bit less redundant, and this helped me to do it so thanks.
I would recommend filing a bug against relm or gtk-rs with a minimal testcase. Gtk objects (and Gdk) all must only be used from the main thread and are not Send because of that, not sure if your problem is caused by violating this requirement somehow (maybe via relm? In gtk-rs all these are not Send at least).
I really like the structure of the newsletter, with both highlights on what was done, what is coming and where help would be most useful.
Actually from the backtrace this looks like a potential bug in gtk itself. Do other gtk applications work for you?
Thanks for the info! The sync version works great, BTW!
Are there any libraries to generate an image, preferably headlessly? As an example, I'm trying to draw a coloured circle to a PNG. The only way I can see so far is to use something like Piston, then pipe it to the image crate (which would be fine, just wondering if there's anything else around).
I like it too! This is so good to see progress on embedded rust. I wish I had more time to contribute/learn myself.
Iâ€™m so glad youâ€™re using it! Thank you!
It sounds like an [Entity Component System](http://arewegameyet.com/categories/ecs.html) is what you are looking for? It's a design which decoupled data and logic of various game subsystems from the identity of objects.
Nice tutorial! You should put this in r/rustgamedev, those guys will definitely appreciate it.
They're input-dependent crashes, which is something I'd usually call a bug. Some of them may even be exploitable (not that there's any way to tell). &gt; it doesn't mean they are what a developer would consider a "true bug I know people who say that reader-writer data races are not "true bugs", so...
yeah, that error makes sense now I get the context, again thanks for helping. I asked this question on stack, not only did I get zero help but even a request to close with no reason why, I'm honestly getting tired of the unhelpful neckbeard elite on stack /:|. I think it's ridiculous that a question on programming is off-topic on a website about asking questions on programming.
I am also interested. is there a e.g. rust discord where we could organize in a dedicated channel to get the different projects together and develop the ecosystem? in my view we need 3 parts: datatypes (numpy, ...), scirust (scipy), rustml (sklearn + layer oriented NN, possibly data flow architecture like torch and TF). we could start with ndarray as it seems comparatively mature.
Yeah, I agree with you. My opinion is that the dev should correct everything so that the fuzzer can go further in the program and find more bugs. But, it appears sometimes the dev have to prioritize their work and don't see it that way. My comment was mostly coming form that twitter thread: https://twitter.com/johnregehr/status/974065412513021952 1. Sometimes the bug is found by other tools but not corrected still (but they show later in the paper that this is mostly not the case). 2. Sometimes what a fuzzer consider "different unique crashes" has only a single root issue that the dev can correct with a single fix.
I wonder if thereâ€™s any support to run rust stuff on power9 CPUs
&gt; Mostly compile-time safety? Complicated regexes are in general worth having dedicated tests written for now, so I don't think it would buy that much. (For simpler regexes, the larger logic they're part of would have appropriate tests, presumably). Even if you don't fancy writing a complete test suite, something like: ``` lazy_static! { static ref MY_REGEX: Regex = Regex::new(...).unwrap(); } #[cfg(test)] mod tests { use ::MY_REGEX; #[test] fn my_regex_compiles() { let _ = *MY_REGEX; } } ``` is quick to write (and macro out, even, if you have a lot of those regexes).
Seems like it, but tonixx is using a yaml build config from what i skimmed on the github page. cross is mirroring cargo interface and you define a target if my memory serves me well. 
Cheers for that idea, and thank you! &lt;3
I'm going through an introduction to Rust (https://doc.rust-lang.org/book/second-edition/ch04-01-what-is-ownership.html) and am learning the very basics of ownership. With this code, when would drop be called? fn main() { foo(); } fn foo() -&gt; String { String::from("Hello, World!") } If we assigned a variable like `bar = foo()`, I would expect drop to be called when we the owner `bar` left scope (aka, when main terminates). Because we don't assign `foo()`, does the drop get called when `fn foo()` returns or is there an unassigned owner that goes out of scope in `fn main()`? Thanks for any clarification :) [edit: formatting]
We may ask in the official \(?\) Rust Discord server to create a channel for ai/ml \(in the same whay there are channels for crypto, embedded and gamedev\).
Right now rust+wasm has poor perfomance because you can't pass structs between rust and js, and stdweb is doing it by conveting structs to json and back. So you have perfomance boost only if you use rust for plain nubers computations. I want to use rust in frontend cause rust has best compile errors (partially because of mandatory anotations for functions' argumants) and it's only language with Traits. So it's even better than Elm/OCaml/Haskell. The only shortcoming is compilation time and inefficent interaction with DOM.
Tuples are inherently for unnamed things. Structs are for named things. That's the only difference between them. So yeah, sorry, you'll have to pick which tradeoff you want.
[Let's try it out!](https://play.rust-lang.org/?gist=2f6a9d5b7bf6abeca35f32238ef5fa91&amp;version=stable) Seems like, as long as the result is not assigned, it will be returned but then immediately dropped.
Hey taifa97300! There are lots of opportunities to help out the embedded rust environment, even if you don't have a lot of time or knowledge about embedded. There are tickets [like this](https://github.com/japaric/svd2rust/issues/183), where you can help out with tools that help out the ecosystem, and might be more accessible if you spend more of your time on "desktop/server" rust. If you (or anyone else) wants help finding a way to get a foot in the door (and a thanks in the next newsletter), let me know! Lots of our projects have "help wanted" labels, and don't always require in depth rust or embedded knowledge!
If you want the low-down nitty-gritty, the source is the rust reference. There's information scattered about, so go to the print view and control-F (search capability should be up in a few days...). In this case, there is an anonymous local which takes the return value of foo(), so it gets dropped in main(). If you want to test more complicated cases, you can manually implement drop on a type so that it calls println!(), or take a look at the MIR output.
Very cool. I've not gotten far enough to know how to have done what you did, but it is legible and very informative! Thanks!
Very cool! I really like your README, it gives a good explanation for what a CRDT is and how it works. I do have one question though: in the example in the README, you have two sites editing the same list, and sending their respective op to the other site for consistency. But what happens when two sites edit the same list like that and they thus execute the two ops in opposite order of the other? Is it based on timestamps, to see who made their change first?
It's actually /r/rust_gamedev :D But yes they would! Also did you see https://ggez.rs/ ? Seems like this sort of thing would be a perfect candidate for using ggez!
Docker is a fantastic technology for a limited set of target platforms. Docker is primarily used for building and running GNU/Linux binaries. Technically, you can target FreeBSD as well, but only from FreeBSD hosts; and musl/Linux as well, but only from GNU or musl hosts. tonixxx intends to support many more target platforms, and to do so regardless of particulars of the host platform, hence using full blown virtual machines rather than (far more efficient) containers.
Sure, you can hack together what you want trough the Deref trait: [Playground](https://play.rust-lang.org/?gist=559dc4849be7ec0e9f360c1cd3a0b583&amp;version=stable) use std::{mem, ops}; pub struct Point { pub x: i32, pub y: i32, } impl ops::Deref for Point { type Target = (i32, i32); fn deref(&amp;self) -&gt; &amp;(i32, i32) { unsafe { mem::transmute(self) } } } fn main() { let pt = Point { x: 42, y: -13 }; println!("x: {} y: {}", pt.0, pt.1); } But I think this creates more problems then you'll solve. I think it's better to provide `From` conversions for / to tuples and arrays and let the user decide in what format they want your points to be in.
Thanks, I've realized I don't really need to reserve to right to add new members and FRU syntax makes this a lot nicer so I'll just remove the one private member.
wasm bindgen enables passing structs between rust and js with an additional memory related info. There are projects like yew for DOM interaction. I am also not sure but Glimmer was doing something related to that. Well compilation time is another big thing to look forward, but I do believe that things will get better sooner. 
which is actually http://ggez.rs/ :p
Oops! I can never remember which sites I visit are https and just assume they are these days :P
Agreed. I'll leave this here in case someone is interested: https://www.usenix.org/legacy/events/hotpar11/tech/final_files/Boehm.pdf.
Actually you were right, it's just that they appear to have troubles with their certificate!
(blame nvidia)
If you don't want a struct, because constructing with `Point { ... }` or `Point::new( ... )` is too verbose, you can create "function-constructor" with a same name as struct: pub struct Point { x: i32, y: i32 } #[allow(non_snake_case)] pub fn Point(x: i32, y: i32) -&gt; Point { Point { x, y } } let p = Point(1, 2); println!("{} {}", p.x, p.y); [Playground](https://play.rust-lang.org/?gist=67d0c9c6df2cadaf5426b5903c459cc7&amp;version=stable)
Also, although in this case it would *probably* be fine, Rust is allowed to reorganize struct members however it likes if it thinks that would improve some aspect of performance, compatibility or whatever. So we can't assumed the first item in memory is the first item in the struct as it's declared.
Fun! Building a DNS, client/server/resolver was how I learned Rust too! Nice write-up.
That entire thread continuing from that tweet is good.
hmmm I like this one, simple, I could even be super terse and make it like, `p(1,2),`.
Tier 2 support for PowerPC linux (powerpc, powerpc64, and powerpc64le) in rustc. ;) https://forge.rust-lang.org/platform-support.html
Yew is using stdweb and has perfomance problems because of it. Not sure how bindgen will work and if it will solve anything.
yeah but it gives dom interaction. You should try wasm bindgen 
Interesting, this might be useful to a project I just started, actually..
&gt;I'm not sure specifically what you mean by "this," as there's at least two things mentioned in the article. My bad. I didn't notice there were multiple projects. &gt;My understanding is that stdweb's author is involved in the wasm working group. Nice. Maybe stdweb can be adapted in the future to use the code in the bindgen.
I've wondering how to resolve the compatibility concerns with impls. Is there a good way to hide impls or will this involve removing them and having to explicitly convert the type?
The (image)[https://crates.io/crates/image] crate might be able to do what you want, unless you're looking for something really high level.
I bought a blue pill myself the other day for the same reason. I've always wanted to mess around with SPI devices for robots, but other stuff always comes up...
Have a look at [imageproc](https://docs.rs/imageproc/0.14.0/imageproc/drawing/fn.draw_filled_circle.html).
Weird... My blog is on github pages and it has SSL (https://aochagavia.github.io/)
Yes, it's tricky to come up with semantics that both work and allow reasonable optimizations. The particular semantics I have in mind are something close to LLVM's (during a read-write race, the read returns undef) but instead have the read return poison, also exposing the proposed LLVM freeze abstraction for programs to use to deal with some interesting special cases. Unfortunately, even this conflicts with one optimization GCC does (see https://people.mpi-sws.org/~viktor/papers/cgo2017-llvmcs.pdf), but LLVM already implements the workaround, and from talking to the author of the paper it sounds like you should still be able to come up with something similar to the data race freedom property that still works under these conditions.
Thanks! Itâ€™s high praise coming from you. TrustDNS is a very impressive project, and quite an achievement. I didnâ€™t appreciate the full scope of your effort until I started looking at DNSSEC and gave up. :)
Doing some work on cost generics, but things have been slow due to most of the low hanging fruit having already been dealt with and because I have been over-thinking some things. Beyond that, I've been working on a crate to support the mk26l so I can make programs for the Teensy LC. It doesn't follow how most `cortex-m` based crates are structured, but I figured I would mess around with things. Additionally, I have been working on a driver for the `embedded-hal` based driver for the XBee S2C.
That was a slog. But I learned a lot!
The continuation of their work can be found here: [https://github.com/spearow/juice](https://github.com/spearow/juice). So, hopefully we'll see that work go somewhere now that there are new maintainers of the project.
Agreed. The old web had a lot to hate on. However things have gotten way better since the bad old days.
It would be awesome!
What's the difference between using a struct and 'just' a tuple other than the .0 vs .x?
Classical Rust, trying to camouflage itself like JS. It's like C all over again. Thought we wouldn't notice it seamlessly replacing critical components one at a time with very little effort. How sneaky of it.
You only get a certificate for a github subdomain, it doesn't work if you're using a custom domain.
How big is a typical `Item`, i e `mem::size_of::&lt;Item&gt;()`? You might be overestimating the cost of the additional copy if `Item` is not very large. I mean `Rc`ing something has the overhead of 2*usize + one memory allocation + one extra pointer chasing at lookup.
Makes sense, will give it a try. However, this will not allow me to modify Gamepad, right? Do you have a suggestion where I can modify Gamepad ?
I don't mean to take away from this at all, because it's a nice tutorial, but the topic of rust snake games reminded me of A Snake's Tale, a fun and well designed puzzle game written in rust by /u/m12y_ and available on [Steam](http://store.steampowered.com/app/654810/A_Snakes_Tale/), [iOS](https://itunes.apple.com/us/app/a-snakes-tale/id1211845149?mt=8&amp;ign-mpt=uo%3D4), and [Android](https://play.google.com/store/apps/details?id=com.m12y.asnakestale). (no relation to m12y_ beyond liking his game a bunch)
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://itunes.apple.com/us/app/a-snakes-tale/id1211845149?mt=8&amp;ign-mpt=uo%3D4) - Previous text "iOS" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dvrevv5) 
Who'd have thunk lifetime elision [comes back to bite me](https://llogiq.github.io/2015/07/09/cow.html)? Also we should probably add a whitelist of types known to contain no lifetimes.
The data format is JSON. So things _should_ work fine. Perhaps print out what serde is generating for your use case. The data exchange system is user-defined, so you should be able to plug in your own transport layer.
Yes gradient descent being an odd choice was also my thought. And it "forces them" to do the extra step of shape&amp;type inference. Besides, although it does improve performance, it does not by a lot. Seems everyone is waiting for their source! It opens much possibilities.
That is amazing! I am so thankful you mentioned that game. And it's written in Rust too. That's awesome. 
OO predates smalltalk though. And it was invented to represent real world things in code, using classes and inheritance. I don't know that there is any justification for viewing Kay's view on OO as the canonical one but it's certainly not the original one.
More wondering about a compatible implementation of the algorithm on the non-rust end. So I can share the CRDT between a js client and a rust server.
u/somesha (Alex Shapiro), any relation to [Marc Shapiro (an author on the original CRDT paper)](https://arxiv.org/abs/0907.0929)?
Am not familiar with Ditto's internals.. but the principles are relatively straightforward. CRDTs are appended only data types. So as long as you preserve the history as is, the central server should be able to resolve any differences. As for resolving differences in the client-side, e.g. master/master replication, that feels very difficult
You'd need to explicitly convert the type. I don't think it's a big deal in this particular instance, since people generally don't use `regex-syntax`.
Quick correction - Ditto data structures are not really append-only. Instead, they use a "summary" that knows whether an element has already been inserted. It allows the data structures to maintain idempotence without having to store the entire document history, which may be massive.
Nope! Just a coincidence.
That is pretty much what I've been using it for. This is just a type I've written repeatedly myself and decided I may as well put it as a library. But to address your concerns, the updating a hashmap is one use, but I find it's most useful when I'm seperating my concerns. Sticking with the hashmap idea, as you said the type itself could carry it's own ID but: * It's not the types responsibility to know where it came from, it's the programmers. * Doing so fixes that type so that it has to go back into the hashmap it came from. So I use "WithIdent" to "tack on" the ID and the functionality of an ID when it's needed. I also make use of the "DeriveIdent" trait if I want to ensure elements of a set maintain a certain property across all elements. 
&gt; but it's a logic error to mutate it in a way that would change how it hashes/compares Ah, well! That does make sense, and the types have to be safe in the face of `rand()`/interior mutability anyway so it's not adding any new requirements/pessimisations.
The data format is unpublished but one of my future goals is to compile Ditto to web assembly and write a JS wrapper around it.
Last commit in src was 6 months ago ...
trying to solve the problem by carefully following a bunch of rules is not interesting to me... that's already what people do that doesn't work.
How do Juice, Greenglas and Coaster fit together? And what would be the equivalent in popular frameworks?
For anybody curious about CRDTS, the [*Rope Science*](https://github.com/google/xi-editor/blob/master/docs/docs/rope_science_00.md) writeup is a wonderful introduction.
It's all good!
This sounds like a very good optimization to make!
BTW, `...` is reserved for for syntax of future tuple unfold operation? E. g. ``` (1, 2, 3) ``` should be ``` (1, ...(2, 3)) ``` right?
Can you expand on what your issue is with this? from https://docs.rs/iron/0.6.0/iron/typemap/trait.Key.html This trait defines the relationship between keys and values in a TypeMap. It is implemented for Keys, with a phantom associated type for the values. From what I can tell Key is essentially a marker trait.
Yep, I recon that much after 15 minutes playing with the docs. Been doing Rust for about 1 hour but still, the discoverability don't feels right to me. It doesn't matter how new I'm I to a new API, I can always find my way on `http://en.cppreference.com/w/` On the example in the book they call `.get("n")` on the result returned by `get_ref`, it just takes a big time to get that that result is a map and the keys are strings...
The syntax is starting to grow on me... hopefully that continues. It's like '0..=5' is 'from 0 up to and equal to 5'.
Yeah, it's an immutable solution. I don't necessarily have any good solutions to modifying Gamepad as well - that's something I'm still figuring out how to design well. The key problem is that if you have modification of gamepad, you could potentially get two mutable references by both grabbing Gamepad and then getting a second one by accessing pong.players inside `update_game`. There are ways to work around this, but they're really just work arounds. If you want, you can use a `RefCell` inside `Rc` - it does runtime checking to prevent multiple mutable accesses. If you're willing to go for a bit more complexity, I would recommend using a system other than just keeping everything in one object. ECS, entity component system (ECS), have all entities are stored in a world, but only accessible via index. They are generally updated in pairs or groups of items at a time, with the system ensuring that only one thing has mutable access at a time. Here's a blog post about writing an ecs in rust, it might be interesting: https://kvark.github.io/ecs/rust/2017/03/08/specs.html
`Key` is not a placeholder for `Any`, rather than that the complete definition for the trait, pub trait Key: Any { type Value: Any; } means: "a type that implements `Key` is a type that implements `Any` and has an associated type, `Value`, which also implements `Any` itself". Therefore, `&lt;P as Key&gt;::Value` refers to this associated type. Now, with this information, `get_ref` is a function that takes a type `P` which implements`Plugin`, which by its definition `Plugin: Key` must implement `Key`, and returns a Result of the type specified by the `Key` definition of `P`. 
Eh, it's a learned thing. I have an easier time navigating Rust's docs than cppreference, but that's only because I've spent more time doing the former.
Not even close. As an implementer of an iterator you have to handle `value_type`, but as a user of the iterator you can't care less. The iterator being external means that, as a user, you know that `value_type` is just the type of the container you are iterating. On this case I was a user of some type for which I didn't knew the type. How would I know that `get` takes a string? C++ templates are difficult but they are always buried on library/implementation. Rarely they are exposed to the users. I do guess that if I give it more time then I would be able to understand more of this.
This because `AsRef`'s method signature is: fn as_ref(&amp;self) -&gt; T As a result, `str` is the lowest level that is able to implement `AsRef`.
is there also a library that helps with data preprocessing like numpy?
What would be a typical use case for a CRDT that is more difficult to achieve using more traditional data structures , serialising and then sending over the wire?
Collaborative document editing.
Do these use dotted version vectors? Are your map keys type-aware? Did you implement ORSwots?
I just want add that I'm so thankful `=..` was decided over `...`. I'm still haunted by a bug I had in my first Ruby project that involved mistyping `..` instead of `...`. \**Shivers*\*
In what sense? In the sense that the user gets to decide whether they can get a reference or moved value? That's not leaking implementation, that's exposing an interface. If there's a `get_ref` method available, then you know you can get a reference. Nowhere is it leaked how that reference is constructed or where it refers. 
I still think going with ... and deprecating .. in favour of ..&lt; would have been much better in the long run especially now with the popularity of swift and haskell.