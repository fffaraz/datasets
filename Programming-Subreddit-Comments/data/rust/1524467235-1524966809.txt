Having an ABI doesn't prevent any of that, optimisation can be part of the ABI. An ABI doesn't have to be stable as long as it is versioned. Since we are talking about compiling two Rust modules with different toolchains, we just need those 2 toolchains to understand the same ABI. Once again, not saying that it is easy... Having a public and stable ABI is another thing and bring other benefits and challenges. Is this really a design decision to not have an ABI? I can't find any reference mentionning that and AFAIK it is still open for debate : https://github.com/rust-lang/rfcs/issues/600
That's called stable, not main.
&gt; Since we are talking about compiling two Rust modules with different toolchains, we just need those 2 toolchains to understand the same ABI. Once again, not saying that it is easy... How do you pass the same struct with two different memory layouts through memory from one crate compiled with one ABI to a crate compiled with a different ABI without incurring any run-time cost?
You are assuming that each crate are compiled completely separately. Different toolchains don't mean that you can't pass around compilation flags like the expected ABI version.
&gt; You are assuming that each crate are compiled completely separately. A crate in Rust is defined as the smallest unit of code that can be compiled independently of any other crate. This is not an assumption, this is by design. 
Good that you mention that, because I think the crate doesn't even need std. I'll turn it into a no_std crate and publish a new version. Thanks!
So you want all compilers to support generating code for all ABI versions after some date ? How do you handle linking against two dynamic libraries compiled with two different ABI versions?
Versioning ABI doesn't mean you have to handle all of them. A sensible strategy might be to support only the latest stable. Dynamic linking is out of the scope, I never mentioned it. This would require two include the ABI version in the artifact AND some backward compatibility strategy.
Something like [this](https://play.rust-lang.org/?gist=2d7e9bf60165b43f19d2b2110649bf93&amp;version=stable)? pub fn get() -&gt; Option&lt;String&gt; { let _ = env::var("JAVA_ENV_MANAGER_HOME").err()?; let home_dir = env::home_dir()?; String::from_str(home_dir.join(".java-env-manager/").to_str()?).ok() } 
I made [rustorm](https://github.com/ivanceras/rustorm) didn't talk about it much, but I use it heavily in my main project [diwata](https://github.com/ivanceras/diwata). Diwata is a user-friendly database interface for PostgreSQL, aimed to be a spreadsheet like UI for the database. It connects dynamically to database.
At a minimum, you can use a library like https://crates.io/crates/httparse to parse HTTP requests. But you can probably use a full HTTP server and don’t need to write your own: https://crates.io/crates/hyper, https://hyper.rs/guides/server/hello-world/
 pub fn get() -&gt; Option&lt;String&gt; { env::var("JAVA_ENV_MANAGER_HOME").ok().or( env::home_dir() .and_then(|path| path.join(".java-env-manager/").to_str() .map(|s| s.to_string()))) } 
&gt; Patch-based VCS is much more flexible than snapshot-based, while allowing to emulate snapshots when needed. The converse is also true. I don't see anything in the "patch theory" that couldn't be emulated on snapshot-based VCSes.
How do you emulate snapshots with a patch-based VCS? Well, emulating patches with a snapshot-based VCS is literally the opposite.
You are correct that `impl Trait` in return position should not increase binary sizes or slow down codegen. This is because, as you said, the compiler just needs to infer the right type and substitute it, and it is always one specific type, so there is no monomorphisation like with generics. However, I've heard that the compiler's algorithm for inferring the correct type to substitute for the `impl Trait` is quite slow, at least for now. This leads to programs using `impl Trait` being slow to compile. So yes, you are correct on everything you said. It is just that the type inference seems to be much slower than you'd expect. However, this will probably be optimised more in future versions of the compiler, so it might not matter as much.
Not necessarily. I disagree. They involve different trade-offs. An `enum`: - uses an extra byte of memory for the discriminant - dispatch is done using simple branches in code (when you `match` on it, etc.), comparing the discriminant, like simple `if` statements; this is as fast as it gets - does not require any heap allocation - does not have any indirection A `Box&lt;Trait&gt;` trait object: - stores an extra pointer in memory for the vtable - dispatch is done using an indirection through a vtable of function pointers - requires a heap allocation - can represent any type that implements `Trait` This means that a `Box&lt;Trait&gt;` could be much more inefficient in many cases, as it involves indirection through pointers (which are more likely to miss the CPU cache) and requires a memory allocation on the heap. However, it is more flexible, as it can represent any object that implements the given trait. By contrast, the `enum` approach is effectively zero cost. My advice would be to prefer the `enum` if you can only have one of a select few number of types (such as a `Read` from `stdin` or a `Read` from a file). It gives you control over whether you want to Box/allocate it or not and usually performs better. Prefer the trait object if you want the flexibility of easily representing any `Read` object type, like if you don't know the exact specific types you would be working with or if you are working with many of them.
lol, no. In patch-based, all commit stands-alone. There's no concept of "at that time, the repo looked like this"; we think: "at that time, we made this change". We emulate snapshots by using tags to group how many single patches we want and say: "consider all these patches and freeze them as a single moment in time so I can reference that part of the repo as a compact unit"; and we use branches to say: "take this patches and send them as a whole, because they belong to a logical unit". In snaphsot-based vcs, you can't do the opposite. A commit is a snapshot of the repo as it looked like at that time. You can't swap around patches, unapply one of them, consider only a group of them. Because it's a snapshot. A frozen copy of the whole repo. Well, you can change that, but it involves very tricky cherry-picking and rewriting history. Cherry-picking in git is an extremely delicate surgery on the repo history.
but the only way to cherry-pick in git is through the cli. You can't script it. (Or maybe you can, but you must be a git wizard with years of experience in something that should just be a tool towards something else.) That's the point, it's a manual, very tricky operation that in patch-based vcs comes for free.
the biggest advantage is that it makes cherry-picking extremely easy and relaxing. If you don't use it in your workflow, it might not be much, but it's really great otherwise. You can accept only part of a pull request, swap patches around, unapply a commit very far in time without creating conflicts (if it happened in a part of the repo which hasn't changed in the meanwile), etc. Also, you can write your software freely, without knowing in advance that you are working on a feature, and make it a branch later on ("spontaneous branches"). Also, it's a simpler (= more natural) mental model, so it's easier to grok.
Ok, so writing this helped me thinking about a potential solution. Maybe I can put the error the other way around, and have `FormatErrorContext` beeing the real error and `FormatError` (now `FormatErrorKind`) being the context. Now I have: #[derive(Debug, Fail)] pub enum CommitValidationError { FormatError(#[cause] Context&lt;FormatErrorKind&gt;), IoError(#[cause] Context&lt;IOErrorKind&gt;), } `Context&lt;FormatErrorKind&gt;` contains the former `FormatErrorContext`, with the indication about the position of the error in the message. I still need a custom `impl Display`, but it seems a little more idiomatic. You can see the full code on the [refactor/error-handling branch on Github](https://github.com/Hugal31/validate-commit/tree/refactor/error-handling).
Correction: you can also use the question mark with `Option`. But that's not nearly as handy in practice. :)
I entered the ludumdare at the weekend and tried to make a game using Rust. Didn't finish what I wanted in time but I had fun https://ldjam.com/events/ludum-dare/41/text-em-up Used wasm-bindgen this time round and it worked pretty well.
Not necessarily true if the column you add is nullable.
- terminal https://github.com/jwilm/alacritty - distributed version control system https://pijul.org/ - operating system https://www.redox-os.org/ - object-relational mapping http://diesel.rs/ - editor https://github.com/google/xi-editor - ethereum client https://github.com/paritytech/parity - find alternative https://github.com/sharkdp/fd - ls alternative https://the.exa.website/
Last week I spent time reviewing PRs from /u/Aehmlo for [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). This week will be more review and perhaps some time to continue the thermodynamic temperature vs temperature interval issue.
https://play.rust-lang.org/?gist=9a43b04a071942f5b0aaf2f70573a2e6&amp;version=stable to https://play.rust-lang.org/?gist=9eac817ab8d6238e15ba03da27bb6270&amp;version=stable and I guess with Failure it would also work. 
This is the second time that this issue has come up in the last couple of weeks. How often has this confusion come up before, I wonder? 
[Week 4](https://github.com/yoshuawuyts/okf-updates/blob/master/week4.md) of working on Rust stuff funded by the [Prototype Fund](https://prototypefund.de/en/). Continuing to port [Hypercore (append-only log)](https://github.com/mafintosh/hypercore) to [Rust](https://github.com/datrs/hypercore). Want to wrap up the `Bitfield` module, and then progress to the `Storage` implementation.
If you want to actually handle the error instead of passing it with '?' then usually you would just use a match. If you wanted to mimic Go's error handling, you could use "if let" instead, but match is more idiomatic.
Not Rust but `ncdu` is pretty dope and worth checking out https://dev.yorhel.nl/ncdu/scr
Finished up work on my RSS reader. See the post I wrote about that [here](https://bheisler.github.io/post/jarvis-impressions-of-rust-libraries/). Next up, I've discovered that the Rust ecosystem doesn't seem to have decent CUDA bindings (only some half-finished attempts). I plan to write a GPU-accelerated path tracer as a project to learn about GPU programming, so this simply will not do. I'll probably take a crack at building my own bindings library while I'm working on the path tracer and hopefully come up with something that others can use as well. Where can I find some best-practices and resources for writing `*-sys` crates?
Coupling your application logic to your database schema is a common rookie mistake. Your database should have as little schema as possible and your application should know almost nothing about it. There is a reason WordPress runs half of the websites on the internet and it’s not the brilliance of PHP that it owes it success but its design, and in particular it’s database schema, which makes it as unkillable as a fungus infection. Download a copy, install it and look inside. You’ll be quite surprised at how simple its schema is.
I think some of the higher level layers were open source, but not the core.
The Nomicon has [an entire section on variance](https://doc.rust-lang.org/nomicon/subtyping.html) which I more or less understand except this little section in regards to `Box&lt;T&gt;` and `Vec&lt;T&gt;` being (co)variant over `T`. &gt; `Box` and `Vec` are interesting cases because they're variant, but you can definitely store values in them! This is where Rust gets really clever: it's fine for them to be variant because you can only store values in them via a mutable reference! The mutable reference makes the whole type invariant, and therefore prevents you from smuggling a short-lived type into them. Can someone explain this to me? Or more specifically, explain what this line means? &gt; it's fine for them to be variant because you can only store values in them via a mutable reference! What is the mutable reference to? Is it a mutable reference to the `Box` / `Vec`? Is that really the only way to store values in them? I thought when you initialize a `Box` values are moved into the `Box`?
What about making the error's location (often specified as a `Span`) an optional part of your `Error` struct? So something like this: #[derive(Fail)] pub struct Error { location: Option&lt;Span&gt;, #[cause] kind: ErrorKind, } pub enum ErrorKind { Format(FormatError), ... } pub struct Span { line: usize, column: usize, } Then if it was provided, you've also got the location of the error. Another thought is to break your error handling up and not try to fit *all* your errors into one enum. For example, you may have one function which reads the data and returns an IO error, then in the validation step you return a `FormatError`.
You might end up with parsing ambiguities if you're allowed to put a comma after `$(...),*`. The macro parser wouldn't know whether the trailing comma belongs to the repeated pattern or if it's part of the next thing. As a general rule, parsers are pretty dumb and tend to blow up or misbehave when faced with subtle ambiguities.
What is a fixture replacement? 
Thank you for your enthusiasm! I put some ideas in the project's [issues](https://github.com/kimond/factory_steel/issues). Feel free to add new ideas. I posted the crate even if it is very experimental because I wanted to know if the Rust community needed this kind of project.
Exploring the possibility of porting a Node.js/Express.js REST API to Rust. Looking into [Gotham web framework](gotham.rs)
Thanks for the feedback! So, the Nest was not intended to do anything more than basic, unstable service before we had a first working prototype of the full theory of Pijul. Now that this is done, we're going to shift development back to it. About the other comments, I believe your problems are due to our basic diff algorithm, which is super naive for now, and consumes *a lot* of memory. We haven't yet done anything to make it faster or implement another one, because it is not the core of what we do. Now that the full theory is here (and we're super happy about it, we do believe it's great news), we are *definitely* going to shift development to all the cool things that make for a pleasurable experience, fast `record` (by the way, `status` does essentially a `diff`), a stable and useful Nest, patch reviewing/editing tools, and all these cool gadgets we've dreamed of. It seems there is a slight confusion here about the actual state of development of Pijul, and what people expect it to be.
What difference does it make? It's a pretty trivial issue and there's no evidence that this isn't a coincidence or some kind of fallacious pattern recognition.
&gt; I’ve read comments saying that the futures library is hard to learn and hard to use. Now that I’ve used it, I don’t think that is the case. Almost everything I know about futures from other languages transfers over quite cleanly. I find this quite interesting. Because it maps with my experience with people having problems understanding the `futures` library actually have problems with learning what a Future is, as a concept.
I would encourage you to add more to the readme. For example, the expected output of the sample program. 
&lt;3 to both of you.
Actually, it does not replace real "fixtures" yet but it's planned. Here is an example of fixture with Django: https://docs.djangoproject.com/en/2.0/howto/initial\-data/. Although Rust didn't have a framework like Django, it has a active ORM [diesel](https://github.com/diesel-rs/diesel) then instead of populating your database using JSON files or other file format for your test purpose, you could use Factory\_steel instead. However, Factory\_steel has no Diesel integration/plugin. I hope I was enough clear with to define what is a fixture. 
"Digging deep on the compiler itself" is more of the contribution guide niko is working on; this is more of a user's manual. :)
I put the output of the `println!` in the comment above the line. But, you're right I think I could add a more verbose example. Any ideas?
Ah cool! Thanks for clarifying :D
[Here's the tracking issue for `$(,)?`](https://github.com/rust-lang/rust/issues/48075), if anyone else was curious like I was :)
Is there any good way / a setup guide on how to create a firefox extension using rust? I have a small utility extension I want to make and I though I might as well try to learn web assembly while I'm at it.
I'm on holiday and fancied working with Rust some more, so I decided to try and recreate a npm library I like in Rust with some extra features. This library lists your npm scripts and allows you to cycle through and select them without having to remember them off the top of your head. Said library is [ntl](https://google.com), and my _very_ WIP attempt is [here](https://github.com/SamHH/sl). At the moment it just checks your pwd (or a directory you pass it), looks for a package.json, and prints out a HashMap of the scripts. My idea is that a) I can extend it beyond just npm scripts, and b) it will be more performant, though I don't know yet if it will be perceptible. Any feedback on code quality etc much appreciated, especially this early on! :-)
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://google.com) - Previous text "ntl" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dxtxfms) 
Thank you for your response. Now I think I understand better what's withoutboats said. Now I have #[derive(Debug, Fail)] pub enum CommitValidationError { Format(#[cause] FormatError), Io(#[cause] IOError), } ... #[derive(Debug, Fail)] pub struct FormatError { #[cause] pub kind: FormatErrorKind, location: Option&lt;Span&gt;, } I tried to break up my error handling and now some of my functions return a `FormatError`, and some others an `IOError`, and it feels better!
Or if you want high scalability and ACID transactions. There are not many alternatives out there that provide that.
I think the bigger problem is coming up with a way that fixes this that won't break existing code. If you leave newlines out, things will break, and that seems far worse than getting people to understand that newlines are included. Perhaps it's an easy thing to not know, but I'd be surprised if there were a better solution than simply telling people the things they don't know. It's not like it's a hard thing to learn. It's just a necessary thing to learn.
Great work - a really good way to learn a language too (implementing a spec). I'll try and read through it when I get a bit of time, but the use of an FSM for the TCP state transition is a good call: I'm personally reimplementing [this](https://github.com/adamkewley/fo2dat) as an FSM (not for any other reason than masturbation) and found the ownership semantics etc. to be great at ensuring transition correctness. For example, in your `TcpState`, you could make `recv_enqueue` take ownership of `self` and make it return `(TcpState, Result&lt;()&gt;)`, which might be intepreted as "The new TCP state (or unchanged TCP state), plus an IO error (which might be handled upstream)". This way, it's a compile error if someone double-feeds your `TcpState` by feeding it once, ignoring the return, and feeding it again. Just food for thought; again, I haven't read your code in detail and don't know the intricacies of your project, so I may be talking BS
I'm not sure why people are downvoting you for using the combinators correctly :/
What does this provide over something like the `Default` trait?
Doesn't cargo lock already do that? Maybe I'm misinterpreting the `[metadata]` section.
So much this! I recently had a very nice dinner with someone running databases a larger governmental service. He in glance said "we're not doing anything remotely big data" and I was like "well, just as a data point, how much do you have?" "Just 6TB". I would instantly hire if I could. Like, the last time I did anything remotely big data, we had 2TB of daily _influx_, and even that can be handled using stock services. 
Can't you do what you want by only running `cargo ... --frozen` and `cargo update` separately?
Maybe the [docs](https://doc.rust-lang.org/nightly/std/io/trait.BufRead.html#method.read_line) would need to be more clear. That is an easy contribution too. :)
Actually, it allows us to define custom default value inside struct definition. However, you should take a look at the coming features: [Fuzzy attributes](https://github.com/kimond/factory_steel/issues/3), [Random value with Fake\-rs](https://github.com/kimond/factory_steel/issues/2) and maybe plugins for existing libs like Diesel.
If this was something that actually DID get changed, it's doubtful that we'd use the same name `read_line` -- it's much more likely that the Rust team would deprecate the old name and use a new one to make an obvious transition path. This behavior was probably better thought-out than I originally assumed. The [example in the `BufRead` docs](https://doc.rust-lang.org/std/io/trait.BufRead.html#examples-4) shows the difference between reading until EOF and until EOL, which is a useful thing to distinguish from the resulting read. I'm beginning to agree that simply educating users that run into problems would be the best solution. There seems to be a good motivation for the behavior. 
Yeah, that might be good. It's kind of hard to tease out. 
[Making a *-sys crate](https://github.com/kornelski/temp-sys-crate-post/blob/v1/making%20rust%20sys%20crate.md)
We have typically not been able to find recording equipment but will try for this meetup.
Wow thanks man. This is a very nice function.
Last week I did a bit of work on [tarpaulin](https://github.com/xd009642/tarpaulin) the need to move over to syn from syntex_syntax is growing as nested use statements cause a panic in syntex_syntax. Someone else is interested in doing it so I'm going to see how they're getting along and provide any help/guidance I can. I also submitted my first issue/PR for the embedded-hal for a watchdog timer interface. Some changes requested and all have been approved so I'm just waiting to see if there's anymore feedback or whether it's ready to be merged in! If it goes in I'll implement it in my own hal crate, otherwise I'll be continuing work on USART/UART trying to sort out different word sizes/parity configs while exposing a nice interface to users.
Also, on very large projects with lots of authors, merges can get tricky. One nice feature of patch-based systems is that you can still undo things, even after you've pushed many other commits/patches, without having to rebase everything that's been done since. Also, the merges in Pijul and Darcs are more deterministic than in Git. More specifically, in Pijul/Darcs, they only depend on the operations (line additions/deletions/edits), whereas in Git, they depend on the actual contents of lines. Also, partial clones are much more natural: patches commute, so a branch is just an unordered set of patches. Just pull the patches that touch a specific file or directory, you can still pull the rest later.
The two examples I know of patch based VCS are Pijul and Darcs, they both have "tags", which are like a normal patch, except that they are marked as depending from all patches currently in the repository.
what type is `str_int`?
Okay, I'm swayed (pun intended). Thanks to both of you. This is way out of my usual domain, but it sounds like there's a strong possibility for using wayland to set up a minimal window compositor, and to keep using glutin+gfx to hopefully make it run on both a home laptop (while testing, building) and on the Odroid. And yes, /u/_Timidger_ I'll definitely reach out to you (probably via the email I found on your github) when things really get rolling. For a bit of background, the whole thing is basically an effort to turn the stack of four [Odroid XU4](http://www.hardkernel.com/main/products/prdt_info.php?g_code=G143452239825)s into visualizers for a 4-channel video + sound installation piece, visualizing chaotic attractors. I've got pipelines and shaders going in OpenGL, so ideally we'd keep that framework...it sounds like using wayland is going to be 100x easier than some kind of super low-level framebuffer situation, and will allow us to leverage the hardware rendering of the Odroid XU4. Thanks!
My guess is that `str_int` is a reference - can you try without the `.into_iter()` method call?
Thanks! Yeah, I looked around on that...my problem (which I didn't mention above, sorry) is that we're all set up to do hardware rendering with OpenGL, and as far as I could tell the direct-to-framebuffer strategy is primarily for software rendering. But if I'm misunderstanding that constraint and hardware rendering is an easy option, then it's definitely on the table.
I've added the struct type. Unfortunately, it is a part of a huge app and I can't disclose the source code. I thought that it is maybe kind of an obvious mistake.
&gt; smoltcp has the entire TCP socket implementation in a single module which I'd like to avoid to stay sane Is there any particular issue with it? I'm quite proud of fitting the entire TCP in less than 1500 lines of well-commented, readable code. Now if you told me that iface/ethernet.rs is horrible, I would agree with you entirely...
It happens. I, at least, won't be able to sort it without the types. https://play.rust-lang.org/?gist=b1b197e553d9b56b17fbd6e5dab0944b&amp;version=stable What's the intoiterator look like?
This is the implementation: impl&lt;Sym, H&gt; iter::IntoIterator for StringInterner&lt;Sym, H&gt; where Sym: Symbol, H : BuildHasher { type Item = (Sym, String); type IntoIter = IntoIter&lt;Sym&gt;; fn into_iter(self) -&gt; Self::IntoIter { IntoIter{iter: self.values.into_iter().enumerate(), mark: marker::PhantomData} } }
Overall great, but I think the code-area (white) needs a lot more paddings, to feel lighter. The top buttons are nice and have enough room to breath.
Oh, I think I found the problem, this code involves Deref and it returns a reference.
To expand on this. Imagine that it is decided that truncation will be performed: `March 31st + 1 month` is therefore `April 30th`. Awesome right? And logically `April 30th - 1 month` is `March 30th`. Wait, does this mean that `March 31st + 1 month - 1 month == March 30th`??? Furthermore, we are assuming a Gregorian calendar, which while common is not the ONLY calendar. Operations on `week`, `month`, etc... should occur within a specified calendar model.
Great!
Yup. I fully appreciate that it's difficult and often requires arbitrary decisions. But we can't just ignore that people are going to need a crate that at least does something reasonable in these situations - refusing to provide an implementation is not going to be sufficient. For what it's worth, JodaTime defines that operation to return April 30.
For right now, this is the best available: https://github.com/japaric/nvptx It requires a good deal of unsafe code and cross-compiling a fork of the stdlib, so it's not for the faint of heart. I plan to do some work on this area myself and I hope to improve the situation somewhat, but it will be a while (likely months) before anything comes from that.
I thought just tagging would be enough for that. Instead than saying: I tested on commit &lt;shasum&gt;, I'd say I tested on tag X which contains {0..n}. Or something like that.
&gt; ticket Done. Thanks!
This series is getting more and more awesome. [whole list](https://www.rust-lang.org/en-US/whitepapers.html)
FDB had a SQL layer before they got bought by Apple. The proof of work is there, however someone would have to do the work in developing a SQL layer that is wire compatible.
Writing a distributed log/state machine using a paxos\-ey algorithm. We're not using HTTP, instead tossing around messages just using TCP streams.
It makes them look more scientific.
&gt; Why are these published as pdf? These whitepapers are aimed at CTOs, not developers. "whitepaper" [is a thing](https://en.wikipedia.org/wiki/White_paper#In_business-to-business_marketing) and are quite often PDFs, so we're just going with convention here.
Awesome stuff! It's amazing how they're still saving time (and probably a lot of frustration) even though they target the Xbox, PS4 *and* Switch, none of which have any official Rust support.
Yeah I'd like to hear more about how they are actually integrating these with Rust in CI.
In [the ama](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/) they added some details on that: https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dotx5y4/
Diesel author here. Great article! Just wanted to mention some of your points: &gt; The major reason why I decided to replace the Scala code initially was because I was having a lot of trouble remembering how to work with the heavily DSL-based Slick library, and I’m concerned that I might have a similar problem with diesel in the future. I hope not! Whenever possible we try to name things as close to SQL as possible, and one of our core design principles is that it should never be surprising what SQL gets generated from a bit of Diesel code. I think the only place we can even be compared to slick is that the method for a `WHERE` clause is called `filter`, which we only do because `where` is a keyword in Rust, and I didn't like the idea of calling it `where_` (though I may just add it as an alias) &gt; I still have to remember, for example, that I need to use diesel::insert_into(feed) for inserts but feed.load for queries. This is actually relatively recent for us. Up until Diesel 1.0, it was `insert(values).into(table)` which I disliked for a variety of reasons, but the biggest of which was that it was backwards from the SQL it generated, and caused rightward drift if your values were complex. When we switched to the new form, I actually considered giving select statements the same treatment. The reason we don't, is that the select clause truly is optional here. A significant percentage of the time, you just want to select all the columns from the table(s) in your from clause (e.g. something roughly equivalent to `SELECT *`, but we never actually generate `*`). That said, we do have a top level [`select`](http://docs.diesel.rs/diesel/fn.select.html) function, which will eventually end up getting a `.from` method (since there are a handful of [mostly PG specific] queries which can only be expressed that way), which will make `select(foo::all_columns).from(foo::table)` incidentally possible if you'd prefer. &gt; I’m just not sure I’ll be able to remember how to write it without referencing the documentation. Please let me know if there are specific cases for which you find this to be true. Generally everything is named as close to the corresponding SQL as possible. &gt; In particular, the documentation on foreign-key relationships and JOINs is buried in the API docs where it’s kind of hard to find. It would be nice if there was a guide to doing these things on the website with the other guides, or at least some links to the right place in the API docs to make it easier to find. Noted. &gt; One comment is that (depending on how you design your database) the DSL imports can clash with likely variable names. One of the members of the core team thinks we should just deprecate the `dsl` module, and I'm leaning more and more towards that over time. I only added it because I got tired of writing `use schema::foo::table as foo; use schema::foo::columns::*;`. But people seem to get confused by it more often than not. I actually have a branch that makes it possible to have the DSL import, and still qualify things as `foo.bar`, but for files that have `use schema::*;` (which I always have), that branch makes it impossible to have a local variable name with the same name as the table. &gt; I thought sqlite would lock the database during writes and that the other threads would block until it was unlocked, then proceed. Instead, all other transactions simply failed while the database was locked. This is definitely something we want to improve at some point. It's been low priority though, since applications which access SQLite are overwhelmingly single threaded. I appreciate the praise on the things you did like. The way we structure associations and using plain SQL files for migrations are two things that came from a *lot* of experience in this space. They're also two of the more "controversial" things Diesel does. Great article overall!
Thanks! This is exactly the type of thing I had in mind. The caveats of that one are a little scary, and it seems a bit out of date, but I'll give it a go.
I find this interpretation rather confusing. It reminds me about the `next Wednesday` debate; on a Monday, for some in means two days hence, and for others nine days hence (and `this Wednesday` means two days hence). I feel like this idea that 1 month can be anything from 28 to 31 days (depending if you are in January or July, respectively) is rather confusing to start with; so I'd prefer if the choice of "rounding" method was more explicit.
Postgres' answer seems reasonable here: [local] sean@sean=# select 'march 31, 2018'::date + interval '1 month'; ?column? --------------------- 2018-04-30 00:00:00 (1 row) (PG is one of the few places I've seen that has a "correct" representation of an arbitrary time period using human concepts) Your question doesn't just apply to months. Days are also variable length. `chrono` sidesteps the most common cause of this (DST transitions) by not supporting time zones, but it's still an issue on days with leap seconds. What should the result of `December 31, 2016 23:59:60 + 1 day` be? It can't be `January 1, 2017 23:59:60` because it doesn't exist.
Ouch, I didn't realize TCP could be so complicated! Good luck :D
Still doesn't work on mobile. :(
Works very smoothly for me (Android/Chrome/Pixel 2XL) [screenshot](https://i.imgur.com/854dF75.png)
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/cogciprocate/ocl) - Previous text "ocl" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dxuh5h3) 
Yeah, for me typing is fine, vim keybindings mode also works as expected.
I'm not sure why that's such a big deal, and it would be a lot of work.
I had a look at ocl, but it's not all that I'm looking for. In the examples, the compute kernel, the real "meat" of the program, is still just declared as a static string of OpenCL code. I'd love if it could be 100% Rust.
For the 99% of what? Chrome &amp; Firefox both have built-in PDF readers. Windows, Linux, macOS, iOS, and Android all have PDF reader apps that come preinstalled. Who can't read a PDF?
Usability significantly decreased - now you have to go into menus to do anything. Yes, the interface may *look* cleaner, but you are not supposed to admire playpen visuals, you are supposed to press those now hidden buttons first of all.
 let mut rom: [u32; 1 * 1024 * 1024] = [0; 1 * 1024 * 1024]; The type [u32; 1 * 1024 * 1024] represents the ACTUAL 4 MiB array. Your code is putting the entire 4 MiB array on the stack. What you want to do instead is use Vec, like this: let mut rom: Vec&lt;u32&gt; = vec![0; 1 * 1024 * 1024]; Now rom is a Vec that dynamically allocates the buffer and will automatically clean it up when it goes out of scope. But more importantly, the Vec only takes up a few bytes on the stack, for the ptr, length, and capacity of the Vec.
The Ace editor is not optimized for mobile usage. Click on the "Config" menu and select the "simplified" editor.
I did not read your full comment. Maybe my crate "kairos" is what you're looking for.
Maybe my crate "kairos" is what you're looking for.
Circling back around to [ggez](https://github.com/ggez/ggez/), a lightweight cross-platform game framework for making 2D games inspired by Love2D. After figuring out my [giant blog post](https://wiki.alopex.li/GgezOnWasm) and playing around more, my tentative plan is to do all the "easy" stuff that ggez still needs doing and call it 1.0. Then work on a much more experimental 2.0 can proceed on the basis that it will be able to be run on `wasm32-unknown-browser` or some equivalent, and I can happily yak-shave my way into making that equivalent exist.
What do you mean pass a lifetime through? If you want `Memory` to own `ram`, you probably don't need a lifetime, and also, why not do the same thing you're doing with `rom`, where you pass a `Box&lt;[u32]&gt;`?
Got to convince Dropbox to do one. I think they're using it on the client-side now? Would love to hear about that.
You should upgrade from that Amiga to a real OS. Even a free one like Linux will do the job, something after 2005 should be able to handle PDF’s. Or ditch that Nokia from ‘98 and get a cheap Android phone. 
I'm working on a rust library for a gtk widget using gir, OsmGpsMap. The FFI bindings generated fine, but when I try to build the library it's not creating any functions. Would someone mind looking? https://github.com/etrombly/osmgpsmap-rs
Problem is that Android phones are going to want you to download it and open it in an app.
Regarding `+1 month +1 month` being different to `+2 months`, it doesn't have to be. There can be a non-normalized form and a normalized form. So in the non-normalized form, 31-Apr can be permitted as an intermediate value.
To be honest, I'm shocked there isn't one already considering there's over 40 languages supported. Oh well, better late than never.
Do you actually use the Vim keybindings on mobile? Are you using a hardware or software keyboard? I can't imagine using the Emacs bindings (my preferred) with a software keyboard.
For the most part, floating point numbers in Rust act the same as in C or Java or many other common languages. Arithmetic operators like `+` and `-` work the same way, as do common functions like `max` and `min`. The main thing that Rust does different from many other languages is distinguishing types that have a [total order](https://en.wikipedia.org/wiki/Total_order) (the [`Ord`](https://doc.rust-lang.org/std/cmp/trait.Ord.html) trait) from types that are [partially ordered](https://en.wikipedia.org/wiki/Partially_ordered_set) (the [`PartialOrd`](https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html) trait). Because of `NaN`, not all pairs of floats have a defined order. Rust's standard library prevents you from using methods like `sort` without defining how you want to handle `NaN`. In other languages, calling `sort` on a sequence of floats that includes `NaN` will usually have implementation-defined behavior that may depend on the initial order of the sequence.
Most of the time it isn't. A HTML page being easy to read is much more dependant on who made the HTML. I much prefer reading a PDF for long blocks of text.
The path + query string part could be parsed as a relative URL using the [url](https://crates.io/crates/url) crate.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://crates.io/crates/url) - Previous text "url" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
/u/kyren [listed the crates they used 6 months back](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/dosz4er/). You may find some more info in the rest of the posts, though I don't think they provided very fine details, and Witchbrook (formerly Spellbound) is an ARPG so I don't think it'd have networking? Not sure.
&gt;implying pdf isn't dependant on layout and font and etc
Haha no, I don't actually use them on mobile, I only included this as a datapoint in case u/JBinero's problem might be due to a keybindings thing. I'm glad I mentioned it though because it seems to have made someone else's day :P 
LISP is good for extremely dynamic systems/programs. Where in rust you might write up what you're doing/have to understand the problem very well, in lisp you explore the problem through code. This makes lisp really good for rapid prototyping
&gt; mod.rb Oh how your motor memory betrays you ex-ruby developer :P
Alright, sweet! I've got: pub struct Memory { ram: Box&lt;[u32]&gt;, rom: Box&lt;[u32]&gt;, rom_mapped: bool } which I initialize with: Memory { ram: vec![0; 1 * 1024 * 1024].into_boxed_slice(), rom, rom_mapped: true } And it all seems to be working now :-) Thanks for the pointers! Was there anything in there that looked like bad practice or bad style that might catch me out later on? I had a couple of problems with borrowing both mutable and immutable references, apparently. In Cpu::step, I was calling `exec` and passing `self` as an argument. It didn't like that, and I had to change it to pass `self.registers` and `self.memory` separately. Couldn't find any way around that. Similarly: self.registers.set_reg_no_flags( 15, self.registers.reg_no_flags(15) + pc_increment ); has to become: let new_pc = self.registers.reg_no_flags(15) + pc_increment; self.registers.set_reg_no_flags(15, new_pc); That's more self-documenting style anyway, but it seems to be saying that... `self.registers.set_reg_no_flags` is borrowing a mutable reference to `self.registers`, because `set_reg_no_flags` takes `&amp;mut self`, so I can't *at the same time* borrow the immutable reference to `self.registers`that `self.registers.reg_no_flags` needs. Am I right in thinking it disallows this so that it can't guarantee to `reg_no_flags` that `self.registers` won't be mutated by `set_reg_no_flags`? If so, the part I don't understand is that `reg_no_flags` has already returned before `set_reg_no_flags` executes. 
Besides what the others have written, it's also not unusual to have them printed and available at e.g. conference booths.
I am looking for a Rust debugger. Has anybody managed to get gdbgui https://gdbgui.com/ to work with Rust? it looks impressive. I have used cargo to build a Debug profile executable. Opening it in gdbgui was initially moaning about scripts that couldn't be loaded so I followed the hacks here: https://github.com/rust-lang/rust/issues/33159 and that went away. But now it just says Reading symbols from target/debug/thx... done. File not found: main
Ha! I had a few people look at that post before publishing and they all missed that.
&gt; Others only use the playground for WASM and others could care less about generating LLVM IR I wonder if a lot of the perceived annoyance could be addressed by making the "Run" button dynamic: have it show the last-used run/build/LLVM IR/... option. This might end up being confusing, but would make the edit/output loop feel nicer.
Working on the latest release of [mem_file](https://github.com/elast0ny/mem_file). Because this library is aimed for high performance apps, I added flexibility by allowing the user to pick the locking mechanism to manage concurrent accesses to better fit their needs. I'm also going to implement an API to open shared memory that isnt managed by mem_file to allow compatibility with other languages/libraries.
&gt; I much prefer reading a PDF for long blocks of text Splitting hairs here, but I tend to prefer HTML for the flowing layout, oeasier on my eyes on my ereader or my smartphone's small screen.
Yep, that's actually another idea that we've been bouncing around, as well as adding explicit "run tests" / "build only" / "build &amp; run" options to that dropdown to expose that existing functionality more obviously.
&gt; My project is a fairly basic service that accepts TCP connections using RESP, does a bit of optimization for types, and dumps the data into a HashMap. Nothing too special but it does allow me to learn a wide range of concepts. Hey, my first non-trival rust learning project was also a toy redis server using RESP. Highly recommand to rust beginners! Here's the plan I had before went into the project: https://github.com/yiransheng/rust-toy-redis/blob/master/PLANS.md 
&gt; [..] rust's floating point numbers are much **easier to work with** then other languages. You know, considering I had to write a pile of extra code just recently when porting some code that used floats from D to Rust... "easier" isn't the word I'd use. Like, *at all.* I'd say floats are a real discomfort in the sitting hardware, at minimum. mbrubeck pretty much already covered why. Now, to be fair, the ported code ending up being a *lot* more well-defined than the original, largely *because* I couldn't ignore NaN. Quite a few fields ended up having `f32` replaced by `Option&lt;r32&gt;` (`r32` being a wrapper that removes NaN), which makes it much easier to keep track of whether "no value" is possible or not. So it's not like they're a colossal arse agony for no reason. Then again, I can't do a `match` on `r32` constants no matter how much I promise to the compiler they don't contain NaN, so that kinda sucks.
What's the best way to run two separate instances of Rust (nightly + stable)? On Linux if it matters
&gt;I would make methods for reading/writing little endian or big endian u32s from/to the rom (using the byteorder crate). Presumably that would involve four load/stores each time. Is there any way that can be avoided? Reading/writing memory will be a significant hotspot.
(The PDF title is "Microsoft Word - ..." which ends up as the title of the browser tab in Firefox and Chrome, at least.)
Using rustup: https://rustup.rs/
I don't know anything about gdbgui, but I'm guessing its running something like `break main`? This doesn't work for rust binaries, since rust function names are mangled. (or something?) Need to use a file:line breakpoint instead: `break main.rs:10`.
The readme and contributing say 1.5GB RAM and 3.5GB disk space required. I'd recommend &gt;4GB RAM, &gt;=4 cores, and &gt;30GB free disk space.
This is weirdly common for PDFs that I see in the wild. I presume it's a side effect of using Word's built-in PDF exporter.
Wondering if anyone can tell me how it's possible to guage a ruby app's performance with Rust, like they do at Tilde? Sounds fascinating to me!
Sounds good: have the '...' be the full menu (with explanations, etc.) and the red button just be a cache.
It mostly hurts generic code. Here's some code to build a LUT/sequence-of-indices representation for a sequences of values: [C++](http://coliru.stacked-crooked.com/a/4801ed5495ad4b7b) [Rust](https://play.rust-lang.org/?gist=e1ba507f8b61447a00b5ff12c1c6109d&amp;version=stable) Floats can't be put into a hashmap (they're neither `Hash` nor `Eq`) so it doesn't work for them in Rust.
For the `Cpu::step` problem, the reason borrowing `self.registers` and `self.memory` separately works is because those only borrow parts of `self`, not all of `self`. In this piece of code: impl Cpu { pub fn (&amp;mut self) { ... // fn decode(&amp;self, word: u32) -&gt; Option&lt;&amp;Instruction&gt; let maybe_instruction = self.decoder.decode(fetched_word); ... if ... { maybe_instruction.expect("...").exec(self, fetched_word); } } } `maybe_instruction` might contain an immutable reference to the decoder, so `self.decoder` is immutably borrowed. `.exec` is really going to be `Instruction::exec(&amp;self, cpu: &amp;mut Cpu, ...)`, which, if you reduce to the borrows, would be `Instruction::exec(&amp;self.decoder, &amp;mut self, ...)` (where `self` is the `Cpu`, not the `Instruction`). That clearly doesn't work, because `self` includes `self.decoder`, but changing it to `Instruction::exec(&amp;self.decoder, &amp;mut self.registers, &amp;mut self.memory, ...)` *does* work because none of those borrows overlap each other. Hopefully that makes sense, my notation for that is not standard whatsoever!
Apart from c stub generation, most of my actual preferences between Ctypes and Rusts FFI, are me preferring it's API. One thing I really like is you can use type representations interchangeably, by writing bijections. I don't want to make another TLDR post, so read these if you're interested. http://simonjbeaumont.com/posts/ocaml-ctypes/ https://github.com/ocamllabs/ocaml-ctypes/wiki/ctypes-tutorial https://realworldocaml.org/v1/en/html/foreign-function-interface.html
Curious to know how they handle memory allocation without overuse of unsafe blocks and also curious about some architectural questions. Have Chucklefish had a good history of responding to inquiries regarding code structure in rust? 
Are there any game engines for Rust available to the general public developers without a licencing fee? 
But someone could define their own Hash for them right?
Yup! I’m not aware of any non-free ones.
How would one try to go about promising to the compiler that they cannot contain `NaN`?
You can't impl `Hash` for `f32`/`f64` of course. Typically people wrap them in a newtype (ex. [1](https://github.com/SergiusIW/noisy_float-rs) [2](https://github.com/reem/rust-ordered-float)) and impl stuff on that but then you deal with plumbing (eg. I have this `Vec&lt;f32&gt;`, how do I get a `&amp;[r32]`? Do I need to allocate? etc).
Is there any type with one owner and multiple weak (or reference counted) references that can work with serde? The closest I've found so far is [froggy](https://github.com/kvark/froggy).
Lol, should there be? That seems like it would be useful. Also, is it possible in the Rust type system to make 0-addition sized structs? Basically, have a wrapper to an `f64` or `f32` within a struct that is the same size as an `f64` and `f32` respectively? 
Sure, you just... don't add anything else to the type you define. I can't think of any situation in which Rust would make a structure with one field larger than its contents.
I was just wondering because of fat-pointers
Does this mean the PDF isn't [written in Rust](https://github.com/fschutt/printpdf)? Shame! Immediately rewrite it! Burn the lowly Word peasants!
Thanks for the explanation. It sounds like you're looking for a higher-level FFI layer that avoids having to write as many of the binding details by hand, and I'd agree entirely. bindgen can help with some of that, and I've seen some other binding generation tools that help as well, but this is definitely an area where I think most Rust FFI libraries simply assume you don't mind calling a raw C interface from unsafe code. I'd like to see higher-level layers on top of that, too.
Even with `--frozen`? And adding dependencies is never silent for me.
I usually have a rule that I import everything from the crate root, i.e. `use types::qarray::QArray;`. I learned this during a big refactoring, when I suddenly didn't know what file `self::qarray` referred to before the refactoring and how I split up my types folder. Using `self` or `super` in an import is a big no-no for me. And with the new syntax with `import types::{qarray::QArray, qinteger::QInteger};` I find this much easier to look at when refactoring files. 
Maybe when that project is shipped...
Pfft screw recreating word, recreate LaTeX!
&gt; As well as that, there are pure Rust libm implementations that should have a good amount of those missing functions. Which ones? The most complete one I know of is [this one](https://github.com/nagisa/math.rs).
So you've accidentally stumbled into the _current_ biggest of piece of drama in the LLVM mail listing. For a sub-set of _all_ programs this is likely possible to prove (in isolation) provided everything is constant. Once you start accepting input from (keyboard, configuration files, environment variables, cli, network). Now that simple `let z = x/y;` Provided `x` or `y` originates _somewhere_ external (to the compiler unit, or program), you've hit the `Nan` edge case again. Also we should discuss that how hardware handles floating point errors is platform defined (ARM, and x64 do different things). [This blog post is great](https://randomascii.wordpress.com/2013/07/16/floating-point-determinism/) as it explains just how _hairy_ floating points can be. 
Yeah, I've been using Amethyst quite a lot on a few personal projects. Would highly recommend it. It has some incredible, dedicated developers working on it, many of whom also work on gfx-rs, the graphics abstraction layer used by Amethyst. Quick thing to note, Amethyst uses an ECS system called [specs](https://github.com/slide-rs/specs) which is, without a doubt, the most correct implementation of a parallel ECS I have ever worked with. 
http://arewegameyet.com/
A little while ago I was playing around with Amethyst during my down time, trying to make a pet project game with a friend. I knew I needed a scripting language and so I fell back to my most familiar friend from C++ engine development: Lua. I went looking for Lua bindings in Rust and they were unsurprisingly a bit scarce as lifetimes and ownership are challenging things to reason about on their own, let alone in the context of a hosted language. The most mature implementation I found was Chuckefish's [rlua](https://github.com/chucklefish/rlua/issues), but it was missing something I desperately needed, the ability to safely store Lua function handles alongside the Lua context with which they are associated (think callbacks, a la Unity components). I posted my issue to GitHub and kyren, the maintainer and Chucklefish developer, not only took the time to answer my rather ignorant question, but to explain the intricacies of Lua and its interaction with Rust. He then implemented an entirely new interface for interacting with the Lua that both solved my immediate problem and opened up a whole host of new features and use cases for the library. Tremendous developer and tremendously nice dude!
Any chance to have keyboard shortcuts for Run, rustfmt, etc?
/u/po8 has the best translation of what you wrote, but I'd argue you really don't want to be returning a `String` here. When dealing with paths, there's always the possibility that the path isn't valid UTF8, so using `OsString` is going to be strictly more correct. Something like this will do that: use std::env; use std::ffi::OsString; pub fn get() -&gt; Option&lt;OsString&gt; { env::var_os("JAVA_ENV_MANAGER_HOME").or_else(|| { env::home_dir().map(|path| { path.join(".java-env-manager").into() }) }) } It's very equivalent to /u/po8's solution, but will also work if paths aren't strictly valid UTF8.
Would you consider using `or_else` rather than `or` so `env::home_dir()` isn't unconditionally called? It seems like this will do a small amount of extra work when the env variable does exist.
There already is for run (control/command-enter; `:w` in the Vim keybindings). but yes, we plan on investigating keybindings. You can see the prototypes on the [user's forum post](https://users.rust-lang.org/t/playground-ui-prototype-feedback/16692)
It's so great to see companies finding use-cases for Rust, especially switching completely to primarily using Rust! I've personally experienced a lot of opposition from certain C/C++ developers to considering Rust, and commonly I think it's a case of "You don't know what you don't know" in regards to the benefits of the type system and crates. I think that's why companies sharing their real-world experiences with Rust are really important for adoption.
The reason I don't love the enum method is because you either have one giant enum that contains more error variants than most functions could return (leading to proliferation of `_ =&gt; panic!("unexpected error {} for fn X")`), or you end up with a separate enum for each possible combination of errors any function returns - in the extreme case, an enum per fn.
I would pay good money for a LaTeX replacement that has sensible errors...
I'm not sure I understand what you're talking about. I use giant enums all the time and have never written your stated panic message.
I better LaTeX is one of those things I would build if I had infinite time. Sadly, I will be long dead before I can ever get to it.
Knowing C before learning Rust will indeed lend some very valuable perspective. But I don't believe it's necessary.
I don't think there's much point in learning C for that reason. You might not know the pain of debugging memory corruption due to dangling pointers and buffer overflows, but knowing that pain is not going to make you a better programmer, only enhance your empathy with C programmers :) Many of the other benefits of Rust are also benefits over other languages like Java and C#.
Actually it shouldn't, `byteorder` implements `read_u32` and `write_u32` using the `copy_nonoverlapping` intrinsics, which should get optimized to appropriate sized loads and stores (and to sse instructions for larger copies, similar to how `memcpy` gets optimized). See here: [godbolt example](https://godbolt.org/g/L9eDbt), the `copy_nonoverlapping` line is just a single `dword` `mov`
Thanks for the response. I am currently working as a Java developer and enjoy doing it, but also want to learn rust. However I am super conflicted right now on whether I should do a bit of C first just to get familiar with low level programming then dive into rust.
I'm attempting to bring `#![no_std]` + `alloc` support to [proptest](https://github.com/AltSysrq/proptest) , because the embedded universe could use more rigorous testing tools.
I really like the elaborated options and how much more obvious it is which options will persist when you produce a shareable link. Good work!
&gt; Most of the time it isn't. I prefer HTML 99 (1 percent is HTML with really bad formatting) percent of the time on desktop/laptop. Reading PDFs on mobile I hate very much and if it is more than a few pages I will convert it to a mobile friendly format. 
I think most of the Rust community comes from non-C / C++ backgrounds. The book is written assuming you don't have any understanding of low level programming. You'll probably want to pick up at least some understanding of C and pointers if you're going to do Rust long term since bindings are a thing but I don't think there'd be a pedagogical benefit to learning C first.
Ohh, sweet. I'll go with that, then. 
Oh my, LaTeX but with the simplicity (and power) of ripgrep... A man can dream.
Actually, I don't think there is a wrong choice here. You're not wrong that knowing C (and its pitfalls) can help you appreciate Rust more. C is also a widely used industry language, and elegant in its own way. But, IMO some of the biggest benefits of Rust (ex. that it tries harder to force you to write correct code) become most obvious when you're working with a large C codebase that you didn't write, that also has a lot of other imperfect programmers working on it, and you have witnessed (and/or had to fix) a lot of dumb things that Rust prevents from happening in the first place. Getting to that point is a little beyond just "learning C". (The same thing goes for C++, except replace "elegant" with "powerful") Hope it helps. 
Can anyone recommend any good small crate to how to organize your code?
Note that Rust has no strict aliasing rule of any kind. This is not yet documented prominently because it is naturally part of Rust's memory model which is not yet set in stone, but it is absolutely the intention that changing Vec&lt;u32&gt; to [u8] as in the current example is a defined behavior. Sorry for not providing a source. I believe this is a folklore among Rust compiler developers.
this is sick 
Are you aware of [specs](https://github.com/slide-rs/specs)? If so, what are your feelings on it?
I believe you. I went back and read this thread here of someone else doing the same thing. https://ayende.com/blog/176801/the-struggle-with-rust?Key=ed64b64e-91c9-41be-ba0f-348641976e20 comex says that rust has no strict alias rule.
https://play.rust-lang.org/?gist=427906b1553c0db2117dc849827bd064&amp;version=stable You get warnings about how it will be phased out, but it does execute and print "hello"
That's not what I've been talking about. [This is](https://play.rust-lang.org/?gist=e9715628a5a6e735537c57675a62bc76&amp;version=nightly). You can't use floats directly because allowing that would blow a giant hole in the whole "exclude NaNs" thing.
Yep, I have seen specs and it looks pretty cool IMO (although I haven't used it yet). If I were to build an engine/game (not just for learning purposes) then I would definitely look into using it.
Having used django quite a lot, I'm quite hostile to the popular 'just populate a real database with test data to run tests and call it unit tests' approach. However, it has value for some purposes (integration tests for example). Practically speaking though, the goal here is to fabricate an object graph on demand, with some automatically generated values; won't adding derive on a struct bloat the final binary with irrelevant test harness code? You could argue that you use test cfg for this, but then you won't have them for integration tests right? I'm not sure I see the specific benefits of this approach over factory functions.
[removed]
I'm a dude, he's a dude, she's a dude, cause we're all dudes! HAY
Great explanation. I think it's also useful to point out that `&amp;mut self` is syntactic sugar for `self: &amp;mut Self`, although that detail may just be confusing. (I'm not very good at knowing what details to leave out when explaining things.) 
Late reply, but thanks!
It is enough, but Pijul's internal representation is likely to be more expensive in disk space than Git's. There is a trade-off, and we decided (about two years ago) to go ahead with this project because disk space is cheap.
Waaiiitttt, though. If it's optimized for non-overlapping accesses, how do I get the `[u8]` to be aligned on a 4-byte boundary? There are some suggestions of over-allocating ignoring the first 0-3 bytes, but that seems a bit hacky. Still trying to figure out whether on the WebAssembly side I can pass a UInt32Array as a [u32].
In case you missed it, I sent you a Pull Request with a config for Travis CI, which allows you to run tests in various integration environments on Linux and MacOS. You can sign in with your github account, activate the project and merge the PR. Let me know if you need something, I'd like to use men_file in [mutagen](https://github.com/llogiq/mutagen), but I don't want to special-case MacOS.
I have 2 cores and my rust workspace takes up 7GB of disk space.
More TWiR, and trying to add [wait-timeout](https://docs.rs/wait-timeout) to [mutagen](https://github.com/llogiq/mutagen)'s test runner.
Nice read and nice discussion. A bit off-topic, but I can highly recommend both &lt;http://comic-rocket.com&gt; and &lt;http://piperka.net&gt; for your webcomic tracking needs. Both have solid webcomic crawlers and allow my friends and I to manage very large pools.
As a massive Rust fanboy and a gamer who enjoyed Starbound and Stardew Valley, I am greatly looking forward to Witchbrook (formerly known as Spellbound)!
&gt; TBH I really like how you challenged me and I think all your concerns are relevant. You made me think much deeper that I was planning at this stage. Same. I might just be too miopically focused as a Rust contributor on "this might be too much work for me or the people I know for unclear wins". I think there is a tension point between those working on the compiler/std libs understanding user expectations and users understanding how things really work underneath. In Rust this differences often are very tiny because it is really easy to hack on the compiler and "everybody can do it", so many intermediate-advanced Rust users have hacked on the compiler at least once and that gives them perspective when asking for things.
I guess the answer to that depends on what sort of game you're building. For example, if you only have a player that can collide with objects, but the objects can't collide with each other then it should be fine to just setup a system that takes a "Positionable" component and check it against your player as O(n), where n is the number of Positionable components you have. But if you have a game with lots and lots of objects, all collidable with each other then checking an object against all the other objects is easily O(n^2) which likely won't be good enough. Then you might have to setup some sort of library specifically for performant collision detection. (Making a lot of assumptions here but I think the gist is the same)
Make sure that the version of `futures` that you've specified in your `Cargo.toml` is the same as the version that `hyper` is using. If `hyper` is built on `futures ^0.1.0` and your code is pulling in `futures ^0.2.0`, which aren't compatible, you'll get these kinds of errors.
Awesome!
The hashmap problem is, in my opinion, mostly a problem of the standard library: why is it impossible to provide a struct that hashes and performs equality checks when creating a new hashmap? Java also has this problem, but in C# you have the `IEqualityComparer` interface and it's great. This would also mean you wouldn't have to deal with defining newtypes whenever you want an alternative hash and/or equality.
Yay, first time posting here. I'm working on a command line Reddit client, called [boba](https://github.com/baspalmer/boba). It's not rocket science, but it's fun to work on. Even though a lot of features are still missing, I still use it on a daily basis. Hopefully I can flesh out the project this week with some extra features.
good bot
Thank you, ibotty, for voting on TweetTranscriber. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Fixed and thoroughly embarrassed!
These kind of error messages are what made me quit Haskell. I added or upgraded a dependency and it was incompatible with the existing one and I couldn't figure out how to upgrade them to be compatible. Not everyone comes to reddit to complain. This is a huge pain. People might give up on rust because of this. I could not find an appropriate issue on github. Shall I create one? A possible solution could be: When generating E0599, check if the name we need is already in scope. If that is the case, then warn about conflicting versions.
No need to be a dick. 
Don't have any hardware with me, so no embedded stuff for a while. Going back to my photo app https://github.com/etrombly/photos-rs . So far it clusters photos based on location or time, going to add other features later. Finished writing the reverse geocoding lib for it (will publish soon). And trying to build rust bindings for an openstreetmap gtk widget now.
&gt;These kind of error messages are what made me quit Haskell. I added or upgraded a dependency and it was incompatible with the existing one and I couldn't figure out how to upgrade them to be compatible. &gt; This is almost every language though. I used to run into these issues all the time in Java projects with Maven. Perhaps the Rust ecosystem could have a better way of warning when two versions of the same crate are used transitively in the same module?
They've done an AMA here six months ago, maybe they already have some answers there for you.
No, not necessarily. Rust will be harder to learn if you never had to think about memory before but it's definitely doable. I've never written a single line of C nor C++ and I'm working with Rust full-time.
&gt; as do common functions like max and min. Well, the regular `max(a, b)` doesn't work because it needs `Ord`. You have to remember to use `a.max(b)`.
Ironically, I think many more person-years have been lost trying to debug LaTeX. Still, we can be thankful Knuth got it to where it is.
Yeah the confusing part of the error message is that it suggests: &gt; use futures::stream::Stream; instead of &gt; use hyper::futures::stream::Stream;
It should actually do that if the name is a struct. https://github.com/rust-lang/rust/pull/28300 Maybe /u/Manishearth has more insight into why this is a bit more tricky for traits. (see the comment in this issue: https://github.com/rust-lang/rust/issues/22750#issuecomment-138912690) In any case, this is definitely an issue that we'd like to improve (as always), but also need more hands for (as always ;)).
But floats are not even partially ordered.
Is there somewhere online (rust-lang.org?) where all the case studies and listed? 
Well those methods are implemented using `libm`, which is a library that the LLVM intrinsics call into in the generated code. So... if you write `#![no_std]` to tell the compiler that you don't want any std library, then... you don't get any. This is pretty obvious to me.
Memo to self: Remind /u/burntsushi of this comment after they become immortal thanks to the AI singularity
So the column would be of type varchar right?
I'm pretty new to databases, I never used once before tbh. I took a look at WordPress' schema. The post metadata table that stores the post_id, a value, a key and has a unique ID looks actually good. Would creating such a table be a good idea for my usecase? So plugin stuff I basically put in there as a key value storage solution, optionally linking to an artist or song if needed to.
How is this being a dick? It's a quote from Good Burger where the protagonist is saying we should be good to each other because we're all dudes. 
True. On mobile things change quite a bit. Personally i only read reddit on mobile so I'm good. :)
how has this gotten -9 lol. For a subreddit like this, where discrimination isn't appreciated, I'd imagine something like this would get more upvotes. Who cares if kyren is a woman or not? It does not matter at all, anything else is discrimination.
Looks great, but I can't find any description of what the actual keybindings are?
I actually hadn’t thought of that! That is definitely a problem...I think the best solution would be if Rust’s `alloc::heap::allocate` was stable, which allows you to allocate with arbitrary alignment. Unfortunately, that is unstable *and* unsafe. Another option is creating a `Vec&lt;u32&gt;`, converting it to the raw parts (ptr, len, and capacity), and then constructing a `Vec&lt;u8&gt;` from the raw parts (with len and capacity multiplied by `size_of::&lt;u32&gt;()`. That’s still unsafe, but at least it’s stable. `std::mem::transmute` would be undefined behavior I think. This is an unfortunate situation obviously! FWIW though, I was looking at the assembly for `store_u32` on a `Vec&lt;u8&gt;` and it was using `movl %eax, (%rbx, %rax)` to do stores to the allocation at `rbx` with offset `rax` with value `eax` (and similarly for `read_u32`), even though it allocated with alignment of 1, so maybe `rustc` is taking advantage of some knowledge that jemalloc only allocates with alignment greater than or equal to 4? I’m sure that might be affected by webassembly though
npm managed to solve that problem quite well
cargo tree -d to see duplicate dependencies of different versions. One of the dups is probably your problem. Very annoying problem the first time around, I agree.
I don't know of a crate, but it's basically: let parsed: Result&lt;Vec&lt;u8&gt;, _&gt; = string .split_whitespace() .map(|chunk| u8::from_str_radix(chunk, 16)) .collect()
&gt; what are factory functions? It's nothing special, just a function that returns an object; but specifically *unrelated* to the object it manufactures. (ie. It can sit inside a `#[cfg(test)]` block, and is omitted in release builds)
Which part isn't true? `num::FloatCore` doesn't even implement `sqrt`, and many other mathematical functions, because they do require `libm`, and the ones that they implement, while they are in pure rust, are not comparable to those that `std` uses, which calls LLVM intrinsics directly that LLVM is able to reason about for optimizations and that LLVM then lowers to `libm` calls.
Hi! Is it good practice to pass &amp;Box&lt;a closure&gt; in Rust, when needing to pass the same closure several times to functions? For instance: type Adder = Fn(u32) -&gt; u32; fn create_adder(added_number: u32) -&gt; Box&lt;Adder&gt; { Box::new(move |number| -&gt; u32 { number + added_number }) } fn use_adder(number: u32, adder: &amp;Box&lt;Adder&gt;) { println!("{} -&gt; {}", number, adder(number)); } fn main() { let adder = create_adder(42); use_adder(10, &amp;adder); use_adder(30, &amp;adder); } If I remove the &amp;, I'll get: error[E0382]: use of moved value: `adder` --&gt; src/main.rs:19:23 | 18 | use_adder(10, adder); | ----- value moved here 19 | use_adder(30, adder); | ^^^^^ value used here after move Is there another, better way of reusing the same closure over and over again, apart from passing a reference to the Box that owns it?
I thought I'd had the same problems with NPM. What do they do differently?
[In the next stable (today's beta), closures will implement `Copy` when all state they capture is `Copy`.](https://play.rust-lang.org/?gist=0459e28a324f4cec51d8b57d8918199f&amp;version=beta) So at that point, you can reuse the closure as many times as you want so long as it only captures `Copy` data, so mainly references or primitives. Your other option is to drop monomorphism and take `fn()` rather than `impl Fn()` -- note the lower case `f`. A `fn()` is a function pointer, and those have always been `Copy`.
Seems like it *should* be possible to match sanely on something with just `PartialEq` as long as there's a default match clause. Might be interesting to play with something like that and see how it works...
That's really weird, I didn't think deriving a trait was any different than implementing it. Do you know why this is?
I have no clue what it is for, but it has fancy graphics 
Typo in the readme: &gt; ...real-time **PubSab** applications...
ECS is used by a lot of AAA studios in games. One example would be Overwatch.. have you heard of that one? :P 
I didn't know about that, thanks!
No problem!
And copy/paste with the middle mouse works again with the simple one! Big thanks for that hint.
Hi! I cannot for the life of me figure out how to get mouse input in Rust (as a learning exercise) - my google foo must be a little off. I understand it may be quite a complex issue (incumbent on a number of platform specific idiosyncrasies)...but I can't even find a low level API to experiment with, let alone tackle whatever complex issues may arise. Can anyone point me in the right direction??
Yes I've played Overwatch. I know that it's probably a solved problem, but what I'm questioning is the rust libraries and whether the foundation they provide is all an ecs system requires. I would hazard a guess that theory and practice is very much like oil and water. But to be honest I don't know, I haven't seen an example of a rust implemented game using ecs. Maybe there are some out there? That's what I'm asking
Oh, I see. Making it trait-based would probably be the way forward (where `#[derive(PartialEq, Eq)]` would generate a *third* `impl`, instead of adding a magical attribute). Although, to be fair, I'm not sure what's happening with pattern-matching floats.
I consider this on-topic because [one of the working groups](http://blog.qt.io/blog/2018/04/23/beta-qt-webassembly-technology-preview/) we have is dedicated to making Rust and WebAssembly awesome. It's interesting to see other technologies making the same decisions and experimenting in the same way!
I was guessing that `ModelInfo`'s `str_int` contained a reference to `StrInt` does, but I was wrong, sorry.
I see that you have multiple `example`s, perhaps we can change the Travis script to run them instead?
There are different ways to solve entities interacting in an ECS system and there are pros and cons just like anything else. For example attaching empty components to an entity to 'tag' it. Or creating events in one system that can be consume by later systems. Sometimes what you think may require elaborate events to realize entity interaction really just requires breaking a single system up into multiple systems with discrete phases.
Did I miss a link to this page on the main site? Can’t seem to find one.
There is the fantoccini crate https://github.com/jonhoo/fantoccini that is connecting to a webdriver ...
That does look way too low level compared to Puppeteer but thanks for the hint.
I'll give a go at an explanation. **PubSub** - **Pub**lish+**Sub**scribe. A system for communication in an application which uses messages. Clients can publish messages which are then pushed (or made available to) other clients which have subscribed to that type of message. I've used PubSub to organize communication within a process (it's basically a fancy queue at that point), but this looks like it's for communication between processes or servers, using TCP. **Scalable** - There can be more than one TreeScale service used to transmit the same messages. This allows it to scale past the capabilities of a single server. **Decentralized** - When using multiple TreeScale message brokers, there is no designated "master" or "root" message broker which makes all the decisions. Each instance is equal, so one going down can't take the whole system down. 
&gt; This basically means that each package is guaranteed to get a version compatible with its desired version. I'm pretty sure it's still the same problem. If I have two dependencies, A and B, and both use different versions of C, what happens in this situation: import {aFoo} from A; import {bBar} from B; let cValue = aFoo(); // cValue is an object from C bBar(cValue); ? I'm fairly sure that NPM doesn't solve this any better than Cargo, Maven or Cabal. 
NO RAGRETS
SILE is a really good attempt at a 'modern' TeX: http://sile-typesetter.org/what-is/ Not sure if it's good enough to overcome inertia, but we'll have to see.
Last commit was a year ago though, so is it inactive now?
Sounds like a good idea for a new crate. You can just fork std's HashMap and add this feature.
I thought the exact same thing when looking at the repository. But it would be really cool to have a fast pubsub server/framework for/in Rust!
&gt; I understand it may be quite a complex issue (incumbent on a number of platform specific idiosyncrasies) Yes :) It depends on what you're using to get your application window. At the low level, the operating system provides messages for mouse position, etc. to the application with their specific APIs: win32/X11/cocoa(?). If you're using those APIs directly, that's what you'd use. Cross-platform application toolkits like wxwidgets, qt, or gtk will have their own message types which abstract over the platform differences more-or-less. If you're using one of those toolkits, you'd use their APIs. Then there are the simpler cross-platform windowing toolkits usually used for games like GLFW, SDL or (in Rust) winit. These also have their own message type abstractions, so if you're using one of those, you'd use their APIs. If you haven't gotten that far and just want to draw some graphics and get mouse events, I'd suggest ggez: https://crates.io/crates/ggez (which uses SDL under the hood).
The site's in the process of being completely redesigned so I suspect that this is just a temporary place these will be listed till then.
LOL, I love that song. George Harrison is one of my favorite guitarists.
Another option for learning purposes. // Changed to &amp;Adder fn use_adder(number: u32, adder: &amp;Adder) { println!("{} -&gt; {}", number, adder(number)); } fn main() { let adder = create_adder(42); use_adder(10, &amp;*adder); // Changed to &amp;*adder use_adder(30, &amp;*adder); } You don't need `&amp;Box&lt;Adder&gt;`, you can just use `&amp;Adder`. `*adder` dereferences the `Box`, giving you an `Adder`, which is unsized - since it's a closure it can be many different sizes so we can't pass it around like a normal value. Taking a reference to this value solves the problem, since the reference is always the same size. 
Maybe not the best example, but since there are no other suggestions... https://github.com/rust-lang-nursery/mdBook It's a small-ish, simple-ish project, but it demonstrates a library with modules, using error_chain, multiple bin targets using the library, examples, in-module and separate tests, etc.
The whitepaper mentions a webservice, I am very interested in finding out what framework and libs are used for this. Could anyone point me to more info / sources regarding their stack? 
What makes it highly-scalable?
Note: in C++, you don't even get implementation-defined behavior; you're downright into undefined behavior... and crashes :(
Do you have a some sample code to compare to, like with what you're using? I'd find it interesting to see ways the example you looked at to be simplified. I'm not `fantoccini`'s maintainer, but API design like this is really interesting to me. :)
No. It's because if it's not derived, there's no guarantee you got it right. And if you didn't get it right (like... `x != x` in some cases), then this could open up unsafe behavior from safe code (butterfly effect-like) after series of transformation.
You should take a look at https://github.com/brson/stdx/blob/master/README.md it's a list of recognized rust code bases
There are others too, like [Mles](https://github.com/jq-rs/mles-rs).
 const args = [ "--disable-setuid-sandbox", "--no-sandbox", "--blink-settings=imagesEnabled=false", ]; const options = { args, headless: true, ignoreHTTPSErrors: true, }; browser = await puppeteer.launch(options); browser.newPage().then( async page =&gt; { try { await page.setRequestInterception(true); // catch all requests and check for XXXX url page.on('request', request =&gt; { //console.log(request.url()); if (request.url().startsWith("https://XXXXXX/API.point")) { // do stuff with request.url() request.abort(); } else { request.continue(); } }) await page.goto(urlcomeshere, { waitUntil: 'networkidle2', timeout: 10000 }).then( async response =&gt; { // get all links from DOM const hrefs = await page.$$eval('a', as =&gt; as.map(a =&gt; a.href));
On the IUI page it says, the last commit was 4 years ago. 
As someone who enjoys Rust but hasn't hopped on the WASM train yet, could someone explain the purpose here? I thought WASM was for calling Rust functions from JS but the UI was still HTML/CSS. Where does this fit in? Will Qt compile to HTML or similar? What is the advantage of this vs using WASM for JS functions + normal HTML/CSS? Honestly not trying to be snarky, I'm uninformed and curious :)
Writing web frontends in PureScript is enjoyable (haven't tried yew yet but it looks elegant, too), why would static typing prevent state driven dynamic UIs? IMO, writing UIs can benefit a lot from static typing. Look at the PureScript Halogen UI library, how it leverages static typing for a truly component based UI framework in a purely functional language. All the react / redux stuff is trying to achieve this but can't, because of lack of a powerful type system.
Very cool. Keep up the hard work.
There's a few common ways in an ECS to solve that problem. Remember that ECS architecture puts all logic in Systems. One approach then is that a System computes mutations to any Components, which is sufficient in the event that state is the only communication necessary. When additional communication is needed, another solid approach is for each System to build a set of actions/mutations which are then passed to "downstream" Systems. E.g., the physics System might fill an array of CollisionEvents which the falling damage System might then consume. That System might not even update any Components; it might instead fill in an array of FallDamageEvents which are later consumes by the damage application System, and also the UI System (for displaying floating damage text) and so on. A hybrid approach is possible where a Component exists that just contains event information. Physics might then create a CollisionEventComponent for an Entity that's collided, and other Systems then take effect for any Entity that has such a Component. Realistically, though, games don't do most of that for things like collisions. Games don't actually operate directly on Components. Modules like physics use highly-optimized purpose-specific data structures that know absolutely nothing about the engine's game object hierarchy (often via a third-party middleware like Havok/PhysX/Bullet/etc.) and which are based on more traditional event callback patterns, and the purpose of an ECS physics System in such designs is just to bridge the *real* physics module with Components as thinly and efficiently as possible. Most production game engines _aren't_ ECS, or at least not _pure_ ECS. They might use elements of ECS or just data-oriented programming in high-value locations while still having components with logic or having actual game objects (not just entities-as-ids) or so on. Most of the ones I've ever seen the code for aren't even _remotely_ ECS architectures (not that I've seen every AAA engine out there, or even close to half of them).
You can also see multiple at a time with itertools' `iter.tuple_windows()`.
Looks really good. I was looking for something like that for one of my projects. Is it possible to render the output as triangle meshes?
I’m interested in making a JS/WebAssembly companion to this library! The library looks beautiful and I’m curious to see this out of order ops PR that you mentioned. 
Also, ...**round-rubin** load balancing using **statefull** path calculation Proof reading outside of one's native language is hard and it appears that the author isn't a native English speaker. Hopefully non-native English speakers can see these kinds of corrections as attempts to be helpful rather than pedantic.
I don’t believe they’ve spoken publicly about it.
It's hard to tell what you mean by "handler". You mentioned that it's similar to `thread::spawn``, but I still don't feel like I understand. Can you just have `spawn1` and `spawn2` take a `&amp;T` instead of a `T`?
So wasm is a platform independent file format. While it's main purpose is for running code on the web, it doesn't mean it can't be run elsewhere! As long as you can interpret the wasm it's code that can be executed. Right now though you mostly just use it on the web and can call it from JS or vice versa but that's going to change over time. So qt will compile to wasm and you'll be able to use it in the browser. So you could define a whole app in qt and the browser will know how to render it just as if it has been made for the desktop. My guess is they're doing some DOM calls out to JS since wasm can't do that yet but I'm unsure how qt setup their code. wasm is great for CPU bound tasks that would take some really weird optimizations to get the same perf in JS. It's not really going to replace it so much as coexist alongside it! If you want more information I'm more than happy to point you at resources or other things as well as the working group if you are interested enough that you want to join us!
There are quite a few of those methods not available on `no_std` that are implemented without `libm`or `libc`.
Oh thank you for your opinion. I will definitely update the code
Yeah I think the problem per se is unsolvable, but there are different workarounds. In a dynamic language like JS, maybe it makes sense to just ignore it and assume that the objects will be "compatible enough". Otherwise, your tests will surely catch that, right? ;)
That's a wonderful introduction! Thank you for the information. If you have any links you'd recommend, I'd love to check those out
&gt; Is it possible to produce the output as triangle meshes that can be rendered on a CPU? Not from this library. But you can look at https://github.com/nical/lyon/tree/master/examples/svg_render
Rustdoc will show you all traits that a type implements. As for basic traits, I [blogged](https://llogiq.github.io/2015/07/30/traits.html) about it some time ago.
Awesome thank you so much! 
fantoccini should get more press. A replacement for selenium in rust... sign me up! 
I wonder how difficult it would be to embed it in a yew app... hmm...
&gt; some DOM calls out to JS Yeah, specifically, `createElement('canvas')` and some `addEventListener` :) I'm 99.9% sure they're rendering everything by themselves. Actually 100% sure for QML/Qt Quick because their wiki says some things about using QML's software backend.
My guess is that Qt for WebAssembly uses WebGL when available.
That was it, thanks. I typed "main" into the file browser box that it has it found my main.rs file and displayed it. I was then able to use the mouse to make a breakpoint. So far so good.
The [wg repo](https://github.com/rust-lang-nursery/rust-wasm) is a great place to start with a lot going on there. If you want to learn a bit about where wasm shines fitzgen did some great articles. [This one](https://hacks.mozilla.org/2018/01/oxidizing-source-maps-with-rust-and-webassembly/) was about speeding up source map parsing with web assembly and [this one](http://fitzgeraldnick.com/2018/02/26/speed-without-wizardry.html) is a response to a response to it which kind of goes into why wasm is great here compared to the optimized JS. You can learn a lot from just those two articles alone. If you're still hungry for more ping me here and I can dig up some other great ones to read! Or if others here are let me know!
The doc page for the [prelude](https://doc.rust-lang.org/std/prelude/v1/index.html) has all the global traits/types.
While this is not flawless English, I have no trouble understanding it.
It's interesting the opposition I see. It usually comes in a few flavors: 1) "why not just use c++ and a static analyzer" 2) "the borrow checkers limitations are too strict and stop you from writing anything cool." 3) "you'll spend more time figuring out ownership than you would foxing bugs in c++ so it's moot and why switch" Unfortunately while I like a lot of things about rust, I'm not very good at debating this line of thought. It's nice to see companies like chuckle fish doing that...
What does "as good as librsvg" mean exactly? Do you have some more details, like a feature comparison or how accurate both render the same SVG testsuite?
Just use [`hex`](https://docs.rs/hex) crate? extern crate hex; let bytes: Vec&lt;u8&gt; = hex::decode(hex_str).unwrap();
The readme in the repository has a comparison with other backends as well, showing test results relative to different suites and bnchmarks
Not OP, but there are some test comparisons towards the bottom of the readme. This library is (slightly) more compliant with the official test suite than libsvg
Looks like they *want* to use WebGL for QML but they haven't done that yet, it's software rendered for now.
A question about backends - is [AGG](http://www.antigrain.com/) still state of the art for subpixel rendering? 
From someone who survived all the way from std/mio/rotor/futures this fells like the actual game changer. Question, does async/await fix the return type problem? Otherwise Either was needed to do `if A { future1 } else { future2 }`. 
Largely yes, since you can do: async { if A { await!(future1) else { await!(future2) } }
Yep, that's the game changer. Tons of kudos to all involved :tada:
[Round-Ruben](https://en.wiktionary.org/wiki/Rubenesque)
Correct. You want to create rows of tagged data values where the tags are indexed and few. Rows are very easy to query, filter and iterate and don’t require locks to read or write. The simplest is straight up key/value but having some categories is fine if there is no other way. Notice that in WP everything is a post. Almost everything is in just one table. There are few joins and very little structure. You don’t want structure in your database. The code which queries and inserts the data in the database presents it to the application through an interface using the presenter pattern. It’s decoupled and abstract and that means you may not even need a database. You can stub it out while you develop the application and test it independently from whatever physical storage system you need in production. It’s called dependency inversion. You can decide on a schema and a database AFTER you’ve developed the entire application. Avoid committing to a physical platform as long as possible. The schema is an implementation detail. Don’t let it drive the design of your application and avoid adding unnecessary complexity when a simpler solution would do the job just as well. 
&gt; allowing "worse" engineers to do better This kind of gate-keeping BS makes me so mad. I work in C and C++ and whenever that kind of toxic behavior comes up we kill it quick (I feel like it's particularly common with C/C++ devs). It's one of the things I like about the rust community. A solid code of conduct + inclusivity requirements.
I switched over to async/ await macros this weekend. I've been a bit of a detractor of futures historically, and I'm still not in love, but wow is it so, so much better. My code actually worked. I rewrote it to use async await an it *actually worked*. I couldn't believe it - it was so easy to get it to compile, I figure it must have runtime bugs. The one issue I ran into was exactly what's mentioned in the article. My first ever use of Rc&lt;RefCell&lt;T&gt;&gt;. It was scary - I'd never done this before, I never even really cared to learn too much about Cell's as I'd never needed them before. I actually even attempted that pattern of returning 'self' but it was not pretty and I gave up. I knew fundamentally I could express what the post describes - I "knew" (honestly, I never really know) that there was a safe way to describe this without Rc&lt;RefCell&lt;&gt;&gt;. Anyways, this couldn't have been timed better, thank you for posting this, I am very happy with where futures are headed. The last few weeks my productivity re: building web services in rust has absolutely improved becaese of these features.
If your ML algorithm needs multi dimensional float arrays (e.g. neural networks, linear/logistic regression), take a look at the ndarray crate.
This is huge! I sure hope we can keep the implications under control – it's quite powerful magic, metaphorically speaking.
&gt;At least this gives me another reason to not use/learn Casandra 👍 If youre set against Cassandra, why not use Scylla?
I'm getting a new issue where I wanted to derive `Clone` on the same objects, and using the supertrait trick does not work, saying | 101 | elements: Vec&lt;Box&lt;MusicElement&gt;&gt;, | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `MusicElement` cannot be made into an object | = note: the trait cannot require that `Self : Sized` Any clues?
These can also be put onto executers, correct?
Thanks, it's more concise this way! It's just a little weird to have to do &amp;*, even if I understand why. It would be great if there could be some kind of coercion from Box&lt;...&gt; to &amp;.
I've had a similar though on using it paths instead of whole variables. I was taking it further though, basically make borrows work on full "ownership" paths instead of the whole member. Ownership paths work just as fine for atomic variables, but you can borrow members of structs, and you're guaranteed that only that member is borrowed, and can use the other members. So if we have something like the following: struct S { a: T1, b: T2, } Given a instance `t: T`, I should be able to borrow only `&amp;t.a`, and then later, without returning `&amp;t.a` I should still be able to borrow `&amp;t.b`. The rules would be: * We declare that a value can have "children" values, which are those members that compose it. Those children are each other's "siblings". * Moving children values away from the parent is done exclusively destructing. * A value can be locked, this means that a borrow prevents some uses. A value is locked as long as the borrow's lifetime remains. A read only borrow does a read-only lock, which allows further read only borrow, but prevents moving or doing mutable borrow. A mutable borrow does a mutable lock, which allows a read-only borrow from the value (read-locking the `&amp;mut`) but prevents arbitrary borrowing, or moving. * When you borrow a value, it locks all its children as well. Because you can access any of the children. * When you borrow a member it locks the parent value, but not the siblings. That is `&amp;mut a.m1` does a mutable lock on both `a` and `a.m1` *but it doesn't lock* `a.m2`. * You can't move `a.m2` because this requires destructuring `a` which is locked and not allowed. So this should keep consistency rules. This means you can do mutable borrows on a value, as long as it's a disjoint set of children. Initially we would do it for members only, but I feel that we might want to allow a similar way to do this with slicing. I can do a `&amp;'a mut x.m1` and a `&amp;'b mut x.m2` which would keep `x` acting as if it were mutably borrowed as long as either of the borrows remains. The problem, of course, is that we need a way to express membership. The easiest way to express it in a way that makes sense. Especially challenging when we get to slices. My current version is to expose a "member" type definition for borrows into something that looks like `&amp;'a T.x` means that we are doing a borrow of the `.x` member of a `T` variable with lifetime of at least `'a`. Then the problem gets harder with slices, I guess it would look like `&amp;'a [T; 1..2]` where the range has to be a series of constants. We should be able to elide `&amp;T.x` into `&amp;U` where `x: U`, and `&amp;[T; S..E]` into `&amp;[T]`, but ultimately the type has higher information for the borrow. I don't quite like it though, because it feels like it really blurs the line in lifetime information vs other type information, some which has different effects in different places.
Can you clarify what you mean by "these"? Async blocks produce futures which can be spawned onto executors, but I'm not sure if that's what you're asking.
You could take a look at [Inko's VM](https://gitlab.com/yorickpeterse/inko/tree/master/vm). It being a VM means there may be some hairy parts, but overall it should be pretty decent.
Heck yeah it is. I'm just glad we haven't yet gotten to the point where Chinese is the dominant technical language so I don't need to know it yet.
/u/pmeunier, I'm not going to go on about this any further and assume you will have resolved it for 0.11. I mean, it's fine if Pijul is IP encumbered and there can only be one implementation and maybe only one host, unless you want to work out a license. It's just important that the IP/patent situation is documented clearly. Clearly Pijul is innovative work and may be protected. Thanks for participating in the discussion here and releasing Pijul. Hoping to use Pijul in the near future. 
So did they specifically only disallow matching with manually implemented Eq only for types containing floats? Why didn't they allow it to enable someone to get it right it and make a crate for it (like noisy float), like with so many other things? And why single out floats, anyone can also manually impl Eq wrongly for a type that doesn't contain floats, which will also lead to incorrect result.. 
Thanks, that is great news!
Well, [I don't mind](https://youtu.be/NoweGN8cm5g#t=19) him, personally.
Well, I'm pretty sure the thinking is along those lines: `match` does exact bitwise comparisons, which is also what the derived impls do, so the only way to guarantee the two are consistent is to require the user to derive the equality traits. What annoys me is that "exact bitwise comparison" is exactly what I'm doing, but there's no way to tell the compiler that. I'm also not a fan in that it represents [a kind of magic](https://youtu.be/0p_1QSUsbsM#t=11), and Rust is the sort of language that should have as little magic as possible.
As matthieum pointed out, it's because `match` doesn't actually use `PartialEq`, and if the two can match, *bad things* can happen. It's a case of Rust not trusting the programmer (which I wholeheartedly agree with), but not providing a way to promise you got it right (which annoys me).
The crate of the week doesn't exist on crates.io.
see `data-encoding` crate
Of course, fixed as soon as I wrote this :D
You say "no filters". Is this a case of "we don't want to support filters because they are smelly and dumb", a case of "the way the code is structured makes it infeasible", or a case of "I haven't gotten around to it yet, sheesh, keep your pants on!"? Also, do you have any position on supersampled rendering? Because I would *love* to have an alternative renderer I could throw my SVG wallpapers at and not have to worry about those bloody antialiasing seams.
It's probably related to the maintenance window I saw on [Twitter](https://twitter.com/cratesiostatus/status/988855670202974208?s=21).
What are you seeing? The page looks right to me.
I'm building a server based chip 8 emulator using dynamic recompilation. Eventually the code for this will serve as a boilerplate for a web based N64 emulator that supports real time online multiplayer play. I'm getting tripped up on implementing a server that supports both http and websockets on the same port. If somebody knows more about this and wants to help you can find more [here](https://www.reddit.com/r/rust/comments/8e96nt/hey_rustaceans_got_an_easy_question_ask_here/dxw8g0o/)
No.
Out of interest, is there a canonical, up-to-date "here is where we are aiming for async" document? I want to keep one eye on the space, but I have to admit I've just lost track of what the plan is, now, particularly in taking the whole ecosystem into account. I mean, this post talks about migrating from futures, but I thought futures was being updated and was going to stay around?
There's not such a document just yet, but as soon as the basic plans are settled (which should happen soon) I will write a blog post with precisely this goal.
Cool; thanks for the update.
&gt; Those who have written much futures-based code in Rust will be able to tell you just how big a deal this is. The only futures I've written are under the umbrella of existing async web frameworks so I'm not an expert on the subject by any means. But with the examples alone in this blog article, it's going to simplify a lot of the *trickery* I've had to employ to get stuff to compile. 
What does "it doesn't render anything by itself, like pathfinder" mean?
crates.io was [experiencing an issue](http://status.crates.io/incidents/ycxkqdc0ssly) an hour or so ago.
Oh hey it's up now. It was a 404 when I looked before.
The value returned by an async function is lazy-- the body of the function won't be run until it is poll'd to completion. Lifetime capture refers to the fact that, because of this laziness, the lifetime of the future is bound to the lifetimes of all the arguments to the `async fn`.
"Trait fields" are proposed feature but it was postponed to some unknown point in the future. The best you can do is put accessor methods on the trait which will ensure that all implementors have the fields. 
I want to have users of a library implement a trait BUT I want the library to be shared between multiple Rust programs. Since Rust does not have a stable ABI, I'd need to go the C route - however I don't know how to expose a trait via a C API? I can use a `Box&lt;T&gt;` - but then, how do I reconstruct that `Box&lt;T&gt;` from C / expose it in a way so that I can dynamically link the library? Is this possible?
This is very ergonomic, but it also seems very magical. What is the code actually doing? How can the mutable borrow happen at some unknown point in the future without invalidating what a mutable borrow is? 
I'd recommend reading through @withoutboats's [blog series](https://boats.gitlab.io/blog/) to get the full details.
You are spot on! The standard library used to have an API that allowed ”scoped threads”; threads that are spawned and joined with a lifetime other than ’static. However, the mechanism that tried to ensure that the thread actually stopped before the callee function returned (an possibly unallocated things the thread might have a reference to) was noticed to be unsound, and the API was removed. You can google for ”leakpocalypse” for more info. At the moment an alternative, sound APIs for scoped threads are provided by the crates ecosystem. Check crates crossbeam and scoped-thread.
Great, works perfectly on mobile.
Haven’t looked at the code yet, but here’s an attempt at explaining why join doesn’t change the lifetime. If you wanted the lifetime of a thread to be associated with how long that thread lives, you’d need to make sure that any dropped thread either joins or cancels. Now, firstly joining or cancelling threads has the potential to block / fail. This isn’t really something you want happening in a destructor. Secondly, you want threads to be able to outlive main (and potentially outlive the entire thread that spawned them), which means you want the actual thread to outlive the Thread handle struct that it’s associated with. This means you couldn’t drop in the thread destructor even if you didn’t care about the blocking / error conditions. Similar to the way that shortening the lifetime of the thread handle struct (by dropping it) can’t affect the lifetime of the actual thread, shortening the lifetime of the actual thread (by joining it) can’t affect the lifetime of the handle struct, which means there’s no way you could tie the lifetime of the inputs of the thread to when it gets joined. Also different tact what happens if someone cancels your main thread before it joins the worker thread? 
Futures with *only* `'static` borrows should already work without the need for explicit `async`/`await`, I thought?
&gt; options = Default::default() Looks like you are calling the method default on the Default trait. How does this work? Does it have anything to do with the type of `options` is known to be `Options`? I was expecting a call to `Options:: default()` instead.
Prime number sieves can be fun. You can try doing SIMD perlin/simplex noise implementations 
&gt; Does it have anything to do with the type of options is known to be `Options`? It's that exactly. In fact, you can use the *even shorter* form: `&lt;_&gt;::default()`, which is even *less* specific in that you don't mention the trait the method comes from *or* the type it's implemented on. Just that there exists an appropriate type for which there will be a `default` method.
This is awesome! i'm exited about the way things are progressing in rust. Haven't done async programing in rust yet. I wonder if there is a way to cancel futures? is it planned to be supported eventually? After reading [this excellent post by njs](https://vorpus.org/blog/timeouts-and-cancellation-for-humans/), i would really like to see some support for this in rust. I think it is important to address this before stabilizing futures, since it might affect their API (every await!(future) should be able to return some kind of `ErrorAborted`, besides the normal errors the future could return).
Ya I decided to squash the listener backlog into one queue to simplify (no need for queue capacity checks during SYN_RECV -&gt; ESTABLISHED transitions). Seems [BSD does something similar](http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html) to this single queue approach.
I'd be interested in this too. I've been working on porting a C project which handles threads with only 3 atomic calls for a field(state.shm.flags) but otherwise treats it as a regular u8(but in Rust I need to use the atomic methods along with ordering). The original C project has a shared State struct with each thread referencing `state.running` as a while condition loop, as soon as a thread causes that to become false, then all threads would exit and the main thread should be able to resume? I added joins as well thinking that would clarify the lifetime issue with my referenced field(state.shm: &amp;KVMFRHeader). In my case that reference is a memory map to shared memory file that another process is altering. It's contents update all of that referenced structs fields(and nested structs), the Rust program only reads the updates to the memory mapping, with the only actual write happening with the atomic flags field(bitflag). I've been having a confusing time trying to port it(first time dealing with threads). Have wrapped the main State struct into an Arc as advised, and used Mutex when the struct is modified(I moved the related fields in the State struct into their own sub structs to group them under one Mutex as they're often only touched by single threads). Only thing preventing me from getting this working now is that lifetime issue with the referenced struct field.. Playground is here: https://play.rust-lang.org/?gist=98aef3b868e4ef9caa79fa34c88285b6&amp;version=nightly
So I'm building Rust as part of a Firefox install on a Gentoo box(x86_64). How come Rust generates backends for all supported platforms? Is there a way to avoid this, it takes a lot of time...
Did you report this as a bug on rust-lang/rust? If not, can you please do so?
Yes I have: https://razrfalcon.github.io/resvg-test-suite/svg-support-table.html I think it's as detailed as possible.
Filters will be implemented in a next release. It's a 0.2 after all. But some features like embedded fonts and animations are not planed at all. The core idea of the `resvg` is a multiple backend support. It you know about a 2D rendering library that has a good antialiasing - I can implement a backend with it. I can't do anything else on my side.
I've newer used it, so I don't know. But I can give it a try.
When I've posted a 0.1 release a lot of people asked about an actual rendering capabilities, but since I'm not rendering anything by myself and simply using an existing 2D libraries - it's not up to me. For example, QtSvg uses Qt itself that has a 2D rendering library (QPainter). I'm not doing the same.
You are right. Will update the readme.
There is no generic way to cancel a future - in fact, it seems Futures will change from being &lt;T, E&gt; to just T, so there will be futures that cannot return errors. About cancellation: what i always heard was to „simply stop polling“; if the future drops, it will clean itself up. However, I’m not sure how to „stop polling“ in all situations. 
It's the default renderer for matplotlib and mapnik (OpenStreetMap's renderer). 
Good to hear about filters. I realise it's early days, I was just wondering if they were going to come at all, since the "TLDR" is quite terse on the subject. The problem with antialiasing is that almost every 2D drawing library does it "wrong" and will produce seams. The only one I'm aware of that can get it "right" is AGG, though I can't corroborate that personally. The simplest way around that the whole problem is to deliberately render the image at a much higher resolution without antialiasing, then scale down. That's something that seems like it could be done above the backend level. (By "wrong", I mean converting coverage to alpha.)
You're not wrong, Walter, you're just an asshole.
I’m less scared after reading this. I just can’t decide if it’s black magic or the good kind :)
&gt; But when I had to downscale it - it will introduce the same errors. No, because the errors are introduced by the anti-aliasing. If you don't anti-alias, the errors don't exist. The problem is that just about every 2D library does anti-aliasing by converting pixel coverage into alpha. This is absolutely correct *provided* the fractional coverage pixels are only ever blended on top of pixels with 100% coverage. If not, it ends up introducing seams. Consider what happens when you have two perfectly black shapes on top of a white shape. Each black shape covers exactly half of the pixel. 50% coverage =&gt; 50% alpha. But white + 50% black gives middle grey, middle grey + 50% black gives dark grey, not black. Rendering at a higher resolution and then scaling down avoids the problem by never allowing coverage to influence alpha, whilst still generating multiples samples per output pixel. For example: [this image](https://svgshare.com/i/6Qz.svg) should appear as a solid, black rectangle. [Here's how it looks in various programs](https://imgur.com/a/iCw8XrW). Note that imgur messes with them a little; you should view them directly to see them accurately.
Ooph, you scared me there for a second. Glad it was just a hiccup; nothing major haha.
It looks like a bot, triggered by the phrase "Or am I wrong?" that is quoting [this scene from the movie The Big Lebowski](https://www.youtube.com/watch?v=uQl5aYhkF3E).
Thank you, Quxxy, for voting on BigLebowskiBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
This is the pre-Rust version of librsvg, and quite old already. Can you re-run with 2.42.3, and maybe even include both results?
Is it possible to use `async` in traits? trait Foo { async fn bar(..) -&gt; Bar; }
It's a particularly stupid bot by the looks of things
I understand it. But what scaling algorithm should be used? Nearest neighbor? Because any other will introduce artifacts too.
Sure, but not all. For example, `FloatCore` does not implement `sqrt` even though it could. However, if it did, it wouldn't be as good as the `std` one by far, because the `std` one just tells LLVM that it performs a `sqrt`, and LLVM understands what that means, and with things like fast math can do optimizations like `sqrt(x) * sqrt(x) =&gt; x` which the Rust implementations cannot. 
I don't have a personal experience, but https://www.datafusion.rs/ has dataframes with csv support.
Bad bot.
Apparently this is a bot that triggers on the question "am I wrong" and responds with a quote from the movie "The Big Lebowsky". The number of useless bots that invade all kinds of subreddits where they don't belong is unfortunately growing. I think this one should just be insta-banned from here.
I don't know much about the pros and cons of scaling methods, but from looking at the higher-resolution image as "many samples per pixel", I would assume just averaging all samples that cover each output pixel would get you the closest to "regular anti-aliasing but without seams". Actually, it's not something I've thought a lot about. I might poke at it a bit.
Have you seen the talk [Building a Ruby profiler](https://www.youtube.com/watch?tv=o6wWSPxYueU) by Julia Evans? Might be a good starting point if you're interested in the topic.
It's not in the gentoo repo yet, so it's very hard to test (it requires the latest cairo, which isn't in the gentoo repo too). But I've done those tests already and the differences are minimal. librsvg became a bit better, but not match. 33 tests was fixed, 18 became broken... As soon as I be able to build the latest version I will update the tests.
Thanks so much!
I wish there was a way to force the created functions (`hello_fn`) to be `unsafe`, or at least - force you to be explicit when you want them to be safe. impl ExecutableBuffer { pub fn to_fn&lt;F&gt;(&amp;self) -&gt; F where F: std::mark::Unsafe // new trait? { // ... } } let hello_fn: unsafe extern "win64" fn() -&gt; bool = buf.to_fn(); 
Did you talk to the person that wanted to rewrite librsvg in Rust? That would avoid duplicating efforts if it already fits their usecase.
Yes I did. At the moment our goals are very different. librsvg is a GNOME library, essentially. And I'm creating a crossplatform one with a multiple backend support. No one stops librsvg devs from using `usvg` or `resvg` directly.
Yes! This is one of the first things I do when building Rust on a fresh clone. In the repo root, copy/rename `config.toml.example` to `config.toml` and find [this line](https://github.com/rust-lang/rust/blob/master/config.toml.example#L58)(58 at the time of writing): #targets = "X86;ARM;AArch64;Mips;PowerPC;SystemZ;JSBackend;MSP430;Sparc;NVPTX;Hexagon" Simply uncomment the line by removing the leading `#` and delete everything aside from `X86` in the string. Then only that backend will be built. Note though that this will cause some codegen tests to fail because they don't detect the missing targets; `x.py rest` will probably never pass cleanly with this config. This obviously also completely removes the ability to cross-compile for other architectures. However it makes a clean build significantly faster, so it's great to use in your local working copy. 
There is such a thing as ["scoped" threads](https://docs.rs/crossbeam/0.3.2/crossbeam/struct.Scope.html#method.spawn), and there's a chance those solve your problem. Or you could use an Arc instead of an Rc, which is allowed to be passed to other threads. But without knowing more about what H1 and H2 are actually doing, it's hard to guess which of these things are possible for you.
Unfortunately it's currently not possible to be generic over all possible function types, so `ExecutableBuffer::to_fn&lt;F&gt;(&amp;self) -&gt; F` is impossible to begin with. This is why the API is currently limited to just giving out raw pointers. One additional benefit would be tying the lifetime of the generated functions to the ExecutableBuffer, so it wouldn't be possible to keep the function pointers around after the Executor lock expires. This is unfortunately impossible as well as normal function pointers in rust don't have a lifetime.
The Datafusion project might be what you're looking for. https://www.datafusion.rs
Thanks!
Sorry, that may not be mature enough for what you need
&gt; No raster images as references. &gt; We are using vdiff tool to check that tests are passed. When you get a difference, how do you decide which rendering is correct? Does this test suite run automatically?
Yes. Anything that empowers "worse"/inexperienced people to produce higher quality stuff despite their lack of experience and knowledge (and possibly learn new things and get better along the way) is great! Nobody started out by being good. We were all noobs once. We've all written crappy code, whatever that means. Rust is fantastic at forcing you to write quality code even if you don't know what you are doing (and also pretty decent at teaching you along the way). It gives so many opportunities to people who would otherwise write horribly buggy and unmaintainable stuff and face a lot of frustration if they were working in C/C++.
I propose we rename Clippy - Rustlin (short of **rust lin**ter). May the bikeshedding commence.
Very cool post. Fun fact: the author thanks Graydon for proof reading :)
The [blog series](https://boats.gitlab.io/blog/) explains it. Basically, this syntax desugars into a state-machine enum of yield points, one variant per await statement, which holds the state of the future and is pinned in memory (unmovable) to not invalidate borrows.
https://github.com/jrmuizel/full-scene-rasterizer/ avoids this problem. I hope to port it to Rust some day.
Ah, so you're thinking about reasoning about disjoint-borrows across method calls: it's sometimes called "partial borrows", and there's an RFC issue for it https://github.com/nikomatsakis/fields-in-traits-rfc/issues/16. As you say, it's not been worth enough yet for anyone to really push it and work through all the little issues. Working with arrays (and especially if it was to work with non-contiguous-storage collection types like `VecDeque` and `BTreeMap`) is definitely a whole extra level of complexity, though.
No, nearest neighbour would make the whole thing pointless. It just picks one of the pixel colours (the one of the "nearest neighbour") and discards the rest. You need to take all the colours into account to effectively do antialiasing. What you want is "bilinear" filtering, i.e averaging the colours. Basically, render at 4x the resolution (double the width and double the height), so that every pixel in the final downscaled image corresponds perfectly to a square of 4 pixels. The colour of the 4 pixels is then averaged to produce the final colour.
Shouldn’t all the generated functions be unsafe anyway? You can easily write a safe wrapper if you want but there’s nothing less safe than whacking raw ASM into a buffer
Makes me wonder if it would make sense to add an `on_thread_panic` handler or somesuch to `std`. If nothing else, it would let you choose whether you want to log the failure (and how to log it), or have the process commit seppuku to avoid disgrace. I mean, we already have a general pre-panic handler. That said, given that Rust goes out of its way to propagate *observable* failures through things like poisoned locks, I'm not sure the criticism is entirely fair... but that's not really the point of the article, so oh well.
wait, how does that work? $ type rust-toolchain -bash: type: rust-toolchain: not found 
You mean /r/rustjerk
Thanks for a great answer. ATM, it won't solve my problem as gentoo doesn't allow me to fiddle with config.toml. But I will probably clone the rust repo later on, and will follow your excellent advice when that time comes.
I'm trying to pass `-Z external-macro-backtrace` to `rustc` when running `cargo test`, but i can't find the right way to do it (if at all possible). Does someone has any clue?
It really depends on your requirements for storage and query. A common pattern is to have a data store for your projections so that you can query that for eventually consistent data, and another data store for your raw event store. Some good ones are plain old postgres, time series databases, etc - anything optimized for storing a lot of rows. Netflix uses Cassandra for a lot of their ES persistence, I believe.
Cool, from the article it seemed to me to imply that currently we could not
`unsafe fn` basically means that calling that function requires you to uphold invariants that are not encoded in the type system (i.e. this *const u8 is a pointer to valid memory of the required length). As long the written asm has no such requirements it could be perfectly safe.
Yeah I noticed it too, the edit and rerun tests cycle is much faster – doesn't make me Cmd+Tab away anymore while waiting.
The problem is that the function pointer is created with `std::mem::transmute`, so the user can pick any signature they want. They can even pick some other, non-function type - as long as it's size is the same.
How about creating your own type instead of using a function pointer? That type could own the executable buffer, so there won't be any lifetime problems, and it's `execute`/`call`/whatever method can be made `unsafe`. The only problem is arity...
No. It's manual, sadly. Here is how it looks: https://imgur.com/a/SdVqX9a
Are you aware of cargo watch? https://github.com/passcod/cargo-watch Basically can compile or run tests automatically on file save. It's great.
Can thread return results?
Please edit your comment to elaborate further on why people interested in Rust ought to read this; it's quite a long article and it's a bit much to ask people to read through the whole thing only two see Rust get mentioned in passing.
arity, argument types and calling convention would all cause issues unfortunately.
I have a few questions since I'm too lazy to read and process the entire article: how does it compare to: * Rayon? * Actix? * Pony?
Not at first, but that will be a big focus after shipping the initial syntax. (This is related to `impl Trait` in traits, which we also want badly...)
You are a very good bot 
There's not really enough info here to say. Can you share the relevant code from your .emacs? Do you get an error from Emacs during startup? If you didn't restart, did you eval the new forms to load the mode? Also, if you're new to Emacs, it's much simpler to use the package system instead of trying to roll your own.
Read the article, it's good.
Sorry, I didn't know that would be relevant. The error also happens at startup. The code I added is verbatim (except the path) to the link, and the rest of the file is unchanged from the original. I wanted to use the package manager, but rust mode isn't there, and manual seemed much easier than dealing with the alternative option
Very cool. I don't know whether or not I believe it all, but it looks potentially quite handy. I whipped up a quick implementation of a nursery here: https://play.rust-lang.org/?gist=0c6d2c757aecf3672c4c1f0050baa1ae&amp;version=stable . Share and enjoy! One incompleteness is that Rust doesn't really have a way to cancel threads, IIRC because it's Very Difficult to do safely in a cross-platform way.
Read the intro and then go to [where the meat starts](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#nurseries-a-structured-replacement-for-go-statements).
Thanks for the reply. I'll definitely look into scoped threads. Do you know why I'm still getting an error in the last playground? https://play.rust-lang.org/?gist=35a0070b1b9d3861c0b53ac880798007&amp;version=stable I thought cloning lines and stuffing them into Arcs would break any dependencies on the 'ml' variable. 
Maintainer of `fantoccini` here! You're right that fantoccini is currently providing somewhat low-level bindings, but what is missing is mostly just glue code. In order to do any kind of orchestration, one needs to support web driver at the very least, and that's what I've mostly been doing with `fantoccini` thus far. Once that foundation is in place, we can add higher-level abstractions like the `Form` type that's already there. PRs welcome!
You are attempting to clone a `&amp;str`. What you want to do instead is to call `to_owned`. Or use `crossbeam`, as mentioned above: https://gist.github.com/a150bc2e353b4a98401336d25ce535d3
I would like to help but my Rust (programming skills in general) is very low level and not used since 1.0 - 1.3.
as well as tokio's runtime or any other similar routine.
This is a better question for /r/emacs
I just wrote a long-ish comment about this over in the r/programming thread; you might find it interesting: https://www.reddit.com/r/programming/comments/8es8x3/notes_on_structured_concurrency_or_go_statement/dxy07yx/
Hypercore looks awesome!
I think it's supposed to be 'containers for child threads'
You could do something like this trait FromAsm { ... } impl&lt;A, O&gt; FromAsm for unsafe fn(A) -&gt; O { ... } impl&lt;A, B, O&gt; FromAsm for unsafe fn(A, B) -&gt; O { ... } // etc.
&gt; Rust doesn't really have a way to cancel threads, IIRC because it's Very Difficult to do safely in a cross-platform way. Yeah, there's this obnoxious thing where if you want to support cancellation properly you have to be Very Careful about which low-level I/O APIs you ultimately use for everything, and then you have to make sure that everyone who wraps the OS APIs all coordinates and plugs into the *same* cancellation system. In principle there's no reason you couldn't make this all work with OS threads and conventional blocking calls (at the Rust level), but in practice it turns out to be much easier to retrofit this in if you're implementing an async library, because that forces you to go redo all your low-level IO calls anyway.
That's what I was thinking, but I'm not sure I understood the guy correctly.
How about cases where the scope is not lexical? Consider for example a GUI screen, which goes and performs concurrent network requests in response to user actions (e.g. button pressed). When the user clicks "back" all of the requests should be cancelled. Presumably, the screen should be passed a nursery so it can spawn the tasks, and the scope of the nursery should correspond to the lifetime of the screen. But how do you model the lifetime (or rather lifecycle) of a screen with a lexical block? I don't know any UI libraries/frameworks that work that way. But it's interesting to think about.
&gt; Trio is the only Python concurrency library where control-C works the way Python developers expect (details). This would be impossible without nurseries providing a reliable mechanism for propagating exceptions.
Run `cargo test -v`, copy the rustc commands, and then rerun with your extra args. 
Thanks a lot!
That sounds pretty good!
Thanks for your answer! Yeah I'm trying to make it link atm with no luck so far :(
It would leak the implementation details of `foo`. I imagine it would be very hard to get this to work correctly for unsafe code as well. If `foo.a` and `foo.b` are really unrelated perhaps they shouldn't be in the same struct.
I'm getting started with rust and I'm on the strings section of ch8 of the rust book 2nd ed. What's the deal with deref coercion? It seems pretty convenient, but are there pitfalls that show up that I should be aware of?
You have me intrigued. Can you explain?
There's a containing program code structure (a kind of code block) that looks after it all, and it is implemented in such a way that it's guaranteed that no sub-tasks (coroutines/etc) will be left running once control leaves that code block. It also seems to have coordinated cancellation and exception handling within that code block for all related child tasks.
The most important part of it, IMO: &gt; ...I find it reassuring that such close variations on this idea have been invented independently :-). The main novel part isn't the idea that lexically scoped threads are a useful tool to have in your pocket, but rather the idea that they're actually a sufficient foundation to build everything else, and that this is worth pursuing.
Indeed, unless I misread the article, this is just an executor. Python's executor supports parallel mapping, too.
How about flake? A metal flake is basically a piece of (maybe rusty) lint.
Or perhaps a struct author should consider having a method to have both. pub fn both_mut(&amp;mut self) -&gt; (&amp;mut u32, &amp;mut u32) { (&amp;mut self.a, &amp;mut self.b) }
Traits already can't have const fns, impl Traits, and they will not have async fns. Rumors say they will be deprecated eventually.
&gt; Rumors say they will be deprecated eventually. what will?
I still worry about this - correct me if im wrong: the default Future in std will be generic (returning T which might not even be Result&lt;,Error&gt; type). anyone could write their own CancelableFuture which would return Result&lt;T, AbortError&gt; or something like that. But if by default most of the ecosystem is using the generic Future from std, wouldn't there be a composability/usability problem for someone who wants ability to cancel his futures?
I think they just made a snarky joke ;)
I doubt that works.
Take a look at how spacemacs [does it](https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Blang/rust), maybe it'll help.
thread interrupts in streams in java were a pain...
This doesn't work if there isn't a hierarchical decomposition, eg. there are three fields, `a`, `b`, `c`, and one method uses `a` and `b` and the other uses `b` and `c`. In that case you have no choice but to take your struct apart into references to individual fields and pass them one by one whenever you want to call these functions.
Isn't this what RefCell does?
In the subtyping section of the rustonomicon, the overwrite example demonstrates that `&amp;mut T` is invariant over `T` with an example that doesnt compile specifically because of that: fn overwrite&lt;T: Copy&gt;(input: &amp;mut T, new: &amp;mut T) { *input = *new; } My question is, wouldn’t the following be a little bit mor clear about the subtyping, by being more specific? fn overwrite&lt;‘a&gt;(input: &amp;mut &amp;’a str, new: &amp;’a str) { *input = *new; } I think this more clearly illustrates that the compiler won’t reduce the lifetime of the `input` parameter value, and that it’s because `new` has to have exactly the same or greater lifetime in order to replace it. In fact, maybe even this would be more clear? fn overwrite&lt;‘a, ‘b: ‘a&gt;(input: &amp;mut &amp;’a str, new: &amp;’b str) { *input = *new; } I guess the example is really trying to illustrate the invalid memory usage that would happen if invariance wasn’t present, but it’s also the first example of what subtyping is right, so maybe it helps to give readers an idea of what all the variance words really mean in terms of explicit lifetimes? Idk, I’ve just been thinking about that section 
Aha! So the idea is rather that we forbid every other type of parallel handling (such as spawning background threads) and see what benefits that would give us. It would be interesting, although a few years too late, to see how we would have dealt with the leakpocalypse if we had chosen this version of thread handling. Or I could ask the other way around: Could we break Trio by putting a nursery into a reference cycle (or something similar that makes sense for Python)?
&gt; It is just not true that you need libm/libc for everything. Yeah, I should have mentioned that. Sorry about it.
A potential pitfall is if the two structs (both the "dereffer" and the "derefee") end up using the same method name. If so it's easy to confuse which method is actually being called. Especially if the "dereffer", the "derefee" and the code that uses the "dereffer" are being written by three different people, and they add more methods over time... Hence, if you are a "dereffer" - especially if you deref to anything, like `Rc&lt;T&gt;` - you should avoid or at least be very cautious to add new methods as you might break other people's code.
I'm dubious of the emphasis on the elegance of Python's `with ... as ...:` construct. Coming from languages like Ruby and JS (especially Ruby), context managers have felt like a weak patch for Python not supporting multi-line lambdas. Much or most of what I'd want to do with a Python context manager I'd do in Ruby with a `yield` + `ensure` method. The concurrency portion feels like that plus `Thread.join` with error checking/re-raising (although I might be missing something) in the `ensure` code.
You could easily solve this problem with `RefCell&lt;T&gt;`s, but I think the point is that you shouldn't have to.
In a way, yes, though it adds a runtime check and means trading compiler errors for runtime panics. I interpreted the author's question as desiring a way to use the type system to specify logically-distinct fields at compile-time, which isn't possible using plain method calls on a parent struct because the typechecker intentionally only looks at function signatures, and so can't tell from the function body that disjoint fields are borrowed. But if one wanted to use RefCells here, it would look like this: use std::cell::{RefCell, RefMut}; struct Foo { a: RefCell&lt;u32&gt;, b: RefCell&lt;u32&gt;, } impl Foo { pub fn new(a: u32, b: u32) -&gt; Foo { Foo { a: RefCell::new(a), b: RefCell::new(b) } } pub fn a_mut(&amp;self) -&gt; RefMut&lt;u32&gt; { self.a.borrow_mut() } pub fn b_mut(&amp;self) -&gt; RefMut&lt;u32&gt; { self.b.borrow_mut() } } fn main() { let mut f = Foo::new(1, 2); let x = f.a_mut(); let y = f.b_mut(); }
The cancellation thing is interesting, especially in languages like Rust without exceptions. It's very similar to unix signals, which Rust also doesn't have a great way to handle. Adding a Cancelled error to every IO operation seems like a kludge to me (interested in your thoughts), but I'm not sure there's anything better in Rust as it is today. If a language were to be designed around nurseries, what in your mind would be the ideal way to handle cancelled tasks? Exceptions? Great post/library by the way, and thanks for putting it out there. Developers love to shit on things they don't understand or are different and it can feel stifling at times.
The problem this creates is that I can't really share binary Rust DLLs between Rust programs if they use generics. For creating reusable libraries, this is a major problem, for example if a company wanted to use Rust to distribute a binary DLL, for example. Also I couldn't put the DLLs in a package, for installing it via apt or similar. Meaning if I create 50 programs that all share the same crates, I can't reuse that, I have to distribute 50x the same code. I hope Rust eventually gets an ABI that is stable across at least a few compiler versions. I mean, they could at least say "ABI version 0.1.0 is compatible from 1.25 to 1.27", for example.
Premature optimization. Your database isn’t your application. 
The example's fine { let a = &amp;mut f.a; let b = &amp;f.b; for x in use_ab(a,b) { let c = &amp;mut f.c; use_bc(b,c); } } You can't make `use_{ab,bc}` methods on `f` since `use_ab` would hold onto the mutable reference to `f` until the loop was over and then you can't make another to pass into `use_bc` in the loop body. The problem with taking individual references is that half the point of creating an aggregate is that you don't have to manually handle all the fields all the time. Note that there's no way to functionally abstract over taking the references since the compiler can't "see through" the function and know which fields your taking references so you have the manually inline taking the references into every caller. You'd have to use a macro as your show which besides being extremely obscure would result in 3^(number of fields) (every field be omitted, borrowed mutable, or borrowed immutably) macros per struct to cover every possibility. What is just `f.foo()` in another language has turned into { // You very often need a block so that the references don't live too long, // eg. if you move f after the call. let ab = (&amp;mut a, &amp;mut b); foo(ab); } in Rust. Now imagine `foo` changes and must take some new field `x`! Time to rewrite all the callers! This is not code I want to write.
Just letting you know that there is a wishlist issue for this: https://github.com/rust-lang/rfcs/issues/1215
If I click run without clicking build first, it should build it.
&gt; would result in 3^number ^of ^fields macros per struct The non-macro alternatives in that example would include making the same number of functions or methods. &gt; What is just f.foo() in another language Because other languages either use GC to manage aliased pointers. If one is willing to suffer runtime checks, then they can use Rc/RefCell.
Here, fixed it with crossbeam: https://play.rust-lang.org/?gist=1f48782817c20c9b879bc702e07e3d01&amp;version=nightly&amp;mode=debug. Notice that we were able to get rid of the Arc, too. IMO crossbeam should probably be the default choice for spawning threads, it has a lot of advantages.
It's `assert_eq!(actual, expected)`; you can see this in tests throughout the stdlib, [like this one](https://github.com/rust-lang/rust/blob/master/src/libstd/io/buffered.rs#L1244-L1250).
I'll c+p what I wrote about this before: If he had instead the title: "Notes on structured concurrency, or: Go statement considered harmful [or: introducing Trio: concurrency for humans]" then I think my head might have exploded with the overload of programming title memes. That said, I enjoyed the article. I am, however, left unconvinced. My primary problem with it occurs when he compares the `goto` and `go` control flow diagrams, and says 'Notice any similarities?'. Well, yes, I can see what you're getting at, but I can notice one huge difference as well - the calling code stays sequential. Really, the whole argument is against side-effects, not against the obfuscation of the control flow. The arguments presented against `go` here are no different from those presented against threading, or external file modification, or whatever. The only way to guarantee no side-effects is to use a functional language like Haskell. To say that the language breaks the black-box principle because functions may spawn a goroutine that they don't clean up is no different to saying that a language violates the black-box principle because functions may create threads, or modify files, or anything else that is persisted beyond the life of the function. So I don't really buy that `go` is as dangerous as `goto` in the same way as I don't think that any other side-effect is as dangerous as `goto`. I do think that the Trio `nursery` solution is a nice way to ensure that your code is correct, it reminds me a lot of how Rust does lifetime scoping. It's not there to make coding easier, but it does make coding *correctly* easier. However, only Rust has that sort of lifetime scoping, other languages get by ok without it - it's not a universally perfect solution, and I think the same can be said about `nursery`.
This seems better suited [as an issue on the nomicon repo](https://github.com/rust-lang-nursery/nomicon/issues/new).
The common convention with methods on a smart-pointer is to make them all associated functions (i.e. static methods) and invoke them as such, e.g. `Rc::try_unwrap(my_rc)`.
There's this one that I ran into: https://github.com/rust-lang/rust/issues/39801 use std::sync::Arc; trait Foo {} struct Bar; impl Foo for Bar {} fn takes_foo(foo: &amp;Foo) {} fn main() { let foo: Arc&lt;Foo&gt; = Arc::new(Bar); takes_foo(&amp;foo); } Seems like it should work, right? Nah, it tries to coerce the `Arc` to a trait object but can't because it doesn't implement `Foo`.
It’s backward-compatible with BinaryHeap in std. Almost all tests copied from std passed just fine. The current rust’s BinaryHeap is max-heap only. In c++ and D language, you can get the values with arbitrary order defined by custom comparator. My crate attempts to fill the gap. My plan is - publish as crate - use the crate from my wavelet-matrix crate which uses binary heap in various way. - ultimately, write RFC and improve std Anyone interested?
This is called splitting borrows and works very well.
Yeah I know it, but good tip :). These tools benefit a lot from all the incremental build improvements lately!
For those who want more elaboration, click "Hello World Rust Project" in the popup and it will also generate a readme with further information.
The article suggests passing a nursery *into* a function, but I don't think returning a nursery would be valid. It kind of goes against the paradigm.
That is an annoying amount of overhead if you just want a min-heap, or to compare on a field rather than the whole value. However, it looks like this library doesn't quite address those use-cases: it helps with min-heap, but using [`std::cmp::Reverse`](https://doc.rust-lang.org/std/cmp/struct.Reverse.html) works for that too, and you still have to define a custom type and implement a trait for the field case. Additionally, the wrapper-type approach doesn't work very well at all if you want to have a closure as the comparator (or, in general, a struct that stores data). Unfortunately, since this `BinaryHeapPlus` stores a `PhantomData&lt;C&gt;` instead of `C` itself, it also doesn't quite address this case either, at the moment. Fortunately, I think this can be solved without too much refactoring: replace the `phantom: PhantomData&lt;C&gt;` with `cmp: C` then adding a `&amp;mut self` argument to `BuildComparator::compare` and updating everywhere to call `cmp.compare(...)` rather than `C::compare(...)` (plus adding a constructor that takes a `C` to store). The `BuildComparator` trait could then possibly be implemented for `F: FnMut(&amp;T, &amp;T) -&gt; Ordering` to allow using a closure literal rather than needing to define a whole type.
&gt; Yeah, I try to instead talk about disjoint borrows mostly because I want to express that even though &amp;X and &amp;Y both implicitly borrow parts of Z (which means its borrowed and can't be used) we are guaranteed that the parts are completely separate and can be managed separately without affecting the other. I don't see how that's different to the issue I linked. It sounds like it's just a different way to phrase what a partial borrow is? You're using different syntax, but it doesn't seem fundamentally semantically different, e.g. your `borrow_sub_slice` in the style of the first proposal could look like: fn borrow_sub_slice&lt;'a, const start, const end&gt;(&amp;'a self) -&gt; &amp;'a [T] where 'a: &amp;self.slice[start..end] {...} I think (if you feel comfortable doing so) that issue is a great place to write up your thoughts, so it doesn't get lost. &gt; Still I wonder if I could break this with threading... No, fortunately, I don't think threading adds any new problems that wouldn't also exist *without* threading for this sort of analysis. Borrow checking is (and should remain) a single-function analysis, meaning all information you need to borrow check a function body comes from type signatures, and you don't need to look at any other function bodies. This includes with threading, because going to another thread always means calling a new function in some form (e.g. `thread::spawn`) and the various rules still apply at that boundary.
I find this slightly amusing since I had to write a new heap data structure a few days ago myself because `BinaryHeap` didn't cut it. (That said, mine is probably about as niche as you can get, so I doubt I'll publish it.)
Oh it is very much the issue you posted. I mostly said that I prefer the term disjoint borrows than partial borrows, as partial borrows don't quite explain the core promise they make (that the parts they use of what they've borrowed are separate), and thinking of it as a "part" might not make sense, because it could be grabbing two sets of borrowed things and turning them into two disjoint subsets (as in the example of the iterator, what it gives you is not part of the iterator). Mostly what I mean with the threads and so forth is that I haven't sat down and validated the semantics of it and what it'd have to be. I have done back of the hand validations for ideal and simple cases, but not when we have threads or other weird complex scenarios. My intuition is that it should apply as you say. The problem with most, but not all, the proposals in those threads is that they expose too many of the internals. I've though about a way of making disjoint lifetimes generic (similar to the composed lifetimes in the thread, but you don't need to explain how many pieces it is) but I haven't actually sat down and written code for most useful cases to see if doesn't break. That literally came up when I was writing the response, I am considering adding it to the thread if it works well.
Thanks for the detailed suggestion. I was wondering how to support closure case. I’ll take a look more later!
Almost done with my dead simple CLI tool [shack](https://github.com/saresend/shack), that's basically a key value store for things like IP addresses, or hacking wargame keys, or anything else thats dumb and simple but useful to have! 
`std::panic::set_hook` is exactly this I think?
Thanks for comment! It’s nice to hear heap is required in many cases.
It should be possible soon with the `!` type.
That's called on panic, but before unwinding begins; *i.e.* it's called before you know whether or not it's going to be caught and handled. The complaint was about panics that go unhandled.
nice! wish it supported passing in args, and stdin/out
Without the Arc, it's like a regular reference? when shared with multiple threads I'd want to still use atomics or mutexes on fields I want to update right? 
Does crossbeam use green threads or system threads? I ran an strace on a binary using crossbeam and didn't see any clone() system calls. FWIW, the program I posted was just a quick example. The actual one I'm working on I finally was able to get std::threads working after arc()-ing and to_owning() various objects, and it's currently running slowing than a straight single-threaded program :( I'd be glad to throw it up on github or something if anyone's interested in looking at it. 
There is no many to many queue in the std library, only a many to one (std::sync::mpsc). For mpmc, I think this might be a good candidate: https://crates.io/crates/crossbeam-channel 
Awesome I will take a look into it. Thanks!
Ah, that seems to do exactly what I want, which is almost disappointing because it means implementing it is only for myself.
&gt; Hmm, but it seems to me that a rayon::scope is the same thing as (what the author calls) a nursery. Right? I think that promises/futures/whatever you call them fit the bill just as well. Or more generally, any construct that *binds the result* of a concurrent computation in a scope with code that *consumes* that result.
And AFAICT you can easily do quite bad things with this if you pass the executor into a function which *also* uses it. `__enter__` and `__exit__` on executors are [https://github.com/python/cpython/blob/3.6/Lib/concurrent/futures/_base.py#L607-L612](defined thus): def __enter__(self): return self def __exit__(self, exc_type, exc_val, exc_tb): self.shutdown(wait=True) return False So you can easily do this: def foo(): with ThreadPoolExecutor(10) as e: e.submit(bar, e) e.submit(baz, e) # hm def bar(executor): with executor as e: pass # do something def baz(): pass What happens if we exit from the `with` block in `bar` before hitting line `hm`? (The answer is you get a `RuntimeError`.) I assume something similar is the case with "nurseries"; if you use one you've been given in a `with`-block, it will break its other users. The whole article was rather frustrating, not only because this is an idiom which has been invented many many times, but also because, as noted, this is an idiom available *in the python standard library*. And of course the executors also do the right thing w/r/t unhandled errors (they're re-raised when you try to extract the value from the returned `Future`). And also because it seems straight inconsistent: the author asserts both that nurseries have equivalent expressive power to `go` statements, but *also* that because `go` statements et rel. have been removed, new features are enabled. These surely can't both be true! This bit reminded me of Oleg Kiselyov's argument that one can do without undelimited continuations and "make do" with delimited continuations, because even a theoretically "undelimited" continuation is in fact delimited either by a REPL prompt or by the initial entry to the program, hence emulable by a delimited continuation whose prompt is set for the widest possible scope. One could view `go` statements, in fact, as simply being `start_soon` invocations on a single ambient nursery, created at program startup and implicitly available. The niceties about ctrl-c and whatnot that are purported benefits of nurseries, and presumably actual benefits of Trio, don't seem to have been enabled by this new concurrency primitive, but by careful programming around a concurrency *framework* enabled by the assumption that it and only it is the one in use. (Is it really impossible to get this kind of behavior from other styles of concurrency, with enough dedication? The post on signal handling definitely makes it seem as if a *lot* of effort went into it.) The library certainly seems cool, but this post in particular struck me as rather overblown.
It is nice to read that folk are using my Vim theme in the real world. I am not a Rust user myself, so the Rust support in vim-moonfly was me just throwing paint at a wall Jackson Pollock style :) Let me know if you need tweaks.
&gt; people are pandering to people with lesser skill-level, allowing "worse" engineers to do better As if "Worse is Better" weren't a thing in IT anyway, for what, several decades now? Of course that's totally misleading as a description of Rust. It's not simply about allowing "worse" engineers to do better; it's just as much, and even moreso, about *preventing "worse" engineers from doing worse*! The distinction is subtle but very important in this context.
What I'm saying is that there is a reason we don't call the technology powering Bitcoin Git, but blockchain. Because, while very similar, as you correctly stated, ther *is a difference*. The difference is that blockchain can achieve consensus in open network, where anyone can join or leave at any time and without possibility of Sybil attacks.
Yeah, that's reasonable. Unfortunately, most ICOs are designed for one thing: to enrich the authors without providing any benefit, taking advantage of current hype and misunderstandings of people.
TBH, I'm still very skeptical, but I will look at it. I'd like to say that I saw many "experts" saying things that are flawed or outright incorrect. Many of them had conflict of interest (were promoting the thing they created, so they weren't independent). There are projects out there that look cool at first sight but have significant problems, when one looks at them closely. This is why I'm *very* careful about these things. I try to understand myself (which I can) and check with people like Peter Todd, Gregory Maxwell, Pieter Wuile and others to see if they bring up some important fact that I didn't consider.
This already looks amazingly ready for RFC and the gems of wisdom that come from that process. :-)
&gt; What makes you think that float was singled out? Your "no" answer :) &gt; Matching is (for now) disabled for any type for which Eq is not derived automatically, because there is a risk that the manual implementation would be incorrect. That's what I meant by this: &gt; But isn't this not because "the language designers don't want you to match on non-nannanble float wrappers" but rather because when Eq is not derived, matching would incur a function call which would not make it a match against a constant but more like matching match x { _ if ZERO == x =&gt;..} which should be done explicitly? By this I meant "isn't it the case that float is NOT singled out, because any non-derived Eq impl requires an explicit function call in match?" So I interpreted your "no" as saying that is IS singled out, because you said "it's not allowed because the Eq impl could be wrong". But do you mean that it's disallowed for *all* custom Eq impls because all of their custom Eq impl could be wrong? (So your "no" meant "not singled out" in that way?) Is anyone working towards allowing custom Eq impls in match?
I really hate that Eq, Ord, and friends are properties of types instead of properties of relations.
I highly recommend Spacemacs. I've recently migrated from emacs and was very surprised that the first time I opened a Rust file it asked whether I want the rust layer installed. I responded 'yes' and, after it installed the layer, it just worked. It did the same for TypeScript and JavaScript as well. 
wee_alloc 0.3.0 has been released too, which is great! The mmap_alloc crate has been dropped. See the CHANGELOG here, https://github.com/rustwasm/wee_alloc/blob/master/CHANGELOG.md. I mentioned it because it solved issues I got in my project.
In itself that's true, but if it's intended to be created with a with block then it the nursery can't even escape the with block, let alone the function.
Seems like it would be easy to have a reference counter, increase it on enter, decrease it on exit and only shutdown when the reference counter is 0.
The Rust layer only uses `racer` for now IIRC. The [Rust Language Server](https://github.com/rust-lang-nursery/rls) is more powerful (although not perfectly stable yet), and can easily be added with [lsp-rust](https://github.com/emacs-lsp/lsp-rust).
I’ll polish it and hopefully want to go through the RFC process.
I’ve actually done exactly what you are saying. It was very redundant because I need to impl Ord, PartialOrd, PartialEq and Eq in the right way. Ideally, only one function is needed.
Standing in for op: it makes in my opinion a quite compelling argument why the lifetime of threads should be treated as a scoping or resource event (i.e. embedded and enforced by the language) using an analogue to goto which I found weird at first but I can now see. I was pretty skeptical coming in because I saw this on hackernews where someone derided it as having missed CSP ( "SER foo bar PAR baz1 baz2 baz3 SER foldbaz" Code), but imo it's a bit more. It makes the case of "fearless composition" of functions as the main thing which makes modern programs manageable, and that thread handles or loose threads are a really dangerous firehatches which can break function scopes. I'm actually convinced now
Yeah, if you want to update shared fields you still need synchronization. But you don't need Arc because the lifetimes are already taken care of thanks to scoping.
Rust has the advantage that it has Send/Sync and lifetimes, which makes it possible to build your own task abstraction while the language still maintains the necessary invariants. So basically, I think Rust should treat threads like an implementation detail and implement a higher level abstraction that is more ergonomic to manage. That's already pretty much how Tokio and Rayon work, and it's no accident. But yeah, we should have better cancellation support.
Be careful with benches. Your `get` fn is not returning a value. I am not 100% sure but there is a high chance that the bench is flawed (some optimizations are done ....). Either make it return a value or use a `black_box` first.
The plugin requires nightly rust unfortunately. The run-time does not.
Thanks for the suggestion. I've updated the code which return `t` in the `get` fn. The result of the benchmark does not changed.
rust has to check if your indices are in the vector for each single time you do an []. you can alleviate that by forcefeeding rust the info about the array length by putting an assert in front of the loop. if that looks ugly you can also try using iterator methods here. it might also be that the fixed indices allow rust to resolve the result during compile time.
One neat trick to speed up such a loop is to avoid branches. You can change your `if` to `t += (v[t] &lt;= v[t + 1]) as usize;`, this should remove the branch on all platforms that have conditional set instructions. Another thing is to notice that you have a needless data dependency by multiplying with 2 in every loop. If I understand the algorithm right, you should be able to just shift-left by `5-i` (where i is the loop counter you just took as `_`). Then you'd just sum over the shifted elements. I'd hope the CPU should see through this.
How does crossbeam's scoped thread support differ from that of the scoped-pool crate?
No need to be that explicit to get the cmov.
I just read it. I think it contains some great ideas about concurrency safety (which is one of Rust's major goals). As someone who pretty much only cares about Rust and not other langs these days, I found it a valuable read. I am glad it was posted. I actually hope Rust core devs see this and think about the ideas presented. I'd love to hear a comment from them about how these ideas relate to Rust's plans for concurrency with async/await, futures, etc. and if they would be applicable or invalid in the context of Rust. Like many other people in this subreddit, I hope to see Rust become the best language it can be. I think any article that discusses ideas around safety/concurrency/etc is valuable for this community, as long as it is not exclusively specific to another language's constructs which are not applicable to Rust. This article is fairly generic and talks about concurrency safety and programming primitives in *any* language, so its ideas could be valuable to the Rust community even though it does not talk about Rust specifically. I hope I inspired you, as a mod, to think more about what content is valuable for the Rust community. My opinion is that even if it does not specifically discuss Rust, if it discusses ideas that are relevant to Rust, it is still valuable to the community and I'd personally be happy to see such content posted here.
I don't think \u\kibwen means that the article is not relevant, but simply that it is good practice to highlight why an article is relevant when it is not immediatly obvious from the article itself. The description gives by \u\igorkraw sums it up quite nicely, and better helps everyone else judge whether they want to read the article or not :)
I just finished the rust book 2nd edition and decided to have a go at writing a rust application. I wrote a brainfuck interpreter, and managed to [publish the crate](https://crates.io/crates/rustfk). It was a lot harder than I anticipated. String handling was also a bit confusing. At some point I wanted to refactor my code to use `std::io::Write` and `std::io::Read` instead of using stdin and stdout everywhere. That took a bit of work. I figured out I could use lifetimes in structs so that I could hold onto the Read and Write. But the code got very messy and ugly. I did a refactor to avoid that. Maybe it gets easier with experience, but I mostly felt like I was just fighting the compiler too much. Previously, I mostly programmed in Go and Python.
Yeah, I might have misinterpreted the mod's intentions. Anyway, I will leave my comment, because I want to share my opinions regarding posts on this subreddit. Yeah I agree it is good to have a comment in such posts to summarise the article and state why the OP thinks it is a good read. 
Thanks for the comment and the 'faster' way actually worked. But I still want to make sure I understood the optimization correctly:) So the `t_max` is to make sure the unsafe `get_unchecked` fn is safe, and `get_unchecked` means it will skip some check so the speed is faster? Another question is why it is also fast if I only remove the `t += 1` in the if block. fn get(v: &amp;Vec&lt;u8&gt;) -&gt; usize { let mut t = 0; for _ in 0..6 { // let (a, b) = unsafe { (v.get_unchecked(t), v.get_unchecked(t + 1)) }; let (a, b) = (v[t], v[t + 1]); if b &gt;= a { // t += 1; } t *= 2; } t } In the above code snippets, I'm using the checked get via `v[t]` and comments the `t += 1` line, and it run fast. Does this means the check of `v[t]` is simple in this situation for the compiler?
This is a great trick, thanks for sharing
&gt; But you don't need Arc because the lifetimes are already taken care of thanks to scoping. Neat :) Thanks for the tip! 
What do you mean? What would be the alternative? Mathematically, relations are defined on types.
Here's a version that produces quite a nice assembly: pub fn get(v: &amp;[u8]) -&gt; usize { let mut t = 0; for (&amp;a, &amp;b) in v[0..6].iter().zip(&amp;v[1..7]) { if a &lt;= b { t += 1 } t *= 2; } t } [Compiler Explorer](https://godbolt.org/g/H9KKtm). Fun fact, if you add `-C target-cpu=native`, [the generated code is different (ie. each comparison put its result in a separate register!)](https://godbolt.org/g/KHwEAh) To make benchmark more reliable, you can consider blackboxing also the input: b.iter(|| get(black_box(&amp;v))) Also, you may consider preparing a few different input vectors up front, and using different ones in consecutive iterations of `b.iter`. Now, no matter how many branches your code will generate, they'll be 100% predictable and won't slow you down (too much). Also, you can try changing the argument of `get` from `&amp;Vec&lt;u8&gt;` to `&amp;[u8]`. That might help the compiler to optimize.
Fixed :) Got some syntax highlighting now and some line numbers too!
As an example of future cancellation built on top of this primitive: the select combinator runs two futures and returns the output of first to finish, as well as the second future, so you can keep polling it if you want. If you don't want to, and you drop the second future, that future is cancelled and never makes progress again.
The alternative would be to make relations first class instead of making them a part of the types they act on. Currently, `T: PartialOrd` means that there is _only one partial order_ for the set `T`. But this is often not true, since for many types, multiple partial orderings exist. Instead, the alternative is to make relations first class: `&lt;T, R&gt; where R: PartialOrd&lt;T&gt;`. That way you can choose which partial ordering relation you want to use for T on each situation.
Please note that LLVM can eliminate redundant assertions when inlined.
actix-web seems to be the most active and more featureful than gotham, rocket is not using async IO right now.
Rocket requires nightly with is a major disadvantage to using it. Also it uses hyper `0.10.13` under the hood which is the last sync version so it not actually async under the hood. I have yet to decide among the other two yet.
If you're looking for performance optimization resources in general, I'm working on a book: https://github.com/dgryski/go-perfbook . Obviously the book is targetted at Go developers, but the large first section is mostly language agnostic.
I think you absolutely should be skeptical, especially when it comes to blockchains and people claiming to be "blockchain experts" and so on. I don't fault you at all for that!
Since /u/fulmicoton mentioned `cmov`, I'd just like to make sure everyone reading this knows of [Chandler Carruth's talk on exactly this topic](https://youtu.be/2EWejmkKlxs?t=2126), where he explains why branches can be faster than cmov.
asyncio in rust is anything but simple, so it doesn't matter what web framework you choose if you're going to use it actix-web is your best option at the moment
I feel bad for pointing out that you never slice the buffer and just keep rewriting over the start of the buffer on each read. 
&gt; If I use a fixed index 0 and 1, the result became to: This may not be a particularly useful comparison, as the compiler can optimize into something unrealistic. The compiler can notice that the condition `if v[0] &lt;= v[1] { ... }` doesn't change between loop iterations and so hoist everything outside (i.e. `get` does just two loads from `v`, and one comparison, not 6): let less = v[0] &lt;= v[1]; for _ in 0..6 { if less { t += 1 } t *= 2 } The `if` can be reduced to `t += less as usize`, meaning the body of the loop is just `t = 2 * (t + (less as usize))`. And once it's done that, the loop can be unrolled to something like (having moved the `as usize` cast): let less = (v[0] &lt;= v[1]) as usize; t = 2 * (t + less); t = 2 * (t + less); t = 2 * (t + less); t = 2 * (t + less); t = 2 * (t + less); t = 2 * (t + less); This leaves `t` equal to (I think) `less * ((1 &lt;&lt; 7) - 2)`, but it takes a smarter compiler to notice that. However, even without that, each of those `t` lines is a single instruction on x86 (using `lea`) so the *whole* loop becomes ~10 instructions total with 2 memory loads. On the other hand, in the real version, *each* of the 6 iterations has to do about that much work even in the optimal case: 6 instructions and 2 memory loads. One way to decide whether this benchmark can be optimized more without a deeper refactoring (e.g. changing algorithms or memory layout), try benchmarking just the memory loads: test::black_box(v[0]); test::black_box(v[0 + 1]); test::black_box(v[2]); test::black_box(v[2 + 1]); test::black_box(v[4]); test::black_box(v[4 + 1]); test::black_box(v[8]); test::black_box(v[8 + 1]); test::black_box(v[16]); test::black_box(v[16 + 1]); test::black_box(v[32]); test::black_box(v[32 + 1]); 
A quick hack that's sufficed for me on a few occasions was pushing tuples of \(isize,T\)
re-read my question!
Wtf?
just a normal fuck
How well do you know Emacs? You should *definitely* use MELPA to install rust-mode and racer-mode (and keep them up to date).
* [actix-web](https://github.com/actix/actix-web) * [rocket](https://rocket.rs/) * [gotham](https://github.com/gotham-rs/gotham) i'd recommend actix-web - speed, simplicity, features. but i am biased
I don't know as much about compiler optimizations as others here, but that version of the function looks like it could compile to essentially fn get(v: Vec&lt;u8&gt;) -&gt; usize { assert!(v.len() &gt;= 1); 0 }
&gt; The newtype pattern would be an adequate solution to this, The newtype pattern is the solution that we already have. The problem is that we want a min-heap of `T`, but to do that with the newtype pattern we need to write max-heap of some other type `U`. It's a solution, but I wouldn't say its a good solution, since now every time you want to, e.g., `peek` in the heap you need to convert from `U` back to `T`.
&gt; The problem is that PartialOrd is used for the syntactic sugar (the &lt; operators) and for specifying the order for sort and friends. Yes this is another problem. &gt; That is not how I interpret it. For me, PartialOrd is the specific order &lt;, and there can only be one without overloading. There are many ways to specify `&lt;` for some types. The problem I meant is that `PartialOrd` only lets you pick one, since as you say, you can't implement it twice for a type without overloading.
Thanks. My usual answer here is, feel free to contact us if the license stands in your way when you have a concrete plan, we'll definitely see what we can do about it.
definitely actix-web
It's certainly soluble but not that easily, I think. Suppose in `foo` above we don't actually switch into `bar` right away, but execution proceeds until the `__exit__` of the `with`-block in `foo`, which detects that now the refcount is zero. Right before calling `shutdown()`, we switch into `bar`, and enter *its* `with`-block. Then we switch back to the main thread, which acquires the shutdown lock and sets `e._shutdown = True` and starts waiting on its child threads. We'll now blow up in `bar`.
Erlang is the ultimate manifestation of simple async io. Nothing else comes close. 
The author's complaints were in that context, but the author's solution wasn't—and the author's solution is built on the same primitives that he's complaining about. It seems a bit unfair.
&gt; This is why I don't like that PartialOrd is a trait on types that embeds a relation, and why I think it should be a trait on Relations instead. This is not possible without losing the syntactic `&lt;` sugar. &gt; In some sense, what we have can be extended to this model. One would only need to extend types like std::BinaryHeap with a way for the user to provide a relation. I agree, this should be doable. 
I don't understand why almost everyone sees nightly as such a "major disadvantage"... Rust nightlies seem rather stable in the sense that you don't just get crashes or everything breaks as soon as the programmer vaguely looks at it. I'm using Rocket right now for a project in my internship and it's really nice, it Just Works. One example: the server "backend" I'm writing handle 10's of thousands of records (in a Vec, because why not) and thinking about it I was worried about how to best share that (in effect) DB between the different routes that query different attributes. Turns out you can just throw that into rocket::State, give your "route" functions/methods an extra argument (like "data: State&lt;Data&gt;") and Rocket does the rest...
How would you do this? If you submit bar to "e" then it can guarantee this doesn't happen, if you don't and call bar directly then Python guarantees you don't leave the first with block until bar has finished.
Stability is not just about your application working now its about things compiling in the future. Breaking changes can happen at any moment with nightly which often causes something you wrote 6 months ago to fail to compile on the latest nightly today - often for multiple reason. This is a huge maintenance nightmare which is compounded by each library that you use that also relies on nightly as once a breaking change happens every library that relies on that feature will need to be fixed one by one until you can upgrade your own application to the latest version. You can partly mitigate this by constantly updating your application or by fixing your self to a particular nightly version but neither are ideal for the vast majority of projects out there. As such stable is generally better then nightly if you have the option between the two. Rust gives strong guarantees that something writing for 1.0 will compile on 1.75 so you don't have to worry about your code bit rotting over such a short time frame like you do with nightly.
I've removed your comment. Please take a minute to read over the rules in the sidebar, and our code of conduct. It is not ok to shout at people who are providing input to a question you've asked, and it is definitely not ok to insult an entire group of people (whether this was intentional or not).
&gt; everything breaks as soon as the programmer vaguely looks at it. For the features that Rocket is using, that's not at all true. We used to live in a world where everyone was pinned to nightly. It sucked, everything broke on a weekly basis as APIs evolved. `stable` is a tag that exists for a reason.
колян, я и не сомневался
Nice hack!
Ok :). I'll PM you to give you the info
&gt; But do you mean that it's disallowed for all custom Eq impls because all of their custom Eq impl could be wrong? (So your "no" meant "not singled out" in that way?) Yes. &gt; Is anyone working towards allowing custom Eq impls in match? Not that I know of.
Awesome dude, these giveaways are always welcome! (I'm not going sadly) 
I really don't understand your max_t function.
Well, we use `t` to index `v`. So we wish to know what the maximum value is that `t` can take, so we can get the bounds checking out of the way. Let's express the maximum value of `t` in the number of iterations. It's easy when the number of iterations is 0: then t will also be 0. So we have: f(0) = 0 The maximum value `t` can take if `v[t] &lt;= v[t+1]` holds for every iteration, because `t*2 &lt; (t+1)*2`. So we can also say: f(n) = 2*(f(n-1)+1) Now, we *could* use our brains to solve this, but I was lazy and had a machine do it for me, see [here](http://www.wolframalpha.com/input/?i=f(0)+%3D+0,+f(n)+%3D+2*(f(n-1)+%2B+1)). Wolfram Alpha tells us: f(n) = 2 * (2^n - 1) Now, we don't just look at `v[t]` but also `v[t+1]`, so we add 1 to the result, giving us `t_max = 2*((1 &lt;&lt; iters) - 1) + 1;`. Tada! :)
&gt; In effect, these let statements become like the “capture clauses” in C++, declaring how precisely variables from the environment are captured. But they give added flexibility by also allowing us to capture the results of small expressions, like self.input, instead of local variables. Worth a read for this idea alone. 
What are the "this"es in "do this" and "this doesn't happen"?
The left shift operator isn’t exponentiation though... right?
&gt; This is not possible without losing the syntactic &lt; sugar. The syntactic sugar would apply to the DefaultPartialOrder if any, for anything else one has to use a relation, and all generic code over relations should use `Relation::lt(a,b)` instead of `&lt;`. 
You should use MELPA and `use-package` to install packages in emacs. Configuring Rust to use RLS on emacs is a bit tricky for a beginner. Here is my RLS configuration if you're interested: https://github.com/CSRaghunandan/.emacs.d/blob/master/setup-files/setup-lsp.el and https://github.com/CSRaghunandan/.emacs.d/blob/master/setup-files/setup-rust.el Cheers
Isn't it? :-D' try it out!1
Thank you. The issue was in fact not having the MELPA package manager, and once I added that, the problem was solved. I'll definitely keep an eye on these files if I need something more complex in emacs
I'm very new to Emacs, with only enough knowledge to know the pull, yank, save, undo, and quit macros. The issue was not having melpa, and once I added it, everything worked. But what is racer-mode?
Thanks for understanding! As I wrote I took a quick glance and to my surprise it seems mostly legit. There are two red flags for me: token and lack of datailed explanation of why blockchain is necessary. I [checked](https://twitter.com/csuwildcat/status/989471243681214464) with "[Daniel B](https://twitter.com/csuwildcat)" who's working on decentralized identity as well, while also being very logical and consistent, understanding crypto space very well. As you can see he has similar view. I'll keep an eye on it. Thanks for motivating me to look at it! :)
Oh, wait. D'oh. I'm a dumb.
TLDR: They chose Swift over Rust because of ergonomics. For their use case the borrowing system didn't carry its weight, and they want to be accessible to programmers of varying proficiency coming mostly from Python. But also, the devs themselves were more familiar with Swift than Rust.
&gt; **Final decision** &gt; In the end, we narrowed the list based on technical merits down to Swift, Rust, C++, and potentially Julia. **We next excluded C++ and Rust due to usability concerns**, and picked Swift over Julia because Swift has a much larger community, is syntactically closer to Python, and because we were more familiar with its internal implementation details - which allowed us to implement a prototype much faster. Given that the goal was to provide an easy-to-use interface for what they estimated would mostly Python users, I agree that Rust's ownership model may have caused more initial friction than Swift's more permissive model.
Chris Lattner is one of the contributors. That might help Swift :) https://github.com/tensorflow/swift/graphs/contributors
But Swift is't available outside the macOS (linux doesn't count). Or they doesn't plan a crossplatform support?
It's hard to reconcile &gt; TensorFlow is open source and has users on every imaginable platform. We want to be able to scale to support all of them. with using Swift, unless its support for Windows and Linux got better than the last time I checked (a long time ago so it might be perfect now!).
Oh! I meant to get myself a Rustfest ticket but completely forgot about it :( If anyone bought a ticket but isn't going, I'd be happy to buy their ticket.
It should probably be possible to edit this configuration as part of the build done by emerge, though, right? I'm not a gentoo expert but I imagine this is an issue that could be solved by the maintainer of the firefox `.ebuild` file adding something to ensure only one rust backend.
Oh, on second thought I think I see the problem.
More context: https://www.hillelwayne.com/post/theorem-prover-showdown/ (although this is less Rust-relevant)
[The Embedonomicon](https://japaric.github.io/embedonomicon/) has instructions that should lead you the way. I use this approach in my bare metal Raspberry Pi 3 tutorials. There's always the platform specific "raspi3\_glue" extern crate that calls the main of my actual crate. For a hands\-on example, [take a look here](https://github.com/andre-richter/rust-raspi3-tutorial/tree/master/05_uart0).
Even the Rust creator switched to Swift&lt;/troll&gt;
&gt;TLDR: They chose Swift over Rust because of ergonomics. &gt; &gt;For their use case the borrowing system didn't carry its weight, and they want to be accessible to programmers of varying proficiency coming mostly from Python. But also, the devs themselves were more familiar with Swift than Rust and they're not *entirely* clear about how much that influenced things. I wish they were more forthright in saying “we hired the person who invented and developed Swift and he has the experience &amp; political capital to lead such an ambitious project”. That's a valid reason! Don't shy away from it!
&gt;It is a bit surprising that rustc/LLVM didn’t optimize this into mov eax,0x1; ret, and that it left some unnecessary prologue and epilogue instructions in there. When gcc and clang are given the equivalent C\+\+, they can boil it down to our expected pair of instructions. It is almost as if the Rust were compiled with an implicit \-fno\-omit\-frame\-pointers flag. If you know what’s going o here, please let me know! The compiler currently force\-enables frame pointers when building with debuginfo: https://github.com/rust\-lang/rust/issues/48785
Note that the project is "Swift for Tensorflow" and not "Tensorflow for Swift"... They want to modify the language. Quoting the README: &gt; Swift for TensorFlow is based on the belief that machine learning is important enough for first-class language and compiler support, and thus works very differently from normal language bindings. First-class language and compiler support allow us to innovate in areas that traditionally were out of bounds for machine learning libraries. edit more quoting, this time GraphProgramExtraction.md: &gt; Our approach came when we looked at the entire software stack from first principles, and concluded that we could achieve new things if we could enhance the compiler and language. The result of this is the compiler-based graph program extraction algorithm described in this document: it allows an ML programmer to write simple imperative code using normal control flow, and have the compiler do the job of building a TensorFlow graph 
Aha! That makes sense! I'll add an update -- thanks!
That's the solution that makes the most sense to me. Agree with you on the macro rule. I guess there could be a separate macro rule for "accept optional trailing commas" vs the general rule to avoid ambiguities ?= 
I was about to say the same! I think I started with [`Vec`](https://github.com/rust-lang/rust/blob/master/src/liballoc/vec.rs), [`HashMap`](https://github.com/rust-lang/rust/blob/master/src/libstd/collections/hash/map.rs), [`RawVec`](https://github.com/rust-lang/rust/blob/master/src/liballoc/raw_vec.rs), and [`RawTable`](https://github.com/rust-lang/rust/blob/master/src/libstd/collections/hash/table.rs). I’m actually looking at them again now, because the implementation for HashMap changed a bunch since I first looked at it.
Thanks, that’s what I was failing to find. What I’ve seen other webapps do is provide a little ? icon somewhere on the page that pops up a window listing all the keyboard shortcuts. 
I think this is a bit complicated. Some time ago I tried to add [config-rs](https://crates.io/crates/config) support in [structopt](https://crates.io/crates/structopt) and created some [working prototype](https://www.reddit.com/r/rust/comments/81tp16/wip_platformconfig_multisource_configuration_for/). As far as I know there is some discussion in [clap issues](https://github.com/kbknapp/clap-rs/issues/748)
I want to write Pure Data abstractions via libpd using Rust. Any suggestions?
Which is why I like rust so much. It's genuinely helpful to learn.
Every Rust feature needs a champion, "stable ABI" just doesn't seem to have found one yet.
&gt; However, the mechanism that tried to ensure that the thread actually stopped before the caller function returned (and possibly unallocated things the thread might have a reference to) was noticed to be unsound, and the API was removed. &gt; At the moment alternative, sound APIs for scoped threads are provided by the crates ecosystem. But why wasn't std's scoped thread changed to be sound, instead of being removed?
In some respects yes but functional or functional style? Functional languages yes because there is no mutable state and therefore no side effects caused by mutation. Everything which changes is changed by computation which is very easy to proof. You can be functional in rust, don’t use mut. It’s not optimized for that tho like a real functional language. If it’s mutable, it ain’t functional. 
Neat! Maybe this eventually leads to LLVM getting ML primitives that other languages can benefit from!
Saw this happening on twitter. Thanks for linking to this summary. I think when people say that FP is easier to reason about, they mean that in statistical/probabilistic terms, as in: "it's easier to prevent many kinds of accidental bugs due to the restrictions of purity and a strong type system", which (assuming it's true) doesn't give any guarantees about correctness against a specification. The best type system in the world (by itself) can't prevent logic bugs because it doesn't know the intention of the programmer. Only when a specification is given (in a sufficiently strong type system), can a compiler use that to prove that the code is correct, whether the code is imperative or functional has no bearing on its prone-ness to logical bugs (locality of side-effects influences this, local mutable vars vs global etc.). But given that the number of bugs in deployed software "in the wild" is to a large extent preventable by putting more restrictions on code by stronger type systems, it's understandable that many people are advocating for more FP even though they can't prove correctness. Because most (even FP) developers never actually prove their code to be correct, but they noticed that they ended up with fewer bugs when using stronger type systems, and historically stronger type systems were mostly pushed by FP research so the bias is understandable. But I think there's a lot of headroom for imperative languages to catch up with strong type systems (like Rust is doing). With strong type systems it's possible to write more statistically correct code without proving it correct (the likelihood of bugs gets reduced, but their absence still isn't proven), and since developers are mostly paid for "working code" instead of "code proven to be correct", it's likely that this trend will continue, maybe it will converge to a situation where at some point in the future, a large percentage of code will be proven correct (at least critical libs that many projects rely on).
I don't know. It's probably technically possible; the question is whether it'd be worth it.
It started off as a swift project a few years ago: http://dlvm.org
Linux is basically fine now. I don’t know about Windows. 
Even reading from global variables makes a function not pure (it could return different values when called with the same arg). Also printing to stdout would make it not pure. But in a purely functional language like PureScript, you run your computation in a stack of monads where each monad allows certain things, like state mutation, IO, or other effects like providing access to a random number generator. The interesting thing is that with this effect system the caller of a function can dictate what the callee is allowed to do. E.g. you could open a "scope" in which exceptions can occur, but none could be thrown outside of that scope. So the exception handler "takes the EXCEPTION effect away" again. And from the signature of the functions you can see what they are allowed to do. E.g. if a function in your PureScript project only uses the `RANDOM` and `CONSOLE` effects, you know it can't be modifying the `DOM`. (So if you're investigating which function could be causing a bug that modifies the DOM, that can help.)
That non-globally-thread-safe thingie seems nasty... I would have done something like this: use std::sync::{Mutex, LockResult, MutexGuard}; use std::marker::PhantomData; pub struct LibpdHandle(PhantomData&lt;()&gt;); lazy_static! { static ref LIBPD_HANDLE: Mutex&lt;LibpdHandle&gt; = Mutex::new(LibpdHandle(Default::default())); } pub fn handle() -&gt; LockResult&lt;MutexGuard&lt;'static, LibpdHandle&gt;&gt; { println!("{:?}", &amp;LIBPD_HANDLE as *const _); LIBPD_HANDLE.lock() } impl LibpdHandle { // Put the entry methods here } That way, whenever you do something with libpd - you'd have the lock that ensures nothing else is calling it's functions.
Your Readme suggests that the server would have to be recompiled (build.rs needs to re-run) whenever the (runtime) config changes. FWIW, I use dotenv + envy a lot (no recompilation necessary): #[derive(Debug, Deserialize)] pub struct Config { #[serde(default = "default_bcrypt_cost")] pub bcrypt_cost: u32, pub frontend_dir: PathBuf, pub mail_smtp_host: String, pub mail_sender_address: String, pub mail_domain: String, pub mail_name: String, pub mail_password: String, } fn default_bcrypt_cost() -&gt; u32 { 11 } lazy_static! { pub static ref CFG: Config = match envy::from_env::&lt;Config&gt;() { Ok(cfg) =&gt; cfg, Err(error) =&gt; panic!("{:#?}", error) }; } fn main() { let _ = dotenv(); let cfg = &amp;*CFG; trace!("cfg: {:#?}", cfg); // this loads the config first, will panic if keys are missing You can also load the config from a file at a given path. For some other configs I use RON files, and for persistent data if it's large I use rustbreak, for simple key/values I use app_dirs/preferences. 
I can't help but get reminded of monad by the beginning of this article. I have not finished it. But when someone mention context manager in the comments, that also reminds me of monad, by my primitive understanding of it, although monad is probably actually more generic. I'd really appreciate if someone knowing more can elaborate more on the relationship between this and monad.
Configuration management is also a topic of concern for the CLI-WG. For people interested, feel free to come help: - [Tracking issue](https://github.com/rust-lang-nursery/cli-wg/issues/7) - [Config-specific gitter channel](https://gitter.im/rust-clique/confy)
Just to be safe. The API was changed completely (into one that uses closures to ensure that the control flow doesn't continue until the threads have exited), and there were still doubts, so it was considered the safest thing to do. It might be that if one were to re-introduce the scoped API into the stdlib via an RFC that might go through, but then again, evolution in the ecosystem is considered an equally good way, and there would be backslash against bloating the stdlib. With the recent advocacy for "nurseries" (see the other thread: https://www.reddit.com/r/rust/comments/8est3f/notes_on_structured_concurrency_or_go_statement/ ), scoped API would be nice to have as a default, though.
This encouraged me to actually read the WebAssembly spec. It was intriguing; I learned some x86 assembly years back but have forgotten almost anything about it. This clearly has a more high level feeling, while still feeling "assembly-like". I like how the system is designed to be trivially checkable for safety just before running! Also the fact that it's supposedly patent-unencumbered and doesn't include a GC is intriguing. To me, it feels much more a true "neutral" platform-agnostic target, whereas JVM and CLI have all kinds of strong ties to companies and techonologies of those companies.
Good choice. Rust is great but it may be difficult sometimes. Still, I think it would be great to have good Rust bindings for people who want to get even better performance.
I have gotten a few working. The easiest is [this one](https://github.com/freemasen/wasm_tutorial) since it has a build script to automate all of the process. I am partially through a full [0-60 tutorial](https://freemasen.github.io/wasm_tutorial) that uses it as an example (start at “a contrived example”) there is still a ways to go on the overall documentation. The other example as part of that tutorial is [a hello world](https://github.com/freemasen/wasm_hw). 
&gt; Your Readme suggests that the server would have to be recompiled (build.rs needs to re-run) whenever the (runtime) config changes. I don't think that's what the author was getting at. There is a `config.toml` which is used to generate the code which can gather the application's config from the environment and/or config files at runtime. If that `config.toml` file changes, then the code to gather the configuration needs to be regenerated.
Couple of comments: * Description in cargo.toml is straight from ripgrep * Why not a BTreeMap (or even a crate like indexmap if you wanna preserve order) instead of a List&lt;KeyValue&gt;? * May wanna look at [structopt](https://github.com/TeXitoi/structopt) for your cli parsing rather than clap-rs * Lots of unwraps() that could be replaced by `?`. Maybe use the failure crate? * Would be great to support alternative db backends, like [cask](https://github.com/andresilva/cask) or maybe some web service * Would be great to be able to output into json or something else 
Yea, I was curious about the close-knit team achievements at the end. Is this like, google's internal language research team?
Thanks for the feedback! Yeah, theres definitely a ton of shortcomings that I'm looking to iron out in the near future, and I'm still new to Rust, so theres a lot that I have yet to figure out. My initial thinking was that since this would be individual user submitted data, the performance under large loads of data would be less critical, so at least until shown otherwise a vector would be simpler, and easier to parse into and out of a serializable format like JSON. 
Complicated to use or written in a complicated way? I'd like to know what exactly is complicated about it and how it could be improved. So far my opinion is that using the crate isn't complicated, but I'd agree it's boilerplate-y. I plan to improve on this. Suggestions and PRs welcome!
BTreeMap implements Serialize/Deserialize. You can write them out directly to a file, and would simplify a lot of your code.
You are correct. I think I will need to improve the documentation, though. :)
Can you provide a short comparison of that library with my crate? Especially which useful features does it have that my crate doesn't.
The code using your crate is complicated. You don't create the configuration struct, so there is already some magic. It means, that a very important part of the code is hidden. As far as I understand, it also autocreates config.rs file during compilation. It probably means, that this file should be added to .gitignore? Writing the configuration for your crate is also a bit complicated. You can for example use types, but you have no syntax checking (at the time of creating config) and no suggestions from IDE. And I think the biggest issue - you try to compete with clap / structopt / docopt which are currently a _standard_ way to work with command line arguments
And what about actor model? There you don't have this sequential execution concept between actors (but within actors you have). Or in an actor system all sent message considered as "goto"? Or spawning new actors are considered "goto"?
You can read the whole generated code in target/*/ directory. That being said, it seems to me that using custom derive would be a better approach, except that it would be more difficult to generate bash completion. I don't think I try to compete with others. I'm trying to provide an alternative that may be more suitable for some use cases.
Thanks! If you're so inclined, please give it a pull request, or open an issue with any features you think would be interesting!
Ferris! He makes emulators.
&gt; Everything which changes is changed by computation which is very easy to proof. [citation needed]
&gt; Everything which changes is changed by computation which is very easy to proof. [citation needed]
Incredible to see this project progressing so well!
Couldn't there be things that are easier to prove for imperative programs, because the imperative implementation is simpler?
Wait, so the compiler is smart enough to skip bounds checks on array accesses if I "reassure" it with an assert? So in this case I would assert that the vector's length is at least as large as the maximum value of t + 1?
[http://aturon.github.io/2018/04/06/futures2/](http://aturon.github.io/2018/04/06/futures2/) So... "might be good enough for you already, will be better \(and possibly breaking changes\) all year, hopefully 1.0 by the end of the year"
&gt;(linux doesn't count) What?
Because Linux support is an overstatement. The support only Ubuntu.
I can't say I'm very sad about that ;)
Ah, I see. It is buildable on other distros, though. For instance, https://aur.archlinux.org/packages/swift/ I suppose Rust doesn't really support any Linux distros specifically either, does it? 
Have a look at https://rust-lang-nursery.github.io/rust-wasm/game-of-life/setup.html and https://github.com/rustwasm/wasm_game_of_life
📅 2018-04-27 ⏰ 02:53:47 [(UTC)](https://www.timeanddate.com/worldclock/converter.html?iso=20180427T025347&amp;p1=1440) &gt;🌌 wasm-pack 0.2.0 is out! 🌌 &gt; https://github.com/ashleygwilliams/wasm-pack/releases/tag/v0.2.0 &gt;&amp;nbsp; &gt;thanks so much to [@mgattozzi](https://twitter.com/mgattozzi) [@jamiebuilds](https://twitter.com/jamiebuilds) [@yoshuawuyts](https://twitter.com/yoshuawuyts) [@sendilkumarn](https://twitter.com/sendilkumarn) [@Andysomniac](https://twitter.com/Andysomniac) [@steveklabnik](https://twitter.com/steveklabnik) [@6b766e_sadpost](https://twitter.com/6b766e_sadpost) [@edsrzf](https://twitter.com/edsrzf) and [@jasondavies](https://twitter.com/jasondavies) for your contributions! ya'll are great! ✨✨✨ &gt;— ashley williams ([@ag_dubs](https://twitter.com/ag_dubs)) &gt;🔁️ 16 💟 56 &amp;nbsp; ^(I'm a bot and this action was done automatically)
Do you mean geospatial? This looks like great stuff! I've been interested in these kinds of crates.
Yes, that's what I get for posting without double checking. Thanks
Damn, as someone very interested in building my own compositor and clients in the future this is incredibly encouraging.
Well, I can install Rust via rustup on any distro and via package manager on most distros. And I can't do this with Swift.
Your prototype looks exactly like what I would want a unified config solution to be. It's promising, are you planning to continue its development?
Hey thanks for pointing out how to approach this. Actuallay i found [this repository](https://github.com/kmtr/pd_ext_rust/tree/master/pd_sys) which seems to already did the binding stuff. So the most effort left is to write a higher level Rust API. What i want to achieve is being able to write my own Pure Data abstractions via libpd so i can use them within Pure Data. And I want to avoid writing error prone code (via c) by using the safe environment of Rust for it.
I think that's one of the great benefits of rust, it's very easy to see where you can apply polish.
You weren't lucky, the number of turn needed in your example game is quite high. The average turn number needed to end a game of War with 52 cards is [a little above 280](http://www.lifl.fr/%7Ejdelahay/pls/1995/030.pdf)(in French, the result in on the last page). But it seems you don't use exactly the same rules since you use the whole 54 deck including Jokers so the figures may vary a bit.
/r/playrust?
Sure, I don't think that would be difficult. Thanks for the recommendation.
You're right. I choose to visualize a game with a high number of turns in order to create an interesting graph. The average case is much lower. The graph also shows a game with 108 cards. This is due to the fact that Israeli kids tend to use double pack with Jokers included.
i would not rely on it, but yes. it also unifies the error path: if you have a few array accesses, lets say a[5], a[4], a[3] you would maybe expect [4] and [3] to elide bound checks, but that does not happen cause different errors or something. if you want to make sure, look at the asm, for example in the compiler explorer.
No - difference in compilation and hardware can result in variations that are impossible to predict without careful analysis of the actual code. Never use floating point numbers for exact comparisons, unless you are within a "safe subset" (eg. if you are javascript and are storing integers in a floating point value, then you *can* rely on small integers being represented exactly). If you need to check floating point values in tests: use a range test like `assert_ulps_eq`, and use whatever range you actually require: eg. if you need results accurate to `0.01`, then use that as the range in your tests. If you do need to perform exact arithmetic, use a different number format (eg. rationals).
I definitely plan to develop some kind of platform config (maybe even this weekend) but I'm not sure if it is the right direction. Most of my current application (I use rust at work and maintain a couple of cli apps) have clear separation between CmdArgs and Config where `Config : TryFrom&lt;CmdArgs&gt;`. This requires some code repetition but also allows to insert some logic (e.g. custom parsing or creating one param from other in case it was not passed and not configured). My PlatformConfig macro merges two structures and makes things less explicit and more magical but there are some benefits too. I'm thinking about the right architecture since I raised an [issue](https://github.com/TeXitoi/structopt/issues/72) in structopt
Errors/uncertainty in FP arithmetic propogate in every single operation, and you lose precision at every single step unless every value is exactly representable in base 2 in the FP scheme, which is very unlikely. So in whatever language you deal with, you face the same issue, unless you use arbitrary precision floating point, which is very slow. You do get more precision by using more bits, but your error still propagates. The method to determine a an upperbound properly is called floating point error analysis, where you observe how error propagates at each point, and the result is highly dependent on what you do exactly, and the analysis is quite complex as far as I can tell(maybe I just suck at it). This is usually the forte of scientific computation people, as they need to analyse the errors for molecular simulations and other stuff they do. So no, there is no simple upper bound that you can guarantee, but setting a large enough imprecision for testing is normally enough(+/- 0.000001, say). And no, you can't do that in `assert_eq` directly, but you can probably make a similar macro that makes it easy to assert the condition. ULP seems to be concerned with accuracy of the floating point repretation, so it is potentially usable, but I am not really sure as this is absolutely beyond my forte. Hope this helps.
&gt; So my question is: is there some simple upper bound to errors in fp that works across all implementations? Can I use it when doing assert_eq? Sort of: the IEEE754-2008 standard that defines them requires that implementations get the correctly rounded answer for operations like `z = x + y` (that is, assume `x` and `y` are 100% precise real numbers, then `z` should be the closest float to the real number `x + y`), but this really only holds for the basic arithmetic operations with [non-tiny](https://en.wikipedia.org/wiki/Denormal_number) operands. Anything beyond that, like `sin` and `exp` and so on, will behave differently on different platforms.
Cool, I'll hold off for a bit then. I'm already using rust-geo for country parser (another program that uses most of the same crates).
This is a known issue that affects numerical computing in general...if you want to bound your errors in a truly rigorous sense and not just hope that they will "mostly" average out over multiple computations, you'll need to use either interval arithmetic (gives you a worst-case error bound on the result for a given precision on your inputs) or "exact" real arithmetic (you can actually request a desired error bound for your computation, and it can then "call back" to request tighter bounds for your inputs as needed, basically a sort of lazy evaluation applied in a numerical context). Both of these are hard to implement rigorously with the usual FP primitives...interval arithmetic is slightly easier but common implementations will be very pessimistic as the computation becomes more involved...
I guess this is the kind of answer I expected. I thought it would be easier to get *an* upper bound, even if it is awful. Very little of the 'business' coding I do involves fp, but I'm exploring hpc at the moment for fun (specifically computer graphics, where most errors are small in the "eyeball metric").
So how is this any different from implementing, say, an associated `new` function and then just calling that to produce a new instance of `Options`? It still requires me to implement `Default` for each type, which is what I'd do with `new` anyway. What I'm after is something like implementing a default *on a trait* and having that disseminate into all structs which impl that trait
Scrolling doesn’t work properly on linux any more, as far as I can tell. The scrollbar works but using my trackpad it locks up. Probably it’s being hijacked by javascript 
You can get Rust for free at [rustup.rs](https://rustup.rs)! Joking aside, I believe you meant r/playrust, and, um, I don't think that Rust is usually free.
As a follow up, I've managed to build and link, see the issue on github for the details :)
I'm continuing to work on the React-in-rust. Most of the work has been on making the jsx! macro work. It's surprisingly easy once you figure out the initial bits to add features, thanks to the amazing nom crate!
Meybe i will find who can help me 
I have written my first little tool in Rust this week. It's only 100 lines of code, but I'm super proud it works now. It's a vanity-address generator for a crypto-currency called Lisk. Basically, it's hashing mnemonic phrases and calculating the numeric length of the address and keeps on brute-forcing new addresses until it finds really, really short ones. Because unique about Lisk addresses is that they are not fixed-length (as opposed to Bitcoin or Ethereum) and one is super fancy if your address is the shortest :) First, I implemented it in a somewhat sloppy Ruby script, but the performance was rather low (400 keys per second), and I concluded a native Rust implementation could speed this up. I'm now at 1200 keys per second, but not overly satisfied performance-wise. I guess there is still a lot of room for improvement. The code is on Github if anyone is interested. I'm happy to receive any feedback. https://github.com/4fryn/lsk-shorty
where exactly are you seeing the breakdown?
Then please help. While the rust ecosystem is small, there is still large parts of it that many of us have not come across. For example, I've seen talk of `configure` but never `config`. I've added it as one of the crates to be aware of.
Meh, as someone coming from Python if you don't want to deal with lifetimes (borrowing is fine, lifetimes are where things get tricky) then just clone clone clone. Also just unwrap whatever and figure it out whenever is also fine coming from Python. I think it would be nice to see a sloppily written app this way so we can say "look its still pretty good and I never had to deal with lifetimes." I know lots of folks are interested in saving that extra instruction, but also lots of us are just happy with easy to read more-efficient-than-Python code.
Really interesting article.
&gt; Offline reverse geocoding library. Debating if I should depend on rust geo for the types, or let users convert for themselves if they want. Neat! Would it make sense to be able to filter the results, e.g. get the closest place with population larger than 10000 (or get an iterator of the closest places in distance order)? Also, in https://docs.rs/rgeo/0.1.0/rgeo/record/struct.Record.html: &gt; name: String &gt; country name Should this be "location name"? Lastly, how big is the data? It'd would probably be appreciated if you included an approximate figure for how big the crate is in the docs, so people can decide if they're willing to pay that cost.
Do you mean port more of it? People are already working on [https://github.com/georust/rust\-gdal](https://github.com/georust/rust-gdal)
Thanks, I'd rather give it to someone from the community :) so it's my pleasure
Thanks!
Maybe this is a question for the TensorFlow team, but does this decision open up new performance opportunities in using Swift vs. using the C bindings for a previously saved Python model in a language like (for example) Rust? In other words, does this imply that using Swift for the graph-creation aspect of TensorFlow will make Swift the categorically better choice for using TF models -- better than using the C bindings? FWIW, in practical use I think of TF as almost an entirely separate language system from Python. You can't really use NumPy, and you're just creating an abstract graph with the illusion of using imperative programming. (It's a pretty easy parallel to many audio coding languages like SuperCollider.) Honestly, I see this as "they want to do machine learning on mobile," given that's what people have used Swift for in the past.
Super cool you can get feedback like that:)
[removed]
What does *relatively soon* mean here? A month, half a year?
I could add the population size, but it might bump up the crate size too much adding another field. Currently it's about 28M, I'll add it to the docs. If you manually download the crate you can adjust some of the parameters in generate.rs (that's what creates the kdtree I use to search), but you need to download the allCountries.txt from geonames, it's 1.5G so I thought people would probably go with the defaults. You're right, it should be location name.
&gt; scenario "parameter is required in configuration, but not required in cmd line" Actually that's one thing I don't really understand there. When would it make sense for it to be required in the cmd line if it's required in the configuration already? And this makes me wonder, how do you handle "this thing is mandatory, but I don't care where it comes from"? Do you put `Option`s in your structop structure and handle the potential error yourself? &gt; It is hard for me to imagine non-magical way to allow user to generate some params basing on others. My macro generates new structured claled YourStructureOptions. Imagine that I allow you to define "default_fn" that creates default value basing on existing configuration. The problem is, that such function must takes param of type YourStructureOptions which has been automatically generated... Too much magic for me Would it be possible to declare what parameters you depend on, and then only pass those to `default_fn`? This would be less magical, I think, but I'm not sure if if it's possible to generate decent error messages when the function signature doesn't match.
&gt;Yea, I was curious about the close\-knit team achievements at the end. Is this like, google's internal language research team? Nope—the work began at Apple. Google just hired the original designer/lead of Swift \(after a brief stint at Tesla\). I believe that some teams at Google forked Swift to introduce these TensorFlow\-specific changes.
Also note that, despite the name, WebAssembly is not tied to the web or a web browser environment. It is a bytecode format (similar to JVM/LLVM/etc bytecodes) that is designed to be flexible enough to represent any low level non-GC language like C or Rust in a way that is secure and sandboxable (to be able to safely run it in a web browser environment). However, this bytecode format could be used for other things too. There is an experimental OS called [Nebulet](https://github.com/nebulet/nebulet) that is based on WebAssembly. It has nothing to do with the web. There is no JavaScript or anything. It is a traditional desktop/server style microkernel OS, except that it runs WebAssembly / uses it for its binary format. It provides its own system libraries and services. The cool thing is that thanks to the nice sandboxability/security/safety properties of WebAssembly, all user processes and applications can run in priviledged mode (hardware ring 0) alongside the microkernel, in the same virtual address space, without risk. This would greatly increase context switching and syscall performance compared to normal OSs, because it avoids all of the hardware protection mechanisms for userspace altogether.
Right, but how do you say "I absolutely want this thing to be defined, but it can be at any point in the configuration layer"? Like, it could come from the config file, the command line, an environment variable, whatever. But it has to come from *somewhere*, otherwise you want an error to be generated and the execution aborted. Would the user have to declare it optional and generate the error manually afterwards?
Herp derp, and in my [writeup about ggez](https://wiki.alopex.li/GgezOnWasm) I said "I guess tables are just used for Javascript interface". Silly me didn't think about how I would have to call a function pointer in wasm! Easy to add an addendum though. 
There's definitely a lot *more* you can check at compile time. Some things are totally enforceable, like "this function returns the right number of values", which is nice 'cause it just removes whole classes of bugs and special cases. Once you touch memory or tables though a lot of promises about type safety go out the window.
I like the diversity in the various "no" answers here, but I feel like it should be possible to give a more complete answer, compiler and hardware differences aside. There's a number of things that *are* exact in floating point, so understanding those might help us consider the problem more easily. I'm no expert but afaict these things should always be true: * Performing the *exact* same set of operations will get you the same result (though if the compiler decides to construct the same equation two different ways you may be out of luck). * Multiplying or dividing a power of two by a power of 2 is exact, to within the precision of the number (It's just flipping a bit in the exponent) * Adding or subtracting multiples of powers of two, or a number divided by a power of two, should be exact to within the precision of the number (its significand is represented exactly). ...Okay, this list is shorter than I expected. Maybe this is just me being optimistic?
I simply return a `Result`. When some required parameter is missing, it is an `Err`
Perhaps add a [default impl](https://doc.rust-lang.org/book/second-edition/ch10-02-traits.html#default-implementations) for the `Widget` trait? And override it for each type as needed. ``` trait Widget { fn width() -&gt; u32 { return 100; } fn height() -&gt; u32 { return 100; } } impl Widget for Square {} impl Widget for Rectangle { fn width() -&gt; u32 { return 200; } } ``` 
also really good demos!
Full disclosure - this was written entirely by me as a side project at work, and today I've finally received permission to open source it! 🎉 It may, or may not be useful to other people. Our requirements for a profiler are a little unusual, which is why `perf` (which is the de facto sampling CPU profiler on Linux) didn't always work too well for us. If `perf` works for you there is *probably* no reason to use this, but it might still be interesting to you purely as a curiosity!
I first got excited about rust in the same way. I had learned Haskell and I really liked it, but I was disappointed in the performance and wasn't sold on the garbage collector or lazy evaluation or lack of mutability. But at the same time, I was disappointed with C and C++ and knew that safety was the biggest problem. I doubted we would still be using unsafe languages for systems programming in the future. D and go came out, but with a GC. I thought "this can't really kill C or C++ if it's not a language you would write a web browser in". I also had this idea that a language didn't have to be low level or high level, but you could have a suitable low level language that made high level tasks easy too. It could have a wide range. As soon as I saw rust, I was sold.
Haha I am not sure how good you are, but porting pandas isn’t just a simple 2-day project!! ;-)
Thanks for the reaction I will definitely look into it.
The state of machine learning and data processing in rust is still very underdeveloped at the moment. You can see an overview of it and a list of all currently in development libraries at [arewelearningyet](http://www.arewelearningyet.com/). There are a few interesting projects around data processing linked to in that site. Maybe you will enjoy jumping into one of them and helping them to develop and mature some libraries around the area. This would be a lot more helpful than starting your own project which would be a lot of work to achieve a stable and useful result.
[`RwLock::write`](https://doc.rust-lang.org/std/sync/struct.RwLock.html#method.write) gives you your hashmap wrapped inside a RwLockWriteGuard, which is a type that contains a reference to the RwLock and when dropped will unlock the RwLock for other people to use it. As is, the RwLockWriteGuard drops at the end of get\_or\_add, but you still want to reference its contents which obviously the compiler won't let you do. There's no way to fix this with the code as it is, I think you need to provide more details of what you're trying to do so we can see how it can be restructured.
So here you need `takes_foo(&amp;*foo);`, right? Which makes sense but looks so weird.
There are two possibilities how you want it to work: 1. You want to unlock the `RwLock()` in `get_or_add` and then return a reference to a String. In that case there's nothing stopping other thread to lock the cache, clear the hashmap and destroy your previously returned `&amp;String`. 2. You want to keep the cache locked while you're using your string. In that case, it might be better to redesign your function to something like `with_cached_value` that takes a `FnMut(&amp;str)` closure. Anyway, the simplest solution is to store `Arc&lt;str&gt;` as values of the hashmap and just clone the `Arc` when returning from cache.
Build your application, benchmark it, then try alternative approaches while benchmarking them and find which one is fastest for your workload. There are quite a few data structures that would fit this but which one is best really depends on the details of what you are trying and your particular implementation. There is no point in trying to optimising things before you have an application to optimise so worry less about this and worry more about building your application. Then once you have a base you can start to profile it, find the slow bits and optimise it from there. If you find the data structures too slow try alternatives and see how they compare, looking at your profiling reports to guide your decision.
i don't deal too much with this but: depends on the access patterns. if you can put data often accessed together physically close to each other than you get a huge win. there are some self-learning data-structures popping up here and there. B-Trees might do the job (think database index), but with only a few millions elements i don't know if it's worth it. if your best assumption is uniform-ish random access then hashmap it is. (with your small amount of data i'd say don't spend too much time on that at first) it's really all about the access patterns. (and your hardware)
This is super cool! Planning on digging into the code in the next couple days :) I see that you are using `gimli` and `cpp_demangle` too -- that is double awesome! How has your experience been? You might want to join the handful of us who hang out in `#rust-debugger-tools` on irc.mozilla.org :) Also https://github.com/luser/rust-debugger-tools-info if you haven't seen it. Maybe there are reusable bits to be pulled out of this project, that could be shared? Fun story: the reason I originally started writing `gimli` was to create a sampling profiler framework. My yak-stack got a bit deep and I never climbed out of the shave :-P The idea was to make writing domain-specific profilers quick and easy. For example, https://perf-html.io/ combines precise tracing of Firefox- and Web-specific events with a sampling profiler. Instruments also has its signposts, which provide similar extension points, but are a bit annoying to use IMO. I find the combination of precise tracing of domain specific operations with stack sampling to be a super helpful combination. The precise tracing gives you an idea of what is "semantically" happening at any given point in time and why, and the sampling tells you where you're spending time during the domain-specific operations. Would you be interested in pulling out the CLI specific bits from `src/main.rs` into `src/bin/nperf.rs`, and moving what is left in `src/main.rs` into `src/lib.rs`? This would be a first baby step towards making the profiler framework vision a reality.
I started work on [mosler](https://github.com/abhijat/mosler) which is supposed to be a shell for hashicorp vault. It uses the HTTP API for vault to run its commands. I have to use vault a lot at work and I wanted to write a repl for it so I can easily run commands after logging in once, with tab completion, history etc. Right now only the ls-policies command works so I have a lot of work to do. There is a vault token in the source code but it just points to a dev instance I was running on my desktop.
Thanks, I didn't know about that!
[removed]
I was confused for a moment there... You surely mean machine learning; not ML the programming language (where Rust is descended from)? (In hindsight it’s too obvious but I was seriously confused for a moment.)
1. Hashmap or Trie variant. I'd go for the std hashmap because it's really fast for lookups and I'm unaware of highly optimized trie crates. Just make sure to use a fast hasher. 2. Same as above, but a variant with trade-offs towards insertions. https://crates.io/crates/indexmap is a good bet.
&gt; Have to store millions of objects How big is each individual object? Depending on the relative size of the value compared to the key, it may be worthwhile (cache-wise) to store key and values separately. --- Seeing as you'll likely face cache pressure, you may want to use bluss' [`indexmap`](https://github.com/bluss/indexmap) as it's quite more compact in memory than the ol' regular hashmap. If speed matters, and the source of keys is controlled, I also recommend investigating alternative hashers. SipHash is good for untrusted content, at the cost of performance. If you control the keys, you can probably a faster hasher... the FNV algorithm works pretty well for small keys normally.
This is so cool! Amazing work! ✨
Nice work! Have you tried simpleperf, it has quite a few of these features too; cross-arch, on the fly unwinding. I'm not sure if it supports mips though. BTW how did you find the documentation for perf_event_open? I'm using it at work and find it quite lacking and buggy. I've spent a lot of time reading the kernel source to figure out how it actually works.
For hasher implementation: obviously, replace std's SipHash if you have trusted keys. Based on [twox-hash's tables](https://github.com/shepmaster/twox-hash), I think at 24-byte key that XXHash beats FNV?
&gt; I see that you are using `gimli` and `cpp_demangle` too -- that is double awesome! How has your experience been? Yeah - those two libraries were absolutely essential in getting this to work, so thanks a lot for them! (: The experience was - in general - pretty great. I haven't encountered anything critically fatal, but from minor issues I've seen: (I really should report those on Github in more detail): 1) IIRC, some of the libraries from the [MIPS64 userland](http://downloads.yoctoproject.org/releases/yocto/yocto-2.4.1/machines/qemu/qemumips64/) I use for tests have entries in the `.eh_frame` section with a different version than what `gimli` expects. (It may be related to [this issue](https://github.com/gimli-rs/gimli/issues/244).) Fortunately this isn't critical for us since the binaries generated by our internal MIPS64 toolchain do not exhibit this issue and the profiler also supports `.debug_frame`. 2) I've noticed that on amd64 the GCC/G++ likes to generate a particular CFA rule which is not handled by `gimli` itself. Or at least I *think* it's mostly the same (or very similar) rule; I haven't investigated this as this happens rare enough to not be a problem for the profiling data to be 99% correct. If you run `cargo test` in the repository you can see it in one of the tests: ERROR 2018-04-27T17:10:44Z: nperf::dwarf: Handling for this CFA rule is unimplemented: Expression(Expression(EndianBuf { buf: [119, 8, 128, 0, 63, 26, 59, 42, 51, 36, 34], endian: LittleEndian })) It would be pretty nice if `gimli` could handle it automatically. (Although, again - it's rare enough that it isn't a problem for us.) 3) The `EndianBuf` does take a lifetime, which is somewhat annoying when you want to just `mmap` a file and you don't want to permanently leak it. What I did here (for now) is I've put everything into one structure (`FrameDescriptions` in `frame_descriptions.rs`), put the mmaped data in an `Arc`, wrapped everything in `mem::ManuallyDrop`, set the lifetimes to `'static` and used `mem::transmute` quite liberally. Ideally I'd be nice to have an `ArcEndianBuf` or something along those lines to use in cases like these. (Which I have thought about whipping up, but the `Reader` trait from `gimli` had quite a few methods to implement, so I decided to go for the faster/more hacky solution for now.) 4) Having a built-in abstraction over both `EhFrame` and `DebugFrame` would be nice. &gt; Maybe there are reusable bits to be pulled out of this project, that could be shared? Definitely! The major thing would probably be the `.ARM.extab`-handling code from `arm_extab.rs` which could be easily pulled out, perhaps even into `gimli`. (Since `.ARM.extab` is, basically, ARM-specific `.eh_frame`.) Another thing would be a high-level wrapper around `perf_event_open` (`perf.rs` and `perf_group.rs`) - parts of the interface which the Linux kernel exposes here are a little hairy and hard to deal with in a sane way. (More specifically it feels like the use-case of attaching to an already running process was an afterthought, and it shows.) There are also some minor things like raw `perf_event_open` bindings in `perf_sys.rs`, a `/proc/kallsyms` and `/proc/$PID/maps` parser, a simple `RangeMap` implementation (which is somewhat naive and *really* simple, but it ended up being faster than an AVL-tree based map, so I left it as-is ¯\\_(ツ)_\/¯) and some other bits and bobs. &gt; You might want to join the handful of us who hang out in #rust-debugger-tools on irc.mozilla.org :) ... I really have to start using IRC more. (: &gt; Would you be interested in pulling out the CLI specific bits from `src/main.rs` into `src/bin/nperf.rs`, and moving what is left in `src/main.rs` into `src/lib.rs`? This would be a first baby step towards making the profiler framework vision a reality. Definitely! I'd love to turn this into a general purpose library for sampling-based profiling and in general for easy out-of-process stack unwinding (which could be useful in other situations besides CPU profiling).
I liked the first post they linked to, the 100 days of rust one.
&gt; Have you tried simpleperf, it has quite a few of these features too; cross-arch, on the fly unwinding. I'm not sure if it supports mips though. I haven't! Interesting. Do you know if it supports non-Android environments? &gt; BTW how did you find the documentation for perf_event_open? I'm using it at work and find it quite lacking and buggy. I've spent a lot of time reading the kernel source to figure out how it actually works. ...yeah, I've read quite a bit of the kernel sources too. (: Whatever documentation is in `perf_event.h` is very useful, but it could be significantly improved.
https://crates.io/crates/metrohash is a good bet. &gt; I think at 24-byte key that XXHash beats FNV? I think so.
Very nice. Not sure if you can answer that, but are you using Rust for other projects internally?
Say I wanted to build an i3 clone. Would I want to use Smithay or Wayland-client for this?
I added a comment on https://github.com/rust-lang-nursery/rustup.rs/issues/1328 with some steps that you could take to try and provide some more information. Right now, rustup seems to be working for most people, so there's probably something specific to some people's network or system setups that's causing the issue. Since you could download with curl but not rustup, it would be useful to see what the difference is between how each of those behave when downloading.
It definitely runs on normal Linux, I can't remember if it's report only or record also though.
I can't give out any specifics about the projects themselves, but the languages we're using are no secret. (: The project I work in is mostly a C++ shop, which is pretty obvious if you look at our job offers and at the agenda of the [Code::Dive conference](http://codedive.pl/) which we organise annualy. (Although last year wasn't as much C++-centric and we *did* even have three Rust talks.) Currenty I don't know of any other internal Rust projects in my immediate vicinity, however Nokia is a *huge* company (102k people according to Wikipedia), so someone else somewhere is probably using Rust in some capacity.
Awesome! Are you interested in publishing the library portions of this to crates.io? I made https://github.com/anp/perf_events to read counters and have wanted to add the sampling API to it as well. Currently I don't think any comprehensive *and* safe perf_events_open wrapper has been published to the registry, so it would be awesome to have a single library that can be used by anyone who wants to do finer-grained profiling in their application.
&gt; Multiplying or dividing a power of two by a power of 2 is exact, to within the precision of the number (It's just flipping a bit in the exponent) I don't think this is true for [subnormals](https://en.wikipedia.org/wiki/Denormal_number).
I've always wanted a profiler for ARM that copes well with limited debug info, because Android phones rarely if ever ship their system libraries with sufficient debug info to do any profiling. This is great!
Just yesterday, I added some `context` to [this small tool](https://github.com/rust-fuzz/targets/blob/9254da3b63d193c1e4679aa76f92768e8073677b/cli.rs) for better errors. It's hard to hit the errors, though, "sorry" ;)
Sorry, I read `rust-gdal` and wrote `gdal-rust` :/. And I didn't realize that both crates are under the `georust` organization. I submitted a drive-by PR to `gdal-sys` a while ago and I might be wrong, but it seemed to me that `gdal` (repository vs. package naming is so confusing) is using `geo` for some its geospatial types. So if you're extracting them in a new crate, porting `gdal` to it might be a good idea.
[Failure](https://docs.rs/failure/0.1.1/failure/macro.ensure.html) Or did you mean historically? [error-chain](https://docs.rs/error-chain/0.11.0/error_chain/macro.ensure.html), I think
Neat helper! I wonder why there isn't a crate for such little neat functions...
A few months ago I made a [comment](https://www.reddit.com/r/rust/comments/7e74ia/whats_everyone_working_on_this_week_472017/dq45qg4/) about me buying the `rustref.com` and `rustreference.com` domain names. Right now I don't really have a plan for them, so I setup https://rustref.com as a way to quickly get to rust documentation without having to remember long domains like: https://rust-lang-nursery.github.io/rust-cookbook I recently finished my semester, and finally added a homepage that lists the available redirects. The main redirects I end up using the most are: std.rustref.com, cook.rustref.com, and ex.rustref.com I also recently found this [list](https://github.com/ctjhoa/rust-learning) which contains tons of useful links as well. I added a redirect for it here: learning.rustref.com The site is built with [Rocket](https://rocket.rs) and there is more info on how it works on the [github repo](https://github.com/nocduro/rustref). I really enjoyed using Rocket, having data guards let me [verify that a webhook](https://github.com/nocduro/rustref/blob/master/src/github_event.rs#L64) came from github before it even hits the handler for it. The site has Cloudflare sitting in front of it, so as long as their cache is warm, the site should load pretty fast no matter where you are. The first call for a certain redirect in each region wil be a bit slow as Cloudflare has to fetch the result from the origin server (located in US central region). This is the first website I've made that has a backend/server, so if you see anything setup wrong, let me know! Also still a bit of a noob with some rust stuff, so any feedback on the code is appreciated too.
Definitely! Although to be useful in general the `perf_event_open` bindings would have to be refactored slightly (I'm probably hardcoding a few too many things in there as that's all I've ever needed.) and the `unwrap`s removed.
I built error handling for [actix-web](https://github.com/actix/actix-web) around failure create. But actix-web is a framework, so errors have different flow direction, from users to the actix
Oh don't worry, I've had my fair share of frustration with rust 😄 the compiler really is like being told to eat your vegetables haha
That's the interesting thing about Rust. I feel like it's made me a better C programmer.
[removed]
I know, but it would be fun to implement at least some basic CSV reader, detection of missing values, normalization functions and outlier detector just to learn programming because I have never really done some bigger projects.
So, if your monitor is refreshing at 60fps, and Alacritty uses OpenGL to render to the screen, wouldn't it make sense for it to be V-Synced, which means that the frame-to-frame time is 16.6ms? If the latency is 15ms, I'm not seeing the problem. The old problem of _"I **need** my terminal emulator to refresh faster than my framerate"_ seems like a made up issue to me. If 15ms means it doesn't get the frame to your screen by the time that frame is drawn, you have to wait until the next frame. Oh my. I dunno. I'm all for performance metrics, but how long do you think it takes for each keypress to happen? Long enough that I can't imagine any human being able to distinguish between *this* "faster than my refresh rate" emulator and *this other* "faster than my refresh rate" emulator.
Well you clearly cannot read. Maybe that's the problem? ;-)
thanks, pretty new to reddit.
I really don't think that async IO is particularly important to the Rust webdev story (as someone who's been spending more and more time working in it)
I feel like fixed point calculations are probably underutilized. Basically, if fixed point numbers will pass your tests, then you should maybe just use them instead.
Rust has certainly made me a better C programmer 
In financial software I've heard that floating points are simply avoided, and rather the lowest unit of measurement is used and counted with integer types which are then converted into higher units of value as needed. I'm not 100&amp;#37; certain this is true, but certainly I have in general come to be of the mind that floating point numbers in critical contexts should be avoided and rather integer types should be used. 
The difference between 16ms and 33ms is definitely noticeable. So if your terminal introduces 15ms of latency on top of the keyboard's, OS's, and monitor's latencies, there is definitely room for real improvement. For that matter, there are situations where even 16ms of *total* latency is still too much. Mouse cursor motion, for example, never goes through the full path that text does- it bypasses everything and goes straight to the display via a hardware overlay in the GPU. Not doing so (e.g. in a game where they render the cursor themselves) makes the cursor feel sluggish. And if you've ever used a 144Hz monitor, mouse motion there is noticeably nicer than even a 60Hz hardware overlay. VR is another example- 60Hz is too slow and often leads to motion sickness. People need closer to 90Hz for head motion to actually feel right. And that's *two* 90Hz displays, so anything rendered there needs to incredibly low-latency. Obviously these are different from the "typing text in a terminal" situation, but people *do* notice this level of latency there as well- often to the point that compositing window managers are noticeably less pleasant to use than old-style stacking ones. For example: https://pavelfatin.com/typing-with-pleasure/, https://danluu.com/input-lag/.
Rust has hygienic macros, so there's no obstacle to alternate parameter passing syntaxes. But default parameters for a plain function can be very unergonomic, so Rust is taking a very sensible approach by not allowing these.
Hello....coworker. 
V-Sync in a terminal makes very little sense. The point of V-Sync is to avoid persistent and highly-visible screen tearing in video graphics that take up most of the screen...if that's not what you're dealing with, just turn it off. A frickin' *terminal* isn't going to tear in a visible way other than when you're scrolling a whole lot of output, and then the text is going to be unreadable anyway. Totally different from the gaming/multimedia scenario that the "wait for vblank" technique is intended for!
(:
&gt; The difference between 16ms and 33ms is definitely noticeable. Only on an ongoing basis. If it takes 50ms for your key to go all the way down and come back up, your brain isn't going to have an exact moment in time to connect to that keypress. It was a continuous event for a (mentally) long period of time. Mouse cursor motion is something that is happening on an ongoing basis, and it is immensely noticeable, because it should be visually continuous.
It sounds like your a beginner? It's pretty common for beginners to be overly ambitious without realizing it. You might want to keep that in mind. I would recommend starting with the simplest thing and seeing how that goes. If it's too simple and easy, then hey you finish it easily and try something else. If it ends up being too ambitious, make a note of that and start something else that is less ambitious. Maybe pick up a text book (Algorithms for Data Science, perhaps?) and start coding up things in the book. See if you can assemble the algorithms/data structures to solve a simple problem. Maybe you can get some traffic data and estimate how crowded the roads are? I dunno, just throwing that out there. My final bit of advice would be, don't start with the plan of re-implementing scikit or pandas, but instead focus on implementing a particular analysis and then implement what you need for that analysis. Then pick an analysis that either builds on the previous on or requires some new stuff, implement what you need. Then just repeat that process for a while. Good luck!
The amount of CPU that's used in repainting a terminal is absolutely trivial - it's not even a rounding error. If you can run a windowed DOS box in an old 80286 or 80386 PC, or a graphical "shell" in an old MC68K-powered box, you can run a terminal without caring about the amount of blitting it does. If you're concerned about hogging a little more CPU when scrolling large amounts of text, you can implement the tricks some terminals use to discard some repainting in that very scenario, and the lack of vsync will still result in improved responsiveness in the typical case.
I don't do that everywhere, however this seemed like an appropriate use of it as it's intended exclusively for "hard coded" values. If you're doing platform abstraction this is the work the compiler has to go to anyways. It collapses down to a single constant, I explicitly designed it that way. If I don't use always then I can't guarantee it's zero cost. I just added a new more convenient syntax for existing features.
As a learning example, I'm writing a simple rust util, that will look up my network's local bastion server - then build a command line up to then execute the full ssh command. But I seem to be getting hung up in the argument processing. https://gist.github.com/drusellers/a9cc5feaadc5542fcbe1eacd848c8956 But I cannot for the life of me get it to work. ``` "ssh" "-o" "ProxyCommand=\'ssh -i &lt;key file&gt; -W &lt;target ip&gt;:22 ubuntu@&lt;bastion&gt;\'" "-i" "&lt;key file&gt;" "ubuntu@&lt;target ip&gt;" ``` With the error ``` zsh:1: no such file or directory: ssh -i &lt;key file&gt; -W &lt;target ip&gt;:22 ubuntu@&lt;bastion&gt; ``` I'm wondering if its the single ticks that are screwing this up some how. Thank you, -d
Latencies below 16.6ms (or ever below a few multiples of that) are best thought of as probabilities: if I hit a key at some random time, what's the probability that it appears on the immediate next frame? With a latency of 15ms, that probability is low; with a latency of 2ms the probability is pretty high. It's also worth noting that your keyboard takes some time to poll the available keys, and the USB controller takes some time to poll the keyboard, so even a terminal with 2ms latency (between receiving a GUI key event, encoding it, sending it to the kernel, receiving the echo, decoding it, painting it to the screen) still has multiple frames of latency. In the heyday of Quake 1 over dialup internet, people could play the game pretty well with 250ms of latency, provided they adjusted their expectations and learned to aim ahead of their target. It took a lot of getting used to, but people did it because that game was designed to provide a test of skill, and overcoming lag was a kind of skill even if it wasn't one the game's designers originally intended. Meanwhile, typing into a terminal is not supposed to be a test of skill, brain-energy spent compensating for latency is not rewarded, and so our threshold for acceptable lag ought to be a lot lower.
/r/play-rust
[removed]
Out of curiosity, do you feel like the focus on asynchronous IO this year is a mistake? What do you consider more important?
[removed]
Why does this matter in debug mode? Not even addition is a "zero-cost" abstraction when not making a release build since it enables overflow checks. And in release mode, just let the compiler do what a compiler does. If it's unable to make sane inlining decision for code that's this simple it's a rustc/LLVM bug anyways. A pretty big one actually, since this is a trivial branch.
The first sentence in Alacritty's readme is: &gt; Alacritty is the fastest terminal emulator in existence so it's fair to criticise it for not being true. Also, depending on the source of the latency, reducing it might be very relevant, e.g. if it's 12ms of CPU time per frame, then just the terminal itself is sucking 75% of a CPU; cutting that to, say, 4ms gives the actual interesting programs half a CPU extra to use.
&gt; modern GPUs differ widly from what was used back then. Not in a way that makes a difference here - we're talking terminals, not 3D scene rendering. You still get a framebuffer/window surface to paint on, which is the same thing that was used back then. Or maybe you can use the GPU's texture support and general compute capabilities to get a modern equivalent of the old "text" modes - IIRC, the Servo project was looking into rendering text via the GPU, but I'm not sure that Alacritty is doing anything like that? &gt; Also, C-states are a thing now, and the more time you can spend inside one, the less energy you waste. Might make sense, except that 15ms isn't enough time to enter a deep C-state and have that be a worthwhile choice. So there is indeed an inherent tradeoff between low latency and better battery life, but if you care about the difference between 2ms and 15ms (which is when vsync enters the picture), it's not like that handful of ms in latency are going to make any difference wrt. power.
&gt; Only on an ongoing basis. The faster you type, the closer you get to "ongoing basis." :) There's a reason both those articles were written- their authors *did* notice the difference, got frustrated by it, and went to figure out what was going on. &gt; If you see discrete frames of the mouse cursor motion, that's easily visible That's not what makes the mouse feel sluggish. Even a 144Hz mouse render rate can feel sluggish if the *latency* is too high- that's why you have to bypass the compositor and use hardware overlays.
Considering that's the foundation for Futures and that's what Hyper relies on, I think async/await is an important feature for webdev, even if indirectly.
&gt; The faster you type, the closer you get to "ongoing basis." Not really. The time between when your finger lets the the last key slide past the actuator and when the last character appears on the screen is the same as it was for the first character. Within a few dozen milliseconds, your brain still has no way to connect the discrete event of the character appearing on the screen to the continuous motion of the key as it goes down and comes back up. Once the latency is high enough that your brain can separate the keypress from the character appearing on the screen, that's when it's disconcerting. But, that's not reasonable here. Even if you could press a single key 20 times per second, that means it's taking 50ms per cycle, which is 3x the latency we're discussing, therefore imperceptible. &gt; There's a reason both those articles were written- their authors did notice the difference, got frustrated by it, and went to figure out what was going on. Lots of people claim to hear the difference in lossless audio versus high quality mp3s, but the evidence just doesn't back it up. Only a very small percentage of people can tell the difference. But, this is all a completely pointless discussion, so I'm done here. All this makes me want to do is write a program which allows you to type, and it will perform a double-blind latency typing test for you. Given two latency targets, you can start typing and it will randomly choose one of the targets, slowing itself down as much as needed to hit the target. It will then ask you which mode it was using, tell you whether you were right or not, and you can repeat it as many times as you want. With latency targets of 5ms and 50ms, I really doubt anyone would be able to pass the test consistently on a mechanical keyboard. A MacBook with the ultra-short-travel butterfly switches might make a real difference in the perceived latency.
Note, I'd appreciate some scrutiny on the soundness of the implementation.
Did you see those measurements of latency with an iPhone recording video at 1000Hz or something? That is actual scientific evidence for latency differences if you need it. I used to keep an old thinkpad with a hardware text mode as a terminal because it just felt so fast, even with the network latency. This is not imaginary. All the little delays really do add up to something measurable.
Can you expand on why you think it is important to web dev for hyper to be async?
&gt; A MacBook with the ultra-short-travel butterfly switches might make a real difference in the perceived latency. Only in a clean room environment where all particulate matter is avoided. The tiniest grain of dust under one of those "ultra-short-travel" keys will render it totally non-responsive, which amounts to indefinitely-high latency.
The name of the rustfmt component is '-preview' rustup component add rustfmt-preview As the error says, you have to install racer using nightly: cargo +nightly install racer
I have some questions about "choose carefully" - I don't know if people who don't know much about these sorts of systems would be able to (well, at least I wouldn't know if I was being careful or reckless) Could you offer advice about which types should be the default and possibly provide some use cases for moving away from the default? When would a use case potentially benefit from a type that might actually be a mistake here? Is it obvious when an error occurs if the wrong choice is made?
I was wondering why does `A` need to be sized here? struct Foo&lt;T&gt; { t: Box&lt;T&gt; } trait A {} fn f(arg: Foo&lt;A&gt;) -&gt; () {} According to my intuition, the size of `A` shouldn't matter to `f` here because `Foo&lt;A&gt;` only contains a pointer to an `A`. However rustc complains with: error[E0277]: the trait bound `A + 'static: std::marker::Sized` is not satisfied --&gt; src/main.rs:29:1 | 29 | fn f(arg: Foo&lt;A&gt;) -&gt; () {} | ^^^^^^^^^^^^^^^^^^^^^^^^^^ `A + 'static` does not have a constant size known at compile-time | = help: the trait `std::marker::Sized` is not implemented for `A + 'static` note: required by `Foo` --&gt; src/main.rs:23:1 | 23 | struct Foo&lt;T&gt; { | ^^^^^^^^^^^^^
Probably a great idea!
 &gt; rustup component add rustfmt-preview Thanks, that seems to have worked, although I don't understand what it has done. This is the output of `ls -l ~/.cargo.bin` both before and after that command. &gt; tile:~ ctesibius $ ls -l .cargo/bin &gt; total 108720 &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 cargo &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 cargo-fmt &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rls &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rust-gdb &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rust-lldb &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rustc &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rustdoc &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rustfmt &gt; -rwxr-xr-x 9 ctesibius staff 6183760 28 Apr 02:38 rustup So still a file with nine links to it. Before the change, executing that file under the name `rustfmt` I get the error &gt; error: toolchain 'stable-x86_64-unknown-linux-gnu' does not have the binary rustfmt - which isn't true! But now after running that command, apparently the same multiply-linked file *does* work as `rustfmt`. Really I'm trying to understand the logic behind why the default install has a link with the name `rustfmt` which doesn't work, rather than not having an executable for rustfmt. I don't have an error message saying that I should install racer using nightly, but I will try that. Now as to the compiler error messages: what is going wrong? I am using stable, so why is code for racer and rustfmt-nightly failing to compile cleanly? And why am I seeing different error messages on the the two different platforms?
That is very interesting article. BTW couldn’t vtable be passed by value into a function? AFAIU, it could be cheaper (because vtable won’t be read from linear memory with bound checks), especially if link-time optimizer could drop unused vtable entries from being passed to the function. 
Those 9 links to the same file are just a proxy that rustup uses to resolve the correct toolchain and delegate. That keeps it from having to play any $PATH or symlink games to invoke the correct executable. I'm on mobile now so I can't check for sure, but IIRC, you should have a .rustup directory that has all the toolchains installed. The command you ran that fixed things changed that directory, not .cargo.
Ok, thanks - I understand what you're saying.
Well, 1920x1080 (or more) versus 640x480, 24-bit versus 4-bit, anti-aliased text versus bitmap, unicode fonts versus 128 or 256-char fonts. So it's not really the same. Also perhaps double-buffering or frame-copying versus hitting the hardware. Or even frame buffers instead of hardware text modes. It's all been going backwards for speed of text handling really. There are some FPGA VGA text-mode solutions out there, though.
I'd say, if you're unsure, you're probably better off using a plain `std::sync::Mutex` or `parking_lot::Mutex`. If you're still interested in using this crate, and are unsure, then `Box` would be the safe choice. To give a little context on why I wrote this crate: - I needed Mutex types using very specific platform mutex primitives in different cases (hint: all the ones provided by the crate, except parking_lot, which is just free bonus). - I wanted to be able to poke at data that belongs to C++ code, while still complying to its locking requirements. Those are very specific needs where you need to be very careful about what you do. Outside this niche, I'm not sure I'd advise using this crate. Maybe I should make that clearer in the README. Or maybe there are objective criteria that can be listed to help users make an informed choice. I'm not sure.
See http://isitsnappy.com/ -- people with iPhones can actually measure it! I know for certain that nothing feels like a hardware text mode, and I really do miss that.
Please correct me if I'm wrong. My understanding is that futures will be in some form in the standard library and that they will use async/await. The other part is that `hyper` uses futures on some trait implementations, like `Service`. Am I getting this wrong?
My question was why you think that is important for web development. 
I'm using Rust for small tasks at the moment, like logging and simple file parsing, but the web server I'm working on isn't in it because I still have a hard time programming a web server in Rust with hyper or another web framework that builds on stable. The web server logic is where most of my time goes right new. I was under the impression that futures would depend on async/await, and that futures are used throughout hyper, which is what I want to end up using. But as I wrote on another thread here, I'm asking where my understanding is wrong so I can correct it.
Because I am waiting for futures and libs that depend on it, such as hyper, to become a little more stable so I can read their docs, source, and use them. My last attempt was with futures 0.1, then 0.2 came out along with a blog article that said 0.3 was going to be released right after, possibly breaking API compatibility. That's when I decided to wait for those things to become more stable before I use them.
Unless they're actively updated, the `-preview` variants are from before those tools were shipped with the standard Rust distributions, when they wanted people to have an easy way to try them out.
One thing I'll add to the good answers here is that if your access patterns aren't random, you'll probably want some sort of up-front cache of the data so that most lookups hit the cache, which will be much friendlier to the TLB and cpu cache. If most hits end up in the cache and/or prefetching can be done during idle, the performance of the backing store is less important.
Well, I think Alacritty has demonstrated that good results are possible even with these innovations. 15ms latency due to wait for vblank is not really that bad, in fact it's a lot better than many of the alternatives. But it's natural to ask whether we might do even better-- especially since this might help us compensate for typical extra latency due to cheapo keyboards and displays, while still providing an enjoyable overall UX. This seems like a worthwhile goal to me.
&gt; Also, it was pointed out to me that yesterday, April 26, is the sixth “birthday” of the borrow check – it’s fun to look at [my commit from that time](https://github.com/rust-lang/rust/commit/50a3dd40ae8ae6494e55d5cfc29eafdb4172af52), gives a good picture of what Rust was like then. Wow, that is bizarre. I didn't pay much attention to Rust before 1.0, I hardly recognize it in this commit!
Interesting idea. There’s a number of Tier 2 platforms missing. Including all the BSDs. 
I was just going through your code until i found this one. I've not been writing rust since a long time but I’ve kept myself updated through this subreddit. Can you just explain what the \`\` pub\(crate\)\` in the following code does? `pub(crate) fn unknown_title&lt;T: AsRef&lt;str&gt;&gt;(unk: T) -&gt; Error {` `Error::from(ErrorKind::UnknownTitle(unk.as_ref().to_string()))` `}`
It depends somewhat on what your web server is doing, but in many cases single-threaded + async is what gives better performance (compared to spawning a new thread for every request). This is especially true if the web server is not doing much CPU intensive processing by itself but spends most of the time of a request waiting, e g for the database to respond. 
This is very neat, especially how easy it was to incorporate the idea that "borrows end at the last point they're used". The idea of start- vs mid-points wasn't returned to. Where's the difference needed?
**C10k problem** The C10k problem is the problem of optimising network sockets to handle a large number of clients at the same time. The name C10k is a numeronym for concurrently handling ten thousand connections. Note that concurrent connections are not the same as requests per second, though they are similar: handling many requests per second requires high throughput (processing them quickly), while high number of concurrent connections requires efficient scheduling of connections. In other words, handling many requests per second is concerned with the speed of handling requests, whereas a system capable of handling a high number of concurrent connections does not necessarily have to be a fast system, only one where each request will deterministically return a response within a (not necessarily fixed) finite amount of time. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
If it's stack like on both ends, what's the advantage over only supporting allocations from one end? Can I free out of order? Is it that if I happen to free the most recent it pops off the state but otherwise uses a free list?
One advantage might be to reduce fragmentation within the scratchpad itself. Put large allocations on one end and smaller allocations on the other.
It's only zero-cost if the compiler manages to prove that evaluation the inputs is side effect free.
Thanks :)
Threads are never free, either in terms of cycles or complexity.
How accurate is your imdb-rename project? I've been working on a similar project that tries to parse the filenames to extract title/year/tv show/episode/season information and look them up on themoviedb.org and it's somewhat successful, but far from perfect.
Yes you should never use floating point for finance. The accounting rules you are using will specify how to handle rounding, and you should use a type that matches those rules
I was under the impression that Alacritty's claims were about throughput, not latency. That being said, there isn't any hard benchmarks to back this up (https://github.com/jwilm/alacritty/issues/289), although the posted benchmarks that Alacritty does well in do seem to be throughput focused.
I don't understand your definition on "compiled languages code works today and tomorrow" there are lots of reasons as to why code working right now might not work tomorrow. What does being a scripting or compiled make a difference when comparing them like this?
What are the keys in both cases? How rare is rare insertion? Does the initially loaded dataset change often? 1. Either some (packed/compact) trie. Alternatively hashmap as a starting point, with a perfect hash in case the loaded dataset changes very rarely. Depending on the what the key is you can add a sharding in front of it. If you have lots of invalid requests, then a cuckoo/bloom filter may help as your first layer. The bigger the objects, the better idea is to store them outside of the search data-structure itself. 2. Pretty much as 1, except leaning more towards hashmaps. 2.1. *Go supports it fine `map[[20]byte]*something`* As usual, when you are looking for the fastest data structure, the devil is in the details. The best way to get the best recommendations in these cases is to build a benchmark with realistic datasets and realistic access patterns. That way people can immediately see what you are trying to optimize. Since you are doing performance optimizations anyways, then it will serve as your guide what to choose anyways.
Another observation, Rust's feeling of, "it compiled so it must be correct" is overly optimistic of the compiler, which acts as a syntax, but in Rust's case , checking it's types and the rules of mutability. A scripting language that would implement both of those would be able to offer those too, only coming short on the usual things they usually are, memory usage, speed, must have a runtime, etc.
You're totally right, I'm also waiting for the `async`/`await` work to get merged into the language and standard library! I was using `#[async]` from `futures-await` a little bit, but now that `async fn` is so close, I'm just waiting.
&gt; But default parameters for a plain function can be very unergonomic, I find them ergonomic, so it makes sense to me why the machine learning frameworks use them to streamline their interfaces. Rust macros are great but they should be for more advanced use cases rather than basic default params..
Lol its birthday is the same and mine. 
Fighting with the borrow checker right now. I understand *why* I get a `source does not live long enough` error, but am confused about how I'd fix it. After source is moved into the struct in `Obj::new`, how can `chars` refer to it?? Here's my code: #![allow(dead_code, unused_variables, unused_mut)] use std::str::Chars; struct Obj&lt;'a&gt; { source: String, chars: Chars&lt;'a&gt; } impl&lt;'a&gt; Obj&lt;'a&gt; { fn new(source: String) -&gt; Obj&lt;'a&gt; { Obj { source, chars: source.chars() } } } fn main() { let mut scanner = Obj::new(String::from("hello, world!")); } And the errors: error[E0597]: `source` does not live long enough --&gt; src/main.rs:12:30 | 12 | Obj { source, chars: source.chars() } | ^^^^^^ borrowed value does not live long enough 13 | } | - borrowed value only lives until here | note: borrowed value must be valid for the lifetime 'a as defined on the impl at 10:1... --&gt; src/main.rs:10:1 | 10 | impl&lt;'a&gt; Obj&lt;'a&gt; { | ^^^^^^^^^^^^^^^^ error[E0382]: use of moved value: `source` --&gt; src/main.rs:12:30 | 12 | Obj { source, chars: source.chars() } | ------ ^^^^^^ value used here after move | | | value moved here | = note: move occurs because `source` has type `std::string::String`, which does not implement the `Copy` trait Thanks!
&gt;We can also note that Vim using GTK3 is slower than its GTK2 counterpart by an order of magnitude. It might therefore be possible that the GTK3 framework introduces extra latency, as we can also observe other that GTK3-based terminals (Terminator, Xfce4 Terminal, and GNOME Terminal, for example) have higher latency. The gift that keeps on giving.
Tearing can actually matter in a terminal. I work with raspberry pi's a lot, and when I write programs with a lot of logging, tears while the text scrolls by are VERY noticeable and annoying. It's not only displaying wrong, but it also messes with the "movement" \- my eye will overshoot / undershoot the location of the line I'm trying to follow. In an embedded environment, where logging everything to disk isn't always an option, that can become a real problem. I agree that it generally doesn't matter. But it should be turned on by a terminal whenever it does fast scrolling.
Hi, [this](https://play.rust-lang.org/?gist=9ad175fbc95f063e3be4cb49d9544120&amp;version=stable&amp;mode=debug) fixes your problem if taking a `source` by reference is acceptable. When you do `source.chars()` in your code, the `Chars` iterator only lives until the end of the `new` function.
I work on a bit higher level stuff myself, but one friend works at a company producing control software for railways. He was pretty interested about Rust, but the main problem was really the rigorous standardization (which is, of course, a good thing from safety PoV) that mandated the use of C. Can someone who knows a little more about the subject shed some light on what kind of a process it would be to get a new language covered for by the standards like EN 50128?
Great idea. Probably useful for other configuration too. Any reason not to use [this construction](https://doc.rust-lang.org/std/macro.cfg.html)?
I think the issue is that while Rust is safe, so is correct C that has 10 years of field testing and reliability behind it. It’s going to be a while before we see Rust replacing C for safety critical systems. Japaric’s embedded work like RTFM is really great and a serious competitor to ChibiOS and RTOS, but basic stuff like being a new language and needing to use nightly is going to prevent widespread industry use.
I'm surprised the author doesn't touch on Ada at all, the prototypical safety-critical language used in all sorts of aeronautical applications. I do agree with the premise of the article though: C, even with static analysis and menial review will never be as safe as a language that is built from the ground-up for safety. Do I think Rust is appropriate for safety critical applications? Not right now. Maybe in 10-20 years time when the language has had time to stabilize. There's a wealth of knowledge and investment in safe C, so whatever replaces it will need to be pretty solid.
&gt; isn't going to tear in a visible way other than when you're scrolling a whole lot of output Isn't that bad enough? It looks sloppy.
Any possibility of getting Nokia on the Friends of Rust page? :p https://www.rust-lang.org/en-US/friends.html
Perhaps when someone has written a Rust language standard and it has gone through a couple of revisions will it be ready to be certified for safety critical systems.
It would be nice if there was some kind of hierarchy. Also an alternative form which makes sure you handle every case, or every case within a subset, perhaps?
&gt; IIRC, the Servo project was looking into rendering text via the GPU, but I'm not sure Alacritty is doing anything like that? Alacritty renders characters on CPU, uploads them to a texture, and draws the whole screen by copying these characters around on GPU. Servo/WebRender is probably doing the same right now. They are eventually going to [draw the characters on GPU](https://github.com/pcwalton/pathfinder) but that won't make a difference when you're using the same characters that were rendered before.
The sel4 microkernel is written in C, but it has been mathematically proven as correct (secure). The proof is verified at the C source level, and for some architectures, the machine code level. If C code has such a proof, then the program should have zero security holes, which is even better than rust sometimes. https://sel4.systems
You can inspect the ASM outputted in release mode: it is identical to straight up having the target type.
This one is quicker to type and more elegant when you're simply setting conditional values.
I really miss the terser `match` syntax without the `=&gt;`, even tho it's ambiguous :(
I didn't say that they were
I think en50128 allows for the use of other languages as long as it is justified. There is a table which lists languages and their recommendedness for each SIL level, but there is a note underneath saying that you can use languages not in the table as long as it complies with the "suitable programming languages" section. The only language explicitly "not recomended" for a particular safety level is BASIC - you can theoretically use even assembly language at the highest SIL level.
I wouldn't call it a mistake, but I don't think it'll be the silver bullet people make it out to be. Much more important is having a refined framework, and better tooling around error tracking, performance monitoring, etc. Right now you have to build all of these things yourself and it sucks.
It's sad that people treat Rust just as a safer C... It has much more things to offer. 
I’d like to note that there’s also no official release of alacrity at this time, which does make evaluating the claims of something not even to its first release a bit weird.
&gt; The only language explicitly "not recomended" for a particular safety level is BASIC That's a good start, but these days we should be adding PHP to that list. And maybe let's think about adding ECMAScript too. (Don't worry, you can still use Hack and TypeScript!) Do they take pull requests?
What'd be the advantage of using C over Rust in that case? A Rust microkernel could simply also receive such a proof. 
The availability of really high level abstractions does not receive the credit it should. It's not only safer as C, but also much easier! 
I'm not sure, I just wanted to highlight the part of the article that the title pointed out. I am a Windows user and so haven't used it myself yet. Can't wait until I can!
Create a global variable in JS and assign it to webAsembly inside the closure (that's what the `webAssembly =&gt; { const { rust_function_name } = webAssembly.instance.exports; }` thing is) but note that even if you have a global variable you can only do things with it once the closure ran, so make sure to start whatever you need to start from inside the closure.
Language support is already there. You’re not using a tool that changes weekly from GitHub.
C compiles to everything.
An even bigger push would be for the micro controller/microprocessor designers to accept that there should be another language to write compilers for. Considering it took Microchip until ~2015 to add full C++11 functionality into their XC++ compiler, I think this will he hard. Plus many vendors that make products for aerospace applications, Cobham Gaisler (Leon), BAE Systems (RAD750), etc, don’t keep their tools 100% up-to-date. They just make sure the tools 100% meet the standards they are supposed to for every revision.
Rust compiles to a lot too! Its list of targets is not as exhaustive as C (yet), but cross platform development sure is a lot easier in it! 
How do you mean? The Rust compiler is very stable and there have not yet been any breaking changes. Furthermore, a new version is released every 6 weeks. 
https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines
 &gt;The idea of start- vs mid-points wasn't returned to. Where's the difference needed? This was my question too.
You're not limited to only allocating from one end at a time. If you set a marker on one end, you can keep allocating from it while setting and releasing markers and making allocations on the other end. I admittedly wrote most of the documentation before I put the dual-stack support in and didn't proofread it too well before pushing this release, so I'll try to clarify that. You can kinda think of it as using a free list if you release markers out-of-order. Internally, markers are only tracked by their last offset within the allocation buffer. If a marker isn't at the end of the stack when it's dropped, I just replace its offset with a `usize::MAX` value. When a marker at the end of the stack is released, it will also check for and pop any `usize::MAX` offsets off the end as well to reclaim the memory that was used by those markers.
Given that `mrustc` compiles Rust -&gt; C, doesn't this technically allow Rust to compile to all those targets as well?
You can still do so. The stacks are managed independently, so dropping a marker from one end will still release its memory regardless of what state the other end is at. I'll try to fix that distinction in the documentation.
If you haven’t yet, this article is a good discussion on how Rust progressed in the past year (from Sept 2017). https://blog.rust-lang.org/2017/09/05/Rust-2017-Survey-Results.html The biggest argument I would have (noting that I’m a proponent for Rust at my company) is out of 5300 people who took the survey, 7.5% had broken code due to an update. I don’t think that number would scale linearly, but the number would be a lot higher if aerospace, automotive, and other safety-critical industries jumped on Rust immediately for their new codebases. That isn’t very good. C is backwards compatible back to the 99 standard excluding some new C11 stuff like multi-threading support and static assertions. Most things that aren’t even used at my company (we work aerospace embedded). I had to push to get a C++11 compiler on a _Linux_ box.
I tried what I think you're aiming at: &gt;var wasmExports; &gt;function importWASM() { console.log('Inside importWASM()'); fetch('worthItFunctions.wasm') .then(response =&gt; response.arrayBuffer()) .then(bytes =&gt; WebAssembly.instantiate(bytes, {})) .then(webAssembly =&gt; { # wasmExports = webAssembly.instance.exports; }).catch(err=&gt;console.log(err)); } &gt;importWASM() But if I try to define a constant globally with it like: &gt;const { rust_function_name } = wasmExports; It complains that `wasmExports` is not defined.
Super naive question but what about UB? How does a mathematical proof interact with UB.
I wrote a Rust application for my company because C++17 compilers still have shit filesystem support. ‘std::fs’ is fantastic, especially when coupled with crates like ‘futures-fs’ and ‘notify’.
It all depends on _when_ it happens. The callback futures you're using to instantiate the wasm module are _asynchronous_. This means that after evaluating `importWASM()`, no^1 work has been done. If you then try to use `wasmExports` on the next line, you'll rightfully get an error, as it hasn't been assigned to yet. Put a log statement next to where you assign it and you'll see this happen. You've got a few options. The simplest is to embrace the callback and call a function to do your work from inside the callback. function main() { fetch('it.wasm') .then(r =&gt; r.arrayBuffer()) .then(b =&gt; WebAssembly.instantiate(b, {}) .then(doWork) .catch(err =&gt; console.err(err)) } function doWork(wasm) { const { rs_fn } = wasm.instance.exports rs_fn() } main() Your second option is to use async/await: async function main() { const r = await fetch('it.wasm') const b = await r.arrayBuffer() const wasm = await WebAssembly.instantiate(b, {}) const { rs_fn } = wasm.instance.exports } and call that from anywhere that allows async functions to be called. The last option is the cleanest but the most difficult to set up (and I've never actually done it): use a standard ES6 module import. With proper module support and/or a good transpiler (I _think_ Babel can do this), you should just be able to import { rust_fn } from 'it.wasm' and it should handle the asynchronous loading for you.
Not an expert either but isn't the point of mathematical proof to avoid all UB? 
Well, what is UB is well defined, and one of the properties that they've proved is that they won't hit UB, I assume.
Rust is a heck of a lot more complex than C - it's possible someone would be able to do it with the MIR, tho.
It's more complex for people writing the compiler, that's for sure, but it's a lot less complex for people using the language. One of Rust's main selling points, which it does not get enough credit for, is high level abstractions. 
You can just wrap everything in a result to pass it in, then evaluate it in a match?
I mean an option, not a result
Do you have an example handy? I’m still a bit lost, sorry :(
Otherwise yes your solution with generics works
While certainly true, the same applies to C. You can also just stick at a stable Rust version for a decade, and then update once. There would also be less breakage that way. That 7.5% number surprised me though. I didn't know anyone had any trouble with it, I almost exclusively work on nightly. 
I think Rust would need to be formally specified first. 
This I can get behind. 
Thank you! Because it is really hard to read the current page (doc.rust-lang.org) to find std/docbook/reference links. Especially std - I really wouldn't expect a link behind the small text "extensive API documentation". What I would expect - it is links behind the sections (e.g 2.1 The Standard Library). So I just bookmarked all links from there. But now my problem is solved. P.S. could you add some bottom padding to the webpage? On mobile opera the last link is near the end of display, it's hard to tap. 
Trying to run a script written a couple of years prior on a new system (or even the same system if it's being actively used) isn't a sure thing due to whatever dependencies are needed and how the system is configured. A binary is less likely to give that issue, though trying to rebuild it may. That's my perspective at least.
Yes actually. You can wrap it in an enum, and pass in the enum variant, that way you only have 1 function.
Yes actually. You can wrap it in an enum, and pass in the enum variant, that way you only have 1 function.
Brilliant, thanks! :)
Thanks! :)
I’ll look into it, thanks! :)
No. System Z and ADA. Maybe rust in the future.
This is amazing!
You can pass a trait object via Box&lt;IntoPrimitive&gt;. That will capture what you want.
&gt; C is backwards compatible back to the 99 standard excluding some new C11 stuff like multi-threading support and static assertions. This feels like a bit of an unfair comparison, since 1999 is so long after the initial development of C, and it has radically changed between that version and its very earliest releases. Rust isn't in the "changes weekly" stages of development anymore, but it's also not in the "stable since time immemorial" stage that C is/was. A comparison that took into account how much time the language had to evolve into its "stable" form would be saying that Rust was backwards compatible to its 2040 standard. I imagine that BC-breaking changes would be a lot rarer 22 years from now. I'm also in embedded aerospace, and I think that Rust isn't suitable for our work yet, but I also don't think it will be that long (certainly in comparison to the lifetime of our projects) before it is. 
Presumably UB must not be allowed to happen otherwise you don't have a valid profo
We just need a system programming language to do the job. In seL4’s case, behaviours are specified and verified by Isabelle, which is an expressive system for formal verification. They chose C. It might be because there were existing works in C related to this topic (e.g. CompCert), or simply that C was the de facto standard and Rust at that time was still in early development. On the other hand, Rust wouldn’t offer much advantage either, given that the safeness enforced by its type system can also be achieved with other verification tools, while Rust itself is not expressive enough for specifications required for an operating system.
I didn’t say operating systems cannot be written in Rust. I just said that Rust’s safeness guarantees are still way weaker than the requirements for formal verifications.
I forgot to add that my project has a larger scope than renaming. It was meant to be similar to the beets project. It would keep a library of the files and episodes and even fingerprint the files so that a downloads folder can be imported over and over again and it only imports the new content. The database also supports multiple files for a single movie, sometimes I have a copy of a movie in French and one in English and I want to keep both.
You said you just needed a system programming language to do the job, and Rust wouldn't be able to because it's not expressive enough. 
You said the cost was insignificant. Adding threading to something that isn't threaded is never insignificant in cost. Not even in rust. That's one of the reasons serverside JS exists because a really good async IO model is really powerful. 
Oh I thought you were talking about the end result. Then, yes, I don't think there's any reason to balance for one or the other, except maybe that it moves the optimization to preprocessing.
No... Concatenated identifiers are the bane of anyone trying to find definitions and usages of identifiers by search. I know, there are good reasons for wanting this, and good IDE support can help, but good IDE support can be quite tough and search is such a simple and universal tool. I've just had enough cases of working with macro systems or metaprogramming systems with concatenated identifiers (object systems in Scheme, the C preprocessor, Ruby's `method_missing`) and found that it makes it a lot harder to explore unfamiliar parts of the code. Anyhow, congrats on this, I do appreciate some good macro hackery, but I hope this gets used very judiciously.
Ah I see neat! Yeah all I really care about is having reasonably named files. I don't have _that_ much media, so I can handle special cases pretty easily and don't mind if automation fails once in a while. But yeah, it does seems like you should be able to use imdb-index instead of themoviedb!
Ruby and Python disagree
Ruby and Python are orders of magnitude slower for writing webservers in many cases. One of the reasons for that is effective use of async IO to turn an IO bound application into a CPU bound one. If Rust wants to be successful in the webserver space, async is a path it needs to pursue. Have a look at the benchmarks for sync rust webframeworks vs async.
You have to give people a compelling reason to switch. Rust offers correctness right now, it would be nice to also offer very high speed. Of course, what you consider fast depends a lot on what you work on. If you're saying async io isn't needed to write a blog, then yeah, I'd agree with you. I think it's being developed so we have a solution for very high throughput situations, or one where a large number of concurrent connections is necessary.
Awesome! I've been trying on and off to achieve something similar for some time, buy my macro-fu has never quite been up to the task. It'll be really useful for being able to ergonomically define functions for things like [jni](https://github.com/prevoty/jni-rs) exports which have to be named like `Java_com_path_to_some_Class_methodName`. Is there any chance that we'll ever get first-class support for concatenating identifiers that doesn't rely on macro-in-macro hackery? As I understand it, the biggest obstacle today is that almost everywhere it would be useful, macro invocations are not allowed by the parser.
This is just wrong. I use `std::fs` on GCC 7.3 and Clang 5 and it works great.
I'm pretty sure he wants generics, not a trait object.
I tend to not use boost in embedded applications because of code bloat.
This is a very naive question (I know next to nothing about theorem proving software), but how can we be completely confident in a proof that has been ostensibly verified by software given that the theorem-proving software itself could be subject to bugs? And furthermore how can we be certain that the "correct" things are being proven? Also, there are many cases of mathematical proofs that have been later disproved due to subtle errors in construction - are proofs constructed for consumption by theorem proving software not subject to these same subtle errors?
I don't know, depending on SIL level there's something to be said for using a language with mature compilers, libraries and toolchains. It's not just your code that's got to be but free. And yes, compilers *do* have bugs.
I disagree. You have to resort to C to do anything meaningful with files other than copying, or removing them. Then, unless you have GCC 8 nightly releases, you can’t just include &lt;filesystem&gt; you have to use &lt;experimental/filesystem&gt; which doesn’t produce portable code. I write software on Linux and test it on Linux via functional tests and unit tests. Then I flash it to embedded platforms. The biggest problem with this is that many compilers implement experimental/* differently if they do at all.
Kind of diverging from the main topic, but I suspect some kind of bindgen using jni's RegisterNatives work around the Java_long_name_noise.
You can mathematically deal with UB in these types of proofs by either (1) writing your programs in a restricted subset of the language to exclude the possibility of undefined behaviour or (2) proving mathematically there are no statements with undefined behaviour through, e.g., static or dynamic analysis. Also, note that if there is a statement without a deterministic outcome (due to UB our interaction with the environment, etc.) you can consider modelling the semantics of this statement with a nondeterministic choice between all possible outcomes. You can still proof properties of software in the presence of nondeterminism. Note that 'safety criticalness' is a sliding scale where depending on the application various international standards place increasing restrictions on how you should go about designing and implementing your software. In reality having UB in a safety critical system would be a no-no and should be picked up as part of the software development process.
There's probably a hell of a lot more research that's gone into formally verifying C programs at this point.
I agree. Although you could consider dealing with UB mathematically I think it's a safe assumption that if you are in a position where mathematical proofs are part of your processes you'd also go out your way to avoid UB in the first place.
If, for some reason, you have an UB in your code but it works fine at the moment, you better not upgrade your C compiler because it could take advantage of this UB in the future and start breaking what used to work. For that very reason, a friend of mine in embedded is was working with MSVC 6.0 (yes, the one from 1998) in 2014 .
Does rust have its semantics formally (mathematically) defined somewhere? Do these semantics play nice with current proof techniques? Note: Am genuinely curious, not being obtuse.
&gt; which is the same thing that was used back then No. Typically, the good ol' 80×25 text mode on PCs used hardware text rendering. You only had a memory space to fill with ASCII chars and their attributes, everything else was done by the MCGA/CGA/VGA/... graphics adapter. Though on some of them you could fiddle with the builtin fonts to edit characters rendering.
It does not! There is a Rust reference, but it's neither a mathematical definition neither complete. This is indeed a real deal breaker, quite a few people were right to point out this Achilles' heel! 
Maybe, though that's [not currently supported](https://github.com/prevoty/jni-rs/issues/92) by the crate. Also, how exactly does that work? Since the methods are registered at runtime, would they only be callable through reflection?
FWIW, I experimented with a lot of note taking strategies because I constantly have to store information / ideas and writing on paper doesn't scale. I used to just write everything into linear text files but then it wasn't easy to see the important todo items at a glance. Mindmaps also don't really work in software but what I found works for me is spreadsheets: Now I store all my todo items in a LibreOffice Calc spreadsheet and I can move sub-lists around quickly and highlight things in different colors. I have long-term and short-term todo lists and different sheets in the same doc for the different parallel visions/plans. So I look at it several times a day to know what needs to be done, and edit it accordingly. I also use it for quick bug tracking, writing down features I want to add to my projects etc. and I can easily search stuff.. Both Google Sheets and LibreOffice Calc are *much* faster to edit/navigate without a mouse than something like Google Calendar or any Todo-List App I found, and it's much more flexible. My productivity has literally skyrocketed since I started using Spreadsheets for fleshing out my plans / todo lists..
That does describe "full screen mode", but if you were doing *windowed* command shells, that meant blitting on some sort of framebuffer, just like xterm. And many machines other than the PC did not have this sort of text mode, so the framebuffer was always involved even when rendering text.
Implementation correctness is one thing; I can still implement an algorithm to run you over in rust.
I have actually been working on something (somewhat) similar in parking_lot: [link](https://github.com/Amanieu/parking_lot/blob/wrappers/wrappers/src/lib.rs#L8) Essentially, you just need to define a type which implements the `RawMutex` trait and then you can define a typedef of `parking_lot_wrappers::Mutex` to provide a full-featured type-safe mutex type with proper mutex guards and everything. See an example [here](https://github.com/Amanieu/parking_lot/blob/wrappers/src/mutex.rs#L88). The goal is to significantly simplify the implementation of custom mutex types, so you can easily make a spinlock or futex-based lock and have the type-safe API be provided for you. The branch is still WIP, but it will be part of the next version of parking_lot when it is done.
I met him at Revision demoparty this year, such a cool guy and so humble :)
&gt; And many machines other than the PC Yeah, I'm only talking about PCs because original comment was about 286/386 PCs. &gt; if you were doing windowed command shells What do you call windowed command shells on old PCs? Full graphical things like Windows 1/2/3, or ‶hacks″ multiplexer like MSDOS shell and the like?
I'm not trying to discourage further research into formally verifying rust. Just saying, that's one good reason to choose C today.
Be it small or big, I'm pretty sure there has been one breaking change in Rust 1.x.x if not more. [Adjust default object bounds [breaking change] #1156](https://github.com/rust-lang/rfcs/pull/1156)
You can concatenate identifiers already in Rust using a proc macro so... this feature does not introduce a New problem. It makes something that is currently painful into something that can be used to generate function names easily for tests, benchmarks and many other boilerplatey things :/ With great power comes great responsibility and all that 
There's a big difference between not being able to create threads when it's the right solution and introducing threads when they aren't. Python and Ruby couldn't thread at all, and the global lock meant a whole mess of other problems. 
To be entirely honest I only investigated it enough to get an intuition that it's worth investigating if I had a large number of functions to expose to Java or wanted a library to be easily integrated into several java projects; for better or worse that wasn't my use case.
I was just joining the discussion at the bottom of the thread...
You can implement a custom parser !
Thanks so much for all the information. I ended up using the async/await method. Still not as modular as rust, but it'll work. :) It sounds like the module integration will really bring rust into the forefront of webassembly. I'll be sure to keep an eye on that issue.
&gt; If C code has such a proof, then the program should have zero security holes, which is even better than rust sometimes. **At what cost?** Yes, it is possible to prove C formally as demonstrated by the SEL4 microkernel. However, what SEL4 also demonstrated was that doing so was extremely costly. The researchers behind SEL4 spent *years* proving the properties of the code; and there's only ~9,000 lines of it. I doubt anyone is willing to wait a 100 years to get their self-driving car... A more compelling argument, here, would be Ada/SPARK.
Note that rather than load a new copy of the wasm everywhere, you probably want something like: const wasm = WebAssembly.instantiateStreaming(fetch('it.wasm'), {}) .then(obj =&gt; obj.instance.exports) Then whenever you want access to the functions, const { rust_fn } = await wasm That way you only instantiate the wasm once, and after it's done loading the await will actually just synchronously return the exports.
You may be interested in the fact that a [Formal Verification Working Group](https://internals.rust-lang.org/t/announcing-the-formal-verification-working-group/7240) has been formed for Rust. I do not know how the group expect to proceed; in their shoes I would opt toward something like SPARK: specify pre-conditions/post-conditions/invariants in annotations, lower down the Rust code to MIR, then prove the annotations hold. It'd be a huge endeavor, but it seems achievable: - SPARK works, Rust has a flexible attribute systems, so specifying SPARK properties with Rust attributes seems possible and allows reusing the engine. - MIR is much more simpler than Rust, so as long as the symbolic relationship between Rust variables/functions and MIR ones is preserved in the lowering, it's much easier to reason about without any loss of functionality^1 . Of course, that's only the first step. Any lowering from MIR to executable code must then also be proven to be correct, for example. It would probably be easier with a custom (lightweight) backend than with LLVM. ^1 *Actually, as a bonus, it means that the lowering to MIR doesn't really have to be proven, since the proof is done on MIR.*
This. As much as I agree that using C is a very dangerous thing, the language itself is the least of my worries here. The code piloting a self-driving car will have to be held to excruciating standards, and this is more about *process* than *language*. Most notably, I regret the absence of *auditing*. Ideally I'd prefer the code to be open-source, but I'd settle for code and process to have to be audited by independent 3rd-parties. I am quite worried that companies will otherwise settle for the least amount of effort, and the accident in Arizona be the first of a long serie :/
The only time I've wanted this is for generating benchmarks. As with many features it can be abused, but for my use cases it is completely benign.
While it doesn't yet, there have been people who have been working on formally verifying Rust; those may become those semantics, depending. There's a working group now.
I guess looking at the flip side, at least we have a data point for the cost of formal verification of a simple kernel in C. I would hope that Rust's type system makes it an even easier task, but sadly we don't have a data point to compare with.
When you write the definition inside `trait View` you are defining default implementations of methods for anything which implements `View`. When you write them inside `impl View` you are defining methods which are valid for trait objects, and trait objects have a default `'static` bound. You have to explicitly opt in to non-static bounds. Try `impl &lt;'a&gt; View + 'a` and the method will compile.
&gt; The proof is verified at the C source level IIRC, the actually proven implementation is written in Haskell and the "production" C code is a 1-to-1 port of the Haskell code.
&gt; trait objects have a default `'static` bound. Oh cool, somehow I missed that, thanks!
docs.rs?
This is verifying the language itself, and then programs. First steps first :) the semantics of unsafe aren’t fully specified so we have wiggle room.
There is a work in progress fork for Windows support. You can get a test binary from it's appveyor build here: https://ci.appveyor.com/project/zacps/alacritty
Ah nice! I’m following the issue but I must have missed that!
Oh! That makes sense. Yeah, the community has definitely chosen to go towards async IO rather than expand what we really need (actually solid libraries and ecosystem). However, I don't think this is necessarily a bad thing! We'll get solid async IO this year, and then when we actually start getting a solid ecosystem as well, all of it will be built on async IO by default, and we won't need to change to it if we want to scale further in the future. I find async IO to be a saner default than blocking IO for most things, and even though we're definitely going out of our way to add support, I don't think that will be bad in the long run.
You can do that, but then you can't run any json queries on that directly in the DB. If you use postgres, there are dedicated JSON and JSONB field types for this purpose.
Define simple. 
AFAICS on docs.rs you can't search for a symbol across crates, you have to know which crate it's from and enter the crate's name, then search in that crate's docs. Or is there such a way?
Not necessarily, because mrustc is only really concerned with one program - rustc. There's no guarantee it works for other programs.
Very nice work! Good job :\)
Good to hear! I'll see about adding some padding, I'm not the greatest with html, so it might take me a bit.
Sadly it's absolutely random. The only thing I know after a certain amount of times is that some objects will be accessed more often than the others.
In my first reply I said functional programs were “easy to prove” which was a mistake. What I really meant to say is easier to reason about. Your comment illustrates this IRL. From my experience using both FP and IP the scope of FP functions are tighter. When something goes wrong it’s much easier to reason about where to look because the boundaries are much more enclosed. There are no variables to consider, global or otherwise., only constants. This code does X and that code does Y and there is no ambiguity about whether x() will impact y(). If your Y isn’t working you don’t need to wonder about whether calling unrelated x() had anything to do with it. Most of the bitchy bugs I’ve had to kill generally turn out to be the result of some side effect which didn’t seem relevant at first or second glance. Writing and reading pure FP code can involve some mental gymnastics but its boundaries are clear. 
I am the TA that spearheaded teaching rust in this course. If you have any questions or suggestions, let me know!
Do you mean with a parameter for each entry in the vtable? Parameters can only be an integer or float, so passing the vtable by value is a little tricky.
Are there any shared memory crates that can be used to communicate with process you don't trust?
There is the rust belt project But from my understanding it is difficult to formally model some of the mechanics of rust 
&gt; 2) I've noticed that on amd64 the GCC/G++ likes to generate a particular CFA rule which is not handled by gimli itself. Or at least I think it's mostly the same (or very similar) rule; I haven't investigated this as this happens rare enough to not be a problem for the profiling data to be 99% correct. If you run cargo test in the repository you can see it in one of the tests: &gt; &gt; ERROR 2018-04-27T17:10:44Z: nperf::dwarf: Handling for this CFA rule is unimplemented: Expression(Expression(EndianBuf { buf: [119, 8, 128, 0, 63, 26, 59, 42, 51, 36, 34], endian: LittleEndian })) &gt; &gt; It would be pretty nice if gimli could handle it automatically. (Although, again - it's rare enough that it isn't a problem for us.) I think maybe there is a misunderstanding. When a CFA rule requires that an expression is evaluated, `gimli` doesn't have enough information to evaluate that expression yet. Evaluating the expression likely requires reading memory and saved register values, and those things need to be provided by the library user. See https://docs.rs/gimli/0.15.0/gimli/struct.Expression.html#method.evaluation and https://docs.rs/gimli/0.15.0/gimli/struct.Evaluation.html Does that clear things up at all? &gt; 3) The EndianBuf does take a lifetime, which is somewhat annoying when you want to just mmap a file and you don't want to permanently leak it. What I did here (for now) is I've put everything into one structure (FrameDescriptions in frame_descriptions.rs), put the mmaped data in an Arc, wrapped everything in mem::ManuallyDrop, set the lifetimes to 'static and used mem::transmute quite liberally. &gt; &gt; Ideally I'd be nice to have an ArcEndianBuf or something along those lines to use in cases like these. (Which I have thought about whipping up, but the Reader trait from gimli had quite a few methods to implement, so I decided to go for the faster/more hacky solution for now.) Opened https://github.com/gimli-rs/gimli/issues/294 for this! &gt; 4) Having a built-in abstraction over both EhFrame and DebugFrame would be nice. Did you see https://docs.rs/gimli/0.15.0/gimli/trait.UnwindSection.html ? Did you mean something else? If so, can you go into more detail (preferably in an issue). &gt; The major thing would probably be the .ARM.extab-handling code from arm_extab.rs which could be easily pulled out, perhaps even into gimli. (Since .ARM.extab is, basically, ARM-specific .eh_frame.) Yeah! I meant to get around to writing a parser for this stuff one day, but never ended up getting around to it, so splitting this out would be awesome :)
This is the current state of what I have going: &gt;const wasm = WebAssembly.instantiateStreaming(fetch('rust.wasm'), {}) &gt;.then(obj =&gt; obj.instance.exports); &gt;async function testMe() { &gt; const { rust_function_name } = await wasm; &gt; console.log(rust_function_name); &gt;} &gt;console.log(testMe()) This yields: `Promise { &lt;state&gt;: "pending" }`
So if I hit this with a Nokia 3310, what will break? The code or the phone?
It’s also a little bit too much trouble: I would prefer to just do impl_something!(x, y, fn_x_y); impl_something!(x, z, fn_x_z); than to add another dependency that allows me to remove the `fn_x_y` ident parameters
Reddit threads have no bottoms!
I'm working on a custom 32/64 bit OS, as seen here: https://github.com/just-a-martian/Project-Longhorn
Nice work :) Does this mean I don't have to wait for ipc-channel anymore to support Windows (seems to be taking forever), I can just use this instead, to communicate between different processes on Win8.1?
Nice work :) Does this mean I don't have to wait for ipc-channel anymore to support Windows (seems to be taking forever), I can just use this instead, to communicate between different processes on Win8.1?
So, this is my first crate - a Rust derivative of `ts` from `moreutils`, and more directly, Kevin Burke's [`tss`](https://github.com/kevinburke/tss), via his blog post "[Profile Anything in Any Language in Under a Minute](https://kev.inburke.com/kevin/quick-dirty-profiling/)". `ts` acts as a command-line filter, prepending each line with a timestamp. As the name suggests, `rtss` does much the same, only it's interested in *relative* durations. `rtss` has a couple of advantages over `tss`: * It can run a command itself, wrapping both stdout and stderr seperately. * It's about twice as fast at processing `cat &lt;huge xml file&gt;`, which I'm sure is a prime use-case for this sort of tool... * I had fun writing it. * It's Rust :P It comes with a library for reuse in other programs, including an `io::Write` you can use with anything accepting such a thing: use std::io::{self, Write}; use std::time::Instant; extern crate rtss; use rtss::RtssWriter; fn main() { let mut writer = RtssWriter::new(io::stdout(), '|', &amp;Instant::now()); writer.write(b"Hello!\n").unwrap(); writer.write(b"World!\n").unwrap(); } This helpfully produces: 0.2μs 0.2μs | Hello! 84.7μs 84.6μs | World! --- This is my fourth Rust project. I started just over a month ago with [gcstool](https://github.com/Freaky/gcstool), which was a bit of a play both with Rust as a brand new language to me (coming from Ruby and C), and Golomb Compressed Sets, which are a neat alternative to Bloom filters for certain use-cases. That also spawned [linereader](https://github.com/Freaky/rust-linereader), a fast line-oriented reader which significantly reduced gcstool processing time on my dinky little Westmere Xeon development machine. Also [bitrw](https://github.com/Freaky/rust-bitrw), a bit-oriented reader/writer. I haven't published any of these on crates.io yet, but I plan on getting around to it at some point. I have to say, I'm really enjoying Rust so far. I haven't been this enthused about trying a new language since I started with Ruby in *1999*.
I know, I just wanted to keep my comment consise. :)
This is really awesome. Thanks for sharing.
Nice. My alma mater and my favorite programming language. Also, I feel like there’s a nice nexus of crab lovers between Maryland and rustations.
I agree that you can't make a blanket statement like "zero security holes", but I would attribute it to point (a). Instead, the honest thing would be say something more like, "there are no flaws of type X, Y, Z". But you can't possibly write down and prove every property. We're finite beings. What happens in practice is that you say, "Okay, here are the security properties we care about for our use-cases" and someone goes off and tries to state and prove some theorems that show those properties always hold for your system (given some reasonable assumptions). Reasonable assumptions you might make are things like, the hardware doesn't misbehave (or isn't tricked into working at weird voltages), the compiler generates the correct code, humans are doing their job correctly, etc. As for FIPS levels, that's a whole different set of concerns. I don't think FIPS even looks at formal verification does it? FIPS, as I understand it, is more interested in the engineering processes that were followed during the development.
Wait, I didn't know that about atomic representations. Do you have a link to something that talks about that?
I can ask, but I can't promise anything. (:
I've narrowed it down to *something* with DNS. I just don't know enough to know what exactly is wrong. I am using a laptop, and it worked fine at my office, but not at home. I have a Raspberry Pi set up to use Pi Hole, but it wasn't working. Once I updated Pi Hole, the download went through.
Thanks for spreading the good word and the teachings of our lord the great Hoare.
I'm fairly inexperienced with javascript (hence some of the bumbling), so again, thanks for the info. I'm really wanting to do this with straight javascript (for being lightweight and to learn it a bit better). Even if I have `document.getElementById("inputID").value = rust_function_name();` inside of `testMe(){}` all I get is the `pending` result. What part am I not understanding about how to have the `testMe()` function actually do something?
Honestly I don't know where you've gone wrong. I might be able to guess if I could see everything, but I really don't know. Just a tip: _very few_ people just write JavaScript with no tooling (though it _might_ happen in the future when native module support is widespread). Any decently complicated task benefits from using separated source files, and the only way to package that all into a deliverable is to bundle it. Doing things manually isn't easy; that's why the tools exist. Don't think you're cheating by using the available tools, so long as you are able to switch ecosystems if required for a mandated project, you'll be well off. On the Rust side, wasm-bindgen or stdweb are invaluable tools (disclaimer; that I haven't used yet) to make this easier. You get out JS sources that encapsulate the requirements of calling into wasm.
What are the preequisites?
Thanks!
No, Alacritty making the claim in the first instance is weird. They can't both make the claim and use the lack of an initial release as a shield.
That is so cool, can you guys record videos of it being taught?
This course is part of the intro sequence of classes. You have to take systems programming and discreet math before.
They already went through the 4 or so lectures of it. There is only 1 project due (as I posted) before they move to the next topic (not Rust). I don't want to sound disrespectful or anything, but from what I understand, the professors are not really Rust people. Hopefully next semester they will understand it more and be able to help the students better understand it themselves.
Everyone, including the professors, learned it this semester. It will get better over time.
You can use the call! macro to wrap a function that returns an IResult. The function can look up the tag name from a vector, for example 
Just so you're aware, as I'm unsure based on the above message: Rocket/Iron/etc are _backend_ technologies. To use those, you just compile your code like normal and deploy it onto a server somewhere. WASM is a _frontend_ technology. This is what actually runs in the browser when a user visits it, and drives the site's interactivity. Most modern workflows would recommend separating the two domains. The two have to work together based on some API, but have very different concerns about how they're implemented and what services they need to provide. I've not used Rust for any web-related development, so I can't comfortably recommend anything. (But just based on hype, I think Tower is backend tech I'd want to use and stdweb is promising.) But I do know that it's an unfortunate reality that frontend developer tooling runs on node and is delivered through the npm registry. Based on the web project I did as part of a class, I wouldn't recommend any serious frontend project to work without Webpack backing it up. SPA's requirements (what I did for the class) are, of course, different from lighter projects. But working without modules is painful. Unfortunately you're pursuing a direction I haven't gone (yet!), so I'm not going to be of much more help. I wish you luck!
Thanks, I'm aware. :) I've played around with rocket a good bit and it's pretty straightforward. I had a quick look up of tower (hadn't heard of it before). I'll keep my eye on it. I'll keep digging. You helped plenty. I'll let you know when I get it done how I want it.
UPDATE: [I got it working, but it's not exactly pretty](https://github.com/nafi-lang/rust-nafi/blob/3888249987f857797ce8e79376c1e8d6cfbf3555/syntax/src/untyped/de.rs). It definitely copies more than necessary. It works, though.
If the break is because someone was relying on what was deemed incorrect code, or a bug the break is allowed. Also, if the break can be determined to not actually break any known code (via crater runs, or the break being deom *extremely* esoteric code) it's allowed. 
Would it be possible to define a enum like - ``` enum Command { Get { key: String, value: String }, Set { key: String, value: String }, Ls, Del { key: String, value: String }, } ``` and use structopt to convert the command line arguments to this datatype? (Why rust is very, mmmm, rusty) Also, to the author, maybe a command such as `clean` would be nice to delete all key-value pairs. 
Yep. Have a look at structopt's git example: https://github.com/TeXitoi/structopt/blob/master/examples/git.rs
Ahh, I see that point, didn't think about it that way. (as obvious as my post)
How did you convince the faculty that this was worth doing? I'm the kind of person that likes to push for changes, but I don't know how.