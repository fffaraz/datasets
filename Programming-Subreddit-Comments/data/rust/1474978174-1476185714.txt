&gt; The only optimization I can think off that would be really hard (or impossible) to achieve would be to make this type of GC compacting Which is the most important optimization in any GC bar none, because it allows for bump allocation in the nursery. If you don't have this your GC always loses.
I've finally found a little bit of time to update my JSON parser. (Even tho it seems that better solutions have popped up, it was a good experience.) https://github.com/Rafagd/json-rs
I had exactly the same idea ;) I came up with a solution (which is actually quite similar to what OP is doing), but people pointed out a number of possible problems with it; you can check the discussion [here](https://www.reddit.com/r/rust/comments/44538m/creating_an_api_for_plugins_in_rust/). EDIT: oh, the link to the blog post no longer works. If you want to see it (and you probably will need to for context), just substitute `ebvalaim.mydevil.net` with `ebvalaim.pl` in the address ;)
[deleted] ^^^^^^^^^^^^^^^^0.9927 &gt; [What is this?](https://pastebin.com/64GuVi2F/34182)
If I have an enum variant with data. E.g. enum foo { bar {x: i32}, } What would be the most 'rusty' way to create a method to access that data. Should I implement a function for that enum? Should I create a freeform function that takes an enum reference? Unfortunately I don't have a choice in changing data structures as the enum comes from a library im using.
That's not what "ownership" means in Rust. If references had ownership, when they went out of scope, the underlying resource would be destroyed. That's not true with references.
The "this" pointer would only be dangling if the object whose member function called "collect()" on the deferred_heap had no one holding a deferred_ptr to it. But if no one holds a deferred_ptr to the object in question, no one should be calling the member function which calls collect() in the first place. It's the same as in a GC language; if some object calls GC.compact() or whatever the equivalent is, then simply by virtue of the object being alive and having its method called, the object itself won't be one of the things cleaned up by that GC pass. Of course, you can violate the rules and hold a non-owning pointer to an object, and no one will save you; all bets are off then.
More functional, less object-oriented.
I think it would be awesome! It sounds difficult to implement, though. I wonder if there is a sane way to deal with things like conditional compilation, build scripts, new versions of reexported crates, etc.
So Rust would likely use capital Foo and Bar, not foo and bar. The subtlety here is that you have to account for what happens if the wrong enum variant is passed. What if it doesn't have data to access or it has data of a different type? To account for this, I would use an if-let and destructuring to access the data as follows: enum Foo { Bar { x: usize, }, Baz { x: String, } } fn main() { let x = Foo::Bar{ x: 1985 }; if let Foo::Bar{ x: datum } = x { println!("My datum is: {}", datum); } else { println!("Wrong enum variant!"); } }
Seems that Solus OS decided some time ago that it would be better to use `madvise`, as they cite that `always` causes higher memory usage and I/O bottlenecks when the kernel compacts pages.
[deleted] ^^^^^^^^^^^^^^^^0.3977 &gt; [What is this?](https://pastebin.com/64GuVi2F/33905)
Yes, its super frustrating when things break due to unexpected API changes
https://github.com/rust-lang/crates.io/issues/435
Thanks but my question is about learning a specific topic, not getting a ready made tool that already solved it. 
References are borrows. I understand the difference between owned pointers and borrows but that is not what I was getting at. 
Wouldn't it make more sense to use -musl- target and static binaries? N900 &lt;3
Yes, I think you intuitively understand what's going on, but you're using the wrong words here. Borrowing and ownership are disjoint properties: you either own something, or are borrowing something. "hence they do have ownership for the duration (lifetime) of the borrow." is not true. I just want to make sure that this confusion in wording isn't going to cause more problems for you later :)
Yeah, the semver spec says &gt; Build metadata MAY be denoted by appending a plus sign and a series of dot separated identifiers immediately following the patch or pre-release version. Identifiers MUST comprise only ASCII alphanumerics and hyphen [0-9A-Za-z-]. Identifiers MUST NOT be empty. 
/r/playrust
Thank you. I thought so too. I watched the video again and I think the nuance AFAIU is as follows: Herb uses raw pointers to denote no-ownership and weak-pointers to denote weak ownership. The tradeoff between the two is indeed some overhead as you mentioned. Herb mentions that if we change the internal structure of the tree (re-parent a node) we need to *manually* maintain the internal invariant that the raw pointer of the child points to the correct parent. So his design is leak-free by construction but if there is a bug that breaks said invariant we still can get a dangling raw pointer. (E.g. removing an intermediate node from the tree and forgetting to update its child's parent pointer - the child still points to thee old, and now deleted, parent) So in Rust land, either I enforce a safe interface but implement it with unsafe implementation (just like other containers in std do) or use weak pointers and take the overhead. And as you said, there is no way to have it statically enforced by the compiler. 
See my reply to Manishearth. In short, there are two options to translate Herb's designs: 1. Use weak pointers that have an overhead. Or, 2. Enforce the data structure's invariants manually using unsafe internally while exposing a safe API.
It may provide a better API for some use cases; it feels a bit more general purpose, allowing you to, say, have multiple distinct types of edges (maybe `parent`, `child`, and arbitrary edges to other nodes). So yes, while you could probably map anything you could do with `deferred_ptr` to `petgraph`, it might be nice to have as an alternative API. On the other hand, I haven't tried using either, so I can't really say with much authority.
&gt; Enforce the data structure's invariants manually using unsafe internally while exposing a safe API. Yes. This is what he is doing in C++ as well, except that C++ can't actually enforce a safe API, just provide an API that encourages safety as long as you follow some unchecked rules. In Rust, a borrowed reference can be thought of as a safe version of a pointer or reference in C++. This safety comes with certain limitations, so if you need to get around those limitations you need to use raw pointers internally, and provide a safe API to users of the data structure, or use other abstractions like weak pointers which come with overhead. But this is not really any different than what Herb Sutter is doing in C++, except that the safety boundary is clearly delineated and borrow rules enforced.
Let's say you have the following graph of objects, all with deferred pointers, where `a` is pointed to by a root somewhere on the stack: --&gt; a / ^ v \ b --&gt; c Now, you call some method on `a`, which calls some method on `b`, which calls some method on `c`, which happens to call something on `a` that removes its reference to `b`, and then calls `collect()`. Now `c` will be collected, but you're still in the body of the method on `c`. You have a dangling `this` pointer, and you do in the method on `b` you called as well. At the time `c`'s method was called, something did have a `deferred_ptr` to it, but you can't be guaranteed that that will be true over the entire duration of the method call. And note that we never used any raw pointers other than the `this` pointer. And while this example may seem contrived, this is the kind of situation that's easy to get in accidentally if you have a graph of heterogenous objects, with abstraction in their methods so you don't necessarily see the mutation of `a` and the call to `collect()` side by side.
I'd be interested.
The payoff was pretty high, because it made for a great story to illustrate how welcoming the haskell community is, which is a pretty effective ad.
Ok, thanks :)
&gt; The subtlety here is that you have to account for what happens if the wrong enum variant is passed. What if it doesn't have data to access or it has data of a different type? I'm slowly starting to wrap my head around Rust enums but `if let` appears to be best for my use case. Thanks for the help. 
Of course and Elm is the same, all it can do is check the export changes and provide a *minimum* version for the new release. And it creates an incentive and culture of proper technical versioning. Note that is does not just watch types, it also watches the changes in exported symbols (a symbol being added to exports is a minor, a symbol being removed is a major)
Whoever called the method defined in the object in the tail of the list should be holding its own deferred_ptr to that object, right? So that anchor keeps the item alive, even after it is removed from the list and collect() is called. deferred_ptr doesn't have to track when a method is called through it; as long as the deferred_ptr is alive, the object it points to is alive, by definition.
It can't be complete. Fundamentally all it can do is look at the pub items changes and provides minimum version bump: patch if no change, minor if new types/function/method, major if removals or signature changes. One question for Rust would be the impact of ABI changes (new non-exported fields in an exported strict for instance)
I don't think musl target is available on arm
I seem to remember semantic versioning at one point was defined so that (in C) binary compatible changes would be a patch bump whereas source compatible but binary incompatible changes would require a minor bump. I can't seem to find an appropriately old version of semver though, so it's possible I'm thinking of some project's definition of "semantic versioning" that predates semver.
Yes. All pointers, including the `this` or `self` pointer, are owned and garbage collected in managed languages like Java or C#. So in this case in a managed language, the `this` pointers would keep `c` alive until the call chain unwound, at which point `b` and `c` could be garbage collected safely. That's the tradeoff that you traditionally make between managed languages with garbage collection, and systems languages with unmanaged pointers; in managed languages, everything is GC'd, while in systems languages that have unmanaged pointers, you can easily make a mistake that winds up chasing a dangling pointer and get undefined behavior. That's the main benefit that Rust's borrow checker gives you. It allows you to use references, which are lighter weight than GC'd pointers, couple with various different types of owned pointers (`Box` vs. `Rc` vs. `Arc`, or just owned unboxed, stack allocated values), while ensuring safety. Of course, not everything can be represented with just a single type of owned pointers and borrows, so Rust gives you the ability to use `unsafe` but provide a safe abstraction, which is what `Box`, `Rc`, `Arc,` and so on all do internally. And that's similar to what Herb Sutter is doing here with `deferred_ptr`; providing a safer abstraction for pointers that can form arbitrary graphs, though since it's implemented in C++, you can't actually provide that safe abstraction boundary that Rust can provide; you do still have to rely on the programmer to get it right, in a way that the compiler can't check.
For some reason the text goes off the screen when I used `h_metrics().advance_width`. I printed out the values and they're pretty large compared to the other values I'm putting into that struct. My hunch is that they need to be normalized. So then I tried normalizing them against the `advance_width` for an `M`. This causes all the letters to bunch up a bit and overlap.
Wouldn't that conflate two purposes though? I mean, if I am exposing an immutable piece of data, why should I have to pay for run-time checking of the absence of aliasing?
Having used NPM, I second this!
Never mind my questions, I think I have the math worked out now. Here is what it currently looks like: http://i.imgur.com/JBZlbC6.png I have to clean it up (you have me some good suggestions on that but I haven't made those changes yet). Thanks again!
Say an object a of class A has a member function f() which does what you suggest (removes itself from the deferred_heap it belongs to, and calls deferred_heap::collect()). Who is calling A::f()? Whoever that is should be holding a deferred_ptr to "a", which keeps "a" alive even while and after A::f() removes a from the deferred_heap and calls collect(). If there is just "some deferred_ptr" on the heap, then that deferred_ptr keeps "a" alive. If A::f() is removing "a" from the deferred_heap, destroying the deferred_ptr that A::f() was called through, and then calling collect(), then sure, you'll have a problem. But the issue here is of design. Whoever called through that heap-allocated deferred_ptr should have arranged for the deferred_ptr to outlive the A::f() member function call. This is no different than any other use of a smart pointer in C++. If someone else has access to change your smart pointer from underneath you while you are using it, you should anchor it someone (usually, to the stack).
[You can read here about how petgraph works](http://smallcultfollowing.com/babysteps/blog/2015/04/06/modeling-graphs-in-rust-using-vector-indices/)
&gt; Final Note: Sharing Custom Data Sharing data types is one thing, however this is not the only one. I have worked with the idea of "persistence" of memory before (in the context of a rebooting process) and beyond data types, there is the whole issue of pointers into the unloaded code. You may have pointers to constants, functions, etc... For example, in Rust, any instance of a `&amp;Trait` has a virtual pointer: - the virtual table is stored in the code section of the library - the function pointers it stores reference the code section of the library If you unload this library and swaps in a new version, those pointers are: 1. Pointing to the old code 2. If they do not crash, using the old code How do you get around this issue?
I don't think so. This is really a social problems and social pressure will be sufficient. There is also the odd company (e.g. all of them?) that uses version numbers as marketing. Not all marketers care for semantic versioning. As Rust becomes more widely adopted, it will be important to be flexible for devs who don't use semver to be able to contribute crates. Fringe case perhaps.. happy to be persuaded that this is a non-issue
Is there any sense in waiting for `impl Trait` to stabilize so the API doesn't have to be full of weird adapter types?
One of the nice things about openFrameworks is that it hides pointers. I think the toughest concept to learn in rust is ownership, and if a higher level language that hid ownership came about it would go a long way towards having oF/artists to jump in. Someone here posted a DSL that looked promising a while ago, forgot the name. Alternatively, even just a proof of concept Setup Update Draw loop rust program would be helpful.
Legit question, when I thought about this my answer was no, we can make that an 1 -&gt; 2 break just as well.
In a word, no. In a few more words, I can imagine a world (this world, perhaps!) where opt-in enforcement would be nice. I assume opt-in enforcement is possible in the first place. The last paragraph of [this](https://gist.github.com/jashkenas/cbd2b088e20279ae2c8e) opinion piece seems relevant: &gt; If you pretend like SemVer is going to save you from ever having to deal with a breaking change — you're going to be disappointed. It's better to keep version numbers that reflect the real state and progress of a project, use descriptive changelogs to mark and annotate changes in behavior as they occur, avoid creating breaking changes in the first place whenever possible, and **responsibly update your dependencies instead of blindly doing so.**
There's a PR to fix the link to the RBML pull request: https://github.com/cmr/this-week-in-rust/pull/316
&gt; This is really a social problems and social pressure will be sufficient. It doesn't seem to have been anywhere so far, the only language/community I've seen make inroads there is… the Elm community where the package manager tries to enforce it. &gt; There is also the odd company (e.g. all of them?) that uses version numbers as marketing. Not all marketers care for semantic versioning. Irrelevant: 1. Semver enforcement is just a minimum version, you can increase your version further if desired (or necessary, elm-package does not know about semantics so if you don't change the API but change the code in such a way that it'd break callers you're supposed to bump the major). If you want to release 4.0.0 differing from 3.2.6 by just a bugfix the tool can't *prevent* you, because for all it knows that bugfix could completely change the effective API even if it doesn't change the exported symbols or their signature. 2. Semver is for libraries, I'd would not expect Cargo to check binaries let alone complex applications. 3. If you're selling a library, it probably isn't on Cargo, and if it is you can have an internal and an external version number. Same with binaries or applications actually: Windows 7 was NT 6.1, Windows 8.1 was NT 6.3. Over-versioning is annoying, but it's not troublesome. Under-versioning is actually troublesome. &gt; As Rust becomes more widely adopted, it will be important to be flexible for devs who don't use semver They can start using semver and make everybody's life easier?
&gt; [trans: Only instantiate #[inline] functions in codegen units referencing them](https://github.com/rust-lang/rust/pull/36524) has a somewhat innocuous comment from retep998: &gt; I just tested this PR locally, and it appears to work. According to -Ztime-passes llvm passes has gone down by over an order of magnitude for winapi (328ms to 14ms). Translation went down also, but not as significantly (628ms to 433ms). The LLVM IR went down from 2,170KiB to 1KiB. are there any other crate that have observed such a *massive* change with that PR? 
The `Self` thing fixes an ICE, it's always been a parse error, but with error recovery rustc has to be careful not to blow itself up in weird cases (such as keywords being used where a regular name is expected).
I remember reading this a while ago.. :) Thanks for the link though! Btw, this explains that petgraph uses a different strategy than what Herb's talking about and it's first listed disadvantage is that deletion from the graph is problematic! IOW, it takes a different tradeoff and is therefore suitable for different use-cases compared to what Herb is talking about in his presentation. 
Remember that Jermey's opinions here are informed by his (vast) experience with dynamically typed languages. Statically typed languages have many more tools for automatically detecting these kinds of changes.
&gt; responsibly update your dependencies instead of blindly doing so Semver enables me to responsibly update my dependencies without having to trawl the trivia of a changelog to see if there's anything I care about. Arguably, it was specified for that precise purpose. Many developers do it wrong, but that's on them.
[This](https://github.com/tomaka/vulkano/blob/master/examples/src/bin/triangle.rs) (from vulkano) is the most descriptive triangle example I have ever seen!
So, I'm playing around with a hashmap and printing some keys in sorted order. The toy map I'm playing with is initialized: #[macro_use] extern crate maplit; // ... let map = hashmap! { "a" =&gt; vec![0], "c" =&gt; vec![1], "b" =&gt; vec![0, 3, 42], }; This compiles: let mut keys: Vec&lt;&amp;str&gt; = map.keys() .map(|x| x.clone()) .collect(); keys.sort(); But this doesn't: let mut keys: Vec&lt;&amp;str&gt; = map.keys() .map(|x| x.clone()) .collect() .sort(); error: the type of this value must be known in this context let mut keys: Vec&lt;&amp;str&gt; = map.keys() ^ (the caret is pointing to map) I'm not sure I fully understand why. There doesn't seem to be any more information in the first form than the second. This is with rustc 1.11.0 
&gt; We have used such analyses in Firefox (sixgill). They're hard to write, as evidenced by the fact that they didn't catch some real exploitable issues. They might not catch everything, but I bet they caught something. And the stuff they don't catch, typically, is stuff that is hard for humans to read as well - and is in heavy need of refactoring. &gt; I agree if you reference count everything and lock down the hundreds of random memory safety holes in C++, then there is some memory safe core you can get to. You don't have to lock down or reference count everything though; you only have to lock down and reference count the things that could be changing from underneath you. With many programs, this is probably a small number of things, especially if encapsulation was done well. Does it fix everything? No, but it doesn't claim to. Is it a step forward? I think so. &gt; Given that nobody has ever written anything of any size in this "safe" subset of C++ Look, I get you are an advocate for a different language, and I also reach for languages like the one you advocate before I reach for C++, but in a discussion about C++ and the benefits this abstraction can have, I don't think statements like this are productive or relevant. For one, it is trivially refutable. Let's stay on topic please. &gt; To bring this back to deferred_ptr, deferred_ptr provides no memory safety features that shared_ptr didn't already have. Directly, if someone uses deferred_ptr where they had to manage raw pointers previously (because they wanted to avoid cycle leaks, or for other reasons), then I think it's a memory safety win. Also, if one doesn't have to reimplement some of the algorithms that one gets with deferred_ptr for free, one is less likely to make a mistake, and that can be safer as well, in all dimensions.
I saw that! The comments in Vulkano's source are incredible
"Don't let the perfect be the enemy of the good."
(on my phone, sorry for the succinct reply) I haven't implemented it yet but the idea is work with quadratic better curves and separate the triangles encapsulating these curves from the tessellation. Then, the renderer could either render the curve in a shader (loop-blinn style) or use a tessellation shader, or retessellate the parts which is a lot cheaper than the retessellate the interior of the shape. There are a few notes about this here https://github.com/nical/lyon/wiki/Experiments Right now I you have to retessellate as you zoom, though. Nanovg uses a different approach to render paths (stencil and cover) which is easier to implement but you can get better performance out of tessellation in my opinion. I also want to experiment with stencil and cover, though I haven't gotten to that yet. Also, Nanovg has a lot more features implemented than lyon at this point but I hope to catch up. The massively parallel vector graphics paper uses another approach (vector texture), a very clever one but it is sensible to driver issues so I am not considering it at this point. It's a good read though
Er… yes? I pretty much said that. 
Nope, because then a bad test (remember, tests can be wrong) can block a minor fix.
:) I said the same thing, but then saw your comment. What we can catch would be really helpful. I think even providing "Are there breaking changes" mechanisms to cargo would be helpful to library authors.
Correct, though it might be worth it to add something to the toml to say "These tests must pass" or some other shenanigans and let the library author determine what a breaking change is and what is not via tests. For example, I would think that examples should compile from one minor release to the next.
Thanks a lot for the reply, not succinct at all! So is it actually possible to "smooth-out" the sharp corners of too few triangles with a tessellation shader? I was not aware that such thing is possible. Isn't it then the best option? I mean, you upload few vertices/triangles and when zoomed-in, tesselate in shader on the GPU..? Also, have you seen [Multi-channel signed distance](https://github.com/Chlumsky/msdfgen)?
You could even put it after the version number blah-1.0.23-Super-awesome-Funtime-Release-8.3 If you really care about marketing releases (most don't).
I think it's great that that people are working on adding tools to make C++ safer. C++ is not going to go away for a long time, and tools to expose safer APIs within C++ are great. `shared_ptr`, `unique_ptr`, and the like already help out a lot, and this is another new tool in the toolchest. I guess I'm mostly taking exception to your statement that "[i]t is solved by not using raw references where you want shared ownership semantics." I suppose "solved" means different things to different people, but I would consider something "solved" if it provided guarantees you can rely on, without having to trust everyone who works with your code, rather than just making it a little incrementally easier to do the right thing. So yeah, I'd call it a win too, and I absolutely think this is an interesting talk on an interesting topic, but I wouldn't go so far as to say that the problems /u/pcwalton brought up are, or probably can be, fully "solved" in C++.
There is no other variant in the standard lib (that I know of) but there is [`Itertools::sorted`](https://bluss.github.io/rust-itertools/doc/itertools/trait.Itertools.html#method.sorted) which would be about what you want in this case. Yes, you wouldn't need `mut` if a `self` variant existed.
&gt; Since this is static analysis, you can be as conservative as you like. Nobody who has worked on static analysis would ever say that.
i like the "enumerate" out front on the RHS, it matches the ordering in the pairs returned, which is reversed vs the pairs with method style call.
You want /r/playrust 
Including me? That's a strange argument to make... When dealing with security, one usually wants to be as conservative as possible. Do you disagree?
This is fantastic. Maybe it's just me, but I've been seeing around a lot more work on Rust in embedded systems and it makes me exceedingly happy. 
I've been working on cleaning up [whatisinternet/inflector](https://github.com/whatisinternet/inflector) after having benchmarks demonstrated [here](https://www.reddit.com/r/ruby/comments/53wec6/how_do_i_should_i_be_getting_performance_boosts/) and on [GitHub](https://github.com/whatisinternet/inflector/releases/tag/0.3.3) that it *was* really slow. The hardest work has been done with optimization (it's now the fastest) but I want to get the project to a state where I feel comfortable with a 1.0.0.
This is a bit unrelated, but it would be nice if there was a "changelog" metadata field in `Cargo.toml`. Cargo could even read it when updating dependencies, and display the section relevant to the version change, or maybe the lines that start with e.g. `breaking:`. (Plus, it would incite more libraries to actually have a changelog te begin with.)
I don't have a lot of experience with tessellation shaders so I can't answer the question of how well it will turn out in practice, compared to other approaches. Tessellation shaders would need some kind of fallback in any case since not so many people have them. At the moment I am mostly making sure the tessellator is compatible with all of the considered approaches and let code that use the tessellator decide which to take. Multi-channel distance fields give nice and scalable results but they are usually pre-booked offline as far as I know. Ideal for font assets in a game but not what I am trying to solve with this library.
That's exactly what I would recommend and what my blog is built upon as well.
I mean, that's like pointing out that the typechecker can't catch all the errors in Rust code. I mean, yeah, it's true, but it's not very surprising.
Ok I misunderstood what was proposed
Cargo will already mis-understand your crate and make your users sad.
Crates that expose no public interface (i.e. executable only) are not bound by the enforcement. Initial publish version can be anything the contributor wants. Major version 0 is also not bound by enforcement. 
I hope this would be the exception, and not the rule.
Is there a comprehensive guide to lifetimes, beyond the intro in the book? In particular, what has a lifetime? Is a lifetime purely a property of references, or do values have lifetimes? Are there formal rules (a la inference rules or something like that) that state precisely how lifetimes behave?
Trusting developers to never make a mistake with Semver is like trusting other drivers to never make a mistake with driving.
Do you think your approach is easier than using zinc?
That quote is amazing :)
[bytecount](https://crates.io/crates/bytecount)
&gt; 1:18 error: #[feature] may not be used on the stable release channel :(
Ah, I made a mistake (corrected now), the feature name is actually `static_recursion`, its tracking issue is [#29719](https://github.com/rust-lang/rust/issues/29719)
Thanks :)
Working on a new "isometric" page rendering framework in Rust, using the same template syntax for server-side and client-side rendering. Basically, the stuff you can do with React/Redux but with compiled code instead of node on the server. Now with working counter demo ;-) [https://github.com/tmzt/incrust](https://github.com/tmzt/incrust)
I'm not really "blogging" (as I don't order the posts by date) but if you want, pandoc, a good stylesheet and a little bit of file structure go a long way: https://github.com/skade/yakshav.es/blob/gh-pages/build.sh (also published to GH pages in the end)
*edit I messed up the target-cpu initially * It's almost 2x the speed with with AVX2 working on 32 bytes at a time. I didn't optimize as hard for the small cases as the other. I just aligned the beginning and end to 32 bytes one byte at a time. I did the adding of 8-wide sums into 64-wide with a single vpsadbw instruction. Sadly I couldn't figure out how to use that instruction with the simd crate, for one it has the wrong type signature. I ended up having to use the gcc crate to compile a C implementation using immintrin.h. test test_hyperscreaming_newlines ... bench: 451 ns/iter (+/- 5) test test_hyperscreaming_nonewlines ... bench: 451 ns/iter (+/- 5) test test_hyperscreaming_random ... bench: 6,659 ns/iter (+/- 88) test test_hyperscreaming_somenewlines ... bench: 10 ns/iter (+/- 0) test test_ludicrous_speed_newlines ... bench: 221 ns/iter (+/- 3) test test_ludicrous_speed_nonewlines ... bench: 221 ns/iter (+/- 3) test test_ludicrous_speed_random ... bench: 3,522 ns/iter (+/- 29) test test_ludicrous_speed_somenewlines ... bench: 27 ns/iter (+/- 0) I suspect if you used 2 or 4 8-wide counters at once (so 16320 or 32640 bytes per loop), then you may be able to hide some instruction latency, and get a little more out of it.
You're correct I fixed the original reply. Sadly the avx2 variant of the sad instruction is missing. I can see the unsafe import, but the type is wrong and it's not exposed via a trait sse fn x86_mm_sad_epu8(x: u8x16, y: u8x16) -&gt; u64x2; avx2 fn x86_mm256_sad_epu8(x: u8x32, y: u8x32) -&gt; u8x32 The output should be u64x4 instead of u8x32. 
That's true, but it's not what this PR is about. This PR brings massive improvements in the case where \#[inline] functions are not used in a library, but made available for users of the library to be inlined there. When the library is compiled, these functions don't need to be passed to LLVM, because they will be translated to machine code as part of the context where they are inlined (and only if they are used). For wrapper crates such as WinAPI or WinRT (where I saw a similar [speedup](https://github.com/contextfree/winrt-rust/issues/26#issuecomment-248959655)) this means that lots of functions that are never actually used can be skipped by the most expensive compiler passes.
Feel free to use https://github.com/killercup/scribbles as a starting point for a Jekyll-based blog! :) (Copy the files, clear the `_posts` folder, remove or edit `CNAME`, edit `_config.yml` and `Readme.md`.)
AFAICS the c++ library doesn't use reference counting to keep track of the number of references to an object on the heap, so if you reimplemented this in rust then you should probably mark all references to the deferred_heap as unsafe. 
This is probably a big ask , But is there a way to get people to proof read posts and correct grammar etc. For my case it will be almost like rewriting the whole thing :)
By that quip, you can't ever trust (and thus use) third-party code either, and are thus not affected by semver concerns.
Personally, I would definitely support Cargo enforcing this both for crates that I write and crates that I use. The only catch might be enums with a hidden-but-public `_nonexclusive` member (or the struct equivalent) designed to allow the additions of new members without breaking the documented API contract. This might be fixable with slightly better declarations at the Rust level.
Learning Rust and fighting with borrow checker. Intention is to learn enough and contribute to OSS(mainly Servo)
You could always ask on IRC and see if someone wants to help out before you post.
I don't know what the exact scope of libweston is, but if it's similar to wlc, bindings to libweston would be orthogonal and incompatible with my wayland-server crate, just like I seriously doubt it's possible to sanely use libweston and wlc in the same project. Regarding wlc and wayland-server, they both do incompatible assumptions about the way meta-data of wayland ressources is handled (aka, both use the `user_data` of `wl_ressource`, in an incompatible way). If libweston does the same thing, no interaction is possible.
Have you looked into Jekyll?
Hmm... I'd like to interpret it as "use with caution", instead of "don't use at all". 
Both values and references have lifetimes. Suppose you have this piece of code: { // scope 'a let v = 5; { // scope 'b let r = &amp;v; } } Now we can say: v has lifetime 'a. This means that v lives only within the scope 'a. Likewise, we can also say: r has lifetime 'b. The type of r is &amp;'a i32, because it points to an object with lifetime 'a. During compilation the borrow checker will verify that the lifetime of every reference is smaller than the lifetime of the value it references. In this case, it will verify that the lifetime of r is smaller than 'a. Indeed, this is correct: 'b is smaller than 'a.
I'm no Wayland expert, so are you saying that your Wayland crates are already (maybe partially) providing the abstractions needed to write a compositor? Reading your blogpost, I was under the impression it's not pure Rust but bindings to wayland and sibling libs, so binding to libweston(-desktop) seemed logical to me, albeit I may not possess the full Wayland picture here. The main reason I like libweston(-desktop) is that the most popular library (wlc) has too many bugs, while libweston(-desktop) (and therefore Weston) is less buggy, although there's still a fair amount of Xwayland issues.
But you could have (that's actually my case) a crate that exposes a public interface via an executable (A command line interface is also a public interface, right ? And I think semver should also apply to that, even if it is not testable by cargo), but also provides a library interface to some of its functions. I think it could be nice to have a way to say "ok, I expose these functions so people can make third party tools, but the stable public API is really the command line, so be aware that if you call these functions directly it might break at any time." (Or maybe a way to mark some methods as unstable in a similar way to the stdlib?). (Of course, it would be possible to have two crates, one for the binary which would probably be 1.x.y and one for the library that would remain in the semver-free realm of 0.x.y, but I'm not sure if that's any better? Or maybe it's just that I feel like i'm "polluting" crates.io if I publish two crates that could be in one :) )
You might want to check out https://github.com/rust-lang-nursery/regex/tree/master/regex-capi , which I think is one of the most complete examples I've seen.
A commandline API is just like a JavaScript one -- cannot be checked for compatibility and thus cannot be enforced. You are free to apply SemVer yourself. &gt; I expose these functions so people can make third party tools, but the stable public API is really the command line, so be aware that if you call these functions directly it might break at any time. Why would you hold your language API to a lesser standard than your commandline API? As long as your API is public you are responsible for maintaining its compatibility. 
Yup, and it's key to zero-cost abstractions too! Abstractions often involve little one-line accessors (e.g. `Index` impl on `Vec`, vs. raw array access) and without inlining, those can't collapse to the C-level equivalent code.
Excellent write up, shame that the destructor safety causes incompatibility with existing toolkits (e.g wlc) as I was looking forward to using this in Way Cooler. Unless another framework is built on top of this library, it'd be hard to integrate this with any other project designed to write compositors, such as libweston or wlc. Most of the work on the wayland front seems to be going into one of those two libraries, so I'm not sure how much a new framework written in Rust could contribute (I could be wrong though!).
I think it should go almost without saying that this monad-based approach does not translate straightforwardly to Rust. So far, if I was to code in a similar style in Rust, I'd probably first look at techniques similar to what the [byteorder crate](http://burntsushi.net/rustdoc/byteorder/) does with its `ByteOrder`crate and `BigEndian`/`LittleEndian` types. [The former](http://burntsushi.net/rustdoc/byteorder/trait.ByteOrder.html) specifies a bunch of operations that do not take a `Self` argument. The latter are empty enums paired with `impl`s for the trait: public enum BigEndian {}; impl ByteOrder for BigEndian { // A bunch of operations whose signatures don't actually // mention the `BigEndian` type. Note that Haskell forbids // typeclass definitions like this one! } Then client code then dispatches on the type variable: fn do_some_stuff&lt;B: ByteOrder&gt;(arg1: X, ...) { // This `read_u16` call is statically dispatched at // compilation time, if I understand Rust correctly... let whatever = B::read_u16(arg1.get_some_slice()); // ... } This illustrates that now you can write functions like `do_some_stuff` that perform static functions calls but are neither hardcoded to which specific functions they call, but also don't dispatch on an object or vtable at runtime. This sort of trick thus lets you do a fair amount of these OOP dependency inversion/Haskell style free monad approaches; you define a trait that specifies the low-level operations that your code relies on, and let your code's clients supply their own `impl`s. It does have some drawbacks: * Unlike free monads, there is no "action" object that reifies the "execution plan." * Free monads go further that that in that the "action" object does not bind to an implementation of the operations.
There is also https://github.com/hsivonen/encoding_rs, which takes a bit of a different approach than regex, by exposing the C API and Rust API in the same crate.
Hi! This is a subreddit dedicated to the programming language Rust. You probably will get a better answer by asking on /r/playrust :)
I'd love to see a comment on this from Ethcore team. As a some what casual outside observer, my sense is that much of the resilience of Parity comes from being a 3rd generation[0] clean slate implementation of the Ethereum yellow paper and integrating a lot of hardening and optimization along the way. Parity is a great argument for Rust as a production grade systems language. [0] 1st: Python 2nd: Golang 3rd: Parity 
Potentially relevant: [How can I move a captured variable into a closure within a closure?](http://stackoverflow.com/q/28521637/155423).
I second /u/killercup's suggestion, but he should probably note that his comment pertains to server code written in the Rust programming language, and has nothing to do with Rust the game (apart from the name similarity...).
Weird then! misc$ git clone git@github.com:llogiq/bytecount Cloning into 'bytecount'... remote: Counting objects: 53, done. remote: Compressing objects: 100% (26/26), done. remote: Total 53 (delta 20), reused 49 (delta 16), pack-reused 0 Receiving objects: 100% (53/53), 13.36 KiB | 0 bytes/s, done. Resolving deltas: 100% (20/20), done. misc$ cd bytecount/ bytecount$ cargo build Updating registry `https://github.com/rust-lang/crates.io-index` Compiling bytecount v0.1.4 Finished debug [unoptimized + debuginfo] target(s) in 1.17 secs bytecount$ 
Sorry for the late response. It's hard to describe what I'm trying to do. I'm using Rust as an intermediate language for a compiler, from a language that doesn't have explicit memory management. So I'm trying to be polymorphic over different memory models, so that arbitrary code can be compiled using RC, but in the events that some functions use unique ownership, we can just instantiate (monomorphize) the function differently. 
&gt; That's not totally true: there are still functions in the Rust standard library that are very public but are marked unstable. I think having a similar feature could be useful in libraries to opt out of this engagement of maintaining compatibility, and in the meantime I'd think that if a function is documented with "WARNING: this interface is unstable and further releases might not be compatible with that" it's quite legit to change its interface without incrementing the major version. From semver.org rule #9: &gt; A pre-release version indicates that the version is unstable and might not satisfy the intended compatibility requirements as denoted by its associated normal version. &gt; the "official" rule for 0.x.y is that any upgrade might be breaking, so you really have no guarantee at all. Yes, I said that: &gt; Major version 0 is also not bound by enforcement. 
&gt; I have reviewed and tested the code and am confident it will run perfectly fine. Famous last words... ;)
It's better to think of variables and references having lifetimes, not values. A variable contains a value. A variable has a lifetime. A reference is a special kind of variable, whose value is an address to some other variable. A reference has its own lifetime. But it's also useful to think about the lifetime of the variable it references. Values can be constructed, destroyed, assigned to variables, moved, etc. They don't have the concept of lifetimes. When you create a Box::new(7), you have a value of type Box&lt;i32&gt;. Don't think of where this integer actually lives in memory nor how that memory is managed. As far as lifetimes are concerned, it doesn't matter. The same applies to Rc. Say you want to have a variable containing the number 7. You have multiple choices of achieving that: let a = 7; let b = Box::new(7); let c = Rc::new(7); All three of these variables contain values of different types (i32, Box&lt;i32&gt;, Rc&lt;i32&gt;). This way you have the choice of where this i32 will live in the memory and how it will be allocated/deallocated. How the memory is allocated for these values of three different types is just an implementation detail hidden within the depths of unsafe Rust. This implementation detail has nothing to do with the world of variables, references, and their lifetimes. To clone a value, Rust will call clone() method on it. Doesn't matter if it's i32 or Rc&lt;i32&gt;. To move a value, Rust will call memcpy() to copy it byte by byte. Doesn't matter if it's i32 or Rc&lt;i32&gt;. To drop a value, Rust will call drop() method on it. Doesn't matter if it's i32 or Rc&lt;i32&gt;. Does that answer your question? Let me know if my attempt at explaining lifetimes is unclear :)
If you want to be specific, Haskell isn't lazy but non-strict. Some evaluation are strict by default, there is memoizing, and the compiler can figure out what should definitely be strict sometimes. It's also not a dogma, but again out of necessity. Because of Haskell's semantics, strictness everywhere would mean no control flow. The compiler relies heavily on it. It sees evaluation as an effect. The community does embrace strictness where it's useful. There's easy syntax to make something strict (`!a`), and as far as I know it's the only language which allows you to change evaluation strategy either "deeply" or "shallowly". Furthermore, libraries to work with data collections/IO/parallelism/concurrency usually have strict variants where appropriate. Newer languages based on Haskell that do not have such an insane graph-based, proof-based compiler usually are strict by default. Non-strictness wouldn't be useful to those compilers and it would come with the usual big overhead in the runtime. Haskell's dogma is that everything should be mathematically provable. Even when you can't get around doing unsafe stuff, people will plead that you somehow use the type system to prove that what you're doing is correct. It's nice that it's possible, but I've seen some silly big proofs for obvious stuff. 
I thought it could be interesting to see how other languages cope with memory safety.
And only 10 days ago: [Security alert: Security alert – All geth nodes crash due to an out of memory bug](https://blog.ethereum.org/2016/09/18/security-alert-geth-nodes-crash-due-memory-bug/). It definitely seems that Parity has an edge over Geth, but being a +1 generation gives such an edge without languages coming into play.
Yeah, it lasted only 20 hours. However in Veedrac's defense, he inherited the error from my code, which in turn got it from the original ripgrep. Current bytecount no longer has that error.
&gt; Does that answer your question? I think so. So `let x : Box&lt;T&gt; =` and `let x : T =` are basically indistinguishable, except for the `box::new` and dereferencing you'd have to do to get at a boxed value. But they'll live in the same way and drop in the same way. And under the hood, one is stack-allocated and copied explicitly, and one is heap-allocated whose address is copied. But that doesn't affect their use at all. And `Rc` is the same, except it's got a fast implementation of clone using ref counting under the hood.
Not entirely. It's also a function *ahem* of your ABI and function call overhead, e.g. which arguments must be passed in registers or passed as references, or whether function preamables/postambles impose any particular overhead. Rust has far less intrinsic overhead here than certain other languages, but it has enough to still be a problem. Inlining essentially needs to always be on for any high-level language, even in debug builds, in my experience - otherwise debug builds are practically unusable in performance-sensitive applications. And inlining by itself is super friendly to debug builds - it doesn't necessarily elide or change the user's code (so long as the debug information is high quality the user won't even see that inlining happened, unless they're debugging at the assembly level) but it results in a lot less (and hence faster) generated code. That said, yes, you're right in terms of fully optimized builds - inlining is essential to being _able_ to run most other optimization passes effectively, esp. those involving any kind of code motion (e.g. constant propagation, strength reduction, devirtualization, and so on). :)
I would recommend you spin up [Ghost](https://github.com/TryGhost/Ghost). It offers a very minimal admin interface, uses standard markdown ,has plenty of customisable 3-rd party themes and a [desktop app](https://github.com/tryghost/ghost-desktop) On something like DigitalOcean, you can even do a one-click deploy and it runs fine on the $5/mo droplet, (+2mo are free with discount code `heresthething`), but since it's just a standard node.js app, it can be deployed anywhere and is even supported on the shared WebFaction host. If you don't want to deal with too many dependencies or simply want something as fast as possible that can be run for free on [GitHub Pages](https://pages.github.com), try [Hugo](https://gohugo.io).
Yes, exactly.
Not very well :-) @safe void main(string[ ] args) { @safe int[] bar(int[] arr) { return arr; } @safe int[] foo() { int[3] arr; return bar(arr); } int[] arr = foo(); writeln("Hello World!"); writeln(arr[0]); writeln("Aloha"); writeln(arr[0]); } The `arr` in main is a reference to dead memory. When I executed the above program it printed Hello World! 12 Aloha 5 But ymmv, depending on what your stack looks like.
It's worth noting that D's definition of memory safety is very different to Rust's definition. For example, dereferencing a null pointer is considered `@safe` in D. See: * http://dlang.org/spec/function.html#function-safety * http://dlang.org/spec/memory-safe-d.html
Regarding the `POPCNT` instruction: There seems to be a microcode bug in many CPUs here: http://stackoverflow.com/questions/25078285/replacing-a-32-bit-loop-count-variable-with-64-bit-introduces-crazy-performance (the top answer is a very interesting read overall, the question contains some wrong speculations)
This is more out of interest than anything else, but is it possible to get the following code to compile to a single rotate instruction when targeting x86? fn rotl(x: u64, k: u32) -&gt; u64 { (x &lt;&lt; k) | (x &gt;&gt; (64 - k)) } And the output I'm getting with -C opt-level=3 movq %rcx, %rax movq %rax, %r8 movl %edx, %ecx shlq %cl, %r8 movl $64, %ecx subl %edx, %ecx shrq %cl, %rax orq %r8, %rax retq Here's the C(++) equivalent: https://godbolt.org/g/xCgEas
Any plans to support Minisign features?
Tonight's a casual project/hack night at the Boston Rust Meetup (info here: https://www.meetup.com/BostonRust/events/234241654/ ), and I thought I'd try to spur contributions by handing these out to anyone who files a PR on a Rust project while there. :) As for Rust Belt Rust ( http://www.rust-belt-rust.com/ ), I've got a MUCH MORE DANGEROUS edition of these in mind for those who attend the tutorial I'm giving! I'll hopefully have a few of those cranked out soon, so stay tuned.
I'm happy that the Rust client is more resilient, but I'm also under the impression (not really following Ethereum closely) that Geth is the client used by a majority of users, which means that any potential attacker might have deliberately targeted weaknesses in Geth. This shouldn't imply that there exist no weaknesses in Parity (though naively I'd expect, as the OP, that Rust's reduced memory and CPU usage make attacks more difficult), especially since attacks that exploit worst-case algorithms can bring even a theoretically ideal implementation to its knees.
Interesting, they are introducing the concept of lifetimes (but not quite annotations).
https://github.com/kud1ing/awesome-rust as some links on the session Resources. http://stackoverflow.com/documentation/rust/topics may be useful.
I'm just not convinced of the whole `@safe` concept. It seems to me you'll either have to impose severe restriction on non-GC'd pointers/references (can't let them escape a function ever: this means you can't assign them to something that outlives the function invocation, and can't return them directly), implement a Rust-like lifetime system, or accept that there are holes in the system.
😻
I'm thinking C/C++ promotes `k` to a `u64` straightaway. Rust doesn't normally do implicit conversions, but shifting is implemented `Shl&lt;u32&gt; for u64` and `Shr&lt;u32&gt; for u64` (and possibly not in the most efficient way?). But if we force the conversion upfront then it compiles to the same thing: fn rotl(x: u64, k: u32) -&gt; u64 { let k = k as u64; (x &lt;&lt; k) | (x &gt;&gt; (64 - k)) } _ZN8rust_out4rotl17h58213aeb85007dacE: .cfi_startproc movl %esi, %ecx rolq %cl, %rdi movq %rdi, %rax retq 
That's the worst case scenario, which is better than now, since at least it's obvious which packages do not promise a stable API. 
Does this prevent maintainers from exposing an unstable "at-your-own-risk" API? It might be that the normal parts of your library are indeed stable, but maybe some low level API that is only intended for use with some specific associated macro package or similar is mutating. Would we be able to mark certain APIs as external, or conversely as ignored?
Please refer to rule #9 of semver.org. 
Has there been any progress on speeding up `rustc`? The build times for my project have started to get really almost unbearable. I tried splitting it up into multiple crates but it didn't really seem to help. Is nightly faster?
Wow. I did not pick a good meetup to skip! Drats.
Sorta kinda. It turns out that the largest users of procedural macros (Serde + Diesel) really needed only a portion of procedural macros: custom derive. So, macros 2.0 is the big plan for stabilizing procedural macros, but macros 1.1 is a way to get just the custom derive part of it, which is much, much easier to nail down. So, we made a decision: stabilize a bit of something so that most people can benefit, and the more complex uses of procedural macros will still have to wait.
The thread sorting changed again!
[This PR was merged recently](https://github.com/rust-lang/rust/pull/36524) which shows some nice speedups in LLVM in certain cases. Are you always building in release mode or something? 
Additionally, I highly recommend [`cargo check`](https://github.com/rsolomo/cargo-check) for making sure things compile. It skips trans, so your intermediate compile-checking step doesn't have to suffer from enabling optimizations in the debug build.
itshappening.gif
RFC 1681, procedural macros 1.1: https://github.com/rust-lang/rfcs/blob/master/text/1681-macros-1.1.md
Both work on stable today, they're just less convenient :)
I've got no less than two draft posts for Rust topics, one on game-style dev with Piston and one on web stuff with Iron. Unfortunately both stalled out around the same points I stalled with what I was trying to do. Need to stick at it and get my head around the 'Rust way' a little more I think. Something I read recently though about it not being inherently OO really struck a chord with me: I'm fully used to using structs and functions to work on them, taking an OO-style approach with a procedural language; but it had never occurred to me while reading the Book that that is how Rust works. I'd just assumed along it was really OO-focused and even though all the clues are there I'd somehow missed that. 
Thanks for the info. Added some for `tantivy`.
First line has: #![feature(test)] on it. :-/
Along the same lines (I've asked before but no response): I'd like to learn a little more about compiler optimization. I have a little experience with SMT solvers, and a lot of experience with mathematical optimization (LP, MIP, CP, QP), but I'd like to be able to leverage that to write optimizations for compilers. And since I like Rust, and I believe there is a lot of potential for optimizations that use MIR's resolved type information, I was thinking maybe I could start out by implementing a basic but fairly common MIR-level optimization. So I've got a few questions: 1) Where can I find the best documentation on the MIR format? 2) Are there any already implemented optimizations that I can learn from? 3) Is there a wishlist somewhere of optimizations that are desired in the MIR stage?
The first line of benches/bench.rs, yes.
&gt; I recently was learning about a concept called key wrapping One thing to note - key wrapping cannot be done with just any AEAD. In fact, it's [exactly what SIV was originally designed for](https://tools.ietf.org/html/rfc5297#section-1.3.1)! Without exactly the properties of a misuse-resistant AEAD, key-wrapping (sans nonce) is unsafe.
&gt; This is essentially what I'm trying to say - if the keys themselves are already diverse (and they should be, to a 'guaranteed unique' degree), I don't know what the nonce provides. See my reply to /u/sacundim above - key-wrapping actually requires more than just AEAD, and is [exactly what SIV was designed for](https://tools.ietf.org/html/rfc5297#section-1.3.1).
[Hackerrank](https://www.hackerrank.com/domains) also has a few domains where rust is enabled as a language, which also have some harder problems. The algorithms including [graph-theory](https://www.hackerrank.com/domains/algorithms/graph-theory) for example.
&gt; Apart from portability, maintenance and cost of development ...speaking as a sysadmin, this reads as "Apart from anything that makes your job humanly possible" :P &gt; there is no reason to run a database any other way What about when there's only one physical machine? My day job involves making appliances, running (yes) Linux, that need to be a single box the client can drop in to their data center. The box needs a database, and we run Postgres - but the primary job of the box is not to _be_ a database. You basically are saying there's "no reason" for a great many things that companies _really do_ to exist. IMO, they do things for a reason - understanding the incentives is important. Furthermore, consider VPS hosting which (under the "cloud" umbrella) has been growing at an amazing pace. The primary win there is _density_, and that's best achieved in three ways: 1. Pack more onto each machine - overcommit it 2. Dynamically migrate things when overcommit means you're oversubscribed 3. Reduce the overhead of running each thing you've packed onto the machine (1) Largely argues against running anything but a multiplexer/supervisor/hypervisor on bare metal. (2) is entirely beholden to portability, in a very strong sense - porting running code between machines without interruption. (3) means you want the lowest-cost way of multiplexing multiple services - and that rules out virtualization, since (as I said above) it's inherently more costly than the "process" abstraction, if both are implemented perfectly. Meanwhile, seL4 implements the process abstraction somewhere very near "perfectly". (Muen SK, possibly, does the same for virtualization). In addition: &gt; kernels impose cost becasue they try to provide services seL4 imposes a _very_ strict minimality principle. In particular, it only implements three services in the kernel: Address space isolation, synchronous IPC with asynchronous notification, and scheduling. Timers are inside the kernel only because scheduling requires them; everything else is in userspace. The kernel does not even allocate memory: If a request requires memory, the kernel informs the userspace caller of this, and the caller then may grant the kernel memory to use for that purpose. &gt; some of which are actually vestigial. See above :P &gt; You couldn't have otherwise hand written more optimal code. seL4 achieves 300-cycle one-way synchronous IPC on Ivy Bridge processors. Linux's most trivial syscall, `gettid()`, is in the low thousands.
What's minisign?
I found working on [clippy](https://github.com/Manishearth/rust-clippy) gave me a lot of insight into how the varying analysis passes work together. It's a much smaller project than Rust and we have mentored issues, so consider yourself invited.
I'm not super familiar with the workings of rustc, but as it's built on top of LLVM perhaps the LLVM chapter of The Architecture of Open Source Applications book is a good start http://www.aosabook.org/en/llvm.html 
Finished my `cat` implementation in rust: https://github.com/lunemec/rust-cate It is extremely basic, but works correctly. Also, `cate`.
this is not about laziness nor purity. he uses Scala (along with Haskell) for examples, which is neither of those. maybe the question you wanted to ask is how is this relevant to a language with not as sophisticated type system? (one can still [dream](https://github.com/rust-lang/rfcs/issues/324)) 
&gt; We do not intend to release any further version of `serde_macros`, not even to fix breakage in future nightly versions. The design of Macros 1.1 is such that we do not expect to see the regular breakage with `serde_derive` that we used to see with `serde_macros`, as it depends on a far more limited set of unstable compiler internals. I suggest marking all versions of `serde_macros` with [`cargo yank`](http://doc.crates.io/crates-io.html#cargo-yank) (perhaps waiting for when it breaks on nightly).
If you put that in context with [this rust trojan recently found](https://www.reddit.com/r/rust/comments/52hfp0/rust_in_the_wild_new_linux_trojan_discovered/), the pieces finally fall into place! It all starts to make sense now!
[Streaming iterators are not in the standard library.](https://www.youtube.com/watch?v=iKF0julgLJ4) [Here](http://burntsushi.net/rustdoc/fst/trait.Streamer.html) is a library that uses them, and it includes a nice description as to why they are a bit tricky to work with.
Hey, good to see people trying things. :) If you are interested in simplifying that code by a large part: your loop &amp; buffering &amp; `write_buffer` function are already part of a method in the standard library: [`io::copy`](https://doc.rust-lang.org/stable/std/io/fn.copy.html). It's really more or less the same as your code, see [the source code](https://doc.rust-lang.org/stable/src/std/up/src/libstd/io/util.rs.html#46-61)
Ah, that is cool, I'll try it, but I have to see if it will work with /dev/urandom for example. It should, the code looks almost the same. However I'm a bit worried about future extensibility, I'd like to implement more of `cat`s features.
Yes, I'm aware of this, I looked at the source of their `cat` for inspiration, but it seemed a bit complex for such a basic tool. Also I wanted to try it myself and use `clap` library :) And I wanted the name `cate` :D
Thanks this explains it well. 
I spent some time considering this paragraph, and I wonder if you could clarify, and confirm my conclusion. &gt; On modern CPUs, the key to making a Boyer-Moore implementation fast is not necessarily the number of characters it can skip, but how fast it can identify a candidate for a match. For example, most Boyer-Moore implementations look for the last byte in a literal. Each occurrence of that byte is considered a candidate for a match by Boyer-Moore. It is only at this point that Boyer-Moore can use its precomputed table to skip characters, which means you still need a fast way of identifying the candidate in the first place. The maximum number of characters that you can skip (e.g. using the bad character rule) is the length of the needle, so if `memchr` is (for example) 8x faster than examining every character, then it's worth using when the needle length is less than 8. Does that sound about right? And, if so, how do you determine that threshold for a given architecture?
You must mean `doge`, right? https://i.imgflip.com/md3m6.jpg
Just finishing up [implementing floating windows](https://github.com/Immington-Industries/way-cooler/pull/111) for Way Cooler, working or resizing windows (both tiled and floating) next. The new dbus IPC is nearly done, which will unblock a lot of things, most notably allow us to work on the status bar and other client programs.
Not a core developer, but I'm also interested in this and these are some resources I've found: - [The RFC introducing MIR](https://github.com/rust-lang/rfcs/blob/master/text/1211-mir.md) - [PR Adding a constant propagation pass](https://github.com/rust-lang/rust/pull/36639) - [PR Adding trivial copy propagation pass](https://github.com/rust-lang/rust/pull/36388) - There are a number of desired optimizations under the [A-mir tag on Github](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AA-mir)
They wouldn't; yank prevents _new_ projects from depending on a version, but existing projects can still continue to use it. 
... and the best way for people to notice it is posting it here https://www.reddit.com/r/playrust/ you end up in the wrong subreddit, this is about the programming language rust.
[removed]
If you want a _truly_ basic `cat` implementation, I use this one in some tests :) https://github.com/oconnor663/duct.rs/blob/master/test/cat/src/main.rs
I don't quite follow why finding a rare character would be more suited to `memchr`. Even if `memchr` is much faster than comparing every character, if the needle is long then you should still prefer skipping characters more than doing long `memchr` searches for a specific character. Or am I misunderstanding something?
Is it just me or is the PDF unavailable? 
Nit: I think it is preferable to use `.into()` instead of `as`, because it documents that you are not losing information in the conversion.
On my phone, clicking it gave weird results. On my desktop, it downloaded and opened just fine. My conjecture is that they're not sending the right `Content-Type` header, but I am too lazy/busy to check.
God i can't wait to be off of nightly. So excited for that!
I worked through this course in rust: http://ad-wiki.informatik.uni-freiburg.de/teaching/EfficientRoutePlanningSS2012 It's route finding in a graph. The course is language agnostic - all of the actual students used Java or C++, but there's no code/library integration at all. It was super helpful because the assignments were challenging, but incrementally built on each other so by the end you have a reasonably complex library. https://github.com/shterrett/efficient_route_planning
`Content-Type: application/octet-stream` Seems right to me. I was served a `link` HTTPS header though with a `rel` attribute that I think might be invalid. Didn't immediately see anything else going on, it just downloaded for me. &gt; `Link:&lt;http://www.nicta.com.au/wp-json/&gt;; rel="https://api.w.org/"`
I think you should just use `fold`. Like you said, working with `FromIterator` is hard because it requires that the type implementing it can be constructed "from thin air". A closure that captures state most certainly does not meet that requirement, nor does a struct that has a function pointer as a member. In theory it would be fine if the function pointer implemented `Default`, but since you can't name the type of a closure, you can't implement any traits for it either. If you're okay abandoning closures, you can easily define a new type: struct PrintFoo; impl&lt;A&gt; std::iter::FromIterator&lt;A&gt; for PrintFoo { fn from_iter&lt;T&gt;(iter: T) -&gt; PrintFoo where T: IntoIterator&lt;Item=A&gt; { for _ in iter { println!("Foo"); } PrintFoo } } But it's just way more attractive to just use `fold`.
As others said, this isn't necessarily the best way to do what it does, but I found a way! The key is that function types and stateless closures are zero-sized because there's only one possible value. So given the type, you can construct a value out of thin air. (0..10) .collect::&lt;Runner&lt;_,_&gt;&gt;() .specify(|x| println!("{}", x)); Here's my annotated implementation: [playground](https://play.rust-lang.org/?gist=77b05e1dc68c04a377b77a78648f001e&amp;version=stable&amp;backtrace=1)
Btw., may I ask you one more thing about it? When you flatten the Bezier curves, the cited paper talks about flattening "offset" curves but in the code you seem to flatten the "path" curve. Assuming I understood it correctly, why's that? Is it because in the later case you flatten the curve only once, and perhaps it is easier to tesselate the thick curve when there are the same number of vertices on both sides of it? And have you perhaps tried different algorithms as well?
This looks like a great update, tons of sweet stuff! Thanks everyone who contributed 💖💖💖
So what's the best way to get (Neo)Vim and (Spac)emacs to handle new error formats right? Last time I tried my spacemacs was hanging on `SPC e n` and my neovim was opening `--&gt; src/lib.rs` files instead of `src/lib.rs`. :)
Great job, team. I didn't carve out time to chip in on the [big campaign](http://www.jonathanturner.org/2016/08/helping-out-with-rust-errors.html) but I'm glad to hear it was so successful. Please let /r/rust know if there's another similar round of low-hanging fruit in the future.
I love the name of this conference, Rust Belt Rust.
Some previous discussion: https://www.reddit.com/r/rust/comments/543qa3/gcpp_deferred_and_unordered_destruction_cppcon/
There's an open PR on the `rust.vim` repo to add support for the new error format. Seems like `rust.vim` could probably use some love https://github.com/rust-lang/rust.vim/pulse
I mentioned to someone on twitter that I'd be interested in adding more maintainers to `rust.vim`. If anyone is, we should all talk about it.
Is this paper somehow connected to [Mu µVM research](https://research.csiro.au/data61/microvm/)? Can we expect more bits of the VM being implemented in Rust?
Has `cat` ever had a buffer overflow vulnerability that this would protect?
Really enjoyed reading this while knowing very little on the implementation side of garbage collectors. I feel like I now know at least something :)
&gt;extra: All crypto functions have been removed and Rust now has a policy of not reimplementing crypto in the standard library. In the future crypto will be provided by external crates with bindings to established libraries. So to do any crypto, we'll have to hope an external crate keeps maintained? It seems odd that a function so important to modern code is something not shipped with the language. Unless I'm misunderstanding.
This comment is from 2014. A lot of things were very different then. Remeber, the Rust team itself also maintains several "external" crates. So it's a little more nuanced than that. But really, we don't want to put crypto in the stdlib at this time for a few reasons. Namely, none of us are cryptographers. Secondarily, there hasn't been much pure Rust/asm crypto being developed, though *ring* is very interesting. We would do a lot more harm by putting bad crypto in the stdlib than we would by having none at all.
It's an important target because it's the primary way people get fully-statically linked binaries on Linux. It's support was requested by a lot of people.
What are the benefits of this over shared_ptr and weak_ptr?
&gt; crates.io itself isn't really aware of that How should crates.io be made aware of that? Asking for a friend...
Since when did the core team decide to market the language as unproductive?
I'm confused, it says the opposite?
Ha, I subconsciously added "safe" into the new slogan. I'm so used to seeing it. Cheers!
No worries! :D
Check for free disk space, I had a similar issue this week and it was that ;-)
Ring has never been audited and we aren't even sure of the cryptographic value of LWE. imo, and no disrespect to the creator of ring because this kind of thing takes time and money but it's not verified secure crypto, it should not be used for anything substantial. For it to be interesting it needs to be audited. I'm not saying Rust has other pure-rust options, I'm saying that maybe Ring is currently a non-option when we're talking about "good-crypto". This is not a dig at the Ring developer, this is a serious concern, relying on unvetted crypto (and even some "vetted" crypto see Dual_EC_DBRG) is unwise, we should stick with binding to tried and true C libraries until we can afford a cryptographer and a team of auditors to put our best foot forward here. The real discussion for rusts crypto situation should be: ~~1) Are we willing to assume LWE is secure~~ ring does not implement ring LWE so ban this. 2) Is there anyway we can generate the money necessary for an audit. * No audit needed * Need money for test automation * Formal methods? Cost? 3) Is there anybody we can even /pay/ for the audit of a pure rust crypto library. *No audit needed Full disclosure: I totally use ring-lwe for a hobby project.
Right, this is what I mean: *ring* is the best we have here, and there's still all of these kinds of problems. This stuff will take time, effort, and money.
/r/playrust
derp
Congrats to the team and thank you! As always, I've updated my Docker image for 1.12. Both the "1.12.0" and "latest" tags are now 1.12: https://hub.docker.com/r/jimmycuadra/rust/
https://groups.google.com/d/msg/mozilla.dev.servo/pt1ywXbG54M/LHG5a_xKBgAJ is the closest thing i've seen to stuff like this.
Just want to say thank you for that image. I use it for building and releasing all my open source Rust programs.
Yes: https://github.com/dlang/DIPs/blob/master/DIPs/DIP1000.md
Well, it's still a bug. `ENOSPC` or its Rust `Err` value equivalent should be returned, and communicated to the end user.
Yes, this would be great
[Alpine Linux](https://en.wikipedia.org/wiki/Alpine_Linux) is a fairly popular distribution in the Docker ecosystem since it's so lightweight, and it's built on musl.
i think that maybe "owners" got a bit more broad since the discussion was originally had?
&gt; rump kernels I haven't seen this term before. After googling it sounds like the same thing as a unikernel. Are they the same? Or is there a distinction that I'm missing? 
What do you mean by "more broad"? That there can be more than one owner? Doesn't being able to go to the "owned by piston group" page solve this problem? Also who decides who owns tags? It'd be the you-know-what problem all over again...
Here's the code if anyone's interested: https://gitlab.anu.edu.au/mu/immix-rust What I really enjoyed about this paper (besides the conclusion and praise) is that it demonstrates that a tricky problem, which you'd assume to be *particularly* tricky in Rust, can be implemented in such a beautifully idiomatic and thoughtful way.
Yeah, especially the minimal unsafe. If anything, you'd expect a GC to use more of it than average.
There are some minor differences if you really care, but in general, a rump kernel is a kind of unikernel.
&gt; Ring has never been audited One of the main points of *ring* is to be so small and simple that it is easy to understand the code and find any flaws. I've tried to make it especially easy to read the diff from BoringSSL. I encourage *everybody* to read the code, write tests for it, fuzz it, and report the results publicly, preferably in the *ring* issue tracker on GitHub or somewhere else where people can see them. In general, we try to use automated testing to make auditing obsolete, but we haven't completely succeeded yet. In the future, if/when we can afford to do so, I hope to use formal methods to prove the code is correct; however, there are limitations even to things we consider to be "proofs." &gt; we aren't even sure of the cryptographic value of LWE. *ring* doesn't implement Ring-LWE and has nothing to do with it. &gt; imo, and no disrespect to the creator of ring because this kind of thing takes time and money but it's not verified secure crypto, it should not be used for anything substantial. No disrespect taken. &gt; Is there anybody we can even /pay/ for the audit of a pure rust crypto library. If I had a budget for convincing people that *ring* is safe to use, I would spend it on test automation and formal methods work, not for the creation of an audit report.
I tend to use the terms synonymously, but I'm not an expert. :)
Great article!
Bought a book about opengl game programming in c++ for beginners, and i'm now following the book with rust and glium.
Rust may not need it. But I thought it could spark some discussion around side effect management. Although Rust is not pure, it is after all kinda descent from ML. Waiting answer with you. 
Good article. I have a bit of constructive criticism: explain the semantic meaning of the Trait bounds of the generic. You list the code, but not how the bound achieves the desired implicit `i32 -&gt; Option&lt;i32&gt;` conversion. 
Someone managed to bring down the server overnight but I had unfortunately misconfigured the logging :(. The server is up again now but I'd be very grateful If I could learn of the code that caused there error so if you think you may have sent something that broke it I'd be happy with an example at https://github.com/Marwes/gluon/issues/171 (or just evaluate it again and the server will log it now).
That's a new technique to me. Is this technique described elsewhere? It looks like a good candidate for an Effective Rust section.
It's probably a thing that never had a blog post! It can save a lot of time sometimes: https://github.com/PistonDevelopers/image/pull/518 I'm sure there are cases where it doesn't save time, or even costs you performance (more inlining / specialization = better code?), but in most cases you don't care about that. File::open is a good example.
Ah, I was thinking about something similar several times. The best you can do is to use `enum { Boxed(Box&lt;T&gt;), RCed(RC&lt;T&gt;), }` and impl `Deref` for it.
It should work in spacemacs out-of-the-box if you have a relatively recent version of flycheck. So in case it doesn't work for you, updating your packages might help.
I went through this briefly. A downside here is that you need null checks everywhere to be safe, since the collector nulls out pointers to break cycles. This is equivalent to enforcing that `Gc&lt;T&gt;` be wrapped in an `Option&lt;&gt;` (or internally making it have an optional deref). This solves the specific problem wrt destructor order and finalizers. A more general solution called "Detach" to this was proposed by https://github.com/eternaleye, where all GCd things implement a Detach trait. Things like options and vecs which can be used to break and create cycles use this trait to do so. It seems like the cycle collector would be possible using the `Trace` trait proposed in the Rust GC hooks (you don't need the actual tracing/rooting hook for a CC). So far we haven't settled on a solution for destructors, but if we leave it to the implementors then this kind of model would still be possible. Still is extremely good for C++. I'm hoping we can do better in Rust wrt finalizers.
Alright, thanks for the tip
Well, I had to carefully think through how the Trait bound would accomplish the conversion, and that's after seeing the code. I'm not sure if I would come up with it myself... 
Yeah, that would work but now there's runtime overhead. I'll keep exploring! 
Just about to port my tojson-macros crate to Macros 1.1. Checked serde's implementation I find we may need a bridge between `TokenStream` and previous API. `syn` is pretty helpful but serde still has a relatively large code base (serde-codegen-internals) to bridge them. Is there any example demonstrates the designed usage of `TokemStream`?
Wow, that's a really cool trick. Do you think in the future `rustc` could be clever enough to optimize this itself? (In the meantime I updated my blog post to include this.)
I wrote my thoughts in another comment here: https://www.reddit.com/r/rust/comments/554skr/how_do_i_set_up_memoization_for_a_function/d888evv
I would of tought, *optionals* is the abstraction for the caller, *defaults* is the abstraction for the callee.
Could we have something like this: impl&lt;T&gt; From&lt;()&gt; for Option&lt;T&gt; { fn from(_: ()) -&gt; Option&lt;T&gt; { None } } To save some keystrokes? That way, you could do this: fn foo&lt;I: Into&lt;Option&lt;usize&gt;&gt;(bar: I) -&gt; usize { bar.into().unwrap_or(42) } fn main() { foo(()); // =&gt; 42 } IDK, maybe it wouldn't save much, but I think it looks nicer than `foo(None)`.
That's very cool - I wonder if you can take advantage of rust's stricter aliasing rules to be able to treat more pointers as non-aliasing and therefore obtain proofs more easily than the equivalents for C-like languages.
As nice as this is, I hope people won't treat this as the "final" solution for optional arguments. It's way too hacky and inconvenient to use for that: - `Option&lt;T&gt;` is larger than `T`, if `T` isn't [Zeroable](https://doc.rust-lang.org/core/nonzero/trait.Zeroable.html). True support for optional arguments would allow encoding default values without having to use `Option`. - You still have to pass `None` if you want to omit an argument. - Due to the use of generics, it can blow up compile times, and needs hacky workarounds to avoid doing so. See [this thread](https://www.reddit.com/r/rust/comments/556c0g/optional_arguments_in_rust_112/d882uc6). I hope that instead of trying to [build upon](https://www.reddit.com/r/rust/comments/556c0g/optional_arguments_in_rust_112/d889mrz) `Option::from` for optional args support, people will put more attention on [this RFC issue](https://github.com/rust-lang/rfcs/issues/323).
Thinking about it more, you can go several steps further: - Immutable borrows, while aliasable, are guaranteed not to be affected by assignments, so for all intents and purposes you can treat them as non-aliasing. - You can use the type system to determine whether two things might alias. Given that rust does not have a defined layout, you can assume that no two variables of different type alias unless one contains a field of the other type.
&gt; You can use the type system to determine whether two things might alias Almost. I need to be able to reason about unsafe programs too, but otherwise, you're right. The correctness checking of the safe parts can be reduced a lot (perhaps even to the point where the reasoning is not much different from classical Hoare logic).
I really hope optional (as exists in C#) never make it into Rust. Those just asks for lazy / overly-generic / "which of these 12 arguments do I need?" APIs.
I'd guess it would take &lt;100 K to get a suitably skilled person like Watson Ladd/ Brian Warner to audit ring. I don't think it would be a huge amount of effort. The primitives are from BoringSSL and set of cryptographic operations are a small surface area. Probably the only value to do this would be position ring for the STL. The incremental user safety benefits would be small. The approach of really pushing on fuzzing, testing and formal methods Blockstream has taken with libsecp256k1 is a better example of what you can do with a larger budget.
Rust's aliasing rules are less strict in some ways too (no type based alias analysis, a.k.a strict aliasing).
The serde-codegen-internals bridge is only for [attribute](https://serde.rs/attributes.html) parsing. We walk the `syn` AST to parse the attributes and build them into an internal AST. If you are not using attributes, just use the `syn` AST directly. See [num_macros](https://github.com/rust-num/num/blob/master/derive/src/lib.rs) for a very simple example of this.
I can't really comment on things unless you give some code, but those results don't look particularly surprising if you've implemented `to_camel_case` directly in Ruby, since Ruby is relatively slow. I bet you could speed up the Rust version, though. 
Yeah, I dislike C# optional arguments most of the time too.
&gt; I'm sure there are cases where it doesn't save time, or even costs you performance (more inlining / specialization = better code?) Considering how small the generic function is, I assume Rust or LLVM will inline it anyway, and possibly the non-generic wrapped call as well.
That's my point. In POSIX enter is represented as \n, but that doesn't apply to all operating.
It reduces it a lot for release mode too, when it applies, like in the image crate example.
&gt; But what about compile times? The next release has some good speedups in it. But in general, this work is paving the way for better compile times. &gt; it seems to me that Rust is lagging behind to other languages. It really depends on who you talk to. I know Scala people that feel Rust is super fast, but any Go person would think Rust is unimaginably slow.
No, my point is that the _stdin_ represents enter as \n on virtually every operating system (including Windows).
Yes I understand that, what I meant was that given the size of the generic wrapper I'd assume Rust and/or LLVM are able to go "through" it during compilation and inline the wrapper and whatever it ends up calling.
I pushed v0.17.0 of [Rusoto](https://github.com/rusoto/rusoto) out the door just before Rust 1.12.0 was released. Big release because all of us maintainers were busy with day job things for a while. Huge thanks to [cmsd2](https://github.com/cmsd2) for creating codegen to create and execute response parsing tests. It's been a great help in speeding up development and gives us higher confidence in our code. On the agenda this week is to close out some old tickets and start the push for S3 client code generation.
Not using LTO is the default, so to describe release mode that's appropriate.
Yeah, but I'm wondering what impact it has with LTO. None? Still makes it better? Makes it worse?
[Looks like builds are working again](https://travis-ci.org/rust-lang/book/builds/164020983), thank you /u/brson!!! &lt;3
Indeed-- I'm just trying to gather inputs for the design work :) Answers to questions like: - What problem are we trying to solve here? (I think it's "indicate which crates on crates.io are owned by the core team") - What is insufficient about the current solution to this problem? (clearly showing "The Rust Project Developers" under owners isn't enough, but I'd like to dig into *why*) - If we had a page that listed all the crates a particular group owned, what would still be insufficient about that? - What problem would tags solve that other solutions don't solve, and why?
Very nice write up, I'm eager to read about the details of your memory model. I'm not too acquainted with separation logic, so what I wondered after reading the post is: What would writing through an aliased pointer look like? Also, did I understand you correctly that you're working on your own Rust compiler, and a verified one no less? That does sound like an ambitious project!
I installed bash autocomplete for cargo from the repo, but it's tripled the startup time of my shell. Any solutions? Edit -- sourcing the completion file takes 0.165 seconds
It would be not just core team, but any particular group. Think of it as an alternative to namespaces ;) &gt; If we had a page that listed all the crates a particular group owned, what would still be insufficient about that? I think this would help a lot. I sort of view this tags thing as a strongly typed version of what you're talking about: right now, anyone can just put "The Rust Project Developers" as the authors, and it would get included. Having this kind of grouping mechanism for real would prevent that.
It probably makes it better irrespective of LTO. It just means there's less total mass of code for the optimizer to chew through. It certainly helps when the function you're de-genericizing is big enough that the optimizer doesn't inline it.
My poor results were mostly because of my test data. I was searching the first 100k digits of PI for a subsequence that I know appears near the end. Obviously this is not playing to `memchr`'s strengths because it will find a match on average every 10 characters. Having adjusted the test case, I'm seeing `memchr` performing up to 80x faster. Even with a needle length of 100 characters, designed to always skip 100 characters per iteration, `memchr` alone is 3-4x faster. When I use them together, I get the best of both worlds! 
&gt; right now, anyone can just put "The Rust Project Developers" as the authors, and it would get included You mean that anyone could put "The Rust Project Developers" as the author in their Cargo.toml, but right now you have to add a github group as an *owner* and crates.io ensures that you are a member of that github group, so not anyone can add "The Rust Project Developers" as an *owner* like [regex has](https://crates.io/crates/regex). Just wanted to make the distinction clear for anyone reading this. Maybe we shouldn't show author on crates.io and should only show owner? This does continue the stranglehold github has on crates.io, though.
Hey /u/ticki_, why is MIR easier to model?
Ah ha! I misunderstood that bit.
:+1:
Scala's too (though as a method call, so change in the default value doesn't require recompilation).
I just tried to execute an infinitely recursive function and cannot connect to the server anymore... EDIT: I ran a local version of the server and tried recursion but it didn't crash. I guess somebody else crashed your server while I was testing it.
Yes, you have our permission :-)
Oh I see. `keynum` in the code. Yeah, it's just a random ID for the key, completeley independent of the actual key. It's only used for checking that the signature was indeed created by the key at hand. It's not necessary to check that, and in fact [I only recently do so in my code](https://github.com/badboy/signify-rs/commit/db9443865accec58556ed2b7b20c7413f1044341). Not sure why it was added in the first place.
https://doc.rust-lang.org/book/getting-started.html
No.
I agree with thiez.
I started writing a library to extract the contents of [XNB files](http://pcsupport.about.com/od/fileextensions/f/xnbfile.htm), which it turns out now requires writing an [LZX decompression](https://en.wikipedia.org/wiki/LZX_(algorithm\)) implementation.
If you are specifically looking for 'wide string' support for interaction with windows API, I [found](https://crates.io/search?q=wide%20string) these two: https://crates.io/crates/widestring https://crates.io/crates/wcstr 
I wonder how that 'rust language vs rust the game' classifier would do on this question :)
Well, the answer is "yes" either way, so maybe it doesn't make a difference
There's nothing in the compiler for this; someone just added a (reasonable) trait impl, and that made this pattern possible.
This is about 10x the speed of the inflections library: use std::ascii::AsciiExt; pub fn to_camel_case(string: &amp;str) -&gt; String { let mut out = String::with_capacity(string.len()); let mut next_upper = false; let mut next_preserve_upper = false; for ch in string.chars() { if is_seperator(ch) { next_upper = true; next_preserve_upper = false; continue; } if next_upper { if ch.is_ascii() || ch.is_uppercase() { out.push(ch.to_ascii_uppercase()); } else { out.extend(ch.to_uppercase()); } next_upper = false; } else if next_preserve_upper { out.push(ch); next_preserve_upper = ch.is_lowercase(); } else { if ch.is_lowercase() { next_preserve_upper = true; out.push(ch); } else { if ch.is_ascii() || ch.is_lowercase() { out.push(ch.to_ascii_lowercase()); } else { out.extend(ch.to_lowercase()); } } } } out } It's not massively optimized, but 10x is a start.
yup, as in jsonapi.org :-) I'm making extensions for Rails' active_model_serializers to speed it up
No, the ASCII optimizations only speed it up a factor of ~1.5 (and it works with unicode, even if at a slight speed cost).
So, I love the videos. As someone who has been trying to branch out into new languages, they're very informative. But I kind of have a problem with how they start. If you're going to show me in a video how Rust works, you don't need to first convince me why I should use Rust. I'm already here. I probably wouldn't be watching the video if I weren't already interested in Rust. But that's a minor thing. It's just a thing I see in a *lot* of similar videos,and it always irks me. 
So I tried to minimize the intro by pushing it into a separate (and skippable...) screencast. But I was wondering if I should just cut it from "Hello, World!" entirely. Perhaps I will.
Yup, I'm NullVoxPopuli on github / AMS Slack. :-) Just waiting on a PR from beauby for a bugfix in his jsonapi gem before I can have my pr to ams have support for case_transfrom-rust-extensions :-) https://github.com/rails-api/active_model_serializers/pull/1928#issuecomment-248793075
I'd definitely mention "If you want to know *why* you should use rust, check out this video". Like I said, it's a very minor complaint. I just see it so often I can't help but point it out. Still a great series, and I'm enjoying working through the exercises!
I did try using a build script. The problems I had were: * No discernible effect even when passing `--verbose` to cargo. For all I know cargo was ignoring my script (I did mention it in the `Cargo.toml`). * The command line to `link.exe` didn't seem to change. The only thing I've had any luck with is to go into the `ears` package and modify the `Cargo.toml` to have a `links = "OpenAL32"` in in the package section. I don't understand how `links` in the .toml is related to having a `links` attribute in the rust code, but when it's mentioned in the .toml file then the cargo config seems to get activated. It's pretty frustrating trying to introspect cargo build issues :/
This is a tremendous amount of work to produce great output like this.
Thanks!
&gt; I'm watching the videos now, perhaps you explain it very well - but i've watched, read, and even paid for Rust content, and it's still not totally grepped. I'd love some more feedback on how I can make this more clear. One thing I was contemplating is a video that specifically explains the idea of "the stack" and "the heap" and so forth. I'm not quite sure if that's what you are asking for, but it seems related. =)
If you're referring to the game Rust, then you want /r/playrust 
That might actually be it. There is a timeout after ~10 seconds but I may have forgotten to add a stack growth limit (the heap is limited however) which can easily cause an out of memory error (which I got this time https://gist.github.com/Marwes/825b1ff9f5484f1ccdfb0eba9f828286) due to how small the ec2 instance is. EDIT: Yep, this crashes the server. 99% sure it is the vm's stack which consumes all available memory. let factorial n : Int -&gt; Int = n * factorial (n - 1) factorial 10
Ah I must admit when I tried a build script the only way I could get it to find all the required binaries was to use the [gcc crate](https://crates.io/crates/gcc) and build the C/C++ dependencies right there (despite its name it can compile things with msvc just fine). I'm not sure if this is helpful but [here](https://github.com/alexcrichton/gcc-rs/blob/master/src/lib.rs#L356) is how it tells cargo where to look for the compiled artifacts.
There's still `repr(C)`, and the representation of a struct with a single member is de facto defined.
Does this mean that this is broken? https://github.com/droundy/arrayref. Lots of things are using such macros to cast a `&amp;mut [T]` to `&amp;mut [T; N]` for some constant `N`.
Hmm that doesn't turn out to work all the way, it still requires an explicit bound on `T::Err`: use ::std::str::FromStr; use ::std::string::ToString; use ::std::error::Error; trait Value: Clone + PartialEq + FromStr + ToString where Self::Err: 'static + Error {} fn set&lt;T: Value&gt;(var: &amp;mut T, val: &amp;str) -&gt; Result&lt;(), Box&lt;Error&gt;&gt; // Still requires this explicit bound... /*where T::Err: 'static + Error*/ { let val = try!(val.parse()); *var = val; Ok(()) } Playground: https://play.rust-lang.org/?gist=0d9c05bb12d4c5a7635a93e589fff1f8&amp;version=stable&amp;backtrace=0
Thank you! I will check num_macros.
I don't see any mention of Mongo, Express, React, NodeJS, Redux and/or Webpack.
haha, yea
Can someone explain where could this GC be used? In another managed language like java or python?
Yeah... I think this is a compiler bug.
`&amp;mut [T]` is a supertype of `&amp;mut [T; N]`, at least according to the coercion rules. It'd have to be, or else the built-in coercion from `&amp;mut [T; N]` to `&amp;mut [T]` would be broken!
&gt; this took me forever to grep maybe try ag or ripgrep
You're probably not getting those last two things any time soon. Rusy used to have green threads but got rid of them because supporting them was limiting the rest of the standard library and performancewise they didn't have much advantage over ordinary threads. I don't think Rust will ever replace Haskell, we don't even have monads and `do`.
&gt; does it even make sense to distinguish 'scripting' languages? I was recently making a similar argument to a co-worker and he pointed out that it can be useful to have a distinction between code you write in order to build and run later and code that you wrote to run immediately. The latter is a pretty good use of the term scripting. Edit: I just realized I misunderstood you. I'm going to leave my comment anyway.
This week in Rust is edited by hand, namely by /u/nasa42 and me (though I'm off for a few weeks currently), whereas this seems to be automatically generated. There is no affiliation I know of.
Yeah, the distinction used to be much clearer. But these days we have languages like Java and C#, which are *not* considered scripting languages, that compile to bytecode and then get jitted at runtime. Then we have Python, which is considered a scripting language, which generates bytecode (.pyc) or compiles to the .net platform and gets jitted, depending on which implementation you use (e.g. cpython vs ironpython). The distinction has become meaningless.
So... Does this mean that we'll be able to create web applications in Rust in the future?
Everything? In reality, Rust mainly replaces C++ for me. Python still finds use in some small scripts, and I've managed to avoid most JVM and .NET projects. There's still more C++ code I'd *like* to replace with Rust, but there's not always time to do so.
Julia?
Let alone "strongly typed"
Would it make sense to write a library in Rust that provides an interface to the DOM? How would you do that? Are there asm.js/wasm intrinsics?
For asm.js, you can use `asm!` to directly write Javascript code that will be in the compiled code, but you can also use an FFI function provided by emscripten that wraps around `eval`, or you can write a glue Javascript library, ask emscripten to include it, and call it through FFI. For wasm, I think the situation is a bit unclear. 
&gt; basic I/O I would write it like this: let mut input = String::new(); std::io::stdin().read_line(&amp;mut input).expect("some message"); let x: i64 = input.parse().expect("some error message"); I don't think it's more complicated than a solution with exceptions and try/catch.
&gt; AND forces the original developer to write large match TFA doesn't have a single match statement, why would you need anything other than `unwrap_or`/`unwrap_or_else` for this use case? &gt; worse sort unwrap statements at the start of a function. If you use straight `unwrap` they're not optional and thus not covered, the methods used in the article have pretty much no relationship with `unwrap` aside from the name: they don't panic, they're used to provide default values where you got an optional one.
This seems really nice, thanks! Can you consider allowing the contributions to subtitles translations, on these YouTube videos? I may give it a try for a french translation.
I very like this work, thanks But as far as I know there is two ways to target wasm one with llvm and emscripten the other by compiling in wasm directly from MIR and using binaryen. what is the interest to have those two projects ? I would love explanation.
Learning Rust is no big deal , the question we need to ask, how do we move on to mainstream production with use of Eclipse IDE and debugging in it; because its very disturbing to see next to none posts regarding wizards and IDE debugging regarding Rust, this is very dangerous and can kill Rust the way great it could be.
This looks like the right tool. Thanks!
No problem. Enjoy your wedding. And congratulations! I might pester you after I notice your github activity ramp up again in a few weeks time :)
As I understand it, the webassembly backend in LLVM is intended to be the main target long-term. Until it's reasonably mature, emscripten (with its non-upstreamed patches to LLVM) is the best or only choice for targeting browsers, compiling to asm.js.
If you just want to play Rust: https://play.rust-lang.org/
There are a number of potential pipelines for producing wasm. This one uses the emscripten [fastcomp](https://github.com/kripken/emscripten-fastcomp) backend to produce asm.js-compatible LLVM IR, which is then sent through the emscripten emcc compiler, and linked with the emscripten runtime. Another is to produce wasm directly from mir, [mir2wasm](https://github.com/brson/mir2wasm). A third is to use the in-progress LLVM wasm backend to produce wasm from LLVM IR, without going through asm.js first. The technique we're using today (LLVM -&gt; asm.js -&gt; wasm) is the worst of the three. The reason is that it relies on the emscripten fastcomp LLVM backend, which does not live in the upstream LLVM tree. To make it work rustc must produce LLVM bitcode that emcc understands, which means the two projects have to keep their LLVM forks in sync, with Rust incorporating parts of fastcomp, and if the user combines the wrong versions of rustc/emcc the toolchain won't work. We expect to migrate away from this approach in the future. This pipeline does produce more optimized wasm than the LLVM wasm backend today, but I wouldn't expect that to remain true. Mozilla and Google are working on a wasm backend in upstream LLVM that should for our purposes replace the fastcomp backend sometime in the future, though it is unlikely to be ready by the time wasm is deployed in web browsers. At that point we can use upstream LLVM to generate wasm directly. Rust will still likely depend on emscripten for its runtime (libc ported to the web), and to compile C code, though it seems likely that over time the wasm ecosystem will depend on emscripten less, with clang supporting wasm directly, and the emscripten runtime being factored out of the emscripten toolchain. When rustc emits wasm directly, we will not need to port the fastcomp patches to our LLVM fork, and will presumably not be coupled to emcc by the LLVM IR version (though now that I'm thinking about it again the details aren't clear to me). The downside to moving to the wasm backend is that rustc would no longer be able to emit asm.js. It is feasible to convert wasm back to asm.js, but it's significant effort that nobody is committed to today. The mir2wasm approach is more speculative, and needs a lot of dedicated person-hours to finish. If it were to be completed the main advantage it would offer is a backend that is much faster to compile than LLVM.
This has been a long time coming, thanks to tomaka17, badboy, rschulman, and others' work over the last 9 months or so. We're still not over the finish line yet, bet we are close. The current patch set allows building both asm.js and wasm targets using the stock Rust master tree. And for the asm.js target at least the test suite passes, modulo many I/O subsystems that aren't supported by the emscripten runtime, and miscellaneous bugs. The wasm target isn't supported by the test suite yet, but it works in cursory tests, and I presume it basically works, since emcc's asm-&gt;wasm conversion is well tested. If you want to try it you can build the asm.js or wasm targets you can get a working toolchain with commands like the following (not tested locally): curl -O https://s3.amazonaws.com/mozilla-games/emscripten/releases/emsdk-portable.tar.gz tar -xzf emsdk-portable.tar.gz source emsdk_portable/emsdk_env.sh emsdk update emsdk install sdk-incoming-64bit emsdk activate sdk-incoming-64bit git clone https://github.com/rust-lang/rust &amp;&amp; cd rust ./configure --enable-rustbuild --target=asmjs-unknown-emscripten python2 src/rust/src/bootstrap/bootstrap.py echo 'fn main() { println!("Hello, Emscripten!"); }' &gt; hello.rs build/x86_64-unknown-linux-gnu/stage2/bin/rustc --target=asmjs-unknown-emscripten hello.rs node hello.js For the target, `wasm32-unknown-emscripten` should work as well, and you can also configure with both targets at once. The next step is to get automation set up to build these targets against pull requests and to produce nightlies, so they can be installed with rustup. I hope to have that done next week. If you are interested in helping the best things to do are: - Test the port against your own code (it should work with cargo) and fix and file bugs. - Fix failing tests in the test suite. - Come up with compelling Rust on wasm demos. I can't stress enough how useful this is. If we can have an attractive web page ready to go showing Rust doing amazing things on the web on the day wasm launches it will be a sweet win for us. Besides emscripten with C/C++ no other language is close to where we are in supporting wasm. Rust can be _the_ language for targeting the wasm web, and if we get out ahead of it we can burn that impression into peoples' minds from the start. You can track progress of the emscripten port on the [irlo thread](https://internals.rust-lang.org/t/need-help-with-emscripten-port/3154), and the [issue tracker](https://github.com/rust-lang/rust/issues/36317).
You may want to try out the secrets crate.
It seems to me like you're confusing two things here that are orthogonal: /owned vs borrowed/ and /stack vs heap/ These are not related concepts. A piece of data can be any combination of (owned | borrowed) x (stack | heap), i.e. * owned and on the stack * owned and on the heap * borrowed and (the data being referenced) on the stack * borrowed and (the data being referenced) on the heap There's lots of info on stack vs heap, and I don't think I can explain this any better than other resources, so I won't. But for borrowed vs owned in general as well as specifically about String vs &amp;str: &gt; "but eventually &amp;str started to make more sense when i thought of it as always owned by someone else. I used String if i wanted to own it, and if i wanted to borrow it, i could deref it to a &amp;str." This is exactly how you need to think about it. When programming in Rust (and other non-GC languages?) you always need to be clear about *who owns that piece of data*. Basically anything that has `&amp;` in its type signature you do not own (and so "someone else" owns it), but everything that does not have `&amp;` in there you do own and you decide everything about its life and death, move or borrow, mutable vs immutable. So with this mode of thinking that you've described and that I tried to elaborate on you should have a really good foundation for understanding, as well as working with effectively, borrowing and ownership. And last note: It's a bit confusing that Rust has a special type `&amp;str` for a string slice, as opposed to just "normal" slices for everything else. But if you just think of a string slice as not really different from a regular slice (except it does have a few distinguishing properties like being a layer on top of the raw byte content in memory; but that does not matter for borrowing and ownership), then it becomes really clear how to view &amp;str and String with regards to borrowing and ownership. EDIT: formatting &amp; minor clarifications
[bots](https://twitter.com/BringerShar/status/782241936329601024 ) I made very simple bots too start testing multiplayer part with more than 2 players :) 
Rust doesn't need IDEs and debuggers. It's not Java. Just grab yourself a copy of Atom, Install Tokamak, and install racer and clippy along with the Rust source code and configure the Rust linter to use Clippy.
&gt; I mean you can build a browser on top of it and normal users won't complain about web page not being rendered correctly. Unfortunately, no browser has ever met this requirement. :) Layout bugs are never-ending even in production browsers. &gt; Which percentage of the HTML CSS spec has already been implemented ? Most of it has been implemented. If you're *just* talking about the CSS spec, we have support for essentially every property in use.
Yes, rustup will be able to install both targets. I will try to make that happen next week.
I have not heard anything about the schedule for actually putting wasm on the standards track, but there will be preview release soon. Both Google and Mozilla are actively working on wasm, and there's reason to suspect the other vendors will follow, so it seems likely to become a standard. Finding a short-term killer feature for wasm has actually been worrying me. A lot of the really tantalizing stuff is going to require lots of experimentation. I think there are three basic use cases for wasm: _CPU-bound libraries to plug into typical JavaScript code_. This is the best short-term way to producing something actually useful. The problems here are identifying something that does enough CPU-bound work that crossing the FFI is worth it, that the web platform doesn't already implement, that JavaScript coders actually want, and figuring out an ergonomic way to present a JavaScript API from Rust. Crypto, hashing, numerical, scientific things are all obvious candidates, perhaps image manipulation, codec polyfills. We might pick one of these domains where Rust is already strong, and where there's some competing JavaScript library, and show Rust crushing. Another tantalizing possibility is creating a decent audio-graph library for complex audio processing; the web audio APIs are notoriously difficult and one could imagine just short-circuiting the whole mess with high-performance Rust. It may be possible to take some of mitchmindree's work and port it in relatively short order. _Replace typical JavaScript frameworks with Rust ones_. This is ambitious and requires a lot of work. The obvious problem is that you need to avoid FFI as much as possible so there will need to be clever tricks to make it performant, up to duplicating much of the what the browser is already doing, ala React. _Porting typical fat applications to the web_. This is what emscripten is already good at - just take some graphical application and port in wholesale to the web. There's definitely some attractive demos we should get out of this. Take some of the stuff tomaka, mitchmindree, etc have been working on and compile them to the web. Maybe we could even convince one of the Rust gamedevs to put together something simple and beautiful just for purposes of demoing. Beyond that, in theory wasm should _eventually_ open up new classes of software on the web that I can't even imagine, but that's only going to come with time and creativity. [Here are some demos badboy put together previously](http://www.hellorust.com/emscripten/). We can definitely use some of them. Since time is short it's probably best if we can leverage Rust's existing strengths: find some of the best Rust libraries and wire them up in head-to-head benchmarks with the best JavaScript libraries. Hopefully there will be some where we can show impressive wins. If you are aware of any CPU-intensive JavaScript libraries that are actually used in practice those would be great for us to go after. 
It would be great to see Electron apps in the future that run on transpiled Rust code. This would be an awesome tool for GUI applications.
To add a bit more context to this statement, the source of most CSS bugs is in the interaction of multiple features. Like floating boxes impacting formatting contexts, or borders around inline-blocks, or vertically-aligned table-cells, or an overflow: auto box with a position: absolute box inside it. It's the combinatorial explosion that kills you.
I guess "production ready" would be a more appropriet term then.
Well, the CPU needs to know somehow whether there's some RC to decrease anyway, so there is no much better way to achieve it.
Wooooo, hooooo!
We kind of have green threads (but not supported on all systems): [libfringe](https://github.com/nathan7/libfringe)
I use [error_chain](https://github.com/brson/error-chain) for easy conversion between error types.
Marker traits do not have methods or an API of any kind. They simply serve as markers for one use or another. They can be automatically implemented for a given type by the compiler based on certain preconditions. Some examples would be `Send`, `Sync`, `Sized`, `Copy`, etc. 
2016 was touted as the year of the Rust IDE. Alas, apart from a few demos (which as I've heard weren't production-ready yet), we're still doing racer + a few plugins to position errors/warnings. With that said, it's probably worth to note that MIR (which getting to run has bound a lot of resources in the last months) is live and the year hasn't ended yet, so a workable IDE based on VS Code's Language Runtime Protocol (or however it's called) could be right around the corner. Not being a fan of JavaScript, I'm rooting for [xi](https://github.com/google/xi-editor) to gain IDE-like functionality and become the Rust IDE of choice.
Read my response to /u/pmarcell. I'm just wondering why the user has to specify String::new, and then parse it. Why not just declare i32 and the environment handles reading it in. I have no problem with the expect bit which I quite like.
I see error_chain being recommend, and I also recommend it. But IMO error_chain tends to help with the top-level try!'s, not the chain operations, which will still need error conversion within the chain.
I do use error_chain, but it does not help with operations **within** a chain.
Ye, these are marker traits. But the question was: why does error mention `marker traits` as `builtin traits`?
This pattern of logarithmic slowdown in memory access time for memory as it grows in scale is actually a result of the physical structure of reality and the limitations on how we can address/access things. The 'closer' it is to the source of activity the better (assuming who ever designed the system understands this basic concept and didn't just 'do something stupid'). So if you can avoid moving up to the next order of memory...do so.
why do you use make for uutils coreutils instead of cargo?
That's kind of an antiquated terminology, from back when the compiler had to be intimately familiar with marker traits to make them work. The only marker traits it's aware of now, AFAIK, are `Copy`, `Sized` and `Reflect`, because they affect core language semantics or otherwise require cooperation from the compiler. Conversely, `Send` and `Sync` have their semantics implemented entirely in the stdlib, with an "auto impl" and explicit negative impls. `UnwindSafe` and `RefUnwindSafe` behave similarly. 
You can choose to read the input as raw bytes, but you have to write the "bytes" -&gt; "an integer" conversion manually (this is a fairly low level of abstraction). Or you can use a String (since every digit is represented as an ASCII character), which can be converted to an integer (this is medium level of abstraction, gives you some control, but it's not a one-liner). The standard library doesn't provide higher-level abstractions for this, but you can use the crates mentioned [here](http://stackoverflow.com/questions/35860264/whats-the-easiest-way-to-read-several-ints-from-stdin-if-its-ok-to-fail).
Sounds like you might mean "stable."
Mostly programming languages are different flavors of syntax. Not Rust though it has entirely new concepts (ownership &amp; borrows...) and teaches you new ways to think about programming. So unless you need it for a project or work or specific goal, any other language wouldn't justify the time cost, but Rust in itself is worth spending time on. If you don't use C/C++ it is not a problem, on the contrary it will be easier in my opinion and the concept you learn in rust will teach you advanced concepts about C/C++ and their pitfalls. 
I've no idea I'm afraid. I'm sure there's specific branches for nightly and stable, so whenever it gets merged in to them :)
I'd like to elaborate on the point /u/oussama-gmd already made, namely Rust teaching you new ways to think about programming. As I only programmed in other languages before using Rust made a real difference in the way I was forced to think about what I was actually writing (as with using Haskell in university). And it doesn't stop with just the basic concept of ownership/borrowing, it's the road that ultimately gets you to the point of not having to "fight the borrow checker" anymore and just outright writing code that is correct as checked/proven at compile time. Note: I consider myself to still be merely a beginner and more or less often fighting with the borrowck.
I'll just leave this here: https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript
&gt; I've given up using combinators to chain operations from different libraries, opting for the try! macro instead, but **I feel like that's a shame.** Why?
The intermediate variables (the results of each try!) are inconsequential. They only exist to feed into the next call. So, in reading you have to essentially ignore the intermediates because they add no semantic value. Basically, instead of: request.and_then(parse).and_then(extract) You get: let response = try!(request) let parsed = try!(parse(response)) let chunk = try!(extract(parsed)) Same effect, but one makes its meaning way more obvious.
RIP YavaScript, you immortal bastard :p
Even if I love Rust, it's not the only one worth knowing even if you never use it ;)
What I personally didn't like about Scala is that there appears to be a lack of an overarching style in the language. Even more than C++, it appears to be the case that you can have different parts of the team coding in entirely different styles and different paradigms. Scala being a big language does not help matters either. The solution here, of course, would be to enforce very strong coding guidelines clearly marking which subset of Scala to use, and how to use it consistently. Too much work in my opinion (in your case).
As far as web dev and neural nets in Rust go, check out [arewewebyet.org](http://www.arewewebyet.org/) and [arewelearningyet.com](http://www.arewelearningyet.com/) to get a quick sense of how Rust fares currently in these ecosystems.
First, you're asking a Rust group; it's gonna be biased, especially since many of us don't know Clojure. Clojure is definitely a language worth learning. The transaction system it has is a great way to write concurrent code. It has better macros than Rust. And it does immutable data structures in an intelligent way. A Rust program, of course, will probably use a fifth as much memory. And while Rust doesn't use immutable data structures the same way, when you do dip into mutability it is amazingly easy to reason about at scale because of how tightly controlled it is. Also, Rust ships with message-passing tools built in, though you don't have to use them.
I have to downvote this for implying that Clojure is just "the same stuff with different syntax." You're massively underselling STM and efficient immutable data structures.
&gt; Having a specific cin-like abstraction by default isn't really that useful. I'd argue that that is highly subjective.
I would say (and I've been doing *everything* in Rust lately) that if you're doing things that are not real-time sensitive or highly sensitive to memory usage you will not *need* Rust per se. However, you will become a much better programmer just for wrestling with the rules that Rust enforces strictly. You will immediately become suspicious of whether Python copies or references Arrays, for example. As a plus, if there's a problem that requires strict memory control you will be able to solve it without dealing with the nightmare of Undefined Behavior. If you do decide to go the Rust route, the [rusty-machine](https://github.com/AtheMathmo/rusty-machine) crate has gotten exponentially better over the past year, and is definitely worth checking out. I can't speak to web development, as I stick to Ruby for that.
Was able to compile a rust NES emulator to asm.js with minimal code changes. The performance hit is significant but that is to be expected, everything else works great. https://nickmass.com/emscript.html 
I believe `let chunk = extract(parse(request?)?)?` would be the question mark equivalent. I can't say I love that much either, but I admit I haven't used `?` enough for it to "look right" to me. I could totally imagine a world with macros in the method position that could do the early return and `into` conversion: `request.and_then!(parse).and_then!(extract)`, but that's a mighty big hammer for a little sugar.
It doesn't exist because I didn't build it that way. That's pretty much the reason. Adding it in now would be a large undertaking, and it's something I would like to do... eventually. The short story is that the implementation makes a lot of assumptions about the haystack being a contiguous region of bytes. Many optimizations depend on it. All of the matching engines are built to "search until end of input or a match is found" instead of "search but keep matching state around for subsequent searches." The API for the types of operations you're asking for is also completely different. Not just in how the inputs are given, but in how the outputs are structured too. In other words, it would have been great if I had built this use case in from the start. But I didn't. And now it's costly to add. (It is not allocationless btw. It just amortizes allocation.) If you describe the specific problem you are trying to solve, I might be able to help you come up with a work around (which may incur additional overhead).
Is there any specific crate on crates.io that you'd recommend for that purpose? (you mentioned 'scanln' in the previous comment).
That looks nice. Thanks, will check it out!
Hm could you please name the files something more informative than interview_3.mp3 in future. So many podcasts do this.
Ruby and Python are strongly but dynamically typed languages. Dyon IIRC is strongly and statically typed. Lua has some features of strongly typed language.
Well, `Error` is a trait, but `Box&lt;Error&gt;` is a struct. So a `Result&lt;T, Box&lt;Error&gt;&gt;` is what I would typically use. Unless it's really simple stuff, then I probably would end up with `Result&lt;T, String&gt;`.
If there's anything that needs improving in my library to make it work for you, let me know!
That's what I mean. I'll edit m'y post.
For Arch folks trying that code snippet and getting errors: `emsdk` script needs python 2, so before and after, update correct the first line of the script (`emsdk_portable/emsdk`) to say `#!/usr/bin/env python2`
If I'm looking for file for Carol Goulding's interview, I would like to be able to tell which one it is by the filename. I cannot remember numbers.
Note that the `regex-syntax` crate exists, so you shouldn't need to write your own parser at least. :-)
In cases where I know all my error messages are static I usually use `Result&lt;T, &amp;'static str&gt;`
Yes please!
That's crazy, they should integrate with BugBounty! It allows outsiders to contribute something other than emoticons and constant pings for updates.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_networking] [Easily generate unique and reproducible IP addresses in Rust • \[x-post \/r\/rust\]](https://np.reddit.com/r/rust_networking/comments/55izet/easily_generate_unique_and_reproducible_ip/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I have done that (FWIW, that's what *error_chain* enables as well), but that doesn't help with chaining operations using combinators.
Owned 
Actually even with everything on the stack you could have *one* dynamically sized value, but Rust for now doesn't allow it. Perhaps that's another interesting capability/'level' that has some solid benefits (esp. when combined with Rust0, e.g. in embedded systems) and could lead to surprising interactions with other abstractions down the line.
[Here's the script](http://codepaste.net/an9743) to generate the random source code and [here's the benchmark driver script](http://codepaste.net/bnyfc5). Any ideas why `-C opt-level=2` compiled faster than `-C opt-level=0`?
I wanted to use Rust code inside Haskell but found the documentation lacking or that the documentation covering these kinds of things not exactly to my liking. I wrote a blog post on how to use Rust inside Haskell so that others wouldn't have to deal with the same frustrations I did, as well as providing an example with a cabal file which I couldn't find anywhere at all.
same with me.
It's a bugged font. Uninstall your local version of Source Code Pro so that it fetches the fixed version from the Google CDN: https://github.com/rust-lang/rust/issues/24355 In Windows 10, type "fonts" in your Start search bar, click **Fonts | Control Panel**, find Source Code Pro, right-click, click "delete", and confirm. Then restart Chrome.
Can't watch the vid right now, but it might be similar to the rump run unikernel: https://gandro.github.io/2015/09/27/rust-on-rumprun/
Looks good. But it should be noted that rust's 'CString' type is not 'repr(c)' and should not be exposed to ffi. You should instead take a good old fashioned 'const *c_char' and use the 'CStr' type for these unowned references. The 'CString' type is for strings owned by rust that are passed to ffi code. 
Ah really now? Good to know! Perhaps that's why I had it eating one of the chars of input every time I did it.
Right, and maybe a reactive UI using WebRender directly could also be supported. I've been working with Google's Incremental DOM which is essentially a set of calls to create elements and would bypass the in-memory DOM tree and mutation events. I think there are also some attempts to build a Transactional DOM. Servo would be a great environment to experiment with this because almost everything could be done through IPC.
I've also updated it to use *const c_char and CStr so that it works safely.
[Here are the docs](https://wiki.haskell.org/Foreign_Function_Interface#Data_structures) regarding data structures. Right now it looks like you have to find the offset manually. I'll have to do some experimentation regarding this. It also looks like their are some tools for writing C header files that Haskell could use. Since they aren't Rust specific though I'm unsure if they would work as intended. This looks like a perfect gap to fill in terms of tooling. It looks like we could use [#[repr(c)]](https://doc.rust-lang.org/nomicon/other-reprs.html) in order to get structs to be like C making it easier to translate to Haskell.
Does someone know what "checking item-bodies" does exactly? Does it make sense to be the single largest step here?
What about enums/tagged unions?
I'd be interested in seeing how well gcc &amp; clang do as C++ compilers in comparison to VS.
There's an [RFC](https://github.com/rust-lang/rfcs/blob/master/text/1444-union.md) for unions that was accepted but it looks like the [tracking issue](https://github.com/rust-lang/rust/issues/32836) is still open. Similar issues to the Structs but it looks like some work is being done on it to make FFI better.
Like if you want three threads to handle the stdin, stdout, and stderr if your child process, while the main thread waits on the child to exit. (And you don't want to use async IO.)
I don't know. Can you? Does Rust make any guarantees about representation?
the demons again!! i guess we are getting close to halloween...
I don't believe so.
So this allowed unsanitized bytecode to be injected afterwards?
It's an interesting idea. I don't know how I feel about using this in the argument position, but allowing the author to omit `Struct::default()` in the trailing `..` makes sense. That is, I like this at first glance: Foo { bar: 0, baz: 2.0, .. } // vs Foo { bar: 0, baz: 2.0, ..Foo::default() } I don't like this as much: Foo { bar: .., baz: 2.0, quux: .., } // vs Foo { bar: i32::default(), baz: 2.0, quux: String::default() } Downsides: 1. It might be less accessible / more special syntax to learn. 2. It would require `Default` to be a lang item, with special knowledge in the compiler. This would make `Foo { .. }` equivalent to `Foo::default()`.
Technically no, but it is hard for me to imagine this not working in practice. I know that Haskell does provide such guarantees regarding newtypes. The one catch is that one must ensure that no code is specializing based on the type. My suggestion is to write up an RFC proposing a _safe_ 2-parameter `Coercible` trait, the instances of which are generated by the compiler (and only by the compiler). Specifically, there is an instance `Coercible&lt;A, B&gt;` if and only if A and B are guaranteed to have the same runtime representation. Coercion via a newtype is allowed if and only if the corresponding field is public – in other words, the user could have written the coercion manually. The difference is that the compiler-generated version has no run-time overhead. This is based on GHC's `Coercible`.
This is fair! I think it might be worthwhile to have some sugary "read from stdin the 'obvious' way" APIs in the standard library, specifically because this is such a common task for _new_ users, who shouldn't be confronted with the challenge of composing these different APIs together before they've even learned what they are. Something like a method on `Stdin` like this: read_val&lt;T: FromStr&gt;(&amp;mut self) -&gt; Result&lt;T, ReadValError&lt;T::Err&gt;&gt;; enum ReadValError&lt;T&gt; { IoError(io::Error), ParseError(T), } So you could write: let x: i64 = stdin().read_val().expect("some error message"); It would silently allocate a `String`, which is unfortunate, but we really don't _have_ to confront new users with these micro-optimization questions right away.
It's not exactly the `Default` trait, but I am keen to have `derive(new)` (https://github.com/rust-lang/rfcs/issues/1318). There's also been talk of default fields (https://github.com/rust-lang/rfcs/issues/1594 and https://github.com/rust-lang/rfcs/issues/1458). https://github.com/rust-lang/rfcs/issues/569 is also about Default and fields. My general feeling is that `Default` is a bit of an evolutionary dead-end and should not be privileged with special syntax. It seems to be rarely used, and when it is it often doesn't quite come close to fulfilling its promise. It's possible that with some addition (default fields maybe) it might get closer to doing what it is meant to, but atm it seems just not flexible enough.
Where specifically is most time spent in rustc compilation? Is there a specific algorithm with poor runtime complexity?
&gt; HM (if it is indeed the case). Nah, it's not, but that's quite some orders of magnitudes that we are talking about here. That seems way too much to me.
[The Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/) currently covers (and has automated tests verifying) Rust via Haskell FFI for: - Integers - String Arguments - String Return Values - Slice Arguments - Objects Unfortunately, tuples don't make sense via Haskell FFI.
This is a comprehensive answer and very useful. Thanks /u/RustMeUp ! Diving into this today.
As long as the executables produced are as fast as possible, I don't care that much about the compilation time -- as in, I don't think it should be as much of a highlight as people make it. Then again, I'm a desktop app person, so the applications I develop are ran many more times than compiled, thus that POV makes sense to me -- it might not make sense to other types of applications.
I noticed that, but I am not sure what that means, internally. I am wondering for something like 'type inference', what specifically in the implementation could be a bottleneck? Or, does it just have to do exhaustive searching of some kind?
The compile times can for-sure be a big annoyance. Just running `cargo test --no-run` (which will build the library and then build the test harness) on my current project takes 49 seconds. And that's without building any dependencies. Imagine you build/test 100 times in a day. That's over an hour just waiting for code to compile. Is is a deal breaker for me? No way. Would I like to see it improved? Totally.
Yes, tell me how that works out for your 1Million+ LOC codebase.
I feel that this is just a lot of nitpicking. I rather enjoyed the informal approach of it all. I just focused on the content, and it went fine for me. Then again, different people operate differently, so I don't mean to invalidate your opinion.
Code-build-test turnaround is still very important to developer productivity, so the runtime of the compiler does matter. Less so for higher optimization levels perhaps. 
&gt; The inherent complexity of Rust's type-checking means optimizations are not necessarily trivial and extreme cases like this can pinpoint low-hanging fruit. If you need another "extreme case" to find low-hangling fruit, [winrt-rust](https://github.com/contextfree/winrt-rust) might be one that also uses more Rust-specific features in a realistic way. It contains a 170k LOC generated source file and compiles in [about 250 seconds, spending 2/5 of them in "item-bodies checking"](https://gist.github.com/Boddlnagg/908f6cd832d328eb096c089dc40abc55#file-winrt-df557dd1a1c3-rustc-1-13-0-nightly-4f9812a59-2016-09-21-debug). I'd also be thankful for some hints as to what I could change in the generated code to make that time go done. 
The second case ( `bar: ..` ) would also possibly introduce parsing ambiguities with the range syntax, especially `RangeFull`. This is currently valid rust: struct Foo { a: ::std::ops::RangeFull } let f = Foo { a: .. };
Yes, but then you'd somehow need to manage their positions, at which point you're into one dynamically-sized arena-like value territory, which is *really* hard to get right. At that point you're probably better off building your own allocator.
What problem would this extra information help solve? Issues with borrows are already pointed out by the compiler. 
&gt; If you are aware of any CPU-intensive JavaScript libraries that are actually used in practice those would be great for us to go after. I'd like to try to move WebODF to Rust. Instead of placing the ODF directly in the DOM as we do now, a virtual DOM would available to the Rust code. The Javascript side would send events to rust and the rust code would update a virtual DOM that's synced to the browser DOM. What would be the FFI overhead? I've done a similar virtual DOM in C++ and kept all the strings as native browser strings, mapped to integers in the C++ code. This gave an amazing performance. Doing the same thing in Rust would give more possibilities for the safe programming.
Speaking about pure Hindley-Milner, the expensive part in big-O terms is finding most general unifiers. Heck if you don't pay attention to how you represent things the size of your result is worst-case O( 2^n ) (you can avoid that by switching to DAGs instead of trees). Rust shouldn't have much trouble, there, though: Unification problems should never grow gigantic so the big-O doesn't matter much. It might just be a case of the implementation not being particularly optimised.
Sure, but wouldn't specialization make this possible? `impl&lt;T&gt; From&lt;()&gt; for Option&lt;T&gt;` is more specific than the blanket impl, so I would expect it to.
Did you mean non copyable?
[removed]
You could still call .clone() on accident somewhere.
The problem is that it's hard to know what gaurentees you need to uphold to safely call setjmp in Rust.
That is type-directed name resolution, which I don't think was ever mixed before with HM. `Vec::push(&amp;mut result, 5)` works, and the `5` can even be `Default::default()`: as trait methods don't need extra resolution to type-check, HM takes care of the rest. To make all cases order-independent you'd probably need constraint-based type-checking, which I believe Swift does (at great cost).
yes thats what i said, the wait for I/O will be a thing of past when Genius guys know about Power of Rust , like those who created Akka. 
As an Android developer, I totally understand this. Until the 2.1 Gradle plugin, which came out not too long ago, a 2-3 minute clean build time was the absolute baseline (no tests involved), and in a bigger app, 7-8 minutes was totally expected. Now, a leaner app can at least get done in 30-60 seconds, and a larger one in under 5 minutes, but it's still death by a thousand cuts. I build at least 100 times a day. I've never worked on a project with a &gt;2 minute build time. Could you imagine working on a project that takes 8 minutes to build? You couldn't even get 100 builds done in a workday. Granted, usually you can get away with a faster incremental build, but I'm usually still sitting there for 10-15 seconds, on a $2500 top-specced Macbook Pro, and I'm sure people's incremental builds out there take well over a minute...
Wow!
Is there a convenient "most wanted" of DOM APIs available?
This is great. Better than almost any other how-to-contribute guide.
Just so you know, -Z no-landing-pads is stabilized as -C panic=abort
&gt; All three options are either unsafe, slow, or clunky to use. I have a proof of a concept for a fourth option. Dumb question perhaps, but how is your option not similar to #1 (a bit of unsafe code)?
Calling it convenient is a stretch, but https://public.etherpad-mozilla.org/p/servo-dom-missing-pieces is one place I've been keeping track of APIs that are known to be very incomplete or completely missing (which can be kind of cross-referenced against https://platform.html5.org/). This doesn't include lots of individual properties/methods, though. I'm looking at ways of getting that information and ordering by real-world usage, however.
The unsafe implementation of `Tree&lt;T&gt;` is hidden from you, just like e.g. the implementation of `Rc&lt;T&gt;` is hidden. You use `Tree&lt;T&gt;` to build your own trees. In this post, I built `Splay&lt;T&gt;` without having any unsafe code in it. Only the code within `impl&lt;T&gt; Splay&lt;T&gt; where T: PartialOrd { ... }` is relevant. Everything else should be implemented as an external library.
Suffixed constants `123i32` improves the compilation times by about 5%. Adding `: i32` to all `let` variable declarations doesn't seem to matter. Still a long way to go.
Fair enough, you can use the same techniques as the aforementioned libraries to implement this no sweat. I would consider using `char` (which is 32bit in Rust) instead of `i32` unless you specifically want to support non-utf strings. The reason for the confusion was that your OP mentions `U16Str` which implies UTF-16 which you'd obviously implement using `u16`.
Am I missing something? Compiling a C++ program with 100 functions and optimizations enabled takes 13 minutes? This number is so far out of whack I find it hard to trust anything else in these charts. 
Indeed, compile time mostly matters for -O0 and -O1 (the latter because some people have projects unusable at -O0), which is what is necessary for developing.
Small nits: `putStrLn . show` is equivalent to `print`. &gt; Every executable has a main function with a return type of of `IO ()` It's not a function; it doesn't have a `-&gt;` in its type. &gt; it returns the unit type `()` upon completion wrapped up in the `IO` monad `IO t` isn't a wrapper on values of type `t`. Rather it's a description of an effectful computation which, if performed, *would* produce a value of type `t`. In essence, `IO` actions are imperative programs, and the Haskell program is a sort of metaprogram which constructs the `IO` program `main :: IO ()`. (Of course the actual implementation in GHC is pretty far from this and boils down to applying actually impure functions in a careful and controlled manner.)
Ah, right. Thanks.
This is an intriguing idea. My only concern is that whereas implementations like `PetGraph` hand out `NodeHandles` and such, which can allow one to add children in constant (or amortized constant) time with no restrictions, this implementation appears to require traversal in order to add edges. Not a huge problem for ordered structures like binary search trees (as demonstrated), but for trees whose items aren't orderable (e.g. parent &lt;-&gt; child relations in a widget-based GUI), adding a child to a node identified by its value would take O(n) in the current form. I'm still new to rust and safety, but would the addition of a `HashMap&lt;T, *mut Node&lt;T&gt; &gt;` member in the `Tree&lt;T&gt;` struct, and a corresponding method `lookup(&amp;mut self, value: T)` that updates the Tree's `node` member to point to the node containing `value` cause any safety concerns? It's obviously not necessary/wanted for all trees, has issues with trees that can contain duplicate values, and it would of course have impacts on the time needed to insert or remove sub-trees - I'm asking more to understand the concept of `safety` within rust. I need to use a Directed Acyclic Graph in one of my projects at some point, and PetGraph has a pretty serious limitation wherein removing nodes causes NodeHandles to be invalidated. Daggy, which builds upon PetGraph, presumably just leaks memory as you add many nodes and then delete all edges to them. So I'm trying to get a general feel for how to go about this stuff before I jump in. As an aside, you may want to document all this code.
You could use conrod if you aren't concerned with native look. It is fairly straightforward to work with for simple controls. The canvas demo is where you may want to focus your attention
That actually answers it. I just really sucked at asking it haha. Thank you!
What's the best lib for tweaking bitmap images? (a lib with nice examples would be ideal) Why i want this is cos I'm attempting a version of https://github.com/mxgmn/WaveFunctionCollapse, but one that animates the process on-screen. I've already got a basic window with a timer/animation loop after following the quite excellent arcade-rs tutorial, so it's bitmap manipulation next... Thanks for reading!
One argument against the conversion existing at all might be: what happens when you're dealing with Option&lt;Option&lt;T&gt;&gt;? What happens for Option&lt;U&gt; where Option&lt;T&gt; is substituted for U? Etc. I'm new to the language, but my intuition is that there'd probably be nasty and unprincipled edge case behavior here. I could be wrong, though.
While I'm sure you are correct, I haven't used or explored Ruby very thoroughly; my professional experience is mostly in C++, Python, Java, and JavaScript.
&gt; What is the expected end date on this book: For the online stuff, the end of the year. For a physical copy, early next year. &gt; And in what ways is it supposed to be better than the current rust book on the rust website? So, I wrote the first, and /u/carols10cents and I are writing the second. The TL;DR is, I wrote the first book in the rush up to Rust 1.0. Now that we've had stable Rust for a long time, we have a much better idea of how to teach it to people. So the book is just going to be far better in almost every way.
Interesting. Nice to see that you can implement all this in normal readable Rust, having only some lifetimes strewn about. I've also recently been diving into DFA's, NFA's and powerset construction (but in C#). In my implementation the user provides a function that creates a single state from a closure of states. That way, they control for example if the payloads are lists, whether to merge them, or if the payloads are strings, whether to concatenate them. It seems your implementation only handles NFA's without ε-transitions, correct?
Good work writing benchmarks. Have you thought about going one step further with this cursor- or zipper-like interface and making traits that any tree library can implement? I gave this a shot with [entmut](https://github.com/dstu/entmut), but that has lain fallow for a while.
Great work! I think the reason why you haven't seen anyone trying this approach before is because rust developers focus on trying to find a safe implementation first. Safety is, after all, one of the three main goals of the language. However, my opinion is that a Tree is basic and necessary enough that we ought have a fast implementation even if not safe.
Increasing the number of lines of code in a codebase doesn't make it any more difficult to debug an issue. It's trivial to diagnose which module is having issues.
This is when you reach for GDB. As of June, it has native support for Rust executables so you should be able to follow any tutorial written with C/C++ programs in mind and just substitute your Rust executable and use Rust expressions. Make sure you compile in debug mode, of course. To debug a segfault, you just have to run your program through GDB and use it normally. GDB will automatically break on the segfault, at which point you can get a backtrace or view the local variables.
I for one enjoy fonts that don't work.
What problems did you have with rust-gtk?
CString is actually an owned wrapper, used for building C Strings so you can send one you created over a C boundary. Tbh I'm honestly surprised it wasn't crashing from the double-free that could have happened, but I guess the program ended before Haskell's GC kicked in.
Tools like Atom already handle that perfectly without needing to be a fully-fledged IDE. State changes are observed in Rust via designing your software using a `Builder` pattern, whereby your code completer will show you your current state in real time. You have no right to question someone's experience just because they see no point in an IDE. IDE's are just bloatware consuming obscene amounts of screen real estate to do nothing that I can't already do with a programming text editor like Atom.
If you have the gumption to dismiss IDEs as "bloatware" simply because you yourself see no value in it, I have every right to question that myself, sir. Atom, eh? I'd like to see some evidence of massive codebases being written using absolutely no IDEs. And if you're talking about Atom being able to do all that, it's far more of an IDE than a text editor, my friend. Stop deluding yourself. 
It's obvious why an `unsafe fn() -&gt; ()` isn't a `fn() -&gt; ()`, but why isn't a `fn() -&gt; ()` an `unsafe fn() -&gt; ()`? That is to say, since unsafe functions are a strict superset of the functions implementable in safe rust, why don't safe functions type-check as unsafe fns? For an example, see [this playground link](https://is.gd/zCYdlH).
I'm working on revamping the Amethyst game engine website to look better and look more welcoming to newbies, and also wrapping up the 0.4.0 release with the rest of the team.
There are plenty of people using Atom, or even VS Code, to manage large codebases, such as the Servo project. Additionally, unrelated to Rust, there are many people who contribute to the Linux kernel, Firefox, and LibreOffice without using an IDE.
It's a shame that GTK itself is so terrible on Windows.
Changes to the language semantics usually require an RFC first. This wouldn't be a breaking change but it would be an observable one, so probably needs an RFC.
I wasn't sure if this was heavyweight enough to qualify for an RFC, but I'll open an issue in the RFCs repo to see what people think.
Experimenting with an implementation of [Google Roughtime](https://roughtime.googlesource.com/roughtime/) in Rust. It's just enough to send a valid response and start parsing the received data. https://github.com/mcpherrinm/roughtime.rs
I think if anything, the right thing to do is have only a limited form of operator precedence that corresponds directly to maths, and where there is any ambiguity involved whatsoever (like, logical operators precedence over algebraic, which isn't a problem in Rust right now because there are currently no types that can receive both but that won't last forever) you simply don't compile without brackets. Maybe that's unpragmatic though, I am quite fond of Lisp so my bracket bias may be showing.
Could you name some problems?
In general clippy is a good source for all these corner cases, though many of them are very Rust-specific and wouldn't affect other languages.
It looks completely different to all other apps. Moreover, it falls back to the default GTK look, something few Linux users see, which hasn't changed since 2000 and so not only looks different, but old fashioned. Things are even worse on macOS where the menu bar is often not used. GTK is much worse then Qt or WX for Mac or Windows development. By design it does not mimic the local look, feel or behaviour. /u/pcwalton was working on a [port of libui](https://github.com/pcwalton/libui-rs) which uses native widgets, but he seems to have been swamped lately. 
And osx. Practically it's a linux only lib.
Akka dev here: there are definitely no geniuses here :) It is not super hard to build a nice actor abstraction in Rust. If I would have more free time I would port a subset of Akka to Rust. I have to agree though with thiez that lack of GC will limit the language in many domains. I don't mind it though, I like both the power of Scala and Rust and I use them as complementary technologies. I think it would be really nice to have a seamless JVM integration story (for example creating cross-platform, JARs that contain Rust based native code and generated Java wrappers).
Yes, it's possible to have a `HashMap&lt;T, *mut Node&lt;T&gt;&gt;` within every `Tree&lt;T&gt;` to support fast `lookup` operations. However, that would come at the cost of maintaining hash maps. If you're willing to pay `O(size_of_subtree)` on every `tree.take(index)` / `tree.link(index, subtree)` to remove / insert key-value pairs from / into the hash map, this is certainly doable. But as soon as hash maps are involved, the "zero-cost" part goes out the window anyway. :) Also, take into consideration that if you don't have tall trees (and that is often the case), perhaps you might design a strategy to lookup nodes in `O(height)`. I would argue that if you want to access nodes using `lookup`, you already have a messy ownership story which doesn't fit the model. In such cases you probably only want safety, while avoiding nicely structured (in other words: constrained) ownership models. Petgraph will be of better use then. Even if you want arbitrary lookups on *unidirectional* trees, you'll still have to reach for petgraph, `Rc`, or some other kind of garbage collection. It's the whole other deal. To clarify, `Tree&lt;T&gt;` is very similar to: struct Node&lt;T&gt; { value: T, left: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;, right: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;, } Except `Tree&lt;T&gt;` also allows you to access the parent node in addition to children. :) This is pure ownership - there's no garbage collection. By the way, I'm confident that it's also possible to design an equivalent of `split_mut` on `Tree&lt;T&gt;`. Sorry for the lack of documentation. If there is an interest, I'll definitely implement this as a polished library.
https://github.com/rust-lang/rfcs/issues/1458
Every time nightly got updated.
Oh, does Fortress have multiple levels of whitespace separation? I can't agree with that one bit. `a+b * c === (a + b) * c` is more fair though, I think, although if I was designing a language I wouldn't include it as a rule.
I have since released a Go library in preparation of the CNI plugin coming next. That should make it easier to integrate this with Rkt, Kubernetes, Mesos and all the other technologies that support CNI for networking.
The decision that [leaking should be safe](https://github.com/rust-lang/rfcs/pull/1066), provoked by the discovery that [the original scoped threads API was unsound](https://github.com/rust-lang/rust/issues/24292).
For cross platform GUIs I would recommend libui-rs (https://github.com/pcwalton/libui-rs). See more on https://rust.libhunt.com/categories/1593-gui
Ah thanks - I removed it :) 
Fair point, I hadn't thought of that
This is the only sugar involved: fn has_hrl&lt;F: Fn(&amp;()) -&gt; &amp;()&gt;(f: F) {} fn has_hrl&lt;for&lt;'a&gt; F: Fn(&amp;'a ()) -&gt; &amp;'a ()&gt;(f: F) {} The problem is that the compiler needs to substitute every type parameter with a concrete type. So for `id_wrapped` it can substitute `()` for the `T`, but for `id` it can't substitute `for&lt;'a&gt; &amp;'a ()`, because that's not a concrete type, it still contains a higher ranked type parameter. It seems like it would be better for the language to support higher rank types to a certain degree, but it presents implementation challenges and toes the line on decidability.
I imagine reference counted types would be significantly more complex - right now they just assume that cycles don't happen. 
I've always found every language's operator precedence to be idiosyncratic and arbitrary, including rust. For this reason I prefer [go's precedence rules](https://golang.org/ref/spec#Operator_precedence), as it has only 5 precedence levels, and I can actually remember it. If you like rust's precedence maybe you can share some underlying pattern that will make it easier for me to remember?
Good catch.
That's a pretty nice rule in theory, but I don't think it adds enough to warrant the extra complexity. That misleading whitespace error is a cool thing though, I wonder if clippy has that already.
&gt; I want to find some really tricky corner cases of the implementation of Rust to make future language designers not fall into it. Just because something is "tricky" doesn't necessarily mean that it's unnecessary. A lot of things in programming language design are there because they need to be, not because the language designer wants them to be complex. Often, simplicity in a language just pushes complexity to the application layer.
Range syntax. Endless hours of debate and it's still not completely over.
You can assign a total order on the types and only allow a type to reference another type if it is strictly less than in that order. Unlikely to be very practical to write programs in, though.
Smalltalk's lack of MDAS is a constant source of arithmetic errors in the first six months people program in it. Arithmetic errors are the worst, since there's generally no automatic way to catch them either statically or at runtime. Hope your tests were good!
The documentation describes a Tokio service as "An asynchronous function from Request to a Response.", so I don't think that's what you want. Maybe look at how the `tokio-service` crate itself is implemented to see how you could implement a protocol which is not request/response based?
Build an abstract interpreter and do safe approximation. (This is what Java does for use-before-def, for example.) Not sure how good an approximation you could get...
What's your application domain? Maybe beginners make a few mistakes at the beginning, and I sure make some once in a while when I'm distracted, but even then my experience with arithmetic errors is a facepalm within a minute of writing one, because the first example I tried produced an obviously wrong result… With complex math, I'd go through multiple named variables for intermediate results to make units and important sub-expressions clear.
Yeah, being able to tell what you see from lexical structure is a very important point, indeed.
If you're comparing that to the Rust reference, understand that the list in the Go Spec is excluding a number of operators, at least the typecast operator, and the assignment operator that I can think of right off the bat. But anyway, the Rust precedence rules are trying to put operators of the same "kind" together, producing a grouping like this: ## Conversion This is pretty much common sense. Typecasting gets maximum precedence in Go, too. * `as` `:` ## Arithmetic This follows PEMDAS. * `*` `/` `%` * `+` `-` ## Bitwise Shifting is typically done to produce a value that can then be masked, rather than the other way around. The only thing I don't get is giving XOR a higher precedence than OR, instead of putting them together. * `&lt;&lt;` `&gt;&gt;` * `&amp;` * `^` * `|` ## Comparison These operators take numbers and produce booleans, so all operators below this point operate on booleans (except assignment, which can operate on anything). * `==` `!=` `&lt;` `&gt;` `&lt;=` `&gt;=` ## Logical This is identical to the last two precedence levels in Go. * `&amp;&amp;` * `||` ## Assignment Operators that don't produce anything you can operate on get the last precedence level. * `..` `...` * `&lt;-` * `=`
We do not.
Why doesn't this work? "mismatched types: expected type parameter, found closure" struct Foo&lt;F: Fn()&gt; { f: F } impl&lt;F: Fn()&gt; Default for Foo&lt;F&gt; { fn default() -&gt; Foo&lt;F&gt; { Foo { f: || (), } } } I'd like to be able to provide a 'default' callable that's just a pass through. So I tried to be clever with an intermediate trait but then rust complains about not having enough type information for inference: [playground](https://play.rust-lang.org/?gist=c28305d81f8ecb8e861567a5e0e4a7a0&amp;version=stable&amp;backtrace=0). How do I achieve this idea of a 'default closure' in Rust?
much upvote!
Our dom interfaces are implemented in Rust, and they manipulate each other all the time. That said, I don't think there's an easy way to embed servo in a rust application and manipulate the dom from there. It sounds possible (you just need to send dom manipulation tasks to the script runner), but no simple API.
It doesn't work because `F` is chosen by the caller but you are trying to define it in the implementation. In other words, `||()` is not of type `F`, which isn't known as it's chosen by the caller, even though it satisfies the `Fn()` bound. Defining a bounded type based on the implementation is what `impl Trait` is for. You can't use `impl Trait` with the `Default` trait (yet) but you could do it in an inherent method: https://is.gd/LowShP I think `pass_through` might be a better name than `default` if a sensible `Default` implementation applies to your actual struct.
Thanks for the hint - is this usable already? Also seems to be in a pretty early state
Looking through the docopt [spec](http://docopt.org/), it looks like you need to change the usage string to `myproject [options] &lt;resource&gt; ...`.
Except Lisp :D
I agree, I instantly change to 'new' but I wonder how many others do.
[Named field puns](https://github.com/rust-lang/rfcs/pull/1682) is in FCP this week.
Please keep Rule #4 in mind.
We do runs with "crater", a tool to check new versions of the compiler across the ecosystem, from time to time. So that will make one or two downloads happen. In addition, I'm busy [fixing some bugs in the semver package](https://github.com/rust-lang/cargo/pull/3154) that required grabbing every crate off of crates.io in order to check version numbers. That also should have caused between two and five downloads in the last week.
I don't see it here - https://github.com/rust-lang/rfcs/labels/final-comment-period
/cc /u/erickt
Intel seems to sponsor a lot of Rust talks, do they actually use it a lot?
My favorites were * Xi: a modern editor built in rust * RFCs &amp; unions * Using generics effectively * and the closing keynote actually all of them
We really need to get the list of jobs up from zero. :{ (Also, I hope my boss doesn't see this comment.)
Three dots are inclusive, two dots right-exclusive. Pattern-ranges are always inclusive (for now) and there is an unstable syntax for constructing inclusive ranges normally.
Thanks for the heads up!
Apparently the procedure changed so that team members sign off _before_ FCP, not during, anymore. I'm not clear on what's supposed to be different during FCP. The bot's comments did not make this clear at all.
[Submitted](https://github.com/cmr/this-week-in-rust/pull/324), thanks!
FWIW, I've submitted an issue to add a summary of what Ruru is at the top of each post: https://github.com/d-unseductable/ruru/issues/37
The type it can't substitute isn't `for&lt;'a&gt; &amp;'a ()` (which is a concrete type not supported in Rust) but rather `&amp;'a ()` with the `'a` binding in a `for` *outside* the `Fn`.
I did spot [this one](https://news.ycombinator.com/item?id=12628852) on HN yesterday.
The screenshot is 404ing.
yesss... was really looking forward to checking out xi.
I'd love math style [ for the inclusive and ) for exclusive so you could do [5..9) EDIT was [5,9)
Nice initiative! But the link is broken, the correct URL seems to be https://github.com/nrc/mentor-rfcs (without the trailing '1')
&gt; If it’s translated fine we’ll print out the input string and if not we panic and cause the program to abort because it failed in some manner. If you want panics to abort the program, you should set `panic = "abort"` in Cargo.toml, otherwise, the panic will actually cause the program to attempt to unwind across the border into Haskell at which point the Sun will go supernova.
&gt;I don't know what would happen by matching on &lt;, &gt; or &amp; in a slice of u8. I guess it would work well in 99% of the cases, but I suppose there is the possibility that the code for e.g. &lt; actually doesn't correspond to a real &lt; but to the second, third or fourth bytes of another unicode character, which could cause quite awful bugs later on. Though, again, maybe ASCII compatibility avoids this problem, but I don't know Unicode enough to be certain of that, and I rather not take risks. (Plus, I also have similar examples that need to replace characters that are not ASCII.) It is actually guaranteed that an ASCII-looking byte in (properly encoded) UTF-8 will actually be ASCII. In bytes belonging to a multi-byte codepoint, the leading bit will always be set. [This table](https://en.wikipedia.org/wiki/UTF-8#Description) shows how the scheme works. 
You should bring up the idea of yanking all versions of dylib or putting a note on the dylib repo/docs.
Thanks for the precisions, I'll try to update the article asap :)
This is a great write up! I love seeing blog posts like yours and /u/apanatshka's from the other day. More string processing/automata please! I'll take a crack at filling in some details. You otherwise asked really great questions and exposed an area for future work. :-) &gt; Great Scott! This is actually three times faster than the fastest implementation when there is no characters to escape, and still 30% faster than the fastest implementation when there are characters to escape. I guess we don't have to choose anymore between the two previous implementations because... wow, Regex is fast. Since you're searching for three bytes, my guess is that the actual search winds up using [`memchr3`](http://burntsushi.net/rustdoc/memchr/fn.memchr3.html) and never even enters the regex machinery at all. &gt; Warning: I don't know a lot about regular expressions, so it is entirely possible that this call to replace_all could be optimised and that it is actually worth using this method instead of find, but if it is, it requires more competences than I currently have. My guess is that the issue is related to getting those `Captures`, which adds overhead. Given your regex though (which has no captures other than the trivial one) it seems like that overhead should be avoidable. So this is a really nice observation, because it shows there is some work to do there in the regex crate! Other than that, [the core loop inside `replace_all`](https://github.com/rust-lang-nursery/regex/blob/master/src/re_unicode.rs#L577-L590) is actually really simple. (Note that the highlighted code doesn't use captures at all.) A key difference between it and yours is that it continues to process chunks at a time, instead of processing char-by-char after the first match. &gt; More surprisingly, compiling Regex with the simd crate (and the above flags) didn't have any impact on the performances either (though, this time, I found e.g. MOVUPS instructions somewhere in the generated binary). I'm not sure what this means exactly: did I miss something? Is SIMD actually not helpful for that case? First and foremost, the SIMD support you're referring wouldn't get triggered in this case. `memchr3` would still be used. With that said, my intention with `memchr3` was to have it autovectorize, but I can't remember if it actually does or not, so that could be using SIMD already (and you don't need to do anything special to get that). Secondly, to get SIMD support from the regex crate (which only applies in some circumstances, and not for every regex), you need to do: RUSTFLAGS="-C target-feature=+ssse3" cargo build --release --features simd-accel If you're compiling an application that uses `regex` as a dependency, then you can use the [same (undocumented?) trick that `ripgrep` uses](https://github.com/BurntSushi/ripgrep/blob/master/Cargo.toml#L46-L47) to forward the `simd-accel` feature. i.e., the above `cargo` command works for `ripgrep` too. &gt; I suppose all of this could be optimised by using a slice of u8 instead of chars and assuming the input to be ASCII. It would probably be faster, and autovectorisation might kick in more easily. However, I'm not sure there is a way to do that without giving up UTF-8 support: I don't know what would happen by matching on &lt;, &gt; or &amp; in a slice of u8. I guess it would work well in 99% of the cases, but I suppose there is the possibility that the code for e.g. &lt; actually doesn't correspond to a real &lt; but to the second, third or fourth bytes of another unicode character, which could cause quite awful bugs later on. Though, again, maybe ASCII compatibility avoids this problem, but I don't know Unicode enough to be certain of that, and I rather not take risks. (Plus, I also have similar examples that need to replace characters that are not ASCII.) You're in for a treat. :-) UTF-8 is said to be an *ASCII compatible* encoding. This means that if you see the byte `&lt;` *anywhere* in UTF-8 encoded text, then it always corresponds to `U+003C`. That is, the byte `0x3C` can never be a continuation byte. This is true for all bytes `&lt;= 0x7F` in valid UTF-8. This means that if you modified your loop to work on `&amp;[u8]`, then it should continue to be correct, so long as you specify that `&amp;[u8]` must contain an ASCII compatible encoding (which isn't true for arbitrary HTML, you'd need to transcode to UTF-8 first). (Fun fact: the `std::path` module makes use of the ASCII compatible invariant of both UTF-8 and WTF-8.) [EDIT] Wow I took too long to write this comment. A few people beat me to the punch. :P
&gt; we all expect x + y * z to have a different meaning than Smalltalk assigns it Sorry, no… when I write maths by hand, I exaggerate spacing to show precedence, and in code I either parenthesize or reorder expressions in evaluation order.
Colloquially all. You are unusual in my experience. 
Is (1,10) a range or a pair?
It's pretty new. Some things will be impossible to use.
It's useful for simple cases. I did use some time ago. Did notice now that is almost 4 month since the last update :|
Continuing to work on https://github.com/tmzt/incrust, my project to build a template engine in rust which can render server-side and client-side with the same logic. Progress this week is focused on demos for more usecases and building out the needed features. The idea is to build a template in rust (currently using macros/plugins and a custom dsl, but will eventually support handlebars, jade, twig and others). Expressions and conditions will be compiled into rust and javascript, and executed in the browser in a reactive template rendering library, which will allow for a fully interactive web application to be defined that will render quickly on the server as compiled code and be updated in the browser in response to server events, user interaction, and Redux-style actions. It will also allow defining data stores that will be accessible both from rust code and from javascript, with REST calls generated for interacting with server-side rust code in response to actions.
Quick question, [here](https://d-unseductable.github.io/ruru/ruru/struct.VM.html#method.thread_call_without_gvl) it says &gt; **Warning**! Due to MRI limitations, interaction with Ruby objects is not allowed while GVL is released, it may cause unexpected behaviour. [Read more at Ruby documentation](https://github.com/ruby/ruby/blob/2fc5210f31ad23463d7b0a0e36bcfbeee7b41b3e/thread.c#L1314-L1398) Can one interact with Ruby objects while GVL is released using only **safe** Rust code? If yes, shouldn't this function be marked as `unsafe`? Or perhaps the "unexpected behavior" never leads to memory unsafety? (How so?)
Has there ever been an RFC for row types? If no, would anyone be interested in collaborating on one?
&gt; Apart from using multiple usizes to keep intermediate counts, unlike my solution in words instead of bytes, which allows it to add more than 255 values and combining those counts only when the ~8k bytes have been screamed through. For some reason I am having an incredibly difficult time parsing this sentence.
This is math style, but just a non-starter for any language which balances parentheses (which is Rust and... all of them, that I can think of, even Brainfuck).
A few things from my quick look on the `run_command` function: 1. Match + unwrwap is a big antipattern in Rust. Instead of doing: let foo = bar(); match foo { Some(_) =&gt; { let baz = foo.unwrap(); ... } ... } You can just do this! match bar() { Some(baz) =&gt; { ... } } This occurs many times in your code 2. Too many mutable variables! You say that early returns are not the Rust way, but in this case, getting rid of `resp` variable and just returning a `String` would be a lot simpler. You can also get rid of `mtime` and `path` mutability, but as you say, that would induce rightwards drift. To make the code more "flat", you can split the function into the inner and outer part, and let the inner part return `Result&lt;String, String&gt;`. That would enable you to use the `try!` macro (you'll need to add some converting from `Option` to `Result` in a few places to achieve that). **Edit** [Example of inner function + `try!`](https://play.rust-lang.org/?gist=3e47fb897d6bc00e6a8d0fa98b1fd3f5&amp;version=stable&amp;backtrace=0). Another (simpler, but more manual) way to deal with the rightwards drift/ boomerang/ pyramids is to let the variables "escape" the pattern matching and let the happy path be unnested. For example: let foo = match bar() { None =&gt; return "error: something"; Some(x) =&gt; x; } That's similar to what the `try!` macro does with `Result`s. You can even let more than one variable escape by using a tuple, in your case: let (mtime, path) = match { /* your parsing logic with early returns */ } // Rest of happy path Sidenote: [There was an RFC to simplify this with "let-else" construct.](https://github.com/rust-lang/rfcs/pull/1303) 3. When using `Captures`, you can change the `captures.at(1).unwrap()` to `captures[1]` (it's not the general rule, `Captures` just happens to implement the `Index` trait).
Great writeup! I might be going insane but this bothers me. In your Find and Regex impls you could do: output.reserve(input.len() - first + 2); because you know it cant ever be shorter than that. But it probably does not make a difference. Except that it will hurt maintainability.
Servo has a history of making references to the Doge meme in various things. Most notably the Servo logo is currently the Rust logo with a doge in place of the R, since they still haven't decided on a final logo.
"Docs superhero" added to his flair.
Wow. Can someone tell me how I got into the friends of the forest list? I mean... I highly appreciate it, though I do not understand why! :-)
Is memchr doing something in C that can't be implemented in rust? or was it just easier to wrap the libc implementation and not bother with pure rust?
I can highly recommend trying [clippy](https://github.com/Manishearth/rust-clippy). It is a linter that can suggest quite a few improvements to make your Rust code more idiomatic.
This is a really valuable comment. Thanks. I'll definitely rewrite the code using `UnsafeCell&lt;T&gt;` now that you've explained the safety issues. Regarding petgraph: Yes, storing data in a vector will increase cache efficiency. However, consider the fact that edges adjacent to a node are not stored near the node, but in a separate vector. Those edges are sequenced using "next" indices, effectively forming a linked list. Therefore, a graph is essentially a vector for nodes, and another vector for edges serving as a storage for a bunch of linked lists. :) I don't want to give petgraph any flak - it's a really good library, and `Graph` is implemented well. However, using `Graph` for building trees is simply an overkill. It's too generic, flexible, and powerful for trees. This unnecessary flexibility comes at some performance cost and increased memory usage. It might be a bit clunky to use in sense that it doesn't guide you into creating trees - you'll have to guarantee that your graph really is a tree by yourself. There are also things like index invalidation on `graph.remove_node`. All I'm saying is, there must be a better way.
Bonus: `String::from_utf8(output).unwrap()` takes O(n) time to check that `output` is well-formed in UTF-8, but we know this is always the case. (`input` is well-formed by definition of `str`, and we only replace ASCII bytes with ASCII sequences.) Therefore it is safe to use `String::from_utf8_unchecked` here.
Also, I wonder if it would help to not push unchanged bytes one at a time, but instead find the next replaced byte and use `extend_from_slice` (which might optimize better) for the unchanged slice in-between.
huh, well that's surprising, didn't know that glibc implemented it in assembly. I wonder how much slower a C version using the same algorithm (and SSE) would be
From what I remember, the "misleading whitespace error" is exactly what you'd get from Fortress.
[removed]
Thanks for the suggestion! I tried it, it's another 50ns gain on my machine, but... I don't know, I always feel uncomfortable having to use the unsafe keyword ^^ I'll try to edit the article later to add this possibility, though.
&gt; Can one interact with Ruby objects while GVL is released using only safe Rust code? It doesn't appear so. See [further down in the Ruby docs](https://github.com/ruby/ruby/blob/2fc5210f31ad23463d7b0a0e36bcfbeee7b41b3e/thread.c#L1378-L1384).
Burntsushi pointed a similar thing (not for bytes slices though). I'll have to look at it.
I mean: if one tries to interact with Ruby objects when the GVL is released, it may cause an undefined behavior, right? If this is the case, then you need to mark that function as `unsafe`, since safe Rust should never lead to undefined behavior by itself. See [this](https://doc.rust-lang.org/nomicon/safe-unsafe-meaning.html) at the Nomicon. Another option is to always check if the GVL is released whenever you call a method that interact with Rust objects. If yes, then you panic. This has a performance cost though. The best option (if feasible) is to have a phantom type in your Ruby context to track whether the GVL is acquired or not. The library could then detect at compile time when one tries to interact with a Ruby object while it is released (this is one thing that makes Rust seriously awesome). It would turn the API much more complex though. I don't have an up-to-date link about the latter technique, but [this blog post](https://pcwalton.github.io/blog/2012/12/26/typestate-is-dead/) talks about it in the context of an ancient, pre-1.0 Rust version (from 2012). In the example given in the post, it allows you to read only from open files (if you try to read from a closed file, it fails with a compile-time error, instead of a run-time error).
I'm still a rust newbie so I wanted to see if I could optimize this further as an exercise: pub fn find_no_cow(input: &amp;str) -&gt; String { lazy_static! { static ref REGEX: Regex = Regex::new("[&lt;&gt;&amp;]").unwrap(); } let first = REGEX.find(&amp;input); if let Some((first, _)) = first { let mut output = String::from(&amp;input[0..first]); output.reserve(input.len()); let rest = input[first..].chars(); let mut start = first; let mut cur = first; for c in rest { let replacement = match c { '&lt;' =&gt; "&amp;lt;", '&gt;' =&gt; "&amp;gt;", '&amp;' =&gt; "&amp;amp;", _ =&gt; "", }; if replacement != "" { output.push_str(&amp;input[start..cur]); output.push_str(&amp;replacement); start = cur + 1; } cur += 1; } // flush output output.push_str(&amp;input[start..]); output } else { input.into() } } The idea is that you push the longest strings you can, rather than pushing every single character individually. Quite a bit faster for the case where there **is** stuff to escape, but a bit slower when there isn't. I'm sure this could probably be optimized even further. Would using a hash map to get the corresponding replacements for characters to be replaced be any faster than using match?
I think the official party line is that SSE2 is always available on amd64 CPUs, so it's just always on. (ssse3 isn't, and in fact, I've had at least one complaint that the binaries I distribute with ssse3 enabled don't work!)
I also seem to recall that `unsafe` should only be used with non-blocking functions -- due to GHC's N:M threading model, to avoid blocking a whole bunch of GHC threads which just happen to be on the same OS thread. In other words, under the assumption that I/O may block, the use of safe/unsafe in the article should be precisely the reverse. (cc /u/mgattozzi)
You bring up some interesting points. You should file an issue with this information in Ruru's GitHub repository, I'm sure its author has some opinions on this (I'm not sure if he checks Reddit).
https://github.com/sinkuu/tokio-framecodecs/blob/master/src/framed_helper.rs Here is my poor attempt to provide simple write/read API for `FramedIo`. You may be able to do things like this (not tested): let tp = length_prefix_transport(tcp); let tp = core.run(framed_write(tp, Frame::Message(vec1)) .and_then(|tp| framed_write(tp, Frame::Message(vec2)))).unwrap(); let (tp, r) = core.run(framed_read(tp)).unwrap();
&gt; I'd point you to the documentation on this, but last I checked, it didn't exist. I used to say this all the time, but I forgot that it's in the nomicon: https://doc.rust-lang.org/stable/nomicon/hrtb.html Still very light though.
If they had a channel on freenode I would have asked there. At this point I just use the Read and Seek traits with the byteorder crate. It's working really well so far. The only thing I've had to write myself is an iterator on top of Bytes that iterates on nibbles and 5 bit values. Given how specific my needs are I'd probably need to define that even if I used a library. Edit: I finally joined iirc.mozilla.org.
Rust only receives a passing mention, and the article itself isn't very inspired in my opinion. Learning C isn't a bad thing to do, but why not learn Rust? People are successfully writing operating systems in Rust, no problem. It is a very low-level language with good high-level features. I sometimes consider it to lie between C and C++ in terms of how high-level it is, but it is wonderfully expressive. Rust has really good performance, easily on par with binaries generated by clang and clang++, although sometimes gcc and g++ do generate noticeably faster binaries. Again, I'm not opposed to learning C, and it is a good thing to do, but this article doesn't leave me inspired with newfound desires to write C code. C is much better than C++, in my opinion, because it is much more explicit with a lot less magic, but I have no plans of choosing it over Rust for anything that I *can* choose to use Rust for.
Wow, I didn't expect such a thorough review! Thanks so much for taking that time! Almost all of this is now in master. I think I learned more about Rust just from reading through your refactor than I have in my 3 days reading the docs. Particularly, the idiomatic early returns were a game-changer. I thought return expressions always had to be the last line of a block! The code is much more elegant now.
Oh, that looks lovely! Will definitely be making use of this in the future -- thanks!
The author does not seem to have really tried Rust, even though it is mentioned. Because if he had, it would have been clear that most of his points really don't apply to Rust. A Rust programmer often has to think about pointers, stack and heap when actually tuning for performance. While a C programmer often has to _worry_ about pointers, stack and heap while doing a little more than just a basic "Hello world!"
SSE2 is part of x86_64 *by definition* (i.e., it isn't an extension to the instruction set: it's part of the core instruction set).
I am trying to use `generic-array` in my project. This code: use generic_array::{GenericArray, ArrayLength}; #[derive(Clone, Copy)] pub struct CustomBuffer&lt;N: ArrayLength&lt;u8&gt;&gt; { buffer: GenericArray&lt;u8, N&gt;, cursor: usize, } Produces the following error: error[E0204]: the trait `Copy` may not be implemented for this type --&gt; src/lib.rs:7:17 | 7 | #[derive(Clone, Copy)] | ^^^^ field `buffer` does not implement `Copy` This is strange because `GenericArray` implements `Copy` trait. Am I doing something wrong or there is another problem? Also that costs of using `typenum`&amp;co. compared to writing several array types explicitly? Is it only compile time or there is runtime price to pay too?
I was mostly OK with the article until "Lastly most of the work we do with databases, key value stores, message queues and other distributed systems technologies mandates C, for performance reasons." This is the "C is the fastest language in the world" myth that Rust has been working tirelessly to dispel. :) In general I think it's fine to teach C with of goal of being able to read programs written in it. It is a legitimate point that there are a lot of C programs out there. But let's not "deify this ancient tongue" or perpetuate the all-too-common idea that "serious software is written in C". That idea is outdated and, from a security perspective, dangerous.
I'm just guessing here, but maybe the string version uses some copy on write properties avoiding the initial allocation.
Ah glad my post encouraged you! I think videos are great as well because some people are better visual learners. I think covering basics like that as well as demonstrating some cool projects people have done with it would be a cool thing you could do. Walking people through a problem and taking about it can be very beneficial!
Thanks for the inspiration to do so, man! I personally like to watch a few videos then read a book or two on the language I am learning. I have been wanting to give back to the community for a long time. I think some cool visual programs like a geometric or fractal rendering would be neat. Building a blog engine is a long time favorite of mine as well. I am still pretty new to Rust but, I think a project like this will be keep me on track and help newcomers get started, and hopefully hooked on it. Thanks again!
Yeah these are cool projects! Walking someone through the whole process could be really cool! I remember someone live coded an N64 emulator and posted it later for everyone to watch and that was fairly popular
If you intend to write something like `(1, [2, 3])` (not actual Rust) but accidentally type the closing square bracket at the wrong place, for example `(1, [2, 3)]`, that would pass the parsing phase and output mysterious error message. Maybe that isn't so big a problem in practice. I'm not sure.
Yeah but that doesn't quite have the ergonomics of `assert_eq!`. That said, I'll create an `assert_result_eq!` for testing purposes.
I know a lot of newbies start with JS or Python/Ruby/PHP because the development community at large views them as easy to start with. If you think about it though, how frustrating would it be to try learning to code with JS and encounter 'X is Undefined'? With Rust we get the nice compiler to help us along the way. Some view compiling as a hard or 'magical' process but in reality it aid you a great deal. Something like "Automate The Boring Stuff with Python" would be good. I think I will target at least mildly experienced programmers first and if that goes well see about an introduction to programming with rust series. Thanks for thee feedback!
The module system is somehow very simple and extremely confusing to newcomers at the same time.
The replacements are larger than what they replace, and thus `&amp;mut str` cannot work: it is not possible to increase the length of it. If it was ASCII &amp;rarr; single ASCII character then your suggestion would be great, something the standard library demonstrates with functions like [`make_ascii_uppercase`](https://doc.rust-lang.org/std/ascii/trait.AsciiExt.html#tymethod.make_ascii_uppercase).
There is the following Rust Learning list, with links to lots of places to learn about Rust: https://github.com/ctjhoa/rust-learning That can show you what already exists, and maybe help you find things that you don't think are well covered or could be explained differently.
A few resources I know of: (though not necessarily beginner friendly) * https://doc.rust-lang.org/book/ * https://learnxinyminutes.com/docs/rust/ * http://rosettacode.org/wiki/Category:Rust * http://rustbyexample.com/ * https://github.com/ctjhoa/rust-learning
Are we comparing similar algorithms or not? Servo is significantly faster than other browser engines (written in C or C++). Some may say it's unfair because it's highly parallelized and similar parallelized implementations in C or C++ would have similar speed; that's true... but how much would it cost to develop them without Rust's data-race freedom guarantees? The regex crate has possibly the best regular expression engine all languages confounded. It could potentially be backported to other languages, but why bother? Today, Rust should have comparable performance to C (sometimes slightly faster, sometimes slightly slower), while being massively safer. Small `unsafe` pockets can be necessary for performance reasons (for example, to avoid bounds-checking), but that is a reason to use `unsafe` which the developers would really like to get rid off. Tomorrow? Rust's strictly better alias documentation behavior should unlock new optimization opportunities that C's `restrict` just cannot hope to match. This requires some work on both rustc (to make sure to annotate safely) and LLVM (which may not have been that worried about non type-based alias analysis since that's how C traditionally does it).
You're borrowing `self` as soon as you enter the function body, and it remains borrowed until it returns.
Let's not forget both the Rust ecosystem &amp; tooling is quite young (compared to C, ridiculously so), and folks are working on building libraries to give us abstractions to work on, others are building lints that can help us write faster code, etc. In a sense we have the good fortune of only one Rustc that we can optimize for (or against, whatever you like better).
&gt; what third generation and beyond programming languages are typically considered to have better runtime performance than C? Not sure about which generation you'd place C++ but I'd argue for that. &gt; I haven't seen many claim it to beat C on overall runtime performance in general, at least not yet. Rust is fast now due to LLVM and so in principle can be as fast as any other frontend for LLVM, including C and C++. There's nuance that should be considered, though. Given input code with the same semantics, Rust "only" needs emit output that LLVM can optimize equivalently to what the C frontend produces. Rust has the potential to surpass C (and C++) in certain cases due to extra guarantees like non-aliasing pointers, so long as those guarantees can be expressed to LLVM appropriately. You also have to answer the question about whether the semantics include the implementation details. Like do you consider error handling with enums equivalent to error handling with integer codes or exceptions (in C++)? Do algorithms have to match? Do two programs have the same semantics when one allows automatic type promotion in expressions and the other does not, or is it sufficient to have input types align? Are you only considering "idiomatic Rust" vs "idiomatic C" to get the same final output? Details in Rust might force it to be slower in certain cases even for similar concepts like dynamic dispatch, e.g. if Rust's fat pointer model is strictly worse the thin pointer model for a particular use case. (I don't actually have real example in mind; I only mean to bring up the possibility that such cases could exist.) And then there's alternate compilers to consider. C and C++ have several options, with gcc traditionally able to beat out Clang + LLVM in the optimization department. So it might not even make sense to compare to "C in general" so much as "C with LLVM". I guess what I'm getting at is I'd be dubious of any claim like "Rust beats C overall" unless it includes a lot of detail.
There is actually a `find_iter` method that is even better for iterating on all matches. (I'm updating the article ^^)
&gt; Rust is fast now due to LLVM and so in principle can be as fast as any other frontend for LLVM, including C and C++. There's nuance that should be considered, though. 'As fast as' still isn't superior to, though, which is what I was asking about. Future potential I'm not asking about, as it then wouldn't already have better runtime performance. Note also that my question isn't about Rust, that was just a remark to try to pre-empt its mention. &gt; Do algorithms have to match? Fastest idiomatic non-matching implementations and general purpose compilers in both languages, i.e. without including foreign code. Slower compilers for any given program can be ignored, as you can always make a compiler cause strictly worse runtime performance than another. Regardless, I'm not comparing Rust and C, I'm asking if there's a language that's generally considered faster than C in general.
Right, I don't know if I was drunk when I read the results, or if my computer is playing tricks on me, but now (without editing the code since then) I see a slight benefice for `String` too.
I wanted to keep my original comment short so I hoped the tenses I used would be sufficient, but while I understand Rust may end up with insane performance, I'm talking about performance attainable by (the fastest) currently existing compilers, not about inherent language performance attainable in the future.
&gt; I'm not comparing Rust and C, I'm asking if there's a language that's generally considered faster than C in general. That was my very first sentence: &gt;&gt; Not sure about which generation you'd place C++ but I'd argue for that. Meaning: I'd argue C++ is generally considered faster than C, I just don't know if it meets your 3rd generation or later requirement. Take [this recent talk](https://www.youtube.com/watch?v=D7Sd8A6_fYU&amp;list=PLHTh1InhhwT7J5jl4vAhO1WvGHUUFgUQH&amp;index=3) as an example - the first half hour or so is on the topic. Or even the canonical `std::sort` vs `qsort` example. And there's always plain-old assembly. The rest was just in response to your aside where my ultimate point is that a claim like "Rust is generally faster than C" might not be meaningful to make without plenty of extra qualifications.
This so much. I just started trying to get into Rust and it literally took me more than an hour to figure out how to compile multiple files that reference each other..
Contrived scenario: I'd like a one-liner that takes a string and an integer and returns a string containing that many repetitions of the first three characters of the original string. The best I could come up with with my mediocre knowledge of Rust's standard library: `String::from_utf8(s.bytes().take(3).cycle().take(3 * n).collect::&lt;Vec&lt;u8&gt;&gt;()).unwrap()`. I assume there's a better way to do this. Is there?
I will be sure to have a lesson or two on just that! Thanks!
Added 2 FCP RFCs.
&gt; &gt; Some may say it's unfair because it's highly parallelized and similar parallelized implementations in C or C++ would have similar speed; that's true... but **how much would it cost** to develop them without Rust's data-race freedom guarantees? I believe you missed a few of his points... &gt; I was thinking of languages that can beat C on a decent bunch of microbenchmarks to keep things simple I believe the goal of Rust is not and has never been to "beat C" at all. It was to not compromise performance while guaranteeing safety... (Safety from the numerous bugs that results from the chaotic nature of human brain!)
Not a one-liner if you count the import but that'd obviously get put at the top of the file: use std::iter; iter::repeat(s.chars().take(3)).take(n).collect::&lt;String&gt;() Your one-liner only works with ASCII strings as it takes the first 3 *bytes*, which would split a multibyte character if its bytes straddled that boundary. Edit: my attempt above doesn't even compile, whoops. Here's one that does, though, and ditches the import too: s.chars().take(3).cycle().take(3 * n).collect::&lt;String&gt;()
I'm asking about performance alone, not cost. Cost is irrelevant as I'm asking about currently existing code, regardless of what process lead to their existence. I'm not trying to do any kind of general comparison. Nor is my question about Rust in the first place, it's just something that I wondered about upon reading a comment here, as this submission itself is almost entirely about C, not Rust, despite the sub. The additional text is just to address questions on how to compare.
Were you using the raw `rustc` or `cargo`? Just curious... Also, if you haven't been already, then let me introduce you to this new (but unfinished) [official Rust book](http://rust-lang.github.io/book/) ([repo](https://github.com/rust-lang/book/)). They'd surely be glad to get feedback from new learners.
The compiler is correct here: if the code was legal one could simultaneously have a `&amp;T` and a `&amp;mut T` pointing to the same data. Specifically, the `&amp;&amp;'a mut T` only "locks" the `&amp;mut` for the (anonymous) lifetime of the outer `&amp;`, but a `&amp;'a T` is not tied to that scope and thus could be held for longer than the `&amp;&amp;'a mut T`, even when the `&amp;mut T` is no longer pinned by the `&amp;` and can thus be used again. Working around it would probably be easiest by seeing a larger picture of what you're doing.
I'm using `cargo` :)
In that case, I believe C code is probably the fastest you can write for most (if not all) micro-benchmarks with "idiomatic" being the constraint while coding in any language. (Though, I am not very educated about "idiomatic C," so I might be wrong...)
The only contender I've seen suggested thus far would be C++, so it seems you may indeed be right when you say none.
Ah! The [modules](http://rust-lang.github.io/book/ch07-00-modules.html), then! You jumped to chapter 7, man!! Remember -- baby steps! :)
you only use `iter` once, you could just `std::iter::repeat` and it'd still be one line.
You might want to have them next week too, since I think most viewers are from the first day or two.
This is the problem MIR and incremental compilation will "solve", right?
Maybe you want to use `Borrow`? I'm still not clear on what you're attempting but here's what I'm thinking: https://is.gd/owLPhb
`GenericArray` only implements `Copy` if `N::ArrayType` does. I tried to follow the code to see when that would be, but I got lost.
You don't need to create a branch for clippy. ~~Make clippy a optional dependency~~Remove clippy from dependencies, and use `rustup run nightly cargo clippy` for running clippy (you need to install cargo-clippy with `rustup run nightly cargo install clippy` before that).
Oh that's a lot easier. I thought the optional dependency would't work because it required a different toolchain, but it works perfectly.
I agree, I just meant that if they _really_ wanted one line, it could be done :)
Thanks for the suggestion. The trouble is that your `Borrow` impls don't link `FooRef` to `FooMut`, you're linking `FooRef` to `&amp;[T]` and `FoorMut to `&amp;mut [T]`. I want to have a trait which defines the relationship between `&amp;mut T` and `&amp;T`: from a `&amp;mut T` I can get a `&amp;T` (by doing `&amp;*T`). Can I put this operation behind a trait, so that I could then implement it for `FooRef` and `FooMut` as well to borrow a `FooMut&lt;'a&gt;` and get a `&amp;'b FooRef&lt;'a&gt;` e.g. fn example&lt;'b, 'a&gt;(foo_mut: &amp;'b FooMut&lt;'a&gt;) -&gt; &amp;'b FooRef&lt;'a&gt; { FooRef { bar: &amp;*foo_mut.bar, baz: &amp;*foo_mut.baz, } } It feels like there is a missing implementation: impl&lt;'a&gt; AsRef&lt;&amp;'a T&gt; for &amp;'a mut T { fn as_ref&lt;'b&gt;(&amp;'b self) -&gt; &amp;'b &amp;'a T { /* what goes in here? `&amp;&amp;**self` doesn't work, as established */ } }
I think it would be useful to show any of the behind-the-scenes "magic" that Rust tries to abstract away from the user, or at least how to figure it out themselves. When I first started programming, I was told by a developer where I worked that Python was a bad starting language because of all the "magic" that it does behind the scenes that makes debugging very difficult. I didn't really know what he was talking about until I tried to convert bytes received on a socket from a C program into text with a Python program. Python would spit out an "encoding" error, which confused me because it was happening when calling the "decode" function. Turns out, Python was encoding the data in between receiving it and decoding it, but I had no way to troubleshoot it because it was abstracted away in such a manner that I had no idea how to debug the problem. Basically, showing users how to dive into the guts of Rust, when necessary, would probably be helpful in the long run.
&gt; how frustrating would it be to try learning to code with JS and encounter 'X is Undefined'? Not that frustrating in my experience. When you're just starting out, you rarely write something that's longer than 20 lines, so most errors are easy to spot. It also teaches people not to use single-letter variable names everywhere. &gt; I think I will target at least mildly experienced programmers first Yeah, I don't think Rust is a great language teach novices about loops, function definitions and conditionals. It's doable, and certainly better than Java or C++, but it's easier in a language like Python or Scheme which come with a REPL and lack a lot of potential distractions. For example, I was watching [this Hello World in Rust tutorial](http://intorust.com/tutorial/hello-world/) the other day, and I can easily imagine my younger self getting confused with `println!` being a macro, and wasting hours trying to figure out why, only to eventually give up because you have to know how compilation works, which is a pretty big jump from your first Hello World program. Anyway, it could be a great language to introduce people to static typing, type safety, concurrency, immutability, systems programming, package management, and other things you don't expect to see in the first chapter of a programming for dummies book. Edit: Actually, a introduction to programming with Rust series wouldn't be the worst idea. There will always be people that want to start out with a "real-world" language, or something "more advanced" than Python, so having one using Rust would be great alternative to the more common Java and C++ ones.
You kind of just skipped right over the other example that was given: the regex library. It's especially fortuitous since there exists a similar regex engine written in C++ (RE2) and a similar regex engine written in C (GNU grep). Certainly, I perceive the deltas between these engines to be substantially smaller than the delta between Servo and any other mainstream browser engine. The algorithms are fundamentally the same. If you erased all of the optimizations in each of the regex engines and compared just the throughput of the DFA in each, then you'd end up with quite similar performance. (At least, this is based on my experience. Substantiating this claim with really hard evidence would be a lot of work. I have a lot of it done already, but there's still a lot more left to do.)
Solid points! I was just thinking it would be a good teaching tool if Rust had a REPL. One thing I have noticed working in the web world is how many developers really don't know a whole lot of CS basics. They can make a web app but, ask them to create HTTP headers from scratch you will get blank stares. While a very broad brush, I think its important to illustrate some of these nitty gritty details(new or otherwise). 
As usual your snarky responses to low hanging fruit leave much to be desired.
Just wanted to drop in and say thank you for this post; helped me with the same issue. 
It would be great if the reader could hover over parts of the code and see a tooltip explaining what each part means. In this case, in order pub[the function is public, and can be accessed from other modules] fn[we are declaring a function] anagrams_for[it is called "anagrams_for"] &lt;'a&gt;[it has one type-level parameter, and that is a the lifetime(click to read more about lifetimes) of the references it works with] ([it takes two runtime arguments] s: &amp;'a str[one called "s", which is a reference to a str(a section of text) that will be available for the duration of 'a], ..etc
ISPC
&gt; gcc traditionally able to beat out Clang + LLVM in the optimization department I agree that that's true "traditionally" but my understanding (and I'm no expert) was that Clang + LLVM has surpassed it in recent years.
While I have no doubt they've closed the gap, last I heard (a few months ago) they were still behind in some areas. It could be they're ahead in some areas too. I'd definitely have to look up those benchmarks again though.
I'm curious to hear what you find out about it! Please message me or reply if you remember. :)
Java, by which I mean the platform, not necessarily the language. Seriously. Just look at the big distributed systems software all the "web scale" players produce, release, or contribute to. Java, Java, everywhere. (Rust has an opportunity here -- it's expressive, produces fast code, has a rapidly advancing async story, doesn't have GC pauses...)
Released version 0.3.0 and 0.4.0 of my [lewton](https://github.com/est31/lewton) vorbis decoder ([changelog link](https://github.com/est31/lewton/blob/0.4.0/CHANGELOG.md#release-03---october-4-2016)). Also got lewton included into cpal.
Rust uses balanced parentheses to detect the end of a macro call.
Doesn't foo.ok_or("error") do the same thing?
I had heard (unfounded buy wouldn't be surprising) rumors of rust in algorithmic trading (specifically HFT) but to see someone actually do it is fascinating! I'll be looking forward to see how this project evolves.
As someone who is interested in learning how to develop on tiny boards like this, can anyone compare this to a Teensy, since that's the one that I've just gotten my hands on? https://www.pjrc.com/teensy/
&gt; (e.g. DirectX is all COM-based **u**se OpenGL u**s**e OpenGL us**e** OpenGL use **O**penGL use O**p**enGL use Op**e**nGL use Ope**n**GL use Open**G**L use OpenG**L** 
I see I see. I felt the same way when I was going to start one for the OC. It's a bummer driving to LA isn't viable. Thanks for organizing it :)
You have several options. I've been exploring the space recently. So I'll try to give you my thoughts and experiences. The main options: * [Piston ecosystem](http://www.piston.rs/) * Tomaka ecosystem * [Amethyst game engine](https://github.com/amethyst/amethyst) * Existing libraries with rust bindings I haven't explored the piston ecosystem yet. It's a loose set of libraries that mostly work together. It's probably pretty nice. I also haven't looked at Amethyst. Tomaka makes great libraries and lots of his libraries are compatible with other libraries. I've been using [glium](https://github.com/tomaka/glium) and it's really nice. I'm currently taking the last approach with some of Tomaka's stuff mixed in. You can find that here: https://github.com/dagit/rust-2d-demo I think /u/Rusky is right about windows stuff, except I've had a lot of trouble getting things setup just right with msvc (I swear cargo is ignoring my `.cargo/config`. I was forced to set the `LIB` environment variable instead of using a config.) but with mingw you can use pacman to install things like sdl. This really only pertains to C and C++ dependencies that you might need. If the dependencies are in rust and come from crates.io (or git repos) then it's super easy and I don't think twice about adding dependencies that way. I highly recommend using [rustup](https://www.rustup.rs/) to install and manage your rust toolchain, regardless of platform. I find rustup to be completely indispensable. It allows you to temporarily switch between toolchains. So if you're using windows and want to see the difference between msvc and gnu first hand, you can just do it with a single command without lasting effects. It's also really great for upgrading when a new rustc comes out or building something that needs nightly, like clippy. I have found though that once you get cargo to see your dependencies then everything works really well from that point forward and is overall much much easier than CMake. It's also easier on Linux and OSX than on Windows (in my experience).
&gt; Would we be throwing these out by using Rust, or do we get to leverage them as well? Yes, you can totally use GDB to debug Rust programs running on the F3. Breakpoints, printing variables and disassembling; all that works. OTOH, the Teensy doesn't seem to have *hardware* support for debugging. I see no mention of JTAG or SWD, which are the standard interfaces for flashing and debugging. Since it mentions a bootloader, I assume that one can only flash programs but not debug them.
[ZoC](https://github.com/ozkriff/zoc) works on win/linux/osx/android, thanks to awesome [glutin](https://github.com/tomaka/glutin) and [GFX](https://github.com/gfx-rs/gfx/) libs :)
Hi! A am working on [game](https://twitter.com/BringerShar) and we are developing on linux and building for windows too. The only and most serious issue with windows - cross compilation from linux doesnt work(or i just couldnt doing it right). So I am using real windows box with jenkins for windows builds. There was some minor issues, mostly with some c++ dependencies, but in general - just "cargo build". Compared to c++ - cross platform builds is much easier. About comparison with cmake - cmake is much more configurable etc, but cargo just works, i am 100% satisfied. We have those 3 (little more, to be fair) projects and everything is fine. TLDR: Rust is great, cargo is great.
Please stay with the topic, and stay civil. Thank you.
You're welcome - I think you're right that reading all the docs available can't replace writing code and getting a "feel" for it - and the community is a valuable resource for getting small misunderstandings out of the way. I recall a highly theoretical discussion about how lifetimes suck with someone who hadn't written a single line of Rust, and it was exhausting, especially since any recommendation to write code was met with "don't patronize me"...
(not the person you're replying to) Modules in Rust still confuse me a bit too, especially the more advanced features. I've been programming in Rust (only a few -tired- hours a week) for only a couple months, but I've been programming in all sorts of languages for 15 years. I read that chapter on modules at least twice, and I still had to do a bunch of googling and looking up projects on github to see how people do things. I don't think it does a very good job at covering what a new Rust-user is likely to need. The example with the language greetings works great to explain "how to provide various implementations of one API", but not so much for "how to compartment a large piece of code in smaller units that need to work together". 
Moreover, C is fast because there is a significant market incentive for C to be fast, and there has been for several decades. Its not that there *couldn't* be a faster language than C, its that there *hasn't* been a better optimizer than gcc/llvm.
Yes, they will be mentioned in all weeks till they are in FCP.
I learned C, but never used it much professionally. My general understanding is that if I need to write in C, I will. But when I want to write code for performance, I'm gonna stick with rust. The borrow checker is a best friend compared to segfaults. But I do, honestly, agree that people should learn some C, especially before they learn Rust (for context).
It's mainly just pandering to C fans. I doesn't really qualify as an appeal to outsiders.
I am interested! Loking at various sellers online, they have boards ranging from 18€ to several hundreds... which should I get?
I'm writing a FUSE filesystem that takes a music collection description, a bunch of unorganized badly/non tagged files and expose the collection in a nice directory structure with fixed tags, ready for consumption by a music player. This allows me to leave the original files unmodified for bittorent seeding (booh !), without duplicating the content on disk.
You mean like http://intorust.com ?
Leaving same comment from HN (TLDR: Most of his arguments about C apply to C++, Rust, and D as well) &gt; It is still one of the most commonly used languages outside of the Bay Area web/mobile startup echo chamber; Fair. &gt; C’s influence can be seen in many modern languages; Saying that that's a reason to learn C is a non sequitur. Why? &gt; C helps you think like a computer; and, So does C++. And Rust. And D. All the stuff about databases can be done in any of these languages, C doesn't have a monopoly over letting you be close to the metal. It's one of the only languages that pretty much *forces* you to be close to the metal, but that's not a plus point. &gt; Most tools for writing software are written in C (or C++) True. Hacking on your tools is great. But hacking on your tools rarely requires proficiency in a language (unless you're doing something major, which you're not), I've hacked on tools written in all kinds of languages that I don't know. And the justification behind this point follows the same flimsy reasoning as the previous one, the reasoning that C is the only low level language out there. The post gives "browsers, operating systems and languages" as examples, but all three of these exist in Rust (Servo, redox/intermezzos/a bunch more, and rustc). I'm sure that D is up to the task for such software too, if it doesn't have them already. C++ of course has all of these. Sure, you need to know some C when doing low level programming and/or FFI. But nobody's arguing against that. "Everyone “has been meaning to” learn Rust or Go or Clojure over a weekend, not C." is a false dichotomy. With Rust for example it's pretty easy to learn enough C to manage once you've learned Rust (there are tons of folks in the Rust community who have done this). You're not *forsaking* C, you're just focusing on something better. You can learn enough C to be able to read code and do FFI, and you're pretty much set for writing databases or operating systems or networking stacks or whatever. Reading C isn't too hard and if you speak another low level programming language you can pick this up over a weekend. The only valid argument I see here is that C is is still *used* a lot in existing codebases, and you should be proficient if you want to be able to contribute significantly to them. Of course. But cut all the crap about C being the only language that can handle these use cases.
&gt; Cost is irrelevant as I'm asking about currently existing code, regardless of what process lead to their existence Rust is approximately as fast as C, in that case. There are examples where it is faster (the regex engine implementation that currently exist, see burntsushi's comment above), and examples where it is slower.
Fortran?
OpenGL has one of the most terrible APIs ever designed if you have to use it directly... If I had to choose between raw GL and raw D3D I would choose D3D by a mile. Luckily there are existing rust libraries like glium which provide a nice safe API over the top, so you don't have to deal with that.
The new 3.5/6 have them broken out, you can do it on the 3.2 but it requires altering the board to get access to the swd pins
&gt; 'As fast as' still isn't superior to, though, which is what I was asking about. Rust is going to have a very hard time beating C while targeting a C compiler backend, speaking the C ABI with no overhead, and running on computers that are optimized for running C code. Go can beat C or Rust on any multithreading benchmark, for example, but it eats a high FFI overhead to do so. A compacting GC can allocate by bumping a pointer. The problem with beating C is that C has a privileged position in the stack.
There's also the fact that you're dealing with COM objects that need to be reference counted, and C++ has more mature options for `ComPtr` wrappers.
[deleted] ^^^^^^^^^^^^^^^^0.0754 &gt; [What is this?](https://pastebin.com/64GuVi2F/57524)
I will definitely cover this. At work I am trying to this very thing. We use Python but, for the thing we are trying to do we need something very powerful while still letting devs use Python(they kinda refuse anything new). It really is a powerful feature.
Hey, a bit of a plug, I've got a crate already for the teensy 3.1/3.2, and it should support the 3.0/3.5/3.6 with a little work, I just don't have access to those boards to test with. Heres the crate: https://crates.io/crates/teensy3 And heres a git repo you can use as a template, with a little bit of documentation to get you started: https://github.com/jamesmunns/teensy3-rs-demo In this crate, you have access to a few hand-made safe bindings (Serial, with SPI and delay about to be merged), as well as unsafe bindings to the entire teensyduino library. It would be great to have more contributors.
Great post, loved it! Would gladly read more port stories, it's so encouraging to see Rust spread. I only have one small comment: there should be a `c_char` in the `libc` crate (IIRC there are platforms with non-8bit `char` in C, so it'd be more portable).
Thanks for all the helpful comments everyone! It's pretty safe to say at this point that our plans to use C++ have *rusted* away.
Someone made a minecraft renderer based on piston. It's one of the examples on their website. Tomaka makes a ton of libraries. Glium and vulkano for rendering. Glutin for getting an OpenGL context and input handling. Cpal and rodio for audio stuff. Immi for UI stuff. That's just the libraries I've tried. He probably has other stuff. 
I've tried to avoid generalized statements about fairness, as I'm interested in the different *perspectives* people have about languages' general performance bandwidths, and only narrowed down after receiving questions in response. Maybe this is not the best reddit to ask such a question; I only asked it here because a comment posted higher up in this thread made me wonder about what people thought about this matter in the first place and I expected the subscribers here to have strong ideas about this in general, given the Rust community's desire for performance, maybe owing to it being called a systems programming language frequently (if not vice versa). I'm therefore well-aware of Rust's very good performance, while today I wouldn't think it to mostly beat C by a metric I would personally deem fair (quoted below). Rest assured that I don't expect a scientific level of support for statements in response to a question that I intended to just get some sense of the perspectives people hold. The most interesting and unexpected answer I received so far was C++, which I thought of so similarly (possibly erroneously) to C that I didn't even stop to consider that possibility beforehand. Aside from that, other interesting suggestions I've seen were Fortran, Java and /u/__Cyber_Dildonics__'s list of suggestions "c#, java, Julia, (lua jit?)" that surprised me, as I think of them as more high-level, which in most of those cases I don't expect to line up with superlative performance. After receiving followup questions, I encouraged the following metric: &gt; Fastest non-matching functionally-equivalent idiomatic algorithms in the fastest general purpose compilers available today. I believe that addresses A-&gt;B translation difficulties that you foresee, which I completely agree with, hence the metric above.
&gt; Go can beat C or Rust on any multithreading benchmark, for example, Only if you try to do system threads vs go's threads: Rust has more options here. You can use a library that implements green threading.
Thanks for the clarification! I didn't mean "potential" to imply "there's none today" but I can see how that would be ambiguous at best now. I also didn't want to say something I had little knowledge of. The codegen phase is very dark gray box to me, though I'd love to lighten it eventually; the compile time explosion with generics is killing me and I want to help if I can. Are there any MIR optimizations in? I knew MIR afforded new opportunities for that but I'm not aware of any which are implemented given how recently it was enabled by default.
Nice! Do you know if the SWO (I think that's the name) is also exposed? I'm referring to the pin that you can use to send ITM packets to the host (cf. CMSIS' ITM_sendchar) Also, the board doesn't have a built-in debugger, right? Do you know what external debugger does one usually use with these SWD capable devices?
I don't think you understood what I was saying. I was making the point that these language's performance are much closer than the speed gains from writing fast software.
I would think they can be reconciled: LLVM today is specialized for C (and C-like) languages, so using an unmodified LLVM it is next to impossible to do better than C. If optimization passes that better exploit alias analysis are developed in LLVM, then C will not (today) be able to fully use them while Rust may, giving Rust an edge. But that's a theoretical edge, and I know of no-one working on this for now. However, this is for the fully-optimized case, where anything Rust does could be reverse-engineered in C (at the cost of maintainability). When people refuse to sacrifice maintainability in the name of performance, Rust may have an edge over C again... and this matters too, because Rust has a 0-cost FFI with Rust, so you can: - use optimized Rust to get C's speed for the critical part of the loop - use idiomatic Rust to get C's speed for the non-critical part of the loop, maybe being even faster than idiomatic C (opaque pointers usually mean memory allocation, for example) which means that Rust can get to C's speed (or very close) with a significantly higher maintainability.
&gt; Rust doesn’t need to string together horse hair to make rope when it’s got carbon nanotubes pouring out of its ears. Quote of the week?
Automate the boring stuff is fantastic. I'd love to see a rust version that walks through basic projects like "scrape the contents of this website". Or "build a csv from a vector of hashes". Or show making simple console applications like in this post! http://ticki.github.io/blog/making-terminal-applications-in-rust-with-termion/ Also, The Bastards book of Ruby is great in this regard as well. http://ruby.bastardsbook.com/toc/
Is there any plan for implementing windowing-y systems in Termion, à la [urwid](http://urwid.org)? Even just tools to divide the screen up into chunks could be helpful. I'd understand if it isn't a design goal, though. 
Illuminati confirmed
Very good article! I think you might have mistakes in several of your C code snippets, BTW. You probably meant to write your functions `void take_ptr(void *thing)` and not `void function take_ptr(void *thing)`.
&gt; a shell in rust named rush simply because the name is perfect You win the thread.
I've been using the image crate for my image loading. I know it can write PNG but I'm not sure about other formats.
Can you leave on interrupts like SIG-INT when you enter raw mode? 
I have been using ncurses-rs but your projet looks nice I'll probably try to switch ! 
Beginner to intermediate would be the correct terminology
That's true, but building your own ComPtr for Rust isn't a difficult task either. Usually the most annoying part if you want to make sure only COM types are used in it, you'll need to implement a trait manually for all of the interfaces you use.
Can't help but notice you translated `int` to `i64`, which is incorrect on *every* modern C compiler. If you need to be identical to C targets, use libc::c_int, which is i32 on all 64-bit targets.
The bigger issue with char is that signedness of `char` various by platforms, so you don't know if it should be `i8` or `u8`.
Jeez, really? That explains some issues I had. Thanks.
True- the other obnoxious part is casting between interfaces, which C++ can just use inheritance for.
This struck me as relevant to most Rustaceans' interests :) I think I'm going to file some clippy issues for some lint ideas!
I didn't downvote you, and I don't encourage anyone to. But if you want to avoid downvotes, maybe explain what's wrong with the code as written and suggest a correction?
Is there a particular reason that the Future trait looks for the current task in global-ish thread local storage, rather than passing it as an argument to `poll`?
Using the replace method will avoid the extra allocation of a Vec, so it's a little more efficient, but yes, #rust-beginner gave you a more direct translation of your original code.
Looks pretty similar to the method I ended up with! No copy-paste on my side, though. Your success gives me hope! I'm currently stuck on some huuuge functions that I flat-out can't port piece by piece :'(
This reads like a case study against Java's checked exceptions (by encouraging people to catch exceptions at an earlier point than you can logically handle the error). While it's definitely possible to do this "correctly" with checked exceptions, human psychology works against it, because you just want to make the compiler stop complaining about the uncaught exception. I generally see try {} catch { Log("problem!"); } pattern way more often in Java than in C#, because in C# you tend to just let the exception bubble up the call stack until you hit a logical place to handle "oops, &lt;task&gt; failed for some reason."
Oh no! I thought about termion for my TUI, I guess I have to use Cursive then... ;-)
There are [tessel boards](https://tessel.io/). Rust support is still work in progress, but development has beeen pretty active lastly, and according to [this blog post](https://tessel.io/blog/150309170742/this-week-in-tessel-special-report-from) from september, the plan is to fully support rust in 2017: &gt; Build first-class support for Rust API and documentation (parity with JS) and figure out JS-Rust inter-exection to provide for performant high-level coding of serious applications. I bought a board but didn't get time to play with it yet, so I can't really give feedback.
Consider working on your phrasing - quoting someone with no comment other than "um, what?" makes it look like your intent is to mock them. If you have a "perfectly valid question", could you re-phrase it to make the question more clear?
Meh, it's fine intermediates. Just read the examples and skip the text. It should be sufficient.
Actually, it was planned that the Redox shell should be named like that, but for some reason, we picked the boring name "ion" instead. Damn, chance missed.
(disclaimer: I'm the author of Copper, Xargo and `f3`) &gt; How is Zinc.rs going? Not in active development. Here's the [mini post-mortem] from its author. [mini post-mortem]: https://users.rust-lang.org/t/zinc-mini-post-mortem/7079 &gt; Is there an updated tutorial to deploy Rust into an Arduino and other small devices? &gt; Arduino Pretty much the only microcontroller family that Rust supports right now is the ARM Cortex-M one (e.g. Arduino Due). AVR (the rest of Arduions) support should be coming next, after the avr-llvm fork has finished its upstreaming process. About documentation. There's no central source of information right now but there are several resources around: - The [Copper] book. Bare metal development for the ARM Cortex-M from scratch. Right now, it covers tooling (OpenOCD and GDB), how to flash and debug your Rust program and how to go from booting the microcontroller to blinking an LED. It's written in a device-agnostic manner. - [rust-on-bbc-microbit]. Top down approach to use Rust within a C framework. - [Hanno Braun's blog]. Rust on the Arduino Due - [teensy3-rs]. Rust API on top of the teensy C libraries. - [f3]. High level, Arduino like API to program the [STM32F3DISCOVERY]. (This crate has zero C dependencies). - [Jake Goulding's blog] and [avr-rust]. [Jake] and [Dylan McKay] are working towards official Rust support for the AVR (Arduinos) architecture. - [Tock]. A secure embedded operating system for Cortex-M based microcontrollers [Copper]: http://japaric.github.io/copper/ [Dylan McKay]: https://github.com/dylanmckay [Hanno Braun's blog]: http://embedded.hannobraun.de/ [Jake Goulding's blog]: http://jakegoulding.com/blog/2016/01/02/rust-on-an-arduino-uno/ [Jake]: https://github.com/shepmaster [STM32F3DISCOVERY]: http://www.st.com/en/evaluation-tools/stm32f3discovery.html [Tock]: http://www.tockos.org/ [avr-rust]: https://github.com/avr-rust [f3]: https://docs.rs/f3/0.1.0/f3/ [rust-on-bbc-microbit]: https://github.com/SimonSapin/rust-on-bbc-microbit [teensy3-rs]: https://github.com/jamesmunns/teensy3-rs &gt; Is there already an 'Are We IoT Yet' website? We have the http://areweembeddedyet.com domain but it's currently empty :-) &gt; Where could I direct people that are interested to talk about IoT and Rust? To [embedded-rust](https://github.com/japaric/embedded-rust). We are organizing ourselves to get Rust on embedded systems off the ground!
Nope!
Fixed.
Take a look at `termion::get_size`. You cannot resize the window. That's simply not possible in the design of the escape codes and the TTY in general.
twas a joke
I meant terminal resizing as in a resize event being caught by the program (and acting on that), not setting terminal size.
Or try vulkan
Are you kidding me? The article title clearly says "porting from C", and when I saw that function definition, it was genuine surprise. And, oh, I did have the courtesy of pointing that out on the author's blog itself. My point is that any other article of such dubious quality would have been raked over the coals under usual circumstances. It makes me wonder about why it did not happen in this case. So, thanks for your advice, but my update was rather rhetorical. It doesn't surprise me one bit.
I honestly have no idea what you're trying to point out here. A question with more detail, such as "Why is this (something) on the 3rd line instead of (something else)?" would have been a much more valid question than "Ummm... what?" 
Quod erat demonstrandum.
This started out as a C++ blog post, but I managed to shoehorn some Rust in there. Let me know if anything is incorrect/misleading; only some of the code was compiled, and I'm I'm not an expert in either language.
`make tidy` lists all features, language and library, so you can find them in the [build logs](https://buildbot.rust-lang.org/builders/auto-linux-64-opt/builds/10656/steps/test/logs/stdio) (scroll to the end). [Here's all of them in a gist](https://gist.github.com/brson/5e94ad9ee14a22793da5782fd1a74e5c).
Oh huh that no longer lists lang features. That's disappointing.... https://github.com/rust-lang/rust/issues/37013
Seeing how my name begins with "Rush", I will be one of the first users of that shell :)
You stopped short of the [true power of this pattern](https://insanitybit.github.io/2016/05/30/beyond-memory-safety-with-types) when implementing a state machine like that. Basically, you hang your methods off the different states and rely on language features like Rust's ownership to ensure that, when a method returns a new state, references to the old state are invalidated. (And, usually, Rust developers then rely on type inference to make it more comfortable) [Hyper](http://hyper.rs/hyper/v0.9.10/hyper/index.html) uses this to ensure, at compile time, that it's impossible to get into situations like the "tried to set HTTP headers after request/response body has begun" that we see periodically on PHP sites. (The compiler can catch that because there *is* no "set header" method on a connection in that state and the invalidating of stale references allows it to be certain that only the correct state is being referenced.) ...though, unlike that blog post, Hyper used parameterized types last I checked, which would make the blog post's version more like `IMAPConnection&lt;Authenticated&gt;`.
Wow, I wasn't aware of this approach. As you say, it takes this pattern to the next logical step. It makes sense, and I can see how you could implement something similar in C++, but you wouldn't be able to enforce the referential integrity. I'll make a mention of this in my post.
This is a known issue of the compiler: https://github.com/rust-lang/rust/issues/30472 A workaround is using `for&lt;'b&gt; &lt;&amp;'b T as Mul&lt;&amp;'b T&gt;&gt;::Output: Into&lt;T&gt;` instead (https://is.gd/WjhdJw).
Brilliant! Many thanks.
Hey, this is a good tip, thanks.
In the beginning, everybody had 16-bit CPUs, so `int` was `u16`, and (for the times that wasn't quite big enough) `long` was `u32`. Then 32-bit CPUs became popular, but there was a bunch of code that assumed `long`==`u32`, so we added `short` as `u16`, `int` became `u32` and `long` stayed `u32`. Many years later, 64-bit CPUs became popular, and by this time, there was very little code remaining that assumed `long`==`u32`, but there was now a lot of code that assumed `int`==`u32`, so now we have `short` as `u16`, `int` as `u32` and `long` as `u64`. ...except on Windows, where Microsoft didn't want to even *potentially* break existing code, so there you have `long` still as `u32` and `long long` as `u64`. Even though it's the native integer size of the CPU. *sigh*
I fired up a Jekyll based blog on GitHub pages in the hopes of blogging more ... mostly about Rust. My old wordpress blog was a bit "bleh" and now I feel like I have more control. I might migrate some things across but for the most part I am starting fresh and trying to improve both my Rust knowledge and writing skills. I have managed to teach a few Rust concepts to a friend who didn't quite understand the book. So I am hoping I can bring that skill to a blog about Rust.
Someone mentioned in [another thread](https://www.reddit.com/r/programming/comments/568o34/typesafe_unions_in_c_and_rust/d8hgcpw) that [boost::variant](http://www.boost.org/doc/libs/1_61_0/doc/html/variant.html) does a lot of this, but C++17's variant is making a few extensions to make it a bit more ergonomic.
That's good to know, but I've basically avoided all usages of boost. It was tough enough getting one codebase compiling for the three major desktop OSes and Android/iOS, and I don't think I could handle throwing boost into that mix.
For reference: https://en.wikipedia.org/wiki/Network_function_virtualization
In the meantime, we could start "Are We 'Are We IoT Yet' Yet"
Yes, I can see that very well indeed. Brilliant job.
Lack of verbosity is for scripting, a systems language should be verbose, Rust is verbose but the syntax is sugary!
Also known as variant records in Pascal and Ada and first class data types on those languages. 
It's also worth noting that the signedness of char in C is not undefined, it's implementation-defined, which means a compiler must document what it does.
&gt; Almost all catastrophic failures (48 in total – 92%) are the result of incorrect handling of non-fatal errors explicitly signalled in software. sounds like you need stronger type systems, not testing
BTW, making `from` argument of the `replace` a char will make it a bit faster. "ciao come va!".replace(' ', "_") benches: running 2 tests test replace_char ... bench: 139 ns/iter (+/- 21) test replace_str ... bench: 169 ns/iter (+/- 11) test split_join ... bench: 190 ns/iter (+/- 7)
&gt; Since day 1, the biggest selling point of rust, for me, has been error handling. I love a lot about rust, but I just feel that it does error handling so well. I don't think that's necessarily how everyone feels - sometimes I see comments about it being verbose, or requiring boilerplate, etc. Personally, I have never felt that way. I love it. Especially the ergonomics around unused Results, try! and such are great! Above all, it's _extensible_. For me, it is basically the promise of Java checked exceptions, delivered.
Since Rust needs individually addressable `u8`s (emulating them in a thread-safe way is hard), those platforms will probably not support Rust well, so I'm not sure if this is worth the bother.
Ahh. I haven't actually had to use `flat_map` in my projects yet (too much time spent on results-centric coding, so I still code mostly in Python, my most productive language at the moment) but, even interpreting it as `itertools.chain.from_iterable(f(x) for x in source_iterable)`, I still don't see how that'd relate to the Rust state machine part. Sure, something like `transforms[x, y]` would let you index into a mapping from `(srcType, destType)` to functions, but, given that the goal is for the compiler to verify correctness, what benefit do you get from specifying the output type in the type signature? It seems to me that it would either have no benefit or require the output type to be known before the object can be instantiated, resulting in prohibitive combinatorial complexity. Compare the approach I'm familiar with, where the input type is constrained by only defining the transition function on certain parameters (eg. `Connection&lt;Pending&gt;`), prevent stale references by having the transition function take ownership of `self`, and let the transition function's signature constrain the output type (eg. `Connection&lt;Pending&gt;::send() -&gt; Connection&lt;Sent&gt;`).
Thanks for the testing. I had actually tried making both the from and to arguments chars, which didn't compile. I wonder why the language designers chose not to allow a char in the to argument!
Yes. I've been meaning to explore that method. But I haven't gotten back to my IMAP library in a while.
Thank you a lot for the information everybody!
Is raspberrypi considered embedded or iot? Curious about support for that.
Question: Could you do the same with an abstract class and then check the type with dynamic_cast? if(NewType* v = dynamic_cast&lt;NewType*&gt;(old)) { // old was safely casted to NewType v-&gt;doSomething(); }
&gt; he transition function there is really just hardcoding a &lt;()&gt; in for that &lt;T&gt;. Not sure what you mean? The transition is defined as: fn transition(self) -&gt; Result&lt;NewState, OldState&gt; I may be misunderstanding you.
Okay! Let me know if it's a 3.0, and I'll make the necessary changes so you can test them :)
Right, that should work. Thanks :p
Raspberry Pis are a different class of devices. Even tho their form factor is small (specially the Zero), it has processing power to run a full Linux OS for example. The tooling to compile to ARM processors (eg: raspberries and many androids) is available already. - https://github.com/japaric/rust-cross - https://github.com/Ogeon/rust-on-raspberry-pi (a bit outdated)
I've been using Rust to write a [simple irc client](https://github.com/FreeFull/ircclient). It's not really good enough to replace any serious client yet, but writing it has been pretty fun so far.
For several reasons (off the top of my head): - As you mention: power usage. An RPi probably consumes 1-2 Watts (my estimate) siting idle. A microcontroller consumes *micro* Watts when it's sleeping (siting idle). That's several orders of magnitude of difference. Power consumption is very important if your product will run powered by batteries. - Lower cost. A microprocessor, like the one in the RPi, can cost like 10$ (my guess). A microcontroller costs 2-3$ or even less depending on features. The difference may not seem much but a microprocessor requires external components like RAM that the microcontroller doesn't (it has internal RAM). Also the Printed Circuit Board (PCB) requires a different, more costly design (and more passive components like capacitors) for a microprocessor because it runs at higher clock frequencies. - You have more control over the microcontroller. A full blown OS runs a bunch of services in the background which make your application less predictable because the OS may interrupt it. Also Linux is not a RTOS ("real time" OS) whereas there are several RTOS for microcontrollers.
Version 0.6.0 adds a lots of new features, like template generation, commit hash links, custom headers/footers and multi processing. 🤓🎉👏
Ok, let's see how far I understand this. &gt; each of these commands should return something out of the state machine! Being primarily a Pythonista, my first impulse would be to resort to tuple packing and unpacking, having the transition function used like this: `return_value, fobj = fobj.read()` &gt; You are probably thinking "hmm, that sounds suspiciously like a functor" I'd probably just say "Huh. Looks like a chainable filter, similar to how I chain up generators to build processing pipelines." I'm too used to Python's "all functions are first-class, the syntax for a generator is just a function that uses `yield` instead of `return`, closures are supported, and you can make any object callable by defining a `__call__` method" approach so I only knew "functor" as the name for how first-class function behaviour is hacked into Qt. &gt; But that would actually not be the best free monad I tried looking into what a free monad is, given that I'd never heard the term before, but I kept running up against the fact that I don't know the syntaxes for any of the functional programming languages used to write the examples in the explanations. The closest I got was a [StackOverflow answer](http://stackoverflow.com/a/13357359) which summed it up as "Free monads are just a general way of turning functors into monads." but then I couldn't parse the example code to understand what benefit you'd get from doing that. However, another post I read talked about them in the context of abstract syntax trees and as a solution to being able to build a grammar where the type signature of each token doesn't depend on the following tokens and the grammar doesn't need a terminal token... so I think I understand that it is used to enable a controlled relaxation of type restrictions to put together a stream of functors. ...however, without actually being able to understand the example code I found, this is all still far too abstract for me to understand why it would be relevant. &gt; Exactly why and how is well beyond the scope of a reddit post, but suffice it to say, you can have a bind op that will not only operate as usual on your return types, but also walk between states of your state machine at the same time. That sounds like you're rephrasing the "you lost me" moment I ran up against while trying to make sense of it myself. How is returning `String` rather than `(String, FileLikeThing&lt;Open&gt;)` superior (is it just a cleaner API?) and, more importantly to me, how do you implement it such that the compiler retains the ability to verify correct use?
Think about my file system example above--`Opened` and `Closed` are states of the state machine, and it makes sense for my file commands to transition between these states, right? But what's the *point* of running that state machine? When I do those file commands, my goal is not merely to open and close files: I want a *result*. Putting that in your `NewState` should immediately feel like something is off--`readContents` does not transition to the state `Opened,String`, that doesn't really make sense: `Opened` is the state of my file handle, the result of the read command has nothing to do with that. The `String` is not the same "kind of thing" as the result of transitioning between opening and closing the file. EDIT: accidentally submitted my post half-written somehow.
Thanks for the shout out. I've been actively [working on landing cross-compilation support](https://github.com/tessel/t2-cli/pull/1014) and we have [an early hardware API](http://github.com/tessel/tessel-rust) and crates for some sensors. Hopefully I can get this online before the relevant RustFest talk is posted :) As mentioned above, we also want the ecosystem to integrate with the work done in [embedded-rust](https://github.com/japaric/embedded-rust) as much as we can.
screenshots, do ya haz some? :) (kewl kidz are towkin' like that, aren't they?)
&gt; sometimes I see comments about it being verbose, or requiring boilerplate, etc. Then again, I've seen so many people (along the years) basically ignoring error handling altogether that having all of it thrown in their face suddenly must be overwhelming. I sometimes jokes that software is 20% golden case and 80% corner cases...
Actually, one of the issue reported is the reverse: using the base class in the `catch` clause and crashing, forgetting to first check for a simple (and I assume trivial to work around) version mismatch issue. That, for me, is the real issue about Java exceptions' dual nature: mixing recoverable and irrecoverable in the same bucket, sometimes you mistakenly abort on something that would be recoverable with a minimum of effort...
You're right, no Kool game can exists without screenshots! Edit: [added](https://github.com/nabijaczleweli/poke-a-mango#features) in [`e672122`](https://github.com/nabijaczleweli/poke-a-mango/commit/e6721226aaa397b1f157ee803d56fc5e0603aa76)
This looks very neat
[removed]
Can someone make this quote of the week? Or make error-chain crate of the week.
Here is a function that compiles. I had to change the size of move_list to 30 to make it Copy. I don't know how to solve this is a pretty way. Perhaps the best solution is to use Vec. https://is.gd/q3vgAm 
Right I can see that. But commands like select do not return a value, only indicate a success or failure to transition state. The equivalent functions like obtaining a mailbox provide returns but have no state machine logic. 
This looks awesome, but doesn't compile under Windows (std::os::unix::prelude::PermissionsExt and std::fs::Permissions::from_mode don't exist)
Looks reasonable, since Windows does not have this permission system... I will have a look at it tomorrow and will provide a fix for that. :)
It works if you manually implement Clone for the second struct https://is.gd/232VzG
This is a really good point. I happened upon a video where Yehuda Katz is showing off using Rust in Ruby, but he ends up diving deep into how Rust handles strings and iteration and it was really informative and cool. https://www.youtube.com/watch?v=IqrwPVtSHZI
X-post from stackoverflow: http://stackoverflow.com/questions/39924909/array-of-structs-of-array-in-rust/39925309?noredirect=1#comment67134488_39925309
I did, but it has been "postponed" for years: RFC #327: https://github.com/rust-lang/rfcs/pull/327 Rendered: https://github.com/engstad/rfcs/blob/9eb0ca1e92092756ea11cf8f9c812bc9d47f62db/active/0000-bitdata.md 
Cheers, mate
Oh cool, that makes sense. I hadn't realized that the separation was so clean.
my gfx can't handle this dawg!
All of these follow the same code-path now so the only thing that matters is personal preference. `.to_string()` used to be much slower because it went through the formatting framework, but we have specialization now so `impl ToString for &amp;str` just does `.to_owned()` instead of following the default `impl&lt;T: Display&gt; ToString for T`.
Great answer, thank you!
You get the same semantics but at reduced performance because you have to go through a pointer.
sorry, I was just kidding.
I'm not entirely sure what you're asking. You can `#[repr(C)]` a Rust enum and it will be laid out in a C-compatible fashion. You can match on it from the Rust side and everything, though if you're using it in FFI you have to make sure that the C side can't set the enum to an invalid variant. I guess that gotcha is the thing that you want to reduce or eliminate, but I'm not sure how that would work since C simply doesn't have proper tagged unions as a part of the language.
I think he means trying to set a standard tagged enum FFI for interop with rust and other languages that do support tagged enums.
I would appreciate any and all resources made available to leverage for learning Rust. Regarding a useful format, I would love to have access to an organized bunch of topics and videos that could be watched in order to complete lessons, or they can be watched individually as quick references. Like stand-alone tasks recorded individually that could be chained together to form "episodes" so-to speak. It's most helpful, for me, to see an example of some Rust code, then break down what the code is doing, and commenting on Rust syntax/terminology/style/conventions/theory/gotchas/tips/tricks. All the above would be useful. Additionally, another idea for more content would be to review your favorite crates. Not only an overview of what they can be used for, perhaps some examples of how to use them, and maybe some ideas of other crates that are similar/work well with/etc. Common crates, your favorite crates, I'm very interested in learning about useful crates! Thank you for your consideration!
Tokio has the [FramedIo](https://tokio-rs.github.io/tokio-core/tokio_core/io/trait.FramedIo.html) trait but there's nothing like this in std
Got a good kick outta that :P
I'd like to understand how. Specifically, I don't see how GADTs can ensure that a given value is not transitioned from more than once. That is, with affine types, you cannot "memorize" a previous state and restart from there unless specifically allowed to, which further restrict the possible actions that can be taken (you are always moving forward, never backward).
Cool! I'm doing something similar, blogging about Rust to improve my writing and Rust skills. And using Jekyll on GitHub pages. If you want to use Jekyll plugins though, I can recommend publishing the generated site on your github pages with `.nojekyll` instead of have the site generated by GitHub. That way you can use whatever plugins you want, and won't have to hunt for the build failure messages in your GitHub repo settings. Good luck with your blogging!
Heck, even on byte streams, many data formats are message structured. Doing a partial read of a message off a tcp channel can be pretty darn useless.
Based off title I was able to guess this was /r/playrust but with a tad low certainty
No I mean it doesn't support frames/etc. It does have a udp support
Fantastic! Thank you for your efforts!
Same here. I'm not a fan of handling error with exception since in most language you can't see what might be thrown out after executing a function. All the knowledge depends on documents or comments, which is not a nice solution IMO (most worse, you have to READ the code). Rust follows the good old returning-value fashion with enhanced features and guarantee, which is quite neat.
I would love for Haskell to have a direct to rust FFI.
Would adding this be something that requires an RFC?
More than that, I believe such an effort would require inter-community cooperation to demonstrate demand and willingness to implement the other side of this, as well as to validate the representation that Rust chooses as being actually feasible for interop. This isn't a task that can be undertaken unilaterally. Also, I'm skeptical about the actual use for this, given that the most commonly-used languages for calling into Rust (Python, JavaScript, Ruby, C, C++) do not feature tagged unions. If there's anyone calling Rust code from Swift, Haskell, and OCaml, then I've yet to meet them. (EDIT: but of course I'd love to meet you if you're out there, *MirageOS take the hint*)
We just switched a home-brew error handling mechanism (pre Rust 1.0) to error-chain. I think error-chain is fantastic and totally deserving of crate of the week. I also think the Rust book should be updated to promote it. 
Where can I get some help with syntex_syntax/libsyntax? Couldn't find any good guide with code generation. (structs and trait implementations) I'm new to reddit and rust community, so I'm not sure if it's appropriate to create a new thread with my question. 
Yes, after a bit of a nightmare getting ruby, rubygems to work on Windows (it... installed in C:\tools ?! followed by TLS certificate errors ._.) I managed to get it to work. D:\Projects\CasualX.github.io&gt;jekyll build Configuration file: D:/Projects/CasualX.github.io/_config.yml Source: D:/Projects/CasualX.github.io Destination: D:/Projects/CasualX.github.io/_site Incremental build: disabled. Enable with --incremental Generating... done in 6.944 seconds. Auto-regeneration: disabled. Use --watch to enable. The website runs locally after running `bundle exec jekyll serve` and works perfectly fine. The external theme [minima](https://github.com/jekyll/minima) is default when doing `jekyll new &lt;name&gt;` to create a new blog. Also github says [here](https://help.github.com/articles/troubleshooting-github-pages-builds/) and [here](https://help.github.com/articles/viewing-jekyll-build-error-messages/) build errors can be viewed in the github pages repository settings, for me it says: " Your site is published at https://casualx.github.io/ " implying everything is fine. My intuition is telling me github doesn't seem to recognize I'm trying to use jekyll, but this can't be right as the jekyll source files are inaccessible from the github pages website, eg: [index.md](https://casualx.github.io/index.md) gives a 404. EDIT: I committed a dummy file [foo.blah](https://casualx.github.io/foo.blah) which is available.
If it works locally when using the `github-pages` gem but the same config doesn't work and doesn't produce errors on GitHub itself, I'd contact GitHub support about it. If it's not a bug in their installation, maybe they could point you to the next troubleshooting step.
I find it extremely difficult to imagine getting a beginner programmer to write 15 lines to Rust on their own. I've written code in C, C++, Javascript, Java, C#, Ruby, Python, Scheme, Common Lisp, Prolog, Ocaml and Haskell, and I'm now trying to learn Rust, and I would say it's *by far* the most diffcult. I learned to program in C, at it's a piece of cake compared to Rust.
Time to climb the SystemD learning curve. Learn to write a SystemD config file for your web server. Put it in /etc. Congratulations. You've just added "ops" to you job qualifications. 
You have several options: 1. Run with nohup command 2. Run within a screen or tmux 3. Daemonize your service
Part of it is a bash scrip that just has the command line to get this started. But the SystemD setup lets you configure a lot of things about keeping a process running (start on boot up? Restart it if it quits? Restart if it crashes? Wait for other tasks to complete before starting?) 
You probably want the subreddit /r/playrust.
For numerical processing, fortran is often able to beat C. I'm working with Java code that is exactly as fast as the same algorithm in C (and yes, I did the benchmarks) down to the nanosecond after some warm-up. In crypto, specialized assembly is often able to get an order of magnitude faster than C. What I'm saying is that it really depends on what you are trying to achieve. Contrary to popular opinion, C is no magic performance pixie dust you sprinkle on your code to make it run fast.
What is the advantage over using GDB?
Is there an advantage if you're running Linux?
Thanks for making this!
Does Rust give access to [floating point rounding settings](https://en.wikipedia.org/wiki/IEEE_floating_point#Rounding_rules) somewhere? The only thing I could find was some [trickery with unsafe C calls](https://stackoverflow.com/questions/36681157/setting-fpu-rounding-direction-from-rust-and-c-changes-nothing), which also doesn't seem to work.. 
&gt; What is the advantage over using GDB? GUI? But you probably meant "GDB with [Native Debug](https://marketplace.visualstudio.com/items?itemName=webfreak.debug) as a front end". I'd say it's less complete. Starting with small things, like not verifying breakpoint locations and not showing static variables, to not supporting more than one level of variable tree expansion, to not having a disassembly view. Besides, the GDB itself tends to not work so well outside of Linux. For example, interrupting a running process via the MI interface seems to be broken on OSX and Windows. Even on Linux, it doesn't work 100% reliably, in my experience.
Use supervisord. Its designed for this exact purpose and it's great at it. Besides, it's not tied to a certain package manager. It handles logging etc...
How can i write a function where i can use the "move" keyword on calling it? I am working with gtk right now, and there is for example this function: https://github.com/gtk-rs/gtk/blob/master/src/signal.rs#L214 When i call it i do something like this: tree.connect_row_expanded(move |tree, iter, path| { // tree is self // iter is the actual iterator that got expanded // path is the path to the actual element that got expanded } I would like to write something like this - but how does this function know what "iter" and "path" are? I do not get that in the source code provided.
Thanks! I was frustrated by this just last week. I can help with the RfC if you need it.
Probably ask in #rust-internals. What's your question?
It is, because the anti-pattern writeup hasn't yet been merged. The link will be fixed when it is.
I suspect there won't be a perf difference with a char in the to argument. Due to the way utf8 works there aren't any additional optimizations that can be performed when inserting a char vs inserting a string. Though being able to pass in a char might avoid allocation. Then again, you can pass in an `&amp;str` made from the char. I'm surprised there isn't a method for creating a one-char `&amp;str` from a char, really.
Thanks, i thought everything starting with "fn" is a function - thats why i did not look for closures.
Hmm I've always written `String::new()` if I wanted a new string that didn't allocate, even though I didn't know `"".to_string()` doesn't allocate imho the first is more clear in its intention.
Feel free to submit this as a PR to the patterns repo.
Good idea. Feel free to submit a PR to the pattern repo to update the example.
Yay, I knew about that already. I also think that this shows how good the Rust stdlib is … when you expect there to be a function to do something, and it is actually there, and pretty much exactly how you imagined it, someone did their job well ☺
 $ ./my-server &amp; $ disown The other answers are "better", in that they're the right way to do something like this to ensure reliability, but this is the most basic form of what you're asking for and is probably what you wanted.
This is seriously awesome. edit: ... but I was a bit skeptical and/or didn't understand what [`mem::replace`](https://doc.rust-lang.org/std/mem/fn.replace.html) does, so [I did test](https://is.gd/47zx32) and it appears to work. `mem::replace` returns the previous `String` (that was stored in `name`) by value, so you end up owning it.
Is there any tutorial-like manual or well-documented code explaining code generation with libsyntax? I understand that it's an unstable internal library, but shouldn't there be some internal guide? Documentation of syntex is a disaster :( Also, is there an easy macro-like way to emit rust code via compiler plugin? 
Haskell has GC, so that's an issue, and its runtime is pretty sophisticated, to deal with lazy evaluation. Might still be possible though. 
*systemd, lowercase
Which is very similar, apart from using a temporary var.
Awesome! I was unsure if that'd work because it hinges on the borrow of the `match` ending before the assignment, so I went the safe route 'analyse then change' that has proven to work well. Can you write a PR to the patterns repository?
Not sure, but it appears /u/diwic has a comparably simple version that already works.
In [Pony](http://www.ponylang.org) [assignment behaves like that](https://tutorial.ponylang.org/capabilities/consume-and-destructive-read.html) out of the box. They claim it's useful when dealing with linear/affine types and while I don't have that much experience with them I tend to agree. The same functionality was also introduced in C++14 as [std::exchange](http://en.cppreference.com/w/cpp/utility/exchange). I like to see that feature under those two angles: - it's half a swap, seeing as `replace(&amp;mut a, replace(&amp;mut b, a))` is a full swap (but it doesn't make too much sense to do it that way, so don't read too much into that either) - it's post-assignment, just like how post-increment yields the old value
After you logged in with ssh, Invoke `screen` and run the the app. You can then close the terminal, since the screen still leaves on the server. You can open the screen session again by logging back in to the server then do `screen -r` this will reattached the previous screen to your new session. TL;DR ssh user@server.com $ sudo apt-get install screen $ screen $ cargo run --release close the terminal ssh user@server.com $screen -r 
Sure, if you want to replicate the behaviour of `mem::replace`. That's not what I did ;)
This might help: https://www.reddit.com/r/rust/comments/54wc6s/strategies_for_including_support_c_in_a_rust_crate/.compact See also: http://jakegoulding.com/rust-ffi-omnibus/
I'm glad to see active work on improving rust docs. I'm still at the point where I spend more time reading the sources than the rust docs. I find that lots of things I need to know are elided by rust docs. It seems like I often want to know all the consumers and producers of a type.
GHC supports both FFI imports and exports. You can even do complicated interleavings of the two. Furthermore, you can start and stop the RTS using C functions. So if you wanted to you could have a C program (equivalently rust) that starts up the GHC RTS calls into Haskell and that Haskell could even call back into C. This stuff is documented in the GHC user guide. 
Sorry, I'm still pretty new around here. Where do I file bugs about the output of rust docs? (the tool, not specific outputs)
https://github.com/rust-lang/rust/issues/new
I was actually just looking at this for use with gnome-builder. Thanks for sharing!
https://doc.rust-lang.org/nightly/book/compiler-plugins.html Autogenerated API docs at http://manishearth.github.io/rust-internals-docs/syntax/ Well, the only people who deal with it are basically compiler devs (and serde/clippy devs), and docs are annoying to maintain for an unstable API, so there aren't any good docs. Besides, there's a new, stable macro system that's coming in piece by piece (see https://github.com/dtolnay/syn), so those would be obsolete anyway. The `quote_foo!` macros can get you quite far with code generation. https://github.com/servo/servo/blob/master/components/plugins/reflector.rs , https://github.com/servo/servo/blob/master/components/plugins/jstraceable.rs , https://github.com/Manishearth/rust-adorn/blob/master/src/lib.rs#L21 are some examples of plugins you may want to look at (the last one might not compile on the latest nightly)
Thanks. Hopefully this description makes sense: https://github.com/rust-lang/rust/issues/37061
Thanks for the great answer! Hope it will be enough for me to implement my ideas :)
I found it interesting to see how the LLVM team works in relation to High Performance Data Structures, and where C++ helps v.s where it makes it more difficult (he does not likes the current allocators syntax/semantics). 
You're welcome!
Here's the [documentation](https://downloads.haskell.org/~ghc/master/users-guide/ffi-chap.html) in question.
Surely this should be named SvgBobRoss!
Can this lead to a new type system for Rust?
+1 for glium
Add this to your `~/.emacs.d/init.el`: ;; Rust mode alignment helpers (eval-after-load "align" '(progn (add-to-list 'align-rules-list '(rust-mode-align-let-= (regexp . "let[[:space:]]?+\\(mut\\)?[[:space:]]+\\([[:alpha:]_][[:alnum:]_]*\\)\\([[:space:]]*\\)=\\([[:space:]]*\\)") (modes . '(rust-mode)) (repeat . t) (group 3 4))) (add-to-list 'align-rules-list '(rust-mode-align-let-mut (regexp . "let\\([[:space:]]?*\\)\\(mut\\)?\\([[:space:]]+\\)\\([^=[:space:]]+\\)") (justify . t) (modes . '(rust-mode)) (repeat . t) (group 3))) )) If you don't like the alignment around `mut`, then only use the first one `rust-mode-align-let-=`. If you find yourself wanting to define other alignment mode helpers, I highly recommend using `M-x re-builder` to workout the details of the regular expression.
I feel like this is the fault of the coroutine library, myself. I mean, the implied assumption of a coroutine library is that anything that uses threads can be simulated using coroutines, implementing any kind of waiting on another thread as yield()ing in a loop until a shared flag reaches the correct value. After all, yield() is supposed to appear to be an ordinary function from the outside, and ordinary functions cannot (in current Rust) leak values they don't at least borrow mutably. (Currently, you can leak a mutably-borrowed value with mem::replace()). So yield() should not be safe Rust as it's currently implemented. A safe API would make the guarantee that, like all other functions, yield() ^(appears to calling code as if it) either returns or unwinds, which is an assumption that I'm pretty sure we need to make if we want to allow ANY kind of code that temporarily leaves a structure in an unsafe state to remain memory-safe overall.
How are you going to enforce that, though? If yield() stays as a regular function call, the typesystem can't actually represent what you're talking about. If yield points are instead the entry and exit points of functions, it gets easier, but now the coroutine framework has to have some way of remembering the return value of each coroutine function and passing it back as a parameter the next time it's called. If we're going to go that route, we could probably drum up a set of macros to rewrite code written using [Delimited Continuations](https://en.wikipedia.org/wiki/Delimited_continuation) into [Continuation Passing Style](https://en.wikipedia.org/wiki/Continuation-passing_style) code, then let the coroutine library itself take ownership of the thunk that represents the code to run after yield() called, then just calls that thunk the next time the coroutine is set to run. (A coroutine itself could satisfy the trait bound e.g. Coroutine&lt;T&gt;: FnOnce() -&gt; Result&lt;Coroutine&lt;T&gt;, T&gt;).
Did you make an issue for this?
Sorry, no idea. I don't use rustfmt.
I'm the creator of the [rust-embedded](https://github.com/rust-embedded) org on Github and author of several Rust projects for use in embedded systems within the context of Embedded Linux ([rust-i2cdev](https://github.com/rust-embedded/rust-i2cdev), [rust-sysfs-gpio](https://github.com/rust-embedded/rust-sysfs-gpio), [rust-spidev](https://github.com/rust-embedded/rust-spidev), and a few more). One of the projects we have on rust-embedded now is [rust-embedded-www](https://github.com/rust-embedded/rust-embedded-www) which has a few parked domains right now including http://rust-embedded.com and http://areweembeddedyet.com/. Talking with /u/nastevens (who registered those domains and is another contributor to rust-embedded) I think our plan is to build an index of embedded rust projects similar to other "are we X yet" sites. Please create an issue on the project or shoot me a message if you want to help out! Rust right now is very suited for use in embedded linux systems (on ARM, MIPS, x86). I personally work for Samsung SmartThings and we plan to ship rust code on our hub in the near future (hopefully we'll be able to share more on that in the future). Don't get much more IoT than that! I'm excited to see how things progress on the Microcontroller side of things!
This is inconvenient for others working on the same project though. They either have to already use emacs and add additional tooling or do it by hand. Adding one variable later and they have to go change it all again.
That would be cool to have that in rustdoc.
That's not the point. Unless everyone on a project is using the exact same tooling this will be an inconvenience. Setting up the tooling is of course pretty minor, but stuff like this adds up quickly over time. If I wanted contributors for a project I'd be hassling them. If I wanted to contribute to a project I'd be hassled. Edit: as for companies though, I wouldn't want to work in a place that didn't have some sort of sane standards. Adopting something like this would mean that you have different style standards between your projects, or a lot of work to do in the middle of one. This isn't the first language that had this idea, and it won't be the last. But there's more than a couple reasons why no other language has adopted this standard.
We should get this added to rustfmt then. Vertical alignment does a lot to improve readability.
This is great! Really nice tip :)
I've given it a little bit of a go, and it shows promise. Like with Racer+(insert text editor here), it doesn't seem to have auto-complete completely down pat yet (there are certain situations, where it doesn't seem to know the type of an object), but it is certainly interesting. Like I said, it shows promise. I'll certainly be keeping an eye on it as I go on.
Rustup can install and update sources so you don't have to maintain it manually. rustup component add rust-src And then set source directory to ~/.multirust/toolchains/&lt;your main toolchain&gt;/lib/rustlib/src/rust Then every time you update your toolchain, the sources are automatically updated as well.
I don't think it's so general that it can be called an idiom, but it saves some needless allocation. I [linked to the blog with the use of `mem::swap`](https://apanatshka.github.io/compsci/2016/10/03/implementing-finite-automata-part-1/#nfa-execution), but I'll summarise here. This is a function that applies an input to a Non-deterministic Finite Automaton and return the payload of the final state it ends in: pub const AUTO_START: StateNumber = 0; impl&lt;Input: Eq + Hash, Payload: Clone&gt; NFA&lt;Input, Payload&gt; { pub fn apply&lt;I: AsRef&lt;[Input]&gt;&gt;(&amp;self, input: I) -&gt; Option&lt;Payload&gt; { let mut cur_states = HashSet::new(); let mut nxt_states = HashSet::new(); cur_states.insert(AUTO_START); for symbol in input.as_ref() { for &amp;cur_state in &amp;cur_states { if let Some(nxts) = self.states[cur_state].transitions.get(symbol) { nxt_states.extend(nxts); } } cur_states.clear(); mem::swap(&amp;mut cur_states, &amp;mut nxt_states); } cur_states.iter().filter_map(|&amp;state| self.states[state].payload.clone()).next() } } So you're in one or more states (`cur_states`) and for every symbol in the input you find the states that you will be in next (`nxt_states`). Then you need to assign `nxt_states` to `cur_states` and have an empty set for `nxt_states` for the next round of the outer loop. If you do a `clear()` + `mem::swap` you keep around the allocated space of the `HashSet` instead of throwing one away and allocating a new one :)
I disagree. I hate gofmt, and none of the go code I write will ever match the output of it. I don't intend to use rustfmt either. Standard never trumps good.
Touch luck. Good looking, readable code trumps convenience any day in my book.
Any library to load http response as [DOM](https://en.wikipedia.org/wiki/Document_Object_Model) so I can easily work with its elements?
But the provided (gif) example is rather extreme. This code would look much better even without this kind of formatting when reorganized.
People using proportional fonts for programming will be kind of sad. 
But then you'd have to `use std::default::Take` to use it, unless we put it in the prelude, which would have the same problem.
It shouldn't be formatted this way AUTOMATICALLY. It should just keep this kind of vertical alignment as is when it seems like it's on purpose.
If you wanted this, you'd be using elastic tabstops. It makes no sense to do it with spaces for diff purposes.
Nice! If you want to optimize SVGs further you could use my library for SVG path strings. It can parse the path strings and output them in a lossless optimized version. It's not on crates.io yet but I can release it if you want: https://github.com/hannni/svg_util
"Gofmt's style is no one's favorite, yet gofmt is everyone's favorite."
Awesome tip, thanks!
Thanks!
It doesn't do this. It uses #rgb notation when possible.
IntelliJ supports a bit more comprehensive multi-caret stuff: 1. CTRL+G will select the next occurrence of your current selection. If no selection, then it will highlight the current word. You can push this combination repeatedly to select more occurrences. 2. This is a well-hidden one: if you double-tap alt, but keep it held down after the second tap (so it's more like "tap -&gt; release -&gt; tap &amp; hold"), you can use the arrow keys to add another caret above or below the existing caret. Keep alt pressed and tap the arrow keys to add as many carets as you want. Not sure how that compares to Sublime, but it's plenty useful for me every day. Can often replace a complicated search &amp; replace regex.
Oh shit, sorry!!!
I don't have much to add, except to check out my projects: [fixedvec](https://github.com/rust-embedded/fixedvec-rs) and [meta-rust-bin](https://github.com/rust-embedded/meta-rust-bin). fixedvec provides a Vec-like abstraction over pre-allocated buffers, and meta-rust-bin is a Yocto layer providing Rust compilation using the pre-built Rust binaries. Rust's possibility in the embedded/IoT space is significant and we are just scratching the surface.
Then the README should probably reflect this. Sorry I did not try, am on mobile.
Nice! Looks like I need to give VS Code another try.
Awesome. Thank you.
I had heard that rustup would download the sources but I didn't know how to do it, nor did I really try to take the time to figure it out... Thanks for the heads up, that's really useful!
That's a nice idea! I guess it should have to specifically check to see if the code was aligned, and then leave it alone.
Depending on the service, it is also a good idea to lock down the service as much as possible as well. See `man systemd.exec`. Some examples: `User`, `Group`, `PrivateTmp`, `PrivateDevices`, `ProtectSystem`, `ProtectHome`, and there are many more...
Some similar things in Rust: https://github.com/servo/rust-smallvec https://doc.rust-lang.org/1.2.0/std/collections/vec_map/struct.VecMap.html Others? 
There's no reason it cannot be implemented in Rust. In fact, iterator invalidation, which is a problem he talks about in the talk would not be a problem in Rust.
If the general indentation style is poor, yes you should use an automatic tool to fix it, but there is no reason to fix something before it is broken. There is no way an automatic tool can cover cleverly all the cases. Generalized automatic formatting guaranties equally bad formatting to everyone. I don't think it is a win.
&gt; I’m going to give the IntelliJ IDE (by Idea Software) a fair shake. FYI, IntelliJ IDEA is made by JetBrains and not Idea Software. Good article though!
Isn't it better than making breaking change?
Actually IntelliJ has a good multicaret implementation, you just have to configure the key bindings. Clone caret up/down
Can confirm, have been writing Rust code for about a year and just now learned about pretty-print from this post.
I'm not so sure. As it stands right now, I think IntelliJ-Rust is still playing catch up with Racer. That said, the future is definitely in the RLS and after watching the demo from RustConf, I can't wait for that to be a usable tool. At the moment, any sort of autocompletion tool for Rust is going through growing pains and misses certain things. It's just the nature of Rust tooling right now.
Can anyone (hopefully someone who has at least cracked it open) comment on the quality of this book? I know it's free so there is no harm in getting it, but is it worth my time to read? Thanks in advance!! 
I honestly don't know. I'd go write an RFC asking for a crater run, but I'm on hiatus until December.
It is disabled by default because it doesn't always provide a speedup. On oxipng, it gives anywhere between +25% and -25% speed difference, depending on the function. Benchmarking your program with and without lto is important.
Protip: if you scroll down to the bottom of the page you can navigate to different categories (data, iot, security) and see more books available for download.
*shrug* good to have support but I think it's worked reasonably well "forever"?
Normally we wouldn't need GDB with Rust but it's great when crossing into unsafe territory (FFI and manually managed pointers come to mind) and you mess things up pretty badly.
Official support is a pretty good thing.
What does it even do for an enum with fields? Arguably it shouldn't even compile.
Do you think this is something we could fix? Does the debug output have any guarantees that we can't break? It feels to me that yeah this would be a better default and that no one should rely on the precise output `{:?}` produces. But I don't know whether there are actual guidelines or guarantees about this.
`#[repr(u8)]` and so on with other integers picks the discriminant size, even for enums with fields. All the repr tags have the effect that layout optimizations are disabled, so that includes (C).
Funny, i'm working on ascii to svg converter https://github.com/ivanceras/svgbobrus just a few days ago. Does any of your library have a way to optimize the paths by rearranging the order of the drawing elements, reversing the element as necessary to have a continuous head to tail arrangement? Been trying to solve it, but it seems like a hard problem. 
I use GDB for day to day debugging even when there are no failures or crashes or anything, just logic problems in the code. I step forward and backward through the code, inspect state, add watch points. Nothing really related to memory safety or anything Rust could help with. I only do this when writing difficult algorithms and tricky numerical code. Which is most of the time in my line of business. I don't really do that when doing easy stuff. That just doesn't happen often :)
What I don't like about the non-pretty default is that `assert_eq!` doesn't pretty print.
Thanks! Fixed.
I use a debugger for logic errors, but I can agree that a debugger is probably not necessary for safe Rust code 99% of the time.
So you put prints in the code or something to see what steps of an algorithm do? Or you get your code right on the first attempt? There's only so much the compiler and type system can do. Another thing I do is set breakpoints to test failures so when an assertion fires, I still can access the state of the program. Typically, I always run my program in the debugger when developing. Crashes, memory errors and other cases where Rust could help are infrequent. But being able to inspect the program behavior when it's live is really helpful. It's just a good habit that doesn't cost much but improves productivity.
I've been looking to contribute to rust. This seems like an easy (technically speaking) way to do it. I'll look into the process tonight!
Documentation got updated in https://github.com/diesel-rs/diesel/pull/474. Would love your feedback.
I didn't mean to suggest that `gdb` is not useful for rust (or only useful for `unsafe` code). Quite the contrary, I've used `gdb` on my rust code and it's very valuable. Just that it already worked without official support from the `gdb` team. I presumed that it was because the rust object model mapped reasonably well into the existing DWARF data structures in use for C/C++/and friends, and it was supported by `rustc` adding those DWARF sections to the output.
I have had a long-standing hunch, though it's just a hunch, that it's related to function size. When I've worked with a 100-line function, I found a debugger useful. When I'm working with ten 10-line functions, I never use a debugger.
I wonder if the pointer bit packing could be used by the compiler to optimize enum MyPointerEnum { Boxed(Box&lt;Something&gt;), Vecced(Vec&lt;SomeOtherThing&gt;), AsText(String), Nothing } to the size of a single Vec. Or a `enum Test {RefCounted(Rc&lt;Struct&gt;), Unique(Box&lt;Struct&gt;)}` to a single pointer.
Logical errors are the *primary* reason for using a line-by-line interactive debugger like gdb. The problems that Rust's type system prevents are best analyzed with another tool such as valgrind, and perhaps additional unit tests. I love Rust's type system but it is just hopelessly naive to think that it magically makes interactive debugging a thing of the past.
Go for it! I can [attest](https://llogiq.github.io/2016/09/14/feature.html) that it's both easy and awesome.
I even converted the latter into my java workflow by editing my IDEs template to throw an Error("unimplemented") for auto-generated methods.
I dunno. To me this kind of change seems on par with changing the default error message styling, which happened recently. There would be no compile-time breakage for anyone. There would not even be change in semantics (it's still debug output whether it's pretty or not). The only change would be an implementation detail for output explicitly intended for programmers. I guess it could be seen as an API breakage for the format string, but in spirit swapping "ugly by default" for "pretty by default" with all other semantics preserved doesn't feel like it would fall under Rust's stability guarantees in any way. Sure some things might break, just like some tooling broke with the error message change, but returning to the current behavior would be a single-character change. That feels like an acceptable cost so that the vast majority of people get more usable output without having to change their code at all. Moreover, I'd argue code (or anything else) relying on programmer-centric debug formatting is code that deserves to be broken, especially when it involves types you don't control and can be auto-generated. I don't think I'd make quite as strong an assertion when relying on output of `Display`; that trait has stronger semantics since it can't be derived and is intended for end-user consumption. However I could be convinced that both `Debug` and `Display` are intended for _visual_ consumption by humans and when you intend for something to be consumed by code you use a serialization format that can be parsed into a type you care about and test against the parsed object. With that view I'd support this kind of breakage even if it affected something like `Display`. All in all I think it's at least worth a crater run.
Yup. This is one of a small collection of things people get wrong when talking about the guarantees Rust provides. The other being the common claim that Rust prevents all race conditions, which it doesn't. It _does_ prevent data races, and I think people often don't appreciate [the difference between the two](http://blog.regehr.org/archives/490).
Here's an invite for solid investigating, despite not needing to. Now your effort was not in vain!
Perhaps so, but not every problem can be broken down to 10 line functions without adding unnecessary complexity. 100 is a bit much, I think a pageful/screenful is a pretty sweet spot. 30-50 or so. Anyway, just to give an example... I was writing code to find closest approaches between satellites in orbit and it had to finish in a *very* finite number of steps. To test, I generated 8M arbitrary pairs of colliding orbits and ran an extensive test suite. A handful of them failed. So, I start stepping through the algorithm in the debugger, find a dodgy step in the way and stop there. Then I invoke a function in the debugger to dump the algorithm state to a file and then visualize it with a plotting tool. I stare the plot for a while, think real hard and then fix the issue. Being able to inspect and analyze the state of a running program is a very valuable thing, regardless how smart compiler or well organized code base you are working with. The code I'm talking about is no more than 30 or so lines of code bbut it's relatively complex logic and the state is all floating point data, so the compiler can't help to maintain invariants.
I was expecting an article about the [X Window System](https://en.wikipedia.org/wiki/X_Window_System), but your article is fine, too.
This is actually a pretty big improvement - debugging sort of worked before because we pretended Rust programs were C++ programs. As long we you only want to inspect values which looked like C values or the stack (which works the same way in both languages) you were fine. But looking at an enum or trait object just would not work. That all works now. Rust is first class in GDB. This is huge for debugging large programs.
Pretty sure *Why Rust?* was written before the scoped threads fiasco.
I should test it myself, but perhaps there are improvements in the GDB side, for e.g. evaluating Rust expressions in GDB and invoking Rust functions. This side isn't really covered by DWARF, etc.
Well it sounds like according to /u/nick29581 that [there are some improvements there](https://www.reddit.com/r/rust/comments/56s6t6/gdb_712_released_debugging_programs_written_in/d8marct).
Can I get a suitable GDB 7.12 from mac homebrew? Do I need to enable any flags? Looks like the formula already has a bottled build: https://github.com/Homebrew/homebrew-core/blob/master/Formula/gdb.rb .
Don't think so. No bash required. For an example, have a look at `/usr/lib/systemd/system/httpd.service` to see how Apache does it (assuming you've installed httpd). Have a look at the other files---there's not much to it. In a nutshell, you write a little config file that tells systemd how to start your program (`ExecStart`)... and when to start (`WantedBy`), and any things that it needs to start after (`After`). Put that file in `/etc/systemd/user/` and you can have it start on boot with `systemctl start myservice` and `systemctl enable myservice`. ...or if you're lazy and don't care about all that, you can just run `./myprogram &gt;&amp; ~/output.txt &amp;`, to run it in the background. When you log out it should keep running.
Yeah, i noticed this a few hours ago as i was about to "delete" multirust in favor of rustup. I was heading for a AUR package but was surprised by this – next step -&gt; rust world domination 
So how do you uninstall rustup? And do you need you before installing one from repo?
`$ rustup self uninstall` :)
How does this compare to implementing `Deref&lt;Target=Bar&gt;`? [This chapter](https://github.com/rust-unofficial/patterns/blob/9d955043a4324e85487e7acc52603bd88483de63/anti_patterns/deref.md) of Rust Design Patterns describes why this is often thought of as an _anti_ pattern.
You mean the Limitations section?
svgcleaner itself can do some optimizations with paths. But it's very limited for now.
You typically wouldn't need to use a debugger when doing type-safe functional programming, which is basically 80% of the Rust story (enums, closures, inductive reasoning, etc.) Debuggers are *great* for memory corruption and heisenbugs, but safe Rust doesn't have much of those.
Agree. Take the project I maintain for instance, not only code format problem, inconsistent style and trailing spaces grows everywhere. That's one good reason to (force) programmer use formatting tool because they don't care how stink their code is. In other case, using formatting tool or not is just the matter of preference or team rules, if the team member care about code quality.
&gt;The problems that Rust's type system prevents are best analyzed with another tool such as valgrind, and perhaps additional unit tests. This is true for the substructural aspect of Rust's type system, but sum types ("enums") and syntactically cheap type declarations are known to help reduce logic errors.
What version of Ubuntu are you using 15.04 or earlier systemd isnt the init manager and the easiest thing might be to update to 16.04
So that one I can get working with explicit lifetimes: https://is.gd/YGFKaA I'm still trying to figure out what's going on with inference, but to no avail.
Native support is exciting, but it's still got a ways to go. It's not better than the in-tree pretty printers yet, IMO. It's a pain trying to see the contents of a `Vec`, it just shows the on-stack layout which is useless and noisy. And it doesn't work with `rust-gdb` anymore, it just prints an error about how the script can't be loaded. 
Yes.
Thanks. I like it a lot, too. :D
Sure, I can't disagree with that. But it's unlikely that type-safe enums would help you find a bug in e.g. a fast Fourier transform implementation, which is the sort of thing I had in mind when I wrote my comment. But I do scientific computing for a living so I'm a bit biased. 
I was actually going to start a series of blog posts on exactly this question. I've been writing toy Rust programs for around 9 months now and there are quite a few things I wish I knew or understood better at the start.
What about code that merely relies on the default debug output being single-line? I just debug output in line-delimited logs, and I think other people do, too.
I really like the idea of a common core for Rust IDE extensions... Hopefully this project either moves to Racer, or replaces it as a cross-editor IDE extension.
&gt; I knew nothing about computers at that time, and I remember thinking what’s so fun about making letters appear on the screen? This seems to be a common first roadblock to many people. I also stopped and started a few time with the 'hello world' examples before I learned to program. I think for me the problem was a little bit different - I couldn't see the connection between what I was doing and writing a program I could meaningfully want to use. When I finally taught myself to program, I had been working as a bookkeeper. I implemented a command line double entry ledger. It wasn't better than the accounting system I was already using, of course, but I could see the connection between what I had written and what was happening in the production accounting systems I was used to using. I'm not sure if this is the same as what held you back, or if its a little bit distinct. It was motivating to have the experience of looking behind the curtain, and actually learning something about how the program I already used worked. `Hello world` doesn't have that, because the magic in `Hello world` is what happens behind the `println`.
You already mentioned, but I'd like to reiterate since it was so valuable to me. I've learned so much from running `clippy` on my code. Appeasing the compiler is one thing, but learning to write better / idiomatic Rust has really been a big step into the ecosystem for me.
Wonderful article, thank you! It is really valuable to listen to someone who hasn't been programming extensively for many years already. It's pretty difficult to remember what it was like when one was learning to code for the first time. Your article also made me realize how many other super interesting things there are to learn. Well, I guess the my `lifetime` is way too short for all of them :/
Enable basic optimizations in your `test` profile via `Cargo.toml`: [profile.test] opt-level = 1 That'll get the most straightforward optimizations (and usually the biggest wins, like lowering to `memset()` and inlining for `#[inline(always)]`) without doing anything too aggressive, so compile times are still decently quick. Also, an `unsafe` alternative that's much simpler is: unsafe { v.set_len(num_bytes); } It's fine as long as it's &lt;= the capacity, which it is in this case. Having access to uninitialized memory as bytes is probably okay for tests as long as you're not doing anything with them before you overwrite them. If it was `Vec&lt;String&gt;`, I'd be a little more concerned. However, if the function that you're testing or the test itself *reads* these bytes at anytime, or doesn't always write to the whole vector, then you're basically asking for errors/test failures that are difficult or impossible to reproduce. I'd keep the zeroing and just add some optimization to make it faster.
Arch Linux is package nirvana.
Delegates could also be more finely grained. E.g. you might have a struct that contains a private `Vec` and want to delegate the `len` and `is_empty` methods without giving access to other methods. 
Hi, I debug using unit tests. It's like this: if my function is misbehaving, I write a test that should succeed and verify that it fails. Then I correct the function so the test now succeeds. Then I don't delete the test (perhaps the bug may return from the dead some day). You can read about testing [on this chapter of the book](https://doc.rust-lang.org/stable/book/testing.html). If I don't know which function is wrong.. then I would try [Mozilla's rr](http://rr-project.org/). I've never used it and I'm not sure how good is the Rust support, but from what I've read it seems amazing. So it would be an excuse to learn it.
Well, you're welcome. I moved it despite not solving the concerns about global installations with rustup, though, which still need to be handled upstream. For instance, rustup will only work for a single user currently.
Disclaimer I come from illumos/smartos. With that out of the way I'm a huge believer in debuggable systems. You don't care about debug ability until your production system goes sideways. I'm used to having rich facilities in illumos such as DTrace and mdb which are instrumental in understanding the software you did or didn't write. Being able to debug in production live without stopping your application is key. Especially when it'a not reproducible in staging. I welcome all debugging facilities to rust. I've been building my rust binaries with a modified Cargo.toml to include symbols and frame pointers. Which makes dtrace and other things work great on rust via lx branded zones. I will try and write a blog post up at some point. 
Trait objects still don't work IIRC. But you should be able to call methods. Though that was broken by a Rust release at some point (should be fixed again?)
That'd be cool to read!
It's more that inheritance is one of those tools with arbitrary limitations - traits are *theoretically* more powerful than interfaces (by design, copying Haskell's success with type classes). The problem with traits is that they interact with the rest of Rust in ways that haven't been studied before because there simply hasn't been e.g. a combination of type classes and region-based borrow-checking, AFAIK. It's *probably* a mistake that we didn't add features like fields-in-traits and delegation before 1.0, but there are RFCs now for both of them, I believe. Sure, we could add inheritance wholesale, but that would be giving up. It would be throwing away the idea that we've built a better foundation for polymorphic systems programmimg *than there has ever existed*. It would encourage people to consider that there are usecases for a relic of a broken world that has forgotten - or not discovered yet - the power of ADTs and type classes, instead of enabling and showing them how to use that power to do whatever they were trying to do in the first place. With C++ finally moving towards a similar model (although still more duckly typed), why should we regress?
I'm used to smaller Rust code bases so I can see where I'd be wrong here.
Thanks nice article! I'm wondering how did you stumble upon Rust and thought it was a good idea learning it instead of something else? Doesn't seem like an obvious choice to someone not familiar with concepts like memory and thread safety.
Yes, but it wasn't as common of knowledge as it is now.
I personally believe that inheritance is very often misused and it would be more explicit and clean to use the deriving approach.
I've done that with servo's `SmallVec` but with `Vec` the pointer itself is behind three or so layers of abstraction (`RawVec`, `Unique`, `NonZero`), it's really clunky to type all those nested field accesses in. The in-tree pretty printer is much more convenient. If `rust-gdb` just worked with this latest release, I wouldn't have any complaints.
Firstly, it allows to implement different traits to different fields. So if you have traits `A` and `B` and structs `X` and `Y`. Then you can do this: struct Foo { #[delegate(A)] x: X, #[delegate(B)] y: Y } Secondly, it's semantically clear what the intention is. Thirdly, it doesn't expose whole inner type. In other words, `Deref&lt;Target=Bar&gt;` is anti-pattern. Explicitly creating your own methods to pass arguments/return values is the correct way to achieve the same thing but it has lot of boilerplate. `#[delegate(...)]` is just like `#[derive(...)]` - it only creates the same implementation for you which you would've created. Is that clear?
I have https://github.com/Manishearth/gdb/blob/e904850adcaf587d06d203f7b0c7953b63fbb53e/gdb/python/lib/gdb/function/unwrap.py that lets you `$unwrap(complex_type)` to get the underlying thingy.
&gt; For instance, rustup will only work for a single user currently. Which is as it should be, IMO, otherwise it would start encroaching on distro package manager territory, a complication it doesn't need. That aside, rustup should be perfectly usable for shared configurations with some sysadmin preparation: one can have a single administrative user who does all installation/update work, while others use `rustup toolchain link` to pull in the shared toolchains.
I've most probably did huge mistake when teaching my girlfriend Python. I made it totally unattractive by printing stuff on screen and she said it's boring. I'm very sad about this now but thank you for opening my eyes! I hope I'll change it one day. :)
`lifetime` made me smile.
I did update my gdb using Homebrew: $ gdb --version GNU gdb (GDB) 7.12 Copyright (C) 2016 Free Software Foundation, Inc. However, when I tried running it so: $ rustc -g display.rs $ gdb -tui display $ sudo gdb -tui display Reading symbols from display...Reading symbols from &lt;path elided&gt;display.dSYM/Contents/Resources/DWARF/display...done. (gdb) b main Breakpoint 1 at 0x1000020e0 (gdb) r Starting program: &lt;path elided&gt;/display During startup program terminated with signal ?, Unknown signal. Am I missing something here?
I know. This is a very tricky thing to do. Upstream was interested in getting this into shape to be properly packaged as part of distro packages, however. There is a big discussion somewhere about that on either a Github ticket or a rust-internals discussion on how to best get rustup into shape to be included in multi user installations but I can't find it right now. brson had some things to say in there.
There's a good (in-progress) article series about it here: [Xplain](https://magcius.github.io/xplain/article/)
The discussion you're referring to is probably the ["Beta testing rustup.rs"](https://internals.rust-lang.org/t/beta-testing-rustup-rs/3316/158) thread on rust-internals. (I've put in my 2¢ in there too.)
Small question, in the router example: ``` let server = Iron::new(handler); ``` did you mean ``` let server = Iron::new(router); ``` ?
I'd be interested to read that as well!
You're looking for /r/playrust. This subreddit is for the Rust programming language.
Just had a look at slog, I am not sure how it is any different than println when working out issues. As others pointed out, debugging your own small tool is not always needed. It is quite a different story when working on large system, especially on code you have not written. &gt;It's funny but there's rarely if ever need to do much debugging in Rust. I spent twice as much time getting my code to compile without weird tricks (unnecessary clones etc.), but 0 time debugging. :D &gt;slog for extensive cost-free logging (so no need to add any weird println!), tests for double checking algo-stuff, more tests for everything else. No weird crashes, no silly undefined behavior, no problems other than borrowck yieling at me. 
I find your view very naive. Debuggers are just as useful for finding faulty algorithmic issues and logic problems in the code. Rust's type system is neat, but it can't guarantee correctness or even simple invariants (e.g. this list is always sorted). Debuggers don't work really well for memory corruption (apart from null issues) and they're much better caught with Valgrind, efence or other memory corruption tracking tool.
Not being able to call a function from gdb was a terrible frustration for me. I have been looking forward to this for a long time. \o/
&gt; Your article also made me realize how many other super interesting things there are to learn. Well, I guess the my lifetime is way too short for all of them :/ Which means you always have something interesting to do as long as you're alive. ;)
By default, Rust only links against `glibc`. If you want fully statically linked binaries, you can use one of the `-unknown-linux-musl` targets. Edit: this only applies to Rust-only crates and the stdlib. Third party crates can link FFI libraries dynamically.
I'd even say that it depends on the type of logic your application contains. I work on a large code base with hundreds of thousands of tests and I spend my days in a debugger (in rr if I am lucky, otherwise plain gdb). Logging does it for simple things but it doesn't scale well with large programs (because of build times, of how it affects reproducibility, and that it doesn't always map well with the nature of what you are investigating in the state of the program). The type system sure helps with some classes of errors, but at the end of the day complex logic can and will fail in complex and type-safe ways. edit: by that I mean for some people it is not "1%". More like 60%.
It also still references the std::thread::scoped function, which is not actually safe.
IIRC you can point rr to a specific installation of gdb and it will use it, so you can get gdb's rust support for free.
On Linux, go binaries* do not use the C library, depending only on kernel version 2.6.23 or above. This means you won't be able to run a go binary on an old kernel, which may exclude some enterprise Linux distros. Rust binaries* dynamically link against glibc, so may require the same (or a later) version of the C library present on the build machine. This means you may have a tricker time moving Rust binaries to older systems. Personally, I think Rust got the balance right. I'd far prefer the Rust developers spend time making Rust awesome than reimplementing the C library. At least for now. :-) \* built normally, on most architectures; both languages let you build binaries in other ways (see other answers)
/r/playrust, my friend (also I think you missed a link?)
Looks great. The infer_schema! macro seems to be very powerful, however, doesn't that mean that it's impossible to compile a project that uses it without having a postgres server running? Is it possible to define a schema without it? Alternatively, I think you could add schema definition files. The cli tool could generate the definition file from a database, and you could load the file it in a macro. I think that would make compilation easier. Just my ¢2.
When I was about ten years old, my dad brought home an old electric typewriter with the plan to connect it to our East German Z80 clone home computer. After he had built all the electronics, we embarked together on my very first serious programming project: Writing a printer driver in assembler. Eventually watching the type writer’s keys being moved by a ghost typist and see the hammers fly with breakneck speed (there had been a long series of experiments to find out the minimum safe delay between letters, including the discovery that if the a letter was repeated we needed to wait longer since the hammer had to move all the way back before it could be triggered again) was a wonderful introduction into what makes programming such a delightful undertaking. While the Internet is a great thing and Web development has been a gateway for many people to actually start learning to program, there’s something magical about making the real world move with the power of your mind’s creation. Rockets beat web sites any day. Somehow, even the ‘Hello world!’ of embedded programming, a simple blinking LED, is kind of exciting. Which is a rambling way of suggesting that there may be plenty of ideas for starter projects in this area. There’s likely a bit of bump with the need to get all the tooling right before the first blinking light, but then, maybe that is why that light is so exciting in the first place: It is quite a bit more of an achievement then ‘just’ copy and pasting a few lines into an editor and running cargo. 
Why I need to use the deref operator '*' sometimes and not others.
I'm going to ask a few questions, not because I currently believe structural inheritance is a good idea, but because there's a lot of points here that are circular. What are the arbitrary limitations of structural inheritance? What do these arbitrary limitations have to do with traits. Sure, traits are theoretically more important than e.g. Java interfaces, but what does that have to do with inheritance? I wouldn't say the lack of delegation in 1.0 is a mistake. 1.0 was going for a minimal set of constructs, and delegation is mostly just sugar. Fields in traits on the other hand, it's a wash. I didn't realize how useful they were until I sort of tried to invent them myself (and then shown there was an RFC already), but that's like saying Java is incomplete because it only has interfaces and not traits. No language is perfect, and few languages seem to be trying to really move the (theoretical) bar as much as Rust has been. Really, had Rust another six years to mature before the back-compat stopping point, yeah, it'd make sense to definitely see them. But without stopping and seeing what people are actually doing and wanting/needing, Rust could have also trailed off into (unknown) regressions of usability quite easily. As such, I don't see it as a mistake - only our lack of knowledge forcing our hands. How is adding structural inheritance wholesale be giving up? How would it throw away our current foundation, rather than add to it? You're making a lot of negative points here, but you don't show your reasoning for making them. :( You call "inheritance" a "relic of a broken world", again without proving that it's broke. I'm pretty sure this breaks the "no zealotry" rule. I also don't see how inheritance theoretically prevents people from using ADTs and traits when we have ADTs and traits. Yes, people who only know of inheritance might first only use inheritance to solve these problems, but when that happens, we can use that as a point to teach about these other solutions. Unless the patterns of inheritance are perfectly contained within the patterns of ADTs and traits, you're ignoring those outside patterns. The final statement also straddles the zealotry rule without actually contributing to your point. C++ is gaining ADTs and traits, but it still has inheritance. It's not deprecating inheritance, so it's not a regression to add inheritance because C++ is adding ADTs and traits. Your entire point seems to be saying inheritance is bad because I've already come to the conclusion that inheritance is bad. And because of that, it doesn't seem to prove anything to me, only that you're preaching to the choir of those who already believe.
Yes, `infer_schema!` calls `infer_table_from_schema!` for you, which in turn calls `table!` for you. `table!` is a normal macro which you can call without a database connection. We have an open issue for generating a file containing the `table!` calls from the CLI.
&gt; So, I start stepping through the algorithm in the debugger, find a dodgy step in the way and stop there. Then I invoke a function in the debugger to dump the algorithm state to a file and then visualize it with a plotting tool. I stare the plot for a while, think real hard and then fix the issue. "Thinking real hard" tends to be the kind of thing it's good to get the computer to help with. &gt; The code I'm talking about is no more than 30 or so lines of code bbut it's relatively complex logic and the state is all floating point data, so the compiler can't help to maintain invariants. Maybe it can't at present, but I see no fundamental reason that it couldn't.