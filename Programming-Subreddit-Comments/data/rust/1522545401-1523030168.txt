That code looks like `partial_ord` on the options themselves except for not handling the `(None, None)` case as equal (is that intended?).
Let me rock your world and point out that the vowl in "four" and "forty" aren't even pronounced the same in some varieties of English.
&gt; Yet, why can't we safely directly convert a ch into a str of length 1? Because a `char` is a 32-bit unicode code point, and a `&amp;str` is UTF-8, meaning it's made up of 8-bit code units. They're completely incompatible.
The type annotations are possibly confusing it since `num` should just be `usize`. If you do the following, does it still fail to suggest `.unwrap()` at the last line? let s: String = "33".to_owned(); let result: Result&lt;usize, &lt;usize as FromStr&gt;::Err&gt; = s.parse(); result.unwrap()
The nom annecdote certainly was familiar to me—[I even wrote about this a few weeks ago](https://vfoley.xyz/ppbert/). In this project, I ended up coding my own parser—a parser for a binary format. In a project, I had to write a parser for a textual format, and I also chose to write my scanner and my parser from scratch. I think any library, either based on macros or functional combinators, would need to have its "tentacles" everywhere (e.g., knowing the tokens or the errors) and the result would be more complex than just writing a bit of boiler-plate code.
My advice would be to ask the community about the parts that aren't explained well enough, and point it out so that the books can be improved.
Anything C can do, Rust can do without C's help. Even a complete kernel and surrounding operating system, as with our Redox OS project.
I just tried it and that does not make any difference. when the completion list opens up on `result.un` .. it does not show any of the methods listed in the original post. I also tried something like, let result: usize = s.parse().un it does not work
Playing devil's advocate, there's a [Go generator](https://github.com/go-swagger/go-swagger/) for the same spec.
It's called "masochism" then
Definitely. In fact, we are setting up a verification working group after some productive discussions at the Rust All Hands this last week, so there should be more public momentum on this soon.
I don't think you can, at least not until we get specialization, but that depends on the exact details of how specialization is implemented. The problem is that you've implemented `Unwrap` *twice* for `Option&lt;T&gt;`. Both of the implementations apply, so the compiler doesn't know which one you meant unless you specify. This is because you added a type parameter to `Unwrap`; essentially, `Option&lt;T&gt;` has `Unwrap&lt;T&gt;` and `Unwrap&lt;Option&lt;T&gt;&gt;` implemented on it. However, if you remove the type parameter, you still have two implementations for `Option&lt;T&gt;`, and they overlap, so the compiler will reject the code anyway. (As an aside, `unwrap` is already defined on `Option`, so you should pick a different name.)
Only if combined with `RefCell` and it needs to be clonable. But when working with thread locals `RefCell` is the better choice than `RwLock`. Will mention that.
Is this something you would want to do? AFAIK threads are only fucked on windows, all normal operating systems can and should use threads.
Thanks for posting this (and doing the work to create the crate!). 
Your scenario where you create a threadlocal value that can be shared across threads is a little weird. I would pass the arc in at the spawn thread function for more clarity. 
Something like [this](http://play.integer32.com/?gist=f79427d17c26dc146135cf9573f2549d&amp;version=stable)?
I got pretty far in the doc before I realized what day it is today. 
Love it. Really.
At least you realized. I only realized when I came here to comment that we should take example from an esoteric programming language and then saw your comment...
The nomicon has a section on Variance, and pnkfelix gave a talk about it at RustFest Berlin.
Pretty stoked about this RFC. Hope I get to implement it ~~though I may secretly want to use it to build my army of llogiq clones~~!
I came here to say what a stupid idea this would be, and then I read your comment. Now I feel stupid. I blame not having had my morning coffee. 
[removed]
I would make it dependent on the complexity of your API. If you are going to write microservices which by nature only have a few endpoints then you can clearly go with Rust. I already wrote some microservices in Rust and the "not so mature or convinient web frameworks" did not stand in my way. Other tasks than the REST API will take most of the time and there Rust really shines. For complex API's I do not know since of the "modern" frameworks I only know rocket which is currently not running on stable. 
Hey all, I was able to attend the Rust All Hands this year, and this is a write up of a cool project I worked on there. Let me know if you have any questions!
Oh! That is very exciting to hear!
Back in those days, I had put the Boost.Spirit grammar in a source file of its own which included *no header* of our own project, so you never had to recompile it during incremental builds. And this file was named with an `A`, to be the first to start to compile during clean builds, because when you had to recompile it, it would take longer by itself than all other files of the library combined.
Yes, I saw your demo. Still feels a bit like a work-around to me, but then again I rarely, if ever, need this.
Please propose this again tomorrow.
This post confuses me. Did you forget to attach a link or text?
I propose to counter the sandblaster by drowning it in love and lace, opinions?
It’s from an actual situation we have. We have a thread local that holds the state of the current task and it’s passed to other workers. At all times it’s bound to a thread local. The pattern for this is similar to how logical call contexts in .net work. 
You're pretty brave, posting it here on April 1st ;)
Okay, so all operations on `f64` values would result in an `f64n`, so all intermediate values in an expression will be `f64n`. If you're using `let` without a type, some of your variables will be `f64n` too. But when you want to store it, you'll have to convert back to f64, which is when you do your `unwrap()` or whatever. Actually perhaps it's better to keep `f64` as it is (NaN-able), and have a new non-NaN type, e.g. `f64v` (for validated).
It always depends on the context/workload. Such a general statement cannot be made, which is probably why you're getting downvoted. Listen to the first 10 Minutes, he explains it pretty well. By using a threadpool or threads in general, you're limited to the amounts of threads when e.g. like setting up EC2 instances on aws, altough the thread would just be idling until the response comes back. Network latency is huge in computer time (relative to the base clock), which is often forgotten. By doing it asynchronous, you can fire of all setup commands at once and collect them one by one on the event loop, resulting in a faster setup. Though if you do computational expensive tasks, which are more bound by core clock than by IO, you'd probably be better of with thread pools.
They almost were! IIRC /u/kimundi was playing with that idea before 1.0.
Very comprehensive post! Thank you! :) ( hope it isn't April's Fool... :D )
Oh no.
Thanks for forwarding. I'm spoiled by twitter I guess...
I believe you mean it's /r/mildlyinfuriating
&gt; However, note that Generator is a trait, and therefore you should be able to implement this trait by yourself to cover those requirements. That's where I'd miss `switch`. Writing `work` in Rust is not pretty. &gt; And if you want a macro to sweeten the syntax, you can write one too. The solution to "I miss this control structure" is "write a relooper for the entire language"?
Isn't this the same as https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html
Unsure if April's Fool...
In-jokes?
Wait 45 seconds on the reddit page and you will understand :)
More like an intersection of April Fool's, keen observation, and D E E P E S T L O R E
Haha. antoyo was afraid of such thoughts (you were right!). So no it's not. Tokio is very difficult to use and removing it makes the whole simpler as the blog post states it.
This is one post that I used for reference, so some of the techniques are the same, however there are some new ones I used in my post, and some of the techniques now have an easier way to use them (like using `Cargo.toml` instead of passing linker arguments). I hope it was worth a read for you anyway :)
Writing game engine, where I need optimized allcoator dor specific tasks.
I haven't fully understood how this will work in the future. Will it still be possible to plug in Futures based code into relm?
Your `take_while` example doesn't work, because `take_while` consumes the entire iterator and returns a new iterator - that's just how it's implemented. As for generators, there is [preliminary, unstable, experimental support for those](https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html), but it is very, _very_ unstable as of right now.
Just upgraded my side project to relm 0.14, and it was a breeze, thank you! I'm new to Rust, and I've really appreciated both the documentation and extensive examples in relm. I haven't dived into rust's async ecosystem yet (one thing at a time!); so far I've just been doing simple channel-based interval polling. But I'll be following relm closely to see how async support evolves, and definitely take advantage of it.
(Update: behold the fruits of my boundless magnanimity.)
&gt; I haven't fully understood how this will work in the future. It has no future.
That's already implemented! If you use `unsafe` in a function, it's `unsafe` and you have to decide whether the function is `unsafe` by marking *the function* `unsafe` or whether it's safe by marking *the body* `unsafe`.
Oh, perfect! I use rust on production for almost 2 years but never had to use unsafe yet
Thanks, the opt-level z makes a pretty big difference for microcontroller use too. It does have some impact on performance, but could be useful if you run out of space. Here's the results from testing with one of my programs: text data bss dec options 10754 0 828 11582 lto + z 11174 0 828 12002 lto + debug + z 16746 0 828 17574 lto 17032 0 828 17860 lto + debug 
The char is internally a `u32` containing the Unicode codepoint number, while a `&amp;str` would need to have a `UTF-8` representation of that number, which may or (outside ASCII) may not have the same bit pattern. So you'd need to create the bit pattern you need, then borrow that, but were will you store it? Best you could do is a `Cow&lt;'a, str&gt;`.
You can use `take_while` in other contexts, for example in an iterator pipeline. 
Why do you think it is a stupid idea? Please keep rule #2 in mind.
It might still be possible with `futures-glib`, but I won't maintain this crate anymore. Anyway, is it really what people want? No one ever noticed that networking tokio code in relm does not work on Windows.
Using words instead of numbers seems counterproductive, and I originally didn't notice that they were limericks, since English is not my first language. This made the most lines somewhat superfluous. That being said, I hope this is actually implemented and hidden behind an undocumented compiler flag. 
Hmm, good question actually. I feel the big issue in C# is that Arrays and Lists are very distinct data types, you cannot convert one to the other without reallocating and copying all the data. Rust in this sense doesn't really have an owned array type, the best you get is `Box&lt;[u8]&gt;` which isn't really useful or used anywhere aside from converting it back to `Vec&lt;u8&gt;`. Furthermore you can convert a `Vec&lt;u8&gt;` into a `Box&lt;[u8]&gt;` (through the into_boxed_slice method) without reallocating ^^(lessormore) so why provide an extra method, just let the user do the conversion after collecting into a vector. Something like that anyway :)
It is worth mentioning that rocket is unlikely to be optimized in any way for binary size, so there might be still plenty of room for improvement by "simply" swapping the framework, and in general being bit more concious about your dependencies.
We talked at the Berlin meetup about generating rust from svd files and you showed how to go about refining that. Very happy that you finished your blog post so quickly. Gonna dive right in!
Does it integrate directly with crates.io and github to try and find the styles we like best?
Fair enough, we should propose translating the limericks into more languages. I can do German (and obviously English) and help with French and Polish. But we'll best do the English version first, as it is, for better or worse, the lingua franca of IT.
Glad you like it. April first or not – let's implement this!
No takesie-backsies! This RFC is now live and will hopefully be accepted.
That's nice to see some projects go on the better path!
We are even looking into making it a decentralized cloud-based solution that stores blocks of code in a chain of hashes.
I was so sure it's a joke...
Thanks! We certainly thought so!
&gt; Increased CPU usage This will be great for keeping my server closet warm in the winter. Brilliant.
I am happy to hear that Redox has had such an incredible positive impact on your life!
We have learned a lot over the past 3 years! Always give your users what they want - less!
I'm trying to understand why cargo is not working on my Fedora on the same project that works fine on my Arch. It says that "Package atk was not found in the pkg-config search path.". I don't understand. I've changed as follows: export PKG_CONFIG_PATH=/usr/bin I'm using cargo run and I've understood that cargo was supposed to download the necessary dependencies. To my understanding cargo should download the dependencies to the folder shown above after I have declared the environment variable with export command...
I'm glad you agreed with our shadowy organization to remove networking while keeping sound. You'll soon see why we said communicating over speakers with ultrasound has many advantages [for us].
You cannot use `take_while`in this context because it will stop one element too late! If your input is "5*3" you will first get in your "parse number" state. If you would then use `(&amp;mut iter).take_while(|c|c.is_numeric()).collect::&lt;String&gt;()`, it would correctly extract the digits for you, but it would advance `iter` one position too far: it will stop taking when it encounters `*`, and in the next loop iteration `iter.peek` would yield `3`, giving you a result of two number tokens with nothing in between. You'd have to introduce some kind of `peek_while` iterator to get the correct result. So why not simply do that? It's not hard to write your own iterator, and I imagine a "peek-while" kind of functionality might come in handy later. I imagine most people would write it somewhat like this: struct PeekWhile&lt;'a, I, F&gt; where I: Iterator + 'a { iter: &amp;'a mut std::iter::Peekable&lt;I&gt;, f: F } impl&lt;'a, I, F&gt; Iterator for PeekWhile&lt;'a, I, F&gt; where I: Iterator + 'a, F: for &lt;'b&gt; FnMut(&amp;'b &lt;I as Iterator&gt;::Item) -&gt; bool { type Item = &lt;I as Iterator&gt;::Item; fn next(&amp;mut self) -&gt; Option&lt;&lt;Self as Iterator&gt;::Item&gt; { let &amp;mut PeekWhile { ref mut iter, ref mut f } = self; if iter.peek().map(f).unwrap_or(false) { iter.next() } else { None } } } fn peek_while&lt;'a, I, F&gt;(iter: &amp;'a mut std::iter::Peekable&lt;I&gt;, f: F) -&gt; PeekWhile&lt;'a, I, F&gt; where I: Iterator + 'a, F: for &lt;'b&gt; FnMut(&amp;'b &lt;I as Iterator&gt;::Item) -&gt; bool, { PeekWhile { iter, f } } You can then use this function in your loop, like `let digits = peek_while(&amp;mut iter, |c|c.is_numeric()).collect::&lt;String&gt;();`. I have the result in the playgound [here](https://play.rust-lang.org/?gist=21bb0d99676012b8b2a1521bcb191a38), it seems to do the right thing. You may or may not wish to also define a trait that is implemented on `Peekable` so you can just call `iter.peek_while(...)`, I personally wouldn't.
Ohhh! Interesting! I can finally take that clothes pin off the spacebar!^[1](https://xkcd.com/1172/)
Why would it be?
Haha, I just finished reading this one and realized that's not the right topic. But I learned a lot of stuff that's gonna be very helpful in the near future so I am not totally sad. :D
The more discrete [feature](https://courses.csail.mit.edu/6.857/2014/files/05-li-lynch-zhao-covert-acoustic-channels.pdf) for networking that comes with your maintaining the sound system. Redox users can use it. Resourceful strangers can use it. Everyone benefits from a good sound system. The other thing we needed was microphone support across major brands (esp USB) to reduce the need for on-site visits during our work. Is that in Redox yet?
Disappointed to see that the new Redox doesn't literally Redox my computer into a steaming pile of metal oxides.
Oh my god, thank you. I finally understand property testing and model-based testing! Very well explained, with great examples. I’m really looking forward to the next post on simulation!
There once was a language from Britain with which the tech world was smitten. Against the flow some proposed Esperanto, but with ASCII it didn't quite fit in.
I'm trying to understand why this code compiles: I started with: let accum = self.state.entry(key_columns).or_insert(self.empty.clone()); But I wanted to change it to be lazy to avoid the unneeded clone. This doesn't work: let accum = self.state.entry(key_columns).or_insert_default(|| self.empty.clone()); But this does: let empty = &amp;self.empty; let accum = self.state.entry(key_columns).or_insert_with(||empty.clone()); Doesn't empty continue borrowing self? How can we start the mutable borrow while empty is borrowed? 
I thought using `impl Trait` in futures was pretty much blocked on `impl Trait` being usable in trait implementations?
`take_while` is usually useful when you're only interested in the prefix sequence for which the predicate holds and want to ignore the rest. Parsing is simply a different use case.
Hold down ctrl-d and it should get close to doing that.
[I still have no idea what you are referring to.](https://media.tenor.com/images/7854175f5c2f6c33196143092092f613/tenor.gif) [It is indeed true that everyone benefits from a good sound system.](https://www.nsa.gov/)
Do you mean for associated types? If so, yeah, that should help a lot, but I imagine it won't be stabilized any time soon.
Managed to solve it myself. At least I was missing GTK (not sure if it was something else as well, I tried a lot of different things): https://developer.fedoraproject.org/tech/languages/c/gtk.html
Wasn't there a way to make self-referential structs or a new language feature to help with it. Was diving into my hobby project on the train and using handles still bugs me...
The kernel is always involved when you preempt, because how else would you get the preemption interrupt? So you can't move it entirely to userspace anyway. I'm skeptical that userspace is able to do *CPU-bound* multithreading well. I'd have to see numbers to be convinced otherwise.
Oh an April Fools joke. Cool.
Getting *anything* to do with GTK to work on windows is a nightmare.
Isn't UPX pretty bad for performance? Near the end of the article they say &gt;We ended up with a binary that was less than 4% of the original size, with only minor tradeoffs in convienence and performance. Is the performance part true?
Instead of a frontal assault of insanity, it feels like I'm being gas-lighted. Nice.
This is fantastic. How come it requires nightly?
Excellent blog post! I'm just getting into 4k/64k demo executables with rust, and this blog post is perfect for starting the path to the smallest possible file size!
It looks like an asynchronous function with a lambda callback. Basically, the connection happens in another thread and when it’s ready, the callback function will execute.
I'm a bigger fan of the [double dactyl](https://en.wikipedia.org/wiki/Double_dactyl). fn foo() -&gt; Box&lt;Fn(u32) -&gt; u32&gt; { let x = 0u32; Box::new(|y| x + y) } &amp;shy; --&gt; src/main.rs:4:14, error[E0373] | 4 | Box::new(|y| x + y) | ^^^ - borrowck borrowck | closure environment | outlives the reference | made on the left | | lifetime-magnanimous | fearless compiler says | add the `move` keyword for | ownership theft
&gt; Removal of window manager, for efficiency Good to see that RedoxOS chooses the minimalist approach to software 
Thank you for your work on the Faust language! I was thrilled to discover that work is being done to compile from Faust to Rust. Both languages are so exciting on their own; the prospect of using them together fills me with joy!
Compiler is capable of tracking borrows of sepparate fields. This works: struct Foo { a: i32, b: i32 } let mut x = Foo { a: 1, b: 2 }; let a = &amp;mut x.a; let b = &amp;mut x.b; So `empty` borrows `self.empty`, and to calculate `accum` you borrow `self.state`, so everything is fine. However, when you use `self.empty` in the closure, the closure just borrows whole `self`, and thus you get conflicting borrows.
One at a time: - `constexpr`: Rust has `const fn`, the basics are there, the interpreter is already implemented, it's just a matter of deciding what to allow (and what not to), - overloading: overloading on types is the bane of inference, and the bane of understanding (for a human); I would be open to overloading on the number of parameters though, - non-type generics: there's been progress on this last year, work is scheduled to resume around Aug/Sep this year (once Rust 2018 ships), - static reflection: unclear how it'd fit; it's unnecessary in the generic programming framework (since Traits lists all abilities and properties already), and code generation is for now in the domain of macros/procedural macros. I've done my share of metaprogramming in C++ (both using Boost.Preprocessor and Boost.MPL), and for now the only pain I've felt is related to non-type generic parameters. I haven't felt the need for static reflection.
You are fully aware that we are April 1st, right?
To my defense, I've posted it when it was still the 31st ;)
Thanks, that's very helpful!
No particular reason except that certain nightly features (such as impl trait) make development easier. :) We'll certainly consider moving to stable Rust in future.
????
I think you're a bit too restrictive. Why not just go for "getting *anything* to work on windows is a nightmare"?
FWIW that's only tangentially relevant to rust, rust used to use [bors](https://github.com/graydon/bors) and now uses [homu](https://buildbot2.rust-lang.org/homu/) not bors-ng, and bors-ng is coded in Elixir.
You can find the full linker script [here](https://github.com/japaric/cortex-m-rt/blob/master/link.x) 
Aaah, this is excellent news, congratulations. Now we just need someone to have a crack at [Arrow](https://arrow.apache.org/), and we can really get the Rust-for-data party started.
There's already an [arrow](https://crates.io/crates/arrow) for this. It is also been actively working on. ;)
Fantastic, I was looking for one yesterday but some how missed it. Will be watching closely. Reading the C++ docs, I was expecting to see common operations like "sum" and "groupby" defined on Arrow arrays, but couldn't see any. Are dataframe-esque operations out of scope for the project?
Also known as the "TempleOS" design.
Because lots of things (such as most pure-rust code) work great on windows? GTK is outstandingly bad at supporting it.
Why was networking removed? Was it to improve theoretical security or was there a vulnerability in the networking stack?
Ahh, thanks
Thanks a lot ! I believe all answers are inside this crate. 
I'm curious; just read your original blog (great read!) post on Rust's async story; I take it you don't feel it has improved much since then, since you are ditching the crates?
Just found https://japaric.github.io/embedonomicon/ .... Now things are becoming pretty clear.
So a device that buries a sandblaster in lace and chocolate, right?
What's confusing for me is as an American expat these frequently show up for me on April 2 now and it throws me off. 
The slice primitive type has the method `split_at_mut` if you really need two `&amp;mut` references, but `swap` is often cleaner. 
Does it include Monero mining?
Oh amazing! Thanks for building this, together with recent work on the Arrow rust implementation this will be seriously useful.
Yeah, great guy /u/japaric wrote a lot of code and documentation about embedded Rust, essentially becoming the Jesus of embedded Rust...
`futures` seem like the way to go in async Rust. Or at least it's the best we have now. Other crates *add* support for them, not remove it. Removing the support is very surprising, especially if it's April 1st.
Distributed realtime java?
Very well documented, nice job!
That's great! I only used `unsafe` for FFI and playing with some exotic shit. :)
When should I use this vs. [futures-timer](https://github.com/alexcrichton/futures-timer) ? Any time I'm using Tokio specifically and not just Futures themselves?
Raw pointers?
I find reading a lot of the autogenerated documentation to be extremely difficult if not downright impossible. A lot of Rustaceans don't seem to have much issue with it because many questions about "how to do X" often get referred to the generated API docs. Is there a guide somewhere on how to read the API Docs? Is it just my unfamiliarity with typed/compiled languages? Also relearning words kinda sucks. Is it safe to think of a `struct` to be equivalent to an `obj` in most other languages? What exactly is an `impl`? [Reading the docs](https://rustbyexample.com/generics/impl.html) doesn't give me any meaningful (to me, at least) information. Unrelated to the `struct` and `impl` confusion - I've ran into the below issue which, while it compiles and does what I want, seems awfully messy. I'd love some advice on handling this in a more sane way. [std::path::Path](https://doc.rust-lang.org/stable/std/path/struct.Path.html) // &amp;user_input is a string returned by the Windows File Browser after the user has selected a file let absolute_path = Path::new(&amp;user_input); // There has to be a better way of doing this than unwrapping twice? let image_parent_directory = &amp;absolute_path.parent().unwrap().to_str().unwrap(); let image_file_name = &amp;absolute_path.file_stem().unwrap().to_str().unwrap(); let image_file_extension = &amp;absolute_path.extension().unwrap().to_str().unwrap(); // I added these as a simple sanity check that my selected file was being returned and that I was grabbing the right pieces // But it means I have to .to_str() and .unwrap() a second time above to get my program to compile. println!("User selected file: {}", user_input); println!("The current directory is: {:?}", image_parent_directory); println!("The file name is: {:?}", image_file_name); println!("The file extension type is: {:?}", image_file_extension); My current understanding of this is that calling `.file_stem()` returns a `Result` enum which contains `Ok` and `Err` values. The `.unwrap()` call is a common shorthand/idiom that pretends that `Ok` is the only result. So on the path `C:\Users\Example.png` the`image_file_name` would be equivalent to a`Path` struct with the value of `Example`, notably not `"Example"`. I don't fully understand the restrictions of `std::fmt` places on `println!` but I can't print `Example` I can only print `"Example"` so I need to cast my `Path` struct to a string. So I call `.to_str()` which itself returns another `Result` enum that contains `Ok` and `Err` and I again need to call `.unwrap()` to get my `Ok` value of `"Example"` which can safely be called by `println!` ^Currently ^the ^program ^will ^panic ^if ^a ^user ^exits ^selection ^without ^making ^a ^selection, ^so ^I ^need ^to ^handle ^that ^error ^somewhere.
Arrow is primarily focused on the in-memory format. However, there are plans to add "kernels" but this is only in the early stages I believe, even for the cpp implementation which is the furthest along. I believe that the arrow team expect the dataframe libraries to be built on top of arrow rather than arrow being one directly. For instance, pyarrow will be the backbone of the new pandas library.
No. Box is not the same as new op in C++ 
Just tangle all the moving parts with lace and get the chocolate in any other crannies you can.
Oh fantastic! I was curious about how that would work. 
Yep! It's making great progress! 
Have you played with cargo bloat? What's left? 
Yeah unsafe was the other recommendation...
The link for Rust 1.25 blog post is broken.
I'm not sure what it would even mean to have a "UTF-8 encoded `char`". `char` is UTF-32 because that encoding allows all unicode scalar values to be represented by different bit patterns of a fixed size. Meanwhile UTF-8 is a variable-length encoding, so some values are only 1 byte and others are be 2, 3, 4, or even more bytes in length.
Have you read [The Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/)?
Just like with any other programming language, your program would benefit from being split into smaller units. In this case, that could just mean splitting your long procedures into smaller ones. You also do some unnecessary cloning inside your closure blocks. (hint: read about move closures [here](https://doc.rust-lang.org/book/first-edition/closures.html#move-closures).) I would also take a close look at everywhere you use unwrap and make sure that either you are sure that there is no way to recover from an error at that point or that you give sufficient feedback to the user about what went wrong and what they can do to prevent it . The .expect("msg") method is a good tool for said situations. All in all though this is a great start. Keep on rustin'!
A UTF-8 encoding of a scalar value is variable-length, sure, but a *single* scalar value still has a max length. That max length happens to be exactly the same as the size of a `char`. So if you're using 4 bytes anyway, maybe it's worth using them in a way that lets you build a `&amp;str` that points to (part of) them.
&gt; I cannot think of a single language that uses obj. If you're coming from another language and you're having trouble understanding Rust's concepts in relation to that language, you need to tell us what that language is. My only experience with programming is Ruby (where basically everything is an object) and Javascript (coincidentally - where almost everything is an object). Rather, I should have correctly said `Object` but am too used to shortening it to `obj`. That was a mistake. I'm doing my best to not conflate any _larger concepts_ together - but just some of the _terminology_ and maybe a few minor concepts. A lot of my existing concepts of Objects I might have will not transfer well (or at all) to Rust but some of the minor details might. An array in Rust is very different from an array in Javascript, but a tuple in Rust is, more or less, the equivalent to an array in Javascript. Little naming differences like that aren't too confusing for me but being able to conflate some things and understand how I might use it skips a lot of the learning process of "Okay, now where the hell would I actually use this"? The concept of an `Object` in Javascript and a `struct` in Rust may not be the same but the terminology for at least some uses of `Object` might be equivalent - just not in _every_ use of `Object` due to different concepts of what an "Object" is. As you mentioned - Rust doesn't have inheritance so that concept can be thrown out the window. But Rust does have "Objects" that have "Functions" (methods) and "Values" (Traits). Conceptually, least to me, there is very little difference between let rect1 = { width: 40, height: 40, getArea: function() { return this.width * this.height; } }; rect1.getArea() // returns 1600 and struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(&amp;self) -&gt; u32 { self.width * self.height } } // This is almost equivalent to rect1 from the first example let rect1 = Rectangle { width: 40, height: 40}; rect1.getArea() // returns 1600 I'm going to be learning C# on-the-job at work so hopefully my training time at work will help me get more more familiar with the differences of terminology and concepts that might carry over a bit to Rust. &gt;People can't help you if they don't understand what the problem is. You need to explain you actual issues, or walk us through what you're trying to do and how it isn't working. The rest of the paragraph was meant to explain my struggles, so I guess I failed at doing that. I think my issue is actually _understanding_ what I'm reading in a practical way I can use, which will come with a bit more experience. Your link to the Traits: Defining Shared Behavior page actually helped clear up some of my confusion. &gt;Then I noticed you're looking at Rust by Example, not the book. Still weird that there's no link back to the book. Woops, you're right. That wasn't "The Book". Thank you for tracking down a better explanation for me - I was stuck on that. :) &gt;The problem basically boils down to: paths don't have to contain valid string data. They can be binary gibberish, which is A-OK as far as the operating system is concerned, but seriously inconvenient for everyone else. Rust cares a lot about these sorts of details. That explains the pain. I don't mind it being ugly if it has to be but I've learned that usually when something is ugly that's because there is a better, more idiomatic way of doing what I want to do and I'm just hitting it with a hammer until it gives me what I want. &gt;`unwrap`ping should be replaced with ? (See: "Recoverable Errors") where it's possible to fail and recover somehow. I've added a `match` on `user_input` for error handling. The rest of the code should be fine as it will no longer execute unless it has a value to execute on. You were right about the `&amp;` being unnecessary. &gt; The `to_str().unwrap()` bits should be replaceable with `.display()` which returns a wrapper type that lets a path be formatted as a string. Received an error `method 'display' is private`, but I'm not worried about it. The `println!` are only temporarily there for some sanity checking so the .`to_str()` conversions shouldn't be necessary.
FWIW, I'd love to be able to use this at $DAYJOB, but that would require stable :( Thanks for releasing this, and I'll be keeping an eye on this to see if it ever works with stable Rust!
Would that work for all scalar values though? I thought there were ones that are 5+ bytes, or that the standard at least allows for them to eventually be a thing if they aren't already
&gt; An array in Rust is very different from an array in Javascript, but a tuple in Rust is, more or less, the equivalent to an array in Javascript. I don't see how that's true. Firstly, you have to exclude the fact that Javascript is dynamically typed. Once you do that, `Vec` is probably the closest to a JS array, since it has a dynamic size. A tuple is really just an unnamed `struct` where the fields don't have names. If you're referring to the fact that a tuple can have elements of arbitrary types like a Javascript array, that still doesn't fit because you can change how many elements a JS array has (which you can't with a tuple), and you can't use tuples with different numbers or types of elements interchangeable (like you can with a JS array). It's nice when you *can* map concepts in a new language to something you're familiar with, but you have to be *very* careful that you don't over-do it and leave yourself with a bunch of incorrect assumptions. A classic one in Rust is seeing "modules" and thinking "oh, I know how that works!" Often, they don't, and end up confusing themselves massively. &gt; But Rust does have "Objects" that have "Functions" (methods) and "Values" (Traits). Again, you appear to have a very wrong conception of this. A minor point is that methods aren't special beyond being functions you can invoke with method syntax (and as a result, have a `self` parameter). But they're otherwise completely normal functions that can be invoked as functions, and which have function types. A bigger issue is that traits aren't in any way "values". The best short explanation I can think of for describing them without re-using terms from other languages is: traits are bundles of associated items (functions, constants, types) that conform to some set of behaviours and expectations, and can be implemented for types. So the `std::io::Read` trait is a bundle of functions that, when implemented for a type, allow you to use values of that type as a source of raw data. A type that implements `Copy` can be implicitly copied around. A type that implements `Sync` is thread-safe. Again, if you *set out* to find similarities, you run the risk of finding ones that don't actually exist. I mean, I do it too, but you need to be careful. &gt; Conceptually, least to me, there is very little difference between [..] You're right in that the probable *intent* of the code is the same, as is the final result. That said, there are at least two differences that I'll mention just to be thorough: - `getArea` is a field of the object, which means it can be different for different instances; this is not true of Rust. - JS is using signed, 64-bit floating-point numbers. Rust is using unsigned 32-bit integers. - JS *might* be using heap-allocation, Rust definitely does not. &gt; [..] I've learned that usually when something is ugly that's because there is a better, more idiomatic way of doing what I want to do [..] Sometimes that's true. Sometimes it's because what you're doing *is just ugly*. There's often no obvious difference between the two. Just wait until you try doing string processing. Or sorting floats. ;) &gt; Received an error `method 'display' is private` [..] Well, uh, you *shouldn't*. [This is what I meant](https://play.rust-lang.org/). As a general bit of advice: if you're asking for help, an example on the playpen people can compile and test makes it the easiest for people to help. Failing that, providing context on the types being used is often needed. When things go wrong in Rust, the important detail is often in the context, *not* in the line the error points to. Also, if you're just using it for debugging, then `{:?}` should work just fine on a `Path` or `PathBuf`.
Care to explain what Nebulet is? I searched for it, but the github readme is pretty generic ;) 
Hm, this is different from my problem in that I'm assigning a `render` member of a `settings` C struct with the `unsafe extern fn(...)` signature. I don't need the closure to capture any of the environment -- in fact it shouldn't. (That's what the `userData` is for: to pass context to the function on each iteration.) I just want end users to be able to provide functions that accept safe pre-verified wrappers or `Option&lt; .. &gt;` objects instead of nullable pointers.
If you read the blog post about the issues with the futures crate, this isn't surprising. I've had similar experience, and similarly gone from 'lets use futures...' to 'lets remove all reference to futures until at least 1.0'.
rustup is a fine tool, but if you want to manage a Rust toolchain yourself for some reason then being able to get the official list of available packages for a given release is pretty useful. 
What you usually do is write a *generic* (over F) extern C function that doesn't actually use F in its signature, only in the body, and pass that function to C. You can't cast F itself to an extern C function directly. I believe that's what the parent comment is referring to by "trampoline".
Working on a toy JavaScript interpreter!
It's a microkernel that employs ideas similar to Microsoft's Singularity. The main concept behind this is; user applications use managed code and run in ring 0. Processes are isolated by software means, instead of hardware, like traditional OS'. Nebulet uses wasm as its platform for running code. Safe memory access, out-of-bounds checks, etc, are performed all in software. This produces an overhead, but it's mitigated by the fact that no context switches occur, even on syscalls. Syscalls are in fact just regular far calls into the kernel from the user application.
The original formulation of UTF-8 allowed encoding up to 31 bits over up to 6 bytes. The ability to encode beyond 21 bits (and over 4 bytes) was removed in RFC 3629 (2003) to avoid exceeding the capabilities of UTF-16. That RFC also excluded UTF-16 surrogate codepoints from UTF-8.
Working on a [JIT demo and tutorial](https://github.com/Cretonne/cretonne/issues/289) for Cretonne!
Could you post any console error? Your device might be missing a proper GPU/driver setup for the OpenGL version that is required by piston.
Working on the type system for my [programming language](https://github.com/Lapz/underscore/blob/master/README.md)
Then you must go fuck yourself 
Oh god Metal is happening 
There are also a couple of people doing demo scene 64k projects with Rust. Would be nice to know which techniques they use !
It's clearly not yet ready to be used.
You have issues with irony. :p But otherwise, any development I had to make on windows has been a nightmare. Too much accustomed to linux I guess?
Attempting to add dependent records to my programming language, [Pikelet](https://github.com/brendanzab/pikelet). I posted some more info and news [on the ProgrammingLanguages subreddit](https://www.reddit.com/r/ProgrammingLanguages/comments/88stz8/monthly_what_are_you_working_on_how_is_it_coming/dwnqagp/)!
The past few weeks I was feeling a bit under the weather and didn't get as much done as I wanted to. To combat that, I decided to go to the Rust Learn/Hack Meetup in Berlin which happened together with the #rustallhands last week. There, I managed to run clippy on a bunch of bigger repos to look for crashes and false-positives. The atmosphere there was super nice and reminded me how it used to be with Ruby a few years ago, but even better. Additionally, I met /u/Manishearth/ and talked briefly with /u/oli-obk/ who asked me if I wanted to help out with the clippy issue tracker. So, uh, I guess now I'm part of the clippy team? Over the weekend I already closed a bunch of old issues that had been fixed previously and this week I want to continue with verifying issues and also hope to fix one or two. 
There is no output on console except cargo info messages about running the binary. There is a pop-up with report error dialog. Its report output is as: https://pastebin.com/YaDv0HsQ How can I check for OpenGL driver on macOS.
&gt; The reason that it's not particularly in-depth is, well, the book isn't a reference. \**sucks his teeth*\* I mean, that's fair enough, but I feel like if someone starts learning Rust via the book or RBE, and they get to a point where what's there doesn't go into enough depth, it would be good for there to be some kind of "see also" interlinking. Also, I'm a little disinclined to let you play that card with the book, since it is *The Book*, and gets heavily promoted as *The* premiere way to learn Rust that all the cool people are using. But, again, that's something that interlinking with the reference and RBE would probably solve. &gt; The book isn't done yet; a comprehensive index is the last thing that you do. *Or* you could use a program that generates one automatically for you as you go... \**comically exaggerated wink*\* Also, manual indices trigger my DRY response. &gt; Oh, and search just landed in mdbook That's *fantastic*. I can't tell you how annoyed I was when the reference was split into multiple files. :D
Yeah, I mean, that's part of why I said to open an issue; I'm 100% open to improvements here. &gt; Also, I'm a little disinclined to let you play that card with the book, since it is The Book, and gets heavily promoted as The premiere way to learn Rust that all the cool people are using. This is literally the first time over the last 18 months someone has complained that there's not enough about `impl`. That doesn't mean it's perfect! But the book is already really, really long, and we have to pick and choose what we go into and how deep we can go into it. For a fairly un-complicated feature, going light is the right call, IMO.
yes it is!!!!!
UPX is a packer. So, it has to unpack your binary during startup. That decompression time is the payment for it. Not to mention other tradeoffs.
TempleOS has a single window... to god.
Looking for authors of `#[proc_macro_derive]` crates to weigh in: * Do you expect macro invocations in your derive input? Why? * Are you manually expanding built-in macros like `stringify!()`? * Would it be preferable if macros in your derive input were already expanded? * How much control would you prefer to have over this behavior?
&gt; There is an hledger written in Haskell that I think is compatible with standard ledger.) For the most part. There are some incompatibilities between the two, a valid ledger file might not work with hledger, and a valid hledger file might not work with ledger. Might be efforts to reduce that gap though, idk. There is likely a compatibile subset of both, though. I just write my ledger in hledger's format and not worry about it.
Working on [wlroots-rs](https://github.com/swaywm/wlroots-rs) and [Way Cooler](https://github.com/way-cooler/way-cooler) live on twitch (https://m.twitch.tv/SirCmpwn) for the [wlroots hackathon](https://m.twitch.tv/SirCmpwn) this entire week in Philly. 
Wait a second, do we want this? I don't know what to think
I very very much do.
Oh now I'm intrigued. I saw the Metal talk as a piece of absurdist comedy on what would happen if we went full circle, but it's definitely an interesting possibility and the benefits are there. Why do you think it's desirable? 
Who is your target audience with this book, what is your approach to teaching, and what do you feel you got right in this book related to my questions?
I am also new to Rust. In fact I am a total Rust newb. Take my words with a grain of salt if you wish. However I have been coding in various languages for many years. I always reach for a toolchain that helps me to write elegant maintainable code. Code analysers that find common complexity issues provide assistance in this area. Just doing a squint test of your code suggests it has a high cyclomatic complexity issues. As bowbahdoe has said you have far too much code in several of your functions. Break it down into more manageable units Also consider writing tests... Still. Awesome work...
Probably not an easy question, but does anyone have an estimate how difficult it would be to build/port a Rust terminal/cli program also for a Termux/aarch64 environment (smartphone/tablet)? Searching turns up activities to make Rust run under Termux, e.g. https://github.com/termux/termux-packages/issues/261 but under a current Termux install I can't find a package. So need to a) compile to aarch64 and b) build with a proper Termux libs runtime environment. As building directly on the final ARM device is a no-no due to flash-wear etc., either make a) a Termux environment in a QEmu emulator or b) crosscompile directly from Linux. Is this a not-yet idea or can this be set up on a long weekend because all the pieces are already available?
No problem! In general, I'm just very interested in alternative architectures for operating systems, and this style goes back to at least where I got interested in it, with exokernels. That is, you can sorta look at this as monolithic -&gt; micro -&gt; exo -&gt; unikernel, and then trying to re-introduce multiple applications on top of a unikernel. Sorta. It's all just fascinating to me.
Congrats on shipping! Writing a book is tough. I'll pick up a copy :)
Same here. I was just looking for something like this. Requiring nightly is however quite problematic.
good bot
No specific advice other that to run [cargo clippy](https://github.com/rust-lang-nursery/rust-clippy) before publishing. It is a really amazing tool that can spot of lot of small issues with your code and help it become more idiomatic. It found about 2 dozen places in your code where you might want to change something. Happy rusting! 
As good a name for Ring 0 as any
My target audience is people interested in systems programming and having followed a one-year course of programming in C or C++. They may be students or developers. No functional programming nor object-oriented programming knowledge is required. My approach to teaching is by following these principles: * Any abstract concept is understandable only by people that already knows concrete examples of such concept. So, you should start with examples of a concept, and then explain the underlying concept. * When teaching a concept, you should never use a still unknown concept. Put in other words: "Introduce one concept at a time". * To explain complex concepts, first explain a simplified version of that concept, and then refine it. It may be necessary to explain first a wrong but very simple version of that concept, and then correct it. I explained some concepts showing the equivalent in C or in C++, and so they should be quite understandable for people familiar with those languages. I also dedicated much text to explain the rationale behind some hard concepts, like trait bounds and lifetime annotations.
Rewriting the database-access code of my homebrew RSS reader from Scala (which I used to use but have largely forgotten and thus can no longer maintain) into Rust, communicating with the main process by serializing JSON messages over stdin/out. For some reason I was convinced this would be easier than just setting up an HTTP server on localhost or using JNI. That was probably incorrect. Anyway, I have a working prototype and now I just have to slog through converting all of the different database calls. After I finish that I'll probably rewrite the HTTP and feed-parsing code into Rust as well.
Not just testing, reading! I do think good code should read well (without going down the Literate Programming route, which originally was a way to make old-fashioned Pascal code more readable and to compensate for its deficiencies. At least in part). Also, as the thinking behind a program evaporates, it leaves just the code. Then you are also that person who needs to read it afresh ! 
This is called a netsplit and there are no general case solutions. It tends to be hard because the application is unaware that the network has been disrupted Better algorithms (e.g. more able to detect these issues and prevent damage) tend to be slower Distributed databases will tend to either require quorum to minimise the chance that a node is working on its own and/or nominate a single node with the privilege of updating state.
I dont know if it fits here, but is there a better/more idiomatic way to conditionally add functions to a struct from a module? With my implementation I need getter/setter methods for every field I'd like to access form the trait inside the module. https://play.rust-lang.org/?gist=c2dd92ca6ab0aea4f892acf8c6526705&amp;version=stable
\m/
I have been working on DataFusion (https://datafusion.rs/), which provides SQL + DataFrame operations on columnar data. I actually submitted the PR for the Rust version of the Apache Arrow library and am now working on updating DataFusion to use the Arrow crate. I have also been looking at parquet-rs and plan on supporting that soon (hopefully in the next few weeks). As Arrow moves into the kernel space I will most likely donate more and more of DataFusion to that project.
It's interesting that it tried to panic, but couldn't do it properly.
Congratulations on this! Must be a good feeling to see the condensed hard work you and everyone around it dedicated onto this and finally have a physical manifestation of it in the bookshelf! 
Finally finish [unrust](https://github.com/edwin0cheng/unrust) 0.1.1 roadmap, we will be making a blog post about all its features. Here is the demo of [sponza](https://github.com/edwin0cheng/unrust) scene, take a look and tell me what is the fps in your machine. 
Why you don’t make the struct itself pub? You want to prevent mutations?
Could you make an example?
&gt; I don't need the closure to capture any of the environment -- in fact it shouldn't. (That's what the `userData` is for: to pass context to the function on each iteration.) I believe it's the other way around: there's no need for `userData`, it's even annoying to use. Capture of environment should be used instead. At least if you want to provide idiomatic Rust API. Depending on what the lifetime is, you can either use `Box` or enable non-boxed closures. I have some experience with this (and I was even seriously considering writing a crate for handling this), so I can help you if you want.
&gt; it does not teach all of Rust programming. What topics does it not cover?
Sweet tool. Thanks!
You should write that! I don't think nebulet is far enough to include much about it, though.
My cyclo complexity is pretty high. I hope to bring it down as I get a better feel for how Rust move memory around, which the link you provided helps tremendously. I have yet to fully get a grip on options and results. Instead I have a silly number of unwraps. The expect("msg") tip is very helpful. Thanks for your feedback!
No doubt my cyclo count is way high. Mostly cause I don't quite know what I'm doing yet. Rust kept throwing compile errors at me every step of the way so as soon as I got a good build I was like "stay put". I've only been at this for a little over a week, but I hope to learn the testing idioms soon. 
Playing around with a system for storing crypto public keys on IPFS and using them to authenticate messages, whether an email or an "login" API call. Seems like it should work fine so far. It's ridiculous that in 2018 one has to write one's own entirely independent authentication for each web backends service, or use OpenID that's so complex and touchy to run only Google and Facebook provide it. And the main peer to peer crypto key infrastructure is PGP? It's silly.
I read it but found it unconvincing at that time. Now I looked at it again and started reading [the linked article](https://theta.eu.org/2017/08/04/async-rust.html) only to find that it references [my own reddit post](https://www.reddit.com/r/rust/comments/5nifpm/they_said_rust_error_messages_with_generics_are/)! :) That being said, I'm convinced it's not a joke, but I'm unconvinced that it's the best move.
It's a shame the default case ends up so slow, plus 24 copies of mov esi, N lea rdi, [rip + .Lpanic_bounds_check_loc.M] mov rdx, rcx call core::panicking::panic_bounds_check@PLT ud2 Someone really needs to figure out how to compile with fast paths and only go down a precise route when you know you're going to panic.
Very cool! My windows/firefox/intel HD 4600 computer at work is getting mid 40fps idle to mid 30fps when moving.
Do you have a repo ? I'd like to check it out :)
Rust-specific things: * `&amp;Vec&lt;u8&gt;` is usually just `&amp;[u8]` (`Vec::as_ref()` can return `&amp;u8`) * The `ascii` crate may make life easier rather than just using `Vec&lt;u8&gt;` everywhere, though I can sympathize with wanting to do everything from scratch. * `safe_line_from_slice()` seems redundant; it could be `s.iter().map(|c| if c &lt; b' ' { b' ' } else { c } ).collect()` or something. * Your life will get *way* easier if you return errors early and use `Result`. That alone will take a lot of the hairiness out of your parsing functions. * There's lots of useful functions in the standard library like `is_ascii_hexdigit` and related things
Yeah but the iterator case and the explicit/assert aren't strictly the same. I suppose if you add the asserts to the iterator version you would end up with a faster version as well.
I see. Thanks for the feedback! We'll see how difficult it is to move to stable and post updates here.
Sounds good. I just ordered the book :-)
Thank you :) A lot of the text is based on the datasheet.
I read that book, it was quite nice easy to follow. Thanks 
Working on adding mutable methods in [rpds](https://github.com/orium/rpds/) (a crate for persistent data structures), in particular `HashTrieMap`. This means that if you do not have a lot of sharing operations can be much faster.
Hell yeah, it is
Termux contributor @its-pointless has a separate repo at [its-pointless/its-pointless.github.io](https://github.com/its-pointless/its-pointless.github.io) with rust compiled for Termux (arches include aarch64). Instructions for adding the repo are found [here](https://github.com/its-pointless/gcc_termux/blob/master/README.txt). After that it's just a simple \`apt update &amp;&amp; apt install cargo\` and if you want \`rust-docs\`, \`rust-rls\` and \`rustfmt\`.
Server software isn't where I would put a high priority on executable size.
What is left in such a binary? 800K of code seems on the high side even for a http framework. 
Ideally, macros would **not** be automatically expanded. IIRC from my lips days, when writing a macro, you get the syntax w/o any internal macros expanded. Then, in the outer macro expansion, you could explicitly get inner macros to be expanded for an AST branch. This would be the best option, though I have no idea how plausible it is to implement with the current macro system. When experimenting with non trivial macro implementations, I definitely hit cases where I wished that I could do the above.
Still working on expression evaluation for the Rust plugin for lldb. I'm making good progress here.
Working on adding ["flavors"](https://github.com/udoprog/reproto/blob/package-translation/lib/core/src/flavor.rs) to [reproto's](https://github.com/reproto/reproto) [intermediate representation](https://github.com/reproto/reproto/blob/master/doc/compiler.md). This provides a flexible way to change which types represents different things like fields and packages, which permits me to write simpler, [more generic](https://github.com/udoprog/reproto/blob/package-translation/lib/backend-rust/src/flavored.rs) backends with safer and less code. This is currently a big refactoring step before I make the push to support more languages.
Ha, this did it! Yes, exactly that. It seems it is different to say 'm' than "m".
Thanks for your reply! I wasn't clear enough on what I wanted. I was just trying to say: let letter = 'm'; I had tried these before without success, so I was just confused what I should do: let letter = "m"; let letter: char = "m"; I didn't understand that " and ' behave differently in Rust.
&gt; I suppose if you add the asserts to the iterator version you would end up with a faster version as well. It doesn't seem to auto vectorize it: https://godbolt.org/g/Txp1En
Most statically typed languages use single-quotes for character literals and double-quotes for string literals. Dynamic languages like Javascript and Python don't have a separate character type so they use single-quotes and double-quotes interchangeably.
Last week, I didn't get to updating the `z3` crate as I'd hoped. I am working on some changes to Z3 itself to modernize some of the C API. That work will continue this week. I did get a lot done in updating the `lldb` crate, and have more to do before I decide to do a new release. I'm still working on updates to my `javascriptcore` bindings and a `serde` integration. I submitted a pull request which was merged for improving the `byteorder` docs and am looking for other crates to randomly submit improvements to. Perhaps the newly released `parquet` library? I made good headway last week on RDF-related parsers for N-Quads, N-Triples and Turtle formats and will continue that work this week.
Okay, did some tests, without xargo trick here is what I got on my system for a hello world in different frameworks: -rwxr-xr-x 1 zokier zokier 998K Apr 2 18:49 tinyactix/target/release/tinyactix -rwxr-xr-x 2 zokier zokier 2.6M Apr 2 18:49 tinyactix/target/release/tinyactix.unpacked -rwxr-xr-x 1 zokier zokier 223K Apr 2 18:57 tinygotham/target/release/tinygotham -rwxr-xr-x 2 zokier zokier 535K Apr 2 18:57 tinygotham/target/release/tinygotham.unpacked -rwxr-xr-x 1 zokier zokier 274K Apr 2 19:03 tinyiron/target/release/tinyiron -rwxr-xr-x 2 zokier zokier 595K Apr 2 19:03 tinyiron/target/release/tinyiron.unpacked -rwxr-xr-x 1 zokier zokier 422K Apr 2 18:20 tinyrocket/target/release/tinyrocket -rwxr-xr-x 2 zokier zokier 979K Apr 2 18:20 tinyrocket/target/release/tinyrocket.unpacked the .unpacked ones are just stripped, and the others are UPX packed. Gotham seems to do well here, although I think iron could be still improved somewhat (like rocket, it ends up having lots of stuff in .rodata). Please do not take these figures too seriously. But I think 500k-ish unpacked is about as small as you can go with current rust web ecosystem. Of course you could probably make much smaller custom thing directly on sockets etc, but that is another story.
Good tips. I was initially scratching my head with the `&amp;Vev&lt;u8&gt;` vs `&amp;[u8]`. By the end of it I figured out they were basically aliases. Another issue I ran into was not finding seemingly simple functions like is_ascii_hexdigit in the docs. Instead I just opted to write from scratch rather than waste time on googling. I figured if I keep coding in Rust then I'll eventually stumble upon everything and assimilate standard patterns. I haven't licked `Results` or options quite yet. But I see the power there and I look forward to rocking the `?` token. 
I imagine just no-std and overall minimizing dependencies would get you pretty far. They also have fairly optimized packers (eg. kkrunchy) in demoscene that help.
Check out my [`numeric-array`](https://github.com/novacrazy/numeric-array) for this exact scenario. I’ve implemented a majority of common operations in a way that is highly conducive to auto-vectorization using the correct compiler arguments, as detailed in the readme. 
Congratulations /u/sunchao! How does it compare (in feature set/compatibility/performance) with the official implementation? Is there a comparison matrix somewhere? TY!
I'm working on a way to search across the entire rust bookshelf: https://github.com/rust-docs/team/issues/13
The `tokio-timer` can be used on its own for general purpose timer needs with futures. `tokio-timer` provides efficient (constant time complexity) timer operations as discussed in this thread while maintaining 1 millisecond level granularity. Basically, `tokio-timer` uses an algorithm and structure that is considered the right way to do general purpose timers (i.e., not high precision timers). I will not comment on `futures-timer` as it is not my crate. That said, when comparing, I would recommend looking at the algorithms used by both and consider your application needs.
I want to publish it at some point but right now is just a little too soon. 
Check out the explanation in this forum thread from earlier today: [&amp;amp;mut T seems to behave like a Copy type](https://users.rust-lang.org/t/mut-t-seems-to-behave-like-a-copy-type/16578?u=dtolnay).
Like the sibling comment says, UTF-8 is limited to 4-byte scalar values. But even if it weren't, it would still have a maximum size- it encodes the length entirely in the first byte as the number of leading 1s.
Playing with Rust embedded this week! Last week I published an svd2rust crate `stm32f469xx`, now I'm working on an embedded hal crate for it and eventually a family agnostic crate for the STM32 DMA-2D or "chrom-art accelerator" which is basically a fancy DMA that lets you also do pixel format conversions and alpha blending. The STM32F469xx is pretty specialist as the F479xx is the only one in the same family and the super generic F4xxxx so there shouldn't be too much wasted work. This should result in me writing a board specific crate for the http://www.st.com/en/evaluation-tools/32f469idiscovery.html I'll also be trying out some experiments with [tarpaulin](https://github.com/xd009642/tarpaulin) because I think I might have cracked an issue with coverage of iterator chains with `?` at the end!
You don't need the explicit asserts, just force the slices to have length 8. If you rewrite your example thus, you will get three bound checks, and then a vectorized loop: pub fn foo(a: &amp;[f32], b: &amp;[f32], out: &amp;mut [f32]){ let (a, b, out) = (&amp;a[..8], &amp;b[..8], &amp;mut out[..8]); for i in 0 .. 8 { out[i] = a[i] + b[i]; } }
Why not use [strum](https://docs.rs/strum/0.9.0/strum/) to derive `ToString`/`FromStr` (which would require lowercased enum case names) or derive `EnumMessage` or `EnumProperty`. And then using [`#[derive(SmartDefault)]`](https://github.com/idanarye/rust-smart-default) to make a case the default..
That's the NoSQL approach but in reality, you can understand CAP theorem as: "In case of network partition, choose between consistency or availability". If no network partition is occuring, we can have both availability and consistency. 
Thank you all! I finally wrapped my brain around the levels of abstraction and got it working. Will post once it's reasonably sort of complete. This is easily the most brain-bending Rust project I've taken on so far, so thanks.
It does if you [slice it instead](https://godbolt.org/g/gqTu7w). I've noticed before that in cases like this the compiler seems to have an easier job with slicing than asserting.
The contains calls are for detecting headers. Sometimes those "headers" can appear in the middle of the file. 
Incidentally, I just wrote a post about my experience in writing a REST service in Rust, maybe there is something useful to you in there: [https://www.reddit.com/r/rust/comments/8908bv](https://www.reddit.com/r/rust/comments/8908bv) I have no experience with go, but will sing praises about Rust to whomever will listen. As I understand, the type system is more powerful than go's, that can add another layer of assurances without writing a single test. My recommendation at this point would be actix-web for the broad feature set and low barrier of entry. Focus on solving your tasks, almost all the parsing, routing and dispatching is taken care of. Async is optional, at least in your code. If your problem is amenable to be solved in Rust at all, I'd think it quite a productive platform.
I think this bug is the cause of your crash https://github.com/tomaka/winit/issues/426
Me too. And the source code. Much thanks.
I guess you know this part but the problem is the inferred lifetime on the reference in that `_` is a constant; namely everything after the definition of `t` to the end of `main`. You can use `rustc -Z verbose -Z unstable-options --unpretty hir,typed` to see that the reference is &amp;ReScope(Remainder(BlockRemainder { block: ItemLocalId(70), first_statement_index: 1 })) mut usize and then use `--unpretty hir,identified` to see that `ItemLocalId(70)` refers to the block that starts on `fn main() {` and `first_statement_index: 1` means the lifetime is from the first statement (`let func_list = ...;`) to the end of the first block. So when you take the reference to `t` on the first iteration of the loop, the borrow lasts that long, so it will still be alive on the second iteration. But the question you really want answered is "why does the inferencer pick this lifetime and why does it do it right if you use `&amp;mut _` instead" and I don't know the answer to that.
I had a very interesting question by PM, so I'll answer here. Here's the question: &gt; Hi, &gt; I'm curious about your opinion on using coroutines in GUI programming. It seems to me that the current Future abstraction is coupled with having a tokio-like event loop to "drive" the futures. &gt; However, this is not the only way to think of coroutines - there is also the continuation-passing approach implemented by Kotlin. In an async/await system a continuation can be obtained by grabbing the top-level generator (or Future in Rust's case) - this post shows how to do it in Python. Specifically, continuations make it really simple to connect async functions to arbitrary GUI events, without having a behemoth like tokio around to serve them. &gt; Do you think continuation-based async functions would be useful for users of relm? It looks very interesting. But it has two problems in relm/gtk (and maybe Rust/gui in general): First, how do you handle stopping event propagation? For instance, let's say we have this code: fn handle_press_event() -&gt; Inhibit { let block = await!(some_async_func()); Inhibit(block) } that will prevent text to be entered in a input text according to the result of an asynchronous function. What would be the actual result of that? When it was possible to do something similar in relm, the text could be entered backward in the text field :) . Also, how do you handle the model, which is a mutable reference? Let's say I `await` in an event handler which has a reference to the model (which is a useful feature of relm) and then another event happens, I'll have two mutable references to the model, which does not work with Rust rules. Since GUI are synchronous by hardware constraint (I came to this conclusion by developing relm), i.e. when I press on a key on the keyboard or move the mouse, the event should be handled immediately, I don't think that async IO inside event handlers make much sense in certain cases. If anyone has a solution for these two issues, I might consider again coroutines/continuations based ideas for relm. For now, we have to live with these limitations. Thanks.
Which version of Rust are you using in this book :) ?
I have this dreaded feeling that we'll have to check the borrowchecker source code to get an answer to that. 
I glued together some tips, and ended with this code: main!(|args: Cli, log_level: verbosity| { let mut bf = BufReader::new(File::open(args.filepath)?); let mut streams = HashMap::new(); let mut l = String::new(); while bf.read_line(&amp;mut l).unwrap_or(0) &gt; 0 { { if l.is_empty() || l.as_bytes().iter().tuple_windows().any(|(a,b)| *a == b'R' &amp;&amp; (*b == b'H' || *b == b'T')) { l.clear(); continue; } let symbol = &amp;l[11..15]; let symbol_bytes = unsafe { *std::mem::transmute::&lt;*const u8, *const [u8; 4]&gt;(symbol.as_bytes().as_ptr())}; // unsafe { (&amp;mut output_path)[11..15].as_bytes_mut() } .copy_from_slice(symbol.as_bytes()); let f = streams.entry(symbol_bytes).or_insert_with(||OpenOptions::new() .write(true) .append(true) .create(true) .open(["C:\\outRust\\", symbol, ".txt"].join("")).map(BufWriter::new).unwrap()); writeln!(f, "{}", &amp;l)?; writeln!(f, "{}", "\r\n")?; } l.clear(); } }); It's running now with 50 seconds to 75 seconds. I was thinking about doing some parallelization, using each stream in a pool thread. Any ideias?
I like this: &gt; Never say "This will be treated in a following chapter." Waiting makes me anxious, like I am being denied info. 
Great to see this get to fruition. Am really encouraged that Apress has also decided to invest in a Rust book
This would be excellent for someone like me. I have read enough of the Cretonne material to think "wow, impressive" but still don't really understand how it works or how to make it work 
This week I will be tidying up the code &amp; copy for my "Files &amp; File Systems" chapter for Rust in Action. I have implemented key/value stores using the CouchDB and Riak file formats to show how high resilience, high reliability can be achieved using potentially unreliable storage devices. Also in the chapter is a hexdump utility that creates PNGs of files' internal structure to reveal the differences between text and binary file formats. Oh - and I have the bulk of the code written for chapter 15(?), which will hopefully be a 3D semi-interactive artificial life (flocking) simulation deployable to mobile and wasm targets. That needs some polish 
The API docs can be pretty hard to penetrate until you figure out where you can look for things. I was amazingly annoyed at them until I took some time to skim/explore through the sections listed [here](https://doc.rust-lang.org/std/#how-to-read-this-documentation) just so I had some sort of idea what was there and where. Highlights: `Vec`/`slice`, `Iterator`, the numerical types (`u8`, `f32`, etc), `String`/`&amp;str`, and `Result`/`Option`. Even just knowing "oh yeah, shoot, there was some method to turn one type of `Option` into another somewhere" can lead you in the right direction, even if you don't remember what it is. Clippy can also help with this.
Thank you for the writeup, it was very informative
Another `&amp;mut T` is borrowed from the first, not copied. Look at `this playground`[https://play.rust-lang.org/?gist=c2a57c7ffb7c14f12e5128634d25c82a&amp;version=stable]. `increment_both` creates two separate temporary `&amp;mut i32` references by borrowing from the `&amp;mut X` parameter. It's the same in your code, except you're borrowing a `&amp;mut i32` from a `&amp;mut i32`.
Clippy looks awesome. I had no idea it existed until @LolWatAmIDoingHere mentioned in this thread. I'm stoked.
In my crate ([derive_more](https://github.com/JelteF/derive_more)) I don't think I handle unexpanded macros.
Update: the [latest episode](https://www.youtube.com/watch?v=bS5rtxWd2yQ) was done with Davinci Resolve. I really enjoyed the polished interface and the extended feature-set. After applying a custom LUT to the video, realtime rendering got extremely slow (1 fps). I had to remove the LUT again and re-apply it at the very end of the process. The final rendering took four hours for 30 minutes of video, which is quite significant in comparison with the background-rendering from iMovie. Overall I had a pleasant experience, especially given the fact that it's a free program. Still considering to move back to iMovie or try Screenflow for a faster edit-render cycle.
Here you go! https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript
It pretty much is :/
[web-reports](https://github.com/jack-fraser/web-reports)! pdfs from html, css, js &amp; json.
Great post :) Hopefully futures/async will get stabilized in a usable state rather soon, I so badly want to use Rust for all things.
Show notes and additional code [here](https://github.com/hello-rust/show/tree/master/episodes/2-snakes-and-gears). If you find any errata, let me know and I'll mention it in the show notes. For future show ideas, you can also create an issue on Github: https://github.com/hello-rust/show/issues
From a person coming from Go, C and a bit of C++, what might I expect to exist or be a certain way that is different in Rust?
I've been wanting to look more at actix. Right now I use Rocket and absolutely love it, I love how you make types do so much stuff, it enhances the type system so much. Honestly nightlies can be challenging - but it's been very much worth it.
Chiming in: it produces a clean abstraction of the underlying architecture. So all the baggage of x86 can be thrown out; a new CPU architecture need only implement the wasm runtime &amp; now you have access to all WASM programs. Compare this to MS having Windows running on ARM with dynamic recompillation of x86 into ARM.. WASM is a better intermediate binary representation than x86
(Not sure why my reply didn't show up here - so repost) In terms of features, as mentioned above, currently it supports all encodings in the Parquet format, as well as most compression codecs. It offers a row-by-row record reader right now, with supports for most types including complex types. We plan to enhance this with a batch-oriented record reader and expect a big performance gain from that. There's no write support yet. Also no predicate pushdown. In terms of compatibility, we follow strictly on the Parquet standard specification and it should compatible with parquet-mr. However, we found a few places where parquet-cpp doesn't strictly follow the specification, so files written by the cpp version may not be read by parquet-rs. We haven't done any benchmark comparison yet. One of the next steps is to do performance profiling and compare with parquet-cpp &amp; parquet-mr. For instance, I'm working on applying bitpacking to the codebase, using SIMD instructions - currently it reads one packed value at a time which is quite slow. 
Working on a very small operating system to learn the finer details of rust 
I’ve been looking at frameworks. I thought the gotham exmples were (now?) excellent and covered the type of topics I was looking for. It looks like a great framework and I’m going to give it a crack.
I love second option (proc_macro::expand_macros). It is very clear and gives full control over the time when macros will be expanded - before, after or in the middle of my macro processing.
And seem like i have to optimize it more. Thanks a lot.
Diverging functions are useful and could be covered in about a paragraph. Meanwhile, if let and while let are excellent show-don't-tell examples of how 'everything's an expression'. I'm a little confused why you wouldn't include them.
What for? 2D? 3D? Scripting? AI behavior trees? Skeleton animation? Physics? Tiles? Platform? Image processing?
Just bought the print version. Can’t wait to get it. Something strange: Apress didn’t yet ask me to pay.
2D games
Graphics: OpenGL? Gfx? Glium? Window: Glutin? Sdl2? Glfw?
/r/playrust
You *might* want to look at OP's profile to see what subreddits they post on.
Neat. There are only 5 advisories, the newest is like 9 months old. Still useful though. Particularly, might be worth adding to travis CI so an advisory counts as a build failure. 
Works on my machine:tm:!
I don't feel the linked explanations were particularly clear, so here's my crack at it. When the rust compiler sees a path of type `&amp;'a mut T` in a context which expects `&amp;'b mut T` the compiler automatically inserts the borrow-of-target pattern. fn increment_twice(x: &amp;mut i32) { increment(x); increment(x); } becomes fn increment_twice(x: &amp;mut i32) { increment(&amp;mut *x); increment(&amp;mut *x); } This only happens when the compiler can see the `&amp;'_ mut _` type. It's not done generically (it won't invoke `ops::DerefMut` automatically). The result is a new reference to the same data with an equal or shorter lifetime. The parent variable cannot be used during that lifetime, so the uniqueness of `&amp;mut` references is preserved. I might guess it's only done when the lifetimes would be different (otherwise it's no more useful than simply moving the value), but [this error message disagrees](https://play.rust-lang.org/?gist=e7d7da95ebae2d9916a392ecb0fba197&amp;version=stable). The desired type must be explicitly known (argument of a function, assignment to a field, IIRC the term is "coercion site"). Otherwise it just moves. let b = &amp;mut a; let c = b; //moves from b
Before posting, you should check what subreddit you're posting to.
Is that hexdump code public? I'm working on a FAT32 library and I need a way to visualize the layout and I've been trying to figure out a good tool to do that with. If yours is public might be a good reference for my own FAT32 visualization tool.
Well it pretty much has to be something that rustc does (differently) if clang doesn't do the same thing, as both are based on llvm
new is an operator in c++. You can override it in global or class level scope. So, all I am saying is that they are not the same if you want to compare them at a deeper technical level. 
Thanks! I definitely hope that rustup might one day be modularised so that other toolchain-deployment tools don't have to start from scratch, but I figured I'd need more battle-tested code before the rustup team would look at a PR.
Working on yet another [file sharing tool](https://github.com/zoranzaric/tmpshare). The main goal is to do some live coding [part 1](https://www.youtube.com/watch?v=kl-w8TQzMv4) [part 2](https://www.youtube.com/watch?v=F3sG3aDQT_4). Any feedback is welcome!
So this is basically a C interface to rustls?
Mvp
It's called a reborrow, if anyone was wondering.
It was posted 0:05 on April 1st, Berlin time zone. So you probably just read an old post on the 2nd :).
I've had this exact problem, and I solved it by just doing away with iterators completely and using indexable slices instead. There's no guarantee that non ASCII characters won't be in the input, so that's a huge flaw, but it was the only way I could think of to avoid any headaches.
You forgot to include the actual link to "this post" here :) I'm not sure what is meant with a continuation-passing approach in this context, and how it should work without any kind of event loop (especially considering that GTK already has one anyway). AFAIU CPS generally means that you would pass a closure that takes the result to each function, but that is basically how the e.g. `and_then` combinator on `Future` works. However, GTK itself is already based on an event loop. There's no need for something like tokio in relm, if one would want to support futures then they could be implemented around the GTK event loop that exists already anyway. Bringing also tokio into the game here only complicates things and you somehow need to integrate the two event loops somehow, which generally seems unnecessary unless an application also wants to use tokio... but that's a problem for that application then. Implementing a futures executor around the GLib/GTK main loop does not look very difficult and could generally be useful, especially in the context of GIO async functions.
Wow, great work 👍
Interestingly, I got this once, and then never again: &gt; thread 'main' panicked at 'bug: failed to send query even though renderer process was still running', /Users/skade/.cargo/registry/src/github.com-1ecc6299db9ec823/turtle-1.0.0-rc.1/src/renderer_process.rs:81:29 note: Run with `RUST_BACKTRACE=1` for a backtrace.
The point is I am assuming to switch the TLS implementation without requiring any programming. Multiple TLS implementations do this because OpenSSL is used in so much software.
Is there such a huge installed base of rust applications/libraries that utilize OpenSSL? I could see that argument with C programs with an installed base that has been growing for decades.
When you provide a C API your audience is the pool of C OpenSSL implementations not Rust ones. Those would use rustls directly anyway.
Hopefully sometime in the future there will be a performant WASM JIT that would allow really high performance execution of wasm bytecode in both Servo/Firefox and in Nebulet. I am really interested to see what the performance implications of something like Nebulet are (no context switches / syscalls, etc) once the bytecode can be executed efficiently.
Ah, so this is for C programmers, in order for them to gain memory safety in a critical part of the software without switching to Rust. I completely misunderstood the point of that library. Thanks for clearing that up!
I filed an [issue](https://github.com/sunjay/turtle/issues/67), I'd be happy if people could ping sunjay there for debugging.
Working on a fast node system that can be used in game dev - https://github.com/rustgd/vnodes There'll be a blog post soon ;)
ISO for Fedora 28 beta from here: https://fedoraproject.org/wiki/Test_Results:Fedora_28_Beta_1.3_Summary?rd=Test_Results:Current_Summary#Downloads
Fuck 
OK I didn't get what you meant. I was implicitly comparing kernel preemption and userspace tasks switching at pre-determined points (i.e. what Go has now). Of course Go's next approach as described in the link needs some kernel interaction (they talk about signals under Linux) so would have a price to pay, maybe too big a price.
30fps in the castle, 15fps outside. Firefox on a Debian machine.
Why do you make that Win32-only ? Why not a cross-platform image browser ?
The README says everything's implemented in Rust, and also that it uses code from BoringSSL, which... isn't Rust. I'm confused. Does anyone know whether it actually uses C code or not?
After I removed the cruft, my accomplishment seems less significant. :/ Meh, whatever. I'm still proud of myself. I finally feel like a rustacean! https://github.com/ericmoritz/bullet/compare/83569a13426c0c22e45172566cd221a4b57d2c34...fbce22223e9d7e2f84412862bbb7739572ad93ad?diff=split&amp;name=fbce22223e9d7e2f84412862bbb7739572ad93ad#diff-639fbc4ef05b315af92b4d836c31b023
My Rust git workspace takes up 7.3G of my 32G SDD. Any ideas on how to reduce the load without giving up on * compiler docs * incremental builds * recent git history
1. it uses `rustls`, which is written in rust 2. `rustls` uses `*ring*` 3. `*ring*` is a fork of BoringSSL (hence the name) which is in the process of porting the C -&gt; Rust, but has not yet finished. So, yes, today there's some C code, but eventually, there won't be any. At least, that's what I understand today.
actix-web looks really great, thanks for posting this! Would you mind explaining the decisions that went into the rust application structure? It was a bit hard to follow at first, since you have to jump between multiple files to see what any given endpoint is doing.
Continuation-passing refers to the technique of implementing coroutines, which is by functions passing around a hidden parameter containing instructions how to resume them. In Kotlin the `suspendCoroutine` primitive then reveals this continuation, allowing the code to stash it somewhere before the actual suspension happens. Rust implements coroutines in a different way, but a `suspendCoroutine` like primitive could still be implemented. &gt; Implementing a futures executor around the GLib/GTK main loop does not look very difficult That's the crucial question. Is it documented somewhere what it takes to implement a futures executor? As argued in my blog post, the experience from Python shows that it is in fact not so easy to adapt one event system to another, as they tend to have different approaches to multi-threading, cancellation, support for nested event loops, and many other details.
Ah, that makes sense! I would not have guessed that openssl's memory-unsafety would be easier to get rid of than its advertising clause, yet here we are.
Thanks for the honest feedback. Working on that. :-) Right now, I'm not sure whether I want to focus more on tutorial-style videos or if an explorational-style is a better fit. Kinda want to do both. That's why I left the bloopers in and and tried more of a free-style session this time. So I hope this well get better in the long run.
So, the current feature set is being able to view a Firefox window in a VR headset? I'm not sure, but that what it seems like from the article and demo video.
Regarding your first question, I think that simply `handle_press_event` should not be async, and `await!` macro inside it is an error. In other words, I agree completely that async IO inside individual handlers doesn't make much sense. But such a handler might want to _start_ a coroutine which will take a longer time. The use cases I see for coroutines in GUI programming are: * tasks which are either long-running by their nature, such as stateful animations * operations that must for technical reasons be dispersed across different callbacks - for example, widget setup code that must do something when the widget is realized, then something else when it's mapped, and something else again when it's destroyed, and you want to keep the state of all these things private. Explicit continuations make it easy to express operations dispersed across multiple callbacks as coroutines. Suspending the coroutine registers the continuation somewhere with GTK, and `await!` wakes up the coroutine when the continuation callback is invoked. &gt; Also, how do you handle the model, which is a mutable reference? Let's say I `await` in an event handler which has a reference to the model (which is a useful feature of relm) and then another event happens, I'll have two mutable references to the model, As agreed above, awaiting in an event handler doesn't make much sense, but launching a coroutine does. It is a good question how to afford the coroutines with references to the model without using `Rc&lt;RefCell&lt;...&gt;&gt;` everywhere.
I'm opening a PR to point out a few things, but a common improvement I can see at first glance is field initialization shorthand. At this line (and others) https://github.com/OUISRC/Rust-webapp-starter/blob/master/src/api/user.rs#L94 You can shorten `current_user: current_user,` to just `current_user,` Source: https://github.com/rust-lang/rfcs/blob/master/text/1682-field-init-shorthand.md
A thousand times this. If you managed the same thing in even less code (while still keeping it readable of course) then you've definitely accomplished something.
I don't like *re*borrow, because *re-* in English often implies extending the duration of an ongoing event (*renew*) or even a new event after the first (*reopen*, *return*, *reversal*).
PSA: there's a recent ` -Zstrip-debuginfo-if-disabled=yes` flag which should help to make `--release` builds smaller, if you are not using srtip already. https://github.com/rust-lang/rust/pull/49212
&gt; That's the crucial question. Is it documented somewhere what it takes to implement a futures executor? Documented not so much (also not on the GLib-side for the relevant pieces). But from looking at the code of all the involved pieces it seems quite possible. I have a proof-of-concept for that on my todo list, we'll see. &gt; As argued in my blog post, the experience from Python shows that it is in fact not so easy to adapt one event system to another, as they tend to have different approaches to multi-threading, cancellation, support for nested event loops, and many other details. I'm only talking about futures, not tokio. Integrating the GLib main loop and tokio is going to be quite awkward (but also possible from what I can see). There might of course still be some way how things don't fit well together, we'll see.
4. BoringSSL is an OpenSSL fork. 😂
It is a new event - you have a borrow, and then you dereference and borrow the object again from that lvalue.
Googling if this was possible I came about this book which seems like the source of the weird lego-planet wall-texture thing lol: https://www.amazon.com/OpenGL-Programming-Windows-95-NT/dp/0201407094
You don't understand. Once you put something in a VR headset, it automatically becomes Web 5.0, revolutionary, and disruptive. 
&gt; Rust, a programming language that **guarantees** memory safety. I thought that wasn't actually true?.. 
Very nice! Though I strongly suggest putting real version numbers for the dependencies in the `Cargo.toml` so it doesn't break at some random point in the future... edit: oh you included the `Cargo.lock` in the repo, my bad
cargo update will break it 
The beauty of FOSS software is that if someone wants Rusty:Eyes to work on Linux or Mac they can fork it and write it themselves. Linux already has Feh as a borderless minimal image browser and I don't care for people who choose to purchase and use Apple software. While the primary purpose is to fix a bug in Impression:Eyes the other goals are to remain roughly the same in terms of executable size and memory usage. Impression:Eyes is 352KB in size and runs on 1,792K of memory when opened and not displaying an image. I found that using GTK was already too much bloat.
Seems like this is part of something called [MesaLock Linux](https://github.com/mesalock-linux), which sounds interesting.
Oh man, 1) I forgot to lock versions, 2) Cargo.lock shouldn't be there 😂
Pure marketing gold, to be sure! ;)
Just because something is in C does not mean it is old. Rust is barely a speck on the radar compared to the amount of C being written and maintained.
I’ve used `cookiecutter` in the past for Python. I’m guessing these templates are something similar?
It's a binary, `Cargo.lock` should totally be there!
It wouldn't be a ton of work.
To add to the fun, OpenSSL isn't really fork-safe. https://wiki.openssl.org/index.php/Random_fork-safety
Looks nice, I will have a look!
My understanding is that, in this project, everything except *ring* and the Rust standard library is written in Rust. The Rust standard library is based on libc and so it has a large amount of C code in it until projects like https://github.com/japaric/steed get further along. Most of the remaining C code in *ring* is being formally verified for correctness by Google. We currently face a tough choice in the *ring* project: Do we use BoringSSL's proven-correct code, or not-proven-correct Rust code? I hope to resolve that in the near future by using proven-correct Rust code, but we don't have that yet.
The other invisible asterisk is "and also this only refers to the language and not the implementation, which has soundness holes".
Woops, corrected.
Because nobody likes to repeat mistakes, but not everyone is in agreement on which things are mistakes and which aren't.
54-60fps pretty stable while moving around in and out of the castle. Chrome on Windows 10, Intel i7-6700K@4GHz, NVidia GeForce GTX 1070
What does returning `&amp;String` give you over `&amp;str`? - Callers can find out the capacity of the internal `String`. Which isn't particularly useful for anything. What does returning `&amp;str` give you over `&amp;String`? - You can change the internal `String` to something else like `Box&lt;str&gt;` down the road without affecting users. - You can return a slice of a larger string without affecting users. - You can return a slice of a completely different string (like a literal) without affecting users. There's no reason I can think of to ever return `&amp;String`, as `&amp;str` is going to be more flexible. In general, try to pick the most flexible type that doesn't prevent you from doing what you need to.
There are frameworks like [A-Frame](https://aframe.io/) that make creating web VR experiences easy, and Unity recently added a WebVR exporter to their toolchain. The idea we're pushing is that if we can get WebVR-capable browsers into arbitrary headsets, any web-based VR experience can be accessed regardless of any other vendor lock-in that may be present on the platform.
I thought the original had only turns to the left or right..? I might be wrong.
macOS on a mbp. &lt; 5fps
Thanks, which mbp? My 2014 mbp can go to 25+ fps, and would you mind to tell me which browser you use? 
Also note that you don't need the `'a` lifetime in the `&amp;str` example. It'll get [elided](https://doc.rust-lang.org/book/second-edition/ch10-03-lifetime-syntax.html#lifetime-elision) for the same reason as in the `&amp;String` example, so both options will look equally clean.
...but, at the same time, don't let pursuit of perfection grind your project to a halt...especially if it's an internal implementation detail that can be safely refactored later. Don't be afraid to `clone()` sometimes, if the situation is complicated and the programmer time you'll save by cloning is worth it.
Arguably a user of a binary crate should not need to do `cargo update`. I still think it's better to always give versions in Cargo.toml, and you need it anyway if you want to publish.
Ah, that's great. So if I used Unity would I be able to avoid JS? Would 'game dev' skills basically be the requirement? I've never built anything user facing...
Ah, you are correct! I believe I was over-correcting after working with a nested data type. struct Foo { bar: Bar } struct Bar { boo: String } That I believe requires the lifetime specifier.
The receiver is closed whenever all the senders are dropped. `tx_chan` is not living long enough.
Actually, I'm not even sure when I started doing it (or maybe it was hold over from a past version of rust).
MacBook Pro (15-inch, 2017). ff or chrome.
but, I am saving the sender in hashMap. is that a problem?
Then the HashMap isn't living long enough. Somewhere, somehow, the last Sender is getting dropped before you do anything with it.
Thanks for posting about this problem! I created the turtle crate. We are working on figuring it out in [the issue](https://github.com/sunjay/turtle/issues/67) that /u/fgilcher created. In the meantime, it has been reported that turtle works with stable Rust. You can switch to that using [rustup](https://rustup.rs/): ``` rustup default stable ``` This will set the default compiler to stable. If you only want to compile your turtle project with stable, you can use the following command: ``` cargo +stable run ```
You could do all this in a single pixel shader using raymarching. Just some note ;)
The cool thing about wasm is that it doesn't need to be jitted. You can just compile it ahead of time. Firefox uses SpiderMonkey. IIRC cretonne is being developed to replace the wasm compiler in SpiderMonkey.
``` use tokio::net::TcpStream; use tokio::runtime::TaskExecutor; use codec::MyCodec; use codec::Message; use tokio::prelude::*; use futures::sync::mpsc::{Sender, Receiver}; use futures::sync::mpsc; use futures::stream::Stream; use std; use state::State; use state::StateMessage; pub struct Client{ stateSender: Sender&lt;StateMessage&gt;, my_tx: Sender&lt;Message&gt;, my_rx: Receiver&lt;Message&gt;, } impl Client{ pub fn new(stateSender: Sender&lt;StateMessage&gt;) -&gt; Self { let (tx_chan, rx_chan) = mpsc::channel::&lt;Message&gt;(1); Client{ stateSender: stateSender, my_tx: tx_chan, my_rx: rx_chan, } } pub fn run(self, socket: TcpStream, executor: TaskExecutor) -&gt;(){ let framed_socket = socket.framed(MyCodec::new()); let (tx, rx) = framed_socket.split(); let stateClone = self.stateSender; let tx_chan_clone = self.my_tx.clone(); let message = StateMessage{ name: "AJ".to_string(), chan: Some(tx_chan_clone), }; //Register client with state manager. executor.clone().spawn(stateClone.clone().send(message).then(|_|{ println!("State Registered for client."); Ok(()) })); let ec = executor.clone(); let socketStream = rx.for_each(move |msg|{ println!("Message Received from socket stream {:?}", msg.Body); Ok(()) }).then(move |_|{ //DeRegister client with state manager. let message = StateMessage{ name: "AJ".to_string(), chan: None, }; ec.spawn(stateClone.clone().send(message).then(|_|{ println!("State Deregistered for client."); Ok(()) })); println!("Socket closed....!"); Ok::&lt;_, ()&gt;(()) }); let rx_chan = self.my_rx; let chanStream = rx_chan.for_each(move |msg|{ println!("Received message from channel {:?}", msg.Body); //process the socket. //then bind this to sink at the end. //We need to create pipe line. Ok(()) }).then(|_|{ println!("Receiver channel got closed."); Ok::&lt;_, ()&gt;(()) }); executor.clone().spawn(chanStream); executor.clone().spawn(socketStream); // let streamer = socketStream // .select(chanStream) // .map(move |_|{()}) // .then(|_|{ // println!("Actor closed."); // Ok::&lt;_,()&gt;(()) // }); // executor.clone().spawn(streamer); () } } ```
can you tell, where I am doing wrong?
This is my understanding as well.
`std::variant` also destroys compile times due to the amount of template instantiations. It also has some fun quirks like: std::variant&lt;bool, string&gt; v = "hello"; Which of course constructs `v` with the type `bool`, due to the fact that pointer-to-bool conversion has higher priority than constructor-conversion.
&gt; The cool thing about wasm is that it doesn't need to be jitted. You can just compile it ahead of time. Oh wow. I didn't know this. I am not very familiar with WASM, so I assumed it was another browser JIT thing. I am definitely a lot more interested in it now. I guess this means that in the future, Nebulet could compile everything ahead of time (at first launch or at install time like Android ART) and cache the resulting machine code (in a secure way that is not accessible from WASM code / application software, so that malware cannot tamper with it / patch it to break the OS's security model, as there is no hardware protection). This would effectively mean no performance overhead at all from the fact that software is in WASM bytecode. I am really really looking forward to the future of Nebulet. I will probably contribute when I find the time. &gt; Firefox uses SpiderMonkey. IIRC cretonne is being developed to replace the wasm compiler in SpiderMonkey. This is great to hear. This satisfies my dream of a common WASM engine for both Firefox and Nebulet. Firefox folks will probably be interested in optimising its performance to make wasm in Firefox work well, which would benefit Nebulet.
I don't believe replacing all of BoringSSL is currently a goal for the project. Only some parts (mainly platform integration). Rewriting crypto primitives is... hard and dangerous.
&gt; They don't FWIW. Really? Python has immutable strings, so I would be surprised if they get copied.
Is it inefficient/is there a better way to generate random numbers using rand than doing: let mut rng = rand::thread_rng(); Specifically if you are doing this in a function that gets called a lot.
Yep, I'll definitely cache the compiled code. I'm aiming to really minimize the cycles used to create processes. Contributions are welcome! I can only do so much since I'm in school right now. I don't have much in terms of issues that people can work on, but once people show interest, I'll work on that.
The original turns in curves and uses a path finding routine, mine is a random walker that can't turn and walk at the same time 😭
Do you have any documentation for the design/architecture / high-level structure of the OS and/or your vision for it? Or are you making it up as you go along? Or is my best bet just reading the source code to learn about the project?
Great! I will join your gitter group. I have suddenly become very interested in your project! :)
http://thecodelesscode.com/case/209
Does Rust have anything like the Data class in Kotlin? [https://kotlinlang.org/docs/reference/data\-classes.html](https://kotlinlang.org/docs/reference/data-classes.html) just a sweet feature
Ah, that's what I was think of!
The new borrow is a region of the control-flow graph which is inside the parent borrow. I can show some examples after I get home tonight if you like.
I posted this link in order to ask this question about it: what in the world is blob invalidation?
For content that can't be handled directly by WebRender we use what's called a blob image. This is a bag of bytes that WebRender will keep track of. When it wants to draw the image, WebRender will call into Gecko and ask it to draw that bag of bytes. Before blob-invalidation, if you had a large inline &lt;svg&gt; and only a small portion of it changed, we'd have to redraw the entire thing. With blob-invalidation we can update the 'blob' and only redraw the part that changed.
Oh. Maze. I just automatically assumed it's actually Pipes :D
The reason not to reuse is the same as in Java (which also has immutable strings), if you only need a small part of the split string you'll retain the full string anyway (which could potentially be bad if the original string is large)
&gt; But from looking at the code of all the involved pieces it seems quite possible. I have a proof-of-concept for [a GLib futures executor] on my todo list, we'll see. Nice, I'd be interested in playing with it. &gt; &gt; As argued in my blog post, the experience from Python shows that it is in fact not so easy to adapt one event system to another [...] &gt; I'm only talking about futures, not tokio. That explains the confusion on my part. I was under the impression that, while not coupled with tokio in a strictly technical sense, futures are only really useful under Tokio or a Tokio-like environment to drive them. For a recent example, [this reddit comment](https://www.reddit.com/r/rust/comments/84y1n1/how_to_implement_the_poll_method_for_the_future/dvu6s2n/) comes to mind: &gt; You should probably try to do something practical using tokio; trying to understand and use `Future` without an executor context is, in my opinion, largely meaningless And it is not the only place where such a claim was made. Not that there's anything wrong with that either - after all, asyncio futures in Python are not much use without an asyncio event loop, and so on. But this is where the ability to suspend the coroutine into a continuation comes in handy: it makes it super-easy to plug coroutines into _any_ callback-based system. It doesn't matter if it's GLib, the event loop of some web server, or a game, if it can call your callback, it can resume your coroutine.
Was Gecko's svg renderer already able to do that and WebRender wasn't taking advantage of it? Or does this update include big changes to the renderer itself? What other content goes through that process, and does this update speed that up too only affect svgs? Thanks for filling me in.
It's just similar for every language; nobody suggests that Ruby isn't memory safe because a bad C extension can cause a segfault.
It sounds good at first, but if you don't have a clear distinction between slices and strings (and Python certainly does not) it is very easy for innocuous short strings to retain huge amounts of data. This is why as the essay notes this exact optimisation was reverted in Java 7. In these situations copy-by-default is much saner as it has clear up-front costs and no big surprises and data-sharing if available at all is an explicit option (for python that'd be `memoryview`, though it only works on bytes-type objects not actual proper strings).
Java has `Optional&lt;T&gt;` now, but it's so new, the bulk of all Java APIs, both native and 3rd party, are still currently using the null pattern as you described.
What really bothers me about Optional&lt;T&gt;, having tried to use it, is that it's just another Java object (what else could it be?), so it can also be null. Of course passing a null as Optional instead of Optional.empty() is insane, but it's possible and someone might do it on accident. So you have to check for that as well if you want to catch all corner cases, which _of course_ is insane in Java. That's what I love soooo much about rust. Catching all corner cases is just what you do. All the time. Not something that a sane person wouldn't even attempt. Also, Optional&lt;T&gt; having 3 possible cases: T, empty() and null reminds me of one of my favorite dailywtf jokes: bool is defined to have 3 possible values: true, false and FileNotFound
It was more intended as a cheap shot, but I can't find any documentation of BoringSSLs behaviour wrt to forking. (and yes, it isn't eased by news about Googles new OpenSSL fork trashing the search results)
Thanks for the interest! There were a number of challenges: * Drawing speeds were a huge bottleneck for a long time. I initially thought that the game couldn't handle inputs faster than 30 FPS for a long time because changing brush sizes would often fail if I went faster. Turns out that the game can handle inputs as fast as 6ms EXCEPT when changing brush sizes. Thankfully, the program was never the bottleneck in drawing. * The brush size isn't one pixel. The smallest the brush size can be is a 12x12 circle. Luckily I was able to just treat the upper left corner of the circle as the pixel I'm keeping and override the rest with the next pixel draw. However, this does leave smears on the edges since we get the full shape of the brush on the last pixel. This is why the program centers the image and paints the edges with white. * Most input libraries only pass input events to the active window, but since my program controls another application, I couldn't receive inputs for things like pausing or configuring the application. I tried using glutin's DeviceEvents, but I still needed to instantiate a window in Windows which was a showstopper. That's what pushed me to write the device_query library and just query the inputs directly from the OS. Rust seemed like a good fit for a number of reasons. Since I wanted to draw as fast as possible, Rust's performance was a big draw. Also, I've always been a fan of strongly-typed languages and languages that support functional programming aspects.
I meant similar to *Python*'s. Thanks for letting me know!
The RNG state for `ThreadRng` is stored in a thread-local (basically a `static` that's unique for each thread). It's not reinitialized every time you call that function, only the first time. All that function amounts to is a single `Rc::clone()`. You can, of course, lift `rng` to a function higher in the call stack and pass it in by-reference. But unless you're sure it's bottlenecking on `thread_rng()` I really wouldn't worry about it.
Thanks for letting me know!
Thanks, fixed.
I love all the news coming out of TiDB these days. Great read. Hopefully this hits HN too.
Another great post /u/llogiq. You are on fire. I've added it to my collection of badass Rust writing.
Thanks for the kind words, and I can assure you that I am *not* on fire, though I may smolder a bit every now and then.
That last one is actually a thing in Java, through the boxed Boolean. It can be true, false or null. Because of automatic unboxing, this means execution of an if statement on a Boolean variable can result in a NullPointerException \^\^
True. But one would at least hope that someone returning an `Optional&lt;T&gt;` would never return `null`, as that invalidates the whole point. FWIW, SpotBugs (nee FindBugs, static analysis bug tool) will catch this. If I were running a Java project, I'd prefer to let SpotBugs fail my build rather than code around my `Optional&lt;T&gt;` being null.
Which c++ string split function does he refer to? I'm not aware of any in the standard library (though boost has some, and the ranges proposal too) 
Yes, Gecko currently is able to do this. Gecko+WebRender does it through a similar technique but does not reuse existing code.
Wasn't lifetime checking in Cyclone?
It's about time. All my 💖 💖 💖 s to the authors, and the authors of ring and rustls.
 C has the strtok function (https://msdn.microsoft.com/en-us/library/2c8d19sb.aspx) that destructively break a string into separate pieces, though it is rather unsafe and easy to mis-use.
Have a look at `std::rc::Weak`, it complements `Rc` to give you a non-owning reference to a value on the heap.
It's amazing how many people post to a sub without looking at it, first. You want /r/playrust.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://doc.rust-lang.org/std/rc/struct.Rc.html) - Previous text "Rc" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dwr9uyv) 
There's a mechanism which you could use for this: `Rc::downgrade` lets you turn an Rc into a `Weak` reference. `Weak` references will no longer grant you access once all strong references cease to exist (and the memory is deallocated). This solves all three of your reasons for not using Rc (but doesn't crash). If you actually do need it to crash, you can write a wrapper around `Rc` that supports the following operations: - Getting a `Weak` reference to the underlying data. - Getting a regular reference to the underlying data. - an implementation of `Drop` that hard-asserts that `Rc::weak_count == 0`.
You can create these types based on `Rc` in just a few lines. I took the liberty of doing so [here](https://play.rust-lang.org/?gist=ceefa2f08096985362130b9941670d1a). Does this implementation cover your requirements?
It doesn't look like `CreatedTask` needs a lifetime at all? It contains no references to anything that it doesn't own (at least, that's what it seems like, it owns the `aux_task` object).
Right, that's one part of the equation -- `CreatedTask` contains a handle to the `aux_task` object, so that the task can be scheduled, but it doesn't actually ensure that the `task` function pointer `(void*)` is valid for long enough to be called. Adding a `PhantomData&lt;'b&gt;` member to `CreatedTask`, and matching that to a mutable borrow of `task`, was my attempt to ensure that the `task` stays valid as long as `CreatedTask` is alive. It could totally be that I'm going about this all wrong. But the core concern here is making sure that the `task` passed into the `create_auxiliary_task` function is valid for at least as long as the handle to the resulting `aux_task` is around.
&gt; news about Googles new OpenSSL fork trashing the search results What now? Didn't hear about this one.
You can write the following: ``` pub fn create_auxiliary_task&lt;'a, A: 'a&gt;(task: &amp;mut A, priority: i32, name: &amp;'static str) -&gt; CreatedTask&lt;'a&gt; ``` Which says that the `A` object being referred to by `task` is what needs to have the same lifetime (or longer) as `CreatedTask`. This will guarantee that `A` doesn't go out of scope too early, but it won't guarantee that no one else borrows `A` (mutably or immutably) because the borrow itself will cease to exist immediately. This may or may not be what you want (I cannot tell from just this code).
&gt; One can call .cloned() to get Strings of the subslices. Easy and performant Unfortunately this example doesn't work: `str` isn't `Clone` and it's certainly not `.clone()`d to a `String`, https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.cloned. It would have to be something like `.map(|x| x.to_owned())` or `.map(str::to_owned)`. &gt; Worse, until a certain Java 1.7, the substrings reused the internal char array of the original String, which kept the reference alive even if just a small part of the substrings were used This isn't wildly dissimilar to what Rust does, with the main difference being the keep-the-parent-alive behaviour is static, not dynamic. &gt; StringRefs, and may use SmallVectors Neither of these are standard, and, neither is any `split` function: are you looking at LLVM's various `ADT/...` headers? C's `strtok` and the `find` methods can be used, but definitely not as nice as `.split("x")`.
Ah, `/usr/include` will likely be headers from any and every library installed on your system, not just the C++ standard library ones.
What's the work flow for developing and publishing rust applications on Fedora going to look like? For a simple rust binary, will it be different from making a tarball of the binary, writing an rpm that wraps downloading the binary, and deploying that rpm?
&gt; It's not reinitialized every time you call that function, only the first time True, but it does reseed itself every 32MiB of data and the reseeding uses the somewhat slow `EntropyRng`. If RNG really is a bottleneck, you can use a smaller, faster generator.
I realize that the Optional&lt;T&gt; being nullable issue is real, but I have never run into it. OR I did run into it once but that wasn't really the fundamental issue (there was a lot of garbage going on - if it hadn't been an NPE it would have been something else). It's bad and silly but not something I would concern myself with as a Java developer. The real issue with Optional, to me, is that it isn't a value type, so it is yet again another pointer chase. It's also not nearly as ergonomic as Enum's in rust, with pattern matching syntax. But overall these are not huge issues and I think it's a really solid pattern.
Right, but then the original asker should consider lifting their `rng` out of the hot function since every other RNG besides `SmallRng`/`XorShiftRng` seeds from `EntropyRng` on construction anyway. So it's more about picking the right RNG for the task and the asker didn't give enough context to make any recommendations.
Thanks for the reply! That almost works for me, but I want the program to crash right when the OwningRef goes out of scope (if there are any NonOwningRef out there).
How can I increase the lifetime of borrowed data? This is the error: error: borrowed data cannot be stored outside of its closure --&gt; src/main.rs:42:17 | 39 | let task = loop_interval | ---- ...so that variable is valid at time of its declaration 40 | .map_err(|err| Error::new(ErrorKind::Other,err)) 41 | .for_each(|_|{ | --- borrowed data cannot outlive this closure 42 | coupler.tick() | ^^^^^^^ ---- cannot infer an appropriate lifetime... | | | cannot be stored outside of its closure The total looks s.th. like this: let loop_interval = Timer::default().interval(Duration::from_millis(2000)); let task = loop_interval .map_err(|err| Error::new(ErrorKind::Other,err)) .for_each(|_|{ coupler.tick() }) .map_err(|_| Error::new(ErrorKind::Other,"uups")); }); core.run(task).unwrap(); The `tick` function looks like this: `tick(&amp;mut self) -&gt; impl Future&lt;Item=(),Error=()&gt;`
What about system queues, semaphores and shared memory?
I think it will! Thank you so much for helping me out with this. I'm trying to make it work with a struct on the inside and running into some problems (https://play.rust-lang.org/?gist=bf3884f95544340dd0ffcd0b41c5d1ad if you're curious) but I think if I hammer on it for a few hours I can make it work. Thanks again!
I do need it to crash, so that wrapper idea sounds like the way to go! I'm currently playing with thiez's attempt at the idea in the other reply. I think it might work!
There we go, got it to work with structs! https://play.rust-lang.org/?gist=305a18652f78ddae5ff42b105287c294&amp;version=stable
Cool project, did you sell any of the art that you printed? Btw, were you aware of the [AutoIt Rust bindings](https://github.com/bbigras/rs-autoit)?
Excellent, got it to work with a struct! https://play.rust-lang.org/?gist=f66d42b971f39be8a381f2fcb6ebbed4&amp;version=stable
If I understand your problem correctly, you should be able to use only (A)`Rc` (without Weak), using `try_unwrap` when deleting domains, to check whether there are still active references. As a sidenote; I'm also new to Rust, but I think it's generally encouraged to move `RefCell` inside your structs, where it actually becomes "interior mutability". In your case it means wrapping your `targets` and `subdomain` fields in `RefCell` individually. This way you also get to avoid the ugliness of `Rc&lt;RefCell&lt;T&gt;&gt;`.
I also can't think of when I'd want to return `&amp;String`. I'm more interested in `&amp;str` vs `String` vs `Cow&lt;str&gt;`: * `&amp;str` is simple and efficient (no copying or allocation). I'd definitely do this in an internal interface (you can always change it later). * `String` is simple and flexible - you don't have to guarantee you're returning something that will stick around. Maybe you later want to change the internal representation and will appreciate not having this constraints. * `Cow&lt;str&gt;` lets you do either, but it's more complex for the programmer and in terms of the amount of generated code. In a public interface, I'd probably still prefer `&amp;str`, but I'd at least think first about how likely I am to want to change my internal representation, how much pain a breaking change would be, and if I care about efficiency (if this is likely to be a hot path).
I have trouble seeing this as "an alternative to things like Futures". Unless you spawn thousands of threads that each do one very trivial thing, won't you want to use things like Futures to deal with the messages?
BoringSSL, but the articles from 2014 about "there's a new Google fork of OpenSSL" are still dominating the results.
Yea, AutoIt seems to be Windows only. Btw, if you create a real world picture printer (e.g. modifying a 3d printer to use pens or even brushes with oil paint), you could probably sell your art for real money in the real world as long as you don't tell anyone that it was printed. The algorithm could be changed to make it look more hand-drawn: http://genekogan.com/works/style-transfer/ https://medium.com/data-science-group-iitr/artistic-style-transfer-with-convolutional-neural-network-7ce2476039fd https://github.com/lengstrom/fast-style-transfer https://github.com/luanfujun/deep-photo-styletransfer The tech is there, someone just needs to combine style transfer with a real picture painter... E.g. you could start by printing popular memes in different styles and putting heavy wooden frames around them.
Ahhhh I parsed that incorrectly. You mean the search results for BoringSSL are poor, not an issue with the library itself.
Nice! Would be great to have something more complicated than integers though. I didn't know `cargo docs` was a thing. Always used `cargo doc` (no s).
great post thanks!
Correct me if I am wrong, but Rust was initially conceived as a message passing oriented system language inspired by languages like erlang and elixir. They eventually pivoted to a compiler oriented borrow-checker for reasons... that escape me now. Thanks for sharing your talk. :)
It sounds like `tick()` is borrowing from `coupler` and returning a live mutable borrow in that `impl Future`. However, `for_each()` requires a closure that don't return mutable borrows from captured state (and I'm not even sure how to describe a closure trait bound that would allow that). The simplest solution would probably be to use `RefCell` to wrap whatever internal mutable state that future needs and change `tick()` to take `&amp;self` and use `RefCell::borrow_mut()` inside that future. Either that or you would need to loop your stream code such that `tick()` takes `coupler` by-value and then returns it on the future's success and reuses it in the next iteration.
I'll have to take a look at this. This seems like a very interesting direction to take this and turn it into a real-world application!
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. 
Maybe you could use petgraph to model your problem? It deals with the problem of ownership quite elegantly.
Perhaps this one (all nodes are of the same type), but not the more general case where nodes can be of different types, and certain nodes can own certain kinds of other nodes. struct Game { levels: Vec&lt;OwningRef&lt;Level&gt;&gt; } struct Level { tunnels: Vec&lt;OwningRef&lt;Soldier&gt;&gt; } struct Soldier { level: NonOwningRef&lt;Level&gt;, targets: Vec&lt;NonOwningRef&lt;Soldier&gt;&gt; } I'll keep petgraph in mind for situations with uniformly-typed nodes though, thanks!
Yes! Completely agree. I am planning to do a fairly complicated example soon to showcase the real use case. You are right `cargo docs` is still not a thing. `rustup docs` is :)
Borrow checker is orthogonal. The reasons for removal are here: https://github.com/nox/rust-rfcs/blob/master/text/0230-remove-runtime.md
There are lots of tutorials online about building your own 3D printer or CNC cutter, and there are also bots to print [pancakes](http://www.pancakebot.com/) and [on eggs](https://www.jjrobots.com/product/sphere-o-bot/) (also an [open-source one](https://egg-bot.com/)). You could start by buying this [watercolor printing bot](https://watercolorbot.com/) and seeing how many artworks you can sell to people on the street. And then you can offer a [bot tattoo service](https://3dprint.com/104488/3d-printer-tattooing-machine/).
Yeah, that was it, when I disabled my adblocker it worked.
I've got a project which connects rocket on a back-end with a webview connecting to a front-end using Vue.js. I would love to put this together as a template. add in diesel, postgresql, and r2d would probably be useful as well. how can I find more info on cargo templates?
some of the most productive days I've ever had at work was when I *removed* code. Code that doesn't exist, doesn't have a bug in it.
Thanks for the kind words.
Thanks for letting me know. Will improve.
I've always used cookies for auth, also in SPAs, never had a problem with them.. Just curious, what was your reason for using JWT?
That was also my thinking. Why use `mpsc::channel` and not the futures mpsc channels and get the execution environment for free?
Would an `owned()` iterator be a possible fix for this? It's also not always clear when there's a missing `Copy` constraint and both `clone()` and `to_owned()` become essentially no-ops when applied to `&amp;T`. I don't have a specific example, but I've run into it a few times.
I gotta say, the Ditto crate is fascinating. I always viewed CRDTs as obscure hairy systems, not something you could just plug into something as a library. The in-order change sending seems a bit of a nasty constraint for p2p systems though...
Yes, and it requires more code without improving nullness checking over what SpotBugs already does. Yet another point where Java wins because of insanely great tooling.
A typical embedded implementation of a GSM modem might have 25 tasks and (the C version) has no issues running on a 66 MHz embedded CPU with 2MiB RAM.
&gt;I would still need to implement OwningRef, to automatically do that try_unwrap() when it goes out of scope, right? Yep! You probably also want that to avoid implicit `Copy`. The pattern is called "newtype" in Rust; wrapping some existing type to modify it's defined behavior. https://github.com/rust-unofficial/patterns/blob/master/patterns/newtype.md
What about them? This model needs only queues but I could see a task with multiple queues and an event group to mark which queue needs servicing.
Provide multiple process access?
&gt; The in-order change sending seems a bit of a nasty constraint for p2p systems though... Why do you say that? The ordering must be preserved only locally (per-site), not globally. So if a client does two edits, they must be sent in the proper order, but that doesn't sound like a particularly strict requirement.
Thanks Brian! It means a lot to us!
JWT is friendly for many-devices apps, cookies isn't well for mobile apps like JWT solution.
I make it , because I want use async stable rust, I had a project like you say: https://github.com/OUISRC/muro
I make it , because I want use async stable rust, I had a project like you say: https://github.com/OUISRC/muro
I'm just not seeing how you couldn't implement a custom executor for futures there? Like, I agree that a better abstraction of the "message passing" model is probably necessary, but futures work on a lower level then that.
See here for details: https://fedoraproject.org/wiki/Packaging:Rust Looks like a rust binary is being compiled, and deployed in an rpm. Personally, I've been doing something similar, sans the rust macros and dependencies, and using `cargo-vendor` to include compilation dependencies when building rpms.
Nice, lots of pain points getting addressed at the moment. The new convenience `fs::write/read/read_to_string` APIs are perfect for quick examples etc.
[I formatted the code if anyone else wants to take a look](https://play.rust-lang.org/?gist=a3c9f8fae1ab9f384d2551c14b54617b&amp;version=stable). What happens to `message` after the send future is spawned? It contains your only Sender after `run` finishes. If it's dropped, your Receiver closes. Does `println!("State Registered for client.");` execute before `println!("Receiver channel got closed.");`? Because I think your Sender get's dropped in the 'State registered for client' closure.
Since C11, it optionally (Appendix K) also has `strtok_s`, which at least is re-entrant.
Assuming these are simple static functions, the best solution is to use modules. mod foo { fn a(...) -&gt; ... {} fn b(...) -&gt; ... {} } mod bar { fn c(...) -&gt; ... {} fn d(...) -&gt; ... {} } You can then import the outer module and access the functions as `foo::a` or `bar::c`.
In that case, any language with an FFI, which is basically every language, is not memory safe, making the term worthless.
The team will open an RFC soon, in my understanding.
Can i also place variables in modules?
The blog post says April 20th but while most of the website says April 20 as well there is one bit that says April 15: &gt; The application period will begin on April 1st and will be open until April 15th. 
thanks for letting me know :) i've fixed it
You can have static immutable variables using the `static` keyword, but it's very uncommon for modules. These are more like python files for grouping methods. For a more direct analogy to classes, Rust has [structs](https://doc.rust-lang.org/book/second-edition/ch05-00-structs.html).
The problem is that a struct has a fixed amount of values. I would want to just be able to assign anything that i want and then access it
Mesalink is not quite a drop in replacement. Firstly there's only one .so file where OpenSSL has two. Secondly the header #defines all SSL_foo functions to something like mesalink_foo. This means all symbols are named differently in the resulting library meaning you have to recompile. Thirdly not all structs from OpenSSL are exposed. Sadly I don't think it's all that easy to replace openssl with mesalink. 
Then no Rust is a strongly typed language so you need to specify exactly what functions and variables will exist. You could "MAYBE" code something like that with macros but you won't be writing Rust at that point. 
Not just any language with an FFI. Any language that end up being executed on any kind of hardware. We should all revert to abstract mathematics on a piece of paper! 
This strategy already has a name. It is called: being a retard
Thanks for doing this! I wonder, where are you actually advertising this? I would expect that people that feel underrepresented in tech and for which that is a barrier to participate in certain communities might not be hackernews/reddit/... readers.
If the JSON has a fixed schema, try deserializing directly into Rust structs that model the schema. This should avoid construction of lots of `Value` objects, and help you processing afterwards. (Haven't used serde_json recently, but it might also be able to use `Cow`, to avoid creating lots of Strings pointing into the JSON data where there are no escapes in the string.)
Awesome!! That little easy trick with `RefCell` saved my day :) Thank you very much!
Just to be clear, you can assign any _local_ variable and access it. The issue is when you have shared state (variables) between functions. In this case I agree with Dynisious: the idiomatic solution is to put all the shared variables in a struct. It just means that you need to declare the variables upfront. Even in Python you do have a finite amount of variables: could you explain why you can't use a fixed amount of variables? (You wrote "values", but remember that struct can contain vectors, sets, maps, etc. so there's no real issue around the number of values). Are you using some sort of meta-programming in Python, dynamic accessors, reflection, monkey-patching, etc? These behavior are not possible in Rust: you can design your code to not need this (or ultimately resort to macros). 
Note that [clippy](https://github.com/rust-lang-nursery/rust-clippy) has a [lint](https://rust-lang-nursery.github.io/rust-clippy/master/index.html#redundant_field_names) for that. I might be worth running it to check for other suggestions.
I was thinking that you might get a panic if `coupler.tick()` doesn't complete before the next timeout as the `RefCell` will still be borrowed, but `.for_each()` guarantees in its documentation that it will wait for the previous future to return before calling the next one. 
That's very interesting, I'd not come across actix before. I think the main difference is that in the Actor model you might create a new Actor for, say, each new incoming connection. In the Task model used by Grease, the tasks are largely fixed at startup and each correspond to a layer in the protocol stack(s) you are implementing. One layer would handle multiple connections in the same task (i.e. thread) through the use of a `HashMap&lt;ConnectionId, State&gt;`.
I look forward to it! That's exactly the kind of discussion this project was intended to provoke :)
As this is an `Rc` rather than an `Arc`, you can just use the `weak_count` and `strong_count` methods before dropping an `Rc`: if the strong count is one and the weak count is more than zero, then you know the `Rc` is about to be dropped whilst there are outstanding weak references.
For a method that works for both `Rc` and `Arc`, you could downgrade it to a `Weak`, and then assert that the weak count is exactly one.
I think I found the issue. state type is future, while it was supposed to be Stream. 
Which individuals are underrepresented in Rust’s community?
Great!
You can use a Hashmap and that somehow reflects the way python objects act like dictionaries ... but i would highly recommend to not use this kind of "anti pattern" in Rust – we want to avoid week "stringly" typing but if you absolutely want to use something like this i would go that route https://play.rust-lang.org/?gist=880eab4ae2751d67e3de63cb00e9ac33&amp;version=stable
Seems to require Chromium: it doesn't work in Firefox.
I meant how a person should know if they are applicable for the program; some random blog post (by someone who has not had any contact with Rust's community by the looks of it) isn't necessarily reliable.
If you feel under-represented just apply. 
Not currently. I believe some coming, future changes to the borrow-checker will allow this, though.
Someone asked Alex about that. It's a coincidence.
The other way around for me :D it doesn't work in Chromium, seems to require Firefox (did work in firefox for me)
Maybe your ad blocker blocking wasm from github.io
Oh indeed, that was the culprit. I am using an ad blocker that has very few false positives (but some ads it doesn't detect) so I am not accustomed to question my ad blocker. Thank you!
The thing i was looking for is logical groups of stuff. I went the structs route
hey! as you might notice i didn't post the program here ;) i am doing a bunch of outreach to communities tend to have a larger number of generally underrepresented folks. if you have any suggestions feel free to share!
confirming what the previous comment said, we have a very wide understanding of what it means to be underrepresented in the Rust Community and tech in general. if you are interested and believe you have a unique perspective and experience, we'd like to hear from you! we were deliberately not specific because we'd rather people just apply :)
I think I now understand your use case better. In addition to the key-press event being _awaitable_, the coroutine that does the awaiting should also be able to _respond_ to the key-press by suppressing it. I hope it would be possible for a hypothetical `next_key_press` coroutine to return an awaitable object that must be called to finish the handling of the key-press: ``` while ... { let key_event = await!(next_key_press()); // (1) if should_suppress { // (2a) await!(key_event.suppress()); } else { // (2b) await!(key_event.propagate()); } // actually react to the event, by inserting stuff into the buffer or executing a command } ``` This would work because the stuff between (1) and (2a/b) is in fact running _inside_ the event handler (as far as GTK is concerned). But if the user forgets to await one of the suppress/propagate coroutine, the handler will exit only at the next call to a coroutine that suspends. I'm not sure if this is a problem in practice, but it doesn't smell right.
wrong rust board. this one is about the programming language
wrong rust: r/playrust
working on developing[A Web Server Unikernel](https://rajiv256.github.io/projects/ouros/). 
The message passing concept scales well when you expand to a distributed system. Performant single process message passing is useful on its own. Using the same semantics and being able to run many processes per server, across many hosts is tremendously valuable.
Chrome Canary worked for me. Very cool. Only 4fps though.
On an `Arc` you could use `assert!(arc.get_mut().is_some())`followed by dropping the `Arc`. Or `arc.downgrade().upgrade().is_none()` where the `downgrade()` drops the data if the reference is unique, making the `upgrade()` fail. `try_unwrap` is pretty close as well, it doesn't fail if there are outstanding `Weak` references, but will render them unusable (i.e. upgrading them will fail).
Yeah, generally you can't do that in strongly typed languages. Although you may be able to do what you want with a `HashMap`. Honestly, I can't even think of a situation even in Python where it would be more appropriate to use class members whose existence is conditional than a dict.
Oh! It sounded like they had to be preserved globally. That makes more sense then, thank you.
Nice. 45-60 fps in Firefox Developer Edition 60.0b8 for me, on an older MacBook Pro Retina (early 2013).
 From the device manual: &gt; "Currently, Yeelight WiFi LED is controlled through cloud. The command will be sent to a cloud server and then forwarded to the device." *Wait, what?* The future scares me.
Pretty cool idea. I can see how these could end up being used as cheat sheets for advanced topics, I like it.
Yeah, I felt the same when I read that line. You can enable LAN control though.
Nice! :) That's actually one aspect of this that I forgot: these basically function as pre-made lightning talks, which could be really useful for meetups, teaching, whatever!
&gt; This isn't wildly dissimilar to what Rust does, with the main difference being the keep-the-parent-alive behaviour is static, not dynamic. It's sort of similar and sort of not (if I'm understanding you right), in Java and in Rust the substring can't outlive the parent, but in Rust the lifetime of the parent doesn't expand when you take a substring from it, where in Java it did.
Yeah, I'm still waiting for signed packages too. https://github.com/rust-lang/cargo/issues/4768 appears to be the latest update. 
Of course. Though the "really insane" part may not fit the style of your blog post.
34-36 fps while moving in FireFox 59.0.2
Will it work with Xiaomi Yeelight Bedside Lamp?
Well, one thing for sure: furries are definitely not underrepresented in the Rust community. The Discord server is full of them. 
You say it’s good Haskell style to put comments specifying function types, but that’s not true. In Haskell, you often write a type signature such as `succ :: Int -&gt; Int`, which isn’t a comment.
`wasm2asm` has you covered https://github.com/WebAssembly/binaryen/blob/master/src/tools/wasm2asm.cpp Tl;DR, compile your wasm to asm.js, and then use it if you need to fallback.
There's no manual on how to run it so when I run your crate it says "No bulbs found." I don't know much about your Yeelight bulb, but my lamp doesn't support WiFi (only Bluetooth). Given that the cloud is involved, I guess my lamp needs a WiFi connection so your program won't work. I use it for my desktop. I use only orange colour because it works well with f.lux on my monitor (same colour spectrum in my room, easier for eyes).
If it doesn't support wifi, then it probably won't work. You need to enable LAN Control from the Yeelight mobile app first in any case though. Otherwise each request has to go to Xiaomi's servers before going to your device, and I can't send anything to their servers.
The futures library abstracts over streams, which have similar behaviour. A "mailbox" in the message-passing/actor abstraction is basically a bounded stream. While I totally agree that a proper message passing framework is useful, I just don't see it as an alternative of futures, they would be an implementation detail.
Isn't this how all Alexa enabled devices work?
&gt; ~~supoprt~~ supoprt FTFY. :) 
Sweet! This is exactly the sort of thing that takes so much friction out of maintaining ser/de needs...and `serde` was ALREADY good at doing that!
First, I'm not trying to write sophisticated code. I just want to understand what is going on here (or not going). I checked other questions but they had complicated situation and I think this situation is the simplest so far. So here is the situation. We have the following code let oneStep: f32 = "4.0".parse().unwrap(); let extraStep: u32 = oneStep as u32; println!("{:?}", extraStep); The way I see it, we have a str, we parse it to a float 32 and unwrap. Then we convert the f32 to a u32. Now why can't I just do this? Isn't this, practically, the same thing? let singleStep: u32 = "4.0".parse().unwrap() as u32; println!("{:?}", singleStep); If I try to run the code above, I get this error &gt; error[E0619]: the type of this value must be known in this context --&gt; src/main.rs:6:27 &gt; | &gt;6 | let singleStep: u32 = "4.0".parse().unwrap() as u32; &gt; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Looks like something requires us to break the operation into two chunks. ( This was posted to StackOverFlow: https://stackoverflow.com/questions/49656792/why-value-must-be-known-in-this-context )
How else will we make all these future visions from dystopian movies come true? (I wish people were working on the classic Star Trek future instead...)
This is awesome!
Would you count Universal Function Call Syntax as one of those ergonomic features?
Love the concept! (Only nit is that the name made me think it was _all_ of Rust in ten slides, which sounded gimmicky a la "Learn C++ in ten hours!". Not sure that really matters, and I might be the only one. But just a head-up from a messaging perspective.)
Thanks, both generally and for that point. Hm. :)
 s/strongly/statically
We stopped using that term because it's quite misleading, incidentally. "Fully qualified syntax" is what we decided on.
I will stop using it then. Thanks for the little nugget of information!
Any time! Names are hard. It took us forever to pick something...
Hopefully project Valhalla will find a way to make value types work in Java: http://openjdk.java.net/jeps/169 Java's Optional has been purposefully handicapped to (hopefully) make it future compatible with value types: it is not serializable because then it would have been serialized as a object.
The error is telling you that you're trying to borrow LINE as mutable, but it isn't declared as mutable. What you'd need to do in this case is either move away from global mutability, because in most cases there's a different and better approach than that, or, make LINE mutable by using something like a Mutex, then lock and mutate it wherever
But does it build with msvc 2015 on Win 8.1?
Is there a particular reason it wouldn’t? That’s a Tier 1 platform for Rust.
Literally 2 links up on today's /r/rust is [A Gentle Introduction to Rust](http://stevedonovan.github.io/rust-gentle-intro/readme.html). And a fitting section on [Object-Orientation in Rust](http://stevedonovan.github.io/rust-gentle-intro/object-orientation.html). Please do read. 
[removed]
Sounds similar to how LIFX the bulbs work. By Default things go through the cloud, allows integrations with thing like IFTT, Google Home, etc. They do have LAN control though and the spec is publicly documented. I used to have some LIFX bulbs and have considered doing something similar to this to learn Rust as well, but I don't currently have any bulbs.
Thanks for the tip. Alas, in this case, I am the user, and panicking is the best approach for my situation. But just out of curiosity, how do you envision working Result into this? I cant quite grok where I would put it.
For loops calling .into_iter() on whatever is given to them was one thing that tripped up a friend of mine for a little while.
But is it also a Tier 1 platform for binaryen?
It doesn't know what type you want to parse the string as initially. `str::parse()` has a type parameter that needs to be filled in, either explicitly or by inference, but the only type information you've given it is that you ultimately want a `u32`, but casts don't inform type inference because why cast if you have that type already?. It also can't infer the type from the string itself because that could be a runtime-dynamic value. This is the core limitation of a statically typed language. You can specify the intermediate type using the turbofish operator (`::&lt;&gt;`) so you don't need a separate `let` binding: let singleStep: u32 = "4.0".parse::&lt;f32&gt;().unwrap() as u32; This fills in the missing type information.
thanks for the answer! found the answer, but i want to know the part "move away from global mutability". how to avoid it? any links?
My current understanding about the `box` syntax is it hasn't been touched in a long time and to not expect it anytime soon. Whether it is just waiting on the backburner while more important issues get worked on or is just a pre-1.0 experiment that didn't work out for whatever reason is unclear to me.
The compiler typically does a good job of obfuscating the code, as the output is bare assembly. (in comparison to, say, Python) Beyond that, I don't see any value in a code obfuscator. If someone cares enough about your code to try to reverse engineer it, an obfuscator is not actually going to help. Even the most advanced DRM tools (which surely obfuscate the code too) [fail in dramatic fashion.](https://arstechnica.com/gaming/2017/10/denuvos-drm-ins-now-being-cracked-within-hours-of-release/) Focus on making a good product, don't focus on treating your users like criminals.
But the cheaters and pirates. No free lunch. ;)
yes, that's called the compiler. nothing else is worthwhile.
Is there an easy way to clear the Windows console window? I've tried the code below but if fails on \- thread 'main' panicked at 'called \`Result::unwrap\(\)\` on an \`Err\` value: Os { code: 2, kind: NotFound, message: "The system cannot find the file specified." }'. if std::process::Command::new("cls").status().unwrap().success() { println!("screen successfully cleared"); }
Just to support this -- even a `Hashmap` won't act like a python object -- all `Hashmap` members need to have the same type. You can get around this by having that type be an enum of a bunch of different types, or using trait objects, but it's going to be a pain in the ass compared to just doing the straightforward `struct`s solution.
Would this work in stable rustc now? [https://github.com/obfuscator-llvm/obfuscator](Obfuscator-LLVM) :)
Anything that processes lots of data in repetitive ways. I want it for image processing for example.
Yes, I completely agree. I just had a desire to voice what I love about rust: That it replaces your "yeah that could happen but it's not a real issue (except when it is)" into "that is not possible (unless some unsafe block went bad ;) )"
Image processing, physics, linear algebra, etc.
Parser probably not. The data being worked with is very linear and it doesn't lend well to parallelization.
&gt; basically some bitwise operations on each pixel It's not usually bitwise operations but normal math. But you got the gist of it. Here's the loop that does levels and white balance in my raw pipeline: https://github.com/pedrocr/rawloader/blob/116208687231a1e9ff542d27fd5c7b2a053dcd29/src/imageops/ops/level.rs#L56-L63 &gt;What about other types of data though. Like, if I wanted to build a json parser, where the data is less structured and has more semantic meaning - not just a friendly matrix of bits - would that still work well? All kinds of data are fine but usually you want stuff where there isn't much need to branch. You want data that you can stream through applying the same calculation over and over. Parsers are not usually good for that. There's a lot of branching going on. I do TIFF/CIFF parsing in rawloader and for that SIMD is not usually much of a gain.
I've never written explicit SIMD code either, so this could all be wrong, but my understanding is it's most useful when you're doing a repetitive but simple action (i.e. not branching) over a large set of data. So while image processing is a great example (apply operation Foo to every pixel), JSON parsing probably wouldn't be, as there's a lot more ifs and branching and different structures and such. However, what might be a good fit is string searching, where you're looking for certain characters in a really really long string. I believe that's how functions like [memchr](http://man7.org/linux/man-pages/man3/memchr.3.html) are implemented.
I assume it'll be left in the compiler, unstable, waiting for a new revision of the semantics (and possibly syntax of) `placement-new`. We'll need to have this eventually, but the current implementation suffers from problems as mentioned in the PR. It's my understanding that `box` is going to still exist in whatever future proposal happens, and will be re-implemented in terms of that proposal's traits/functionality, but it won't be stable until that happens.
So I'm new to Rust, trying to get up to speed. I'm slowing wrapping my head around Option and Result, and everything I read says "Don't use unwrap and expect, write proper error handling with match/if let and use it"...if that's the case, why does every example I see use unwrap and expect? It seems really counter intuitive to have a construct in the language you're discouraged from using, and then to have every tutorial available, even from the Rust team, use that constructor heavily rather than showing the correct way to do things.
Why can't it be simply merged in the most basic form (i.e. as a shorter Box::new and for pattern matching)? 
Code obfuscation isn't really worth it for a language that compiles to machine code. Unless you're targeting a very specific person who is good enough to attack raw machine code without debugging symbols but only barely, and they can't just throw it at someone else online who's more skilled, it's just another avenue for hard-to-debug bugs to creep into your release builds. Even the stuff developed by career DRM developers, that AAA companies pay a fortune for, like Denuvo, isn't enough.
Pass things around in arguments and struct members.
How would you convince huge sceptic of all altcoins except Monero, Grin and maybe Litecoin?
I used SIMD &amp; OpenMP for metaballs: https://github.com/serprex/Metaballs/blob/master/meta.c
Because stabilizing `box` syntax means prescribing it to the spec for essentially forever. The semantics chosen by a future accepted placement new may require changes to the current `box` feature.
Stable 60fps @ Firefox 59.0 / FreeBSD 12-CURRENT / Mesa 18.1.0-devel / AMD Radeon RX 480
\*nod\* As I understand it, it's common practice now for servers of multiplayer games to use tricks like doing visibility testing before sending clients data to to beat x-ray vision cheats and verifying the plausibility of what the client sends back to mitigate cheats that substitute for player skill. (Because even the AAA publishers with the budget to buy any protection solution they want are getting hit by cheats.) As for piracy, I do wish more people were as principled as I am. If I can't get something DRM-free, I don't pirate it, I just play one of the other games I own (1200+ on GOG.com alone) and know that I've done my part to penalize the company's choice to use DRM in a completely ethical and moral way.
`cls` is a `cmd` interpreter command to clear the console window. In C++ you'd issue it with the `system()` function but here you probably have to explicitly call `cmd` with `cls` as the argument: std::process::Command::new("cmd.exe").arg("/C cls") However, if you're talking about an up-to-date Windows 10 console window, you can actually control it with [ANSI escape sequences](https://en.wikipedia.org/wiki/ANSI_escape_code) now: // ESC [2J clears the entire window println!("\27[2J"); // println! so it flushes
SIMD can help parsers quite a bit. Parsers may do bulky look aheads (eg is the next word “func”) and can so benefit by multiple comparison instructions that SIMD provides to eg compare a pair of four-byte strings in a single clock cycle. Intel has a full white paper on using SIMD to accelerate XML parsing: https://software.intel.com/en-us/articles/xml-parsing-accelerator-with-intel-streaming-simd-extensions-4-intel-sse4
DRM and client-side anti-cheat measures are usually more inconvenient and intrusive to paying customers than they are to pirates and cheaters. E.g., Denuvo, VMProtect, all the problems with Punkbuster, Blizzard's anti-cheat spying on players, etc.
They're not *evil*, their usage is just discouraged in production code because robust programs should try to recover from errors whenever possible. `.unwrap()` and `.expect()` (I prefer the latter as you can grep for the error message when you don't have a backtrace), and panicking in general, should be reserved for exceptional error conditions or ones which wholly prevent the program from continuing.
Do you have iterators or loops on collections in your code? Decent chance SIMD can speed something up in that code.
Wow, that was fast.
I was wondering how Rust can be taught in only 10 slides. They must be huge slides! It's actually: Rust Concepts in 10 slides per concept. This approach splits the language into discrete pieces, each piece being defined as whatever can be illustrated in no more than 10 slides. I don't know whether or not this is the best way to approach the language but it certainly makes it seem approachable, and one more learning tool is always good so... cool!
I'm focus on a good product but cheaters ruled experience for legitimate peers. 
Audio processing is another one.
That's compile time? if so big.
SIMD is most naturally suited to scenarios with low control-flow divergence, though it can be suited to cases where you can convert those to short parallel data dependencies. It is (unfortunately) naturally averse to data with "less structure" and "more semantic meaning", so you tend to only get it either in reductive cases (eg. simple loops) or when you have planned in advance to accommodate for it. A typical use is in mathematically heavy code, but it is also important in accelerating common language features like `memcpy` and is used frequently in game programming where appropriate strategies (eg. "data-oriented design") allow you to bulk process large quantities of entities very quickly.
That only works if you know there's only ever going to be one strong reference - if you don't know that it's impossible to do for `Arc` non-racily.
&gt; String search isn't the traditional use of SIMD, but more and more people are using it to speed up search. Yeah, to be honest it's part of why I'm asking this question. I can understand simd for math / image processing, that's always what I've thought of it for. But then you were using it to optimize regex... and I had never considered that. So I'm sort of wondering what I've done that might benefit from it.
when you sell copies of the game, each copy goes to a unique account, right? The only way to get that account is for them to pay for the game. If you identify someone is cheating, you ban their account, and they can't play multiplayer anymore. If they want to keep cheating on multiplayer, they have to pay full price for another copy of the game. I don't see how that would turn into a big problem that would ruin the experience for legitimate players.
I use simd for alphablending pixels with background. So Red Green Blue are processed in one step. There are a lot of use cases for simd. You will eventually find a use case while you are coding. ;) 
[Well…](https://github.com/rust-lang/rfcs/pull/1199#issuecomment-141535962)
Multiplying matrices is a very common usage.
I never have. But I don't do things like image processing, or linalg, etc.
Oh, yeah, I have been waiting on SIMD for a while now (in Rust terms at least), but in terms of actually having this library in `std` we seem to have zoomed through.
yeah, we need more easy examples/documents for that.
Yes, it compiles into the correct sequence of Vec::push and BTreeMap::insert calls, with no TOML parsing happening at runtime. That also means you can interpolate variables much like with the `json!` macro. let p = "toml"; let cargo_toml = toml! { [package] name = p }; 
I don't think these names have any specific meaning in Rust. In C they are reserved for use by the compiler and standard libraries. Some Rust crates might expose C symbols that use those reserved names.
whoa
And, as I mentioned in one of my other replies, I think that DRM has a terrible ROI (return on investment) and you'd be better off focusing on content and value-adds which inherently depend on per-purchaser accounts that can be banned for cheating or excessive account-sharing.
Well it's never to late for some nifty image processing :) I am also not an image processing guy. While I was working on my game there was this annoying piece of code having this stupid code repetition.. Like calc red, calc green, then calc blue and all with the same parameters. It was screaming for SIMD usage. In fact compilers nowerdays can detect code like that and optimize it with simd if the right compiler optimization is configured. If you have written some rust or c++ code chances are not so little that you actually have used some simd implicitly. ;) 
It does.;) How do you detected them?
RFC, PR, doc, etc. :)
Here is an example where it is used: https://doc.rust-lang.org/std/fs/struct.DirBuilder.html fn fmt(&amp;self, __arg_0: &amp;mut Formatter) -&gt; Result Seeing as I see it in the standard library quite regularly, and have memory of someone defining its semantic meaning (even if only by convention), I imagine it must be signifying some communication rather than just being a syntactic idiosyncrasy. 
&gt;And, as I mentioned in one of my other replies, I think that DRM has a terrible ROI (return on investment). You'd be better off focusing your time and effort on content and value-adds which inherently depend on per-purchaser accounts that can be banned for cheating or excessive account-sharing. Now code obfuscation isn't DRM and it can be automated. onions.
I've done about 122 hours of the handmade hero project in rust. And ive used rust more generally off and on since rust 1.15. I still don't feel too confident with most advanced rust shenanigans.
when players report them and you review the gameplay recordings
In addition to what /u/Furyhunter said, because it doesn't currently work right. I mean, the reasons for removing placement in still apply to `box`, and it is not currently useful as a placement feature because it can be buggy in debug mode and could cause stack overflows where people are relying on that not happening. I mean, it's not ready.
This module is a little weird regarding docs; basically it's a direct export of these instructions, so the real docs, in a sense, are the Intel manual. Most people will not ever use these things directly, instead using `std::simd` or stuff like the `faster` crate; that doesn't mean that this module deserves *zero* docs, but most of the people who are using it already know what's going on.
It might, but I don't think 'copying move of return value optimizations' to the front end is at all trivial. If someone writes an RFC describing the exact process, how we'd integrate it, and then also writes a PR to rustc doing that, then that could work. It's my understanding that rust could definitely come up with a good solution, but no one's written it yet, and it's very low on the priority list for Cole rust team members compared to everything else happening.
I came across this summary of a paper earlier this year you might find interesting https://blog.acolyer.org/2018/01/18/rustbelt-securing-the-foundations-of-the-rust-programming-language/
mmm, manpower?
I think its important to use crates from crates.io and get to know the crate ecosystem. Knowing Rust is much more about knowing what tools are out there. Don't forget there are also traits from some libraries like serde which are accepted as the de facto way to implement certain things like serialization.
there's no way to cheat here. DRM, obfuscation, etc... *they have no impact.* Remove them from your calculations entirely. Since those have no effect whatsoever, what options do you have? if you think manpower is the answer, you'd be right, but it's possible to empower the users so that you don't have to make these decisions. Reddit employs very few people, but look at all these volunteer mods!
If you're iterating on a vector of numbers, performing some mathematical operation on each value, you could probably benefit from simd.
&gt; And manpower isn't the only answer. You can write a server side program that monitors for impossible levels of accuracy or other things and eventually bans a person if they continue to exhibit this impossibly good behavior. Anti-cheat software like VAC? 
Cool, yeah, this is basically what I was thinking - string search is a component of parsing, so simd could make sense there. But for like smaller portions, with branches in between.
Cool. This makes sense and fits my conception of SIMD. Thank you.
I would like to plan for it. :)
I don't know what that means.
Security come in layers like onion. ;)
That's called defense in depth, and obfuscation does not help you. It hurts you and your users. Stop considering it even a minor positive, because it isn't.
Seems to be an artifact of how `#[derive(Debug)]` is implementing `Debug`. It looks like an automatically generated name for the 0th argument, and that makes sense, given that it appears in a method generated from `derive`. I doubt it has any meaning other than being a name which is guaranteed not to conflict with any other argument names.
(Slight note, Isis goes by the pronoun "they", not "she")
&gt; and I can't send anything to their servers. Which is great. I would like to experiment this. Good work Anything to work with their WiFi camera would be very interesting.
It's often used to indicate: - "hidden" fields that have to be public that you're not supposed to use. Usually you'll see stuff like `#[doc(hidden)] pub __dont_use_this,` - stuff in macro expansions to avoid clashes where hygiene doesn't fix the problem It's worth noting that clippy has an off-by-default lint that lints for `_foo` where the variable is actually used, but it won't lint for `__foo`, so in some cases this is a way to say "Ignore both the lint for unused and the lint for underscore-things-which-are-actually-used"
[removed]
The double underscore there is [my fault](https://github.com/rust-lang/rust/pull/32251#issuecomment-197481726). We could also have derive generate single underscores (clippy doesn't lint this on derive expansions anymore anyway) or have `unused_variable` ignore `derive`. I kinda like that solution, really.
thank you...
[Fast JSON parsing using SIMD](https://github.com/pikkr/pikkr/blob/master/README.md)
This is for numerical code. Any time you want to, say, do a multiplication on each of an array of values, SIMD instructions lets you do it 2,4 or even 8 values at a time, instead of just one. The number depends on the specific hardware and the size of your data type. With that said, memory access is a real limitation. High-performance code today is largely a fight to keep the CPU core with data to work on (that's why the recent Spectre vulnerabilities is such a big deal for performance). If you do 4 multiplications in parallel, you'd need to grab data from memory at 4x the speed. Which is in general difficult to impossible. You need to make sure the CPU will pre-cache your data in CPU caches, and even then it may not be able to keep up. The compiler needs to be clever enough to interleave these SIMD instructions with other useful work that doesn't need fresh memory loads, giving the memory system time to keep up. 
There's some documentation on [`std::arch`](https://doc.rust-lang.org/nightly/std/arch/), and the specific instrinsics offered by the submodules are matched to the vendor, meaning tools like [the Intel Intrinsics Guide](https://software.intel.com/sites/landingpage/IntrinsicsGuide/) can be used to work out what a given thing does (and also find out what one can use for a given task).
My mistake, I was honestly not sure and simply tried my best, however I will remember from now on to use 'they'. 
Very nice! A small edit instead of reference there is ‘referemce’ 
I'm working on a PR that will allow out-of-order sending in all cases. Basically, if it receives an element deletion before an element insertion, it will cache the deletion until the insertion is received. That should take care of all the user edge cases.
[removed]
in language level, i will be happy if rust supports all these situation with provide generic method.
I'm not sure I understand the code because of the bad formatting, but I don't think that would work either. Remember that GTK actually manages the buffer, so this is out of my control.
no mistake, floating point math just is not very accurate. you will not get exact results with floating point calculations. if you actually need perfectly accurate (and not just reproduceable) results you can use fixed point or rational numbers or move to interger calculation. even then accuracy will be limited by how many bits you use for the number.
"Is feature $X of language $Y broken?" Try it in another language. Python 3.5.1 (v3.5.1:37a07cee5969, Dec 6 2015, 01:54:25) [MSC v.1900 64 bit (AMD64)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; "%.30f" % (10.0 ** -1.0) '0.100000000000000005551115123126' No, it's not Rust, it's floating point.
Anywhere you do `"".to_string()`, it can be replaced with `String::new()` for clarity, but they do the same thing. Empty `String`s don't allocate. You also don't need it in `format!()` or `println!()` invocations; they work fine with borrowed strings. You don't need `.to_string()` [here](https://github.com/andreicristianpetcu/maven_sidekick/blob/0d66cd9e96e8f2003727c902f6f5c1756eb8ece0/mvns.rs#L54), as `name` is already a `String`, or on [any of these lines](https://github.com/andreicristianpetcu/maven_sidekick/blob/0d66cd9e96e8f2003727c902f6f5c1756eb8ece0/mvns.rs#L67-L74) as `data` is already a `String`. On [these lines](https://github.com/andreicristianpetcu/maven_sidekick/blob/0d66cd9e96e8f2003727c902f6f5c1756eb8ece0/mvns.rs#L107-L109) you can deduplicate `entry_path.to_str().unwrap()` into a single `let` binding. With those taken out it should look a lot cleaner
I wonder how much that could help out the parsing in the Ion shell. Particularly statement parsing.
In addition to what DroidLogician said, you can [clear the console via the Win32 API](https://support.microsoft.com/en-us/help/99261/how-to-performing-clear-screen-cls-in-a-console-application)... though it's just a *little* more involved...
There is no one stop fix to avoid global mutability. Context is necessary.
I really like the handmade hero video where he switches the pixel pushing to use simd 
Totally depends on the player. I, with 228 hrs managed to stay pretty much even with a guy I met in rusty tags who had +8,000 hrs.
Isn't that a plural word, though? It's grammatically incorrect to use it to refer to an individual. Seems wrong.
That's some good shit right there 
It's not. https://en.m.wikipedia.org/wiki/Singular_they
Non-Mobile link: https://en.wikipedia.org/wiki/Singular_they *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^167905
**Singular they** Singular they is the use in English of the pronoun they or its inflected or derivative forms, them, their, theirs, and themselves (or themself), as an epicene (gender-neutral) singular pronoun. It typically occurs with an antecedent of indeterminate gender, as in sentences such as: "Somebody left their umbrella in the office. Would they please collect it?" "The patient should be told at the outset how much they will be required to pay." "But a journalist should not be forced to reveal their sources." The singular they had emerged by the 14th century. Though it is commonly employed in everyday English, it has been the target of criticism since the late 19th century. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; Isn't that a plural word, though? No. https://en.wikipedia.org/wiki/Singular_they "Somebody left their umbrella in the office. Would they please collect it?"
Firstly: no, not really. \[Use of the singular they goes back to the 14th century\]\([https://en.wikipedia.org/wiki/Singular\_they](https://en.wikipedia.org/wiki/Singular_they)\) and can be seen in the writings of, among others, Shakespeare, Jane Austen, and Charles Dickens. Secondly: there is no central arbiter that decides what is and isn't correct in English like there is in, say, French. "Correct English" is just the English we all use; nothing more and nothing less. And it changes over time: "you" used to only be used for the plural \("thou" was singular\), but its usage and meaning changed organically over time, and now nobody thinks twice about it \(even though it still takes plural agreement: "you are" instead of "you is"\). So even if singular they \*weren't\* already standard \(which it is\), there's no reason we couldn't just collectively decide it was, especially if it's more inclusive.
I see what you did there.
I'm not sure that this is a meaningful question. I probably know Rust better than any other language at this point (and can't even begin to give a number-of-hours estimate), but what does it mean to master it? It's just a language. If you can read and write it, you're fluent, and everything after that is domain specialization...
Why? Nobody ever got good at mathematics by memorizing textbooks.
What is the stabilization process? Reading the release notes I see a lot of different standard library APIs and even language features (e.g. underscore lifetimes). How does an API become stable? And when should I use unstable features?
Thanks for sharing this! I've recently been trying to grok `nom` to implement a basic parser and I found the dedicated chapter introduced it very well. I liked how it gradually introduced more combinators and demonstrated their utility, rather than simply listing all available ones and terse description as the `nom` documentation has it.
I think you might be in the wrong subreddit. /r/playrust is the subreddit for the game.
This is more general concept in programming. I believe you can already find tons of resources on this. E.g. "Uncle Bob" published some books and videos on architecting software in general. I highly recommend Clean Architecture.
I just discovered into_iter. Whenever I needed to take ownership I had to write a for loop. 
I'm sure it is as meaningful as asking how many hours it takes to learn a language like Spanish. I suppose this may not be very meaningful as well given that there are individual differences such as the languages they are already fluent in, their individual learning speed for such things, and so on, coupled with the ambiguity of what it means to really know a language. I've heard commonly that Rust has what would properly be called a shallow learning curve by education theorists, this being a function of time and knowledge of the whole accumulated. It is hard to even know what the whole would be in terms of Rust, seeing as it spans into areas including nontechnical folklore even. So I do understand why you think the question isn't meaningful, but ultimately I suppose I should ask how difficult is Rust considered to be to learn or how does its learning curve appear to be as compared to other languages, or with any variants taken into consideration such as starting languages for an individual to know, essentially I would like a discussion that characterizes Rust in terms of its difficulty to learn to varying degrees, and what those varying degrees consist of, things like this. 
My 2011 MPB gets &lt; 5 fps, using the latest FF stable (59)
With other languages I've taken a more hands on approach to learning them. For example, I read very little material on the C language as compared to the amount of time I spent implementing things in it, though I did read specific things as I needed them, as well as did read over long periods of time probably a total of two complete books on the C programming language as well as a couple of specialized security books regarding how to write secure C (which consisted primarily of dozens upon dozens of rules and guidelines described in varying ways). With Rust, I've decided to learn things more thoroughly prior to implementing much. Although I have implemented a few things in Rust, including a Socks 5 client multiple times as my skills progressed, and a few other little things (all of which I need to redo anyway), I have focused predominantly on memorizing the language thoroughly and holistically rather than on actually implementing things in it. This has some trade offs of course, however I've found this style of learning to be good for Rust due to the enormity of it (though of course I know of no book of dozens upon dozens of rules that must be adhered to when using Rust in order to avoid security catastrophes, rather a book of similar size for passing static analysis and being able to compile!). One advantage is certainly that when I do start writing code, it will be high quality and make use of the language in succinct and skillful ways, that I would not know of had I spent less time mastering Rust and therefore ended up implementing things that would need to be redone in short order as my skills progressed as I implemented things. I would rather progress to having the skill in Rust that I had in C prior to coming to it, rather than getting there via working through poor implementations that will simply need to be done over, I would rather learn how to use the language as properly as possible prior to implementing things in it and learning in a more hands on fashion as I had done with other languages. 
Would you mind to test this demo : https://edwin0cheng.github.io/unrust/demo/postprocessing/ And tell me whats ur fps ?
They probably meant “cool rust team” ;)
&gt;I've heard commonly that Rust has what would properly be called a shallow learning curve by education theorists I've never heard this anywhere, nor would I agree with it.
0. Design your data flow in a way that's amenable to batch array processing, because otherwise there's not going to be a "hotspot" to optimize later on.
Thank you for the info, so there's a ported Rust compiler. So either one runs it directly on the target device - will not happen - or setup an Android Emulator environment, import the sources from PC and build there.
There's not really any significant character count limit for posts on reddit. Feel free to use entire sentences to express details regarding your needs and any complex software development project questions you might have.
Obviously singular they is associated with essentially a political movement, particularly when used to describe a known individual. This is certainly considered to be incorrect usage of the language by the majority of people classified as professional linguists, however I see this ability to use genderless singulars as being an evolution of the language and a useful feature that I would not want to be without simply due to it being traditionally incorrect. I personally have no problems with the more liberal associated political movement toward gender equality, though am more socially libertarian oriented myself, but I see the matter linguistically as just being an appropriate evolution of the English language (which I am quite proficient in with it being my native tongue and my verbal IQ being quite high, I mean I simply linguistically recognize that traditional English is flawed as a language, while simultaneously recognizing that singular they is indeed incorrect in the confines of traditional English) . 
I expect that this initiative will encounter some derision, but I'm genuinely hopeful that the Rust community can show open source communities that it's possible to foster a safe and welcoming environment
Yeah, I can see why there is a pattern of choosing cloud by default. It makes integration with other services trivial, which otherwise could be very hard to correctly implement. (Along with taking each bit of our data, of course)
futures + tokio for async, num for number generics, rayon for parallel iteration rand for random numbers failure for error handling...
Be that as it may it is still the general theme of the wikipedia article on the matter that it has been considered largely as incorrect since at least the English that was taught to recent generations as being formally proper, albeit with some disagreeing with the alleged impropriety. My impression after having read up on the matter was that although English is superior to use singular they, it is traditionally incorrect to use singular they, defining traditional English as what has been taught to the prior several generations with few exceptions and recognized by the majority of language formalists. 
In that case, I'll probably paraphrase.
Congrats for being the only one who answers the question. 
Personally, I think that mastering Rust doesn't take that many hours. The real challenge is what follows: mastering a wide array of software techniques and architectures that result thereof, or are merely an artifact common of programming general. Building bigger and better systems, writing closer to the metal, trying out different approaches. It's less about mastering Rust at that point, and more about mastering software designs, and specific fields. I've lost count of how many hours I've spent with Rust over the last three years. That Rust knowledge has been applicable in pretty much every programming language. Although we still build software very differently from how others do it in their languages. You can't expect C library authors to make extensive use of generics and tagged unions, for example. There's much to be said about having a core and standard library that offers updated language concepts, and makes it easy to use them. But if I had to put a number on it, I'd say maybe ~4 months to a year. I feel that days are likely a better measure instead of hours, since you can spend hours staring at a screen and not getting anywhere. Proper rest &amp; energy is required to absorb information, and there's only so much that the human brain can retain at a given time. Actually, it's even been proven that if you balance your day by getting a decent amount of physical exercise in, instead of studying the whole day, you'll likely make more daily progress than had you spent the whole day staring at the screen.
Does this explain it? https://doc.rust-lang.org/nightly/std/arch/ "The arch module is intended to be a low-level implementation detail for higher-level APIs. Using it correctly can be quite tricky as you need to ensure at least a few guarantees are upheld: The correct architecture's module is used. For example the arm module isn't available on the x86_64-unknown-linux-gnu target. This is typically done by ensuring that #[cfg] is used appropriately when using this module. The CPU the program is currently running on supports the function being called. For example it is unsafe to call an AVX2 function on a CPU that doesn't actually support AVX2."
Already this thread is severely off topic, and I'm totally okay with this and request that by all means it is not locked despite this conversation. I think this conversation is good for us to have, and particularly for people foreign to our culture to observe and understand. I am not trying to twist reality, I am simply explaining to you my understanding of reality. Perhaps my understanding of reality is wrong, I have not done an immediate assessment of my understanding of reality, but only because it was only several weeks ago or so that I read up on the debate regarding singular they. As I said, I have nothing against the political movement that is undeniably associated with the singular use of they, although I don't consider myself to particularly be a part of it insofar as it is largely liberal whereas I am more so libertarian. My understanding of this matter is essentially that it was taught to at least my parents generation (who are just entering their sixties), that masculine pronouns were to be used for gender neutral words. This is silly to my ear and eye, and colloquially we commonly use singular they as a gender neutral word, but in formal guidelines of English, particularly American English, it is generally regarded as incorrect at worst and controversial by essentially any account. However, this is politically and personally offensive to some people, particularly but by no means exclusively people of a more liberal and feminist leaning background that is both very accepting of and integrated with the LGBT movement as well as against what they characterize as patriarchal language. Personally, I simply feel that singular they is a useful construct in English, and therefore I fully endorse its use in the language even separate from the politics surrounding the matter, because I think it improves a language to have a gender neutral word like this and I would not want to confine myself to a specific variant of English that considers this incorrect, when I could instead use a new variant of English that I find superior. But please let us not be disingenuous with ourselves and imagine that this is not a political issue that is playing out, where each side has some correctness and it is to some extent a personal matter that could cause hurt feelings and so on, because that is what this is and there is no need for us to be worked up about things and to argue when we can come into what is actual reality together instead of imagining we are in actual reality incorrectly. 
You’re the one spilling ink on it.
I am giving a correct and neutral contextualization of what is happening here to people who may not otherwise be familiar with the matter, but certainly people can read the entirety of the wikipedia page on singular they if they so desire, and realize that in this thread an extension of this version of singular they covered by wikipedia is being discussed, with some people vehemently insisting this is what would be regarded as traditionally correct English by correctly pointing out that singular they in some forms have been used by a select few erudite linguists in the history of the language, but they are ignoring the section of English that I label as traditional English is a taxonomically distinct variant of English that does consider singular they in any form to be incorrect. 
Holy run on sentence, Batman! Why does it even bother you?
No, that's the job of a higher level crate. If using `std::arch` directly, you'll need to do runtime feature detection yourself, or it'll fail.
I was wondering whether it would be possible to use SIMD to build a fast router (for matching http routes with functions). Perhaps using a macro to build up something "optimal". Course, 'cos I don't know SIMD or macros yet it remains just an idea at the back of my head.
Unfortunately things like gender pro nouns and the Rust community mix like petrol and fire. 
Complexity always has a cost and obfuscation works by adding complexity to make the release artifacts harder to comprehend.
There are a number of academic papers on arxiv and elsewhere along the lines of "We used Rust for X", and they usually include some comments on the good, bad and ugly. Random selection: [Rust as a Language for High Performance GC Implementation](http://users.cecs.anu.edu.au/~steveb/downloads/pdf/rust-ismm-2016.pdf) [What can the programming language Rust do for astrophysics?](https://arxiv.org/pdf/1702.02951.pdf) [Rust-Bio—a fast and safe bioinformatics library](https://arxiv.org/pdf/1509.02796.pdf) [The Case for Writing a Kernel in Rust](https://www.cs.virginia.edu/~bjc8c/papers/levy17rustkernel.pdf) [System Programming in Rust: Beyond Safety](http://soarlab.org/publications/hotos2017-bbbprr.pdf) [Sandcrust: Automatic Sandboxing of Unsafe Components in Rust](https://os.inf.tu-dresden.de/papers_ps/plos2017-lamowski-rust-sandboxing-paper.pdf)
That said, if you want to reduce the chance of people complaining about "they", look for ways to rephrase sentences to avoid using "they" as a "concrete singular" pronoun. "They" as an "abstract" or "collective" has been well accepted for ages, but "they" as a concrete singular still "feels wrong" to a lot of native English speakers when they hear it. That's why, if you find the word "themself" in a dictionary, it's likely to be one of the words they consider "documenting actively used but incorrect English in the wild". * **Collective:** I talked to the petitioners. They are not happy. * **Abstract:** A lone petitioner came to me one morning. They were not happy. * **Concrete:** I was talking to Dr. White this morning and they told a funny joke.
Post a link to a valgrind log paste. A random thought would be that valgrind is confused by musl, especially when statically linked. Instead of seeing familiar dynamic calls to glibc malloc/free, it just sees your application mmapping allocation arenas directly. These arenas handle many allocations, and are not freed immediately. A quick google shows that others have also experienced valgrind oddities with musl, but I don't know if that's still the case. One random github issue stated that valgrind sorta worked with a dynamically linked musl, but complained about invalid use of malloc/calloc/realloc/free/..., while statically linked musl didn't work at all with valgrind.
[removed]
Anyone who has publicly criticized/dismissed Rust has been subjected to quite a lot of vitriol. Theo de Randt, Richard Hipp and probably others. Anyone who is willing to do so under his real name is naive in it being worth the pain or enjoys it. Your barrier to entry to this discussion is poorly thought out.
&gt; not European Liberal which is libertarian in U.S.A. wat I don't know what your definition of libertarian is, but European liberalism is largely a centrist to centre-right movement. It's more similar to US democrats than any libertarian platform I know of.
We have mostly been fuzzing C++ programs, like the [Realm database](https://github.com/realm/realm-core/blob/master/seasoned-software.sh), where we discovered a couple of things. For Rust projects, we did test against the Rust library for Cap'n Proto messages where we found a fairly [obscure bug](https://github.com/capnproto/capnproto-rust/commit/e72746cdd4c672a4b8881ed2ed0375b69d1afb3a) after ~2 weeks of fuzzing. It could be fun to take in a couple of nom projects. At least it should be fairly straight-forward to add a fuzz-test harness to projects that mainly eat Vec&lt;u8&gt; or String :-)
Yes language regarding this is controversial with many people arguing one way or another, just as the general topic this thread has turned into. This thread has turned into an unexpected politically intense and off of intended topic discussion. US democrats are traditionally regarded as being a left wing political party, US libertarians are more often considered as right wing though they are more so toward the bottom of an authoritarian to libertarian axis in two dimensional political compasses. These systems have so many variants and there are so many nomenclatures that it leads to confused thinking and speaking, and it becomes a matter of which of the taxonomies should be considered as correct essentially. Nevertheless, I've found that Europeans tend to think of right wing libertarianism when they use the word liberal, whereas in the U.S.A. the liberal movement is closer to what the Europeans consider as socialist movements. This is of course disputed, but it is valid for me to state what I did to try to disambiguate the matter for Europeans or those who know other variants of English. For example, in British English the term Asian typically refers to people from the middle east, whereas in American English it typically refers to people from countries more like Japan, China, and Korea. Many people have found it helpful to try to clarify what is meant by liberal when discussing matters with people who are not native U.S. English speakers. 
&gt; criticized/dismissed Those two things are not the same.
Serde is a central one. But it depends largely what you want to do with the language. Studying is great too, but you’re missing out if you are not using it for anything.
Yay! Congratulations! When is ARM likely to come?
did you look into how much space is taken up by generic functions being specialized multiple times? (a demangling nm should give the raw data from which that can be derived). that's where i'd intuitively look for "wasted space" (rather "space traded off against performance"), but i did not have an opportunity yet to verify that intuition with realistic applications. (if that's the case, what could be tested is to pass in trait objects there instead of the generics; so far, i've only tested some of that).
What has happened here comes down to misunderstanding. You interpreted my original post to which you responded as intending to imply that the U.S. liberal/progressive movement originated this use of the language. I had no such intention in stating that this style of English is currently associated with them due to political reasons, which I maintain is a factual statement. I was aware that singular they, particularly in a form unlike the one discussed in this thread, had been used by prior linguists of international acclaim for generations, however this did not detract from my knowledge that by a variant of English that has traditionally been taught at public and private schools for the past several generations in the United States, that it is always incorrect to use singular they, and that even though it is commonly colloquially done, using it in the way suggested in this thread is a new variation of this already formally contested construct. Certainly people should be free to fork the language as they see fit, I personally am a fan of gender neutral pronouns and therefore prefer to use the variant of English that I've labeled as modern to hyper-modern English, over the variant of English that would necessitate the usage of masculine pronouns in situations of ambiguity in order to receive credit by the grading system. However, that was traditional English, as is still commonly taught at schools I imagine seeing as creationism is for that matter, but essentially my father for example he learned English to use masculine pronouns in ambiguous situations and one could not fault his imagining that this is correct English seeing as he was taught traditional English in school. I cannot recall which variant of English I was taught in school, however I've always colloquially made use of the gender neutral they construct, and am happy to use it even in a hyper-modern context such as this, but please let's not pretend that this is correct by the traditional English grading system when it is defined as that which has been taught at most schools for the past several generations. 
thanks! i am reading it now, TIL, uncle bob is Robert C. Martin.
Hopefully we can use this opportunity to revisit the syntax for this feature, the `&lt;-`-based syntax is really unergonomic *and* it wastes a potentially useful token like `&lt;-` for a feature that will find comparatively infrequent use, and even less in user code.
&gt; The compiler can already tackles a lot of the simple scenarios for SIMD and you should just let it do that. Not true. Even nowadays compilers are extremely hit or miss with autovectorisation. This example doesn't get autovectorised by clang 6.0.0: #include &lt;stddef.h&gt; float sum_gt10(float arr[], size_t len) { float sum = 0; for (size_t i = 0; i &lt; len; i++) { if (arr[i] &gt; 10) { sum += arr[i]; } } return sum; } But this one does: #include &lt;stddef.h&gt; float sum_gt10(float arr[], size_t len) { float sum = 0; for (size_t i = 0; i &lt; len; i++) { sum += arr[i] &gt; 10 ? arr[i] : 0; // Trivial change, yet vectorises } return sum; } (You can paste both of these examples and pass `-O3 -ffast-math` for Clang 6.0.0) Moral of the story: If it's really necessary for your code to use SIMD, you need to use intrinsics (or use a tool such as ISPC). If you rely on the compiler to do autovectorisation for you, it means you don't actually care whether or not the code in question is performant.
&gt; I've found that Europeans tend to think of right wing libertarianism when they use the word liberal, whereas in the U.S.A. the liberal movement is closer to what the Europeans consider as socialist movements. But that's simply not the case. That's absurd. You'd be hard pressed to find any centrist party in Europe that concerns itself with key libertarian issues. Anyone who claims that European liberalism is somehow equivalent to libertarianism simply doesn't understand the meaning of those terms. I also think you're confusing socialism with social democracy. I'm not even sure if you could call the American liberal movement social democratic. Not with the current democratic establishment. Your analysis is sound insofar as saying the democrats are comparable to socialism for being slightly left of (the American) centre and European liberalism comparable to libertarianism for being slightly right of (the European) centre. But this is completely meaningless since both socialism and libertarianism are extremes and not equivalent to any centrist movement.
I'm interested in translating PLUTOcode to rust, as a part time hobby. Do you think that it will be useful to this kind of work or can I help?
This is slowly changing now that `?` can be used in main: https://doc.rust-lang.org/nightly/std/fs/fn.read_to_string.html (But you're right, for sure)
Thanks for this wonderful framework, seems well documented! Always wanted to learn distributed programming, think I will get around to it this time, now that I can do it on my favourite languages :)
Cryptography can use simd with certain algorithms. Eg the Slasa family of stream cyphers is designed so that implementations can use simd. memcpy, memset, memchr can all make use of simd. 
I was about to write something in Dask, but I have to look at this first!
Yeah, pretty much. The only thing I can think of is that in the repo, there's some rust crates precompiled such as `ripgrep`. I'm not sure what's involved in making that though. The Termux tool chain modifies some things from the standard Android one.
Fair enough :-D It is not really ergonomic, but you can use [capnp-rpc](https://github.com/capnproto/capnproto-rust). Having a polished Rust/C++/Java/... client API is planned but before stabilizing its internals, we wanted to only do it if there is serious interest. For us, Python is what we would mostly use for the graph definitions. A more interesting planned Rust (and C/C++) interface point is writing your own task types (i.e. subworkers). With rust, you can simply hack your code into the [worker task code](https://github.com/substantic/rain/tree/master/src/worker/tasks) and recompile, but we have something better and more robust in mind for the future.
 use std::io::Read; let mut buf = Vec::new(); f.read_to_end(&amp;mut buf); LittleEndian::read_i16_into(&amp;buf, &amp;mut x);
Looking forward to your work, this is a very useful tool! 
/u/notsoviet /u/the_murz Comparing and contrasting the American political landscape with the European political landscape sounds like a great topic for an undergraduate research paper, but it seems very off topic for /r/rust. Could you two please take the discussion somewhere else? Thanks.
I would like to warn you that Rain is much less mature than Dask. For serious work, if you have a use case for Dask, then is it better to use Dask:). But we would be very happy to hear about your use case and user experience.
Thanks! I am, and we also talked with /u/frankmcsherry (the author of Timely). Rain and Timely target different workflow types: Timely processes continuous streams of events or data, the nodes are permanently running, you care about latency. In Rain the tasks are one-shot, the data are generally huge blobs and immutable once computed, you optimize for the overall runtime. While you could in theory build a system supporting both modes of operation, the batch systems and stream systems differ quite a lot e.g. with respect to scheduling, resource allocation, resiliency and even monitoring.
Yes, you can! It's possible to submit multiple task graphs, the task execution is then managed by Rain itself, aiming to run as many tasks in parallel as possible (respecting available resources and task resource requirements).
As I understand the question, the answer is yes. A submitted graph may have several separated components, hence more task graphs may be submitted at once. You can also submit them one-by-one, there is not much difference against the previous case. The scheduler starts to distribute the work of all submitted graphs as long as there are free resources. If there are enough resources then they will be executed in parallel.
I believe his name is Theo de Raadt, and his opinionated review mostly drew ire for his dismissal of the importance of memory safety, which many construe as willful ignorance. Richard Hipp is probably one of the few persons on this planet who is able to write mostly safe C code (however [not completely safe](https://www.cvedetails.com/vendor/9237/Sqlite.html), as the otherwise remarkably good CVE record shows). So their purview is sufficiently different from 'average coders' that their opinions about the viability of C for internet-connected software should be taken with a good helping of salt. No vitriol here.
So I don't know if this is the right way to test, but seeing as musl is something I need for work I tried testing it. fn main() { for _ in 1..100000 { let allocation = String::from_utf8(vec![b'a'; 1024usize]).unwrap(); let allocation_2 = String::from_utf8(vec![b'b'; 1024usize]).unwrap(); let mut allocation_3 = String::with_capacity(2048); allocation_3.push_str(&amp;allocation); allocation_3.push_str(&amp;allocation_2); println!("{}", allocation_3 ); } let _ = ::std::io::stdin().read_line(&amp;mut String::new()); } And I can confirm that allocations are happening with cargo profiler callgrind --bin ./target/x86_64-unknown-linux-musl/release/musl_test Profiling musl_test with callgrind... Total Instructions...1,778,307,024 1,435,585,644 (80.7%) ???:memrchr ----------------------------------------------------------------------- 95,599,059 (5.4%) mod.rs:core::str ----------------------------------------------------------------------- 29,899,821 (1.7%) ???:0x00000000004604cd ----------------------------------------------------------------------- 28,401,965 (1.6%) ???:0x0000000000460524 ----------------------------------------------------------------------- 13,899,898 (0.8%) ???:musl_test ----------------------------------------------------------------------- 10,800,540 (0.6%) jemalloc.c:je_mallocx ----------------------------------------------------------------------- 9,804,601 (0.6%) ???:pthread_mutex_unlock ----------------------------------------------------------------------- 9,399,906 (0.5%) mod.rs:core::fmt ----------------------------------------------------------------------- 8,999,910 (0.5%) mod.rs:std::io::Write ----------------------------------------------------------------------- 8,998,961 (0.5%) jemalloc.c:je_sdallocx ----------------------------------------------------------------------- 8,399,916 (0.5%) buffered.rs:&lt;std::io::buffered ----------------------------------------------------------------------- 8,299,917 (0.5%) buffered.rs:&lt;std::io::buffered ----------------------------------------------------------------------- 6,900,345 (0.4%) lib.rs:__rde_alloc Make of this what you will, I'm not qualified to comment on if this is a sufficient test for a memory leak. Both debug and release builds had constant memory usage. 
Are you an astrophysicist, then? I have been pursuing something similar to this for a while now, too. So far I have used timely dataflow for parallelization. But this looks like an interesting alternative, too.
Thank you for the explanation. Then it seems like Rain would fit my use case (simulations of computational fluid dynamics) slightly better. I have been using Timely for my experiments so far. Seems like I have to look into Rain a bit more in-depth. ;)
I would second that interest… if only to avoid writing compute kernels in Python.
That sounds as an interesting application! What is the overall workflow of your algorithm?
It is not easy for me to answer this as PLUTOcode seems completely out of my scope. If tasks that you want to distribute are standalone programs or can be expressed in Python then Rain can be used as it is. If your tasks are C/C++ function then it is not possible now (If I am not counting wrapping C++ functions by Python functions or creating a set of standalone programs) We want to support C++ (and other languages) via additional "subworkers" that allows this, but right now we have only Python subworker.
Don't be afraid about the performance because of the Python interface. Rain enables to easily "taskify" and pipeline also existing binaries which makes it easy to outsource the heavy computation out of Python.
Sorry, it didn't occur to me that I was in this subreddit..
I think we can also add Gnome to this list, even though I'm not sure they have shipped any Rust in production yet. (Has the new version of librsvg been released ?)
Probably not, although I am not really sure what you mean here. If you mean CPU caches, then we expect the tasks and data to be much larger than the caches and so it is not really relevant (i.e. we are not aiming at micro-tasks now and your tasks need to be cache-friendly themselves).
It's not *supposed* to pass if there's another strong reference, because in that case the target data is not going to be dropped - the OP wanted something that would panic instead of "nullifying" weak references.
If we are talking about the same PLUTOcode, then this is about the simulation of astrophysical fluid dynamics problems. Fluid dynamics on its own is algorithmically not that complicated. It is basically a sequence of discrete timesteps that runs in a loop. Each timestep involves computing fluxes between neighbouring cells of some discretization of a computational domain (for instance, a grid of rectangles) and use these to extrapolate the new state of the system. The classical approach here is to use MPI to divide the grid up into parts and then send around data to co-workers as needed. However, there is a very recently published implementation of a task-based system for doing this called [DISPATCH](https://arxiv.org/abs/1705.10774). In addition, when more physics come into play, there is also a use case for solving more global problems, which require communication across the entire domain. Often you end up with large sparse matrix equations or Fourier transforms that have to be solved in parallel.
As I mentioned, you can hurry us along in any direction with your use-case :) It could be interesting to get in touch and see what your application needs. We can chat on our [gitter](https://gitter.im/substantic/rain) or just email me (gavento@ucw.cz) if you prefer.
I would also be interested in running this for pest!
Being aware that Dask is much more battle-tested solution (and also much older project), I would still recommend you to give Rain a spin. We really work hard to find any potential issues and will be happy to fix them as fast as possible if you'd find any. 
That's not quite true everywhere. In France at least, people claiming to be «libéral» are mostly influenced by _Ludwig Von Misses_, _Friedrich A. Hayek_ and _Frédéric Bastiat_, claiming that state is oppression and the true freedom comes from a market free from any political intervention, much like American libertarians. You can find plenty of those among the upper class (even though they aren't the majority there either).
That means you have a binary for every kind of task you want to execute. The binary also has to take care of serialization on its own, I guess? Maybe I haven't gotten the full picture yet, but it seems a bit tedious compared to passing in a function, as you'd do using Python.
Why not just switch to protobuf? Or is that too much work.
We had some ideas around resource management that includes numa-aware pinning, but we have not implemented it yet. Mainly because we had no real numa use-case. If you have one, it could helps to improve Rain in this direction:)
alternative theory: coal mining to fuel PR production
It is one of the options and we are still considering them. For client-side, we want something easy to use, so we could use gRPC (with protobufs) or a REST API (specified with swagger or similar, we need it for the monitoring anyway). A simple RPC based on framed protobuf is an option, but makes integration in other languages a slightly harder (both implementation and debugging). Internally (e.g. server-worker), we would prefer the protocol to be zero-copy (especially for binary data blobs), protobuf would also construct large allocated intermediate structures. We are looking at flatbuffers, [tarpc](https://github.com/google/tarpc) and even [abomonation](http://www.frankmcsherry.org/serialization/2015/05/04/unsafe-at-any-speed.html) (although it might be wiser to avoid even looking at it).
`T: Add&lt;Output = T&gt;` will do what you want. You'll still have some borrowck errors to take care of though.
Doh! Thanks
Also see the internals thread at https://internals.rust-lang.org/t/a-formal-look-at-pinning/7236
&gt; (although it might be wiser to avoid even looking at it) :D
Of course not, I do perform a check to prevent that I just didn't include it in the example. I do agree with you though. Thanks, I will give both of those a go and see which I like best.
Please do, I always find a gorillion panicks in my nom parsers with fuzzying. 
Rain allows to define and pipeline different types of tasks ranging from [built-in tasks](http://rain.readthedocs.io/en/latest/user.html#build-in-tasks), through [external programs](http://rain.readthedocs.io/en/latest/user.html#running-external-programs) to pure [Python tasks](http://rain.readthedocs.io/en/latest/user.html#python-tasks). It is OK (and very common) to combine different task types within a single pipeline - where you can quickly implement some lightweight data pre/post-processing as Python tasks linked to some heavy lifting tasks that wrap external applications. To get a better idea how to employ an external application, I would recommend you to check this [distributed cross-validation example with libsvm](http://rain.readthedocs.io/en/latest/examples.html#distributed-cross-validation-with-libsvm).
gRPC is a very heavy dependency and not extremely well supported cross platforms. protobufs are very well supported. For external access I would go with a HTTP API that responds according to Accept header (application/json or application/x-protobuf). Internally bincode is very popular in the rust world. Don't know how well tarpc works however. For allocations the only one that minimizes them is quick-protobuf. 
It's not uniformly taught as incorrect, and that same argument applies to contractions, which are also taught as "outright wrong" or "bad for formal writing" in many schools. Anyway this is super off topic, go argue about this somewhere else.
could you show me your parsers? Usually, there are very few ways they can panic (mostly integer under or overflows in binary formats).
https://nbaksalyar.github.io/2015/07/10/writing-chat-in-rust.html Do you have any idea if this tutorial is still adequate in 2017? If not, do you know something similar? (a learn by doing tutorial) 
Theo made bold claims that Rust didn't have an ecosystem for writing operating system tools and kernels (even though we had Redox OS and uutils). He also made a point that there's essentially no point in safe programming languages because programmer error will always happen (contradictory logic). Not exactly a credible point of view to take.
Looks interesting, but for my needs (running parameterized machine learning simulations across ~100 servers), I'd prefer something lighter weight and using pure rust IPC. My current solution is just a little rust code + zeromq.
When people say they stay away from Rust because it's run by SJW's or whatever other nonsense, it's threads like this that give those accusation legs.
The one I remember is the control-code crate, some panicks were inside nom (remember those UTF-8 panicks?), but I remember a couple that were in my parser, don't remember what tho. 
Sounds like great work. I'm in general very hopeful that Rust will see a substantial expansion of scientific computing capabilities in the coming year, since that's much of my programming.
You are the one who derailed this thread, I merely stated what is entirely correct and your moral virtue signaling needed to be contextualized as there was confusion as to why you were using a variant of English other than traditional English. I to no extent apologize for correctly characterizing the matter in a neutral manner, and take your offense at me having done so into no consideration. 
I believe you are seeing most of the time spent in BTreeMap manipulation inside your various from_json functions. For comparison, I tried the same benchmark with: for line in file.lines() { serde_json::from_str::&lt;serde::de::IgnoredAny&gt;(&amp;line.unwrap()).unwrap(); } and it runs about 8x faster. So you should expect a speedup of up to 8x by replacing your hand rolled Value-based functions with serde_derive and actual Deserialize impls for your types.
Consider using [`par_lines()`](https://docs.rs/rayon/1.0/rayon/str/trait.ParallelString.html#method.par_lines) from Rayon to process the lines of input in parallel. Compounded with the speedup from using Deserialize impls rather than Value, if your machine has 4 cores you may see a 32x speedup.
What's interesting is that some of these are avoided by language design decisions, and others are avoided by library design decisions, and some are really just by convention. 1. Array/Vector out-of-bounds indexing: Anyone writing any unsafe code has to remember to add appropriate bounds checking. The only real safety in Rust comes from the standard library doing it, and the convention that all unsafe code must not depend on safe code doing the "right" thing. 2. Map `[]` operator: language-design means that not everything can be value-initialized, which in turns means that whoever wrote HashMap would have had to require a `V : Default` bound to implement `[]` in the C++ style. So instead we got the panicking form of `[]` + the `.get()` for optionality (which handles `getDefault()` use-cases) and `.entry()` for getting a nice, explicit version of the C++ code with no (?) perf hit. 3. `getDefault()` returning a reference to a temporary: Solved partly by lifetimes (if it's a temporary, then the returned value hes the shortest of either lifetimes), and party by the fact that string literals are `&amp;static str`. This means the no-copy code C++ users keep wanting to write for `getDefault()` actually works in Rust. 4. `volatile`: Arguably this isn't fixed by Rust the language, but by the cultural insistence on abstractions to wrap unsafe code. 5. `shared_ptr`: `Sync + Send` and `Arc` vs `Rc` allows the full range of thread-safety tradeoffs, while the borrowchecker stops the actual bug (multiple write-references to a single `shared_ptr`). 6. Default constructor syntax + RAII lock objects. Solved half by the lack of magical default constructors (all construction requires a method call), half by the fact that the lock object actually wraps the underlying data.
&gt; This is certainly considered to be incorrect usage of the language by the majority of people classified as professional linguists Uh, certainly not. Linguists concern themselves with how language is actually spoken, and of the several that I know none would call it "incorrect usage". You can try googling "linguist" and "singular they" for a sampling of thought, but the vast majority of results I saw called it acceptable. "Hey, can you take this call right now?" "No, tell them to call back" is so obviously natural that no linguist would say that's incorrect. Now, "grammarian", whatever those are, call it incorrect. I don't disagree with your point that starting a couple hundred hears ago a lot of people were schooled that singular they is "incorrect". But my sense is that fact, along with other wrong teachings have been slowly reversing. Consider Churchill's [apocryphal](http://itre.cis.upenn.edu/~myl/languagelog/archives/001715.html) "up with which I will not put" quip making fun of the incorrect "never end a sentence with a preposition" rule, or Star Trek's famous "to boldly go" split infinitive. Singular they is part of the general trend of "descriptivism" vs. "prescriptivism", and while it is certainly caught up and helped along by the current gender pronoun atmosphere, it _is_ distinct from it. I, for one, have been championing singular they and other valid English constructions long before it was a hot topic, anyway.
As an aside. French doesn't have any such arbiter either, and in fact I doubt any language with a non-negligible community of native speakers could ever work like that. People (French or otherwise) like to pretend that the Academy does play this role, and occasionally use this "fact" to support the same sort of silly arguments over pronouns etc. we're seeing in this thread, but never consistently respect what the Academy has to say about anything. French has millions of speakers and they speak the way they like just as much as English speakers do. All the Academy really does is publish one immediately outdated dictionary per century, produce half-baked spelling reforms that nobody even acknowledges, then backpedal on them, and occasionally release contradictory statements which everybody promptly ignores on some obscure usage point (I don't even know who writes those tbh). Essentially they produce exactly the same BS that you might find in a pedant's grammar column or blog in some other language, but in a more institutional form, and with as little impact. I guess the Academy had some genuine purpose when it was created but nowadays it's largely decorative, basically.
&gt; When is ARM likely to come? There are ~10 ARM intrinsics implemented on nightly, from probably 1000s, so unless people start submitting pull-request the answer is probably never.
There is a strongly-typed version of the `std::arch::{x86,x86_64}` modules which uses `std::simd` here: https://github.com/gnzlbg/typed_arch
It will almost definitely not work as written since it uses the "bleeding edge" of various git repositories from when it was written three years ago. Nowadays you would use tokio and futures to write an async app like this, but I don't know which tutorial is the best. Some of the post that's not specifically about event loops may still be applicable. 
What is a computational framework?
Placement new should really be quite popular though. It's basically just free performance.
Well, we have similar concerns about gRPC. But HTTP also has some downsides: JSON does not support binary data directly and I am not sure about server callback support (e.g. for waiting for a result other than polling). But maybe I am missing some obvious good solution there - web technologies are not really my cup of tea :-) Keeping an OpenAPI JSON schema in sync with protobufs might be an extra trouble and source of bugs, but perhaps it would be worth it. Anyway, if not for large data blobs, JSON parsing itself does not seem to be a real bottleneck, at least not client-side.
Does this mean we users have the ability to write SIMD code in rust or rust is able to optimize some operations using SIMD?
Rust will already attempt to use SIMD when it thinks it can. This is a way for Rust programmers to explicitly write SIMD so that you know it will always be used. This is also the lowest level interface; most would use higher level libraries built on top rather than this directly.
Not sure exactly what kind of credentials you're looking for, but here are a few views from people who were already well known for involvement in other open source projects. Neil Brown, maintainer of Linux's md (multi-disk, software raid) subsystem wrote a fairly positive overview of [Rust 0.6](https://lwn.net/Articles/547145/). This is pre-1.0 so some things have changed since then, but overall it's mostly still accurate. He also wrote a couple of other articles on Go and Rust; one on how they [both lack traditional OO and what their alternatives are](https://lwn.net/Articles/548560/); there was another on for loops, but since it was pre-1.0 the Rust syntax has since changed. Armin Ronacher, author of the Flask microframework in Python, wrote a [Rust for Python Programmers](http://lucumr.pocoo.org/2015/5/27/rust-for-pythonistas/) and has been involved in the Rust community for several years. Robert O'Callahan has been a Mozilla developer for quite a long time, working on Firefox and known for creating the the [`rr` debugger](http://rr-project.org/) (a debugging tool that allows for reversible debugging at much higher speeds than most other reversible debugging tools, making it more useful for tracking down problems deep in complex codebases). While he works for Mozilla so there's a slight conflict of interest, I don't believe he's ever worked directly on Rust, but he has some good blog articles on using Rust for some of the tools that he works on, such as [speeding up `dwarfdump` with Rust](https://robert.ocallahan.org/2018/03/speeding-up-dwarfdump-with-rust.html). Andrei Alexandrescu, famous for his work on template metaprogramming in C++ and his involvement the D language, has a well known [brief critique of Rust in which he claims that it "skipped leg day" by focusing too much on memory-safety](https://www.quora.com/Which-language-has-the-brightest-future-in-replacement-of-C-between-D-Go-and-Rust-And-Why/answer/Andrei-Alexandrescu?share=1). It is unclear how much he actually knows about Rust given the criticism, especially since the other criticism is of having unfamiliar syntax despite the fact that Rust is not much more different in syntax to C++ than Go is; it seems like a bit of a throwaway criticism without much analysis, but it's worth considering. Eric Raymond has [a fairly scathing critique of Rust](http://esr.ibiblio.org/?p=7294), and he did actually spend some time trying to use it, and after some discussion in the comments he had a [followup](http://esr.ibiblio.org/?p=7303). His criticism had three main points; one was that he thought that many simple things were just too difficult, with too much ceremony, and the documentation wasn't sufficient to learn how to actually cope with this complexity. The next criticism is that there isn't any form of abstraction over event-driven networking in the standard library. The last is that he thinks that the Rust development model, with a core team rather than a BDFL and a lot of work being done in crates outside the standard library, is not the best way to achieve a coherent, integrated result. The first criticism is one of the biggest stumbling blocks for most people in Rust. There is a steep learning curve, and there are a few things for which you need to put more thought in, than you would in a garbage collected language. There has been ongoing work, both before and after his critique, on improving the ergonomics of the language; there have been a few that have already landed, like some substantially improved error messages, and more that are coming soon, like non-lexical lifetimes. But even still, Rust does have a somewhat steep learning curve compared to other languages. The second is about the lack of a built-in solution for event-driven networking. Now, I don't believe that C or C++ have such a thing, but I think the fact that Go has that baked in at a fundamental level using goroutines spoiled him a bit in thinking that's a fundamental requirement for a new language for networking programming. At the time, Tokio and Futures had just recently been released, and were undergoing a lot of active work; and that work is ongoing, with both of them having moved to 0.2 versions by now, some language features being worked on to make asynchronous programming easier, and so on. So this is a place where there's active development, but it's still a bit rough. The last point mostly reveals some difference in opinion on project governance, but he also had some valid complaints about the difficulty of finding which library in the crates ecosystem he should use for a given purpose. Since there is no explicit curation of the crates ecosystem, there were some problems in finding the right crate for a given purpose. There's been work since then to improve this; there are more features in crates.io for categorizing crates, for exposing more information about crates that is useful for judging which ones you are interested in, and there's been work on a Rust Cookbook which shows examples of how to solve common tasks in Rust, in many cases using crates that are considered high quality and widely used in the ecosystem. Not sure if it's what you're looking for, but a few pointers to both positive and negative reviews of Rust from people who are already somewhat prominent for work on other software.
This is an interesting point, and one where I'm really a complete novice. Happen to know any good write-ups on the subject?
https://github.com/dbartolini/data-oriented-design
Cut it out.
Some random things off the top of my head: 1. Generics, generics everywhere. Your C++ knowledge may help but also may hurt, as Rust's work differently in some important ways. 2. Rust has a small standard library, like C, and contrary to Go. We also have Cargo, and so one of the reasons why std is small is that it's so easy to pull in a dependency, there's less pressure to put things in. 3. The release cycle: Rust updates every six weeks, rather than the ~6 months of go or 3 years for C++. We still have similar stability guarantees though, so don't be afraid of upgrading. 4. The Rust compiler is much more strict than those languages', and so you're going to have the compiler print out lots of red text. It's okay! It's trying to help. What you get back is data race freedom, and significantly less (in my experience) debugging time. Think of it as moving some of your debugging time to compile time rather than runtime. :) This gets easier over time. 5. Implementing data structures is a great way to learn C, but a terrible way to learn Rust.
&gt; Map `[]` operator: language-design means that not everything can be value-initialized, which in turns means that whoever wrote HashMap would have had to require a `V : Default` bound to implement `[]` in the C++ style. So instead we got the panicking form of `[]` + the `.get()` for optionality (which handles `getDefault()` use-cases) and `.entry()` for getting a nice, explicit version of the C++ code with no (?) perf hit. Actually, a regular pitfall of using `[]` in C++ is that there is a performance hit: an object is first constructed and then assigned over. For objects whose constructions is costly, such as allocating memory to avoid having to check for null pointers later on, it's a performance pitfall. A second pitfall of using `[]` in C++ is to accidentally use it to get an object out of the map, without realizing that it'll be created if absent. Not only does it lead to incorrect result (you get a default value instead of an error), but it also leads to artificially inflating the size of the map, consuming more memory than expected and degrading look-up performance. So... I'd argue that `.entry()` is as likely to offer better performance than it is to offer worse performance; and it'll probably vary by use-case. 
Compression? If you're using btfrs or any filesystem that can compress directories on the fly, you should give it a try, the lzo/lz4 algorithms are pretty good with executables and text, you could easily save 50% with a small performance penalty. Although it's better to use it on hdds, where it's usually faster to read and decompress than read the decompressed file ^([citation needed]). fusecompress used to be a thing for compressing directories when your fs doesn't support it but I'm not sure what do we use now.
This is great! Short and concise for the beginner. It works as a reminder of certain behaviors of the language too. Now, this reminded me of [http://intorust.com/](http://intorust.com/) started by Nico. Any chance we can get all these resources (and some other cool ones) in one place?
My thoughts in order: 1. You can't teach Rust in 10 slides, that's ridiculous! 2. This must be a beginners guide/intro. 3. It is probably just a catchy title, let's check and see... 4. Cool!
Thanks! Projects like rust-learning try to collect up tons of links, so maybe that counts?
Auto-managing dependency upgrades was something I posted about in my [rust2018 post](https://epage.github.io/blog/2018/01/crate-management/) and recently [someone let me know](https://github.com/rust-lang-nursery/ecosystem-wg/issues/10#issuecomment-378997548) that Dependabot has added support for this. I haven't heard of them before but I decided to give it a try. So far it seems to be working well. - [Example of upgrading `Cargo.toml`](https://github.com/cobalt-org/liquid-rust/pull/169) - [Example of upgrading `Cargo.lock`](https://github.com/cobalt-org/cobalt.rs/pull/408) Recommendations - Be sure to limit what branches your CI runs on to avoid the CI running twice, once on the PR and once on the branch Dependabot creates (fixing this in my projects atm) - Be sure to test using your oldest supported Rust to avoid accidentally bumping your minimal Rust version. I'll be updating [crate-ci](https://crate-ci.github.io/) with these recommendations.
https://spark.apache.org/ 
Have you looked at Spark's Scala API? And at Spark in general? (I mean, I get that Rain is not in-memory computation, and mostly about scheduling.)
I forgot about it. Good catalog. https://github.com/ctjhoa/rust-learning
If I code like the following if cfg!(debug_print) { println!("Some debug info here"); } How do I tell cargo to actually conditionally compile it? Is there a command line argument I can pass? Can I set it to always do it in a profile?
&gt; I will refrain from continued off topic, but I am disgusted by the show of virtue signaling by numerous individuals in this thread and the fact that they have ganged up on and down voted me for saying what is factually true and simply against their moral sensibilities. I'd challenge your suggestion that they are just virtue signaling and argue that "singular they" is actually correct usage. I'd also argue that your statement that the use of singular they is associated with a certain political movement is factually wrong. "Singular they" is in heavy general use and there are published works from all the way back to the late 1300s. It's been used by well known authors (Shakespeare, Austen, Thackeray, Ruskin). It's even used in the King James Bible, and I doubt one can argue that religion is really pushing for gender neutrality. Also it's used by pretty much everyone in colloquial speech, even those people that heavily argue against it, saying that it is wrong, unconsciously use it since it just "feels right". Furthermore the English language has precedent in the form of "singular you" or would you argue that it must not be used for singular? Yes, it was originally only used for plural, but eventually evolved into being both plural and singular. In fact modern English doesn't even have a separate word for the singular version anymore. &gt; This is certainly considered to be incorrect usage of the language by the majority of people classified as professional linguists I don't know where you get this from, the Merriam-Webster Dictionary for example endorses the use of singular they. And most of the linguists I know are either in favor or neutral to it's usage. --- So what is it that makes "you are" correct as singular and "they are" incorrect for singular? Why doesn't the precedent count? What is it that makes 7 centuries of common well documented usage of singular they incorrect? Why does the general usage of the language by the overwhelming majority of the Population not count? I'd say that it's not a Political movement that's associated with the use of singular they. No, in fact singular they is correct and used by the majority, it's the general case. I'd say it's a certain Political movement that's against the usage of singular they, a movement that is against the use of gender neutral usage, even against precedent, historical use and overwhelming use in modern English.
Would you please share some examples regarding "switching to Rust really made a lot of things much more elegant, easier and robust."? 
Is Rain in the same ballpark as Apache Airflow? I read your docs about what you try NOT to achieve. With those given, Rain is achieving similar aims? 
Hah, last year I started a toy programming language in Python and named it Rain. I fell out of interest with it for one reason or another and then started revisiting it this year in Rust instead of Python. Interesting to see that another (more mature) project now is using the name for both languages! This looks awesome though. I'll have to take some time at work to dig into it.
Is there visual material I may reference that depicts what this "computational framework" is addressing? I'm making a lot of assumptions about it otherwise.
I would just like to suggest [milksnake](https://github.com/getsentry/milksnake) if you haven't seen it already. It's a project born of frustrations mentioned [in Armin's talk](https://www.youtube.com/watch?v=zmtHaZG7pPc). I'm not even an industry programmer and I've run into the problems he outlines, and am therefore porting a project to milksnake.
Yeah, I was referring to the Académie française, but only in a sort of straw-man capacity. I know nobody except government employees actually calls email "courriel." Still, I think with these kinds of discussions, where I ultimately want to end up is "there's no such thing as 'correct' grammar," but sometimes an easier rhetorical tactic seems to be: even if we assumed a theoretical "correct" grammar (or spelling, or whatever) did exist, who would decide what it was? And in French, there's at least nominally a body that has that responsibility (leaving aside its effectiveness), whereas English has nothing that could be argued to do that. There's really no logical position in English to take other than "'correct' is whatever we collectively all decide it is," whereas in French there's maybe room for debate. As you say, though, people taking the other side in that debate are in practice pretty clearly wrong. Maybe German, what with its legislatively mandated spelling reforms, would be a better example.
Yup. This kind of work is quite crucial if we are to ensure that new features, either in the language itself or in its core libraries (at least, new features that significantly interact with Rust's basic guarantees, as with this case) are elegant, ergonomic and easy to teach and learn, and interact in sensible ways. It looks like this goal was achieved with the pinning addition to the language, so this is significant progress towards making this available in Stable Rust.
In simple terms, distributed computational frameworks take some computational task (ex. Processing a large amount of data) and use multiple computers to do the task, instead of using one really strong computer to do it.
Understand please that I am fully in favor of singular they. I have no allegiance to any variant of English. In fact, I have no allegiance to English in any case. Preferably I would like a new human language that fixes bugs in the current language. There is actually a great deal that can be done in this area, which I've researched for many hours. For one example, dyslexia manifests differently in different languages, so an individual fluent in Chinese Characters may be dyslexic in English Latin Script, or vice versa. However, there are scripts that combine alphabetic and logographic stylistics, such a dscript, which I imagine may allow for more communication. I am totally in favor of completely making a new human language with intelligent design and ditching traditional English for good! However, there is a variant of English by my understanding, which was commonly taught as correct for maybe even hundreds of years in the United States, certainly my father was taught it and I think I may have been as well, where correctness inside of this framework is to use masculine pronouns as gender neutral pronouns. I think this is silly, but there is a variant of the English language with substantial popularity, particularly among older and more conservative people, that considers it to be linguistically incorrect to use singular they in any form, let alone the more hyper-modern form it was used in here. This is all I am saying. Someone stated this is incorrect English, and I simply stated that this is the case in traditional English as is typically or was typically taught in the American school system. One merely needs to look over the wikipedia page to verify that this is so: https://en.wikipedia.org/wiki/Singular_they &gt; Though both generic he and generic they have long histories of use, and both are still used, both are also systematically avoided by particular groups.[99] Style guides that avoid expressing a preference for either approach sometimes recommend recasting a problem sentence, for instance replacing generic expressions with plurals to avoid the criticisms of either party. &gt; The use of singular they may be more accepted in British English than in American English,[100] or vice versa.[101] ... &gt; According to The American Heritage Book of English Usage, many Americans avoid use of they to refer to a singular antecedent out of respect for a "traditional" grammatical rule, despite use of singular they by modern writers of note and mainstream publications: .... &gt; Pauwels, Anne (2003). "Linguistic sexism and feminist linguistic activism". In Holmes, Janet; Meyerhoff, Miriam. The Handbook of Language and Gender. Malden, MA: Blackwell. ISBN 978-0-631-22502-7. I mean anyone who reads the page who wasn't already familiar with the issue will conclude that I neutrally and fairly characterized the situation, nearly every professional opinion regarding the usage of it in American English said it is ungrammatical. &gt; "Although some experts accept they, them, and their with singular indefinite words, most do not, and many teachers and employers regard the plural as incorrect. To be safe, work for agreement between singular indefinite words and the pronouns that refer to them ..." It is simply false that traditional English has a valid singular they, regardless of if has been used by numerous individuals throughout history, the English used throughout history has not all been the traditional English consisting of the primary English taught at American schools for the past several generations. 
Should probably specify location and/or whether the position is remote friendly :)
Your code works as expected. Thank you :\)
Well, I see your point about the rhetorical device, but I tend to think replacing the misconception "there is an absolute standard for what is correct language" by "there isn't an absolute standard for English, but it's a thing" (plus some vaguely xenophobic stereotypes) isn't very helpful. I'm not saying you think the latter, but people definitely derive the latter from the sort of argument you just made. I remember seing comments about "prescriptive languages" and "descriptive languages" on /r/badlinguistics. Or Anglo exceptionalism like "only English doesn't have rules" etc. &gt; I know nobody except government employees actually calls email "courriel." I think you are referring to some other misconception here. :) It's not the Academy that makes up the translations of English borrowings. They are way too slow to react to anything for that. It's dedicated government committees (in France and in Québec), or sometimes just random people / "organic" usage. (Also, people do in fact use courriel, and many other such translations caught on as well. You might be confusing it with "mèl" which is only used on government forms to my knowledge. Not sure who made up "courriel" btw.)
Found on their page: "We are hiring for all positions for our office in Orange County, California."
I would be interested in doing machine-learning on a large numa computer. Hundreds to thousands of nodes. Current plan is looking to spark and see if I can configure it to run efficiently using the numa interconnect.
Given the nature of the work(it's tough to work with hardware remotely), we're focusing on on-site positions right now, but we're open to other possibilities.
Hey folks; This is the RFC for finalizing the syntax of `try { .. }` expressions (formerly `catch { .. }`) for the new Rust edition of 2018.
In Rain, there is a strict separation between graph construction and execution. All client code except functions annotated by @remote() is always executed locally in the client application. The communication with the server is done explicitly by calling methods like submit/wait/fetch. Python code annotated by @remote() is executed only by subworkers (i.e. on machines in the cluster). Can you please be more specific what you mean by flexibility in task execution management? The server is the only single point of failure in our design. System is designed to survive failure of workers (and subworker); however it is not implemented yet. But this type of resilience is high in our todo list. 
well, isn't this is a question you can answer yourself? is it easy or hard for you? i've been learning rust for months now and it's easily the hardest language i use. scala is hard because it comes with the whole kitchen sink, but it's easy to do things like store Futures in a HashMap and things like that. meanwhile in rust, i'm not sure i could figure out how to build some datastructures with a week to do it. rust comes to some people easier than others just like human languages, but that doesn't make it any easier for you.
It will invoke undefined behavior, such as causing SIGILL to be received.
Hey, I'm isis lovecruft (yes, lower-cased, e.g. as in 'bell hooks', whom I suspect you'll also have "linguistic" issues with). It looks like you've already spent the last day learning about my pronouns, so I'll skip that part of the introductions. ;) My colleague [Chelsea Komlo](https://twitter.com/chelseakomlo) (she/her) and I are currently considering doing a broad, retrospective talk at RustConf 2018 on the joys and eldritch horrors we've come across while integrating Rust into a large, rapidly evolving, C codebase—particularly one with asynchronous networking, lots of cryptographic primitives in use, and security and anonymity as its primary focuses. Many problems have been entirely unexpected, for instance things like: * Should you always copy bytes across the FFI boundary, or are there tricks you can play with the allocator and `mem::forget` that would be more efficient? * Which allocator do you use and when? * Is there a way to have static string literals in one language or the other, but use them safely from both? * How do we test Rust code which wraps C code (which calls Rust code, and so forth) without running into linker issues? * What's the best way to fuzz both C and Rust functions to ensure that their behaviours are identical? (Interestingly, it's an anonymity issue if the two codebases behave differently, as it allows partitioning the anonymity set.) * many more Things We Did Not Think We Would Have To Think About… That said, our experience of using Rust in tor has been excellent, which is why we're continuing to use it! We've even uncovered a couple security bugs in the C code (e.g. [CVE-2018-0490](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-0490)) by painstakingly scrutinising behavioural differences to the Rust implementation. And our code reviews are so much faster for Rust than for C, since we know that (other than ripgrepping for "unsafe") there's not likely to be any of the memory issues that we need to tediously hunt for in one another's patches. Additionally, reasoning about type-safety and easy-to-use APIs in the Rust has enabled us to find even more issues buried in C code we previously thought was fine. It's a really fantastically designed language (also did I mention fucking *fast*), and I love Rust more and more, the more I write it. My team at Tor seems to be mostly enjoying it as well, and some of us have started using Rust for other projects—both weekend projects and at work—like my coworker [Alexander Færøy](https://twitter.com/ahfaeroey)'s (he/him) [tool for making unique visual fingerprints for cryptographic material](https://github.com/ahf/hashvis). Anyway, one of these days Chelsea and I will hopefully get around to submitting the RustConf talk, so maybe, hopefully, there will be more on the topic soon! ♥Ⓐ isis
"fearless programming" Out curiosity, why are you worried? When you move into a threaded context, you will need to switch to `Arc` from `Rc` to shared across threads, and then you'll want to figure out your writes, `Mutex` being the easiest to reason about, `Atomic*` not requiring any explicit synchronization between threads... The type system will stop you from doing anything not allowed, as long as you don't use `unsafe`.
Looks fine to me, fun part is compilation will fail if you naively try to make it multithreaded. So I guess that's what goes wrong, you need to make it actually threadsafe as soon as you want to use threads. 
&gt; flexibility in task execution management? Sure. Basically, there are a number of "distributed process managers" out there at the moment. These vary from hosted solutions like amazon's or google's various cloud offerings to Mesos, Kubernetes, Docker Swarm, Nomad, Celery and so forth. Basically, existing setups for executing workloads and distributing those computations across nodes. Most of the ones I've named are pretty generic in terms of what they let you do, though there are definitely workload specific ones out there (like Spark, for example), but the basic gist of the interaction method is you build some config object that describes the workload to execute and then submit it to the framework and it goes off and tries to execute the requested job. There's usually some sort of interface for monitoring execution and rather than directly feeding input and output blobs to these systems, you'd probably pass around some metadata describing what to feed in and out (to alleviate copying/transmission costs of GB or TB sized workloads). That said, there's a ton of different approaches to task execution graphs and I wouldn't say I know all the different sorts of things people want to do with them. I'm just familiar with the sort of workloads I have to run.
I have worked on similar type of project written in C++ over libuv and the biggest simplification (for my part) that I see is due to tokio and futures. For example, forced termination of tasks in worker just by dropping future is quite straightforward. Also error handling where almost everything can fail (tasks, network connections, moving data objects around file system) is much easier and robust.
I've implemented a `struct u5(u8)` that is limited to values in the range `0..32`. Now I want to write a function that would check a `&amp;[u8]` if all elements are in range and returns a `Result&lt;&amp;[u5], Error&gt;`. It would be much easier to just return a `Vec&lt;u5&gt;`, but that would need an allocation and I think it is unnecessary. I thought about using transmute, but the docs are rather discouraging. Can someone say for sure if a `std::mem::transmute::&lt;&amp;'f[u8], &amp;'f[u5]&gt;(some_slice)` would be safe if `u5` is `repr(C)` (and I do make sure that elements are in range)?
Is spark considered a computational framework?
Our goal is definitely not to make a replacement for tools like Kubernetes or PBS (in HPC world). Rain is a framework for tasks on a smaller level of granularity and we expect that it is executed inside these "big" schedulers that allocate machines for us. Right now, we have a trivial support for PBS; however we would like to support also more cloud oriented solutions. (We have recently received a credit for testing from Exoscale, [thank you!], so probably in some short term we will do some work in the cloud world.)
My first paragraph was defending the sanity of the original question by comparing it to human languages. In the process of doing this, I acknowledged that the question may not make sense for a human language after all, because of how individualized these things are. I made reference to the fact that some human languages are easier or harder to learn based on the languages you already know, and implied this would come into play with computer programming languages as well. I acknowledged the fuzzy nature of determining what it means to actually know a language even. In my second paragraph I start by explaining that although colloquially one would say Rust has a 'steep' learning curve, I prefer using the proper nomenclature from education theory where the learning curve maps over time how much of the whole you have learned, which means a shallow learning curve indicates something that is very time consuming to learn (as opposed to a steep learning curve being difficult to get up in a synesthetic sense, as it is colloquially used). I finish the second paragraph by essentially stating that there are numerous angles one could provide a sensible and contributory reply by presuming, and that people should attempt doing this rather than imagining that such a question is nonsensical and impossible to constructively extend on. Your answer was satisfactory however! 
I built the Thrift rust implementation, and I'm definitely active in fixing bugs. That said, it only generates sync code (I'm waiting for the futures and tokio changes to subside before building async generators). FWIW, the company I work at uses Thrift heavily internally (no Rust tho.) and it's been great for our needs.
Working towards 1.0 for https://GitHub.com/rcoh/angle-grinder Adding support for expressions, improving docs &amp; parse errors
&gt; I would expect the CPU to raise an "invalid opcode" trap of some sort. You only get a SIGILL if the intrinsic is actually executed and the CPU detects it as illegal. Those are two very long shots. First, if a CPU doesn't have an instruction, it was almost by definition designed probably years before the new instruction appeared. It must therefore be able to recognize a specific sequence of micro-ops as an illegal instruction, and this is something that also, by definition, couldn't have been tested when the CPU was designed and built. Second, Rust, LLVM, and the assembler, assume that if you call an intrinsic that requires some feature, that that particular feature is enabled. That is, surrounding code might be compiled with the feature enabled, and even if that's not the case, LLVM and the assembler will insert no-ops to properly align certain instructions, and those will depend on the features that are actually enabled. Those no-ops might not be no-ops on a CPU without the feature, and as a consequence, the intrinsic that should cause the SIGILL might actually never be reached. Those "no-ops" can do anything, including reading and writing to memory (e.g. writing to an specific address that can never be read is a reasonable way to insert a no-op for alignment).
Instead of returning `&amp;[u5]`, you can create your own "slice" type that wraps the `&amp;[u8]`. You can even make it an enum to handle both `&amp;[u5]` and `&amp;[u8]`, like enum&lt;'a&gt; u5Slice&lt;'a&gt; { CheckedEight(&amp;'a [u8]), Five(&amp;'a [u5]), } The lifetime annotation might be a bit wrong but the idea is correct.
I'm currenty on ext4, which AFAIK doesn't allow transparent compression. I'll look into changing to BTRFS.
I understand, people mean by "computational frameworks" and "pipelines" various things depending on their backgrounds. Unfortunately, we do not have more pictures than what you can find in the user guide. Maybe I can rephrase the description of Rain as "similar to Dask/Distributed that is open-ended for different type of clients/subworkers and with a direct integration of executing 3rd party applications" or "Some kind of Tensorflow where tensors are replaced by generic blobs" (Ahh, I should not used the seconds description as it is misleading on many levels:). If you can tell me which tools you are familiar with, maybe I can try describe Rain in different terms. [This reminds me, that we really need "comparison to other tools" in docs]
Great! Please don't hesitate to let us know if anything else comes up! We're all happy to help. :)
Thank you for the comment! We are looking forward to your feedback.
I've just come to accept that objects can only be mutated by one owner or via a locking mechanism I guess! haha. This feels like cheating.
We too :-) Lets keep our fingers crossed (and hopefully contribute a bit)
I thought about wrapping a `&amp;[u8]` into such a struct. The drawback would be that I loose all traits that are implemented for slices. I'm not sure how the enum makes the situation any better, I now have to handle two cases whenever I use a `u5slice`. Since the new type pattern is known as a zero cost abstraction I'm pretty sure it shouldn't change the memory layout of it's underlying type. So I hope someone can clarify under which condition casting between an array/slice of newtypes and the underlying type is safe.
&gt; this service is free for open source projects! Yeah, when I was signing up, it doesn't look like it'll be free but when you hunt around on the page enough, you see the check box for free open source service. I'm impressed that it tries to detect the relevant sections from a changelog and the relevant commits form history. Definitely helps in knowing the impact.
We always try to justify all the design choices that we made to ourselves as much as possible in order to make the framework as useful as possible to the potential user community. We have decided for a Python API because, from our previous experience, we know that broader scientific community likes Python and speaks Python quite well. Assuming that many data scientists and domain specialists know a good bit of Rust would, in my personal opinion, significantly reduce the potential impact of the project at this point in time.
Yes
Trying to implement a generic trait for a trait object [playground](https://play.rust-lang.org/?gist=933c9a6d5c0a293d2a50513624ea6c24&amp;version=stable) [gist](https://gist.github.com/933c9a6d5c0a293d2a50513624ea6c24) If I specify the type of value used in `Example` (i.e. in the playground a `u64`) it compiles and works as expected. However I'm unsure how to do this for a generic type `T: Add`. My initial guess was something like impl Add for Example&lt;T + Add&gt; { OR impl Add for Example&lt;T: Add&gt; { &lt;insert any other permutation of T, :, + and Add that you can think of&gt; Is it possible to do something like this, ideally without having to implement it multiple times for all the numerical types? 
This is exciting. I seem to be in the minority in Rust-land but I actually *like* exceptions as a model. I like when for simple problems I can program for the happy path and handle all of that error nonsense elsewhere (or not at all!), and I'm not especially worried about the flow control being not exactly what the lexical order of code makes it appear to be. But more so, I'm glad that this discussion makes it clear that it's being handled in an extremely thoughtful way by people way smarter than I am
For me that would be the stronger type system (traits, and very nicely designed std lib), elegant definition of structs (with free impls for debug, serialization, eq, hash, ...), move semantics and the borrow checker (while restrictive, it catches many errors that would be hard to debug, and it is a blessing during any refactoring together with the type system). The tooling is very nice (RLS, doc gen, integrated tests and crates.io). In C++ you can get some of these e.g. with boost (which tends to change over releases), macros and by *correctly* using the modern features of C++ (which is rather nontrivial) so I would subjectively call it a big improvement :)
Blowing up the stack or not depending on how the stars align within the optimizer, and or whether optimizations are enabled or not, sounds like a pretty bad idea to me.
[This implementation](https://play.rust-lang.org/?gist=d07363606e6263ce3b8fa9078c6e1ec8&amp;version=stable) will add `Example&lt;T&gt;` and `Example&lt;U&gt;` iif `T==U` and `T: Add`.
Mine works - although I have split my vim configs into system level packages. Here are the two relevant ones: * [base](https://github.com/mdaffin/arch-pkgs/blob/master/pkg/mdaffin/mdaffin-base.vim) * [rust](https://github.com/mdaffin/arch-pkgs/blob/master/pkg/mdaffin/mdaffin-devel-rust.vim) I think the key difference is let g:LanguageClient_serverCommands.rust = ['rustup', 'run', 'stable', 'rls'] Basically, rls is now available on stable.
&gt;&gt; But from looking at the code of all the involved pieces it seems quite possible. I have a proof-of-concept for [a GLib futures executor] on my todo list, we'll see. &gt; Nice, I'd be interested in playing with it. I've added a very minimal and hackish initial version here: https://github.com/sdroege/glib-futures/blob/master/src/main.rs I'll clean this up in the next days, add support for GIO async functions and make it a proper library crate.
I can call it manually, it still returns "Not found!" in my statusline. I guess I'll try and switch to stable. 
A bit missleading, I thought it was related to wasm ;)
I do note that when I try to use it I do get `Not found!` when the cursor is over a symbol that cannot otherwise be resolved - but when over one that can (variable, type I have defined, functions etc) it does work as intended. Can you show an example of what you have tried it on?
Do you guys create any products that will be directly used to harm humans? Depending on the result of that question, I could be interested.
Wow, the details with the changelog being pulled in is very nice, and the recent commits... cool.
If i do a brand new cargo init, and add actix-web as a dependency for example. I then run cargo build and cargo doc. I then open vim on main.rs and try and :K or gd on anything in there. This is using the main.vim from here https://github.com/actix/actix-web/blob/master/examples/hello-world/src/main.rs
It's still possible to have logic errors that break some standard library functions when using Cell. They won't result in unsafe code, but they will result in the strangest of bugs. 
Do you have any examples? I have yet to run into such a thing.
I'm quite interested in helping contribute to the `rand` crate. It was one of the crates that I tried to use early on, but it was easier to just write my own since the API wasn't close enough to what I needed. Where do I look to see the latest thinking on what the `rand` API should look like? And how much appetite is there to change the existing API (rather than just change the implementation of it)?
Another neat feature is that it will "rebase" when there is a conflict. Say I have 2 PRs for my lock file. Both have the green light. - I merge the first and the second now has a merge conflict - Dependabot will scrap that commit and recreate it based on the new `Cargo.toml` file. You can explicitly tell the bot to do this as well in case you are concerned about a commits logically conflicting even if its not a git conflict.
What better way to demonstrate it than with some code: https://play.rust-lang.org/?gist=fe5c3974664d8391eb6db31abcba02e2&amp;version=stable This has some consequences. If you are writing code that is generic over a type T, and you have an immutable borrow to said type T, or you give an immutable borrow away to another function, you cannot assume it hasn't been changed.
I indeed had missed this wrinkle from Nikos post. Great to hear that there is a way out. One thing I don't quite like is the proposed syntax: something like `T specializes U` would be easier to read. I'm not sure if `T :- U`, `T :&gt; U` or `T :? U` would be as readable; it would sure be shorter to write and easier to switch specialization clauses to normal clauses and vice versa.
Your link goes nowhere.
Ah, yes... that's a perfect example! Don't use cell for keys... or use something like BinaryHeap which will reorder on key changes :) 
Right, you're correct about your assessment and the general tradeoff (the talk also agrees with this, although more from a correctness perspective). The example I had in mind (from the talk) where the C++ `[]` approach shines, is in implementing a counter: loop over keys, `[]` and increment the count. This is much nicer and faster than the Java counterpart, where getting (with default), incrementing and reinserting is a much larger amount of code (and slower to boot). Rust having `entry` means it covers that use case just as well.
Looks nice! I'll likely use this for the ruma-signatures crate rather than depending directly on *ring*. Do you anticipate API changes before a 1.0, or just more providers? I think I may have spotted a couple mistakes: 1) sodiumoxide's signer struct is documented as a provider for *ring* 2) yubihsm's signer struct is private.
Ah, I see you edited your comment. I adapted my BTree demo to also break BinaryHeap. https://play.rust-lang.org/?gist=6bc3f889632a146824191e81a7a5f209&amp;version=stable I don't think we need !InteriorMutibility. It's only a logic error. 
So basically we're taking the Swift route for this feature, syntax wise? I like that
Yeah. I thought I had used this in BinaryHeap, but of course that still wouldn’t work, unless you took a mutable reference to the key/Cell. So it’s a bug there too. I reviewed my code and edited the comment to drop that ;)
I knew it!!
That's exactly what you avoid by moving these transformations into the front-end, where you can control it independently of back-end optimizations. C++ did this for RVO, Rust could (I think) do it for placement new.
You may like swift’s way of handling that. When calling a throwable function, you have to use the “try” keyword. 
So, basically, [type roles](https://internals.rust-lang.org/t/blog-post-maximally-minimal-specialization-always-applicable-impls/6739/10) for Rust? :D
Yes, to be clear, I gave approximately 0 minutes of thought to the syntax here, and we'll definitely want to play with it.
50+fps on my 2014 macbook pro. i can walk through walls.
Some Rust computational frameworks: https://www.datafusion.rs/ https://andygrove.io/rust-is-for-big-data/ https://github.com/frankmcsherry/differential-dataflow
Looks really promising! Tried it on one a my bigger repos that have multiple sub-crates in it. Unfortunately that couldn’t be added, if complained that there was no Cargo.toml in the root. Is supporting multiple Cargo.toml projects in the same repo something that is on the roadmap? Would be really nice to have it, and ideally with a setting if it should create an upgrade PR per crate or single one per repository
To try to get to the heart of the matter, what I think you are being critical of is (correct me if I'm wrong): + In a language like Java, the type `T` of a value `x : T` says nothing about the exceptional cases, so `x` can be an exceptional case of any error condition even tho `T` says nothing about this. In Rust, we have `Result&lt;T, E&gt;` and you know precisely that a) there can be errors here, b) the set of values inhabitable in `E` are not all possible errors, but a limited specific subset. + Implicit propagation of exceptions. Rust indeed has exceptions - but they are reified and explicitly typed, and are ordinary values. What is different in Rust compared to Java is that we manually **propagate** our exceptions. With `try { .. }` and `?` we get manual error propagation, but in a syntactically light-weight way that blesses the happy path.
Trying to learn the language by developing a new approach to fuzzer development
I don't know if we have any representatives of Dependabot on here but they seem to take feedback via [github issues](https://github.com/dependabot/feedback/issues). The blog mentions workspaces are supported. A possible workaround is to create a workspace in the root of your repo?
Check out this Json parser using SIMD: https://github.com/pikkr/pikkr &gt; Pikkr is a JSON parser which picks up values directly without performing tokenization in Rust. This JSON parser is implemented based on Y. Li, N. R. Katsipoulakis, B. Chandramouli, J. Goldstein, and D. Kossmann. Mison: a fast JSON parser for data analytics. In VLDB, 2017.
Can you comment on how this compares to Berkeley's Ray project? I believe they actually started with a rust + zeromq implementation but switched to c++ for reasons of ecosystem maturity at the time.
Agreed! I mention this briefly in the post, but I'm reasonably confident that we can check for such cases and lint against them, essentially by comparing against a "naive" specialization to see if we get a different answer.
i think specialisation would solve the or-ing problem, because it would allow you to implement Collect for 'static for copy and for 'static+Copy, but i am not sure and it does not seem the current proposal for specialisation would cover it.
&gt; and the convention that all unsafe code must not depend on safe code doing the "right" thing. I don't think "convention" is a strong enough word, although I'm not sure what word is better. Although this is not enforced by the language, exposing unsafe behavior in a safe function is considered "wrong".
Latency is not important to me at all. Each task is just a simulation run with a different set of initial parameters (no sharing of data). I might have 10,000 parameter sets that I want to test on 100 servers with each simulation run/task taking a few minutes of number crunching.
into_mut consumes self since it isn't passed by reference: https://play.rust-lang.org/?gist=3b299dae19b83c99a2077b14347587ce&amp;version=stable
API changes should be largely additive at this point. Feel free to send PRs for those issues, otherwise I'll correct them soon.
What do you mean by you've been asked to read an rfc you authored once?
Right? :D
Does this mean any trait requiring `'static`, like `Any`, or any trait "extending" those, would never be usable as bounds in a specialized impl?
Never doesn't really work for me. :-( I could add trying to make a PR to my (long) todo list. Is there manual work to do for each one? I'd naively guess that given these are supposed to exactly match vendor intrinsics (as exported through LLVM), one could run a perl script or something that would generate the Rust file in question. Does it need to be complete before stabilization, or is it possible to stabilize some useful subset?
+1 for Python API
Thanks for the huge amount of work you put into that well written RFC! I am not in favor of repurposing the try. For one that it introduces unnecessary confusion with the old macro and things like "capture" or "catch" just fit better in my opinion because in my mental model we are capturing here and not trying. Trying is having a mental indirection. "try this block of code and in the event of an error capture/catch it" whereas if you stick with the capture/catch terminology you have something just like "capture every error here and preventing proper gating" this is explicitly better because the mental "trying" is implicit anyway! Every block of code (like a hole function body or a single statement) that returns a result is "trying" anyway. So by choosing "try" we omit the "real" thing what is going on - we are catching here - with a term that is implicit anyway and had a mental redirecting, at least from my point of view. TLDR; I am in favor of catch/capture and against try for various reasons. 
LOL
Sorry, what you mean by 'arrow'? As we are currently thinking about replacing capnpc with something else, your second question is still open for us:) At the beginning, we did some comparisons of RPCs including Thrift; Unfortunately, I did not remember exactly why we did not use it. Does it allow for bidirectional calls over one connection? I cannot see this by quick scanning of the documentation.
Why are you so opposed to feedback? Everyone's telling you the same thing but you're just ignoring it. &gt;onion
* maven has 'parent projects' where a subset of entries in the `pom.xml` project descriptor may be omitted and will be filled from the parent. I think this may be a good idea for setting up dependencies &amp; tasks, and has the benefit of not even needing to have then written out in the `Cargo.yoml` at all * tasks should be callable e.g. from `build.rs` as additional build steps and/or integrated with /u/Manishearth's custom post-processing RFC.
I am little bit aware of Python API for Spark, do you have something specific in mind? I would say that Rain also support "in-memory computation", since mapping data objects to a file system is optional. As long you do not need to execute external programs, a worker may hold data in its memory. Also keeping worker's "working directory" in ramdisk is one of intended use cases (some HPC installations do not have hard drives in nodes).
What's the intended usage? It seems likely that in the example the `rust-on-rails` would provide its own CLI, just because it's easier to get started with `ror startproject name` than creating a new bin from cargo, adding the a task crate as dependency and then calling `cargo task startproject name`. I would like having a tasks dir or similar in my project where individual files are added as a task to cargo though
Instead of introducing a new keyword, why not just declare a break label that references the enclosing function, say `'fn`, then: * `return x` is just sugar for `break 'fn x` * `try {}` is simply a labeled block that uses `'fn` as it's label. Obviously, the label `'fn` would be up for debate, maybe `'`-itself or `'try`.
This only works for `let a &lt;- b`. The moment you have to go through n function calls from the expression whose result should be boxed to the place where the placement box actually happens... you need at least to be able to inline through all of that.
I really like the first idea. It is awesome to be able to have binary dependencies... It always felt wrong that you were forced to `cargo install` some tool to use some library/framework... its version not being tracked in in Cargo.lock and if you have two projects that require two separate versions you are in bad luck as well... &gt; A while back I proposed metapackages as a way of grouping and versioning a set of dependencies. But in my chat with @wycats, we had the insight that metapackages could more generally be a way of abstracting a chunk of Cargo.toml, including not just normal dependencies, but also tasks, build scripts, and more. How well will that interoperate with `extern crate` deprecation? More specifically, if `extern crate` is deprecated, Cargo.toml will be the only place where you'll have a list of dependencies available. But with this proposal that list would get factored out to different places. Is this really what we want? Why not: * let people do `pub use` of crates * having a special setting that provides binaries to users of the library
Why the sad face?
It's not a sad face, it's an upside-down smiley face :)
don't you lose all the benefits like caching etc if you naively hosting the static bundle.js through your rust web framework instead of using nginx?
Thank you :-) its very encouraging !
I personally find tasks too similar to cargo subcommands. Maybe what we need is a way to set cargo subcommands that must be available in the `.cargo/config` file of a project, and for cargo to automatically install those on first usage. This could allow you to override system-wide components.
Ah, you've come to the right place then: Reddit, where we bikeshed minutiae for hours, even if they are not yet of importance.
One way to reduce verbosity is to define aliases in `.cargo/config` for particular tasks. For example, by adding [aliases] foo = ["tasks", "foo"] you can type `cargo foo` directly. Implementing some sort of "automatic" aliasing would be cool as well, though it is unclear how that would interact with custom commands. `.name` proposal seems neatly weird! :-) &gt;The way I'd always imagined this feature was having a scripts directory, where each .rs file was automatically available. I think the "embedded dependencies" bit is tricky here... OTOH, you totally define tasks in a local package: Cargo.toml src/ lib.rs tasks/ Cargo.toml src/ bin/ script1.rs script2.rs script3.rs That is, you need some constant up-front scafolding to setup tasks, but, after that, adding a new tasks is just adding a file to `tasks/src/bin`. I personally very like the idea that tasks are full-fledged packages: that means you have access to the crates.io ecosystem using just dependencies, you can abstract shared functionality in a `lib.rs` task library, and you can even tests your tasks! 
&gt; `.name` proposal seems neatly weird! I mean, any prefix that is very unlikely to already be in use would work. To my mind, it's really no different to `rustc +version ..` as a shortcut for `rustup run version rustc ..`. Presumably the reason the developer wants to use tasks at all is because they're frequently used, and if they're frequently used, they should be as quick to access as is reasonable. &gt; I think the "embedded dependencies" bit is tricky here... [Embedded manifests have been a solved problem for ages](https://github.com/DanielKeep/cargo-script/#scripts). &gt; That is, you need some constant up-front scafolding to setup tasks, but, after that, adding a new tasks is just adding a file to `tasks/src/bin`. &gt; I personally very like the idea that tasks are full-fledged packages: ... All of those things you can do with standalone scripts just fine. If you need just a few, relatively simple scripts, a whole package is kinda overkill.
I tried this, and the results were very surprising. Before I even tried Valgrind out, I ran the program after compiling it using the system allocator rather than the default jemalloc. When I tested it, the memory leak didn't occur. Switching from jemalloc to the system allocator fixed the problem entirely... I'm still unsure as to whether or not this is a problem with jemalloc, musl, Rust, Rocket, or some combination of those things. My (uneducated) guess is that it's got something to do with the linking process, but I really don't know. Do you think this warrants an issue opened up on the Rust Github? I talked with SergioB who created Rocket and he helped me though this a bit, but I don't think opening an issue on Rocket's end is the right move. Btw, thanks for this suggestion; I wouldn't have found this if not for it!
A nice technical benefit of tasks, declared in Cargo.toml, as opposed to custom subcommands and custom cli tools, is that you only need cargo to invoke them. That is, you can clone the repository and invoke `cargo task foo` right away, without installing anything else. For new projects, this would work nicely with proposed addition of templates. You do `cargo new --template rust-on-rails`, and that setups tasks and dependencies for you. That said, I agree that a dedicated `ror` utility might be a better user-experience for something like an all-encompassing web framework. At least for me, the main reason for tasks is not to provide framework-specific workflows, but to implement project specific automation. When I develop projects in any programming language, I often need a way to automate some part of my workflow. I usually solve this by writing a short bash script, but this is not cross platform and pretty limited. With tasks, which you sort-of already could use, if you combine [enough hacks](https://matklad.github.io/2018/01/03/make-your-own-make.html), you will be able to write this automation in Rust, and the sky is the limit to what you could do. Just imagine using serde in your "bash scripts" :-) 
That example does not work for me and after a quick try with that and I could not get it to build (which is probably why - don't have time now to get it to build). Try this instead: fn func(value: i32) -&gt; i32 { value * 2 } fn main() { let value = 0i32; println!("{}", func(value)) } If this works then your setup is correct and it is something wrong with the project.
Sorry I'm not a web expert. What exactly is nginx doing when caching? For simple static file serving, having the response in the binary may be faster than fetching it from filesystem.
I wasn't able to reproduce the issue with trivial allocations; the only way I got it to occur was with Rocket, and the issue didn't come up when using the local client. I don't see any calls to `free` in there, which doesn't really mean anything on its own but... maybe? I really don't know. I wasn't able to get Valgrind's memory leak profiler to work with jemalloc enabled, and when I switched to the system allocator as suggested by /u/WellMakeItSomehow the leak went away.
The full output was rather long, but the constant memory usage seemed to indicate my example wasn't leaky. So it seems that valgrind just doesn't play well with jemalloc? 
How does this tool compare to Apache Airflow? It seems like it targets a different use-case (Airflow: repeated scheduling versus ad-hoc jobs for Rain), but I'd still be really interested to hear your thoughts.
Unfortunately, given `struct try {}`, then `try {}` would be ambiguous - so reserving the keyword is not so much about semantics as it is about syntactic ambiguities, so we have to reserve a keyword, or go with `do try { .. }`.
This is amazing. It was only 2 weeks ago that I was lamenting the fact that there was no easy way to interface between arrow and rust. And now there is a native rust implementation. 
Yeah, that's not too surprising. I couldn't get Valgrind to detect jemalloc allocations myself, and the only workarounds I could find mostly involved stuff like building Jemalloc from scratch with debug enabled or something similar.
Thanks, and no collision detection implemented (yet) 
Understood, but I'm suggesting abandoning the `try` syntax entirely and just using a designated block label, eg.`'fn: { f()? }`.
`free` doesn't show up because `callgrind` shows what's taking most time. It's quite likely that `jemalloc`'s `free` is fast enough that it didn't get included in the log.
The other big difference between Rain and Airflow (and e.g. Luigi) is that Rain provides own transfer of data objects between workers. Rain allows to map data object to a file system; however, it does not use shared file system and transfers data by itself. This allows to create lots of short running tasks without hammering a distributed file system.
No. The embedded server is able to serve the assets with the same caching headers and honor conditional requests the same way that nginx would. 
I am not familiar with Ray; I will try to answer after reading their paper.
I believe that only primitive types are supported at the moment, but I'm with you. This is extremely exciting!
How stable do you find the `capnp-rpc` crate to be? I'd like to replace a `protobuf` over `0mq` pub/sub and RPC combo with `capnp-rpc` but stopped when I saw that support for capnproto is anemic non-c++ platforms. 
&gt; By default, lifetime parameters would be parametric and type parameters would be non-parametric &gt; &gt; [...] &gt; &gt; If a parameter is parametric, not only can you not specialize on it, you can't pass it to other generics in a non-parametric slot. Wouldn't that be a breaking change? There's nothing stopping you passing a parametric-in-your-proposal argument to a non-parametric-in-your-proposal slot right now, is it? Or am I missing something? I guess the the same solution as in /u/aturon's post could be used here, that is, opting-in to all that by using `specialize` keyword somewhere and ignoring impls that do not conform to the rules.
why is this taking the Swift route? As far as i understand this, Swift try is working very differently, first it more resembles the `try {} catch {}` methodology but they changed it to `do {} catch {}` and annotate every occurrence of an possible error with `try` which is basically Rusts `?`/`try!()` inside the do block. 
A good example would also be diesel: diesel has a CLI for managing your database, but you should make sure that the _version of the CLI_ matches the _version of your project_. You may also want multiple installs, if you have multiple projects with differing versions. Tasks provide that, by binding the tooling to the project, cargo install doesn't.
For completeness, let me mention [`Iterator::sum()`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.sum) already in the standard library. It lets you do for example [`vec![1,2,3\].iter().sum::&lt;i32&gt;()`](https://play.rust-lang.org/?gist=ac82fb4962d83b27966a5bd481a5133b&amp;version=stable).
Thanks for the elaborate reply! Interesting to hear Niko's reasoning about that. I thought he was more leaning towards `catch` from my memory to be honest or maybe it is just outdated and he changed his mind. Anyway. Point 1-3 are very subjective and the reasoning on both sides are very understandable. Point 4 is interesting on its own because 1. i very much agree with you here. But the question is if we want to go that rout anyway and basically copy Java/C#/C++ here 100% and stick syntactically 100% with how exceptions are handled even though we are doing semantically a very different thing – with no way to indicate that. If we do a different thing in Rust i think its fine to handle it differently – and by that i mean to be open to other (potentially better) solutions than what other languages are doing. Especially in the case of wrapping function i find fn fun1() catch { } very compelling because it would resemble the "thing" we already do (in the case if we choose catch) how does it look with fn fun2() try { } and what if we expand this to "catch" handlers? Anyway i don't want to look to much on not yet decided elements of the language. 
&gt; At least for me, the main reason for tasks is not to provide framework-specific workflows, but to implement project specific automation. Totally agreed. In Django/Flask, I have my `manage.py` where I can add subcommands as I want. It's nice to be able to register some subcommands from crates (like https://github.com/django-extensions/django-extensions adding `shell_plus` etc) but the project specific ones are much more important for me. 
I think this one needs to be valid: impl&lt;'a&gt; Trait for Foo&lt;'a&gt; where specialize(Foo&lt;'a&gt;: OtherTrait&lt;'a&gt;) {} What other lifetime could you provide to `OtherTrait` in this context? The second one, I think has to be invalid. Consider that impl alongside another one: impl&lt;T&gt; Trait for Foo&lt;T&gt; where specialize(Foo&lt;T&gt;: OtherTrait&lt;T, T&gt;) {} impl&lt;T&gt; Trait for Foo&lt;T&gt; where specialize(Foo&lt;T&gt;: OtherTrait&lt;T, u8&gt;) {} For `Foo&lt;u8&gt;` it would still be ambiguous which impl of `Trait` to pick.
What's the difference between serde and serde_derive? It is not obvious from the documentation.
I just did a re-read and saw this line: &gt; the ability to direct cargo new to start with a custom template defined in crates.io Depending on crates.io for a template seems like a bad idea. Repository/folders are much more suited as we are dealing with files, there's no point wrapping it up in a crate as far as I can see.
Don't you have another yak to shave? 😁
As it turns out, `Cell` really is that easy :)
Yes, I'm aware of this, my question is still unanswered. Why does `get_mut` exist? In what scenario do you _not_ want a reference with the lifetime of the map?
I'm a bit confused, given the number of choices in both RFCs, what is being proposed here. Is this correct? try { let mut file = File::open("/etc/hosts")?; let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; let parse_result = my_parse_fn(contents)?; } match { Ok(v) =&gt; println!("Yay {} ", v), CustomError(e) =&gt; println!("Boo") } With the `CustomError` in the `match` block definining the type of`From` implementations to use for io::Result and my own custom parse result?
Ruby uses catch in a similar way and as far as I know there is not much confusion, and the difference between Ruby's `begin` + `rescue` + `raise` and `catch` + `throw` was obvious after seeing it once.
Capnp-rpc actually serves us quite well at the moment, the rust crate works fine (apart from minor [#93](https://github.com/capnproto/capnproto-rust/issues/93)) and it performs well, but the integrations with other languages are less developed (e.g. the Python interface is not very pythonic, no Java or browser JS). My feeling is that the design idea is great but perhaps a bit too ambitious, and the support in other languages varies. And we also hit the 64MB message limit of capnp ([here](https://github.com/substantic/rain/issues/8)). 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/capnproto/capnproto-rust/issues/93) - Previous text "#93" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dwwmcmp) 
It is wise to postpone asyncio until the tokio/futures dust settles this year. Thank you for writing the Thrift-rs implementation! I'm not familiar with the issues people have had with Capn-proto, are you? I think that lack of support was one issue. The Rain folks may be able to help shed light on others. 
The problem with terminal one-liners is that they are platform-specific... If you are ok with this, you can probably write a one-line bash script?
Great! Please drop by in on GitHub https://github.com/rust-lang-nursery/rand. Just open an issue or comment on something and we can go from there. The methods that we ended up with in the `Rng`, `RngCore`, `SeedableRng` and `Distribution` traits have seen such a large amount of discussion that we would not get exited with another round t.b.h. Methods could be added though. The documentation of the [master branch](https://rust-lang-nursery.github.io/rand/rand/index.html) is basically how these traits should look like. What I am currently interested in exploring is more [sampling algorithms](https://github.com/dhardy/rand/issues/82), [SIMD support](https://github.com/rust-lang-nursery/rand/issues/377) and improving different areas of our [`no_std`-support](https://github.com/rust-lang-nursery/rand/issues/313). And please tell what was to obstacle that made it easier to do things by hand.
I kind of feel like a nicer way to deal with that would be to drop the `Any: 'static` requirement... or I guess since that would be backwards incompatible add some parent trait that doesn't require it. I am still not sure why it's necessary in the first place; anywhere you can use `Any` (references and Box) already makes you add an explicit lifetime if it's not `'static`, so the only real issue is that there's no easy way to find reasonable lifetimes when you downcast, and you can solve that problem by requiring `'static` on the downcast method instead of the trait. Is there any other interesting trait with that requirement?
This is what we initially believed, and is why (many of) the intrinsics started out their life as safe functions.
You can contribute them to stdsimd (did you see my sibling comment?): https://github.com/rust-lang-nursery/stdsimd Each intrinsic usually has at least one hand-written unit test and a codegen test.
This is flattering. :D Thanks! However, I didn't do any of this in Coq, so I'd call this more like a sketch of a formal model. Still, it makes me reasonably confident that I could build a formal model along these lines, and that's about all I can do right now time-wise. Too many things to prove, too little time...
No, the proposal does would only permit the first part without the `match`. You'd have to rewrite that as: ```rust match try { let mut file = File::open("/etc/hosts")?; let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; let parse_result = my_parse_fn(contents)?; } { Ok(v) =&gt; println!("Yay {} ", v), CustomError(e) =&gt; println!("Boo") } ``` The `try { .. } match { .. }` idea where `match` constitutes the handler does seem quite interesting tho. I could see that being done as future work.
I don't think this was ever supported in `std::fmt`, but in the meantime there is a [pretty-hex](https://docs.rs/pretty-hex) crate
Does anyone know what the equivalent block cipher for the following Java is? import javax.crypto.... cipher = Cipher.getInstance("AES/CTR/NoPadding"); cipher.init(Cipher.DECRYPT_MODE, new SecretKeySpec(cipherKey, "AES"), new IvParameterSpec(iv)) I've tried extern crate crypto; let mut cipher = crypto::aes::ctr( cipher::aes::KeySize::KeySize128, cipher_key, iv, ); as well as 192- and 256-bit keys, and none of them give the same en/decryption results given the same cipher key and IV. This might be slightly off topic for /r/rust, but this is frustrating the hell out of me.
Also: in practice it is relatively unlikely that a group of, say, five different servers in very geodistributed datacenters, which are being actively monitored and replaced if they crash, will find themselves unable to form a quorum (unless there's a problem with your application or deployment script, in which case choosing a different isolation level probably won't help). Doubly so if you have another instance of consensus running inside each of the datacenters (since wide world networking failures and in-datacenter networking failures aren't so strongly correlated). Obviously, there are circumstances where you really will become unavailable even then (someone attacking internet infrastructure, for instance) but in most cases you can get to the point where problems other than network partitions dominate any shortfall in your availability SLA. You may not be willing to pay the latency price, though...
I wasn't going to mention PyO3 since I though that the request was for something like SWIG which could generate multiple bindings with minimal duplication of definition, but, since you mentioned it, I might as well point out that if PyO3 is being considered, [rust-cpython](https://github.com/dgrunwald/rust-cpython) also should be. (PyO3 is a fork of rust-cpython in the name of providing a more comfortable API at the expense of requiring nightly, but rust-cpython is still quite comfortable.)
You can do emplacement without generics (trivially, C++'s constructors), but yes, having thought this through a bit longer my approach doesn't seem trivially feasible. In essence the problem is that RVO can be non-optional, but placement new requires pointer indirection which can be inefficient. Ergo you need two different "forms" of structure in the fully general case. However, it does seem like the overhead would be negligible in precisely those cases where it is important (large return values), so I'll have to think about this a bit more.
What I dislike about this is that it is hard (or misleading) to tell which `impl` will take effect.
Missed that, thanks!
Big +1 on this or something like this. This is definitely a real pain point, where at $work, one of us might have v1 of a codegen tool while the other might have upgraded and got v2, which might produce different codegen. The result is a ping-ponging back and forth, or worse, a reintroduction of bugs that one dev thought was fixed by uprading to v2. We will probably try to fix this using our own tooling, but it would be great if the package manager took care of this for us. (This is not for a Rust code base, but the same principle applies.)
Use `get_mut` if you want to keep the entry alive to maybe reuse it later. Otherwise use `into_mut`.
RE Tasks One piece of prior art here is [`Pipenv`'s `shell` and `run`](https://docs.pipenv.org/#other-commands) subcommands. One advantage of this approach is that if a user chooses to drop into a subshell, they don't need the `tasks` prefix. On the other hand, to to run a cargo subcommand without dropping into a subshell gets nasty `cargo run -- cargo foo`. RE Metapackages I have experience with a proprietary build system that we've built up a convention like metapackages, we call them "sdk"s. Our build system is based on `make` and we built metapackages/sdks out of - Injecting dependencies into clients. - Injecting make logic into clients. Its a feature we don't use frequently but from time to time has worked quite well. We don't yet have the concept of `tasks` (working on a pipenv-like system right now) but this does make me realize we might not have a way to choose it as a build vs dev vs task vs regular dependency.
before you had `serde = {version = "0.3", optional = "true"}` in your Cargo.toml, and `#[cfg(feature = "serde")] extern crate serde;` and `[cfg(feature = "serde")] impl ...` etc in your Rust code. With the extern crate deprecation you will have: `serde = {version = "0.3", optional = "true"}` in your Cargo.toml, and `[cfg(feature = "serde")] impl ...` etc in your Rust code. The only thing that changes is that extern crate is gone. Before, Rust would only link in a crate if it was mentioned by extern crate somewhere in the crate. In the future, it will only link in a crate if you `use` it. So if you have a crate in your cargo.toml that you don't use, it will still not be linked in.
Thank you for pointing to Arrow, I was not aware of it. Rain core infrastructure operates over blobs so it does not need to know internal format of data. However, we provide some helping methods (e.g. deserialization) for known "content types" in Python binding. It seems that supporting Arrow in this place could be useful.
On their website they call themselves patriotic mad scientists and are lamenting the end of Cold War as an unfortunate stumbling block for innovation. What do you think they are doing?
The question is, why doesn't `get_mut` return a reference with the lifetime of the map in the first place?
&gt; You can do emplacement without generics (trivially, C++'s constructors), In C++ all functions that do emplacement take the constructors arguments and forward these using generics until the place where the object is actually constructed, which is what happens "in place". If you have: // a.hpp struct A { unique_ptr&lt;array&lt;int, 40960&gt;&gt; a; A(array&lt;int, 40960&gt;&amp;&amp; a); }; // a.cpp A::A(array&lt;int,40960&gt;&amp;&amp; a) : a(make_unique(std::move(a))); // b.hpp #include &lt;a.hpp&gt; struct B: A { B(array&lt;int,40960&gt;&amp;&amp; a) : A(std::move(a)) {} }; B foo() { return B(array&lt;int, 40960&gt;{}); } The call to `foo` blows up the stack. Note that `A::A` just takes a reference (a pointer) to a temporary, and it is compiled independently of the translation unit `b`. Also note that `b` has no idea of what `A::A` is going to do with the object, that's completely opaque. The way all placement methods work in C++ is that you tell the method (or it already knows) the type of the object that is going to be constructed, and you pass it the arguments to its constructor, which get forwarded, until the object is constructed in place. If the argument is the object itself, then you are going to create a temporary first, and then emplace that temporary into the final location (like in the case I showed above). For example: struct A { int i, j; }; std::vector&lt;A&gt; a; a.push_back(A{}); // constructs A, then moves it a.emplace_back(A{}); // same as a bove, a.emplace_back(3, 4); // ^ constructs 3, 4 on the stack, then forwards them, // and then constructs A{3, 4} in place.
Could you clarify what you mean by “bidirectional calls over one connection”? I think what you’re saying is that regardless of which node establishes the connection, the ‘client’ can change for each request?
Just a thought, but Rhai provides scriptability with a lightweight, pure Rust crate with no dependencies. Very easy to add Rust functions and even custom types.
Are the missing types planned (or is their representation feasible in the Arrow protocol)?
[removed]
No worries! I can always find a new one before I publish :)
To be honest, these types aren't urgent for my needs right now as I have everything I need with structs and primitives but I definitely would like to see them added. The next priority for me in Arrow would be implementing the IPC mechanisms and testing interop with other languages.
 B foo() { return B(array&lt;int, 40960&gt;{}); } This blows up the stack because the argument isn't being emplaced, not because of the later call to `B`. You can emplace manually with T *memory = malloc(...); T *foo = new(memory) T(); This isn't generic, it just passes `memory` as `this` to `T::T`. Fundamentally that's all emplacement is; the example with a vector is just that the memory is allocated by the vector instead of a call to `malloc`.
Great to know, thanks. I am currently interfacing with a tick database written in another dimension in C# and python, and I am going through a thin rust wrapper using FFI / PYO3, and was considering introducing a broker and using `capnp-rpc` to send each column / dataframe over the wire. I might reconsider now, and just use serde + tokio.
What if you always had to give a name? For example you could have [tasks.ror] rust-on-rails = "0.2" which is run by `cargo ror server`, etc. This also solves the problem of importing two task crates that both provide a "server" binary. However, I also like your idea of a completely separate namespace, `cargo .name`. Any scheme that adds a ton of `cargo xyz` risks collisions with `cargo-xyz` that people have set up on their own systems. It's going to be annoying to check out someone's crate to make a PR and have your muscle-memory cargo command do something different. 
Thanks for staying in top of these new abstractions Ralf. I imagine this will find its way into the next paper? I hope this come to a future publication and that research continues.
I mean that both sides can simultaneously post multiple requests to other side, i.e. both sides are simultaneously server and client at the same time.
I see it now. Thanks!
I see. No: they can’t do that on the same connection. But you can do it on two connections: both sides open up a server socket and accept a client connection from their peer. Edit: does any auto-generating tool support this? From what I recall, neither grpc or protobuf services do, but I last checked a while ago.
One thing that I haven't seen mentioned in a while is a libc 0.3 release. This has a lot of breaking changes and needs a driver. It is a crate that's normally pretty low in the dependency tree, but it hasn't had enough of a dedicated driver to get a 0.3 release out the door. Were there any discussions about libc and just nothing came of them or does this crate fall outside of the working groups and likely won't get much resolved this year?
Because it *can't*. It doesn't own the map (and thus may not borrow from it), only the Entry. Hpwever, the Entry itself *is* actually little more than a borrow in the map, so it can be changed into one.
This is trivial in capnp. You can exchange handles on remote objects and call methods on them, regardless where they reside. So for the described scenario you just need to exchange two handles.
It's true yeah that libc 0.3 and/or 1.0 hasn't come up in awhile. I was personally under the impression that there's not much impetus and the priority is pretty low, but can you detail the breaking changes that you're worried about or would like to see?
I am using the APIs of my bank that have been implemented as a consequence of [PSD2](https://www.youtube.com/watch?v=AF-8v3yG4Pc).
Sure, but that's the solved part of the problem and Rust can already do that with `box`. The whole `Placement` discussion is about adding a way to abstract over it, so that you can have the expression that creates the value to be logically far away from where the value is actually emplaced, so that you can write `Vec::push(expr)` and the result of `expr` is constructed directly on the heap allocated memory without using any temporary storage, similar to how `vector::emplace_back` works in C++. This is the hard problem.
Wow, [doxidize](https://github.com/steveklabnik/doxidize) looks great! I knew there was an update coming to `rustdoc` that would make it easier to include stuff like guides, but I didn't expect a rewrite from the ground up! How will this interact with docs.rs?
Do the two handles correspond to the creation of two connections? Or do they reuse the same connection under the hood?
Sounds really awesome. So sad I couldn't join you folks. At least there will be RustFest in a few weeks.
I would consider capnp for a c++ or even Rust project with very involved RPC with remote objects, promise pipelinig etc, but for rust-rust messaging, serde+binpack (or anything similar, possibly tarpc) seems enough. Good luck with the project!
&gt; How will this interact with docs.rs? Open question. That's something to figure out once it's actually usable.
Hi! I am not sure I get the question - do you mean some particular code? In any case, in Rain there is only one socket for client-server and only one for server-worker and every worker-worker pair.
Understood - TY!
I like the auto-aliasing `cargo foo` with the option of fallback to `cargo .foo` if there is a naming conflict. Especially since `.` means "current directory" in in the *nix's speak I like that kind of means "current project/workspace" in this context. This would mean there's two options to disambiguate global/local where if `.foo` means local, naturally `..foo` could be global? Upon conflict the UX could be as simple as: $ cargo foo error: command 'foo' is ambiguous and exists both locally and globally To use the workspace local 'foo' $ cargo .foo To use the global 'foo' $ cargo ..foo There's other options like no aliasing and requiring `cargo task foo`, or allowing inference such as `cargo ta foo`
So for some reason it deleted my configuration and had to recreate it. In doing so I noticed that when you first add a project, if you expand "Advanced", there is an option to set the project root within the repo.
Thanks for the clarification. `match try` already seems readable to me. I do like that Rust keeps syntax and sugar to a minimum. I wouldn’t like to add too much magic. 