In a small problem like this, that is a valid suggestion. In general though, both for sanity and for testability, you don't want to mix you side-effects in that much. The more and longer you can work with pure data, the better.
It was binary at first (hacking, I'd say), but now I'm organizing it and later, I may share some parts as library. This is still in development.
Thank you for information!
You're looking for /r/playrust
Ok thx
I've done done anything GUI-related in rust, but libui-rs looks pretty interesting.
Like any style question, on some level, when you have two equivalent things, you end up picking one. There are reasons to pick either one; we chose line comments.
Add `mod window;` to your `main.rs`. Then, in `main.rs`, you can either say `window::Window` to access it, or add `use window::Window;` and then just use `Window`. For more, see https://doc.rust-lang.org/stable/book/crates-and-modules.html or https://github.com/rust-lang/book/pull/142
One does *not* simply *return* an Iterator... Well, I mean, until now...
Not bad considering I never bothered to benchmark or try to optimise it. :P That said, a fairer comparison would be against 64-bit LDC, but it's good to see they're all in about the same ballpark.
Now look what you've done...
Done. (if the newly minted minor dieties, other mods, or general riff-raff would like it reverted, please let me know)
Does it come with a shrine for people to toss coins into? I could use the income...
Tokens, not coins :P
Thanks. But what if my `window.rs` needs to use macros? `rustc` says I can't use `#[macro_use]` in a file other than the root, but I need to use it in `window.rs`.
I'm personally not a fan of javascript but I figured since it was one of the most widely used scripting languages there would be demand. Plus most of the best UI I've seen is done in html/css. Unfortunately the ecosystem is so hacked together there's no way to use it without the bloat of a full web browser. Plus the three different js libraries that are apparently needed for the most basic of projects. I really should have written this down elsewhere, but I was going to make a Pango or QML bar with Lua anyway. The bar is an extension anyway and will be totally swappable.
/u/erickt has [a prototype called `stateful`](https://github.com/erickt/stateful) of a syntactical state machine transform and [this blog post](https://erickt.github.io/blog/2016/01/28/stateful/) mentions how the main cost is that of boxing to return the iterator, which is... no longer necessary :). So yeah, feel free to add a nightly mode to `stateful` that uses `-&gt; impl Iterator` and you'll have the first version of crude (but working) generators in a post-1.0 world.
I have read in multiple places that a function which does not contain any arguments cannot return a `&amp;str`. Why is it that this code actually works? I would have expected `foo()` to return a dangling pointer: fn foo&lt;'a&gt; () -&gt; &amp;'a str { let val: &amp;'a str = "World"; &amp;val } fn main () { let baz: &amp;str = foo(); println!("Hello {}", baz); } Thanks! 
It's coming! I first need to finish cleaning up how expressions are returned from one state to the next for async/await. Then I'll play with impl trait :) People need to stop distracting me with cool things so I can actually get a 0.1 out the door!
Do you even need that annotation? I don't write many macros, so I always forget the rules, but I thought `macro_use` was to import macros from another crate.
Ah, ok. So, I suppose that would explain why this does not work: fn foo&lt;'a&gt; (x: String, y: String) -&gt; &amp;'a str { let r = format!("{} {}", x, y); let val: &amp;str = r.as_str(); &amp;val } fn main () { let baz: &amp;str = foo("Hello".to_string(), "World".to_string()); println!("{}", &amp;baz); } Thank you much for your help.
Exactly! You're welcome :)
The functions are monomorphised exactly the same as they'd be if you were explicitly stating the return type. See https://is.gd/eo860M as an example. `function` would be monomorphised the same (with one copy for `i32` and one for `&amp;str`) if I had said the return type was `T::Bar` instead of `impl Bar`. You can generate the LLVM code to see the two versions. The associated types in the example serve the same purpose as fundeps, but I believe they're closer to Haskell's type families.
Oops, yes I suppose I was both confusing and a bit over zealous there. If it had been written in C we could have done something similar, using a pool and handle system similar to how wlc works in order to implement the adjacency list. What I meant to say was it would have been more difficult, even if we a library that existed for that specific purpose. Pet graph, though it is very simple, has been adapted by others to build trees in rust and in many ways I find it a practical solution for Rust. C, with its decades of libraries might have something we could have used. Rust, despite being very new and having so few libraries, has libraries that are both flexible enough to use in creative ways while also being easier to use than C's. So I probably should have said something like "despite the immaturity of Rust's ecosystem, the existing tools are very versatile and well documented enough to work as good as, and perhaps even better than, am equivalent library in C" Thanks for pointing out this glaring error :-) EDIT: I have updated the blog post, so for confused time travellers, that was the previous, very wrong quote and I have since rectified it thanks to /u/nemaar.
Oh absolutely, and that's what eg pet graph uses under the hood. For trees, which can be considered a subset of graphs in this case, the ownership model can get a little more complicated when you want a way to traverse back up the tree while being able to mutate it 
Yeah I know petgraph uses indices, big fan of the lib. Only meant to say that I wouldn't even if each for Rc (or references in other langs) for my graphs in the first place. At any rate, it's a great write-up for some of the reasons you shouldn't reach for references (pointer chasing and many small allocs is another reason, in perf critical code)! Oh and also wanted to point out that, at least strictly speaking, trees are precisely the graphs that rust's static ownership model doesn't struggle with. It's the addition of parent pointers (which graph-wise introduce cycles, therefore stopping the graph from actually being a tree) that makes your case problematic. Not sure I understand exactly what you mean about ownership being complicated by mutation when iterating child to parent. I guess deletion and index invalidation gets tricky (which is why relying on an abstraction like petgraph is a good idea!) 
This is a LOT faster than current rust implementations, and even faster than libwebsockets (see https://ws-rs.org/)
Just to be clear: I didn't mean to say "just read the docs", but I realize that it may look like I did. What I mean was rather "don't forget about the docs, they are also useful". It's sometimes too easy to get stuck in the wrong mindset and not realize that it's hard to communicate certain nuances through text. Sorry about that. Your questions and requests are completely valid and I understand that the mere size of gtk-rs may feel overwhelming. The only advice I can really give is start small and work you way out from there. There will be a lot of other things to learn if you are new to Rust, besides gtk-rs. Good luck!
I much prefer the enum solution to the dependency injection solution. That's still easier to test and understand IMHO. But I guess the polymorphic function can specialise and inline the displayer, making it more efficient :/
If you don't plan to delete nodes, why not just use a TypedArena? If you do delete nodes, you have the issue of keeping track of "holes" in the Vec.
A TypedArena avoids the tiny allocation problem.
I'm trying to do that but still don't know how :p
I had this implemented last year, but it's not in the RFC. I need user pressure to actually get this feature in. To be clear, on the trait side you'd have to use an associated type, but you could plug in `impl Trait` in some or all of the implementations of that trait (via the associated type).
I'm actually more interested in the non-associated type form which lets me basically hack in HKT. &gt;:) The RFC as it stands makes sense. The ability to return unboxed closures is an important win. 100% of my uses are in traits though, so ¬Ø\\_(„ÉÑ)_/¬Ø I will write an RFC eventually.
I was using the mobile app and couldn't see all the stuff indicating that this was the wrong sub reddit. 
1. `impl Trait` in a `trait` is just sugar for an associated type, you can do it today 2. HK(A)T will not happen without HKT - this is one of the reasons we're not adding the `impl Trait` sugar for associated types in `trait` definitions, before we know what the HKT story is going to be You can emulate HKAT by putting the associated type in another, more generic, trait, e.g.: fn map&lt;F&gt;(self, f: F) -&gt; &lt;Self as IteratorMap&lt;F&gt;&gt;::Output where Self: IteratorMap&lt;F&gt; { IteratorMap::map(self, f) } The only thing missing for the emulation to work well in all cases (with only syntactic overhead) is "type HRTB", e.g. the ability to write `I: for&lt;F: FnMut()&gt; IteratorMap&lt;F&gt;`.
&gt; Rust has the ability to be written in a beautifully functional style I think I'd like to disagree with this claim :) Personally, I'm not sure such an introduction would be very useful for Rust. It'd be something along the lines of "ignore all these things in Rust that make it useful and focus on /these/ few features". Most of Rust is dealing with resources (especially memory), which is something decidedly *non-functional* in character. The one thing I can think of is intelligent use of iterators, but even that is functional only shallowly.
You do have a point. The type system is really nice though. And it has lambdas. In my admittedly simplistic view, that should be enough to write some pretty code.
&gt; impl Trait in a trait is just sugar for an associated type, you can do it today Not with unboxed closures you can't.
It‚Äôs also important to bear in mind when designing these things that you *must* not depend on a destructor for memory safety; leaking memory is defined as memory-safe. Your `Node`-with-a-`*mut Node`-parent-which-is-nulled-in-that-parent‚Äôs-destructor approach is probably memory-unsafe because of this (though I haven‚Äôt actually looked at it closely).
You're referring to `impl Trait` in a `trait` `impl` which is orthogonal to `impl Trait` in the `trait` definition, *unless* you have a default body, in which case it's both, combined.
Borrowing is mostly just you creating a pointer to some data. Rust disallows Mutation + Sharing to ever happen at the same time, so there's mutable borrowing (&amp;mut T) and shared borrowing (&amp;T). When you are borrowing you are creating a so called "reference". It compiles to the same code as a pointer, but it has additional semantics that the compiler enforces. One of them is that you can't have any other references to an object when you have a mutable reference and vice versa you can have as many shared references as you want as long as there's no mutable reference at the same time. Also &amp;T isn't actually the full type. The full type is &amp;'a T. The 'a is a lifetime. You can think of it as some kind of generic parameter of the type. The interesting thing is, whenever you create a reference, it "generically" assigns the lifetime of the object to the reference. This generic lifetime "type" can then be tracked by the borrow checker similar to a type and checked for "type errors". So if you try to return a reference to some local variable, the lifetimes won't match up and the compiler will complain. So it's similar to a generic type, but it tracks how long the original object is still valid and stores it in the type, so it can be checked elsewhere. So if you want to store a reference in a struct, you obviously shouldn't be able to use an object of that struct for longer than the object you are referencing. So you introduce a lifetime just like a generic `struct MyStruct&lt;'a&gt;`, and then you use that lifetime on the reference as well `my_reference: &amp;'a u64`. You can read this as "The lifetime of MyStruct is limited to the lifetime 'a of the u64 that we are referencing". That way the programmer and the compiler will understand that relationship. When you are creating an object of the struct, it will then automatically infer the generic lifetime parameter 'a for you based on the reference you are using. Most of the time you can just use &amp;T however, as in most cases the compiler can "elide" the lifetimes with reasonable defaults. This is different to "infering" though, as the compiler will just guess which lifetimes are related. So if you have a function that takes a reference as a parameter and returns a reference, you could specify a generic 'a lifetime and give it to both to indicate that the reference you are returning is based on the parameter and therefore is able to live just as long. However this is also the "sensible default", so the elision rules allow you to not specify any explicit lifetimes in cases like this. Ownership is just you having an object of a certain type. As there's no Garbage Collector, someone has to store the actual object and later has to deinitialize (drop) it properly. So in Rust, similar to RAII in C++, you simply own the objects you create and they get dropped / deinitialized properly when they go out of scope. References are non-owning, as they are borrows, so if they go out of scope, nothing happens. Rust also makes heavy use of Move Semantics, so if you pass an object to another function or variable binding, no deep copies are made. Instead the Ownership of the object is simply transfered to the function / binding (so it's a simply memcpy at worst, but there's a large chance it will just reuse the old memory if possible). The compiler understands this and won't allow you to access the object through the old binding anymore and also won't attempt to drop (deinitialize) it anymore, as both could be really dangerous as the function took Ownership of the object and if it went out of scope, might not even exist anymore after the function call.
As an emacs user one of the things I've noticed is that emacs lisp being dynamically typed has lead to packages being less than robust. Usually the advantage of a "scripting" language like Lua is it's a lot more terse, but Rust is already much less burdensome than C, so I wonder if Lua is necessary.
&gt;Let's not forget that Haskell suffers from acute operatoritis (a.k.a. "Why do my programs look like Snoopy swearing" syndrome, a.k.a. "I can't believe it's not Perl"). aka "You guys are really cute, try reading Scala or, God forbid, APL" aka "C has a ton of symbols and operators and you aren't complaining about them because they're familiar to you" aka "This is a non-issue if you actually learn the language. Hieroglyphics are natural and understandable to those who read them. C is not any easier to read than anything else."
No, all they do is flatten the callback hell.
It shouldn't be unsafe, since parents always own their children they'll be dropped immediately. It's a little over verbose and not necessary at all, but I find it better to crash early in this case if somehow a parent out lived their parent (better than a dangling pointer). This can never happen though, and was more just to illustrate what I'm doing and who owns what (and I believe I mention that in my post)
Hmm, interesting. Though in this case the main point of breakage for the bar will be when communicating with Way Cooler, which will be done either through Wayland protocols (which has a clearly defined interface with versioning) or through our IPC (which requires you to parse JSON, and is a runtime issue already), we haven't decided yet. Either way, it's either a fixed problem or won't change if we use Rust. We'll definitely look into it, and I wonder what /u/snirkimmington thinks about it.
I unfortunately do not know Xapian. I skimmed the document, which was quite sparse, and I still do not know "what is under the hood". I can compare it projects that I know about : Lucene, and some proprietary search engine. I also read a bit about Sphinx. Needless to say, Tantivy is super young and lacks a lot of text analysis functionality that Xapian and Lucene has. (no lemmatization, no synonym expansion, no proper tokenizer, etc.). Actually it even lacks proper implementation of queries. For the moment, I mostly focused on getting the architecture and datastructure right, so I will only compare it on these points. Tantivy's index format and core datastructure are conceptually close to most recent versions of Lucene. Especially, one choice that has been made in Lucene is that the index is split into individual, independent index called segments. Each individual segment carries all necessary information to work as a small search index. This has a lots of pros and a few cons. For the rest, * The term dictionary is based on FST (like in recent version of lucene). * The inverted lists and term frequencies are compressed using a bitpacking-base format (like in recent version of lucene). One edge that I have over lucene here, is that I can rely on a state of the art C++ library https://github.com/lemire/simdcomp that uses SIMD instructions. * There are no skip list in tantivy yet. It is bound to happen though. * Everything is MMapped. I don't have any field cache, which is something that Lucene is actively trying to remove. What I called Fast values are very close to what Lucene calls DocValues. * The way positions are encoded are quite different, and sucks pretty badly in tantivy. I really need to change that. About the stuff that not even there in the data layer. * Tantivy does not have a taxonomy for facetting yet * Tantivy does not handle deletes yet * Tantivy does not have any merge policy system yet. People have to merge their segments manually. 
And I apologize for the lack of documentation. I really need to explain in further detail all of this in the doc.
Just out of curiosity, is there currently any project which aims to be the de facto standard implementation of Wayland, a la Xorg to X11?
Indeed, the manual on why you probably don't want to websockets: https://samsaffron.com/archive/2015/12/29/websockets-caution-required
Not directly - one of the major drivers of the next-generation display servers is that the X11 design with display server, window manager, and compositor all separate pieces makes it really difficult to develop certain desirable features¬π. So, by design, there *is* going to be no Xorg equivalent. Instead, we might get a compositor-support library to make writing display servers easier - *libweston* is one, and *wlc* (which Way Cooler uses, apparently) is another. (*Mir* is designed from the get-go to be this, but may not be interesting for you ‚ò∫) Even there, there probably won't be a single winner. GNOME already has a fully^* functional Wayland compositor implementation in Mutter, KDE has one in KWin. Neither are likely to switch, so any other project is pretty much going to be only for the niche desktops. ¬π: Input transformation for scaled windows is the canonical example here. ^*: for sufficiently loose definitions of ‚Äúfully‚Äù üòÄ
Awsome, I will try, may I can help some. This is also what i wantting to do.
I wondered the same, but I have not find anything besides a few short articles. [You may find this answer useful](http://codereview.stackexchange.com/questions/101621/netscape-bookmark-file-generator#answer-103799) which transform a Haskell code into Rust so that the latter looks like the former.
Yeah that's a good point, and perhaps I shouldn't have kept it and instead of just explained with prose, but I wanted to be explicit, though it's possible it just confused things. 
Lovely. I have been waiting for this for so long. It's practically mandatory for refactoring code with closures, and it's crazy to finally have it in sight. --- I'll put in a quick note that `stepping` is just fn stepping&lt;Step, Item&gt;(mut step: Step) -&gt; impl Iterator&lt;Item=Item&gt; where Step: FnMut() -&gt; Option&lt;Item&gt; { std::iter::repeat(()).scan((), move |_, _| step()) } Also, `paste_blocks` should call `fused` on its input iterators.
Working on my turn-based strategy game [Zone of Control](https://github.com/ozkriff/zoc), as always :) . ### This Week in ZoC Last week I: - [Finished sectors/victory points/game results screen](https://github.com/ozkriff/zoc/issues/124) - Replaced unit ids with unit type names in context menu: - http://i.imgur.com/m0h2d5j.png - http://i.imgur.com/YdfyxNW.png - Added basic unit info to the upper-left corner of the screen - [Fixed roads](https://github.com/ozkriff/zoc/issues/216) - [Added water tiles](https://github.com/ozkriff/zoc/issues/204): - http://i.imgur.com/POhSLwh.png Still working on [smoke screens](https://github.com/ozkriff/zoc/issues/160): - http://i.imgur.com/9o8o7dk.png This week I [hope to](https://github.com/ozkriff/zoc/labels/s-active): - [Finish basic smoke screens](https://github.com/ozkriff/zoc/issues/160) - [Fix armored units reaction to light reactive fire](https://github.com/ozkriff/zoc/issues/191) - [Fix bridges slots count and passableness for infantry](https://github.com/ozkriff/zoc/issues/214) - [Improve error message about missing assets](https://github.com/ozkriff/zoc/issues/211) - [Fix buildings rendering](https://github.com/ozkriff/zoc/issues/182) - [Make discovered FoW tiles fade to transparent smoothly](https://github.com/ozkriff/zoc/issues/210) [@ozkriff](https://twitter.com/ozkriff)
I'm looking for some code review of a library I've written for work recently. It is an implementation of [AMP](https://amp-protocol.net/) in Rust, since most of the rest of our code is written in Python using Twisted, and I needed a way to easily interoperate. For now, the Rust side is synchronous; once Tokio, futures-rs, and `impl Trait` settle down a bit, I'll give a shot at implementing this asynchronously, but for my purposes right now the synchronous interface should be sufficient. https://gitlab.com/unlambda/amp-rs I've submitted some patches to other projects before, and written some smaller test programs, but this is the first substantial Rust project I've written from scratch, and boy does my inexperience show. In particular, I think the serialization and deserialization code could have been a lot cleaner, and probably copy a lot less, but I couldn't quite figure out how to get serde's structure to play nicely with the somewhat odd AMP serialization format. I also don't know if the `command!` macro is a particularly good idea, but it does cut down on a lot of boilerplate. I think the `SyncEndpoint` interface is reasonably nice, and hope that I can make an async endpoint that's as nice to use in the future. Right now, this is still fairly rough and the interface is unstable, and I haven't added many tests for failure cases, so I wouldn't recommend using this for production work. Anyhow, comments, criticisms, and patches welcome!
I'd argue the longer definition of `stepping` is *much* easier to understand (plus, I can never remember the exact semantics of `scan` due to the name not making any sense to me). Also, I *never* remember the whole "not fused by default" thing. I will probably be fixing bugs caused by that for years to come. :P
Sure, there are some ugly things, mostly related to achieving great Java compatibility (handling of null for example). Rust's type system is definitely cleaner (but also less powerful). But if you look at the theory behind Dotty (the new Scala compiler) it's really small, powerful and proven to be sound. It's a great foundation to build a programming language on.
I agree about fusedness. I expect to replace `T: Iterator` with `T: FusedIterator` in most of my code [relatively soon](https://github.com/rust-lang/rfcs/blob/master/text/1581-fused-iterator.md). I'm not so sure about `stepping`. If you don't know what `scan` does, I suppose it's harder to understand, but fundamentally all it is is `stepping` plus inputs plus a second space for state that I assume exists because you couldn't return closures. I just set those both to `()` and ignored them in the function.
What's the right way to declare a function that returns something that implements a trait? I'm porting some Java code, and have a function that returns an Iterator over Strings, something like: public Iterator&lt;String&gt; foo() { ... } I'm wondering what the equivalent in Rust would be? I've seen some discussion, but it looks quote old (and mentions some upcoming Rust features), so wanted to check what the current state of things is.
I am going to be working on [euclider](https://github.com/Limeth/euclider), a non-euclidean ray tracing prototype. Last week I implemented correct camera movement in non-euclidean spaces, and just yesterday I've added surface color layer blending modes. Make sure to check out both scenes in the `scenes` directory, if you're trying it out. I would also like to port parts of the code to be run on the GPU. It would be great if I could run Rust code on the GPU; I've seen [this project](https://github.com/TheAustinSeven/rust-on-gpu), but I have no idea how I could integrate my project with it.
"A year with Python" is not a good way to measure your expertise. If you feel comfortable with basic programming concepts, just dive into Rust and see where that takes you. 
You have to return a `Box&lt;Trait&gt;`. This is known as a trait object, which is confusing terminology because trait object also refers to a function argument with dynamic dispatch (using a vtable), but without a `Box` wrapping it. `fn name(traitobj: Trait)` As opposed to a statically dispatched arg, where there is one function in the binary per type T in use: `fn name&lt;T: Iterator&lt;usize&gt;&gt;(static_arg: T)` In the same way, you might have a trait object (ie a boxed version) as the output of your function, but anyone using what it returns will be dispatching dynamically. This works because Boxes (pointers) have a statically known size, but you have the performance penalties of indirection + dynamic dispatch. `fn name() -&gt; Box&lt;Trait&gt;` (Think of this as if you put a type bound on it as with static arguments.) The new `impl Trait` proposal (not here yet) is essentially static dispatch on the return type. There are a few rules and quirks that must accompany these semantics, I would encourage you to read the RFCs on it (e.g. [this one](https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md)). 
A condition variable (`CondVar` in Rust) is a way to sleep threads until some condition (signaled by another thread) holds. It is an extension of the ubiquitous mutual exclusion (`Mutex`); you can think that the "condition" of the mutex is the number of threads in the critical section. A condition variable typically has two modes to wake threads---pick any single thread (possibly preferred by OS), or wake everyone. I'm not sure why you are reading `Semaphore` implementation, but for the completeness, `Semaphore` is essentially a mutex for multiple resources. The pre-1.8 semaphore implementation is implemented with an atomic thread counter plus a condition variable---the latter is important because we need an arbitrary condition (i.e. the thread counter goes positive) for waking threads. My guess is that the semaphore got removed later since i) it is relatively trivial to recreate one and ii) when you have multiple resources to synchronize, you sometimes need features not supported by a simple semaphore (e.g. callbacks), forcing reimplementation anyway.
Thanks for the information, that helps a lot. The new impl Trait proposal sounds hopeful too, though at least I've got a working solution now, thanks.
&gt; (In my opinion, recursive functions are the essence of functional programming.) If you write them yourself, e.g. a `fold`. However, if you already have a solid foundation in the standard library, you're mostly using higher order functions and compose them to new functions, e.g. sumOddUpTo :: (Num a, Enum a) =&gt; a -&gt; a sumOddUpTo = sum . filter odd . enumFromTo 0 fn sumOddUpTo(n: u32) -&gt; u32 { (0..n).filter(is_odd).fold(0, add2) } But no currying and (currently) missing TCO makes FP in Rust slightly awkward. 
Yes. Only you can decide if this is something you like doing. And in my experience, you can only *really* decide that after spending some time with it. So, I'd recommend reading the book, playing around with a few simple pieces of code and see if it's something you enjoyed when the weekend is over. Same goes for every other new technology you want to learn :)
I've been finishing the core behind [dynasm-rs](https://github.com/CensoredUsername/dynasm-rs), a compiler extension + runtime for dynamically generated code. Currently finished are the following: - [Full encoding data on the x64 instruction set + several extensions](https://github.com/CensoredUsername/dynasm-rs/blob/master/plugin/src/x64data.rs). - Encoder supporting all of these encodings. - Global, local and dynamic label support. - A runtime supporting these and threaded assembling (one thread can assemble, others can execute), while never having both writable and executable memory. - Clear error handling. Everything that can be checked at compile time is checked at compile time. A usage example can be found [here](https://github.com/CensoredUsername/dynasm-rs/blob/master/testing/src/main.rs). Note that this is mostly feature testing, and doesn't assemble into anything useful. What's currently not finished: - Stabilization. - Documentation: only the runtime is currently documented. Documentation isn't online yet. - Type maps: Basically easier syntax for accessing fields of pointers to known struct types. See the [original dynasm](http://luajit.org/dynasm_examples.html). As we operate on the ast the size of the relevant type isn't known at this point and currently the compiler only deals with static scales in memory operands. Also, `offset_of!(T, attr)` is not a thing yet (although it can be emulated, but that approach can be problematic with compiler optimizations). - Macros: I'd preferably just use rust macros for this, but currently there's no easy way of expanding macros to tts inside the compiler so the macros can be expanded before the compiler extension parses it. - x86 support. The biggest problem here is that the runtime currently assumes position-independent code is used, and therefore if it runs out of space it will just allocate more memory pages and copy everything over. As 32-bit code doesn't have RIP-relative addressing this means it doesn't support referencing data in the assembling memory itself. Outside of that the differences are mostly in the sizes/amounts of registers and the effective operand/address sizes of some instructions. 
Sorry this is confusing: I used my old account to reply. I am the user called "poulejapon"
I'm in vacation from tomorrow until Sunday (Summerbreeze festival). I wanted to rewrite libimagentryfilter using my new filters crate this weekend, but a PR was filed and so it's already done... I'm not complaining! :-D
One point off the top of my head: you can fix the `Cow::from` boilerplate problem by using the `Into` trait, e.g. fn foo&lt;'a, T&gt;(s: T) where T: Into&lt;Cow&lt;'a, str&gt;&gt; { let s = s.into(); // Now a Cow } This function will accept both `String` and `&amp;'a str` as arguments.
I know this probably sounds like a vaporware, but I think I finally managed to find a correct design for vulkano's command buffers. This should ultimately allow advanced resources management, like sparse memory or splitting a buffer into independent sub-buffers. 
1) Probably an IronError 2) https://doc.rust-lang.org/std/primitive.slice.html#method.join Vec auto dereferences to a Slice, so you can call slice methods on it. 3) Not sure without digging in a bit more 4) Path is to &amp;str as PathBuf is to String 5) Cow pointers are cheap if no work has to be done - if your string is already UTF8, why copy it onto the heap? There's no need. 7) Yeah, rust compile times are slow.
The `Hash` Trait is used to compute hash values, but you most likely don't want to compute a hash value from `Properties`, but access the values by their keys, right? So you want a function like: impl Properties { ... pub fn value(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;str&gt; { ... } } For holding the key/value data inside of `Properties` a `std::HashMap` is a good choice. For removing the trailing whitespace there's the `trim` method. 
Is the MIR code generated before or after the type/borrow-checker parses the code? Would it be feasible to handwrite the MIR code and use it alongside Rust? Example: MIR: &lt;Handwritten MIR code&gt; Rust: fn hello_from_mir() { println!("{}", some_mir_string); } Just out of curiosity..
When I was learning, I did Python and then C, and I liked that a lot. Python gets you comfortable with the fundamentals that you find in almost any language: conditions, loops, functions, lists, all that jazz. Then in C you go back over the same concepts, but closer to the way that the machine underneath is really representing them. C++ and Rust both expose the same low level machinery that C does, so it's possible that you can learn the same things. But because they have so many more high level conveniences, sometimes they're closer to Python than to C, and you might not end up learning as much. Knowing how to manually grow an array with `malloc` is pretty important, and in C++ or Rust you won't see that unless you read the implementation of `std::vector`/`Vec`.
Yes! Sorry, I mis-understood; I thought you were trying to write your own macro, not use one from another crate. &gt; Maybe that's the way it is supposed to be done, but why? Macros don't have any scoping, they're global, so if you couldn't say "please import macros from A, not B", if A and B had the same named macro, you couldn't include them in the same project.
For the NRF51 we just switched to the NRF51-DK. I've gotten it up and running on the RedBearLab nrf51822 as well. For the SAM4L we're using a research platform called the Firestorm (which is not widely available because... well... students have time constraints). However, we're going to release a dev platform that _will_ be widely availabe and sold through Stanford (more or less at cost, but don't expect $10 until we're doing really high volume runs).
When I started learning Rust I realized what's happing with my code inside python and what is a safe code. Especially I was imbued with this conception of owners and borrowers. So I guess it's way to go!
6) You can just call collection::browse directly. So for example `collection_browse(&amp;path.unwrap())` would be `collection::browse(&amp;path.unwrap())`.
I initially tried making the `ScriptMetadata(Cow&lt;'a, str&gt;)` variant like `ScriptMetadata(Into&lt;Cow&lt;'a, str&gt;&gt;)`, but that doesn't work. It's obvious now why not: `Into` is a trait and isn't `Sized` (I think that's the reason). Maybe I misused the trait in the variant? I don't have a function which I can convert to use the `Into` trait. And it seems like writing a function to return a `ScriptMetadata` would merely move the boilerplate somewhere else.
I mean the fact that I've found a design for command buffers. I think it's like the third or fourth time I reply to a "what's everyone doing this week?" post saying that I found a design.
You have to clone the state outside of the handler, and move the cloned value there (by adding the `move` keyword before the closure definition) - or skip the cloning part if you don't need it in the Manager.
Taking "by value" is the semantics of the public API. Sometimes you only need a reference to it. It basically saves you one line where you would instead define a reference variable. [Here](http://stackoverflow.com/questions/30655741/how-to-use-closures-in-nested-map) is a link to a situation where a reference variable was needed.
I finally got [modesetting-rs](https://github.com/Slabity/modesetting-rs) into a usable state with some actual documentation. Now you can manipulate display controllers and render to them using memory-mapped dumb buffers. Next I want to work on hardware compositing with the display controller using planes, and set up a system for receiving vsync events.
What error?
After, currently, but borrow checking is going to be moved to the MIR eventually (that's how non-lexical borrow scopes will be implemented). AFAIK there is currently no parser for handwritten MIR code.
I get that `AcqRel` can't be found in libcore. Don't have macbook with me I'll update with full text later.
I guess in that case you do need to manually `drop` things in the order you want. Though that might require making those members `Option&lt;T&gt;`, or some other workaround to let you drop them individually?
Once unsafe union's get implemented, we'll be able to add a zero-cost `NoDrop&lt;T&gt;` wrapper (union's don't implement `Drop`) so you'll be able to just wrap your fields in `NoDrop` and the manually drop them in the right order in the destructor.
Ok, it works ... I didn't think move closure were working like that. I thought that move closures were only usable once, because well they "move" the value in the closure, but I guess it's more like it's moving in the environment of the closure, and then copied if needed afterwards ? Thanks anyway, it solved my problem. To think it would have been this simple ...
Note that Rust is not the only casualty here: https://www.colm.net/news/2015/09/26/first-dev-version-of-ragel-7-released.html
I'm afraid I won't have much time to do more than my TWiR contribution and perhaps clippy a few projects.
I'm continuing work on a project which I hope to monetize one day! I'm using Rust for the RESTful API which the product runs on. Basically it's a system for managing sports leagues. It aims to be user friendly, and to ease the logistics and communications of managing a league. For instance if it's raining, texting all team captains that the games are cancelled for that night then rescheduling is a big pain when done with pen and paper. That's where this system fits in. Currently I'm using these technologies: - serde (json (de)serialization) - diesel w/ postgres (persistance layer) - r2d2 for connection pools - iron (web framework) - jwt/pwhash for authentication - some other utilities The runtime speed is great and I really love writing in rust. My biggest gripe would be trying to upgrade libraries or rust versions. Right now I'm using `nightly-2016-03-25` because it seems like I've found a version which works for serde and diesel. Every attempt to upgrade to newer versions of nightly has been unsuccessful since then. I don't want to use stable since both [serde](https://github.com/serde-rs/serde#using-serde-with-stable-rust-and-serde_codegen) and [diesel](http://diesel.rs/guides/getting-started/#compiling-for-stable-rust) require different changes which feel hackey in order to run. The next hurdle I'm coming upon is adding a versioning/deprecation strategy and implementing it. This way my API can be more backward compatible if clients never upgrade their version.
Not yet, no 
Not yet? Is there a conversation I can look at?
I'm working on adding ambient light adaptive brightness based on polling the webcam to dux. Working on an X11 window manager that will replace the ugly mess that my Fluxbox + Ruby script setup is. And fixing some bugs/adding improvements to screenruster. 
I have a file containing numerical values and their names. Example: MAX_VOLTAGE 34.0 I'd like to convert every such line to a Rust constant: const MAX_VOLTAGE: f64 = 34.0f64; Questions: 0. Is generating a file with these declarations the proper way to do this? 0. If "yes", what is the preferred way to do so? I currently just assemble the declarations as strings and print them to a file. I'm looking to use [`aster`](https://crates.io/crates/aster), but it's difficult since it lacks documentation. Is there documentation somewhere? Is there a more proper library?
I think you are missing `MONTH_NAMES` in the gist but I can guess what those are ;)
You can think of a closure as an anonymous struct, where every variable used in the closure is a member. Usual closures use references (or simply copy the `Copy` types). Move closures "move" the variables into the struct, but the struct itself can still be used multiple times. On the other hand, `FnOnce` is trait that consumes the closure, and therefore can only be called once. They're not directly related to move closures. EDIT: [Apparently](https://doc.rust-lang.org/book/closures.html) closures will by default try to move the environment when required, even without the `move` keyword. So maybe cloning the state before the closure is enough, without the explicit `move`?...
It doesn't work witout the explicit move, this is what it says : --&gt; src/main.rs:21:24 | 21 | let handler = |_ : &amp;mut Request| { | ^^^^^^^^^^^^^^^^^^ may outlive borrowed value `weak_cloned`
Great read, Jeena! :) --- &gt; The Rust compiler does a great job of pointing out possible sources of error in the code. Compilation errors are not scary, and they're in fact a great conversation starter with the compiler. Try introducing different kinds of errors, and see how the compiler responds. From these conversations, I find myself learning new concepts that I didn't know before, and writing better code over time. This. When I came to Rust I briefly glanced over "The Book" and then went straight to just "talking" to the compiler. Jumping from error to error. Felt like I didn't even need the book with a compiler as nice as rustc. I still remember the day rustc first told me about HRTBs. Good times.
I have a `conflicting implementations` error that I don't understand. The code is on https://is.gd/iC9jrc I have a trait: `IsSimilar&lt;T&gt;` The two implementations are: `impl&lt;T1: IntoIterator, T2: IntoIterator&gt; IsSimilar&lt;T2&gt; for T1 where T1::Item: IsSimilar&lt;T2::Item&gt;` and `impl IsSimilar&lt;i32&gt; for i32` I'm impmenting the trait for all type that implement `IntoIterator` and `i32`. `i32` doesn't implement `IntoIterator` so the two implementations shouln't conflict. What am I missing ?
Oops, I didn't realize that a link post wouldn't let me post a description as well, so I'll explain the problem just now. Also, as a background note, in C# `IEnumerable&lt;T&gt;` serves the same role as `Iterable&lt;Item=T&gt;`. `SudokuState` represents a partially filled-in Sudoku board, with `null` representing blank spaces. (Since C# doesn't have a built in `Option`, nullable int was enough to work) In `SudokuState.GetSolutions()`, we either have a base case of the entire state being non-null, and so (because we have guarenteed elsewhere that it is impossible to build an invalid state) we can simply return an "enumerable" consisting of just that state on its own, or there are blank spaces left in the state, and we must recurse, which is done by trying each possible value in the blank space and getting the set of solutions from each possibility in turn and concatenating each list together. Doing this in Rust presents a problem, even with the recently introduced support for `impl Trait`, as each of the two cases naively involves returning a different concrete type of `Iterable`. (Either an object that just returns one item and then stops, or one that may be the result of an unknown amount of recursion) It is of course possible to do both in one type, but this is a rather massive contradiction of SRP, as well as simply messy to write. It's also possible by making the recursion explicit and manually managing the stack, but I'm sure you'll agree that the problem is most naturally stated in its recursive form. Additionally, while I haven't tried it in detail, I would think the recursive form to be much more readable and understandable than trying to do the same procedurally. What is the most idiomatic way to achieve this? EDIT: If there is not a similarly readable way to achieve this, is there any possibility of one being added? Being able to achieve this easy style of functional programming while also retaining the speed and efficiency of procedural programming seems to be one of the major benefits of Rust, so it would be disappointing if "obvious" extensions like this were simply impossible to do concisely. 
It doesn't, in principle, need to recurse, but it looks very elegant and understandable stated recursively. (As [in this C#](http://pastebin.com/HUVTXNb0)) Since this turned out to be less easy than I thought, I started [a new thread](https://www.reddit.com/r/rust/comments/4xw60k/how_does_rust_do_recursion_with_sized_abstract/) instead. 
This is due to the [coherence rules](https://github.com/rust-lang/rfcs/blob/master/text/1023-rebalancing-coherence.md), particularly the restrictions around negative reasoning. In general you cannot rely on `T: !Trait` if neither `T` nor `Trait` are local to your crate. This allows the upstream crate the freedom to add a non-blanket `impl Trait for T` in the future. In this case the upstream crate is the standard library and in principle they could add `impl IntoIterator for i32` in the future in a backward-compatible way. Since the compiler can't rely on `i32: !IntoIterator`, both implementations apply, hence your conflict.
Oh I see. Yes for replication that makes sense. I will check out how FTS works. 
What is the best way to give notes? A GitHub issue?
Thanks for your answer!
Im writing a chip-8 interpreter!
Getting rust/racer working in emacs, A losing battle. 
The following implements a calculator with precedence in [pest](https://github.com/dragostis/pest): grammar! { // precedence climbing expression = _{ // rule is silent because it's the rule we're matching { ["("] ~ expression ~ [")"] | number } // primary addition = { plus | minus } // precedence 0 multiplication = { times | slash } // precedence 1 } number = @{ ["-"]? ~ (["0"] | ['1'..'9'] ~ ['0'..'9']*) } plus = { ["+"] } minus = { ["-"] } times = { ["*"] } slash = { ["/"] } whitespace = _{ [" "] } // whitespce gets run between all rules }
1. It's at least not a terrible way, I can't think of something super better myself. 2. It's hard to say without fully describing your file format, but a build script with some basic parsing shouldn't be too tough. If it's really just `name spaces value`, then the parsing isn't too bad, and given these are just `f64s`, I wouldn't bother with something like `aster`. But it really depends on how complex this file truly is.
I see who/what/when/why, but not *where.* Assuming in or around SF?
Sorry, the main page at [rustconf.com](http://rustconf.com/) has that info: &gt; The inaugural RustConf will be held at the beautiful Nines Hotel in the heart of downtown Portland.
We're working on getting serde and diesel onto stable. I mean, they already work on stable, but are slightly harder to use; we're working on the ease of nightly + the stability of stable. Stay tuned! &gt; The next hurdle I'm coming upon is adding a versioning/deprecation strategy and implementing it. URL versioning is the way to go, don't let anyone tell you differently ;)
Interesting. Seems like it would take a lot to socially engineer this, though. The people who are likely to change their github username are also far more likely to not have popular repositories or crates published, I would guess.
&gt; Path is to &amp;str as PathBuf is to String You meant "`Path` is to `str` as ...", or "`&amp;Path` is to `&amp;str` as ...".
It's a bit odd to be talking about inefficiencies there when you're cloning the board every iteration. A backtracking search is likely to end up a lot faster, and would let you remove the chain of boxes at the cost of a single allocation to store the search path.
So much this! The best way to learn Rust is to just `try!` and see what works (or is this to just see what works`?` now?)!
I think it's disappointing for a lot of people but not in the rust community. Rust has pretty damn good tooling for this sort of stuff in the language (macro abuse :D).
Thank you! For 5), is the better way of achieving the same result to replace the .into_owned() call by a .deref() call?
That's what I tried. But it's complaining about the browse function defined in the api module. 
Yup :) I did notice that this pattern is what a lot of libraries do, but had assumed it was due to wanting to include extra functions in their iterators. Makes sense for avoiding a performance cost though.
I had a look at what Ragel generated a while back and it wasn't very pleasing. Bascially, it was "let's just wrap what we do in C in an unsafe { } block and run with it". I was kind of excited back then, but now I don't see it as a big loss.
Other stuff that landed as a result of this: https://crates.io/crates/ring-pwhash https://crates.io/crates/nobsign And a pull request for rusoto: https://github.com/rusoto/rusoto/pull/347
&gt; Also, my understanding is that a Box puts its contents on the heap, which seems to introduce an inefficiency that's not strictly necessary, at least in theorectical terms. It's pretty much necessary in theoretical terms: you have dynamically sized types, so you need dynamic allocation. That's either some sort of boxing, or dynamic stack allocation in an ancestor (and the risk that you'll run out of stack space or allocated space without being able to resize, and there's no allocator for that ATM). Recursive datastructures is exactly something Box is for.
Unfortunately, at the moment that has to be written as: fn sum_up_to(n: u32) -&gt; u32 { (0..n).filter(is_odd as fn(&amp;u32) -&gt; bool).fold(0, add2 as fn(u32, u32) -&gt; u32) } which isn't super friendly for functional programming.
You would need to implement Drop on Foo, add some flag to know if the `foo` was properly initialized, and use mem::forget(self.foo) in drop to bypass default arc drop. It would be the same cost as wrapping foo in Option: #[derive(Clone)] struct Foo { foo: Option&lt;Arc&lt;Foo&gt;&gt;, }
Is that related to ring IM? 
I'm working on my netlink/iproute2 [library](https://github.com/polachok/pnetlink). It's still very early in development, but it's possible to do simple things like [dump all interfaces](https://github.com/polachok/pnetlink/blob/master/examples/ip_link.rs) (links) and addresses. I'm not satisfied with provided API, but well... that's a start.
To have a mutable field in an otherwise immutable struct you can use a Cell from from the standard library std::cell::Cell.
I used `top` and then `massif`. Both says that the process uses at least as much memory as the file size. And I confirmed this by searching for `mmap big files` on the web. The right way to do so is seemingly to mmap only small portions of the file. So, I will probably remove the use of the crate `memmap` when I find how to process big files with nom.
That's neat! I might move https://github.com/Keats/rust-jwt to ring if it's straightforward (only need SHA family). I also have [bcrypt](https://github.com/Keats/rust-bcrypt) crate still depending on rust-crypto 
&gt; I don't understand how I can have a mutable field in a struct. Have you tried reading the book? For example, the [structs chapter](https://doc.rust-lang.org/stable/book/structs.html) talks about exactly this: &gt; Rust does not support field mutability at the language level, so you cannot write something like this:
I am not convinced that your reasoning is correct. The whole point of mmap is that you are NOT copying actual data, it only maps the whole file into the address space of the process. It is fast and cheap. Since it does not copy data then it is quite clear that it does not need extra memory (other than the memory needed for paging but that's a small amount). top prints a lot of stuff, in some of the columns the virtual memory of the process is printed and it can be very large but that does not mean that your process actually uses that much memory. In fact, you can mmap files much larger than the available memory in your machine. That is a possibly easy and very convincing test:-)
To me this looks completely correct, are your concerned that you have throw `mut` everywhere? One of the goals of Rust is to be explicit, and part of this explicitness is about specifying what things can be mutated in a program. As you keep writing Rust, you'll be surprised at how often you don't actually need mutability to achieve what you need. The high level functions on for example `Option` and `Result` types also really help in this endeavor, while making your code more functional. For the cases you do need mutability, simple using the `mut` keyword is sufficient in most cases. I think what you're concerned about is that you have to take the "whole struct" as mutable. As another commenter pointed out there is something called `RefCell` in the language, which is a "smart pointer" that allows you to do borrow checking rules at runtime. This means borrowck no longer has your back for when you have multiple mutable references (your code will panic), but that means you can have a immutable reference to your structs while being able to freely mutate the values within it. I don't suggest you switch over to `RefCell` in this case however, as overuse of it is considered a code smell since we lose many of the guarantees from Rust.
&gt; I may turn everything to mutable, which is probably not intended by the programmers of rust As I tried to clarify in my other comment, mutability outside mutable references is not as important as ownership of values. If there is some function that does not need to call mutable "Properties" methods, you can ensure that by passing only a &amp;Properties to that function. It does not matter if Properties was mutable or not, *that* particular function will not be able to call mutable methods on it. So it's better to think of mutability as a way to add more details to the contract/api between methods or functions, and "mut" keyword more as a way to signal other developers what was an *intent* of some parameter or variable. This (mut), in addition to mutable and immutable borrows (&amp;mut and &amp;), also serve another important purpose - together they help to prevent data races, even in single-threaded code (think iterator invalidation). The downside of all of this is that developers need to learn to write programs in a bit different way than they used to in languages such as C# or Java, where everything could be mutated by anything. However, this enforces many good practices developers already follow. For example, single responsibility principle says that class should do one thing. Indeed, if you try to make a struct in Rust with methods that mutate two unrelated things, you are asking for trouble. It is good practice to keep "DTO" structs separated from smart classes. Likewise in Rust, structs that perform some smart actions should not contain DTO data, and pass it as plain owned values instead (I would recommend separating your Properties into two parts: one that is responsible for reading/writing, and another for containing). Also, having explicit mutability and borrowing rules prevent many action at a distance problems.
I like the idea of Rust, but when I read this kind of tutorial it reinforces my conviction that it's too complicated for me.. 
[std::ptr::write](https://doc.rust-lang.org/std/ptr/fn.write.html) allows you to set the value of a pointer without dropping the old value.
Im working on some sort of seeder. Generating fake data and making API requests to your server to seed your db. It will be json configurable
&gt; The name ring comes from the fact that ring started as a subset of BoringSSL, and "ring" is a substring of "BoringSSL". https://github.com/briansmith/ring/blob/master/README.md
Not really. https://github.com/briansmith/ring explains: "The name ring comes from the fact that ring started as a subset of BoringSSL, and *ring* is a substring of Bo*ring*SSL."
You might also consider making it a weak reference, which has a `new` constructor creating an empty reference, so you don't even need the option. It might also take less manual jiggery to prevent leaks.
Link for the lazy: https://doc.rust-lang.org/stable/std/sync/struct.Weak.html
You could do it safely using `mem::swap`/`mem::replace` to put a new value in and then `mem::forget` to drop the old value without running its destructor. (Or rather, a little bit more safely. Creating a zeroed value will always be unsafe.) But just using a type like `Option&lt;T&gt;` that's safe to drop, like /u/nercury suggested, seems like the Right Way to do something like this.
&gt; I still don't understand, why the language needs this It might just be that you're new; in Cargo, for example, there are 1708 `let` bindings, and only `347` of them are mutable. I haven't had too much time to check out this code yet, though, but it's possible that either this problem needs a lot of mutability, or you're missing out on some patterns that let you not bother.
Can someone help me improve my simple iterator (this is a learning exercise, I'm sure there's something that exists that already does this). I'd like to get rid of the copying and recursion: use std::str::Chars; struct Cells&lt;'a&gt; { source: Chars&lt;'a&gt;, buffer: String, } impl&lt;'a&gt; Iterator for Cells&lt;'a&gt; { type Item = String; // This reads until the next delimiter (comma) into the internal buffer, // then copies the buffer and returns it. It uses recursion instead of // a for loop to continue pulling new chars from its source member until // a delimiter has been encountered, because my attempt at a for loop was // giving me "cannot move out of borrowed content" errors. Similarly, // I couldn't figure out how to return the buffer itself instead of a copy. // The intent is that the returned string is only valid until the next call // to `next()`; perhaps I should be returning a `str` instead? fn next(&amp;mut self) -&gt; Option&lt;String&gt; { match self.source.next() { Some(c) =&gt; { if c == ',' { let tmp = self.buffer.clone(); self.buffer.clear(); return Some(tmp); } self.buffer.push(c); self.next() } None =&gt; { if self.buffer.len() &gt; 0 { let tmp = self.buffer.clone(); self.buffer.clear(); return Some(tmp); } None } } } } fn main() { let data = String::from("foo,bar,baz"); let cells = Cells { source: data.chars(), buffer: String::new(), }; for cell in cells { println!("{}", cell); } } EDIT: This is what I want to write: fn next(&amp;mut self) -&gt; Option&lt;String&gt; { self.buffer.clear(); for c in self.source { if c == ',' { return Some(self.buffer); } self.buffer.push(c); } if self.buffer.len() &gt; 0 { return Some(self.buffer); } None } 
Just looking in libcore, the code that prints that message isn't platform-dependent. It looks like `AcqRel` is only for atomic swap/exchange/arithmetic, not loads and stores.
If you'd like to switch your bcrypt crate to *ring*, perhaps consider contributing it to ring-pwhash? https://crates.io/crates/ring-pwhash
Why use bcrypt instead of scrypt (which is available in rust-crypto)?
I guess I shouldn't just do blanket search replaces :|
Also the following changes happened: - rustbuild will now produce source tarballs (for every platform) - A new source package is produced by both build systems in the "rust-installer" format suitable for consumption by rustup ;)
Thanks for your answer. I think you are right. The `VIRT` column was indeed showing a big value, but what was confusing me, is that the `RES` was slowing getting bigger and bigger until it reaches the value show in the `VIRT` column. Moreover, `massif` is a memory profile, so I though it would only show me the memory that is actually used, not the virtual memory. It is hard for me to test with a very big file because the mmap is on a binary file, so I would need to craft a big file by writing a software. After all, I believe that using mmap is correct, but I still have the issue that I want my nom parser to produce a lot of data and I don't know how to tell nom to produce the data in small chunks. Does anybody know how to do so? Is writing a [`Consumer`](http://rust.unhandledexpression.com/nom/trait.Consumer.html) the right way to do so?
No actually it should be "`&amp;Path` is to `PathBuf` as `&amp;str` is to `String`".
Awesome! I'm a big fan of Finagle, but have ended up not using it for a few things because with Scala most abstraction layers are not anywhere close to zero-cost. I'd be curious to see what sort of overhead tokio has (memory, binary size, or performance) over something a little more raw. What sort of improvements are you looking for with this hack night? There aren't many open issues. 
Thank you regexident! What you told Malisa and me about `let () =` couple months ago has been super handy!
[I have a parser for an archive.](https://github.com/antoyo/uncbv/blob/master/src/cbv.rs#L213) Currently, this parser (well one its its sub-parser) writes the result directly to the files. I would like to make this parser return the data instead, so that another function can writes the result to the files (separation of concerns that would allow me to write tests more easily and could allow other usage for this parser). However, if I update the parser to return a struct `Archive` containing the decompressed files, this struct may uses a lot of memory. That is why I am looking for a way to parse the input file by smaller parts: that would allow me to parse a bit of the input file, decompress it, write the result to a file and continue. I don't know how to do this with nom, [that's why I asked a question on this project GitHub issues](https://github.com/Geal/nom/issues/286). Thanks for your help.
Working on the plugin infrastructure for [xi editor](https://github.com/google/xi-editor). Last week I did some under-the-hood work so there can be an "idle task" that runs at a lower priority than handling requests. The next step is to efficiently run style data back to the core using Operational Transformation; all the pieces are in place now.
I know it's quite a spurious meme that Rust and Go are competitors, but they're at least competitors in the web space for sure, both have benefits and downsides in that area. I think Rust is head and shoulders above Go (despite Go being pretty awesome) but if we were to hire more developers, for example, the up-front training cost would be much lower for a consciously simple, small language than for something as powerful-but-strict as Rust.
I'm not clear on what you mean by "the MIR code is handwritten" because the textual format is just a printed representation of the actual MIR, which consists of various compiler-internal data structures.
I started learning Rust with less than a year of programming experience, mostly Python plus a small amount of C. :-)
And the best thing is they're getting even better now with every nightly...
How do you plan to schedule background tasks (like syntax highlight, static checks, etc.)? I doubt there will be a solution that makes even a majority of users happy.
Would it be possible to parse the file into a static hashmap using lazy_static? Not exactly what you're looking for but it might work. 
Note: scrypt is also available in ring-pwhash: https://crates.io/crates/ring-pwhash
One option is to hold a reference to some source and yield subslices of that source. Something like [this](https://is.gd/2dU3PV) maybe. It feels ugly to me, but functions for the example. That's about the least amount of copying you can do.
Then you can remove the virtual function call with a specially-crafted `enum`, but you're going to need boxing regardless.
That explanation of ownership, borrows, and slices was amazing, even with some yet-to-be-implemented diagrams. Keep up the good work!
The stack overflow is a problem, but it's a problem intrinsic to the idea of putting all the results on the stack, so I wasn't expecting Rust to be able to do anything about it. I initially thought that you could work around the sizing thing because, while the function as a whole doesn't have a definite return size, each branch has a well-defined and sized type, so the compiler could either track this as it passes out of the function, or just allocate the maximum size any of the branches could return. Of course, while this (potentially, maybe) works in a standard `let foo = call()` case, it explodes all over the place if you tried, say, `[1,2,3].map(call)`. I think you could achieve what I was after by explicitly allocating the storage in the caller, and passing mutable references to the called function, and then once the "map" is completed, passing the values into an owning iterator (Such a thing exists, right? I can't remember off the top of my head) which you then pass to your own caller by mutable reference. Thank you for enlightening me about why you can't do it just by returning.
Oh, nice to see Intel as Gold sponsor along Skylight and Mozilla, I didn't know they were interested in Rust.
That's where the `Box` comes in.
Yup! https://twitter.com/intelopensource/status/740647000530550784
Specifically for the purposes of implementing scrypt! (so far) That said, ring-pwhash uses *ring*'s implementation of PBKDF2 to implement scrypt.
/r/playrust
Tokio depends on futures-rs. There currently is some overlap between Tokio's reactor and futures-mio, but the focus of each project is different. Tokio is trying to provide a toolkit of reusable components (based on futures) to rapidly build protocols where as futures-mio is mostly just exposing sockets using a futures API. That being said, I expect there will be news on the topic before Rustconf.
They're not competitors; Tokio actually uses futures-rs. The exciting thing about Tokio is that is wraps a lot of the typical networking aspects of servers into a high-level interface based on futures. You get to write an RPC server by just giving a function from requests to futures of responses. (This works much like [Finagle](http://finagle.github.io/) in Scala, which is similarly layered over a futures library.) Alex and I are working closely with Carl to tighten this integration further, incorporating some nice ideas from the Tokio implementation directly into the lower future layers. We're also hoping to contribute to the upper layers of Tokio in the near future. Tons of great stuff is on the way!
Would the tokio-redis sample be a good example of a protocol with long-lived connections? I'm thinking of writing an MQTT broker and wasn't sure if tokio is mostly for a `Open Connection -&gt; Request -&gt; Response -&gt; Close Connection` type of server or if it handled long-lived connections equally well. I hope that makes sense, thanks for all the async stuff you've done for Rust so far!
I'm putting my immediate mode GUI library in progress to work driving a tile map editor for my game. Need a custom map editor since the game does all sorts of sprite formatting tricks that won't translate to an off-the-shelf tilemap editor. Also hoping to get around to testing the new tile portal features in the map system by setting up portal layers in the editor.
Yep! It's definitely intended to work with long-lived connections. Check out the [pipeline](https://github.com/tokio-rs/tokio/blob/master/src/proto/pipeline/mod.rs) transport; it's specifically intended to send many messages over a single connection.
Excellent! That's the piece I was missing, I see now that the redis example uses pipeline.
Having UIDs in URLs is a usability nightmare though.
Thanks for the kind words.
You could easily just write a macro that parses these definitions.
I should look into macros. Thanks.
BeepBeep! I'm a bot. Your comment seems sad to us, cheer up! Have a [kitten](https://img.buzzfeed.com/buzzfeed-static/static/2015-09/1/12/enhanced/webdr10/enhanced-3453-1441124243-2.jpg) P.S. This bot is powered by A.I. [sentiment analysis](https://www.youtube.com/watch?v=hPzNl6NKAG0&amp;feature=youtu.be)
I didn't know the module, std::ptr! And, with some code poking, I found out std::ptr::copy is the best match for my problem. Thank you.
This time I delivered: https://github.com/tomaka/vulkano/pull/216
I wrote code following your advice. For reuse of the circular-referenced Foo instance, it or its clone cannot be moved to mem::replace. So, something like std::read would be necessary to copy and save the original Foo instance. I will try the totally safe one with Option&lt;T&gt; too.
I'll be there. Great location by the way.
And a block from where I am. Hosting in Kendall square makes a lot of sense. Lots of tech companies here. (Can you tell I really want it to keep being there?)
As a side note to your C# code, I'm pretty sure your flatMap is the same as the standard SelectMany.
Sentiment analysis fails sometimes. Unlike kitten.
Rust-to-Javascript is likely of interest of a large number of people. If there are notes, slides, or other artifacts worth sharing, please do!
I think you are conflating asm.js and WebAssembly. Not that either is as readable as handwritten code, but at least asm.js should run in any JavaScript supporting browser.
I am indeed. I thought that WebAssembly was an umbrella term and asm.js the current (soon to be obsolete) JS representation. In fact, WebAssembly (wasm) is the byte code format, though.
Sorry to reply so late, it wasn't until now that I knew exact details. I work in security company. The company is paying attention to security etc. The reasons to not use others people library: * Someone has to check for security issues and updates. * Someone has to do code review to find if there isn't backdoor * Someone has to code review all updates. * Licenses * If there for some reason is a vulnerability, attacker has it much easier to find it in FOSS (keep reading) The reasons to use publicly available library: * No need to reinvent wheel * If the library is popular, it received much more code review than what could any company afford The conclusion is: it's better to use library **iff** it's highly beneficial and popular. It makes a lot of sense to me now.
Oh, thank you for this information, sounds really great! I feel excited that the community is working together to achieve great usability of Rust. I hope that I will contribute in some way too.
I agree. IMO, they just shouldn't allow username reuse.
What's the best way to loop over an iterator until it's empty, if the loop conditionally pushes new elements onto it? I've got a `HeapQueue` that I pop an element off, then either `continue`, or push new elements on, depending on its value.
Normally the borrow checker will prevent you from adding/removing elements to a collection while iterating over it.
something like: while let Some(x) = q.pop() { if test(x) { q.push(x + x) } else { println!("{:?}", x) } }
Support for signed crates might be a good idea as well.
We _could_ attempt to forward-port it to the current book....
Finished [my first Rust program](https://github.com/ciofeca/sdsdata) to read data from the USB cradle of a Sigma bicycle computer. I guess this makes me a rustacean.
The name is a bit awkward. Girls? Grills? Gil-r-s? Gillers? How do you speak it out loud?
Hi, you're looking for /r/playrust
That sounds like you're looking for an excuse to get out of writing ;)
Is there a way to have a function like this? fn dedup(s: String, map: &amp;mut HashMap&lt;String, Rc&lt;String&gt;&gt;) -&gt; Rc&lt;String&gt; { (map.entry(s).or_insert(Rc::new(s))).clone() } The naive solution would be to rewrite it like this: fn dedup(s: String, map: &amp;mut HashMap&lt;String, Rc&lt;String&gt;&gt;) -&gt; Rc&lt;String&gt; { let t = s.clone(); (map.entry(t).or_insert(Rc::new(s))).clone() } But this implies a clone at every lookup, instead of a clone at every new insert.
Vim isn‚Äôt really an IDE, it‚Äôs an editor. It is quite different from other editors out there, and it has quite a steep learning curve (which in my opinion is worth the effort, but it will take time). You could try [VS Code](https://code.visualstudio.com/) instead, which has basic support for Rust out of the box. Or [Sublime](https://www.sublimetext.com/) or [Atom](https://atom.io/) with the appropriate plugins. For completeness I‚Äôll also mention [Emacs](https://www.gnu.org/software/emacs/), but like Vim it is also a bit different (but in a different way than Vim) with a steep learning curve. If you do want to use Vim, there is [a Rust plugin for Vim](https://github.com/rust-lang/rust.vim). It comes with installation instructions in the readme. You can install Vim plugins directly, but it is a bit messy, so most people use one plugin to mange the rest of their plugins. I use [Pathogen](https://github.com/tpope/vim-pathogen) myself, and so far I‚Äôve been happy with it. Now you‚Äôve got an editor set up with syntax highlighting and ‚Äî if you use Vim ‚Äî heuristics-based autocomplete (try pressing ctrl + N). This is not like Visual Studio, where you can ‚Äúdot into an object‚Äù. There is [Racer](https://github.com/phildawes/racer) which offers this kind of completion, but I haven‚Äôt used it myself so I can‚Äôt give you advice on that. I just didn‚Äôt have the need for it so far. If you go down the Vim road, you will find that although it is far superior to most IDEs regarding *text editing*, it lacks many additional features that IDEs usually have. Vim is often used with external tools that fill those gaps. [Here](https://sanctum.geek.nz/arabesque/unix-as-ide-introduction/) is a nice article explaining that. There is also an attempt to build a real IDE for Rust, but I forgot the name, and I don‚Äôt know if it is in a usable state yet. Probably somebody else here will have the link.
Thank you! I feel welcomed already!
I've taken a look at these plugin managers, i.e. pathogen and vundle. How do I install pathogen, the instructions on the README on Github is quite vague. Before I forget, thanks for the detailed answer!
Yes, it should be poll, not pool, thanks.
What OS are you using ? if you are on a Linux Desktop , go to your home folder via the terminal. cd /home/[YOURNAME]/ Then ONLY if you vim installed enter the .vim folder mkdir -p ~/.vim/autoload ~/.vim/bundle &amp;&amp; \ curl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim 
 I'm using vim (actually neovim, but it works the same) with: * `vim-plug` as plugin manager * `rust.vim` for the basic rust support * `YouCompleteMe` for smart autocomplete (it has rust support) * The usual vim goodies (`nerdtree`, `syntastic`, `vim-fugitive`, ...) You may need to download the rust source code for racer. It's definitely not the best for beginners (especially if you never used vim before), but it works well once you're used to it.
That makes me sad :(
You'll have to write this with explicit matching on the entry variants: fn dedup(s: String, map: &amp;mut HashMap&lt;String, Rc&lt;String&gt;&gt;) -&gt; Rc&lt;String&gt; { match map.entry(s) { Entry::Occupied(e) =&gt; e.get().clone(), Entry::Vacant(e) =&gt; { let val = Rc::new(e.key().clone()); e.insert(val).clone() } } } 
Damn! I was trying something like that but instead of let val = Rc::new(e.key().clone()); I was doing let val = Rc::new(s.clone()); Soooo thank you! EDIT: [Sigh, I got ICE'd](https://is.gd/S9iQK3)
I use Vim on Windows and Linux. To add on to /u/mkawia's comment, here are Windows-y versions of their instructions: - Go to your home folder "C:\Users\BadassBanana123\" - You may need to create the vim folder in this directory. On Windows, it's called "vimfiles" (so the full path should be "C:\Users\BadassBanana123\vimfiles\") - If necessary, create two new folders there called "autoload" and "bundle" - Save this file https://tpo.pe/pathogen.vim to "C:\Users\BadassBanana123\vimfiles\autoload\pathogen.vim"
Generally, when you have a hashmap where the key and value are functionally equivalent, it's easier to have a `HashSet` instead: fn dedup(s: String, set: &amp;mut HashSet&lt;Rc&lt;String&gt;&gt;) -&gt; Rc&lt;String&gt; { // We can use `String` for the lookup if let Some(val) = set.get(&amp;s) { return val.clone(); } let val = Rc::new(s); set.insert(val.clone()); val } The `.clone()` calls here are only cloning `Rc`, which is comparatively cheap. `HashSet` doesn't have an Entry API, so you have to eat the cost of double-hashing. If you want to avoid double-hashing as well, you can take advantage of the fact that `HashSet&lt;T&gt;` is really just `HashMap&lt;T, ()&gt;` and use the Entry API: fn dedup(s: String, map: &amp;mut HashMap&lt;Rc&lt;String&gt;, ()&gt;) -&gt; Rc&lt;String&gt; { match map.entry(Rc::new(s)) { Entry::Occupied(e) =&gt; e.key().clone(), Entry::Vacant(e) =&gt; { let ret = e.key().clone(); e.insert(()); ret } } } This avoids double-hashing as well as cloning a whole `String` on insert, which happens in /u/birkenfeld's example. Allocating an `Rc` is cheap by comparison, and isn't dependent on the length of the string. This also avoids keeping two redundant `String`s around to be both the key and the value in the same map.
Thank you! The example with the set is eye-opening. The version with the map still gives an ICE (am I missing some use clause?). Please see my other answer.
It has a `+ 'a` at the end to name the lifetime (and matches your other answer). What am I missing?
/me notes down: include explanation of the terms.
The goal is having correct programs, where "correct" means meeting the specification. It's often the case that this includes safety in the Rust sense of the word. However, writing programs in Rust and using rustc is not the only way to get correct programs! In fact, when "correct" here also includes "has no input-dependent timing variations", achieving correctness using Rust and rustc is near impossible (due to unfortunate consequences of common hardware architectures and LLVM's timing-ignorant semantics that it optimizes against). In some ways, the burden of showing correctness for assembly programs is much higher than showing correctness for Rust programs. This shouldn't be taken as an innate evil, forbidding writing programs in assembly. Rather, it should be carefully taken into consideration when deciding how to implement a program.
Still working on X Rust Bindings using futures: https://github.com/jeandudey/xrb
The library looks very nice :) Do you have a GitHub / Bitbucket mirror though? I hate GitLab's interface in general and after browsing the repo for 5 mins, I already noticed several bugs of the mobile view in Firefox on Android.
`Sender` can be cloned, so you will just have to put it somewhere where it doesn't have to be `Sync` (I don't know enough about Iron to know where). You can, by the way, "make" things `Sync` by putting them inside a `Mutex`, but that may become a bottleneck in some cases. Edit: You are actually cloning it, so that's not news, after all :)
Bummer, I once knew the definitions by heart but now have to look it all up again to even remember the relationship between rings and groups. So, a ring is a specific type of group (commutative) with an additional operation that has the properties of associativity and distributivity and has an identity element. And you're saying one of these additional properties of the second operation is bad for asymmetric crypto? Mind helping me out putting the pieces together?
It's not necessarily that ring structure is bad, but often you can exploit additional structure to make the problem easier. For example, http://wstein.org/edu/2010/414/projects/novotney.pdf explores this, or https://eprint.iacr.org/2013/487.pdf.
/r/playrust
I recommend reading [this article](http://blog.ircmaxell.com/2014/03/why-i-dont-recommend-scrypt.html) *very carefully*, doing some experiments in your own setup, and make your mind up from that. (You can also read [this Stack Exchange question](http://security.stackexchange.com/questions/65660/has-scrypt-been-broken-finally/133510), where the author summarizes it a bit more.) But **TL;DR:** scrypt is not unconditionally superior to bcrypt, for a couple of reasons. First: scrypt, contrary to the na√Øve explanations you typically hear, does not *require* a lot of memory‚Äîrather, it *slows down a lot* when you *don't* dedicate a lot of memory to it. But this means that in some settings, scrypt may not be more secure than bcrypt with a suitable work factor. Second: scrypt is potentially vulnerable to some attacks, most notably cache timing attacks. See Appendix A of [this paper](https://eprint.iacr.org/2013/525.pdf). These attacks aren't necessarily fatal, but they do mean that you may have more things to guard against. Third: scrypt doesn't look like it'll become the dominant memory-hard password hashing function in the long term. See the [Password Hashing Competition](https://password-hashing.net/). So if you're asking yourself "Should I use bcrypt or scrypt?", you should really be asking yourself "Should I be using bcrypt, scrypt or [Argon2](https://github.com/p-h-c/phc-winner-argon2)?" (The answer isn't obvious‚ÄîArgon2 is very new!)
&gt; +924 ‚àí12,508 Love it.
Looking forward to the nostarch published version! I sometimes get too distracted while reading on a computer and I like to support the authors!
Dat diff tho.
i dont know.
So it is. I was writing the algorithm as a quick sketch of the idea more than anything, and didn't bother to look into Linq to see if there was a standard way to do it. (Especially since it writing it myself was trivial) I'd certainly have a look for it in the stdlib rather than writing it myself if I was using this in a more polished context. 
Ah, yeah, I get that in Rust, the Box has the Iterator. I meant more that, because of C#'s semantics deliberately hiding the distinction between the heap and the stack and passing everything by GC'd reference, `IEnumerable&lt;T&gt;` is the functional equivalent of... um... something like, `Box&lt;Iterator&lt;Item=&amp;Box&lt;T&gt;&gt;&gt;`. 
Ah, good call.
Just to list yet another option, the [intellij-rust](https://github.com/intellij-rust/intellij-rust) plugin works fairly well as of late.
There is so many plugin managers: * https://github.com/junegunn/vim-plug * https://github.com/gmarik/Vundle.vim * https://github.com/xsc/microbe-vim.git * https://github.com/ardagnir/vizardry * https://github.com/tpope/vim-pathogen * https://github.com/Shougo/neobundle.vim I prefer use vim-plug that is easy to configure and has nice features (update for example). To install you need copy the plug.vim file on the autoload folder. This is a simple configuration for the vim config file (*~/.vimrc*): source ~/.vim/autoload/plug.vim call plug#begin('~/.vim/plugged') Plug ...MyPluginHere... call plug#end() 
Sometimes it is hard because papers that present only a high-level design have no code to share. Examples of this include the original MapReduce paper from which Hadoop was implemented. Other papers give very precise technical descriptions and thus code isn't quite necessary to share, but many have been releasing their code recently.
Would appreciate constructive criticisms and suggestions. Hoping to get v0.1.1 out by September
This is the subreddit for the rust programming language. I think that you are looking for /r/playrust
This is great work (I've seen a talk on it). I think it's fair to say that the intended use cases are fairly different than what the Microsoft language server protocol targets. This is about doing deeper analysis of potentially very large code bases, with special care to cross-language projects (so you can follow links through FFI calls and the like). Microsoft language server, by contrast, is about doing incremental analysis for very quick results. That said, a lot of the underlying infrastructure that's needed is similar, so I hope the two efforts can share code and knowledge.
Aaand travis zeroed right in on src/libcore/mem.rs:523: TODO is deprecated; use FIXME
Thanks for letting me know. Sorry
Got it, thanks for clarifying. Looking more closely, I think your second implementation with ptr::copy() can actually lead to some undefined behavior! The problem stems from the fact that you're making an unsafe copy of an Arc without bumping the reference count. With a bit of mem::replace() gymnastics, we can exploit that to create two mutable pointers to the same value. Example below ([playground link](https://is.gd/oP25zC)). There's probably a way to make all this safe, by explicitly making a clone() of the outer Arc, and then using ptr::copy() together with mem::forget(). Maybe... But this example should emphasize how *extremely tricky* it is to stay safe when you're using unsafe pointers. use std::sync::Arc; use std::mem; use std::ptr; #[derive(Clone, Debug)] struct Foo { foo: Arc&lt;Foo&gt;, // Some data to play with. i: i32, } fn foo() -&gt; Foo { unsafe { let mut x = Foo { foo: Arc::new(mem::zeroed()), i: 0, }; // This ptr::copy() copies x.foo's Arc into its own Box. The // copied Arc points to the same box its sitting in, circularly, // which was our goal all along. Yay! // // But OH NO! Because we created this new Arc without using // clone(), we forgot to increment the reference count. Each of // these two Arcs still thinks it's the only one. We can exploit // that below to create Undefined Behavior in safe code! ptr::copy(&amp;x, Arc::get_mut(&amp;mut x.foo).unwrap(), 1); x } } fn main() { let mut my_foo = foo(); // Swap out the inner Arc with a dummy. This will let us get our // mutable hands on it and the outer Arc at the same time. let mut inner_foo = { let dummy_foo = Arc::new(foo()); let inner_foo_mut = Arc::get_mut(&amp;mut my_foo.foo).unwrap(); mem::replace(&amp;mut inner_foo_mut.foo, dummy_foo) }; // Obtain two mutable pointers to the same i! Undefined behavior! let i1 = &amp;mut Arc::get_mut(&amp;mut inner_foo).unwrap().i; let i2 = &amp;mut Arc::get_mut(&amp;mut my_foo.foo).unwrap().i; println!("Before: {} {}", i1, i2); *i1 += 1; println!("After: {} {}", i1, i2); } Edit: A simpler version of the same exploit, without the `mem::replace`: https://is.gd/nnKw66
Ahem. If you read that line you will see it is *engineered* to trigger a tidy fail.
That's awesome !
As Gitlab is open source, these are easily remedied by filing bugs! [Here's](https://gitlab.com/gitlab-org/gitlab-ce/issues) the bug tracker for Gitlab. As neither Github nor Bitbucket are open source, I'm actually surprised how much FOSS code is developed on them when Gitlab is (or at least is very close to) having all the necessary functionality and whose development is directly guided by the community.
Because sentiment analysis or kitten?
Interesting. Here is a nice blast from the past: https://mail.mozilla.org/pipermail/rust-dev/2011-June/000529.html
A co-worker has written a guide which is a good starting point: http://codecapsule.com/2012/01/18/how-to-implement-a-paper/ . Having implemented many papers myself (check my github :) , my best advice is to make sure you understand the paper otherwise you won't be able to debug your implementation. Note this probably means doing more research on the topic, either reading earlier papers with simpler algorithms, or later papers with better explanations. For maglev in particular, I can point you at both https://blog.acolyer.org/2016/03/21/maglev-a-fast-and-reliable-software-network-load-balancer/ and my Go implementation of the hashing algorithm https://github.com/dgryski/go-maglev .
I prefer GitLab's UI, but GitHub mirror is good idea because of how popular GitHub is. I will try to set up it today.
Brace yourself, typestate will come back soon ;)
Your code actually works, I had exactly the same thing with a RwLock (instead of a Mutex), which doesn't work. I don't quite know why it doesn't work with a RwLock though, but well with a Mutex it does so I guess my problem is solved ! Thanks !
test is a shell builtin, which is why it is better to call such programs try rather than test.
Urgs, you're right, but it's even more convoluted, because I've set `.` as my first entry in `$PATH`, but `test` is a bash builtin which comes first.
Yeah, jesus, I just asked myself why this never was an issue for me before, well, because I'm mostly writing C/C++ code, and the default executable name then - at least for gcc - is `a.out`. Facepalm! 
Well, the issue seems to be mostly in the emulator and it doesn't seem to be reproducable in any other way. So idk if it makes sense for you guys should bother with it at all.
If it's too much of a hassle for you: You can set up an automatic mirror at bitbucket.org.
Wow thanks for the links! It sounds like Maglevs bread and butter is the hashing algorithm. 
The "map/reduce" concept was already present in the functional programming community. Google's innovation was applying that to large workloads via distributed computation.
Let us know what parts you like and helped you!! That's the support and fuel that sustains me more anyhow &lt;3
I've only been using it for the binomial distribution, but it works great and thank you for doing this.
Looks great! A few comments: * The description on Github is not very informative if you don't know what Math.NET is. Maybe rather say what it does? (Sample from distributions etc.) * An `assert_almost_eq!` macro (like `assert_eq!`) could be nice for writing tests. * Instead of rolling your own special functions, you could use the `special` crate. * It would be quite useful to have the quantile function as well. (R implements this for instance.)
Aren't the use-cases solved by this kinda overlapping with the use-cases for named arguments?
I wanted a case-insensitive equivalent of tag_s! from *nom*, so I wrote this one. Is this efficient? Can it be done in a better way? I looked at the generated assembly with optimizations and debug info, to see what kind of code was generated, but I couldn't decide if it was good or not. It was a bunch of SSE ops that I can't follow. https://github.com/jdeeny/nom/commit/ef00efa647f77cfd4486c7db50ea2819c81f639d #[macro_export] macro_rules! tag_nocase_s ( ($i:expr, $tag: expr) =&gt; ( { let res: $crate::IResult&lt;_,_&gt; = if $tag.len() &gt; $i.len() { $crate::IResult::Incomplete($crate::Needed::Size($tag.len())) } else if $i[0..$tag.len()].chars().map(|c| (c).to_lowercase().next().unwrap_or(c)) .zip($tag.chars().map(|c| (c).to_lowercase().next().unwrap_or(c))) .map(|(tc, ic)| tc == ic) .take_while(|r| *r == true) .count() == $tag.len() { $crate::IResult::Done(&amp;$i[$tag.len()..], &amp;$i[0..$tag.len()]) } else { $crate::IResult::Error($crate::Err::Position($crate::ErrorKind::TagStr, $i)) }; res } ); );
nice one! Thanks :)
What's the absolute time? Or percentage difference? The difference between 0.2 seconds and 0.4 seconds is a lot bigger than the difference between 100 seconds and 100.2 seconds :)
Got some help on #rust. Turns out it is harder to do case insensitive comparison of unicode characters than I realized. https://botbot.me/mozilla/rust/2016-08-18/?msg=71530738&amp;page=13
Ah, I found from the Diesel source code that the expected format is &gt; postgres://username:password@localhost/diesel_demo ...which totally makes sense. Strange that I had hard time finding that format with Google! (It was here, in the end: https://www.postgresql.org/docs/9.5/static/libpq-connect.html#LIBPQ-CONNSTRING )
Is that sentinel swap to index 0 intentional to elide some bounds checking?
Since you are implementing a quicksort, watch this video on engineering the quicksort. [Three Beautiful Quicksorts](https://www.youtube.com/watch?v=QvgYAQzg1z8) It explains how to avoid the some of the weaknesses of quicksort and to make it a lot faster. 
The pivot is generally placed at the beginning for in-place quicksorts, and in general you want to use the middle element as the pivot as a good middle-ground for eg when a list is already reverse sorted. Apparently I wasn't consistent in the variable usage though!
Thanks, I definitely will!
Can servo integrate this with the SpiderMonkey garbage collector?
Certain details you have to redesign yourself, such as the distributed RPC system, leader election, distributed locking, etc. Often such big systems cannot describe in detail all aspects, so only those which are non-intuitive end up with a description. edit: One example of a reimplementation of a technique in a paper is Aaron Turon's [crossbeam](https://github.com/aturon/crossbeam) repository, where he reimplements a Treiber stack, and an MCS queue.
That'll be something to keep in mind as this works to being an RFC.
Let me reiterate what I said: &gt; &gt; I recommend reading this article very carefully, doing some experiments in your own setup, and make your mind up from that. Now, to address this: &gt; If I understood correctly, scrypt with default parameters is stronger than bcrypt. I don't understand why you would weaken it. ...the answer is that scrypt's default settings might be too costly for you. This is why I say to "do some experiements in your own setup"; you need to find out what settings you could afford to use for bcrypt vs. scrypt, and make a call whether scrypt really is a win in those circumstances. This is a bit obscure in the article, I'll admit, but the "key derivation" vs. "password storage" comment is about that. scrypt was invented to derive encryption keys for [Tarsnap](http://www.tarsnap.com/security.html), an online backup service where the key derivation runs on the client, so they can afford to crank those cost settings much higher than a web application server authenticating a high volume of passwords would be able to.
Is it already the default on stable?
"that are not yet stable" no, MIR is in beta but not in stable.
We actually have `sum` now? `mind == MindState::Blown`
First of all, very cool to see ideas for GC! I have few thoughts about the GC tracing (I am no expert though, so please bear with me). Use of type system here looks cool, but I think there might be some trouble if the scanning is combined with tracing. It looks like whatever GC is invoking `walk_roots` already knows which tracer is running (tracer of this particular GC?), all it needs is the list of `Gc&lt;T&gt;`, so `walk_roots` may produce this list for any GC by running the same code with no dynamic dispatch. Speaking of `Gc&lt;T&gt;`, how does the tracer recognizes it as its own value? Surely `Gc&lt;T&gt;` must contain some flag for that?
Woo! As always, I've updated my Docker image: https://hub.docker.com/r/jimmycuadra/rust/ The tags "latest" and "1.11.0" are now both Rust 1.11.
How easy will it be to limit the range of the GC to a single thread or a group of threads to control GC pauses?
Even pretty simple Rust projects tend to pull in a ton of crates as dependencies. I'm worried it's going to be nearly impossible to develop Rust without using a GC. GC-less memory-safe code is my #1 reason for using Rust. 
If I'm reading this correctly, the binary of "requires a GC" may not be a great heuristic for whether a library should exist. If we can have multiple interacting GCs running it makes sense for libraries to provide "bounded" garbage collected types, such as a lock free datastructure that can guarantee that all references to internal data a invalid after the structure is destroyed. The `Epoch` type in `Rayon` is sort-of an example of this. I also think this is less of an issue for Rust because it doesn't seem like you'll be able to have whole program Gc in a meaningful way, whereas D has one whole program Gc by default. That all said some sort ability to turn of Gc seems necessary for Rust to be as low-level as it needs to be.
drat. I was hoping stable `?` would make it into 1.12.
Sure. These were known old trans problems.
Wow so I was just really unlucky 
Absolutely.
In idiomatic Rust, you don't actually need methods that take `&amp;mut self` that often, because in many cases passing ownership will be better. I would say that in this case for example, assuming that you want to load properties from only one file most of the time, you would write a `fn load&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Properties` instead of `fn new()` and a mutating `fn load`, avoiding a mutation. Let me also give you the tip that the loop in your `filter` method could better be written as `for line in reader.lines() { ‚Ä¶ }`, so you can save another mutable variable. From how your example is designed, I presume you come from something like java, not something like python?
You already have this problem though. The `Rc` struct is an implementation of a garbage collector. I don't really care if my dependencies use it though, as long as it doesn't leak through the crate boundaries. In many cases, using a local GC produces code that is much easier to read, and nearly as fast.
Exciting times everyone. Kudos to all contributors and happy Rusting to all Rustaceans!
Almost 1200 new crates since you gave the talk, that's like 8 crates per day!
I didn't even think to check this!
I haven't gotten around to refactoring stuff, because I wrote it in a hurry today, so there's some nasty copy-pastey stuff with opening and writing to JSON files. edit: not anymore, it should be nicer to read now.
This is nice, probably nicer than yaml for config files and such.
There are a lot of versions of this problem. Other things that a dependency could do without necessarily telling you: - pull in libstd - allocate memory - spawn threads - fail to implement `Sync`/`Send` - implement `Drop` - call OS-specific functions - mess with the standard IO handles / sig handlers / cwd / environment - have bad `unsafe` code that causes undefined behavior - exit the entire process Part of the solution for any of these might be to come up with some convenient testing / linting tools that let you say "please explode if any of my dependencies commits Grievous Sin X".
Bingo. D is a language with "Optional GC" which, AFAIK, is hard to do without. A lot of standard and common libraries forced you into using a GC. I have nothing against GC per say. However, one of the key features of rust is its lack of GC. It would be a shame if to do anything interesting in the language you had to start pulling in a GC.
Rustaceans in VT represent!
There is a difference, though, between Rc and GC. Rc has ridged definitions on how it will behave and the overhead it will introduce. Most garbage collectors, while faster than reference counting, trade off the fixed overhead. As for the crate boundaries. I don't think it would be wise to make a Gc that is bounded by a crate. Reading the proposal, that isn't what it sounds like will happen. Rather, it looks like GC will be turned on for the whole application and applied to the whole application. You wouldn't want every crate that brings in GC to have its own GC running. You really do want to share the heap for all GCed things and run a single GC algorithm against it to gain max throughput (I know, RC is technically GC... I'm referring to M&amp;S and generational style GCs). GCs are cool, and you can do a lot of neat stuff with them (heck, dynamic memory can be done WAY faster on a GC heap than on with Rcs). But you can get really good and really predictable performance if you avoid them all together.
Thank you very much for the feedback. I'm not sure how to simplify those complex structures, but it definitely hurt a lot to write them, and I imagine it hurts even more to read them :) I will try to make better errors in detect_distro(), something along the lines of what you mentioned and also using some distro as default if it can't detect one by itself, but that will require some more changes overall.
D hamstrung itself by including a GC, hopefully rust won't make the same mistake. Systems programmers are skittish.
People often do this with symlinks. We probably could too, but we don't. There's always something more pressing to do... that said, /u/brson corrected me: we don't actually do the deletion + copy anymore, it's an S3 sync. But things went a little off this time. It happens. Releasing stable is still a semi-manual process.
This sounds like you want something akin to Paxos or Raft? If so, you can check out https://github.com/pingcap/tikv They have a raft implementation. I can't really find anything else though.
I assumed it was something to do with negative trait bounds.
That's because D has a pervasive GC. The proposed GC is to be used in very specific situations and not for every variable, much like RC. There won't even be a GC in the stdlib.
Gah thanks! Will check tomorrow
Yeah I get that but it's confusing, i was wondering if there was still time to update it to say something like "While it's not ready for primetime a lot of work went into making Mir a default part of the compiler pipeline. This will enable us to achieve things like incremental compilation(link to incremental compilation progress). Tacking on "laying the groundwork" at the end of the sentence makes people question if it's in yet or not.
That's up to the implementor. The stack maps have no cost -- they are generated in a different section. They may inhibit some optimizations but I don't see that happening too much. The cost only steps in when you walk the stack, and its up to the GC implementor to restrict those cases.
I'd say /r/playrust, but i'm sure they don't want this either.
Hey, let's organize a meetup! I know at least one other avid Rustacean in VT. Where about? I'm smack dab in the middle (Montpelier), so pretty much equally inconvenient from everywhere.
Note that this is very different from what D does, and the costs of a library using GC are significantly smaller; comparable (but probably slightly more than) to the costs of a library using Rc. (See my comments below)
If you're concerned, open an issue about it. I don't know enough to comment on your concern, but the appropriate place to raise them is on the issue tracker. 
Unfortunately it also created new ones (well, at least one new one &lt;:). One of my unpublished crates fails to compile in release mode with MIR enabled; I'll have to cut it down and report a bug when I'll find some time.
Short form: Can Rust support safe mutable state for interrupt handlers? Long ramble: I've been thinking about the way data is shared between interrupt service routines and mainline code. It is basically impossible to do useful work without *some* state that is mutated by both parties, and for high performance code, the shared mutable state may be fairly complex; how can that be systematically made safe? The basic idea is that mainline code has to access shared state within a critical section delimited by mask_interrupt and restore_interrupt, but an ISR automatically masks its interrupt. It seems like something analogous to RefCell::borrow_mut() could be used to mask and restore interrupts. But (a) can the runtime overhead be optimized away in the ISR, and (b) in a multi-interrupt system, how can the ISR's interrupt number/level be correlated with the interrupts the baseline masks? I am specifically interested in uniprocessors (ARM Cortex-M), but multiprocessors make the problem even more interesting. Anyway, is there a ready solution? Are people working on it? 
I don't think subtly different cuts it. The usage is very similar - to short-circuit when you hit an error. But the result is very different. I actually rather like the try! macro. Well, it's ugly as a macro, and `try` is the wrong word, and you need a safe navigation operator to make it more useful... I think handling the early return at the statement level is the right place, and use safe navigation to make writing those statements clearer. I would have brought this up earlier, but I had assumed (falsely!) that all the talk about introducing a `?` operator was going to be a safe navigation operator. Now, that's partly my fault for not reading the RFCs closely, but the fact that I read about this for nearly an entire year before realizing it didn't do at all what I expected seems like a pretty big cause for concern. 
D hamstrung itself by not investing the required resources to make a GC implementation that performs well. I was an happy Oberon user for a while. We also have the UK Royal Navy Flex, Xerox PARC Mesa/Cedar, DEC Topaz and Microsoft Singularity/Midori for examples of usable systems programming languages with GC. 
&gt; The struct keeps a reference to the F closure for creating new connections [...] It doesn't. That's a value. Rust doesn't have reference types (*i.e.* types which are intrinsically referred to by a pointer) like Java does. Everything is passed by value; if there's a pointer involved, it's explicit (*e.g.* `Box&lt;F&gt;`, `&amp;F`, *etc.*).
You bring up a good point. Are you more likely to call a function on a type that is returned on pass the return type into another function. Has anyone collected stats on this? 
In the past year I automatically put a small "-1" on every proposal that adds something to the syntax just for the purpose of making the language nicer. This includes for example anonymous structs, the ? operator, or the `for elem in &amp;container` syntax that was sneaked in just before 1.0 without an RFC. I can't help but feel that these RFCs are wasting everyone's time and energy for very minor gains, while I'm desperately waiting for important features, such as plugins, to come. 
&gt; Iterator has two new methods: `sum` and `product` This could be a silly question, but couldn't these be defined to take any type that implements `Add` or `Mul`?
The four riders of the Rust apocalypse?
They should probably be new types, since, while their representation might be a float, passing `std::sin` degrees instead of radians is an error that should be caught at compile time.
I really don't understand that argument of "being different than error handling in other PL but acts very differently" is a bad design choice. In the context of Rust error handling story, the semantic of `?` is the most appropriate: you couldn't design it any better (modulo discussion on the `Carrier` trait). And I would never expect any of the PL you mentioned to do that like in Rust as they have a fundamentally different error handling story. You argument can also in general be applied to a lot of features between two PL: * `class` keyword. It does not have any semantic equivalence between Java, Swift, JavaScript, or Python for instance. They all end up creating objects with very different layout in memory, different way of being managed (GC, ref-counted), and also behave differently in the way they are initialized (metaclass, prototyping, automatic / no base constructor call) and when considering inheritance its again a total different story. Does that mean that they should all have chosen a **different keyword**? Obviously no. * Generics. The syntax is mostly the same, and they looks similar in many PL, but again very different. If you consider the benefit (Java: no benefit it's just compile-time, C++/Rust: monomorphization) or the subtyping rules (covariant? contravariant? or invariant?) Java, C#, C++ can all have visually equivalent statements that are valid in one and invalid in other. In Java, it also can't be used with primitive types, so you really can't use them as you would in Rust for instance. * and so on... My point is that when you use a different PL, you **need** a different mindset otherwise, you'll do it wrong. I would **never** write my Rust code like my Java code or my JavaScript code. System programming language requires you to think about the code that you write very differently than managed languages.
Problem is, you need not only Add but also the zero element for empty iterators. Previously sum and product were defined in terms of Add and traits called Zero and One, but they have been removed because general numeric traits were not ready for the stdlib (they're being developed in the "num" crate).
It's a lot less thinking, even if not less typing.
I truly feel your pain. I was trying to fight that RFC but unfortunately I miserably failed.
But why are we singling out sin x?! What about cos x, or sec x?!
AFAIU D started with a standard library based heavily around GC and then removed it, this meant that the community ended up heavily relying on the GC and that made it difficult to use D without the GC. Rust is doing the opposite, it's adding the _possibility_ of using a GC when it's needed. If Rust wanted to suddenly start using a GC for everything and couldn't use any non-GC crates, then I think the problem would be comparable to D.
You are right but JSON is used a lot for configs. YAML does not fit the bill as it is not very human friendly either.
When you want it to be used by other C programs as a dynamic library or by other languages that can connect to dynamic C libraries.
I think that sounds like a really good idea. Being able to catch errors like that in the compiler would be awesome
Please no.
In the past, the `for` operator would only accept iterators directly. Therefore it's a change to the language to make it accept `IntoIterator`. As for why it's bad, it's the same reasons as all the language changes. It adds complexity to the language, can confuse people who are not aware of that syntax (which will happen more and more often if we add new syntaxes), and hides a function call. The only gain is that you save 6 keystrokes by replacing `.iter()` with `&amp;`. EDIT: Also, for that thing in particular IIRC it's what prevents the `Range` struct from implementing `Copy`, because of an unforeseen consequence of that change. I rarely use `Range` even in situations where it would be appropriate because it doesn't implement `Copy`. 
I cannot disagree more. I have been using the `?` operator for months now and it's great. If anything it's missing the public carrier trait to support `Option` as well. Safe navigation is a horrible feature in a language that is all about performance. Please let's not make the mistake of trying to do things other languages do just because someone has a hunch that it's going to confuse people. I have in fact made the opposite experience: newcomers to rust over-use `unwrap()` and trying to make them stop it is hard. `error_chain` and `?` are the closest I have found so far that makes people embrace it because the complexity in dealing with it is heavily reduced. It makes me almost angry that people still bikeshed over this. Everybody has an opinion about it. This requires just making a call and then sticking with it. And that call was made.
Same, but not for `?`. I'm actively using it and it makes my code more readable and nicer to work with. I'm happy to not get any other syntax though :P
&gt; I totally agree error handling in Rust is too verbose today. I disagree on the approach to fixing the problem, because it looks very similar to error handling in other languages, but acts very differently. Did you actually try to use the feature or is that just a hunch? Because as someone who *is* using it and explores different error handling ideas in Rust I absolutely adore the feature. I have yet to encounter someone who gets confused by this in fact.
Seems AMD is also using ref counted wrappers for Vulkan. https://github.com/GPUOpen-LibrariesAndSDKs/Anvil/blob/master/include/wrappers/instance.h#L47 Though it is only Rc not Arc. Well I guess in C++ it is easier to still use Rc in a multi threaded environment, if you are careful. In Rust I either need to use Arc or do some unsafe pointer stuff. Maybe I should try to implement a taskpool that can take references with lifetimes.
Right now the Rust language allows you to create macros. For example you create a macro named `foo`, and then you call it with `foo!(a, b, c)`. Then the call to the macro is replaced with what the macro produces. This is similar to `#define` in C. For the moment, macros are fairly limited. With plugins, however, you can create macros that execute some external code in order to produce their output. For example if you have a plugin that contains `bar`, then when you call `bar!` a function in the plugin is executed by rustc at compile-time, and the call to `bar!` is replaced with the output of that function. Why is it useful? You may ask. It is useful because it allows creating DSLs directly embedded in Rust. Example usages: - You can recreate OpenMP for Rust. - You can automatically add some profiling code around all your functions and easily benchmark what takes a lot of time. - In the case of a website, you can put HTML templates in your Rust source (EDIT: I don't mean in your .rs file, I mean alongside with your Rust code). The plugin can then extract the variables that the template requires, and generate a function that takes as parameter the value of these variables and builds the template. - You can put SQL code in your Rust source, which will be automatically parsed at compile-time. The plugin can then generate a struct whose members are the columns of the returned query. This ensure that strong typing is preserved and that you didn't make a typo. You can even check that the SQL code matches a certain database schema or something. - You can write an equivalent to `include_bytes!`, except that the plugin would do a prepass on the resource. For example you can write `include_svg_to_png!(image.svg)`, and the plugin would convert that SVG into a PNG at compile-time and include the content of the PNG instead. I can't find any other example on the top of my head, but I'm sure that there are literally tons of usages for plugins. 
Seems that sum and product could then be implemented in the num crate generically as well then?
Many libraries already use strong typing like that. For example, [`cgmath`](https://github.com/brendanzab/cgmath) has `Rad` and `Deg` types and many functions accept a generic parameter bound to be an [`Angle`](http://brendanzab.github.io/cgmath/cgmath/prelude/trait.Angle.html). I really like `cgmath`, especially for strong typing (position and direction vectors are represented by different types, too). There is also [`dimensioned`](https://github.com/paholg/dimensioned) which experiments with strong typed unit systems. 
tomaka17: iirc it's the opposite: without `IntoIterator`, `Range` had to *itself* be iterable, and that precluded it being copy because it could lead to confusing situations where the same section of the range was iterated multiple times. If `IntoIterator` had existed from the start, we could have had a separate `RangeIter` type or similar that doesn't implement Copy.
I had not found quick-csv. See [the comments](https://github.com/BurntSushi/rust-csv/blob/master/src/reader.rs#L749-L763) in rust-csv code. I am asking what the state of play is, especially with regard to what appeared to be blockers in the past (at least for a general, ergonomic implementation) and how they were solved. If this is so easy for quick-csv then why were people finding it hard a year ago?
It looks like you are copying out of the reader - do I understand correctly? Part of the motivation for the discussions in the past was to avoid allocations (25-50x performance improvement).
The `Result` is, while larger in the representation, solely intended as an error handling mechanism. The `Option` has no such restriction. (Haskell, by the comparison, has an `Either` type which has `Left` and `Right`; it is commonly used as Rust's `Err` and `Ok` but it is only provisional. In Rust such general two-variant sum type would be nominal.)
&gt; Safe navigation is a horrible feature in a language that is all about performance. Out of curiosity why would safe navigation be bad for performance?
This is not something that can be handled at the statement level: it must be an expression for one thing, and it should be possible to chain together. I fail to see exactly what danger you expect to come of this? Rust is statically typed: that means if you use ? expecting it to act like `and_then`, you will get a compiler error. There's therefore little value in trying to make it behave like it does in other languages!
that part of nom does not use iterators, and there's some unsafe behaviour because data is parsed from a kind of ring buffer. Right now, I would not recommend it, since tokio seems a lot better at what I tried to achieve (when futures-rs and the reduced impl Trait did not exist).
Yes, data is copied into a Vec via the BufReader. Ok I see your point now. I cannot help and I'm curious about the 25x boost. Thanks
I think sin, cos and sin_cos, tan, etc are a part of the C stdlib because they are physical machine operations on some computers. Not sure if those two are, but it would make it more convienent since you already have the trig functions.
What does safe navigation have to do with performance? Safe navigation is just syntactic sugar around something like: let something = match something_else { None =&gt; None, Some(x) =&gt; match x.inner_something { None =&gt; None, Some(y) =&gt; Some(y) } };
&gt; I really don't understand that argument of "being different than error handling in other PL but acts very differently" is a bad design choice. Principle of least surprise and/or cognitive load. Most languages use the term "capacity" to get the size of the internal array in a Vec/ArrayList/vector/etc. Imagine if, in Rust, Vec had a "capacity" method that did something completely unrelated to getting the capacity of the vec. It will still work, but someone who's programmed in both rust and many other languages will, when reading the code, see "mySlice.capacity()" and understandably think the programmer wanted the size of the vec's internal array. Thus, adding a completely different capacity() method to Vec would make rust code harder to read for anybody who's used a different language before, and it would make every other language harder to read for someone who started with Rust.
&gt; What does safe navigation have to do with performance? Because instead of jumping out of the function once, you keep hobbling over the (hopefully cold) path. It's the same issue you have with mapping over long chains of options or results.
&gt; But we don't live in isolation. We live in a world with many other programming languages, and needlessly diverging creates friction. I don't buy this argument at all. Programming languages have completely different syntax for flow and safe navigation as it stands. A lot of programming languages disagree on safe navigation for instance. I have seen `foo.?bar`, `foo?.bar`, `foo&amp;.bar` and `foo.bar` all mean the same for safe navigation. Likewise `?` itself already has different meaning in other languages. Safe navigation itself is in my mind an abysmal concept to begin with. It's the modern version of "on error resume next" and if I see code with it I wonder why those things are null to begin with. In Rust we have Options to much better express this and chained unwrapping of options is an incredible rare thing to begin with. Different languages different rules. We also don't get too concerned with that unary `!` in Rust does something fundamentally different than in other languages :)
OK, that makes sense, though I think that the `IntoIterator` mechanics of for-loops are easy to learn because other languages have this kind of feature as well (Python with its `__iter__` methods comes to mind).
&gt; I doubt this will happen. As I've outlined in the post, GC is for some relatively rare use cases (and is more likely to be used in the application than the dependency). I don't see the Rust community jumping on using GCs everywhere just because they exist. I am not that sure. There are some data-structures in /u/aturon 's crossbeam library that already use e.g. epoch based garbage collection. Different concurrent data-structures might want to implement different garbage collection strategies, and these data-structures _might_ benefit from both using Gc&lt;T&gt; and exposing it in its API. Right now these are implementation details, but it would be cool if whatever gc approach proposed would either work nicely for crossbeam, or be completely orthogonal to it. I'm pretty sure you guys have talked about this, but maybe /u/aturon could also chime in and comment on any thoughts about the interaction of the proposed gc method and concurrent data-structures like the ones in crossbeam (in Java _a lot_ of high performance concurrent data-structures exploit the GC). OTOH crossbeam users don't care that much about the garbage collectors used by crossbeam data-structures, but they will expect them to be able to move objects from one garbage collector to another seamlessly, and from one garbage collector to contain references to an object in a different garbage collector.
You want /r/playrust
Yeah, makes sense. Though using crossbeam itself is a choice made by the application writer, and if they know enough to want to use the persistent datastructures, they probably would know there's a gc involved. 
Do you mean the examples in the manpage? Agreed. Edit: Added in [`0d03cf4`](https://github.com/nabijaczleweli/checksums/commit/0d03cf479242c100f46e4b2a7a8bc0e11090ba3f)
I agree. The only reason I don't use it is if I want something to compile on stable. Cannot *wait* for `?` to stabilize.
This is my favorite example of something I can do with `?` let event : EventInfo = self.request(Method::Post, &amp;dsn.get_submit_url())? .with_header("X-Sentry-Auth", &amp;dsn.get_auth_header(event.timestamp))? .with_json_body(&amp;event)? .send()?.convert()?; that is abysmal with `try!`: let event : EventInfo = try!(try!(try!(try!(try!(self.request(Method::Post, &amp;dsn.get_submit_url())) .with_header("X-Sentry-Auth", &amp;dsn.get_auth_header(event.timestamp))) .with_json_body(&amp;event)) .send()).convert());
&gt; The first point is, as far as I can tell, a valid concern brought up for the first time and I believe it is something we have to do. Not enough to stop the RFC, but we need to clearly point out that it is universal, and you can use really everywhere. I thought `?` was the same as `try!`, in that you can *only* use it in a function or method where the return type is `Result`? I would not describe that as "really everywhere"...
You might also like the tool I made https://github.com/ioquatix/fingerprint
Neat, but Ruby
Is there any reason the nice `Result::and_then` method can't be used in your case? let event : EventInfo = self.request(Method::Post, &amp;dsn.get_submit_url()) .and_then(|r|r.with_header("X-Sentry-Auth", &amp;dsn.get_auth_header(event.timestamp)) .and_then(|r|r.with_json_body(&amp;event)) .and_then(ApiRequest::send) .and_then(ApiResponse::convert);
For starters this won't compile because they do not return the same result objects.
I meant in the Documentation, but you changed that too Nice job doing that so fast üëçüèª
&gt; What is the effect of it? It's described in the link in the announcement, but it doesn't include rust-specific metadata, so it's a much smaller binary. Nothing like what you're imagining.
Removing "cdn." made it work, thanks. Any idea why Firefox would choke on the original URL? It's very interesting to me.
Sure we have other operators that can be used. `!` for instance would work well as a suffix operator. One could use something like a prefix `?` or `::`, `??` etc. There are a lot of options.
Are there any plans for general numeric traits to make their way back into the stdlib?
This will never, ever happen. The GC in this crate is not easy to use. You have to *really go out of your way* to use it. Everyone who needs GC-like things will just be using RC instead, except for the specific use cases outlined here. Rust *already* supports GC, as Servo uses one, so this just improves the situation that already exists. Servo's support of GC has not resulted in an explosion of GC-dependent crates across the ecosystem. In fact, I can't think of a single crate that requires GC.
&gt; modulo is this the geekier version of ‚Äúnonwithstanding‚Äù?
Can you provide examples of languages using '?' for error handling?
It doesn't, actually, I use FF myself and it works fine. I suspect it's something to do with caching (and, more specifically, cache-missing) on the CDN, when I checked back a few minutes after that occurred to me it was working fine.
And then how does it figure out where to `Into` to? With a return there is a clear thing to type infer to: the return value. With a chained `Into`s this will not pass any type inference in Rust currently and produce god awful errors even if it did. Also all of this ignores the fact that `.and_then(|| ...)` is inferior in every single regard. Not even sure why we are having this discussion. Neither is it easier to read, nor easier to debug, nor easier to compile, nor will it be fun to optimize, nor can you break up large pieces of code easily if you need to add debug printing and stuff because you just moved your inference information. I really do not see any upside to what was proposed. If `and_then` was a legitimate thing then we would see more code use it. But we do not. The example also only works because there is no contained condition other than the error handling one.
OpenMP is rayon, and profiling doesn't need extra language syntax. I'm not denying that plugins are useful, but empirically what almost everybody uses them for is serde. There's large diminishing returns past custom derive.
There's no specific plans. Just like everything, we need something, then we need something good, then we need something with consensus, then we can think about it. Numeric traits are stuck on the "good" step.
&gt; empirically what almost everybody uses them for is serde The current state of plugins is that they break often, are difficult to write, have no guide/tutorial, and maybe not even any online documentation at all. People aren't going to start big plugin projects while all these problems exist. 
&gt; And then how does it figure out where to Into to? With a chained Intos this will not pass any type inference in Rust currently. As it does now, and_then is expected return a Result&lt;T, E&gt; where T may be different, but E is the same. Maybe you'll need to start with an Ok(()).and_then() to get it mapped to the correct type, but that's not very unreadable, at least any more than Ok(()) already is. &gt; . . . and produce god awful errors even if it did. &gt; &gt; Also all of this ignores the fact that .and_then(|| ...) is inferior in every single regard. Not even sure why we are having this discussion. Neither is it easier to read, nor easier to debug, nor easier to compile, nor will it be fun to optimize, nor can you break up large pieces of code easily if you need to add debug printing and stuff because you just moved your inference information. Can't all of the same things be said of the iterator usage? &gt; If and_then was a legitimate thing then we would see more code use it. But we do not. Argument from silence? The community is still developing tools and libraries. This doesn't really seem to hold up especially with Futures and other libraries coming out. &gt; Not even sure why we are having this discussion. Sigils are easy to add, but they're not always the best choice. There's obviously a lot of support for the `?` operator, and it obviously has its advantages, but there also seems to be a good deal of people unhappy with the idea of adding it-- some with good reasons. 
&gt; Has this stopped being discussed because it's not possible for now (without HKT/HKP)? This is my take on the situation. I don't see this being fixed any time soon. The approach I used in the fst crate is very limited. For example, no useful adapter methods can be defined. I wouldn't recommend using it. The csv crate needs some work and that unsafe iterator isn't part of the public API.
Here's one reason ! could be problematic: Assume you have a `foo: Result&lt;fn(), ()&gt;`. Then you need somehow distinguish between `foo!()` as a macro, or as a use of the ! operator.
/r/playrust...
Maybe that's the new compiler error system. Get it right or else!
I guess *"shooting yourself in the foot"* just got a little more literal ;)
Yeah but they don't use `std::shared_ptr`, they have their own rc implementation.
&gt; it seems to be impossible to use impl Trait inside a Trait is that right? eddyb answered that in another thread [here](https://www.reddit.com/r/rust/comments/4xneq5/the_calendar_example_challenge_ii_why_eddyb_all/d6hgyam). It's technically feasible, and was previously implemented, but wasn't part of the RFC that got approved. It'll take enough people asking for it and a new RFC to get that in. But it should be possible to do effectively the same thing with an associated type today. trait Test { type Out: Iterator&lt;Item=u8&gt;; fn test(&amp;self) -&gt; Self::Out; } I actually wouldn't be surprised if `impl Trait` like that were implemented with anonymous associated types. &gt; Can someone explain why the + 'a is necessary? I believe that's due to what is mentioned in [the PR implementing the feature](https://github.com/rust-lang/rust/pull/35091). &gt;&gt; No lifetimes that are not explicitly named lifetime parameters are allowed to escape from the function body The reasoning is not all that clear to me but based on other comments in the PR it might be a constraint due to the current regionck or lifetime inference implementations. I'm not even sure what the implications of allowing anonymous lifetime parameters to escape would be. I don't know exactly what adding `+ 'a` actually accomplishes to fix it. If I had to guess it allows inference to assign `'a` to some of the inner borrows. Using `fn test&lt;'a, 'b&gt;(..) -&gt; impl Iterator&lt;..&gt; + 'b` might also work and would disassociate the two lifetimes. Might need `where 'a: 'b` now that I think of it. Perhaps /u/eddyb (all hail) can clarify for us?
I mean in that case I'd expect crossbeam to factor the GC-based stuff out into another crate. I expect the Rust community to be pretty careful about accidentally letting a GC in. Folks are paranoid about panics, GC would be right out. Yeah, there may be a few GC libs, one of which may become canonical -- but that won't make it something you're actively encouraged to use (or is otherwise well-advertised) . The docs don't even encourage using Rc. I mean, yeah, it's possible that this happens to rust. But not likely. And all of us working on the GC stuff don't want it to happen, so I'm pretty sure the messaging around this will consistently be "dont use this unless you absolutely have to"
Right now, as your `MyContainer::iter()` is implemented, no. At some point `impl Trait` won't be restricted to return type position but for now it is. First, your `type Item` declaration is incorrect. It would be `::std::str::Split&lt;&amp;'static str&gt;`, which comes from `str::split()`, not `[T]::split()`. You then have two options for making your iterator type identifiable: box the closure and coerce it to a trait object (slower because of the virtual function call on each iteration), or implement `Iterator` manually and do the equivalent of `.filter_map()` in your `.next()` method.
Hrm, that sounds like something that LLVM should be able to optimize away. If it doesn't, that's unfortunate.
&gt; or the for elem in &amp;container syntax that was sneaked in just before 1.0 without an RFC This claim is incorrect. https://github.com/rust-lang/rfcs/blob/master/text/0235-collections-conventions.md#benefits-of-intoiterator
If you've already opened the file then you can specify the exact size of the vector without needing to waste memory allocations. let capacity = file.metadata().ok().map_or(0, |x| x.len()); let mut bytes = Vec::with_capacity(capacity as usize);
Maybe "sneaked in" is a bit too aggressive. What I didn't like is that: - It was a change in the language in the middle of a large list of changes to the collections library's API. - Although it was accepted before the alpha, it was implemented only after the 1.0 alpha, and then stabilized in 1.0. The 1.0 alpha was supposed to not change the language anymore, and only some remaining APIs were supposed to change. - It was backward compatible change. A big number of features were rejected on the only motive that they were backward compatible, up to the point where backward-compatible changes were almost automatically rejected without being examined. But this one went in. Point 1 and 2 were the reasons why I didn't catch this change. Even though my small "-1" wouldn't have changed anything, I'm still a bit bitter because of this and it's part of the reasons why I follow RFCs more closely now. 
&gt; Interacting GCs is a *very* niche use case Not so niche. Every Xamarin app on Android is running both the Mono GC (SGen) and the Java GC, with a ‚Äúbridge‚Äù between them‚Äîwhen Mono does a GC, it verifies the liveness of bridge objects by consulting the Java GC: triggering a collection on the other side of the bridge, then checking which objects are still alive. This is fairly expensive and ad-hoc, so it‚Äôd be nice to have a better way of doing it. 
Using `+ 'a` to allow lifetimes didn't even cross my mind! That is, I couldn't get `impl Trait` to contain a value which used a lifetime parameter. What `+ 'a` does in this case is it enforces that inference finds `'a` as the *single* solution, which then can be "exported" out of the function. [The tracking issue](https://github.com/rust-lang/rust/issues/34511) has more discussion on what the most ergonomic (and implementable) approach for lifetimes would be. Stay tuned for a nicer solution! (you can "Subscribe" to that issue, for example)
I'm just imagining a graph library that uses its own GC internally and the user never needs to know that there's a Gc in the back end
:D I just wanted to emphasize the fact that this aspect of the feature is still [debated](https://github.com/rust-lang/rfcs/issues/1718) (it has an experimental [implementation](https://github.com/rust-lang/rust/pull/35777))
I guess I meant to say " ... In Rust". When you are writing code in a GCd environment, the likelihood of a second GC being in your library is similar to the likelihood of one GC in a language like Rust :) But yeah, interacting GCs exist. The design lets you choose how to handle them, and you can make it safe if you restrict it to a couple other known GCs. Allowing it for arbitrary GCs feels like a recipe for disaster, but idk, there might be a way to make even that sound.
I feel like `!!` would be a good operator. It doesn't overlap with the other languages that use `?`, its an extra character but they're individually thin and take up about as many total pixels, while also saying 'pay attention'. There's also a nice symmetry where the macro-like behavior of the feature has a similar syntax to macros. 
&gt; But it's an and_then with a partially known type chained to a and_then to an entirely unknown type chained to an ‚Ä¶ and finally and and_then with a known type (the return value). I did not try this actually but I doubt this goes through the type inference. &gt; &gt; &gt; I cannot follow. I have no idea how this is related to either type inference, error messages or debugging. Can you elaborate where the overlap is? &gt; &gt; How would a sigil help iterators? Where would you place a sigil with iterators and what would be the point of it. The closest equivalent to this discussion i remember is the yield statement to build state machines / generators and that has been proposed many, many times. Even if it can't infer it, shouldn't it be able to, in the case just mentioned? The expected type is already declared in the return type, so this isn't as ambiguous as it is in some other places. If there's an inconsistency in the return type, that's another type of error. Each method in the chain is required to return something that can be converted to E-- it would be an error otherwise. The remaining type inference issues would be rare, in comparison. Still, this is getting off-topic a bit. My point was that (if) there are problems with type inference, error messages, and debugging-- adding the sigil doesn't change that. Those are still things that should be dealt with and aren't, by them selves, really good reasons to push something forward. &gt; How would a sigil help iterators? I may not have represented my point as clearly as I could have. I was trying to emphasize that just because we *can* do something, doesn't mean we should. Having too many ~~sigils~~ symbols is definitely something that can be a problem. Do we have an idea where to draw that line? Should we really add this when the error handling in Rust is still seeing development and the error handling still leaves much to be desired? I wouldn't think so. &gt; They would not, because async and await like yieldwould require heavy compiler support because it would require rewriting code entirely, moving it into closures and change semantics of move code. Personally, it'd be nicer if the Rust macro (or "plugin") system could allow for such things. Adding new ~~sigils~~ symbols seems like it should be a fairly big deal (maybe more than adding keywords, maybe not). I've not really seen something that would prevent having too many ~~sigils~~ symbols. I'd be disappointed if the feature ends up being stabilized in the next couple months based on just on what's been on the GH issues and the discussion boards. Some of the comments here have increased that feeling. I'd really not like to see Rust go down the road of just adding things like sigils because it makes the code a little neater (for now) while still leaving a lot of room for improvement in the error system. The RFC was more than just the sigil, and maybe it'll help-- but it doesn't seem to be something to rush. Slight edit: I meant symbols, rather than sigils.
I have troubles following your thinking process. First of all this is not a limitation of type inference: it's unclear how inference would work here due to the lack of type information. Secondly wet to iterators: there is a clear reason for `?` and that was demonstrated. The hypothetical argument of iterators clearly doss jor get us anywhere as even you do not have an example in mind. It's just arguging about the argument's sake. I don't think there is something to be learned from this exchange I'm afraid. 
I don't get the hate for IntoIterator. It seems like a sensible API and it never cause me issues. What's not to like?
Thank you for saying this in a way I could not elucidate. The rust project is a distributed effort; to belittle the extraordinary efforts of the individuals putting forth these RFCs -- for features which a *lot* of people do care about -- frustrates me greatly. It also doesn't strike me as very Rusty.
&gt; This will issue a syscall on every iteration Why does that happen?
&gt; problem is writing faster, not reading faster I don't understand this sentiment. /u/mitsuhiko's example from elsewhere in the thread is a fantastic example. The `try!` version is just nonsense - `try!(try!(try!(try!(try!(...)))))`. The `try!` version is both harder to write and harder to read (how many results was that, and what calls are they coming from?). &gt; against rust's explicit nature Even though we have lifetime elision, you can still figure out relative lifetimes for some arbitrary function signature. Given the definition of `?`, you know what the sigil does. You know it could lead to a return or give you an `Ok(T)` value. It's equally as explicit as `try!`. For now, it _is_ `try!`. I don't see how it's hiding anything at all.
There is always an RPC into Python ...
I think a Makefile may very well be the better solution in that case. A small make rule that creates the png image, combined with `include_bytes!` seems like it would be much more pleasant than a compiler plugin that has to perform image conversion and understand filesystem modification dates.
Examples like that are why I support the RFC. 
&gt; you might want to look at You dropped off at the end there.
Whoops, meant to paste a link to ndarray.
If we're really going with a single postfix `?`, could we at least agree to put it on the next line in a method chain? Like this: let event : EventInfo = self.request(Method::Post, &amp;dsn.get_submit_url()) ?.with_header("X-Sentry-Auth", &amp;dsn.get_auth_header(event.timestamp)) ?.with_json_body(&amp;event) ?.send()?.convert()?; It's so, so easy to miss otherwise.
The chan crate is a good example of an expensive abstraction. It's completely unsuitable for fine grained concurrency, but is quite nice for coarse grained concurrency IMO.
I could just as easily say that deeply nested try!s isn't a problem that comes up in practice either. (I've never needed more than two for example.) Of course, it does, and wanting to see where all the possible error points in a function seems like a perfectly reasonable thing that one would want to know in practice. I think it would be a lot better if everyone assumed opposing positions were perfectly reasonable on this topic and not act as if there is an obviously correct solution.
`PI` may be a universal constant and `log` may be non-trivial to implement, but they *also* have non-controversial interfaces, their implementations conform (mostly) to a single standard, they reduce the number of possible misinterpretations for the tokens they replace, and they are used in a large number of programming domains. These are the more salient characteristics of their inclusion, which are all shared by `to_degrees` and `to_radians`. I mean, that's why I would include them if I had made the decision. I have no clue why they were actually included, but I'd give enough credit to the Rust team to expect that they had at least some implicit understanding of these reasons.
Feedback on the code is welcome. Maybe the decoding/encoding could be done in a nicer fashion than the current solution using the byteorder crate, which is sometimes [extremely verbose](https://github.com/crumblingstatue/rgen3/blob/236614ba1bc2046a6ea4de66c1d3368f6058dd46/rgen3-save/src/rw.rs#L456).
IMO, the difference between `rdr.read_u16_be(xs)` and `rdr.read_u16::&lt;BE&gt;(xs)` is pretty marginal. Also, does your crate handle native endianness? Would you need an additional set of methods? There are quite a few trade offs at play. There was a long discussion here: https://github.com/BurntSushi/byteorder/issues/27
There's probably room for a higher level abstraction for parsing more complex binary formats such as yours. (Can [`nom`](https://github.com/Geal/nom) do it today?)
&gt; The ? can be easier to miss than a try! Maybe that's a thing (which I challenge however since you can uniquely syntax highlight both) but I honestly doubt that it matters. I have never seen it being an issue.
IMO the real problem is that it's called `.into_iter()` and not just `.iter()`; `into_iter` is a much better default. This also lowers the API surface, as you don't have both `(&amp;nums).into_iter()` and `nums.iter()`. If I get to dream, I'm making references postfix, so we wouldn't have to then bracket `(&amp;nums).iter()` (you'd instead use `nums&amp;.iter()`). In fact, if we do this we might not even need auto-ref or -deref, which is another source of confusion, since `foo&amp;.bar()` and `foo*.bar()` suddenly become palatable. But, alas, Rust is well past the point that these things can be changed. 
Heh, I definitely don't intend to get as well used byteorder, I just preferred my way and thought I'd put it on crates if someone else wanted it :) and it's easier in my opinion to type _be than ::&lt;BE&gt;. But even if that weren't the case, that's why I have the Wrapper type so that reader.read_u32_be becomes wrapper.read_u32. And no, it doesn't handle native endianness but I designed it with disk/network serialization in mind, where you should always use a consistent endianness.
Frankly, I'd be happy to have something better replace `byteorder` but I fear we may have landed at a least bad solution that covers most of the use cases given the set of features in Rust as it is today.
If at first you don't succeed, `try!(try!(try!(try!(try!(` again? By the way, rustfmt also turns the second version into a very strange inverted triangle.
I'm writing a compiler for a low-level language in Rust. This would be fun for compiler errors when the user does something *really* crazy, or ICE messages. fÕñlÃ¶Ã∞Ãªoat ÃØrÃ¨ÃñÕïÃªÕéeÕöÃòÕçÃ≤iÃ´Ã≤ÃûÕñÃùÕçnÕçÃûÕÖÕöÃôÃ≤Ã†tÕöÃóÕâÃúÃ≤eÃóÃ§ÕÖÃóÕñrpÃòÃØÃùÕôrÃùÃ©eÃ∫tÕïÃ¶Ã¨ÃóÃπÃñÃúeÃ§ÕôÃúÃôdÃ±Ãº aÃñÃúÃ†ÕïÃ¶s Ã≥ÃºÕñÕâÕñpoÕìÃûÃ∫ÃñiÃ≠nÃπÃºÃ±tÕìÕáÃ•ÕïÕáeÕçÕîrÕÖ Ã£oÕñÃ•ÕÖÕôÃóÃ§Ã≥hÃ†Ã≤Ãπ Ã™Ã≠Ã≤Ã™goÃûÃ¨dÕñÃ≤ÕöÃ∞Ãñ
From a cursory view of the code, there are a few places where you use `&amp;String` and `&amp;PathBuf`. These should be replaced with the more idiomatic `&amp;str` and `&amp;Path`.
I use as many original/unconverted types as possible for performance.
Ah, good point Edit: Fixed in [`ef0202c`](https://github.com/nabijaczleweli/checksums/commit/ef0202c2612f319c7a7ef1ab45faeb60a9a97327)
is it always fixed length data? If you have fixed data sizes, and know your endianness, and check your buffers correctly, you can borrow a C idiom and do something like [this](https://is.gd/Ze1D1w). 
Runtime errors... like, FileNotFoundException?
Hey, Check out Whiley (whiley.org). Eliminating errors is what it's all about. See this: https://youtu.be/C5QhzEk9dOE Other systems include: Dafny, Spec#, Idris and Frama-C.
Eh, obviously referring to runtime errors that can be checked for at compile time. However, good runtime error handling for exceptions like FileNotFound would be a huge bonus. Rust does both very well.
Here's how you could've written that post so that it was less shitty, and actually helpful. &gt;"Hey, you listed nerdtree in there, [foobar] is a lighter alternative that I've had a better experience with." Right now, all you did was say something I use sucks, and I don't even know what to do with that information...
If you're doing it as an exercise it doesn't really matter whether it already exists does it? For example, I wrote base64 en-/decoding a few weeks ago, of course it already exists but I wanted the exercise...
I have actually never thought about that problem, but I ran into it yesterday because I removed all my `Arc`'s. That is kinda awkward, that basically means I can not store raw references inside those structs. I am currently just passing them explicitly for every function call like phyiscal_device.something(&amp;instance); I probably will make this library just a raw vulkan wrapper without many safety features. I also don't think that a vulkan library has to be super safe because the debug layers can catch a lot of bad stuff. Then again I think that `Arc`'s are not that bad either. You still have atomic operations but they shouldn't happen often. What I kinda want is something like a mix between Arc and Box. One owned pointer that can give out N references. Sort of like one Arc with N weak pointers. But weak pointers are kinda expensive because you have to upgrade them to an `Arc` which probably increments the atomic counter and that would be expensive. So yeah I have no idea what I will be doing, but thanks for the post. 
I have never felt the need to nest one try within another. I can't see any benefit to this rfc, it just damages the explicit nature of rusts error propagation, which for me is one of the best selling points the language has. 
&gt; If you're doing it as an exercise it doesn't really matter whether it already exists does it? It doesn't, it's just funny that we have it already.
F* is another. ATS and Ur/Web as well.
What's your opinion on method-position macros instead of `?`. I.e., the above would become: let event : EventInfo = self.request(Method::Post, &amp;dsn.get_submit_url()).try!() .with_header("X-Sentry-Auth", &amp;dsn.get_auth_header(event.timestamp)).try!() .with_json_body(&amp;event).try!() .send().try!().convert().try!(); IIRC, this alternative was brought up a few times during the RFC, but was never really weighed as a real alternative. IMO, it addresses concerns for both sides, since: - It doesn't conflict with other languages' syntax (at least, any more so than Rust already does with regular macros) - It's clearly visible - It doesn't require lots of nesting with `()`s - It's much more generalizable, since other macros could use the same syntax (see [`pry!`](https://docs.capnproto-rust.org/gj/macro.pry!.html) and [`unwrap!`](https://github.com/canndrew/unwrap) for two macros that would benefit from this)
Scala
I have F# project which measures at roughly 10k loc and the amount of runtime crashes I had was staggering. The project required a lot of exception handling to work, most of those exceptions would have been caught by Haskell or Rust at compile time. .NET is a poorly designed platform for any language to truly catch problems at compile time.
Wow. Good to know.
I've been curious about Scala a long while now. Is it actually any better at catching problems at compile time than Java (the language and compiler) is? If yes, how significant the difference is? Does it get anywhere close to what Rust can do?
You'd have to wrap channels to those threads with something that allows GC to be sent. You would need a new marker trait, and unsafe code when setting up the threads and channels, but it is doable.
After hearing an episode of embedded.fm about Ada I've finally put it back on my list of things I want to dive into soon. It sounds delightfully strict and usable.
It may be possible to write your own Arc. For example, you can convert Box to raw pointer, use it however is needed, and then convert it back to Box in the drop function so it can be deallocated properly. I am doing this in my octree implementation (I will publish it some day).
I agree, but on the other hand that is only possible in small teams. My main use for C++ is for use cases where neither the JVM nor .NET can fully fulfil the task at hand. So I get to have full control over the quality of the code and take advantage of C++ *the right way*. However when I look at code on customer sites or SDKs, they are stuck in a *C with Classes* mindset. Languages that outsource quality to third party tools, suffer that not everyone is going to use them.
`rustc` used to have H.P. Lovecraft passages in ICE messages :D https://github.com/rust-lang/rust/commit/3d5fbae33897a8340542f21b6ded913148ca9199
Kotlin makes a big deal about nullable types. 
Great link, this language looks very well designed and useful! I've played around with the idea of named return values just for this reason but never got this far with it. I will definitely be keeping my eye on this.
I have updated the original post with languages mentioned in comments. While at it, I also made an attempt to categorize the languages and to add links to their respective subreddits.
I don't like it as replacement for `?` and i think in general it's not a good feature because it encourages clashing macro names. These macros will only work on a subset of types most likely and it cannot be type specific. So moving it to a more method suntax i think has more downsides than upsides. 
The lint check option `unsafe-code` can be used to deny the `unsafe` keyword, for a guarantee of safety as defined in the Book. Is there a similar way to make Rust purely functional? Is it enough to prohibit the `mut` keyword, and is there lint support for this?
Done.
You mean `fn do_nothing(&amp;self, bar: &amp;Foo&lt;T&gt;) {}`?
Features which improve safety of C++, such as those mentioned by MengerianMango. C++ coding guidelines (best practices) in which these features are taught and used.
If you're asking what I think you are asking, it's very simple: impl&lt;T&gt; Foo&lt;T&gt; { fn do_nothing(&amp;self, bar: &amp;Foo&lt;T&gt;) { // literally does nothing } fn new() -&gt; Foo&lt;T&gt; { Foo { v: Default::default(), } } } 
``` chain!(many0!(space) ~ alt!(tag!("#"), tag!("//")) ~ many1!(space) ~ not_line_ending ~ eol) ``` Something like that. Untested. It's been a while since I did some nom.
I've seen [Pony](http://tutorial.ponylang.org/types/at-a-glance.html) (scroll down to the "what guarantees..." section) come up in this context a few times recently. 
Not in main() for sure, which many beginners are sure to stumble over right away ;) 
I'm probably missing the point here but it seems to me like you are making up a list based on your own unmentioned criteria. You could add C to that list. It has a type system, it's not much but better than nothing.
&gt;Variants, concepts, move semantics, etc.
Yeah that should work. You can also wrap the raw_pointer in some struct that has the same lifetime as the `Box`. I think I'll implement that just for fun right now, thanks.
Could you share the code you tried on both sides?
I think there is still * https://doc.rust-lang.org/book/mutability.html#interior-vs-exterior-mutability * https://ricardomartins.cc/2016/06/08/interior-mutability
Describing `Box()` as doing heap allocation seems like a misnomer. Wouldn't it be more accurate to say that Box(object creation) moves its arguments onto the heap, but box itself doesn't allocate the object there. That Box is not an answer for doing __large__ allocations but having long lived allocations. And that if one wanted to construct extremely large objects on the heap, one should mirror how `Vec` [0] works internally. Everything that is inside of a Box, was created on the stack at some point. Could one create a `Box!(allocation expression)` that forces the allocation to be on the heap, never touching the stack? [0] https://doc.rust-lang.org/src/alloc/up/src/liballoc/raw_vec.rs.html#75
Try wikipedia and the language's website. Many of those languages are functional, which in most (all?) cases imply elimination of wide variety of runtime errors that imperative languages suffer from. Some of the languages are hybrid languages, which too implies elimination of runtime errors but usually far less than true functional languages. Rust is also a hybrid language, which is why Rust is so unique because it rivals functional languages in safety.
Wherein switching from separate x, y, and z parameters on a lot of functions to a BlockPos class (in Java) came at a significant performance cost to Minecraft: https://www.reddit.com/r/programming/comments/2jsrif/optifine_dev_minecraft_18_has_so_many_performance/ In languages with value types this is zero cost.
Conversion from utf16 could fail.
If the crate guarantees that it is always well-formed UTF-16, then UTF-16 to UTF-8 should never fail.
Imho Java does not deserve a place on this list. It's checked exceptions may promote it to the list, but the fact that everything is nullable (and even null by default) should demote it again. I understand there's Optional, but that isn't nearly enough to solve the mess. Kotlin did the right thing by making types not nullable by default.
Add Nim to the list
&gt; If you use the language correctly, it can be very hard to shoot yourself in the foot. I don't agree. There's no way for C++ to get rid of the pervasive specter of use-after-free. And use-after-free empirically does happen all the time in modern C++ codebases, leading to exploitable security vulnerabilities. Most of the move toward safety was completed in C++03, with things like std::string and std::vector eliminating buffer overruns and the like, and std::shared_ptr making reference counting easier. IMO, C++11 is a little less safe than C++03, due to use-after-move being a problem and lambdas making dangling references easier. I believe that there's no way for C++ to achieve Rust's level of safety in practice.
&gt; While your own code may be safe C++ code, even modern C++, isn't safe.
Wonderful example. Another excellent addition to the list of memory safety problems in modern C++ :)
[Epigram](https://en.wikipedia.org/wiki/Epigram_(programming_language)), [Cayenne](https://en.wikipedia.org/wiki/Cayenne_(programming_language)), and other [dependently-typed](https://en.wikipedia.org/wiki/Dependent_type) languages. Also research on [total functional programming](https://en.wikipedia.org/wiki/Total_functional_programming) (eg. Epigram and [Charity](https://en.wikipedia.org/wiki/Charity_(programming_language))), which lets you prove termination of all programs.
Are you sure about Haskell popularity?
`EXPR ?` is as _explicit_ as `try! ( EXPR )`. It is less _verbose_. These aren't the same thing.
Xirdus, your code looks like the comment parser. Here's the working implementation: ``` named!(comment (&amp;str) -&gt; &amp;str, chain! (space ~ alt! (tag_s! ("#") | tag_s! ("//")) ~ space ~ comment: rest_s, || comment)); ``` (gist: http://play.integer32.com/?gist=77fdcbd2594778c27b50836b48e17bdc) Writing the comment parser isn't a problem though. It's unambiguous and doesn't need any backtracking or the like. Parsing everything *before* the comment into a separate variable - *that* is the problem. Because to do that I have to use the comment parser as a delimeter or something. In other words, with the comment parser I can now parse `/\s+#\s+(\w+)$/`. But how do I parse `/(.*?)\s+#\s+(\w+)$/`?
Love the podcast. You forgot the shadercat.com link in the notes.
I was looking for code examples of some of the featured languages, and I noticed that swift is extremely similar to rust. [Just look](https://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/TheBasics.html). The most notable diference I noticed is the lack of semicolons. I used to think that c# is a copy of java by Microsoft, but that's nothing. Swift is a rust.clone() by Apple.
In the frontend all languages functional languages that compile to a .js file that not only is bigger,also blocks rendering of the page. The first render takes a while because instead of sending the user some html for what they requested they first get a spinner downloading the thing that theen go download what they requested. 
I swapped from C++ to OCaml in 2004 and then added F# in 2007. I work as a consultant with ~1,000 client companies using those languages. 
Any Rust function can do IO. There's no real way to ensure Rust code is pure.
I'm working on changing that for Coq, by basically adding the IO monad. (the code is on gitlab, the project is called beque)
That's what the `box` syntax is going to be. While `Box::new(thing)` constructs `thing` on the stack and moves it to the heap, `box thing` constructs `thing` on the heap.
I know you're also a very experienced Java programmer, but I've spent a not insignificant amount of time optimising Java code in my previous job and my experience differs. There are some [microbenchmarks](https://gist.github.com/cristicbz/9d983732acfe629c0100020883ebf073) I quickly whipped up, but the gist is: **Getters and Setters** Getters and setters only get inlined if no dynamic dispatch is needed. Because there are no real sum types in Java, your only available abstraction ends up being dynamic dispatch even when a Rust, zero-cost `Enum` would have been fine. **Containers** High-level containers introduce indirection and are much slower than `Foo[]` (or Rust's `Vec`). Using an `ImmutableList` or an `ArrayList` is a performance trade-off you have to consider. **Wrapper Types** Adding wrapper types creates GC pressure and causes some indirection even when things get inlined causing slower average perf. A a class Foo { private int a; public Foo(int a) { this.a = a; } public int getA() { return a; } } is not zero-cost in the same sense that pub struct Foo(i32); impl Foo { fn new(a: i32) -&gt; Foo { Foo(a) } fn a(&amp;self) -&gt; i32 { self.a } } is. I have had to manually de-aggregate value classes and create manual enums (union of all fields + discriminant) to fix performance issues. There are bunch of other things I could mention (like using Guava `FluentIterable`---or Java 8 streams---frequently being much more expensive than for loops), but this could go on forever. The ridiculously intelligent JIT helps, but there are some fundamental design decisions that prevent many abstractions to be zero-cost in Java.
move constructors are typically supposed to leave the moved-from object in a non-specified but valid state. Thus, use-after-move shouldn't be a problem from a memory safety perspective. (At least all types from the standard library obey this: ‚ÄúObjects of types defined in the C++ standard library may be moved from. [‚Ä¶] Unless otherwise specified, such moved-from objects shall be placed in a valid but unspecified state.‚Äù, and template functions from the standard library expect it to be true for any `MoveConstructible` or `MoveAssignable` type: ‚Äú`rv` must still meet the requirements of the library component that is using it. The operations listed in those requirements must work as specified whether `rv` has been moved from or not.‚Äù.)
is homu defunct, or has the servo fork taken over? https://github.com/servo/homu/
In the `Uart::init` method, you don't use volatile_store/load to access the registers. The optimizer may have reordered or removed the access to the registers in a way that the peripherals doesn't like. The fact that it work when running step-by-step is troubling but may indicate some timing issue. Like writing to a register before the peripheral is ready. But in this case, I don't see how it would be the case.
Yep.
Bors is the name of "government integration robot" from Philip K. Dick's sci-fi novel The Last of the Masters. How about "Mercer": &gt; An entity that humans "merge" with using an empathy box. By showing that they are able to empathize with another person, they also show that they are not androids. The grim gag here is that to prove you are human, you have to empathize with a machine. From Philip K Dick's another novel: Do Androids Dream of Electric Sheep?
Except that WideCString is meant for FFI, mostly for Windows. On Windows, many wide string functions don't actually use UTF-16, they use UCS-2 and don't handle surrogate pairs *at all*. (This is because Windows started using Unicode before UTF-8 or UTF-16 existed, when all of Unicode was less than 65535 code points. Being ahead of one's time can have unfortunate side-effects sometimes...)
/subthread
B-but i actually liked the Lyoko reference...
Perhaps we could find a way to transfer the "bors" name, though there's a chicken and egg problem since we need bors now, and aelita needs time to mature and prove itself. I'm also not sure how this relates to the ongoing effort to rehost homu-as-a-service, though i imagine homu's former users will be happy to have an equivalent substitute.
&gt;&gt;And use-after-free empirically does happen all the time in modern C++ codebases, leading to exploitable security vulnerabilities. I work in HFT and we haven't had a single use-after-free in our many C++ applications in at least the past 6 months. If you're writing an application that necessitates C++ you're unlikely to be dynamically allocating much memory, and if you do it'll be straight into unique pointers, which are safe from use-after-free unless you do something stupid. Even if mistakes are made, they'll almost certainly be caught by continuous integration builds running unit and integration tests through Valgrind. So in my experience, with proper development practice the chance of a use-after-free bug making it into production in modern C++ is minimal.
Agreed. To be perfectly honest though, I am a beginner myself in Rust, so probably not in a position to write an "expert" level tutorial. Not yet anyways :)
You are absolutely correct there, my bad.
This is incredible! I was just about to start writing a JIT, and this piece was what I was really worried about!
The servo fork doesn't have an associated public instance like homu.io. You need to host it yourself and manually do the configuration. It is used by servo and redhat (for dnf I think). The https://github.com/rust-community/bors is where the rust community is trying to set up homu-as-a-service, like homu.io.
`Built by MinGW-W64` **does not** mean it's 64-bit: that's the name of the project (which also produces 32-bit binaries), not the target platform. I dunno about whatever source you used; I get `gcc` through MSYS2. `gcc -dumpmachine` gives me `i686-w64-mingw32` for a 32-bit compiler, and `x86_64-w64-mingw32` for a 64-bit compiler. It's the **first** word that's important, not the second or third (which would suggest that *both* compilers are simultaneously 32-bit and 64-bit).
The official Playground doesn't support any external crates. However, you can try [/u/shepmaster's version](http://play.integer32.com/) which supports a number of crates, including `regex`. Original announcement post: https://www.reddit.com/r/rust/comments/4tqn41/playground_with_certain_crates_is_now_available/ List of available crates: https://github.com/integer32llc/rust-playground/blob/master/compiler/base/Cargo.toml
Hmm. That might be the problem. I'll try uninstalling MinGW-W64 and installing MSYS2. ^^^^I ^^^^recognize ^^^^you ^^^^from ^^^^IRC ^^^^BTW
Macros cannot be type bound. 
Thanks! It worked! [I generated a 10,000x10,000 Ulam spiral for you in return](https://www.dropbox.com/s/kxmjpvcejxzjba5/output.png?dl=0) (I had to host it on Dropbox, as Imgur wouldn't accept it.)
All I see is a slightly off-white square. On an unrelated note, I'm just gonna go clean my screen; seems a bit dirty...
Yes! I really enjoyed reading [Niko's parallel iterator post](http://smallcultfollowing.com/babysteps/blog/2016/02/19/parallel-iterators-part-1-foundations/) (and it's part 2) and would love to read more articles like that with a lot of technical details!
In my opinion that is precisely is why `WideCStr` should not implement `Display`. The blanket `ToString` implementation is not problematic since `std::fmt::Write for String` never errors.
I get a 502 Bad Gateway on the link :/
loved that show as a kid, very surprised to see it pop us as a name for a bot
search for related forum posts( where people are looking how to copy, delete, long path files ) and leave there suggestion to try Long Path Tool 
This is the subreddit for the rust programming language. You are looking for /r/playrust
Honest question: can you point to an example where a C-style for-loop is clearer/safer etc than its equivalent iterator-based loop or while loop? I've written a fair bit of Rust code by now, at work and at home and have not missed it once, despite coming from C++ as a first language. Genuinely want to know what pattern(s) I'm missing from my arsenal.
Thanks both, no idea why it redirected to this one, i have deleted and reposting :D Thanks for the notification however ;)
You really should use jmh for java microbenchmarks
Argh! I'll update it shortly; thanks for letting me know!
Okay, here's *one* way to do the `/(.*?)\s+#\s+(\w+)$/`: http://play.integer32.com/?gist=40c57e64df3dc38396e25d323bdbc0df (https://gist.github.com/40c57e64df3dc38396e25d323bdbc0df). Regular expression `/.*? $remainder/` says "*Take everything until we hit the $remainder. Then take the $remainder*". In nom this can be expressed with `many0! (alt! ($remainder | take! (1)))`.
While you can't guarantee this won't happen at compile time, you *can* guarantee that you handle this case, and you can also guarantee at compile time that code requiring the ability to read from/write to a file can only do so with a file that exists and has been opened in the correct way (as writeable or readable, as appropriate).
Java will get value types in java 10 tho (I hope) :D
Now that we have impl trait, you might want to add something about defining traits methods that return iterators and implementing them
Let me explain what this loop does. It starts with a 32-bit unsigned variable (`i`) that is set to all 1s. Then it shifts this number each loop to the left by one. It fills the least significant bit with a `0`. The loop terminates when all the 1s have been cleared. Why would we want to do this? When matching an IP address in a routing table. We want to search *most specific* netmask match, then match the next most specific, all the way up until the last specific netmask match. A netmask is a combination of 1s and 0s. The 1s are all a continuous set from the most significant bit, and the 0s are a continuous set from the least significant bit.
I apologise for reacting. I should have explained in the first place. My issue is that inexperienced coders are quick to pooh-pooh the C `for` loop - so they talk down to anybody that suggests it. Then when I explain a valid use-case I get told I'm making a mistake. But better to calmly explain than react. I was wrong.
Again, sorry about the UB mix-up. This is a pretty good example; I think I'd write this as: fn main() { for mask in (0..32).map(|i| !0u32 &lt;&lt; i) { println!("{:b}", mask) } } But I agree it isn't obviously superior to the C version and it may end up generating worse code.
Actually this is a great example. The Rust manual should have a "Rust for C Developers" section (a bit like the Perl Camel book has a section on Perl for C Developers section) with this very example. I've been an ass. This is quite a clear way of writing such a loop. I think you might have converted me with that post. For the first time I can see that the C `for` loop isn't necessary with this `map` iterator function.
Following links, it seems they were included in compiled binaries. &gt; It looks like this is 2640 bytes of lovecraft quotes in each exectuable (out of 469320, 0.56%). It was pointed out that it should be possible to build "hello world" in ~10KB, at which point it could be 20% Lovecraft, and that this concentration might be considered unwise.
(tl;dr: is there any way to perform dynamic dispatch for generic functions, or functions which require their most important argument to be `Sized`? Understand this isn't possible using vtables, but open to outside-the-box solutions.) I have a type `SmartPtr&lt;T&gt;` which has a bunch of inherent methods (`foo`, `bar`, `baz`) implemented for all `T`. I also have `Erased`, which is a type-erased `SmartPtr&lt;T&gt;`. Using runtime data, I can type-check the conversion from an `Erased` to a `SmartPtr&lt;T&gt;` for various `T`. Given an `Erased`, what is the best way to invoke those methods (`foo`, `bar`, `baz`) on that Erased, independent of its actual underlying type? The obvious solution is to produce a trait object, but unfortunately some of my methods are generic and some of them require `T` to be sized; neither of those things are supported by trait objects. My current "solution" is to manually write out every method call for every known `T`, but obviously that's labour-heavy and inelegant. Any ideas?
I'm having issues with `Into`, why am I getting error: unable to infer enough type information about `_`; type annotations or generic parameter binding required [--explain E0282] for the following snippet? `From&lt;T&gt; for U` implies `Into&lt;U&gt; for T` and it knows `T` (which is `MyInt` as well as `U` which is `i32`) what more confusion could there be? How do I make the following snippet work? https://play.rust-lang.org/?gist=d067d3457dc297754f0d054fd8b4425f&amp;version=stable&amp;backtrace=0 struct MyInt { value: i32, } impl From&lt;i32&gt; for MyInt { fn from(val: i32) -&gt; MyInt { MyInt { value: val, } } } fn main() { let val = MyInt { value: 42 }; assert_eq!(val.into(), 42i32); } 
I better go over that again, then. Cheers.
Ok! I think I just saw someone discourage `while true` in favour of `loop`, that makes more sense. 
Rust has `OsString` to handle communications with the OS, and it should be suitable for this (it does not make any guarantee that the OS doesn't). Its `into_string` method can convert `OsString` into a `String` if it's valid Unicode, and returns the original `OsString` otherwise. There's also `OsStr` (the `str` equivalent) which has a `to_str` method which returns a `str` only if the slice is valid Unicode and `to_string_lossy` which returns a `Cow&lt;str&gt;`. If there is something missing for interactions with OSes, it should be raised. As far as I can see I would expect that all the pieces are there, just waiting to be used. (We can argue that it is not particularly convenient, but I would blame the OSes allowing arbitrary binary sequences to be used)
Oh I see, thanks. However adding impl Into&lt;i32&gt; for MyInt { fn into(self) -&gt; i32 { self.value } } does not solve the problem and I get the same error.
In C11 and C++11 there might be a workaround: atomic_signal_fence() is a type of barrier that only impacts the compiler itself. It might not have broad enough semantics, in that a strictly conforming implementation will only prevent loads and/or stores from moving across the fence. But if it does work, that's a fair sight better than resorting entirely to asm. Update: So doodling around with that godbolt.org link showed me that this trick does work with GCC, but only if the result includes an assignment to global memory. Simply making it a store to local stack-allocated memory doesn't help. So, that's no good if you can't refactor your code in such a way without imposing a severe performance penalty (alas). You might be able to throw in a volatile empty assembly statement with "mem" side-effects, though.
It has the advantage of more clearly expressing the intent. With the C version you have to think about the "&lt;&lt;= 1" bit for a while to realize that it is maintaining an implicit invariant of "iterate though every bit mask with n leading 1s". Much better to have it explicit.
&gt; I can't think of any language that doesn't have a similar iteration protocol since it's that popular and common. Go
What a lively discussion :) To clarify, the intent of the article was and not to dive into nitty-gritty of C vs Rust loops, but rather to provide an introduction of iterator basics and common patterns. But for the purposes of this conversation, let me explain what I meant in more detail. I had a very simple scenario at the back of my mind. Consider the following `for` loop in C: int x; for (x = 0; x &lt; 10; x++) { // lots of code that does stuff } And its equivalent in Rust for x in 0..10 { // lots of code that does stuff } Is Rust's version more readable or safer? I don't think so. These read about the same to me. Some may even argue that C version is *more* transparent as to what exactly is happening with `x` on each iteration, and I would tend to agree. Now, let's tweak our code a bit: int x; for (x = 0; x &lt; 10; x++) { // lots of code that does stuff x--; // even more code that does stuff } Boom! Just like that I introduced infinity. Now, in an of itself, that may not be an issue. I may have intended to have an infinite loop. The problem is I can't tell that this is now an infinite loop just by looking at how the loop is defined. I have to dive deep into the loop's body to figure that out. And the C compiler won't even make a peep that I am doing something counter-intuitive. So, regardless of my intent, the readability of code suffered. Now, consider the same in Rust: for x in 0..10 { // lots of code that does stuff x -= 1; // even more code that does stuff } First of all, this won't compile. The compiler will throw `error: re-assignment of immutable variable x`. That's great not only because it's safer, but also because it makes me stop and think about what I am doing here. Which would probably lead me to using an infinite iterator `(0..)` with some adaptors/consumers. The infinite iterator, seems to me, is more readable in this context as it explicitly expresses my intent. As an aside, I *can* actually make `x` mutable and then change its value inside the loop. Even then, I can't inadvertently introduce infinity in this manner because the value of `x` will be "reset" back to the next provided by the iterator on subsequent execution of the loop. for mut x in 0..10 { print!("{} ", x); x -= 1; } // output: 0 1 2 3 4 5 6 7 8 9 This code *will* compile and run, but the compiler will still issue `warning: value assigned to x is never read`, hinting that I might be going the wrong way about whatever it is I am trying to do here. And I am not even talking about the fact that in Rust, `x` is inaccessible (goes out of scope) after the loop is completed, which again aids in safety as I can't inadvertently reuse garbage left behind. for mut x in 0..10 { } println!("{}", x); // error: unresolved name x In conclusion, I am *not* trying to say that C-style `for` loop is strictly speaking worse that Rust's iterator-based `for` loop. I truly believe that an experienced C programmer who is following best practices can write clear, safe, and maintainable code using whatever language facilities are available. The point I am trying to make is that in C, the compiler will be happy if I subvert the `for` code in a way that makes it completely counter-intuitive and potentially buggy, while in Rust, the compiler, by leveraging iterator semantics, will make it a lot harder for programmers at different skill levels to alter what's happening with the iterator variable inside the loop aiding in safety and maintainability of the code. Hope this makes sense... 
I confirm.
As I said Vim has built-in file manager that is called `netrw` which is quite good but is also a little bit overengineered. But hey, this is built-in and is [much saner in Vim environment](http://vimcasts.org/blog/2013/01/oil-and-vinegar-split-windows-and-project-drawer/). If you want lighter alternative then I know about 2: - `ranger` + some plugin - external tool that has Vim-ish navigation - `vim-dirvish` + `vim-vinegar` - light wrapper on `:r!ls` with some utilities (`vim-vinegar` is also great tool when used with `netrw`) About completion. Vim has quite good manual completion called OmniCompletion, check out `:h compl-omni` and keyword completion `:h i^n`. Together with `racer.vim` it works really nice. Also if you use `vim-gutentags` with `universal-ctags` you have really nice name completion for your project just by using `^n`. About `syntastic`, it is just `au BufWrite * make` with signs. It blocks your editor and with some tooling it can be really slow. Instead you should check Vim 8 channels or NeoVim with Neomake or similar tool that would run linters in background.
thanks @rabidferret. unfortunately this won't help: https://github.com/pansen/sanchez/commit/bd41d3d12d1eaa9038280d2634d6b180023d50aa 
If you include languages like Elm and Purescript, I think it only makes sense to drag in other "compiles to javascript" languages. Haskell has GHCJS, OCaml has js_of_ocaml, etc.
&gt; You could do a bitshifting iterator but it will require a lot of additional code. Yes, but the joy of the Rust for loop is you could do that additional code once, and then reuse it. Which eliminates the opportunity for someone to get it slightly wrong, or have trouble understanding it. I am a C developer (most of the time), and won't mourn its absence. I've encountered too many subtle bugs when people were using it.
Probably extremely stupid (but I couldn't find clarity in the book and other resources), but as the compiler does accept Option::None::&lt;&amp;mut bool&gt; I would expect it to accept the following for Option::Some(_): Option::Some(_)::&lt;&amp;mut bool&gt; But the compiler complains with this error; error: expected one of `=&gt;`, `if`, or `|`, found `::` Option::Some(_)::&lt;&amp;mut bool&gt; ^^ I know this isn't idiomatic rust but still I'd like to know how this is supposed to be done.
Here's the situation with what Github and Travis CI can do themselves: 1. Github itself can block pull requests that, when tested in isolation, fail. 2. Github can also block pull requests that cannot be strictly fast-forwarded onto master. Alone, neither of these are sufficient because they can't do anything about semantic merge conflicts (and I'm not talking about the weakness of three-way-merge: even Pijul can't recognize when one patch renames a function that another patch calls as a conflict). Together, they can solve the problem, but it ends up being completely manual. Your contributors have to manually rebase their commits when it's their turn to be landed, then someone has to sit on their thumbs waiting for the test to finish, then merge it and move on to the next one. That's basically what Aelita does, but it does it automatically (and it uses merges instead of rebases, but that hardly matters).
Thanks for your help, Xirdus, but no, I can not. `/\s+#\s+/` is not the same as `/#/`. Also please note that the regular expression is just an example. The point of the question is learning a way to use a nom parser as a delimeter. `take_until!("#")` does not help there either.
I think the users in r/playrust will get more from this content. :-)
You're right, and on Windows, I think OsString will allow invalid surrogate pairs because that's what the platform requires in many instances. But OsString doesn't have an `as_ptr` method, nor does it null terminate, so you need CString for that. But CString isn't for wide strings, and the standard library doesn't have an appropriate equivalent.
I'm using /u/brson's [error-chain](https://github.com/brson/error-chain) crate for the first time. I have code like this (currently also testing out the new question mark syntax as you can see!): let db_host = env::var("GANBARE_DATABASE_HOST") .chain_err(|| "GANBARE_DATABASE_HOST must be set")?; let db_name = env::var("GANBARE_DATABASE_NAME") .chain_err(|| "GANBARE_DATABASE_NAME must be set")?; let db_user = env::var("GANBARE_DATABASE_USER") .chain_err(|| "GANBARE_DATABASE_USER must be set")?; let db_password = env::var("GANBARE_DATABASE_PASSWORD") .chain_err(|| "GANBARE_DATABASE_PASSWORD must be set")?; However, it occurred to me, how irritating it can be to fix one error, and only after that, get another. I'd like to collate all these errors into one, fatal "set the environmental variables" kind of an error and then return that. Is there any nice, non-boilerplatey way to do that kind of a thing?
[removed]
That's a good point, thanks. I'll look into that.
Only thing I'll say about this is that I think it's less clear because of two things: firstly, the duplicated `32` (in both `(0..32)` and `0u32`) is quite ugly and confusing, and the `!0u32` instead of `0xffffffff`.
Thanks, glad you liked it!
That's why I said Nullable. Nullable is actually a value type with a couple special semantics that disallow it from passing either 'struct' or 'class' bounds. It might be best if option&lt;int&gt; implements its own Nullable tho since Nullable&lt;Nullable&lt;int&gt;&gt; isn't allowed
If you don't know what 2^(32)-1 then you definitely are incompetent.
This thread originated with a suggestion that try should be replaced with a method-position macro.
&gt; I think you might have converted me with that post. Just wanted to thank &amp; recognize you for being open minded. This is an undervalued quality in internet discussions and its very important.
`u32::MAX` is an even better option in my opinion (in both code samples)
Sorry, I meant suffix, not prefix. Aka. "Why does this matter for a method-position `try!()`?"
&gt; Rust prevents memory leaks, a subset of concurrency bugs, and others. It‚Äôs not some magic bullet, but to not have to deal with memory access issues? Null pointer dereferences? Memory leaks? Leaking resources like memory or file descriptors is not considered unsafe. You can safely call `std::mem::forget` or implement `IntoRawFd` without any unsafe code.
Because method syntax macros would be dispatched the same way as free functions, instead of the same way as methods. This is confusing, and its a serious downside to them.
&gt; I had been shown the light, and there is no going back once you have been to the promised land. All of my colleagues have gotten tired of me talking about Rust‚Ä¶ I definitely feel like a bible thumper sometimes. Can relate. 
Good article. Yes, Rust rocks! BTW, just curious, have you measured performance relative to other DNS servers out there?
[removed]
I'm not the author of the article, however bluejekyll did answer on Hacker News, you might have better luck asking there. https://news.ycombinator.com/item?id=12332876
Hmm yes. You're absolutely right. I wonder what I was thinking this morning!
To link to a C library, you need a rustified version of the library header. [bindgen](https://github.com/Yamakaky/rust-bindgen) can help create it automatically. Every C function call is unsafe, and often use C pointers rather than references, so usually a binding library mostly consist of safe wrappers around those. Apart from that, the C function is called just like any other function. C++, as you guessed, is currently out of the picture.
Python reference counting everything is a non-zero abstraction.
And if you don't have a competent team, how does Scala protect you from runtime errors? A competent team protecting you from runtime errors seams like a totally different consideration.
Just a matter of taste but I prefer 0xffffffff here. If I see 0xfffffffff somewhere I know someone is trying to build a bitmask.
Requires login? Slides without login: http://pnkfelix.github.io/presentations/qcon-london2016-deploy/qcon-london2016.html
Hmm‚Ä¶ Can't tell if genius or insanity.
While there are lots of unimplemented things, [Servo's fork of rust-bindgen](https://github.com/servo/rust-bindgen) does work on C++ files. It will generate methods by outputting the mangled names (and then wrapping them). Unlike C, where you can run bindgen once and commit the generated bindings, for C++ you will have to run it once per platform or set it up to be run during the build.
Me too.
While on the topic of DNS, what is the best library for pulling all of the DNS records for a given domain name. What about reverse DNS for an IP? 
Working on my turn-based strategy game [Zone of Control](https://github.com/ozkriff/zoc), as always :) . ### This Week in ZoC Last week I: - [Implemented basic smoke screens](https://github.com/ozkriff/zoc/issues/160): - http://i.imgur.com/WgQNu8H.png - https://youtu.be/WJHkuWwAb7A - Added attack hit chances to context menu: - http://i.imgur.com/qnZZgdX.png - [Fixed armored units reaction to light reactive fire](https://github.com/ozkriff/zoc/issues/191) - Fixed bridges passableness for infantry: - http://i.imgur.com/iAGqD7v.png - [Improved error message about missing assets](https://github.com/ozkriff/zoc/issues/211) - [Made MapText fade to alpha smoothly](https://github.com/ozkriff/zoc/commit/ac2c7c6) - [Fixed annoying vehicle-in-building pathfinder bug](https://github.com/ozkriff/zoc/commit/1ee698) - [Fixed buildings wireframe rendering](https://github.com/ozkriff/zoc/issues/182): - http://i.imgur.com/wjWcix7.png This week I [hope to](https://github.com/ozkriff/zoc/labels/s-active): - [Fix bridge slot count](https://github.com/ozkriff/zoc/issues/214) - [Make discovered FoW tiles fade to transparent smoothly](https://github.com/ozkriff/zoc/issues/210) - [Add helicopters](https://github.com/ozkriff/zoc/issues/111) - [Add vehicle towing system](https://github.com/ozkriff/zoc/issues/161) Bonus: memoir44-mockup of smoke demo map: http://i.imgur.com/ZplFvxR.jpg :) [@ozkriff](https://twitter.com/ozkriff)
Is there a technical reason why exception handling can't work cross language? It sounds like it's just a "sure it's possible but we didn't feel like supporting this use case" to me. Unwinding could trivially have a standardized function pointer to be called per stack frame then each language implements it their way to clean up that stack frame (defined by the platform). Exception catching has another marker such that you cannot catch cross language exceptions (this may or may not be desired) and would also allow a language to impersonate another to catch its exceptions. Just doesn't seem like it's actually technically impossible, just a decision that was made.
&gt; C++ might never be fully interoperable with any language. Even D can barely interoperate with it. C++ is not fully interoperable with itself. Just try linking to a library that was compiled with a different C++ compiler. This is not something that Rust can or should fix. The only way to interoperate in C++ between different implementations of the language is to provide C bindings.
I will try to create a small web framework based on the simple HTTP server framework PoC from Alex Crichton (Zero-cost futures in Rust). Not sure about the name, maybe `corruption` :). It may help me to learn futures in a real project. I think I will first add a router, and refactor/rewrite code from the original `futures-minihttp` PoC
I thought Clang/Gcc followed AMD64 ABI while the MSVC name in the mangled name what ABI the linked symbol expects/uses. Ofc this ignores virtual calls, I'm just thinking about when linking against dynamic library libraries. The Itanium ABI is only used in Itanium chips, x64 doesn't have enough registers :| and Itanium does have the x87 FPU legacy bullshit. 
Itanium ABI is not solely about calling conventions. It is also about name mangling, using `libunwind`, and what not more. For calling conventions, true, the ABI is different, as Itanium has a way different register set.
I think you've misunderstood what GraphQL is and isn't. It is decidedly **not** a [Data Definition Language](https://en.wikipedia.org/wiki/Data_definition_language). You can't just take a GraphQL schema and map it to a SQL database. Instead think of GraphQL as an application protocol, kind of like SOAP or REST (but much stricter defined). GraphQL describes the shape of an API, not *how* that API is implemented, just how it is queried. So while it sounds on the surface that SQL and GraphQL are somewhat similar, they are in fact vastly, vastly different, and comparing them or trying to generate one from the other will not work at all. I'm also working on a [GraphQL implementation](https://github.com/jnicklas/graphers) in Rust. It's currently a toy project, and not at all useable, but you might learn something from it, I dunno.
Should be a pretty easy question: how would I specify which source files I want to compile based on which OS I'm building for, if I'm writing a piece of software that I want to run on multiple operating systems, but that uses a significant amount of OS specific code?
Just published the second release of a Rust macro, that **generates setter-methods** for your structs and helps you reduce this kind of boilerplate. It's basically as simple as **#[derive(Builder)]**. #[macro_use] extern crate custom_derive; #[macro_use] extern crate derive_builder; custom_derive!{ #[derive(Builder)] struct Lorem&lt;T&gt; { ipsum: String, dolor: T, } } You can read the [full announcement of derive_builder](https://users.rust-lang.org/t/announcing-derive-builder-which-generates-setter-methods-for-your-struct/6990) on the Rust users forum.
The website seems down.
You could move all the lines there into their own function, and then `chain_err` any error that function returns with a "set the environment variables" message. Edit: My bad, I totally misunderstood what this was trying to do.
General tips which you may or may not be doing already: - If you have more than one processor core, use `codegen-units` for parallel compilation - Use debug mode, if you can stand the terrible runtime performance during development - Split your code into separate crates - Split your code into separate crates - Split your code into separate crates - Avoid macros that expand into tons of code (including `#[derive]`) - More [here](https://www.reddit.com/r/rust/comments/3tco32/shattering_a_crate_in_pursuit_of_compile_times/) (/u/acrichto's advice on an old post of mine)
Ah, that would probably work. Thanks.
I think what you are looking for is `nslookup`-type functionality in a rust library. I don't know if there is such a thing today. There is an unstable function `std::net::lookup_host`, which works fine, but that just returns A records, and doesn't seem to have support for MX, NS, PTR, etc you are looking for. There are also a few crates on [crates.io](https://crates.io/search?q=DNS) if you search there for "DNS". May be worth checking out.
I still cannot acces the website. And [Down For Everyone](http://www.downforeveryoneorjustme.com/http://beyermatthias.de/blog/2016/08/22/filters-everywhere/) also tells me it is down. I will wait until your provider resolves their issues.
Also having issues! Got this error page: https://i.imgur.com/6PSK9L5.png
I would like to write function which takes file path and returns `Vec&lt;&amp;str&gt;`. Now, how do I tell borrow checker that string, which is red from the file, should live as long as the returned `Vec&lt;&amp;str&gt;`? Ideally I would *move* the string with the vector into same data structure. Note that string itself is going to be read-only. struct A&lt;'a&gt; { s : String, ss : Vec&lt;&amp;'a str&gt;, } fn f&lt;'a, P: AsRef&lt;std::path::Path&gt;&gt;(fp: P) -&gt; A&lt;'a&gt; { let mut fd = std::fs::File::open(fp).unwrap(); let mut a : A; a.s = String::new(); fd.read_to_string(&amp;mut a.s).unwrap(); a.ss = a.s.split('a').collect(); a }
Is there an easy way to override a dependency of my dependency in Cargo? I'm depending on the yet-unreleased master branch of Diesel, but a dependency of diesel_codegen pulls the released version of the Diesel, and I have two Diesels. (And the codegen generates code with the older one, which doesn't yet have some trait impls I'd like to use)
Maybe you can model the HashMap value as a struct (https://doc.rust-lang.org/book/structs.html)? 
You folks are killing it (in a good way). Kudos for the good work.
With my [modesetting](https://crates.io/crates/modesetting) crate in a usable state, I've switched my efforts to another crate to work on getting high-level access to libgbm buffers and binding them to EGL.
you can view the presentation without login or you can log in via twitter or other social network
This can't work, because once `A` has a reference to itself, you can't move it, or all the pointers become invalid. In _this specific case_, this might be okay, because the contents of the String aren't going to move. But Rust doesn't know this. I think the owning-ref crate might be able to help? Alternatively, you just accept a `String` into this function, like this: https://is.gd/MUfYXw 
&gt; A web browser + Javascript JIT compiler is one of the most complex things out there, and as you say one of the most critical security targets, so I don't think it's representative of most C++ applications. Which don't have large numbers of people trying to attack them Right. If security isn't a concern for your domain, then that particular benefit of Rust isn't an advantage over C++. &gt; I'd also argue that the code there is not a good example of modern C++; better to use a map (wrapper) that returns a boost::optional (or C++17 optional), which is at least a bit more safe, than an iterator. I see this kind of argument over and over, and honestly "no true Scotsman" is the only way to describe it. Iterators are part of modern C++ by any account.
Thanks, I guess mutable buffer passed as another argument might be acceptable workaround.
Thanks for the update! Now that tock builds with Cargo does it also build with a recent Rust?
Here you go: https://github.com/LTD-Beget/syncookied
Thanks!
Ah, yes... this is an old argument, and perhaps I should change my wording. The same comments come up in Java discussions as well. I've always been loose with my definition of memory leak, as for me what I've meant is that coming from C and C++ a memory leak was forgetting to free alloced memory. If we want to be pedantic about it then there is no language that prevents memory leaks (well at least non that have heap allocation, and arguably non even if they were restricted to the stack). But there are memory safe languages (like Rust) which guarantee, under normal circumstances, that memory will be freed at some point. But, I will go back and change the wording. Honestly, I forgot that `std::mem::forget` isn't unsafe, I used it once in some FFI code (not in this project). Side conversation, should `std::mem::forget` be "safe"? Or a different question, when are people using `std::mem::forget` in a manner that is "safe"?
I'm using `serde` (in particular, `serde_yaml`) to parse a config file. Yaml knows about various types, such as strings and ints, and it seems to me that `serde_yaml` is able to identify them and extract them appropriately based off of the example that they provide on their readme. However, their example only creates a `BTreeMap` from `String` to `f64` - how would I go about making a mapping from `String` to any of the types that get read in? 
Thanks a bunch!
Interesting! Maybe you can also help with finding a good API for the next version of hyper? (There is also tokio-hyper as a POC.) I'm pretty much waiting for more async stuff to land/converge in a design before diving into web stuff with rust (again) :)
How would I go about implementing `serde`'s `Serialize`/`Deserialize` trait on structs that were not defined by me? *TRPL* says "either the trait or the type you‚Äôre implementing it for must be defined by you", which I think means what I want to do is impossible; however, this leads me to a follow-up question: how do people then accomplish this use-case, which I think would be rather common (such as when trying to serialize types from a library that you didn't create)?
Well I got downvoted for the answer: https://www.reddit.com/r/rust/comments/4yxz98/a_year_of_rust_and_dns/d6rr713 There are full internet scan dumps out there, there is a service which makes use of the data: DNSDumpster It will only discover a domain if it's on reverse lookup.
&gt; It is rather hard to implement actually. Isn't the bigger problem that those traits are unstable?
Yes, that's an issue as well. I'd still merge patches if they implement such a feature as long as it must be enabled via a compile option (`cfg(unstable-foobar)` or so).
There was [AXFR](https://en.wikipedia.org/wiki/DNS_zone_transfer) but apparently some people think it's a bad idea to have the description of your entire internal network leaked to the internet.
I was just griping about having to give up custom derive in a library I'm building. It's so convenient to use it with serialization, giving it up is a real pain. This will be a really big win for me.
I don't think that estimates like this are really possible, but one of the points of the RFC was to be as minimal as possible to ensure a speedy path to stabilization, so we'll see.
Three (simple, I think) questions: 1. Where does the name ("Rust") come from? I tried googling and came with nothing... 2. Is there a reason not to require parens on loops? (C-like) 3. I like them but the compiler warns about them being unnecessary: is there a way to turn off the warning only for loops?
&gt;Side conversation, should std::mem::forget be "safe"? Or a different question, when are people using std::mem::forget in a manner that is "safe"? Always. In Rust safe means unable to: access a null pointer, read uninitialized memory, break pointer aliasing rules, have data races, and create invalid primitives. In Rust bad things that can happen even in "safe" code: non data race conditions, leak memory, abort program, overflow integers, deadlock. https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html Other than the part where Rust's ownership system and smart pointers make it hard to forget memory deallocation, Rust provides zero protection against C and C++ style memory leaks. 
Any reason to require named args?
Thanks! I'll keep looking, for now I'm getting confused :)
I'm running into an issue that I would normally classify as 'non-lexical lifetimes needed', but I can't get around it even by explicitly bounding lifetimes with explicit scopes: https://is.gd/PJbRgI The interesting part (there are good reasons I can't use `HashMap::entry()` here -- I need a mut borrow of it in the 'vacant' case and may insert other keys in the process of building the new value): fn do_stuff&lt;'a&gt;(m: &amp;'a mut HashMap&lt;String, String&gt;, key: &amp;str) -&gt; &amp;'a str { { let maybe_entry = m.get(key); if let Some(s) = maybe_entry { return s; } } m.insert(key.to_owned(), "new_value".to_owned()); m.get(key).unwrap() } Any ideas? EDIT: I'm getting around this with `if let Some(s) = unsafe { transmute(m.get(key)) } { ... }` for now, but obviously this is a bit distasteful...
One option is to create a newtype (`struct MyType(TheirType)`) and manually implement the traits for your wrapper.
From: https://www.reddit.com/r/rust/comments/27jvdt/internet_archaeology_the_definitive_endall_source/ &gt; "Rust is named after a fungus that is robust, distributed, and parallel. And, Graydon is a biology nerd."
The crate `custom_derive` works on stable.
&gt; Rust provides zero protection against C and C++ style memory leaks. Do you mean in FFI C/C++ code? or do you mean in general? b/c I'd say Rust is pretty excellent at making sure memory is freed.
You could also use something like `.map(|x| x.to_owned())` to convert all those `&amp;str`'s in the split into owned `String`s, so that you can pass them around without worrying about their lifetimes at all. That'll cost you a memory allocation and a copy for each one of them, but if this isn't super-high-performance code you probably won't notice the difference. Here's an example: https://is.gd/EEpE8P
Ok, that is a crazy long thread, definitely don't want to rehash it here. From the docs, I think this is the most useful thing: " This function is not marked as unsafe as Rust does not guarantee that the Drop implementation for a value will always run. Note, however, that leaking resources such as memory or I/O objects is likely not desired, so this function is only recommended for specialized use cases. " Basically, it is intended for well known situations where drop is undesired. Makes sense, and I've only ever used it in FFI, which usually contains at least a few unsafe blocks.
Yeah, coming from C I'm used to the parens and find it weird reading loops with no parens... Maybe you're right, they don't contribute much so I should just get used to it. Thx for the answer! PS: I never really liked the looks of Ruby
I suspect this means we won't ever really have namespacing for macros or derives?
We will, but not until macros 2.0
I can't tell if you want a clone of Pokemon Go written in Rust or if you are in the wrong Subreddit. I'm thinking the latter though, so here you go /r/playrust.
Nice, good to know! Thanks!
So, you might want to look at the various threadpool crates on crates.io for now. The stuff to do this really nicely is _just_ coming along, "futures-rs" and "tokio" are a current work in progress that will make this fast and efficient in the future, but were just announced, so it's a bit wild-west at the moment.
Assuming that the representation of a 32-bit number if well-defined by Rust's documentation and isn't just an implementation detail like it is in C, sure.
Working a language where the programmer specifies message types and a state machine, and it's used to generate networking code across languages. https://github.com/tmerr/adele . I think I have most of the details worked out in my head so I'm getting started with the coding now :D
My Scala experience involved dealing with too much Java interop, so it was more of an issue for me. What is most annoying is that null values don't turn into exceptions at the point where you enter Scala code, but only later when you invoke methods or have unboxing. I have a similar problem with Haskell's error function (Not used for exception handling, more similar to a panic). Because of Haskell's lazy nature it often isn't triggered where it would help debugging.
I just pushed a new lint to [clippy](https://github.com/Manishearth/rust-clippy) today, with the awesome help of /u/mcarton. Also now that my [RFC 1623](https://github.com/rust-lang/rfcs/blob/master/text/1623-static.md) has been accepted, I'm going to implement it. While waiting for the Rust build, I'll be running around clippy-ing projects left and right.
Are there any plans for UDP support in tokio?
Here's the second way to implement the `/(?x) (.*?) remainder/` parsing in nom: http://play.integer32.com/?gist=a585a81649b69f4de69181481ee2322a It involves extending nom with a new macro. The macro that scans the input looking for the remainder and then returns the text before the remainder as well as the parsed remainder. Here's how you implement regex-like replacement with this building block: let mut output = String::new(); let mut pos = input; while let IResult::Done (tail, (head, parsed_remainder)) = take_until_parse_s! (pos, parser) { output.push_str (head); output.push_str (parsed_remainder.whatever()); pos = tail;} output.push_str (pos); And here I've added a second macro, `take_until_find_parse_s`, that can be optimized with SSE2 search from `jetscii`: https://gist.github.com/ArtemGr/63a5957fb8b342e097f100d857e3dbf6 P.S. The new macroses (take_until_parse_s, parse_replace_s, take_until_find_parse_s, find_parse_replace_s) are now a part of gstuff: https://github.com/ArtemGr/gstuff.rs
Something I don't get is why the `loop` would be required in the `tick()` method. Every code path in there returns a value, so why loop?
rustup is amazing. Thanks so much for providing it. Completely unrelated: but is there a chance to move the self update stuff into a cargo crate? I looked into self updating rust binaries recently and the amount of stuff needed to make that work on Windows is quite impressive.
I hope we will - this RFC is hopefully hitting the sweet spot in that it is using current macro tech for using derives, and new macro stuff for defining them. So moving from 1.1 to 2.0 should be fairly painless for both parties. Having said that, naming for custom derives is a bit complex and there isn't a long term plan yet, so I can't say for sure this will work. I pushed pretty hard on 1.1 only applying to custom derive so that it doesn't affect the chances of macros 2.0 happening for more general macros.
I tried reading through the RFC (rendered?) and I'm not sure I understand what this means (I'm a beginner). I gather one of the side effects is that `serde` becomes usable in stable which is a huge plus, but what is a "procedural" macro? Does that mean macros can be defined as rust code processing the AST instead of the current method - which is similar, but not wholly rust code processing?
This is, in terms of functionality, performance and traceability of code through macros strictly a step back. However it is a *necessary* step back so we can have more freedom to find a better solution to move to in the long term. Also procedural macros on stable, however limited will probably be a net win, despite not many of the advantages over plain code generation remaining in the current design. I'm cautiously optimistic.
Exactly. *if* I go back and update that code, I'd probably switch to bitflags! But for now, it works fine, and I don't think it's is less functional, so I probably won't make the change at the moment. I've been thinking of switching over to Serde all the parsing and stream processing, at that point I'd look at making this change.
We could have a dynamically-sized heap-allocated enum that would be (relatively) expensive to create but extremely cheap in memory and cheap to read, any point in code where it is read would statically know how many bytes the variant would be.
Thanks for the nice words! It means a lot to us! We will keep up the good work!
Package manager and package manager manager 
Rustup lets you compile different projects with different versions of Rust. This includes nightly, beta, release, and versions for other platforms. It will download the necessary files to compile for another platform so you don't have to do it manually. Cargo is the Rust package manager that has a central repository http://crates.io for compiling packages from source code and getting all of their dependencies automatically. What's impressive about Rust is the focus on automatically doing these tasks and having just one official tool to do it. What's more is that these tools usually do the right thing, and get better over time.
Package? I'm sorry if I'm bothersome.
Package as in library. If you've ever used Ruby or JavaScript, cargo fills a similar role to bundler or npm. It helps you manage the libraries you're using to build your program. You should probably be using cargo to compile your programs, rather than using rustc directly, because it makes a lot of things easier. Rustup helps you manage which version of Rust and cargo you are using, lets you use different versions in different projects, makes it easy to update to the latest version of Rust, and so on. Read more here: https://crates.io/ (cargo) https://rustup.rs/ (rustup)
[This page] (http://doc.crates.io/guide.html) should give you a good idea or what cargo is and what it does 
Yes, that's right. The type of macros you define with `macro_rules!` are called "macros by example." The kind that just got green lighted in that RFC are procedural macros, where a function defined as a macro receives the actual AST of some code, can do whatever arbitrary logic it needs to transform that code, and then returns the final AST, which the compiler inserts back into the user's code.
Or `Arc` !
That is exactly the plan, pretty much, as laid out in rfc 156-something, which was just accepted (sorry, on mobile now)
Hey, it is great that the author of tokio comments on my post. I will use this chance to ask some simple questions with probably obvious answers. :D Thanks for your explanation of `write_all`. I will fix it after I understand how my code should work. Suppose I receive a long message and read the first bytes into the buffer. I try to write them to back to the `TcpStream` but it would block. So I return `Tick::WouldBlock` and store how many bytes wait to be written. Since there are more bytes in the `TcpStream` will tokio call `tick` again or does it know that I want to write some bytes and wait until the stream is writable? In the first case, am I expected to always read all bytes from the stream? &gt; They are actually slightly different. The implementation directly on TcpStream takes &amp;self where as the one for io::Read and io::Write takes &amp;mut self. I find this interesting. With `io::Read` and `io::Write` taking `&amp;mut self` only one can write or read the stream because of the ownership and borrowing rules. If `read` and `write` are `&amp;self` is it possible to do parallel reads and writes? And doesn't it may cause garbled output if multiple tasks write to a stream at the same time? &gt; Regarding DNS lookup, this is a high priority Oh, I missed that `ToSocketAddrs` may do DNS lookup. On a HTTP server I usually do not need it but I would like to have the comfort of automatic conversion to socket addresses. 
It will. :-) https://github.com/rust-lang/rfcs/pull/1561
I respectfully disagree :)
Correct link: https://github.com/rust-lang-nursery/rustup.rs/issues/678
&gt; If it were like coder543/openldap, that would be infinitely preferable. What specifically does this solve that `coder543-openldap` doesn't solve?
When you provide a service like crates.io, you have to choose a policy. You have two options: 1. you can say "we run this service so we'll do as we choose with crates and who gets them" 2. you can say "first come, first served." We decided to go with #2. #1 leads to a lot of complexity, for all kinds of reasons. Mutable state is very tricky when you don't have a borrow checker ;) In the end, append-only and immutable is the architecture we chose for crates.io, both technically and socially.
I would argue that that means that most people don't share the opinion that this is some sort of dire problem.
&gt; In any case, is anything being done to discourage this or at least make it reportable? You can always contact the crates team about that. I'll advise them to make this clearer on the page. Thanks for bringing it up. First of all: statistics. Automated processes download packages. So any package will have a slowly rising number in downloads. There's a couple of reasons for landgrabs: one of them is that people have a library ready soon (one common example was a windows-api crate with around 200 packages, where many of them had yet to be written, but fit a naming scheme). Others are pure landgrabs. If you need such a name, please contact the auther or the crates.io team. Pretty often, people grabbed a name in excitement and later found out that they couldn't follow through with the project. When it comes to policies, you can find them here: https://internals.rust-lang.org/t/crates-io-package-policies/1041 Edit: Issue here https://github.com/rust-lang/crates.io/issues/408
Nothing is *stopping* anyone from naming their crates that way either. I suggest you start a trend!
&gt; You can always contact the crates team about that You can, but we don't currently arbitrarily take crates from people and give them to others, nor delete crates that don't yet have code in them. We can try to put you in touch with the author to see if they'll give it to you, but that's the best we currently do.
That statement is definitely a false dichotomy, as mentioned elsewhere. There are other options, and they aren't burdensome.
Rubygems.org has not degraded in the way that it works over the years.
You may be interested in previous discussions on this topic: * https://www.reddit.com/r/rust/comments/2uc3m9/placeholder_packages_at_cratesio/ * https://internals.rust-lang.org/t/crates-io-package-policies/1041 
That's right. I woke up, grabbed my cup of coffee, and opened up the newest release of TWIRd. Life is good üòå
No need to apologize here. The community is really open and loves answering even basic questions so feel free to ask away and jump on IRC and ask even more there. To answer your question cargo is used to manage projects and get dependencies sort of like bundle or npm. Rustup is used to install specific versions of the compiler for projects making it easy to switch between nightly beta or stable.
Well, for one thing _I_ could upload `coder543-openldap` right now, correct? :)
\#1 always applies, even when \#2 is chosen, or \#N, it's just a matter of how it gets applied.
No, it does not, and it's important. Look at what happened with npm and `left-pad`: the CEO of npm intervening in the ecosystem, handing the `kik` package from one person to another, upset someone so much that they deleted all of their open source and caused a huge bruhaha. It's important that people be able to trust that things are stable and won't just go away. So, we have made a promise to our users. Yes, in theory, alex has access to the database table and could do whatever he wants, but it's important to state that policy is that he doesn't, and that we won't use that power that we have, in theory. (Except if compelled for legal reasons, of course.)
And with namespaces, you could create a `piston_framework` namespace, and put packages under it, still leading to confusion about the relationship between what you've uploaded and what they've uploaded.
Sure, but once `piston` would have claimed theirs (maybe with a logo on their crates.io pages) it would be a lot easier to tell them apart. It would actually be exactly what I want. A separate `piston_framework` group can work by itself without them having to worry that `piston` is disturbed, and `piston` doesn't have to worry about others using their best library names just because they got popular.
There is another CSON which is quite popular - https://github.com/bevry/cson (Atom uses it - http://flight-manual.atom.io/using-atom/sections/basic-customization/)
that is an excellent point to add to my repertoire on this subject.
This is why we can't have nice things. It's only a matter of time before someone exausts the entire dictionary, just to have it.
The piston team literally has their logo on their crates.io pages today. * Screenshot: http://imgur.com/VI5Gweb * Example: https://crates.io/crates/piston_window
Contrary to other threads, this is actually nothing to do with the namespace. [1] Rust is a new langauge, and it would take much time to have a good enough library for most things imaginable in Rust. Given enough time you will (hopefully!) see that a library you want is clearly visible from the search. If you cannot wait for any reason, it might mean that Rust is *not* what you need right now... [1] I know that this is very controversial subject, and I kept my urge to participate to the discussion down so far for that very reason.
Awesome, but that's not really what I'm talking about, it was just an example. It's great that they can mimic namespacing close enough, but then once again: So can I, correct? And since there's no way for me to see what `piston_*` crates are really affiliated with the piston project, the logo currently doesn't tell me anything.
This is the same as this [StackOverflow question](http://stackoverflow.com/questions/39098003/scraping-javascript-enabled-websites-in-pure-rust).
[removed]
Do you have any plan to deal with people who can't be contacted/get hit by a bus?
The plan currently is "Sorry, you'll have to pick a different name." Same as if they do respond and say "no, I am not interested in giving up the name."
Unless of course you use username-based namespaces like GitHub does, forcing it to be `some-person/piston_framework`. Which has the added benefit of making the authorship of any code you grab much clearer, which is a good security benefit ("I meant to grab the official Piston framework `piston_framework` but instead I accidentally grabbed the similar-but-trojaned `pistn_framwork`").
Certainly sounds like something useful. But that ties that feature to github doesn't it? Wouldn't any crates.io side umbrella functionality supporting github, gitlab, bitbucket, and non-standard sources require something like namespaces on the side of crates.io? What if a project wants to move from github to a self-hosted gitlab?
A crates.io user or group, not a github one.
Both asked by plusti. He's just using multiple sources to get his answer.
I also dislike that cargo is non-namespaced. What I've ended up doing is using github url's instead. I think it would be interesting if people stopped using crates.io and just used GitHub to circumvent these issues in the future.
Thanks! I'm pumped for it too :)
&gt; They could also grab the list of namespaces too. But they could never take `iron/cookies`, `iron/uri`, or any other simple obvious name the project hasn't thought about yet.
Yes.
Does crates.io have a _strong_ captcha system? What's preventing someone from squatting crate names like people do with domain names? One could use a simple wordlist and register every one, two, three word combination, set the website to some PayPal form, and profit. Suddenly crate namespaces sound like a bloody awesome idea.
I'm locking this thread for the following reasons: * The discussion has been had multiple times before * The discussion is not constructive * People are getting stressed, disheartened, and upset My apologies for dismantling the bikeshed, have a pleasant day.
Moved https://github.com/Keats/rust-jwt to ring and it took me about 5 minutes, great work!
Will the Carrier Trait also include a nicer way of going from an Option to a Result?
Just curious, have you tried the [parse-macros](https://crates.io/crates/parse-macros) crate? It works on stable. It has some severe limitations, sure, but it is also very powerful.
I tried doing that, but the issue that I'm running into is that `Value` itself doesn't implement `Deserialize`, meaning that the `from_str` method complains to the compiler that the trait bound is not satisfied. If I put in a specific type (ex. `String`), then it throws a run-time error when another type shows up (ex. `i64`) in the file. However, by perusing the tests, I saw that I could make a struct that implements Deserialize, and then basically just use that as a hardcoded map, which works for my use case. I still would like to know how to make a container hold a generic value - such as a `BTreeMap` from `String` to whatever - or be told that that's impossible.
It seems like you want an `or_err` method on option with this signature: fn or_err&lt;E&gt;(self, E) -&gt; Result&lt;T, E&gt; Then you could write `foo().or_err("foo didn't foo!")?`
 If the `or_err` method from above would be possible: foo().ok_or(Err("foo didn't foo".into()))? vs. foo().or_err("foo didn't foo")? 
Link to MP3?
Re: Read / Write require mutable access. There is actually a trick :) `impl&lt;'a&gt; Read for &amp;'a TcpStream` &gt; Suppose I receive a long message and read the first bytes into the buffer. I try to write them to back to the `TcpStream` but it would block. So I return `Tick::WouldBlock `and store how many bytes wait to be written. Since there are more bytes in the `TcpStream` will tokio call tick again or does it know that I want to write some bytes and wait until the stream is writable? In the first case, am I expected to always read all bytes from the stream? So, the reactor works using an "edge" notification style. Your task will only be invoked when the TcpSocket readiness initially changes from "not ready" -&gt; "ready". So, your task will not get called again simply because there are more pending bytes in the socket... However, if you think about it, that is ok, because even though there is more to read, your task isn't ready to make progress. Your task can make progress once the socket becomes writable again. So, when the socket is writable, you finish flushing the pending bytes and immediately try to read from the socket again... since there are pending bytes it will be able to continue to make progress. Basically, your task needs to do as much as it possibly can until it is fully blocked. Hope this makes sense. 
both `custom_derive` and `derive_builder` work on stable and we plan to keep it this way. :-)
Not only him, but all of the team is just plain awesome.
I wasn't aware of that, but thanks for pointing it out. I'd have to look at the produced assembly to answer that, unless someone from the core compiler team knows. People seem to generally dislike the way I have it there, which I find intriguing.
Cool. One thing about our macros that makes tooling easier is that the macro stuff has to be within `!()`, and tooling concerns were part of that, so I was wondering if they still found it super onerous.
/u/pcwalton had some good numbers for Servo too; I think that it might be moves, but that's based more on "what causes lots of memcpys" rather than some specific knowledge.
I'll just scrape off the "C" on my "I'm a crustacean" T-shirt.
&gt; Make the memory dependence queries in the memcpy optimizer nonlocal. This doesn't tell me a lot - I don't know much about how this works to begin with. Anyone have a good explanation? I see this: &gt; MemoryDependenceAnalysis - This is an analysis that determines, for a given memory operation, what preceding memory operations it depends on. from: http://www.llvm.org/docs/doxygen/html/classllvm_1_1MemoryDependenceAnalysis.html So it's a way of tracking loads and stores and I guess this patch would expand the scope of the analysis? Is this even close?
IIUC the current optimization of eliding memcpys works within a single block (think of it like a Rust scope, but in LLVM IR). This patch extends this optimization to try to elide memcpys across different blocks. For how this is exactly done, when/how does LLVM give up, can this be made even better... let's just summon /u/pcwalton It's an interesting topic.
Via webdriver maybe?
Wrong subreddit. You want r/playrust
Isn't that the point? You want to highlight the normal code path. On the other hand, if you're looking for early returns, you will be looking for `?`, which will almost always follow a `)` or be at the end of the line.
The author has the right ideas. 2016 was touted as the year of the Rust IDE, yet we're missing so much functionality that could make life much easier that it's probably not funny anymore. I mean, I can get by with the current state of the art, but an IDE with those amenities would make onboarding new Rustaceans so much easier. I do remember blogging about this last year, too. The author may want to look at [awesome-rust](https://github.com/kud1ing/awesome-rust), though this admittedly doesn't scale. Perhaps we should add some forge-like functions to crates.io?
* single threaded mioco echo: 136217 request/sec, * tokio echo (I believe, signle-threaded ATM): 157687 request/sec * multi-threaded mioco echo: 265042 request/sec I would have to re-run when [`write_all` bug] (https://www.reddit.com/r/rust/comments/4z2aa3/a_tokio_echo_server_in_35_lines/d6sc9jx) is fixed in tokio tcp echo, since the correct logic would be slightly more complicated, potentially changing perf. a bit.
I'm not familiar with all the different types of t-shirts there is.. of the short sleeves type listed, is there a difference in quality? or is it just the style?
Found some explanation: https://www.reddit.com/r/Teespring/comments/2odozy/whats_the_difference_between_a_hanes_tagless_tee/
If you run Servo binary with --help, there is --output output.png option, which may be of help.
I'm working on a [Master Password](http://masterpasswordapp.com) CLI clone. It's a stateless password manager. The idea is to use the full name of the user and a master password to derive a key with scrypt, and then use the key to deterministically generate passwords for each website using the website's name. The basic functionality is done, I'm currently finalizing the CLI.
Looks like you are getting close to the same parser abstraction as I use in combine. pub trait Parser { type Input: Stream; type Output; fn parse_state(&amp;mut self, input: Self::Input) -&gt; ParseResult&lt;Self::Output, Self::Input&gt; { ... } // Snip other methods which are optimizations/convenience } // EDIT pub type ParseResult&lt;O, I&gt; = Result&lt;(O, Consumed&lt;I&gt;), Consumed&lt;ParseError&lt;I&gt;&gt;&gt;; Have you been able to utilize the having the input as a parameter rather than an associated type? [I tried it](https://github.com/Marwes/combine/pull/61) but anytime I tried to benefit from by say having `Any` (which is a parser that can work on any input) instead of `Any&lt;I&gt;` (which can only work on input of type `I` rustc would not be able to infer the correct type. Also, have you considered moving the input type inside the result type? It is quite nice to be able to use `try!` for monadic parsers.
Has there been any update at all, even in an RFC or off hand comment or anything?
Yes, and the Maidsafe one can be remote! Just out of curiosity, anybody knows if it's fully remote or just US remote?
They are located in a small town in Scotland, so I suspect that it would be ‚ÄúEU remote‚Äù if anything. :-) If you look at their other job offer history (sprinkled over the internet), they request you to be available between 9am and 5pm GMT (or BST), IIRC.
So fwiw, I ordered this the first time it was up for sale. I love my Rustacean shirt, it's easily one of my favorites. Comfy, soft, and I like cute logos. I try to wear it when I'm out giving trainings, as a bit of Rust-vertising :) That said, I could do without the text on the back. It's rather obnoxious, and you sometimes get odd looks which is why I largely only wear it around other tech people.
It does. I've updated the blog post. Thank you for your explanation. By the way the fixed impl uses `try_write` and `try_read`. It makes things really easier.
I am not sure I completely understand the `or` example; from inside the function body, you are returning a closure. If I understood returning `impl Trait`s correctly, the closure needs to implement the `Parser` trait for this to work. I was looking through the source code and couldn't find where you implement `Parser` for any of the `Fn*`. So, how does this work? Did I misunderstand something? I am thinking of this code example: pub fn or&lt;I: Input, F, G&gt;(f: F, g: G) -&gt; impl Parser&lt;I, Output=F::Output, Error=F::Error&gt; where F: Parser&lt;I&gt;, G: Parser&lt;I, Output=F::Output, Error=F::Error&gt; { move |i: I| { let m = i.mark(); match f.parse(i) { (b, Ok(d)) =&gt; (b, Ok(d)), (b, Err(_)) =&gt; g.parse(b.restore(m)), } } } **EDIT:** `durka` on `#rust` helped me find the trait impl: https://github.com/m4rw3r/chomp/blob/experiment/impl_trait/src/macros.rs#L703-L711 
While on the one hand it's a nice thought, on the other, as long as you do things rationally, meaning you don't download unverified binaries over an unencrypted channel, it's not really a problem. Self-updating doesn't mean auto-updating though.
Have you tried IntelliJ? They've been hard at work, from what I hear.
Does VSCode have a lint plugin? I'm using Atom and the lint plugin is great. It compiles my project on file save, parses the output, and adds the red squiggles in the editor. It covers a huge part of what I'd want from a full IDE. 
I've seen it, but haven't tried it (yet), it's next on my list of things to try because that's official from IntelliJ isn't it? (or am remembering the announcement wrong?)
The small images at the top of every project don't load in Firefox 48 at least, maybe because they point from HTTP to HTTPS, not sure
In this case, the presence of `rustc_trans::type_::Type::metadata::h6b0fabf4f075d372` and `_&lt;rustc_trans.._match..MatchInput as core..fmt..Debug&gt;::fmt::h9fe8c1a13512a52c` make me suspect that this is caused by debuginfo generation.
Thanks! I was trying to make a smaller fragment that reproduces the error, but it seems that when I fix the errors/warnings in my code, the compiler error goes away. In any case, it does seem to be fixed on nightly. Thank you, and everyone else who replied. 
`Trait&lt;Assoc=Type&gt;` is the syntax for specifying equality constraints on associated types, so it's correct. Since `Mul` has a default for its type parameter, `T: Mul&lt;Output=T&gt;` is the same as `T: Mul&lt;T, Output=T&gt;`.
We finally released [syncookied](https://github.com/LTD-Beget/syncookied) - our syn flood mitigation solution - as an open source project.
Is there a way to obtain a variable number of mutable references into a slice without resorting to unsafe code? Currently I have the following code: fn split(values: &amp;mut [u32], used: usize, index: usize) -&gt; (&amp;mut u32, &amp;mut [u32], usize) { let (use_now, remainder) = values.split_at_mut(index - used + 1); (&amp;mut use_now[index - used], remainder, index + 1) } fn refs&lt;'a&gt;(values: &amp;'a mut [u32], indices: &amp;[usize]) -&gt; Vec&lt;&amp;'a mut u32&gt; { let mut v = Vec::new(); let mut rem: &amp;mut [u32] = values; let mut used = 0; let rem_0 = { let (elem_i, rem_i, used_i) = split(rem, used, indices[0]); v.push(elem_i); used = used_i; rem_i }; let rem_1 = { let (elem_i, rem_i, used_i) = split(rem_0, used, indices[1]); v.push(elem_i); used = used_i; rem_i }; let rem_2 = { let (elem_i, rem_i, used_i) = split(rem_1, used, indices[2]); v.push(elem_i); used = used_i; rem_i }; v } fn main() { let mut vector = vec![10, 11, 12, 13, 14, 15]; let indices = vec![1, 3, 4]; println!("{:?}", vector); for r in refs(&amp;mut vector, &amp;indices) { *r *= 2; } println!("{:?}", vector); } Is there a way to change the refs() function to use a loop to go through the elements of indices instead of the fixed-at-three-elements unrolled version shown?
yeah. that's explained a bit in the overview of the [neural networks page](http://www.arewelearningyet.com/neural-networks/). For the time being though, it still seems worth mentioning leaf, though I suspect the sorting of crates may need to take recent activity into account at some point in the future.
hmm.. I haven't been able to repro, and mixed-mode issues should only cause problems going from https to http. Part of me wonders if some ad blocker or other plugin is blocking shields.io badges. I'll take another look tonight.
Nevermind thanks alot man! lol appreciate u taking the time.
I'd be curious to see some kind of benchmark before/after. Like http serving (not micro benchmarking).
Do you know why C++ code isn't seeing the same level of improvement? 
This is great news for all LLVM based functional languages (IIUC)! Awesome!
Same, except for panic!. I read panic! as PANIC!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Very nice, I should probably add this to some projects as well as my [good practices article](https://pascalhertleif.de/artikel/good-practices-for-writing-rust-libraries/). --- Also, I keep wondering why people (incl. me) keep writing `cmd1 &amp;&amp; cmd2 &amp;&amp; cmd3` which produces [weird error messages](https://travis-ci.org/cobalt-org/liquid-rust/jobs/143378751#L335-L366). Something like abort_with() { echo $1; exit 66 } cmd1 || abort_with "first thingy failed" cmd2 || abort_with "second thingy failed" cmd3 || abort_with "third thingy failed" makes jumping to the last line and reading CI log output much nicer.
/r/playrust
That's a really nice article! (And a good suggestion)
Wow, that is nifty. Another point for Rust.
I think you're looking for /r/rust_gamedev
Oh, I was under the impression it was more in a beta stage, but that was just a poor assumption on my part. I will investigate around on /r/servo in the near future. One option I am evaluating is building the CEF library, but then I'm back in the C/C++ world - I don't mind being there, but I was hoping to use Rust. I could build CEF and then make some sort of rust wrapper, but I think it's silly by principle to do Rust/Servo -&gt; C/CEF -&gt; Rust/Wrapper. Maybe I'm just being picky at that point, so feel free to disagree with me. To go back into C, it looks like someone has already done the [grunt work](https://github.com/glennw/miniservo-gtk) with Gtk, so I could probably use the same concepts with something like SDL2...but this goes grossly off-topic.
C++ patterns are much less reliant on move optimizations and move there usually leaves an somewhat initialized object behind (as in, it can be reused). Rust move semantics are much simpler/strict, it's always byte-wise copy and nothing is left behind.
I don't know why everyone complains about not having an IDE... I use emacs with rust-mode and racer-mode and it's awesome.
Agreed.
I've been using GNU Parallel a lot recently, so I'm excited to see an alternate pop up. You might want to post this in /r/linux as well to get their input.
Work has begun, but in the form of experimentation on prototype projects rather than on an actual start to the RLS (nee Oracle). The good news is that it is a key project for both jntrnr and I for the foreseeable future.
Many/most functional languages do not do large memcpy's: they are much more aggressive about using pointers and thus doing 4/8 byte "moves".
Metaprogramming is great, it‚Äôs these blasted metaprogrammers that cause all the trouble.
I find that https://github.com/maciejhirsz/json-rust is a better fit for the case where you have more freeform data (nicer API on it's Value type). I think it covers all of the cases this crate adds for Serde by default, and without macros. However, I'm glad to see an alternative in Serde-land. 
Reddit doesn't support fenced code blocks, only indented ones. extern crate heapsize; extern crate num_traits; extern crate rustc_serialize; extern crate serde; use std::cmp::{self, max, min}; use std::fmt; use std::iter; use std::marker::PhantomData; use std::ops; import ( "heapsize" "num_traits" "rustc_serialize" "serde" "std/cmp" "std/fmt" "std/iter" "std/marker/PhantomData" "std/ops" )
That is nice! To be honest I wasn't aware it existed. (Kinda funny considering it's literary called "json"). As a side note, I feel that with all these nice libraries Rust does JSON better than JavaScript.
Thanks! 
That would be awesome indeed.
I remember writing a similar thing in Python some ~8 years ago to speed up our CI: we would describe the tasks to be done and their dependencies directly in Python, and the program would automatically parallelize build/setup/test as much as possible. I used the same approach (loop over active processes every N s to check which is done). It's amazing how that simple (crude?) loop can speed up things.
&gt;&gt; Finally, use can import things from other modules in the current crate, so you can't just assume the first thing in the path is a crate. I understand. In Go both crates and modules are merged into a single "package" concept (which may be a good or bad thing, depending who you ask) so I guess that's why they could afford a single keyword. Nevertheless I think a grouping feature would make both `extern` and `use` more pleased to work with especially if you use an editor without auto-complete(my case).
Wasn't too stoked about the ad on the back. Also, shipping to europe is pricy. So I just used an online t-shirt printing service to print [this design]( https://i.imgur.com/3O0clcJ.png) Am not a billboard and it's a nice rusty brown to boot.
Note that Rust requires the braces but not the parens, while C is the contrary. I think Rust's compromise is much better (leads to less surprises with braceless ifs)
Wow, that's a thorough answer, though maybe I don't understand all of it. I'm a highly 'surface level' programmer, heh. I do have a few questions though. Like I said, this is my first time working with such a low-level language, so even if I've read through a good chunk of the book it hasn't all clicked yet. * Why does a `Box&lt;Link&lt;T&gt;&gt;` work if a `Link&lt;T&gt;` won't? Is it _only_ because the unknown-size `Link&lt;T&gt;` is now on the heap instead of on the stack? * What are the differences between using a `Box&lt;Foo&gt;` trait object and an `&amp;Foo` trait object? * What do you mean by 'atomically update/swap objects', and why does larger than pointer size' matter here? * Adding edit: I thought the rule to structs with unsized types is that the final field and the final field only can be unsized, so why doesn't the first link example work?
/r/playrust
Also `set -e` aborts the script after first failure. `set -o pipefail` makes all components of a pipeline count towards the failure of the pipeline.
I agree that the effect will be most pronounced in Rust. However, even an 8-byte copy has to amount to a non-zero time, so I stand by my assertion that this will be applicable even outside of Rust.
&gt; Also, correct me if I'm wrong, but when you say a Box&lt;Foo&gt; can be moved around, this means that a Box&lt;Foo&gt; could be, say, returned from one method and then passed to another, and hang around for as long as it needs to, while an &amp;Foo would need a defined scope, right? Correct.
You're looking for /r/playrust, this is the subreddit for the Rust programming language. It's always amusing when this happens :)
I tried to reproduce the benchmark with GNU parallel 20160722, but using just the command line from the README I couldn't reproduce the extreme sluggishness: $ time parallel 'echo {}' ::: /usr/bin/* real 0m4.828s user 0m3.993s sys 0m4.237s $ time target/release/parallel 'echo {}' ::: /usr/bin/* real 0m12.517s user 0m0.146s sys 0m0.840s $ time target/release/parallel -d 1 'echo {}' ::: /usr/bin/* real 0m0.686s user 0m0.107s sys 0m0.593s 
Maybe your shell has a native reimplentation of `parallel`
Is there anyway to iterate over a range of type `f32` in set increments without breaking out a `while loop`? Example - here's what that would look like using C: ``` for (float curr = 0.5f; curr &lt;= 1.5f; curr += 0.5f) { .. } ```
I don't understand why polling is necessary. Would it not be possible to send the back on completion the worker id on a single `mpsc` so that the main thread knows where to send the next job? Or just stick them all into a `spmc` and leave workers dequeue items by themselves.
I've eliminated the need for polling, and eliminated the need for channels.
Haha :). Well, that works too. I can try both your code and `parallel` on an Arch box to see if I can reproduce your `GNU parallel` issue.
In C++ the moved away object can still be accessed, so the memory of the object has still to be associated with it. In Rust it's statically enforced that the moved away object can't be accessed, so a move doesn't even need to do a copy but can just associate the memory with the new object. 
`RUST_BACKTRACE` has been broken for me for a while now. thread 'main' panicked at 'test: SystemErrorCode { code: 1812, identifier: "ERROR_RESOURCE_DATA_NOT_FOUND", message: "The specified image file did not contain a resource section." }', ../src/libcore\result.rs:788 stack backtrace: 0: 0x6cefc2 - &lt;unknown&gt; 1: 0x6ccd5a - &lt;unknown&gt; 2: 0x6cd62a - &lt;unknown&gt; 3: 0x6cd4c6 - &lt;unknown&gt; 4: 0x6cd3d9 - &lt;unknown&gt; 5: 0x6cd35b - &lt;unknown&gt; 6: 0x704795 - &lt;unknown&gt; 7: 0x40622f - &lt;unknown&gt; 8: 0x403699 - &lt;unknown&gt; 9: 0x40c0f8 - &lt;unknown&gt; 10: 0x414702 - &lt;unknown&gt; 11: 0x6cd298 - &lt;unknown&gt; 12: 0x6d7418 - &lt;unknown&gt; 13: 0x6cc333 - &lt;unknown&gt; 14: 0x414cea - &lt;unknown&gt; 15: 0x4013b4 - &lt;unknown&gt; 16: 0x4014e7 - &lt;unknown&gt; 17: 0x7ffd41e413d1 - &lt;unknown&gt; error: Process didn't exit successfully: `target\debug\c4.exe` (exit code: 101) This is on nightly GNU 1.13 for Windows.
Most interactions with such small values will be direct loads and stores, which I believe LLVM already reasons about more aggressively.
In cases of "convenience vs. explicitness", Rust often opts for "explicit without sugar". I like that. Also, crates are regularly renamed when linking, so the syntax would need to remain, but only be invoked in special cases, which makes the whole thing more complex.
Looks like it. I can't be bothered to install MSVS on this machine atm but it's nice to know how to fix it if I really need to.
Yea that's exactly what I need. I knew somebody had to have made that already if there wasn't something like that in the std.
You may want to follow https://internals.rust-lang.org/t/line-info-for-unwrap-expect/3753.
But still: parallel 'echo {}' ::: /usr/bin/* &gt; /dev/null 26.85s user 12.48s system 215% cpu 18.236 total target/release/parallel 'echo {}' ::: /usr/bin/* &gt; /dev/null 0.34s user 2.02s system 118% cpu 1.998 total This ain't bad :).
You can also do `unwrap_or_else(||panic!("oh no!"))`.
why cant you do `expect("oh no!")`?
While we are on topic, I have always wondered why the following restriction existed? In imports, groups / braces can only contain items one level deep, why can't we group items with the same root together? Like this: use std::{ fs::File, io::Read } 
Because my version shows the "correct" source of the panic, while yours shows the line number of the `expect` method in the standard library.
This whole conversation is so nice to read... alternating between "awesome explanation" and "someone understood something", both of which make me smile ‚ô•
Added to https://wiki.mozilla.org/Areweyet
https://github.com/rust-lang/rfcs/issues/1400
&gt; Most monadic parser-combinators share the same type-signature (or something close enough), otherwise they would not satisfy the required composition operations. True, though if we compare with [parsell](https://github.com/asajeffrey/parsell) it uses many more traits to try and model commited and uncommited parsers which makes it quite different in the end. &gt; And yes, I seem to have managed to use the input generic as a type-parameter: any The return type `impl Parser&lt;I, Output=I::Token, Error=Error&lt;I::Token&gt;&gt;` is still parameterised by `I` which I believe is what lets type inference still do its thing. I tried to [parametrize it on the token/output type](https://github.com/Marwes/combine/pull/61/files#diff-22220c516cf66da9c3dfb5cca7cf802dL57) but that ended up making type inference fail. Didn't see the point of having as a parameter then since that only implied additional typing as associated types can be omitted when they do not matter. EDIT: I would be surprised if it matters if the input type is inside or outside as it is going to be de structured anyway in most cases. Then again, the benchmarking I have done this week has proven that LLVM was unable to optimize several things I expected it to easily deal with. 
I doubt your flag testing is your bottle-neck, and you can probably trust LLVM to do the right thing here (when compiling with optimizations), so why think about it? The "optimal" instructions on x86/x64 probably use "and" and then branch based on the zero-flag, which you cannot express directly in languages such as Rust or C, nor should you try.
You're looking for the... [BOOLINATOR!](https://github.com/DanielKeep/rust-boolinator). Although I believe /u/Quxxy disowns it...
That thing has been downloaded more times than `cargo-script`, `scan-rules`, and all the `parse-generics` crates, all of which took a lot of time. `boolinator` was a five minute joke. &amp;nbsp; *I loathe that damn stupid crate...*
That's a story about how fame works! ;)
That's for my taste a bit too much! ;) I just looked at my code what the most error cases are. Most "errors" - or lets call it results to be handled - are of type `Result`, `Option` or `bool`, which in quite a lot of cases should be somehow converted into the returned `Result`. For `Result` and `Option` there's already a nice, convenient and consistent way to handle them with `try!` and `Option::ok_or`, only the `bool` is a bit lacking. For me the `ok_or` operation on `bool` feels quite natural especially compared to the one on `Option`. 
Sure there is always a nice possibility with `iter`. Here is one: macro_rules! range_step { ($start:expr, $end:expr, $step:expr) =&gt; { ::std::iter::repeat(()).scan($start, |state, _| { let out = *state; *state += $step; Some(out) }).take_while(|&amp;i| i &lt; $end) } } fn main() { for i in range_step!(1.0, 7.0, 1.7) { println!("{}", i); } } [This prints](https://play.rust-lang.org/?gist=111911b074cd79a28d9414fe79fc1cda&amp;version=stable&amp;backtrace=0)... 1 2.7 4.4 6.1000000000000005 Float, fuck yeah \^\_\^
`multipart` 0.7 lists `hyper` 0.8 in its dependencies. If you just downgrade `hyper`, the program will compile. What's unfortunate is that it could force you to use workarounds for incompatibilities between 0.8 and later versions of `hyper`. For example, `hyper` 0.9 uses the external `Url` type for constructiing a `Request`, while 0.8 uses `hyper::Url`. Is there a recommended approach for resolving such problems?
Imho this is not really user friendly. It would be much better placed in a merge bot like @bors.
&gt;&gt; In cases of "convenience vs. explicitness", Rust often opts for "explicit without sugar". I like that. Simplicity is hard and I have to admit that I prefer convention over configuration(i.e. Go approach). Somehow they managed to use only one keyword without any conflict/confusion (i.e on linking etc) which I think it's laudable. &gt;&gt; Rust often opts for "explicit without sugar". Still I don't see any good reason to repeat a keyword 20 times instead to use a group-like syntax. Go allows you to use multiple import statements[3] too but in practice nobody does that after 1st week/month of coding. [3] import "fmt" import "xpkg" import "ypkg
It doesn't seem to work when compiling with `-O` with rustc versions bigger than 1.9.
I note that this comment has been reported for zealotry. However, high praise of other programming languages is not usually frowned upon here. (Note to self: try to switch off display &amp; code in perl)
I understand that cargo.toml is not part of the language. After all it's just a configuration file. I was hoping that it could be "generated" based on the `extern statements` but it doesn't seem to be the case. 
I stand corrected. Thank you, Huon.
As /u/thiez said, it's not really something you usually have to care about. One reason you couldn't make any sense out of the assembler might be that LLVM completely eliminated the checks. It could statically see that the results are `true`. You can use `test::blackbox` in the assignment to `value` to stop LLVM from doing that. And then LLVM still only does one comparison and reuses the result for both `println!`calls, because it knows that both forms are equal in this case. But as /u/thiez said, the comparision against a mask is strictly more powerful.
You still need to bring it into scope. Just because you list a library like serde in the Cargo.toml file doesn't mean it's in the code. It's just a dependency that isn't used. You need to to use extern crate to be able to use any of it's methods. If you don't use extern crate at some point then rustc won't work.
yes, cargo build --release 
&gt;You're going to need to post the C# code if you want us to draw any comparisons. Sorry I wasn't clear, I was only timing the loop, not the array creation. Yes the for loop does not make sense, it is just bench marking so I can learn the best ways to work with arrays in rust. It sounds like the answer is basically that you almost never should/need to use arrays, just use vector. 
I agree. There's an [RFC issue about it](https://github.com/rust-lang/rfcs/issues/1400).
That would be pretty nice to have as a feature and not having to pass extern crate in everywhere or at the crate root.
There's nothing quite as efficient for oneliners. Some command line switches to the interpreter, less than 50 characters of code, and most tasks that take a multiline script in Python are done. Sadly Python is the second best language for everything, so i know it much better than Perl, and the few times where I was sure I could have used Perl with dramatically less code weren't worth learning it to the necessary extent. Perl 6 is pretty awesome though, I'll learn it for sure once i find time.
Yes, stack allocation for small arrays is useful. Writing a small static array into the code is useful too. It is somewhat non intuitive though that you can get a stack overflow when you: Box:new([1.0;BIGNUMBER]) though. When you say arrays too large for the stack are rare in practice, I assume you mean *in rust* right? Because you would use vec for large dynamically allocated arrays? Because arrays larger than the stack are certainly not rare in general. 
I'm very familiar with those issues. The benchmark works fine for what I am trying to learn, once I used Rust properly the timing was exactly the same as equivalent C# and C++ code, as expected, and it is in fact impressive and cool that you can fold a vector and produce basically the same assembly as an imperative C++ loop. 
Interesting! The for syntax is different than in F#, and in a good way! Thanks for the tips. 
That would be cool, but could this work considering a crate can contain a lib + multiple bins at the same time?
That is in fact what makes it work; you can't depend on bins, only libs, so just one lib means that it's just fine.
No but I mean, currently there is no way to specify in your `Cargo.toml` that dependencies are only needed for your lib or for a specific bin. For example if you have an args parser in your dependencies and `extern crate`s would be inferred from your dependency list, it would be injected in your lib as well, no?
Seeing similar gains on my systems. My laptop takes 2m 9s with GNU Parallel and only 0.84s with the Rust version.
I've never really understood this issue. Is this primarily about improving the efficiency of generate code/ preserving zero cost abstraction?
I want something like this in `std` :) Does anyone know of an RFC targeting something like this?
There used to be special syntax for direct heap allocations. `box [1.0; 1000000]` would directly allocate the elements on the heap, instead of copying them from the stack or static memory like `Box::new([1.0; 1000000])`. The compiler team is currently working on a design for a generalized version that wouldn't hard-code the `Box` type and allocation source.
Yeah this is about memory efficiency and performance. The flag ends up adding an extra word to droppable items, which can lead to using more memory than expected. Performance wise since the flag had to be zeroed drop, it added a write. A year or two ago, I found they to interact poorly some LLVM optimizations for serde. In one of my micro benchmarks, I could see performance drop up to 15% with droppable types. I can't wait to see how we do with them gone. 
And the two pull requests might help even more :).
So why the copy? Because it has to move to an other stack frame? (Move happens at call/return time, so how come it isn't just pushd/popd?) If it's on the heap, then it should be just a small struct indicating the what and where, no?
&gt; Idiomatic &gt; Fold üòÇ I'm pretty sure if Niko had his way they'd just remove fold altogether.
Playing around with wrapping Agner Fog's `objconv` library with the `rustc`. What are the flags does `cargo build --release` normally sets for the compiler? I'd just prefer not to build a new cargo project in `/temp` every time I go to disassemble a single function. Thanks steve!
Really? Any particular reason?
It's been a while since I discussed it with him, but I believe we're both of the opinion that it just makes code way more opaque than necessary.
In this case you can use `sum()` instead. fn main() { let v = vec![1.0; 32000000]; let sum: f32 = v.iter().sum(); println!("sum: {}", sum); }
&gt; I've never really understood this issue. Consider some code like this: { let s = String::from("droppin'"); } Here, you know that `s` will go out of scope at the `}`. So we're good. But consider this: { let s = String::from("droppin'"); if something { drop(s); } // A } // B Here, does `s` drop at `A` or at `B`? You can't know until runtime, when you evaluate `something`. So how do we fix this problem? Previously, the solution was to add "drop flags" to everything that implements `Drop`. In other words, if you look at a `String`, it looks like this: struct String { ptr: *mut u8, len: usize, cap: usize, } (This is technically wrong but close enough for my point) What rust _actually_ does is something like struct String { ptr: *mut u8, len: usize, cap: usize, drop: bool, } (again, technically wrong but close enough) And it re-writes your code to something like { let s = String::from("droppin'"); s.drop = true; if something { s.drop = false; drop(s); } // A if s.drop { s.drop = false; drop(s); } } // B Again, slightly wrong, but close enough to get the idea. So, what's the issue? Well, every single `String` now has this extra flag attached to it, making it larger, even in the cases where you can statically determine how to drop it. It's also weird that adding a `Drop` impl makes your struct larger, and also means that FFI now has problems, since the definitions differ... Furthermore, consider two strings: we now have a drop flag and check for each one of them, wasting more and more space the more things we use. So, how do we fix this? The answer is "stack based drop flags", which means that we no longer have to add the flag to the struct, but instead, re-write the original code to something like this: { let s = String::from("droppin'"); let mut s_drop = true; if something { s_drop = false; drop(s); } // A if s_drop { s_drop = false; drop(s); } } // B Now, instead of being paired with the String, we store that flag on the stack instead. String isn't bloated anymore. Make sense? Again, I'm being _slightly_ hand-wavy with some details.
Good thing he doesn't!
Really? Then why do I get this result: struct S { _v: i32 } struct S2 { _v: i32 } impl Drop for S { fn drop(&amp;mut self) { } } fn main() { println!("{} {}", std::mem::size_of::&lt;S&gt;(), std::mem::size_of::&lt;S2&gt;()); // Prints 8 4 } edit: on both stable and nightly, according to playpen
It probably doesn't matter that much, but will LLVM merge all (concurrently live) drop flags in a function in a single word?
Because compilers are dumb, basically.
lol, I have no intention on spending time implementing `--bibtex` nagging.
I don't know anything about the details, but compilers are quite complex beasts, so what sometimes looks easy from the outside isn't that easy if you're looking at the details.
I wouldn't expect it to be a very important optimization anyway; most code shouldn't ever necessitate drop flags afaict.
First good news: Stable rust now has .sum() for iterators! let sum = v.iter().sum::&lt;f64&gt;(); Then complicated news: There's lots of ways to sum floating point numbers. The default way is both slow and inaccurate. Slow because the compiler can not autovectorize the sum, since it takes your request to add numbers in the instructed order seriously, and will not reorder additions. Inaccurate because rounding errors may accumulate. You can add with less error accumulation using the kahan sum algorithm https://en.wikipedia.org/wiki/Kahan_summation_algorithm You can add floats quickly using a different implementation that is autovectorized. For example using .scalar_sum() in the ndarray crate. The autovectorized sum is actually a bit more accurate, since it parts the sum into eight different streams that are summed in parallel, then the totals are summed up.
Generally speaking, is llvm able to optimize the copy away? 
This is definitely something really interesting if you combine it with rustfmt. Bringing in rustfmt into the ecosystem might allow the compiler to infer indentation and provide better errors as well. I think some people would complain that if the compiler uses indentation it's all messy, but we developers use indentation when reading code. It's actually weird that the compiler doesn't use indentation, even though there is a redundancy with curly braces, but that already existed. Since Rust is all about pushing stuff out of the developer's head and into the compiler, I this this is a natural fit, though I don't know how easy a maintainable implementation would be.
I'd be down with `extern crate hyper = 0.9.*;` or even `extern crate futures { git: "github.com/alexcrichton/futures-rs", version: "0.9.*" }`. Repetition is the mind-killer.
It depends, but certainly not if you don't ask for optimizations, which debug builds don't. This is how you get "works in release, crashes in debug" behavior.
Moreover I'd be down for a `.crs` format that makes mixes cargo and rust code. I.e. [this](https://github.com/DanielKeep/cargo-script) but designed for ergonomics instead of ease of implementation, as well as less emphasis on only using `cargo run` style commands.
[It's also on crates.io, by the way.](https://crates.io/crates/linefeed) As the title says, this crate is intended to replace GNU `libreadline` for Rust programs and it should run on all platforms supported by Rust (thought I haven't been able to thoroughly test it on all platforms). The API is nice and Rust-y, using traits for completion and custom functions. The user interface closely resembles `libreadline`, though not all features have been implemented. If there's any particular feature you want (like, say, vi mode), feel free to file an issue on the project and I'll see what I can do. I hope this helps those making REPL projects in Rust. Feedback of any sort is welcome. EDIT: Oh, it also reads existing `inputrc` files for bindings and settings (for those commands and variables which have been implemented). On Windows, I wasn't sure where an inputrc would be found, so I made up a new path: `%APPDATA%\linefeed\inputrc`. If there's anyone using GNU Readline on Windows and knows a more "standard" path for inputrc, let me know.
Oh right I just remembered that that would require cargo to parse the entire crate
Bring back .rc files
Oh, and the nomicon has a chapter too https://doc.rust-lang.org/stable/nomicon/drop-flags.html
And further, LLVM should often just be able to reuse the actual condition (like `something` in the example) rather than necessarily maintaining a separate flag on the stack.
&gt; Why does the "for x in" pattern go slower? ... I see that if I iterate more explicitly that speed is then good Does it? I ran a quick `cargo +nightly bench` with [this code](https://is.gd/Byyw9M) and the in/range/fold/sum variations presented in the thread all came out comparable and within each other's margins of error. running 4 tests test tests::fold ... bench: 102,067,176 ns/iter (+/- 2,175,857) test tests::for_in ... bench: 102,041,682 ns/iter (+/- 1,814,473) test tests::for_range ... bench: 102,351,656 ns/iter (+/- 1,822,336) test tests::sum ... bench: 101,743,320 ns/iter (+/- 836,509) I suspect something else was going on. Maybe it was different on stable? Edit: Pulling the vec allocation out of the bench iteration reduces overall time but not relative results. I originally avoided that because it doesn't have precisely the same semantics since you can't invoke `into_iter` to move the vector into the closure. running 4 tests test tests::fold ... bench: 29,176,816 ns/iter (+/- 703,092) test tests::for_in ... bench: 29,223,901 ns/iter (+/- 801,076) test tests::for_range ... bench: 29,211,877 ns/iter (+/- 827,700) test tests::sum ... bench: 29,152,604 ns/iter (+/- 861,693)
I cannot express how flattered I am that someone imitates GNU Parallel :) GNU Parallel is extremely sluggish because it does all sort of different things behind your back: It buffers output on disk (so the from different jobs are not mixed and you are not limited by the amount of RAM - it will even compress the buffering if you are short on disk space), it checks if the disk is full for every job (so you do not end up with missing output), it gives every process its own process group (so the process with children can be killed reliably with --timeout and --memfree), and a lot of other stuff. It lets you code your own replacement string (using --rpl), and lets you make composed commands with shell syntax: myfunc() { echo joe $*; } export -f myfunc parallel 'if [ "{}" == "a" ] ; then myfunc {} &gt; {}; fi' ::: a b c It does not need a special compiler, but runs on most platforms that have Perl &gt;=5.8. Input can be larger than memory, so this: yes `seq 10000` | parallel true will not cause your memory to run full. You can read a lot more about the design in `man parallel_design` and see the evolution of overhead time per job compared to each release on: https://www.gnu.org/software/parallel/process-time-j2-1700MHz-3000-1000.pdf In other words: See GNU Parallel as the reliable Volvo that has a lot of flexibility and will get the job done with no nasty corner case surprises. It is no doubt possible to make a better specialized tool for situations where the overhead of a few ms per job is an issue and where you neither need seatbelts nor airbags. xargs is an example of such a tool, and you can have both GNU Parallel and xargs installed side by side. 
Nice. Is it something intended to fit in a microcontroller?
[removed]
Without `extern crate` dependencies would be included or not included in the code essentially based on command-line flags. `extern crate` at least means it'll fail explicitly if you compile with `rustc` and don't include some dependencies. Some big projects don't use cargo because they predate it or need custom tooling, and the lang team understandably would not like to tie the dependency manager/build tool to the compiler.
Oh... jesus i feel stupid. Thanks haha...
The indentation awareness is only required during error reporting. The parser also already stores spans. Also the parenthesis are vital in getting rid of if-else-ambiguities.
I was looking forward to a crate like this! Previously I tried `readline`, which has a pretty unergonomic API, and `rustyline`, which had some functionality problems (home/end keys didn't work, among other things). This seems to both be functional, and have an ergonomic API. My one complaint is that it depends on `libtinfo`, which seems to be a pretty obscure dependency. I'm on Arch Linux, and I had to install it from the AUR, because it wasn't in the official package repositories. This doesn't give me much confidence that users will have `libtinfo` readily installed. Would it be possible to have a build script to compile and statically link libtinfo at build time, so users of one's application don't have to hunt it down?
I believe they should be the same. You can see the `const` declaration [here](https://github.com/antoyo/des-rs/blob/97031b96ebb2534a8b0bb9cf3cc675048fb0d742/src/lib.rs#L258). When I run `cargo bench` with the `const` declaration, I get: running 1 test test bench_decrypt ... bench: 1,621 ns/iter (+/- 15) Try replacing `const` by `let` and I get: running 1 test test bench_decrypt ... bench: 18,203 ns/iter (+/- 99) On another benchmark, I think it was 4 times slower with `let`. Is there any explanation about that? What seems even stranger is that using `get_unchecked()` [here](https://github.com/antoyo/des-rs/blob/97031b96ebb2534a8b0bb9cf3cc675048fb0d742/src/lib.rs#L302) instead of `[]` does not seem to improve the performance as much as I expected (something like 0.5% faster) even though the cost shown by `callgrind` changes from 10 to less than 1. I will do some tests to get more information about this. N.B.: I made the changes mentioned in my previous post: now my `des` crate is only 5 times slower than the OpenSSL implementation!
clever: https://github.com/bluss/rust-ndarray/blob/master/src/numeric_util.rs#L18
I know, but how often will you write such a code? I got this error a while ago and it took me some time to understand what was going on.
Yup. That's the worse. It's happened in some JS and Rust programs I've worked on and the error is in the absolutely wrong spot because of the easy way.
That seems very strange. File a bug?
I would watch a stream of Rampage Jackson programming in Rust forever.
The `libtinfo` dependency is unfortunate, but, I think, unavoidable. It is a part of ncurses, so I had hoped it would be pretty ubiquitous on Linux systems. However, I'm not very familiar with non-Debian distros. I want to make sure `linefeed` will support any Unix (pseudo-)terminals in use, rather than just targetting xterm and the like. `libtinfo` comes with the `terminfo` database, so I think it would be rather difficult to include it in the build process with Cargo. How difficult or troublesome is it to install from AUR? I could add a note to the README with install commands to help Arch users.
Results on my i7-6700HQ running Arch (3171 files in /usr/bin), wall clock time, median and standard deviation of 7 runs, in seconds: Gnu: 5.39 ¬± 0.09 Rust: 4.8 ¬± 0.3 Are you sure you didn‚Äôt make a typo somewhere in that Ubuntu command? 
It's not rolling my own crypto, I'm just using scrypt. Anyway, I won't recommend anyone to depend with his life one it.
Just a tiny correction, but you got a typo in your second code block. You forgot to change the `if s.drop` to `if s_drop`.
You might want to try compiling the code with optimizations (which unfortunately currently seem broken for rustc &gt; 1.9).
Yes, all I'm saying is that if you make it indentation aware, then it's worthwhile to use it for more than error reporting. Put differently, I don't think you can make it a little bit indentation aware just for error reporting without allowing parentheses elision.
Aren't `ncurses` and the `terminfo` database (`/etc/terminfo` or `/lib/terminfo` or something) available in the official repos? Perhaps `libtinfo`'s symbols are simply built into the library for `ncurses` because standalone `libtinfo` is not seen as necessary. Even so, that seems odd to me. On my Ubuntu install, `bash` links `libtinfo` directly without `libncurses`.
Not really. They might be packed together at the byte level, but that's not necessarily going to happen. That said, drop flags aren't actually going to be around in many functions. The compiler detects "static" drops, where the value will always be dropped at a given location, and doesn't bother with drop flags in those cases. That's actually the common case, as dynamic drop is when something is moved in one branch, but not another. On top of that, the optimiser can reason about the flags pretty well. The way the flags are used is pretty trivial compared to most code, so LLVM will happily get rid of them in many cases, often just reusing the original condition that set the flag in the first place. It may also shuffle code around if it can so the flag check is implicit in the control flow (think generating an else block for an if).
Beautiful! Thanks a bunch!
No worries; it happens quite often!
You can just write: script: - cmd1 - cmd2 - cmd3
So if drop flags are gone, should this section of the nomicon be removed?
Let's not forget the representation issue too. You could not implement `Drop` on a `struct` which layout you wanted to carefully control because a boolean flag would be added. Really annoying when precise bitwise control was necessary.
Is it done using gitbook? It's a really nice website.
Not a big fan of having the landing page being a gitbook, I'd prefer it be at /documentation/ or something.
If you see anything that is unclear or needs more detail please let us know by filing a GitHub issue (https://github.com/serde-rs/serde-rs.github.io/issues) or dropping by our IRC (#serde on irc.mozilla.org). There is a lot left for me to do - I am still working on a thorough explanation of the Serializer/Deserializer/Visitor traits, I have a few more examples lined up, and our rustdoc (https://docs.serde.rs/) is in pretty poor shape so that may be next.
I opened an issue for this almost 3 years ago! https://github.com/rust-lang/rust/issues/10483 (now moved to the RFCs repo: https://github.com/rust-lang/rfcs/issues/630)
All this cli ergonomics activity is making me hopeful that one day we'll get something like [prompt-toolkit](https://github.com/jonathanslenders/python-prompt-toolkit) in rust.
Hmm, might be a bug. I can't see why it would be applying the coercion here. The use of the Unsize trait outside of the CoerceUnsized impl might be a reason though. Rc doesn't have them for its PartialEq impl, for example. 
Or modified, yes. Let's wait till this lands in stable first.
Does this mean that when Rust 1.13.0 is released, we will be able to implement `Drop` for `#[repr(C)]` structs?
Thanks, since you both seem to agree it may be a bug I've filed an issue about it. https://github.com/rust-lang/rust/issues/36007 The `Unsize` constraint wouldn't be needed here, but is for the rest of my code.
I believe that that will be possible. It's one of the most annoying things which drop flags have imposed upon us. 
/r/playrust
I was running with the same buffer: 16KiB. I redo the test using newer version and performance is quite the same. My guess is, that `write_all` usually writes everything anyway. The benchmarks I'm using are checking the response and compare it with what was sent, so they would complain if any data was missing.
Linking to `ncursesw` works on my system, as well. (There's some neat little text file in place of `libncursesw.so` that includes both the actual `.so` and `libtinfo`. I didn't even know that was a thing.) It's hard to say whether this will provide better support for all reasonably possible Linux distros, but I'll give it a try and see if I get any issues on it. Thanks for bringing this to my attention.
For some reason I think that when the first command fails it will continue and run the other ones. (Will look at Travis docs to confirm)
Currently I can't think of a lot of cases were I want to convert a `bool` into an `Option`, but there's IMHO nothing wrong having this `Into` implementation, but I wouldn't like if this would make the more often case - anyhow in my code - to be more verbose. I'm curious how the type inference can infere the `Option` here? try!(some_bool.into().ok_or("eeee")); Oh, is it because there seems to be only one `ok_or` method in the whole standard library? 
thanks a lot! In case of an update, is the version pinned?
If there is a PhantomJS-api lib you could use that. Otherwise I've build a small cli that takes a textfile with x lines, send these to my PhantomJS Webserver instance over local http 127.0.0.1 where it does stuff with the JavaScript and send that back as the http answer to my cli where it gets logged for me in a textfile. Works fine so far for me.
this has not been a good experience so far. Different errors for different versions, sometimes even 'An unknown error occurred'.
[japaric](https://github.com/japaric) has some useful resources on embedded development with rust: - A book: https://japaric.github.io/copper/ (https://github.com/japaric/copper) - "Testing ground" for the book: https://github.com/japaric/cu - Xargo, which can help you set up a cross-compiling toolchain: https://github.com/japaric/xargo 
Such is unstable features!
Have you tried let deserialized_map: List&lt;BTreeMap&lt;i64, BTreeMap&lt;String, BTreeMap&lt;String, String&gt;&gt;&gt; = serde_yaml::from_str(&amp;default_courses).unwrap();
Just for those not fully into lingo, is the "app store bitcode" the same as LLVM IR?
Here's an example of Racket using indentation information to give a better error message in this case: http://pasterack.org/pastes/6205
I think the protocol(i.e git, hg etc ) could be negotiated by cargo(Go works that way) so you could reduce that to 'extern crate futures "github.com/alexcrichton/futures"'
If stuff is regularly down, please file bugs. It shouldn't be.
I think you may want to repost this in /r/playrust
I think 100% Rust can't really be the goal. The Rust compiler (and particularly LLVM beneath it) doesn't make any guarantees about writing code that runs in constant time, which is a really important property for crypto. That's why the Ring library imports assembly implentations from BoringSSL. In addition to being super fast, the assembly gives us the constant time guarantees we need. Using Ring/RusTLS would be really exciting. Can Servo afford not to support TLS 1.1 though? Maybe it can?
An alternative has existed for quite a while ~~(probably at least an decade)~~ in moreutils. E: I was wrong, it's only 7 years old.
Game changer for FFI. Can we get drop-by-value next?
As usual, seeing my own words on reddit prompted a "duh" and I changed the top of vox_box from use sample::window::Hanning; to pub use sample::window::Hanning; and imported Hanning from vox_box rather than from sample. But I'm leaving this up here, because I want to know: is there another way to do this?
On a related note, what's with the `where` declarations? Is there somewhere I can read up on them? I'm mostly curious why I can't just do enum Closure&lt;A,B, O&gt; { Fun(Fn(A) -&gt; O), Pair( Fn(B) -&gt; Box&lt;Fn(A) -&gt; O&gt;, B) }
Type inference should take care of it in most cases or do you never want to deal with it, even in function argument and return types?
The only reason I'd expect Rust crypto to need unsafe is to call assembly, which is probably unavoidable for performance reasons. But the surface area of the actual crypto is relatively small compared to all the code you need to support it, so I don't think it undermines the point of doing it in Rust. As with all things Rust at some point at the lowest levels one must break the safe abstraction barriers and actually emit machine code.
Did you compile with optimizations enabled? (e.g. `cargo run --release`)
That type signature is Rust's subtle way of saying your data model might be a bit off :) It's a place like this that [serde_codegen](https://serde.rs/codegen.html) might be helpful. If you have the flexibility to change the serialized format, you could do something like this: #[derive(Serialize, Deserialize)] struct Course { lecturer: String, otherkey: u32, } #[derive(Serialize, Deserialize)] struct Semester { courses: BTreeMap&lt;String, Course&gt;, } #[derive(Serialize, Deserialize)] struct Schedule { semesters: Vec&lt;Semester&gt;, } ... let schedule: Schedule = serde_yaml::from_str(&amp;default_courses).unwrap(); This would expect your `default_courses` to look something like: --- # recommended route semesters: - CS101: lecturer: someone otherkey: somevalue CS102: lecturer: another one otherkey: another value - moremath: lecturer: someone else otherkey: someothervalue - ... 
One thing your first implementation is doing is that you're making multiple passes through your string. First to find your stop words, then to parse the numbers. The second implementation is parsing at the same time. I'm guessing this is the bulk of where your time is being spent. The second major cost is that you're searching for `','` from the beginning of the string. You could same some work by searching with `row[origin_stop.unwrap() + 3..].find(',')`. Third, I don't know where you're getting this implementation of `.parse()`, but maybe it's not implemented optimally. Forth, you are assuming your input is valid in your second implementation. Maybe `.parse()`is not making the same assumptions you are? Finally, you are also doing some redundant work by `.unwrap()`-ing a few redundant times.
Yes I did. Thanks for asking I should have mentioned it.
Support for existentials is weak in Rust right now but not non-existent. For this use case you should use trait objects.
I am reading the line several times. That is one of the reasons I thought nom may be faster. But I did not get it to do better. I did try `row[origin_stop.unwrap() + 3..].find(',') + 3` it made ~ 15 k-lines/sec difference. Better but not significant. parce is from [hear](https://doc.rust-lang.org/std/primitive.str.html#method.parse) whare it called [from_str](https://doc.rust-lang.org/std/primitive.u32.html#method.from_str). If std can be improved that is a great outcome. I will add some more validation. I doubt it will make things 5x slower. I have been wrong before. I did reduce the calls to `.unwrap()` but it did not make things faster. 
Another part of the community has a telegram chat: https://telegram.me/proRust
Yes, I do nead to add more validation. It will slow things down. I doubt it will make things 5x slower. I have been wrong before. I will look into using an iterator. Thanks. Maybe it can be made ievan faster. :-P
Ah Thanks! I guess the method I would need is `termion::input::TermRead::read_line()`. The problem with this is - as far as I understand it - , that it does not return if it was `\n` or `\r` :( 
termion hardcodes the escape sequences used to perform various terminal functions. It assumes the terminal you're using will interpret these escape sequences properly. `libtinfo` is used here to access a database containing proper escape sequences for each terminal. Whether hardcoding escape sequences would work just as well depends on whether one is using a terminal interface that accepts different escape sequences for the functions used by `linefeed`. That is a question that is difficult to answer. Is everyone just using `xterm` (and derivatives) these days and supporting these ancient terminals is no longer required?
1. Reboot 2. Run Rust Parallel 3. Reboot 4. Run GNU Parallel 5. Run GNU Parallel 10 times 6. Run Rust Parallel 10 times No changes
Hmm, why not... [Here's a version that uses iterators](https://gist.github.com/malleusinferni/2d7a51687f399c82747db20e724a76ba), and also does input validation and reports the line number where an error occurred. There's probably a lot of room for further improvements, but see where that gets you for now. **EDIT:** Updated with some minor improvements and a crude test harness. Compiled in release mode, it parses 100,000 rows in about 0.025 seconds. Not bad, I suppose.
I just tried out Rust for the first time over the weekend, wrote a simple [multithreaded grep clone with syntax highlighting](https://github.com/evanbowman/Oxide). It's incomplete right now though.
Thanks for sharing, I didn't know that we can create a simple parser in Rust as elegant as the first code. Is `row.find(" - ")` roughly equivalent to a for i in 0..end: if chars[i]=="-": return i in other languages?
&gt; Well, that's just a trait: you need Box or Rc or Arc or &amp; to make a trait object. I prefer to think of a trait in type context as a trait object and the trait itself as something that is no type. But the difference between your definition and mine seems a bit philosophical to me as you can't instantiate a raw trait (object) anyway.
The naive version could be made faster by being more explicit about "what you want". Your naive version involves iterating over each line more than once: let origin_stop = row.find(" - "); let des_stop = row.find(','); See that? Those finds involve the same traversal of characters that your second version does only once. Your first version will involve multiple bounds checks, and I believe the second will optimize most of these out. Why will it optimize them out? Because in the second you're only ever using array accessors that are a priori known to be within your loops. I believe llvm will correctly optimize this: while (ind &lt; row.len()) { ... something row[ind] ... } Such that `row[ind]` does not have an additional bounds check. But this: `let origin: u32 = row[..origin_stop.unwrap()].parse().expect("Failed 3");` The expression `..origin_stop.unwrap()` I believe will insert bounds checks. Yes, even though you and I both know that it will be in bounds, the compiler often does not have the appropriate hints (and smarts) to remove bounds checks in every possible case. (The answer why involves some CS theory.) Generally speaking: iterators are nice because they provide the right hints to LLVM that expressions are within bounds. Not using iterators (as you do in both examples) means that it doesn't know that. *That said!* Your code in your second example is written in an iterator-like fashion. That is, you perform loops over an index, and then access data based purely on that index. Your "naive" version looks like it would correspond extremely closely to someone "unrolling" iterators. tl;dr: Your first attempt is not actually using "zero cost abstractions" because it is not idiomatic, and so Rust inserts checks in your code to maintain safety guarantees. Your second attempt generates assembly I would guess extremely similar to what that of idiomatic, iterator-using code. So use iterators! You didn't in either attempt.
The only way I know is to use the template for the irc playbot, which has a VERSION const in it. You can run playbot on irc with --nightly VERSION. Right now it's answering `"rustc 1.13.0-nightly (499484f56 2016-08-18)"` actually. I'm just assuming this is using the same version and installation as the website, that might be wrong(?)
This is generally true, however the implementations of some targets (e.g. LE32 target, used in PNaCl) are explicitly designed in a way that uses a lowest common denominator of features. ~~I suspect the App Store bitcode is done in the same way.~~ /u/comex tells me that it is not: https://stackoverflow.com/questions/33680293/is-there-any-indication-as-to-which-apple-platforms-allow-inline-assembly
I tried, but it was not faster.
Hi, and thanks! I did try row[origin_stop.unwrap() + 3..].find(',') + 3 it made ~ 15 k-lines/sec difference. Better but not significant. I did try [slice_unchecked](https://doc.rust-lang.org/std/primitive.str.html#method.slice_unchecked) to remove bounds checks, but it made no difference. I will try with iterators, Thanks.
I've made [some measurements](https://gist.github.com/krdln/0b34319beb97cbe6bf5a1049bf9c268d), and the results are quite interesting. (assuming the compiler hasn't outsmarted these black boxes). Since searching and indexing in separate instructions is kind of antipattern in Rust (similarly how `is_some()` + `unwrap()` is an antipattern), I've tried to use iterators. So eg. instead of let origin_stop = row.find(" - "); let origin: u32 = row[..origin_stop.unwrap()].parse().expect("Failed 3"); I did (^(`splitn` is slightly faster than `split` if you know number of iterations beforehand)): let mut split_dash = row.splitn(2, " - "); let origin: u32 = split_dash.next().unwrap().parse().unwrap(); But it made no significant difference in the runtime (although I think the code is more idiomatic, as it gets rid of all `+1` / `+3` etc.). It turns out that the bottleneck was parsing `f32` (only `f32`, handrolled `u32` doesn't make a difference)! It seems that the `std` version is really slow (probably because parsing floats is really a hard job), compared to the handrolled one. It's quite possible that the handrolled version will loose some accuracy on the last digits on some edge case, but I'm no expert on this topic. Anyway, version with custom parsing and iterators is still slower that the fully-handrolled one, but it would be only fair to compare if the latter had proper error detection. Btw, binary char and string literals are handy: `'9' as u8 == b'9'`. **Edit**: So it seems that using `nom` or `regex` won't change runtime significantly if you stick to `f32::from_str` from `std`. There's a one more thing that is suspicious for me. I'm seeing 30√ó speedup, while OP reports only 5√ó. So either my artificial benchmark is producing wrong numbers (likely) or there's yet another bottleneck (either on Rust side, or the problem is just IO-bound) outside this function.
You can't instantiate one, but it is a real type, and is used in other contexts. In other words, with your definition fn foo&lt;T: Fn(i32) -&gt; i32&gt;(f: T) is using a trait object, which it's very much not!
Thank you! This is really useful information!
/u/Eh2406 I modified the naive `parse_row_1` implementation to simply be this: #[inline(never)] pub fn parse_row_1(row: &amp;str) -&gt; (u32, u32, f32) { let origin_stop = row.find(" - "); let des_stop = row.find(','); let origin: u32 = row[..origin_stop.unwrap()].parse().expect("Failed 3"); let des: u32 = row[origin_stop.unwrap() + 3..des_stop.unwrap()].parse().expect("Failed 4"); let dist: f32 = parse_f32(&amp;row[des_stop.unwrap() + 1..]); (origin, des, dist) } and it went from `1,546 ns/iter (+/- 388)` to `119 ns/iter (+/- 5)` on my machine. Parsing a floating point number is _extremely_ error prone, and doing it safely takes a lot of time, apparently. If you're feeling more cavalier about your parsing, then that `parse_f32` function does it much faster.
Hi, I will try and dig up my nom code. As I did not get it to be faster, I did not keep it. If [krdln](https://www.reddit.com/r/rust/comments/4zpgfs/zero_cost_abstractions_but_500_faster_parser/d6xunuy) is corect than it is not nom's falt. The nom would just pass to `std f32 from_str` which is the bottleneck.
Yeah, but all I mean is that the "knowing how to use them as intended" cost isn't part of "zero cost abstractions." Like, no zero-cost abstraction could have saved OP from walking the string multiple times in the first version, and not in the second; that's an algorithmic difference.
I guess what I'm saying is, when you say the bare `Fn` is a trait object, that's how I would then read a signature like this.
I like the compiler-based approach very much; I even wrote a bit about it at https://briansmith.org/GFp-0 regarding a subset of the problem. I've also created prototype translators/compilers. However, time-to-market (we've actually already lost the race), lack of resources, performance issues, and maintenance difficulties are all likely to be major roadblocks to adding crypto-specific optimizations to rustc. Also, as a crypto person, if we need to do compiler engineering anyway, I think we should consider building tools for crypto-specific DSLs (not `macro_rules!`, but independent languages), rather than trying to shoehorn crypto optimizations into compilers for general-purpose languages.
Now that plugins light are landing I can't wait to serde more. It's pretty great and my only real frustration with it was the whole making rust happy business.
&gt; The only reason I'd expect Rust crypto to need unsafe is to call assembly, which is probably unavoidable for performance reasons. Almost true, but not quite. See https://github.com/briansmith/ring/blob/master/src/polyfill.rs for some cases where we had to use `unsafe` to implement some missing language/libcore functionality it *ring*. Hopefully this will go away as Rust and libcore improve.
Have you considered adding some multithreading? It wouldn't make `parse_row` faster, but I imagine you could easily create 1000-line chunks by splitting on every 1000th newline character, and throw a threadpool at the chunks. From those numbers you quote it sounds like you're not yet IO bound.
Taking your function example, I'd say fn foo(f: Fn(i32) -&gt; i32)) would be using a trait object (if it were possible). So when I see `Type: Trait`, that's a type that implements the trait, but in places where types are expected like `let identifier: Type`, `fn&lt;Type&gt;(_: Type) -&gt; Type`, or `Box&lt;Type&gt;` , I think of `Trait` as a trait object (type) because otherwise it makes no sense to me to have a trait there. Because a trait is no type. 
Nah. It all gets inlined anyway. I just figured OP might like them.
The next thing I would try is to have it take [a Byte iterator](https://doc.rust-lang.org/std/io/trait.Read.html#method.bytes) as its input, so it can be used on a BufReader that transparently refills the buffer by reading chunks of data into memory. I'll give it a shot later if you like.
it already seems to be resolved - cannot reproduce the issue with the same nightly - 12 HOURS LATER.
Okay that's fair. I think turning the first kind of code into the second would be some AI, errr, "sufficiently smart compiler" stuff, though.
Good luck adding drop flags back, we already have a PR open for `union` which takes advantage of them being gone, and more trans cleanup changes are expetected :). Unless you mean whether we want to make their disappearance officially permanant, which makes sense.
For what it‚Äôs worth, you can always encode a rank-n existential as a rank-(n¬±1) universal. If you have a function that takes an existential as an argument, just change the quantifier to a universal and move it up a level: (‚àÉc. c √ó (A √ó c ‚Üí B)) √ó A ‚Üí B ~ ‚àÄc. c √ó (A √ó c ‚Üí B) √ó A ‚Üí B For a function that returns an existential, convert it to continuation-passing style: A ‚Üí (‚àÉc. c √ó B) ~ ‚àÄr. A √ó (‚àÄc. c √ó B ‚Üí r) ‚Üí r 
This sounds insanely interesting. Is there a paper about this transformation I could read somewhere? More details of any sort? Also, does Rust support higher-rank universals?
[Like this](https://is.gd/lBvDCo) Thanks I got it working it is coming in at 1200 k-lines/sec.
https://crates.io/crates/cue is very limited in functionality, but is made for situations where you need to bound the size of the work queue.
Hi there, I guess I'll introduce myself as I always do on these issues. I gave this talk back in December 2014: https://speakerdeck.com/tarcieri/thoughts-on-rust-cryptography These are difficult tradeoffs. I consider myself to be pretty conservative, so I think unless there's a whole-hearted effort to create a new TLS library in Rust, it's probably not a good starting point. I am quite interested in `rustls` and other efforts in this space. I certainly can't disagree with [pcwalton](https://www.reddit.com/user/pcwalton/) that it would be a shame for the Servo team to invest heavily in using a wrapper to NSS, BoringSSL, etc. only to have a promising mostly-Rust TLS library appear, but personally I'd rather see a concentrated effort on that TLS library, or starting with a wrapper to a commonly used library.
Beautiful, amazing work. This is going to have a huge impact on the Rust ecosystem. Thank you!
I think this is basically PL-theory folklore; I haven't seen a really good description because everyone seems to just know it. Rust supports higher-rank lifetimes: fn foo&lt;'a&gt;(&amp;'a u8) { ... } conforms to for&lt;'a&gt; Fn(&amp;'a u8) which you never see in Rust because we have this sugar: Fn(&amp;u8) That is to say, that function is higher-rank over all lifetimes (a single instance accepts all lifetimes). We messed around with this a bit last year; it was used a bit in the std lib (now removed), and by this library: https://github.com/bluss/indexing (it's README has some links to some of my sketches on it)
&gt; As I did not get it to be faster, I did not keep it. You should store everything in git, even these little projects :)
Is this now an official Rust project or officially endorsed? Let me just say that the design is absolutely gorgeous! Very nice work on that. I could see crates.io being redesigned in the same style. ;) 
&gt; Is this now an official Rust project or officially endorsed? It's been built entirely by /u/onuras and a small crew: https://docs.rs/about /u/heinrich5991 had picked up the domain, and wanted to donate it to a good cause, so I took it off his hands, and then when onuras was working on a front-end for crates.fyi, we talked and they decided to rebrand as docs.rs, since we had the domain. So, it's not, strictly speaking, from the Rust Project proper, but what does that even mean, really? :p I guess that would mean "run by the docs team", which it isn't. But pretty much everyone is really into this, glad it exists, and behind it fully. 
I wish it was possible to upvote this more than once.
Awesome! Small note: github's `Readme.md` presentation support some html tags like `&lt;img&gt;` with more features than otherwise available in pure markdown; on docs.rs, those tags are not parsed at all.
&gt; otherwise available in pure markdown "pure markdown" is a superset of HTML; that is, it's supposed to render them directly. (This doesn't really invalidate your point, just thought I'd mention it)
1. How can one get docs.rs to link to my website for the documentation for my crates, instead of hosting them itself? I haven't had time to think about it, but I have been very happy to have the docs hosted on my own domain and for now I'd rather keep it that way. 2. How can one get docs.rs to pass a non-default set of feature flags (e.g. `--features=rsa_signing`, which *ring* requires)? Or, how do I enable certain features in my library in a manner like `#[cfg(test)]` (maybe `#[cfg(doc)]`)?
&gt; But pretty much everyone is really into this Absolutely, me too ;) This is a great project that will be really beneficial to the whole ecosystem. And to top it of, it seems to be really well built. Kudos to /u/onuras and contributors! I think what I wanted to know is if this project is "officially endorsed" in the sense that we can now consider this a part of the Rust infrastructure. I am not sure what that even means, but I guess like, it would get some ressources or care if need be, we can rely on it and eventually think to integrate it a bit more with crates.io by making all the doc links point to it by default for example.
&gt; eventually think to integrate it a bit more with crates.io by making all the doc links point to it by default for example. Yes, I think this would be a a cool idea. It really depends on what /u/onuras wants; it's fundamentally their project.
&gt; have the docs hosted on my own domain and for now I'd rather keep it that way Is there any particular reason for this? You sort of loose the advantage of a centralized "doc warehouse" if everyone starts to point to his own domain. 
&gt; How can one get docs.rs to pass a non-default set of feature flags (e.g. `--features=rsa`_signing, which ring requires)? Or, how do I enable certain features in my library in a manner like `#[cfg(test)]` (maybe `#[cfg(doc)]`)? Currently there is no way to define extra features to build, but there is definitely [demand](https://github.com/onur/docs.rs/issues/29) for this. I think docs.rs will support extra features in near future.
Won't crates.io still link to whatever documentation URL you specify?
There it goes! I've been checking in every other day or so, now that it looked like it was nearing completion. Very nice! :-) What build environment is used? It could be useful to know so that one can have a feeling for what it will manage to build and not.
Actually, wouldn't it make sense to have this on crates.io itself?
could we get, like, newrelic uptime monitoring on it?
This is such a huge gift to the Rust community! Thank you so much!
A few times, I have accidentally stumbled into a subreddit about a game called Rust, instead of the subreddit concerned with the programming language Rust. Have you perhaps done the opposite here?
You want /r/playrust
I get 1400 k-lines/sec. So much cleaner than my nom. Thanks!
I just made a revision to `parse_{u32, f32}`. I'm now getting: test tests::bench_naive ... bench: 2,881,008 ns/iter (+/- 140,819) test tests::bench_nom ... bench: 147,026 ns/iter (+/- 8,668) test tests::bench_unrolled ... bench: 1,724,606 ns/iter (+/- 289,574) Is that real? `verify()` thinks so... o_O I actually had to change from comparing with `unrolled` to `naive`, as the revised parse_f32 actually has better precision than `unrolled`! (Way) faster and more accurate to boot! EDIT: another revision, forgot to simplify some math. A teeny bit faster still.
I get 2200 k-lines/sec! That is very close to the 2400 k-lines/sec I get with unrolled. Trying GNU instead of MSVC... That is a big difference. Your nom 2300 k-lines/sec vs. unrolled 2900 k-lines/sec
This is so great. And golly, the crate page is nicer than `crates.io`‚Ä¶ a bit of UI and branding collaboration would bring about some wonderful improvements for everyone!
Awesome&amp;huge.