By static link, do you mean passing `cargo rustc -- -C target-feature="+crt-static"`? Does that work with MinGW and MSCV?
I would suggest using `ring` + `curve25519-dalek`/`ed25519-dalek`. https://github.com/isislovecruft/curve25519-dalek https://github.com/isislovecruft/ed25519-dalek
Probably, but we could also just keep it like this until rustc gets a proper wasm linker.
Why *doesn't* bail allow for non string errors? My typical use of `ensure` and `bail` was to validate requests returning various `BadRequest` or `NotFound` errors as I went through a request handler
:-) the implementation details are interesting though! Where could one learn more of Mozilla's WASM execution engine?
Ultimately coherence reasons; I'd like it to allow for non string errors but it doesn't work. :-\
I haven't written anything even medium size in Rust, but this is the internet, so i'll share my thoughts anyway. &gt; For example, I'm very used to creating 'domain objects' (plain C# classes consisting only of data) and passing them back and forth between layers of my program as a sort of dependency-free communication medium. That should work in Rust too! &gt; I also do a lot of work with interfaces to provide abstraction around dependencies [...] A lot of my business logic is made up of classes that take interfaces that are then implemented by one or more other classes, turning the whole thing into a set of useful puzzle pieces that can be mixed and matched to create new things. How do these ideas translate to Rust, if at all? Using generic rather than parametric polymorphism. You can write a trait to define an interface, write code that takes inputs as a generic type bounded to that interface, then bind it to a concrete type a the point of use. You can do that at the level of structs or methods. I have an app that processes a stream of events through a pipeline - i'll show you some pseudonymised bits of it, so apologies if these aren't quite valid. I have a trait like this: pub trait EventHandler { fn handle_registration(&amp;mut self, user_id: u32, user_name: String, log_publisher: &amp;mut Publisher&lt;LogMessage&gt;) -&gt; bool; fn handle_checkout(&amp;mut self, user_id: u32, order: Order, log_publisher: &amp;mut Publisher&lt;LogMessage&gt;); } Then a bunch of implementations which do different things: debouncing duplicate events, rejecting invalid events (checking out with an empty order etc), and eventually, passing the events on to another system. Here's an implementation: pub struct UserChecker&lt;Next: EventHandler&gt; { valid_user_ids: HashSet&lt;u32&gt;, next_handler: Next, } impl&lt;Next: EventHandler&gt; EventHandler for UserChecker&lt;Next&gt; { fn handle_registration(&amp;mut self, user_id: u32, user_name: String, log_publisher: &amp;mut Publisher&lt;LogMessage&gt;) -&gt; bool { if self.valid_user_ids.contains(user_id) { log_publisher.send(LogMessage::UserAlreadyRegistered(user_id)); false } self.valid_user_ids.insert(user_id); self.next_handler.handle_registration(user_id, user_name, log_publisher) } fn handle_checkout(&amp;mut self, user_id: u32, order: Order, log_publisher: &amp;mut Publisher&lt;LogMessage&gt;) -&gt; bool { if !self.valid_user_ids.contains(user_id) { log_publisher.send(LogMessage::UserNotRegistered(user_id)); false } self.next_handler.handle_checkout(user_id, order, log_publisher) } } The main method of the app builds a chain of event handlers, each parameterised on the type of the next. The magic of generic polymorphism means that all those types are resolved to concrete types at compile time, and so there is no dynamic dispatch. Inlining can potentially reduce the whole chain to a single straight-line run of code, which is really useful if you're doing high-frequency, er, e-commerce. Some points about ownership in this design: 1. Handlers own their next handler. This lets them call mutable-self methods on it. You could do this by storing mutable references, but then you'd have to futz around with lifetimes. I don't think using references would buy you anything over taking ownership. 2. I pass event parameters (user_name and order) as owned values. Again, this avoids having to think about lifetimes, and it fits nicely with the conceptual model of a pipeline, where each stage does something to an event, then hands it off to the next stage and forgets about it. 3. I pass shared mutable supporting objects (like the log publisher) as parameters to the event methods, rather than making them fields in the handlers. Once more, this is about lifetimes - to share a mutable object between multiple stages, i'd have do muck around with some sort of Cell. If there were more of these things, i would probably wrap them up into an EventContext object, and just pass a reference to that along the pipeline. &gt; and abstract classes to facilitate code reuse; for instance, my database access code usually has an abstract base class that provides basic get/create/update/delete functionality, and then I implement more complex table-specific queries (or overload the defaults, if a table's a little special) on top of those. You can do creative things with traits here. Write a generic data access trait whose methods have default implementations, then write implementations of the trait for specific types where you override and add methods as needed. An example is a bit long for a post, so [here's the playground](https://play.rust-lang.org/?gist=1a1b65a57d08508a43b4a4762701f2a3&amp;version=stable). &gt; I also usually stick to a single class per source file, have a lot of folders that are 1:1 with my namespaces, and tend to split presentation, persistence, and business logic up into separate projects. This makes sense to me, but that doesn't seem to be what many Rust repositories are doing at all - I'm still not entirely clear on how Rust developers like to organize their projects. Lots of things seem all crammed into single files! I don't think there's a strict cultural preference for crammed files. I split my app into smaller files, one per domain concept, which means i end up with loads of modules, and loads of use statements linking them to each other. Each file typically contains a main struct, plus any enums, smaller structs, errors, and helper functions that go with it. 
My dream is a templating engine with 'development' mode which is dynamic, and 'production' mode which is (mostly) static.
I don't quite get what you're asking, but there is a difference between ``` fn by_reference(v: &amp;Type) fn consumes(v: Type) ``` where the first one just "borrows" the data and works on the reference, whereas the second one moves the data into the function, which then owns it and consumes the value ```v```. There is no function overloading in Rust, you will have to write two methods for "both behaviors". I hope I answered your question! :)
It might be worth fleshing this out a bit: #[derive(Debug, Copy, Clone)] struct Point(f64, f64); struct SizedConvex { vertices: Vec&lt;Point&gt;, } struct UnsizedConvex { vertices: [Point], } pub fn main() { let p1 = Point(1.0, 0.0); let p2 = Point(2.0, 2.0); let p3 = Point(3.0, 1.0); let c1: SizedConvex = SizedConvex { vertices: vec![p1, p2, p3], }; let c2: &amp;SizedConvex = &amp;c1; let c3: &amp;UnsizedConvex = unsafe { std::mem::transmute::&lt;&amp;[Point], &amp;UnsizedConvex&gt;(&amp;[p1, p2, p3]) }; println!("first vertex = {:?}", c1.vertices[0]); // value, one indirection println!("first vertex = {:?}", c2.vertices[0]); // ref, two indirections println!("first vertex = {:?}", c3.vertices[0]); // ref, one indirection } Making Convex unsized lets you pass it around by reference, but still get at the vertices with a single indirection. So, if you're going to make it sized, you want to be able to pass it around by value - like String and Vec. If Convex has no other fields, and doesn't need to be mutable, then this is fine. Convex is just a newtype for a slice of Points, which is a perfectly fine and conventional thing to do. If, on the other hand, Convex needs to have a significant volume of other fields, or have other fields which are mutable, or contain a mutable reference to the vertices, then that won't work - you need a reference to the Convex itself in that situation, in which case the sized approach does indeed involve a double indirection. 
Take that, CPU! :S
That's exactly what I was asking, thank you for your answer. So it does mean that I should either duplicate some of the code, forbid one behavior or let the reference function call the move function after having copied its argument? 
That's exactly what I was asking, thank you for your answer. So it does mean that I should either duplicate some of the code, forbid one behavior or let the reference function call the move function after having copied its argument? 
Static polymorphism in Rust is generally based on stating your requirements via one or more traits, and then *only* using the operations in those traits. There's kinda two ways of looking at this. On the one hand, the problem with "how do I paper over value/ref/mut ref differences?" is that... there isn't a whole lot they have in common. What they *do* have in common is pretty much just: moving, and immutable borrows only. In other words: the intersection of value/ref/mut ref. But that's pretty much *just* the semantics of an immutable borrow, except without copy. So if you're going to do that, you might as well just use immutable borrow semantics and be done with it. On the other hand, you can consider it from a more granular perspective. Let's say you have two functions that do almost, but not quite, the same thing. You can try to unify them by defining a trait for the type(s) being operated on, with a method for every possible point of difference. Depending on what you're doing, this can be *really* fiddly, but might be closer to what you want. For example, I vaguely remember defining a trait for something where there were two methods for what was almost always a wrapping addition, except for some types, where it was *slightly* different. Explaining the distinction in the documentation basically boiled down to "these are the same, except when they aren't, good luck". Short version: depends on *exactly* what you're doing, why, and what you actually want at the end of the day. It's like so many "what's the Rust equivalent of (thing from C++/C#/Java/Python)" questions: "what do you mean, *'the'*?"
Generally you'd just write the one which requires the least stringent access without losing efficiency. - If you're going to call clone on the reference anyways, then just accept by value and let the caller deal with cloning. - If you wouldn't benefit from ownership, accept by reference. The caller can usually trivially pass in a reference instead of a value. Note however that the later may run into lifetime issues in your "read-one-at-a-time-from-disk" situation. This is because a StreamingIterator trait, where each item has a short lifetime, isn't yet possible (Associated type constructors will solve this).
I specifically mean it for MSVC. MinGW usually links dynamically to mscrt.dll, which in theory should be problematic (at least it was prior W10) but in practice worked very well.
It's supposed to be like any other assembly language.
Ah, okay, gotcha. I guess I'll distribute statically-linked MSVC builds going forward. Thank you for your help!
It's unclear why you would want to cache data in memory, so I suspect you're not giving us enough information about the way the data is accesses/processed. If the data is processed in two linear passes after all a single implementation with a normal buffered file reader probably work great (relying on the OS to do readahead and disk caching, and using a small buffer to reduce system call overhead). Anyway, just to take a stab at interpreting the question as asked, I'd make the reading code own the data in both cases and just pass it to the processing code as an iterator, a slice, or a reference (depending on what kind of processing is being done). 
It's all good; I've been working on the book so std hasn't improved a ton; it'll get filled out more in the future.
I did not, actually :)
So, wasm has *two* text formats, one Forth-y, one Lispy. And yes, it's disassembled bytecode.
That's already true of `rustc` even without wasm :P
Although, I bet your abundant excitement around WASM has definitely been a good push for the community. It would very be interesting (to me) if what makes Rust more "mainstream" is its potentially prominent use in front end web development.
I've used it to tinker around a bit and I've contributed some https://github.com/keeslinp/qml_todo. It's great for small things right now, it integrates super well when there's one component that you need to write it's controller in rust. I've been meaning to try combining it with quick-flux to see if I can replace the main redux store with a rust object. What's nice about this approach is that QML is handling all of the funny business with GUI that isn't easily compatible with safe rust, leaving just the stuff that rust is good at.
If we ever switch over the cretonne, this might be much easier.
I hope so! I also hope it sorta trickles down to embedded, since wasm is in many ways an embedded target.
I don't see how your question is related to your problem. If you can store the data in memory, it doesn't matter if you move or borrow it to your algorithm - your algorithm has access to all of it anyways. If you can't store it all in memory, you can do neither - you can't borrow it because there is no where you can borrow everything from, and you can't move it because then the code that pass it to would still need to have it all. What you are looking for is an [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) - a construct that allows you make a pass on the data. Iterators don't allow random access, so it's easy to create one that doesn't store everything at memory at once. The problem with iterators - unlike collections(list/vec/etc.) you can only make a single pass on the iterator. So - it's not move vs borrow - it's collection vs iterator. Now, you can't make multiple passes on the same iterator - but if you had two iterators you could make one pass on each. So, what I would do is make the algorithm accept a function that generates the iterator. If the data is small, the function can just hold it in it's closure and `iter()` on it. If it's big, it'll just generate an iterator that loads it each time it is called. You can even make something more complex, that decides at runtime. For example, here is an implementation for the simplest algorithm that requires multiple passes - counting the number of elements greater than the average: https://play.rust-lang.org/?gist=1d6069c7e1867c6daa998efc249faf5c&amp;version=stable fn greater_than_avg&lt;F, T&gt;(nums: F) -&gt; usize where F: Fn() -&gt; T, T: Iterator&lt;Item=i32&gt; { let mut sum = 0; let mut count = 0; for num in nums() { sum += num; count += 1; } if count == 0 { 0 // avoid division by zero } else { let avg: f32 = sum as f32 / count as f32; nums().filter(|&amp;num| avg &lt; num as f32).count() } } fn main() { // Small enough to store in memory: let nums = vec![1, 2, 3]; assert!(1 == greater_than_avg(|| nums.iter().map(|n| *n))); // Too big - need to read/generate on each pass: assert!(50 == greater_than_avg(|| 0..100)); // (yea, we can store 100 i32s in memory. That's not the point) }
I totally forgot to press the importance of functional programming. Just mentioning it is probably wrong. It is definitely important to use it when it writes and reads cleaner, which is so often in Rust. Sometimes it isn't so great, but it's good to use it when it is. I wouldn't go as far as to say one should learn Haskell to learn Rust though, but it wouldn't hurt.
I tried compiling the example in "Release" and got: Compiling playground v0.1.0 (file:///playground) /root/entrypoint.sh: line 7: 5 Killed timeout --signal=KILL ${timeout} "$@" Unable to locate file for WebAssembly output
At least I can fry an egg while my program compiles.
There's a lot of unused guff from the rust standard library in there that could get snipped out at link time. Even just the assembly of `add_one` by itself is a bit weird-looking though. At a quick glance it's using `i32.sub` and `i32.gt_s`, which I didn't expect. Overflow checking on the addition maybe.
WASM is actually a stack machine at the binary level to achieve smaller binary size. Perhaps that is why it appears FORTH-like.
Does the FORTH-y one have a name?
At the very bottom, there's some error messages about addition with overflow, so I think you might have a good guess
Yeah, I am glad we got to this point. Hopefully we will start to see amazing things in the web that weren't possible before written in Rust. Maybe we will also see amazing things in the web that shouldn't be there either, like firefox being ran inside of firefox.
What happens? Do you get any error messages? I'll try installing on another computer later today and see if I can figure out if there is anything else I've done.
I'm not sure.
Those are just from the standard library guff I think. It looks like the actual computation step is the `(set_local $l3 (i32.add (get_local $l10) (get_local $l7)))`, where local `$l7` has just been initialised to `1`. Curiously `$l10` _doesn't_ get loaded from the parameter `$p0` (in fact nothing does), but instead gets populated from linear memory via some weird dance that I didn't trace much. I wildly guess that this last part is caused by Rust doing some trickery with stack management?
You seem to have submitted this message... many times.
There's a lot of other stuff included but `add_one` compiled in release looks about right to me: (func $add_one (export "add_one") (type $t8) (param $p0 i32) (result i32) (i32.add (get_local $p0) (i32.const 1))) 
Thanks for the detailed answer. I was aware of the iterators existence, but my understanding is they come it three flavors in Rust, two of them exposing a reference and the third a value. So they don't solve the question of whether one should use reference or move semantics. I edited my OP to give more details.
Thanks, I edited my post to give more details. 
Yep, I'm totally doing it. Last year, I used the first few to learn Rust a bit better. This year I'm going to try to keep up as well, with a theme of refinement. [Github.](https://github.com/kazagistar/advent2017)
Nope, `iter()` only borrows nums.
Yes but dereferencing is a moving operation isn't it? I always get a 'cannot move out of borrowed content' when I try that
There's a wrapper in failure to work around the incompatibility: https://docs.rs/failure/0.1.1/failure/struct.SyncFailure.html Still, it's rather ugly and requires a mutex lock when you do pretty much anything with the underlying error. I'm not sure if that PR will actually go through. error-chain errors *were* `Sync` for a brief time before the constraint was reverted due to some complaints. But I guess it's possible that there were some further discussions in IRC that I wasn't around for, and the error-chain guys are on board with bringing Sync back. 
In the integer example dereferencing them is fine because they are Copy and therefore copy on move, just like C++.
Not sure if this is exactly what you're after, but all the wasm design docs are here: https://github.com/WebAssembly/design
Think of the possibilities!
Can I propose 40 if there is none yet? Like wat, I prefer my terms to be completely ungoogleable
Since you can mix both styles in a single wasm text file, I don't know if it would make sense for them to have different names. For example, this is what a disassembled recursive power function looks like in Firefox: (func $func1 (param $var0 i32) (param $var1 i32) (result i32) get_local $var1 i32.eqz if i32 get_local $var0 else get_local $var0 get_local $var0 get_local $var1 i32.const 1 i32.sub call $func1 i32.mul end )
[Here's](https://github.com/WebAssembly/spec/tree/master/interpreter) the reference interpreter. I'm sure it's much simpler than what's in Firefox though
Yes, this is what I meant. I probably should've clarified
To answer my own question This example worked https://github.com/schodet/1bitsy-rust-bsp
/r/playrust
So, uh https://twitter.com/nybblr/status/923569208935493632
Awesome!
I don't think this is possible, you'll need to create your own cargo feature.
what library did you use for OpenCL?
I haven't personally had a problem with this.
Switch to release mode and it will get rid of all of that. Rust does overflow checking in debug mode, but no in release.
This looks like some pretty fantastic work! Nice job! :) I'm pretty new to Rust and have only written a few smaller projects but even still error handling has manifested itself as the most difficult part of converting from a C++/Java/PHP background. Failure looks like it could make my life a lot easier with some other projects I have planned but I'm not quite sure where to start as my familiarity with even standard Rust error handling practices is pretty low. Does anyone have any recommendations on examples or tutorials to help me get started with Failure?
Ocl core https://github.com/cogciprocate/ocl/tree/master/ocl-core I preferred to use close to C API methods because they felt more natural than the higher level api in ocl. 
It's [already being run](https://github.com/integer32llc/rust-playground/blob/3801a2092456d88cb18c4ab3f69b808361db8b16/compiler/base/cargo-wasm#L40-L51)!
Wikipedia calls it linear assembly bytecode. AFAIK it only supports function bodies though and the rest still has to be defined in S-Expressions
&gt; Eventually the playground will run in your browser with all tools bundled. Doubtful. This was one of my first questions to Alex when I learned about WebAssembly. It was pointed out that you'd have to download hundreds of megabytes of wasm. No one is going to put up with that.
There's a 10-second timeout to reduce the impact of misbehaving code. WASM has an... *intensive* linking step which can sometimes take a while. LLD is a hope for a better future!
&gt; what disassembler they're using [wasm2wat](https://github.com/integer32llc/rust-playground/blob/3801a2092456d88cb18c4ab3f69b808361db8b16/compiler/base/cargo-wasm#L40-L51)
For reference, you will almost always get better / cleaner output if you [compile as a library and choose release mode](https://play.rust-lang.org/?gist=9e09f9ebd855169ae8416fe6e7f091b0&amp;version=nightly&amp;mode=release): #![crate_type = "cdylib"] #[no_mangle] pub fn add_one(x: i32) -&gt; i32 { x + 1 } 
I have to agree with you here. I'm personally getting some Rust code into production right now for the very same reasons, easy to compile the project on any machine, well supported and wide spread tolls for statically linking with 3rd part dependencies, easy to integrate with python and support for "performance first" coding whilst being decently safe. It's a shame that language like C++ or even C11 don't have similar tolling, because I genuinely dislike Rust as a language when it comes to other things, especially when compared to C++, but I'd rather focus on writing code than focusing on fighting with build systems and dependencies... and in the end syntax is personal preference and a small cut in performance here and there is not relevant even for 99.99% of the projects that need performance past what a runtime-bound, gc language and provide.
and the 3 line example translates to only 59_233 lines...
I *think* (not sure) that while the lispy things are often called `.wat` files, the FORTH-y are called `.wast` files. But really not sure.
As long as you only care about Linux.
It's early days yet, Rust is barely optimizing the output for size at all (see the other posts in this thread about wasm-gc).
Another big thread is here: https://www.reddit.com/r/linux/comments/7gpcu5/system76_will_disable_intel_management_engine_on/
Honest question: Is there a reason you wouldn't move your other .Net Core work to Rust?
What makes it ugly? I have used Rust for production and fun and have yet run into anything terribly ugly. 
*Disclaimer: I'm a dilettante when it comes to security...* It seems to me that the publishing server is a Single Point of Failure. An unauthorized party gaining access to the publishing server can easily publish a new build artifact with all the associated manifests and the correct signatures. Since you have managed to get reproducible builds, it would be interesting to build in *auditing* on top. For example, I could imagine an independent 3rd party being able to build new images and then check that the image they obtained matches the published image for a given build number. Then, even if some rogue actor manages to publish a "legitimate" looking image, then said 3rd party could warn about the mismatch, and humans could investigate.
Ugly is subjective. I consider a language ugly if API's that should be uniform aren't, standard library naming is bad and achieving "basic" things require hacks. In the case of rust the obvious examples are the containers, where you have things like Vec::new(); vec!(1,2,3); map!(1 =&gt; 2, 2 =&gt; 3, 3=&gt;5);... etc As opposed to C++ where all containers are initialized in a standard way: vector{}, vector{1,2,3}, map{{1,2}, {2,3}, {3,5}} ... etc Anything to do with low level memory management (read: The things that usually end up causing weird error to do with resource allocation), don't benefit from any of rusts "safety features" and often end up being less safe to do than writing said stuff in C++. The obvious examples here are the poor design one must adopt when writing multithreaded code (See the Mutex from the standard library), which basically revolves around "Wrap your class in 3 different classes to make the compiler think all your mutable methods are immutable", thus throwing even the small amount of thread safety a compiler can provide via const/non-const methods out of the window and adding layers of hard to understand abstraction to already difficult concepts. The other obvious example here is the infamous "unsafe" block and the associated tooling (e.g. UnsafeCell), which, again, will result in code going from "Safer than any other language" to "about as safe as writing ANSI C", and since unsafe functions and classes can leak out of these unsafe structures (again, see the example above with how a mutex is implemented) that basically means as soon as you have a library which has a single unsafe block (read: most projects will have them), the whole idea of being able to "prove" your program is memory safe is thrown out of the window. Naming is another obvious one, shit like Arc and Vec seem like the result of a 10 year old designing a library, whilst other standard library features have useless verbosity (e.g. HashMap, which should either be called Dictionary or UnorderedMap or LookupTable, since the Hash tells nothing to someone who doesn't already know what Hash Map is and the implementation may well not be a Hash Map but any O(1) lookup strucutre... e.g. it could be an associative array that relies on un-hashed keys). To add to that there are features in the standard library which can't be implemented using the language (which begs the question of why they aren't in the core language), there are unwieldy implementations for very basic concepts (e.g. String and File System usage) and there are plain bad features in the language which are both less powerful and harder to understand than those of other language (e.g. Macro system). Those are, at least, some of the things that make Rust an "ugly" language compared to C++, adding to that the fact that Rust shouldn't be compared to C++ but rather with more modern system languages that could be used instead (e.g. D or Scala-Native), since C++ and C11 are compeating with the advantage of not requiring software and libraries to be re-written in order for them to be used in production, and I think it's a rather poorly designed language. But, again, those things are subjective and the great tooling and community, I think, are more important.
I'm quite confused by the second part of your comment. What exactly do you prefer about C++ compared to Rust?
Eh ... I doubt it would make for good egg frying, because of how the hardware works. The compiler (especially with wasm) would needs lots of memory accesses and would thrash the cache insanely. Your cpu will spend most of its time idling and waiting for memory. It would really not make good use of the cpu core's hardware resources, and the CPU wouldn't be releasing much heat, even though the OS will show 100% CPU usage. If you want good egg frying on a CPU, run something like prime95 or another stress test that is designed to fully fit in the cache and is written in super-optimised assembly to make best use of the cpu core and fry your cpu as much as possible. Also, make sure to disable thermal throttling from your BIOS and replace your cpu heatsink with some kind of heat spreader that gives you a nicer surface to fry eggs on.
Nice to know my Game Boy software will outlive anything else I write. :)
Depends on how tightly it needs stuff to be timed ;)
&gt; "Wrap your class in 3 different classes to make the compiler think all your mutable methods are immutable", thus throwing even the small amount of thread safety a compiler can provide via const/non-const methods out of the window and adding layers of hard to understand abstraction to already difficult concepts. **Strong** disagreement here. In case you haven't read it, [this blog post](https://manishearth.github.io/blog/2015/05/27/wrapper-types-in-rust-choosing-your-guarantees/) is a pretty good overview of how this works. The `Cell`/`RefCell`/`Atomic`/`RwLock`/`Mutex` wrapper types do not "throw out" any thread safety whatsoever- they *preserve* it far better than C++ can. If you want to bake their functionality into the language instead, that's fine, but it's hardly accidental complexity you can just throw out. &gt; as soon as you have a library which has a single unsafe block (read: most projects will have them), the whole idea of being able to "prove" your program is memory safe is thrown out of the window. This is just nonsense. Yes, `unsafe` blocks cannot be proven by the compiler. *That's the point.* But once they're contained via visibility, trait bounds, etc. the compiler can guarantee that any memory/thread unsafety that does occur is due to the code in and surrounding the `unsafe` blocks. This doesn't make proving your program impossible at all- it makes it far more feasible to prove since most of the proof is now done by the compiler. &gt; useless verbosity (e.g. HashMap, which should either be called Dictionary or UnorderedMap or LookupTable, since the Hash tells nothing to someone who doesn't already know what Hash Map is and the implementation may well not be a Hash Map but any O(1) lookup strucutre Before 1.0, the standard library collections did use names like that. They were all intentionally changed to be named after their implementation, to leave room for traits using the interface names. This is the more uniform approach IMO, and it means that `HashMap` will in fact always be implemented as a hash map. &gt; Rust shouldn't be compared to C++ but rather with more modern system languages that could be used instead (e.g. D or Scala-Native) Why on earth not? Just because C++ has the advantage of a large existing ecosystem doesn't mean Rust doesn't have the advantage of memory and thread safety. (Which D and Scala don't!) Rust has its downsides to be sure, but these aren't they.
&gt; Its so easy to work with rust and integrating it in to other runtimes thanks to it's C ABI compatibility. Choosing rust over C/C++ was a nobrainer thanks to that. (Assuming C++ rather than C) I'd rather write a first-class wrapper for my high-level logic in a high-level language (C++/CLI) and use that directly than write a C wrapper that you then have to P/Invoke with (probably warranting a second "-sys" wrapper). Choosing Rust here might be a no-brainer, but I don't think _better_ interop is a given.
Upvoted for clearly explaining your opinions, even though I disagree with them.
[removed]
Wow, this is great documentation! This makes it a lot easier to wrap my head around the magic of Diesel. There's some really nice details in there, too, that I feel like should have a big highlighted box around them. I'm pretty sure at some point I've spent some time pulling my hair out because of issues related to this: &gt; The **dsl** module should only ever be imported for single functions. You should never have use **schema::users::dsl::*;** at the top of a module. Code like **#[derive(Insertable)]** will assume that **users** points to the module, not the table struct.
Rust memory management allows for safety and the performance of C but the trade of is readability^1 if you compare with languages that have automatic memory management. I think it's a perfect match to write highlevel logic in C# or F# and then the low-level performance stuff in Rust. I will however write more stuff in Rust and it could well be that i will write whole systems in Rust in the future. ^1 A lot of extra characters for pointers, borrowing and lifecycle management 
Interesting. I have found Rust to be much more expressive than our C# code. Additionally, the verbosity of C# (public and statics everywhere just to name a few examples) add up compared to Rust's lifetimes and other syntax. C# is more productive. I am hoping over the next couple of years Rust will continue to approach the level of prudcitivy of C#, But pure character count is not a problem I see between C# and Rust.
I believe `.wast` files are for testing and include the ability to do assertions
Could be something that i will learn to handle better but the more non alpha-numerical characters i see in code the harder it is to read. Ex python is super easy to read.
Yay! Is it feasible that Gimli might be able to replace our usage of libbacktrace in the compiler someday?
Better yet name it after something common do it's Googleable but not the results you want. rust, cargo, etc
Silly question: is `failure::Causes` designed to be used as an applicative error type?
Thanks for elaborating and outlining your perspective. &gt; As opposed to C++ where all containers are initialized in a standard way I'm a big fan of uniform initialization, but I think this is a relatively moot point considering that there are still myriads of ways to do this and code is inconsistent. Moreover, iterators are cumbersome and difficult to support, and many custom collections omit STL support and cannot be used with standard algorithms. Rust's iterators are a big improvement IMO. I find `vec!` and `map!` consistent, but the fact that a macro is preferred for literals is perhaps a wart. &gt; the infamous "unsafe" block It's absolutely true that `unsafe` code may "leak" and affect safe code. I don't think the idea is so much that `unsafe` blocks should be entirely self-contained in terms of safety, but rather that it dramatically reduces the surface area where code must be very carefully audited and certain classes of bugs can occur. &gt; shit like Arc and Vec seem like the result of a 10 year old designing a library Names are of course highly subjective. :-) I'm sure we can find names in any standard library that we dislike. I generally prefer clear names even if it means that they're a bit verbose, but I think `Arc` and `Vec` are named that way because they are used so often that brevity becomes a reasonable thing to optimize for. They seem okay to me. &gt; other standard library features have useless verbosity (e.g. HashMap ...) I think "Hash" is not needless verbosity in this case. It does tell you something: this is a hash map (as opposed to a generalization of a lookup table). The fact that this is hashing is an obvious and important part of the type. For example, it exposes a state type parameter that is nonsense in the general case and has `Hash` and `Eq` constraints on it's key type. It does not attempt to generalize lookup tables. Names like `UnorderedMap` etc. would be too generic, I think. &gt; there are features in the standard library which can't be implemented using the language In `std` or `core`?
There is no such a thing C/C++. 
I wrote such a custom derive for [`relm`](https://github.com/antoyo/relm). [Here's the code.](https://github.com/antoyo/relm/blob/master/relm-derive-common/src/lib.rs#L94-L128) You will need to create a proc-macro only using that, but [here's how it's used in `relm`](https://github.com/antoyo/relm/blob/efafa7767fab36719106cda6fcc34bef2de7ffd8/relm-derive-common/src/lib.rs#L18) and this function is used for the [`proc_macro_derive` here](https://github.com/antoyo/relm/blob/67a28bcf57c98d03439a302abd13194ad54c37ca/relm-derive-state/src/lib.rs#L24).
Thanks for pointing this out to me! There still seems to be a problem with being able to fill out the Error::cause() method. How would you ever be able to fill that out if it requires a reference to something inside self, but the error you're trying to reference requires a lock? I hope the PR goes through. Although it's a breaking change, I think it's correct and necessary. 1. They're fighting against the standard library because io::Error can only wrap Sync errors. 2. They're recursively making everyone else's errors !Sync. 3. Unless I'm mistaken, anyone that wants their errors Sync can't fill out the cause method using an error-chain error. 4. If they refuse to fix this, I think any library that uses error-chain should rightfully get an issue reported that their error isn't Sync when it should be. I would think it would hurt adoption of error-chain in the long run. 5. Anyone that breaks with this PR, I think, chould just add a mutex for the parts of their errors that require synchronization and it shouldn't really affect anything else.
You are not understanding my point. I'm not talking about the USAGE of the Mutex or any other such access wrapper, I'm talking about the IMPLEMENTATION. Find the code here: https://github.com/rust-lang/rust/blob/master/src/libstd/sync/mutex.rs Also, it's implemented using UnsafeCell, which quite frankly I didn't get into the implementation of, but I assume it's even more of an ugly hack than the mutex implementation.
`UnsafeCell` is required to inform the compiler that it can be aliased. It's the key to the entire thing, the most important primitive.
`libstd` uses some nightly-only features, but you can use it from stable Rust. This is not true of other libraries.
Two crates that do this are [`enum_derive`](https://crates.io/crates/enum_derive) and [`strum`](https://crates.io/crates/strum).
Speak for yourself! I already download it with `rustup update`, what difference is it if it's through the browser? ;) A heck of an important 304 status code though...
compiled with release and using wasm-gc, an add_one function comes out to about a hundred bytes.
You can't move from a borrow. The iter method borrow by self, so the inner values cannot be moved. You can only move if using the into_iter or drain methods.
I think this is mostly a matter of experience. I'm pretty sure experienced Lisp coders are fine with Lisp code, while personally all I see is a soup of parentheses. On the other hand, after 10 years of C++ code, those angled brackets/semi-colons are bread and butter for my brain to pattern-match on, and it seems my subconscious directly interprets them so that I "see" the semantics, not the syntax. Still, with all that said, I would not necessarily recommend Rust for everything as the very strict lifetimes can indeed cause "design challenges". It's possible it's for the better in the long term (clear data-flows), though unproven, and in the short-term it can be really annoying.
Note for future readers: if like me you ponder for a while what "tolls" Rust imposes that other languages don't... read it as "tools" and it'll all become much clearer!
This is awesome! I had been wanting to write my own Oauth2 back-end as well. Maybe I'll take my side project off the backburner and start toying around with this. 
Thanks so much! We're very happy users :)
Totally; a pure-Rust unwinder is being worked on here: https://github.com/gimli-rs/unwind-rs I haven't had time to contribute directly to that repo yet, but I believe it is semi-functional already.
Ah awesome!
And here is the repository: https://github.com/aochagavia/rocket_wasm
As ever, feel free to [fill out the form here](https://github.com/rust-lang/rust-www/issues/new?title=New+Website+Logo%3A+[insert+name]%0A&amp;body=To+list+your+organization%27s+logo+on+the+Rust+website%2C+fill+out+the+following+information+and+click+%22submit+new+issue%22.+Alternately%2C+you+may+edit+_data%2Fusers.yml+as+described+therein+and+submit+a+pull+request.%0D%0A%0D%0A-+Organization+name%3A+%28as+you+want+it+displayed%29%0D%0A-+Homepage+url%3A+%28homepage%2Fprimary+entry+point+for+users%29%0D%0A-+Logo+url%3A+%28svg+if+possible%2C+pngs+over+400x200px+with+transparent+backgrounds+are+also+acceptable%29%0D%0A-+How+you+are+using+Rust%3A+%28one+sentence+describing+your+use+of+Rust%29%0D%0A-+Url+describing+Rust+usage%3A+%28optional+link+to+e.g.+blog+post+explaining+how+you+use+Rust%29%0D%0A-+Organization+contact%3A+%28name+and+email.+we+may+contact+you+when+updating+this+page.+alternately+you+may+email+this+information+to+user-logos%40rust-lang.org+and+it+will+be+kept+secret%29.%0D%0A) if you'd like to get your company on the [Friends of Rust](https://github.com/rust-lang/rust-www/issues/new?title=New+Website+Logo%3A+[insert+name]%0A&amp;body=To+list+your+organization%27s+logo+on+the+Rust+website%2C+fill+out+the+following+information+and+click+%22submit+new+issue%22.+Alternately%2C+you+may+edit+_data%2Fusers.yml+as+described+therein+and+submit+a+pull+request.%0D%0A%0D%0A-+Organization+name%3A+%28as+you+want+it+displayed%29%0D%0A-+Homepage+url%3A+%28homepage%2Fprimary+entry+point+for+users%29%0D%0A-+Logo+url%3A+%28svg+if+possible%2C+pngs+over+400x200px+with+transparent+backgrounds+are+also+acceptable%29%0D%0A-+How+you+are+using+Rust%3A+%28one+sentence+describing+your+use+of+Rust%29%0D%0A-+Url+describing+Rust+usage%3A+%28optional+link+to+e.g.+blog+post+explaining+how+you+use+Rust%29%0D%0A-+Organization+contact%3A+%28name+and+email.+we+may+contact+you+when+updating+this+page.+alternately+you+may+email+this+information+to+user-logos%40rust-lang.org+and+it+will+be+kept+secret%29.%0D%0A) page. :)
https://imgur.com/vcAW51S -- Proceeding with the installation was successful. What happens for you?
Thanks :-)
I did address that. `unsafe` and `UnsafeCell` are the building blocks by which libraries can extend the analyses done by the compiler. There are three options here: 1) Do some incredible new research and figure out a way for the compiler to verify the implementation of `Mutex` via some new lower-level concept, similar to the borrow checker. 2) Bake the implementation of `Mutex` into the compiler. 3) Make the compiler extensible via `unsafe` and `UnsafeCell`. All three options require you to trust *something*, whether that's the underlying rules for #1, the implementation of `Mutex` in the compiler for #2, or the implementation of `Mutex` in the stdlib for #3. Since nobody's figured out how to do #1 yet, #3 is the most pragmatic option. It's easier to audit and maintain Rust code than it is to audit compiler-code-that-generates-machine-code, and it's easier to add new abstractions in libraries than in the compiler.
I hope you are using Rocket to serve the demo page.
&gt; I'm personally getting some Rust code into production soon […] I genuinely dislike Rust as a language Isn't that the definition of success for a programming language : when people who don't like it still decide to use it because it's the best tool for the job.
When I tried [earlier](https://www.reddit.com/r/rust/comments/7gsq89/the_playground_now_has_a_wasm_button_for/dqlw5mw/), I couldn't make it compile at all in release mode. It's working now, but we still have lots and lots of standard library code that isn't actually used. The overflow checks are optimised away at least.
If you don't already know C, start there. It's ubiquitous, and something any system programmer should know, no matter how great Rust may be. It's also a much smaller language that will take much less time to grasp. Knowing C will also help you to understand more clearly the many benefits of Rust, something that may not be so apparent if you're learning it first. And don't worry about wasting your time: C will still be around in 20 years, don't doubt that, so it's a skill that will remain useful.
Hey! That definitely worked. Maybe I missed a step in my last trial? Not sure. I was messing up somewhere, but not sure how...
&gt; C will still be around in 20 years, don't doubt that, so it's a skill that will remain useful. That is exactly what I needed to read. Thanks! 
awesome, thank you!
It sounds like your distaste for Mutex's implementation is predicated on UnsafeCell being hacky, but then you say you don't actually know if it's hacky or not. So if UnsafeCell is not hacky (and I would argue that it's not) does that then clear up your concerns about Mutex, or are their others?
Holy crap! Of all of Rust's C dependencies that can be realistically replaced (so, all of them but LLVM), libbacktrace is the only one that I thought nobody would tackle. Huge kudos! Is there a tracking issue in the Rust repo yet for using this?
Are there any crates that can deserialize an unknown structure? I'm working on a tool that will reformat a project layout to some other layout. I have these structs: #[derive(Debug)] struct Layout { dirs: Vec&lt;Directory&gt;, } #[derive(Debug)] struct Directory { name: String, subdirs: Option&lt;Vec&lt;Directory&gt;&gt;, } And I want to take in a yaml file of the desired file layout and read it into the Layout struct, for example a file like: src: main test utils: scripts
I'm not sure what you mean by not being able to fill out the Error::cause() method. This turns the old `Error + Send + !Sync + 'static` type into a `Fail` type, leaving behind the `Error` trait impl altogether. Is that what you mean? I'm not disagreeing with you on any of those points, it's just that they've all been made before and were apparently deemed less important than "hey, that broke my error type!" But maybe incompatibility with failure can provide enough motivation to re-add the `Sync` bound?
To be concrete, let's say you depend on a crate called foo with a function bar(T). If you use bar(i64) and bar(u8), then when you compile your project the compiler will generate functions bar(i64) and bar(u8) and then compile both of them to machine code. Incidentally there are a handful of intermediate forms the code passes through, but none of them should last longer than from when you execute rustc to when it terminates. Does that help?
I just want to say - thanks a lot! I've been using `gimli` for some of our internal tooling at work (an multi-architecture `perf`-like CPU profiler with online stack unwinding), and it has been a really great experience. So, thanks again!
Absolutely love this idea. Also grateful we didn’t go the route of defining eprintln! ad print_err! in hindsight.
Ah, I saw [your comment](https://github.com/withoutboats/failure/issues/65#issuecomment-347407922) on GitHub. Thanks anyways, boats—it's a wonderful great crate.
Thanks. However, if I understand you correctly, you seem to describe how monomorphization works in general. My question was more what `Compiling nom` actually does, and how the *intermediate forms* look like. 
&gt; You get used to it, though. Your brain does the translating. I don't even see the code. All I see is blonde, brunette, redhead.
Just don't call it OperatingSystem 2, might get confusing
 To be more specific: In C# any library is compiled into a .dll. In my project I can then reference this DLL, the compiler will read it again, it will check how I use referenced types and eventually produce my application. Unless I'm totally wrong, these DLLs will even contain "compiled generic generics", which I can monomorphize(?) in my own code. In that case saying `compiling [X]` makes sense, as X is transformed from multiple source code files into IL bytecode. Rust, however, ultimately compiles to machine code. I am struggeling to see how generic code would look on machine level, so I am wondering what it is that Rust actually produces when it says "compiling [X]". 
To be more specific: In C# any library is compiled into a .dll. In my project I can then reference this DLL, the compiler will read it again, it will check how I use referenced types and eventually produce my application. Unless I'm totally wrong, these DLLs will even contain "compiled generic functions", which I can monomorphize(?) in my own code. In that case saying `compiling [X]` makes sense, as X is transformed from multiple source code files into IL bytecode in form of a DLL. Rust, however, ultimately compiles to machine code. I am struggeling to see how generic code would look on machine level, so I am wondering what it is that Rust actually produces when it says "compiling [X]".
Well, C++ approach is to force programmer to check everything to match the function's contract. And you rarely can actually figure this contract by function signature. That's why rust is so damn good: it actually let's you design APIs which enforce it's contract at compile time, making those "silly" mistakes almost impossible to occur.
Yes, crates that expose generics have them compiled to an intermediate form that dependencies can use to monomorphize them. I believe the end goal here is for all rlibs to contain *only* MIR, both for generic and non-generic functions, which is the form used right before LLVM IR. Before getting to MIR, the "Compiling nom" step also parses all the generic code, type checks it, borrow checks it, and potentially runs some pre-monomorphization optimization on it.
This is really cool! I am confused, I thought wasm32-unknown-unknown could only compile non libstd stuff but in Cargo.toml and the code in general I do not see where that would happen. I thought for instance you could not have Vec because there is no dynamic allocation of memory but I see some, etc.
Wrong Sub. You want /r/playrust 
I think the thing here is that there's really no such thing as a compiled generic function. In a language that does compile-time monomorphization like c++ or rust (or I'm assuming c#, though I've never used it), you need something pretty close to the original source to do monomorphization on. I'm willing to speculate that a c# dll has the compiled non-generic functions and then some sort of compressed version of the source of the generic functions. Rust has an internal representation of the ast that is what it uses for monomorphization, but I'm pretty sure it doesn't currently ever write that to disc in the normal course of events. At compile time it parses your source and dependencies, monomorphizes, and then compiles all that down to the mir, and then from there to llvm and eventually machine code. You can have a dynamically dispatched function, which is a way to do genericism at runtime, but because you don't know anything about the memory layout of the argument the only thing it can really do is call functions attached to it. I should say I'm not an expert, so if I've said something wrong I hope someone corrects me. And I'm still not totally sure I've understood your question, but I hope I helped.
Great, thanks! Is there a path on my hard drive (e.g., under `.cargo` or in the project folder), where I can see the output?
"Hundreds of megabytes" does seem fairly consistent for a native compiler (GCC, Clang, Rust, etc.) but I wonder if that could be made smaller for a wasm-only toolchain. A build of LLVM with *just* wasm codegen, or maybe just the Cretonne backend, might shave off a large chunk of that. It would certainly be a nice way to sandbox things like procedural macros!
MIR isn't currently written to disk (except maybe with incremental compilation?). You can get the compiler to print it out in various ways- at least one of `-Z dump-mir`, `--emit=mir`, or `--unpretty=mir` should work.
I hope they're using Rocket (the game) to serve the demo page.
Hm, but then I'm back to square one ... `Compiling rand` seems to happen only once when I add the crate / first build. So something seems to compile that is not MIR (since it's not written to the disk as you say), as compilation does not happen again when I regularly build my project.
Er, it *is* written to disk for generics. Sorry to confuse.
`std` supports the wasm target, but it has a lot of stuff stubbed out. A lot of APIs will simply panic when invoked, like trying to spawn a new thread or open a socket. Since there is no multithreading and hence no issue with data races, `Mutex` is simply a wrapper around a `bool` that panics on recursive locks to avoid multiple mutable references (like a simplified `RefCell`; `RwLock` is essentially just that as well). Allocation is actually supported as well, though the implementation is comparatively primitive: * https://github.com/rust-lang/rust/blob/master/src/liballoc_system/lib.rs#L463 * https://github.com/alexcrichton/dlmalloc-rs/blob/d3812c3accaee7ad23068ed4fc089cc05c7a538f/src/wasm.rs
&gt; MIR is a very de-sugared version of Rust. This is true in principle, though I want to make sure people don't take this to too literally. MIR is still its own language, and isn't just a source-compatible subset of Rust; it has its own constructs and syntax.
Great, thanks! I assume the `.rlib` files is where this is happening? I also found a [Stackoverflow comment](https://stackoverflow.com/questions/30725907/how-are-the-generic-functions-and-types-stored-in-an-rlib) which says: &gt; An rlib is a regular static library (built in the ar format) that contains additional metadata. That metadata contains, among other things, the complete, serialised abstract syntax tree (AST) for all generics and functions marked with #[inline].
Let me explain what I mean. Maybe you know a good solution for this. Forget about the failure crate for a moment and let's just talk about `std::error::Error`. struct NonSyncError; enum MyError { nse(NonSyncError) } impl ::std::error::Error for MyError { fn description(&amp;self) -&gt; &amp;str { fn cause(&amp;self) -&gt; Option&lt;&amp;Error&gt; { ... } } 
&gt; Allocations can be freed and reused, but what isn't implemented is freeing memory to the runtime, so the resident set will never shrink. This is indeed correct! Unfortunately although wasm has a "grow memory" instruction I don't think it has a "shrink memory" instruction to release the memory we got :( 
Wrong subreddit mate you are probably looking for playrust
Wrong subreddit, you want /r/playrust 
The HotSpot JVM has been around for over a decade and they still don't bother freeing memory to the OS, so I guess I wouldn't really worry about it.
The docs of `grow_memory` vaguely imply that the operand could be negative, maybe something to try? https://github.com/sunfishcode/wasm-reference-manual/blob/master/WebAssembly.md#grow-linear-memory-size
What's this a reference to? I have heard it before I believe
It's a quote from the the film The Matrix. Decent film, shame they didn't make any sequels.
There are 3 films afaik ;-)
Yep! The reason I hedged earlier about MIR being the long-term plan is that it's changed over time and I'm not totally sure what state it's in right now.
It's from the Matrix movies. It's in regards to those outside the simulation looking in on it via the famous green code rain on a monitor.
The "didn't make any sequels" is a knock on the actual sequels being terrible to the point of pretending they don't exist.
It does not and I don’t expect it to, given conversations I’ve had, but I’m not sure why...
It doesn’t even really have a syntax, only a decent text-based debug output.
Heck I’d go farther than that, even within function bodies I tend to make a scope for importing the DSL.
Ah, I see what you mean now. You're right, you can't do it directly there. At best, you can mimic what we're doing with the `SyncFailure` wrapper like this: https://play.rust-lang.org/?gist=1e8b4880781cf60abe04d807ae9e139e&amp;version=stable. You still can't get the `cause` of the non-sync error, but you can at least return a wrapped version of the non-sync error for description/display purposes, though for errors where it's already cheap to display, it's probably better to just convert it to a pair of strings and call it a day. The other solution is to bug the other crate author to make their error `Sync`, which coincidentally is the other strategy that `failure` is attempting to solve the problem with :D
C and something that can be used for web like Python or PHP should be your priorities, once you're employed you can maybe sneak a rust project here and there, depending on how much freedom your employers give you.
Shouldn't you be using [include_str](https://doc.rust-lang.org/std/macro.include_str.html) rather than [include](https://doc.rust-lang.org/std/macro.include.html)? But, if you look at the GitHub version of your repository, you can easily see exactly what files are being published in your repo.
Why not `dotenv` instead?
Rust is first compiled into two different levels of code before it's compiled into the final machine code, I think. All these languages are machine code-like and may be really awkward to read, even in human readable form. Afaik, for generics rust generates a copy of the function for every version it saw being used and calls the correct one when necessary. I think it may also use vtables or void pointers when it's not so clear what tipes can be used.
Puchline of https://xkcd.com/566/
wat
Sorry, I meant it would strip out the gunk within the function, not all of the other gunk. But yeah, compiling as a library seems to be a good way to do that.
I will do as you guys say. Late I will comeback to Rust! 
Rustafarian mahn!
I generally wouldn't after with starting with C. When I tried to get into programming in my youth, I struggled rather hard to get into programming because of the steep learning curve of C and C++. So many hidden gotchas that the compiler won't point out for you. Rust, on the other hand, finally allowed me to gain entrance into systems programming, where it's compiler quickly points out your flawed line of thought and guides you into the subject, and quickly teaches you a number of best practices that wouldn't be apparent to a beginner trying to figure out why their stuff doesn't work in C.
I'd recommend against using the browser as a display engine. Specially if you're planning on rendering everything yourself, without using html, js and css. You would probably get better results using something like gtk-rs ou the winapi instead.
Once I you can write some stuff in C I highly recommend learning the basics of assembly. You'll gain much better understanding of what the code you write is making the machine do.
Please no PHP. I really want that language to die. Python is a better option because it's useful for web, applications and scripting. It's also cool because it has some pretty interesting programming concepts. Of course, Java is also ubiquitous and is useful if you want to do backend, mobile or even applications, but you'll likely find yourself working at a megacorp, so take that into account if that's not your thing.
[Limn](https://github.com/christolliday/limn) is all about making a GUI toolkit backed by WebRender. It’s a long way off complete, but it’s feasible. But it has nothing to do with JavaScript or WASM.
C was the first language I learned when I was really young (though luckily I had family members that could help me when I got stuck). I'd say that if I had picked a different language to start with (say, Python), I would have gotten started programming useful things much quicker, and starting with C probably caused me to take a year or two longer. That being said, C gave me a much deeper insight into what happens BEHIND languages like python, and what it meant to properly manage memory (or at least, to the extent that my 8-year-old mind could understand :P). So I think learning C works, and learning Python or a higher-level language works, but each come with their trade-offs. I'm curious what it would've been like to learn Rust as a first language, and how my experience would have differed, though.
Rust is basically on the same level as C, so anything that C can teach, Rust can also teach. With the aid of the compiler and all of the advanced features that Rust has, it can do it much better, in addition to teaching a number of techniques that a beginner to programmer would be oblivious to. For example, I wouldn't expect someone approaching C as a beginner to think about trying to replicate iterators and sum types in C, as a Rust programmer might approach C, or have a good understanding of how to manually employ move semantics, threads, mutexes, atomics, etc. -- areas that require significant investments of time to comprehend and master in C without existing prior knowledge on the subject. Rust was basically my first programming language, and after a handful of throwaway project,s I was already writing my first application by the end of the second week, with a good understanding of atomics, mutexes, threads, bitwise operations, and writing allocation-free parser iterators; then by the end of the month my first GTK3 application. Fast forward two years later, and now I've got the Ion shell as my biggest achievement; experience with full stack web development; writing distributed computing client/server architectures; and GTK3 desktop applications. So I do see Rust as the gateway drug into systems programming. It takes an otherwise complex area that most people avoid with their garbage collectors and virtual machine runtimes, provides top-tier tools for writing and managing projects, top-tier documentation written for an audience that has no prior experience in systems software development, and a very helpful compiler to point out all your mistakes. It's effectively a surefire fast lane to reaching mastery of systems software development.
A "shrink memory" intrinsic doesn't seem like enough anyway. Maybe some of the time you get lucky and the stuff you want to release is in (more precisely: the entire contents of) the highest pages, but one little allocation is enough to prevent you from releasing any lower pages. Much more useful to be able to return arbitrary pages via an equivalent of `madvise(..., MADV_DONTNEED)`. Then that one little allocation only stops you from releasing the page it's actually in.
My cpu gets hotter when compiling poky world than when running p95. Poky builds lots of Linux packages in parallel. 
So, as someone who's woefully unfamiliar with C++, I'm curious to know if I understand this from some google fu * In C++, the "empty string" is actually a pointer to a specific value in memory, whose only contents is `\0`. * C++ `strings` are strings which have a certain length, and start at a specific point in memory. To a `string`, `\0` is just a single character that isn't printed. A `string` knows if its size is 0, and makes it an empty string. * A `c_string`, instead, is a series of bytes which start at a certain point in memory, and continue until they find `\0` which acts as an endpoint marker * `Censored` is a struct that contains an IP as a string. * When `get` is called, `Censored` is *supposed* to return the IP as a string. * Due to poor implementation, `get` creates an empty string, which points to the "universal empty string", the `\0` character that all empty strings access * `get` then takes the ip address and copies it into `result`'s point in memory, overwriting the original empty string, and leaving a `\0` at the end by pure luck * This does not affect a regular `string`, because a `string` knows it has 0 characters to read. Printing an empty `string` is unchanged. * This affects a `c_string` because a `c_string` only knows to stop when it hits a `\0` which, due to `get`, is now at the end of an IP address; the "empty" `c_string` is starting at the beginning of the address and only finishing when it reads the `\0` at the end * And the IP address was outputting the IP address where there should've been nothing, due to `get` replacing "nothing" with the IP address Is this more or less the easy version?
You know, I'm genuinely curious what you mean by this. C++ is among the most well known programming languages. I'm assuming you're not just trolling outright, and that maybe there's some miscommunication here. What do you mean, "There is no such thing as C/C++"?
You can use `serde_yaml` for this, you just deserialize into a `Value` rather than a struct. (haven't tested this code) extern crate serde_yaml; use serde_yaml::{self, Value}; let mut file = std::fs::File::open("stuff.yaml").unwrap(); let value: Value = serde_yaml::from_reader(file).unwrap(); let sequence = value.get("src").unwrap()
I don't think this is possible with only changes to your own crate. I don't know about this case in particular, but in general you could break the build in your dependencies, if you reached in and tried to turn off features in their dependencies. I think to make this work, each of those crates would need to expose a feature for it, all the way down.
I think the monomorphization has to be static. It would either have to invoke the compiler to monomorphize at runtime, which seems very unlike rust.
I think you can do this with a [\[patch\] ](http://doc.crates.io/manifest.html#the-patch-section) Something like this: [patch.crates-io] aho-corasick = { version = "2.0", default-features=false, features = ["use_std"] }
I recommend using PureScript, it's higher level than elm, it's like haskell with eager evaluation that compiles to js, specifically for writing web apps / frontends. And then you can use Rust for the server backend. 
If WASM was a meta-evaluator it could coalesce the underlying memory pages. This is why userland needs access to the MMU! If your turtle doesn't have a saddle for a turtle, you are turtling wrong.
&gt; So, you know what? I'll be Rusting this week-end. Erryday I'm Rusting... ♬
You ended up posting this message about 10 times by the way.
&gt; This rust code will most likely go in to production Doing god's work there, son.
[removed]
[removed]
This [has been attempted before](https://github.com/msiglreith/inspirv-rust).
They mean that there's no such language as "C/C++". Languages are often compared to "C/C++", for example when discussing safety features in Rust. A common objection from C++ programmers is that C++ and C are very different languages, and conflating the two is an indication that the person referring to "C/C++" doesn't know enough about modern C++. This objection typically comes up when the objector believes that C++ is in fact far safer (or better in some other way) than it is being portrayed as in the comparison, and believes that the person making the comparison is wrongly imagining that C++ still looks like "C with classes".
Hmm, I actually liked all three. Why people hate the other two?
there's been talk of post-mvp wasm supporting multiple ByteArrays at some point in time - would probably behave a bit like an MMU. so rather than elaborating the "grow" intrinsic, there could be a "give me another ByteArray of size X" intrinsic that would reside somewhere "far off" from the main allocation. like with other operating systems, the allocator would then need to decide whether it can serve a small allocation from an already allocated (or maybe growable) block, or whether it's a large allocation that's better handled by the OS.
Ah, sorry I didn't get that joke ;-) And I like all three ...
What is MimbleWindle and what is Monero?
`'_` is going to be syntax for an inferred lifetime. You have to explicitly name it as of now like this `fn foo&lt;'a&gt;(arg: Arg&lt;'a&gt;)`. In this case the proper way would be to be generic over some iterator fn foo&lt;T&gt;(iter: T) where T: Iterator&lt;Item=char&gt;, { // code } and if it needs a lifetime I think it would be `foo&lt;'a, T&gt;` and `T: Iterator&lt;Item=char&gt; + 'a` instead in that snippet. That said, I'm wondering how you came to interpret code that doesn't compile in the first place to be some sort of anti-pattern.
The first one has more philosophical depth and nuance than the sequels. That said, I liked the first and third. (The second was too much of an extended action sequence for me.)
Again, I'm not arguing here that Mutex alone is an ugly implementation, is just the example I happened to look at a while ago, the whole way unsafe and UnsafeCell are being used seems hackish to me. And they are used in a lot of places, basically anywhere where you'd need highly efficient concurrent data structures and most places where you'd need efficient data structures and algorithm (I haven't checked this tbh, but I'd be willing to bet 90% of data structures and algorithms in the rust std contain unsafe blovks). And the places where they happen to be used are usually highly complex and difficult to write code. So suddenly whenever I want to write anything that's difficult all the language safety features are gone and on top of that I have to keep in mind A) The abstractions that I'm using to fight the borrow checker and the thread-safety checks B) My actual work, whereas with a language like C++, even when writing the most difficult of code, you only have to take care of B), the compiler will allow you to compile it. So a core "selling point" of the language is only a selling point when writing really basic code, but, again, my point here is not to prove/disprove this opinion, I shall stop the rant. My point was that even if I dislike the language I think the tooling, community and ease of compatibility when it comes to writing libraries for other languages are more than enough to make it superior to a language like C++, even if the language itself may be worst (again, in my subjective view).
You're looking for /r/playrust :)
&gt; struct Censored { &gt; std::array&lt;char, 15&gt; ip; &gt; &gt; std::string get() const { &gt; std::string result; &gt; std::copy(ip.begin(), ip.end(), result.begin()); &gt; return result; &gt; } &gt; }; Any half sane C++ programmer, not an expert, not a guru, but like... me when I was programming for 6 months and had touched C++ for 1 week, has heard of the idea of constructors and how they should always be used when initializing an object. The compiler doesn't enforce this, yes, I'd be too hard to enforce considering the fact that there are cases where it doesn't hold true, but companies and teams can enforce this by making sure everyone in the team has a basic understanding of the language (mandatory reading of a C++ beginners book) and the basic logic of a mildly mentally challenged 12 year old (e.g. being able to score over 50 in an IQ test, ability to walk, talk, recognize faces, fit shapes in matching holes... etc). If the team you were working in had those basic requirements that code would have looked like this: &gt; struct Censored { &gt; std::array&lt;char, 15&gt; ip; &gt; &gt; std::string get() const { &gt; return std::string {ip.begin(), ip.end()}; &gt; } &gt; }; Ideally your team is formed not only of less than smart kids with some fundamental knowledge of C++, but of actual C++ developers, adult human being with a good understanding of the language, of the machine architecture they are working with, of the libraries they are using and of the codebase they are adding to. This way bugs like these can be spotted via the process of refactoring. You are blaming on C++ a far deeper seated problem with your team/organization, which will manifest itself in due time in any codebase, including one written in Rust, if none in the team care about the team itself or if the team is part of a large organization run by morons (aka corporation). Your your complaints about C++ in this case are analogous to: * Your car if unsafe, my baby boy drove it for no longer than 2 minutes before crashing * * This typewriter has a weak keyboard, my orangutan broke it * * You're creative writing courses are horrible, my chihuahua is still unable to write his novel * * You CAD software is bad, my 105 years old demented uncle designed the support system for my house using it and it all came crumbling down * * Well of course my kid took out a knife and started murdering people in the hallway, the teacher never warned him against it ! *
I did not meant it really seriously. I do know that actually shipping a full-blown compiler as an embedded wasm module might not be ideal (even though feasible).
Use the trait `IntoIterator` for iterable arguments whenever you can.
That's a well known fact that only retarded children with no knowledge about C++ working in stupid organization can write C++ with memory bugs. Another well known fact is that Google and Mozilla only hire this kind of people to work on their browsers …
That's a well known fact that only retarded children with no knowledge about C++ working in stupid organization can write C++ with memory bugs. Another well known fact is that Google and Mozilla only hire this kind of people to work on their browsers …
C and modern C++ are indeed very different languages, but they are sharing a common sin : undefined behaviors ! (Espacially those linked to null pointers)
That's not a memory bug, read the fucking code please. That's someone that instead of initializing a string with some content. initializes and empty string and then does a memcopy at the pointer pointing to the start of the empty string. The "bug" is much harder to write than the fix, so yes, the person that wrote that code either did not read a single book on the language in his life or was mentally ill or had malicious intent.
This sub is dedicated to the programming language Rust.
As much as I like rust, unless you're doing something with sufficient complexity, at least for now, using rust is impractical. 
Isn't webrender too big of a dependency for the functionality it provides, if you're not doing web stuff?
[Monero is a cryptocurrency](https://monero.stackexchange.com/questions/2254/what-advantages-does-monero-offer-that-are-not-provided-by-other-cryptocurrencie/2255#2255) where transaction privacy is achieved (sender, receiver and amount hidden) by clever use of well-known cryptographic primitives such as ECDH, ring signatures, and commitment schemes. MimbleWimble is another scheme for a cryptocurrency, also using well-know cryptographic primitives in a clever way to maintain transaction privacy but at the same time enable extreme compression of the blockchain. It's not yet implemented in any cryptocurrency. First cryptocurrency using it will be [Grin](http://grin-tech.org/), which is being developed entirely in Rust!
Since he's asking specifically for a job, I felt it would be bad for me to leave PHP out.
I just looked at the safari page for it. Apparently one of the topics is "text editors". :-) 
/r/woooosh
&gt; We have a project in .NET Core that needed to do some physics calculations with a huge amount of data. We wanted to utilize the graphics card to do the calculations (OpenCL). Can you not do that from .NET? Excluding GPU, can you quantify any performance advantages you saw with Rust? 
Isn't this possible in the rust size now? Instead of doing nothing on freeing, the "free" data is added to a list of possibly usable buffers. When the next allocation comes, it can either use some of those buffer or grow further.
&gt; Rust memory management allows for safety and the performance of C but the trade of is readability1 if you compare with languages that have automatic memory management. I think it's a perfect match to write highlevel logic in C# or F# and then the low-level performance stuff in Rust. FWIW, I looked into doing this but couldn't find cases where the performance difference was worthwhile. Even if the performance difference was worthwhile I'd probably just use LLVM directly from .NET rather than go via Rust. 
Can someone formulate what the benefit of Failure over error-chain is in one sentence?
Rustling, you mean
Yes
&gt; And the places where they happen to be used are usually highly complex and difficult to write code. So suddenly whenever I want to write anything that's difficult all the language safety features are gone and on top of that I have to keep in mind A) The abstractions that I'm using to fight the borrow checker and the thread-safety checks B) My actual work, whereas with a language like C++, even when writing the most difficult of code, you only have to take care of B), the compiler will allow you to compile it. But C++ does not provide the "language safety features" in the first place, so you "only have to take care of B" in the sense that the language always expects you to take care of the rest anyway and has never tried helping with any of it. The idea of Rust is that it lets you opt into a less hand-holdy mode (`unsafe`) when you need to under the assumption that it's easier to check the hell out of a few unsafe block than the entirety of the codebase.
If you're using `cmd`, it's: `set RUST_BACKTRACE=1` If you're using powershell, it's `$Env:RUST_BACKTRACE=1`
&gt; The fact that this is hashing is an obvious and important part of the type. For example, it exposes a state type parameter that is nonsense in the general case and has Hash and Eq constraints on it's key type. It does not attempt to generalize lookup tables. Names like UnorderedMap etc. would be too generic, I think. It also gives hints (though not necessarily guarantees) as to its performance profile, and of course nothing prevents HashMap from eventually become ordered (see: OrderMap, a naturally ordered hash-based map competitive with HashMap) at which point `UnorderedMap` is not just too generic but a lie (and would thus really need to be `MapWithOrderingNotGuaranteed`, which doesn't help you if what you're looking for is a hashmap and O(1) indexing)
I have the same experience. I'm using some Rust code through FFI, and it was so easy to make it work. Like, we used to have some C++ code through FFI once. I couldn't for the life of me to get it to compile: vague and unhelpful linker errors. And it didn't even use dependencies! The code was a complete unreadable mess because C++ apparently doesn't even standardize exporting a function, or platform consistent APIs. Rust? Works perfectly, readable, compiles everywhere with dependencies, etc... 
&gt; on top of that I have to keep in mind A) The abstractions that I'm using to fight the borrow checker and the thread-safety checks B) My actual work, whereas with a language like C++, even when writing the most difficult of code, you only have to take care of B), the compiler will allow you to compile it. The problem with this logic is that in C++ you still have to keep in mind A), it's just that when you don't you get UB, memory corruption, and crashes instead of compiler errors. There are certainly ways the borrow checker could be less in the way ([non-lexical lifetimes](https://github.com/rust-lang/rfcs/pull/2094), [in-band lifetimes](https://github.com/rust-lang/rfcs/pull/2115), etc.) but the core rules are just as relevant to C++ as they are to Rust.
&gt; It's also a much smaller language that will take much less time to grasp. I disagree. It's easy to get started and create a buggy program in C, it's much harder to create a *correct* program in C. Sure, you can argue than most of the time the buggy program will work as expected... but what's "most of the time" for you? 99%? 99.9%? For me that's low. Especially for a beginner, I'd advise to learn from the strictest tutors. Let Rust whip you into shape, it'll be hard(-ish) maybe, but you'll be better off in the future. And once you grok Rust, go along and learn some C, and shiver in the face of all that Rust was shielding you from.
Did you enable the [static flag](https://docs.rs/gcc/0.3.54/gcc/struct.Build.html#method.static_flag) in your build.rs file? By default the GCC crate links dynamically IRCC, so it builds a .so file. See [here](https://github.com/fschutt/lua-jit-sys/blob/master/build.rs#L49-L51) for an example usage. 
WebRender itself isn't really that heavyweight. It doesn't deal with HTML or CSS directly, it takes a display list that's already been through styling and layout and thus mostly consists of rectangles and pre-positioned text.
You can start with Rust if you don't know C yet and I would even suggest you do. C has ruled by accident and unfavorable market forces, while harming quality of software and causing stagnation of the field. The only redeeming quality of the C hegemony is the FFI supported by everyone, but other than that it's been a major reason why there has been a distinction between "productive/scripting" languages and "systems" languages. To give a trivial example: int* rust, cpp; What type do `rust` and `cpp` have?
Couple of remarks: * You are quite overestimating human ability to write errorfree code. * The code mentioned might be simplification of larger piece of code (imagine creating empty string and filling it based on some conditions, or whatever). * As for car metaphor, why are we investing so much in car safety, when we can just tell people to be better drivers?
Hi! With a decade of C-experience, I'd learn Rust first. It is easy to get grasp of C later. And you'll write much better C after learning Rust well...
Why so angry?
I would start at C. C is a very small language, and you will lern how a computer works. A good resource for learning C is the K&amp;R "The C Programming Language" book. Moreover, C will be around for a long time. For example I write Firmware for 8 Bit Microcontrollers at School. Since they use a custom Compiler you can only write C Code there. And they probably will never get rust support since writing a new rust compiler is a hell of a project.
Thanks a lot, I ended using cap'n proto, very happy with it!
K900_ showed that somebody tried it. It should also be possible have automatic GPU offloading like in CUDA, C++AMP, etc. with rustc compiler plugins. Personally I would really love to have something like this in Rust but I know that developing such a system is a huge undertaking. 
The car metaphor was to demonstrate how absurd the code sample was. The case where you append to the string, again, shouldn't be done using memcopy (which is all that std::copy) really is, but rather += or .append or some other method of choice that doesn't involve memcopying. I understand that many people here (including, I assume based on the code example above, the poster I replied to), are C programmer which came to rust without contact with C++ or without contact with any good material on writing C++, so they may assume what the poster above wrote is reasonable code, but it's not, Let me write you the "equivalent" of that code in Rust: unsafe { let ip = vec!['1','2','3','4']; let mut result = String::new(); copy_nonoverlapping(ip.as_ptr(), result.as_ptr() as *mut char, 4); } This code will compile and run, resulting in either corrupted memory or a segfault or some other ub. Would you blame Rust for this ? Would you call it an unsafe language because you can write this ? Or would you blame this on the user that went out of his way to write this instead of just just using a single call like String::from_utf8 ? 
Basically what you need here is some websocket library, e.g: https://github.com/cyderize/rust-websocket And possibly a library to handle async/io which as better than the standard library way of doing it via futures, e.g [tokyo](https://github.com/tokio-rs/tokio), in which case you will probably want a different web socket library [which is designed to work will with you async io library](https://github.com/snapview/tokio-tungstenite) Look at the examples in some of the above repositories for various coding patterns in order to write safe asynchronous code. The specific coding patterns you need to learn would depend very much on the libraries you end up using and whether you want to use any libraries or not. Since if you use something like mio or tokyo a lot of the event scheduling heavy-lifting is abstracted away for you, if you use an actor framework a lot of the concurrency itself will be abstracted away, if you use no library be prepared to understand how poll and epoll work. Other than that, use the correct data structures for your needs and the rest will fall in place.
From looking at the docs, playing with it a bit, and looking a bit through the code, I _think_ Cargo's build script functionality is effectively per crate, not per thing build in the crate (it is really per target, as in OS/architecture, but probably you're only building for one of those). I would try making your library project a [workspace](https://doc.rust-lang.org/book/second-edition/ch14-03-cargo-workspaces.html), with the binary as a separate crate inside it. (By the way, iooks like the `gcc` crate has been renamed to [`cc`](https://crates.io/crates/cc) and has reached 1.0 - probably use that instead to make sure you have the latest features / bug fixes / whatever.)
Wrong. Signatures are done by the build server, so a compromised publishing server will have invalid signatures. All build servers and the publishing server need to be compromised to generate bad artifacts. They are located in different physical locations and are locked away so this is highly unlikely.
I don't know how much you know about text editing, but it can get really complex. By fancy text editor, it sounds more like you want a code editor, which has even more complexities. I recommend you take a look at https://github.com/google/xi-editor and its docs, especially https://github.com/google/xi-editor/blob/master/doc/rope_science/intro.md. There are a lot of crappy text/code editors out there, e.g. Atom that naively implement a text editor and thus ends up extremely inefficient. I have no idea if xi can be compiled to wasm, but I'd really look at using xi as your text editing backend. The project has been designed from the start to be completely modular to support arbritary number of frontends, ie. every new "text editor" just has to implement a frontend and not the whole complicated backend engine. If you're playing around with wasm it would be interesting to see if you can compile the xi core to wasm
Not exactly what you asked for, but you might be interested to explore Erlang or Elixir for this type of problem, the ecosystem has very powerful paradigms and heaps of prior work in this space 
Ah! I had missed that. So there are multiple signatures (1 per build server) being published alongside each artifact?
why no mention of Go? If you want to learn a language for web applications (the backend part) or any networking applications, Go is an awesome program to pick up. Go is one of the fastest growing languages in popularity. It's probably also the easiest language to learn out of everything, mostly because the spec is so small. You can get through the entire tutorial within a day and start writing useful code by the second day. Also please no PHP
Yes
I finally tried to replace my dirty manual command-line parsing by structopt: https://github.com/Genymobile/gnirehtet/commit/structopt It works well and the source code is far better. However, it makes my resulting binary 6× bigger. For instance the release+stripped version grows from 600K to 4M, so at least 85% of the binary is related to command-line parsing… So for now, I don't merge it :(
Rust type system also understands fat raw pointers (`*mut [u8]`) and smart pointers (`Arc&lt;str&gt;`) but the standard library functions to manipulate them are often missing.
Oh, firmware drivers are said to be as cool as system programming. I will keep an eye on it too! I 've been learning from King's C book...(pointers so far) thanks!
I will learn both at the same time, but 60% C and 40% Rust. I know it can be confusing but I 've time and patience! Thanks!
Sorry, I was on mobile and it said repeatedly that there was an error when trying to submit... (I just noticed and deleted the other messages.)
C is a PL and C++ is yet another. There is a lot of difference between them. 
I wonder how much of ASM I will need to know. I've read some pages of an ASM book(Jeff) and it is totally different from C... Kinda scary PL! 
Actually me and my team is trying to decide between Go or Rust for the web-socket server. I will take a look on those two, but they will probably want to stick with one of those two.
It would definitely have to be a restricted subset, you can't do recursion in GPU-SpirV.
Honest question: Why Go or Rust? I love Rust but this kind of thing is exactly what Erlang was designed to do and has been doing very successfully for literally decades. 
Is there any good book to avoid making buggy programs in C?
Erlang is built for things just like what you are attempting to do. Using cowboy (an Erlang http/websocket server) you can literally get going in minutes. Of course you don't know the tech so it would be a couple of days to get going. 
Think about it this way: in C++, every line of code is essentially an `unsafe` block and every variable is essentially an `UnsafeCell` by default. So why is it suddenly so terrible when Rust lets you opt into those same semantics in limited, controlled ways?
Readability? One word: macros.
Doesn't that mean you can't ever have closed source dependencies with generics?
 thousand to millions of connections It sounds like your pitching your startup idea instead of asking for development advice. That you *want* it to be millions is irrelevant until you hit 100.000. https://www.reddit.com/r/rust/comments/2qzyfb/erlang_vs_rust_for_high_concurrency_servers/ I was looking for a similar thread we had before. instead i found this one and there is still some very good advice in there even thought its a little old. Since it sounds like your building a new program, you should especially read [this comment](https://www.reddit.com/r/rust/comments/2qzyfb/erlang_vs_rust_for_high_concurrency_servers/cnc61fs/) 
I have the following problem: I operate on a generic piece of data. I then have a struct that takes several other structs with bounds which need to work on the same type of data. So what I tried to do is similar to the following: trait I&lt;T&gt; trait J&lt;T&gt; struct S&lt;T, A: I&lt;T&gt;, B: J&lt;T&gt;&gt; {i: A, b: B} This doesn't work, since T is not actually used in S. Is there any good way to do this? I could use Box for my fields but that brings other problems. I could probably also create a dummy field of type Option&lt;T&gt;, but that doesn't seem right.
There might totally be reasons to use these languages, e.g. if there is a lot of CPU-bound work to be done while processing the information that you need to push out. However the Erlang VM (both Elixir and Erlang use the same VM) has extremely nice isolation and fault tolerance features (e.g., one connection causes an exception, the other connections will still work and not get dropped), which can be a game-changer in this problem space IMO
Every few years, everyone working in the tech field should probably spend a bit of time surveying everything that has happened since they learned whatever skills they're currently using, pick five to ten new technologies in related fields, and learn them. In 2010, the skills I was currently using had started to seem long in the tooth and out of demand. I picked ten new things to learn, and among them were node.js, bitcoin/blockchain tech, and golang (besides just... more modern web development best practices). I got lucky and 30% of the things I decided to learn became relevant. The rest never went anywhere or stayed very niche. My New Year's resolution for 2018 is going to be picking ten new languages/technologies to become more familiar with (Rust is top of the list).
I've never learned C itself (I learned Pascal and C++), and I generally do not learn by reading books, I much prefer experimenting and poking around. So, in this case, I will point you to StackOverflow, and specifically the [C tag description](https://stackoverflow.com/tags/c/info) which includes prominent questions as well as, toward the bottom, a link to a list of books sorted by level.
Perhaps, but IMO it's too easy to develop bar design patterns with PHP compared to other languages because it allows you to do templating directly from the language. It's pretty easy to pick up a language once you know 2-3, so I'd focus on languages and communities that encourage good design patterns. You can write terrible code in any language, but some communities put more emphasis on writing good code than others. So the goal is: * easy to learn * supportive and constructive community * widely used * community has unique , sound approach to solving problems I think Python, Java, and Go fit that bill, though I think everyone should learn C, so I tend to recommend Python, Java, and C. Rust is getting closer to being viable, so perhaps it'll replace Go at some point for me for some recommendations.
Most people don't use assembly in their day-to-day lives because it's 1) Even less abstract and more verbose than C, it's hard to get anything useful done with it; and 2) ASM is totally non-portable between hardware architectures such as x86 and ARM (even x86 and x86-64 have major differences). In the past, some developers were better at hand-optimizing assembly than a compiler was, but compilers have improved and machines have become more complex, so that's rarely true today. But there's no reason to be afraid of assembly, and there is always a time and place. Examples of use: -- creating a function in $your_favorite_language that wraps a useful instruction(s) that your particular language can't invoke natively (such as x86 "popcnt" or SIMD; however these are not great examples since many compilers already have builtin functions for you to do that stuff) -- some kernel, bootloader, or other low-level work, such as cache line invalidation, memory barriers and synchronization (useful for building mutexes and other locking primitives), low-level hardware interrupt handling, etc. -- If you are writing a virtual machine, native compiler, assembler, debugger, or if you want to examine a compiler's output to understand what it is optimizing your code to, it could come in useful :-) -- The last place I "used" assembly was a couple of weeks ago, just to figure out whether an Android crash (that thing that Rust prevents :-) ) was caused by a memory read or memory write. You don't have to be an assembly expert for that; you just have to find the faulting instruction and then google it. No big deal. Hope it helps. 
I do often recommend Go, but I think it makes sense only after learning C. I like to recommend languages that have different ways of solving problems, with one of those languages being C, so I tend to recommend Java, Python, and C because they're similar enough to pick up easily, but different enough to get different approaches to problem solving. I think once those three have been learned, Go and Rust are both great options for a next language. PHP, however, isn't really valuable from a learning perspective, and it's pretty easy to pick up if you're only after jobs.
This subreddit is about the rust programming language. Not about the game Rust.
You're looking for /r/playrust 
Same. The current editors story is pretty sad. I'm waiting for `xi` to became usable.
As soon as I saw this post I came here to say this. Elixir+Erlang are great tools
As the error suggests: trait I&lt;T&gt; {} trait J&lt;T&gt; {} struct S&lt;T, A: I&lt;T&gt;, B: J&lt;T&gt;&gt; { i: A, j: B, _marker: std::marker::PhantomData&lt;T&gt; } 
Oh.. so after compiled, Rust is an instruction translated into Assembly as C? It that it that common a compiler get it wrong and create buggy programs?
Have you seen https://github.com/housleyjk/ws-rs ? Also, let's break this down: * How many connections are you expecting? * What's the source of info upstream (push or pull)? If you're talking about a massive distributed system, I'd encourage you to read the book Designing Data Intensive application. The challenges there well known, and the language of choice wont make much difference (except erlang) 
Oh, thank you!...I am totally unable to learn something with teachers so I don't have a choice...books, books!
There's no such thing, really. Basically, you have to try to write your C programs as you'd write them in Rust. Allow any number of immutable shared values, but only allow a single unique mutable borrow at a time. Don't free more than once, and don't use after free. Watch pointers pointing to memory that gets reallocated, and good luck with handling UTF8 strings properly. Problem is, C compilers will not provide any guarantees about the code you write. It will still compile even if you violate these rules. And it won't give you any visual or compiler aid on whether that data you shared to a function was freed before it returned, and so you shouldn't use it again. The compiler will not tell you that it was freed.
Good learning...
So how experienced C programmers find those bugs? Are those bugs not capable of to be written in any other PL or sorely in C?
Funny. I keep coding Go, .net and rust. Whenever I switch to something other than Rust I miss the certainty that Rust gives that my code was really checked, that wont be concurrency issues, bad pointers, etc. While I still thinking coding in Rust feels less productive than others langs I'm familiar with, it pays off. It's a future contract with the software you're building. 
Lots of time and experience being bitten by these problems. Very careful treading, and thorough code reviews. It's an inherent problem with C and C++. It's why Rust was created. High level languages don't suffer from these problems because they abstract all these details from the programmer through runtime garbage collectors and virtual machine runtimes. Although high level languages often still suffer from difficulties with data races in multithreaded code, which is something that Rust makes easier to manage.
Thanks! Turns out I needed a short break, haha.
&gt; Basically, my server will manage multiple client connections (thousand to millions of connections). These clients can send messages to subscribe to receive some type of information when available. These information are normally available from 5 to 40 times per second, so the server needs to be able to broadcast it to all the subscribed clients at 25 ms maximum time, preferable less. We are missing one very important parameter, and so are you. The number of subscribers to a given topic. For example, Twitter found out the hard way that some accounts have a very large broadcasting ratio. Pop stars can have hundreds of thousands/millions of followers. How do you broadcast a piece of information to millions of subscribers simultaneously? How fairly? Those are questions you need to think about. --- In any case, you need to think about bandwidth too. 40 messages/second to 1,000,000 subscribers mean, in the absence of multi-cast technology like UDP, 40,000,000 messages/second. On a 10 Gb/s line, that's 250 **bits** per message. As in 32 bytes.
This is awesome but I miss Failure impl for Error sooooooooo much
SPIR-V for Vulkan is severally limited but you can do recursion or at least I am pretty sure that it is allowed. I would test it but it seems my `mir -&gt; spirv` compiler doesn't yet handle recursions :(.
Others have mentioned Erlang. If you want to use rust, perhaps look into actix, which should provide a similar model.
&gt; How do you broadcast a piece of information to millions of subscribers simultaneously? How fairly? &gt; &gt; Those are questions you need to think about. Yeah once you reach millions of users and are growing fast. Before that point, you can get up and going extremely easy with Erlang/Elixir and can very likely maintain that tech into tens of millions of users if not hundreds. Way easier than Go, Rust or Java. 
[Second bullet point](https://www.khronos.org/registry/vulkan/specs/1.0/html/vkspec.html#spirvenv-module-validation) :(
Is that wrapper expressive enough to catching buffer management / fencing issues? I've never used OpenCL / OpenGL from Rust yet, but I found this one of the more frustrating things to debug when I was doing some fancy things with them from C. I was kind of hoping a Rust wrapper would be able to help with that.
Yeah you are right :/. I think I just misread that point. I thought you just wouldn't be allowed to call an entry point inside an entry point. (which doesn't even make any sense) Thanks for pointing that out.
I'm not sure if your problem is related, but you really should be returning a `*mut u8` instead of `i8`.
Or better, return `*mut c_char`
Why do you think Rust is a better fit than C?
It is very rare that the compiler gets it wrong. In an unsafe language like C it is very common that the programmer gets it wrong and asks the compiler to generate a buggy program.
So you were just saying that "C/C++", as a single unit, isn't a thing, not that C doesn't exist and that C++ doesn't exist.
Even then, a single memory page will generally contain many allocations. You can only release back a memory page when all of them are freed. This seems unlikely to happen by accident, unless a very large amount of short-lived allocations are done sequentially with no long-lived allocations in between. 
How's Erlang's C FFI? You could plug Rust in for computation-intensive bits.
UnsafeCell exists and *must* be used by Mutex because it has a special meaning to the compiler (in Rust terms, it's a "lang item"). It's how you tell the rust compiler that the thing being wrapped can change, even though the compiler can prove that a non-mutable reference to the containing object exists. This is all explained pretty well in the docs for UnsafeCell tbh. 
Well, there's this: https://github.com/hansihe/rustler, so I would imagine that using rust for the computation backend would be fairly painless!
Not really. Getting the MIR for generic/inline code is nowhere near getting the actual source. It's lowered to the point that it doesn't even contain the original control structures or variables anymore, let alone the names or formatting or comments. C++ doesn't even go that far- closed source dependencies just put their templates and inline functions in header files in source form. Doesn't seem to be a problem there, as far as licensing goes.
I found the error, please check the `Edit` section in the original post
/u/jackpot51 do you plan on porting this to redox?
Instead, using [`CStr::from_ptr()`](https://doc.rust-lang.org/std/ffi/struct.CStr.html#method.from_ptr) is likely a better choice as it more accurately models the ownership.
&gt; Yeah once you reach millions of users and are growing fast (which is as likely as winning the lottery). There's a slight difference between millions of users and millions of subscribers/subscriptions. A single user could subscribe to many topics, for example. Imagine... github. For every pull request I have left a comment on, I get a mail notification when someone else replies, until this pull request is closed. --- In any case, my point is to get the OP to *think*. And get them to re-appreciate the magnitude of what they are talking about. When your usecase would saturate a 10Gb/s line, you may want to re-think it.
&gt;otherwise the Drop from CString will overwrite the first byte of the pointer to 0x0 "eating" the first letter :-) Yay! Glad to see this trick exposing real-life bugs early!
Cool. Any chance of making it work on mobile? Just having a few buttons would be good enough for a demo, though some touch events would be awesome, though I'm not sure how it would work.
I'm not too sure if this makes sense contextually, but is there any way to cache results here? Or will the input be different every time?
Have you considered the tokio variant of tungstenite? 
Not that I could see. I'm starting with a large `Vec&lt;String&gt;` and I call this function on every line. There's often a repeat in the first 8-10 bytes, but not of the full line. And to identify that, I'd have to walk through the full `Vec` and compare the first few bytes of all lines, which is basically what I'm doing here anyways, right?
You mean in `str_len` function?
Hmm, I see what you mean. What about splitting up the work to be done on the array across some number of threads, getting it all done in parallel?
I'm no optimiser, but my first thought is to check the shorter cases (single characters) first in hopes of cutting down a few comparisons? But if they're far less frequent I guess it doesn't matter. Oh well 
I did get some improvement using the following code. Basically it first compares the first byte of `s` and then it does the more expensive `starts_with` check only if necessary. pub fn parse_str&lt;'a&gt;(s: &amp;'a str) -&gt; Option&lt;Card&gt; { use self::Card::*; match s.bytes().next() { Some(b'N') if s.starts_with("NODE") =&gt; Some(Node), Some(b'S') if s.starts_with("SHELL") =&gt; Some(Shell), Some(b'$') | Some(b'#') =&gt; Some(Comment), _ =&gt; None, } } 
I’m still lurking in the Rust world, but generally, it seems like you can cut down on looping (in starts_with) by looking at the individual chars—at some loss of clarity. Looking at the first char alone, you already know if it will be a Comment, None, or might be a Node/Shell. Then you can continue to look at characters based on if it might be a Node or Shell. You’d loop through the list exactly once, but I think your comparisons are the same, so my guess is though that the gains would be trivial.
Maybe do it the Minetest way and use something like Lua as a glue language? You can then write your logic in Lua, and call into Rust/C libraries when needed.
10/10 shitpost
This function doesn't look expensive to me. If it's dominating your profiles, is it possible you're calling it much more often than expected/necessary?
Correct.
Since Grin is written in Rust, &gt; We'll likely do it in Rust, though, so we won't be able to inherit anything from grin except their learnings in building it:) Why is the twitter saying that, because they will do it in Rust, they won't inherit anything from Grin?
Personally I'd hardly call this a "trick" and say it is exposing bugs. It is subtle behavior that tripped-up OP without any indication from the language or compiler. That said I am still thoroughly uninformed regarding advanced 'trickery' in Rust and do not have a better idea on how this could be communicated to the programmer.
[removed]
Things people use can irritate them and anger them but that irritation and anger is taken out on other people, not 'things' (if there are other people around at that particular moment). Trouble is, they don't realize themselves the things they use is what angers them. Instead they believe it is the people around them that are responsible for their displeasure. Not gonna elaborate beyond that...
Without this zeroing, the effect would be as if the code is working, which is worse than a deterministic failure. Of course it would be better to prevent this statically, but such is the nature of FFI that it's difficult to invent ergonomic zero-overhead and safe solution. At least, we haven't fond a pretty solution in https://github.com/rust-lang/rfcs/pull/1642 :) 
Because he didn't know at the time that Grin is written in rust =) &gt;Oh weird - I thought they used Golang, TIL! https://twitter.com/fluffypony/status/936258805775597568
Recall that if you're building in debug mode, which disables most optimizations.
On the other hand, perhaps we **could** fix it? https://internals.rust-lang.org/t/pre-rfc-make-cstr-a-thin-pointer/6258/13?u=matklad
Yeah, using scripts for mods would make sense. In your example, I'm guessing I could use [hlua](https://github.com/tomaka/hlua) to create a Lua environment for each mod. That would be nice.
It is an EFI program, so that is impossible.
I played around with the code a bit more to handle the case of two check strings starting with the same characters, and as an example added `Card::Notice` for `"NOTICE"`. This code benches a little faster still. fn check_rest(mut rest: Bytes, check: &amp;[u8], card: Card) -&gt; Option&lt;Card&gt; { for b in check { if rest.next() != Some(*b) { return None; } } Some(card) } pub fn parse_str(s: &amp;str) -&gt; Option&lt;Card&gt; { use self::Card::*; let mut bytes = s.bytes(); match bytes.next() { Some(b'N') =&gt; match bytes.next() { Some(b'O') =&gt; match bytes.next() { Some(b'D') =&gt; check_rest(bytes, b"E", Node), Some(b'T') =&gt; check_rest(bytes, b"ICE", Notice), _ =&gt; None, }, _ =&gt; None, }, Some(b'S') =&gt; check_rest(bytes, b"HELL", Shell), Some(b'$') | Some(b'#') =&gt; Some(Comment), _ =&gt; None, } } 
I feel that at the moment, it's simplest to use an existing websocket server technology and just use it as a naive proxy. This can still work for distributed websocket servers too which helps you scale up when you grow. For my board gaming service, I have the following configuration: * Rust application servers * Redis servers purely to use PUB/SUB * NodeJS websocket servers The process looks like: * The user connects to a websocket server with some subscription details * The websocket server connects to a Redis read only slave node and uses SUB to make relevant subscriptions * The application sends PUB messages to a Redis master node. This works surprisingly well in my experience. If you need to support clients talking back it can just be simplest to let them just request directly to your app server. In terms of latency, this should be fine unless you're making some twitchy multiplayer game.
Are you sure about that? I see some non-reproducible gains (i.e. different between benchmark runs) in my benchmark. I've made a dedicated one for this function, and I don't see any gains there. My benchmark is this: #[bench] fn bench_parse_str(b: &amp;mut Bencher) { use std::fs::File; use std::io::{self, BufRead}; let file = File::open("files/example.pc").unwrap(); let v: Vec&lt;String&gt; = io::BufReader::new(file) .lines() .map(|l| l.unwrap()) .collect(); b.iter(|| { let r = test::black_box(&amp;v); let parsed: Vec&lt;Option&lt;Card&gt;&gt; = r.iter().map(|s| Card::parse_str(s.as_ref())).collect(); }) } Did I do anything wrong?
Hmm, gluing together the results from the splits will be nontrivial, but I'll think about it!
He thanks, but I'm using `cargo bench`, which compiles in release mode.
I think I'm calling it exactly as often as I need, namely one per line I get passed :) "Real conditions" are kinda hard, it's a benchmark for a part of a larger thing, so it's of course not the full story. Also, my vec is about 1% or 0.5% of the size I'll be using it with eventually, that might screw things (there's a problem with a dependency which is why I can't really work with larger data). Maybe my binary is already sufficiently fast :) I'm not sure, since I do not yet have a good way to test. But as I said, I'll have to scale it up quite a bit eventually, that's why I started thinking about some parts of my app. I did not suspect this function initially, and it might just be the case that it can't be sped up, even though it's dominating the benchmark.
I just benched with a very small set of strings (see below) and saw the gains. About your benchmark, I think you should `black_box(parsed)`. #[bench] fn bench_parse_str(b: &amp;mut Bencher) { const S: &amp;[&amp;str] = &amp;[ "NODE", "SHELL", "Not", "Something", "$comment", "#comment", "None", ]; b.iter(|| { for _ in 1..100 { for e in S { black_box(::parse_str(e)); } } }); } 
Cool. Thanks for the answer. Sometimes the topic of dynamic linking and shared libraries comes up and the opinions vary a lot. I think it's interesting for larger projects.
Putting the `black_box` in did nothing. But your 2nd function does work excellently: &gt;test bench_parse2folddata ... bench: 108,273 ns/iter (+/- 2,079) &gt;test bench_parse2folddata2 ... bench: 107,015 ns/iter (+/- 2,156) &gt;test bench_parse2folddata3 ... bench: 71,834 ns/iter (+/- 1,371) &gt;test bench_parse_str ... bench: 97,468 ns/iter (+/- 2,754) &gt;test bench_parse_str2 ... bench: 91,382 ns/iter (+/- 1,817) &gt;test bench_parse_str3 ... bench: 61,615 ns/iter (+/- 1,360) Here, `parse_str` is my original function, `parse_str2` your first shot and `parse_str3` your second (I deleted the notice variant though). The `parse2folddata` are the corresponding full benchmarks. The improvement 1-&gt;2 is there, but it's small, and not really present in the full benchmark, but 2-&gt;3 is very good and it all translates to the full benchmark, too. Thanks a lot.
Benchmarking is not profiling. If you run an expensive function `expensive` ten times, and a cheap function `cheap` a million times, `cheap` can still dominate profiling, but if you benchmark the two functions, `expensive` will take much longer. So even if the benchmark shows that `parse_str` is the function that takes the longest *for a single call*, it does not mean that it will dominate execution time. In general, first you profile to find the function that is taking the most execution time, and then once you identify that and start optimizing it, you benchmark to see that the optimizations are effective.
Excuse the wasm newbieness, but is there a way to talk to a server with wasm ? Like UDP or websockets ?
Eh yeah, I got confused. I did profile indeed (I used perf), but I used the binaries generated by cargo bench, so that's release mode. After seeing that this function takes roughly 60% of the execution time (if I understood it all correctly...), I decided to benchmark it and see if I can improve it.
You can try [actix-web](https://github.com/actix/actix-web), it is built on top of actix actor library, so you can get actor system. You would need to implement multiple machines communication yourself though. Another option is [SockJS](https://github.com/actix/sockjs), it is high level WebSocket server, it already support complex session management. Also it is possible to use http/2 and event source instead of WebSockets, you can do this with actix-web as well, it supports http/2
Rust actually has at least two wasm targets right now: - `wasm32-unknown-emscripten`: This is the "high-level" target, that attempts to provide a `libc`-like runtime using Emscripten. - `wasm32-unknown-unknown`: This is the "low-level" target which assumes no OS-like functionality. It's basically like a bare-metal embedded system, and depending on how you set it up, you may not even have a memory allocator. In the latter case, one of the goals is to minimize the required toolchain and runtime support as much as possible, in hopes of building modules that fit in a few kilobytes.
It's websockets. I don't think std binds it currently, but [here is an example of it being used in C example](https://stackoverflow.com/a/44637040).
In terms of raw speed, [minihttp](https://github.com/tokio-rs/tokio-minihttp) has proven to be extremely fast on the [techempower benchmark](https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=plaintext) where it hit around 3.6 million responses per second. While they used the http 1.1 protocol, theoretically one could switch out the underlying protocol to use websockets. The source code for the benchmark is [here](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Rust/tokio-minihttp).
yep!...
You're welcome. I got different gains probably because my test data was not really representative of `example.pc`. And about the `black_box`, I guess the compiler is currently not smart enough to figure out that the whole `parsed` line can be optimized out; I got the same results using just b.iter(|| v.iter().map(|s| Card::parse_str(s.as_ref())).collect::&lt;Vec&lt;_&gt;&gt;())
Wow, there is a lot to learn..data race, multithreaded...haha
There isn't anything in the standard library for this. (There used to be a `std::dynamic_lib`, but it was deprecated and removed.) In part that's because there's no stable ABI for Rust _types_; across different versions of the compiler and possibly even different options (optimization level, etc.), even simple things like `String` and `Option` could change their representation, and [do in fact change](https://twitter.com/Gankro/status/932445149422071808). So you have two choices: either you can make sure everything goes through C types and use the `cdylib` crate type, or you can compile your program and all its loadable modules at once in the same way and use the `rdylib` aka `dylib` crate type. Allowing other people to build/distribute modules that take or return Rust types is currently unsound (and unsafe), unless you do something like declare a supported compiler version and options (and even so, it will be complex to upgrade your compiler and sync with everyone else). But as long as the interface is C, it doesn't matter if the other side doesn't use Rust at all, so it also doesn't matter if it's a different version of Rust. There will be one copy of libstd etc. per module and one for the main program, but it's private so they won't communicate with each other. (This also, in theory, lets your users write their plugins in many other languages too.) I would take a look at [libloading](https://docs.rs/libloading/0.4.2/libloading/) for support for opening a library (`.so`) and getting a function pointer (`fn`) from it. See also [this users.rust-lang.org thread from last year](https://users.rust-lang.org/t/how-to-write-plugins-in-rust/6325) and [this current internals.rust-lang.org thread about "Rust on Rust FFI"](https://internals.rust-lang.org/t/rust-on-rust-ffi/6323). (A side note: "C" here really means "the defined platform ABI". It happens that because of C's prevalence, every platform that Rust runs on / is likely to run on any time soon has defined their platform ABI in terms of the C language&amp;mdash;there's a rule for how structs are laid out, there's a rule that assumes functions don't have multiple return values, etc. There usually aren't rules for things like objects or exceptions. So FFI-stable types use `#[repr(C)]`, the crate type is called `cdylib`, etc. There's no actual dependency on the C language or C compiler; it's simply a _lingua franca_.)
Yep, I understand that. I'm talking about a different target supported by LLVM, which has a more standard toolchain. `wasm32-unknown-unknown` still depends on `binaryen`, while `wasm32-unknown-unknown-wasm` is roughly the same, but it can be linked with `lld`. I believe this is LLVM's recommended target, going forward. Emscripten as a whole is kind of a bad model. It's a very magic, hand-wavey toolchain and a `libc` that has a lot of questionable behavior. I don't see any reason for wasm to be fundamentally different than, say, aarch64 at the toolchain level. Clang -&gt; LLVM -&gt; `lld`, plus `musl` and `compiler-rt` really ought to yield a toolchain for just about anything. Throw in `--gc-sections` (which wasm `lld` doesn't have yet, but should have eventually) and you should be able to get pretty small binaries.
It may be overkill but... this seems a job for nom (https://github.com/Geal/nom). 
Your remark about the test data made me run benchmarks on 2 other files. The first one was 1.2MB size, the 2nd is 13MB and the third is 67MB. I've ALSO taken a 4th one, that was 1.5MB in size, because both larger files were very homogenous content wise (almost singularly NODE and comment lines), and the other ones are realistic in content. The files I will use this with will be much larger (I guess 300-500MB), but of mixed content with large intervals of homogeneous lines... man, this benchmarking thing is hard! Ok, here are the numbers, if you're interested, thanks again :) * Size 13MB test bench_parse2folddata ... bench: 1,396,084 ns/iter (+/- 33,971) test bench_parse2folddata2 ... bench: 1,428,183 ns/iter (+/- 32,326) test bench_parse2folddata3 ... bench: 1,414,108 ns/iter (+/- 117,098) test bench_parse_str ... bench: 1,378,794 ns/iter (+/- 72,449) test bench_parse_str2 ... bench: 1,408,226 ns/iter (+/- 45,288) test bench_parse_str3 ... bench: 1,404,563 ns/iter (+/- 27,317) * Size 67MB test bench_parse2folddata ... bench: 7,424,549 ns/iter (+/- 140,441) test bench_parse2folddata2 ... bench: 7,575,688 ns/iter (+/- 376,005) test bench_parse2folddata3 ... bench: 7,577,492 ns/iter (+/- 93,626) test bench_parse_str ... bench: 7,409,543 ns/iter (+/- 97,304) test bench_parse_str2 ... bench: 7,590,281 ns/iter (+/- 103,818) test bench_parse_str3 ... bench: 7,591,661 ns/iter (+/- 122,406) * Size 1.5MB, realistic file test bench_parse2folddata ... bench: 151,047 ns/iter (+/- 5,090) test bench_parse2folddata2 ... bench: 130,429 ns/iter (+/- 3,618) test bench_parse2folddata3 ... bench: 100,260 ns/iter (+/- 3,302) test bench_parse_str ... bench: 131,903 ns/iter (+/- 3,337) test bench_parse_str2 ... bench: 105,357 ns/iter (+/- 1,996) test bench_parse_str3 ... bench: 80,525 ns/iter (+/- 2,189) 
I've asked about this in another thread here on reddit, and I was steered away from using a parser library. But I will very much need to extend the parsing, so I guess I'll have a real look into nom. Thanks!
There's a number of ways that you can go about this. Have you thought about using an IPC model instead? Would allow mods to be written in any language, and merely communicate back and forth through a socket. Allows mods to run in parallel.
I thought I might try to adapt this setup for debian, but I found that (other than the compiler itself) the **mingw-** packages you've listed seem to *only exist* in Arch space. I was unable to find equivalents for debian, or in ppas for ubuntu. There were more matches in Fedora/SUSE space, but not 100% from what I could tell. At any rate, I guess I'm posting to clarify what these dependencies are. My guess is, they are Lib and DLL files built of the libraries *for windows* using mingw which will be linked to during the cross compile. I suppose so long as each has a shallow tree of dependencies of their own that shouldn't be too bad to reproduce from sources.
That C++ code looks innocent though. I could have written that just by thinking that `std::string result;` allocates a fresh new string. Which is *exactly* what it appears to do. And in fact what most predictable C++ objects do. If I wrote your Rust code I'd be thinking "there is nothing I want to do that is `unsafe`. Clearly, this is incorrect code."
I find it's useful to look at data rates for perspective. The benchmark framework will compute this for you if you set `b.bytes` within your `#[bench]` but since you gave the sizes, I'll compute it by hand for this run: * In the `bench_parse_str3` line of those results, the 13 MB file was parsed at 9.3 GB/s. * The 67 MB file was parsed at 8.8 GB/s. * The 1.5 MB file was parsed at 19 GB/s. You should expect a 500 MB file to take roughly 50 milliseconds. I don't know the larger context, but if for example this is a commandline utility you'd run on one file at a time, 50 milliseconds is pretty good. Some keyboards [take longer](https://danluu.com/keyboard-latency/) to register a single keypress.
If you've already checked the first byte, you won't need to check it again. Could improve performance by just checking if they start with ODE or HELL.
If you pursue this idea, I recommend checking out [rayon](https://crates.io/crates/rayon).
Since the UI is done from Javascript, this should be easy to achieve. Do you have any experience with touch events and Javascript? I looked around for some easy solution (e.g. using NibbleJS) but didn't manage to get anything working and this project has already taken more time than I expected. Feel free to open a PR in case you want to get your hands dirty.
Very interesting, thank you! Just to make sure, reading the file from disk was not part of the benchmark.
Note that, in the example, websocket-related functions are passed explicitly from Javascript to C. It would be possible to write the same code in Rust with the current compiler.
The most active project for a scripting language binding in Rust is probably https://github.com/servo/rust-mozjs. I know what you may be thinking; "ew javascript". But if you're looking to make a minecraft-style game, A javascript style event model for mods might not be terrible, you could expose a set of event handlers (e.g. mouse-over, mouse-down, mouse-up, block-remove, block-place, etc. ) that would allow complete gameplay customization.
I considered using communication over sockets/FIFOs for a little while. I originally decided against that because I thought each mod would have to be run in its own process or thread. Now that I'm thinking about the idea more, message passing sounds decent, but I'm probably going to just use Lua or another scripting language like another user mentioned. They're more portable across platforms since they don't have to be compiled, which also makes mod development/maintenance easier.
Also, the smaller file going at a higher rate is probably due to CPU cache effects. If you were to run `perf stats` to compute CPU cache stuff on one benchmark at a time (e.g. via `perf stat -e LLC-loads,LLC-load-misses target/release/mybench... bench_parse_str3`) you should see a worse cache hit rate when you access more data. You may be limited by memory bandwidth, which means on a sufficiently large input the only worthwhile improvement is to reduce extra data being processed. One idea along those lines: a `Vec&lt;String&gt;` on a 64-bit platform has an extra 24 bytes per line of overhead (each string's pointer, size, and capacity). One big `String` with all the lines in it is a more memory-efficient format. If you need the whole file in memory at once, it may be better to get its size, reserve that much space in a `String` or `Vec&lt;u8&gt;`, and read it all into there at once. (Maybe even using unsafe to avoid zeroing the whole thing first.) Or similarly use `mmap` then `madvise` or `mlock` (but note with mmap, your program will crash with `SIGBUS` if the file is truncated while you're reading it...)
You may also want to consider [dyon.](https://github.com/PistonDevelopers/dyon) It's sort of made for that kind of thing and has a few of the same features as rust, including lifetimes.
Rust and C both compile to native instructions. One step of the process involved in generating the native code instructions is turning the Rust or C into assembly. Assembly is the last human readable step before it becomes machine instructions
Running perf with cargo bench can be confusing in a few ways: * running `cargo bench` of course invokes cargo, potentially rustc, and then your program. `cargo bench --no-run` just does the first part, so you can do `cargo bench --no-run &amp;&amp; perf ... target/release/...`. The name of the generated program is kind of confusing; one I just ran was `target/release/deps/moonfire_nvr-c9cd9f0fb80591b8`. The long hex string is...I dunno, a digest of all the package versions or something. * it runs each benchmark as many times as it needs to be satisfied that it's achieved accurate results. That means if you speed it up between runs, it's not even obvious you've done so from looking at the profile output alone. You might even find more total time is spent in a function you just optimized. * likewise, if you have multiple benchmarks in your binary (and I see from another comment that you do), if you run all of them, the one that most of the time is spent in isn't necessarily the slowest one, because it might run the faster ones more times. I think it's more straightforward to make a binary target just for profiling that runs what you want to profile a fixed number of times or in a loop forever. Of course then you need to remember to run it in release mode. If you're like me and tend to forget one little flag like that and have to spend a while figuring out what you did wrong, it might be worthwhile to make your to-be-profiled binary crash if not compiled in release mode.
I'm getting the dreaded "Cannot move out of borrowed content" error while trying to write an iterator adaptor. The code in question can be found [on the playground](https://play.rust-lang.org/?gist=3cdcc1f0ca0857abd244658d35e080cd&amp;version=stable). It's in the state of "trying to make it work somehow"... I don't think the body of the `for` loop starting at line 22 does matter, so you don't need to look any further. Here's what I want to do: I have a `v: Vec&lt;String&gt;` and a `parse_str(&amp;str) -&gt; Option&lt;Card&gt;` function. I'd want to call `v.iter().map(|l| parse_str(l.as_ref())).enumerate()`, which will get me an enumerated iterator over the parsed card types of the strings. Now I need an iterator adaptor that returns the ranges of card types with certain rules (I don't think it matters really). Now, `next` takes a `&amp;mut self`, so `self.orig` is also mutably borrowed. But it's an iterator, shouldn't it return values, not references? Why can't I use them then? As you can see, I've also tried to just take references (both `usize` and `Card` are `Copy`, so it doesn't really matter to me) to no avail. Thanks for any pointers :)
In general, yeah, they would each run in their own process, but you could also write a mod that runs multiple mods in different threads in the same process.
&gt; running cargo bench of course invokes cargo, potentially rustc, and then your program. cargo bench --no-run just does the first part, so you can do cargo bench --no-run &amp;&amp; perf ... target/release/.... The name of the generated program is kind of confusing; one I just ran was target/release/deps/moonfire_nvr-c9cd9f0fb80591b8. The long hex string is...I dunno, a digest of all the package versions or something. Yeah, that's what I did. I needed some time indeed to find the binary :D &gt; it runs each benchmark as many times as it needs to be satisfied that it's achieved accurate results. That means if you speed it up between runs, it's not even obvious you've done so from looking at the profile output alone. You might even find more total time is spent in a function you just optimized. But the percentages should be telling right? &gt; likewise, if you have multiple benchmarks in your binary (and I see from another comment that you do), if you run all of them, the one that most of the time is spent in isn't necessarily the slowest one, because it might run the faster ones more times. better to use th You can just run a single one by using the `--bench name_of_benchmark` switch. That's what I did :)
I'm sure now that support is out, someone is already working on a JS lib that exports a bunch of APIs to WebAssembly, and then Rust bindings can be written for that.
Have a look at [reqwest](https://docs.rs/reqwest/0.8.1/reqwest/).
That looks very promising, thank you.
Perhaps I will. I have some experience with touch events in a JavaScript, so perhaps I'll take a look :)
&gt; But the percentages should be telling right? I don't really understand something here -- if you'd benchmark only your `parse_str` function, then it should in theory take approximately 100% of time? That would surely not help you in finding bottleneck of your program. So I guess you're benchmarking some other function, that is approximately what your `main` will do, and `parse_str` takes 60% of that one. Am I understanding you `perf`ing workflow correctly? Anyway, if your `parse_str` function probably lives in the separate crate, so you can try adding `#[inline]` annotation to it! Functions can only be inlined if they're from the same crate, are generic or have `#[inline]` attribute (or if you have LTO enabled). (I'm assuming here that you're running your benches from `benches/foo.rs` or `main.rs` file, which use your `parse_str` function from `lib.rs` or some other crate via `extern crate`)
Thanks for the suggestion! I'm a bit hesitant to only support Dyon because it is not as widely-known and is still in development. However, I do support the work they are doing, and I'll think about supporting it alongside another more popular language. 
&gt; But the percentages should be telling right? Yes, I think the percentages should be accurate, provided that your benchmark is an accurate reflection of your overall program. In this case, you benchmarked parsing a `Vector&lt;String&gt;`. * If your real program is creating that vector, that part might take longer than the parsing. * If your real program is reading one string then parsing it and proceeding to the next, the parsing portion will probably go faster than in your benchmark because the string will always be hot in L1 cache.
As for compilers. There is any major difference between C compilers any other than performance, maybe some weird behavior occurring only in one? Cause I see that people are using Clang and discarding GCC but clang is not ubiquitous as GCC is...
Well, if you need MAC, you can take [Mac](https://docs.rs/crypto-mac/0.6.0/crypto_mac/trait.Mac.html) trait, which is currently implemented generically for HMAC, CMAC and PMAC. For public-key signatures, unfortunately this field currently is not developed in RustCrypto, so no common traits. But I would be happy to add such crate to [traits](https://github.com/RustCrypto/traits) repo, but I think we should do it with at least one implementation at our hands. So good start can be to contact maintainers of `ed25519-dalek` and ask them if they would like to abstract over traits from other crate. And, well, open an issue in the traits repository. :)
&gt; (both usize and Card are Copy, so it doesn't really matter to me) This makes it easy. Then you can just add clones: https://play.rust-lang.org/?gist=b3d3542437c247ca943b8059e9d0ad70&amp;version=stable
&gt; Am I understanding you perfing workflow correctly? Yes. I profiled the benchmark `parse2folddata` you can see in https://www.reddit.com/r/rust/comments/7h4q0i/can_this_function_be_improved_performancewise/dqo94wy/. &gt; Anyway, if your parse_str function probably lives in the separate crate, It's exactly as you say, I'm using a `benches` directory. I added `#[inline]`, and holy hell did that bring down the numbers for the larger benchmark. As you said, enabling LTO had the same effect. I had no idea! Is there anything that should keep me from adding `#[inline]` everywhere? I mean, my final binary lives in the same crate as the library, so it's not important, but of course I want my benchmarks to reflect the behavior of the final binary...
You are looking for r/playrust
This is not the subreddit that you're looking for.
What about aho-corasick? This would allow searching for all of them at the same time, I believe. The regex crate's implementation should optimize it down to aho-corasick if you just do a bunch of strings or'd together. 
He thanks! I might not be able to keep `Card` as `Copy` (although there might be ways around it), would you know what to do in that case?
My first answer was wrong and I edited the comment. Please look again :)
Well, the benchmark measure a portion of the overall programm. It's not yet done, and won't be for some time, but I got interested in setting up benchmarks early, and then tried and... well, you probably know how it went :) But it's a large portion of what I can influence, I'm sure of that. I'm not creating that vector, it gets handed to me from a msgpack communication over stdin/stdout. Effectively, there's a thread running that does the communication, and it sends the Vec over a channel to the main thread. In the benchmark, I read it from a file before runinng the iteration... would that screw things?
I will look into this, thanks!
Yeah, using a well-known scripting language is probably a better idea for modding. Just wanted to make sure you knew about that option.
Thanks a lot, this looks like what I need! Depleting the iterator should be fine, my definive goal is to run through each iterator only once anyways (since they'll be somewhat large).
I do agree; I was more comparing learning C as a first language versus a higher-level language like Python. Were the option of rust available when I was younger, I definitely would have learned it. 
yes, const generics will be awesome for sure, but generic-array is a good enough stopgap for me for now
You may get better responses on http://internals.rust-lang.org, some of the more knowledgeable rustaceons don't check Reddit that often (AFAICT).
This is awesome! Can't wait to give it a swirl. :-)
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. 
&gt; I got the same results using just &gt; b.iter(|| v.iter().map(|s| Card::parse_str(s.as_ref())).collect::&lt;Vec&lt;_&gt;&gt;()) IIRC, `Bencher::iter` passes the result of the supplied function to `black_box`, so having your closure return non-`()` is idiomatic.
Some new protocols designed these days are committing to specific cryptographic algorithms, see e.g. the Signal protocol . This helps a ton to make all the hidden assumptions clear and ensure all the edge cases are tested, which is vital for code that is both security-critical and complex. And if you need to change it, just use whatever versioning scheme you already have in place for the entire protocol. I'm sorry if this comes off as preachy or if it's not relevant to your usecase.
That sounds a lot like what [Amethyst](https://www.amethyst.rs/) wants to be. You may want to check it out, either to use it or be inspired by it.
Well, I won't be using it. Like I said, I am developing this partly for the experience of developing it. Still, thanks for sharing!
Makes sense. I think that's the best benchmark you can write to focus on just "your" code given this interface. You can influence more than "your" code, though. :-) All the Rust code is young and open source, though, so you might find some glaring performance problem and fix it yourself (or file an issue). Also, if you really wanted to speed things up, it looks like there's a [rmp::decode::read_str_from_slice](https://docs.rs/rmp/0.8.7/rmp/decode/fn.read_str_from_slice.html) and such, so you could do the msgpack stuff in a streaming way without memory allocation. Your program might end up a lot harder to maintain, though, so I'd just start with the simpler high-level thing and only mess with it if I find the performance is unacceptable.
A for loop always consumes the head (i.e. the thing after `in`). You can see this because the [expansion](https://doc.rust-lang.org/beta/std/iter/index.html#for-loops-and-intoiterator) calls `IntoIterator::into_iter` which takes the iterator by value, so you're definitely not getting it back. Same thing with `for v in vec {}` consuming `vec`. However it's easier to get around in common cases because e.g. `for v in &amp;vec {}` consumes a *reference* to `vec` which leaves the vector itself alive.
with Rayon, you might find it actually is trivial
Awesome! Looking forward to switching to this. My commentary below is about the whole workflow and not just criterion.rs 1. So using `#[bench]` requires nightly but its possible to enable `#[test]`s during the `cargo bench` run? Good to know. 2. Odd though, from `cargo bench --help` &gt; `-j N, --jobs N Number of parallel jobs, defaults to # of CPUs` Shouldn't the default be `N=1`? 3. Is there a recommended CI configuration for benchmarking? Use cases that I can think of - Checking PRs against master - Tracking performance over time
GCC has been around for decades, Clang+LLVM is the new kids on the block. Clang is the frontend that takes C and turns it into LLVM bytecode. LLVM is where most of the optimization happens. People like LLVM so much because the clang part is easily replaceable. Rust, Haskell, and many other languages all use LLVM to generate their binaries. You can read about some of the differences here https://clang.llvm.org/comparison.html
Thanks!
Thanks
I love the hatred on reddit because I don’t know how to use it. I would expect a computer dipshit like you to get pissed cuz I don’t know how to use reddit yet
Thank you 
I can't speak to the details of the standard benchmark harness, I'm afraid. I believe that vanilla `cargo bench` does run each job sequentially though. As for CI configurations - I hadn't thought of that, but I can see that would be very useful. Unfortunately, at the moment I know just enough about Travis-CI/Appveyor that I can usually fix it when the Criterion.rs build breaks. I've added [a ticket](https://github.com/japaric/criterion.rs/issues/89) to add some examples and suggestions for using Criterion.rs in a CI pipeline. If there's anyone out there with some ideas on this subject, this is one area where community participation would be especially helpful. I'd imagine that managing the 'current' benchmark result files would be a challenge, since Travis-CI/Appveyor don't give the user many tools for preserving files between builds.
Bench mine, bench mine! :) pub fn parse_str&lt;'a&gt;(s: &amp;'a str) -&gt; Option&lt;Card&gt; { use self::Card::*; use std::ptr; // I only wrote the little endian version assert!(cfg!(target_endian = "little")); const NODE: u32 = 0x45444f4e; const SHELL: u64 = 0x4c4c454853; let b = s.as_bytes(); let mut m: u64 = 0; unsafe { ptr::copy_nonoverlapping( b.as_ptr(), &amp;mut m as *mut u64 as *mut u8, b.len(), ); } let m0 = m as u8; if m0 == b'$' || m0 == b'#' { return Some(Comment) } if m as u32 == NODE { return Some(Node); } if m &amp; 0xffffffffff == SHELL { return Some(Shell); } None }
&gt; I'd imagine that managing the 'current' benchmark result files would be a challenge, since Travis-CI/Appveyor don't give the user many tools for preserving files between builds. Found one post where someone suggested Travis running the bench on the PR and master in the same job. That might be a possibility https://beachape.com/blog/2016/11/02/rust-performance-testing-on-travis-ci/ My hope is there is some awesome service I haven't found yet that is like coveralls for performance.
That wasn't really hate I just figured you were trolling and I thought it was pretty funny. No need to get so defensive
I'm learning Rust, and as a project I'm just going to implement basic data structure. I think I understand why the following code doesn't work. I can't mutably borrow and try to access (read) the value at the same time. However I am stuck on how to implement `add_ege`. The whole idea is to have `Graph` hold a list of `Node` in the heap. The `Node` itself keeps track of adjacent nodes (edges). However, I don't want `Node` to hold a copy of `Node`, instead I want it to have reference to any of the `Node` held in `Graph`. struct Node&lt;'a&gt; { value: String, adj_nodes: Vec&lt;&amp;'a Node&lt;'a&gt;&gt; // refer to Graph.nodes } pub struct Graph&lt;'a&gt; { nodes: Vec&lt;Box&lt;Node&lt;'a&gt;&gt;&gt; } fn mk_node&lt;'a&gt;(value: String) -&gt; Node&lt;'a&gt; { Node{value, adj_nodes: vec!()} } pub fn mk_graph&lt;'a&gt;() -&gt; Graph&lt;'a&gt; { let nodes = vec!(); Graph{nodes} } impl&lt;'a&gt; Graph&lt;'a&gt; { fn add_node(&amp;mut self, val: String) { let node = Box::new(mk_node(val)); self.nodes.push(node); } fn add_edge(&amp;mut self, from_node: &amp;'a mut Node&lt;'a&gt;, to_node: &amp;'a mut Node&lt;'a&gt;) { from_node.adj_nodes.push(to_node); // won't work because I already have from_node as mutable borrow to_node.adj_nodes.push(from_node); } } Is there a way to do this?
The problem is with `flat_map(|l| { l.unwrap().split_whitespace() })`, because the value in the closure doesn't last long enough (it is dropped at the end of the closure). My 'solution' which is a 'functional form' is as followed, which compiles but I didn't know your usage and couldn't test it properly. use std::io::stdin; use std::io::BufRead; fn main() { let sin = stdin(); let v = sin.lock() .lines() .map(|l| { l.unwrap() .split_whitespace() .map(|s| s.to_owned()) .collect::&lt;Vec&lt;_&gt;&gt;() }) .collect::&lt;Vec&lt;Vec&lt;_&gt;&gt;&gt;() .concat(); v.into_iter().for_each(|w| println!("{}", w)); }
@alanhoff could you post your fixed code. I'm confused on how you could forget the string and return .into_raw().
Where does the `String` that the split-apart components are from live? Not in the `FlatMap`: it doesn't hold onto the element that it applies its function object to, and even if it did, it would need to hold (1) the `String` and (2) an iterator that depends on the lifetime of that string, and this is a self-borrow and Rust can't do those. In fact, you can't do the former where an iterator spits out `&amp;str`s at all. The reason is that an iterator spits out elements of a single static type, but your desired iterator needs to spit out elements not of one type, but of many: first `&amp;'a str`s (where `'a` is the lifetime of the `String` for the first line), then `&amp;'b str`s (where `'b` is the lifetime of the `String` for the second line), then `&amp;'c str`s, etc.
/u/redattack34, thank you so much for taking over maintenance &lt;3, and congratulations on the v0.1.0 release :tada:.
Be nice.
First, thanks for contributing to the Rust ecosystem! I quickly looked over your examples and some code and my first piece of feedback would be to use either [error-chain](https://crates.io/crates/error-chain) or [failure](https://crates.io/crates/failure) instead of rolling your own. 
Yeah, no, if you want to respectfully say that folks need to double down on learning the details of C++ safety, you can, but personal attacks like the ones here are uncalled for.
I see no one is talking about architecture, but only about libs. If you want to have this kind of scalability, it's best if you think about horizontal scaling first(architecture) and then vertical(library, hardware, whatnot). I guess from your description there will be very few messages compared to the number of clients. In that case, I would design the architecture by splitting the API into two pieces. First you send a request to a server asking for certain categories of messages, then you get a list of endpoints complete with URLs that will serve those messages. The client then connects to these endpoints and starts receiving the messages. With this aproach you get at the same time load-balancing, an easy way to split your traffic in an equal way, and you don't overload your backends. This API endpoint could also be the starting point for an adaptation engine that starts VMs/containers that will host your backends and configures them to send whatever data your clients require. Of course, all the endpoints need to report a lot of metrics for this process to be possible - number of connected clients, number of messages sent, bandwidth out, etc. At this point it doesn't matter what lib you use in the begining, because you can scale horizontally and optimize your code later when it makes sense.
You can use `.unwrap_or_else` which takes a closure to delay evaluating its argument until it's actually needed: let password = prompt_password() .unwrap_or_else(|| exit_with_message("..."));
thanks. that was one of the first things I tried, but I just realized my mistake was that it needs a placeholder for the closure, I think: let password = prompt_password() .unwrap_or_else(|_| exit_with_message("..."));
If you want to do systems programming, you should start by learning computer architecture. That said, you are a new programmer so you should probably start by learning basics. Python is not a bad place to begin.
Since you're cloning the strings and collecting them into a `Vec` anyway, you can call `flat_map`, which makes it a bit simpler: ``` use std::io::stdin; use std::io::BufRead; fn main() { let sin = stdin(); sin.lock().lines() .flat_map(|l| { l.unwrap() .split_whitespace() .map(|s| s.to_owned()) .collect::&lt;Vec&lt;_&gt;&gt;() }) .for_each(|w| { println!("{}", w) }); } ``` In theory, the cloning and collecting could be avoided using `StreamingIterator`, if we had a way to define a struct containing a `String` and a `SplitWhitespace` that borrows from it. Or maybe generalize `SplitWhitespace` to take any type implementing `Borrow&lt;str&gt;` instead of just `&amp;'a str`, (I'm just bouncing ideas off the wall here).
May I ask, do you have any non system programming knowledge? 
Panicking is only for programmer failure in held assumptions, and should not be used for anything else.
I'm basically going for the equivalent of panicking that isn't for programmer failure but rather early termination in an anticipated manner. And I figured it out.
Rust: The most popular and robust language for writing your Brainfuck interpreters.
For what it's worth, you can call .wait() on a Future to make it block the current thread until it completes. That'll essentially make your calls synchronous.
Reminds me of a [talk from Andrei Alexandrescu](https://www.youtube.com/watch?v=vrfYLlR8X8k&amp;t=15m0s) about optimisation. There he argued that the best performance measurement is *"Only keep the minimum value"*.
This is reading out of bounds if `s` is less than eight bytes wide.
wait... It's that easy? 
Just to amplify this, my experiments show that things work under some important conditions. _Everything_ must be dynamically linked to the Rust stdlib, since you want to share the allocator. _Everything_ must be compiled with the same Rust version. Cargo doesn't fully support this scenario, so I compiled by hand (actually, using **runner**). The idea is that both the host program and the plugin share a trait, and the plugin entry point is a C-style function which returns a _pointer_ to the insides of an allocated `Box&lt;Trait&gt;`, which we then make up into a `Box` again on the host side (This is of course an unsafe operation). You can then call the trait methods on the box. At the end, the box drops, and since this uses the shared allocator, no weirdness happens. I had an entertaining discussion with /r/claire_resurgent, who reckons that this is an inherently dodgy operation, since there is no stable Rust ABI. My position is that C++ people do this all the time, and the C++ ABI is still very much a moving target as well (try running a C++ program compiled on Ubuntu 14.04 on 16.04)
Yep, try it out! It obviously defeats a lot of the purpose of using Futures but if you just want to turn an asynchronous API into a synchronous one, that's one way to do it.
In case you just want to use string interning there is also https://github.com/servo/string-cache
Nothing elegant about panicking (although safe.) As a consumer of a program, I'd far rather see a clear error message and a clean non-zero exit than a stacktrace. (And if it's a serious program, some detailed log output.)
I have a related mini-project: [wsbroad](https://crates.io/crates/wsbroad). It just broadcast every message to other connected clients. But note that by design in wsbroad messages can be lost in the way to avoid accumulating them in memory or slowing down senders.
You need to have been spawned another thread that runs the reactor, though.
What if the cache is moved in memory when it needs more space?
I just want to confirm something, when you run `cargo bench` the code is compiled in `release` mode but I don’t think it will be compiled the same way with `cargo test`, do you confirm that ?
What of it? `String` is heap allocated, so the `'static str` would remain valid. It *would* be problematic if OP would hand out `&amp;'static String` instead.
That‘s not entirely true. For tokio‘s futures to make progress, you need to run Tokio‘s Core somewhere. You can run it in a different thread and then use .wait() in another, but overall, it needs to run, otherwise .wait() is just going to block your thread forever with no one unblocking it. So it‘s probably better to just use core.run(future) if you want to synchronously execute your future.
Also check out `string_cache`, which is super fast and can pre-intern strings during compilation.
You're right.
Ahh I was thinking about one function level higher, where I use these results to classify the lines into certain intervals I don't know beforehand, and _that_ will be more complicated. But I could experiment with first running this function over the whole vector, and then use that result for the classification.
I don't fck know nothing about programming at all! haha
Too late, I got my eyes on C, ASM and Rust cant undo that! haha
Actually, I already did send a request to neovim-lib exactly because of this (the vec was passed by ref before, so I had to copy all the strings, while now it's passed by value), and improvements were made quickly. Great experience :) Thanks for the hint about the stream, when I have things running at some point in the future I'll keep that in mind (actually, I just added it to my TODO for later consideration).
&gt; I'd imagine that managing the 'current' benchmark result files would be a challenge One could go wit approach similar to ghpages update on successful build. Just push the criterion artifacts to some special branch on ci PR/merge success. And then pull these artifacts prior each benchmarking run. I've never used criterion so no idea how hard would that be but it should be relatively similar to the ghpages case.
`error-chain` is the oldest one, reliable but not without some quirks. `failure` is the new kid on the block, "an experimental new error-handling library."
 test bench_parse2folddata ... bench: 142,596 ns/iter (+/- 3,607) test bench_parse2folddata2 ... bench: 112,754 ns/iter (+/- 5,285) test bench_parse2folddata3 ... bench: 84,150 ns/iter (+/- 2,498) test bench_parse2folddata4 ... bench: 118,382 ns/iter (+/- 3,076) test bench_parse_str ... bench: 116,772 ns/iter (+/- 2,977) test bench_parse_str2 ... bench: 88,432 ns/iter (+/- 1,919) test bench_parse_str3 ... bench: 73,109 ns/iter (+/- 1,128) test bench_parse_str4 ... bench: 91,220 ns/iter (+/- 1,657) Yours is number 4. I tried with the different files, the result was somewhat the same. I'll need to get really realistic files though :) 
The `failure` crate was designed to replace the `error-chain` crate and was "heavily influenced by learnings we gained from previous iterations in our error management story, especially the Error trait and the `error-chain` crate."[1] `failure` was designed to be backwards compatible with external crates still using `error-chain`, however the other was designed to replace the other, so they weren't intended to be used together in the same crate. I'd say you should use `failure` for any new projects and even the announcement post[1] encourages to migrate any applications (as opposed to libraries) to using the new crate as soon as possible. I find the design of `failure` to be more elegant and flexible than that of `error-chain`'s and the `failure::Error` type into which you can cast *any* error type using `try!` or `?` is amazing while prototyping. [1]: https://boats.gitlab.io/blog/post/2017-11-16-announcing-failure/
I wouldn't necessarily thing of the other as "reliable" and the other as "experimental". Both of these crates only provide rather basic types pretty much without any application logic in them and so I would argue that using either one is just as "safe" as the other. Any problems are likely to occur at compile-time and neither of these crates have reached the magical "1.0" so API breaking changes can still happen in both. 
I'd advice against system programming ten. Start with python. You can do easy and powerful apps. In fact you can do almost everything with python. You can find jobs with Python. And Python is way more fun to learn. With it in your grasp you may see if you need more performance and control over apps. Just know that 99% of devs don't (and that 99% of stats are made in the spot). Once you have learned python, the basics of a high level language and algorithmic you can dive and learn rust more easily, while being super productive in an other language. Starting with rust is going a rough path that probably has no reward in the end, or not enough.
It really looks like that's not possible. Thank you for the suggestion! I will try it out.
Seems only reasonable if sorting is faster then parsing to begin with, right? I'll think about it, thanks :)
Based on your example use case, you could take a look to Mles websocket proxy how to implement such service: https://github.com/jq-rs/mles-rs. It is part of a client there, though.
I'm interested in all these questions, too, but I approach it from a slightly different angle: I'd really love to hear from anyone involved in `rustc` or WASM-related development **what they imagine WASM+web support in Rust looking like in the future**. I'm specifically interested in what people think is the most promising/exciting/realistic approach to allowing existing crates to work on the web (ideally with minimal modification) if they currently assume, for example, that they can access a filesystem, threads, graphics hardware, socket IO, etc. I imagine the answer will vary for each, but some patterns will emerge. Or equivalently, where do you see the responsibilities for each piece required for integrating Rust with the web sitting—which bits should live in: - the compiler? - a handful of interchangeable "shim" crates? - every crate deals with it by itself? - JavaScript/NPM modules to provide shims? - "post-build" tools / custom linkers? - something else? 
I'm feeling a bit dense now... so of course the head is consumed by `into_iter` and the result is bound to that "internal" variable `iter`, which of course means you can't do anything with it during or after the loop, because ownership of the data went away. But that's not what's happening on line 32, is it? I'm not trying to access that iterator after or within an iteration. I think the expansion shows it anyways: `into_iter` takes ownership of its argument, which is `self.orig`, but since `self` is just a reference, ownership can't be transfered for one of the struct members. Line 100 is wrong anyways I guess. Thanks a lot! 
Everyone says Python. But I kinda always liked to tweak with Gnu Linux system tools as partitions, init, bootloader, device drivers fixing, kernel modules... So after years doing it I kinda want to write some system tools or fix them. Is it impossible to begin programming by learning C or Rust?
`cargo test` doesn't do optimizations by default. See http://doc.crates.io/manifest.html#the-profile-sections for all the different profile defaults and what command they are used for. Criterion seems to use `cargo bench` so compiles with optimization. But uses `#[test]` to annotate the benchmarks in the code.
Oooops... yes, my bad, I didn’t notice that it uses `cargo bench`
Oooops... yes, my bad, I didn’t notice that it uses `cargo bench`
Keeping the minimum value is a blunt, if somewhat effective tool. But often you don't care for only the best case. If one out of 500 customers of your website gets the site in 100ms and the others wait for five minutes, you'll be out of business soon, despite stellar benchmark results.
You can create many tools in Python. Many linux services use python behind the scenes. I don't want to discourage you about rust. But I first started like you with low level language, got annoyed of not being to do anything useful. Learned python and enjoyed programming, and I acquired a solid background. Now I can learn virtually any language without the beginner barrier. And for most tasks (and I really mean MOST) it is good enough, if not outright the best. Now to answer your question, you can start by learning c or rust. Just know that you may (from my own experience) get bored of doing boiler plate stuff before being productive. And you may get annoyed by the number of concepts to learn at the same time. But just know many (MANY MANY) people started with C and are just fine. I just think that starting with Python may not only speed up the process, but you may just settle for it and enjoy it.
I do it with a custom target like this: https://github.com/intermezzOS/kernel/blob/e6972ec09b2f02305cc79a40c6ad2e6624869b4f/x86_64-unknown-intermezzos-gnu.json#L17
Yes it doens't apply to network traffic. It's not the area Alexandrescu cares about.
One more question for today :) How do people deal with code they want to keep for later, but out of the project for now? People have been very helpfull here in this very thread, and now I have around 5-10 variant of some functions that I benchmarked and studied. I just want to choose one now and keep on working on the app, but I want to revisit those variants later (partially to benchmark them when more of the program structure is fleshed out and when I have different data to benchmark, and partially to see if I can make those variant work later when I probably remade some of the code). I could put them in the vcs, like make a commit and revert, but that feels wrong, I'll probably forget about it. I could make a "notes" style file where I can just collect code, but that's just bound to be large and unstructured. Maybe an "alt-*" crate where I can collect alternatives? If anyone has a better idea, I'd be glad if you told me :)
Oops you're right, I forgot about Tokio cores.
I actually had the pleasure to talk about that with Alexandrescu, so I can give some insight in this. There are 3 points: - Use the [mode](https://en.wikipedia.org/wiki/Mode_(statistics)), - Use the minimum, - Micro-benchmarks lie. --- The first point is that mean, median, percentiles, etc... are not very good. Even mean with standard deviation is not so good. The reason is that those statistics say nothing about the *distribution* of your data; for example, the mean/median is rather non-sensical when you have a bi-modal distribution. Therefore, it's better to present the user with the mode(s) because it shows *the clusters*. --- The second point is that when benchmarking a CPU/memory bound piece of code, there's a lot of interference: - Memory swapping (please tell me it's disabled on your computer), - Memory-bus jam (another program was requesting something), - Scheduling (your thread is paused and resumed in the middle of the measure), - ... Those interferences are *statically independent* from your piece of code. Pure background noise that reveal nothing about the performance of your code, and that your code *does not* influence in any way. And therefore, Alexandrescu argued that in those situations the mode is actually the minimum, or close enough it doesn't matter. --- The third point is that micro-benchmarks lie through their teeth. They have exclusive use of the CPU cache, the CPU branch predictor, etc... it's easy to accidentally "overuse" one of those resources and not realize it, and when you plug the code into your real program its performance is way worse because it has to contend with the rest of the program. All the fancy statistics in the world cannot make up for a flawed benchmark, and most micro-benchmarks are flawed anyway. Spending time analyzing fancy statistics at this stage is premature, you're losing your time. The minimum is a sufficiently good approximation, and it'll allow you to iterate faster. --- And to wrap up, the work-flow he advises is: - pull out the offending piece of code, - optimize it in a micro-benchmark, as it allows fast iteration, - plug it back in, and measure. You're welcome to use fancy statistics on step 3. Actually, you probably should.
Damn, that one was faster for me, haha. There was also this one where the `copy_nonoverlapping` compiles to an unaligned read rather than a `memcpy` pub fn parse_str5&lt;'a&gt;(s: &amp;'a str) -&gt; Option&lt;Card&gt; { use self::Card::*; use std::ptr; let b = s.as_bytes(); let len = b.len(); if len == 0 { return None; } if b[0] == b'$' || b[0] == b'#' { return Some(Comment); } else if len &gt;= 4 { let mut int: u32 = 0; unsafe { ptr::copy_nonoverlapping( b.as_ptr(), &amp;mut int as *mut u32 as *mut u8, 4, ); } const NODE: u32 = 0x45444f4e; const SHEL: u32 = 0x4c454853; if int == u32::from_le(NODE) { return Some(Node) } if int == u32::from_le(SHEL) &amp;&amp; len != 4 &amp;&amp; b[4] == b'L' { return Some(Shell); } } None } 
I agree with your assessment of why you can obviously see the rust code is bad (simple task that needs an unsafe block). Indeed, I think that given a Rust codebase a lot of debugging could be done by just greping for "unsafe". Usually in a C++ codebase greping for the words "*copy" , "new", "free", "*alloc", "delete" and the symbol "*" is enough to get 99% of the code that will cause memory bugs and usually enough to determine which maintainers are C developers (and that's the code one should be reviewing). So in the same way you could look for shady unsafe blocks in rust I could look for unsafe raw pointers and direct memory management in C++. Also, I will guarantee to you the C++ code doesn't look innocent, it may to a C developers, where initialization and allocation of resources are considered to be separate things, but reading even an "beginner book" on C++, like A Tour of C++ (Meant for high school students and people new to programming and created by the original creator of the language), will probably make you see warning signs when looking at that code.
Sweet! Didn't know there was a meetup or much interest in rust in SA, glad there is though. 
I don't see it as a personal attack per say, but I've spent too much time addressing people in this thread already and my opinion is obviously un-welcome, so I'd rather not start arguing what constitutes a personal attack and what doesn't. If you do wish to remove any of the comments since you think they constitute a breach in the subreddit's code of conduct please remove my top level comment, so that there aren't weird half-finished discussions left.
So it will take even more to be productive ....well I already have a solid career so I can endure some years till I can make the switch! Thank you! 
[removed]
well AWS has interest in rust, but they're in cpt. 
Whoever this someone is, I want to thank him in advance. And I can't wait for the future wasm libstd.
Awesome stuff. I'm very happy it's gaining a foothold here 
Trying to learn Rust by going through [adventofcode](http://adventofcode.com). Here's the repo where I'll put my solutions, any comments are appreciated: [Github](https://github.com/FFCrew/advent-of-code-2017).
What information is given by the compiler for the trait implementations of a given type when generating the docs?
Well you will have to use one or the other to compile your C code and run it
You're talking about [this](https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html#implementations)?
`cargo test` is compiled without optiizations, yes. Criterion.rs uses `cargo bench` which is optimized, though with the `#[test]` annotations and everything I agree that it's confusing. One of the first things I aim to do is make it work more like the normal `cargo bench` behavior.
Yes. I really don't like how it's currently laid out, and in some cases (integer primitives) it's practically unusable. Therefore, I want to at least try to do something about it, rather than just moaning.
The main issue comes not from lifetimes (there are no references flowing in or out), but having to figure out and communicate to the compiler who owns the in and out values. With your bound on T, the closure takes arguments by value (move) - whenever you use the calculate closure on some arg: TIn, it is consumed and disappears. If you want to put it in the HashMap afterwards, you need to have cloned it beforehand. Similarly, HashMap owns its keys and values, and unless you're ok with removing the key/value pair from the map altogether, you can't get TOut out of it - only &amp;TOut or &amp;mut TOut, both bound to the lifetime of the HashMap. Again, the solution, if you want to maintain the original signature of T, is to settle for the &amp;TOut and clone it to get a "standalone" TOut. The example from TRPL is deceptively simple, because it deals with primitive types (integers), which implement Clone + Copy, that is, not only are they clonable, but they also get automatically cloned wherever you would get a compile-time error otherwise. That being said, I am not a very experienced Rustacean, so [my solution](https://play.rust-lang.org/?gist=68036daebd2efa173a4c29b0fac0396a&amp;version=stable) turned out much less elegant than I had expected - mainly due to problems with modifying the HashMap while holding a reference to a value. If someone more experienced could comment, that would be appreciated.
So a Rust program is made of function calls. Even basic operations like "add two `i32`" is done with a function call. Obviously to make anything reasonably fast (and Rust is typically among the fastest languages) it's necessary to *not* translate every function call to a `call` opcode. Most should be implemented using "inlining," meaning that one function is copied into another. It's best to think of this as the default: the `call` opcode is used sparingly and only when required. But, you can only make calls between dynamic modules using a `call` opcode. This is because dynamic loading works on the machine code level. So you need some mechanism to specify that Rustc *has to* generate those dynamically linkable machine language calls, instead of its preferred, faster inlining. The one mechanism that does this and has stability guarantees is `extern "C"`. Anything else is undefined behaviour per the Rustonomicon. Rust doesn't have a formal specification yet, but if you do one of the 'Nomicon listed Bad Things, you should expect it to *break unpredictably with security implications.*. It's the opposite of a stability guarantee. Because trait objects (pointers to a trait type such as `Box&lt;Trait&gt;`) require dynamic dispatch, they coincidentally need `call` opcodes and it's possible to pass them between modules and it might work. The problem is that a Rust call like `Module::Initialize` will turn into something like machine language `call [trait method #3]`. **There is no guarantee that different modules compiled at different times will use matching numbers.** And your machine code might call `Module::Uninitialize` instead, probably with the wrong number of arguments. Experiments by /u/stevedonovan suggest that if you use exactly the same compiler and library version, you'll most likely get modules which agree. And with the compiler team making idempotence a goal, okay, yeah, that's likely to stay reliable. But it has to be exactly the same compiler (rustc same build same platform), which means you can't have different projects (game engine vs game) talk to each other, so it's really not terribly useful. 
I was nodding my head, agreeing, until the last paragraph. Cargo makes pretty sure that any artifacts are rebuilt if the compiler changes, and generally you'd do a rebuild-world when this happens. Assuming that all artifacts are built with the same compiler, then there's no reason why projects can't talk to each other.
It's something complicated. I'm working on a more global information presentation. The point would be to only display what's necessary by default and then allow readers to have more information.
Haven't read all the comments, but here are two things that came to my mind: - Use `-C target-cpu=native` and LTO - parallelize reading the lines if possible (e.g., using [rayon](https://docs.rs/rayon/0.9.0/rayon/str/trait.ParallelString.html#method.par_lines)) - Matching on the first char might be a good idea, and the largest string you match on is just 5 bytes in UTF-8. You might be able to do some bit-wise comparisons. LLVM might already do some of that (check the ASM). Next step would be to use SIMD instructions to boil this down to as few instructions as possible, e.g., by trying to check for all four masks in one go.
This is a writeup on the making of the WASM port. Previous discussion can be found [here](https://www.reddit.com/r/rust/comments/7gy068/rocket_the_game_on_wasm/).
Yeah, I figured it wasn't easy, or it'll have had something done about it by now. I was thinking something akin to [this mockup](https://i.imgur.com/j57cDwL.png) I threw together some time ago (except styled by someone competent). But generating that would require having access to the generic signature of the traits and their methods.
In case you decide to give it a try, you should take a look at [this code](https://github.com/aochagavia/rocket_wasm/blob/ddee487a67370712a6cb9ae31a169d981f13f28c/html/index.html#L140-L157) which handles keyboard input. You could reuse the `module.toggle_*` functions, so you only have to change the Javascript code.
I see this is using rustc_serialize, can I ask why? Also, what nightly features are you using? (I see [feature(test)], but I've never heard of that before...)
You got it. No moving out of `&amp;mut self `.
&gt; (I see [feature(test)], but I've never heard of that before...) The `test` feature is what you use when you want to use the `test` crate, which contains the `Bencher` type for benchmarking, and also `black_box`. Example: https://github.com/BurntSushi/rust-memchr/blob/master/benches/bench.rs
&gt; So using #[bench] requires nightly but its possible to enable #[test]s during the cargo bench run? Good to know. Yep, cargo bench is stable, but not the `#[bench]` framework. This means you can already run benchmarks on stable using something like bencher, which is the standard bench framework extracted as a crate. &gt; Odd though, cargo bench --helpsays -j N, --jobs N Number of parallel jobs, defaults to # of CPUs. Shouldn't the default be N=1? I think (by analogy with the cargo test options) that this refers to the number of cores used to compile the code. If using criterion and `#[test]`, one may want to run them with `cargo bench -- -- --test-threads=1`. &gt; Is there a recommended CI configuration for benchmarking? In my experience, Travis and CI in general is not a good setup for benchmarking: CPU and memory are shared in virtual machines between multiple jobs. This means that the performance of your benchmarks will depend on what other project is running on the same machine as you. For benchmarks, you want to have some hardware just for yourself. But if someone have a setup that can work for benchmarking on a CI like provider, I would love to hear about it! 
`#[feature(test)]` gives access to the internal of the test framework, for example to define tests by hand or so. It might be possible to remove this feature by using https://github.com/servo/rustc-test, a crate that contains the same code, but made to work on stable. The main downside of `rustc-test` is that the users have to manually annotate the all tests as `harness=false` in Cargo.toml.
pta, so close enough that I can make it, but I'd likely only start attending from next year on if I decide to go, it's crunch time now
Does this also mean returning errors over thread boundaries is easier now? I guess after the 0.5.0 release of imag I will switch the whole infrastructure over to failure. 
Ah, that was a silly mistake on my part. I think the trait bound actually doesn't need to be T: Fn(TIn) -&gt; TOut, but would be fine as T: Fn(&amp;TIn) -&gt; TOut. I [made that change](https://play.rust-lang.org/?gist=0422585718d5f640b26087b7eb720f51&amp;version=stable) on your solution, and I'm back to getting errors about missing lifetime bounds, so I think that's still the blocker. I will keep messing with it and try to get it right. Thanks!
The direction you took is different from mine. In my case, we'd have very little of rust syntax. It'd be more like "function X" or "method Y" without arguments or anything. But it makes search more difficult sometimes, which is why there's still nothing in docs yet.
Criterion.rs uses `rustc_serialize` mostly because it hasn't been updated yet to use Serde - most of the file IO code was written before Serde was first released. I'll make an issue to update that. Aside from using the `black_box` function from libtest, most of the nightly-only features are in the statistics sub-crate [stats.rs](https://github.com/japaric/stats.rs). Most of those features aren't strictly required and will probably go away soon (eg. fn_traits and unboxed_closures).
You have also changed value from fn value(&amp;mut self, arg: &amp;TIn) -&gt; TOut to fn value(&amp;mut self, arg: &amp;TIn) -&gt; &amp;TOut do you want to give away TOut itself or a reference?
Yes, I think it should be a reference. The Cacher/HashMap should stay the owner of TOut. 
[There you go](https://play.rust-lang.org/?gist=9b2d6cf1df6d6917eadbad6e4330b667&amp;version=stable) :)
Thanks! Exactly what I was looking for :)
Everything aside, that is seriously addictive. Thanks for sharing! 
Ah, you mean make it more like the Methods sections? My desired outcome would be to preserve all of the information that is currently there, as it is very useful, but to reduce the repetition. 
Can this fallback to asm.js? Does Rust allow that?
https://www.reddit.com/r/playrust/comments/7h3kg2/free_rust_steam_key/
Rust does, this target does not yet. Using the emscripten target lets you get it though.
My preference is always to go for the struct way. `Value` is for when you really don't know what the JSON contains. If there are fields in the outer objects that you don't care about, simply leave them out of the struct and they will be ignored. The struct way will generally give you much better error messages than `Value` because by the time you have deserialized a `Value` and start manipulating it to build a `Vec&lt;MyStruct&gt;`, it no longer has enough information to tell you what line and column in the input JSON was wrong. Also structs give you a much easier path forward when you realize later you actually do care about one of the additional fields in an outer struct. But there is an easy way to make it work with `Value` if you can't stand the extra structs. #[macro_use] extern crate serde_derive; extern crate serde; extern crate serde_json; use serde::Deserialize; use serde_json::Value; #[derive(Deserialize)] struct Response { data: Data } #[derive(Deserialize)] struct Data { children: Children } #[derive(Deserialize)] struct Children { values: Values } #[derive(Deserialize)] struct Values { content: Vec&lt;MyStruct&gt; } #[derive(Deserialize, Debug)] struct MyStruct { user: String } fn main() { let j = r#"{ "data": { "children": { "values": { "content": [ { "user": "YourGamerMom" } ] } } } }"#; // One way. Better error messages. let resp: Response = serde_json::from_str(j).unwrap(); let content = resp.data.children.values.content; println!("{:?}", content); // A different way. let resp: Value = serde_json::from_str(j).unwrap(); let content = Vec::&lt;MyStruct&gt;::deserialize(&amp;resp["data"]["children"]["values"]["content"]).unwrap(); println!("{:?}", content); } 
Check out the [OSDev Wiki](http://wiki.osdev.org/Books) books page. The OSDev Wiki is a fun place in general really. And don't forget to keep a goal in mind as you explore.
Since the compiled code is WASM without dependencies (besides the `extern` functions), I guess it should be easy to translate it to asm.js... Though a quick Google search didn't return anything relevant.
Re PS: yes, its the same as let anon = S { f: vec![] }; let mut x = &amp;mut anon;
Ok, thanks for the quick answer. This will be useful for the code production part of my compiler.
Sorry, looks like you only read the title. I've since become aware of the complications of dynamic linking in Rust and it's not the way I plan on doing it anymore.
Wow...I think I found the heaven...lots of good reading! Thanks! 
&gt; Assuming that all artifacts are built with the same compiler That's the issue; it's hard to coordinate with mod developers and packagers to make sure the compiler version they're using matches. To make matters worse, different OS package distributors ship new compiler releases at different times, meaning that everyone may be "up-to-date" but still out of sync with each other.
[removed]
Didn't expect a response from a serde dev! Since error messages are important to me, I think I'll bite the bullet and make all the structs. Thanks for the tip about the other way, though. Thanks.
Any expression producing a value can be borrowed, and yes, the result points to a stack temporary, in which the value was stored. C (and to some extent, C++) impose artificial limitations - some of them might have to do with safety, although, in C++, methods will gladly give you back this power (via `this` and friends). Rust , OTOH, can actually track the references and so accidentally using a reference past the scope of the temporary it points to gets you a compile error instead of UB, so there is really no point in disallowing it.
/u/dtolnay is anywhere and everywhere. Just whisper _serde_ and they appear instantly. A specialized genie if you will.
For reference, Stroustrup explicitly mentioned that he thought that the ability to bind temporaries to references (not const-references) would be harmful and thus he forbid it, however for a long time MSVC was not conformant, allowed it, and I can't remember any harm coming from it. It was as gut-feeling decision, and honestly I don't see much value in it, especially as you mention since methods can be invoked on temporaries anyway.
Awesome. Thanks for sharing. 
[removed]
I love conversations like this.
`x` and therefore `tmp` are just pointers to the anonymous S that lives on the stack for the duration of `main`, so reassigning pointers is fair game since it's all coming from the already-borrowed S value
Wait, can we not render w/ webgl using wasm / asmjs? i'm sure it's possible with the standard emc compiler, does rust not support this / have any gl libraries to target webgl?
Yeah. I finally watched withoutboats' talk on the failure crate. I found that very useful. More so than the documentation on the crate itself. Thanks.
I'm concerned about someone thinking that they can expect plugins (like 90s web browser plugins) distributed as binaries to work. 
Got branches for me.
Any word on when the example code will be out? The repo mentioned, https://github.com/oreillymedia/programming_rust, doesn't exist yet.
Go with `Failure`. In your binaries use `failure::Error` in libraries, or a very self-contained code with clear error conditions use types implementing `failure::Fail`. `error-chain` is our previous best error management library, and they should interoperate well.
1) Because your code only creates a specific instance of the iterator (`Cycle&lt;Chars&lt;'_&gt;&gt;` to be exact) you should not be using a type parameter for the iterator. This is the same as the SO answer - you are lying to the compiler by saying "I can create this for any A", but you only create `Cycle&lt;Chars&lt;'_&gt;&gt;`. 2) One of the problems is that you create some iterators, but the try to hold them `by_ref`, so you get the complaint that stuff doesn't live long enough. Also, you try to put `chars_iterator` in the struct, and also use it `by_ref` in zipping, which looks pretty bad - either aliasing multiple references, or stuff not living long enough, or self-borrowing struct. If you wanted to have multiple copies of the iterator just `clone` them - but of course they will not stay synchronized, they will be just separate iterators. In the end, here's how I attempted to fix it, but to be fair I'm not that sure about what your code should be doing in the first place: https://play.rust-lang.org/?gist=b0a47263a609237e06950e570f35a51e&amp;version=stable
Or if you are ok with using experimental stuff, take a look at futures_await. That way async code looks pretty much like synchronous, just with some await! macros and #[async] attributes sprinkled here and there.
Good point. ABI stabilisation will happen, eventually, although I can see that it isn't a useful priority at the moment 
You'll probably want to read: http://cglab.ca/~abeinges/blah/too-many-lists/book/ and/or https://rust-leipzig.github.io/architecture/2016/12/20/idiomatic-trees-in-rust/
TL;DR: Use indices, or smart pointers, or unsafe.
[removed]
Not to be confused with [that other Rocket in Rust](http://rocket.rs).
This may just be me but I haven't been convinced of the value of any of those crates. I prefer my handcrafted, artisanal `Error` enums which I occasionally automate with [derive-error](http://docs.rs/derive-error) and [macro-attr](https://docs.rs/macro-attr/0.2.0/macro_attr/)+[enum-derive](https://docs.rs/enum_derive/0.1.7/enum_derive/).
What do you mean by reloading templates at runtime? If the template is just standard Rust code, then you're hot-reloading the whole application... which becomes normal restarting of the process, right?
[Here](https://www.reddit.com/r/rust/comments/7gg7lm/what_is_currently_the_best_options_for_gui/).
is your source code available? this sounds like a fun project.
This is part of a course on compilation. I will put it up on Github.com at the end of the year. This is in Ocaml though, so I don't know how useful it will be to you. 
Well, I kinda didn't expect to find that rustdoc is actually part of the compiler, nor that you're using the cleaned AST directly to generate the docs. I can see how that would complicate things. This should be interesting, I've never dug through a compiler source before.
Take a look at [conrod](https://github.com/PistonDevelopers/conrod). I think it fits your use-case well.
Note quite. You have to rebuild the template but you don't have to restart your app. Check yourself in the example crate. 
I understand that the compiled code will work just fine and that the code respects the safety principles of rust. But what is the general rule? Could you give me a link to a good in depth explanation of the borrow checker? The book pretends that it is simple but there seem to be many corner cases (think about if/else for example) that are not explained. I looked at the github repo and there is an explanation in the librustc-borrowck folder but it only considers lvalues and not any value. 
I've never used them myself (though I have used IDEA's *Shelve Changes* feature which is very similar), you can create patch files of the different functions and apply them without having to maintain a bunch of branches which tend to fall out of date rather quickly. It's literally as simple as saving the current diff from `git diff` to a file, resetting your working tree, and then telling Git to apply that diff sometime later: https://stackoverflow.com/a/15438863/1299804
The empty string is probably implementation dependent, that is, not specified in the C++ standard. GNU does it this way, other standard library implementations may not.
The problem isn't this, it's that we generate the HTML directly instead of generate JSON and then use JS to generate HTML. Other than this, most "interesting" code is in `html/render.rs`.
It is, but having the rust syntax is slowing down the doc reading. That's the current issue. I want to make a compromise between the two.
&gt; mingw-w64-harfbuzz The nice thing about aur packages is you can look at the packagebuild and see how they are being made. For example the harfbuzz package is here: https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=mingw-w64-harfbuzz If you look at the file, it's grabbing the source from here https://anongit.freedesktop.org/git/harfbuzz . Then compiling with a couple flags set. I wouldn't say it's easy necessarily, but not too difficult. The other option is making an arch docker container for cross compiling. That would be much easier.
Thanks for the feedback. I'm looking at this right now! 
I think /u/japaric would be a better person to ask about this; the statistics code was already in place when I took over the project. One of my major tasks for the near future will be to dig into that part of the code, understand how it works and document it.
I just wish the docs of failure were a bit more fleshed out. The other part I miss is the `quick_main!()` macro.
Just so you know that name may lead to confusion for those, eventually, looking for a crate that allows [Metal](https://developer.apple.com/metal/) development.
Sure there is, just like you can say "Ruby/Python". They're not talking about a single language, they're saying "I've worked with C and C++ before and they both have problems". It is possible to compound things when making comparisons.
I feel like Cape Town has a more active open source developer base, this based on them having hosted a Debian conference, and the first South African Python conference.
&gt; Right now, my intuition is that a slice is a struct that contains a length and a pointer. https://doc.rust-lang.org/1.22.0/std/primitive.slice.html agrees with you. Slices are views into data but are not the container that actually stores the data. (didn't read any of the code, there's too much of it, and I have too little time)
`let tmp = x;` infers that `tmp` has exactly the same type as `x`, including its lifetime. Then `x = &amp;mut tmp.f[0]` is okay because the lifetime of `tmp` has to outlive `x` and *every lifetime outlives itself*. Outlives is the same relationship as subtypes, so it's reflexive. 
Sometimes it just doesn't make it into the nightly. I think it's usually because continuous integration notices a problem, but I really don't know. There used to be a great website for seeing when rustc nightlies failed to build and things like that, but I can't even find that website right now. It would be nice if the Rust CI logs were better linked to.
Things changed in nightly that made RLS not compile with the most recent compiler. It'll probably reappear over the next few days. If you think this is annoying (it is!) and you want to do something about it, have a look at https://github.com/rust-lang-nursery/rustup.rs/issues/1277 :)
And not to be confused with [that rocket in other rust](http://rust.wikia.com/wiki/Launch_Site).
Why don't you like [maud](https://github.com/lfairy/maud) or [horrorshow](https://github.com/Stebalien/horrorshow-rs)?
This is so annoying it should be that a nightly that breaks installed components should not install on rustup update. 
Btw, [here](https://www.reddit.com/r/rust/comments/348yu2/string_interning_libraries_for_rust/) is an old thread about string interning libs.
So lifetimes are transfered in a let binding ... That explains everything. I can finally sleep, thanks. 
Can anyone recommend a good open source project to enhance your understanding of language and best practices via reading &amp; learning other people's code? Jumping into servo or similar codebase size and complexity-wise projects is rough.
Thanks for the pointer of where to look, I think I'm starting to get a basic understanding of how the data is stored and pages generated. You weren't kidding about the embedded HTML. That's uh... yeah, that's embedded.
Hi Guys, This is the forth post I wrote about [Learning Rust on Medium](https://medium.com/learning-rust). In there I tried to summarize about, ▸ Modules * Modules in the same file. * Modules in a different file in the same directory. * Modules in a different file in a different directory ▸ Crates * lib.rs file on the same executable crate * Dependency crate specified on Cargo.toml (from path, git repo &amp; creating a create for crates.io) ▸ Workspaces ▸ std modules and Preludes I am a 🇱🇰 Web Developer who lives in 🇻🇳. So I am not a native English speaker and just learning Rust, If you found any mistake or something that I need to change, even a spelling or a grammar mistake, please let me know. Thanks.
Yeah, I mean, if you can guarantee that you're using the same libstd and the same compiler / optimization level at compile time, and you can deal with the lifetime issues of a dynamic module, and you're using an rdylib, it should work fine. There's no reason it's unsound. However, the C++ ABI is much closer to stable on some platforms _in practice_. I'd guess the difference between Ubuntu 14.04 and 16.04 is GCC's "C++11 ABI", which makes a couple of small but wide-impact changes to satisfy requirements of C++11 (constant-time length on `std::list` and no copy-on-write on `std::string`, or something, I think). Outside of that transition, GCC / libstdc++ hasn't changed its ABI in many, many years, and won't change again for many years. And libstdc++ changed the assembly names of symbols to attempt to catch this, and included compatibility versions with the old names. Rust makes nowhere near as much of an attempt of stability of libstd type definitions, on purpose, because changes of this scope or more could potentially happy at every minor version or even a patch version.
I was not aware that Erlang / Elixir was so better to do that kind of thing, that's why I was trying it with Go or Rust. Now I'm learning Elixir and doing some tests with Phoenix Framework, it seems like it has all the features I wanted and right for that job. Thanks a lot everyone that suggested it!
How did it go? Did you succeed with the backup?
Just curious why somebody downgrade this?
This is probably the most interesting Rust code I've written so far. Getting all of this stuff working together was quite fun. Practically, this is a way of solving the [xcape for Wayland](https://github.com/alols/xcape/issues/67) issue, while also allowing other fancy input mapping things to happen.
I very much dislike DSLs. The fact that I have to sprinkle the code with some weird sigils like `@` to have a loop is a pain. And templates create new problems: weird error messages, tools incompatibility etc. I wanted to push non-template solution as far as possible and see how far I can get.
Is it going to be like [IncludeOS](https://www.includeos.org/) but for Rust? That'd be really cool!
wasm and asmjs are not the same thing. `emcc` is emscripten, which is also not the backend being used here, while it is a supported option. you can render with whatever you want. But, WASM does not have **any** ability to interface directly with the DOM or WebGL or anything. If you *believe* it does, then you've simply seen WASM compilers that bundle a JavaScript standard library that exposes those interfaces to WASM automatically, but WASM currently *must* communicate through JavaScript to do anything that yields visible results.
Yep! I'm planning for it to be the backend for metalOS, but you'll be able to use it for pretty much anything.
Oh i had no idea that wasm didn't support that, I just knew you could use opengl when you had asmjs as a target with the emscripten c compiler! I thought it was a limitation of the rust compile target rather than wasm itself. That being said that's super sucky, i've heard people talking about wasm only being a 'companion' or whatever to JS, is there a big push for opengl support w/ wasm, is it planned? Or is wasm always going to just be this thing you call into from JS? That'd be a real shame:(
I think it's [being considered](https://github.com/WebAssembly/design/issues/1079), but no idea when it will happen. For now, I keep hoping that someone (maybe me) will implement as lightweight of a "standard library" as possible in JavaScript to expose all the standard functions to WASM.
I also noticed this with `rustfmt-preview`.
just guessing, but the title being all-caps and not specifically sounding like programming probably led someone to believe this was another spam post about the Rust video game. I personally see like 3 or 4 of them per day.
yeesh, i'd be kiiiinda okay with DOM access but no rendering capabilities too? There aren't even any technical issues regarding GC here like there are with DOM, right? What a pain. HMU on github.com/tomc1998 if you're gonna go ahead with that, would be really interested in contributing.
I think the main reason is they're just trying to get a minimum viable product that all browsers can implement that has the smallest attack surface for vulnerabilities. Just guessing. If I do find motivation to work on something like that, I'll let you know! Motivation has been a real struggle lately.
A small tip when coding in Dyon: "for i len(evts) {" can be replaced by "for i {" since Dyon understands from "evt := evts[i]" in the loop body that it should use the length of "evts". You can also use this trick for packed loops, for example: list := [[[0; 2]; 3]; 5] for i, j, k { list[i][j][k] = random() } More information about this design here: https://github.com/PistonDevelopers/dyon/issues/116
These generic names really cause unnecessary problems. Not only is metal generic, but it is already a library created and popularized by apple.
I almost understood half of it. Still trying to wrap my head around the current object hack! :)
Heh, this looks a lot like the templating system I made for [domafic](https://github.com/cramertj/domafic-rs/blob/master/examples/todo_mvc.rs#L79). We both have very similar `impl_tag` macros, too! ([yours](https://github.com/dpc/stpl/blob/master/src/html.rs#L179), [mine](https://github.com/cramertj/domafic-rs/blob/master/src/tags.rs#L283)). :)
They just spawn on top of you, still or not.
I'm amazed at how nice the rust-javascript interop looks. It's crazy how quickly WebAssembly has gone from "Cool in theory but hacky" to "this is nice and ergonomic."
rustup should have something like `rustup install nightly --lastgoodbuild` that will grab the latest nightly where everything built correctly...
Wasn't sure where to post this and I didn't want to clutter the sub. I view reddit on half a screen which results in a "narrow" window by most people's standards. While reddit is already fairly hostile to such narrow windows (sidebar claiming half the window I'm looking at you ಠ_ಠ) it's usually handled with slightly more grace than on r/rust. Usually the entire page is used for content starting below the sidebar, on r/rust this isn't the case. Here's a couple screenshots of what browsing r/rust is like for me: - Significant whitespace in the sidebar between shortlink and submit button (not the end of the world but would mean more narrow content in a future where the content is widened after the sidebar) N.B. I don't have adblock enabled: [sidebar whitespace](https://screenshots.firefox.com/a2C1x3aPo8UNIjsU/www.reddit.com) - Normal comments are narrower than they have to be because of wide left margin: [normal comments](https://screenshots.firefox.com/WLQ2oSsGfugd7oWu/www.reddit.com) - Comments rapidly disappear off screen, at which point the only thing that helps is a wider window: [silly vertical text](https://screenshots.firefox.com/H6c4KD6aSAFiwDVY/www.reddit.com) I have added custom css to my firefox profile to make r/rust usable for me so this isn't really an issue for me anymore but I expect plenty of people either don't know how or don't want to invest time in doing this and there's no reason for a theme to be this unusable in less than fullscreen windows. One more thing, the logo isn't part of the sidebar even though it is visually. I don't display the sidebar when my windows get too narrow so it'd be nice if the logo was part of the sidebar.
Yes, they look very much alike!
Was is the difference between WASM and asm.js? Does one of them has better browsers support? 
http://doc.crates.io/build-script.html#case-study-code-generation
I feel like a complete idiot, because i'm actually completely aware of build.rs and have used it before._. thanks;)
To add to what coder543 said: you're screaming in the title, and it says absolutely *nothing* about what it's about. I assumed it was yet another Rust-the-game post and only clicked on it to make sure it had been reported and downvoted. Also, as an aside, please don't speak in emoji. I can't understand what you're saying.
[removed]
The comparison is necessary because there is no implicit cast from integer to boolean, but I assume it will be optimized away by rustc. Someone more knowledgeable might confirm this.
The easiest way to implement the coercion behavior to bools that many languages do is just to add `!= 0` after your expression. So: if foo &amp; 1!= 0 {...} It does exactly what you want. It might be a bit verbose, but it is a lot more explicit in what you're trying to do. As for efficiency, if you meant runtime efficiency that !=0 check will usually just get optimized away to whatever the hardware does. 
 pub fn f(x: u32) -&gt; bool { (x &amp; 1) != 0 } compiles to example::f: and edi, 1 mov eax, edi ret No comparison.
&amp; is not a comparisson operator. It's a bitwise and. That usually returns an int in both rust and C. The difference is that C converts "if (condition) {}" into "if (condition != 0)" but Rust requires condition to be boolean. The resulting compiled code should be about the same in both languages, with the same efficiency.
I probably should have put quotes around comparison. I guess it just seems redundant to me because a 0 bit is false and a 1 is true, and that being the case why would I want a != 0 when I already "have" the Boolean as a bit value? I see what you're saying though, If the compiler optimizes it, I guess it doesn't matter. 
It's not a case for optimization. It's a case where C doesn't differenciate between boolean and int, giving you a syntax suggar in conditional expressions. Under the hood they both ifs should compile to the same code. Even in C, even without optimizations.
Bits are not boolean. They are int. Even in C.
Same exact way as Java.
*Types* are transferred. Lifetimes are just a kind of type. I'm at a real keyboard now, so let me work your example all the way through with lexical borrowck. fn main() { let mut x = &amp;mut S{f: vec![]}; while x.f.len() &gt; 0 { let tmp = x; x = &amp;mut tmp.f[0]; } print!("{:?}", x); } Give locals types, expand macros, and dispatch methods. Also line numbers because why not? 00 fn main() { 01 let mut x: &amp;'_ mut S = &amp;mut S{f: Vec::&lt;S&gt;::new()}; 02 while Vec::&lt;S&gt;::len(&amp;x.f) &gt; 0 { 03 let tmp: &amp;'_ mut S = x; 04 x = &amp;mut (*tmp.f)[0]; 05 } 06 { 07 let fmt_args: Args00&lt;'bl08&gt; = capture_fmt_args_00::&lt;'bl08&gt;(&amp;x); // where Args0: fmt::Arguments 08 Result::&lt;(), fmt::Error&gt;::unwrap(write_to_stdout(args)); 09 } 10 } Lexical borrowck creates one type per scope (expression or block). So here we have three blocks: `'bl05` `bl09` `bl10`, each named by the last line in the block. And a bunch of expressions `e01`, `e02` (the while-predicate) `e03`... Here's the function with lifetimes inferred: 00 fn main() { 01 let mut x: &amp;'bl10 mut S = &amp;mut S{f: Vec::&lt;S&gt;::new()}; 02 while Vec::&lt;S&gt;::len(&amp;x.f) &gt; 0 { 03 let tmp: &amp;'bl08 mut S = x; 04 x = &amp;mut (*tmp.f)[0]; 05 } 06 { 07 let fmt_args: Args00&lt;'bl09&gt; = capture_fmt_args_00::&lt;'bl09&gt;(&amp;x); // where Args0: fmt::Arguments 08 Result::&lt;(), fmt::Error&gt;::unwrap(write_to_stdout(args)); 09 } 10 } Lexical lifetimes are *really pretty simple, no?* Any reference variable needs a lifetime that lives to the end of the block where it is used. Now check the borrow sites, the places where the borrow operator are used. - The borrow at `01` borrows a temporary location, so that's easy. Just take note that the temp location lives until the end of the block instead of the end of the expression. - the borrow at `02` needs lifetime `s02`. Shared borrow of the path `x.f` is needed in that expression, so `x` can't be mutated by anything else in the expression. Check. - there's no borrow at 03, just moving a reference. - the borrow at 04 borrows the path `*tmp.f` (`tmp` `tmp.f` and `*tmp.f`) uniquely. `tmp` may not be touched by anything else between lines 04 and 10, and it isn't. Check. - the borrow at 07 borrows the path `x` for the lifetime `bl09`. `x` may only be shared (not mutated) between 08 and 09. Check. 
This is correct. If you pass it to a function, they will be passed as an argument. I recommend godbolt to check that kind of intuition. Even if you suck at asm (like I do) it answers this kind of question. https://godbolt.org/g/XnqHJ9 Here you can see the function expect the len in rdx and the pointer in rdi. So everything happens as if you were passing this two as argument to a C function that used System V AMD64 ABI convention. https://en.wikipedia.org/wiki/X86_calling_conventions
**X86 calling conventions** This article describes the calling conventions used when programming x86 architecture microprocessors. Calling conventions describe the interface of called code: The order in which atomic (scalar) parameters, or individual parts of a complex parameter, are allocated How parameters are passed (pushed on the stack, placed in registers, or a mix of both) Which registers the callee must preserve for the caller How the task of preparing the stack for, and restoring after, a function call is divided between the caller and the callee This is intimately related with the assignment of sizes and formats to programming-language types. Another closely related topic is name mangling, which determines how symbol names in the code map to symbol names used by the linker. Calling conventions, type representations, and name mangling are all part of what is known as an application binary interface (ABI). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
C doesn't have boolean types at all. Boolean types in other languages are just syntax sugar for restricted integers not the other way around.
SWEET! RIIR!
Porting a famous japanese tokenizer library called kuromoji to rust.
I used H1 all capital on Medium because they don't support H3s and I have to use H1 and H2 inside the post.
Sorry. I used H1 all capital on Medium because they don't support H3s and I have to use H1 and H2 inside the post. 
I'm talking about the Reddit submission title, not the blog post
Motivated by: https://stackoverflow.com/a/47625964/3486684
First I thought "this sounds like the wrong subreddit". Then I clicked the link. Neat trick 8).
Too bad no one really uses it xD
Honest question, why would anyone use hg? I used it for about a year and constantly ran into systemic problems with tasks that are relatively simple in git. Even trying to rework a commit message that happened before a *local* merge felt terribly unwieldy. After giving up on writing wiki pages to answer a constant influx of hg questions on my old team, I moved them over to git and was have never looked back.
What about just using it to prove properties of would-be-unsafe Rust where that code is done in verified x86 wrapped in a safe, Rust interface? Might be useful for critical applications until Rust gets something like Microsoft's VCC, Frama-C, or AdaCore's SPARK. Meanwhile, I've suggested to people to do such critical ops in those tools with languages like Rust using the verified code with FFI. One person confirmed that plugging SPARK code into a Go app. Idk if anyone is mixing such languages with Rust, though. 
A lot of people say that git is too complex and that it's interface is bad. Mercurial is often cited as an alternative with a good interface that's simpler to use and understand. 
More like an inversion, C was an extension language, and now Hg will be embedded in Rust. 
[removed]
as long as you're doing very basic things I guess this is true. It would depend on your team and workflow though. 
This looks pretty cool. Do you have any experience with touchpads and evdev? It looks like you created this to solve keyboard issues specifically but I'm asking because I've been trying to create a virtual touchpad through libevdev with no success. A mouse is really simple but it turns out touchpads are quite complex XD. 
Can you check the content as well :D
What's the reason for the use of `pcg_rand`? From a brief look at the crate, it wasn't clear to me what the practical advantages are over plain `rand`. Are the generators faster than `XorShiftRng`?
Facebook uses it and I wouldn't say they use it for only "simple" things. 
Their complexity is about the same—it’s just that Git’s command line interface is *terrible* (look through [Steve Losh’s *Git Koans*](http://stevelosh.com/blog/2013/04/git-koans/) for some examples of how) while Mercurial’s is fairly good (and has shown an interest over time in improving it).
2017-11-15 is one that's working. I randomly guessed toolchains until I found one with rls that isn't too ancient
And mozilla uses it too, for Firefox. Doesn't change the fact that it is utterly slow compared to git. Also, it has no staging area, something I really like about git. That being said, it is great that they are rewriting it in Rust :). Now only git has to follow as well.
Raph Levien's [Rust container cheat sheet](https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/edit#slide=id.p) confirms your intuition and would probably answer other questions you're likely to ask too.
I'm really impressed that this is happening; it's a very ambitious undertaking! I hope they get good success with it :D
&gt;A lot of people say that git is too complex and that its interface is bad. If this was ever true, it hasn't been for a long time. I used Mercurial from 2008-ish (the rationale for choosing it back then was that Git was very much a second citizen in Windows at the time) and up until 2014 (I think) before switching to git, and never looked back. Switching to Git was an enormous improvement in every way, and pretty much revolutionized the workflow by allowing quick and easy creation of branches. While Mercurial does have a few advantages over Git, they do not come close to outweighing the downsides. The main ones I can think of are the fact that Mercurial tracks renames and the "convert" extension making it very easy to split repositories.
So it might not be slow anymore, after this rewrite
I really don't understand why everybody treats mruby as a non-existant solution. I understand why someone wouldn't want to use Lua in this particular use case, but mruby provides a powerful language without the huge load time issues and without requiring having Python installed.
Skype interview is good. But security is a concern for me. Hence, my company uses tools like on premise R-HUB web video conferencing servers for conducting online interviews. It works from behind the firewall, hence better security. 
2017-12-01 does as well.
Facebook uses mercurial [because it scales better than git](https://medium.com/@prasoon2211/mercurial-vs-git-scaling-and-architecture-94f70bb206ef).
In this particular use case, because it doesn't have a good Python interoperability story, and it didn't exist until long after Mercurial was released. This is where the Oxidation proposal gets interesting - leave the Python in place, and use Rust to replace the commonly used bits with faster code.
I noticed the same, I think it's because Jim Blandy used to maintain and work on emacs? Doesn't make much sense though
It's been gone for a few days in nightly. I solved it by switching back to "nightly-2017-12-01", which has it.
Seems to me like it would be a good idea by default to only perform an update if the new version has every component that the current version does and just fail with a notification saying what's missing if it doesn't.
Git is _internally_ very simple, spartan even. The problem is that it doesn't translate this architecture simplicity into interface simplicity. Mercurial has more concepts (like branches vs. bookmarks, for example), but they seem to be more readily approachable by beginners. Having used both, however, I vastly prefer Git for its flexibility.
I, for one, really appreciate memory safety in my Brainfuck interpreters.
Do you have a link to the talk? I can't find it on youtube or a ddg search
afaict the current implementation just has memory management inside rust on a single grow-only ArrayBuffer. freeing does do something on the rust side (the next rust allocation can take the memory), but rust can't return the memory to the browser, but keeps it around for future allocations. i wouldn't fret with it too much, though; once it becomes an actual issue, wasm can still either add a "shrink" functionality, or something like "trim" in the storage area where the memory user can signal to the lower levels that it's not using the memory there any more, so while it reserves the right to use it again at a later point in time, the memory provider is under no obligation to keep its current contents around any more. (this can be trivially achieved by zeroing freed memory and implementing memory compression).
Git is still a second class citizen on Windows, and apparently always will be.
rustdoc is being rewritten, maybe take a look at the new version?
https://air.mozilla.org/bay-area-rust-meetup-november-2017/ I couldn't find it on YouTube either, even when I knew what I was looking for. That link is to the video of the whole meetup. The talk on 'failure' is third: it starts about 1:15 into that recording.
[Asm.js](http://asmjs.org/) is a subset of Javascript. Any browser can run it [because it's just javascript]. Many browsers have made sure to optimize for it. [Wasm](http://webassembly.org/) is a binary format. Support for it is nascent and older browsers will not be able to support it natively. There's some hope even for older browsers though as I think a JS-based interpreter can be made to compile wasm code. Though at that point maybe best to keep two copies on hand on the server. P.S. I am not a web developer!
By "bare metal", do you mean a unikernel "library" à la [Mirage](https://mirage.io) or [HaLVM](https://galois.com/project/halvm/) or something completely different?
&gt; If this was ever true, it hasn't been for a long time. It's still true in 2017, you've just gotten used to it.
&gt; they seem to be more readily approachable by beginners. Mostly it has a clearer, more approachable and more discoverable UI. It's not that the concepts are more approachable, it's that the way you interact with them is more orthogonal and clearer. It also has revsets, which I regret every time I have to check `gitrevisions(7)`.
Isn't this basically what [dependent types](https://en.wikipedia.org/wiki/Dependent_type) are? 
**Dependent type** In computer science and logic, a dependent type is a type whose definition depends on a value. A "pair of integers" is a type. A "pair of integers where the second is greater than the first" is a dependent type because of the dependence on the value. It is an overlapping feature of type theory and type systems. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I will try to find some time to work more on a pure-rust solution to read the ROOT binary format - a file format use everywhere (to a fault) in particle physics. The idea is to use this Rust implementation in my [alice-rs](https://github.com/cbourjau/alice-rs) project. The `alice-rs` project is about analyzing the public data of the CERN base ALICE collaboration.
Marijn Haverbeke talks about Typestate in Rust, how it ooked like and why it was removed at the beginning of his talk "The Rust that could have been" on RustFest 2016. https://www.youtube.com/watch?v=olbTX95hdbg&amp;list=PL85XCvVPmGQic7kjHUfjHb6vz1H5UTEVG
I was actually thinking about building the same thing, though mostly with battery status in mind. Given that this is more a widget than actual UI with buttons and stuff, my thinking was to build it directly atop [cairo-rs](https://crates.io/crates/cairo-rs). But since thinking was exactly as far as I got, I have no idea how easy it is to build animations with that.
Why use Tokio? 
To be clear, *neither* Git nor Mercurial were adequate for Facebook's monorepo -- a use-case that neither tool was built for -- so Facebook started extending the tools to better enable said use-case and found they could adapt Mercurial more easily than Git because Mercurial wasn't written in C.
Some monorepos use it because git just can't handle large repos. Overall it's a very different model from Git and I've heard the _exact same complaints_ from folks who move from Git to Hg. (Note: hg has changed a lot in the past few years, the history editing story used to be pretty bad in the past). 
Facebook uses it _precisely because_ Git is utterly slow compared to hg. For Facebook's repo. I use git (via cinnabar) to interact with mozilla-central and git is also pretty slow here (hg does ok, usually). IME the staging area is a downside of Git. It's nice to have, but it's actually a lot of friction for newbies that doesn't need to exist. The ideal system would be something like mercurial that let you explicitly stage things at one point in time, but usually just commits stuff.
by the way, the current implementation in code: https://github.com/rust-lang/rust/pull/45905/files#diff-a7cb10d38695189cd9186f24c90e1634R464
No, as the SO post says, this requires explicitly annotating a function with the properties you intend to use. It does *not* give you the ability to later discover new properties about the function. In a dependently-typed language setting, this is not an issue: `double : N -&gt; N` exists independently. You do not need to explicitly annotate `double` with every imaginable property (i.e., `monotonic`, `even`, etc.), which would require Nostradamus-like foresight at the time of writing the `double` function.
It would make more sense if they were; unfortunately, it looks like they want to incrementally rewrite certain pieces of it in Rust, which I'm not optimistic about. Type systems give you *internal* consistency. If you're mixing a bunch of different languages together and have a large variety of FFI calls, a type system isn't going to help you much. Having a good type system for 20% of your code is like cleaning 20% of your hospital instruments.
Also important to note: Git is getting partial clone features where only a part of the blob set gets transmitted (right now you already have partial checkouts but all blobs get transmitted so it is not very useful).
&gt; It's nice to have, but it's actually a lot of friction for newbies that doesn't need to exist. I admit that view is popular, so it is even more important that I express my view that I like it :).
Well, if you go down that rabbit hole most things are just syntax suggar for things that can't be directly represented in asm. Plus C does have some ideas on what a boolean type should be, it just never formalizes it.
Because my server component will need an event loop at some point anyway and I wanted to use the "state of the art" library for async IO. It might be overkill for my use case but I figured it couldn't hurt to gain more experience with tokio.
No it's definitely google's fault that it doesn't give the results I want for searches like "rust diesel rocket" or "rust crate failure"! /s
I think it's more because Mercurial has a clear internal design, making it much more straightforward to change in the ways that Facebook needed. As I understand it, Git is sort of a hodge-podge of C and Perl and bash thrown together and with less internal layering/architecture, so that it's much harder to make large-scale changes to it. Also, some parts of Mercurial's design probably make it more amenable to the kinds of use cases Facebook has (per-file revlogs).
So, according to him the only reasons why Rust currently is not (yet) not suitable are compilation time and memory requiremtens on 32-bit systems?
To paraphrase some of answers given on /r/programming on the same topic: 1) No, rustc cannot compile rustc on a 32-bit platform (currently), because it runs out of memory addresses. You can however cross compile a 32-bit version of rustc on a 64-bit platform, making this issue mostly redundant, as you can use this compiler to compile whatever 32-bit binaries you need on your 32-bit system. It is only relevant in a case like BSD, where it is demanded that the software must be completely self-hosting on a given platform. 2) There exists the [uutils/coreutils](https://github.com/uutils/coreutils) project, which aims to reimplement the UNIX utilities in Rust. This project is not complete yet, but it does render Theo's assessment (that no such thing exists) inaccurate at least.
Rust compilation times are crazy high compared to most C software, comparable to some C++ software. It's all nice and dandy when you've got fast machine but have your ever tried compiling remotely complex Rust project? It can take hours, depending on a machine and crates project needs to compile. And if those dependency crates are complex themselves... well I've did it on such a machine and greatly prefer rust binaries. Compiling Rust is pain in the butt.
Is it possible for you to edit the submission title? If yes, please do. There is no reason it has to be all caps on reddit. Additionally, if you could find something more descriptive, that would be even better!
I highly doubt that any programmer is proficient in C or C++, or even in Ruby or Python! 
You are making your life needlesly complex. Use mio and keep your sanity.
&gt; you've just gotten used to it If so, I managed to get used to it in about an hour and find it an improvement over Mercurial, which I had been using for years before.
I disagree. Git for Windows got a major overhaul several years ago, and went from using an ancient version of MSYS to the much newer MSYS2. It's been in excellent shape for years, and is almost always up to date. At this point, it doesn't feel any more like a second citizen on Windows any more than Mercurial does.
Ludum Dare 40! - https://ldjam.com/events/ludum-dare/40/stackboxes source: https://github.com/fschutt/LudumDare40 [Current WIP screenshot](https://i.imgur.com/jtNv3NW.png) It's my first game jam (but not my first program). I started on Saturday, using glium (graphics) + cpal (sound). Sunday I worked on getting textures on the screen. Today I'm working more on the actual game, 13 hours to go! Not sure if I'll finish it, but I'll definitely report if I did. The game is simple: There are boxes / crates falling from the top of the screen, you have to catch them and put them on a stack. The white line represents the highscore, done by determining the highest stacked crate. If the stack tumbles / falls, you lose and get a game over screen. That's it, mostly. I am somewhat proud of the architecture of the game, I encourage everyone to look at the source. 
I'm writing a short tutorial on calling Rust code from Excel/VBA. There's a lot online about using C/C++/C# for this, but I couldn't find anything specific to Rust. Turn's out it's not too hard! First I wrote a small library that has some toy functions like "double this integer" and "divide these two floats" to get things working. Then I modified the [Sieve of Eratosthenes demo from Rayon](https://github.com/rayon-rs/rayon/blob/master/rayon-demo/src/sieve/mod.rs) to solve [Project Euler Problem 10](https://projecteuler.net/problem=10). It allows me to do something like this in Excel: Cell A1 = 2000000 Cell B1 = SumOfPrimes(A1) Solving the problem for 2 million is instantaneous. Solving for 20 billion takes about 5 seconds and uses all cores on my computer as well as nearly 10 GB of RAM. I also wrote a small crate that is like [libc](https://crates.io/crates/libc) for Excel VBA. It provides bindings according to [this page](https://msdn.microsoft.com/en-us/vba/language-reference-vba/articles/data-type-summary) for the different numeric types. Example: pub type Byte = u8; pub type Boolean = bool; pub type Integer = i16; pub type Long = i32; 
I will try to, yesterday was busy for me, but I should have time to read an article today
it's not possible to edit a submission title on Reddit, sadly.
I finished the semantic analyzer for [my implementation of the language Tiger](https://github.com/antoyo/tiger-rs/tree/master/tiger).
That'd probably be a good idea. You wouldn't have a link would you? I can't seem to find one, and there are like 4k forks of Rust.
I use it daily and have had zero problems.
I doubt that Rust will be included on OpenBSD in the forseeable future, for cultural and technical reasons. A big technical reason is that OpenBSD doesn't care about [breaking compatibility in minor versions](https://github.com/rust-lang/libc/issues/570). As far as culturally, obviously I don't know every OpenBSD developer, but from what I've seen on mailing lists and GitHub issues, they have some very vocal members who seem to think that if something is done differently than C, then it is wrong. I'd love to be proved wrong though.
We don't have the same definition of first class citizen, then. What I see is a Linux code base that is being ported to Windows by an independant group. And technologically, Git still depends on other Unix utilities and shells (provided by msys, as you said). That's clearly not first class citizen. I understand why it's like this. Last time I tried Git on Windows was indeed when they were not finished migrating to msys2, and they were multiple releases behind Linux Git. I remember messages warning me against running git from cmd, and I remember the pain to setup an ssh connection. This and a few crashes were enough for my company (we are a Linux and Windows dev company) to not choose Git.
Maybe you got a process problem if management has to deal with DVCS.
&gt; and the "convert" extension making it very easy to split repositories. While that looks like it might be a bit more comfortable than `git filter-branch`, what I really need is an interactive way to fine-tune things until everything looks right. I have so many Python repos where part of it could be split out into a library, other parts aren't ready to post (and may be private), and I'm unwilling to lose the history on the split-out part or awkwardly iterate on `git filter-branch` until I trust I've got everything I want included and excluded correctly. In fact, one of my back-burner projects is to develop a GUI tool for just that purpose... mostly just thinking about how it should work so far, but here's the current draft UI I've slapped together in Qt designer which would be built on top of PyQt and either [Dulwich](https://www.dulwich.io/docs/) or [GitPython](https://gitpython.readthedocs.io/en/stable/). https://imgur.com/tD9RIlY (It's all tuned for efficient keyboard use and the "Files to Commit" listing will allow selecting A, B, or discard for each folder or file, with each checkbox supporting a third state meaning "inherit state from an ancestor commit or, failing that, an ancestor in the current commit's folder tree.")
I remember de Raadt being outspoken in the past, but not like this. &gt; So rather than bothering to begin, you wrote an email. He's got some great points, so why does he have to resort to being so shitty? Even Torvalds managed to express these same criticisms much more politely if I recall correctly. This is really bothering me, so I'm going to put a fine point on it: if someone says something to the effect of "that is stupid" it's not polite, but it criticizes the idea. When someone says what de Raadt said above, it criticizes the person. It's more than just insulting, it's dishonest. Obviously the question was meant to figure out whether it was worth trying to satisfy this insufferable... individual, and what it would take to do so. But de Raadt's response paints it against a different intent entirely.
Ditto. The staging area is the #1 reason why I don't even consider Mercurial as an alternative to git.
It's still relying on whole a ported Unix env. Kinda like asking Linux people to use wine to run windows programs "natively".
I'm working on a tool for spidering websites, and retrieving all the source files used by the site. The current tool we use at work stores everything in some undocumented file format that is a combination of XML and base64 encoded strings. I'd like to be able to be able to store plaintext copies of the data so I can compare changes between security tests. I've been using hyper to make the requests, and things are going well so far.
That depends on how you layer things. I have a Python project I'm rewriting in Rust incrementally (with Python eventually being limited to serving as a QML for PyQt's QWidget API) and Rust's type system is very useful at providing internal consistency because of how I'm pushing outward from the starting points to eventually produce a solid, reusable core library and a frontend which just happens to be written in Python.
&gt; 2) There exists the uutils/coreutils project, which aims to reimplement the UNIX utilities in Rust. This project is not complete yet, but it does render Theo's assessment (that no such thing exists) inaccurate at least. Is it POSIX compliant?
Reddit lies, downvote counts aren't accurate. It will always show some downvotes, even if 100% of people have upvoted it. This is to confuse spammers.
Oups, sorry, forgot to give it. Here it is: https://github.com/steveklabnik/rustdoc
https://github.com/steveklabnik/rustdoc it is very much an experiment
&gt;We don't have the same definition of first class citizen, then. I suppose technically it isn't first-party support, but it's so good at this point that it might as well be. It's even being offered for download directly from the official Git site, so it's at least officially approved. &gt; Last time I tried Git on Windows was indeed when they were not finished migrating to msys2, and they were multiple releases behind Linux Git. I remember messages warning me against running git from cmd, and I remember the pain to setup an ssh connection. This and a few crashes were enough for my company (we are a Linux and Windows dev company) to not choose Git. I'm guessing this was a very long time ago then. Setting up an SSH connection was never a problem even before the MSYS2 update (I believe it was at 1.8 or 1.9 when I started using it), and I've never had any issues with it crashing either. The only issue used to be that the old MSYS utilities (notably bash) were incredibly ancient and didn't support some things that would have been useful in hooks we were using at the time, and required me to use some rather ugly workarounds. That's no longer the case since the MSYS2 upgrade, and also we are no longer using any local hooks.
Yeah, I saw that in the docs, felt a little "too magic" for me :)
I'm not sure what you mean by this.
My thanks. Hopefully RLS has an easier time with this; it didn't seem to like the Rust project much.
&gt; Is it POSIX compliant? What does this tell about Rust being suitable for such tools?
Hack? What hack? :D I posted the non-macro version to [the issue tracker](https://github.com/PistonDevelopers/dyon/issues/489). It's basically finding `main` and… doing the exact same thing Dyon would do when you create a current object inside of a Dyon script.
Mirage and includeOS
Well, I use a touchpad with evdev, but no experience programming a virtual one. The configuration parser here only supports keys for now, but I'll add other events too. Anyway, it won't be easier than libevdev, you'd be still emitting the same raw events from evscript…
This is true, but in practice it doesn't matter. If you're only using git, you don't need to deal with the other *nix utilities any more than you do with Mercurial, and if like me you're familiar with *nix tools, having them available on Windows is actually convenient and useful sometimes. Sure, if someone came up with an alternative DVCS that had all the nice features of git, such as easy branching and rebasing, staging, reflog, etc. etc. and happened to be written cleanly in a single systems programming language, completely free of any shell scripts, perl scripts, or other nastiness that required a unix-environment to run, I'd definitely give it a try, but as far as I know, such a tool does not exist yet.
I'm an amateur programmer and I'm learning Rust in my spare time. As a learning exercise I'm writing a short tutorial on calling Rust code from Excel VBA. There's a lot online about using C/C++/C# for this, but I couldn't find anything specific to Rust. Turn's out it's not too hard! First I wrote a small library that has some toy functions like "double this integer" and "divide these two floats" to get things working. Then I modified the [Sieve of Eratosthenes demo from Rayon](https://github.com/rayon-rs/rayon/blob/master/rayon-demo/src/sieve/mod.rs) to solve [Project Euler Problem 10](https://projecteuler.net/problem=10). Now in Excel I can do this: Cell A1 = 2000000 Cell B1 = SumOfPrimes(A1) Solving the problem for 2 million is instantaneous. Solving for 20 billion locks up Excel for about 5 seconds, uses all cores and about 10 GB of RAM. But it works! I also wrote a small crate that is like [libc](https://crates.io/crates/libc) for Excel VBA. It provides bindings according to [this page](https://msdn.microsoft.com/en-us/vba/language-reference-vba/articles/data-type-summary) for the different numeric types. Example: pub type Byte = u8; pub type Boolean = bool; pub type Integer = i16; pub type Long = i32; pub type LongLong = i64; pub type LongPtr = isize; pub type Single = f32; pub type Double = f64; This lets me rewrite code from: [#no_mangle] pub extern fn divide_floats(num: f64, denom: f64) -&gt; f64 { num / denom } to [#no_mangle] pub extern fn divide_floats(num: Double, denom: Double) -&gt; Double { num / denom } This makes the Rust code slightly less readable, but makes things much easier when linking to the .dll in VBA, since it looks like this: Private Declare PtrSafe Function divide_floats Lib "C:\rustlib.dll" (ByVal num As Double, ByVal denom As Double) as Double My next steps are to learn string handling, arrays of values, and custom structs (VBA structs are #[repr(C)] ), and then to write the whole thing up. My final goal is to publish a libvba crate that provides bindings to most (all?) of the VBA types with convenience functions for converting between types.
Thanks. I'll be having a look at that later.
&gt; Switching to Git was an enormous improvement in every way, and pretty much revolutionized the workflow by allowing quick and easy creation of branches. Sounds like you are not aware of Mercurial bookmarks. (In Mercurial core since 2011, before that available as a bundled extension.) They allow the same "revolutionary workflow" and are just as quick and easy to create as Git branches.
Those exact words aren't used in the README, but since it's a rewrite of the existing tools, I take it that should work as drop in replacements at least. So my guess would be "yes" (when it's complete at least), but we'll need to talk to the author to be sure.
Maybe I tried Git for Windows at the worst moment possible, with a broken version, I don't know. Does Git still warns you that it may be broken when it's run outside of bash ? 
It helps to think about where he's coming from. Maintainers of large open source software projects tend to get a lot of pushy suggestions / demands for work. People giving drive by opinions instead of rolling up their sleeves. It can be exhausting. Culturally, doing this is considered particularly poor taste in the OpenBSD community, which prides itself on being welcoming to and supportive of contributions, particular from new people. Yes, in this instance, Theo's comments come across poorly. But I don't imagine this is the first time he's gotten comments like this, and it can wear anyone down. We should all strive to be kind in our communications, but sometimes we're not, and I'm willing to cut Theo some slack here.
I've heard of them at a later, but I was not aware of them back when I was using Mercurial, so I don't know exactly how they work. Can you rebase or merge them as conveniently as git branches?
From a quick look at your messages it seems that your protocol does not multiplex transactions (that is, a request needs an answer before you can send a new request over the same connection). In this case, I would forgo `tokio_proto` in favor of using `tokio_core` directly. I would implement this via a connection type and two futures. The first future implements the process of connecting and resolves into the connection type (which basically just wraps the socket). That connection offers a method to start a new IPC request which actually consumes the connection value and returns a future for the IPC transaction. This future resolves into a pair of the IPC response and the connection value. If you want more complex things, such as a request queue, you can construct them on top of this basic construction. Personally, I would build these futures by hand using an enum and my own implementation of `Future::poll`, but using the combinators and then boxing the result is a reasonable choice as well. For the time being, you need to execute the future in the same thread as a reactor core (I think), so this needs some thinking about. The [currently ongoing effort to break up execution and event polling](https://github.com/tokio-rs/tokio-rfcs/pull/3) will make this a lot more simple, though. Which is the reason why I am holding off on rewriting [my own Tokio stuff](https://github.com/partim/domain#is-it-alive).
As far as I really appreciate this subreddit's focus on politeness in discussions, I don't think it's a good thing to judge how people outside the rust community express themselves in their own discussion places. Imho it's totally irrelevant to the point Theo De Raadt is making, and it might even be seen as arrogant, which is not good for the Rust community.
I've been using python-evdev to play around and try get something working as it's really easy for prototyping. There are docs for what events you have to emit so that's not a problem (I think), however just setting up a device as a touchpad that libinput recognizes is what I'm stuck on. Libinput relies on the touchpad having a prop set as "internal" or "external" however I've looked through the libevdev source and headers and can't find anywhere where you can set a string prop. It seems to come from some pre-configured hardware db which is kind of useless for a virtual device (libinput makes lots of assumptions based on the hardware manufacturer etc). If you haven't played around with this side of evdev, do you know where the best place is to ask about this? This is the first time I've actually touched any low level code like this so I don't really know what I'm doing XD.
Agreed about the staging area / index. As far as i can tell, all it does is require more typing, and encourage bad habits like partial commits.
I have rustup set in `~/misc/root/rustup-root` (`RUSTUP_HOME`) for its stuff and then I also have `~/misc/root/rustup` (`CARGO_HOME`) which contains the binaries which are rustup-aware. I have functions to help use these roots and enable them at need. Basically just set those paths in the environment and modify `PATH` and I can keep `rustup` out of `$HOME` and organized.
Yes, both the tone and the content of the email struck me as problematic. There's a bunch of statements that can be contradicted with a few google searches, like: There has been no attempt to [...] provide replacements for base POSIX utilities or The only things being written in these new languages are new web-facing applications, quite often proprietory [...]. Not Unix parts. which are preceded by I was stating a fact. Then there's the tone: &gt; This brings me to the question, what if someone actually bothered? So rather than bothering to begin, you wrote an email. Awesome. Dismissiveness and condesention are not only very dishonest ways to counter arguments, since they actually don't, but also very toxic in communities relying on contributions like open source. That's sure to turn away future (and current) contributers but also minorities who are already facing these sorts of attitude in general regarding there concerns, and are unlikely to put up with it for long. The third problem I felt was a certain lack of desire to evolve the project and active discouragement of such initiatives, which can spell the death of projects in the long term. Why would anyone bother? There is a rampant fiction that if you supply a new safer method everyone will use it. People should switch languages? DELUSION. I don't know how prevalent this is in the OpenBSD community, I sincerely hope for their sake this is an exception, and that if it's not they'll be able to address it sooner rather than later.
Nothing to do with Rust. Everything to do with Theo's argument.
Of course. But seems like a drop-in for GNU utils, which sometimes are not POSIX compliant.
 So rather than bothering to begin, you wrote an email. Awesome. I wouldn't stick around the OpenBSD community very long if people replied to me like that. If there are a certain number of questions that come back regularly, then a post or a web page should be written to answer these questions, and overly enthusiastic newcomers should be kindly redirected there. I'm thinking of how the rust community discourages the RIIR attitude for example.
Fwiw GNU coreutils aren't 100% POSIX either. This [issue](https://github.com/uutils/coreutils/issues/67) asks about POSIX compliance vs sticking to GNU quirks and it wasn't especially clear for the project creator &gt; IMO for now best-effort is good, but if the code can be made more correct with regard to windows line support or unicode then I think they should be. But this should definitely be thought through a bit more :) It was almost 4 years ago, and the initial creator isn't even working on the project yet, then it might be good to ask for an update on this.
I don't think I've seen that warning, so I assume not.
I can't remember that it ever did that, and I usually run it from a Windows console via ConEmu. If it did, that would have been a long time ago, at least before the MSYS2 upgrade. Like I said before, it was at 1.8 or 1.9 back when I started using it, so I don't know what state it was in before that.
&gt; 2) There exists the uutils/coreutils project, which aims to reimplement the UNIX utilities in Rust. This project is not complete yet, but it does render Theo's assessment (that no such thing exists) inaccurate at least. Wow, they're close!
Last week I wrote a [DXT encoder/decoder]( https://github.com/PistonDevelopers/image/pull/700), I'm planning to use that this week to implement the DDS file format. 
I understand your perspective; I also never really had any problem learning git, and I don't understand why so many people find it difficult. But I've personally seen the difficulty people have first-hand. I've lost count of the number of times I've had to draw a diagram to explain the difference between a merge and a rebase, or just the number of random questions I get. I'm hailed as "the git expert" just because I know a little more than how to commit and do a 3-way merge (and that I know the difference between a 3-way and a fast-forward). I think part of it is people not spending adequate time RTFM, but I can also see where people get confused. Git's flexibility is powerful, but that can also make it confusing.
You clearly haven't read the link in the OP, so here it is: &gt; Are they POSIX compliant? No. They are completely different programs that have borrowed the names. His argument isn't only about i386 rustc not being able to build rustc, but also about POSIX compliance.
Yes. And (stealing Rust terminology) "fearlessly".
I would like highlight [this](https://marc.info/?l=openbsd-misc&amp;m=151239514405129): &gt;Idiots who shouldn't be coding, coding. &gt;"safe" languages being trusted to be safe when in the hands of idiots. Like you said. &gt;The more I see of "safe" languages, the more I love assembly. Most people who call themselves programmers...shouldn't. Wow. Just wow.
You may be right, but I'm having a hard time understanding how developers, who presumably in most cases would be dealing with infinitely more complex tasks could have these problems. The basics of using a VCS, including such things as merge and rebase (which are also a thing in Mercurial) ought to be basic knowledge for any developer.
I get where you're coming from, but I'd much rather be cussed out than have my motives misrepresented. It's sick.
I can see that a lot of hard work went into writing this. It's very good! The only thing I would complain about is how every single line in the article starts with an Emoji or other symbol. This is way too loud in my opinion. &gt; Ok, I’ll stop the forth post "forth" should be "fourth". There were some other small mistakes, but it was very good overall! I also highly recommend using a more descriptive title for future blog posts.
Can someone assemble a list of Rust related discords please? Does such a list exist somewhere?
Yeah, I really don't get it either, for the same reason. But I've seen these same developers do pretty complex tasks, so I know they're competent. Even though it's hard for me to understand why, logic dictates that the common factor is git itself.
I'd argue that cleaning 20% of your instruments is better than cleaning none.
Did no one see the [accompanying video](https://www.youtube.com/watch?v=fYgG0ds2_UQ&amp;feature=youtu.be&amp;t=2112)? In it, he states that no one has made any attempts to write kernels, shells, and system utilities in a memory safe language. Yet Rust has the Redox kernel, Redox OS, Ion shell, Redox utils, uutils, fd, ripgrep, etc. When told that there were such attempts, he merely goes off on an overly-critical tirade about POSIXness of such projects -- completely disregarding the merits of using a memory safe language (or that uutils is a 1:1 MIT-licensed reimplementation of the GNU core utilities, which is POSIX + extra GNUness). [Relevant image](https://i.redd.it/2vrm9df5vgvz.jpg)
Oh, I messed up. For some reason (monday?) I read that as getting your managers to understand git within an hour (wat). Sorry. Anyway, my experience with git is that even after using it for years, without too much trouble, I'm still never confident with it when issuing anything else but the simplest commands. git reset will just clear the index, right? mmmkay... It always feels to me like I'm on the verge of doing something really stupid. I haven't developed an intuition to figure out a safe path from one state to the other, the granularity of the commands being just to fine. I feel most of the issue is that git's workflow is geared towards maintaining / merging patches (e.g. you're Linus), when what I'm mostly doing all day is writing code. I would like a tool that's a bit more prescriptive. Sure, I can script my most frequent operations, but then I get a custom system, when I would actually prefer to use the same commands as everybody else.
Mercurial doesn't handle monorepos much (any?) better than git. Facebook has written about heavily modifying mercurial to support their monorepo, but I haven't heard about any other large mercurial monorepos.
Just pushed a new update. Fixes argument parsing and text feedback.
The Ion shell that I've developed has about 15,000 lines of Rust within itself -- not counting dependencies, and it is in direct competition with C shells that contain 150,000 lines. It takes ~1-3 minutes to compile the first time, depending on how fast your processor is. Incremental compilation drops compile times majorly nowadays for subsequent builds.
My views are my own and not representative of the Rust community (otherwise I wouldn't bother posting them in Rust fora.) I'm not sure how it's arrogant to criticize that kind of behaviour. Every workplace I've had with someone acting like that has been toxic, and all the ones with a boss who talked like that now have zero employees.
and how to do that on linux?
&gt; "forth" should be "fourth" Fixed, Thanks :) 
Last week I put aside my Rust lldb work for a bit, in order to fix up the DWARF output for enums -- this needed some attention after the enum optimizations landed a few weeks back. I've got an LLVM patch to enable emission of the needed DWARF construct, and most of the Rust compiler patch.
Theo de Raadt was, is and probably ever will be a difficult human being to interact with. Hell that was one of the reasons OpenBSD even exists (he got "kicked" from NetBSD after allegedly being quite an asshole to other developers).
It seems like all they really want is: * Performance * Memory safety * Good cross-platform and cross-language support They may not get the full advantages of Rust but it seems like a good tool for the job.
Now I'm remembering when an inchoate Rust first showed up on LtU. That little language sure did grow up! It used to be "that language with typestate" to me but now I use Rust all the time and I haven't thought about typestate in years.
Oh, I didn't realize. I figured the original implementations were basically the standard, warts and all.
I had similar pains growing out a large Python codebase for my last job. The lack of strong typing was frustrating on the Python side and dropping down to C was something I never did because I C code is very hard to write correctly and to maintain, especially given the software devs I was working with. These seems like a reasonable path forward for Mercurial. Since they have tools that are already pretty modular and decoupled, a lot of the work will be just getting the data types defined, which it looks like FB has already done. If this project moves forwards and succeeds we're definitely in a movement towards more compiler checking being desirable in languages.
https://doc.rust-lang.org/stable/book/second-edition/ch09-00-error-handling.html
In my experience the bulk of Rust compile time is spent within LLVM, and that time is roughly proportional to number of lines of IR handed to LLVM. Disclaimer: not always the case but hopefully this is helpful anyway. This Cargo subcommand was helpful to me recently in tracking down two large improvements in serde_json compile time [(1)](https://github.com/serde-rs/json/pull/388) [(2)](https://github.com/serde-rs/json/pull/389) by revealing which functions contributed most of the IR or were instantiated more than expected.
They're close to [the first](https://en.wikipedia.org/wiki/Ninety-ninety_rule) 90% ;) (I do think it's an admirable project, but coreutils is seriously battle testes).
**Ninety-ninety rule** In computer programming and software engineering, the ninety-ninety rule is a humorous aphorism that states: The first 90 percent of the code accounts for the first 90 percent of the development time. The remaining 10 percent of the code accounts for the other 90 percent of the development time. This adds up to 180% in a wry allusion to the notoriety of software development projects significantly over-running their schedules (see software development effort estimation). It expresses both the rough allocation of time to easy and hard portions of a programming project and the cause of the lateness of many projects as failure to anticipate the hard parts. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
There also exist [Redox's coreutils](https://github.com/redox-os/coreutils) which are actually based on BSD coreutils instead of the GNU ones; that should be kosher with Theo. Of course, they surely are neither complete nor 100% POSIX compliant at the moment. But so what? Theo's claim, which he stated literally as fact, was that "There has been no attempt to move the smallest parts of the ecosystem, to provide replacements for base POSIX utilities". **That's patently false**, a simple Google search would have shown him otherwise. For me that renders his whole response as a rude rant from someone who makes big generalizations about things he doesn't know much about. What really alarms me is seeing security minded people so casually and ignorantly discarding a language that could offer real gains in security without compromising performance. The compilation in 32-bit platform issue, while real, is hardly a reason to deny altogether the opportunities that improving and including Rust code in their codebase could provide. I expected better from the OpenBSD folks. 
No? We've been using Git on Windows for 6 years now and I don't think anybody at the office has ever seen such a message.
So I guess I'm not a programmer. I'm just a guy who wants to get shit done.
I'll have to remember this - it looks really useful! It would be good to use it to generate and track the metrics for some big rust projects across multiple versions of the compiler.
Better to have a solution than to not have a solution at all.
I'll post this here as I'm sure it'll get swallowed up by negativity in /r/programming: Nothing is stopping you from forking and introducing whatever you want, just because someone says, "no" doesn't mean it's the end of the line. I personally think it'd be a cool project and if it works, more power to you and you might have an actual argument on your hands. I'd contribute and say it's the future of safety, because it is, but OpenBSD does a lot of good things with what they have and they know how to work their process, hence the resistance, because it's an awful lot of work and they most likely have other goals they'd like to meet, rather than just rewriting everything. If anyone wants to form a group dedicated to a decent BSD base (OpenBSD) and pushing Rust as the main OS language, I'd happily contribute and help, but because someone has different goals or an idea about how to reach an end goal doesn't mean they're wrong, even if they're an asshole, it's your job to prove it.
I am surprised not to see a link to the Haskell library with the same name. http://hackage.haskell.org/package/criterion
Will Rust ever bundle crosscompilation the way Go does? Honestly that’s my favorite feature, saves so much bother compared to manually configuring toolchains.
He's clearly aware of at least some ports, he mentions them later in the same post. His problem there seems to be that they're not POSIX compliant, not that there are no similar tools at all. The rest of his post also makes some really strong points. I don't think it's fair to dismiss his response as "as rude rant" or because "he doesn't know much about" Rust.
...and comparable BSD tools take on the order of seconds, not minutes.
Interesting, back there in 2014 an user was able to replicate closely enough any popular Git workflow in Mercurial — the phases were there since 2012, bookmarks were just merged to the core, being shipped with Mercurial since 2010. Were you aware of these back then? &gt; the fact that Mercurial tracks renames Wow, that's puzzling. I mean, really, the means to keep your history accurate, the way to actually write down what happened exactly — a downside? Could you elaborate?
I haven't experienced how simply Go does it, but I know cross-compiling pure-rust projects is pretty simple. Here's an example of what I'd do to cross compile from linux/mac to windows: # download standard library for target rustup target add i686-pc-windows-gnu # build - target binaries in target/i686-pc-windows-gnu/ cargo build --target i686-pc-windows-gnu The caveat is that this only works for _pure_ rust projects. If you want to build anything which depends on C or C++ libraries that are also normally compiled as part of the build process, you'll need to install a C cross-compiler as well. I don't know if/when this will ever be simplified, simply because there isn't a better way to cross compile C dependencies, then, well, to cross-compile them using a special build of gcc or other compiler.
From the article: &gt;“Master,” said the novice, “what is the nature of long and short options for commands? I thought they were equivalent, but when that developer used -h you said something different than when I said --help.” &gt; “Perspective is everything,” answered the Master. &gt; The novice was puzzled. She decided to experiment and said “git -h branch”. &gt; Master Git turned and threw himself off the railing, falling to his death on the rocks below. This masterpiece belongs in a museum
Is there any current plan to allow macros in ident position? Or is that dependent on macros 2.0?
Are you saying something like "hey, you're dealing complex problems on daily basis, sure you wouldn't mind tackling another one supposedly less complex (or not, you never know for sure) while publishing your output, would you?"
&gt; (and even so, it will be complex to upgrade your compiler and sync with everyone else). Unless you always receive modules as source, and ship a Rust compiler with your game.
* In Rust: polishing up a toy handwriting recognition library. I say 'toy' because it's not a very good recognizer (1-layer feed-forward). It _is_ a cool showcase for some nifty techniques, like: - using nalgebra for insane performance and safety - build-time training and everything that entails (including non-code assets, build.rs, sharing code between build script and library, etc.) * Not (yet) in Rust: I'm using my department's cluster to perform _massive_ faceoffs between student-authored test suites and student-authored implementations for programming assignments. Consuming sixty hours of computing time in twenty minutes is my new guilty pleasure!
Do you have an example BSD tool that's 150,000 lines of code and compiles within seconds?
Judging by this [video](https://www.youtube.com/watch?v=fYgG0ds2_UQ&amp;feature=youtu.be&amp;t=2112) I wouldn't say he *was* aware about Redox or core utils ports at all. To me POSIX compliance rant looks more like attempt to hide the fact that he was talking about things he does not know much. Yes, his post has several valid points, but still it does not change the fact above.
As far as I'm aware there are no plans to allow macros in ident positions, even with macros 2.0
FWIW, I think using Tokio is far easier than using mio directly. Mio is a very low level abstraction over epoll, etc. Tokio provides a much easier and higher level API, with things like `TcpStream` that make async reads and writes much easier to manage.
Perhaps an easier comparison (what I'm going on) would be the grep compile times cited in Theo's post? They're about half a second. No Rust grep replacement I've ever seen has compiled that fast. This isn't exactly controversial. Rust is currently much slower to compile than C, and that's a legitimate reason not to use it. That is improving and I hope it continues to do so, but being confrontational about it is worse than useless.
He didn't actually call people using "safe" languages idiots. He only pointed out that Java (and other gc languages) shouldn't be falsely seen as memory safe (they aren't). He didn't even say anything insulting or controversial imo.
I liked that in other comments this has been named the "True POSIX compliant" fallacy. Both projects mentioned by /u/KasMA1990 and me have some degree of compliance. I cannot state how much because I truly don't know, but it's unrealistic to expect 100% POSIX compliance to even consider something as a replacement. I bet that they started using their version grep even when it wasn't 100% ready for the things that it could do and advanced in their usage as it matured. And take this into consideration: OpenBSD isn't certified as POSIX compliant by the IEEE, so as far as we know not even them meet their standards. I get the impression that Theo doesn't know anything about the projects mentioned here, and he's just using this POSIX compliance thing as a quick way to be dismissive of them. And now I ask you: which are his really strong points? That "base builds base" is a requirement that they have imposed on themselves, as well as short compilation times. Both things are understandable from a project management point of view; however in the case of Rust both are solvable. The thing that I find deeply disappointing in him is that he's rejecting a very capable language well aligned with the core value of his project (security) because of some solvable technicalities. Rust could improve OpenBSD's security even farther than it is today, but he flatly dismissed that in the name of some UNIX purity that I found surprising to say the least, coming from him. The reply I expected from him was something like: "Rust seems interesting from a security standpoint, but we consider that the ecosystem is not there yet and there are a couple of technical issues with 32-bit compilation and the speed of compilation that make it impossible to include it in our project at the moment. We will reconsider if those things change". Was that so hard? That's polite and answers what was asked. Instead we got this BS about POSIX compliance.
&gt; FWIW, I think using Tokio is far easier than using mio directly. We have a Tokio question thread every couple of days with people confused how to use it. Tokio is a solution that is way more complicated then the problem. &gt; Mio is a very low level abstraction over epoll, etc. Which means your hands are free to solve your problem. While using mio you are making steady progress constantly, because you are not working with one hand tied behind your back trying to interpret your problem in terms of a framework. Frameworks make easy things easier and difficult things even more difficult. By definition they optimize for a narrow path of execution. Building software out of easy to understand and easy to combine building blocks is a tried and true method. 
So I've been a bit lax recently but I'm hoping to make some progress in [tarpaulin](https://github.com/xd009642/tarpaulin). Raised an issue in the rust compiler because link dead codes behaviour has changed in beta which means tarpaulin doesn't work properly! So I'll be following that issue and potentially reacting if anything has to change my end. Aside from that there are some issues I'd like to make some headway in. I don't think I'll be able to dedicate enough time to branch/condition coverage in the following fortnight so going to keep it to smaller issues. 
The "commit phase" [concept](https://www.mercurial-scm.org/wiki/Phases) (Mercurial has them for almost 6 years already, Git doesn't and probably never will, considering the appropriate GSoC proposal didn't gain enough traction) enables user to rewrite history in a much safer manner. In short, it keeps track for which commits have been "published" and acts as circuit breaker when you accidentally trying to rewrite published ones. Git, true, says `non-fast-forward merge, try -f` (which BTW is a gibberish to a first-timer), but only _after_ you've carefully rewritten shared history and are trying to push it! But there's more: the in-development, but already usable enough [`evolve` extension](https://www.mercurial-scm.org/doc/evolution/) enables multiple user to rewrite same history in a safe manner; absolute most divergences are automagically got away of with single `hg evolve` invocation. There's nothing like that in Git (there's reflog but it is _local-only_ and thus not distributed).
&gt; He didn't actually call people using "safe" languages idiots. And I didn't meant that he did, my point is that his message is quintessence of fallacy and arrogance, which showcases bad soil for introducing Rust into such environment. &gt;He only pointed out that Java (and other gc languages) shouldn't be falsely seen as memory safe (they aren't). No, he assumed that everyone sees "safety" as a silver bullet which will protect against stupidity of coders, and of course we don't have languages with such "safety". But surprise, I haven't seen anyone who would seriously understand (memory) "safety" of the language in such way. So it's not only poor anecdotal evidence, but also essentially a strawman argument.
What are you saying? The person you are replying to listed that as "one of the few advantages of" Hg.
&gt; It is only relevant in a case like BSD, where it is demanded that the software must be completely self-hosting on a given platform. I think most Linux distros also self-host their builds. In Fedora I had to disable rustc debuginfo for ARM ([rust#45854](https://github.com/rust-lang/rust/issues/45854)), and while i686 seems OK for rustc *so far*, I have [rhbz1520079](https://bugzilla.redhat.com/show_bug.cgi?id=1520079) reporting exhausted memory compiling other crates.
It makes it really easy to split up a huge change into logical commits. Of course, it is up to the user to split the change properly. A hammer isn't bad because you can hit your fingers with it. Maybe this is possible some other way in Hg, but that is one benefit of Git's staging area.
Don't forget fearless concurrency too!
I attempted the ludumdare again. Didn't really finish or get anywhere but I tried. https://ldjam.com/events/ludum-dare/40/dungeon-run Compiled to wasm (emscripten backend not the new one) so it would be playable in the browser.
Oh. It makes sense now. I honestly thought "the main ones" was a reference to disadvantages. Not a native speaker, sorry
How is Java not memory-safe? AFAIK there might be some memory unsafety around its memory model in the face of concurrency/atomics, but last I heard this was mostly theoretical.
JVM enforces memory "safety" at run-time but nothing in the Java language itself prevents me from compiling code that leads to null pointer exceptions. Sure, null pointer exceptions and array out-of-bounds exceptions aren't segfaults, but I don't see how this helps anybody.
Libinput doesn't make "a lot" of assumptions. A quick search in the libinput codebase reveals that the only vendor check is for Apple touchpad buttons. And the internal flag seems to be this: `tp_is_internal = bus_tp != BUS_USB &amp;&amp; bus_tp != BUS_BLUETOOTH;`
That helps A LOT in the context of security. It is also allowed without breaking memory safety. How is Java not memory safe?
That was actually my favorite part. Installing git is the least painful way to get a good, if basic, command line environment on windows.
I'll plug [Philipp Oppermann's blog](https://os.phil-opp.com/) as it was integral to getting me started on my own rust kernel
NPE and AIOOB are not memory unsafety. They have clearly-defined, safe behavior (although that behavior is "throw an exception" and often as an immediate consequence "crash the thread"). Barring JVM implementation bugs (note that the JVM is a complicated beast; it's a safe bet there are bugs in it) or unsoundness in the type system (AFAIK it hasn't been fully formalized and checked), it is impossible in Java to accidentally read, write or execute arbitrary memory.
Correct me if I am wrong, but it is the JVM that provides safety. "javac" in itself doesn't produce any magic code. If you could compile C to JVM bytecode, it would be safe as well.
Well said sir! Out of mod points, or I'd mod you up!
The PartialEq derive for big enums is very dangerous. 
You are right and I will retract the word memory from my first comment.
Thanks, great talk!
Not an expert but I don’t think so. Accessing/modifying a stack allocated array without bound checking could potentially leak info. Also, since in C there is no notion of “reference counter” if you just pass pointer around as a number, garbage collection is not possible.
I think that you're missing some of the context from the [video](https://www.youtube.com/watch?v=fYgG0ds2_UQ&amp;feature=youtu.be&amp;t=2112), as well as missing a little bit of Theo's frustration as a free software maintainer who's being asked a fairly general question about "would you accept X" without specifics and without accounting for how much extra work X would take. In the video, someone asked "how about memory safe languages, because I don't think that ASLR will ever become watertight." With some back and forth, the questioner mentioned `ripgrep`, and Theo asked if it was a POSIX compliant `grep`. And Theo is not necessarily asking about to the letter POSIX compliance, but "will this be a drop in replacement that existing shell scripts can use, and it won't break the whole ecosystem." And `ripgrep` is not that. So Theo goes on to talk about how the question about memory-safe languages doesn't really make sense until someone actually does the work to write compatible versions of all of the existing tools in those memory safe languages. And he goes on to talk about how memory-safe languages aren't a cure-all, since there will still occasionally be unsafe code, calls out to C code, etc, so you still need all of the other mitigations as well. In this thread, someone asks (not bringing up Rust), "what if such POSIX compliant memory safe reimplementations existed? what would be the requirement to get them integrated?" Theo was clearly a little frustrated at being asked a what-if question rather than having someone actually make a proposal ("So rather than bothering to begin, you wrote an email. Awesome.") The thing is, as a maintainer, it can sometimes be hard to answer such an abstract question; it is a lot easier to respond to a specific proposal. But then he does go into some of the things that might prevent replacing large parts of the core system with alternate implementations in other languages; such as compile time, compilation address space requirements, toolchain complexity, and the like. The rules about being able to self-host compilation don't come from a vacuum. Many distros do self-hosting rather than cross compilation, and have requirements that you be able to do so; OpenBSD isn't unique in this regard. Many packages don't work well with cross compilation due to having poorly written configure scripts or other assumptions that don't work in a cross compiled environment, cross compilation complicates testing infrastructure as you need to separate the build from testing, and for a general purpose computer running a free operating system, which i386 is, you should be able to download the source of a package, modify it, build it, and run the modified version. I think that the reason he's being so dismissive is that some people act as if rewriting in Rust is an obvious solution and why aren't you spending all of your time doing it, and so it's easy to get frustrated that they are dismissing the work he is doing and discounting how much it would take to do this.
Probably, it is worth to note that Google is also trying to [use hg](https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext) as an DVCS interface for their monorepo. I am not in a position to say much about it, but the rationale of using it instead of git is similar to FB's.
Nothing is 100% POSIX compliant anymore. Some of the POSIX _standards_ are just backwards and actively harm performance. For example the most recent POSIX requires `dd` have a default `-bs` (block size) of 256bytes, even GNU violates as their default is `16KiB`
Wonderful stuff. Personally as someone who is an SRE I have been working now primarily in Rust (started playing around pre 1.0) and finding it a home within our tooling.
Wow!! N u are a amateur programmer...
Thanks to you and others for the pointer to `uutils`. I'd just been wishing for such a thing given the recent Debian `ls` fiasco; I'll probably put some energy into helping out with the project. It looks pretty awesome.
I have been working on Falcon https://github.com/falconre/falcon . I have a few last things to polish and I’m hoping to release 0.2.1 this week, in time for a talk at Rust DC next week! I’ve been using rust about six months now, so I should probably do a post on my experiences and thoughts so far.
Rewriting my older systemd-manager GTK3 application at the moment, with a screenshot referenced below[1]. Unsure when I'll be finished with it, but I'll get back to writing my Rust GTK tutorial series shortly after that. May also have a new release of the Ion shell soon. And I need to plan for a rewrite of my parallel application. [1] https://i.imgur.com/EPQm3co.png
I am quite certain there is a record of Mercurial developers acknowledging that tracking file renames was a design mistake and Git's approach is more sensible. It's completely impossible to find in a sea of "how do I" false-positives, of course.
&gt; Installing git To get good, if basic, command line environment on windows, I've been using [GOW](https://github.com/bmatzelle/gow/wiki). Just in case it can be useful to someone !
I'm not saying it's good or bad. I'm pointing out it is one of Theo's arguments right there in the OP link.
That was really fascinating to watch! The lighting and shadowing looks amazing. Thanks for sharing. What sort of FPS do you get with it?
It would be much appreciated if you try to write your network in CNTK (https://crates.io/crates/cntk), to give some testing to the bindings.
I believe it's the _reddit_ title that's bad, not Medium's. Generally Reddit post titles in this subreddit should at least tell someone what the topic's about (rust is obvious from the subreddit). In future: it doesn't have to be the exact same as the Medium (or other site) title if that title isn't descriptive.
I'd agree with you in all parts but the second to last. Tokio in particular made building simple things _much harder_ for me than mio, but it made composing different parts together much easier. I'd say mio is great for simple projects but if you want to build a larger application tokio is going to make the code much simpler.
You want /r/playrust :)
/r/playrustservers
I think it is time for a security minded distro that doesn't attempt to overly compatible with the past. Between containerization and safe languages, Linux or FreeBSD could be very usable AND be secure out of the box. OpenBSD can have the 80s Unix running on i386 niche to themselves.
Oh thanks I’m sorry. I’m new to reddit tbh and still learning :). Thanks though 
In bash and friends you use `export RUST_BACKTRACE=1`
Incremental rewrites makes it a lot easier to say, five years down the line or whatever, "hey let's get rid of the last few bits of Python". A full blown rewrite from the ground up would be a hard sell.
JVM bytecode is memory safe, but if you wanted to run "all of C" on the JVM, you'd have to create a memory abstraction within the JVM that would allow for such things... Indeed, the JRuby/Truffle people are doing such things for support of C extensions: http://chrisseaton.com/rubytruffle/cext/
Thanks for this! It's going to save me some headaches.
Hey! I'm an engineer working on a software development framework for embedded devices (cubesats) running Linux. The majority of embedded software these days is still written in C. After looking at Rust over the past year we have decided to start writing small components to test the waters. Our architecture is a distributed set of processes communicating via GraphQL/HTTP and D-Bus, so bringing in other languages on a per-process basis isn't a big deal. I'm currently wrapping up an example implementation of a subsystem (hardware) handler. It will essentially serve as a GraphQL-based abstraction for a hardware device. Anyone interested can take a look at the PR [here](https://github.com/kubostech/kubos/pull/217). Looking forward to learning and writing more Rust!
Thanks this is really useful.
It looks like [this](https://github.com/media-io/rs_mpegts) can parse them ([crates.io](https://crates.io/crates/mpegts)).
Isn't that just a function that returns an iterator? 
&gt;The PartialEq derive for big enums is very dangerous. Could you explain this comment? Sorry, I just sub here and don't really write rust, and I can't find PartialEq mentioned in any of the referenced links.
Working through this was pretty cool: https://os.phil-opp.com Also you can download the linux staging kernel, follow it's development through the Linux kernel mailing list, and hack around on your own. If you have as much experience as you say you do the lkml (although not specific to Rust) could be an excellent learning resource. You can get started with all that here: https://kernelnewbies.org
Fiasco? What happened?
They actually don’t, this is off topic there too :)
Did you track these down by pointing this at serde itself? Or a library using serde?
I can't seem to get this to work. I'm interested in pointing this at Diesel (though most of our compile time comes from the item body checking pass it seems). When pointing at Diesel, I just see `ptr::drop_in_place`. When pointing at crates.io which should have much more, I see [~/builds/crates.io] cargo llvm-lines --lib | head -20 Compiling cargo-registry v0.2.2 (file:///Users/sean/builds/crates.io) warning: ignoring emit path because multiple .ll files were produced Finished dev [unoptimized + debuginfo] target(s) in 28.89 secs 34164 1679 core::ptr::drop_in_place 1859 160 core::ops::function::FnOnce::call_once 221 12 core::clone::Clone::clone 178 13 core::ops::function::FnMut::call_mut
Eeeeh I don't know about that. I'd rather not have applications, websites and services that are horribly insecure and leak private data like it's no big deal.
Is getting? Isn't that just a shallow clone, which it has had for a while (although they became much more useful witth "unshallowing" not too long ago)?
Well, when you say BSD specify which one. Half of rust compile time is bundled LLVM. FreeBSD compiles the very same LLVM plus clang (ok, not the same, yours has SIMD patches) and it's not updated that often. OpenBSD, I believe, switched to that combo as well. In that scenario, rust doesn't take _that_ much to compile. On my machine, in a single thread, it takes an hour to compile llvm + rust and an hour to compile Firefox. Good luck compiling GCC &gt;6 on i386. One of my build slaves couldn't even _extract_ source code from the archive without catching OOM. 
It depends on the individual of course, but in my case it really helped to get into Rust first, and learning the intrinsic details of system programming (memory management, performance-oriented programming, etc) in the context of a modern language that does not allow one to mess up badly without noticing. After that, you automatically become a better C/C++ programmer as well, and can also more easily get into the details of those languages.
In rust, you can derive certain traits, like Debug and PartialEq. It's done like this: #[derive(PartialEq, Debug)] struct Vec2f { x: f32, y: f32 } PartialEq automatically generates code that allows you to use the '&lt;', '&gt;', etc. symbols with your struct or enum. 
Theo is a perfect example and explanation of why no one except for 3.5 people needs OpenBSD today. There are a lot of good projects spawned from it, but itself...
I want to do work on my MK20DX256 chip support crate, but most likely won't have time. Instead I will just do this year's [Advent of Code](http://adventofcode.com) in Rust.
Any plans to record this for people not in the area? :)
Sadly I don't think we usually have access to recording equipment, sorry!
Sorry I have not figured out what the problem is yet, but I am tracking this bug in [dtolnay/cargo-llvm-lines#4](https://github.com/dtolnay/cargo-llvm-lines/issues/4). Would appreciate help debugging from anyone else running into this!
Any way to avoid the .map call on this code? while let Some(c @ 'a' ... 'z') = reader.check_ahead(0).map(|c| *c)
The serde_json improvements were from pointing the tool at the [`json-benchmark`](https://github.com/serde-rs/json-benchmark) repo. Running on serde itself was not helpful because so much of it is generic that nothing really gets instantiated until a concrete data structure and a concrete data format are interacting with each other.
Looks to me like [POSIX](http://pubs.opengroup.org/onlinepubs/009695399/utilities/dd.html) and [GNU](http://git.savannah.gnu.org/cgit/coreutils.git/tree/src/dd.c#n97) agree on 512. Also, many GNU utilities which differ from POSIX offer a `POSIXLY_CORRECT` environment variable to switch them to POSIX mode.
&gt; I think it is time Exactly Theo's point. It's all well and good to think it's time; show us the code.
&gt; So, according to him the only reasons why Rust currently is not (yet) suitable are compilation time of the Rust toolchain and memory requirements during compilation on 32-bit systems? He's saying it's not yet suitable because no one has yet put the work in to make it suitable. Those are some of the hurdles he can think of off the top of his head; there are likely more. For a start, [here's a list of OpenBSD's supported platforms](https://www.openbsd.org/plat.html), and note that "Official support means that the release install media is known to work, that the architecture can self-compile itself, and that most of the basic tools exist on the architecture." I don't believe that LLVM has an SH4 target, for instance. It will take a lot of dedicated work before Rust is considered acceptable to build core OpenBSD tools in, and someone has to write the implementations of those tools in Rust. What he's also saying it's not a silver bullet (which is true, it's not). You still need to work on things like ASLR, `pledge`, and so on, both for mitigating problems in existing C code, and for Rust code as Rust code may link to C code, may use `unsafe`, there may be soundness holes in the compiler that turn out to be exploitable, etc.
Well, I've now had a look. Unfortunately, I wasn't able to get it rendering any output. I ran a webserver with the output, but I couldn't get any browsers to load the JS files because the checksums were wrong. I saw the issue open about blank rendering, so I'll look into it closer tomorrow, and add to that. In the meantime, I decided to hack at the existing version to see how hard it would be to alter that. After seeing the embedded HTML, I can't say I had high hopes, so I was surprised at how easy it was to figure things out. It only took me about 3 hours to make it [do this](https://i.imgur.com/Jryr2zN.png).
Once `impl Trait` lands in stable, the best thing to do will simply be a function returning `impl Iterator&lt;Item=TheType&gt;`. Before then, I'd recommend just doing an iterator and returning `Box&lt;Iterator&lt;Item=XXX&gt;&gt;`. If you need more performance and aren't on nightly already, it can sometimes also be feasible to create a new structure which stores state manually and implements Iterator, and to return that.
Don't downplay the documentation. It will take a lot of effort to write well but unlike code clean up will be visible to everyone. 
Everything seems pretty good, the one thing I'd change to make this more "rusty" is to ensure every method a user can use on your struct can only be used if the struct is in a valid state. Is it alright, for example, if I call `ip_proxy` multiple times? What is valid for me to write to the underlying socket before and after I call a `*_proxy` method? If this was a rust library, these are things I'd expect to either be encoded into the structure types, or documented fairly clearly. Of course, if this is for internal use, that's not necessary - but it can still be nice to have. The other thing is that because all of `TorClient`'s fields are `pub`, it's possible for a user of the struct to manually construct one from any TcpStream. From the documentation, it's not 100% clear if this is a valid use of `TorClient` or not. I guess that if I were looking at this as a rust library, I'd be certain what each _method_ did, but I'd really have no idea what `TorClient` represents. It doesn't seem to guarantee any state besides _any TcpStream_, and it doesn't seem like any state is really necessary to call any of the methods either. If I can construct a `TorClient` with anything, use any methods on it at any state, and it's just a `TcpStream`, why not just have the methods as functions operating on a `TcpStream`? I mean, I'm not suggesting that you should get rid of the structure. If you would want to make this into a better abstraction for an API though, you'd probably want to restrict usage of it more, and probably introduce different structures to represent different states of the protocol negotiation? ---- Given all that, I'd say all the code was very well written. If this were internal to a binary or a non-exposed part of a library, it'd be totally good. In addition, the errors are on point! Besides that a bit of abstraction missing from the `TorClient` structure, everything I see is pretty excellent.
Can anyone recommend a cheap (sub-$100) mini-stx form factor or smaller with tier 1 support (https://forge.rust-lang.org/platform-support.html)? I was going to use a pi but would like tier 1 support.
I'm working on a multiplayer space combat game where you build spaceships out of modules, inspired in part by [Captain Forever](http://captainforever.com/). Multiplayer isn't implemented yet but most of the other gameplay works (but the game isn't public yet). It's compiled to wasm and uses WebGL. Screenshot: https://i.imgur.com/64s0uwo.png
On my 5 years old mid-high range PC, the fps drops below 60 only when I have a 4x larger area totally filled with plants. Updates are done asynchronously and take a bit longer. At the end of this video the update rate was below 1Hz. I've optimized it a lot in the meantime, though, so it's faster now.
Man, the Boston Rust meetups are always on days when I'm not in Boston any more (I'm in Boston every other Monday through Wednesday, but Wednesday evening is when I'm traveling home).
Excellent. One thing that I like to do when looking at a crate's 1.0 release is to see how many dependencies it has at 0.x still: bigdecimal ^0.0.10 optional chrono ^0.4 optional clippy = 0.0.174 optional ipnetwork ^0.12.2 optional libc ^0.2.0 optional libsqlite3-sys &gt;= 0.8.0, &lt; 0.9.0 optional mysqlclient-sys &gt;= 0.1.0, &lt; 0.3.0 optional num-bigint ^0.1.41 optional num-integer ^0.1.32 optional num-traits ^0.1.35 optional pq-sys &gt;= 0.3.0, &lt; 0.5.0 optional quickcheck ^0.4 optional time ^0.1 optional uuid &gt;= 0.2.0, &lt; 0.6.0 optional On the bright side it looks like all of these are optional, though I can't say how optional each is in practice. I'm curious how many of these are on the track to stability; libc is, though I don't know about any of the others. It looks like the time crate is only used for the "deprecated-time" feature, presumably, shouldn't this be going away before 1.0?
We could try and schedule the next one on a Tuesday, how does January 16th sound?
Was documentation downplayed? That was very much not the intention. Docs are the release blocker for a reason. 
This is awesome! Thank you so much! Probably the best way I was ever sold on a new tool that at first looked like I had not use case for it.
You should do a Boston meetup where everyone in Boston flies out to SF and then do the meetup here instead &gt;_&gt;
dperecated-time refers to the crate time which lives under the rust-lang-deprecated org. Our support for it isn't deprecated, but I couldn't come up with a better feature name. Chrono is probably the most concerning here, TBH I'm not sure why they aren't on the path to 1.0. I have considered putting all these features behind an additional "unstable" feature, but that feels like it doesn't really help much other than allowing us to say "but we told you it was unstable". Even so, due to the additve nature of cargo features, it's easy for someone to accidentally depend on an unstable feature. So I'm not sure what to do about this problem. Rust clearly has a 1.0-phobia issue, but Diesel is ready to stabilize it's API, and doing so will be huge for Diesel and for Rust. I don't see value in delaying that because libraries which we optionally support are afraid to stabilize their API. I guess when Chrono releases a breaking change we'll have to deal with it. :/
Oh I should also mention that mysqlclient-sys and pq-sys will get a 1.0 release alongside Diesel so that's at least 2 off the list
I've been working on on a [crate](https://github.com/forrest-marshall/serde-hex) for easy and highly-configurable hexadecimal serialization/deserialization with serde. It allows you to do nifty stuff like this out of the box: ``` #[derive(Serialize,Deserialize)] struct Foo { #[serde(with = "SerHex::&lt;StrictPfx&gt;")] bar: [u8;4], #[serde(with = "SerHex::&lt;CompactPfx&gt;")] bin: u64 } ``` The `bar` field will be serialized with full left-padding and the `0x` prefix. The `bin` field will be serialized in its most compact possible representation. I've been using this project as an exercise to improve my Rust API design, so I've been experimenting with different methods of providing useful generic impls and helper macros. Among other things, this project has convinced me that type-level numerics are going to be awesome. The increase in my compile-times after I added macros implementing the `SerHex` trait for various array sizes was crazy. I imagine that mine cannot be the only crate that will get a meaningful speedup once we can operate generically over array length.
The grandparent post lists examples of projects doing this.
I definitely second this. Rust was my first low-level language, and I definitely appreciate having been introduced to systems programming by a language that forces best-practices. Plus, the Rust community is just insanely friendly and helpful.
What is `check_ahead`? Anyway `Some(c @ &amp;'a' ... 'z')` should work (in fact I was going to make a slightly different suggestion but the compiler suggested this one).
Maybe if Rust gets officially sponsored by JetBlue. :P
Please don't interpret this as me scolding you for having unstable dependencies, I'm thrilled at all progress towards having stable libraries. :) I just think it's useful to subtly encourage recursive stability as a strategy for gradually stabilizing the entire ecosystem. Well done!
/u/kibwen and /u/rabidferret I have left [an issue here.](https://github.com/chronotope/chrono/issues/195) I am known to be a [strong supporter](https://github.com/rust-lang/libc/issues/547) of the Rust ecosystem releasing solid crates as v1.0. If the crate *isn't* ready for people to use it, then staying below v1.0 makes sense, but otherwise... not releasing a v1.0 doesn't make sense to me. You can always release v2.0, v3.0, and so on if you *need* to make breaking API changes, but the Semantic Versioning scheme is not designed to operate very well below v1.0.
Seems.. complicated. I just do `curl -s https://static.rust-lang.org/dist/channel-rust-nightly.toml | grep rls`, and if it's non-empty I update.
I've seen people recommend https://www.pcengines.ch boards a lot. Though they're all above $100. Intel compute stick is also close. There's not much in x86 below that. I wouldn't worry about using a tier-2 platform though. The stable releases are very stable, and the nightlies don't break much more than the tier-1 nightlies do.
Why don't we include RLS in the CI system and force all check-ins to not break/fix RLS before merging?
How would I organize two very similar functions? For instance: fn binary_search_right&lt;T: Ord&gt;(arr: &amp;[T], val: &amp;T) -&gt; usize { ... if value &lt; arr[mid] { ... } ... } fn binary_search_ left&lt;T: Ord&gt;(arr: &amp;[T], val: &amp;T) -&gt; usize { // Same as _right, but with &lt;= instead of &lt; }
I would have gone with [Art] over [fluff]. I am curious though, why'd your workplace have _you_ make paper snowflakes?
I didn't interpret it that way at all. I've just spent a *lot* of time thinking about this and figured it was worth documenting. :) Thank you for your support! &lt;3
Probably more art than fluff, yes. Everyone got to make snowflakes. We are a young and hip office (thumbsup)
Probably more art than fluff, yes. Everyone got to make snowflakes. We are a young and hip office (thumbsup) 
That's some, uh, interesting rustational symmetry you've got there!
Let us not look the **HOLIDAY-THEMED RUST PROPAGANDA** gift horse in the mouth, eh?
 fn thing&lt;F&gt;(mut out: F) where F: FnMut(i32) { out(0); out(1); out(2); } That or return an iterator from the function and compute the elements lazily.
You can try [actix](https://github.com/actix/actix), it is actor library built on top of tokio. It is easy to build complex interconnected actors. Here is example [fectl](https://github.com/fafhrd91/fectl) it uses different types of communication channels, uds, pipes, etc
I think this is because of even more painful "synchronized updates" - any breaking to parts of rustc which rls uses would be delayed on rls updates before it made it to nightly, even for people who were wanting to just test the update without using rls.
That's one of my off weeks, but a week earlier or later would work. I don't expect Boston Rust to schedule around me, but Tuesdays would help.
I think it's a matter of perspective - were you already familiar with git when you tried using mercurial? I've used mercurial for 8 years and would consider my self proficient in it for the last 5 years after I decided to dedicate time to learning and practicing and understanding the tool. I love using mercurial because I'm efficient with it and have that "understanding of internals" that you hear most people say to learn about git. I try using git every now and then and I get flustered with trying to manage local/remote branches, not to mention I have to pilfer through man pages (then resorting to web searching) to remember how to do basic things -- `hg help` will generally guide a newbie to the right areas pretty quickly. Btw, your example is a more complex situation however in newer mercurial your example is much more simplified than before with the evolve feature: update to the commit to change, amend it to modify the commit message, `hg evolve` to put the repo in a stable state. What is git's comparative solution - s there a one-liner for it or is it also 2-3 commands?
emcc uses a js library to convert opengl calls to webgl. Its a subset though. https://kripken.github.io/emscripten-site/docs/porting/multimedia_and_graphics/OpenGL-support.html
FWIW with Chrono there are a couple things that I'm aware of: * The original maintainer has almost exactly 0 time to maintain it * I am trying to keep the lights on but (a) I also don't have the time required to maintain something real and (b) the author hasn't found time to do releases and hasn't given me release authority (they don't know me, so honestly that's legit) so it's hard to find the motivation to do real work. There are known API problems in Chrono. I would expect it to break before it hits 1.0, or for someone else to write something new/based on it. Though, most of the problems I'm aware of are missing items (timespan, some iterators) and nothing with the underlying structs themselves, so it seems possible that we could use the SemVer trick for future releases. There is some pretty serious trait surgery that needs to happen, though. If you want to be really sure about no unnecessary 2.0 I'd consider putting Chrono behind a more specific `chrono04` feature. If we maintain compatibility it's easy to add a `Chrono` synonym, but adding a `chrono1` feels hackier. Also, if anybody read what I said and decides they want to help more than I've been able to there are lots of obvious things to do and if be happy to create gh tickets or communicate in some other way about making it better. If you're reading this and interested, then I'm excited.
The rules of good style say that panicking is for catching logic bugs before they turn into undefined behaviour. A correct program shouldn't panic outside of bizarre circumstances, but an incorrect program should panic or deadlock instead of overflowing buffers or use-after-free. If your program has subcommand functions, they should return errors. Look into `error_chain` or `failure`.
That sounds really awesome! Any way you can open source it (or its core?)?
Is a `prelude` module a crate convention, just just something that Diesel is doing?
Hey Theo. I use Exa (ls replacement) and RipGrep at work and they work great. RipGrep is freaking amazing. Also redox has written a shell and a windowing system and an entire os in rust. That good enough? Pick some better strawmen. 
You can also use the beta channel, but I'm not sure how far it lags behind nightly
Posix is mediocre anyways. There are some terrible APIs in posix. The whole signal infrastructure is basically impossible to use properly.
https://github.com/BurntSushi/ripgrep https://github.com/ogham/exa Fucking Firefox https://github.com/redox-os/redox How do I google?
I am coming from JS, Python so I have a pretty stupid doubt. Why does everything in Rust needs to be inside a function, atleast inside a main function?
Also posix is in general a shit design from the 70s. Aspiring to posix compatibility is a pretty low bar. It's like saying you can't build a car unless it can use parts from a Yugo.
It's convention. The std library does it too, actually. The std prelude is imported by default for projects.
Thanks a lot! Any good resources on Rust? Apart from documentation?
Thanks a lot! And what about database part I mentioned?
One of these false positives would be Linus' words about that :) And no, it's not a mistake - file names _matter_.
if you look at `evdev_tag_touchpad` in that same file you'll see it looks up a udev property with key string `"ID_INPUT_TOUCHPAD_INTEGRATION"` which gets the value from a hwdb (https://www.freedesktop.org/software/systemd/man/hwdb.html). Either way a virtual touchpad is neither in a hwdb nor is connected via usb or bluetooth and I haven't found a way to explicitly just set the device as `internal` or `external`. If the prop is unset then libinput throws an error when reading the device events and I think that is why I haven't gotten it to work yet, although I can only verify that when I manage to set that prop and it still doesn't work and then I'll be sad XD. Anyway this is very off topic to this post so not really the right place to discuss this.
https://www.sqlite.org/src/doc/trunk/README.md
Gameplay video here: https://youtu.be/MHnXQrwT8cs
&gt; I'd say mio is great for simple projects but if you want to build a larger application tokio is going to make the code much simpler^*. * Once you spend a ton of time figuring out your problem in Tokio terms 
&gt; he got "kicked" from NetBSD after allegedly being quite an asshole to other developers [No need to put quotes on it](http://mail-index.netbsd.org/netbsd-users/1994/12/23/0000.html).
True, but I feel like that's a one-time step. I mean, it took me a while to "get" futures, but I won't ever have to spend that time again. Any new projects I start or work on now just make sense - and I don't have to think about how I'm going to integrate into any existing systems. That is part of why I don't think it's not great for simple projects. It isn't a framework built for show or good examples, it's a framework built for making larger interconnected applications with many moving parts. There's a mindset needed that isn't obvious from the start, but once you've learned it, you've learned it.
I think it's because js and python are interpreted languages, so their programs entry point is simply the beginning of the file, while one compiled languages the starting point needs to be specified. Also, logic can only be performed in functions because functions define a static order of instructions that the compiler won't change around. It's not much different from puthon and js in practice except there's no globals and stuff like that. Sorry I'm kinda bad at explaining lol but I hope it helps somewhat 
qq: why are a majority of Rust projects that I've seen dual licensed with Apache License, Version 2.0 or MIT? (IANAL ofc)
Thanks for the explanation. It was genuinely helpful, you ain't bad at explaining. :D
That's the case for all compiled languages (that I know). Python and JS have a concept of a module that is loaded and interpreted when needed, compiled languages have to verify and optimize all code upfront, so the idea of a module does not exist at runtime. A sort of exception (but not really) is lazy_static! macro which allows you to visually place some code invocation inside a module, but really groups those call together and run as part of program initialization.
Mozilla require all their code to be licensed with the Apache license or the Mozilla public license (which is compatible with the Apache license). A lot of free software is licensed under the more permissive MIT, however, and perhaps some library writers also want to give such permissions. So one is for ecosystem compatibility, the other for maximum amount of permissions. 
Thank you, however I seem to be struggling to understand the implications of this. _I really don't know much about the rust ecosystem_
Watch Herb Sutter and Scott Myers talks.
https://doc.rust-lang.org/1.4.0/complement-project-faq.html#why-dual-mit/asl2-license?
Dual licensing means you may pick whichever license you like best when you use the library. 
The reason for being so hung up on posix compliance for things like the coreutils is very simply one of compatibility. The current tools that openbsd uses are build to be posix compliant, so if you’d even want to consider replacing them than the new tools must also be. He could also have stated that they are not openbsd coreutils compatible, but openbsd is hardly designing in this place, but attempts to build a secure alternative.
Okay.
Using semver trick for pre-1.0 releases is all good, but please, please, please do not use it for 1.0 ever. Having 1.0 crate to depend on it's pre-1.0 version looks really horrible, especially in a long run.
When asked about tensorflow, it would have been great to plug the [Weld compiler](http://weld.stanford.edu) from Stanford and Frank McSherry's [timely-dataflow](https://github.com/frankmcsherry/timely-dataflow). They're not in the same exact space, but both are cool projects on the data engineering side.
I've contributed to ripgrep, and use it daily. ripgrep is not a drop in replacement for `grep`. So its existence does nothing to remove the exposure of the hundreds of shell scripts on my system which call `grep`, possibly on untrusted input. The uutils project is an admirable compilation of tools which are designed to be drop-in replacement for core utilities. So they get you a lot further than ripgrep does. But there's still a lot of work to be done before any major distro is going to consider switching to them over GNU coreutils. As /u/nerpderp83 says, it would be possible to build a new distro, on new tools, that doesn't worry as much about backwards compatibility. That's a great idea; but, it's also a lot of work. So better to just get down to it and start building it, rather than asking at every talk on adding hardening to an existing distro "why don't you just rewrite it in Rust"?
&gt; I mean, really, the means to keep your history accurate, the way to actually write down what happened exactly — a downside? It's not a downside, it's one of the only two avantages Mercurial has over Git that I could think of. I didn't actually explicitly mention any downsides. I guess it was poorly formulated.
Well, the things you need to do in Git most of the time, aren't really complex at all. Mostly, it'll be committing by picking out and staging the desired changes from the working directory, and occasionally rebasing or merging. The staging part here is one of the huge advantages Git has over Mercurial, as it lets you pick out what changes you want to go in the commit and actually store this information so that it isn't accidentally lost if you need to do something else before actually committing, while also easily letting you see a diff between the current working directory and the staged changes. GitExtensions, the GUI I mainly use for this, additionally takes control of committing and staging to another level by allowing to stage, unstage or reset individual lines in files. TortoiseHg, which I used for Mercurial before, only allowed you to pick which files should be committed, and IIRC, even that was lost if you closed the window before committing.
Yes, I think it's a great idea to try building kernels and userlands that aren't constrained by many old design mistakes, or even design constraints from the 1970s that are less applicable today. But what I'm seeing a lot of in this thread is people simply expressing what they would like to see without really doing the work to do it, and dismissing other people who are putting in the work but with different approaches (like Theo), and I'm trying to provide a little context for why not everyone wants to drop what they're doing an RIIR immediately.
Is the file large? It cold just be an issue of disk speed ( potentially multiplied by anti virus snake oil).
Wow, that's some serious elitism.
It's only 900k. Can I certify my program somehow? The antivirus is McAfee
In a way it is, but way the data are generated is such that creating an iterator would amount to generating all the data, storing them in a buffer and returning an iterator to that buffer. 
Neat, I didn’t know about that feature. But as I replied somewhere else, returning an iterator is quite clunky in my case. 
Cool, I think that’s what I’m going to go with. Are there any example of such usage in e.g. the standard library?
Speaking for bigdecimal here: the "outside" user facing api should be pretty stable: Add, Subtract, formatting... It's mostly internally that we may change some stuff. Since the crate was mostly meant to be used with Diesel (or that was why I did my contributions), those changes will go hand in hand... I use diesel+bd for my accounting, so you can count on that :')
The default output of `/bin/ls` currently looks like this: ``` goodbyecruelworld hello@world goodbyecruelworld-ineverknewye 'hello\012world' 'hello world' "helloworld's" ``` This quoting extravaganza only happens on a tty, and can be turned off with `-N` or some environment variable I can't remember. First major change in `ls` output since the 1980s. Supposed to "help new users", and maybe it would once every UNIX new user guide in use gpt rewritten. Turns out *uutils* `ls` is good enough for my day-to-day terminal needs, so I've stuck it in my path.
Ah, alright. That's pretty reasonable - iterators are pretty clunky to create unless the function is already written in a very functional style. There's also `Generator`s, but they're super unstable and likely to change IIRC. If you'd want to check them out, there's a page here: https://doc.rust-lang.org/std/ops/trait.Generator.html. Involves wrapping your function in a closure and returning `impl Generator`, and will be very efficiently compiled, but probably not the best solution until it stabilizes. Glad you found one that works with the method callback though!
Yes it's not that difficult. Just takes a bit of time to understand how it works and then it's just straightforward.
C++/CLI isn't supported on .Net Core, so that's not an option. P/Invoke is the only way to access native code.
Couldn't your iterator just generate a single value and store the state needed to calculate the next value in the iterator's struct? If you couldn't do that then I don't see any way to not generate all the data.
Thank you especially for the RFC link. I stumbled upon that once and couldn't find it again. You are correct my protocol is really simple which is why I wanted to use core directly. As my library should eventually used by other languages I think I will just make the API synchronous and use a Core inside the struct to execute the futures.
I think you have it backwards -- in the [semver trick](https://github.com/dtolnay/semver-trick) the version with the smaller number depends on the version with the larger number. So 1.0 would never depend on pre-1.0. I see nothing wrong with using semver trick for a 1.0 release.
While Rust is excellent language, you probably won't understand why until you face the real problems of C/C++. I don't encourage you to study C hard. Just find few examples of broken code. Like this one: int main() { int *a = malloc(sizeof(int)); *a = 42; free(a); printf("a=%d\n", a); } Then move to the better language. :)
Is this still a problem? Because the O(N^2) behavior should have been fixed way back https://github.com/rust-lang/rust/pull/15503. It is still linear in terms of the code it generates but that can't really be improved except for C-like enums, but the code of those is constant size as expected.
Does this help http://doc.crates.io/guide.html#project-layout ?
Check memory. You system may be running out of memory while executing your program and swapping heavily. Also, although unlikely, your system may be overheating. I've had slowdown issues that turned out to be caused by poor system cooling.
Doubt it. Cool as cucumber and running only this one program
Well, its part of the documentation, but the second edition of the Rust book is supposedly really good: https://doc.rust-lang.org/book/ Otherwise I'm the wrong person to ask for resources sadly :)
I've been thinking about writing something similar as a library. &gt; predicates are not, unfortunately, composable. :'(
If you don't want people to use your crate, why release to crates.io in the first place? The only reason I can think of is to reserve the crate name. With your logic, the initial release of a crate on crates.io would be 1.0 and development would continue from then on. I have seen shitty crates with 1.0 version numbers and excellent crates with 0.1 version numbers. But honestly this entire discussion about version numbers is pointless. What *does* matter however is the move towards maturity, which is done via the policy checklist (although I do disagree with some of the rules in the policy checklist).
Add this to your TOML [[bin]] path = "server/app.rs"
 if self.socket.read(&amp;mut response)? &lt; MIN_RESPONSE_BYTE_COUNT { return Err( ErrorKind::InvalidValidationResponse.into() ); } Doesn't look correct as `read()` is not required to read whole slice. You probably need `read_all()`. In case of variable messages, you need to `read_all()` the header to determine the length, or `read()` in a loop until you reach some end marker. Also, consider using `tokio`.
Ah, yes. My bad.
Not that I can think of off-hand. Iterators are more flexible, so that's how things are likely to be implemented. Using a sink callback is less work, so I tend to use them when I'm feeling lazy.
Two days ago I wrote something similar over websockets. I simply used something like this for handshake: client.send() .and_then(|client| client.into_future().map_err(|(err, _)| err)) .map_err(MyError::Websocket) .and_then(|(message, client)| if check_success(&amp;message) { Ok(MyStruct(client)) } else { Err(MyError::BadHandshake) })
Oh, good. I was imagining some huge security issue. Properly quoting strings seems almost like the opposite of a security issue. Thanks for the explanation. 
In the standard library, the closest thing I can think of is the `Read` trait: https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_end
Maybe another nightly feature comes in quite handy. Generators: https://github.com/rust-lang/rust/issues/43122
It returns Option&lt;&amp;char&gt;. I just changed Option&lt;char&gt; to Option&lt;&amp;char&gt; in some type, and many tiny parts were broken.
Maybe try profiling the program?
I also had misgivings regarding that piece of the code, however I don't know that it is possible to improve it. Using read_to_endl() will not work as the socket will never have EOF from that point, resulting in it blocking indefinitely. The Socks 5 protocol doesn't have any end marker that could be used to break a loop, and due to the variable octet length of BND.ADDR the response byte count is unknown. I'm not sure what you mean by look at the header to determine the length, to my knowledge there is no way to determine the incoming byte count from any header, though I could be wrong regarding this, the Socks 5 protocol doesn't include an incoming byte count on BND.ADDR in response to a connect request, and it could be variable lengths. I personally consider this to be an issue with the protocol in that if I were to create a network protocol I would certainly always encode exact byte counts or use delimiters to be able to ascertain that the correct number of bytes has been read, however I believe that simply using read() here is nearly if not the best that can be done. In practice it seems to be working, but I totally agree that I wasn't happy with this segment of the code either. 
Is the slow computer running it from a network drive by chance?
Thanks for this comprehensive analysis, I will certainly be refactoring my code with your advice in mind. I can imagine an improved version already after having read your post, using multiple structures as you said in a builder pattern of sorts. 
Thanks I will give this a read, error handling has been one of the hardest things for me to wrap my head around with Rust. Oddly enough I never really experienced problems with the lifetime and borrowing system and found it intuitive and quick to pick up, but other areas like error checking, generics, things like AsRef and Deref Coercions, and generally determining which features to make use of like whether or not to use traits and how to generally structure the code, I struggled with substantially more so. 
Do you need to use nightly?
Actually i found that it was because I had turned RUST_BACKTRACE=1 on the slow computer.
wasm debug builds seem to have quite a few problems right now. I didn't see one with that exact stacktrace but at least a couple mention debug build issues near the top of: https://github.com/rust-lang/rust/labels/O-wasm 
A myriad of factors can come into play here. The fact that it's a corporate computer is probably the largest (probably slower hardware, virus scanners, proxies, etc.). Did the program get recompiled first because you ran it with `cargo run`? Why are you running it like that anyway? I'm assuming it's a "finished" project, since you said you hired someone to write it for you. I'd just run the binary directly. --- Start diagnosing by figuring out what happens when the program starts up. Is it launched from a network drive? Is it being blocked and scanned by an anti virus or Windows itself? Is it being sandboxed? Secondly, check the resources of the corporate computer. How much memory does it have? What CPU and how many cores? Compare that with your private computer and see if the slowdown is within the boundaries of the slower hardware. Oh and generally, If a corporate computer has an antivirus installed, it **is** going to scan stuff; especially unsigned, random executables. Hope this helps!
Exactly. I have a big enum and according to `llvm-lines` PartialEq generates about 1 KLOC for both `eq` and `ne`.
Ah, I'll remember that next time, thanks!
No. The "problem" is in an amount of generated code.
Yes.
It's not a strawman argument. He answered within the context of OpenBSD maintenance. Can you promise me Exa will work in all scripts that currently use ls, without any new bugs? Of course not; "exa’s options are almost, but not quite, entirely unlike ls's.".
`.cloned()` should do the same thing
Reading through articles on [lwn.net](https://lwn.net/) is super informative about the internals of Linux.
You could instead put them inside of `src/bin`, and then Cargo will just know about them. Or use workspaces.
Your corporate PC may have something like Bit9 which scans executables as you run them. In case of self-compiled ones, it's likely it's getting pretty suspicious and scanning them _very_ thoroughly.
&gt; If you don't want people to use your crate, why release to crates.io in the first place? A simple answer to this is that *I* want to use the crate in other projects (not via path references) but I know it isn't ready for *others* to use yet.
What kind of APIs do they expose? C? C++? COM? Rust is great at interacting with C DLLs and I believe the [winapi](https://crates.io/crates/winapi) crate provides support for interacting with COM objects. C++ APIs are difficult for anything but C++ to interact with because C++ has no stable ABI.
Is there a simple way, using serde-json, to (de) serialize an integer field using K,M,G suffixes ?
A reason to publish to crates.io is to get feedback from actual usage, rather than from just talking about it.
If you need some additional help I'm happy to spend some time on it.
so why not release 1.0? the number is largely about API stability, which you say should be pretty stable, so I don't see the harm.
So sorry i missed this message. I would be reading thru the code now, best way to contact you if I have some doubts?
To add to whats been said, we have an [issue open](https://github.com/rust-lang-nursery/api-guidelines/issues/140) on the api guidelines for documenting best practices for these,
The fix here is uninstalling McAfee, since it is trash