If you're unironically referring to yourself as CHM, I have some bad news for you.
Amethyst.rs reminds me of this: [https://www.youtube.com/watch?v=lpzVc7s-\_e8](https://www.youtube.com/watch?v=lpzVc7s-_e8)
Super awesome!! The author also has some pictures of finished games up on Twitter: https://mobile.twitter.com/WAptekar/status/1133558375583768580
Hello, &amp;#x200B; I am trying to understand how to properly import objects that I defined in a different file. For instance, in &amp;#x200B; [https://github.com/ecks/msf-client/blob/73d0cc32d344821890b1b11c93f0e6775b591de5/src/conn.rs#L10](https://github.com/ecks/msf-client/blob/73d0cc32d344821890b1b11c93f0e6775b591de5/src/conn.rs#L10) &amp;#x200B; I have \`\`\`use crate::msg::Tokenize;\`\`\`. I would like to change it to be \`\`\`use msg::Tokenize;\`\`\` instead, but my compiler is not letting me do that. I can see other open-source projects don't have to use the full path with "crate::" in it, so I am wondering what I am doing different.
Can confirm
Nice, the await improvements are coming in right on time.
WHy is rust so fucking hard, i jlust want to learn but it is too complicated plz make it easyier
&gt; Identify plugin in requests to crates.io during completion in Cargo.toml properly There's a Yak Shave coming about this. This was actually the end of a 3 day rabbit hole &gt;_&gt;
I really wish it was just part of intellij...
I try (heh) to use \`?\` everywhere. But basically: * Use `?` in library crates. * Do what you like in bin crates, depending on your requirements, but still preferably use `?`.
[Here](https://github.com/chris-ricketts/keyboard-layouts/blob/master/tests/all_layouts.rs)'s an example of from the `keyboard-layouts` crate showing how to use `tokio-linux-uhid` to emulate a keyboard device.
FYI, Today, Friday 07. June 2019, Pact have their e-books for sale at $10.
[removed]
Anxiously awaiting that, love me some Yak Shave
I can't directly answer your question, but check [https://github.com/RustCrypto/hashes](https://github.com/RustCrypto/hashes) for a collection of crates that implement a common interface for cryptographic hash functions, for another source of inspiration.
On Windows, you have to use the "-gnu" toolchain in order to debug, it's not possible to debug the "-msvc" one (yet). &amp;#x200B; Here is mine: &amp;#x200B; \&gt;rustup show Default host: x86\_64-pc-windows-gnu &amp;#x200B; installed toolchains \-------------------- &amp;#x200B; stable-x86\_64-pc-windows-gnu stable-x86\_64-pc-windows-msvc beta-x86\_64-pc-windows-gnu beta-x86\_64-pc-windows-msvc nightly-x86\_64-pc-windows-gnu (default) nightly-x86\_64-pc-windows-msvc &amp;#x200B; active toolchain \---------------- &amp;#x200B; nightly-x86\_64-pc-windows-gnu (default) rustc 1.36.0-nightly (50a0defd5 2019-05-21)
It's in episode 16. We've got 2 through editing, I just need to get around to reviewing. I promise I'll get on it soon!
/playrust
As someone that works on an internal tool written in rust, I know there's a decent chance that there are APIs out there not publicly used. Especially considering I submitted a necessary API to an upstream that gets used in said internal tool. Whether or not API stays around should be based on possible users, how appropriate it is, and the maintenance cost.
That's a requirement for the 2018 edition which is set in all new projects. You can switch it back to the 2015 edition (old path semantics) in your Cargo.toml: [package] name = "msf-client" version = "0.1.0" authors = ["Hristo Asenov &lt;hristo.s.asenov@gmail.com&gt;"] edition = "2015" # changed here
Will it use Juniper or will they be implementing graphql themselves?
Hello everyone! I am looking for an idiomatic way to convert an `Option&lt;String&gt;` to `Option&lt;&amp;str&gt;`. So far, here is how I do it : ``` let initial_value = Some(String::new("Foo")); let final_value = initial_value.map(|string| string.as_str()); ``` Is there a better way?
&gt; Do you agree that there is a problem in the cishet male community, though? Hi, I'm a non native speaker, so please interpret my words as kindly as you can, I might not pick the perfect wording every time. The thing I was wondering about; could you explain your reasoning behind the phrase "**the** cishet male community"? It sounds like you group all cishet males together to form one single community, but that's not what reality looks like to me? It's rather that, assuming a community which excludes everyone who is not cishet male, a lot of cishet males would also avoid that community for various good reasons.
I believe it will be rewritten in Rust but it will only support Go and JS.
...but JetBrains really wishes for you to pay for debugging.
&gt;I do agree, and I do not mind the idea of talking openly about these things, and including them everywhere, at all. It makes the world more colorful, and I like that. Me either. Ignoring problems in communities usually just exacerbates them. &gt; we are all unique, different from each other no matter how similar we may find each other.... I think that too often people worry that talking about our differences you are $something\_phobe. There's no point in pretending I'm just like a straight person, I'm not. But it also doesn't bother me to be thought of as different. It only bothers me when people think I'm inherently lesser for being different. &gt;so just address 'cishet' in general instead of calling out males especially? This is a fair point, and to be honest, I just didn't think of it. The first draft used the term "Straight White Male" before feedback I got made me realize race doesn't factor into it, and your comment has made me realize the same is probably true of gender in this case. Thank you.
One difference might be that you're using Rust 2018, which somewhat changed the rules for importing. If I remember correctly, *in Rust 2015*: * If you wanted to `use` something in the same module, you would preface it with `self::` * If you wanted to `use` something in the parent module, you would preface it with `super::`. * All other uses of `use` were relative to the crate root. If you had `extern crate foo` in your `main.rs`/`lib.rs`, you could write `use foo::something`. If you had `mod bar` in your `main.rs`/`lib.rs`, you could write `use bar::blah`. If you had `pub fn do_the_thing()` in `main.rs`/`lib.rs`, you could write `use do_the_thing`. In a Rust 2018 context, every `use` has an implicit `crate::` in front of it unless you have `super` or `self`. In *Rust 2018*, this has changed: * The first component of the path is considered to be relative to the current module, unless it's `crate`, `super`, `self`, or the name of an external crate. * E.g. if you have an external crate `foo` in your `Cargo.toml`, you can write `use foo::something`. * If you have `mod bar` in your crate root, you'd write `use crate::bar::blah` (unless you're in your crate root module, in which case you can omit the `crate::`) * If you have `mod quux` in your current module, you can write `use quux::thing` * If you write `use std::io;`, you can then, later in the same module, also write `use io::Write`. * In case of ambiguity (you have a local item with the same name as an external crate), you would need to disambiguate (`::foo` for an extern crate, `self::foo` for the local definition; the compiler's error messages will guide you here.) * You _can_ still use `extern crate` to add a crate to a module's namespace, but you probably shouldn't if you can help it. If you want to reduce the amount of typing involved, you can rewrite the `use` lines as a single one: use crate::msg::{Tokenize, AuthLoginCmd, CmdType, RetType}; You can nest `{}`s too: use foo::{ bar::Quux, flintstones::{ Fred, Barney, Wilma}, Thing}; and if you want to import a module alongside a couple of its contents, you can say, e.g. `use crate::msg::{self, Tokenize, Others};`
lol.
So still won't be able to use it in rust? :( Cruel world.
&gt;Hi, I'm a non native speaker, so please interpret my words as kindly as &gt; you can, I might not pick the perfect wording every time. The thing I was &gt; wondering about; could you explain your reasoning behind the phrase &gt; "the cishet male community"? Sure. I meant people in the software development and gaming community that identify as cisgender, heterosexual males. It isn't a community you can opt out of, just like I can't opt out of the "cishomo male" community. It's just part of who I am. This does *not* mean every cishet male is responsible for the poor behavior of others, just like I am not responsible for the poor behavior of people in the LGBT+ community. But I do feel an obligation to point out poor behavior in the LGBT+ community, and I think cishet males should do the same. Feedback about behavior coming from a peer is much more effective.
The rustonomicon has a pretty good explanation here: https://doc.rust-lang.org/nomicon/ffi.html
First, your code as written right now won't work: `.map` will consume `initial_value`, so your closure would be returning a `&amp;str` that points into a `String` that gets dropped at the end of the closure. (The compiler will catch this for you; it will also complain that `String::new` doesn't take any arguments, but that's less relevant.) The usual answer to that is to call `.as_ref()` on the `Option`, to turn a `&amp;Option&lt;T&gt;` into an `Option&lt;&amp;T&gt;`. let initial_value = Some(String::from("Foo")); let final_value = initial_value.as_ref().map(|string| string.as_str()); At this point, the closure we're passing to `map` is just a single method call, so we can pass in the method instead: let initial_value = Some(String::from("Foo")); let final_value = initial_value.as_ref().map(String::as_str); If there's a better, more idiomatic way to do the conversion, I'm not aware of it, but would love to find out.
No problem with doing it that way; that's probably how I'd do it.
I meant to respond to this earlier; it's a good comment. I personally, and at least several LGTB+ people in the Rust/Amethyst, would love it if this were a non-issue and we could just go back to working on Amethyst. The fact that it \*is\* a big deal, though, means it does need to be addressed. It is critically important to the Amethyst community to \*actively\* make people feel safe and welcome, and part of that is to espouse our values and be outspoken on public platforms like this about these issues. I only decided to write that post after days of having to defend our logo change and multiple of us repeating our stance over and over. Hopefully we'll have these discussions, people can choose to stay or leave the community if they wish, and the focus will shift back to coding.
I've read that but that is only for global callbacks. Or a singular callback that targets a specific object. Consider the following. foo1 = Foo::new(); foo2 = Foo::new(); foo1.set_cb(_); foo2.set_cb(_); foo1.run(); foo2.run();
sorry, i omitted the part where i created the problem, edited it in, I'm still unsure how to solve this proper.
sorry, i omitted the part where i created the problem, edited it in, I'm still unsure how to solve this proper.
sorry, i omitted the part where i created the problem, edited it in, I'm still unsure how to solve this proper.
You want /r/playrust. This subreddit is about the Rust programming language.
Oh wow, I've also been working on an OpenAPI generator -- but based on https://github.com/glademiller/openapiv3 Right now mine is WIP too and I have not even finished generating Rust types from JSON schemas in a manner that I'm happy with. I'll let you know when there's something consistent to look at :)
Keep reading.
Yeah, when I created the servo PRs my tool actually warned about some API stuff. I didn't see any usage in tests or in Firefox so I removed it. Then it was pointed out to me that they consider it to be part of the public API of the entire servo project. So I put it back in. Ultimately, this tool doesn't replace that human judgement. You could probably think of some future attribute `#[pubic_api]` or something to signify that some API is meant to be used by end users of the entire multi-crate project.
Off the top of my head, here is a scheme that will work a bit better than yours: Serialise each item in turn into a buffer, comma separated, and count how many bytes you have written. When you have exceeded 1MB then backtrack (truncate so that the last item you wrote no longer exists) and terminate with a closing bracket. There are probably ways to do this with less copying, but it's probably not worth optimising for until you have profiled it.
Thanks!
Just wanna say I think rust is really good generally at having a "light touch" CoC. And the community is very good. It's not often at all that a moderator has to intervene, and when they do, they are always very clear as to why they are moderating. I hope you feel that rust is welcoming. I think the problem is that sometimes being welcoming to one community is interpreted as endorsing all their views, being hostile to another. So for example, if I were to use a crescent to show that Muslim people are welcome, that doesn't mean that I'm endorsing every (or any) interpretation of that religion. All I'm saying is that those people are welcome, along with everyone else. In this case it's possible that people who are not LGBT feel like the focus on pride is somehow against them, and so i think it's right to explicitally say that this isn't the case. It's unfortunate if this comes across as patronising, but imo it's worth it for the sake of clarity on this.
&gt;I hope you feel that rust is welcoming. I hope you do as well. =) &gt;All I'm saying is that those people are welcome, along with everyone else. We are in complete agreement here. &gt;In this case it's possible that people who are not LGBT feel like the focus on pride is somehow against them, and so i think it's right to explicitally say that this isn't the case. Sure. I think at least some feel that way due to the way the LGBT+ community sometimes treats them, which is an us problem, not a ya'll problem. That won't happen in the Amethyst community, at least. &gt; It's unfortunate if this comes across as patronising I'm uncertain what you think might be patronizing in your post. The only thing that could be construed (imo anyway, and if this is even directed at) as a bit patronizing is the explaining of the Rust community, its moderation policies, etc. to someone (me) who has been here for years. =P And that is so minor I only mention it because I don't know what else in your post could be construed as patronizing.
I don't think it is patronising, that's a point others have made.
Somebody should rewrite Rust (the game) in rust (the programming language)
gotcha thanks. if that's the case then I will keep it like that then. Just curious what exactly is my crate root module? If my project folder is msf\_client, I have the folder msf\_client/src/. Is the project root the msf\_client folder or is it the src folder?
They have several crates on the alpha branch, and a few of them use [graphql-parser](https://crates.io/crates/graphql-parser), but I couldn't find juniper among the dependencies, at least not yet...
As a cishet male I loved this post. My gut tells me that any community that could produce an article like this REALLY cares about having a healthy community. I‚Äôve been interested in amethyst for a while - but this post made me really want to check it out. You guys are awesome.
typescript too
You're going to have to point out the exact section for me. Because as far as I can tell there's nothing there that would allow the above code to work.
You'll need to either accept an `extern "C" fn` as your Rust callback, be able to store an additional pointer in the C struct, or be able to pass additional parameters to the callback function in C. If just taking an `extern "C" fn`, you can just pass that as the C pointer to a callback. For the third, you'll need to check out [this StackOverflow post](https://stackoverflow.com/a/32270215), or [this example](https://github.com/hashmismatch/freertos.rs/blob/a5b296a64d48db97c711673a825f6a0e5b9d9188/src/task.rs#L109. For the second, just do the same as above but store a `Pin&lt;Box&lt;Box&lt;Fn()&gt;&gt;&gt;`, and then store the pointer of the first box in the C struct, and then deference it in a callback (see the links above).
Hmm, maybe I should make a PR for it? :D Ah, I understand now, doing this only works because there isn't anything more to lose. So would calling `self.iter_mut.by_ref().flatten().next()` have any extra overhead?
Ironically, that's how I really found out about Rust the language. Went to go see if the game had a subreddit and found myself here!
I'm sure if we could put the whole world through a parser and quantify everything, every person's opinion, views on critical topics, loves and fears, and every information relevant to a research, we could get a statistics chart that would tell exactly how much race and gender matter in questions like this. That would be both amazing and terrifying in my opinion. I do want to say that the post was really well written. I'm aware how hard it is to talk about this, and write a post like this and make sure to not start a flame war/hate mob, or make a mistake that would cause big issues for you or a group in general. It was a really good read, and anyone who complains about these things are exactly the people who need to read about these things and be made more aware.... Thank you for your reply. I was really unsure how to put what I wanted to say, but your comments really made me glad that at least I made some sense with what I said.
Yep that was me xD
&gt;May be it is because of the focus on individual freedom in America, where society encourages people to define themselves as a free individual, rather than as a member of society, and so people try harder to forge an individual identity. I wish. It is tied much more to our Puritanical roots as a country, the conservative movements that began in the 80s, and the almost non-existent boundaries between religion and politics, both at the governmental level and individual level. I've lived in Spain and Finland, and I always struggle trying to explain how intertwined identity, religion, and politics are for Americans. (It is nearly as difficult as trying to explain what a spelling bee was to Spaniards in a language where all vowels each have one sound only) As Jon Stewart (I think) once said, "If you aren't talking to God on a daily basis, you won't get elected in America." This is, as you can imagine, a very complicated topic. If you're interested in it, I'm happy to discuss it somewhere else in much greater depth.
Sadly I am writing bindings for a library. So I do not control the c struct and can not put additional things into it. I think having users of my crate having to write an `extern "C" fn` is annoying but probably the way to go. Hopefully I can get a macro working so they never actually see it and it just works.
Unrelated, I believe Grammarly works by collecting basically *all of the text you write* and sending it to their servers. Consider a vuln like this: https://twitter.com/taviso/status/960556482646261760 Just saying, I am personally *very* wary of an extension like this and I really would recommend everyone avoid it. If you install it on a work computer you are almost certainly violating your company's policies and potentially leaking intellectual property or other sensitive information
I pay for intellij ultimate.
Just to make sure‚Äîthere's no like "free pointer" or any user data in the struct?
Lol
The crate root is your [`lib.rs`](https://github.com/ecks/msf-client/blob/73d0cc32d344821890b1b11c93f0e6775b591de5/src/lib.rs). It's the top-most module, with all other modules in your crate living beneath it‚Äîevery other module in your crate had to be explicitly declared using the `mod` keyword. If this were an executable instead of a library, the root would be your `main.rs`.
It shouldn't, none of those adaptors add much and LLVM is pretty good at optimizing iterator chains. This isn't like Java where every object has its own heap allocation.
Still going through the posts, but this one definitely seems to have missed the point more than any of the others and does not at all seem to be in good faith.
It's a tradeoff - with more complexity, comes more expressive power. It makes rust a super bad first language, so if you're learning it as your first, I would highly recommend learning python (or another similar language) first. --- With that said, learning rust is still hard, anyways, without it being your first language. From what I can remember when I was learning rust, keeping in mind things like the following definitely helped. Hope these can help you? - There isn't just one way to learn rust. There's the [official book](https://doc.rust-lang.org/book/), there's [rust by example](https://doc.rust-lang.org/stable/rust-by-example/), there are [random blog posts explaining rust through specific journeys](https://rust-unofficial.github.io/too-many-lists/), there are [youtube](https://www.youtube.com/playlist?list=PLJbE2Yu2zumDF6BX6_RdPisRVHgzV02NW) [series](https://www.youtube.com/playlist?list=PLJbE2Yu2zumDD5vy2BuSHvFZU0a6RDmgb). If one way isn't working, another might. - No one knows everything, and no one expects you to be able to figure everything out. Many people know many things, though, so if you ask for help, people help. I only know as much as I do today because I asked for help, and people on IRC, on reddit and on other forums (like users.rust-lang.org) answered. The questions don't just have to be "this code doesn't work" either, you can ask conceptual things too (like "why do lifetimes help?", etc.) - Everything takes time. Learning rust won't happen in a day, or a week, or a month. You'll be able to do more after each of those time periods, but it won't be instant. - If things are overwhelming, there's nothing wrong with taking a break and coming back. Some people I know who know rust today didn't learn it the first time, or the second time they tried. Maybe there's something that just needs to sit in your mind for a while before it clicks, I don't know. Taking a break, if you can afford it, isn't the end.
What version of Rust are you compiling on?
https://doc.rust-lang.org/nomicon/ffi.html#targeting-callbacks-to-rust-objects
I did mention it when I said &gt; Or a singular callback that targets a specific object. That ties one object to one global callback. For my code above this method would cause `foo2.set_cb(_)` to take away the callback from foo1.
rewriting the entire thing in rust instead of fixing the poor programming of the jvm based version seems like a kneejerk reaction. high ram usage with a constrained jvm isn't really normal. Good for rust though.
This makes me very happy.
To be fair, we all have bad days. Being misgendered call feel deeply dehumanizing, and it always hurts. If the misgendered individual just had a day full of harassment (which happens a LOT to trans and other folks that don't fit into the gender binary), they might react angrily because they don't have the emotional capacity to react any other way. It can be hard, but don't take that personally if it happens. Apologize and acknowledge your mistake. If they're still angry, just give them some space. Don't make a huge deal out of it, especially publicly, because they may not want a lot of attention drawn to them over it (since it can make them feel like they need to be treated differently from everyone else - which is often called "othering"). Come back later and privately let them know that you're genuinely sorry, that you take it seriously, and that you will do your best to get it right in the future. If they're still angry after that, then that's unfortunate, but they're probably doing what they feel is necessary to protect themself. Sometimes marginalized individuals can't risk opening themselves up to more emotional pain, even if you have good intentions. But even if it doesn't go well with that individual, I promise that your efforts will be appreciated by others.
\[It's your \*\*\_FUNCTION?\_\*\*\]([https://www.youtube.com/watch?v=w1DC2a2tGfQ](https://www.youtube.com/watch?v=w1DC2a2tGfQ))
Another vote for [Programming Rust](http://shop.oreilly.com/product/0636920040385.do) here, it's hands-down one of the best texts I've ever bought, read through (in pieces) several times, and continue to consult. (It's on my night stand.) They cover the right material to an appropriate depth at the right pace in a good order (what a mouthful), and their writing style is simply fantastic. &amp;#x200B; I have "Mastering Rust" as well as several other Rust books from Packt - others have (rightly) commented on Packt and quality control and they're generally right. Typos and non-compiling code aside, though (I can't remember the extent of them), MR is still a worthwhile book, but given the choice I would absolutely say "Programming Rust". &amp;#x200B; Can't comment on "Hands-On Data Structures" or "Rust Programming By Example", unfortunately.
That's funny, I was just looking into this recently. I'll have to look at what you've got.
&gt;Programming Rust If you have the PDF for this book, definitely read it then. That level of quality is exceedingly rare.
Spot on.. "The Book" is a great introduction (especially being free), but PR is a great reference that fills in a lot of the depth that the official book and many others (including Packt ones) are lacking.
Really love the project itself. The fact that it was written in rust makes it even better :D
I'd like to start by saying that I agree that specifically mentioning men (to the exclusion of women) in this doesn't necessarily provide an accurate reflection of the issues at hand. I do think that it's important to note that different groups tend to face discrimination from some sources more than others. Trans individuals are frequently the target of harassment by cisgender individuals (perhaps more often by cis men), but trans women specifically face a lot of harassment from TERFs (Trans Exclusionary Radical Feminists). Bisexual and pansexual individuals frequently receive harassment from straight people as well as gay and lesbian people ("oh they're really just straight or gay" is an incredibly common comment), and they're frequently left out of conversations like this entirely. Most people don't even know that intersex individuals even exist, and many that do think that it's a disorder. And this doesn't even cover the sorts of harassment that particular to individuals who are asexual, agender, non-binary, gender non-conforming, genderfluid, genderqueer, or any other identities that I've missed. I mention all of this because I think it's hard to succinctly capture the nuance of the sources of discrimination. Perhaps it isn't true for all cases (especially when it comes to TERFs), but men seem to perpetrate more harassment than women, and because of that, it is an easy shorthand when there isn't space to explain everything in great detail.
I think you're right that it could be invalidating to individuals who do feel insecure in a vulnerable way. I personally read that portion as indicating that individuals whose insecurity causes them to feel threatened in such a way as to respond in an aggressive and harmful way needn't feel that way, that their identity is not at risk because of something like changing the colors of a logo.
I promise you, it was with a lot of effort.
Nice job! That's one more game than I've ever published to steam
Also WIP, but there is https://crates.io/crates/openapi-codegen that you may want to look at
That's the nature of interfacing with C code. If your C library doesn't provide the facility to attach context to a registered callback, then you're going to have to manage that context yourself. I've usually solved this problem by writing a small wrapper library in C that manages my context, and register that library with the external dependency. My Rust code would register with the wrapper library.
Could have done without the 63 mb gif.
That's what the All Products Pack is for. It gets you everything.
Why assume poor programming? Writing memory constrained things in Java is hard, and gets non-idiomatic rather quickly.
TBF, the link is pretty blended (being on the amethyst theme and in a header), I didn't see it the first time I read, but I also already knew what it meant I also think that the text felt a bit stereotypical and passive agressive, and I don't believe it will help you get many allies. Like: CHM can't be fabulous? Can't gays be masculine? (and must CHM be?) It looks like you're reinforcing existing stereotypes... It's also a little off-putting that its tailored for men (I know lots of women, maybe even more than men, who are homophobic) At the same time, I get that having to deal with these issues constantly is pretty hard and can get you really out of your mind, I just think you should reconsider how you speak about it. PS. Thanks for your work on amethyst! It's an amazing project :)
‚ÄúPoor programming‚Äù is much easier to mitigate when the language helps prevent it too...
Is parsing MJPEG anything like parsing RGB?
&gt; Additional Notes: You probably won't get very far without a mouse. Nice. It'd be cool if we could eventually make a crate that abstracts somewhat over the different LED sync vendors out there (AlienFX, Razer Chroma, Logi LightSync, etc).
Hello \[Siyo\](/u/Siyo), Great question, thanks for the astute read of the code. I did think about that, in fact I implemented it that way the first time. However, I changed it to the "poll-interval" method because each every iteration of the interval gets access to the internal state of the actor (and the actor context). The utility of this is easiest to describe with an example: &amp;#x200B; Consider that you want to decouple the consumption of messages from the processing of messages. So once you consume a message you send it to be processed and immediately consume another message without waiting. Eventually, it's likely that the processing of your messages will be a bottleneck and you will want to apply back-pressure. (You may even want to get fancy and make some kind of PID controller). By accessing the state of the actor at the start of the interval you could access state that encapsulates that control - which could be modulated by the processor, for example. &amp;#x200B; Now I'm not saying this isn't possible with the stream processor but I found it easy and intuitive to do it this way. The more typical approach is to wait for the processing to complete before consuming another message, your parallelism is now the number of consumers, not the parallelism of the processors.
Or perhaps they are referring to a large CVS receipt.
Ask /r/playrust.
That is referring to a subset of async APIs on Windows and Linux which don't support synchronous cancellation. Your link doesn't support your sweeping assertion that the pull model is problematic for all IO on Windows and recent Linux systems.
Cool! Definitely!
Hm, I think I saw that at some point, but I couldn't find their repository :/
Ok, thanks for the explanation. &gt; But I do feel an obligation to point out poor behavior in the LGBT+ community, and I think cishet males should do the same for their peer group. Feedback about behavior coming from a peer is much more effective. I've been pondering about this for a bit, and why I'm hesitant to that statement. So I think that how strongly you feel you are part of a "peer group" - and thus, how receptive you are to feedback from people in the same group - depends very much of the size of that peer group. E g, if I'm abroad and find someone that speaks my language, then I would feel connected to him/her, like we have something in common in a world of strangers. At home, I don't feel that way at all, because my language is what most people speak. Likewise, I believe people in the LGBT+ peer group feel more strongly connected, because they are a minority, they have something in common in a world of "others". Whereas the cishet male group is just too large for people in that group to feel connected to other cishet males, at least in general. And even less so when interacting in a community about software, where ideally gender and sexual orientation should be irrelevant. (To clarify: I think we all have obligations to act on bad behaviour whenever we see it, this is part of being a responsible citizen in any community. It's the part about the relative effectiveness I'm pondering upon.)
&gt; On Windows, you have to use the "-gnu" toolchain in order to debug Jetbrains really doesn't support windows debugging?! Crazy. Rust itself emits msvc-compatible debug info, even debugger visualizer files, and VSCode can debug it just fine with the C/C++ extension. Does jetbrains just not have a windows debugger at all?
Agreed. Much better to use [LanguageTool](https://www.languagetool.org/) [[2]](https://www.languagetool.org/compare) instead. It's open-source and can be run locally. (Though you won't get as good results from running it locally unless you [download](http://wiki.languagetool.org/finding-errors-using-n-gram-data) the optional 8GiB bundle of supplemental n-gram data.)
Holy shit, did I say anything about ownership or borrow-checking or heap management adding to the complexity of the crates' apis? I even stated I value those aspects. That's not what this discussion was about. It's about the complexity in the code within a crate's api implementation and the level of complexity of examples provided within a crate preventing it from further being reused. Did you not get that I was being holistic language agnostic that probably all languages suffer from this debilitating disease of un-necessary levels of complexity within api implementations and examples? I further provided constructive criticisms.
`split_whitespace` borrows `data`. The `special_words` vector holds references to `data`, so you cannot modify it later. I don't know what you exactly want to do, but the obvious solution to solve your issue is to create a new string for your data in the second part.
That's a decent idea, I had a play with this but didn't have much luck using macros (scoping and macro hygiene issues, complicated by the fact that I'm documenting a procedural macro which doesn't allow exporting procedural macro items). There may be a way to do this using the macro approach, I'd be interested in seeing what others can come yup with. I did have some *limited* success using `include!` though this does have some caveats, mainly that you have to define the `main` function manually (`include!()` seems to expect the included content to be an expression in this context, see [here](https://doc.rust-lang.org/std/macro.include.html)) and so the include has to be outside of the `main` function. Including both types and expressions seems to require multiple include files. //! # include!("foo.in"); // the file foo.in declares the Foo struct //! # fn main() { // we have to create the main function manually //! # let foo = Foo(); // we would rather do this in the include //! let bar = foo.bar(); // the actual line we want to doctest //! # } There may be other and better ways to do this as it stands, if not it would be nice to see doctest provide support for this.
You could probably take inspiration from [Project Aurora](https://github.com/antonpup/Aurora), it's a program that aims to abstract over them and allow games with support for X to support the other vendors as well. Written in C#/C++ though.
Thank you for your comment. As you pointed out, my first example resulted in me fighting the borrow checker (again). Thanks to your comment, I understand how powerful `.as_ref()` is :) I remember there is one Clippy lint which warns when just you map to a simple function call. It was completely out of my head when I wrote my comment. Thank you for your answer, now let's get back to code !
I think there is some fairly relevant backstory here, as to why this piece was even published in the first place. If you jump on their discord server ([https://discord.gg/amethyst](https://discord.gg/amethyst)) and join the #meta channel, you will find: \- No one had an issue with raising awareness for the movement. The issue was with how the decision was made, and the handling of the entire situation. &amp;#x200B; \- The changed was labelled as a "community decision". \- Anyone that asked about the change, was quoted the CoC and silenced. \- The amethyst team actually locked out the channel, so no one could talk about. \- The essay in question was posted. \- After the discord channel was unlocked, a few people voiced their concerns about the decision making process and the handling of the situation, and this forum post was created: [https://community.amethyst.rs/t/personal-opinion-on-the-pride-month-logo/894](https://community.amethyst.rs/t/personal-opinion-on-the-pride-month-logo/894) \- Turns out, the the amethyst team is a "private body", and "community decisions" do not involve anyone that is using/contributing to amethyst. You have to be apart of the actually private body team to have anything to do with a "community decision". \- Also transparency about decisions are not on their agenda.
Rust in IntelliJ is great, makes doing rust so much easier.
Yeah that makes sense. I actually attempted to do this myself (in Riker) shortly after posting this and quickly ran into lifetime issues. The `MessageStream` needs to have a reference to the Consumer and if you want to store them in the actor, you get the classic self-referential struct problem. I found your approach to be much simpler, although I was a bit worried it could increase pauses between Kafka message batches, so I made the poll interval pause slowly increase over time when no messages are available (e.g. 1ms, 2ms, 4ms... up to configurable).
That doesn't sound like it would fix the problem, though, which is multiple IDEs.
I'm not going to add any more of my thoughts on this here, because I don't want to get people even more upset at me. All I'm going to say is thank you for this reply, and I'm glad you're seeing the situation from all of these perspectives.
Indeed, took quite a large chunk out of my mobile data limit.
&gt;Likewise, I believe people in the LGBT+ peer group feel more strongly connected, because they are a minority, they have something in common in a world of "others". Yup, this is correct. &gt; Whereas the cishet male group is just too large for people in that group to feel connected to other cishet males, at least in general. And even less so when interacting in a community about software, where ideally gender and sexual orientation should be irrelevant. I understand what you're saying. In that situation, I would probably consider my co-workers, friends, and others in my social circle to be my peer group. An example I like to use is that if a man is interrupting a woman in a business meeting constantly, there is some amount of responsibility on the other men in the room to say something like "Hey, dude, she was talking. I'd like to hear what she had to say." &gt;It's the part about the relative effectiveness I'm pondering upon. Every little bit helps. And don't feel obligated to call out each and every incident you ever see. That's an unrealistic burden to put on yourself, and will just burn you out. Do what you can while protecting your own mental and physical health. A trauma counselor I saw for awhile give me three questions to ask before getting involved in conflicts: 1. Can I do something about this? 2. Should I do something about this? 3. Do I want to do something about this? It is perfectly fair to answer no to any of those. What you are able to do, \*will\* be appreciated.
They're working on it. The msvc debugger has some license restrictions which prevents them from using it, but I believe there was some progress on that front recently.
It doesn't solve the problem of multiple ides, but at the same time even with plugins supporting the same base features in Idea, I end up using the dedicated ides like pycharm, rider and CLion since they have better UI/UX affordances for their respective languages which really add up in terms of being nicer to work with than contorting Idea
It‚Äôs not uncommon for me to see huge RAM usage with software based on the JVM. Not sure what its cause is though. Another example: https://andygrove.io/2019/04/datafusion-0.13.0-benchmarks/ And from personal experience https://www.yworks.com/products/yed usually uses 1 GB for about 20 Nodes and a few edits.
Yes pretty much. I'm heavy CLion (their C++ ide), ReSharper and IntelliJ user.
&gt;TBF, the link is pretty blended (being on the amethyst theme and in a header), I didn't see it the first time I read, but I also already knew what it meant Hmm. Is the &lt;midi&gt; tag still supported? More seriously, I'm not exactly sure what else could be done. If I'm reading an article and I don't understand a term, I google. That post has quite a bit of dog-whistle phrases, and very little substance. It is a waste of my time to engage with someone who actively chose to remain ignorant and ignore provided resources. &gt;I also think that the text felt a bit stereotypical and passive agressive, and I don't believe it will help you get many allies. I really do try to aim for aggressive-aggressive if I am going to be aggressive. =P When writing that response, I had a list of priorities. Gaining allies as a result of it was not the most important thing; making sure that members of our community felt safe and protected was the highest. That includes the cishet men of our community who felt they might be banned. &gt;Like: CHM can't be fabulous? Absolutely! There's some metro guys that look sharp af and put me to shame. &gt;Can't gays be masculine? (and must CHM be?) Defining masculinity, and the subject of healthy vs. toxic masculinity, is a whole different discussion, I'm afraid. The cishet male community is not the only one that struggles with toxic ideas of masculinity. Hop on Grindr, and you'll quickly see profiles that say things like "masc4masc". This is one problem that cuts across all communities of men. I'm happy to discuss this in more detail, but probably best to do it elsewhere. &gt;It looks like you're reinforcing existing stereotypes... I'm afraid I don't know what you mean by this. &gt;It's also a little off-putting that its tailored for men (I know lots of women, maybe even more than men, who are homophobic) Do you think that everyone that if I had said "cishet people" instead of "cishet men", all the men who felt targeted would be ok with the post? &gt;At the same time, I get that having to deal with these issues constantly is pretty hard and can get you really out of your mind, I just think you should reconsider how you speak about it. I'm unsure what "out of your mind" means. If you mean impulsive or something, while I wrote the post, it was reviewed by multiple people, male, female, gay, straight, trans. I think cishet people should reconsider how they speak about the LGBT community. Maybe we can each work on that with our respective communities and review progress we've made in a month or so? &gt;PS. Thanks for your work on amethyst! It's an amazing project :) Thanks! It is a team effort. Please feel free to and stop by to chat or contribute.
Bump: here is hoping that the weekend brings fresh eyes on this.
Thank you both, I'll certainly look at this!
Sent you a tutorial on how to write scalable data parser in rust , hope it will help.
I feel really bad to tell you this and it will probably only make things worse, but I think you're looking for /r/playrust. Depression is not fun by any means and can be extremely hard to cope with. Just know that even if this isn't the sub you meant to post this to, you still have people who can relate to your experiences.
You're probably looking for /r/playrust
Maybe the devs should rewrite their game in Rust ü§î
Good on you for giving people the benefit of the doubt, but this post is definitely a cynical scam. If you Google search for the first sentence of the second paragraph, it reveals that most of the post is copy-pasted from a sample college admissions essay. This is also obvious in the last paragraph, where the poster describes himself as "daddy's baby girl" then says that he's "proud to be his son".
You may be looking for r/playrust. This sub it's dedicated to the Rust programming language.
oh my bad still new to this thing. Sorry about that. I'll delete.
&gt; I'm curious what you think I'm rubbing in, though? I honestly don't know. What do you think you‚Äôre going to achieve by telling them about their insecurity regarding their masculinity? If you rightly point out how damaging all this easy jokes about e.g. profile pictures can be, is making somehow ‚Äúfun‚Äù about the insecurities of people that much better? I mean, you most likely won‚Äôt convince people if you‚Äôre - to a certain degree - also make the same easy jokes.
So cool! I love it!
[phf](https://github.com/sfackler/rust-phf)?
Serialize each element individually, then build an array of elements where you add up the running total of size (make sure to add room for overhead!). When you reach the limit, serialize the array and send it (note: might be fast and more memory efficient to serialize directly to the wire rather than making an additional memory copy, if possible, but that's just good advice in general).
I joined Prisma early this year as a senior Rust engineer to help them with the transformation. I've been mostly responsible of the connector architecture and supporting engineers with less Rust experience to get up to speed with the language. Here's some notes: The most important thing for now is to ease the workflow of a TypeScript/JavaScript/Go developer for now to use Prisma without a need to run Docker or an extra server. I mean we have users who find Docker hard to use and would benefit a lot if they could just npm install Prisma and start using it. Prisma itself benefits a lot of the Rust type system and guarantees. It is also quite simple to just implement wrappers to different languages, priorities now being the three languages mentioned above. You can still run Prisma as a server and we will get there eventually. The first version relied heavily on Sangria GraphQL library, now the company wants to have more control how to parse and evaluate GraphQL. This is a lot of work now, but will help us in the future. We'll expect to be in a better position later this year, but in the last three months we've built a full Rust team and we've been moving forward faster than we thought. Rust helped us a lot on how we could start the work in two parts: first writing the connectors in Rust and connecting them with JNA to the Scala codebase, letting us to use the massive amount of tests from the JVM codebase. At the same time the other part of the team could start writing the core with GraphQL parsing and later on we could connect our systems. Now we're abstracting the connectors in a synchronous way, but I've been experimenting a lot with Futures/Tokio, having some years of experience with them already. It really seems we must jump to the nightly train and start utilizing async/await in Prisma. Using the combinator approach gets quite tricky very fast. Some libraries already spit out from the project: * [https://github.com/prisma/prisma-query/](https://github.com/prisma/prisma-query/) \- A DSL for building an SQL abstraction that can be passed around the system. Seems that we want the actual Row/Transaction abstractions here too. Under construction, but been very helpful. We evaluated Diesel, but its dynamic possibilities were not there yet when we started the project and it was faster to just write a small library and move forward. It takes ownership a bit too much and my plan is to introduce some cows there, allowing the usage of references in use cases where you can cope with the lifetimes. * [https://github.com/prisma/faunadb-rust](https://github.com/prisma/faunadb-rust) \- An async client for FaunaDB document database. I just finished this yesterday and I haven't tried it yet in actual use.
Shame. I have been recently considering getting into Amethyst but I am not a fan of the radical left's tendency to silence moderate and conservative voices. I'll be staying away. In the future, avoid politics, or at least pick an issue of some consequence and stop peddling the narrative that gays and women are somehow discriminated against in the West when we all know that isn't the case.
I found a fantastic hack in the actix techempower submission where they match on str.length() and use a where clause that matches the actual string. https://github.com/TechEmpower/FrameworkBenchmarks/commit/4a88c99dc8de7bdfddec69cb14837e893ec190f5#diff-4496412ec3ee36c0684c73e72a8b64b1L47 Looks like it got removed though, so maybe the compiler got cleverer or maybe it was considered cheating (I'm not sure). Honestly though, I wouldn't bother optimising it unless you have production profiling data that tells you that it's a bottleneck. Idiomatic rust like `match` is probably fast enough and will probably be easier to maintain.
Hi Mohamed, Thank you for the kind words! &amp;#x200B; Actually an the WebView is a VueJS App which talks to a JSON API. Native apps are planned for Q1 2020, you can follow us on Twitter [https://twitter.com/42bloom](https://twitter.com/42bloom), in order to stay updated. We will come back on Monday with an announcement regarding the next steps and how to organize contributions :)
Looks better than most of what gets shoveled on Steam these days :) at first glance it kind of looks like an RSI waiting to happen though, I would suggest focusing less on speed and more on precision - e.g. make the targets smaller instead of adding more on screen or require specific click sequences to destroy some targets. Maybe you could also add some power-ups that can be activated with the keyboard e.g. something that slows down time or clears the screen.
Indeed. The JVM can be surprisingly fast, but it's often very memory hungry...
I don't know how the performance will compare either. It sounds like you have specified your problem pretty well though. My next step would be a microbenchmark. If your list is smallish, then I wouldn't worry about constructing your matcher at runtime.
Thanks a lot, it seems that as you pointed ptr::read is the better way of dealing with this situation. I just replaced uninitialized with ptr::read and all my tests are passing, and thankfully I have less warnings to deal with ;).
Just in case you weren't aware, transmuting `#[repr(Rust)]` types is undefined behavior. The compiler doesn't guarantee that two identical types will have the same memory layout.
I saw that the Pin API was stabilized and it will allow self-referential structs and have been trying to figure out how to implement an intrusive doubly linked list. I have seen the explanation on the docs but wasn't able to understand it. Will be grateful if someone can give me an example implementation.
I usually do this even for binary crates, putting the logic inside the library and having `main.rs` only deal with the CLI (argument parsing, error presentation, ...).
If the C API callback signature does not allow for a 'data' pointer associated with the function pointer then you cannot wrap it with an `Fn*` trait. The only way you can smuggle a data pointer in there is with code generation where you encode the data pointer in the instruction stream. Unfortunately this is a hard requirement, without a data pointer or codegen you _cannot_ use the `Fn*` traits as callbacks. If you want to avoid `extern "C" fn` in your user signatures you need to wrap things up in a trait and a dummy struct. You can also use macros to wrap around things too. Have an example, the SetWindowsHookEx function had the same issue and this is how I managed: [github](https://github.com/CasualX/external/blob/master/src/hook/mod.rs#L82-L112). You can see the ugly `extern "system"` signature is a default method in the trait, hidden as much as possible and a user implementable invoke method. Here's how it's used: [github](https://github.com/CasualX/external/blob/master/src/hook/mod.rs#L14-L33) and the code it generates for the user: [github](https://github.com/CasualX/external/blob/master/src/hook/mod.rs#L37-L63). EDIT: Now that I think about it, if the callback isn't reentrant you may be able to get away with thread local variables to stuff the context in...
True, but all the generated [builder structs have exactly one non-zero sized field](https://paperclip.waffles.space/tests/src/test_k8s/io/k8s/api/apps/v1/stateful_set.rs.html#71-76) and I'm using `#[repr(transparent)]`, in which case the layout is guaranteed (more on this [here](https://www.reddit.com/r/rust/comments/avrbvc/is_it_safe_to_transmute_foox_to_fooy_if_the/ehha11n/))
Utilizing the string length is a really neat way of eliminating paths.
&gt; stop peddling the narrative that gays and women are somehow discriminated against in the West when we all know that isn't the case. Do you really think so? My own step-sister is gay. From the moment I met her, she always brought girls home. Her siblings would be bringing their partners to family events, she would come with her roommate girl friend. The family was accepting; except her father. To the best of my knowledge, he never acknowledged her "friends" as anything more than roommates and friends. He stubbornly refused any hint, and would evade any attempt at conversation on the topic. He did mercifully stop asking her about boyfriends at some point. How would you feel bringing someone you consider living your life with home, only for your own father to dismiss them as obvious non-choice from the get go? Asking you in front of them when you're considering bringing a partner home? I admire her courage. I admire her loving her father nonetheless. It must have been tough.
Thanks for your replies. I was deciding whether or not to use bundled LLVM for Rust's Solus package. I'll keep the bundled one for now.
Hmm, could that optimization be part of the default impl of PartialEq for slices? (Best I could find right now was [this](https://github.com/rust-lang/rust/blob/7f90abe3aa1864e40e3d516b936c4a1a84e72aee/src/libcore/cmp.rs#L1037-L1043)(
Coders have much to learn from you. Beautiful piece of code. Easy to follow. Gets the job done.
It is part of the [slice impl](https://doc.rust-lang.org/src/core/slice/mod.rs.html#5194).
Thanks for finding this! :)
Thank you for dropping by. Yes I did file some bugs. https://github.com/google/tarpc/issues/224#issuecomment-490560298 https://github.com/mtp401/protoc-grpcio/issues/19#issue-448835668 https://github.com/mtp401/protoc-grpcio/issues/19#issuecomment-496679815 https://github.com/pingcap/grpc-rs/issues/325#issuecomment-498002188 https://github.com/cirocosta/gupload/issues/7#issue-448997678 It is not like I do not understand the code. I just do not understand the hairy code, nor should I attempt to. Developers should attempt to keep the code sophisticated yet simple to read. That was my point. The constructive criticisms I have been bringing up could be applied to all programming languages. I am recommending tools that constrain developers to lower the cognitive load by identify blocks of code of high complexity and refusing to compile because of it. This would ensure that all developers could understand the code in the long-term. Another criticism is function chaining. When I see one code statement divided on many lines via function chaining (i.e. f1().f2().f3().f4().f5().f6()...f999n();) It pisses me off to no end when compilers complain about the error on that line, when function names are not self-explanatory, when the return arguments passed from each function on that line are implied and non-existent on that line. It reminds me of those perl competitions for accomplishing the most tasks in one line. It might seem cool to look at, (it looks like magic!), but it is the furthest thing from long-term maintainability.
WOW so MUCH DOUBLE STANDARDS, BALUUDY MOXILLA JHACKOSSES Thee bastrads block and ban whoever tries to make JS and node OBSOLETE Since they themselves are INCOMPETENT OBSOLETE
That reminds me of an interesting bit of PHP trivia. The reason for many inconsistencies in how functions are named is because different lengths was helpful for looking up functions. https://www.i-programmer.info/news/98-languages/6758-the-reason-for-the-weird-php-function-names.html &gt; htmlspecialchars was a very early function. Back when PHP had less than 100 functions and the function hashing mechanism was strlen(). In order to get a nice hash distribution of function names across the various function name lengths names were picked specifically to make them fit into a specific length bucket.
Why is T the letter used in Option&lt;T&gt;?
Every time, I have to redirect those who don't read sub descriptions to their correct subs...
How are you getting the tokens in the first place?
Without a minimal self contained example, nobody really can help you. I can imagine 10 different things that you might be asking about, yet you are probably having a different problem. The only thing I can tell you is that wrapping callbacks from FFI has worked fine for the dozens of libraries I've had to wrap, and I can't imagine something that's not supported.
Here is some example code I gave above: https://old.reddit.com/r/rust/comments/bxzzk8/ffi_how_to_do_callbacks/eqb1kjv/ I can't give a working example because I do not have one. Although If you want to know the actual c code here: https://git.archlinux.org/pacman.git/tree/lib/libalpm Notably the struct `alpm_handle_t` which stores the callbacks. And `alpm_option_set_logcb()` which is a setter for one of the callbacks.
I didn't ask for a working example, I asked for the C API that you are trying to wrap. How would you use that API in C? If you can't provide working C code, then... that might be a better place to start.
Prisma co-founder here. While the GraphQL resolver system was a great way for us to get started two years ago, it is not flexible enough for us to implement the advanced query optimisations you would expect from a transactional data access layer. So with this rewrite we wanted to take full control over the execution of the query, which made it impractical for us to use a framework such as Juniper. We didn't really evaluate Juniper in depth, but it seems to be a solid foundation for the GraphQL/Rust ecosystem.
Prisma co-founder here. Prisma has a very flexible architecture that on a high-level looks like this: [your app] &lt;-&gt; [generated client] &lt;-&gt; [query engine] &lt;-&gt; [connector] &lt;-&gt; [database] The complex component is the query engine. This is where we will perform query optimisations, caching, batching, tracing and many other things. The query engine can connect to any data source that has a connector implementation. Prisma will ship with multiple first party connectors, but it will be possible for the community to implement connectors for more niche databases as well as proprietary in-house data sources. Applications can use the query engine through generated clients. Prisma will ship with a number of first-party clients, but just like for connectors, it will be possible to build custom clients to support very specific use cases or in order to use Prisma from a language that does not have a first party client yet. Initially we are focusing on js/ts and go. More will follow later. We will talk much more about this architecture at our upcoming conference in Berlin: https://www.prisma.io/day/ We are about to sell out, so hurry up if you are interested. Videos will be available online afterwards.
Apparently, https://github.com/MabezDev/rust-xtensa is taking place.
MJPEG is lossly compression using discrete cosine transform and RGB is a raw format. Couldn't be more different
I wrote the initial Scala implementation, so poor programming can definitely not be ruled out ... In all seriousness - the JVM is a great platform for high-scale application servers. Implementing business logic in Java or Scala takes 2-5 times less time than Rust, so it is usually worth it to pay the GC overhead and provision a few extra servers. The Graal project pushes the boundary even further. Prisma however is not an application server. We are building serious infrastructure and need to maintain a low memory overhead. While it is possible to do this in Java (especially when building a binary with Graal), it is more productive to use a language that is designed for that purpose. We will be writing more about these considerations in the future, so keep an eye out on https://www.prisma.io/blog/ We are also likely to talk about the transition at the Berlin Rust meetup in the future. And if you are a developer in Berlin interested in this kind of stuff, please feel free to send me a mail at schmidt at our domain. Happy to chat over lunch in our lovely Prisma Garden.
Hi Tom üëã I believe you met Niko at a recent meetup. I am trying to organise drinks with a few Rust people to talk async-await. Would be cool to have you join if you are around in Berlin?
How much does the plug-in know about the rust language? Is this a half rust compiler in kotlin or it's very far from that?
This context-less post seems to be about a port of the "Physically Based Rendering: From Theory to Implementation" book to Rust.
Wrong sub my dude
Doesn‚Äôt it say so, here: https://www.rs-pbrt.org/about
Yes but that's two clicks away -- while it could totally be part of the title of this post. It is a good practice to start each release announcement with a sentence that says what the project is about.
I don‚Äôt even know how to change the title of the post in the reddit app ... anyway, fair enough
Title should be ‚ÄúRelease Notes for rs-pbrt v0.6.0 (Rust based Physical Based Rendering)‚Äù
Can't, reddit post names are permanent (at least, as far as I'm aware)
We're working with [Connexion](https://github.com/zalando/connexion) which does the routing for Flask/AioHttp from a Yaml schema. Is possible in Rust, for say Actix?
Does anyone have the executor-reactor-future interaction expressed as a UML sequence diagram to understand who invokes what in response to which triggering events?
/r/lostredditors
Wrong rust, fyi. You want /r/playrust
Not sure why it's not linked from crates.io, but https://github.com/jonathanmorley/openapi-codegen-rs
Well, I don't know, this image describes my coding process too specifically
Because you can put in (almost) any "T"ype
Might be worth looking into the fst crate. Might be a bit overkill for the number of keys involved and I haven't used the values to construct enum variants but it will get you into constant time lookups.
That makes sense, thanks for the reply! I‚Äôve used Prisma on a few small projects and it‚Äôs been a great experience so far. Do you think that some of what you implement will be generic enough for other projects to take advantage of? Right now, Juniper is the Rust GraphQL framework, but with the rapidly developing async webserver ecosystem I think there is a lot of room to grow in Rust/GraphQL space.
I have been using it for the okta crate too if you wanted a real world example usage
The compiler will already branch on the string length if it feels it's worth it: https://rust.godbolt.org/z/iEw0zY. (The string length field is passed in $rsi)
AAAAAAAAAAAA
I'm quite optimistic about this, so I definitely think it's possible! I'll be focusing on the server-side code once I release the crate with client codegen support.
How does performance compare to the regex crate?
As someone who uses Rust mainly for numerical/scientific code, dealing with numerical constants in generic code has frequently been a pain point. Take the motivating example from the README of this crate, for example, in which we implement a function to compute the golden ratio: ```rust fn golden_ratio&lt;T: Float&gt;() -&gt; T { ( T::one() + T::sqrt(T::from(5).unwrap())) / T::from(2).unwrap() } ``` This is not only annoying to type, it also severely hurts readability. `numeric_literals` is a tiny crate providing only a few very simple attribute macros. Rewriting the above function with one of these attribute macros, we may rewrite the above function as ```rust #[replace_numeric_literals(T::from(literal).unwrap())] fn golden_ratio&lt;T: Float&gt;() -&gt; T { (1 + T::sqrt(5)) / 2 } ``` This is arguably far more readable. The macro does nothing else than substitute each numeric literal with the code that you provide, using `literal` as a placeholder for the actual numerical literal. The crate also provides `replace_float_literals` and `replace_int_literals`, which allow slightly more fine-grained replacement. This is necessary if you use literals for, say, both integers and floating-point operations, which is frequently the case in numerical code. See the README for more: in particular, one should probably try to keep the macro invocation close to the literals in question, otherwise the code may become very confusing (if one cannot see the macro invocation nearby, it is not obvious that the literals are being transformed).
Thank you
this was it, thx!
The regex crate is faster by a fair margin. The regex crates uses a nfa/dafa, where globber uses recursive backtracking algorithm. However, most of the extended functionality of glob requires backtracking hence why I couldn't just compile glob patterns to regexps. For an example of that check out (minimatch)[https://github.com/isaacs/minimatch]. Here are some non-scientific benchmarks, on a 7700k 5ghz. ``` /some/**/**/needle.txt time: [69.608 ns 69.727 ns 69.859 ns] thrpt: [313.98 MiB/s 314.58 MiB/s 315.11 MiB/s] Found 6 outliers among 100 measurements (6.00%) 2 (2.00%) high mild 4 (4.00%) high severe /a*a*a*a*a*a*a*a*a time: [138.70 ns 139.34 ns 140.24 ns] thrpt: [210.80 MiB/s 212.17 MiB/s 213.14 MiB/s] Found 10 outliers among 100 measurements (10.00%) 5 (5.00%) high mild 5 (5.00%) high severe /*hello.txt time: [65.454 ns 65.869 ns 66.499 ns] thrpt: [301.17 MiB/s 304.04 MiB/s 305.97 MiB/s] Found 12 outliers among 100 measurements (12.00%) 5 (5.00%) high mild 7 (7.00%) high severe /!(+(secret|private)*+(.jpg|.gif)) time: [2.0428 us 2.0541 us 2.0685 us] thrpt: [7.3769 MiB/s 7.4285 MiB/s 7.4696 MiB/s] Found 12 outliers among 100 measurements (12.00%) 4 (4.00%) high mild 8 (8.00%) high severe ```
How many commands are we talking here? If you have 10, just do a linear search; O(10) is constant time, and this is not your bottleneck. Otherwise I would use the [phf][1] crate combined with a convert to lowercase. This will be O(length of string), and can be prepared at compile time. Note that a phf map will never have a hash collision. From the phf readme: ``` pub enum Keyword { Loop, Continue, Break, Fn, Extern, } static KEYWORDS: phf::Map&lt;&amp;'static str, Keyword&gt; = phf_map! { "loop" =&gt; Keyword::Loop, "continue" =&gt; Keyword::Continue, "break" =&gt; Keyword::Break, "fn" =&gt; Keyword::Fn, "extern" =&gt; Keyword::Extern, }; ``` [1]: https://github.com/sfackler/rust-phf
As a note, your game runs almost 100% perfectly under Valve's Proton for SteamPlay. The only issue I found is the mouse cursor is a small red dot instead of a crosshair like in the video (which makes the game MUCH harder).
Very, very cool idea and crate. I have‚Ä¶plans for it. Thanks much for sharing.
[I benchmarked this.](https://gist.github.com/f00e4867f5f14019ee5dea93175ddeed) For an enum with 5 elements, eq_ignore_ascii_case was the fastest by far. rust-phf is constant-time, however the penalty of lowercasing and hashing the key will likely outweigh the benefits. For case sensitive matching, a simple `match` was fastest, and rust-phf was 15-20ns slower. If you have hundreds or thousands of variants, rust-phf might be worth it, though.
The fst crate is useful if you have *a lot* of keys. Lookups in an fst will generally have more overhead than hashmaps or aho-corasick.
You'd think they notice literally every post has nothing in common with the game nor is the sub themed like the game
This is great, I can't count the times I've written a numeric function, tried to generify it, and given up out of frustration. I'll be giving this a try, thanks!
Definitely interested, I'll send you an email :)
You don‚Äôt have to manually manage memory in Rust like you do in C and C++. No malloc(sizeof(x)) and free. You also don‚Äôt have dangling pointers or index overruns. I‚Äôm not the best C programmer so I‚Äôm sure others will chime in.
C++ has a lot of zero-cost abstractions, that's right. Rust has the major advantage of a central package management that really works. You can clone a random git repository from github with Rust code, enter `cargo build` and it will download all dependencies, compile them for your platform and link it together with the code. In C/C++, you always have to hunt down the development environment the code was written for and try to get it to work, including locating, downloading and installing the dependencies manually. The autotools and cmake are horrible for that, and they're not the only ones. Sometimes I also have code written for an old version of Visual Studio that doesn't compile on modern versions any more. Concerning the language itself, macros are much cleaner than in C/C++, since they're more intelligent than a simple search/replace. That said, beginning programming in Rust is pretty hard. You have to concern yourself with a lot more things than in C/C++ from the get-go, because otherwise the compiler won't compile it. For example, nobody cares if your C/C++ Hello World program doesn't free its memory correctly, but the Rust compiler does care. It took me about two months of experience writing code to get to the level where I didn't have to implement trial-and-error fixes to get the memory management right. The Rust compiler is also pretty good at checking your code style, so it adheres to the official one. C/C++ don't even have an official code style, everybody uses their own. There are additional packages that do that for C/C++ as well, but they're a lot of work to install and configure. This also doesn't help with external code.
Here are some things that I suspect might be improvements but I might be completely wrong so please let me know - Macros are expanded in a different way - Errors in macro parsing are handled better - Errors in macro after expansion are handled better - Errors can be reported to a user of a library better - Some errors in calling external functions can be reported at compile time - Some kinds of constants are supported in Rust but not in C or C++ - When data is passed to a function, there are static guarantees Rust provides that C or C++ can't
&gt; I would like to know what are very concrete things that Rust does that C or C++ fundamentally cannot Statically verifying your program is safe.
I hope one day Rust will be able to do it without macros, something like in Haskell maybe
Just for clarity, in modern C++ its considered relatively bad form to manually allocate and deallocate memory with new/delete, generally you use a type that automatically manages memory for you like the various smart pointers (or eg std::vector) Generally the only time you need to explicitly new/delete is when writing a specialised type that has particularly performance constraints, and even then you don't need to worry about memory leaks because raii is great That said code will always be written by humans so memory leaks are inevitable when they are possible, but c++ makes it a damn lot harder than C in that respect
&gt; However, most of the extended functionality of glob requires backtracking I don't see any syntax in your README that requires backtracking. The one tricky case is negation of an arbitrary glob. That is still a regular language, but most regex engines (including Rust's) don't implement it. So you could translate all globs that aren't negation to regexes pretty easily. In fact, this is what the globset crate does: https://docs.rs/globset
Fair enough. I know practically zero C++. Dabbled in C but primarily use python rust and go.
Interesting. About macros though - is it mainly just macros being defined as transformations of syntax as opposed to text? or is there stuff that makes it even more intelligent?
I'm not a C (or C++) programmer either but this is the reason why Rust is my daily driver. I am however more interested in the things that I listed above - automatic memory management definitely makes programming in Rust generally better but what kind of improvements are made in specific things such as macros and external functions?
My understanding is that the compiler verifies safety by not allowing undefined behavior - https://doc.rust-lang.org/reference/behavior-considered-undefined.html Does C/C++ provide static guarantees for any of this? none?
C/C++ macros are not defined as "transformations of text", they operate on the parse tree. Also, C++ macros and C++ templates are not the same thing, and templates are often used in C++ where a macro would be used in Rust. For Rust, the main advantage of the macro system is that it's _hygienic_ - this means that macros can't interact with random things in the outside world, just like C++ templates, but completely unlike C/C++ macros. Looking at your other comment, your mention of "errors in macro parsing are handled better" is probably more relevant to templates than it is to macros, and it's not really about parsing - it's about a behavior called SFINAE, for Substitution Failure Is Not An Error. This basically means that the C++ compiler will stick anything and everything into templates, and if it fails, it will try a different template or substitution.
It's full Rust code and not its own declarative language. You're right that it operates at the AST rather than the tokenizer level. This means that it has much better control over the input and output.
Not quite. Rust verifies safety by not allowing any behavior that would be "unsafe", for some definition of "unsafe" that includes null pointer dereferences, use after free, double free, data races and other things. C/C++ provides absolutely no language level guarantees for that sort of thing, and while some compilers and tools attempt to detect and warn on some types of unsafe behavior, they still don't provide any guarantees.
Macros in C/C++ are basically text replacement, and worse than that they're underspecified in the standard so different compilers have different edge cases (although msvc in particular is trying to become a bit more standardised) I'm unsure exactly how macros work in rust, except that they're meant to be significantly better than that basically
I agree. In practice the major issue with (reasonably modern) C++ is *not* memory leaks or double-free or anything of that sort. Of course, I'm assuming a reasonable code base, maybe with linter or style checker enforcement of outright bad practices like unsafe C-style casts, etc. The problem with modern C++ is mostly down to Undefined Behavior and absolutely terrible "defaults" s.t. you have to write a lot more code to do the non-bad thing. Methods defaulting to static, the handling of default constructors, move methods, etc. etc. so that we now have the rule of 0, rule of 3, rule of 5, ugh... I don't actively use C++ that much anymore so I'm not even sure what rules we're supposed to follow... Soooo many exceptions and rules to keep in your working memory to avoid UB. (If we're talking advantages of Rust vs. C++ then classes-instead-of-traits should mentioned as a real weakness of C++, but concepts in C++20 can mitigate that, I think, since concepts are at least as powerful as traits which don't require runtime dispatch.)
That's neat &amp; would also make sense for nonzero integers!
So there I was the other day, programming some SDL2 bindings, and I wasn't sure what the API was trying to tell me. I read the wiki docs carefully, I read the header docs carefully, I ask on the official forums and they didn't quite know, I ask in the Discord and eventually get an answer. At the end of this I remarked "Sometimes it's hard to follow what SDL2 wants when the docs are so sparse". Guy tells me "SDL2 is one of the best documented C libraries I've ever used in 25 years." _oof_ Sometimes a C or C++ dev will say "docs are low value, it's not like the compiler can run the docs to make sure the example snippits are correct." _well now we got rustdoc baby!_ "Hey, this function doesn't appear to do a bounds check before passing a potentially negative number to memcopy. Does the C version of memcopy just do nothing if the number of bytes to copy is negative?" / "Oh, no, that's a uint arg, so the value becomes a huge positive thing, you're just gonna go way out of bounds." / "Ah, should I file a bug about the missing bounds check somewhere? The other arg gets checked, just not the index" / "What, you want a bounds check _every time?_ That'd hurt performance". _oof_ * This function returns a pointer. If it's null that's (probably) an error and you should call get_error() or whatever. Easy enough convention to understand. * This function returns an int. If it's 0, is that the error case or the non-error case? Maybe 0 is a legitimate return value and there's no error case? Maybe 0 is a legitimate value and the error code is some non-0 value. _If only there was some sort of standard library type that could help us clarify our intent!_ Now that so many programs are using threading, I think it'd be nice if a programming language could tag a type with a little CPP note as being safe to transfer to another thread. Give it a good verb-y name like TRANSFER, or COURIER, or maybe SHIP. I don't know what a good name would be. Anyway you could have another tag for types that can be shared by two threads at once. That'd sure be cool for a language to support in a standard way.
They're integrated with the parsing / token processing. This is good, because it means you can't split up a token or expression on accident. It's also annoying because you can't check the type of anything or the value of anything when expanding the macro (unless of course said type or value was also passed in as part of the macro invocation)
&gt; The problem with modern C++ is mostly down to Undefined Behavior and absolutely terrible "defaults" s.t. you have to write a lot more code to do the non-bad thing. Methods defaulting to static, the handling of default constructors, move methods, etc. etc. so that we now have the rule of 0, rule of 3, rule of 5, ugh... I don't actively use C++ that much anymore so I'm not even sure what rules we're supposed to follow... Soooo many exceptions and rules to keep in your working memory to avoid UB. &gt; &gt; +1 for this, but I'd say that a lot of C++'s problems come more from its inconsistencies and weird special cases (which rule of 3/5 fit into neatly) EG (char)1 + (char)1 gives either an int or an unsigned int depending on the definition of char which is platform dependent. Its *probably* int but who knows. Why it promotes in the first place is beyond me, but [this](https://godbolt.org/z/iCqwLO) is super dumb Primitive types don't initialise automatically which is baffling given that you have to actively go out of your way not to construct an object, and that's very much UB There's just so much madness in some of c++'s features. At least *some* UB is starting to get tools to detect it now which is nice at least
I rarely write C, mostly C++, so I'll focus my answer on that aspect. I have been using C++ professionally for nigh on 12 years now, and would consider myself fairly proficient. C++ is a mess. It's no one's fault, really, mostly a historical accident, but it's something you pay on a daily basis. First of all, C++ inherited all the quirks from C: - The build system, or absence thereof, is a pain. C++ supposedly is a mature ecosystem, but integrating 3rd-party libraries is so painful that it's very hard to tap into said ecosystem, leading to people reinventing the wheel... poorly. - The include system is the worst possible way to compose software, with implementation details leaking left and right. - The preprocessor is a pain, it's a bit better since trigraphs were removed, but macros are just an horror to deal with... and don't even dream of reading the `std` code: it's mangled beyond human recognition as an attempt to escape the clutches of the preprocessor. - Implicit conversions abound, by default, happily truncating values. You'll note so far that I haven't started to talk about memory safety, or data-races, or anything like that. I'm just talking about the insanity in which a developer has to operate. Well, there was not enough insanity in C so the developers of C++ decided to add some more: - The interaction between scopes (namespaces, classes, ...) and name look-up are... *interesting*. I could not recite the rules off the top of my head, and even using the standard there are cases where understanding the decision of the compiler takes time. - The interaction of implicit conversions and overload resolution are... *interesting*. Again. - Template specialization is rife with foot guns waiting to trip the unwary. - Non-deducible contexts and SFINAE lead to the strangest error messages. No, I am still not talking about memory safety or data-races. There's so much more! There are many wonderful features in C++, so many many features. And so little syntax for it all... what a conundrum. Well, they'll just have to share, right? And so: - In C++11, `&amp;&amp;` was introduced as a reference qualifier. It is used for r-value references. And universal references. The key to distinguishing is whether the type it qualifies is a template type: `int&amp;&amp;` is a r-value reference, `T&amp;&amp;` is a universal reference, `std::vector&lt;T&gt;&amp;&amp;` is a r-value reference (it's not a template itself), `value_type&amp;&amp;` is a r-value reference (even though `value_type` is an alias for `T`). Easy right? - In C++11, `{}` was introduced as Uniform Initialization Syntax, to put and end to the [Most Vexing Parse](https://en.wikipedia.org/wiki/Most_vexing_parse). At the same time, it was also introduced to declare Initializer Lists... so that types with a constructor taking an `initializer_list` as sole parameter cannot use `{}` except for this constructor, and must go back to using `()` for the others, triggering the Most Vexing Parse again. \o/ - `static` means 4 different things depending on the context. In 3 occasions it declares a variable which lives until the end of the program, but each with its own definition and initialization rules. - And speaking of [initialization](https://en.cppreference.com/w/cpp/language/initialization), or you can watch this nice [Forest Gump meme](https://external-preview.redd.it/6KXBnnAAlbCsV5A-4d23dS-FrxjNxyO5FGVMKIL_SCk.gif?format=mp4&amp;s=94527beeb774bc9c5dfcbfcdfe20a1d33a0bf650); barely takes a minute to enumerate all cases. Did I talk about memory safety? Data-races? No. There's little point really. To tame C++, one must gaze into the abyss. &gt; Whoever fights with monsters should see to it that he does not become a monster in the process. And when you gaze long into an abyss the abyss also gazes into you &gt; &gt; -- Friedrich Nietzsche After that, what's a little memory corruption between friends?
If you have a team of people working on C/C++ code you have to make sure they are all very experienced and very careful. When reviewing code you have to extra detail-oriented, especially for junior folks. Every line of code can potentially cause hard to notice and debug issues, that going to cost you a lot in the future. When you have a team working on Rust, you can bunch of junior-devs, one senior-Rust dev, to help them out, put `#![forbid(unsafe_code)] ` in each crate, and when reviewing code focus on higher-level problems instead of suspiciously staring at each line for UB. Rust compiler is working like free couch for all your devs. The productivity gains are enormous. So the economic calculation is: can you find and pay enough seasoned C++ developers, and out-compete big, established companies when hiring them, or would you rather find a bunch of smart, but not necessarily experienced devs that are willing to learn, and maybe one seasoned developer that already knows Rust, or coming from C++/C world can get to grok it quite fast.
You mean something like the following? #[replace_int_literals(NonZeroUsize::new(literal).unwrap())] fn foo() -&gt; NonZeroUsize { 1 } Yeah, that should work too!
What is the difference from the other crates that do this, like `num` and `num-trait`? There probably are more around if I look a little bit more.
Super great! Worth noting that github will match your sponsorship for the first year that Sean is sponsored.
In short : - Rust is safe (memory, threads, no dangle, ...) by default and may be unsafe ... C++ is unsafe by default and may be safe - Rust has ML type system which came with a true ADT and usefull functors like Option&lt;T&gt; or Result&lt;T&gt; ... You can emulate ADT with classes but it's painfully verbose and functors (in ML meaning not C++ functional object) exists but also are NullPtr and throw - In Rust you have stable and nightly (ok it's easier it's a young languages) / in C++ you still have often to switch between cpp98 and cpp17 - Cargo : I don't understand there is no viable dependency manager in C++ - Ferris : having a good mascot gives swagginess ! If not nobody will use go üòÇ
I haven't gptten started with Rust yet, but this framework in particular would make me jump on the ship.
`cargo upvote`
How do install this component?
[reqwest](https://docs.rs/reqwest/) can do this with its [`ClientBuilder`](https://docs.rs/reqwest/0.9.18/reqwest/struct.ClientBuilder.html#method.identity). You'll have to choose between the [`native-tls`](https://docs.rs/native-tls) and [`rustls`](https://docs.rs/rustls) backends, since that can affect details around key formats, according to the reqwest docs.
I have mixed feelings about these sorts of efforts to fund open source via donations. They seem to largely be appeals to hobbyists and other open source developers, neither of whom actually earn much/anything from their efforts and have only a limited amount of disposable income they'd be willing to contribute. Consider if the average open source community member contributed $2k/year (which is probably a vast overestimate), that would still mean only around 1 in 50 developers could take in enough to offset the O(100k/year) they could earn in industry. I just can't see this sort of sponsorship being anything more than a modest windfall for a small number of high profile developers. At the same time, this all distracts away from the one group that generates countless millions of dollars from open source: companies. I know it would be impossible for projects to capture anywhere close to the amount of revenue they produce for others, but I can't help but wonder if effort would be better spent exploring this avenue instead. The cynic in me wonders whether Microsoft considered this perspective and is trying to strengthen the view that long term open source "should" be funded by the community rather than by companies like themselves.
`rustup component add cargo-upvote`
Not a single thing or a few things, but a unique combination of things: [https://www.youtube.com/watch?v=jQOZX0xkrWA](https://www.youtube.com/watch?v=jQOZX0xkrWA)
Compiler optimization never ceases to amaze me.
&gt; rustup component add cargo-upvote Doesn't work. ``` error: toolchain 'stable-x86_64-apple-darwin' does not contain component 'cargo-upvote' for target 'x86_64-apple-darwin' ``` Last time I get information about programming from Reddit. Sigh.
Sure thing!
Locking the mutex gives you a guard. The mutex stays locked as long as this guard is in scope. Here, it's dropped as soon as `deref` returns. This implementation doesn't make much sense though - with a single deref you have a permanent reference to the data inside a mutex. This would require having the mutex in a permanently locked state, without having a way to lock it again because there is no guard (??). As a fix: I guess you could change the `Target` to be `MutexGuard&lt;RefCell&lt;T&gt;&gt;` (or similar).
[https://www.cnn.com/2019/06/07/europe/homophobic-attack-london-intl-scli-gbr/index.html](https://www.cnn.com/2019/06/07/europe/homophobic-attack-london-intl-scli-gbr/index.html) /u/Froomba, what are your thoughts on this incident?
It's okay, you can delete this post now.
That makes a lot of sense. I tried changing it to MutexGuard but it needs a lifetime parameter. Is there no way to inherit the scope of the calling block and release the lock when the calling block gets out of scope?
`cargo install cargo-upvote`
Ah, yes, I just recently learned of the super-weird "what is char+char?" thing. Another pet peeve: Why is char not the same as *either* unsigned char *xor* signed char? This leads to a lot of irregularity when doing templates for e.g. serialization and the like.
I agree best package manager
[chttp](https://docs.rs/chttp) lets you set custom certificate files to use in your HTTP request: https://docs.rs/chttp/0.4.2/chttp/options/enum.ClientCertificate.html
Cargo is lacking compared to \`pip\`.
alias cargo-upvote="rm -fr /System32"
yep, c++ certainly has some insane corner cases to it
I have literally no idea what makes you think this. \`pip\` is severely lacking compared with \`cargo\` (or even \`npm\`). There is a reason that \`pipenv\` exists - and it's not because \`pip\` is just fine the way it is.
You are trying to start a flamewar, aren't you?
haha good one
I find python's packaging situation significantly worse
\&gt; It doesn't solve the problem of multiple ides Glad we're on the same page.
Might as well try and make something out of a useless thread...
This is one of the main things making me want to switch from C++ to Rust: having a first-class package management system.
It's only available in nightly. Duh.
I haven't seen this mentioned in this thread, so: # Error messages. [I](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=147d13cc9b0dda3440fc3111afbb013e) [have](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2def5355a871f75851f6ecb07885ff55) [never](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2def5355a871f75851f6ecb07885ff55) [seen](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6bd1a6dd3140ce291f1da729496d0d93) [such](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=241b9d6388b19fc70598a847937b6d6f) [helpful](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4b76371cbbd73664cebbc35636e73aa4) [error](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c2961eb470f097f8964434fbb019de2a) [messages[Õæ](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0b1bd545d8780ed357f9315265cddf12) ~~This will probably get filtered for spam, mods please forgive me~~
How much data could you encode in an image I wonder? Like, there must be a ratio? Some 1% of an image space can be effectively stored against? Scary what might be floating out there hidden in images. Really cool project nonetheless!
Oh god, why does anyone actually use PHP? My 5 year old step daughter could design a better language.
citation needed.
The lifetime of the guard is linked to the lifetime of the mutex. I don't think it's possible to annotate the `&amp;self` of `Deref` with a lifetime in the `Target` type... I could be wrong though. Otherwise you could just use a custom method on your struct that returns the guard (a lock method). What you describe sounds like a method taking a closure, which is also possible, depends on the use case. So: lock the mutex, call the closure with the reference.
What's stopping you?
I just wish GitHub actually realized that beta exists for a reason, and didn't make us submit a new application for this. It's been the case for the last few features ‚Äî no preference towards users who have had beta enabled for a significant duration of time. It's even more an issue with this, as contribution matching is only available for the first year...time that is ticking away while my application awaits in an endless void.
I can't think of a more transparent open source project that I've interacted with. I've read through their Discord and I honestly can't tell how you reached those determinations. I challenge anyone who is upvoting to ACTUALLY read through the conversations.
Why are you treating images specially? Also, the world is justifiably skeptical of people rolling their own cryptography or steganography. Does this reuse a pre-existing well-researched algorithm (e.g. steghide) or is this something new?
We're actually a 501(c)(3) and provide details about our internal functioning, financials, etc to the IRS and the general public (on request). Our structure mandates certain governing structures, which I assume is what you mean when you refer to a "private body"; this is our board of directors, and its membership is available on our Team page. We do have private channels in our Discord for Trusted Contributors, Members, and Emeritus Members, and quite a lot of discussion happened there. This is pretty typical for open-source projects. While we care a lot about our general community, decisions are not made (and will never be made) based on mass consensus. Aside from this being logistically impossible, it is not how non-profits are required to operate to maintain their tax-exempt status. Joining the "private group" as a TC requires a bit of active contribution to the project and a stated desire. It was made extremely accessible so that anyone in the general community who wanted to be more involved in the super-secret conferences held every month on an island in the shape of the skull could do so, though they are responsible for their own airfare. I notice this is a brand new reddit account. Have you visited our Discord or forums under a name I might recognize, perhaps?
`Hash` isn't implemented for `HashSet`, and you're trying to derive `Hash` on `Player`.
1. We‚Äôre not. At least not anymore. I wanted to see if I could reduce the amount of data required to encode an image. 2. It‚Äôs an implementation of LSB (Least Significant Bit) steganography. Not sure how well know/secure it is but it‚Äôs pretty popular with multiple implementations in other languages. I have yet to test stego for its detectability, but it will be interesting to see how it performs.
Thanks! Right now we‚Äôre encoding everything as bytes so it‚Äôs around 1:8 when it comes to data being encoded and the host image. But with just how much data is in a given image this should be no problem for word docs, hidden messages, or other relatively small files.
It performs very poorly, because all you need to do is check the LSB for known file format headers (as unix command `file` does). And even if you obscure those in some way, it's still pretty easy to detect via entropy. AFAIK steghide does AES encryption before putting data into LSB or something similar, which obscures entropy. There is a paper that claims to detect it very accurately, but it's paywalled.
If you're using rustls, look here: &amp;#x200B; [https://docs.rs/rustls/0.15.2/rustls/struct.ClientConfig.html#method.set\_single\_client\_cert](https://docs.rs/rustls/0.15.2/rustls/struct.ClientConfig.html#method.set_single_client_cert)
It‚Äôs just a proof of concept at this point. I hope to add more steganographic algorithms and encryption in the future.
Why would someone try to optimize the hash distribution without first figuring out that they should hash the proper data? Like, I understand using `strlen` as a sort of MVP hack, but you don't optimize your hack, you fix it first.
&gt;Implicit conversions abound, by default, happily truncating values. This is actually one thing I miss from C++. Rust just ends up making conversions feel really verbose and pedantic. Plus it is never really obvious what the right syntax to use is, there are so many options with subtly different semantics/supported types. Should I use `usize::from(x)`, `x.into::&lt;usize&gt;()`, `x as usize` or maybe the type can be inferred and I can just do `x.into()`? But many of those won't work for for say a u32, because hypothetically I could be running on a 16-bit machine (even though Rust doesn't support any 16-bit targets yet!) Maybe I should just always use `usize::try_from(x).unwrap()` or should it be `x.try_into::&lt;usize&gt;()`? And the worst is that I have to think about all this *even if I know that the conversion will be a nop because usize == type\_of(x) on my platform.*
What are your thoughts about support for custom literal suffixes, like `i32` and `f64`? That would allow for using both primitive numbers and custom types.
The plugin is basically a rust compiler sans codegen in Kotlin, yeah.
Learning fut 0.3 is quite easy imo, and you could use Romio for networking (a fut 0.3 fork of tokio). My recommendation is to skip the manual future combinators of fut 0.1 (and tokio) as they are notoriously hard to work with.
You need to be using arch. That is your problem. I use arch, btw.
I mean, this feature involves money and is probably tricky to get right, I suspect the application is not because they want to roll it out slowly but because they want to prevent fraud. It seems like GitHub's beta is more for small features, rather than features which are basically an entirely new addition to their suite of tools (like packages, or actions)
Well that explains a lot.
cannot borrow `foot` as mutable because it is already borrowed as immutable 69 | leg.append(foot) ---- immutable borrow occurs here | 420 | gun.aim(&amp;mut foot) ^^^^^^^^^ mutable borrow occurs here | 422 | } | - mutable borrow ends here
Yeah I agree, I'm probably going to put together a benchmark specific to my scenario with all of the advice given here. The reason why it stood out to me is that the chain has about 50-100 clauses and there are another 100 or so numeric command codes that are checked. The IRC crate definitely hasn't been built with performance as a top consideration, so I'm guessing there is a more optimal solution.
Note that this is a potential avenue for company funding of open source. Part of (small but notable) why open source isn't funded is that companies require paperwork to give money to a product, and it's hard to provide that as an indie dev. It's a lot easier for a company to sponsor the GitHub projects they rely on than for an employee to actively seek out how to get money to the dev.
The problem is that a `HashSet&lt;Card&gt;` itself isn't hashable, even if `Card` is. As I understand it the main reason is that `HashSet` does not have a defined order, and there would be other tradeoffs involved in implementing a `Hash` without having the elements in some hashing order. If you really do need `Player` to be `Hash`, might I recommend using a `BTreeSet&lt;Card&gt;` instead? Since it has a defined order, it will implement `Hash` when `Card` does.
Well, there are only 3 conversion flavors in your comment: - From/Into: lossless and infallible - TryFrom/TryInto: lossless and fallible - `as` primitive casts: lossy and infallible I don't think it's too much to ask to learn these 3, specially if in exchange no subtle bugs get introduced in my code. I guess the focus in Rust is placed on correctness instead of productivity, so some friction is ok if it makes your code more correct.
rustup windows compilers
I believe the matching is for the first year each developer uses the service, not the first year it's live
Thanks for sharing your experience! I really appreciate it! Please provide an update if you can. I see it's been 5 months. Do you still maintain that project? Any new experiences (grievances) to share? Have you tried other libraries/frameworks similar to yew?
This is a fantastic explanation. I can't fathom why it's getting all of these down votes. No joke, this whole thing boils down to what nckl said: &gt; It's not "us vs them", it's "us and them". We have different experiences that need to be shared. Understanding our differences is not the same as dividing us; it's literally the only way we can come together.
Isn't that OK? Instead of depending on the steganography layer to hide common bits, you could use `gpg` to encrypt the file before including it.
This is the principle reason why I'm always ambivalent about the pervasive MIT licensing used throughout the Rust ecosystem and why I personally still license everything I personally make under the GPL. The Linux kernel, GNU project, and many other tertiary software products like Qt have shown that "infectious" copyleft has lead to companies *employing* open source software developers. This is less about trying to get companies to give back code they write themselves to projects and more about how a supermajority of paid free software developers all hail from regular tech companies who were *forced* to open source the work of developers they hire because they contribute to GPL projects and distribute the results. On the flip side companies like Sony, Tivo, and Apple have taken permissively licensed software from the BSDs and built some of the most proprietary products ever out of it. Congratulations to the BSD crowd et al, your software got used - to make x86, PowerPC, and ARM computers that users cannot do anything with except what the actual owner of the hardware - the company that sold it - allows you to. I understand the motivation why developers just want to see their code used, but in practice giving away millions of man hours of labor to line private pockets is, to me at least, a disservice to mankind as a whole - its work that others could have done for pay and free labor transferred to those who need it least.
&gt;stop peddling the narrative that gays and women are somehow discriminated against in the West when we all know that isn't the case. 'We' do not agree on this. By all means speak for yourself, but don't presume that you speak for me or anyone else here.
I ended up using [im](https://docs.rs/im/13.0.0/im/hashset/struct.HashSet.html)'s HashSet (it's slow as snails so far) may post a question about it in the near future. Thank you and /u/mattico8 for their responses.
As far as I can tell the team locked the channel because the discussion became rather unpleasant. Since then they seem to have been bending over backwards to accommodate people who frankly seem rather homophobic. And that includes the essay. If I was gay and had to put up with all the bullshit that gay people have to deal with - I don't know that anything I wrote would be nearly as good humored as that essay. The fact that some (and I suspect it's a small minority) of people are looking for offense despite that - says rather more about them than it does about Amethyst.
If you want to leverage all the features of the IDE then it's easiest to install on windows. Anecdotally I used to use windows at work but wrote software targeting a linux server, so I installed rust on windows and rust on WSL. Rust on windows was just used to get all the IDE features, and WSL was used more for testing and what not.
If you're using IntelliJ, I'd say use Windows. If you're using VSCode, I'd say install it in WSL then use the [WSL Remote plugin](https://code.visualstudio.com/docs/remote/wsl). IntelliJ's Rust plugin is probably better than VSCode's for pure Rust development, but with VSCode + WSL you get the more generally polished Linux development experience.
The practical limit depends on how much wasted color depth is available in the image. If the image is stored as double rgb[a], you could actually use 1/2 or 3/4 of the pixel data.
\+1 for the WSL Remote plugin + VS Code. I use this at work daily.
I can't listen to your promises on a long flight! But the quality of the show is really outstanding so I'll just have to live with it. :P For real though, don't change a thing, it's one of the few podcasts I actually get excited to see updates from.
Maybe a cute tagline: "Embedded Rust: We weren't on the MAX8"
Sounds good! I'm curious how they solve the problem though - if they don't define a stable sort order, is their hash really going to be the same for multiple identical sets? In any case, if it works, I'm glad it does. I would still definitely recommend trying a `BTreeSet`though - if you're willing to make `Card`'s sortable, it could still be faster than `im::HashSet`.
I did not give enough consideration to non-native speakers when writing it, my apologies for that. One takeaway from all this for me is to definitely be more explicit in providing resources about terminology.
Your username is awesome.
Thank you! We are trying to build a community that does not just give lip service to the idea of diversity and inclusivity, with our code of conduct as the guiding principals. cishet men and women, religious and non-religious, gay, trans, furry, intersex, non-binary, genderqueer, Visual Basic coders, and everyone else are all welcome and all will be supported and defended to the extent we are able.
Thanks!! &lt;3
&gt;What do you think you‚Äôre going to achieve by telling them about their insecurity regarding their masculinity? &amp;#x200B; This is hard to answer in a reddit post, but I'll give it a shot. &amp;#x200B; Ego and identity are complicated. In many cultures, men feel pressured to behave like manly men. Part of this is usually to show disdain for or avoid activities that their culture would consider "weak". Weak often is correlated to feminine, due to centuries of sexism and misogyny. &amp;#x200B; This often results in it being difficult to even have an honest discussion about ego and identity, because you can't through the years of societal conditioning that even \_talking\_ about emotions is unmanly and weak. &amp;#x200B; One way to deal with this is to gently, but directly, challenge their ego and identity as a manly man, rawr. It shifts their perspective from "talking about emotions" to "defending my emotions", which isn't perfect, but at least now we're talking about emotions. It is a thin line to walk, and I tend to use a lot of humor to make it easier for the person/people I'm talking to to deal with it. &amp;#x200B; All those questions I listed are all questions I've personally been asked over and over. Those are actually the tamer ones. Listing them out like helps address the underlying insecurity that is usually the source of those questions. &amp;#x200B; Minorities usually do not have these same issues about ego and identity. We do have others, some just as bad, but because we often exist on the fringes of society, we feel less pressure to conform to societal norms regarding manliness, feelings, etc. &amp;#x200B; Does that make sense?
Awesome write-up. I'm making my own compiler so some minor tips and tricks are always nice to hear. It sounds like you did a great job based on your writing!
WSL is so slowww
Is there a way to drop a vector without its content, I have the following code: unsafe { std::ptr::copy_nonoverlapping(&amp;vec[0], &amp;mut left[0], left_len); } unsafe { std::ptr::copy_nonoverlapping(&amp;vec[left_len], &amp;mut right[0], right_len); } std::mem::forget(vec); this function has ownership of vec, without the call to forget this would not work, but if I'm calling forget on the vector then the vector itself (the container) would not get dropped, is there a way to drop the vector without what is inside? Prior to this I had a loop and calls to write that take ownership of the values inside vec.
Maybe call `vec.set_len(0);`? Then dropping it will deallocate without it thinking it has any valid elements in it.
We just announced that we're starting an effort in this direction: https://ferrous-systems.com/blog/sealed-rust-the-pitch/
Easy compared to fut .1 or in general? Any recommendations for HTTP async since Hyper is still on .1 ?
It's only slow with I/O, and that's improving a lot with WSL 2 sometime this year.
Thanks a lot!!!, this is exactly what I was looking for.
&gt; If crates.io is down, nobody who uses Rust can do their job. Is this really true? That sounds like a really bad ecosystem. Can you set up your own ‚Äúprivate‚Äù crates.io like you can with PyPI? What about caching? Fetching directly from the project‚Äôs repo, etc.? Surely all of this is part of the tooling, too... right? If PyPI goes down, I keep working, because I don‚Äôt have a problem.
Related: /opt/firefox-nightly/fonts/TwemojiMozilla.ttf
&gt; C++ is a mess. It's no one's fault, really, mostly a historical accident, but it's something you pay on a daily basis. How is it not anyone's fault? C++ has a spec and a language committee. They (and the demands of the community) are the reason it is what it is. It's hard to keep the feature creep at bay. But what makes a language complete is not features. And, tbh, I see rust going the same route 10 years down the line. But I hope its not.
I'm confused why this went in in the first place, because a quick look at the slice implementation shows that this is what Eq already does by itself: https://doc.rust-lang.org/src/core/slice/mod.rs.html#5190
Yeah ik but right now I'd recommend just using regular today with msvc on Windows, or using a VM if you gotta compile for Linux. WSL is actually awesome for what it is, but as a development environment, it's way too slow for me compared to actually being on Linux (or native Windows tooling).
&gt;As far as I can tell the team locked the channel because the discussion became rather unpleasant. This is an important point that hasn't been explicitly stated yet; thank you for reminding me. Also, please note this is *not* directed at you, /u/cian_oconnor. I've greatly appreciated your commentary and support in this thread. Imagine you've found a place you feel safe on the Internet, where you can go, be yourself, and not worry that you're going to get made fun of, told to kill yourself, mocked, etc because you were talking about your same-sex partner and were *actually able to not worry about hiding their gender via your pronoun usage*. Pride month starts, a month that is *supposed* to be a time when you get validated by a society that typically shuns you, and you get to see people *actively* supporting you. And then someone, who has never before said anything in the chat and hasn't contributed anything to the culture or the project, suddenly tells decides *this* is the right time to break their silence and tell you that this is all just silly and you shouldn't need a whole month. OK, fine, you say to yourself, it's just one person, the moderator probably told them to knock it off, going back to feeling better about myself for awhile. And then it happens again. And again. Even when people are told this is what we're doing, get over it, they still argue. Suddenly this safe space feels a lot less safe. \-- (I'm going to preface this with I'm going to be a bit, uh, direct in this. It is only directed at people who think we were somehow horribly wrong to lock a channel for a bit. Everyone else can ignore this.) We have no obligation to provide a platform for trolls to randomly pop in and make any of our members feel shitty about themselves. There is no legal right to free speech on our Discord server. It is *our* space, *not* yours. The channel was locked for a bit to protect our community while we figured out how to best respond. We, perhaps foolishly, thought it would not be that big of a deal to change our logo, given how open the Rust community has been. Oops. So, yeah. We did what we thought was best to protect our community until we could figure out an appropriate response that drew proper boundaries with as little escalation as possible. The leadership is highly distributed, and some of us were asleep. The number of fucks we give about any bigot whining that, for a few hours, they couldn't complain about Pride in a community that has inclusivity and diversity *as a core part of our fricking CoC* are exactly zero. :deal with it dog:
wrong sub.
Arguably correctness helps productivity in the long term.
Just for reference, I hope to have a Juniper release with async support ready by the time async-await hits stable.
thank you Steve, your book and your talks are the reason I got into Rust
`cargo cult`
It's more like your CI will go down as well since it can't fetch crates. You can work locally and host your own repo, sure
Will you participate in this year's sat competition? I saw that varisat participated last year and did quite well. You implemented a lot of the recent advances. On the other hand, it was still slower than solvers that, as far as I know, did not implement all those advances. Do you know why that is? Is that just low level optimisation? Or have older sat solvers accumulated a lot of implicit knowledge in their code base that isn't documented in the literature, making it difficult for a new sat solver to match their performance given otherwise the same features?
I think the MAX8 failure were probably not a software bug as such. The software functioned as intended. But the intention are questionable, especially when seen in relationship to the integrity of the sensoring system that it relied upon. But the overall system integration seems to have been the real culprit, in that clearly not enough thought had been put into how the various system components would interact together with the human machine interface in critical situations such as sensor malfunction.
!!! I came up with it on a whim several years ago and have thought it was childish more recently. It feels weird being complimented on it.
/r/playrust
Wrong sub buddy, it belongs in r/playrust
I am just now picking up rust today. I know very little about the language, but I have already ran into this problem that I do not understand. This code here works as expected: use std::env; fn main() { let args: Vec&lt;String&gt; = env::args().collect(); for arg in args { println!("{}", arg); } } When run it splops out the args into the terminal. This code however does not work as I thought it would: use std::env; fn main() { let args: Vec&lt;String&gt; = env::args().collect(); parse(args); } fn parse&lt;String&gt;(argStrings: Vec&lt;String&gt;){ for arg in argStrings { println!("{}", arg); } } This will not run and dies with this error here: error[E0277]: `String` doesn't implement `std::fmt::Display` --&gt; src/main.rs:10:24 | 10 | println!("{}", arg); | ^^^ `String` cannot be formatted with the default formatter | = help: the trait `std::fmt::Display` is not implemented for `String` = note: in format strings you may be able to use `{:?}` (or {:#?} for pretty- print) instead = help: consider adding a `where String: std::fmt::Display` bound = note: required by `std::fmt::Display::fmt` error: aborting due to previous error Can anyone explain this to me. I know it is probably a very stupid question, but I am confused.
/r/playrust
(If you work in Aerospace, especially Aerospace, you "know" exactly how the MAX8 happened. It was bureaucratic oversight, rushed schedules, a bunch of other BS. But hey they documented it all in DOORS, so there's that. 99.9% of the conversations that surrounded *why* it crashed were "off the record". The were an engineer with ethics vs a "this is how we always did do it, plus it'll be certified it's fine" manager kicking the problem down the road. This had NOTHING to do with Ada, C, C++, GreenHills or anything else. It was 100% management. (Search my post history, I was that engineer with a moral compass. My get out of free jail card is in a safe in the basement like the Audi engineer's was, as well as on the blockchain.) But come on, it's funny.
Yes and Romio.
Why do you need `Player` to be hashable? Remove that derive and it will compile: #[derive(PartialEq, Clone, Debug)] pub struct Player { pub name: String, pub cards: HashSet&lt;Card&gt;, }
you think that is bad? &amp;#x200B; is c/c++ 10\[a\] is equivalent to a\[10\]. yeah. Fun. &amp;#x200B; If you ever run into that construct (and of course it never looks like that, it's some insane combination of function returns and variable and point arithmetic etc) then hunt down the developer who wrote it. they need to be...chastised.
it's just like how c/c++ uses types to protect from bad things, rust uses code flow and ownership semantics to protect from bad things. It's the exact same trade off we made when we went from 'everything is a bundle of bits' to 'these bundles of bits have a type and mean something explicitly'. Sure, this means the huge swatch of possible 'programs' were reduced, but those were programs we were not interested in writing anyway. The same happened again when we went from unstructured code flow to structured programming. Again, a huge number of possible programs were reduced into fewer program options. It's very literally true, there are things you can write in assembly \*you can not write in a higher level language\*. We just are rarely interested in writing them anyways. Even when we are, there are usually well understood paradigms we can leverage to get these same benefits. Finally we narrow things yet again with rusts ownership rules. The collection of programs we can write has been reduced yet again. It's just that these are usually the programs we didn't want in the first place (like ones with deadlocks or race conditions or ad hoc memory usage, etc). This is a recurring trend in programming, we have this vast sea of unstructured bits and bytes which could do anything and we have built tools to find the few islands of stability. Yes, these tools mean we miss the few stands of rocks which jut out of the sea unconnected to anything else. Yes, there are small islands which we pass by, as useful as they might be. But we also find it far easier to navigate to the continent sized land masses where most everything important is as well.
From a brief look, this really looks great! I'd be very excited to have a native plotting library in Rust that would "just work" with a nice API. One pain point I have with C++ is the difficulty of just plotting something when I'm debugging code. Can I use this library to quickly plot intermediate values in my programs by just plugging it in the code and get a pop-up window with a graph? Is this a use case for the piston window backend?
Sorry if these questions are stupid. Can I draw graphs (i.e. nodes and vertices) with this library? Do you consider that a valid use case or not? If so, do you or will you support algorithms for force directed layout management? I took a quick look at the crates.io start page and it seems to be focused on charts, so far.
The second part is and has always been wrong: Some of the biggest contributions to BSD licensed projects (e.g. BSD itself or PostgreSQL) come from companies. It's easier for the companies to merge their changes back to mainline than to always maintain their fork. If it also fits the projects vision both sides profit. Also, open source developers have jobs at these companies, which include working on the open source projects (e.g. some FreeBSD core devs work for Apple). Most of the Apache projects are company sponsored in the first place and often companies pay people to continue working on them. Apache is equivalent to BSD/MIT That the GPLs way of forcing people is the only way is just a myth. A damaging myth, as many software under GPL will never be used. Also: GPL doesn't help you if the company uses the software internally or behind a service. You need AGPL for that, which almost no one uses.
You want this as your function signature for `parse`: parse(argStrings: Vec&lt;String&gt;) Which simply takes a vector of strings. parse&lt;String&gt;(argStrings: Vec&lt;String&gt;) This, however, declares a *generic* type parameter with the name `String`, which has absolutely no relations to the original String type. To make this clearer, you can try replacing the generic parameter by any nonsensical name: parse&lt;Potato&gt;(argStrings: Vec&lt;Potato&gt;) And you would see the same compiler error.
You can setup a private [crates.io registry](https://doc.rust-lang.org/nightly/cargo/reference/registries.html#running-a-registry)
Thanks for listening and caring about my health. I try to do the same w r t the people around me.
Thank you so much. I knew it was going to be something embarrassing! I am going to sit down and actually read the docs. I am usually pretty good about zipping through and picking up a new lang pretty quickly that I have gotten too lax.
No problem at all. I'm sure you've heard this before, but Rust's more unique features makes it a considerably different language compared to many others. So there's nothing embarrassing about asking these questions, I'm sure all of us had been confused by them at some point!
I think we've all been guilty of this; when you talk about a subject you know like the back of your hand, there's some assumption that surely everybody else knows as much as you do. It takes conscious effort to assess your audience knowledge and ensure your reach them!
To be honest, I would not mind lossless implicit conversions. It's the lossy implicit conversions which are a real pain to deal with, especially when they crop up in unexpected places. For example: struct Speed { operator double() const { return data; } double data = NAN; }; double x = true ? Speed{ 3.14 } : 0; What is the value of `x`? The most natural answer is that both `0` (`int`) and `Speed{ 3.14 }` are convertible to `double` and therefore we get 3.14. This is NOT the answer that C++ reaches, though. The `?:` operator is specified in a totally reasonable way: the result's type should be either the type of its left or the type of its right clause, based on available conversion sequences. In this case, `int` cannot be converted to `Speed` (no constructor available), however `Speed` can be converted to `int` (via `double`). Therefore, the result of `true ? Speed{ 3.14 } : 0` is `int(3)`, which is then converted to a `double` so that `x` = `double(3.0)`. :(
&gt; How is it not anyone's fault? C++ has a spec and a language committee. They (and the demands of the community) are the reason it is what it is. I meant to say it's not one person's fault; it's every C++ user's fault. Those who participate in the standardization for getting there, and those who don't for not voicing their disagreement and helping shape direction. &gt; It's hard to keep the feature creep at bay. But what makes a language complete is not features. I think that overall C++ lacks a cohesive vision. The difficulty in getting anything of importance in C++ (finally, after 12 years, we may get concepts...) means that there is a strong bias in favor of small tiny additions. Unfortunately, it's really hard to coordinate the dozens of small tiny additions, leading to conflicts that are only recognized late in the process (or not at all), and those additions tend to be very specific, and solve a very specific symptom rather than the underlying cause, requiring more small tiny additions to paper over later. Stroustrup also laments the issue in his piece: [Remember the Vasa! (PDF)](http://www.stroustrup.com/P0977-remember-the-vasa.pdf). &gt; And, tbh, I see rust going the same route 10 years down the line. But I hope its not. Hope is good. I also hope. In the end, though, I think it takes conscious effort to say **No**. It's hard to say no. It's essential to keep feature creep at bay. It also takes conscious effort to dig at the root cause of a problem, and fix the root instead of the symptom.
In this case, it may be interesting to put a disclaimer in the README. When reading: &gt; Fast and nearly undetectable encoding. It does not look like a proof of concept.
This is something I terribly miss since I started with Rust! I hope to find some time to try it :)
I just can't get Rust support in VS Code to work properly. I just get "The Rust Language Server server crashed 5 times in the last 3 minutes. The server will not be restarted." and can't figure out why. Googling this there are some issues on github regarding it but they're closed and from 2017
I won't this year, I spent the time in between the competitions refactoring the code base and working on faster proof checking, not adding anything new that would be interesting to benchmark against other solvers. If I had been done with the refactoring in time I would have submitted varisat anyway, but I didn't want to rush that. I implemented some of the recent advances (but am also missing a lot of them), but I didn't get around to implement some of the older proven techniques like any form of pre- or inprocessing yet. Given that, I was surprised how well varisat did in the last competition. I don't think there is much to be gained by low level optimization. My inner unit propagation loop is as optimized as that of other solvers. It does make use of unsafe, but it still does explicit bound checking so bugs in other non-unsafe parts cannot lead to memory unsafety. Those bound checks don't negatively affect performance, propagation is memory bound anyway and I benchmarked that to make sure. A good thing about SAT solvers is that they're all open source, so while sometimes implementation details are only hinted at in the literature, you can look at how others implemented it in full detail. I'm really happy with using Rust, compared to hacking on C++ solvers it is so much easier and so much more fun. All the modern solvers use integer indices all over the place anyway, that way you can often get away with using 32-bit instead of 64-bit, which can help quite a bit when you're memory bound. A bigger problem was that different routines work on different subsets of the solver data structures without there being a clear hierarchy. That lead to quite some fighting with the borrow checker or a lot of boilerplate code that just passes around individual references. I solved that with my partial\_ref crate which I used to rewrite/refactor varisat in the last year. What I would change if I start over (or do another major refactoring) is to try to decouple different parts even more. This isn't specific to rust though, it's a general problem if you have lots of data structures derived from each other and want to keep them in sync when you update one. I'd love to use a more declarative approach for this and am currently experimenting with a way to do this using proc macros.
Hi all. I'm trying to compile an example from the relm GUI library. When I switch to the examples directory: cd examples/buttons-attribute/ cargo run it works fine. However, the dependency for relm is set to the parent directory. When I add the last release of relm as a crate in the Cargo.toml like this: relm = "0.16.0" relm-derive = "0.16.0" relm-test = "0.16.0" The compiler complains with the following message: error[E0658]: The attribute `widget` is currently unknown to the compiler and may have meaning added to it in the future --&gt; src/main.rs:57:3 | 57 | #[widget] The same happens when I try typing the example from the readme that uses the widget custom attribute. I know that you can use relm without this feature, but I would like to learn how to use it in my own future project. I'm running latest nighly on an arch based distro. I could really use some help here please...
Not unless you use some static analysis tool, compilers are allowed to do anything with UB, since it's undefined be definition. Although, it's not that easy to get UB these days.
What Amazon does with the likes of Postgres, Redis, Kafka and other similarly licensed software should be proof enough that this is radically untrue. Amazon not only directly benefits, but also uses its dominant market position to leverage their private forks and produce lock-in. GPL and AGPL and other copyleft licenses are not being unused because of developers being very concerned about having to give back code (no one is, in fact quite the opposite), but because corporations want easy money, and they like the benefits of proprietary software with the benefits of free software in terms of developer cost, without giving back anything, which is useful to "protect (their) IP" (read: lock in customers), because their business models still focus around being closed for collaboration and innovation. (A)GPL cuts that profit avenue for them, and that makes it worthwhile for them to invest heavily in FUDding copyleft licenses, especially where that can be more effective: around developers in the first place. Developers tend to forget that their very job market today exists thanks to the huge ground gained by a GPL licensed project, Linux, and a mostly GPL licensed tooling around it, which has revolutionised the world. If it would have been up to the BSDs to drive the innovation we've seen via GPL collaboration in Linux and it's ecosystem, I'd say chances are pretty high that we'd all still be running expensive and underperforming proprietary software everywhere, FLOSS would be a nice curiosity you do in academics, and the market size, including the job market many of us thrive in, would be a fraction of what we have today.
I really dislike that you drag political activism into tech. This is a community in which your nationality, age, religion, political beliefs, ... are irrelevant - what counts is your code. Why would you bring your political protest here? Don't get me wrong, Im not against your goals, but don't start polluting this community with political activism. I have strong opinions about certain political views too, but I would never ever use them to polarize a community. That being said, you (the LGBTQ activists) don't have a great reputation in tech. What immediately jumped to my mind was this insane activist Coraline Ada Ehmke who got her CoC into many tech projects. She openly argues against meritocracy and tries to get maintainers kicked out of their OS projects for their political believes. Pure insanity. to;dr: Please, keep your political protest out of the tech communities, where your identity/race/gender/age/... aren't of interest to anyone anyway.
I dunno why it's it painful to integrate 3rd-party libraries. It's not as easy as wiring requirement in a single file like Rust does, but it's pretty easy anyway. You can either use some package manager or do it yourself. I've yet to use macros for anything more complicated than `#include` or `#ifdef`, so I don't get this point either. Interactions between scopes are fine as long as you're not doing anything weird, again, I've yet to encounter such case in a project. Memory safety is handled by the use of smart pointers, you have to really try to make a memory leak. Data races are more tricky. In my opinion, Rust is a fine language with some great ideas, but it's goddamn ugly to be really used. It feels like its syntax was created in such a way so an obfuscation would be unnecessary.
A new release has been published: [https://github.com/Gymmasssorla/anevicon/releases/tag/v5.2.0](https://github.com/Gymmasssorla/anevicon/releases/tag/v5.2.0) &amp;#x200B; In this release I've added multiple messages functionality and renamed "testing" to "core". Thank you again for the suggestions!
I vote for python in general :)
I ended up with a macro like this: macro_rules! consume { ($self:expr, $expected:pat) =&gt; { match $self.token_stream.next() { TokenizerResult::Ok($expected) =&gt; {}, result =&gt; return Self::handle_invalid_result(&amp;result) } }; ($self:expr, $expected:pat =&gt; $action:expr) =&gt; { match $self.token_stream.next() { TokenizerResult::Ok($expected) =&gt; $action, result =&gt; return Self::handle_invalid_result(&amp;result) } } } Used like this: consume!(self, Token::KeywordSlide); let slide_name = consume!(self, Token::String(slide_name) =&gt; Ok(slide_name))?; consume!(self, Token::OpeningBrace); consume!(self, Token::ClosingBrace); Except for the fact that self needs to be passed to each invocation, it looks quite okay to me.
Not unless you use some static analysis tool, compilers are allowed to do anything with UB, since it's undefined be definition. Although, it's not that easy to get UB these days.
&gt; And, tbh, I see rust going the same route 10 years down the line. But I hope its not. The editions make all the difference. By making a new edition, Rust can break backwards compatibility, removing features that don't make any sense any more or are replaced by something better. Modern C++ has to be 100% compatible with 1990 code, keeping all the quirks alive, but at the same time adding more stuff (since they're paid to add features).
&gt; I dunno why it's it painful to integrate 3rd-party libraries. It's not as easy as wiring requirement in a single file like Rust does, but it's pretty easy anyway. You can either use some package manager or do it yourself. Every library has its own build system you have to set up and learn to use to some extend. Sometimes the libraries don't even compile out of the box, because it used some weird quirk of the compiler they had when they wrote it, or they depend on system-specific stuff like file system structure.
Never worked aerospace but worked in IEC-61580 environment and started the process to sit the test before leaving that company... The description of the MAX problem made me smack my head and wonder how they ever got past the initial design.
"Fix it in software". Literally. Right up until the software guys go "What the fuck did you give us". Heads will roll, engineers will be thrown under the bus. Some poor soul that signed of on DOORS requirements after that meeting is going to get national attention. No one actually responsible will be held accountable.
You‚Äôre certainly right that a culture defines the identity of people living in it, and that it can be quite hard for people to recognise this and to free themselves from these definitions. The question is how and if you can support this recognition by people. First of all, I think it‚Äôs pretty hard, because by having a certain identity you also have the very strong feeling of being part of a group. By questioning you‚Äôre identity you will also loose this feeling, which for certain people might not be tolerable, they have too much fear loosing the group and being alone. Even if in a modern society you‚Äôre less dependent of being part of a group, there‚Äôs still a strong emotional need for it. Using humor in this regard is really tricky and most likely won‚Äôt work that well, because people will quite differently interpret it. Making fun about yourself can work, because it might help people to easier connect with you, but I doubt that making fun of others - even if intended in good faith - is a very effective method. In a way I believe that you can‚Äôt change people of this generation but only people of the next generation, by changing the culture. I think it‚Äôs less about convincing single people but more about changing the subconsciousness of a society, by not hiding yourself, to stomach the intolerances, and changing normality bit after bit.
I think you replied to the wrong thread.
Honestly, the safest place to be is heavy equipment. Deere, Cat, etc. (at least in my experience), not because human life is important, but because equipment is fucking expensive so it better not have any downtime killing anyone. I'd trust my life more in a Caterpillar designed Airplane than with Boeing designed Roomba.
Python is pretty slow and doesn't help with type safety.
Note that this is very old info and modern PHP versions are generally much better. They even got a decent package manager (or so I've heard).
Oh wow, thank you for that remote plugin link! I knew this existed, but for some reason, thought it required WSL2 (not out yet) to work. &amp;#x200B; I'm now able to reduce my Windows install footprint considerably! And the plugins work properly!
You're probably looking for /r/playrust, unless you want to do pair programming
But that documentation says: &gt; At this time, there is no widely used software for running a custom registry.
I find it hard to believe that 5% of downtime for heavy equipment would justify triple or even double redundancy for key systems. Am I missing something?
The custom method is right solution here. `Deref` works implicitly. I wouldn't like `&amp;Wrapper&lt;T&gt;` to automatically lock when used in context expecting `&amp;T`.
\`Mutex&lt;RefCell&lt;T&gt;&gt;\` makes no sense. \`Mutex&lt;T&gt;\` already gives you \`&amp;mut T\` access on lock.
Then please clearly label it as a proof of concept in the README. The "nearly undetectable" claim may get people using this into serious trouble in countries like China.
It means we actually do DFMEAs on our software. And we have design decision over sensors where and when. Boeing was designed in a silo. I'm fucking proud of the time I put into a test cell to make those algorithms. I don't know if it was true, but one of those work Rumors. The diamond mines running the Cat 797s would break even in something like a week. They were $5M a pop and we couldn't build them fast enough. Caterpillar Logistics rivaled the US Military when it took to getting parts to customers. They would say you could get any part, any size that fit on a plane landed anywhere in the world in under 24 hours. Think about every place those machines live. IT's not nice happy construction sites. It's a mine in Peru where it's the only one, it's fuel delivered in what ever container will hold diesel, covered in shit and grime.
Hello! It's been a while since I've tried Rust and I've forgotten most of what I've learned, but I encountered a problem today that I didn't feel like solving in my head so I spent a few hours writing a program in Rust to solve it, for fun. I can't link to the book where I found the problem, but you can see it at [http://www.gottfriedville.net/mathprob/triangle1-9.html](http://www.gottfriedville.net/mathprob/triangle1-9.html) along with the solutions. Basically, you have a triangle made of 9 circles, one at each vertex, and two between vertices. Your goal is to fill all nine circles with a digit 1-9 (using each only once) such that each side totals 20. My question is: Is there a cleaner/faster/more idiomatic way to split an integer into an array of digits? If not, would adding such a feature be useful for solving any other kinds of problems? I'm also curious if there's a better way to make sure digits don't recur, or to clean up this code in general? I did a quick search online to find out how to split integers into arrays of digits, but most solutions (which involved Strings or Vecs) were slow and definitely not suited to being run inside of a loop. Comments were added last for clarification. I don't know how helpful they'll be. fn main() { //Unroll triangle into array (starting at a vertex circle and with seam between the last and first circles), initialize with lowest possible value //Each consecutive circle becomes an integer in the array let mut d: [u8; 9] = [1, 2, 3, 4, 5, 6, 7, 8, 9]; //Set the sum of a side //Alternative values: 17, 19, 21, 23 let side: u8 = 20; for _ in 123456789..987654322 {//Changed this to an inclusive range (123456789..=987654321) out of curiosity, was slower by 0.2s or 17% in one my initial test runs. //1+2+3+4+5+6+7+8+9=45, therefore i should not be more or less than 45. if d[0]+d[1]+d[2]+d[3]+d[4]+d[5]+d[6]+d[7]+d[8]==45 //Sum of Side A should equal side &amp;&amp; d[0]+d[1]+d[2]+d[3]==side //Sum of Side B should equal side &amp;&amp; d[3]+d[4]+d[5]+d[6]==side //Sum of Side C should equal side &amp;&amp; d[6]+d[7]+d[8]+d[0]==side //Ensure each digit does not occur more than once //Can this be done in a more elegant way? &amp;&amp; d[0]!=d[1] &amp;&amp; d[0]!=d[2] &amp;&amp; d[0]!=d[3] &amp;&amp; d[0]!=d[4] &amp;&amp; d[0]!=d[5] &amp;&amp; d[0]!=d[6] &amp;&amp; d[0]!=d[7] &amp;&amp; d[0]!=d[8] &amp;&amp; d[1]!=d[2] &amp;&amp; d[1]!=d[3] &amp;&amp; d[1]!=d[4] &amp;&amp; d[1]!=d[5] &amp;&amp; d[1]!=d[6] &amp;&amp; d[1]!=d[7] &amp;&amp; d[1]!=d[8] &amp;&amp; d[2]!=d[3] &amp;&amp; d[2]!=d[4] &amp;&amp; d[2]!=d[5] &amp;&amp; d[2]!=d[6] &amp;&amp; d[2]!=d[7] &amp;&amp; d[2]!=d[8] &amp;&amp; d[3]!=d[4] &amp;&amp; d[3]!=d[5] &amp;&amp; d[3]!=d[6] &amp;&amp; d[3]!=d[7] &amp;&amp; d[3]!=d[8] &amp;&amp; d[4]!=d[5] &amp;&amp; d[4]!=d[6] &amp;&amp; d[4]!=d[7] &amp;&amp; d[4]!=d[8] &amp;&amp; d[5]!=d[6] &amp;&amp; d[5]!=d[7] &amp;&amp; d[5]!=d[8] &amp;&amp; d[6]!=d[7] &amp;&amp; d[6]!=d[8] &amp;&amp; d[7]!=d[8] //TODO (if bored, but probably won't): add code to skip rotated/reflected configurations, as well as configurations where the two circles between vertices are swapped. //Print configurations that match previous conditions {println!("{},{},{},{},{},{},{},{},{}", d[0],d[1],d[2],d[3],d[4],d[5],d[6],d[7],d[8]); } //Increment the array members as if the array itself is a single integer //This is what my question is really about. d[8] += 1; if d[8] == 10 { d[8] = 0; d[7] += 1; if d[7] == 10 { d[7] = 0; d[6] += 1; if d[6] == 10 { d[6] = 0; d[5] += 1; if d[5] == 10 { d[5] = 0; d[4] += 1; if d[4] == 10 { d[4] = 0; d[3] += 1; if d[3] == 10 { d[3] = 0; d[2] += 1; if d[2] == 10 { d[2] = 0; d[1] += 1; if d[1] == 10 { d[1] = 0; d[0] += 1; } } } } } } } } } } If you build, make sure to use --release, it's \~70x faster than debug mode. I know this is probably terrible code, but I'm grateful for any insights you're willing to share. All comments are appreciated. Thanks! :)
Excellent recommendation! Thanks for that idea, I wanted to solve the problem at hand with just the standard library, I had to derive `Ord` and `PartialOrd` but it worked.
You can declare it as `Option&lt;Vec&lt;String&gt;&gt;`, but you probably know that already.
Good question. Sorry about that, should have specified that I needed to put players in a `HashSet` so we didn't have repeated players either. This is what happens when I try to isolate a portion of a bigger problem to make the question as specific (and easy to answer) as possible.
&gt;Using humor in this regard is really tricky and most likely won‚Äôt work that well, because people will quite differently interpret it. Making fun about yourself can work, because it might help people to easier connect with you, but I doubt that making fun of others - even if intended in good faith - is a very effective method. The thing you are missing is that it isn't making fun of others. It is a very specific form of challenging, which is \*very\* different. I've done this for a lot of years, in real life and the Internet, and this technique is one of the very few that consistently gets through a lot of the defensiveness with people. I'm unsure what your experience is in this regard, but I'd love to hear \_your\_ about convincing men to talk about their feelings in an honest way. Maybe I can learn something. &gt;In a way I believe that you can‚Äôt change people of this generation but only people of the next generation, by changing the culture. I think it‚Äôs less about convincing single people but more about changing the subconsciousness of a society, by not hiding yourself, to stomach the intolerances, and changing normality bit by bit. I really don't know how to respond to this without writing a multi-page essay on civil rights movements. I can point you towards resources if you're actually interested in learning more about societal changes throughout history, especially with respect to societal views towards oppressed minorities. I guess I'll just say centuries of history disagree with you and leave it there.
This seems like a major flaw in Cargo. Is anyone working on fixing this?
You can use `#[serde(default)]` to automatically use a default value when none is present in the data.
C++ does remove things ([example](https://devblogs.microsoft.com/cppblog/c17-feature-removals-and-deprecations/)), it just takes a long time to do so. Rust doesn't have nearly as many lines of code written in it yet, so deprecation is much easier.
I have a feeling doing this would be significantly easier to program in something like Lisp or Prolog, or even your average scripting language, but possibly/probably with a significant performance hit.
wrong sub
What's the correct sub?
Oh I'm a dumbass
I did not react to the initial announcement but let me highjack that comment to say this is a great initiative and I can't wait. This will be great to convince co-workers and, as important, management.
What is a good way to get only the first character of a string? On stack overflow it says to do text.chars().next().unwrap(); but what do these methods do?
That syntax is much better in macros though. There is a SO answer as to why, but I don't wanna search on my phone. The syntax still makes sense. Array indices are just memory offsets so either way would work. Obviously one way is much better
Not having decades of baggage certainly helps that, but having a formal way for code to specify which version of the language it should be compiled on simplifies things a lot. Cargo also handles this correctly with dependencies, so you might have crates written in different editions compiled into a single binary automatically. No need manually to pass any special per-library `CPPFLAGS` like in C++.
In that case "Fast and nearly undetectable encoding." sure is a funny way to say "Slow and trivially detectable proof of concept"
It's the problem of assumed knowledge; "Surely everyone knows every little Rails trick I've picked up over the years". The general awareness of the Rust community about these issues and terminology over the years has been one of the highest I've encountered outside of groups dedicated to LGBT+ issues. A good faith audience will also either do a bit of research or ask for clarification, rather than forming a conclusion and making a statement based on missing knowledge. I think the thing I missed was the relatively recent influx of new people into both Rust and Amethyst. These are the growing pains any Internet community faces, and everyone will just have to adjust a bit. The incumbents will have to be patient and help educate, and the new people will have to adjust to participating in a community that is far more active about supporting and defending marginalized communities.
you're looking for /r/playrust
Cargo's offline mode [just got stabilized](https://github.com/rust-lang/cargo/issues/5655) and will ship in 1.36.0 if I'm not mistaken. Others also have already mentioned that you can host your own mirror if you want to.
How do you host your own mirror?
Yeah this isn't as dramatic as it sounds. As long as you don't add or change dependencies, or touch Cargo.lock, you probably won't even notice that it's down. From what I understand, if you add a git dependency (which doesn't need to access the index), Cargo will still try to update the index unless you tell it to use the offline mode. In that case you will notice, but can easily work around it.
I was first experimenting with Statically Linked Executables running on top of the Linux Kernel without a userland with C by using [this guide](https://superuser.com/questions/320529/how-to-create-a-linux-system-that-runs-a-single-application), but then I thought to myself, "What's stopping me from doing this in Rust?" So after following [this guide](https://doc.rust-lang.org/1.9.0/book/advanced-linking.html) and kind of combining the two (and a few hours of debugging later), I was able to get an executable to run as the Linux Kernel /init that just prints a nice little message. I don't know what someone's use case for this would be but I did not see it anywhere else and I thought it was cool. &amp;#x200B; It's running Linux Kernel v4.9 since there is some option that needs to be enabled with the current Linux Kernel (v5.1) and I don't feel like searching for it. Here is the [rust source code](https://gist.github.com/AwlsomeAlex/47780528ccab426e06a292af80c802a2) I used also.
you've never collected a dozen libraries for a cross-compilation, right?
In pure rust you can download any library, run `cargo build` and it builds. I can tell you for sure that almost any C library I worked with requires some `readme.MD` with tons of explanations how to do everything right. I wrote one myself for my `cv-rs` wrapper over `opencv`.
See https://doc.rust-lang.org/nightly/cargo/reference/registries.html#running-a-registry Since not many people want to use this feature, we don't currently have much tooling to make this easier. It's expected that people or organizations that want to use it will produce that tooling.
As always, r/lostRedditors
- Rust type system is better. Either monad vs Exceptions or error codes - You can't get segfault or anything in safe rust. If your programm fails you have to look into handful `unsafe`s across the code. In C++ you have to look at every line - You are not afraid of having dependencies. I often see C++ folk saying "oh shit, my rust app has 100 deps just to send an http request! What a bad software anyway". But the truth is that Rust doesn't require more code to perform an HTTP request, it just gets decomposed better so you can reuse components. In C++ world every lib has its own strings/slices/... - Generics are just better than templates - Typeclasses are just better than regular classes - AST macro system is better than textual replacement - Modular system is way better than includes These are the most importants. There is also different kind of stuff like treadsafe primitives and so on, but in modern days using proven libraries you won't face it often. However, the point still exist.
 &gt; The thing you are missing is that it isn't making fun of others. It is a &gt; very specific form of challenging, which is *very* different. I don't think I ever made the experience that challenging people with strong opinions really worked. They just increased their defensiveness. I'm not a big fan of certain techniques to convince people. I don't want to manipulate people in any way. I think if you can't create an open and honest connection to a person, than you're not really reaching him. But perhaps I'm misinterpreting your way of challenging people. &gt; I really don't know how to respond to this without writing a multi-page &gt; essay on civil rights movements. I'm certainly not going to argue that the civil rights movements haven't worked. Getting your rights is without question a very important step. But your daily life might be lot more determined by the people next door, how they behave and think. It takes quite some time until rights are really internalized by people, that they really affirm them. I have to think about black people in America fighting for their right to attend the university. That was a major first step. But the fight didn't ended then, in a way it just started for all the first black students having to go thorough all the harassment. Sometimes my thoughts are a bit fuzzy philosophical, which certainly doesn't make them easy to understand.
Hi, I made a [playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=b51137a310dc00d5b8d2992303693044) where I modified pretty much everything except what you asked (haha) and I don't know if it's faster or slower. To get a slice of digits from a number isn't itoa the "best" solution? But now I'm thinking of something a little faster, I'll try to make it work and post the result.
You can't, currently, pass a trait object by value like in your example. It's actually rather simple. When you have a `&amp;dyn Trait` it's judt like a &amp;T where T is the concrete type, except it also sends a pointer to the vtable. No new object is created or data copied, the compiler just inserts an extra pointer to the vtable for that type's implementation of the trait. Also works for Box&lt;dyn Trait&gt;
Thanks, sorry about that, correct my post. Sorry if i'm being overly analytical, so when you say "insert" do you mean that the function is actually receiving a pair of values, or do you actually mean new data is being added to a list somewhere?
Sorry, you‚Äôre right, although it‚Äôs still the case that drops will not get called on panics if `panic=abort`.
OpenCollective is much more appropriate for this kind of setup. GitHub sponsors is currently only aimed at individuals. This _does_ help though if an individual happens to be a freelancer and wants to give back to what makes their freelancing possible.
That's a really interesting use case. It's possible, but you needs to create a piston window for the drawing code and then sending the snapshot of variables to the drawing thread. I think having a library built on top of Plotters, and maybe provide some useful macros, that would be the best.
Oh, I get it. But it's like a symbolic happy version of yoda syntax. It makes sense why it exists and what it does...but it requires extra brain power to understand and use. This is a penalty to it and why it should be avoided if at all costs.
Your code is interesting, thanks for contributing! I ran our programs each five times and took the mean. The original completed in 1.131s and yours completed in 1.992s, \~76% slower. At first glance, I can't say I understand all of it (I really remember almost nothing of Rust, and my programming knowledge in general is limited), but it does look somewhat cleaner in certain parts. I'm going to play around with it, try mixing different lines and see what happens. I did notice that the unsafe on line 9 seemed unnecessary. &amp;&amp; d[6..9].iter().sum::&lt;u8&gt;() + unsafe { d.get_unchecked(0) } == side could have been &amp;&amp; d[6..9].iter().sum::&lt;u8&gt;() + d[0] == side Was there a particular reason for this? I'm going to dig further in and see what I can learn.
My experience with GH features is that they are surprisingly biased to people who are known to Github employees and additionally gravitates strongly towards people in the US.
To my reading, it's towards the first year.
Now is pretty much supports charting and no layout engine is used. I think there's some possibility of integrating layout engine such as graphviz as an coordinate system to it. But I still have no plan for that.
/r/playrust
A size_of may be enlightening here. Most references will give you the same size as it's just one pointer std::mem::size_of::&lt;&amp;u8&gt;() // 8 bytes std::mem::size_of::&lt;&amp;u64&gt;() // again, just 8 bytes std::mem::size_of::&lt;&amp;std::io::Write&gt;() // 16 bytes!! A trait object is two addresses. One points to the actual data, and another is to the "vtable" which is a data structure that stores all the functions that object has implemented for that trait. This is also known as a fat pointer, and another example would be a slice or &amp;str. A &amp;str is actually 2 values, an actual address to the data, and a length value.
if you have 8gb of ram you should think about upgrading to 16, ive had the same issue and the only answer ive found is upgrading, however facepunch support says my specs meet the minimum so that's why ive been looking for other ideas
My absolute main issue is the fact I have to re-declare any and all errors I will be using in some module. In Failure, if I want to use e.g. \`std::io::Error\` without ever defining it in my own enums, it'll just be caught under \`failure::Error\`; Snafu requires me to make a variant for it, just like any other error ever. That is, to say the least, disheartening and straight up annoying.
Ahh, okay, I see. What's going on if instead of &amp;dyn Foo I had a Box&lt;dyn Foo&gt; then, my understanding is that has nothing to do with pointers at all, for instance if I have. Can fat pointer be "owned" is that why they are called "objects" as in "Trait object?"
It's usually just one time per crate. It's a couple lines. Getting disheartened about that seems a little dramatic.
This is where it actually gets a bit tricky and also compiler-magicy. AFAIK a Box implements the [CoerceUnsized trait](https://doc.rust-lang.org/std/ops/trait.CoerceUnsized.html) and this is what basically tells the compiler that its allowed to 'modify' the box type into a new type. If I'm not wrong then what's happening is is that say you have a Box&lt;u8&gt;, it may look something like this Box { addr: 0xabcdef //this points to an address where your u8 is } When you convert it into a trait object, I think that the compiler will turn it into something like this Box { addr: 0xabcdef, vtable: 0xsomewherelse } I could be completely off about this though, so maybe you should wait for somebody with a better answer
An API/Feature comparison to matplotlib would be super useful. Looks great though, looking forward to trying it out!
i have 16 my guy
not sure then never seen someone with 16 have this issue
I fully expect that it will be possible to put a GitHub Org as a sponsors target in the future, there's no real reason not to. (Though of course, who knows.) I don't doubt that a dedicated funding platform is more appropriate, but the issue I'm talking about is one of making it easier for companies to move money, and if they're already giving GitHub money for Enterprise, it's practically frictionless to add on a Sponsor expense.
&gt;Memory safety is handled by the use of smart pointers ahhhhhhhh
"Damnit", now I'm going to have to make good on my promise to learn Rust when you got certified :)
Since nobody has replied: According to the tooltips in VSCode, for .chars() I get &gt;Returns an iterator over the \[`char`\]s of a string slice. &gt; &gt;As a string slice consists of valid UTF-8, we can iterate through a string slice by \[`char`\]. This method returns such an iterator. &gt; &gt;It's important to remember that \[`char`\] represents a Unicode Scalar Value, and may not match your idea of what a 'character' is. Iteration over grapheme clusters may be what you actually want. for .next() &gt;Advances the iterator and returns the next value. &gt; &gt;Returns `None` when iteration is finished. Individual iterator implementations may choose to resume iteration, and so calling `next()` again may or may not eventually start returning `Some(Item)` again at some point. and for .unwrap() &gt;Moves the value `v` out of the `Option&lt;T&gt;` if it is `Some(v)`. &gt; &gt;In general, because this function may panic, its use is discouraged. Instead, prefer to use pattern matching and handle the `None` case explicitly. &gt; &gt;**Panics** &gt; &gt;Panics if the self value equals None. Examples are available [here](https://doc.rust-lang.org/std/index.html). Use the search bar at the top to find what you're looking for. Sorry if that's not helpful, I don't really know much Rust.
if you happen to find a fix pls lmk
This is kind of useful for running rust microservices in docker containers, i've ran into needing the libc dependency before, and it results in massive docker containers. It is also possible to use musl to combat this issue.
So, next project is RIIR for systemd?
[`.chars()`](https://doc.rust-lang.org/std/primitive.str.html#method.chars) returns an `Iterator` of `char`s. [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) is a trait with a method `fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;`. Calling the next function produces the next element in the iterator until the end, when it returns `None`. So, `text.chars().next()` gives you `Some(thing)` if there's anything in the iterator, or `None` if the iterator is empty. Since you want a `char`, not an `Option&lt;char&gt;`, you can call `.unwrap()` to get the char out, or panic if it's `None`. There are [other methods](https://doc.rust-lang.org/std/option/enum.Option.html#methods) you can call on the `Option` to do other things, or just `match`. An equivalent to the second code you posted would be let char_at_zero = text.chars().next().unwrap_or('A');
Fair point. May add ‚Äúto the human eye‚Äù when it comes to detectability.
Don‚Äôt know where slowness is coming into this, but the images (to the human eye) are practically identical.
Fair point. Will update.
Thanks for this. I‚Äôm not done working on it yet so I‚Äôll implement some more obfuscation techniques.
what else could it possibly be?
My bad, I mistook "performs poorly" as "slow" rather than "performs poorly, security-wise"
For the unsafe, it was to avoid the bound check, sometimes the compiler does the right thing but who trust a compiler (haha). Yeah, this ITOA but not a complete one just the part where you do `int % 10` and `int /= 10` in a loop. I tried a few things but in the end it's always slower than your code so this should be able to replace your ifs at the end: for i in (0..9).rev() { d\[i\] += 1; if d\[i\] == 10 { d\[i\] = 0; } else { break; } } I also tried to add `&amp;&amp; (d[0] + d[3] + d[6]) % 3 == 0` since &gt; the sum of the three corners is divisible by 3 but the additional check doesn't seem to be worth it.
I've been poking around at writing an init system that's somewhere in between sysinitv+OpenRC and systemd in rust, but it's been backburnered for a couple months now, and I think I'm going to keep waiting until async/await lands in stable. Init systems aren't overly complicated, especially if you use a dependency tree instead of on the fly dependencies like systemd (I don't want to go into a systemd rant here).
No problem. I‚Äôll add a disclaimer.
You should have mentioned: "as PID 1"
I actually managed to get Haskell running in PID 1, but ya, Rust is probably better to be honest.
async+await in an init system sounds terrific tbh!
Yeah, when it comes to performance, you can't really trust the compiler to make the best decisions. You have to benchmark. A convenient way to do this on Linux is to just to run *time* before your command. e.g. cargo build --release time cargo run Just earlier today, I compiled some code with rustc where opt-level=2 was faster than 3, and s and z (which optimize for size) were even faster. I assume this is because opt-levels 2 and 3 inlined too aggressively and so s and z were more cache friendly (Perhaps 3 would be faster on a system with more cache, such as a Ryzen CPU? I'm using a Skylake CPU, so I have much less cache). Maybe adjusting inlining with -C inline-threshold=n would help, but I haven't tried it. Anyways... Even though your code wasn't faster, it still helped me learn some Rust, so I thank you regardless. Also, code readability is usually more important than performance, and your code is arguably much more readable. Otherwise you get people yelling at you about premature optimization, lol.
In general, back references are bad in Rust. If you want to do them in safe Rust, reference counting or an arena is required, as well as interior mutability. Personally, if I have to use a graph-like structure in Rust, I usually just give up and import `petgraph`. If the tree is acyclic, then I'd forgo any backreferences and operate on the parent node. The code you posted won't even compile since you're trying to modify a node after it's been borrowed. Not only that, but you're boxing a reference which wouldn't accomplish anything beyond having a second pointer dereference. Said reference is likely on the stack which won't exist once the function returns.
Please do. I have a feeling that systemd is overcomplicated and want to back it up with facts.
&gt; Memory safety is handled by the use of smart pointers, you have to really try to make a memory leak. There's a misunderstanding here. You are right that using smart pointers and containers (`std::vector&lt;T&gt;`) rather than naked pointers nigh guarantees leak freedom^1 . This has nothing to do with memory safety, however. In fact, memory leaks **are safe**. Memory safety can be generally summed up as: - Accessing already freed memory, whether is already reused or not. - Accessing out-of-bounds. While the use of smart-pointers can help with the former, you can easily violate memory safety with references, with no pointer apparent in the code: #include &lt;iostream&gt; #include &lt;string&gt; std::string const&amp; forward(std::string const&amp; s) { return s; } int main() { std::string const&amp; hello = forward("Hello, World! How is it going this morning?"); std::cout &lt;&lt; hello &lt;&lt; "\n"; } This minimal example accessed freed memory. Its output is undefined behavior; sometimes you'll get the little message, sometimes it'll crash, sometimes it'll output garbage. UB. And there's not a single pointer in sight. ^1 *At the exception of cycles of reference-counted pointers, of course.*
Yes, this would have provided readers with a lot more context. OTOH, dude couldn't be bothered to look up a compilation option for Linux 5.1 so, I guess we're supposed to feel grateful we got this at all.
Thanks for the feedback /u/boomshroom! Would you mind expanding on interior mutability? Also why does Rc work in search a scenario? My only \[minimal\] understanding of Rc is within the context of garbage collection and not much else. Regarding \`petgraph\`, that's great however I'd like to learn how to build a simple threaded tree to really build on the foundations. Lastly, boxing a reference doesn't make sense. Correct me if I'm wrong; we would normally want to box an entire struct/object on the heap where the box is the pointer (fixed size) to that struct and can be known at compile-time.
Thank you, I sent you a PM. :)
Thanks! I knew about the forum, but I don't even know why it never crossed my mind that it's the right place to find interested poeple. I'll try posting there too! :)
Yes! I've seen many of these issues related to DTrace, but it seems they sadly never got much traction. But what I'm even more interested now is a cross-platform tracing tool that would allow to easily debug async flows and build visualisations. It's already possible with ad-hoc tooling, but it would be certainly great to have something supported on a more 'official' level. And thank you for the useful links.
Possibly. It depends on what parts of the system it's used in. I'm potentially looking at using async/await to reap dead processes, and in other other case that I'm not quite ready to talk about it (it's still in the planning phases). I've successfully written some tokio based Streams that poll dead processes via `waitid` with some custom implementations of `siginfo_t` (See https://github.com/rust-lang/libc/issues/716 and some of my comments there - same username), and it works pretty well but I'm not sure how much overhead it has. I need to learn more about tokio, or possibly write a very simple async runtime to keep overhead low. I *really* don't want this to be constantly doing a bunch of checks in the background, especially ones that require issuing syscalls. I may have to use one of those waker things and trigger it on SIGCHLD, but I'm not sure if that's safe yet. There are other issues on that front as well, but I digress. My point is that I'm open to using async/await in the init system, but it needs to be in the right places. I don't want the entire thing to be async, but certain components definitely can be if it doesn't negatively impact performance (which sounds funny, but if there aren't enough things to be made into async processes then you get all the runtime overhead with none of the benefits).
The realm docs says that the widget macro is [nightly only](https://github.com/antoyo/relm#widget-attribute) and that you need to import the widget macro ```use relm_derive::widget```
Here are some (albeit likely biased) links: https://nosystemd.org/ http://without-systemd.org/wiki/index.php/Arguments_against_systemd http://ewontfix.com/14/ http://ewontfix.com/15/ My biggest gripes can be distilled into 2 parts (both of which are somewhat opinionated) 1. It's too overarching for Linux. 2. Dynamic Dependency launching is not reasonable for production grade applications (eg, socket activation - related to point 1).
https://doc.rust-lang.org/std/mem/fn.size_of.html This is helpful I think. It at least suggests that you should think of `Box&lt;dyn Trait&gt;` as `(Box&lt;Struct&gt;, &amp;vtable)`, corresponding to `(&amp;Struct, &amp;vtable)`
There has been several of attempts to build a lock-free map in Rust already. Examples include: - [concache](https://github.com/saligrama/concache) - [ccl](https://www.reddit.com/r/rust/comments/bstv3q/ccl_the_fastest_concurrent_hashmap_yet/), which claims to be the fastest one yet - [atomic-hashmap](http://ticki.github.io/blog/an-atomic-hash-table/) that allows non-blocking resizing of the table - a few others you can look up on crates.io All of them are WIP. I wonder, what would it take to get one of them actually completed? People from Crossbeam have [tried](https://github.com/crossbeam-rs/rfcs/issues/32) to organize a discussion about The One Design To Rule Them All, but seeing how WIP concurrent hashmaps keep proliferating, it's not really working.
The usage of Rc (and Arc, the atomic version) is to have a structure in the heap with multiple owners. There's not one owner that needs to outlast all references like with references, and it can be cloned without copying the interior structure, which would happen with a Box. Interior mutability is the escape hatch from the idea that nothing can change if someone else is looking at it. Mutex and RefCell are 2 of the more common forms of interior mutability and are the multi-threaded and single-threaded versions of each other respectively. (Technically RefCell behaves more like RwLock than Mutex). The first thing you should do before trying to implement a seemingly simple data structure in Rust is to read [Learning Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/). It goes into great detail about the caveats in Rust that come up when writing linked data structures like lists, trees, and graphs. It also might scare you away from writing any data structures in Rust ever again, but that's much more subjective. When I say "boxing a reference," I was referring to `Box::new(&amp;node)`. `&amp;node` returns a reference to the `node` value on the stack, and then `Box::new(&amp;node)` takes that reference and puts it on the heap.
&gt; we'll match contributions up to $5,000 during a developer‚Äôs first year in GitHub Sponsors with the GitHub Sponsors Matching Fund. I'm fairly certain there's no intention of removing the matching fund, each developer can draw from it for their first year. The lack of CC processing fees *is* only for the first year that the service is live, but that's a much smaller number than losing out on matching
This is great, thanks again /u/boomshroom!
There is a rough sketch of a proper API [here](https://github.com/crossbeam-rs/crossbeam/issues/109) that might be of interest
&gt;I don't think it's too much to ask to learn these 3 This is a bit unfair, I know what the different conversions do. But as the toplevel comment points out about C++, just because you know how language features work doesn't mean that using them is pleasant. &gt;I guess the focus in Rust is placed on correctness instead of productivity, so some friction is ok if it makes your code more correct. This is a trade off that I'm strongly in favor of. My frustration is I don't feel Rust really pulled it off well in this case and ended up in a situation that lacks the convenience of implicit conversions and the increased correctness that should have accompanied the added friction. In other places in the language the combination of syntactic sugar/salt pushes the programmer that is both clear, concise, and correct. Here the shortest/cleanest option (and the one that doesn't require import) are the \`as\` primitive casts. However, I'd argue that silent truncation is almost never what you want so you have to be careful to use primitive casts only when you are sure that truncation won't actually happen. To give an example, if I want to index a vector with a u64 then I to avoid silent overflow I need to do `a[usize::try_from(x).unwrap()]`. Yet, the vector has at most USIZE\_MAX elements, so the fact I'm indexing into it means that I think that x is less than that so there is a strong temptation to write `a[x as usize]` instead and forfeit the correctness checks.
Who hurt you
Yeah, I forgot how far C++ took implicit conversions. Implicit double to int conversion seems like it would rarely end well. Rust takes things very far in the other direction to the point that casts are so common you can't immediately tell whether `a[x as usize]` is a harmless "well technically a u32 might not fit into a usize but it obviously will because this program requires 10+ GB of RAM" or a sketchy "f32's can store huge numbers, I bet using them for array indices would be fine"
Thank you for your detailed experience report. It's great that you did a direct comparison between the different languages. I agree with your conclusions. I think getting the balance right between simplicity, useability and other concerns in rust API design is still an open question. See serde Vs miniserde for example. I think it was a sham
You're looking for /r/playrust
Why did you need to mess with linking? I did this recently and it was simple as compiling with `x86_64-unknown-linux-musl`
My big problem with it is that they should have put as little as possible into PID 1 and had it spawn a helper process for the rest of the logic, which could then be safely killed and respawned if it hung or started to misbehave.
Yup. Too many critical and complex tasks being handled by a process that cannot ever crash.
it's on [crates.io](https://crates.io), you gotta do \`cargo install cargo-upvote\`.
I don't know, are you running nightly or stable? Which crates did you use for your game?
A crates.io index is just a git repository and whilst there is no widely used software for running a custom registery you can use https://www.reddit.com/r/devops/comments/bjitie/worlds_first_private_cargo_registry_rust/ and you can just write a custom frontend
I wouldn't say it's not working. I would say it's in the beggining. It's very hard to be the one, it takes years and years. Some have already been done, but some haven't. We just have to wait for the science to get there
You may want /r/playrust. This sub is for the programming language Rust.
I have that part already. [https://github.com/antoyo/relm/blob/4ade1dc8b4530d579c81774a2910b3ce06cab0d9/examples/buttons-attribute/src/main.rs#L39](https://github.com/antoyo/relm/blob/4ade1dc8b4530d579c81774a2910b3ce06cab0d9/examples/buttons-attribute/src/main.rs#L39)
Will this give you the behaviour that you want, though? It will ensure that each `Player` will be distinct, but the `HashSet` might consider `Player`s distinct that you don't, e.g. let cards: HashSet&lt;_&gt; = vec![Card{ number: 1, suit: Suit::Diamonds }].into_iter().collect(); let player1 = Player { name: "Jim".to_string(), cards}; let mut player2 = player1.clone(); player2.cards.insert(Card {number: 2, suit: Suit::Diamonds }); let players = HashSet::new(); players.insert(player1); players.insert(player2); assert_eq!(2, players.len()); We duplicate a `Player`, give them an extra card, and now our `HashSet` contains Jim twice, and there are two copies of the Ace of Diamonds in play. Unless you consider the same player at different points in time to be separate, this doesn't give you the protections you might think. If you consider two players with the same name to be the same player, you could write: use std::hash::{Hash, Hasher}; impl Hash for Player { fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) { self.name.hash(state) } } and then it doesn't matter that `HashSet&lt;_&gt;` doesn't implement `Hash`.
I‚Äôm really new to Rust and I was unaware of this to be completely honest. I googled ‚ÄúStatic Linking for Rust‚Äù and this was the first to come up so I followed it.
Sorry for the late reply! &gt; I'm afraid I don't know what you mean by this. When I wrote those questions, my intention were more rhetorical to show how your text may be interpreted as stereotypical. But now, after reading your post more times, I think I get what you meant. The way I first interpreted it (and probably others too) was that "not all have their masculinity threatened by LGBT+ (which are inherently fabulous)", but now I get that you meant that some have their masculinity threatened literally by fabulosity, whether its actually from LGBT+ or not. (from the "Author's Addition") Part of the problem is that the same text may be interpreted in different ways, specially in the written medium. &gt; Do you think that everyone that if I had said "cishet people" instead of "cishet men", all the men who felt targeted would be ok with the post? Not all, but I guess some. I'm not sure as I **felt** ok with the post, but using men specifically made me feel like you're just ignoring part of the problem. &gt; I'm unsure what "out of your mind" means. If you mean impulsive or something, while I wrote the post, it was reviewed by multiple people, male, female, gay, straight, trans. Sorry if it felt offensive or somethinng, its was more in the biased sense. Like you're too into the discussion and too stressed from discussing it for hours, that you sometimes tend to see only one side or get more agressive without realizing it. Maybe I was the one out of my mind (I was really tired), but its also subjective and I'm guessing that ambiguity is ONE of the reasons the post wasn't *that* well received. &gt; I think cishet people should reconsider how they speak about the LGBT community. What specifically bothers you or you find toxic? &gt; Maybe we can each work on that with our respective communities and review progress we've made in a month or so? Not sure I'd be personally really helpful. I don't really interact that much with cishets and I don't really consider myself part of one or another (I actually believe sexuality is fluid, but I'm mostly het and don't have to deal with any consequences). Still, I'm always willing to help, and when the opportinity rises, I'll be glad to do my part. &gt; Thanks! It is a team effort. Please feel free to and stop by to chat or contribute. I gotta say that the post and all of your interactions made a very good impression, if I ever find some time, I'll give it a try!
Think you might need to move the forks out of the way first: &gt;usb-rs/usbfs-sys already exists and You don‚Äôt have the permission to create repositories on usb-rs
It is really starting to grow on me. I gave been doing js dev in emberjs for like 6 years now for my job. I feel like it is really getting me out of that rut. I want to really start pushing my company to start transitioning our codebase to wasm via rust. Type safety and the wasm speed would make my life so much better. I really like the Rust community so far. It seems like discussion is way more sustainability focused and friendlier.
I saw this one in another reddit thread. It might help visualize your point: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=be954607fa08ef0c8bf6fdf23d28789b](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=be954607fa08ef0c8bf6fdf23d28789b)
To answer your question about there being a nicer way to count in base X using an array: for i in (0..9).rev() { d[i] += 1; if d[i] == 10 { d[i] = 0; } else { break } } However: there are 9! = 362880 ways to place numbers in the triangle, ignoring various symmetries. You are checking 864197533 different values, or 2381√ó as many as you need to. Even if you had a more efficient way to cycle through all 864197533 possible values of `d`, most of them will be irrelevant: if `d[1] == d[0]`, you don't recognize this and immediately try to increment `d[1]`. (Similarly, if `d[2] == d[1]` or `d[2] == d[0]`, etc.) You could probably rewrite the loop to make it more efficient, or you could change how you tackle the problem entirely. [Here's my solution](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=8b2ff71f0dc9ccdbbd293950c4e907b9), which manages to find all solutions, for all side-lengths, in less time. Mostly it's just a recursive approach, where we add an unused digit to the end of the list, call ourselves recursively, pop off the old number and try the next. Just checking the list of already assigned numbers would probably be fast enough, but instead I pass around a bitmask to track which digits we've used already. If the list has 9 elements, we check to make sure that all the side lengths are the same. We don't need to check that there are no duplicates in the list. As an additional optimization, you could check at 7 elements to make sure that the first two lists are the same, or as a further optimization, at 6 elements choose the 7th so that the first two side lengths will be the same.
I really appreciate all the work! Could you add support for **const generics**, too? They can be tested on Rust nightly, but when using them in IntelliJ Rust, syntax highlighting is broken, and jagged red lines appear everywhere.
That sounds reasonable - assuming you want to be able to store different states of the same player as distinct items. In this case, instead of using a HashSet, you could use a bitfield, since there are (presumably) only 52 cards. You could possible use a crate like [bitfield](https://github.com/dzamlo/rust-bitfield/) or [bitvec](https://github.com/myrrlyn/bitvec) to help with this. I think this would require manually implementing methods you might need, like `.contains` or `.iter`, however.
I've been meaning to extract this from my generative music project so that it may be open-sourced for general use for quite a while now! I finally got around to it assisted by some coffees (and now beers) on this cruisy Sunday :) While this is hosted under [the nannou organisation](https://github.com/nannou-org) - a creative coding framework that captures most of my attention these days - the widget itself should be compatible with any [conrod](https://github.com/pistondevelopers/conrod) GUI project, no matter what backend you happen to be using. You can find a picture of the widget in the form of a screenshot of the example at the linked repo. You can also find a picture of it in use by the generative music project I mentioned earlier [here](https://www.mindbuffer.net/#/jen/).
If you want to dig even deeper, [this](https://github.com/rust-lang/rust/blob/9ebf47851a357faa4cd97f4b1dc7835f6376e639/src/libcore/raw.rs) is the file where the compiler-internal `TraitObject` struct is defined.
I was waiting for you to merge it; I'm going to sleep, but tomorrow I'll delete the forks so you can move the repo.
No injury recieved or given. If I had accomplished such an interesting result, only to confuse my community with a vague headline, I'd expect some helpful person to razz me about it too. I give him credit for clearing this up in the first comment.
I'm using `serde` for pretty much the first time and I'm having some issues. I tried to make a type that never fails deserialization, but I'm getting an error that suggests that the input is invalid, which it's not: &gt;Error("expected \`,\` or \`\]\`", line: 1, column: 2) Any idea what I'm doing wrong? [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c5ff56eb6df421386477deb3e10f782d)
I use musl when I deploy, it works awesome and only adds a few MB to the binary size
Try compiling with musl as the target, it's really awesome. At my work, we use an old version of RedHat and the libc is pretty terrible, so I just use statically linked musl as my deployment target. It adds about 4 MB to the binary size, but works perfectly on any Linux machine. After going through a lot of headaches with C++ cross compile the musl target in Rust works like a dream. [https://blog.rust-lang.org/2016/05/13/rustup.html](https://blog.rust-lang.org/2016/05/13/rustup.html) is what I followed
If you want to have your `Serialize` implementation skip empty things, I would recommend manually implementing `Serialize` rather than using `#[derive(Serialize)]` - the code can still be pretty succinct! See https://serde.rs/impl-serialize.html. Maybe you're already doing this, though? For deserialization, as /u/apemanzilla said, the `#[serde(default)]` will use the default value if the field is missing. See https://serde.rs/field-attrs.html.
If this doens't get answered, might I suggest crossposting this to https://rust-lang.zulipchat.com/#narrow/stream/182449-t-compiler.2Fhelp? A lot of the discussion around rustc development seems to happen on zulip, rather than reddit.
thanks for the tip!
I'm not sure if this is the problem in your real one, but the problem in your reduced example is that the caller to `should_construct_struct` _defines `'a`_. Since you have it as `&lt;'a, ...&gt;`, the caller can choose any `'a`, and then `A` only satisfies `Constructor` for that lifetime. But the function needs `A` to satisfy `Constructor` for one particular lifetime, the lifetime inside of `should_construct_struct`. There's a bit of esoteric syntax which is built for this scenario in particular. If you require `&lt;A: for&lt;'a&gt; Constructor&lt;'a&gt;&gt;`, that says "for any lifetime, A must be a constructor using that lifetime". See documentation on [hrtb](https://doc.rust-lang.org/nomicon/hrtb.html). With that said, this... still doesn't fully solve the problem. If you write, fn should_construct_struct&lt;A: for&lt;'a&gt; Constructor&lt;'a&gt;&gt;() { let context = Context {}; let a = A::new(&amp;context); } Then you're still left with an error, saying "the trait bound `for&lt;'a&gt; Example&lt;'_&gt;: Constructor&lt;'a&gt;` is not satisfied". This is now complaining that the type you passed in, `Example`, is actually implied to be `Example&lt;'_&gt;` for some specific lifetime, and not an example valid for "any lifetime". In particular, it's not an example valid for the lifetime inside of `should_construct_struct`. For this reduced problem, the best solution I can come up with would be to abstract the "constructor" away, and have it be a separate struct capable of "constructing" something. Say we introduce this trait: trait CanConstruct&lt;'b&gt; { type Constructed; fn new(context: &amp;'b Context) -&gt; Self::Constructed; } And implement it for a new lifetime-less "constructor" type: struct ExampleConstructor; impl&lt;'b&gt; CanConstruct&lt;'b&gt; for ExampleConstructor { type Constructed = Example&lt;'b&gt;; fn new(context: &amp;'b Context) -&gt; Self::Constructed { Example::new(context) } } Now it's completely valid to have the constructing function be: fn should_construct_struct&lt;A: for&lt;'a&gt; CanConstruct&lt;'a&gt;&gt;() { let context = Context {}; // type annotation for clarity (not necessary) let a: A::Constructed = A::new(&amp;context); } And now the call in main becomes: should_construct_struct::&lt;ExampleConstructor&gt;(); Since this `ExampleConstructor` type _doesn't have any lifetimes tied to it_, it's valid to pass it in and use it for any lifetime (particularly, the lifetime inside `should_construct_struct`. This has the disadvantage of it being a different type from the constructed type, but maybe you can make that work? Here's a link to a working playground for your reduced issue: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=85976e0f6d44d8076adaa869bd50312c
Replacing the `(Nothing, Nothing)` with `(i32, String)` makes it work, so my suspicion is that your deserializer isn't actually consuming any input. Serde calls the method, goes to check the next character and finds the next character is still a 1. Since it's expecting to have just consumed an entire item and to be seeing either a `,` (still more list to go), or a `]` (list finished), it returns an error.
In general everything in the signature of a type/function most be the same level of public as the function. For structs this means the struct itself not its members. There are different levels of public [1] which you might find helpful. I don't know of any work around for this as the thing calling your function needs to have access to its return type. Someone else can chime in if they know a different method. [1] https://doc.rust-lang.org/reference/visibility-and-privacy.html
This would be a pretty useful project to rewrite, in my opinion. It's massively important infrastructure and another implementation could provide a bit of insurance in case a major hole is discovered in the main project. Moreover, it's actually several executables so a "rewrite" could easily be incrementally.
If you're on Ubuntu, it's pretty easy to get going: sudo apt install musl-tools rustup target add x86_64-unknown-linux-musl Then to compile the binary: cargo build --release --target x86_64-unknown-linux-musl
Thanks for the interest you've shown so far in my question. Actually, the nature of the problem is far more complex (and actually makes sense). You can check it out [here](https://github.com/ignaciomosca/chesschallengerust) (feel free to create a PR with suggestions if you feel like it). I didn't want it to make my question sound like "Please solve this problem I'm having", that's why I created that dumb example. At the same time, I don't want you to waste time in solving something that it's not an actual problem. It does not revolve around poker cards or players, but around chess and the n-queen problem. The algorithm and the solution are still pretty clunky and doesn't have a very good performance (I'm still getting the hang of the borrowing semantics so expect a lot of horrible code).
I appreciate this greatly thank you!
rock on
&gt; error[E0603]: module module is private This error is not about returning the struct, but rather the fact that _you cannot access it_. If a module is private, then nothing outside of that module's parents can access it. That includes your code! Might I ask, what's your objection to making this module `pub`? In general, all `pub` does is expose the thing to things outside the module it's declared in. If you make your module pub, then it's accessible from code outside of the module it's declared in (where the `mod module;` is located). If you don't make it pub, then you can't use it from anything outside of it's parent. If you want to access `mod::module::Struct` from outside `mod`, then why not just make `mod::module` public? ----- There's one more alternative, which is `pub(crate) mod module;`. This makes it public, but with the exception that if it would be accessible from outside of the crate, it isn't. For more info on this, I'd recommend reading https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/.
Thank you for the information; I am going to read this link. I understand the reasoning behind privacy, but this issue was particularly frustrating. I just want to use a method like usual, but I couldn't mention the private module in the function's type signature. I would be eager to hear from anyone who takes a functional approach to Rust, and how they work with private modules.
The crate in question is [gfx-backend-vulkan](https://github.com/gfx-rs/gfx/tree/master/src/backend/vulkan/src). The method is create_render_pass from the ::device module, which returns the struct ::native::RenderPass. Since it wasn't my crate, I didn't think there would be a simple way to change the visibility, but I'm still a noob so maybe I'm wrong.
The crate in question is [gfx-backend-vulkan](https://github.com/gfx-rs/gfx/blob/master/src/backend/vulkan/src/device.rs). The method is create_render_pass from the ::device module, which returns the struct ::native::RenderPass. Since it wasn't my crate, I didn't think there would be a simple way to change the visibility, but I'm still a noob so maybe I'm wrong.
Oh! That makes sense. I didn't realize you were trying to access something private in another crate. In your particular case, `gfx-backend-vulkan` has intentionally made `RenderPass` inaccessible. The best solution here, if you do really need to deal with it, would be to file a bug to `gfx` asking for that to make it accessible. To be completely clear, if you really do need to deal with `RenderPass`, any other solution here is a workaround for that bug in `gfx`. With that said, there is a workaround. Since it's used as an associated type `RenderPass` for [`gfx_backend_vulkan::Backend`](https://docs.rs/gfx-backend-vulkan/0.2.1/gfx_backend_vulkan/enum.Backend.html)'s implementation of the [`gfx_hal::Backend`](https://docs.rs/gfx-hal/0.2.0/gfx_hal/trait.Backend.html) trait, you can refer to it as that. You should be able to write use gfx_backend_vulkan::Backend as VulkanBackend use gfx_hal::Backend as HalBackend; fn x() -&gt; &lt;VulkanBackend as HalBackend&gt;::RenderPass { // create_render_pass call }
Thanks so much for this. Looks like I need to read up more on associated types in case I encounter any similar issues in the future.
No problem - glad to help! This kind of inaccessible type is annoying, but can be useful for particular things - like making a trait which can be used, but never implemented. I'd argue them making a type like this and returning it _is_ a bug, but eh.
It looks like the crate supports a "bundled" feature. Have you tried that?
Thank you for replying and extra thanks for coming up with a different, better solution. When I decided to program a solution in Rust, my first thought was to use some kind of flag for each digit, so that each would only be used once, but I had no idea how to implement it. Using a bitmask never even occured to me. The only bitwise operations I've ever used are shifts, and that was just to compare performance of shifts and the multiply function in C. I've already learned a lot from your solution. I will study it further to learn more! Thanks again! :)
One thing to keep in mind: `for` loops are equivalent to calling `Iterator::next` in a loop. In other words, following pieces of code are equivalent: for x in lst { println!("{}", x); } and let _it = lst.into_iter(); loop { let next = _it.next(); match next { Some(x) =&gt; { println!(x); } None =&gt; break, } } What makes iterators work is the [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) trait, and in particular the `next` method. The suggested piece of code just calls next manually, rather than using a for loop to do it.
As I understand it, the Pin API makes it safe to expose something that's self-referential, but it doesn't actually provide any code to make self-referential things. It's more like... the `Pin` type lets you guarantee a struct will never move. So, someone else can build a self-referential struct using unsafe code, and use `Pin` to expose a safe abstraction for it. I think there's an example of doing this in the `Pin` docs, if you haven't seen it. It's not a very advanced self-referential struct, but it's here: https://doc.rust-lang.org/std/pin/index.html#example-self-referential-struct When I was first looking at pinning, I found withoutboat's blog posts pretty helpful for understanding it. https://boats.gitlab.io/blog/post/rethinking-pin/ should give a fairly good overview?
There are some tricky things involved - see https://www.reddit.com/r/rust/comments/9lu9xo/can_a_no_std_crate_depend_on_a_procmacro_crate/. In particular, https://github.com/rust-lang/cargo/issues/5730 means that if your library depends on other libraries with `std` features, you need to make sure that they're disabled - or those `std` features will leak through to the users of your proc macro. If you make sure not to run into that, then it works! And I think it'd be appropriate to assign `no-std` to your crate too, yeah.
[https://github.com/intellij-rust/intellij-rust/pull/3990](https://github.com/intellij-rust/intellij-rust/pull/3990) [https://github.com/intellij-rust/intellij-rust/pull/3993](https://github.com/intellij-rust/intellij-rust/pull/3993)
Hello, author of ccl here. At the moment DHashMap is mostly finished and will only be accepting small patches. I've now turned m attention toward newer designs for coming versions.
&gt; All of them are WIP. I wonder, what would it take to get one of them actually completed? Enough people considering it a good investment of their time and enough people trying them out to actually check them and use them.
You might be able to use impl trait here. You still have to make the struct public, or create a public proxy. Impl a trait for its public interface. Then you can return the proxy, which might privately be able to be converted into the private object if necessary. This provides some level of abstraction and obfuscates your type so that the caller doesn't know private implementation details. If you use a box, you could box the private struct (I think), and either return that or use impl trait and auto implement the trait for a Box&lt;Trait&gt;.
From the point of view of developing production code, that sounds pretty dramatic to me. But if you‚Äîthe metaphorical you‚Äîknow all of this going in, you make preparations so that it won't stop the show. I guess that's just where Rust is in this stage of its evolution. What it seems like to me is that rust needs a few companies willing to take that risk of using this new language that doesn't have the infrastructure that more established solutions do. Those risk takers will be how infrastructure/tooling serving commercial development gets built. You need a Jane Street.
I believe the problem here is calling `wait`! When you call `wait`, you're blocking the thread on the future completing. But the connecting future won't complete by itself, it requires other things to run in the larger event loop. By calling `wait`, you never give those other things a chance to run. Futures work by letting the event loop run when they aren't actively doing anything, but that event loop _runs on the same thread_. I would recommend never calling `wait`, as it kind of disrupts the flow of futures, and rarely actually does what you want. The problem is that futures don't, and can't, "run now". You can chain them, and ask something to happen when they complete, but it's not really possible to block the current thread until they're done - because other things need to happen in the background. Instead, you have a few other options: - Use `tokio::spawn(fut)` rather than `fut.wait()`, and immediately run other code (your future will run as soon as your current code finish). I don't think this will be useful in your case, as you have to return something from the `HttpServer` closure. - Chain your future using `map` or `and_then`, and use the result inside those closures. I think this is probably the easiest to do, but it means you will have to do the connection outside of the `HttpServer` closure. The closure you're passing to `HttpServer` must be able to run synchronously, and you won't be able to get a result from a future inside there effectively. This brings up one more technical problem, which is that you'll need to run futures outside of the `HttpServer`. The `HttpServer::run()` method isn't built for this use case, so I'd recommend using `HttpServer::start()` instead, and perform the futures work inside `actix_rt::System::run`. Something like this is what I have in mind: actix_rt::System::run(|| { println!("connecting to postgres"); let fut = tokio_postgres::connect("host=localhost user=vincent connect_timeout=10", NoTls) .map(|(client, conn)| { println!("in map?"); // spin the connection future off, keep the client let conn = conn.map_err(|e| eprintln!("connection error: {}", e)); tokio::spawn(conn); client }) .map(|conn| { println!("connected to postgres"); HttpServer::new(|| { App::new() .data(RefCell::new(conn)) .service(web::resource("/db_test").route(web::get().to_async(db_test))) .default_service(web::route().to(|| HttpResponse::NotFound().body("404 Not Found"))) }) .bind("127.0.0.1:8080")? .start(); Ok(()) }).then(|res| { // we need to handle the error somehow if let Err(e) = res { panic!("error: {}", e); } }); // trigger the future being called (we can do this since we're inside the tokio runtime started by `System::run`) tokio::spawn(fut); }); (gist at https://gist.github.com/rust-play/bf3439e36b1e518f43665dfa36394789) Rather than trying to make the futures block, instead we just `map` on them and start the `HttpServer` only once the future's completed. --- Working with futures without async/await can almost feel like an entirely different mindset sometimes, so it's reasonable to take a bit of time to get used to it. Hope that helps, though!
I tried modifying my code to use your snippet but I'm getting this instead: error[E0277]: the trait bound `(): futures::future::Future` is not satisfied --&gt; src/main.rs:58:16 | 58 | }).then(|res| { | ^^^^ the trait `futures::future::Future` is not implemented for `()` | = note: required because of the requirements on the impl of `futures::future::IntoFuture` for `()` error[E0277]: the trait bound `(): futures::future::Future` is not satisfied --&gt; src/main.rs:66:9 | 66 | tokio::spawn(fut); | ^^^^^^^^^^^^ the trait `futures::future::Future` is not implemented for `()` | = note: required because of the requirements on the impl of `futures::future::IntoFuture` for `()` = note: required by `tokio::executor::spawn` error: aborting due to 2 previous errors which is very confusing because I'm obviously not calling `then` on `()`. could this message be improved?
Hello! ccl is evolving but the concurrent contender map from it is now set in stone and will not be changed in any major way. Some new designs are in the works. I'll be publishing some benchmarks later today comparing lots of concurrent hashmap. Stay tuned.
https://github.com/ELD/muslrust This repo helped me yesterday when I wanted to build a minimal docker image from statically linked rust. Dependency caching is a bliss.
Ask in /r/playrust as it looks like this is about rust-the-video-game, this place is rust-the-language.
Right, I think I know what's the cause of the error - I'd forgotten to stick an `Ok(())` in the `then()` closure. If it's like the following, it should work: .then(|res| { // we need to handle the error somehow if let Err(e) = res { panic!("error: {}", e); } Ok(()) }); It's complaining about the fact that the closure passed into `then` doesn't return anything, and thus returns `()`. But `()` isn't a future or result, so it can't spawn it - returning `Ok(())` fixes this. &gt; could this message be improved? There are small improvements that could be made, but in general, these are just functions taking closures - and the errors are going to reflect that. I wouldn't really expect much improved error messages in the future, especially because `async/await` is so close to stabilization, and it'll improve much more than just the errors when dealing with futures.
/r/playrust
So what is Rust? Is it something from the Survival videogame?
If it's not too much work to include this one too, it would be great :-). Though, I don't expect mine to be extremely fast (it is 2-3 times slower on lookups than std hashmap in single-threaded cases, it can outperform BTreeMap if there are enough elements). But the algorithm I use should perform well under multithreaded update-heavy scenarios.
https://doc.rust-lang.org/book/ch20-00-final-project-a-web-server.html
I'll include it! There are multiple benches to simulate multiple scenarios. I'll reply with a link once everything is done.
Not very familiar with internals of serde, but I think you need actually consume the input with a visitor. This works, but is somewhat lenghty: [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f9631bb0b116e453d43dbf256990492f).
And if the service manager crashes when not PID 1, then what? It gets relaunched? Would that effectively act as a soft-reboot?
I can definitely sympathize with this. It's even worse when the bug disappears when run through a debugger...
The general quality of code in the ecosystem. Which is to some extend the blessing of a late birth. The amount of time wasted because of bad libraries in other ecosystems is just ... and yeah, being forced to reinvent wheels as a consequence might be even worse. I always laugh, when people point out Java and C++ biggest strength, libraries for anything. Sure, good luck buddy. (obviously, there are also marvels there, sometimes even for very specific stuff)
*Tutorial
Is there a way to use `impl Trait` here? fn foo(xs: &amp;[u8]) -&gt; impl Iterator&lt;Item=u8&gt; { xs.iter().cloned() }
So the problem is that, rather than actually cloning the `u8` vector and returning it with an iterator, you're returning a *streaming* iterator which holds a reference into the slice, and clones its items one at a time. The fn's concrete return type is `std::iter::Cloned&lt;std::slice::Iter&lt;'lifetime, u8&gt;&gt;`. So, as well as restricting the iterated type, you also need to restrict the iterator's lifetime so that it doesn't outlive the slice: fn foo&lt;'a&gt;(xs: &amp;'a [u8]) -&gt; impl Iterator&lt;Item=u8&gt; + 'a { xs.iter().cloned() } From the reference: "`T: 'a` means that all lifetime parameters of `T` outlive `'a`". So by adding the `+ 'a` to the return type, we're ensuring that the lifetime parameter to `std::iter::Cloned&lt;std::slice::Iter&lt;'lifetime, u8&gt;&gt;` will outlive that of the `&amp;'a [u8]`.
I've heard of brand new locamotives being pushed off the train tracks because it was cheaper to replace the engine than suffer the downtime of the rail line.
Thank you! This solves my problem. I'm curious if there is a way to use it when not all the lifetime parameters of `T` are equal, eg. fn foo(xs: &amp;[u8], ys: &amp;[u8]) -&gt; impl Iterator&lt;Item=(u8,u8)&gt; { xs.iter().cloned().zip(ys.iter().cloned()) }
Thank You for such a descriptive and in-depth reply. That does indeed solve my problem and it is possible for me to implement it into my codebase. I am very grateful, have a nice day!
What‚Äôs the cache efficiency of CTrie ? E.g the main advantage of hash brown is good Cache locality and vectorization, but it appears that the CTrie is ‚Äúnode-based‚Äù.
Ah, I wrongly assumed that it would automatically skip to the next "thing" then. Thanks, this totally explains why that particular error message is displayed.
Very interesting! So `Deserializer::deserialize_any` will look at the type of data and skip it for you. That makes a lot of sense in hindsight. Thank you!
Yes, it is node-based and the answer to cache locality is probably ‚Äûnot great‚Äú. Yes, there are costs to having it concurrent/lock-free, this is one of those. You can expect that hashbrown will outperform anything concurrent in single-threaded scenarios.
Nope I'm not even sure how to do that
Doesn't seem updated, at first glance. You're still using SyncActor for database execution despite the more streamlined approach available in 1.0. This would be fine if it were based on a deliberate design decision but as this is a tutorial intended to educate others about 1.0, probably isn't.
Would you mind posting a final working example to the official examples repo for actix?
They posted the [SAME](https://old.reddit.com/r/rust/comments/bya8k6/programming_with_rust_vs_c_c/eqi9zb5/) comment!
The renders are coming out great! Cool to see you're parsing blender files now too.
That's an interesting one. The concrete type is: std::iter::Zip&lt;std::iter::Cloned&lt;std::slice::Iter&lt;'_, u8&gt;&gt;, std::iter::Cloned&lt;std::slice::Iter&lt;'_, u8&gt;&gt;&gt; The problem is that any lifetime bound we put on the return type will apply equally to *both* of those lifetimes. So we can't request the return type `impl Iterator&lt;Item=(u8,u8)&gt; + 'a + 'b` because that would require `'a` to outlive `'b` and require `'b` to outlive `'a`, which is only possible when `'b` and `'a` are the same lifetime. Unless you're willing to write out the whole return type rather than using `impl Iterator`, I think the only solution would be to require both input slices to have the same lifetime: fn foo&lt;'a&gt;(xs: &amp;'a [u8], ys: &amp;'a [u8]) -&gt; impl Iterator&lt;Item=(u8,u8)&gt; + 'a Luckily, the compiler is often smart enough to unify two lifetimes which are actually different from one another. This compiles without any issues: let outer = [0u8, 1]; let outer_ref = &amp;outer; { let inner = [1u8, 2]; let inner_ref = &amp;inner; for i in foo(outer_ref, inner_ref) { println!("{} {}", i.0, i.1); } }
Do you think it would be possible to make something hashbrown-like concurrent?
1) Read the sidebar before posting!! You're looking for /r/playrust
I have not studied hashbrown nor array-based concurrent hash tables in detail (if there's such a thing; I guess growing + rehashing in concurrent case without locking might be a bit of a challenge) so I can't say for sure. Nevertheless I'm a bit sceptical. Is there such a thing as vector-sized CaS operation? I have the vague impression that not many architectures support even the double-word atomics and even those that do are said to be slow.
What is the new approach?
I was surprised how small it could get. I went from Gb to just a few Mb when using musl and multistage the build onto the scratch image!
use the ``web::block_on(...)`` api
https://doc.rust-lang.org/stable/cargo/reference/manifest.html#the-features-section https://github.com/jgallagher/rusqlite#user-content-notes-on-building-rusqlite-and-libsqlite3-sys
For terminal UI's, I use tui-rs. https://github.com/fdehau/tui-rs Just don't call alternative screen, and use that + clap and you'll probably get what you want. For XDG stuff I use directories (on crates.io).
there is a nice blog post by the author of diesel-rs. It's a good start: [https://deterministic.space/rust-cli-tips.html](https://deterministic.space/rust-cli-tips.html)
Not specifically for the 12 factors, but you might want to give [interact](https://interact-rs.github.io/interact/doc/interact/index.html) a look.
Our code is open source, but we will no be building a separate GraphQL abstraction that it would make sense to use outside the context of Prisma. Our current implementation is not async, so we will be going through this transition in the coming months together with the rest of the Rust community. Hopefully we can share notes with Juniper and other projects.
Termion is great for abstracting over control characters and using raw mode: [https://github.com/redox-os/termion](https://github.com/redox-os/termion)
Yeah, what's up with that? Every time I see a post from someone who misinterpreted the subreddit's name, I wonder how that is even possible.
 Code is here: https://github.com/banaio/openbanking.rs. Well I managed to get this to work with and frankly I have no idea how everything works. Please be gentle as I new to this. Feedback is more than welcome - I do not take things personally. Feedback is as follows: 1. I am baffled by the line `reqwest = { version = "0.9.18", features = ["rustls-tls"] }` that I added to `Cargo.toml` that allowed it work. 2. Not sure what the main difference is between `fn main() -&gt; Result&lt;(), std::error::Error&gt;` vs `fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt;`. 3. _Very_ confused about all the tls crates available for Rust. I am coming from Go/Golang and this stuff is very easy to do in Golang/Go. I wish someone would do a write explaining the differences. 4. Errors are useful but only so useful because it's hard to figure out where they are coming from. It would be better if the function and line were included in the error somehow. What I've liked so far is that after I got the code to compile it mostly worked the first time, i.e., I did not spend a lot of time debugging. RLS VSCode is quite good. I am basically building a client around the Open Banking APIs (https://en.wikipedia.org/wiki/Open_banking). In the UK all the "major" banks have to implement this standard. There is a Open Banking Security Profile v1.1.2 (https://openbanking.atlassian.net/wiki/spaces/DZ/pages/83919096/Open+Banking+Security+Profile+-+Implementer+s+Draft+v1.1.2) and the standards for the Read/Write Data API Specification - v3.1.2 (https://openbanking.atlassian.net/wiki/spaces/DZ/pages/1077805207/Read+Write+Data+API+Specification+-+v3.1.2). Example output: $ cargo run Compiling openbanking v0.1.0 (/Users/mbana/dev/banaio/github/openbanking) Finished dev [unoptimized + debuginfo] target(s) in 4.08s Running `target/debug/openbanking` INFO 2019-06-10T12:32:28Z: openbanking::oidcdiscovery: openidconfiguration=OpenIDConfiguration { request_parameter_supported: true, claims_parameter_supported: true, request_uri_parameter_supported: true, introspection_endpoint: "https://matls.as.aspsp.ob.forgerock.financial/oauth2/introspect", issuer: "https://as.aspsp.ob.forgerock.financial/oauth2", authorization_endpoint: "https://as.aspsp.ob.forgerock.financial/oauth2/authorize", token_endpoint: "https://matls.as.aspsp.ob.forgerock.financial/oauth2/access_token", version: "3.1", userinfo_endpoint: "https://matls.as.aspsp.ob.forgerock.financial/oauth2/userinfo", jwks_uri: "https://as.aspsp.ob.forgerock.financial/api/jwk/jwk_uri", registration_endpoint: "https://matls.as.aspsp.ob.forgerock.financial/open-banking/register/", require_request_uri_registration: true, grant_types_supported: ["refresh_token", "client_credentials", "authorization_code"], scopes_supported: ["openid", "payments", "fundsconfirmations", "accounts"], id_token_encryption_enc_values_supported: ["A256GCM", "A192GCM", "A128GCM", "A128CBC-HS256", "A192CBC-HS384", "A256CBC-HS512"], acr_values_supported: ["urn:openbanking:psd2:sca", "urn:openbanking:psd2:ca"], request_object_encryption_enc_values_supported: ["A256GCM", "A192GCM", "A128GCM", "A128CBC-HS256", "A192CBC-HS384", "A256CBC-HS512"], claims_supported: ["acr", "zoneinfo", "openbanking_intent_id", "address", "profile", "name", "phone_number", "given_name", "locale", "family_name", "email"], token_endpoint_auth_methods_supported: ["client_secret_post", "private_key_jwt", "client_secret_basic", "tls_client_auth"], response_types_supported: ["code token id_token", "code", "code id_token", "device_code", "id_token", "code token", "token", "token id_token"], id_token_encryption_alg_values_supported: ["RSA-OAEP", "RSA-OAEP-256", "A128KW", "A256KW", "RSA1_5", "dir", "A192KW"], subject_types_supported: ["public", "pairwise"], id_token_signing_alg_values_supported: ["RS256", "PS256"], request_object_signing_alg_values_supported: ["RS256", "PS256"], request_object_encryption_alg_values_supported: ["RSA-OAEP", "RSA-OAEP-256", "A128KW", "RSA1_5", "A256KW", "dir", "A192KW"], userinfo_signing_alg_values_supported: ["ES384", "HS256", "HS512", "ES256", "RS256", "HS384", "ES512"], userinfo_encryption_enc_values_supported: ["A256GCM", "A192GCM", "A128GCM", "A128CBC-HS256", "A192CBC-HS384", "A256CBC-HS512"], userinfo_encryption_alg_values_supported: ["RSA-OAEP", "RSA-OAEP-256", "A128KW", "A256KW", "RSA1_5", "dir", "A192KW"], token_endpoint_auth_signing_alg_values_supported: ["RS256", "PS256"] } INFO 2019-06-10T12:32:29Z: openbanking::client: response={"access_token":"eyJ0eXAiOiJKV1QiLCJ6aXAiOiJOT05FIiwia2lkIjoiRTE5N1kzMVFLT05mSk42aTdrQlkyMzFneUFvPSIsImFsZyI6IkVTMjU2In0.eyJzdWIiOiI0YzYyNTU1NS0yZTI5LTQxNGEtYjZlMC1mOGNiNzgyNTZmZGYiLCJjdHMiOiJPQVVUSDJfU1RBVEVMRVNTX0dSQU5UIiwiYXVkaXRUcmFja2luZ0lkIjoiOGEwNTFlODAtYzY4ZS00MDhhLWIxN2ItMWEzM2FhNGE0NmUxLTEwMTQwODIiLCJpc3MiOiJodHRwczovL2FzLmFzcHNwLm9iLmZvcmdlcm9jay5maW5hbmNpYWwvb2F1dGgyIiwidG9rZW5OYW1lIjoiYWNjZXNzX3Rva2VuIiwidG9rZW5fdHlwZSI6IkJlYXJlciIsImF1dGhHcmFudElkIjoiN0otUkF4WjVqNFg1ZU5yTmRNTG5NNGxzS0dJIiwiYXVkIjoiNGM2MjU1NTUtMmUyOS00MTRhLWI2ZTAtZjhjYjc4MjU2ZmRmIiwibmJmIjoxNTYwMTY5OTQ4LCJncmFudF90eXBlIjoiY2xpZW50X2NyZWRlbnRpYWxzIiwic2NvcGUiOlsib3BlbmlkIiwicGF5bWVudHMiLCJmdW5kc2NvbmZpcm1hdGlvbnMiLCJhY2NvdW50cyJdLCJhdXRoX3RpbWUiOjE1NjAxNjk5NDgsInJlYWxtIjoiL29wZW5iYW5raW5nIiwiZXhwIjoxNTYwMjU2MzQ4LCJpYXQiOjE1NjAxNjk5NDgsImV4cGlyZXNfaW4iOjg2NDAwLCJqdGkiOiJmS3hBS09rRU83aUU3Z2xOVTlkUTQydG13VncifQ.gkMU9OaTvlkni0kYhTzp5JObYA2BDimkv-upfIfcyhXoQcDcDV9idS8RILXK_5Ud8k6ibNSkSptQrmT7YT831g","expires_in":86399,"id_token":"eyJraWQiOiIyYzk3ZDdmOWQyYjRkNTE5OTI4MDM2MGVkZTMzZTYzZDQ4MTUwOTRkIiwiYWxnIjoiUFMyNTYifQ.eyJhdF9oYXNoIjoiMkZJWDFLZHZEMGdhVTZxWlA2MEFtdyIsInN1YiI6IjRjNjI1NTU1LTJlMjktNDE0YS1iNmUwLWY4Y2I3ODI1NmZkZiIsImF1ZGl0VHJhY2tpbmdJZCI6IjhhMDUxZTgwLWM2OGUtNDA4YS1iMTdiLTFhMzNhYTRhNDZlMS0xMDE0MDgzIiwiaXNzIjoiaHR0cHM6XC9cL2FzLmFzcHNwLm9iLmZvcmdlcm9jay5maW5hbmNpYWxcL29hdXRoMiIsInRva2VuTmFtZSI6ImlkX3Rva2VuIiwiYXVkIjoiNGM2MjU1NTUtMmUyOS00MTRhLWI2ZTAtZjhjYjc4MjU2ZmRmIiwiYXpwIjoiNGM2MjU1NTUtMmUyOS00MTRhLWI2ZTAtZjhjYjc4MjU2ZmRmIiwiYXV0aF90aW1lIjoxNTYwMTY5OTQ4LCJyZWFsbSI6Ilwvb3BlbmJhbmtpbmciLCJleHAiOjE1NjAyNTYzNDgsInRva2VuVHlwZSI6IkpXVFRva2VuIiwiaWF0IjoxNTYwMTY5OTQ5LCJqdGkiOiJkOTRmZjk0NC1kM2Q2LTRkMDEtOWEwYy1hMzQyMGQ5ZjU2OTAifQ.DykB-XTAZdB-YxzlLoHS7BZM8HlhOhBM5Orrrw3Pazprh3WmXKGHICIfqn2mHdvFOvTb9rdI51w8av195zkrTt3c0KJjEf0URErXdyJ-zldKlk-VdSJKiuTFFvLd6842vMUNlA52Haxc1PgYutng9Cd0ivEtHFG8n0j-aQ7TMiZvAGeTJregTnw-Cc40gtfMD5Bod50_-PmxqEJFBLoM0xFE7GcgSrLH-hzCJNV1m2mSlSTBNmusRp7MIsFrjwg9E7n7lqaCxp54ubqiyp-ViuD-QsFZuVB9MH7LaCZo-NDSGGCJaYj1qHsVRyC3j3khMQDyq2N8AN6zo8RH6Wrcmw","token_type":"Bearer","scope":"openid payments fundsconfirmations accounts"} Thank you all for the initial feedback that you left.
Would you be willing to write up a tutorial of the process?
Sure. I can‚Äôt at the moment but as soon as I can I will
&gt; Do you think that everyone that if I had said "cishet people" instead of "cishet men", all the men who felt targeted would be ok with the post? I would suggest that, instead of targeting people by using some general characteristic that they usually (but not always, and not exclusively) share is a poor effort. If you're talking about assholes who do something specific, well, call them that. Otherwise you're including people that were minding their own business. It's particularly jarring in this case as you're singling out the vast majority of community for no valid reason.
I ran into the same issue. How do I run `serde_json::from_str` on a string that is strict superset of the struct that I am trying to convert to. That is, the struct does not define all the possible fields that might be contained the json.
Special thanks to [kampffrosch94](https://github.com/kampffrosch94) for their contribution on the [toml](https://crates.io/crates/toml) crate.
Great! Looks really interesting and fun
In terms of design, no. In terms of performance: yes. I'm the author of ccl and currently devoting time towards making a new concurrent map in that performance league.
Hello, author of \`ccl\` here. \`DHashMap\` is now stable and will not change and i do not consider it WIP anymore. ccl is getting more alternative designs with different characteristics soon though.
Hello! The benchmarks results are now out. Go check them out at [https://gitlab.nebulanet.cc/xacrimon/rs-hm-bench](https://gitlab.nebulanet.cc/xacrimon/rs-hm-bench).
currently [https://github.com/actix/examples](https://github.com/actix/examples) uses 1.0
You don‚Äôt need WSL, just get rustup for Windows and install the rust plugin for VSCode and you‚Äôre done
Modulating the poll interval - interesting. What I've done is keep a set of the (topic, partition, offset) tuples that are "outstanding", meaning a task has been invoked on their behalf, but we haven't heard back yet. Then in the poll loop you can have logic around a maximum number of outstanding messages. There is a little more trickery around when to commit. In general, however, at this point it's always going to depend on your use case - but it's pretty awesome that the actor framework is flexible to most of them! I would be interested in seeing your Riker code.
Agreed! What I'd _really_ love is a `tracepoint!()` macro or something easily accessible that produces the appropriate trace point for the current platform.
Looking through the results and the API on docs.rs‚Ä¶ Am I right ccl is concurrent API-wise, but not lock-free and does so by some clever locking inside? I'm not saying that design is useful in some scenarios, only trying to understand :-).
You're right that \`ccl::dhashmap\` is not lock free, I've never said it was. It does do some clever locking internally though.
Worth noting that this seems to be quite out of date, specifically the error_chain recommendation.
the easiest way to expose the complexity of `systemd` is to try one of the simpler alternatives and do your own comparisons. I really liked `runit`.
Also keep in mind that it supports modification of elements that are already inside with tables\_write and get\_mut while i believe contrie doesnt allow modification except cloning an element, modifying it and then putting it back in which may be expensive or impossible depending on the key and value types.
Have a look at the CLI WG book it will help https://rust-lang-nursery.github.io/cli-wg/ :)
maybe it's a 'soft sequel sea-boot reboot prequel'?
And wasn't one of the big changes of actix-web 1.0 the switch to tokio?
Which highlights - [structopt](https://docs.rs/structopt) - [indicatif](https://crates.io/crates/indicatif) - [env_logger](https://crates.io/crates/env_logger) - [clap_verbosity_flag](https://crates.io/crates/clap-verbosity-flag) - [assert_cmd](https://docs.rs/assert_cmd) - [exitfailure](https://crates.io/crates/exitfailure) - [ctrlc](https://crates.io/crates/ctrlc) - [signal-hook](https://crates.io/crates/signal-hook) - [human-panic](https://crates.io/crates/human-panic) - [atty](https://crates.io/crates/atty) Surprising, it doesn't mention - [assert_fs](https://github.com/assert-rs/assert_fs) - [quicli](https://github.com/killercup/quicli) - [Some other crates in development by the CLI-WG](https://github.com/rust-cli) Also, a good resource is to look at the [CLI-WG's issues](https://github.com/rust-lang-nursery/cli-wg/issues) since you can find discussions on crates dealing with [config file management](https://github.com/rust-lang-nursery/cli-wg/issues/7), [packaging](https://github.com/rust-lang-nursery/cli-wg/issues/8), and a host of other topics.
I'd consider the CLI-WG's book (see [DegaussPenguins's post](https://www.reddit.com/r/rust/comments/bywri0/crates_recommendations_for_cli_apps/eqnlln5/)) to be the successor to that blogpost. The author (killercup) also leads the CLI-WG and wrote most of the book.
Just like London Buses.... you wait a long time for one..... then 2 come along at once. We are having our first Hack n Learn hangout on the 25th of June you can sign up here for that event as well [https://www.meetup.com/Rust-London-User-Group/events/262176607/](https://www.meetup.com/Rust-London-User-Group/events/262176607/) &amp;#x200B; Regards Team London
&gt; (since 1.26 Rust has supported returning a Result from main()) Returning `Result` directly from `main` is almost certainly not what you want in CLI tools because it will show the `Debug` representation of an error, not the `Display` representation.
I hadn‚Äôt realized Nannou had gotten this far, it looks amazing! Are you at liberty to speak at more length about the types of commercial projects you‚Äôve been using Nannou/Conrod/etc. with?
Sometimes structs are private because there is no assurance of backwards compatibility, by making it public they have to support it or make a breaking change, which is harder to work with. So if it's a API they have no intention to keep stable they shouldn't make it public. But file an issue, they may be simpathetic to your needs or help you making a work-around, like re-implementing yourself what RenderPass does (copy pasting).
wmanley, I really appreciate you dropping by and supporting what I believe were constructive criticisms. That said, I've done constructive criticisms like this for msvc and golang also and the negative feedback I got back then was similar so I am used to it. For example a Microsoft Visual Ada...never happened. Golang modules usage with local directories without having to resort to github paths...The only way that's accepted is if the go modules are disabled. Golang UML Tools...non-existent because the Golang creators don't believe in such tools for golang. My brain is wired in such a way that when I analyse a problem, I break it down not in code, but as a tree first, then as a uml collaboration diagram no matter what programming language I decide to implement a solution in. I perceive uml to be very useful, but I wouldn't expect rust uml tools because I couldn't get golang uml tools. I think my requests were unreasonable, but at least I made them. No harm in asking.
Fork for `usbfs-device` has been deleted, fork for `usbfs-sys` awaits merging into your code, and you (temporarily) have admin access to create repositories. Hopefully that's enough.
I‚Äôll try to refactor as soon as I get some time thanks for the suggestion üôèüèΩ
&gt;GPL and AGPL and other copyleft licenses are not being unused because of developers being very concerned about having to give back code (no one is, in fact quite the opposite) /me raises hand As a developer and an attorney, I think GPL, especially AGPL, is a bad bargain and would not use it on code I write if given the choice.
Indeed, I find Rust stance possibly *too* strict. I understand the explicit conversion to `isize`/`usize` to some extent, however not having implicit conversion from `i16` to `i32` seems pretty restrictive. I'm afraid that the desire for explicitness may have gone too far.
Great, thanks for the fast response!
There's a better way to set up a global build cache using [sccache](https://github.com/mozilla/sccache). It comes with [experimental Rust support](https://github.com/mozilla/sccache/blob/ae25547ff5ab64a8dde3f2be65ecc1c8f34bc01c/docs/Rust.md).
If you do not impose *single array*, then it's possible to use a jagged array as the basis for the hashmap which avoids having to move anything when growing at the cost of more look-ups. A jagged array is an array of sub-arrays of increasing size (1, 1, 2, 4, 8, 16, ...), so that adding a "new" sub-array doubles the overall capacity. Doing look-ups backward (starting from latest sub-array) gives 50% chance of finding the element in the first sub-array visited, 75% of finding in the first 2 sub-arrays visited, etc... --- Personally, I've found that the difficulty here is always reference vs writes: - References are great for read-heavy loads, as even atomic increments (reference counters) can noticeably decrease performance in concurrent scenarios. - But they're really hard to reconcile with other usecases, such as update and deletion :/
Interesting, the install steps seem more complicated than setting one environment variable tough.
Oh my Lord, I was looking for creative coding framework for Rust just week ago, since I think this is the best way to learn language (I did this with c++). Thanks for sharing !
I'm going to take a look at this. I've noticed a typo on [https://guide.nannou.cc/getting\_started/platform-specific\_setup.html](https://guide.nannou.cc/getting_started/platform-specific_setup.html) apt-apt should be apt-get
A basic install is just cargo install sccache export RUSTC_WRAPPER=sccache This will give you an install using the default local cache dir. You can configure more and make it complicated if you need that, but you don't have to if you don't need it
 &gt; And I know, I‚Äôm bad at naming libraries, the name is silly. You meant that the name was *contrieved*, right?
Why not "apt install"?
&gt; I fully expect that it will be possible to put a GitHub Org as a sponsors target in the future, there's no real reason not to. (Though of course, who knows.) They have made noises already that they want to support this. &gt; I don't doubt that a dedicated funding platform is more appropriate, but the issue I'm talking about is one of making it easier for companies to move money, and if they're already giving GitHub money for Enterprise, it's practically frictionless to add on a Sponsor expense. I don't agree there, on the level of larger expenses, they still want some kind of vetting and no middleman. The platform must provide other features there (like OpenCollective does: funds tracking and such).
It didn't though, I'm the author of the forum post that was linked, and it wasn't unpleasant (in my opinion, at least), in the meta channel. That was my problem with it being locked, however I was later informed that apparently it got really bad in the actual Rust discord, and it might have been locked early due to that, but I wasn't there for the argument over there so I don't know exactly what happened
Thanks, and sure! I think the first commercial project that we used nannou in was [LATTICE](https://www.mindbuffer.net/#/lattice/), a multi-channel laser installation driven by a generative music engine that I had been working on for a number of years before we landed the gig. I'm not sure that it was called "nannou" at this point, but many of the pieces of Rust that we used are part of what makes up nannou today. Nannou was used to develop [the generative music engine](https://www.mindbuffer.net/#/jen/) along with its GUI (only visible to us). We also used Rust to implement a custom networked LASER protocol and to bind to a really ancient, undocumented Pascal API in the proprietary LASER software we were using at the time (these days we just use [nannou_laser](https://github.com/nannou-org/nannou_laser) and avoid all that). The next commercial project was an exhibition called Beyond Perception that will apparently run for the next 15 years, also at Scienceworks in Melbourne. We were commissioned to create a networked, spatial audio server that would run throughout the whole floor of the building. Here's a link to the project [on our site](https://www.mindbuffer.net/#/spatial-audio-server/) and here's another to [a video](https://vimeo.com/339975595) of it in action. Nannou was used for everything in this case - the GUI used by the composer and staff and the 100+ channel audio support. Conrod can be a bit tedious for putting together GUIs on its own as it involves a bit of boilerplate depending on the backend you use, but nannou makes it a lot easier as it just picks one backend and creates a much simpler API on top. Similarly, nannou's audio API wraps up CPAL for pure-rust, cross-platform, audio I/O streams, but provides a simpler, non-blocking API with a whole heap of reasonable defaults. This project was actually the motivator that drove me to add input stream support to CPAL (no duplex support just yet, maybe that's next!?). We managed to negotiate an open-source release of the audio server after the launch of the exhibition - you can find the code repo [here](https://github.com/museumsvictoria/spatial_audio_server). If you take a look, please keep in mind nannou has changed quite a bit in the last year! I'm planning on making some improvements to CPAL to get ASIO support working properly on Windows soon, after which I'll likely update the audio server to modern nannou. Since we launched it, Museums Victoria have been using audio server in a bunch of different exhibitions, some of which I haven't been to yet. Earlier this year we used nannou to develop two installations for the Gut Feelings exhibition at Melbourne Museum. One was a [microbe mirror installation](https://vimeo.com/340928061) where visitors can stand in front of one of three mirrors and watch microbes flow throughout different parts of their body while the mirrors share facts about gut health. Nannou was used for everything in this one, including binding to the nuitrack camera SDK, filtering the incoming depth images with compute shaders, graphics via Vulkan with a bunch of custom GLSL shaders and a GUI for tweaking params like physics/particles/flow-field behaviour and colour schemes in real-time. The other is a projection mapping ["Gut Tunnel" installation](https://vimeo.com/340891341) at the entrance of the exhibition. This one also uses nannou for everything, including triple-window fullscreen graphics, the GUI, particle systems, flow-fields and integration with an Arduino laser sensor via serial-over-USB. We shared a lot of the assets, physics and particle system code between the projects to try and maintain a theme throughout the exhibition while keeping things simpler for us. A lot of the graphics code in these projects was quite low-level, setting up our own vulkan graphics pipelines, writing custom GLSL shaders, etc. We wanted to make sure that all the low-level stuff was exposed in nannou and accessible before going on to write higher-level abstractions on top. The experience of using it in a commercial setting in this manner helped us to realise what we really want in terms of a higher-level API, and we're hoping to get around to implementing some of this in the near future. Next up was Pitch Festival in Victoria, Australia - we used nannou to VJ on the main stage for a few of our favourite artists including Avalon Emerson, Daniel Avery and Charlotte De Witte. We wanted to use the gig as an excuse to explore real-time ray-marching in GLSL fragment shaders, which was a lot of fun! We used nannou to write a small GUI that would let us visualise the tempo, sync with the current playing artist and generate rhythmic patterns that we could feed into the shaders for some real-time musical synchronisation. @freesig has put together a (fairly low-level) [shader hotloading example](https://github.com/nannou-org/nannou/blob/master/examples/vulkan/vk_hotload.rs) and has another shadertoy-esque experience [in the works](https://github.com/nannou-org/nannou/pull/310). We normally like to try and get some low-level examples down like this first so that we can feel out the right API before writing a higher-level into nannou itself. Finally, the most recent paid gig was an AV electronic music set we played in Melbourne. /u/Joshua_Batty and I originally started [MindBuffer](https://www.mindbuffer.net/) as a music project accompanied by super-synced visuals, so it's nice when we get the chance to play out :) We played an Ableton Live + Nannou LASER set, where nannou was used to develop the LASER software from scratch using [nannou_laser](https://github.com/nannou-org/nannou_laser). I just checked the old FB event page and found [this vid](https://www.facebook.com/events/1095340663923570/permalink/1134835199974116/). Maybe /u/Joshua_Batty will share a video he took of the laser software itself here? I've gotten carried away here, but hopefully this gives you an idea about the kinds of paid work we have been up to with nannou!
We have automated everything so on fist cargo build, nannou will go and install all dependancies for you. It really is that simple now. This was all due to the amazing work from Tom Gowan who spent a long time getting this right on all platforms.
Not sure how relevant this is to the 12 factor guidelines but for building interactive command based cli apps you might want to take a look at my crate cmdr www.crates.io/crates/cmdr
Hi! I'm trying to access functions from other files, and I'm not sure why it isn't working. Here's what I'm trying to do: abc.rs mod xyz; //The line that breaks it pub fn print_abc() -&gt; () { println!("ABC"); } xyz.rs pub fn print_xyz() -&gt; () { println!("XYZ"); } main.rs mod abc; mod xyz; fn main() { abc::print_abc(); xyz::print_xyz(); } How do I reference stuff from xyz in the abc file?
If you do `a[x.into()]` you can rest assured that the conversion will be lossless, and not be any sort of integer &lt;-&gt; float shenanigans.
I started using nannou to create cool visuals a few weeks ago, and I love it. Thank you so much for the effort! I hope your wish to build a healthy open source community around it comes true, the project really deserves it.
GitHub has promised that all sponsor funds go to the sponsored (modulo processing fees (which they're covering for the first year)), if you believe they'll keep that promise. And in a decent number of cases, the company just wants to write a check and have "the problem" go away, and don't need to know anything more specific than "paying for support". More transparency is never bad (that's what OS is about, imho), but for companies used to licensing closed tools, it's not a requisite. I'm mostly talking about the case where the companies would already be willing to pay for guaranteed library support if it were simpler to get it past payments.
Try replacing that line with use crate::xyz; The mod keyword is used to declare that a module exists, and the use keyword is used to bring an existing item into scope. In this case, the problematic line is saying that yet another xyz module exists as a sub-module of abc.
&gt; checked the old FB event page and found [this vid](https://www.facebook.com/events/1095340663923570/permalink/1134835199974116/). This doesn't actually link to a video, just the event page. Or do I need a facebook account to see it?
I don't think sccache does the same thing. If I start from a clean slate, and make two projects that both only depend on `serde`, and I cargo build in one, then cargo build in the other. How many times is `serde` compiled? With the shared `CARGO_TARGET_DIR` it is only built once. If I use `sccache`, I think it is built twice. I think it has to be, the panic messages included the `TARGET_DIR` so the resulting artifacts are not the same. I would love to discover I was wrong.
Agh sorry about that! The link seems to work for me, but you might be right about needing facebook... The video is probably not worth a FB account :)
Well, first, the [`holding.rs`](https://holding.rs) file is incomplete. With only a partial implementation we can't give no feedback. `tdms_dataypes.rs` file: \- FloatWithUnit&lt;T&gt; can be set to only accept `float` wheter 32 bit or 64 bit in two easy ways. You can use the `num` crate, which extends functionality on Rust's primitive numeric types. With this crate you can use a Float specific trait. If you don't want to pull a dependency for this, implement an empty trait (e.g. `IsFloat)` ) only for `f32` and `f64`. Then you just have to use `FloatWithUnit&lt;IsFloat&gt;`. \- When returning a posibility between a wide variety of types, I would personally recommend to stick with returning enums, as I think it's the way that gives the less headaches. &amp;#x200B; `main.rs` file: \- I don't know how you are going to implement the crate nor do I know much about TDMS, but if you are going to read from a file, maybe it could be advantageous to perform one read of the file, store everything you find in a struct of some sort and implement `Iterator` for said struct. This gives quite the flexibility when you start to operate on the data.
At least on Linux, sync/async are fundamentally different syscalls so even if the compiler was smart enough to inline everything through all of the different abstraction layers, you're still doing different operations. So I don't think you can build a zero-cost `block_on` because it's doing something fairly different between the sync and async implementations.
Hi sevenpost, Thanks for the feedback! Tdms files can potentially contain many gigabytes of data so the idea I was thinking was of reading in all the metadata. Then I was imagining the user could load the channels they desired by calling a list of paths. I will at some point implement a "load-all" function. I'm not really sure at all what the API would look like but I was hoping to make it a library eventually. Edit: I like the idea of implementing iterator, I wonder if I could combine that approach?
By zero cost, I assume you mean without a tokio runtime or any calls to epoll? If that's the case, there are future combinators and manual future impls that couldn't be supported by this synchronous transformation, e.g. `future1.select(future2)`. These types of futures rely on multiplexing operations on multiple underlying event sources and make deep assumptions about their nonblocking semantics.
You mean the I/O calls, right? I assume I'd use trait parameters to abstract the library over an I/O library as well. At least that's how I'd do it on C++.
You might be able to return an `Option&lt;RwLockReadGuard&lt;&amp;Document&gt;&gt;`, although it starts to look icky. I don't know the rest of your code, but if would probably make more sense if `DOCUMENTS` was actually a field in a struct instead of what's basically a global variable.
I see. Yes, even when running in a scheduler, I'd like to implement a small runtime layer instead of using tokio. If possible, I'd rather even go `#![no_std]`, and create a C library. I've played a bit with the experimental support for coroutines in C++ using clang, and the compiler is able to remove the abstraction... but the overall experience when programming Rust is better than programming in C++, so I was wondering if I could do what I want by using Rust instead.
If you want to build something *really* high level, that's probably possible but I'm skeptical that the optimizer will really make it zero-cost.
How did I not know about this project? Rust moving too fast to keep up now. This looks truly awesome ‚Äî thanks for sharing!
Yes, you're right about that. That's what I said ‚Äí there might be use cases where either is the better match.
It's mostly a research project, so if I don't succeed but learn some things in the process that's still good enough. As of now, I'm mostly curious if the Rust compiler would be able to do something like that (writing the same piece of code abstracting over sync and async use cases).
One benefit of `sccache` over local caching is that team members regularly running similar builds can take advantage of each other's build artifacts if you're using networked storage (e.g., S3).
I just got bitten by the fact that `Box&lt;dyn Trait&gt;` can't be dereferenced to `&amp;dyn Trait`; you have to call the `as_ref()` method instead. This is inconsistent with the general rule, which is that `Box&lt;T&gt;` auto-derefs to `&amp;T`. Out of curiosity: what's the reason for this inconsistency?
Thanks for the kind words about lyon in the post. It means a lot! Lemme know if I can help with anything lyon-related!
the docs link does not seem to work
https://docs.rs/juniper-eager-loading/0.1.0/juniper_eager_loading/ On my phone right now. I‚Äôll fix later.
Your best bet is to use async, but depending on what the user wants either make everything serialized (so simply await everything that you started "in the background"), or speed things up by letting things run side by side. &amp;#x200B; Basically let the scheduler concurrency factor run from 1 to whatever you want.
This will never work. Your reference to a document can never outlive the lock you take.
There's 2 options: * The [`alloc`](https://doc.rust-lang.org/nightly/alloc/index.html) crate. This provides the standard container types, but doesn't come with a default allocator. Instead, another crate or the end binary provides an implementation and instance of the [`GlobalAlloc`](https://doc.rust-lang.org/nightly/alloc/alloc/trait.GlobalAlloc.html) trait and tags the instance with `#[global_allocator]`. * Less common and still experimental is [`core::alloc::Alloc`](https://doc.rust-lang.org/nightly/core/alloc/trait.Alloc.html) It's a bit of a higher level interface and it should be doable to pass around references to an instance of it to custom containers. With it, you could have something like `pub struct MyBox&lt;'a, T, A: Alloc&gt; { ptr: NonNull&lt;T&gt;, alloc: &amp;'a Mutex&lt;A&gt; }`. There's also [`alloc::alloc::Global`](https://doc.rust-lang.org/nightly/alloc/alloc/struct.Global.html), which is an instance of `Alloc` that uses the current `#[global_allocator]`
Thx. I have some questions: - In mssql the max number of arguments for in query is something like 2300-2500(i do not know the exact number) what happens if I use more than the limit? - Is it not possible to produce/generate inner join? If the developer knows that the query will produce n+1 queries, let the developer have a way to use specific generator to produce inner join maybe?
Actually, file descriptors on Linux can be configured to be non-blocking, so that I/O syscalls return with a WouldBlock error instead of blocking.
Okay, but if I'm just using unwrap it works?
Thanks for the hard work updating, and for the original post! I consulted it a lot when originally learning actix-web (and Rust) to develop my own API, and it really helped to create a system that leverages a lot of wonderful Rust-ness (like creating a domain-specific error type, translating third-party ones to that, and surfacing in handler to automatically respond with an HTTP request).
Could you please add a post saying what Tokei is ? It's handy for lazy me not to have to follow three links to find an answer. Thanks
Yeah, I've approached it from the first option side, since I'm trying to stick with stable. I'm mainly wondering if that approach would be terrible for reasons I'm not aware of.
A benchmark would be nice where the concurrent maps are read and modified *at the same time (concurrently).*
Sounds good, coming soon
Could you possibly post that working code? I agree with /u/thiez that the underlying issue here is your returning a raw reference to something that needs a lock. This code using unwrap throws the same error? fn read_document(id : &amp;str) -&gt; &amp;Document { DOCUMENTS.read().unwrap().get(id).unwrap() } Error is: error[E0515]: cannot return value referencing temporary value --&gt; src/lib.rs:11:5 | 11 | DOCUMENTS.read().unwrap().get(id).unwrap() | -------------------------^^^^^^^^^^^^^^^^^ | | | returns a value referencing data owned by the current function | temporary value created here
It's the approach the vast majority of crates use. It should also be usable in a program that uses std as it provides a default `#[global_allocator]`.
Interesting, I wonder how it compares to something like [dataloader](https://github.com/graphql/dataloader), which I think is kind of the opposite of this -- lazy batching instead of eager batching. From what I understand, coalescing data loads is extremely important for good graphql performance so this is cool to see
If you have a graphql field that returns that many items you should consider paginating it. It'll be a performance issue regardless. My library doesn't really help you there. It'll happily give you 2000 ids to load. All the library requires is for you implement a trait that defines how load a list of models from a list of ids. You are free to do joins if it makes sense for your app üòä Fixed the docs link by the way.
Totally. I honestly haven‚Äôt looked much into data loader. I know of some libraries inspired by it that uses futures (afaik), but I haven‚Äôt played around with them. I like the caching things they do and would like to do something similar. I actually did in an earlier version but removed it due to the added complexity. I come from the Rails world where eager loading is the go to solution.
Nevermind. I used it before, but used an extra struct like this: pub struct Cache{ pub cache : HashMap&lt;String, CachedFile&gt;, pub value_cache : HashMap&lt;String, String&gt;, } lazy_static! { pub static ref CACHE: RwLock&lt;Cache&gt; = RwLock::new(Cache{ cache: HashMap::new(), value_cache: HashMap::new() }); } But could you explain to me, why this works and the code above not?
There are 128-bit CAS, and hash brown only uses 128-bit wide SSE operations anyways.
&gt; Tokei is a program that displays statistics about your code. Tokei will show number of files, total lines within those files and code, comments, and blanks grouped by language.
If I'd had to guess I'd say `CachedFile: Copy`, but since you haven't once given a complete runnable example my guess is as good as yours.
As I understand it, `serde` is indeed built only once with `sccache`. Cargo will act like it's built twice, since it has to call what it thinks is `rustc` twice, but underneath `sccache` will only execute one compilation. I'm not sure how it handles the TARGET_DIR directories, though it does only execute the compilation once. I just tested by clearing the cache, making two new projects, depending on `serde_json` in both of them, and then compiling one after the other. After compiling, these are the stats: Compile requests 18 Compile requests executed 8 Cache hits 4 Cache misses 4 Cache timeouts 0 Cache read errors 0 Forced recaches 0 Cache write errors 0 Compilation failures 0 Cache errors 0 Non-cacheable compilations 0 Non-cacheable calls 10 Non-compilation calls 0 Unsupported compiler calls 0 Successful distributed compilations 0 Failed distributed compilations 0 Average cache write 0.000 s Average cache read miss 4.015 s Average cache read hit 0.000 s Non-cacheable reasons: crate-type 6 - 4 Cache location Local disk: "/Users/dbross/Library/Caches/Mozilla.sccache" Cache size 4 MiB Max cache size 10 GiB The four cache hits are ryu, serde, itoa and serde_json - the second compilation was almost instant compared to the first (although cargo did act as though it was compiling everything).
I would expect overloading behavior of `std::result::Result` to run into coherence issues? I think having `main` return a custom type would be a good way to handle this, though. Or just having it catch the result and run `eprintln!()` itself, which was the general solution before Termination existed?
As /u/thiez said, it's super hard to tell without a full runnable example. I would expect this code to fail, too - and without more information I can't tell why it wouldn't.
Wrong reddit, this is Rust programming language
Finally, the long awaited ASN.1 support ;)
Ok, here's my full example: #[macro_use] extern crate lazy_static; use std::collections::HashMap; use std::sync::RwLock; lazy_static! { pub static ref CACHE: RwLock&lt;Cache&gt; = RwLock::new(Cache{ value_cache: HashMap::new() }); } pub struct Cache{ pub value_cache : HashMap&lt;String, String&gt; } impl Cache{ pub fn new() -&gt; Cache{ Cache{ value_cache: HashMap::new() } } pub fn add_value(&amp;mut self, name : String, value : String){ self.value_cache.insert(name, value); } pub fn get_value(&amp;self, name : &amp;str) -&gt; Option&lt;&amp;String&gt;{ if self.value_cache.contains_key(name) { return Some(self.value_cache.get(name).unwrap()); }else { return None; } } } fn main() { CACHE.write().unwrap().add_value(String::from("test1"), String::from("Yeah!")); println!("Value of test1: {}", CACHE.read().unwrap().get_value("test1").unwrap()); } Or on playground: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9ed4f124d58abc77a12b5dbbbdb3097d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9ed4f124d58abc77a12b5dbbbdb3097d)
I just made a vscode container which includes rust and all the extensions I wanted. I think you could probably find the container and docker-compose file somewhere on Github.
Amazing work! And I have one question for you guys, and please, I'm not trying to raise a ware here. It is out of curiosity that I'm asking and because I want to learn more. That being said: why not python? I always hear about the joys of python as a prototyping and scripting language, and I always thought python would be a way better fit for that kind of stuff. Is it rust's performance? Anything else I'm missing completely?
This is getting into the realm of sophistry, I fear, and the time I can spend on this answer is limited. A cishet person who does not behave as described can easily just go "Eh, probably not meant to apply to me." Claiming that it is necessary to exhaustively list out every specific thing done to the LGBT+ community or it auto-includes people minding their own business is rather silly.
Right! In this case, the reason it works is that you aren't returning the value from the function you get it in. When you use the lock "inline" like this, the `RwReadLock&lt;Cache&gt;` is still alive as a temporary value, and it's still alive while you use the `&amp;String`. If you were to put it in a function like you did in the post in OP, it would still fail: fn get_val(name: &amp;str) -&gt; Option&lt;&amp;String&gt; { CACHE.read().unwrap().get_value("test1").unwrap() } They key to getting it to work is that the `RwReadLock&lt;...&gt;` (gotten from `CACHE.read()` or `DOCUMENTS.read()`) has to live at least as long as anything borrowed from it.
`apt-get` is available on more platforms and has a more stable API. apt(8): &gt; The `apt` command is meant to be pleasant for end users and does not need to be backward compatible like apt-get(8).
If you want to avoid this altogether, one option is to store reference-counted `Arc&lt;Document&gt;` values inside your map. Then when you return a value, you can clone the `Arc`, and you won't need to keep the map locked while you use the value. The other option, which is a bit more heavy handed, is to use something like the [`owning_ref`](https://kimundi.github.io/owning-ref-rs/owning_ref/index.html) crate to keep the "lock" alive as long as you're using the value. Using OwningRef would look something like this: fn read_document(id : &amp;str) -&gt; Option&lt;RwLockReadGuardRef&lt;HashMap&lt;String, Document&gt;, Document&gt;&gt; { match DOCUMENTS.read(){ Err(_) =&gt; { eprintln!("Document store is poisoned."); None}, Ok(documents) =&gt; { let owning_ref = RwLockReadGuardRef::new(documents); owning_ref.try_map(|documents| { match documents.get(id) { Some(document) =&gt; Ok(document), _ =&gt; Err(()) } }).ok() } } } ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=571d326e30f4aa5a35932078f6e7f94a)) It's a bit of syntax, but it should work. The one thing to keep in mind is that your lock will remain locked as long as this `RwLockReadGuardRef` exists.
&gt;Part of the problem is that the same text may be interpreted in different ways, specially in the written medium. Yes, and part of good faith discourse is to ask clarifying questions and go back and forth until understanding (thought not necessarily agreement) has been reached. People often argue about what they think is the same thing, but in reality are very different things. &gt; Maybe I was the one out of my mind (I was really tired), but its also subjective and I'm guessing that ambiguity is ONE of the reasons the post wasn't *that* well received. Why do you think it wasn't well received? This is actually one of the few times I've received far more positive comments and useful discussions on reddit, discourse, twitter than I did death threats, suggestions about how to kill myself in bizarre (and frankly inefficient and logistically impossible) ways. In my view that's a win, and was quite well received! To answer your question (I think), I wasn't out of my mind, nor was anyone else. We were acting with urgency, but not carelessly. &gt;What specifically bothers you or you find toxic? I'm unsure how to respond to this. Do you not know the common behaviors towards LGBT+ people on the Internet? Or can you narrow the scope of your question? I mean, being told to kill myself, or that I rape children kinda bothers me and could be considered toxic. If you truly don't know what specifically is toxic and would bother LGBT+ people in online interactions...umm...not sure how to fix that, except to interact with us more, I guess. &gt;Still, I'm always willing to help, and when the opportinity rises, I'll be glad to do my part. Cool! I'm curious what your experience so far has been? Have you found many opportunities to help? Maybe I can learn something from how you approach these situations to handle them more delicately. &gt;I gotta say that the post and all of your interactions made a very good impression, if I ever find some time, I'll give it a try! I'm glad. Hopefully everyone can continue with constructive dialogue, and at least in Rust and Amethyst, avoid the extreme polarization that infects many online communities.
You can create a new `actix_rt::System` then use the `block_on` function to run a future to completion before initialising the HttpServer. I‚Äôm using the [`L337`](https://github.com/OneSignal/l3-37) connection pool, and my code looks like [this](https://github.com/mordhub/mordhub-backend/blob/master/src/main.rs#L50).
it will relaunch if it is registered to do so (with the init system).
I've moved a fairly complex project over to bazel, and not having good editor tooling has unfortunately really hurt momentum (should have foreseen that). Does anyone have an idea how this could work with bazel / rules_rust? I'm assuming rules_rust might need to be updated to get `project-lock.json` support.
I'm pretty much out of emotional bandwidth to keep up with this thread multiple time per day, and I think (hope) that all the major questions/concerns have been addressed. If you have questions/comments specifically for me or about Amethyst in general, feel free to visit us or send me a DM here. I have to say, this went WAY better than I've seen it to go in previous communities over the past decade. In particular, I want to thank all the cishet men and women who posted their support. *That* is how you be a respectful ally, and I promise you, it meant a lot to us. One thing that isn't often talked about or even acknowledged is the shaming and attacks our cishet allies who actively show support sometimes suffer from taking a public stance, even in an anonymous and online environment. &amp;#x200B; Thank you. &amp;#x200B; You are all welcome over in our Discord anytime.
Are redundant conversions more expensive? That is, if I call happen to call `.into()` to turn `T` into `T` when returning from a function, is it more expensive than just returning `T`. For example, I have a trait that takes three type parameters, `T`, `U`, and `V`, and `Self` is of type `T`. `T` implements `From&lt;U&gt; + From&lt;V&gt;`, and at the end of a member function, I have a value of either `U` or `V`. Since the function returns type `T`, I call `.into()` on any value before it is returned (unless it is already of type `T`). ``` fn go(val1: T, val2: U, val3: V) -&gt; T { if cond1 { val2.into() else if cond2 { val3.into() else { val1 } } ``` The thing is, most implementations of the trait will result in `T` being the same type as `U` and `V` (`MyTrait&lt;i32, i32, i32&gt;` (or the same with `f32`) will be the case probably 80% of the time). Will that redundant `.into()` slow down my code at all, even in the slightest bit? It's only important because this function could be called, for example, multiple times per frame in a game, or a similar situation where speed is important. Any comment is appreciated! Thank you!
Can someone please explain 'scalability'?
So you basically have a hard non-Rust dependency on Macs now? What about those Windows platforms with Intel Skylake/Broadwell gpus, are you abandoning them?
As long as you're compiling for release, `.into()` from `T` to `T` should be a nop: see [this sample function](https://godbolt.org/z/vj-EQn).
Can you give an example? I'm not sure I understand; you can ref a `Box&lt;dyn Trait&gt;` just fine into a `&amp;dyn Trait` [like this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e0d8d216abe634a324c04fbdc01193a0).
Thank you for your in-depth comment. That line of work seems so interesting to me. As a bit of a generalist, audio, graphics, and programming are my three 'passions'; though truth be told, they often feel at odds with each other and compete heavily for time and attention. Your description sounds like it would be the synthesis of these fields. Have yet to encounter another career that encompasses those domains.
As far as the kernel is concerned, `errno` is just a basic `int`. All of the macros and functions and such you see in libcs are just wrappers around that `int` to provide things like threading support.
The part I‚Äôm confused about is how the kernel and the application coordinate the location of errno in memory. I guess the kernel checks in the symbol table whenever it runs a binary or something. I still don‚Äôt know how to declare and define that variable in Rust instead of c though.
Probably something like that; I am not yet familiar with that level of kernel/libc interaction. All I know thus far is that `errno` must be declared as a global symbol.
Often times these sorts of software are deployed in museums or public exhibits of some sort. For any non-simplistic visualization, it is difficult to keep track of every code path. And for exhibits it's a really bad look to have something like `IndexError Key Not Found`
At the syscall level, `errno` isn't a thing. When a C program calls a libc function backed by a syscall, like `write`: - libc takes the arguments and gets them into the form expected by the `write` syscall. - libc invokes the syscall API with a small chunk of assembly code - libc examines the value returned from the syscall. If it looks like an error, libc stores it in the `errno` variable and returns -1, otherwise libc returns the value as-is. In particular, for musl libc, the return value mapping is done in [`src/internal/syscall_ret.c`](https://git.musl-libc.org/cgit/musl/tree/src/internal/syscall_ret.c). If you're writing your own pure Rust libc replacement, don't bother with `errno` at all, it's a terrible design pattern that came about because C doesn't allow a function to return multiple values. Rust does allow that, with `Result`, so use that instead.
That is much more in line with what I know so far. I managed to confuse myself by searching the kernel sources for `errno`. Never answer technical questions late at night, folks.
::std::io::Error::last_os_error() checks errno and turns it into an io::Error
errno isn't a real thing. The libc creates it. If you want to be libc you need to convert the aha all's return value into errno.
Okay this makes more sense. The source of my confusion then, is the documentation of the syscalls in the man pages. For example open(2) supposedly describes a ‚Äúsystem call,‚Äù and states that it returns -1 and sets errno on failure. I guess, then, this isn‚Äôt actually documentation for a literal syscall, but then what is it documentation for? And where can I find documentation for the syscalls?
If you go to submit a post from your front page and type in "rust" for the community (at least on mobile) it doesn't show you posts from that community.
Okay, that's good to hear. Thank you! Would it be different when compiling with the dev/debug profile?
Yeah, I imagine you'd have the overhead of calling \`into()\` there, since it wouldn't be optimized away - the function for the \`From&lt;T&gt; for T\` impl doesn't actually do anything, but you incur the cost of pushing the arguments onto the stack and calling and such. I don't think it'd make too much of a difference; I imagine there are many much greater sources of inefficiency in a debug build.
Yeah, even the "low-level" manpages like `open(2)` are really describing libc's wrappers rather than the syscalls themselves. I figured out the things I wrote above by looking up the generic wrapper `syscall(2)`: &gt; `syscall()` saves CPU registers before making the system call, restores the registers upon return from the system call, and stores any error code returned by the system call in `errno(3)` if an error occurs. If you want to learn more about the interface libc uses, rather than the one it implements, I guess you want to look for information on accessing system calls from assembly language. For example, [this](https://en.wikibooks.org/wiki/X86_Assembly/Interfacing_with_Linux) or [this](https://linux-kernel-labs.github.io/master/lectures/syscalls.html), or [this](http://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/).
To perform a syscall in Linux/x86 for example, what you do is load some CPU registers with values and then call the `syscall` instruction. For example, `RAX` holds the number of the syscall, `RDI` might hold the first parameters, `RSI` the next and so on. Then after the `syscall` instruction returns, it sets `RAX` to a result which can indicate an error code. A wrapper for the `open` syscall in a typical libc would set up the registers, do the syscall and then check the result. If the result indicates an error, then it would set the `errno` global variable and return `-1` otherwise it could return something like the new fd. So `errno` is really just a convention used in some libcs, not anything to do with syscalls or the kernel. You could make your own libc that dispensed with `errno` completely and provided error values in some other way - though of course it wouldn't be compatible with existing programs.
ASYNC is a flag passed to open http://man7.org/linux/man-pages/man2/open.2.hml . The system calls remain the same. Notice how Writev(3) system call they discuss the syscall memory model? http://man7.org/linux/man-pages/man2/writev.2.html Anyways all system calls have to go through LIBC to ensure platform compatibility with the host kernel.
This was a super interesting read! You should add it to the website :-)
&gt; Rust is a multi-paradigm system programming language focused on safety https://en.m.wikipedia.org/wiki/Rust_(programming_language) https://doc.rust-lang.org/stable/book/
Ah yeah, that makes sense. Thank you for your help! Turns out I'm not going to be able to use this anyways, because I was using the trait `PartialOrd` which doesn't have implementations for arbitrary types like I assumed it did (for example `PartialOrd&lt;i32&gt; for i64`) so I will end up just using a single type, `T` instead. That said, thank you again. Even if I don't use it here, that was a valuable lesson nonetheless!
That is a pretty bespoke scenario, so I'm not really sure if standard library has anything off the shelf you can use. Digressing a bit: I would use match instead of `if let ... else ...` since you're not only matching one single pattern, and using match makes it more obvious in this case. That is: ``` let min_good = match min_good { None =&gt; Some(back), Some(min) =&gt; { if min &gt; back { Some(back) } else { min_good } } }; ``` IMO it's more obvious what you're trying to do with the match above, while it's a bit twisted when reading `if let` clauses with an `else` in it somewhat.
As far as I know, `Option&lt;U&gt;` automatically implements `From&lt;U&gt;`. When you call `Option::map_or()`, you return `U`. As such, you can use `Option::map_or().into()`. The only downside of the method is that it requires you to annotate the return type. If my explanations are not clear enough, feel free to ask more questions!
As far as I know, `Option&lt;U&gt;` automatically implements `From&lt;U&gt;`. When you call `Option::map_or()`, you return `U`. As such, you can use `Option::map_or().into()`. The only downside of the method is that it requires you to annotate the return type. If my explanations are not clear enough, feel free to ask more questions!
`Some(opt.map_or(init))`?
You can use: ```rust min_good = Some(min_good.map_or_else( || back, |min| if min &gt; back { back } else { min }, )); ``` I prefer the syntax of: ```rust min_good = min_good .map(|min| if min &gt; back { back } else { min }) .or_else(|| Some(back)); ``` but it will call the two functions each time.
Hi - rust lurker here. Could you give an example of when it would be useful to define a trait that can be used but never implemented?
Also nobody mentioned yet that errno is not a variable, it's a macros that expands to a function call. So you can't access it like a normal global variable.
You might consider the owning_ref crate
Sure! The main use case is when a library wants to allow users to write code generic over multiple structures defined in the library, but does not want to allow the user to implement that trait themselves. In particular, this allows adding methods to the trait to be backwards compatible (since all implementations are in the same library), whereas otherwise, adding non-default methods to a trait is a breaking change. See the [sealed trait](https://rust-lang-nursery.github.io/api-guidelines/future-proofing.html#sealed-traits-protect-against-downstream-implementations-c-sealed) API pattern in the api guidelines. One such example trait is [`byteorder::ByteOrder`](https://docs.rs/byteorder/1.3.2/byteorder/trait.ByteOrder.html). Since it's sealed, byteorder can add more methods to it without that being a breaking change. The trait is still useful, since users of the library to be generic over multiple byte orders defined within that crate.
how can you check for the type of an `dyn Error`? I created a custom `MyError` but I cannot check for it's type :( i tried match
I just bought the game and I‚Äôm stuck in the loading screen, I tried restarting my pc, lowering the graphics, and I don‚Äôt know what to do.
Digital arts push the limits of their computer. Python, even with the scientific Python stack, can be resource hungry. Interpreted languages are also harder to deploy off site.
Strangely enough, reading [the docs of `block_on`](https://docs.rs/actix-web/1.0.0/actix_web/test/fn.block_on.html) : &gt;Note that this function is intended to be used only for testing purpose. This function panics on nested call. Is this really "the new approach" ? Or are the docs not up to date ?
I think errno is thread safe, so it can't be a global variable. It could be a thread local variable though. But if it is really a function call in a macro, I suppose that function could do a lookup into a global table based on the caller's thread_id.
Wow, this looks amazing - never heard of creative coding before, I think I'll give it a go!
I'd be very interested in knowing the implications of that. Does that mean that the typical case is very fast, but there could be latency spikes occasionally? Does that limit scalability in some way? In fact, it's probably best to put this info in crate description so that anyone shopping for a concurrent hash table would understand the characteristics of ccl-dhashmap up front.
Yeah it probably is. Average case performance is awesome. It does resize concurrently though meaning other threads can still work. The only time you should encounter spikes is if by some chance multiple threads try to access the same chunk at once.
My own use-case was [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8aea6cb2d7c0f68ec5359a8885bcb2c0), which gives me the error "doesn't have a size known at compile time". If I change it to an empty trait (as in [this StackOverflow question](https://stackoverflow.com/questions/49218474/how-to-convert-a-boxed-trait-into-a-trait-reference)), the error changes to "the trait bound is not satisfied". If I change it to `std::fmt::Display`, then you're right that it does work. I think you've stumbled across a corner case with your example. The standard library has a blanket `Display` implementation: impl&lt;'_, T&gt; Display for &amp;'_ T where T: Display + ?Sized If you change it to almost any other trait (say, `std::ops::Neg`) then the inconsistency becomes more clear.
I‚Äôm glad it was useful to you, as pointed out in this thread I‚Äôll be updating it again to leverage the newer 1.0 api to make it even simpler. üôèüèΩ
Thanks for referencing data loader! Wasn't aware of it. Made a very simple node.js lib with a similar idea 7 years ago: https://github.com/kolloch/aggregate it would be interesting to combine this idea with transactionality. Maybe data loader does?
Step 1. head over to /r/playrust because this sub is dedicated to the programming language Rust, not the game :) &amp;#x200B; Have a nice day, and i hope you get the problem fixed soon and have a lot of fun playing it.
reqwest definitely works. It‚Äôs used in many crates and projects, including some of my own. I would suggest trying to track down why you have multiple executors. Alternatively perhaps try taking [one of the examples](https://github.com/seanmonstar/reqwest/tree/master/examples) as a starting point and build on top of that.
I have no clue what's an executor that's a library detail how am i supposed to one why it happens ? I have only one request from my app that's the weird part and it falls so i can definitely say that reqwest doesn't work
&gt; I guess, then, this isn‚Äôt actually documentation for a literal syscall, but then what is it documentation for? For a libc pseudo-syscall wrapper. Here [as defined by posix](http://pubs.opengroup.org/onlinepubs/009695399/functions/open.html) but others will be e.g. glibc wrappers to platform-specific syscalls e.g. [clone(2)](http://man7.org/linux/man-pages/man2/clone.2.html). &gt; And where can I find documentation for the syscalls? The kernel doc for linux, possibly some manpages (e.g. syscall(2) and syscalls(2) on linux). It's important to note that on most platform calling syscalls directly (bypassing the platform's library) is *not supported*. It is on Linux because the Linux project is "just" a kernel (and needs to provide an API/ABI for distributions). BSDs or Windows ship as *systems*, the kernel and standard library are part of the same system, evolve in lockstep, and bypassing the stdlib is risky at best and impossible at worst (IIRC, windows syscall numbers change pretty much all the time).
You definitely can. It is required by the ISO C standard to be modifiable by user code, you can take a pointer to it, etc. In GNU libc it is [defined as](https://github.com/lattera/glibc/blob/master/stdlib/errno.h#L37): ``` extern int *__errno_location (void) __THROW __attribute_const__; # define errno (*__errno_location ()) ``` The function `__errno_location(void)` returns a pointer to a thread-local `int` which contains the value, so the statement `errno = 5;` will assign to that thread-local variable.
I've got the same error with `reqwest` as you did, seems like the newest version, \`0.9.18\` does something that causes it. Try using the previous one, declare it in Cargo.toml as \`reqwest = "=0.9.17"\`, that worked for me. There's an issue open, so hope it gets fixed soon: https://github.com/seanmonstar/reqwest/issues/541
Basically, the ability to handle increasing load without changing the software, just potentially throwing more hardware at it.
That issue is also by me I am also hoping to get it fixed but meanwhile my project just sits and waits for this fix
For the situation where debug becomes unworkable, there's also the compromise of using "opt-level = 1" in the dev profile, while still generating debug info.
Ah great, thank you for reporting it. &amp;#x200B; Did you try updating your Cargo.toml as I've proposed? Using \`reqwest = "=0.9.17"\` there worked for me, so no need to just sit and wait. &amp;#x200B; Speaking of the project, it would be really helpful if you could post a link to it to the ticket you've created, so that the maintainer could easily reproduce the issue.
I'm using reqwest inside an actixweb endpoint someone suggested it might be because actixweb endpoints are async as well but this is a library why and how am I supposed to know the internals
This is exactly what I've said, it's a macro that expands to a function call. And you can't access it like normal global variable, this Rust code (which OP said he tried to do) will not work: extern "C" { static mut errno: isize; }
An executor is whay runs Future's in Rust, and comes from the Tokio library.
Something like dataloader will be a good fit once juniper supports Futures/async.
Are you using two libraries that both use `tokio` behind the scenes? If so, I think it's because you are executing a HTTP request in one library and whilst you are processing the result you are attempting to make another request using a different library and hence you get that error. I had the same issue when I did this: 1. Use `hyper` to make the initial request, and when the result arrives (in the `and_then` method or whatever it is called) ... 2. Make another request using `reqwest`... 3. I get the error `attempted to run an executor while another executor is already running`. If you can make a minimal example that'd be great. Otherwise, I might attempt to do it since I got the same error. The error disappeared when I just used `reqwest` for everything. Hope that helps.
They're using `actix-web`, so yes.
"Why not python?" is a question that holds for any field. If you think your specific field is better suited by using something else than python, then you don't know enough about this field. Creative coding is very resource consuming. You'll want access to all the features of your GPU. You'll need to specify direct buffers so that the GPU can actually perform whatever task you want. You'll want to use anything that can help you interface with any other device you have via network or whatever fancy hardware protocol there is. Python might provide that. Rust might have a crate. Python is great. Rust is great. But I prefer nannou over processing.py for example. And I've been doing years of processing before switching to nannou :)
How can I work around the fact that some types in Rust are hard (near impossible?) to write down? For example if I create an instance of a type where all the generic type arguments get inferred for me because it's a local variable, and then I'd like to create a function that returns that same instance... how do I do that? I know about \`impl\`, but that doesn't seem to apply to my case. Motivation: I'd like to write a bunch of tests for my actix\_web application. I'd like to not repeat myself over and over with setup code like \`\`\`rust let \_ = actix\_rt::System::new("actix-runtime"); let mut app = test::init\_service(App::new().configure(move |cfg|configure\_app(cfg))); \`\`\` and instead would just like to create a \`make\_app\` function that returns the same thing I have in my \`app\` local variable there. How do I do that? The only workaround I can see is using a macro that is unhygienic and thus puts stuff in my local scope. Which isn't as nice, I feel.
What about `.ignore` as supported by rg/ag/‚Ä¶ following https://news.ycombinator.com/item?id=12567328 ?
https://crates.io/search?q=base64
Great, I'm trying it out! After downloading a file in Bitflow and having it in Drive I'd love the ability, as per Seedr.cc, to right-click on a file and 'copy dwnload link' - this way you can paste the file's url into an app without having to download the whole thing to local storage. Is this possible?
impl From&lt;String&gt; for PnGImage or something like that?
Good catch. Updated
Thanks for this gread post, and update, that helped me a lot writing my own tiny website. A question: are you sending the email in a synchronous fashion?
At that point you might as well `Some(Option::map_or())` directly no?
If you're shoving around multiple HD video streams in Python, you'll be doing it using C-binding libraries anyway. So then it's more of a question of why Rust instead of C? They do a pretty great job of answering that question [here](https://guide.nannou.cc/why_nannou.html#why-rust)
Randomly adding * and &amp; gives me this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=74ee0228f9a616da2dca1749040672e8
Fair enough
&gt; Is there any way to do this? It's *always* possible in a turing-complete language but, to answer the question you intended, yes. The portion after `data:image/png;base64,` (beginning with `iVBOR`) is the raw contents of the `.png` file, encoded in base64. 1. Slice out that portion of the data URI 2. Decode it using [base64](https://crates.io/crates/base64)`::decode`. 3. Decode the resulting bytestring using [image](https://github.com/image-rs/image)`::load_from_memory` or `image::load_from_memory_with_format`.
In other languages you use something like try/catch to catch exceptions. If something goes wrong in the try block it does something with the catch. However from what I've heard Rust made an active decision to not go down this path, and instead use Result types, as they may be better performance and complexity wise. In rust a function that may error will return a Result&lt;T, E&gt;. If everything went Ok, then it will return an Ok(T), but if something went wrong, it will return an Err(E). Both T and E are generic types, which means they may vary from function to function.
On the crates.io page, about the current async solution, I read "This is a current patch in the waiting of a better asynchronous solution.". Will this get better when async/await get stabilized?
In short, it means that exceptions are merely values, a struct/enum, handed around in the program. An function in Rust that can produce an exception will return either a value representing a successful result (Ok), or a value representing an error (Err). However, Rust has native support for unwrapping results using the ? operator
Yes I do think so. It should be easier to draft a new `Storage` that works asynchronously. :)
Do I have to do something besides dropping a stream when I want to deny an incoming connection over a TcpListener?
Well that just raises more questions üôÉ I love Rust, but it can be a bit perplexing sometimes...
Yes sending emails is a sync api AFAIK
As the author of scc another code counter I‚Äôd like that and implement it. To be honest I may just add it anyway, but I‚Äôd love Tokei to follow it as well.
My understanding is that .ignore is pretty much ".gitignore without the git part" so the spec would be gitignore(5) (ping /u/burntsushi is there something more specific or a ".ignore project"?). Rust projects probably have it a bit easier as /u/burntsushi also provides the ignore crate.
Absolutely, thank YOU for making lyon! We have been playing around with it for creating paths for laser projectors recently and it's been a joy to use. We are going to start on a lyon branch for 2d graphics soon, i'll open up a PR and invite you on Github into the conversation and we'll take it from there. Cheers!
Exceptions can cause undefined behaviour. Rust doesn't like undefined behaviour. As the other comments have noted, the \`Result\` type allows for passing up errors, with the \`?\` operator providing a means of easily bubbling the \`Result\` error up the call stack in a predictable fashion.
Yep. From what I have looked into that‚Äôs exactly what it is. You have moved me. I‚Äôll implement this in the next scc release. I have been meaning to add recursive ignores for a while now so I may as well do this at the same time.
You are probably looking for /r/playrust
To add, [panics](https://doc.rust-lang.org/book/ch09-01-unrecoverable-errors-with-panic.html) are roughly analogous to exceptions as you're used to. That page explains there's a cost to the traditional exception model, and rust is intended to go anywhere C goes. Very low memory embedded targets for example can't really afford code bloat and perf hit from exception handling, and need to be able to opt out without sacrificing idiomatic error handling. With Result/Option the compiler can follow the normal, relatively straightforward path. If something fails, you're forced to check it via [exhaustively matching](https://doc.rust-lang.org/book/ch06-02-match.html?highlight=exhaus#matches-are-exhaustive) over an Option/Result (or using the ? operator which basically writes that code for you) or explicitly turn it into a panic with operations like [.expect("Some crash message")](https://doc.rust-lang.org/std/result/enum.Result.html#method.expect) for example.
I've not found anything that works easily with ntlm auth yet.
I have a struct in which a TcpStream resides: struct Basic { timer: Timer&lt;usize&gt;, data_timeout: Option&lt;Timeout&gt;, test_data: [u8; 6], stream: Option&lt;TcpStream&gt;, } later, after initializing this struct, I want to send stuff if the stream does exist: fn tcp_sender(basic: &amp;mut Basic) { if basic.stream.is_none() { return; } basic.stream.unwrap().write(&amp;basic.test_data); } The compiler figuratively says I'm stupid: cannot move out of borrowed content I think I get the problem: The unwrap moves the ownership. But how do I solve this? I want a function which only sends if a stream already exists and doesn't do anything if there is none yet. Is there a smarter way to solve this? Maybe hand over a copy when calling the function and checking the Option in the caller?
/u/Manishearth's suggestion expanded min_good = Some(min_good.map_or(back, |min| cmp::min(min, back))) Maybe this is a little more readable, though: min_good = match min_good { None =&gt; Some(back), Some(min) =&gt; Some(cmp::min(min,back)), }; If you do this in a loop it might be possible to rewrite this in terms of iterators which then allows you to write something like this: let min_good = some_iterator_of_i32.min(); Consider whether it's possible to do so and how it would look like.
``` match &amp;mut basic { Some(stream) =&gt; { // Use stream } _ =&gt; unreachable!() } ```
Yes, the spec is indeed in `man gitignore`. (We even got bug fixes applied upstream to the spec itself, with respect to the intended behavior of `**`. ripgrep followed the spec, but git's implementation was different. The spec was changed to follow the implementation.) One caveat is that ripgrep supports `{a,b,c}`-style globs where as git does not. It's likely that support for those will be removed at least from ripgrep's support for `.gitignore`. I haven't decided yet whether support for those should also be removed from `.ignore` or `.rgignore`.
Within the definition of Box there's a pointer, and that pointer gets replaced with a fat pointer (i.e. a pointer/vtable pair)
What's the difference with if let? Can I create a variable with if let which can be used outside of the match-expression? My problem with match is that it often enforces too many indentations
Actix-web actually has it's own HTTP client, which you may wish to use if you're already using actix-web: https://docs.rs/actix-web/1.0.0/actix_web/client/struct.Client.html
Be warned, getting the ignore files correct has been, and continues to be, one of the hardest parts of building and maintaining ripgrep. ripgrep does _a lot_ better than ag, but there are still a couple outstanding bugs. And figuring out how to fix them is generally pretty tricky. And making them fast is also quite difficult. The code itself is a mess too.
In short you have to write it like this ``` // Return Result&lt;T, E&gt; let result = foo(); // Not the real error handling, but pretty much it looks like this if result.not_error { // Do something }else{ // Warn the user } ```
It's not so enigmatic if you follow the types one by one. `source: &amp;Box&lt;dyn ...&gt;` `*source: Box&lt;dyn ...&gt;` `**source: dyn ...` Thus `&amp;**source: &amp;dyn ...`. Automatic conversion you mentioned is called coercion in Rust, but it doesn't seem to be the case in this situation: https://doc.rust-lang.org/nomicon/coercions.html
Executors are actually external to the library. Rust provides Futures, but they're an empty shell that has to be filled by libraries like reqwest and run by executors like tokio. This is necessary so you can do multiple things (maybe from different libraries) at the same time in the same thread.
The theory is there but do you have any suggestion to actually fix this problem I'm having. I don't want to make the request async I need to return the result from the endpoint but seems I cannot do it if I wanted everything to be async I would just go use nodejs
&gt; We even got bug fixes applied upstream to the spec itself, with respect to the intended behavior of **. ripgrep followed the spec, but git's implementation was different. The spec was changed to follow the implementation. Funny. What was the divergence? And I'd guess the other way around was probably not an option but was it your preferred change (aka if you could choose did you prefer the specified or the implemented behaviour?)
As u/nicoburns said, Actix has a Client. You could look at this example: [https://github.com/actix/examples/blob/master/http-proxy/src/main.rs#L21](https://github.com/actix/examples/blob/master/http-proxy/src/main.rs#L21)
Could you elaborate what undefined behaviour exceptions can cause exactly? I haven't heard of this and want to learn.
r/playrust
\`libc\` does not require \`std\`
Post that in /r/playrust, this subreddit is about the Rust programming language
Ups lol sorry :D
But different Rust code will work. The \`libc\` crate exposes \`errno\`.
I'm very excited for that :)
I think that Kotlin has a lot of competition with other JVM (and perhaps .Net) languages, while Rust is really competing with C/C++, and languages that regularly use C/C++ libraries.
&gt; Funny. What was the divergence? The spec used to say this about `**` (emphasis mine): &gt; Two consecutive asterisks ("**") in patterns matched against full pathname &gt; may have special meaning: &gt; &gt; * A leading "**" followed by a slash means match in all directories. For &gt; example, "**/foo" matches file or directory "foo" anywhere, the same as &gt; pattern "foo". "**/foo/bar" matches file or directory "bar" anywhere that &gt; is directly under directory "foo". &gt; &gt; * A trailing "/**" matches everything inside. For example, "abc/**" &gt; matches all files inside directory "abc", relative to the location of the &gt; .gitignore file, with infinite depth. &gt; &gt; * A slash followed by two consecutive asterisks then a slash matches &gt; zero or more directories. For example, "a/**/b" matches "a/b", "a/x/b", &gt; "a/x/y/b" and so on. &gt; &gt; * **Other consecutive asterisks are considered invalid.** Now it says this (emphasis mine): &gt; Two consecutive asterisks ("**") in patterns matched against full pathname &gt; may have special meaning: &gt; &gt; * A leading "**" followed by a slash means match in all directories. For &gt; example, "**/foo" matches file or directory "foo" anywhere, the same as &gt; pattern "foo". "**/foo/bar" matches file or directory "bar" anywhere that is &gt; directly under directory "foo". &gt; &gt; * A trailing "/**" matches everything inside. For example, "abc/**" matches &gt; all files inside directory "abc", relative to the location of the .gitignore &gt; file, with infinite depth. &gt; &gt; * A slash followed by two consecutive asterisks then a slash matches zero or &gt; more directories. For example, "a/**/b" matches "a/b", "a/x/b", "a/x/y/b" and &gt; so on. &gt; &gt; * **Other consecutive asterisks are considered regular asterisks and will &gt; match according to the previous rules.** Basically, `**` was considered invalid, but `git` treated it as valid. ripgrep was previously emitting warning messages, and it turned out that a lot of folks were using `**` in weird places: https://github.com/BurntSushi/ripgrep/issues/373 &gt; And I'd guess the other way around was probably not an option but was it your &gt; preferred change (aka if you could choose did you prefer the specified or the &gt; implemented behaviour?) I didn't really have a dog in the fight. I just didn't want to implement something that diverged from the spec, only to have the git implementation changed later to match the spec. Personally, I would have preferred that git just reported an error for "invalid" `**` usage from the get-go, but it's completely reasonable why they wouldn't change the implementation to match the spec later. Otherwise, lots of .gitignore files would become broken. (In fact, a lot of people have "fixed" their .gitignore files as a result of ripgrep warning about the invalid syntax. Hah. Which it no longer does because the spec was updated.) &gt; Is there an upstream testsuite of some sort so the various project trying to &gt; parse and apply .*ignore filters have a good basis or does every project get &gt; to enjoy rediscovering every edge case? I actually never checked. ripgrep has certainly grown its own test suite though.
Because they're all on /r/androiddev
From what I could tell kotlin has a very active community on [official slack](https://kotlinlang.slack.com). I think it is just the fact that /r/kotlin never had the critical mass of active users on reddit, while community here is very active.
`unwrap` takes `self`, which consumes the the `Option`, hence the moving it out of `basic`, with nothing to replace it. Instead, you can call `.as_mut`, which will turn the `&amp;mut Option&lt;TcpStream&gt;` into a `Option&lt;&amp;mut TcpStream&gt;`. This new option *isn't* owned by `basic`, so you can unwrap it safely. That said, checking for `is_none()` usually isn't the approach you want to take. In this case, you can use if-let: fn tcp_sender(basic: &amp;mut Basic) { if let Some(stream) = &amp;mut basic.stream { stream.write(&amp;basic.test_data); } } This avoids the `is_none`, the early return (which you can still do in an `else` block, if necessary), and even the call to `as_mut`.
You're using a low level language, it's bound to happen.
I am using a high level library I'm not writing a brand new http client
I think because Rust team/community/Mozilla did a good work presenting Rust on media. Rust-related sites have nice flat-styled modern design (are we yet sites), docs have beautiful fonts, eye-friendly colors. Colorful messages in rustc, cargo, and all other stuff give an impression of a language made with love. Haven't really used Rust, but it is what I feel. After hearing all these slogans, now I think of Rust as a robust, modern, community beloved programming language that is superior to C++
kotlin ain't got no memes
If you‚Äôre running a server on the same thread, you can‚Äôt make that synchronous, otherwise the whole server won‚Äôt respond while it‚Äôs waiting for that HTTP response.
Yes, a different code will work, you can call libc::__errno_location() and get your raw pointer, great. I think OP was under the impression that errno is just a global variable, so I pointed out that it's not the case. I don't see anything wrong with what I've said.
That makes sense
You're using a high level library with a low level language. It's the same reason CPython is single threaded. If you don't want to use a low level language, then don't.
Honestly, when parsing something that encodes specific data in a format, I'd recommend using a parser framework instead, such as [peg](https://crates.io/crates/peg) or [nom](https://crates.io/crates/nom.. This will also validate magic bytes within the data.
What you wrote is technically true, but not really helpful for a person who does not already understand the difference between both concepts (errors-via-exceptions vs errors-via-results).
I wouldn't recommend downgrading, it's not a bug in reqwest. It is noticing that you are making a blocking network request while inside a non-blocking future, likely a server. While that request is blocked, your server is likely hanging and being unresponsive to any other request. The fix is to just change from the blocking reqwest client to its async client. If you're already inside a future, you can return reqwest's future.
See mdsherry post. He has the example with if let. I personally find myself often in the position that there must be a socket and if not its an error. In these cases I use match with unreachable!. I would use if let with else if I want to handle both cases of having or not having a socket.
Switch from `reqwest::Client` to `reqwest::async::Client`. That all. This error has warned you that while the blocking network request was waiting, your server was likely hanging unresponsively. You may be using a library, but a web developer needs to know when they are making blocking and non-blocking actions.
Thanks for your reply. But isn't Rust doing same thing?. Returning value in OK and error in Err. This is what we do in try/catch. I might be missing something. Can you please explain a bit?
Hi, chttp maintainer here. I saw your issue you opened and am working hard on a fix. Don't run away yet! Sometimes it can take a couple days for tricky bugs to get fixed in open source, especially if you only have a couple unpaid volunteers...
You're correct about that. In modern libcs that support threading, `errno` is indeed usually a TLV or the like. I was just trying to give an example of how the syscall and `errno` setting process worked generally, rather than a specific example that took into account all the factors a libc has to deal with like threading.
They are the same thing in that they achieve the same outcome, but they are not the same thing in performance. Raising and catching an exception is a more expensive process than simply returning a value and checking if it's an error. Also, in languages with exceptions, usually any exception can be thrown at any time and you need to read the documentation (which is hopefully accurate) to even know what to catch. In Rust, the possible errors are encoded directly in the return type, and if you use `match` to distinguish them, the compiler will force you to consider all possibilities.
The catharsis is strong with that meme sub.
Not entirely. Rust doesn't let you just pretend the error path is not there. In, say, Python, I can write this: def two() -&gt; int: if random.random() &lt; 0.5: raise Exception("oh my god everything is on fire") return 2 def four() -&gt; int: return two() * 2 def main(): print(four()) And this program will work (and typecheck, even assuming strict typing), and `main` will crash when called. Note that I'm not handling the exception, or even the _possibility_ of an exception in `four()` - it just passes through and bubbles up into `main()`. In Rust, I have to declare upfront that `two()` returns `Result&lt;i64, SomeErrorType&gt;`, and I _have_ to handle the possiblity of an error in `four()`, either by explicitly letting it bubble up with `?` or by handling it in some other way (providing a default?).
Cool I'm looking forward to it I prefer good old curl over all this complications for my case I just simply want to send a request and wait for it I really like chttp How long do you think it'll take ? I'm just kinda running against a deadline
I can't speak for Kotlin, but as an in-love Rust user; Rust has a lot of community activity, trajectory, friendliness/etc. Not that Kotlin doesn't, but there's a weird critical mass for communities that I think is important for people to actually subscribe, stay involved, etc. I frequently see questions, new ideas, new frameworks, updates on the language, etc. I can check /r/rust multiple times a day and often see something interesting. This naturally brings people in. I think _any_ subreddit lacking in this level of activity has a much slower growth. Yet, once you start to get that your activity snowballs. I'm not sure where /r/rust sits on that "activity snowball" front, but it definitely feels active enough for that activity to gain subscribers alone. My 2c
Right, say you have a function `parse` that takes a string, returns an integer but might fail. In Python for example, `parse` would raise an exception, but it is down to the programmer to remeber to `try`/`except` to catch the exception. In Rust, the function would be `fn parse(s: String) -&gt; Result&lt;i32, Err&gt;` where `Err` is your error type. In Rust, you can't use `Result&lt;i32, Err&gt;` as an `i32`, which means the programmer has to handle any potential errors.
It's OK to make a request while processing another, that's how a proxy usually works. This error only happens if you try to use the blocking client while running inside an async server. The solution is just to use reqwest's async client.
Personally I would be inclined towards a state machine rather than serde for a task like this.
Rust gets now news because people are adopting the language from a variety of previous languages. The obvious migration is from C/C++ where Rust's speed and low profile make it usable as a replacement, and the package management, memory safety, linting and functional language features make an attractive development environment. There is a smaller migration for Node developers who want a more structured language, but don't want to abandon package management. Cargo is a great upgrade from npm/yarn, and the speed and reliability make it a good language to move to if you want to save money on your VPS servers, or you want faster scripts. Finally, I see a migration from functional programmers who want to use a lisp, or Haskell, but want a more pragmatic language with more built in tools and available packages. Rust had enough functional goodies for keeping the quality' of code while providing fast execution, and a compelling development environment with the RLS, and cargo commands. Finally I see programmers looking for an exciting language for hype driven development that like the documentation and community that comes with this language. Discord and irc severs are pretty responsive, and getting past the borrow checker or successfully unwrapping an atomic result option is a cool milestones.
Oh. Good, so Rust did replicate the idiotic sandwich issue from Python.
I found that statement odd too. Certainly, there exist implementations of exceptions that could have UB in them if mishandled. In particular, if you unwind past an ffi interface, then you're almost certainly going to run into UB, and that can happen in Rust too. (IIRC, there was some effort to translate unwinding past an ffi barrier to an abort automatically, but I don't know whether that has landed or not.) The other possible interpretation here is exception safety. It can be pretty easy to corrupt state when using interior mutability when catching panics for example, but this in and of itself doesn't lead to UB. In less safe languages though, this might not be true.
I can't explain why rust doesn't have try catch, but I can explain why I'm happy it doesn't. Try catch is a fancy goto which means it doesn't compose well (or at all). This is because it creates a second point of return that all functions may or may not be subject to, you don't know. With the result type, functions explicitly call out when they can fail (or in the absence of result when they can't fail) and what failures to expect.
A deadline? Hmm, I think i can publish a workaround in an hour or two. I think the full bug will be fixed this evening (CDT) so maybe 12 hours?
According to the TcpListener documentation, ‚Äúthe socket will be closed when the value is dropped.‚Äù Presumably, this means if you want to deny incoming connections, you can just break out of the `incoming` loop. The TcpListener value will then be dropped when you exit the scope.
I don't know have any good explanation, but I would like share something. I am java developer but I don't know if there is an active forum of Java developers, my 25+ dev team also does not know if there is a Java forum. Most of the info is a quick search away. But I at least check rust forum once a day to know anything exciting coming up. Also if you search then there is a chance that it direct you to Reddit or the rust users forum.
Well, you _can_ if you understand the downsides and don't care ;) Reqwest is crazy simple if you want it to be. Example: https://github.com/seanmonstar/reqwest/blob/master/examples/simple.rs As long as you understand the downsides of synchronous code go for using the simple if you prefer. :)
It'll be perfect thanks
I am not familiar with this expression. Care to elaborate?
No more gradle builds üò©
Think the issue with exceptions is how hard it is to determine ALL possible errors to catch. You have to read docs extensively and hope they match your version of the compiler/lib/etc so you don't miss any that might have been added. With Rust, errors are typically an enum so its SUPER easy to know exactly what kinds of errors can occur so you can write code to handle them. Most code completion even offers you a list of all possible enum variants(!) with the worst case of docs being outdated fixed by looking for the relevant enum in source.
Its really easy to ignore exceptions when you're writing code, and then an error that occurs way down in some low level function can crash your whole program. If you do actually handle exceptions, how do you know you have really caught every possible exception that might occur at a lower level, and dealt with it correctly? What if a library maintainer adds an exception later on that you don't handle? Your code will still compile, but when that error occurs your program crashes. Result types force you to deal with the errors up front, and if the errors from lower level functions change your program won't compile. That's good, because you need to respond to the errors properly.
(The abort change landed but broke people so it got un-landed and there‚Äôs been trouble re-landing it)
I‚Äôm surprised you‚Äôre surprised. I have no interest in Kotlin and it‚Äôs the first time I see someone comparing them. Why are you assuming they play in the same garden? &amp;#x200B; Kotlin targets the JVM and JS. Rust has a much bigger scope and is a systems language.
I always use `yansi` for coloring, `xdg` for xdg, `prettytable-rs` for exactly that. `promptly` is sometimes useful for basic interactive prompts. `liner` if you need a more advanced interactive prompt. `cursive` is a pretty good TUI framework, as is `tui` and `fui`. Also, `secstr` for securely handling passwords received by the user. `fern` for its flexible logging requirements. Cannot forget `libc` for properly handling signals. I should also mention that [lib.rs](https://lib.rs/) is a good index for locating crates.
This is neat
 x.map(Œî).or(your_option_u);
Or (combine)[https://crates.io/crates/combine] while we're at it. Personally I got the best results with nom so far for parsing file formats and network protocols :)
I can also vouch for nom here, currently in the process of writing an RFC 2822/5322 parser, and nom has been treating me pretty well.
It works too! But I prefer the former syntax because left to right reading is easier to read and to understand But as you pointed out, your syntax is as much valid as mine!
As I explained: According to SO, Kotlin, Rust and Python are considered most likable languages lately. I omit Python as it is not new language. I am not comparing languages but community growing. I would expect Kotlin to grow faster as it is more approachable. Perhaps it is just reddit community. I was just curious. The others seem to understand why I am asking.
Congrats! Your project is an inspiration.
&gt; Why Rust doesn't have exception handling? On of the reasons, which I believe was not yet stressed enough in the other comments, is that exceptions bubble up by default, which may be surprising / unexpected. With exceptions, any function call can blow up in arbitrary ways - it can throw all sorts of exceptions from any depth of the call stack. This is partially solved in some languages with the concept of checked exceptions (or exception specifications). This approach sort of goes in the direction of functional-style error handling, but doesn't quite get there. You could think of Rust's `Result` type as the logical next step, ie. exceptions ‚Üí checked exceptions ‚Üí `Result`. The functional-style (ie. `Result` in Rust) error handling is sort of like checked exceptions, but implemented with regular returnable values using sum types, which means the implementation is simpler and allows for more flexibility - you don't need to write complex try + catch + rethrow statements just to turn one error into another for example.
Because Rust itself is more of a friendly, community, open source culture language itself and that's big part of it's developers base. I don't mean community like number of profiles on online Q/A forums, I mean punch of like minded people who care about the language and not just using it solely to please their employer or because a company decided that's what gonna be used so they've to follow. Of course, there might other (technical) factors but I think this is the main reason behind it's popularity
No experience with mongodb driver, but... We migrated from mongodb to PostgreSQL using their jsonb data type and the result was above our expectations. Indexes, query analyzer, etc. all worked. Turns out the data in mongo was highly relational and the IO balance for the workload was reads &gt; writes, so in our case the initial selection of mongo was a poor one anyway. jsonb allowed us to do a nearly 1:1 dump and import from mongo. Our particular solution ended up having significantly better performance in postgres than in mongo. This is not advice, I'm not saying that you should do this. I completely understand your need to use an existing mongodb and that is completely valid. I would tell you about the Rust mongodb driver if I had experience with it. Point is, I'm not trying to be "that guy" that questions your question. I'm just offering a data point from some experience. I hope that comes through.
The macro expands to: impl From&lt;A&gt; for Foo { fn from(val: A) -&gt; Foo { Foo::A(val) } } which is just as legal if you write it yourself without a macro. Why would it not compile if produced by a macro?
Macros just produce a stream of tokens, so it doesn't really matter that you're using `ident` here because the compiler will resolve it to the appropriate type/path anyways.
Assign it to a variable of the wrong type (`let () = ...`) and then copy the type from the error message? You can also use type aliases to shorten things, especially if they are used multiple times.
Will you be making a new post or just editing this one?
I thought that `ident` had to point to a specific variable. I didn't realize that it only had to resolve to something w/in the macro. Neat!
In general, you should only be using trait objects if you don't care about the actual type, only the functionality it provides via the trait. In this case, a `dyn Error` should have a method `description` that returns a string. If you actually need to check what type of error it is, consider using an enum instead of a trait object.
This post has almost nothing to do with Rust. It feels like the author is showing off his setup, and the fact that he got a job programming in Rust.
With Rust, its probably better to have it separate. Means that even *if* it crashes out, it can be restarted from a master PID. Would make it ultra stable like Rust intended!
I was having this same issue a few days ago &amp;#x200B; This will skip fields that are not present in json `#[derive(Serialize, Deserialize, Debug, Clone)]` `pub struct ConnectorInfo {` `#[serde(skip_serializing_if = "Option::is_none")]` `dashboard: Option&lt;ServerInfo&gt;,` }
This is already supported as Tokei uses the same library as ripgrep, I've just added a [custom ignore file using ignore's library](https://docs.rs/ignore/0.4.7/ignore/struct.WalkBuilder.html#method.add_custom_ignore_filename).
Well now that's fast support!
Ok, so every async implementation needs an event loop, right? The problem is that users of a library might not ever be *exposed* to the fact that there is an event loop that they need to be cognizant of so they go along merrily writing their code as if they're not doing anything particularly asynchronous, you know, just doing computations on IO that's been managed for them. Suddenly, they need to do some IO, so, they go and reach out for a library to help them with that. Now, the crazy thing is that if they use a library that does *blocking* IO that doesn't use an event loop, they don't necessarily have any kind of problem. Because the IO just blocks and the whole event loop they're inside of waits as if they're stuck on some long computation. But if the library they use *does* work asynchronously, one of two things happens: 1) Either they go merrily on their way because the library they used happened to be using a different event loop library (this was pretty frequent in Python because there were a bunch of asynchronous programming libraries) or 2) they get a weird error about an event loop already being running. This generally leads to wailing and gnashing of teeth because there's not an easy way of knowing how to thread an event loop through the user's code to the site where they were supposed to have it. You can use global state because that's how the bottom layer of the sandwich knew to throw an error, but you'd think that if the bottom layer *knows* it's being called synchronously and it *knows* that there's an active event loop, it should just shut up and schedule itself and act as if it were synchronous like the user wanted it to. The reason that this I think this is **stupid** is because it prioritizes performance over code that just works despite it being easier to back into limited asynchronicity *later* to get the performance back once the bottleneck is realized. Alternatively, there should be some kind of way to "wrap" a synchronous call site implemented asynchronously to say, "Yes, I know I'm being a bad boy, just do what I want." Because, honestly? Sometimes people just don't give a shit about performance.
You can't use `$ty` in place where `$pat` is expected. But you can use `$ident` for both `$ty` and `$pat` because in Rust's AST ident is valid form of type and pattern.
https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html
Rust standard library is linked statically into the binary by default, while C++ links its standard library dynamically. You can try to compile your C++ example with `-static-libstdc++` flag and observe the difference.
&gt;currently in the process of writing an RFC 2822/5322 parser Please, please post about that here (and get it into ThisWeekInRust) when you publish it. I'd love to have that for a variety of purposes, including parsing various Debian metadata.
It's going to be my first real project so it may take a while, but I'll be sure to do that when it's done!
Might also be because Kotlin is a lot easier that Rust being just another jvm lang, which means people are already pretty familiar with it's concepts which reduces the need for discussions.
&gt; nothing is stopping you except the time it takes the maintainer and all the extra issues that come with having that support
https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html At least one of them don't apply anymore (jemalloc was removed by default), the rest does: * rust includes debug symbols (you can remove them using strip(1)), that's ~100k * rust optimises crates individually, lto fixes that (40k before stripping, 15k after) * rust uses a "nice" panic handler (provides backtraces on panics), that's ~15k before stripping, ~4k after Using rustc 1.35, ` -Clto=on -Cpanic=abort` then strip-ing the binary gets me from 272k to 156k. Sadly that's the end of the easy gains, because the last issue is that Rust statically links the stdlib while C defaults to dynamic linking (often necessarily e.g. you simply can't statically link OSX's standard library), and Rust's stdlib simply provides a bunch of stuff. Removing `std` is what the article above ends up doing, but you end up with C, in a Rust syntax.
In that case tracking an old rustc might not be the best idea in the first place. The time saved by the maintainer is time lost for other maintainers having to work around these quirks.
Simple, because Rust embraces the lgbtq. /s
I may have misunderstood. But could you send the name of the service through channel from B to A?
For a long read on error handling in various languages, types of exception handling and the various design trade-offs made, this is maybe interesting: http://joeduffyblog.com/2016/02/07/the-error-model/
This looks very nice. I've used OpenFrameworks in the past, but I found that I spent more time fighting with C++/libraries, than getting stuff done. This, amethyst and the recent movement in the RustAudio space are very exciting. I would love to see Rust as the default platform for creatives. Any plans to support WebAssembly?
Actually, if it was true than Python would be incredibly hard language to learn judging from size of its community. üòä Thank you anyway.
I'm a bit surprised that's allowed and the default despite (AFAIK) C++ lacking a stable ABI. Are the stdlibs specifically built so they're ABI-stable?
There‚Äôs nothing much to discuss. It works. It‚Äôs a closed development process as far as I‚Äôm aware. And when you do have a question, you use SO. But the language is so much easily understandable that you don‚Äôt really have many questions to begin with. And it‚Äôs JVM and you usually already know everything need about JVM, coming from Java.
&gt; except the time it takes the maintainer and all the extra issues that come with having that support Those exist far worse with supporting ancient unsupported rust versions, though. Unless you fork rust and implement them yourself, you don't get any bugfixes, security fixes, new features, usability improvements, etc. It just makes life harder and insecure for everyone for no worthwhile benefit.
This isn't 'undefined behavior' that a compiler/language is worried about. This is a logic bug, or flow control bug, not undefined behavior. Even if from a user point of view it's behavior which shouldn't be happening.
Fair enough. I was just taking a stab at what the parent poster was trying to say.
I‚Äôll most likely edit the same post
Oh, I think you are right as to what he was trying to say. I was just pointing out that 'Undefined Behavior' is more than and different than what he implied. &amp;#x200B; Undefined Behavior is a big deal. It can launch nuclear codes or set fire to your computer, all behaviors are 'acceptable' when it's Undefined Behavior. A logic bug can do all of the above as well...but it's unintentional and accidental and you can change it. 'UB' can do it \*intentionally\* at the compilers discretion and you can't call it wrong, it's right by definition.
I use it in production without problems. You can also take a look at [https://github.com/H2CO3/avocado](https://github.com/H2CO3/avocado), nice wrapper for object oriented approach.
My thoughts after watching this are that it must make testing much much harder. The traditional compiler model can just have tons of input rust source code files to exercise any behavior from the compiler. With an interactive compiler, maybe you'll hit weird cases, like non-deterministic results, that only happen if you, say, edit one function, then another, then another, in a particular order. How do you write tests in order to exercise all the different combinations of interactions a person might have with a compiler?
The speaker mentions "Rusty" which I assume is their implementation of a Rust compiler, does anyone know if the code has been published anywhere already? Thanks
Theoretically, but B has to send to A which name it wants to activate. Both threads are busy with various jobs and eventloops, so you can't just poll
I think he was saying `rustc`, the rust compiler.
Oh, that would make sense, thank you
An old compiler version can be a hard requirement from the platform or environment. While not optimal that is the reality of Linux distributions (including `Debian`‚Äìstable is on 1.24.1, just noticed your user-tag) and corporate installations.
Also, it‚Äôs a great trap for unsuspecting/confused gamers.
Thank you. The crate is still very much in development. So if you find a use for it feel free to give me feedback on github. I would love to know what works for you and what doesn't.
For me working offline and unplugged is key. So having it included in cargo is a huge plus over an external tool with a seperate update cycle.
Who is interested in Kotlin? \- Android devs \- Java devs (btw not all) Who is interested in Rust? \-C/C++ devs \- Java devs \- Ruby devs \- js devs \- Haskell devs ... So no surprise.
Not to mention gaymers.
I might wait and see what comes about once async / await stabilizes and the ecosystem catches up. My understanding is that Pin is intentionally a somewhat low-level API, akin to the std::ptr module. I have a feeling that we are going to see crates appear that implement commonly used futures / combinators wrapping Pin safely.
It's a good point, although the most important function of the compiler is still to produce executables, and the existing test suite of a crap-ton of Rust source code files works just the same for testing that (not to mention Crater). For testing the IDE-facing bits of the compiler, I think you may want to have some sort of fuzzing system that generates combinations of queries.
It's still unidiomatic to use is_none()/unwrap, a pattern I sometimes use to avoid unnecessary indentation in a big function is: let stream = if let Some(stream) = &amp;mut basic.stream { stream } else { return; };
&gt;Because, honestly? Sometimes people just don't give a shit about performance. And when your computer is running hundreds or thousands of background processes work by people who "don't give a shit about performance," you suffer a death by a thousand cuts and everything slows down.
It's hard to say without code but I think you have these two options: `Arc&lt;Mutex&lt;HashMap&lt;ServiceName, bool&gt;&gt;&gt;` (which should be easier) or channels. AtomicPtr gives you raw pointer which is more for writing low-level abstractions than application logic.
In this case that's *not* an issue because we're talking about processes blocking on IO, not processes consuming more resources than they should. Stop trying to globally optimize literally every program. Most code gets thrown away. How many people on this very subreddit say to just use clone when you hit problems getting started?
I had to use mongodb in rust to import/export a large amount of documents. A couple of months ago the driver you posted above was abysmally slow. The mongo_driver package which is a wrapper of mongoc worked pretty well and the speed was on par with the Go driver which is famous for being one of the fastest out there. Setting up mongoc on Mac was a bit of a nightmare but I would help if I can.
thank you very much all of you for your information Appreciated
Hello everyone! I'd like to know if there's a way to add a constraint to the type that can implement a trait for example: ```Rust pub trait FFI&lt;T : Sized&gt; { fn to_handle(self) -&gt; T { std::mem::transmute::&lt;Self, T&gt;(self) } fn from_handle(handle: T) -&gt; Self { std::mem::transmute::&lt;T, Self&gt;(handle) } } ``` how would I make a constraint that only Sized types can implement the FFI trait?
\`\`\` pub trait FFI: Sized { ... } \`\`\`
one of the first versions has been written in nom and I still have the source code around, but I have several problems with using it; the first thing is, that there is a major rewrite of the nom api planned (they want to switch from macros to functions) another problem is, that a serializer needs to either be written by hand or with serde and the error reporting of nom sucks at the moment (will be fixed with the nom rewrite). &amp;#x200B; Therefore, I decided to do it with serde, and I am quite happy with the code.
He mentioned this was the third rewrite of their framework, and the second version was scrapped because of exactly this problem. The solution they found was to use top-level methods, in a way that forces deterministic output, and have the framework force you to correctly record all dependencies of a query. If you build this part of the framework correctly, this entire class of problems is eliminated. Near the end he discusses how being able to catch cycles breaks this invariant, meaning true cycles in the queries are always wrong. This problem is why cycles in data must never be detected by catching query-cycle-errors. Instead you can detect them inside a single query.
The query system is honestly quite ingenious.
It sounds like you may not be using the Pin API optimally... Firstly, Pins can be constructed entirely safely at the cost of a heap allocation: https://doc.rust-lang.org/std/boxed/struct.Box.html#method.pin Secondly, you only need to construct a `Pin` when implementing an executor (which unless you're implementing Tokio itself, you don't need to do), or when writing *some* "old-style" future-combinators (ie. not using async/await syntax). In other words, if you can afford a heap allocation, there is no need for any unsafety at all, and if you do need that last bit of performance, you can avoid unsafety by using newer language features.
&gt; With Pin, it is unsafe if user wants to do something useful with a Pin pointer, and unfortunately Pin pointer shows up in some important interfaces such as Future, which makes unsafe spilled everywhere touching those interfaces... This is because the unsafe side of `Pin` isn't meant to be used in end-user programs. It's a _tool for building safe abstractions_! Not a safe abstraction itself. With futures, as I understand it, the only parts of the pin API you should need to touch are `Box::pin()` and `Pin::new()`, and you might not even need to do that if you're using `async/await` to interact with it. `tokio` and `futures` libraries will be using the unsafe side of pin, as will the implementations of `async` functions - but those are the safe abstractions themselves.
I think the author just noted that there was a lack of entry-level Clojure positions in Berlin. I think that implies that there are more Rust positions, but seeing as I was literally looking at a Clojure position yesterday and I don't think I've seen a Rust position outside of Mozilla, I'm not sure how true that is.
I just don‚Äôt really see what the appeal of Kotlin is. Sure, maybe it has some syntax that it‚Äôs users like etc, like any language. But if I want a random mid-level compiled language I would choose Go. Rust lets you do things other languages don‚Äôt.
I would recommend the `log` crate, and either `log4rs`, `fern` (disclaimer: I'm the main author of fern), or as you mentioned `slog`. The main difference between `log4rs` and `fern` is that `log4rs` is configured using a YAML configuration file, and `fern` is configured using a builder struct in rust. Both should work for your purposes, and be able to format, and log to stdout and syslog. -- For logging, the `log` crate provides [logging macros](https://docs.rs/log/0.4.6/log/#use) - `info!()`, `debug!()`, `warn!()`, etc. - all matching the syntax of `println!()`. For configuring log4rs, check out [an example configuration on `log4rs`'s documentation](https://docs.rs/log4rs/0.8.3/log4rs/index.html#examples). To use it with syslog, you'll need to also use the `log4rs-syslog` crate - see [an example from their README](https://github.com/im-0/log4rs-syslog#initialization-based-on-configuration-file). For configuring fern, see [an example setup](https://docs.rs/fern/0.5.8/fern/#example-setup), and [documentation for using with `syslog`](https://docs.rs/fern/0.5.8/fern/syslog/index.html).
&gt;(The abort change landed but broke people so it got un-landed and there‚Äôs been trouble re-landing it) If it broke people invoking what is already said to be UB, then was anything actually broken...?
When *implementing* futures without async/await syntax that contain in their pinned state: * asyncronously pollable objects that do not satisfy `Unpin` (e.g. they are generic); * values that need to be moved out of the pin; you need to unsafely access the pinned data of your future and decide which parts you want to expose as structurally pinned (such as the sub-pollables), and which parts have no structural impact on the pin (e.g. values that are constructed with no use of pinned data or moved under the pin) so they can be safely exposed as mutable or moved out.
Uff, thx. The Rust error handling is really driving me nuts, as powerful as it might be..
Even if you do require `FFI: Sized`, I don't believe that it's possible to have the default methods you've written. Transmute is compiler magic, and does extra checks to ensure the types aren't just sized, but that they're _the same size_. It isn't generally possible to use it within a generic context like this. I would recommend just having it be trait FFI { fn to_handle(self) -&gt; T; fn from_handle(handle: T) -&gt; Self; } and then implementing it either manually, or with a macro to avoid duplication.
If you share `&amp;HashMap&lt;id, AtomicBool&gt;` or `Arc&lt;HashMap&lt;id, AtomicBool&gt;&gt;` between the two threads, you don't need a mutex. That will prevent you from adding or removing keys, but you can still modify the values.
This seems to reflect my findings when I tried this over 2+ years ago.
This is definitely true! I guess my base assumption was that no one would be manually implementing any futures outside of `tokio` or other abstraction libraries.
&gt; How can I use `&amp;mut Cow&lt;'a, str&gt;` or can I at all? What you put into `Cow&lt;'a,str&gt;` needs to still respect the lifetime `'a`. So if you update with `Owned` this is trivial because functionally the `'a` lifetime is meaningless (_not exactly_) [playground-link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=24a640864fa3012a3b72f3822c344321). If the goal is for `Cow` to hold borrowed data then the incoming data must have the same lifetime (to ensure the `Cow&lt;'a,str&gt;` doesn't outlive the data it contains). [Here is the original reference with just `/Owned/Borrowed/`](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e7effe1f4fd73747502787cf261cc64a). But as we annotate the lifetimes, the compiler passes [another link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a20fb0366c27d80c42bd7b01a22e9f5f) To directly fix your problem change the `from: &amp;str` to `from: &amp;'a str`. This will ensure the `&amp;str` won't live shorter then your `Cow&lt;'a,str&gt;`. &gt;I couldn't find string templating engines meeting my requirements. Most were cli apps, and none supported to-be-replaced-values from structs. Any similar experiences? Have you tried [TinyTemplate](https://docs.rs/tinytemplate/1.0.2/tinytemplate/) ? I haven't used it myself but it appears to be what you are looking for.
You misunderstand. There is nothing that prevents a libc implementation from declaring it as a global thread-local, as it would still be conforming to the standard. I'm fact on closer inspection it looks like glibc does exactly this for some platforms. It's true that you can't expect to access it as an `extern int`. In technical terms, `errno` is required to be an lvalue expression, where a "function call" with no additional context would typically be considered an rvalue expression. Hope that clears it up.
You can also use $tt and coerce it to all sorts of things.
Right, there's nothing wrong with it in that sense. Whether or not it is a global variable or defined in some other way will depend on the exact implementation of libc, so it may sometimes work, but of course the correct thing is to use the abstraction in the `libc` crate. :-)
Thanks a lot already. I am using Cow for 2 reasons: * as long as nothing is replaced, it holds a `&amp;'a str.` Because I have to replace the entire str when one or more variables are detected, I *have* to save an Owned String (`std::str::replace(from, to)` returns a `String`) * Parsing to `&amp;'a str` may fail at runtime due to special characters. Cow resolves this issue. See [here](https://users.rust-lang.org/t/solved-serde-deserialize-str-containig-special-chars/27218/2). I can still check for validity and exit with a proper error I will have to use something resembling the code in the first link you attached.
"old style" seems to me to be necessary when returning futures from trait fns, or when doing complex operations. Re: the latter, I have a server with a manual future impl and would be interested to see if I can do this purely with future combinators (and whether it'd improve readability): "select the first available of (response available to write to sink, and the sink is ready) or (request available to read from stream, and either (1) under the max in flight requests limit or (2) the response sink is ready to write to)"
What's your recommended value for "old rust versions"? 2 releases old?
Even if you aren't doing IO, as far as I can tell, rustc isn't able to optimize out async/await overhead. In general, you don't want rustc to do this since you might want your executor to have the opportunity to run the various pieces on different threads. But even with a dumb executor that just immediately runs futures and assumes synchronous execution, rustc won't optimize async/await out. However, hand-coded Futures can be optimized out by rustc. I think the difference is due to the fact that async/await futures generated by the compiler use thread local storage, since otherwise I can't tell the difference. I tested this with an example that adds 1000 + 300 + 37 using futures and an executor that assumed synchronous execution. ### Implementation 1 async/await [playground](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=5862c609caa8c57379966495751f45d4) / [godbolt compiler explorer](https://godbolt.org/z/2a1Eoy) The result 1337 doesn't appear in the assembly. It calls into the executor for each future. ### Implementation 2 hand-coded futures [playground](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=a769d7f4a995041d2a3be67dc82b9e4d) / [godbolt compiler explorer](https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYFsAOBLANgUwCcAabECNLPIkAO22AQBdcBPYgMzyaIGdyARiADkABmHEB2WgENCrEQEYJldPlpMA8rTYjxxACb50M2sAJ6JB7IXzIm2AG75%2BYifgAedgK48lE6R5cS2JcbAFCOVYAYVQjf2ImQmx0fwBKUNNQQm9eJlDw/kgM1EwHVFpXAFpogGpSpiqCZ1wAUgBmABF22pra3CZUDs6K3qr8a3LaWoAmUUUADl66zFNsZGGZAVRCJgleVG9CZHwQRQzg4QBWCVoQ1BEcvORa%2BkYWVlqIAFFJndrWjN2opiLVYlQCIQAUDzrUAEq5PaJSxpDIIfAyIyEcgZADWIHa7QAdITSWTyQA2UIiAAst3uIn2IFEyLcGTgsCQaCMv2wgxIZAgACszpkzCAnvkDkcTiJAe0wGBWlcAEIcDFMI74CAyXisWjIAD6MgA7jI%2BWllZ1WqIAIK5fC1PIGEAgDi%2BLWugBiHtsHRVNvtvEdztdODuIAACtJ/YGHU6mC6QExdfiQK0AOwq2IaTz5SOoXC4Yhw00AdRkuKIJfLlaIADUACpbAjECtVwiZ63tAN2wN5HL2Wq2gwGH2a2wArOB2qz2oeEC1bDtGbEGdzhRLldrvsZ619u0pTC4WrjrW1Dj/Edj32OzO921z2pMViYR2aXyYXwArpbmaxu0nw4aZMELXAIGDXAOEXaNaA6aJAQpdBvwAZXwKCOm%2BUFDUXRDkKYMEKh4DwmHgsBhENTC0l6TDagLIt4LQqDXQ/Jgv1I9pvinB8nyfejghAOEMQMVgIPQjgiQ8aEVSdcSiVYS1ALnLtAxUg9bQHbwh2vM9bCEjZ2miL1F10/B4NY9jhmXf9ONo%2B911naDTx3R85wAL0XayXLU21AyPNpDOM09b3Mz9fCsldMMBFUAFVaHDWjTIvK9R1M/T4K9OzpyU2cXzfWoLO/YY/wA1zHJAsCxOYuiY0MvDUPEzDQXsBdoSQ78c2IjjonIyjOOoqpaP4xjxJYsKOK4%2Byct4ggCLcn9OlkqCiTc0reLnWbanDBbam8SoZHVe9IIkkxMENPbkHRZAqwMQ18IgTNol4R62vwp0iQ4S09zW9bahMJhLq26QiVAosKCYDxqKmsrftnfjXUjdRrDMBbaNWehkEVCAMgc2G6LA10hMxUTHChrohoJwThJJ6K3Jx6anx8xnvt3fdfLtYDamQXAKm1VqACo0EqJhsYG2jSxNdsiG43GJal7E6HwE0IA8UFEKbW0VQAGW%2BRTfJZ9nbU5s0qwgHDakFio8lFmXpvR9Ysb1nzA05gxCFKM3F0t4Wbeh527SFvJag17XvkXOW60IJsWzvX8I47aOBAsRXldx7neZcp8TfwTO52z3PZzd0oXMtHtVI56Yk9Qa7DQqDKTJCziIDe90mBMsXONPMa2KK7KYc2wgTR2%2BOaBTiDEzDJJXVobwwYyNqQ510ueI2/ACOzqFir23gDrMrN5ddDh3fQQ1ImVwevu7FfZ02t6Wp2zq80P4/DQ3h6ZgpDfl9xzbW8Nbat77UOlmWC08lbnQNFdG6792oEVbpfH6N817zh2n/cMINKr1QIi1b%2B01/qAyktDWG8MqbEwgKTVGndHAF14iQxGtBkbAEoVxe2mNig0OdgbQMX4BAXmmCYaQ2Nbb92Qa3HaOlbzpSzE5CRE494qlaooUQyjQSbnaMorsoIPK1HaBmFSZdpqbUcDtKuNcKgQHgYgrayQNC4FoFjQE/5pzfRmKuWopNSpdmEBcEQNxiB3DcMQB4wgERB2lMcO8MIJBtzZHiAkxJySJNJFSS4dJ/EMmEEyFkMTxDshgIgEAhwe75EFJQHAkJRQTD5DsUUJpIiYHSNSa49JAnBPlIoWoJo%2BQIFqJKF4bxmBsGiSiOJhISRJMSU0tJAT9DBKyayXJPjhAzBabMxkCzvEZGcIQXg2AKggBpEAA%3D%3D) The result 1337 is in the assembly. The executor initialization code still runs for some reason, but none of the futures are executed and the value is simply printed.
Stopped listening as soon as he started talking about being a pacifist. The Second Amendment gives us the right to keep and bear arms.
Amazingly, you can have or support others having guns and still be a pacifist.
It depends on what your users have available. If your library is widely used, you will want to support very old compilers. If you still want to use recent Rust features in your ongoing development, OP's suggestion makes a lot of sense: supporting an older release with patches and patch updates of your dependencies, while making sure your older 'LTS' release still compiles on your target platforms. If you say you want to target Debian stable, you will currently need to live with 1.24.1, that's from 2018-03-01. (Though the next Debian stable coming in a few months contains 1.32.0) This will get better as Rust matures. At least now we have Rust and Cargo easily available on Linux distros.
Hello all -- tried asking on #rust-beginners but didn't see any response. Thank you all for consistently being so helpful in these threads. When pattern matching against a few characters that will be needed for the expression following the match, I assume a binding is the way to go. However, those characters (or numbers) may not always be expressed as a range, and in such cases it looks like the binding has to be repeated for each character -- is that true? E.g. for a range, you can use `foo @ 1..5`, which is awesome, but if you wanted to match `'^'|'&lt;'|'&gt;'|'v'`, I would have to repeat `foo @ '^' | foo @ '&lt;' | foo @ '&gt;' | foo @ 'v'` -- is that correct? Is there a more elegant way? (Yes, I'm still working on AoC.) TIA!
You could use a concurrent hashmap. There are a few, [chashmap](https://docs.rs/chashmap/2.2.2/chashmap/) seems like a decent choice.
I used it for some (small scale) data import/export and migration. I actually had some problems with underlying `bson` https://github.com/zonyitoo/bson-rs/pull/110 , and it worries me that this PR is hanging for a long while now.
I typically just use the variable being matched on; if the match expression isn't a variable then I extract it to one. I don't like passing complex expressions directly to `match` anyway because it gets hard to read.
Rust dynamically links against the platform's libc to use it as a platform ABI wrapper unless you're targeting Linux using the musl-libc target. For C++, the C++ standard library is considered part of the platform which you may need to update. (For example, each version of Windows comes with a pile of Microsoft Visual C++ runtimes and, for stuff that came out later, installers must either bundle or ask you to acquire those vcredist installers.)
Unfortunately, it looks like you're stuck writing `foo @` for every case. One work around would be let c = character_to_match_on(); match c { '&lt;' | '^' | '&gt;' | 'v' =&gt; // Do things with `c` here _ =&gt; // Not a direction }; (Why do you need `foo @` on every case? Because `|` is [used by `match`](https://doc.rust-lang.org/reference/expressions/match-expr.html#match-expressions) to separate patterns; it's not part of a pattern itself. `foo @ _` is an example of an [Identifier pattern](https://doc.rust-lang.org/reference/patterns.html#identifier-patterns), rather than something `match` specific. It would be nice to allow something like `Some(1 | 2)` but that would be a change to pattern syntax that would impact everywhere where patterns are used.)
The talk is still good.
This is really interesting! Thank you.
/r/playrust
The problem with nom is you then have to write the serialize part separately, whereas with serde you get both.
Gah. I guess that should have been obvious, seems to make the compiler happy. The [example from v1 of the rust book](https://doc.rust-lang.org/1.1.0/book/patterns.html#bindings) seems a little now: If you use @ with |, you need to make sure the name is bound in each part of the pattern: let x = 5; match x { e @ 1 ... 5 | e @ 8 ... 10 =&gt; println!("got a range element {}", e), _ =&gt; println!("anything"), } Seems like using `x` in the match arms would have sufficed; v2 seems to [use a better example](https://doc.rust-lang.org/stable/book/ch18-03-pattern-syntax.html#a-bindings).
In some sense, no. But in another sense, we have the power to not actively break people‚Äôs code. The idea is that maybe a solution can be found, and then the code can be updated to use it, and *then* the old behavior breaks. I personally would have probably just broke it, but I can see why the lang team hesitates, too.
That's actually not a bad idea. I assume this wouldn't much slower than a truly synchronous code.
&gt; It would be nice to allow something like `Some(1 | 2)` That's what the feature [`or_patterns`](https://rust-lang.github.io/rfcs/2535-or-patterns.html) are going to permit. /u/mdsherry In the future, you might be able to write `foo @ ('^' | '&lt;' | '&gt;' | 'v')` in this case.
Thanks for the explanation and example -- I guess as long as I'm not destructuring anything in the match, just using the variable (`match c` in your example) should be fine.
What you were trying would make the `match` a single expression which might look nicer as a single-line closure; it's unfortunate that the repetition is unavoidable with the current grammar (wrapping the whole thing in parenthesis would try to match a 1-tuple and the compiler would complain about mismatch types).
If you're writing a compiler then probably most of the time will be spent doing lexing, parsing, AST fiddling. Very branch heavy memory intensive stuff. I/O will be pretty irrelevant. Especially for benchmarking. (Let the kernel do whatever it does, cache thing - especially writes; possibly doing prefetch.) &amp;#x200B; So all what matters is function call overhead of async vs non-async, scheduling, function sizes due to Future type wrapping, etc.
It's probably not the answer you want, but I think the best tool today is the IntelliJ plugin with its refactorings and other features. Other than that, rust-analyzer might offer something similar in the future. I think it's a good idea to focus on things like completion and go to definition / find references support. These require that the tool offering them has a good understanding of the code, which is probably a prerequisite for the features you want. If you feel comfortable working on what's basically an interactive compiler and you want to contribute to rust-analyzer, it will probably be well received. Its author previously worked on the IntelliJ plugin and seems open to including a grab-bag of functionality, as opposed to e.g. Visual Studio, which has a limited set of refactorings/assists.
Could you help me to help understand this? &gt;Replaces the value at a mutable location with a new one, returning the old value, without deinitializing or copying either one. this is in the docs for `mem::replace`. This seems counterintuitive. Why does it return the old value? Where is the "new" value after replace?
for starters my example was wrong, you shouldn't write the returned value to the pointer, it should just be allowed to drop. -- It returns the _old_ value as its now dereferenced, and the _new_ value is written to memory at the location of `&amp;mut T` argument. The _why_ is beyond me. It is a builtin the llvm exports, which fits well into the rust ownership model, so it is kind of just a bit of _magic_ hanging around.
Realized that after looking at the implementation of `Option::take()` pub fn take(&amp;mut self) -&gt; Option&lt;T&gt; { mem::replace(self, None) }
Just implemented your `mem::replace` solution. It's more than 60% faster on release builds, incredible. Have great night, thanks
&gt; The Second Amendment gives ~~us~~ Americans the right to keep and bear arms. FTFY. No one else cares.
Pretty much nobody is going to use Debian Stable's provided ancient version of Rust to build their stuff. They're going to install a modern version of the Rust toolchain and use it. Rust 1.24.1 doesn't even support 2018 Edition. Many crates are going to be rewritten in the next few weeks to support async/await and lots of them are going to drop support for 1.36 and earlier in the process. Supporting old versions of Rust will be a big waste of effort for most people. Conversely, having good support for the newest stable version is really important and useful and easy to do.
I recommend people only support the latest stable version of Rust. I have been doing this for years with my crate and it has worked great.
The problem is that not everyone knows that. People are accustomed to being able to install a C or C++ compile via their Linux distro, and then use that to compile projects. I know I occasionally get bug reports saying that one of my crates doesn't build, and it's because they're using their Linux distro's version of the Rust compiler. Sometimes a little education there helps, and they're happy to use something like `rustup` instead. But not everyone does. &gt; Many crates are going to be rewritten in the next few weeks to support async/await and lots of them are going to drop support for 1.36 and earlier in the process. Supporting old versions of Rust will be a big waste of effort for most people. This feels like a special case. A lot of people have been waiting with bated breath to do anything asynchronous in Rust until async/await lands. I know that's certainly the case for me.
I have a hard time believing that Matrix is winning the new chat location vote. It was my vote, and I think it‚Äôs a great choice, but I didn‚Äôt think it would be the popular choice.
If you've already added rand as a dependency you can just run cargo doc -p rand --open and the docs will open in your browser.
Generally, there are two ways I get documentation: looking at the crates.io page and clicking "documentation", or looking directly on docs.rs. In rand's case, it doesn't seem to use docs.rs. Looking at its [crates.io page](https://crates.io/crates/rand), it links this as the documentation: https://rust-random.github.io/rand/rand/index.html
Very old compilers don't get security fixes, so it is not very useful to support them with new releases.
&gt; It's important in the sense that the ecosystem shouldn't stagnate Right. That was my initial motivation to committing to supporting only the latest stable, beta, and nightly releases. To prevent stagnation you have to design your build system so that you are always able to update the toolchain. You have to be prepared for somebody finding a critical security vulnerability in Rust 1.35 and earlier versions that is only fixed in Rust 1.36, which would require you to update to Rust 1.36 immediately to get the fix. Note that the Rust team *themselves* only support the latest stable, beta, and nightly versions. They generally won't fix a bug in Rust 1.35's libstd after Rust 1.36 has been released.
Ah ... right, "is it possible without writing too much from scratch? " is what i meant. Thank you very much, it worked!
We've decided for nix to only update the min compiler if necessary for some feature (doesn't need to be super compelling, just has to be something). And never go newer than 2 versions back. I think that's a pretty good policy, not making people have to have the newest compilers, but not unduly holding back development of the library. For my personal projects I follow a similar policy.
I stopped listening when he talked about being a vegetarian, because I like to eat meat. Seriously?
That won't work since rust [won't be able to infer the types properly](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=93b065630be1c95b998c96a40c5b441d). If x is a u32, then `a[usize::from(x)]` won't work either because usize doesn't implement From&lt;u32&gt;.
I think the rewrite due to `async` is still a bit away. Which is good for that specific case because it incidentally means that the next stable release (expecting it in/close to fall based on previous release cycles) of Debian *might* ship with a compiler version capable of supporting it well. I think in general `1.24.1` has proven to be a somewhat influential version‚Äîalso one of the most well received ones in the subreddit. I would be very happy if a newer versions were to establish itself as similarly great. Knowning that `async` is happening soonish and considering the slow transition *in practise* I'll wait for updating the compiler requirements until that point. I don't see edition 2018 as sufficient motivation since it does not actually fix any problems I'm having. Sure, the syntax updates are somewhat nice and consistency is important but the real hell of `try` transition was done and a lot is purely syntactical not semantical. The greatest reason to transition to newer version in my opinion is actually the standard library but it is not critical. I understand the difference for crypto use though, and keeping moving so that you can expect users to quickly adopt fixes in MIR semantics or other new intrinsics if necessary.
That's exactly why I was wondering if the Rust compiler could remove the abstraction; for most processing code I don't even need I/O, I could just add all the input into a gap buffer before starting "compilation" itself.
You're looking for /r/playrust.
Ty
Looks interesting! I‚Äôve done a skim so far, I‚Äôll try to get some time to go through this. I‚Äôm not a Rust novice, but I think I‚Äôll still learn something.
Readability issues really make the prevalence of shortcuts in Rust code all the more annoying for me. It is impossible to know what `$ty`, `$tt`, `$pat`etc. stand for without looking up documentation.
&gt;I don't think I ever made the experience that challenging people with strong opinions really worked. They just increased their defensiveness. It depends on how you do it. There's multiple techniques, and the best one to use varies depending on who you are talking to, and your own personality and rhetorical style. In case it wasn't obvious, I'm what you might call a direct communicator, and patience is an acquired skill for me. My tolerance for talking in circles, or with someone obviously acting in bad faith, is pretty low. I've found that with many relatively young, heteronormative, Western-cultured males, challenging their ego in a direct but non-insulting way is pretty effective. Pride will often compel them to at least make an *effort* to respond with a rational, logical argument, particularly if their peers are watching. Honestly, once you get past that initial, instinctual reaction of feeling like the core of your being a \_man\_ is under attack, it goes pretty well. I have, uh, zero problems sharing *my* feelings in an open and honest matter. If someone says something that hurts me, I'll respond with "Dude, that kinda hurt." That can often help people feel less threatened. On the other end of the spectrum, there are men who *want* to share their feelings and talk about "sensitive" stuff, or be hugged by another guy and told things will be ok. Their reasons for not talking about feelings is very different (they get shamed, mocked, insulted, etc), and I would not use the same technique. Empathy, active listening, and sensitivity in a more private setting work much better. But then, those guys are not often the ones posting bombastic comments on a subreddit. None of this is particularly magical or mysterious. You can learn most of this in two speech courses at your community college, and a seminar or two on communication techniques and cross-cultural understanding. Add a bit of empathy training (which, yes, is a skill you can improve), introspection/awareness, and anyone can learn to have productive, genuine conversations with their fellow human beings. &gt;I'm not a big fan of certain techniques to convince people. I don't want to manipulate people in any way. I think if you can't create an open and honest connection to a person, than you're not really reaching him. Almost all human communication is an attempt to manipulate the other party. This does not mean it is inherently dishonest. Next time you're trying to convince someone to do something, start with "You mind if I try to manipulate you into doing something for me?" $5 says you're more likely to succeed if you do that. You're trying to manipulate me in this response, for example, that using humor as I do won't get a good response. This is *ok*. It doesn't bother me. You're right that some techniques are unethical. Using false urgency ("buy this car now, the deal may not be here tomorrow!"), veiled threats ("I'd hate for something to happen to your funding..."), micro aggressions (Exchange student from China: "My name is pretty hard to pronounce, you can just call me John". Ignorant person: "No no, tell me your real name!") and things like that. I was an EMT for awhile, and one thing we learn to deal with is suicidal people. You know the number one thing that works to keep certain people from killing themselves in the short term? Their kids (if they have them). So you use that. "If you're gone, who will take care of your kids?" "Don't you want them to have more time with their mother/father?" Is this wrong? Is it unethical? I don't actually know, and I don't care beyond the academic thought exercise. I do know it significantly increases the likelihood that those children are going to see their mother/father again, that's what matters. &amp;#x200B; Phew, this was a bit longer of a response than I meant. I guess my tl;dr to you is that it is never as clear-cut as you seem to think it is in human communication. Honest communication is not some clearly defined set of rules. Focus on not harming others emotionally, of taking care of yourself (don't overpromise), and when you can, stand up for those who can't do it for themselves, and you'll probably do fine.
I don't know _too_ much about lock-free programming but it seems to me that only having one writer limits the utility quite a bit.
Hey /u/4lDO2. I'm glad to see this pop up today, because I am in the market for lock-free maps. And I need to be able to iterate over ranges, so I can use this to make a BTreeMap sharable and lock-free, right? Being able to wrap _any_ type and make accessing it lock-free seems like magic! Do you have links to any docs about the technique used here?
This is over kill, but hopefully you'll find something useful here. Going to link a series of blogs which helped me. This list covers the C/C++ memory model that Rust inherited for pragmatic reasons. 1. https://preshing.com/20120612/an-introduction-to-lock-free-programming 2. https://preshing.com/20120625/memory-ordering-at-compile-time 3. https://preshing.com/20120710/memory-barriers-are-like-source-control-operations 4. https://preshing.com/20120913/acquire-and-release-semantics 5. https://preshing.com/20120930/weak-vs-strong-memory-models 6. https://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu These videos are also worth checking out as they cover the academic approach to cache oblivious algorithms. Which are useful when designing lock free systems as it ensures high cache locality. 1. https://youtu.be/V3omVLzI0WE 2. https://youtu.be/bY8f4DSkQ6M 3. https://youtu.be/Fs4-E4Nj1Ks 4. https://youtu.be/CSqbjfCCLrU 5. https://youtu.be/C6EWVBNCxsc
&gt;have thought it was childish more recently. One of the fun things about being an adult is you can be childish if you want to be. =) Admittedly, people tend to give you some odd looks if you are alone in the ball pit at McDonald's PlayPlace. ...not that I ever went to one by myself specifically to play in the ball pit...
Um... thank you for this? A real gift.
To me, it seems like a clear win when you're stuck having to develop on the JVM. For Android development, most obviously (I should probably take a look at Scala some time). Presumably there are other areas where Java libraries are essential, but not ones I'm familiar with. Otherwise, I suppose it's not an especially attractive language, when I'm free to choose anything. Though I guess if it's something that just works without being particularly exciting, that's not by any means a generally bad thing.
Some man pages mention the differences from the system call. For instance, the "C library/kernel differences" in `clone(2)`. They don't include details like how `errno` works, since that applies to every system call. Also note that the available calls depend on the architecture. I'm not too familiar with the architecture-specific differences, but one example, consider `socketcall(2)`. On some architectures, all the calls related to sockets really use this one system call. On others: &gt; On a some architectures‚Äîfor example, x86-64 and ARM‚Äîthere is no socketcall() system call; instead socket(2), accept(2), bind(2), and so on really are implemented as separate system calls. Have fun messing with this, but at least when one wants to support every Linux architecture, it genuinely is a lot easier to just wrap the C library.
Woah, that's cool! I mean, that's a _little bit_ dirty and quite tedious to use, but it could be used for crates that can't be deployed on crates.io for stability reasons, or because it uses a git dependency. Thinking more about it, it feels reaaaly hacky, but it excites me nonetheless, I can't tell why...
That's pretty cool. A nice introduction on rust's registry structure. Having been looking at IPFS recently makes me want to try putting a registry there.
I voted Matrix as well. I'm a bit disappointed that Discord is getting as many votes as it is, though.
It's easy to imagine lots of "broadcast" cases where having one writer and multiple readers is useful, though? Being able to do so locklessly is outstanding.
This is so comprehensible for a compilers talk. I can't look away. Niko, you are the best. üòç
You can't use `thread::yield_now()` and claim lock-freedom for all operations. It's also important to note that `evmap` published very poor throughput numbers, both because of poor benchmarking practices and not understanding the results. These may very well be useful libraries, even locks themselves are not evil, but it pains me to see (innocent) abuses of meaningful terms.
I would only recommend the latest stable (+ beta &amp; nightly) releases of the compiler. The stable one is the only compiler we offer support for in terms of providing point releases for soundness fixes and whatnot.
Hello all! As a beginner, I have felt that Rust tries to make everything in the language an expression. It makes me curious why the `let &lt;pattern&gt; = &lt;expression&gt;` syntax is not one. I thought it was to avoid things like `while(x=1) // meant to write x==1` that appear in C, but with the `while let` syntax, such a thing is already possible in Rust. I thought it was because one can not make a good assumption on the return values of something like an assignment, but `if let` and `while let` already suggest that a "successful" variable binding would return `true`, and `false` is returned otherwise. I personally feel it would make sense if the `let` syntax is an expression. If that is the case, "almost everything in Rust is an expression" would be a much truer statement. As variable binding and assignment are used very often, when they are expressions one can see much fewer cases in Rust code where something is not an expression. Also, `while let` and `if let` syntax would no longer be special syntactic elements that need to be memorized individually: it would be just natural to think of and use them. Another advantage is that `;` would be less ambigurous. Currently, when it is appended to an expression, it discards the return value of that expression and return `()`. But when it is appended to the `let` syntax, it discards nothing, but becomes part of a statement which returns `()`.
As long as it‚Äôs not winning. You can‚Äôt fault people for not liking it. Ignoring ideology, they do a great job with UI and keeping everything performant.
The Art of Multiprocessor Programming is an excellent book. You can then follow it with reading research papers, many by the same authors. All of the material Paul E. McKenney has written (linux memory barriers, [perfbook](https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.2018.12.08a.pdf) is also wonderful as a follow-up. It is much easier to write correct lock/wait-free data structures in a GC'd language. In that case, the Java community has the best examples to draw from. Doug Lea's work is the gold standard (`java.util.concurrent`), with other interesting tidbits like JCTools' queues and lock-free map. Once you have a handle on the topic, it should be much easier to implement ideas in Rust where the lack of a GC requires a few more tricks (e.g. epochs).
&gt; It's important in the sense that the ecosystem shouldn't stagnate, and there might be cases where certain things are materially improved via new language features in the public API of a library, but this is fairly rare in the grand scheme of things. Honestly, when I read this I feel rather underappreciated... I feel we regularly, with every or every odd release, provide material improvements with new language improvements. For example, `const _: () = $expr;` is going to improve life for macro authors, `Self::Variant(..)` is going to make code more pleasant to write, and so on. Are these critical? Perhaps not, but they do frequently remove rough edges.
I wouldn't target Rust itself, I'd target an IR if anything, probably MIR. You'd still be constrained by the borrow checker though, and I'm not sure if you actually want that in a dynamic, garbage collected language. Sure, you could compile it to unsafe Rust, but at that point you might as well go down to LLVM IR.
This is great! I hope this instruction gets incorporated upstream somehow.
You asked for pros/cons, so one con is compile time. Rust is already slow to compile, compile-to-Rust language will be even slower.
The real question is: Is mongodb reliable in production? ;)
I like using systems in ways they weren't supposed to be used as a means of getting myself and others to think of a future that could be. That's what excited me about doing this in this first place. Dirty, an absolute hack, and making you go, "wait? What? Hell yeah!"
My understanding of the docs is that as long as it's a URL your computer can get too and it's a git repo for your index then you're good to go. So maybe! Would be really neat!
r/playrust
He is pretty explicit about saying that indeterministic compilation is bad. But what you are actually describing is more than just nondeterminism, it‚Äôs *different behavior*, which is a compiler bug no matter what compilation model one chooses.
If it has to be a git repo, that might interfere with things. It can be read from just fine, but writing is a different story. What I think you'd have to do in that case is set up the repository in a local directory and then add that whole folder to IPFS. If you could just point cargo at a directory, then it would be much simpler. IPFS comes with a UnixFS abstraction for changing directory structures and adding files and it would be nice to be able to use that.
This is my general approach to programming. * "Is it useful?" No. * "Is it good design?" No. * "Should I ever use this in production?" No. * "Is it *awesome?*" YES!
I'm no expert, but isn't this the distinction between "lock-free" and "wait-free"? A lock-free algorithm can have threads that wait for other threads (and perhaps yield). A wait-free one by definition can't.
&gt; But the strong guarantees of the compiler are very enticing. ‚ÄãI would count this as a pro to using rust as a language to build the compiler, but not really as one for _targetting Rust_. If you're compiling your scripting language to rust source, wouldn't it be kind of a bad thing if that rust source ever failed to compile itself? I guess I'm talking from a consumer standpoint here - if you're interested in targetting rust, by all means, go ahead. Having rustc check your language rather than checking it in the compiler seems like it definitely would result in a worse experience writing code in your language. Re: RC - it's definitely a possibility. There's the hard problem of dealing with reference loops, though, and that's generally why GC is chosen instead. (or in addition to - Python is generally reference counted things with a GC added on to catch loops). In terms of an algorithm, `std::arc::Arc` is already quite fast. Reference counting isn't hard - it's incredibly simple. I wouldn't even really count it as an "algorithm", more like a data structure - it doesn't do much, just increment and decrement some integers when cloning and dropping clones. If you're interested in having the programming language not leak memory on reference-loops, though, a gc is probably required. There has been prior work - https://boats.gitlab.io/blog/post/shifgrethor-i/ and https://github.com/Manishearth/rust-gc if you haven't seen either of these - but as you noticed, no tried-and-true solution.
I say this sitting as a southern daughter of a leader in our state Appleseed chapter who was born and raised steeped in a politically conservative gun culture sitting less than 15 feet away from a completely full 600 lb gun safe: I cannot plumb the depths of the stupidity of this comment. On top of being totally unrelated to the subject at hand, it‚Äôs also astoundingly stupid regardless of political ideology. Being a pacifist is completely orthogonal to one‚Äôs stance on gun rights generally, much less the Second Amendment‚Äîa purely _American_ construct by definition. By the way, did either one of your overworked brain cells notice all of the accents in the audience? This was a talk at The Second _International_ Programming Language Implementation Summer School (PLISS) which was held in _Bertinoro, Italy_, you vapid tool. An American immigrant speaking in a foreign country to an international audience and you get upset because of a non sequiter about the United States Constitution... an inebriated tin can would outwit you. I just cannot imagine what it must be like to be so ignorant and fragile that even the slightest wiff of philosophical difference, no matter how fleeting, completely shuts you down. You must live in constant misery and fear. The energy required to sustain that level of anger must be exhausting. May you never reproduce, and may God have mercy on your soul.
That‚Äôs ok, you wouldn‚Äôt have understood it anyway.
Awesome!
You have a typo: "incorrent"
For me, the best way to learn is to build something I am interested in. As far as the sessions go, you could try to make projects that target specific areas. Maybe one that could be a good introduction, another that could emphasize the borrowing, and a third that could target multi threading. 10,000 hours is pretty crazy tbh, if you spend 8 hours a day only doing that it would take roughly 3.5 years.
Almost, and perhaps what you meant. Lock-free means there is a thread making progress and that any given thread being suspended does not cause others to halt from making progress. However, the insertion of yield statements directly begins to indicate flaws in an implementation, especially if not done as a last resort for performance after significant maturity. In this case, the library also uses a mutex when calling `refresh()`. There are many wonderful algorithms that support lock-freedom on a critical path and lock otherwise, but they should not advertise themselves as lock-free. It is fairly common for lock-free approaches to be slower than a locking alternative, so it's usually an implementation detail not worth emphasizing.