Thanks! Yes, Chrome via webdriver is the most common way of doing e2e. It's just quite a memory hog.
There is more undefined behaviour in C. For example compiler can remove infinite loops under certain conditions. See [this issue](https://github.com/rust-lang/rust/issues/28728). Example in this issue crashes on current Rust compiler but may be fixed in the future. However, if you recompile that code to C, it might always crash on Clang and this would not be considered a bug by Clang developers because it conforms to the C standard. There are likely other similar issues.
LLVM to C Compiler https://github.com/JuliaComputing/llvm-cbe some features still need help (mainly exception handling and many Intrinsic are missing)
A P2P application works just like a server-client application except both parties can fullfill both roles. In Rust you can simply implement this with socket programming like you would in other langs.
You probably need OpenSSL headers.
Chrome uses nearly a hundred megabytes *for a single website* being rendered. Webkit's memory use is more around 10MB to 15MB when embedded. The point of embedding such a thing is that -- when the memory use is predictable -- it's relatively simple to implement a work-stealing queue-processing pipeline via massive threading. (24 *full* instances of Chrome would eat gigabytes of memory whereas 24 embedded instances of Webkit use less than *500MB*.) &amp;#x200B; That said, by doing some juggling and application-specific surgery it's even possible to keep the instances warm and simply inject new configuration into the application (via JS) and thereby even avoiding the cold-start delay caused by a full page load. Sure, this can also be done with webdriver, but adding this to the massive parallelism really gives us an edge in scalability.
&gt; is there no way of getting rid of LLVM to speed up compilation? Likely the rust compiler team is able to support a great many targets, due to the fact that they don't compile it directly to machine code, but let LLVM do that (as well as some level of optimization). They could in theory write something that would compile it directly to machine code, but then they would have to support all of the different machine architectures, something LLVM is already handling for them nicely. Likely, the reason they use LLVM is because target support &gt;&gt;&gt; compile time.
Look up the difference between str and String. Basically, you're creating a String, which is really a pointer, a length, and a capacity all bundled together. The pointer will point to data on the heap, however the pointer itself (and the capacity and length) are stored on the stack. That means the String is only valid as long as you are in the `auth` function. As soon as you return from that function, the String becomes invalid (its memory in the stack might be overwritten on the very next function call). By returning a reference to a String, you are saying "I want to leave this String where it is on the stack, which will become invalid shortly, and I want to let someone else borrow it after it becomes invalid", which is obviously a bad thing. Instead, you probably want to return the String itself, since that is like saying "I have this String on my part of the stack, and I'm going to give it to you so you can keep it on your part of the stack. You are now the owner of that String, and therefore it is up to you to clean it up." On a similar note, when a function makes a call to `auth`, the caller will need to give up ownership of client_id and secret. If you want to use either of these strings after the call to `auth`, then you probably want `auth` to take a `&amp;str` or `&amp;String` instead, to indicate that `auth` is only borrowing those values. Also, you might want to check out a library called [maud](https://maud.lambda.xyz/) (or on [GitHub](https://github.com/lfairy/maud)), which (in my opinion) is really nice and easy to use for building HTML strings. I think it still requires nightly to build though, which is a downside.
Really? Damn, this whole time I thought go uses LLVM as well.
https://github.com/llvm-mirror/llgo exists but is not the main implementation.
I would say that it is not the matter of a library choice, because any of those specified by You would suffice. It seems to me that you lack the basic understanding of Rust's ownership system. I highly recommend You to check out The Rust Programming Language's chapter 4: "Understanding Ownership" [https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html)
I am super excited to see this. I started an [github org](https://github.com/esp-rs) last month with plans to start developing pac crates and then a runtime for the tensilica cores. I got bogged down with setting up mrustc and never actually got to developing anything. Once I figure out how to bootstrap rust with thier llvm fork I can start working on it!
/r/rustjerk
I am just starting to learn Rust, coming from python, c and java. I am lost, so the iter produces an iterator, map converts to string. second map is where i get lost. where does the or expression operator come into play?
I build a crate for that usecase 3 years ago: https://crates.io/crates/sun Maybe we can combine the effort?
That really depends on your usecases. In my case, templates are always dynamic/user generated so it wouldn't be possible.
The last time I checked, D compile times were pretty bad. Not bad-bad, but considering that they advertise(d) DMD as blazingly fast, rather disappointing. That was about half a year ago. Has much changed since then?
ah that's awesome, i'll take a look.. &amp;#x200B;
ah exception handling.. does Rust use it for it's panics? (is it not just for errors- can a rust thread panic whilst the rest of the program continues, with spawning a thread being an extreme sort of 'try'?) would you need to rely on a C++ compiler for that - I wasn't aware C could do it. I would be ok to lose the 'thread recovery' idea perhaps &amp;#x200B;
the || is an empty parameter list for a closure function. 
I get if it's an exercise and all but do people really use iterators like this? ``` for i in ["Baby", "Daddy", "Mommy", "Grandpa", "Grandma"].iter() { for _ in 0..3 { println!["{} shark doo doo doo doo doo doo", i]; } println!["{} shark!", i]; } ```
Likewise. Rust already supports the blue pills and black pills in my "grab bag o' microcontroller supplies", and support for the old AVR-based Arduinos will come if/when it comes but, beyond that, ESP32 and ESP8266 boards are the main remaining things. (There are also a few STM8 dev boards, but those are more for situations where I'm willing to use C in exchange for sub-$1 per-unit prices.)
I honestly don't know how rust handles panics. It is possible to implement something similar to exceptions with setjmp/longjmp in c.
Still way faster than Rust ones.
Or even a `format!`
If you come from functional programming or work with rayon, yes.
Ada, Delphi, Eiffel, D, .NET Native compile faster than Rust, while being complexer than C or Go. Even C++ does, on Windows with a mix of pre-compiled headers, incremental compiling and linking, minimal use of templates (or extern templates) and 3rd party dependencies as binary libraries.
Ada, Delphi, Eiffel, D, .NET Native compile faster than Rust, while being complexer than C or Go. Even C++ does, on Windows with a mix of pre-compiled headers, incremental compiling and linking, minimal use of templates (or extern templates) and 3rd party dependencies as binary libraries.
LMAX disruptor only allows a single writer. All the Rust implementations of the pattern have the same limitation except multiqueue, which is what I ended up using.
I think it's a style thing. I really like chaining over blocks of code (and find it more quickly readable for me)
I modified the following statement from the HTTP server example in Chapter 20 of the book. This is what's in the book: let thread = thread::spawn(move ||{ loop { let message = receiver.lock().unwrap().recv().unwrap(); match message { Message::NewJob(job) =&gt; { println!("Worker {} got a job; executing.", id); job.call_box(); }, Message::Terminate =&gt; { println!("Worker {} was told to terminate.", id); break; }, } } }); This is how I modified it: let thread = thread::spawn(move || loop { if let Message::NewJob(job) = receiver.lock().unwrap().recv().unwrap() { println!("Worker {} got a job; executing.", id); job.call_box(); } else { println!("Worker {} was told to terminate.", id); break; } }); Note the type of receiver: \`receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Message&gt;&gt;&gt;\`. My problem is the \`Mutex\` is never dropped in my modified version of the loop and I don't know why. \`job\` does get dropped every loop right?
Once you get to 8 bit microcontrollers you're kinda in the realm of things where *no* high-ish level language really works that well... 
I'm still waiting for a systems language that uses ML syntax rather than C syntax. Purity by default if possible. :P
\*nod* Hence the edit I probably made while you were typing that where I said "It'd be like expecting to develop real-mode DOS software in Rust." (I used that example because one of the hobby projects I'm picking away at is writing an InnoSetup-esque installer creator for use in DOS on floppy disks by retro hobbyists.)
Funny you should mention that; I’ve had people ask if you can write real-mode DOS software in rust before...
&gt; pre-compiled headers, incremental compiling and linking, minimal use of templates (or extern templates) and 3rd party dependencies as binary libraries Well, duh. If you don't compile, you don't spend time compiling :) I especially like the "minimal use of templates". Rust with minimal use of generics also incrementally compiles in debug mode pretty quickly. &gt; complexer I'm not talking about some abstract notion of complexity though, there are very specific things (namely static dispatch of generics, i.e. templates) that make the amount of work needed *explode*.
Industry member with 20+ years coding experience here. Absolutely, FP for life. Functional composition leads to safer code than object composition and muddy state, and code that requires less concentration to read by humans.
\*nod* I used it as an example because it's one of those things that would be nice, and isn't implausible (see, for example, Free Pascal's i8086 support), but is unlikely to materialize due to the amount of work necessary to support a non-flat memory model.
Knowing rustc, the resulting assembly is likely nearly the same regardless of what you choose, so feel free to pick your preference!
Haskell with ! evaluation everywhere
Based on [The Incredible Giant Crab](https://www.deviantart.com/vegasmike/art/The-Incredible-Giant-Crab-8458503) by [VegasMike](https://www.deviantart.com/vegasmike)
Agreed. `TryFrom` is not complicated, we just need to stop making it complicated.
you can try actix-http [https://github.com/actix/actix-http](https://github.com/actix/actix-http)
How do I compile it for a freestanding environment and still be able to use closures? I like OS development and don't have a heap to play with until building one manually.
Yes, Rust uses exception handling infrastructure for panics. And panics can be caught anywhere, not just at thread boundaries: https://doc.rust-lang.org/std/panic/fn.catch_unwind.html You can, however, compile Rust in a mode where a panic aborts the process rather than unwinding the stack. The idea is that the existence of this mode prevents libraries from relying on panics to function, limiting `catch_unwind` to use for fault isolation. A C backend could go far supporting only this mode.
Not in the standard library, but there is [`itertools::repeat_n`](https://docs.rs/itertools/*/itertools/fn.repeat_n.html)! itertools::repeat_n(clone.clone() + &amp;" doo".repeat(6), 3) It merges the `repeat` and `take` operations into one so that, as you said, it's only cloned `3` total times. I guess this optimization is not considered important to have an `std::iter` adoption yet, though :p.
r/rustjerk
How'd you learn? Haven't found any guides, tutorials, or simple examples.
I agree about the cloning, but I think a few more `map`s are tasteful. Here's my rendition, based on /u/Devnought's and /u/tim_vermeulen's suggestion of not cloning too many times in `repeat`: use std::iter; fn main() { let doo = " doo".repeat(6); ["Baby", "Daddy", "Mommy", "Grampa", "Grandma"] .iter() .map(|kind| format!("{} shark", kind)) .flat_map(|shark| { let repeated = format!("{}{}", shark, doo); let last = shark + "!"; itertools::repeat_n(repeated, 3) .chain(iter::once(last)) }) .for_each(|shark| println!("{}", shark)); } 
Hmm, I suspect C as a memoization/curry lib or three somewhere...
Sometimes. Often it works until you look at it the third time and say "this could just be a for loop". Or vice versa.
 let message = receiver.lock().unwrap().recv().unwrap(); match message { Message::NewJob(job) =&gt; { println!("Worker {} got a job; executing.", id); job.call_box(); } Message::Terminate =&gt; { println!("Worker {} was told to terminate.", id); break; } } The above code is from Chapter 20 of the book. I replaced what's above with the following and the HTTP server is now behaving very differently: match receiver.lock().unwrap().recv().unwrap() { Message::NewJob(job) =&gt; { println!("Worker {} got a job; executing.", id); job.call_box(); } Message::Terminate =&gt; { println!("Worker {} was told to terminate.", id); break; } } All I did was inline a variable. Why did this change the behavior? What's different is before inlining the variable, all threads would help handle requests. After inlining the variable only one variable handles requests. &amp;#x200B;
The runnability and syntax highlighting of code snippets is powered by JavaScript, but they should show up on the website without JS too. Could you provide a screenshot of the page?
Rust can already do currying with existential types. Memoization would naturally require dynamic memory unless you preallocated a massive buffer, so it's not a requirement. Plus the whole, you know, parenthetical calls and statements?
I don't know if it helps, but `x.map(|kind| kind + " shark")` can be written in Python as `[kind + " shark" for kind in x]` or `map(lambda kind: kind + " shark", x)`.
There are multiple places working on autonomous car stuff in rust. Some are small startups, some are... much larger. That’s all I can really say. (I’ve been job hunting) We’ll see...
You rock dude! So this way is basically syntactical sugar for a lambda expression.
The rust code is more akin to chaining maps together than comprehensions. `|x| expr` is a lambda (like `lambda x: expr` in python)
This is huge! Thanks for bringing it to notice. Rust on ESP32 and especially ESP8266 is a juicy combo.
Something like the seti@home project.
This seemed like a nice Code Golf question, [so I posted it to the StackExchange](https://codegolf.stackexchange.com/questions/179998/sing-baby-shark). No rust solutions *yet*, so someone from here could be the first!
To a sufficiently advanced optimizer with sufficiently well-designed iterators, the compiled result is the same either way.
I belive xtensa (of esp32 fame) also has non-flat memory
I was so caught up in the flat map I failed to see the opportunity for the map. I like that a lot more!
Thank you for this. I'm learning a lot about iterators from this thread
Even further, just dropping LLVM is pretty much impossible. LLVM does a huge amount of optimization as well as just generally allowing Rust to target any platform LLVM does. If the Rust compiler removed it's dependency on LLVM then it would also need to target every platform you wanted to compile Rust for.
&gt; However, this leads to a compile error about an unsatisfied lifetime Yes, unfortunately `format_args` can be only used in a very temporary curcumstances. I'm using a fomat_macros crate when I want to print something non-trivial. It doesn't create temporaries, but calls write! directly. fomat_macros::wite!(dest, for word in &amp;wordlist { "\"" (word) "\"" } separated { ", " } ); Writing from phone, so sorry for any typos.
You can still put the template in a separate file if you want to. The success of frameworks like React and Vue show that sometimes having HTML and logic in a single file can be desirable. I would rather give people the choice. Tera and Slim also need custom syntax highlighting support, so I don't see how that argument applies here. On the other hand, being integrated into Rust means that these libraries can re-use the highlighting from the host language.
You've been caught by a subtlety in how drops work around `match` blocks. I'm assuming here that `receiver` is a `Mutex&lt;mpsc::Receiver&lt;Message&gt;&gt;`, which means `receiver.lock()` is getting an *exclusive* lock and blocking other threads waiting for work. In your first example, by binding the result to a local, you only lock the receiver for the amount of time it takes to pop a single message out of the queue. The mutex is unlocked immediately after. However, in the second example, no rvalues in the expression passed to `match` are allowed to be dropped until the `match` block is completely evaluated; this is so the arms can borrow into the rvalue passed to the block. Since drops are deferred, the lock isn't going to be released until `job.call_box()` returns, which means no other threads can get work while the first thread is completing its job. When the lock is finally released, the first thread to be woken pulls the next message from the queue and holds the lock until *that* thread finishes its job, and so on. This is why you're only seeing one thread doing work at a time. The simplest solution, of course, is to revert the inlining of the variable. However, you're not going to get the best throughput in this design because of that high-contention mutex. Might I suggest looking at either the `deque` or `channel` modules from [crossbeam](https://docs.rs/crossbeam/0.7.1/crossbeam/), which provide a performant work-stealing queue and MPMC channel, respectively. Or, you can use a `ThreadPool` from [rayon](https://docs.rs/rayon/1.0.3/rayon/) which manages threads and a work queue for you; the worker threads quit when the `ThreadPool` is dropped. 
This is complete conjecture, but I imagine that enums will almost always beat dynamic dispatch since they still allow for inlining and other cross-function optimizations. *However*, the one case where you might see improvement with dynamic dispatch is when the trait objects/enums contain large amounts of data: trait objects are constant-size, just two pointers, and thus are quite cheap to move around, whereas if you have a lot of data in an enum, like maybe a variant with a large inline array, that data has to be copied every time that enum is moved around. Of course, you can combine the benefits of the former and the latter by simply heap-allocating the data in a `Box` or `Vec`.
As an aside, I was reading up on [HTML Modules](https://github.com/MicrosoftEdge/MSEdgeExplainers/blob/master/HTMLModules/explainer.md) earlier today. If that effort bears fruit, then we might go back to writing HTML by hand again! Funny how technology goes in circles like that.
Mostly just from reading the API docs for both libs. But I have a pretty strong background in parsing and writing macros in Clojure. Have you hit specific roadblocks in understanding, or just not found a compelling enough tutorial?
The latter. I've found no place to start. The Rust book, which for the most part is excellent, has little info on macros. There are a few resources on dec macros, but none on proc. I'm decent at dec.
Interesting. My impression was that D compiled significantly faster than Go. Or at least that used to be the case. I wonder what changed? &amp;#x200B;
Wow, this is gold!
I've got some code that I've used on two projects now: // Get available port // based on: https://elliotekj.com/2017/07/25/find-available-tcp-port-rust/ const TMP_PORT_RANGE_START: u16 = 8000; const TMP_PORT_RANGE_END: u16 = 9000; const STARTUP_EXTRA_WAIT: u64 = 100; fn get_available_port() -&gt; Option&lt;u16&gt; { let mut rng = rand::thread_rng(); let mut available = false; let mut port = 0; while !available { port = sample_iter(&amp;mut rng, TMP_PORT_RANGE_START..TMP_PORT_RANGE_END, 1).unwrap()[0]; available = port_is_available(port); } Some(port) } fn port_is_available(port: u16) -&gt; bool { match TcpListener::bind(("127.0.0.1", port)) { Ok(_) =&gt; true, Err(_) =&gt; false, } } The code could be made more idiomatic/better -- but my main concern is whether this is more of a blog post piece of code, or a small crate -- feels like others could find it useful.
You should really use [`bat`](https://github.com/sharkdp/bat), or alias it to `dog`. 
Is this an acceptable practice? I imagine this makes code really hard to read. Wouldn't it be easier to make reference variables instead of chaining anonymous functions?
What do you mean by "easier to maintain"? Traditional template engines are usually more complex than their macro counterparts, as they need to implement a parser and interpreter out of whole cloth instead of building upon the host language. I agree with your other points, though. I did some benchmarks a while ago and even the slowest templates rendered in a couple of microseconds.
I suspect you'd find [hyperbole](https://crates.io/crates/hyperbole) more suitable.
Interesting project, I like how you set up the readme. I'll give it a try and hopefully have more time to think about the borrow checker as I'm still learning about it.
Yes. The specific question I was addressing is very narrow: what's the penalty for doing locked insns etc when everything is running on a single core in a multicore machine. It used to kind of not matter IIRC: it was almost as expensive to take a lock on an old Sequent box when pinned to a single core as it was when multiple cores were sharing the lock. It looks like that is less true today, although the penalty is still substantial. Does that sound right?
Here's the closest I can get with macros: use std::fmt; struct LazyFormatted { formatter: Box&lt;dyn Fn(&amp;mut fmt::Formatter) -&gt; fmt::Result&gt;, } impl fmt::Display for LazyFormatted { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { (self.formatter)(f) } } macro_rules! lazy_format { ($($args:tt),*) =&gt; { LazyFormatted { formatter: Box::new(|f| write!(f, $($args),*)) } } } fn main() { let x = lazy_format!("{}", 3); let y = lazy_format!("{}: {}", 4, 5); println!("{} {}", x, y); } It still does an allocation, which is something you were trying to avoid.
 fn main() { for kind in &amp;["Baby", "Daddy", "Mommy", "Grandpa", "Grandma"] { for _ in 0..3 { println!("{} shark doo doo doo doo doo doo", kind); } println!("{} shark!", kind); } } What are people's thoughts on iterator-adapters IRL? They seem like a great tool for building composable/generic APIs but not necessarily the best replacement for good old-fashioned imperative loops.
I'll keep those libraries in mind, but I'm not interested in optimizing the code, I was just finishing "the book". I've been trying to recreate a smaller example where inlining a variable in a match can cause different behavior, but I haven't been able to get anything much smaller or simpler.
This is the best place to ask: https://github.com/rust-lang/rust/issues/42774
So much boilerplate... makes rust look nasty. Here it is in JS: https://jsbin.com/puvecaceka/edit?js,output o.innerHTML = ['Baby','Daddy','Mommy','Grandpa','Grandma'] .map(kind =&gt; kind + ' shark') .map(shark =&gt; (shark + ' doo'.repeat(6) + '\n').repeat(3) + shark) .join('\n') https://i.imgur.com/qAyzLgJ.png
`message` clearly contains `job` somewhere inside of it. How can `message` be dropped while `job` is still in use? There must be a copy somewhere right?
Right, I missed the part where you said it was in the book. This is definitely a potential footgun loaded with deadlocks, though; I hope it says somewhere to not use this pattern in production. Here's an example I threw together that shows how the drop is deferred by the match block: [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=49c86f326f7733138d5cc09f06130c34) use std::cell::Cell; struct DropCell&lt;'a&gt;(&amp;'a Cell&lt;i32&gt;); impl&lt;'a&gt; DropCell&lt;'a&gt; { /// A method on the struct that lets us use it in a match expression fn get_matchable(&amp;self) -&gt; Option&lt;()&gt; { Some(()) } } impl&lt;'a&gt; Drop for DropCell&lt;'a&gt; { fn drop(&amp;mut self) { println!("{}", self.0.get()) } } fn main() { let cell = Cell::new(0); // prints "0" let _ = DropCell(&amp;cell).get_matchable(); // prints "2" match DropCell(&amp;cell).get_matchable() { Some(()) =&gt; { cell.set(2); }, _ =&gt; (), }; // semicolon necessary to prevent borrow-check error } The semicolon prevents a borrow-check error by making the `match` its own lifetime region; otherwise, it would be in return position and it would try to make that `DropCell` live as long as the `Cell` it references (this would be an issue if we were somehow trying to return a borrow into it but we're obviously not, so perhaps that rule is too rigid or is intentionally invariant to make inference easier).
Templates are easier to maintain, not template engines.
It's not so much a "shorthand" as another way of doing it. Python list comprehensions are provide the same functionality as `map()` and `filter()` (which are builtin functions in Python, and `Iterator` methods in Rust). But in Python, `map` and `filter` are generally discouraged, as is the use of `lambda` generally. Anonymous functions are more idiomatic in Rust than Python. Both methods are borrowed from functional programming languages like Haskell. You could argue which is better generally, but in any case, Rust doesn't have list comprehensions. One advantage of the Rust method here is that the language itself doesn't need to have any special support for this; the `Iterator` trait is just implemented as normal Rust code with no special compiler support. The method syntax Rust uses allows chaining operations. It is confusing at first, but I think it becomes easier to understand when you're used to seeing code that does that. Of course, it whether or not it's the best solution depends on the specific task and personal preference.
I think in Rust what people usually do is one of these two: 1. Just have your Rust program be its own standalone web server. This works because Rust is quite fast and has good support for parallelism. 2. Have a dedicated web server like nginx which proxies HTTP requests to your Rust code. Essentially, HTTP is your "gateway interface" in this scenario.
Thank you very much. I'll have to dig into that example tomorrow. Haven't used Cell yet so now I have an excuse to learn. :) And yeah, the book mentions in multiple places that it's not really a good way to build a HTTP server.
But this sounds more like classic server/controller + slave/worker programming. Like a few controllers that coordinate the task and many workers that does the heavy calculations. Correct me if I am wrong. 
Can someone describe the significance of this, i.e. what is ESP32?
Saw your message; we fixed it. Take another look. :)
Great! This was exactly what I was looking for! Thanks!
from their wikipedia article &gt;ESP32 is a series of low-cost, low-power system on a chip microcontrollers with integrated Wi-Fi and dual-mode Bluetooth. The ESP32 series employs a Tensilica Xtensa LX6 microprocessor in both dual-core and single-core variations and includes in-built antenna switches, RF balun, power amplifier, low-noise receive amplifier, filters, and power-management modules. ESP32 is created and developed by Espressif Systems, a Shanghai-based Chinese company, and is manufactured by TSMC using their 40 nm process.\[2\] It is a successor to the ESP8266 microcontroller.
it becomes harder to do what you'd consider easier when you factor in ownership and lifetimes and whatnot plus, this is done with the aim of using functional programming, obviously. as such, you use anonymous functions a decent amount
Yep, you're right! My mistake. I solved the problem by creating the "line" in a separate step: ```rust use std::iter; fn main() { ["Baby", "Daddy", "Mommy", "Grampa", "Grandma"] .into_iter() .map(ToString::to_string) .map(|kind| kind + " shark") .map(|shark| { let line = shark.clone() + &amp;" doo".repeat(6); (shark, line) }) .map(|(shark, line)| { iter::repeat_with(move || line.clone()) .take(3) .chain(iter::once(shark + "!")) }) .flatten() .for_each(|shark| println!("{}", shark)); } ```
You're technically correct but it's JavaScript so wrong
You're moving `job` out of `message` by matching by-value. `job` itself is dropped when `.call_box()` returns. What I was talking about specifically is one of the intermediate values in that long method-call chain. `receiver.lock()` returns a `MutexGuard` which derefs to `&amp;mut mpsc::Receiver&lt;Message&gt;` so that you can call `.recv()` on it. However, `MutexGuard`'s other purpose lies in its `Drop` impl: when it falls out of scope, it releases the mutex lock so you don't have to remember to do it (a luxury not every mainstream language has still; [Go is, disappointingly, one of them](https://tour.golang.org/concurrency/9)--you can `defer` the unlock statement and put it next to the lock statement for clarity, which effectively does the same thing, but you still have to write it out). So the drop that's being deferred here is the drop of `MutexGuard` because of the lifetime rules of a `match` expression.
I assume they are referring to the examples I gave, but those are just two things I thought of on the spot, so unless someone else had the exact same ideas, you will not find them in the book.
Ahh, the closure-in-macro idea is what I needed
ESP32 has instruction and data memory address regions, but it doesn't have overlays in the way 16-bit x86 programming does.
Just a note: You do #2 with an application server host like [uWSGI](https://uwsgi-docs.readthedocs.io/en/latest/) or [Gunicorn](https://gunicorn.org/) too so that it doesn't need to be concerned with efficient, scalable serving of static files.
Yeah. The distinction between `near` and `far` pointers on 16-bit x86 and the complexity of data structures which need to extend over multiple segments is the real killer for the prospect of a real-mode x86 Rust.
\*nod* This really made me cheer: &gt; Current Xtensa target list: &gt; - support Xtensa LX6 target (ESP32) by default &gt; &gt; [...] &gt; &gt; Plans for next releases &gt; [...] &gt; - rebasing on the upstream version of LLVM, following the new monorepo layout (https://github.com/llvm/llvm-project/). &gt; [...] &gt; - support for LX106 target (ESP8266)
Well, here's some of the reading that I did while learning (and a few others I just found): &amp;#x200B; \- (Good Overview of the landscape) [https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html](https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html) \- (Haven't read, but it looks visually very nice :) [https://tinkering.xyz/introduction-to-proc-macros/](https://tinkering.xyz/introduction-to-proc-macros/) \- (I skimmed this one a bit, nice writing style): [https://naftuli.wtf/2019/01/02/rust-derive-macros/](https://naftuli.wtf/2019/01/02/rust-derive-macros/) \- (Shorter and probably most of the material was covered by other posts): [https://joshleeb.com/posts/rust-procedural-macros/](https://joshleeb.com/posts/rust-procedural-macros/) \- And finally, the closest thing there is to authority on the little details of how things work in Rust, the Reference page: [https://doc.rust-lang.org/stable/reference/procedural-macros.html](https://doc.rust-lang.org/stable/reference/procedural-macros.html) &amp;#x200B; Also, mandatory reading (and usage I would argue) are the [syn](https://docs.rs/syn) and [quote](https://docs.rs/quote) packages. And certainly [proc\_macro2](https://docs.rs/proc-macro2/0.4.27/proc_macro2/) is a useful reference. In particular, because I was working on parsing a custom syntax with a function-like macro I found the [lazy\_static example](https://github.com/dtolnay/syn/tree/master/examples/lazy-static) particularly helpful.
Well, of course. But it's because Rust's compiler is unusually slow, not the other way around.
&gt; some of the instruction formats are awful Care to elaborate which ones and why? 
Hi, I don't know enough about Rust, nor am I going to tell you to not learn it (Note: for the curious, I only happen to find this Reddit post in my Google search for Ada related activity). However, since you are interested in safety critical software development, I recommend learning SPARK since it has at least a 30 year proven track record of being used to develop software with \*ultra low\* defects (see Bristech 2018 SPARK presentation here: [https://www.youtube.com/watch?v=VKPmBWTxW6M](https://www.youtube.com/watch?v=VKPmBWTxW6M) ). Any positive experience from that will probably help you with any safety critical software you decide to develop with Rust. I say this because my experience with Ada without a doubt had a big positive influence on how I write C and C++ software. No doubt Rust technology will get to the level of SPARK (e.g. ability to prove software is \*free\* of runtime errors), but keep in mind that SPARK will keep improving as well (e.g. SPARK is currently getting some form of ownership capability inspired by Rust: see [https://fosdem.org/2019/schedule/event/ada\_pointers/](https://fosdem.org/2019/schedule/event/ada_pointers/) ). So learn both languages, see how well each one can or cannot support the level of safety your software requires, and you will be better than if you only knew one of them.
Clo-one shark 
That depends on your code a lot. If you write C-like stuff, all D compilers do very well. Throw in any templates (especially recursive ones) or non-trivial compile-time computation, e.g. generating code from an external file like JSON/XML/etc. and it gets very bad very quickly. &amp;#x200B; The second problem is being worked on, though. [Stefan Koch](https://github.com/UplinkCoder) is writing a patch to D compilers' frontend called newCTFE that evaluates functions at compile time a lot faster. His approach is to compile relevant chunks of code to a simple binary for a built-in virtual machine and then execute it. It's not as fast as JITing it to the native architecture, but it's still far better than traversing and modifying the AST (that's how it's done ATM).
 for name in ["Baby", "Daddy", "Mommy", "Grampa", "Grandma"].iter() { println!("{} shark doo doo doo doo doo doo", name); println!("{} shark doo doo doo doo doo doo", name); println!("{} shark doo doo doo doo doo doo", name); println!("{} shark!", name); }
I don't know the gamut of your skills but I have seen your PR and dev-evangelism side and that is one of the best ever I've known. I think you'll fit in great at Microsoft- they need someone like you and they love devs.
I like chaining too (I'm mainly an F# dev, chaining is our bread and butter) but multiple maps in a row is generally overdoing it in my opinion.
It's not always that simple, unfortunately. Some structures can be iterated significantly faster using internal iteration, and in some cases external iteration is sufficiently complex that it's unreasonable to expect the compiler to make it as efficient as the same code using internal iteration. My hope is that for loops will at some point be converted to internal iterators right at the beginning of compilation, rather than translating it to repeated `next()` calls and trying to optimize that.
Wow, this is some really cool stuff. Just out of random interest, could this be used to translate [RPython](https://rpython.readthedocs.io/en/latest/rpython.html) (and thus to implement PyPy)?
I also feel it's important to note that I took a long break from writing some proc macro code to make this image because my macro code is overflowing the compiler's stack and absolutely cannot figure out why :D This meta-programming stuff is hard!
Nice! I didn't know about itertools' `repeat_n`, that's good to know.
&gt; In't the Go compiler written in Go for example? It's blazingly fast. As I know the first version was in C, and rewrite in Go cause compilation time regression and several major releases the Go team step by step return back what was before. 
I'm glad *somebody* here doesn't pointlessly overcomplicate things! (Yes I get in this case it is just for fun but please don't do it in real code!)
Here's the text of Niko's comment so y'all don't have to load the giant thread on GitHub just for the relevant info. --- &gt; So, we had a number of discussions about async-await at the Rust All Hands. In the course of those discussions, a few things became clear: &gt; First, **there is no consensus (yet) in the lang team about the await syntax**. There are clearly a lot of possibilities and strong arguments in favor of all of them. We spent a long time exploring alternatives and produced quite a lot of interesting back-and-forth. **An immediate next step for this discussion, I think, is to convert those notes (along with other comments from this thread) into a kind of summary comment that lays out the case for each variant, and then to continue from there.** I'm working with @withoutboats and @cramertj on that. &gt; Stepping back from the syntax question, another thing that we plan to do is an overall triage of the status of the implementation. There are a number of current limitations (e.g., the implementation requires TLS under the hood presently to thread information about the waker). These may or may not be blockers to **stabilization**, but regardless they are issues that do need to ultimately be addressed, and that is going to require some concerted effort (in part from the compiler team). **Another next step then is to conduct this triage and generate a report.** I expect us to conduct this triage next week, and we'll have an update then. &gt; In the meantime, I am going to go ahead and **lock this thread until we've had a chance to produce the above reports**. I feel like the thread has already served its purpose of exploring the possible design space in some depth and further comments aren't going to be particularly helpful as this stage. Once we have the aforementioned reports in hand, we will also lay out the next steps towards reaching a final decision. &gt; (To expand a bit on the final paragraph, I am pretty interested in exploring alternative ways to explore the design space beyond long discussion threads. This is a much bigger topic than I can address in this comment, so I won't go into details, but suffice to say for now that I am quite interested in trying to find better ways to resolve this -- and future! -- syntax debates.) 
Is memory deallocation unsafe in SPARK too like plain ADA?
To expand on what u/emekoi quoted, the great thing about the ESP32 (including its predecessor, the ESP8266) is that it's incredibly cheap for what it includes. It packs a ton of features and pretty capable Wifi / Bluetooth hardware while costing about 5-8€ for a development board. Afaik, its power usage is still not optimal (tbf you can only get so far when you need to include a whole WiFi stack hah), but I assume that's going to be fixed in a future rendition of the chip. They're awesome for home automation, but also great fun just to tinker with :D
...uh. Nginx serves the static files. In most of my work the app server doesn't even get to see the statics.
I believe yes, but it will be fixed in the next revision, basically by porting borrow checker. Prototype is already done. https://arxiv.org/abs/1710.07047
Thank you all for your suggestions and to /u/CUVIper for mentioning crate \`ctrlc\`: it works like a charm
I get that FP is in style right now (and I come from FP too), but I tend to go with what's most reasonably readable and understandable. In this example I find the for easier, even with the `doo doo ...` being somewhat repeptitive.
That would be quite amazing... And should be simpler to do than full python, since rpython has some compiler-friendly restrictions on it already.
You're sailing in dangerous waters. This discussion edges on functional vs procedural programming. Functional programming (what you see here) has a handful of advantages, but it isn't C + some sugar, so many consider it less readable.
Thanks, i'll take a look into it.
If you've heard of Arduino, it's like a next-gen sucessor to that.
IIRC, the two main caveats are: - It targets a rather old version of Rust by now. - It performs no borrow-checking, so the code must be proven correct by rustc first (`cargo check`).
Has it been suggested to overload the `?` operator? It kind of goes against Rust philosophy but it solves the precedence issue and doesn't introduce a new sigil or cumbersome syntax. It's also already known as an "unwrapping" operation and that it affects control flow.
&gt; A C backend could go far supporting only this mode. This. Especially for an MVP, just go with `panic = abort`, it'll simplify a lot of things!
Eventually, yes, it should be possible. I haven't heard of RPython before, but I already like how restricted it is. It makes a good candidate for first fully supported Python subset. Though there are still exception handling, default arguments, inheritance and other not easily transpilable stuff.
There is a lot of UB to navigate, indeed, however at least in C (unlike C++), there is an appendix listing all instances of UB, and there are compiler modes to smooth some out (`-fwrapv`). It's still a challenge, though.
There's an obvious bit of optimization I'm surprised nobody has suggested yet: `s/shark/crab/`
&gt; If you've heard of Arduino, it's like a next-gen sucessor to that. Arduino (AVR and ARM based boards) and ESP32 differ a lot and are not made by the same companies, so calling it a successor might be misleading to some.
Yeah heavy emphasis on "like". It's not an official successor, but most Arduino code runs on the ESP32 without modification and the community has enthusiastically adopted it.
I'm not convinced that Rust is currently at the level of verification that SPARK can provide right now. It's going to need dependent types to same level of static verification that SPARK can provide, as well as a formal language specification (but for that I think the plan is to wait for the RustBelt formal language verification).
*What follows is strictly my opinion as an observer.* My take on portability is that things are going to improve in the coming years. The first step is already being worked on: *cranelift*. Going from 1 backend (LLVM) to 2 backends (+cranelift) will require some refactoring and decoupling that will later pave the way to further backends. The second step, for me, once cranelift is integrated, should be attempting to integrate a 3rd backend: GCC. With LLVM and cranelift both being supported, it should take less refactoring/decoupling, only tweaks here and there. GCC is not only valuable for portability, it's also valuable for code generation quality opportunities: the C++ applications I work on compile to faster binaries with GCC than with Clang. I suppose compiling to C could be a third step; but it's unclear whether there'd be much interest once both LLVM and GCC are supported: they'd already cover a broad range of architectures. Especially as there are companies extending LLVM as we speak, [see this new Xtensa backend](https://www.reddit.com/r/rust/comments/ar2d3r/espressif_have_finally_released_an_llvm_fork_this/). If it is judged valuable, then I would suspect that getting a C backend in cranelift would be the easiest: as a younger project, it's more open to experimentation.
Every single possible option has been suggested and argued for (and argued against), so let's just wait for the reports in a peaceful moment of silence until the discussion gets a much needed injection of organized thought. Or, in words of Niko, "further comments aren't going to be particularly helpful at this stage".
Thanks! Good luck on your learning journey. Looking forward to your pull requests with good ideas!
&gt; cramertj opened this Issue on Jan 15 · 509 comments Indeed, a structured approach would be helpful. I don't think wading through 509 comments, with dozens of mostly-but-not-quite duplicates, is anyone's idea of productive time.
I read the same message you did. I'm simply asking if anyone knows if the ones I mentioned were discussed already and what people thought of them. I'm seeing a lot of creative suggestions in that thread get dismissed out-of-hand so I wanted to make sure these weren't overlooked. 
Not necessarily. For example, I have nginx running with `mod_uwsgi` instead of just having an http `proxy_pass` that goes to uwsgi. But I think with gunicorn that is usually the case.
what about the hourglass emoji ⌛
[You bet.](https://i.imgur.com/3UFUeh9.png)
Or only [Cairo](https://crates.io/crates/cairo-rs) if this is about drawing 2D graphics without UI
I have been using Frama-C with C and C++ lately, and many of the things which need to be proven (pointer validity, separated pointers, RAII, ...) are non-issues in Rust. Not saying that Rust does not need formal tools, just that it's gonna be quite different and awesome.
That's what I said. #2 is irrelevant/misleading because, if you're using a "gateway interface" like WSGI, you *still* put the WSGI host behind a server like Nginx or Apache.
&gt; I want to find a lib like uwsgi to help improve my server. Improve in what way?
Module or separate process, the point is that you don't expose a self-contained uWSGI process directly to the Internet, so saying #2 in the context of "one of these two" is irrelevant and/or misleading. It's "both of these two".
Lots of prototypes are done in rust. SPARK strength it’s that it is not only prototyped but also industry-proven and critical domains certified (aeronautics, railways, nuclear, space, ...) Prototype is no argument for ADA
What? I meant SPARK and Ada will have safe deallocation soon, and this is credible because a prototype implementation (written in Ada, implemented in GNAT) already exists.
They were all discussed. The proponents of sigils were actually very loud in that thread. Someone even proposed: let res: MyResponse = client.get("https://my_api").send()?!?.json()?!?; Other proposals: self.logger.log("beginning service call")(?); self.logger.log("beginning service call")(await); .send()＠? foo()~; foo()^^; foo()&gt;&gt;&gt;; let s ​=​​ [&lt;-]​ f​(); optional_struct​[-&gt;].​optional_sub_struct​[-&gt;].​field let user = user.res.[*json::&lt;UserResponse&gt;()]?; let user = self.[@request(url, Method::GET, None, true)]?; client.get("https://my_api").send() await?.json() await? and so on.
Well I'd take "average" compilation speed for Rust code I guess...
What do you mean by soon? Available for production? Which level of criticality?
Ah, interesting. This is definitely outside of my area of expertise! So thanks for the information :)
I think we need something similar to QML but implemented in Pure rust. i don't know how they achieve it but its fantastic , its super flexible you dont have to relie on the widget you are provided with. you can design your own like you do with HTML and CSS plus you can put animation just like javascript and the best part is QML can be compiled to native for further performance.
By soon, I mean the next standard revision. There has been Ada standard in 1983, 1995, 2005, and 2012. The next revision is tentatively 202x. Available for production and critical work.
Thx
This is a really great project. I'm not sure if you are far enough along for this, but do you have a goal for pyrs to be able to completely transpile itself to rust? I could imagine a really thorough automated test suite which could start by having pyrs transpile itself to Rust. Then run snippets of python through both the original pyrs and the rust pyrs and ensure they match. 
I used to work in automation and controls and in my experience the work was done primarily in much higher level languages. Can I ask which particular fields you are working in and which country you are from? 
God i hope someone can just pull the band aid though. At this point it sounds like there's no direction. What are our options? Either wait until someone comes up with new brilliance that gives direction, or pull the band aid and pick an existing option? Is there something beyond those two options i'm missing?
You should use `RUSTFLAGS='-Z time-passes' cargo build +nightly --release` so that you get the information from all crates.
I am a polyglot, so I will be keeping up with Rust and other languages. Spark has my attention for a current job I am working on, since Rust does not yet have the number of libraries available, and I cannot budget in writing them in a language in which I am a beginner. I believe Idris aims to try and do a lot in this area too, but is also more academic at this point. I agree Rust and Spark seem to be a great duo!
I wrote a reddit bot and a library for using the reddit API. I believe there are other more developed libraries out there, but it may be helpful to read this one for some simple tips on how to get things working with reqwest. Unfortunately it won't help with issues around combining rocket and reqwest, and it may be using an outdated version of reqwest. https://github.com/JoshMcguigan/rraw https://github.com/JoshMcguigan/license-bot 
I work in the entertainment engineering field, and I am from the US, but I have lived and worked in SE Asia for 8 years just recently. Manufacturers generally have provided higher level language interfaces to their products, but I am speaking about creating controls systems, not integrating systems.
Can you share a link to the crate? 
I can easily see Rust already being used where C/C++ may have been for autonomous vehicles, but it's going to take guys like you to develop the libraries and help it to gain industry-proven experience like Spark. I am in my mid-fifties now, and don't have the time to be part of that charge. I need to deliver/ship a product in 14 months. I am looking to replace C code with Rust incrementally.
That's some beautiful Perl code.
😢
Which is why we should be wary of adding a new sigil to the language.
Not sure what you mean. The lang team will make the final decision. Not everybody will be happy with it but they will choose whag they think is best.
So you're thinking they're going to choose an option from what has been discussed? Hope they do so soon. I know, i'm being impatient haha, but it's just been a long, long time coming. We feel so close, and so far away. Note that none of this is meant to take away from the efforts of all that contributed to this and the work yet to come. I mean no disrespect :)
Given the amount of discussed options, anyone will be hard pressed to find one that *hasn't* yet been discussed.
Thanks. I was thinking about benchmarking transpiler by transpiling itself, but pyrs is heavily reliant on dynamic Python features like 'isinstance' and most of the stuff is inherited from standard ast Visitors. So right now it is far from possible.
I suppose the LLVM-IR -&gt; C path is one that might help the world more, i.e. &lt;for other languages that use LLVM-IR&gt; as per the julia example someone linked here. The other thing that might be interesting about Rust -&gt; C is really convincing people who are driven by emotion *and safe habits* that this scary new language really is the same sort of thing as C,C++ (just with additional high level safety ) - there are people more afraid of a new language than the danger of raw pointers etc. (i'm talking to one now elsewhere..). perhaps it could help streamlining inter-op. I guess I would have suggested "LLVM and C backends" rather than LLVM &amp; GCC.. but I've not volunteered to put time into it so it's just an opinion.. I have used GCC in anger and in contexts where there's other reasons to patch it (and eventually saw the community get that done..) - it's the opportunity to decouple the changes though (handling seperate issues at a different pipeline step) that seems to appeal to me
ah that's re-assuring to hear.. both that the catch ability is supported and the ability to disable it 
Good stuff!
&gt; while costing about 5-8€ for a development board Cheaper if you order from China. You can get an ESP8266 board for under $2 US (free shipping) if you poke around on various direct-from-China sellers, and ESP32 boards seem to be going for around $8 US after shipping. (With sales dropping their prices as low as $4.50 US after shipping) You can see why I have a few in my grab bag of components to play around with.
&gt; they love devs *cries in Xamarin* Hah no, seriously, you're right. Might be a nice option.
Yo. Just want to point out that [pleroma](http://pleroma.news) is a thing and unless you have any specific problems with that, rather than reinventing the wheel, support that development instead. It's very nearly there!
I like this solution too, find it much easier to read compared to the original one.
&gt;It's mostly due to the LLVM (LLVM IR -&gt; binary) phase. So, you are saying that clang as slow as rustc? I doubt that. 
ok.
Ah thanks. I found that lib already. However, for my usecase I would have to #\[derive(FromForm)\] from the rocket lib, so I can parse form data into a struct: [https://api.rocket.rs/v0.4/rocket/request/struct.Form.html](https://api.rocket.rs/v0.4/rocket/request/struct.Form.html) &amp;#x200B;
Hi all! I've got a function that I'd like to be async. I would also like one of the arguments to be another async function. How would I declare such a function? ``` use std::future::Future; async fn some_function(next: impl Fn(&amp;str) -&gt; impl Future&lt;&amp;str&gt;) -&gt; &amp;str ``` Gives an error since &gt; `impl Trait` not allowed outside of function and inherent method return types So what's the best way to take an async function as an argument?
I agree that in general a C backend for LLVM could be useful for everyone, not only Rust. It could even provide easy cross-language inlining with C and C++: transpile to C/C++ (a subset of both languages), then feed the generated files to a C or C++ compiler alongside the regular C or C++ files and reap the benefits. Unfortunately, from experience, it just doesn't seem to happen: - There's the issue of maintenance. It's not enough to just write a LLVM 7.0 backend, the LLVM project requires a commitment to maintain the backend: fix bugs and handle evolution of the LLVM IR. - There's the issue of volunteering. I'm firmly in the "could be nice" camp, but honestly all architectures I really care about are supported by LLVM already, and I just have projects that are more important to me. 
I have written a web app for supply chain research recently, using async in Python. It was really painful to convert a function from non-async to async as the design evolved. I wish we will be able to do async in rust without having to write await whenever an async function is called. We may add optional await for more complicated scenarios like awaiting on multipe coroutines. But for awaiting on functions one by one, which is the most common case, I wish await will be optional. 
This is looking like still more of the push to make graceful degradation impossible, similar to how Web Components *could* have bound custom HTML tags to templates declaratively to provide some minimum level of graceful degradation but, instead, needlessly do it in JavaScript.
Give collecting and organizing the community's thoughts a chance. Good decisions take time, especially when the team is still working out a satisfactory decision making process.
Not sure how to contact Niko, so commenting here. There are several structured debate platforms designed to evaluate pros and cons for various courses of action, such as https://www.kialo.com/ These might be worth giving a shot.
I wonder if custom allocators should be passed as *trait parameters*. There are good reasons to do this. It makes stateless allocators cheap (no extra state), and it helps with inlining, etc... On the other hand, the case of allocator type parameters is not clear cut. Drawing from my experience in C++ here, customizing is a rare enough requirement that many people *forget* about them, so that many generic methods over, say, `std::map` will take a `std::map&lt;K, V&gt;`, and therefore can only be used with regular comparison and allocators. This has the effect of splitting the ecosystem between *allocator-aware* crates and the rest of the world. It also requires more "bloat": the code is "polluted" by allocators, the debug symbols are "polluted" by allocators, etc... The latter can be partially remedied by hiding default type parameters in demanglers (which I just suggested on the RFC), but still... Would it be worth it embedded allocators with *run-time polymorphism* instead?
I am **SUPER** excited to see the team put concrete structure in making this decision. I hope they continue to do this in the future for this and other important decisions. (Shameless plug: my [suggestion](https://www.reddit.com/r/rust/comments/ai5l5l/how_will_the_await_syntax_finally_be_decided/eeme8r1/) for a way to keep it up.) Here's to hoping that the summary document carefully, concisely, and fairly weighs each of the options presented so far. In the meantime, we should be grateful that somebody else is doing all that grunt work! Imagine how productive the conversation will be with all that low-hanging fruit definitively out of the way.
Here's a thing to think about: "Readable" is relative. For some coders, a chain of functional operations might be more readable than a nested loop.
This would be implicit await and it has been proposed and discussed in the thread. The main takeaway is that it wouldn't work well with the async execution model of Rust so I wouldn't get my hopes up too much.
&gt; some of the instruction formats are awful &gt; &gt; Care to elaborate which ones and why? My main complaints are the compressed instructions and anything involving immediate values. So far in my alternate encoding doodles I have most of the base integer instructions encoded in 16 bits but with the caveat that only the first 16 registers are accessible. Load, add, xor, and, or immediate all specify a size of the constant using a 2-bit field within the 16bit opcode which can mean 16,32,48?, or 64 bit constant data in the following 16bit words. It is variable length, but the length can be determined by the first word. You'll need a 32bit instruction followed by constant data to get at the other 16 registers. As it is today RISC-V requires a 32bit instruction for small constants (12 bits IIRC) and two 32 bit instructions to load a 32bit constant (load upper immediate and add immediate) and there is no way to load a 64bit constant - you have to fetch it from memory, not that that is necessarily bad but it means D-cache instead of I-cache. I really like the instruction set a lot - very compact but effective. I just don't think the encoding is very good. There is one other thing I wonder about. I appreciate the elimination of flags by using the compare-and-branch instruction but I wonder if it would be better to have a simple IF instruction that does the comparison and only executes the following instruction if the condition is met. This still means no explicit flag register visible to the programmer, but it provides conditional everything. It would be up to the CPU designer to decide how to implement it in hardware, but just dropping the next instruction or its result would do. Another feature is that it could work with the simple-v proposal - that hidden flag could be a vector of bits, eliminating any need for user visible predicates on vector operations. 
I'll buy it, that seems like pretty sound conjecture to me. Thank you!
Dynamic languages and templates can also have type checking. It just wouldnt be typechecking on the rust level. 
I figured it out! Future travelers beware creating a struct with a ‘quote::ToTokens’ impl and then trying to interpolate fields inside that. ‘quote! { #self.name }’ reads as “interpolate self into input by calling ToTokens::to_tokens on it, then append the literal ‘.name’ to the output.”
A reason why the LLVM phase takes a long time is because rustc passes in LLVM-IR that is harder to work with, which is why people aren't sayinfy that clang is as slow as rustc
I advise that you get into the habit of creating MCVE (Minimal Complete Verifiable Examples) when tickled by a problem. In your case, the MCVE can be found [on the playground here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=608d5ece8aa58331fb8951947ff0ac0d): use std::sync::Arc; fn send&lt;T: AsRef&lt;[u8]&gt;&gt;(data: T) { println!("{:?}", data.as_ref()); } fn main() { let x = Arc::new(vec![0u8]); send(x); } And the error is given as: error[E0277]: the trait bound `std::sync::Arc&lt;std::vec::Vec&lt;u8&gt;&gt;: std::convert::AsRef&lt;[u8]&gt;` is not satisfied --&gt; src/main.rs:9:9 | 9 | send(x); | ^^^^ the trait `std::convert::AsRef&lt;[u8]&gt;` is not implemented for `std::sync::Arc&lt;std::vec::Vec&lt;u8&gt;&gt;` | = help: the following implementations were found: &lt;std::sync::Arc&lt;T&gt; as std::convert::AsRef&lt;T&gt;&gt; You can note that the compiler did not consider, at all, which `AsRef` implementations `T` implemented: it does not recursively unwraps. In that case, you can manually unwrap one layer: fn main() { let x = Arc::new(vec![0u8]); send(x.as_ref()); // ^~~~~~~~~ } And lo and behold, it compiles!
Hi, thanks for the reply! I think I have tried that, and it won't work. I believe the problem is that in my code, I can't pass a reference in the `write_all` function. This is because `write_all` has to own the variable, since it is a future and the `r` variable in my scope is getting out of scope before the reference is actually used. In the code you give you can simply use the `as_ref` method since `x` is not dropped until `main` returns, which is definitely after `send`. I tried creating a smaller piece of code to post but due to my limited knowledge in rust, futures and tokio, I am not exactly sure what exactly causes the problem.
Jackie Chan
That site looks awesome! Do you know if it supports only pro/con sides? With the syntax discussion there are more than two sides.
I am currently thinking of implementing/porting PRNU extraction, matching and tools to rust (Photo response non-uniformities, used for camera identification from images). This would however be my first proper rust project (the only thing I did before was implement a perfect Yahtzee playing program), so my question is whether that is an appropriate project size to begin with? I already have a lot of experience in C, C++, Java and some others. As far as I see, 2D wavelet transforms are already implemented in rust ([https://docs.rs/GSL/1.1.0/rgsl/wavelet\_transforms/index.html](https://docs.rs/GSL/1.1.0/rgsl/wavelet_transforms/index.html)), but I am not sure if that fits what I need for PRNU extraction. 
I feel like I'm being woooshh-ed here, but I don't know in what way...
Challenge accepted ;) One option I didn't see discussed that I kind-of liked is postfix cast-like syntax. `fut as awaited` It retains the benefits of the postfix syntax while still reading well. Of course, I don't think it has any chance of being popular, which is why I never suggested it in the thread, but the point is, there are probalby some other dark-horses out there somewhere!
If you're just looking for well-defined problems to solve in rust, I might suggest running through the Advent of Code challenges. They seem like great ways to force yourself to dig into various parts of a language while solving a specific challenge. https://adventofcode.com
I designed it as a legit Rust riddle. The 'liked' types all share a property which non of the 'disliked' types has. The property has little practical impact, but related to fundamental language features of Rust.
I've implemented this idea among other changes, like supporting `Vec&lt;T&gt;` result type and its variations in the 0.1.1 release: https://crates.io/crates/shellfn I've used your example with the module in one of the examples (`cargo run --example calendar`). Thank you for this suggestion.
Does this help? https://docs.rs/tokio-io/0.1.11/tokio_io/io/struct.Window.html
That doesn't fit the 'no new keywords apart from `async`/`await`' rule.
I'd consider this a bug – both should elide bounds checks.
I'm guessing it has to do with how the first range index is performed on a fixed-size array, while the second is on a slice that doesn't include its size in the type. The single bounds check it does is `if 10 - offset &lt;= 2`, equivalent to `if INPUT - offset &lt; OUTPUT`. That's the check needed to ensure that the `[..OUTPUT]` access is in-bounds.
You can pass `--emit=llvm-ir` to see the difference in the IR. That said you can always use get_unchecked if you want to avoid bounds checks. 
Is there a summary of why implicit is a bad fit? The current thread is so huge to try and read through and it just seems to make sense to me that you'd mostly just want the asynchronicity to be waiting for input in sequence rather than waiting for input in parallel.
&gt;I like `Vec`, but hate arrays and tuples. But do you like a tuple that contains a `Vec`?
No
Ah, yes, my mistake, I kinda dropped the ball there.
The context for the question is that I want to optimize how the `array_ref!` macro is written. In general it does need to do bounds checks, because its a safe interface. But I'm hoping to write it in such a way that when the caller has already done the necessary checks, the compiler is able to notice that and elide the extra work as much as possible.
Hey, thanks for the suggestion! If I get this right window is just a wrapper around something that implements `AsRef&lt;[u8]&gt;` so that it can be used as a slice. This does not solve my problem I think, since the cause of the error is that `Arc&lt;Vec&lt;u8&gt;&gt;` does not implement `AsRef&lt;[u8]&gt;` to begin with. What I ended up doing is defining this struct: #[derive(Debug)] struct Wat(Arc&lt;Vec&lt;u8&gt;&gt;); impl Wat { fn new(t: Arc&lt;Vec&lt;u8&gt;&gt;) -&gt; Wat { Wat(t) } } impl AsRef&lt;[u8]&gt; for Wat { fn as_ref(&amp;self) -&gt; &amp;[u8] { self.0.as_ref().as_ref() } } So that I can pass something that is not a reference to the `write_all` function. I may be overcomplicating things however... This pattern seems very similar to the `Deref` trait where it automatically derefs the variable until it gets to the actual value. I would assume that something similar would happen with "nested" `AsRef`s but it is not the case as far as I can tell.
I see use for both Rust and Spark in critical systems. I use C/C++ for space systems (earth science instruments, not human rated), and I'm very interested in seeing Rust in that domain, and to see more Spark getting used as well. It would be a huge improvement along many axis from what i currently see being done. I could see Ada/Spark used in critical pieces of software, Rust in other areas of the software, and likely C/C++ in others, each with different use cases. Its awesome to have these options now, with different levels of assurance. 
you can always make yourself a "crate" without publishing it if it's just a personal project. Cargo lets you link to crates from your local file system or online repository. then you get the cross-project code reuse benefits without any maintenance obligations. [this chapter](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html) from the Cargo Book gives a pretty clear explanation of how :)
&gt;! **I am the `Drop` trait bound.** fn likes_drop&lt;T: Drop&gt;() {} accepts all 'liked' types from the riddle and produces a compiler error for all disliked types **How does the `Drop` bound work:** 1. Trivially droppable types (e.g. integers, floats, references) do not implement `Drop` 2. Types for which the user manually implements `Drop` with `impl Drop for T {...}` satisfy the bound 3. However if the custom `Drop` behaviour is encapsulated in a field and the compiler derives how to drop the type do not implement `Drop`. This means that there is a publicly visible distinction between types which directly implement `Drop` and types which delegate resource ownership to a holder type. This bleeds what should be an implementation detail into the public API. **Explanation for some of the types from the riddle:** `Vec` directly implements `Drop`. `String` is just a wrapper around `Vec` without a custom `Drop` implementation. `CString` is a wrapper around `Vec`, but also adds a custom drop which sets the first byte to 0. `BTreeMap` has a custom drop, while `BTreeSet&lt;T&gt;` is just a wrapper around `BTreeMap&lt;T, ()&gt;`. `HashMap` and `HashSet` both wrap a common private helper type. `std::sync::Mutex` wraps `Box` and has a custom drop implementation. `parking_lot::Mutex` is just an atomic byte and be dropped trivially and thus doesn't satisfy `Drop`. **Possible breaking change:** This also has the unexpected implication that refactoring struct Collection { } impl Drop for Collection { fn drop(&amp;mut self) { ... } } into: impl Drop for Inner { fn drop(&amp;mut self) { ... } } struct Collection { inner:Inner } is a breaking change. To avoid this you'd have to add an empty `Drop` implementation to `Collection`. Or you simply decide that nobody is silly enough to use `Drop` as trait bound and accept the theoretical breaking change. --- *Related thread on rust-internals: [Fixing the `Drop` trait bound ](https://internals.rust-lang.org/t/fixing-the-drop-trait-bound/9458)* !&lt;
C - less to learn, shows you something closer to how the machine really works\* but takes more work to get things done. Rust - steeper learning curve but more powerful when you persevere a caveat is that Rust's advantages show up more in larger teams / online collaboration , and concurrency. writing small programs for yourself, you might find C or C++ more rewarding &amp;#x200B; (\* not saying this applies to you but in extreme cases i've heard Java people think that classes are fundamental to how computers work..)
Another option is Arguman (which is FOSS) https://en.arguman.org/
I would still like to hear what you mean by that, because in my experience that hasn't been the case.
Hi, thanks for sharing this. Can you explain a bit more what a `cloud native buildpack` is? I use a this [0] buildpack to deploy one of my projects [1] to heroku. How does your buildpack compare to that? [0]: https://github.com/emk/heroku-buildpack-rust [1]: https://github.com/JoshMcguigan/license-bot
I totally get why `curl http://acme.org/bin | sudo sh` is a problem, but without sudo this is 0% different from downloading and running a binary. If anything, you could make the argument it's slightly safer because it's easy (if time consuming) to inspect a shell script than to understand what a binary you don't have the source to is doing.
so like cloudlibc?
For one – all the traits that have methods consuming `self` (instead of borrowing `&amp;self`) won’t work by default with references, as they require owned value. Sometimes implementing such traits for references or mutable references with a little different semantics makes sense. For example [`std::iter::IntoIterator`](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html) is implemented for `Vec&lt;T&gt;`, creating an iterator over values of type `T`, but also for `&amp;Vec&lt;T&gt;`, creating an iterator over `&amp;T` and not destroying the original vector, and for `&amp;mut Vec&lt;T&gt;`, creating an iterator over values of type `&amp;mut T`. Thus you can do things like let v = vec!["abc".to_string(), "def".to_string()]; for s in &amp;mut v { s += "/n"; // mutate elements } for s in &amp;v { println!("{}", s); } println!("and v still exists here: {:?}", v); Another reason might be that the trait just makes sense for the reference, not the actual value. Eg. from the documentation linked by you, [`std::fmt::Pointer`](https://doc.rust-lang.org/nightly/std/fmt/trait.Pointer.html) is a trait that lets you format all kinds of pointer-like types as a memory location, so it is implemented for a generic `&amp;T` (formats the memory address represented by the reference), and not for generic `T` (as generic `T` generally is not a pointer).
Learning the answer to your question surprised me so much that I wrote this riddle. So it was a good question. At one point I wondered how the `Drop` trait worked. So I tested `Vec&lt;i32&gt;` and `i32`, the former implements it, the latter does not. I did not consider the possibility that `Vec` and `(Vec, )` might differ. Since custom droppable types satisfying stricter bounds that trivially droppable types looked dubious to me, I researched the `Drop` trait and ran into [a post](https://internals.rust-lang.org/t/can-we-deprecate-t-drop-trait-bounds/9238) which said: &gt; Usage of `T: Drop` for specialization is dangerous and wrong. The type `(Vec&lt;i32&gt;, Vec&lt;i32&gt;)` does not impl Drop. You should specialize on Copy instead. Since I don't think I'm the only person who wouldn't expect this, I wrote this riddle to spread the joy ;)
This is really extensive, thank you!
Yes, it is very easy to make the mistake that if a destructor runs user code then it implements `Drop`.
The only thing I want is for waiting on multiple futures to be ergonomic. In C# this is a bit painful at the moment, but Rust's syntax *ought* to make it short and elegant, e.g.: let (result1,result2,result3) = await (task1, task2, task3); A lot of the proposals don't allow this type of syntax, which IMHO is a bit short sighted... 
I thought this, but somebody demonstrated a hypothetical attack where the server detected whether you were piping the file (using some info like whether curl paused to let the script execute a chunk) and sent different content based on that.
It's quite similar to a Heroku BuildPack :). The CNB BuildPack creates an OCI image (Open Container Initiative). Heroku and Cloud Foundry joined forces for this one. See [https://buildpacks.io/](https://buildpacks.io/) for more info. 
Why not having both? For that you only need the postfix one. Postfix await, opens the posibility to implement an await! macro easily, but prefix await does not allow you to implement your own postfix variant.
How is "Basic UI" (current) different from "Basic UI library" (planned)? Typo, or a modularization thing? Does "A scripting language" imply a **new** scripting language? If so, why? There are already a bunch of them, Lua is fairly well-established in gamedev, and JS&lt;-&gt;Rust bindings are already a focus of attention for WASM?
Would it be possible to convert default arguments to either an `Option&lt;T&gt;` and an if statement, or a builder type?
As always, when topics of packaging/building come up, the answer is Just. Use. Nix. It doesn't require root, it enables reproducabe builds (in many cases NixOS installs are 95% bit-for-bit reproducable), it doesn't require root to install packges, can have multiple versions installed, has sandboxing, , has isolated shell environments with custom packages etc, etc, but no one ever cares. We're doomed to reinvent a shittier wheel with Docker or something.
I can't say for sure without seeing the rest of your code, but it looks right. The contents of a closure are only calculated when you call it, so you can store it and then use it later. For questions like this, it's helpful to make a small runnable version of the code you're asking about on the [Rust Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=95c0e2ced4823cfe6c4f4788b94b7c7e).
Right, sorry, I scanned your answer incorrectly first time around.
Reads more like a wishlist than a roadmap, but good to see the developers have big ideas.
I would be so happy if it were nearly *anything* but Lua. I've developed a panicked distaste for Lua after too many off-by-one problems. And I don't know how WASM helps for non-WASM targets. Still you're right, and it's a good question. A *new* scripting language is probably not a good idea. Bindings to a more established language would probably be much better.
From what I have seen of their talks it sounds like they are planning a language agnostic driver with native FFI interfaces to rust. Which should allow a lot (LuaJIT for one). Though I’m just following it so I may be wrong. 
Yeah, Unity/Godot-level 3D sounds... *ambitious* within the year.
I the problem first is its http. Then the rest.
Thanks! Looking forward to it.
Not really. There are some clones of Rack if I recall correctly, but Rack and UWSGI are solving problem of integrating web framework with webserver, which is no an issue in Rust (yet). Because of how rust different from Python and Ruby such thing is nearly impossible to build effectively. Python and Ruby have numerous web servers each has its own pros and cons and they all work together just fine because of one big assumption - GIL. Reason there are multiple servers are because of different ways to enable parallelism and concurrency one way or another.
Whoa this would be super useful.
What’s wrong with await Task.WhenAll?
Sounds great. The more serious projects like this one that I see, the more intrigued I am to learn Rust. I feels like the Rust ecosystem is growing pretty fast.
so, what about my users on Mac and Windows? or any normal Linux installation that doesn't include Nix? Nix is not the solution here, and it is especially not "as always" the solution.
Need help writing function signature. I'm using `warp` library for creating HTTP server. This code won't compile: extern crate warp; use std::env; use warp::Server; pub fn init&lt;S&gt;(routes: S) -&gt; Server&lt;S&gt; { let port = env::var("PORT").unwrap(); let addr = format!("0.0.0.0:{}", port).parse::&lt;std::net::SocketAddrV4&gt;().unwrap(); warp::serve(routes).run(addr) } because it needs the contraints for `S`. Looking at the [docs](https://docs.rs/warp/0.1.13/warp/fn.serve.html), it seems that I need `IntoWarpService` constraint. However, this trait is private. So, how to make this code compile?
Nix works fine on any Linux distro, and Macs, and they're evaluating Windows. Don't act like everything has to be done separately for Windows anyway. &gt;Nix is not the solution here, and it is especially not "as always" the solution. /me looks at his continuous integration that is 1/10th the complexity of this. Okay, if you say so.
Thanks for the link. What environment do the build and detect scripts run in? The reason I ask is that the examples are given in bash, but it looks like you write those scripts in go. Would it be possible to write the build and detect scripts in Rust? Also, the docs say you need the build and detect scripts in a `bin` directory, but your folder structure is different than that. Did you override the defaults somehow? 
Well, `as await` would. Still not gonna happen.
Thanks for trying it out man. Very cool. Very helpful. &amp;#x200B; There are some scripts in the scripts directory - all in bash for now - that are used to run unit and integration tests. As well as a script to package up the buildpack. The buildpack itself is all in Go. We are in the process of rewriting all the bash scripts in Go as well (see [https://github.com/cloudfoundry/cnb-tools](https://github.com/cloudfoundry/cnb-tools)). But it's still work in progress. It will most likely be done somewhere next week. &amp;#x200B; If you follow the steps in the readme file you should be able to create a OCI image out of your source code. Really curious to see how your experience is with that. Before you do so you will need to grab some stack images from docker as well as the builder (all in the readme). &amp;#x200B; Let me know how that goes. And if you have any questions. Again, thanks for looking at it! &amp;#x200B; The "bin" directory is created when you run the install\_tools script. After that you can use pack to package your buildpack (.bin/pack ...args) 
I updated the readme file just now and mentioned that the ".bin" directory should be used to run pack. Thanks!
As far as scripting goes, are there any well-established options besides Lua and JS? Neither seems optimal for game dev, though they are both used for that. I'm aware that Piston uses a new language, Dyon, for its scripting. The problem of game scripting seems far from solved, so I wouldn't be disappointed if Amethyst took another stab at it. 
Interesting point, but ultimately still the same thing. You're just taking away the "if anything, slightly safer" part. Now it's exactly the same as just downloading and running the binary.
The Piston project has a scripting language called Dyon. [https://github.com/PistonDevelopers/dyon](https://github.com/PistonDevelopers/dyon)
WhenAll would need to allocate a Vec&lt;Response&gt;. If it were built into the compiler it wouldn’t need to. Instead it could assign them to as many variables as needed. It should be possible through a WhenAll! macro that can return tuples the size of the macros arguments.
I think it's more like seccomp-bpf, but instead of the programs applying the restrictions to themselves, you apply them externally.
What's with the "Windows MacOS and Linux compatibility"? It already has compatibility for them so why's it on the road map 
Yeah IMO using `ptrace` is a weaker security mechanism than seccomp or pledge. If for any reason the `syswall` process were to exit, IIRC it would cease to gate the system calls.
You can already do this, but it’s always implicit. Is the explicitness alone really worth a whole macro?
Ah, I was not aware that it could be done implicitly Can you override the implicit with an explicit definition during implementation?
Thanks this is almost certainly the best way to go about it!
&gt; Take a look at the html of a site I just wrote with inferno There is no html, only an empty black screen.
Async/await didn't come from Javascript, though it does nicely solve its particular problems. The most established use of async/await is instead most likely C#- where it's used for GUI and network programming. It's much more lightweight than a thread pool can ever be. It's also not an *alternative* to `tokio` or `libuv`- it's purely a syntax to be used *with* `tokio` or whatever other runtime you want (including a minimal hand-written one specifically for your embedded application...). Really, it's not even new to Rust. Originally Rust supported lightweight async code via Go-style green threads, and only removed it because it couldn't be made to fit into the language in time to be stabilized with 1.0- async/await is the culmination of that original promise. In the end the reason it's part of the language is that people are *already* doing async stuff (execution model-wise), but either the syntax or performance are suboptimal. Async/await fixes that.
&gt; It's much more lightweight than a thread pool can ever be. I seriously doubt that. If you could provide a source on that I'd appreciate it. &gt; it's purely a syntax to be used with tokio or whatever other runtime you want But `tokio` works fine without it? I don't follow how it's "just" a syntax. &gt; syntax or performance are suboptimal. Async/await fixes that. But you just said it was a syntax to use with whatever runtime you decide to use - how does that solve a performance problem?
Maybe my question and the idea are not clear. I have a case now, build a web server via iron, and the user can enter the url to search the database (use Cassandra). For example, if the url entered by the user is: ‘ip address/*/table_name/primary_key/epoch/’, the result of this query will display on the web page. So, in order for the iron to continue to run and mount to the server, the idea of ​​uwsgi lib will appear. Is there a better way? Or the direction of the question I asked at the beginning is wrong? Of course, I also need to use nginx as a reverse proxy.
Nothing, technically, it's just a bit verbose for my taste. IMHO, there's only "two type" of async code, if you oversimplify things: Sequential async and parallel async. The C# await syntax makes a sequence of async tasks trivial to write, you can just let the compiler turn it into a state machine for you. I love this feature, and wish more languages inherited it. The other scenario is parallel async, where you kick off a bunch of tasks and want to sleep while they execute in the background in any order (possibly concurrently) and then continue with their outputs. The outputs may be of different, incompatible types, so stuffing things into an array is unwieldy, as you'd have to cast to Object, which is a code smell. So for example, the pseudocode is: var t1 = Foo1(); var t2 = Foo2(); var t3 = Foo3(); await Task.WhenAll( t1, t2, t3 ); var r1 = t1.Result; var r2 = t2.Result; var r3 = t3.Result; This is... fine, but much more verbose than my preferred "one liner" syntax. It also allocates a temporary array for the WhenAll "params[]" input and allocates a new Task for the output. Minimum two heap allocations, one extra await on top of the original three required, and I don't believe it can handle non-Task awaitables like the stack-allocated ones used in .NET Core. There is a reasonably terse syntax available, but I think this has some inefficiencies as well related to waking up the thread for each awaitable even though no useful computation can continue. I'm not an expert, but I think this is required because with this style the exceptions must be thrown in the order that the awaits are specified in: var t1 = Foo1(); var t2 = Foo2(); var t3 = Foo3(); var ( r1, r2, r3 ) = ( await t1, await t2, await t3 ); What most programmers want is this: var t1 = Foo1(); var t2 = Foo2(); var t3 = Foo3(); var ( r1, r2, r3 ) = await t1, t2, t3; This would mean: only wake up once and don't allocate new Tasks. This would work with stack-allocated awaitables as well, and is strongly typed. As long as Rust has something similar, my syntax needs are met! 8) 
Async/Await is orthogonal to threads. Without async/away you can run threads in parallel, but they may block when they could still be doing useful work. Async/Await is simply a way to hook into a notification system like epoll so we can run other pieces of useful work on a given thread if that thread has nothing else to do without context switching, which is expensive. Javascript is heavy on operations that can potentially block and do IO without a whole lot of processing, so async is a good model for it. As for why people specifically need async/await to be standardized, it's because we don't want to go back and rewrite everything. Having a shared implementation of Futures simply means that the backend can be plugable, so we can use backends designed for heavier IO or CPU, etc.
&gt; If you could provide a source on that I'd appreciate it. This is well-known, it's why people use async code (even without async/await) to begin with. A thread requires a user space stack and a kernel stack and a large data structure in the kernel, and has to go through the kernel scheduler. A task requires precisely the space used for local variables live across await points, and is scheduled by the thread loop. &gt; But tokio works fine without it? I don't follow how it's "just" a syntax. Indeed, and it works fine without tokio. An async function is compiled down to a small object that implements `Future`, you can use it on whichever runtime you like as a substitute for all the combinator gook we use today. &gt; how does that solve a performance problem? It solves a performance problem relative to threads- you keep the built-in control flow structures, and gain the performance of async code.
[This GitHub issue](https://github.com/rust-lang/book/issues/850) appears to talk a lot about this, for anyone else who may find this thread one day. It contains an example like the following: struct Foo; impl Foo { fn new() -&gt; Foo { Foo } fn is_bar(&amp;self) -&gt; bool { false } } impl Drop for Foo { fn drop(&amp;mut self) { println!("1. Drop"); } } fn main() { let x = Foo::new().is_bar(); match x { true =&gt; {} false =&gt; { println!("2. Not bar"); } } } If you inline `x` in `main()` you will see that the order of the printed messages changes. This is the simplest recreation of what I was asking about I have seen. I haven't read it yet, but it looks like [the reference](https://doc.rust-lang.org/stable/reference/expressions.html#temporary-lifetimes) has more to say about this as well.
Which GCP service(s) do you want to use Rust with? This is pretty vague as it is.
Question: Is there a version of async/await where I could avoid having to maintain an async and non async version of my libraries? As far as I understand it asyncio in Python for example, has basically fractured the ecosystem into things that are async compatible and normal python.
&gt; This is well-known, it's why people use async code (even without async/await) to begin with. It's only true until you need to do more work that one thread can perform. Then your performance degrades. It's very useful in some situations, but it is not an end all solution. &gt; A task requires precisely the space used for local variables live across await points, and is scheduled by the thread loop. A task requires user-space memory to track jobs that haven't been executed as well. Just because the scheduler and support structures don't live in the kernel doesn't mean they don't take up memory and cpu cycles. &gt; you can use it on whichever runtime you like as a substitute for all the combinator gook we use today. So `async/await` isn't a runtime itself? It's basically a framework for implementing runtimes?
&gt; As for why people specifically need async/await to be standardized, it's because we don't want to go back and rewrite everything. Having a shared implementation of Futures simply means that the backend can be pluggable, so we can use backends designed for heavier IO or CPU, etc. I think this is what I was misunderstanding - I was under the impression that the goal was to natively *supply* a runtime, not add in hooks for *supporting* runtimes. Is this correct?
Yes, all your getting from the stl is sugar for creating Futures. You don't get an event loop to actually run those futures on. That's what mio/tokio are for. You could also write your own with libevent or whatever you want to do to fulfill the future. You could provide something that isn't really even asyc if you wanted to. The choice is yours.
Ohhhhh, okay, thank you for clearing that up. So I really don't have any issues with `async/await` :)
&gt; A task requires user-space memory to track jobs that haven't been executed as well. Yes, but much less than a full general-purpose thread. &gt; So async/await isn't a runtime itself? That's correct, it's a small interface that runtimes can use- and basically the same one they use today already anyway.
Gotcha. Thank you very much for helping me understand!
&gt; it’s only true until you need to do more work than one thread can perform What tokio does is schedule M tasks onto N threads. So you’re still using multiple physical cores, and getting most of the speed up of that. &gt; ... just because the scheduler and support structures don’t live in the kernel doesn’t mean they don’t take up memory and CPU cycles The scheduler itself still has overhead, of course. The difference is that being in the user space, you don’t need to do a cpu context switch before and after running scheduler code. That’s the main time save in running a scheduler as part of your application. &gt; ...isn’t a runtime itself Exactly. 
Gluon is awesome, https://github.com/gluon-lang/gluon/ I think that the scripting API should be language-agnostic though.
Async/Await makes sense for rust. I come from C++, and we do the same thing for high performance networking. The issue with doing something like Go is that you have very limited introspection into the runtime. Async/Await is basically giving you raw building blocks, or really just interfaces, for you to implement it however you want. And because it's completely separate from threading, it just means that you have basically all the flexibility in the world to build whatever you want. But there is a real downside. Async/await is harder to reason about. Go and Erlang basically let you right sequential code and it figures out the async stuff for you. But in Rust, we're going to have to deal with think in terms of async. You've got a head start, since you've already done JS. You'll also have to decide, when you want to write a library, if the library will be async or not. If the functions don't return Futures, they can't be run on the event loop, and won't work for people using async.
&gt; If the functions don't return Futures, they can't be run on the event loop, and won't work for people using async. That's a good point. It inevitably will (I think) lead to an undesirable disconnect between async and non-async rust libraries, but hopefully utility libraries can be written in ways that can be used in both styles. JS has `util.promisify` and `Promise.then` to switch between callback and await style programming, but it does still lead to a disconnect. 
It sounds to me like what you really need for this problem is a [real-time operating system](https://en.wikipedia.org/wiki/Real-time_operating_system) that can provide better support for precise scheduling. Regular operating systems can pause a process at any time and won't try very hard to wake up a sleeping process at exactly the time it asked for.
It would be cool if you would compare your approach with existing crates like `specs` and other ECS libs.
Why not wasm? Integrate wasmi/wasmer and leave the user to pick the language. Sounds ideal to me.
First thing what came into my mind: "tuples". And Vec&lt;Box&lt;Struct&gt;&gt;&gt;.
Browser? 
In JavaScript, `let [r1, r2, r3] = await Promise.all([t1, t2, t3]);`, which isn’t too bad, and avoids magic like treating arrays specially (given that awaiting a non-promise is fine in JavaScript, simply producing the value unaltered). Rust could much more reasonably make tuples of awaitables awaitable, especially if it finally added tuple flattening for recursive impls. Then you could reasonably just do `let (r1, r2, r3) = await (foo1(), foo2(), foo3());` (for whatever await syntax) and it’d be nice.
I like the idea of being able to await on non-futures, it might be useful in "fully generic" code that can treat everything the same way. Certainly could be useful in Rust where the () type is used a lot to remove unused struct members.
This isn't an ECS library, though it could perhaps be used as a building block for one. (Like maybe a `specs` `Storage`?) The main direct comparison for `soak` is things like [soa](https://crates.io/crates/soa) or [soa_derive](https://crates.io/crates/soa_derive). If I publish an ECS crate though I'll be sure to compare it. :)
Developing and testing against one platform is way easier than 3, so it’s likely tempting to ditch the cross platform-ness and make progress on other things. Making it a goal to maintain the compatibility is a very deliberate decision. 
I personally think they should pick 1 language, and say that's the official scripting language. Then look into a language agnostic driver later down the line. The problem with modularity is it often leads to a cluster fuck of an API, pointless configuration, and everything is half built. It often harms the majority of users, whilst only a minority really appreciate it.
I guess you meant to divide nanos here? fn to_seconds(d: Duration) -&gt; f64 { d.subsec_nanos() as f64 * 1e-9 + d.as_secs() as f64 }
Try looking at this: [https://www.rust-class.org/](https://www.rust-class.org/) This is an undergrad OS class that was taught entirely in Rust. Keep in mind that it was an early version of the language, but it's interesting nonetheless!
Nah, supporting awaiting on non-futures would be a bad design for a language like Rust. In the *very* rare cases where you might want it, it should be straightforward to implement in a library, though not being familiar enough with the code involved I haven’t considered whether or not that would be necessarily less efficient.
This isn't that long, but nonetheless, TL;DR scrap the helper method, in my opinion. I'm not very experienced with `warp` (or Rust tbh), but assuming you are creating a binary, the following would be my recommendation. It comes from experience with other HTTP libraries. Writing helper functions like this don't always work the way we want them to. From what I see, I'm assuming you are going to call this inside a `main` method and grab the `Server`. The thing is, top level functions like `warp::serve` (from my limited experience) are intended to be called from the `main` method directly. You're best bet would be to go with something like this use std::{ env::var, net::{Ipv4Addr, SocketAddrV4}, }; pub fn addr() -&gt; SocketAddrV4 { SocketAddrV4::new( Ipv4Addr::UNSPECIFIED, var("PORT").parse::&lt;u16&gt;().expect("Invalid port in $PORT"), ) } And then, in your `main` module use my_module::addr; fn main() { // stuff... let routes = // get the routes from wherever... let server = warp::serve(routes); server.run(addr()) // other stuff } I get the point of abstracting this bit out but it's just not worth all of the generics drama. There is a reason that trait is private. It's because the `serve` method is supposed to be a helper method. (In my opinion, this is not good design choice on the library's part, but I haven't done any better so I can't judge.) I know this doesn't exactly help, but it's all I can do. Also, side note, your method signature says you are returning a `Server&lt;S&gt;` but the method `run` consumes the `Server` created by the `serve` method. Your signature should either return `()` or not call `run`. This actually helps my case for a helper `add` method, if you think about it. Besides, having this `init` method doesn't really do much. The implementation you've written is only 3 lines of code (2 if you use `SocketAddrV4` a bit more idiomatically) Another small side note, assuming you're using Rust 2018 edition, you don't need the `extern crate warp;` (apologies if that was just included for this example) Some links: * [`Server::run`](https://docs.rs/warp/0.1.13/warp/struct.Server.html#method.run) * [`warp::serve`](https://docs.rs/warp/0.1.13/warp/fn.serve.html) * [Source code for](https://docs.rs/warp/0.1.13/src/warp/server.rs.html#334-337) `IntoWarpService`
Is there any blog post or webpage that has up-to-date steps for cross-compiling from MacOS to Windows? If not, does anyone know where I can find the standard library required for cross-compiling to `x86_64-pc-windows-msvc`? I'm compiling a simple binary, that has not odd dependencies. Here's my dependencies [dependencies] serde = { version = "1.0", features = ["derive"] } structopt = "0.2" serde_yaml = "0.8" serde_json = "1.0" I've looked at [this post](https://www.chriskrycho.com/2016/using-rust-for-scripting.html) but it's not helping me much. Any help is appreciated! Thanks!
Great point, though I don't know how easily it can be addressed. &gt; Would it be worth it embedded allocators with run-time polymorphism instead? This seems a bit problematic, since I think that would add some run time overhead even to the majority of code that doesn't use custom allocators. Not a huge amount of overhead, but this is generally avoided. I suppose what would probably be ideal is compile-time polymorphism, but in a way that the type parameter doesn't have to be explicitly handled by generic functions. But I don't think there's a way to do that. This is not an uncommon case of polymorphism. A type `T` is used internally, but the API the type provides is the same for any `T`. Do any other languages have type systems that provide a way to not need to explicitly be generic of type parameters of this kind?
Power management can cause strange effects like this. Putting the processor into a deeper sleep means it takes longer to wake up. This might even mean more efficient code and otherwise idle systems actually perform worse in terms of waking up at the expected time. iirc, Linux has a sysctl specifically controlling how closely it has to follow the application's requested wake-up times; it chooses different sleep levels accordingly. It also may batch several wake ups to allow longer sleeps at the CPU level. Unfortunately, I can't seem to find the name of this sysctl or even a reference right now. I'm on my phone, which doesn't help... 
Thanks for your reply. The example is just a small part of bigger. I'm trying to structure my code so that each functionality is on it's own file, and one file contains everything across layer (http definition, business logic, db access). Alright, so it means the HTTP part needs to be in it's own file then.
I don't have any formal CS education or training, but rust has definitely taught me a great deal about memory ownership. Things that seem daunting to do in a low level language (particularly C/C++) actually aren't so bad in rust, so not only has the language itself been a good teaching tool for memory semantics, it's also allowed me to play with larger concepts that would have been much more taxing to do in C/C++. Instead of worrying about how much arcane magic it takes to make my program run correctly, I get to spend my time thinking about how bad my algorithm is and how crazy it is that it actually seems to work.
This isn't the sysctl I was thinking of, but would allow you to eliminate power management as a cause: for i in /sys/devices/system/cpu/cpu*/cpuidle/state[1-9]/disable; do echo 1 &gt; $i; done I wouldn't recommend running that way permanently but it should be a useful diagnostic step.
I see your point, but even if you do structure your code like this, you still need to glue it together. If you will allow a slightly corny analogy, things stick together better when you use your own glue between them rather than using self-adhesive components. Use the main function as your glues, rather than trying to completely compartmentalize your code. This doesn’t mean you can’t abstract the http handling, business logic, and database functionality separately, but try to expose a sort of library interface to your abstractions that your main method uses rather than having the abstractions run on their own like this. In essence, the main method should be the one visibly doing everything, but your abstractions should be tools presented to the main method so that it can accomplish what it wants to in few lines of code, through function calls that return values which are manipulated by other things in the main method (possibly other functions). Rust’s module system is very nice, so make sure you take advantage of it. I get the drive to structure your code like you are, just make sure you keep it Rusty.
I believe the code is from the rust book section on closures.
Not OP, but I've been trying to find examples of how to use datastore and cloud storage. The repo OP linked to doesn't have any examples. Can't seem to find ant crates on crates.io either.
I feel like every programming language should be taken seriously as a teaching language. Newer programming languages tend to focus their attention on a particular set of principles. Some like types and algebraic data like Haskell. Clojure focuses on immutability and convenient transformation of data. Rust has lifetimes. I felt like university was a good opportunity to learn about the abstract problem domain. My university classes focused on describing graph theory problems and establishing the historical concepts (Turing Machines and Lambda Calculus). My Java class was the preliminary CS class, so pretty basic.
Thanks OP, I was curious myself. Thank you to everyone who participated in the constructive discussion - I learned a lot!
This looks great! I personally always wanted to come up with an API which lets you write things like this (pseudo-code) let entities = getEntitiesWith&lt;Position, Velocity&gt;(); for entity in entities entity.position += entity.velocity But with zero runtime overhead, so that the code above would be translated and purely procedural SoA access with no allocations (though an operator for `entities` is probably still needed). I'm not sure it's possible in Rust at the moment, but I hope that eventually we will be able to create an API that feels natural to use.
Since SOAK is largely about performance, it would be great to see a benchmark comparison against array of structs with SIMD. Varying the amount of used vs unused object data in the cache stream would make for a nice validation and help others decide when to SOAK.
Cloud SQL, Cloud DataStore, Cloud Storage
I don't know if you've seen this, but it appears that a C backend already exists: https://github.com/JuliaComputing/llvm-cbe
This should not be solved by the compiler tbh. (task1, task2, task2) is just a tuple of 3 futures so what you want is having the Future trait implemented for tuples. Then we can use any await implementation for tuples.
yep. I study now that section
In order to clarify things what I want is client libraries to access GCP services like datastore. Like they currently have client libraries for Node.js, PHP and etc.
Teaching a Rust course right now! https://m.youtube.com/watch?v=Oy_VYovfWyo
In futures 0.3 right now, there's a join!() macro that gives you something similar. let (res1, res2, res3) = join!(fut1, fut2, fut3);
I believe the answer is no. Async "poisons" the flow of a program, as made famous by [What Color is Your Function?](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)
That is a really nice explanation of why this is valuable. 👍
Rust has too many symbols to be a first language. Many would be turned off by simply how confusing it *looks*.
I agree, but if the script is doing something nasty, that would be fairly obvious to see. Obviously even if I didn't see anything I would probably miss a lot because you're right. &amp;#x200B; But again to pinpoint a script that does a pbpaste (dump your clipboard), or cat \~/.aws/credentials and POST it back to a server is easy, which is the level of sophistication I would expect to see. I would expect people to write simple evil scripts that act on masses rather than very clever binaries that act on a specialized group of people. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Have you seen jon blows way of doing this in Jai? It's very interesting and flexible.
I agree! I tried to learn rust 2 or 3 times over the past year before I finally stuck it out. I meant that at some point during the 3/4 years of a CS course it should be taught. I remember Java being horribly off-putting in my first year when we had been only just been taught exclusively python.
I don't really intend this tool to replace tried and tested systems such as seccomp and OpenBSD pledge, rather I wanted to create an end-user tool to allow a user to understand what software is actually doing. In the process, they have control as to what the software is allowed to do, but certainly if this is a concern I would recommend a more well-known security-focused system. There is a ptrace option which syswall uses which kills the child process if syswall also dies, but I have yet to test this to any great extent. Thanks for your comments!
doesn't SOA vs AOS really just depend on the problem? doing a benchmark like this seems misguided at best, dishonest at worst. if anything the benchmark should be between this lib and manual SOA; performance and lines-of-code considered.
Déjà vu? https://new.reddit.com/r/rust/comments/aq0wb6/memory_management_rust/
The line between dishonest and indicative benchmarks is blurry, yes. My hope is that % of object data (bytes) used in a tight SIMD benchmark would provide some guidance on what to expect regarding the impact on caching. Other parameters might be useful and suggested by this community.
I'm teaching Rust as a combined grad/undergrad elective for the third time this Spring and the fourth time this Summer (if all goes as planned). Using Rust as an introductory language would be pretty challenging at this point. The language is still changing fast, so materials (and instructors!) get out of date easily. For the students without some prior programming experience, fighting the compiler is pretty discouraging: we'd probably lose the bottom 25% of the class. This would be especially unfortunate for an intro class here in the US, because the underrepresented-group students we want to retain generally come in with the least background. On the upside: *Programming Rust* is a fantastic course textbook; and the students who do/would get through understand a lot of important programming ideas really well as a consequence; not having to worry about speed and space too much when implementing is nice for concentrating on just solving the problem. Our eventual plan is to maybe start teaching the systems programming and operating systems courses in Rust. We're kind of back-burnering it until we feel like we can bring our students up to speed quickly.
For a first language, I have always thought that Haskell would be a good choice. I have nothing to back this up, but I'm quite positive that what make Haskell hard to grasp are the years of imperative and OO that most developpers have: I honestly think that someone who never programmed before would find Haskell very easy. So yeah, this wouldn't teach imperative nor OO programming, this wouldn't teach what's going on inside the computer, but that would definitely teach how to solve a problem programmatically and would also be a nice introduction to type systems. 
`"3".to_string().parse::&lt;u32&gt;().unwrap()` Yeah, I can reckon that 
`"3".to_string().parse::&lt;u32&gt;().unwrap(); // wait, "3" isn't a string ? Also, what::&lt;the heck ?&gt;()` `"3".parse::&lt;u32&gt;().unwrap(); // Yes it is, well, kind of. But why can I call to_string() on it then ?` Yeah, I kind of agree. The existence of `&amp;str` and `String` will throw off most students. 
My systems programming course at my university program required the use of C with the gcc flags `-ansi -pedantic -Wall -Werror`. This is as close as you can get to Rust in C, and I agree that using Rust instead would be a great choice (note that I attended more than a decade before Rust even existed, I don’t know what they’re doing now). This course was really annoying to code for, but it opened my eyes to clean programming. I was much better at error handling afterwards. It’s probably a big influence why I like Rust so much now.
Yes, Rust shouldn’t be your first language, it’s way too complicated for that. I say that here frequently, but it always gets downvoted for some reason. I think that many here simply have no idea how it is to start learning programming (I used to teach that, so I have experienced it with my students).
Yeah, you're probably right. Something like await_or_passthrough() is probably all that's required, defined such that it awaits futures and returns everything else as-is. I'm not entirely sure if Rust allows that kind of function definition... might need a macro or something.
Are Rust futures auto-starting, or do they need to be explicitly run? Because auto-starting futures would make this *really* terse: let (res1, res2, res3) = join!(fn1(), fn2(), fn3());
&gt; It's only true until you need to do more work that one thread can perform You can have a multi-thread executor. I think you are too stuck with how async works in js, you should just forget all about it and have a look at how it actually works in rust/tokio. &gt; A task requires user-space memory to track jobs that haven't been executed as well. Just because the scheduler and support structures don't live in the kernel doesn't mean they don't take up memory and cpu cycles. An executor isn't doing full preemptive scheduling like a *nix kernel, also entering the kernel isn't free, at the very best it involves an ooo machine reset, and because Meltdown it's a almost a full context switch with TLB flush which is very expensive (okay, the tlb flush itself is cheap, the code running after it will be very slow for a while though). Also when you start up a new thread or send work to a threadpool that likely involves synchronization between cores, another costly operation. So there is definitely an overhead in using threads, how this affects your program depends on how big a unit of work is, if it takes seconds you won't notice it at all, for short operations it could mean an order of magnitude speed improvement.
We are trying to make a generic interface for programming languages. We do not want to write our own language, but we want to integrate a couple of famous ones (Lua, Rust as a scripting language, JavaScript maybe and one visual programming language, at least), and let the community integrate others as 3rd party if they need it. If you are interested in the technology behind it, you can check out [the scripting RFC](https://github.com/amethyst/rfcs/pull/1) or ask on [our Discord server](https://discord.gg/amethyst)!
A (late) 2018 retrospective blog post about [lyon](https://docs.rs/lyon), a collection of crates to help with rendering vector graphics on the GPU using tessellation. If you haven't heard of this project before, my [blog post from about a year ago](https://nical.github.io/posts/lyon-intro.html) or the [Rustfest Paris talk](https://app.media.ccc.de/v/rustfest18-7-vector_graphics_rendering_on_the_gpu_in_rust_with_lyon) explain what it is about.
I took this class! AMA :P
But the problem with picking one first is that you get locked into a language, and years down the line you end up writing your own custom compiler for that language because requirements have changed. I'm sure we can make a quality integration on top of an abstract foundation, in the spirit of gfx-hal.
Is this the same problem as column store vs row store in the database design?
This is my entire point. 99.9% of users are not looking for a custom Lua compiler. They are looking for a popular scripting language. By setting out to solve the custom compiler problem then you are jumping the gun. Don't make a custom compiler. Just use Lua. If people want better speed then they can make extensions in Rust that are called from Lua. They can cross that custom compiler bridge themselves.
The trouble is that Rust makes it hard to implement some data structures that are very common in teaching, such as [linked list](https://cglab.ca/~abeinges/blah/too-many-lists/book/) or [tree](https://rust-leipzig.github.io/architecture/2016/12/20/idiomatic-trees-in-rust/), not to mention graphs. And then there are concepts like iterators that are trivially implemented in garbage-collected languages (Python, Java) or unchecked ones (C++), but made very hard in Rust by the borrow checker. You *could* use Rust to teach the basics, but you'd have to carefully think through how to present algorithms and data structures, e.g. by introducing `Rc` and arena-crates early enough, and by avoiding the known pitfalls. These are all solvable problems - after all, C++ has its own share of issues, and universities teach it just fine - but you'd need a generation of TAs who are committed to Rust and understand it in some depth.
I guess in retrospect every language would've suited you better.I think it's only because you already made the hop into programming. getting people hooked is especially hard. In my experience the first time anyone's really enjoying programming is, when the first own projects starts. IMO with a simpler language, like java / python you'll reach that goal faster. Finally getting people to be better programmers is and will be person driven, as you strive to be a better programmer. The university is teaching you the basics and how you can learn on your own to get a starting point for your journey through rust. Sure. you could increase the difficulty level of programming, but at least at my university people are struggling. hard. we already lost over 50 percent in 2 semesters, and this one just ended and is the biggest hurdle.
Such posts are usually censored here
This is the LLVM backend that OP was talking about. It used to be in LLVM, if I recall correctly, then was removed as nobody was willing to maintain it. It's made a number of appearances over the years in personal repositories, but was never merged back into LLVM proper. Now, Julia folks have done some great work, so the backend being maintained by them is a good sign, however it's not clear if it's fully functional, or limited to what is necessary for Julia programs (or even only a subset of them). And there's also the problem that there's a single branch, so it's not clear which version of LLVM it targets, which causes issues for anyone wanting to use it downstream, or wanting to release it in an "integrated" fashion. Do you have any idea what Julia is about with the project? Do they plan to continue to maintain in off-tree or instead to merge it within LLVM?
Why does Clippy complain that the function is not defined unsafe? Do I need to mark the entire function as unsafe is I have only a tiny part of unsafe code in it? #[no_mangle] pub extern "C" fn find_segments(iarr: *const f64, length: usize, maxx: f64, maxy: f64) -&gt; CPoint { let arr = ndarray::arr1(unsafe { std::slice::from_raw_parts(iarr, 4 * length) }) .into_shape((length, 2, 2)) .unwrap(); Also there are cases where it complains f32 == comparison with f64 when the both structs where the values come from are clearly f64. Is there something subtle I'm missing?
It would be cool if you would provide comparison of your approach with existing crates like [soa](https://crates.io/crates/soa) or [soa_derive](https://crates.io/crates/soa_derive) 
Discrimination on the various qualities that the CoC forbids can often be 'disguised' as a political opinion. Surely protecting political opinion would be contradictory in that case? Perhaps you could give an example of something that has happened in the Rust community where protection of political leanings would have created a better outcome?
Unlike race and gender, political leanings are a choice, and so are usually open for debate.
Because political leaning is not an indelible characteristic and likely should not enjoy protection on par with an indelible characteristic. Arguably your political leaning is more akin to a communicable disease that you happen to be infected with -- but through dint of minor amount of effort could cure yourself of -- and the code of conduct really should protect others from encountering it _well_ before it protects your right to continue trying to harm them with it.
I would be very much in favor of this. However, as many of the current or former Rust core team members are left leaning to left extreme, I don't think this will find much support. Likewise, the current CoC does have political undertones, and in most previous discussion I read this particular color of politicism has been defended by most commentors. 
I think that someone's political leanings should be a subject being discussed in the domain which concerns itself with professionalism. However people should not be afraid to state their mind when being asked for honest opinion. Or that people should not be persecuted for having "wrong ideas" as defined, usually by another set of ideas. I do believe that it's not that difficult to differentiate holding beliefs and going out of your way to mistreat people. I'm not sure we should wait until such thing happens. We already seen it happen in different areas as I've pointed out few examples.
This is such a tiring and stupid discussion. All the CoC is trying to say is "don't be a dick", so yes, if you get harassed because you are XYZ on the political spectrum, that's probably a violation of the CoC. But there are plenty of ideologies that are in conflict with the CoC, what if a Nazi says his harassment of other races is protected by the CoC? Intolerance cannot be tolerated, you have to draw the line somewhere.
Same applies to religion as it's also set of beliefs in values.
Same applies to religion or choice of dress as it's also set of beliefs in values. If ones cares to reason honestly and maintain logical consistency when religion part becomes also suspect to such view. That's why, in my estimation, constitutions of numerous countries mentions both.
I think it has a shot if you manage to explore the right things first (whatever that means hehehe). Also, the compiler is fantastic at hinting! I mean, students basically have a duty to make mistakes. It will happen, a lot. With rust or without rust. I think the frustration would be worst if the mistake resulted in a segfault than in a mostly-helpful compilation error. But yeah, it does have more concepts, is harder to grasp or have a higher overhead..
I don't believe that anything justifies harassment.
You can have that opinion, but many would disagree. See also the [paradox of tolerance](https://en.m.wikipedia.org/wiki/Paradox_of_tolerance).
Things that are at least as much of a choice as political orientation, and are explicitly protected by the current CoC, in order of occurrence: - gender expression - personal appearance - body size - religion - nationality If we want rules saying people can't be discriminated because of these, why not add political orientation to the list. Each item added would just strengthen everyone's protection. Also, the point is not whether these or political leanings are "open for debate". The discussion is about how to focus on Rust contributions, and how we can make sure everyone gets their safe space to contribute without fear for being offended on one of these. Whether someone is right or left extreme shouldn't matter for the scope of contribution, as long as that person doesn't interfere with someone else's ability to contribute. 
I'm well aware of it. However same paradox of tolerence is used for intolerance. That's why it's a paradox. You've marely chosen that your set of beliefs doesn't violate it. However, there is no evidence that that's actually true.
Exactly. We don't need to have a political forum. It's not the point. What I'm concerned about that there will be a competent person who someone will find out voted for certain president in election and that person will be harassed because of it. Given that political leanings are not being protected this will go unnoticed or not morally considered.
Not precisely the same; if you -- and anywhere I use the term "you" from here I'm talking about a hypothetical perspective -- are a Jew, for instance, you were born into the religion absent your own volition... yes, you then have to affirmatively choose the faith from the perspective of others _within_ the faith, but that doesn't affect the perspective of those _without_ the faith. Specifically whether or not you had had a Bar or Bat Mitzvah was not used as a filter at the railhead at Auschwitz. Thus like ethnicity or nationality it "adheres" to you inherently and indelibly and again absent your volition; that's why it warrants carving out as a specific item that shouldn't be discriminated against. The same is not true of political leanings. Your political opinions are something you have adopted of your own volition... you _may_ have adopted them because you received them from your parents and/or tribal progenitors, but the moment you attain majority you may freely choose to relinquish them like the childish things they are and be fully welcomed into the rest of the community. If opinions that you _choose_ warrant the condemnation of the wider community than that's the natural and necessary price of those opinions; you should be ready to pay that price, and asking for protection for them merely reveals a lack of courage in conviction. This is not true if you can demonstrate a genetic component to a particular political leaning; if it turns out libertarianism is an _inherited_ character flaw and not an adopted one, for instance, then perhaps there's room to move on this point.
&gt;Your political opinions are something you have adopted of your own volition... you *may* have adopted them because you received them from your parents and/or tribal progenitors, This is actually not entirely correct. We know that genetic predetermination informs our political leanings too. There are a lot of conclusive studies on this being done which ties directly to inherited big 5 personality traits.
Python/Ruby?
I personally think I would have had a lot of trouble with rust if I didn't already have an understanding of stack/heap and an idea of what memory management is and why it sucks. Without knowing these things, I don't know if I'd have understood how valuable the limitations of the language are, and it might have been a very different experience as a result. From that perspective, I don't think rust would make a good first language. But it could make a great second language if the first deals with the above concepts.
Rust has a bit of a learning curve in terms of its type system etc. did that affect the course or detract from learning OS concepts? Also, when working with a higher level language like Rust, wasn't it hard to understand what happened on a hardware level? I of course realize the many safety benefits of writing an OS in Rust, but when learning it, wouldn't something more straight forward and unobtrusive be better?
I don't see the need for *two* posts on such tightly related subjects. Comments should be redirected to: https://www.reddit.com/r/rust/comments/arg1g9/using_rust_on_google_cloud_platform_for_production/ .
See also usage of Rust on Google Cloud Functions (by OP): https://issuetracker.google.com/issues/124539361
AFAIK, rustc does not yet perform any bounds-check elision, or any other optimization: optimizations are delegated to LLVM instead, and LLVM can be pretty finicky... I spent 4 week-ends desperately trying to get `&lt;RangeInclusive&lt;T&gt; as Iterator&lt;Item = T&gt;&gt;::next` to perform as well as `&lt;Range&lt;T&gt; as Iterator&lt;Item = T&gt;&gt;::next` and LLVM stubbornly refused. There are plans to have some high-level optimizations made on MIR inside rustc; I am not sure if bounds-checking was considered.
"We" do not know this, you believe it... you should question that belief, along with any such "we know" statement. First, can you even establish that psychology constitutes a quantitative science capable of making reliable predictions based on the "Big 5"? I personally have not been able to do so to any degree of confidence. I can also see considerable long term evolution in all 5 described traits in my own experience, especially once I began to travel internationally and engage more heavily with that "openness to experience" trait... if one cannot make meaningful predictions about one's own outcome using these supposed traits -- while simultaneously being the sole extant individual qualified to quantify them -- then how valuable can they even be? But, more importantly than this, you're stating that something _beyond_ nature vs nurture is a decided and understood problem well before nature vs nurture is anywhere near decided or understood. That gyre does not hold. Again, _establish_ an indelible basis for political leaning and it might be worthy of being considered a trait worthy of communal protection. Merely _posit_ that basis and you haven't reached the bar. Also one can point at any number of examples of people who have professed wildly different political leanings and mutually contradictory ideas within their lifespan... anecdotally I'd say at least 80% of all "liberal" individuals and 100% of all "conservative" individuals demonstrate too much psychological and intellectual plasticity just from puberty to middle age for there to be any hope for proof that political leanings are worthy of protection as an indelible.
This is cool, maybe you should mention that the course is in Russian :). Any chance to release an English version ?
Essentially yes. For example, imagine that you need to check the `health` of each object to know which are less than 50%: if you use an array of objects, you'll be loading `GameObject` (~20 bytes) to check its `health` (4 bytes) and wasting 80% of the bandwidth/cache on top of not being able to use SIMD instructions. Not exactly efficient.
How did you feel about it? 
This is a drop in replacement for C's `malloc`/`free` (even without recompiling, via `LD_PRELOAD`), and so should be possible to use in Rust (even easy, if someone creates a `GlobalAlloc` wrapper for it, similar to [`jemallocator`](https://github.com/gnzlbg/jemallocator)).
Before anything else Rust should be used to teach people to think in a rational and logical manner. If you never state your beliefs they can never be reacted to with opprobrium. The obvious answer then is do not engage in political commentary in a professional context. If however you choose to state your beliefs and find that they're reacted to with opprobrium, then you've got two possible reasons for that: 1. Your beliefs are valid, and the collective is being intolerant in discriminating against your morally superior beliefs. 2. Your beliefs are invalid, and demand opprobrium from those whose beliefs are valid. It doesn't matter who you are or what you believe, your inherent bias as the one either worried about receiving, or actually receiving, opprobrium will never accept 2, so you push for protection from 1. Consider very carefully the prospect that it's 2. That it's always been 2, and that your beliefs are in fact abhorrent.
Why is a `&amp;mut[T]` not mutable by default? Example: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=01af6c16cc610125d6423c4d2e0788e4 I assume it's because `&amp;[T]` and `&amp;mut[T]` area treated as primitive types, rather than true references. This seems to lead to a bit of an inconsistency if you expand the previous example to this https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=06d141c14d3878a8ea3826d828972c9d In the first example, the `b` in the first half of main had to be made mutable in order to write to it, but the `b` in the second half of main was an immutable value that happened to be a mutable reference. That seems to mean if I want to use a `&amp;mut[T]` in a mutable way, I cannot also ensure the variable doesn't get pointed somewhere else in the process. In the second example, the `b` in the second half of main had to become `mut` so I could have it point to `bytes2`.
Making things work on stable, draft: - Derive: Create an associated type for each field: `GameObject::Position`, `GameObject::Velocity` and `GameObject::Health` here. - Derive: Implement a dedicated trait for all fields of each type: `impl FieldOf&lt;GameObject&gt; for GameObjectPosition`, ... where given a `&amp;GameObjects` or `&amp;mut GameObjects` a method returns `&amp;[T]` or `&amp;mut [T]` respectively. - Library: Implement traits for multiple tuples arity: `impl&lt;O, T0&gt; X for (T0) where T0: FieldOf&lt;O&gt;`, `impl&lt;O, T0, T1&gt; X for (T0, T1) where T0, T1: FieldOf&lt;O&gt;`, ... in `std`, the limit is 12 fields. Painful, but it's a one off. With that, the user should be able to query: `table.get_mut::&lt;(GameObject::Position, GameObject::Velocity&gt;()` and get `(&amp;mut [Vec2], &amp;mut [Vec2])` or `RawSliceMut&lt;GameObject, (GameObject::Position, GameObject::Velocity)&gt;`. You'll need a run-time check to ensure that all fields are different in the `&amp;mut` case (aliasing concerns), but it should be trivially elided. The trait `FieldOf` may have to be `unsafe`, depending on how the aliasing check is done (wouldn't want a user implementing `FieldOf&lt;GameObject&gt;` for an unrelated type and cause havoc). 
My favorite class at my engineering school was the "Exotic Programming Languages" course. It was pretty intense: about 1 language per week over 20 weeks. The goal, of course, was not a deep dive in each language, the schedule simply didn't allow it. Instead, it was breadth over depth: get acquainted with novel programming paradigms, make parallels, see how languages share paradigms, etc... Pretty crazy overall, as it tried to touch on about everything: Forth, Prolog, SQL, Haskell, Erlang, etc... but it certainly opened my mind to the wealth of ideas out there.
This is such a tired debate. The CoC doesn’t forbid discrimination based on political leaning because it is explicitly sanctioning discrimination against certain political leanings. If you adhere to one of those, the Rust community is explicitly saying that any expression of your opinions is not welcome. If you don’t express those in any way that’s observable to the community, you will not be discriminated against. It’s not a grey area, it’s a very strong statement of what the community tolerates and what not. 
I am going to pre-emptively remove this topic before it devolves into anarchy. Meta-discussions such as discussions of the CoC or moderation policies tend to attract trolls, and reddit moderation tools have proven insufficient to manage them in the past; and I simply do not want to waste my Sunday afternoon chasing trolls.
great, now I have to learn Russian first in order to learn Rust \*begrudgingly opens Russian course book\*
It really does depend a whole lot, if you had a value type GameObject that was just huge, and you iterated over say, only it's position field very often, then pulling out the position field to it's own array would be a massive speedup. If the GameObjects were very small, maybe just position and a name, then the speedup might be zero. Similarly, if the SOA layout lets you use SIMD intrinsics, or lets the compiler autovectorize, the speedup could very different depending on how amenable the algorithm is to vectorization and what cpu the customer has. Supposing you are working with f32 types, SSE2 would get you nearly a 4x speedup sometimes, as 4 floats fit in each simd register. Sometimes the speedup can be a little more, sometimes it can be a lot less. If you used AVX2, the speedup might be more in the range of 8x, again, sometimes a little more, sometimes a lot less. I did a little video teaching about SIMD in Rust that has some examples of speedups from this kind of conversion: https://www.youtube.com/watch?v=4Gs_CA_vm3o * adding 3d vectors in a medium sized gameobject went from 410us to 230us when switching to SOA layout. * SSE2 adding of vectors dropped time to 62us. AVX2 in this case would have dropped it down to ~30us * normalizing vectors went from 422us to 67us with SSE2, which is a little more than 4x thanks to the reciprocal square root function available in SSE2 (maybe there is a way to do that in non SIMD rust but it isn't built in) * a routine that clamps vector length, which has a branch (harder to SIMDify) 170us to 101us with SSE2 * clamping vector length with AVX2 (or SSE41) fares better, thanks to the blend instruction which helps deal with branches a little better. 52us with AVX2 
While the title of the paper only mentions C and C++, the technique is actually language agnostic and would apply equally well to Rust. The gist of it is relatively simple, and based on mapping multiple virtual pages onto a single physical page to compact memory. It does nothing for fragmentation of the virtual address space, but reduces physical memory consumption. The numbers they post are pretty attractive: 16% reduction for Firefox on Speed-o-meter and 39% reduction for Redis, with little impact on actual speed. Their implementation may not have the "best performance" it could have (I have some concerns with the usage of locks), however the principle is generic enough that it merits scrutiny in my opinion: other implementations based off the same principle could have different trade-offs while still shaving off memory usage.
Does Rust have more symbols or syntax than C++? Many universities already teach C++ so I don't see why that would be an issue for Rust.
Gentle reminder for everyone: Please keep discourse civil. Also note that the CoC does not tell you what to believe, but how to behave. You can have any political leaning and still be within the lines of the CoC. However, if you act out on your leanings, and you make someone else feel unwelcome or unsafe, we will ask you to apologize and refrain from further such actions.
Azul looks great, but does it refresh at 60 Hz or so, since it is IMGUI-oriented?
Honestly, I think if you're coming at it from a low level course, I'd learn C first. C is a good way to explain *why* Rust prevents you from doing the things that it does.
You can call this function with invalid (*ptr, length) pairs resulting in an invalid slice. This is very much unsafe and your function should be thus unsafe.
Frankly, it doesn't make it hard, it just makes it different. As long as you know Rc, and arena are, and what they do, it's not that difficult. As someone who recently implemented A* algorithm in rust for an assignment, programming in rust made me appreciate the nuances of the algorithm way more than my classmates who wrote a python script and called it a day.
&gt; In my experience the first time anyone's really enjoying programming is, when the first own projects starts. I agree! As a sysadmin who spent 10 years trying to learn using languages like Java, Python, C++, Ruby, etc I had zero luck getting my own projects started and going. Integrating libraries was a pain in all of them for me. Making sure I didnt trip up and do something stupid with memory was a frequent cause of frustrations around getting a project compiling and then finding out it liked to crash... Most I ever managed was some simple CLI programs with mediocre "text adventure" style game play. And that one time I got Java to make a GUI tic tac toe game. With Rust, I went straight from writing a "hello world" and finishing a few chapters of the book to successfully wrapping an HTTP API behind an abstraction and then using that now external crate in an CLI program to perform a common set of functions for me on demand. All while transforming the data received into whatever the API or stdout required. It's frustrating fighting the borrow checker (and I'm finally getting good at knowing how to do it right!) but for me, cargo/crates.io and the borrow checker made me fall in love with Rust. It's so damn easy for me to do BIG things with it!
I think there is a misunderstanding, as I meant that you will have to write a custom compiler if you chose to design your support with a specific language in mind.
If it's to be used as a teaching language I feel like it should be alongside C. Why? So you know why it does what it does, and why you want it to do that. 
Performance, mainly. If you're going to run compiled code anyway, why not just link it? WASM is an acceptable compromise for a web browser, but if you've got control of the runtime, why pay that cost?
Security. Wasm cant go writing to disk or opening sockets.
"Graphical capabilities on par" - they are already on par. gfx-hal is there for you to use so you can do anything. So of course it isn't clear what they mean :D 
That's an excellent reason to use it in a web browser, but not in a game engine. In fact, that would be a good reason to *not* use it in a game engine.
Rust 
why would I bother using amethyst if I'm going to be writing lua? 
Explicitly run.
I'm still hoping to see this advanced enough to be used in web browser engines to render SVG. Any idea how much remains to be done before that becomes a possibility? \&lt;troll mode on\&gt; When is the 1.0 release? \&lt;troll mode off\&gt;
But i guess a proc macro can "de-async" a function into its sync function. Let's see if it will come out.
If your main objective is to make CS enrollment drop to single digits then yes, that’s a wonderful idea. 
Click on the "run with RUST_BACKTRACE=1" on the playground and you'll get a full backtrace.
I think I got .. I just created Hashmap from 1 to 2 in the for loop .. I thought for loop iterate till n, but actually its only n-1
In Rust we have `Future::wait(self)` (somewhere in the fog of `futures:0.3-preview`) to run an async future by blocking a single thread. It's not perfect, but it allows use of `Future`-based libraries in a "just do it sync" context that doesn't need an event loop. [[ /j can I interest you in my toy language that I've barely gotten started writing support libraries for where _everything_ is async and there is no such thing as sync code ]]
That could be solved in rust with a array and `typenum` (or const generics when they happen).
In the playground, you can enable the backtrace (which will show where this happens) via a menu opened by clicking on three dots in the top left of the page. The same can be achieved in the terminal by prepending `RUST_BACKTRACE=1` to your `cargo` invokation. No idea how to do this in an IDE, never used them for Rust myself. As a note, `unwrap` is only should be used when you either know that it's safe, or you don't care if it isn't 'cause you can't do anything but die otherwise anyway. Neither seems to be the case here, so pattern matching would be more appropriate, I think.
&gt; Frankly, it doesn't make it hard, it just makes it different. I agree with this mostly. It makes it hard to implement the same way you are taught normally. But rust teaches that there are some very large problems (potentially) in the way you use a linked list. I've always thought a linked list was a simple data structure, and it is if it is immutable, but beyond that I've realized that a linked list a actually a *deceptively* simple data structure.
This is exactly what I’m talking about. I did my algorithms, ai, and optimisation courses completely in python. It wasn’t until I studied for the exam that I actually had to learn properly what the different algorithms were really doing seeing as python just took care of a lot of things for me.
It’s more about improving compatibility than dropping it. Amethyst will stay cross platform ;)
I think if there are any pitfalls to teaching introductory courses in Rust they'll become apparent only after actually teaching an introductory course. At least for me.
This is for the choice of scripting language.
We can get the file and line of the panic once [implicit caller location](https://github.com/rust-lang/rust/issues/47809) lands. Before that, besides using backtrace, you can change to use `expect` with unique message to distinguish between different panic sites if you can change the code.
right and im saying if you are going to go the route of making a game with something like lua for your game logic what upside does amethyst have any more? you add garbage collection back into the system, you lose data race protection, you probably can’t leverage the ecs system well, etc etc. 
Wasmer has quite decent performance, doesn't it? Wasm can still be hot-loaded, which linked code can't (easily) be.
&amp;#x200B; Guys Some of the facts were off thank you very much for correcting me, have amended the article as per suggestions, let me know if I need to change some of the things more :)
Decent, but natively compiled code would run much better. And compiled code most certainly *can* be easily hot-loaded. Even easier than using WASM.
I think that a lot would need to be done to use the tessellator in a web browser. This is because I suspect that anti-aliasing approaches such as MSAA and FxAA which would be easy to use with lyon's output aren't up to the quality we are used to see in web browsers. So other more complicated techniques need to be experimented with. It's probably a fair amount of work. Lyon is still a good option for a lot of use cases like games, maps, and pretty much any interactive 2d vector graphics need that don't require the highest anti-aliasing quality. What /u/pcwalton is working on with the latest iteration of [pathfinder](https://github.com/pcwalton/pathfinder) is probably a better fit for web browsers in the foreseeable future. It is based on a very different approach and was designed with high quality anti-aliasing in mind. I could go on for a long time about the different trade-offs chosen in pathfinder and lyon, and how they both have their place in different use cases. I'm equally excited about both projects. That said, pathfinder already uses lyon_geom so even if tessellation doesn't end up being the selected approach for vector graphics in, say, Firefox, other parts of the project might end up being useful there anyway. &gt; When is the 1.0 release? The question is fair. I'm thinking of calling it `1.0.0` once the new tessellator I mention towards the end of the post is ready, stable and polished. It doesn't mean the end of breaking changes but it's where I have wanted to take the project for a long time.
Guys Some of the facts were off thank you very much for correcting me, have amended the article as per suggestions, let me know if I need to change some of the things more :)
Easily be hot-loaded how? I know there are ways to do it, but an _easy_ way? Please do tell!
https://en.wikipedia.org/wiki/Dynamic_loading If we're using C or C++, there are libraries that smooth over the platform differences. I know Rust has dylib, but I don't know if that's the de-facto standard dynamic linker these days.
While the title of the paper only mentions C and C++, the technique is actually language agnostic and would apply equally well to Rust. The gist of it is relatively simple, and based on mapping multiple virtual pages onto a single physical page to compact memory. It does nothing for fragmentation of the virtual address space, but reduces physical memory consumption. The numbers they post are pretty attractive: 16% reduction for Firefox on Speed-o-meter and 39% reduction for Redis, with little impact on actual speed. Their implementation may not have the "best performance" it could have (I have some concerns with the usage of locks), however the principle is generic enough that it merits scrutiny in my opinion: other implementations based off the same principle could have different trade-offs while still shaving off memory usage.
It does, but I'm not sure if it's by much.
In practice it's not as simple as just unloading and loading a new dynamic library. What about state? And if you manage to reload state in the newly loaded dynamic library, what about pointers? The old ones won't be valid anymore. It introduces a _ton_ of problems. Sure, they are solvable, but I really wouldn't call it "easy".
Compared to integrating webassembly, somehow, and still having to solve the same problems? I'd say it's pretty easy. And most of those problems go away if you just forget that unloading is an option.
&gt; We were taught concepts like memory safety, concurrency, and making speed optimisations all in the algorithms &amp; data structures, but it was communicated in Java, which didn't really have much impact when used to demonstrate these concepts. I don't understand. These concepts are important in every programming language. I'd say that Java is well suited to learn them. &gt; I absolutely agree that rust shouldn’t be an intro language Me, too. But isn't it usually the intro language where you learn concepts such as concurrency and efficient algorithms and data structures?
As far as I know in a scripting language (or wasm), the language runtime shouldn't own any of the state that should remain, so hot reloading isn't a problem. I haven't looked into it very much, but Wasmer doesn't seem very hard to integrate, and it'll probably only get better.
I personally feel that there shouldn’t be too much emphasis on a language so much as concepts. If you have the concepts/theory down then learning a language shouldn’t be too much extra work. Languages come and go, the ideas don’t change too much 
\&gt; Libraries like SPDK help with this by rewriting the Network Stack and drivers in userspace, and using a polling interface instead of a kernel-based waiting interface. I'm pretty sure you mean DPDK ([https://www.dpdk.org/](https://www.dpdk.org/))
At what cost, though? You're still using compiled languages. You still have to standardize the plugin/engine scripting API. You still have a compilation step. And you gain... nothing. You're running at a lower efficiency. The security features that make it great for running untrusted code get in the way of creative solutions to game development problems. As for owning state, that's a big gray area. Having stateful scripts does make things a lot easier. An engine should always lean towards the "make it work now" workflow, while making the "make it work better" possible.
http://aturon.github.io/2018/04/24/async-borrowing/
Use `..=` instead of `..` to include the end value of your range. Ranges by default (in most languages) are exclusive, ie they run till before the last number, but you can specify in rust to include it.
 How does rust A* differ from python A*? 
 How does rust A* differ from python A*? It's cool that your teacher allows any languages for your assignments. 
&gt; That would introduce a lot of other problems though, wouldn't it? No, it's actually quite freeing. If library loading is a one-way street, then it massively simplifies your plugin API.
It's mostly about the pointers. In Rust, you handle them on your own. In python the language handles them for you. Also, at the end of the algorithm, you trace the path back from the goal state you found to the initial state using the pointers to the parent state you saved for each state. It is very easy to do in Rust, I am not sure how one would do it in python without it being inefficient.
Then use Rust. The discussion as I understood it was about adding a scripting language on top. So you can reload scripts at runtime and the like.
You gain the ability to use something other than Rust or C for game play logic, which is a _huge_ benefit to a 'generic' game engine. I also can't imagine the compilation taking long for small independent scripts, but if I'm wrong on this, then I agree it might not be worth it over a language that isn't compiled &gt; The security features that make it great for running untrusted code get in the way of creative solutions to game development problems. I'm not sure I understand, but if you're talking about loading files or using sockets directly from game play logic, I definitely do not agree. 
You've always had that ability. You're still going to have to make the heavy translation layers that you'd have to make when using dynamic linking. You're just doing it less efficiently. And as for scripts loading files, not all scripts exist to simply update game state. For instance, Unity uses C# as its scripting language, and any game of any complexity will eventually need to write loaders and managers for its own proprietary assets. This requires filesystem access.
I can't tell if your last line is joking or not, but I would certainly like to see it if it exists.
How do I take ownership of the value of a fat pointer that I have a mutable reference to? To explain myself, here's some code: let mut result = Vec::new(); let mut buffer = String::new(); let mut new_loc = location.with_offset(1); let mut i = 0; //and then once in a while the following happens: if i &gt; 1 { buffer += new_loc.substr(i); new_loc = new_loc.with_offset(i + 1); i = 0; } if buffer.len() &gt; 0 { result.push(Syllable::OpaqueString(buffer, *location)); buffer = String::new(); } It compiles fine, but these two ifs appear several times in my code, so I extracted them into a function: fn flush_buffer&lt;'a&gt;( buffer: &amp;mut String, result: &amp;mut Vec&lt;Syllable&lt;'a&gt;&gt;, i: &amp;mut usize, new_loc: &amp;mut Location, location: &amp;Location&lt;'a&gt;, ) { if *i &gt; 1 { *buffer += new_loc.substr(*i); *new_loc = new_loc.with_offset(*i + 1); *i = 0; } if buffer.len() &gt; 0 { result.push(Syllable::OpaqueString(*buffer, *location)); *buffer = String::new(); } } Now rustc complains about `Syllable::OpaqueString(*buffer, *location)`, saying I cannot move out of borrowed content. Except it should be fine, since I'm sticking a different String into the reference on the next line. I can work around this by replacing that reference with "take-and-return", but can I make that work with a reference?
Я уже выучил. Оно этого стоило.
There are two synchronization points present in the implementation (https://github.com/plasma-umass/Mesh/), and I wonder if they could be improved on. --- The first, and most trivial I think, is that a single global lock is used both for meshing and for a thread to acquire a new span from the global pool. It makes sense in that a thread should not acquire a span undergoing meshing, but also seems somewhat wasteful. It seems a first improvement could be a more fine-grained use of the lock: (a) acquire spans to be meshed under lock, (b) release lock and mesh, (c) acquire lock again to put meshed span in. This global lock really bugs me. It may work well on consumer hardware, but I have some reservations on server hardware. My company has been experimenting with dual-sockets servers of late, the largest having 2x48 cores (Hyper Threaded). 48 physical cores contending for a single global lock does not make for a happy panda. *Also, speaking about dual sockets, the system should probably be NUMA aware, and avoid meshing together pages from different NUMA nodes. At that point, it is conceivable to at least have one "global lock" per NUMA node... but even then there's still 24 physical cores competing.* --- The second, and more difficult one, is the write block during meshing. Meshing is about physically copying bytes from one location to another. Due to the fact that the pages are exclusively "owned" by the meshing thread, it's guaranteed that no new allocation is performed, however there is no guarantee that the page used as a "source" is not being modified concurrently by another thread; thus the write barrier. The current implementation is simple: - `mprotect` on source page + custom fault handler. - copy source into destination + redirect virtual mapping. - `mprotect` on source page to make it writable again + unblock writer threads. The algorithm should be smart enough to copy the less populated span into the more populated one, so less than 128 elements (a span has a maximum of 256 elements)... but this does not solve the problem. The problem is that *any* thread can block *any other* thread. Cue Priority Inversion issues, unbounded latency due to preemption, etc... Furthermore, due to the page protection, *any* memory write can block. It's going to be painful to debug the performance issues this may cause as they may happen at any random spot even in normally non contended sections of code. Yet, at the same time, I don't see a way to implement meshing without some kind of read or write barrier in multi-threaded programs.
YES
As someone who has no formal training in programming or mathematics, yet uses Rust daily, I have no idea what most of the words you wrote mean. What are some of the real world applications your crate?
Comment, fixed, thanks, was on mobile before. It's unlikely that I do an English version, but we'll see. I do plan to publish sources of the slides.
&gt;You've always had that ability. You're still going to have to make the heavy translation layers that you'd have to make when using dynamic linking. You're just doing it less efficiently. I'm not sure I follow. How would you be able to (easily) use any language by loading a native dynamic library? &gt; And as for scripts loading files, not all scripts exist to simply update game state. For instance, Unity uses C# as its scripting language, and any game of any complexity will eventually need to write loaders and managers for its own proprietary assets. This requires filesystem access. Oh, yeah, that's true. I guess a solution to add this flexibility would be to make it possible to load dynamic libraries which can in turn bind to the scripting runtime, but then we're not so far away from the native approach anyways.
I'd love to see rust become a devops language. I think it has a lot of potential for that use case, but the space is pretty heavily dominated by python. I'm definitely biased, because I much prefer a strongly typed language (how do you stay sane when you can't even rely on what type a variable is?) but it makes me sad that nearly everything in devops is python.
Base Unity/Godot level visuals aren't that impressive. Uniity usually requires multiple plugins to start looking really good.
It's called [nafi](https://github.com/nafi-lang/rust-nafi) and most of the design is still purely in my head while I work on a (fifth?) parsing backend. (Getting the repo link reminds me that I need to update the badges since I'm trying to retire my Gitter usage and I've made a [Discord](https://discord.gg/FuPE9JE) for it) I've never gotten further than parsing. But I think I've finally got a design I like with [rowan](https://crates.io/crates/rowan) and [salsa](https://crates.io/crates/salsa) so maybe I'll actually get something working this time.
&gt; I'm not sure I follow. How would you be able to (easily) use any language by loading a native dynamic library? By linking the runtime as a shared library with bindings for the target plugin architecture. You'd do the same thing in WASM. Look at how Godot does it with GDNative.
But that'd mean a lot of work for every language, while WASM would be a one-time thing?
It's exactly the same amount of work, if not more, for WASM.
Just impressed about finding Portuguese comrades here
Starting a position in a few days that's at a company moving to devops. They don't appear to have language requirements. I plan to make use of Rust myself. The code is arguably the most stable I've ever written and I'm not even trying to make it stable... Since "stable" is such a weird word my definition is: Ripping a chunk of code out and refactoring it to add/remove functionality or using it elsewhere has never resulted in very odd and hard to track down bugs. At worst it's a minor logic problem and a few minutes fighting with the compiler but it almost always compiles and works exactly as I expect it to without any issue. As an admin, I value that greatly. I'm not sure how if its possible to say how much I value Rust's restrictions on what I can and can't do. I can't always make code reusable in crate form for common admin tasks and new projects likely have different data structures and types. Rust enforcing that so strictly lets me very easily reuse code that normally wouldn't be with a few quick and easy tweaks. The memory safety and nearly forced error handling lets me know that even if its slow because I just don't get computer science my program won't have a lot of the common bugs I have faced in other languages.
You probably misunderstood me. Yes, WASM might require more than most runtimes, but most runtimes don't give you the ability to write in 20+ languages. Anyways, I see your point! 
WASM doesn't give you any more ability to write in 20+ languages than plain ol' dynamic linking does.
I'm coming from the same place as you (no formal CS education), have you found that has held you back in anyway from learning Rust at all or no biggy?
It'd give you the ability to write in any language that can compile to WASM, without having to write extra translation layers for each language, wouldn't it? Dynamic linking would require translation layers for each runtime?
No, it wouldn't, not any more than you could with any language that can be built as a shared library.
I'm a sysadmin who has taken 2 101 level college courses that covered Visual Basic and Java at the most fundamental of levels. I have 0 formal education when it comes to programming as far as I can tell. Especially since those classes went over what I had already taught myself. Rust is *very* frustrating at the start with its errors and admittedly strange syntax. Read the book, pick some crazy project to do, start it, and when you get stuck ask in IRC for help. Eventually, you'll begin to grasp what it's doing doing under the hood and how to avoid it if you are a half decent sysadmin. Even a half-decent admin should be really good at finding patterns to computer behavior and tracking it down to a root cause. The compiler errors are your friend and protect you from things that other languages don't even attempt to! The code I write is basically guaranteed to only have logic faults. No memory issues like forgetting to initialize a variable in time or dealing with empty variables (null values) etc. It's so incredibly freeing for me to know that if it compiles, I don't need to break out reference manuals to find why a small edge case behaves stupidly.
please use pos not pow, check cardano blockchain(it will beat ethereum) it has a rust implementation aswell, they are responsible for ourouborous pos research
As ever, thank you for giving context. :)
So you mean I've been wrong to think of WASM as a separate (assembly-like) language that requires its own runtime? Just like CLR or JVM. Is WASM really "close to the metal"? 
You should be able to use `std::mem::replace`: ``` let s = mem::replace(buffer, String::new()); result.push(Syllable::OpaqueString(*s, *location)); ```
Closer than the javascript runtime it was intended to replace, at least. It is its own runtime, but it shares a lot of the advantages (and disadvantages) of native code.
It's not a problem that's limited to Rust or JavaScript and there's actually a fair bit of prior discussion about it. Have you read an article named [What Color Is Your Function?](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) about the sync/async split?
Huh, I learned something new, I didn't know about `std::iter::once(x)`. So far I've been (ab)using `Some(x).into_iter()`.
If you’ve already downloaded the dependency, which you have if you’ve run a check, build, or run, then you can just run `cargo doc` to build the docs for all your packages. You can pass `--open` to open the docs after building. 
Your experience sounds exactly like mine, except that I got Prolog instead of MATLAB and I essentially got one module of C and C++ blended together and half a module of C++ because I took an intro to game development as part of broadening my experience. ...of course, being the geek I am, I was already pretty experienced with Python when I started, among other languages.
Delphi/FreePascal is great there. Is still a powerful lang behind yet with the RAD interface make some basic programs is easy enough. &amp;#x200B; Is very hard to "connect" to a language without some graphical feedback. &amp;#x200B; P.D: I'm moderator on a Delphi forum of Latin America (http://www.clubdelphi.com)
Hi! First-order logic is an extension of propositional logic (which relates statements - sentences that can have a truth value, like 'Socrates is a man' and 'Socrates is mortal' by means of connectives - conjunction, disjunction, condition, negation), adding to it quantification and relations between particular objects (like assigning a property to a particular object, or relating some object to another object, or affirming something about some set of objects). It is useful in the formalization of mathematical theories, and it can be used for formalizing natural language as well (which is the focus of _Meaning and Argument_. My crate, while it can be used completely independently, serves to power the website, which does all the heavy lifting of parsing the resulting truth tree(s) and rendering them, along with the analysis of them.
The book section on closures with the Cacher memoization doesn’t have much to do with closures. You’ve already read about what a closure is, the Cacher is just confusing things. A closure is simply a function that can capture the environment. But the book example closure doesn’t capture its environment, so it could have been replaced with a function. But then there’d be no closure example shown. I was disappointed in this section of the book. Somehow we end up with an example that demonstrates memoization more than closures.
Well, better late than never I suppose: `soa` and `soa_derive` both use the "struct of `Vec`s" approach that I did compare `soak` to in the post. But on the other hand they both present safe interfaces on stable. I didn't feel it was necessary to call them out in the post because all three crates are so small and `soak` is still so new. :)
Whoops, yeah. I've been looking at spdk for polling storage access and confused the two. 
For cloud SQL, I think just a normal db connector should work but you'll have to use cloud sql proxy, which you have to use in any case (I have not tried this with rust though). For the rest, I'm in the same boat as you.
&gt; Is very hard to "connect" to a language without some graphical feedback. What do you mean?
I don't feel like it has hindered me learning rust, but I'm sure it has prevented me from using the language to it's full capability. That said, I've been on-and-off hobby programming for over 10 years now. I've occasionally written tools that I can use personally for work, but basically never anything I'd be comfortable having others use as a production tool. In order of exposure (not necessarily proficiency), I've used C/C++ (don't remember which I learned first, but one right after the other), Lua, C#, Python, Go, and now Rust. So while I'm not a professional, I'm not exactly new to these concepts.
This post may be useful to you, it tries to holistically explain why a bunch of this is useful in rust and how all the pieces fit together: https://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/
This is similar to a direction I started going before I decided I wasn't sure I liked it, and wanted to publish *something* in the meantime. The derive is currently generating one associated *const* per field (that's how the `GameObject::position` syntax works). The type of that const is `Field&lt;GameObject, FieldType&gt;`, and its constructor is unsafe, much like `FieldOf` would be. Generating a new type in the derive is where I stopped. (I also considered generating a new trait.) I can't make its canonical name an associated type- I would have to make up some new name, so either the user would have to name it or there would be the potential for collisions- generating new associated consts already feels kinda borderline to me. The unstable feature blocking this approach is just hygienic proc macros (or more specifically `proc_macro_def_site` if the way things are split up stays the same). That's a lot closer than GATs or variadic generics, so maybe I'll be able to publish `Table` sooner rather than later. Probably should have put this in the post!
OP posting from a different machine/account. For sure, I could go hard realtime. The trick is, to do that means rewriting a huge portion of the codebase from scratch, which is brutally expensive to do. Would it work? You bet. Is it the best option? That's one thing I'm trying to determine.
I guess you missed the negative before the 9
Thanks for the explanation. I think I understand: if one were to map all the rules (grammar, spelling, etc.) of a language like English, its truth tree would be much more complex than say Esperanto? I would also imagine English would have quite a few contradictions.
May I ask why you think Rust should NOT be taught as an "intro language?" I am quite new to coding, and have dabbled in (in order): html, Python, Rust, Ruby, and now back to Rust - all within about a two-year or so time frame of "off and on" tinkering. Next to Python (which I did through one of those "free codeing" camps), Rust has been my favorite. I simply opened up the Rust Programming Language online manual, and started following along. I'm only in Chapter 3. Chapter two had us make the first "real" program (a guessing game), which was awesome. But I just feel so "all over the place," like I don't know where to go... There's just so damn much information lol. So I figure doing *something* is at least a start. I will say, of all the communities I've experienced, Rust (or at least the Reddit comm.) has been super welcoming, which is great. Any suggestions for a newbie?? 
Dang, the hatching pattern generation makes me want to write a slicer for 3D printing. Also huge kudos to Tom for the Bezier curve algorithm and the [followup PR](https://github.com/nical/lyon/pull/427), that's a lot of effort!
Not sure about that. Don't game mods often lean heavily on scripting? I'd have thought they fall into a trust grey area where a sandbox might be appealing.
I don't think game developers should tackle that problem, and I certainly don't think game engine developers should, either. If a user wants to mod their software, they assume responsibility for their actions.
Yeah, it tries to efficiently render as often as possible. This thread in the issue tracker has a good explanation: https://github.com/maps4print/azul/issues/10
&gt; I'm up against a rust skeptic who cites platform support as a reason to avoid it :( it's unfortunate we live in a world of vendor-locking strategies ) Sounds more like a reason to avoid iOS (that they make it difficult to use any technologies other than the ones they provide). But Android isn't that much better. And I don't anyone can reasonably claim this is a disadvantage of Rust in general; Rust supports more platforms than many languages. That's a pretty good argument against Swift, really; which mainly supports Apple targets. Though specifically for iOS development, in may be better to stick what Apple offers. &gt; Is there something like SDL that's pure Rust, which could be distributed by cargo `glutin` comes to mind; specifically for providing a portable API for getting an OpenGL context (I suppose that's not ideal on modern iOS since Apple decided to create their own graphics API called Metal?). The documentation has information about Android and Emscripten targets. It probably could be ported to iOS, assuming there isn't already support.
That's a bingo! With those idle states disabled all three lanugages run at 124.1Hz, same as they would if I added external load. Awesome! So the question now is why is the C++ version so much better than the Rust version when there's a seriously misbehaving python script elsewhere on the system?
you can reload rust at runtime
People do often underestimate how easy Rust is to learn, especially in a guided learning course where you can get mentored (provided the instructor has mastery of Rust).
As far as concepts go, Rust is the best I've seen at demonstrating a wide variety of them in practice.
&gt;Sounds more like a reason to avoid iOS I agree but i'm a tiny % of the buying public &amp;#x200B; \&gt; Rust supports more platforms than many languages. &amp;#x200B; I've seen enough to convince me it's safe to get a new iDevice as another toy to run my own rust/c++ projects, but this was still a hurdle: I fully understand why there's skepticism. It is an unwelcome hoop to have to jump through .. breaking out of the comfortable settings, digging around docs that can unfortunately be a bit out of date . I do get why my eval world acquaintances are sticking with 'mainstream' languages. I am lucky enough to have freedom to dabble here. &amp;#x200B; gluti comes to mind; specifically for providing a portable API for getting an OpenGL context (I suppose I should take a look.. straddling my own choice issues, i've also preferred to stick to things with CFFI where possible ..the option of going back to C++ which I'm still faster at using, unfortunately. &amp;#x200B; kind od ironic.. I'm writing personal projects in Rust but motivated by the idea that Rust \*would\* be much better for teamwork.. but I still have all the NIH urges which is why i'm not focussed on real world tasks based on established C++ libraries that customers want..
[It's actually very easy to implement a linked list.](https://github.com/orlp/slotmap/blob/master/examples/doubly_linked_list.rs)
After doing this should I see the API docs for Rand in the global API docs, which I access by rustup docs?
Thanks, that was really informative!
&gt;Sounds more like a reason to avoid iOS (that they make it difficult to use any technologies other than the ones they provide). But Android isn't that much better. This is very inaccurate. Android have it worse. By a lot. You need to get down to c then get up to Java. Is a huge hurdle. &amp;#x200B; With iOS, is easier by an order of magnitude. The developer experience on iOS is far better than android that is not even funny. Not even talking about APIs and a lot of nonsense that plague android. &amp;#x200B; The only real gripe is the need of a Mac for developing.
I feel a bit confused by the options available in Rust's wasm ecosystem. What's the difference between `wasm-pack` and `cargo-web`? Where do they overlap, where are they different? If I want to write a bunch of frontend code for my personal webpage and want to use as little JS as possible, which one would work better?
To understand how a the language work. Specially for first-time learners that haven't developed the mental model in how the abstraction works
Develop more good habits? Who knows. Apply more computer science concepts than Python or Whatever? No, don't see why. You might apply more low level computer concepts in Rust than in Python though. 
I'm one of the authors -- thanks for the detailed analysis! Having finer-grained locking around meshing + acquiring spans makes a lot of sense, we've been plodding away at improving other bottlenecks that I think we will get to this soon. I also don't see a way around the current read/write barrier (as implemented with \`mprotect\`) for meshing in multi-threaded programs -- I would love any suggestions or wild ideas people have here.
&gt;The only real gripe is the need of a Mac for developing. &amp;#x200B; that's the killer. If I keep using iOS devices, i'm locked in to keeping an apple computer. I've been "mac laptop , linux desktop" for a while but I really wish I could ditch that. a whole other discussion. &amp;#x200B; putting up with the extra little bit of stub (java-&gt;C-&gt; rust lib) or (java -&gt; C/C++) is nothing compared to the requirement to buy apple hardware. Now I remember I came to think of the mac hardware as a dongle for the iOS SDK. So i'm paying for a pro IDE, but I can't use that for rust :(
I had not - thanks for linking that, it was a really good read.
Minor nit: `(T0)` should be `(T0,)`
Practicing will definitely make you write better C++ (and even C to an extent). But it will also make you think more functionally, training some of your Haskell or OCaml maybe. Overall I think this is a good idea, and no I am definitely not biased as a Rust fanatic.
Perhaps [Topological](https://en.wikipedia.org/wiki/Topological_sorting) sorting can help you and there is a Rust crate that works well: [topological-sort-rs](https://crates.io/crates/topological-sort). I never has any issue.
Yes, as long as `rand` is a dependency of your crate that has been previously downloaded (e.g. `cargo build` works), you'll be able to access the docs for `rand`. If you don't see it in the side bar from `cargo doc --open`, you can run `open target/doc/rand/index.html` (or the equivalent of `open` on your OS).
Thanks, fixed.
In reality, first-order logic is not capable of of formalizing the entire English language. You'll need a higher-order logic to do that. Consider a statement of the kind 'Most people voted against it.' and 'Few people voted against it.'. The statements are contrary, and yet if one were to try to formalize them, the most reasonable thing you could do, to the extent of my knowledge, is 'Some people voted against it.' for both. It is true that if either of the former statements were true, the latter would be as well. But if the latter were true, it would be ambiguous which one of the former it was meant, if any. You wouldn't have one truth tree for the entire English language, though. Logic captures the basic structures (in first-order logic, that is 'and', 'or', 'if .. then', 'not', 'there exists', 'for all', and verbs (O²xz = relates some general object 'x' to some other general object 'z', where the verb is given by 'O' - the relation), and truth trees function with particular statements. If you browse to the website of logic-rs: [https://ixjf.github.io/logic-rs/](https://ixjf.github.io/logic-rs/), you'll see some example input in the editor. You could assign to each different capital letter some verb, and translate it to an English sentence. For example, for the first line of the default input: `(∀x)(H¹x ⊃ A¹x)` Assigning to H¹ the relation 'is a human', and to A¹ the relation 'is an animal', you'd get the following English sentence: Every human is an animal. Translating the second line, the conclusion, assigning O² to 'is related to' and P¹ to 'is a person', you could get: Everyone who is related to some human is related to an animal. ...and you could make up an infinity of other interpretations depending on what verbs you assign to each relation. But regardless of what interpretation you use, these two statements, in the order shown anyway, form a valid argument - it is not their contents that determine that they form a valid argument, it is their structure. Try running the truth tree solver. Click on 'Solve' and see the result.
Alternative perspective: the rust compiler is a good way of really ingraining into your memory exactly what you ought not to do in C, and the Rust book is a good way of explaining why. C itself doesn't really tell you why, it will just crash on you if you do it wrong. You need an external resource to really learn why, and there's no reason why that can't teach you using Rust.
Go seems pretty popular in that space...
Thanks for the reply; do you happen to have a ballpark number of how long it takes to mesh two spans together?
The Rust book has the best explanation of the stack/heap I've found online. That topics like this were well explained in Rust resources is one of the things that made Rust more approachable to me than C/C++... That said, I agree that something like python or JS would make a better first language.
Yes. I like that Cargo is included. Makes 3rd party libraries nearly frictionless. I remember how Maven and then Gradle were like learning a new language each time for my Java projects.
If you're interested in trying out, I've mostly implemented this on the master branch now. Just finishing things off.
Good point about external types being unwieldy... and clever of you using associated consts to overcome their shortcomings!
And other languages like Python and Go don't seem to have as consistent of an experience imo either. Cargo can get specific versions whereas Go just pulls whatever is at a specific git repo address. Pip has its own issues with virtualenvs. Cargo is just a line saying what you want and it works! Simple, no fuss, no muss.
I have yet to find a "guided learning course" for Rust, but that'd be great. In a way, the online manual is sort of a "learning course" in a way - although I do feel is presumes you have at least *some* knowledge of programming beforehand. That being said: it is pretty thorough - leading more seasoned coders to find the book somewhat elementary or verbose. 
[https://github.com/timelydataflow/timely-dataflow](https://github.com/timelydataflow/timely-dataflow)
I think Rust is the best programming language out of all the ones I have tried, unquestionably. Having said that, I still would not recommend it as a first language. Learning a language with a bigger user base will give you access to more guidance from other developers. Even though I think JavaScript is a very flawed language, it is probably a better choice for a first language because there are more tutorials and you can see the results of your progress instantly on the browser as you develop.
I've never really used Apple hardware, let alone developed for it. So I certainly may not have an accurate impression. But are you saying iOS is better than Android for allowing developers to use languages other the ones they provide? That's all I was claiming; not that iOS might not be better in other ways. From the few things I've heard about iOS it seems like iOS is probably at least slightly worse than Android in this particular regard, but they're both fairly close (and not great). Though worse than either was when I tried to write code to run on Tizen (specifically a Samsung Gear smart watch). The options were a Web app in HTML+JavaScript or a native C/C++ app. Their toolchain supports both C and C++. But they use EFL as a toolkit, and for whatever reason they don't include the C++ bindings (nor could I figure out a way to generate bindings that would work with their libraries). With Tizen 4 (which my smartwatch recently gained support for) they've added C# as an option, which might be better.
I wouldn't recommend JavaScript because of its too many quirks. Python however...
&gt;If you haven't heard of this project I hadn't - but I'm glad I had. My mechanical plotter is looking forward to it.
It sounds like the difference is in the busy loop portion? You could look at that in the Godbolt compiler explorer to compare what it's doing. Maybe `Instant::now` is significantly different than what you're doing in C++.
No, it won't be there. It will be in the local target/docs folder for just your project
ahh I see. It is working, I was trying to make it accessible somewhere else. Ill copy the generated docs there. Thank you!
&gt;Async/await didn't come from Javascript, though it does nicely solve its particular problems. &gt; &gt;The most established use of async/await is instead most likely C#- where it's used for GUI and network programming. &amp;#x200B; I think it was F# 1.0 &gt; C# 5.0 &gt; Javascript. Not sure if F# took the idea from somewhere else or if it was their invention. F#'s implementation of async/await is still more advanced, more general and more unobtrusive than C#'s (like it's not part of the language - its built using computation expressions, cancellation tokens are being automatically passed in the background and so on). &amp;#x200B;
Came here to write essentially what you said here :) &amp;#x200B; Pathfinder and Lyon make different sets of tradeoffs. Pathfinder 3 is a tiled non-tessellating software antialiased coverage renderer, while Lyon is a tessellating renderer that fits in more trivially to a regular GPU pipeline, at the cost of relying on hardware antialiasing. &amp;#x200B; Pathfinder 2 experimented with something more like what Lyon does. However, I ultimately abandoned it because I didn't want to regress the antialiasing quality that Firefox already has. Also, there were temporal stability issues when using tessellation in 3D scenes—the 3D demo turned into a mess of static in VR, for example—which ultimately boils down to the same issue around antialiasing. &amp;#x200B; For less demanding use cases, though, such as most games, Lyon's approach may well be better, simply because of how simple it is. You use the tessellator to create a mesh and render triangles. It's really nice to be able to render SVG just like any other model. I suspect this is why Unity's new SVG importer uses a technique like that of Lyon: game developers don't want to have to drop down to the raw CommandBuffer API in order to just put some SVG on the screen. &amp;#x200B; I think we should try to share code wherever possible :) Currently I'm moving away from the \`euclid\` crate in favor of a custom library with better SIMD support, and so Pathfinder is using less and less of Lyon, but I'd be up for merging again if you're OK with that.
Does [petgraph]([https://docs.rs/petgraph/0.4.13/petgraph/](https://docs.rs/petgraph/0.4.13/petgraph/)) help?
&gt;In Rust, async/await can simulated by creating a ThreadPool and passing off tasks to it to run, and wait on a CondVar to ensure it's completed (it's really just let result = [pool.Run](https://pool.Run)(move || {...}).await();). [pool.Run](https://pool.Run)().await() wastes a thread by blocking it until the result is available. async/await never blocks a thread. You can await 100k results concurrently with a single thread. &gt;So, in summary, I don't think that async/await actually does anything for Rust other than bloat the language, since their primary use is in single-threaded applications and Rust has access to system threads. async/await's primary use is not in single threaded applications. Its primary use is in IO heavy applications where you either have to waste/block threads while waiting for IO operations to complete, poll, or wire up ugly spaghetti callback code.
&gt;It's only true until you need to do more work that one thread can perform. Then your performance degrades. The opposite... if you run async/await on a thread pool executor it'll automatically scale to all available cores and push your CPU close to 100% when the load rises. async/await is not bound to a single thread.
I wouldn't agree. Rust isn't exactly a newbie friendly language. And put aside additional cognitive overhead required to develop in Rust when compared to something like Python, a compiler which kinda calls you out on doing stupid things each time you write a few lines doesn't exactly add to incentive to learn to program.
Yeah, here's the quote: &gt; In future work, we plan to explore integrating Mesh into language runtimes that do not currently support compaction, such as Go and Rust. 
I used to be an advocate for Go in that space, and then I found Rust and saw the light. In all seriousness, I don't think Go is all *that* bad for devops. It does do some things pretty well. The biggest complaint I see here is the lack of generics, which I do find annoying. I'm also uneasy about the auto trait (interface, I think?) implementation on any type with matching function signatures. I feel like that could lead to some interesting behaviors... Also, devops sort-of inherently doesn't mind a small run-time, since you're not writing code for embedded or low-level systems stuff. And as far as languages with a run-time and GC, I think there are worse choices. In general, I do think both Python and Go are easier to pick up for a sysadmin if they have little-to-no past experience. So as much as I like it, Rust might be at a heavy disadvantage.
&gt; you can use it on whichever runtime you like what other rust runtimes are there other than tokio?
I think they teach different languages for a reason. You need to learn basics of Asm to understand underlying machinery better, then you are taught higher level language to learn system programming, then even higher to focus on design patterns etc. Rust will require you to think about memory allocation while you actual goal is learning something else. E.g. you will struggle making some double linked list for no good reason. Python is not a good general choice as well IMO as it's used predominantly by data scientists or devops and they usually don't care about good practices rather they do some ML research or quick deployment script. The language itself allows same level of hackery as JS. Use multiple languages. Try Rust as a replacement for C when you have some system programming tasks. Definitely get back to Rust when you finish your degree or even before that.
The main problem I see with the global lock is that depending on the lock it might allocate memory, but that’s something that requires some thought when happening inside the allocator (initialization, malloc).
Check this: [https://github.com/chancancode/rust-delegate](https://github.com/chancancode/rust-delegate) (there's a PR where I rewrote it as a procedural macro). However it's a bit more manual than I'd like (and than you showed), because I don't think you can get the methods of a trait/struct without using a compiler plugin in current Rust. So you have to list the forwarded methods manually.
Thanks I'll check those out.
This is great. Thanks!
Cheers. That is indeed helpful
Any particular reason?
Can I ask what university is that? Do you have any materials you can share?
New content in rust: ballet
I'd love to merge more of this stuff. There is a good chance that what pathfinder needs can be useful to euclid/lyon/webrender. 
r/playrust ?
I'd never actually heard of `cargo-web` before, but I have some experience with `wasm-pack`. I don't know all that much about it but I know that `wasm-pack` generates bindings for npm. I believe it is meant to be used directly with `wasm-bindgen`. `cargo-web` is not listed under the [import tools](https://rustwasm.github.io/book/reference/tools.html) or [important crates](https://rustwasm.github.io/book/reference/crates.html) in Rust's WebAssembly book. I just took a quick look at it, but `cargo-web` looks very good for it's purpose, but newer tools like this don't always work as well as they look. If you have used both, it's up to you to decide, but I would look through [Rust's WebAssembly tutorial](https://rustwasm.github.io/book/introduction.html) for some official advice. Good luck with your website though!
There really isn't a single language that maps well to what's happening at the hardware level, except HDLs and assembly. I don't see any difference between C and Rust for building an OS. 
Wow, this looks amazing! All the other online truth tree solvers I've used in the past are super inefficient and look like relics from the 1990s, so I'll definitely use this in the future. Btw, when writing up the deduction system how did you deal with the undecidability of first-order logic?
Sorry, but I can't help it. :o What kind of bad experiences have you had? 
It doesn't really add anything – `solar_position()` is just as clear as `calc_solar_position()`.
I love Python's, Elixir's and Haskell's community. The only bad experience I had was with the Go community, which I found really unwelcoming for a beginner. 
[Tell more about toxicity](https://twitter.com/ManishEarth/status/826513245624152066).
I tried teaching Rust to my newborn, but they are struggling with the borrow checker.
My past experience shows that there is no point going into detail, it will only increase the chance that my post is locked / deleted. Like I said, I don't expect to change anyone's mind.
You better be careful, that person is a moderator on this Reddit and has publicly stated that criticizing a person's actions or statements is not allowed.
If you used Haskell and C++, Rust should be very easy to grasp. So yeah, I'd definitely go for it.
Honest question: what is the purpose of the post, then? I understand that you believe that your criticism will not change things, but I encourage you to gather your thoughts, approach this honestly and I'm convinced that people will hear you out. I know that this can seem hopeless sometimes and that one's ideas and views are not held to the value that we expect, but maybe the person in cause may have had a bad day or was overwhelmed or just generally busy. &amp;#x200B; Unlike programming, people are hard. We get tired, pissed off and, quite often, afraid and discouraged. Nobody really does it on purpose and I hope that your experience will improve here and in other communities!
I don't think Rust is a good choice as a first language. It's primary benefit over easier [garbage collected] languages is performance, but when you're just learning that's not very important at all. Rust can be very frustrating to learn even when you have years of experience. Being frustrated is not conductive to learning when you're trying to grasp the basic concepts of software development. I would go with a popular [statically typed] language with a well-established ecosystem and tons of trainings materials. C# and Java are both good choices, as you can use free-as-in-beer high quality IDEs (Visual Studio Community and IntelliJ IDEA) with them. If you're feeling a bit more adventurous, try Kotlin instead of Java.
Concatenation doesn’t seem to be a u32 operation. So formatting numbers to string and back should be the right idea.
What do you hope will come of this negativity, then? What about your complaint is actionable?
As a TypeScript user and enthusiast I wouldn't pick TypeScript as a first language. It has all the same quirks as JavaScript, just with static typing. Setting up the compiler and configuring typings files is not something any beginner should have to do.
Perhaps the Rust community needs to develop more tolerance for negativity that doesn't come with ready-made answers, as long as it's expressed in a civil way. Perhaps it can start a conversation, or cause others to reflect on their own beliefs. It's not really the responsibility of one person who dislikes the community to figure out how to fix it.
Most communities are toxic to some degree or another, especially most Reddit communities, as a result of the hive-mind created from liking/disliking threads, and banning anyone who disagrees or creates wide spread emotional disagreements. I don't know what to tell you other than cult-like mentality is exactly what Reddit is designed to achieve. Each subreddit is a group of people with their own opinions, ready to tell everyone else they're wrong, and ban anyone who's not of their taste by sending them to the bottom of a thread and throwing rocks at it. It's all very human-like behavior and when the mob isn't running the show, the moderator comes along and locks a thread, turning it into a dictatorship, which has the potential to light another fire if people aren't happy. This is just humans being humans. We're emotional train wrecks in one way or another and how we deal with that varies wildly from case to case, with some being more compatible with each other than others.
Thanks for linking that RFC! It's a good read. The idea that the same interface will be able to support compiled systems in rust and dynamic systems in lua/python/js is really cool!
I'm not just talking about Reddit. The same thing happens on IRC and Discourse. The common denominator is not the platform but the people and especially the leadership / moderators.
You can do it with arithmetic operations only. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4a015eea93b77d23c03e7684f9686876
https://learning-rust.github.io might be helpful to gather Rust basics quickly.
&gt; I encourage you to gather your thoughts, approach this honestly and I'm convinced that people will hear you out. It doesn't work, I have tried several times and I've seen others do the same. &gt; Unlike programming, people are hard. We get tired, pissed off and, quite often, afraid and discouraged. Too true. We also judge people hastily and too easily develop an us-vs-them mentality. I am certainly guilty of this as well. &gt; Nobody really does it on purpose I agree, it is a community dysfunction and not an individual one, although some individuals contribute more than others. Groupthink is not really one person's fault and avoiding it requires effort from everyone. &gt; I hope that your experience will improve here and in other communities! Thanks!
Thanks!
When you say "concatenate", do you mean back into another u32? i.e. `concat(3, 4) == 34`? I would do something like: // Just doing this in float for now but see https://stackoverflow.com/questions/25892665/performance-of-log10-function-returning-an-int // for better ideas fn mod_10(n: u32) -&gt; u32 { (n as f64).log(10.0).floor() as u32 } fn concat(n1: u32, n2: u32) -&gt; u32 { n1 * 10_u32.pow(mod_10(n2)+1) + n2 } fn main() { println!("{} mod 10 = {}", 9, mod_10(9)); println!("{} mod 10 = {}", 10, mod_10(10)); println!("{} mod 10 = {}", 99, mod_10(99)); println!("{} mod 10 = {}", 100, mod_10(100)); println!("concat({}, {}) = {}", 1, 2, concat(1, 2)); println!("concat({}, {}) = {}", 100, 2, concat(100, 2)); println!("concat({}, {}) = {}", 1, 200, concat(1, 200)); } [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=be370e04b4e9eab758a822d27d23129f)
&gt; Why do Rustaceans always say that other programming communities are "toxic"? It's been my experience that we don't. I'm subscribed to the sub's RSS feed, I've been lurking here, reading pretty much every thread, since before Rust 1.0 and I haven't seen *anyone* calling other communities toxic since one comment about PHP and one comment about C++ way back around the 1.0 release (years ago). &gt; I've seen a lot of bad behavior from the Rust community and leadership as well. Examples, please? I'm honestly curious what you consider to be bad behaviour. I've seen various cases where mods aggressively lock/delete threads to enforce posted rules like "constructive comments only" and "no zealotry" but, in general, I've found this sub to be the most civil ones I've ever seen. &gt; The idea that Rust is "friendly and welcoming" has become an article of faith. Not for me. I see it reinforced every day. In fact, I see it reinforced right here in this thread, where people are responding to you by politely trying to engage in constructive discourse when, in many contexts, people would react emotionally and take offense. &gt; If you go into details then you're "engaging in personal attacks" or "not being constructive". I'd need to see an example but I suspect it has more to do with how it was said, rather than what was said. I don't fear that I'd be penalized if I were to link to someone else's comment and politely air my concerns. &gt; If you speak in generalities then you're "too vague". Speaking in generalities tends to violate the "Constructive comments only" rule which requires that comments be actionable. &gt; Anything critical is tone-policed to death. Not really. From what I've seen, unless it's trying to incite a flamewar, it just gets downvoted for being more likely to provoke an argument than to form the basis of a productive conversation... as the downvote arrow is intended for. &gt; I've even seen someone claim that criticism from within the Rust community somehow proves that other communities are toxic. Now *that*, I'd like to see a link to. You've got me curious. &gt; If you've had a great experience, that's great, however it doesn't invalidate my shitty experience. Fair enough... but, if you're not going to give us examples of bad interactions you had, how can anything come from this except maybe making you feel better for wasting our time? There's nothing wrong with venting, but this isn't the place for it. &gt; If you want to paint me as one of the Bad People who deserves to be kept out, then whatever. I think you're breaking the sub's rules about content being constructive and actionable, but I don't know enough about you to judge you as a person. &gt; Downvote or delete my post, you're only proving my point. Not really. They're just keeping with the rules for constructive and actionable content that have been posted for years in the same way that they send memes to /r/rustjerk/ and players of the Rust game to /r/playrust/ It's really no different than StackExchange moderators migrating questions from StackOverflow to ServerFault or vice-versa inf they're not on topic.
You’re looking for /r/playrust
Looking like relics from the 1990s doesn't necessarily mean that they will perform worse than mine :P But if you do find something that doesn't quite look like what you expected, please do fill a bug report and I'll look into it. As for the undecidability of FO logic, currently there is no restriction on allowed input, in keeping with the book's ideas. However, that _does_ mean infinite trees will appear. I applied the idea of some sort of paper I've found on a university website, in relation to the order of application of rules, which necessarily will lead to all unsatisfiable input sets being correctly classified by the algorithm, unless there is some bug. If the algorithm gets stuck in an infinite loop, then it's guaranteed that the input set is unsatisfiable. I'm not quite sure how else to solve this problem. I've come up with two concrete ways, but I dislike both: 1) limiting the universe of discourse, so infinite trees will no longer appear, but this implies that: a) you'll get unnecessarily long trees when an infinite tree would previously appear, b) the allowed input sets are limited, even if some are unsatisfiable and won't lead to infinite trees 2) stopping the algorithm when the first open branch appears, which is enough to determine whether the input set is satisfiable, but this also has consequences: a) it could be that the tree has only the main branch and it is infinite, so you'll still get into an infinite loop b) you'll get incomplete trees otherwise Of course, if I make it mandatory for any solution to not change the set of allowed unsatisfiable input sets, then we (probably!) can't find any (_maybe_, just _maybe_, and this is a blind guess, you could somehow only limit the allowed _satisfiable_ input sets, even if some don't lead to an infinite tree). If we could know beforehand precisely which sets of statements are satisfiable and will lead to an infinite tree, then we wouldn't even have this entire problem in the first place. So any solution to this will involve limiting somehow the allowed input sets. I just don't know which ones to limit without making the solver unusable. One thing I do want to maintain - the correctness of the algorithm in classifying all allowed unsatisfiable input sets.
Yes, I’m wanting to concatenate them into an integer again, however I’m concatenating an unknown amount of them. It could be 10 long, or it could be 2
Why we need Golang?
I recently wrote code to do this, the implementation was ~70 lines for the graph and the sorting algorithm. Can't recommend the linked wiki enough, this is how I got mine working. I achieved it with the depth first search variation :) good luck!
Easiest way is to fold on an iterator: https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.fold
Try as many programming languages as your heart desires. There isnt very much downside to learning Rust if you have the time. &amp;#x200B; The immutable data by default will help with your complex projects. It is very easy to write spaghetti c++ as a beginner. Hopefully your profs will be cool with you using Rust for your projects and all your friends will be jealous because you completed the project in half the lines of code that they did
&gt; it will just crash on you Nah, if you're *lucky,* it'll first rack up a few million in lost reputation and/or fines by disclosing something it shouldn't.
Nice, I encourage you to write up your design, and maybe even post it here to /r/rust. I'm pretty interested in learning about this design space!
The biggest cost is finding the spans to mesh in the first place -- in our redis example the largest time spent in \`meshAllSizeClasses\` was 21.7 ms, where 2502 pairs of spans were meshed. Amortized, that is around 8.7μs per two spans
I don’t know how I plan to handle overflow, but I should be fine with a cap of 2bil (10 was an exaggerated example)
Really like this one https://itch.io/queue/c/449652/rustlang-games?game_id=353525. Hard - or I may just have misunderstood the tactics.
I love [gource](https://gource.io/), it's so calming to watch. I am experimenting with using it to visualise audit logs. I should probably contribute a pull request to `rustc` again so I can see my name in 2019.
How is your C++ code measuring time? Is it using the system clock? `Instant::now()` uses a monotonic clock, not the system clock. Try the same with `SystemTime::now()` instead.
Can you make `TrieView` a struct, which is generic over `T: Trie`?
Is there a way for a closure to `move` only some variables from the environment? In C++ I'd write: { int a = 5; int b = 10; auto foo = [&amp;a, b]() { return a + b * 5; }; } To move `b` into the lambda but borrow `a`. In Rust, I know you can say move || a + b * 5; but that moves both `a` and `b`, but if I leave the `move` out it borrows both. How do I specify individual variables to be moved / borrowed rather than everything?
We don't- just a convenient language because all the other Cloud Foundry buildpacks are in Go ;) - so using Go took care of a lot of boilerplate. 
A key tactic is to take up spaces on the board with your people, so that they can't walk there...
Awesome! This looks like a step in the right direction.
I want different implementers to be able to define their own view structure. My current implementation uses a single HashMap to associate (u32, K) pairs (representing node id and key) to Nodes. enum HashTrie&lt;K, V&gt; { Empty, Trivial { value: V }, Standard { map: HashMap&lt;(u32, K), HashTrieNode&lt;V&gt;&gt;, next_id: u32 } } enum HashTrieNode&lt;V&gt; { Branch { id: u32 }, Leaf { value: V } } struct HashTrieView&lt;'a, K, V&gt; { trie: &amp;'a HashTrie&lt;K, V&gt;, id: u32 }
I think a language like Java, C++, or Python might be more suitable for someone who is still in the process of figuring things out. I think Rust is a very opinionated language that actually tries to improve on C by introducing a lot of new stuff, and while I kinda adore it I do find some of its inventions (or borrowings from other languages) not so simple. Most importantly, Rust still hasn't even made a dent in C/C++, which puts its future viability as a general purpose language into question. 
We use some of GCP's Stackdriver services in a production Rust app. Specifically Stackdriver Error Reporting (via logs that we ship via [journaldriver](https://github.com/tazjin/journaldriver)) and Stackdriver Trace, for which we have a custom Rust client instead of a generated one. I've a vague intention of extracting at least the Trace client and starting some sort of "Rust on GCP" repository. A long time ago I started work on a [Datastore client using Serde](https://github.com/aprilabank/datastore.rs) for Rust type &lt;-&gt; Datastore entity serialisation, but we didn't end up going with Datastore (in favour of PostgreSQL). It did seem like a promising approach though ...
Do you know if fragemented virtual memory can still cause a significant overhead for the OS's managing it?
Could someone help me with module system? Having quite a hard time cracking how I should import modules for usage in another modules, which are siblings for example. Imagine I have a module which I need to reuse in multiple other modules. And perhaps at the time of writing it I cannot for see of yet where it might be applied in the future. Some other module might need the structs or services defined in it. In javascript it's pretty easy, you just import what you want export what you want to where you want pretty much as long as you do not cause circular dependency. But in Rust this is a bit weird for me. I've red through the Rust book, and it failed to provide an answer as I see it. I've checked a few open source projects like Deno, but there everything is kept in same folder. And in manner that is still difficult for me to keep track of. And there is also seem a bit outdated information which google indexes in it's search results before Rust 2018 which is a bit confusing. So the case. Imagine I have two modules: Module world which provides me a function which returns a string. Module hello which provides me a function which prints a greeting. I want to use string from module world in my module hello to print a "hello, world". Which could be later used in perhaps another module of whatever. Currently I've managed to do it in [main.rs](https://main.rs) and it looks like I have to declare all the modules I'll need and that allows me to specify path in a module of another module to get access to it's functionality as long as both are under same scope. However this sort of "bridging" of modules through higher level and not using mod inside of a mod makes me to scratch my head. As now there is two places which I need to change / "bridge" to take care of dependencies. Am I doing something wrong? Maybe there is some more exhaustive literature or examples you could point me to?
It definitely has quirks, but many of which, if you actually look into why they exist, can give you a good understanding of lower level things too.
&gt; Would it be as simple as SELECT * FROM table WHERE array_column = $1, where $1 is the Vec&lt;String&gt;? Yep, that should work.
You could just do it in unsafe for the intro, and explain why that's necessary. Then it's no different than C.
You can explicitly borrow some of the variables and then use them in a `move` closure: ``` let a = 5; let b = 10; let foo = { let a = &amp;a; move || a + b * 5 }; ``` You're now moving `a` by value into the closure, but `a`'s type is `&amp;i32`.
Yes. Those VM pages need to be mapped to physical pages by the MMU. That mapping is slow, so the result is held in a cache called the TLB. If you under-utilise VM pages, you will need more of them, which means more mappings, which means you're more likely to evict TLB entries and necessitate a page walk. https://en.m.wikipedia.org/wiki/Translation_lookaside_buffer
I read the Rust book, but I'm still struggling against the borrow checker... I have a struct method with a `mut &amp;self` argument, where I'm trying to `drop` something that's an attribute of `self`. I'm getting a `cannot move out of borrowed content` compilation error: ``` struct HalState { id: u32, } impl core::ops::Drop for HalState { fn drop(&amp;mut self) { // ... println!("Boom boom"); } } struct Application { hal_state: HalState, } impl Application { fn main_loop(&amp;mut self) { // ... loop { drop(self.hal_state); } } } fn main() { let app = &amp;mut Application{hal_state: HalState{id: 1}}; app.main_loop(); } ``` I can't do `drop(&amp;self.hal_state);` because drop has to be called on an owned value, not a reference. I tried using a `RefCell` but when I tried to `drop(self.hal_state.borrow_mut())` it wouldn't actually run the `drop` method, I think it was dropping a `RefMut`. Any insight would be appreciated.
I wrote my 2019 Global Game Jam game in Rust, compiling to WASM: [ItchIO](https://bsurmanski.itch.io/belonging-ggj19) (playable in the browser) [Github](https://github.com/bsurmanski/ggj2019) It wasn't on the list. Note I made it solo in 48h, so it's not super polished but I'm still proud of it :) It shows a proof of concept of using SDL2 + GL and compiling with emscripten. The weird global state stuff is because emscripten kept corrupting my context object on callbacks... I think there's a bug there somewhere. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Hmmmm, yeah this is a tricky problem, and I don't know if there is a satisfying solution. You could implement several options and let the user pick which one they want (eg. even if infinite trees can show up, I think it would still be useful to allow running the general algorithm and then cutting off after a certain time limit). There are also decidable fragments of FO logic, such as ones where [all predicates take a single argument](https://en.wikipedia.org/wiki/Monadic_predicate_calculus), and depending on how expressive they are it might not be too bad to restrict the solver to those classes (for example, I doubt anyone would miss anything if you excluded ∀∃∀∃ statements).
Could you say a bit more about what problem are you trying to solve to avoid this being [an XY problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem)? For instance, what input values do you expect?
Dr Evans is great, isn't he?
You already use Haskell that is pretty different than most, so for this alone what the hell, use rust. &amp;#x200B; However, to stay on point: &amp;#x200B; When you are a beginner, the *first programs* you wrote will be almost similar in structure. How good/bad are the compiler errors make a difference, and rust is better than c++ by a lot. &amp;#x200B; However, in the moment you start to make a *real practical project*, the difference will be **bigger**. For what *kind of project* **X** language will make your *life easy*, that depend. Pay attention to the tagline of rust, and you will see for what kind rust match. &amp;#x200B; No many languages are good enough for most kind of projects. And I mean, good to finish them. That is what people mean when say "this lang is productive". Rust, Haskell and a few others trade "bye right now, but start slow" instead "make result now, but pay for bugs later" than many others. &amp;#x200B; However, if you are starting? Pick a more "harsh" language NOW. You have all the time of the world! Eventually you will pick the pace and start to defeat IN TIME and IN RIGTH to most other developers. &amp;#x200B; Plus, you not need to just use 1 language. I think the sweet spot is 2-4 depending on the market you are. And just 2 for most task. For example, use Rust and a scripting lang like python. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Beautiful. The way the spirals move reminds me of this incredible Numberphile video about how the golden ratio is the most irrational number: https://www.youtube.com/watch?v=sj8Sg8qnjOg
I am going to play this later, but I wanted to say the dancing crabs gif, and the music rock!
Yup, those darn *symbols*, automatically evil. Thats why the only valid programming language is [Whitespace](https://en.wikipedia.org/wiki/Whitespace_%28programming_language%29), which has an easy to remember ***three** symbols, space, tab, and linefeed. Simple!
&gt; But are you saying iOS is better than Android for allowing developers to use languages other the ones they provide? Yes. Not saying that in both platforms some stuff is harder here or there. The thing is that on iOS, you already get a SDK that is low level-is. Is MUCH easier to glue from low-level to high-level than the opposite. For example, I have certain code on .NET that wish to use on Android. The problem is, this is only "easy" if I run .NET on android. I can't run that small thing directly from java. Now considere this problem from the other perspective and multiply for the fact that Android is Java. If I need something made on Java/Android on .NET/iOS I'm DOUBLE screwed. In contrast, when you start from C/C++ the path is far easier, and on iOS, you already have a foot there. P.D: Of course I'm more than aware that both companies have a lot of incentive to make this as hard as possible. Right now, cross-platforms is a "solved" thing except on mobile. But when you could factor political and economic issues, the fact is that Android have ALSO a technical issues when marry it on Java. 
I’m writing an expression calculator. Currently it iterates through every character of the input string. Eg: 201 + 11 I’m trying to combine the chars of 2 0 1 then parse them into a u32 and push them onto my tokens vector 
Should both feature requests should be merged? I filed two separate feature requests because although all are GCP services, they is some separation when supporting these two (client libraries vs CF). ex: there is client lib support for PHP but not on CFs.
Is it just me or does the number of files in the video seem really small and not seem to grow very much at all?
why you use rust only for stackdriver? is it because of performance.
&gt;it's even less "safe" because of the raw pointer deref, even though we know the pointer is valid; it's still just worse style. Perhaps more importantly, \`transmute\` will fail to compile if the types have different sizes, while this sort of code would compile without warning and then result in undefined behavior at run time.
Working with lyon is consistently one of my favorite parts of making `ggez`. We honestly only use its most basic capabilities in terms of shape and path tessellation, but it's consistently high quality and only getting better, and working with Nical is fantastic. For other projects I've been in the position of "if I want to make these vector graphics work well I need to either write my own tesselator, software-render everything with SVG or Cairo, or hand-model everything"... Having a simple but very good tessellator that produces geometry you can trivially give to the GPU is heaven.
Would it be possible to emulate the write, by peforming the copy of the effective addresses first and then resuming at the next instruction?
The syntax for list matching is `WHERE &lt;column_name&gt; in (&lt;val1&gt;, &lt;val2&gt;,...,&lt;valN&gt;)` or `WHERE &lt;column_name&gt; in $1` where `$1` is a tuple of strings. You will have to experiment to determine how a `Vec&lt;String&gt;` is represented in the statement.
deceptively simple... if you have a gc. we had to do linked lists in c and memory leaks were treated as incorrectness, so ownership was still a thing. it just wasn't enforced by the compiler. really hammering home resource ownership would be valuable in my opinion. 
Rust is good as a first language, though surely not an easy option.
I know some ways to work around it, but I just don't understand why this code does not work. fn main() { let mut sign:i32 = 1; let mut run = || { sign += 1; }; sign+=1; run(); dbg!(sign); } Saying that I cannot use `sign` because it was mutably borrowed. I know I can work around this by just inlining my `run()`, or by explicitly passing `sign` as a `&amp;mut i32` param. But I would love to understand why it doesn't just work this way. If it's unsafe, what makes it unsafe? Thanks
Files were limited so that things stay readable.
Ah interesting project! A possible alternative approaches is grouping the input into consecutive substrings representing a single "entity", e.g. `"201"` instead of `'2', '0', '1'`. This is sometimes called "tokenizing" the input, and a manual way to do it would be to keep track of the index of the first piece of each entity and then slice when you come to the end (E.g. using something like `str::char_indices`). Another approach when you're consuming individual digits like like that is to build the integer using multiplications by 10, going back to the first principles of what "201" means as a number (`2 * 10^2 + 0 * 10^1 + 1 * 10^0`): something like let mut number = 0; for digit in input { number = number * 10 + digit; } `number` will be 2, 20, 201 for each input digit. This works because your input is constrained to be individual digits. The solutions involving logarithms are slow but great for concatenating arbitrary integers.
Not sure if this is relevant, but if you try to implement `Copy` for `HalState`, you'll find that you can't because it has a destructor: $ rustc --explain E0184 Explicitly implementing both Drop and Copy for a type is currently disallowed. This feature can make some sense in theory, but the current implementation is incorrect and can lead to memory unsafety (see [issue #20126][iss20126]), so it has been disabled for now. \[iss20126\]: https://github.com/rust-lang/rust/issues/20126
Check out this post that gets in to how closures are implemented in rust: https://stevedonovan.github.io/rustifications/2018/08/18/rust-closures-are-hard.html The upshot is that your closure has the effect of holding a mutable reference to `sign`. As I'm sure you know, in rust you can only have a single mutable reference at a time, so when you try to mutably borrow `sign` again to add one to it, you're out of luck. 
It was indeed using the system clock on the cpp side. The line in question there is `std::this_thread::sleep_for(TARGET_PERIOD - (std::chrono::system_clock::now() - now));`. Per your suggestion I rewrote the rust version to use SystemTime... but that seems to have made the problem slightly worse, by which I mean it increases the odds of a negative duration panic. Or maybe I made some mistake? extern crate statistical; use statistical::{ mean, standard_deviation }; use std::time::{ Duration, SystemTime }; use std::thread::sleep; const TARGET_FREQUENCY: u32 = 125; fn to_seconds(d: Duration) -&gt; f64 { d.subsec_nanos() as f64 * 1e-9 + d.as_secs() as f64 } fn abs_duration(a: SystemTime, b: SystemTime) -&gt; Duration { match b.duration_since(a) { Ok(d) =&gt; d, Err(e) =&gt; e.duration(), } } fn main() { let target_period = Duration::from_secs(1) / TARGET_FREQUENCY; let mut deltas = Vec::with_capacity(10 * TARGET_FREQUENCY as usize); let mut previous = SystemTime::now(); sleep(target_period); for _ in 0..deltas.capacity() { let now = SystemTime::now(); let dt = to_seconds(abs_duration(previous, now)); deltas.push(dt); if deltas.len() &gt;= 2 { println!("mean period: {:.6}, stddev: {:.6}, dt: {:.6}", mean(&amp;deltas), standard_deviation(&amp;deltas, None), dt); } waste_six_milliseconds(); sleep(target_period - abs_duration(now, SystemTime::now())); previous = now; } println!("Final: {:.6}Hz (target was {}Hz)", 1.0 / mean(&amp;deltas), TARGET_FREQUENCY); } fn waste_six_milliseconds() { let start = SystemTime::now(); while abs_duration(start, SystemTime::now()) &lt; Duration::from_millis(6) {} println!("{}", to_seconds(abs_duration(start, SystemTime::now()))); } 
I've seen a lot of programs where top-level/pperf show like 15% time spent waiting for the TLB (before a couple optimizations) so this is pretty important. But optimizing that on Linux is basically allowing transparent huge pages to work. This thing breaks them by doing a bunch of remapping on 4k boundaries. I wonder how a huge page-aware version would compare.
Thanks a lot. I will improve my tokenizing to do this
Thank you
I'd say it's the professor's job to explain why C crashes (or, you know, does something worse). I suspect it's worth the experience of actually seeing the bad behavior rather than taking a book's word for it.
That's really cool. Thank you!
I was trying to make sense of the assembly for entirely too long before I realized that Godbolt doesn't include the assembly for library functions you call. Overall nothing obvious is jumping out to me (now, keep in mind, this is the first time I've ever attempted to read x86_64 assembly) about either version. The Rust one has some jmp instructions that could be eliminated with reordering the code, but perhaps there's some arcane reason the compiler didn't do that. But other than that, nothing seems out of place in either.
As another data point, my 7 year old daughter often asks me if she can borrow something mutably.
Right, then that's not the culprit. In the meantime, I've taken some more time to look at your code and also played around with it in the playground, and I think I found the issue. You call `println!()` in every iteration and also in `waste_six_milliseconds()`. That has not one but two sources of possibly unbounded delay: First it needs to acquire a lock, since it internally synchronizes stdout, then it makes a system call, which causes a context switch and may even deschedule your program. Removing the `println!()` from the loop at least fixed the problem to a point where it doesn't panic due to the underflow anymore. There's a deeper conceptual problem with your this approach, however. No matter how fast your code is, the way your control loop works it will **always** eventually be out of phase with whatever you're trying to keep up with. The problem is that you keep sampling the clock to figure out your goal time to sleep for. This means that any tardiness (be it do your own code being slow, due to the OS not waking you up at the exact right time or maybe even due to your program being descheduled) will accumulate, because in the next loop your goal time itself will be too late. This is why you see a consistently lower frequency than what you're aiming for. Even the C++ code will have this problem if it is structured the same way, although it may be less pronounced because there is no `println!()` or because C++ doesn't synchronize stdout. The solution is to always just shoot for the last goal time + 8ms, regardless of how much time has passed. This is way more robust, as your code now gets the opportunity to catch up if it lags behind. [Playground Link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2560675a235bc7836785773b6eaf2f83). I've changed some things to make it work on the playground, since there is a 10 seconds timeout and the statistics crate is not available. This version hits 125 quite consistently.
/r/playrust
Deciding what this operation should mean with respect to overflow sounds...horrifying :) Hopefully some version of "sorry you can't do that" is workable, like refusing to accept more input or just panicking.
First `Debug` is unsized so you must declare `trait A&lt;S: ?Sized&gt;` to allow `A&lt;Debug&gt;` type. Second `B` impls `A&lt;u32&gt;` doesn't imply `B` impls `A&lt;Debug&gt;`.
That wasn't really my point. I can guarantee you that the mere existence of str AND string would make Rust very hard for a beginner. You need advanced knowledge to understand why both types exist.
There are schools that use C++ as a first language in courses taken by non-CS majors so it's not as stupid of an idea you might think.
Let me preface to say that I don't know the answer to your question. I think the answer is that its not *directly* possible to do what you want, but you can still get the example working. &amp;#x200B; What your trying to do in your example is have a vector of trait objects that all implement trait `A` with different types. The problem with what you want to do with trait `A` is that its method `foo` returns the generic type. This generic type is a sized type, meaning the compiler can determine what size it is (something like str is not sized). This restricts the vector to only be of trait objects that implement `A` of a certain type. Otherwise, how would the compiler know the size of the return type if your vector was implemented to be of trait objects with any type for the generic of `A`. Trait objects are just mystery objects to you and me, but the compiler needs to know their size at compile time if they are on the *stack*. So to get around this, all you need to do is make sure that the return trait object of function `foo` is not on it. ​ Here is a snippet of what can be done use std::fmt::Debug; trait A { fn foo(&amp;self) -&gt; Box&lt;dyn Debug&gt;; // &lt;&lt;&lt; Return a boxed trait object instead } struct B; impl A for B { fn foo(&amp;self) -&gt; Box&lt;dyn Debug&gt; { Box::new(42) } } struct C; impl A for C { fn foo(&amp;self) -&gt; Box&lt;dyn Debug&gt; { Box::new("bibity") } } pub fn main() { // Not a better way, just showing another way of coercing Box&lt;B&gt; and B&lt;C&gt; to Box&lt;A&gt; vec!( Box::new(B) as Box&lt;dyn A&gt;, Box::new(C) ).iter().for_each( |d| println!("{:?}", d.foo()) ); } But this doesn't directly answer your question. What if you wanted to force someone to associate a generic with `A` so that `foo` can only return objects of that type. Well to try and do it the simplest way I've removed the `foo` function to show you're not actually doing what rust thinks your doing. The problem is that you can implement `A` with its generic type *as* `dyn Trait`, meaning that rust thinks you're trying to convert one trait object to another. // But first here is an example without 'impl A&lt;dyn Debug&gt; for B {}' to show what I mean // // My apologies to those on phones :/ use std::fmt::Debug; trait A&lt;S: Debug + ?Sized&gt; {} struct B; impl A&lt;u32&gt; for B {} pub fn main() { // error[E0277]: the trait bound `B: A&lt;dyn std::fmt::Debug&gt;` is not satisfied // --&gt; src/main.rs:9:15 // | // | let _a1 = Box::new(B) as Box&lt;dyn A&lt;dyn Debug&gt;&gt;; // | ^^^^^^^^^^^ the trait `A&lt;dyn std::fmt::Debug&gt;` is not implemented for `B` // | // = help: the following implementations were found: // &lt;B as A&lt;u32&gt;&gt; // = note: required for the cast to the object type `dyn A&lt;dyn std::fmt::Debug&gt;` // let _a1 = Box::new(B) as Box&lt;dyn A&lt;dyn Debug&gt;&gt;; // error[E0605]: non-primitive cast: `std::boxed::Box&lt;dyn A&lt;u32&gt;&gt;` as `std::boxed::Box&lt;dyn A&lt;dyn std::fmt::Debug&gt;&gt;` // --&gt; src/main.rs // | // | let _a2 = Box::new(B) as Box&lt;dyn A&lt;u32&gt;&gt; as Box&lt;dyn A&lt;dyn Debug&gt;&gt;; // | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // | // = note: an `as` expression can only be used to convert between primitive types. Consider using the `From` trait // let _a2 = Box::new(B) as Box&lt;dyn A&lt;u32&gt;&gt; as Box&lt;dyn A&lt;dyn Debug&gt;&gt;; } From what I know, I don't think it's possible to use a trait object as a generic for `A` here, since traits themselves cannot be used as a generic, you'll be implementing the generic of `A` to be a trait object instead. This means that you can implement `A&lt;dyn Debug&gt;` for `B` and get it working, but you cannot implement A with a type that implements Debug. In fact, this is the cause of both errors. In the first error the compiler is looking for the implementation of `A&lt;dyn Debug&gt;` for B but it only finds the implementation of `A&lt;u32&gt;`. In the second error, because you can implement `A&lt;dyn Debug&gt;` for B, it cannot be possible to perform a primitive cast from `Box&lt;dyn A&lt;u32&gt;&gt;` to `Box&lt;dyn A&lt;dyn Debug&gt;&gt;`. // Here is an example of what you could do (if you're insane) to // 'fix' the errors from the previous code. use std::fmt::Debug; trait A&lt;S: ?Sized&gt; { fn debug_box(&amp;self) -&gt; Box&lt;dyn A&lt;dyn Debug&gt;&gt;; } #[derive(Debug)] struct B; //************************************************************** // Here is trait A implement for B with A's generic input being // a trait object //************************************************************** impl A&lt;dyn Debug&gt; for B { fn debug_box(&amp;self) -&gt; Box&lt;dyn A&lt;dyn Debug&gt;&gt; { Box::new(B) } } impl A&lt;u32&gt; for B { fn debug_box(&amp;self) -&gt; Box&lt;dyn A&lt;dyn Debug&gt;&gt; { Box::new(B) } } impl From&lt;Box&lt;dyn A&lt;u32&gt;&gt;&gt; for Box&lt;dyn A&lt;dyn Debug&gt;&gt; { fn from(a: Box&lt;dyn A&lt;u32&gt;&gt; ) -&gt; Box&lt;dyn A&lt;dyn Debug&gt;&gt; { a.debug_box() } } pub fn main() { // Hey they work, but do you really want them to? let _a2 = Box::new(B) as Box&lt;dyn A&lt;dyn Debug&gt;&gt;; let _a2 = Box::&lt;dyn A&lt;dyn Debug&gt;&gt;::from(Box::new(B) as Box&lt;dyn A&lt;u32&gt;&gt;); }
You might want to teach the whole sharing is caring paradigm first. 
Just please not Racket. 
Kind of, have you tried to deploy a Rust based app on the Windows or Mac OS store?
As always, tweaking various code (IoT agent, tui real-time dashboard, network utilities) in rust at work. Not too bad if you ask me.
You can sprinkle those `ok_or_else` where you get the result, instead of putting them all at the end and `map`ping everything. Here's my attempt: fn walk_content_header(node: &amp;Handle, post: &amp;mut Post) -&gt; Result&lt;(), Error&gt; { node.children.borrow().iter() .find(is_h1) .ok_or_else(|| format_err!("Post header is missing"))? .children.borrow().first() .ok_or_else(|| format_err!("Post h1 is missing"))? .children.borrow().first() .map(|title_str_node| match title_str_node.data { NodeData::Text { ref contents, } =&gt; { post.title = Some(contents.borrow().to_string()); Ok(()) }, _ =&gt; Err(format_err!("Post was expected to be '&lt;h1&gt;&lt;span&gt;text here&lt;/span&gt;&lt;/h1&gt;'. The 'text here' bit is missing.")) }) .ok_or_else(|| format_err!("Post h1 &gt; span is missing"))? }
&gt; It's a pain to write That makes it not an easy language.. how easy it is to write an interpreter for, or how easy the theory behind it is, is meaningless if it isnt easy to actually *use*. Having too many symbols/sigils can be a problem, but rust isnt at that point yet, and the ones it does have are pretty standard for C-likes.
Is there a nice way of modifying things returned by an iterator in-place? I have a function `f(&amp;mut T)`, and right now I am using `iter.map(|e| f(&amp;mut e); e)`, which does the job, but I'm wondering if I'm missing something, because it seems like such a common usecase.
Being painful to write and being hard is a different matter. Whitespace is a pain to write because you need tons of characters to write a simple instruction. Not that those characters are hard to come up with (it's rather easy, hence it being an easy language), it's just painful to write. And the theory is all that matters for beginner developers, a language is a just a tool. If you don't understand what a stack is and what a heap is, how do you want to use Rust? Or C? The best first programing language is no programming language at all. Learn the concepts, then a language is just a set of syntax to apply those concepts.
Yeah, hope the Drop trait gets revised someday. I would think that all non-trivial types would implement Drop, even if they don't explicitly `impl` them.
First time answering this kind of post! A friend and I have been working on a 2 player 2D game for 3 weeks with ggez, nphysics and specs. We plan on having something almost playable in 3 weeks. We particularly enjoy our time coding with Rust and these incredible libs!
I agree. While it adds many safety checks to Javascript, the language still hasn't got the ergonomics to handle them well. I really miss the `?` operator.
In terms of solving this problem, perhaps this is something for the user to decide. You could provide three different functions in your crate: 1. Option 1: No limits at all. 2. Option 2: limiting the universe of discourse 3. Option 3: stopping the algorithm when the first open branch appears Then let the user decide which one is best for their use-case?
&gt; then a language is just a set of syntax to apply those concepts. And the language is useless if it's hard to apply those concepts because of syntax. Maybe the *theory behind* Whitespace is easy. Whitespace itself *isnt*.
Man you're lucky, my kids have an ownership-only API because they drop stuff anyways...
I agree that that neither Rust or C maps well to the hardware level. But if you are new to Rust, and to programming in general (which you probably are on a university) might that not present a significant challenge, even though the final product is better? Learning non-trivial language semantics on top of hardware abstractions and OS concepts, is that the right choice for *learning* OS'es?
Then why even use Rust?
Hi, So what is the fixed example with 2018 edition? Because the following does not work for me and I get a compilation error. 10x, Israel `error: cannot find derive macro \`Deserialize\` in this scope` `--&gt; app/test_it/src/main.rs:21:21` `|` `21 | #[derive(Serialize, Deserialize, PartialEq, Debug)]` `| ^^^^^^^^^^^` `error: cannot find derive macro \`Serialize\` in this scope` `--&gt; app/test_it/src/main.rs:21:10` `|` `21 | #[derive(Serialize, Deserialize, PartialEq, Debug)]` `| ^^^^^^^^^` `error: aborting due to 2 previous errors` **Cargo:** `...` `preferences = "1.1.0"` `serde = "1.0.88"` `serde_derive = "1.0.88"` **Code:** `use preferences::{AppInfo, Preferences};` `use serde::{Serialize, Deserialize};` `const APP_INFO: AppInfo = AppInfo{name: "some_test", author: "somebody"};` `#[derive(Serialize, Deserialize, PartialEq, Debug)]` `struct TestConfig {` `version: u32,` `value: u32,` `}` `fn main()` `{` `let c = TestConfig { version: 1, value: 7, };` `debug!("conf={:?}", c);` `let file_path = "/Users/israel/conf-test/conf-test.cnf";` `let save_result = c.save(&amp;APP_INFO, file_path);` `assert!(save_result.is_ok());` `let c2 = TestConfig::load(&amp;APP_INFO, file_path);` `assert!(c2.is_ok());` `assert_eq!(c2.unwrap(), c);` `}`
For all the other code you write that doesn't require it? Making a safe interface to an unsafe datastructure could be a good assignment as well. Plus the tooling is better and usually you get error messages instead of segfaults.
Thank you so much for the kind words!
It would be nice if the scaling could be configured. Less than half of the game fits on my screen without having to scroll.
Can you create a working code that show the problem? Because having some code reproducing your issue would help a lot and remove any ambiguity.
I haven't been able to update my nightly for days, maybe weeks. It says : "some components unavailable for download: 'clippy', 'rls'". It this some temporary known issue on nightly or is something wrong on my side ?
If I remember back to my intro courses, the very first starting stuff concentrated mainly on "programming" concepts, while later on in another course we learned more of the technical background from the operating system &amp; hardware side. I think in a super introductory course, Rust would be a hindrance because it forces you to think a lot about the technical background when you don't actually want to burden your students with too much of that _yet_. Many students struggle enough to grasp all of the basic programming language concepts, stacking the hardware &amp; OS worries on top of that may be counterproductive. However, once the students are over that initial hump and have a basic grasp on programming, they do need to learn about the OS &amp; hardware side of programming - that's where I think Rust would absolutely shine as a teaching language because it ties some otherwise abstract concepts (everything around memory management, stack/heap, pointers, memory-related errors) directly into programming itself.
Never mind, everything is stated on rls's github page. [https://github.com/rust-lang/rls#error-component-rls-is-unavailable-for-download-nightly](https://github.com/rust-lang/rls#error-component-rls-is-unavailable-for-download-nightly) You can find the latest nightly with rls support here : [https://mexus.github.io/rustup-components-history/](https://mexus.github.io/rustup-components-history/)
I started with Java and was super annoyed by its inconsistencies, its distinction between primitives and objects, and so on. I think the best for learning would be something without much syntax sugar but internally consistent. Python has a lot of sugar and hidden behavior, however all of this is rather hidden in normal code. C has no sugar but it's annoying to work with given its segfaults. Hmm
The lack of scaling and the weird text editor immediately defeated me.
You can download the full code [here](https://www.dropbox.com/s/ieysspidlx6hrhf/rbc.zip?dl=0). I don't expect you to have [ROS](http://www.ros.org/) or [rosbridge](http://wiki.ros.org/rosbridge_suite), installed. If you actually do, start the rosbridge tcp stream with `roslaunch rosbridge_server rosbridge_tcp.launch.` If you don't just run the exemplary server in src/bin with `cargo run --bin server` And the client in src/bin/main.rs with `cargo run --bin main`. Short explanation for the main: use rbc::msgs::geometry_msgs as g; fn callback(data: &amp;g::Point) {} fn main() { let mut rbc = rbc::RBC::connect("127.0.0.1:9090"); // 1 rbc.subscribe("/rosbridge/test", callback); // 2 let p = g::Point { x: 1., y: 2., z: 3. }; // 3 rbc.publish("/rosbridge/test", &amp;p); // 4 } * 1 calls the connect function seen in my original post, in src/lib.rs * 2 only saves an entry of another struct and the function pointer in a hashmap, ignore for now * 3 struct that is serialized to json and * 4 send over the websocket on a "topic", an identifier for the server, in very basic terms (this part works though)!
I started learning javascript, then python, then rust and I encountered significantly more frustration refactoring and debugging in javascript and python than with Rust. From my perspective you deal with the correctness of your program either way: before compilation with Rust or later with other languages. True other languages have more learning resources but rust has actually descriptive error messages and strong typing combined with an IDE can introspect variables types and this may result in deep grokking your problem domain.
To quote myself: &gt; You just put serde = { version = "1.0", features = ["derive"] } in your Cargo.toml the important bit is `features = ["derive"]`
Our backend is primarily written in Rust, but the Stackdriver stuff is the main integration with GCP. We don’t use other GCP services because we don’t have a need for them in this project. 
Considering how rarely doubly linked lists are useful in the CRUD apps most developers will write for a living, I don't think that's going to be very much of an issue. 
I work on HTML parser to nodes - maybe will try to add SDL2 and display some kind of visual presentation. On other words very simple browser ;)
[WebRender 0.60.0](https://crates.io/crates/webrender/0.60.0) is up on crates.io (thanks to the continued work of the whole Mozilla gfx team and volunteer contributors). There is no particular highlights in this release (lots of bug fixes), we're just trying to remember to push snapshots regularly.
I haven't run the code but I think it's due to how you used RBC fields. You wrote `rbc.reader` rather than `&amp;rbc.reader`: owning a struct field will cause the struct to become unavailable and thus go out of scope, and thus its `drop` gets called. Example: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9ec824e3d8bd42e1849708538c30c049
Building a small program that emits MNDP query packets on the network and listens for the replies of Mikrotik access points. When it sees one that is still on it's default address, it SSH's into it and programs it with our site setup. It allows you to take a brand new access point out of the box, plug it into the network and wait 30 seconds and ta-da, configured. So this was an interesting mix of UDP sockets, SSHlib crates, opening files, and my favorite crate, clap, which lets you make tiny programs with easy parsing of command line arguments and help.
Ah, I see.
I agree, but the op is in college and they usually go through ll and graphs. 
It also fun to watch. Especially, famous projects with long history. 
&gt; anything involving immediate values I'm not sure I follow you arguments against immediates. 
Ah, yes. Sorry.
which instance are you talking about exactly? &amp;#x200B; Wouldn't the compiler catch this? My code compiles with no issues and no borrowing/moved errors
Added!
Yes, please do that! No need to invent the wheel twice! 
I've also been in a program that used java as a teaching language. It's doable and there's material, but ultimately it just combined annoyance with uselessness. It's ridiculously verbose but not in any useful way and the runtime is so bloated that benchmarking becomes hard and the tools aren't as portable as they pretend to be and installations are invasive. Only useful target seems to be some enterprise servlets or whatever they're called now. I'd probably advocate python as a general purpose language because it lets you demonstrate just about anything and lets you get useful things done immediately from line one. Rust is a very tempting candidate to replace that, though. Teaching any UI programming with it might be one hurdle. Otoh it does stretch down to embedded systems now. In some environment, python might do that as well, though. Down there, the recipe of at least one assembly language and C is still pretty much the only available option.
The compiler should disallow that because RBC implements Drop. You should get this error instead: https://doc.rust-lang.org/stable/error-index.html#E0509
I think the problem is that `RBC::drop` is called before the `drop` methods for its members. See the output of [this code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=dcb1daed767daf6e1a732fbdbe315ab6). It has to be this way because `RBC::drop` takes `&amp;mut self` so it needs to be able to access all of its members.
The culture of 'lets hack something together in C until it compiles and passes a few rudimentary tests' might make you pass the class, but yet another example of why we as an industry suck so bad. We desperately need to get away from such footgun-prone languages! &amp;#x200B; And no, I don't think Rust is a good choice for a first language. Better than C, yes, but I think for a first language people would be better off with some high-level managed language like python, Java, C#, or maybe even Javascript (or Scheme, if that floats your boat). But by the time when you reach some place in your curriculum where you need an unmanaged language, I think it'd be better to teach Rust than C or C++.
Looks like it. But why is that? I have this spawned thread with an endless loop in one of it's members. And more importantly, what can I do to get the intended behavior? 
use .iter_mut()
It has to be that way because dropping invalidates the members, but the struct's drop method can potentially access those members. For example, if one of the members is a `Vec` then the memory the `Vec` points to will be freed, and trying to access that pointer afterwards is invalid. c++ appears to be the same order: https://docs.microsoft.com/en-us/cpp/cpp/destructors-cpp?view=vs-2017#order-of-destruction Java does not define the order: https://docs.oracle.com/javase/specs/jls/se8/html/jls-12.html#jls-12.6
I completed 100 PRs to the Rust ecosystem (mostly Clippy) this past week and wrote a blog post about it: https://phansch.net/2019/02/18/onehundred-rust-prs/ I don't think it's particularly interesting, but it helps with my impostor syndrome when I look back at what I've done in the past year. This week I want to focus on improving the Clippy contributing instructions to make lint writing easier. I have an initial version on [hackmd](https://hackmd.io/ENi5W7SyRqSHCKIKD5mrFA#) that I want to flesh out.
&gt; Looks like it. But why is that? This way, you have the choice of when to finalize/drop any members. For example, you could replace a `Vec` with an empty one, causing it to be dropped early. If drop was called after the members' drop, many cleanup actions would be impossible. Imagine a socket member; if you wanted to do some cleanup involving sending a message out on the socket, it would be impossible to do in drop if the socket was already dropped (i.e. closed). &gt; Also, isn't it the other way around in most languages? Java, C++, etc...? Aren't the members destroyed before the class itself? At least in C++, members are destructed after the parent.
Hi, Thank you for your prompt answer. It was incorporated in the edited version above. BR, Israel
It's literally impossible for me to enter a minus sign with a German keyboard layout...
Still working on [Eko](https://github.com/eko-lang/eko), a simple scripting language written in Rust. I’m in the middle of a rewrite tho :(
Once you've learnt rust, you write C like rust. I'm not sure you can call C the lowest-level language - you have to use its ABI so there's no opportunity for more efficient struct layout, for example. It might be the simplest. I've thought about whether you could teach rust firstly using raw pointers/unsafe, then moving on to references and safe aliasing.
Itertools has [`.update()`](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.update)
Ok, so how can I force rust to keep all members in RBC alive as long as the last connection in either WriteHandler, or ReadHandler (in this case: endless loop) has happened? Do I need to add a lifetime for this then? 
Thanks, but no, I need to iterate by value, it's just that I need to modify the values. References won't cut it in this case.
Ahh that's awesome, thanks!
I don't think java is a good language for writing data structures because there is no lifetime management - just GC. I wish I'd learnt data structures in C/Rust, then realized in java I just create resources and forget about them. Java just seemed like magic in that regard, and probably teaches you to write inefficient code.
[https://crates.io/crates/anevicon](https://crates.io/crates/anevicon) [https://github.com/Gymmasssorla/anevicon](https://github.com/Gymmasssorla/anevicon)
Still actively contributing to https://github.com/svenstaro/miniserve :) Next big feature will probably be the upload. If you have any suggestion, please feel free!
Did you make sure (or intend) to implement `Preferences` for `AppInfo`? impl Preferences for AppInfo { fn save(/* */) -&gt; Result&lt;/* */&gt; { /* */ } } Since you seem to be trying to store config data or something, I would recommend that you use the [`directories`](https://crates.io/crates/directories) crate for deciding where files should go instead of dumping stuff in the home directory. `directories` will select the right place to put caches, program data, config files and more on Windows, MacOS, Linux and other platforms. [Here'](https://docs.rs/directories/1.0.2/directories/)s a link to the documentation, since it's not included on crates.io.
&gt; Do I need to add a lifetime for this then? No, adding lifetimes doesn't change how long things live. It only helps the compiler check that they are living as long as they should. Stop trying to use drop. Use normal methods that have the control flow you want. For example, something like: impl RBC { fn finish(&amp;mut self) { self.writer.join(); self.reader.join(); self.unadvertise(); } }
No, you'll get them (and your own package's) through `cargo doc`, `rustup doc` is only the compiler / stdlib documentation.
&gt;For example, you could replace a Vec with an empty one, causing it to be dropped early. I'm trying to imagine this scenario. A simple member variable of type Vec? &amp;#x200B; I still don't quite understand, why the drop of RBC is called at all? the reader member variable is never done processing due to the endless loop in the new thread.
And when would I call this? Would I have to catch ctrl-c pressed by the user? 
&gt; Also, isn't it the other way around in most languages? Java, C++, etc...? Aren't the members destroyed before the class itself? Not that I know, it's pretty necessarily in that order since by definition the parent retains a reference to the child, and thus prevents its destruction. Advanced runtimes may "bulk up" the finalisation of the entire subgraph, or not finalise it at all (at program termination), but they're not going to finalise the children before the parent. e.g. in CPython class A: def __init__(self, name, c=None): self.name = name self.c = c def __del__(self): print("del A %s" % self.name) super() A(0, A(1, A(2, A(3)))) will destroy the objects from "the outside in" (parent to child) in CPython.
You would call it instead of dropping the RBC. I assumed you were already doing that at the correct time... I don't know enough about the problem domain to be able to advise, sorry.
Thanks for the clarification
&gt; isn't it the other way around in most languages? Java, C++, etc...? No, and I don't think destructors works that way on _any_ language since that would make them useless. It seems that you have a fundamental misunderstanding about how destructors works, it might be probably better for you to address that in some language that you are more familiar with, instead of trying to address that and learning Rust at the same time. 
What music did you use? I want to use this while at work :)
At least they declare their intentions! My 2 year old borrows things left and right, but then does really, really unsafe things with them...
\## No. But you should be fine. \- New programmers hardly know what a string or data structure is, much less a library. \- Borrow checker can easily become a blocker once a true beginner thinks "let's try and build that thing called a linked list" \- Types can be confusing upon very first sight too. You're not programming for the first time though. So you're not a beginner. This is your third language, technically. You should be fine. &amp;#x200B;
You seem to be quite knowledgeable about this so I have two questions, in case you happen to have thoughts :) 1) Does this also improve cache efficiency (besides just memory usage)? I guess this is another way of asking -- are CPU caches keyed by physical or virtual addresses? That is, if a program refers to the same physical address using N different virtual addresses, will the cache store only one copy of the cache line, or N redundant copies. (If it does improve cache efficiency I could imagine this *improving* execution times in some circumstances, though apparently that didn't happen for any of the actually-performed benchmarks...) 2) Much more open-ended: In the context of a language runtime which is "in on the conspiracy", rather than a transparent `malloc` replacement, I wonder if there are any interesting further improvements which could be made or synergies which could be exploited? Obviously in the general case such a language runtime could be an arbitrarily sophisticated compacting GC in which case the question is probably not very interesting, so maybe let's restrict it to otherwise-non-compacting mark/sweep or reference-counted ones...
Apart from my misunderstanding of the order, why is drop called at all in this instance? I still have the active member variable "reader" with an endless loop in a separate thread in RBC. 
Got my Gameboy emulator working on wasm. Code will be coming soon (after I clean it up and comment it) but feel free to give it a [try](http://107.20.134.212:9998/) now! (You'll need to supply your own rom if you want to play something interesting. The default rom is a freeware homebrew.) Right now, all my favorite games are playable, including Mario Land 2, Kirby's Dreamland 2, Pokemon, Tetris, and Link's Awakening. Let me know if you found some others that work too. It's pure rust-based wasm made using the excellent wasm-bindgen and web-sys. No emscripten and a minimal amount of JS for handling the rom files and keyboard events.
how can i have a mutating collection without reallocations? specifically pub struct Screen { pub components: Vec&lt;Box&lt;dyn Draw&gt;&gt;, } impl Draw for butt { fn transform_lab(mut self: Box&lt;Self&gt;) -&gt; Box&lt;dyn Draw&gt; { Box::new(label { x: self.x, y: self.y, text: self.text }) } } impl Draw for label { fn draw(&amp;self) {} fn transform_lab(self: Box&lt;Self&gt;) -&gt; Box&lt;dyn Draw&gt; { self } } let sc = Screen { components: vec![ Box::new(label { x: 0, y: 1, text: String::from("fawfa") }), Box::new(butt { x: 32, y: 0, text: String::from("fawfaw"), act: Box::new(|x: i32| { let y = x + 1; }), }), ], }; let mut sc = Screen { components: sc .components .into_iter() .map(|i| { let c = i.transform_lab(); c }) .collect(), }; but into_iter requires collect() and reallocation of the whole damn thing. ???
What happens at 2:35 when the bubble in the upper right corner suddenly gets smaller? 
Is there a resource that shows what is coming in the next version of Rust? I checked the rust repo on GitHub thinking the release notes would be updated on the branch for the next version but they don't appear to get updated until right before it ships.
I'm guessing it'd be transmitted as a text-form array litteral, in which case one would want to use `WHERE mycol =ANY($1)`, which would resolve into something like `WHERE mycol =ANY(’{"foo","bar","baz"}')`.
I'm on my phone at the moment so I can't checkout your code. But in your example it looks like the new thread is spawned and then main immediately exits. When main exits I believe it doesn't wait for child threads to finish processing it just begins immediately cleaning up the program, killing the child threads and dropping RBC. If you want it to not be dropped you need to join on the child thread in order to stop main from exiting (or just put main in a loop, but joining gives you the option to stop running later). Sorry if you're actually doing this in your main implementation, that's just what it looks like from the code snippets.
Yes, that has occured to me. But allowing the user to choose implies that he knows what kind of input he has at hand, which is probably never the case. So there would have to be some way to stop the algorithm from running forever anyway. A timer would be the easy solution, but it's unreliable.
The following example I got from the rust book compiles on the website but not locally. I'd post the compiler errors but there are many all over the place. If I add parameter names to the trait method contains all problems are fixed, I'll add the working code in the comment below. rustup says stable-x86_64-apple-darwin. Did something change in the syntax happen and the book is not updated? struct Container(i32, i32); trait Contains&lt;A, B&gt; { fn contains(&amp;self, &amp;A, &amp;B) -&gt; bool; // &lt;- works only on website fn contains(&amp;self, a:&amp;A, b:&amp;B) -&gt; bool; // &lt;- works everywhere } impl Contains&lt;i32, i32&gt; for Container { fn contains(&amp;self, number_1: &amp;i32, number_2: &amp;i32) -&gt; bool { (&amp;self.0 == number_1) &amp;&amp; (&amp;self.1 == number_2) } 
What’s rustc —version? And also, where in the book? Is the edition key set in your cargo.toml? (This syntax was deprecated, but I don’t remember the exact details, nor did I think I included it in the book...)
I haven't looked too much into that yet, but at least monadic predicate logic is too limiting, especially when it comes to formalizing natural language. Sucks.
There are often PRs for updating RELEASES.md; here’s the next one, for example: https://github.com/rust-lang/rust/pull/58227
Hmm... 1. What installer did you use? Even it's the regular Rust you only need to download &lt;300M of stuff. If you're working with embedded, you probably don't even need that much. 2. About that high resistance thing. First, if it's a book by a software engineer, ignore it. Second, high resistance and high impedance pretty much mean the same thing in reality. You adjust the impedance by selecting different resistors in the mcu. The only problem is you don't really hear people say "high resistance" so you might get confused a bit. 
You can't blame the language for a single stupid book… rustup is just a convenience script, you can install rustc manually as well to whereever you want, but that's more work then. I checked my installation, 277MB of it are just documentation. When you're on shitty hotel WiFi, that's something you should actually appreciate. 155MB are the libraries. In total, it's only half a gig here, which is still quite a lot though. The rest I didn't mention is the compiler itself.
I love how many names there are for DoS tools. "Load generator", "stress tester", "ion cannon", "traffic generator"... Yeah intention is probably not to be used for DoSing but they are functionally the same as a DoS tool
&gt;It's not fucking High Resistance. It's fucking High Impedance and cannot possibly be confused with resistance. Unless you have an Arduino sketch level knowledge of hardware. I agree that it technically should be high impedance. However as you obviously know this information to be incorrect you could have submitted a pull-request to the repo in order to fix the documentation or you could have at least opened an issue that someone might want to look into this documentation again. Instead you chose to insult the contributors of the rust-embedded book, which I am sure have invested a lot of time and effort into creating it, by implying that they only have very basic understanding of embedded electronics. As an open-source project Rust depends on the contributions made by all members of the community. The Rust community is known to be one of the friendliest and most welcoming communities as far as programming languages go. If you have nothing nice to say, you probably shouldn't say anything at all, regardless of how much industry experience you have. 
Oh. You're opening a door to the topic of Rust as a really good cyberweapon building tool. Please shut it down before it is too late...
Speaking of, I wonder if there's a good crate similar to what Scapy is in Python... 
So I believe you are asking for 1: choosing where to install the rust tool chain 2: a smaller rust tool chain and 3: a small fix in an unfinished book? 1 and 2 sound like reasonable concerns that some people have but I would encourage not giving a strike for 3, it's fixable, you could write up an issue in a few minutes and it would likely get fixed (under the assumption that it actually is a bug/error/mistake) _eventually_, if you wrote a pr it would probably be reviewed and merged within a few days (guessing, haven't actually sent any prs, for all know they're swamped and it would take a while). https://github.com/rust-embedded/book ~mobile so bad formatting. 
So your major complaint is with the size of the toolchain? My `.rustup/` contains around 850MB of stuff. In it is a lot of documentation. Another of your complaints is, that there is an error in a book that utilizes the language? &amp;#x200B; What exactly is your problem with the language?
I just closed the [SPPM ticket](https://github.com/wahn/rs_pbrt/issues/86#issuecomment-464720592). All fours phases of a single **Stochastic Progressive Photon Mapping** (SPPM) iteration are now multi-threaded and thread-safe, but it's still not as efficient as the C++ code: https://discourse-cdn-sjc1.com/business5/uploads/rust_lang/original/2X/4/4f49a98a8561ad415c3cd011f45fa6fb28431ebd.png Anyway, I think I will clean up a bit and prepare a **new release** this week ...
Oh wait, its not "the book", its "by example". https://doc.rust-lang.org/stable/rust-by-example/generics/assoc_items/the_problem.html
I wrote a program to clear the whole grid, until the game froze on level 8 :( MOV 1 M NOP NOP RCC CLEAR: MOV -5 H LOOP: MOV H M MOV 0 M ADD 1 H MOV H A SUB 6 A JNZ LOOP RCC MOV 1 M MOV 0 M RCW JUMP CLEAR
Ah, well that’s a bug. Mind filing one? :)
I prefer to see it as load testing as a service 
I followed the exact installation procedure in the Embedded Rust Book as it was a week or two ago. It installed 872MB to be exact. And no. No. Resistance is not the same thing as impedance in reality and no you do not adjust impedance by selecting resistors inside the MCU. You may be confusing pull-up resistors with changing the i/o state of the pin. This is incorrect. An open-drain output will float and the pull-up brings it to a known state.
Given the ridiculous levels of Rusticle evangelism you better believe you need to get things exactly right, especially when the embedded space is one of your prime targets. Wait until you encounter a crusty old radar or analog engineer if you think I wasn't nice. I'm very nice. I love Rust's appearance and the promises of correctness. But if you want to appeal to more than the next-shiny-thing-Millennials you need to up your game.
I'm not sure what the bug is, that its an old syntax, or an old rustc on the website, or both?
None at all. My time is valuable and if you want to convince those of us who have seen many languages (including ones we love) come and go in a flash you need to make things easy and direct and correct. Putting the software where \*you\* want to put it - no go. Huge downloads? Possibly livable but needs looking at. Confusing fundamental hardware properties when you're specifically targeting embedded engineers? Tsk tsk.
https://github.com/rust-lang/rust-by-example should not use an example with old syntax, so filing there is right. Thanks!
The Rust community is not a unified bloc. For a while, we had a great deal of frustration from having to clean up after enthusiastic people who thought they were being helpful by bothering various projects about rewriting in Rust. If there's a problem with the embedded book, the best way to get results is to report it in the place where the people who work on it are most likely to see it.
&gt; I'm very nice. As exhibited by dropping f-bombs? It seems like you got a little upset there. &gt; But if you want to appeal to more than the next-shiny-thing-Millennials you need to up your game. Yeah, but things don't magically appear out of thin air, someone has to check for and correct errors. In a project like Rust that can be everyone.
Correct. I like you. You don't seem like a typical snowflake. However - Rusticles are making a push for the embedded space. You are trying to convince me and people like me to give Rust a chance. I have no interest in trying to fix mistakes - yet. If I get into Rust I will happily submit PR/bug fixes as I do on many open source (and even proprietary..) projects. But I have to be able get into Rust first and climbing over barriers that don't need to be there impedes that.
You can use ADD 1 M
I assume that [this PR](https://github.com/rust-lang/rust/pull/53860) was responsible for that, migrating at least **2,481** files from `run-pass/` to `ui/`.
Rust is not an easy language, tho. If you do not want to invest time, you are going to have a hard time anyways. But this fact is stated multiple times by the community any several ways. &amp;#x200B; No offense, but your complaints feel uneducated. Getting fast into stuff always sacrifices something (as you should know as an embedded software engineer). Maybe you just read through the book and see if you like language regardless.
Oh, I like immediates and think they are rather important. What I don't like is how risc-v handles them. They have optimized for small values (12 bits) which sounds reasonable, but severely hampered the use of large values. This seems to have been in an effort to have fixed 32-bit instruction size, but then they added compressed and blew the fixed size anyway. I'd prefer if the instruction word was just that, and any immediate data came after. Once you do this it only takes a couple bits in the instruction to encode the length of the immediate constant, but then it starts to look like variable length instructions - which they have anyway. There is also no JAL (jump and link) to an immediate absolute address, if you can imagine that. I'm not sure weather this is a concern with modern compilers an OSes, but it sure seems strange to me.
Thanks! I think I really meant testing M. The idea is to encode "move 3 steps" by putting 3 in M and decrementing until it's zero.
I'm joining in the drop implementation of ReadHandler. You're saying joining at the end of the main is a better option?
I write a fair amount of Haskell so I don't think Rust will give me excessive difficulty. Only terrible embedded software engineers rush into things. Especially those of us in safety/mission critical hard real-time systems. Paranoia, a great deal of control-freakism and care gets the job done and keeps people alive. And massive chemical retorts from spilling over...
Unrelated, but don't you use rustfmt? Are there any good reasons for not using it?
Drop is called when the object is dropped, whether the object itself has fields that are still in use or not doesn't really matter for that. 
Why not?
It's pretty different from Haskell. Some similarities to OCaml but you're still fundamentally using different data structures.
Probably `iter_mut().for_each(...)` or the equivalent `for` loop over `iter_mut`. That should work for now, but if you need interaction between entities then you're getting into entity-system or entity-component-system features.
Yes I would give it a shot. I don't know the exact details of Rust's cleanup process but what you're observing could be because when main exits it kills the child threads before beginning to clean up. This would cause the join in the drop to always succeed without waiting for the ReadHandler to finish what it was doing (since the thread was already killed). I would either add a join in publish so that publish never returns until the reader is finished, if ever, or I would add a finish method that joins on the child threads.
Cool thanks for the link. Just what I was looking for.
&gt; I'm assuming that I need to tell the compiler that I want the box where B and C are covariant over A, and u32 and String are be covariant over S. How do I specify this to the compiler? You cannot do this in Rust because it would require type information to be available at runtime. When you use a generic type, you must specify all of the types in its type parameters. You can sometimes use a type without specifying all of its type parameters if they are instead associated types: ``` trait A { type Output: Debug; fn foo(&amp;self) -&gt; Self::Output; } ``` However, to box `A` you must still specify its associated `Output` type. To get around this, you can introduce a second trait that has no type parameters nor associated types and then implement that trait for any types that implement the first one: ``` trait Print { fn print(&amp;self); } impl&lt;T: A&gt; Print for T { fn print(&amp;self) { println!("{:?}", self.foo()); } } ``` Now you can box implementations of `A` as `Box&lt;Print&gt;` and print them: ``` let test: Vec&lt;Box&lt;Print&gt;&gt; = vec![Box::new(B {}), Box::new(C {})]; for t in &amp;test { t.print(); } ``` 
tl;dr: If you run rust on top a faulty malloc implementation, it can segfault.
The conclusion is not really wrong, but is this information helpful? &amp;#x200B; I can argue that any language is unsafe, once it interfaces with hardware. Since memory is hardware, we have to rely on it to work correctly. If the RAM/CPU is not working correctly, all guarantees a programming languages gives you are kind of meaningless. So what am I supposed to do with this information?
In the 2018 edition, anonymous parameters are no longer allowed. You can read about it here: https://doc.rust-lang.org/stable/edition-guide/rust-2018/trait-system/no-anon-params.html and here: https://doc.rust-lang.org/nightly/reference/items/traits.html#parameter-patterns
&gt;Without being able to trust the allocators, we’d have no reason to trust the safety guarantees made by Rust. I'm not sure if this is a joke.
&gt;we had to do linked lists in c and memory leaks were treated as incorrectness, so ownership was still a thing. it just wasn't enforced by the compiler. Which basically means it wasn't enforced at all, unless you've implemented a borrow-checker too. It is common practice in C to return a pointer to an item in a linked list, but I've never seen an implementation that didn't just say "if you assume the pointer is valid, that's your fault."
Well, this conversation appears to be pointless. I don't really care to convince you as you already have made up your mind. **My final points to this post:** All your complaints are irrelevant after all. Especially after you dropped that you write a fair amount of Haskell, as if installing Haskell and it's packages does not take forever and is rather large in the end ... You blame a mistake in a book on a language ... bonus points for everyone who finds the direct causal chain without inventing some new kind of logic. *Strike 1* is just a confession that you put more time into writing your *"complaints"* than into researching on how to do what you want to do or relying on the comfort of rustup and complaining now that it did not what you wanted it to do ...
Does anything actually use it?
I don't think you understand what a scripting language is for.
Some discussion on internals: https://internals.rust-lang.org/t/blog-series-generators/9410
I'm trying to promote Rust as an alternative to C# at my company (aside: I love C#; I just think Rust makes more sense for some of the services we're building), and I've gotten positive feedback all around. I want to build some PoC pieces for internal review, but we have a number of foundational pieces that would need to be built first. I'm struggling with taking some C#/OO concepts and making them idiomatic in Rust. For instance, I have a class that finds a configuration file on the server at-or-above the current directory: public sealed class ConfigurationFileLocationService { public FileInfo FindConfigurationFile() =&gt; this.FindConfigurationFile("config.xml"); public FileInfo FindConfigurationFile(string filename) =&gt; this.FindConfigurationFile(ConfigurationFileLocationService.RootDirectory, filename); public FileInfo FindConfigurationFile(DirectoryInfo searchDirectory, string filename) { // Code omitted } } I've ported the logic into Rust without much effort, but I'm not sure this is the right way to do it? pub fn find_configuration_file(mut searchPath: PathBuf, filename: &amp;str) -&gt; Result&lt;PathBuf, std::io::Error&gt; { } I really like having overloads with parameters (so if I don't care, I can use the defaults). I'm also not sure where to put this method--does it belong in a module by itself (mirroring the C# factory-like pattern) or in a shared module dealing with all the configuration concerns?
Thanks a lot! That fixed it! Wow, i did learn a lot from previous suggestions, but it did take a while until someone found the solution.
/r/playrust please
I don't need you to convince me, snowflake. I'm already nearly there - that's why I want to try it out. Instead, after all the yammering by Rusticles about quality this and quality that I hit one annoying thing after another. I don't use Haskell for embedded software work. And indeed dealing with Cabal and even Stack is often a mind-bending clusterfuck that would be comical if not so enraging. But y'all are selling Rust as a solution to the embedded space: safe as Haskell, as fast and small as C. That gets my attention. Your execution leaves lots to be desired. So fix it.
I'm sorry, but seeing Austin Powers in the thumbnail and "load generator" in the post title is conjuring up some naughty thoughts for me. :/ However, "most powerful" makes it even funnier, since it sounds like one of Dr. Evil's contraptions.
"Cyberweapon" omg
&gt; But this example does highlight an assumption of Rust’s memory model that I haven’t seen discussed much: safe Rust is safe if, and only if, the allocator it relies on is “correct”. And because writing an allocator is fundamentally unsafe, Rust’s promises will always rely on some amount of “unsafe” code. It is discussed. A lot. It's the entire point of safety in Rust. The issue here might be that you're focusing on allocators in particular, but there's no reason to constrain it to such things. Safe Rust isn't just safe if the allocator is correct, but rather, safe Rust is safe if and only if _all_ uses of `unsafe` are correct (among perhaps some other "details", like, "the borrow checker is correct"). This is the fundamental value proposition of Rust and it is the key invariant that anyone who uses `unsafe` must uphold. This isn't a "wat." It's not a gotcha. It's not a dismissed detail. It's _the point_.
So this guy claims to write a program that segfaults in safe Rust, but the reason for the segfault is that it uses a deliberately broken memory allocator written in _un_safe Rust. This is supposed to prove what exactly?
I thought this tl;dr was a joke but...tl;dr it's not.
As for Solution 1: Function adapters, would it work like this? for _ in generator().iter() {} Or for the try result case: for _ in generator().try_iter() {} These methods would live in two different traits with respective blanket impls in the std prelude. Or in case the compiler generated generator, make them auto generated inherent methods. 
i mostly don’t buy the idea the javascript/python/lua etc are innately easier than statically typed languages, so given that, yes, i don’t understand what scripting languages are for. but ignoring that, i feel like amethyst in particular loses it’s value proposition if you use a scripting language with it. better to make a game with unreal, unity, or godot at that point. what makes amethyst appealing, to me anyway, is the combination of performance, safety, and rust. 
"Safe Rust code can crash and I can prove it. I hacked up a special Linux kernel that crashes every time you call `write(2)` from a process named `crashme`. I then wrote `crashme.rs` that did a `println!` and my 'safe' Rust program crashed. Mind you, I'm not claiming that this makes Rust unsafe. (I'm claiming this makes Rust unsafe.)" I mean, OP is not wrong that it would be better if the Rust memory allocator was written in safe Rust. Currently, calls to the memory allocator are `unsafe`, and most Rust programs make calls to the memory allocator under the hood. OP's "trick" won't work with a `nostd` program with no `unsafe` code: if you let the Rust compiler prove the memory safety of *everything* your program is memory-safe (up to compiler bugs). I just don't think this is a particularly informative or constructive piece. OP is not wrong…
Yeah, Rust is a really good instrument for building security applications since it is fast and at the same reliable. I think we'll see more programs in Rust like sqlmap, Burp Suite in near future.
&gt;I really like having overloads with parameters For this case, a enum is the best way. &gt;does it belong in a module by itself That is certainly the idiomatic way on rust. Make it global make sense if all is in the same crate. Otherwise, put in his own module.
I hadn't considered an enum, but that makes so much sense and is a lot more descriptive as to what is happening. Thanks!
what are you talking about? for s in sc.components.iter_mut() { *s = s.transform_lab(); } cannot move out of borrowed value. is there literally no way to do this with iterators?
I'm glad that fixed it!
See also: [https://www.producthunt.com/posts/anevicon](https://www.producthunt.com/posts/anevicon)
&gt;amethyst in particular loses it’s value proposition if you use a scripting language with it &gt;what makes amethyst appealing, to me anyway, is the combination of performance, safety, and rust. You don't lose performance, safety, or Rust if you use a scripting engine, so I don't see why you think Amethist loses anything by gaining an orthogonal feature. &gt;better to make a game with unreal, unity, or godot at that point. 
Rust stdlib uses methods with different names, so you'd have find_file(), find_file_in_directory(..). Alternatively you could use Into trait (example: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c3c62e1bd5d0471617effbd7486e0b4e , I'd use &amp;str instead of String and Result but I wanted example to be simpler to read) and get sort of method overloading. As to where to put it - I'd suggest utils::configuration module. Separate create maybe if you share it between projects. 
Why do you need the lifetime on `TrieView`, it doesn't look like you are using it. Then you could just use `type View: TrieView&lt;K, V&gt;`. No GATs needed.
I definitely don't want to implement Copy for it, because it is a large structure, embeds references to graphics devices and windows, and can't safely be copied.
You haven't even met the borrow checker, and you're already giving up! I suppose you think that with 40 years of experience, Rust will be a stroll in the park. Your expectations are unrealistic! You will have to apply much more time/effort than that. And this is not because no-one has tried to make it easy for you (they really have), but just because coding in Rust means being forced to learn concepts and patterns that really don't exist in other languages (yet). If it doesn't seem worth the time and effort to you, we totally understand. Rust will never suit every coder, or every coding task.
Maybe function adapters could exist as a transitional thing, to avoid blocking on Chalk, with a plan to deprecate them once Chalk-based disjoint trait impls are available?
I'm not an embedded programmer, but for point 1, what installer did you use? I've never seen rust take up a significant amount of space on any operating system. Is it possible it was also downloading the msvc c++ build tools and your (I'm assuming) windows machine didn't have those already? Regarding point 2, if it's egregious you can make a pull request against the book to fix it. It may have been an oversight or a legitimate misunderstanding by the author (again I'm not sure which of you is right), but a simple error like that doesn't seem like a reason to abandon learning a language. After all the book is not meant to be an introduction to embedded systems as a whole. 
Your language here is pretty flippant and incendiary. "Snowflake" is ironic when you're the one getting so upset over a simple typo in an unfinished book. Other comments you've used in this thread like "next shiny thing millenials" show a gross lack of respect for the community that's trying to assist you ,and others who follow, to have a better experience.
Would be my solution as well. Introduce the function adaptors from solution 2, wait for Chalk to stabilize, deprecate the functions later. This would create no dependencies between generator feature and Chalk, but still allows the best result in the end.
After Haskell, Ocaml, plain-jane old ML, Erlang, occam, Forth, APL/J/K/Q, Fortran, C/C++, Python, Lisp, PL/1, BASIC and more assembly languages I care to remember (oh yeah, VHDL and Verilog too), I doubt Rust would defeat me. My expectations are pretty clear and laid out in my post. You Rusticles want penetration into the embedded space. You have to deal with hugely experienced and capable people there, not Millennial snowflakes who think IoT is the pinnacle of the embedded world. (Or even more than an utterly trivial part of it, based on my conversations with OEM FAEs, manufacturer reps, and disties.) If you think Rust can replace C or C++ in embedded systems you better have a tight story to tell and not annoy the prospective customers along the way.
I have no idea how Google would prefer to handle it, so I cannot advise on that. Sorry.
yes they have scripting languages. that is my point. why use a beta niche engine behind your script instead of proven ones? maybe one day when people are reaching for amethyst for reasons other than it being in rust adding a scripting interface would make more sense.
I use Linux. And I haven't abandoned Rust yet, I've put it aside until you guys get your shit together. And it's up to Rusticles to make that happen. You're selling, I may be buying. Get it? Stop installing vast amounts of shit where I didn't want you to and don't make elementary hardware mistakes that make me believe you're nothing more than an IoT Millennial knucklehead. Then we'll see what Rust offers.
What's with all this name calling? Your insecurity complex is showing
We Gen-Xers despise Millennials and your even worse Baby Boomer parents. Luckily Gen-Z has a lot more on the ball. And nobody in this comment thread offered any help because there's none to give. I gave my reasons why it wasn't worth my time evaluating an over-hyped but possibly very useful language because of various annoyances. Fix those and I'll be back. In fact, don't fix 'em and I'll probably still be back. It's such a pretty language.
Indeed. Large/Huge pages (2MB/1GB) help a lot in alleviating TLB pressure... however they would also make meshing more difficult.
Until then, you'll probably just be ignored.
I tend not to like Millennials because as a generation you are the worst educated (albeit credentialed) in American history while being gloriously narcissistically unaware. You also have delicate personalities imparted to you by lengthy stays in day-care which have damaged you for a lifetime. Your Baby-Boomer parents have much to answer for.
https://github.com/rust-lang/rust/issues/50154 While this is a bug in the compiler, you'll likely also have a bug in your code as well because you probably aren't doing one of the following: 1) [enabling AVX2 by compiling with `#[target_feature = enable("avx")]`](https://doc.rust-lang.org/std/arch/index.html#dynamic-cpu-feature-detection) or 2) [compiling with the appropriate target features or target CPU](https://doc.rust-lang.org/std/arch/index.html#static-cpu-feature-detection).
Who hurt you?
First hint this is not to be taken seriously: `sudo cat hello.rs`
I'll get straight to the point and let you know: **rust is not for you**. The embedded area of rust seems pretty young from what I can tell (the book's github repo only has commits showing it being &lt;1 yr old), so it's unknown how expansive it is and how much it has (I'm not an embedded person, so I'll leave final call on that to them). With that considered, rust still can offer embedded systems some wonderful things with its borrow checker, lifetimes, speed comparable to C/C++, and so on. However, while the language itself can be a wonderful fit for embedded systems, I do not think you will like it. From what I have seen both in the post and your comments in the thread, if you are getting angry at a small typo in a very young book (still in progress), or at the installer and having to fight it, or even at the community as it stands, you will not enjoy rust. You will fight the borrow-checker. It will piss you off. Lifetimes will probably piss you off. And if you really don't have a lot of time on your hands, it will take longer than you are probably willing to spend getting past that point. Rust as a language has a really high learning curve and is not something you learn overnight or even in a week.
The embedded Rust installation process hurt me.
Am I missing something, but why is a simple Hello World program calling malloc?
A typo caused you to besmirch an entire generation of people. Surely you can see the irony of you calling everyone a snowflake.
The RAM thing is a reason some of us are paranoid about ECC. Similarly with disks and controllers and end-to-end filesystem checksums. Both have saved me from literally *thousands* of corruption events since I started using them, and so I wouldn't really consider doing anything serious without them. Yet people without these things frequently dismiss them as unnecessary. I suppose in this case it's a matter of not assuming you can't possibly have memory corruption. Your tower of purity still rests on top of a huge pile of ad-hoc unsafe gunk. Maybe the occasional smoke test with jemalloc debugging, dmalloc, or valgrind is worth a free moment.
Are you an early adopter type, or late adopter? (I mean early in the total lifecycle of the language.) I think you must know that as an early adopter not everything will be perfect but the product will have enough going for it that it makes the effort worth it. So, right now not everything is perfect when coding in Rust. Lots of things are still being worked on. But if you are an early adopter that is fine. The core is solid and more than enough to build shipping products on. Maybe some things (libraries, etc) that you need will be missing, but with your experience, it is easy to fill in those gaps. That's where Rust is right now. Alternatively you could wait and be a later adopter if you wish. Also, please don't underestimate the mental shift required to work with the borrow checker. Really it is not for everyone. The best thing is to try a small-to-medium sized project in safe Rust (not a tree or doubly-linked list implementation!) and see how you get on with it. You will be forced to change your coding patterns, so be ready for that. The ideas are now being incorporated into ADA and SPARK. I also have a pretty long programming history, and familiarity with some of the older stuff on your list and still it took me a few attempts to find the right approach with Rust -- and I'm still learning. Best of luck with it.
&gt; You seem to be quite knowledgeable about this so I have two questions Just enough to be dangerous, so take any answer with a grain of salt. &gt; Does this also improve cache efficiency (besides just memory usage)? I guess this is another way of asking -- are CPU caches keyed by physical or virtual addresses? It may depend on the CPU. What you are looking for is information on the [TLB: Translation Lookaside Buffer](https://en.wikipedia.org/wiki/Translation_lookaside_buffer), the component in charge of translating from virtual address to physical address. On Intel CPUs, a very fast TLB sits between the CPU and the L1 cache ([source](https://software.intel.com/en-us/articles/how-memory-is-accessed)) and will translate virtual to physical within 0.5 - 1 cycle, if cached. This means that for Intel, caches deal exclusively in physical addresses, so there is no copy of the data... however the mapping itself takes place in the TLB, and more pages mapped will decrease performance. On the (hypothetical) Mill CPU, a single virtual address space is shared by all processes and caches deal exclusively with virtual addresses; moving the TLB to sit between L3 and RAM, where latency matters much less. Normally, the trick is to switch to bigger pages -- Large/Huge pages of 2MB or 1GB instead of 4KB on Linux. Mesh would have to be adapted for large pages (2MB), and this may negatively impact its performance as checking if pages can be meshed, and meshing them, would require accessing more data. &gt; Much more open-ended: In the context of a language runtime which is "in on the conspiracy", rather than a transparent `malloc` replacement, I wonder if there are any interesting further improvements which could be made or synergies which could be exploited? That's a good question! In essence, Mesh is compacting memory, however the virtual address space is "leaking" and redundant mapping are polluting the TLB. My first thought therefore would be in having the run-time seek to evict all references to remapped pages, by rewriting addresses and freeing the old pages (would require dedicated function). However, at that point, the runtime is performing compaction, and so is behaving like a compacting GC already :/ I am curious to see what others would come up with.
I know... Cheesy right? Please give me a better word for next time.
&gt; Millenial snowflakes [https://www.rust-lang.org/policies/code-of-conduct](https://www.rust-lang.org/policies/code-of-conduct)
[Eh?](https://news.softpedia.com/news/new-linux-trojan-discovered-coded-in-mozilla-s-rust-language-508135.shtml)
Yes, there are very good crates for raw packet access and I've used them to implement a tcp stream hijacker (rshijack) with them.
`snedpacket`, `pnet`
Adding \`target\_feature\` made no difference, but is nonetheless the correct thing to do. Updating to a newer nightly fixed it though.
&gt;typo It's not a typo. It's a fundamental misunderstanding of the difference between resistance and impedance. This is something any competent embedded software engineer knows. And I actually got a claim from an earlier comment that it was ok to use it. No, it's not. And it's a natural conclusion that if you get such obvious stuff wrong I'm going to be very cautious about your other claims of safety, speed and size.
Luckily we're not on the rust-lang site, we're on Reddit. If the mods want to delete my post they are free to (hopefully they're Senior Rusticles who go back to the Rust Hive and fix the issues I raised). Don't tell me how to speak or think, Millennial.
ive tried to be polite and civil in this discussion. did i fail? you are likely correct though, plenty of ideas that don’t make sense remain popular and i certainly may just be entirely wrong.
I'm sorry that I took so long to respond, but I had to do take a bus and I don't have a data plan. This answer was as a result written in two sessions, which is why it is a bit disjointed. First of all, where did you get the name "Rusticle" from? Secondly, here's the answer to "Strike 1": &gt;Installation: The installer won't let me install where I want it to go which is a separate filesystem I use for 3rd party packages. I have to stop installation, delete crap and make symbolic links to where I want it. It's unfortunate that this isn't discoverable from the `rustup` installer itself, but there is a way to specify where `rustup` downloads itself and its toolchains to. It's documented in the [rust-lang-nursery/rustup.rs](https://github.com/rust-lang/rustup.rs) repository's [README.md](https://github.com/rust-lang/rustup.rs/blob/master/README.md). The [rustup.rs](https://rustup.rs) website does link to this repo at the bottom of the page, but it's not the first place I'd look either. &gt;**Choosing where to install** &gt; &gt;rustup allows you to customise your installation by setting the environment variables CARGO\_HOME and RUSTUP\_HOME before running the rustup-init executable. As mentioned in the [Environment Variables](https://github.com/rust-lang/rustup.rs#environment-variables) section, RUSTUP\_HOME sets the root rustup folder, which is used for storing installed toolchains and configuration options. CARGO\_HOME contains cache files used by [cargo](https://github.com/rust-lang/cargo). &gt; &gt;Note that you will need to ensure these environment variables are always set and that CARGO\_HOME/bin is in the $PATH environment variable when using the toolchain. Lastly, I'd like to cite a few points from the Code of Conduct which I believe you've been breaking at various points in this thread. &gt;Please avoid using overtly sexual aliases or other nicknames that might detract from a friendly, safe and welcoming environment for all. You've been calling people "snowflakes", "Millenials" in a way that's hard to interpret as anything but demeaning. &gt; Please be kind and courteous. There’s no need to be mean or rude. You seem to be somewhat aware of this one yourself, give that you said: &gt; Wait until you encounter a crusty old radar or analog engineer if you think I wasn't nice. 
Adding `target_feature` does fix it. Compare https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=7576669b70e0a35cebe053b9052b3a21 with https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=02d942f8b5ad2a47606883d2dca0c313
Mate, put in a pull request to the book instead of going of on an unhinged rant at everyone. You could have fixed it in the time you spent bellyaching. The book does not represent the language. The book is a work in progress. Have you never made a mistake before? Did someone shit all over your entire generation because you made a mistake? But really mister macho man who will "throatpunch" people , you seem smart enough to not bother with books written by millenials. So go back to your sad violent corner and ignore what everyone here is doing. It'll be better for your clearly waning mental health.
`stdout` is buffered, which requires an allocation. It's also synchronized with a mutex, which is boxed internally so the OS primitives aren't moved after initialization.
Huh, it does. I could have sworn I had no difference when I tested it on my machine, but I probably confused the results.
Still working like 50+ hrs a week and being utterly exhausted. This is the last week of that nonsense though! Maybe I can find the time to catch up on the bug backlog for ggez? Right now it feels like 80% of them are due to gilrs having crap platform support or winit being stubborn about hidpi, which makes me unhappy. I don't have energy to deal with those anytime soon though; I barely have time to keep up with what needs doing.
I work in safety/mission-critical hard real-time systems so late adopter is what I actually must do. But personally I'm an early adopter, trying out all kinds of new languages and approaches. I evaluate them in the context of eventually using them professionally. Or just for fun. In this case Rust has gotten so over-hyped and promoted for embedded systems use I decided to check it out. I had two annoyances and the third (temporarily) killed me. It's a fundamental misunderstanding, not a typo. If you spend endless time promoting Rust and make such a mistake it makes me question just how reliable are the claims of safety, speed and size.
The rust-lang site's code of conduct is a part of this subreddit's rules, albeit in a somewhat modified form. &gt;**1.Respect our code of conduct** &gt; &gt;See [here](https://www.reddit.com/r/rust/comments/2rvrzx/our_code_of_conduct_please_read/). TL;DR: we strive to treat others with respect, patience, kindness, and empathy. &amp;#x200B;
Being offensive is not really helping in any way. Just drop it. The people here are not really going to be affected much by it. Rust (and its community) doesn't have to prove itself to you or anyone. Okay, there is still loads of work to be done, but Rust as a language has already proven its value beyond doubt for very many people.
That isn't entirely true. A load generator or stress tester should try to model realistic traffic patterns, for instance by having controllable probability distribution for request spacing (likely to simulate a Poisson process arrival distribution). Though tellingly this crate doesn't seem to have such a feature...
Try using + instead.
I found the first example weird, why does one need to \`clear\` the \`String\` after the last line ? 
I just tested on my system, and found: a) You code works as expected in development; b) it gets the same wrong answers you get in release c) coding it inside an unsafe function, with avx2 feature gets right answers. d) removing AVX2 feature returns incorrect results. &amp;#x200B; I thinks its conclusive, you need AVX2 feature enabled. 
Source code: [https://github.com/00benallen/first-rust-game.git](https://github.com/00benallen/first-rust-game.git)
The fact that you get wrong answer here *is* a compiler bug though. See my original link, which does appear to be fixed in the latest nightly: https://github.com/rust-lang/rust/issues/50154
You're not wrong... but at the same time the conclusion is very limited. The safe portion of the Rust language is safe^1 regardless of `LD_PRELOAD` (or others) simply because a programming language is first and foremost a mathematical construct which lives outside the constraints of implementations. It's important to dissociate Rust the language from its possible implementations: - Formal reasoning at the language level are possible, regardless of the final implementation or platforms. - The behavior of various implementations on various platforms may deviate from the prescriptions of the language due to implementation bugs. Alright, but what about rustc 1.32 running on Linux on a default x86_64 host? Is it safe? **No**. There's no need for `LD_PRELOAD` tricks. There are currently 36 issues opened on the Rust repository tagged with [I-unsound](https://github.com/rust-lang/rust/labels/I-unsound%20%F0%9F%92%A5). Such an issue means that either the compiler may accepted unsound code accidentally, or it may mangle safe code. Notably, one issue is that LLVM consider infinite loops to be Undefined Behavior. Alright, but supposing a *perfect* implementation of rustc running on Linux on a default x86_64? Is it safe? **No**. It's pulling in C libraries from whatever distribution of Linux it is running on; most likely `libc`, which regularly has bugs. Alright, but supposing a *perfect* implementation of rustc and a *perfect* set of C libraries? Is it safe? **No**. It's running on Linux, and Linux regularly has bugs. Alright, but supposing a *perfect* implementation of rustc, set of C libraries, and OS? Is it safe? **No**. It's running on physical hardware, which may be faulty, or subjected to external influences (temperature, gamma rays, etc...), which may corrupt random bits. So what's the point? Well, as [ObliviousJD](https://twitter.com/ObliviousJD/status/1094456407376637952) puts it so concisely: &gt; I love Rust because it reduces bugs by targeting it’s biggest source... me. That is, while all those layers may be faulty, in practice they rarely are, and therefore the point of using a safe language is to address the biggest source of bug: us. ^1 *Or at least, it's expected to; various subsets have been formally proven but not the whole thing, and a few I-unsound issues are tagged T-lang.*
I'm using Piston 0.87 and glfw window 0.47.0, and I'm just about ready to throw in the towel on this one, as I can't find an answer ... I'm trying to call "window.draw_2d()", but I'm getting the following error: ``` win.draw_2d(&amp;event, |_c, _g| { } ); ^^^^^^^ the trait `input::generic_event::GenericEvent` is not implemented for `&amp;input::Event` | = help: the following implementations were found: &lt;input::Event as input::generic_event::GenericEvent&gt; ``` I haven't a clue how to fix this. Help!!
Why does the compiler emit functions for the AVX compiler intrinsics? An example is here: [https://godbolt.org/z/gLMIVA](https://godbolt.org/z/gLMIVA). It seems the body should turn into a few vmovaps and a vaddps but it seems to emit a lot of extra instructions including calls to the instrinsics. Is there a way to optimize the code generation there? &amp;#x200B;
Hmm, not fixed here. Still failing on nightly without AVX. ``` adrian@bastet:~/code/test/avx$ cargo run --release Compiling avx v0.1.0 (/home/adrian/code/test/avx) Finished release [optimized] target(s) in 0.30s Running `target/release/avx` [2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0] adrian@bastet:~/code/test/avx$ rustc --version rustc 1.33.0-nightly (daa53a52a 2019-01-17) adrian@bastet:~/code/test/avx$ ```
The fix was very recent, so your nightly is too old. It should work if you update it.
Currently working on converting Pushrod to use GlfwWindow as its standard rendering window, which seems to be more os-independent. Also working on implementing text and button widgets soon. 0.1.11 is the latest release, documentation is still (mostly) up-to-date. Could use eyes on the project, love to hear feedback from people to see if you find it useful. I'm hoping to have a more substantial test application soon, which will probably turn into a Sudoku game at some point; perhaps even Tetris. https://www.github.com/KenSuenobu/rust-pushrod/
Please read the issue I linked. In particular, see: https://github.com/rust-lang/rust/issues/50154#issuecomment-462948927 If it's really not fixed in the latest nightly, please try the example in the issue and post details. Include your Rust version.
Currently working on a simple html game made with Yew. Currently in the process of shifting code to better places and cleaning it up because past me for some reason decided that using tuples would be a great idea (Spoiler alert: They where not) Its my first project with rust and also the first time I write anything in a language without a garbage collector. So far I actually really like it though I do have the feeling sometimes that I am doing something in a non-ideal way but I guess that is just my inexperience with rust...... For those that are interested you can find it at : [https://github.com/lenscas/arena\_keeper](https://github.com/lenscas/arena_keeper) . Feedback is of course very welcome.
You're compiling without optimizations. The compiler [inlines those calls with optimizations enabled](https://godbolt.org/z/sCDv5j). 
Is there a risk that Chalk won't work out and they don't want to get locked into solution 1?
Ah, makes sense. I thought compiler explorer defaulted to release builds for some reason. Thanks!
Command line tool that sends UDP packets...?
I don't think you're being impolite or uncivil, but you are certainly presenting poorly reasoned arguments. For instance: Why did you say "beta niche engine?" If Amethyst gets a scripting engine, I don't see why it should match this description. Why do you think the existence of a scripting engine would make people *not* want to use Amethyst, rather than the opposite: that people would choose *not* to use Amethyst because it lacks a proper scripting engine? I don't think most people involved will have these hangups, so they will probably (and IMO, justifiably) ignore these kinds of arguments.
Last week I got a PR done to get [tarpaulin](https://github.com/xd009642/tarpaulin) and my coveralls-api crate working better with other CI servers. Hopefully, this week I can close that out then tackle the mysterious threading-test-segfault bug... As something to help me relax doing rust I'm also working on an ndarray based computer vision library. Basic image type is implemented, convolution and PPM serialisation/deserialisation. This week I hope to finish off my code for converting between different colour models, test what I've got more thoroughly, add functions to create common convolution kernels and move on to bigger things 
(citing post from internals) Honestly I am baffled by the last blog post. The whole premise sounds wrong. I think here: &gt; But we want to be able to make this into an `Iterator` with an `Item` of `io::Result&lt;usize&gt;` Author confuses "how we want to" and "how we are used to". I would like to argue that most of the code which uses `Iterator&lt;Item=Result&lt;T, E&gt;&gt;` stops iteration after the first encountered error. For example some of my code is plagued with lines like these: ``` for record in iterator { let record = record?; // process record } ``` This is why I've wrote this [proposal](https://internals.rust-lang.org/t/pre-rfc-generator-integration-with-for-loops/6625). And to me it looks like the author wants to set in stone automatic `Generator -&gt; Iterator` conversion, while the linked proposal argues that `Iterator&lt;T&gt; -&gt; Generator&lt;T, ()&gt;` is a much more natural generalization. But indeed there are cases when we want to convert generator into iterator. Why don't just add methods to `Generator` trait which will do the conversion? So instead of `iter::try_gen(generator())` we for example will write `generator().into_iterator()` for Iterator which will ignore result and `generator().into_try_iterator()` for iterator which will convert `Generator&lt;T1, Result&lt;T2, E&gt;&gt;` to `Iterator&lt;Result&lt;T1, E&gt;&gt;`.
Maybe try `win.draw_2d(event, |_c, _g| {});` as the error message indirectly suggests.
Datagram Artillery, got it.
Is there a way to avoid writing out all the members of an enum value when matching on enums? Example `match instruction {` `Instruction::ADD_reg {` `rm,` `rn,` `rd,` `setflags,` `shift_t,` `shift_n,` `thumb32,` `} =&gt; { if *thumb32 { 4 } else { 2 }` `}` Here the thumb32 is the only relevant enum member that decides what value to return, so I would like to avoid writing the other members in this case. The particular issue can be seen in context here: [https://github.com/jjkt/zmu/blob/213ff0580d90a53dd07cc33e68c5336821187fd3/zmu\_cortex\_m/src/core/instruction.rs#L2217](https://github.com/jjkt/zmu/blob/213ff0580d90a53dd07cc33e68c5336821187fd3/zmu_cortex_m/src/core/instruction.rs#L2217) &amp;#x200B;
the default behavior of ctrl-c is for the process to be immediately killed. you probably want to use https://crates.io/crates/ctrlc or a similar crate to override the default signal handler if you want custom behavior.
 match e { Enum::WhatIWant =&gt; { /* ... */ }, _ =&gt; { /* everything else } } Does that help? 
Love it! 
What is Chalk? I keep seeing it mentioned.
It's [a PROLOG-like interpreter](https://github.com/rust-lang-nursery/chalk) intended for use in rustc's type system implementation.
\`read\_line\` appends to the input buffer. [https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read\_line](https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_line) So the String has to be cleared.
So what you're saying is that `cargo-edit` should support `cargo add *` :P
No idea...was just trying to collect creates that I would want before my trip and have the documentation in a single place to make it easier to reference. I'm coming from the java world where most of the libraries anyone would need, as opposed to want, are available in the java development kit.
I made a crate to make it easier, but yeah it should be easy and nice out of box &amp;#x200B; [https://github.com/vova616/simple\_generators](https://github.com/vova616/simple_generators) &amp;#x200B; #![feature(generators, generator_trait)] use simple_generators::*; fn main() { println!("{}", test_macro(10).sum::&lt;u64&gt;()); let foo = Foo { vec: vec![10, 20, 30], }; for e in foo.test_macro() { println!("{}", e); } } #[generator] fn test_macro(n: u64) -&gt; impl Iterator&lt;Item = u64&gt; { let mut num = 0; while num &lt; n { yield num; num += 1; } }
That's an ownership issue, as the compiler says. `transform_lab` consumes its input. Once you put a `Box` into a function you don't have a `Box` anymore. Because it's an ownership issue, you actually can't fix it with indexes either. The obvious way of writing C/C++ code would risk creating a dangling pointer if `transform_lab()` throws an exception or long-jumps. The safe solution is: - Change your `Vec&lt;Box&lt;dyn Tr&gt;&gt;` to `Vec&lt;Option&lt;Box&lt;dyn Tr&gt;&gt;&gt;` Then s will have type `&amp;mut Option&lt;Box&lt;dyn Tr&gt;&gt;`. And let x = s.take().unwrap(); *s = x.transform_lab(); This is equivalent to temporarily putting a null pointer in `*s` during the execution of `transform_lab`. An alternative without changing the type is to allocate some other `Box&lt;dyn Tr&gt;` as an exception-safe replacement. Then you can use `std::mem::replace` twice to swap the old Box out and the new Box in. If you don't care about exception safety or have some other way to contain the dangling pointer, you can unsafe read and write. Finally, if possible, you could change the trait so that `transform_lab()` takes either `&amp;mut self` or `&amp;self`. There's a performance trade-off, but I think if you're using dynamic dispatch you probably should use the `&amp;self` signature. 
What is hoped to be accomplished by this integration?
Ah, then that makes sense. Maybe if you had a list of capabilities you wanted to work with we could make some recommendations as far as dependencies. Something like ``` cargo install cargo-edit cargo new --bin hello_rust cargo add &lt;some dep&gt; # cargo-edit has some helpers for doing this kind of thing cargo add &lt;some dep&gt; # continue until you have all the deps you'd like to investigate ... ```
Why does /r/rust bring out this absolute inane nonsense? &gt;I think we should start by talking about JavaScript, since that's where this whole async/await notion came from (at least in recent years). Imagine being this ignorant. What is it with nodejs people learning a single language and thinking the world revolves around them and that nodejs is the pinnacle of innovation. Christ, it's not even good at the things it's proponents claim its good at. I'm just glad we didn't get some asinine benchmark with an unoptimized debug Rust binary showing nodejs being better at some thing.
It's a more general solution to type inference than the current ad-hoc system – and more flexible to allow implementing a more powerful type system. For example, the current system often isn't powerful enough to deduce that two types are distinct. Chalk can solve this, while offering comparable performance to the current system.
Hmm, interesting argument, i planned to rant that rust is just awkward, but you do make a good point. Couldn't i also alternatively just force my way with unsafe?
I see, thanks! You don't suppose e.g. the write barrier problem could be helped with runtime support?
Wow congrats on finding my name and that I live in Chicago! Would you like my boss's phone number so you can file a complain with him about me? I'm glad to know that the Rust community is so welcoming. 
It's like rust is retreading the issues that Haskell had with mixing IO and streaming a half-decade ago. Look at what \`pipes\`, \`conduit\` and friends do.
It would also match what you regularly have to do with slices and non-owned vecs, so people wouldn't have to learn new habits in order to run them.
Nice project! I looked at your source code and learned a lot :) Star and upvote. 
Looking at Python generators, their semantics closely corresponds to Solution 3. Consider this generator: def gen(): yield 1 open('nosuchfile') yield 2 yield 3 If you instantiate `g = gen()` and call `next(g)`, the result is: ``` &gt;&gt;&gt; next(g) 1 &gt;&gt;&gt; next(g) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in gen IOError: [Errno 2] No such file or directory: 'nosuchfile' &gt;&gt;&gt; next(g) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; StopIteration ``` Merely requesting an item propagates the exception. If exceptions were implemented by returning values, as they are in Rust, the exception-carrying value would be returned by generator's `__next__` (the special method invoked by `next`). Following those semantics, `?` in a generator should be understood to apply to the yielded value, not to the returned value. The downside is that it would require all `yield`s to include an `Ok()`, i.e. `yield Ok(string.matches(...));`. This is is probably not a big deal and it's equivalent to how a function that uses `?` has to return `Result`, so all of its non-error returns have to wrap the value they want to return in `Ok(...)`.
But note that overriding the default behavior of ctrl-c is usually a bad idea, since it breaks user expectation. It also hints that your application does not behave well when instantly killed for other reasons.
I think that using words like "attack" and "victim" is not very wise if you are trying to convey the program as a load tester, and not a DoS tool for script kiddies.
"src/attack.rs" "struct Attacker" hmmmmmmmm
&gt;The conclusion is not really wrong, but is this information helpful? It's good to be aware of these sorts of issues, and the limits of safety guarantees. If anyone's not aware of this sort of thing, it's good to find out about it (I think some people do have unrealistic ideas about Rust's safety). That said, there's no reason to single out allocators specifically (although I guess that's a good example since it's implicitly used in many places).
i guess time will tell how many actual games are made using amethyst plus a scripting language compared to how many people just think it is an interesting thing to add to an engine. 
I'm not sure exactly what benefit you're expecting. There isn't much of a performance penalty to calling C APIs from Rust, and LLVM is written in C++, which doesn't particularly make it slow. Cranelift, which has been mentioned, is a potential back-end written in Rust. The difficulty here is that a compiler back-end targeting many processor architectures with substantial performance optimization is a very complicated task, so rewriting that in Rust is not trivial. The work-in-progress Cranelift back-end for rustc doesn't aim (at least at first) to complete with LLVM for the performance of the compiled binaries, but it compiles faster. So the idea is that in the future, if all goes well, rustc will default to Cranelift when compiling in debug mode, for fast builds, and LLVM for release mode, to maximize the performance of the resulting binary.
&gt; That said, I haven't looked into whether it tries to work well with partial, asynchronous updates (which is what GUI apps typically do), or if it's more oriented towards the clear-everything-draw-everything model of action games It's not opinionated, you can do either with it :)
My main takeaway from one of the comments in that thread is that we're conflating A: "iterator that stops on first error and yields the inner Ok() values until then" and B: "iterator that yields Result&lt;&gt;s". They're entirely different models, for entirely different situations. and the situation is further complicated because A is pretty difficult, so people typically approximate it with B. So taking a step back and answering the questions would help: - Do we want generators to let users model A? - Do we want generators to let users model B? - Are we comfortable with A being used to model B or vice versa?
Not after you have read the last line. There you can just \`drop\` the \`String\`. No need to call \`clear\` first, and then \`drop\` it.
Yes but it's probably not exception-safe. Depending on your goals that might not matter. For something that may be exposed to data from the Internet, I wouldn't. Nor for controller firmware. It may be acceptable for a game engine. Using abort-on-panic on your release builds would be a good idea. Test extensively. If you want to do that, `std::ptr` is the crate. I also recommend the *Rustonomicon* for a decent and entertaining introduction to where the sharp edges are, especially if you don't already have a deep understanding of C/C++ undefined behavior.
Minix is a really interesting operating system. I've been digging a lot into its virtio and network stack lately and it took my a while to wrap my head around the micro-kernel aspect of it. &amp;#x200B; Awesome blog post! I'd love to see where this project goes.
SIGINT was never meant to be a generic graceful process killer; that's SIGHUP's job. Processes can and should do whatever they please with ctrl-c and SIGINT.
You can use `..` as shown [here](https://doc.rust-lang.org/1.30.0/book/second-edition/ch18-03-pattern-syntax.html).
You don't have to call the iter method on slices; they implement IntoIterator.
You're right. I was thinking of if you want to do any iterator things like enumerate() or map()
Yes, I [wrote](https://internals.rust-lang.org/t/pre-rfc-generator-integration-with-for-loops/6625/23?u=newpavlov) about it in the Pre-RFC thread. I think generators can be used for both use-cases, for A you get `Generator&lt;Yield=T1, Return=Result&lt;T2, E&gt;&gt;` and for B `Generator&lt;Yield=Result&lt;T1, E&gt;, Return=T2&gt;`. It's just because ecosystem is `Iterator`-centric we became accustomed to `Iterator&lt;Item=Result&lt;T, E&gt;&gt;`, which can be used for both cases and user should deduce how it behaves without any help from type system. In other words, it's simply lack of `Iterator` expressiveness, which for some strange reasons started to stir design of `Generator` in an (arguably) ugly direction.
Thank you. Seems my rustup update was not updating nightly. I have fixed this, and its all working correctly as you stated. Without this, I would not have seen nightly had blocked its updates. 
I definitely agree that Rust is my favorite programming language... and that it’s terrible to learn on. I personally think C is the best intro to the basics, because it’s such a *simple* language. There are so few constructs that it’s relatively easy to explain. Python is *okay* because it hides some of the nasty parts of C, but it comes with the baggage of being *significantly* more complex.
I may misunderstand, were you asking why not clear it before the \`read\_line\` call?
Personal projects depend on your personal motivation - so if you want something that'll let you quickly iterate on a project to see it to completion .... uh .... lots of people write good things in python. :-D But yeah a lot of the Good Habits in other languages regarding memory are required and enforced by the Rust compiler.
Those exist. FBI shut a couple down last year. 
I guess I was thinking that creating a custom compiler might allow you to strip out all of the unnecessary bloat of a more general compiler. It would also be one less third party dependency. &amp;#x200B; I have very limited knowledge of compilers though.
This is a great case where you could take advantage of some of Rust's fearless concurrency features! Implement this with a map-reduce pattern and you could see even greater improvements
Why does it look jittery?
Ew, you can take your nonsense spam with you on your way out.
I asked &gt; why does one need to `clear` the `String` after [reading] the last line ?
Mick Rippon - Tribute to Paddo https://www.youtube.com/watch?v=eZ2cWiBoDzw
&gt; I'm not sure you can call C the lowest-level language - you have to use its ABI so there's no opportunity for more efficient struct layout, for example. There's no opportunity for the compiler to reorder structs for you for more efficient layout – but you're free to do it yourself. That's pretty much the meaning of low level. The Rust compiler's naive packing is a good idea most of the time, but that doesn't mean it's always optimal; performance depends on how the struct is accessed and how that interacts with the CPU caches.
And relevant to the blog post we're commenting on, should the ? operator be useful for A? for B? for both?
Ok so I'm tired of seeing bullshit like this so here's a good tip: You don't need to make your own cryptocurrency to make it easy to use. How do people use cryptocurrency? With software. Make the software easier to use and you make the coin easier to use. So if you think that the current people use Bitcoin and Ethereum are too hard, then you can fix it. It's all free software and nothing is stopping you from making your own frontend to the node software. Blatant cash grab.
I think we should follow the "straightforward interpretation", i.e. A. I believe it's not only the most natural and easy to understand approach (after all it will be *very* strange if classic and generator closures will behave differently in this regard), but also that most of the code (at least in my practice) does not resume iterations after a first error. It may be worth to wait and see, and if there will be enough demand to add later some kind of `?` variant for yielding error instead of returning it.
Working on \[Nimiq Rust node\]([https://github.com/nimiq/core-rs](https://github.com/nimiq/core-rs)).
Very nice!
When I ran the tests, they failed: ---- tests::parse_device stdout ---- parse_device - Test Summary: 16019 out of 16021 test cases passed --- Failed Test Case ---- Expected DeviceTestCase { user_agent_string: "HbbTV/1.1.1 (;;;;;) Maple_2011", family: "HbbTV", brand: Some("Samsung"), model: Some("HbbTV") } Got Device { family: "HbbTV", brand: Some("Samsung"), model: None } --- Failed Test Case ---- Expected DeviceTestCase { user_agent_string: "HbbTV/1.1.1 (;;;;;) firetv-firefox-plugin 1.1.20", family: "HbbTV", brand: None, model: Some("HbbTV") } Got Device { family: "HbbTV", brand: None, model: None } thread 'tests::parse_device' panicked at 'assertion failed: failed.is_empty()', src/lib.rs:177:9 note: Run with `RUST_BACKTRACE=1` for a backtrace. 
I'm worried that emulating the write is going to be a morass of figuring out all the different architecture-specific (and variable length) instructions that might result in a write (let me know if I'm misinterpreting things!). &amp;#x200B; I suspect the best thing we can do here is increase the granularity of our locking, ensuring heap pages are \`mprotect\`ed the minimum amount of time necessary and concurrent writers are unblocked asap
What does this have to do with Rust?
you probably can't actually do the sdl2 rendering on multiple threads, like I think it will actually not work. You can do all the setup for the rendering but the final "Draw the texture" I think has to be one the same thread you create the windowcontext. "The thread that created the main window is the only thread that can access it (including e.g. handling events). This is more of a limitation of the underlying APIs, really (I recall the WinAPI imposes this limitation, for instance). " 
Oh that's just my recording software, not jittery natively :P
Will we be running rust code on intel's ME soon :p?
/r/playrust
This subreddit is not about the game Rust, it is about the programming language called Rust. You're looking for /r/playrust 
my bad, i was going to check on the post so i looked this up then realized that this is not about the game so i tried to delete it, could figure out how, new to reddit
Looks like replacements aren't working correctly. See regexes.yaml lines 5019 which should replace the model with the capture group `$1` =&gt; `Some("HbbTV")`
Lots of benchmarks will show two implementations faring in a variety of problems, it's nothing new ?
Thanks for your explanation. 
Hello all, I'm running into what I'm sure is an easy problem but I can't figure it out. I'm running into the following error with a \`fold\`: &amp;#x200B; \`\`\` **mismatched types** **expected (), found struct \`std::vec::Vec\`** **note: expected type \`()\`** **found type \`std::vec::Vec&lt;rusoto\_dynamodb::BatchWriteItemInput&gt;\`** \`\`\` &amp;#x200B; This is the code in question: &amp;#x200B; \`\`\` items.into\_iter().fold(writes, |mut acc, item| { &amp;#x200B; }) \`\`\` &amp;#x200B; I have no idea why the compiler feels I should be providing \`()\` for my accumulator.
Yes, they are might not the best words to describe the Anevicon philosophy) I'll fix it today.
Yep, I figured it was better to just let those cases fail and output a summary than to do anything else. Good catch, though!
I was thinking about this and I'm not sure how to accomplish that without some kind of const function. I have an example in there that demonstrates using `include_bytes` to include the `regexes.yaml` at compile-time. A compile-time `UserAgentParser` would be much cooler, however :). I'm open to suggestions if you have them.
That one in particular is the only one that fails because it asserts below the summary output. The other tests don't fail, just output.
&gt;Rust has a bit of a learning curve in terms of its type system etc. did that affect the course or detract from learning OS concepts? Conceptually, I thought it actually helped, because understanding Rust's safety features requires you to understand what they're protecting you from (if that makes any sense). The main downside was that Rust in 2014 was still under very rapid and active development. Finding up-to-date documentation and tools could be a real pain. &gt;Also, when working with a higher level language like Rust, wasn't it hard to understand what happened on a hardware level? I don't think Rust is nearly high-level enough to interfere with understanding low-level concepts. All of Rust's "magic" happens at compile-time, so as long as you understand memory allocation etc., it isn't really hiding anything from you. In fact, its compile-time features helped teach us some systems programming concepts. For example, memory ownership certainly exists in C and C++. But when the compiler enforced memory ownership rules and gave me helpful error messages, I started to really internalize why it's such an important concept. &gt;I of course realize the many safety benefits of writing an OS in Rust, but when learning it, wouldn't something more straight forward and unobtrusive be better? It's worth noting that previous courses in the CS curriculum had covered intermediate C++ and basic C and assembly. In the process, we learned lower-level concepts like how the stack and the heap work, how numbers and data structures are laid out in memory, the x86 calling convention, etc. So the Rust OS course was free to focus on things like cooperative vs. preemptive concurrency, multithreading, synchronization, and shared memory management. I found that Rust's "hand-holding" and error prevention in these domains helped give me a deeper understanding of the concepts - as well as the pitfalls you can encounter when using/implementing them. All that being said, there were plenty of students who weren't jazzed about the class. It was far from traditional and took us all by surprise. But I enjoyed it at the time, and I'm glad I took it and got to "see the light" about how wonderful Rust really is :)
Right, the upstream uap-core repo has a ton of different test cases written as part of several Yaml files. These tests just load those and collect failing and passing test cases into vecs, then I assert that the failed vec is empty. 2 of the 16021 test cases currently fail in the `parse_device` test - I've yet to do anything about it yet, though.
No need to worry, this community is awesome. 
It was a very non-traditional class and really took all the students off-guard. I came around to both the class and the language pretty quickly, but some of my friends thought I was crazy for enjoying them so much. I learned a lot, and I felt like Rust's safety features actually helped me learn. More detail in [this comment](https://www.reddit.com/r/rust/comments/arhuv8/i_feel_like_rust_should_be_taken_seriously_as_a/egrtjoi).
No need to worry, this community is awesome. The problem is that you have sub *defined* twice. In main.rs you should have `pub mod sub`, but in file.rs you should have `use crate::sub`
I thought he was a classic quirky professor. There was a method to his madness!
I was thinking about this recently, and it shouldn't be too hard to do with a couple macros. But no, I don't know of anything that does this at the moment. 
No problem! To delete it, go to https://www.reddit.com/user/jskskskskskdood/submitted/ and click the little "delete" link under the post. 
Thank you!
Don't use homebrew to manage rust Use the instructions on this site using curl https://www.rust-lang.org/tools/install
yeah, the test is wrong in uap-core. The `model_replacement` is missing from regexes.yaml, but it defines a model "HbbTV" in `test_regexes.yaml`. Maybe there's suppposed to be some fall through? But there's other devices with `None` models... :/ 
I did that. But when I try to install emacs-plus using homebrew, it asks rust as a dependency to another package. Do you know what I should do to "say" to homebrew rust is installed? Thanks!!
I have a function which returns one of three fixed-sized arrays based on the argument. The thing is, that those three arrays may be of different sizes (say, up to 10 elements). So something like: \`fn test(i: bool) -&gt; \[u8\] {if i { \[1,2,3,4,5\] } else { \[1,2,3,4\] } } \`. So I try to do this: \`fn test(i: bool) -&gt; \[u8\] {if i { \[1,2,3,4,5\]\[..\] } else { \[1,2,3,4\]\[..\] } } \`. But it doesn't work since the slice \[u8\] isn't sized. But a slice is just a pointer to the backing array with a size, So is there a way to return a slice along with it's backing array?
Good clean easy-to-read code, thanks for sharing. I'm not sure that analyzing *1984* in 300ms was that unusable to begin with 😁 but it's sure faster now. README mentions readability and complexity metrics: looks like that's future work at this point?
Your closure should return the same type as your accumulator. Assuming you're not just leaving it empty to make the example shorter, it has a return type of `()` right now.
There are a couple ways to get around it. This answer sort of covers them https://apple.stackexchange.com/a/25055
No worries! To be clear, you can define a module in any other module. But you can only define it once. This gives you great control over how your project is laid out. For example, you can have a `file` module, that has `file1`, and `file2` under it. So main has `mod file`, and file.rs has `mod file1; mod file2;`. Main can then `use file:file1:function`.
/r/playrust
I'll try that! Thanks a lot!
Nothing, check their post history. They're just posting the same crap all over the place.
It is used in the `get` function. It associates the lifetime of the `TrieView` with the lifetime of the `self` it is based on
Done: [https://github.com/Gymmasssorla/anevicon/releases/tag/v0.1.1](https://github.com/Gymmasssorla/anevicon/releases/tag/v0.1.1)
Unfortunately there's no way to return one of multiple sizes of array without either wrapping it in an enum or heap-allocating with `Vec&lt;u8&gt;` or `Box&lt;[u8]&gt;`. Even `impl Trait` requires all return values to be the same type. There's [arrayvec](https://crates.io/crates/arrayvec), which behaves like `Vec` but uses an array as a backing store. You would return `ArrayVec&lt;[u8; N]&gt;` where N is the greatest length of array you want to return and then construct it internally like you would a `Vec&lt;u8&gt;`. If you don't want to reach for an external crate, though, wrapping the return value in an enum is the most idiomatic: // I recommend naming the enum and variants to be more specific to your application pub enum DynamicArray { Three([u8; 3]), Four([u8; 4]), Five([u8; 5]), } // these impls will make it nicer to use // implementation left as an exercise for the reader impl AsRef&lt;[u8]&gt; for DynamicArray {} impl AsMut&lt;[u8]&gt; for DynamicArray {} // this lets the user call slice methods on it impl Deref for DynamicArray { type Target = [u8]; ... } impl DerefMut for DynamicArray {} What is less idiomatic but finds use in some projects that want to avoid or amortize allocations is taking a mutable slice and then returning a subslice of the valid data: // it's typical to take a slice instead of an array so this could be used with `Vec` as well pub fn test(i: bool, out: &amp;mut [u8]) -&gt; &amp;mut [u8] { // ensure that we have the minimum capacity required assert!(out.len() &gt;=5); if i { out[..5].copy_from_slice(&amp;[1, 2, 3, 4, 5][..]); &amp;mut out[..5] } else { out[..4].copy_from_slice(&amp;[1, 2, 3, 4][..]); &amp;mut out[..4] } } Or even just returning the number of elements written to the slice, like in `Read::read()`.
![](http://www.varsitypetsonline.com/templates/__custom/Images/varsity-ball-dog1.jpg) 
Maybe you should use a [channel](https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html) 
This is freaking cool way to visualise lifetimes
Portland State University. Here's the Spring 2018 [offering](http://moodle.svcs.cs.pdx.edu/course/view.php?id=30). It's a pretty straightforward course, really: just work through [Programming Rust](https://www.amazon.com/Programming-Rust-Fast-Systems-Development/dp/1491927283) in 10 weeks. Had people write some code along the way and do a project at the end either individually or in small groups. Was big fun: am excited to do again. (I'd share the eight-week Summer syllabus as well, but I used Google Classroom and it gives me no way to make the course public. Oops.)
I don't see that in the latest commit. Regardless, why do you need it on `get`?
Very true!
my github remote is pretty stale, let me push and you can look at the current state of things.
MINIX 3 I assume, the one with the NetBSD userland. MINIX 2 was the one we hacked on in college in an operating systems class many moons ago because its codebase was very small and minimal. I remember adding a keyboard delay &amp; repeat rate fix to it because the hardware defaults were painfully-slow.
No, that's a bad idea because adding an unmanaged rustup and piping into a shell aren't good ideas. It's far better on macOS to use `brew install rustup-init` instead.
``` fn test(i: bool) -&gt; &amp;[u8] { if i { &amp;[1, 2, 3, 4, 5][..] } else { &amp;[1, 2, 3, 4][..] } } ```
I have pushed my changes to the trie module. Everything else is pretty stale still but this api should be current
Is there any way to conditionally filter an iterator. I am accepting `String`s as arguments from the command line using `structopt` as a way for the user to filter results, but they are optional (the user can just have all the results printed). In `structopt`, I accept these parameters as `Option&lt;String&gt;`s. When I'm filtering results, is there any way to filter the iterator only if a conditional is met (or an if-let statement)? I can't use an if-let statement inside the `filter`'s closure, because it is an `FnMut` closure and the search string would be moved (which is bad in an iterator), and I can't use a setup like this ```rust let i = entries.into_iter(); //.for_each(|e| println!("{}", e)); if let Some(m) = filter { let i = i.filter(|e| m.is_match(&amp;e.tag().unwrap_or_default())); } if let Some(m) = search { let i = i.filter(|e| m.is_match(&amp;e.label())); } ``` because the compiler complains about the moved value of `i`. So is there any way to filter an iterator like this? Any help is appreciated! Thanks!
LOL.. 
Wow, I'm surprised you saw that - I didn't see anything about borrowing vs. ownership there. That really had me scratching my head pretty furiously. Works great now, thanks!!
I sent a pull request.
I sent a pull request with some changes.
It's issue postings like these in Piston that really make me reconsider using a different library. https://github.com/PistonDevelopers/piston/issues/1275 That's just spooky as all hell.
The architecture of Minix is indeed quite interesting. I'll have to take the time to look into it more; I was too busy porting this to actually try out Minix much :-D Though, if nothing else, this wasn't the worst possible way to get some sense of what library functions are implemented on Minix. Not the best way either, but not the worst.
I'm not familiar with the semantics of `'_` in this case, does it reference the elided lifetime for `&amp;self`?
Yes, `'_` just means infer this lifetime, so all lifetime elision rules apply. So in this case it just means use the same lifetime as `&amp;self`.
what effect does moving the `'a` lifetime outside of `TrieView` have on `HashTrieView`? [https://github.com/Kylebrown9/Slang/blob/master/src/trie/hash.rs#L186](https://github.com/Kylebrown9/Slang/blob/master/src/trie/hash.rs#L186)
Hm, I guess I'd have to look into the exact nature of those Intel ME exploits people have found... Of course, I'm really just doing this as a plot to get Intel to hire me to develop NSA back-doors in Rust. Because if you're *going* to have NSA back-doors, they really should be in Rust (mostly joking; in practice I'd be more concerned about unintentional security vulnerabilities in the ME than actual nefarious intent).
Nothing, it can stay the same. The lifetime on `HashTrieView` is necessary so that you can store references.
Specifically, the lifetime bound on `TrieViewable::View` just means that it must outlive that lifetime, which `HashTrieView` does.
Put four spaces in front of a line to make it code formatted. like this multi line works great and indents.
Yep, Minix 3. Specifically, I'm testing with a build from the latest git sources. I'm actually taking an OS course at university now, but based on Linux, and it doesn't involve actually working with the kernel's code (the programming assignments are purely done in user-space).
Triple ticks don't work on (all of) reddit. You need to format code with just the leading 4 spaces, like this: let i = entries.into_iter(); //.for_each(|e| println!("{}", e)); if let Some(m) = filter { let i = i.filter(|e| m.is_match(&amp;e.tag().unwrap_or_default())); } if let Some(m) = search { let i = i.filter(|e| m.is_match(&amp;e.label())); }
Sorry im really late 😂, um i don’t think that is a thing in rust
This is awesome. I'm excited that there's more people thinking about this. I've been really burnt out for about a year and haven't been able to jump back on like I had planned. (Great podcast on burnout by Chris Krycho here https://newrustacean.com/show_notes/bonus/burnout/index.html). I'd love to be able to say that I could start right away, but I don't want to get back into the habit of overcommitting. For anyone who does want to pick this up, I can provide some guidance. The direction I had last gotten from Niko was to come up with a design first and not be constrained by what editors and the compiler are currently limited to doing. The idea would be to try to get changes into the editors and the compiler (the later through polonius, the system coming after NLL) after an ideal design has been reached. Even though I haven't been making any progress, I have been thinking about it from time to time. The new challenges that have made coming up with a design more complex than previously are generators and async/await.