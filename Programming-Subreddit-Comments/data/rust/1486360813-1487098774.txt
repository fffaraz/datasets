Gotcha. Thanks!
We're going to split up [Rusoto](https://github.com/rusoto/rusoto) into [multiple crates](https://github.com/rusoto/rusoto/issues/559). There are already a few crates split off the main Rusoto crate, such as our [code generation from botocore crate](https://github.com/rusoto/rusoto/tree/master/codegen) and [AWS credentials crate](https://github.com/rusoto/rusoto/tree/master/credential). It's time to step up our game by giving each AWS service their own crate. Using cargo features in our main crate has worked well for us up to now, but compiling the 60 or 70 AWS services we support at once causes both TravisCI and Appveyor to run out of memory. It's going to be a large undertaking but we've bumped into the limits of what can be done on free CI systems and there's another 10 or 20 AWS services yet to implement.
Isn't the default implementation for `Debug` simply the name of the variants?
tried this [Vim plugin](https://github.com/VSCodeVim/Vim) yet? Also [Rust](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust) fork of VSCode seem to be actively maintained.
I got a bit sidetracked last Friday &amp; implemented [slice in-place partition](https://github.com/llogiq/partition). Now I'll need a proper README &amp; an example of how to use without `std`. Also the usual TWiR, and preparing our next Meetup. And still too little time to do that RFC...
A closure works in the easy case, but requires linear control flow.
You are mistaken. Rust would not have prevented Heartbleed.
The reason I suggested increasing the number of characters is because shorter strings should be easier to compare. Of course, that does depend on there being enough visually-distinct emoji, and while there's a ton of emoji, I don't know how many are left once you remove all of the similar stuff (e.g. faces).
I am working on [[package.metadata.docs.rs]](https://github.com/onur/docs.rs/pull/73). With this feature crate owners can finally tell docs.rs to build non-default features. This is one of the most requested feature but I always wanted docs.rs to build everything automatically without any user input. But looks like it is not enough.
You're right, this is maybe too strong to present this like that. The meaning is: Most data are allocated on the stack by default, when possible. Should I rephrase? When presenting the slide out loud, everything was OK, but maybe the text is ambiguous.
This looks great. I'm not sure I understand the API design, though: why not a single struct with a ::new() like std::collections::HashMap instead of a read/write handle and why do values need to implement Eq?
As suggested on StackOverflow in the second answer, you could also do this by using `Drop` to do something smart; like, a wrapper type that keeps track of methods called and will call the reverse methods as part of `drop()`. Is there any reason this would not work well?
For your information, I've just added support for nested messages in quick-protobuf. I have only done very basic tests so it may not work. If you have some time I'd like having a real world scenario.
Indiana for the dog
This is interesting as I expected chashmap to scale better in the uniform distribution. It'd be interesting to try the benchmark in a non-numa intel architecture and enabling parking_lot nightly features.
You can use [generic-array](https://github.com/fizyk20/generic-array) but it's a filthy hack. Type-level values are [in the works](https://github.com/rust-lang/rfcs/issues/1038) (there are a few related issues there), but there's no good consensus on the final design and so as of yet we don't have an implementation.
Ah right, thanks. That actually solves the problem I was having :)
Yeah, they definitely implement `Drop`. If you ever call it, you should `panic`.
Title is a bit clickbaity but it's an alright article.
Isn't IDEA an example of the opposite? Eclipse and IDEA were competing on equal terms. JetBrains and IDEA exists _because_ of the failure of the open source community, not the other way around.
Well, there are ways to go around that. Maybe returning a flag to the enclosing method to indicate if it should or should not call move_right subsequently.
I do not use linting at all. I found it distracting. I'm using only Rust Enhanced and RustAutoComplete. As I sad before, features set is not important for me when everything else is slow as hell. So no Atom, VSCode, IDEA, etc.
Heart bleed was caused by a failure to bounds check. Since bounds checking is mandatory in Rust... Citation: https://en.m.wikipedia.org/wiki/Heartbleed
Because BTreeMap takes keys by reference and not by value.
thx for answer in detail. why i can't find them in other languages then?
Seems to me that a state machine could be used here. Have structs FooUnmoved, FooMovedRight, and FooMovedBoth. Have your function return a FooMovedBoth. Only a FooUnmoved can produce a FooMovedRight and only a FooMovedRight can Produce a FooMovedBoth.
Can you give an actual usage example to see what problem it solves elegantly? I'm trying to wrap my head around what's stack and not heap allocated.
My C++ experience is limited to one CS datastructures and algorithms class, but I imagine `std::shared_ptr` gets used a lot in large codebases where it isn't feasible to check every nook and cranny for memory unsafety. In most cases, it's probably cheaper than copying, but you could make the argument that it makes C++ a *de facto* garbage-collected language.
Do mainframes typically have web browsers installed on them? 
What do you use the unsafe for? And Go uses garbage collection while Rust only uses static memory management. I don't think any other language allows the programmer to do this completely safely with no runtime memory management. In C++ you can do this, but if the original class goes out of scope while the reference lives on, it will be come an invalid reference and point to garbage memory. In Go, you have the garbage collector impacting performance. But in Rust, the original struct is statically guaranteed never to go out of scope before the reference does, and so this pattern is guaranteed memory safe, with no runtime memory management at all.
A common/trivial example is a vector: if you get a reference to an element of a vector then modify that vector, you may have invalidated the original reference, at which points all bets are off: http://rextester.com/SJMX4279 note that after the loop our old reference points to some random garbage (I see 35827760) which is neither the original value (0) neither the final one (9) but I'm pretty sure this is an UB so it could just as well segfault or lead the compiler to [start time-traveling](https://blogs.msdn.microsoft.com/oldnewthing/20140627-00/?p=633). In Rust altering the vector requires getting a mutable reference to it, and Rust won't let you take a mutable reference if there are extant immutable references, the translated code will fail to compile entirely: https://is.gd/5IuqkZ
He doesn't mention GC at all in the post. It seems unfair to say that other languages can't do this. 
This lint would probably still be useful if it was done only for non-Drop types.
Comparison to Rustls and _ring_?
If you look at the [bugzilla thread](https://bugzilla.mozilla.org/show_bug.cgi?id=1284816#c7), at least for debian, being able to build on the target platform is a requirement.
The unsafe pointer is only used to demonstrate that `x.y` is interior to `x` rather than a separate allocation. You can remove that line and the example is still valid. I think this is a perfectly fair reply to the post. Go is a garbage-collected language that can handle interior pointers into struct types. Since it uses GC it doesn't handle this exactly like Rust, but as far as I can tell (I'm not a Go expert) it meets both the safety and memory layout requirements.
oops, didn't know that really.
If "Mozilla binds Firefox's fate to the Rust language" I wonder why it doesn't fund it respectively. As mentioned in the bugzilla issue: &gt;Running a compiler testsuite on QEMU is courageous, to say the least. In Debian, we don't allow builds for release architectures on emulated hardware for very good reasons. There have been multiple cases in the past where compilers generated wrong code when executed on QEMU. I have made plenty of experiences in this regard. &gt;Really, you *need* a complete CI setup with real hardware for all the ports you actually want to support like Google does for golang [1]. Otherwise claiming to support any of such architectures is a bit dishonest. At the same time Rust doesn't have enough resources to test everything even on QEMU! The [PR adding ARM testing](https://github.com/rust-lang/rust/pull/39400) mentions this problem: &gt;We're running low on capacity on Travis, can we afford adding another builder? &gt;According to Travis we can have 35 concurrent jobs total. We currently have 26, this PR adds one more, and #38847 adds another, bringing the total to 28. 
&gt; I think TFA is a bit disingenuous, I'm reasonably certain you can return a reference to an inner member in C++, the issue being the compiler will not enforce lifetime so you may end up with use after "free" It ... explicitly mentions that, I don't see how it's disingenuous. "C/C++ can't do it because the compiler does not perform the lifetime checks. "
If you create that unsafe pointer variable, and then keep the pointer around, while dropping the interior, does the GC collect the struct after a while?
The need for separate read and write handles comes from the fact that there can only ever be one write handle at any given point in time (it needs to hold on to the "other" map). The read handle on the other hand can be `Clone`, since it just holds a pointer to the current map's `Arc`. Values need to implement `Eq` so that you can do multi-set removal. I guess technically I could remove `Eq` from the overall `impl`, and instead just require it for `remove()`. Would that be better?
Yep, that's my experience working with multiple large codebases. Most don't use shared_ptr directly; they have their own refcounting abstractions (sometimes providing both threadsafe and nonthreadsafe refcounting unlike shared_ptr), but it's basically the same. I think the cost still differs from a "real" garbage collected language, but it's there.
Rust makes it's checks at compile time, not at runtime. shared_ptr is similar to Rust's [Rc](https://doc.rust-lang.org/std/rc/) and [Arc](https://doc.rust-lang.org/nightly/alloc/arc/struct.Arc.html). I don't think you can make [this sort of mistake](http://stackoverflow.com/a/25949914) with Rust's shared references and mutable references. You can with Rc or Arc I think but not with what is written in the article.
Assuming you are writing code outside of both A and B, you can't. You can either define a new trait related to the A trait and implement that for the B type, or a new type that wraps the B type and implement the trait for that.
I read it as if he meant Y would be a distinct heap object. It wouldn't be unless it's an interface, which is analogous to a trait object.
This was my immediate thought as well
Go doesn't handle unsafe pointers in its GC analysis, so yes.
(from the comments) &gt; I think the Rust community has a HUGE problem. &gt; Most people I know who today write C++/System programming are senior and rarely trip on lifetime problems. And that's the biggest problem, AFAIK, that C++ community has... Self-confidence. I've worked with large C++ codebases (and still do!). Lifetime issues do occur on a day-to-day schedule, and they consume/waste huge amount of time and effort to chase and fix, since they often show up past-shipping.
I wasn't trying to compare reference counting and ownership/borrow checking directly. I was trying to make the point that most people will probably still reach for garbage collection for most non-trivial use cases because it's difficult to reason about shared raw pointers in C++. 
AFAIK linear types are incompatible with implicit destructors, so to add linear types to the language you'd have to go into every single scope that contains an object with a destructor (every Box, every Vec, every Rc, etc) and insert an explicit drop call for each one. And that's not the only potential source-breaking change. It just isn't going to happen, it would surpass Python 3 in terms of breakage.
That doesn't work, `&amp;` only works on lvalues in C/C++: int main(void) { int *ptr = &amp;3; return 0; } gives In function ‚Äòmain‚Äô: error: lvalue required as unary ‚Äò&amp;‚Äô operand int *ptr = &amp;3; ^ 
So this is, in fact, unsafe, as the struct can suddenly disappear and the pointer points into garbage. EDIT: without using `unsafe.Pointer`, so just using `&amp;x.y`, it is safe, but it uses a GC, so it's effectively reference-counting the struct. What OP said was that Rust can make this work safely without run-time GC, reference-counting, or similar
https://github.com/ferno/base65536
Refcounting is, on paper, orders of magnitude cheaper than tracing garbage collection. I imagine most of the cost is from poor cache locality due to the necessary heap allocation (especially bad for `shared_ptr&lt;vector&gt;`) and leaks due to cycles, which can be difficult to detect and reproduce. Pointer invalidation can still be an issue, of course. Nothing is stopping you from taking an iterator into a `shared_ptr&lt;vector&gt;` and then pushing to it such that it reallocates. The core problem hasn't really been solved.
This is great! Sorry for the possibly dumb question, but would managed state be good for, for example, passing around a database connection pool?
I mean, the importance of testing all platforms more often was brought up _just now_, it's disingenuous to paint the lack of it as a matter of mozilla not funding Rust. I discussed this a bit with brson, we do have resources to qemu test every nightly or something. I also talked with Firefox people, there is hardware testing infra at mozilla; but it's a bit tricky. I'm sure something can be worked out; we have the whole year to do this. Someone has been hired as a Firefox side rustc developer (i.e. a rustc dev focused on the needs of Firefox. Not sure of the details)
Manager of the Mozilla Rust team here. You're reading an awful lot into that comment. We're in the midst of transitioning our entire CI infrastructure to Travis and Appveyor. Alex is talking about "affording" in the sense of using our existing capacity, which, when we get close to the top, can cause significant slowdowns. This was also just one concern among many kinds of ramifications for his PR. Until the dust settles on the new infrastructure, it's hard to know what our exact needs are going to be. If initial capacity limits prove to be a blocker, we'll re-evaluate at that point.
I'm famous now.
Why do you refuse to correct that untruthful claim?
Working on finishing up `.gitignore` support in [watchexec](https://github.com/mattgreen/watchexec) most likely, then looking at ways to support multiple concurrent workflows. I'm really happy with my choice to use Rust for this project.
Hell, I work on a *small* C codebase that handles network traffic. Lifetime issues scare the shit out of me, and I have a strict one-producer-one-consumer flow. I would kill to be able to do this in Rust.
/r/playrust
[Hypothetical.](https://www.reddit.com/r/rust/comments/5rwwrv/chashmap_efficient_concurrent_hash_maps_in_rust/ddbozkp/?st=iyudyg83&amp;sh=2cd2dfd8)
I'm not painting anything, I'm genuinely curious, that's why I'm asking. As an outsider to Mozilla I have no idea what happens there internally. My long-time impression was than heavy reliance of Rust on people contributing for free on GitHub, active work on attracting new contributors, very few people hired full-time, all are signs of either some financial hardships in Mozilla, or deprioritization of the project. I extended this impression on testing infra capacities that are currently lacking and cannot be increased for free.
Oh okay thanks 
/r/playrustservers. /r/playrust doesn't want server advertisements.
&gt; all are signs of either some financial hardships in Mozilla, or deprioritization of the project. Not at all. It's just how open source works. Rust has more paid developers than any language I've ever worked on, even with companies that use them and have higher revenue than Mozilla. Rust is a community project that Mozilla supports. Community projects need community involvement, by definition. In my personal opinion, if Rust only catered to Mozilla's needs it would be far worse.
So should i just delete this post? i have a new one on /r/playrustservers https://redd.it/5sfocb
That's because Rust is a community project (which started at Mozilla). Everyone uses linux but very few have paid devs on it. The same goes for most programming languages out there. Mozilla does not want to be the "overlords" of Rust either, which is why two years ago there was a push to decentralize governance. If Rust was a Mozilla project we'd still have green threads.
Can you propose it? Are your limitations technical (platform support) or something else (need to convince coworkers/boss, dependencies, etc)? I work on a small-ish Go codebase (30-40k SLOC) and my main issues are non-technical, and mostly boil down to convincing my boss that the time investment is worth it (Go is already fantastic).
&gt; so just using &amp;x.y, it is safe Exactly, and that's OP's point. Yes, they're different, but they achieve the same end result without memory safety concerns, but they don't have the same performance characteristics.
It wouldn't surprise me. Eclipse has always been sort an example of how being open can't fix poor/missing vision and leadership when it comes to overall design goals. (That "be everything to everyone, please no one" aspect of it.) It's a subset of the more general "technical solutions can't fix social problems (only help to bring a proper fix within reach)" effect.
Sort of, but with many languages, doing what OP did (pulling out a pointer to an internal variable) is *not* safe, whereas in Rust it's checked by the compiler to guarantee its use is safe. This is a classic example of use-after-free that Rust eliminates. Go is an interesting example because it gives you the same result, but uses a garbage collector to do so, while Rust doesn't use a garbage collector and uses the compiler to guarantee that it's safe.
Why does that guy always have to put religion in your face?
rocket seems to use [compiler plugins](https://api.rocket.rs/rocket_codegen/index.html) fairly extensively, including for two lints.
So C++ can do it, but without a lifetime check, so you have to be cautious about lifetimes. That isn't the same as C/C++ can't do it.
The built-in command `cargo update` will update your lockfile to the newest versions permitted by your dependency specs (i.e. following semver). To check whether a version newer than that is available, you can use the third-party command [`cargo outdated`](https://github.com/kbknapp/cargo-outdated).
Also see https://github.com/ctz/rustls
So many exciting things ahead for Rust in 2017! I am really happy to see this project embracing the community-driven roadmap methodology for determining what to focus on. My favorite upcoming features are impl delegation, incremental compilation, the RLS, and the Crates.io improvements. üëè!
That is the same. The post isn't talking about whether or not you can return a pointer to a struct member. It's talking about if it can be done safely. C++ does not let you express the validity of the pointer, which is _exactly what the post is talking about_. Your "it" here is different from the post's "it".
&gt; And it's next to impossible to emulate a multi-value map on top of a single-value map through an oplog. I think it could be made possible at marginal cost by passing a "replayer" trait dynamically in the constructor. trait Replayer&lt;K, V&gt; { fn insert(&amp;self, current: &amp;mut HashMap&lt;K, V&gt;, reflog: RefLog&lt;K, V&gt;); } It's *one* virtual call per replay. Then you use the builder methods: - `new()` creates under the covers a `SimpleReplayer&lt;K, V&gt;` which just adds/remove `V` - `with_replayer(replayer: Box&lt;Replayer&lt;K, V&gt;&gt;)` allows the user to pass in a specialized version, for example one that merges values
Hmm, that's an interesting idea. It would make it tricky to have a map in which you could both add to/remove things from the multi-value *and* clear/replace, but that might be fine. I'm not sure virtual dispatch would even be necessary -- the entire map could be generic over an instance of the Replayer trait. I'll play around with it in a branch and see what I can make of it. EDIT: it also gets quite hard to give a good API for remove. For a multi-set, you need to provide the *value* you want to remove. For a regular map, the key is sufficient...
Have any of the nightly feature flags been excised since the 0.1 release? I vaguely remember /u/Manishearth indicating that many of them seemed unnecessary, and of the ones that are necessary I'd like to know which Rust ought to prioritize stabilizing first (e.g. macros 2.0).
I think the crucial point is: &gt; It compiles down to what you'd expect a C compiler to produce (pointer addition) with no space or time overhead. That is, Go would NOT compile it to what a C compiler would produce; you would have some overhead for the garbage collection. On the other hand, I fully agree that interior pointers can really help making in lessening the GC pressure.
Note that you can reduce this to two types really: `Foo` and `FooMovedRight`. Add `FooMovedLeft` to the mix if you want to handle the symmetric case.
I haven't had a use-case that necessitated this as of yet. Usually, readers only care about how up-to-date the information they get is, and the writer is the one who can accurately gauge that. Otherwise you might have readers that end up calling `refresh` even when there has been no change to the data. Furthermore, you get the same behavior if the writer just shows restraint in calling `refresh`. The readers will see no contention (well, apart from the `Arc`, which is something i'm working on fixing by having per-core reference counts). Both your proposed solution and the current one have the issue of write-starvation -- as long as there are readers using the old map, the `refresh` won't finish. I'd be hesitant to introduce a third map, *and* I'm not sure it would fundamentally fix the issue. If you have a reader holding on to the deprecated map, you then just block writers from doing a second `refresh` instead of the first.
Actually... probably not `Rc` and `Arc`. If the requirement is to ensure that the `Drop` occurs, then reference-counting is out as it allows leaks.
&gt; it'd be more accurate to say it'll drive development for LLVM since that's where the codegen will happen. It actually also impact Rust, not the language but: - the compiler: the C ABI is dictated by the platform, which affects `repr(C)` structs layout and function calls - the runtime: platform specific code may be necessary to start the binary, which LLVM may or may not paper over - the standard library: anything that is platform specific may need be ported over I am not sure that the Rust toolset already supports all the platforms that LLVM does.
&gt; very few people hired full-time I am pretty sure there are more Rust full-time developers than there are Go full-time developers. And that's with Mozilla not having as deep pockets as Google. So I'm not sure there's deprioritization here; if anything I would say that the fact that: - more developers are hired regularly - Firefox is now committed to Rust are a significant signal that Mozilla is investing in Rust with a long-term view.
Nice! I actually need something like watchexec, so glad you posted. Also have you seen https://crates.io/crates/ignore ? Made by the venerable burntsushi, so you know it's good. I just came across it a few days ago and was stoked it existed because the less parsing and case handling I have to do in my app's code the better :P
Why does my program run more slowly when its console window is out of focus? I put a timer on to measure how much time it takes to complete various tasks, and it shows when I click onto any other window to the console the program is running in, it becomes glacially slow.
That is true (as far as I understand those parts of the type system). But that would only help with the type part of the problem, right? It would still be required to change (simple example) fn identity&lt;T&gt;(value: T) -&gt; T { value } to fn identity&lt;T:?Affine&gt;(value: T) -&gt; T { value } 
If you have to you can use compound literal syntax in C: `f(&amp;(int){3})` (The temporary value will outlive the function call).
&gt; Sadly enough I'm the kind of programmer who has only dealt with pretty "high level" stuff and will probably keep being that kind of programmer for a long while (e.g. The projects that I work on can afford the cost of doubling RAM or CPU ressources but not the cost of spending 2 weeks finding a deadly bugs that causes a kernel panic due to trying to write to an inaccessible location in memory). As someone who formerly worked almost exclusively in Python, PHP, JavaScript, and shell script, I can say that Rust is definitely worth it. You get very close to the high-level experience of a language like Python, but you get a top-notch type system which can rule out entire classes of errors at compile time and it's easy to build Go-like static binaries with no external dependencies for easy deployment. (even on Linux, thanks to `rustup` and the `*-unknown-linux-musl` targets) For example, the Hyper library uses a combination of parameterized traits and Rust's ownership system to implement the HTTP protocol's state machine in a way that rules out PHP-esque "Can't set new headers. They've already been sent." errors at compile time. (You can't do that in languages like C++ because they don't have an ownership system to enforce invalidation of references to old states.) My personal favourite slogan is "fearless refactoring". It's **much** easier to feel confident that you're not invisibly breaking something when you refactor a Rust program, compared to a program in a dynamic language like Python. &amp;nbsp; &gt; I've build software in C++ before (And currently have just started working on a project in C++), but I wouldn't say I'm a master of the language. I've also come to the conclusion that I enjoy javascript, scala and golang quite a lot. I haven't felt the need to dip into Scala or Go, but I've worked with C and C++ and come to the conclusion that they're simply far too stressful to get right. Rust may throw a lot of compiler errors my way when I'm learning how to use a new language feature, but it's the first systems-level-capable language that I've felt comfortable developing in. &amp;nbsp; &gt; Is it even worth using RUST for writing software that is not resource limited but might at some point have to scale really fast (i.e. by just adding resources to the machine, not re-writing the whole thing) ? Definitely. One of the big reasons I use Rust is because I have a history of burning myself out trying to reach a satisfactory level of unit test coverage. In rust, most of the unit tests which burn me out are unnecessary because, if it compiles, what they're testing for is impossible. The simplest examples are: * In Rust, if the function doesn't return an `Option&lt;T&gt;`, you know you can't possibly get a `NULL`/`None`/`nil`/etc. from it. (Interacting with C involves a special unchecked pointer type that you can only dereference in `unsafe` code.) * Rust uses monadic error handling, so you can't be surprised by an uncaught exception. If it doesn't return `Result&lt;T&gt;`, it can't error. If it does, handle that and you've handled all catchable failure cases. (I say "all catchable ..." because it's still possible for a function to `panic!` if it encounters a situation where the program somehow got into an inconsistent state and the only safe solution is to unwind and kill the entire thread.) &amp;nbsp; &gt; What are the best resources to learn RUST, considering the "in-heavy-development" state of the language. Are there any books that are kept up to date ? Online tutorials ? Well documented open source projects (just pulling your leg, I'm past the age where I believe in the existence of such things...). * Here's the official book: https://rust-lang.github.io/book/ * ...and here's something which helped me internalize more details of how Rust's ownership system works: http://cglab.ca/~abeinges/blah/too-many-lists/book/ I haven't read it yet, and it's still in development, but there's also this book for when you want to start using `unsafe` for more than just trivial C FFI: https://doc.rust-lang.org/nomicon/ &amp;nbsp; &gt; What are the cons of rust ? As in: If I have a piece of software I want to write in C++ and decide to use Rust instead, what will be the biggest "Why the hell is the syntax written this way ?", "Why is this not in the core/std ?", "Why is this running so slowly ?", "Why the fuck is this a runtime error instead of a compile time error ?", "Why is this thing no documented" ?. * You *will* need to refactor C++ programs a bit when porting to Rust, because Rust doesn't use classical inheritance to compose functionality. * In some types of method chaining, Rust's standard library APIs are little too generic for their own good and you'll have to use the turbofish operator (`::&lt;type&gt;`) to make up for a failure to infer the desired type. * The syntax strikes a pretty good balance, given what it needs to juggle. It can be a little verbose at times, but there's always a good reason for that (eg. type inference stops at function boundaries to ensure stable APIs and limit complexity of type signatures in error messages) and you can always define shorthands for complex type signatures. * Rust tends to push as much functionality out of the standard library as possible, relying on how well-designed `cargo` is, but Crates.io is still working on systems to help evaluate how mature and popular packages are, so there is still a bit of an issue with "If you're not following the subreddit, you may have to ask in order to know which of multiple crates is the best choice." * The first trick is to look for crates that are maintained by the Rust team. Those are basically bits of the standard library which can't be part of `std` itself because they need to evolve at a different rate. (The `regex` crate is one example of this.) * You'll have to unlearn some of the design patterns you're used to, because Rust's ownership system shifts their cost-benefit trade-off relative to alternatives. (Basically, stop and check for alternatives any time you'd want to write your own implementation of something which embodies a reference cycle or persistently storing a pointer to a specific entry in a collection.) * Rust is specifically designed for predictable behaviour and follows C++'s "zero-cost abstractions" principle, so your "Why is this running so slowly?" questions will be about the same as they'd be with C++. * You're actually more likely to ask "Why the fuck is this a compile-time error instead of a runtime error?". The community has a bit of an obsession with massaging the compiler into enforcing as many invariants as possible but, on occasion, it can make for the odd surprise when something you thought was safe turns out to be subtly broken. * Rust's documentation story is good. Not only does `rustdoc` provide a javadoc-like "Write your doc comments and run `cargo doc`" workflow, it'll also run any example code in the documentation (unless you opt out) to make sure it works. (I will caution, however, that it currently only documents `pub` things unless you run `rustdoc` directly with some command-line flags... so you can't just `cargo doc` and get documentation for the internals of a non-library project. However, it *is* fairly simple to build a project which is both a library and a thin shim to produce an executable from it.) The introduction to the "Too Many Lists" book I linked does a great job of making you question your preconceptions about linked lists, so I'd read that to get an idea of what I'm talking about. &amp;nbsp; &gt; Lastly, how would you compared the community to that of other languages in terms of how active and helpful it is ? Best in all categories. (Most welcoming I've ever been in, most friendly I've ever been in, most knowledgeable I've ever been in, and most helpful I've ever been in) ...though the Python community comes close.
Not almost, it is "a poor man's DI". i.e. Its limited to "singleton" scoped beans, and only auto-injects into route handlers. Depending on your experience with DI, rather than "a poor man's DI", I'd call it "a smart man's, minimal, DI". To explain slightly, every time I've seen "request" scoped beans, or aop-scoped proxies, and the like, there is too much magic. New developers, and some experienced developers, have no idea what is happening. When they wrok on these projects they make poor decisions, and their ability to refactor is impeded by this general purpose DI framework. Personally, it took me at least 6-12 months to actually understand how Spring does what it does. Every time I have to deal with a failing project, the first thing I do: Painstakingly, get rid of all the non-singleton scoped beans. All of a sudden, every developer regardless of experience level, understands what is happening, and is able to adequately work on the project. I'd go so far as to say, general purpose DI mixed with inexperienced developers, was the sole reason these projects were failing. 
That sounds like an issue specific to your terminal emulator. Rust does not care whether it is in the foreground or the background, and it can't even tell. While it is conceivable that someone could implement a complicated library to determine whether the window in focus on every desktop environment is the terminal that the current Rust program is running in, and by that knowledge choose to slow itself down, it would be a massive undertaking, and it certainly wouldn't make sense to compile that into every Rust program. Rust is a systems programming language that wants everything to be explicit and obvious, rather than hidden and automatic.
I've had good and bad experiences with DI. So, IMO, the best DI in Java land, at least, is Dagger 2. Primarily because it removes a lot of the problems and magic that is associated with DI. Once you grok it, it is extremely helpful. I've experienced Guice DI, and while it is powerful, when it fails it can be excruciatingly hard to debug. Primarily because it is doing all the proxy magic for you. Dagger restricts the DI graph to be acyclic, which goes a long way in solving all of the wackiness that happens when DI is applied willy nilly. On top of that, it restricts the DI that it can do to be compile time only, which is really nice to know exactly when you have angered the DI gods and where (dagger was far easier to debug than guice has been. I've also heard of the nightmares that can come from Spring). There is a niceness to acyclic DI. Especially if you find yourself passing a parameter for the sole purpose of passing it down the stack a few times. There is also niceness in using it to replace the spots where you find yourself cooking up factories. This stops short of where I would want DI to be. But it is understandably good enough for what it proposes. One of these day's I'll figure out how to cook up dagger for rust.
I hope this isn't too off topic, but Rust is not an acronym, and it does not need to be spelled in all caps. 
Now 17 out of 20 chapters!
There's no such thing as a local impl right now, but it's been proposed as a solution to coherence and some people are discussing similar ideas [here](https://github.com/rust-lang/rfcs/issues/1856).
How many times has the rust book been rewritten in the past few years?
So, originally there was "the Rust guide". I wrote "rust for Rubyists", which was about 50 pages. Then I re-wrote the guide into what today is the book. Now, working on the second edition of the book. I can't wait until I finish it so that I can work on other things ;) Each time we decided to do major work on this, it's been sorely needed. However, this time, I'm confident we won't need any major updates for a very long time. Yay stability! 
The problem is I'm trying to use FromStr in a generic context, trying to adapt your code, e.g: https://is.gd/rgMS3X says it needs to know the type of `err`. I'm not sure how I could add such a constraint to my generic signature. 
And honestly, if Firefox can install on x86 for Windows, Linux and Mac and ARMv6+ for Linux, iOS and Android, it hits the majority of its userbase (probably &gt; 99%). AFAIK, this is already solved (except iOS, but that's a political issue). If it can additionally target PowerPC Linux and Mac (older Macs, modded Playstations), that brings it significantly higher, but it's probably not worth the effort.
It looks like the set of [feature flags](https://github.com/SergioBenitez/Rocket/blob/v0.2.0/lib/src/lib.rs#L1-L7) enabled for lib.rs in 0.2 has actually increased by one (pub_restricted) since [the last 0.1 release](https://github.com/SergioBenitez/Rocket/blob/v0.1.6/lib/src/lib.rs#L1-L6).
How is this? https://is.gd/l2yJrd I had to break the error formatting code into a separate function, but that's probably just because of my limited knowledge on the subject.
That's awesome, I think that's exactly what I need, thanks! Do you know if this bit, `&lt;T as FromStr&gt;::Err`, has a name? I didn't know you could cast a type parameter to a trait like that, I'd like to read more about it.
GOT IT!!! https://is.gd/Jj9Bp7 Everything you ever wanted! No separate function required.
Its a high priority feature.
How are generics different from templates?
Non-Rust-user here. I tried Rust about a year ago and gave up on it as not ready. Unfortunately, I don't think this roadmap addresses the problems that made me reject it the first time around. The main problem I have with Rust is that it's not up to the task of dealing with C APIs, particularly POSIX. The issue I got stuck on was https://www.reddit.com/r/rust/comments/47a0s3/dealing_with_variation_in_c_ffi_interfaces/ . There are two possible things Rust could do that would make me give it a second chance: either commit to maintaining bindings for all of POSIX and libc as part of Rust core, or fold rust-bindgen into core and get it into shape. Creating higher-level libraries like Tokio is nice for some use cases, but right now Rust doesn't have a working safety valve for things C can do that Rust can't. This greatly magnifies problems like lack of bindings for select() (see http://esr.ibiblio.org/?p=7294&amp;cpage=1 ; I too ran into that problem, and lost a few days to it.)
How many times has the language been rewritten in the past few years? :)
The collective effort could be lower for people to learn their way around the labyrinth than building it from scratch. The new rewrite, if successful, will end up in the same situation in the long term, so why is it worth it? 
Sounds like you should open an issue; it's pretty much the crate for safe bindings, but as I'm sure you know, there's a lot of tiny details to get right.
Templates generate C++ code to be compiled. Generics are incomplete types which are locally specialized to a single type for their lifetime. Post compile none. Rust like C++ will resolve the interior types during the compile process... Well unlike C++ Rust also uses its generic/template system for dynamic dispatch, or can. Rust prefers to resolve the types within a generic when possible. 
&gt; If Rust was a Mozilla project we'd still have green threads. I really love those in Go, is it planned to bring them back somehow somewhere in the future?
Yeah, that's why I qualified it with "on paper", haha.
C++ templates are only type-checked after being specialized, whereas Rust type-checks the bodies of generic code based on the trait bounds in its signature. The C++ approach means one gets type errors from deep inside library code, if one passes an incorrect/invalid type, while the Rust approach means errors will be at the place the users called the functions. That said, I'm not entirely sure how the grandparent thinks the difference is relevant here. I would be very surprised if the Rust and C++ implementation approaches were significantly different; in particular, I don't think C++ compilers can be described as generating C++ code from templates any more (or less) than the Rust compiler can. The major difference is just in error messages.
The Nix crate is trying to provide a safe interface on top of POSIX/libc. This isn't something that has been automated -- as using bindgen produces unsafe functions directly bound.
I think the discussion of these runtime details is somewhat missing the point: ownership. &gt; Passing by reference is generally better then pass by value. Writing too the stack, and reading from it incurs a small but real runtime cost. This isn't true for small register sized values as they'll be passed in the registers. &gt; Comparison operators work on &amp;self (pointer to self) so passing the whole value is rather pointless as the comparison will be done with a pointer. Comparison operators take `&amp;self` because they don't need ownership, which is, "coincidentally", also the reason that `get` takes things by reference: it doesn't need ownership. Consuming a generic value would make it impossible/difficult to use with some key types, and impose a requirement for additional `clone()`s for others (a much larger cost than assembly-level parameter-passing details). &gt; For pure integers (like &amp;3 and &amp;4) the LLVM will see that you have a pointer to constant, and it'll inline that constant at the site of comparison (this is called constant propagation). Only if things get inlined far enough for the constant-ness to be true and for it to be visible, which is unlikely for something as complicated as `BTreeMap`. &gt; The LLVM will see a pointer to a integer and just leave the integer because integer values can be copied register to register at literally no cost on modern CPU's so it'll handle the pointer messiness. What does this mean? Are you trying to say that LLVM will promote some pointers into registers, when it can see that nothing cares about the value having an address? While true, I don't think it is entirely relevant. &gt; The LLVM (FYI, LLVM is just "LLVM", not "the LLVM": the name being an acronym for 'low-level virtual machine' has been retired as misleading, and it is just a "meaningless" proper noun, now.)
I'm spoiled by SublimeLinter and wish that the there was a plugin for it that supported newer versions of Rust. I'll likely try to submit a pull request to fix this.
Nix still needs to have the FFI definitions for all the functions it is wrapping safely: one could use bindgen for that part, and people for the other part.
&gt; simply because every change of scope, every functional call, requires a number of threadsafe mutations This phrase packages up many of the reasons that it can be misleading to do a blanket comparison of "ref counting" vs. GC. Obviously there's a wide variety of GC schemes, but also there's a variety of options for RC too, some of which address these comments: - aggressive language features let one avoid spurious reference counts, e.g. passing around a `&amp;Arc&lt;T&gt;` (or `const shared_ptr&lt;T&gt; &amp;` in C++) lets one avoid touching the reference count until necessary, when letting the reference escape. - aggressive compiler optimisations/runtime representations can similarly elide reference counts by doing things similar to the latter (e.g. Swift has a concept of "pinning" to avoid touching reference counts when passing down the stack, along with [other optimisations](https://github.com/apple/swift/blob/master/docs/ARCOptimization.rst)). - doing non-threadsafe reference counts is possible (`Arc` vs. `Rc` in Rust). Additionally, focusing on just tracing GC vs. RC in isolation ignores extra factors like languages that use RC (like Rust, C++ and even Swift) often offer more aggressive stack and inline allocation than languages that use tracing GC, the former is even cheaper than a generational GC's young generation (it's a statically-determined, no need to dynamically find objects that need promotion) and the latter folds objects together, reducing the number of allocations. &gt; accessing a concurrent hash map several times on every function call (how Swift does RC IIRC) No, it does basically the same thing as Rust: a reference count integer in the object. Maybe you're thinking of Objective-C weak pointers.
i know that, but still feel use &amp;3 as key abit strange,why not use coercion here?
The ignore crate is great but our slight differences in use cases make it hard to bridge the gap.
Zero.
I just released CSS for both the official playground and [integer32's](http://play.integer32.com/). Feel free to check it out (it's on the repo as well as available from [userstyles.org](https://userstyles.org/styles/138541/ayu-rs-dark-theme)). And make sure you have the `Chrome` syntax theme selected in the editor in order to use the one that I put together for this theme (all the others are able to be used as normal if you desire).
They're at odds with Rust's present-day identity as a language of zero-cost abstractions. It's one of the reasons I, for one, am so on board with the language. You can always build things like futures-rs tasks on top of the language to get similar or better abstractions if you need to.
Seems like FUD. But in the end a good article
You're my hero
Years plural, it hasn't been two years since 1.0 yet. Plus docs lag behind code.
The gist of the issue is that the author has these values that borrow each other: let alto = Alto::load_default(None).unwrap(); // bring the default OpenAL implementation in let dev = alto.open(None).unwrap(); // open the default device let ctx = dev.new_context(None).unwrap(); // create a default context with no OpenAL extension And he wants to put them in a struct like this... struct Audio&lt;'a&gt; { alto: Alto, dev: Device&lt;'a&gt;, // borrowing alto context: Context&lt;'a&gt; // borrowing dev } ...which isn't allowed. He points out that Rust would need to know the right drop order if it was going to allow something like this. That's true, though there would be other problems too. Rust would have to know that assigning to the `alto` field isn't safe, because it's always borrowed. It would also need to ensure that all the pointers that `dev` and `context` are borrowing are on the heap and not the stack, or else it would never be safe to move an `Audio` struct at all. (The [`owning_ref` crate](https://github.com/Kimundi/owning-ref-rs) has a trait for this distinction called `StableAddress`, but Rust itself doesn't keep track of it.) In this case, would it work to just make a reference to `alto` accessible from `dev`, and a reference to `dev` accessible from `context`? Then instead of trying to put all three in a struct, you could just pass around `context`?
I'm excited about trait system will be rewrited with prolog logic support, does that mean we can do logic programming easily with it?
The more you thinking on this, the more you'll agree, it is good in all aspects: simple, consistent, ergonomic, beginner friendly, ease of compiler implementation...
The problem is indeed more about the image and reputation of Rust than any concrete upheaval. Rust is compiled, linked language, and there isn't any technical reason (Edit: expect maybe for macros, why didn't I think of those.) why the compiler couldn't support both 1.0 syntax and 2.0 syntax at the same time, and linking crates of both syntaxes together, provided the changes were only syntactical. (Also, providing a rustfix tool for easy migration.) But the state of the documentation and the ecosystem of all the blog posts, tutorials and Stack Overflow answers would be the real problem of such a transition. Plus that it doesn't look good to many people.
For a second i tought i was on the subreddit of the videogame Rust and i was so confused about all this. I was like damn, you guys really go deep into the details of the game programming and stuff but what about gameplay and balance, i want something concrete. I think i need to go to bed.
&gt; Heartbleed is an implementation error Kind of a tautology though? And of course I agree with your point. 
Trait is like interface in object oriented languages, it is natural to use an interface as a type name, so is trait name.
Yes. `impl Trait` is _not_ like interface, however, `Box&lt;Trait&gt;` (and bare `Trait`) is the closest thing to what you get when you use `Interface` as a typename in OOP languages. `impl Trait` is completely different and is a concept that does not make sense in many object oriented languages.
What's the reasoning for this? How would they even be able to tell the difference between binaries?
[caps](https://github.com/lucab/caps-rs), a pure-Rust library to work with Linux capabilities. The idea is to provide an idiomatic library which fully supports modern kernel features and doesn't require an external library (useful for static targets). Written on the plane back from FOSDEM, reviews/comments are welcome!
semantic completion with YouCompleteMe + racerd: https://www.reddit.com/r/rust/comments/404nno/youcompleteme_rust/
Everyone else has given fantastic answers, so I'll speak to Go, as that's what I write in every day. Go is a fantastic language and it gets a lot of things right, but you can still get yourself into trouble. I've had several concurrency problems due to assumptions that weren't correct (thought a type/library could be used from multiple threads, but wasn't). Rust eliminates these classes of errors and eliminates the need to debug complex concurrency issues. Go and Rust are fantastic, but if I had my choice of which to use, I'd use Rust nearly everywhere.
I'd like to point out the topic where possibility of Heartbleed in Rust is investigated: https://www.reddit.com/r/rust/comments/2zd797/would_rust_have_prevented_heartbleed_another_look/ TLDR: OpenSSL authors gone long ways to write trying to squeeze last bits of performance while compromising safety. Rust would significantly lower probability of such a bug, not prevent it. Also excellent citation from the thread: &gt;No Turing-complete language can "prevent" heartbleed; 
Agree. Once we are familiar with this concept may feel the `impl ` prefix surplus.
&gt; No, even if Rust 2.0 happens it's not likely to have breaking changes like this. Why do you say so?
That the benefits are "at best questionable" is an opinion, though. That it would break a ton of existing code is not in doubt, but in my opinion the only change we're going to break over is something big enough that it would probably affect everyone. Of course, that would only happen if we built a consensus that the benefits are more than "at best questionable." I would say that as a migration strategy 2.0 would need to be a strict subset of its previous 1.X version, meaning your code could not start doing something different - just stop compiling. So there would be a period in which you have to deal with both `dyn Trait` and `impl Trait` or whatever. The only thing that I'd say _couldn't_ be part of a 2.0 change would be a change for which a strategy like this is not viable. In fact I'd say this is the most likely change to be in a 2.0 (which is not to say it has more than a slim chance of happening), because its the only breaking change I know of any will in the community to make happen. In any event a breaking change is not on the roadmap for 2017 &amp; this is idle speculation.
I see, so backwards compatibility is not easy to fix.
I agree that this is about ownership and not references. I think though that comparison operators could in addition, have an impl that takes ownership for ```Copy``` types. I'm not saying we should add such impls for this very minor syntax peculiarity, be in theory we could add them, couldn't we? 
In the long run, Rust "just" needs a better story for native dependencies. After all, bindgen is no different from any other crate that depends on libclang, other than that it isn't usually cross-compiled - but that makes it less demanding, not more. There should be a well-supported way to just put LLVM, Clang, etc. version X on crates.io as crates: not just wrappers, but actual copies of the source code for that version that get automatically compiled using the system C compiler. Including proper behavior when cross-compiling. And then ideally there should be an online crate binary cache, so people can get precompiled binaries of that or any other crate rather than always compiling everything. Well, I can dream...
Are you suggesting that Niko isn't web-scale?
I'm afraid that I can only re-hash that old joke about Niko not implementing `Clone`.
[cpal](https://github.com/tomaka/cpal) is probably your best bet right now, I'm not sure I know any other pure rust cross-platform libraries (unless you want to use bindings for PortAudio or something else).
How would this work with Drop types? I assume they would still be bound to lexical lifetimes? Also presumably structs containing drop members would also be bound to lexical lifetimes?
NLL doesn't change how types are dropped. It only changes the duration of the _borrow_ of an object. (I've seen it mentioned that "lifetime" refers to the valid span of a borrow, whereas a "scope" refers to the span of an object, despite that being the opposite of what might be inferred from their names.)
I program in Python and Rust. I am not exactly a scientist or anything, I wrote an n-body gravity simulator in python, and might port it to rust, as it is faster and could be paralleled.
But what do you do about the two others? They have to be carried somewhere. If you keep references around, you have to keep them in a way so that `alto` outlives the two others and `dev` outlives context. I guess you‚Äôre talking about my *closure* solution, something like that: with_audio&lt;F&gt;(f: F) where F: FnOnce(‚Ä¶) { let alto = Alto::load_default(None).unwrap(); let dev = alto.open(None).unwrap(); let ctx = dev.new_context(None).unwrap(); // additional init code f(‚Ä¶); }
I am interested in writing my own firmware for [this keyboard](https://input.club/devices/infinity-ergodox/). It has an MK20DX256VLH7 chip, so I think this series is going to be super useful. Thank you so much for writing this.
Unsurprisingly, we get that a lot. You want /r/playrust
I've had the same problem with working with glium. Everything was using lifetimes at the start, then I realized it was the opposite of practical and I started forcing people to use `Rc`. In my opinion having to use reference-counted objects everywhere kills the point of using Rust in the first place. In vulkano I've had a different approach, which is to make all objects generic over the pointer type. Eg. instead of having `struct Child&lt;'a&gt;(&amp;'a Parent);` I used `struct Child&lt;P: Deref&lt;Target = Parent&gt;&gt;(P)`. This caused another problem however, which is that one can write a rogue implementation of `Deref` that can make your code unsound (see [this rfc](https://github.com/rust-lang/rfcs/pull/1873)).
Resin.io is looking for a Full Stack dev with knowledge of Rust. See https://resin.workable.com/jobs/399897 . Not sure if this counts as a "Rust job" but thought it'd be good to share in case someone is interested.
Yes. Yes, if the random crate license is compatible with GPLv3. Yes, you can distribute binaries. 
Statrs should appear in crates.io's science category https://crates.io/categories/science anyway, thanks for your work, i hope to have the occasion to use it someday
What I'd like to see is the /u/Ticki's `dyn` keyword. I think that having that kind of an annotation as the recommended way to do things is valuable even if we aren't going to get rid of the `Box&lt;Trait&gt;` syntax *ever*, and only issue a deprecation lint after some time.
If you need speed: fortran or C/C++ if you need flexibility : Python or R Rust (or go or whatever) is much to young for having an interesting ecosystem.
Not that I think it is a good idea but why would it break existing code? Isn't `fn find(t : Trait)` currently illegal? 
curious: how would this perform on multi-lingual text (especially as you start to add reliability metrics)?
I‚Äôd probably also just use Python in your place. If you need speed and want to build bigger maintainable codebases, then Rust might be worth it (and you‚Äôll learn a lot about good practices in programming with it), but you will probably miss a lot in the ecosystem and will need to write a lot of stuff yourself. If you just need speed, then you can also take a look at Julia (http://julialang.org/), which is designed (as I understand it) as a fast compiled language for numerical computations with a bit Matlabish syntax.
I have to agree with everyone else here, and I'll add that [SciPy](https://www.scipy.org/) really makes it hard to go past Python for scientific computing, until such time as you start having really specific requirements that convince you that you really need something else.
Depends on how much of Theseus' ship you chopped into firewood to break both pieces
With a reliable automatic source translation tool (like Go had in pre-1.0 development) you could make quite large syntax changes without breaking existing code.
I am developing a n-body simulation code in Rust (my bodies are not planets but atoms, but the algorithms are similar), see it [here](https://github.com/lumol-org/lumol/). I considered many other languages, here is a short list of why I picked Rust over others languages: - In comparison to C, C++ and Fortran, I get safer code. Which means I can spend my time developing new algorithms, and not debugging segfaults/crashs/uninitialized memory. I am a scientist, not a developer, so the less time I spend fixing an debugging code, the better. - I wanted to write an extensible/object-oriented code with rich types, so this ruled out Fortran and C, where the standard library and object-oriented capacities lack behind Rust. - C++ is nicer, but you still get the safety issues/data races issues; and the language and tooling are complex. I tend to avoid dependencies, because adding them in a C++ project is a mess (and yes, I use CMake =)) - Python was out of the league for this code, because I needed to get all the available computing power, and numpy would not have helped a lot (the code is not based on matrix operations). - Julia was nice, the code actually started as a Julia package. Then, around 2000 loc, I started having problems with refactoring and organizing my code. Rust compiler and module system are very helpful here. - Rust promised me to enable parallelism, and Rayon looks very nice to do it. That is what I use, and why. What you should use depends on your skills, and who you will be working with. For short analysis scripts and anything short-lived, I'll go with Python, because you can use the existing code, and leverage to the whole ecosystem. For longer-lived projects, and libraries/simulation code you hope to still be using in 5 years, then Rust might be a nicer choice, because it simplify a lot maintenance and updating the code.
&gt; // btw: play.rust-lang.org timeouts if i put "args.len() &gt; 123" here - why? That doesn't seem to happen for me?
Well lifetimes refer to references correct? So in that way it does make sense as is.
You can't yet have integers as type parameters in Rust. `tiles: [[u8; X]; Y]` is illegal.
* For windowing, there's glutin. It's similar in scope to GLFW and I haven't had any trouble with it yet. * There isn't anything like three.js yet. There's the piston project, but it isn't anywhere near maturity yet. You could also check kiss3d, it's meant to be really simple, but the featureset is quite limited, unfortunately. For low-level graphics, see glium. It's a thin layer on top of opengl that makes everything safe. You still get some driver bugs, though. There's also a backend-agnostic rendering library called gfx-rs, but I haven't used it myself. * Don't know about SVG/OTF, check crates.io.
Thanks) That's exactly what I did:) (however the best would be to build mobi from the most recent sources from github repo)
I don't know if there are any official plans for a REPL. I agree with /u/icendoan that cargo check does that for me, but a real REPL would be cool too.
We'll find out exactly once there's an RFC :)
AFAIK Gnome team is working [librsvg](https://github.com/GNOME/librsvg) to eventually use rust. Currently the project is 18% rust.
You still have to worry about tooling and the ecosystem.
I mean i686.
It should be noted that [glium is no longer in development](https://users.rust-lang.org/t/glium-post-mortem/7063). Hopefully, with lessons learnt from glium, something similar can be built. There are also some libraries targeting Vulkan around. I haven't used or looked closely at any of them though. 
It would require to change any function wishing to handle linear types, of course, but that can come gradually as it's backward compatible.
A couple months ago, we ran into similar problems with gimli IIRC and ended up with this script and Travis CI config: https://github.com/gimli-rs/gimli/blob/master/coverage https://github.com/gimli-rs/gimli/blob/master/.travis.yml Hope this helps!
I've now started listing _disposition_ with today's issue.
Did you mean the [random] (https://crates.io/crates/random) crate? (As opposed to some randomly selected crate.) If so, it's dual licensed Apache-2.0/MIT and MIT is compatible with GPLv3, so the answer is yes. 
&gt; which means that sort takes any type S where S: Sortable but S itself is opaque (fully opaque for virtual Sortable) This is different from `impl Trait`. `impl Trait` is not "any type", it means that "this is a _particular_ type", without monomorphization. Rust already has `fn foo&lt;T: Sortable&gt;(range: T)`. This is not the same as impl trait. impl trait doesn't even work in argument positions. The difference is evident when returning things. `fn foo&lt;T: Sortable&gt;() -&gt; T` is a function that can return _any_ type implementing trait `Sortable`(you specify which type you want when calling it, via `foo::&lt;SomeSortableType&gt;()`), and will monomorphize to a function for each distinct type required. `fn foo() -&gt; impl Sortable` is not this. It is not a generic function. It is a function that returns a single concrete type, which implements `Sortable`, it's just that the function signature won't tell you what that type _is_ (and callers cannot rely on any knowledge about the type other than the fact that it is `Sortable`). This is useful for returning anonymous types like closures, or hard-to-name types like composed iterator adapters. In other words, the difference is basically that `Sortable` in C++ is "any type of concept `Sortable`". `impl Sortable` in Rust is "there _exists_ a single type of trait `Sortable` that I'm using here. I won't tell you what it is, but it exists". This is very different. `impl Trait` is something pretty different, and C++ does not have an analogue for it. I mean, I guess, given that SFINAE exists, abstract return types and generic return types are expressed the same way, but that's due to C++ not typechecking templates. As Rust's typesystem _does_ fully typecheck generic bodies, there does need to be a separation between "any/forall" and "exists". (I guess "existential" isn't the right term to use here. I've seen it used in this context before; but in Haskell existentials are more like `for&lt;'a&gt;` in Rust IIRC, and this concept again has no analogue in C++) &gt; So I wonder why in C++ it isn't weird to use impl Trait in argument position (and for local variables, and return types...) without an special keyword, but for Rust it is a must. It's not a must in Rust. In Rust you can't use impl trait in argument position at all. You can specify generics in an argument position. C++ has no analog for impl trait. ----------- "In a completely different design space" is debatable -- it depends on what you're talking about. C++ certainly is as low level as Rust. But Rust's type system is closer to Java's (and much closer to Haskell's) -- C++s generics are really magical macros, when you have things like SFINAE going on, and bodies aren't typechecked.
&gt; Screenshot &gt; No screenshots. Maybe this section could be omitted when there's no screenshots, instead of teasing us with it. :P
All of the comparisons the algorithm did before that patch were already of the form `cmp(...) == Greater` or `cmp(...) != Greater`, i.e. it didn't need to know whether `(a &lt; b) == false` means `a == b` or `a &gt; b`. &gt; Guess this shows how fickle compiler optimizations are. The optimisations don't seem too fickle to me: a direct `&lt;` doesn't have to waste time distinguishing `a == b` vs `a &gt; b` (which is likely to be at least an extra instruction), while hoping that the optimiser will notice that this split is unnecessary. Not ever doing work is always likely to result in code that is at least as fast as doing that work and then undoing it.
`Box&lt;impl Trait&gt;` is also valid. If every `Box&lt;Trait&gt;` meant that over night, a lot of things would break.
Ah! I see. I thought that the algorithm as somehow leveraging the richer information. If it's not then it makes much more sense.
There appears to be a [bgfx crate](https://github.com/rhoot/bgfx-rs) There's also [gfx-rs](https://github.com/gfx-rs/gfx/) which aims to be something similar, it seems. It's somewhat more low-level than bgfx and not the easiest thing to get started with though; their reference docs are pretty decent but lacking in overview/tutorial information. Don't know about SVG, but for font rendering the go-to is [rusttype](https://github.com/dylanede/rusttype). It works pretty darn well, but there are apparently some features it doesn't support yet which means it can't always load OTF font files.
It's not dead, it's pining for the fjords! Really, the right term is "maintenance mode". Maybe you can add a note to that post clarifying that?
`cpal` (and the higher-level library built atop it, `rodio`) are both quite good. If you want to use OpenAL, I believe the most popular/complete-ish bindings are `alto` and `ears`.
Say 30 language implementations. Say 3 of 10 tasks could use libraries. Say 3 applicable libraries for each task for each language. Are you saying all those libraries should be [evaluated before](https://wiki.haskell.org/Lazy_evaluation) a program has been contributed?
&gt; I don't know what the rules are Your posts still claim *"‚Ä¶the rules say‚Ä¶"* but now you say you-don't-know. Please correct your untruthful claims. ---- Your posts still claim *"C doesn't have a HashMap, so they get to write one specific for the benchmark"* but we can all see the C HashMap is not written for the benchmark. Please correct your untruthful claims.
Again, they _do_ get to use one specific for the benchmark. I am not changing anything until you actually lay out the rules. I'm also not replying to you any more.
Unfortunately, I've gone through many cases of * SomeBody (SB): Hey jabl, can you help me get this Fortran [1] program running on [new machine | new Fortran compiler] * Me: Ok. So I go and compile the program per some vague instructions given (Makefiles, who needs that when you have that 10 year old mail from you former supervisor with some shell command line). Crashes instantly. Uh oh, lets add the array bounds checking flag and whatever other debugging flags I can find in the compiler man page. Oh, looky, it aborts with an array out of bounds error. * Me: I found a bug, enable options *-foo* *-bar* run it and you'll see [2]. * SB: Unpossible, the program must be correct, we have published several papers using the output of this program. * Me: *unspeakable thoughts...* So yeah, if a bit of bondage and discipline can fix issues like the above, I'm all for it. That being said, to answer the OP, yeah, like others said, it's hard to go terribly wrong with scientific python. The ecosystem there is huge. [1] Not piling on Fortran specifically. Fortran is actually somewhat helpful here due to compilers more or less universally having array bounds checking options etc. [2] Of course, I did usually dig deeper so I found the actual error, but omitted that here in order to make the post shorter.
Is it possible to write OpenGL glsl shaders and run them as part of a piston backend?
It is possible to be truly lock-free, although it is a little tricky. You have to make sure that the append operation is atomic, and then update the "tail" pointer in a way such that other threads can assist if the original writer stalls. See here for a truly lock-free MPSC queue on a ringbuffer: https://github.com/Diggsey/lockless You can use the same technique with producers for an MPMC queue.
The behavior where you don't get any input until enter is pressed, is a property of the terminal itself, not a property of Rust. Even if you use the `read` function to read a single character, you won't see any input before enter, unless you put the terminal in "raw mode". The libraries that /u/moosingin3space mentioned can handle those sorts of platform details for you, if you don't want to dive into Unix docs.
Ooh, Servo in moz-central. What sort of things does this make easier? Is it for sharing WebRender et al without needing to use git submodules (or is m-c still on hg? hg submodules?)?
Thanks for your information, that is wonderful. Looked on crates.io before, but now I know which to use.
Could do it manually, but probably opting for the libraries! Thanks for clearing it up.
So if you are in the area on Friday February 24th, perhaps meet us in Darmstadt &amp; polish a random crate with us. This workshop is also an experiment to see if random polish works. If it does (and I'll be sure to blog our findings), we can replicate it to advance the crate ecosystem.
I benchmarked this some time ago and found the same (but different tradeoff for floats because of NAN).
Hey steve! Yep, I know this feature, but I was more looking for a "I'm working on a project with a given set of crates and I'm looking for a simple way to access the crates docs" feature. Can be handy when you are offline too...
There's also the [Compiler Explorer](https://github.com/mattgodbolt/compiler-explorer), which works for Rust, C++, D, and Go and provides color-coded visualization of how the higher-level language constructs translate to x86 assembly: Hosted instances: * http://rust.godbolt.org/ * https://gcc.godbolt.org/ * https://d.godbolt.org/ * https://go.godbolt.org/
It looks like your queue requires that the maximum number of senders is known ahead of time for the lockless implementation, but that is a pretty neat algorithm. I'll have to update the readme! I think the goals are different as well - your queue seems more suited for hard-realtime systems that can make such promises, but there are some tradeoffs in the pop method that would hurt latency on a modern server class machine.
&gt; That doesn't mean you couldn't (or shouldn't) use them for before-the-fact resiliance. It means that it's incorrect to extrapolate these things to a principle of resiliance, which is what you want in a language if resiliance is important. &gt;&gt; Erlang's principal philosophy is literally "Let It Crash", and many of its features are built around this. &gt; That doesn't mean you have to follow "best practices" to the letter. I certainly don't. It means that the language is not designed to aid you should you follow a different philosophy. &gt; That said, the point of "Let It Crash" is often to prevent exactly the sort of situation you're seeking to prevent: the sooner our filesystem process (for example) crashes, the less risk of it (in this example) doing something harmful to the underlying data The alternative I'm promoting is more static checks, preventing things going wrong in the first place. &gt;&gt; Saying "you can't be perfect so don't bother trying" is a terrible argument. &gt; Indeed, which is why it's not my argument. My argument is and has been "you can't be perfect so be ready to eat your mistakes". That argument is exactly "you can't be perfect so don't bother trying" because it's a bait and switch. The more important goal for these projects is not to eat mistakes, but to avoid mistakes in the first place. Putting emphasis on eating mistakes is a distraction from the issue, and results in the same fundamental problem of not focusing enough on before-the-fact verification. &gt; "fault-resistant" (as you say; I'd probably opt for a term like "fault-preventative" to better describe the Rusty approach) The term "fault-resistant" was chosen arbitrarily. I'm happy to switch if it would clarify things for you. &gt; I don't. I prefer spending half a *second* "rebooting", and not losing the entire system state when I do so :) *That wasn't the question.* I'm unsure know how to write this in prose any clearer than I have, so let's try bolding things. Hopefully this doesn't come off as aggressive, but I suspect it might work. If Rust's safety checks mean **anything at all**, then Rust code will be **more fault-preventative** than the equivalent Erlang code. This means Rust code is **more likely to preserve an uncorrupted or recoverable file system state**. This means that the Rust code is **less likely to result in irrecoverable corruption**. Similarly if Erlang's fault tolerance tools mean anything at all, then Erlang code will be more fault tollerant than the equivalent Rust code. This is where the trade-off comes from. Pointing out that you can write fault-preventative Erlang code is **completely, utterly beside the point**. Saying that you can write a journal in Erlang is **also completely beside the point**. We're talking about **relative merits**. Rust's relative merit here is that it has **more static verification**. Erlang's is that it has **more fault tolerance**. As said elsewhere, **fault-prevention provides safety** and **fault tolerance provides availability**. &gt; This is again comparable to the difference between a monolithic kernel and a microkernel (in fact, it might as well be synonymous): all your drivers sharing their memory with one another and the kernel v. all your drivers being isolated processes that can stop and start independently from one another (respectively). Again, this is talking about code, not data. Ergo it is irrelevant. &gt; At this point, I feel like associating fault-tolerance with data corruption is itself a strawman. *That* is a strawman. I am **not** saying that. I am saying **fault tolerance is associated with availability**. Being fault tollerant says **nothing at all** about how resistant you are to data corruption. The reason Erlang is more suceptible to data corruption than Rust is that it has **less fault-prevention**. That is the **only** reason. &gt; Real-world journaling filesystems are implemented in languages with far worse "fault-resistance" than Erlang Ergo the appeal of Rust; it lets you have more of what's important without sacrificing things low-level driver writers won't sacrifice, particularly performance and lack of runtime. &gt; Must like how it's not fair of me to assume that Rust's only recourse in the face of an error is to `panic()`, it's not fair of you to assume that Erlang is entirely incapable of preventing errors before they happen. I'm not assuming that. I'm saying it's *comparatively* worse at this than Rust. &gt;&gt; corruption can result in permanent, unrecoverable errors &gt; And the sorts of corruptions we've been discussing are very rarely (if at all) subject to mitigation by compile-time safety checks Strongly disagree. I can give you a bunch of examples if you need, but a simple one to start with is enforcing correct handling of a state machine through use of affine types and move semantics. https://insanitybit.github.io/2016/05/30/beyond-memory-safety-with-types Rust makes it very easy to take invariants you must uphold in "the world" and enforce them in the type system because move and borrow semantics are powerful tools for tracking external state statically. &gt; it doesn't come anywhere close to [the sorts of things normally implied by the term "formal verification"](https://en.wikipedia.org/wiki/Formal_verification) Showing that there's something better does not make everything worse *equally* worse. It just means that there's something better. If the (extremely high) cost of formal verification is worth the gains for your project, and in some cases (eg. cryptography) it is, then you should use a formally verified language. I have no qualms with that. 
Again, you have claimed more than "get to use" you have untruthfully claimed: -- "so they [**get to write** one specific for the benchmark](https://www.reddit.com/r/rust/comments/5queq5/how_high_performance_is_rust/dd29td5/)". Your refusal to correct your untruthful claims shows that you make those claims in the full knowledge that they are untruthful.
I'm not completely familiar with Iron (though I use it for some basic stuff), though you typically do this through a cookie or something. The usual process for maintaining state between requests is: - receive request - store data in database using an id - set a cookie to reference the id from previous step - on page load, request the data associated with the id The reason for this is that a redirect is sent to the browser, then the browser requests the page that it's redirected to. You can template this into the HTML page if you don't want to request it from JavaScript. You can use [handlebars-iron](https://github.com/sunng87/handlebars-iron) (haven't used it, but it seems decent) for doing templating if that's the direction you want to go. I typically build websites as a single page application, where instead of using a `form` post, I send the data with JavaScript using XmlHTTPRequest and handle updating the page in JavaScript. This eliminates the need for cookies (you can maintain state within the JavaScript session instead of the server), which is nice as it makes the server a bit simpler.
mozilla-central is still hg. The idea is that right now the Servo subdirectory is read-only (except for updating the vendoring), but in the near future we're going to turn on bidirectional syncing so changes to mozilla-central/servo will be automatically committed upstream on github. This should streamline the process of making changes that bridge Gecko and Stylo significantly.
It doesn't look like it runs things in parallel at all since the number for ns is 200 and below the threshold. See here: https://users.rust-lang.org/t/calling-rayon-users-opinions-wanted/7290 And here: https://github.com/nikomatsakis/rayon/blob/master/src/par_iter/len.rs#L40 To answer your question: Rayon is not creating a new thread pool each time. IIRC it's initializing it once using a registry: https://github.com/nikomatsakis/rayon/blob/master/src/registry.rs#L54 If you're interested here is an overview and comparison of some parallelization crates I made some time ago: https://github.com/willi-kappler/mandel-rust 
I indeed decided on rustyline! Maybe one day I'll do it by hand, but right now the goal is to do this: http://www.buildyourownlisp.com/ in Rust which is why I needed the functionality in the first place.
Thanks, this one fixed it. Well at least I get different errors to think about. But if I think about this: As Point2D acts on a generic type, it has to know, what kind of type the function is expecting, correct? Could I use a generic type instead of f32?
&gt; works as well since auto foo(args) -&gt; X is equivalent to X foo(args) Which is equivalent to `template&lt;typename T&gt; requires X&lt;T&gt; T foo(args)`, no? The reason that works is deferred call site checking of templates, a feature unique to C++'s substitution-based template system. C++ does not typecheck a template body assuming that all valid values of the parameters should be allowed. C++ will defer typechecking for until the template is fully substituted. Rust's generics work differently. If I have `fn foo&lt;T: Trait&gt;() -&gt; T`, calling `foo::&lt;SomeStruct&gt;()` will always work provided `SomeStruct: Trait`. This is not true in C++; you can have substitution failures. This is a fundamental difference between the two systems, and due to this it is important to disambiguate between `-&gt; impl Trait` and `-&gt; T where T: Trait` in Rust. Using bare concepts as existentials in C++ makes sense, kind of. But it only makes sense due to a feature unique to C++s template system -- it's wrong to blindly compare the two. In Rust there's a clearer distinction where this is involved, and hence it's important to have different syntax. &gt; You mean as in _ is inferred only from the function body right? Yes &gt; `fn foo&lt;T: Sortable&gt;() -&gt; Sortable` could get the return type deduced from the call site, but `_ : Sortable`/`impl Sortable` cannot? There's no call site inference in Rust, except for closures. --------- Regarding your edit to your previous comment, &gt; Or in other words, why does the user need to easily differentiate between existential types and "forall" types in practice? For example, should C++ use: `auto foo() -&gt; existential Callable&lt;void(void)&gt; { return [](){}; }` My point is the confluence of `auto` and `-&gt; Callable` is already unique syntax. I'm not suggesting C++ do something extra here. Besides, due to monomorphization-based-typechecking it's totally fine to return a concrete type when a template parameter is expected, so it makes sense that you can just use `Concept` when you want an existential. 
In that case, that's just confusing, really -- I assumed it desugared to a template because that made the most sense. `Concept` in argument position makes a template, but in the return type position makes an existential? That's .... very strange. It makes sense in one way, but now you have a type meaning different things in different positions, which is unexpected. Ultimately, I'm not sure that there's much value in comparing Rust's design here with the design of something similar in a language with a _very_ different type system. Especially if the mere idea of typeclasses is something that's being bolted onto the language later in its evolution (which involves a different set of tradeoffs from needing to integrate with the existing type system).
 fn solve_bezier_curve_debug&lt;T&gt;(original_pts: &amp;[Point2D&lt;T&gt;]) -&gt; [Point2D&lt;T&gt;]{ would make the function generic
The finished chapters of the new book were my introduction to Rust; my first low-level language. I've said it before but it's fantastically written‚Äîeasily the most digestible intro book I've come across. My thanks to everyone who contributed to it.
Thanks those `-Z` flags! Loading and serializing the dep graph is indeed where it's spending lots of its time: $ cargo +nightly build | grep "graph" Compiling app v0.1.0 (file:///.../app) time: 8.949 load_dep_graph time: 0.000 assert dep graph incremental: 65642 nodes in dep-graph incremental: 5168906 edges in dep-graph incremental: 4961206 edges in serialized dep-graph incremental: 17944 hashes in serialized dep-graph time: 7.595 serialize dep graph Finished dev [unoptimized + debuginfo] target(s) in 36.40 secs (`MIR optimisations` is another big one at `8.667`) I don't _think_ the codebase is too weird in any obvious sort of way: $ cloc src/ ... Language files blank comment code ------------------------------------------------------------------------------- Rust 66 1101 29 7455 ... $ git grep "\bmod " src/ | wc -l 16 $ git grep "\bfn " src/ | wc -l 221 $ git grep "inline" src/ | wc -l 0 
&lt;3 &lt;3 &lt;3
The cost model can even be just different. A generational GC, if it's implemented with a copying strategy, costs less to free an object in the nursery than to retain it. Allocating into the nursery is just a pointer bump, and "deallocating" from the nursery is done by not copying it into the old folk's home and marking the entire nursery as free.
https://is.gd/mZezGF
For reference --- I agree that Go can do this. I updated the OP to say so. Of course, you're still locked into the inevitable tradeoffs imposed by GC.
`use self::Color::*` should do what you want. The `Option` variants are imported by the prelude.
You may want to run [clippy](https://github.com/Manishearth/rust-clippy) on your code.
One way to fix this is to have mod cpu; pub use self::cpu::Cpu; // or pub use self::cpu::*; in `cpu/mod.rs`. That way you can `use cpu::Cpu` and keep `cpu/cpu.rs`.
Awesome, thanks! I'll be sure to clean those up soon :)
Very nice. It could be interesting to have a benchmark with 1000 particles. This will probably require a Verlet neighbor list or something similar to keep track of pairs particles that are close enough to interact, and that may or may not highlight an extra cost of safe rust checking ranges when using indexes.
Is there really no ^ or ** equivalent
Absolutely! I was considering it a few days ago but never got around to setting it up. Will do soon.
Very weird...
It's not been mentioned but the glutin developer also heads [cpal-rs](https://github.com/tomaka/cpal), a pure Rust audio library that leverages futures-rs.
Yeah I kinda assumed so. I don't know, I just guessed that rust would have something like that built in.
&gt; It means that the language is not designed to aid you should you follow a different philosophy. Except in this case it seems to be, seeing as how Erlang prohibits a very large class of unsafe things (particularly around shared mutable state). Despite Erlang's philosophy ostensibly being "let it crash", there's clearly an attitude of "don't crash if you don't have to". I think part of the confusion here is that "crash" is a bit ambiguous in this context. In the Rust world, "crash" means "segfault". In the Erlang world, "crash" means "send an exit message to your supervising process". Those have entirely different semantics and properties in fault resistance/tolerance, and treating them as equivalent is only going to lead to confusion as it seems to be doing now. &gt; The alternative I'm promoting is more static checks, preventing things going wrong in the first place. Which - again - is not a silver bullet. You can't always prevent things going wrong. &gt; That argument is exactly "you can't be perfect so don't bother trying" because it's a bait and switch. It's not, and this conversation is starting to become way less fun when words are being put in my mouth. You should obviously try to prevent errors. You should also try to handle them should they occur anyway. I have been very consistent and repetitive with that viewpoint, and yet you're continuing to paint my viewpoint as "don't even try to prevent errors". My entire argument here is "errors happen anyway and you need to be prepared for them". That does not mean "don't try to prevent errors" in any way, shape, or form. It means be prepared when they *do* happen, regardless of whether or not you decide to prevent them (and you *should* decide to prevent them, but you should also decide to recover from them, too). &gt; Pointing out that you can write fault-preventative Erlang code is completely, utterly beside the point. &gt; Saying that you can write a journal in Erlang is also completely beside the point. Then bringing up a journaling filesystem at all is completely beside the point. &gt; As said elsewhere, fault-prevention provides safety and fault tolerance provides availability. The implication here is that availability is somehow not an aspect of safety. I disagree *very* strongly here. Availability is absolutely *vital* to safety, since a full-system crash means *crashing every other component of the system*, including safety-critical aspects. If I have two filesystem processes running (say, one for internal storage and one for an external SD card, as is reasonably common in embedded devices), I don't want one process crashing to bring down the other in the middle of a write. I want the non-crashed process to at the very least have the opportunity to finish its write operation rather than leave its own data in an inconsistent state. If we're going to ignore the fact that Erlang can be used to write fault-preventative code, then it's only fair to ignore the fact that Rust can be used to write fault-tolerant code, and therefore will fail *horribly* in situations where two ostensibly-independent systems end up in a cascading system-wide crash. Yes, obviously you should try to prevent those crashes in the first place, but when that's not an option anymore (like - again - if the compiled code itself is corrupted after compilation or the programmer forgot to include a certain state transition or some piece of hardware failed unexpectedly or what have you), the system should at the very least not crash other things. That is a very basic safety requirement in virtually all but the most trivial of safety-critical systems. My car's engine timing subroutine shouldn't stop mid-operation just because the EVAP sensor check subroutine choked on some anomalous value. My filesystem shouldn't stop in the middle of a write operation just because some unrelated process tried to divide by zero. My rocket's engines shouldn't spontaneously shut off (or equally bad: fail to shut off at the prescribed time, thus sending my satellite to a heliocentric orbit instead of the Moon) just because the guidance system lost contact with ground control and is stuck in an infinite loop trying to reconnect. &gt; I'm not assuming that. I'm saying it's comparatively worse at this than Rust. And Rust is likewise comparatively worse at fault-tolerance than Erlang in its default state. And as explained rather thoroughly above (and in previous comments), fault-tolerance and system-wide availability are absolutely essential in the overall safety of most real-world safety-critical systems. The difference here is that Erlang at least tries to do both out-of-the-box, even if the fault-preventative aspect is not necessarily billed as such, and even if it doesn't go to quite the same lengths as Rust. &gt; I can give you a bunch of examples if you need, but a simple one to start with is enforcing correct handling of a state machine through use of affine types and move semantics. This assumes (as I subtly alluded to above) that the programmer actually addressed all possible states in the state machine, and that the state machine actually corresponds to reality. This ain't always the case, especially when interfacing with hardware. Meanwhile, as a counterexample to this "Rust can catch anything at compile-time" attitude, there's also the fact that Rust *doesn't* catch everything at compile-time; [out-of-bounds indices, for example, won't cause problems until runtime, upon which the code will panic](https://github.com/rust-lang/rust/issues/33701) (and no, that bug being "closed" does not mean "fixed"; per the comments, fixing it would be a breaking change that could land no sooner than Rust 2.0). If you're reading external data for use as an index (as is not-unheard-of in filesystems, network protocols, etc. involving complex data structures), and the resulting index is outside the bounds of the array you've allocated... whoops, you've got a `panic()` on your hands. Same deal for [overflow errors](http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/), mind you; Rust doesn't catch their possibility at compile-time, and to make things even better, the behavior is different if you're building for `debug` v. `release` (the former `panic()`s, the latter wraps around; the programmer *does* have control over the exact behavior, and in fact does so in some rather elegant ways, but the persistent theme here is that Rust won't prevent this at compile-time, meaning that it's possible for this to happen unexpectedly in a Rust codebase). Overflow/wraparound errors are notorious for data corruption in - you guessed it - filesystems. &gt; Showing that there's something better does not make everything worse equally worse. It just means that there's something better. I brought up formal verification to illustrate that Rust and Erlang are actually very close in terms of fault-prevention in the grand scheme of things. They're both in the class between full-blown "this software is provably and mathematically correct" and "this software might have shared mutable state managed in an unsafe manner". Both Erlang and Rust are in the general category of languages which prevent the possibility for unsafely-shared mutable state (by disallowing mutability/sharing and by restricting them, respectively) and segmentation faults (at least when not subverting the safety mechanisms with NIFs / `unsafe {}`, respectively), and while one is certainly better at it (in some respects) than the other, the improvement is actually comparatively minor when comparing across all programming languages/environments.
This is really cool! I've been working on a CHIP-8 emulator myself after watching the yupferris streams. You should swing by the [emulation development slack](https://emudev.slack.com) if you're looking for another place to hang out and talk about (rust) emulators. I found it to be super friendly and fun.
That's pretty neat :) I read a few things about the CHIP-8 and it seems a bit strange compared to a lot of the architectures today lol I might check out that Slack channel, though I haven't used Slack before but wouldn't hurt to give it a shot!
I believe you can just press them as extra flags. It shouldn't matter since both Linux and Windows should be using the new build system with Python. If you're lost try running `python x.py --help` which should let you know what's possible with the build system. The readme or other files might be able to help out if my answer was incorrect.
Updated my proposal.
Ping me if you need any help.
So the post about [similarities between Elm and Rust](https://dev.to/martincerny/what-elm-and-rust-teach-us-about-the-future) is out!
I don't think it is "useless". Roughly I think that: - types are a form of documentation, some type information makes code easier to read - types are a contract, code with _exact_ types is inflexible, but API changes are diagnosed early IMO existential types give you the best of both worlds. Consider let x: impl Iterator = foo(); // with existential types let iterator = foo(); // without existential types I consider the first one "easier to read" because from the call site, `foo` can return anything. The exact type of the iterator is probably irrelevant, but knowing that it does return an iterator (and shall do so forever) is helpful while reading and refactoring (safe, easy and fast refactoring is something I enjoy in Rust). The second example in my opinion smells, if only because the variable name contains type information that cannot be checked by the compiler. I guess a similar argument could be made about `impl Trait` in function argument position, but if one need that _now_ one can go to full blown generics, and using `impl Trait` in function argument and return type position has its downsides, e.g., even if changing the exact type is allowed, doing so is still probably an ABI breaking change.
&gt; There's also gfx-rs which aims to be something similar, it seems. It's somewhat more low-level than bgfx and not the easiest thing to get started with though; their reference docs are pretty decent but lacking in overview/tutorial information. Certainly true, a lack of tutorial, but I find looking at the examples is actually pretty informative. I've been quite happy with gfx-rs.
I'm very sad to hear that. Glium was the best effort in hardware accelerated graphics I've seen for many years.
&gt; It is hard to tell, why are you considering doing that? That is, what is your motivation? I want this project to be easy to maintain and fast. Learning more Rust would also be nice, of course: last time I‚Äôve used Rust was in the early 1.0 days. &gt; For example, you can replace OpenMP today mostly with rayon, but rayon programs look very functional in style. Depending on what you are exactly doing with OpenMP you might want to use something else though (like a thread-pool, or cuda... or the simd crate... or all of them... OpenMP can do a lot of things...). Ooh, rayon looks good, but didn‚Äôt pop out in my searches. Thanks! I‚Äôm doing exactly two things with OpenMP. In the main: #pragma omp parallel #pragma omp single nowait Then, inside a recursive function, just before calling itself: #pragma omp task So basically a thread-pool, with no synchronization between threads. &gt; For math you can try ndarray, or if you are doing geometry manipulations you might want to try some geometry library. ndarray sounds like overkill. I only need x and y fields, the four arithmetic operators, L1-norm and L2-norm. &gt; It might well be that you end up with a smaller, faster application in Rust That‚Äôs my hope, yes (= I‚Äôd be really impressed if the Rust code turned out *faster* than the (heavily optimized) C code; I‚Äôm only asking for ‚Äúalmost as fast‚Äù. 
&gt; There will only exist one implementation of it in generated code. What is the type of the value returned? isize? u8? Consider a slightly different implementation: fn number() -&gt; impl Ord { 255 + 1 } Is this guaranteed to not overflow‚Äîi.e. guaranteed to use a type that isn't i8 or u8?
Porting your program to Rust (in particular if you don't know Rust well) takes a lot of effort. Given that you will end up with a program that will probably behave almost identical in both cases, and that doing nothing (keeping your program in C) takes no effort, I would say that porting it to Rust is not worth it _for you_ in this case. If your main motivation would be to learn Rust, then it would be totally worth it. But it isn't, so if it isn't broken, don't change it. Add more features, or write some other program you need in Rust next time.
If you just want to check for correct syntax with no extra codegen, you can use `cargo check`, which for a project of this size should by my estimate hover around 1-5 seconds depending on your processor and many other factors. Also, expect this to change in the near future, as increasing the 'pleasantness' of the edit-compile-debug cycle is one of the big goals on the [2017 Roadmap](https://blog.rust-lang.org/2017/02/06/roadmap.html). EDIT: spelling
You should read the other comments, the author claims otherwise.
Note that you need to go to https://slofile.com/slack/emudev to join. After you join you can use either the Slack client or a normal IRC client to connect.
In fact, there's already stuff on nightly for this, so OP should develop on nightly for the time being. I haven't played with it yet, but initial reports seem promising.
&gt; Given my requirements, would Rust be a good fit, or am I better off sticking to C? The best thing you can do is trying to port your code *incrementally.* So your code will be always working and you can try things without fear. See [Rust out your C](https://github.com/carols10cents/rust-out-your-c-talk) for more details. Also, see [A Guide to Porting C/C++ to Rust](https://locka99.gitbooks.io/a-guide-to-porting-c-to-rust/content/). &gt; Should I use Corrode, or do the porting manually? You definitelly don't want to use Corrode on the whole codebase. 
Thanks for the links! &gt; You definitelly don't want to use Corrode on the whole codebase. That‚Äôs sad, but mostly expected.
Another neat thing: Adding `--open` to `cargo doc` automatically opens the generated docs in your browser.
Hi! So I've been writing a neural network library as a platform for exploring Rust and, while the library is still in pretty rough condition, I think this image upscaler is ready to see the light of day. Let me know what you think!
I wouldn't call what you are doing recursion: the rec function and the closure are only evaluated once per iteration of the for loop, rendering the closure kind of superfluous. What are you trying to achieve more specifically?
Not related to Rust but since you have an example which talks about money you really should be using integers and not floats. Even if it is not really relevant to what you are explaining it is something that one should never do even in examples (0.3333333333 $ is not monetary quantity). 
This link might be enjoyable for you as well: https://people.gnome.org/~federico/news-2016-10.html#25 He has since written probably a dozen articles detailing each facet of porting existing C code to Rust by hand. His writings are very good reads, in my opinion.
What is a stemmer and why do you use it over and over without defining it?
The readme says, "now with fearless concurrency", but I looked through the code and found no use of any concurrency features. Am I missing something?
Thanks! Performance is quite good on recent CPUs thanks to basing sgemm on bluss' matrixmultiply. Alumina won't have good GPU/cuDNN support any time soon, although a knocked together arrayfire sgemm is doable. Currently Rusty_SR isn't trained to handle jpeg artefacts unlike waifu2x, however I have already started building an image et based dataset of various levels of jpeg compression. It is certainly easier to compile/set up though. The reconstruction quality is visibly better than SRCNN which waifu is based on, but I haven't got a luminance only psnr value on hand to compare to a more recent neural architecture like VDSR. 
If you don't have traits, you can implement the same method on two different objects, but there's no way for them to them to be used interchangeably. This makes any generic code that actually interacts with the objects impossible. Traits are a way of telling the compiler "the `foo` method on `Bar` does the same thing as any other `foo` method on other objects that implement `BazTrait`. As a bonus: &gt; you can only define the signatures of methods in them. Is technically wrong, you can define any number of actual functions, as long as they only rely on other methods of the same Trait. [`Iterator`](https://doc.rust-lang.org/src/core/iter/iterator.rs.html#31-2142) is a great example: Define `next`, get dozens of methods for free.
 fn rec&lt;F&gt;(...) -&gt; F The type parameters are chosen *by the caller*, and the caller cannot possibly know what the type of a closure inside a function is going to be. Also, the compiler *will not* infer types in signatures by design. To do this, you need `impl Trait`, which isn't stable yet. However, even *then*, it won't work because you still have to specify what the return type of the `Fn` is, and there's no way to refer to a recursive type without first giving it a name... at which point, you're back to using something like `Marker` at some point. So, basically: because that's not how generics work, type inference doesn't work there, and you can't write a recursive type without names. :P
&gt; The readme says, "now with fearless concurrency", but I looked through the code and found no use of any concurrency features. The author must be a /r/programmingcirclejerk follower, "fearless concurrency" is regularly used as a reference to Rust there ;-)
Nailed it! 
Agree with your comment. In addition: Despite the advantages currently offered by Rust, C is a very mature language and it would take a lot to justify moving from a very stable and mature language to a somewhat stable and not as mature one. Especially if the features offered by Rust isn't really needed. If it ain't broke then don't fix it. 
They are equivalent to Java interfaces. You can also `impl` for traits to create other traits. You can read about the general idea here https://en.wikipedia.org/wiki/Composition_over_inheritance .
Thanks, that's was a good resource.
&gt;[Open Source vs Closed Source](https://i.imgur.com/tJ2JEVb.jpg) I'm mad.
I recently found out about true color escape codes (allows you to set the foreground/background using RGB). It looks like it's not supported very well. Konsole/Yakuake (my terminal in KDE) support them, but I wouldn't start using them in my programs yet. Someone compiled a [list of supported terminals](https://gist.github.com/XVilka/8346728#now-supporting-truecolour), and there are a couple big ones in the [unsupported list](https://gist.github.com/XVilka/8346728#not-supporting-truecolour). I've implemented lolcat in Python and C, and ended up converting RGB to Hex, and then from Hex to the closest matching 256 color based on a [map from closest-hex-value to terminal code](https://github.com/welbornprod/colr/blob/94e2ebd56df386c553b39a2ee22c1c5a13a8be1f/colr/trans.py#L300). The original mapping was done by [Micah Elliot](https://gist.github.com/MicahElliott/719710), but he was using a list of tuples. I'm using RGB in the C version, only because I'm not looking forward to implementing that map in C. My original use case was a small terminal color library ([Colr](https://github.com/welbornprod/colr)), and the C version is just for learning purposes.
This seems interesting at the first sight, but I find it difficult to understand what it actually does. The documentation is clearly missing. Thank you anyway!
Well, I found a way now with your explanation to do it: /// drop i elements from a list, returning a mutable reference to the tail /// returns None if the list is smaller than the number of elements to be dropped pub fn nth_node_mut ( &amp;mut self, i : usize) -&gt; Option&lt;&amp;mut List&lt;T&gt;&gt; { let mut i = i; let mut tail = Some(self); while i &gt; 0 { if tail.is_none() { break} else { i -= 1; tail = tail.unwrap().tail_mut()}} tail} They key is to not store the tail itself in the variable but what is essentially a dummy placeholder Option that contains it. And the `tail = tail.unwrap().tail_mut()` line that updates it. Since the old tail is unwrapped it isn't borrwed but moved into unwrap so no more references to it remain and one is free to immediately re-assign the return value.
Graphics-related application are often using even more bits to represent colors (even 48). It seems that terminals will follow.
speaking of crates, it's totally OK to embed quite a few less restrictive licenses into GPL. Crates licensed as BSD, MIT, or Apache, for instance, are safe to be using. also note that GPLv2 can't be upgraded to GPLv3 unless it specifically mentions "or later versions" (which is frequently shortened to a GPLv2+ license) I'm a proponent of licensing libraries as MIT and fully functional software under the GPLv3, so have at it
I understand that it might be better to use same repo, but in my case it makes more sense to have several crates inside single git repo. I'll just try it out. I managed to solve the openssl issue but I hit libiconv issue. Wish me luck... :/
Please note that the main reason for the inferior performance of Rust's benchmarksgame entries is that there are only few folks optimizing them, whereas, say, the C entries have seen much more refinement. Also there have been some regressions we haven't been able to track down, e.g. n_body.
Does this mean it will be possible to `cargo build` a new compiler from git?
https://github.com/rust-lang/rust/pull/39633
Oh nice! Yeah I probably will, I have a folder of references and docs that I'm using right now but the more the better, definitely. Thanks for the link and good luck with your project! :D
Yeah, the examples are pretty solid.
Sounds good, its nice to have a lot of references to other projects people have done for if I get stuck or need to understand something better. Thanks for the link! :)
What runs the build script when you don't have a Cargo yet?
It would be nice if it could override pre-existing coloring versus printing butchered text.
https://www.reddit.com/r/rust/comments/5stcgf/the_makefiles_are_dead_long_live_rustbuild/ddhqw4q/?st=iyx7mwdx&amp;sh=96bea66b
MAYBE ;)
What installs python? You have to assume the user as _something_ to start the dependency chain. Removing a 3rd party tool is what I thought this patch was trying to move away from. 
&gt; Removing a 3rd party tool Nope, this was about removing `make`, specifically, and moving to cargo to build. Python is very widely installed, and it was still required previously.
Even with undefined behavior, the C language is still more stable and mature than rust. I subscribe to this forum because I like rust, so my intention isn't to discredit rust. In the context of the discussion, moving from a mature language to a less mature one is generally a bad thing when there isn't any other justification for the move.
This is ok to have a python script for the unfortunate people who have not been blessed by the holy cargo yet. But it would be great for the enlightened ones to be able to build everything with a `cargo build`
&gt; Why is std::sync::TaskPool only documented in two-year-old pages? Was it deleted? What‚Äôs the replacement? Lots of things used to exist in pre-1.0 Rust which were removed. In this case something like rayon may suit your needs better. There are also threadpool crates on crates.io. &gt; Should I use Corrode, or do the porting manually? For a 2.5k line codebase I think it's easier to just do it manually but idk. Corrode gets you past the "wrap everything in unsafe" part quickly. &gt; Given my requirements, would Rust be a good fit, or am I better off sticking to C? Rust is a pretty good fit. Parallelism is great in Rust, with lots of cool libraries making it dead easy. As others have mentioned, there's not much *point* to doing such a porting unless the main goal is to learn Rust. Or unless you're having lots of trouble with parallelism in C or in general find the codebase hard to work with.
Why not a collection of shell scripts? Every system has a shell.
In addition to using cargo-vendor, there's also [cargo-local-registry](https://github.com/alexcrichton/cargo-local-registry) which I think will meet your needs of having a place that multiple repositories could get their crates from. I don't think it runs a server, I think it just collects the tarballs onto the filesystem.
If the is no concurrency, you don't have to fear it.
well, I am practice or trying Rust, nothing more and I am not asking XY problem. I just wondering about why something I could do in Python like rec(5)(5)(5)(5)(5) in Rust I have to create a wrapper to achieve the goal. Sorry about my English.
&gt; It can't work on function arguments since inference doesn't exit functions. Indeed.
a python but which python? 
I find it easier to read and it's a personal teaching exercise anyway. I find: } } } } Incredibly obnoxious. C sort of kept it to a tolerable minimum because you have less nested expressions but in a lot of rust code you waste 8 lines under half your functions "unwinding the scope" with lines that contain only a brace and whitespace. With lisps it goes even further how many nested braces there are so they just decided to put them all behind each other and call it good. The reason Haskell decided on indentation-based scopting probably in no small part has to do with that if you use braces you also get stuck with that. And like you said, it basically has the effect of making the code look like Python, you mentally decide what belongs where more by indentation than counting braces anyway so I don't really see the problem in clarity myself.
So I have a pretty decent understanding of inlining and what it's used for, I guess I'm more curious as to how the compiler determines what to inline. I suspect it has heuristics to determine things that should be inlined even if no `#[inline]` attribute is supplied, and I also suspect that the compiler would naturally inline the method like `get_bc` based on these heuristics. An emulator will naturally have a lot of methods like your example above, is it reasonable to have to provide an `#[inline]` attribute for all of them?
I think its more so to make sure the compiler does decide to inline it when appropriate, sorry if I missed that part of your question. I'm not quite versed on how `rustc` does optimizations on functions like that without adding the attribute. I messed around with [the Rust version of the Compiler Explorer](https://rust.godbolt.org) and it didn't inline the example square function until I set it to `#[inline(always)]` so your mileage may vary depending on build flags/debug/optimization level/etc.
This is more of a stylistic question than anything else. I finally got my feet wet with variable lifetimes, solving a problem this way: fn decode(&amp;mut self, buf: &amp;mut EasyBuf) -&gt; std::io::Result&lt;Option&lt;Self::In&gt;&gt; { if buf.len() &lt; 12 { Ok(None) } else { let mut length:usize = 0; let mut code:u8=0; let mut byte_count:usize = 0 ; // Scope created just for z so it goes away before we run parse() { let z = buf.as_slice(); code = z[7] as u8; length = match FunctionCode::from_u8(code).unwrap() { FunctionCode::WriteMultipleCoils | FunctionCode::WriteMultipleRegisters =&gt; { if buf.len() == 12 { 0; } byte_count = z[12] as usize; if buf.len() &gt;= byte_count + 13 { byte_count+13 } else { 0 } }, _ =&gt; 12 } } let S = &amp;buf.drain_to(length); The *z* slice had to go away before I could get back to using *buf*, so I just an inner scope. Is this, as opposed to naming the lifetimes, something Crustaceans approve of doing?
Not the right subreddit.
It's not just evolution of the standard - the main issue is compiler optimizations getting more and more aggressive. A lot of things that were always UB "worked" in the past because the compilers weren't smart enough to optimize them. Then one day, you upgrade GCC, and boom.
This is a bug with how lifetimes/borrows are tracked when something is reinitialized, and can be worked around by moving out of `tail` into a temporary before calling `tail_mut` (this is essentially what the `Option` suggestions are doing). This ensures the compiler understands that it is okay to overwrite `tail` with a new value borrowed out of it. See http://stackoverflow.com/a/27083650/1256624 and https://github.com/rust-lang/rust/issues/10520 for more info.
But that's not the case, not even here pub fn nth_node_mut(&amp;mut self, i: usize) -&gt; Option&lt;&amp;mut List&lt;T&gt;&gt; { let mut i = i; let mut tail = self; while i &gt; 0 { if let Some(tail_) = tail.tail_mut() { i += 1; tail = tail_; } else { return None; } } Some(tail) } If you get into a situation where you're getting that many curly braces just one after the other, with no useful work being done, you probably need to apply [early return](https://softwareengineering.stackexchange.com/questions/18454/should-i-return-from-a-function-early-or-use-an-if-statement) to the way your logic is laid out at that point. In your particular case, you could probably even use a [`while let` statement](http://rustbyexample.com/flow_control/while_let.html) to reduce the number of levels of indentation, if they bother you too much. Stylistic choices aren't the most important thing ever, especially when you're working solo, but conforming to local conventions is always necessary if you ever want to collaborate with others, regardless of which language or community you're in, over my many years of experience. I love auto formatting tools that actually work, because then I'm not the one having to worry about code formatting.
(The `{tail}` thing is clearer if one just uses a proper temporary variable `let tmp = tail; ... tmp.tail_mut()`, IMO.)
Once the botostrap compiler has been downloaded, or if something suitable is already installed, can we _then_ build with `cargo build`? We want `cargo build`!
Surely, by this time, everyone should have moved to Python 2.
equivalent?
Personally I went the other way and put only module level declarations in mod.rs. For my project, that means having `pub use` and `lazy_static!` declarations. I then `pub use self::foo` in foo/mod.rs and get the best of both worlds. My reasoning is that if I wanted to expand, it's easier to do so if mod.rs already treats the module like there are several components. It also makes it easier to see what part of this module is public and which is private because it's not mixed in with a bunch of logic (mod.rs is only for declarations) 
No problem! If you find out any more information about it I'd love to hear :)
Not sure if typo or troll...
&gt; The reason for this is that a redirect is sent to the browser, then the browser requests the page that it's redirected to. Put so simply I feel silly for not realising that sooner. I assumed the request was just sort of "passed on" internally. I am indeed already using handlebars on the project. Cookies or JS seem to be my way forward then. Thanks for taking the time to explain! It's much appreciated.
Thanks!
[removed]
[removed]
Neither. I was making a joke.
&gt; If someone rewrites khash in a Rust library, could the Rust implementation use that library instead of the one bundled with the standard library? Shouldn't that depend on what they actually implement?
If no one contributes a k-nucleotide program that uses `CHashMap` then we can be certain it will mean nothing.
If it's just a straight port of the C version (adjusting, of course, for variations in language idioms), would that be acceptable? From what I understand, you don't want people writing to the test, so to speak, but if another implementation is faster primarily because of an implementation detail like which hash it uses, that seems to defeat the intent of the game: to measure language implementations, not benchmark implementations.
Do you need this? http://stackoverflow.com/questions/38915653/how-can-i-pass-around-variables-between-handlers
&gt; would that be acceptable? There will be no sight-unseen promise. The hypothetical answer to your hypothetical question is, of course, yes -- and the actual answer to the actual library may well be not-a-chance. As TeXitoi said -- [a popular implementation of HashMap](https://www.reddit.com/r/rust/comments/5queq5/how_high_performance_is_rust/dd2p82g/). The current "popular implementation of HashMap" seems to be `std::collections::HashMap`. As soon as CHashMap was announced, someone announced [another experimental hash map implementation](https://www.reddit.com/r/rust/comments/5rwwrv/chashmap_efficient_concurrent_hash_maps_in_rust/dddmf12/?st=iyxj7k6c&amp;sh=3399d3e9). 
That's one reason, but there are others. We have cameras capable of capturing more colors and devices able to display them. None of that is needed for terminals, but hey, someone somewhere will want to show gradual effect between two shades of red so that cowsay looks cool. I expect terminals to eventually get color management system too :-)
Thanks, that helped already. I suspect all this will become difficult since I need to include a C union as well. Also, the functions in the library I am calling use '...' for argument lists. I don't know if this is possible with rust.
x and y just equal x0 and y0 at the start. those are both positive. the issue comes from trying to calculate a and b (not always positive) from x0 x1 and y0 y1
'...' is no problem (only in ffi though). take a look at [here](https://github.com/pythoneer/enigo/blob/master/src/macos.rs) on `CGEventCreateScrollWheelEvent` The union is a little bit harder. You need a little bit to dig (can't really write code on the phone) try to look at how it is wrapped in the winapi crate and how i used it [here](https://github.com/pythoneer/enigo/blob/master/src/win.rs) like in `mouse_down` EDIT: a better idea is probably to just search for blogposts about Rust and FFI unions like [this](http://hermanradtke.com/2016/03/17/unions-rust-ffi.html) sry for just send you out to the web ;)
build scripts are a cargo thing, so, it wouldn't run even if python was installed but cargo wasn't :P
Steve. You changed 2112 files. What have you done you insane man?
my pleasure! maybe consider using [bindgen](https://github.com/servo/rust-bindgen) as well
You know what I mean. :P Why is Python easier to install than Cargo?
&gt; bindgen Seriously!? This must be magic.Everyday something new about Rust.
Ah okay, thanks so much!
All I'm saying is I have 5 computers in my house. 5 of them have Cargo installed. 2 of them have Python installed. Since I am clearly representative of the majority of users, clearly requiring Python is a mistake.
I have an [old project](https://github.com/tedsta/deeplearn-rs) that sounds awfully similar to yours, I'd love to see how you did it! My OpenCL skills are not good at all.
`let mut x: usize = x0` will never do any conversions, it assumes that `x0` is in fact a `usize`. This will fail at compile time if it isn't. `let mut x = x0 as usize` will allow for any (numeric) `x0` and try to convert it at runtime. It's actually `let mut x : usize = x0 as usize`, but the type is being inferred from that of the expression (`x0 as usize` which is always a `usize`). The conversion will fail if `x0` is negative, or if `x0` is too big to fit (for example, it's a `u64` on a 32-bit machine). What "fail" means depends on the mode: - In debug mode, this will panic. - In release mode it will silently overflow.
Thank you! This is very helpful :)
&gt; Except in this case it seems to be, seeing as how Erlang prohibits a very large class of unsafe things (particularly around shared mutable state). Despite Erlang's philosophy ostensibly being "let it crash", there's clearly an attitude of "don't crash if you don't have to". If Erlang has that attitude, I haven't the foggiest how they arrived at a dynamically typed language. &gt; I think part of the confusion here is that "crash" is a bit ambiguous in this context. In the Rust world, "crash" means "segfault". No, in Rust *crash* normally means *panic*. &gt; In the Erlang world, "crash" means "send an exit message to your supervising process". Which is another way of saying panic, except cheaper. &gt;&gt; The alternative I'm promoting is more static checks, preventing things going wrong in the first place. &gt;Which - again - is not a silver bullet. You can't always prevent things going wrong. Nirvana fallacy. &gt; You should obviously try to prevent errors. You should also try to handle them should they occur anyway. I have been very consistent and repetitive with that viewpoint, and yet you're continuing to paint my viewpoint as "don't even try to prevent errors". &gt; My entire argument here is "errors happen anyway and you need to be prepared for them". That does not mean "don't try to prevent errors" in any way, shape, or form. It means be prepared when they *do* happen, regardless of whether or not you decide to prevent them (and you *should* decide to prevent them, but you should also decide to recover from them, too). What you're saying is still exactly the same bait and switch I've been talking about. What I've been saying, and what you keep arguing against, is that *fault tollerance does not substitue for fault prevention*. It's like, let's say you're buying a phone, and you happen to need one that lasts 10 hours. Then someone starts selling you their ErlPhone that lasts 9 hours. You're like "no, that's not enough, I need it to last 10 hours. It's going to run out." And they're like "but every phone runs out *eventually*, that's why the ErlPhone has QuickCharge capability and recharges in just 60 seconds!" Then you're like, "that's awesome and all, and really cool, but *I need it to last 10 hours*. I might not be at a charger for 10 hours, and I'm an emergency contact." And they're like "but hey, the Rust-o-Phone lasts 10 hours but it's not as good as the FormalPhone, which lasts *fifty*. 9 hours and 10 hours are basically the same by that measure." And you're like "no, I would love to have 50 hour battery life but really I only need 10. The FormalPhone costs way too much for me." And they're like "but QuickCharge is *really convenient*. Like, what if you forget to charge your phone overnight? You'll really want it then. Get an ErlPhone!" But you're like, "no, you *really don't get it*. I need 10 hours. That's non negotiable. Sure, when I use the Rust-o-Phone I'm going to have to be extra-careful to make sure it's always charged overnight and it will be way less convenient than just having QuickCharge built directly into the phone, but that's a cost I'm going to have to live with *because I need a 10 hour battery life*." That's how this conversation feels to me. &gt;&gt; Pointing out that you can write fault-preventative Erlang code is completely, utterly beside the point. &gt;&gt; Saying that you can write a journal in Erlang is also completely beside the point. &gt; Then bringing up a journaling filesystem at all is completely beside the point. I brought up the journaling filesystem to give an example of a system which needs fault prevention rather than fault tolerance. I stick by that point. &gt;&gt; As said elsewhere, fault-prevention provides safety and fault tolerance provides availability. &gt; The implication here is that availability is somehow not an aspect of safety. I disagree *very* strongly here. Availability is absolutely *vital* to safety, since a full-system crash means *crashing every other component of the system*, including safety-critical aspects. I'll admit you have a point here, but it's not as strong as you suggest. Most of this is still the domain of fault prevention. Process isolation is fault prevention, since it expands the set of valid states in an outer component to include more states in the inner component; handling crashing components is fault prevention, since it involves being careful about the applicable semantically legal of values a component can produce, etc. A system that did a clean shut down after the sound driver crashed would be *safe* but not *available*. That said, there are cases where clean shut downs aren't possible, and they include several of my own examples. So I'll concede a point here, even though it doesn't really change the debate as a whole. &gt; If we're going to ignore the fact that Erlang can be used to write fault-preventative code I'm not doing that, and I've explicitly stated the opposite. &gt; The difference here is that Erlang at least tries to do both out-of-the-box In no more genuine a sense than Rust tries to do both out of the box. &gt; This assumes (as I subtly alluded to above) that the programmer actually addressed all possible states in the state machine Nirvana fallacy. &gt; Meanwhile, as a counterexample to this "Rust can catch anything at compile-time" attitude, there's also the fact that Rust *doesn't* catch everything at compile-time Nirvana fallacy. &gt;&gt; Showing that there's something better does not make everything worse equally worse. It just means that there's something better. &gt; I brought up formal verification to illustrate that Rust and Erlang are actually very close in terms of fault-prevention in the grand scheme of things. "Even major lighthouses are dim compared to the sun, so why are you complaining my handheld torch won't suffice for warning ships at sea? They're both in the class between 'this light will literally vaporize your flesh' and 'this light is dimmer than my phone's flash'." like, seriously. I just demonstrated that Rust provided measurable safety benefits that Erlang does not give, and I warned you against conflating the two by comparison to the extremes.
Solution: make cargo into a fully-fledged build system
Yup. This isn't a make replacement, though.
You might want to try OCaml a bit. :)
On average, Rust users have a Python version of 1.32 installed on their system. Gotcha.
You can do time travel debugging in rust with [rr](http://rr-project.org/). There's an older blog post about it http://huonw.github.io/blog/2015/10/rreverse-debugging/ I haven't messed with it recently but I don't know why wouldn't be working now. I think gdb added official rust support so on new gdb's you may not even need the rust-gdb wrapper.
Having made no changes to anything, `cargo` is suddenly shitting itself. I had a failed build with `error: failed to parse manifest at '/home/directory'`, even though I have my toml right there next to it. Couldn't figure that out, so I just `cargo new foobar`ed a new project and got the same error when I tried to build. This happened to me in the middle of a programming session and I'm pretty annoyed. What did I do wrong? e: The full error message includes &gt;Caused by: &gt;no targets specified in the manifest &gt;either src/lib.rs, src/main.rs, a [lib] section, or [[bin]] section must be present But I *have* a `lib` section, and the error happens on new, cargo-initialized projects (with and without the `--bin` flag), so I have trouble believing it's something simple with my setup. It's looking in the wrong place but I can't figure out why
Interestingly, I was just experimenting with [three-rs](https://github.com/kvark/three-rs) the other day. It is certainly appealing to have Three.js like API in Rust, given how popular it became in JS world. One of the problems that such an implementation would need to solve is having a [scene graph](https://github.com/kvark/three-rs/issues/1) of nodes.
There's some misunderstanding here about how close rustbuild is to being simply `cargo build`, and the answer is not close at all. rustbuild is the build system for rust itself, and it delegates to cargo for doing what cargo does. The Rust build is complex. Like really, mind-bendingly complex. Self hosted compilers are not built like any other software. Attempting to shoehorn it into the cargo model isn't worth it. rustbuild is tailored to exactly whatever the Rust developers want or need in order to make the massive system that is Rust work. But lots of the Rust build is encoded entirely in Cargo. Very soon for example you will be able to build std with cargo, assuming you have the right compiler; or rustc with cargo, assuming you have the right compiler. xargo will know how to set up that pairing and build std with a simple 'cargo build'. Most people probably won't want to call 'cargo' on the rust source directly though because it won't get them the configuration and bootstrapping they need. 
Having a native rust libraries to rely on is so important for exactly this reason. The team behind image have done a great job w.r.t ease of integration and format handling.
1. `mod.rs` and `string.rs` are indented more than `lib.rs` but there's no parent node for them to be inside. I assume this is a typo? 2. `extern crate` is for referencing things outside your project which will be linked in by either `cargo` or a custom argument to `rustc`. 3. You probably need to use `mod module_name;`. For example, I have a project where I'm rewriting a Python script into Rust for more compile-time verification and it looks like this: rip_media/ .. src/ .. .. main.rs .. .. platform.rs .. .. subcomands.rs .. .. validators.rs .. Cargo.toml ...and, before I can use `subcommands::rip` from `main.rs`, I have to include this line so Rust knows that the `subcommands` module is a child of `main.rs`: mod subcommands; In your case, I'm assuming that the missing directory is `.. .. string/` for an end result like this... string/ .. src/ .. .. string/ .. .. .. mod.rs .. .. .. string.rs .. .. lib.rs .. Cargo.toml ...in which case, you'll want to... 1. Put `mod string;` into `lib.rs` so that `string/mod.rs` becomes a child of the top-level `string` crate defined by `lib.rs` and `Cargo.toml` 2. Put `mod string;` into `mod.rs` so that `string/string.rs` becomes a child of `string/mod.rs`. Then, you can reference `string::string::StringOb` from `lib.rs`.
&gt; t there's no parent node for them to be inside. I assume this is a typo? Sorry, I just updated it. It was a typo! I've also just used it as a separate cargo project which i linked through Cargo.toml. I've added all the things you mentioned already near the end but it does not work in my test project (which is separate from that library, just to test extern crate). So I'm doing the testing in a separate main.rs from another project (to which I linked correctly in terms of paths since the compiler is compiling the library, but it cannot find the object from the subcommand::rip i used.
Basically, once you obtain your `Child`, you can access that child's standard output like so: let mut stdout = child.stdout.as_mut().expect("unable to open stdout of child"); Then you can just simply use the `read` method to read a little bit of data at a time. How you buffer it is up to you. You can either write it a temporary file (these typically live in RAM on Linux systems) or passing it through a channel.
Is there a way to use rustc like a library? I'd like to integrate it into postgres so that people can write functions in rust without moving .so files around. More like an interpreted scripting language.
I would stay far away from designing software using recursion. Not only does the Rust compiler not optimize it, but even if it did, they are inefficient regardless. There's always a better way to write software that doesn't require recursion.
I would be very interested to know if [the modules chapter in the in-progress version 2 of the book](http://rust-lang.github.io/book/ch07-00-modules.html) is helpful to you!
In your current layout, you'd need to do: extern crate string; string::string::string::StringOb::new(); * The first `string` is the extern crate, with source in `src/lib.rs`. * The second `string` is the submodule, with source in `src/string/mod.rs`. * The third `string` is the subsubmodule, with source in `src/string/string.rs`. Also, check out this cargo plugin! [cargo modules](https://github.com/regexident/cargo-modules)
[Doc Reference](https://doc.rust-lang.org/std/prelude/)
I'd recommend filling a github issue. Also - if you're using `rustup` it's very easy to check against beta, nightly etc. to see how they behave.
What's the problem with representing the game board as say `[[bool; 100]; 100]`? (or `Vec&lt;Vec&lt;bool&gt;&gt;` for a dynamically sized board) What other information would you want to encode? Of course, you should likely create a struct wrapper around it to add methods.
How do you do sessions in your single page apps, do you use JWT? I considered using JWT for sessions but then I found this: http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/
The only weird/interesting way of implementing game of life that I'm aware of is to use a comonadic approach. I don't think you can make a general comonad in rust due to a lack of higher kinded traits, but I think you could still take the ideas and "do it monomorphically" in rust. Here is a random blog post I pulled up via google that explains how you'd implement a comonadic game of life in Haskell: http://blog.emillon.org/posts/2012-10-18-comonadic-life.html Converting that to Rust should be an interesting exercise.
Another user replied here and mentioned that there is another level (parent) we have to account for. So it's not actually string::string::StringOb, it's string::string::string::StringOb!
I haven't tried rust yet, but why does `rustc` need a specific to get build? That sounds like the compiler itself uses _very_ recent language additions if you cannot use version xx.yy-xx.zz to compile xx.aa (yy &lt; aa &lt; zz for some yy and some zz). Does Rust have a (complete) formal specification or a (complete) language report?
I think the direction is to have propositional resolver (aka prolog) working on type-level so that you can attach the most specific trait impl to trait requirements (and also being able to work backwards). This is the way Scala is going for resolution of implicit values/classes/functions that are used to provide a superset of what's possible currently in Rust.
Rust has neither, no. The implementation is the definition, at least for now. There is a reference, but it's not complete. Making it more complete is a good thing to work on.
Does this require that there are already binaries supporting your platform? 
&gt;And to remove a dependency for some people, although it's not exactly a difficult one to handle. And add a dependency in that if binaries don't exist you're screwed. 
Problem: getting binaries onto other systems. 
Well, That is known facts, depend you how "better way" to write codes. Unoptimized code but better readability, or Optimized code but lacks of readability, or has both or not.
&gt; This isn't perfect, since I actually ran out of distinguishable emoji that didn't require support for Unicode 9.0. Yup, I've got the same idea but I'm waiting for EmojiOne to get done with their B&amp;W edition.
Like in movies .... This is impressive and so easy to use! Thanks
Immediately followed by https://github.com/rust-lang/rust/pull/39633
This would be a huge endeavor and a typical case of NIH. Proper build systems 1) are complex 2) support many languages and mixing languages in one project (I doubt Cargo is ready to implement and maintain all the C++ specific stuff) and 3) already exist. It wouldn't be super hard to turn Cargo into a bad build system (which it already is), but it would be better to find a way to integrate it into existing build systems. There's a [thread](https://github.com/rust-lang/rust-roadmap/issues/12) about this.
How could I get the largest value in a list or Vec&lt;T&gt;?
&gt; You definitelly don't want to use Corrode on the whole codebase. Why is that? My impression was that Corrode is mature enough to use on decently-sized projects, it might just give up for some files where you then have to translate manually or change the C code and rerun corrode.
Yes, just like with the makefiles.
You've wandered into the wrong sub-reddit, you likely want https://www.reddit.com/r/playrust/ (this Rust is a programming language)
I'm working on an SVG rendering library called [libresvg](https://github.com/RazrFalcon/libresvg). But it's in an early stage of the development. Currently, it's build on top of *cairo*, like *librsvg*, but uses own svg parser and svg dom, unlike *librsvg*, which uses *libxml2*. Also it's doing a lot of preprocessing before actually rendering anything, so it can be used with many back-ends. Currently, only shapes rendering are supported, with all fill and stroke attributes and gradients.
Well, you beat me to it. I was thinking about doing this just the other week. :)
Try stepping with "next" instead of "step"?
My best guess for killing all inlining is `cargo rustc -- -C llvm-args="-inline-threshold=0 -inlinehint-threshold=0"` with or without `-- release` after rustc.
Thanks. So in your app, do you ask the server regularly who the logged-in user is? (So you can show the right UI for that user). Do you have a route like `/user` for that? Or does your js read the cookie? At which intervals / points do you check who the logged-in user is?
Macro's are always inlined, as they expand into native code locally at their call site. To better understand inlining of functions consider the attribute family: * `#[inline]` hint that LLVM should attempt to inline * `#[inline(always)]` tell the LLVM to treat your function more like a macro, always inline it at the call site. * `#[inline(never)]` never, ever inline in this function. Ensure it is called into. For sensitive assembly debugging work I generally tag the function I'm inspecting with #[no_mangle] #[inline(never)] pub fn extern "C" foo_bar The *extern "C"* doesn't do much, just helps you trace args as sometimes the LLVM will insert a *fun* calling convention as an optimization. The `#[no_mangle]` is fairly self explanatory, I'm lazy and grep doesn't do name mangling. 
What about neighbors? If we were using a linear 1D datastructure, then we know that the neighbors of a cell are constant spaces apart. How would you encode that in the type system? I guess you can just make do with "const". Like so, const LEFT: i8 = -1 const RIGHT: i8 = 1 or that the lower left corner of the board will always be found at index (Sx(S-1)) where s is the size of the board. So if s=8, then the board has 8x8=64 cells. And the lower left corner of the board will always be found at index (8x(8-1)). This is all in a 1D linear structure. Not a 2D matrix like structure. 
Why are all of the dependencies being included in the repo? Can't it just use `crates.io` like the rest of the system? (Not criticising, just curious) cc /u/steveklabnik1 
Nice work! Recently I have been thinking about what it would take to get completely safe bindings to Rust from Python (i.e., without the ability to mess things up while binding on the Python side) and this looks like a good example.
&gt; why does rustc need a specific to get build? The compiler itself uses unstable features, and has to implement unstable features. So it's easier to coordinate builds by only making the guarantee that it's only the previous version.
Got it. Thanks!
Very nice work!
If you want to reduce the number of times you have to write `string`, you can put pub use string::string::StringOb; Inside of `lib.rs`. Than you would only have to type extern crate string; string::StringOb::new();
Take your pick: https://crates.io/crates/concurrent-hash-map https://crates.io/crates/linked-hash-map https://crates.io/crates/chashmap https://crates.io/crates/intmap
My suggestion, make it configurable. There are many types of color blindness and it becomes very hard to pick a color scheme that is good for everyone. So instead of trying to have just one, have a few that are friendly to the various types of colorblindness. It is rare for someone to have multiple forms of color blindness, so just target the major groups. My other suggestion is to use some color blindness plugins that exist to evaluate how friendly your color scheme is.
Tell him what? You asked for proof of alternate hashmap implementations and I give you links to them. Can they be used in the benchmarks game or not?
This is pretty normal in open source. It's part of why being open source is important; at least others can carry on! There's not really much to do about it, as there's tons of reasons why something like this can happen, and they're not really "fixable."
Problem is just that everyone knows "RustyCode". So people will continue to use it though it isn't maintained anymore and if someone decides to continue the project it's hard to tell everyone that there's a new project / to decide whose fork should be now be used.
I think that's a great idea. Additionally a theme of white-on-black or black-on-white "plain" text coloring should be sufficient and would also help those who need a high contrast mode.
Have you taken a look at how the linked lists book does it? http://cglab.ca/~abeinges/blah/too-many-lists/book/second-iter-mut.html
You've asked me to spend time evaluating whether a bunch of "alternate hashmap implementations" are acceptable. How does that scale-up when there are 30 other language implementations each with advocates who want their experimental libraries to be used? Why spend any time evaluating a library that isn't used by any contributed program?
I haven't asked you to do that. You've asked for proof of alternative hashmap implementations and I've given it to you. My question is if you would accept a program that used an alternative hashmap implementation. I'm not looking for you to tell me which of these libraries you would accept. I just want to know if, in principle, you would accept one.
That's like saying you don't need a package manager for Rust because package managers already exist. But Cargo is the most well-made one I've used to date. Can't Rust devs make the best build system?
Ooh, my two favorite languages, nice! Anyone tried communicating with Elixir via a Port, rather than a NIF? As I understand it, those are the two sort of standard ways for the BEAM VM to work with code in another language. Would be interested in a comparison.
Yes please! Long time Erlang user learning Rust reporting.
Ports are still plenty fast for many use cases though. In fact, probably for most use cases.
Using Strings takes more memory, but makes for easier AST transformations. Otherwise, you need to keep the transformation chain (which then owns any backing store).
Homu is maintained here now: https://github.com/servo/homu/
RustyCode: https://github.com/KalitaAlexey/vscode-rust
I'm curious if anyone benefits from/notices the different colours for the different types of type? I personally rarely care whether something is a struct or enum or type alias when reading the signature of functions that take/return it. The example of using colours to distinguish `io::Result` from the normal `Result` seems unnecessarily subtle, and might be better addressed via some other means.
Isn't a port just a pipe connected to the stdin/stdout of an external program?
WRT racer, the project is essentially in maintenance mode. New features are added only to support the RLS. PRs are still merged occasionally if someone makes the time to put one together. Racer is going to be obsoleted at some point by the RLS, so there's not a lot of incentive to continue improving it.
Is there a chance to get UBsan working? I would really like to be able to check for unaligned memory accesses.
The entire backend is Rust. There's almost zero JS on the frontend. The only JS I have in use in the frontend is for sending a POST to the backend for tracking stats, and for the horizontal drop down menu item for the sidebar.
[Homeland Security Secretary floats plan to ask US visitors for social media passwords](http://www.theverge.com/2017/2/8/14549026/homeland-security-kelley-social-media-passwords-travelers) &gt; "We want to get on their social media, with passwords: What do you do, what do you say?" Kelly told the House Homeland Security Committee about the potential vetting measure, in a moment noted by NBC News. "If they don't want to cooperate then you don't come in."
&gt; That's one weird rule... When Steve writes - *"...the rules say that..."* [we can all see that Steve is not being truthful](http://benchmarksgame.alioth.debian.org/u64q/knucleotide-description.html#knucleotide).
&gt; To build rust, I need to use rustscript. Rustbuild, but yes. &gt; To build applications with rust, I use cargo build. Yes.
homu is indeed broken for new arrivals. I tried to sign up for a couple months ago. It does appear to be working for those who signed up a while ago though. :-)
I can't wait to build a distributed application in Erlang with an Elixir/Phoenix web frontend with Rust for native libraries/high-performance tasks. This sounds like a dream stack. Add in an operating system that uses object capabilities for security like Robigalia, integrate it with the Erlang VM, and.... *(I'm too excited about the possibilities to finish)*
It's unfortunate that this slipped through the review process, but I'm very glad that it was fixed in a point release, rather than letting it be a canonical function for an entire release.
If rustdoc spits html, maybe give each "thing" a css class and then people can make their own custom stylesheets, collect them from the colorblind users into a repo? And I imagine that attribute would help out blind e-readers.
https://doc.rust-lang.org/book/lifetimes.html#lifetime-elision
Actually, they already are! That's how they get colored like that to begin with. Any proposed changes to the colors would just be a change to the static CSS file that rustdoc includes by default.
&gt; That book seems to use Node ( T, Option&lt;Node&gt; ) instead which makes unsure how it makes an empty list. An empty list would just be represented as None.
It has to be a `build-dependency` for the `build.rs` build script to be able to use it. See here: http://doc.crates.io/build-script.html#build-dependencies
Supposedly I had it working but couldn't figure out an example that triggered an UBsan violation (iirc, I tried float -&gt; int casts and integer overflow (wrapping_add)) and that's why I didn't add it to the PR. It's also possible that I had not implemented it correctly or that I needed to backport some compiler-rt patch (our compiler-rt fork is old-ish and I had to backport two patches to get, iirc, ASan and TSan working). If you have some Rust snippets that you are sure would trip up UBsan then I can give it another try.
It would definitely break code that was relying on lifetime inference in functions with `&amp;mut` arguments. And the lifetime wasn't the problem: changing it to `&amp;'a [T]` wouldn't have helped.
How often do functions rely on lifetime inference for `&amp;_ -&gt; &amp;mut _` signatures? I can't even think of a reasonable function for which that is a correct signature.
I clicked through a few of the links but I can't find any information about what "sanitize" means in this context. Is there documentation of what this feature does and why it's useful?
Or get the old maintainer to hand over control to you. That's my preferred method as you don't need to change the repository and just add collaborators (i.e. nobody has to even notice the old maintainer doesn't care anymore). I've done that with a few repositories in other languages, and it works quite well. I consider a fork/rename to be somewhat of a last resort, especially for more established projects.
I thought of `RefCell::borrow_mut`, except that doesn't return a direct `&amp;mut`, but rather a `RefMut` that implements `DerefMut`. Could there be a similar function that doesn't need such a wrapper?
From what I understand, it's essentially making sure you don't have memory leaks, memory errors, data races and random other stuff that happens in unsafe code, though I imagine a few of those cases could happen in normal, safe code (like memory leaks). I'm not really sure though, but that's what I understood from a cursory review.
Thanks for clarifying the terminology
`RefCell`, `RwLock`, `Mutex` all come to mind.
They don't return `&amp;mut _`. It is true that the return objects are semantically `&amp;mut _` (and only different because they want to have a destructor), but the actual methods to get the `&amp;mut` out of them are also `&amp;mut _ -&gt; &amp;mut _`, meaning the chain is something like `&amp;_ -&gt; Opaque&lt;_&gt; -&gt; &amp;mut _`.
Yeah, a function that permanently mut-borrows the `RefCell` could have that signature (call it `RefCell::leak_borrow_mut` or something), but I don't consider that a particularly reasonable function (hence the use of the weasel word :P ). I would be surprised if anyone defined such a function, and I would think that they are defined so rarely that not having elision work is okay.
Yeah, of course :)
Sure, but given that we're talking about when lifetime elision can occur (it can here), ultimately you have to treat `&amp;mut T` as `U: DerefMut&lt;Target=T&gt;`
Seems to be norm to me. Python is the only popular language with an exponent operator that I know of.
Great point. Does someone want to write an RFC for linting this?
I've been looking at the HTTP libraries, mainly hyper. How easy would it be to: 1) Throttle the file download speed (for example for certain mimetypes, when downloaded by specific IP ranges) 2) Limit the file upload size. EDIT: I've found the following: https://github.com/abonander/multipart/blob/96a565494e08a17022ca3b983391f9f7d6a61c9b/src/server/iron.rs#L35-L38 3) Send the request to /dev/null if the headers size over a set limit. 4) Close the connection if the request size larger than a defined limit.
A sanitizer in this context is runtime instrumentation that makes sure one's program is free from certain errors. https://github.com/google/sanitizers is the "home page" for the four sanitizers that rustc now supports. In [summary](https://github.com/google/sanitizers/wiki): &gt; AddressSanitizer (ASan) is a fast memory error detector. It finds use-after-free and {heap,stack,global}-buffer overflow bugs in C/C++ programs. &gt; LeakSanitizer is a memory leak detector which is integrated into AddressSanitizer. The tool is supported on x86_64 Linux. &gt; ThreadSanitizer is a fast data race detector for C/C++ and Go. &gt; [MemorySanitizer is a] fast LLVM-based tool that detects the use of uninitialized memory.
&gt; Creating the test looked complex enough that we wanted to just get the build started (we validated the fix manually). Totally - first priority would be getting the fix out. A regression test is always a nice to have, glad that it's being worked on. &gt; We haven't discussed a test for the &amp;mut self issue. It would require a standalone compile-fail test in the test suite. I agree that most every fix should have tests and I'll add one for this too, but it's hard to imagine a likely scenario where this regresses (I guess an accidental revert would be the only reason). Yeah, for such a small function it would be kinda strange - I expect that code to just sit there. Still, perhaps the other thing to consider is coverage for unsafe code, or maybe patterns for testing unsafe?
It's great that somebody picked up rusty code, but it has the same weakness as the original one. It's on a personal account.
Yes I think it would be interesting to think about what kind of test would be appropriate for this - there's a long-standing need in Rust for a stock way to do unit compile-fail tests. If there was a culture of writing negative compilation tests for unsafe functions that seems pretty great. 
Hm. It would be interesting to see unsafe coverage as its own metric in a project. If a function has unsafe, how's the branch coverage, etc. Might encourage testing unsafe more strictly. edit: Having guidelines around testing unsafe might be interesting. I would definitely want to target anything like an integer overflow, since that + unsafe seems like a really likely bug to trip over without considering the wrapping behavior. Coincidentally Asan is getting native support, which is pretty relevant - having sanitizers as part of your default test environment would be a huge win for rust.
This seems like an excellent thing to include in the trust CI template once it's reliably available in the most recent nightly!
It's really cool to see Google doing Rust stuff. Does anyone know what they're using it for?
Most likely it's not a problem, but I don't think non-owners can add people.
Your right dude thanks
I'm [starting a series of posts](https://pliniker.github.io/post/eval-rs/) to go with a toy interpreter project and the design and decisions along the way. I've been planning this for quite some time so here goes.
You're looking for /r/playrust.
Open source projects start small, and when they gain enough traction, they become a timesink. Reading issues, helping people, testing changes, thinking about harder uses-cases etc. And they are usually done in people's free, unpaid time. Life situation changes, more demanding jobs happen, people get tired and bored. Generally any small Open Source project needs more than one or two people to sustain itself. Being approachable (in terms of reading the code, and understanding the goals and architecture) is important because it helps attract people to help. For bigger project there's no other route than someone getting paid for working on them. At the end of the day bills need to be paid.
I don't have any issues currently but as another poster said there are many forms of color blindness. I have the most common one (I can't remember the name of it right now). Nice job starting this thread.
Oh, yes, interior mutability to hand out pieces of an internal buffer like `TypedArena::alloc` was the one case that seemed like it would be safe, but I didn't actually connect the dots to arenas doing it in practice. Thanks! The private functions are `unsafe` helpers, that may be able to be expressed in a safer way.
 fn main() { let bytes: [u8; 9] = [0, 0, 0, 0, 0, 0, 0, 0xF0, 0x3F]; let first: f64 = unsafe { *(&amp;bytes[0] as *const u8 as *const f64) }; let second: f64 = unsafe { *(&amp;bytes[1] as *const u8 as *const f64) }; println!("{}", second / first + second); } Will print 1 on x86, will crash on other architectures (most likely).
That seems reasonable. (Using &amp;str)
As the guilty party for many of the crimes committed in those makefiles, I salute you.
&gt; Still, perhaps the other thing to consider is coverage for unsafe code, or maybe patterns for testing unsafe? Clippy does some of this. I think linting `&amp; -&gt; &amp;mut` signatures is something that should be in rustc itself.
We have run it in the past, and I think PRs have been submitted. However, this might have been before we got many correctness lints, so it's worth trying again. Given that rustbuild exists it might actually be pretty easy to do now (it used to be fiddly in the past) The problem with running modern clippy on large, old (have existed during all the rustc churn of pre-1.0), codebases like Servo and Rust is that you just get _so many warnings_. You can turn off style lints and get something better, but it's rather annoying. If you want to make it a habit you really need to go in and fix all the issues once, so that the next time you try it there will only be a few recently-introduced issues. This is why we don't regularly run clippy on Servo. I plan to get folks to work together and clippy-clean Servo at some point, though.
Why 2.0.0 when the current release is 0.9? I'd have thought 0.10 or 1.0 would be more suitable.
1.0 will have the same API as 0.9 and works on Rust stable. 2.0 changed API and depends on Rust unstable features.
I don't know how you expect that to work. It doesn't define kkk in a logically consistent way.
Is there any advantage to release your own project under Google's name other than exposition?
That is my first crate. Any feedback, reviews, pull requests are welcome!
Cool! I'm wondering if it would be a good idea to build a canonical crate that defines all natural languages, similar to your lang-module but without the LangProfileLists. This would enable a smooth chaining of many nlp-crates. For example choosing the correct [stemmer](https://github.com/JDemler/rust-stemmers) for any given text: let stemmer = Stemmer::create(detect(TEXT).unwrap().lang); for token in TEXT.split_whitespace() { println!("{}", stemmer.stem(token)) } 
Maybe just create a lint that will warn if you do it without some special annotation (e.g. `#[allow(dynamic_borrowing)]`). That would at least force people to think about it more.
I actually did write a crate that contains definitions of various NLP annotations such as languages, part-of-speech tags, grammatical relations, etc. See for instance https://github.com/rust-nlp/nlp-io/blob/master/nlp-annotations/src/languages.rs The language list is not as complete as yours, but there's a nice macro to automate all of the conversions to/from strings. I'd be happy to give you co-maintainership of the crate, since at the moment I am quite busy and haven't touched those crates in over half a year. Also let me know if you'd like your nice crate to be hosted under https://github.com/rust-nlp .
Sounds like you want a workspace, maybe?
/r/playrust
Mi ≈ùatas vidi Esperanton en la README :)
Hello everybody. I want to hear what is missing.
After the fun at FOSDEM last weekend where I joined the rust BoF and I met a lot of amazing people, this week I'm helping a friend to start the rust meetup in Rome(the first event is planned for next week), and I continued to do some rust coding on this project https://gitlab.com/tglman/persy that is slowly getting shapes.
I think this is the same question I have, just restated. I dunno if I want my struct to own the string--I just know that the data will live forever and should not change for the life of the app. On one hand it *seems* like I want my struct to own the data, yet since the data will live forever, static strs also make sense.
That's good to know--I've yet to use `Cow`, so that's helpful in general. In this case the values should not be dynamic--they're known at compile time and should never change.
Interesting--I've not heard of that pattern. I'm on mobile right now but will check into that. Off hand, do you have any good references for this pattern?
Ok, good to know--thanks!
Did you try https://aelitabot.xyz/ ? I thought that was the successor
I think I saw that, and there was some reason why I couldn't use it but I forget now. In any case, [that repo](https://github.com/AelitaBot/aelita) says it's now deprecated and that [bors-ng](https://github.com/bors-ng/bors-ng) is the successor. Neat. I'll take a look that. Thanks! Ah, right, now I remember. At the time, I wasn't looking to run my own instance. Maybe I'll reconsider. homu wasn't just something you ran, it has (or had) a web site that [ran the service for you](http://homu.io/). That's what I was looking for.
 RUSTFLAGS="-Z sanitizer=leak" cargo test --target x86_64-unknown-linux-gnu Works for me. You always have to pass `--target x86_64-unknown-linux-gnu`. (A bit silly, I know. It's a Cargo "feature"). That's in the README &gt; Be sure to always pass --target x86_64-unknown-linux-gnu to Cargo or you'll end up sanitizing the build scripts that Cargo runs.
They are not really intended for "matching", they are just bitflags. You would "match" on them with bit operations not with pattern matching. For example: flag1.contains(Test::A | Test::B) 
Years ago I promised myself that when I started a new language, I was going to create a set of benchmarks and run it on every release so that I would know when the 'fast' idioms had been surpassed by others, due to changes to the libraries and compiler. This would serve to help me unlearn old habits that made my time with the language a liability instead of a benefit. 'Course, I failed to act on that when I started using Node, and I don't know enough Rust yet to start, so I thought I'd put that out there if someone else thought that might be a worthwhile idea. 
By the way, I think without bindgen you would have to copy-paste the C definition, rewrite it to Rust syntax (using the various `c_` types from [std::os::raw](https://doc.rust-lang.org/std/os/raw/index.html) for fields of primitive types) and add a `#[repr(C)]` annotation. But bindgen seems to be the better choice here, and probably in most cases where you want to wrap a simple C API.
Yes. Or using Erlang and Elixir together. Lots of possibilities. 
This subreddit is for the programming language Rust. For the game, you want /r/playrust
1. You're looking for [Vec::get_mut](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.get_mut) if i'm not mistaken. edit: Nevermind, realised [this](http://play.integer32.com/?gist=f4dee830a673a037719fc1858aa073ac&amp;version=stable) also works. 2. Not really sure how could i explain this in depth on the choice of using `Box` and not a reference, but maybe [this](http://play.integer32.com/?gist=9a4a3ac6256f89d3eb81ac8fb451f80e&amp;version=stable) example and the error it produces might help?
Apart from that, you can't go through IARC (copyright assignment) if the project is related to your main work. That's the main reason I did Enjarify as a 20% project, rather than trying to go through IARC. 
You may also want to consider [easy_strings](https://crates.io/crates/easy_strings), which essentially provides a nicer interface around Arc&lt;String&gt;. This provides both ownership semantics and constant time clone(), at the expense of some runtime overhead.
It is described on Visual Studio Code site. I don't think it is worth it.
* https://aturon.github.io/features/types/newtype.html * https://doc.rust-lang.org/book/structs.html (3/4 down page) as far as i know it comes from haskell. in haskell there is no runtime cost for newtypes, anbody know if the same is true of rust?
oh I missed that, thanks.
Is this going to be cross-platform? I've been using gtk-rs, but it's a pain to install gtk on windows and it's a little rough around the edges. I'd love a pure-rust cross-platform UI lib!
Some thought provoking things in here, thank you. FWIW, the YAML data is really just a transformation of [some XML](http://unitsofmeasure.org/ucum-essence.xml) standard, defined by the [UCUM](http://unitsofmeasure.org/ucum.html). It essentially defines this set of standard unit types (in my case, is made up of `BaseAtom`s, `DerivedAtom`s and `Prefix`es, all variants of an `Atom` enum) and how they can be converted to other types (well, grossly simplified). The Ruby code I'm porting defines some other object types which makes use of these `Atom`s &amp; company to make them useful. For example, a gram is a `BaseAtom`, but that's useless in practice without some quantity; so you have another type that composes the value and the atom type. If you want, say 10 kilograms, you compose the "kilo" `Prefix` plus the "gram" `BaseAtom`, plus the value. &gt; Finally, if you use &amp;'static str then everyone using your library also has to hard-code their units. I generally avoid using any library that places this kind of unnecessary demand. I certainly want to provide a friendly API, so I'll be referring back to this in the future for sure but... In both of the cases I listed above, it *seems* like users of my library should not ever need/want to change those underlying `Atom`s--would you agree (from what you can tell from my short, opaque examples)? Thank you for the hypothetical example too--I'll be referring back to this as I continue to refactor.
For those of you who use VSCode for Rust and have used Atom or Vim in the past, could you describe some killer features of VSCode vs Atom/Vim wrt Rust? I'm currently happily using Atom with vim-mode-plus and my machine is powerful enough that Atom is usable without any lags, so I'd like to hear about features other than speed :) The main reason I've not given VSCode a shot for more than a few minutes is because I find its UI much less "pretty" than Atom, especially on Retina/4K resolution.
The problem is probably that `regex_syntax` only accounts for the subset of regexes that `regex` supports.
Thank you! So box allows us to allocate values that will eventually fall out of scope?
`Cow&lt;'static, str&gt;` is a nice compromise if you have compile time init or dynamic.
https://doc.rust-lang.org/beta/book/the-stack-and-the-heap.html (I hope it helps!)
Thanks, it's actually really useful to see the state of memory alongside the code! Maybe I should consider doing something similar when debugging :)
&gt; Yes. Or using Erlang and Elixir together. Lots of possibilities. No point unless you're using existing Erlang libraries. Elixir is just Erlang with a different syntax and a few additional features.
Hard to imagine how something under `src/test/` can prevent that though (until we have a static analyzer for unsafe code). That requires process changes.
Dimensioned is in the process of a rewrite (which is almost complete!), so if you check it out, look at the "rmdim" branch. Its goal is to provide units with no runtime cost, so it does things quite a bit differently.
Perhaps it'd be easier if we added clippy to the rustc build proper, as an option. That way, we could `#[cfg_attr(_, allow(..))]` where applicable. I think following the goal of getting rustc clippy-clean would benefit both rustc &amp; clippy.
Good to know, thanks. I skimmed through your branch and definitely want to spend more time understanding how you're doing things--specifically to try to see how I can make things more Rust-ful. Looks like good stuff in there. And FWIW, work has settled on the [UCUM](http://unitsofmeasure.org/ucum.html) mostly for the way units are named. We have a number of SOA HTTP services &amp; apps, written in different languages, that need to use a common "language" for dealing with units. We're also an Ag software company, thus deal with unit types like "acre inches" and "hectare millimeters" (volumes), so things get a little weird.
Only being part way through the port, I tend to think `&amp;str`, but I also have a feeling that that could change based on how other objects need to use that info. I haven't used `Cow` before, but have read some great posts about it and am definitely keeping that on the back burner.
I tried setting it up with vim, and got nowhere. Really looking forward to docs or blogposts with working setups for non-vscode editors. :)
It is possible! Shameless self promotion: [Domafic](https://github.com/cramertj/domafic-rs) I noted above that you mention your app does a POST to the backend-- for now, you'll have to use the `http` branch, but I'm planning to merge it shortly.
Who "he" ?
I like it. Error in readme? // BitFlags { 0b11, Flags::[A, B] } let flag1 = Test::A | Test::B; print_test(flag1); // true println!("{}", flag1.contains(Test::A | Test::B | Test::C)); // false println!("{}", flag1.contains(Test::A));
This one works pretty well, but it is still so-so. How much of that that is due to the package and how much is due to the RLS I don't know. One thing is that it doesn't natively support any of the completion frameworks (Company, Auto-complete), so you have to manually use `completion-at-point` for the time being.
A few thoughts: * Rust supports doc comments, which work like this: /// &lt;- Three slashes /// This documents the function that follows /// And will be used to generate documentation when running "cargo doc" fn my_function(...) {} * You can even have some markdown in those comments, as well as some code examples, which will be run as part of the test suite! * The body of `is_valid_input` could simply be: `arg_count == 2`. Maybe `assert!()` is interesting to you in this context as well. * Not a single `.unwrap()`. Nice! * When you're about to refere to all the variants of an Enum, you can use e.g. `use Token::*;` to bring them all into scope, so you don't type `Token::` every time. Please don't ever do this at the top level though; Only within a function when relevant, usually before an exhaustive match statement. * You can combine match arms that you want to handle the same way like this: `' ' | '\n' | '\r' | '\t' =&gt; Whitespace,` You may have been doing this for alignment though. * I would rewrite lines 153 and up as : match next_token { Whitespace =&gt; print!(""), Error =&gt; {...}, _ =&gt; {...} } * I feel like the loop at 265 might be rewritten with an iterator and the [take_while](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.take_while) method * Parse keyword and parse_integer are very similar; Perhaps they could become one function that gets passed a predicate? I may be wrong. * In the match statement at 317, I think you should be able to do away with the `return`s * You may want to to express your file path as an [std::path](https://doc.rust-lang.org/std/path/). * If you can use external libraries, use [clap](https://crates.io/crates/clap) for argument parsing, especially if you plan to add more options. It enforces correct usage of the arguments, so you can do away with the tests you wrote for that. My god reddit formatting sucks.
http://cglab.ca/~abeinges/blah/too-many-lists/book/ I'm working through that tutorial/book, and I find it helpful, if at times a little short on explanations. The benefit of being short on explanations is I have to think more about what's going on, which is never a bad thing. EDIT: sorry, I should have been more specific about the link: The author works through similar problems to those you face. It might provide you with some insight.
Why are you specifying the enum value for each token? I'd just leave the compiler to decide them. That also allows you to associate values with specific token values -&gt; I'd change `Integer` to `Integer(i64)` (or whatever you want the integer type to be), and `Identifier` to `Identifier(String)`. I'd also remove the `Error` enumerable, and use the `Result` type for handling errors. Do something like: enum CompileError { InvalidIntegerLiteral, UnterminatedStringLiteral, // ... Other error types } type CompileResult&lt;T=()&gt; = Result&lt;T, CompileError&gt;; This way I have most of my lexer, parser and compiler methods return a CompileResult, so for example `next_token` would return `CompileResult&lt;Token&gt;`, and this lets you use the `?` operator which makes control flow much nicer: when inside a function that returns CompileResult and you call something that returns CompileResult, often you just want to pass the error upwards, so you can do `let foo = some_function(...)?;`, if the result is an error it gets returned, otherwise you unwrap the successful value. You could make a function `match_char`, which returns true if the next char matches the given one and advances, otherwise false. That lets you put more code inline, making it clearer, for example: '=' =&gt; next_token = parse_equal(&amp;buf, &amp;mut i), Goes to something like '=' =&gt; next_token = if match_char('=') { Token::LogicalEquality } else { Token::Assignment }, You can avoid unnecessary allocations by changing `let mut buf = Vec::&lt;u8&gt;::new(); f.read_to_end(&amp;mut buf).expect("read_to_end failed");` to `let buf = file.as_bytes()`, and also the parameter to your function should really be `file: &amp;str`, which would for example let the user pass a string literal. `&amp;new_char.to_string()` allocates `new_char` on the heap making a `String`, then the `&amp;` coerces it to a `&amp;str`, you could just do `&amp;new_char[..]` to make a `&amp;str` without the allocation. It's worth reading up on the difference between String and &amp;str, boils down to String is something you own and which resides on the heap, &amp;str is a reference to a string someone else owns, it can even be a partial slice of a String (&amp;string[3..5] gets a reference from bytes 3 to 4) or a string literal. In this case you could just do `keyword.push(new_char)` to push the char on the String directly without allocations. 
I've seen you mention Derin a couple times now, and it sounds pretty exciting; good luck!
I can't reproduce the code, as I have since changed it, but my search history reveals the error message was cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements where the function was the insert method I showed in the original playground link and I had a single lifetime parameter which was placed predictably. At the time I couldn't gather anything useful from this, but I'm still a rookie.. It makes two copies, but if I think one copy will be discarded, no? I copy the tree in forrest[i], but then I reassign forrest[i]. Thank you for all of your help!
Will there be no official support for windows GUI?
I can't read the whole response right now but the enum values were required by the assignment this is for. Thank you for the feedback - more detailed reply coming later. :)
This is an alpha release. As stated on [the roadmap issue](https://github.com/rust-lang/rust-roadmap/issues/6): &gt; To seed development, we provide a reference implementation of an RLS frontend for Visual Studio Code. IIUC, a plugin will need to be developed for every editor and the instructions would be specific to that plugin + general instructions for installing the RLS. At this stage, you'd need to develop the plugin for your favourite editor. If you're not up for that, don't worry, someone will do so soon enough.
It would be interesting if the crate system had some sort of opt-in dead mans switch / escrow so that publish-authority can be reassigned if specified conditions arise. Don't know how that would work practically, but it might help kill a lot of dead projects down the line.
No 'killer' features, but VSCode feels about 5 times faster than Atom. And 100 times less weird than Vim. (Sorry Vim users but it's true.)
When I come across a sleeping player and steal their stuff, is their stuff gone when they log back in?
I want to have something like this in my input config [Action.Shoot] keys = ["LeftMouse"] [Action.Jump] key = ["Space"] mod = ["Ctrl", "Alt"] I would then parse the modifiers as an enum and convert them into a bitflag. 
Ah. Fair enough. I'm just a little hesitant to have 2 bitflag crates. Could I ask you to make an attempt to proposition an enum/derive API in the main bitflags repo? And I assume you're using https://crates.io/crates/config to parse your input config, right? :) 
Depends whether their stuff implements `Copy` or not. ... you want /r/playrust. How did you get so far in without noticing this isn't a gaming subreddit?
So your goal is to abstract over native toolkits? Like Windows, Mac, and maybe GTK for Linux? That'd be awesome. Tho I do remember another project already attempting to do this, but I can't remember the name. 
I searched for Rust and clicked on this one and saw the easy questions thread and assumed it was for the game because other subs do these kinds of threads too.
I am not sure, maybe someone on the compiler team will answer :)
It should also be noted that a jump table isn't always the right thing to generate. Cache misses, memory loading, and assembly code is really expensive and, relatively speaking, some branching is not. There is a tipping point where jump tables are faster than branch statements and that is some of the math that is going on with LLVM code generation.
Not so much an addition, but i think the options in the readme are out of date, based on what VSCode auto completes.
Well, I don't mean to pee in the punch but the other problem is that you'll have to have a variant for every single combination of flags for them to be useful. This would mean the number of variants could grow exponentially. I'm not sure I understand how this is useful but maybe I'm missing something.
Thanks, I didn't notice it.
Maybe you can find some answer here: https://github.com/rust-embedded/rfcs/issues
I don't follow this stuff closely, but I don't think avr is ready yet. /u/shepmaster and /u/dylster3 are probably the right people to ask. It [doesn't look like](https://github.com/rust-lang/rust/issues/37609) Rust has been updated to use the avr-enabled version of LLVM yet. In fact, it doesn't look like the new version of LLVM that includes the support is scheduled to be itself released for another couple of weeks. If you want to sneak ahead to the prerelease bleeding edge stuff, there's the [avr-rust](https://github.com/avr-rust/rust) project (looks like the avr-support-4.0 branch is the active one). I have no idea what does and doesn't work, but the presence of an [Arduino Uno library](https://github.com/avr-rust/arduino) suggests that at least the basic stuff does. Actually, after a little poking around, it turns out there's a [blog post](http://dylanmckay.io/blog/rust/avr/llvm/2017/02/09/safer-microcontrollers-almost-here.html) from just yesterday that goes into a bit more detail. 
That blog post is fantastic! 
Sounds like you got about everything right! Some minor additions: &gt; it doesn't look like the new version of LLVM that includes the support is scheduled to be itself released for another couple of weeks. Rust has it's [own fork of LLVM](https://github.com/rust-lang/llvm) that is also associated with the [emscripten LLVM fork](https://github.com/kripken/emscripten-fastcomp) (although I'm hazy on the details). This means that the official LLVM 4.0 release doesn't *have* to be out for Rust to use it. &gt; there's the avr-rust project (looks like the avr-support-4.0 branch is the active one) Yup, although it's lagging behind a bit (November 2016! That's like an infinite number of Rust releases ago!). Once LLVM 4 is mainlined, keeping that up-to-date should be easier. &gt; I have no idea what does and doesn't work, I [made an LED blink](http://jakegoulding.com/blog/2016/01/24/rust-on-an-arduino-uno-part-3/)... is there anything else that embedded development is good at? /s
The box keyword isn't there for performance reasons, it's just sugar. The performance-related feature is placement-new, which is tried in with the box syntax sugar. The tracking issue for these features is here: https://github.com/rust-lang/rust/issues/27779 and there was a recent status update at https://internals.rust-lang.org/t/lang-team-minutes-feature-status-report-placement-in-and-box/4646 (feedback requested).
I started doing that, but was stumped on unions, and variable argument lists. Also, some structs where only typedef'd in the header but implemented in the C file. Although that would work simply by declaring a rust struct with #[repr(C)]?
This is one of the stealthiest improvements to Rust that I'm excited about for the coming year. And I'm quite surprised to hear that LLVM's new AVR backend was borne out of a desire to use Rust! Well done, Dylan McKay. :)
[`cargo install cargo-edit`](https://github.com/killercup/cargo-edit) And then: `cargo add &lt;dependency&gt;`
What if you had a s version (s1.0.0) for Rust Stable versions and an n version (n1.0.0) version Rust Nightly? That way you don't mix two compilers into the same versioning, which could possibly lead to errors or a messy versioning later.
&gt; It makes two copies, but if I think one copy will be discarded, no? I copy the tree in forrest[i], but then I reassign forrest[i]. Thank you for all of your help! That's correct for `i1` (it gets replaced), but not for `i2`, which does end up in 2 independent copies, as best as I can tell. I was looking for an easy way to replace `i1` with something that contains, in place, but there doesn't seem to be one.
Thanks to some [wonderful work from /u/dtolnay][feature], the playground now inspects the feature flags of any crate it compiles. If it finds a feature named `playground`, it will enable that feature for that crate. This allows crate authors who already show up in the playground to have a say in the best way of presenting the crate to the world. [feature]: https://github.com/integer32llc/rust-playground/pull/100
Thanks!
Doesn't mean the other developers have to make the same choice, right?
Is there any chance of getting an MIR output button like `play.rust-lang.org` has?
Thanks for the update!
There already are multiple bitflag crates around: https://crates.io/search?q=bitflag
What about for distros that can't have something reach out to the network during the build phase? This is something I've been pushing on firmly for some time across the ecosystem and want to make sure it wasn't forgotten. 
Tthanks for the info, googling this stuff doesn't give the best or most recent results, at least for me When is the rust team incorporating an SEO expert?^(&lt;/s&gt;)
Interesting. When I first learned about rust I was wondering if it had a compiler for any microcontroller I could use (avr/arm) and was slightly disappointed. This means rust on arduino might soon be a thing. This is the kind of project I wish I could contribute to, but I don't have the sufficient knowledge for it :/
Yay! This will be my excuse to use Rust on a real project! All the hobby keyboard kits use some version of the AVR chip, so I'll finally be able to write keyboard firmwares in Rust.
Why does this blog post mention emscripten/fastcomp backend as a pre-requisite for adding AVR support?
How does the playground do it then? custom build? Using whatever nightly the current stable/beta are equal to?
C is currently a better option to program microcontrollers. By the time you have a decent understanding of how to program with extreme memory and CPU limits, [you'll be able to use Rust.](http://dylanmckay.io/blog/rust/avr/llvm/2017/02/09/safer-microcontrollers-almost-here.html)
Is the new `return` parameter annotation on `foo` required or optional? Does `return` also work if we hide the array in a `struct` or `class` (as a member)?
&gt; When is the rust team incorporating an SEO expert? When we find one who's willing to participate. Any technical authors with SEO experience that want to contribute to a FOSS project that _values and praises such work highly_, can contact us through `core-team@rust-lang.org` or `community-team@rust-lang.org`.
Very cool. I wonder, can the Rust system do bounds checking of its entire memory usage? The trickiest bugs I've run into on microcontrollers were from using too much memory, causing one variable to overwrite another and stuff.
&gt; The problem with running modern clippy on large, old (have existed during all the rustc churn of pre-1.0), codebases like Servo and Rust is that you just get so many warnings. You can turn off style lints and get something better, but it's rather annoying. If you want to make it a habit you really need to go in and fix all the issues once, so that the next time you try it there will only be a few recently-introduced issues. This is why we don't regularly run clippy on Servo. I plan to get folks to work together and clippy-clean Servo at some point, though. Wouldn't that be a great students or *SoC project? I always found comparing (and porting) old do new code a great learners experience. You need to understand what the old code does, you need to understand why the new pattern is used, you need to learn the transformation from old to new. You see and learn lot of stuff that way.
 #[derive(Eq, Copy, Clone)] pub struct BitFlags&lt;T: EnumFlagSize&gt; { val: T::Size, } Where `T::Size` is the type inside the #[repr(u8)]. I also do some checks to see if the flags are actually valid.
&gt; What do you mean? typedef'd to what? Actually, they were just declared but no members defined, thats what I meant. Unions, thats awesome! Bindgen defines some __BindgenUnionField, but I don't get what happens there.
You can use [dirty scheduling](https://medium.com/@jlouis666/erlang-dirty-scheduler-overhead-6e1219dcc7) to do long calls.
If you are interested, this is the issue for the [NVPTX and MSP430](https://github.com/rust-lang/rust/issues/38824) platforms. You can't use libcore on these targets, as libcore includes support for i128 as it does for other integer types.
&gt;custom alligators
Are there any C libs present on the VM that it's running on? If I were to add `playground = ["sqlite"]` to Diesel, is there any chance this would work for demos with in-memory databases?
Uhm, yes it does? While it has a warning that it should only be used on unstable (but is still available for backwards compatibility), it very well works on stable/beta. It is tracked here: [#31847](https://github.com/rust-lang/rust/issues/31847)
Cross post this to r/mk if you haven't already :)
Placement in is not only performance related. How do you put a big array on the heap in Rust portably without placement in? As somebody in that internal thread mentions, doing so in stable Rust either works, panics, or segfaults, depending on the platform =/
That makes sense. I expect there will also be other things stopping `libcore` being compiled however. On [avr-rust/rust](https://github.com/avr-rust/rust), we never did get `libcore` built due to at least one code generation bug. Since then, a bunch of bugs have been fixed though. Looking forward to having an up-to-date Rust AVR compiler again so we can see which backend bugs we need to prioritise.
It was quite a bit of effort to be honest. Unlike a lot of APIs, the LLVM C++ interface has no stability guarantees. There is an official C library with stronger backwards compatibility (which Rust does use) but it doesn't support a lot of things the full C++ API has. There is a PR open for all of the changes to `rustc` itself required for the upgrade [here](https://github.com/rust-lang/rust/issues/37609). After the API uses are corrected in the Rust compiler, you're correct that the only thing needed is to update the submodule with the new one. 
&gt; Rust has neither, no. If Rust aims to replace C at some point, I think it will __really__ need one. The great thing about a spec is that you always have something to reference. If you have an error in your program, is that due to some compiler bug? Or due to some unspecified/undefined behaviour? Furthermore, a spec makes it possible to create another, but spec-fulfilling compiler. Note that I'm not saying that Rust needs more than one compiler at a given time, but the GCC development heavily sped up after it got a competitor (clang). The downside, of course, is that someone has to write the damn thing.
Not all ;)
Yes, and no. In debug mode, yes. In release mode the optimizer can elide many kinds of copies, but there's no solid guarantees. Overall, having a 1MB array on the stack isn't really a good idea. I believe the default stack size of a new thread on Linux is 1 MB, so attempting to initialize such an array could mean an instant stack overflow. After a certain size, going to the heap is really the better approach. `Vec&lt;u8&gt;` is insanely cheap to move around. 
I've been working on upgrading [chrono-tz](https://github.com/djzin/chrono-tz) to chrono 0.3. I also forked zoneinfo-parse to my own parse-zoneinfo, so now chrono-tz should work properly on all platforms, with both chrono 0.2 and chrono 0.3 (before it had a dependency on datetime crate which was causing issues on windows).
Completely different species from custom crocodiles
See! That's why newcomers find Rust scary!
The WASM parts of it at least, in my understanding, are.
awesome!
Hierarchical state machines for Rust, with codegen: https://github.com/hashmismatch/fsm.rs My personal interest for it is a Cleanflight-style quad flight controller.
You can use Rust for ARM already if you didn't know that.
I always wanted to get into that, but never managed to. This can finally be my excuse to get into keyboard firmwares! :D Please open a new thread here with github links once you get on it. :-)
Check out github.com/japaric for arm stuff
Cool! I wonder if they'll support PIC microcontrollers eventually. 
It shows weekend / weekday at the moment. What I find interesting is that it correlates well with the StackOverflow survey 2016, which showed Rust as [the most loved technology](http://stackoverflow.com/research/developer-survey-2016#technology-most-loved-dreaded-and-wanted). It's nice to see that despite condescending comments, plain ignorance and relative youth, there's such a keen interest in Rust. Of course, it doesn't mean we should relent in our efforts to convince more people to try it out, and help smooth the onboarding experience for them so they can get past the tipping point :) 
Very cool! Most people already know this, but I think it still needs a mention (from README): &gt; Disclaimer &gt; &gt; This is not an official Google product (experimental or otherwise), &gt; it is just code that happens to be owned by Google.
Sweet. I'll definitely play with this.
TeXitoi and Veedrac have told Steve that what he's claimed is not true. I've show that what Steve claimed is not true. Steve's claim is still there - uncorrected and misleading. *That's one weird rule [that Steve made-up].*
That would be really cool. Microchip's tools are expensive for the proper compilers and are as old as time itself.
This would be potentially solved by specialization, but I would argue that this particular usage is a code smell. Try implementing and using `FromIterator` instead for this kind of case.
Steve, could you please correct your claim: &gt; My latest favorite example: the rules say that if your language's standard library has a HashMap, you must use it, rather than writing your own. C doesn't have a HashMap, so they get to write one specific for the benchmark, but we can't, even though we could implement the exact same one in the same way as the C one. Either striking it out since it's incorrect, or rewording it into something akin to (leaving the original stroked out as otherwise the conversation below doesn't make sense): &gt; My latest favorite example: the rules say that you have to use a popular implementation of a hash map, not one crafted specifically for the benchmark. C does not have a standard hash map, so there are many popular implementations with various trade-offs, and they get to pick the one that performs best (`khash`, from klib). In the mean-time Rust uses the general purpose `std::collections::HashMap`, which is the only popular implementation of a hash map in Rust. It's still unclear to me whether Rust could get away with a custom re-implementation of khash, since it is unlikely to be popular, but for now let's calm things down. *And please avoid engaging igouy, there appears to be bad blood between the two of you, so just Chill Out (and ignore each others).* 
Now all we need is a GBA emulator called Mermaidman.
I already have FromIterator, it's used internally inside From. The thing is I want From to be used for more than just from. The basic use case is that From on this data type itself should obviously be a zero cost conversion while if it's another iterator it is linear time. I have a couple of functions which consume this type but can conceivaby work on any iterator, or anything that can be converted into this type. If it's this type already the conversion should just be free whreas if it's an iterator it should create a new one from this iterator. That's why I want the functions to work on `T : Into&lt;MyType&lt;T&gt;&gt;` rather than `T : IntoIterator&lt;Item=T&gt;`
&gt; Software and shit Best name for a dev blog I've seen yet
The teensy uses an Atmel AVR chip
&gt; It's nice to see that despite condescending comments, plain ignorance and relative youth, there's such a keen interest in Rust. There's a bunch of stuff going on when people say negative things about Rust that seem to be ignorant. First, Rust will make some languages (at least one) obsolete. (Not an explicit goal of course, but practically, that's what Rust does). To the users of those languages, Rust is hostile just by existing. (This is a hell of a phenomenon that's hard to explain fully.) Another category of negative comments come from people who have actually used Rust and came away frustrated. When people try to comment on a tool that left them frustrated, they might easily say things that don't make a lick of sense. Patience seems to be the only answer here.
All of the Teensy 3.X boards are Freescale/NXP ARM chips, and Rust already works great on them! Seeing progress on AVR is still very exciting :D
If you compile with debug assertions on (enabled by default) all safe array accesses have bounds checks. You may consider leaving them in for Release builds, they don't slow down that much AFAIK. ralloc is a Rust memory allocator that can have a bunch more checks enabled, give it a look. I think most embedded software doesn't use the heap much, though.
There are some modifications to the compiler that are needed to enable a new target. For many targets it's about a hundred lines or so to enable the target, add a target.json, and a few other things. This is probably a bit more involved since it's the first 8-bit target. I think (hope?) that AVR has 16-bit pointers so it might not be that different from MSP430 which is already enabled.
Cross-posted on [stackoverflow](http://stackoverflow.com/questions/42178842/implement-from-on-a-trait-which-has-self-as-member).
imag as sample repo :-D I can't stop grinning! Wow!
Out of interest, what's the usecase for the `playground` feature? I can't immediately see why you'd want a crate to appear in the playground other than with the default options.
I was actually suggesting that they answer your question in the book a few days ago because of how many bits of disparate knowledge I had to piece together to answer it for myself and how, if I hadn't, I'd likely have made poor decisions based on prior experience with managed/scripting languages. **Memory Overhead:** There's no memory overhead because Rust structs are like C structs (even without `repr(C)` in the ways relevant to this question) and, as the K&amp;R C book or playing around with Python's `struct` module will tell you, C structs have no "framing", so a struct with only a single element has a memory representation identical to accessing that single element directly. (That's why, historically, the solution for reading/writing file formats was to define structs and pretend that endianness wasn't a thing. For most (all?) file formats, if your CPU is the right endianness, you can just copy the headers into memory and then unsafely cast the pointer to a C struct.) **CPU Overhead:** In release builds, there's no CPU overhead because optimizing away indirection in static lookups and dispatch is one of the most basic things any compiler optimizer that's even halfway competent will do. (ie. Recognizing that "address + offset" can be replaced with "address" if offset is known to always be zero.) According to [the Compiler Explorer](http://rust.godbolt.org/), It'll add an extra `mov` per lookup during debug builds, but that's to be expected since rustc currently relies heavily on LLVM's optimizers to clean up the sloppy LLVM IR it generates. In essence, the newtype pattern is a zero-cost abstraction because, like so many things in Rust, all trace of it (compared to what a reasonable programmer would hand-code) vanishes during the compilation phase in release mode. (Or, to put it another way, C and Rust structs are not self-describing like compound data types in languages like Python/Ruby/etc. and the LLVM optimizers will purge the "description" from the generated machine code, since seeing it as a bare variable is equivalent.)
Also to the contrarians among us it can be fatiguing just to see the word Rust on your HN front-page every day. I know it can be for me and I'm a pretty big Rust fan.
&gt; could you please correct your claim: Sure. &gt; And please avoid engaging igouy, there appears to be bad blood between the two of you, so just Chill Out (and ignore each others). I did a few days ago, dunno why you're getting to this thread now :)
MIT 6.824's assignment set(https://pdos.csail.mit.edu/6.824/) is an excellent material for distributed systems. Note that you may also want to look into the past year's lab for Paxos-based assignments. I'd like to mention that before diving into the assignments, it is worth studying basic concepts of distributed systems like consistency models, fault models, logical clock, etc. Sadly, I'm not aware of good materials other than grad-level classes :(
I only got a message today, and realized what a mess this thread had become :( Thanks for fixing your claim, somehow. Hopefully this will defuse the situation and we can all go back to enjoying our weekend :)
Thanks for the feedback! There are plans to do ziggurat sampling (in the back of my head anyways) but it's currently low on the list of things to do. My main focus currently is porting the bulk of statistical functionality over from [Math.Net Numerics](https://numerics.mathdotnet.com/) and then I'll do another once over for speed and accuracy optimizations where I can.
So `1 + weekday`? 
&gt; There are plans to do ziggurat sampling (in the back of my head anyways) but it's currently low on the list of things to do My point was you don't have to do anything to benefit from ziggurat sampling because you can just call the sampling functions in `rand` directly (e.g. `use rand::...; r.gen::&lt;StandardNormal&gt;().0 * std_dev + mean`), and it would also simplify the code. (Also, I added some things to my original comment.)
It's all good; I'm just happy we finally know the rules.
You could potentially reduce the sizes even more. Since any non-leaf node has exactly two children (i.e. it can't have just one), you could just store a single pointer to a *pair* of nodes. That only helps if you can reduce the size of the leaf case though. E.g. maybe use null-terminated strings if that isn't going to cause problems in your algorithms. That brings each variant down to the size of one pointer + enum discriminant, and you could maybe just use the least significant bit of that pointer as a flag telling you which kind it is (unsafe code, assumes that all allocations are at least 2 bytes aligned, which is a pretty safe assumption.. don't forget to clear that bit before dereferencing) so you don't even need the 8 bytes to know which one you are. EDIT: If you want to go even more crazy, another option is split the leaf and internal node types up, which means leaf and internal nodes can have different sizes. Then use tags in the pointer *to* a node to determine which type it will be. So an internal nodes have a single pointer (referencing a *pair* of nodes). The two lowest bits indicate the four possibilities of nodes that are in that pair. So e.g. 00 = pair of leaf nodes, 01 = pair of a leaf and internal node in that order, and so on. So check the tag bits, and cast to the right kind of pair before working on the children. So internal nodes will be one pointer sized, leaf nodes could be two pointers to account for length (or maybe 1 pointer and a 24 bits of length or whatever). Another option is to allocate these various pairs of nodes in arrays and use indices instead of pointers (maybe you can get away with &lt;64 bits including the 2 flag bits). That may mean you have to do some array resizing every now and then. 
I've fallen down a rabbit hole of implementing DMA with `futures-rs`. I'm unsure when (or if) any of this will end up in a blog post. The next post on handling errors and improved safety is in progress, and sort of stalled while I mull over some thoughts on safe interrupt handling.
Are you asking if the bot can use the two libraries at the same time? .-.
&gt; I'm not sure what you mean. You have to store multiple pointers some place or else you don't have a tree at all. Nope, you don't! Instead of storing two pointers, you could easily imagine storing a tuple (pair) of two pointers to nodes right? That's pretty much exactly the same. Well, from there it's an easy conceptual step to store a single pointer to a pair of nodes instead. Effectively this means you're allocating all your nodes (except the root) in pairs, instead of one at a time, which that means you only need one pointer to give access to the two children of a node. If you had a tree where an internal node might have only one child, you'd have to allocate "dummy" children to make this work (since some pairs of leaf nodes only have one "live" member). That's not the case here, but even if it was it could still be valuable. &gt; Note that in this application, there are relatively few leaf nodes, so while switching to null terminated strings could theoretically help, it wouldn't make a real difference. In a tree like this, each pair of leaf nodes has one parent node, depending on how balanced things are, you'd have approximately as many leaf nodes as internal nodes (think about it this way - each time you pair up leaf nodes, you only get half as many internal nodes). 
Update: I tried the system allocator, but it was much worse than jemalloc. (This is on Linux)
The reference counts are needed to garbage collect the nodes themselves. Note that the strings are stored implicitly as the concatenation of other strings, and only the leafs are contiguous strings. This means that you can do something like let a = 'foo' let b = a + a let c = b + b let d = c + c let e = d + d ... and use only a linear amount of memory, rather than exponential. 
&gt; Are there any C libs present on the VM that it's running on? Generally, I add whatever C libraries are needed to compile the top ~100 crates. However, if a crate has onerous installation requirements, I'll simply [blacklist](https://github.com/integer32llc/rust-playground/blob/5e95d344a45e808e8b793916a6dc33d1eb5aff0d/top-crates/src/main.rs#L120-L133) it. If something is easily installable in an Ubuntu 16.04 Docker container, it should be fine. However, please note that Diesel isn't currently [in the top 100 crates](https://github.com/integer32llc/rust-playground/blob/master/compiler/base/Cargo.toml), so you may not want to put any effort into it yet ;-). The selected crates are based on the top downloads of all time, but there's some thought about [trying to favor recently-popular crates](https://github.com/integer32llc/rust-playground/issues/101). It's mostly based around being fair about which crates to pick, not accidentally picking malicious crates, and time/money (I pay for the EC2 instance out-of-pocket). Maybe I should consider "sponsorships" from projects that want to guarantee that their crate is available! \^_\^
&gt; it has a warning that it should only be used on unstabl Yeah, I told a tiny white lie ;-). Really, I don't want to *start* using an accidentally-public feature that's scheduled to become an error at some point in the future.
&gt; Removing the enum discriminant would shave off 8 bytes, but that requires a lot of error prone unsafe code. And of course, it wouldn't actually gain you anything under jemalloc anyway. I agree you'd need unsafe code, but if you're willing to do it you can probably go down the 16-byte size class. One of Chandler Carruth's CppCon talks mentioned that LLVM does a lot to pack stuff into small spaces by using the bottom bits of aligned pointers. If you can ensure the pointers are aligned (and I haven't looked but I bet jemalloc has a minimum alignment &gt; 1), you can do the same thing: * Leaf: first 8 bytes holds an aligned pointer + discriminant low bit = 1. second 8 bytes hold the length. * Concat: first 8 bytes hold an aligned pointer + discriminant low bit = 0. second 8 bytes hold the second pointer. Also, does jemalloc have any way of customizing the size classes? I wouldn't be surprised if it did, although I didn't see it in a quick skim of the man page.
Can anyone give me some hints on why mcu's would be 'safer' using rust?
That's a great tip. In general I have such a tendency to want to get it all perfect right now, that I often get hung up on minutiae or things that could just be refactored later, often times leaving me to burn out on that code because it takes so long to get to that "it's working" state. I've had projects that accomplish goals but I hold back from releasing because it's not quite what I want, then I don't get around to ever getting it there--which is effectively a waste of all that effort in the first place. I digress. I think you just articulated something that's been looming in my brain for a couple years. Thanks for that.
For a long time, I thought that the playground actually switched you to nightly implicitly. However, [as /u/badboy_ points out](https://www.reddit.com/r/rust/comments/5tbozx/the_integer32_playground_now_supports_serde/ddlymqp/), the stable compiler [currently allows you to call these options](https://github.com/rust-lang/rust/issues/31847). Since that feature is scheduled to go away, I'm not sure what the plan is.
I doubt that changing the metrics to recently popular would change anything. Most of the top crates aren't there because they're old, they're there because they have more daily downloads than most crates have lifetime downloads. Things like libc and winapi are always going to be universal.
Useful project. Thank you.
If it's the only tool available I suppose that might be an argument, but there is some legitimate cost in providing the tools and keeping them available. Not having used them myself it's hard to tell what I would think. I tend to think that regular software of any kind shouldn't exceed $50-60 with the exception of stuff like OSes which need to be all around better which necessitates a lot more labor in making them. Having crappy tools that are expensive is reprehensible imho and should just be treated by refusing to buy the product in the first place.
Twice a day doesn't sound like that big a deal honestly assuming you work more than 4 hours a day. I also don't think stuff NEEDs to be pleasant/comfortable. Perhaps you should go write some in Rust and see whether it's really better or not. I am just highly skeptical of anything claiming superiority in this arena because frequently it's just a different paradigm/process/view and not necessarily better so much as different with different quirks and dilemmas.
Together with the expected salary, right? /i
&gt; Twice a day doesn't sound like that big a deal honestly assuming you work more than 4 hours a day. I also don't think stuff NEEDs to be pleasant/comfortable. I don't really understand this argument and I run into it a lot - maybe you can help me understand where you're coming from? I agree that things don't **need** to be pleasant or comfortable. But given a choice between pleasant and unpleasant, why wouldn't you choose pleasant? And when you encounter something unpleasant, don't you feel a desire for it to be pleasant instead? I just don't understand why "the thing we have works now" somehow fights against "the new thing will be better than what we have now". Both things are true! And hopefully, both things will continue to be true for a long time as things continue to get better and better. &gt; I am just highly skeptical of anything claiming superiority in this arena because frequently it's just a different paradigm/process/view and not necessarily better so much as different with different quirks and dilemmas. This I get. I'd say the major tradeoff with Rust is there's a lot of up-front work which doesn't pay off if you're not supporting the project for a long time. But there are definitely some areas where I'd be hard-pressed to come up with a tradeoff and the Rust way just seems strictly **better** - the major one that comes to mind is that Rust's macros (even in the limited form they currently exist in) are just way better than C's.
I guess this works when the library is more of a framework. And often, frameworks do come with additional tools to auto-generate or validate code since it's almost developing it's own DSL. I think of diesel as a framework more than a library. I do agree that complete type signatures are close to useless in probably the majority of real-world error cases.
Templates are a big part of C++, It's kind of unfair to exclude them. Type-level integers and variadic templates are not to be underestimated. Rust lacks variadic functions, although there is some debate as to whether this is actually a desirable feature or not. Rust for some reason does not have function overloading (except for weird trait functionality). This is actually for me the biggest thing that rust lacks right now. `constexpr` is very powerful and is also something that rust currently lacks. C++ has the benefit of many competing compilers, each with some of the best compiler architects in the industry (and the backing of extremely large companies). rust so far has only `rustc` for viable compilers.
Rust's lack of function overloading is the reason that you will see a lot of `new()`, `with_***(...)`, `from_***(...)` in libraries. It can be more informative, but also prevents a one-to-one translation of many popular C++ apis. (edit c -&gt; c++ thanks /u/notriddle)
I suspected it might be. My understanding is that jemalloc is strongest in situations of heavy load, which is why Firefox uses it, but I'd also heard claims that the allocator used in glibc was only inferior in the face of long-running processes where memory fragmentation could accumulate, so I just go with "Let's find out. Test it." as my approach to that.
Q1: No. Most TLS implementations avoid DTLS because it is a pain to implant. UDP is very unreliable and now your trying to make reliable, AND secure. Q2: One can take the OpenSSL library and build your own futures library above this. It isn't not necessarily blocking as your can pass it non-blocking IO, it calls out specifically the special errors it returns when it errors b/c of a WOULDBLOCK. This will require a lot of RTFM and being frustrated but it is doable. Q3: I would go for a long walk in the park, speak to my loved ones, and try to forget about what unfortunate circumstances lead me to a chain decisions where implementing my own TLS/DTLS implementation was even being considered. TLS/DTLS are very difficult services to implement as they're are attacks against EVERY layer of their stack (internally) and leaking cryptographic data is never ever good.
You can avoid most of the error prone code by having a pointer type that wraps a usize, then methods to convert to an enum with each variant holding a reference to an appropriate struct type. That corals all of the unsafe code into the pointer type. The enum is only temporarily allocated on the stack, so it should be very low cost.
A language specification.
C++ does something called "mangling" , which basically means that the compiler generates unique function names for each version of a function. In Rust, this is a manual process, which encourages the programmer to give now descriptive function names. Mangling is the reason you have to use `extern "C"` for C++ functions you want to call from C, so basically you need to turn off features to get your code to work with existing code. I don't know if there are other reasons to not support it, but that alone is enough for me to prefer to not have that feature. Some languages do this with variable length argument lists (implemented as an array in most languages), which Rust also doesn't have IIRC. This is traditionally used for things like `printf` and in most circumstances, an array or a macro is completely acceptable, which I'm guessing it's why Rust doesn't feel the need to implement it as a core feature. I'm not a language designer or compiler hacker, but hopefully this is helpful.
Of things possible in C, not possible in Rust ‚Äì you cannot create dynamically-sized array on the stack. But that‚Äôs also impossible in C++ (it‚Äôs one of those few things where it breaks C compatibility).
I know a lot of people will disagree on this (including part of me, actually), but... OOP? I mean, I get why OOP is criticized but I still think there are some cases where it's useful, and working around it when you are used to it is not always obvious and seems to be a common question for newcomers. OTOH, what I liked when I learned Rust is that while complicated it wasn't as complex as C++ (or how I perceive it, at least): there are less different concepts that you need to understand. So, well, there are a few features that I miss (variadic functions/methods are one of them, too), but I quite like that Rust doesn't have *too many* features either, so meh.
I keep meaning to find a good screen so I can try to port Doom to the 3.5/3.6. I might give it a try with a smaller screen
Interface with existing C++ code. Work with existing C++ tools. Be understood by C++ coders (who haven't learned Rust yet). From a practical perspective, that's the biggest barrier to Rust adoption.
I'd say the biggest reason not to support it is specification complexity. If you've ever looked at the Java language specification, the rules for deciding which overloaded method to call are enormously complicated, and I'm sure C++ is worse. You can sort of opt in to overloading in Rust by writing a function that is generic over a custom trait, but that requires a lot of boilerplate, and you get many of the downsides of overloading, such as confusing error messages and breaking type inference.
&gt; ... but I feel as though it's also really unique to C++ ... D would like to contest that statement.
So does this just mean that a Google engineer built it on company time, or does Google own anything their engineers make at any time? 
Wrong sub. I think you want /r/playrust
I want to use short, immutable byte arrays as keys in a simple k-v store I'm working on. The byte arrays will usually just contain strings. So far I've written everything using `Rc&lt;[u8]&gt;` which seems to work, but ... how do I actually create them dynamically? Do I need to move to Rc&lt;Box&lt;[u8]&gt;&gt;? And is this the best way to make one? `Rc::new("hi".as_bytes().to_vec().into_boxed_slice())` ?
I'm sorry we didn't choose discord-rs. It was either that or serenity, and the circumstances happened to lead to serenity. Sorry :/
Oh, right, sorry, was forgetting that the allocation is `ArcInner`, not just `LongStr`. Seems like it's at least possible through the method /u/comex describes, with some caveats. Alternatively, would it be practical to increase the branching factor? a trinary tree or some such rather than binary, to make use of a full 32 bytes or more.
You could be right. For what it's worth, I think github is a better metric. So yay us!
I tried implementing the bit packed approach, but it just crashes and I don't feel like trying to debug it. Such is the peril of writing tricky unsafe code, I guess.
Yeah github is public work that impacts lots of developers, work leading to SO questions may never see the light of day. Mind you the answer to the SO question is useful to anyone new to the language, but eh.
One other thing that C++ has that Rust (currently) does not is a memory model ([open issue](https://github.com/rust-lang/rfcs/issues/1447)). The [C++ one](http://en.cppreference.com/w/cpp/language/memory_model) is complex and with lots of gotchas, but if you do it right you end up knowing precisely what code (including lock-free atomic operations) will work correctly.
&gt; non sequitur Is it? How else am I supposed to explain that Rust and Erlang are much more equivalent fault-prevention-wise than you think if you keep calling out all their similarities as irrelevant? It's boiling down to "la la la I'm not listening" on your part, and if it weren't for me finding an immense wealth of joy in discussing these sorts of technical things, I likely would've said "good day" and left it at that a long time ago. &gt; Dialyzer is weaker than Rust's type system At type-checking, perhaps. Erlang doesn't need static typing to be type-safe; pattern matching provides a *much* stronger defense against invalid values than simple type checking alone, and Dialyzer is built around that. &gt; Do I need to link the Wikipedia article on the Nirvana fallacy I'm fully aware of the definition of "Nirvana fallacy". None of what I'm saying comes *anywhere* close to it, for the same reason that none of the statement "you should carry chains in your car even if you have snow tires" comes nowhere near the Nirvana fallacy. &gt; No, I've said that Rust is more appropriate. And I've expressed my disagreement with that *very* logically and coherently, at least so I think/hope. There are some faults that Rust prevents better than Erlang. There are some faults that Erlang prevents better than Rust. Continuing to ignore the latter as "non-sequiturs" while propounding the former to be some kind of infallible truth suggests... &gt; my understanding of logical soundness ...that your "understanding of logical soundness" is flawed, to say the least. I've tried my best to explain my own perspective here (as a user of both languages) as clearly and logically as possible, as I'm sure you have as well. This might unfortunately be the point where we just agree to disagree.
&gt; Leaf is two words because of the slice length. You are right, thanks. But it still doesn't work if leaf if 8 bytes length: enum LongStr { Leaf(Box&lt;u8&gt;), Concat(Box&lt;u8&gt;, Box&lt;u8&gt;), } It is still 24 bytes. &gt; Does the null pointer optimization actually work that way? I thought it only triggered if the other variant was empty. Apparently it doesn't work. But I think it should. Why woudn't it?
It just seems like some things are the cost of working with a language, Java's "boilerplate" if you will being one example. Unless the non-ideal quirk (the stuff you'd rather write in Rust) is a big time waster due to high frequency or high time cost then it's just how things are, no? Yes, I suppose that I'd prefer pleasant over unpleasant. Hence why I write code in Java. It's just less painful to work with than say Python. If I had a job it might have more of an impact and I might prefer something else for it's speed/efficiency. Couldn't tell you. I'd speculate that it has to do with investment though. If I could code well in C then why would I invest time and effort switching to something where I have to relearn everything just to do the same things a little better? Presumably it gets back to the difference between liking something better and it being objectively better. It's great that people are creating new stuff, but sometimes they're just re-inventing the wheel and a circular wheel might only be slightly better than n-gon wheel the closer n gets to infinity (i.e. a 100-sided wheel might work nearly as well as a circular one). I'm pretty sure C macros are just pre-processor text replacement, what do Rust's do? In any case, I think macros are a terrible coding practice. It's alright for some stuff, I've seen some C code using it for maximum and minimum tests where it avoids a function call by just inserting the test wherever (i.e. MAX(a,b) ). Once things get to a certain complexity...
Holy crap, somebody actually came up with a legitimate use case for `Box&lt;[T]&gt;`!!
&gt; `constexpr` is very powerful and is also something that rust currently lacks. What benefit would Rust get from something like `constexpr` that isn't already fulfilled by the macro system?
I want some way to do this built into the language, but I don't know what it would look like. This sort of suggests a shape for it that might work - crates could define assocations between error codes, types, and special notes to add to the error message.
Macro is another language into the language. It does not operate with typed variables but on code structure directly. It's great but it works completely differently than normal Rust, it's a shame to use this for thing that could get handled cleanly by the normal language constructs. 
As you describe it, the problem is that it is not C++. 
Boy, yes. My past few projects have had to build on VC++10 and g++ 4.8 or so, and it is occasionally very tiresome. I hope that if alternative Rust compilers crop up they'll be better about supporting specific revisions of the language, although without a spec that might be hard. 
A `constexpr` function looks like a completely ordinary function, just with `constexpr` attached to it.
I meant: I prefer to use (weekend / (weekend + weekday)) *rather than* using (weekend / weekday)
Oh, apologies.
&gt; However, that doesn't compile because e.g. on lines 12 and 19 it's possible that T1=T2, and I have two impls of &gt; AsRef&lt;T1&gt;. Right now there is no way in rust to say: impl&lt;T1, T2 != T1&gt; .... (I don't think that's entirely accurate to &gt; what's going wrong, but it's that sort of thing.) This is absolutely correct. If you have `input: (i32, i32)`, what is the value of `let x: &amp;i32 = input.as_ref()`? There is no way to tell. The way to do this would be to introduce a new trait to get the printer inputs from a type, and then implement this trait for all the types you care about: https://is.gd/hrRIJ1 In general, though, an attempt to make code "easier to use" by allowing parameters to be switched is probably heading down the wrong path. As you can see, these functions are already becoming unwieldy, and it's probably better at that point to have the caller simply switch the arguments.
A heads up to anyone reading this: due to language changes, the macro the third chapter describes no longer works (and frustratingly, *cannot* be made to work without procedural macros). It really needs an update, but that would entail either totally removing the third chapter, or gutting and rewriting it with a new macro (which I haven't been able to come up with yet)... so I haven't been able to muster the necessary enthusiasm.
`Vec&lt;i32&gt;` means a vector of `i32`s. This works because `Vec` is a _generic type_ - it's defined to work with any type of argument, so you can have a `Vec&lt;i32&gt;` and a `Vec&lt;u32&gt;` and a `Vec&lt;MyStruct&gt;` and even a `Vec&lt;Vec&lt;u32&gt;&gt;`. The type between `&lt;&gt;` is what's called the argument - it's substituted into the type definition of `Vec`. There's a better explaination [in the book](https://doc.rust-lang.org/book/generics.html).
Yes, crates that generate code for you and expect a certain structure will benefit more from this. Another good way to see if crate X would benefit from this: Is X using compiletest?
Didn't Rust use to have a `pure` qualifier for functions?
Also, Rust pretty much supports inheritance. In interfaces through supertraits, and in structure through composition + `Deref`.
But in C++17 there are very little basic things that one cannot do inside constexpr functions any more (one can even use closures and what not). The things that are still not allowed in C++17 constexpr are placement new, reinterpret cast, new/delete, goto, explicit destructor calls...
Many differences have been mentioned already. These are some other things that C++ has but Rust does not: - placement new [0] - existential types [1] - conditional compilation with arbitrary predicates on types (using type information) - support for allocators in the standard library - dynamic dispatch using thin pointers - exceptions as a control flow mechanism [2] - compile-time detection of functions/expressions that might possibly panic (`noexcept(expr)`) - higher-kinded types - function overloading on type-constraints (multi-dispatch on multiple traits [3]). - transactional memory (disclaimer: I am not saying that these are gaps that should be closed, these are just differences that came to mind) &gt; Rust for some reason does not have function overloading (except for weird trait functionality). This is actually for me the biggest thing that rust lacks right now. Rust _does_ have function overloading which is achieved using Traits. This is much cleaner than the C++ overloading rules, which are very hard to use correctly, e.g., every time somebody calls a namespace-qualified customization point like `std::swap(a, b)`, `std::begin(it)`, ... they are overriding ADL and thus making a subtle error. [0] Available in nightly. [1] Partially available in nightly (can only be used in return type position, while in C++ one can use existentials as the type of a local variables, as arguments to type constructors, ...). [2] Rust has this too, but in C++ exceptions are meant to be used this way, and there are various language level constructs to make this very easy. [3] I don't think this can be done with traits, but would like to learn how to do it if it turns out to be possible.
/r/playrust
&gt; More specifically, overload on value category (ie. on whether an argument is an r-value). The only reason I can think of why you'd ever use this is to be able to re-use resources allocated by a value if that value is about to die anyway. For this, Rust has the move-by-default semantics. If you take a `T` you can always re-use the resources of that `T`, which you can't do in C++ without also knowing its value category. I'd prefer it if Rust didn't get lost in the weird value category marsh that C++ has got stuck in, where you have to keep a mental model of whether something is an rvalue, lvalue, xvalue, glvalue, or prvalue. &gt; In Rust, index must return a (Rust) reference, which the compiler automagically derefs. Related: the syntax `v[idx]` can't return an object by value in Rust. Yes, `Index` is one of the traits that I hope gets a tweak in Rust 2.0. The reason it's written the way it is, is because the returned reference must have the same lifetime as `self`, which cannot be expressed any other way in today's Rust. When Rust gets associated type constructors it should be possible to make `Index` more general. 
&gt; But that‚Äôs also impossible in C++ With non-standard features it [is possible](http://man7.org/linux/man-pages/man3/alloca.3.html). (It's also [supported by MSVC](https://msdn.microsoft.com/en-us/library/wb1s57t5.aspx), so I guess it doesn't matter in practice that it's non-standard when it's available on the 99% of the systems you're going to use.)
I assume safe from buffer overflows? Safe as in type safety. Unfortunately, Avr support comes as tons of hobbyists are switching to the esp8266.
thanks
Nice write up! I'm a bit suspicious that having a billion `Rc` is the right solution. Some more higher level, block wise memory managment feels more appropriate.
I quote withoutboats [here](https://users.rust-lang.org/t/is-it-possible-to-specialize-hashmap-index-for-copy-types/7750/5?u=leodasvacas) on why function overloading may not be a desirable thing for Rust: &gt;There are a few reasons I think its unlikely Rust will have this feature any time soon: &gt;* It's not usually that useful, since you can just use a different method name. &gt;* Using it is often not a great idea, because if these methods have different signatures and different implementations, like as not they should have a different name. &gt;* In a language with a lot of type parameters flying around like Rust has, proving that the two signatures are actually disjoint is not trivial. We'd have to have a whole coherence system for function signatures, and before long we'd be talking about specialization between signatures.
&gt; I feel like that is a huge missing feature (curious to know the design decisions to keep it out of the language)! OK, I'm not a language designer, but here's my take on this. Quite a lot of people consider function overloading to be a poorly thought-out feature the way it's done in C++ and Java. The rules that govern which function to pick need to be incredibly complex, because they interfere with just about every other facet of the language. Implicit type conversions, inheritance, and function pointers; all of these features have to be taken into account when you design the rules. And it also restricts heavily what library writers can do without potentially breaking other people's code. Want to implement a new interface to a class in your Java library? Sorry, that's a potentially breaking change, because someone else might have a separate overload for that interface, causing their program to take a different code path. And the thing is that Rust *has* function overloading, but with one key change. It's not *your* function that has twenty different implementations to handle twenty different types. Instead those twenty other types all specify an implementation that "plugs in" to your function. This is essentially what the trait system boils down to. To me, this a lot more structured and easier to reason about, since the language rules are simpler. It's less limiting in a way, since anyone can create a new overload of *your* function just by adding a new trait to *their* type, completely without touching your code. And adding a new trait to a type in your library is *not* a breaking change.^‚Ä† I agree that function overloading is occasionally useful, and I could imagine adding a well thought-out subset of it to Rust. But the full C++-style function overloading would be a misfeature in Rust, in my opinion. ‚Ä†) Okay, that's a bit of a lie. Using features in the `std::any` module, you can write code that changes behaviour depending on which traits are implemented on other types. But this is opt-in, and with the behaviour clearly expressed in code, so you really only have yourself to blame if your code breaks. 
I would argue that the trait system is perhaps more efficient than inheritance ala Java/C++ in some aspects. For example the fact that in a trait all methods are final by default means that when a trait method invokes another trait method on `self` (even that of another trait) there's no need for a virtual dispatch: the type is statically known. This opens up a lot of opportunities for de-virtualization and therefore inlining that is generally left untapped in Java/C++ because non-final virtual methods are so pervasive.
&gt; Yes, Index is one of the traits that I hope gets a tweak in Rust 2.0 You might wait a long time; there's no plan to get a Rust 2.0 that I know of and I doubt `Index` alone warrants it.
Yes... and no. Nim compiles down to C++, making it trivial to have C++ FFI, and yet Nim is not C++. It removes one of the barriers.
Of course, and I'm not arguing for a Rust 2.0 roadmap either. There's a lot still to do on the 1.x track. But I do believe that a 2.0 revision will be inevitable at some point, and when then time comes I do have a list of language features that I'd like to see tweaked. `Index`/`IndexMut` is one of them, but I also have thoughts about `Drop` and the operator overloading story. A man can dream. ;-) 
Compile big projects in a reasonable amount of time. :(
Thanks, I like your implementation better than that crate :-)
You're not really supposed to use deref for delegation, it's supposed to be for cases when there's an actual deref (or at least, that's what I understand the style guideline to be). There is a separate delegation proposal I've seen floating around a few times. Rust's supertrait inheritance does help, but the whole thing is still very different from classical single inheritance. It does us no favors to pretend that it is a actually inheritance -- Rust's "composition over inheritance" model means that for practical purposes there is almost always a Rusty way to solve a problem you would solve with single inheritance in another language; but that does not mean that we "support single inheritance".
Huh? Is that chapter from before Rust 1.0?
Backcompat of macros has always been a bit iffy (follow sets help dampen this effect, but not entirely). If you're doing really really complex matches with macros such breakages may happen when something is added to Rust's syntax.
&gt; Maybe you should file an RFC. Probably RFC is not needed, because enum layout is implementation defined, and not a part of specification. &gt; whether it would be worth the extra complexity required I think, any optimization which does not have downsides besides implementation complexity (e. g. which does not add more runtime cost) should be done. &gt; I don't know how often that case actually comes up I don't know either.
&gt; **I don't see** how they would be using different implementations, they would always use the same one because it is unambiguous which of both is more specific. The problem is that just because *you* don't see an issue doesn't mean there is none. That's what really tricky here, it's easy to lull yourself into thinking that you've worked out all combinations and it works... but experience shows that most likely you've actually forgotten about that rare situation that comes and bites you back. It only takes a single counter-example for a beautiful theory to crumble down. Or for the system to be unusable. --- In the case of specialization, you are right that there is a partial order, that's not the problem though. The problem is one of visibility. If rustc was using whole-program compilation, your scheme would work. But compilation times would likely be even more atrocious than they are and dynamically loaded libraries would be impossible. So rustc uses a separate compilation scheme, which makes it possible for two different crates to consider a *different* set of implementations to pick from. And that's where the danger lurks. The rules, whatever they end up being, have to be crafted so that all crates that see an instantiation of a trait for a concrete type consider the very same set of potential implementations *and* agree on which should prevail. Today's rules (Orphan rules + no overlap) are overly strict; but they provably give this guarantee. Tomorrow's rules have to preserve this soundness. --- And theory is not enough, it also must be practical. A. Turon raises an issue in his blog post that is important: adding an implementation in a base crate. It's not enough that the resulting system work "statically", it must also account for the fact that libraries evolve and trait implementations appear. 
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
Seems like exactly! Thank you!
If you use the `Result` type instead of option, you may use the question mark operator: type Result&lt;T&gt; = std::result::Result&lt;T, ()&gt;; fn my_func(a: u32, b: u32, c: u32) -&gt; u32 { a + b + c } fn apply_my_func(a: Result&lt;u32&gt;, b: Result&lt;u32&gt;, c: Result&lt;u32&gt;) -&gt; Result&lt;u32&gt; { let x = a?; let y = b?; let z = c?; Ok(my_func(x, y, z)) } fn main() { println!("{:?}", apply_my_func(Ok(1), Ok(2), Ok(3))); } You can of course just write `Ok(my_func(a?, b?, c?))` instead if you want. There is talk of enabling the `Carrier` trait (which powers the question mark operator) for `Option`, for precisely your use case.
[removed]
[removed]
[removed]
Someone pointed out to me: Servo is technically using pointer casting, not transmute. It's achieving an unchecked bitwise type conversion. My error.
[removed]
In some cases, traits are more efficient. But you're not going to get a more efficient implementation of stuff like GObject and the DOM than built-in OOP. Also, methods aren't virtual by default in C++.
C++ isn't exactly fast to compile, either. Rust's implementation is still improving, while Clang is state of the art.
If you feel like learning way too much about hardware design, you could buy an FPGA dev board and turn it into a serial-to-HDMI converter or something like that. You should be able to push a low resolution image over the serial line to the FPGA
Rust catches many bugs during compile-time. The code won't even compile, if you have a dangling pointer or use-after-free bug. I have experience working with MCUs. Memory bugs happened several times. And debugging microcontroller is much, much more difficult than debugging PC application.
If Rust had arity overloading, it would've needed it from the beginning, so that the syntax could refer to the correct function (like `&amp;something/1`). I don't think it could really be added at this point.
Great, looking forward to use it!
Methods are not virtual methods by default, but overriding methods are not final by default either: - since `final` only appeared in C++11, many people plain do not use it (for lack of awareness or habit), - even when knowing of `final`, there's a tendency to avoid it because the Open/Close principle says it's great when things are open (opinions diverge). Now, I'm not saying that the DOM is not a good usecase for OOP; more that in general there are inefficiencies that sneak in more easily in C++ than Rust so that the performance picture is not unilateraly tilted in favor of C++.
Why? The number of arguments of a function is statically known, and that's all that's necessary for arity overloading. *Internally* the compiler might want to keep track of `(name, arity)` instead of just `name`, but the user should not need to. The only "difficult" case is when passing a pointer-to-function, and this can be solved by type ascription/casting: let fun: fn(i32) -&gt; i32 = &amp;something; pass_the_callback(fun); in the rare cases where type inference does not work it out. Also, I do expect all current programs would compile since they do not have overloaded functions to start with (so no ambiguity). Of course, introducing an overload would be a breaking change.
I personally miss integers in generics and `size_of` being const fn.
Maybe the problem is also caused by implicit coercions in C++, don't you think? Anyway, I don't miss overloading.
Lack of overloading felt like disadvantage to me too at first. But when used in practice, I found out that I don't miss it much. I can always invent useful name. And I often don't need it thanks to traits.
There are only programmers in /r/rust ‚Äì it's a programming language subreddit. You are likely looking for /r/playrust, although I'm unsure if they like your post better than we do...
Combined with `static_assert`, it'd be nice to use when creating newtyped values. e.g. `let divisor = NonZero::const_new(THE_ANSWER);` instead of `let divisor = NonZero::new(THE_ANSWER).unwrap(); // Will this accidentally panic?`
I actually like that Rust pushes people to do things right. Can you provide an example where you consider inheritance superior to contain&amp;delegate?
`rustc` static linking isn't bad - if you use `strip` you will see that the executable itself isn't too large - it just has lots of debug information. And you _can_ choose to link dynamically to the Rust stdlib and then you get really dinky executables.
`BufRead` only exists because there are additional methods that buffered readers can support; `BufWriter` is fine with the `Write` trait's methods (and it also implements `Seek`). If you only want to allow buffered writers, it may be a better idea to take any `W: Write` and wrap it in a `BufWriter` yourself. Otherwise, just take `W: Write` and use its writer methods directly.
I still think there should be a `BufWrite` trait because you may wrap something twice (would be solved with specialization in some cases). I think it would be good to have a guarantee that it is buffered and there aren't too many system calls. Otherwise, if it is not a system resource, it is already "buffered" and there should be no indirection. Probably we should have a marker trait like this trait BufWrite: Write {} ?
It is a feature. The basics can be emulated in Rust with panic and panic handlers up to a point, but not enough to be able to use it effectively for control flow (which is a good thing). Then there are some more tricky parts that cannot be emulated in Rust at all, e.g., dynamic exception specifications, typed exceptions, ... C++ has lots of things.
Am I the only one for who the comments link at the bottom links back to the post itself?
Yes, during the pre-1.0 era but it was removed. IIRC it was because the notion of purity was not clearly defined and it was not bringing more safety than the borrow checker.
&gt; determines what monomorphizations we need which
I pay for the site license for all of JetBrains stuff, and I don't think I use any features outside of the community edition for all the apps I use simply because the support is so good. If you regularly install more than one Jetbrains product, checkout the [Toolbox](https://www.jetbrains.com/toolbox/). Plus the site license gets you access to DataGrip, CLion, WebStrom, etc.
Yeah, its broken for me too. It should probably point to: https://internals.rust-lang.org/t/feb-2017-compiler-design-sprint-summary/4783
&gt; So you eschew a dynamic memory allocation, but there's a cost. And it's not quite clear what the price is. Have there really not been any existing efforts to investigate this? &gt; And there are other ways to implement it (a parallel stack for dynamic allocations comes to mind, which still takes advantage of stack dynamics without trashing the actual stack). This is probably obvious but just to be sure I understand it - this means that instead of "the stack pointer", you'd have two, "the static stack pointer" and "the dynamic stack pointer"?
IntelliJ, the basis for those other systems is [Open Source and Apache Licensed](https://github.com/JetBrains/intellij-community) and developed in public. I can't possibly understand what your complaint is. The basis for PyCharm is also [developed in public](https://github.com/JetBrains/intellij-community/commits/master/python). I am as freetard is comes, I love the GPL, including the AGPL but the vast majority of people who use Free Software, use it because it is zero cost, not because of libre. I support my continued use of libre Jetbrains software by paying for a [subscription](https://www.jetbrains.com/idea/buy/#edition=commercial). There is nothing crippleware about the community editions, they are buildable and usable by anyone and everyone today.
If this is for your own internal code, you could make this trait yourself, so you can always be sure you only pass a buffered writer. If this is library code, you should just ask for a `Write`, and allow the user to determine if they want buffering or not.
Indeed. https://doc.rust-lang.org/std/fs/fn.canonicalize.html#errors Path, afaik, doesn't have a concept of a cwd. It is just a collection of functions and data useful when dealing with string that probably represent paths on disk. You can use a mix of [`path.parent()`](https://doc.rust-lang.org/std/path/struct.Path.html#method.parent) and `is_file`, `has_root`, etc to do something more specific. If you have a `root_path: Path` that represents the root of your filesystem (`/`) and you try to canonicalize `..` + `root_path` what would you expect to get back?
I'm not very familiar with alloca but I've long been tempted by it. The size concern with alloca seems less disastrous than the usual size concern with stack allocated arrays. With a statically sized array a size computation error results in the classic buffer overflow vulnerability, but sizing the alloca wrong just causes a stack overflow - much less bad. Are you sure that alloca will often cause a function to suffer from computing offsets from rsp? I'm used to seeing rbp used to find stack items and it would be unaffected. Regarding register pressure, in the case where you are using a dynamically sized stack array, wouldn't the length probably be needed in a register already? I don't quite understand the cache usage drawback. Whether the cache lines are on the stack or elsewhere doesn't make a difference to the CPU. In the statically sized stack allocation case, I think it would be *more* likely to waste cache lines since the end of the array will almost always be loaded into cache due to its locality to the previous stack frame, but is unlikely to be needed. A dynamic allocation is almost a sure miss. Reusing the same scratch space for multiple calls means worrying about concurrency and re-entrance, problems from which alloca does not suffer. With the static buffer and dynamic fallback you may see a step-function difference in execution time, which might be problematic in some domains.
That's because `Debug` and `Display` are implemented for borrows like this: deference to get the underlaying value, format it with the value's `Debug`/`Display` implemantations and then give it back. Meaning formatting with either the reference or by deferencing it yourself and then using it is gonna be the same really.
I believe `BufWrite` could avoid some copying. Especially, if the code doing writing needs to use temporary buffer to create the data, it might use the buffer of `BufWriter` to be efficient. That is why I added `BufWrite` trait into [`genio`](https://github.com/Kixunil/genio).
You migh provide implementation for [`genio`](https://github.com/Kixunil/genio) as well. It has `BufWrite` trait but it's not mature yet. Any help with design would be appreciated.
I haven't had time to properly evaluate IntelliJ yet, but these evaluation criteria are why I shy away from Open Core offerings until convinced otherwise (and the links I gave mean that it qualifies as Open Core): 1. How viable an option is it if I pretend the commercial options don't exist and will never exist? 2. Do I foresee any situations where I would be significantly personally disadvantaged by needing features for which they are selling paid versions (ie. nonexistent versions re: point #1) 3. Does paid functionality eventually make it into free versions? (ie. Are the paid versions a rolling window or do paid-only features just accumulate?) 4. What's the company's track record in cases such as "community reinvented paid features"?
&gt; Have there really not been any existing efforts to investigate this? That's my question. I don't recall any, I've seen people either saying "it's obvious it's better" or "it's obvious it's worse" but I can't recall any performance measurement. I suppose it would depend on the cases (and notably the architecture), etc... so like all benchmarks it might not be easy, but I can't recall any at all. &gt; This is probably obvious but just to be sure I understand it - this means that instead of "the stack pointer", you'd have two, "the static stack pointer" and "the dynamic stack pointer"? Yes, that's the idea. It meshes very well with SafeStack: - all scalar values on the "static" stack - all arrays/dynamically sized values on the "dynamic" stack You benefit from having your scalar values fitting in as few cache lines as possible, and at the same time you harden the implementation against buffer underflow/overflow used in ROP since buffers are on the dynamic stack and the return pointer is in the static stack (with Rust it should be less of an issue, but unsafe indexing still exist). In Clang, it's claimed that: &gt; [SafeStack](https://clang.llvm.org/docs/SafeStack.html) is an instrumentation pass that protects programs against attacks based on stack buffer overflows, without introducing any measurable performance overhead.
Exactly. When you read documentation, you find: impl&lt;'a, T&gt; Debug for &amp;'a T where T: Debug + ?Sized impl&lt;'a, T&gt; Debug for &amp;'a mut T where T: Debug + ?Sized impl&lt;'a, T&gt; Display for &amp;'a T where T: Display + ?Sized impl&lt;'a, T&gt; Display for &amp;'a mut T where T: Display + ?Sized
Your concerns are valid and I am not dismissive, I believe what I said, genuinely w/o sarcasm. The community editions of IntelliJ and PyCharm are truly community projects, the extensions that are in the Ultimate and Pro versions support individual frameworks and libraries (Spring, Django, etc). They make things easier, but are absolutely not required to use the product. I have never seen an instance of Jetbrains preventing someone from making a free version of one of their paid extensions. Most of those extensions are in the exact solution space that isn't valued by Open Source, there is really no other way for them to exist. To make them free as in beer would do no one a service.
Indent code blocks by 4 spaces to get them formatted as code. Inline code can be enclosed in backticks (`).
I can understand where you come from, but I'll rather have this done right than done fast. Nevertheless, I'll see what I can do to speed up the process.
Ahh. If my own investigation confirms that, then I'll likely use it. ...but "You should probably only use software you wrote." really is a great way to shut down discourse, given that no man is an island. (For the record, aside from IDE choice, I'm quite happy with my system, where the only closed-source components are my BIOS, nVidia binary drivers, Flash, Upwork Team, and games.)
And there was a bug in the version of `cargo` that shipped with 1.15 that wouldn't run doc tests for proc_macro crates, but it has since been fixed :) So that explains that! Links: * https://github.com/rust-lang/cargo/issues/3545 * https://github.com/rust-lang/cargo/pull/3552 * https://github.com/rust-lang/rust/issues/37480
We can punt on MIR borrowck and only allow unsized initialization in `let ... = rvalue` (by removing the `typeof(rvalue): Sized` requirement) then implement unsized initialization as a special-case in trans (by getting an alignment and size from `rvalue` and generating a dynamically sized `alloca`). AFAIK, nothing else in between needs to be changed, and optimization passes like copy propagation will likely work with DSTs as they are right now.
Yeah I'm only disappointed about what's happening. I didn't mean to say that it's a bad decision. 
Yep, it's my personal project. Not a Google official thing. Thanks for clarify!
&gt; You did mention reusing a single scratch space as well as the two stack idea. Actually, that was the same idea. The second stack was my scratch space. &gt; but I don't think it's every case. Maybe, maybe not. SafeStack uses two stacks and reports there's no performance penalty, so it's one data point. 
I've got this news from Phoronix. http://phoronix.com/scan.php?page=news_item&amp;px=RSPIRV-Rust-SPIR-V
If it was closer to the date of [Anarchapulco](https://anarchapulco.com/) maybe more people could attend. At least I'd consider attending...
So excited for all the stuff the compiler team has in the pipe. Though I'd love to know if there are any ballpark timelines for seeing any of this land in nightly. :)
Why not just join? ``` let path = env::current_dir()?.join("hosts"); ```
A thin-pointer-like feature in Rust will probably not look like anything like the feature in C++ I guess. I think there were already some discussions about virtual structs but they did not materialize in anything.
That depends on what you mean. I've had to fix a few memory leaks, but I haven't written much in C that's more than a couple thousand lines at the absolute most. I try to write good code. I mean there's always passing the wrong type to sizeof() when malloc'ing a block of memory, but I assume you mean something a little different.
Maybe I'm misunderstanding, but what's wrong with `.as_os_str()`? ...or are you looking for something analogous to Python's `os.path.abspath`, which ensures a path is absolute without checking it for validity? (By contrast, Rust's `canonicalize` is analogous to Python's `os.path.realpath`, which does hit the filesystem to resolve symlinks.)
The full error message has some explanations and tips: https://doc.rust-lang.org/nightly/error-index.html#E0038
 os.path.abspath
I actually just finished verifying my suspicion that it was a platform limitation by checking the `getcwd(3)` manpage. Discovering these sorts of "you never handled X" cases in things I did for years is one of the things I love about Rust.
&gt; because you may wrap something twice That's a general problem. Something that is `Read` and `BufRead` passed to a generic function accepting a `Read` that then wraps it again is common. Sadly there is no way to check if `Read` also implements `BufRead` in a function.
Your size calculations have the right spirit but I don't think they're quite correct. - `size_of::&lt;Point&gt;() == size_of::&lt;i32&gt;() + size_of::&lt;u8&gt;()` -- there is likely some padding also for alignment. On my machine this equation says `8 == 4 + 1`. - In the second calculation, `size_of::&lt;Option&gt;` doesn't really make sense. It's more that the size of `Option&lt;T&gt;` is the size of `T`, plus 1 for the discriminant (plus padding maybe).
I was going to suggest /u/wafflespeanut use his fuzzy-finding code to implement an fzf/selecta-like fuzzy finder, but that already exists it seems: https://github.com/lotabout/skim
OMG, you're right! There is some padding, I just ran the code again on Rust playground, the size of Point is 8. Thank you so much for pointing this, I will update the post.
/r/playrust
Are there any existing compilers that support on-demand compilation? Java? (I don't know much about compilers‚Ä¶) Has the Adapton approach been tested in a compiler before? 
Lol
This is relevant to my interests. Can you talk a little bit about the design? Are you implementing the full HSM/statechart "spec" (is it a spec? I dunno)? Happy to see no_std support too.
The pointer case is exactly what I'm thinking of (obviously a static call is fine).
You are looking for /r/playrust, about the game Rust. This subreddit is about the programming language Rust.
This is an amazing tool. I use this all the time to debug issues in my derive_more crate that adds #[derive] for common traits like From, Add and Mul. https://github.com/JelteF/derive_more
I agree, delegation of implementation would be great. I'm even following that RFC. Specialization would be great too. I hope it'll land one day.
Ah, I see. I viewed it similarly before. But when using Rust I found out that I kind of like `from_???` and `with_???` names.
To be more specific - if `T` is known to never be zero, then `Option&lt;T&gt;` doesn't have a bonus flag for `None` and uses the zero value instead. This behavior extends to all two-variant enums where one variant is holding a value and the other doesn't. It's called "null pointer optimization", and it's there so that optional pointers are pointer-sized (so you can use `Option&lt;T*&gt;` in FFI for nullable pointers).
You have to do the later in my experience. pub enum Attribute { Field, Constant, } pub enum Line { AttributeDefinition(Attribute), Directive, } Is the easiest way. You can't include a private enum inside a public one, as the field will be public, but hold private data. The pub enum Line { enum Attribute { Field, Constant, }, Directive, } isn't valid syntax. The block post you link defines a structure as an enum field. 
Thanks. It had never occurred to me that the behaviour I see in DOS on my retro-PC would extend to the APIs applications interact with. That said, Python is broken in that case too. `abspath` relies on `join` to do the right thing and `join` doesn't. Given that I don't have the means to maintain such an abstraction (I develop exclusively on Linux), I'll stick to the Python-style naive version and, if anyone complains, I'll blame the Rust devs for not providing an `abspath` that both exists on Linux and calls `GetFullPathNameW` on Windows.
I got used to them, but from(u8) from(u16) from(u32) from(etc etc etc) all convey the same concept. make from this thing I'm giving you. The concept is the same, therefore the name should be the same. 
[removed]
In that case I think you need to do `Rc&lt;Box&lt;[u8]&gt;&gt;` or `Rc&lt;Vec&lt;[u8]&gt;&gt;`. I think in theory a bare `Rc&lt;[u8]&gt;` could be allocated but AFAIK there's no way to do it now without unsafe code and relying on implementation details.
/r/playrust
:D
What? 
This subreddit is for the rust programming language. Posts related to the rust video game should be posted to the subreddit for said game: /r/playrust.
Meh, we have a library for everything! :P
Agree 100%, posts like this are awesome.
Hm, I've actually never tried compiling Rust on Windows via VS before. If you don't get an answer before tomorrow, I'll try giving it a crack. Is there a guide somewhere with specific steps that you're following, so that I can try to reproduce the issue? In the meantime, you may be interested in the #rust or #rust-internals channels on irc.mozilla.org for more help: https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;channel=%23rust https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;channel=%23rust-internals And if you're really impatient, maybe try compiling Rust via the MinGW route and see if that gets you anywhere. Good luck! :)
That looks like a good calculation for an enum but this is a struct.
Oh wow. 
Thanks for your help and investigation, this was really the case! Now I use `rust,ignore` tags with fencing so the examples aren't build.
Translation: rustycrate.ru is the biggest Russian-speaking community for Rust programmers. Our community is 300 people in chat, a site and multiple social network accounts, where you can get Rust news anytime. We translate books, write and translate articles, organize meetups. We help businesses to find Rust programmers for paid work. There's an active gamedev subcommunity and a separate offtopic chat. Our chat is very active and is sprawling with discussions. There, we help people solve their problems. Our gamedev community members are developing their own games and are eager to share their experience. There are 500 members worldwide. We had 280 people come to our meetups, and 11000 people visited our site. Our goals: **30$/month** We'll have hosting, domain and paid services covered. **100$/month** We'll hire professional designer to draw a beatiful, memorable logo and will start printing small souvenirs - stickers and bracelets. We'll distribute these at meetups. **300$/month** We'll regularly pay to articles authors to produce high-quality, fact-checked articles about Rust for our journal. The articles are to be clear, useful and concise, with necessary illustrations. **600$/month** We'll start producing *big* souvenirs with our logo - t-shirts. We'll distribute these at meetups. **1000$/month** We'll start developing new site design and "community-as-platform", to make a web app that unifies various mediums: articles, forums, chats and social networks to talk on any technical topic.
&gt; I guess I'm not helping with perfectionism, am I? :D Ha! Well, I think I'm currently struggling with how to design well--or at least with purpose--in Rust; your suggestions follow some patterns in code I was recently looking at (maybe something in stdlib?), which is quite helpful (since it reinforces the pattern). I feel like once I can lock in on a design that feels right, I can move forward a little easier. FWIW, I think part of what makes this difficult is the nature of units--and maybe more specifically, the nature of the rubygem that I'm porting: not all unit types are defined at runtime. Part of the allure &amp; power of its design is that it lets you compose unit types using already known unit types. I think I gave the example of of "acre inches" or "hectare centimeters" somewhere in this post--with the latter, the rubygem defines the `Prefix` "hecto" (which is a scalar of `1e2`), the `DerivedUnit` "are" (which is an area measurement of 100m2), the `Prefix` "centi" (scalar of `1e-2`), the `BaseUnit` "meter" (a length measurement); combining any area measurement and a length measurement renders a volume measurement, essentially letting you build unit types that fit your needs using a large set of building blocks. I don't have to define what a `HectareCentimeter` ahead of time (and don't want to have to since there a so many possible unit definitions out there, it'd be ridiculous to try to do so). All that to say that your design suggestion makes sense, but I'm not sure yet how to make that fit. It's definitely got my wheels turning though. Thank you!
I'm pretty sure this is what Microsoft does in many of its compilers at least; I know I've heard Anders Hejlsberg present this kind of compiler architecture and its benefits.
I know about the first two, but the last two I've never run into. I'm sure if I made a larger program that did more than a couple of things I'd hit some of those more often. Extra care is required when writing C for sure... Blowing away some part of your own allocated memory is likely to be an issue... For real fun, you have to write a program in C++ though and make a function that returns an object, but forget to include the return statement and then try to process junk data as if that were an object.
Yes, when people write large programs they usually encounter all these bugs. Forgetting return is also an important one. This is why I find Rust very useful. Instead of running run-time tests and then analysing them it just directly points at incorrect line and refuses to compile. It's much faster and I end up with higher-quality code.
Thank you! On that page was exactly what I was searching for: "If only some methods aren't object-safe, you can add a where Self: Sized bound on them to mark them as explicitly unavailable to trait objects. The functionality will still be available to all other implementers, including Box&lt;Trait&gt; which is itself sized (assuming you impl Trait for Box&lt;Trait&gt;)."
I'll be doing my usual TWiR schtick, try to clippy Rust (including the mut_from_ref lint I finished yesterday) and start preparing for our next meetup.
I am trying to remove the most significant bit of a `usize`. To do this, I tried wrapping-shift-left by the number of leading zeros + 1 followed by right shift. It works for every value except 1. The problem is that 1.wrapping_shl(64) == 1. See https://play.rust-lang.org/?gist=5e89f3bdc1bb9dab7899cd014cbcc79c&amp;version=stable&amp;backtrace=0 Is this a known problem? I can see that shifting left by 64 or more bits might be considered different to shifting left by fewer bits. Is it Undefined Behavior? Also, feel free to suggest a better way to mask off the MSB.
Often the requirement only comes lter when you are already settled on the API :(
You can ignore the `..` issue if you distinguish between `make_absolute` and `normalize`. Normalization requires getting rid of `..` components, while simply making a path absolute does not. On Windows `..` is actually treated naively by the OS so you can normalize a path without having to worry about symlinks, which also functions as making a path absolute (so you can use `GetFullPathNameW` for both functions). On posix systems `..` actually hits the filesystem so normalization cannot be done without hitting the filesystem, but simply making a path absolute can, so you'd have separate implementations for those two functions.
/u/steveklabnik1 /u/aturon Would it be possible to organize a non-profit Rust Language Foundation ? I would like to donate money to support those working on the compiler, the language and infrastructure full time (and maybe also donate hardware), but "Donate to the Mozilla foundation" is not good enough. This has been asked a couple of times already during the last year, and I think that for Rust to be a truly open-source project, something like this is necessary. Every time something gets reposted in /r/programming some people also ask what will happen to Rust when Mozilla bankrupts. I do not share these concerns but I think that something like the Rust Language Foundation would help reduce those concerns.
No it's not possible. Separate allocations are necessary so you can free the nodes that aren't being used any more. 
As a part of preparation to v1.0.0 this week I'll continue working on performance optimisation of my [Cassandra driver](http://github.com/AlexPikalov/cdrs). This weekend I was able to eliminate almost all of unnecessary `clone()` calls. It significantly improved performance of parsers on big amount of data.
I think you are looking for (/r/playrust) . This is the subreddit for Rust the programming language.
The repository seems to be located at [here](https://github.com/marblestation/benchmark-leapfrog). That said... is the result for C correct? In my laptop (13" MacBook Air, Early 2015) both Rust and C took essentially same time to complete (14.17s and 14.11s in the wall clock, respectively). It is very hard to believe that C is 10x slower than Fortran in that case [1]. [1] I do know that Fortran may benefit from its lack of shared pointers to the same array (and that C's `restrict` keyword is introduced for that) but it's still just an additional pointer access. 10x is unbelievably extreme.
Something jumping out at me is that the Rust and Fortran versions of gravity_calculate_acceleration have j 0..n in the inner loop while the c and go versions have (j = 0; i &lt; num_particles; i++). This seems like a loop bug but I'm not certain. It does prevent i==j from being true most of the time, so the C version would be doing more work. Still doesn't seem like enough to explain the difference though.
I'm still fighting with dynamic dispatching. I want to move a trait-object out of it's box: trait GetMeOuttaHere { fn escape_the_box(self); } fn foo(x:Box&lt;GetMeOuttaHere&gt;) { x.escape_the_box(); } Of course that doesn't work. The error kinda makes sense. It can not move it out when dynamically dispatching, because the trait object is not sized. So I try dynamic dispatch on the Box type instead. Box is supposed to be sized, so I should be able to do that? trait GetMeOuttaHere{ fn escape_the_box(self) where Self:Sized; } trait EscapeHelper{ fn escape_helper(self); } impl&lt;T&gt; EscapeHelper for Box&lt;T&gt; where T:GetMeOuttaHere+Sized{ fn escape_helper(self){ let x:T = *self; x.escape_the_box(); } } fn foo(x:Box&lt;GetMeOuttaHere&gt;) { x.escape_helper(); } Is there no way to get the object out of the box? That would be kinda silly.
Seems it‚Äôs [just been corrected in C](https://github.com/marblestation/benchmark-leapfrog/commit/c51d95dad0a83d6c3cb5f2868896da3bfa46e158), but is still [present in Go](https://github.com/marblestation/benchmark-leapfrog/blob/master/go/leapfrog.go#L73) (`for j := 0; i&lt;n_particles; i++ {`).
Heh, I remember my program for my master‚Äôs thesis in computer science ‚Äì written in Java (sic!) ‚Äì where I hardcoded every single parameter (or input file path) as a constant and recompiled it for every additional simulation/dataset. Terrible thing I did there, could and should have done it much better. (And I probably could have tried to write it in Rust at that time ‚Äì but I neither had the time to thoroughly learn it, nor Rust was stable at that time. Anyway, knowing about Rust‚Äôs existence made it a pain to write anything in Java. And yet, I still do it, although with Java 8, streams and Optionals it‚Äôs not *that* bad anymore.)
Thanks! I have just pushed the correction for Go too.
How `make_absolute` actually gets implemented isn't what I was trying to focus on. (Though, in hindsight, I *really* should have made that clearer.) You said that it was possible to ignore the `..` issue if you distinguish between `make_absolute` and `normalize` and that's what I was responding to.
I thought GNU was the bazaar ;)
Thanks for maintaining Serde! I've just finished a PR to [update](https://github.com/arcnmx/ocf-rs/pull/2) the OCI crate to serde-0.9. Next item on my list is familiarizing with recent support for [internally tagged enums](https://github.com/serde-rs/serde/pull/739) and update a bunch of code to it.
Indeed. For benchmarks it's generally a good idea for the input to the calculation not to be a constant, as the compiler may outsmart you and use the knowledge about the inputs to avoid part of the calculation as happened here. You could e.g read it from a file, or input it as a command-line argument (of course then you have to avoid timing the input parsing to get an accurate result which may complicate things). In C you can also use a `volatile` variable, not sure what the equivalents in Rust/Fortran/Go are. I would think it would also make sense to check if the output from the different languages end up being the same.
Yes, that would help with input from the command line, but you still need to specify 10+ parameters usually. So usually the configuration file is more useful. Sorry for my ignorance, I haven't checked but, is there a good crate for config parsing?
capnproto is awesome. but it is focused on data exchange (serialization/deserialization). What I want is common data structures (vec/map/set) sharing (not transfer) between process. for example: Master process create a huge Map data object, and transfer a snapshot id to child process. The child process open this snapshot id, got a mmap key/handler which wrapped into a MapView object, and then, child process could use this MapView object to query something, no need to REBUILD the many many internal hash nodes.
I agree, all of this is very exciting, and I'd like to be able to donate to the Rust project directly.
In that case: * provide new API (function) * make old API wrap new one with `BufReader` * deprecate old API
I don't think that is the right way to go about it and judging by what I saw elsewhere in the Rust community wrapping things internally with BufReaders is not uncommon.
Yes, you are perfectly right on this part. I am myself a physicist and work in a physics department. :-) When writing my comment above I was specifically thinking about how easy it is with rust to serialize/deserialize your data, and also how things like `clap` hide all the gritty parsing details from you. And of course `cargo` makes it a breeze to get all that stuff into your program to begin with. My issue with changing some parameter and recompiling the file is not that it adds overhead to the process - that part is usually negligible. The problem is that you lose the *self-documenting* aspect of your code, and thus reproducibility suffers.
crypto is hard, and there are so many ways to make mistakes that are not memory errors, for example ignoring a side channel attack, not using constant time code, depending on secret values for jumps/matches/switches/ifs. so while openssl definitly is a huge mess, and i personally would not feel comfortable with using it in my projects, i do not (yet) have enough trust in rust (or generally new) crypto libraries either.
it is impossible to have an actual hashmap as immutable data structure, immutable data structures always look tree-ish, so a b-tree-map would be very much possible.
Doing some rearchitecting on [Anterofit](https://github.com/abonander/anterofit), the transition from adapter -&gt; service wasn't really satisfying so I'm tinkering around with a more flexible abstraction that will also make delegation more elegant for API wrapper crates. Also, polishing my CV and doing some job hunting.
Shouldn't those be Some(...) instead of Ok(..)? myFunc should probably be wrapped in a Some as well.
The problem is, once you've gone to a trait object, the type is *erased*, meaning that it's lost forever unless you provide a way for the trait object to unbox itself. If you have a specific type to convert to, you can have a trait method that does the unboxing: // Can be any type struct Foo { /* */ } trait GetMeOuttaHere { // Not every type works in the `self: $type` position. `Box` is just kinda magic that way fn escape_the_box(self: Box&lt;Self&gt;) -&gt; Foo { self.into_foo() } // The `where Self: Sized` bound keeps the trait object-safe fn into_foo(self) -&gt; Foo where Self: Sized; } Of course, that requires knowing the target type ahead of time, and locking it into the trait prototype. If you want to do something akin to runtime reflection, there's the [`Any` trait](https://doc.rust-lang.org/std/any/trait.Any.html). If you have your trait inherit from this, you can downcast from a boxed trait object at runtime via [`Box&lt;Any&gt;::downcast()`](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.downcast): use std::any::Any; fn print_if_string(value: Box&lt;Any&gt;) { if let Ok(string) = value.downcast::&lt;String&gt;() { println!("String ({}): {}", string.len(), string); } } fn main() { let my_string = "Hello World".to_string(); print_if_string(Box::new(my_string)); print_if_string(Box::new(0i8)); } 
OK, it appears that this is not implemented due to 1 &lt;&lt; 64 being undefined behavior. See http://llvm.org/docs/LangRef.html#shl-instruction 
Thanks. That looks like the way to solve this.
Actually, you can't use `Option&lt;T*&gt;` for nullable pointers since raw pointers are allowed to be null. `Option&lt;&amp;T&gt;` will have the null pointer optimization though (and `Option&lt;Box&lt;T&gt;&gt;` etc). https://play.rust-lang.org/?gist=8452a739ec50b32c2c684afd093fa501&amp;version=stable&amp;backtrace=0
If you'd like to help we could always use another set of eyes on the [constant time](https://github.com/valarauca/consistenttime) crate. 
I'd imagine that especially for computationally expensive stuff you *want* your things to be hardcoded: For the simple reason that you can't do constant propagation (or, more generally, partial evaluation) at run-time. Of course, you still need proper coding practices but "recompile to configure" is not a bad thing in itself. Heck, xmonad does that and it works just fine: Why hack together a configuration language when you've got an excellent Haskell DSL to write window managers in. Having to change the underlying library (if there's even such a thing) each time you change configuration, now that'd be bad.
I sort of answered my own question by looking through the [libstd source](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/mod.rs). My solution is to have the directories "arch_x86", "arch_arm", etc... and to have the following in lib.rs: #[cfg(target_arch = "x86")] #[path = "arch_x86/mod.rs"] pub mod arch; #[cfg(target_arch = "arm")] #[path = "arch_arm/mod.rs"] pub mod arch;
There's actually a patch to fix this in the beta branch, but it seems there hasn't been a beta build since. Also, 1.17 should be getting suggestions for when you misspell a derive macro.
What's the best way to have tests in their own file, separete from the library implenentation?
tree-ish is also fine, have you any suggestions?
&gt; trying to deploy python packages behind in these environments has been a struggle. What becomes the problem?
capnproto is pitched as serialization/deserialization but it is more than that. From [its documentation](https://capnproto.org/index.html): &gt; This benchmark is, of course, unfair. It is only measuring the time to encode and decode a message in memory. Cap‚Äôn Proto gets a perfect score because there is no encoding/decoding step. The Cap‚Äôn Proto encoding is appropriate both as a data interchange format and an in-memory representation, so once your structure is built, you can simply write the bytes straight out to disk! I'm not entirely sure it can work in your use case, but it was designed as a fast/secure way for different processes in sandstorm to communicate, and so I think it *might*. On the Cap'n Proto [homepage](https://capnproto.org/): &gt; Inter-process communication: Multiple processes running on the same machine can share a Cap‚Äôn Proto message via shared memory. No need to pipe data through the kernel. Calling another process can be just as fast and easy as calling another thread. All that said, when I tried to use cap'n proto in rust maybe a year or so ago, I ran into an issue (can't remember what, though!), so while the C++ reference implementation might be great, I'm not entirely sure about the maturity of the rust one.
Why does it need to be rewritten?
&gt; Maybe i am not up to date, but do we have any chance to get linear types in Rust in a foreseeable future? I don't think anything is planned.
Maybe it was that late, but notice of the (upcoming) break came far earlier. Just saying, you're holding this grudge alive for a long time, there's no point in that.
&gt; I suppose that Python code is primarily to do data analysis? We write python for processing the data as it comes off the sattelite, simulating data, and testing the instruments as well as analysis. &gt; And, as always, there is the additional difficulty that people would rather learn a widely popular language like C++ than go for something as arcane as Rust. Reasons brought up are frequently non-available libraries and the like, although my impression is that most people don't even use these. Well, I'd love to trade the learning curve for memory management headaches when it comes to low level code. However, for my team's next project (a fast image simulation program), we've decided to go with CUDA since neither C nor python are performant enough. If rust could handle CUDA interop I'd push for it for our CLI. But all the crates for that are WIP right now and there are deadlines. Anyway, I sincerely do hope in time that rust gets more of a foothold in scientific computing, since I'd much rather use cargo than cmake and serde than writing 500 lines of config-file handling code.
Wouldn't the same thing apply for a program written in Rust?
I was skimming your solutions. It seems for the *Group By* examples, using a `fold` would be more comparable to the C# and Swift solutions rather than a `for` loop.
Hash Array Mapped Tries (HAMT) are very common cores for persistent data structures. There seems to be at least one Rust implementation of Ctrie (a concurrent lockfree HAMT) but it's fairly old and seems unmaintained. I don't know that you could implement a safe cross-process variant though.
You need to make sure that the beginning and end of the slice are not in the middle of a multi-byte character.
No, it's not. It can fail if you try to slice the middle of a character, [like this](https://is.gd/J4afYc). The first version will panic, the second will produce a malformed string.
They may be referring to [Niko's recent blog post](http://smallcultfollowing.com/babysteps/blog/2017/01/26/lowering-rust-traits-to-logic/).
If you don't need efficient update, you can use a [minimal perfect hash function](http://cmph.sourceforge.net/) to build a very efficient lookup table without any internal indirection. Given n keys, cmph will give you a bijection between the keys and [0, n). Assuming you have fixed length values, you can then just store an array of key-value pairs in hash function order.
You can use [lazy_static](https://github.com/rust-lang-nursery/lazy-static.rs). I'm fairly new to this community, but that's my first instinct when you say "Singleton".
Should I go down the singleton road, this will certainly come in handy. I wonder if there is a way to make this safe without the use of singletons. Ideally I want the Environment wrapper to live within a scope instead of being static, so it doesn't live for the whole runtime of the application, but I still need the compiler to check that there is only one instance.
rust-openssl [could support](https://github.com/sfackler/rust-openssl/issues/580) building openssl, like rust-curl [supports](https://github.com/alexcrichton/curl-rust/tree/master/curl-sys) building libcurl.
Wow, this is awesome! Didn't know this was possible.
I'm trying to expose only the minimal required functionality from `rand` if possible. I don't want Statrs to break on the off chance the distribution API is moved out of the `rand` crate
Thanks. I'm using `str::from_utf8().unwrap()` now, which will panic eventually... I should probably rewrite it. Is there an article about how parsers should be implemented in Rust? For example, `rust-cssparser`uses [from_utf8_unchecked](https://github.com/servo/rust-cssparser/blob/master/src/tokenizer.rs#L875). My own [svgparser](https://github.com/RazrFalcon/libsvgparser/) uses [unwrap](https://github.com/RazrFalcon/libsvgparser/blob/master/src/lib.rs#L30), which is not really good, but at least I'll get a backtrace. When I started to learn rust, I tested `u8` vs `char`for parsing, and `u8` was much faster. So I stick with it.
I know, but even 2003 would probably still be good enough for the point I was trying to make. Which is, that if one is just doing plain numerical analysis, modern Fortran provides a comfortable approach to programming without the issues of C derived languages regarding pointer misuse, lack of bounds checking, UB and so on. Then again, I never really used Fortran in anger, so I might be completely off mark.
this is amazing, wow as rust can run in the browser now, this might be a really usefull tool for that, maybe combined with domafic https://docs.rs/domafic/0.1.2/domafic/
That wasn't covered much in the sprint mostly due to who was in attendance. Niko and I plan to push on this work in the very near future. **EDIT**: you can find the tracker for this work here: https://github.com/aturon/rust-roadmap/issues/8
Integration tests? Put them in `tests/everything_works_probably.rs`, load your library with `extern crate your_lib;`, and run the tests with `cargo test`. The cargo docs and the book have more information on this.
To clarify: you say you'd like to donate to those working full time -- do you mean to those who are already employed to work on Rust? Or were you saying you'd like to donate so that more people can work full time? The core team has discussed donations and foundations in the past. It's a tricky issue; to support engineers on a full-time or even part-time basis we'd need to raise pretty significant money, and we'd need a process for determining how to allocate that money. From what I understand, many existing foundations around projects like Rust have over time turned into a mess of political infighting. But maybe there's a way to avoid it. I do think things like providing hardware for volunteer contributors could make a lot of sense. Right now, Mozilla itself provides such support from time to time (as well as flying out volunteers to events like this compiler sprint), but with donations we could further expand. Anyway, I'm curious to get a better sense for what you have in mind, and I'm happy to re-raise this issue with the core team this week.
What is the best suggestion for a lightweight HTTPS (it would be great if support HTTP/2 as well) server framework with very basic feature like request parser, routing? I don't need template engine since I'm working on a RESTful API. 
I think https://github.com/sfackler/rust-native-tls is the way to go. I wish it would be more developed though :(
&gt; with only one writer and many readers. thus, the readers can safe read without any lock. Nope, you need a reader-writer lock.
Does RLS works with vim, too?
I started with a byte buffer on the stack, and filled it for each item in an iterator. Then I pulled in rayon, and turned my stack buffer into a thread_local! buffer and the iter into a par_iter. This moved my nice logic into a closure, and turned my (error chained) error handling from Err(e) =&gt; return Err(e.into()), into Err(ref e) =&gt; Err(e.description().into()), because I couldn't move that error e out of the closure. Is there something else I could do to return the error object, instead of losing it and just taking the description instead?
Perhaps the error is clonable? What is the error type? Can you show your code?
[OpenAI](https://github.com/andrew-lucker/rust-openai) bindings for Rust. Working this week to make the library feature complete compared to all the things you can do in the canon Python version.
Does it also show the lifetimes which has been automatically generated? This might be useful because newcomers might see how lifetimes are set correctly. I myself suffered a lot of when I learned rust and was thinking of lifetimes. Actually I am sometimes still suffering :P 
 thread_local!(static BUF: RefCell&lt;[u8;1024*4]&gt; = RefCell::new([0u8; 1024 * 4])); fn check_file(result: glob::GlobResult) -&gt; errors::Result&lt;(PathBuf, String)&gt; { BUF.with(|buf| { let mut buf = *buf.borrow_mut(); match result { Ok(ref pb) =&gt; { match hash_file(pb.as_path(), &amp;mut buf) { Ok(result) =&gt; Ok((pb.to_path_buf(), result)), Err(e) =&gt; Err(e.into()), } } Err(ref e) =&gt; Err(e.description().into()), } }) } Looking at it, I realize that I could push accessing the thread_local much lower. The error type is a [GlobError](https://doc.rust-lang.org/glob/glob/struct.GlobError.html) from the glob crate, which doesn't show it is clonable. In the general case, do I need clonable errors to pull this off?
If you just make it a `move` closure, you should be able to return the error directly.
Why is `RUST_BACKTRACE=1`not the default behavior? Does it add substantial overhead?
Isn't that really a compiler feature though?
You cannot override a non-virtual method.
That's what I was fearing :x
&gt; existential types Could `auto` / `impl` Trait be really considered "existential types"?
Iron is a good "use the parts you want" framework. It uses hyper under the hood so it supports HTTPS. Don't know about HTTP/2. Also, Rocket is the new hotness in Rust web frameworks, but I haven't tried it yet.
`Option` is not a pointer, it's `boost::optional`. `Box` is a pointer, and with `Box` it works :)
How do I get my Rust Discord server more lively? It currently has over 100 people but everyone's just so... quiet. EDIT: For anyone who downvoted, no, I'm not trying to advertise it. It's a legit question because I've never grown a community before and I don't know what Rust related things I can put on the server to make it interesting for both beginners and veterans at Rust. 
You can. It just does dispatch based on the static type instead of the the dynamically-determined "actual" type. Usually, if you're overriding a method, you want to do dynamic dispatch.
The only way to ensure that only one instance exists is to have it tracked by a global resource. Either make the object itself global (with `lazy_static`), check and set set a global flag in the constructor, or have it acquire a lock on some global resource like a file handle or database connection. 
I looked at a few cases in your parser and generally for an svg parser it should be safe for all slices as the character after would be an ascii character. Having said that you might prefer panic version to avoid undefined behaviour in the case of a bug.
Why do you think so? I didn't see much of that wrapping but I'd be careful about judging things by community because all communities have imperfections...
To clarify, panicing / unwrap is the correct behaviour if the errors can only happen if there's a bug in the program. Like for example that last result can never panic as the bytes are controlled by the program.
new is the most common need. I want something new, here are the arguments. i may want to express this across multiple arguments, but what I *want* to do in each case is the same without end. make me a new one of x. imagine a square struct. I probably will just store a single side and have a method which calculates an area. I will need a new which creates a square given a side to work with...but I also might want to be able to create a side given some area. see? Yeah, the side version new is probably the most common and will work 90% of the time, but being able to offer the second type of new is seriously nice from an api point of view.
That's a good point. I'll experiment with it in the next release!
That may be true in safe rust, but going beyond, it's definitively possible, the tradeoffs may or not be worth it.
&gt; (or generally new) crypto libraries either. To be clear, *ring* is a re-do of boringssl, which was a fork of openssl. So it's not _totally_ new.
That still means you need a cross chain for C code set up on your box.
I wouldn't mind seeing backtraces on by default in debug mode.
personally, i just find them hard to read, especially when you are dealing with both postfix and prefix versions of the operators and expressions that also contain binary additon and subtraction. having the ability to write let i = j + ++p; doesn't really lead to faster or more readable code in my experiences.
Nice post. This least resistance path algorithm is more commonly known as DTW (dynamic time warping). It also possible to do something similar using the eikonal equation
panicing on an internal bug is the correct response. That quote really means "a library should not panic modulo bugs". The rust book contains some good advice on this https://rust-lang.github.io/book/ch09-03-to-panic-or-not-to-panic.html .
https://github.com/tomaka/rouille emphasizes being light and stable. Hyper based frameworks (iron and rocket) have not been reliable in the near past due to bugs in hyper. Not sure if the situation is better now.
lmdb is good, though the available rust bindings to it aren't great.
aha, ttyrec + ttygif https://github.com/mjording/ttyrec https://github.com/icholy/ttygif Great tool. Works flawlessly!
I'm also willing to help coach local teams in SF/Berkeley (I did coach last year, but remotely -- most coaches are local and I think it works better that way). And/or help mentor rustc/servo projects.
&gt; It's more than generally the stack variables are all close together, on a few cache lines. IIRC the C and C++ standards say nothing of ordering of local variables, so a compiler is free to reorder however it sees fit. &gt; On the other hand, the dynamic allocation is more likely to be aligned on a cache boundary Dynamic allocation will always be aligned to page size, although I don't know any current arch that has a page size not div by cacheline size.
The code has now been improved with all the suggestion friendly made by the Hacker news and Rust subreddit communities. Now C execution time is similar to Fortran and Rust seems faster, but we don't claim that Rust is generally fast. We just wanted to try if with some basic knowledge of each language, you can write some simple scientific software reaching kind of a similar execution speed. And please, take into account that this is a proceeding to present work in progress, not a paper. We could not go into details and we are still developing the more advance N-Body simulator with tidal effects (where we do not use unsafe blocks, btw). Thanks for the comments and suggestions!
of course, it is possible with immutable data structure: `let state1 = reduce(state, action);` both state and state1 are wrapper to snapshot id (which is a offset on shared memory page), and then send state1 to process b, b can use it without any lock.
Seems like I should've been more clear. C and C++ don'd have the concep of [lifetimes](https://doc.rust-lang.org/book/lifetimes.html), [ownership](https://doc.rust-lang.org/book/ownership.html) and [borrowing](https://doc.rust-lang.org/book/references-and-borrowing.html) written into the code. If you look at pointer or reference in C, you don't know whether it's heap-allocated or stack-allocated. You don't know how long will the object it points to exist. You don't know whether other thread can mutate it. In Rust, all code is annotated (explicitly or by well-defined implicit rules). Only that way can compiler check anything. If safe code compiles you are *guaranteed* that it is absent of memory bugs (except for memory leaks, which are usually highly unlikely). Yes, operating system can do anything but that doesn't mean it wants to do anything. To solve thing like bindings with C code or syscalls, Rust uses `unsafe` blocks. Those allow to do things that could cause memory bugs but compiler is unable to make sure it's safe. Those blocks are very rare. The idea is to costlessly wrap the unsafe blocks in safe code to enforce invariants. Thanks to this, Rust can easily call C code and even be used to create an [operating system](https://redox-os.org/). As you see, safe properties of Rust are no barrier to do it. :) Is it more clear now?
I guess you'd use newtype to distinguish between side and area, right? Yeah, it's nice feature to have. But I don't miss it myself. Other. benefits of Rust are much more important to me.
&gt; as the character after would be an ascii character Does that follows from the SVG protocol? If yes, then assuming the input follows the protocol easily leads to a DoS vulnerability. Parsers should not assume that the input is valid. Imagine a browser crashing (e.g. panicking) because a random image was intentionally or unintentionally corrupted.
&gt; The existential deconstructor is what defines an existential type This makes sense, thanks. &gt; And last I checked I don't think C++ even has higher-rank types, at least not in C++14. No, it doesn't, and I cannot recall any proposal that argued for HRT. I was trying to avoid talking about whether these features were useful or not because that's not easy, one always must frame them within the contexts of problems that the language is trying to solve. For example, I think that in a low-level language somebody somewhere will always have a good reason to _really_ want to inspect the exact type. That is, something that truly hides the exact type is going to be less useful than some "loose" existential type feature that offers a escape hatch (arguably, if they offer an escape hatch, they are not existential types anymore... but bear with me). In C++ it would actually be pretty hard to retrofit a system with "strict" existential types. Even then, a skilled hacker has so many tools at its disposal that chances are it will manage to obtain it anyway somehow. So the obvious just works: Concept foo() { return 3; } Concept value = foo(); using value_type = decltype(value); static_assert(Same&lt;value_type, int&gt;); // not concept, but the unhidden type! It is pretty easy to make use of this in C++ to do something useful: void bar() { Concept f = foo(); using f_t = decltype(f); // different behavior (or optimizations) depending on the exact type if constexpr(POD&lt;f_t&gt;{}) { // ... e.g. if POD, call memcpy } else { // ... otherwise call std::copy } } Rust is different. But I would say that any existential type feature in Rust should also provide an escape hatch. What do you think?
Going through the tutorials haha. I'd love to program a video game and this seems like a good goal to learn some Rust. I'm positively surprised by the Windows support btw, using MSVC as a backend works like a charm (after learning about vcvars ;) )
&gt; Houston, we have a problem. Not necessarily, they may be previously ensuring that the content is valid UTF-8 during parsing. That's what I did a while back when I tried writing a streaming JSON parser, the initial version worked on chars() but the decoding costs turned out prohibitive, so I converted it to work on bytes directly and perform UTF-8 validation on the fly, and since I controlled value boundaries there was no risk of splitting in the middle of a codepoint. In fact if you check the first httparse callsite that's what you see: https://github.com/seanmonstar/httparse/blob/master/src/lib.rs#L415 It calls from_utf8_unchecked on a sequence which it made sure was only composed of printable ASCII characters or tabs. Just looking for `from_utf8_unchecked` is far from enough to see whether they're using it correctly or not, if the parsing process already includes UTF-8 (or even ASCII) validation there's no reason to pay that cost twice.
That's true but I was just referring to OPs specific case where the input has already been validated as utf-8 and he is splitting it on ascii characters.
Good point! But there's a room for improvement. &gt; In fact if you check the first httparse callsite that's what you see: https://github.com/seanmonstar/httparse/blob/master/src/lib.rs#L415 I might be reading this code wrong, but it seems to **return** the HTTP status string to the library user. And by returning a `&amp;str` it **lies** to the library user that the status is a valid UTF-8. If I'm wrong, I'd like to see it better clarified in the code. Indeed, even the library author felt that the part should be returned as is: "*The fully compliant parser should probably just return the reason-phrase as an opaque &amp;[u8] data*". I've seen HTTP server implementations where the status string can be used to get extra information to the client, so it's not a non-issue.
&gt; it seems to return the HTTP status string to the library user. That's correct, more specifically it returns the Reason string (the part that's after the status code). &gt; And by returning a &amp;str it lies to the library user that the status is a valid UTF-8. **That is not correct**. The function checks that all content is either a horizontal tab or a printable ASCII character (0x20 to 0x7E), all of which are valid self-contained bytes in UTF-8. If any byte is out of that range it will return an `Err(Status)`. &gt; If I'm wrong, I'd like to see it better clarified in the code. Code seems pretty clear to me: * if current byte is LF * if next byte is not CR, return error * else return validated reason * if current byte is CR, return validated reason * if current byte is neither printable ASCII (0x20 to 0x7E) nor TAB, return error * loop to next byte &gt; Indeed, even the library author felt that the part should be returned as is: "The fully compliant parser should probably just return the reason-phrase as an opaque &amp;[u8] data". That is due to the "obsolete text range" (any byte above 0x7E), which the library currently considers *an error*.
I see. Wasn't familiar with how `Bytes` work in this parser, sorry for the confusion.
Just tried it - seems to work on x86_64-unknown-linux-gnu
&gt; Just looking for from_utf8_unchecked is far from enough Yes. That's why I kept only few examples. There are much more crates with unsafe/unwrap, but they have an explicit comments about what they doing right before unsafe/unwrap.
Is anyone using TiDB/TiKV in production yet? I've been following along with these weekly updates for a while and this looks like a great piece of software. There aren't that many good, open source, scale-out SQL databases around, and the ones that do exist seem to require a big JVM infrastructure (i.e. something like Phoenix or SpliceMachine) Is TiDB+TiKV ready for prime-time?
What is wrong with [`HashMap::iter_mut`](https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.iter_mut)? It makes sense that you are not able to modify keys because this might invalidate other pointers into the `HashMap` as entries get moved around inside.
There shouldn't be any other pointers into the HashMap as you have a mutable reference. However you're right, in its current implementation the iter_entries_mut() doesn't offer much that is new. I edited the question above to reflect what I'm really after: for the "Entry" API to allow you to delete an entry, and to be able to iterate over the entries so that you can delete during iteration.
Because we don't have streaming iterators in the stdlib.
It's more of a matter of the library has already checked it's valid beforehand. Edit: to clarify it's code like this which never panics regardless of the input let input = "User controlled; string"; let bytes = input.as_bytes(); for (i, b) in bytes.iter().enumerate() { if (b == b';') { return String::from_utf8(&amp;bytes[0..i]).unwrap() } }
I think the main issue is that modifying the keys would put you into the position where you need to rehash the keys, but it's not clear when this can happen.
What does it do exactly? Does it run the function marked with init()? The documentation is a bit sparse...
I think it would be useful, occasionally, to have an iterator API that allows you to delete the entry you're currently visiting. Not because of performance, but for *clarity*. Creating a separate `Vec` for holding indices, or breaking the loop every time you delete an item, is just extra boilerplate which makes the code more difficult for the next person to understand. And Rust certainly has all the tools to make such an API both safe and understandable, with high performance as a lucky side-effect. For example: for entry in collection.entries() { if predicate(entry.value()) { entry.delete(); } } Here the `delete` method could consume the entry, so that you can't access it anymore. The programmer's intent is clear, the API is safe, *and* it could have high performance since it's the collection that decides the deletion strategy. Win-win-win all around. 
You have to ensure the address is changed atomically; looking at crossbeam (crate of lock free structures in rust), it appears to require the use of raw pointers, which, to use, need unsafe. The crossbeam datastructures are wrapped in a safe api though, which is nice; I'd be surprised they can be used across processes without modifications. The author, Aaron Turon /u/aturon may have more insight. Oh, and you need an effective and efficient way to clean those "snapshots" while accounting for use by multiple processes.
Of course it could. The collection chooses deletion strategy. A `Vec` could simply log the deletes in a list and apply them all at once at the end, whereas a linked list could apply it immediately. Remember, the collection is still mutably borrowed during the whole iteration, so it's free to do whatever it wants so long as it's in a consistent state when the borrow gets released. How deletion is performed is just an implementation detail.
I'm also curious, is there a use case for this I'm not thinking of? It's a fun hack either way though.
&gt; escape hatch Well, if it does, then it had better be `unsafe`. The usefulness of existential types comes from the guarantee that the callback *can't* inspect it.
I tried i686-pc-windows-gnu, i686-pc-windows-msvc, x86_64-pc-windows-gnu and x86_64-pc-windows-msvc. All of them seems to work.
Hi, The code you listed can be rewritten as follows: use std::collections:HashMap; fn main() { let mut map = HashMap::&lt;i32,i32&gt;::new(); match (map.get_mut(&amp;23)) { Some(value) =&gt; { *value = 42; }, _ =&gt; { map.insert(23, 42); }, } } making it clearer why the mutable borrow is rejected in the else branch. This a known limitation, but as far as I know there is ongoing work to improve things. The keywords to search for are "non-lexical lifetimes". Here is a link to a post discussing it: http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/ Cheers! 
&gt; A Vec could simply log the deletes in a list and apply them all at once at the end So you just want the Std library to allocate the vector for you? I thought you wanted to avoid this allocation?
&gt; The usefulness of existential types comes from the guarantee that the callback can't inspect it. For example, in: let v: impl Iterator = foo(bar(a, b), c).baz(c).moo(d, e, f); existential types are useful independently of a escape hatch being available: - as a reader: it tells me that `v` is an `Iterator`, which makes the following code more readable, and saves me from having to inspect the complex expression (i might not care about it, but I might care about what the following code will do with v). - as a writer: this helps refactoring, since if that complex expression stops returning an iterator, I will get a compilation error, but I still have the flexibility to make it return a different type of iterator. whether a escape hatch is available or not does not make them less useful for these purposes, which are IMO the biggest advantage of existential types in practice (at least in Rust and C++): they transmit more information than code without type annotations, but without a significant flexibility loss. &gt; Well, if it does, then it had better be unsafe Why? The escape hatch just lets you inspect the exact type. If you use it, and the type is changed afterwards, the worst that can happen is that your program stops compiling (you will get a type-checking error). Using it cannot introduce any unsafety (neither memory nor type unsafety), at least when doing static dispatch. I do not think allowing the escape hatch for inspecting existential in associated type positions or return values of trait objects makes sense though, but there are already other limitations about which language features one can use for unsized types.
I was the one who specifically wanted to avoid the allocation. I think @my_two_pence wanted the feature for primarily ergonomic reasons, with performance a secondary benefit where available.
I believe a single commit is promoted to nightly everyday now, though I think it is still rebuilt currently, instead of being simply marked as such at the end or start of the day.
**tl;dr:** it wasn't Rust, it was the `bitflags` library, and the problem is already solved. These aren't the droids you're looking for. Move along.
&gt; This functionality is called the Entry API and is also found on Python dictionaries. Not to my knowledge no, and in Python you'd just `map[23] = 42`
&gt; I thought you wanted to avoid this allocation? If allocating a list of indices is the fastest solution, I want it to do so of course. If it's faster to move the elements as the iterator advances, keeping a "hole" in the vector, then I want it to pick that. If the type is non-zero, like `&amp;T`, it could mark deletion by zeroing the element. Above all, I want the collection make the choice, because I have no way of knowing which is faster, and I want the API to be agnostic of this choice. 
That was changed during the stabilization phase. You are not responsible for stripping attributes. You can declare them in your code now. I believe the docs have an example. 
One other use case that my computer systems class did in C was to load the memory and registers of a previous running program and then immediately jump in and continue with the execution of the program. The equivalent rust code might as well just be totally wrapped in unsafe, but it could be possible with something like this. 
Mac OS 10.11.6 (`Darwin ginhi.local 15.6.0 root:xnu-3248.60.10~1/RELEASE_X86_64`) and it worked fine, rustup gave me: `nightly-x86_64-apple-darwin updated - rustc 1.17.0-nightly (0af0b580c 2017-02-13)`
Very cool. I've been toying around with a similar concept for an Elm-inspired library for Cocoa/Appkit. 
You might be interested in [ordermap](https://github.com/bluss/ordermap). It doesn't have the functionality you're looking for today, but I'm working on it. üòõ
&gt; d = [1:1, 2:4, 3:9] Not valid python &gt; d.get(4,16) == 16 # set 4 to 16 and return it Does not actually set anything, this just returns the default value if none is set. `setdefault` will set-and-return. However it's not an entry API, you don't get any sort of entry object to manipulate and can't lazily compute your eventual value. &gt; d[4] == 16 raises KeyError. evidence: &gt;&gt;&gt; d = {1:1, 2:4, 3:9} &gt;&gt;&gt; d.get(4, 16) 16 &gt;&gt;&gt; d[4] Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; KeyError: 4 
Please be constructive and nice.
I've got some detailed asnwers, but first some general thoughts: The good thing about rust is that due to language guarantees, api changes are possible - but still take an effort. APIs are political things. If you are apple, you can get away with changing it weekly, and the world will adopt (mostly). If you are trying to win one small client who has plenty of choice, you may not have the luxury to redefine api ever. I don't know your position, so only you can assess what you can do. Second, it seems that your APIs are byproduct of your system internals. From the client perspective, that sucks, every time you change anything client will need to adapt. Perhaps look at what client needs, design API *and only then* start working on implementation. &gt; some APIs take self, some take &amp;self, and yet others take &amp;mut self This isn't decided willy-nilly, there are reasons for choosing one way or the other. &gt; you have some refactoring done which changes some use-cases Your method signatures and what you will allow your client to do are contracts with users of your code. Its not something you change without good reason, so you need to weight costs and benefits, have good explanation and migration path. &gt; how much of an effort does it take to work around it It depends. In some cases, change is trivial and client doesn't care. If you take away mut, they may be unable to do what they were doing. You should ask your clients, not random people who don't know your code. &gt; Again, how much effort would this kind of refactoring take Again, it depends. But if you ask me to change my code just because "we did some refactoring", I'll start looking for another provider. 
What's the difference from just putting `init();` at the beginning of `main`?
Yes, there are about ten use cases in production environment. We will release RC2 in this month and GA in this year.
Hey i'm trying to interface with a c library file for the SMC in my mac, with this function specifically just for testing bool is_battery_powered(void) { kern_return_t result; smc_return_t result_smc; result = read_smc(BATT_PWR, &amp;result_smc); if (!(result == kIOReturnSuccess &amp;&amp; result_smc.dataSize == 1 &amp;&amp; result_smc.dataType == to_uint32_t(DATA_TYPE_FLAG))) { // Error return false; } return result_smc.data[0]; } the rust code i use for it is extern crate libc; extern { fn is_battery_powered(); } fn main() { let x = unsafe { is_battery_powered(); }; println!("100c is : {}", x); } but this code gets this error when i compile what does this mean, and how if possible do i fix it? = note: Undefined symbols for architecture x86_64: "_IOConnectCallStructMethod", referenced from: _call_smc in libsmc.a(smc.o) ld: symbol(s) not found for architecture x86_64 clang: error: linker command failed with exit code 1 (use -v to see invocation) edit: here is the build.rs if it matters extern crate gcc; fn main() { gcc::compile_library("libsmc.a", &amp;["src/smc.c"]); }
&gt;Does this mean a safe wrapper around an ODBC Environment can not be written? No. Ultimately a certain degree of trust must be placed on the end user. You can put a guard rail in front of a cliff. But if somebody is determined, they can jump the guard rail and jump off the cliff. Neither you, nor your library is to blame. Really ODBC is for being kinda crappy. But mostly the end user who did this idiotic thing is. No language's safety guarantee can prevent stupidity. If you make a safer system, nature will make a better idiot everytime. 
The book is tied to the compiler release cycle (that might be changing soon) so for up to date docs you want to go [here](https://doc.rust-lang.org/nightly/book/procedural-macros.html). Still the attribute thing is undocumented.
You want to return your Result all the way through the program, back up to 'main'. Then check if your received an error, and if you did, display it with a nice message, and exit wih an error code. Using expect here is nicer than unwrap, but it's hostile both in output and future flexibility (since 'catching' that expect is possible but not at all recommended) 
`panic`s are used to report logic errors, i.e. "programmer has made a mistake when writing the code" kind of thing. Their outputs are intended to be seen by the programmer, not the user. `expect` calls `panic`, and they share the same semantic. Same for `unwrap`. I personally regard them like an assertion about `here it shouldn't fail`. User facing errors are handled on your own. It's usually just "check error and early return" till the `main` function and print to stderr on your own. I usually do something like this: // String as error type for demonstration purpose. Should use an enum in actual code. fn app() -&gt; Result&lt;(), String&gt; { let something = my_function().map_err(|e| format!("Xyz failed: {}", e))?; // the try operator "?" early returns Error(e) if its operand is an Error. let some_other_thing = my_function2()?; // if the Error types are the same or convertible. // use "something" and "some_other_thing" Ok(()) } fn main() { if let Error(e) = app() { // print e to stderr. This should be easier in stable rust. use std::io::Write; writeln!(::std::io::stderr(), "{}", e).ok(); // the `.ok()` means even if it fails, ignore it. We are exiting any way. I think it's a common pattern to abuse `ok()` like this? ::std::process::exit(1); // or your own quitting logic } } 
How strong is the promise of safe code? Is my code only supposed to be safe by itself, or should it still be guaranteed to be safe if composed with other arbitrary safe code? Somehow I feel this could be resolved if only I could take ownership of the underlying C-API.
Excellent! Thanks for the link as well. I will definitely check that out and post my feedback there!
the python equivalent for `Entry.or_insert` is [`dict.setdefault`](https://docs.python.org/3/library/stdtypes.html#dict.setdefault)
&gt; If you are apple, you can get away with changing it weekly, Okay, that made me laugh!
It can be use in a library crate to execute code without requiring the `main` function to invoke it. This is quite a dangerous pattern and has a bunch of issues if languages like C and C++. Rust has explicitly stayed away from it. https://doc.rust-lang.org/1.4.0/complement-design-faq.html#there-is-no-life-before-or-after-main-(no-static-ctors/dtors)
python likes protocols and simplicity. in the case of [`dict.items()`](https://docs.python.org/3/library/stdtypes.html#dict.items), simple means that it serves one purpose (iterating/enumerating the entries), the entries are a simple data type (duple), and aren‚Äôt bound to their source dict. the canonical way to get-or-else-update is [`dict.setdefault(key, default)`](https://docs.python.org/3/library/stdtypes.html#dict.setdefault).
I mean, you could also write the exact same code in Rust.
Ah... well that's not called overriding in the C++ standard :)
You probably meant to post to /r/playrust
&gt; Weird os-centric resource errors are not part of Rust's safety guarantees Sadly creating a second ODBC Environment will not fail, with some error like "You already have one". The allocation of the environment will most likely return SUCCESS. Using it then results in race conditions and memory corruptions. &gt; You cant reasonably be expected to police other applications, or libraries in not-yet-written software. You can't fight the future... It hasn't happened. Maybe you are right. Still it feels like commiting the first half of a deadly embrace. It is not yet a bug on its own, but might become one.
Yes, I think a guideline would be helpful. Basically I'm asking the question if composing my library with other libraries wrapping the same C-API is supposed to be safe. Pragmatically I think RustDragon and valarauca8 are right. It's likely that no one will encounter the issue. Yet it is possible, so I wonder how high are the standards for safe code?
&gt; panics are used to report logic errors I can't remember where I read, it but I like to think of `panic`s as for `unrecoverable errors`
It's probably too early (or maybe secret) but I would love to see a blog post at some point featuring some of the production installations, stuff like how many nodes, how much data is stored, reqs/sec, how monitoring is done, are they using TiDB or KV store directly, what industry/purpose it's used for, etc...
What action would you prefer be taken when Steve next posts a blatant lie? (Text strike-out 2 weeks late is this medium's *closing the door after the horse has bolted*). 
I like to think of panics as 'the program is broken as coded, not that the input is unexpected or broken'. panics mean the programmer screwed up. errors mean the data is messy or nonsensical and I should either handle it gracefully, or report it and have someone fix it.
Ah yes I should have been clear it's being worked on. And yes your correct that the compiler will do basic optimizations for numerical calculations. But any thing more complicated that should be static (eg a hashmap) generally has to live behind something like a lazy static. I haven't looked at the new procedural macros yet, but yeah macros could probably replace a lot of the more clever compile time tricks boost does 
Not exactly binary trees, but from me to you, this is recommended reading: http://cglab.ca/~abeinges/blah/too-many-lists/book/
Doesn't lazy static take care of most of the things you'd want this for anyway?
RFCs aren't really intended to be a specification; they're a way of making decisions. This should be updated in the chapter in the Rust book/reference, that's the right place for it.
There are gcc extensions to do something similar to this, also at the end of main. I have used it before for quick and dirty things. This is not somehing you should use everyday.
This seems like a great read, took a quick look and it seems like a very "explain it to me like I'm 5" kinda thing while going as in-depth as needed, definitely favorited I'll read it tonight. Thanks :)
hm... while I get your point, I tend to disagree. New features in rust are sometimes poorly documented. If one didn't follow the RFC discussion or PR discussion it is sometimes really hard to get a grasp of what was actually implemented. I'm assuming here actual implementations are often close to what was discussed in the RFC, please correct me if I'm wrong. But if that is the case, isn't the RFC itself, which specifies and discusses alot of technical detail, the best template for a specification. Also, not maintainting them means that they are worthless after the implementation. They could have been implemented as specified but it is not certain. So either update them, maybe keeping the pre-impl-RFC, or throw them away so that no one looses time on them.
I made a macro at one point to combine the println! and the exit. so it would be: exit!("Xyz failed", 2); or exit!("Xyz failed: {}", e.description(), 2); Makes for cleaner use in closures.
[Entity component system](https://en.wikipedia.org/wiki/Entity%E2%80%93component%E2%80%93system)
&gt; New features in rust are sometimes poorly documented. We now have a merged RFC that requires all features be documented before they're made stable. This is a very recent development, so it only has applied to a few things. There's an effort underway to go through and backfill the rest as well. &gt; isn't the RFC itself which specifies and discusses alot of technical detail, the best **template** for a specification. Emphasis mine. It provides a starting point, but it's not organized around being a specification; RFCs are organized around building consensus about how things should work. &gt; Also, not maintainting them means that they are worthless after the implementation. Historians will disagree :) 
http://rust-lang.github.io/book/ch12-03-improving-error-handling-and-modularity.html is an example of refactoring some code to do this.
I definitely don't want to mess with explicit lifetimes yet. What would you recommend Rc or Box? Seems like the most common options on code I read seem to be boxes or cells (not intirely sure what the latter do but I've not read up on them yet) The thing is whenever I associate something with the word pointer I was panic (haha) that everything's getting freed, these "abstractions", specifically box deal with that for me right? If I do: let mut x = Some(Box::new(20)); x = None; The previous box and its contents are gone from memory correct? 
Yes, you are right. And I was also trying the same thing, and it works out greatly. One side question, why the error message complains '_serde' crate is missing, instead of 'serde'? The underscore is quite confusing here. 
Do you have `serde` in your `Cargo.toml`? That's what this sounds like to me.
No, it was not there. Including it solves the issue. ;-)
First your Rust code contains a few mistakes: 1. `is_battery_powered` returns a boolean but you declared it to return nothing, so it should be extern { fn is_battery_powered() -&gt; bool; } 2. Then you are ignoring the return value in your `main` fn, it should be `let x = unsafe { is_battery_powered() };` (removed semicolon). Now onto the real question, it looks like you need to pass `-framework IOKit` to the linker in order to use this function. Add this line to your build script: println!("cargo:rustc-link-lib=framework=IOKit"); (edit: or use my [new crate](https://www.reddit.com/r/rust/comments/5trjco/whats_everyone_working_on_this_week_72017/ddr6do6/) and write `link_lib(LibKind::Framework, Path::new("IOKit"));`!)
Many thanks! 
I think i have found a way to do it with the gcc crate, it supports specifying command line args through gcc: config::new()
Regarding which to go for: - use `T` directly when possible - `Box` when necessary - `Rc`/`Weak` when necessary In this order. The only reason to use `Rc` over `Box` is when you want to share ownership; it's a rare requirement (or it should be, if you find yourself sharing all the time, take a step back, something's probably wrong).
It is! Thank you :)
I did a little bit of work on this, and today it launches!
Discord, has a "fight the borrow checker" section. Link: "https://discord.gg/23sA8nR".