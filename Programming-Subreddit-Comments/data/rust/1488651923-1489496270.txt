Try calling `.into_owned()` on the `Cow` types returned by `replace_all()`?
Your link is missing a closing bracket.
That's an interesting solution. I had to do the same thing (write a function for drawing images) and ended up making a macro for default parameters.
the problem is the early release doesn't entitle you to the final release (at least so i've been told)
I don't like these comparisons much because i think they are a bit unfair. If Rust wins everybody cheers and if C wins everybody says "well, Rust is still better for big projects because C becomes really hard when resource managment and concurrency aren't easy." In some situations Rust will be faster because of its strength in others it will be C and sometimes one will be faster than the other for no good reason other than compiler magic. I'd rather talk about why Rust (or C) was the better choice for a certain project. How where you able to leverage the strengths of the language you used? If we are going to disassamble anyway and check which language resulted in better assembly (with total disregard to code clarity in the source) we might as well use inline assembly. At that point you are just trying to get the compiler to output the assembly you wanted all along anyway. This is aspecially true if you are in an unsafe block anyway.
Ooh. Hashlife.
Just to be clear: with "implicit borrow" I mean the coercion of expressions of the type `T` to `&amp;T` by automatically creating a borrow. I don't mean handing through references which is done for patterns. I'm okay with making it not necessary to write ref.
I've contributed a bit to Servo, but I feel like a drag not being super fluent with the language and I don't like to over-ask about what is probably basic Rust. 
The reverse is also good if you're also familiar with C ;) My first "major" thing I did in Rust that actually shipped in something was wrapping `toml-rs` in a C API (none of the C toml libraries I could find have serialization support)
How do I assign assign a bytes iterator from io::stdin() or from a child process stdout to a variable? The gist of my code is: let input_stream; if use_stdin { input_stream = io::stdin().bytes(); } else { let process = Command::new("foo") .stdout(Stdio::piped()) .stdin(Stdio::null()) .spawn() .expect("failed to execute process"); input_stream = process.stdout.unwrap().bytes(); } The compiler says expected struct `std::io::Stdin`, found struct `std::process::ChildStdout` on the next to last line. EDIT: Figured it out. I boxed the values, and declared input_stream as type `Box&lt;Bytes&lt;Read&gt;&gt;`.
I'm probably not looking hard enough because I still don't see it.
Yup. Only fast for stable patterns, but when it works, it flies.
Are there any resources for someone new to rust who wants to make a GTK application?
Sorry I'm just really excited about it. I learned to program in large part by reading O'Reilly books when I was a teenager, so this book coming out (which really is quite well done!) also feels to me like the end of some strange, computer-flavoured circle of life.
Commenting because I am also interested in this. Also if someone could instruct me on how to make working bindings for GTK libraries that use GObject introspection (i.e. libchamplain) that'd be lovely.
Just want you to know that there are two bugs having to do with how crates.io should display yanked crates-- it sounds like you're running into [#76](https://github.com/rust-lang/crates.io/issues/76), where the max_version doesn't get set to the next-largest unyanked version when you yank the max_version. There's someone working on a [PR](https://github.com/rust-lang/crates.io/pull/582) for that as we speak, so it should be fixed soon! The other issue you might be running into, but seems less likely from what you said, is that [it's hard to get any information about a crate when all its versions have been yanked](https://github.com/rust-lang/crates.io/issues/502). I'm probably going to investigate this one and get it on the E-mentored list soon. As far as your worries, I have a feeling I'm not going to convince you, but please don't stress too much about version numbers. They're free, there's plenty of space on crates.io for more versions and more crates, no one is going to think your version numbers are ridiculous (or if they do, they find [mine to be more ridiculous](https://crates.io/crates/sassers/versions)). As far as working on the 2.0 version before it's released, there are a few options: - Since cargo supports installing crates from github, you could encourage people who want to try out the in-progress to install your crate from there. - It's true that the string after the hyphen is just a string, but that's kind of how it is with 0.x.y versions too. To look at a widely-used project in another ecosystem: Rails, for instance, [releases versions such as 5.0.0-beta1, 5.0.0-beta2, etc, then 5.0.0-rc1, 5.0.0-rc2, then 5.0.0](https://rubygems.org/gems/rails/versions) (and 5.0.0-racecar1 in there too, for example, see even big established projects sometimes release silly version numbers!) - Probably more ways of doing this that others will chime in with There's YET ANOTHER [crates.io bug](https://github.com/rust-lang/crates.io/issues/468) that [is currently being worked on](https://github.com/rust-lang/crates.io/pull/577) that would keep any version numbers with -whatever out of the copy-paste box on a crate's page (unless the crate only had versions with those). Would that help too? If there are any other problems with crates.io, or enhancements that we could make that would improve these situations, please let me know! ❤️
no_std code can still use FFI or even plain syscalls to do arbitrary stuff. So depending on your threat scenario, it may offer *some* minor defense-in-depth by making such stuff a tiny bit harder.
As /u/Ganrko talked about, I get this sort of situation today largely from blanket impls or the like; in highly generic code it will tell me to add a bound I don't want which would imply the bound I do want. (A simple example, if you're missing `T: ToString`, it will suggest `T: Display`.) What's troubling about the errors today is that we allow a certain negative reasoning so that you can implement `ToString` if you don't implement `Display`, and its not incoherent (this reasoning is strictly local). I'd like to see this fixed in a version of Rust for which the negative reasoning is more total and less of a happenstance, like it is today. I agree with you that we don't want to see too much of this kind of chaining. For example, while I think `foo&lt;T&gt;(arg: Hashmap&lt;T, String&gt;)` should infer the bound, `bar&lt;T&gt;(arg: T) { foo::&lt;T&gt;(table) }` should not infer it. It needs a syntactic element in other words. And I think the *best* example for using this is impl blocks where the type with propogated bounds is the receiver. Here, of course, there is no indirection.
I don't think the refactoring thing is an issue because the short version implies the String is moved which makes "unrelated change" only true in the context that you know it wasn't actually moved.
LGTM
I think the [examples](https://github.com/gtk-rs/examples) are a good place to start looking at. We intended to write a tutorial some times ago but didn't take time to finish it. Might be worth doing it some day...
I've thought about it a bit, I actually went with it because I was thinking that maybe you want to be able to handle errors in the lispy code. I'm not sure though, just testing stuff out atm. :) I think it complained about Func when I did 'use Token::*;' since it's already a struct or trait. And since I'm swedish (we spell it 'funktion') and like some funk I figured I'd solve it the lazy way. Yeah, that'd be the best way to measure performance (though the laziness struck again (to be fair I've only slept like 4 hours a day this week, freshly baked dad woo)), but I was also wondering if there are other caveats. Like, you say there's a slight overhead (in memory?), so if I very seldom clone Rc is worse, but if I often clone, Rc is faster? Please bear with me if my questions are beginneresque, I've mostly dealt with JS before trying to do stuff in Rust. And I mean, I do well enough without knowing that much about the memory usage of different methods, but I figured it's good to learn a bit more about that.
If that's the case, is the gir binding generator all I need for it, and then just write a rust-y API around that? I already dabbled in generating bindings from gir files before (thanks for making that generator, by the way) but I'm not quite sure what I have to do with the generated bindings.
I see what you mean with the error thing, I thought that the `Token` type came before parsing (usually in cases like these, lexing produces tokens, which are fed to a parser to be turned into the actual program structure). If you never clone your `Rc`, then it should act like a `Box`, with a small memory increase in the form of the reference count itself. If you don't need this, then the pointer indirection may cost you (although, I don't know what kind of speed you want from this, are you counting CPU cycles, or seconds?). If you clone often, but never (or rarely) mutate the data, an `Rc` will prevent the whole structure from being copied every single time, in favour of simply copying a 32 or 64 bit pointer around. In terms of measuring, simply creating a sufficiently complex test case and then timing it like `time cargo run` should be enough to tell you if the `Rc` makes a big difference.
No need to delete the post. :P Glad you solved your issue, though. 
Euh... You're losing me... A binding is just a wrapper on top of C function basically. An easy example: // C functions extern "C" { fn strlen(s: *const i8) -&gt; u64; } // rust functions fn get_len() { let x = b"hello\0"; println!("len: {}", unsafe { strlen(x.as_ptr() as *const i8) }); } Now you can call `get_len` from rust code "safely". That's the point of bindings. Then you build something more clever on top of it to actually improve the usage of the C code by providing rust safety. Did it answer your questions?
Done. I've testes 'svgparser' on about 70k files and everything was fine, because files itself are well-formatted. But thanks to cargo-fuzz I found a lot of stupid bugs.
I've tried this: .filter_map(|line| get_title(line)) .map(|title| reg.replace_all(title, "").into_owned()) .map(|title| reg2.replace_all(&amp;title, "")) But get the infamous `temporary value dropped here while still borrowed` on the second map.
I think so, yeah. Thanks once again!
Compiling vs Linking: I am following the instructions to install various tools and I see the installation of `rustfmt`, `clippy` and `rls` have many common libraries with the same version numbers but it recompiles the library rather than reusing existing and linking. Shouldn't cargo be able to detect the dependency and link if library with same version already exist? e.g. cargo install --force rustfmt .... Compiling toml v0.2.1 Compiling rustc-serialize v0.3.22 cargo install clippy .... Compiling rustc-serialize v0.3.22 Compiling toml v0.2.1 
i think linus is perfectly able to surf the web on his own. there is a project somewhere that builds an empty kernel module in rust, maybe that would be of interest. i would be much more comfortable with rust having some sort of reproductible build before putting it into the linux kernel.
Heads up! gtk-rs.org documentation is out of date. `AboutDialog::set_website`'s signature is still the same. At first glance, I would have thought that `Into&lt;str&gt;` would not be possible because it rules out widgets stored as trait objects. I know that gtk-rs doesn't use the type system in the same way other projects usually do; Is this not an issue for gtk-rs? Also, what do you think of linking to gtk at runtime rather than requiring gtk at compile time? (i.e dlopen) Do you think it's possible, practical? It would make portable rust applications that fail gracefully possible on linux (musl+gtk-rs). GTK is not the most exciting thing in the world to work on, but it is mature, proven, and cross-platform. gtk-rs is a very important cornerstone in desktop Rust. Thank you for your work, and thanks to every one else that works on it. P.S. Please enable HTTPS on gtk-rs.org if possible.
&gt;Given what Rust is today, and what it's planed to be tomorrow, is it still possible for a gcc implementation to exist? I think the main blocking issue is nobody is working on it. --- The real *blocking* issue is Rust isn't formally standardized. So there is zero guarantee the compilers could compilers could interopt. C took &gt;10 years from its first release to standardization. This just doesn't _happen_ overnight. 
First of all thank you for your response and all the great work. I really appreciate it. Cargo, crates.io are one of core parts that make Rust ecosystem awesome. I hope I didn't come out too negative - I'm just trying to give feedback and get help. Thank you for pointing me to the bugs. It now makes sense. I guess some part of my confusion was due to things that will get fixed soon. I also now understand my root mistake (see my response to your other comment), and I think `2.0.0-0.1` might work just fine (+/- the tools like `cargo-outdated`). Personally the 4.0.0-alpha1, -beta, -rc, and 4.0.0 does not fit me most of the time. I like the freedom that 0.x.y gave me. "When it's ready, then it's ready", so I hope "2.0.0-x.y" approach is going to work well for me. What do you think about it? Does it make sense? Do you see any problems with it? Eg. will people be able to use `mycrate = "2.0.0-1"` to get `mycrate 2.0.0-1.0`, `2.0.0-1.1` and so on? One pain point that remains is that it's hard to experiment with versioning and discover such things by yourself. 
They do, it would be insane if not :p
&gt; Given what Rust is today, and what it's planed to be tomorrow, is it still possible for a gcc implementation to exist? Sure -- there's already talk of using Cretonne as a back end to rustc; wiring up GCC to rustc is about the same difficulty. It's a "wish I had time" project for me... There's also https://github.com/thepowersgang/mrustc -- a cleanroom Rust compiler front end, written in C++. 
I thought about it, but: * Semantically `mycrate 2.0.0-x.y` is just another version of `mycrate`, and not something different. * I'd like to piggyback on popularity of `1.x.y` to let willing users to try `2.0.0-x.y`. * I don't want to "pollute" crates.io with yet another set of crates. It seems to me, it might be confusing, and they will have stay there, even after I'm done with them. * It seems like a maintenance complication. Now I have another set of crates.io entries to remember about.
I get an error: Compiling gtk-rs-examples v0.0.1 (file:///home/bromskloss/code/examples) error[E0277]: the trait bound `std::option::Option&lt;&amp;str&gt;: std::convert::From&lt;std::option::Option&lt;&amp;std::string::String&gt;&gt;` is not satisfied --&gt; src/notebook.rs:69:21 | 69 | let label = gtk::Label::new(Some(&amp;title)); | ^^^^^^^^^^^^^^^ the trait `std::convert::From&lt;std::option::Option&lt;&amp;std::string::String&gt;&gt;` is not implemented for `std::option::Option&lt;&amp;str&gt;` | = help: the following implementations were found: &lt;std::option::Option&lt;T&gt; as std::convert::From&lt;T&gt;&gt; = note: required because of the requirements on the impl of `std::convert::Into&lt;std::option::Option&lt;&amp;str&gt;&gt;` for `std::option::Option&lt;&amp;std::string::String&gt;` = note: required by `gtk::Label::new` 
Iiiiiiis there now? I should find that. Custom derives being stable is awesome.
Excellent write-up :) very easy to follow and informative!
In a Serious Lisp, traditionally, I believe you usually intern symbols to turn them into small, easy-to-copy value types. IIRC that is generally done during the "read" step.
If he didn't switch to modern C++, which is more safe than C, such as RAII or array safety, is almost backwards-compatible with C, and has multiple compilers, I doubt he'd switch to Rust.
I dunno, I think `funktion` sounds sorta metal.
Thanks! Glad you liked it!
That changed after I wrote the post. Will update.
Sum type is one of the things you didn't know you need it before, but can't live without after. I was introduced to it by Swift and now can't imagine going back to languages without it. No sum type is like doing bit manipulation with only &amp; and no |
Don't sweat it! Thanks for sharing :) 
Wait a decade, then ask again. Linux is, understandably, risk-averse in the devil-we-know-is-better sense.
&gt; Let’s try to avoid using confusing terminology, however. If Rust does get “pi types”, let’s just call them “dependent types” or “integer generics” :) The best thing about Rust is that you can talk about something like pi types or monads *without* producing confusing monad tutorials. Haskellers would probably talk about products in the category of dependent burritos or something like that. 
Sounds like you want rustfix, which is in the works
&gt; In languages with lazy evaluation (like Haskell), there is no difference between having a function that can give you a value, and actually having the value. Maybe in languages *like* Haskell, but in Haskell itself, things are otherwise: Prelude&gt; seq (\() -&gt; undefined) 3 3 Prelude&gt; seq undefined 3 *** Exception: Prelude.undefined I'm pretty sure that even in the absence of `seq` there are (unobservable) differences with respect to sharing.
Are pi types and refinement types interchangeable terms? Or is there some nuance I'm not seeing here?
Nah, they're different. A refinement type is being able to say "This is an integer, but only between 1 and 20". A dependent type is being able to parameterize types on values.
A refinement type is merely a type that satisfies a value-based predicate. Isn't a exact-sized array precisely that? Take [these](https://github.com/fthomas/refined/blob/master/README.md) refinement types for example. Wouldn't your example just be an instance of the Size[S] refinement on a collection?
It's really hard to rip apart the whole core infrastructure and keep API as it was, especially when you crate uses a lot of open-ended traits. Plus, my whole point is: getting to 1.0 is often a road of trying things, getting feedback and trying something else. It's hard to keep things "stable" and slowly obsolete them when you want to look for new ways, iterate, break things back and forth, and so on.
Thanks, works perfectly, I've gone for the `into_owned()` twice. I do not care about performance in this area but readability. As a newbie it is very surprising that in the case of only having one map I did not need to call `into_owned()` and when I have two, I have to call it twice. I would prefer when there is only one map I would have needed to call it also. 
Yep. That's why I didn't get into the terminology nit picking in the post, I instead papered over it with some sleight of hand with the `make_array` function.
I'd like to mention the "inconsisteny" in structs without any fields. They can be defined as `struct Foo;` or `struct Foo {}`. The first one can be instantiated as `let a = Foo;` while the second one can be used as `let a = Foo {};`. I believe most people find the second form more natural, maybe we could implement a warning or a lint for that.
It would solve the trusting trust problem.
In the post we install clippy via nightly which has its own library set.
\#define |(a,b) ~(~a &amp; ~b) If you don't have a NOT you're kinda fucked, but then computing is weird in that we teach the logic primitives as ~, &amp;, and | as discrete atoms when actually ~&amp; and ~| are not only universal operators but also the atoms we use in hardware, at least while CMOS is still king.
The "type cardinality" shenanigans get even more interesting when you look at [infinite types](http://chris-taylor.github.io/blog/2013/02/11/the-algebra-of-algebraic-data-types-part-ii/).
&gt; Sum type is one of the things you didn't know you need it before, but can't live without after. Meh, a tagged union used to be good enough. Obviously compiler support for it is better.
That's what I was searching for, thanks! Don't know why I couldn't find that.
Ah indeed. I'll refresh them when I have time!
Absolutely!
The vast, vast majority of confusing/confused monad tutorials with silly metaphors etc. are written by people who just had their first epiphany about them, not experienced Haskellers. I joined the community a bit before the explosion, understanding monads for me wasn't a matter of reading tutorials but looking at the type signatures of the type class methods until reaching enlightenment... in retrospective I didn't, but at least my code compiled and adding a return or not wasn't a matter of shotgun programming. Just wait until Rust gets its first *serious* influx of new users, I can almost guarantee there's going to be some topic which is going to invite such a blog deluge. In particular the ownership system should have plenty of opportunities. ...but, yes, Haskellers have a pencheant to completely ignore more traditional programming jargon and instead go for mathematical terms, instead. Generally because they just express the thing better (even if still fuzzily from a mathematician's POV... `Functor` isn't a functor, it's an endofunctor in Hask).
If I remember C++ took around 10 years too: - work started in 1979, - C++ name was adopted in 1983, - first book published in 1985, - second edition of language came around in 1989 (multiple inheritance, still missing templates), - second edition of book published in 1991, - first ISO standard published in 1998, - first revision of standard in 2003, - ... If we check Rust: - work started in 2006, - 1.0 release in 2015, - ... I expect a standard being published around 2024. Or maybe we can just do without a standard; Python has a reference implementation instead and it's not such a bad idea: much easier to test!
You can sure call it for the one-replace case, and the results are different: you get a `Vec&lt;Cow&lt;str&gt;&gt;` or a `Vec&lt;String&gt;`. Depending on how you continue working with it you might not notice the difference (because the `Cow` automatically derefs to a `&amp;str`). Now in the two-replace case, you *can't* not call `to_string` or `into_owned`, because that would mean problems in some cases. Let's start with those that work: * Start with a `&amp;str` --&gt; first replace returns `Cow::Borrowed` referring to it --&gt; second replace returns `Cow::Borrowed` referring to it --&gt; final Vec contains the original `&amp;str` in a `Cow::Borrowed`. * Start with a `&amp;str` --&gt; first replace returns `Cow::Owned` --&gt; second replace returns `Cow::Owned` --&gt; final Vec contains (and owns) the new string in a `Cow::Owned`. But now the problematic one: * Start with a `&amp;str` --&gt; first replace returns `Cow::Owned` --&gt; second replace returns `Cow::Borrowed` --&gt; final Vec contains `Cow::Borrowed` referring to the intermediate string from first replace! The intermediate string has to be alive somewhere. But it's not alive in the initial collection or in the final collection (which only contains a reference to it). You would refer to freed memory, and that's the error that Rust is preventing you from making here.
Yeeah, that's kind of what I want. Right now I have an "environment" which is a HashMap&lt;String, Token&gt;, which the Symbol(String) refers to. But I guess strings aren't the best candidate for "easy-to-copy"?
Tagged unions did the job, but they weren't terribly ergonomic to use.
One of the simplest things you can learn about that explains both HKTs and Pi types is the lambda cube. It's a way of measuring the features of a type system on a lambda calculus.
Thank you for the long explanation, I understand it now. I think my main problem is remembering that it is possible to have a variable with complex stuff that is hold in memory by someone else. It seems that Rust really try hard to avoid copies of data wherever possible (File.read_to_string comes to mind, where it allows you to reuse a buffer instead of allocating and returning the allocated memory) and I still need to get used to this.
C++ just has even more and exciting ways to shoot yourself in the foot than C does. Linus avoids C++ for very good reason. (Not saying that Modern C++ doesn't solve or at least provides many tools to help solve the problems of C/C++ -- but I think it's out of the question to move to C++ at this stage of kernel development, that'd be slightly insane.)
I have been using "labeled generics" for a while in [gluon](https://github.com/gluon-lang/gluon/blob/3a12f66d741ba843e5e85fa8f8d18ef7438284f7/vm/src/api.rs#L1377-L1532) as a way to marshal record types [to and from the virtual machine](https://github.com/Marwes/gluon/blob/29804e1a6f4bd077ce3ecf37b2240decac4e29cd/examples/http.rs#L287-L297). I may need to rewrite that implementation however since it cannot handle field names which collide with keywords (which hadn't been a problem until until just a few days ago https://github.com/rust-lang/rust/pull/39921#issuecomment-283604972). Anyway, I might actually switch to this since I probably need to rewrite my implementation anyway :). Have you got any plans to make it possible to get field names out of a `Labelled` struct? Ideally a `&amp;'static str` but I suspect that is not possible with the tuple representation. I might attempt to add it otherwise since I think that is the only part missing for my purposes.
Pi types and refinement types are both forms of dependent types -- that is, they both let types depend on expressions instead of just depending on other types. Typically systems with a fully-general form of pi types are more expressive than refinement types, because refinement type systems only allow certain kinds of expressions in the types. If you have full dependent types, you can use them to express traditional refinement types, but you can also do many other things with them.
&gt; Would it work on more platforms? Yes, this is something we've heard from many people.
Noone was asking for monad metaphors! ...and, no, all the mechanics still provide for ample of room for bonkers metaphors. You'll see elaborate book lending and owning schemes which distract from the actual algebra of stuff by referring to intuitions about the real world that people have -- and that never match, such intuitions are not a substitute for understanding. That there is a readily-available metaphor doesn't mean that using it suddenly makes things sensible.
This would be really great. I constantly see excuses for why no-one should bother doing user studies of programming languages because its really hard. So let's not do it at all and instead focus on approach #2 that you lay out ("10 weeks thinking about the problem in your head"). That being said, this is really hard. Observing a (necessarily small) sample of heterogeneous programmers dealing with (necessarily small) tasks isn't easy, either. I wonder whether users would consent to having their text editors and compilers instrumented to produce a user study of every single character typed and every single build (failed or successful, especially failed). I would imagine that a language designer could learn a huge amount from seeing all the things their compiler is rejecting from real users...
Compared to actual CT it's seriously toned down. Of course there's people who specialise in transposing things from CT into usable programming stuff and those speak hard CT, but that's not the level the usual Haskell programmer works at. But in the end a lot things just *are* CT in Haskell, and it would do noone a favour to obscure that fact. You certainly don't need to understand CT to understand lenses, but it *does* make sense to not have an panic reaction when you see the word "profunctor" and instead go ahead and look at the types: class Profunctor f where dimap ∷ (c -&gt; a) -&gt; (b -&gt; d) -&gt; f a b -&gt; f c d (note the mixed co/contra variance) Can you seriously think of a better name for that thing, in all its generality, without using the systematic term from CT? This is not a case of calling table salt natrium chloride, this is a case of calling polyethyleneglycol polyethylenglycol.
&gt; of a box [...] that contains a value A monad contains values in about the same way that addition contains a number: Not at all. &gt; i.e. a moral equivalent of and_then Yes! `and_then` is bind, together with a constructor (`return` in Haskell) you have a monad, iff you obey the laws. Which are about basic sanity, let's take `Option`: Left identity: Some( a ).and_then( f ) ≡ f( a ) Right identity: m.and_then( |x| Some( x ) ) ≡ m Associativity: m.and_then( f ).and_then( g ) ≡ m.and_then( |x| f( x ).and_then( g ) ) "Monad" is just a term for that generic algebraic pattern. Nothing more, nothing less. Rust can't (really, at least not the last time I looked, lacking HKTs) express that generic pattern so every type defines its own `and_then`, limiting expressiveness because you can't abstract over it: If you use it in a function, that function will be limited to one particular type, not support all that support `and_then`. 
How can I avoid the borrow issues when writing a piece of code like this: let mut x = Foo::new(); x.set_something(x.get_something(), 12345) I get an error that a mutable borrow starts at x.set_something so I cannot borrow immutably at x.get_something. I've been working around it by doing the get ahead of time but is there a better way? let mut x = Foo::new(); let y = x.get_something(); x.set_something(y, 12345); 
Compile times seem fine to me at the moment, but then again I'm a Scala guy ;) I think your idea sounds interesting, would love to see a working PR. EDIT: oops I just realised that there might have been a misunderstanding. I don't generate an enum for every character because I encode non-English chars in UTF8 as well (see [here](https://beachape.com/blog/2017/03/04/labelledgeneric-in-rust-what-why-how/#how-the-labelledgeneric-derivation-is-generated))
TAPL is the standard text for an introduction to type theory but it doesn't cover concepts like dependent types. It's approachable as long as you understand some of the mathematical notation used in type theory beforehand.
C++ has tagged unions but they don't get used as often as they do in languages with built in support. There's a stark difference due to ergonomics. 
No problem - I understood /u/formode. I'm sure you'll have Rust clients in the next few years. People like me are introducing Rust into our workplaces ;)
Surround inline code with \` (next to the 1 key on my keyboard). The `Rc` will ensure you don't have dangling pointers, or use-after-free (although you can still leak memory if you get into a circular reference). As for boxing in enums and structs, the only time you *need* to is if you need a type to contain itself, eg: struct Node&lt;T&gt; { data: T, next: Node&lt;T&gt; // this will not compile } struct Node&lt;T&gt; { data: T, next: Box&lt;Node&lt;T&gt;&gt; // this is fine } Enums are always as large as their largest variant (plus a little bit to keep track of which variant it is). You don't need to box a variant just because it's bigger that others. If you are counting seconds, then the difference between an `Rc` and `.clone()`ing everything will probably not be important to you ([premature optimization is the root of all evil](https://en.wikiquote.org/wiki/Donald_Knuth)). As for sample lisp code, I don't really know what kind of dialect you are hoping to build, so I can't help you there.
Just for my personal understanding, because I've never had that one specific epiphany moment others seem to talk about when they mention monads: 1. You have some function `f(a: t) -&gt; b: t` 2. You have some type `T&lt;t&gt;` Then the monad is the thing what provides: 1. `g(a: t) -&gt; T&lt;t&gt;` (so I can "pack" arbitrary values of type `t` "into" `T`) 2. The ability to use my function `f()` on `T&lt;t&gt;` instead of `t` (so it becomes `f_m(a_m: T&lt;t&gt;) -&gt; b_m: T&lt;t&gt;`) Is that about correct…?
It can't express the generic pattern, however that doesn't make Option and Result not a monad; it just means that Rust doesn't have a `Monad` trait.
&gt; First of all thank you for your response and all the great work. I really appreciate it. Cargo, crates.io are one of core parts that make Rust ecosystem awesome. I hope I didn't come out too negative - I'm just trying to give feedback and get help. You're welcome! &lt;3 and if anything, you were too hard on yourself and not hard enough on crates.io! We definitely have things that need to get fixed :) Whatever you decide to do, as long as you document it in your README, I think will be fine :)
But the type `{x where x &lt;10, x in Integers}` refers `10` in the definition of that type, and `10` is a value-level thing, right?
Right, but it's always known at compile time, it doesn't depend on a runtime value. Most types can be expressed as sets involving numbers in their definition.
People are scared of math, that's why
&gt; f_m(a_m: T&lt;t&gt;) -&gt; b_m: T&lt;t&gt; Erm... well. Let's start from the beginning. Every monad is a functor, where we have (abusing self syntax): fn fmap( self: T&lt;A&gt;, f: fn( A -&gt; B ) ) -&gt; T&lt;B&gt; Which means "If you can give me a function from A to B, I can apply that over the container (or computation, context, whatever)". Every monad is also an applicative functor, where we have fn ap( self: T&lt;A&gt;, f: T&lt;fn( A -&gt; B)&gt; ) -&gt; T&lt;B&gt; Which means *kind* of the same as above, but as `f` is in `T` the implementor of T now can do all kinds of funky stuff with it. With T = Vec you could e.g. apply a vector of functions to a vector of values, getting out a vector of everything applied to everything. But you can also use them to [parse context-free languages](http://www.cs.uu.nl/research/techreps/repo/CS-2008/2008-044.pdf). You can't do that with `fmap` alone, best way to understand that is probably to try. Finally, monads are about: fn bind( self: T&lt;A&gt;, f: fn( A -&gt; T&lt;B&gt; ) -&gt; T&lt;B&gt; ...with that, you can write parser combinators for context-dependent languages, reason being that you can influence later computations by looking at previous results -- the inner part of that type, `A -&gt; T&lt;B&gt;`, is the essence: It's the only function we have here that actually lets you "get something out" of the `T`. ("Get something out" is a bit misleading because your function has to put it back in, you can only borrow it so to speak. Any particular `T` may or may not provide `T&lt;A&gt; -&gt; A`, that's not part of the algebraic thing that monads are).
&gt; are written by people who just had their first epiphany about them I think the problem is that you often end up getting directed to them, probably because there's a prevailing sentiment that you should understand category theory to understand Haskell (which might be true, but it leaks into "you should understand CT to _use_ Haskell") &gt; In particular the ownership system should have plenty of opportunities. I don't think this would be the case, it's not like there's something "more" behind that curtain. Rust does have some hairy bits involving dispatch, though. &gt; and instead go for mathematical terms, instead I'm even really okay with this (prefer programming jargon but w/e). I'm less okay with the bait-and-switch of "let's use math jargon" followed by "ok now you need to understand math". The entire community doesn't do this, but it's prevalent enough that a lot of my acquaintances learning haskell have stumbled across this too.
Better, but it's still easy to miss because of the low-contrast color scheme for comments in embedded code snippets. For better or for worse, when people are tired, distracted, or merely midly curious, there are three things which they treat as signals to skip or skim something because the amount of effort invested for [what is assumed to be] the same return is much higher: * The text is low-contrast (I hate how often this happens to comments in syntax highlighting color schemes. They're at *least* as important as the code.) * The text is in a very large paragraph (referred to as a "big wall of text" in extreme cases) * The text is too close to a complex equation (sadly, the "eyes glossing over" effect does exist) (eg. And those are non-binary, non-exclusive judgments, so the paragraph following the sigma notation example would count as "likely to be skipped" because it's "sort of long" and immediately following an equation where sigma notation automatically renders it "mildly complex" )
I suspect samth (below) might be a better source of "official" answers on this :)
Not sure what you mean? Constructively you can do negation as `fn(T) -&gt; !`, to use Rust notation, with propositions-as-types meaning the negation of the proposition represented by `T`. But it's challenging to assign any such interpretation to Rust.
I'm writing a bytecode WAM compiler (the WAM is a Prolog VM) entirely in Rust, so I can speak from my experience on that (if you're interested, it's here: [rusty-wam](https://github.com/mthom/rusty-wam)). On the lexing/parsing front, LALRPOP is *amazing*. Combined with cargo and algebraic data types, it is so, so much nicer to install and use than yacc/bison/flex, etc, a definite plus for Rust. The memory model is fine, *once you understand it*. I spent the requisite amount of time fighting the borrow checker and struggling to understand the purposes behind the many heap data types as a beginner. Those two were by far the greatest impediments to my being productive in Rust. I don't know how much time you have, but that learning curve should be considered -- it can be steep. By the sound of it you have some background in Haskell and OCaml, which is a definite help in understanding the type system. But the borrow checker and heap representations may be novel enough that learning them will consume a non-trivial amount of time.
I actually learned boolean algebra in digital technology (something closer to EE than programming), and we definitely did the whole NAND thing. The kind of lecture where you do adders and stuff, dunno what's it called in English.
I more intended that as a caution for future posts that any key details should appear outside such a paragraph. (Either only or in addition) ...basically, aim for some variation on the writing style taught in journalism school, where you summarize first, then elaborate separately so that you get a consistent flow from most to least summarized and the reader is served well by stopping at whatever point their schedule and interest level dictate.
&gt; for a type theoretic explanation of traits That's a rather early and specific paper, the more generic thing is [qualified types](https://www.cs.ox.ac.uk/files/3432/PRG106.pdf).
Yeah, I usually do that, but I'm not very consistent about it :)
I think it's a different proposition between 1.0 and 2.0 (rather than 0.x and 1.0). But you make a good point about Traits etc. where it may not be possible to simply deprecate. To be fair the whole point of 1.0 and 2.0 is that 2.x is no longer backwards compatible (otherwise it could still be called 1.x).
&gt; Meh, a tagged union used to be good enough. Tagged unions haven't been good enough since ALGOL68 added united modes, let alone since ML added first-class sum types support in '73.
Hm, yeah it seems like they may not show up unless you're logged in as me... I'll see what I can do.
That is one way, using dynamic dispatch. The other way, which is not as universally applicable, would be to make the code that *consumes* the bytes a generic function over `Bytes&lt;T&gt; where T: Read`, and call it in the if and else branches.
There's an open PR, that's enough "as we speak" for me ;) &lt;3
I assume that that means that while I can write an impl for UdpSocket, it's impossible for a client to do the same for some third-party socket, unless they're also the original author/crate of the type? (Although I guess you could just write a new struct that wraps the socket and implement the trait on that, right?)
&gt; #define |(a,b) ~(~a &amp; ~b) And here's a mind-blowing bit: you can do the same trick with types! First, we need a type-system equivalent of `~a`. This can be implemented as the type of functions from `a` to an empty type like the one from the [`void`](https://github.com/reem/rust-void) crate, but I'll use the following: type Not&lt;A, R&gt; = fn(A) -&gt; R The negation of a type `A` is the type of functions that take `A` as argument and return an `R` of *any type of the caller's choice* (we assume that the caller gets to instantiate `R`). One key insight to this is that the following trait: pub trait Empty { fn unreachable&lt;R&gt;(self) -&gt; R; } ...can only be safely implemented for *empty types*, i.e., types that have no possible values, like empty enums: enum Void {} impl Empty for Void { fn unreachable&lt;R&gt;(self) -&gt; R { match self {} } } This is safe because, as the name suggests, `unreachable` can never be called, and thus it may safely promise any return type `R` of the caller's choice. My `Not` synonym is a minor variant of this; a type `A` is empty if and only if, for all choices of `R`, `Not&lt;A, R&gt;` is *nonempty*. Now, if we use a tuple struct as our "and", we can translate your `~(~a &amp; ~b)` to this: type Or&lt;A, B, R&gt; = Not&lt;(Not&lt;A, R&gt;, Not&lt;B, R&gt;), R&gt; Which is equivalent to: type Or&lt;A, B, R&gt; = fn((fn(A) -&gt; R, fn(B) -&gt; R)) -&gt; R If you stare at this type a bit you should see that it's kind of like the "type" of a `switch` statement on an enum: let result: R = switch someEnum { case Left(a) =&gt; /* something of type `R` */, case Right(b) =&gt; /* something of type `R` */ } A switch statement on an enum is kind of like a "struct" of cases, each of whose "fields" describes how to handle a particular variant of the enum, all of which must agree on the result type `R`. Another thing that's similar is the OOP Visitor pattern, as seen in this pseudo-Java example: interface Sum&lt;A, B&gt; { &lt;R&gt; R accept(SumVisitor&lt;A, B, R&gt; visitor); } interface SumVisitor&lt;A, B, R&gt; { R onLeft(A a); R onRight(B a); } And a third thing that's closely related is the [disjunction elimination rule](https://en.wikipedia.org/wiki/Disjunction_elimination) in mathematical logic: given `a OR b` as a premise, to prove `r` you must prove `r` with `a` as a premise and prove `r` with `b` as a premise. Basically, there's a *duality* between product and sum types, such that you can define the equivalent of either in terms of other. So if we take the equivalent `a &amp; b = ~(~a | ~b)` and translate it to types, we get something like: enum Or&lt;A, B&gt; { Left(A), Right(B) } type And&lt;A, B, R&gt; = Not&lt;Or&lt;Not&lt;A, R&gt;, Not&lt;B, R&gt;&gt;, R&gt; type And&lt;A, B, R&gt; = fn(Or&lt;fn(A) -&gt; R, fn(B) -&gt; R&gt;) -&gt; R ...which says something like "the product of types `A` and `B` is the caller's choice to read either an `A` or a `B` from the value, producing a result of type `R` of the caller's choice." So to summarize we have this situation: 1. To use an `Or&lt;A, B&gt;` type you must supply a way to handle its `A` case **and** a way to handle its `B` case. So you can encode the case analysis as a struct of handlers, and thus you can encode enums in terms of callbacks that dispatch to such a struct. 2. To use an `And&lt;A, B&gt;` you must supply a way to handle it's `A` member **or** a way to handle its `B` member. So you can encode that choice as an enum of handlers, and thus you can encode structs in terms of callbacks that dispatch on such an enum. I.e., [De Morgan's laws](https://en.wikipedia.org/wiki/De_Morgan's_laws) can be seen as statements about the relationship between algebraic data types and callbacks.
This will likely be fixed by non-lexical borrowing as /u/birkenfeld says, until then use [unborrow](https://crates.io/crates/unborrow).
Goddamn, logic is cool
Yeah, the Pi-types RFC would make this at least somewhat simpler.
With just a quick look, one thing I noticed: When you have an argument that's an `&amp;Vec&lt;T&gt;`, its often better to make it an `&amp;[T]` slice instead. A vec reference will coerce to a slice automatically, and accepting slices makes it possible to pass in _part_ of a vec, if that's ever something you need to do. Similar advice applies to taking `&amp;str` instead of `&amp;String`.
Then Rust will be powerful enough, monad will be a trait. Just like in Haskell, monad is a typeclass. There's no deep meaning in simple algebraic constructions. You have some rules for X, you call any thing X if that thing satisfy these rules. 
This would be really cool as a follow up post. I love the way this works.
/r/playrust 
Disliked.
I think Rust needs some time before getting a standard initiative off the ground. Implementation is partly about proving something can be done. Rust should continue to develop behind rustc for a while. I think it's good that we have a core team that works with the whole community to organically set a standard. Once that has more or less settled we can look at what the standard turned out to be and then codify it.
Boxing the largest variant might save you some memory, but the trade-off is that if you access the boxed element, the pointer indirection will cost you time and cache-misses (although, if you're counting seconds, it's probably not a big deal for you). Putting memory (even a large amount of it) on the stack is very cheap, as all it requires is to increment the stack pointer. If you're using a tutorial type thing, then you should probably use the test cases provided there (testing for speed and correctness all at once!). I used a much more basic dialect, [here](http://www-formal.stanford.edu/jmc/recursive.pdf).
For ironing out language ambiguities, multiple front-ends is more important. But new backends is more interesting in terms of code optimizations and faster compilation.
We need production quality rust frontend for GCC to start talking. Even if Linus loves rust, he can't just drop platform support for Linux. 
You'd be hard-pressed finding Haskell material that even mentions sigma types, reason being that Haskell doesn't have them (though newer type level extensions might allow for some restricted forms -- I haven't really kept up there lately). Then, they're more often called dependent pairs. [At least Idris does](http://docs.idris-lang.org/en/latest/tutorial/typesfuns.html)... and that's a language that comes with a theorem prover!
I see. :) Thanks a lot for all answers. I feel like I understand a bit more. Oh, I'll check that out. I thought Schema was basic, haha. I'm not sure I'll implement it all, I find it enjoyable to add more stuff as I go. haha. :D I guess that's the joy of writing an interpreter.
Is there an attribute that is the opposite to #[cfg(test)]? Meaning I want to compiled *only if it's not a test-run*. I have a HashMap of URLs to a REST API. When running tests, I want my module to use another set of URLs. Is there a simple way to do this? The reason I'm doing this is that I'm using [yup_hyper_mock](https://byron.github.io/yup-hyper-mock/yup_hyper_mock/index.html) to mock the Hyper HTTP Client, but it only accepts a single reply per domain, which is kind of annoying. As such, I'd also appreciate any alternatives to this crate. I'd be a lot easier if I could just specify one reply for example.com/someendpoint, and another for example.com/someotherendpoint, but it seems yup_hyper_mock doesn't support this.
Should be fixed by now.
They have a similar purpose, but their strategy and goals are different. Dependent types start with a disciplined type system that is known to be powerful enough to express most of mathematics, and then try to apply that to real world programs. In doing so they realize a lot of things are very tedious to manually so their goal is to simplify and automate as much as they can. Refinement types start with an unruly type system (e.g. C) and add predicates and constraints ("refinements") on its types such that they could be proven automatically, but these additions are still not powerful enough to encode every kind of property in a program. So their goal is to try increase the expressiveness of refinement types. http://cs.stackexchange.com/questions/21728/dependent-types-vs-refinement-types
There is an interpretation: you can think of `T -&gt; !` as a continuation / nonlocal goto that steals the `T` value and escapes the current context. With that interpretation you find that double-negation elimination = setjmp-longjmp pair!
That looks like the CPS transformed version of a sum type (Scott encoding), which OOPers seem call the "visitor" pattern (`std::visit`).
I had to fight the reverse psychology but successfully disliked it.
 #[cfg(not(test))]
ty appreciate it
"Homotopy Type Theory" is another good one. You can find a free copy [here](https://homotopytypetheory.org/book/).
Ohh, I see. Yeah this works: Prelude&gt; let x = undefined :: () -&gt; a Prelude&gt; let y = \() -&gt; undefined Prelude&gt; :t x x :: () -&gt; a Prelude&gt; :t y y :: () -&gt; a Prelude&gt; seq x 1 *** Exception: Prelude.undefined Prelude&gt; seq y 1 1
The implementation @steveklabnik1 is referring to is my [mrustc](http://github.com/thepowersgang/mrustc) compiler. Its primary goal is to bootstrap rustc, but extending it into a general purpose compiler may not be too hard (famous last words).
Strictly speaking, your interpreter doesn't have to be a WAM. In an expressive language like OCaml (or Rust, for that matter) you can write a prolog interpreter with very few lines of code. At least, I've seen people do as much in Haskell, and OCaml &amp; Rust aren't far off in terms of expressive power. | Your project seems very interesting. Have you considered doing any writeup? Thanks. From the beginning I thought of doing an in-depth write up as a series of blog posts. It informed the structure of the project, in fact. There are branches in the rusty-wam repo corresponding to the progression of languages leading up to Prolog in the WAM tutorial -- L0, L1, and so on. That won't be for a while, if ever, but it helps to know that someone is interested. In any case, OCaml is a fine choice for writing a compiler.
&gt; Google's Go But there is a gcc compiler for Go. It lags, but it works and was pretty much the only choice until 1.6 or so for cross compiling with FFI. I think having multiple compiler backends is good, but it's really only important for smaller community languages like D and less so for languages backed by partner companies like Go and Rust since they have teams dedicated to improving it (which means it won't stagnate).
&gt; It doesn't really reflect the real world Except it sometimes exposes suboptimal code gen, which is awesome. But yes, most of the time it's just a friendly competition.
I wouldn't use Python's lack of a standard as something to measure yourself by. Esp since it conflates the language and the stdlib (batteries). Every other implementation is asymptotic to a release in the past. One of the wonderful qualities of modern languages with a public repository is that an alternative `rustc` can do its own [crater run](https://github.com/brson/taskcluster-crater). 
&gt; C++ just has even more and exciting ways to shoot yourself in the foot And lots of surprising ways as well, unless that falls under "exciting". I try to steer clear of C++ because I know that I'm the sort that plays with things to be clever, and C++ just has too many exciting toys. In Rust, I feel like I can go nuts and trust the compiler to let me know when I've gone too far.
You can use the current compiler for writing kernel modules, so you can get pretty far. I really don't think putting Rust directly into the kernel is a good idea as there is way too much there that isn't "safe", so you'd mostly just write in `unsafe ` blocks and lose most of the benefits until you replace a significant subset of the kernel. I think a better bet is to write a competitor, but keep it compatible with Linux so you can keep compatibility with kernel modules and just replace it wholesale. However, that seems like a bunch of unnecessary work.
I'm continuing work on serialport-rs and gattii, but have recently been focusing on adding features to their supporting libraries to reduce the amount of unique code on my end. For serialport-rs I use the termios-rs library, which is at least partially covered by nix, which provides that and more functionality, so I'm working to make sure nic has all the necessary termios functionality I need. And for gtk-rs it's missing functionality dealing with the `GdkRGBA` data type, so I'm working on PRs for that. This'll let me add a circular progress indicator to gattii for how complete it is in sending a file. 
Done.
Adding some UI automation to my console-game library. Also pulling my hair out trying to figure out how to incorporate shaders. https://github.com/aschuhardt/panda_console
Okay, as it turns out, getting an index in Rust always returns a reference. That is why just removing the `&amp;mut` didn't fix the problem. Fortunately `remove` will return an actual value from the vector. This code works: pub fn lookup_id(&amp;mut self, id: &amp;str) -&gt; Option&lt;&amp;mut Vertex&gt; { let mut vs:Vec&lt;&amp;mut Vertex&gt; = self.verts.iter_mut().filter(|x| x.id == id).collect(); if vs.len() &gt; 0 { Some(vs.remove(0)) } else { None } } Also, here is the even further refined lookup function. Thanks again! I was unaware that the `find()` method existed! pub fn lookup_id(&amp;self, id: &amp;str) -&gt; Option&lt;&amp;Vertex&gt; { self.verts.iter().find(|x| x.id == id) }
I wish I didn't have school this thursday....
That's a nirvana argument. It can obviously be always more perfect. Right now you have to trust mozilla (and mozilla has to trust "the cloud", as the builds don't happen on mozilla controlled hardware) that the compiler isn't backdoored, or go through the very complex process of bootstrapping rustc from the original ocaml compiler, and reviewing the source code at every step. Once mrustc can be used to boostrap rustc, you'll only have to review mrustc and rustc+llvm sources. This is far more easier to do, albeit still hard.
Unlike most people here, nothing too amazing I'm afraid. Working on a Mastermind clone.
Well then. That was simpler than I expected.. Thanks!
Identifying (and hopefully fixing) the remaining issues of the [Rust LLVM 4.0 Upgrade](https://github.com/rust-lang/rust/pull/40123).
I can give some more insight, [this](http://xion.io/post/code/rust-optional-args.html) article also explains it. The trait `From` has been implemented for `T` over `T` for a long time (`impl From&lt;T&gt; for T`). `From` implies `Into`, just like `Copy` implies `Clone`. In 1.12, a feature emerged from nightly where `From` was also implemented for `T` over `Option&lt;T&gt;`, this meant that any `T` can be into()'ed to an `Option`. As such, using `None` or `t` just works.
It's gratifying and encouraging to see folks' enthusiasm for the book. We are doing our best to finish quickly, even if only for our own sakes, and we hope the result will be valuable to you. As fitzgen says, I'm working on the last chapter (on unsafe code), and Jason has begun addressing comments from the technical reviewers. We're not anticipating any major changes at this point^1. Q2 2017 is a reasonable guess. I don't know quite how long O'Reilly's production phase takes, and the book has gotten longer than originally planned (originally 350pp, now around 500pp). If you are especially keen to see it now, you can get it through O'Reilly's Early Release program: you get regularly updated drafts in electronic form, and when it's all done, you get the final book, also in electronic form. http://shop.oreilly.com/product/0636920040385.do ^1 Except /u/brson wanted us to add an entire chapter about ferns. This is a true fact. Brian, we were in favor but our editor is just so mean^2, you understand, right? ^2 That was a joke, our editor has not been mean at all, O'Reilly has been wonderful to work with. But I don't want to hurt Brian's feelings about rejecting his fern chapter suggestion; it's bad enough that we've made him read the entire book as a technical reviewer, and I think the strain just got to him.
From O'Reilly's site: &gt; With Early Release ebooks and video training, you get access to titles while they are being written so you can take advantage of these technologies right now. You'll receive updates when content is added, as well as the completed ebooks and videos when they're done. So you do not get a complete paper book, but you do get the final ebook.
I've done Windows-&gt;ARM Linux. See [this question](http://stackoverflow.com/questions/39705213/cross-compiling-rust-from-windows-to-arm-linux). Basically you need a cross-compiling linker installed, and then you specify it in `.cargo/config`. At the moment I think that is probably a huge pain for Mac and I would recommend just setting up Travis and using the artefacts from there. (Travis is also a pain but at least you get a nice badge from it.) When LLD is used this will be a whole lot easier.
Well spotted, thanks ! Fixed :)
Very nice! I'm the author of the [retry](https://github.com/jimmycuadra/retry) crate, which is a slightly different use case (it retries until a specific condition supplied by the user is met, rather than just `Result::Ok`) but your API is really nice. I wonder if it would be worth joining forces to try to create a single crate with a lot of tools for retrying operations.
These are some resources I've found really useful: * The [Rust Design Patterns](https://github.com/rust-unofficial/patterns/blob/master/README.md) repository is a great resource to learn some of the common idioms of the language. * Using the [Rust Playground](https://play.rust-lang.org/) to write little code experiments can be quicker than looking up documentation if you're trying to understand some of the particulars of the rust language; moreover I find it a much better way to understand and learn. * Finally, [24 Days of Rust](http://zsiciarz.github.io/24daysofrust/) volumes 1 and 2 are a great way of getting a quick overview of some of the more popular crates available for common tasks.
Thanks for fixing! Did you mean to write `DeletedUser` in the second example, or is this supposed to be `JumbledUser`?
Continuing work on an anonymous (inspired by onion routing) E2E encrypted messenger.
I am very aware that there many Russian developers prefer alternative Russian communities to be available. But just out of curiosity I would like to know why you prefer it, expect the language barrier? haven't seen dedicated german or ex-Yugoslavian subreddits for something development related for ages. 
I was literally just about to comment that synchronous retries might be nice too. I think there is a lot of use for simple tools to make it easier to reattempt flaky operations. I know the Python retry library has shown up in a fair number of spots in code I've written..
I'd say that's pretty amazing!
[removed]
Суть в том, что если нашим участникам удобнее комментировать на русском, они могут сделать это у нас.
I'm doing the [7 Day Roguelike Challenge](http://www.roguebasin.com/index.php?title=Seven_Day_Roguelike_Challenge) this week, implementing a turn-based tactical mail-delivery game set in a post-apocalyptic future. The game is called "Apocalypse Post". Links to [github](https://github.com/stevebob/apocalypse-post) and [development blog](https://gridbugs.org/).
Based on [this Hickey talk](https://www.youtube.com/watch?v=oyLBGkS5ICk): don’t break things. If you are unhappy about your current API, make a *new* one with a different name. Add a `yourcrate::v2` and put new things in there. If the major version has sentimental value to you, and you want to be able to experiment and break things without bumping the major version, then define away the problem by putting a big “warning, this stuff is unstable and might change” on the `v2` namespace. Optionally, when you feel that you are ready, release a 2.0 where you delete the original namespace and promote `v2` to be top-level.
Dude. Please. 
This might be slighthy off-topic, but I don't get why the constraint "Box&lt;Any + 'static&gt;" means. In the example a string is used which doesn't (AFAIK) have a 'static lifetime so I am a bit puzzled on what you can or can't use it with?
This chapter from ATTAPL covers dependent types: http://cs.swan.ac.uk/~cspt/DependentTypes.pdf
What's the current status of rust for building web sites/services/app/whatever-the-cool-kids-call-it-nowadays? There seem to be three (among others) competing frameworks for this: Iron, Nickle, and Rocket. Do they have a different focus and/or is one of them deprecated? For background, I use Django for my personal projects, and at work I use .NET (both MVC and WebAPI). Thank you! P.S: My focus would be personal/toy projects, I'm not necessarily asking production 24/7 uptime ready
It looks like language is a large reason for the separate subreddit; this gives a place to post Russian-language Rust articles, without bothering people who don't speak Russian who use the default subreddit. The majority of articles on the front page of that sub have titles in Russian. I feel like many technical communities, even in non-English speaking countries, just use English, since a lot of them are too small to support language-specific communities and English proficiency is high enough since it is a prerequisite for getting good technical education. But I think that there are a few, like the Russian and Chinese communities, which are big enough that there can be localized communities that mostly use that language, and it's possible to gain a reasonable amount of technical proficiency without being fluent in English, so having language-specific communities both helps for people who don't speak English as well and has enough participation that they can gain critical mass.
[removed]
The French (and perhaps other folks) feel so strongly about the erosion of their language that they promote French versions of technical words. What little I've seen of German technical words usually look like Germanization of English words rather than brand-new-German-words. Do you worry about the erosion of the German language/culture as a result of the adoption of English as a lingua franca for software? Do most Germans?
I have been working on the [brain compiler](https://github.com/brain-lang/brain/tree/develop) which compiles code into brainfuck. Writing a compiler is really fun and interesting work! This is an example of the [cat program in brain](https://github.com/brain-lang/brain/blob/develop/examples/cat.brn): // cat program let ch: u8; // stdin.read returns false when EOF is reached while stdin.read(ch) { stdout.write(ch); }
I'm not sure what version of clang is required, but at least Travis CI and one rusqlite user had a clang old enough that they saw missing symbol errors at runtime: * https://travis-ci.org/jgallagher/rusqlite/builds/199825417 * https://github.com/jgallagher/rusqlite/issues/242 I agree if running bindgen at buildtime (a) didn't require users to install other software and (b) didn't take so long, it would be the better solution. What we have in place should be perfectly serviceable though, since updates to SQLite (which follows semver) should not break our prebuilt bindings.
I've heard the same from people in various other countries. I work with several Polish developers, and they all tell me that they find it weird to try to use Polish terms for technical topics, and much prefer to work in English. But I think that it does vary by country/language, and there are a few countries where there are a lot more people who do cover technical topics in their native language rather than English.
I'm moderately excited about the ecosystem fragmentation and subsequent cross-pollinating that this is going to bring.
&gt; What little I've seen of German technical words usually look like Germanization of English words rather than brand-new-German-words. English words sound "cooler", and sometimes even more sophisticated to many Germans. A bit like you use latin or greek words in English. Or sometimes, people just don't know the German words because the English ones are more prominent. It goes so far that people say "updaten" (germanized version of 'to update') instead of "aktualisieren". I'm sure there are a lot of very nice German technical words that people have just forgotten about. &gt; Do you worry about the erosion of the German language/culture as a result of the adoption of English as a lingua franca for software? I personally don't worry about that, as I see "the German language/culture" as something that is constantly in flux anyway and it seems silly to stand in the way of inevitable change. What each of us can do, of course, is try to take the best of everything. I probably enjoy the "German" versions of döner and pizza more than the original ones. :D
Aside from all the language stuff: Very cool theme! Edit: Is there a Russian Rust logo? Maybe with a "Р" (from Ржа́вчинные) instead of an "R"?
[removed]
I'm working on a standalone typechecker for Lean. It's a pretty small kernel for the calculus of inductive constructions. I plan on adding a compiler using Cretonne.
After watching @withoutboats excellent presentation on Coherence, I immediately had the `type`alias syntax pop into my head as a possible syntax for declaring type scoped orphan rules. I was wondering if this idea has been already thought of and if this could be a viable RFC Concept. 
Compatibility layer should be possible at least in user space. Maybe someone clever will find a way to make compatibility layer for drivers too.
&gt; haven't seen dedicated german or ex-Yugoslavian subreddits for something development related for ages. Generally this depends on the language, Chinese, Portuguese (mostly from Brazil), Russian, and somewhat Japanese programmers tend to have robust language communities, whereas German and many other language-speakers tend to use English. A lot of this depends on the availability of resources in that language, and the fraction of speakers who speak English anyway. Once such a language-community exists, it's going to end up with a lot of great programmers who never had to speak English, so language communities tend to only grow after a critical mass. It's great that language barriers to programming get lowered like this. I love how inclusive the Rust community is, but ultimately it's not great for non-speakers of English, which isn't something we can help much. (well, we can, but this requires a shift in how we deal with the internet in general. I have complex Thoughts about this, which I don't really want to get into here)
&gt; Do most Germans? This is not just limited to the technology sector. A few years ago the German minister of the exterior refused to follow the request of an english speaking reporter to answer in english, saying "in germany you speak german". Throughout politics, this had been a source of criticism. I think this has historic origins. 70 years ago, the nazis cared quite a lot about not just their language/culture but about further things like this made up thing called "race". They even started rejecting things like Christianisation. They started a war, and lost. After the war German culture changed in many regards. If you just compare Germany with the US, you'll have US flags in every second restaurant, and ahead of every sports event the anthem is sung. In Germany, anthems are sung very rarely, and the German flag can be found very rarely as well.
I'm not an expert on kernels, but I think that would be quite difficult since drivers use some internal state I think.
Time for r/learnrust ?
&gt; Travis is also a pain but at least you get a nice badge from it. That depends. Once I feel I understand `error-chain` enough to use one of the projects built on [my CLI utility boilerplate](https://github.com/ssokolow/rust-cli-boilerplate) for testing (without potentially embarassing code being in the git `HEAD`), I plan to come up with a `.travis.yml` which works if simply copy-pasted into all such projects.
Some examples might be informative. "Not possible" is a strong protest.
&gt; Good thing we have crates.io for the missing batteries :) I just realized I forgot to address this. There are two main problems with it: 1. I'm a KDE user and I'm not willing to let GTK+ 3.x and 4.x take me back to the days before `QGtkStyle` guaranteed a comfy, unified desktop look and feel, regardless of whether you like the art direction GNOME is going. (I still remember the bad old days) 2. Sure, `crates.io` *can* provide the missing batteries, but they tend to be papercut things that, even with PyPI, people tend to reinvent or post in hard-to-find places. I'm doubtful it'll happen quickly while Qt already has: * Toolbar and panel support with all the trappings baked in (Reposition/resize/tear-off/hide/show/etc. with "set some flags in Qt Designer and you're done" support for constraints like "this panel with inherently tall-and-narrow content can dock left or right but not top or bottom") * Every Qt toolbar and panel header automatically gets a default context menu containing a checkbox list of toolbars and panels. * Support for serializing/restoring the window geometry and toolbar+panel state for a window with one method call each on the window. * "Write your own MVC model" docs that are more comprehensive than GTK+'s and with code examples where readability isn't crippled by reinventing classes and classical inheritance in C. * Various other functionality. (I don't feel like making an exhaustive list) The main thing I actually *do* expect to show up in `crates.io` without too much delay is an extension to the `preferences` crate which replicates [QSettings](https://doc.qt.io/qt-5/qsettings.html)'s "just do what I intuitively expect" behaviour with regards to deferred commit. (It basically sets a timeout when you set a value and then commits to disk when either the timeout has passed or the "event loop is shutting down" signal fires.)
switch/goto is just a way to eliminate function call overhead, so I expect that you could achieve a similar effect with inline_always.
Also note that alternative Pythons (Pypy, Jython, etc.) have subtle incompatibilities and behavior differences. At least the Python docs tell you when something is likely to be CPython specific.
One pattern that you are missing is higher-order functional programming, whereby you may pass a function or closure as an input argument to define what to do with your return type, without needing to return that type. fn attempt(connection: Connection) { // do something } connect_and_attempt(path, attempt); connect_and_attempt(path, |connection| { // do something });
I suspect the author was talking about [Duff's device](https://en.wikipedia.org/wiki/Duff%27s_device) (~~obsoleted by good optimizing compilers~~... but you still need to ensure the compiler is as smart about `match` in Rust as it is about `switch` in C/C++) and jump tables. (~~I couldn't find it again~~ [[1]](http://eli.thegreenplace.net/2012/07/12/computed-goto-for-efficient-dispatch-tables), but there was a great blog post on this topic which showed how a hand-coded jump-table still beat the pants off compiler optimizations for things like `switch` statements when writing an emulator in C++.)
I see - if this overwrites the alias syntax, that opens a can of worms in itself. Playing around more with the concept shows some intriguing patterns: https://gist.github.com/Latrasis/d6710a13000cb18e5efb2da2fdfa6536 As much as I find it interesting however, I can see how it would overlap with existing concepts.
Finalising the first beta release of NWG ( https://github.com/gabdube/native-windows-gui/tree/v2 ) . There's alot of documentation to do.
In that case, we just need an Esperanto board and by which English, Russian, Chinese, Japanese, etc. speakers can all communicate together without barriers.
That paper doesn't say you can, but other papers do say you can: https://www.dwheeler.com/trusting-trust/
&gt; now that it's the default I think you should consider using that instead. It's not just the default, the makefiles are totally gone on master now.
Sometimes the main implementation can stagnate not due to lack of interest but due to dysfunction in the dev team. Definitely not saying this is happening or likely to happen, but it has happened to other projects.
As the connection is owned by the pool and connection pools really only make sense if there's a single pool being used for most (if not all) connections, I'd say passing in &amp;pool instead of &amp;connection would make sense. 
I don't know anything about Russian language education, but as for the Japanese, the reason why people don't speak English despite studying it quite a lot is because the whole education system is based on highly standardised testing. These kinds of tests often measure explicit knowledge about language despite language acquisition research saying that explicit knowledge correlates poorly with the ability to communicate using that language. This, together with the fact that in Japanese society the test scores have quite of an impact on the futures of the kids, leads people to optimising for wrong things. ("Wrong" as in: not for actual performance but "measured performance", which includes a significant bias here.) However, this is just a part of a feedback loop: people not knowing English creates a naturally a larger market for things in Japanese, which in turn decreases the people's dependence on English. This is totally different in smaller countries, where people readily consume English goods because the market isn't just as large. I think it's good to have a variety of communities in all kinds of languages.
Thanks for sharing, I always love hearing about microcontroller development in rust. An open source bluetooth stack in rust is extremely exciting!
I would call this continuation-passing style, not higher-order functional programming. I mean, it is clearly a higher-order function since it takes a callable as a parameter, but I would call the _programming pattern_ CPS.
I am still working on DTLS support for rustls - a bigger project than I thought. But it's fun, thanks to the guys in the IRC channel!
Looks very useful! It'd be nice to have support for using the built-in tokio-core timers rather than tokio_timer.
It's not a tool, it's just a project template that happens to use `just` (a pure-Rust analogue to Make) to automate a bunch of common tasks. My intent is to work toward a `.travis.yml` which Just Works™ with the broadest swath of Rust projects possible and then assemble an associated quick reference to reduce the time spent on things like "Does this project require GCC 4.9 or can we save time by omitting `sudo: required`?". (Given that I've already had good experiences using it to mimic VPSes I intend to deploy to, I plan to speed up the process as much as possible by using [Vagrant](https://www.vagrantup.com/) to manage VMs approximating the various environments Travis presents.) That said, I really think there should be some kind of collaborative effort to document these sorts of gotchas... I just don't have the social expertise and time necessary to found such an effort.
Awesome! Can you flesh this out a little more for me? I'd love to include this in the article if you don't mind.
That's "effectively countered," which is different than "solved." DDC makes this (very very) harder, not impossible.
I guess that falls under "fork" in my mind.
https://www.reddit.com/message/compose?to=%2Fr%2Frust (linked from the sidebar) will let you message all of the mods directly, at once.
 &gt;For struct types or dynamic growable types like Vec, String, and HashMap, it probably makes a lot of sense to box these values. It generally doesn't make a lot of sense to box Vec, String or HashMap as these types are mostly wrappers around boxes themselves and their structs only use of few words worth of memory. 
The reason I've tried with configure was because the gentoo ebuild for rust uses it. I will try to ask the creators of the ebuild why they use it instead of x.py since my main goal is to add the targets to that ebuild. Thanks! Edit: Do you have the steps necessary to patch configure so yout mytarget.mk change would work?
(withoutboats here) To make this compatible with the present semantics we would need to introduce some pretty complicated special casing, because type aliases and the nominal type they alias are completely interchangeable today. [Consider this example](https://is.gd/Gx5Awp), where the orphan rules don't apply. It seems we'd basically have to treat the alias and the nominal type as different only in the context of orphan impls. This essentially becomes a form of named impls. This is the most ergonomic I've ever seen named impls be, but I'm not sure its worth it. (also not sure it's *not*, though)
See also [`man 7 unix`](http://man7.org/linux/man-pages/man7/unix.7.html). Note that connecting to abstract sockets seems unsupported from the safe rust api, you need to use something like [`socket` from nix](https://docs.rs/nix/0.8.0/nix/sys/socket/fn.socket.html)
For anyone missing the joke, undocumented feature is another word for bug. So hopefully at some point in the future this will return a compiler error. So it's not something you would ever use for real code, but right now it's ripe for underhanded rust contests as the parent mentioned.
The main tradeoff is that you're relying on the compiler to optimize your code properly, whereas with goto, you "force" the inlining. Apart from that, there's Rust specific syntax stuff like function signatures requiring explicit types, whereas within a single function you can use type inference and anonymous types.
It would greatly enable Python as a platform if the interaction between the base system and the batteries was specified. Lots of platform specific idioysyncracies leak into the stdlib making the stdlib itself hard to port not only to different OSes, but also to different Pythons (PyPy, Jython, etc.) I have a dream, and it stays a dream where the batteries are broken out of the VM and tested against other implementations, that the battery&lt;-&gt;VM contract is codified. Standardization by implementation is pretty lousy.
That's great feedback, cheers! I was actually unaware there was such as thing as timers in `tokio-core`, having not worked with the low-level bits of tokio before. This way, it seems I could even get rid of the `tokio-timer` dependency completely. Are there any downsides you know of with using the core timers over `tokio-timer`?
They're useful for different cases. tokio-core uses a min heap, which performs well for small numbers of timers and is somewhat precise, while tokio-timer has uses a hashed timer wheel, which provides low precision but scales well to massive numbers. As an implementation detail, tokio-timer is driven by a dedicated internal thread. I expect most people don't need tokio-timer, but it does have a reason to exist.
If owned values that are returned are copied why don't they need to implement Copy? Want to follow here I thought that was efficient. 
It tricks the borrow checker into thinking the returned reference lasts for longer then it does. Using the reference returned by `connect` would be undefined behaviour...
You generally don't need to `Box` *any* return types unless you're trying to do type erasure with trait objects. It's considered idiomatic to leave the choice--whether or not to box--up to the caller. For large values, the compiler optimizes away copies pretty well. For example, the following: fn init_array() -&gt; [u32; 256] { [!0; 256] } let array = init_array(); Will be optimized to something like this: fn init_array(array: &amp;mut [u32; 256]) { *array = [!0; 256]; } let mut array = unsafe { mem::uninitialized() }; init_array(&amp;mut array); This is done by many compilers for many languages, [most notably C++](https://en.wikipedia.org/wiki/Return_value_optimization) and is actually defined in [the C calling convention](https://en.wikipedia.org/wiki/X86_calling_conventions#cdecl).
I've only just read some of Rust book, so maybe I'm just misunderstanding how crates work. Here's their demo number guessing game: extern crate rand; use std::io; use std::cmp::Ordering; use rand::Rng; fn main() { println!("Guess the number!"); let secret_number = rand::thread_rng().gen_range(1, 101); println!("The secret number is: {}", secret_number); println!("Please input your guess."); let mut guess = String::new(); io::stdin().read_line(&amp;mut guess) .expect("failed to read line"); println!("You guessed: {}", guess); match guess.cmp(&amp;secret_number) { Ordering::Less =&gt; println!("Too small!"), Ordering::Greater =&gt; println!("Too big!"), Ordering::Equal =&gt; println!("You win!"), } } In that, what is `use rand::Rng` introducing? I would expect in a Python-like language that it introduces the namespace `Rng` that I can call in some way, but it looks like it's adding in some traits instead? It's very confusing compared to Python, ES6, Go, whatever because you can't just look at the name of a thing and tell which of the imports is responsible for it or vice versa. Edit: I looked at the docs, and it appears it's responsible for `.gen_range` working. But wouldn't it be more clear as as `.Rng::gen_range` or something (fudging the syntax a bit)? How is anyone supposed to guess what names come from where? Python doesn't have traits, so there's no clear equivalent, but you'd probably do something like `Rng::gen_range(rand::thread_rng(), 1, 101)` instead of adding methods to something else.
Moves are very different in my understanding of C++. Move is semantically always a memcpy in Rust, though it may be eluded by the optimizer.
There are basically three primitive ways to get a socket handle from one process to another on Linux, that I know of. * Pass by `fork()`: The IPC handle (whether an anonymous socket or a pipe) is created before forking, so child process just uses the inherited file descriptor. It's great because you don't need to create a filesystem entry, but it's terrible because `fork()` is terrible for multithreaded programs. This is how bash pipes work; it's very much the old-school UNIX way. * Pass by CLI: When starting the worker process, pass the path to the socket as a command-line argument. This is how Chrome and Servo get their socket paths to their child processes, because of fork's problems with both threading and Windows. * Pass by filename: Just put the socket at a well-known path. This is how systemd's control socket is done. This last one only really works for unique daemons (like systemd). 
Yes, the way it works is that once you `use` a trait you can call its methods on types that implement it. The explicit syntax you wrote where you specify the full path to the trait also works.
Usually, Rust does return value optimization, which is even better than moving the value out. With RVO, it constructs the returned value directly in the calling function's stack frame, which saves it the 24 bytes of copying it needs to move a `Vec`.
The meetup is at 7PM, if that helps at all!
No, Vec/HashMap/String are already 'boxed' because those values are heap allocated to begin with. If you're boxing a vec then you've got a heap pointer to a heap pointer.
I disagree that pattern 1 should be avoided, it should be used a lot actually, since complex types tends to wrap heap allocated structures already (e.g. collections). If you're trying to eliminate allocated data structures, that's another story obviously.
There's some confusion here between the (pointer, length, capacity) triple and the contents of the vector itself, I think.
And as others mentioned, even stack allocated structures can benefit from this pattern due to effective compiler optimizations. Goes without saying that everyone should profile when thinking about performance.
&lt;small&gt;24 bytes on a 64-bit system, 12 on a 32-bit one.&lt;/small&gt;
There's a distinction between semantically what's happening and what the optimizer will do with it. Semantically, it's being copied. Practically, the optimizer will write it in the parent's stack frame.
awesome!
Yeah but that's an optimization thing. The solution is generally more nuanced than "box everything". 
I built that crate most of two years ago, obviously long before futures/tokio existed. It was really just to scratch my own itch for a specific use case. The abstractions in your crate are much nicer. How would you want to merge the two? "retry" is obviously the nicer crate name" but I'd feel bad just stealing all your work by moving it into my repository. Maybe I'll sketch out an API for doing both sync and async retries using your trait abstractions, and cc you on a PR.
You just need to use the same name in `with_name` as you do in `value_of`. Otherwise clap won't know which argument is which. Also, you need to use `values_of` for the arbitrary number of arguments. Here's a [working version](https://is.gd/dBoMys) 
I'm trying to compile my piston game to the web. 
Fair enough. In this case though, I feel as though this line &gt; for any nontrivial type, we’ll almost certainly be wasting memory by making identical copies of some piece of data makes it sound like this is a practical downside to returning owned types, instead of a semantic one.
[removed]
Yep! [Here it is](https://is.gd/oOxwNG). That said, I think you'd be better off with something like [this](https://is.gd/92EOny) as it will generalize better to other non-infix functions. A good starting point for macros (after The Book) is [The Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/README.html), specifically the `macro_rules!` section.
Totally! It's a bit of a contrived example. I mean, would the connection really work if the pool went away? Unclear... I just wanted something close enough to reality that I could work with returning references without writing a whole application.
I'm part of a racing league, so we have multiple servers with basically the same config for each one, but with different port numbers and such. It'll also generate the grip settings and weather. Basically, the idea is that it'll have a template loaded, and then just replace bits of it with the generated parts. The track, series, and server data used is being stored in JSON, which I'm parsing using Serde. So basically the UI will be selecting the track, series, number of drivers, average laptime, and which servers will be in use, which is where Pancurses comes in. So far I have [this](http://i.imgur.com/ezTXV5m.png), which I can scroll up and down with. The list of items can be arbitrarily long, though there's no scrollbar support yet. Of course, if I were smart I would have done this in C#, which I'm familiar with, and had it done in an evening with a fancy GUI. But this is more fun.
Happen to have a resource where I can learn more about (rust's use of) LLD?
This. Is. Rustup. The rustup executable sits as a shim between you and cargo/rustc/rustdoc/.. and routes your call to the selected toolchain.
Wanted something distinctly associated with Rust.
You may want to read an old [blog post I wrote](https://llogiq.github.io/2015/08/19/closure.html) about this.
'moving' is still a copy, it just has to also make sure that the value you moved from is no longer valid.
Oh wow, thanks. I don't think you could've written a better reply. Thanks for the examples and the link, I'll check it out!
There's a setting called `TrailingVarArg` which is probably what you want, take a look at http://kbknapp.github.io/clap-rs/clap/enum.AppSettings.html. I haven't found a way to make it take require at least one argument though.
&gt; [u32; 256] Note that `[[u64; 512]; 512]` is enough to overflow the stack on debug builds, so that will give you a segfault there, but will work fine in release due to the optimization you mention.
Redundant copy or not, a 2MB array will overflow the stack on pretty much any OS. Linux and Windows both use a default stack size of 1 MB, and while the main thread in a process on OS X will start with an 8 MB stack (though it's unclear how much of that gets eaten up by things the programmer has no control over), child threads spawned by Pthreads (the API that `std` abstracts over) will have a stack size of only 512 KB. However in release mode this might still work, if you initialize but never modify such an array or if you modify it in a way that the compiler can const-eval, then the array data will end up stored directly in the binary like it was placed in a `static`, and thus never touch the stack.
For tooling, we feel we need Rust to write great software without runtime hassle. 'If it compiles, it's probably already better than most things you could have written in X' is something that feels very true to me. On top one will always assure logical correctness with tests on appropriate levels, which is always needed, but it's not necessary to cover every case anymore. 
I don't get why this is downvoted. It's a simple question; ill-informed but nothing unconstructive.
I was evaluating Hugo for my own site. Can you elaborate on your issues with it?
As part of a 'learning Rust' project, I'm writing a library for creating/editing simple images, and I have a couple API questions on this function: /// Sets the given pixels to the given indexed color fn set_pixels(&amp;mut self, pixels: &amp;[Point], color_index: usize) -&gt; bool { ... } 1. Is there a better/more idiomatic way than the `&amp;[Point]` slice I'm currently using to pass in which pixels to affect? 2. Is there a better way to return success/failure than a `bool`? I was thinking about using a `Result&lt;()&gt;` or something, so it can be used with `try!`, but as the function is just returning status and not any actual data, I'm not sure that would really fit.
Sorry, what I meant was not to "just" put the array on the stack, but rather to just indirectly put it on the heap. Consider the two following cases: // Example 1: // Crate A: pub fn foo(x: u64) -&gt; [[u64; 1024]; 1024] { [[x*x*x; 1024]; 1024] } // Crate B: extern crate crateA; fn main() { let m = Box::new(crateA::foo(314)); println!("{}\n", m[500][500]); } and // Example 2: fn main() { let m = Box::new([[u64; 1024]; 1024]); } Example 2 overflows in debug builds but not in release builds because the optimizer avoids the stack allocation. LLVM is able to do this in release because it can see the code. Example 1 overflows in all possible combinations of release/debug, which includes when both crates are compiled in release, _unless_ one annotates `foo` with `#[inline]`. My point being, when dealing with fixed-size arrays, one needs to be careful not to put very large ones on the stack (not even as temporaries) because that might crash your program even on release unless the right combination of optimizations trigger. This is brittle. And it can easily happen if one mixes up the trade-offs of two rust features: modules and crates: - Modules are a zero-cost code reuse feature, that actually has real zero cost (the generated assembly of code that uses modules equals that of code that does the same without modules). - Crates are rust feature for separate compilation and code distribution (there is no "modules.io" website). For separate compilation, crates are a zero-cost abstraction, but they are not zero-cost. In fact, crates actually introduce a _huge_ cost, since their boundary is an inlining barrier (and hence an optimization barrier). In particular, those who argue against `#[inline]` annotations because "the compiler knows better" completely miss the point. Inlining as an optimization itself is very boring. The real value of inlining is what it unlocks, which is basically all optimizations that LLVM can actually do. Without inlining, LLVM cannot see the code. And not only LLVM cannot optimize code that it cannot see, but it actually must assume the _worst_ about that code. 
Nice! I like the name :) I think it's worth mentioning (in the README, etc.) that CountdownEvent is known as CountDownLatch in Java. I only knew the Java name.
&gt; I suspect the author was talking about Duff's device (obsoleted by good optimizing compilers... but you still need to ensure the compiler is as smart about match in Rust as it is about switch in C/C++) and jump tables. [In 2015, re-implementing the `std::find` algorithm to use Duff's device delivered a 2x performance improvement in LLVM's libc++](https://bugs.llvm.org//show_bug.cgi?id=19708), and put it on par with GCC's libstdc++, which also uses Duff's device... So... neither LLVM and GCC are particularly good at optimizing Duff's device-like code, nor is it a micro-optimization that only applies to obsolete hardware (I mean, 2x faster `std::find` in 2015!). FWIW, there are actually a couple of C++ STL algorithms in which `goto` is used across different implementations for performance reasons. If anybody wants to write a `goto`-RFC using the performance argument as motivation, it might be worth it to scrap those implementations, rewrite them in Rust, and show whether the Rust implementation is inherently slower due to the lack of goto. 
Does xi have a good graphical environment? I'm huge fan of things like Sublime and Atom, but xi is mostly text based, no?
Semantically, it's moved (which usually involves a bit-by-bit copy). However since there's not really a place where you can put a large value on assembler-level, a large return type is converted to an implicit first argument which is the pointer where the function will write its result to.
No, this does depend on the function being inlined. Large return values cannot live anywhere else than the parent's stack (e.g. on x86_64, %rax gets the return value, but it can only fit 8 bytes), so functions with large return values always have an implicit first pointer argument that specifies where the function should put its return value.
IIRC rust's calling convention will guarantee this RVO occurs.
The ABI currently does, but the ABI is not defined, technically, so yes and no.
This is completely different from inlining, in my understanding.
The configure script writes out a _very_ small makefile that invokes rustbuild with the proper options. IIRC, we're going to keep it there to make it easier for people not familiar with rustbuild.
1. Source code: https://github.com/rust-lang/rust/blob/master/src/libsyntax/feature_gate.rs#L112 2. Online list: https://bot.tinaun.net/rust/featurelist/ Also I saw it somewhere inside Rust docs, but can't recall where. However, second list is more useful than just plain list of features. 
This just mean that the value will be put in the stack, but on the parent stack frame, you might be wanting to heap allocate the result, in which case you need to avoid the intermediate stack allocation (which can overflow the stack). /u/eibwen__ /u/steveklabnik1 I made a comment above where I show an example of this happening: https://www.reddit.com/r/rust/comments/5xuq1l/strategies_for_returning_references_in_rust/dem3q11/
Back when this was probably done, it was true, but now it is more true. CPUs now-a-days rarely are waiting on their instructions. Almost all time CPUs spend is waiting on memory access. There is a reason almost all of the CPU transistor budget for modern CPUs has been going to increasing the cache sizes.
Nice pointers! Thank you
https://doc.rust-lang.org/nightly/unstable-book/ Which is only in nightly for now, is a guide to literal feature flags.
&gt; if I make technical mistakes please let me know and I will try to correct them. Looks good to me! Great post.
That's good to hear. Thanks!
We'll add graphical elements such as icons in gutters, but for the moment it's pretty much text.
Yeah, I later realized that inlining isn't quite the same. What you really need is something more like tail call elimination where you reuse the stack frame.
Because many people are lazy (i.e. not willing to write a reply), and egotistical (i.e., "this person, and indeed *everyone*, needs some indication that I know they are wrong"). So, rather than reading existing replies to make sure the misconceptions were corrected, writing a reply to correct the misunderstanding, or perhaps just moving on, they click the down arrow. Hard. Maybe three times, for emphasis. FWIW, I up-voated it so it wasn't negative (at the time of this writing), since others are likely to have the same misunderstanding, and could benefit from the thread.
If you ever find that blog post, please share!
No, because for example, the Cat vtable for Mammal is the same for every Cat, it will be statically initialized. The vtable pointer just points to some read only segment of the binary, so there is no heap allocation.
I found [this macro](https://gist.github.com/wtfaremyinitials/8dd412b39aebdac5e6692f6c90482f7e) on Twitter a few months ago and does pretty much exactly what you're looking for.
Since you asked, I did a little more playing around with search keywords and managed to track down a likely candidate for what I was vaguely remembering. [Computed goto for efficient dispatch tables](http://eli.thegreenplace.net/2012/07/12/computed-goto-for-efficient-dispatch-tables) by Eli Bendersky (July 12th, 2012) (It's been a couple of years and I never really did anything beyond a cursory reading for curiosity in the first place, but the site theme looks right and, aside from being about "dispatch tables" rather than "jump tables", VMs rather than emulation, and relying on assembly dumps rather than benchmark graphs to justify its observed performance differences, it matches my memory.)
Sweet. I probably read it when it was first posted (been following his blog forever), but don't remember it, so I'm looking forward to the read. Thanks for taking the time!
&gt; Does this mean that when I pass a stack-allocated reference to a function taking some trait, rust allocates a temporary object holding the vtable pointer? Kinda. The vtable pointer is part of the reference itself, a trait objects reference is actually double-wide (one pointer to the object and one pointer to the vtable), same for owned pointers: https://is.gd/NVqjBk If you original reference is to a struct, Rust will implicitly convert it to a trait object reference before passing it in: https://is.gd/CsoUpe
That is a really good point. I hadn't thought of it that way.
Huh. I wouldn't have expected it to be possible to have a method and a property with the same name (except if namespaced in a trait).
In addition, you can also call the `a` method by doing `Foo::a(&amp;f)`.
JSON serialization and deserialization is typically handled by `serde_json`. You shouldn't have to provide your own string\_to\_action and action\_to\_string conversions. Here is what it looks like: #[macro_use] extern crate serde_derive; extern crate serde; extern crate serde_json; #[derive(Serialize, Deserialize, Debug)] struct Message { action: Action, } #[derive(Serialize, Deserialize, Debug)] enum Action { #[serde(rename = "do_qqq")] Qqq, #[serde(rename = "do_rrr")] Rrr, } fn main() { let msg = Message { action: Action::Qqq }; println!("{}", serde_json::to_string(&amp;msg).unwrap()); let j = "{\"action\":\"do_rrr\"}"; println!("{:?}", serde_json::from_str::&lt;Message&gt;(j).unwrap()); }
My reaction exactly! :D
thanks! this makes sense, though coming from c++ it's different from what I expected. 
I've barely even looked at F#, so my understanding may be off here. This looks like a channel with a user-supplied message loop? Seems simple enough to wrap, except for one wrinkle: This uses `async`. If I were to port this faithfully, I'd want to use futures's channels instead of std's, and make everything futures-based. If I were to use std's channels, I'd also want to pop a thread for the message loop or make .start() block the current thread for the message loop, like tokio does. I'd like to keep synchronoise from adding any dependencies other than std, but I guess it wouldn't be a big deal to make it a crate feature to add futures-based stuff. Also the Scan method could be problematic to add if I want to use existing channels, since neither std's nor futures's channel allow you to peek through the channel and keep everything in order. I'd have to allocate a separate buffer to hold the messages so further reads get the rest of the messages in order.
If I understand correctly, you can do this directly with serde. Something like this: http://play.integer32.com/?gist=09c376d20b573997c8a9634fd0c737a9&amp;version=stable
I see. so /u/alschwalm 's diagram isn't quite correct when comparing to c++. It seems to imply that the following c++ layout: * or &amp; -&gt; [vtable*, data member 1, data member 2] corresponds to the following in Rust: * or &amp; -&gt; [data*, vtable*] i.e., it has in his words 'an additional layer of indirection' when actually, Rust does: [data*/&amp;, vtable*] i.e. fat pointers. What he calls Trait Object doesn't really exist then, there is no object for the trait itself, there's an pointer to the underlying type and a pointer to the vtable, which are stored next to each other. A trait reference isn't a normal reference to a trait object at all, but just two pointers stored next two each other instead of 1 pointer
`bench_nested_loops` iterates over `1..TEAMS` instead of `0..TEAMS`. Is that a typo? (Changing it doesn't impact the speed measurably on my computer, though.) *UPDATE:* Oh, I see the 0 doesn't matter to the results here because `0..0` is an empty range. Changing the flat_map version to map over `1..TEAMS` speeds it up very slightly. On my 4-core desktop using the latest Rust 1.17 nightly, the flat_map version is "only" 3.5x slower than the nested loop version. If I increase `TEAMS` to 30, it's only 9% slower, which probably means the loop version is no longer unrolled. (I haven't inspected the assembly.)
Agreed :)
Hum... reminds me of webassembly?
You can think of it as that Rust has fat pointers, slices are also 2-wide value types, [here are some examples](https://is.gd/89BD6x). 
does anyone really find the loop version harder to understand? I like functional programming like the next guy but this is just needless abstraction.
Why? (Please explain what are you trying to achieve in the first place, so we can think about the actual use case as well)
The `build.rs` script is automatically run by cargo as part of the build process. That build script outputs a file containing the various definitions, which the lib.rs then reexports.
This makes me wonder: if a trait object is a pair of pointers, then why are trait objects not `Sized`?
A trait object **reference** is a pair of pointers. The underlying trait object is just an object of an unknown type. It's the same with slices, except that the extra information passed around is the vtable pointer, rather than the length. Basically, &amp;[T] and &amp;Foo are both fat pointers, while [T] and Foo are objects of unknown size.
You may find this tutorial I wrote helpful: http://fitzgeraldnick.com/2016/12/14/using-libbindgen-in-build-rs.html
I strongly dislike crates that run bindgen at build time because it means anyone who wants to use that crate needs to have libclang or build libclang which is frankly ridiculous. It's vastly better to just generate the bindings once and then check them in as source files, so users of your crate don't have massive build dependencies.
I find it useful for writing getter functions if you need to expose a field in a trait.
I've wondered about it myself. I think that phrase works better when you compare Rust iterators with the ones in e.g. Java or C#. The Rust ones usually don't allocate or involve dynamic dispatch, but due to various reasons like LLVM not figuring stuff out the generated code is worse than when using loops. On the other hand, iterators are sometimes faster and I find it hard to say which will work better without running the code or looking at the assembly.
How can I differentiate a bare character from its escaped version? '"' and '\"' are seen as equal and I'd like to tell them apart.
The problem is that a lot of C libraries have platform-specific `#ifdef`s all throughout, so you can't use the Mac `bindgen-ed` version on Windows, or whatever.
Cool; thanks for explaining! My question is partly motivated by some frustration I was just having trying to create a value of type `Box&lt;SomeTrait&gt;`. I saw some posts explaining that trait objects generally have to be referenced or boxed, but did not see explicit instructions on how to create a boxed trait object. I saw that `Box::new()` requires its argument to be `Sized`, which made me feel like I was stuck in a loop. It took some reading and head-scratching to come to the conclusion that I should create a boxed concrete type first, and then coerce that boxed value to a boxed trait type using `as`. E.g., let boxed = Box::new(valueOfConcreteType); let boxedTraitObject = boxed as Box&lt;SomeTrait&gt;; 
Two reasons: *I'm not OP*. For `#[repr(packed)]` it can relatively useful for *attempting* to ensure the atomic operators *inside* the structure are aligned on the *cache line boundary* this can avoid issues with [cache contention](http://blog.mischel.com/2011/12/28/more-threads-makes-the-program-slower/). For `#[repr(u8/i8/ect./i64/u6)]` it would super useful for a way to specify *I only want a small value to sit on the stack, not a huge struct*. 
Nice find! Although I tried to use it and, like you, haven't come up with a solution for my use case.
In which case you can manually go through all the conditional blocks and make the Rust bindings properly cfg'd. Sure it involves a bit more manual effort, but it'll work across major platforms without introducing a massive dependency on libclang. However the *real* solution is to simply rewrite everything in Rust so we don't have to bind to C libraries.
In Rust string literals? Raw string literals don't process character escapes: https://is.gd/puAR04 You can have any number &gt;= 1 of `#` on either side as long as they match.
These are available [in the `libc` crate](https://doc.rust-lang.org/libc/x86_64-unknown-linux-gnu/libc/fn.posix_fadvise.html). You can get the file descriptor of an open file with [`std::os::unix::io::AsRawFd`](https://doc.rust-lang.org/nightly/std/os/unix/io/trait.AsRawFd.html).
No, it's from external input that I convert to Vec&lt;char&gt;
No. Of course the nested loop is easier, but the iterator version is more flexible/composible – which is why Rust uses iterators in the first place.
You should probably provide a more complete example, as escaping shouldn't be a thing outside of raw strings in your program.
Yes, with larger loop counts, the difference gets smaller, eventually the unrolling gets into diminishing returns.
`Display` is generally for output suitable for presentation to a layman user. `ToString` has a blanket implementation for `Display`; you'd have to use the specialization to override this. `Debug` is for an honest representation of your datastructure for its users to inspect. There's also `std::fmt::Binary` which is similar to `Debug` but for binary representation. And then for writing to streams, there's no clear-cut convention. I like having an inherent method `write_to&lt;W: Write&gt;(&amp;mut self, to: W) -&gt; io::Result&lt;()&gt;`, but you could also have a method which produces a type that implements `Read`.
Hey, maybe what you're looking for is along the same lines as [Cobalt](https://github.com/cobalt-org/cobalt.rs) - Static site generator written in Rust. A decent amount of work has been put into it, and I think there are tasks that anyone can tackle if you'd be looking to contribute to a open source project. And of course there's always forking if you want to start with Cobalt as a base.
I guess the blocker is making `mem::size_of` const, due to [this line](https://doc.rust-lang.org/nightly/src/alloc/raw_vec.rs.html#60).
[Github Repo](https://github.com/abonander/anterofit) [Crates.io Entry](https://crates.io/crates/anterofit) [Discuss on users.rust-lang.org](https://users.rust-lang.org/t/anterofit-wrap-rest-apis-with-rust-traits/9826)
1. I see. Maybe use an iterator instead of a slice? That would be more efficient, for example if you fill a rectangle and the pixels can be calculated easily, because it does not force you to allocate memory for all points. 2. Couldn't you break this with `image2.set_pixels(&amp;[image1.get_point(x, y)], ...)`? You would probably have to make `set_pixels` a method of the pixels themselves, i.e. `image.get_point(x, y).set(color_index)`. Replacing `color_index` with `image.get_color_index(i)` will give you trouble with the borrow checker though. In the end, you might also consider just panicking, this is what happens if you access an array out of its bounds, which I think is similar. 
I would say "beneficiary" rather than "culmination." It's nitpicky, but accurate. I think computer science "culminates" when Skynet kills us all.
As soon as you have multiple error conditions, that's an opportunity to define an error enum. If you return `false` or `Err(())`, the caller doesn't know if the problem is one of the points or the color index. So you could have something like `Result&lt;(), SetPixelError&gt;` where the error is `enum SetPixelError { NonexistentColor, InvalidPoint { index: usize } }`.
If the whole package (Cargo etc.) came in 1973, then it would be a lot of open source today and more focus on fixing the remaining security issues. More people might write in Rust, and SQL injection could be prevented by using a suitable API. Instead of using Rust as it is today from 1973-2017 it is more likely that compilers would evolve to the point where theorem proving techniques would be much stronger. In theory, this should make it possible to generate faster code from a higher level description of the program. You might not recognize it as Rust because all the current stuff comes from computer science research that would advance further in that time.
I was unhappy with the current state of libraries for windows named pipes so I started working on my own modeled after the standard library `UnixListener`.
Thanks for the great answer in my absence! :)
beneficiary is a better word choice, I've updated my comment
Is there a crate for easy and fast recognition of common file formats? I'm mean like "is this jpg, png, mp3, xml, zip, tar, bash script, windows executable, ELF executable; if not recognized, does it seem binary or plaintext?"
Sufficiently advanced file type detection is indistinguishable from [magic](https://crates.io/crates/magic).
3
I recently wrote [an MPEG-2 subtitle decoder in Rust](https://github.com/emk/subtitles-rs/blob/master/vobsub/README.md), and spent my weekend attacking it with `cargo fuzz`. The fuzzer ran over a billion sample inputs through my code. I discovered: - No malloc/free-related errors, thanks to the borrow checker. - 3 errors where I constructed invalid `Range` objects. These might have been exploitable or resulted in infinite loops in C. - One arithmetic underflow error, which might have been exploitable if it weren't for Rust's bounds checking. So while writing high risk code, Rust ruled out most errors at compile time, and caught 4 more at run time. Up until now I had underrated Rust's runtime checks as part of the overall security story, but I now consider them as indispensable as the compile time checks. Additionally, my experiences with `cargo fuzz` suggest that it should be part of the standard Rust toolset, just like rustfmt. It's definitely good fun and the Rust ecosystem would be even better if it were widely used. After hearing about the CIA leaks, I basically have even less desire to run C code on hostile inputs than before. 
yeah, there seem to be a _lot_ of miss-categorised posts lately...
&gt; which probably means the loop version is no longer unrolled. (I haven't inspected the assembly.) [Your intuition is right!](https://godbolt.org/g/sjN0kv)
The first one doesn’t compile now because of a bunch of unconstrained type parameters—this was a genuine tightening of the rules of what is permitted. No idea if it can be made to work again or not.
Perhaps it would be easier if you think of Trait objects as an abstract type. It doesn't make sense to "create" one, because it isn't a concrete type, it's an interface that represents an unknown concrete type. The C equivalent would be asking how to create "void" so you can get a void pointer.
Didn't mean to imply that it was obvious, though I see how my post can be read that way. Just curious about how /u/TheBullshitPatrol came to the conclusion he did since understanding things like that can help us avoid giving people misconceptions while teaching them.
So, here's what I've done, really, and [here's a crate I wrote to make it easier.](https://docs.rs/type-operators/0.3.4/type_operators/) My argument for the Turing-completeness of the Rust type system is that you can write partial recursive functions, essentially doing a sort of case-analysis by dispatching over trait impls. The macro in that crate gives you a sort of tiny programming language to automate that process. However, going back and searching for sources to prove that this is indeed a valid proof, I ran into some info that stated that the functions I thought could only be implemented using partial recursion (specifically, division iirc) were in fact implementable with primitive recursion. I'm not even fully certain of this, actually, because I suspect that it might even be simplified (not partial) division - sort of like implementing truncating subtraction/monus instead of partial subtraction over the natural numbers. I'm still certain that traits are Turing-complete; however, right now that's only shakily held up by anecdotal evidence of a *lot* of debugging of bits and pieces of my [type-level logic crate](https://docs.rs/type-level-logic/0.1.0/type_level_logic/) which resulted in a lot of clear cases of accidental infinite recursion during trait resolution. So, I've decided to go and try to implement Smallfuck in Rust traits in an attempt to prove my point once and for all! I'll be back with the results. EDIT: Results! https://github.com/sdleffler/tarpit-rs I'm fairly sure this is a correct Smallfuck implementation in the Rust type system! If anyone wants to donate some more example Smallfuck programs to be extra-sure of its correctness, that'd be great.
r/playrust
FYI for those reading this in the future: That project has been merged into diesel proper https://github.com/diesel-rs/diesel/tree/master/examples/sqlite so my repo will be deleted shortly.
&gt; 2. **What are common vectors for security exploits besides buffer overruns?** Does the design of Rust help protect against these cases as well? Another common attack vector is format string vulnerabilities, caused by using a string supplied by the attacker as the format string in `printf`. The string formatting macros (`format!`, `println!` etc.) in Rust help prevent this class of attacks as well, since the format string must be a string literal.
Really it's the only time that i've found myself initializing a collection and not having to specify the type. An array, for instance, has to be instantiated when it's declared, right? 
&gt; As in real estate, ownership can be transferred. Like selling a house, assigning one variable to another variable transers ownership. We say that the value has been “moved.” Similar to how selling my home means moving my stuff, moves in Rust copy data to a new place in memory. Transfer ownership doesn't cause move of memory. The old variable die and the new variable own the same memory.
Currently porting over my github library over to the async version of hyper. So far so good! I've got it making requests. Now all I need to do is rewrite the rest of my library to utilize it, that and I'm refactoring it into something more usable. Having used it in a personal project, it wasn't as ergonomic as I had originally hoped for.
There is [peano](https://github.com/paholg/peano), but I'm not sure it's any simpler to use.
Fair enough &gt; An array, for instance, has to be instanted when it's declared, right? Strictly speaking, no, the following is valid let x; // Array declared here x = [1, 2, 3]; // and instantiated here or more interestingly, the following is valid let x; // declared here (note that it doesn't need to be mutable) if some_condition { x = [1, 3, 5]; // either instantiated here } else { x = [2, 4, 6]; // or instantiated here } println!("{}", x[0]) It's also worth pointing out that `let x = vec![]` is instantiating `x`, it just happens to be to an empty vector, likewise `let x = []` would be instantiating `x` to an empty array (which isn't very useful, since arrays aren't growable). It's also possible (but trickier) to instantiate a non-empty array without giving an explicit type when doing so, for instance the following is all valid let x = [vec![], vec![]]; // We know that x is of type [Vec&lt;T&gt;; 2] for some T, but we don't know T let y = unsafe{ [ std::mem::uninitialized(), std::mem::uninitialized() ] } // We know that y is of type [T; 2] for some T, but we don't know T let mut z = unsafe{ std::mem::uninitialized() }; // We define and instantiate z here without saying anything about it's type z = [1, 2]; // here we use z, and let the compiler the type is [i32; 2]
I would expect latex to be more complex than our type system.
They are a theoretical possibilty (mentioned here: http://aturon.github.io/blog/2015/09/18/reuse/#thin-pointers ), but I don't think they are possible to express currently.
What unanticipated problems appeared?
You haven't used async expressions? I find them quite a bit easier to compose than MailboxProcessor for most async code. 
Pretty sure I've done it! https://github.com/paholg/minsky/ /u/lifthrasiir thanks for the idea to implement a Minsky Machine.
As a matter of fact, I'm done! I used only very vanilla Rust features. Just `trait`, and some type synonyms to make things readable. Nothing exotic, no `#![feature]`s or anything. *However*, if you go to try to read this code you may be confused since it's using my `type_operators!` macro - but don't be. It all expands to vanilla Rust. I am 95% confident the type-level implementation is correct - but some more example Smallfuck programs would be nice so that I could test it out better and be extra sure. https://github.com/sdleffler/tarpit-rs I might write up a blog post later. **Some people** have been telling me I should do stuff like that...
It is. See https://github.com/ozkriff/zoc
/u/nasa42 I tweeted so many limericks that edunham suggested I be called llimeriq, and this is the best quote you could find?
You may want to see section 7.6.3.3 and 7.6.3.4 of [this](https://downloads.haskell.org/~ghc/7.8.2/docs/html/users_guide/type-class-extensions.html). GHC's `-XUndecidableInstances` flag may provide some enlightenment for you; there are two conditions which `-XUndecidableInstances` lifts, which Rust does not seem to care about: &gt; The Paterson Conditions: &gt; &gt; 1. for each assertion in the context: &gt; a.) No type variable has more occurrences in the assertion than in the head and &gt; b.)The assertion has fewer constructors and variables (taken together and counting repetitions) than the head &gt; &gt; 2. The Coverage Condition. For each functional dependency, tvs_left -&gt; tvs_right, of the class, every type variable in S(tvs_right) must appear in S(tvs_left), where S is the substitution mapping each type variable in the class declaration to the corresponding type in the instance declaration. Rust doesn't have functional dependencies, so the coverage condition is irrelevant. So, it looks like the main culprit is the lack of the Paterson conditions.
Well, suggestion to use your [reddit quote](https://www.reddit.com/r/rust/comments/5wt2vq/this_week_in_rust_171/ded0un1/) received more upvotes than all your limerick tweets combined. :P PS: In my defence, I don't use Twitter and I didn't see your tweets until you mentioned (I don't have a personal Twitter account). Please submit quotes to [the thread](https://users.rust-lang.org/t/twir-quote-of-the-week/328) or at least tag [@ThisWeekInRust](https://twitter.com/ThisWeekInRust) in a tweet.
Do you think this RFC is acceptable or not?
Interesting, based on [stack overflow](https://stackoverflow.com/questions/3213490/how-do-i-write-if-typeclass-a-then-a-is-also-an-instance-of-b-by-this-definit) my interpretation of the paterson conditions is that they make blanket impls illegal. I also learn that Haskell essentially doesn't look at any `where` clauses when checking coherence. Both of these seem like very important features for the way Rust uses traits, and I wouldn't think of trading them away for decidable typechecking.
This was a super helpful and informative post, and I feel like I understand the ideas behind pi types (and the name) on a much deeper level than before. Thanks!
&gt; You can have an error in the business logic that controls a bank where if someone deposits $12.01 exactly, you double the amount of money in their bank account. Rust can't prevent this kind of thing, only good software architecture and code reviews. Ideally, Rust's focus on immutability by default, ASTs, etc. allows you to Make Impossible States Impossible, but that's up to the programmer to use those tools or not. This is an area where programming languages have potential to improve enormously in the future. For example there is work done in Idris to encode communication protocol properties in the type system to verify the security of the implementation in the type checker (I think some of this can be done in Rust as well, but to a much lesser extent). Just imagine if OpenSSL could be written in a language like this.
Consider iterating over a vector of thin pointers in C++. If you have a reasonable number of types in your hierarchy: - the vtables of your objects will be in cache, - you are always accessing the same vtables so the branch predictor can work very good (and will work perfectly if you sort the vector by type), - you need _half the memory_ than rust for those thin pointers. My point being: it's a trade-off. Which one is the best depends on what you actually want to do. It is trivial to use fat pointers in C++ (there are many libraries to emulate virtual concepts in C++11), but emulating thin pointers in Rust is not that easy (although there were a couple of blog post about a language feature for it). 
that design patterns repo tho Great recommendations 
Yes, because it always was. Pithiness aside, you can't tell the difference between unsafe code in the crate that forms the executable and unsafe code in a library, because to the executable they are simply all functions in the single flat namespace
/u/llogiq I'm so very sorry. In an attempt to make amends, I've dedicated my Rust time tonight to fixing some of my _other_ sins as admonished by Clippy.
But it still defeats the very use case of references to values heavy to clone. It would be very hard to justify in my opinion.
All Rust code needs to (normally indirectly) use unsafe code to do I/O and many others. In the ideal world you may have an operating system kernel that knows Rust ABI (assuming it has been stabilized somehow) and produces a stack layout exactly suitable for calling Rust's `main()`, but... yeah, until then you _need_ unsafes. If you are doing some sort of auditing, you can use `#![deny(unsafe_code)]` and so on to control the use of unsafe codes in a particular crate (you can `#[allow]` it only for some sections later). This is not transitive however and auditing all dependencies including libstd will be very hard to do.
This worked great! changing the rust/mk/cfg/i686-unknown-linux-gnu.mk to use my compiler did the trick. But now I'm having another problem, it seems that the build will only compile compiler-rt to the host x86_64 and not to my target i686 since when compiling the stage2, the compilation will fail in that line: x86_64-unknown-linux-gnu/stage2/bin/rustc --cfg stage2 -O --cfg rtopt -Cdebuginfo=1 --target=i686-unknown-linux-gnu -C linker=i686-unknown-linux-gnu-gcc -C ar=i686-unknown-linux-gnu-ar -C prefer-dynamic -L "i686-unknown-linux-gnu/rt" -lstatic=compiler-rt --out-dir x86_64-unknown-linux-gnu/stage2/lib64/rust-1.15.1/rustlib/i686-unknown-linux-gnu/lib -C extra-filename=-570da8f8 -C metadata=570da8f8 src/libcompiler_builtins/lib.rs error: could not find native static library `compiler-rt`, perhaps an -L flag is missing? Maybe I need to change something else?
Like this? https://is.gd/9vTsoL.
[This page](https://killercup.github.io/trpl-ebook/) has some ebook versions of the original for download. The new version is pretty far from completion still.
Coming from Java, I'd assume that x would be instantiated as Vec&lt;Object&gt; (or whatever is the top type in rust, if it even has one) . It's cool that rust is able to do that.
The problem with the return from the `new()` method or any other copy/move of `Test` is, that when `Test` gets copied/moved, then the memory location of `Test::b` changes, but the reference `A::b_ref` isn't updated. The Problem with `Box&lt;Test&gt;` is, that a `Box` is clonable but because of the problem above, there's no way to make a valid copy of `Test`. In this case a `Rc&lt;B&gt;` seems the way to go, which is shared by `Test::b` and `A::b_ref`. https://is.gd/GYayFn
Return `Cow`, caller calls as_ref(), tada rest of code can be focused on &amp;T
Using `Cow&lt;T&gt;` as result type and using `.into()` is probably an alternative II. The problem with this one is that `Cow` has a too specific name, despite being useful in other cases.
AFAIK there is no really nice solution in this case. Unfortunately, the borrow checker is not smart enough for this case, yet. Do you have a practical use case for this pattern?
Interesting, the docs at https://doc.rust-lang.org/std/rc/ seem to have a similar sort of scenario as OP.
Hmm. It does mention the native library is the one it's looking for. Are you using the local `llvm` or your own build? Sorry I can't be more helpful. I usually pop in to `#rust` or https://internals.rust-lang.org/ to get help on detailed stuff like this. But take note -- they'll probably all tell you to switch over to `rustbuild`. I was worried about switching after getting the `.mk` file configured for my target but it turned out to work better for me. I think `rustbuild` makes fewer assumptions and makes cross-compilation easier.
Rustup comes with the complete documentation. Rust book, API reference, Rustonomicon... it's all in there. :) rustup doc Though I'm not sure about the new book, I don't think it's finished.
Yeah, I made a second post with a more specific case. https://www.reddit.com/r/rust/comments/5y7xsx/glium_vertexbuffer_mapping_lifetimes/
Why is it claiming that Firefox 52, [which does have wasm support](https://www.mozilla.org/en-US/firefox/52.0/releasenotes/), does not support wasm? Does it require a new feature only available in Firefox 54?
&gt; If you are doing some sort of auditing, you can use #![deny(unsafe_code)] &gt; .... &gt; you can #[allow] it only for some sections later Note that if you actually don't want to allow any unsafe code, you can do `#![forbid(unsafe_code)]` in the crate root, and it can't be overridden inside the crate any more. Of course, any crates that you use will still be able to use unsafe code. 
Yes, but I'm on my iPad and as far as I know I can't install rust on it :) 
If you look at cert advisories, a great many of them are due to buffer overflows, null pointer exceptions etc. Code is inadvertantly or maliciously fed malformed data causing it to exceed an allocated buffer, overwrite something important and become exploitable. I think the absence of null pointer in safe mode, pointer arithmetic, nul terminated strings, unbounded crappy C functions like sprintf would prevent a lot of those errors before they even happen. What Rust wouldn't stop are errors in application logic. e.g. if the code skipped some important security check because a value was set wrong, or got caught in a loop then the language isn't going to save you. It might also be easier to cause a Rust program to panic thereby causing denial of service so even Rust code would have to be hardened to cope with unexpected values, e.g. not blindly unwrapping values without checking for errors. 
Definitely came up for me when dealing with abstractions around mmap. 
I have a about how to cleanup the last line of the following function: fn create_factors(length: usize) -&gt; Vec&lt;usize&gt; { (0..length).scan(1, |state, _| { let result = *state; *state *= 2; Some(result) }).collect::&lt;Vec&lt;usize&gt;&gt;().into_iter().rev().collect() } It needs to create numbers that double in size, largest to smallest. e.g. a length of `3` should return `4, 2, 1`. The current problem I have is that `Scan` doesn't implement `DoubleEndedIterator` because of it's state, so a simple `rev()` doesn't work.
Oh, I'm sorry about that, don't know how I missed that part. That's what I get for procrastinating at work...
I know why it's caused, in C I'd solve this with allocating to the heap and returning a pointer. What is the solution in rust when we do not have access to the reference inside the objects?
&gt; As the author of the original brainfuck interpreter Sorry, I might be missing something, but you don't *seem* to be Urban Müller, just based on your reddit history (and something makes me doubt that he even has a reddit account). Can you clarify what you meant when you said this?
`wget -r http://rust-lang.github.io/book/`
They clearly mean the brainfuck interpreter implemented in the Rust typesystem linked in OP's post, click that link and you'll see they're the author.
Even on Firefox Nightly (currently 54 for me), this does not detect wasm support, so the feature detection is likely broken.
If you just started using Rust, then better not, because when writing unsafe Rust code you should really know what you're doing. I think it's better to only use unsafe code if there's a real need for it, otherwise why using a safe language at all?
&gt; I belieive so, recreating the mapping every time I need it (once every frame) would be pretty counter intuitive for a mapping. I don't think so. It's IMHO more counter intuitive to have two variables which aren't independent of each other. If I want to write to the VBO I'm calling `map_write` on it, seems quite intuitive to me. 
It's a very big improvement. Going further, I'd like to see some effort put into ensuring that it fits well into tooling -- i.e. Consider how logcat for Android allows you to click on an error in logging to have it take you to the corresponding sourcecode. It is entirely feasible to do this from the backtrace, and would be very valuable to me (that is, at least in any cases where proper integrated debugging isn't an easy option). For the most streamlined workflow without need for intermediate reformatting, I would suspect using just 1 row per backtrace element would be better than spreading across two lines. I mention logcat for reference, since someone pointed out to me that logcat does what I do in my work, but I haven't actually seen it in action. Personally.. rather than use logcat, I tricked Eclipse into thinking my runs are builds -- and I set up a custom 'build error parser' to parse source:line out of the log message and let me take me to the source. Hardcoded limitations in tooling are frustrating, but entertaining.
&gt; I tweeted so many limericks that edunham suggested I be called llimeriq, and this is the best quote you could find? &gt; \- llogiq Sounds like QOTW material to me
In general, many things that could be `const fn` aren't yet, because it's still a not really finished feature.
Ditto. I've tested in Nightly (now 55), Dev (53) and Release (52). edit: Looks like [an issue](https://github.com/davidMcneil/the-rusty-web/issues/1) has already been filed.
Thanks, that explains it.
By default, there is no way for one field to have a reference to a member of another field in safe Rust. However, this is a common pattern, so there are libraries to help. Specifically, you should check out owning_ref and rental.
Rust doesn't have any top type. Java style inheritance has a performance penalty for every type, even when you're not using it. The closest equivalent is Any, but you have to box the object first, and there isn't anything useful you can do with Any objects anyway.
This could be used to overcome Index trait limitations: https://www.reddit.com/r/rust/comments/4as7gx/why_make_the_index_trait_so_useless/
Oh hey, I'm currently working on something closely related to this! (Although my use case is mostly putting Rust completely in charge instead of acting as a library for JavaScript.) 1. A cargo helper for everything client-side web in Rust, e.g. installing all of the necessary gunk like Emscripten (not yet done), building, testing (currently launches tests in a web browser in Chromium, although I plan to switch to Chromium's Headless Shell), running (currently launches an embedded web server) and deploying (not yet done). You can see a very early work in progress [here](https://github.com/koute/cargo-web). 2. An alternative to the `webplatform` which allows you to directly embed JavaScript code in Rust like this (works right now): let name = "Bob"; let value = js! { console.log("Hello " + @{name} + "!"); return 2 + 2 * 2; }; println!("2 + 2 * 2 from JavaScript is: {:?}", value); or this (also works right now): let callback = |name: String| { println!("Hello {}!", name); }; js! { let cb = @{callback}; cb("Bob"); cb.drop(); // Necessary to clean up the closure on Rust's side. }; (As you might have guessed this pretty much stretches Rust's type and macro systems to their very limits.) Currently I'm working on adding `serde` support so that you can also directly pass structures that implement `Serialize` and `Deserialize`. After that I need to add bindings to enough Web APIs to support a basic todomvc example and I can release it into the wild, which will hopefully be soon™.
No, I mean map_write is the glium's API that it's exposed to me. It creats a memory mapping and returns you the object which represents the mapping. I can't change this - calling map_write every loop will just slow my program down, and defeat the point of having a VBO there anyway.
&gt; calling map_write every loop will just slow my program down, and defeat the point of having a VBO there anyway Drawing with a buffer that is currently mapped is forbidden by OpenGL, so this slow down is mandatory anyway. Not that glium's API is perfect, but all the objects with a lifetime have been designed to be temporary. 
Oops, I now realized that the overflow seems to be from trying to store a number too big into an i32... :D But thanks for your advice either way.
I tried to do this on my iPad but it doesn't download properly to iBooks, sadly.
I happen to have a small list of reasons why Rust *can be* theoretically faster than C: https://gist.github.com/kvark/06c96ef8081e2239955b
The problem is that with these comparisons people will avoid all of these weaknesses anyway because it's not about which language is faster/better/stronger in the real world but in that limited scenario. You can work around most of the stuff on your list. It's a strength of Rust's that you don't have to but it's not like you couldn't avoid those sources of overhead in C++ it's just more work. That's why I suggest we talk about real projects and how people were able to make use of Rusts advantages instead of looking at small benchmarks where both Rust and C++ code might look very different from how people would write it in a production context.
Yes but it's really just not finished, as in only about half of it is actually written. Many of the pages are just stubs or outlines and it makes references to chapters that don't exist. I did find the chapters covering the borrow checker useful though. The original left me a bit confused.
👀
Thanks, I'll download both and read through them.
I think the first thing is to split the data into static and dynamic ones and have separate buffer objects for it. The dynamic one should be as small as possible. Perhaps some dynamic data can be switched into static data by putting the dynamic logic into a shader. I think there're options to tell OpenGL how you're gonna use the buffer object e.g: GL_STATIC_DRAW (never changes), GL_DYNAMIC_DRAW (changes sometimes) and GL_STREAM_DRAW (changes every frame). 
Oh! Interpreted like that it makes a lot more sense. I'm sure Rust will be faster than C++ in many projects because of the reasons in your list. So for real world projects those are definitly relevant points!
Cool, thanks. :)
You can do something like `buffer.slice(0 .. n).unwrap().write(..)`.
Yep. I tried a couple of hacks to bypass this, but I don't see other options than creating my own fork/patch and compiling rust from it.
Interesting. I was going to try doing something completely awful that this could help with. I essentially want to run a scripting language (lua or dyon) with WASM and call it from JavaScript. I'm building a game and want the AI to be in a scripting language with the renderer being written in JavaScript. I want my AI to run server-side, but in single player mode allow it to run locally so it doesn't hit the server at all. So essentially: - Rust library to talk to lua/dyon - separate renderers for each platform (Android, iOS, HTML5, desktop) - AI written in lua/dyon and portable to each platform I'm interested in your progress as I may want to do something similar.
Instanced rendering is where speed comes from. 
This is a blanket impl, and it doesn't compile for what seem like those rules: class Foo a class Bar a instance Foo a =&gt; Bar a Errors: Illegal instance declaration for ‘Bar a’ (All instance types must be of the form (T a1 ... an) where a1 ... an are *distinct type variables*, and each type variable appears at most once in the instance head. Use FlexibleInstances if you want to disable this.) In the instance declaration for ‘Bar a’
Thanks, I'll check those alternatives out! :) EDIT: Sadly rlwrap doesn't work in eshell, but it works fine in the terminal. Thanks again!
Even with FlexibleInstances, the example doesn't compile. FlexibleInstances allows unbounded blanket instances: `instance Foo a`. But it doesn't allow bounded blanket instances: `instance Foo a =&gt; Bar a`.
There's [a current RFC](https://github.com/rust-lang/rfcs/pull/1823) for that.
/r/playrust
Thank you!
Tail call is if the recursion is at the end of the function. Rust does not optimize for recursion, hence your issue with mapping recursive logic to their recursive equivalent in Rust.
Ahhhhh okay. I had no idea this was a thing, seems to be lots of funny things like this that're less intuitive to find:P You're a rust g0d dude, how do you do it;)
OK, pray 10 needless_return, 5 needless_borrow and one map_entry.
&gt; One thing I didn't see mentioned is the cost associated with a lot of OOP languages that incurs cache misses each time a method is called Virtual/Dynamic dispatch is horrible for branch prediction, uOP caching, decoding, cache locality. Intel dedicates many pages of their performance manual telling people all the common mistakes you can make implementing one. But in the grand scheme of things 1000+ cycles on a function call is still so stupid fast compared to a hosted vm language nobody cares. Also Rust's *everything is an enum* approach is really no different. Enum matching is no different then dynamic dispatch. Maybe with aggressive inlining of future branches bad branches could be pruned, but I don't know compilers that well. 
If typeck wasn't already undecidable, I'd want to keep it that way, because if the type system is guaranteed to eventually terminate, then there's no need for a recursion limit. If we already had a recursion-limit-free typechecker, I don't think we'd want to introduce the need for one.
`let b: Vec&lt;_&gt; = bep.into_iter().map(|x| { x.1 }).collect();` Changed two things here: added the `Vec&lt;_&gt;` annotation, as `collect` needs to know what data structure to collect into, and changed `iter` to `into_iter` so we can move out of tuples (otherwise it would be a reference, and we wouldn't be able to transfer ownership from inside one).
I'm trying to refactor a data structure I've built into a crate for standalone publishing. Unfortunately, it contains a statically allocated array, and the size of that array would vary depending on the exact application. (For the original use, I just picked a reasonable size, but it would vary depending on what time/space tradeoffs you want to make) I don't want to impose a choice on the client code, but I don't know of any way of defining an array with a generic, unspecified (but still static) size. Any suggestions? EDIT: I also can't take an array that someone else has passed me, because I need internal, non-public data associated with each item, so if I took an array from the client, I would still have to be able to construct a new array of the same size with my own data.
One sanoogle, if I try to move the join up onto the same line I can't write the type hint and collect won't know what to what to collect into again.
You can always give collect an explicit type like so `.collect::&lt;Vec&lt;_&gt;&gt;()`
No, what you want is a [trampoline](https://en.wikipedia.org/wiki/Trampoline_(computing\)) ([here's an article about it](http://www.datchley.name/recursion-tail-calls-and-trampolines/)). It's often used to optimize tail-calls in languages that don't do tail call optimization, but you could use it to make deep recursion stack efficient.
Just as a note for your version that uses remove -- this will mean the temporary vector would have all of its elements be moved over, in order to accommodate moving out the &amp;mut Vertex from the first position. Using iterators it is not only easier to read, but also more efficient :-)
This is fantastic. Rust output already tends to be pretty good but this was a weak point. Good job to the dev team!
Soon™! I really don't want to give out any promises that I won't be able to keep; as I've said I have a pretty short TODO list that I want to go through before going through with the initial release - `serde` support (halfway done!) and a working todomvc example. (I don't want it to be totally useless.) While I can estimate the `serde` stuff I have no idea how much effort supporting everything else something like todomvc will actually take. (I haven't yet looked into it too closely.)
Better ergonomics for match: https://github.com/nrc/rfcs/blob/match/text/0000-match-ergonmics.md
I think implementing `IntoIterator` for reference won't work, because for more layers of indirection and confusion I wanted to have in struct an owned variable with `NumberCollection` trait bound :) . I figured out how to do it with boxing (at least it compiles now), so I guess I will settle for that.
This got me wondering if it was possible to expose any iterator over matchups and have the consumption of that iterator inlined. With the help of the OEIS and a few extra optimization flags, it was: https://godbolt.org/g/xbXLp5
You can't return a bare trait (because it's unsized). You can however write the trait like this: trait NumberCollection { type NumberIterator : Iterator&lt;Item=i32&gt;; fn numbers(&amp;self) -&gt; NumberIterator; } Then each implementer gets to return their own type. It would be statically typed and incur no dispatch cost and require no heap allocation. Container::NumberIterator would be something like (Map&lt;Pieces::Iter, ...&gt;).
Yeah, it wasn't a stack overflow, just an integer overflow. But this is what I got, so I misunderstood it: thread 'main' panicked at 'attempt to multiply with overflow', src/main.rs:407 note: Run with `RUST_BACKTRACE=1` for a backtrace. I erroneously assumed it was a stack overflow.
The OP said &gt; while iterator exists I should not be able to mutably borrow container. Meaning that the trait should be (with lifetimes manually annotated) trait NumberCollection { type NumberIterator&lt;'a&gt;: Iterator&lt;Item=i32&gt; + 'a; fn numbers&lt;'a&gt;(&amp;'a self) -&gt; Self::NumberIterator&lt;'a&gt;; } Unfortunately, this requires the "associated type constructor" feature specified in [this RFC](https://github.com/rust-lang/rfcs/pull/1598).
[DevDocs](http://devdocs.io) has [Rust documentation](https://devdocs.io/rust-guide/), including the book, and it allows you to use [offline browser storage](http://devdocs.io/offline).
In general I see very little development in the GUI space because of the lack of Rusty libraries for generating them. Conrod is an option, but it's not native on any platform, gtk-rs is incomplete, and I don't know the state of win32 or cocoa APIs. Because of this it wouldn't surprise me if there really is nobody doing development in your specific area. That being said I've been building a cross-platform app [gattii](https://crates.io/crate/gattii) that uses GTK+. GUI development is a little different in Rust than what I've seen before and the "right way" to develop GUI apps isn't quite fleshed out yet (like [how to properly store global references to UI elements](https://users.rust-lang.org/t/avoiding-global-objects/9814/18), etc.). So it'd be great to have someone else trying to build complex GUI applications so that we can drive Rust forward in this area, as it's definitely a weak spot right now!
When coming from C one important thing that's different is that rust has strict aliasing. In C it would be kind like sticking restrict on everything. If the values may alias you need to use unsafe cell which is specially handled in the compiler and turns off the strict aliasing for what it contained. There's a few core rust data structure's that use, I think mutex is implemented ontop of unsafe cell. You may not need it, but the optimizing compiler will cause very confusing bugs if you missed a spot where it was required. The best reference for writing unsafe code is the [rustonomicon](https://doc.rust-lang.org/nomicon/). Some of that is a little dated, for instance drop flags are no longer needed. Also a proper rust API on top of unsafe code should maintain the safety for any callers no matter how the use the API. [This blog post](http://smallcultfollowing.com/babysteps/blog/2016/05/27/the-tootsie-pop-model-for-unsafe-code/) has some good info on a way to approach that.
But it *doesn't* compile down to that if the set is genuinely open, since the set of destinations cannot be known at compiletime. This places the optimizer and code generator in a very different position.
To answer the question, no. let mut a: [_; 2]; // Declare with parts of the type to infer a = [1., 2.]; // Still could infer to f32 or f64 a[0] += 1.0f32; // will inform type inference to pick f32 for _ 
You can move the lifetime up to the trait itself. trait NumberCollection&lt;'a&gt; { type Iter: Iterator&lt;Item=i32&gt;; fn numbers(&amp;'a self) -&gt; Self::Iter; } That way, you can use `'a` when specifying the type of `Iter`.
&gt; since you can’t decide how objects are organized in the heap Can somebody explain why this has to be the case?
I think the author of Conrod might have an audio related use-case in mind or is working on [something](https://www.youtube.com/watch?v=_ZXLCVibI8c&amp;t=186s). In any case, I'd agree that Rust needs more in the UI space. I use Conrod for cross platform apps and it's great but as you say, a lot of use cases needs a more traditional UI.
In addition to the libc crate mentioned by /u/DroidLogician there is the nix crate which encapsulates libc and POSIX APIs into a safe API. I'd recommend starting there instead of with libc depending on your crate because it's much easier to learn. Do be aware that both libc and nix are under a lot of churn as their both manually implemented, but I've contributed to both and it's pretty quick to add something if it's missing. 
Yes, Conrod is awesome and easy to use :)
I'd love to see a project like this get started. In my head, I tell myself I have enough free time to even work on one, but sadly reality catches up with me. I had some idea about how nice it would be to build effect systems, virtual instruments, convolution engines, etc using the Rust iterator model. I have some experiments here, and I'd love to get them to a decent state and at least blog about them.
Fair enough. I want the whole enchilada (or monadic burrito, as the case may be). I am, maybe unreasonably, optimistic that that effort will bear fruit. :)
I have a microtonal ([31 ET](http://31et.com) actually) sequencer/DAW in mind, and going to slowly start implementing it. &gt; I guess if a project for this would start up, it would use RustAudio and Conrod Indeed. There's not a lot of choice anyway. Btw, the autor of Conrod is working on [some DAW](https://cloud.githubusercontent.com/assets/4587373/22770737/d0459974-eee6-11e6-8e1b-cb545d0ce0d6.png) too. This DAW is not publicly available though. 
/r/playrust
Old win32 or WPF?
Very cool.
[AVR support](http://dylanmckay.io/blog/rust/avr/llvm/2017/02/09/safer-microcontrollers-almost-here.html).
You'll get a better response over in r/playrust This sub is about the programming language rust.
It comes down to undecidability of typechecking. If you can embed a Turing complete language such that given some program in that language you can calculate some output type (although I think the input need not be a type, nor the output) then you can show that the typechecker must be capable of infinite loops. Essentially, if the type system is Turing complete then that means that typechecking involves interpreting a Turing-complete language.
No worries. Thanks for the honest response. 
how is quasar going?
Java is "overrideable-unless-final", but C# actually requires you to specify the "virtual" keyword.
&gt; equivalent of C's ternary operator Still generates a branch mov $a, %%eax; test $b, %%ebx; cmov $c, %%eax; Is still a branch and a full pipeline flush if mispredicted this is the equivalent of return x== $b ? $a : $c;
I wrote a very naive delay vst plugin: https://github.com/sklopi/diLay I wouldn't use it myself, but it was a very interesting experiment.
Awesome project and great write up. I got a great sense of where the project came from, where it is, and where it's going. I wish more project announcements were this thorough.
technically, it's based on `Arc` and `Condvar`, so a C++ implementation would be straightforward to write, although not necessarily easy to debug :)
Yeah, that's what I was thinking too. Just looking for the right project to do it for. Because we already have a bunch of audio encoding/decoding crates. Audio player crates, etc. It's just a matter of swapping out some pieces little by little.
What does `vst` mean?
edited
That does sound interesting. Back on the AtariST, I wrote a text-file based tool to drive the 3-channel soundchip that supported flexible time-changes and microtonal stuff, e.g. I could fit a flourish of 13 notes into a minim if I wanted, and do half-semitones by adding a symbol, and arbitrary cent differences with 3. Moving onto trackers, it seemed that you're much more fixed to the grid by default -- both the 12-note scale and the time grid. Yes, you can do other stuff but not so easily. Creating something that more easily enables fluid musical changes is on my wishlist of projects too ... but no time.
At the end of your post you mention component graph systems. Is this the kind of system used in the godot engine (where you have a node tree, and each node has a simmilar task as a component)? Do you have any more information on these types of systems? Great post btw.
My head is too square to understand the metaphor. The holy grail is supposed to be unattainable, how can it then be part of almost every game?
Holy Grail, in this case, implying that it is the best of the known, and maybe best conceivable, solution and people aren't looking for a better one because the current solution is that good. Not exactly the original nuances of the term, but not too far off.
Virtual Studio Technology https://en.wikipedia.org/wiki/Virtual_Studio_Technology
I've been wanting to write a Fruity Loops/FL Studio-type app with rust, though to avoid the GUI issue I was going to start with porting something like [beats](https://github.com/jstrait/beats) to rust first.
That's a great idea. I love the YAML notation actually. After drums are implemented, you could add notation for musical notes in the YAML file as well. Adding the gui could be the last step.
supporting LLVM coroutines would definitely be *fun*, but I want alternative backends to Rust... I don't want Rust to become too dependent on LLVM either.
This looks a lot like [Bart](https://github.com/maghoff/bart), which I am (slowly) developing. I guess it was pretty inevitable to get "competition" in this field ;) The language seems to be much richer than Bart (which is Mustache inspired), which can be considered both a blessing and a curse :)
Vim, sed, perl, etc.
That's awesome. Looking forward to an initial release.
Yeah, originally what I wanted to do was to just buffer a small section of the memory, but I saw no glBufferSubData equivalent in the API. I'd never used any OpenGL mappings before, but I assumed that for some reason glBufferSubData was obselete somehow from an API perspective and using mappings was superior - I didn't realise they needed to be returned. In addition, somewhere in this thread Tomaka mentioned the way to buffer a region in memory - ``` buffer.slice(a, b).unwrap().write(data); ``` for anyone wondering.
Oh good. I didn't realize that the docs were at a separate url. Guess I need to publish 0.1.1 to fix that.
Yeah. I only noticed the platform dropdown in the top-right corner of docs.rs pages very recently. That could really stand to be improved.
I have some thoughts on this, having done [Music Synthesizer for Android](https://github.com/google/music-synthesizer-for-android) in C++. It's crossed my mind to rewrite (at least parts of) it in Rust. The core of this thing needs to be a module system similar to Core Audio in scope, where modules are strung together in a graph. The main method of each module is something that takes in some buffers, and produces 64 (or so) samples of audio. Everything in the graph running path needs to be no-allocation, lock-free. This is hard when you need to dynamically reconfigure the graph - you need to do the allocations in a different thread than the audio, then use something like compare-and-swap to bounce it into the audio thread. I didn't deal with that problem in MSFA, I just preallocated 16 voices (a voice in FM synthesis only takes a few dozen bytes). Next level up (but still important for a DAW) is deciding which modules actually need running based on non-zero input. The logic for this is nontrivial - if you have a note flowing into a reverb, you want that reverb to run for a couple seconds after the note itself becomes zero. You also want to be able to run the nodes at different sampling rates, and do sample rate conversions between them. This last is especially tricky because SR conversion imposes some delay. MSFA contains some modules that are, I think, much higher quality than your typical hobbyist synth. In addition to the 6-op FM voices, there's [band-limited waveform](https://github.com/google/music-synthesizer-for-android/blob/master/app/src/main/jni/sawtooth.cc), a pretty accurate Moog-style [ladder filter](http://levien.com/ladder.pdf). I also got started on FIR and IIR filters. The latter are based on [state variable filters](https://github.com/google/music-synthesizer-for-android/blob/master/lab/Second%20order%20sections%20in%20matrix%20form.ipynb), which are much better than the direct-form biquads you see all over the place. Most of this code has SIMD (either NEON asm or intrinsics), which is a massive speedup. The audio engine and UI should be separated. I tried to do this in MSFA, with a bit of success; the [dexed](https://asb2m10.github.io/dexed/) project shipped the FM voices in multi formats for DAWs. They forked the code rather than contributing upstream, though (I'm sure build nastiness made that much harder; cargo makes it so much easier). VST is the industry standard, but its non-open source licensing is tough. I wouldn't directly participate in a project that required me to sign the VST license agreement, but working on an open source engine is fine. I'd be interested in participating in such a project, but it would depend on a solid plan. That's a fairly tall order, I know; a lot of the pieces I mentioned above require serious engineering. 
Interesting! Is there a checkout available somewhere that does not include auto-generated code, but contains the generators and their inputs instead?
&gt; I don't understand why somebody should want to call js in rust There are many possible reasons why someone would want to call JavaScript from Rust; e.g. I'd like to write fully featured web applications 100% in Rust without touching JavaScript at all. Why? Well, I like Rust. I like static typing. I think it's great for long term maintainability. And I personally don't like what the client-side JavaScript ecosystem has become. Another use case would be porting Rust applications to the Web so that they can run in a browser (e.g. I'm planning to hook up [my NES emulator](https://github.com/koute/pinky)), or maybe treat the JavaScript world simply as a cross platform GUI framework (and as we know the GUI story in Rust isn't too great right now).
This is incorrect, cmov does not affect control flow (see [SO thread](http://stackoverflow.com/questions/27136961/what-is-it-about-cmov-which-improves-cpu-pipeline-performance)). Whether it's a ternary operator or an if statement makes little difference here - if the branches are side-effecting, then ternary must take one or the other. Similarly, a good compiler will generate cmov for simple non side effecting branches.
That seems inaccurate at best; [it has data dependencies](http://stackoverflow.com/a/14131292/1256624) but the whole reason cmov exists is to avoid branch prediction, because some code is better off with the reliable small cost of data dependencies than the unpredictable large cost of a mispredicted branch. You can see this in the classic ["why is it faster to process a sorted array" SO thread](http://stackoverflow.com/a/11227902/1256624): &gt; GCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move. So there is no difference between the sorted and unsorted data - both are fast.
Nice! Thanks for the feedback. 
How does this compare to [Tera](https://github.com/Keats/tera) "A template engine for Rust based on Jinja2/Django"?
Rust would probably be better leveraged writing low-level audio libraries. Maybe cross-platform embeddable audio systems.
What would you use for the actual GUI app then?
After some fixes to a few of the Rust benchmark programs, Rust is now equal to Go in one benchmark, and [significantly faster than Go in all the rest](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=rust&amp;lang2=go). Rust is also now [about as fast as or faster than C++ in all but two benchmarks](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=rust&amp;lang2=gpp) (the two SIMD-heavy ones).
Perhaps the Rust frontend for GCC may not be needed if the [small amount of patching needed to build the Linux kernel using Clang](https://github.com/ramosian-glider/clang-kernel-build) makes headway in the kernel community (performance would be a good rallying cry for it).
In my personal benchmarking I see a cmov regularly taken/not taken as ~20 cycles faster then a cmov irregularly taken/not taken. Which is a on par with a full pipeline flush. (Testing on Skylake-6600k) https://github.com/valarauca/consistenttime/issues/2#issuecomment-266172354
Try /r/playrustserver
Probably for Anti-Reversing? I'm doing a wild guess...
You could use Rust, it's just it's UI bindings are relatively immature. So it would be better to use something like QT/C++. If the Rust community started an initiative to write low level signal processing libraries. Then once UI integration is more robust, it could instantly start building around the audio libraries. That way we get a project from the ground up that is pure Rust. But... pure Rust is not necesserily a virtue. People can work on what they want, but in the long term starting with lower-level projects will provide something with much more longevity. But rust is made to be able to interact with C libraries, so certainly take a look at FFI. A lot of C libraries are very stable, and wrapping them up around safe Rust is not a bad project either. That sort of thing needs to be proved just as much as pure Rust initiatives. Anyways, that's my rant, others can way in.
Have you seen the state of the art of decompilers? There is no way to prevent local code from being understood by a determined attacker. This is one decompiler: https://derevenets.com/examples.html The only effective way to protect code as intellectual property is to have it only on your servers, and provide a remote API. A very important point is that code is cheap, generally. It's highly unlikely that your code is doing anything revolutionary, there are probably no revolutionary algorithms. Why would someone put in the effort to reverse engineer your code? Most likely just to disable a licensing check, and you can do that just by studying the raw assembly, without even using a decompiler. This advice applies to all programming languages. If you want to strip out those strings, you can pretty easily overwrite them in the generated binary by writing a small tool. Maybe there is a way to disable them in the compiler, but I dunno.
I feel like something else is going on in those benchmarks, because everything I've ever seen, including my own benchmarks (such as the one I just ran on a slightly older 4870HQ) and [the Intel Optimization Manual](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf), has no branch prediction penalty for `cmov` (the optimization manual explicitly recommends `cmov` for avoiding branch prediction penalties in section 3.4.1.1 Eliminating Branches, while also describing exactly the data dependency trade-off I mentioned above).
They are filenames from the system rustc was built on. You can see them with RUST_BACKTRACE=full
Sorry about my bad communication. &gt; If you want to strip out those strings, you can pretty easily overwrite them in the generated binary by writing a small tool. Maybe there is a way to disable them in the compiler, but I dunno. Like you said, I just want strip out that local source file path. or 'How to do not let rustc writing that local source file path string in the final compiled binary program?'
I wonder, could ECS-style approaches work for things other than games that would otherwise require a kind of graph of pointers? I need to read up on it more.
For now the question is, How to do not let rustc writing that local source file path string in the final compiled binary program? I am sorry about my bad communication.
You need to distinguish between a reference and a value. struct/class accomplishes this one way another is explicit references. I at this point am biased towards explicit references but I have to admit that the succinctness of struct/class can be nice in the vast majority of code since you typically want a reference.
I'm not saying that overall programs are 50x slower in C#, I'm saying that parts of programs can easily be sped up by orders of magnitude by carefully managing the cache (which is hard to do in C#, but more manageable in C++). For "idiomatic" code (where neither is particularly careful about cache access), I routinely see 2-3x perf. difference IME. Not all the time, but often enough. Sometimes you can fix it by writing the C# code in a less idiomatic way (e.g. unsafe code). Perhaps this is "virtually as fast" if you're used to comparing C++ with Ruby or Python or something, but for many industries that is a serious issue. 
Microsoft has published countless articles on how memory allocation is the most important consideration when looking at performance problems. This is especially true when talking about how they improved the framework itself.
(Author here) While I don't think I mentioned rust in the article, I do think Rust is a great example of a language that's high level but thought very carefully about how design decisions would impact implementation performance, and is thus better placed for high performance.
[removed]
The objection is to the struct/class approach, not the existence of the problem its solving. The struct/class approach is bad because it's the author and not the user making the decision, and if the author picked 'class' and the user needs 'struct', the user is completely screwed. One possible approach would have been to make the usual Swift strategy for adapting a struct into a class (i.e. just create a thin wrapper class around a struct) an automatic part of the language. Authors only get to write structs but every struct gets a phantom wrapper class automatically. No idea how pleasant this would actually be to work with but seems like it could be a lighter weight approach than requiring some kind of reference sigil everywhere.
I agree that a straight task/job system is better scalable than a classical ECS (which is only going to matter for really big projects), and we explored a bit in this direction with [fibe-rs](https://github.com/slide-rs/fibe-rs) back in 2015. However, it's not necessarily one or the other: we could be able to make ECS systems spawning multiple batches/jobs into your task graph. Currently in `specs`, to split a system's task into batches, you'd need to [chunk](https://doc.rust-lang.org/stable/std/primitive.slice.html#method.chunks_mut)-up the iterator over the relevant components. The produced chunks are bound by the lock guard lifetime, so it would require a bit of magic to move them out of the system execution body.
Thanks for clarifying!
I agree! I really liked your article, good writing!
This is actually amazing. Maybe even create a new thread to let other know!
Thanks you understand the means.
Oh. Sorry, but you weren't very clear. It's very common to have path information like that in compiled binaries. There are multiple sources of it. Macros that will print file, line where an assertion failed, debugging information. Good example how common it is: http://www.bitbenderforums.com/~grogan/kernhowto/dmesg.gif - every time you boot linux you see username and hostname where the kernel was built. C compiler will do that too. There are `__FILE__`, `__LINE__` preprocesor macros, and will pull that information every time eg. `assert` is used. https://github.com/lattera/glibc/blob/master/assert/assert.c#L101 So yeah... If you don't want these too leak, build in chroot, or on a build machine. I hope that's of any help for you.
Ah, lost that context when OP copied the same to the edit message.
After reading both a bit, it seems the biggest difference is that Askama processes the templates at compile-time, associating them with custom structs to provide the context for template fields - whereas Tera processes the templates at runtime, using Tera's own "Context" struct or your own structs if they implement the "Serialize" trait. Seeing as how the two libs seem to complement each other, I hope they keep some level of compatibility when it comes to syntax and filters. 
I exist as a counter-example for that statement. I'm very careful to handle all of my `Option&lt;T&gt;` and `Result&lt;T,E&gt;` values appropriately, but, when I work in C or C++, I do occasionally overlook something that can return `NULL` despite trying my hardest. In Rust, doing that results in a compile-time error.
Use one when you want to be able to edit your templates without having to recompile your Rust app. Use the other when you want to lock things down and don't plan on changing the templates.
Hmm... A Workaround. Thanks your help.
I haven't really thought of the recompilation being a big deal, but I guess for some it might be. Let's just hope that incremental recompilation will land soon.
Sorry, I didn't make my point clear. I am not questioning its safety, but its efficiency. Let's take a simplified model of a game engine consisting of only a physics engine and a render engine for rendering scene entities. These are also usually the most computationally demanding systems in most games. Now, the renderer depends quite heavily on the outcome of the physics processing, so it would either have to: 1. Synchronize and simply wait for the physics engine in order to lock the necessary components. When the lock is obtained, the physics engine must wait for the renderer to release its lock before doing more work. 2. Copy all the necessary data. This might reduce the need for synchronization, but it still needs to synchronize to make the copies, so you trade a huge chunk of additional memory usage for possibly only a small (or even none or negative) impact on performance. My point is that the most computationally demanding systems tend to have complex inter-dependencies, and the result is that they will more or less run synchronously even if you run them on multiple threads.
I agree, that is what I had as a first version. But Rieuxs one line solution looks a lot better.
But you can get your non-computationally demanding things off the critical path by running them in parallel. Obviously in the super simple example of 2 systems you get no performance benefit but what if you had 20 or 100 systems? You are going to end up with parallel things and with this kind of system the parallel-ness could be implicit without requiring you to maintain it.
&gt; Sometimes a naive implementation in a garbage collected language can actually be faster than a naive implementation in a language with deterministic allocations, like RAII provides for local variables. This is because allocation and deallocation has a large penalty from context switching to the operating system and coming back. "Local variables" are stack allocated in most low-level languages, so "allocation and deallocation" amount to bumping a pointer. And you can get a comparable benefit for non-stack variables simply by using an arena allocator that allows you to just delete the whole arena when you're done. Rust makes these sorts of refactorings far easier and safer than other low-level languages, so they become a natural step up after the "naive implementation". Compare this to trying to fix a "naive implementation in a garbage collected language" and make it actually efficient. 2-3x perf. differences are not negligible BTW: they can easily impact consistent user responsiveness (hence, usability) in a user-facing application, and they lead to increased hardware costs and power/cooling requirements in a server-side app.
And I wrote [a Mustache engine in JavaScript](https://github.com/maghoff/mustachio) :D Seems like we have found our respective tastes in templating languages ;)
If you are debugging std, you may want to have the filenames and lines. Otherwise, they are useless.
Ah, for some reason I'd assumed backtraces weren't available in release builds.
Yes, and that's certainly an exciting prospect! But to me it's not clear if the potential for parallelism translates to increased performance. Even though it's implicit it means that you're working with more constraints, so it's a trade-off - the question is if it's worth it. In any case, I think it's really cool that this can be done with Rust's type system, and I'm very excited to follow the development. I'm particularly interested to see what kind of experiences people make as they integrate specs into their games.
&gt; This is because allocation and deallocation has a large penalty from context switching to the operating system and coming back. Note that modern allocators do not context switch into the OS for every allocation, they chunk and amortize quite similarly to a GC and use techniques like free-lists to reuse previously-requested allocations. Even a naive implementation that just calls libc's `malloc` and `free` directly gets to benefit from this. There are of course other factors at play here, but I'm not sure that the OS context-switching is the one to focus on.
Other little-known fact: they're in `panic=abort` builds as well! They're often not as _useful_ in release builds, as you don't have debuginfo in there generally, but they do exist.
This is super cool! I've been wanting something like this for a while.
I've been working on nonblocking concurrent data structures in C and Ada SPARK lately (see https://sstewartgallus.com/git?p=uevents.git;a=blob;f=README;h=cb0c3a32d568a381d7ea0fe3c04a4ef1f883e5ac;hb=HEAD and https://sstewartgallus.com/git?p=linted.git;a=blob;f=src/ada-core/src/linted-lock_free_stack.adb;h=193305c0f3fc2ef30fd1e47682ecb5cfab3c413f;hb=HEAD .) I've been considering doing some work in Rust too.
Great work. &gt; Template inheritance (one level only) Is there any design limitation that prevents arbitrary amount of levels? My ideal template system would one that allows to compile as well as interpret templates at runtime, to avoid compile/edit cycles during development, but provide type guarantees for production. This could be achieved if template data conformed to some interface allowing introspection for interpeted runs. I often work with large sites with hundreds of templates, and its just not possible to wait for all of them to compile just to fix a typo.
You can pretty much setup the futures so that they execute immediately and wait on them to finish and return that value. It shouldn't be too hard to write a wrapper to do that for your own stuff. reqwest should fit most of your needs but if you really need that fine granularity then you'll just have to write some wrapper code for Hyper
&gt;Does "How can I stop rustc including system specific information such as absolute file paths of the source it's compiled from in the binaries it generates?" capture your question? Yes. Thanks you. &gt; It feels like this might be a bug in rustc as it could also cause problems with reproducible builds? These local file path string that looks are do nothing in compiled release binary. And these debug info should be not included in compiled release binary.
&gt; As it is, tons of people use Python Python can be quite useful even today for prototyping and more generally for writing one-off code which might be expected to change quickly, and this might explain why it's still being used in a game backend like EVE Online. I think it's worthwhile to consider what features can make even a compiled, "safe" language more useful for this sort of coding. Shorter compile times are part of the answer in many cases, and Rust is definitely working towards that goal. Another useful feature is IDE-like assistance to the programmer, enabled by a more effective type system. (Arguably, custom IDE support is one important reason why Java and C# are used as widely as they are, despite their otherwise considerable drawbacks. Dependently-typed functional languages like Agda and Idris though show how similar features can be relevant even in a rather different context.)
Some comments. (I haven't done much in Rust, so these might need to be tweaked before they're correct.) * In `keep_awake`, `sintinel` is a typo. It should be `sentinel`. However, you don't actually need the `sintinel` variable. Its only purpose is to give you a way to break out of the loop; but that's what the `break` keyword is for. ([docs](https://doc.rust-lang.org/book/loops.html)) BUT, you don't actually need `break` either. You know what condition should cause you to break out of the loop - namely, if `exit == 0 || active == 0`. So the loop could just be `while exit != 0 &amp;&amp; active != 0 {`. (I've just used [DeMorgan's Law](https://en.wikipedia.org/wiki/De_Morgan's_laws) there, to simplify `!(exit == 0 || active == 0)`.) * In `keep_awake`, it seems like `exit_after` and `active_for` ought to be optional unsigned values, right? `Option&lt;u64&gt;` instead of `i64`. That way you can represent "absence" properly, and you don't waste bits that you'll never use. Check out the [docs](https://doc.rust-lang.org/1.10.0/std/option/index.html). There are some great methods on the `Option&lt;&gt;` type called "combinators" that let you do some really neat things with them - check those out as well ([docs](https://doc.rust-lang.org/1.10.0/std/option/enum.Option.html)).
Very cool project. I was actually surprised there isn't one like it already since it seems so obvious once you see it. Thanks for sharing it. One point I'd like to bring up though. One of the nice things about dynamic languages for things like templating, is that you can make arbitrary nested structures without much boilerplate. For example, twig/php: The first value is {{ some_struct.list_field.0.value }} The second value is {{ some_struct.list_field.1.value }} I would just need to pass the rendering engine something like this: $renderEngine-&gt;render('myTemplate', [ 'some_struct' =&gt; [ 'list_field' =&gt; [ 'list_field' =&gt; [ 'I am first', 'I am second' ] ] ] ]); Where in your example, it looks like I'd need to define 2-3 different structs immediately. While it is nice to get the compile time checks, having to define new structs for every level of nesting I want to seems like it would make using it pretty cumbersome. It would be nice to be able to define multiple levels of nesting with just one struct definition. Is this something that's doable? I cannot tell from your example.
(Also, btw, you can cast a `bool` to `u8` directly with `as` no need to jump to the overkill `transmute`.)
Thanks for that. Very helpful. The reason I use i64s is because one of the crates required them in one of the crucial functions. 
One reason I have this class is to avoid heap allocations. Also, while alloca would be useful, I'm actually after something with the same effect as generic integers, just... without specifically having to have syntax for them. (I thought it might be possible by using generics, but couldn't quite work it out.)
By the way, which languages actually invented these things?
If I had to guess, Lisp or ML
Like [this](https://github.com/paholg/dimensioned) (specifically [this](http://paholg.com/dimensioned/dimensioned/macro.make_units.html))?
Well, pattern matching is at least as old as [Refal](https://en.wikipedia.org/wiki/Refal). Not even talking about Prolog, which is essentially pattern matching: the language. 
I think the popularity of F# has lead the C# team to implement similar features in their language. It helps that both C# and F# compile to the same bytecode. (edit) Some of the new features make use of a sort of type guard. In my mind this is undoubtedly brought over from TypeScript (another MS-supported language). Must be nice having all these different languages and teams working for the same company!
Have a look at [typenum](https://crates.io/crates/typenum) maybe.
Thanks to everyone for the replies.
(Author of Tera here) Replying here to that question and to /u/dochtman comment First: &gt; For a longer version, I first have to confess that I have not very deeply looked at Tera, because even skimming through the README, it did not feel like the right way to implement something like Jinja in Rust Since none of my own usecases for a template engine would be possible with Askama I would have to disagree on that :) For the differences: - **Speed**: Askama is going to be faster to render (10-100x faster than Tera) at the cost of compilation time. See https://lambda.xyz/blog/maud-is-fast/ for some benchmarks, Tera being about twice faster now. One thing to keep in mind though is that Tera renders some mildly complicated template in 10 microseconds (micro, not milli) so template rendering is very unlikely to be your bottleneck anyway. Increasing compilation time on the other hand is something I personally do not want, it's already long enough. - **Type-safety**: Askama approach is pretty neat and allows calling methods directly in the templates. There is an issue on Tera on how to keep type-safety (https://github.com/Keats/tera/issues/24) which points to the same approach as Askama. Since I wouldn't use it myself and it's a pretty huge chunk of work, it hasn't made any progress. Tera does some error checking when parsing templates but since it doesn't have the type informations it's limited to some basic sanity check. The obvious issue of type-safe templates is that it requires Rust which means it won't be usable by third parties. - **Flexibility**: It's going to be hard to match everything Tera can do in Rust code. Happy to be proven wrong of course :) I mostly write SPAs these days so most my template engine usages are the following: 1. user-defined templates 2. static site engine generators 3. extending some framework templates As far as I'm aware none of these are possible with a compiled-to-Rust template engine so I guess it depends on your specific usecase. It's also nice to live reload your templates without having to recompile anything :) A potential ideal world for Tera would be to have both modes: compiled and interpreted that you can switch on. I.e. develop using interpreted mode and compile for production but that would be a huge undertaking. 
Naah it feels very F#-y... Which feels very Ocaml-y.
Looks like people beat me to linking it, but if you have any questions about dimensioned, I'd be happy to help!
Using both is annoying now because reqwest pulls in hyper 0.10.x while you're using hyper master. But I imagine that will be resolved soon. Would you still want to replace reqwest if it didn't pull in so much extra code?
Tested it out and that did it. I always forget about using `{}` as a scoping trick for borrowing.
Coroutines are an open C++ TS so they're likely to be supported by other backends _eventually_
Well, the client bits I need are a series of simple SOAP calls, I could just move that over to Reqwest. It might be fun! Come to think of it, wouldn't be the first time my projects pull in several versions of hyper...
I installed it with the dangerous but often recommended piped command with curl. I'm using an arch-like distro, and `which rust` gives me this, interestingly: `which: no rust in (/home/me/.cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl) `
Whoops, sorry, "which rustc".
We're certainly moving in a functional direction! Right now you can't do nested pattern matches, but we hope to support it in one of the next minor releases. One of my favorite features that I wish rust would pick up is the "guard" syntax for matching: if (!(o is int i)) return; // bail from the function early WriteLine(new string('*', i)); // `i` is in scope (as an int) here
/home/me/.cargo/bin/rustc
You can write similar things in Rust: let i = if let Int(i) = o { i } else { return; } where `Int(usize)` is some enum value. Since Rust doesn't have inheritance, matching an enum is the probably most direct equivalent to something like `if (o is int i)` (except maybe `Box::downcast` on trait objects).
Was Rust the first to do _ number in literals? Everything else in the title comes from elsewhere, but I'm not sure about literals :) P.S. Does anyone else have the heart in the footer of embedded gists slightly off centre (to the right) in Chrome? It bugs me so much... 
Aren't these all the benchmarks that you are not allowed to optimize? As in you have to use the standard library implementation rather then one suited to the task.
Landin's ISWIM had tuples and nested destructuring, and Burstall extended that to pattern matching in a 1968 paper: _Proving Properties of Programs by Structural Induction_. Neither language was implemented at the time.
Java 7 added _s in number literals, and I'm sure it wasn't the first.
No. The administrator does restrict programs in various ways to allow for reasonable comparisons between languages, but for example the fastest Rust [k-nucleotide program](http://benchmarksgame.alioth.debian.org/u64q/knucleotide.html) uses the [ordermap](https://crates.io/crates/ordermap) crate instead of std::collections::HashMap.
Could we do something to lower memory consumption? It only seem fair to beat C++ in every aspect... :D
/u/nwydo did a bunch of work modernizing and optimizing several benchmarks recently, especially k-nucleotide ([previously](https://www.reddit.com/r/rust/comments/5vcrvb/rust_is_now_the_fastest_language_on_knucleotide/)), fannkuch, mandelbrot, and binary-trees. (The new binary-trees program has not been added to the web site yet.) I did a big rewrite of reverse-complement with contributions from nwydo. And all this was done with much help from /u/TeXitoi who has long maintained the [benchmarksgame-rs](https://github.com/TeXitoi/benchmarksgame-rs) repo. Notably, the new [reverse-complement](http://benchmarksgame.alioth.debian.org/u64q/revcomp.html) program is the fastest of any language by a significant margin. Unlike the old program it no longer contains any unsafe code. And it's both shorter and twice as fast! Many of the programs now use [Rayon](https://github.com/nikomatsakis/rayon) for parallel processing, and I recommend it highly for any similar task. In just a couple of lines you can split data into parallel jobs, and Rayon does the heavy lifting of scheduling them across CPU cores, using work-stealing to make efficient use of memory and caches. (Update: I'm excited to hear that Rayon is being [considered](https://internals.rust-lang.org/t/scoped-threads-in-the-nursery-maybe-with-rayon/4942) for the rust-lang-nursery, which would make it an official part of the Rust project.) Take from the numbers what you will. In practice it will generally be possible to get comparable performance from Rust, C, and C++ for most tasks of this nature. (Studying some of the fastest Go and Swift programs has also made me appreciate how good those languages can be for writing clean fast code!) For the benchmarks I've worked on, the differences between Rust/C/C++ say more about the specific programs than about the languages they're written in. But what I love about Rust is how *pleasant* and easy it is to write fast, maintainable, parallel, cache-friendly code.
KDE you can create an activity and for that activity disable sleep. Then simply use that activity for things like controlling 3d printers.
From my experience with [Bart](https://github.com/maghoff/bart) [1], which is similar with respect to how you specify input to the template, I have not found this to be possible, no. On the other hand, it is quite convenient to be able to directly use the structs that I already have defined for other parts of my code. Combining it with [Diesel](http://diesel.rs/), you can get the same structs type checked against both your database and your templates. That is quite nice :) [1]: This may also be an answer to your surprise; There is also Bart! :)
&gt; but it regressed quite a while ago and no workaround has been found. I wonder if it's because https://github.com/rust-lang/rust/pull/31545. The fix is being tracked [here](https://github.com/rust-lang/rust/issues/31681).
The code generator currently generates base templates (that is, templates that have blocks, but no `extends`) as traits, which seemed like a nice mapping of how I think template inheritance works. There might be some other way to generate something that supports multi-level inheritance, but I like the conceptual mapping of this way, and multi-level inheritance seemed at least somewhat niche. For reference, here's the inheritance test case (the structs, displayed here without attributes) including generated code (the impls) from Askama's test suite: struct BaseTemplate&lt;'a&gt; { title: &amp;'a str, } trait TraitFrombase2ehtml { fn render_block_content_to(&amp;self, writer: &amp;mut std::fmt::Write); fn render_trait_to(&amp;self, timpl: &amp;TraitFrombase2ehtml, writer: &amp;mut std::fmt::Write); } impl&lt; 'a &gt; TraitFrombase2ehtml for BaseTemplate&lt; 'a &gt; { #[allow(unused_variables)] fn render_block_content_to(&amp;self, writer: &amp;mut std::fmt::Write) { } #[allow(unused_variables)] fn render_trait_to(&amp;self, timpl: &amp;TraitFrombase2ehtml, writer: &amp;mut std::fmt::Write) { writer.write_fmt(format_args!("{}", self.title)).unwrap(); writer.write_str("\n").unwrap(); timpl.render_block_content_to(writer); writer.write_str("\n").unwrap(); writer.write_str("Copyright 2017").unwrap(); } } impl&lt; 'a &gt; askama::Template for BaseTemplate&lt; 'a &gt; { fn render_to(&amp;self, writer: &amp;mut std::fmt::Write) { self.render_trait_to(self, writer); } } struct ChildTemplate&lt;'a&gt; { _parent: BaseTemplate&lt;'a&gt;, } impl&lt; 'a &gt; TraitFrombase2ehtml for ChildTemplate&lt; 'a &gt; { #[allow(unused_variables)] fn render_block_content_to(&amp;self, writer: &amp;mut std::fmt::Write) { writer.write_str("Content goes here").unwrap(); } #[allow(unused_variables)] fn render_trait_to(&amp;self, timpl: &amp;TraitFrombase2ehtml, writer: &amp;mut std::fmt::Write) { self._parent.render_trait_to(self, writer); } } impl&lt; 'a &gt; askama::Template for ChildTemplate&lt; 'a &gt; { fn render_to(&amp;self, writer: &amp;mut std::fmt::Write) { self._parent.render_trait_to(self, writer); } } 
&gt; probably incomplete Very probably. I don't even remember how I collected it.
Okay, got it now. So yes it is the same approach. Thanks.
[removed]
The idea is that they shouldn't be implementations that are built just for the benchmarks. This is because the idea is to test the language and its 'standard' libraries as opposed to who can optimise their algorithms the best. Standard is pretty loose in this case, but it basically has to be something that's in common use.
Sadly the incremental compilation is not that great yet, I've been using it since it was released in nightly and a simple change in Tera makes the compilation take 12s instead of 17s. Better but still way too long for me to consider adding more stuff to be compiled vs &lt; 0.01s parsing with live reload. Regarding the flexibility, it's more not being able to extend some random out-of-crate template, not having unlimited inheritance, having to define structs for macros (I guess? If you intend to implement them obviously) etc. I don't think you would be able to make or extend the Django admin with compiled templates for example (I could be wrong though). In some ways, Askama is more flexible as you can call Rust methods directly but I'm more with the Django philosophy of doing as little as possible in the templates. What are your typical usecases? The Django codebases I've worked on were making very extensive use of the admin and had dozens/hundreds of templates, which would probably turn into obscene compilation times unless incremental compilation improves dramatically. Productivity-wise, having to rebuild my whole project just to fix a typo in a template would be a time sinker too. Askama is probably how I would have done a typesafe Tera though 
...... We can just do `let x;`?! TIL. 
I'm certainly interested in making this cross-platform and I've looked at GTK a bit so that I can plan around it. However, I haven't looked at Cocoa at all so I can't say if I'll need to modify my code's API to get it working on Mac. That being said, it should be a bit easier to get the other platforms working than it was for Windows. Windows provides basically no help besides the basic widgets, so I needed to do things like write a layout engine from scratch. 
Or just tick the little box in the battery applet (on a Laptop, don't know if it's there on a desktop) that says "disable power management"
Not exactly https://www.reddit.com/r/rust/comments/5rwwrv/chashmap_efficient_concurrent_hash_maps_in_rust/ddifssa/?st=iyxt4e92&amp;sh=b86eff70
It happens! I'm just glad I learned something's new so thanks for experimenting and figuring that out.
It would be nice if the paths were relative, rather than absolute. I think it's much *less* useful to see: /home/tomwhoiscontrary/src/github/initech/myapp/src/protobuf Than it would be to see: src/protobuf The location where i happened to check the project out before compiling it is completely incidental to understanding why it's crashed after i've run it.
The emergent standard around [drum tab formmating](http://www.underwaredesign.com/forums/index.php?topic=573.0) fascinates me (there's a section in there about how people have formatted triplets). I've definitely wanted to make a drum tab editor, but it's also just kind of neat that I can use my code text editor for it too :)
I proposed this for Rust in [RFC 1303](https://github.com/rust-lang/rfcs/pull/1303).
I know! I don't think I commented on the issue, but I was arguing in favor of it on IRC for a while
I agree. As far as I can tell, they simply don't benchmark clang. I didn't look to see if they have an faq or policy about it.
Perhaps you can use [backtrace](https://crates.io/crates/backtrace) crate to get call-stack.
F# is mostly taking from OCaml. There doesn't seem to be much Haskell influence apart from the stuff *ML and Haskella already shared earlier
Quick update, I prototyped a lock-free queue based on a Treiber stack, designed so one side can have no allocation, and it looks pretty good. I might keep playing with this.
Yeah, F# is mainly OCaml inspired at its core, but a lot of PL research is going on in Haskell, so I imagine some specific new ideas has come/could potentially come from there. Even if F# is in the ML family. A language can take ideas/specific features from languages outside of its immediate "family".
[removed]
That being said, it's using GCC 5, which is more than a year old.
I don't really want to slice by byte positions in case s is "漢字", for instance. Is there some way I can make it work?
Oh, right. In that case, use `.char_indices()`, get the byte offsets, and then slice.
Don't worry. I am busy myself and progress on fireplace has been rather slow (but there is still). Additionally I started working on u/levansfg 's project smithay to port fireplace eventually on top of it, which also takes a good chunk of time. I can totally understand that.
That would probably be considered cheating, even if inline assembly in Rust was stable. But the benchmarks game only allows stable Rust features, so it's out regardless.
I think any explicit use of `unsafe` in these benchmarks is hugely unfortunate. With that said, I am impressed with the current state. I suppose this would go doubly for inline assembly. I don't know the official rules on it though. Regardless, this matters not, since inline assembly is not stable and therefore cannot be used.
&gt; That benchmarks game is total crap though. Careful, careful: check the sidebar, rule (2) is "Constructive comments only". --- That being said, do note that the Benchmark Games is concerned with *idiomatic* code, not with *free-for-all* code. If it was not the case, all the C, C++, Rust, ... entries would probably heavily enlist assembly code for the critical sections. Thus, without more details about your changes, or Isaac's, it's hard to understand whether the changes were warranted or not. --- Regarding binary-trees, the C++ implementation is using OpenMP; I am not too familiar with OpenMP, but it seems to me that it only performs coarse-grained parallelization: that is, different iterations of the loop are executed in parallel, but a single iteration is executed fully sequentially. This would mean that a single slow iteration would slow down the whole program, and seems corroborated by the fact that one of the CPU is reported at 53%. The `schedule(dynamic, 1)` should help with this, but apparently does not fully. The Rust implementation, on the other hand, uses Rayon for (1) fine-grained parallelization with (2) work-stealing; as a result, all 4 CPUs are above 96% utilization. It seems to me that this benchmark is perfectly playing its role at exposing the fact that parallelization in Rust is more efficient. *Note: and maybe the `object_pool` is less efficient than the `TypedArena`...* --- Regarding nbody, Rust is currently lacking stable SIMD (and assembly is out), and LLVM does not autovectorize the code by itself, so indeed Rust can really lag behind C or C++ in benchmarks for which SIMD reigns. Until SIMD gets stabilized, it'll be luck of the draw in this regard.
That's just something made-up and spread as a-kind-of *not fair to Rust* meme. Meanwhile other people wrote and contributed better Rust programs. 
It should be possible to test this by either building a custom rustc that emits the LLVM markers or even easier comparing LLVM bytecode output between rustc versions and copying over the markers.
&gt; faq or policy *"If you're interested in something not shown on the benchmarks game website then [please take the program source code and the measurement scripts and publish your own measurements](http://benchmarksgame.alioth.debian.org/play.html#languagex)."* 
I filed https://github.com/RustAudio/dsp-chain/issues/141; we'll see how that goes.
I like your blog, what are you using for it? (You might also want to adjust your homepage: http://www.acrawford.com/ )
Oh shoot! I forgot to talk about that. I'll have to add that when I get home tonight. I'm glad you liked the write-up.
C#'s LINQ was directly influenced by Haskell though. There was an interview with a C# and Haskell developer not too long after its release, in which they explained how they collaborated. I think they also mentioned that C# ideas were finding its way into Haskell, but I can't remember what those might've been. 
This is starting to seem like an annual [re-post of false claims](https://www.reddit.com/r/rust/comments/39mqen/rust_vs_benchmarks/cs4py9g/). &gt; recently took k-nucleotide in F# and made it 3.6x faster 2013 and the program was never contributed to the benchmarks game. &gt; Binary-trees in Haskell "de-optimized by Isaac Gouy". As-before: a program which existed temporarily until Don Stewart had time to provide a program with strict allocation - so the required allocations would actually happen.
For future reference, it's not that dangerous if you don't pipe it. Just save the script somewhere, read it, and execute it if you see it's safe. It's not that different from installing things from the aur. 
The thing with SIMD is that you want good platform specific SIMD first (maybe one or two platforms) and then build higher-level SIMD that does the right thing in majority of the strait forward cases.
I often find myself having some iterator-like interface, where I can do `while let Some(element) = thing.next() {` but `next()` doesn't conform to Iterator because of lifetime issues (returned reference only valid until next call to `next()`). I understand the value of the current Iterator requirement, eg for `collect()` to work, but it'd be good to have a standardized interface for my use case as well (that works with for loops).
&gt; the Benchmark Games is concerned with idiomatic code, not with free-for-all code Why not have separate competitions for both types of code? :(
**gz** column. [how-programs-are-measured.html#source-code](http://benchmarksgame.alioth.debian.org/how-programs-are-measured.html#source-code) 
Because they are ramping up C# evolution now that people are interested in it (OSS, dotnetcore etc). C# 6 also added some cool things (e.g. expression bodied members, "int foo() =&gt; 1+1")
Ahem! Thanks! I am surprised that rust isn't shorter across the board.
It's not going to be too elegant, but I think I can make it work -- thanks.
It has and requires a garbage collector, and therefore it is a flawed design. Garbage collectors are crutches for bad language design. You'll notice that effectively all the engineering work put into Go revolves around the garbage collector, instead of the language.
Yes the lineage you want to trace is basically "[Edinburgh LFCS](https://en.wikipedia.org/wiki/Laboratory_for_Foundations_of_Computer_Science) languages", along with relative communities in [Cambridge UCL](https://en.wikipedia.org/wiki/Computer_Laboratory,_University_of_Cambridge), [Oxford UCL](https://en.wikipedia.org/wiki/Department_of_Computer_Science,_University_of_Oxford), ENS + [INRIA](https://en.wikipedia.org/wiki/French_Institute_for_Research_in_Computer_Science_and_Automation), CMU, UIUC, Princeton, UPenn, SRI and Bell Labs, lately MSR... (At some point every genealogy collapses into everyone-has-shared-influences-from-everyone)
I know I'm coming late here, but that suggests that we should be using `*` instead of `ref` to rereference in binding context. i.e. match *foo { Some(*contents) =&gt; { ... } None =&gt; { ... } }
OK. Well, the language is finished, so there's a lot less opportunity for engineering now than in the implementation (including the GC). IMHO having a GC was a good design choice in the case of Go because it keeps things simple for the programmer, which was their explicit goal.
No kidding. Send me a PM, to meet another Rustacean from the CL.
If I recall correctly, one of the things holding up language development before C#6 was the compiler. From what I understand, the old compiler was rather difficult to work with, and quite a bit of time was spent on building Roslyn.
Perhaps I have had a different experience.
the mirroring is: When you do match x { Some(y) =&gt; ... } then in `...` you have the identity `x == Some(y)`. In particular, the expression `Some(y)` inside the arm produces a value equivalent to `x`. Likewise when you do match val { *ptr =&gt; ... } in `...`, `*ptr` is equivalent to `val`. This might be clearer if rust maintained a stricter separation between T and reference-to-T, like C does. (TBH, have not touched rust recently, so not sure where this currently stands.) Bringing these together, in match x { Some(*ptr) =&gt; ... } we have `x` equivalent to `Some(*ptr)`. The problem arises with irrefutable patterns. For consistency, we'd be able to do let *ptr = val; which would mean let ptr = &amp;val; This is very confusing because of the "false relation" with the assignment syntax `*x = y` (which may suggest this assignment syntax was foolish). Of course, the real problem is that `*x` in expression context can dereference multiple kinds of thing; which kind of "reference" would be bound by `*ptr` in binding context? Perhaps the "real" solution is to allow `ref x` in expression context to mean `*x`, but only for reference (not any impl of Deref), and `ref mut x` (or whatever it is) to mean `*x`, but only for mutable reference.
For installing in a VM you’d need an actual VM, with a separate system and you’d install it there like everywhere else. If you want something like Python’s virtualenv, you’d need to install rust somewhere (eg. in `~/.cargo` using rustup), then copy/move that to destination directory, and then write some scripts similar to Python virtualenv’s `activate` which would add that directory to `$PATH`. But what’s the point? Rust projects are self-contained, and compiled do not need the toolchain anymore, so there is no reason to separate Rust toolchain for different projects – also if you add a dependency to your Rust project (through project’s `Cargo.toml` file), that library is downloaded to the project’s directory (and not installed system-wide, or user’s home-wide). And the reason behind python’s venv existence, IMO, is mainly to be able to cleanly manage project’s dependencies separately and independently from the system (make `pip install`ed libraries local to the project) – but `cargo` does that for you. And maybe to manage Python versions for a project, but `rustup` is Rust’s answer for this.
I took some of the suggestions in this thread and wrote up a [concrete example](https://is.gd/rwmr5h) for how you might return an unboxed iterator.
Isn't it premature to make a 1.0 RC on the heels of so many changes?
/u/igouy would it be possible to have a graph for this sometimes? not that its relevant for the things that the benchmarks game is supposed to show, but i think its interesting nevertheless :)
A while back I did an informal interview with him and he struck me as one of those people who are incredibly talented and smart, but humble as well. PS: Interview is here if you care to watch (starts around 1:20): https://www.youtube.com/watch?v=KnV9L5xiHt0
 I'm really not versed in this kind of stuff, so I must be wrong. Most benchmark I saw tend to say that clang++ make faster program. ( e.g. http://www.phoronix.com/scan.php?page=article&amp;item=gcc-61-clang39&amp;num=1 ). Is it generally accepted that gcc is faster ? 
clang compiles faster, gcc produces faster binaries (in general). You linked to a benchmark of time to compile. Honestly it'd be nice if benchmarks combined both dimensions &amp; put them side by side. Otherwise one might as well compare gcc -O2 to clang -O3
This seems like a lot of changes in an area that is one of the hardest in computer science (reasoning about weak memory models is cutting edge research, let alone nice ways to write code in it a language like Rust), packaged in a way that's very hard to review. It's a rather annoying request, but it'd be great to see commits broken down into simpler/smaller packages rather than just, say, [" Refactor ... the entire epoch module. "](https://github.com/crossbeam-rs/crossbeam/pull/122/commits/7fc75e8a12c62e2bb92d56f67205c07d7416928c). (E.g. I noticed that [the `participants::Iter::first` field](https://github.com/crossbeam-rs/crossbeam/pull/122/commits/7fc75e8a12c62e2bb92d56f67205c07d7416928c#diff-39adc2728702dff10ba448135944f5d4R112) is never set back to `false`, but only because it was the last change in the diff; I wonder if there are any subtler problems hiding in the rest.) (Also, I'm curious what [the "severe" use-after-free bugs were in `ArcCell`](https://github.com/crossbeam-rs/crossbeam/pull/122/commits/e1a9244ea05fa7c9ad21f1fa52cb067d221515af): avoiding `transmute` is a great choice, but I don't see how it fundamentally changed the behaviour of the code.)
This board should be able to be targeted by Zinc. I was going to look into that after I write up the hard-fault post.
I've told you before, saying this is "false" is okay, saying this is "made up" or a "lie" is not, it implies ill intent. As has been explained to you many times before, you have never really been clear about the rules here and misconceptions have spread due to that, through no ill intent. Please stop with the accusations or you will be banned from this subreddit.
Hi. I'm trying to follow your writeup. Can you please also post your .cargo/config file? I would love to get this working too. &gt; we’ll need to add "-C", "link-arg=-Tlayout.ld", into the rustflags in our Cargo config. How do you add multiple link-args? We've already added "-nostartfiles". 
Binary trees has been merged now! Faster than c++, but still behind C. I'm done for now, it takes way too much energy to get them submitted... http://benchmarksgame.alioth.debian.org/u64q/binarytrees.html Edit:static link
Did someone tried to compile prolog (aka. Horn clauses) to traits? That should be relatively straighforward, and would prove the same result in maybe a more straightforward way. I want to point out that turing completeness is not only about the halting problem, Lot's of other properties become undecidable. An obvious one is: Given a type T, is there a value of such type? Also, good luck to the guy who will decide to implementation search by types in libraries. ;)
cretonne is one being developed in Rust for fast compilation speeds. For debug builds, it could be a magnificent improvement over waiting on LLVM while still offering reasonably performant output.
You're welcome. Showing working programs in [a wide range of languages](http://web.archive.org/web/20080730204710/http://shootout.alioth.debian.org/gp4/) (not quite A-Z) was one motivation for me. The other motivation was to give those who would otherwise be tempted to draw broad conclusions from 12-line fibs something more to think about.
Actually this is against their rules too, OP wants /r/playrustservers
It's said the trait system will be rewrited with prolog logic support inside rustc compiler,so should it be easily implemented?
Good to see more microcontroller experiments with Rust :-) Your CSS could use some tweaks for mobile. The menu obscures the content when zoomed: http://jmp.sh/8WkQhK9
Rules, guidelines, my point stands.
&gt; Simple! Well not for everyone! This looks great but i guess I have lot of things to learn to be able to teach to machines like you do.
Is the predicate "is property *X* decidable" always decidable? (Hmmm... if it's Turing-complete, then the above question might not be decidable either. Intuition says we're in Gödel territory, although I'm not fluent enough in mathematics to prove it.)
&gt; All you really need are *two unbounded incrementor/decrementors with an "is zero" output each* and a FSM FTFY (Albeit with double-exponential slowdown!) One of my favorite unexpectedly Turing-complete systems. With two counters, you can check the modulus K of one of the two counters nondestructively for any fixed K by allocating one state for each 0..K-1, where each state decrements the counter &amp; increments the other counter. Adding a fixed number is trivial. Multiplying and dividing by any fixed number are also doable. With two counters, you can emulate K counters by storing 2^(a)\*3^(b)\*5^(c)... To check if a counter K is zero, see if the counter mod P_K (the Kth prime) is zero. To increment a counter K multiply by P_K, to decrement divide by P_K. With 4 counters (or 3 if you're willing to juggle), you can emulate two stacks using a similar trick - treat the value in the counter as a base S number (where S is the number of symbols). To push, multiply by S and add the new number. To pop, divide by S and keep track of the remainder. And then with 2 stacks you can emulate a classic Turing Machine, as you mention.
Haha wow that's awesome
How is a single line of code blocking an important feature? I'm confused
That's an awesome explanation, thanks! Support for both `tokio-core`'s `Handle` and `tokio-timer`'s `Timer` is now available in a new version via cargo feature flags: https://docs.rs/tokio-retry/0.0.5/tokio_retry/
http://cs.stackexchange.com/q/42198 discusses your question a bit.
I mean that line is why `Vec::new` depends on `size_of`. It is apparently hard to make `size_of` constant -- I don't know the details of why.
Neat! Thanks :)
(:
SPJ gave a wonderful talk on the history of Haskell at HOPL-III. One funny part was when he joked self-deprecatingly about his dress sense. He showed a 15 year old photo from the early days of Haskell in which he was wearing a ratty red sweater... the exact same sweater he was wearing while giving the talk. I later told Julian Seward, who is a former colleague of SPJ, this story. Julian's reply? "Was it the red one or the blue one?" (It was the red one.) Edit: I found a link to the talk: https://www.microsoft.com/en-us/research/video/simon-peyton-jones-history-haskell-lazy-class/
Hello. My first rust project is being some embedded firmware. Is the following cargo layout considered good or bad practice? src/main.rs -- firmware ARM binary src/lib.rs -- firmware ARM library src/bin/*helper*.rs -- x86 host tools for the project bin/*helper* -- symlink to target/release/*helper* Build sequence: cargo build --bin *helper* xargo build --bin my_project --target thumbv7m-none-eabi Is there a way to prevent building the lib when building bin helpers? Currently I have the following attribute in lib.rs as a workaround: #![cfg(target_arch = "arm")] Maybe there are more idiomatic ways to have custom project tasks like in make or ruby rake? These tasks are small and very project specific. Therefore, I don't like to extract them into separate projects.
Surely, though, with e.g. combining characters, `.char_indices()` is likely to cut off in the middle of what we'd logically call a character?
Feel free to do so, but I suspect it's a lot of effort. I also suspect it's not that easy to find good benchmarks. For example, imagine that we settle on FizzBuzz as a benchmark, for values of `n` in `[10**2, 10**4, 10**6, 10**8]`. What prevents me from hardcoding the full result in the binary? Then the "speed" contest degenerates to a contest of who gets the fastest I/O (ie: it's assembly). And it also becomes totally pointless. Who cares about the speed at which a program can stream a hard-coded buffer to file? So, to start with, you need a *wide* array of inputs, an upper-bound on total code size (including libraries) and an upper-bound on compilation-time (to avoid using compile-time computation pre-computing everything). You should also forbid network connections (to avoid fetching the results from a website, or using AWS to compute them). Oh, and I would also forbid FFI (except for the very language implementation runtime and standard library). If you care about measuring language speed (and not language ecosystem speed), then there's little point in having it spend 90% of its time in a function implemented in another language. That would mean `numpy` is out in Python. --- I would also randomize the inputs: ie, for each "round" of measurements, I would generate 5 fresh sets of inputs, then run this serie 5 times. Why changing the inputs? To avoid overfitting and nip compile-time computation in the bud. Of course this requires offering a way for authors to see the results of their programs on individual inputs, to be able to debug edge-cases they didn't account for. If you nip pre-computation in the bud, and avoid FFI, I think you should be able to offer a representative measurement of a specific language speed/memory. It's a lot of work though, and I've got plenty other things I already don't have the time for...
Are they supported by LLVM? That is a prerequisite for rustc support.
Thank you ! I needed that clarification.
&gt;Given a type T, is there a value of such type? This is an application of Rice's theorem right? Which does not hold for properties that are true or false for all values. I think you property is true for all types. Can't you for any type T construct a value in the following way: let f be a function from Int -&gt; T defined as f(x) = f(x). (just returning a recursive call to itself). Now f(1) is a value of type T. This will of course not terminate, but it will type check. If the type checker was capable of rejecting such programs it would solve the halting problem or Rust itself would not be Turing complete. Of course you can make the type checker reject this particular program, but you can always find a more complicated way of writing it that the type checker will not catch. But in general Rice's theorem says that any "interesting" property is undecidable, where interesting means that it is not always true or always false, and it is in some sense a semantic property and not a syntactic one i.e. "this type is longer than 10 characters" is not "interesting".
/r/playrustservers
https://doc.rust-lang.org/std/sync/atomic/fn.fence.html seems like the closest? Although this is a very low level construct for which there might be better alternatives, if you understand what it's currently used for.
In your mind "made up" may imply ill intent, but people [confabulate](http://dictionary.cambridge.org/us/dictionary/english/confabulate) all the time without there being implication of ill intent.
If you add an example of what you consider to be a "real" regex benchmark that might become a constructive comment ;-)
If you want to force the language to use the regex engine, why not do something like [this](http://blog.burntsushi.net/ripgrep/#subtitles-no-literal)?
Sure, it has a name, streaming iterator. For example https://github.com/sfackler/streaming-iterator Though its trait is limited to output elements that are references. It reflects how Rust's type system cannot express this more generally.
I think a real regex benchmark might fall outside of the benchmark game. It's more a benchmark of regex engines &amp; what constitutes a regex varies (ie, should it include back references?) So to say "benchmark regex" is a bit inaccurate, there'd have to be "benchmark backtracking regex" &amp; "benchmark DFA regex". &amp; backtracking regex would have to be regexes which are not able to be run by DFA regex Then there's the matter of feasibility. [Mail::RFC822 is probably too far out](http://www.ex-parrot.com/pdw/Mail-RFC822-Address.html) In a way regex is its own language, and any pressing benchmark of it will get into the benchmark being cases optimized for by the tradeoffs of the engine being used by the program 2 regex classics: `/^1?$|^(11+?)\1+$/` relies on backtracking to determine primes /^[a-zA-Z0-9.!#$%&amp;'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/ is a simpler email regex proposed by w3 So what am I trying to get at? I'm not sure. General benchmarking is hard &amp; regex is a fluid beast to come up with a good set of specific expressions [CPython's regex benchmark](https://github.com/python/cpython/blob/c20740109d59847ef3c7bfcb968e8c8fe019928a/Tools/ccbench/ccbench.py#L79) [Some random benchmark between perl/python/ruby](http://snowplow.org/martin/rebench) [Some regex benchmark on sourceforge](http://sljit.sourceforge.net/regex_perf.html) with [discussion on python-speed](https://mail.python.org/pipermail/speed/2016-March/000311.html) The last one seems good-- benchmarking regex needs a suite
I'm here the consumer of the ring buffer. The producer itself is the kernel module where the actual ring buffer data structure is modelled. How about implementing a Linux kernel module in Rust? 
I know about `!` but it's not a proper type (yet?). You cannot write `Option&lt;!&gt;` for example. In Rust, OCaml and Haskell you can type `fun () -&gt; None` as the polymorphic `unit -&gt; 'a option` type where `'a` is a type variable. But in Scala `None` actually has the monomorphic type `Option[Nothing]`, which is a subtype of `Option[Int]`, etc.
Didn't know about if let, thank you. The loop is there so I can make an early break from a block of code, kind of like `do { } while (0)` in C.
 enum Void {} This is a type with no values.
`alert!` is my personal favorite so far. [This comment](https://github.com/rust-lang/rfcs/pull/1869#issuecomment-285875573) gives a good reasoning. Also those exclamation mark looks nice with `alert`!
After reading through some of the docs, I didn't really get how PumpkinDB enables this mode of operation. Where is the event log? How do you manipulate it? How would the program state be constructed?
Practically speaking there are very few implications. This does not imply Rust is unsound. If you're just programming in Rust, and even if you're trying to do type-level programming like I show here, then the only implication is that Rust will sometimes have to reject potentially valid programs which cause it to hit the recursion limit inside the compiler. And of course if your program causes it to do so you can always raise the recursion limit with `#![recursion_limit = ]`.
Excellent work! As I read through I thought "That won't work, because XYZ" - and XYZ was invariably exactly the next thing you added. You clearly worked through this the same way I did. Check out https://github.com/thejpster/stellaris-launchpad for an example that works with the Cortex-M4. I'm trying to share crates with @japaric and the rest of the #rust-embedded team where there's commonality, to try and drive to some sort of consensus on what embedded ARM Rust should (or could) look like, so please do take a look. 
Last I checked Zinc.rs was pretty dead. Check out https://github.com/rust-embedded for the latest on embedded Rust.
Supported in what sense? The key thing is the ABI - which arguments go in which registers, etc - and on ARM I think everyone does it pretty much the same way (i.e. arm-none-eabi). If you can munge the OS's headers into some rust "C" linkage externs, I think it would work.
There is an interesting recent paper (draft?) co-authored by Peyton Jones about retrofitting linear types to Haskell. It mentions Rust, as an example of a language which uses "uniqueness types", which are similar to linear types. https://www.microsoft.com/en-us/research/publication/retrofitting-linear-types/
[Does this work?](https://play.rust-lang.org/?gist=4e5fdc51c5f1e890d0e71a73e57da7eb&amp;version=stable&amp;backtrace=0) It required poking at lifetime annotations a bit, so it might not still meet your requirements.
Yes that definitely works, but I knew that and should have included that in the explanation. That was not an acceptable limitation because it makes the callback, which ought to be generic over the lifetime, not generic over the lifetime. My question is specifically about making a callback that is generic over the lifetime.
I think the `if let` will take care of that though, unless you're doing something else with the `parent` that needs it.
Have you disabled triple buffering?
Haskell does have a bottom type, its written _|_ and pronounced 'bottom'.
&gt; It does not have subtyping relations with the other types though That's kind of the point though. Even in Java I can define types that will never be inhabited, as in: public class A { private class B{}; B test(){return null;} } What's useful about a traditional bottom type is that I can use expressions with this type in any place. &gt; But `!` will be promoted to a real type soon. BTW, what's the rationale for that? What's the advantage compared to using an unrestricted type variable?
https://wiki.haskell.org/Bottom Would make it a link but I'm on mobile and don't know how.
Supported as in does clang/LLVM build on them?
Yeah, that's another good idea, any time you want have a bit of code you can't move into a function you can ALWAYS move it into a macro haha. For some uninteresting reasons, using a macro meant I had to repeat some code more than I'd like, or make many individual macros and it wasn't a very attractive solution. In general, that's a good idea though
Ah, someone asked before what my Cargo.toml looked like. There is a line in there that tells Rust to abort on panic. Without that config option, it's going to try to unwind the stack. I'll have to add that to my post.
The page you cite talks about "bottom" as "_a computation which never completes successfully_" (quoted from that same page). Where did you see it was a type? It's not even a construct of the language, just an informal concept.
Yes, but in practice it'll err on the side of caution and terminate once it hits the recursion limit.
You might want to check out the benchmarks in Rust's regex crate. It includes pcre, pcre2, re2, tcl and oniguruma. Benchmarking regexes is very hard. Splitting them based on implementation doesn't seem right, although the analysis involved in the benchmark should certainly address that.
Or https://crates.io/crates/measurements. 
I am confused when I read this part of FAQ: https://www.rust-lang.org/en-US/faq.html#why-are-there-multiple-types-of-strings &gt; If the function does not care about the string type, and wants to handle the two possibilities uniformly, use Cow&lt;str&gt; as the input type. I'd just default to `AsRef&lt;str&gt;` if I don't care about owned-ness and want to take both `String`/`&amp;str`, but is this considered unidiomatic? Taking a Cow will require user to convert `String` or `&amp;str` to `Cow&lt;str&gt;` (and should add small runtime cost due to branching between `Cow::Owned` and `Cow::Borrowed`).
Oh, I almost forgot to ask. Given that this uses a CC-BY-NC license to enact a "pay if you're going to use this commercially" licensing structure, can anyone recommend a competitor that passes the OSI's [No Discrimination Against Fields of Endeavor](https://opensource.org/osd) rule? (ie. What's the most Rust-friendly-for-someone-inexperienced-with-debuggers thing like [DDD](https://alternativeto.net/software/ddd/?license=opensource) or the [Qt Creator](https://doc.qt.io/qtcreator/creator-debugging.html) or [Code::Blocks](http://wiki.codeblocks.org/index.php?title=Debugging_with_Code::Blocks) debugger plugins which properly complies with the OSI's open-source definition.) I don't mind others using this if they don't mind that requirement, since it just means more and better libraries for me, but it's too much hassle for me to maintain a list of "things I can only use and recommend freely for non-commercial projects" and avoid building a habit of using them. (It's also nice to stick development tooling that at least has the option of showing up in the distro package repositories, whereas the [DFSG](https://en.wikipedia.org/wiki/Debian_Free_Software_Guidelines) explicitly mentions commercial use as an example in its phrasing of "No Discrimination Against Fields of Endeavor".)
Can I be Mexican too?!????!!!
`alert` makes me twitch, coming from JavaScript.
`eprintln!` gets my vote. I'm hesitant to assign a meaning to the macro beyond "print to stderr."
Oh i just tried to open the rustc file instead of calling it in my terminal. Rookie mistake lol
&gt; is this considered unidiomatic? No, I don't think that's what this section meant to imply. If you're not holding onto the string then `AsRef&lt;str&gt;` is better. `Cow` is more useful for when you're holding onto the thing but you want to be variant over ownership, and don't want to lift this to a type parameter. When I take `Cow&lt;str&gt;`, I prefer to be generic over `Into&lt;Cow&lt;str&gt;&gt;` so the conversion isn't on the user. The cost of matching is negligible, even more so if you consider the cases where the compiler can know which variant it is (and thus elide the branch). It's too bad the layout of `String` and `&amp;str` (or `Vec&lt;T&gt;` and `&amp;[T]`) aren't compatible because the compiler could potentially disregard the match in cases where the variant doesn't matter, such as converting to `&amp;str`. But alas, `String` goes `{ pointer, capacity, length }` where `&amp;str` goes `{ pointer, length }`, so you can't just transmute the former to the latter.
"SDK" is a really loose term, but generally you have to have a big enough software project that it warrants an entire set of libraries created to interface with it, and the Rust ecosystem just hasn't gotten that far yet, as far as I know. You could argue that, e.g., [Rocket](https://rocket.rs/) or [Iron](http://ironframework.io/) are SDKs for the web, but they self-describe as "frameworks". [Piston](https://github.com/PistonDevelopers/piston) comes close, but it's more of a loose collection of game-oriented libraries with some interoperability. There's just nothing that's "batteries-included" enough that I would call an SDK in the Rust ecosystem; it's all very peacemeal, which isn't necessarily a bad thing. With an SDK you have a large number of APIs that all have to evolve together in some organized fashion, which requires immense oversight, or else development fumbles around in the dark and you get a mess of APIs lacking many common paradigms and all using different incompatible types that break arbitrarily (I'm sure everyone reading this has had a number of examples pop into their head). I think Rust has a good thing going so far; there's some flaws, sure, but there's room to grow, too, which is something traditional SDK architecture can't really claim, I think.
Okay. Thanks for the info. 
Sure, _depending on what you mean by SDK_. I'm going to interpret it less as 'just' a library, and more as a collection-of-tools-needed-for-developing-software-on-a-particular-platform. Rust's standard library is an SDK of sorts for platforms that have a particular, minimal set of capabilities (particularly, platforms that support heap allocation, networking, and have a file system); the [`core`](https://doc.rust-lang.org/core/) library is a subset of `std` for more limited platforms. The [`os`](https://doc.rust-lang.org/std/os/) module contains operating-system-specific routines. As a whole, the [Redox ecosystem](https://github.com/redox-os/redox#-ecosystem-) forms something of an SDK for [Redox OS](https://www.redox-os.org/). 
Rocket.
Great. 
A warning: object-orientation (in the Java sense) is a paradigm that often transfers poorly to Rust. The rust language really accommodates data-oriented (as opposed to behavior-oriented) approach of design. Rust has a growing number of opinionated frameworks. [Rocket](https://rocket.rs/), for designing web applications; [Diesel](http://diesel.rs/), for ORM and database queries; [Rayon](https://github.com/nikomatsakis/rayon), for data parallelism; [Adaptron](http://adapton.org/) for incremental computation; [Timely](https://github.com/frankmcsherry/timely-dataflow) for dataflow, [error-chain](https://crates.io/crates/error-chain) for error-handling, [Conrod](https://github.com/PistonDevelopers/conrod) for implementing GUIs; [futures](https://github.com/alexcrichton/futures-rs#futures-rs) for futures; and [Tokio](https://tokio.rs/) for asynchronous networking--to name a few.
Interesting. I never had seen it that way
"Error macro" makes me think it's some sort of `Result` helper. For those not quite sure it's essentially `println!` for stderr.
I've just started learning C# (for work). People says it's like Java. But looking around it's kinda a Counter to java. With java people relatively thin on language features where's C# has features coming out it's ears.
You'll never be able to force Rust to become object-oriented. It's best to give up that idea completely. The data-oriented design of Rust encourages safer, more efficient, and produces re-usable generic code through the use of protocol-oriented and functional programming. For application development, just pick whatever OS-specific crates that you want from Crates.io. There's cocoa bindings for Mac OS X, gtk-rs bindings for Linux, and there's some Windows libraries for interfacing with Windows components. As for non-OS-specifc, there's a ton of those. For web applications, there's Rocket as a high level framework that takes advantage of Rust's macro system. It bundles most of what you need for web development, but it's still a WIP. There's also domafic which you can use to jumpstart WebAssembly development for the frontend.
Wrong thread?
Thank you!
Yeah, but then I'd have to check that mark to stop running scripts on your web page since I don't want to have to click OK every time
Wouldn't it make more sense to allow optionally passing `std::io::stderr` (or any other stream) to `println!`? For example Python3 has a `print(..., file=sys.stdout, ...)` default argument, so I can write `print(x, file=sys.stderr)` or `print(x, file=my_stream)`.
That exists and is called `writeln!` (well kind of, since it returns a Result).
What do you mean? In the compiler's internal representation? Do you have a source? That would be interesting.
I like `alert!` for the same reasons. Same length as `print!`, says what it does not how it does it (seriously, we print to stdout why would we have to error to stderr), avoids the {,s,f,v}print{,f} bullshit from C.
`rcdom` puts entire nodes inside `RefCell`, so you need to borrow that refcell to do *anything* with a node. As you found out, this is often very inconvenient. Things get somewhat better if a node is not inside a big `RefCell` but each of its components that needs to be mutable is in its own cell (of various kinds). You can write your own tree data structure to do this, or use [Kuchiki](https://github.com/SimonSapin/kuchiki). Note that `rcdom` mostly exists so that html5ever can run its own tests, it does not aspire to provide to be convenient to use as a general purpose library.
This is what I ended up with: let mut is_script: bool = false; if let Some(ref e) = node.parent { if let Some(parent) = e.upgrade() { let ref parent = *parent.borrow(); is_script = match parent.node { Element(ref element, ..) =&gt; { element.local == *"script" } _ =&gt; false, }; } }
You sound like me. I did the same thing in a Java subreddit. Heads up, don't order from Spreadshirt. The quality was bad. If I were to do it again, I'd just do it myself anyway. It looks fine after a touch up though.
He is a pretty cool guy.
This is one of those questions where you don't know which Rust its about, and whether to redirect to r/playrust or not.... The thing that made this post unambiguous is its mention of "VS".
Thansk for your answer ! I'm pretty new to the " dark side " of setting up languages, paths, environment variables, so it's helpful :)
Hm, since we're in the Rust Language subreddit, I thought it would be pretty obvious ... My bad, but I can't correct my title.
This is not possible in rust at the moment, as far as I know. The type that you would like to give `wrap_callback` is (using pseudo-syntax): fn wrap_callback&lt;'a, A, R, F&gt;(mut f: F) -&gt; LuaCallback where A: FromLua, R: ToLua, F: 'static + for&lt;'a&gt; FnMut(&amp;'a Lua, A&lt;'a&gt;) -&gt; R&lt;'a&gt; where `A` and `R` are higher-kinded types (they would be of kind `Lifetime -&gt; Type`) and the `ToLua` trait definition would look like this for example: trait ToLua { // note: Self takes a lifetime parameter fn to_lua&lt;'a&gt;(s: Self&lt;'a&gt;, &amp;'a Lua) -&gt; LuaValue&lt;'a&gt;; } This appears to be what the `ATC` proposal is about, so it should become possible in the future (although perhaps with different syntax)
&gt; The data-oriented design of Rust encourages safer, more efficient, and produces re-usable generic code through the use of protocol-oriented and functional programming. In "data-oriented" programming languages (e.g. Halide, Jai, ...) you can switch the data-layout of slices and types from SoA to AoS and vice-versa by just changing one single line of code _in your whole program_. You can even change it on a library without breaking downstream code... Have you tried benchmarking any real rust program for two different fundamental data-structure layouts, say SoA vs AoS ? Rust ecosystem doesn't even have a `SoAVec&lt;T&gt;` that's a drop-in replacement for `std::Vec&lt;T&gt;`... Trying a different memory layout that might be slower in Rust is comparable in effort to doing a whole program (and whole dependent crates) rewrite... for something that might not even be worth it... Rust is great at many things, and I agree that _Rust is a data-oriented language_, but IMO it is actually pretty horrible at data-oriented design. Just because its as bad at it as C doesn't mean its good. But I don't know, maybe you were being ironic or joking... 
Actually no, that's the CEO of my company :P. Sorry for the noise, he was making a joke that only I would get because he saw me having a technical discussion on reddit.
Thanks, I'll check that out!
I guess that my point can be summarized in two arguments: - Rust is a data-oriented language, - Rust has some capabilities for abstracting about data layout but these are very primitive. It encourages to structure programs around data, and how to process it, and it offers some primitives for "abstracting" over data-layout, e.g., both a `Vec&lt;T&gt;` and `[T; N]` can be, for processing purposes, abstracted as a `&amp;[T]`, but that's more or less about it. SoA / AoS layout is a pain point of Rust abstraction capabilities when it comes to data, but Rust also has other pain points when it comes to data processing. For example, the iterator abstraction works great for sequential data, but external iterators for e.g. hierarchical/multi-dimensional data (trees, tensors, ...) are both harder to implement using iterators because of ownership (e.g. one typically needs to use state machines for indices and random-access on slices), and have bad performance in general (without heavy fine tuning), mainly because compiler backends in general (not only LLVM) can "easily" optimize nested loops, but they cannot transform the state machines that results from the external iterators that generate the indices into a sequence of nested loops that they can afterwards vectorize, not even in "trivial" cases. In practice this means that optimizing data-oriented applications in Rust is not worth it for the single threaded case, because trying out new data layouts or data-access patterns requires too much of an effort. Yeah people go for Rayon, throw 12 threads, see an 11x speed-up and are hyped at how great Rust is. But someone replacing an external iterator with an internal one can get 10-100x speed-up for the single threaded case (due to auto-vectorization), and 110-1000x speedup when going to those same 12 threads. I don't know, for me performance is "hierarchical" in nature: good data-layout, good explicit and implicit vectorization, good shared-memory parallelism, good distributed memory parallelism. Rust has a good foundation for shared memory parallelism, but the data-layout part is left in limbo, and SIMD is left either explicit to the user, or left up to LLVM which only understands Rust idioms in simple cases. At distributed computing Rust is as good as everybody else (everybody just use FFI with C for some distributed memory library, e.g. ZeroMQ, MPI, etc.). 
Right, that parameter shouldn't be there. 
The title prefixed with `[Windows]`, it's not ambiguous.
Jokes are not allowed on Reddit. As a CEO, he should know that. Now get back to work, you only have a single lifetime to care about.
Every few days or so there's someone who posts something about the game here, so that's why /u/est31 pointed out your post as being rather ambiguous regarding which subreddit it belongs to. You didn't do anything wrong :)
Say there's a function returning a Result&lt;Something, ErrorMessage&gt;. I call the function and I want to: - Bind the unwrapped Something if it's Ok - Print the error message and end the function (return 1) if it's Err In C, it would probably come down to something like this: char *str, *error; str = get_str(error); if (str == NULL) { printf("Something bad happened: %s", error); return 1; } /* Continue with str */ Is there a nice way to do this in Rust? So far I've found using match, but that forces me to enter a new scope, which gets ugly if I have to call multiple functions like this. EDIT: I think I found a pretty way using let and match together: let something = match get_something() { Ok(something) =&gt; something, Err(msg) =&gt; { println!("Error: {}", msg); return 1; } } I thought this would make something be bound to 1 in the Err(msg) case, but it seems that return always returns the function, not the expression it's in. Is this the prettiest I can get?
Rust the video game seems to support Windows, macOS and Linux, so probably it's still ambiguous :D
You can change the `CARGO_HOME` variable. However, what I did was to move the `C:/Users/&lt;Me&gt;/.cargo` and `C:/Users/&lt;Me&gt;/.multirust` folders to an other drive and leave links to the new locations. In my case, `C:/Users/&lt;Me&gt;/.cargo` is a link pointing to `Y:/Tools/Rust/.cargo` etc. Found out about those variables after my memory ran out.
This is causing problems: if (self.closure)(val) { self.iter.next(); Some(*val) // trying to move borrowed value! } else { None } You could either restrict the `Item` to `Copy` or `Clone` or... just remove that line! if (self.closure)(val) { self.iter.next() } else { None } But unfortunately, this also doesn't compile, because Rust thinks the `val` is still borrowed when you call `next()` (this should be fixed with NNL (non-lexical-lifetimes)). Anyway, the workaround is to move the call to `next` to outside of the match: let ok = match self.iter.peek() { None =&gt; false, Some(val) =&gt; (self.closure)(val) }; if ok { self.iter.next() } else { None } You can even shorten the `let ok` to: let ok = self.iter.peek().map(&amp;self.closure).unwrap_or(false);
Haha, it was pretty bad, I was supposed to be having fun at a party but instead I was having work related technical discussion, so he decided to troll me until I decided to join the party. It worked :P
☕ + 🔧 = ®
But what use is a mug if it only holds solid amounts and not liquid amounts?
Besides from Rust-specific answers, as a general workaround you can use [NTFS directory junction points](https://en.wikipedia.org/wiki/NTFS_junction_point) which are essentially same to symbolic links in Unixes (but limited to directories). For example I have used this workaround to move [blockchain databases](https://en.bitcoin.it/wiki/Data_directory) to another drive.
[logs-201612-201703](http://benchmarksgame.alioth.debian.org/download/benchmarksgame-logs-201612-201703.zip)
My problem with alert is that it's not clearly defined as an error. You could alert someone to them being the millionth prize winner or something and that's a positive. Alert is ambiguous whereas eprintln would clearly say hey this is an error being printed to stderr. That's how I look at it at least.
If we used stderr for errors only and stdout for normal output only, I'd agree with you. But stderr has pretty much become the channel for informing or alerting users of information that doesn't belong in the pipeline. Stderr doesn't mean error anymore, it means information that is only relevant to someone watching, but irrelevant to something consuming.
Yeah I know about hyper and httpie. it's just a project for learning purposes.
In this case, I think your best bet for making this code prettier would be with [macros](https://doc.rust-lang.org/book/macros.html)! They can be somewhat intimidating to get into, but the tl;dr is that they take some form of input, and expand that code based on the macro rules into some, more complex piece of code. If you use that pattern a lot, the following macro would allow to re-use it more easily: macro_rules! print_err_ret { ($result:expr) =&gt; {{ match $result { Ok(a) =&gt; a, Err(e) =&gt; { println!("Error: {}", e); return 1; } } }} } Then, if you needed to use that code you could just do this: let something = print_err_ret!(get_something()); That being said, returning an integer error code isn't exactly the most idiomatic way of returning from a function early in the case of an error. If you aren't handling the error right there in your code, the best way is to use the `?` operator and modify the function containing `let something = ...` to return a `Result&lt;SuccessTy, ErrorTy&gt;`, like so: fn operate_something() -&gt; Result&lt;Something, MyError&gt; { // Returns from operate_something() if get_something() returns an error. // Otherwise put the value in Ok(something) in the something binding. let something = get_something()?; Ok(transform_something(something)) } Using the `?` operator essentially takes the expression that's provided to it (here, `get_something()`) and expands to the following code: let something = match get_something() { Ok(something) =&gt; something, Err(err) =&gt; return Err(err) } The main advantage to this approach is that the function calling `get_something()` doesn't actually take an opinion on how the error is handled - that responsibility is passed up to the function calling `operate_something()`. 
This was also what people did before Steam got support for separate install locations. 
Unfortunately (from docs): &gt; The 3 is no longer there, because it was consumed in order to see if the iteration should stop, but wasn't placed back into the iterator or some similar thing.
This... this solution is so elegant and simple. I tried `is_some()` etc, but I didn't think about bool... Thanks!
No, I don't care about what you _say_ you mean, only about what the apparent meaning is. Anyway, I don't have the energy to argue with you. Bottom line: don't do it again. You have plenty of other options open to you, including usage of the word "false", and just asking the mods to handle it.
Definitely the next step, I just wanted to get the code out there first.
It cannot work otherwise, except in languages where all iterators have a "peek" or "push back" functionality. Example in Python: &gt;&gt;&gt; import itertools &gt;&gt;&gt; it = iter(range(10)) &gt;&gt;&gt; list(itertools.takewhile(lambda v: v &lt; 5, it)) [0, 1, 2, 3, 4] &gt;&gt;&gt; list(it) [6, 7, 8, 9] 
But what does that mean in the context of `Result&lt;String, Self::Error&gt;` where `Error = !`? Or is there a more compelling example?
Oh, so macros are pretty close to C precompiler macros. I thought they were like functions, so that return would return from the macro, not the function. Really cool. Wow, using ? and returning a Result looks a *lot* neater! I had something like this (context: small command-line tool): fn run() -&gt; i32 { /* Do stuff, print message and return 1 on error using match */ 0 } fn main() { process::exit(run()) } Now it's like this (boxed error [so that all sorts of Result types can be returned](https://doc.rust-lang.org/book/error-handling.html#error-handling-with-boxerror)): fn run() -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { /* Do stuff, use ? when dealing with Result */ Ok(()) } fn main() { if let Err(msg) = run() { println!("Error: {}", msg); process::exit(1); } } Thanks a lot for your explanations!
It means that you can cast it to `Result&lt;String, SomeErrorType&gt;`, which makes it useful in cases like `try!` (of course, try uses `From::from` anyway, so you don't really need a magic coercion here)
I've also had problems installing rustfmt using cargo with the current nightly, so I guess you're not alone.
You are most likely running into https://github.com/rust-lang/cargo/issues/3819.
Cool. When I tried to build with cargo, it crashed right after printing it's "downloading" message for the first lib. I've had success with nightly-2017-03-04 though.
&gt; what does a lifetime mean when it is specified in trait and on some references? A useful starting point is to think of lifetime parameters as just another kind of type parameter: a type which gets determined at its usage site and that applies concretely throughout the body of the definition. (The main difference is that lifetimes have [variance](https://doc.rust-lang.org/nightly/nomicon/subtyping.html), but that doesn't really matter right now.) Let's say you have a trait with a type parameter and a function that uses that parameter trait Trait&lt;T&gt; { fn func(t: T) -&gt; (); } In this case the type parameter `T` will be chosen by the usage of the trait, e.g. an `impl`, and then `func` will only accept values of whatever `T` _actually is_. struct S; // trait type parameter is i32 impl Trait&lt;i32&gt; for S { // so cannot accept anything other than i32 as a parameter here fn func(t: i32) -&gt; () {} } Lifetime parameters work much the same way. They're specified at usage and then hold concretely afterward. So if your trait has a lifetime parameter too trait Trait&lt;'a, T&gt; { fn func(t: &amp;'a T) -&gt; (); } Then the `impl` behavior is similar struct S; // trait lifetime parameter is 'a impl&lt;'a&gt; Trait&lt;'a, i32&gt; for S { // so cannot accept anything that lives shorter than 'a here fn func(t: &amp;'a i32) -&gt; () {} } For example static i: i32 = 3; // 'a is determined by the use of this function and is longer than any reference created inside fn test&lt;'a, T: Trait&lt;'a, i32&gt;&gt;() { let j = 3; // say this has lifetime 'j T::func(&amp;i); // this line is okay because 'static is longer than 'a T::func(&amp;j); // this line is not because 'j is strictly shorter than 'a } So within that function `'a` is fixed to some lifetime and anything passed to the function must adhere to that fixed lifetime. &gt; it seems that when I call test1(), it borrows t up to the end of the function, right? Why is that? All of the above also applies when you put the lifetime on `self` as it's just another function parameter. Looking at your example declarations trait Test&lt;'a&gt; { fn test1(&amp;'a self) { } fn test2(&amp;self) { } fn poke(&amp;mut self) { } } fn test&lt;'a, T: Test&lt;'a&gt;&gt;(t: &amp;'a mut T) { ... } By the trait declaration, the only value that can be used when calling `test1` is `'a` (or something longer than `'a`), which is the lifetime of the trait itself. Within `test`, `'a` subsumes the full scope of the function body. So even though you have `{ t.test1(); }` the inner scope doesn't matter - the only value that can be used to borrow `t` when calling `test1` is `'a`. Therefore the immutable borrow must extend for the rest of the function and prevents the subsequent mutable borrow. In this particular case you can use [higher rank trait bounds](https://doc.rust-lang.org/nightly/nomicon/hrtb.html) to change the declaration of the function such that the inner scope does what you expected. fn test&lt;T&gt;(t: &amp;mut T) where for&lt;'a&gt; T: Test&lt;'a&gt; { // works as before t.test2(); t.poke(); // now also works { t.test1(); } t.poke(); } Roughly speaking this lets the body of the function decide what `'a` should be when calling `test1` since we have said it works "for some `'a`".
I found the IRC message format simple enough that I decided to forego a parser library and just do a handwritten parser. I would typically use a library like nom for parsing, but didn't feel the need to add the extra dependency this time. 
* `error_println!` * `std::println!`, `std::error!` * `std::println_err!` (would cause a tab complete hit every time, but also associate through a common prefix) I don't think logging should remove the good names for a more common occurrence. It would make more sense for logging to happen through `log::warn`, `log::error`, etc.
That's right, I had forgotten about that property of Rust – did not realize it made things nicer variance-wise. My second point still stands though :\^)
I'll send you a PM!
Ah, I thought using `$row as Queryable&lt;T&gt;` would imply `$row: Queryable&lt;T&gt;`. Awesome, that indeed satisfies the compiler. Thanks!
Wow, that reply was fast! I just thought about giving you a note about it, so you can use it in substudy, but you beat me to it. &gt; Feel free to link against my vobsub crate Yeah, that will be the next step. I just wanted to do that refactoring step first before integrating other formats. &gt; Rust doesn't really have the kind of shared library support required to relink an application binary against a newer version of a library. I wondering how that was handled that too.... Thanks for the pointer, I will look what I can do about it. My intention is to make my project copylefted but allow proprietary applications to use it.
Cool project! I don't know how hard it would be (maybe very hard) but a subtitle aligner based on the video audio would be awesome. But maybe it needs speech recognition, which would be language-dependent and hard @o@
&gt; Yeah, that will be the next step. I just released [`vobsub` 0.1.2](https://docs.rs/vobsub/), which has fixes for all the panics found by fuzz-testing it with over a *billion* malicious and corrupted inputs. ([`cargo fuzz`](https://github.com/rust-fuzz/cargo-fuzz) is awesome.) Please use that as a minimum version. And please don't hesitate to ask for any tweaks you need! (Also, if you'd like help fuzzing your subtitle parsers, I'd be interested in tackling your `*.srt` parser at some point and maybe sending a PR. I need a robust one.) &gt; My intention is to make my project copylefted but allow proprietary applications to use it. [The GNU Classpath project](https://en.wikipedia.org/wiki/GPL_linking_exception#The_classpath_exception) shows one popular way to handle this. As far as I know, this works fairly well for languages like Rust with messier linking issues.
Yes. To roll back the latest working nightly: `rustup install nightly-2017-03-04`. Then `rustup override set nightly-2017-03-04` or `rustup default nightly-2017-03-04`. 
If you use rustup you can set the --prefix to any location 
&gt; Given a type T, is there a value of such type? Can you explain this for person who has no knowledge of PLT?
You've got kind of a weird thing going on here. You have both a `lib.rs` and `main.rs`, and `main.rs` declares `mod graph;` but not `mod life;`, which is what's causing the error. Generally if you're building both a library and a binary, you have the latter import the former, so in your `main.rs` you would have extern crate conway; use conway::graph; fn main() { let x = graph::Graph::new(); } And then in your `lib.rs` you'd need to make your `graph` module public: mod life; pub mod graph; So your `lib.rs` and its submodules encapsulate all the functionality, while your `main.rs` serves as a shim to call into the library. Edit: the crate name is `conway`, not `gol` 
Your main problem is you have both a lib.rs and main.rs file! The program is having a hard time determining if you're a binary or a library but I think it's defaulting to a library. If you remove your lib.rs file and place `mod life;` at the top of your main.rs file it should compile and you'll be good to go! While you can have a library and binary in the same directory it usually causes a bit of confusion with setting up cargo right and is usually not what you want to do. Since this is a Game of Life program I figured you'd want it to be an executable rather than a library. It can be a bit hard to figure out how it all works. I actually used to do this all the time too when I first started out. I always thought that you needed a main.rs and a lib.rs file, but it turns out you don't!
Looking at the parsing code, it's quite long and it seems nom would do a good job making it short and concise.
Both is totally fine, and arguably idiomatic for a bunch of reasons, including testing. It's even in the new book. The key is to keep your binary small and hav it use the library, not giving it submodules of its own.
As a rule of thumb, if it's not in the function's signature, code outside the function doesn't know that it exists.
For me, the #1 advantage of `Result&lt;T, E&gt;` and `Option&lt;T&gt;` is that I know exactly what I'm getting. Exceptions present a hidden (and possibly more prone to change) part of the API definition that may require a code audit to discover unless every dependency in the call tree had sufficient discipline when documenting their APIs. With Rust, the function signature encapsulates every response which I should handle for properly robust operation.
Hmmmm. I can see that. At this point we're all just bikeshedding, but I'm more inclined to eprint since it's dedicated to stderr which is the channel it's being output on and would be less confusing to new users in the sense that many people know what stderr is and alert isn't something commonly used for it or at all as far as I know.
Oh we're *hella* bikeshedding lol. eprint is fine, and I'm sure that's what will get chosen.
Yeah, that pattern is quite common. See here: https://rust-lang.github.io/book/second-edition/ch13-03-improving-our-io-project.html
From the votes that's what it looks like. This isn't the Error Macro Naming Crisis v2017 for nothing!
Very opaque. I'd rather just write a quick Python script to generate lines of rust code and paste them into my source. Less likely to have errors that way. (As you don't save much by asserting that your constant are correct anyway.)
I did that too and mine is just 61 LOC https://github.com/phaux/rust-brainfuck/blob/master/src/main.rs
&gt; You can ignore results, too, by assigning them to `_`: &gt; &gt; `let _ = File::open("does not exist");` As a more realistic example, there are lots of functions that return `Result&lt;(), Error&gt;` to signal failure, but not return anything normally. Then you can do `let _ = write!(out, "Don't care if this {}", "fails");`
Hey, thanks for taking a look at the code. I have to say the documentation was a big help to me in general. Especially the sections on writing a codec and augmenting the transport. I also spent a lot of time reading through the crate documentation for both tokio and futures to help me gain a better understanding, which I found very helpful in better understanding how futures and streams work. Once I understood how polling worked, that helped quite a bit. I did have to spend some time digging through the source code of both projects, just to see how things were implemented to help my own understanding. I made the most progress on the project when I realized the `Stream` trait worked quite a bit like the `Observable` type from Rx. I figured out that by calling `split` and then applying combinators to the incoming stream (which includes getting outgoing messages from other sources, like channels) and then running the resulting stream into the `send_all` method of the `Sink`, it allowed me to achieve my goal of handling a streaming style protocol instead of a request/response style protocol. I wound up writing my own custom futures and stream for this project, specifically to avoid the combinators so I didn't have to box up the futures and streams my library is returning. I would say that having the ability to return `impl Stream` and `impl Future` would have probably reduced the amount of code I had to write to just avoid boxing, but that's mroe of a nit with the language itself and not tokio or futures. I also really like how the transports can be layered and built up into the final thing. It took me very little time to get fully functional support for TLS connections with the tokio-tls library and as my code shows, I was able to reuse a good chunk of the machinery between unencrypted connections and TLS connections to easily allow for both forms of connecting to a remote server. Overall my experience has been really positive and I absolutely enjoy writing code using tokio. I'm getting ready to start integrating hyper into my main project to handle making API requests external to the bot and I'm really excited that I'll be able to leverage futures and tokio for that work. It'll make integrating the components really easy IMO. I would say the one thing that would probably really help the documentation for my sort of use case is maybe a small sample of some sort of simplistic chat server and client.
Trying to figure out more about this crate (since the README offers very little info), I discovered that its crates.io Documentation link is going to random dodgy advertisers.
The crate on crates.io is not updated at the same time? Is cargo install no longer considered a recommended approach to install it?
"long time" is a bit of an understatement... but, see https://github.com/stoklund/cretonne
Whoops. It's updated now. Thanks! `cargo install` has never been (and never will be) the recommended way to install ripgrep. That's why it's listed near the bottom of the README with the description, "... for Rust programmers ..." :-)
And it's only one macro, too. I can't wait for when we have to build not just a bike shed, but a bike warehouse.
It's usually more complicated than that. At least in theory the two languages, when used by perfect programmers who know what they're doing, with perfect understanding of what the compilers are doing behind the scenes, and with identically effective compilers, will get about the same runtime. In practice: - Rust's compiler is newer, and while it builds on top of LLVM, LLVM does not have many (or any?) optimizations that benefit only Rust, while it (usually) works better on C/C++ generated code (because it's been around longer). And GCC (usually) produces faster code than LLVM, and it doesn't support Rust. - Rust makes it easier to write code that uses references everywhere and doesn't crash. This means that mere mortals like you and I are way less likely to copy stuff constantly in Rust "just to be safe", whereas that's a pretty common thing in large C++ codebases. - Rust's safe-by-default approach means that sometimes you'll incur multiple bounds check when one would have sufficed. C/C++ programmers have the opposite problem, of doing 0 bounds check when 1 was required, which is a faster-running mistake. - C++ has better-baked const support right now (edit: `constexpr`, as explained by /u/nwydo), which can definitely be an advantage.
LLVM moves/breaks fast and has a very active community that uses C++ so no. also "Rust is now faster [...] than C++" is at best debatable.
Good luck finding people with enough skill, time and willingness to work for free.
Rust 2.0 the bike shed factory!
So why should we? LLVM exists today and is working well. At that scale languages mostly don't matter (unless you've made very, *very* wrong choices), the overall design and communities matter more. Efforts to rewrite and recreate LLVM can be much better spent to explore other possibilities like Cretonne.
It's clearly necessary. If we were a better shed, the bikes wouldn't be Rusty!
Huh our old shed must have built with some leaky unsafe holes. Better to rebuild it from the ground up without them.
A somewhat dumb solution: Spawn a thread that `wait`s on the child process then sets a flag. By looking at the flag, you can know whether the child process has exited yet. Downside is you have to spawn one thread be subprocess if you want this to be accurate.
Wow, I didn't expect utf-16 support to be developed so quickly. I know some vs-code developers listed this as one of their many wishes for a regex search. I hope this might help tilt the support in favor for rust :)
No.
The _entire_ repo? If you just need it for a project, look at cargo vendor. Otherwise, I am not entirely sure how to do that (apart from just git cloning every item in the index with a script).
I'm confused. I thought the actual code is stored in GitHub/other hit hostings, and the index just references the repositories' URLs
BTW, sorry for the late response. That's what I ended up using
Got it. So, probably the best way to achieve this is to clone the index and somehow use cargo in a script and download individual packages.
...and put them to the S3-like storage. I think this part is the most difficult (you probably need something like fakes3 and hosts replacements) and yet to be solved.
Cargo communicates directly with S3? Can it be configured to use another source?
Kinda like how NodeJS programmers don't user NPM and Ruby programmers tend to avoid RubyGems, right?
In my understanding, yes. Oh! I've found that there is now [a proposed PR](https://github.com/rust-lang/crates.io/pull/601) to allow using the local storage instead (mainly for development), so it might be changed soon.
Some progress was made after `item` being replaced by `ident`. However, now `rustc` complains about the `A` in `wrapper!(a, A)` as "unresolved name".
After all is said and done, no body will keep you from doing it. Seriously, if you want to do the work, kudos for you!
Is there already a ripgrep Windows GUI similar to [grepWin](http://stefanstools.sourceforge.net/grepWin.html) (or [AstroGrep](http://astrogrep.sourceforge.net/), [PowerGrep](http://www.powergrep.com/), [BareGrep](http://www.baremetalsoft.com/baregrep/), ...)?
&gt; C++ has better-baked const support right now, which can definitely be an advantage. Can you elaborate on that?
They use them to install dev tools. Ripgrep isn't one. Tools written in Python meant to be used for the system are installed through the system package manager before they're installed through PyPI. Tools written in Rust should be the same way. Don't be that way.
Note that I've just updated the post to reflect the requirement to be able to kill the process from my program. I'm not clear on how channels could be used if the thread is blocked waiting on the child to exit. Could you please elaborate further? As for external crates, I want a pure std solution if possible.
Awesome, cool project!
Note the parentheses. The non-compiling version only has `|fp| regexp.captures(&amp;fp)` inside `and_then`. The compiling one has the entire expression including the subsequent `map` call in the `match` arm. I expect moving the entire expression inside `and_then` would also work. It's not sugar in the sense that the compiler elides or rewrites code though - `and_then` is a separate function.
&gt; To a first approximation, ripgrep is approximately 5x slower searching UTF-16 when compared to UTF-8. From this pull request: https://github.com/BurntSushi/ripgrep/pull/398
Seriously, it's nice to see a lack of bias here. Refusing blanket statements and maintaining pragmatism is important.
&gt; To a first approximation, ripgrep is approximately 5x slower searching UTF-16 when compared to UTF-8. From this pull request: https://github.com/BurntSushi/ripgrep/pull/398 
What's a good guide to starting out and getting familiar with the language with a hands on approach? Tutorials where I don't build anything actually useful or interesting don't grab my attention enough, and going off to build my own dream project is too big a task for me to maintain interest, simply because it's a huge wall to overcome. Note I'm a pro JS dev with understanding of lower level concepts. Just not useful in any of the low level langs. :)
So, when GNU grep doesn't support UTF-16, why not replacing it with ripgrep? Do you think distribution maintainer would accept an enhancement request?
Basically, but with more algorithms and a more permissive license (no code is taken from pHash itself; I haven't even looked at the API).
&gt; C++ has better-baked const support right now, which can definitely be an advantage. I thought it was the opposite. Const correctness in C++ is just an after thought which doesn't provide any useful gaurentees, since const references can be aliased with a mutable reference, and const is in the eye of the beholder. 
This might be what you want: https://github.com/tennix/crates-mirror A clone from a few weeks ago takes around 6.1 GB.
I'm 90% sure that it isn't just a rule of thumb, this is rather an explicit goal/target so that the internals of a function changing without changing the signature can never be a breaking change.
I’ve been working on a library for dealing with protocols defined via ABNF atop Tokio. At the moment, it does parsing directly from an `EasyBuf` using `Poll` to signal results. It provides combinators for typical ABNF operators and parsers for the core rules. Writing will come, too, once I progress towards that in my SMTP implementation. Since I am not sure what the intended rules about the `tokio-` prefix are, I simply named the library [abnf](https://github.com/cloudshipping/abnf). An example of its use with SMTP would be [in the smtp library](https://github.com/cloudshipping/smtp/blob/master/src/syntax.rs).
Is it treating untrusted data? Is preventing a compromise important? If you've answered yes to both questions, then Rust is for you.
i've done some input stuff for different platforms, unfortunately i have not much time as of now and i have not fully discovered everything i need to achieve this. Maybe i find some time and complete my tasks because [enigo](https://crates.io/crates/enigo) could be helpful for you on this project, but is currently in a bad state :(
Yes, that's true. But when a beginner reads "no crashes", he has something different in mind.
I spent the last few days working on [my forum](https://git.nokaa.moe/nokaa/neppit). Added an API, basic moderation system, and some nice parsing of user content. I'm planning to add more moderation features over the next several days. I'm debating about whether or not I should use JavaScript to make administration easier. Right now there is no JS. I also began porting stagit, so I'll probably finish that this week.
&gt; Haven't looked in detail, but here is one tip: you don't have to re-&amp;mut the mutable reference when you pass them on to other functions. That also gets rid of the mut x: &amp;mut Y in function arguments (becomes x: &amp;mut Y). Thank you so much! I actually tried that first, but rustc gave me an error in main: error: cannot borrow immutable local variable `left` as mutable --&gt; src/main.rs:20:15 | 19 | let (left, right) = setup(); | ---- use `mut left` here to make mutable 20 | join(&amp;mut left, &amp;mut right); | ^^^^ cannot borrow mutably If I change the "let (left, right)" back to "let (mut left, mut right)" then it wants me to add 'mut' to the function arguments again. Do you know how to solve this? Thank you for your other tips, I've learned a lot.
What is the best approach to have custom project tasks like in make or rake? Say, a task to flash compiled firmware to a device.
See the PR/commit for a little more detail, but the TL;DR is that UTF-16-&gt;UTF-8 transcoding dominates the runtime. This means clever things like literal optimizations are all but negated. Because of this, encoding support is more about improving the UX than anything else. If you have GB of UTF-16 that you want to search a lot, you'd be better off converting them to UTF-8 first.
Object detection for a Rust openai bot. Trying to identify the cartoon representations of things and then handle the game objects appropriately.
Not to my knowledge.
I think he's talking about Rust lacking constexpr support. Rust is better at understanding runtime const value propagation, but C++ compilers are capable of compile time expression evaluation.
I worked on [relm](https://github.com/antoyo/relm), an asynchronous GUI library based on GTK+ and futures/tokio, inspired by Elm. * I added the ability to communicate between widgets. * I tried to convert GTK+ callback functions to Stream, but it does not really make sense. * I improved the http example so that it does not freeze the UI when loading big images. * relm now logs a warning if the `update` function takes more than 200ms (so that we can see which message freezes the UI). * I removed some useless heap allocation for futures. * I added a function to remove a widget. * I fixed and refactored the examples. This week, I plan to: * add support for managing the errors coming from the Futures. * add a feature to support synchronous GTK+ callback. * create a more complete chat client/server example.
&gt; everything anything*
Ah right, thanks /u/bstrie. I've been in touch with the vscode people, so I forgot to update that issue!
Should it become a replacement though? Would it be valuable, and would there be a cost to being so relied-upon?
You're welcome! `main()` is the one place where you need the `mut` annotations :) There you're creating two JoinFiles and taking mutable references to them. (But there they aren't function arguments.)
&gt; Just like before you can unblock workers stuck in self.queue.pop() by sending a Quit message over the queue. If all the workers are stuck (e.g., when there's no work left to do), who sends the quit message? (You're right though that switching `try_pop` to `pop` would fix the `thread::sleep` problem, but I couldn't figure out how to make it work.) &gt; Apart from that using a global queue with a mutex and a condition variable as well as per-worker queues by using work stealing would be another improvement as well as solve this problem. This is how ripgrep worked before. The problem I was trying to solve with the new approach was parallelizing directory traversal itself. Setting up a simple worker that does directory traversal in a single thread and produces work for other threads to consume isn't optimal because there is a big bottleneck in that single producer thread. The issue isn't necessarily just a simple directory traversal, but rather, the application of `gitignore` logic, which can require some heavy duty globbing for every single file path searched. This has to be part of directory traversal itself because you really want to avoid descending into directories that are ignored (e.g., a `.git` directory). Unless someone can help me reorient myself, then from my perspective, this means the producer *is* the consumer. I struggled with termination because the only way I could articulate it was by forcing all of the workers into a state where, if they get there, then I know no future work will ever be produced. But it's a bit of a dance. This is great though. I'd love to have more eyeballs on that code. If I can get it into a state that I'm happy with (or equivalently, come up with a solid argument for why it is the way it is), then I'd love to write more about it!
Well, I mean sure, if you want to use `cargo` to install ripgrep then knock your socks off. :-) I do upload it to crates.io for folks that want to take that path. But recommending all end users go that path by installing a Rust toolchain is a bridge too far IMO.
Model generating SMT solver with a focus on logic programming and CP problems. Currently coding a graphstructure for limiting the search space.
As somebody new to operating systems, can you explain or provide a link about what it means for grep to be POSIX compatible? I had the impression that grep/ripgrep were high-level enough to not worry about that.
I've solved this by doing fork+exec myself (also due to other requirements) and then tokio-signal to wait on children (I used tokio anyway). The application was specifically designed to be Unix-only.
&gt; If all the workers are stuck (e.g., when there's no work left to do), who sends the quit message? You're right. There'd be a race condition between worker A calling `self.waiting(true);` and later on `self.queue.push(...);` and worker B checking `if self.num_waiting() == self.threads` and wether the queue is empty as well. It could be solved but only properly if you stop using `MsQueue` to be able to make incrementing the `waiting` counter as well as calling the blocking `pop()` a single atomic operation. &gt; This is how ripgrep worked before. No what I meant is actual work stealing. I implemented such an algorithm for a multi-producer/-consumer before, where the consumers are also the producers, just like with ripgrep. The way it works is that you give every Worker instance a statically allocated, fixed size SPMC work-queue (**L**). This must be a plain ring buffer to support batch operations. Furthermore you need a global, unbounded MPMC queue, which as well has to support batch operations (a `Mutex&lt;Vec&lt;...&gt;&gt;` works) (**G**). And finally you need a global list of parked workers protected by a `Mutex` and a `CondVar` (**W**). Every time a worker wants to **consume** a message it should first try to pop a element from it's local **L**. If that fails because it's empty it should then try to _randomly steal_ messages from other workers' **L**. And if you do steal messages you don't steal just one: No you steal _half_ the queue in a single batch operation! If that fails as well (because all workers appear to be empty) you finally try to again steal a batch of messages from **G**. If that fails as well it's very likely that every worker is idle and the global queue is and will stay empty. You should now take the mutex lock of **W** and try the above process again. If it fails again you should enqueue yourself into **W** and wait using the `CondVar`. Now every time a worker **produces** a bunch of messages it should try to enqueue those into it's own **L** first. If there are too many elements it copies the rest of them into **G**. Every time you produce something you have to also check wether something is in **W**. If that's the case you should wake up one or more of the other workers by signaling the `CondVar`. Why is this complicated algorithm preferable? Because work elements are most of the time coming from the local **L**, which means you immensely reduce the pressure due to lock contention. Furthermore if a worker needs work it doesn't acquire just a single element but a entire batch at a time and thus ensuring that lock contention stays low. You can find a old implementation of mine for that [here (the worker part)](https://github.com/zonyitoo/coio-rs/blob/269eda9d9b67ca465ab2a1d790364654a90746fd/src/runtime/processor.rs#L410-L651) and [here (the global part)](https://github.com/zonyitoo/coio-rs/blob/269eda9d9b67ca465ab2a1d790364654a90746fd/src/scheduler.rs#L610-L718). The original solution to the delicate part of spinning workers who have no work can be found [here (Go code)](https://github.com/golang/go/blob/dd0e1acfeb50f33f79738b2ef7e21a61ecec9d22/src/runtime/proc.go#L2001-L2059). If you have any questions I'll try my best to answer them. 🙂 P.S. If you whonder about the performance of steal-half: It's probably not very relevant for ripgrep... You can find a paper for that [here](https://ai2-s2-pdfs.s3.amazonaws.com/5343/61b70ff69ea6c68e8bdad73c468fce408ad0.pdf) on page 6. I personally actually believe that the `sleep(1)` solution is probably just fine, except if a cpu cycle instrumentation ever says otherwise.
Just finished rewriting all of the flow control logic in the [Ion shell](https://github.com/redox-os/ion), which is now complete, and implemented a number of critical shell features that were missing, so the shell is now pretty capable. It is possible to write a [fibonacci function](https://github.com/redox-os/ion/blob/master/examples/fibonacci.ion), for example. For this week, I will implement stderr redirection and piping, and handling unterminated quotes within the shell. Maybe even optionally-typed function parameters.
If your program is that large, I don't think the Rust library ecosystem is ready for you, at least when you are not ready to rewrite those dependencies in rust (hard), or provide bindings for them (easy). The language is definitely ready, multiple big code bases are written in Rust (the compiler, servo, and ethreum parity). Of course its all a question of how much resources are available to you which you can deploy.
&gt; How do you know when all producers are done producing? You currently only have a single path for submitting and consuming work. In my algorithm description above though this is different and there is a fast path and a slow path. Due to that checking wether all other threads are idle/parked is quite easy because the parking happens on the slow path. For instance you can just protect the entire global state - including the list of parked workers - using mutexes (or simply with only one), since that's the slow path and it doesn't matter at all if it uses regular locks. There are really only 2 problems there: - Preventing the thundering herd problem (quite easy to solve). - When parking a thread you have to make sure to _first_ take the global mutex lock and _then_ check all worker queues again. That way you ensure that no other thread submitted a worker job in the meantime while you check if everyone else is truly idle. Afterwards you just park yourself. **And while you do that you check wether everyone else is parked as well and wether the global queue (G) is empty.** If that's the case you can exit. As I said the idea for that comes directly from the Go scheduler source code. And here's how they ensure that the transition of a "spinning worker" (a worker thread actively searching for work) to a parked worker (sleeping) is protected: &gt; We unpark an additional thread when we submit a job if there is an idle thread and there are no "spinning" worker threads. &gt; A worker thread is considered spinning if it is out of local work and did not find work in the global run queue; the spinning state is denoted in `worker.isSpinning` and in `global.spinningCount`. &gt; Threads unparked this way are also considered spinning; we don't do job handoff so such threads are out of work initially. &gt; Spinning threads do some spinning looking for work in per-thread run queues before parking. &gt; If a spinning thread finds work it takes itself out of the spinning state and proceeds the execution. &gt; If it does not find work it takes itself out of the spinning state and then parks. &gt; If there is at least one spinning thread (`global.spinningCount &gt; 1`), we don't unpark new threads when submitting jobs. &gt; To compensate for that, if the last spinning thread finds work and stops spinning, it must unpark a new spinning thread. &gt; This approach smooths out unjustified spikes of thread unparking, but at the same time guarantees eventual maximal CPU parallelism utilization. &gt; &gt; The main implementation complication is that we need to be very careful during spinning-&gt;non-spinning thread transition. &gt; This transition can race with submission of a new job, and either one part or another needs to unpark another worker thread. &gt; If they both fail to do that, we can end up with semi-persistent CPU underutilization. &gt; The general pattern for submitting jobs is: submit a job to local work queue, #StoreLoad-style memory barrier, check `global.spinningCount`. &gt; The general pattern for spinning-&gt;non-spinning transition is: decrement `global.spinningCount`, #StoreLoad-style memory barrier, check all per-thread work queues for new work. &gt; Note that all this complexity does not apply to global run queue as we are not sloppy about thread unparking when submitting to global queue.
Saw this [on /r/haskell](https://www.reddit.com/r/haskell/comments/5z3ue9/retrofitting_linear_types_pdf/) and thought it showed another interesting point in the language design space. Rust is mentioned quite heavily in section 6.
Great stuff, thanks so much. This has given me a lot to think about!
Me too. I basically make a macro with this exact name that passes varargs to write(stderr...) for anything that doesn't require trivial error logging.
I'm implementing `global_asm!()` for module-level inline assembly support in `rustc`. Seems to be pretty easy, so far, so I'm baffled why no one else has implemented it yet. Tracking issue for RFC: https://github.com/rust-lang/rust/issues/35119
Rewriting my spreadsheet formula lexer with [nom](https://github.com/Geal/nom), which I probably should have used in the first place anyways.
That's pretty interesting stuff! One small suggestion, could you put some time wrap up a README file? That might help new users/contributors a lot.
Fuchsia is now at tier 2 for nightly, which means more work getting Rust more deeply integrated into the Fuchsia build system. Also more xi work - I'd like to either get my [patch to unicode-segmentation](https://github.com/unicode-rs/unicode-segmentation/pull/23) landed, or just move the work to xi-unicode. For fun, over the weekend I started coding a lock-free audio graph runner (not released yet, but will sooner or later).
Very useful project for me :)
As you may have seen from my recent post, I split off the IRC portions of my Twitch bot into a library of its own and open sourced it. It's still really bare bones at this point. I plan to spend time documenting it and improving the functionality. I also plan to continue working on my Twitch bot.
&gt; what makes you think this is a good idea in the first place? Rust has guaranteed memory-safety, zero-cost abstractions, threads without data races/fearless concurrency. We'd be eliminating entire classes of errors by re-writing everything in Rust. Plus the pattern-matching and trait-based-generics would mean we'd spend less time writing application logic.
Not with just references. `RefCell` yes, but that's not what I'm talking about. The classic "returning a reference/pointer to freed memory" is flat out impossible in Rust (unless you use `unsafe`, of course).
My recommendation is to pick a space you know, so that you don't have to handle the complexity of both "new language and ways of doing things" and "new topic I've never dealt with before".
you're a lifesaver
rust has these guarantees, but the LLVM IR it spits out does not. rewriting LLVM to self-host like this would probably be a lot harder than you're imagining given the relative lack of runtime constraints vs compile-time constraints.
Exceptions are a bad solution to deal with "errors". · Very often, exceptions are not exceptionals. · They are not part of the signature, but in general, it sould be. · The code jumps, in some cases farther than a goto. · It's easy to reason with Result, Option or Maybe. · If you try to convert an string to a number introduced by user, you have to consider (nothing excepcional) the possibility the string cannot be converted to a number. It is part of the function, it could not be converted. Therefore, it's part of the signature. With pattern match and ADT the compiler can help us to consider all possibilities when calling any function. That will reduce programming errors, easier to reason and easy to maintain (compiler will help you when refactoring). Return value is better than exceptions, but "liquid types" looks even more promising (control it as soon as possible, before calling) https://www.microsoft.com/en-us/research/video/liquid-types/ https://hackage.haskell.org/package/liquidhaskell
I usually put them in `src/bin`. However: &gt; Say, a task to flash compiled firmware to a device. This approach won't work as well here, since you want the tasks to be compiled for the host, but the project to be compiled for the target. I'm not totally sure what I'd do in this case. Interesting.
(The above poster is from another subreddit that makes fun of us; they're not actually trying to talk to you, they're just spouting memes.)
Possibly not really what you're looking for, but have you checked [rustbyexample](https://rustbyexample.com/). It really was (and is) useful to me along with the [Rust book](https://doc.rust-lang.org/book).
Yes, that's how I did it!
I don't think I'd make such general statements without knowing more. Maybe it's a million lines of code because it has very *few* dependencies, in which case I would say rust is ready. 
Hi! I was looking through Rosetta Code and noticed that the [Rust merge sort](https://rosettacode.org/wiki/Sorting_algorithms/Merge_sort#Rust) isn't very good, which led to me writing [my first ever Rust code](https://paste.ubuntu.com/24172047/). I'm kinda proud of it, the way babies are proud of their paintings. Does it look alright? What can be improved?
How big of a project? Every time I think of something I add it to my list of ideas [here](https://github.com/cretz/software-ideas/issues), but many are large undertakings and/or specific for non-rust use. Feel free to grab one there though if it matches.
&gt; but my impression is that distro maintainers are a very very very different target audience. Well, it depends. Here's a POSIX incompatibility bug in Redhat that's marked [CLOSED WONTFIX](https://bugzilla.redhat.com/show_bug.cgi?id=135406). Distro maintainers don't care about POSIX... they care about not breaking shit. In theory it would be nice if every program anywhere assumed strict POSIX, but in fact they don't, they're generally either written for GNU or BSD and then get some bugs ironed out upon porting. I can't tell you how many `#!/bin/bash` shebangs I fixed to get things running on NixOS. Alas, even with things that *are* POSIX, like `sh` and `env`, POSIX doesn't specify their exact location. Arguably, they should at least specify `/bin/env`, to have at least one reliable entry point. Or, even better, something like `/std/posix/env`, which may or may not be the system standard `env`. ...and we haven't even gotten to run grep yet...
Is it still LLVM if you rewrite it in Rust? https://en.wikipedia.org/wiki/Ship_of_Theseus
Although clearly incomplete this seems like a cool idea. The things I miss from python in Rust are mostly things from the [collections](https://docs.python.org/3/library/collections.html) module. Stuff like namedtuple, defaultdict or ordereddict are structures that make my Python code much simpler in general. I was already thinking about writing a clone of those for Rust. IMHO they would be valuable additions to this library.
As a simple example, I could have an assembly file in my project and use `global_asm!(include_str!("my_asm_file.s"));` instead of using a build script to assemble, create a .a file and link it with my rust code. The link to the tracking issue (and the link to the RFC) also provides a couple examples. Mostly, since we copy all assembly in `global_asm!()` through to the assembler without the compiler doing anything to it, you get full access to your platform assembler's facilities, which is helpful (if not required) in certain not-unusual low-level cases.
&gt; […] more aggressive &gt; aggressive dead code elimination wow, that *pretty* aggressive
Thanks! Your contributions will be welcomed. I wonder how many of these APIs don't rely too much on the dynamic aspects of Python. I'd rather promote the idea of static typing while keeping similar APIs.
It is for me, I don't know about other people.
And despite being the only semi-major language with first-class support for linear types, Rust still apparently doesn't merit a mention in the abstract. :P
my thoughts as well. idk if this much aggressiveness fits to our community guidelines 😉
The thing I miss most from Python in Rust is definitely *generators*. Directly implementing iterators is so painful after all those years with Python generators. Maybe LLVM 4.0's new experimental support for coroutines paves a path for such functionality in Rust in the future?
If your main goal is to gain experience using the language on a real project, obviously you can do whatever you want, and it doesn't matter if it's already been done before because you'll still accomplish your learning goal regardless. I was looking for a similar project a while ago and settled on implementing a text-based strategy game. Text-based because I'm a fan of the simplicity and because it should make implementation easier. A strategy game because its design is complex enough to force me to find patterns for organizing code rather than just writing a giant procedural rats' nest---you've got the game logic, map generation, AI, command line parsing, configuration files, save files, graph algorithms, etc. Honestly it's more involved than I had initially expected, which is a good thing. The result? Well, I've encountered frustration and spent months at a time off the project, only to come back and move forward to the next step in the design. The strictures of Rust have forced me to think very carefully about my design. The unruly tangle of shared mutable state that I'm accustomed to in Java or Python is suddenly much less agreeable, so I've found ways of architecting around it. Where I've gotten hung up and stuck with a suboptimal design, I've eventually learned that one language feature or one strategy that I needed and been able to move forward. It's been really tough, but I feel like it's forcing me to learn things that I wouldn't have been able to on a more toy-like project. Anyway, mostly I don't think it matters what you work on so long as it's pushing your current abilities. So good luck!
Ah, Input Method Editor. Thanks
Unfortunately, it's one of the few large platforms rust doesn't run on.
It would be awesome if it had the Rust logo somewhere. Even the bottom would work...
s/easy/stupid s/subtyping/struct composition and data layout. This has nothing to do with abstract or algebraic types, or with function usage. Purely pointers and memory chunks. This is motivated by my work in C, so it may not be supremely relevant, but what the heck. So, C "supports" "subclassing" structs via composition, just like Rust does except the C type system is shy and willing to let us run roughshod over it. Example: struct A { int a; }; struct B { struct A a; int b; }; The B struct is two ints, and a `struct B *` pointer can freely be made a `struct A *` pointer, and vice versa (if we're willing to accept potentially breaking things, which, it's C. Of course we are). struct B b; struct A * pab = &amp;b.a; // typesafe struct A * pa = &amp;b; // not typesafe, but still true assert_eq!(pab, pa); // not C, but still true Since we can go in reverse, we're free to assume that if we're passed a `struct A *` pointer that we're *totally sure* points to a `struct B`, we can cast it and access the `int b` member. (struct B *)(pa)-&gt;b; // not a segfault ... this time struct A a = { .a = 1, }; struct B * pb = &amp;a; // C will allow it pb-&gt;b; // and that's a memory failure This works great for single inheritance. But we hate ourselves (again, it's C. Of course we do), so let's do multiple! struct C { int c; } c; struct D { char d; } d; struct E { struct C c; struct D d; }; struct E e = { .c = c, .d = d, }; We know that `struct C * pc = &amp;e;` is valid, and we know that `struct D * pd = &amp;e;` is NOT. However, we can freely give out properly-acquired `struct D *` pointers (`&amp;e.d`), and again, if we're willing to dance with segfaults, we can make `struct E *` pointers from them: struct E * pe = (struct E *)((char*)&amp;e.d - sizeof(struct C)); This is workable, but an ugly hack. Is it possible to do similar things in Rust via pattern matching? That's essentially what the C code is doing, except via pointer math because C doesn't know what patterns are. What I mean is, given some reference to a struct member, not necessarily the one at offset `[0]` from the parent struct because Rust's memory model isn't nailed down and `#[repr(C)]` is not to be assumed, could we create a reference of the parent struct type, referring to the memory which the parent would occupy if the member reference is in fact pointing inside the parent to a field. Example: pub struct R { r: i32, } pub struct S { s: i16, } pub struct T { r: R, s: S; } let t: T = T { r: R { r: 1, }, s: S { s: 2, }, }; let ps: &amp;S = &amp;t.s; let pt: &amp;T = &amp;T { s: *ps, .. }; The last line basically says that there exists a struct `T` such that its `s: S` member is referred to by `ps`, and that `pt` is a reference to that struct `T`. This would obviously be `unsafe` as hell, since the compiler may not be able to prove that the `&amp;S` in question was obtained from a `T` structure owning it. Or maybe it might; I've learned to not underestimate `rustc`'s intelligence in which case creating an `&amp;T` from an `&amp;S` known to be (a) valid by lifetime and borrowck and (b) obtained from a `T` would be ... perfectly safe. Is this a thing Rust currently supports and to which I've been so far blind? I know it's possible to copy and alter a struct by using my example syntax to steal from a struct of the same type (`let t1: T = T { /* ... */ };`, `let t2: T = t1 { r: R { r: -1, }, .. };`) but I've not seen any type hackery like this. I suppose it could be done via `From` and C-like unsafe pointer math. If it's not a thing, would it be something Rust may want to implement? It seems to me, from first blush and doing weird things in C for system level programming, that such subtype behavior may be necessary in the wild and something Rust may want to support at the type/pattern level to advance its "OO" story. Or am I completely off the rails with this one?
A bit of a tangent, but the point of RAII is that you *don't* have to manually free your heap allocations. Both C++ and Rust collections/smart pointers use RAII semantics to accomplish that. 
Ooo I have not! Didn't know that existed. It certainly feels better than a sleep!
You're absolutely right. Sorry if I came off as grumpy and/or ignorant. Love what you're doing.
oh good, i'm glad! &lt;3
Yes I know, and this was only a requirement because of exceptions originally, was my point:P Using `new` and `delete` in C++ is pretty dangerous, because you could leak memory at any point if an exception is thrown.
Yes, ADCE is an existing pass: http://llvm.org/docs/doxygen/html/ADCE_8cpp_source.html It was made more aggressive :-)
Honestly, we could use more people working on GUI apps in Rust. I've posted in the Users forum before, but this is still a very underdeveloped area of Rust. The scratching-your-own-itch mentality is great here if you find a GUI app. I'm doing that for serial terminals, where they're all ugly, unusable, unmaintained, or buggy. If you have some GUI app that you'd like that is in a similar boat, reimplement it in Rust and help us solve the various problems that face GUI apps. Like which cross-platform GUI library will work, how to do notifications, software updates, program configuration, internationalization, packaging, etc. Otherwise if you want specifics: 1. I'm trying to use the rust-notify crate, but it doesn't have cross-platform support, so I can't use it in my crate yet. If you have a Mac or Windows and want to try adding it, it'd be great! 2. There are some reimplementations of Elm, some of which are aiming for native cross-platform widget support. I'd love to use this, but there are a few different implementations and none have started to go to even two platforms, so I'm sticking with GTK+. 3. Both [nix](https://github.com/nix-rust/nix) and [libc](https://github.com/rust-lang/libc) have tons of missing functionality, many of which I've posted issues for, so adding that functionality would be much appreciated! 4. There's no high-level API like nix for Mac. Implementing any functionality using Apple's APIs is pretty painful, having that in the ecosystem would be good.
Grep also supports a different regex syntax (actually multiple syntaxes, I know it supports perl-compatible regex as well with -P), so at the very least there would have to be a translation layer, if not a new parser entirely. It could be done I suppose, but I don't think it's worth it. You're right though, it's theoretically possible.
It seems the talk I gave at the Raspberry Pi 5th Birthday was recorded by an audience member. Slides are on https://thejpster.org.uk 
I have the same requirement (and it's just sound business practice anyway). I use `cargo vendor` on my Internet connected workstation to store just the crates I use, which the CI system can then pull from our repo.
One error in the slides: Rust does not prevent you from leaking memory.
(FWIW reviewing that is on my list; I just have a bunch of other things to complete first)
Contribute to [steed](https://github.com/japaric/steed).
https://github.com/rust-lang/rfcs/pull/1823
Perhaps it would be a good idea to have Message's command member be an enum with an Extension variant in the same vein as Hyper's [Method enum](https://docs.rs/hyper/0.10.5/hyper/method/enum.Method.html)? That would allow you to skip an allocation for each message at the expense of having to think about stability of enum variants.
Made a small patch to [tantivy](https://github.com/tantivy-search/tantivy) so it doesn't have to link the C++ standard library. Now that it builds on musl I'll keep working on automatic binary releases for the tantivy CLI. Also getting back to integrating Rust and C# now that I've got a nice way to consume Rust libraries from .NET
Rust supports affine types. Affine: Can only be used once Linear: Can only be used once, must be used
You can do `mystring.as_bytes()[0]`. This gives you access to the raw utf-8 bytes. Whether that's useful is a different question (I use it a lot for high-performance parsing and unicode operations). You can also do `mystring[0..].chars().next()`, which gives you the codepoint starting at byte offset 0. I also do that a fair amount, when I care about the non-ascii unicode.
Yep, my #1 feature is the `bitreverse` LLVM intrinsic, which compiles to a single instruction on ARM :D Hopefully they fixed the bad performance of the intrinsic on non ARM platforms before the release, but I don't think so (my LLVM bugs are still open).
UTF-8 has some characters encoded as multiple-bytes. For example, what should "ABCD€F"[5] return? Python will return "F", but in order to do so it has to look at the whole string, character by character (maybe, unless it [decides to use UTF16 based on the contents of the string](https://www.python.org/dev/peps/pep-0393/)). C will return `0x82`, because it indexes by the byte. This is fast but wrong. Rust doesn't want to pretend character indexing is fast (`foo[5]` looks like a simple pointer offset), and doesn't want to give you the "wrong" answer, so it doesn't provide indexing. You can always use `s.chars().nth(5)` to get what you want (modulo the caveat about multi-codepoint symbols).
This wouldn't be necessary if Rust would have full UFCS though :/ 
Constant-time operation is an operation that takes a fixed amount of time – that is, doesn't depend on the length of the string, for example. An example of a constant-time operation would be getting the `n`th integer from an array of integers. The getter method can calculate the memory address of that integer in a constant time using simple arithmetic. UTF-8 doesn't allow constant-time indexing because the codepoints take variable amount of space. That is, some take only single byte, whereas some might take two or three, or even more. That's why you can't know the memory address of `n`th codepoint using a simple calculation, but you have to "scan" from the start of the string, codepoint by codepoint. If we say that the codepoint we are trying to access is halfway the string on average, we must read half of the string every time we are indexing, so it doesn't take a constant amount of time, but is dependent on the length of the string.
I mean positional unpacking like this: let (x, y) = (1, 2); You cannot do this for structs right? 
[Isn't this UFCS?](https://is.gd/koJEkw) I don't think any of this crate so far is necessary; it just moves intrinsic and scoped functions into the global namespace because that's what Python seems to do. When in reality, Python winds up doing exactly what Rust does (type-level dispatch), just with terrible syntax because freestanding functions are cool, I guess. I'm sure there are parts of the python stdlib that would be nice to have; I just fail to see how freestanding functions are those parts.
So the short answer is that indexing a string by 'character' is a very thorny issue outside of latin languages. The closest approximation to what people think of as "characters" are "unicode grapheme clusters". These are variable length and cannot be easily indexed randomly. Python3 does the wrong thing and indexes by codepoint: &gt;&gt;&gt; z = "resumé" &gt;&gt;&gt; z[-1] '́' &gt;&gt;&gt; z[-2] 'e' &gt;&gt;&gt; len(z) 7 This is probably not what you want. So rather than provide an error-prone interface, Rust allows you to index UTF-8 encoded bytes and punts on the complex issue of indexing characters. A very good [article](http://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points/) about this by /u/Manishearth.
I've thought about doing that, but the problem is that IRCv3 allows for the arbitrary extension of what commands can go in the command field once an appropriate `CAP REQ` has been made. That unfortunately means I cannot know all possible values for command. **EDIT:** It could be possible to have a variant that contains a string for unrecognized commands, such that an allocation would only occur when a non-standard command is received. **EDIT 2:** Taking a look at Hyper's `Method` enum, that's exactly what they have done. I'll definitely consider this, thanks for the suggestion!
Even UCS-4 isn't enough because surrogate pairs aren't the only thing that cause a single grapheme (what humans expect "character" to mean) to map to more than one code point. Eevee did a great rundown of why Unicode is hard which includes this issue: https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/
On posix you could check for presence of a process with kill using zero as a signal number.
I'm a frontend guy and I want to challenge myself. The goal of this small project is to generate a status badge from your project cargo dependencies. Exactly like npm badges but all done with rust at realtime powered by rocket. Basically your Cargo.toml will be downloaded, analyzed and compare with latest versions available of your dependencies. Code review welcome.
Are you using a certain definition of "subtyping" when discussing this? I ask because, to me subtyping is less about memory layout and more about the type's interface. This is the type of subtyping contract that is enforced in most "OO" languages, and is what Rust supports via traits. I personally would not expect Rust to support C-like "type punning". However, I am curious what juicy use cases you want to use this for. Maybe you can show me what I am missing! And thanks for the interesting question
&gt; Isn't this UFCS? One would need to omit `Iterator::` to make it UFCS, because the _U_ in UFCS stands for _uniform_. For that to be UFCS one would need to write `iter.Iterator::all()` instead of just `iter.all()`. Rust is actually far away from UFCS. It is not due to the point above. In a language with UFCS it doesn't matter whether you write methods or functions. In Rust, methods are way more powerful than free functions though, e.g., methods can be "overloaded" for the first argument, and on nightly they can be specialized. Free functions do not support any of this.
Wow, that's actually a great use of the Into derive of the [derive_more](https://jeltef.github.io/derive_more/derive_more/into.html) library already made. Thanks for the idea! 
This already exists and is called HList :)
There's another alternative that should be in the comparison: That `5` in `foo[5]` is the same location in the string that `&amp;foo[5..]` starts with (The latter is already valid). It could be constant time and fetch the `char` that starts at byte offset `5`, which is consistent with how slicing with ranges works. (It would also have to panic on offsets that are not on a char boundary, just like slicing does). Alas, there is no way to implement it, it would need an `IndexGet` trait, because strings don't contain `char` values so the regular `Index` trait can not return a `&amp;char`. Edit and here is yet another alternative of a `str` indexing scheme that is constant time and consistent with slicing. https://is.gd/bicoL4 . Only reason for the `Str` newtype is so that we can prototype it outside of libcore.
&gt; _Self-synchronization_: Unlike in UTF-1, the high-order bits of every byte determine the type of byte: single bytes (0xxxxxxx), leading bytes (11...xxx), and continuation bytes (10xxxxxx) do not share values. The start of a character can be found by backing up at most 3 bytes. Together with the prefix property, this makes the scheme [self-synchronizing](https://www.wikiwand.com/en/Self-synchronizing_code). ([Wikipedia](https://www.wikiwand.com/en/UTF-8#/Description))
Latest (active) review links can be found in the [bug report](https://bugs.llvm.org//show_bug.cgi?id=28958#c5).
Though you might be worried about your process exiting and then the PID getting reused by something else. It's not likely, but if you're writing library code that might run in who-knows-what environment, you probably don't want to assume.
I do have one nitpick, even though I understand that much of your talk is rhetorical and/or satirical: Go is a system's programming language. You can rewrite the runtime *in Go*, but you don't really have to. You can write Go code that runs without a runtime. Go, like Rust, was essentially designed to be a drop-in replacement for C. But eh, that's not the point of your talk, so I'm just being an asshole. I really did enjoy this talk.
I don't know. If I had to guess - rust's mutable references have a uniqueness constraint on them, only a single writer XOR any number of readers. https://en.wikipedia.org/wiki/Uniqueness_type Based on that it isn't quite the same, but it seems like it effectively is.
Do you know why explicit support for coroutines is necessary in the code generation library? My assumption was that LLVM's IL would be simple and flexible enough that coroutines could be built on top of it in the front-end. Is that not possible?
Really interesting interview.
Rust doesn't guarantee struct layout (and there are [plans afoot](https://github.com/rust-lang/rust/pull/40377) to optimize memory usage by reordering fields) so this seems risky at best.
Isn't Rust designed to be a drop-in replacement for C++ instead of C?
Given that it's skewed more toward userland right now (much like C++), that's a very good point. But honestly, it seems more like Mozilla wants to make Rust the goto tool for people who want to make. . .well, anything. Which is basically what C has been for a long time. It's all kinda fuzzy, and I meant my point to be more of a general statement that Go is supposed to be low-level just like Rust than to be any sort of definitive stance on what Rust is going to replace.
Borrow-checking needs to model stack interactions still, and they get more complex than anything we have in Rust so far.
Frankly, given the OP's question, &gt; Why does the UTF-8 encoding not allow this? your post really doesn't "answer" his question. Yes, *literally* you answered #1, but you omit anything answering #2, and I think the OP's question deserves a more thorough treatment. We want him to leave this discussion, ideally, understanding the difference between bytes and text, how text is encoded into bytes, and how, because of the encoding that Rust's `String` and `str` types use, it is not possible to index strings (at least ones stored in that form / in those types) in constant time. What I don't want is the OP to leave the thread thinking that there's some problem inherent in the Rust design due to poor choices — and it's easy enough to assume this, since plenty of other languages appear to allow constant time indexing into the string. (And the result of indexing a string in many of those languages is borderline useless, or at least frustrating, but one won't understand that until one fully understands encodings, particularly the Unicode ones, and whether one's language of choice is giving one code units, code points, or graphemes.) This is a question that *so many developers/engineers struggle with*, too, in my experience. We *need*, not just as a Rust community, but as a software engineering community, better material (and better education in the college level, IMO) about this.
I've been working on a binary logging format. If you're asking "why?": because most text logs aren't directly parseable (that is, they lack an unambiguous grammar). Trying to grep a time range is a rather painful experience, and I long for something like `log cat --when 2017-03-02 --grep-message SomeExceptionName` and having it be efficient not only to type, but also to run. The binary format is roughly a CBOR encoding of the log messages with a record separator (s.t. if a message is corrupted mid-stream, you can seek to the next record separator, and continue reading; this is similar to how a newline functions in many text logs, but the record separator is guaranteed to not otherwise appear, unlike a newline in text logs which can *easily* appear in the log), optionally compressed. I don't really expect everyone to like this. But I've `grep`'d too many logs. Ideally, I'd like to have some stuff to make it easy to write loggers that do proper rotation. The other great thing about having discernible record boundaries is that you can pipe to another utility, and have it perform the separation for you. I have found the [cbor-codec](https://crates.io/crates/cbor-codec) quite helpful, and *very* well implemented. I am also quite liking CBOR, and highly recommend it as an alternative to JSON, and an alternative to things like msgpack.
[There are no `rustc` binaries that execute on Android](https://forge.rust-lang.org/platform-support.html). You can SSH into your PC and run `rustc` there, if you have a means of synchronizing work. Or you can use https://play.rust-lang.org/ or https://play.integer32.com/
Oh, _that's_ where my closure went. Thanks, I've been looking for that for about 350 years now.
ELI5, please? :|
Hey /u/Caleb__. I thought that this python video would be relavent to your question as well. https://youtu.be/sgHbC6udIqc. Encodings are things you need to think about in python as well.
What am I doing wrong here? trait Super&lt;T&gt; {} trait Foo: Super&lt;&lt;Self as Foo&gt;::Bar&gt; { type Bar; } type BoxFoo = Box&lt;Foo&lt;Bar = u8&gt;&gt;; Error: `the trait Foo cannot be made into an object` `the trait cannot use Self as a type parameter in the supertrait listing` ==== `Self::Bar` is the type parameter, not `Self`... right?
I can't say what you're doing wrong either... because that code [compiles](https://is.gd/DvFDLt).
I forgot the `Box`.. I've updated my post.
Using `take` simply did not occur to me. In hindsight, it's obvious. Thank you both /u/krdln and /u/nswshc!
AVR is a microcontroller family made by Atmel, which is also used in many low cost, low power Arduino and other boards. So AVR support would mean being able to compile and run rust programs on AVR Arduinos and other AVR powered devices. Pretty sweet! Edit: Whoops, it's Atmel, and not all Arduinos are based on AVR.
Technically, they can only be the *irrefutable* kind of pattern, but yeah it's awesome.
I'm not saying that learning Rust is super easy, but specifically mentioning it has a "pretty steep learning curve" in a blog post about extending a Haskell compiler with linear types is a bit weird to me.
Feedback/critiques appreciated.
Others have made very good suggestions, but I would specifically like to respond to your comments about open source communities. My own experience has been that the people involved with open source Rust projects have been very pleasant to interact with. My experience is, of course, just an anecdote, but I hear similar stories from lots of people. So please, don't rule out contributing to existing open source Rust projects.
Source: https://github.com/juchiast/boxcrash I wrote this game in order to learn the Piston engine. There are still many things to implement, if you're interested, I'm glad to receive your helps :) Here is the list (taken from repo's README): - Write an article about the writing of this code. - Fix some known bugs. - Test game on more machines. - Write a GUI to configure and restart game. - Draw more details of box and the road. - Add crashing animations. - Add some sounds. - Try to build on Web and Android. PS: Thanks for all of your comments, it's really encouraging :)
The impression I got was that Rust is aiming to be as suitable to large projects as C++ but with the reduced cognitive complexity and greater API/ABI interoperability of C. Or, to put it another way, Rust isn't a "C++ successor" because, historically, that has biased perception of what such a language needs to be... it's just a C successor that happens to have solutions to the same kinds of problems as C++.
&gt; It makes it significantly more difficult to do accidentally, but no language can prevent it. Fortran 77 does not have memory leaks unless you use FFI, so... arguably it doesn't by itself leak ;)
why'd you write the runtime in C?
Work is underway... https://github.com/rust-lang/rust/pull/40123
To add to this, some Arduino-branded boards (e.g. Arduino Due) are based on an ARM processor and already work with Rust.
Is Go as "low level" as rust even though it has a GC? Wouldn't the fact that it has a GC limit some applications, like OS Dev? 
It's a shame that Redox is still pretty much a one person project. 
&gt; Checking on your children without blocking in rust? I thought you're writing your own nanny-cam and needed to do it with fearless non-blocking concurrency :&lt;
I'd rewrite this: fn is_valid_symbol_start(c: char) -&gt; bool { // TODO: avoid allocatiing this in each call let symbol_start_chars = vec!['+', '-', '*', '/', '#', '&lt;', '&gt;', '=']; let mut ret = false; if c.is_alphabetic() { ret = true; } else { for s in symbol_start_chars { if c == s { ret = true; break; } else { continue; } } } return ret; } to: fn is_valid_symbol_start(c: char) -&gt; bool { c.is_alphabetic() || match c { '+' | '-' | '*' | '/' | '#' | '&lt;' | '&gt;' | '=' =&gt; true, _ =&gt; false, } } 
Interview begins at 5:41
I do have a specific "style"-related question. In https://github.com/samrat/rusl/blob/master/src/anf.rs#L161, I get `els_assigns`(which is a Vec) and I mutate it before it gets used to create a `Flat::If`. That seems pretty inelegant to me and I was wondering what more experienced Rust developers would do in such a case?
Thanks! That's a lot better than what I did there.
When a string is created, It scans all characters, and chooses internal representation with suitable size, starting with 1 byte/character and upgrading if needed. See https://www.python.org/dev/peps/pep-0393/
Yes, go is not suitable for self-contained things like operating systems. There are also other features provided by runtime beside GC. In Rust you can work without stdlib, avoiding the need for any runtime completely.
I believe the BMP/surrogate caveat is wrong, that only applies to UTF-16 and not UTF-8, and our chars are 32bit values and not UTF-16 code units either. What you should modulo is that if you ask for a char, you'll always get a single unicode codepoint, while you might be thinking of some other definition like a grapheme cluster or w/e i dont even know.
Sounds like what systemd's journal is doing...
MIR-based borrow-checking has been planned for a while, yes.
&gt; Linear: Can only be used once, must be used Which always makes me wonder: do linear type systems need some sort of "drop" hole which *must* be explicitly called to get rid of a value?
Yep, the question becomes essentially "enough for what". If we are doing something at codepoint level, it's enough. But if we are doing something at graheme level, it isn't. And to answer that question, we need programmers that are aware enough to have a grasp whether the thing they are doing is doing something with bytes, with codepoints or with graphemes.
I am hoping to build more of a community around [Intecture](https://intecture.io), my server management tool.
&gt; I can declare `mut v` in my function and so I'm able to mutate the vector, although it was not declared as mutable in `main()`. Why is that ? The *ownership* of `v` is passed into `push_one`, so that function can decide whether it wants to treat `v` as mutable or immutable. Note that after the call to `push_one`, you cannot use `v` in `main` anymore, because you gave it away. &gt; I can use a pointer to the reference n to increment a number and push it into the vector. But I can't point to the vector passed by reference. I have to use the reference variable v as if it was the vector itself. Numbers are `Copy`, which means they can be copied freely. Things than are not `Copy` are moved, not copied. That's why you can't dereference `v`: doing so would move the vector out of the reference, which would invalidate the reference, which is illegal. &gt; Except when I print `*v`, there it works. But it also works with just `v`. The `println!` macro expands to something that takes references to all arguments, so `println!("to {:?}", *v);` *actually* sees `&amp;*v`, which is okay (it reborrows `v`, which does not "move out" of the reference). I would recommend reading more about ownership and borrowing in Rust. Some other commenter will probably show up and link to the correct chapter of the book, or some helpful blog post somewhere :p
Indeed it is, here is the PR with a possible fix https://github.com/rust-lang/rust/pull/40479
In the first edition of the book: http://rust-lang.github.io/book/first-edition/ownership.html In the second edition of the book: http://rust-lang.github.io/book/second-edition/ch04-00-understanding-ownership.html
This sounds good and all but... A key issue with me following your path is that I don't think I actually have any *performance* complaints with the current implementation. For example, using ripgrep with more than 8 threads is probably atypical. My complaints are mostly about the structure of the code: 1. Termination is hard to reason about. 2. I'm using `thread::sleep` to avoid burning the CPU. Note that neither of these are really performance related. The first is really about maintenance of the code. The second isn't strictly necessary, but it makes ripgrep a better citizen on an end user's machine. I think what I need to do is follow this work stealing path and see where it takes me. I've in particular wondered if `rayon` would help me with this problem. I looked at it very briefly, but perhaps I dismissed it too early. Once I get to that point, I'll have to ask, is it worth it? &gt; Maybe this could even be abstracted into a seperate crate - something like worker-pool? Have you seen [rayon](https://github.com/nikomatsakis/rayon)? If not, does it do what you're suggesting? If you have heard of it, what is it missing?
Ticki wrote like 20 thousand lines of code just for TFS. If you check individual repositories there are several people who contributed more than 10 thousand lines of code. Many others contributed at least 1 thousand.
Gottfried Wilhelm Leibniz is gonna be real glad you finally got that cleared up
You're wrong. Very wrong. Redox has at least 20 active contributors, and while Jeremy has done the vast majority of the work on the kernel, Redox OS isn't just a kernel. The ecosystem surronding has even more lines and workhours in them. These components are build by many different people, like Jeremy (e.g. Orbital, OrbTK etc.), me (TFS, ralloc, coreutils etc.), and many others. Some projects (like my [formalization of MIR](https://ticki.github.io/blog/a-hoare-logic-for-rust/)) are research project for e.g. proving Redox sund. It is ~~hardly~~ not even remotely an one-man project. We have a whole Redox community and active chat and collaboration. Anyone can PM me if they want an invite.