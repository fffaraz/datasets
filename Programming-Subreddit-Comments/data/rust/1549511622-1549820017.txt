What's clwn?
This is awesome! I'm the maintainer of derive-builder; I'd love to update the docs for both crates with a guide of when to choose one or the other, since I've had people ask for compile-time-checked builders from derive-builder in the past. Also, I'll use this as a chance to shamelessly advertise [`darling`](https://crates.io/crates/darling). It's a library that's designed to make attribute parsing for libraries like this one drop-dead simple, and as of the latest version it also generates good error messages for invalid attributes with no configuration required.
You cannot change the default type of integer literals in Rust without breaking existing stable programs, which Rust has promised to never do. Therefore, the answer is "it can't happen at this point". Further, why do you think `u64` is a better default than `i32`? 32-bit integers perform considerably better on many platforms still in use today, and they have a range that is large enough to be useful for many practical applications while not wasting memory. Also, switching the default to unsigned will probably cause overflow-related bugs, as it's easy to underflow past zero. Last, that change wouldn't be easy (though it wouldn't necessarily be hard), as you would need to rewrite the source of rustc itself to specify that integer literals are `i32`s wherever necessary (because rustc is a self-hosted compiler).
This looks similar to [strum](https://crates.io/crates/strum). Are there cases in which to use one over the other?
I can help with this if you're looking for a solution.
I agree with the part of just how many outdated embedded guides there are. I‚Äôve been writing Rust for TI-Nspire calculators, and it‚Äôs hard sorting out what currently works and what doesn‚Äôt. 
s/Boardcasting/Broadcasting/ ???
&gt; I think such a project could be successful. I'm skeptical for several reasons: 1. An LSP client or server can be written entirely in the language you're already using. (The IDE's client can be written in what the IDE is written in and the language's server can be written in either the language itself or what the language compiler/runtime is written in.) 2. An LSP server is seen as far less of a central thing than a build system, so people are less opinionated about them. 3. An LSP server is a "just works" sort of thing and an ecosystem-specific build automation system can approach that simplicity, while a general-purpose build system has a lot of (very necessary) complexity that people will shy away from if they don't personally need it. (To this day, I've managed to avoid needing to internalize any build systems more complex than GNU Make (*without* autotools), Watcom WMAKE (for build automation in DOS retro-programming), Python's setuptools (`setup.py`), Cargo's `Cargo.toml`, and NPM's `package.json`.) 4. It'll inherently be a huge uphill battle to get people to switch build systems from something that already works well enough for them. &gt; Regarding language, I think also that python is a good compromise language to write such a system in. It runs on most platforms because it is written in C. It is a well known scripting language. Many ad-hoc build systems (x.py, mach) are built in python. As much as I love Python and use it for automation of various types (eg. to orchestrate stuff like puppeting DOSBox to test my DOS retro-programming creations and take screenshots in ways WMAKE isn't expressive enough for), I do so with the understanding that it's a special-case thing. In the DOS case, I use WMAKE for everything which can be done either as a cross-build or within DOS itself using a DOS installation of Open Watcom C/C++ and I use Python 3.x (because it either is or will eventually be pre-installed on most major distros) for things which are specific to cross-building and need to be more expressive than shell scripting makes feasible. *Even then*, if it weren't such a hassle for this sort of task, I'd use Watcom-compilable C to remove Python from the list of dev-time dependencies. For my Rust projects, I tend to explicitly pick my crates and configure my crate features with the intent of making it as easy for 3rd-party contributors to pick up as possible, by making the development instructions no more complex than: 1. Install rustup and let it install Rust and Cargo 2. Download a copy of my repo 3. Hack on the code 4. `cargo build` or `cargo run` Depending on another language runs counter to that and I will shun any build option which complicates the story for allowing a first-time Rust developer to contribute a PR to my projects.
Our crypto platform uses consensus algorithms that rely on gossip and other forms of communication. Even though our algorithms will not break if someone decides to tamper with the gossip they could make our algorithm less fair, slower, or allow censorship. (Consensus algorithms are called fair when the reward for participation is proportional to participation. Censorship is when mining nodes do not include some or all transactions into the blocks, because then they produce blocks faster and get more reward, [see](https://ethereumworldnews.com/mining-empty-blocks-ethereum-could-be-a-problem/).) Therefore our consensus algorithms should be tightly integrated with the network, which makes it harder to use the existing solutions without major modifications. &amp;#x200B; We experimented with libp2p and substrate's network a lot. Unfortunately, they are more trustful than we wanted them to be. Modifying libp2p to support protection against adversarial behavior, suspicious behavior (that's what we call adversarial behavior that we cannot cryptographically prove and therefore slash) or selfish behavior would require a lot of effort, arguably more than writing it from the scratch (since our code does not have to be as generic as libp2p), and it will make our code (+ dependencies) more complex, which is what we really want to avoid.
I won't disagree with that. After all, I do actively seek out crates that can be configured to build without FFI to ensure the easiest possible development experience for new contributors.
r/playrust
Thanks. The crate is performance oriented uuid parse/generate lib. Welcome to issue and pr it.
 ‚ûú cargo check Finished dev [unoptimized + debuginfo] target(s) in 0.04s ‚ûú cargo clean ‚ûú cargo check Compiling pkg-config v0.3.14 -- snip -- Checking my-project v0.1.0 (...path...) warning: unused variable: `a` --&gt; src/main.rs:24:9 | 24 | let a = 1 / 0; | ^ help: consider using `_a` instead | = note: #[warn(unused_variables)] on by default I've noticed I can do `cargo check` and it might not show any warning or errors (see above), but that doesn't mean my code if free of warnings and errors, because if I do `cargo clean` then `cargo check` again, I get warnings and errors. My code never changed during this process. I only get one chance to see the warnings and error after every code edit, and if I miss it I have to jump through hoops like doing `cargo clean` or editing the file again. Is this expected behavior?
I haven't use the new Rust runtime. So not sure of the current situation. I was developing Rust with SAM a while ago. \`sam local start-api\` worked with Rust by using the Go runtime inside Docker. It was pretty slow though.
The answer ‚Äì as usual ‚Äì is: it depends. Where your values are from, how you store them, how many values there are (e.g. do they fit in cache as `u16`?), etc. As Kirk Pepperdine likes to say: "Measure, don't guess‚Ñ¢" (and yes, he owns the trademark).
Hmm.. does this mean that it's a bad idea to have Futures rely entirely on polls, since the executor and the future would then be potentially waiting for each other? Like if I were to, say, implement a timer wait with a future that compares the current time with some value upon being polled...
While we're on the topic.. What do you think of this [Rust NanoID library](https://github.com/nikolay-govorov/nanoid)?
I ended up figuring out, and didn't need to use the Go runtime workaround. If you set the runtime as 'provided' in the SAM template and point it to the zip it works perfectly. Makes sense, as this is exactly how the AWS documentation on custom runtimes explains it. 
Thanks. There are so many pieces of async that it takes time to learn (and remember) them all. Has anyone made a flowchart yet? It would probably help. &gt; One of the great things about Rust‚Äôs design is that you can combine different executors with different reactors, instead of being tied down to one runtime library for both pieces. ...but the downside of that same design is that you pay (in the form of complexity, perhaps also performance) even if you don't use different libraries for different pieces. 
For #1, check out https://github.com/nabijaczleweli/cargo-update/ ‚Äî definitely think this would be a great piece of functionality to move into cargo proper. IMO. 
You could use [cargo-binutils](https://github.com/rust-embedded/cargo-binutils) instead of the GCC toolchain. This even works on Windows then, which would make your tutorial (almost) cross-platform! üòä
My man. I was just looking into using Rust &amp; Flutter together a few days ago, but didn't find anything promising. Mainly I was looking at mobile stuff, but I ended up stopping my search after running into code examples for Android of using JNI to interact with the hardware from the Dart VM, which seemed... not quite what I was looking for. Cool stuff!
That's great :) I'll be sure to reach out. I decided to complete some of the Project Euler problems in Rust as a way to learn by doing. Also started converting a few of my bash scripts into Rust CLIs.
Thanks. So, I understand that sometimes waking comes from a separate thread or an interrupt, and maybe then calling `waker.wake` from that thread makes sense. But since the whole idea of async is to avoid spawning a separate thread for every wait of some kind, it seems a bit weird to design a waker API that is tailor-made for that specific use case...?
I think it's expected, insofar as the behavior is the same for `cargo build` and `cargo test`. (In all three cases, you see warnings when building is actually happening, but not when nothing needs to be built.) I sometimes use a command like touch src/*.rs &amp;&amp; cargo check which prints any warnings for the current crate but avoids rebuilding dependencies.
[https://this-week-in-rust.org/](https://this-week-in-rust.org/)
The Little Typer is a fun book.
As someone unfamiliar with both Dart and Flutter, can you explain the significance of "**Build flutter desktop app in dart &amp; rust**"? How much Dart does one need to learn, or in other words, what types of app-building activities would require Dart vs Rust?
If you could show us your most recent attempt, and the errors it produces, we could give you feedback about what's going wrong. I recommend using `String` rather than `&amp;str` in your main container, since there won't be much borrowing in this problem. I also recommend using the `HashMap::entry` API for initializing hash map keys that don't yet exist.
I'd say mainly make sure you use names that start with your program name, or maybe a top-level directory that's just your program name. Look in `~/.local/share` on a Linux system to get an idea of how these paths get used.
Well, strum looks like a more complete solution, so, not really? Unless for some reason you like my syntax more. To be fair, I didn't know strum exists (my bad for using google instead of crates.io's search). I made this to learn how to write proc-macros and thought i would share it.
The Dart code would be for the frontend. Flutter makes it super simple to make native looking applications for different platforms. Rust would be the backend. 
The Book doesn't explain this properly either. I'm going to file a bug.
I was also confused looking at the example, because all the application code was written in Dart. I believe this is something like the [Desktop Embedding](https://github.com/google/flutter-desktop-embedding), but written in Rust instead of C++.
So why do you think that matters in this case? The pointer will still be 8 bytes long, just the length and capacity will be short. And working with 32bit integers is as fast (and maybe even faster) as working with 64bit integers on x86_64.
I love this crate - just started using it in a new project. Keep up the good work!
Hi! I had a quick read through the sources of the demo, and it looks like the application's logic is written in Dart. So... Is Rust just a "launcher" here ?
You're supposed to learn about type systems?
&gt; So it separates the "executor" from the "reactor", but why? Now that I'm thinking about it, could lifetimes be the reason for the split? I e, the reactor and waker are both `'static` and thus usable with TLS. Whereas this split could enable the Futures and the Executor to be `'a`, i e, borrow from their environment? 
Too bad it will be [deprecated and removed](https://lkml.org/lkml/2018/12/10/1145) from the kernel. But in the end it will just save you only 4 more bytes per string compared to what you can get already with 32bit length and capacity, for a huge price in compatibility.
Yes, if a Future doesn't have a way to ensure that wake gets called, it's somewhat expected that it won't ever get polled again. There are probably exceptions and an executor that just polls everything constantly is totally doable, it's just not the intended way for the interfaces to interact. You can force an executor that only responds to wakeup requests to poll your particular future constantly by calling wake *before* returning a `Pending` result. The executor should then poll it again at its next convenience.
Wait, so is this the flutter engine build with Rust?
No, the executor doesn't need to know anything about the reactor. It just needs to know how to put itself to sleep and wake back up when one of its wakers gets called. The reactor (which is tied to the `Future` implementation, not the executor) then is responsible for receiving the io readiness events and translating them to wake calls.
Areweasyncyet.rs is awesome, might be good to have in an appendix or a ‚Äúcontinue reading‚Äù section
how do i filter out nsfw results?
Right, and that's where a more featureful reactor comes into play. If one reactor can handle the events and wakeups for *all* of the futures, then you only need to have one extra thread. Or, if you put the reactor inside your executor, you can even receive the events in-line with the main execution loop and do all of your waking up without additional threads. I believe that's how tokio works, while romio takes the former "separate reactor thread" approach and doesn't actually include an executor. But don't quote me on that.
With that I fully agree with you. 
Wow, this is perfect timing, I was just getting set up with my Blue Pill using Platform IO and was wondering how easy it would be to set up rust. Turns out not that bad. I'll try it out on my machine over the weekend maybe. What do you think is the best resource for getting started with embedded rust? I'll have to look more at the embedded rust book, but are there other resources you found?
Do you think these optimisation could apply to the `uuid` crate?
If you're looking for something even more powerful for multi-threaded apps, check `slog`. 
My two cents: https://link.medium.com/SNYwTLvO6T
This is a really cool proof of concept! It's fast and it seems to work well. I also quite enjoy the idea of an open source torrent repo, but I gotta ask, is gitlab gonna be okay with this? Seeing as you may potentially (cough cough) be providing magnet links to copyrighted materials?
The best Resource: This Blogpost ;-D Hmm I don't know. I used Google, the embedded books and the Crate documentations. Many posts I found were using custom HALs, which seemed a bit outdated. The crates I used seem to be a bit morr "standard"
Sorry about my tone before, I had a stressful day yesterday and I guess I kind of vented on reddit about a completely irrelevant topic. 
Yeah, good point. Thanks! I played around, but for sake of simplicity I used the gcc ones, as I know how to use them. I'll take a look at it!
&gt;There are so many pieces of async that it takes time to learn (and remember) them all. Has anyone made a flowchart yet? It would probably help. Totally fair. I'm waiting until things stabilize before working on docs, personally.
&gt;There are probably exceptions and an executor that just polls everything constantly is totally doable, it's just not the intended way for the interfaces to interact. [https://doc.rust-lang.org/nightly/std/future/trait.Future.html#runtime-characteristics](https://doc.rust-lang.org/nightly/std/future/trait.Future.html#runtime-characteristics) says &gt; The poll function is not called repeatedly in a tight loop-- instead, it should only be called when the future indicates that it is ready to make progress (by calling wake()). If you're familiar with the poll(2) or select(2) syscalls on Unix it's worth noting that futures typically do not suffer the same problems of "all wakeups must poll all events"; they are more like epoll(4). So yeah, that's not expected. Calling wake repeatedly is probably better, I think.
You use python to build the rust project? 
Can you write the solution here, for future programmers that try to google this problem and end up here?
Thanks, I have approved your PR, and made some further modification: 1. For the nosort version, the results are directly added to a variable `total_area` in the process of refining the intervals, so that the temp variable areas is no longer needed. 2. Based on the nosort version for numba, I correspondingly updated the pure python version. 3. Benchmark results of the new codes are updated. 
I had heard of Flutter before but didn't really read that much into it. Just going off [this article from December 2018](https://medium.com/flutter-community/flutter-on-desktop-a-real-competitor-to-electron-4f049ea6b061) it seems desktop support is pretty immature at the moment. Dart seems to be required since a lot of the widgets for Flutter have been written in Dart, then uses to Skia for a lot of the graphics stuff. From a quick search it seems as though there's also no mature LLVM frontend for Dart, which may explain why it's still a hard requirement even though it can be AOT compiled. Somebody with more knowledge in this space can (and please do) go into more detail about challenges implementing this in pure Rust.
The behaviour of `?` is controlled by a trait, `Try`. You have to implement it for your type, so `some_value_of_your_type?` calls into the `Try` trait. You can't change how it operates for existing types, unfortunately. Documentation for the trait is here https://doc.rust-lang.org/std/ops/trait.Try.html
From that thread: "Additionally, x32 support in many applications is either rudimentary or broken. For example, while LLVM has support for x32, the backend isn't really stable on this target meaning that compilers like clang or Rust are partially broken or crash." Oh well. I guess we end up continuing to fake 32-bit pointers with u32 handles where it matters. (Even Java has a 32-bit pointer implementation for references internally.)
RIIR, anyone? /r/playrust
"Why would you ever need" is something that Rust tends to account for. Edge-cases matter! If you want to really focus on minimising stack size, I'm sure you can find a `String` alternative on `crates.io` that does what you want.
Have you considered using actor model (e.g. Actix / Riker)? Seems like it should work in your case.
Have you tried building it in release mode?
Thanks for the suggestions, cool stuff!
Pushrod is a "Cross Platform UI Widget Library for Piston".
At the base of every executor (scheduler) and reactor (external event manager/listener) is usually a highly sophisticated and well optimized data structure (concurrent atomic or lockfree hashtable) that handles multiplexes exactly all those "virtual threads". So that async becomes more efficient than spawning mass amount of threads (where the OS/kernel manages the scheduling and I/O concurrency for you, but you still have to be careful with shared stuff, eg. memory - hence the the borrow checker). In the specific case of time duration waits reactors use a timer wheel (or timing wheel): https://blog.acolyer.org/2015/11/23/hashed-and-hierarchical-timing-wheels/ (which of course has to at some point rely on the OS to get the current time (gettimeofday, clock_gettime), and sleep for a bit, eg nanosleep). For I/O there has to be again something that interacts with the OS to register those I/O events, and there select, poll, and in more modern times epoll is used. (In Windows there is IOCP - i/o completion ports; and on FreeBSD there's Kqueue, all work sort of similarly, but people can argue about them endlessly: https://news.ycombinator.com/item?id=11864211 https://news.ycombinator.com/item?id=11866592 , and of course in Linux there's signalfd so signals can be waited on through the one big true epoll loop, and people always complain about how horrible Linux AIO is [it is, but ..] but if you preallocate the file [because that's usually a blocking thing, because it has to go and fiddle bits of the filesystem inodes for the file, and the directory, and so on], then with O_DIRECT it's async as fuck - exactly what trent said on the hackernews comments ... so flamewars are fun :) but I guess I got lost with my train of thought quite a bit.) Anyway, eventually for all of these I/O and other "resources" there needs to be a Rust implementation at some level that interface with the lower level messy OS stuff. Probably this is where the "reactor" comes in. (And that's sort of what the mio crate does, it handles platform dependent stuff, as far as I know.) 
It's very much architecture-dependant. Using AMD K10 as an example because that's what I'm working with right now: The smallest size that the load hardware understands is four bytes. Whenever you store a value that isn't aligned to 4, it knows that there is a read-after-write hazard, but it can't easily resolve it. The fastest resolution would be store to load forwarding. The load is filled with the value in the store queue or when the store is committed there. It's possible to do this even earlier (memory renaming) but the AMD manual doesn't disclose whether that's a capability of the K10. So the load has to be filled from L1 cache. That's no big deal, two L1d operations per cycle and only a little bit of latency. But it gets worse. Stores must propagate from the store queue in order. (x86_64 is strongly ordered) So any load that's *near* the small store has a false dependency on all previous stores. But it gets *worse* when you're trying to go fast. Loads must appear to be filled in order. The K10 load queue *can* speculate on load ordering, but it has to fix the read-after-read hazard. Suppose your program does this (plus a few dozen other instructions in the mix) store to A (L2 or L3 cache) .... store to B (small stack variable) .... load from C (stack variable) load from D (atomic variable, L1) and there's a false dependency between C and B. - The store to A is retired to queue waiting on a cache line fill. - The store to B is queued behind A even though the cache is hot. Stores must be ordered. - The load from C is queued behind A, even though there's no true dependency. It can't be retired. - The load from D is filled but marked speculative. - The core has retired A and B and may decode up to 28 cycles past C, at 3 instructions per cycle. - An invalidation message arrives for D. It's an atomic variable and some other thread is changing it.. It would be correct Rust semantics to continue with the speculated load. No matter what the Ordering is on the atomic op, C is known to be local. It will be polled again so a little latency is acceptable. But x86_64 machine language doesn't express relaxed ordering. - So Load D is marked mispredicted - Cache line for A is filled. - Store B is propagated to L1 cache. - Wait the L1 cache store to load latency penalty. - Load C with the correct value and finally retire it. - Restart at Load D: flush subsequent instructions, 12 cycles just to refill the pipeline, *ouch*. The RaW hazard creates a RaR hazard that would normally be minimized by reading only from warm cache lines. The window for this race-like condition is a lot wider when false dependencies are holding it open. (The CPU still does the right thing so I wouldn't call it a data race.) Will a compiler help you out here? Maybe, but probably not. The penalty is only an occasional misprediction so this only *really* matters when you're trying to write branch-free code. Should you worry about this? Probably not. Does it cancel out the tiny performance gains of using a small type? I'd bet they're both in the noise. Now, if you have a large array or this is the difference between fitting a hot buffer in L2 or not the overall cost-benefit is likely different. 
Thanks for sharing! I'd been looking for something which would excite me to get me into trying rust properly and this may well be it, as I've built mobile apps with flutter so it would be cool to try and port them to desktop using rust!
Not OP. And haven't given that a thorough look. But need a v5 replacement. Saves me a bunch of database hits. 
But the executor does not know how to sleep? Because it depends on the reactor whether sleeping means a call to epoll, waitmessage, IOCP, or what native api that the reactor calls to wait for events.
Thank you, thank you. I will persevere (I think). I'm an odd person, I think, in that, I want to do EVERYTHING. I suppose, as much as I hate to perhaps admit it, a "jack of all trades" (master of none?) Although I have a masters degree (in a liberal art) and am a pretty damn good guitarist (been playing over twenty years). I just fear the same may happen with programming. BUT, I truly feel this knowledge could be one of the most important things I'll ever learn, but as a 30-plus year old just starting out, it's daunting in a world where some of the richest, most successful individuals are already younger than you and have been "doing what you're doing" for many years already. I suppose my only hope is to actually - namely Because of my eclectic history and experience - bring something new and useful to the table. End rant. 
Also totally fair :-)
&gt;Previously, concerns were raised that actix-web contained a lot of unsafe code. However, the amount of unsafe code was significantly reduced when the framework was rewritten in a safe programming language ‚Äî Rust. &amp;#x200B; Am I the only one reading this as "previously it was written in another language than Rust"?
It doesn't have to, I think. In your timer wait case, I think the idea is for the executor to run on top of the main loop, instead of being the main loop itself. The executor only posts its task on the main loop if it's awake, and creating a timer generates a different task on the main loop, unrelated to the executor, which wakes it up -- makes it post its task on the loop -- when the timer expires...
Wow, this is awesome, hopefully this will soon be in stable
Fair enough. Thanks for the explanation. It just seems weird to design for any extra threads at all, if the main motivation for async is to avoid threads.
If the executor is running on a dedicated thread it can use [`std::thread::park`](https://doc.rust-lang.org/nightly/std/thread/fn.park.html) to sleep, include a `std::thread::Thread` in its waker, and call [`std::thread::Thread::unpark`](https://doc.rust-lang.org/nightly/std/thread/struct.Thread.html#method.unpark) to wake the executor thread up when any future is ready to run.
Here's an idea: eliminate the capacity field. The memory allocator already knows how much memory it allocated in a block it handed out, otherwise it wouldn't be able to release or reallocate it. That would require having a call to retrieve allocated memory size, which is not standardised across platforms, but popular libcs do provide them: there's `_msize` on MSVC, `malloc_usable_size` on glibc and some BSDs, and `malloc_size` on ~~Mac OS X~~ ~~OS X~~ macOS. Rust's former default allocator, jemalloc, also provides it. Cons: overhead of calling the allocator to check if the allocation is large enough, and some logic bugs may be harder to catch.
I see people say this a lot on the internet, but it's really not true at all. People successfully convey sarcasm on an almost daily basis in the chat rooms and forums that I frequent. Word choice, punctuation, formatting, cadence and content of the surrounding text and more all contribute to a written "tone of voice" that's just as rich as spoken tone. The specific sentence tobz1000 quoted just doesn't contain any clear indicators of sarcasm. Especially since the rest of the post [seems to conflate futures with tokio](https://www.reddit.com/r/rust/comments/an8ts4/osakars_rust_async_without_the_noise_an/efrxq2r/), it's very plausible that this sentence is a serious, genuine conflation "rust" with the web/desktop app ecosystems. I choose to give the author the benefit of the doubt and ignore that particular sentence only because it isn't central to any of OP's arguments, unlike the futures/tokio conflation.
Flutter already has over 50k stars on GitHub and has incredible momentum already. I am older and seen a lot of tech come and go and rarely do you see something gain as much momentum as Flutter this fast.
I think so
They're very high resolution screenshots that are being downscaled by your browser, picking one at random it's being scaled to ~33%, so quality probably depends on your browser downscaling implementation (maybe they still look good on a retina monitor, so wasn't noticed by the blog writer?).
Deja Vu. I'm pretty sure this exact sentence and question has shown up here before, and the answer was something like "we meant it was rewritten in *safe Rust*". Even then it's weird phrasing.
What is that?
YES
But that is my whole point. Why can't it be the other way around, efficient strings in std, and special crate on crates.io for strings larger than 4billion characters. The vast majority of strings in computing are shorter than 16 characters, but each such string pays a little for this edge case of 4billon characters. You shouldn't pay for what you don't use, "zero cost abstractions" and all that.
Et voila: https://rust-lang.github.io/async-book/getting_started/chapter.html
I am also confused by this. How can the lifetime chain be broken properly without altering logic or introducing unnecessary complexity?
Because edge-cases matter. Covering "the vast majority" but failing on the edge-cases is not an acceptable thing in the world of Rust. This really isn't something that should concern you since there are very, very few circumstances in which this is a performance problem. If it is... well, that's what crates.io is for. This falls under the umbrella of "zero-cost abstraction" since, in 99% of cases, it has zero or negligible cost. x86_64 likes 8-byte alignment anyway, and loading a 64-bit number into an x86_64 register is no slower than loading a 32-bit number. I know that intuitively it seems wasteful, but when you consider the design of the CPU architectures on which 99% of Rust code runs, it's actually note a problem. If you compile for i386... then guess what? `usize` suddenly becomes 32-bit and the problem is evaded there too.
Could this be a somewhat ill-considered attempt at a joke?
is there a way to avoid panicking and instead "assert" it as a failed test.
If you're looking for situations in which Rust's `std` favours stability, correctness and ease of maintenance over performance, there are many. Rust is still a relatively new language, and `std` is still relatively unoptimised. The focus is more on stabilising interfaces: performance is secondary. If you really, really, really need neck-breakingly fast types (surprise: you probably don't), then there are plenty of compatible alternatives on crates.io, but that isn't a goal for `std` yet, and probably won't be for some time.
Thank you for doing this and I hope there are more efforts towards some of the really, really exciting and cheap boards. These are some of the cheap, and relatively powerful boards: - The Blue Pill STM32F103 : (but I prefer the Maple mini version): http://wiki.stm32duino.com/index.php?title=Maple_Mini - STM8S103F3P6 ( 8 bit) https://www.st.com/en/microcontrollers/stm8s103f3.html - ESP8266 : One of the most bang for buck with a wireless support on board : https://en.wikipedia.org/wiki/ESP8266 Other interesting but more powerful alternatives: Raspberry Pi, STM32F4, ESP32. 
What does escaping a reference mean? Could you provide an example?
A mixture of gfx-hal and pathfinder would be ideal for this. I don‚Äôt know how to use pathfinder though and if it works together with gfx-hal yet.
Awesome. Thanks for the link
If you're a more visual learner, /u/jonhoo has an amazing explanation of async from the kernel up [here](https://www.youtube.com/watch?v=9_3krAQtD2k). He ends up explaining everything about how reactors work with futures and even gets into nightly features that aren't stabilized.
Heya, I've just made a toy prompter for you. [You'll find it here](https://bitbucket.org/Ad_Au/toy_prompter/src/master/). It uses Amethyst engine (tailored for games), and it's pretty simple for now. You will have to play a little bit with creating/deleting entities (which appear/disappear on the screen) of text and better handle loading texts. This solution is fully compliant with points 2 and 3. However, I can't say for point 1, maybe it'll be better to simply use the monitor configuration of your OS.
Is this a fullscreen thing you want to draw? ...because, if so, I'd think that using your OS's display control panel to set up a mirrored configuration between the two monitors would be the simplest and most reliable way to ensure that both monitors display identical content.
Please do PM me. :)
I have some ideas for an object-capability enhanced ambient authority shim. This would enable you to override the assumed authorities of std for a given code block or function. Including allocations (as alloc-counter already does to a simpler degree), networking, filesystems, threads, and reading/writing from the global file descriptors stdin/out/err. Using the same thread\_local! stacked scopes in alloc-counter. You could use this to redirect anything that tries to do eprintln, in a defined scope, to your configured logger. &amp;#x200B; For now I'll leave it as eprintln until I have something written down for this safer std-shim.
- I have been learning Rust through the book + discussing and practicing with the rust meetup group folks for quite some time now. - Learning on company's time would be awesome but I don't get those apparently I'm spend most of my time fixing bugs or on enhancements. But yeah learning rust and practicing projects was on personal time. - oh! yeah I felt TypeScript + Node would be better. I'm very productive with Node.js - But I have a project in mind which I want to take up with my mentor mostly related to netconf and yang. Also I felt there are some libraries I want to port to Rust.
2 days back I saw a talk by Michael Snoyman. Probably one of the best talks I have seen where he focused on long term maintainability and code refactoring. Thanks for the pointer. :+1:
Have you thought of using/creating a DHT crawler (like what https://btdig.com/ does) to find public torrents (regardless of tracker) to populate your database of torrents?
Ah, I get it. So it's a marker that Juniper can use to invoke other arms of the macro.
With Enduro/X Middleware and their UBF buffers you may write enterprise level, microservices based open applications with C/C++. The framework gives process level parallelism/load balancing, clusterization, distributed transactions and very flexible data buffers. Thus you may write simple C single threaded apps with global variables, use static "char" buffers and get code which is quite simple. But with help of the middleware you load balance the processes in multiple copies (even hundreds of them) and use powerful API for service calling. Thus in the end you get solution which is built by several binaries (services &amp; clients), which is very scalable, ultra fast (fast middleware which uses kernel queues for IPC and C modules are fast too) and reliable (as middleware may reload/restart dead components) . Telecoms and banks are using such frameworks today and new software is being developed for it too.
Ok, so I'm not an expert on this stuff, so take my explanation with some skepticism. I'm interested in getting a good answer to this myself, so here's what I've found so far. Lifetime parameters in structs basically communicate that the struct acts as a 'view' over some data (and that data must outlive the struct.) The `Dispatcher` is a 'view' over of the following types of data: pub type SystemExecSend&lt;'b&gt; = Box&lt;for&lt;'a&gt; RunNow&lt;'a&gt; + Send + 'b&gt;; pub type ThreadLocal&lt;'a&gt; = SmallVec&lt;[Box&lt;for&lt;'b&gt; RunNow&lt;'b&gt; + 'a&gt;; 4]&gt;; Note that `Dispatcher` is storing *trait objects* and that the lifetime parameters are really bounds on those trait objects. This essentially allows you to specify a `Dispatcher` which can contain trait objects for *references* which implement `RunNow`. (Remember you can implement a trait for a type or a reference. The `+ 'b` syntax is necessary to allow impls for references in trait objects.) So for a `Dispatcher` to be valid, it can only refer to `RunNow` implementors (your systems, IIUC) which outlive it. If you build a `Dispatcher` using references, their lifetimes must be provided in the `Dispatcher` parameters. If you build it using owned objects, you can use `'static`.
Yeah I also always had problems with the documentation being outdated. Simple stuff (sorry: blinking an LED) was ok-ish. But as soon as I tried to do more stuff (IIRC semihosting &amp; -rt) I ran into problems.
By 'lifetime chain', I assume you are referring to the fact that a lifetime parameter on a struct has to be present on all structs which contain it. The answer is that you *can't* break this chain without using a 'static' lifetime. The struct is only valid if it lives within the lifetime of some other data, and the only way to guarantee that occurs is to propagate this condition up to all containing structs, or use static data which is guaranteed to always exist. If you have a lifetime parameters on a struct, you should really think of that struct as a 'temporary' kind of object which should only exist while you are directly using it. If you want it to live a long time, you need to structure your program hierarchically so that everything can run in a lower scope, or you need to make the struct own the data (with awareness that Arc/Rc are convenient shared ownership constructs.) 
Super interesting: Data Races in Safe Code.Rust supports shared variablesin atomic types, such asAtomicBool,AtomicPtr, andAtomicUsize. Read and write conducted on atomicvariables are automatically ignored by Rust‚Äôs ownershipcheckings. All races in safe code are caused by misusingatomic operations.
Yep!
It's not so much that thread avoidance is the goal, but rather using threads more efficiently. It's kind of like using a thread pool and a work queue rather than spawning a thread per thing that needs doing.
So, I didn't read the paper, but from this, I think this is the issue. These are \*not\* data races. These are race conditions. Data races are UB, race conditions are not.
There's also the [RobotDyn version](https://robotdyn.com/stm32f103-stm32-arm-mini-system-dev-board-stm-firmware.html) that I've been using lately. Basically a blue pill but with some of the problems solved (supposedly)
Have you tried debugging yet? I don't have an st-link, so I'm not really sure how that works, but I've had great success using another bluepill(-ish) board acting as a black magic probe to flash/debug my target device.
Well, it's for Rust. But it uses Piston. I fixed it . :)
So... would `push` still be amortized with this approach?
Section 4.3 talks about data races in safe code, but I disagree with how they're using the term "data race". The two atomic operations in question are memory safe, since the memory in question will never end up in an indeterminate state. It's the lack of atomicity for the operation which is the bug, as they correctly describe, but that is usually described as a race condition rather than a data race.
The benchmarks-game is measuring performance on hardware Quad-Core 2.4Ghz Intel¬Æ Q6600 \[How programs are measured.\]([https://benchmarksgame-team.pages.debian.net/benchmarksgame/how-programs-are-measured.html](https://benchmarksgame-team.pages.debian.net/benchmarksgame/how-programs-are-measured.html)) &amp;#x200B;
I've used this crate: [https://github.com/NikVolf/parity-tokio-ipc](https://github.com/NikVolf/parity-tokio-ipc) Seems to work fine, as long as you mind the quirks of Windows named pipes.
Thanks! I clicked on several links and just could not find that page. In fact, going back to the home page, I still can't find my way to it. In any case, it looks like while the compile options are different, they likely do not result in pertinent codegen differences.
Great, thanks a lot. 
Just use async await. They are nightly yet, but it's much much easier to catch with async using them
This worked great, thanks!
&gt; Are the data races on these flags harmful? Perhaps not. For example, in the evening we might shut down all transaction-processing threads and then select 10 random accounts that are flagged as having had activity for manual auditing. For this purpose, the data races are entirely harmless. Is this part still accurate? My understanding was that modern compilers will read this code and assume that the variable you're setting is un-aliased, which can then lead to UB down the road because of invalid optimizations. I think I'm getting this from Herb Sutter's Atomic Weapons talk, where he says there can be "benign races" in machine code but there's no such thing in code you feed to the compiler.
&gt;The specific sentence tobz1000 quoted just doesn't contain any clear indicators of sarcasm. That's the thing, when you are actually talking, you can convey sarcasm without any indicators other than tone and gestures. When you write that down the sarcasm is lost.
This is my most recent attempt: use std::collections::HashMap; use std::io; use std::fmt::Display; fn input&lt;'a, T: Display&gt;(text: T) -&gt; String { println!("{}", text); let mut commands = String::new(); io::stdin().read_line(&amp;mut commands) .expect("Failed to read line"); commands } fn main() { let mut employees: HashMap&lt;&amp;str, Vec&lt;&amp;str&gt;&gt; = HashMap::new(); loop { let commands = input("How can I help you?"); let args_vec: Vec&lt;&amp;str&gt; = commands.trim().split_whitespace().collect(); if args_vec[0].to_lowercase() == "add" { let name = args_vec[1]; let department = args_vec[3]; employees.entry(department).or_insert(Vec::new()).push(name); } else if args_vec[0].to_lowercase() == "remove" { let name = args_vec[1]; let department = args_vec[0]; let list = employees.get_mut(department).unwrap(); let index = list.iter().position(|x| x == &amp;name); list.remove(index) } else if args_vec[0].to_lowercase() == "display" { let department = args_vec[1]; println!("{}", department); for name in employees.get(department) { println!("{:?}", name) } } else if args_vec[0] == "goodbye" { println!("Goodbye"); break; } else { println!("I'm sorry, that is not a valid command.") } } } This is the error that keeps popping up: error[E0597]: `commands` does not live long enough --&gt; src/main.rs:22:35 | 22 | let args_vec: Vec&lt;&amp;str&gt; = commands.trim().split_whitespace().collect(); | ^^^^^^^^ borrowed value does not live long enough ... 28 | employees.entry(department).or_insert(Vec::new()).push(name); | --------- borrow used here, in later iteration of loop ... 53 | } | - `commands` dropped here while still borrowed 
You could start by waiting till it is stable :-)
There's no categorizing the torrents, it's just a list of the most popular ones, so no nsfw filter currently (most torrent search engines don't have this either tho). I'm open to possible ways to do this tho.
They've been okay with it for a few months, but if they decide to shut it down at some point, I'll just move it to a self-hosted gitea instance.
I would run a DHT crawler but unfortunately I live in the US (which has data caps), and running one is very heavy. I have one ready to go tho if someone else could run it.
Here's a maybe-stupid solution: 1. Prerender the whole text to an image. 2. Scroll image on both monitors. GPUs are great at translating textures, and text-wrapping happens in advance.
Yes debugging with the ST-Link worked. The open source ST-Link tools provide a GDB Server
Perfect, thank you. It looks like you're running into the difference between `&amp;str` and `String`, which is a very common issue for folks learning Rust. If you have time, I'd recommend re-reading the [ownership chapter of TRPL](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html), which goes into all sorts of detail about the ownership rules and why they are the way they are. But I'll try to summarize a bit here for your specific case. The core issue is this line: let mut employees: HashMap&lt;&amp;str, Vec&lt;&amp;str&gt;&gt; = ... The quick fix will be to turn both of those `&amp;str` types into `String`, and then to just fix the rest of the type errors you get by inserting `.to_string()` calls. (You'll also need to `if let` or `unwrap` your `index` variable, since you can't use an `Option&lt;usize&gt;` as an index directly.) Here's some more context about why that's the right fix: What the type of `employees` is saying is that the keys and values in your map will both be "string slices" (`&amp;str`), which are _borrowed_ strings, essentially pointers to strings owned by something else. That in turn means that if the map outlives any of those owners, the borrow checker is going to get upset. (In C or C++ that situation would turn into a "dangling pointer" and undefined behavior, but in Rust it's usually a compiler error, which is a huge win for safety.) The error you're seeing, `commands dropped here while still borrowed`, is exactly this. The compiler is saying that you've tried to stash pointers to `commands` inside of `employees`, but `commands` doesn't live long enough for that to be safe. Let's look at that in more detail. let args_vec: Vec&lt;&amp;str&gt; = commands.trim().split_whitespace().collect(); ... let name = args_vec[1]; let department = args_vec[3]; ... employees.entry(department).or_insert(Vec::new()).push(name); The type of `args_vec` shows that it's a Vec of borrowed strings, and it's borrowing them from `commands`, which is an owned `String`. That means that `name` and `department` are also borrowed strings tied to `commands`. So finally, when you try to insert them into `employees`, the compiler has to ask, "ok hmm, is `employees` allowed to contain pointers to `commands`?" And the answer to that question is no, because `commands` only lives for a single loop iteration, while `employees` lives on past the end of the loop. But when you call `.to_string` (or `.to_owned`, both work) on a `&amp;str`, you copy the data into a `String` that allocates and owns its own storage. That object is no longer tied to the lifetime of the data it came from. When you insert a `String` into the employees map, ownership of the `String` and its storage passes to the map, and the compiler sees that everything is consistent and fine. If there's a single rule of thumb here, it might be that "containers of references have to be short-lived." If you want to hold `&amp;str` or `&amp;[u8]` or `&amp;mut u64` or anything like that, it had better be the case that your container is only going to exist for a short time, while those references are valid. A long-lived container usually needs to fully own its contents, to avoid lifetime issues.
Without any context, I would say that you have the wrong abstraction. If you're trying for code that can accept either a Bar or a Baz but performs differently depending on which it receives, then you're looking for `enum`.
Rust has no RTTI. When the compiler is done with them: * Like in C, a struct is just the concatenation of its members' in-memory representations, plus any padding necessary to meet alignment requirements. * A method call is just syntactic sugar for a function which receives a struct as its first argument. While insane tricks do exist which can let you tell what you've got, they should only ever be used in debuggers and the like. You need some kind of marker. (Theoretically, it's always possible to tell Bar and a Baz apart in any language which allows raw memory access. Just get a known Bar and a known Baz and check which one your function pointer matches... but it's not something to ever trust in production code. It's a hack that should be limited to debugging. For example, for picking apart a bug that vanishes when you try to enable debugging symbols.)
As someone who sees fads and the latest and greatest web development frameworks come and go all the time, could you elaborate on the excellence? In particular I am exhausted of learning all of the new niche languages, and I only want to make the time investment if it's really worth it. I'm making that investment for rust because of the borrow checker and the attempt to make a modern systems language heavily differentiated from most of the other contenders -- but Dart just looks like someone trying to patch all the bad mistakes in JavaScript (if JavaScript is C++ then dart is D, not Rust).
Alignment need not be specified in the interface of `InlineBox`: you can place the item appropriately in the buffer (skipping some bytes) as necessary.
Rust provides the [`Any` trait](https://doc.rust-lang.org/std/any/) which is implemented for all `'static` types (required because type erasing a lifetime is not sound). Compared to other languages Rust's run time type information implementation is _very_ bare bones. This is both good and restricting. Using Any you can only downcast to a concrete type, it can not be used to check if a type implements a trait. Whenever you think you need `Any`, consider if you can achieve your goal in a different way. _Why_ do you need to tell if it's a Bar or Baz? Can the functionality that is different for these types not live in the trait itself? Eg a trait method which does whatever is unique to each type? (that is kind of the entire point of using traits) If that is not the case, why not provide 2 different methods each specialized for Bar or Baz? Do you _need_ them to fall under the same function name? Do you want to overload the method based on the type name? Rust does not have overloading (sort of...), consider just making 2 methods.
Nice! Is the difference between the BNO055 and the BNF055 is that the "O" part has firmware, while the "F" part is program the M0 yourself? The crate is to interface to the running firmware of the BNO055?
[removed]
Rust types behave similarly to C structs, they have no introspection capabilities, so if you need that, you need to provide your own. And the traits by themselves are not types. If your function accepts something that implements `Foo` (`fn accept_foo&lt;T: Foo&gt;(f: T)`), that means you the function is generic over types implementing `Foo` and it will be monomorphized for all types it accepts (`rustc` will generate different functions for all types that are passed to it). If you accept a trait object ‚Äì some kind of a smart pointer to `Foo`, like `&amp;Foo` or `Box&lt;Foo&gt;` ‚Äì then it won‚Äôt be generic and will actually accept two pointers, one to data ‚Äì the original struct, and the second one to the data type‚Äôs virtual table of the `Foo` trait, and here Rust AFAIK also does not generate any introspection capabilities. If you really need that, you might add some function like `fn type() -&gt; &amp;'static str` or `fn type() -&gt; TypeEnum` to your trait.
While that sounds like much, I have absolutely no information on how much LLVM bytecode is normal. Do you know how much the clang frontend generates?
Flutter has a hot reload with the tree shake and it keeps state between runs. Which is really weird at first to get use to but for development just is incredible. Dart is a very easy language to pick up and is key to Flutter being performant. I have been around a long time and seen things come and go and Flutter is the real deal. 
Do you have the full code available?
Rust beginner here, is this approach likely to be the one to be further fleshed out and become the standard in rust core going forward? In other words, is it worth hunkering down and investing in this approach, in the medium to long term?
Yeah, but why wait?
Yes async/await will be the standard. I don't think it makes sense to look into the much more complicated futures/tokio approach now. Just wait until async/await is ready. At least that's what I'm doing. :-)
Thank you! You got my code to compile. I appreciate the detailed explanation too. You've been a big help!
Awesome, thanks for the heads up, I know what I'll be doing this weekend :)
That's not a stupid idea at all! I'm pretty sure a lot of current teleprompters take that approach, since they take a couple seconds to move from the "editing" view to the "display/scroll" view. I'd personally like to be able to do basic text editing without dropping out of the scrolling view down the road, but as an MVP, that could work.
This enum can be made to be the size of two strings, it just hasn't been implemented yet. See [this issue](https://github.com/rust-lang/rust/issues/46213)
The tricky thing with using a "mirror display" option is that one of the screens often has to be horizontally flipped to account for going through a mirror. Also, it would be really nice to have the talent's monitor in fullscreen, but have the operator's screen be windowed so that other programs or controls can be open.
That's awesome, thanks! The problem with simply screen mirroring, is that the talent's monitor often has to be flipped horizontally to account for mirrors in the physical teleprompter. It would also be nice for the operator's monitor to be able to show controls that the talent monitor doesn't have, but that's a future feature.
Thanks. I ended up writing a little script: #!/usr/bin/env bash find . -iname "*.rs" -exec touch {} \; || exit 1 cargo clippy -- -W clippy::pedantic 
Cool article! I appreciate the clippy shout-out.
Awesome. This `String` vs `&amp;str` distinction really gets at the heart of what makes Rust different from other languages, so once you've gotten comfortable with it, learning the rest of the language will be a lot easier.
That makes a lot of sense.... I'm wrapping my head around it still, but that does make sense. In the current structure of my program, the systems belong to the dispatcher, so I think from what you've said, the static lifetime is fine. I guess I'll have to reevaluate if I ever want to dire tly own some of the systems. Thanks for your help! 
Code of the driver is on Github: [https://github.com/eupn/bno055](https://github.com/eupn/bno055)
So I am writing a macro to simplify my code (and to learn of course!). My idea is to write as_result!(e, MyEnum::Variant, MyError::Error) and to be interpreted as match e { MyEnum::Variant(n) =&gt; Ok(n), _ =&gt; Err(MyError:Error) } But I am having trouble writing it. I currently have macro_rules! as_result { ($e:expr, $wrap:expr, $err:expr) =&gt; { match $e { $wrap(q) =&gt; Ok(q), _ =&gt; Err($err) } } } Any ideas?
I'm excited to see if the new `Pin` api will allow zeroing memory more reliably.
I would say the idiomatic way to do something RTTI-like is a custom derive. If you really want runtime casting though then trait Foo: Any and using downcast_ref might work for your usecase
For the "one windowed, the other fullscreen" the best solution would probably be to render to a texture which you then present in both windows. It's been far too long since I touched OpenGL, and I did far too little of it, so I don't know how you'd go about mirroring the texture in the GPU but, if you're using an X11-based graphics system (eg. on Linux), then mirroring one of the screens is simple. For example, this will mirror my left-hand monitor horizontally: xrandr --output DVI-I-1 --reflect x
Maybe read the `tokio` [docs](https://tokio.rs/docs/getting-started/echo/). `await` isn't quite there yet, but the basics will stay the same. In that example, `tokio::spawn` is used to spawn another task on the same executor. The docs also show you how to start the runtime.
Escaping is a bit hard to define as it refers to the escape analysis that LLVM performs and doesn't correspond directly to language features. At a high level it means the reference has "escaped" the function, which can happen by: 1. Storing the reference on the Heap (e.g. \`Box\`) 2. Storing the reference in a global variable 3. Passing the reference to another function that hasn't been inlined 4. Storing the reference inside another escaped value When this happens LLVM is forced to use the canonical memory layout defined for the enum and can't cheat by breaking in to registers. As a general rule if you're only using an enum value within a single function it won't escape. LLVM will treat it as a bunch of scalar local variables and optimise appropriately.
Really? It seems to me that misusing atomics could easily lead to actual data races. In particular relaxed loads and stores to the same location. It's just a very unsurprising result. Also I disagree a lot with the claim that atomics disable ownership checking.
The use case is a self-evolving tree; for each call, the tree is traversed and a new tree produced. In some cases, the constructor for a node can make performance-significant choices not to return a new instance of itself, but of a different node that removes dead branches, but in order to do so it has to be able to tell what kind of node it received to place there. I'm asking this because I've done that, and while the results are promising the actual implementation was fractured and messy. I want to move the decision-making operations into factories associated with node types, so that it's explicit what node is being used and what choices are being made. 
I'm making a basic real-time event loop framework for a computer game (for learning purposes). Currently I'm using the `DateTime` struct in the chrono crate for representing time. Well actually the NaiveDateTime, but that may change. If I were trying to make a highly performant application with this framework, is this crate suitable?
That's very interesting. Thank you for the thorough explanation!
This paper is bad, but maybe it's at least valuable as something to learn from. The authors measure the number of "`unsafe` tags" in Rust code across Servo, TiKV, and `rand`, then make this claim &gt; Compiler checkings do restrict Rust‚Äôs programmability. Future works on more precise compiler checkings to give developers more flexibility and verifying unsafe code in Rust to provide a certain level of confidence in safety are needed. The second part of this _may_ follow, but the first is... confusing. Did the authors look at what `unsafe` is being used for in these codebases? `unsafe` is required to do FFI and the compiler _cannot_ verify that FFI is safe. The authors attempt to quantify unsafety by the amount of times the keyword appears which is _very_ dubious. A single unsafe block can contain a lot of non-obvious programmer-maintained contracts. Number of lines of unsafe code would be a vastly better metric (though still possibly deceptive). Why the authors didn't do this I don't know. The authors also appear to have conflated a generic race condition with a data race. These are _very_ different issues, and again their methodology is suspect. Searching the commit history for the word "race" is a strange approach when Servo's issue tracker has `label:I-race`. Based on their sloppy methods and use of terminology (and possible misunderstanding of data races), I wouldn't believe any of the claims made in this paper.
The best example I have is a web server. If you request a piece of information out of the database, that's wasted time that the web server could be using to process other incoming requests. Once the data comes back, the web server can respond to your initial request with the values it got back. The crucial bit here that a lot of my colleagues and I struggled on is that async code isn't faster--it's actually a little slower (at least in C#). The benefit is that throughput is dramatically increased. If you're writing a single-threaded app that just immediately awaits asynchronous operations, you're not really getting any benefit from it.
Especially opening a file should not panic since it is very likely to happen. The application should handle this. I only use `.expect()` when I'm pretty sure it will not happen. If it happen anyway, it's a bug and the developer should get information, why this occurred. 
Uh, /r/playrust?
I used to use failure description, but i think it saves time to just describe the operation (expect("open config file") etc). But I'm interested to hear other's opinions of it anyway.
Lol mb
Ok, so if I'm understanding you correctly, you think that the specific example I provided is a poor time to use `.expect()` because file IO fails too often. But, stepping back from the specific example, you think that the first use of `.expect()`‚Äînamely, providing the developer with helpful error messages‚Äîis a good reason to use expect? (As opposed to just for documenting invariants?) Did I get that about right?
Yup, exactly! 
You can also just `transmute` reference to something on heap and `forget` container. But that is not what you usually do. Forgot about `Box::leak` though.
Rendering to a texture sounds right. I think I convinced myself I could split the entire text into texture "panels" so that each one isn't gigantic. Then I might even be able to have basic editing since it's not rerendering the entire text at once. So, then it's about finding the right way to draw text onto a texture.
Do you know all of the different possible node types? If so, then you may want to try using an enum to represent a node, rather than a trait. &gt; I want to move the decision-making operations into factories associated with node types, so that it's explicit what node is being used and what choices are being made. Could you implement this as a method on the trait that the nodes share?
This is precisely the case where you want enum, not rtti.
For that web server, how can it process other requests if it's awaiting on a DB query?
The typical approach to represent different types of tree nodes in Rust is to use enum variants, something like, for example for a hypothetical DOM tree implementation: struct DOM { root: Element, } enum Node { Element(Element), Text(Text), } struct Element { name: String, attributes: HashMap&lt;String, String&gt;, children: Vec&lt;Node&gt;, } struct Text(String); Or for a toy programming language AST, you might do something like (taken and simplified from [my attempt](https://gitlab.com/silmeth/yarli/blob/master/src/lox/ast.rs) at a Lox interpreter): pub enum Expr { Binary { lh: Box&lt;Expr&gt;, op: BiOperator, rh: Box&lt;Expr&gt; }, Literal(Value), Unary { op: UnOperator, rh: Box&lt;Expr&gt; }, Logic { lh: Box&lt;Expr&gt;, op: LogicOperator, rh: Box&lt;Expr&gt; }, // ‚Ä¶ } pub enum Stmt { Block(Vec&lt;Stmt&gt;), Expression(Expr), While { condition: Expr, body: Box&lt;Stmt&gt; }, // ‚Ä¶ } pub enum UnOperator { Not, Minus, } pub enum BiOperator { Plus, Minus, Mul, Div, // ‚Ä¶ } pub enum LogicOperator { Or, And, } Then you can just match on your node types. match(node) { Node::Element(elem) =&gt; process_element(elem), Node::Text(text) =&gt; process_text(text), }
&gt;Build flutter desktop app in dart &amp; rust So is this what I think it is? Build a front end with flutter and dart while the heavy logic is done by rust? I mean can we mix flutter (frontend) with rust (backend)? Dart VM FFI just moved from "todo" to "in progress", this could open a more direct integration between dart and rust [https://github.com/dart-lang/sdk/issues/34452](https://github.com/dart-lang/sdk/issues/34452) Flutter + Rust would be a dream come true.
I haven't watched the talk but I've gone through the slides, and Sutter explicitly calls out that atomic reads and writes are safe from reordering.
I'm not sure I understand the question. Let me break it down two ways: \- How does a second request get processed? A web server is usually built to be asynchronous and multi-threaded; it processes the requests as soon as it can wherever it can. Note that async and threading are very different and not replacements for one another. \- But doesn't the database query block the request? No! Good async implementations don't block anything. Imagine that the method gets chopped in the middle at the \`await!\` and just stops running--not blocked on some spinwait, just not scheduled . The second half will get scheduled to run when the async method has completed (by some magic, be it completion ports, interrupts, or what have you). I come from C#, so that's my mental model, but from what I gather, the Rust solution is conceptually similar, if implemented differently. You might benefit from reading [There Is No Thread](https://blog.stephencleary.com/2013/11/there-is-no-thread.html).
When using `.expect` on a `Result`, the panic message is your message, then a colon, then the error message itself. So I like to describe what failed at a high level like `.expect("Could not reticulate splines")` so that the panic message says what was running and what went wrong, like `Could not reticulate splines: actual error message`.
I do not believe that relaxed ordering introduces data races. The model does not imply any kind of ordering around memory accesses, but it still guarantees atomicity, so only atomic values that could have been written will be observed.
this is a constant overhead over field access. to answer your question- yes
Decided to give rust a try after frustrations related to the slow speeds of javascript, and create a simple media streaming application. The app is going to be based on rocket, and ideally would first query and create a struct containing all of the files (in a vector), and then cache it for use. Whenever a request is sent for the data it would be sent by serialization. In javascript, this shared data would be handled with a global variable, however rust does not seem to allow this feature. Any and all help in learning the more pragmatic programming patterns for this is much appreciated! &amp;#x200B; Here is the minified forms of the two functions that need to be able to share data: &amp;#x200B; #[get("/")] fn index() -&gt; Template { //how can I access paths? Template::render("index", &amp;context) } fn main() { let paths = fs::read_dir("./").unwrap(); /* How will paths be shared with fn index? */ rocket::ignite() //etc }
There really isn't outside of trivial CLI programs. Panicking is rarely an acceptable alternative to returning an error, especially for 3rd party crates. 
I'm not quite sure what your model of data race is then. The typical example is executing something like `a += 5`. Except for syntax that is` a = a + 5`. The data race only occurs because reads and writes interleave unexpectedly. Performing the exact same operation with atomics can produce the exact same problem, even with sequential consistency. If a data race only occurs when to writes partially overwrite the same data, as you seem to imply, I don't think they even exist for register sized values. And (at least on x86_64) we only have those as atomics in Rust.
What do you thinks about cases like the one the Rust Book describes as [having more information than the compiler](https://doc.rust-lang.org/book/ch09-03-to-panic-or-not-to-panic.html#cases-in-which-you-have-more-information-than-the-compiler)? The example it gives is fn main() { use std::net::IpAddr; let home: IpAddr = "127.0.0.1".parse().unwrap(); } How would you handle that? You can *guarantee* that parsing "127.0.0.1" will never fail. Would you leave it as a bare unwrap? Or an expect that documents why you're sure it won't fail? (trivial in this case, but one could imagine examples where you're just as unwrapping can't fail but where it might not be obvious in six months.) Or would you still return an error that you handle, even if you know it won't ever come up?
I was more thinking about the implementation of that crate. Im trying to get a nrf52832 devboard to work myself, and having some troubles getting gdb + openocd to work.
&gt;the method gets chopped in the middle at the `await` and just stops running Then how are any other requests supposed to get handled? 
&gt;There really isn't outside of trivial CLI (command-line-interface) programs. I'm pretty sure a 5 line program with no IO fits well into this description. --- There is also nearly no real world scenarios where you'd write that code as why would you hard code that constant? And if you wanted to hardcode it you could use an `[u32;4]` and avoid the panic. 
All the requests run independently of one another--each request is independent, while the web server coordinates all of them. If you're looking for how, I'd suggest you read the Tokio docs that were posted earlier.
can i pass some expression to hide certain phrases like 'xxx' , at least?
Ok. What if it's more than http. What if you have a persistent tcp connection, and any peer can ask you to do some async operation at any time. How do you do something like that?
Try `$wrap:path`
It depends on the type of code: Library code can't panic for these types of things (missing config file, etc), although it still should for broken invariants. Application code should probably only panic in this way at startup, and even then only if it's an unexpected error that it can't really recover from, and the error would be developer facing anyways (so most CLI tools shouldn't just panic as an error message, but if your server can't find a config, panicking is fine). Tests should usually just panic. The test runner will catch the panic and mark the test as failed. Throwaway code (prototypes or demos) can panic.
Awesome! thanks
I live in the US and have never heard of data caps.
HTTP is just a layer over top of TCP, so the process is going to be very similar. I'm not sure of the particular implementation details.
That describes writes. Is it the same for reads?
They're basically the same from the application's point of view. Under the hood, I'm sure there are minute differences.
I ask because I've been trying to implement something like this and I have not been seeing the use case for async. Maybe I am not thinking about it right, though, which is why I ask here
if you want a deep dive into the internals of how something like tokio works, this is a great read: [https://rust-lang-nursery.github.io/futures-rs/blog/2018/08/17/toykio.html](https://rust-lang-nursery.github.io/futures-rs/blog/2018/08/17/toykio.html) &amp;#x200B;
Wow! This looks really amazing. Thanks for sharing it. I'm looking forward to trying it out; would love to hear from others who have.
70% of the US has data caps. Comcast, atnt, cox all give you 1 TB per month. 
I'll see if I can figure something out. 
Thank you :). To be honest I'd also love to hear from others who try it :P
Hmm. I have had Comcast before and never heard of any data caps. Looks like this isn't a thing in the north east? https://www.theverge.com/2016/10/6/13192832/comcast-xfinity-home-internet-data-caps-one-terabyte
For reference, here's the process described in the Stripe docs: &amp;nbsp; **Step 1: Extract the timestamp and signatures from the header** Split the header, using the , character as the separator, to get a list of elements. Then split each element, using the = character as the separator, to get a prefix and value pair. The value for the prefix t corresponds to the timestamp, and v1 corresponds to the signature(s). You can discard all other elements. &amp;nbsp; **Step 2: Prepare the signed_payload string** You achieve this by concatenating: - The timestamp (as a string) - The character . - The actual JSON payload (i.e., the request‚Äôs body) &amp;nbsp; **Step 3: Determine the expected signature** Compute an HMAC with the SHA256 hash function. Use the endpoint‚Äôs signing secret as the key, and use the signed_payload string as the message. &amp;nbsp; **Step 4: Compare signatures** Compare the signature(s) in the header to the expected signature. If a signature matches, compute the difference between the current timestamp and the received timestamp, then decide if the difference is within your tolerance. To protect against timing attacks, use a constant-time string comparison to compare the expected signature to each of the received signatures.
Hello, I wrote a public function in MyProject/*src/my\_file.rs*, I want to do some benchmarks in *MyProject/benches/bench\_function.rs*, how can I include the file so I can use the function ? I already tried `mod my_file` and `use my_file`
Do you have plans to make this into an project-agnostic application that can serve the same purpose the desktop emulators currently do?
&gt;You cant miss you, Effie! I cover the floor unconscious. My fingers stroke the smooth my hair, olive skin, weaving disguises from vines to conceal the boys like her, waiting for a sign of another eligible boy, I think about what exactly protects it from the woods. I trust their sense my pursuers are not extreme enough. &amp;#x200B;
A survey of existing S-expression parsing libraries found on crates.io, and why I think it would make sense to create yet another one ([obligatory XKCD reference](https://xkcd.com/927/), based on the ideas found in https://github.com/zv/sexpr, which is not published on crates.io.
You need to *publicly* declare the `my_file` module in your `lib.rs` file, so that it gets included in your crate and exposed to callers. Just having it in the `src` directory isn't enough. For example: lib.rs: pub mod my_file; my_file.rs: pub fn number() -&gt; u64 { 5 } benches/bench.rs: #![feature(test)] extern crate my_project; extern crate test; use test::Bencher; #[bench] fn bench_number(b: &amp;mut Bencher) { b.iter(|| my_project::my_file::number()); } 
I'm all about the idea of the one ui framework to rule them all, but... &gt;Closest thing would be Qt with Python. There are a number of things out there that try and accomplish the same goal. But they all have the same problem, which is that you can't deploy the same UI to every platform. The best you can do is enable developers to customize their UI for each platform in a way that's sane. &gt;But then there is the fact Flutter spans iOS, Android, Windows, OS X, GNU/Linux and iOT. It's going to be a real challenge for them, but I'm stuck here wondering why I want my MacOS/Windows/Linux app running on iOS or Android or vice versa, why I need a runtime on my IoT device. Maybe we should stop treating all platforms like they're created equal? If there's anything that's true in UI, it's that one size cannot fit all. 
The standard way to get your hands on a global in Rust is the `lazy_static` crate. If the struct only needs to be initialized once and then never modified, that crate by itself might be enough, with all the initialization taken care of the first time it's read. If you do need to modify the struct after initialization, then you can to put it in something like an `RwLock` to allow mutable access through the `&amp;T` that `lazy_static` gives you. It might be that Rocket provides you some other mechanism to get data from `main` to your request handlers, but I need someone more familiar with that framework to chime in here.
The servers runs an "event loop", basically a loop which checks a set of sockets if they're ready to be read or written (operating systems have a special system call for that). At first you create a listening socket and add it to the set. When a client comes, the socket becomes "ready to read", which means that connection can be accepted. So you call "accept()" on it and a new socket is born and you add it to the set. So when a client sends some data on the connection, the server is notified that a socket is ready to be read. You call "read()" to read the data in non-blocking mode, which returns EWOULDBLOCK if there's no more data available. (For example, the client sent 8 bytes of data and you read 8 bytes of data, then a subsequent call to read() will return EWOULDBLOCK immediately). This is the moment when you can switch to something else: if there other sockets ready at the moment you can process them, accept new connections or whatever. After all sockets are processed the loop turns and starts waiting for sockets in the set to be ready again. I would recommend learning [mio](https://docs.rs/mio/0.6.16/mio/) to get a feeling of how async works on the lower level before going tokio/async-await route.
This ia really good write-up! I think this will become my go to article to share if they ask my about Rust. It explains its core principles in a very clear and concise manner. Two things &gt; Send [...] more descriptive name for this trait might be UniqueThreadSafe. &gt; Sync [...] A more descriptive name would be SharedThreadSafe Interesting analysis. It took me a while to understand Send and Sync and their exact differences. I still feel they are somewhat poorly named. But the parallel with shared vs. unique references and shared vs. unique ‚Äúthread-safeness‚Äù really helps. &gt; ... we need UnsafeCell&lt;T&gt;. The compiler knows about this type and treats it specially. Is this actually true? I always assumed it was implemented entirely in the stdlib without compiler support.
&gt; you can't deploy the same UI to every platform. Not sure what you mean here. So if already aware I apologize for explaining when I do not need to. Flutter is different. It includes everything. Which is also pretty weird and cool at the same time. So I can deploy my Flutter app on Android with iOS behavior/look/feel, etc. Or I can do Android on iOS. It is part of the application. It does NOT use native. So if want iOS you use Cupertino. If want Android you use material. The reason you want is because it is insane we have completely different teams doing development. It is incredibly inefficient. But we just never had something that was truly performant. 
Thank you! That's exactly my think of rusty way to solve this.
This is great! One thing I wish could be improved here: The explanation about how the compiler treats UnsafeCell specially depends on the aliasing concept introduced in the previous section. This isn't ideal; aliasing and optimizations is an implementation detail but UnsafeCell has a real meaning at the language level. Better would be to first have a paragraph explaining UnsafeCell purely in terms of unique/shared ownership, which is what the whole article is about anyways. This especially helps if the reader is only skimming at this point ;)
UnsafeCell is marked with `#[lang(...)]` which makes it a ["lang item"](https://manishearth.github.io/blog/2017/01/11/rust-tidbits-what-is-a-lang-item/) that has special meaning built in to the compiler: https://doc.rust-lang.org/1.31.0/src/core/cell.rs.html#1444 
Thanks; that‚Äôs a good point.
attribute macros are the shit
The [Async book](https://rust-lang.github.io/async-book/getting_started/why_async.html) is also a good read.
I also was stumbled upon bizarre problems with nRF52 + OpenOCD only, but recently figured out that OpenOCD somehow downloads broken firmware to the chip and it HardFaults. So I switched to JLinkGDBServer for firmware uploading and continue to use OpenOCD for debug and semihosting. Semihosting also doesn't seem to work with JLink's GDB server. &amp;#x200B; That being said, could you try the same approach? Stick to JLinkExe / JLinkGDBServer for firmware download and OpenOCD for debugging, for me that worked. Good luck!
This is awesome! Thanks for releasing these graphs! Is there any raw data you can provide in addition to this? (Maybe in CSV format or something?)
Another observation that I've made during this week is that RTFM doesn't seem to work with nRF52's low power mode. In particular, when you execute \`WFI\` instruction within \`#\[idle\]\` handler, software tasks that were scheduled with timer-queue will never run. This is because nRF52 enters low-power mode by \`WFI\` instruction and ARM core and its peripherals (SysTick and DWT) are stopped during this mode. Since \`timer-queue\` are built on top of said peripherals, it stopped working too. As workaround, I've reimplemented RTFM's \`timer-queue\` on top of nRF52's RTCs, which are working during low-power mode.
Thank you! Now I have the error *cant find crate for 'my\_project*' :( 
Yeah, I just tested with the JLinkGDBServer for uploading. I'm using the commands JLinkGDBServer -device nRF52832_xxAA -if SWD -speed 4000 arm-none-eabi-gdb -q target/thumbv7em-none-eabihf/debug/rust-embedded (gdb) target remote :2331 (gdb) load But it seems no matter what I do when I try the load command it only reports with (gdb) loadStart address 0x0, load size 0 Transfer rate: 0 bits in &lt;1 sec. I am very new to tinkering with embedded outside using premade solutions, SEGGER IDE w/ debugger and ICE + ATMEL, which requires nothing in comparison to set up.
Ignoring the debate on whether or not **these particular** cases justify a panic - these are not two different use-cases but different approaches to the same usecase. `except` may cause a panic, and a panic should always have the same meaning: &gt; _I'm not going to deal with this possibility because I know that this possibility can never happen, but the type-system doesn't know that it can never happen so I need to assure it that if it does happen it can be considered a bug, and the program should crash with a stack trace that can be used to track and fix that bug._ So - your code should panic if there is a bug. Also, your code should never panic. These two claims may seem contradicting, but they are not - because _your code should not have bugs_. Of course, that's easier said than done - we are only human and codebases can get large and complex, so there will be bugs. And that's why we are using `expect()` instead of `unwrap()` - so we can have some context in case there is a bug. So - both examples are of the same usecase - the type system believes there is a possibiliy (config file cannot be opened or full name is missing) that you consider a bug so instead of writing code that deals with it you tell the rust to crash if it happens and provide a short message to help debug it if it does happen. The difference between the approaches is how that short message is phrased. The first one describes what **went wrong** (the config file could not be opened) while the second describes what **should have been** (`full_name` should have been set in `get_full_name()`). As far as I know, there is no consensus in the programming world on which style is preferable - but consistency is always good so you should stick with one of them, at least in the same create. And since the standard library and docs seem to prefer the former (saying what went wrong) - I'd say that unless you need to match an existing codebase then this is how you should be phrasing these messages.
If `"127.0.0.1".parse()` returns an `Err` - that's a **bug** in your code, and you want it to panic so you can get a detailed error message with a stack trace. If `fs::File::open(&amp;config_file)` returns an `Err` that's not necessarily a bug, because there could be many external causes for that. Maybe someone deleted the file? Maybe there is a problem with the disk? Maybe the program runs under windows and the config file is locked for writing?
Sorry, I used a different crate name. In your case it might be `MyProject`. It needs match whatever name you're using in `Cargo.toml`.
&gt;Not sure what you mean here? What I mean is that a desktop is fundamentally different from mobile or IoT. The ability of a framework to _target_ multiple platforms is not valuable in and of itself. I can already do that in a dozen different ways that don't require me to learn a new programming language or use a different toolchain. To me the value of cross-platform UI is the ability to roughly translate my UI and styling to a different platform, but retain the freedom to interact with the UI in a platform specific manner. For example, mobile has no concept of windows, menu bars, or key commands. MacOS menu bars are integrated into the app, on Windows they're drawn onto the window itself. I could go on, but the point is that different platforms don't deserve the same UI, since users don't interact with them in the same way (nor should they, mobile UI on desktop sucks). Simple things like mouse interaction that's analogous multitouch is just a first step, there's a laundry list of crap a cross-platform toolkit needs to be useful. Personally I don't care about hot loading either. My users' time is more valuable than mine, I can wait a few seconds for something to build.
I care
I've put the right name ( The real name is TestRust ) I wrote it with the CamelCase, and it matches the name in the Cargo.toml
Didn't realize there was a survey. When was this?
Hey you're the clippy guy! Thanks for your work!
I don't think I'm going to as it is quite a pain working with LimeSurvey (even though I appreciate the free and open source project), and the answers have personal details in some of them like E-mail addresses provided in comments, as well as it records IP addresses, and I am not very eager to try to make sure everything is sanitized. Also, I made the tag clouds myself by copying and pasting each response and then manually removing the words that were irrelevant, and the raw text of the comments I am not comfortable with providing because people clearly thought they were going to be kept private as some people gave me their E-mail addresses for example, and I don't want to try to sanitize the raw data. &amp;#x200B; The biggest thing I got from being able to view the raw data was to see that even though Beginner is very large in the tag cloud for things sought after in Rust literature, people actually primarily want beginner through to advanced material regarding advanced concepts like lifetimes, traits, generics, and macros, rather than wanting beginner material such as "what is a variable" or things like that. So the capital beginner is a little bit misleading as compared to the raw data, which actually suggests people want primarily intermediate to advanced material. &amp;#x200B; Other than that, I just directly entered and double checked all of the numbers into a graphing tool, as the survey software wouldn't make proper graphs out of the raw data due to the size of my answers causing them to all be cut off. I could see this being cause for concern as I had to rephrase many of the answers people had to pick from, but I am not actually concerned that this tainted the data and am actually going to use these graphs and such myself rather than the raw data. Example of a change in answer -&gt; &amp;#x200B; Which sorts of language do you have the most experience with? (Classifying languages is hard, but which of these keyword sequences sounds the most familiar?) &amp;#x200B; Virtual Machine, Compiled, Byte Code: Java Scripting, Command line, Configuration: Bash Compiled, Machine Code, Systems Programming: C and C++ Interpreted, Scripting, RegEx: Ruby, Python, and Perl Web, Scripting, Routing, Interpreted: Javascript, PHP Other &amp;#x200B; Became -&gt; Which sorts of language do you have the most experience with? &amp;#x200B; Compiled Interpreted CLI Scripting Web Virtual Machine &amp;#x200B; Other actually did have one result in the survey that I didn't record in the graph here, but that is the only one that had more than zero responses that I didn't include. All of my changes were like this, so if you think that preserved the validity of the responses, I don't think any of the other changes I had to make to let it display as graphs are any more concerning than it. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
That's a good first approximation. Here's another: if an end user of your application sees a panic, then you should probably consider that a bug that ought to be fixed. Who's to blame for it might be a bit trickier. If you're using `expect()` on File I/O then it's you, but if a library you're using does it, then the bug is in the library.
When using `.expect` on a `Result`, the error message (what comes after the expect message) is just what's contained inside the `Result`.
There are many cases where you receive a `Result` or an `Option` and you *know* that it will *always* be an `Ok` or a `Some`. In those cases it is correct to use `unwrap`, as the compiler can't know that those are always going to be `Ok` or `Some`.
I wonder how someone tells if a metering library is fast. In other words, who meters the metermen?
Can you expand on this a little more?
Can't you get into a invalid struct state from a race-condition? That's basically a data-race if invariants are broken by using relaxed ordering while messing with many atomics.
I'd rather say I'm one of the various clippy folks. I'm not even that active in developing it anymore.
If you have a `Vec&lt;u8&gt;` of sensitive data, you may want to zero it on drop. Sadly, this won't wipe out any old memory that was left behind if the underlying buffer was copied during an expansion. I was just wondering if it were possible to use the new Pin api to guarantee that all the memory containing the sensitive info can be cleared. I'm not an expert in this area.
Well, actually, technically there was also one vote for "not yet learning rust" or whatever that I didn't include a bar for, as that person submitted after I had already finished making the graphs and things. So the very last person to take the survey had no results applied to it, but thankfully they only said they were likely to read a free book and hadn't yet started learning Rust. 
About 48 hours ago I posted a link to it here and on the official Rust forum. Results came in very fast at first but there had been no activity for several hours when I started making the graphs, but one person did submit during the time I started making them. Also, as I recently discovered, a much larger **(and completely unrelated)** survey of Rust users was officially conducted by Mozilla, in case anyone wasn't aware of this. [https://blog.rust-lang.org/2018/11/27/Rust-survey-2018.html](https://blog.rust-lang.org/2018/11/27/Rust-survey-2018.html) So, their survey was actually conducted in 14 languages, and most likely provides a more holistic data set, but the **unofficial** one I posted on Reddit and the Rust Forum about two days ago also has some insights I believe, &amp;#x200B; &amp;#x200B; 
I have a setup which has a single command build &amp; deploy &amp; debugger attach from cargo run with hosted output including panics visible as normal output. No OpenOCD is used either, but needs another microcontroller, either a cross-flashed STLink, a programmer on the board or another Blue Pill. PM me if you need it now, but I'll definitely put it on GitHub when I have some time.
Won't large stack values cause similar issues with running out of registers?
How it would work is basically this: The tokio runtime manages all of your sockets (or other IO resources if you are using them) and a pool of threads that your actual code can run on. The runtime uses the OS's underlying mechanism to efficiently watch many sockets at once (epoll on Linux) and keep track of which ones are ready to be read from or written to. When your code does await! on reading or writing on a socket, it gives the runtime a "Future" which tells the runtime what condition needs to be met for it to continue to do work (i.e. for the socket to be ready for that read/write). Then, its thread goes back into the thread pool so that some other task can be scheduled on it. When the runtime has a thread in the thread pool that is ready for something to run on it, it will check the Futures for one that is ready to run and then it will use the thread to run from where that Future was awaited.
Your crate is producing an empty binary, the linker should be specified in `.cargo/config` and optional dependencies should be bundled into a feature in `Cargo.toml.` &amp;#x200B; Filed a PR with fixes: [\#1](https://github.com/trondhe/rust-embedded/pull/1)
Also, please note that there is an implicit selection of linker file and chip model in [Cargo.toml](https://github.com/nrf-rs/nrf52-hal/blob/e438a5a2a674b21e8f5162eb5da49330d0a55771/nrf52832-hal/Cargo.toml#L48).
Only if the scalar values that make up the enum are actually used. For example, `String` and `Vec` have a capacity `usize` to allow for efficient appends. If they‚Äôre never appended to then LLVM is free to eliminate the capacity register completely. Similarly, variants that are never constructed and alignment padding do not need to be stored in registers. LLVM can typically pack structs quite efficiently in to limited registers. The rest will be spilled to the stack as needed. 
Well thanks for it anyway, it's a great tool.
One nuance is that while it‚Äôs true that mutable values and references must be unique, the inverse is not true. One thing that I love about Rust is that variables are ‚Äúimmutable by default‚Äù, which makes certain classes of logic bugs easier to avoid. This is orthogonal to the discussion of mutability and memory/thread safety, but I do think it is an important feature. Conflating mutability and uniqueness shadows this point.
Sounds great. Creating such a setup will be my next step. If you put it on github, I'll surely take a look!
&gt; Only if the scalar values that make up the enum are actually used Oo. This is a very good point, that I hadn't considered. Thanks :) 
&gt; Is this actually true? I always assumed it was implemented entirely in the stdlib without compiler support. It is not possible to implement UnsafeCell&lt;T&gt; without special-casing it in the compiler. It is basically a marker for "this type breaks the contracts assumed for references to types". Everything else that uses it can be built in the standard library.
I love this! It looks like a super neat design. I just might try and implement a serialization backend for this, since I've long wanted to hook up veneur (which I work on at work) to rusty code. Metered looks like it'll take good care of the parts that I wouldn't have designed as neatly (:
Why are people downvoting this thread?
I, for one, am super excited to see Aaron wanting to work on specialization and generic associated types. If he realizes his vision for Tide, then it'll be great for the ecosystem as a whole too!
It must be done in kernel. Clearing libc or rust buffers is not enough, as there are a lot of places with buffered i/o: 1. Rust std lib 2. Libc 3. Kernel 4. Pages 5. Memory device To ensure your sensitive data is not stored you have to hack all of this stuff and zero all levels stuff, and even so you can't be sure 100%, as device's controller can tell you after your request that it cleared the data while it simply could ignore you.
This looks really interesting. I'm curious about the decision to use unquoted paths in the attributes; last I checked, `syn` didn't support this, and as a result `serde` and other crates have wrapped paths in quotation marks.
&gt; Metered lets you build your own metric registries from bare metrics, *or will generate one using procedural macros*. You say that it uses no globals or statics, but it will also create a registry for me. How can that work? Does the procedural macro somehow crawl all the source files and find my annotations?
+1, Coming from C++17, seriously miss templated using declarations inside structs (which I think are equivalent to GATs).
r/playrust Seriously we gotta get some kinda karma requirement or a bot to get rid of this stuff
Uh, is it just me or is this a definite trend now? Can anyone tell me whether I should be concerned?
You can run micro benchmarks. You'd assume the crate includes some self measurement mechanism.
Quoting the post: &gt; I‚Äôm staying on the Rust team at Mozilla, but will be shifting my focus to more technical work, particularly on the compiler. GATs and specialization, here we come! I also plan to remain on the Lang Team and to continue work on Tide. He's renouncing his role as a manager to spend more time writing code.
Hmm, I was tempted to add xray support to `rustc`. This makes me think that maybe there's a market for that.
Because of the existence of pattern matching and combinator functions like `and`, `and_then`, `unwrap_or`, `get_or_insert`, etc, I find that there are *very* few cases where I find it necessary to use `expect` on an `Option` or `Result` generated by my own code. The only time I tend to use it is to unwrap things returned by libraries I am using.
Being on the core team is exhausting. I made the same decision years ago and I'm still as much of a Rustacean as ever.
You define a registry object in your instance and you bind it using an annotation. Check out the readme example.
Actually this made me pretty excited. GATs and specialization can't come soon enough
Good luck Aaron! Keep up the good work! 
Did you comment on the wrong post?
Unless you just created that file.
It's guaranteed for you, not for whoever wrote that parser code. I try to only use `.expect()` in tests and when it's acceptable to panic (which is pretty much never to be honest, but oh well). Panicking in CLI is weird because the end user has no idea wtf is that. I use `.expect()` for example when I get a lock on mutex - if a lock is poisoned then I have a serious problem and issa bug in my code, that case should never happen, so providing proper error handling is a waste of time IMO. Library? there I got extra effort to never panic, only do `.expect()` when I'm 100% sure it will never fail. 
Ah the other thing is that I think it needs to be a lib.rs/library and not a main.rs/binary. Maybe that's the trouble? (If anyone from the cargo team is reading along, this is a case that could use a more helpful error message.)
First two words of title: panic. Rest of title: sigh of relief. I'm *really* glad Aaron has decided to step down from managerial duties‚Äînot because he wasn't good at it, but because it was clearly a draining role. It's great that he had the maturity to do this before burning out and needing to leave Rust altogether. And now we have someone extremely capable, who knows all the history and has all the context, working on high profile features that users really want.
You should not be concerned: the post makes it clear there's no need to be.
great post!
When I see `Send` I think about a value being sent on a channel. When I see `Sync` I think about a value protected by a mutex. 
This error is raised from the fact that `thread::spawn` requires that all captured variables are `'static` because it makes no guarantees that it will complete within the lifetime of the function its called in. You can wait for a thread to finish, but you don't have to, hence it's not secure to capture any references with a shorter lifetime than `'static`. What you want is [rayon](https://crates.io/crates/rayon), which has several constructs you could use. Most notably it has `par_iter`, which returns a parallel iterator that automatically distributes the work of the iterator across a thread pool. 
That's reassuring. I actually thought you were still on the core team.
But you are a very smug person, at least on the stupid orange website. And from what i've seen here too. So i bet everything is exhausing for you.
Thanks for the reply. I looked into `rayon` originally but it didnt seem to fit my use case. Can you tell me if im wrong? The overall idea of this function is to return vectors with n indexes, and each index in all vectors across threads should correspond to the exact same word. This is why i use `hashmap_mutex`. It contains the index that should be used for each word. When a new word is found the mutex is locked the new word is inserted. After looking over the `rayon` documentation and `rayon:scope` i dont see anything that can guarantee the indexes are the same in all return values. As for my implementation I tried to `.join()` all threads at the end of the function to ensure that the value would be kept alive but the error persisted. Are there libraries / alternatives to achieve this goal ( and am i missing something in the `rayon` documentation)? 
i would also add the very powerful cheap K210 based risc-v MAIX modules: https://www.indiegogo.com/projects/sipeed-maix-the-world-first-risc-v-64-ai-module#/ https://www.seeedstudio.com/catalogsearch/result/?cat=&amp;q=k210 and synthesized risc-v cores on FPGAs (especially latttice ICE40 and ECP5 ones, which can by used by open source development tools), which allow interesting co-designs of typical ¬µC- and hardware accelerated circuits on affordable simple boards (e.g. https://radiona.org/ulx3s/). i don't think, you'll find much rust support for this kind of approach until now, but for example the FuPy project (https://fupy.github.io/) looks very instructive in this regard.
Am I missing something? Stripe sign their API responses. That happens on the server side, and it's not something that a client library can control. If Redding doesn't do the same thing, then it's not going to happen. But both Reddit and Stripe get a pretty high level of authentication from HTTPS, which uses TLS, also known as SSL. If you receive an HTTP response form the Reddit API, you can be pretty sure (under certain assumptions about e.g. corporate environments) that it came from reddit.com. Do you have reasons not to trust HTTPS? Can you go into more detail about what you're trying to achieve?
Can we throw you away?
you'll get cramps soy
You could use a scoped thread like [`crossbeam::scope`](https://docs.rs/crossbeam/0.7.1/crossbeam/fn.scope.html) to run threads with non-static references. I don't understand your problem description enough to help you deal with your index guarantees, but maybe rayon's `par_chunks` will work to just parallelize that outer loop directly. vector.par_chunks(n).for_each(|chunk| { count_occurrences(...); });
`Mutex&lt;T&gt;` is actually `Sync` regardless of whether `T` is `Sync` (though `T` does need to be `Send`). It's `RwLock` that requires `T` to be `Sync`.
That‚Äôs the spirit! Good luck with your book!
Opened a pull request for the standard lib. https://github.com/rust-lang/rust/pull/58289
Depends on what you define as the trend; in some ways, this announcement is the opposite of mine. I left Moz, but not the core team, Aaron left the core team, but not Moz. In general, things happen, times change. This is normal and expected. It's also why we have the teams rather than a BDFL; we can survive people moving on.
No ad hominems on my watch.
Reddit fuzzes downvotes; it's possible that nobody downvoted it even though it may show some.
To clarify a bit; async/await \*produces a Future\*, so you can't really totally ignore futures as a concept. You can not worry about how to implement the Future trait.
I've tried to read your description several times but I can't seem to understand it. Could you post some inputs and what you would expect as outputs? Maybe this is a [XY-problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem) in the sense that you're trying hard to solve it a certain way but there is a easier way to solve it if you explain more of the overarching goal you have? 
Even then permissions could be messed up. 
&gt; I'm not quite sure what your model of data race is then. The typical example is executing something like `a += 5`. Except for syntax that is `a = a + 5`. The data race only occurs because reads and writes interleave unexpectedly. In the terminology of Rust's safety guarantees (derived from the terminology of C++'s memory model), this is a *race condition* (multiple threads may interfere with each other), but if the accesses individually are atomic (i.e. relaxed loads and stores), it is not a *data race*, which is undefined behavior. Put it more concretely. Let's say I have this code: fn thread_func(counter: &amp;AtomicI32) { for _ in 0..10000 { counter.store(counter.load(Ordering::Relaxed) + 1, Ordering::Relaxed); } } If I run this code in many threads in parallel with the same counter, I get a race condition: the loads and stores may interleave and thus increments may get lost. However, because I'm using atomics, I do not get a data race, i.e. *undefined behavior*: I am guaranteed to not get torn reads, partial writes, or the compiler deciding that this whole code is nonsense and doing something else entirely. (Fun fact: because of the way relaxed operations work in the memory model, I'm pretty sure the compiler is allowed to optimize the loop to a single +10000 addition. I don't think it currently does.) Safe Rust only guarantees the absence of data races, not race conditions; in fact the latter is probably impossible to statically guarantee, because whether something is a race condition is sometimes dependent on the goals the programmer wants to achieve.
&gt;I'm not quite sure what your model of data race is then. The classic definition is: A *data race* happens when there are two memory accesses in a program where both: * target the same location * are performed concurrently by two threads * are not reads * are not synchronization operations My understanding is that even if you get the orderings incorrect, this is still a "synchronization operation", and so getting it wrong is a data race, not a race condition. Not an expert on atomics, though.
Thank you so much! Ill go out of my way to get a BNO055 and test out your crate in return! I see that your changes matches a bit up with what the nrf-52 rtfm example does. It seems like my code was some misunfortunate combination of that and the instructions given in the rust embedded book. Thank you again.
It would be nice if you could link here in the PR.
To put it in simple words, in order to process multiple things interleaved, there has to be some point in the codebase where an async operation is *not* immediately awaited, but instead added to a list of pending async operations. In a web server, this place is probably inside the HTTP server implementation where it accepts connections. If you write, say, a little command line utility for downloading many files at once, that place would be the loop over the list of files; it would start each download as an async task, but *not* await it immediately. In any given code, this can also, for example, happen if you take multiple futures and combine them with `when_all` or `when_any`. If you then await the resulting combined future, all the async functions inside will interleave, i.e. when one blocks on an await, the others may continue to make progress.
... another process deleted the file. Filesystem operations are inherently racy, and should always be treated with suspicion.
Oh, I did in the commit message and gave you credit
Done.
True
This subreddit is about the programming language rust and not the game
I'd say this is off-topic here. &amp;#x200B;
To be clear, I wasn't referring to Rust's mutex or Rust's channel, I was talking more generally. My understanding is that: \- \`Send\` implies a transfer of ownership across a memory barrier. \- \`Sync\` implies synchronised access where ownership is not transferred, eg a mutex protected value. \- A value that implements \`Sync\` is using some kind of mutual exclusion and is therefore "mutex-like". These are all fundamentally language-agnostic ideas.
Speaking in generals: It's not surprising and not too concerning. Goals being hit (like Edition 2018) often opens up space for change that people don't want to enact before. This phase _is_ always a as risky as any change phase, so I don't want to say that you shouldn't bother. Just be clear headed about it and try to watch out for positive and negative changes coming in the wake.
fucking love you mate
I don't think `crossbeam::scope` or `rayon::scope` fit my use case because it does not appear that they can share and update a piece of memory to stay consistent between threads. Let me explain with an example my situation and why its important. If you have a vector_1 of phrases: `["a sample", "another sample"]` and a vector_2 of phrases: `["sample sample", "a sample"]` and a vector_3 of vectors holding all counts: `[]` then my code would do the following (single threaded): //vector_1 first word: "a" =&gt; add ("a, hashmap.len()) to hashmap (since its not there already), `vector_3 = [[1]]` second word: "sample" =&gt; add ("sample", hashmap.len()) to hashmap, `vector_3 = [[1,1]] // start second word word: "another" =&gt; add("another", hashmap.len()), `vector_3 = [[1,1,0],[0,0,1]]` word: "sample" =&gt; **"sample" is in hashmap**, fetch its index and update that position =&gt; `vector_3 = [[1,1,0], [0,1,1]]` //start vector_2 word "sample " =&gt; **"sample" is in hashmap** =&gt; `vector_3 = [[1,1,0], [0,1,1], [0,1,0]]` word "sample" =&gt; **"sample" is in hashmap** =&gt; `vector_3 = [[1,1,0], [0,1,1], [0,2,0]]` //second word of vector_2 word "a" =&gt; "a" is in hashmap =&gt; `vector_3 = [[1,1,0], [0,1,1], [0,2,0], [1,0,0]` word "sample" =&gt; **"sample" in hashmap** =&gt; `vector_3 = [[1,1,0], [0,1,1], [0,2,0], [1,1,0]]` It is important that the indexes that correspond to each word remain constant (and that the total length of each vector) remains constant because dot products and magnitudes will be calculated later on. If the hashmap is not updated between all threads then the indexes of the words will not all match. The name of the problem I am dealing with is [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) if it helps at all. Is there a way to solve this threading issue with `rayon` or `crossbeam` scopes? Side note: i remember seeing your name on [this](https://github.com/rochacbruno/rust-python-example/pull/3) pull request which is one of the first things i was reading when deciding to use rust over c / cpp 
I think the intent was to contribute to the discussion on what hurdles would need to be overcome to stabilize Rust's ABI in the future.
I think the intent was to contribute to the discussion on what hurdles would need to be overcome to stabilize Rust's ABI in the future.
I added a detailed example in the other comment [here](https://www.reddit.com/r/rust/comments/aod9zq/lifetimes_help_with_passing_chunk_from_vecchunks/eg09wub/). It may very well be an XY problem as you mentioned. The core issue with using the `crossbeam::scope` and `rayon::scope` is that i do not see a straightforward way to share the hashmap between threads (which is critical and explained in my example). Without sharing and updating the indexes for each word the resultant word counts will not be formatted correctly. I hope I have cleared things up
I actually do the opposite. I'm paranoid about code I didn't write myself panicking in a situation that *I* could recover from (eg. malformed input in a hand-written parser when doing batch processing), so I don't use `expect` for third-party crates because the `std::panic::catch_unwind` blocks that I wrap all my third-party calls in would turn `expect` into a shoddy attempt at exception-based error-handling.
You guys are too nice I'm telling you :)
I like to think of it like this: 1. If it's something you expect a downstream consumer to encounter, pass the `Result` or `Option` up the call stack. 2. If it's something that either should never happen (eg. failing to parse a constant string) or which you can't safely recover from (eg. memory parity error), use `expect()`. 3. You're free to use `expect()` in the top-level application (as opposed to a library) as a shorthand for writing your own "If `Err`, die with a message" code with uglier output but I don't because I feel it's unprofessional to expose `expect()` rather than designing a more user-oriented format for fatal error messages. 4. Designing your application around passing `Result` up the stack makes it easier to add proper support for batch processing later, rather than relying on `catch_unwind` to stop the panic at the level of a single batch job.
To share and update a hashmap across threads you can use `Arc` and `Mutex` as you already did. Using `rayon::scope` or `crossbeam::scope` only enables you to have a non-static shared reference. In your first piece of code you used `chunks` which takes a shared reference, hence we assume you needed the ability to do that. If you need mutable access one option is as mentioned `Arc` and `Mutex` as you used in the code example. In that situation you can use `thread::spawn` because you move a separate `Arc` into each thread. 
It wasn't meant as a goad, but as something worth looking at as a future direction for Rust. The technical aspects are probably best described in the Swift ABI Stability Manifesto, which is originally from 2017: https://github.com/apple/swift/blob/master/docs/ABIStabilityManifesto.md But the news that this is no longer theoretical, but something they've actually pulled off ‚Äì for the first step, anyway (standard library ABI stability) ‚Äì is quite interesting to me, and I thought it was worth posting here.
I'll concede that this is correct by the definition of the memory model. It just feels very unhelpful. You remove the data race, but retain the problem that (supposedly) you had due to a data race (i.e. it appears to be the example that's given most of the time). It seems to me that you would lose very little, but remove a case of undefined behavior, by just defining regular writes on primitive types to be relaxed atomic writes. Obviously not a problem/option in Rust though due to borrowck.
Interestingly enough, I also had a problem doing this earlier. I found that even when developing with 2018 edition, I had to use the `extern crate test` to import the `Bencher`.
I don't want to kick you when you're feeling down, but you might be looking for r/playrust ;) This sub is about the programming language Rust.
This works! Thanks you so much for the help it would have taken me much longer to figure it out. Thank you /u/CUViper aswell. I didnt realize you could just do that. 
This is pretty huge for Rust. Be great if Rust became the primary way to develop system code with Zircon. Zircon is written in C and C++ but with this API it could be a boost for using Rust to develop additional system code.
&gt; It wasn't meant as a goad, but as something worth looking at as a future direction for Rust. Ahh. It comes across as a potential goad because the benefits of having a stable ABI have been obvious all along, and there's been an issue open for it [since 2015](https://github.com/rust-lang/rfcs/issues/600), so people who see it are likely to dismiss your actual intent from consideration because "this is stuff that's easy to find with even the most trivial of googling, so it'd be an insult to accept the 'he's that ignorant of past discussion' interpretation without more evidence". &gt; But the news that this is no longer theoretical, but something they've actually pulled off ‚Äì for the first step, anyway (standard library ABI stability) ‚Äì is quite interesting to me, and I thought it was worth posting here. Submitting a text post containing both the "ABI Stability and More" link and the ABI Stability Manifesto link and a brief explanation of why you think it's on-topic would have been perfectly fine. Posting just the link to the non-technical post comes across as not meeting the relevance requirement in the rules for this subreddit.
&gt; What I mean is that a desktop is fundamentally different from mobile or IoT. Gotcha and complete agree. But obviously there is also a ton of overlap. &gt; I can already do that in a dozen different ways that don't require me to learn a new programming language or use a different toolchain. Not aware of any other way to do it and get 60 fps. Or really any performant way to do it. 
I am using diesel with r2d2 as connection pool. In this case, connections are managed by r2d2, you store pool reference which implements cloned, so you can copy it wherever it is needed, including app state, middlewares and so on. When you need a connection, you obtain it from the pool. See this: https://github.com/diesel-rs/r2d2-diesel .
It might be easier to grasp the fundamentals in the form of the good old POSIX `select` system call. you have a bunch of sockets you're listening on (for some combination of "incoming data waiting to be `read()`", "output buffer has free space again", and miscellany like "connection closed"), you feed them to `select()` and it'll wait up to `timeout` before returning an empty list of ready sockets. If you specify a timeout, that lets you write a simple loop which waits on multiple connections in parallel. If you specify no timeout, you can have a loop which does things and periodically calls `select` to check if any network traffic is waiting to be handled. When you go full async, it's basically a form of [cooperative multitasking](https://en.wikipedia.org/wiki/Cooperative_multitasking). The library you build on (eg. the Node.js standard library) has function calls which mean "Do thing X. Wake me when you're done." and while one block of code is sleeping, it'll run something else. `await` means "I'm going to sleep. Wake me when X is ready." When you `await`, the executor can then wake something else that `await`ed and is now ready to wake up.
Don't worry, I think it's relevant and I appreciate the link.
I am ashamed 
&gt; These prevent data races by use compiler intrinsics that provide synchronized operations. And they prevent pointer invalidation by refusing to give out references to their contents; you can only read from them or write to them by value. "by use" should be "by using" and I think it feels unnecessary and awkward to start a new sentence before "And" in this case. &gt; These prevent data races by using compiler intrinsics that provide synchronized operations, and they prevent pointer invalidation by refusing to give out references to their contents; you can only read from them or write to them by value.
`text.get(1..10)` returns `Option&lt;&amp;str&gt;`.
How about `text.get(1..10)`? https://doc.rust-lang.org/std/primitive.str.html#method.get
https://doc.rust-lang.org/std/primitive.str.html#method.get
But... how do you know what is the error that caused that third party call to panic? And if you can't know it in advance - how can you recover from it?
(For what it‚Äôs worth, I didn‚Äôt downvote you.)
Even if there is a trend... wanting to move on from any given role in any given project after some years is natural. Maybe Rust is now just at that age where many of the people who got involved in the early days are reaching that point at roughly the same time. We shouldn't be concerned that there's some churn! A healthy project shouldn't be reliant on a few key persons sticking around for a decade or more!
As a side note, you can always turn Option into Result using ok_or or ok_or_else https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or
Yeah, I assumed Rc/Arc would be the most correct solution to this if I want to pass references around. Thanks!
As deep\_fried\_eyeballs said, it is possible to microbenchmark some code and compare the performance with metrics manually added and metrics added using Metered. The last two results should be similar, since Metered writes the boilerplate we'd write anyways. So mostly we'd be benchmarking the metrics themselves, in both thread-safe and unsynchronized scenarios. This is something planned but I had no time so far, contributions welcome ;) Also, because metered uses macros, it should be possible to disable some metrics at compile-time: for instance if one were to build a library that uses metrics, a feature flag could let its users decide whether they want to enable them at runtime or not. 
Thank you :). It would be awesome to get a veneur back-end! Please don't hesitate to bug me for help; there might be slight design changes required to make hooking external systems easier.
Thanks. Missed this one. I was looking for `*slice*`. Method overloading can be a problem sometimes...
That's why I built [Synattra](https://github.com/magnet/synattra) : a more general Syn attribute parser. I think this is one of the main strengths of Metered, because it lets you use any type path (or sometimes regular Rust expressions), so you can just use types you have imported, or put a complete type path, or \*customize\* a metric with a different type param: ```rust use metered::{metered, HitCount}; \#\[derive(Default, Debug, serde::Serialize)\] pub struct Baz { metric\_reg: BazMetricRegistry, } \#\[metered(registry = BazMetricRegistry, registry\_expr = self.metric\_reg)\] impl Baz { \#\[measure(HitCount&lt;metered::atomic::AtomicInt&lt;u128&gt;&gt;)\] pub fn bar(&amp;self, should\_fail: bool) { println!("bar !"); } } ``` Here the `#measure` attribute accepts any type implementing `Metric`, such as `metered::HitCount`. `HitCount` is imported so we can use it, but it defaults to an `AtomicInt&lt;u64&gt;` backend. I have great hope to see more of this pattern in other Rust code because it makes attributes extensible through the trait system, and meta-programming meets type-level programming. I don't know much if other crates do this, but I did not see it elsewhere. When I started hacking on Metered I tried alternative attribute parsers and none supported this. I am pretty confident this code is not "edgy", as in "maybe will one day become invalid", because macros are designed to work from a `TokenStream`, and will always be able to represent these.
As fulmicoton said, Metered will build a struct under the name you choose from your `impl` block, and just put it next to it. It's up to you to use it, and it implements `Default` so you can initialize it easily.
It works with lib.rs, thank you so much for the help !
&gt; It seems to me that you would lose very little, but remove a case of undefined behavior, by just defining regular writes on primitive types to be relaxed atomic writes. That's pretty much what Java and C# do. But on non-x86 architectures the performance loss can be significant.
In practice, you don't need to know what the error is as long as you know that it's "something went wrong while processing file X" and the proper response is "log the failure and move on to file Y". I've been using `except Exception:` in Python for that purpose since *long* before I started using Rust.
Rust lacks of mature neural networks libs for now :( [http://www.arewelearningyet.com/](http://www.arewelearningyet.com/)
- What do you need? If you have a need to scratch, you could try that. - What projects have you written in another language and you'd be interested in rewriting? If you have one, you can try that. - Would you like to help maintain an existing project instead? There's plenty of them that could use some help. - Do you have some domain-specific knowledge or need? Maybe you could start a crate or help an existing one. Even if it's something very narrow, like an [id encoding](https://github.com/nikolay-govorov/nanoid). - Have you seen the various [lists](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust) of crates someone [would like](https://github.com/dtolnay/request-for-implementation) there to be? - What annoys you about the command line tools you're using? Maybe you find `firebase deploy` too slow. Maybe you don't like including language X in a your Docker containers just because one tool is written in it.
Sounds like you're making excuses. Something doens't have to be performance critical to write it in Rust. Don't get me wrong, performance is nice, but safety is why I write things in Rust. Web backends is actually a pretty good place for Rust I think. Rocket makes things ridiculously easy, and Actix seems like a great place to learn async (I haven't succeeded with that one yet...). There are other frameworks if you want a middle ground too. My first Rust project was a "zero-knowledge" backup solution. It was terrible, didn't scale, wasn't really zero knowledge yet, and doesn't compile anymore for unknown reasons. But it worked, and it got me an A lol. 
These are indeed excuses. However, I usually cannot bring myself to do a project if my way is not the most efficient way possible (considering all my expertise in other languages, team members available, etc). Thanks for the suggestions! Maybe I'll come up with an interesting back-end app idea.
If you want to make a proxy that allows export of decrypted https traffic you‚Äôd make me happy üòÇ
I have a lot of experience too, but I still write [stupid little things like this in Rust](https://github.com/BurntSushi/vcr), even though I could have easily done it in Python. If you're having trouble picking a project, then pick a project you've done before and then port it. It's a nice way to learn a language because you're working on a project you already know very well, so you reduce the number of things you need to learn. Otherwise, nobody can really tell you what to do. You need to find something that interests you. :-)
It appears you have a grudge against `unsafe`. Please explain to us why you don't like it or what you think is wrong with it, that way we can help you clear up misunderstandings. I assure you, there's nothing wrong with it.
It would be awesome if someone would write a `tar` clone in rust. Especially with better command line argument parsing. Could be name `rat` :)
Awesome. :D
Or `feather` :)
CLI tools in general? Maybe a backend app that has a reason to not be nodejs (memory usage, easy deployability)?
So you don't need to `catch_unwind` every third-party call - you need to `catch_unwind` the entire block that handles the file/entry/etc.
I‚Äôm looking to have a ‚ÄúGlobal Configuration‚Äù construct that I can access from any place in the application I‚Äôm coding. Now, this could be achieve with a simple struct but I have a few requirements. 1. It is a commandline application. I‚Äôm using Clap. I‚Äôd like that the commandline arguments take superiority over the default configuration. 2. I‚Äôd like to read the environment variables and apply them as well. They do not take superiority over the arguments passed to the CLI. 3. Default configuration. That configuration is determined at execution time (it‚Äôs not static). How I think this will happen: 1. Rust initialize the default configuration (some kind of a struct I think). 2. Rust loads up the environment variables and replaces the default configuration where it applies. 3. Rust does that too for the arguments passed to the CLI. Anybody did something similar?
@aaron\_r\_p, you should expect to see a semi-official crate with the release of InfluxDB 2.0.
Excellent - thanks!
Ahh, that's where the miscommunication came about. What I meant to say is that every third-party call is within the scope of a `catch_unwind` block... not that every third-party call gets its own one.
The tensorflow crate is currently best used for executing graphs defined in Python. In other words, you'd build the neural network in Python and export it, then load it in Rust and do training and inference there.
For my projects I tend to look at things that I happen to need at that time. In my last project I created a tool to convert netctl profiles to iwd profiles, and did the crypto in rust. Would it have been easier to write it in bash, and shell out to `wpa_supplicant` for the crypto parts? Definitely, but that wouldn't have given me a Rust project to work on. Your project doesn't have to be made for Rust, you just have to write it in Rust!
&gt; If you're having trouble picking a project, then pick a project you've done before and then port it. This cannot be emphasized enough. It eliminates all of the cognitive overhead of figuring the program out, and lets you focus on the differences between the two languages.
Unsafe doesn't mean unreliable. If that were true, rust would not have anywhere near the value proposition that it does. Unsafe just allows a few extra abilities. It doesn't disable all the existing checks. It's essentially the code writer telling the compiler, and future readers of the code, that "hey trust me with this little section here". It's necessary anytime you need to cross the rust boundary into another language or implement certain data structures which are inherently unsafe, like you mentioned. The nice thing with unsafe is it is explicit. You know where it is, it's obvious. Overuse of unsafe may be code smell but unsafe in and of itself isn't bad. 
Thanks. I could do that then if nothing else works. Makes me wonder: Would it be possible to build a deep neural network using only the primitive bindings of `tensorflow-rust`? Would it be a lot of work?
let's call it rustar ^^for the sake of bikeshedding
I agree. The mods should have banned you weeks ago.
Do you have any example code? Perhaps we can help you out. &gt; I think most of the time, lifetime, NLL and other problems will not happen in simple code block, it needs me to think more about language not my basic logic. Things like this quickly become second nature if you commit to it. You're in the process where borrowck is breaking you down, pointing out safety issues in the code you write, and teaching you to write that code safely. As long as you follow the borrowck rules, you'll do fine. &gt; it's different from C++, and if you want to do the same thing, it's really difficult without unsafe block The same approach in C or C++ will also work in Rust in an unsafe block. Naturally, Rust is going to outline that the approach is unsafe, and writing a safe solution requires knowing safe patterns. Though that's not to say that using unsafe is wrong for designing a primitive type. If you want a safe solution, you should look into arenas. Crates like [generational-arena](https://github.com/fitzgen/generational-arena), and [slotmap, which has a doubly-linked list example](https://github.com/orlp/slotmap/blob/master/examples/doubly_linked_list.rs), are often used for this exact purpose. The arena approach is often more efficient than an approach without. &gt; if you want to dereference pointer you need to use unsafe block, this makes rust code unreliable It's no less reliable than doing the same in C or C++. The act of dereferencing a pointer will always be unsafe, regardless of the language used. &gt; in the Rust source code, there is a number of unsafe areas. Which is perfectly fine, since they've largely been vetted to be safe.
PyTorch has a complete C++, since 1.0. There were an [attempt](https://www.reddit.com/r/rust/comments/a93pml/is_it_possible_to_write_or_generate_bindings_for/) to create bindings.
Awesome !! I was planning to build a similar wrapper to enable AWS cross-region replication using ZeroMQ pub/sub. Currently, I am using \`mio\`. It seems time to switch to \`tokio\`.
&gt; Also, what's the state of cross-platform GUI in Rust? [OrbTk](https://gitlab.redox-os.org/redox-os/orbtk) has made a lot of progress lately. See the [updated calculator example](https://gitlab.redox-os.org/redox-os/orbutils/blob/orbtk-next/src/calculator/main.rs). Grid layouts are now supported, and the API for layouts was recently majorly improved. &gt; Normal desktop apps: I don't have many ideas for this. There's a lot of opportunity in this area. &gt; I don't think Rust have engines with editors as feature-complete as Unreal/Unity/Godot. [Amethyst](https://www.amethyst.rs/) is working towards that. &gt; Back-end web apps: I have far too many custom tools made for NodeJS Sunken cost? Personally, I wouldn't trust anything written in JS to be reliable, or efficient. &gt; and its ecosystem is huge As Rust's ecosystem is quickly becoming: https://crates.rs/ 
I think there's a tar the Redox extrautils package
Fuck I was wondering why there were no rust posts 
Thanks for the updates on the state of libraries! &gt; Sunken cost? Maybe. But it's not just my sunken cost, but industry's sunken cost as well. Realistically, it is much easier to find developers and tools for JS than for many other languages. &gt; Personally, I wouldn't trust anything written in JS to be reliable, or efficient. It gets so much better with TypeScript in strict mode. Not only you have null-safety, but in recent versions all user input can be typed as `unkown`, which forces you to validate it to do anything meaningful. Being fully asynchronous and writing type-level functions also helps. So, as much as I hate JS design choices, it got a lot of advantages in recent years, and this makes switching to something else even harder.
&gt; Is there a better, simpler, shorter way? Maybe. You might not need to convert them them to byte arrays. Also, you'll end up with duplicates if there are case differences in your input.
I've found CLI applications are a good way to start off, and rust is great to produce a native binary which you can distribute. This can also lead to long lived services if your CLI turns out to need longer lifetime. For example right now I'm trying to build an event generator which will start firing off events when my Linux machine meets some threshold like CPU too high, the threshold is described in a json file and stop when the threshold is lost (completely useless I know but sometimes you just write some code to see how it works). Then any consumer can consume the events. Usually I think go or python is used for system services like this but I find rust fairly good in this area. Just a possibility to explore.
You could use a radix tree https://en.m.wikipedia.org/wiki/Radix_tree
Desktop link: https://en.wikipedia.org/wiki/Radix_tree *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^237075
Personally, I use [autograd](https://crates.io/crates/autograd). While it's lacking a lot of features, it was enough for me to implement a few basic neural networks and train them. Note that it only runs on the CPU, so if you need to train on the GPU you need to use something else. That's not an issue for me, as I haven't had any luck ever getting opencl to work, so everything I've ever done was on the CPU. It should suffice as long as you don't need anything fancy, like complex regularization (dropout layers, etc.) although you can always implement that yourself. Just note that if you want to use ReLU, you NEED to implement some form of regularization, otherwise the gradients will make the network's weights blow up to infinity. I suggest writing, and then using a few helper structs that look roughly like this, I found this API really helpful when playing around with some simple networks: impl NetworkBuilder { fn new(in_size: usize, out_size: usize) -&gt; Self { ... } fn add_layer&lt;F: Fn(ag::Tensor) -&gt; ag::Tensor&gt;(&amp;mut self, neurons: usize, activation: F) { let last_layer = self.last.take(); let w = ...; let b = ...; self.last = Some(activation(ag::matmul(last_layer, w) + b)) } fn build(self) -&gt; Network { /* create loss and optimizer tensors */ } } impl Network { fn eval(&amp;self, input: &amp;ag::NdArray) -&gt; ag::NdArray { ... } // technically, these two functions could take &amp;self, as all operations on tensors work through &amp;self, but that feels wrong fn train(&amp;mut self, input: &amp;ag::NdArray, output: &amp;ag::NdArray) -&gt; f32 { ... } fn load(&amp;mut self, weights: &amp;[f32]) {...} fn save(&amp;self) -&gt; Vec&lt;f32&gt; {...} } Then you can use this API as: let mut net = NetworkBuilder::new(2, 3); // XY -&gt; RGB for &amp;size in &amp;[12; 7] { net.add_layer(size, &amp;|t| ag::tanh(t)); } net.add_layer(3, &amp;|t| ag::sigmoid(t)) let net = net.build(); while train { // generate xs, ys let loss = net.train(&amp;xs, &amp;ys); // do stuff } let weights = net.save(); // write to file net.load(weights); let xs = { ... }; let ys = net.eval(&amp;xs); for pred in ys.outer_iter() { let (r, g, b) = (pred[0], pred[1], pred[2]); ... } It's definitely far from pretty, there are tons of checks that can't be done at compile-time, since autograd uses dynamically sized NdArrays internally, but it works, and is actually quite fast and nice to use (maybe apart from creating, mutating, and extracting data from NdArrays).
You can have this one for free: In NLP, a lot of work still uses word embeddings to map from words to vectors. Without going into to much detail in the immense value of embeddings, the process usually ends up being done inefficiently, and many python ML servers are out there are spending hundreds of megabytes of these vectors in memory per web server process. It's a terrible waste of memory, and still ends up being a surprisingly slow part of the process. Using rust, you could make an embedding server (probably not http) that would allow you to do this mapping way faster and more efficiently in terms of memory use. You would also provide aggregation modes to reduce the number of bytes you needed to ship back, since some simpler models are doing weighted averages of the embeddings anyway. I've been "planning" to make this forever, but just haven't had the free time.
Thank you for your answer. Do you mean, that it is possible to make "global" **pool** variable and share it across the system?
Do you wanna break new ground, or solve one problem you have in the past? &amp;#x200B; In my case, I already wrk like with 5 different languages so in the side working (slowly!) in a relational language (to, in my wild dreams, to be a better Access/Visual FoxPro). it break new ground (almost no relational lang to be used outside a RDBMS) and solve problems of the past (I have too many Langs around the same kind of programming task around data)
JUCE, Electron, Sciter or any other Electron alternatives... there are plenty of cross platform GUI frameworks. 
I think for the Rust part of this you'd want a new allocator that zeros on free and the ability to make `Vec` use it. Unfortunately, this isn't a thing yet because it involves a few different pieces that need to be settled first. https://github.com/rust-lang/rfcs/blob/master/text/1398-kinds-of-allocators.md#what-about-standard-library-containers
&gt; OrbTk has made a lot of progress lately. See the updated calculator example. Do you guys (or at least the OrbTK guys) have discord or similar where I can ask questions without having to open a ticket on the repo? I've been looking at OrbTK recently for a project but with the lack of documentation (at least as far as I've been able to find there's only API docs) I can't even figure out _whether_ it's possible to do what I want yet, let alone _how_. 
Don't use Typescript for your small web game. Use Rust WASM. More efficient, which you seem to like, and more likely to work right. WASM is a lot of fun.
The hashset will deduplicate, no worries there. It may not be the most efficient way to implement what you're asking *period*, but it's probably the most efficient way using only standard library data structures ^^
Doesn't `Sync` represent transferring a borrow across a memory barrier? (e.g. Sending a `&amp;T` or `Arc&lt;T&gt;` across a channel)
You can [request to join the Redox OS Mattermost chatroom](https://chat.redox-os.org/). Discussion of OrbTk is carried out in the `orbital` channel.
This really helps clear up a lot of the container-confusion I have, which probably stems from never reaching those parts of The Book, or reaching and then not using within a timeframe that would have reinforced the reading.
Does not have to be native. Has to be performant. Flutter is a scaled down Electron. Both built on Skia. JUCE and Sciter are not like Flutter. Neither capable of 120 fps. Neither offer the developer experience.
Thanks that's very useful! You said there is no "complex regularization". Then you said I will need to implement regularization myself. So is there no built-in way to do regularization?
Interesting, thanks. For now I will wait and see if anyone does the work.
There's a more detailed explanation in this thread: - https://www.reddit.com/r/redditdev/comments/ao8vqc/authenticate_reddit_api_data_w_ssl_signature/ but essentially the data is going to a public database (blockchain) which anyone can submit data to. There needs to be an easy, fast, and deterministic way to check that the data submitted to the blockchain came directly from Reddit without being altered along the way. Checking against an SSL signature would be an easy way to do that, but right now the library I'm using to access the Reddit API just sends me the data without the https signature. I don't know much about networking or web scraping so I'm not sure if there's a glaringly obvious way to do this or if it's a genuinely hard problem ¬Ø\\\_(„ÉÑ)_/¬Ø Thinking that if the API method doesn't work, I could just write a generic web scraper that sends a header with the signature and a chunk of raw data. Then I'll parse through it and make it pretty **after** the signature has been verified. This might work, but seems a shame since Reddit already sends data in such a nice convenient format via the API. Again, not sure if there's an obvious way to do this that I'm missing. Any help would be greatly appreciated :) 
Yeah, this is the data structure that was pretty much designed for OP's use case (storing sets of words).
`T` needs to be `Sync` in order for `&amp;T` and `Arc&lt;T&gt;` to be `Send`.
Fixed. Thanks!
`Sync` is needed for transferring a shared borrow (`&amp;T`) or shared ownership (`Arc&lt;T&gt;`). `Send` is needed for transferring a unique borrow (`&amp;mut T`) or unique ownership (`Box&lt;T&gt;`).
To be precise: Its possible to have many copies of pool reference and use it to obtain connection when needed, but essentially yes.
...or startup time. Rust programs can start as instantly as shell scripts while giving far more than Bourne, Python, or Node.JS in the way of compile-time safety guarantees.
`temp_dic.insert(word.to_string())` won't insert more than one copy of the `String` into the `HashSet`, but it will do a heap allocation even if the word is already present. You could avoid that by doing a `get` first. That means two hash set operations instead of one, though, which is a different inefficiency. (Probably better than the heap allocation but a benchmark would tell you for sure.) `HashMap` has an `entry` API that lets you avoid both problems. Today I learned `HashSet` [doesn't](https://github.com/rust-lang/rfcs/issues/1490) have this. Maybe a `HashMap&lt;String, ()&gt;` would be better then.
I assume that "representing time" is referring to some game-loop related bookkeeping like measuring and regulating the speed of the game loop or controlling the execution of periodic tasks. For those uses `DateTime` is not ideal, mostly because it is not monotonic: later measurements of the clock can be before earlier measurements of the clock due to time zone changes, daylight savings time, clock changes, ntp updates, leap seconds, etc. Game loops usually use a fast high resolution monotonic clock for such things, like `std::time::Instant`.
As others have said, unfortunately there aren't really any non-dead, production-ready neural network crates out there. ): `tensorflow` is alive, but it doesn't really allow you to easily train a network. I recently started [a new neural network/deep learning crate of my own](https://github.com/koute/sarek). It's still highly experimental, is missing a lot of features, and (currently) has a hard dependency on Python and TensorFlow. It's definitely not ready for *any* use, but training on MNIST works, e.g.: let ctx = Context::new().unwrap(); let training_data = /* ... */; let input_shape = training_data.input_shape(); let model = Model::new_sequential( input_shape, ( LayerDense::new( 512 ), LayerActivation::new(), LayerDropout::new( 0.2 ), LayerDense::new( 10 ), LayerSoftmax::new(), LayerIntoCategory::new() )); let test_data = /* ... */; let mut instance = Trainer::new( &amp;ctx, model, training_data ) .unwrap(); for _ in 0..4 { instance.train(); let loss = instance.test( &amp;test_data ); info!( "Accuracy on the test set: {:.02}% (loss = {})", loss.accuracy().unwrap() * 100.0, loss.get() ); } It's intended to be a high-level, Keras-like library which is easy to use, is well tested, has good defaults, has GPU acceleration, doesn't use CUDA (which is a vendor-locked, 5GB big dependency), can use but doesn't require any external non-Rust dependencies to work, and is relatively small and simple (as opposed to the kitchen sink which is TensorFlow). Obviously right now it doesn't fulfill all of these. Once I'll finalize the basic API, expose enough of the functionality from TensorFlow, train CIFAR-10 to a reasonable accuracy and write enough tests I plan to start reimplementing the compute parts in pure Rust. Anyway, again, this is not ready for any serious use. I'm just throwing this out here in case someone is interested. (:
I'm glad this was posted here. Seeing as Swift is a code competitor to rust in terms of goals and features I think it's interesting to see them developing an ABI. Its something I really wish Rust had, and maybe this will flesh out some of the problems and provide justification for prioritizing it in Rust. Given, I think it is probably more important for Swift as I suspect they are targeting closed source developers much more than Rust is.
In case it wasn't clear to anyone else like it wasn't for me: this isn't about the \`auth\_cache\` crate specifically, that's just the alphabetically first one, and all the others are available in the pane at left.
Sorry about that. It was the link. If went back one you also got Dart and that link is broken.
Just wait until the creators of the game decide to re-write Rust in Rust, then things will get really confusing!
&gt; but essentially the data is going to a public database (blockchain) which anyone can submit data to. I'm not going to comment on what's an appropriate use of a blockchain. I'll defer this to others who are more knowledgeable than I. &gt; There needs to be an easy, fast, and deterministic way to check that the data submitted to the blockchain came directly from Reddit without being altered along the way. That depends on who you want to trust. If you get a response from `orca`, you can be pretty sure it came from reddit.com and not from someone trying to impersonate Reddit. But that's not enough to trust someone else that they indeed made an API request instead of forging the response. &gt; Checking against an SSL signature would be an easy way to do that, but right now the library I'm using to access the Reddit API just sends me the data without the https signature. That's not the fault of `orca`. Networks have various layers that are stacked. Disregarding what happens on your local network, the protocols involved in your request are IP, TCP, TLS (don't call it SSL), HTTP, and the Reddit API. IP and TCP don't really matter here. Now `orca` is using an HTTP library (`hyper`) to talk to Reddit. It know stuff about the Reddit API, but doesn't know anything about HTTP or TLS. `hyper` speaks HTTP, but the only thing it knows about TLS is that it's there, and so it delegates that stuff to a different library like OpenSSL. `orca` doesn't (and can't) know anything about the TLS layer. And there is no "TLS signature", at least not in the sense of that HTTP header that Stripe sends. It's an ephemeral thing that only exists while you're connecting to reddit.com and getting back the response. &gt; Thinking that if the API method doesn't work, I could just write a generic web scraper that sends a header with the signature and a chunk of raw data. Then I'll parse through it and make it pretty after the signature has been verified. I see a couple of solutions for you, depending on whom you trust: - make a proxy to the Reddit API that forwards the requests to reddit.com, reads the response, and signs it; your client connects to this proxy, gets a signed response back, and forwards it to the blockchain thingy. The blockchain thingy can then connect to your proxy and verify the message in some way, either by asking it to do so, or by knowing (or retrieving) a public key of the proxy and checking the signature. The downside here is that you have to run the proxy, and take care of the key used to sign the response. - since you have that proxy, why not eliminate the middle man? You can have the client send the request to the proxy, then the proxy can pass the response to the blockchain. It can even sign it or whatever. The same considerations as above apply. - the harder approach is to realize that the TLS messages already contain enough information to prove that the response comes from Reddit. You can store this raw data somewhere, and anyone so inclined can verify that this was indeed an exchange between Reddit and another client. It should be pretty easy to save the data (but I can't tell you how, as I haven't really used any TLS library), but a little harder to actually verify it. That's because you need to validate the whole certificate chain. Again, there are libraries for this, but I don't know how the code would look. This is something that `hyper` does, for example.
Thank you, I'll take a look
Looks like a roundabout way of writing: let collection: HashSet&lt;Vec&lt;u8&gt;&gt; = tokens .map(|word| word.to_string().to_lowercase().into_bytes()) .collect(); This saves the extra allocation from the to_vec(), avoids the temporary set, and avoids concerns over how you do the inserts because collect does it all for you.
Yeah, cant really give advice to this post when laid out like it was &amp;#x200B;
You could also pick a preexisting project to contribute to if you want something useful to work on.
That's the terminology used in C++ in fact (unique and shared).
If you want to make a front-end web app, I think [yew](https://github.com/DenisKolodin/yew) is really cool. If you want to make a small game, [quicksilver](https://github.com/ryanisaacg/quicksilver) is a rust game engine that compiles to both desktop and web from the same code!
I tend to only use .expect during the initialization process of an application. Things like reading configs and such.
Isn't NLL now in stable for Rust 2018? So you shouldn't need to ask for it specifically: https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html Coding in safe Rust means some of the data structures you once thought of as basic and easy in C can't be implemented directly. Instead you have to use a collection from 'std' or a crate, or implement it on top of a Vec. This is the cost of safe Rust. It seems really restrictive at first but then you find a way. Also Rust's collections have been tuned for modern CPUs, so they end up loads faster than simple linked lists or binary trees or whatever. You can also search for crates or 'std' functions doing a similar thing to what you want, and look at how they do things through the [src] links. This is the cost of getting the extra safety that Rust gives you. However this safety does mean you can rely on the compiler to check things for you, and so you end up being able to do things that would be much too error-prone and dangerous to do in a language without these checks. So the safety lets you do more, when you get used to it. If you want to implement a new type of collection, then you might be able to do this efficiently on top of Vec (mem::swap and mem::replace help), or else you'll have to reach for 'unsafe' and read the Rustonomicon, which tells you all the stuff you need to worry about (which is similar to what you really should be worrying about in C and C++, except that most people don't worry enough about safety in those languages). You make the API to your new collection safe, and prove to yourself in your head that no-one can do anything unsafe through it, and then write the rest of your code in safe Rust (letting the compiler check it).
Makes more sense. And this is also a good idea for jobs that don't use third party calls, because your own code may contain bugs that you want to properly log and not make other jobs, that did not trigger that bug, crash because of them.
Womp womp. 
`HashMap`'s entry API does not help with the allocation - you must provide a `String` just to get the entry, even if it is occupied. And in that case you don't even get that string back - whereas insertion will give you `Option&lt;String&gt;` back, so you can at least reuse that allocation. To fix this there was a proposal for [raw entry API](https://internals.rust-lang.org/t/pre-rfc-abandonning-morals-in-the-name-of-performance-the-raw-entry-api/7043).
It sounds like you already know how you wanna do it, so i'm not really sure what question you're asking. But if your question is how to set up the global config struct then the easiest way is probably with the [lazy_static](https://crates.io/crates/lazy_static) crate. You can initialize a hardcoded default to start with then further modify the configuration with env vars and CLI args afterwards
You may find it useful to look through past postings on this subreddit for postmortems. Recommended reading: - https://www.rust-lang.org/production - https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/ - https://blogs.dropbox.com/tech/2016/06/lossless-compression-with-brotli/ - https://people.gnome.org/~federico/blog/guadec-2018-presentation.html
Oh, that's unfortunate. Thanks for the correction and pointer.
https://github.com/michaelsproul/rust_radix_trie
Not an expert, but I think only public elements' documentation is displayed by cargo doc. There usually isn't any in a mere binary, but if you start declaring stuff as `pub` then it should appear.
I still couldn't manage the debugging part. Would you be able to help please?
As the other commenter mentioned, the guessing game you linked contains only a `main` function, meaning there's not else `rustdoc` can display. Add more functions, structs, and external crate dependencies to your project, and you should see more output. With that said, I think your real problem may be because you used `cargo rustdoc` at the beginning over `cargo doc`. The former documents only your current crate by default, while the latter documents all crates in your project (including `rand`, which is mentioned in the guide you linked). Try running `cargo clean` to completely remove the existing HTML and then run `cargo doc --open` to generate the documentation for all crates anew. You should still only see `main` in your crate, since that's all the guessing game project has, but the sidebar should contain a link to the `rand` API documentation as well. I've confirmed this locally with an empty Cargo project with `rand` 0.6.5 as a dependency.
`cargo doc` documents your crate (or crates) and its dependencies. If you only have a `main` function in there, you won't see much in the output. In your case, clicking `main` should allow you to see its signature (because it's `pub`) and source code. You can add some dependencies to generate the documentation for them. You'll also see any documentation you've written (it's a special syntax, use `///` instead of `//`, and place them above a function, struct etc. declaration.
&gt; A value that implements `Sync` is using some kind of mutual exclusion and is therefore "mutex-like". `u8` implements `Sync`. `String` implements `Sync`. Most types in Rust implement `Sync` but are not "mutex-like." `Sync` just means that you can move a shared pointer (e.g. `&amp;u8` or `Arc&lt;u8&gt;`) to another thread, which is perfectly safe for "normal" Rust types that are immutable when shared. Only types that have **shared mutability** need to enforce mutual exclusion in order to be `Sync`.
I don't have any suggestions, but... would you terribly mind speaking about what the image is meant to convey?
Thank you for you suggestions! :) This is all new to me so I appologize if these questions are redundant, but if I understand correctly: - If there is a proxy that's doing the signing, then the proxy has a signing key that would have to be managed and trusted, and thus the signature would not be straight from Reddit right? - In the harder approach, a script simply scrapes Reddit and includes **all** the data that comes back including the TLS signature (is that the correct terminology?). Then something like openssl can verify that the signature matches the Reddit public certificate? And then once the data is verified it can be parsed via a script after it's on the blockchain vs before being sent to the blockchain. Overall the goal is to eliminate trust in the connection between Reddit (or any website) and the blockchain as much as possible. Of course the data on Reddit itself changes, but right now I'm just focusing on creating a bridge between the two. Does that make sense?
Sorry, in the OP, that was an unordered list of commands. cargo doc --open was the first command I ran. But it got held up on winapi. I didn't know how big that library was, so I thought it was frozen. So I exited and tried cargo doc --nodeps -- open. Then onto searching and trying those other commands. PS C:\Go_Rust_Work\rust\my_project\src&gt; cargo clean PS C:\Go_Rust_Work\rust\my_project\src&gt; cargo doc --open Compiling winapi v0.3.6 Compiling libc v0.2.48 Documenting libc v0.2.48 Documenting winapi v0.3.6 Checking rand v0.4.6 Checking rand v0.3.23 Documenting rand v0.4.6 Documenting rand v0.3.23 Documenting my_project v0.1.0 (C:\Go_Rust_Work\rust\my_project) Finished dev [unoptimized + debuginfo] target(s) in 4m 33s Opening C:\Go_Rust_Work\rust\my_project\target\doc\my_project\index.html The html is the same for me. &amp;#x200B; &amp;#x200B;
This is BIG
Thanks for the clarification. If you run `cargo doc --no-deps`, then the output you showed in the OP is working as expected. No dependent crates should appear in the sidebar and only the documentable data from your own crate is shown.
As someone working in low-latency environments, I like the idea of measuring *everything*, however I do not like contended/measure code in the hot path. A strategy we often use, instead, is: - Locally gathering information on each thread. - Shipping a batch of local measurements to a SPSC queue toward a background thread; generally at the end of a request, once off the hot path. This lets us take many measurements without any contention, and ship them off with minimal contention. All computations -- lifetime of requests, number of active requests, etc... -- are strictly delegated to the background thread. Do you think metered could be used/adapted toward such a usecase?
Thanks! I asked here, because I was looking through several of those, plus some other postmortems, and the ones I've seen haven't really addressed at the project level changes, but have focused more on performance and the mechanics of converting code.
Found the issue ... It was NoScript, the browser extension. Yeah ..... Thanks for your help! DERP!
&gt; It gets so much better with TypeScript in strict mode. I came to Rust from JavaScript, and this is definitely true. BUT, Rust is another step up in reliability! It has to be experienced to be believed.
It was NoScript blocking the information... I may need to take a break. I'm a Python Programmer. The amount of colons in Rust must be getting to me. :P
Thanks for sharing. What is Tide?
When submitting links to articles that are not obviously related to Rust, such as this one, please: 1. Preferably, use a *text* post, and explain in the post why the link is relevant. 2. If you use(d) a *link* post, then explain in a top-level comment why the link is relevant. 
Nice, glad you found the issue. Take that break if you feel you need one, rest up, and come back to it. I happen to come from a C++ background, so I'm pretty familiar with the over-abundance of colons and angle brackets, personally. Wishing you all the best on your Rust projects!
&gt; If there is a proxy that's doing the signing, then the proxy has a signing key that would have to be managed and trusted, and thus the signature would not be straight from Reddit right? Yes. &gt; In the harder approach, a script simply scrapes Reddit and includes all the data that comes back including the TLS signature (is that the correct terminology?). Then something like openssl can verify that the signature matches the Reddit public certificate? Yes, though there's a slight complication here. The Reddit certificate is signed by DigiCert, and that in turn has a certificate that's signed by a DigiCert Global Root CA that's implicitly trusted by your system or browser. The response from Reddit contains all three certificates. The issue is that the certificates have an expiration date: Reddit's expires in 2020, the intermediate DigiCert certificate expires in 2023, and their root CA cert expires in 2031. So you can prove that a response from Reddit was signed with the DigiCert certificates attached to the response, but at some point you need to know that on Feb 8, that DigiCert Root CA certificate was valid. This is because the certificates can be revoked at any time (in case they're compromised), which happens by publishing them on a Certificate Revocation List that's periodically updated. There's also an on-line protocol for checking certificates called OCSP, but I don't really know how that one works. So someone interested in check such a response in 2040 would need a history of the various certificates that were involved and if or when they were revoked. A submission from today might be valid, but the certificate it's signed with might be revoked next month. That doesn't mean that my submission is no longer You can look into PKI if you want to know more about these. Yes, someone already had the idea to put them on a blockchain. I don't know what happened to that. &gt; And then once the data is verified it can be parsed via a script after it's on the blockchain vs before being sent to the blockchain. Yes, with the caveats above.
To expand on that harder approach: - entering `openssl s_client -showcerts -connect www.reddit.com:443` from the command line shows the Reddit cert - This cert is also checked with any arbitrary https connection right? - If so, then I think I just need to figure out how to find that in any arbitrary https request, then pass that request to the blockchain unaltered, and the rest is just making the data look pretty/usable.
great URL
Hey, thanks every so much for this! Cracking stuff.
If so, then I think I just have to wade through the Rust openssl docs to find the right combination of functions to combine into a script. Not sure if there's an easier way to do this though? - https://crates.io/crates/openssl - https://docs.rs/openssl/0.10.16/openssl/
I think the benefits of ABI stability are pretty clear; but as everything there's a trade-off. --- As a counter-point, I'd like to point out the *downsides* of ABI stability. The performance of `std::regex` (C++) is crap in every single implementation (MSVC, GCC, Clang). It has been so since the release of `std::regex` with C++11, and has remained so for 7 years now. Unfortunately, the performance of `std::regex` cannot be improved without breaking ABI compatibility. ABI stability would mean never being able to implement Short String Optimization for `String`. It means not being able to switch the way `enum` are encoded. **ABI stability** is generally equal to **ABI stagnation**, at the exception of additions. --- Editions were a really nice way to get stability without stagnation at the source code level; unfortunately I have serious doubts that such a painless approach is possible at the ABI level.
It really is!
Not data from an organization, but you may find this post interesting: https://www.reddit.com/r/rust/comments/8zpp5f/auditing_popular_crates_how_a_oneline_unsafe_has/ &gt;Unlike C libraries, Rust crates do not dispense security vulnerabilities when you poke them with a fuzzer for the first time (or sometimes even the third time). Humans make all the same mistakes, but Rust prevents them from turning into exploits. Mostly.
Thanks. I like the initiative! So the current approach is to use python bindings and so use TensorFlow through Python? And you will completely get rid of the TensorFlow dependency (even tensorflow-rust) eventually? I suppose you want some library that does computations through graphs, can compile to GPU targets, and can do automatic differentiation then. (there is some WIP in that area, such as https://gitlab.com/sebk/bullet -- but the author says he will next do a complete rewrite)
What do you mean by defect rates? As in bugs?
Ok great! ATM this is a prototype so anything longer than 1 year out is of no concern. If I can figure out how to get this to work then maybe I'll look into a way to "pin" the latest cert to the blockchain or something via a staking reward. Not a concern atm though. &gt; You can look into PKI if you want to know more about these. Yes, someone already had the idea to put them on a blockchain. I don't know what happened to that. Are you referring to Public Key Infrastructure or something else? If you have any idea what that project might be called I'd be very curious to research it! So far the oracle problem (verifying off-chain real world data to be fed to a blockchain in a way that's "trustless" is a hard problem) has been a major obstacle holding the space back. This project is just a toy example, but the idea is to start to explore ways to bridge web2 (centralized databases) with web3 (decentralized "blockchain" databases) :)
This is actually something you often see in the corporate world: when a team/department is working on a long-term project, there's relatively little movement in the last year(s) as everyone is keen on seeing the baby taking its first steps, and then when it's finally clear it's up and running, then people who had wanted a change but refrained suddenly all request it. As for what it means for Rust, there's a risk indeed, but also an opportunity: fresh heads, fresh ideas.
Well, I wouldn't get too excited :-) As the title says, it's only a partial implementation. In its current use case, the physical layer is implemented in hardware, so this crate only covers the MAC layer (and not not completely). That said, the crate is already useful, and I hope it can serve as a basis for future work.
How does Rust being new imply it being simple? Rust is inherently complex since it's designed to identify potential ways the code would fail before running any of it. For dereferencing outside of `unsafe`, references are generally used instead of raw pointers. References come with the guarantee that what it's pointing to exists and is a valid instance of its type, along with the guarantee that no one else is modifying the value at that time. If the compiler can't prove those guarantees, then it won't let your code compile without `unsafe`. If you do use `unsafe`, then it's up to you to make sure that those guarantees are maintained. The issue with linked lists other than the naive singly-linked list is that they inherently violate rust's guarantees. As such, they always require some for of `unsafe`. [Learning Rust With Entirely Too Many Linked Lists](https://cglab.ca/~abeinges/blah/too-many-lists/book/) is a fantastic introduction to how structures that seem simply in other languages can be deceptively complicated in the context of the rust compiler guarantees.
No worries at all, there doesn't seem to be an obviously-better place to link to.
&gt; I'm really glad Aaron has decided to step down from managerial duties‚Äînot because he wasn't good at it, but **because it was clearly a draining role**. I am very grateful for Aaron to have stayed at the helm for 5 long years. After having led the rush to Rust 1.0 (2015), and survived the stress, the criticisms on the tough choices, etc... it must have taken guts to decide to re-enlist and lead the rush to Rust 2018, and he clearly wasn't spared -- ergonomic initiative (modules!), ... BIG thanks to Aaron, really, for keeping a cool head in not one but two crisis. And now I am looking forward to ATCs :) 
Well yeah. An immutable type is enforcing mutual exclusion implicitly via its immutability (ie, no one can mutate it - which is a form of mutual exclusion). Mostly when people use the phrase "mutual exclusion" it's in reference to serialising *write access*. Immutable data is not writable and as such it's somewhat unproductive to say it is "mutex-like", even though it technically is. In Rust, it is the compiler that enforces mutual exclusion on types like \`String\` and \`&amp;String\` because of the immutability by default language feature. You would use a \`Mutex\` in instances where the compiler is not capable of enforcing the mutual exclusion for you. 
In my opinion, you should use locks unless you have empirical evidence that would speak for a lockless approach, ie delays caused lock contention (not just contention for the cache line). I say this as someone who has fancy lockless stuff in my synthesizer project, but I have very specific reasons for that (described in my [talk](https://synthesize.rs/nov-2018-talk/)). Many people read "lockless" as faster, and that's not a good generalization.
&gt; Are you referring to Public Key Infrastructure or something else? Yes. &gt; If you have any idea what that project might be called I'd be very curious to research it! There are some Google results for "blockchain PKI". I remember seeing article tiles about it in the past, but I didn't read them. &gt; explore ways to bridge web2 (centralized databases) with web3 (decentralized "blockchain" databases) Yeah, it doesn't seem like a trivial problem :-).
Basically, yes. It's a metric for measuring the number of bugs roughly consistently over projects of different sizes. 
That's exactly why it is such a big thing. It can be the basis of a fully implemented IEEE802.15.4 standard. I am very curious what will come out of this.
The simplest way is probably to: * make a PR to `orca` to allow the user to configure the Reddit URLs (there's two of them, one for authentication and one for the API, you only care about the latter) Ugh, do you need to be authenticated to use the API? You'll get your session cookie stored on the blockchain. - make a TCP-level proxy that saves the data passing through it and have it listen on `localhost` - use the new `orca` setting to connect to `localhost`
I don't have any hard data but I can give you my own anecdote. For context we have an API that powers our product's integration into the various CRMs we support. That API communicates to CRM adaptors via a well established contract. The latest implementation for a new CRM was done in Rust the other two we support were written in Scala. Defect rates have been good. The new implementation was written very quickly and has had roughly between 5-10 minor data mapping bugs IE we didn't pull the right value from the CRM or pass the value back correctly. The only issue we had with Actix Web was [https://github.com/actix/actix-web/issues/616](https://github.com/actix/actix-web/issues/616). In practice it didn't cause disruption because of redundancy. &amp;#x200B; The initial implementation was done very quickly on a very tight timeline with me doing the majority of the work. Based on that I think the defect rate is quite superb. Since then we have had 4-5 other people from my team in the code base and the defect rate has been very reasonable and on par with what we were seeing with Scala. &amp;#x200B; As far as productivity vs Scala I think they are nearly equivalent with Rust having an edge when talking about complex async call patterns because we are using the Nightly async await syntax. Scala has an edge in tooling and available libraries. I feel like like the complexity in Scala because of implicit parameters/conversions, being OOP and Functional make it harder to work with overall. Team members new to our Rust code bases have reacted favorably despite initial worries about it potentially being difficult. &amp;#x200B; Maintenance is easier in my opinion with Rust because of lack of some of the more complex features in Scala such as the above mentioned implicits. Additionally while the testing frameworks available for Scala are more featureful they also introduce complexity. For example using Mockito with Scala can be painful at times and mocks in general have made some of our tests harder to maintain than I would like (could be we are just doing it wrong). &amp;#x200B; Both Scala and Rust are very similar in a lot of ways so going between the two hasn't been overly painful. &amp;#x200B; One major thing I am missing right now is the ability to easily generate swagger/openapi documentation from my service code or generate the service from the documentation. &amp;#x200B; The experience has been positive enough that we have since re-written or implemented a few other services in Rust and thus far it has been nice to have reduced memory/cpu usage. 
You can‚Äôt port c++ or java code to rust line for line. The language forces you write the code differently to enable the safety the language guarantees. If you are writing unsafe code, you are either wrong, or doing something super super advanced and optimized. If you want to line for line copy things, don‚Äôt use Rust. It takes a long time to get useful in rust and to be able to write code without compilation errors all over the place. I sometimes found myself frustrated. To fix that, I just researched more and found out how to do things the rust way, instead of the ways I‚Äôve been using coming from a Java background
Write a thread safe trie. Try to make it concurrent besides just being thread safe. It‚Äôs a great exercise. P.s. check out parking_lot 
So far it looks like `get_recent_comments()` in the listings module is the best fit. - https://github.com/IntrepidPig/orca/blob/master/src/app/listings.rs I went through and printed out the `req` request parameter and this is what it was sending to Reddit: ``` [src/main.rs:135] &amp;req = Request { method: GET, uri: https://www.reddit.com/r/daonuts/comments.json?limit=10, version: HTTP/1.1, headers: {}, body: Body } ``` Then the response is an Object that holds all the data. I think I need to dive into the response function to ask it to return the header with the TLS signature too right? Also you don't need to be an authenticated user to read data from Reddit. Authentication is only to write data to Reddit (posting, commenting, PMs) as a specific user. 
Cool! BTW thanks again for all your help. This has been really eye opening and now I have a clear direction to attack the problem :)
You can implement your own trait for any std structs. If you don't, though, _no one else can_. Trait implementations must either be in the same crate as the trait, or in the same crate as one of the types the implementation is for. This prevents ever having duplicate trait implementations which could conflict. So: to restrict what std types implement your trait, you simply don't implement it for those std types you don't want. Users of your crate can implement it for their types, but not for raw std ones. --- On the other side, yes, almost. You can implement all std traits for your type, as long as none of them conflict with existing blanket implementations. For example, you can't write `impl&lt;T&gt; Into&lt;T&gt; for MyStruct;` because it conflicts with `std`'s `impl&lt;T, U&gt; Into&lt;U&gt; for T where U: From&lt;T&gt;`.
The way I understand it is that a crate can only implement a particular trait for a particular struct if either the trait or the struct is defined in that crate. So if you define a trait, you're the only one who can implement it for the std structs. But other people can define their own structs and implement your trait for those.
Nobody likes beggars
That's HTTP, the signing happens at the lower layer, TLS. `orca` and `hyper` don't know about that. You could probably make a TLS connector for `hyper` (I think they're pluggable, see `hyper-tls`) that logs the encrypted data, but I didn't look at the API. And you can probably drop `orca`, since you're interested only in simple queries. &gt; to ask it to return the header with the TLS signature too right Again, there is no TLS signature header. Headers are HTTP, TLS is the layer below it. Think of it as receiving a letter (HTTP). It's got an envelope to make sure it's unopened (TLS), but your SO found it in the mailbox, opened it, and gave you the letter inside. When you use `orca` or `hyper`, the envelope is gone, because it's done its job and your SO threw it away.
Got it. Thanks. It's been a while since I researched the process and now in blockchains all data is in "blocks" and all metadata is in the "block headers" so I'm kind of stuck in that mindset lol I'll drop Orca though, as convenient as it is, and hop on over to `hyper-tls`, `hyper-openssl`, and/or `openssl`
Problem is, it's not always easy to identify such delays. So I guess the question is, what's a better default. Start with locks by default or start with lock-less? I agree that lock-less approach has its own trade-offs, it's not "just better" than locks for every case.
Isn't it impossible to measure this with any sort of objectivity? It's not obvious how to standardize bug severity / complexity. People can't even agree on LoC measurements (and it's entirely possible that e.g. comment lines could be the difference between a bug being introduced or avoided). And then it depends on how easily bugs are discovered and how frequently they're reported...
Lovely explanation, thanks. So it‚Äôs a simple as you can only implement it if it‚Äôs in the same crate?
Ty :)
If you have better metrics, then please share them. I think for a given team, transitioning from one language to another, it's useful enough. Defects per feature might be better. Defects per week might too. Honestly, I'm not really interested in bikeshedding this. I'm interested in information I can use to persuade my CTO and my team to start an experiment.
Hi, I first considered a thread-local strategy for Metered but chose not to go for it at first, because of coordination issues. First, I was not very keen on using a channel for single metrics (it makes more sense when sending a whole registry). So with no channel, I needed another way to coordinate writers vs readers. In my situation, I'd like to pull metrics every 5 minutes and clear them -- so we can monitor how the application behaves over time -- and in my case this polling task is triggered by a Tokio timer. To poll safely, the threads writing thread local metrics must not be touching that backend when the reader comes. I was considering an approach somewhat similar to the \`evmap\` crate (using two metric backends that switch between read/write using a semaphore/epoch counter, except it would be optimized for writes using thread-local objects, and merging them once writers are done), and I thought it would be a nice future crate to work on but I wanted to finish a first version of Metered first :P. Also, I found using CAS counters down the hot path was okay compared to the cost of IO we're actually measuring, and keeping the costlier metrics (ResponseTime, Throughput) in higher-level entry points. In the situation you suggest, you seem to be in control of when you publish metrics; Metered as it is works at the metric (eg HitCount) granularity, but a metric could be composite and measure distinct metrics, then push them to an SPSC channel; however the \`#\[metered(...)\]\` attribute does this at the method level, and you might wish to measure different methods then publish them (that should also be possible with unsynchronized metrics if you can live with a !Sync type, then you will get uncontended metrics per method then publish the metric registry to your channel). Finally, you can also use Metered's metrics with your custom metric registries and the \`measure!\` declarative macro instead of the procedural macro, which gives you finely grained control but no boilerplate generation. In general, I haven't completely given up on using thread-local/uncontended strategies and I think it is completely possible to use Metered as it is currently, but some slight adjustments could make it even better. If you decide to give it a go, please let me know and I'm open to support more use cases if possible.
&gt; I wondered what's the best way to make sure that each string is only stored once, hence the HashSet. It's easy to insert strings to the HashSet, but I am not sure, if I am inserting a Vec&lt;u8&gt; if dupletes will be stored. They will not; this is required by the Hash trait protocol contract that if a type implements both Eq and `Hash` that if two elements of the type are equal than so should its hashes be; if they are not this is a _bug_ in the implementation. As such HashSet will deduplicate it; it will not store for the second time something which hashes identically. This has one very interesting implication: two vectors are equal if they have the same length and their elements are equal. This means that two vectors of a different capacity can be equal and thus hash to the same value; the hash does not consider the capacity. So if you attempt to store a second vector with a different capacity that is not equal in the hashset it will not attempt to store the second one with the different capacity. This can in fact read to some rather quirky behaviour if you have elements in a vector that have unusual equality tests. For instance you could conceivably create an `CaseInInsenistiveString` wrapper around a `String` which does the same as a `String` except it does not consider case in all its operations. You can implement `Hash` for this too and it won't store the second one if it has different cases.
TVM (http://tvm.ai) has rather useful rust bindings in the meanwhile.
I have some quantitative data on exploitable security vulnerabilities in Rust code versus C code. Feedback-driven fuzzers, when they first appeared, have discovered a slew of vulnerabilities in widely used C code. Here are the trophy cases of those fuzzers, listing only the exploitable vulnerabilities and ignoring the regular crash bugs: * http://lcamtuf.coredump.cx/afl/#bugs - the most impressive one * http://honggfuzz.com/ (scroll to "Trophies") * http://llvm.org/docs/LibFuzzer.html#trophies That's *a lot* of vulnerabilities. Compare that to the fuzzing trophy case for Rust for all three of those fuzzers combined: https://github.com/rust-fuzz/trophy-case That's also quite a number of bugs, but out of that entire list **only 3 bugs** are exploitable vulnerabilities. So if the Rust trophy case would be maintained in the same way as the C ones, it would only contain 3 entries. Of course, there is much more C code than Rust code out there, so you would have to correct for that. However, there are many pieces of Rust code that implement the exact same thing as the C counterpart, and have exactly zero vulnerabilities revealed by the same fuzzers that found bugs in C code. See PNG or JPEG decoders for example. Another example: [this](http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=libvorbis) is the list of vulnerabilities in libvorbis, the most commonly used OGG Vorbis decoder written in C. About a half of that list is memory corruption bugs leading to information disclosure or arbitrary code execution. The other half is denial-of-service bugs. Compare this to https://github.com/RustAudio/lewton - a Vorbis decoder in Rust, which contains no memory-unsafe code. This means that memory disclosure and arbitrary code execution vulnerabilities can be completely ruled out, assuming the Rust compiler and the Rust standard library are correct. This does not rule out [denial of service](https://github.com/RustAudio/lewton/issues/35) issues, though.
&gt; Send [...] more descriptive name for this trait might be UniqueThreadSafe. Sync [...] A more descriptive name would be SharedThreadSafe An even better, more Rusty, descriptive name would be `MovableAcrossThreads` for `Send` and `BorrowableAcrossThreads` for `Sync`. It also explains the duality as something born out of Rust's own duality between Moving and Borrow. That is because borrowing is how Rust defines sharing. `Rc` and `Arc` are just fancy borrows. Notice that you can only convert them back to owned/movable types if it's cloneable (which means you own a clone, not the actual value `Rc`ed value). Everything about the rules of borrowing, mutable, lifetimes, are just rules for multiple pieces of code sharing the same thing. The interesting thing is because `Arc` has `impl&lt;T&gt; Send for Arc&lt;T&gt; where T:Send+Sync` is the `Send` really necessary if the Arc guarantees that we aren't moving the wrapped object around at all? Because moving isn't the best term, instead we should call it "borrowing" and "giving", which make it clear. In other words `Arc` mean that any one of the `Arcs` can take ownership of the value at any given time (and delete it if they are the last reference being dropped), this means that any one thread can move the object contained into non-existence. Very insightful article though, and it really makes me wonder about the language's semiotics.
NPM has a case study. They initially looked into Rust to improve performance, but found that their pipeline was already so optimized that Rust didn't make much of a difference. However, they migrated to the Rust implementation anyway because of its reliability. See https://www.reddit.com/r/rust/comments/9tc5qq/
Not forcefully, you can send read-only references to other threads, but own it an delete it on your own. It requires bounded threads (as static lifetimes don't really work will with owners). I feel that there's a lot of assumptions about what Send and Sync mean, but only happens due to other constraints.
I think the default should be locks, as it's usually simpler, and you should try to instrument your code to gather more data if it's not clear.
`hyper-tls` looks like it creates an https connection, but doesn't expose the handshake and thus TLS signature. - https://crates.io/crates/hyper-tls - https://docs.rs/hyper-tls/0.3.1/hyper_tls/index.html `hyper-openssl`seems to have TLS data in the handshake. I think the function `new()` in `impl HttpsConnector&lt;HttpConnector&gt;` has it right? - https://crates.io/crates/hyper-openssl - https://github.com/sfackler/hyper-openssl/blob/master/src/lib.rs `openssl` seems like it can do anything, but frankly to me the docs are confusing af **because** it does everything and I can't find what I want lol - https://crates.io/crates/openssl - https://docs.rs/openssl/0.10.16/openssl/ There's also `ssl-expiration` which seems to check the SSL/TLS cert directly, but then doesn't seem to do anything else - https://crates.io/crates/ssl-expiration - https://github.com/onur/ssl-expiration/blob/master/src/lib.rs 
&gt; or implement certain data structures which are inherently unsafe, like you mentioned. Inherently requiring `unsafe`, but not inherently unsafe in the more vernacular definition... just inherently unable to be automatically checked for correctness by Rust's usual measures.
What benefits do they provide over using indecies?
Probably none to be honest. Maybe the fact that they can live on the stack and point to something higher on the stack.
Looks good so far. Have you tried to animate it?
&gt; So the current approach is to use python bindings and so use TensorFlow through Python? Yes. I wanted to get something working ASAP and have high confidence that the actual machine learning part of the library actually works. (Although TensorFlow had a completely broken dropout layer for the last two versions now and no one noticed, so I'm not so confident about it now. ¬Ø\\_(„ÉÑ)_/¬Ø) This also has the nice property that I can write tests based on TensorFlow, and then once I'll be reimplementing the compute parts in Rust I'll already have a test suite which I know also passes on the TensorFlow-based implementation. &gt; And you will completely get rid of the TensorFlow dependency (even tensorflow-rust) eventually? Yes and no. I do plan to keep it, but I'll be most likely switch it off by default. &gt; I suppose you want some library that does computations through graphs, can compile to GPU targets, and can do automatic differentiation then. I'm most likely going to use something more low-level; I would be more interested in having something simple and backend-agnostic (e.g. a library which would simultaneously target OpenCL and Vulkan and allow you to just run manually scheduled raw kernels, for example) rather than have any bells-and-whistles like graphs and automatic differentiation (which most likely I wouldn't use anyway).
You can only implement it if the trait or the type is in your crate. The workaround for this is you can define a "newtype" struct that implements the trait. So instead of implementing a Foreign trait on u8, you would do: struct WrapperU8(u8) impl ForeignTrait for WrapperU8; and then maybe implement some convenience traits like `From` and `Deref` for your wrapper type. 
Conceivably I suppose a Result option would give you a way to distinguish between the out-of-bounds failure mode and the not-slicing-at-Unicode-boundaries failure mode?
I know, found out about it recently and have used it since then actually! Crossbeam should just be interested into rust (same with parking_lot and maybe hash brown, both of which may happen).
"Are we X yet?" is pretty common, with appropriate URLs to match. e.g. https://arewegameyet.com
True. I have to admit that I do actually do that as an extension of the habit of doing `except Exception:` in Python. Maybe I just get complacent with the Rust standard library because I trust the function signatures and documentation more.
It is in most cases, but not all. Specifically, in impl Trait for Type { } There must be *some* part of either Trait or Type which is defined in the current crate, and if either is generic (contains a T somewhere in it), it must not conflict with any other possibly generic implementations. I usually reason through it by thinking "would this ever conflict with another impl allowed similarly in a different crate?" - and if I'm wrong, the compiler will error and usually say what I'm missing (it suggests what the impl would conflict with). For most cases though, yes. The rule of one or the other being in the same crate works.
I know, but the learning one is especially funny
Trait bound needs to be `T: Robot + ?Sized`. `?Sized` is a relaxed bound on `Sized`; it isn't required to satisfy `T`, so you're saying `T` *might be* sized. The error tells you exactly what is going on: `the trait 'std::marker::Sized' is not implemented for '(dyn Robot + 'static)'` Dynamically dispatched trait objects (`dyn Trait`) are not sized. When `T: Robot`, `Box&lt;RobotSwarm&lt;dyn Robot&gt;&gt;` does not have a size known at compile time becase without the relaxed sized bound, you are implying that `T` is sized. `dyn Robot` is not sized because it is dynamically dispatched.
Great answer, thanks! I checked out `synattra` and think it's pretty cool; I maintain [`darling`](https://crates.io/crates/darling), which attempts to solve a similar problem in a way that feels like `serde` from an API perspective. Does `synattra` try to support nesting with parentheses, or is that a non-goal?
You might be interested in [remacs](https://github.com/Wilfred/remacs).
A device driver for Windows or Linux or macOS is a project where Rust would be the best choice. Of course, you should have a hardware device to drive. Another one would be a language interpreter with garbage collection and JIT compilation . Of course you should have a lot of time.
Is it possible to implement a trait `T` for any type `A` for which `&amp;A` already implements that trait? I tried trait T {} impl&lt;'a, A&gt; T for A where &amp;'a A: T {} But that doesn't work ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2bfc3854f504386172321c758a2a5919)). The reason I'm asking is that my actual trait has a method that needs to consume `self`, but for some types a reference to `self` would be enough, so the idea is that I would implement the trait for `&amp;T` and have `T` then implement it automatically.
Can help you any more, sorry. But you don't need to decode the TLS handshake at this point. You just need to log the encrypted data, i.e. put something between the socket (TCP, called `Transport` in `hyper-tls`, probably) and the TLS library.
Thank you!
That's really usefull.. I do a lot of sprite merging to with piskel files using stuff like [https://www.filesmerge.com/pt/merge-images](https://www.filesmerge.com/pt/merge-images).
Good bot
Somehow I hadn't found about \`darling\` while searching for crates handling parsing attributes... Thanks for the pointer, I just had a look and it seems super useful. Wouldn't it support the same kind of attributes that Metered does, e.g I could syn::Path in a struct and darling would parse it? &amp;#x200B; To be honest at first I was more drawn to something like \`darling\`, and found a crate named \`prom-attire\` that did not support parsing type paths. Maybe if it did (or if darling did), I'd have used it an be done. Instead I wrote the code using Syn's design and later extracted it to Synattra. In the end, I found that Syn's design composes extremely well and, in practice, "transfers" the parsing rules to Rust's type system, in the sense that when my parser compiled, it was correct, and it makes it extremely easy to refactor my code or add new options, even if it's a bit more code. &amp;#x200B; About Synattra and parentheses, everything goes as long as your type implements Syn's \`Parse\` trait. For parentheses, brackets and curly braces I used Syn's macros which work great. I use Punctuated for punctuated sequences, etc. It's only a bunch of types to work with Key Value options, including single/multiple values support, but Syn's doing the heavy-lifting. &amp;#x200B;
It's currently only 2D noise but making it 3D shouldn't be too difficult. Definitely gonna try it!
He could use it as a starting point and build a version of tar that unifies the good parts of tar and bsdtar.
But I don't want to fight the compiler, I want to program!!!
It's fairly easy with \`stdweb\` and \`cargo-web\`. Only thing you can't do is multithreading, sadly :(
You could copy this (C + Rust hybrid project): https://chromium.googlesource.com/chromiumos/platform/mosys/ 
I have no idea what the project does because the readme is so sparse. So my critique would be to improve that, especially if you want people to use it!
There are some community lists of project ideas: - [request-for-implementation](https://github.com/dtolnay/request-for-implementation) &gt; Intended for ideas where a design mostly already exists and can be concisely described. It should be ready for someone to dive straight into code and it should be clear when a library has accomplished the intended design. - [not-yet-awesome Rust](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust) &gt;- Enumerate specific use cases and their problems domains that do not yet have a robust ecosystem in Rust. &gt;- Encourage the Rust community to approach gaps in the Rust ecosystem by providing this list as a point of collaboration! 
I‚Äôm not sure I understand, as C++ does not have ABI stability. 
One approach I employed recently was prototyping/training models in python (theano, gpu) with production "inference" in rust. The forward pass math is typically way simpler/straightforward than backdrop/training, so not that hard to reproduce in rust, relatively. Trying different model architectures would be a chore. Python data loading/prep is so freaking slow, though, I am perenially tempted to just do the whole thing in rust. I had to write model weight serialization code. 
I so something like this with docker: \`\`\` cat test-data/input.json | docker run -i --rm \\ \-v ${PWD}/target/x86\_64-unknown-linux-musl/release:/var/task \\ \-e AWS\_DEFAULT\_REGION=${AWS\_REGION\_DEV} \\ \-e AWS\_ACCESS\_KEY\_ID=${AWS\_ACCESS\_KEY\_ID\_DEV} \\ \-e AWS\_SECRET\_ACCESS\_KEY=${AWS\_SECRET\_ACCESS\_KEY\_DEV} \\ \-e DOCKER\_LAMBDA\_USE\_STDIN=1 \\ lambci/lambda:provided handler \`\`\` And I almost always compile using musl-libc, there is a docker image for that also (there are many!).
I just spent 5 minutes trying to figure out what PoC Relative Pointers are. For everyone trying through headbutt through the same wall as me: 'Proof of Cobcept: Relative Pointers' is the conclusion I reached after a regretful Google search.. Sorry but I can't contribute anything to the discussion itself. 
Awesome stuff! Did you use something like [ffi](https://www.npmjs.com/package/ffi) in node?
I see that it‚Äôs a technical standard for wireless communication? Can someone eli5 what this means that it is being done with rust and why it‚Äôs big?
From the linked thread: &gt; [IEEE 802.15.4](https://en.wikipedia.org/wiki/IEEE_802.15.4) is a standard for low-rate wireless personal area networks. It is used as the basis for higher-level protocols like 6LoWPAN, Zigbee, or Thread. [6LoWPAN](https://en.m.wikipedia.org/wiki/6LoWPAN): &gt; 6LoWPAN is an acronym of IPv6 over Low-Power Wireless Personal Area Networks. 6LoWPAN is the name of a concluded working group in the Internet area of the IETF. &gt; &gt; The 6LoWPAN concept originated from the idea that "the Internet Protocol could and should be applied even to the smallest devices," and that low-power devices with limited processing capabilities should be able to participate in the Internet of Things. [Zigbee](https://en.m.wikipedia.org/wiki/Zigbee): &gt; Zigbee is an IEEE 802.15.4-based specification for a suite of high-level communication protocols used to create personal area networks with small, low-power digital radios, such as for home automation, medical device data collection, and other low-power low-bandwidth needs, designed for small scale projects which need wireless connection. Hence, Zigbee is a low-power, low data rate, and close proximity (i.e., personal area) wireless ad hoc network. [Thread](https://en.m.wikipedia.org/wiki/Thread_%28network_protocol%29): &gt; Thread is an IPv6-based, low-power mesh networking technology for IoT products, intended to be secure and future-proof. TL;DR this crate is a stepping-stone to high-level networking libraries for Internet of Things devices and other embedded devices written in Rust.
I second this. Use `structopt` to make a clean command line app.
It's all static HTML and JS, no Node or any server behind it.
How do I request to join? I can only see login page.
You can send me a PM to request for an invite link.
FIDL is tied pretty tightly to Fuchsia. It makes use of capabilities that the Fuchsia Kernel provides, e.g. to share handles/capabilities between processes via RPC calls. Therefore it won't help to glue together Flutter/Dart and other apps on other platforms like Linux/MacOs/Windows. gRPC would be a more generic solution that other platforms could utilize, but which does not provide the ability to exchange those low-level data types.
&gt; Somehow I hadn't found about darling while searching for crates handling parsing attributes Hmm, I may need to update my search keywords then. Do you remember what you searched for at the time? `darling` relies on `parse_meta()` from `syn` at the moment, so it wouldn't be able to handle a path without quotation marks. That was what `serde` did when I made the library, and at the time I wasn't trying to implement my own parsing. The interesting question in my mind right now is whether someone could have an attribute that was partially handled by `synattra`, handing off to `darling` for the parts that can be parsed as a `Meta`. I'm already planning to add a wrapper type to `darling` so that any `FromMeta` can be wrapped to `impl Parse`, which would make it work with `synattra`. I'm going to try implementing something with `synattra` this weekend and see how I do.
Hopefully soon though!
https://github.com/ebobby/simple-raytracer
I just started using rust about two months ago and I rarely run into issues with fighting the compiler now. It takes some getting used to but it's not that bad. If you're talking about the webassembly part, it's fairly straightforward as well, check out the book on it, it's very concise!
Is it possible to create a trait that can be used in both contexts? ``` fn foo() -&gt; f64 { "42".magic() } ``` and ``` fn foo() -&gt; Result&lt;f64, SomeError&gt; { "42".magic() } ``` ? Basically, if the return type is Result&lt;T, E&gt; where T: FromStr, then I want to simply perform `parse()` but when return type is not Result, then I want to perform `parse().unwrap()`. I've tried to create custom trait and implement it once for T where T: FromStr and then for Result&lt;T, E&gt; where T: FromStr but unfortunately, rust says me that this is ambiguous because someone in the feature can add FromStr for Result&lt;T, E&gt; and then my implementations would be ambiguous. Is there any way to solve it? 
PoC = Proof of Concept. Relative Pointers refer to pointers stored as offsets from their own address.
Wow, that's a lot of different interesting stuff under one project! A game engine, Pure-Rust image decoders and decision theory... and is that friendly AI problem? Out of curiosity I've re-run the in-tree fuzzing target for `png` crate that I've added about 6 months ago and looks like the library crashes on malformed input again: https://github.com/PistonDevelopers/image-png/issues/103 Memory-safe image decoders that you can expose to untrusted input are very cool, but bugs like this one undermine the value proposition massively. You should probably run fuzzing on CI to prevent regressions such as this one.
I can't be the only one who didn't know what worley-noise is and was disappointed when some 70s sounding synth ambiance didn't come out of their browser. It's still very pretty, though!
Question: how long do the compile times ruin for you with std-web? I've really liked using it with yew, but the build times are pretty painful.
Haha yeah it's noise in a mathematical sense. However you totally can use it to sample audio, like white noise. It's probably not very interesting tho.
Very quickly, didn't notice much of a difference compared to a regular build target.
 #[no_mangle] pub extern "stdcall" foo (args...) -&gt; result
Right, I've gotten that far, but I don't know how to match this specific signature -- specifically, how do I accept a `PUNICODE_STRING`, and can I use it as a Rust `String` or are there conversions I need to do (other than dereferencing that pointer in the first place, that is)?
Does the winapi crate export those types? If yes use those. If no, you need to check the C language representation of those types and use the appropriate rust equivalents. The `String` type is not portable across library boundaries. 
If you know the type, wouldn't you already know the offset? 
It does have a `PUNICODE_STRING` type, which is a `*mut UNICODE_STRING`, which is [here](https://docs.rs/winapi/*/x86_64-pc-windows-msvc/winapi/um/subauth/struct.UNICODE_STRING.html). I don't see a way to get this into a Rust data type I can use. Unless I'm missing something?
Looking at it closer it would be something like use winapi::subauth::UNICODE_STRING; use std::slice::from_raw; impl to_string for UNICODE_STRING { fn to_string (self) -&gt; String { unsafe { let slc = from_raw (self.buffer, self.Length as usize); let v : vec [u8] = slc.iter().map(|c| c as u8); v.to_string() } } } Apologies for formatting or typos, I'm on mobile 
Sorry I added another comment for you showing roughly how to do it. You basically want to convert the buffer (`*wchar_t`) to a slice, then convert it to a vector of u8, then convert to String. 
Short of a method on `PUNICODE_STRING` itself, that doesn't look too bad. Thank you! Since this is a work project and it's now the end of the work day (well, a few minutes past...), this is going to have to wait until Monday now, but I wasn't expecting to have this done today anyway.
I've got a *very* long way to go with my Rust, so thank you very much (again)!
Yea, ToString is the std trait for converting types to strings. You can do it as a free function or in your code somewhere, but this is a more rust-ic way of doing things. Just note the difference between encoding (wchar_t is u16, Rust strings use u8), and the unsafe code there (check the pointer for being null? Probably safe, maybe not) 
C++ does have ABI stability for, basically, anything that can appear in a .cpp file rather than a .h file. That mainly consists of definitions of non-generic functions. Generic (template) code has to be written entirely in header files, at least if you want the client of your library to be able to instantiate it with their own choice of types. Even non-generic classes/structs generally have to have all their fields defined in the header file, including private fields (so that clients know the size of the class/struct), so you can't change those. Thus, keeping a C++ library ABI stable requires accepting some intrusive restrictions on how you can write it, but it is possible. 
Nice! I made a rust raytracer following the raytracing in one weekend book, but I didn't really adapt the structure to fit rust very well. So I ended up with this rather awful C++-ish rust code. This project looks much cleaner and nicely rustic. 
Specifically, Swift's generic use runtime dispatch semantically, but the compiler is quite eager to specialise as an optimisation.
You might be looking for an [fst](https://github.com/BurntSushi/fst)
Hmm... I was going to say, why can't `std::regex`'s performance be improved? In theory, as long as the main matching routines were non-generic and non-inline, implementations would be free to change their behavior without breaking ABI compatibility. So I looked at libc++'s implementation and... ah, it's because `std::regex` is actually just an alias for `std::basic_regex&lt;char&gt;`, where `basic_regex` is intended to support providing your own choice of "character" type and thus has to be implemented entirely in the header file. Sigh. That's just bad design. In general, I think Rust could theoretically do a lot better than C++ in maximizing flexibility for ABI-stable libraries. For example, as you may know, C++ inherits C's ability to have "forward declared" structs/classes whose layout is not known, but such classes can't have methods declared on them. So unless you use awkward workarounds like "pImpl", you have to declare your classes' fields in header files, meaning that any changes break ABI compatibility. This is a completely unnecessary limitation; [C++ might fix it eventually](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0309r0.pdf), but Rust never needs to have it in the first place. As another example, I think Rust ought to eventually have an explicit way to represent "subset of this API which existed in past versions", to help with both API and ABI compatibility. This would make it a lot easier to avoid breaking something by accident. (I know `rust-semverver` already exists to do something like this on the API side, though I haven't used it.) But it's true that ABI stability inevitability imposes some limitations. I think it's still valuable enough to be well worth doing, as long as it's done smartly..
Did you get it working, and if so, could I check out the code for the openssl or non-openssl versions? 
[https://github.com/samsartor/sidequest/](https://github.com/samsartor/sidequest/tree/master/src) &amp;#x200B; It's definitely a work in progress but I've had a lot of fun trying things out over the last few years. I recently added a real-time preview window and progress bar.
Or transducers https://blog.burntsushi.net/transducers/ https://github.com/BurntSushi/fst
Well, did you look at that thread on GitHub? It is exactly how the author described it. 
But have you renedered the *teapot*?
I tried to learn how to do stuff the Rust way along the way. Plus, clippy is pretty helpful. I started by reading a blog post too, but I tried to actually work the math in my notebook to truly learn. I bought a few books. I intend to take it further. 
I need to add code to load such models.
Nice! Only had time for a quick glance through the code, but it's shockingly easy to follow for a ray tracer. I look forward to fiddling with it.
&gt; &gt; &gt; This also has the nice property that I can write tests based on TensorFlow, and then once I'll be reimplementing the compute parts in Rust I'll already have a test suite which I know also passes on the TensorFlow-based implementation. Nice! This sounds like the Javascript test suite that is tested with multiple engines.
&gt; there is no commercial license for it, as I don't own one and therefore cannot grant it Is this type of licensing agreement common in the publishing industry? When I commission work, it comes with a full copyright assignment (automatic in my jurisdiction since I'm paying for it). Even in countries where a copyright reassignment is not possible, I would expect at least unrestricted sub-licensing rights. I suppose there is nothing to be done since it seems from your post that he's redoing the work under the same contract, but if you're going to pay again, I strongly advise you to renegotiate for more favorable sublicensing terms. If the amount being payed is enough to justify it, get a lawyer. &gt; If not ideas, please comment on this image and let me know what you like or dislike about it from an artistic point of view, so that I can take your commentary into consideration as I brainstorm. ‚ÄãHave you provided the artist with all text and logos as they will appear in the final product (locations, colors, sizes, weights)? To my inexperienced eyes, the composition of the image doesn't seem particularly suited to being used as a book cover background. Also, from the aspect ratio, I assume this image will only be used for the front and wont wrap around the back? The coloring and linework are both very pleasant. The subjects and objects in the work do raise a few questions: the crab is rust's mascot, but what about the hedgehog? What is the relevance of the disco ball for it to demand such a prominent position and color contrast? Do these represent concepts discussed in the book (say, unsafe rust or algorithms, respectively)? Again, I'd like to stress that I have no experience with the publishing industry, so you should take what I wrote with a giant grain of salt.
Thanks! It was a real rat nest for a while. Glad to hear I've gotten better.
How would one go about calling a function after a certain (configurable) duration? My intuition tells me Futures (with or without Tokio), but I'm having difficulty figuring out how it would work together with the Rocket server. The server would have to be able to add events onto the event loop dynamically. This is _essentially_ the equivalent of JavaScript's `setTimeout`, which is what I'm trying to translate over.
No worries. Thanks again for all your help though! :)
It appears to take 2 images and overlay them on each other
I've now uploaded the initial version of the proposed crate: [`lexpr`](https://crates.io/crates/lexpr). Any feedback is welcome!
It is technically possible to define and train a neural network entirely in Rust with the `tensorflow` crate, but you would have to reimplement quite a lot, like gradient descent. The problem is that the `tensorflow` crate can only export bindings which the TensorFlow C API exports, and that doesn't export many higher-level concepts, yet.
where is the source code ?
Not offset within a struct, an offset from the location of the pointer.
https://github.com/rust-net-web/tide
I submitted a patch to webpki which was merged already, see https://github.com/briansmith/webpki/pull/86 I also submitted a PR for extracting the public key but it is still in progress, see https://github.com/briansmith/webpki/pull/87
Solving that problem *efficiently* with threads is a touch more complex than just throwing the hash-map into an `Arc&lt;Mutex&lt;_&gt;&gt;` `Mutex` will allow execution one at a time and then you just have a serial algorithm with extra overhead. Instead I would consider multiple passes. First you need to replace each input text with a histogram of words (or n-grams). That's a *map* problem and easily parallelized with rayon. Next simple step is to create an overall word list. That requires merging the word lists from each input. That's a *reduce* problem. Map, reduce. Then go back to the histograms and turn each one into a frequency vector, using the master list to put each frequency into the correct place. Map problem, since each input may be considered separately. From that point it's just linear algebra, which can be parallel if that makes sense. After all, there's some overhead in transferring work between worker threads. Rayon tries to avoid needless overhead by only actually transferring work when a worker is starving. Even so there's some overhead in making the work available. Thinking about how to map and reduce data is good for noticing the opportunities for parallelism. As a rough rule of thumb I then think about L1 cache size. If a task can fit into L1 cache, about 32-64 KiB, it probably shouldn't be divided further - any remaining parallelism is "instruction level" not "thread-level" and would be an opportunity for optimization techniques rather than threading.
Cool thanks :) 
* deployment frequency * Average time to complete an issue * Average time to fix a defect
Thanks for the reply. I ended up shifting my implementation to using multiple passes to simplify things. My first pass creates a hashmap with indexes and my second pass constructs the counts of each word. I considered concatenating all phrases into a single vector and then performing operations at a faster rate, but i believe this introduces extra entropy into the final calculations which is not desirable. I definitely am open to experimentation so i will try your idea. The only point im confused on is &gt;go back to the histograms and turn each one into a frequency vector I thought i would also add that the order of the vectors does not matter, just that batch #1 and batch #2 do not mix. I have never used threading/locks before (python makes it inefficient) so I chose `parking_lot::RwLock` so there would be the least overhead for reading / writing.
\&gt; (WebAssembly/asm.js still have too many issues) What kind of issues? I'm working on a pretty heavy front-end app in pure Rust (with web\_sys for JS bindings to the web APIs) and it's working out really well.
My intuition: Rust minimizes rework costs (new feature, issue correction, safety/critical bug). And rework costs have the largest share in the total costs of SW dev (from scratch to end of life) What I would look for in public large alive codebases: - issue raised per feature added - issue correction duration (time to correct it) for issues that are not functional, e.g. memory issue, concurrency issue, correctness issue. Those theoretically do not exist in Rust - issue correction duration for functional issues; this should emphasize the refactoring capabilities of rust According to me, data mining could be done on big github/gitlab/svn sources of the languages you want to compare With those KPI, and based on the assumption that rework is the main source for SW costs; a semi rational comparison could be established 
TIL about clippy. Do you parse the output of clippy in your editor? I use vscode, and I'd like to have the warnings show up in my code the same way RLS does, but before I write a big regex expression to capture it manually I'm trying to figure out if there's a better way to go about it.
thanks for your hard work, Aaron! You presided over an immensely successful period for Rust!
IIRC the official rls plugin for vscode can do clippy warnings, but I haven't used it in awhile
IMHO, no body actually do training part of machine learning tasks with native compiled language. If you simply want to deploy your trained model, then I suggest have a look [TVM](https://tvm.ai/). They have [rust binding](https://github.com/dmlc/tvm/tree/master/rust). But the project itself is still in early development stage.
Is there any way to make fold stop in a cyclic iterator? Does something like a Continue, Stop enum exist, where the fold would finish when it received a Stop variant? I've done this with a loop, but I think a way similar to the above is more idiomatic. input.split("\n").map(|x| x.parse::&lt;i64&gt;().unwrap()).cycle().fold(0, |sum, x| { if x % 2 == 0 { Continue(sum + x) } else { Stop(sum + x) } })
https://gitlab.com/sogomn/worley-noise
I've also been working through Peter Shirley's raytracing in a weekend book in Rust (https://github.com/davechallis/rust-raytracer is where I'm at so far). It's mostly been a pleasant experience in Rust, and was able to get images rendering on multiple CPUs pretty easily thanks to Rayon. Only bit which has been painful so far was building tree data structures, and dealing with passing round boxed trait objects in many places to deal with different shape/material types.
https://github.com/rust-lang/rls/blob/master/README.md#configuration There you go. Just put `clippy_preference=on` in your settings.json file in vscode or put a `#![warn(clippy::all)]` in your crate root and the clippy warnings will be displayed in vscode. BTW If you find any bugs or have new ideas for lints, just open an issue in the clippy repository. Or (even better) you can implement/fix it yourself! We're always happy for new contributors and will help you get started. Clippy is a great project to start to get involved in the rust eco system! :) 
You can look at the type definitions here https://docs.microsoft.com/en-us/windows/desktop/winprog/windows-data-types
Perhaps `try_fold` does what you want?
Thanks! I'll make sure to do that if I come up with anything.
Thank you
Thanks for your reply. Why not use a native compiled language for machine learning? I just did a bechmark with Python+TensorFlow vs. Rust+Juggernaut with Q-learning in an Acrobot environment. The Rust version did 50 episodes in 3.8 seconds, while the Python version did 50 episodes in 705 seconds.
Does that work? I `UNICODE_STRING` is a wide string and you're casting that to `u8`. 
Yes, it does work, but I have to return something as Err, when, in this case, it's not really an error. But it works.
I guess that‚Äôs true. I‚Äôm not sure how useful that is though.
There is no *standard* ABI for C++, however in practice every single C++ implementation provides a stable ABI. For most, this is the Itanium ABI.
Love me some Raytracers. It's my go to project when learning a new language. Here's [mine](https://github.com/k0nserv/rusttracer) from when I started doing Rust. 
what a coincidence! this is actually going to be my next project! awesome to see some of the resources here. &amp;#x200B; OP, would you say that building it has substantially improved your understanding of 3D rendering engines? that's why I want to do it.
What rjsberry said is all correct. But i'm not sure it solves your problem. If i understand your request correctly, you want a collection of robots, but not have every robot behind a fat pointer (to lookup its trait implementation). And you want a non generic RobotTestingFacility that can hold such a collection. struct RobotSwarm&lt;T: Robot&gt; { robot: T, robot2 : T } impl&lt;T: Robot&gt; RobotSwarmTrait for RobotSwarm&lt;T&gt;{ fn get_first(&amp;self) -&gt; &amp;Robot { &amp;self.robot } fn get_second(&amp;self) -&gt; &amp;Robot { &amp;self.robot2 } } trait RobotSwarmTrait { fn get_first(&amp;self) -&gt; &amp;Robot; fn get_second(&amp;self) -&gt; &amp;Robot; } struct RobotTestingFacility { swarm: Box&lt;RobotSwarmTrait&gt; } Where you should modify your SwarmTrait to expose what is commonly required of swarms. i.e. the more you can implement inside the ' impl _ for _ ' the less vtable's are addressed. But in practice the speedups are insignificant on modern day CPU's. 
This is waaay nicer than my own attempt, really nice!
Was this rendered in real time?
&gt; FIDL is tied pretty tightly to Fuchsia Well Fuchsia is in the name. But my interest is what it does with Zircon. Which is the Fuchsia kernel. &gt; Therefore it won't help to glue together Flutter/Dart and other apps on other platforms like Linux/MacOs/Windows. That is definitely true. An excellent point. A really important point. Thanks! 
Depends on the framework you want to use. I think the guide on https://rocket.rs is solid, and great for a beginner. 
If I don't want to use framework , so where can I start from? 
Probably not a guide out there for that. It‚Äôs a serious project to build a web server or frontend in Rust from scratch. What do you actually want to do? Learn to code? Learn to make websites? Learn Rust? Learn Web assembly? 
You *could* implement `Try` for your type, but I'm not sure if it's stable yet.
Unfortunately no. Real-time path tracing requires an extreme level of optimization, very creative sampling techniques, and a lot of GPU acceleration. It's not quite impossible but *way* out of the current scope of sidequest. I really just wanted to learn how path tracers work, not totally revolutionize real-time graphics! I am quite proud that you can watch each frame take shape tile-by-tile in the preview window. However, depending on your hardware and on the scene, each frame can take quite a while to converge.
Yes. My purpose is learning, both rust and do fundamental web design in rust. 
&gt; Only bit which has been painful so far was building tree data structures, and dealing with passing round boxed trait objects in many places to deal with different shape/material types. Have you tried a more data oriented approach? Just store all nodes / edges in arrays and the tree itself could just be a bunch of indices into those arrays.
[removed]
The thing is just that I have no use for this now (neither commercial nor noncommercial), so there is no reason to just have it collect dust on my hard drive, as other people may have a noncommercial use they can put it to. 
I addressed this in my response to chuecho. 
I‚Äôm no sure what‚Äôs going on, but I can‚Äôt see that comment.
With writing your own web framework. You cannot create a web application without writing the code that will make it work, and such code, even when slightly generalisied, will by its nature become a framework.
It's because my account is so new that my posts still need to be approved by moderators I think. 
If anyone's curious about Path Tracer vs Ray Tracer, I found this a good read https://www.dusterwald.com/2016/07/path-tracing-vs-ray-tracing/
Do you want to use Rust as a sort of replacement for PHP or Go or Node JS? If yes, you should use Rocket. If no **you will need to write a web server (like nginx or Apache) on your own.** That's a massive task to do well. Anyway, the Rust book has a section on making a VERY SIMPLE, INEFFICIENT web server which takes far more time with than it's worth. That kind of thing is not _really_ in the realm of web development, and CERTAINLY not in the realm of web design. https://doc.rust-lang.org/book/ch20-00-final-project-a-web-server.html 
Because most of the time you are the tweaking the parameters. But if you are CPU bounded in the DRL scenario, then it make sense.
You should post that on r/playrust
Did you even read what this subreddit is about before you posted? Does it seem like this subreddit is about the Rust game?
Did you even read what this subreddit is about before you posted? Does it seem like this subreddit is about the Rust game? 
You probably want /r/playrust. This subreddit is about the programming language called rust, not the game called rust. If you do fancy learning the programming language anyway now that your here, check out https://doc.rust-lang.org/book/
Yeah, all those other languages listed above include built-in web server support. Rust does not. If you're looking to create your own websites, you really want to start with an existing Rust web server (usually included in a framework, which is why we bring it up). Building your own web server is non-trivial and time-consuming, and doesn't bring you any closer to actually making any websites.
I don't know, rust doesn't have that high of requirements. Won't it compile on your machine or what? 
I don't think the applications of Java and Rust overlap 100%. I personally don't like the Java/C# kinds of languages that much(Not having done Java, but disliking C# a good deal). For high level I go really high level with Python and for deep down rust (or if that's not possible C). That said: I think Rust definetly has a future but there probably are 100 times more Java jobs. 
I love the idea of someone stumbling into learning rust after an accidental post in the wrong subreddit :D
It's because of the lifetime you specify in the function bar - you have said that 'a is the lifetime of the borrow saved in i inside the struct, and this is the same lifetime as that used for the borrow of self in bar. As a result, Rust cannot let you reborrow self at all after you've called bar - for all the borrow checker knows, there's unsafe code that depends on not being able to borrow again after the call to bar. Change the lifetime specifier in bar to fix it - I simply removed it (so &amp;mut self) as lifetime elision rules do the right thing here.
When you do `&amp;'a mut self` I think you are saying the mutable borrow lasts for the lifetime `a` which includes your `let _borrow = &amp;foo` line. The playground link below does compile, and is more likely what you would want in this situation. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ff2499fe169777a08e50527613660e8b
Yep, this library is extremely low-level as far as machine learning goes, but it's also extremely powerful. If you want regularization, you need to implement it yourself by adding something like `some_factor * ag::reduce_mean(ag::square(&amp;flattened_weights_array), &amp;[0], false)` to the variable you are optimizing. If you want to implement dropout, or other complex kinds of regularization, you need to really think about how to translate that to tensors. For example, what is dropout? - It's a boolean mask filled randomly (use `rand::thread_rng` while training, and a vector full of ones in `eval`), which you apply after each layer, just before activations. You can add gaussian noise exactly the same way, by adding, or multiplying your activations by some input vector. You can then implement that in the convenient `NetworkBuilder` struct, but you need to keep track of those vectors and fill them in when calling `Network::train` or `Network::eval`.
Thank you. 
I have a bit of experience with this in that I develop Spring for my day job but work on a side project in Rust. I totally believe Rust has a very bright future ahead of it - as a programming language it does things in a way that just make a lot of sense, and lead to safe, performant programs in a way that no other language really can help you with in the same way. Like, Spring applications tend to have a massive memory overhead, for instance. Null pointer exceptions are still a very real thing in the Java/Spring as a legacy from older applications and libraries which is a whole class of bugs that Rust basically just erases. Rust is *so much harder* to work with than Java/Spring - now, bear in mind this might just be time constraints talking - particularly if you're using Spring Boot which basically just gives everything to you on a silver platter by comparison. Whereas with Rust there aren't really sensible defaults, so you have to read into things a bit more. Like if you want to do CSRF protection on your forms, Spring obviously just gives that to you with Spring security. With rust, maybe if you're using Iron or Actix then you can use their CSRF protection - but the most natural library for somebody coming from Spring would be Rocket, which doesn't support it yet. A consequence of this is that there isn't like this central repository of documentation to put together an application, but instead you have to go onto different project pages and figure out how to piece everything together for yourself. Fortunately this isn't actually that hard, it's basically equivalent effort to learning how to use the different components of something like Spring in my experience. I've also found it's very difficult to write code that is testable with unit tests using things like connection pools with diesel where you're sharing resources all over the place and then you're using them in a which requires you to give it a connection with a fairly complex type which you can't really mock effectively meaning many people just end up relying on real connections in their tests - not a dealbreaker, but it's not ideal, either. Either way, in the Java world that'd be seen as integration testing and testing purists would note that it kind of distorts your test pyramid. This is particularly unfortunate because with Rust's reputation as a safe language, this makes it hard to write code that you could otherwise have confidence in and it's not a problem that I've been able to solve in my spare time. Part of the problem with this is there isn't really a good answer to dependency injection in the Rust ecosystem which is in large part because it just doesn't have the same kind of flexible runtime that Java enjoys. So testing strategies tend to be quite a bit different in general. Nevertheless, I see these problems as more aspects of the ecosystem not quite being totally mature yet, and I'm confident that if Rust keeps up its current momentum it should solve those problems. As for "does rust have a future?" I think it must, it has some very obvious benefits over many programming languages. It does have a learning curve but it's not totally insurmountable and most of its design choices are pretty pragmatic. There are quite a few large organisations now using Rust including: Mozilla (obviously), Cloudflare, Amazon, Dropbox, Google, Facebook, Microsoft, Reddit and others. See: https://www.jonathanturner.org/2018/07/snapshot-of-rust-popularity.html However, we're not really seeing it much in the space of serving web applications or APIs by the looks of it.
Friendly AI has been renamed to Control Problem due to a general trend of separating ethics from technical goal alignment. It's a huge field now, and I'm just focusing on a very small part of it. I've been interested in weakening of assumptions behind Instrumental Rationality and grounded semantics in agents that think about smarter versions of themselves. This umbrella of ideas is called "Zen Rationality". There has not been much progress as hoped, due to most of it being beyond our current technical capabilities. Thanks for the fuzz! I'm not the expert on this, so I hope somebody working on the image crates picks it up and fixes it.
Do you mind explaining what CGI is? I only know that acronym to mean "computer generated images".
There is a million Java jobs. Rust is niche yet. So for making money, getting experience, having secure job, go for Java. Better yet, aim for Kotlin, as nobody in Java world actually likes writing in Java anymore.
This is exactly what I've been doing using crossbeam MPMC channels in GTK applications, which allow cloning of both the receiver and sender for sharing. Although, I've been using `gtk::timeout_add(16, move || loop { match state.ui_event_rx.try_recv() { .. } });` to listen for the UI events in GTK's main loop, breaking on `Ok(TryRecvError::Empty)`, since it's not integrated with GTK. To prevent spawning a lot of threads, it's ideal to have at least two channels -- one for handling UI events in the main thread, and another to handle background events in a background thread. That way, background threads, GTK widgets, and application startup can send events to the same channel for handling in a central location. To support Wayland, it's also a good idea to have a third channel, where the application will launch with `pkexec` / `sudo`, spawn a new background thread to handle privileged events, downgrading the main thread so that all future threads will be the user, and then initializing GTK. It looks something like this: /// Downgrades the permissions of the current thread to the specified user and group ID. fn downgrade_permissions(uid: u32, gid: u32) { unsafe { // By using system calls directly, we apply this on a per-thread basis. // The setresuid() and setresguid() functions apply to all threads. libc::syscall(libc::SYS_setresgid, gid, gid, gid); libc::syscall(libc::SYS_setresuid, uid, uid, uid); } } Then in the application, when setting up state and channels: let (back_event_tx, back_event_rx) = unbounded(); let (priv_event_tx, priv_event_rx) = unbounded(); let (ui_event_tx, events::privileged(ui_event_tx.clone(), priv_event_rx); // If running in pkexec or sudo, restore home directory for the open dialog, // and then downgrade permissions back to the original user. if let Ok(pkexec_uid) = env::var("PKEXEC_UID").or_else(|_| env::var("SUDO_UID")) { if let Ok(uid) = pkexec_uid.parse::&lt;u32&gt;() { if let Some(passwd) = pwd::Passwd::from_uid(uid) { env::set_var("HOME", passwd.dir); downgrade_permissions(passwd.uid, passwd.gid); } } } events::unprivileged(ui_event_tx.clone(), back_event_rx);
Sure, I mean the Common Gateway Interface standard used by Apache, nginx etc.
We all love to Alt+Insert/Option+Return/whatever your generate keybinding is.
Not true at all, I love Java and so do a handful of devs that I personally know. That being said, I am personally dipping my foot into WASM and Rust.
1. Its good to be proficient in many tech areas; you don't "drop" them. After you've been around for awhile, you'll be surprised at what comes back around or how different technologies link together. 2. Yes, IMHO. 3. I'm learning it myself, but you've got an opportunity to be learn while being paid, go for it. 4. Buy a book, keep up with search resources, and experiment on your own.
1. There's a lot of people around here that would be happy to ditch a job writing Java for a job writing Rust. Personally, I think it's a great idea to take an opportunity that can push you far ahead of the competition. Rust talent is more rare than Java talent, which can mean greater demand for Rust talent, especially in this time where many are looking to make the shift. 2. There seems to be a general trend that the industry is moving towards Rust. I even use Rust for about 90% of my job with System76 -- occasional C / Vala usage when working with third party open source projects. IE: GNOME Control Center requires C to glue in the UI, but major functionality can be provided by connecting to a DBus daemon written in Rust. 3. Difficulty varies from person to person. Some find it easy, others find it hard. Importantly, the benefit in Rust is that it's easy to master once you've learned it, since the compiler does the job of preventing most bad practices from the beginning. 4. I wasn't thrilled by the amount of resources for Java, honestly. Too many resources can easily be a bad thing. Most of them are outdated, and there's a lot of people attempting to teach bad practice out there. It's really difficult to find good resources that are actually up to date. Personally, I don't think Spring is that great of a framework -- it's just what a lot of companies have been using for decades.
Thanks for the reply, the part about `pkexec`/`sudo` is very useful to keep in mind for certain kinds of applications :) &gt; This is exactly what I've been doing using crossbeam MPMC channels in GTK applications, which allow cloning of both the receiver and sender for sharing. Although, I've been using gtk::timeout_add(16, move || loop { match state.ui_event_rx.try_recv() { .. } }); to listen for the UI events in GTK's main loop, breaking on Ok(TryRecvError::Empty), since it's not integrated with GTK. That's something you can also do with the std MPSC channels, but the polling that causes the main loop to wake up all the time is something I wanted to prevent. It's either a waste of resources or if you poll not often enough the UI updates will be delayed. OOC, why do you need MP**M**C channels? What's the use case here for multiple consumers in the context of sending data to the main thread? But it should be easily possible to copy my implementation and replace the std channel with the crossbeam one. It's a wrapper around the std one plus wake-up logic for the main context. Or maybe you want to send a PR to optionally have API around the crossbeam channel in glib, enabled via a feature flag? Then all that glue could easily be shared between both kinds of channels.
I think the tokio-timer crate?
Would https://docs.rs/cgi/0.1.0/cgi/ work?
I guess not, but there are some web pages and tutorials you could skim from time to time.
I wrote up this post after reviewing a crate which was returning specific exit status codes based on the specific error type in the application. It takes a small amount of setup in order to use the `?` operator in main, while also returning custom exit status codes, so I created a simple [exit crate](https://github.com/JoshMcguigan/exit) to solve the problem, and wrote this post to document the process.
I'm aware of the effort, but I didn't make the connection. Maybe the remacs folk can make use of the parsing code in [`lexpr`](https://github.com/rotty/lexpr-rs), once I get around to actually implementing a parser...
I tried that, but it didn't work. I hoped there would be something official :)
Crossbeam only offers MPMC channels, and they're significantly faster than than the MPSC implementation in the standard library, which is based on a mutex. That's one reason to prefer it. Even if you don't use the MC feature of a MPMC channel, the option is there if you do happen to require it at some point. Having multiple background threads listening for events from the same channel, to process them in parallel, for example.
Does it have to be CGI? As far as I know, it's a lot more common in rust to have the rust application actually handle the requests itself, with, e.g., [actix-web](https://github.com/actix/actix-web) or [rocket](https://rocket.rs/). Then you'd put nginx or apache in front as a proxy.
&gt; I hoped there would be something official CGI is a technology that's been deprecated over 20 years ago. The Rust team can find better things to invest effort into. &gt; I tried that, but it didn't work. Can you say what you've tried, and why it didn't work? The crate seems maintained so opening an issue might be a good idea.
&gt;CGI is a technology that's been deprecated over 20 years ago. Do you have a source for that? I know that most, if not all, shared hosters only allow CGI or FastCGI. &gt;Can you say what you've tried, and why it didn't work? The server of my hoster refused to execute it. Weirdly enough it worked with Go. Maybe the compilation target was wrong. &gt;The crate seems maintained so opening an issue might be a good idea. Good to know, it looked unmaintained to me :)
Yes, my hoster doesn't allow me to run anything other than CGI or FastCGI.
I have almost a decade experience in developing Java/Spring as a professional and have been learning Rust for fun aprox. a year ago - I am 33yo. Yes, it is harder at first, but I really learned some new stuff that kept me motivated - I think it's much about the mindset. Not everything is harder, some concepts are really neat like the less verbose syntax (some can argue it still is verbose, but Java is my anti hero in that matter). 1. Learning a new language will not make you "drop" your current skills. Being a good developer in any language will make you a better developer generally speaking. The future is polyglot - I think I even heard that from an Oracle guy promoting their shiny GraalVM. 2. Noone can tell. For sure noone can take your experience. 3. See above, but having a company paying you for learning a programming language is great! 4. Java / Spring has a lot of resources but my colleagues and I still occasionally have a bad time in reasoning about setup or errors in medium to large sized projects. Rust has a nice and small community, Java world has tons of resources with different quality.
&gt; Do you have a source for that? I know that most, if not all, shared hosters only allow CGI or FastCGI. Random article: https://blog.layershift.com/which-php-mode-apache-vs-cgi-vs-fastcgi/ FastCGI is totally fine, CGI is only supported for legacy reasons. There's no reason to use it for a new project. &gt; The server of my hoster refused to execute it. Weirdly enough it worked with Go. Maybe the compilation target was wrong. Possibly, or a dependency issue. You can test it on your computer. As for the dependencies, using a `musl` target might make it more portable.
You could have a large memory bock with some heterogeneous data allocated into it (not just a flat array but different types of structures which points to one another using relative pointers). One great thing about this is that this big heterogeneous data structure with relative pointers is position-independent, so it can be, for example, written to disk and (unsafely) loaded back without having to fix any offset up, or it can be cloned with a simple memcpy etc. 
It solved my most pressing concern which was that I just had no idea what was going on. The behavior/existence of the ?Sized trait bound was not intuitive for me. The efficiency issue is a bit of a premature optimization anyhow. I ended up running into additional hurdles as I really wanted \`RobotSwarm\` to be able to replace dead bots, but it seems like constructors are not "object safe." In the end, I created a "robot trait" by matching every "trait method" for every bot type in an \`Enum\`, which is not very ergonomic (understatement), but so far is working great. This seems great, because bots will not vary too drastically in size, and being able to include arbitrary bots from other packages or whatever isn't a hard requirement.
But... I thought borrows have scopes. If so, what is the scope of the mutable borrow?
Woah, nice! I've never seen a government-maintained reference like this, and certainly not on GitHub. Is anyone aware of other resources in a similar vein? 
I don't think many of us are using Meson here. Cargo handles 95% of the job, and a simple Makefile is enough for the remaining 5%.
Plenty of people in Java likes to write Java. Kotlin in only a thing in Android J++ due to being stuck with a subset of Java 8.
Great stuff; I tried existing noise crates a while back, and were disappointed they wouldn't compile to the wasm32-unknown-unknown target.
You mention python being common for system services, but it's not good for distributing standalone executable like CLI apps. It tends to rely on system or virtualenv python installations, which can be a mess (Python 2 vs Python 3 that comes with the OS vs Python 3's latest version etc)
I frown every time I see a new application that looks neat, but which cannot be easily packaged for Linux because of this. You'll get downvoted in /r/linux if you point out that Python makes packaging complex though. :P
The problem I was having was adding events to an already running event loop. I presume that's possible, just not sure how.
Ah, Rocket is not async, and does not use tokio. Sorry, I missed that part; I was reading on my phone.
Yeah, was going to run them side-by-side. Different threads, most likely.
followed the doc and it says, I should use cargo-outdated and cargo-audit. Why is it such a big program, if it just checks if a version in the Cargo.toml is outdated? Updating crates.io index Downloaded cargo-outdated v0.8.0 Downloaded 1 crates (20.9 KB) in 1.31s Installing cargo-outdated v0.8.0 Downloaded failure v0.1.5 Downloaded env_logger v0.6.0 Downloaded tempfile v3.0.6 Downloaded backtrace v0.3.13 Downloaded humantime v1.2.0 Downloaded regex v1.1.0 Downloaded termcolor v1.0.4 Downloaded tabwriter v1.1.0 Downloaded failure_derive v0.1.5 Downloaded atty v0.2.11 Downloaded rustc-demangle v0.1.13 Downloaded backtrace-sys v0.1.28 Downloaded aho-corasick v0.6.9 Downloaded docopt v1.0.2 Downloaded utf8-ranges v1.0.2 Downloaded memchr v2.1.3 Downloaded thread_local v0.3.6 Downloaded regex-syntax v0.6.5 Downloaded synstructure v0.10.1 Downloaded strsim v0.7.0 Downloaded cargo v0.32.0 Downloaded ucd-util v0.1.3 Downloaded crypto-hash v0.3.3 Downloaded serde_json v1.0.38 Downloaded clap v2.32.0 Downloaded crossbeam-utils v0.5.0 Downloaded shell-escape v0.1.4 Downloaded opener v0.3.2 Downloaded crates-io v0.20.0 Downloaded tar v0.4.20 Downloaded ignore v0.4.6 Downloaded flate2 v1.0.6 Downloaded home v0.3.4 Downloaded filetime v0.2.4 Downloaded serde_ignored v0.0.4 Downloaded jobserver v0.1.12 Downloaded hex v0.3.2 Downloaded rustfix v0.4.4 Downloaded env_logger v0.5.13 Downloaded git2-curl v0.8.2 Downloaded rustc-workspace-hack v1.0.0 Downloaded bytesize v1.0.0 Downloaded unicode-normalization v0.1.8 Downloaded git2 v0.7.5 Downloaded curl v0.4.19 Downloaded smallvec v0.6.8 Downloaded globset v0.4.2 Downloaded ansi_term v0.11.0 Downloaded crossbeam-channel v0.3.8 Downloaded vec_map v0.8.1 Downloaded textwrap v0.10.0 Downloaded crc32fast v1.1.2 Downloaded curl-sys v0.4.16 Downloaded libgit2-sys v0.7.11 Downloaded crossbeam-utils v0.6.5 Downloaded socket2 v0.3.8 Downloaded libssh2-sys v0.2.11 Downloaded libnghttp2-sys v0.1.1 &amp;#x200B;
It was already mentioned that either the trait or the struct need to be in the current crate but you can actually restrict traits so that they can only be implemented by types that itself implement specific traits. ``` trait Foo : Send { fn bar(); } ``` This way, only structs, that implement send, can implement Foo.
CGI spawns a separate process for every single request, that is the death of any server hosting a moderately used web page.
Is the compiler able to detect situations in which races or deadlocks can be proven not to occur at compile time and emit code without atomics/mutexes as an optimization? The premise of my question might be wrong: My intuition is that such situations do exist (compile time provability), but maybe they don‚Äôt. And if they do exist, my intuition is that they are really hard to detect. 
It sounds like they spend a lot of effort reducing the version checking to Cargo's implementation. &gt;To retrieve the list of available SemVer compatible dependencies, cargo-outdated firstly creates a temporary workspace, then executes cargo update against it, finally compares the temporary dependency tree with the original one. &gt; &gt;Similarly, to check the latest dependencies, cargo-outdated replaces the SemVer requirements of direct dependencies with wildcards then goes through the same process.
Yeah that is true. But I haven't found a way by now to execute FastCGI except it is PHP on my hoster. Might talk to them about it.
Thank you will try that.
thanks. sounds plausible.
However, it's *great* for having a ton of very rarely used services. (I made a [socket activation based solution](https://github.com/myfreeweb/soad) for that, but I still kinda miss CGI.)
That's probably the route I'll take longer term. At the moment I've just been following along with some C++-based tutorials, so have data structures similar to those. Once I'm through them all, I'm planning to work on making things a lot more Rust-friendly. Not having to deal with (null)pointers has saved me a ton of frustration/errors already though, Rust is definitely a great choice for this sort of thing.
Often when I google stuff about Rust, the first result is content from the old book warning me that it is old. &amp;#x200B; Is anything being done to "SEO" this?
It's the one you told it to have, the entire lifetime of Foo. If you don't like the result then maybe don't do that?
when you write struct Foo&lt;'a&gt; { i: &amp;'a i8, } impl&lt;'a&gt; Foo&lt;'a&gt; { fn bar(&amp;'a mut self) { This means that the borrow lives as long as the lifetime of the Foo (because with your definition you have `Foo&lt;'a&gt;: 'a`). This is a mistake: bar should borrow self with a smaller lifetime. You do this by defining a fresh lifetime, like fn bar&lt;'something&gt;(&amp;'something mut self) { Or by letting Rust infer a fresh lifetime for you fn bar(&amp;mut self) {
Why are you downloading a hack?
Definitly looks very strange to me for such a simple task: Compiling serde v1.0.87 Compiling proc-macro2 v0.4.27 Compiling unicode-xid v0.1.0 Compiling libc v0.2.48 Compiling void v1.0.2 Compiling semver-parser v0.7.0 Compiling cc v1.0.29 Compiling pkg-config v0.3.14 Compiling memchr v2.1.3 Compiling cfg-if v0.1.6 Compiling matches v0.1.8 Compiling autocfg v0.1.2 Compiling failure_derive v0.1.5 Compiling ryu v0.2.7 Compiling regex v1.1.0 Compiling lazy_static v1.2.0 Compiling rand_core v0.4.0 Compiling ucd-util v0.1.3 Compiling openssl v0.10.16 Compiling utf8-ranges v1.0.2 Compiling crc32fast v1.1.2 Compiling percent-encoding v1.0.1 Compiling rustc-demangle v0.1.13 Compiling foreign-types-shared v0.1.1 Compiling unicode-width v0.1.5 Compiling bitflags v1.0.4 Compiling itoa v0.4.3 Compiling openssl-probe v0.1.2 Compiling same-file v1.0.4 Compiling quick-error v1.2.2 Compiling fnv v1.0.6 Compiling ansi_term v0.11.0 Compiling remove_dir_all v0.5.1 Compiling vec_map v0.8.1 Compiling termcolor v1.0.4 Compiling strsim v0.7.0 Compiling hex v0.3.2 Compiling bytesize v1.0.0 Compiling home v0.3.4 Compiling shell-escape v0.1.4 Compiling rustc-workspace-hack v1.0.0 Compiling glob v0.2.11 Compiling lazycell v1.2.1 Compiling crossbeam-utils v0.5.0 Compiling unreachable v1.0.0 Compiling libz-sys v1.0.25 Compiling openssl-sys v0.9.40 Compiling libnghttp2-sys v0.1.1 Compiling curl-sys v0.4.16 Compiling backtrace-sys v0.1.28 Compiling libssh2-sys v0.2.11 Compiling libgit2-sys v0.7.11 Compiling miniz-sys v0.1.11 Compiling log v0.4.6 Compiling unicode-bidi v0.3.4 Compiling rand_chacha v0.1.1 Compiling backtrace v0.3.13 Compiling rand v0.6.5 Compiling thread_local v0.3.6 Compiling crossbeam-utils v0.6.5 Compiling rand_core v0.3.1 Compiling rand_jitter v0.1.3 Compiling regex-syntax v0.6.5 Compiling foreign-types v0.3.2 Compiling textwrap v0.10.0 Compiling tabwriter v1.1.0 Compiling humantime v1.2.0 Compiling walkdir v2.2.7 Compiling smallvec v0.6.8 Compiling rand_isaac v0.1.1 Compiling rand_xorshift v0.1.1 Compiling rand_hc v0.1.0 Compiling semver v0.9.0 Compiling toml v0.4.10 Compiling serde_ignored v0.0.4 Compiling socket2 v0.3.8 Compiling rand_os v0.1.2 Compiling filetime v0.2.4 Compiling atty v0.2.11 Compiling num_cpus v1.9.0 Compiling fs2 v0.4.3 Compiling jobserver v0.1.12 Compiling quote v0.6.11 Compiling unicode-normalization v0.1.8 Compiling crossbeam-channel v0.3.8 Compiling serde_json v1.0.38 Compiling rustc_version v0.2.3 Compiling aho-corasick v0.6.9 Compiling tar v0.4.20 Compiling clap v2.32.0 Compiling syn v0.15.26 Compiling flate2 v1.0.6 Compiling rand_pcg v0.1.1 Compiling idna v0.1.5 Compiling synstructure v0.10.1 Compiling serde_derive v1.0.87 Compiling curl v0.4.19 Compiling crypto-hash v0.3.3 Compiling globset v0.4.2 Compiling env_logger v0.5.13 Compiling env_logger v0.6.0 Compiling url v1.7.2 Compiling ignore v0.4.6 Compiling docopt v1.0.2 Compiling failure v0.1.5 Compiling git2 v0.7.5 Compiling crates-io v0.20.0 Compiling rustfix v0.4.4 Compiling opener v0.3.2 Compiling tempfile v3.0.6 Compiling git2-curl v0.8.2 Compiling cargo v0.32.0 Compiling cargo-outdated v0.8.0
There is a chroem extension to redirect to the new book
Definitely not cloning or running *anything* from that repo. 
That's cool, but IMO not a good solution as most be people don't have that. It's not a good first impression.
Beware ~~nerds~~ spies bearing gifts.
Pretty much. 
The British gchq has some really useful stuff on github One of their tools I use the most is cyberchef! 
Shared hosting is in general a bit of a dead end. For super low end and boilerplate sites (very basic webshops and blogs) things are moving to fully-hosted solutions and for anything above that a VPS (5$ a month) is usually not that big an expenditure. Especially since it's pretty easy to cram a lot of unrelated things into the same VPS without getting a maintenance hell nowadays thanks to Docker.
why do you have to use this particular hosted? Heroku has a great free tier, no CGI mess required
That‚Äôs what I was looking for! Thank you very much
Because I mainly have wordpress blogs and they run on that hoster. Apart from that it has integrated email, enough unlimited databases and never sleeps like the free heroku tier.
Speak for yourself. I like Java and so do people at my company.
I prefer to have not to worry about the security and maintenance at all, cause I don't have the time for that. I currently have a Managed vServer so I might be able to make use of FastCGI.
Thanks - got it. Going through the course now. 
One of the packages being downloaded here is `cargo` itself, which has quite a few dependencies. If you check on [crates.io](https://crates.io/crates/cargo-outdated), there are only a handfull of dependencies. So I'd say the rest is mostly cargo's fault. I assume they are using `cargo` to do stuff like dependency renaming resolution and properly handling feature tags or something similar?
Rustup is the easiest way to install and manage Rust toolchains on a system.
So I don't remember what I search for, probably something like "Rust parse attributes proc macro", and most probably on Google. I tried using parse_meta() at first as well, hoping those special cases (such as TypePaths) would be a `Verbatim` variant but it failed. I'm pretty sure you can use Synattra as a back-end for darling instead, and that would be awesome! 
Well fair enough I guess. I don't know what your requirements are; if you have to manage a bunch of small domains with oddball requirements that are well supported by shared hosting control panels (email, ftp, db backups, other random crap) then I guess it would really help not having to manage that yourself. Just be aware the tech is all pretty old and that has some downsides.
You can also combine multiple constraints like this ``` trait Foo : Send + Sync { fn bar(&amp;self); } ``` Also you should be able to use functions from the `Send` and `Sync` traits (if there were any) on the self reference.
Yeah I know. I had fairly good experience with Go and CGI, the performance was actually decent and it ran fairly good. But yeah, I manage 9 domains (including subdomains) and have about 20 email addresses. And before I forget it, 8 databases. I really hope my hoster supports FastCGI, cause that would make Go even more performant and hopefully I can get Rust up and running.
&gt;An even better, more Rusty, descriptive name would be `MovableAcrossThreads` for Send and `BorrowableAcrossThreads` for Sync . But that‚Äôs not accurate: `T: Sync` is needed for shared borrowing across threads (`&amp;T`) and shared ownership across threads (`Arc&lt;T&gt;`). `T: Send` is needed for unique borrowing across threads (`&amp;mut T`) and unique ownership across threads (`Box&lt;T&gt;`). The difference is *not* borrowing versus moving. It's uniqueness versus sharing. For example, check out the difference in these impls for the two types of borrowed reference: [https://doc.rust-lang.org/1.31.0/src/core/marker.rs.html#586](https://doc.rust-lang.org/1.31.0/src/core/marker.rs.html#586)
Note that I'm using ‚Äúborrow‚Äù in the sense that it's used internally in the compiler (e.g. *borrowck*) and in the [reference](https://doc.rust-lang.org/reference/expressions/operator-expr.html#borrow-operators). In this sense, an `Arc&lt;T&gt;` is not a ‚Äúborrowed‚Äù type.
Kotlin is [bizarrely popular in Germany](http://pypl.github.io/PYPL.html?country=DE), which I haven't quite wrapped my head around.
I‚Äôm not aware of any such optimizations implemented by rustc.
What is problematic with tweaking parameters? If you refer to recompiling every time you change some value: it's easy to make a parameters file and deserialize into a struct (e.g. from toml). What is DRL?
Do they help the world get safer computers? 
it's... a book. Plaintext. The only even vaguely executable code there is the travis config. I'm assuming you don't use Tor or SELinux.
I am not British and don't really know what exactly gchq do. But this is an intelligence agency so one of their goal is to break into computer. Go Google it for more information. 
https://github.com/18F, part of the US federal government's General Services Administration
NIST uses Github, too. Example: https://github.com/usnistgov/800-63-3
&gt; To support Wayland, it's also a good idea to have a third channel, where the application will launch with pkexec/sudo ... I don't know the bigger picture behind what you're trying to do there but it sounds very much like a bad idea. Don't run your whole app as root. The whole idea behind polkit is that unprivileged apps talk over e.g. DBus to privileged helpers as separate processes. And threads and setuid() simply don't mix; setuid is process global. 
It will also panic when it's out of memory. So it's not just for bugs but also for some kinds of resource exhaustion. In general, you should panic if there's no way to continue the computation. This doesn't mean the program will quit: remember a thread can panic while others continue to do its stuff (and will have to cope with this panic somehow).
just do `"127.0.0.1".parse()?` and have whatever you're writing return a `Result`
Rust really needs a spec.
&gt; so it can be, for example, written to disk and (unsafely) loaded back without having to fix any offset up ...but please, only for caching data. I'm ideologically opposed to games with non-portable save formats and data formats where the loading logic has to account for two possible endiannesses for the input data. (eg. While it's not an endianness thing, the Windows and Linux releases of Megabyte Punch use different save formats. The windows version stores the save data separately, the Linux version embeds it within a config key within the Unity `prefs` file, and I haven't gotten around to figuring out what escaping or subtle difference in the schema prevented it from working last time I tried blindly copy-pasting the save data from my old Wine install to my newer native Linux install.)
It is not.
Itertools has [`.fold_while()`](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.fold_while) but it's been deprecated in favor of `.try_fold()` (perhaps prematurely since `Try` is unstable).
As /u/karroffel pointed out, it depends on the `cargo` crate (probably to avoid doing a buggy reinvention of things like feature flag handling and dependency resolution). I did a quick tally-up and nearly half of those crates (43 out of 111) are direct depencencies of the `cargo` crate (I didn't bother checking what those depend on in turn), so there's where your complexity is coming from.
I'm not sure how much their purview overlaps with the NSA but, generally, such agencies are also responsible for helping to protect the nation's information from foreign aggressors. As I remember, it was the NSA who made a change to the DES standard that took over a decade to be identified as hardening it against a cryptographic attack that was, at the time, not known to the general academic community.
You could import the variants with a rename to suit the semantics you want, but it might only serve to obscure the intent: use std::result::{Ok as Continue, Err as Stop}; iter.try_fold(0, |sum, x| if x % 2 == 0 { Continue(sum + x) } else { Stop(sum + x) } )
Alternately, you could do this: input.split("\n").map(|x|x.parse::&lt;i64&gt;().unwrap()) .cycle().take_while(|x| x % 2).sum::&lt;i64&gt;()
If you're using a recent compiler version (so your project is in 2018 edition mode), you can remove the `extern crate` line. This might already fix it.
As the disclaimer states it, this is only a Pre-RFC. I want you peeps to comment and provide feedbacks (I take both Reddit comments and GitHub commit comments) to enhance and, eventually, open a PR to have the best chances to have it merged quickly. Thanks and **keep the vibes**!
I updated to the latest version (1.32.0) thinking that might solve it. After removing the extern crate line I had exactly the same errors as before. Thanks for the suggestion anyway.
This is the subreddit for the Rust programming language. You're looking for /r/playrust
try use PROJECT_NAME:cli; instead of mod cli; mod cli declares "here is the content of the module cli" of the same crate. Create a [lib.rs](https://lib.rs) and out mod cli; into the [lib.rs](https://lib.rs) Then your project looks like: src/cli.rs extern crate structopt; use structopt::StructOpt; #[derive(StructOpt)] pub struct CliContext { .... src/lib.rs pub mod cli; src/main.rs use std::io::BufReader; use std::io::prelude::*; use std::fs::File; use cli; fn main() {. .. &amp;#x200B;
Nice blog. Hope you will keep us posted on the result of your 7DRL Challenge.
This also sounds like something that could work well with ECS. If the label is stored as an entity, the entity ID could then be easily copied to the other thread and then back again when the entity-component map needs to be accessed (in order to set the label).
I believe that what you're proposing is not technically "rank-N types", but rank-N trait bounds. After all, a direct translation of the Haskell example foo :: (forall a. (Show a) =&gt; a -&gt; String) -&gt; String would be something like fn foo(f: for&lt;A: Display&gt; fn(A) -&gt; String) -&gt; String i.e. the *type itself* has a `for&lt;&gt;` in it. That's not what your Rust examples show, and it would be rather difficult to implement since it would be incompatible with monomorphization. Assuming you did mean to limit this to trait bounds, it might be better to call the proposal "unrestricted higher-rank trait bounds" or "HRTBs for types" or something like that, since that's what it is; the current wording makes it sound like an entirely new feature that happens to share similar syntax.
In addition to updating the compiler, you'll have to add the following to your `Cargo.toml` under `[package]`: `edition = "2018"` 
You also have to add `edition = "2018"` to cargo.toml https://rust-lang-nursery.github.io/edition-guide/print.html#enabling-the-new-edition-to-use-new-features
I've wanted something similar in the past as well, but I don't think it is possible. You cannot implement a trait twice for the same type and \`Result&lt;A, B&gt;\` is basically a "subtype" of \`T\`. So everything that is implemented for \`T\` is also implemented for \`Result&lt;A, B&gt;\`.
Make sure you have `edition = "2018"` in your `Cargo.toml` as the behavior for derive macros from external crates seems to have changed between editions. After switching to rust 2018 I had to make some changes to your imports to get it working: diff --git a/src/cli.rs b/src/cli.rs index dcd40ae..5766c35 100644 --- a/src/cli.rs +++ b/src/cli.rs @@ -1,4 +1,3 @@ -extern crate structopt; use structopt::StructOpt; #[derive(StructOpt)] diff --git a/src/main.rs b/src/main.rs index b0f953b..93422bf 100644 --- a/src/main.rs +++ b/src/main.rs @@ -1,6 +1,7 @@ use std::io::BufReader; use std::io::prelude::*; use std::fs::File; +use structopt::StructOpt; mod cli; I'm not sure where exactly it's defined, but derive macros don't seem to get imported from external crates in rust 2015 unless the crate is declared in crate's root, moving your `extern crate` declaration to `main.rs` also fixes the problem.
I believe the standard way of doing this in Rocket is to use [`State`](https://api.rocket.rs/v0.4/rocket/struct.State.html). You can get access your data through request guards.
When I tried this the error changed to "no function or associated item named `from_args` found for type `cli::CliContext` in the current scope" That function should have been generated by structopt. Further it says: help: the following trait is implemented but not in scope, perhaps add a `use` for it: | 2 | use crate::cli::structopt::StructOpt; | which is kind of ridiculous since there clearly already is a "use"...
That seems of.. extremely dubious benefit? It's not like the proper version ordering is undocumented, and getting crate info programmatically is as simple as https://crates.io/api/v1/crates/rand and JSON. That seems like a lot of dependencies and work just for that.. Especially when `cargo`s version checking implementation is just [the `semver` crate](https://crates.io/crates/semver), a dependency of the `cargo` crate.
Yes, structopt is in the dependencies. This is why it works when it is all one file. The rest of your suggestions also did not work. When I tried use rgrep::cli; (the project name is rgrep, set as name under package in the Cargo.toml) it just said it couldn't find an external crate called rgrep.
Why would they have to handle feature tags or crate renaming or anything just to check if something is outdated on crates.io though? 
I copied what you posted and amended it: // src/main.rs use std::io::BufReader; use std::io::prelude::*; use std::fs::File; use structopt::StructOpt; use tes::cli; fn main() {... // src/cli.rs (no changes) extern crate structopt; use structopt::StructOpt; // src/lib.rs (create new file) pub mod cli; It compiles and runs here.
Thank you! this fixed it for me. These rules seem really weird to me though, I would never think to include a use in a file the compiler is not complaining about to fix an issue. There was not much help on this matter in the rust books either. 
deps.rs is an excellent alternative https://deps.rs/ eg: https://deps.rs/crate/regex/1.1.0
If you're goal is employment: 1. You should stick with Java. 2. It seems so as it's being adopted and seemingly outdoing Go when controlled for time-frame. 3. Yes, it is more difficult to learn than most other high level languages. There is simply more things to think about when programming in Rust which are automatically handled for you by high level languages. 4. I would recommend to stick with Java. And return to Rust when you'll be comfortable with common structures / patterns used in programming as a whole.
To do WASM you should be able to do JavaScript at relatively high level in regards to beginner. Not that WASM requires it by itself, but type of apps which would benefit from leveraging it are usually quite complex. And doing entire frontend in WASM is still not practically feasible at this point.
If I had time for learning another language that would be Kotlin. Seems like it was designed with developer experience in mind and elegant syntax.
RFCs tend to be titles with words I don't understand. Or rather, I understand the individual words, and that's it. Should I be worried?
This is a great writeup. Very detailed while also paced at a way not to be overwhelming! Thanks for letting us know about Quicksilver -- I was searching for 2d Rust game engines just months ago but never heard about it, and having an API that targets both Web and Desktop is definitely a goal for me. P.S. I thought artefact was a typo, and was going to let you know, but it seems to be valid UK spelling? TIL. &amp;#x200B;
&gt; AI &gt; Ethics &gt; Zen Rationality [Ummon](https://hyperioncantos.fandom.com/wiki/Ummon), is that you? In all seriousness, have any of the publications from the "Advanced Research" project been reviewed by any serious research body? I've seen this question [asked before](https://www.reddit.com/r/rust/comments/6ocm7g/announcing_new_algorithm_that_makes_functional/), but without a satisfactory answer. Has anything changed since then outside of more self-published "advanced research?"
Oh this is awesome! This is exactly what I needed and it's so noob friendly that even I understand it! :-) Can you give a rough estimation of when this will be released? I suppose it will be part of gtk-rs 0.6.0 ? 
/u/slsteele I was expecting an implementation of [Noise the crypto protocol thing](https://noiseprotocol.org) :D
Ah good idea! I will incorporate the README and example! Thank you
Thank you! I'm glad people find it useful! I will continue to work on this project
One thing to consider: if you just want to find a good project for learning purposes, the lack of a strong ecosystem in certain areas could actually be a benefit. Just find something that's missing from the ecosystem, and implement it. I don't know exactly what your goal is, but implementing a good Rust library that others will find useful to achieve something Rust didn't already have a library for seems like a good "real-world project" to me. In the long run, Rust seems almost undeniably a good choice for writing an OS kernel or programming a micro-controller, even if the ecosystem is currently a bit lacking, since few other languages can be used for that (mostly just C or C++). And the same is true to a slightly lesser extent for things like a game engine, browser engine, etc. &gt; I think something performance-sensitive may work. Have you written anything in a slower language that could use a performance boost? Rewrite either the whole project or only the performance critical parts in Rust. &gt; I also have the same issue with some other languages (like Haskell). This page seems helpful for Haskell: https://github.com/Gabriel439/post-rfc/blob/master/sotu.md (Haskell seems pretty great for writing parsers, for one thing).
Adding to what Holy\_City is saying, the `PUNICODE_STRING` contains a pointer to a `PWSTR` which is UTF-16. I think for correctness you would use `from_wide` from `std::os::windows::ffi::OsStringExt`. [Windows-specific extensions to the primitives in the std::ffi module.](https://doc.rust-lang.org/std/os/windows/ffi/index.html)
&gt; A device driver for Windows or Linux or macOS is a project where Rust would be the best choice. Of course, you should have a hardware device to drive. I would generally avoid writing Linux kernel modules in Rust (except for fun / proof of concept / etc), since it won't be merged upstream. But if it's something that can be done in user-space, Rust might be good. I can't comment of Windows or Mac drivers, which I know nothing about.
&gt;1. Should i drop Java/Spring and start Rust? In tech, the answer to should I learn X, is almost always yes. Sometimes I think the software engineering is one endless learning curve ;) &gt;2. Does Rust have a future? No know really knows the future, learning something is always a net positive so you win either way. &gt; 3. How hard is it to learn?(i only worked with Java which has a garbage collector and auto memory allocation) Rust has a certain learning curve, however it depends on many factors, such as ones prior experience/knowledge and learning rate. E.g some engineers are up an running in a week, others months or even longer. &gt; I am not thrilled by amount of resources i stumbled upon in my first 10 minutes of googling for them(Java/Spring seems to have infinite more), where would you recommend me to start(starting from zero) Rust is much newer then Java _(which is much older and established)_ ergo Java will have more documentation. However its not just about quantity its also quality. I've found documentation mostly adequate, there is also the wider Rust community which is one of the most friendly and helpful I've found. 
We'd need more information about the kind of management you want and the kinds of servers you have. You are also likely to receive a better result asking in /r/playrust
No, you should not be worried. :) RFCs affecting the type system often use words from type theory and related fields which are pretty confusing to anyone who doesn't work in those fields. The Rust language team does a great job of finding ways to then package these ideas into language features that are much more easily understood by "regular" software engineers without a type theory background. In fact, you'll notice in most (all?) language-related RFCs a section titled "how do we teach this"? I struggle to follow a lot of the language especially around the core of the trait system in RFCs, but by the time I'm using the result of that work, it seems almost miraculously clear and comprehensible. You can rest assured that a guiding principle of the Rust language design is that everything possible should be done to make powerful concepts accessible to mere mortals. It's even in their slogan now: &gt; "Empowering everyone to build reliable and efficient software." Type theory talk is still super-dense to me, but I know that Rust has my back. :)
Management , maybe Acess the Server By RDP and Control It modify it and own it. My currently servers are dayz. Arma 3. CoD Servers. Rust seems such a fun game. 
Where I work we consider OOM as a bug, as it is usually a sign of a memory leak. And yes - [these can happen in memory-safe languages, too](http://thecodelesscode.com/case/209). Same for FD exhaustion, and other resources - this is something you need to debug. And if there is no sensible way to continue the computation, then either something is wrong with the input - in which case you should return a `Result` - or something is wrong with the code - which means you have a bug. And of course other threads can continue. Having the program crash in case of a bug is not a hard requirement (unless you are running tests). Having the program emit a notification of some sort in case of a bug, with as much information as plausible, should be a requirement - and that's what a panic does, even if it's caught with `catch_unwind` or `JoinHandle.join`.
r/playrust
Could you elaborate on why? Genuine question. I understand what a spec is and the touted benefits. Please correct me if I'm wrong: - easy availability of all features listed in one place - serve as the gold standard to describe behavior - allow ease of alternate compiler implementations - easy reference for plugin/crate development As someone who just heads to the source code of a language when I want to understand some feature, is my understanding of the need for a spec correct?
Step one: Avoid FFI.
Is it Safe Rust and Unsafe Rust?
Agreed. Maybe a better example would be sharing a complex read-only data structure over shared memory to another process in a way that the consuming process can directly work with ,even though it has a different address space. Or just that on 64 bit architectures, sometimes slimming pointers down in a few critical places can make a difference regardless of the "position-independence" property (that's the original motivation in the linked video). 
It must be a different Germany from where I live, as I never saw it used outside Android projects, specially since most Java enterprise shops usually use Eclipse for JEE and Spring projects.
I want to do that too! However, the closest thing I tried usable is `piston`.
Liar OMG
I'm not an expert on this sort of thing, but `setjmp` and `longjmp` are very much "Do not use unless *absolutely* necessary" (eg. Lua API) things in Rust. Barring everything else, they're to regular `unsafe` as `unsafe` is to safe rust, because it's so easy to break language invariants by misusing them, causing undefined behaviour. The unpredictable exit code makes me suspect you're corrupting your memory somehow. Even Microsoft's [MSVC documentation](https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/longjmp?view=vs-2017) lists a non-trivial list of restrictions for when it's safe to use them in C++ code, and that's with Microsoft having explicitly addressed the intercompatibility between C and C++ on that front. The [discussion around an example of using them from Rust](https://www.reddit.com/r/rust/comments/991joh/an_example_showing_how_to_access_setjmp_and/) specifically mentions the example as not working on Windows and, according to one of the comments on [this issue](https://github.com/rust-lang/rust/issues/48251), they had to roll back an FFI safety mechanism (abort on panic unwinding across FFI boundaries) because the Windows implementation of setjmp/longjmp uses the same underlying platform-level exception mechanism that Rust also uses for panics and it was catching setjmp/longjmp attempts.
Idiot OMG
&gt; Don't run your whole app as root. The whole application is not running as root. Only the privileged thread spawned at the beginning of the application is running as root, while the main thread is running as the user who spawned the application. This is required for an application to spawn on Wayland, as Wayland does not allow the main thread to be root. If the main thread were root, GTK would fail to initialize. &gt; And threads and setuid() simply don't mix; setuid is process global. As the comments in the code pointed out, while the behavior of `libc::setuid()` does apply to all threads which belong to a process, this does not apply for invoking the `setresuid` syscall directly. That applies on a per-thread basis.
Very nice abstraction! I like the way the shader program is modeled as a trait with methods representing the stages. Might look at this some more later.
Actually, I would almost say the opposite should be encouraged. Not in standard Rust, but as a means to get people working in Rust and out of whatever unsafe language they‚Äôre currently working in. Think of FFI as the mechanism to implement the strangler pattern on C or C++ libraries. Over time the entire library can be rewritten, but while that‚Äôs happening all development outside the library can happen in Rust.
Did you try implementing the Friends trait? Let me give you an example: `impl Friend for ThisIsTheWrongSubReddit { fn hahayeah(&amp;self) { println!(‚Äúyou‚Äôre looking for r/playrust‚Äù) } }
This is a subreddit for Rust the programming language. Try /r/playrust instead.
Incremental improvement is solid! I am also in favor of exposing crates as object files for linking with existing C/C++ projects.
The compiler error gives a clue of what is going on. If any n-level reference type `...&amp; A` (no matter how deep) implements `T` then it gives the implementation of `T` for `A`. However that doesn't make sense because an m-level reference type, n‚â†m, could also provide the implementation of `T` for `A`. The compiler couldn't figure that out. Sometimes type-related stuff is *not decidable* and the compiler has to either crash or hang. It's analogous to asking for the last digit of pi. It would be helpful if Rust could, as a special case, only consider *one* level of reference. By thoughtful magic, it actually does do that. Simply omit the blanket implementation and Rust will apply the implementation of `T for &amp;A` for you. Rust dispatches method calls at compile time by searching for a *method* which can accept a `self` variable of type: - `A` - `&amp;A` and `&amp;mut A` - If `A` can be dereferenced, repeat all steps including this one for the type `&lt;A as Deref&gt;::Target` During method dispatch it doesn't check the type named in the `impl` block. It checks the type associated with the method. (This can be a confusing gotcha if you call `.clone()` on a reference-typed variable because `&amp;T` implements `.clone()` with the signature `fn(&amp;&amp;T) -&gt; &amp;T`. Same for a reference-counting shared ownership pointer: `fn(&amp;Rc&lt;T&gt;) -&gt; Rc&lt;T&gt;`. As a point of style, I use explicit typing when calling `.clone()`.) Naturally, if matches are found for both `(&amp;x).foo()` and `(&amp;mut x).foo()` the compiler will throw an error.
Thank you, this is leading me to a slew of resources I didn't know were there, this could prove very useful!
What you most likely want is type `&amp;'b mut Foo&lt;'a&gt;` - lifetimes (plural) chosen by the caller. 'a is the lifetime of borrowed data on which Foo depends. 'b is the lifetime of the method call. The implementation allows you to call `bar` on the type `&amp;'b mut Foo&lt;'b&gt;` for any lifetime `'b` chosen by the caller. You've bound the two lifetimes together. At the impl block this combined lifetime is called `'a` but don't be confused - it's almost exactly the formal vs actual parameter distinction. The 'a in `struct Foo&lt;'a&gt;` is also a formal parameter. (To be more precise `impl&lt;'a&gt; Foo&lt;'a&gt;` means "implement, for any lifetime 'a, methods of Foo&lt;'a&gt;" - `'a` is a 'universally quantified' type parameter. When you make a specific use of `Foo`, the borrowck uses this universal implementation to check a specific use case. ) Now, 'b is probably within 'a. We'd write `'a: 'b` and that means `Foo&lt;'a&gt;` can be safely upcast to `Foo&lt;'b&gt;`. Making a lifetime shorter places a stricter limit on where a value can be used so that's okay. This is similar to upcasting with a trait. If `Foo&lt;'a&gt;: Debug` can be upcast to `dyn Debug + 'a` However `&amp;mut` references do *not* allow the compiler to freely upcast a lifetime in the target type. The details are subtle, so don't worry about them right now. But to simplify it, a `&amp;mut` reference allows you to put things inside the target. If `T` can be given an arbitrarily short lifetime, you can use `&amp;mut T` to put something inside it with a short lifetime. Then when the `&amp;mut` borrow ends, the `T` will contain an invalid thing that has escaped it's lifetime. The important thing in this case is that the implementation of `bar` probably does *not* require that the two lifetime parameters be identical. So you shouldn't bind them together You only need fn bar&lt;'call&gt;(&amp;'call mut self) where 'a: 'call which is such a common pattern that it can and should be abbreviated as fn bar(&amp;mut self) 
This is a really awesome idea. A push towards writing more secure code will benefit all, consumer and producer alike.
A more snappy title to make this understandable to people plus highlight the main use case: **Generic closures**. As a matter of framing, that is less general, of course, but it makes more intuitive sense. I have sometimes the need for this feature. Not very often, but when I do, man do I miss it. It's funny that you can already circumvent the limitation using associated generic functions on traits, so I don't think this wouldn't even bring fundamentally new expressivity „Éº only convenience, which makes it an even stronger case.
Thank you for this. ZeroMQ is such an awesome piece of technology. Your API looks nice, too.
It will be, but it's more work than just "enabling" it. There are more changes to the underlying type checking which need to happen before we can have this. In short, the compiler doesn't have the functionality necessary to correctly type-check with `impl Trait` in traits. When that functionality is implemented, the design will need to be solidified, and then stabilized. We will definitely be able to do this eventually, but it will probably be a while. --- I'm not sure how to explain the actual issue with it without diving into lingo, but this depends on what's currently being called "existential types". The current design will be for traits ho always declare an associated type (`type ParserOutput: TraitBound;`), then have the function return that. The `impl` block will then be able to use `existential type ParserOutput...` to declare the return type without naming it. The main rationale for doing it this way is to have as many types nameable as possible.
impl Trait in trait methods is unlikely to ever be a thing because all trait implementations have to return the same concrete type and you're not declaring which one is being returned for the actual implementations to target that. Theoretically we could try unification on all the impls and if there's a mismatch, throw an error, but non-local type errors like that are bad.
It gives you a good understanding of the basics depending on how far you take it. But modern engines are quite advanced. 
Gender isn‚Äôt politics 
Also for some domains such as crypto, it can still be better to use the "battle tested" C implementations since getting things right can be really tricky. Rust does help to make things _safe_ but _secure_ is whole different ball game.
+1. Standard Chartered's Haskell compiler uses monomorphization and hence doesn't support higher rank types, unlike GHC. [[source](https://www.reddit.com/r/haskell/comments/46lux3/monomorphization_good_or_bad_idea/d080npi)]
I'm sincerely sorry. That was a very poor choice of words. I've retracted that from my post.
"If your business isn't politics, don't put politics in your business."
Where to look for Rust jobs?
I'm not sure what the parent post means, but in general you need a spec to determine if an implementation is correct (according to the spec)... otherwise all you can say is it does what it does. This is what happens when you don't document code, for instance. Presumably parent would like a formal spec for rust so that parts of rust (it's safety properties I guess) could be formally verified. But I don't know much about that.
Can you explain or give examples of ‚Äòeffects system‚Äô?
This is my first time coming across quicksilver. I'm supposed it's not part of areweguiyet...
Appropriate descriptive pronoun for a crab would be "it".
Do you feel like this would make a difference? I guess it's hard for me to get in the mindset of someone who would find the specific phrase "gendered pronouns" so offensive that they would quit Rust, but would broadly still be OK with using singular "they" as a pronoun. To put it another way: if this one sentence makes them think Rust is a language for SJWs, wouldn't the code of conduct elicit an even stronger reaction?
&gt; But I've been faced with the same response probably half a dozen times (paraphrasing): "Sounds like Rust is just a language for social-justice warriors" as soon as they get to that page. I'm not sure the kind of people that talk like that would (or should) be welcomed in the Rust community.
I can only hope. I only have my experience to go on. I'm not sure it's that these people find it i offensive. I "think" they just find it jarring and I guess it makes them feel like it's not a serious programming language? I think the code of conduct is exactly where this should live. I would expect the code of conduct to cover this - for sure! But on the getting started page, it's just misplaced. I would guess they would never read the code of conduct until they needed to so they could fall in love with the language first, before knowing how to interface with the community. But they all read the getting started page, because that's the entry point to the language. That's what I think anyway. I hope that what I've suggested would help, but I'm not sure.
Everyone starts on a journey. And seeing as though it's meant to be a welcome place for everyone, I disagree.
No safe, no secure.
This is really a ridiculous concern and I'm not at all interested in catering to people whose engineering decisions are completely clouded with idiocy about "social justice warriors"
I echo everything here. Java will get you a job and it‚Äôs a good thing to be good at
It's very real. I debated about making this post because I understand your concern. Rust is a language first - if the website was a reflection of that, some barriers could be broken down. The people I mentioned in the original post are all great people and I love and respect them for who they are. I just want them to experience and love Rust the language first, everything else can come later.
If the people you are trying to introduce to Rust use "SJW" unironically, they are a problem, not the Rust website. And that's being generous with this post, which is most likely just concern trolling.
I don‚Äôt think it‚Äôs the gendered pronouns that‚Äôs the issue, but really, for a *crab*? The only acceptable pronoun for a crab is it.
I don't really know what to say. I'm sad that you've just dismissed a genuine concern with "trolling" as your argument. I love Rust and want it to do well. I want to share it with as many people as I can and I've had some (admittedly small) trouble doing so. I'm sorry that you feel the way that you do. I don't like offending people. Especially those that have helped me personally quite a lot on the past.
Engaging in people skills is a foremost part of being in the Rust community. It's really just a cloying waste of time to try and make those who seek to completely forgo using those skills feel more welcome, and someone (myself included, being nonbinary) will have to pay for it eventually when they're accepted and catered to unconditionally. 
Having zero personal skills is a big reason I felt programming was so approachable when I was younger. I beg to differ. To your other points, if the appetite to change the website isn't there, than I am the one in the wrong and I am sorry. Thank you for the discourse nonetheless.
For a programming language you are totally right, those things don‚Äôt really belong there. *But*, Rust is not only a programming language. Rust is *also* a community. And that sentence is there to show that this community is welcoming for everyone and I don‚Äôt think that‚Äôs a bad thing.
I think if even the mildest inclusiveness strategies bother you, you're not the kind of person I want to work with. I understand the irony of that sentence, but that's the paradox of tolerance. We have serious issues with inclusion in this industry. If making it clear that a mascot is a-gendered can create a tiny quantum of reassurance for someone who is affected by gender issues, then its value far outweighs the cost of excluding people who are bothered by it. Frankly it's stuff like this that creates a great smell test for the folks that cause problems. If someone says "it's just for social justice warriors" that's a red flag to me. Just like people who get upset at codes of conduct. It tells me more about the person who is upset than anything. 
Tbh personal skills is something we're all working on daily. For me, what separates people is who is willing to grow and create better community connections between each other, and those who refuse to do so. "Social justice warrior" is a large red flag for me for people, showing they'd rather not change to improve their relationships with others. Not having skills is very different from this mentality.
If seeing "gender neutral pronouns" is enough to make someone not use a programming language, that's a pretty good indication of their acceptance of trans people and their ability to make a welcoming space.
[Here's the Wikipedia page for Sebastian, the crab in The Little Mermaid](https://en.wikipedia.org/wiki/Sebastian_(The_Little_Mermaid)). Whether "acceptable" or not, it's pretty common to use personal pronouns for animals. I don't call my dog "it." Anyway, if *this* is the issue then that's even weirder and more petty than I thought. "I was interested in this programming language but they did not refer to their cartoon crab mascot as 'it' which is *the only unacceptable* pronoun for their cartoon crab mascot. Je refuse!"
I thought this was going to be rust code which transpiled to GLSL, maybe I should write that...
I understand. I know these people personally. They are not bad people. I don't think they've used it in that way, or have that mindset, but I can definitely understand how it would seem like that.
Where are you getting the idea it's meant to be welcome for everyone no matter what? There are all kinds of things that shouldn't, and aren't, welcomed. Spambots, trolls, people in general violating the [code of conduct](https://www.rust-lang.org/policies/code-of-conduct). Just because it amounts to "be nice or get out" doesn't mean everyone is welcomed. Sometimes people aren't nice. Further, starting on a journey would mean, well, actually starting one? Not the journey itself changing to suit them. In this case that would mean getting over the existence of the words "they" and "them". I suspect someone who has a problem with something as simple as "address people/things how they want to be addressed" may need to progress a bit more before joining our community. Even if you/they think it's weird for the crab to have pronouns, who cares? Does it matter? Does it really affect anything? What kind of hill is that to kill a programming language on?
Thank you for this explanation. So do I understand correctly that that associated type would be implicitly generated by the compiler? As in, for each trait function that returns an `impl Trait`, an associated type implementing the trait would be declared and in the `impl` set equal to whatever the concrete type returned by that function's implementation would be? Not sure if I'm making that clear, but basically, this will all be transparent to the user unless they have some particular need to reference that type? Or do I misunderstand?
It's a cartoon crab mascot, it's not like it's uncommon for mascots to have genders and names and stuff. Someone should tell [sports teams their mascots](https://en.wikipedia.org/wiki/List_of_National_Football_League_mascots) don't belong, with their silly "names" and "genders". Get outta here [Poe and your "brothers"(is it "its" or what?)](https://en.wikipedia.org/wiki/Poe_(mascot))
100% agree. It's a crab mascot, who cares and why? What kind of thing is *that* to make an issue out of? Having a problem with something as trivial as that says a lot.
I mean, what's the game plan here? Hide the gender stuff in a less-viewed page, so people fall in love with the language first, and then by the time they see the code of conduct, *BAM* it's too late, they love the language, they are in too deep, muahaha! Jokes aside, I find this kind of bait-and-switch to be pandering... But I also think it's ineffective. People don't develop &amp; challenge their opinions because a programming language's website is written one way or another; people develop opinions primarily due to the influence of friends and family. Really a much more effective intervention in this circumstance is for you to have some potentially awkward conversations with your friends. I mean you can lighten it up with some humour. "A 'language for social justice warriors' what does that even mean lol? My dude this shit right here guarantees memory safety." "You may not like that line about their mascot but it doesn't mean it's not a serious language. Dropbox is using it in production!" "IMO it's pretty dope that they put this much thought into their mascot, who is also super adorable. Anyway, whatever, have you seen this shit? It guarantees memory safety."
Hey, thank you. I think you are right.
Dogs and personal pets are different, they get gendered naturally. They still do not get personal pronouns, nobody goes ‚Äúmy dog prefers to go by they/them‚Äù because that would be idiotic. Note that I don‚Äôt necessarily agree, I‚Äôm just trying to see the other point of view. I don‚Äôt think anyone would be instantly turned off to the programming language(a straw man), but it might raise some questions about the team/their politics behind the language. Like ‚Äúwhy is a crab being given personal pronouns, when it makes literally zero sense?‚Äù.
You only have a minute of someone's time. You shouldn't put anything on the website that doesn't help promote Rust. It's basic advertising.
My question is related to references. In some examples, when you want to iterate over a vector and you don't want the for loop to borrow the vector, it is written as for elem in &amp;elems { access elem } while in other examples I have seen it as for &amp;elem in elems { access elem } Is there any difference between the two? I read them both the same to mean that elem is a refence, but can't figure out what the exact difference is between the two syntaxes. Thanks!
My understanding is that `-&gt; impl Trait` will _never_ be allowed in trait definitions. The current plan will never allow this code to be written: trait Parseable { fn parser&lt;I:Stream&gt;() -&gt; impl Parser&lt;Input=I, Output=Self&gt;; } I interpreted your question as asking whether this will be possible, though, which it will be. The following will be exactly equivalent: trait Parseable { type ParserOutput&lt;I&gt;: Parser&lt;Input=I, Output=Self&gt; fn parser&lt;I:Stream&gt;() -&gt; Self::ParserOutput&lt;I&gt;; } impl Parseable for X { // synax for this line not fixed: existential type ParserOutput&lt;I&gt;: Parser&lt;Input=I, Output=Self&gt;; fn parser&lt;I: Stream&gt;() -&gt; Self::ParserOutput&lt;I&gt; { ... } } This still has the main advantage of `-&gt; impl Trait`, which is that you don't have to write out the type of whatever `parser` returns (so it can be arbitrarily long and complicated and have closures in it). Something like this would need both GAT (generic associated types) and existential types to implement, but I only mention existential types since I think GAT will be coming first (they're also needed for async functions IIRC, and that's a pretty high priority). 
Actually the opposite might be interesting too, taking SPIRV and compiling it to a trait implementation compatible with this.
It's not part of the current plan, but we could turn `-&gt; impl Trait` into an associated type automatically, right? The following is already valid rust: trait Parseable { type Output: Parser; fn parser() -&gt; Self::Output; } It's just that we can't then implement `Parseable` without naming the exact type that `Output` is.
&gt; Side note, you linked to a fictional character in a film which is different imo, but he still doesn‚Äôt have personal pronouns. That‚Äôs not what I was talking about. I'm genuinely curious, what's the difference? Ferris is also a fictional character. Or is it the "in a film" part that's the distinguishing feature? Also it seems like we're using the term "personal pronouns" differently. The Wikipedia page uses "he" to refer to Sebastian; is that not Sebastian's personal pronoun?
This is a subreddit about the Rust programming language. I've removed your post to spare you further embarrassment. Next time, please read the info before posting.
&gt; that's a pretty good indication of their acceptance of trans people and their ability to make a welcoming space. It's also a good indication that dealing with their bullshit will consume more time and energy than it will provide.
Crabs are a very popular food where I'm from, so I'd accept "yum" too! :-P
Maybe I‚Äôm using the terminology wrong; but an animal has a sex. We can‚Äôt go ‚Äúit prefers to be called this‚Äù because animals can‚Äôt communicate that with us. Humans can go ‚ÄúI prefer to be called this or that‚Äù, which is totally fine. But it, naturally, gets a bit blurry with fictional characters. The crab from the Disney film is animated and has a personality. For all intents and purposes, he is a human but the film was under the sea so anthropomorphic animals were used instead. And it‚Äôs just Disney‚Äôs thing. He‚Äôs decently fleshed out in the film and interacts with other people in the film. Ferris is a glorified branding logo, isn‚Äôt it? For a programming language. It wouldn‚Äôt make sense to put stuff like ‚ÄúFerris prefers coffee to tea‚Äù‚Äìit‚Äôs just not relevant on a page aimed at newcomers trying to learn about the language. To me, personally, it feels really forced to say ‚Äúwe refer to Ferris with they/them instead of gendered pronouns‚Äù.
In 2015 edition all `use` imports go from root. This means that since you write `extern crate structopt` in cli.rs then you must import it as `use cli::structopt` (or `use self::structopt` inside cli.rs module). In 2018 edition all imports start from external crate name or one of `crate` (this crate root), `super` (parent module), `self` (this module).
I did for a bit, but sadly I've become quite addicted to modal editing (in particular kakoune) and when I last tried it the advantage wasn't worth using IntelliJ. Probably unfair of me to compare to Java's IntelliJ support then, though. I use it then just because Java's pretty impossible to use without good editor support.
I tried to set it up when it was first announced, but got stuck with some incompatibility with [kak-lsp](https://github.com/ul/kak-lsp) (or my doing something wrong). Probably worth retrying, though! Might make that my project for tonight.
It's like having a well documented API, with all the benefits that that provides. Doesn't mean that you never have to go into the source code, but it does make things easier for the cases you describe.
["Personal pronoun" is just a grammatical term](https://www.merriam-webster.com/dictionary/personal%20pronoun); "personal" as in personhood, not personal preference. "I" and "we" are personal pronouns. Anyway, at this point we're speculating about the intentions of OP's friends based on a message that has been deleted so... I don't anticipate being able to actually get to the bottom of their issue. For my perspective, I got into programming through irreverent texts like "Why's (Poignant) Guide To Ruby" and "Learn You A Haskell For Great Good," so an unusually specific characterization of a mascot like "Ferris only drinks the finest espresso" doesn't phase me at all and if anything makes me a little happy. But I understand that not everyone will react the same way.
Under the section ‚ÄúCommon patterns that may cause panic‚Äù, ‚Äústring formatting using format!‚Äù is mentioned. Would someone mind giving an example of this? I find it quite strange that this could panic
Items 2) and 3) on your list. Basically Rust right now is whatever the implementation says it is, with a spec we can argue about it without having to read and write code.
It isn't literal `move`, but using `&amp;` in the match pattern does this, right? Like let x = &amp;Some(10); match x { Some(&amp;var) =&gt; { // var is copied/moved here } None =&gt; ... }
There are constantly improvements coming that I hadn't even realized I wanted so much. Of course in retrospect, not having this has been a subtle pain for a long time. nifty
OK, but this "how we teach this" makes little sense. I get generics, but I don't know why this rfc is needed. If there were examples with other generic types, that'd be great. Off the top of my head: say you had a hash map and you generically want to see if it has some key and then convert it to a string. Is that a use case of this? I think you'd need `Fn(hm: Map&lt;A, B&gt;, str_fn: T) -&gt; Option&lt;str&gt; where for&lt;B&gt; T: Fn(B) -&gt; str` and that's rank 2? I guess one can induct on the number of hash maps that are nested for rank N? 
Still, with everything else that's been said, and regardless of the community-building efforts, I agree that it feels odd to give that degree of prominence to it. ...but what do I know. I'm one of those people who sees pseudo job titles like "code ninja" and "rockstar coder" as annoying and ineffective attempts to "market" employees into being happier.
Just chiming in to say massive thanks for both the write-up and pointing out that Quicksilver exists.
To be honest, I think I know what webdevnomad is trying to get at and I agree with it. If it was talking about the welcoming and inclusive community, that'd be professional and I'd feel good about that. Communicating that in this manner feels weird and, if it were my first impression, I'd be worried about how they might react to honest mistakes. RationalWiki has a good passage on the topic of [identity politics as a vehicle for oppression](https://rationalwiki.org/wiki/Identity_politics#Identity_politics_as_a_vehicle_for_oppression) which explains the basis for that sense of concern: &gt; Its chief political victories resemble this; "speech codes" and other new forms of etiquette are some of its more conspicuous successes. In essence, identity politics is constantly generating new forms of etiquette. But, since the function of etiquette is to perform social status and rank, and all etiquettes create an underclass of the rude and uncouth[18], identity politics constantly undermines the egalitarianism it aspires to in theory, and as such tends to exaggerate class resentments the more rigorously its new etiquettes are enforced. &gt; &gt; Social constructionism invites us to believe that we can change the world by using different words. As such, building on its postmodernist tendencies, identity politics as an academic exercise generates a great deal of jargon. This obscurantist approach comes at a price, however ‚Äî deconstructionists have been criticized for constructing elaborate systems of such jargon which seems indistinguishably like a device for wrapping empty ideas in the appearance of sophistication. 
This will likely attract a new batch of rust enthusiasts. A lot more than the last tweet, as his first good impression seems to have be confirmed. I am curious of what will john‚Äôs first crate be. Anyway, good for rust, good for r/rust_gamedev 
Looking forward to seeing something written in Rust by Carmack. 
Probably a good idea to quantify that as "seeing *gratuitous* gender neutral pronouns". I won't bat an eye at seeing a community member who prefers gender-neutral pronouns, or a CoC that mentions them, but giving prominence to the gender of a mascot in that manner is off-putting because it's the kind of thing that often indicates [identity politicians signalling to the in-group defined by the ability to keep up with the jargon](https://rationalwiki.org/wiki/Identity_politics#Identity_politics_as_a_vehicle_for_oppression).
As your percentages sum up to 100%, this is simply not true. cargo is fine for simple things, as are additional Makefiles, but not for a more complex project. See also the previous discussions e.g. [here](https://www.reddit.com/r/rust/comments/anllbi/on_possible_futures_of_meson/efv32yg/) and [here](https://www.reddit.com/r/rust/comments/anllbi/on_possible_futures_of_meson/efv32yg/).
Not to mention that, as I elaborate in [this reply](https://www.reddit.com/r/rust/comments/ap0h5m/small_concern_about_the_website/eg58rac/), it can actively hurt rust because it resembles the warning signs of a community that is caught up in identity politics an has developed an "in-group" who are superior because of how well they keep up with the latest in rules about what to say and not say.
I get the impression that you're struggling to put words to something you have a solid but non-verbal understanding of. Does it overlap with [my post](https://www.reddit.com/r/rust/comments/ap0h5m/small_concern_about_the_website/eg58rac/)?
Well said. That feels like a significant quote but Google gives me no results when I look for someone to cite. Are you paraphrasing?
A quake 3 port would be great. It has always been one of my favourite c codebases, so cleanly written but without being a toy project.
The problem is that this particular means of expressing that (as opposed to, say, just talking about the welcoming and inclusive community) resembles warning signs that a community may be devolving into an in-group/out-group split based on how well one can keep up with needlessly complex rules of etiquette. RationalWiki has a great little snip on how identity politics tends to develop that which I quoted and summarized in [this post](https://www.reddit.com/r/rust/comments/ap0h5m/small_concern_about_the_website/eg58rac/).
I suspect webdevnomad was trying to express something like [this](https://www.reddit.com/r/rust/comments/ap0h5m/small_concern_about_the_website/eg58rac/) but lacked the words to do so.
Fair enough, you are right about RLS being not great. IntelliJ does have a vim plugin too, absolutely no idea how good it is compared to the real thing though. All I know is my colleague (who uses a browser with vim keybindings) is happy enough writing scala in intellij's vim mode.
Yes, there's a difference between them. ``` let vec_a: Vec&lt;i32&gt; = vec![1, 2, 3]; for elem in &amp;vec_a { // elem is &amp;i32 println!("{}", elem); } for &amp;elem in &amp;vec_a { // elem is i32 println!("{}", elem); } for elem in vec_a { // elem is i32, and the vector is moved / consumed println!("{}", elem); } let x = 10; let x_ref = &amp;x; let vec_b: Vec&lt;&amp;i32&gt; = vec![x_ref]; for elem in &amp;vec_b { // elem is &amp;&amp;i32 println!("{}", elem ); } for &amp;elem in &amp;vec_b { // elem is &amp;i32 println!("{}", elem ); } for &amp;&amp;elem in &amp;vec_b { // elem is i32 println!("{}", elem ); } for elem in vec_b { // elem is &amp;i32, vec_b is consumed println!("{}", elem ); } // This will not actually compile, as we're using vec_b after move for &amp;elem in vec_b { // elem is i32, vec_b is consumed println!("{}", elem ); } ``` In more abstract terms, you can think of `for elem in elems` as being `for &lt;pattern&gt; in &lt;expression&gt;`. The variable name with a `&amp;`-prefix is a [reference pattern](https://doc.rust-lang.org/reference/patterns.html#reference-patterns). An expression prepended with `&amp;` creates a reference to it, so `&amp;elems` creates a `&amp;Vec&lt;i32&gt;`. The vector reference is converted into an iterator using the `into_iter()` method of the `IntoIterator` trait, which in the case of `&amp;Vec&lt;T&gt;` creates an iterator yielding `&amp;T` references. When `elems` isn't a reference (and is therefore moved), the iterator yields normal `T` values without a layer of indirection. So the TL;DR/ELI15 is that `&amp;elems` makes the loop iterate through the vector by reference, instead of consuming it like it normally would. `&amp;elem` dereferences the element.
True... though, as long as you stick a header on it which you can use to do a quick "is this cache loadable on our arch or do we need to regenerate?" check, it'd also work as a way to stream loaded and processed data to disk to speed up future loads. (I'm not sure where that would bring performance benefits in a game's own data, but I know that video drivers implement shader caches for similar reasons.)
Would this feature solve the author's complaint in this piece of code?: https://github.com/bisqwit/password_codecs/blob/master/solarpass.rs He's complaining about Rust not supporting generic closures. He's a youtuber who makes programming videos, and the code is featured in https://www.youtube.com/watch?v=6zyub-c1X3c.
Yeah it's not as well known than ggez or Amethyst. I've always thought of it as a game engine than a GUI thing, though. It's more about drawing shapes and images than buttons, windows, text input, etc. It is in arewegame yet: http://arewegameyet.com/categories/engines/#quicksilver
I've tried IntelliJ's vim plugin but I'm still too used to kakoune's command style - and it's just different enough from vim's to make it hard to switch between them. I'm sure it's great to use as a vim user, though! I could definitely learn vim, and if I need ro, but at the moment I'm being lazy with regard to learning editors. There are definitely similarities between vim and kakoune, but the differences, mainly action-&gt;text selection in vim vs selection-&gt;action in kakoune, aren't trivial.
Ah I see, when you said "modal" I immediately thought you were talking about Vim. Time to write a kakoune intellij plugin then ;)
Thanks! There's a few things coming up that may prevent me from participating. But if not, I'll keep you posted for sure :-). Hope others will do the same. Rust is pretty well-positioned for a 7DRL language these days.
They are fairly similar :) I definitely need to get on that, though. A kakoune intellij plugin would be nice to have!
Threads are not a reliable security boundary; because all threads share an address space if *one* thread of your application is running with root privileges, other threads can quite easily hijack the privileged thread and use its privileges. It can prevent *accidental* use of root privileges on your non-privileged threads, and put a small speed bump in the path of attackers who can compromise code running on one of the other threads. Unless, perhaps, you're installed aggressive seccomp filters on just that thread - I *think* you can key them on requesting thread. But if you can interact with the privileged component over a channel then you can almost as easily fork/exec a helper and interact with *that* over IPC, which sticks a full, hardware-enforced security barrier between your GUI and privileged helper. 
These projects have been an effort to implement cgi using wasm as the binary, interesting concept maybe worth a look. [https://github.com/Geal/serverless-wasm](https://github.com/Geal/serverless-wasm) [https://github.com/losfair/IceCore](https://github.com/losfair/IceCore)
Thanks :-). It was posted here a few times (that's how I found out about it) but it's not as popular as ggez. FWIW, ggez has plans to support the web out of the box too, but IIRC that's not happened yet. Though there is a repo out there that can do it. I went with Quicksilver because it's all so seamless out of the box. Your P.S. made me laugh. English in all its forms is a ridiculous language (but I love it to bits). I'm sure there's plenty of other typos in there though :-).
My pleasure! &lt;3
My pleasure :-)
I'm sure there's a good reason for why we don't have this yet, but it's definitely one of those things in Rust that violates the "principle of least surprise," if you subscribe to that -- probably most Rust users have written `const NUM = 50;` at least once and went "Huh??" when it doesn't work.
/r/playrust
No matter how many fancy words you use to dress it up, at the end of the day you and OP are the ones making a huge problem and political/social issue, for some reason, out of something as simple as "this is how the crab is addressed", which says a lot more about you than it does anything else. To put it nicely. It's no more a "problem" than the mascots name, or gender, or species, or whatever else! Would you be out here crying about "SJW identity politics, how dare anything other than cis male cartoon crab mascots exist", or something, if it was a female cartoon crab? Or maybe if it had a title, like Doctor, so the page said "(s)he should be addressed as Dr. Ferris"? Or maybe "it", though that would be as much a "political" statement as anything else since mascots generally have genders. 
https://github.com/MaikKlein/rlsl for compiling to SPIR-V
How we teach this is now mandatory, but is a fairly recent addition.
Sure, that‚Äôs a possible weakness! It is a pre-rfc after all. This is good feedback.
Hello, is there an easy and straightforward way to generate a cumulative sum iterator, which (when collected) turns a vector like \[1,2,3\] into \[1,3,6\]? (Or if there aren't, why is it not relevant?) Thanks!
All I'm saying is that there's a risk that people coming in will see that and think "Oh, no. I'm not getting involved with that again" because, the last few times they saw that particular way of focusing on such details, it turned out to be indicative of a community that had gotten wrapped up in identity politics and social jockeying. It'd be a shame if the website drove people away by giving them an incorrect first impression of what the community spends its time doing.
Is there a language issue about fixing`Drop` as generic bound? The current behaviour of `Drop` as bound looks clearly flawed to me, however I couldn't find an issue discussing this. Every type can be dropped. Types which don't explicitly implement `Drop` fulfill strictly stronger requirements (trivally droppable) than types which implement run user defined code as part of dropping. This is similar to `Copy` and `Clone`, where copy is trivially clonable. However the the `Drop` bound corresponds to `Clone + !Copy` making it an effectively negative bound, which rust deliberately doesn't support.
The research going on under AdvancedResearch is open for anyone to review and give feedback. I'm open for a dialogue to anyone working in a serious research body to get more work reviewed and published. So far, I've never received negative feedback to the project overall or pointed out unrecoverable mathematical mistakes from anyone, or discovered serious unsoundness in the generic automated theorem provers we've developed. If you know some people who you think can help with this, PM me.
This is really cool and the way you write everything out is an example and inspiration for the community.
fan
I‚Äôm not exactly sure, to be honest. I like rust‚Äôs team for the work that they‚Äôve done to be inclusive. I just think there‚Äôs way better ways than forcing human gender topics onto a brand logo during a language tutorial. I thought the rust team‚Äôs approach and the CoC were sufficient‚ÄîI‚Äôve been using rust for like almost a year now and I didn‚Äôt need a crab being referred to as ‚Äúthey/them‚Äù to understand that the rust community was welcoming.
Thanks! &lt;3
It's not rust, but if you haven't heard of it, [mitmproxy](https://docs.mitmproxy.org/stable/) is good for this kind of thing.
What do y'all think he meant by "wholesome"?
It's just that warning sign in front of a cave that says "Here there be dragons." No reason to fear it, just know that the compiler assumes your code is safe even if it isn't (like C and C++ always do). ... Right?
Can you give me an example of `From` failing at runtime? `From`s contract is to be infallible and for example for integers only exists for the values where it is safely possible.
I'm having the same problem, but in a no std environment, are there anyways to do such a thing without boxing the trait? 
&gt; "Oh, no. I'm not getting involved with that again" But what is "this" supposed to be? What do they so want to avoid being involved in? Basic human decency? Respecting how people want to be addressed? I can hardly imagine the horror that people who don't like those things may be turned away. The horror. &gt; the last few times they saw that particular way of focusing on such details, You could make the same irrational argument about the name or gender of the fictional character too. It's still just as irrational. &gt; it turned out to be indicative of a community that had gotten wrapped up in identity politics and social jockeying. If the mere idea or mention of pronouns is enough to drive them into a fit, maybe its for the best they're scared away. They could use some character growth first. It's not any different than how it's generally assumed you're male online absent any obvious indicators to the contrary, and then correcting them. Is it "identity politics" and "social jockeying" to correct that? &gt; It'd be a shame if the website drove people away by giving them an incorrect first impression of what the community spends its time doing. it would not be a shame if those kinds of people were driven away, since they clearly aren't a good fit for the community. The same way it isnt a shame if the Code Of Conduct drives anyone away. The kinds of people stuff like this drive away are not the kinds of people you want in a healthy, respectful community. &gt; Likewise, "Dr. Ferris" would seem like a weird thing to use with a mascot whose design has no visual indication of their doctorate It's weird to be called "Dr." unless you look a certain way? ü§îü§îü§î I didnt know only characters with glasses could have PhDs. Just say the cartoon mascot is into computer science. No weirder than being a crab, just how the mascot would be, little to no explanation needed. ---- The mascot is a character. They have a name, they may have a gender, you have to refer to them in some way and those ways are called "pronouns". Who cares *what* they are? Only people who have a problem with basic respect make an issue out of basic respect. It's just as much an issue as the gender of the character, or their name. it's not like these are some new made up words or some outlandish new usage of them, singular they/them sure as hell isnt new, [it's been in common use for hundreds of years both by writers of good standing and informal speech](https://en.wikipedia.org/wiki/Singular_they#Usage)
I definitely agree with you there. Even ignoring the resemblance to warning signs of identity-political in other communities, it's needless friction when the focus should be on other things. Phrase it so no pronouns are used and, if anyone goes looking for what pronoun to use with Ferris, *then* tell them. (In fact, until now, I hadn't even thought about Ferris's gender and, if I'd been asked, I would have responded with "I dunno. Cute?" I think that's another reason that it bothers me. Like noun-engenderment in languages which have it, it needlessly assigns a gender up-front, rather than waiting until it becomes an issue. Ferris is Ferris.)
I was mistaken, From can panic, but won't during native type conversions. From does have a major problem, which is type inference: fn main() { let a: u8 = 1; let b: u16 = 2; // let c: u16 = a.into() + b; // fails // ^^^^^^^^ cannot infer type for `T` let d: u16 = u16::from(a) + b; // works }
This is the subreddit for the Rust programming language. You're looking for /r/playrust
What is Cargo ship? A new subcommand?! üòÜ
&gt; But what is "this" supposed to be? What do they so want to avoid being involved in? &gt; &gt; Basic human decency? Respecting how people want to be addressed? I can hardly imagine the horror that people who don't like those things may be turned away. The horror. Communities gripped with high-school-ish/aristocratic jockeying for position based on who does the best job to sticking religiously to the minutia of their system etiquette. (eg. Places that let it stain your reputation for ages if you accidentally use the wrong pronoun, despite apologizing and never making the same mistake again.) &gt; You could make the same irrational argument about the name or gender of the fictional character too. It's still just as irrational. As I just said in another reply, until now, I'd never thought about Ferris's gender beyond "I dunno. Cute?" Bringing it up at that point is unnecessary and distracts from what is *supposed* to be the primary focus of the document. &gt; If the mere idea or mention of pronouns is enough to drive them into a fit, maybe its for the best they're scared away. They could use some character growth first. &gt; &gt; It's not any different than how it's generally assumed you're male online absent any obvious indicators to the contrary, and then correcting them. Is it "identity politics" and "social jockeying" to correct that? No, but caring enough to bring a mascot's gender up so eagerly, when it's not particularly relevant, tends to correlate to people whose priorities are counterproductive. &gt; it would not be a shame if those kinds of people were driven away, since they clearly aren't a good fit for the community. The same way it isnt a shame if the Code Of Conduct drives anyone away. You're making assumptions about my intent. I'm saying that, had I just wandered by with no prior experience, with the site not yet having sold me on the value of continued engagement, that might have discouraged me from engaging with the community because "I don't have time to play 'Will you find something to misinterpret based on your own biases or am I smart enough to write something that can only be interpreted as I intended?' with Twitter expatriates right now." &gt; It's weird to be called "Dr." unless you look a certain way? It's odd to have a mascot with a professional title in their name such as "Dr." or "Professor" or "Sensei" or "Sargeant" without said mascot incorporating some nod to their profession in their visual design. (ie. glasses, reflector headband or stethoscope, lab coat, beret, helmet, etc.) &gt; The mascot is a character. They have a name, they may have a gender, you have to refer to them in some way and those ways are called "pronouns". When I see a crustacean without some obvious gender cue, like a bow or a beard, I don't ascribe a gender to it at all. Ferris is Ferris. Likewise, it's usually possible to introduce a character without using pronouns and have it feel natural. (eg. "This is Ferris. Ferris is...") Putting the attention on Ferris's gender at that point feels sort of like saying "This is our classical box-and-corrugated-hose robot mascot. She's female." I think. "Umm, ok. Aren't we supposed to be talking about programming? Why do you care so much that you have to make that clear *now*?" &gt; it's not like these are some new made up words or some outlandish new usage of them, singular they/them sure as hell isnt new, it's been in common use for hundreds of years both by writers of good standing and informal speech I'm a big proponent of singular they. My problem is with caring so much about the mascot's gender at a point when it's so unimportant.
It is pretty simple, actually. You can use the `.map()` combinator which takes a closure that mutably captures its environment and then a variable on the stack that stores your sum so far: let mut sum = 0; let cumulative_sum_iter = array.iter().map(|x| { sum += x; sum }); If you add `move` to the closure definition then you can even return this iterator from a function; the captured variable will be kept with the closure inside the iterator as it's moved around: fn cumulative_sum_iter&lt;'a&gt;(vals: &amp;'a [i32]) -&gt; impl Iterator&lt;Item = i32&gt; + 'a { let mut sum = 0; vals.iter().map(move |x| { sum += x; sum }) } let vals = [1, 2, 3]; let cumulative_sums = cumulative_sum_iter(&amp;vals).collect::&lt;Vec&lt;_&gt;&gt;(); assert_eq!(cumulative_sums, [1, 3, 6]); [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8050cd866bc8c729a1b471fb7f47c5f7)
I am testing out using `std::process::Command` to run the command 'git checkout &lt;&lt;branch\_name&gt;&gt;', but there seem to be a problem with how `Command` determines its `stdout` and `stderr`. Here is a snippet of the code: let output = Command::new("git") .arg("checkout") .arg(branch_name) .output() .expect("Unexpected error: Git checkout"); When doing git checkout, the output comes in 2 lines: Switched to branch 'test-branch' Your branch is up-to-date with 'origin/test-branch'. And because it comes in two lines, the second line goes to `stderr` instead of `stdout`: OUTPUT: Output { status: ExitStatus(ExitStatus(0)), stdout: "Your branch is up-to-date with \'origin/master\'.\n", stderr: "Switched to branch \'master\'\n" } Can anyone advice on the best way to resolve this?
I agree, in time Rust crates should provide higher confidence because of the additional safety. My understanding is that for now any "secure" lib requires a level of detail that's only accessible to assembly. Things like minimizing cache and timing variations between code paths to prevent runtime statistical attacks, etc.
Something that doesn't cause pain.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Writing a Rust Roguelike for the Desktop and the Web](https://www.reddit.com/r/rust_gamedev/comments/ap3fsg/writing_a_rust_roguelike_for_the_desktop_and_the/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Wouldn't he have written "painless" then? What's the connotation that I'm missing?
Yeah, that and capturing on Squid's outbound and exporting the private key were the two options i was looking at. Thanks!
Something that you know is as good for you as it is for the world. Something that does the right things for the right reasons.
If you code in rust, you know what he means. It's an overwhelming feeling of completeness pouring out of your being through your brainwaves and into the global human consciousness, causing a positive net shift and reducing human suffering globally. This newly generated positive energy's existence is only possible from bringing order to chaos and reducing the entropy of the universe, increasing the time for all conscious beings to experience it in all of its beauty. Only the truest programmers who take the rust pill and follow its guidance will know this feeling: the feeling of mastering your physical domain to the point where you can wrangle with its fundamental laws at the just the right macroscopic scale that allows for you to achieve the *exact* results you want in the least time, efficiently using as much of your conscious effort as possible without going past the breaking point. I never could have written a comment like this until programming in rust... Since then I've been a more creative, intelligent, more enjoyable person to be around and it's all thanks to rust. I've even begun borrow checking my own thoughts now and have a much safer thought process because of it, as well as a deeper intuitive understanding of what exactly the creation of thoughts is in the mind.
Kotlin is a tool vendor's language and is merely sugar coated Java. It solves a few issues but doesn't bring anything new to the table. Java is evolving faster now and will pick up the slack in a year or two.
Agreed! 
another common syntax is \`std\` / \`alloc\` e.g. serde: [https://serde.rs/no-std.html](https://serde.rs/no-std.html) 
&gt; only convenience, which makes it an even stronger case. Interesting; I was thinking exactly the reverse. My thinking was: - It's an edge case. - The work-around is well-understood. - Doesn't seem necessary. Since each additional feature adds a burden on both further compiler development and users encountering the constructs, I think it's important to be conservative in adding new features, and instead focus on features enabling new usecases: async, const generics, specialization, ... I can see an argument for `for&lt;T&gt;` in the sense that `for&lt;'a&gt;` already exists and users could instinctively try `for&lt;T&gt;`, but: - I don't see a big benefit: it's a rare edge case, so it doesn't seem to warrant first-class syntax support. - I don't see a cost analysis: how complicated is it to implement? how complicated will it be to maintain? how complicated will it be to teach? For me, the costs/benefits seems to fall short.
Nit: I'd write it like type ParserOutput&lt;I&gt; = impl Parser&lt;Input=I, Output=Self&gt;; to stay consistent with `-&gt; impl ...` that it is replacing, rather than introducing a contextual keyword (`existential`).
My guess is that programming in Rust just made him feel good. Some critics of other languages often mention they feel miserable sometimes. I'd say he hasn't experienced it too much with Rust yet. But again, just speculating.
The dictionary definition is: &gt; conducive to or suggestive of good health and physical well-being. It's generally used to mean: *make me feel good*.
Is PCJ leaking again?
It is interesting to me, would not it be difficult for him to write something like "fast inverse square root" using safe rust? :
Is it faster than the quickest JS to JS compiler, namely `cat`?
What use is a Drop bound? You can‚Äôt invoke Drop::drop anyway.
As of right now `cargo-nono` doesn't know anything about `alloc`, and strictly checks wether `std` is going to be included or not (which it correctly does for serde). [There is an issue to make cargo-nono aware of alloc, though](https://github.com/hobofan/cargo-nono/issues/20)
Yes. Additionally please see the numerous threads over the past two or so weeks on this subreddit about it.
I'm mainly using `existential type` because that's the syntax [RFC 2071](https://github.com/rust-lang/rfcs/blob/master/text/2071-impl-trait-existential-types.md). The word `existential` is explicitly a placeholder which will be bikeshedded before stabilization, but as far as I know this is the closest thing we have to what the real future syntax will be.
I don't understand what you're asking really - that code doesn't access memory (or really have any state) so I'm not sure what rust is going to bring to the party.
&gt; Do you know if the consensus has shifted to adopting `= impl Trait;` instead? No idea; I just personally find it more "obvious".
It's not really hard, [just a pair of unsafe transmutes instead of the casts](https://github.com/itchyny/fastinvsqrt#rust). What I'm not sure of is how *legal* it is (according to the wiki, the original is UB in C, the "defined" version using a union is UB in C++). Also technically Carmack didn't write fInvSqrt.
&gt;cumulat This is perfect, thank you!
I'm looking forward to knowing the answer to this.
Great response. Thanks!
Congrats! &gt; And suggestion or help welcommed. When making an announcement, I suggest the first thing to write is at 1-3 sentences that answer the question "What is this?".
By now `f32` has `to_bits()` and `from_bits()`, so it can actually be done entirely in safe Rust without any transmutes.
Very cool but I'm afraid it won't get the love it deserves. Our UI build times are bad enough to be annoying, but not bad enough to justify moving to an unfamiliar build tool. Especially since live reloading works pretty well.
Cool, thanks. Noted :)
I wonder how it would react to a NaN input.
Macros were treated extra special for a long time. Things are much better now, but it‚Äôs recent enough most internet documentation is out of date or assumes you had it working in 2015 and are moving to 2018. Sorry you had a rough experience with this gotcha !
Sounds like an opportunity to do better than an existing implementation!
&gt; **What can swc do?** &gt; &gt; It can transpile typescript / jsx / ecmascript 2019 to browser-compatible javascript. 
I agree with this post in general. I don't know why this isn't the case already, but if there is a good reason not to do this, I hope something like the second example `const NUM: num = 30` since numbers are the biggest headache in consts. Generally, if I write `cosnt STR: &amp;str = "Hello"`, the type isn't ever going to change, but if I write `const NUM: usize = 30`, I might need to use that number as any i* or u* types.
Thanks! If you have feature requests, I'm very happy to implement them.
I'd like to look into doing something like that, although I'm not sure I have the knowledge of LLVM and Rust internals to do so. `rlsl` seems to have this space covered with its SPIR-V target.
NaNs are still bit patterns, so that should not be an issue.
Oh cool, I had completely missed it! And it takes/returns an u32 too.
I meant how would it react to the wild bitshift mess that is the invsqrt approximation.
I'm concerning it too. So I will work on stuffs like create-react-app-swc to attract people.
This is a really active project with a great start. There are 2 things stopping us from using it: - TypeScript compiler does not check types, it just transpiles valid syntax (even if the types are invalid). I opened an issue about that. - I haven't seen a straightforward way of bundling multiple transpiled files (through imports) without using node-land tools. I'm sure this could be done with a transform of some kind though.
It seems that some footer links are broken.
The Tarolli-Carmak fast reciprocal sqrt is obsolete: hardware usually has an instruction with much better latency and throughput and no worse precision. ([x86 SSE](https://www.felixcloutier.com/x86/rsqrtps) [ARM NEON](https://developer.arm.com/docs/dui0473/k/neon-and-vfp-instructions/vrsqrte)) 
There's been pretty good reviews about [actix-web](https://github.com/actix/actix-web), or you check out [tide](https://github.com/rust-net-web/tide) if you feel experimental. Or check out r/playrust.
It's very interesting to see this seemingly only increasing game development interest in Rust. It's something I wouldn't have thought I would see back when I was following Rust in the pre-1.0 days. Of course, in hindsight, it makes total sense, but it's still just *neat*.
\#[jerk] The only thing that ever improves Rust is a tasteful sprinkling of assembly.
Oh, I see bundling is being worked on here: https://github.com/swc-project/swc/compare/master...kdy1:bundler
I would assume that it would interpret most NaNs as very large numbers. And hey, it's easy to test: [Playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d4d83bedc3cc8109319114a76302af36) It seems I was wrong. The second I saw that the result was also a NaN it hit me: the step of newton's method at the end does a multiply with the original number, and result of any mathematical operations on NaN are of course also NaN. 
&gt; TypeScript compiler does not check types, it just transpiles valid syntax (even if the types are invalid). I opened an issue about that. &amp;#x200B; Note that this *is* exactly how Babel does it, and to be honest I don't see much of a problem with it. It's expected that you simply run TypeScript to check for type errors, similar to how you would run ESLint to check for linting errors.
Not sure what you mean, works just fine: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0959a9cf1836a4f79bfee0a5df74defe Comparison with the C code: https://onlinegdb.com/rkmUZTaV4
I would be very surprised if this wasn't just how git does it's output in that case. Did you test it with `cat`ting to a file?
https://this-week-in-rust.org/ for example
It is now üòÇ
Any tips or artciles on advising a company to start using Rust? (They want to convert an exisiting PHP backend to Rust, but want more info about the possible risks) Like, Rust is obviously in active development, and some older projects won't be able to compile with the current version of Rust. Is there any documentation or something on upgrading your projects or annoucing that some code will break in a release soon(tm)? In the end they want to use Rocket.rs, Diesel.rs and for newsletter stuff Lettre (with dynamic tags in a template, think of Name etc) Are there perhaps even any risks in particulair on the mentioned libraries? (Rocket, Diesel, Lettre)
Ohh, thank you for this post. Trying Quicksilver was on my list anyway and this post seems to be a really good intro!
Your `flush` method calls itself, leading to the stack overflow. &gt; I find it "weird" that I have to pass a u8 buffer to fn write. I'd think that the implementor handles that on their own. Am a creating a design error here? Yes. The `Write` trait is for things that can be written to, i.e. sinks, like files, pipes or network sockets. Your write method does something completely different. You can instead have a `fn serialize&lt;W: Write&gt;(dict: &amp;Dictionary, dest: W) -&gt; io::Result&lt;()&gt;`, of a `fn serialize_to&lt;W: Write&gt;(&amp;self, dest: W) -&gt; io::Result&lt;()&gt;`.
Would love that. (Or SPIR-V)
I got some pretty interesting results: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=e6664edd261066e007d47cfdfa2d8431 Panics for any negative number, unless in release (duh), and the edge cases have some differences with the naive version, but overall the precision is GOOD.
I had some fun by [replacing the input by NaN, but not the final multiplication](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=0c6033d15dc9e101afac6a9b415b93fb). Spoiler alert: you were close, you get really small numbers instead of really large ones.
Googled. I can't figure out whether that's [Petroleum Corporation of Jamaica](https://www.pcj.com/) because he talks about energy, or [Pontifical College Josephinum](https://www.pcj.edu/) because it's sorta spiritual. 
/r/programmingcirclejerk
You are comparing a crab to a family member which dogs and cats are often considered to be a part of. There's also the whole thing about the fact that you often know the gender of a dog but you dont know the gender of a crab. Example: Oh no poor Max, he got hit by a car. Look at that crab, it got crushed by a car. 
&gt; Doesn't seem necessary. let result = a.simd_iter().zip(b.simd_iter()) .map(|(a, b)| a * b) .collect(); Without generic closures, `|(a, b)| a * b` cannot be instantiated different types. That is, you have to decide at compile-time whether you instantiate it as `Fn((a: _m128, b: _m128)) -&gt; _m128` or `Fn((a: _m512, b: _m512)) -&gt; _m512`. That's pretty bad.
It assumes the bit pattern of NaN to be a very large number, therefore 1/NaN^0.5 is a very small number.
&gt;ecks ok that makes sense. so then from what I'm understanding for &amp;elem in elems { access elem } is only used when *elems* itself is a reference, and the *&amp;elem* itself is used to dereference it (kind of like how you do (\*elem) in C). However the derefence is read-only right? Assuming *elems* wasnt defined as *&amp;mut elems* here.
ok that makes sense. so then from what I'm understanding for &amp;elem in elems { access elem } is only used when *elems* itself is a reference, and the *&amp;elem* itself is used to dereference it (kind of like how you do (\*elem) in C). However the derefence is read-only right? Assuming *elems* wasnt defined as *&amp;mut elems* here.
&gt; From can panic, While this is technically incorrect, `From`'s documentation also say that it should never panic. In the future, we could add a `#[no_panic]` attribute that enforces at compile time that functions never panic, `From::from` would be one of the first functions in which we'd like to ensure that. If someone is writing `From::from` implementations that `panic!` their code is already broken.
My pleasure! Thank you again for mononoki :-).
Your understanding is correct. Sometimes you want to consume the vector, but I think looping through a reference is the most common case. &amp;#x200B; If you dereference the element and it's not a reference, you'll get value which you can mutate if you want to. Values don't have mutability - only references and variables do. I don't think "dereference is read-only" means anything in the context of Rust. &amp;#x200B; You can also use \`for elem in elems.iter\_mut()\` to iterate through mutable references to \`elems\`.
*xer 
My first and main comparison was to Sebastian, the crab from the Little Mermaid, who is referred to as "he". What's makes for the different rules for Sebastian and Ferris?
I wish Rust had a SPIR-V backend just like it has a PTX one.
This is great, JavaScript build times are ridiculous (and so is memory usage). Will have to try this out.
The borrow checker helps avoid problems like dangling pointers too, not just concurrency-derived data races.
It‚Äôs still safe for - Error handling as you will match Results - No null pointers - ownership makes bugs harder when writing loops/iteration - a small one, but having immutable by default is great - Expressing which functions are ‚Äòread‚Äô vs ‚Äòwrite‚Äô is amazing. Functions that don‚Äôt return anything still need write access tell users that they mutate something There are plenty of reasons IMO, coming from a Java background. 
Should it though ? I personally implemented Ord on a struct containing floats, and considering those floats should NEVER be NaN, preventing a panic in the Ord (like for the from) would force me to make it fail silently by simply considering NaN the lowest value.
*Rust* doesn't have a PTX (or AMDGPU) backend, *LLVM* has them. And of course [there is work on LLVM-SPIRV](https://github.com/KhronosGroup/SPIRV-LLVM-Translator) translation.
Well, If I was a betting man, I'd bet Sebastian is a male crab and I'd be right 99.9% of the time. We specifically dont know what Ferris's gender is because they refer to it as being they.
Memory safety. You cannot crash because of a dangling pointer or read from a memory that is uninitialized or not owned by you (unless you use *unsafe*).
&gt; Rust doesn't have a PTX (or AMDGPU) backend, LLVM has them. And Rust has LLVM. And no, Rust does not support LLVM's AMDGPU backend, nor LLVM has a SPIR-V backend. 
Honestly part of Rust's benefits are that it's extremely easy and safe to go from single threaded code to multi threaded code when the need arises. If you use rayon you usually just throw some `.par_iter`s on there, but even just doing it manually the compiler will ensure no data races occur and will error if there is a problem.
A type system expressive enough that you can verify proper use of any API which can be represented as a state machine at compile time. (See, for example, The "hyper" HTTP library, which will give you a compile-time error if you try to replicate the infamous PHP bug where you try to set a request or response header after the body has already started streaming.)
[Scan is also a perfect fit for this.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e1efac2c440b55d906f249d550382ea6)