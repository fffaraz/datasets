you linked master, but seems the code changed, and is taking the size from command line
Unfortunately, I haven't investigated setting things up to attach a GUI to the debugger yet. It may be especially hard on macos because it uses lldb instead of gdb (which has more mature GUI wrappers). You can get the experience you are looking for today if you use Windows. Visual Studio is almost nice enough to make me want to give up Unix sometimes.
The problem is that you're mixing your package sources. The VSCode extension relies on the Rust Language Service project which depends on internal compiler apis which change version to version. In order for this to work, you need the exact same compiler for both `rustc` and the `rls`. Because you've installed `rustc` from Debian but you're installing the VSCode extension from their extension repo, this isn't going to be possible. You either need to use the regular non-Debian `rustc` provided by rustup with the VSCode extension, get Debian to package the VSCode extension in such a way that it works with their `rustc`, or not use the VSCode extension.
It would however empty the channel which would be free to receive a new value which is against the requirements.
Maybe /u/wezm would want to showcase [his nice e-ink conference badge](https://www.wezm.net/technical/2019/01/linux-conf-au-rust-epaper-badge/)? :) Also, the link to edit the next post is broken. It should be https://github.com/rust-embedded/blog/edit/master/content/2019-04-05-newsletter-18.md.
Implementing a trait for a struct in a crate, shouldn't be able to cause another dependent crate to stop compiling. I believe this is the main rule that would be violated if we relaxed the orphan rules. I think [Niko's blog post](http://smallcultfollowing.com/babysteps/blog/2015/01/14/little-orphan-impls/) from 2015 could provide some background as I think there hasn't been much updates to the orphan rules since 2015.
I wouldn't call it a crawler, but such thing exists by virtue of how Spark works. Spark works with lazy evaluation, so when you first create a transformation that reads the file, it infers it and keeps the schema in cache. I think with databases it's 'easier' because it requests the table's metadata.
&gt; The only big problem that I can see is that if e.g. crate A implements `Hash` on `[u8;64]`, and crate B does also, then you simply cannot build a project that depends on `A` and `B`. So it might be kind of hellish for the ecosystem in the end if there were really a total free-for-all on who gets to implement the trait. The Orphan Rule may indeed be the "best practice" esp. for library code that will be reused in many projects. This is the major reason AFAIK. The C++ ecosystem favors large packages for a variety of reasons while the Rust ecosystem favors many small packages. It seems likely to me that while this isn't a big deal in the C++ ecosystem, it would be hell in the Rust ecosystem.
Ahh I didn't know how Spark barebones worked. I used AWS Glue which is Amazon's version of spark where they have a crawler to infer the schema into a meta-data table in a DB that you can read from.
In Rust, I've found that my code remains simpler when I use mostly imperative code with a little functional thrown in. This is my implementation of find: fn find(string: &amp;str, substring: &amp;str) -&gt; Vec&lt;SubstringLoc&gt; { let mut locs = Vec::new(); for (line, content) in string.lines().enumerate() { for (col, _) in content.match_indices(substring) { locs.push(SubstringLoc { line, col }); } } return locs; } (I've changed the names of the fields in SubstringLoc to make them, I think, clearer.) I've used the `enumerate` combinator—like the functional version in the video—because that's clearer and less error prone than having a mutable variable for the current line number, however I find that the for loops are easier to read than the long sequence of combinators. Speaking for myself, I've had difficulties remembering if the lambda of a combinator (map or filter) takes its arguments by move or by borrow; that's typically never a problem with loops. A Rust project at work has also convinced me that it's easier to insert instrumentation code (e.g., log statements, pushing metrics to a series database, etc.) in imperative code than in a long sequence of combinators.
Is this for flat files? That makes sense because you then incur the cost of inferring once instead of each time you read the file for the 'first time'.
Not just flat files, it takes in JSON, XML and custom pattern matches to infer the schema.
Thanks for the pointer. I will probably submit it. 
I don't expect you to change your mind based on this, but I do want to understand how you expect users to get detailed error info. Let's say I'm making a text editor, and I want the user to be able to do regex searches. Let's also say I want to highlight or squigly-underline where the user enters bad syntax. As far as I can tell, the only way to do this would be to use the regex-syntax crate, as you suggest, however I can't find a way to take the output (type: Mir, if I'm understanding that crate) and get a Regex object (from the regex crate) that I can use to actually do the search. So instead I would have to parse the syntax once to check for errors, and then a second time to use it. That seems less than ideal. Is there something I'm missing?
Sure. Unergonomic.
Thank you, this makes perfect sense. So basically, implementing these wrapper classes is protecting me from build-breakage -- if I have a type from A and I need it to have Hash, then I need to wrap it and provide. If the downstream guy decides to provide Hash later, my wrapper class still uses the version that I provided, and it's up to me to decide to remove from the wrapper class, or factor out the wrapper class if it's no longer needed
Too bad we don't have something like trait macros or [postfix macros](https://github.com/rust-lang/rfcs/pull/2442), where theoretically a crate could re-export a `with!` macro as described elsewhere in this thread, so that you could do let config = MyConfig::default().with! { .foo = 42; .enableBar(); .baz("blah"); }; without explicitly depending on the crate providing the `with!` macro.
Yes, hugs and kisses to the authors
Const generics are very nearly here. Your array iterators will work soon :)
Does anyone know of a chempy equivelent for rust?
It depends on your use-case. If you want the user of your library to handle your errors (and they contain meaningful information), then let your errors be open. If you can only give the user a simple message because implementation details are too esoteric, then do just that.
You're not missing anything. That's exactly what you have to do. There's no other way without making regex-syntax a public dependency, and that will never happen, by design. regex-syntax only exists as a service to those of us with more niche use cases. Most regex libraries don't provide anything like it at all.
One thing to note is that futures are still 1.0 - which most likely is the (or part of) root of the issue.
Does it cope with using `?` on an `Option`?
Are you sure that you actually have enough users for the data structure to matter? Could you just store all the tuples in a Vec using sorts for insertion and binary searches for lookup?
I looked it up and its config builder does have a `temporary` flag which defaults to `/dev/shm` (tmpfs volume). Presumably it's not going to be as fast as something that's designed for in-memory use though.
I spent a fairly long time nailing this algorithm, which you're welcome to port to rust: https://github.com/Lucretiel/SkillServe/blob/d3a38978f35c83d2a308f2aa489e5c1b092a7731/frontend-src/store/leaderboard.jsx#L24
No, rust is very fast, i tried sorting a list of 5000 people, and it took 0.7 ms :p, so I can afford sorting the list for every score update.
Unfortunately not, it only works on `Result` (or more accurately, tryable types with `map_err`, which in stable is just `Result`). I considered trying to add support for any tryable type, but since the [Try](https://doc.rust-lang.org/1.29.2/std/ops/trait.Try.html) trait is the only way to do that (as far as I'm aware) without requiring modifications to the original code, and that trait is only available in nightly, I didn't bother to implement. I guess I might add that as a optional feature in the future though.
https://docs.rs/log/0.4.6/log/
Linking/ODR is a red herring here. Haskell allows orphan instances and it doesn't have ODR violations. The problem is with language semantics - enforcing canonicity (one trait-type pair has one impl) is much cheaper if you have an orphan rule. If you are willing to give up canonicity, you need something like ML modules or Scala objects instead of Haskell style type classes, to ensure coherence (different typing derivations leading to same runtime semantics).
I don't agree with this. Futures are great; but the ergonomics depends heavily on getting async/await syntax stabilized. If you're willing to use the current async/await in nightly, they can be pretty nice to use. (Well, except for all the current limitations on what the borrow checker can do). It was the same with javascript - when promises landed, there were countless articles about how to awkwardly structure code by chaining \`foo().then((res) =&gt; {})\` calls. But now we have async/await, you just write code more or less imperatively and pepper a few of your calls with \`await\`.
Their is already a tool with this name which may conflict for packaging purposes: https://www.boost.org/doc/libs/1_69_0/tools/bcp/doc/html/index.html
Could you give examples of the kinds of things you do? I hardly ever use dd.
&gt; One of the downsides of Rust's error system compared to exception systems found in a lot of other languages is the lack of stack traces. Can you elaborate? How do I get stacktraces from exceptions in C++? And have you seen the `failure` crate, which has error types that can print backtraces?
This seems to be very global-oriented, something I think is to be avoided to make testing much easier.
&gt; I was thinking of something like a btree that stores, in each node, how many leaves are in the left and right tree. /u/isaacg1 and /u/krdln talked about writing a similar data structure in a recent thread: https://www.reddit.com/r/rust/comments/awlqqi/augmented_binary_search_tree/
There's a reason why we love futures. Just because I'm waiting for the database to respond doesn't mean I should leave a whole OS thread blocked in the meantime. It can do other useful stuff, such as responding to other requests, while waiting. Did you know you can run a web server in a [single thread][1] with tokio, while still being able to respond to several requests at once? This is what futures allow. [1]: https://docs.rs/tokio/0.1/tokio/runtime/current_thread/index.html
There is no technical reason; you could always come up with some sort of rule to fix the problem. The reason is social; these rules would be subtle and lead to bugs; a failing compile is *much* better, and gives you control.
I would definitely be interested in this. Having created a futures-enabled library myself I am pretty well versed in futures, and while I have not used any future-enabled database library, I have used diesel quite extensively.
It *could*, but it’s controversial enough that we haven’t pursued it.
Syntax did get bikeshedded a lot, but the main thing that did it in was the fact that it's really hard to guarantee placement in more-complex scenarios. For example, the ABI around `Result` means you can't just `some_place &lt;- some_result()?` and expect it to work- and that sort of thing happens all the time in idiomatic Rust.
https://docs.rs/log/0.4.6/log/trait.Log.html
I'm very familiar with JS async / await, but have only heard about it coming for Rust. What will that change? Even current abstractions on top of Futures like Tokio are ridiculously hard to understand and use. Will async / await make using Tokio easier in some way?
&gt; There's a reason why we love futures. Just because I'm waiting for the database to respond doesn't mean I should leave a whole OS thread blocked in the meantime. It can do other useful stuff, such as responding to other requests, while waiting. They used to have a way of doing this back in the old days, I think it was called multi-threading.
About impl IntoIterator for array, I guess it would be a breaking change nevertheless. I'm wondering whether it would be possible to make the impl itself be conditionally used for the next edition (2021 maybe?) so that we don't stick with this situation forever, while we don't need to introduce such breaking change for old codebase.
In `tiberius`'s case I think a major complicating factor is its Error types. They don't seem to implement std::error:Error or std::fmt::Display adding to the confusion trying to interoperate with other frameworks.
Yes, I looked at this already but the problem is that the macros don't take a context object, they seem to assume some global logger object.
You may be interested in [`newtype_derive`](https://docs.rs/newtype_derive/0.1.6/newtype_derive/)
Great! The iterators in the PR do work, but with an ugly type signature and only up to length 32. That will all be nicer with const generics. The big question is the migration story though...
&gt; I'm waiting for the database to respond doesn't mean I should leave a whole OS thread blocked in the meantime The things is, futures is not the best way to solve it. Or more correctly, is not fun to use futures. &amp;#x200B; When async/await land then maybe things be better. &amp;#x200B; Also, the use of futures/async assume you want the extra complications it bring. &amp;#x200B; For example, a main use case for me is to run ETL. Async here is wasteful. I only need to get data, transform it and pass to the next in the pipeline. I don't need async at all (also, most of the apps I interface can perform in parallel!).
A cargo package can only have one library, at maximum. You’d need a workspace to accomplish this.
I think you want /r/playrust!
AIUI, there's no mechanism for any sort of cfg-edition in the standard crates, and a big reason is that crates from different editions are still interoperable. I haven't worked out the consequences, but it's probably bad if two crates compiled together don't agree whether arrays implement `IntoIterator`.
I guess I was a bit unclear here, I'm not trying to imply that stack traces are inherent to exception systems, but that most languages (that I've used) with exception systems also have stack traces for those exceptions (here C++ is the *exception* to the rule, pun very much intended). I haven't had a look at failure in particular, but as I mentioned in my post I've already seen similar packages that encapsulate errors to capture stack traces. These might work better if you implement your own types, but my goal with this package was to avoid declaring "wrapper" errors just to do debugging—adding the attribute should be the only change you need for any function to start debugging. It's also not quite suitable when you need to return a given error type, for instance in closures or functions with a specific required signature. That being said, one of the advantages of `failure` crate (and others like it) is that they do runtime backtraces, so you get the entire stack, while with my crate it happens at compile-time, so you'll just get the line where the error occurs.
&gt; I haven't worked out the consequences, but it's probably bad if two crates compiled together don't agree whether arrays implement `IntoIterator`. That's a good point. I guess it wouldn't be too bad, as anything accepting `impl IntoIterator` has to be generic, and such generic can be resolved at its callsite. There might be more cases need to be think about, but possibly edition-based conditional `impl` in std could be a useful thing?
I think it's a coherence thing. Suppose crate `foo` is on the old edition, and has a `trait Foo` which it implements for `T where T: IntoIterator` and separately for `[T; N]`. These are distinct if the array iterator doesn't exist. Then crate `bar` is on the new edition, and tries to use `Foo` on an array. Which impl does it get? Maybe there's some way we could tag that `T: IntoIterator` (according to my own edition), so it never overlaps. This seems pretty hairy though.
My condolences.
Isn't that pretty slow/resource intensive? I assume that's why Go works so well for web servers, because of their lightweight goroutines.
We've been using `err-derive` to create custom `Error` types from enums. You can use `.map_err(CustomError::Variant)` to convert an error.
&gt; This is like one of those classic examples where everyone's standard of success just keep moving That's not necessarily a bad thing, it usually means progress is happening. To be completely fair, I've used and don't have any issue with your library personally. And I think if I were actually making a text editor, I would likely prefer a slightly different syntax than you implement, so I'd have to roll my own (or find another) anyway.
I used git to get RLS after VSCode had problems getting it to work. This failed to build so I didn't even try and build my own copy of the VSCode Extension... not sure what u r saying. I never tried to use two versions of rust at the same time, fearing that would break things.
I have no experience with graphics stacks, but it seems really impressive that folks have built gfx and gfx-portability with Rust, and then seem to keep dropping it in places and seeing stability and performance increases. I would love to see more about why this is the case - is Rust that good? Was gfx really well designed from the getgo? Are the folks working on it made up of experts who are getting to design the ultimate "second system"? All seems really impressive to someone that only understands a tiny bit of context!
Isn't romio only a very small portion of the various tokio apis as well? I thought it was stricky some TCP stuff, more as a proof of concept?
But you are now talking about two different things. Your argument works great if you are talking about lots of open idle connections, like websockets, then async is the only options. But if you are backing each web request with database access, it really doesn't matter if you are async or not, the database has a much lower limit of the number of simultaneous requests it can handle, so handle each web request with a OS native thread is not going to be limiting in any way, and in fact might be faster that async.
Nice tip!
Depends what you find difficult about working with tokio. If it's creating and joining futures together to create a data flow, with logic (wait for all these things to finish / wait until one of them is finished, then run this other thing and if it times out do this, otherwise do this" and so on) then yes, async/await will make that a lot easier and more straightforward to read and write. 
It is limited to TCP and UDP, but everything else being used from tokio was moved to the futures create itself. What isn't provided by either romio or futures-preview isn't being used here.
Check out \[slog\]([https://crates.io/crates/slog](https://crates.io/crates/slog)).
I see, I will have to dig into this more with this context. Thank you for the explanation!
I can understand. thanks
&gt; A Rust project at work has also convinced me that it's easier to insert instrumentation code (e.g., log statements, pushing metrics to a series database, etc.) in imperative code than in a long sequence of combinators. Rust has the [inspect](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.inspect) combinator, which helps a lot.
FWIW, those impls are conflicting already (in both editions), and the error message cites that std could add the impl in the future even though it doesn't now. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=1b55a3091c0b3ff78d7a531c6f068772))
You probably want a BTreeSet. You may need to add an ID element to the tuple to prevent duplication. Or, use a BTreeMap and use the value as a count. The normal approach for this is a balanced binary tree. If you read the std BTreeMap docs, they explain the choice of BTree over binary tree. Writing binary trees without GC is complex because of the lifecycle and ownership issues it raises. And Rust makes you actually solve those issues. Database indexes are a related problem, but often won’t fit in memory, so the solutions are slightly different. 
No problem!
So how would I store a player's score in a btreeset? and how would I look up a player's position with a btreeset?
Ah, right, thanks. I'm not sure if there are other ways it could break... maybe it would be OK!
Well, Rust is awesome, *and* the folks working on it are made up of experts, *and* this is the end result of several years and several API design decisions and re-decisions ;D /u/kvarkus probably wouldn't say so without prompting, but is definitely a graphics wizard, and is the main driving force behind gfx at this point, and then grovesNL (I don't know his reddit username, sorry!), /u/msiglreith, /u/omni-viral, and several others who I don't remember off the top of my head that are also graphics wizards have all contributed a lot to get it to where it is. 
&gt;&gt; Examples tend to assume the user is well-versed with the tokio and futures universe, which often makes it difficult to follow them. I don't know how many times I've looked up the difference between map and and\_then. I've honestly given up on most combinators. No offense, but that's just a lack of basic FP knowledge. Sorry but you just need it in 2019. Future is a monad. The easiest definition of monad I ever found: something that allows you to sequence computations. That's why monads always have map and flatMap (and_then) methods to chain these computations. Once you know this you won't ever have a problem with any monad: Option, Result, Future, etc. Of course there is some room for improvement in ergonomics and Future 0.3 will be easier to work with.
You asked how to store player (name, score) tuples sorted by score. Flip that around to (score, name) and use that as the Map key. Traverse the map to get the sequence. Looking up position by name just isn’t something you’d solve without traversal, I think. 
I proposed a solution for looking up position by name in the OP, that i'm pretty sure would work without traversal, in O(log(n)) time.
You can use [`Itertools::unique`](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.unique)
&gt; I couldn't find any documentation links that listed out all the functions that arrays have access to You probably mean Vec, which has [all its methods listed here](https://doc.rust-lang.org/std/vec/struct.Vec.html#methods). If you actually have a slice/array, you probably want to operate on it as a vec instead. &gt; count number of unique entries in an array If you can mutate the vec, sorting and deduping it is probably easiest. `Vec` provides a dedupe method, and once it's deduped the length of the remaining vector is the number of unique elements. If you don't want to lose duplicates, and don't care about memory usage much, you can just copy it first and then do the above. If the above doesn't make sense, it would help to first write your attempt to solve the problem as a [rust playground](https://play.rust-lang.org/) which will make it easier for someone else to understand what you're trying to do in the first place.
I feel your pain. I totally agree that many crates have some flaws about its documentations. My last bad experience was learning diesel, which is one of (if not the) most used orm crates for rust. It lacks docs in its guides about Queries (!)... I spent almost a full weak just to make a simple dynamic query for a pagination listing use case. don't get me wrong here... diesel is awesome, but this issue is open for about a year: https://github.com/diesel-rs/diesel/issues/1108 diesel is really powerful and I like it, but you have to get your hands dirty and spend some good hours reading api docs to do simple stuff done sometimes. 
It should have been `from_str` instead of `from_string`. Thanks! I feel ridiculous for not catching that after hours of trying to figure it out.
I personally enjoy `self` a lot for a simple reason: it forces you to use that _method chaining_ stuff only for when it’s needed. If a method returns something, you shouldn’t try to use that function in a method chaining way. Method chaining is something that has been around for a while especially in OO languagese. I personally use it only with the `Builder` pattern. **People abuse method chaining and think it’s a cool, fancy and modern way to call functions.** Method chaining, to me, is used to “perform several endomorphisms” (i.e. pure computations on a single value, so you want `self`). Using method chaining for IO feels like a bad idea. The “old” way to call a function, as you said, is just the regular and normal way. Depending on another crate to perform such a work feels like complete overengineering to me and is not necessary.
Hmm, makes sense thanks. I think what threw me is that Python also treats empty lists as false-y: lst = [] if lst: print("true") else: print("false") This is of course different than performing an operation on the empty list but it seems counter-intuitive to me that an an empty list evaluates to `false` but performing operations on it evaluates to `true`. I certainly don't have a formal logic background though. &amp;#x200B;
What /u/Ralith said. Consuming by moving-in is always strictly powerful than borrowing (since you can borrow by moving-in).
Just use a hash set: trait CountUnique { fn unique(self) -&gt; usize; } impl&lt;I, T&gt; CountUnique for I where I: Iterator&lt;Item = T&gt;, T: Eq + ::std::hash::Hash, { fn unique(self) -&gt; usize { self.collect::&lt;::std::collections::HashSet&lt;_&gt;&gt;().len() } } If you want a faster impl swap in `hashbrown::HashSet`.
That seems like a bad thing for Dart then… :D &lt;/sarcasm&gt;
r/playrust is your place. This is subreddit for Rust Programming Language
Look up position by name in two steps. Firstly, have an O(1) method of looking up score by name (either a hashmap, or store the score inside the user struct). Then, use the BTreeSet to lookup the position by score. If your BTree keeps track of the number of items each node has, you’d be able to count the position quickly enough. 
I prefer to use a enum and the `From` proc-macro derive from `derive-more`.
Thanks!
You can't look up anything in a btreeset, I want key: user, value: score. A btreeset only has value: user, and a way to determine an ordering on those users. I think you mean a btreemap. &gt; Then, use the BTreeSet to lookup the position by score This would not be very good, because if i were to insert a new score (my scores are floats) I would potentially have to update all positions in the score -&gt; position map. And if you propose having your btree keeping track of how much items each node has, that's exactly what I proposed in the OP, and you wouldn't need a dual hasmap and btreemap structure for that, just a btreemap would be able to accomplish everything on it's own.
Frankly, beginners invariably get unsafe wrong - for different reasons depending on their background. So it's not so much a matter of "if" but "what". Glancing at your code on mobile, I did find a likely correctness issue which is *technically* not an unsafe violation: you leak the Box&lt;FnBox&gt; if lazy is never forced. This will lead to memory leaks in applications.
While Haskell technically allows orphan instances they are generally shunned in the community and there are ways to ban them. I don't think ML modules or Scala enforce coherence a la Haskell (and Rust) in the sense of [this blog post](http://blog.ezyang.com/2014/07/type-classes-confluence-coherence-global-uniqueness/). I know that Idris's type classes don't. Instead, they use proof search to infer a dictionary so the provenance of the proof is relevant as opposed to Haskell &amp; Rust.
In any sort of search tree, you have to pick a sort order. You can't have two. The OP sounds like you want to sort by score, but you want to lookup by name. Lookups are only fast if it's a lookup by sort key. You can't have both in one tree. You can have two trees, of course, or a tree and a hash table, as suggested by ashfordneil. Your idea of storing subtree size in each node isn't a bad one. It'll be some extra work to maintain it as you balance your tree. But you still need to sort by both score (necessary to rank the players) and name (necessary to find by player), which is two separate data structures.
It has been pursued, and rejected. That's different from being too hot to handle, as you imply.
You’re misunderstanding my suggestion. You’re trying to get a user -&gt; position map, I’m suggesting you have a user -&gt; score map, and a separate score -&gt; position “map”. The user -&gt; score map doesn’t need to be any form of tree structure, modified or otherwise. This is all I’m suggesting you use a hash map to do, as there’s no ordering necessary and so it can all be O(1). The (modified) BTreeSet I suggested was for the score -&gt; position “map”. I’m aware that BTreeSets don’t have values, but the purpose of the structure isn’t to store positions - it’s to make it really fast (probably log(n)) to *calculate* positions. All you need to store in it is a set of scores*. As long as you have the modifications discussed, you can very quickly count how many leaves there are to one side of a given leaf in the tree. Because positions themselves aren’t stored, you don’t need to update positions when you change anyone’s scores or add new players, meaning that is still a quick log(n) operation. I am aware that you’d suggested the same modifications in the OP. I just wanted to stress that a regular BTreeSet wouldn’t be capable of solving the problem. *other comments have suggested ways of achieving it, I’m not going to rehash what they’ve said. 
if `q` is an array and `k` is it's `clone`, then, `k.sort()` and then `k.dedup()` and finally `k.len()` should give unique elements
Just a small addition to /u/termhn answer: analysis of why exactly our implementation is faster is non-trivial and will definitely worth a separate dedicated blog post. My first approximation suspects are: - better low-level primitives to build upon: `fxhash`, `parking_lot`, and our own `storage-map` - more aggressive caching, e.g. of render pass descriptors - less lazy state, e.g. we are eagerly binding vertex buffers instead of waiting for a draw call
or [`derive_more`](https://github.com/JelteF/derive_more)
I think a btreeset where i store the score in the user struct, so i can sort my btreeset on the score.
Hmm, after thinking about it a bit more, I also think a btreeset would be useful, where you would put the score in the user struct, and sort the btreeset on that. This would mean reinserting on score updates, but that wouldn't be hard to guarantee if I made the struct immutable, and made it consume itself upon changing the score.
&gt; such as a new bot to let anyone apply issue labels and one to automatically manage PR rollups to aggregate CI runs. For managing the rollup, we've implemented logic for doing this in the [`git-topic-stage` crate](https://crates.io/crates/git-topic-stage). It basically takes a set of topics (PRs here) and manages a branch based on top of the target branch (`master`) and handles updating when the base changes, a PR is updated, conflict notification, etc. I admit it could use better documentation, but I can prioritize that if Rust wants to start using it. I'm working on a command line tool that would work with GitHub Actions (and probably GitLab-CI too) to do this, but we're using it via a webhook-driven deployment right now, [`ghostflow-director`](https://gitlab.kitware.com/utils/ghostflow-director/) that works with GitLab and GitHub webhooks and interactions.
I'm not sure why you think modules and implicits don't preserve coherence. If you look at this paper: https://arxiv.org/pdf/1512.01895 &gt; Without such inference, Scala’s coherence can rely on the weaker property of non-ambiguity instead of canonicity. &gt; Uniqueness In order to maintain coherence, modular implicits require the module returned by resolution to be unique. &gt; In order to maintain coherence we must require that all implicit functors be pure.
Your code doesn't trigger any warnings from MIRI (you can find it in the tools menu), so while it might not catch all potential instances of UB, it at least suggests that your code isn't doing anything horribly wrong.
I'm sure formal logic doesn't say anything about the truthyness of non-boolean values. Rust does not allow such implicit type conversion for exactly this reason: It can lead to wrong assumptions and is generally not intuitive enough.
That's true that ES 3's \`with\` is even worst than the proposed one, but the ambiguity can also come with this one : with(some_val()) { with(some_other_val()) { .chain(); // which one are we chaining here ? .chain(); if some_condition { .chain(); } } } &amp;#x200B;
You can read a bit about this property of empty sets, if it interests you, here: &amp;#x200B; [https://math.stackexchange.com/questions/50873/assumption-about-elements-of-the-empty-set](https://math.stackexchange.com/questions/50873/assumption-about-elements-of-the-empty-set) [https://math.stackexchange.com/questions/50492/true-false-or-meaningless](https://math.stackexchange.com/questions/50492/true-false-or-meaningless) [https://en.wikipedia.org/wiki/Vacuous\_truth](https://en.wikipedia.org/wiki/Vacuous_truth)
I was especially referring about syntactic issues regarding the old \`with\` statement that was deprecated in ES5's (through \`strict mode\`) and basically removed\* in ES6. &amp;#x200B; (\* yes I know it's not completely removed since ES3 is valid ES6 but you can't use any of the new ES6 syntax at the same time as \`with\` so I'd count it as “removed”)
I was struck by the same thing, but my reaction is a bit different. Rust really doesn't make this intuition easy to pick up though with its choice to name "flat\_map" differently for each use case, and you shouldn't need an FP background to work with basic Rust types. * Iterators have "map" and "flat\_map" (and "flatten") - ok. * Future has "map" and "and\_then" even though it also has "flatten", so the name "flat\_map" would make total sense. Why? * Option has "map" and "and\_then" and no "flatten". * Result has "map" and "and\_then" and no "flatten". Beyond those basics, there are also arbitrary-seeming differences in the operations that are available. For example, if I want to ask, "is this Option a Some(foo)" (in a context where pattern-matching would be awkward), why do I have to do ".iter().all { |o| o.is\_foo() }" instead of having "all" (or even an equivalent) on Option? It really feels like in the name of a more intuitive/less-FP-centric interface, Rust has made itself harder to learn even for people with zero FP background, because you have to approach each monad separately and learn the operations all over again. And if you have no background with monads, none of them (except maybe iterators) will be intuitive! Meanwhile, if you have even a modest FP background (like me), having to remember which name works where is pretty annoying. Fortunately this is a fixable error: I see no reason "flat\_map" can't be a working alias everywhere! (Note this isn't an argument that "Rust needs monads" in the sense of some generalized monad abstraction. I accept that Rust's type system is designed with different goals. But that shouldn't preclude helping people recognize the common patterns among things that are, in fact, monads, because that makes reasoning easier even if you're never going to touch any higher level of abstraction.) &amp;#x200B;
Not every web request necessarily accesses the DB, accesses the *same* DB, or requires the same commitment to the DB (in terms of query time, etc). If you looked at 1000 identical requests, each with an intensive DB access, then, sure, multithread it because it won't make a difference, but, it is rather short-sighted to think that this is the *only* way that developers utilize a database.
There's a great talk by withoutboats that explains this in detail. It starts about 40 minutes into this video: https://youtu.be/AI7SLCubTnk
I haven't actually used Futures in Rust, but I've written a lot of Scala code with Futures (specifically the Twitter variant). In the Scala context I find them a pretty ergonomic abstraction (and notably easier/higher-level than thinking about threads). But it seems to be the general consensus that Futures in Rust are very un-ergonomic. If anyone here has experience with both Futures in Scala and in Rust, I'm curious - do you find Scala Futures awful too? Or if not, what makes Rust Futures worse? I understand that the zero cost goal can impose some limitations, but how does that manifest concretely in usability?
&gt; Without such inference, Scala’s coherence can rely on the weaker property of non-ambiguity instead of canonicity. I don't buy that this is coherence. You should still have the `Set` problem since you can encode funny business such as: ``` trait Add[T] { def add(x: T): T } object Main { def add2[T](x: T)(implicit s: Add[T]): T = s.add(x) object alpha { implicit object A extends Add[Int] { def add(x: Int) = x + 1 } def foo(x: Int): Int = add2(x); } object beta { implicit object A extends Add[Int] { def add(x: Int) = x - 1 } def foo(x: Int): Int = add2(x); } def main(args: Array[String]): Unit = { println(beta.foo(alpha.foo(42))); } } ``` (Yes, I know GHC can be made to accept this as well with orphans which is why they should be refused...) &gt; For their own design: I only skimmed the paper but it seems quite similar to Scala's design and from what I see I should be able to encode the above scheme in modular implicits. I think for practical purposes everyone means canonicity ("global uniqueness of instances") by coherence.
Thanks! 
How big of a DB connection pool are you going to have that will exceed a reasonable number of native threads on your frontend server? Sure you can make the argument that you have a front facing raspberry pie backed by a mysql cluster of 100 servers each allowing 200 connections. So the pie either needs 20000 threads or needs to be async all the way from front to back. But in almost all situations you will easily be able to run enough threads to keep the DB redlined.
/r/playrust
If we treat it as the sugar it is, we can say that the `with` block introduces a new local variable `with$`(because `$` isn't a valid character for a variable today), and then your double with becomes: { let with$ = some_val(); { let with$ = some_other_val(); with$.chain(); with$.chain(); if some_condition { with$.chain(); } } } And it is obvious that there is no ambiguity; the innermost with expression's binding is the one that's modified.
I had this crazy idea tonight of writing a terminal shell as a web component written in Rust that could be used to launch other web assembly modules. The idea is to have a simple html: ```html &lt;wasm-shell module="../../wash.wasm"&gt; &lt;command module="helloworld.wasm" name="hello"&gt;&lt;/command&gt; &lt;command module="goodbyeworld.wasm" name="goodbye"&gt;&lt;/command&gt; &lt;/wasm-shell&gt; ``` That will embed a terminal shell in your browser. The executed apps communicate with the shell to put characters up on the screen. The executed apps also have the capability to get the root DOM element of the shell and create "child windows" with DOM elements, giving the capability not just for text apps but visual apps.
I had this crazy idea tonight of writing a terminal shell as a web component written in Rust that could be used to launch other web assembly modules. The idea is to have a simple html: ```html &lt;wasm-shell module="../../wash.wasm"&gt; &lt;command module="helloworld.wasm" name="hello"&gt;&lt;/command&gt; &lt;command module="goodbyeworld.wasm" name="goodbye"&gt;&lt;/command&gt; &lt;/wasm-shell&gt; ``` That will embed a terminal shell in your browser. The executed apps communicate with the shell to put characters up on the screen. The executed apps also have the capability to get the root DOM element of the shell and create "child windows" with DOM elements, giving the capability not just for text apps but visual apps. The shell code actually wasn't even that hard: https://github.com/web-dom/wash/blob/master/src/lib.rs here's an example of a web assembly app that can run within the terminal ``` use wash_syscall::*; #[no_mangle] pub fn main() -&gt; () { print("hello world!\n"); } ``` `wash_syscall` is the library for making system calls out to the shell let me know what you think! My plans are to: * create a virtual file system that apps can access with easy upload/download * create a compiler that runs in the shell
We use it a lot in our System76 projects. It's basically a requirement for managing GTK applications, and forces you to keep widget construction organized.
I love this series, it is hands down the best explanation of rust code. &amp;#x200B; But the volume goes from almost silent to loud constantly. This is a serious issue.
Seriously, I've just realized it and opened Reddit to check if someone replied about it :D I should've checked that I am actually enforcing invariants expected by ManuallyDrop: to drop it manually, always... Thanks anyway - this is pretty important point even though it's not technically unsafe.
The major problem with Futures in Rust is the type system and the borrow checker. Often, you have to sprinkle clones, Box, Arc and Mutex all over your code to get things to work, including boxing returned futures. Just having two different branches retuning a different future is a pain. This all adds up to a lot of manual overhead that makes things cumbersome. Combine that with endless, confusing error messages (think C++ templates) that often make it very hard to figure out what's wrong and force you to seni-randomly fiddle around with code until it compiles. Impl trait return types helped a little bit but not nearly as much as was promoted. Async await will probably help quite a bit with some things like borrow checker issues but won't make them go away. We can expect async await to help but it by no means will make all problems go away. Using it will still require more competence than in other languages. Promises are painless in eg JavaScript because of the lack of static typing, GC and lack of parallelism (single threaded) . I did use futures in Java and Scala too and again the type system, lack of Send/Sync restrictions and the GC make things a lot easier. We will have to wait and see how things develop.
I was thinking the same thing.
This is very cool. I'll have to think about what one might do with it. Code fences don't work with Old Reddit Markdown. Suggest using four spaces before code instead. Also, that HTML line is quite long…
Thanks for the tip!
Why does it depend on [ezomyte](https://crates.io/crates/newtype_derive/reverse_dependencies?page=2), a library for Path of Exile API?
Tried it myself before posting, but I was still worried about special cases more experienced Rustaceans could know about, that may not be triggered by simple usage like in playground above. But "isn't doing anything horribly wrong" sounds good anyway :)
No offense taken :) I use ReactiveX (rxjs and RxJava/RxKotlin), so assume I have some basic knowledge. I enjoy using futures and chaining promises in other languages, but the problem in Rust is that it often feels like you need to know very advanced features to use them. `dyn`. I still don't really understand when to and when not to use it `impl Trait` has made returning future types easier, otherwise `Future::Map&lt;Future::Chain&lt;something&gt;&gt;` errors are pervasive. These are what I imagine most of us struggle with. Ignoring thread safety (which Rust helps with), a mere mortal like me would want to be able to: ```js let mut value: i32; let fut = my_future.map(|f| f.to_i32()); // sort of possible, unless the crate explicitly wants a runtime value = fut.wait(); // some runtime value = tokio::runtime::Something(fut).unwrap(); ``` We don't always want stuff to propagate all the way up. I want to get a handle to a connection which I can use to create new futures, which I'll propagate up in their context.
But at least the 2 cases you mention are already possible. For 1 you can easily change the backend. And for 2 you can create your own logger that logs to a `String` and at the begining of a test do `log::set_logger(&amp;MY_LOGGER)`
Oh, I dunno. I get paid extremely well..
Moreover `consume( Foo::default() .chain() .chain() .chain() .chain() );` looks so ugly. Why not `Foo::default() .chain() .chain() .chain() .chain() .consume();` like Dlang ?
Like this, I think? &lt;wasm-shell module="../../wash.wasm"&gt; &lt;command module="helloworld.wasm" name="hello"/&gt; &lt;command module="goodbyeworld.wasm" name="goodbye"/&gt; &lt;/wasm-shell&gt; and use wash_syscall::*; #[no_mangle] pub fn main() -&gt; () { print("hello world!\n"); } 
Won't that interfere when running multiple tests? What if I want to log only parts of my library by providing said part a string output but not to other parts?
Slog is quite cool, but it doesn't appear to be standard, has its own \`Record\` type similar to \`Log\`, thus not making it easy to change out
We're currently rewriting our service from Scala to Rust in https://prisma.io and will definitely need to turn on the async execution in the upcoming months. We've been thinking to just use blocking and threadpool for now, but I saw your `tower::Service` implementations for certain databases, it would actually make sense to join forces and we could help with writing them for the databases we need to support, which are postgres, mysql and mongodb for now. We're not really there yet, everything is under construction. But some of our work might be usable for others already. [prisma-query](https://github.com/prisma/prisma-query/) is an abstraction and a DSL over SQL statements and a part of the upcoming [prisma server](https://github.com/prisma/prisma) rewrite. We need to dynamically generate complex SQL and there was no proper crates to do that when we started. Diesel expects static schema you already know, but our schemas are kind of dynamic in this level of abstraction. The crate takes ownership for everything now like a boss, knowing our architecture at this point, but it already gives you an easy parameterization and trait implementations for different databases, so you get an SQL string out with parameters implementing the right trait so you can just pass the results to the conncetion adapter. Our first priority is sqlite, but postgres will follow soon and we're trying to make the database story for Rust better, it being our main business.
&gt; it doesn't appear to be standard Neither is `log`.
Nice.
The tiberius issue for me is as Jon describes; it takes self so I cannot save connections somewhere for reuse.
Yeah it's unfortunate, might be cool to have a trait in std so we can all orient our loggers toward it. But logging is hard with many variables and moving parts.
I was also trying to use this for crud, but keeping the connections was a big headache and I ended up using odbc with r2d2. I'm also in South Africa(Centurion) if you want to chat. 
Yeah, Rust is not very consistent here. I think one day when we get HKT we'll create RustyCats or something like that :)
&gt; You should still have the Set problem since you can encode funny business such as: That is an example of non-canonicity, not incoherence. The paper talks about this (I urge you to give it a thorough read instead of skimming it): &gt; Scala supports overlapping implicit instances. If an implicit parameter is resolved to more than one definition, rather than give an ambiguity error, a complex set of rules gives an ordering between definitions, and a most specific definition will be selected. An ambiguity error is only given if multiple definitions are considered equally specific. This can be useful, but makes reasoning about implicit parameters more difficult: to know which definition is selected you must know all the definitions in the current scope. Our proposal always gives an ambiguity error if multiple implicit modules are available. So yeah in OCaml's case that would be an error. In Scala's case, the choice of implicit is well-defined. It might not end up picking the implicit you want (if you don't know how to rank the definitions), but that's a programmer error. This is very much distinct from Haskell's IncoherentInstances where the compiler can pick _any_ instance whatsoever. In any language, you can certainly define APIs (by mistake) which allow the user to mess up the invariants for your data structure. In OCaml and Scala, the correct way to define APIs so that such that the Set problem doesn't arise, is to keep track of what instance was used to create the Set in the types. &gt; I think for practical purposes everyone means canonicity ("global uniqueness of instances") by coherence Well in Rust-land/Haskell-land, that certainly seems to be the case. I've also seen the same happening in some Scala discussions. That said, I personally think we should prefer to distinguish between related-but-distinct terms, especially when we're having these sorts of discussions, where the distinction matters. My reading is that Yang's article is advocating for the same.
I agree than Rust needs a set of database connectivity traits first and foremost. One sync (that can be stabilized earlier), one async (that can evolve in lockstep with the core language async support). Ideally switching the RDBMS behind the application should require changing just two lines: one in `Cargo.toml` to load a different implementation crate, one to instantiate a different driver. Everything else should be created by the driver.
Looks great, one of those things I've always thought about implementing but never got around to it. Thanks!
You can do like shown below `and_then()` returns a tuple where the second argument is the connection. I see they even updated the [documentation with this.](https://docs.rs/tiberius/0.3.1/tiberius/#a-simple-example) let fut1 = conn.and_then(|conn| { conn.exec("DELETE FROM somtable", &amp;[]) }); fut1.and_then(|(_,conn)| { let conn: SqlConnection&lt;Box&lt;BoxableIo&gt;&gt; = conn; conn.exec( "INSERT INTO () VALUES ()", &amp;[]); Ok(()) });
I miss the drawings from Lin Clark. Would be helpful for me!
This is a really awesome. Did you see [https://twitter.com/spacekookie/status/1108805890990395392](https://twitter.com/spacekookie/status/1108805890990395392) ? I'm generally interested in getting a db-wg off the ground. Maybe you wanna DM me to coordinate?
&gt;The things is, futures is not the best way to solve it. Or more correctly, is not fun to use futures. I agree that they are not fun, but that doesn't mean it isn't the best way to do it. As for people not needing async. Sure, it's a pain for them, but you can wrap a futures-enabled crate into a blocking one, but the opposite is not possible. Look at reqwest and hyper for a good example.
Finally, resource-efficient alternatives to java apps. Thanks for doing this, I’ve been waiting for it for the last 10 years.
It is open source? 
The link provided is the Github repository.
Thanks for the link! Is there a comparison somewhere with Tantivy? https://github.com/tantivy-search/tantivy
It uses the Mozilla Public License, but slightly modified to prevent commercial competitors.
Thanks for the sample. What I want is more of a connection pool that I can create when my server starts. Connections will be used by a web service. Somthing like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9b6b286eec93d860ece9cb561f915195). The issue I keep running into is that the exec function takes self, so I cannot use refs.
Thanks! Seems to work :D
More importantly the linked repository has an open source license.
The source is available, but [its license](https://github.com/valeriansaliou/sonic/blob/master/LICENSE.md) is restrictive, for instance &gt; it is forbidden to sell a service that builds its core value on the software and &gt; you are not allowed to build an Algolia competitor based on the licensed source code
It has restrictions that make it not open source, in the same way that the JSON.org license that bans use 'for evil' make it a non open source license
Isn't Free of use and Open Source differents things? What I understand here is that it's open source but not totally free of use.
That's a pretty important modification.
Hi! Sonic is not comparable to Tantivy. We focus on simplicity and doing few things as fast as possible with the minimum resource footprint. If you are looking to get reliable results with minimum index size on disk but retrieve documents for matches from an external DB, look at Sonic. Otherwise look at Tantivy, which is more advanced on its query engine and seems to store documents (not sure about this one though).
Ok! Thanks! Tantivy indeed stores documents just like Lucene
It's a political argument usually. I think FSF would call this a "source available" project. Tbh, I'd just call it a project with a license that ensures it won't develop real traction. Though happy to be proven wrong on that 🙂
&gt; dyn &gt; . I still don't really understand when to and when not to use it &gt; impl Trait &gt; has made returning future types easier, otherwise &gt; Future::Map&lt;Future::Chain&lt;something&gt;&gt; &gt; errors are pervasive. These are what I imagine most of us struggle with. This is not something Future related, but rather a general issue we have in Rust. It's simple: - use impl when you can - you can't use it when you define a trait method however (compilation error) - you will be able to use it in traits with 'existential types' when the smart guys implement them - for the time being just Box them when you cannot use impl &gt; Ignoring thread safety (which Rust helps with), a mere mortal like me would want to be able to The problem extracting value from the Future (in any language) is that you need to block the thread. And to do this you need to be absolutely sure you are aware of where your futures execute, which threads - otherwise you'll get a deadlock eventually. I think you can avoid extraction by implementing your own future type where you can control polling yourself, checking if underlying connection's future is ready or not.
I've ran into a similar problem once (not in Rust though) and found that this is a pretty fast solution. Sorting algorithms are crazy fast and it was a lot faster than using HashMaps or binary trees.
In my opinion, using an external data storage for your docs is generally a good idea. Tantivy does ship with a docstore but I'd actually recommend to use another DB if you have a very serious usage.
Assuming you already read the license- may I request you to not help perpetuate the hijacking of the term open source? You may use "permissible license" instead 
It's not.
Was already posted here: https://www.reddit.com/r/rust/comments/b3e4xn/sanakirja_pure_rust_database_backend_gets_its/
Personally I try to write scripts that only assume POSIX compatibility. Much of GNU's extended functionality can be considered bloat and/or redundant.
Free software and open source are different, but the differences are very small. This is neither free software not open source.
There are other json serializers/deserializers than just serde. The [json](https://docs.rs/json/0.11.13/json/) crate claims to be about as fast as serde directly parsing to structs (see the [performance](https://github.com/maciejhirsz/json-rust) paragraph).
[removed]
Strip the debug information - it should reduce the executable size quite a bit.
+1 on using AGPL for this
This is exactly why I mentioned that I compiled it with --release... Anyway, I tried `strip` and now it's 3.4MB -&gt; 700KB for windows and 2.4MB -&gt; 200KB for unix systems... Thank you. I remember now. On Windows, it would use special files (MSVC specific) to store debug info separately so I'd never have to strip anything ever and I completely forgot about it, though that's still very weird that release mode executable has debug symbols...
I actually feel the opposite. It's _great_ that a release executable has debug symbols by default - disk space is cheap, and time is expensive, and getting a proper stacktrace when the release build of your app crashes is often worth _a lot_ of time.
Just genuinely curious OP - why do you need such small executables? 
I'll just make a PR real quick that appends a 10 hour rickroll video to the end of compiled executable so that rust toolchain and executables it produces aren't too small.
I don't really know what you're talking about, this seems like a problem in a big enough projects, big enough where 3MB executable in fact would make you go "wow, so small". If anything, it should be opt-in, or cargo itself should have a strip option.
That's unnecessarily rude/snarky for a legitimate question.
What, the debug info? I've yet to see a Rust project with "huge" binaries honestly. Even rustc itself is like 10MB with all the debug info.
What's really rude is to pretend that it's ok for your executables to be in tens of MB's when they are literal "Hello world" printed in your shitty terminal.
That'd be awesome!
No one is pretending anything. They asked you a question and you're being quite aggressive about it. Please take a step back and reassess the situation.
Let me ask you this. Why are your images always stored in png or jpeg formats and not bmp? What's the point really? If you can answer this to yourself then the question prior to this is invalid, and in fact I don't care what you think. 
That's beside the point. The point is you're being flippant for no good reason. This helps noone.
That's 10 times as much as gcc. If that doesn't ring the bell then nothing will.
Yeah, because gcc's executable is basically just a wrapper around a dynamic library that's actually huge for unrelated reasons.
The problem with putting stuff like this in std is it's way harder/less advisable to change std. Futures did it mostly right, where it's gone through a few iterations very publicly. It is very much the standard library for futures, to the extent that the upcoming async/await language keywords are oriented towards them (and might only support them? Haven't done enough research), but even still they're not standard because Rust isn't exactly sure how they'll end up.
Despite OPs undue rudeness, one possible solution is to provide debug=false in the cargo.toml for profile. release https://doc.rust-lang.org/cargo/reference/manifest.html Afaik this still leaves stdlib debug symbols however.
Is there a reason you’re skipping ludicrous and leaping straight to plaid on your asshole mode setting? There’s good reason to ask _why_ you want smaller binaries; the specific answer to that question might point at specific solutions / workarounds. Though I can empathize with your inability to see through that enormous chip on your shoulder.
Unrelated reasons, such as the fact that you can have multiple versions, use, for the most part, exact same dynamic library. But of course, since HD space is so cheap, fuck dylibs, compilers and even OS'es (thanks to Rust community's logic, hopefully not) will be 100 times more bloated because everything will be embedded into executables and on top of that have their own debug symbols inside. Let's bloat the basic ~20GB installs to 2TB just for the OS, especially when rust is supposed to be one of those languages used in low level system programming, right?
All you can argue is about "someones tone" and not the topic, that's your exact problem, keep your issues to psychologist and yourself. kthx.
&gt; Unrelated reasons, such as the fact that you can have multiple versions, use, for the most part, exact same dynamic library. Not how it works with GCC - the dynamic libraries are versioned together with the compiler and don't have a stable API _or_ ABI. &gt; But of course, since HD space is so cheap, fuck dylibs No one said that, please stop extrapolating. &gt; everything will be embedded into executables Rust supports dynamic linking. &gt; and on top of that have their own debug symbols inside. You can strip those, my point is that it's generally not worth the tradeoff. &gt; Let's bloat the basic ~20GB installs to 2TB just for the OS You're seriously overestimating the file size of debug information.
I'm going to use Tesla modes as my scale from now on
Read again that bit about disk space being _cheap_ and time being _expensive_. It’s been a _long_ time since the average system’s resources made the trade off you’re making actually _usually_ worth it.
Any reason you didn't use Option and RefCell instead of ManuallyDrop and UnsafeCell?
Heh. That’s Spaceballs scaling... Elon’s not what I’d call original.
I feel the same. Thanks!
It only has debug symbols for `std`. I'd actually prefer if the `release` profile had `debug = true`.
The `release` profile has debug info disabled.
Oh snap. I was \*just\* looking for something like this! I will have to investigate more. I don't suppose you could offer some example code for those who know nothing about search engines? :D
Oh I figured it was not since they were getting the debug symbols. But I assume that is just what comes from the stdlib then?
I guess you could run tests with `cargo test -- --test-threads=1` or using a global mutex, and then filter events based on https://docs.rs/log/0.4.6/log/struct.Record.html and delegate to other logger.
[https://www.rust-lang.org/policies/code-of-conduct](https://www.rust-lang.org/policies/code-of-conduct) :)
Welcome to the wonderful wide world of operating system development. :D It looks like tons of fun. Keep it rolling!
/r/playrust
I was a bit confused because this post was the top level, and the original post didn’t seem bad at all. Then I scrolled down and saw the replies.
Yeah, most likely.
I haven't experimented with wasm at all yet, but could somebody explain why wasm binaries in the git repo are this big despite only using a print syscall and not importing anything else? Even when I built it on my nightly, both helloworld.wasm and wash.wasm are around 800k and 900k. What exactly takes up that much space and what can be done about it? wash-syscall does use Vec, could that the reason?
I'm not so sure about that. There's plenty of people and companies using proprietary software with even more restrictive licenses then this. If you can use this as a drop in replacement for an elasticsearch cluster and it's much easier to manage then elasticsearch, then I see a lot of companies using this. As someone who has helped administer elasticsearch clusters at my last 2 companies, I can tell you that managing and ELK stack is no small feat. Elasticsearch might be extremely useful and fantastic software, but that doesn't make it any less of a hairy beast to manage. Most startups don't need all the elasticsearch features too
Rust on PC on PS4
What about [Toshi](https://github.com/toshi-search/Toshi)?
I'm not too familiar with it, but this pages has some tips on optimizing wasm for size: [https://rustwasm.github.io/docs/book/reference/code-size.html](https://rustwasm.github.io/docs/book/reference/code-size.html)
This could be prevented by enforcing that orphan implementations must be in a separate module, so if there are multiple implementations in your dependencies, you can choose which one you want to `use`.
Sweet! Any plans to add something akin to ES’s distributed shards to provide scalability?
It's possible, but not desirable. 
Repost! The author of this post already posted this here: https://www.reddit.com/r/rust/comments/b3j818/rust_the_hard_parts_part_one_references_borrowing/
You're absolutely right about this, it's hard to figure out what's truly shared by all loggers. But we have a solution that's adequate for now.
Ok, will remove. Thanks.
Sure! What would you need to see exactly?
I think the feature you're interested in is [specialization](https://github.com/rust-lang/rfcs/blob/master/text/1210-impl-specialization.md), which is still [WIP](https://github.com/rust-lang/rust/issues/31844).
(You may open an issue with detailed information about your needs and I’ll see what I can do about it as to document them)
Not yet, as this adds a lot of complexity. But that’s an idea for the future. I’d like to keep things simple as eg Redis does it. My first focus is on improving performance and search relevancy even further, then I’ll handle the high availability part I guess :)
We just do this because we don’t want to see people making a business out of Sonic’s core value. It’s permissive though, but maybe we should have been more explicit about that part. I completely support OSS and my other Rust projects are fully non-modified MPL 2.0; this clause was necessary due to internal concerns.
Oh yeah, I think specialization could help, but the problem is can I deal with overlap in my case...
Device: Samsung Galaxy Tab Firefox: 25 fps with 100 ferris, 3 fps with 1000 ferris Chrome: 60 fps with 100 ferris, 20 fps with 1000 ferris 
thanks :D
I wonder if this is a good idea. CSS uses specificity to do the same thing and most of the people I've worked with who use CSS every day have no idea about specificity and thought it was just cascading.
This was posted in the wrong subreddit tho. 
Well, I implemented first version like this and then I tried to shave off as much indirection as possible... Technically, I could use Option (when wrapping non-null pointer, it optimizes into null pointer, doesn't it?), but because Cell requires Copy and RefCell adds overhead, I decided to use UnsafeCell - truth is, I should have probably done some measurements before doing any conclusions about performance...
Possibly. It allows some types of overlap, but the rules were never perfectly clear to me. The simpler workaround I always use is just creating wrapper structs for the different impls and the ln requiring callers to use those. In your case something like: struct Val&lt;T&gt;(pub T); struct Ref&lt;'a, T: 'a&gt;(pub &amp;'a T); struct Function&lt;T: Fn(&amp;T) -&gt; bool&gt;(pub T); And then `impl`s for your trait for each of those structs.
`Cell` doesn't actually require `Copy` any more to do what you want; you may be reading some old tutorials or whatever. Only `Cell::get()` requires `Copy` now. `Option` impls `Default` for all `T`, so you can just do `cell.take()`. This is just shorthand for `cell.replace(None)`. This would allow you to replace both `UnsafeCell` and `ManuallyDrop`, which I think makes your code totally safe. First rule of unsafe is don't use it unless you actually get a benefit.
Haha sorry, I can imagining it does pay well, I just have bad memories of working in that field.
Why do big companies avoid AGPL?
The reason for the complexity increase in the type system mainly comes from the need to model the complex/dynamic types that are prevalent in the JS ecosystem. It's become much easier to write good typings. I do agree though that the type controtions can become hard to understand.
When they say rust is a systems programming language, it just means it is suitable for that purpose. It doesn't mean you can't use it for other things, and indeed it's used for lots of projects and products outside of that domain. Do you need a degree etc? No. Many programmers are self taught. But you have to be a self motivated learner and be willing to admit when you don't know something, see that as room for improvement and keep learning. For reference I'm a developer at Apple and previously a supervisor at another studio with no formal education in programming. Does rust help your career? Maybe. There are very few rust jobs out there, and if you only know rust it makes you less valuable than a polyglot who knows other languages. I'd recommend at least learning one or more other languages that have more career viability. Can you contribute to the rust ecosystem as a beginner? Yes. You can make crates, write documentation, find and file bug reports, contribute to existing crates. 
How old are you? What country are you in? "going all in" is rarely a good choice. As for having no knowledge of systems programming: learn it like you learnt any kind of programming. People have some stigma about the word "systems" but at the end of the day it doesn't mean much without a clear context Contributing to open source helps you get a job, but not as much as you might believe. It helps you get a job by being a way to learn how to program with other people, good open source projects will give you experience with code review, software design, etc. It'll also help you make connections with people, who may one day help you advance your career. But that's long term, short term you need to focus on learning &amp; getting a job _somewhere._ I'm speaking as a programmer with nearly 8 years of experience &amp; no degree, I viewed accepting an underpaid job as being paid to go to college, X years of experience in the field will compensate for lacking X years getting a degree. You want X years of experience because programming professionally every day will teach you all the soft skills of this field. Programming is a very social field for all the anti-social stigma it gets. You need to learn how to have technical debate. It's only once you've built up those skills that you'll be able to take on opportunities. &amp; you can't try say you've got potential, people want to hire someone who has achieve that potential already
Congratulations! Sorry I've lost touch with the project. What are the plans for this crate? Will it maybe also be used inside the standard library?
&gt;Does contributing to open source help me to get a job ? You mentioned "where I come from". For most countries it will not help you much, if you are notcontributing to a large extent. No HR manager will read your CV and check your repository. Might happen, but less likely. Sayif you contribute large chunks of code to Servo (Mozilla) and if the company you aplly a job for needs exactly that, you would be considered maybe. But anything else, I doubt it. Without a degree and your life plan, maybe freelance work could be something for you. It takes the risk away from the company to hire a "problematic" candidate. Problematic in a sense that you have nothing realy on your CV to convince the company to hire you. A freelance job and/or internship may help to get a foot in the door. &gt;So how can I contribute to rust ecosystem with no knowledge of systems programing ? With the level of knowledge at the moment you probably cannot contribute much. Maybe you can find smaller crates and do bug fixing, maybe you have seen some code samplethat could be used instead of the current implementation and suggest a pull request (better, faster, safer implementation). I don't know where you live, but I think it'll be hard to find a direct way into a rust dev job. There arean't many jobs available either. It's a very young language, most businesses need years, maybe decades to switch from one language to another. Jobs decsriptions I find require usually a set of languages and rust may be one of them. &amp;#x200B;
Going all in on any programming language is not a good career choice.
Jesus, they were just asking a question... 
Thanks man! It is fun!
I see three questions: &gt; So how can I contribute to rust ecosystem with no knowledge of systems programming Yes, you can. Many project have issues for beginners and will help you learn. &gt; Is going all in to rust language a good career choice? Probably not. There are still not a lot of rust jobs in comparison to other languages, and even less entry level ones. So i wouldn't bet my career on it, at least not yet. But there is no shame in writing Python/Java/JS/Whatever for money and do rust for fun on the side. It can still be your secret weapon at work. If you are proficient in rust, you shouldn't have any problems learning one of the mainstream languages. &gt; Does contributing to open source help me to get a job This differs from company to company. Some look at open source contributions as references (which is problematic in itself, but thats beside the point here), some don't. But if you want to get into the industry without official credentials it certainly doesn't hurt to have a something to show.
I personally hope that eventually it will eventually become a lang item integrated into `std`/`core`, but dhardy is less [sure](https://github.com/rust-random/rand/issues/648#issuecomment-469395506) about that.
Here's a really short explanation: futures are to parallel I/O as threads are to parallel compute. If you want to write a function that does three I/O things, maybe transforms the data it gets back, and then returns it; you want to use futures. Otherwise, you have to: * Use sequential I/O and read your files one-at-a-time, which means poor performance (I/O devices love deep queues) * Simulate parallel I/O with many threads, which means more memory usage (thread stacks use more memory) * Use a lower-level primitive, such as callbacks, which means more code complexity (callback chains are ugly and hard to maintain) Futures give you low-overhead parallel I/O without the complexity of manually chopping your code up into little pieces.
Could you add few descriptive issues to the project? I’d be happy to contribute!
This idea gave: error[E0277]: no implementation for `{integer} | vulkan_drawer::shaders::OP` --&gt; vkwayland/src/vulkan_drawer/shaders.rs:190:19 | 190 | (2 &lt;&lt; 16) | OP::CAPABILITY, | ^ no implementation for `{integer} | vulkan_drawer::shaders::OP` | = help: the trait `std::ops::BitOr&lt;vulkan_drawer::shaders::OP&gt;` is not implemented for `{integer}` [https://github.com/cheako/smithay/blob/fd038fb6316f7f17958bf72db85829d0ab68ae91/vkwayland/src/vulkan\_drawer/shaders.rs#L189](https://github.com/cheako/smithay/blob/fd038fb6316f7f17958bf72db85829d0ab68ae91/vkwayland/src/vulkan_drawer/shaders.rs#L189)
Sure; this issue would be interesting as a starter: [https://github.com/valeriansaliou/sonic/issues/64](https://github.com/valeriansaliou/sonic/issues/64) Adding more details in this issue comments in a few moments.
Just having the license not be word-for-word identical to one of the licenses on the list the company has already paid their legal team look over is enough to cripple uptake.
You either need to cast to an integer first or implement `BitOr` for your enum. I think the documentation of that trait or the one of `std::ops` should have an example (only on mobile, or I would link to it).
"Open Source" is a term maintained by the Open Source Initiative and, while they're more OK with letting "open source" mean multiple things than the FSF is with "Free Software", most people mean "OSI-approved" when they call a license "open source". For that, they maintain [The Open Source Definition](https://opensource.org/osd), which is basically a more verbose, less ideological-sounding version of the same requirements embodied in Stallman's [Four Freedoms](https://en.wikipedia.org/wiki/Free_software#Definition). The Open Source Definition contains the following two criteria: &gt; 5. No Discrimination Against Persons or Groups &gt; &gt; The license must not discriminate against any person or group of persons. *(Ed. Note: "This statement does not apply for core project contributors.")* &gt; &gt; 6. No Discrimination Against Fields of Endeavor &gt; &gt; The license must not restrict anyone from making use of the program in a specific field of endeavor. For example, it may not restrict the program from being used in a business, or from being used for genetic research.
I wish you luck, but I have no interest in licenses which aren't OSI-approved and you're never going to get that past the "No Discrimination Against Persons or Groups" and "No Discrimination Against Fields of Endeavor" criteria of the Open Source Definition. I'll go looking for something AGPLed instead.
Are there benchmarks comparing it to ES?
Their definitions overlap such that all Open Source software is also Free Software, but not all Free Software is necessarily Open Source. But in practice I believe the real differences are very small to none.
That's pretty directly against the idea of Open Source, since the Open Source Definition explicitly says you must not limit the fields of endeavor the software is allowed to be used in. That means you must allow making a business using the software for it to be Open Source.
Can you send to the good one please? &amp;#x200B;
Cannot get the keypad to show on Firefox nightly for Android.
"Open source" is not a term that developed organically. It was created during the source release of Netscape Communicator (which eventually became Firefox) as a more palatable-to-management alternative to "Free Software" and the people who created it formed [The Open Source Initiative](https://opensource.org/). They have a [definition](https://opensource.org/osd) of criteria licenses must satisfy to be "open source" and they maintain a [list](https://opensource.org/licenses) of "OSI-approved" licenses which they certify as meeting the definition. Note points 5 and 6 in the definition. This license doesn't meet them.
No, there's none. It's an alternative, but it's not comparable apples-to-apples, the set of features Sonic provide is much more limited, and Sonic does store IDs. It's designed to index database identifiers (eg. to SQL primary keys); and does it in a compact and efficient way; ES has much more features. Though, you can look at the Benchmark section on Sonic's readme and compare for yourself Sonic's response time on queries, and ingestion times as mesured, and compare it to ES benchmarks on similar data with a similar setup and index size (1M records).
Done!
&gt;Open Source Definition To my knowledge, "Open Source" is not a registered label which constraint you to what you can call Open-Source. There is a sensibility to it, and mine tells me Sonic is still OSS. Though, correct me if I'm wrong, I'm taking criticism seriously and debate is important :)
The OSI is more permissive about the use of the term than the FSF, but you're the first person I've met who has actually taken them up on that. Everyone else I've run into has had an intuitive expectation that "open source" means either "OSI-approved" or "I have no formal definition, but my impression basically aligns with this Open Source Definition you just introduced me to". ...and, from there, that intentionally disagreeing with the OSI on whether your license is "open source" makes you a person to be wary of because who knows what else you might language-lawyer to benefit yourself at the expense of others.
I think I used serde_json because we already used it elsewhere in the crate. I am planning on comparing with the json crate in the coming weeks. Thanks
Sequential I/O is sufficient for many use cases that aren't performance driven. Parallel I/O with multiple threads (not many) with thread pools don't cause a significant amount of memory overhead. I've used callbacks in C and I've not hit multilevel callbacks (callback chains?) and while they are cumbersome they work for C where there aren't many other good options.
no, I didn't. I'll give this post a few more days then I'll get in touch with people who've shown interest
We have a meetup (https://www.meetup.com/Johannesburg-Rust-Meetup/events/gpxrtqyzgbfb/) which I'll be giving a talk at, Centurion might be a bit far, but it'd be great if you'd join us sometime. Though this will be my second time there
I am 21 years old and from India. People around me doesn't have any kind of interest in coding and they still get a job in corporate companies like Accenture, Infosys. It's like mass recruitment with only requirement of degree. I don't want to work with bunch of folks who are just there to earn money with no interest in coding.
Check the `cargo.toml` files to see if they both have `edition = "2018"`
&gt; It is basically 'let that = this' from JS. First things, first, that pattern is actually quite common in Rust due to lifetimes, but I don't think that's what's happening here. If you check the `Cargo.toml` for each project, you may find a line for `edition = "2018"`. If you do in one but not in the other, it means that the 2 projects are actually using slightly different languages. (not as big as python2 vs python3, but more than a small version difference) One of the consequences of this is known as NLL (Non-Lexical Lifetimes) which is only present on 2018. If project2 is on the 2015 edition (by not having an edition line), then it will attempt to resolve lifetime problems purely from the lexical structure of the code, which means it will borrow `self` for the method call, and then `self.shift` for the argument. In 2018 with NLL, the compiler will recognize that this isn't desirable and will flip the borrows to make it work. The simple solution is to bring project2 to the 2018 edition by adding the `edition = "2018"` line to `Cargo.toml`, though since it does have other breaking differences, you should probably run `cargo fix --edition` before adding the line.
Thanks! I will attend
Inb4 wash is made the standard shell for Nebulet. :P (Nebulet being an OS kernel with a userspace running entirely in WASM)
This was it! thank you so much!
That was it, thanks for the history too!
Interconnective data and memory management hardware components programmer. 
I think that having contributed to open source can be useful to show to future employers what you are capable of. It's just a different kind of experience you gain compared to working at a traditional company. 
I think that's a reasonable interpretation honestly. People are generally too dederential to the OSI in my opinion. With that said, if you aren't up front about Sonic being source available and not open source, then the zealots will never leave you alone, because the Internet is no place to be Wrong. For that reason alone, speaking from experience, I personally would just end the distraction and be upfront about this using the "proper" terms. (I have been pelted in the name of OSI before myself, so I know what it's like to be in your shoes.)
Hmm, can I use it without taking and putting value in every time I want to check if it is forced?
This page has it at 1.75 seconds https://benchmarksgame-team.pages.debian.net/benchmarksgame/performance/pidigits.html
I was assuming this page hasn't been updated yet.
Try reproducing the benchmark on your machine. Do you see a difference? rustup should make it easy to try with both 1.32 and 1.33. Perhaps another assumption is the the link you gave has a bug. :)
You want /r/playrust.
You might want to read a couple of posts on this sub-reddit and then consider if it's the right place to spam your server.
Thanks. How would you be upfront about it in "proper" terms? (your way, from your experience); would that involve being more specific in the license terms, or probably not labelling the license as "OSS", or else using the README as a way to be specific?
I'm about 90% certain this is experimental error caused by running it on different machines. I tried 1.32 and 1.33 on my mac and it moved from 0.647s to 0.643s (well within statistical error margins). GCC is 0.641.
The page in the OP also has it at 1.75 when you click the C++ comparison, and 0.60 for the 3 other comparisons. Perhaps the 1.75 pages are lagging behind the others, but I would put my money on the 0.6 results being incorrect somehow.
It took 1.528 seconds in Rust 1.33 on my PC. I don't know how to install Rust 1.32 though.
&gt; Perhaps another assumption is the the link you gave has a bug. :) Yes I think you are correct; it appears Rust's timing was copied for N=6,000 instead of N=10,000, and the correct value should match C's 1.75s runtime. Compare rust vs c in the OP's link to Rust `pidigits #3`vs c `pidigits` in the links below. [C benchmarks at multiple N values](https://benchmarksgame-team.pages.debian.net/benchmarksgame/measurements/gcc.html) [Rust benchmarks at multiple N values](https://benchmarksgame-team.pages.debian.net/benchmarksgame/measurements/rust.html)
In the README, I'd have, in this order: project name, brief few sentence description, CI badges, license info. In the license info section, I'd say, "This project is source available, and not open source. See our modified MPL license for more details." Since OSS is generally the default expectation, it's a good idea to go out of your way to make this point super clear. I might even mention it when linking to the project on other web sites. At least, that's where I would start. Then iterate as you get more feedback.
The 4 days old (as of now) version is. Anyone who really wishes an open source version could continue from just before https://github.com/valeriansaliou/sonic/commit/417c0468009f67e3a8b86428c0208ee4b776c2d7
To expand a tiny bit, for a good developer a programming language is just a tool. The question in the title is analogous to asking a carpentry subreddit whether "going all in to hammers" is a good woodworking choice.
Your comment reminded me of http://www.jasonbock.net/jb/News/Item/7c334037d1a9437d9fa6506e2f35eaac
\&gt; Does contributing to open source help me to get a job ? &amp;#x200B; In my (somewhat limited) experience hiring candidates I would say absolutely. You would be surprised how many professional programmers have very little public work available for any sort of review. And I think of my own open-source work as the strongest part of my resume (I don't have a degree).
Alternatively you could just have a thread-local logger
It’s off topic there too, they want /r/playrustservers
Is Wash supposed to stay a terminal shell, or will it cover full [terminal emulator](https://en.wikipedia.org/wiki/Terminal_emulator) use cases in the long run ?
ive had many hiring managers check my repo 
&gt; Possible explanation seems enum tag at the beginning and then aligned value This is correct. The size of a type generally needs to be a multiple of the largest alignment that it contains, so that arrays don't require additional padding.
OSI introduced the term, so they get to define it. Also everyone else has accepted their definition ... it's not like there are two camps here. I seem to remember at the time it was introduced, that there was talk of a service mark to reserve its meaning, but now I can find nothing on that. So perhaps it wasn't possible to legally protect the meaning of the term from misuse. Okay, [found it now](https://opensource.org/pressreleases/certified-open-source.php).
Makes sense, thanks :)
Nah, don’t think so, I’m just going to make something that makes executing wasm easy in browser. I’ll probably borrow a lot of ideas that could allow someone else to write their own emulator as an app.
You have it reversed (mostly; there are a few exceptions for licenses which are FSF-approved but not OSI-approved) -- [here's a wikipedia article with a table of licenses and their approval status](https://en.m.wikipedia.org/wiki/Comparison_of_free_and_open-source_software_licenses). You might not saddle your definition to the FSF and OSI, and that's fine, but it is the case that the definition of open-source is slightly more open (than the definition of free software) in a manner which makes it more palatable to commercial applications. In practice, though, I do agree that most people tend to use the terms to mean roughly the same thing.
You don't have to re-sort the list at every insertion. Instead you could do an insertion sort. Use binary search O(log(n)) to find the insertion point, and then the insert in a vector takes O(n/2) time. This is faster than O( n*log(n) ) for qsort.
I'd love to have a standardized interface that works for all relational databases. It's a pity the ecosystem around DB is so fragmented: In Java, all JDBC drivers can be used in the same way. I heard that Go uses a similar approach. I'm currently working on a Spring Boot app on my job. It does have its downsides, but it works better than diesel IMHO. Also, diesel only supports 3 databases (mysql, postgres and sqlite), which I think is a shame.
Open Source was originally planned to be a registered label with a reserved meaning, but it appears that it took off before OSI could get a trademark on it. Still, they introduced it, and their meaning is what is generally respected. It didn't have any meaning at all in the software world before they introduced it and popularised it, so you can't claim you're using it in some prior sense.
Recently [MongoDB and Redis switched away from AGPL](https://www.zdnet.com/article/its-mongodbs-turn-to-change-its-open-source-license/) precisely because it didn't prevent companies like Amazon building profitable services without paying anything back. They got an awful lot of pushback from the community, so I don't know if those changes stuck, but even if they went back to AGPL I'm sure they'd still like to get away from it.
I'm pretty sure back end devs just hate stuff they cannot care to learn to use, since back end is more important than front :D
The problem is that I want it for single function to accept various forms of predicates, so even if I'd make separate types, I wouldn't have conversion for all possible generics. Which then defeats the purpose :)
How can I put a struct in a hashmap where the key is a reference to one of the struct fields? For example this does not compile; use std::collections::HashMap; struct Foo { name: String, bar: i32, } fn main() { let mut hm = HashMap::&lt;&amp;str, Foo&gt;::new(); let foo = Foo { name: "foo".to_string(), bar: 1 }; hm.insert(foo.name.as_str(), foo); }
I'm well educated on the topic. I never said there were two camps. My previous comment should make it abundantly clear that I'm not interested in a debate. I commented only to commiserate with someone else being pelted for this.
The single most important thing you can do to make sure you have a successful career is to set yourself up as a committed, lifelong learner. If you’re excited about Rust right now, then I think you should go all in on Rust and learn it to the maximum. I agree with your assessment that many folks (in India at least) are getting degrees, getting jobs at large corporations, and not really committing themselves to the craft of programming. In the LONG run, you will have greater success by cultivating your passion in software development. If that means Rust right now that’s perfect. Stay curious and don’t fear learning the next thing when it comes along. Other in this thread are correct that there aren’t as many Rust jobs out there right now, but here’s a secret: Software Development is a global market, and being in India gives you an advantage: your cost of living is less than most, so you can charge less than most of the other Rust developers out there. I made $155,000 USD last year as a salaried employee working on Rust for a company in another country. I work from home. You could likely charge *way less* than that and live comfortably at this early stage of your career. Later in your career, if you stick with it and constantly develop your skills, you can reasonably expect to make over $100K USD, but only if you're constantly improving and learning. Some specific advice: 1. Yes learn Rust and contribute to open source as a way to improve your skills. 2. Develop some domain expertise. This could be: Cryptography, machine learning, web apps, GIS, etc etc. It doesn’t matter what it is, but having a specialty will help. 3. Make it known on your GitHub profile that you’re looking for work as an independent contractor. Make a website for the same. Make it clear you are *affordable*. 4. Work on improving your written English. If you want to break out and work in the international market, you’ll need excellent written English skills. 5. Feel free to PM me directly if you have any other questions etc. 
First of all, thanks for releasing this under whatever license: it looks pretty great for a lot of applications. I understand that you're trying to do the best for your community and your contributors. Did you have a competent IP attorney review and draft your modification to the MPL? To be perfectly honest, it doesn't look like it — if not, I would strongly recommend doing so. If you want a recommendation for somebody good I'd suggest contacting the Software Freedom Consortium or the Electronic Frontiers Foundation to see if they can recommend anyone they think knows the ropes. I am not an attorney, but I've spent several decades working with and understanding open source IP law. As the license stands, I am skeptical that the modification would be worth anything in court: it looks to me to be just causing confusion and threat for no actual gain. In particular, as others have pointed out, "core value", "core contributor" and "Algolia competitor" are pretty slippery propositions. I wouldn't want to go up against a tech giant in court with this thing; then again, I wouldn't want to go up against a tech giant in court *at all,* which is what this invites in my opinion. Speaking just for myself, I am not choosing to investigate this promising-looking project for an application I have because I don't want to get involved in some potential legal mess in any of a dozen ways that I can imagine off the top of my head. To pick just one example: if somebody forks *my* project and violates the terms of your license, I am now "in the middle" and likely to be named as a defendant or called as a plaintiff witness by one or both sides of an infringement suit. tl;dr: Please seek legal help from an attorney demonstrably competent in open source IP law. This is a cool project, and I would hate to see it lose out because of a silly licensing mistake.
toshi uses tantivy
There're actually two parts of it: 1. Currently futures-state-stream is used, which has and will have several downsides. I'm not quite decided on which approach will work best for the future and will probably just wait out until async-rust matures a bit more and how different approaches (e.g. tokio-postgres) work out. 2. There isn't really much progress on async-conn-pooling yet: https://github.com/sfackler/rust-postgres/issues/233 I anyways won't have the time for some of the big changes I'd like to see implemented until end of the year.
lol, can't argue with that =)
I agree 100%. Open-source work is a *magnet* for recruiters. 
Sorting algorithms may be really fast, but they're still not linear. Given a big enough array it's inevitable that a solution using `HashSet` will win out.
Sure, one is https://levien.com/xw/ok_17.cnf .This takes 41s with glucose-3. In the same dir, ok_21.cnf takes 14s. I wasn't able to build varisat, I got errors about ``use of undeclared type or module `alloc` ``. This is even with nightly.
Thanks for the nice writeup, it clearly shows how to write a useful procedural macro, while making it seem almost pleasant. :) The usage reminds me of Lisp's `DEFMACRO`, with the `quote!` macro having the role of the backquote operator, and with the `#` inside it being equivalent to Lisp's `,` inside the backquote. On an unrelated note, places like this is another area where const generics would help **a lot**. (Usually only the examples with numeric arrays and matrices are brought forward.) For the fun of it, I tried to convert the code to C++. The hard-coded `r==2` version would look like this: template&lt;typename T&gt; std::vector&lt;std::array&lt;T, 2&gt;&gt; combinations2(std::vector&lt;T&gt; &amp;pool) { const size_t r = 2; std::vector&lt;std::array&lt;T, 2&gt;&gt; res; size_t n = pool.size(); if (r &gt; n) return res; size_t indices[r]; std::iota(std::begin(indices), std::end(indices), 0); res.push_back(std::array&lt;T, 2&gt;{ pool[indices[0]], pool[indices[1]] }); while (true) { ssize_t i; for (i = r - 1; i &gt;= 0; i--) if (indices[i] != i + n - r) break; if (i == -1) break; indices[i] += 1; for (size_t j = i + 1; j &lt; r; j++) indices[j] = indices[j - 1] + 1; res.push_back(std::array&lt;T, 2&gt; { pool[indices[0]], pool[indices[1]] }); } return res; } On the other hand, the generic version is almost exactly the same, just with an explicit `for` loop to create the array: template&lt;size_t r, typename T&gt; std::vector&lt;std::array&lt;T, r&gt;&gt; combinations(std::vector&lt;T&gt; &amp;pool) { std::vector&lt;std::array&lt;T, r&gt;&gt; res; size_t n = pool.size(); if (r &gt; n) return res; size_t indices[r]; std::iota(std::begin(indices), std::end(indices), 0); auto make_pool_array = [&amp;]() -&gt; std::array&lt;T, r&gt; { std::array&lt;T, r&gt; arr; for (size_t i = 0; i &lt; r; i++) arr[i] = pool[indices[i]]; return arr; }; res.push_back(make_pool_array()); while (true) { ssize_t i; for (i = r - 1; i &gt;= 0; i--) if (indices[i] != i + n - r) break; if (i == -1) break; indices[i] += 1; for (size_t j = i + 1; j &lt; r; j++) indices[j] = indices[j - 1] + 1; res.push_back(make_pool_array()); } return res; } The function is used like the previous version, simply replace `combinations2(x)` with `combinations&lt;2&gt;(x)`. It will be a great day when [RFC 2000](https://github.com/rust-lang/rust/issues/44580) lands.
Moto Z Play Android 8.0.0 Firefox Beta 10: 60 fps 100: 28 fps 1000: 3 fps
&gt; Does contributing to open source help me to get a job ? Yes, 100%. Including your github profile on your resume and linking to it from LinkedIn are highly recommended. &gt; I don't want college degree and all that corporate level jobs. No offense to college degrees but where I come from its all corporate level politics all about money. You can certainly be very successful, proficient, and happy without a college degree, but keep in mind it can be a huge help in getting your foot in the door. &gt; So how can I contribute to rust ecosystem with no knowledge of systems programing ? It will require a combination of learning systems programming and starting out with "low hanging fruit." Sure, you may not be able to build something like tokio or diesel yet, but you may be able to make small but useful changes to those crates as they exist now. Over time if you learn systems programming you can one day be the creating of successful tools like those. As for going "all in" on rust, I currently would not recommend that. It doesn't see heavy use in industry just yet (less than 10% of the code I write at work is in Rust by my own estimation), and no one is sure if it ever will (I bet it will though). I would definitely be worthwhile to pickup more mainstream languages as well, and that shouldn't be too difficult if you know Rust. Python is extremely popular and simple, C would make you learn some elements of systems programming along the way, Java sucks IMO but is still in heavy use in industry.
And expanding a little more, the important thing isn't so much that you know a lot of languages/tools, but rather than you can pick up new languages/tools quickly. That's really the professional attitude you need to take towards languages: "I'll work on lots of different projects, and they'll be using different languages, and I'll need to be able to get up to speed quickly on whatever they're using." It makes sense to learn some of the most ubiquitous languages somewhere along the way, and it also makes sense to learn a variety of different things to get a broad exposure.
thank you!
You said it was a "reasonable interpretation". It's only reasonable if the OP doesn't know where the phrase came from, i.e. if they're taking it as literally "open" + "source". Perhaps call it "open code" or something if you don't want to be weighed down by all the history of the term. But you can't avoid the history because it is just there, like a huge boulder, existing. I also don't see any point in a debate. I'm just trying to fill in any information or knowledge apparently missing in the conversation. I mean I could try and redefine "carrot", and maybe I'll have success in my own head, but I'm going to be constantly frustrated in my interactions with the rest of the world.
Thanks for the details. After discussing internally, we've decided to remove our license clause and thus go full MPL2.0 (as our modified license minus this clause is exactly MPL2.0 word-for-word). After considering feedbacks from the community and the wariness of people sincerely willing to use Sonic in their projects but itching on this specific licensing &amp; "partial OSS" point (which is a deal-breaker for them), I think it's wiser to fully open-source the software; for the good of the software on long-term. This will also allow us to abstract some code away from Sonic (eg. the stopwords management) and share it in MPL2.0 libraries, as we had planned but which could have been limited by that license clause.
You're right, I have little knowledge of legal things and we've not been helped by any IP attorney on this. We've decided to remove the special clause and fully open-source Sonic under the terms of MPL2.0. Based on the feedbacks we received, it's definitely what's best for the project in terms of philosophy, contributions and people actually using it in a wide range of setups.
Because it is reasonable. There has been and always will be a tension between jargon and colloquialisms. Plenty of other people have already made it known the difference in this thread. It's impossible to miss. You don't need to continue harping on it. &gt; But you can't avoid the history because it is just there, like a huge boulder, existing. Go back and read my original comment. Why is it that you think I gave the advice I did? Because I understand this point. As I said, I've been there and done that. Not only does that history exist, but nobody will ever let you forget it. Zealots will fill up every Internet discussion on your project about this one singular point until you capitulate. Frankly, I just can't stand the constant regurgitation of OSI (or FSF) talking points. It's a borderline religion. People such as the OP get caught in the middle and it sucks.
Awesome. I know it's tough to make these decisions. Kudos.
thank you this is great
My understanding is the AGPL is basically formatted to allow profitable web applications to use your software on the backend, but force you to say you used them and share code changes, the difference with the GPL being if they make changes they have to say so on the webapp and share them? So even though a webapp is closed source, the open-source components are still obvious and public with any changes they make. I tend to disagree with the idea that this allows companies like Amazon to use them *without paying anything back*. Sharing code improvements, bug fixes and providing support does pay something back to the open-source community. A developer for Amazon might be answering stack overflow questions about it since they use it, or writing a blog article on it, allowing more people to successfully use that software. They might find bugs and submit pull requests. They might add a feature and have to share it. Just because they can profit off the work being a component of their software doesn't mean that specific component is taken away from the community. Being free money-wise is an important aspect, but not making profit isn't necessarily, and I think the most important aspect is that the open-source community maintains ownership over that component and its derivatives no matter how it's used.
If I understand it correctly, the AGPL is tailored for web applications so that companies have to explicitly say more on the actual visible webapp. You can run a linux server and no one is the wiser, but if you use AGPL software to power your site, you might have to mention it on the site and changes you make. Not a big deal, but requires more and is harder to be compliant, so I can see why people might just avoid it altogether.
Yeah... You should be able to use dummy traits to get some form of overlapped specialization to work by creating a hierarchy , but since all that isn't stable, you'll have to mess around on nightly and YMMV.
My background before rust was cs 1 and 2, mobile apps dev, cryptography, and most importantly computer systems (in C). Having a deep understanding of the C programming language and how computer (operating) systems work will definitely help with learning rust. Once you have that the Rust book should be sufficient. There will be a lot of new terminology, but you should be able to connect the concepts to things you already understand at that point.
There's some nice ideas here. Thanks for sharing. Honestly, though, the example could use some work. Idiomatic Rust here might be i64::max(a, b) rather than a user-defined function. Better might be a.max(b) which looks worse because it is asymmetric but doesn't require specifying the type, so will be safe against type changes to, for example, unsigned types: it works for any `a` and `b` of the same type `T` that implements the `Ord` trait. So it might be more idiomatic to say Ord::max(a, b) But of course the restriction that `a` and `b` be the same type is problematic also. If they are different signed integral types, and you're not sure what they will be, you can use i64::max(a.into(), b.into()) which will (notionally, before compiler optimization) promote both `a` and `b` to `i64`, do the comparison, and return the `i64` result. But that's kind of uggy too: what if `a` or `b` is an unsigned type? What if you really don't want to promote so far? What if you want to compare an `f32` with an `f64`? Let's get more generic. I'm going to switch back to defining a function here, because continuing with an expression is hard to write and read. fn generic_max&lt;A, B, R&gt;(a: A, b: B) -&gt; R where A: Into&lt;R&gt;, B: Into&lt;R&gt;, R: Ord { R::max(a.into(), b.into()) } fn main() { let a = 3_u8; let b = 7_i32; let r: i64 = generic_max(a, b); println!("{}", r); } Note that we've lost inference on the result type here: we have to specify it explicitly. (If we had used the result at some location that required a specific type, the inference would have come back.) The compiler will fail our program if either argument can't be safely converted to the result type, though, so there's that, which is nice. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4cc1ca9cc01fc39ffdd3355583bb17ec)) Is this last "idiomatic Rust"? I don't know. In some circumstances it will be what you want: in other circumstances it will be ridiculous overkill. There's a lot to more to writing idiomatic Rust than expression-style programming, too. Indeed, some of the idioms haven't really settled yet: right now there's a tendency toward a functional style, but imperative-style stuff is also considered idiomatic. In short, you've taken on a really complicated and important topic. I'd encourage you to continue to explore it as you get going in Rust, and keep blogging about what you find.
Look at that diff more closely, they didn't change the license terms, just clarified by changing the name from "Mozilla Public License Version 2.0 (Modified)".
All evidence points to OSI not having invented the term: https://hyperlogos.org/article/Who-Invented-Term-Open-Source
There's a good beginner's guide called [The Rust Programming Language](https://doc.rust-lang.org/book/index.html). It does a good job of providing examples and breaking down those examples to explain what each part does.
When I'm learning something new I always like to relate it back to things I already know, just so it's grounded. In this case, you know python and C, that's great! If I had to pick two languages to make explaining Rust easy, those would be they. C has structs. So does Rust. In both cases they live on the stack unless you put them elsewhere. Rust has a thing called "ownership" that you can start off understanding as an automated version of the manual memory management in C. In C, to avoid memory problems you have to keep track of when things can and can't be referenced and when they should be freed. Rust does that for you, but at the core it's the same process. If you just think of the compiler as an incredibly aggressive C code reviewer it'll take you pretty far towards getting Rust. Have you tried your hand at writing Python in the functional programming style? List comprehensions, for example, are thin veils around standard functional programming idioms. Rust has those same tools, but codified slightly differently to facilitate having types. In Rust they're all methods on Iterators, but at the core it's the same idea. And so on. Rust doesn't actually do anything new, it just assembles the good parts of many previous languages and presents them together with a coherent design strategy and a flipping awesome compiler. As far as putting an info sec spin on it? Info sec people should see Rust the way horse veterinarians saw the first mass produced automobiles. It's very clearly progress, but your field is going to shrink (in terms of market share).
Not sure how it's done in other countries / cultures. Here where I work, the hiring decisions are not made by HR. HR might spot a potential candidate, and that's generally not based on technical capabilities assessment, and forward that to a tech lead. Who in turn handles most of the process and makes the hiring decision. And yes, if you contribute to open source, have a track record of showing incentive which results in functional code, that's a HUGE plus. Now whatever that will help you land Rust dev job.. I don't think there are many "rust dev" positions. That's not to say there aren't programmers who work with Rust at full time, but that's generally people who started with other languages in their career and adopted the tool along the way within the company.
I don't think you can, but you can use a HashSet and impl Hash for either Foo or a wrapper struct, based on whatever fields. use std::hash::{Hash, Hasher}; use std::collections::HashSet; struct Foo { name: String, bar: i32, } struct FooByName(Foo); impl PartialEq for FooByName { fn eq(&amp;self, other: &amp;Self) -&gt; bool { self.name == other.name } } impl Eq for FooByName {} impl Hash for FooByName { fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) { self.0.name.hash(state); } } fn main() { let mut set = HashSet::new(); let foo = Foo { name: "foo".to_string(), bar: 1 }; set.insert(FooByName(foo)); }
I wouldn't encourage to learn rust if the basic programmer fundamentals aren't really clear. Even the Rust book is calibrated for people who are already familiar with basic programming concepts. And if you're a beginner, that is someone who haven't worked as professional developer at least for a half a year, it would be feel wrong for me to advise someone to mix up the languages. You already mentioned Python. And I really do not want to step on your toes, but given that you have such a hard time to understand Rust it lets me to believe that you haven't actually worked with it in professional setting, meaning you didn't get paid for meeting requirements. And no, university doesn't count here. Now if all you're doing is just for the heck of it, hobby stuff, when yeah sure. Rust can be huge source of fun. I had a blast learning it and I still do. But if you care about becoming a better developer and forward your career, you should really invest at least a few years in Python and when see where you can diverge. I'm sure many people may not agree with me on this one, it's okey. But for me personally it wouldn't feel right to advise anything else in this situation.
I don't really see how that helps. The point of my code is to cache a bunch of object then retrieve them from cache using their name without allocating. With this code I still need a complete struct to do lookup. And I'll still need a String and not a str.
&gt; That is an example of non-canonicity, not incoherence. The paper talks about this (I urge you to give it a thorough read instead of skimming it): I don't really have the time the time to read the paper in full right now but I understand the difference. To me, the interesting property to maintain is canonicity as it is what gives you proof irrelevance and the neat benefit that comes with for practical programming. &gt; So yeah in OCaml's case that would be an error. Note that in the example above, in `foo`'s scope there's a unique resolution to one "instance" per package. It iss locally coherent. I don't see why it would be rejected by the paper's proposal. &gt; It might not end up picking the implicit you want (if you don't know how to rank the definitions), but that's a programmer error. It's not really interesting to call things programmer errors or not. Based on your language's rule you can turn pretty much anything into a programmer error. The question is whether this is best left up to the programmer or not. &gt; This is very much distinct from Haskell's IncoherentInstances where the compiler can pick any instance whatsoever. No one should ever use IncoherentInstances. I wouldn't touch code that uses [-XOverlappingInstances](http://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#overlapping-instances) either. &gt; My reading is that Yang's article is advocating for the same. Agreed.
You can use the Borrow trait. This is what lets you lookup e.g. HashSet&lt;String&gt; with a &amp;str. [Playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ec3fcb3ec78e4ce0b8a487b1905e6128)
Do you have some examples of Rust that seems unreadable to you on first glance? Rust has a few unique concepts, but in general it works like C/C++ with a more function typesystem.
I'm genuinely happy to hear this — also geniunely sad that this has been a source of difficulty for you. I wish we lived in a better open-source world, with less legal and ethical grief. I wish your most excellent project all the success in the world. I'll be checking it out soon.
Oh right thanks that works. I was really confused about how it works but reading the doc for Borrow it's explained there. &gt;As a consequence, the hash map breaks if a K wrapping a Q value produces a different hash than Q.
I can do for you tonight. Tell me what you need. Email me or dm me. My username at the google email domain.
Is there any way to measure perf of your crate, compared to Box or copyless. Do you have any idea which method is preferable? (Or are do they have different use cases?)
This was probably because Non-lexical lifetimes became default on the 2018 edition.
Problem was just with bad code.
&gt; Note that in the example above, in foo's scope there's a unique resolution to one "instance" per package. It iss locally coherent. I don't see why it would be rejected by the paper's proposal. Got your point. I misunderstood your Scala code initially. Yes, one can write a similar example in OCaml that would compile. &gt; No one should ever use IncoherentInstances. I wouldn't touch code that uses -XOverlappingInstances either. The point I was making was that if there is an arbitrary choice being made, that leads to incoherence - if there is a well-defined way to rank in case of ambiguities (like in Scala) or reject ambiguity (OCaml), that doesn't lead to incoherence. I'm not making a case for/against any pragmas.
While I agree with you that sharing code improvements, sharing bug fixes and providing commercial support all enrich the open-source community in various ways, my understanding is that Redis and Mongo were hoping to be enriched with actual riches. The idea that /u/MysteryManEusine proposes is that a business can develop a tool or service and publish it under the AGPL to get good will, code improvements and bug fixes from the community (who like the AGPL), and under a commercial licence to get money from large businesses (who are terrified of the AGPL). The problem with this idea is that Amazon is an enormous business who is not even slightly scared of the AGPL, and will happily run your software for millions of customers without paying you a dime for a licence or support or anything. If you picked the AGPL because you believe in the Free Software cause, this is fine and it's what you signed up for. On the other hand, if you picked the AGPL as a sales tactic, this is a spectacular back-fire.
Let me just tell you, no matter what you do, you're already on the right track with what you just expressed. Standing out in a sea of mediocrity will be hard at first, and there is no simple way to do it, but once you find the right people it'll get easier. Learn all the things, don't focus on just one. Knowledge expands exponentially as you connect the dots.
or without allocating a vec array.sort(); let len = if array.is_empty() { 0 } else { 1 + array.windows(2) .filter(|win| win[0] != win[1]) .count() };
In some cases you can't practically reach a high enough N for the linear algorithm to overtake the log-linear one before the runtime becomes prohibitive anyway.
You want /r/playrust. This is a programming language subreddit.
Is there a module out there for transmuting u8, u16, u32, etc to and from [u8; 1], [u8; 2], [u8; 4] etc? I'm thinking of building one and seeing if I can get it added to the `num` crate, but it seems like the kind of things that might already exist. 
I can't remember right now how the blog was named but it was a person (a girl if Im not wrong) showing an experiment with Rust in which they tried to make an OS from the ground up and showed how to colour the screen, typing a key would change the screen colour and etc. Honestly I couldn't follow along. Maybe it was because it dealt with OS stuff (That's why I asked if I should handle it after reading Tanenbaum's book)
Thank you very much for that reference
Wow what a detailed answer. Im extremely interested in this observation: &gt;It's very clearly progress, but your field is going to shrink (in terms of market share). Why is that? isn't the influx of coders who don't know what they are doing pretty much generating the opposite?
When I first released my GPL'd code it was called "freeware". That was the normal term at the time, to contrast with "shareware". Then the FSF realized that "freeware" was also being used for other things (e.g. closed source things given away for free), so they decided to insist that it be called "free software". This only added to the muddle of terms, so when "Open Source" came along they took good care to make sure it didn't clash with any other use. IIRC, there was one use in some other industry, and some similar legal term, but apart from that it was free of confusion, and so it was a good choice to start afresh. At least that is my recollection of the publically-viewable discussion at the time. I don't know what historians have maybe dug up since then, but my recollection was that no-one anywhere was talking about Open Source in the public arenas I was participating in until the whole OSI thing started (which then started off its own huge OSI-vs-FSF battle of ideologies).
I think byteorder is the crate you want (to make sure you don't introduce different behaviour on big endian/little endian machines).
Fair point! I guess it's always good to keep in mind how small a factor of log N is compared to N. The constant factor could indeed have a larger impact (for realistic N).
I looked at it, but it doesn't do quite what I need. Some more detail: I have a type that I'd like to be generic over all the primitive numeric types, but I need to be able to get a `[u8; N]` representation out of them. I imagine this would be a trait over all primitive numeric types that returns either: 1. A `GenericArray&lt;u8, N&gt;` 2. An iterator that emits `u8`s. 
I thought you didn't want to debate this? I'm just stating how things are. I'm no zealot. When I started this was all called "freeware", but then we were told by the FSF not to use that term. Whatever! It's not worth fighting about. Freeware, open-source, free software, whatever ... the communities establish meanings so that we can all communicate and understand each other. However, if someone tries to use a term with a different definition to the established one, they obviously someone will point that out. I really don't see the big problem. I'm no religious nut, and I take no side in OSI vs FSF. Pragmatically, I have seen how GPL is completely ineffective when megacorp steals an individual's work (as one did mine). So might as well BSD it, less stressful. But like it or not, you have to watch your licenses and copyrights if you care about the future of your software project, startup or company, so misrepresentation of a license is always going to give people a nasty shock and get called out.
You're right, the actual change from MPL was a day before I thought https://github.com/valeriansaliou/sonic/commit/0db1af71ce4799f7c152af079b515cfd7a107d42 However as you note today it's been switched back to standard MPL, hooray!
I started learning Rust a few days ago. As a small project I tried implementing a binary search tree in Rust ([code](https://github.com/derivmug/binary_tree/tree/master/src)) with generics. I'd be very grateful for any advice on what I should change and things I should avoid doing / should do. (I think I might have overused the `Option` enum a bit.) Thanks for your time :)
How is it not open source? I understand that it isn't "free-as-in-libre" software, but it does seem "open". 
The state of rust for GUI, as far I see, is still immature. Sadly, you will not find many options in the UI store apart of the same old: &amp;#x200B; * Native UI as coded by each OS * HTML * QT * LCL (FreePascal) * Many, many options, nothing close to LCL, much less to Native &amp;#x200B; I'm in the same boat, and think in use rust behind a REST embebed server, and use the native toolkit (ie: Swift for iOS/OSX, Kotlin for Android, Delphi/FreePascal for Windows) and/or use a WebViews and do the UI on HTML. &amp;#x200B; This, I think, is the closest to bring a decent solution in the near term. &amp;#x200B;
Not really. The compiler is more stubborn than the newbies are inexperienced. The idea of Rust is to make invalid memory states _impossible_, not merely less likely. Yes, there is a keyword that allows you to fuck things up, but if you simply fail to use that keyword (or automatically reject any pull request that includes it) no amount of inexperience (or even malice) is going to cause certain types of problem. Of course, the newbie will find it frustrating to use, but the compiler doesn't budge.
Probably the OS stuff. I'd consider myself of at least comparable skill to you (at *least* a 5 out of 10 in Python, maybe a 1 or 2 out of 10 in C and C++, and some experience with PHP and JavaScript), and I didn't have any trouble grasping Rust, but I'd have trouble with OS internals too. When writing an OS, there's an inherent need to have a deep understanding of what's going on underneath the usual layers of abstraction. My advice would be to start by learning Rust as a faster, more reliable option for the kinds of tasks you already know how to do and then only move on to OS internals once you feel comfortable with the language. Don't try to learn too many different things at once. (I started by working through ["The Book"](https://doc.rust-lang.org/stable/book/), puttered about in [Exercism](https://exercism.io/)'s Rust track a bit to practice things like mathematical tasks I don't normally do, and then moved on to [Learn Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) to solidify my understanding of how Rust's ownership model affects actual tasks.
r/playrust
Ye I should prolly go there
You don't, but if the keys are stored elsewhere and that "elsewhere" clearly lives longer than the map, then you're allowed to have a diamond-shaped dependency: the map's table of keys references the backing storage and each value structure also references the backing storage. This requires creating the map in a context that's tied to the call stack, so it is likely *not* what you want, but it's very much possible and might be what you need for some kind of text processing. What's the "x" you're trying to do?
Remembering to drop isn't an invariant though. It's always safe to forget a value of someone else's type (though you may provoke a logic bug). And if it's not safe to forget a value of a type, the expectation is that the code defining that type will encapsulate (or at least *loudly and clearly* warn about) that unsafety. The "Pre-Poop Your Pants" article is still a really fun read, but might not be the best until you've absorbed the Rustonomicon. https://cglab.ca/~abeinges/blah/everyone-poops/ (And the scoped concurrency problem *is* considered solved now. You either accept the sightly buggy RAII technique that was criticized back then - because it's easy enough to get it right - or if you have a higher commitment to safety, use a HOF and `catch_unwind` to guarantee any mandatory cleanup happens before the HOF returns. Crossbeam and Rayon implement the latter.)
Rust is a fantastic language, but currently it's not the right choice for company GUI projects. And realistically, on a project like this you're probably not going to learn much of Rust.
/r/playrust
It's perfectly fine with GTK, or for designing a web UI. Complex GUI projects have been written in it with Rust before.
To help with your interest in Rust, you should probably apply to Ather energy (a super cool electric scooter startup), Bangalore. Open source is a great path, but if you can also have great engineers (physically) around you to help you through the journey, you'll learn faster. And Ather has many great engineers. Also being in Bangalore you'll get to go for all the Rust meetups. Check out Ather's GitHub page. They're working on ab MQTT client. https://github.com/AtherEnergy/rumqtt
Oh I'm sure it's been done before. I'm saying for OP it's not a good technical/business decision.
I don't think it's hypocritical for the Rust team to not want to set goals for projects that aren't under their umbrella. If tokio, hyper, etc... did make it into the roadmap it would have to be from the perspective of what a working group can contribute to those projects specifically, not for the projects generally. Setting goals for a working group makes sense because if the group doesn't meet those goals it's accountable to the Rust project at the end of the day, and something can be done if the goals aren't being reached (restructuring the group or refocusing it's effort on something more likely to bear fruit, for example). Setting goals for third party crates themselves implies that the core Rust project has some authority over how those crates are run which simply isn't true.
\&gt;The community team is the only team that is a full hobbyist team Off-topic, but I just want to say thank you to you and all the other members of the Rust team that spend your valuable free time contributing to the project. It's a lot of work to make/manage something like Rust, probably much more than is visible from the surface, but the work you do has a real, tangible benefit to myself and others every day. Thanks.
What about piston?
Methinks you have posted in the wrong subreddit good sir.
It's deprecated sugar for [Box&lt;T&gt;](https://doc.rust-lang.org/std/boxed/struct.Box.html) See https://github.com/rust-lang/rfcs/pull/59
Great attitude, I don't think you will have a problem getting where you want to be. But: 1. Never get career advice on Reddit. You might have skills nobody else here have and you are limiting yourself to fears and shortcomings of other people 2. Always get advice from people who are "chefs" not "cooks" How to find them: - Rund or join a local Rust MeetUp group. You might be surprised of how many people are interested and how manu companies internally are trying out Rust - Join other MeetUp groups and learn which person you can trust with advice and which one not If you have no prior experience: Look for a company who supports your enthusiasm and has a great CTO. Maybe a smallish firm with maybe 20-30 people? You learn a lot there, especially from your work colleagues. So look for income, get a junior position, iterate fast and figure out what makes you stand out and what you are naturally good at. At some point you can argue that Rust is reducing AWS bills and this alone could be your business. I would also argue that yes, focussing on one language might be a good choice, but it depends a bit on where you are in your career and what do you want.
thanks 
In older (pre-1.0) versions of Rust, `~T` was a heap-allocated object of type `T`, and `~[T]` was a heap-allocated vector of elements `T`. We eventually decided to drop the special syntax and use `Box&lt;T&gt;` and `Vec&lt;T&gt;` instead. `~""` would have probably created a `String`, or `~str` in the old syntax. The modern equivalent would be `"".to_string()` or `String::new()`.
MySQL and PostgreSQL don’t handle many connections well, at all. They use many MB of RAM per connection. For PostgreSQL, pgbouncer is probably the better choice.
Use the amazing winapi crate if on windows Note to quixxy: I know you will comment ;) so please remember that winapi is faster than frameworks. If not on windows use any of the million c-libs from github using ffi. Not the best looking but will get job done.
rust-sciter
Oh, right, you actually want to use the final value multiple times. Yeah... Cell won't work.
What's this token then? [https://holo.host/holo-fuel/](https://holo.host/holo-fuel/)
We should totally start a Rust Database Working Group db-wg!!! We should just start the discord channel. People will join and it will be a thing!
That's not possible to enforce. There was a discussion about this a few months ago and there's no way to make that possible without seriously crippling the language itself. In any language package manager for that matter.
Perhaps something with a more permissive license.
What do you mean "GUI database"? Something like Microsoft Access?
Looks like you are trying to use [this](https://rustr.org)? Can you share more about the specific problem you are having? Can you give a small example that doesn't work?
libcore has various `as_bytes` and `from_bytes` methods, but IIRC they're unstable.
Who is nobody in that case? I haven't looked at the code yet but from the conversation it sounds like the trait have to be marked unsafe. Even if no user - someone outside of the crate - can use it wrong but someone as a contributor to the crate can, it has to be marked unsafe. Imagine the unrealistic case that all contributor's leave and someone else takes over maintenance and has some cool ideas involving using it wrong. Is it still "totally safe"? 
Hi! Thanks for the thought-out feedback. I really appreciate it! Your points regarding the example are quite valid and on the nose. The blog post was rather pretentiously titled "Writing idiomatic Rust", while I'm barely beginning to dip my toes into the water. The examples were there to provide a sense of familiarity to people who've not encountered Rust before and show them the freedom that is possible with the language. I did consider throwing a generics example into the mix, but I feel that that would have put off people who're not familiar with bounds and traits. I also didn't want to preach about something I myself don't understand completely yet. I'll definitely keep exploring Rust (and writing posts!). It's been a blast so far, and it's forced me to think in different ways than what I've been used to.
Nowadays you can just use `cat` to do this. 
Restricting stuff like that is only possible for "walled gardens" operating systems. 
Not quite, it was all of the owned pointer types, including String and Vec
I'm one of the 0.001% of people who miss the rust pointer sigils. Something about `~` and `@` spoke to me in a way that `Box` and `Rc` do not. I also am a fan of lens's operators. There may be some correlation...
A lot was changed since the previous release. Now you can execute multiple tests in parallel mode, allow sockets to send packets to a broadcast address, specify different verbosity levels and more.
Safe languages can restrict individual libraries to some degree. C#/.net supported that at some point. And I would assume that languages designed around capabilities handle this very well.
I would love to see `~""` back. Or any other short syntax for creating owned string. `.to_string()` is very noisy
Hijacking the top comment to say the authors changed the license now to be really open source - they now use Mozilla Public License 2.0. (Previously it was MPL 2.0 with custom modifications that made it not satisfy the Open Source definition.)
Well then I guess I'll have to wait for stabilization... It seems wasteful to create separate methods to accept closure instead of value. That's why we should have overloaded functions....
For what reasons is it not enforceable? I imagine that it could be possible by doing stuff like adding checks whenever a syscall is made. I.e. a "is this function allowed to call this syscall". Of course, `unsafe` would throw all these guarantees out of the windows.
Doesn't your NIC/OS just fragment the packet to the highest MTU for the medium?
I don't think it's possible. C# is safe but it is managed language. Rust is also safe but with safe abstraction around unsafe codes. Rust is also low level languages just like C, C++, Nim, Jai, etc. and I don't know any similar low level languages have any means to enforce package security.
This needs to be enforced by the kernel to be secure. You can do that with seccomp for your project but it's going to be a lot of work.
Supposing it is all pure Rust code, could we not inspect the LLVM bitcode for any system calls and augment them with checks?
Having a special case without having a special syntax feels wrong
This doesn't work. It would add significant overhead for honest programs for each syscall and a malicious crate could just rop style search for \xcd\x80 in executable memory, setup the registers+stack and jump there directly for unconstrained syscalls. The only secure way to enforce this is in the kernel, which doesn't know about the concept of crates.
If you are talking about \_adding\_ restrictions downstream, that sound's pretty much impossible. However, it should be entirely possible for the crate author to declare guarantees that are statically checked, although it would be a huge project to undertake. It's possible to create a call graph of a crate (or multiple crates). One could then declare a list of known language items, functions with unsafe and FFI functions that have well-defined effects, and check if these are called. One could then consider everything else (FFI and unsafe code) causing "arbitrary effects". Then you propagate the effects using the call graph and check if it's possible to reach some listed, effectful function. Dynamic dispatch (trait objects and function pointers) bring their own complications; either you consider them causing arbitrary effects or then you constrain the effects a dynamically dispatched type can do and consider assigning an effectful object to that type a "compilation error" or then you extend the checker to support polymorphic effects without enforcing any restrictions. All in all, proving that a function from an external crate don't do anything funny with the outside world is possible. Depending on how smart the checker would be, you might get some false negatives though. There will be a somewhat cruder version of this in Rust some day: the const declaration means that the functions you call can't communicate at all with external world. However, I'm not aware of there being plans for a more delicate effect system, although I think /u/etareduce has indicated interest for having one. Anyway, even if there wouldn't be a language features for tracking effects (except for the const stuff), using rustc to get the call graph, it should be possible to implement one as a external tool. An external tool wouldn't be able to enforce restricted effect polymorphism, but it could at least prove the effectlessness of some parts of code.
The check would ideally be elided in cases where the syscall could be determined statically, e.g. by letting LLVM inline the check. Wrt. jumping to other crate's code, that should not be possible in safe code, right?
&gt; lens's operators The only results I found with a quick search on DDG related to optics. What are lens's operators?
It's a haskell lib: https://github.com/ekmett/lens/wiki/Examples
Thank you for detailed response. I will look forward on this.
I think they're referring to the Haskell package of that name.
Well thanks for suggestion. Looks like we do have rustaceans in India
https://hoogle.haskell.org/?hoogle=lens&amp;scope=set%3Astackage Here you go! 
Thanks. I do think Rust will help us reduce AWS bills. Just look at the [sonic](https://github.com/valeriansaliou/sonic) project.
Afaik for GTK someone had to setup a C toolchain. I guess that can be hard for a beginner of Rust, not having the amenities of rustup and cargo.
Honestly, discouraging allocation is a good thing.
There are methods on primitive types with names _(to|from)_(le|be|ne)_bytes_ to convert between byte array and certain primitive types. Eg. `assert_eq!(42u32.to_le_bytes(), [42, 0, 0, 0])`
I'm pretty sure dd forces sync between the device and doesn't copy it into system memory too if it's block device to block device. That may be me talking rubbish however.
Executor is a trait, so when creating a library it allows users to choose their own implementation of the executor, also known as the runtime.
There's a gtk library https://github.com/gtk-rs/gtk You could also consider using WASM (with something like Yew) + Electron. There's a few blogs that talk about how this is surprisingly performant. 
C++ has been a pretty good choice for me! Not that I don't know other languages, but most people know one much better than any others I find. Having Rust as that language *might* be a good move, but it might not.
Piston is pre-alpha.
Can you name some? I have never seen any.
Not Perl again, please!
To be fair, that's *why* people want it in std. When someone says "I want it in std" they mean "I want it in std so its interface will be stable and everyone can rely on it sticking around".
Interesting read, thanks. Well, I probably didn't use the right word, but what I meant is that with ManuallyDrop, if I don't always take care of dropping, it will leak - what is actually a bug in this case (I don't want to fill up memory just by creating unused lazy values...).
So, at the end, I probably still want to use UnsafeCell - Cell just doesn't fit my purpose and I need to use unsafe anyway (with raw pointer to extend lifetime to that of Lazy's reference), so RefCell is just making things more complicated...
It's a haskell library which generalizes getters and setters to a ridiculous degree: &gt;import Control.Lens &gt;import Data.Aeson.Lens &gt;:set -XOverloadedStrings &gt;sumOf (key "foo" . values . key "count" . _Integer) "{ \"foo\": [ { \"count\": 1 }, {\"count\": 9}], \"bar\": false }" 10 It is well known for having a lot of operators. Usually only a couple operators are actually used but since the operators follow an internal logic you can combine a bunch of features to get ridiculous syntax: -- Stateful operators contain = count += 1 -- &lt;&lt; returns the old value (think x++ vs ++x in c) -- yes this is super ugly oldCount &lt;- count &lt;&lt;+= 1 -- % runs a function: count %= \c -&gt; c * 3 `mod` 5 -- %@ runs a function that receives an index: users.each %@= \idx user -&gt; ... -- ALL OF THE ABOVE: oldUsers &lt;- users.each &lt;&lt;%@= \idx user -&gt; ... 
Well, could always write backend and frontend separately and with different languages/technologies. Either frontend is started as a service/daemon, and frontend connects to it via an API, protocol could be HTTP(S).
I see, they have implemented a perl simulation.
It's not supposed to be a special case forever. `DerefMove` has just turned out to be much harder than expected. It's a wart, but all languages have their warts. 
There is a (one-man?) effort going on- search for cargo cred I think?
`men::uninitialized` has turned out to be *really* hard to use correctly within generic code. There's an unstable replacement, `MaybeUninitialized`, though, but it still has some rough edges around array initialization. Also personally I think `as` shouldn't have been in the language.
Yeah absolutely. I've been playing with it for a fork of the foundationdb rust bindings. [This is what the async-await version looks like](https://github.com/josephg/foundationdb-rs/blob/master/foundationdb/tests/get.rs). Its very similar to how you'd write it in javascript, or C#, or anything else with async/await. ([This](https://github.com/bluejekyll/foundationdb-rs/blob/master/foundationdb/tests/get.rs) is the equivalent using futures 0.1 without async/await for comparison) Unfortunately its not really ready to use - aside from the syntax being in flux, the borrow checker has some glaring issues.
Just out of interest: How long have you been working on this? Happy to see some java apps competition
Channels, List, etc. Basically all the special stuff that’s not needed by most programs and that are not vocabulary types / traits.
That's so much better than typing `Box`.
Is that what it will be called, and not `DerefOnce`?
I think your implementation has problems when lazy value evaluation is recursive. This example is somewhat contrived, but fails in miri, and segfaults both in debug and release mode ([playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=28e6fc54a621c732823a6cb467ca98c3)): fn main() { let c: Rc&lt;RefCell&lt;Option&lt;Rc&lt;Lazy&lt;i32&gt;&gt;&gt;&gt;&gt; = Rc::new(RefCell::new(None)); let c2 = c.clone(); let flag = Rc::new(Cell::new(false)); let x = Rc::new(lazy! { if flag.get() { 0 } else { flag.set(true); ***c.borrow().as_ref().unwrap() } }); *c2.borrow_mut() = Some(x.clone()); println!("{}", **x); }
While I understand the reason why these are problematic, I don't feel satisfied with their replacements. I've always struggled with accepting built-in functionality with library features. One reason is debugging, stepping through code which replaced built-in functionality tiny function library calls makes debugging essentially impossible. It will step into all the tiny helper functions. It ruined C++ stl code for me (do I really need to step into _three_ levels of abstraction when iterating an std vector?!). Rust is less impacted by this because compiling code tends to be working code. In C++ I would enable the inliner in debug builds to get rid of at least some annoyance. I also had high hopes for `#[inline(semantic)]` to guarantee inlining to cover this papercut but unfortunately this didn't make it. For uninitialized data there are even more hoops. My particular use case is 'out' parameters in C style APIs. The C API takes a parameter of type `Foo` not `MaybeUninitialized&lt;Foo&gt;`. Sure I can call `as_mut_ptr` before calling the C API but again that is a library call interfering with debugging and extra noise I don't care about. Further now I have to annotate the uninitialized type whereas before it would be inferred... I get the idea of discouraging use of unsafe features by making them less ergonomic but this is just over the top to the point where I will continue to use straight `mem::uninitialized` for C style API out parameters. I wish the compiler could support this use case directly. eg. `let mut out_data; C_Api_Call(&amp;mut out_data);` &lt;- that is what I want to write, let the compiler figure out the rest. Under the proposed rules I would have to write `let mut out_data = mem::MaybeUninit::&lt;Foo&gt;::uninitialized(); C_Api_Call(out_data.as_mut_ptr());`. Not only does this look ugly with a lot of extra noise, stepping through this code causes two jumps (one for the call to uninitialized, another for the call to as_mut_ptr). Oh did I mention? The pdbs produced by Rust have an issue where the debugger can't find the source files the std lib of these methods so the debugger (I am using VSC with the rust-lang extension and msvc C++ debugger) pops up a message box saying it can't find their source file, dismiss that and press shift-f11 to jump out back to where I was... I get the problematic aspects of `as`: It does too much and for integer conversions easily lets you ignore overflow if the result doesn't fit in the target integer type. But `Into` and `TryInto` just aren't enough to replace the ergonomics of integer conversion aspect of `as`... Again the issue of library calls while debugging as well as the lack of type ascription really hurt these. I apologize if I misunderstood some aspects, these are from my understanding of these two cases, I hope I didn't misrepresent how the lang teams sees how they should be replaced. The rust language has set certain ergonomic expectations of the existing features. I understand the current situation is flawed, but please try to fix these without significantly impacting the ergonomics of the existing, flawed solutions.
There’s a gui library that seems to have potential, it’s called OrbTK, the only downside right now for me is that it uses sdl2 to draw, it could not be bad if you are on unix like systems, but in windows is a pain to setup (at least isn’t just execute a command and you are ready to use sdl2). Other that I‘ve read about was Azul, but I didn’t follow it so don’t know exactly the state nor how is the experience with it. Also you can check other libraries in [Are we a GUI yet?](https://areweguiyet.com/).
&gt; `DerefMove` has just turned out to be much harder than expected. The language is certainly expressive enough that [the interface of DerefMove can be defined in it](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=36b3e2b6429344c14ae1d4292ade09d0). I'm guessing that the difficulties revolve around the fact that the compiler currently hardcodes a lot of `new` and `drop` for `Box`, and that the hope is to replace that hardcoding with placement once that particular bikeshed is assembled and painted. http://blakesmith.me/2018/12/31/what-is-placement-new-in-rust.html Unless I missed it, `Box` doesn't have a function to deallocate the Box without first dropping the contents. And that means I couldn't implement `deref_move` using unsafe `ptr::read`. (So my example code works, but it's like how ops for primitive numbers are implemented each with a circular dependency on itself.)
So it was sugar for `.to_owned()` or `&lt;$T as ToOwned&gt;::Owned`, depending on whether a value or type was needed? That's delightfully sweet, especially the latter.
So async / await removes the need for Tokio?
This is such a surprising question in my mind. It’s probably worthwhile to ask “What area of software engineering am I really interested in, and want to work in?”, pick up the languages common there, and then start learning other languages and principles along the side. It may turn out that Rust is an excellent replacement for some projects in that domain, but that should come as a result of your first choice.
No, the DerefMove interface that Box has is much more complex than you think it is: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=30a072a0c497830ada30432cc2ac5afb
It's totally safe for the user of the library. Whatever happens during the *development* of the library is a different story and essentially an implementation detail.
Now that futures are in std, tokio is just a library. If you want futures combinators, you can use [futures-preview 0.3](https://crates.io/crates/futures-preview/0.3.0-alpha.13). If you want IO futures &amp; an event loop, [romio](https://crates.io/crates/romio) is pretty great.
Still seems like inline(semantic) would still cover most of what you care about.
\`std::sync::mcsp\`. Thank goodness for crossbeam.
Might be possible to just use the stdlib‘s heap which basically does that for you. 
All popular debuggers allow a "step over function", which lets you step through your code line by line but never descends to new stack frame. This should help with your problem with STL.
&gt; One reason is debugging, stepping through code which replaced built-in functionality tiny function library calls makes debugging essentially impossible. It will step into all the tiny helper functions. It ruined C++ stl code for me (do I really need to step into three levels of abstraction when iterating an std vector?!). Thats more a failure of debuggers, not languages. Debuggers should support only stepping through *your* code, Just My Code features. [MSVC has it for C++](https://docs.microsoft.com/en-us/visualstudio/debugger/just-my-code?view=vs-2017). &gt; pops up a message box saying it can't find their source file, dismiss that and press shift-f11 to jump out back to where I was... You can use [this extension](https://www.erwinmayer.com/labs/visual-studio-2010-extension-disable-no-source-available-tab/) to prevent the no source available page from appearing, if it helps.
I think that the closest you are likely to get using the operating system's own configurable constraints for your application as a whole, rather than policies for individual packages. Sandboxing your application and enforcing OS restrictions should provide some defence. On Linux, you can apply [seccomp](https://en.wikipedia.org/wiki/Seccomp) (see the [sniffglue](https://crates.io/crates/sniffglue) crate for an example of how this is applied), which you could then pair with a suitable mandatory access policy via SELinux or grsecurity. For FreeBSD, you could use [capsicum](https://crates.io/crates/capsicum) and pair that with a [Jail](https://www.freebsd.org/doc/en_US.ISO8859-1/books/handbook/jails.html). These approaches can help confine an application - e.g. to working with specific read-only directories and only allowing the app to listen for inbound network traffic, rather than initiate a connection to other systems. OS resource limits can also prevent and warn on excess compute and disk usage etc. Outbound traffic policies can prevent a compromised app from downloading additional code externally etc. A separate host-based intrusion detection system can also detect changes to critical files (e.g. the ssh daemon or kernel). Host-based auditing (e.g. auditd or openbsm) can trigger on access to sensitive files (e.g. your bitcoin wallet).
 [https://github.com/Gekkio/imgui-rs](https://github.com/Gekkio/imgui-rs) 
I do kinda' like the specialized syntax for something as ubiquitous and important as heap allocation.
You want /r/playrust
Does that then mean that if I get errors with multiple executors, the library didn't implement the trait but implemented a runtime?
`mpsc`? (Naming is one of the issues with the channels ecosystem currently unfortunately.)
Multi producer single consumer 
I'm not sure what you mean, but if a library would hardcode say `tokio::runtime::threadpool` it would _probably_ cause issues with other runtimes. In general you wouldn't want two threadpools next to eachother. See for example `hyper`, they provide a way to change the used runtime: https://docs.rs/hyper/0.12.25/hyper/client/conn/struct.Builder.html#method.executor.
OP put `mcsp` of which there is none in stdlib
Oh, yes they did. Perhaps a typo or a foggy moment. 
GUI database, what is that? Dont reinvent the wheel, good dbs already exist. 
If only it was that simple: for (auto it = vec.begin(), end = vec.end(); it != end; ++it) process_item(*it); // I want to step into process_item, but skip the operator* for iterators Yes nowadays you have a better way of looping which avoid this particular pitfall, but I haven't been in touch with C++ lately, Rust has taken the spot so some of my grievances are probably outdated. So yes if things are on separate lines then I can skip over, but this isn't always how it is.
The easy way to do this is to sandbox your environment with Docker or such. This gets really inconvenient though, and is imperfect anyway. The hard-but-complementary way is to perform analysis, automated and manual, to know what a Cargo package is doing. [There are](https://cargofox.io/) [some projects for this](https://github.com/dpc/crev) [underway already](https://users.rust-lang.org/t/announcing-rustprazi-a-tool-to-build-an-entire-call-graph-of-crates-io/22696). Disclaimer, first one is mine.
This is a great resource. Thank you.
It looks interesting. 
Sure you call it 'failure of debuggers' but it impacts my experience debugging _Rust_ using a fairly standard setup of VSC + RLS + msvc C++ debugger. I'm not interesting in pointing fingers, what matters is that it impacts my experience. That extension is for VS where this issue is less problematic, at least it can be told to show disassembly. The msvc C++ debugger for VSC is more annoying as it pops up a literal dialog to find the source file myself. It shows some of the rough edges of debugging Rust code. Further I'm personally not in favor of many small extensions to paper over minor shortcomings. I'm really _really_ wary of installing arbitrary extensions. We've all had the discussion about untrustworthy dependencies yet nobody has an issue installing arbitrary extensions??
Yes but the decision was to go for a different solution than semantic inlining [see the RFC](https://github.com/rust-lang/rfcs/blob/master/text/2091-inline-semantic.md).
&gt; Also personally I think as shouldn't have been in the language. Just for integers or also for `struct as trait`? If also the latter, then what would be the proper replacement?
I have found a bug with an incorrectly specified packet length (see [https://github.com/Gymmasssorla/anevicon/commit/08091f0be7878fc1ae2affd992f07a9c1cf5fb08](https://github.com/Gymmasssorla/anevicon/commit/08091f0be7878fc1ae2affd992f07a9c1cf5fb08)). &amp;#x200B; Now if you run this command: ``` cargo run -- --receiver [5.5.5.5:5](https://5.5.5.5:5) --packet-length 66000 --wait 0s ``` You will get an error because of a too long message. I don't know if my operating system fragments UDP packets under ~65535 bytes, but it doesn't let me send a too long message.
What can I say... Thanks for writing this :).
Probably just a GUI for a database 
```std::mpsc```
Well, it seems like `failure::Fail` is what `std::error::Error` should have been. Fortunately they're largely compatible. Also `std::io::Error` is annoying AF to work with. In general I think the conservative approach to the standard library is a good balance. Though I still prefer too much (Python) over too little (JS).
Well, yes, but the safe code boundaries are not really able to deal with straight up malicious behavior right now. I think there's still a couple of ways to create unsound behavior in the stdlib even. They're the ones that have a lower priority because you really have to try pretty hard to get them to trigger, and it's not worth it to fix them now when they will be automatically fixed by some longer-term infrastructure improvement that is ongoing. You also have to think about dependencies. Either a "restricted" crate can only depend on other "restricted crates" (i.e. no unsafe), or you have to whitelist some crates that contain unsafe to make them available to restricted crates.
`as` operator, `mem::uninitialized`, `LinkedList`, mutex poisoning (specifically `lock` returning `Result` which you cannot do much with other than `unwrap`-ing), `sync::mpsc`, `time::SystemTime`
[Fixed](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=94befcaabb9cdec4387289db54962389), but what I don't understand is why size of inner enum increased...
Coming from Go, I love these things to be in the standard library. It's also nice to see that community made alternatives can be moved into the std
There’s fun history here: channels used to be a part of the language. They even had their own keyword!
Just out of curiosity what's the complaint with Linked List? 
&gt; Can someone explain this? For a few months, an additional measurement was made at N=27, to check that output format was correct for every program. So there were 4 workloads for each program [N=27, 2000, 6000, 10000](https://benchmarksgame-team.pages.debian.net/benchmarksgame/measurements/rust.html). That broke a bunch of contributed programs (for little benefit as-far-as I could see) — so I put things back to 3 workloads N=2000, 6000, 10000; and apparently forgot all about it. Programs measured before, I put things back, have 4 measurements; programs measured after only have 3 measurements. So, `C pidigits #1` N=10,000 is being compared to `Rust pidigits #3` N=6,000. Oooops. 
A bin gets to pick the concrete implementation, a library should just use the traits.
I think you want /r/playrust
thanks &amp;#x200B;
OnePlus 6 in chrome. 60 fps up to 1000. 5 fps at 10,000. 
90% certain, 100% wrong ;-)
There's no strict crate ownership of code in Rust, generics mess this up badly. But this is true even without generics to some extent.
A blast from the past: https://mail.mozilla.org/pipermail/rust-dev/2013-April/003867.html
Not even quite that, the representation of ~[T] was not the same as Vec&lt;T&gt;, in my understanding.
It's not used often, and it's missing a lot of features that would make it more usable (e.g. views).
You want /r/playrustservers 
Thank you as always for your kind and thoughtful response.
I think we just have different opinions about that topic and neither is wrong nor right. I think it boils down to the question if "I" (as an author of code) want to write code that is "just" easy and safe to use for the user or do "I" want to have those benefits for myself and co-authors. 
That makes sense, but it's a little problematic of an outlook. What people really want is a stable contract that won't change and works for everyone. We can't know that it's a stable contract that won't change and works for everyone until we've tested it thoroughly over years in production environments. Just putting it into std is a good way to make it look like it's a stable contract that won't change and works for everyone, but it's not a good way to *make* a stable contract that won't change and works for everyone. That said, right, maybe the optimal solution is forcing ourselves to not change it and adapt it later if necessary. I don't think it's there yet, though.
It's only difficult to set up if your platform makes it difficult to set up. At least on Linux, it's as easy as `sudo apt install cargo libgtk-3-dev`, then `cargo build`.
GNOME's been doing a lot of gtk-rs work lately. [GNOME Fractal](https://gitlab.gnome.org/GNOME/fractal) and [GNOME Podcast](https://gitlab.gnome.org/World/podcasts) are good examples which use a handful of widgets. I've used it for System76 and Pop projects just fine. The `cascade` crates helps to make the API less boilerplate-y.
&gt; Also personally I think as shouldn't have been in the language Can you justify this? I've never seen this argument and personally have never had any issues with `as` (though I guess I don't love the syntax).
I agree - if it's possible to use wasm-bindgen without all the Javascript nonsense why on earth doesn't their tutorial *start* with that? Nobody *wants* to use webpack, npm, gulp and all that nonsense. And even if you end up having to use some of that crap to interoperate with Javascript, it is crazy to have the basic tutorial include all of their complexity.
As currently implemented in Rust, it's useless, in particular missing any cursor-like functionality, making it essentially a worse `VecDeque`.
Not sure how that's possible in .Net, what's stopping me from P/Invoke it? or even read the Assembly IL and run it line-by-line?
I don't think a tutorial should start by setting up the environment that every will end up with. It should start with the simplest environment that works (i.e. not using webpack), and then motivate why you might want to use webpack (I have no idea) and then add it. Starting off with webpack and npm really puts me off (and it seems to have put richardanaya off too). Part of the promise of Rust/WASM is that you can write all of your code in Rust, not have to deal with Javascript and have it work on the web. Not "let's start by installing webpack".
I might be mistaken, but as far as I know enum layout works like this: 1. If there are at least two variants that have non-zero sized payload, use the usual tag + union of payloads layout. 2. If there are no variants with non-zero sized payload, layout as an integer. 3. If there's one variant that has payload: 1. Count payloads niche values (for bool it's `2..=255`, for boxes and references it's 0, for chars there's two large ranges that are never used, and so on...) 2. If there are more payload-less variants than niche values, fallback to the first layout. 3. Otherwise, represent the only payload as itself, and other variants as its niche values. So for `Lazy&lt;()&gt;` with your previous implementation there was only one variant without payload, and now there's two. But `Box&lt;dyn FnBox()&gt;` seems to only have one niche - null, so now it it no longer benefits from niche value optimization.
You want a different use case than what the WG thinks is the majority case. They want to focus on integration with existing JS, not pure Rust frontends.
What would be the downside of marking it unsafe? It gives you a nice `unsafe` block to remind you where you have tricky invariants. And library users aren't affected because they don't need to implment the trait anyway.
&gt; Well, yes, but the safe code boundaries are not really able to deal with straight up malicious behavior right now. In theory it should, but it's a matter of priorities. Seems sensible. Safeguarding against malicious behavior is a ton of work. &gt;You also have to think about dependencies. [...] You definitely needs some way to say "I trust that this crate's use of unsafe exposes no undefined behavior". It would also be complicated by stuff like closures. `std::iter` might not need IO access, but it might call a closure that does and the security model would need to reflect that. A simpler security model might make sense for most crates, though. And of course, these kind of guarantees only helps if it's maliciously trying to interact the system. If a hash library maliciously returns 0x00 for all inputs, then this is not going to stop it. &gt;It's probably possible to build and use Rust dependencies in a totally untrusted manner by doing all the builds inside a locked down Docker container or something There's also sandboxes like [gvisor](https://github.com/google/gvisor). You do have to pay a fairly heavy performance price, though.
The problem with `as` is that we use special syntax for something that could easily have been a function – and the default does too little checks (for example you need clippy to check for alignment on pointer casts).
Could be a generic function `fn as&lt;T, V: T&gt;(v: V) -&gt; impl T`.
I really do not like mutex poisoning. I get why it exists, but I have yet to find and application where you would do anything else besides unwrap on the result.
I disagree. Rust has threads, mutexes, and atomics in std - a sync'd queue feels like another basic concurrency primitive. Crossbeam should just make it back into std later.
So, in the case where I get errors about there being multiple executors running at the same time, or an executor being shut down (when calling the lib), does it mean that the lib has used a concrete implementation?
Runtime checks are not enforceable without serious performance implications, but in theory I suppose we could scan a crate to see all possible syscalls it might make and then show that list in a pretty format on Crates.io. It would then be up to you to audit your dependencies by checking that list for each.
The problem, of course, is wanting to step in the function: auto it = my_method(container-&gt;begin(), container-&gt;end(), *x); If you are using `std::unique_ptr` for `container` and `x`, you are in for a world of hurt, because those simple looking `-&gt;` and `*` are *each* a dozen "step in" before you finally get into `my_method`. The same is for taking a `std::shared_ptr` by value, etc... The problem is that there's no syntax to tell the debugger *what* you want to step into, so it steps into **everything**.
Interesting. I was aware of the need / lack of cursors; I didn't realize anyone thought they were important enough to not stabilize a implementation of Linked list. I agree that they are almost never the right choice and if you need one you probably need the more advanced api of cursors. So once [this rfc](https://github.com/rust-lang/rust/issues/58533) gets implemented would this be addressed satisfactorily? 
In gdb, I just run `finish` every time I step into something I don't want. Not ideal, but not quite a world of hurt.
I would prefer `S"foo"` or something.
Well it sure would give my alt gr button more work...
According to the [Syntax documentation of the `regex` crate](https://docs.rs/regex/1.1.2/regex/#syntax), this is not supported
What evidence did you have that could make you "90% certain" ? 
"mute" is probably the right way to pronounce it. I'm just strange... 😀
I agree `std::io::ErrorKind` is super annoying to use any time you want to construct a `std::io::Error`. 
We're lucky that hashbrown is API compatible with std's hashmap, but this isn't necessarily true for all replacements.
The JavaScript Debugger in Chrome has this feature IIRC (i thingk it allows you to step through expression evaluations, and not just lines). And when I debug C or C++ code I tend to use gdb with a dashboard like pwndg (I usually do Capture the Flag stuff) and use `ni` to step over functions without stepping over the whole line
C# has/had the same problem with `MutexAbandonedException`
No, it does not and likely never will. The opening sentences of the regex docs state: &gt; This crate provides a library for parsing, compiling, and executing regular expressions. Its syntax is similar to Perl-style regular expressions, but lacks a few features like look around and backreferences. In exchange, all searches execute in linear time with respect to the size of the regular expression and search text. Recursion isn't explicitly mentioned here, but recursion I suspect prevents linear time matching, and certainly enhances the regex to support matching things beyond regular languages. You have a few choices: * Don't use a regex for this. (This is probably the route I'd go.) * Find a way to use multiple regexes to do what you want. * Use [Oniguruma](https://github.com/rust-onig/rust-onig). * Use [PCRE2](https://github.com/BurntSushi/rust-pcre2).
I'll definitely be working on this. It's the thing I want to improve the most. I hope the next iteration is much better.
https://doc.rust-lang.org/1.2.0/std/sync/struct.Future.html
Looks great.👍 Honestly today I was adding map_err to my code to get better messages. I think there are more uses for this than stack traces. Could be used to add other info like function inputs to errors. 
Ye if crossbeam becomes std it'll be... Interesting 
One advantage of `LinkedList` is O(1) `append`. Rayon uses this during the reduction phase of `collect`.
Most everything to do with Iterators. If they had just waited for `impl Trait` the API and documentation would be much cleaner... Likewise, I suspect that all the slicing operations should still be waiting for const generics, `fn as_slice&lt;len: usize&gt;(&amp;self) -&gt; &amp;[T; len]` seems about right. The prelude feels like a mistake to me. Not having a prelude, but having it special cased like it is. Possibly fixable in a backwards compatible manner though. For that matter `#![no_std]` also feels wrong, `std` could just be treated like any other crate now that we don't have to type `extern crate foo`. Of course, all this runs into the whole "we wanted to publish a usable backwards compatible 1.0" thing.
Thanks, I've switched to using Oniguruma.
&gt;The idea of Rust is to make invalid memory states impossible I have never been so hyped regarding something related to programming
That looks like it should give a compile error, unless `z` is secretly a reference.
About cursors, I don't think Rust should have them. Linked lists in standard library were a mistake in my opinion. Linked lists are very much a niche data structure that shouldn't have been in a standard library, but it was stabilized for Rust 1.0 by being mostly ignored (other than changing its name from `DList` to `LinkedList`) and it stayed unchanged aside of introduction of `contains` method in Rust 1.12.
... yeah... Rust has that effect on people. Convincing my coworkers to start transitioning to it was astonishingly easy.
It would also turn all of [these](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22) issues into security issues. I think Java is a pretty good example of why relying on the language for security isolation is generally a bad plan.
Oh... right. Seems rather niche, but I mean, `LinkedList` is niche itself. This probably could be done with `Vec&lt;Vec&lt;T&gt;&gt;` (if I understand correctly what is being done) or something if Rust didn't have linked lists, but linked lists don't seem like the worst choice here.
Hmm. Thanks for sharing. I think I probably agree with you. if they're frequently not the right choice I guess why are they there? I can see people complaining about the lack of them since you have to drop into unsafe to implement them though. And also complaining just from a feature parity perspective (Java and C++ as well as many others include linked list in the stdlib)
`as
Your other thread is probably blocking in the read call. One solution would be to use tokio instead, because that uses non-blocking IO.
I have stored a prng in a mutex, and if the mutex got poisoned it _doesn't matter_ because the prng is always in a consistent state no matter what. It was some other code that did the panic, so I do not care, you can just grab the prng from the Err side and continue.
\&gt; Most everything to do with Iterators. I agree. I hit constantly problems with iterators, mainly because I need generators or iterators that allow to do more than NEXT. &amp;#x200B; The problem is that also is too hard to make replacements. 
We will add it. The downside is that technically that's a breaking change. However, now I'm not sure if that's really worth a minor bump, given 0 external implementations of it.
I can't seem to find a good explanation about what Box actually is for. I read the docs on it and I get that it stores things on the heap instead of the stack, but why would you want to do this? I thought it was ideal to store things on the stack whenever you could.
Sure! It's all about making good abstractions. The question here is where the abstraction boundary lies. Most obvious one is between the library and its users, and it's the most important one. A less concrete boundary is between particular parts of the library and the rest of it. Given the ridiculously small size of the code right now, and the number of contributors, there isn't much value in that boundary. If we were talking about something like gfx-rs, then it would make much more sense.
Ok, let's say that no optimization is done - we have 8 bytes for max(Box, Unit) (size if Box - 8 * 8 = 64 bit pointer), aligned after enum tag - shouldn't that be 8 + 8 = 16 bytes?
Giving your `altgr` key more work is as simple as changing your keyboard distribution;3 I have `{` in `AltGr+Q` and `}` in `AltGr+W`, also `[` in `AltGr+Z` and `]` on `AltGr+X`, both on linux and windows C:
The point about Iterators isn't obvious to me. Could you please give an example where it would be much cleaner? About `#![no_std]`: although I totally agree that it feels wrong, I am unsure if it is that easy. `std` sets up a few thing like panic handlers(as far as I know, you need to setup a few additional functions/symbols to work in no_std mode, one of them is panic handler). And I don't think it is a good idea to turn off and on those definitions implicitly. 
I think this is more a question of defaults- a `try_` variant that lets you grab the data from a poisoned mutex is probably better than writing `.unwrap()` all the time.
&gt;The problem is that there's no syntax to tell the debugger what you want to step into, so it steps into everything. That's not true. In VS you have *Step Info Specific* command which it's use for exactly the aforementioned case ([example](https://40jajy3iyl373v772m19fybm-wpengine.netdna-ssl.com/wp-content/uploads/sites/9/2019/02/step-into-specific.png)). &amp;#x200B;
Personally I like seeing the unwrap all over the place. I like to see the panic moments written down.
Not sure how I feel about that :D I guess having `{` and `}` at `AltGr+Q` and `AltGr+W` would be better than them being under `AltGr+7` and `AltGr+0`, less finger contortion that way.
`Box&lt;dyn FnBox()&gt;` is a fat pointer, so it takes 16 bytes.
This was before reborrows?
Several things. If something is very large, you probably don't want it on the stack. A neat thing with `Box` is that it can hold unsized types, unlike the stack, so you can have things like `Box&lt;str&gt;` (which is basically like `String`, but without a `capacity` or the ability to grow). Also you can move a `Box` by only copying the pointer and not all the data (which, again, may particularly be desirable with larger values). Someone else could probably come up with more use cases.
Your thread is blocking on read(). One possibility would be to save a handle to the tcp stream and close it, that would wake up the thread.
It it that simple: [https://imgur.com/TVb4azq](https://imgur.com/TVb4azq)
Ha! Well played.
BinaryHeap does not do that - as its name suggests it is a [heap](https://en.wikipedia.org/wiki/Heap_(data_structure\)). It just uses a vector as its backing storage.
You wouldn’t need those individual structs for each method, they could return impl Iterator instead.
How is this different from Safe Haskell?
this would be just as true if it were a function
In a functional immutable strongly typed language. You should see the type checking errors. It's like an abstract math random poem generator.
Can you explain why? 
&gt;Rust is also safe but with safe abstraction around unsafe codes. I don't know if this is that different. The C# standard library presumably has to do much the same thing, wrapping unsafe code in safe C# functions. Relative to C or C++, Rust has a unique potential here due to the safe/unsafe distinction. In principle, it would be possible by banning unsafe code in the untrusted crate, and restricting which functions can be called. But hardening against intentionally malicious code would be quite difficult, and even if it were achieved somehow, it would probably be a hassle to use. To my knowledge this is a pretty uncommon feature to support even in high level languages.
&gt; Not having a prelude, but having it special cased like it is. How is it a special case?
I strongly disagree with you on the iterators. I think named types are always preferable to `impl Trait` (in public functions). And `impl Trait` is insufficient to capture the full functionality of the iterators we have today. For instance, when using `map` on an iterator that implements `ExactSizeIterator`, the result is *also* `ExactSizeIterator`. How would you conditionally implement `ExactSizeIterator` on an unnamed type? Specialization would make the api much messier than it is now.
&gt;Haskell libraries are however a different matter entirely. Those libraries do tend to be dense wrt. the concepts they introduce. I think to an extent it's just a technicality whether something is part of the language or a core component of the standard library (the difference matters in some ways, but not in others). At the most extreme, the syntax and semantics of a simple Lisp might be almost trivial, but you'll still have a lot of trouble understanding any non-trivial code because most of the "language" is standard library functions.
There are 2 things here: 1. Isolating Apps (end users): this must be done by the OS (see the Android example, Mac OS, iOS and flatpak do similar things) 2. Isolating test and compilation environments (developers): this could be done by cargo. Bazel does this. A docker driven system would work. In general, cargo could set up a sandbox for compilation and testing. 
There are 2 things here: 1. Isolating Apps (end users): this must be done by the OS (see the Android example, Mac OS, iOS and flatpak do similar things) 2. Isolating test and compilation environments (developers): this could be done by cargo. Bazel does this. A docker driven system would work. In general, cargo could set up a sandbox for compilation and testing. 
Ahh, I thought you were testing lower level stuff. Well Ethernet would frag it into chunks of 1500 bytes, but this is after it's been reconstructed.
Assuming `Box` is a library struct like it should be, when taking a reference to `x.0`, it should mark `x` as borrowed. At `let z = x.1;`, the compiler could detect that only the first field is borrowed, so the second is free to be borrowed, but since `Vec` isn't `Move`, it should ask to take `x.1` by reference, which would make `std::mem::drop(z);` a no-op. Even if it did take `z` by value, it would mean that `x` now has a hole in its second value which is impossible in library code without an explicit `Option::take()`. If the `y` reference was dropped, you would expect `x` to be unborrowed and be able to be passed to another function or returned, but then the function it's being passed to wouldn't be able to know about the hole, and if it were allowed, would cause a double-free.
Well, yes. But you would not be able to store them in a struct. Or use in a trait. And I have seen a few usecases, where this was needed. So, although, I think it is not ergonomic from library writers perspective, it is ergonomic to users. 
The only other Reddit API crate I could find was [rawr](https://github.com/Aurora0001/rawr), but that's also fairly old. Rather than looking for a specific Reddit client crate, you might want to consider just using a general purpose HTTP client to hit [https://www.reddit.com/user/andreaskrueger/comments/.json?t=all](https://www.reddit.com/user/andreaskrueger/comments/.json?t=all). [reqwest](https://github.com/seanmonstar/reqwest) is a very popular HTTP client library that you could use for that, and it doesn't have too much of a learning curve. There's an example of using reqwest for simple untyped JSON [here](https://github.com/seanmonstar/reqwest/blob/master/examples/json_dynamic.rs), and an example for reading JSON into a struct [here](https://github.com/seanmonstar/reqwest/blob/master/examples/json_typed.rs).
&gt; If they had just waited for impl Trait the API and documentation would be much cleaner... I don't know that this is true, since you still can't have `impl Trait` in a trait interface definition, and "Iterators are as fast as the equivelent machine code" is one of the very earliest killer features in Rust.
Well I wrote orca. I wouldn’t really say it’s a great quality crate, and I stopped actively working on it about a year ago, out of laziness pretty much. I don’t think there is currently a way to accomplish what you are trying, as the amount of Reddit’s api orca actually covers is rather small (https://github.com/IntrepidPig/orca/issues/2). It turns out the reddit api is kinda huge, and at the time I couldn’t think of a way to efficiently write a Rust layer over all of that. It’s especially tedious to account for things in the JSON api like fields than may not be present, or using empty strings as null. As a way of getting around this, I thought about implementing a more low level version of the api that will cover things like authorization, ratelimiting, HTTP headers, etc and allow the user to interact with reddit by simply picking an api endpoint (a String) and returning the JSON as it was received from reddit. This would offload some of the grunt work to the API user, but it would make orca a lot more flexible and effectively cover the entire reddit API, and it would still take care of the complicated stuff. I never got around to this, but if you would be interested in something like this, it should be pretty fast to put together on top of the existing orca codebase.
I've been running into this issue a lot as I get into more sophisticated usages of `impl Trait`. We make a lot of use in Rust of "transitive traits"; that is, we have things like `impl&lt;T: Clone&gt; Clone for Struct&lt;T&gt;`, and there's as yet no way to capture that in `impl Trait`. I also run into issues with lifetimes.
You could try using \`sendmmsg\` to send more than one packet per syscall and reduce cpu load that way.
Ah sorry, I was thinking gdb/lldb. Actually, in VS you have even better: you can tell the debugger to skip "not your code".
"Assuming Box is a library struct like it should be" It is not. The compiler treats Box completely transparently and can individually track the initialized-ness of each field, just like a local variable.
I strongly believe that `std::forget` should never have been made safe.
Wouldn't they be marked `unsafe`, as they cause undefined behavior on certain inputs?
That's clever, actually. I only used `finish` to know the result of a function without giving it a name, but had not thought about using it for skipping intermediary expressions. I'll have to keep it in mind!
Oh, I do understand that if we were to implement Box in a library, the above code would give us an error. But, if I understood your previous comment correctly, the above code should be rejected not because the compiler is not smart enough, but because that code contains some flaw/source of bugs. Am I misunderstood you? 
It is a (long-standing, very embarrassing, but generally non-problematic-in-practice) compiler bug that they have undefined behavior.
No. The fact that it exhibits UB is a bug. It _should_ be safe.
Other crates can't have them. I.e. I can't go ahead and define `my-std` with a prelude (if this was an option, it should probably also be possible to import `my-std` without the prelude, possibly even by default).
&gt; you still can't have `impl Trait` in a trait interface definition Good point on this, I basically assume that will be fixed one day though.
What are you trying to do? Depending on your use case, another tool might work much better :) 
Good points - haven't run into these probably as a result of not actually having attempted to re-implement iterators.
Would you replace `Index`/`foo[i]` with `*foo.get(i).unwrap()`? That's the comparison I'm making here. In normal usage it's *always* a bug if a thread panics while holding a lock, and it's a relatively uncommon exceptional case that you can recover from that.
Indexing is core enough to the rust experience that it has its own operator, so you learn that indexing can always panic. Other arbitrary methods aren't. That said, yeah I use Get instead of Index as often as possible, so your argument falls kinda flat to me.
You can store them in a generic struct, I don't think it's a good idea to write the type `Map&lt;SliceIter&lt;'a, u32&gt;, some_function&gt;` in your struct anyways, makes things to inflexible. I assume issues with traits will be solved eventually. I think `impl Trait` is more ergonomic to users from a documentation perspective, easily worth the trade of with structs. /u/thiez has some good points about what it can't do though.
And I hate it. The fact that you're partially moving the box means it's no longer a value. The moment you pass it out of the function, everything breaks. fn use_box(b: Box&lt;(u32, Vec&lt;i8&gt;)&gt;) { println!("{:?}", b) } fn main() { let b = Box::new((6, vec![1,2,3])); let _v = b.1; use_box(b) } - Compiling playground v0.0.1 (/playground) error[E0382]: use of moved value: `b` --&gt; src/main.rs:14:13 | 8 | let _v = b.1; | --- value moved here 9 | 10 | use_box(b) | ^ value used here after partial move | = note: move occurs because `b.1` has type `std::vec::Vec&lt;i8&gt;`, which does not implement the `Copy` trait error: aborting due to previous error For more information about this error, try `rustc --explain E0382`. error: Could not compile `playground`. To learn more, run the command again with --verbose. I like Rust precisely because it has very little magic, and this is what I'd call magic.
Really, it just looks like it should error (and would if you passed the box out of the function) because it behaves differently from how you'd expect Rust values to behave.
You can store them in a struct.
For what it's worth you can return `impl Trait1 + Trait2`, e.g. `f() -&gt; impl Iterator&lt;Item=Foo&gt; + Clone`. Doing so conditionally is a problem though.
Agreed
Oh, so it makes sense then, thanks :)
I’m part of the Ensembl project and this project. Feel free to ask any questions
Do you mean that "memory leaks should be unsafe" or just not `std::forget`? If the latter can you expand on why?
Neat shortcuts. For DuckDuckGo users, the equivalents are `!rust` (stdlib), `!crates` ([crates.io](https://crates.io)), and `!rs-docs` ([docs.rs](https://docs.rs)), [among others](https://duckduckgo.com/bang?q=rust).
Thank you so much for posting this! The inability to customize the search engine list was by far my biggest gripe with Firefox. (It wasn't a big enough gripe to to justify dealing with Chrome's antipathy towards MRU Ctrl+Tab though, so I've just been sucking it up)
In an ideal world, we'd have had proper coroutines before having built iterators and futures. Then iterators and async streams would be just coroutines with special-cased return types. Also const generics and variadic generics from the get go, so we don't have a septillion effectively duplicated trait impls for arrays from 0 to *only* 32 elements and tuples from 0 to dunno-how-few elements. Well... I wouldn't call iterators and all those trait impls premature, really, but I definitely call coroutines and const generics too late.
The big problem for me is that it is inconsistent across other types. If it's consistent all the way across the ecosystem, then it's not magic, it's just the way the system works. &amp;#x200B; As it stands, yes, it's magic and I don't like it even if it is useful.
&gt; If something is very large, you probably don't want it on the stack. Why not? &gt; so you can have things like `Box&lt;str&gt;` (which is basically like `String` So is `Box&lt;T&gt;` pretty much just the non-iterable equivalent of `Vec&lt;T&gt;`? &gt; Also you can move a Box by only copying the pointer and not all the data So, as a noob to memory management, I was under the impression that the only data that lives on the stack is what is present in the code at compile time (e.g. `let stuff = "hello"`). Is that not correct? I may be confused about how this aspect of Rust works. I've used `reqwest` to get data from APIs, and (to the best of my knowledge) the data that came back had to be put on the heap because my compiled binary wasn't aware of the size before it received the response. Because of that, I used references to it instead of copying it around. I didn't use a `Box` for this at all... Again, super noob questions, but these are the things keeping me awake at night.
I'm going to assume you've read the book. If not, please do so first, it's a great way to learn the features Rust has to offer. There's no real one-to-one relation between the abstractions Java and Rust offer as programming languages. There are definitely plenty of features that are similar, but that's about as far as it goes. As a result, you shouldn't go about this "one class at a time". I think the best way to go about this, is to start reimplementing a single feature from the ground up in Rust. When you get that working, try to add more features. 
Seccomp is overkill. Why not just execute \`[build.rs](https://build.rs)\`'s in namespaces? There's no fundamental reason why this isn't enforceable.
If you consider this code: ``` struct Foo { a: Vec&lt;u32&gt;, b: Vec&lt;u32&gt;, } let x = Foo { a: vec![0, 1], b: vec![2, 3] }; let y = &amp;x.a; let z = x.b; drop(z); println!("{:?}", y); ``` It would compile(modulo some syntax errors). Partial struct destruction is a thing. You can move a part of a struct while borrowing the other one. If you couldn't, you wouldn't be able to write code like: ``` let x = (vec![0, 1], vec![2, 3]); let (a, b) = x; ``` As it is sugar for ``` let x = (vec![0, 1], vec![2, 3]); let a = x.0; let b = x.1; ``` And this requires to have a struct with a "hole"(after you moved `x.0`, `x` is no longer valid, but you still know, that part of `x`, namely `x.1` is valid, so you can move). So, for me it would be a surprise if the code we started with hadn't compiled. In a sense currently `Box` is truly transparent. You just work with the box, as it is a value. And I think that `DerefMove` should make it possible so leave `Box` transparent. 
No. just. No. Do not invent two (TWO!) new terms for things which are very common, simple, and \*old\* concepts. &amp;#x200B; sheesh. If your program is supposed to be unix friendly, then it doesn't loop like this since it's supposed to hand off the results so it can be combined with other programs. If you are not writing a unix friendly program then it's likely you should have probably made it \*GUI\* driven since this is the \*same exact thing\* only without a pretty user interface. So all the penalties of a command line program but none of the benefits (combining them and using standard terminal tools to leverage value from the terminal).
I didn't look at the code, but there might be a little overlap with some of the [`tower`](https://github.com/tower-rs/tower/) crates.
What exactly are you talking about enforcing? The event-stream issue was at build time, not exec time, to my memory. Restricting build scripts is not unenforceable at all.
You can add search engines for crates.io and docs.rs to the search bar in Firefox by just clicking a button. You shouldn't need advanced bookmarks They did in a recent update hide the button under the three dots button in the URL bar
I ran into this as well when I was trying to write a moderator bot that would: * Detect an incoming post * Check if the incoming post was a cross post that led to an external link * If so, delete the post and add a comment about why it was deleted That is such an obscure case that orca, rawr, or even praw did not supported it.
Better for std `file:///home/&lt;username&gt;/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/share/doc/rust/html/std/index.html?search=%s` I wonder what it would take to do for "rust doc for current project"
It's pretty obtuse to say iterators were prematurely stabilized. Iterators are one of the main selling points of the language, and imo it's entirely possible that rust wouldn't have survived up the point where impl trait was implemented without making a compromise on iterators. It's like saying the borrow checker was prematurely stabilized, or traits themselves. It's not premature stabilization if the language literally would not exist without them.
For std I always go for `$ rustup doc --std`
You can easily add these shortcuts like this: - go to https://crates.io/ or https://docs.rs/ or etc - right click the search input - choose "Add a keyword for this search"
Thank you, I'll try it.
That's... the point/joke? I acknowledge as such in my last line. This post is getting at several things - These are some areas I think we should look at in the future, for Rust202x. - As much as "standard library features" being standardized too early, you should ask whether the language was. They had good reasons to want to hit push out 1.0, but there were also good reasons for the opposite. A bit of searching should be able to find you lots of debate from the time. - That 'premature' doesn't exist in a vacuum. The post mainly focused on the first bullet point, otherwise I would have picked on things like `Box` that everyone agrees needs to be improved (un-special cased). I think slices are even more important for the language than iterators btw. Curious choice of what to pick on.
While that's true, what you can't do is this: fn wrap&lt;T&gt;(value: T) -&gt; impl Trait + CloneIfTIsClone
Use Kotlin, probably. Rust doesn't play well with ownership cycles or downcasting, but those aren't any problem for Kotlin. Rust's dynamic dispatch is okay and static dispatch is even better than C++, but the lack of JIT and GC means your software needs to be designed to not depend on that runtime support. It's certainly still worthwhile to learn Rus. At the very least it *will* teach you how (and maybe why) to avoid overlapping scopes of aliased mutability, and that's useful for any imperative language especially if you would like to write concurrent software. But if you still love your Java designs and are just sick of NPEs, Kotlin is the language to migrate to.
An advice which is not specific to Java/Rust. When picking up a new language is never a good idea to attempt to shoehorn the language you intend to learn to the paradigms you are used to. Not only it's not very productive in terms of learning but also kinda beats the point of you trying to pick up a new language. The best way is to just go throug the [Book](https://doc.rust-lang.org/stable/book/) chapters. And if you find something you can relate or associate with, that will help. Rust is not easy to pick up language. And it doesn't share as much similarities to Java as for example C# or even Python would. So I don't believe that one can simply attempt to rewrite existing code from one language to another by not consulting the language guide first.
 &gt; I was under the impression that the only data that lives on the stack is what is present in the code at compile time (e.g. `let stuff = "hello"`). Is that not correct? I would rather say, that the only data that lives on the stack is local variables and arguments(plus some technical stuff, like "where your function wos called from"). *NB. The string "hello" actually does not live on the stack, only the refference does. The actual string usually lives in static memory* &gt;&gt; If something is very large, you probably don't want it on the stack. &gt;Why not? Well, when we are talking about low level stuff, there's a lot factors that do affect your performance. One of such factors is cache-locality. In simple terms if you access data that is close to each other, your data accesses are much faster. One of the reasons stack is fast is because it is small, so you do fall under previous optimisation. And if you put large struct on the satck, your locals would be separated by this large chunk of data, and thus fall out of the optimisation. Returning large struct is also not the best idea. Because every time you move your struct it will copy its whole content. Over and over. And if had it in a box, it would only copy the pointer, which is only 4/8 bytes, and thus is way faster. P. S. Do note, this is very simplified. 
I do think that memory leaks would ideally be unsafe, but I recognize that it's probably impossible as long as `std::cell` can coexist with `std::rc`. Nonetheless, I think that too many things rely on the assumption that destructors run (for instance, Mutex Poisoning, Guard clauses, anything that ensures that references (especially via raw pointers) don't outlive their referee)
Slicing with dynamic lengths is useful, which your proposed `as_slice` doesn't handle. It can/should exist on addition to the dynamic ones.
I am the creator and lead developer of Redox OS. Let me know if you have any questions about this release!
I'm under the (possible false) impression that we'll be able to pass dynamic values as the "generic" in const generics?
`!docsrs` and `!docs.rs` also work.
I'm seeing a bunch of GL libraries, do you have graphics drivers already!?
Note that since `impl Trait` can't be used on trait functions, Iterator would still have to be implemented as it is today
Its based on the mesa software rendering. 
Yikes.
Amazing. Can't wait to take it for a test drive.
From a high level view, what are the big features you still need/want to complete with Redox? Because, from a quick glance from someone who hasn't followed it closely, it seems very useable already.
We are using llvmpipe for software rendering: https://www.mesa3d.org/llvmpipe.html
Apparently not.
Thank you! Love and support from around the world!
&gt; according to archive.org Incidentally, although archive.org is wonderful, the benchmarks game webpages &amp; the benchmarks game measurements, are versioned in [a GitLab repo](https://salsa.debian.org/benchmarksgame-team/benchmarksgame). That GitLab repo is complete and easier to work with.
Having permanent installs is not really feasible at this point. Getting to some level of stability is a big feature that I see as really important for moving forward. If a release could be installed and upgraded forever more, it would probably be 1.0.0.
You are probably looking for /r/playrust
&gt;So is Box&lt;T&gt; pretty much just the non-iterable equivalent of Vec&lt;T&gt;? I suppose that's one way to describe it, more or less. But a critical aspect of `Vec` is that it can expand in size. Also note that you can have `Box&lt;T&gt;`, `Box&lt;[T]&gt;`, and `Vec&lt;T&gt;`. The latter two are both "iterable" as you describe it, but only the `Vec` can expand in size. &gt;So, as a noob to memory management, I was under the impression that the only data that lives on the stack is what is present in the code at compile time (e.g. let stuff = "hello"). Is that not correct? Actually, the string `"hello"` won't be in the stack. Constants and globals are instead in the data segment. Depending on what you mean by "present in the code at compile time", you're either 100% correct (well, excluding things like `alloca()` in C, and all sorts of things you can do in assembly) or 100% wrong. The size of the stack frame a function needs is determined at compile time based on the space its local variables need, but the actual values exist at compile time. For instance, for a recursive function, you can have many stack frames based on the same function for each recursive call, and the number of them may be determined at run time. Read up more on the stack if this doesn't make sense. Another example of `Box`, that isn't about performance: ```rust enum List&lt;T&gt; { Empty, Cons(T, Box&lt;List&lt;T&gt;&gt;) } ``` This implements a singly linked list. The enum takes as much space as `Cons`, which is the size of `T` plus the size of a pointer for the `Box`. Without `Box`, it would fail to compile, because it's size would have to be infinite/undefined.
You should probably go to the rust game subreddit
I've done quite a few code migrations between ecosystems that seemed wildly disparate, and the most important step I've found is to strip out everything but (or at least identify) the bare minimum you actually care to keep. Trying to go through every single class and move everything over is enormously complex, especially since you might find much of that code doesn't even apply after you move to rust. Specific to rust, I recommend really practicing From/Into and understanding collect. You don't really have "objects" in the same way, but understanding how one type can be changed into another is really going to help you. Study lots on composition vs inheritance, even just from the Java side. Implementing traits takes much more compositional thinking - you're not saying so much "I inherit from X, therefore I'm also X", rather you say "I implement this interface, therefore I can be used by these things". Composition as it works in OO won't directly translate over, but thinking in interfaces and traits in Java will help you a lot more than thinking in inheritance. 
Thanks!
Rust runs blazingly fast. You probably want /r/playrust.
Use a `Vec`. Linked lists are often advertised as being good at deletions, but that's only true when you already have a cursor at the desired node. If you don't then while navigating to said node is `O(n)` just like copying the values in an array, it's orders of magnitude slower due to processor behavior that many computer science classes don't mention because its too low level.
[Parse HTML, of course](https://stackoverflow.com/a/1732454/2083075)
Just like in the other comments, read the book while learning. Now, the thing with rewrites is that you need to know what the program does and not how. Look at your Java code and note down what each class, method does (tasks) and how data is accessed from a field. Then find the order in which tasks are executed and how data is changed. This sounds hard but you can start by just summarizing the program. For example, the guessing game tutorial in the book just generates a random number which is stored in the program, then the user can enter input which is parsed to a number that is compared to the random number. If the answer is correct it returns a congratulation message. I left out a lot but you can do the same. After figuring this out, try to implement a major step (e.g. generating a random number) one at a time.
What sorts of things are still causing that instability? Is it that a proper update system is not in place? Or is it that despite using Rust, there are still too many bugs that cause crashes? Or is that too many things keep on changing (the other type of stabilization)? Something else? Also, how soon do you think that could be fixed? Because 1.0 has a *lot* of power, just look at the Rust language itself. Sorry if I'm asking too many questions. 😅
Your second comment is a great description of exactly why forget is safe - making it unsafe would have been pointless and would have made the definition of unsafe much less clear.
Instead of removing all the a's from an existing list, create a new list that has all the elements minus the a's. Easy and O(n) with a `Vec`.
System call and scheme stability. The base of Redox - kernel, drivers, and services, need to be stabilized.
Regular Expressions are not very well standardized and each implementation tends to have its own extensions to the language. AFAIK, if you want to write portable RegExps, you should stick to the "basics". 1. \^ start marker 2. $ end marker 3. . any character 4. \[abc\] only these characters 5. \[\^abc\] not these characters 6. (abc) this subsequence 7. (abc|def) either subsequence 8. \* previous character or sequence happens 0 or more times 9. \+ previous character or sequence happens 1 or more times 10. ? previous character or sequence happens 0 or 1 time 11. {x, y} character or sequence happens between x or y times (or exactly x times if you omit y) 12. A couple of escaped special characters that I always have to check the meaning like \\w, \\s, \\b Everything else is an extension and you should be aware that your regex might not be portable if you use them.
IIRC, we hand undefined behavior due to this bug in Rand.
As a devops engineer that actually doesn’t much matter to me at all, as my general upgrade strategy is to deploy a new VM. What’s the story for aws/cloud? How about for containers? If I wanted to use redox to run a webserver, how would that go?
`Vec`s knock several seconds off my `VecDeque` implementation, but I'm still left with a 19 second runtime compared to 0.02 seconds in my C implementation. &gt; Linked lists are often advertised as being good at deletions, but that's only true when you already have a cursor at the desired node. Exactly! Super powerful if you have such a cursor. :) Thanks for being candid about how the Rust team feels about LinkedLists. The lack of the `remove` method makes the implementation incomplete IMO, but your explanation explains a lot and it's a lot more sensible and understandable than any computer scientific explanation anyone has provided that I've found. You're quoting this: &gt; Almost always it is better to use `Vec` or `VecDeque` instead of `LinkedList`. In general, array-based containers are faster, more memory efficient and make better use of CPU cache. My lists have 50,000 elements. In a `Vec`, presumably the elements are kept contiguous to each other as they are in C++ `Vector`, so taking out an element means a block of on average 25 elements needs to be shifted over in memory. In my C implementation I make an array in which I plonk all 50,000 values, and then just manipulate the pointers and don't care about leaving any values dangling: at the end of my program, the entire array gets freed anyway. It seems more memory efficient to me to manipulate a couple of pointers than to shift many KB in memory. Is my C implementation an example of a linked list that's entirely on the stack? If so, why is it pointless to use a linked list in my particular case (after all the performance speaks for itself)? Should I have done that differently?
Ahh, that makes sense then. Just like in Rust, you want to make sure you get those right. Thanks for the Q&amp;A!
I also find just the `!` bang quite useful, which is for I'm Feeling Ducky (to instantly open the first result). For example: `! rust clap`
\&gt;but I'm still left with a 19 second runtime compared to 0.02 seconds in my C implementation. &amp;#x200B; Are you running with \`--release\` or optimizations?
From my last attempt to play with redox I remember being sad to find out that it wasn't really possible to have redox run on real hardware. Any update on this? 
I am not! Thanks for pointing that out. With `--release` the runtime is 1.1 seconds.
Maybe I don't know Rust well enough yet, but why would you want a garbage collector? It feels to me like Rust's lack of GC is a great feature rather than an absence. Am I missing something?
It depends on your hardware. Graphics support almost always works. Input usually does, with PS/2 emulation if required. Sound uses Intel HDA, but many codecs have quirks that need to be addressed in the HDA driver so it may not work outside of VMs. The worst thing is networking. Network support is limited to the e1000 and rtl8169 family of devices. System76 laptops, for example, mostly have rtl8169 ethernet, so they have networking support. Wireless networking support is not present.
Yep, exactly!
Ahh I see. I'll give it another go some day soon, see if I get lucky with my ethernet card. How come networking support is so hard to get right? 
Also, I don't know what you're doing with a vec right now, but it should be fast if you make a \`Vec&lt;u8&gt;\`, and when you find a specific character, swap it with the last and \`pop\` the last element. That should be very fast. Otherwise, you could link your code and I'll have a look.
`crossbeam-epoch` isn't what you want unless you're writing your own concurrent data structure. It's specifically designed for that use case.
Lifetimes and automatic freeing are a great construct and a great way to deal with memory, until you need to deal with certain data structures like arbitrarily nested lists. The borrow checker can't handle that, and so you have to use something like `Rc&lt;T&gt;` to automatically count how many places a certain object can be accessed from, and drop it when it's no longer in use. The problem with that is this. Suppose I have two structs: struct A { b: Rc&lt;B&gt; } struct B { a: Rc&lt;A&gt; } What if I have an instance of each and they refer to each other? They'll never get freed by `Rc` because the reference count will never reach zero. This is when you need a more sophisticated garbage collector. My use case is that I'm building a Lisp interpreter, specifically a new dialect of Lisp that I'm creating. Lisp is totally dynamic, and as such it *needs* GC. (GC was actually invented alongside the first Lisps!)
Probably on times where you don't know when values are going to be dropped. When building an interpreter for another language that is impossible to know ahead of time, so some kind of memory managment has to be built. Or not even that far, librariees with which you can create some custom data structures can't know when certain parts of memory will be dropped, like graph certain graph structures.
You're right - I'm writing an interpreter. 
The alternate way to remove an element from a Vec is what Rust calls [`swap_remove`](https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.swap_remove) which doesn't preserve ordering, but is constant time regardless which element it is since it just takes the last element and uses it to overwrite the removed element with no shifting. `VecDeque` lets you choose between `swap_remove_back` and `swap_remove_front`. If you're removing multiples of the same or similar items, it may be faster to use [`retain`](https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.retain) to remove items in bulk. When I said "allocated entirely on the stack", I was mostly referring to having a singly linked list where each node lives a strictly shorter time than the previous ones like when binding variables in a compiler. Lastly, if you care about speed, compile with `--release`. Rust has a very heavy reliance on compiler optimizations and will run very slowly when unoptimized. The optimizations are mostly to inline the high level functions and combinators into equivalent code as C. If you really need a linked list with a cursor, the most supported one that I can tell is from [`intrusive-collections`](https://crates.io/crates/intrusive-collections). Don't panic about it being a 3rd party library. Rust relies on 3rd party crates for most functionality largely because the standard library is extremely difficult to change after programs start using it. If you end up using this, make absolutely sure to benchmark it. The results are not always what you expect them to be.
Yes. Generics are always compile-time only.
After a long time but a lot new features.
Vec has a `retain` method: `v.retain(|ch| ch != 'a');`
They are called *const* generics because they only admit values computable at compile time. To allow run-time values would amount to full dependent typing and that is not planned as of yet.
This is pretty much what everyone else has said: You won't be able to translate Java to Rust in any kind of direct way, not even at the class level. You'll have to go higher-level, more of a rewrite than a translate. 
&gt; and when you find a specific character, swap it with the last and `pop` the last element. Vec provides that as `swap_remove` and VecDeque has `swap_remove_back` and `swap_remove_front`.
"Objects" have data + behavior intermixed. From this, all depend in the implementation. With something like Java, it have a lot of machinery to support tree hierarchies, encapsulation, etc. Translating to rust, at the basic level is easy. &amp;#x200B; Use structs to declare "fields". Attach methods with *impl*. From this, support inheritance is where is the complication. Nothing automatic for that. But, using the From trait make easy to translate from struct A to similar struct B. &amp;#x200B; You need to invert your way of thinking. Think first how using enums + structs (model the data). This is key. Next, instead of *object.func* think more how could be *func(object)*. Even when you are implementing on top of structs (ie: *object.func* ). I mean, you wanna put in the mind "how the data flow" , not "how a object operate". &amp;#x200B; Where thinks become REALLY complicated is when you wanna be polychromic. Traits in rust look almost like a solution, but have some weirds rules that could make you hit walls.
What's the project's stance on unsafe code?
Nothing. I just stumbled through this error and I didn't understand the error message. 
&gt; The compiler attempts to dispatch to any trait method to_owned &gt; &gt; One trait method matches: ToOwned::to_owned. However the trait isn't implemented for the type. This is an interesting bit. Does that happen at compile time or run-time? 
Python isn't really used for ML. It's used to preprocess and present data. All python ML libs are bindings to C++ libraries.
Someone has to own the hardware and write the drivers for it, essentially.
I'm pretty sure gdb has something similar. I'm pretty sure I've used it several times exactly for this kind of code. I'm pretty sure it was a pain to google up that function, and unfortunately I can't remember any details. But I'm pretty sure it worked decently well. As much as anything can work in command-line gdb.
Just one, I love you!
Do they need the doubly-linked list there though? Seems like single-linked would suffice.
Compile time. Even dynamic dispatch will fail at compile-time and not runtime, not unless it hits `unimplemented!()` or something like that that's *explicitly* a runtime error. 
What's the best way for others to contribute/help?
If I impl MyTrait for fn() { fn my_method(&amp;self) {} } (Yes, `fn`, not `Fn`!), what actually `MyTrait` is implemented for? I can't write fn foo() ... foo.my_method() I could write it if `MyTrait` was implemented for `Fn`.
Maybe there's something I'm missing, but this feels like a potential [XY problem](http://xyproblem.info/). &gt; Unfortunately, this doesn't work. The in closure needs an immutable reference to the other hardware, and the out closure needs a mutable reference to it. So I get a borrow conflict. Can you elaborate on why the API has to be this way? &gt; What I really need is `fn step(&amp;mut self, in_out: PickOne&lt;impl FnOnce(u8) -&gt; u8, impl FnOnce(u8, u8)&gt;)`. This signature guarantees that step calls at most one of the two functions, so the references do not conflict. I get a strong sense that there has to be a better way to do this. Specifically, with `enum` being such a central way to do "this or that but not both" in Rust, I get the impression that, if you can't do it using `enum`, you're probably misunderstanding how the pieces are supposed to fit together and trying to force things. (Though, admittedly, I've never written anything resembling an emulator, so I lack the intuition to suggets a "right way" to do things.)
There's two more recent attempts that are much closer to what you want: [shifgrethor](https://github.com/withoutboats/shifgrethor) is an attempt to solve the API problems of a GC by tracking roots on the stack, and [luster](https://github.com/kyren/luster) bypasses the question of stack roots by suspending and resuming the mutator in a Futures or async/await-like style.
To be honest, this post is pretty confusing -- you switch between a couple different problems / questions. Towards the end of the post, talking about the actual application, it sounds like you want to define two closures, one that holds a mutable reference to some variable `x`, and another that holds an immutable reference to the same `x`. At a type level, both of those closures can't be live at the same time because of the borrowing rules, whether they're abstracted behind some trait or not. One approach would be: change your `in` and `out` closures so that they take a reference to `x` as one of their arguments, so that the borrow only happens after you've decided which closure to call.
looks like it has unsafe code in there. if that's what you're asking
Looks like you're painting yourself into a corner :). If the `out` function requires a mutable reference, then try and work *with* that: Rust doesn't want you to alias a mutable reference, so let's go with the flow and not try and work around that. struct OtherHardware&lt;'a&gt;( &amp;'mut otherStuff ); impl&lt;'a&gt; OtherHardware&lt;'a&gt; { fn in(self, u8) -&gt; u8 { /* your impl here */ } fn out(self, u8, u8) { /* your impl here */ } } Tada, now you can pass a `OtherHardware` instance to your `step` function, and call either `in` or `out` on it. No need for `in` and `out` to exist at the same time.
I've found shifgrethor - it looks interesting, but it's not stable. I'll have to check out luster. 
So does this mean right now you can tweak things at the system call level and then rebuild the whole world and it works out, but because you don't have any stability here, it's constantly a moving target? Honestly, it sounds cool that you already have the architecture such that you have built so much and still have so much flexibility. Very, very cool. Reminds me of the benefits people get from monorepos at large orgs, where API changes can actually happening rapidly, even in breaking ways, because you can update the entire world at once.
Thanks!
maybe start by telling us what safe haskell is
I didn't even know this was possible :O seems to work if you bind the function to a variable. idk ```rust trait MyTrait { fn my_method(&amp;self); } impl MyTrait for fn() { fn my_method(&amp;self) { println!("Hi"); } } fn foo() { } fn main(){ let local: fn() = foo; local.my_method(); } ```
Infrastructure software. For example cloudflare, sentry, firecracker. Performance critical parts of applications / FFI's to other languages. Web Assembly. Rust is probably the best language for WASM atm. Microservice api's for the web, although web ecosystem is still a bit lacking. Empowering other languages, environments like deno.ts Firmware. &amp;#x200B; Rust provides abstractions similar to high level languages, and the compiler doesn't allow to make critical mistakes thus making the language accessible to web developers. Thus allowing to bring C++ like performance for web applications. Although databases remain the bottleneck.
This is actually not quite like an enum. In a sense, it is the opposite. &amp;#x200B; In an enum, the variant is chosen when the enum is constructed. When you use it, you have to handle both cases. enum Either&lt;A,B&gt;{ Left(A), Right(B) } impl Either&lt;A,B&gt; { fn left(a: A) -&gt; Self { Left(a) } fn right(b: B) -&gt; Self { Right(b) } fn destruct&lt;T&gt;(self, f: impl FnOnce(A) -&gt; T, g: impl FnOnce(B) -&gt; T) -&gt; T { match self { Left(a) =&gt; f(a), Right(b) =&gt; f(b), } } } &amp;#x200B; On the other hand, in my `PickOne` type idea, the variant is chosen when the type is used. When you construct it, you have to handle both cases. impl PickOne&lt;A,B&gt; { fn left(self) -&gt; A { ... } fn right(self) -&gt; B { ... } fn construct&lt;T&gt;(x: T, f: impl FnOnce(T) -&gt; A, g: impl FnOnce(T) -&gt; B) -&gt; Self { ... } } &amp;#x200B; &amp;#x200B; As for the XY problem, there may be that there is a better way to do what I am trying to do. But whether there is or not, I still think this type is a useful idea. In fact, I thought of this type long before this project, but this use case motivated me to actually try to implement it. &amp;#x200B; &amp;#x200B; &amp;#x200B; Here is a simplified example of how I am using this: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c66ad901ffb0db61e25917fcc541b181](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c66ad901ffb0db61e25917fcc541b181) &amp;#x200B;
I want to pass two closures into `step`, *only one of which will be used*. Normally, the borrowing rules still forbid this, because they can't tell from outside the function that only one closure will be used. What I am trying to do here is create a type `PickOne&lt;A,B&gt;` that guarantees that only one of A or B will be used. Then I can prove to the borrow checker that only one closure will be used. &amp;#x200B; Here is a simplified example of what I am doing: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c66ad901ffb0db61e25917fcc541b181](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c66ad901ffb0db61e25917fcc541b181) It seems to work.
Yes, this works. But it kind of feels backwards to me to pass the rest of the hardware into the processor.
Rather than reiterating what others have stated, I think it's more useful to list what's I think is long overdue: 1. `std::random` 2. more expansive `std::time` functionality 3. `std::syntax` for rust syntax parsing (possibly versioned) 4. reintroduction of `dlopen`, even if only made available under an os specific module. In general, I'd like to see more functionality that people expect to find in the standard libraries of systems languages.
My long term plan is build something alike Access, but I think is better to just use HTML or a native toolkit.
I'd encourage you to try bacon_rajan_cc. It doesn't have any big users yet but I think it's a reasonable approach to doing in GC in a language where most things don't need to be GCd. Let me know if you run into any issues.
After thinking about it some more, I think I will just do what you suggest. But as I mentioned to another commenter, I had the idea for this `PickOne` type long before I had this use for it. &amp;#x200B; I wonder if there are better use cases for `PickOne&lt;A,B&gt;`.
Neither of them are stable- at this point they're probably more useful as references for how you might approach the problem in your own codebase.
Have you not activated the `--release` flag? If you don't it's running in Debug. Which explains why it's so slow.
It's also not designed to handle cycles which is the exact reason tracing GCs exist.
I think I've settled on that. The others either aren't stable or aren't designed for what I want. Thanks!
So I started to try your suggestion. But `OtherHardware` wasn't in the same module as the `step` function, and I didn't want to import it. (I don't know if cyclic module dependencies work, but I don't like them.) So I modified your solution to this: // In same module as `step` trait InOut { fn in(self, u8) -&gt; u8; fn out(self, u8, u8); } // In module where OtherHardware is defined impl InOut for OtherHardware { ... } &amp;#x200B; But then I looked at that trait and realized: (self, u8) -&gt; u8 (self, u8, u8) are uncurried forms of (self) -&gt; impl Fn(u8) -&gt; u8 (self) -&gt; impl FnMut(u8, u8) which is just the interface of PickOne&lt;impl Fn(u8) -&gt; u8, impl FnMut(u8, u8)&gt; &amp;#x200B; So your solution appears to be mine in disguise?
Command line tools: No runtimes needed/easy deployment, good tooling, easily cross platform, smaller exes than many other languages (but if that is your main goal C can do better).
Recently on twitter, [someone asked fora a practical explainer for `PhantomData`](https://twitter.com/RReverser/status/1106357847695257602) and while I don't have that I did want to share one place I have found `PhantomData` to be useful. This blog post is an overview of how I ended up using `PhantomData` in my builder patterns that require a generic type argument. Hope you all enjoy! As always, feedback is appreciated.
I'm currently using gtk-rs... Right now I can't recommend it. If we're discussing the technical aspects it's okay (except for the last point below), but: - The documentation's very lacking - Examples, which aren't plentiful either, are in C (???) - No multithreading until very recently - I'm not sure how correct this is but it seems you can `clone()` a lot of things and get a struct *that's actually a mutable reference.* And them "being" structs, you don't get the "only one `&amp;mut` allowed" guarantee Rust makes.
Kernels, operating systems, services, applications, games. There's really no limit to what you can, and what people are, using it for.
r/playrust 
I don't see any information about installing redox in your documentation? Is there somewhere that outlines what each of the release options might be for?
As long as you still have both head and tail pointers for the list, that's enough for O(1) append.
Wait, it runs doom now? Are you kidding me?! This is huge!
If people are writing ML in python, people are writing ML in python. Back-end details are kinda pointless since most people would not interact directly with them.
How to activate it
Spent this weekend vastly improving my api generator. You can access webgl apis on web-dom now! Check out the rust demo code here: [https://github.com/web-dom/web-dom/blob/master/examples/webgl/src/lib.rs](https://github.com/web-dom/web-dom/blob/master/examples/webgl/src/lib.rs)
Spent this weekend vastly improving my api generator. You can access webgl apis on web-dom now! Check out the rust demo code here: [https://github.com/web-dom/web-dom/blob/master/examples/webgl/src/lib.rs](https://github.com/web-dom/web-dom/blob/master/examples/webgl/src/lib.rs)
It takes a lot of work to make system call changes, but thankfully the entire set of packages for Redox are all linked from the cookbook. System call changes are only made when it appears impossible or undesirable to continue on with the current set of system calls.
Or Cython...
We use it for realtime interactive AV installations, live performance and generative art, mostly through [nannou](https://github.com/nannou-org/nannou). Our installations/performances run from anywhere from half an hour to 15 years so the reliability that rust provides is very important to us. The ability to interface with strange C APIs (like SLR SDKs, depth sensors, strange lighting protocols) easily is also important. The performance is essential as we're often working with realtime audio/video/laser/DMX/etc streams. You can see some of our work [here](https://www.mindbuffer.net/) if you're interested. 
I haven't watched the video yet but I have a feeling you are looking for /r/playrust
The contributing docs have a couple comments about unsafe: https://doc.redox-os.org/book/introduction/unsafes.html#unsafes &gt; We seek to eliminate the unsafes where we can, and when we use unsafes, we are extremely careful. https://doc.redox-os.org/book/contributing/best_practices/rusting_properly.html#rusting-properly &gt; When unsafe is unnecessary, don't use it.
When can we expect Redox to overtake Linux?
Some options listed in https://doc.redox-os.org/book/contributing/direct_contributions/low_hanging_fruit.html 
Yes, exactly.
I agree. In fact, I'd argue that restricting build scripts is more possible now that most operating systems provide some sort of sandboxing. Restricted build scripts should be the default. Crate users should be able to manually grant additional privileges to crates that request them via Cargo.toml.
Also, no startup delay. CLI tools in node or java or python can get annoying really quick if they use large libraries.
hi! is there a blog where we can follow your development or ideas? I would like to know how you start off with something like this and how then you build or add things on top of the initial code.
2019 will truly be the year of desktop Redox!
Another good example is Dropbox rewriting parts of their storage backend from Go to Rust and seeing dramatic memory savings and much better tail latencies. I love this example because it shows that Rust even has something to offer when your software is already in a modern, high-performance language.
I'm actually glad `std::random` doesn't exist. The rand crate is just 1 line away in `Cargo.toml` and is too fully featured to be in the standard library, but absolutely amazing for applications where you want random numbers.
Rust is catching up in backends since 2018. With Futures coming up, I'm seeing it as a pretty direct replacement for a lot of JavaScript work, especially with wasm giving you most of the advantages of isomorphic javascript. A lot of the progress I'm tracking off github, and the kind of questions I see on the discord, show more people happy to use it for their web apps. I'm really enjoying it for the strong typing and thread safety -- I'd say about 80% of the issues I hit with the apps I write that are mainly RESTful/graphql services are things rustc catches at compile time. I'm also seeing that old philosophy of "cycles are cheap - just write your code and come back to fix bottlenecks later" look exponentially more ridiculous every year. Especially with distributed applications, I don't want to waste memory + CPU on abstractions that have started to hurt me more than help me. One of the big moving targets we've been hoping rust lets us hit is for ML. We're not expecting anything in the immediate future, but being able to run some of our clustering in NLP on the client-side via wasm would be fantastic. 
Not about the release specifically, but is TFS development continuing after Ticki has left? It looks really interesting and I'd like to contribute, but it looks like it's dead (e.g. issues with no replies, stale PRs).
As std error now have the \`cause\` api, \`Failure\` could be easily replaced by using std error types. This is a topic discussed many times before. It's better especially when you are developing a library ( by removing a dependency ). &amp;#x200B; However, if you are developing an binary, \`failure\` could be easier
Well, it's not like there aren't a bunch of old unixy programs that work just like this. Think of fdisk, bc, ed and so on. Note how they still compose well and can be used in a pipeline. There's no inherent need to run them interactively, you just might need to insert a bunch of newlines in there.
The issue here is a difference between fn items and fn pointers (which I don't fully understand the reasoning behind). `fn()` is a fn pointer but `fn() {foo}` (which you see in the error message for your code) is a fn item. Items get coerced into pointers, at least sometimes, but I think not when they're behind a type, like `&amp;fn()` or `Option&lt;fn()&gt;`. To get around this, you have to cast it into a plain `fn()`. The easiest way is probably this. (foo as fn()).my_method() &amp;#x200B;
Because your `no_std` doesn't say anything about whether your dependencies used `std`. If you want to make sure you've tested without *any* `std`, try building where there is none, like for one of the thumb targets
There may be really valid reasons to use a ndarray for this, but I have to ask whether using an in-memory sqlite Db wouldn't be easier? I've built apps that way, and it's pretty painless, and performance is great.
I might be crazy, but in the text you say "why can't rustc infer that T is an f32", but in the example above, it looks like you're asking the compile to infer a f64 as provided to \`build\`: &amp;#x200B; fn main() { let \_thing = Thing::builder().option\_one(199).build(4.5f64); } &amp;#x200B; Is that a typo, or am I just confused? &amp;#x200B;
That’s a typo, thanks for pointing it out! 
Super! Thanks again for the post, well done!
I also set about doing the 2018 AoC as a means of learning rust, and ended up in the exact same conundrum. After some head scratching, I found that it was actually way faster to use a Vec, iterating through it and copying (or omitting) elements based on whether they looked correct or not. If you want to see my solution, it's here: [https://github.com/skrap/aoc\_rust\_2018/blob/master/src/bin/5b.rs](https://github.com/skrap/aoc_rust_2018/blob/master/src/bin/5b.rs) Happy to answer any questions!
I'm planning to use [pest](https://pest.rs/) when I get around to experimentally discover the syntax for a bunch of old records that I habitually wrote in a "should eventually be machine-parsed" syntax of my own design.
/r/playrust
How long did it take to write? 
Even so, I'm content to make it clear that "you are almost certainly doing something unsafe if you are using it". The reality is that the definition of `unsafe` *is* unclear, since it's mostly about memory safety but also includes UTF-8 correctness, etc.
I'm building a language, and need support for in-memory transforms. &amp;#x200B; Also will support integration to sqlite but is tangential to this.
Rust is being used for security critical applications using Intel SGX. It is really important to do high performance cryptography and avoid buffer overflows especially in these settings, so Rust is a natural choice.
Anyone having trouble with installing programs? Internet works fine (tested netsurf). Im getting "error during dependency calculations: IO error: Connection timed out (os error 110)" Just trying to get doom running :) &amp;#x200B;
The definition of unsafe is still unclear though, because it's explictly unsafe to rely on destructors, which are essential for ensuring safety in a lot of cases.
Python and Rust are interesting for InfoSec for very different reasons. As you mention, Python is great for exploits and other things you might need to whip up quickly during something like a CTF. I'd say it is great for the "offense" part of InfoSec. Rust is the opposite. It's quite an annoying tool if you want to write a script and get it working as quickly as possible. But for "defense", it's great. Rust is the sort of language that I would like the web browsers, database engines, web servers, operating systems etc. of the future to be written in.
In this line of thinking, would `ManuallyDrop` also be unsafe to construct?
Consumes 100% of 1 core and gives about 2 fps. Completely unresponsive. File manager takes about a minute to open the directory.
Does it uses 'libc' anywhere under the hood?
That's nowhere near extremely complex json object. Any jigh3lever programming language will parse it super fast. Who expect to get your data
Well I'm talking ns speed, not an 'acceptable' speed
If you need to serve that data, you should paginate it on server side. And expose what client ask for
HoloFuel is a cryptocurrency but it's not a token. It's a crypto credit. 
Duh we're doing it on the server side
How is server accessing that data? It should be cataloged in database to allow blob search. 
It's not like we just started -&gt; we've been doing it for a while with code written in Haskell and C++, but we're slowly making the switch to Rust and hence this question
Your question is so basic, you must not understand what you're doing, how you get it, or how to serve it.. sorry.
As /u/JayDepp wrote, you need to clarify the type for this to work. Binding to a variable will also do this.
Wonderful thank you! Now I have a debugger set up!
I was asking for a god damn crate recommendation, I'm maybe better of writing a serializer and deserializer myself
Plz chat me. Maybe my background can help
I've never needed to work with that much JSON but, judging by [this benchmark](https://github.com/serde-rs/json-benchmark), you want [Serde](https://github.com/serde-rs/json). (And, again judging by the benchmark, probably the struct (`#[derive(Serialize, Deserialize)]`) API rather than the untyped/DOM (`serde_json::from_str`) API but not necessarily.)
How u index. Serve? Serve through? Chat me.
I've already know that project, but i didn't notice they also targets on clients. Thank you for letting me to know. But a little excuse, it seems to me that it does not fit well with what I needed; the example in the readme shows exactly what it is. I think that tower is mainly focused to build a service, and most of features are depending on their [`Service` trait][1], even on the client side like tower-retry. It's too much for my goal. I want to focus on the side which will send a request, and to work with existing libraries like rusoto, not to make a new one.
Thanks for pointing that out. Those don’t have ‘Rust’ in their names, so they didn’t show up in my search, heh.
Oh, excellent!
Now you're my man, why didn't you exist in the last hour? Everyone's telling me how to parse JSON, when I'm asking for a crate recommendation! And you're the 'ultra-man' who understood it straight out of the box! Thanks! And yeah, I was planning for going with either Serde or json-rust and yeah, I'll use Serde, because that's also recommended by the Rust team! Thanks again for understanding! 
You never provided ANY adequately sufficient information about your data. And after i asked for more informations over chat, you never responded. Thanks for all shitty down votes asshole.
Your initial reply violated the sub's "Respect our Code of Conduct." and "Constructive comments only." rules. &gt; Your question is so basic, you must not understand what you're doing, how you get it, or how to serve it.. sorry. That looks pretty clearly like you're just insulting the OP without asking for more information. &gt; Plz chat me. Maybe my background can help "Plz chat me" doesn't help anyone who might come here off Google with the same problem in the future. (Same problem as with StackOverflow answers which just dump links without excerpting/paraphrasing the relevant bit.) &gt; Thanks for all shitty down votes asshole. Cursing might be enough to earn a downvote or two. Actively insulting people definitely will.
Sorry for trying to help, then being ignored and down voted any technical issue typical user might have.
No problem. I hope you won't take this as a typical /r/rust/ experience. As far as I can see "everyone" is one guy who is very much *not* the typical /r/rust/ member.
And there the posts vanish! We should've tagged a moderator
The most important thing in any subreddit is to obey the rules. How would you like it if some random person ran into your favourite restaurant house and started making a mess?
Trying to make network packet sniffing and manipulation tool. Also trying to make a small script to scrape basic html pages. Only if rust had more devs, I could've found libraries, but no.. I guess I may have to code it. I'm new to rust. Any help is appreciated!
I know right! I fell in love with Rust, right when I met it! I started putting patches to the compiler and all were approved and merged, such a welcoming community! And when I come to /r/rust there's this random dude who's just throwing random comments, and not willing to understand what my question is.
Redox has it's own libc called relibc. It's written in Rust.
Whichever i didn't follow? I literally have question as a dev to dev. You ppl fail. I asked multiple times for details, only to be down voted. You 2 are a scam.
Did you try pikkr? In-place, avx2 [https://github.com/pikkr/pikkr](https://github.com/pikkr/pikkr)
Looks interesting. For now I'll stick with Serde, but I'll definitely keep pikkr in mind (starred on GitHub). Thanks for the recommendation
I already told you [here](https://www.reddit.com/r/rust/comments/b56h7d/guide_needed_how_to_parse_extremely_complex_jsons/ejblcqh/).
What is Redux OS ?
Thanks for that. I thought I remembered another, faster parser but I couldn't remember its name or find it in a cursory search.
/u/kbnapp
Wait what? You mean to say I switched to a language that doesn't have backward compatibility with packages?!! Don't tell me I've to go back to C
You are lying. Not nearly showed entire collection of events. Didn't even preserve ALL evidence in proper time that they happen. You are a fraud.
Exploring the quicksilver library for games. Seems pretty intuitive and has nice tutorials generated from its documentation. I also love the one command wasm compilation! Will try to make a small game with it. Also trying to setup a vim env for rust but rls is acting up so I might look at other options.
UTF-8 correctness is implied by memory safety, since many `&amp;str` methods will read out-of-bounds when given invalid input.
Writing a cuda library that allows you to include cuda code. Same fashion as vulkano-shaders generates bindings for glsl
Where did you get that from? Rust has very strong backwards compatibility guarantees. Nothing in this post is about a break in backwards compatibility. 
Yeah, it's a bit weird, but you can think of `Service` as a function from a request to a response. Once people use that trait, you can implement various "middlewares" once, and reuse them everywhere, even on the client side. The naming issue was discussed [here](https://github.com/hyperium/hyper/issues/1782).
I agree this does seem worrying. Although @kbknapp posted a \[blog post\]([https://kbknapp.dev/clap-v3-update-structopt/](https://kbknapp.dev/clap-v3-update-structopt/)) earlier this month describing the current project status. Short summary is that he's busy with life stuff and wants to ensure that any future changes made to clap are quality. Sounds good to me.
Thanks for sharing, haven't seen that.
It would be quite interesting to hear from you what was your journey like from being having no formal training to work for apple. 
Thanks for this. This is very helpful. One question: is there a reason why `build` takes a reference to `self` instead of consuming itself? I would think after calling build you no longer need/should have access to the builder, and it allows you to move the `String` into the final struct, instead of having to make a copy, right?
Maybe your VM settings are a bit off, because it runs just amazing on my machine.
You may already know that, but you can use `core` in non-`no_std` crates.
Essentially I went to school to be an animator. I ended up teaching myself python to ease some repetitive tasks. This combination of skills (animation plus coding) got me an entry level position as an animation support TD(technical director...meaningless title but sounds cool). Studio I was at won the Oscar for life of Pi, but then went bankrupt but I saw the writing on the wall and got a gig at another studio working as an entry level pipeline developer on Cloudy with a Chance of Meatballs 2 (sequel to my favorite animated movie). From there I worked my way up the ranks and was a pipeline and layout supervisor (so tools, workflow but also set design and camera work) for spiderman homecoming. (Also contributed to spiderverse). This involved a lot of Python, c++, Lua etc... All self taught again. Then Apple needed people who understood both the artistic and technical side of things so I made the jump over. Can't say what I do here for obvious reasons though. If you're interested, I have some blog posts on the kind of development work I did before Apple. http://dgovil.com/blog/2016/11/30/python-for-feature-film/ It's mostly python but I've broken it down by film as well. Though missing my most recent ones.
This is also described at [https://www.mercurial-scm.org/wiki/OxidationPlan](https://www.mercurial-scm.org/wiki/OxidationPlan) **:** &gt;It takes several dozen milliseconds to start a Python interpreter and load the Mercurial Python modules. If you have many extensions loaded, it could take well over 100ms just to effectively get to a Mercurial command's main function. Reports of over 250ms are known. While the command itself may complete in mere milliseconds, Python overhead has already made hg seem non-instantaneous to end-users. &amp;#x200B;
You can still use the package with Rust 2015 and probably with Rust 2018. You just have to still use macro_use 
Worth listening to/reading the interview "[The Changelog: Building a secure Operating System (Redox OS) with Rust](https://changelog.com/podcast/280)", and there are some great posts on https://www.redox-os.org/news/
Last time I tried this, I could single-step just fine, but variable introspection didn’t work at all.
Worth listening to/reading the interview "[The Changelog: Building a secure Operating System (Redox OS) with Rust](https://changelog.com/podcast/280)"
Could you give an example where this would be useful? I’m having trouble conceptualizing it.
If all your errors implement the `Error` trait it should work if you take a trait object as the parameter. let unwrap_or_error = |err: &amp;dyn Error| { /* ... */ } If you don't capture any variables from the environment, perhaps it's better to define a function instead of a closure? fn unwrap_or_error(err: &amp;dyn Error) { /* ... */ } What I think would be even nicer is to propagate all errors using the `?` operator and then handle them at the top level e.g in `main`. 
thx
What exactly do you mean by "mutate the rows/columns"? ndarray provides, among others, the ` column_mut`, `row_mut`, `slice_mut`, and a few more methods to manipulate the elements of various views in place.
I'm using it for computationally expensive operations in my web app through Web Assembly. Enabling release mode in the compiler makes the result blazingly fast.
I recently published another crate, [compact_arena](https://crates.io/crates/compact_arena) that provides typed, compactly indexed arenas with branded indices. Next up is making it no_std-compatible.
You can't have generic closures, but as long as you don't need to actually close over variables, you can use a generic inner function (for that matter, you can move that function to the top level; I've found myself writing something similar repeatedly anyway).
There's https://doc.redox-os.org/book/getting_started/try_vm.html and the section after that.
I found out that [hedgewars](http://hedgewars.org/) (FOSS Worm-ish clone) have been experimenting a bit with rewriting the game in rust and decided to [contribute](https://hg.hedgewars.org/hedgewars/rev/29dbe9ce8b7d) some basic map rendering over the weekend ([a very zoomed-out 32x16k cheese map rendering smoothly!](http://i.imgur.com/GdK1mXR.png)) If you're interested they hang out in #hedgewars on freenode!
When designing an API, should `Copy` types generally be passed by reference, or moved in function calls? I've seen both used in libraries, so far. Is there any performance difference? Should passing references always be preferred for clarity? For example, which implementation of `Add` would be preferred below? #[derive(Copy, Clone, Debug)] struct Foo { value: f32 } impl std::ops::Add for Foo { type Output = Foo; fn add(self, rhs: Foo) -&gt; Foo { Foo { value: self.value + rhs.value } } } impl std::ops::Add for &amp;Foo { type Output = Foo; fn add(self, rhs: &amp;Foo) -&gt; Foo { Foo { value: self.value + rhs.value } } } The first `impl` allows for e.g. let a = Foo { value: 1.0 }; a + a; which is arguably more convenient to use than taking a reference with e.g.: let a = Foo { value: 1.0 }; &amp;a + &amp;a; So mostly checking whether there are any performance or best practices to bear in mind here. While implementing both of the options above is possible, I'm not sure if it would be useful in general (i.e. it would give users two ways of adding `Foo`, and also double the number of `impl` to maintain). 
Finished my DMG renderer and I'm gonna move the whole project to be 100% `sdl2-sys` based.
I'm creating a simple SMTP server in rust, to learn both how SMTP works and to get a better understanding of rust.
What are the next steps to self hosting? Really excited for this! The difficulty of building it makes it somewhat difficult to get software onto.
I’m working on a rest api to add like button on my static blogs using Arctic, diesel and Sqlite, will publish this as post on my blog [here](https://gill.net.in) once done 😃
I was searching something like this! It's wonderful, thank you
I've rewritten Sonr from scratch. It's now less simple but more performant. (https://github.com/hagsteel/sonr)[https://github.com/hagsteel/sonr] I started Sonr as I wanted something less complicated than Tokio and still non-blocking. There is still much to do and the documentation is pretty sparse (bordering on useless) as the core principle isn't described yet, but there is an example, as well as some WIP projects around it. I'm also working on (https://github.com/hagsteel/remonitor)[https://github.com/hagsteel/remonitor], a server for broadcasting messages to connected clients. It seemed like a good first project to build with Sonr, and allow me to monitor all the servers on my network by writing various "monitors" for them them (again very much WIP).
&gt; T is a type parameter, nothing more than a placeholder for a concrete type, like i32 **o** f64 typo &gt; It suffices to say, for now, that **moving ownership of a value of a type that implements Copy has exactly the same computational cost of copying its value over using clone** - hence Rust avoids us the trouble of sprinkling clone calls around and copies the value implicitly when required. The phrase is unclear to me, the *over using clone* part.
There’s a project called Redox, is an OS written in rust, don’t expect too much from it because is in very early stages, but sounds cool to have an OS written in a safe memory language, let’s see how many memory bugs are found in the future. The only area that is IMHO mature enough to be used in real projects is services and web, in the other areas the ecosystem is too young so you don’t have pure rust tools mature enough to build something usable in a reasonable time, but it’s growing. For gaming there are some studios that are starting picking it to use, I read about Seed iirc (some EA company, had some tools written in rust), also ex Seed employees had a company called Embark studio, and they are looking for rust game devs and also Chucklefish have some work in progress game with rust iirc. Note: some company names may be misspelled, correct me if there’s some error, thanks.
[nom](https://github.com/Geal/nom)'s error management is not great right now, unless you're willing to spend some time interpreting error traces. But I was just this weekend working on a [new error management design](https://github.com/Geal/nom/issues/887) for nom 5, that will make things much simpler and provide good error messages :) And [nom 5 gets a complete rewrite](https://github.com/Geal/nom/issues/878) to use functions instead of macros for its combinators, but still keeping macros backwards compatible if needed. So it might not be what you need right now, but once nom 5 is out, I encourage you to check it out :)
I made an internals post talking about some of the high-level roadmap things we need to figure out: [https://internals.rust-lang.org/t/kickstarting-a-database-wg/9696](https://internals.rust-lang.org/t/kickstarting-a-database-wg/9696)
For `Box&lt;FnOnce()&gt;` issues, use `#![feature(unsized_locals)]` to make it callable.
Doesn't look like valid function to me. Trait cannot be used as type parameter.
Superb work!
Hey there! Yea, Kevin is taking a hiatus from the project and has left maintenance with the CLI-WG. Unfortunately we've not given the project as much time as it would deserve. Especially the clap \`3.0\` stuff we wanted to have done by the end of \_last\_ year didn't get done. &amp;#x200B; At the all-hands in February we laid out a plan on how to proceed. There's things we want to do with clap, but of course we also have to maintain the current version people are using. If you're interested in helping out with maintenance or the future of the library, I can only recommend you come by our next CLI-WG meeting to get invovled. &amp;#x200B; Until then...should probably go through some of the PRs 😬
What are the plans in the future for hardware acceleration? I'd assume it's a long ways away but how do you plan on implementing it? Would you port DRM drivers from Linux or try and do your own approach?
The thought of using redox for minimal cloud vm or even immutable vm images is with me for a year now. It could actualy works as it used tu run in qemu, real hardware support is less important. Never had the chance to investigate. What are your thoughts?
Yeah, I should make a blog post for this, but I did collect this knowledge in a [twitter thread](https://twitter.com/bitshiftmask/status/1082997711861891072), or OP can look at [this PR](https://github.com/shekohex/curve25519-rs/pull/4/files) to see what is needed to test this.
I do this for crates using Alfred on Mac, but I hadn't thought to do it for docs etc. This is a great tip, thank you! https://www.alfredapp.com/
Especially since `std::mem::forget` is implemented with this one line - `ManuallyDrop::new(value)` .
[Safe Haskell](https://downloads.haskell.org/~ghc/7.8.4/docs/html/users_guide/safe-haskell.html) is an extension to GHC that ensures that your dependencies can't do unsafe things unless explicitly allowed to.
You might want to look at [https://docs.rs/intrusive-collections/0.7.8/intrusive\_collections/](https://docs.rs/intrusive-collections/0.7.8/intrusive_collections/) .
Hello, ensembl's (current!) main rust dev here. &amp;#x200B; Thanks for your support. I'd like to add that I'm a complete Rust noob, kinda backed into choosing it, a language which I didn't know, after we decided WASM was the best way to get client-side speed, and to avoid browser GC doom, and it seemed like the best option (it also had a sane type system, which helps!). I do actually like rust though, now that I'm learning it. &amp;#x200B; We have a very tight schedule, so there's lots of anti-patterns and the like in the code at the moment (eg cloning like billio at the slightest excuse), that I'm now rapidly going back to correct in the codebase, and generally structure the code correctly, now that I have a few more miles on the Rust clock. There's also almost no docs at the moment. The group are being very helpful in giving me time to pay off that technical debt right now. My partial background as a C programmer is helping lots as the language seems to capture all the pointer-handling good-practice that you learn over the years, with a great dollop of "well, technically, you could represent the data like that, but you really don't want to" experience being very useful. (Having done some stuff in the ML/Haskell world helps, too). &amp;#x200B; At some point I'd be happy to answer questions on this and follow threads but, I hope you understand, there's a load to do here over the next couple of months to get this project sane. Thanks again!
 `struct_opt` is a pretty good option that uses clap internally that is much easier to read and use. 
Why do you need a GC? Are you writing a new language? What are you building? (ELI5 if you can)
If the type implements `Copy` then taking it by-value is fine. For user convenience you may actually want to include more impls like the following: // value + reference impl Add&lt;&amp;'_ Foo&gt; for Foo {} // reference + value impl Add&lt;Foo&gt; for &amp;'_ Foo // &amp;mut foo (autoref) += value impl AddAssign for Foo {} // &amp;mut foo += reference impl AddAssign&lt;&amp;'_ Foo&gt; for Foo {} // use `Iterator::sum()` for value type impl std::iter::Sum for Foo {} // use `Iterator::sum()` for references impl std::iter::Sum for &amp;'_ Foo {} These come in handy in generic contexts like `Option` or iterator chains where you would need to stick in `.cloned()` to make it compile with just the by-value impl. As for performance concerns, keep in mind that if the type fits in a register or two (if it's a couple `u64`s or smaller), LLVM will usually just not bother using pointers anyway.
What corrections are you hoping to make? Is the program not behaving like you expect it to?
Have you considered using String(not the same as &amp;str) instead of Vec&lt;char&gt;?
Documenting libalpm while porting it to rust as an exercise to learn how package managers work.
I wasn't aware of the ongoing work to move nom away from macros, but now I'm looking forward to it. Thanks for your work!
Is anyone else having problems with fonts if you go this way. If I use `rustup doc` and click the link to the API reference then all the fonts are correct, but if I go directly to the API reference search then I get a bunch of CORS errors for trying to request fonts from `file:///`. In this same tab, if I manually browse to the doc index, then follow the link to the API reference the fonts work correctly again... I have a feeling the index has some CSS/font stuff that the API reference doesn't have but a quick glance doesn't show anything obvious.
Wov, kudos to the developer. Going to try redox under VM. Hoping to run on top of baremetal soon...
Thanks for sharing. I really appreciate how this blog post is structured, iterating on the example scenario one small step at a time.
This code is basically in line with expectations. just now i fix a bug, reader.back() from \n. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8e618cd5388915efa6e625ac4f770f6e My problem is that the way I use rust-related methods is incorrect. Like borrow_mut, borrow, text.chars().collect(). Is there a better way to code this?
This looks really really awesome! While I haven't evaluated Transactional Memory libraries in rust at all, the one I had seen so far looked more like experiments and not as mature and performance-oriented as this one. This could lead to really really awesome concurrent applications.
I believe its about 2 years old now. Granted most of this was done by a handful of people in their spear time.
On the /r/redox the author answered a question saying cargo wasn't fully working and rustc is not a package yet. Though last year they did have rustc in a very primitive state. So I would Imagine getting those two things to work would be the next step.
If it's just to tinker then I say absolutely give it a try. You'll probably have to port your software over though. Though I would say a hard no for anything to serious tell it stabilizes a bit more.
Everything can run Doom
For mod related, I know this project: https://github.com/cmatsuoka/oxdz seems dead, but can be useful. About mixer in rust, sorry I don't know any. I would recommend writing your own, preferably pure rust, but if you'd want something faster, creating a sys create from a C lib, there are some alternatives out there, not sure if the mixing quality matches what you expect, but these are used for/on modular music, like sdl mixer and SoLoud (I have a modified version, to be a single header only on my repo https://github.com/fungos/ass may be easier to use in a crate).
Actually, first library, not first crate, I wrote and published some CLI utilities before. Of course I would proofread everything except for post title (which is the only thing I cannot edit now)
The problem with `std::random` is there's a lot of use cases for random numbers and the right tool is different for each of them. (A simple LCG is [enough for Pokémon](https://bulbapedia.bulbagarden.net/wiki/Pseudorandom_number_generation_in_Pok%C3%A9mon), but criminally negligent for crypto.) Having it in the stdlib would suggest that it's a reasonable choice for *any* application; the cognitive distance of needing to add a crate also clues you in that you need to consider what you're doing.
This is not helpful. 
Starting to design a Kafka cluster manager tool. Initially I just want to be able to start a Kafka service (in cluster mode) with some configuration setup initially.
Continued work on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). I've been reviewing some PRs for new quantities as well as working in my experimental branch on proc macros.
Using w0rp/ale I recently switched to rust-analyzer and it has been working much better than rls does. https://github.com/iliekturtles/dotfiles/commit/7ab6cb4c2983ca9692f25bc2fa6876a7649c4c84
while we're semi offtopic: I also like gumdrop, same concept of struct_opt but less dependencies (doesn't use clap at all)
I have a trait `ScalarLength` that I have implemented for all `T` where `T: IntoIterator&lt;Item = I&gt;` and `I : ScalarLength`. However, When I try to implement the same trait for `(T1, T2)` where `T2: ScalarLength`, I get a conflicting implementation error. [Playground](https://play.rust-lang.org/) What is going on? As far as I can tell, tuples don't implement any Iterator traits.
I see that the macro rules for 'actor!' resemble Python syntax and i am not convinced if that is the best approach. Usage of lambda functions is popular among Rust programmers and library creators and i believe that going from ident-significant rules into brace-significant would make it fit better with the rest of the language? Overall - very nice library.
The worst part is that most of the types you actually type with in lens are actually synonyms for simple cases of larger types. So out of nowhere your compilation errors start spitting out new types that the tutorials never went over!
What is the Clap 3.0 work?
Originally this included making `clap` less stringly typed and integrating structopt as well. There were a whole bunch of other changes. There's a big tracking issue for it. We did however now have some plans to add structural changes as well, which would allow `clap` to have a smaller binary size footprint 
The problem is that, even if the trait implementation that makes it conflicting may not make sense semantically, it's still possible that it could be added in the future, which would be a breaking change from your perspective. This is called the orphan rule and is in place to prevent this from occurring. The idiomatic workaround is to create a new wrapper type like a tuple struct, which is a type definition that you control and can add impls for 'till your heart's content.
Indentation is optional (as `TokenStream::to_string()` strips newlines, resulting in input being one line (but not always, its quirks are just amazing)), I indent for readability. There are restricted keywords instead (listed in documentation as attributes), e.g. `input:`, and everything until the next keyword is seen as content. I actually wish I could use indent-significant rules, it would allow users to e.g. have variable called `input` in `data` section (right now in `pub input: String` `input:` would be interpreted as keyword).
I kind of understand the orphan rule and have been making newtype structs/tuple structs all this time to workaround it. But in this case, not sure how the orphan rule applies. Is this just a case of a possible future where Iterator traits are implemented for tuples?
&gt; Is this just a case of a possible future where Iterator traits are implemented for tuples? Pretty much, yeah. It may not actually be the orphan rule (I can't keep all the language terminology straight) but it falls under the same umbrella of coherence. The point is that this error prevents adding trait implementations from being a breaking change, which would be a big hangup for API evolution. You might get away with this under specialization if you marked the more generalized blanket impl with `default` but it may still complain. Also, specialization needs nightly and tends to cause compiler panics so you may not want to deal with that. 
Both the `RefCell` and `text.chars().collect()` usages can be eliminated with a few minor API changes. The question is whether you can afford those API changes, or you want `TextReader`'s interface to remain exactly the same. I'll go ahead with the assumption that these changes are fine, and see what can be done. The `RefCell`s can be removed entirely if we change some methods to take `&amp;mut self` instead of `&amp;self`. The compiler will start yelling at us about overlapping borrows, but that can be fixed by returning `Option&lt;char&gt;` in `next()` and `peek()` instead of `Option&lt;&amp;char&gt;`. Since `char` can be trivially copied, I Don't see why it would be necessary to return `&amp;char`. Regarding `text.chars().collect()`, it doesn't seem necessary at all for `TextReader` to own a copy of the characters of the text. Instead, we can directly reference the `&amp;str`, call `.chars()` on it when we need a `char`, and slice it when we need a subslice. Here is the code with the changes applied: &lt;https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1309d23d465794ff68fa0070bf22e24f&gt; Note that these changes only address the two pain points you mentioned. This is most likely still not the optimal way to define a `TextReader`. Rust strings are unicode strings encoded in `UTF-8`, which is much more complicated to work with than a simple slice of bytes, as in the case of ASCII. If you only care about ASCII, you could work on bytes (`[u8]`) directly, and things would be much simpler. 
Not exactly Rust, but here's a notable pick from the latest research: https://github.com/lemire/simdjson
Thanks for the explanation. 
Thanks, I'll try it out!
Thanks! I couldn't find that when I was searching. I did eventually manage to get it working without that, though.
docs.rs doesnt even need a bang, lol. It is so easy to just type docs.rs/serde or similar
Yes, if you access any generated docs with file://the root is calculated incorrectly. You can get around that by running a small http server (like `python3 -m http.server`) in the docs directory.
 I was getting tired of converting my defaults to strings and parsing them back again, good to hear that's being worked on. :)
Glad you like it!
In addition to your `join_handle` field, you could have a field called `stop_flag` or something of type `Arc&lt;AtomicBool&gt;`. Create it in `new` and pass a copy to the thread you spin up, and set the `stop_flag` to true when it is time to join. Your read calls would have to be `TcpStream::connect_timeout` in a loop and check your `AtomicBool` to know if you should stop or not.
How much did you know about OS development when starting Redox and how much did you have to learn along the way?
Ah, no worries. The crate exists as a minimal OS interface, and yes, some people would like it merged into the std lib (though I can't say whether that will or won't happen).
You could use gstreamer, takes a little while to learn, but it's pretty powerful. https://crates.io/crates/gstreamer
I personally find `Option`'s implementation of `IntoIterator` completely out of left field compared to the rest of stdlib. 
Not true, this is too harsh of a statement. Just a few examples off top of my head: https://github.com/hyperopt/hyperopt https://github.com/ogrisel/pygbm (I’m well aware that most big popular Python ML libraries are bindings to C/C++ backends, but still...) 
We use it for medical imaging, mostly 3D and 4D images of human brains. Rust, rayon and ndarray make it a pleasure to work. It started as a test to see if we could avoid C++ and it's now our standard tool.
Re: client-side ML, check out https://github.com/snipsco/tract - a WIP ONNX backend for Rust. (disclaimer: I’m one of the contributors, currently working on the forest ensembles; the core devs did an amazing amount of work already on neural nets)
Awesome. Thank you c:
To add to DroidLogician's answer, you can get around it by doing your first blanket impl on `(T)` instead of `T`, the compiler knows `(T)` and `(T1, T2)` do not overlap and your blanket impls won't conflict.
I [started an RFC](https://github.com/rust-lang/rfcs/pull/2484) to find replacements for `as` last summer, but it stalled, and I have little desire to put further effort into this.
I wanted to get to know reqwest better and in the future use serde to manage json objects. &amp;#x200B; So far I've built a cmd line program that pulls the daily message from [dailytao.org](https://dailytao.org) and outputs it with formatting to the console.
Python is definitely used by ML users, if not by ML library implementers.
C applications use `relibc`, but Rust applications interface directly with the kernel
A major issue with `impl Trait` is that it's currently not possible to capture the return value of an `fn(..) -&gt; impl Trait` function into a struct, except as a generic field. [RFC 2515](https://github.com/rust-lang/rfcs/pull/2515) is about addressing this.
It makes `wrap` inflexible. Essentially you'd need two functions to do the same job: ``` fn wrap&lt;T&gt;(value: T) -&gt; impl Trait; fn wrap_clonable&lt;T: Clone&gt;(value: T) -&gt; impl Trait + Clone; ```
Yes, you'd have to wrap it in a `Mutex`, and possibly with and `Arc`. This ensures that the value will be safe to share between threads (sync) and safe to send between threads (sync).
I agree it's weird but I find it one of those secretly brilliant bits; you can do `some_vec.extend(some_option)` and it just Does The Right Thing.
To add on to this, you can also avoid the dynamic dispatch in `unwrap_or_error` by making it generic. ```rust fn unwrap_or_error&lt;E: Error&gt;(err: E) { panic!(err); } ```
This is correct. That is exactly the package I have been trying to use. I cannot figure out how to pass arguments to the rust() package::function as variables, i.e. 5 passes, but when x = 5; then x does not pass. I was also wondering how the data types in R are interpreted in Rust, for instance R matrices and lists. Thanks for your comment.
Huh, now that I compare the two they are slightly different, but not in a way that I would notice without putting them in two side-by-side tabs and clicking back and forth. Possibly because I think I have a form of Fira Sans already installed.
Well, yeah. It's an operating system, which has to do unsafe stuff to work with the hardware...
Anyone have tips for debugging hashmaps?
Ok, so don't understand this as being defensive of Rust, rather, being defensive of moderate levels of rigor in writing. This article has such glaring methodological problems it isn't even up to the standard level of rigor _for a blog_. I get that blogs aren't supposed to be science. That's fine. But this is up there with a blog post claiming that nobody on earth knows what color the sky is. Development _always_ follows a long tail model. It doesn't matter what we're talking about the development of. It's always a long tail. The speed of change is always proportional to the distance that remains to go. C changes very little. This much is true... but C is over 40 years old. Rust is 3 years old. Golang is 9. Based on these facts alone you should expect _much_ faster changes in Rust. The only real question is why is C++ changing as quickly as it is given its age... Personally, I think it's because C++ still has a long way to go... but that's another matter.
I'm working on my email and SMTP parsing library called [rustyknife]. I published the code publicly last week and I'm working towards having a sane and complete API. [rustyknife]: https://zerospam.github.io/rustyknife/rustyknife/index.html
Oh, i see. Thanks for the explanation, seems more logical ;)
Being able to have more control over the tab completion that is generated by clap would be great.
He's a great guy, but I've talked with him about Rust and it's not worth trying to talk with him about Rust. It would be real nice to have a small, lightweight, orthogonal language that could do what Rust does, but we don't have one and we aren't going to know how to make one without Rust learning a bunch of stuff about how to get stuff done first. Once we can make a complicated system that can do what we want, we can figure out how to make a simple system that can do the most important bits. And we aren't going to manage it with attitudes like this article. (Yes, I'm annoyed.)
Concurrency is not parallelism. 
rust-analyzer is amazing, and it's got some great logic behind it. So great even, that I believe the compiler team is talks with them to see if some of it can be brought into rustc. Its only major missing pieces are trait and macro support, and I think there's active work on both of those! Here's a WIP PR for initial trait support: https://github.com/rust-analyzer/rust-analyzer/pull/1040 Exciting stuff all around.
How does this library compare to actix?
Well, if he's a hacker, then I understand his anger towards Rust... What would be a hacker if programs had no "segfaults and buffer overflows" (quote) :)
What's the difference between a smart pointer and a fat pointer?
It seems like many of these criticisms are not of Rust itself, but just it's youth, and a lot of these problems are being worked on. It's fair to say that Rust is young, so you don't want to jump ship, but I don't think it's fair to pin all these problems to Rust itself. 1.0 was only released 4 years ago, so of course it's still getting lots of features. Only time will tell if the language will stay on that path or hopefully calm down to more stability. AFAIK, Rust's spec is being worked on, but it will take a while. Figuring out how to formalize Rust's lifetimes is one issue in this task. Rust's ABI is unstable/unpresent because, yes, Rust is young. For interacting with other languages, you can use C ABI. Expecting interfacing with a language with completely different ideas to be really idiomatic is unrealistic, IMO. We have things like CStr to help with this. Even when the Rust ABI becomes stable, how should a given language interact with it, expecting to give or take ownership, exclusive references, etc. The rest of the points in the article are valid if somewhat personal, although I'm not sure what the point on safety is about.
Something like this works if the pattern is irrefutable. here is an example of that: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a9bbb5b6e3a9827e053eadd5f72da241
This seems like something I'd use a `while let` loop for: let mut iter = vec![Some(1), None, Some(2)].into_iter(); while let Some(Some(x)) = iter.next() { ... } This way makes it a little more clear that the pattern is refutable.
I think OP is specifically interested in a loop that skips over elements for which the pattern doesn't match.
You can write a macro for this: macro_rules! for_let { ($p:pat in $e:expr, $body:expr) =&gt; { for x in $e { if let $p = x { $body } } } } fn main() { for_let!(&amp;Some(x) in &amp;[Some(1), None, Some(2)], { println!("{}", x); }); }
For the record the current way of doing it would be like this: for x in my_vec.iter().filter_map(std::convert::identity)
Seemed fair, until I got to: &gt; Yes, Rust is more safe. I don’t really care. In light of all of these problems, I’ll take my segfaults and buffer overflows. I noped back out. That attitude is no longer acceptable.
They're definitely similar, but I'd say a way to separate them is that a fat pointer is an implementation detail of how to represent some type, while a smart pointer is a pointer with some extra meaning. When you have a slice like `&amp;[T]` or `Box&lt;[T]&gt;` or a trait object like `&amp;dyn Trait` or `Box&lt;dyn Trait&gt;`, these are internally represented by fat pointers, even though that's not really what the type looks like. ["Smart pointers, on the other hand, are data structures that not only act like a pointer but also have additional metadata and capabilities."](https://doc.rust-lang.org/book/ch15-00-smart-pointers.html) Types like Box and Rc are pointers but also represent being on the heap or being reference counted, respectively.
Actix team is focusing mostly on `actix-web` nowadays, their [website](https://actix.rs/docs/) has next to none actor documentation. Meanwhile [actix crate docs](https://actix.rs/actix/actix/index.html) seem overwhelming. It is broad in scope, and has its mental model you need to grasp in order to use the library. Movie is much more primitive (code below), but if you know Rust, using it shouldn't be a challenge. Actix has its runtime, while movie uses system threads (that can be changed if you have a function with signature similar to `thread::spawn()`, but I haven't tried it). Runtime is good when you want to handle 100K+ actors/second (like in web server), but when you do a lot of system calls, it may be slower than system threads (see Golang issues with FFI performance). Runtime also puts some constrains on the user - e.g. you cannot use `tokio` async I/O in Actix actors, as they all run on single thread. I'm not sure what happens when an actor tries to start up new runtime. I thought Actix does not feature ticking (periodically waking up), but now I see it does ([IntervalFunc](https://actix.rs/actix/actix/utils/struct.IntervalFunc.html)). Now, code. This: actor! { SomeActor public_visibility: true, docs: /// This is an example actor. input: Ping, on_message: Ping =&gt; (), } turns into: /// This is an example actor. pub mod SomeActor { use super::*; pub struct Actor {} pub enum Input { Ping, } pub type Handle = movie::Handle&lt;std::thread::JoinHandle&lt;()&gt;, Input&gt;; impl Actor { pub fn start(mut self) -&gt; Handle { let (tx_ota, rx_ota) = std::sync::mpsc::channel(); let (tx_kill, rx_kill) = std::sync::mpsc::channel(); let handle = std::thread::spawn(move || { {}; // on_init let mut running = true; while running { while let Ok(message) = rx_ota.try_recv() { use Input::*; match message { Ping =&gt; (), //on_message }; } if let Ok(_) = rx_kill.try_recv() { running = false; {}; // on_stop } {}; // on_tick use std::thread::sleep; use std::time::Duration; sleep(Duration::from_millis(100)); } }); movie::Handle { join_handle: handle, tx: tx_ota, kill: tx_kill, } } } } 
I follow some of his projects on GitHub and I'm not surprised that he says so. Many (most?) of the issues he has are segfaults and memory problems. Even though he is an extremely rigorous coder..
One think about the "good errors" is how customize the diagnostics. Is fine to get an automatic behavior but sometimes is good to provide more context. &amp;#x200B; Is this planned?
And it allow to add or remove columns/rows? Or only change the inner content?
While it would be great to have the builder consumed on the `build` step, one of our goals is to allow for these all to be chained together. If `build` took `self`it couldn't be appended to that chain since each of the methods returns `&amp;mut self` instead of `self`. You can see it in this playground: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e63ed3fdccf0067a88e2a45b447473c7 One thing it might have been wise to explore in that post was choosing to return `&amp;mut self` instead of `self`. I prefer this because it means that you don't have to assign the builder to a variable before chaining.
TL;DR Rust is new. New is bad. 
My company ([Wuzu](https://wuzu.io)) uses Rust for its matching engine. I haven't heard of other people using Rust in fintech yet, but I see it as a good fit with its performance and features that help writing correct software.
The response to this is IMO simple: reject the premise. People are obsessed with the word "replacement," and it leads to a tireless and pointless debate. Rust is _literally_ not a replacement for C (or C++) because there exist use cases where you probably can't practically use Rust. Those range from simple technical problems (the Rust compiler doesn't support the target platform) to simple social problems (your employer has a whitelist of languages) to legacy problems (you already have N lines of code in C (or C++)) or even simple preferences ("I hate languages with lots of features"). All of those reasons are valid reasons not to use Rust. Presumably, a lot of people like say, "Rust is replacing C" or "instead of using C++ use Rust" or whatever. They're not wrong either! That's because there are tons of use cases for which "Rust or C or C++" are all valid things to pick. There are plenty of use cases where you might even throw Go or Java in there as possible choices as well. Rust doesn't just have to be used in specific performance critical applications. Sometimes you might use it for [movie/tv show renaming](https://github.com/BurntSushi/imdb-rename), or [serving as glue to digitize VHS tapes](https://github.com/BurntSushi/vcr) or sometimes [just shuffling data around](https://github.com/BurntSushi/critcmp). Any one of those things could be written in Python. Does this mean Rust is a Python replacement? Of course not. But it's certainly replaced Python for me in some cases, not just because Rust lets me write fast programs, but because I actually really like the language itself. TL;DR - Stop taking everything so literally. --- To be a bit more charitable, Rust is definitely a bigger language than C, and in some respects, it is a kitchen sink. At this current point in time, I do happen to believe that most of the language features in Rust are exceptionally well motivated. In particular, it would not be practical at all for Rust to, for instance, drop zero-overhead polymorphism, which is itself a very large contributor to Rust's complexity. Without zero-overhead polymorphism, you could still write performant programs, but it would be _much_ harder to abstract over `unsafe` code, and therefore would be much harder to build safe interfaces to things that are otherwise unsafe. This either leads to worse performance (where people opt for safe code that might be slower than what `unsafe` could achieve) or leads to a proliferation of `unsafe`. Both of those things are really generally incompatible with Rust's goals. Nevertheless, if memory safety isn't that big of an issue for you (maybe your threat model is very weak? the stakes are small?), and you really don't like languages with a lot of features, then hey, sure, go use C. I understand the desire for a simple language. I felt it when I used to write C, and I feel it when I use Go today. It's nice. I spend very little time needing to explain Go constructs to others, for example, but that's a completely different story with Rust, where much needs to be explained because it's a more complex language. The real interesting question to me is whether Rust's complexity is _necessary_ complexity, _given its goals_. And that's really what this blog post should have been about, because that's a far more interesting interpretation of "replacement" in my opinion. Otherwise, this blog post could have been shortened to a single sentence: "I disagree with that the problems that Rust tries to solve are problems worth solving, therefore its complexity is far greater than what is necessary."
I ended up following this advice after all. Thanks!
My 2 cents: * C is a literal "minimal infrastructure" built upon assembler. Many decades later it still requires programmers to carefully think what they're doing * design choices may become obsolete. C was born in a time when checking for array bounds was a waste of precious bytes of memory and precious CPU cycles * Rust demands a mindset (and that's why it has a steep learning curve), mostly about what C programmers lack * no such "good for everything" language exists * Cargo: when something does a pretty good job, there is little interest in wasting time searching for an alternative
Just a note, I don't think the person who posted this is actually acting in good faith: https://cmpwn.com/@sir/101811808237011353
I'm not actually familiar with the package. Can you please give some example code you've been trying so I can try to understand what's going on? Thanks.
I do the same thing, but I just use `c` for crates.io and `d` for docs.rs.
Step by step, clear and precise. Someone call that 5 minute rust video guy and have him make this into a video!
Yes and posts like those get old. Why spend all that energy lamenting? Nobody will take C away from the author. He can do as he pleases. There is nothing to be gained from discussing this...
I can appreciate the different perspective about one may be productive at the keyboard, environment and programming language of choice. I can appreciate and respect this coder did great work in C. Where I differ is I believe others can do great work in other languages like golang and rust. I also believe interoperate between these languages is useful but always inconvenient. Let's talk about great work. The following gui libraries empower developers to develop something with innovative guis, but it doesn't come easily no matter what toolkit you use, no matter what language you use. Rust emphasizes safety, control of memory layout and concurrency which is why I have started to prefer it over golang and c++. * https://github.com/therecipe/qt * https://github.com/KDE/rust-qt-binding-generator * https://blog.bhdouglass.com/clickable/ubuntu-touch/2019/01/18/clickable-5-4-0.html * https://gtk-rs.org/ * https://www.redox-os.org/news/release-0.5.0/ I would like to highlight the fact that I believe gui work is high-impact to how well-received an operating system is. The flow of the gui is key. Buggy gui's are seemingly acceptable provided the flow remains intact most of the time. RUST's REDOX operating system capabilities are growing modestly but when it provides not only a prototype workable gui flow, but also the necessary tools to build those guis within its os, I believe it might overcome Linux' popularity if not grow on top of it since it is inheriting the LINUX mindset: open-source, reliable and respecting digital freedoms. Once the rust operating system is running, all the other languages could be running on top of it more reliably or at least that is what the current existing projects are pointing towards: i.e. javascript interpreters in rust, lisp interpreters in rust, python interpreters in rust, web assembly in rust etc... I'm not making this shit up. It already exists. So yeah subtleties are already indicating RUST and REDOX will fly and its wings shall be huge and strong.
A "fat pointer" is a low-level implementation detail for a pointer that carries some additional runtime information. `*const T`, `*mut T`, `&amp;T`, `&amp;mut T` are "fat pointers" under the hood if `T` is an unsized type. A "smart pointer" usually involves ownership semantics. It's "smart enough to release its pointee automatically" on dropping it -- so it "owns" its pointee. I havn't come across a pointer-like type that is called "smart pointer" without ownership semantics. These concepts are orthogonal. You can have a smart pointer that is implemented in terms of a thin pointer or a fat pointer. And you can have thin and fat pointers that are not smart. *const i32 // thin &amp; dumb &amp;[i32] // fat &amp; dumb Box&lt;i32&gt; // thin &amp; smart Box&lt;[i32]&gt; // fat &amp; smart :-)
I think one could sum up the gist of the article with the [linked tweet](https://cmpwn.com/@sir/100437209244243864) and the final sentence of this post: &gt; .... now you [Rust programmers] know why we are still writing C, and hopefully you’ll stop bloody bothering us about it. /me sighs. I wish I knew why Drew was so irritated by this. If Rust isn't going to make a difference, why bother taking time to address it? Perhaps you spoke with the Rust Evangelism Strike Force and not the actual Rust community? --- Noting that I respect Drew as a developer, here's my feedback on information in the article: &gt; C is the most portable programming language. Yup. No argument there! That's demonstrably true, so long as you only argue that the LANGUAGE is portable and not the code written in it. :) &gt; **C has a spec.** .... That they [the Rust community?] can’t slow down to pin down exactly what defines Rust is also indicative of an immature language. There's no doubt that a spec is a point of maturity in the language. Work is being done here, but right now the language is a moving target on purpose. Yes, that means that there's churn. Yes, that means that things will (and have) become outdated. That's valid. However, the part that I omitted above: &gt; Any behavior it exhibits could change tomorrow. Some weird thing it does could be a feature or a bug. There’s no way to know until your code breaks. ...is *not* valid. Stability in the language has been [promised since Rust 1.0](https://blog.rust-lang.org/2014/10/30/Stability.html), and from what I can tell the Rust team has made good on that promise (at great effort, mind you!). I can still compile code written in Rust 1.0, soundness-bug-inducing code notwithstanding. &gt; **C has many implementations.** Another point of maturity here. I understand why Drew argues this is beneficial. &gt; **C has a consistent &amp; stable ABI.** The System-V ABI is supported on a wide variety of systems and has been mostly agreed upon by now. Rust, on the other hand, has no stable internal ABI. The only code which can interact with the rest of the ecosystem is unidiomatic Rust, .... The outside world exists, it speaks System-V, and us systems programmers spend a lot of our time talking to it. Drew is interlacing a few points here, and thinking critically about this paragraph they feel conflated. Is the problem a lack of stable ABI, the friction in writing FFI into C (which *is* a stable ABI), or not using the System-V ABI? The first and third points don't seem a problem given the second. &gt; **Concurrency is generally a bad thing.** Serial programs have X problems, and parallel programs have X^Y problems, where Y is the amount of parallelism you introduce. .... However, nearly all programs needn’t be parallel. .... Rust in no way forces you to use concurrency. You still have this choice with Rust programs. But *when you decide to actually reach for it, concurrency is supposed to be easier than with C.* So, how is this point valid? As for the other part of the paragraph I think needs to be addressed: &gt; **Cargo is mandatory.** Rust’s compiler flags are not stable. Attempts to integrate it with other build systems have been met with hostility from the Rust &amp; Cargo teams. The outside world exists, and us systems programmers spend a lot of our time integrating things. Rust refuses to play along. Yes, Cargo is supposed to be the authoritative Rust building tool, and that's by design. I don't understand why that's a problem! The [vast](https://github.com/rust-lang/rfcs/blob/master/text/2136-build-systems.md) [majority](https://github.com/rust-lang/rust-roadmap-2017/issues/12) of discussion for integrating into other build environments is via `cargo`, not `rustc`. For all intents and purposes, `cargo`, not `rustc`, is what you use to build Rust code -- even programmatically. Compiler flags are not the point of integration that we should be talking about in the first place. So, this particular complaint about integrating with `rustc` seems misplaced to me. Second, honest question: what examples of hostility are there? I'm not familiar with Rust development history here. I'd be surprised if this were actually true, but I want to make sure I understand the context of this point before dismissing it. &gt; A program which uses poll effectively is going to be simpler, reasonably performant, and have orders of magnitude fewer bugs. Polling is fundamental in concurrency...so Drew's point here seems to be that using simpler primitives results in better code? You can use basically any concurrency primitive available in C in Rust, so I don't see any implication for Rust specifically. Anybody see something I don't here?
Sounds just like he regrets developing wlroots/sway in rust?
I see no downside to speak of. I haven't looked at the ImageMagick code: it's old, so maybe it does striping or something where it can to save memory, but there's a good chance it just reads the whole image into RAM anyhow. If you care a lot about transient memory use, you could hack up `imageproc` to do striping also, I guess. Honestly, though, with a GC-ed language like Ruby the last thing I'd be worrying about is a few hundred MB of transient image data.
I've done a similar thing to debug rust embedded code, but using the Cortex-Debug addon instead.
ImageMagick doesn't have a stellar security track record. It's worth considering Rust for that reason alone.
It works like a charm! Now, I was wondering. To access the value within the mutex I need to lock it always. I thought that locking the data is only required when I want to access it to write on it. In a following case I only want to access it in a readonly way. Is there a way to do it with mutexes without having to lock it? Im currently looking here for a solution but I cannot seem to find anything: [https://doc.rust-lang.org/std/sync/struct.Mutex.html](https://doc.rust-lang.org/std/sync/struct.Mutex.html) &amp;#x200B; Cheers and thanks! 
Regarding PhantomData for fullfillng a struct bound; I would argue that you probably don't want to bound a struct like that at all. I prefer to leave my struct type params unbounded and add bounds in implementations.
There isn't really a good reason to need to do this - but, is there any way you can name a macro \`fn!\`?
PR author here. Thanks for bringing attention to this -- I hate to put pressure on /u/kbknapp, but I do think that is an extremely simple PR that would give some good bang for buck with transitioning to Rust 2018.
If you want to skip over the `None` variant? Here you go, `flat_map`. [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=43ba49c28ee1f5ff2a5e36a83eab3bfc](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=43ba49c28ee1f5ff2a5e36a83eab3bfc) for x in [Some(1), None, Some(3)].iter().flat_map(|x| x) { println!("{}", x); }
This is 0.4 of pulldown-cmark? We've been making big changes. Also, any chance you can benchmark cmark and hoedown? I'd be interested to know if we're actually fastest. /u/marcusklaas has been working on SIMD and other optimizations, which should get us even better performance.
Who is this guy? Why am I supposed to care what he thinks?
Re: your VHS project... I thought I was the only one crazy enough to use Rust as an interface around ffmpeg. (Though my usecase is a lot different, my rust program just invokes &amp; shepherds a number of ffmpeg encoder processes that make up an HTTP live stream.) It's exactly as you said though: my program started life as a simple shell script, and when I rewrote it I could just as easily have chosen Ruby or Python etc., but honestly I just find Rust pleasurable to write.
He is developing "the" helper library for wayland compositors called wlroots. Unfortunately he chose c even though it was a greenfield project.
It's necessary to lock it because, otherwise, you run the risk of someone else writing to it while you're in the middle of reading it. The only data types you can avoid this with are the ones in `std::sync::atomic` which are guaranteed to be readable/writable in a single operation.
I just took a quick look at [gumdrop](https://crates.io/crates/gumdrop) but haven't tried it out yet. Other than having fewer dependencies, how does it compare to [structopt](https://crates.io/crates/structopt)?
wlroots and sway are written entirely in C.
I'm a minor contributor to Sway and wlroots and have been following these projects very closely over the past few months. I can probably count the number of memory bugs found on my hands, and they have all been solved very promptly. Both of these projects add up to almost 100K lines of C and yet are still rock solid. Contributing to these projects is what made me start loving C more than Rust.
Right, but that's a mouthful. I'm just talking about some sugar for these cases. 
yup
Writes a blog post that starts by arguing that Go, not Rust, is the true successor to C. Continues with a critique of Rust which applies almost in its entirety to Go.
I can never get this to work when it comes to working with files. If I have a file in the cwd, the code doesn't pick it up which leads to me not being able to debug a lot of stuff
Presumably `r#fn` works for macros, unless it eats the `!`.
Author here, stepping into the lion's den. The Rust community has a reputation, so note that I'm ready to abandon thread as soon as it gets hostile in here. &gt;I can still compile code written in Rust 1.0, soundness-bug-inducing code notwithstanding. Right, but that code is no longer idiomatic. Rust code becomes stale quickly, C code does not. &gt; Is the problem a lack of stable ABI, the friction in writing FFI into C (which is a stable ABI), or not using the System-V ABI? The first and third points don't seem a problem given the second. The problem is that Rust talks to itself using one ABI, and talks to everyone else using another (System-V). That means you have to have an interface with the outside world which is not idiomatic Rust. IMO this over-complicates the design in the name of supporting features I don't even think Rust ought to have. This problem is not exclusive to Rust - C++ and Go, for example, have the same issues. &gt;Polling is fundamental in concurrency Polling is fundamental *for* concurrency, but you can use poll without having any concurrency. &gt;Rust in no way forces you to use concurrency. You still have this choice with Rust programs. But when you decide to actually reach for it, concurrency is supposed to be easier than with C. So, how is this point valid? I'm de-fanging the purported benefit of concurrency being easier in Rust, as it's frequently trotted out as an argument for Rust. But for most programs, concurrent design is bad design, so this argument holds little weight with me.
`flatten()` is just for this :)
Thanks! As the guy who led development of "the" replacement helper library for X11 called XCB 20 years ago, I agree with you that the choice of C in current year was…unfortunate.
I'm working on figuring out the right way to add moments to `uom` over at https://github.com/iliekturtles/uom/issues/118
Taking a step back I think some of this criticism is valid. I don't think there can [be a formal/defined spec yet](https://users.rust-lang.org/t/is-there-a-plan-to-get-a-formal-rust-language-specification-at-some-point/21622), but it would be a great step forward. I think the point on ABI stability needs to be brought up more often, with [Swift](https://github.com/apple/swift/blob/master/docs/ABIStabilityManifesto.md). Not the de facto ABIs of C. It's certainly possible to have a binary with a stable ABI in Rust today, by writing an unsafe C-linkage wrapper around it then writing a safe wrapper around the C wrapper. But that's a lot of boiler plate that throws out the safety guarantees of the compiler. Dependence on Cargo for tooling/building and lack of stable `rustc` flags is also a problem that isn't mentioned a ton. We talk a lot about how Rust best fits in with a policy of writing new components or safe rewrites into existing codebases, but that's not exactly painless (depending on your build system, it's not terrible with CMake).
The author claims that System-V is "basically standard" C API, which I find amusing given his insistence on a spec. But anyway, isn't this Windows-exclusionary? I know that people like to pretend Windows doesn't exist, but it's still ~50% of user and developer computers.
`Iterator::flatten` is equivalent to `flat_map` with the identity function, which might be a bit nicer in some cases. Since there are plenty of ways to do this with both control flow ops and iterators, I doubt they're going to add any syntactic sugar for it soon. I can't link because I'm on mobile but there was a discussion somewhere explaining how they prioritize new features over prettifying existing ones.
Ok first impression: overusing interior mutability and vec of char seems like code smells to me. First I went to replace all RefCell with regular Cell. RefCell are Rust's borrow checker rules at runtime, however for simple data types that is not needed and Cell's more simple semantics work just fine: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6ea20e7bf22781db69b132dc11130056
I don't think sugar is a good thing to be adding to the language. If you look at Scala, they took sugar to the fucking moon and now there are 4 ways to write code that compiles down to the same thing. Since Rust wants to be explicit, using filter\_map or flat\_map is much better and more clear.