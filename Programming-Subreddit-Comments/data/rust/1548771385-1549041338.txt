Any idea why the `pulldown_cmark` plot on the right is very non-linear between 200 and 300 iterations? 
Yes, as well as having looked at Tokio and tokio-threadpool in particular. Unfortunately, I tend to have a bit of a hard time wrapping my head around the existing implementations, probably due to not being too familiar with all the internals.
`foo` actually has a very simple types, it's `fn() -&gt; ()` as you can see here: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ce85ffb6da7f20eb62db27e891da1c2d Only closure types are unnameable (and different for every closure). To be able to work with them, they implement (at least one of) the Fn-Traits, i.e. Fn, FnMut or FnOnce (note the upper-case F).
Anyone has good examples for using assert_cmd: https://docs.rs/assert_cmd/0.11.0/assert_cmd/ The documentation/source lack that. Basically I'm looking to send argument, check output, send multiple commands and check in between.
Per our on-topic rule, I would ask someone to leave a top-level comment explaining this submission's relevance to casual readers of the subreddit.
Oh okay lol. Indeed it is too unintuitive
Ralph's data structure might be a better fit for audio than `SegQueue` since it's been specifically designed for that domain. That said, I've heard stories of success even with using `mpsc` channels for audio, so who knows. :) To be honest, it'd be great to collect some thoughts from people who need queues/stacks for audio in Crossbeam's issue tracker. Then we can weigh in all the different tradeoffs and come up with general solutions that cover the broadest set of applications.
in main.rs you'd put `mod libA::libA1;` `mod libA::libA2;` etc. Then if you want to use an item from libB2.rs in in libA1.rs, you'd say `use crate::libB::libB2::item` in libA1.rs.
I wrote [this](https://bheisler.github.io/post/state-of-gpgpu-in-rust/) months ago but it's still broadly accurate as far as I know. I'm not as familiar with OpenCL/Vulkan, so there may be new developments there that I'm not aware of. Support for compiling Rust code to CUDA has gotten better since then ([link 1](https://github.com/rust-lang/rust/issues/54115), [link 2](https://github.com/rust-lang/rust/pull/57937), [link 3](https://github.com/rust-lang/rust/pull/57268)) but I wouldn't call it production-ready yet. There is also [my RustaCUDA library](https://github.com/bheisler/RustaCUDA) which provides Rust-y bindings to a subset of the CUDA API which can load and execute compiled kernels that could come from any language (though in practice it's almost always either Rust or CUDA C). My recommendation (for the moment, anyway) is to use Rust for the host code and CUDA C for the device code, loaded and launched with RustaCUDA. Hope this helps!
Task schedulers that go for high performance generally want to come up with their own mechanisms for thread blocking/unblocking. That is why `crossbeam-deque` isn't concerned with blocking operations at all. I suggest you create a `crossbeam::sync::Parker` for every thread and some kind of queue/stack of parked threads, let's say a `SegQueue&lt;Unparker&gt;`. When a thread finds no work, it pushes its `Unparker` into the queue of parked threads, and then checks *again* if there is any work. If there is still no work, then it calls `parker.park()` to go to sleep. When a thread wants to notify others that there is work available, it pops from the queue/stack of parked threads and calls `unparker.unpark()` to wake all threads. Now, there are lots further optimizations one could do here, but it is a good start, and might even be good enough. This is more or less how Rayon and Tokio work, too, although they do utilize a few more tricks to make things faster but nothing major.
Is this semver trick an unintended feature? It seems dangerous to use type equalities across incompatible versions like this. Now you can mix and match functions that use the 0.3.1 type and the 0.4 type and all possible combinations should work correctly.
IIRC, I have seen people get worse performance with their Rust port because they did not use the `--release` flag. I don't remember the specific instance though, sorry. &gt; Maybe for heavy string manipulations, where most Python functions just directly call the corresponding C routines. I think you can construct an example with anything where most of the work is done by some C library. Regular expressions, numpy, etc.
Yes, i'd like to name those special types, to provide specialized impls just like this monomorphisation example. There are other options, but since each fn already is its own type, and each fn has a name, why wouldn't you be able to name the type?
&gt; but a method-like .await_!() macro is completely unrealistic. It requires a new syntax that is impossible to justify just for this special case. My point is exactly that there is plenty of justification for this kind of syntax. even things like `expr.dbg!()` and `"hello {}".format!(foo)` would be pretty nice. And as far as I can see, the implementation of postfix macros would pretty simple. It could be almost entirely in the frontend parsing of the compiler, and simply desugar to a standard macro like so: `expr.macro!(foo, bar)` =&gt; `macro!(expr, foo, bar)` (there are also a few other possible desugarings which could be considered)
I've wanted to start using Rust for more than just the Advent Of Code, so I was going to take up a side project. I'm interested in proc gen, so I was going to play around with some voxel cubes and see what I could do. I wanted to use Rust/Vulkan, but that is a dark path to start down. Luckily, just yesterday, I found out that [Veloren](https://www.reddit.com/r/Veloren/) existed. Veloren is a FOSS voxel RPG game inspired by Cube World/Dwarf Fortress. I've started talking to the community, and already I've learned a significant amount about what makes Rust great for this type of project. I've always used C++ in Uni for game dev, so this is a great improvement! Excited to see where Rust can take me :)
That's the name of Mars' moon. The smaller one, I think.
Yes, fn item type coerces to a function pointer (and is zero sized, because the type itself represents which function will be called). To see it, you need to use it where a coercion cannot happen (either impossible, or wrapped in some other type): https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=57efbb149c5242f30417d56d42443e98
I see, thanks. It is indeed not possible to name the function. (You can name the type of a pointer to it or use generics though.) Why would you want to name the type? The type is unique to the function. If you know the type, you might as well just call the function. If you want to store it in a struct, you can use generics or indirection. I don't see a use case for naming the type of a function, I guess that is why it is not implemented.
As with all things, it's a trade off to avoid ecosystem wide breakage: https://github.com/dtolnay/semver-trick I'm not aware of the semver trick being intentionally designed.
Yes, what you are seeing is coercion to a pointer, see the [docs](https://doc.rust-lang.org/reference/types/function-item.html).
This does help me quite a lot! Thank you so much!
I read through the thing from your GitHub issue and it feels like a bug because of the unintended consequences it can have.
With the semver trick, you get some breakage in weird spots. Maybe there is a way to smooth it out, I don't know. Someone smarter than me will need to figure it out. Without the semver trick, you either stagnate or break the entire ecosystem.
AFAIK currently cranelift probably doesn't have the "good performance even in debug builds" bit.
Yes, it is right. Rust relies a lot on LLVM to do the heavy optimization lifting, so you if you disable optimization (as we tend to do for debug builds), you may end up with very inefficient code (depending on what you do). Those abstractions don't magically evaporate. That said, I personally find that the development cycle with Rust is more staggered than with, say, C++, because Rust is much stricter. So where in C++, you'd code / compile / run / crash / debug / repeat, in Rust you'd code / check / repeat / test / repeat / run / debug remaining problems. This means that Rust is worse off if you're debugging gameplay, but better getting the foundations right – so you can win by writing your high-level logic in a scripting language and the lower levels in Rust.
Ah, that sounds interesting so I'll take a look at that. Thanks!
It is right. I began to develop a brick-breacker with Piston (not a heavy framework, tho): without optimization, when hundreds of balls were on the screen, it was laggy AF, but with optimization thousands of balls were not even a slight issue. There are orders of magnitude between non-optimized and optimized code.
crossbeam looks awesome. I'm not writing high-concurrency stuff in Rust now but will have fun trying this out when I do. Has anyone looked at using Linux's [restartable sequence](https://news.ycombinator.com/item?id=17368305) support within crossbeam to avoid atomics? Google uses this stuff internally everywhere (including something like crossbeam-epoch) to reduce overhead. One downside of using it outside of a controlled environment like Google production is that it's only supported in quite recent vanilla kernels, so you'd probably have to compile in both codepaths and select the implementation at runtime.
By writing this function signature: ``` impl&lt;'a&gt; B&lt;'a&gt; { fn set_a(&amp;mut self, a: &amp;'a A) { ... } } ``` you promised to the compiler that `a` lives as long (or longer) than any struct of type `B`. Your code breaks that promise. Working around this leaves you with two options: 1. Make `a` live as long or longer than `b`. 2. Change the signature of `set_a`, no longer promising that `a` outlives any instance of `B`. 
The GUI ecosystem in Rust is not really mature yet and it is the object of many discussions, so I'm afraid there is no standard answer to your question. Moreover `gfx-hal` has just been released, so I don't know if there is any GUI framework supporting it yet. Anyway, you can look for more informations on areweguiyet.com
 FWIW If your situation allows it ( T can impl Copy ) you can use [as_slice_of_cells](https://doc.rust-lang.org/std/cell/struct.Cell.html#method.as_slice_of_cells) as in [here](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=4b4d7b5483aff3f0b0abb252183e154b) which shouldn't Copy at all. Then again, if that is the case, you can skip all the cell casting and just use the copy , LLVM will optimize it away.
Preferably, the `let a` could be moved to the same scope as `let b`. This would result in a shorter lifetime, while still satisfying the borrow checker.
My problem is harder in some ways (rigorously allocation-free) and simpler in others (it's basically single consumer, with potentially some relaxation of that constraint). Based on discussions with u/Holy_City, one of the related things I plan to explore soon is an allocation-free refcount cell. Basically, when it gets dropped in the realtime thread, it gets added to a deallocation queue, which is processed in a different thread. I'm basically in agreement with u/stjepang here, this is not a "one size fits all" situation, and it makes sense to have data structures that are specialized to their use cases. That said, it's great to have a solid library of primitives that cover more and more interesting cases.
The channel, deque and two queue implementations all seem to be kinds of queues. It would be helpful to have a brief table of features/benefits on the crossbeam front page to help people choose between them. (Fantastic work on all of this BTW!!!)
Oh, it's /u/eddyb (and a couple of others whose names I didn't recognize): https://github.com/orgs/lykenware/people To the Lyken folks: You could add a bit more credibility with some "who we are"/"what we do" kind of info on your site rather than just a few email addresses and some promises that you'll do stuff.
Azul is build on top of WebRender which, I think, is planning to migrate to gfx-hal eventually. 
I'd rather this not be posted to this subreddit, we're still somewhat in stealth mode (even if some people know that I have a company), and there's not much to see anyway. The website is mostly a placeholder, the main reason I got a domain is for email addresses (e.g. `eddyb@lyken.rs`).
See [my other comment](https://www.reddit.com/r/rust/comments/akzsff/lyken_software_solutions/ef9w8ep/).
Ah sorry so I misunderstood you. Can't help with that unfortunately. 
I would just do it like this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=413c989416764371a8203dc3e2b21fde In order to send an already-locked `Foo` to another thread, the lifetime of the guard would need to be `'static`, which you're pretty much never going to get. It's much easier to just send the entire `Arc&lt;Mutex&lt;Foo&gt;&gt;` to the thread in question and lock it there.
To save the embarassment of u/steveklabnik1 telling HN that — "C version was ported to be the Rust one".
Ah, guess you got yours in between a refresh and leaving mine!
... it was ported though? Sure, additional modifications were made too, but you also recognize that as a "straight port" vs a "port".
Is your deallocation queue bounded? How do you prevent locking or allocation if it's not.
&gt; If a future is calling wake before returning Pending, it's not because it can actually make progress, it's because it doesn't have a better way to get its task woken up. If it could actually make progress and is so CPU/cache bound that maybe having to wait in line to get polled again is a problem, then... Why is it in the hot path of an IO-bound event loop in the first place? And why not just go ahead and make its progress rather than yielding? How do you tell a Future that calls wake before returning `Pending` from one that returns `Pending` and right after `wake` gets called apart?
The primary problem is when you build complex things out of many chained iterators. With --release, those turn into near ideal machine code, with a single loop with all the things done inline inside it. With --debug, you need iirc more than a single function call per iterator per iteration. IMHO we need a halfway step between --release and --debug, that collapses chained iterators but generally limits other inlining. Or we need some way to mark each instruction inside the iterator chain with "I belong to *this* iterator" tag.
I've removed the post; though of course it's probably been seen by quite a few people by now.
I’m not sure whether it addresses your question specifically, but Rúnar Bjarnason’s [talk](https://www.youtube.com/watch?v=rp_Eild1aq8) about Unison at LambdaWorld 2018 was quite informative.
My work actually bought me a new machine recently specifically to help in this area, so times have drastically improved. On my old machine, Building from scratch for debug took\~5 minutes, release took about twice as long. I just cleaned an rebuilt. On my new machine (Intel Core I7-8700 @ 3.20 GHz + 16 GB RAM (if RAM even matters) ): * `cargo check`: 0:40 * `cargo build`: 1:33 * `cargo build --release`: 2:28 * small, incremental `cargo check` (touched a file): 0:06 * large, incremental `cargo check` (renamed a struct that is used in almost every file): 0:12 Now that I look at those times, they actually seem really good considering the size of the codebase. It is possible that I felt it was slow because I recently did a huge refactor and the RLS was very slow to update. I am considering switching to simply using `cargo check`, but something tells me it won't be much faster if at all.
Have you looked into nebulet?
*psst someone do 7z in rust*
From the outside, you don't, it doesn't matter. I'm more talking about how the future itself is implemented.
As I continue work on my OptiX-based pathtracer (not yet public), I've been writing a wrapper for OpenImageIO, which is here: [https://github.com/anderslanglands/oiio-rs](https://github.com/anderslanglands/oiio-rs) &amp;#x200B; It's been an interesting exercise in how to bind a large and complex C++ library with many dependencies to Rust. So far I've settled for forking OIIO and OpenEXR to have reliable branches to use as submodules in the project, while requiring image libraries and boost as pre-installed dependencies. 
I wonder if macros might be an acceptable compromise. Wrap the iterators in a macro that is basically a DSL with identical syntax to just using an iterator except it does the same sort of optimization as the rust compiler such that you get a fully optimized iterator. &amp;#x200B; This way you're only running the "optimizer" on the iterators that you care about being fast at debug time. The macro could even just emit the input in release build so that it gets optimized as normal in that scenario.
Last commit 4 months ago
Regarding `CachePadded&lt;T&gt;`, I noticed that you use [a 64 bytes alignment](https://docs.rs/crossbeam-utils/0.6.5/src/crossbeam_utils/cache_padded.rs.html#52). C++17 surprised me by settling on *two* "cache line" sizes: [hardware_[constructive|destructive]_interference_size](https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size). This led me [to investigate](https://stackoverflow.com/questions/39680206/understanding-stdhardware-destructive-interference-size-and-stdhardware-cons), and I discovered that Facebook's Folly library was using [128 bytes](https://github.com/facebook/folly/blob/master/folly/lang/Align.h#L107) on non-ARM processors (presumably Intel/AMD) with a reference to Intel processors starting from Sandy Bridge pulling *pairs* of cache lines leading to artificial contention with alignments lower than 128 bytes. It may be necessary to reflect this divide (64 for constructive/128 for destructive) into `CachePadded&lt;T&gt;`, in some form.
There is also the [Zig Language](https://ziglang.org/), which has much the same goals as Jai. &amp;#x200B; This seems to be happening over and over in different industries. My take is that C/C++ were what we needed at the time, but then everyone moved onto Java/C# for many types of work that you could have used C/C++. At some point everyone realized either A) you can't use Java/C# for some things or B) you could have a system language with lots of neat features but actually still be performant. Either way, we started to see a lot of languages enter into the ecosystem. Go, Swift, P, D, C# low level primitives, Rust, Jai, Zig, C++11, etc. It feels like people want something \*like\* C/C++, but they don't want the languages themselves. And that makes sense. C/C++ can do anything, but they're not really good at any \*one\* thing and they get all this general power by forcing you to write your own high level features using patterns, which are going to be different and incompatible with everyone else's libraries AND by having a lot of UB. &amp;#x200B; Power is nice, but if I had to open an envelope with a chain saw or shot gun I wouldn't be very happy. I want the less powerful, but more purpose made letter opener. &amp;#x200B; I think that what we're seeing right now is many different domains constructing their own programming languages that can be used to replace C/C++, but will not be applicable across the board. If you tried to replace C/C++ wholesale you would just get C/C++ again. However, it is possible to replace it on a domain by domain basis. So my predication is that we're going to be seeing a lot more programming languages rise up in the next 5 - 15 years. &amp;#x200B; Rust is probably useful for subparts of game development, but the overall picture is different enough that game development will probably end up being dominated by some other language that is purpose built for it. Jai looks promising but hasn't been released and Zig looks promising but is still in the beginning phases. &amp;#x200B; Personally, I'm going to use Rust (or a custom language that I write) for game development, but that's because I'm not a professional game developer and I don't need to push the hardware as far as it will go and I'll spend most of my time wrestling with concepts that the professional knows like the back of their hand. &amp;#x200B; Rust is in a very good place, but it isn't going to be universal.
Out of interest, why have you removed the one with the new optimisations? (in [this commit](https://salsa.debian.org/benchmarksgame-team/benchmarksgame/commit/7a43f67264792e45fc1534dd4a4392645a504562)) From my reading, it doesn't change the algorithm, but moves loops around so that they're more easily optimisable by accident. I see from [the issue](https://salsa.debian.org/benchmarksgame-team/benchmarksgame/issues/97) that the original contributor has provided two implementations - one with small changes, and one which is a "straight port" (the definition of which, I believe, is rather fuzzy), would it be possible to host both of them? 
Ah hah! I tried using the `Arc&lt;Mutex&lt;Foo&gt;&gt;` but kept failing to get it returned when I locked it, didn't occur to me to return the whole lock and let it return. Appreciate it!
What kind of issues are you running into, what interface would you prefer, and is using ndarray not an option for you?
They say that code is read more frequently than it is written. But it is always run more often than it is read. One could argue that the best code is that which runs so well it doesn't need to be read at all.
Never used that library but using it seems straightforward. You can always look inspiration from [open source projects](https://github.com/search?l=TOML&amp;q=assert_cmd&amp;type=Code). However, I don't quite understand what you're trying to do. Are you trying to test an interactive application? Or pipe data between applications?
I'm guessing it's because you turn the first `&amp;mut self` into a `*mut T` and then turn that back into a new `&amp;mut` reference. Turning a raw pointer into a reference is an unsafe operation that creates a new lifetime from the aether. The compiler does not check this lifetime and leaves it on you to make sure it's correct.
It's unbounded and based on linked lists. To be clear, I haven't implemented the reference counted version yet, right now it's done explicitly by sending the dropped item back on a return queue.
Slightly more precise instructions: 1. Draw a triangle 2. Draw a thousand more triangles 3. Do an OpenGL call to transcribe it to a screen buffer 4. Display the screen buffer
Most UI libs depend on an awesome svg rendering library. I think a better question might be something like “could libcairo be written in gfx -hal”
An excellent general resource for this is Dimtry Vyukov's [queue catalog](http://www.1024cores.net/home/lock-free-algorithms/queues/queue-catalog). Also, I want communicate one thing clearly. There are tons of audio implementations out there that do some allocation. You can get away with it if you either increase buffer lengths to hide the resulting latency variance, or are willing to tolerate an occasional glitch. I strongly want to do better, and feel that's the Rust Way - get the low level stuff right, then people can build cool stuff on top of that. If you just want to bodge together a bunch of stuff that kinda works, we have other languages for that (which I won't name out of respect for the forum rules).
So, is it me or has Appl really been granted a patent on seemingly every modern programming language?
Could be `Vec` reallocation. I'd be interested too if somebody digs into this.
This is true, but I want to let people know we're working on a `new_algo` branch that will both be faster and fully spec compliant. Progress has been in fits and starts, largely because I've got my fingers in too many pies, and also because I've been hoping to mentor somebody to take it on more seriously.
Unfortunately [Gecko](https://en.wikipedia.org/wiki/Gecko_\(software\)) haven't really been embedded in a long time. With [Servo](https://en.wikipedia.org/wiki/Servo_\(software\)) we may be able to do this. Doing Web GUIs with Rust shouldn't be much different from any other backend. Simply run the backend server on localhost and connect to it with regular JavaScript and the browser of your choice. To do this, look into frameworks like [Rocket](https://rocket.rs/). However I don't really know how you could distribute this easily. As you mention, something like [Electron + Rust](https://keminglabs.com/blog/building-a-fast-electron-app-with-rust/) could work but is not optimal.
Just the last few days I checked out the email crate ecosystem and a comprehensive set of quality crates that handle both parsing and generating emails, thoroughly tested with real life data, is sorely needed! I did see this set of crates. Sadly, as is mentioned in the post, parsing is not yet supported so I hope this get's implemented in the future.
On newer nightlies you can use the experimental flag \`self-profile\` that will give you an idea of what the compiler is doing: &amp;#x200B; \`\`\` $ RUSTFLAGS=-Zself-profile cargo build Compiling proc-macro2 v0.4.23 Compiling libc v0.2.43 Compiling unicode-xid v0.1.0 Self profiling results for unicode\_xid: &amp;#x200B; | Phase | Time (ms) | Time (%) | Queries | Hits (%) | ---------------- | -------------- | -------- | -------------- | -------- | Parsing | 5 | 2.91 | | | Expansion | 23 | 11.54 | | | TypeChecking | 19 | 9.47 | 120660 | 99.04 | BorrowChecking | 1 | 0.74 | 202 | 52.48 | Codegen | 25 | 12.45 | 829 | 68.52 | Linking | 8 | 4.02 | 110 | 63.64 | Other | 121 | 58.89 | 63272 | 83.54 &amp;#x200B; Optimization level: Aggressive Incremental: off \~\~\~\~\~\~\~\~\~8&lt;\~\~\~\~\~\~\~\~\~ \`\`\`
I believe you have to have the same type in both arms of OK and Err. in OK you return a type T in the Err arm you return nothing. that's not working.
It's part of an infinite loop until the user *does* enter a correct type.
How would this even be enforced? Sure, it makes sense that Apple could start demanding money from the companies behind the languages, but what about all software already written in those languages? 
&gt; Windows Found your problem! Okay, jokes aside, here are the methods available: https://docs.microsoft.com/en-us/windows/desktop/ipc/interprocess-communications Too bad you're not on *NIX, UNIX Domain Sockets are a nice option for this.
Ah, very cool. I did in fact find an active clone of WebRender that appears to be migrating to gfx-hal: https://github.com/szeged/webrender
Porting my c++ android app to rust. And forking Lewton.
The patenting landscape in the US is weird to say the least. What many companies end up doing is a kind of mutually assured destruction approach. If you sue me over patent x, I will sue you over patents y and z. Hence companies optimize for acquiring as many patents as possible. A big portfolio acts as a deterrent. You can't really blame companies for this, they have to play this game. It's the patent system that is broken. Another use for patents is the "protection money". If you are a big industry player you are _sure_ to have many neat patents for it. So you can insist on anyone license your portfolio, and they can both use your patents, but also have us counter sue active who threatens you. Cause we actively need to prove that we have the best ~bombs~ patents.
Starting the beginning of a new rust GUI framework, nothing revolutionary just a challenge for me instead of learning gfx. Once its done I'll probably upload it, and then switch to gfx
Often with large companies it's more a question of building up their "war chest" of patents. The idea being that if someone large with a lot of patents of their own starts filing piles of lawsuits against you, you need a plausible threat of filing piles of lawsuits back against them. The rational strategy in this system is "patent everything and ask questions later," and it may be that no one ever intends on enforcing them. (But that can change when a company goes out of business or gets acquired, and all their patents go out to the highest bidder. The whole thing is so weird.)
I am doing this for my android app using crossbeam bounded channels. The c++ version uses moodycamel’s spsc.
Just incredible. I can't tell you how happy I am to see how far this work has gone. A huge thank-you to everyone involved!
if you look at the error message the compiler throws it probably says something like incompatible types arms. or similar. &amp;#x200B; if you use "match" to compare things the return type from the blocks (OK or Err) must be the same. In your example you return something in the Ok arm, but nothing in the Err arm. 
This post mentions multiple soundness issues in older versions, which is kind of expected of a project with this complexity. However, [only one ever got a RustSec advisory](https://github.com/RustSec/advisory-db/pull/75). https://github.com/crossbeam-rs/crossbeam-utils/pull/36 for example deals with lifetime issues. I didn't dig deeper, but that could result in a use-after-free bug, which can be exploitable. Could you [file advisories](https://github.com/RustSec/advisory-db#rustsec-advisory-database) for the other memory safety issues so that people could check if they have a version with known soundness holes somewhere in their dependency chain with [cargo-audit](https://github.com/RustSec/cargo-audit)?
It does compile without the T argument to println, and works as expected. The purpose of this function is to provide a shortcut: get input as a string, and ensure that string can be parsed as some type (T) before moving on.
Two things: 1. Not sure where you got `stdout().flush()` from - there is no such API in the standard library. 2. You can't just print a type, you want to print the type's _name_. There is currently no stable way to get it, but you can use the unstable `std::intrinsics::type_name` intrinsic.
&gt;can be parsed as some type (T) before moving on. what do you mean by that?
That's pretty neat. Still trying to get into rust. Maybe a gamejam is the way to do it. &gt; + Added help screen, and stuff 2 days ago Just had to share this. Still better than my &gt; Fixed stuff :D
Most believe that it’s defensive. The point is not to enforce it, the point is that now nobody can really sue Apple for these things.
As for the first thing, using `std::io::Write` allows me to flush after using the `print!` macro. Not really sure why, I found it online when trying to find how to get that functionality of prompting for input on the same line as the input. Thank you for letting me know about the `type_name` thing. Are there plans to be able to print such a thing in a stable way, or should I instead rely on a second parameter with a friendly name for that type?
As for the first thing, using `std::io::Write` allows me to flush after using the `print!` macro. Not really sure why, I found it online when trying to find how to get that functionality of prompting for input on the same line as the input. Thank you for letting me know about the `type_name` thing. Are there plans to be able to print such a thing in a stable way, or should I instead rely on a second parameter with a friendly name for that type?
The intrinsics themselves are unlikely to be stabilized any time soon, or at all really. There might be a different way to do it in the future, or you can use [this crate](https://docs.rs/typename/0.1.0/typename/).
I'm taking some arbitrary input from the user as a string, and they can enter anything. I just make sure that their string is a valid representation of whatever type I want by attempting to parse it as that type, and trapping them at that prompt until they do. For example, I want the user to put in some `i32`, and only an `i32` is acceptable. If I then invoke this function: `let val: i32 = get_typed_input::&lt;i32&gt;("Enter a number: ");` the function will print "Enter a number: ", and repeat it if the user enters something like "k", only yielding a value when they write something like "42". That way I guarantee that the user input was valid. Enter a number: k Hey, that wasn't the right type! (Expected: [type name goes here]) Enter a number: xyz Hey, that wasn't the right type! (Expected: [type name goes here]) Enter a number: 42 
Thank you! That crate looks like exactly what I want.
By the way, Ticki has experimented with a GC based on hazard pointers and has a mostly working implementation. You can check out a very good writeup on how it works here: http://ticki.github.io/blog/fearless-concurrency-with-hazard-pointers/
&gt; It would also be nice to see what the overhead is of pushing into the Injector I ended up doing some basic testing using [this benchmark](https://gitlab.com/snippets/1806530). This produces the following output: playground $ rustup run nightly cargo bench Compiling playground v0.1.0 (/home/yorickpeterse/Projects/rust/playground) Finished release [optimized] target(s) in 1.10s Running target/release/deps/playground-bf16eaf49df753cc running 4 tests test tests::bench_crossbeam_channel ... bench: 28 ns/iter (+/- 4) test tests::bench_crossbeam_injector ... bench: 78 ns/iter (+/- 89) test tests::bench_crossbeam_worker ... bench: 78 ns/iter (+/- 66) test tests::bench_parking_lot ... bench: 368 ns/iter (+/- 155) test result: ok. 0 passed; 0 failed; 0 ignored; 4 measured; 0 filtered out While the exact timings are a bit inconsistent between runs, the `Injector` type appears to perform very well when compared to the alternatives.
Note that in the case of Patent Trolls, the issue is not whether the patent is affordable, but whether whoever they sue can actually afford the lawsuit. If you are an indie developer, a start-up, or even a small company, your pockets are just not deep enough to afford a protracted lawsuit. And therefore it's cheaper, in the short term, to settle and pay them some fee. Hopefully Apple will not attempt to use this patent in such a way, because they certainly have deep pockets.
So you would have to allocate to deallocate things?
Yes, no allocations in the audio processing loop was the rule I remember when working on something like this on ancient hardware, due to it being time-critical. New buffers for graph changes could be allocated in another thread. However I guess you may be attempting something a lot more dynamic or with a different model. Anyway talking in more general terms, it would be good to have a comparison of the three crossbeam MPMC implementations at least. Looking at it recently, I read the docs of all of them, skimmed over the implementations of each and couldn't really judge which was best for what I needed. I found some soundness criticism of MsQueue's original algorithm on the 'net, and SeqQueue seemed related, so I went for `channel` in the end; but really I'm guessing, not knowing this area very well. `std::collections` has a section "When Should You Use Which Collection?", so something similar could help a lot here.
It would be a mistake to assume that there is a uniform opinion among game devs.
I'm not sure I understand the question, but I'll try to really briefly sketch the concept. The reference counted container ends up being similar to `Rc` but has an additional link pointer. When it's sent across a channel, the link participates in the Treiber stack. When the reference count goes to zero, the link is used to add it to the deallocation queue (which is also basically a Treiber stack). So the idea is that these can be allocated in any thread other than the real-time thread, and dropped in any thread, and no allocations or deallocations will happen on the real-time thread. Obviously there will be some tricky implementation details, and validating that it is safe is not trivial (as is the case for *all* lock-free algorithms). But I think it will work, and will be useful in rigorously low-latency contexts.
Ohhh I see. Thanks!
I remember reading that the wild card doesn't necessarily download the newest version but the one that is used the most by other crates.
As /u/raphlinus pointed out down this chain, you can get away with allocations/frees on the audio thread. It just creates a non-zero probability that you make a blip. I've played around with both std::sync::mpsc and crossbeam channels on audio callbacks for sending/receiving across threads, and haven't had many issues. So don't freak out about it until it becomes a problem. Imo a very reasonable approach to this problem is to think carefully about the architecture of your system to minimize what the callback actually needs to do, and what needs to be synchronized in the callback. At the end of the day, the callback's job is to render audio, not deal with book keeping to prepare to render audio. One interesting thing that goes against a "one size fits all" approach is that the audio callback is probably going to consume data very irregularly (you can't predict when new parameters/events happen). But it is probably going to product data _very_ regularly. Similarly, the audio callback needs to respond to data it consumes as fast as possible, but it's likely that anything consuming data it produces can wait or lock. So when it comes to deciding on what abstraction to produce/consume data on the audio callback, its likely you shouldn't be using the same data structure for both. Unbounded, MPSC queues with lock/wait free popping are great for the consumer side, while bounded or even double-buffered FIFOs are fine for producing data off the audio callback. Just things to think about when picking a data structure for your inter-thread communication. 
I suppose this would be new to Rust, but are there other implementations of this kind of thing out there for education purposes (real time multi threading without allocation on the RT thread)? Having this particular project out in the open (not buried in synthesize) might be good for getting us more people to pitch in. That's why I like the idea of putting an issue on Crossbeam, but I don't think that would be effective since it's so specific as you mentioned above.
This depends on the requirements of the interface. You could e.g. build a shared library in Rust that you link into your C++ program. If you want a standalone process you could use e.g. protobuf or Cap'n Proto for communication, which gets you both high performance and well-defined interface.
What book would you recommend to learn more about what you just said? With parking and stuff.
I don't know if that's good rust code, but it should do what you want: trait TypeInfo { fn of(&amp;self) -&gt; &amp;'static str; } macro_rules! impl_type { ($t:ty) =&gt; { impl TypeInfo for $t { fn of(&amp;self) -&gt; &amp;'static str { stringify!($t) } } } } impl_type!(f32); impl_type!(u32); impl_type!(i32); impl_type!(String); macro_rules! ma { ($t:ty, $input:expr) =&gt; { match $input.parse::&lt;$t&gt;() { Ok(s) =&gt; { println!("{}", s.of()) }, Err(e) =&gt; { let et = stringify!($t.of()); println!("Wrong type {}. Expected: {}", e, et ) } } } } fn main() { ma!(u32, "Hello World".to_string()); ma!(u32, 42.to_string()); } 
Yay! This will be great for the admin/DevOps people who work with Windows. :) I've actually got a WMI parser (from scratch, no C libs) that I've used to understand WMI better that I hope to be able to open-source soon. As soon as I can make sure that there are no conflicts at work...
My first thought as well. It looks like very recent windows does support unix sockets, so it might work for OP: https://blogs.msdn.microsoft.com/commandline/2017/12/19/af_unix-comes-to-windows/ 
I'm not aware of an implementation of this particular concept, but to be honest I haven't studied the literature too carefully. I like to think of synthesize.rs as being "out in the open" but understand the desire for a separate crate :)
This is super cool! I've been having a rather stressful day and your post title made me smile. Thank you. You say you don't think your code is very good, are you interested in some constructive code review/advice from this subreddit? If you aren't, I'm happy to just congratulate you on doing the thing :)
I think this is generally true, but it's worth thinking about the risk of Apple turning evil. It happened with Sun, when Oracle bought them, and this did lasting damage to the open source language ecosystem.
The expression `return x` has bottom type, not the type of x.
A better solution would be to print the error message, rather than discarding it and expecting your user to guess based on rust type names.
I have yet to try switching to using failure instead of error chain
planning to release fluent-rs 0.5 and fluent-syntax 0.8 which will bring rust implementation of Fluent (localization framework) to the current syntax version, and bring zero-copy parsing, better docs, better perf and other goodies. :) If you want to skim through the code/docs before the release, look at https://github.com/projectfluent/fluent-rs - we're accepting issues/patches :)
C++ has C types in it, and duck typed templates, it's not as strongly typed as Rust
Oh totally; I’m not a fan of patents at all.
There's one obvious way it should work, where in C++ the literal 0 can be whatever type it wants, really
We had a crate with too much unsafe and we are able to fix most of it by grepping for `unsafe`. Try doing that in C++
It took me more than a year, but I started at 0.6 so it kept changing under my feet (something like 70 commits to my fizzbuzz repo since that time) Right now they removed so many paper cuts beginners can easily learn it
I just used Arc, and it was still very very fast. Faster than cloning
Just use neovim. :troll:
As suggested by others, you want `PhantomData&lt;T&gt;`. However, I would love Rust to move away from this to be an error. It has been so frustrating to me when I moved from Haskell years ago. Phantom typing is a feature that is weirdly supported in Rust right now. :)
I certainly hope this will be used defensively to kill off some patent trolls ...
What do you mean with "turning"? [https://www.theverge.com/2012/11/7/3614506/apple-patents-rectangle-with-rounded-corners](https://www.theverge.com/2012/11/7/3614506/apple-patents-rectangle-with-rounded-corners)
Great read! Rust has some fascinating libraries, that very clearly had some talented people taking their time to write something well. Slightly OT question: Are the well known rust libraries typically written by people during the course of employment? Perhaps at an educational institution? Or by hobbyists? The (quality of) development that happens within this community is a style that is quite alien to what I have seen in the commercial world.
# Rust built-ins Is there a list of language features that are built-in the compiler? I know there are some traits and primitives of course and maybe macros as well. But is there a guide on this somewhere?
Game jams are less than 48 hours long, so it's pretty understandable that you have hacks on hacks on hacks. If you wanted to work on the game further after the jam, the first thing pretty much any team would do is sit down and clean up the code for a while. At one point for this year's GGJ, my team couldn't connect to our SCM server, so we all just started taking turns doing our stuff on one computer until it was resolved, lol.
Oooh, I wasn't aware of that, thanks! We should probably align to 128 bytes on x86-64 then. From Intel's [Optimization Reference Manual](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf): &gt; Spatial Prefetcher: This prefetcher strives to complete every cache line fetched to the L2 cache with the pair line that completes it to a 128-byte aligned chunk
Considering Apple has [offensively used patents about phones being rectangles with round corners](https://en.wikipedia.org/wiki/Apple_Inc._v._Samsung_Electronics_Co.), this makes me pretty unhappy. Hopefully some group with lawyers (Mozilla, EFF?) will challenge this.
"Parking and stuff" sounds very general :) but we have a [wiki](https://github.com/crossbeam-rs/rfcs/wiki) with tons of learning resources. If you need more specific pointers, let me know and I can give some recommendations.
There seems to be talk of adding MIR optimizations to the rust compiler. Doing that could speed up debug builds quite a bit
This is misinformation based on a misunderstanding of how patents work. The scope of a patent is based on its claims; the abstract and description merely help explain the claims. Also, to infringe a claim of a patent, you have to match all of the details in that claim, not just some of them. I analyzed the claims of this particular patent in the original forum thread: https://forums.swift.org/t/apple-is-indeed-patenting-swift-features/19779/32 TL;DR: The patent mainly covers the Objective-C importer feature.
That doesn't make sense: the version above was ported from C, and doing a direct port without modifications will only make that even more true. Additionally, a comparison like that works just fine if the Rust is ported back to C, as in my second question you ignored.
Hi, We can do remote, however they need to be close to the same time zone as the team. In this case PST. 
Thanks for doing this benchmark! However, I'm afraid the results could be misleading: 1. In every `#[bench]` function, we should make sure spawned threads are stopped before returning from the function. You can replace `thread::spawn()` with `crossbeam::scope()` and problem solved. Otherwise, I'm worried spawned threads might carry over to another benchmark and thus slow it down. 2. In the channel benchmark, we receive using `receiver_clone.recv()`, which will block the current thread when the channel is empty. But in other benchmarks, we just keep looping if the queue is empty, thus burning CPU. So this is an apples to oranges comparison :) `channel::unbounded()`, `SegQueue`, and `Injector` should generally have similar performance characteristics because they are all powered by the same data structure. `Worker` has a completely different implementation, though, but it should still have the same ballpark performance. Finally, `Mutex&lt;VecDeque&lt;_&gt;&gt;` being slower than concurrent queues is to be expected - that part makes sense. 
Not a blog post, but there is a conference presentation that gives a good overview of what they're doing. https://www.youtube.com/watch?v=rp_Eild1aq8
Actually, scratch that. `*mut T` implements copy. `offset` one, then use `from_raw_parts_mut` both.
Quick question, just because I couldn't find it anywhere, but is there any method on `str` that resembles `slice::chunks`? I found [this RFC](https://github.com/rust-lang/rfcs/commit/566bb704942f68645d992cbaac36e4b7eb635f80) but I don't know how exactly to interpret it. I'm working with UTF-8 only, so I need the `str` type, but I don't need to have graphemes or anything. I'm simply looking for chunks of a certain size. If there isn't a specific method for this, would it be easier/faster to turn it into a slice and back? Any help is appreciated! Thanks!
Seems so. But these days the patent office often acts as a rubber stamp; the patent examiners are both tremendously overworked and often incapable of actually understanding the patent before them. It's left for the courts to deal with; a claim of infringement against someone for this patent would almost certainly be struck down due to existing prior art, assuming the defendant has the ability to afford the litigation.
Except the MAD concept is nonsense when applied to apple. They actively use their patents as a weapon to beat their competitors with.
I'm no patent lawyer, but it sounds like the patent is _far_ more specific than that. 
This sounds a lot like adapton. Do you know about it, and if so, how does salsa differ from it?
Replying to myself since an edit doesn't seem appropriate for this: I think it's worth remembering that this isn't just an action by "Apple", this is something done by programmers, Chris Latner et al. When you file for a patent you have to also file a [declaration under penalty of perjury that you invented the thing, the application is correct, and so on](https://globaldossier.uspto.gov/svc/doccontent/US/201414502697.A/1-3-US%20%20145026970BP1%20/3/PDF). All the listed inventors on [the patent](https://patents.google.com/patent/US9952841B2/en) had to sign that. 
You're right! I fiddled around a bit and I think I managed to resolve these issues. The results are now along the lines of the following: running 5 tests test tests::bench_crossbeam_channel ... bench: 34 ns/iter (+/- 2) test tests::bench_crossbeam_injector ... bench: 44 ns/iter (+/- 1) test tests::bench_crossbeam_worker ... bench: 78 ns/iter (+/- 36) test tests::bench_parking_lot ... bench: 1,275 ns/iter (+/- 420) test tests::bench_std_channel ... bench: 85 ns/iter (+/- 1) test result: ok. 0 passed; 0 failed; 0 ignored; 5 measured; 0 filtered out
Feeling really dumb right now. I need to check if an `i32` is even, and I'm trying to use the `is_even()` method implemented for `Integer`. I know I can just `if n % 2 == 0` but I'm really confused as to why the method isnt working. use std::num; use std::ops; fn main() { let n = 3; if n.is_even() { // do stuff } } the compile error I'm getting is: no method named `is_even` found for type `i32` in the current scope Thanks so much! &amp;#x200B;
This is maybe the most important thing you have to learn about rust. Ownership an borrowing. &amp;#x200B; Consider the following: &amp;#x200B; fn foo(word: &amp;str) -&gt; usize { word.len() } fn bar(word: String) -&gt; usize { word.len() } fn main() { let x = String::from("Hello"); let foo = abc(&amp;x); let bar = bar(x); } The fn foo takes a reference to a String, also called a slice, the fn bar takes String as argument. The main function declares and defines x, it's the owner of x. In both cases references are passed to the funtions foo and bar. The difference is, that when main invokes foo it borrows foo that reference, when bar is called main gives ownership to bar. The ownership moves to bar. When a function ends, all variables received as arguments or declared inside the function get destroyed. In this example &amp;str and String are destroyed. Since main keeps ownership of x, when it passes the reference &amp;str, after foo ends, x still exists, only the reference is destroyed. When bar is called, x moves ownership to bar. The main fn does not have "authority" anymore over x. When bar ends, all references to x are destroyed, and since there is no owner has gone too x is deleted too. &amp;#x200B; If you would try to println!("{}", x); after that in the main fn you would get an error message. because x have been moved to bar by doing "let bar = bar(x)". If you comment that line out, the println should work.
&gt; In any case, it would sure be nice if Rust someday gained Swift-level integrated C support `-C cross-lang-lto` allows you to inline C code into Rust (and vice-versa).
Oh god, I didn't realize the standards for mail were that messy.
From [Salsa's readme](https://github.com/salsa-rs/salsa/blob/d9098e30cf24c35ca6f57bc1dfd7a3b29b143447/README.md#credits): &gt; This system is heavily inspired by adapton, glimmer, and rustc's query system. So credit goes to Eduard-Mihai Burtescu, Matthew Hammer, Yehuda Katz, and Michael Woerister.
The thing about US Patents is they don't have to be enforced. You can have one, no matter how illegal, and do whatever you want with it. Nobody challenges patents. For example, thats the reason why there was an illegal patent on minigames, in loading screens, for decades, that prevented people from having them, despite decades of prior art and the patent being wholly illegal and "unenforceable". Sims 2, notably, IIRC, paid for permission to use it, though i can't currently find a source for that. https://www.eff.org/deeplinks/2015/12/loading-screen-game-patent-finally-expires http://www.gamasutra.com/blogs/DavidHoppe/20150109/233806/2015_The_Year_We_Get_Loading_Screen_MiniGames_Back.php The mere existence of the patent is enough to cause trouble for a lot of people, and who has the money and lawyers to fight apple in court? Not that theyd easily let it come to that.
Glad to see how it helps to write independent ide tools: rust-analyzer. Everyone who didn't try it, give it a chance now. It already has a lot of features.
The standard library does not have an is_even trait for integers. The num_integer crate does, if you are using that crate you need to bring the Integer trait into scope with `use num_integer::Integer`.
And of course, notably, this is bad news for anyone who *isn't* a large company with a warchest of illegal patents and an army of lawyers, who can just be threatened into paying whether it's enforceable or not. Lawsuits are expensive.
Lock free chests can be so difficult to synchronize though
IMO, no. You should be able to get access to any private method via some public method--if you can't, you have dead code.
Would it be reasonable to use gfx-rs + Metal for a 2D gui library? Can Metal reasonably work in 2D the way OpenGL can? Or maybe even better?
For certain use cases, the imgui library is *really* nice. I wrote [a gfx-hal backend](https://git.chronicembetterment.org/benjamin/imgui-gfx-hal/) for it. I won't promise it's high quality or robust though, because it definitely isn't.
I think this is a problem in criterion, ultimately.
The situation where this comes up is where you have public *read* access to a value, but can't (conveniently) write the value with public methods. In the playground example, the `name` field is set by a database query and there's no public API for setting it manually. So the `#[cfg(test)]` is there to let the test code *write* to a field that it could normally only read. (Totally open to the idea that this is bad practice, but I don't think it creates dead code.) 
`return x` has the top type, written `()` in Rust. The bottom type is `!`.
If you put tests in the same module as the code they are testing (or in a submodule of it) then they can access its private fields and functions directly.
From what I gather, one of the main differences is that salsa doesn't do as fine-grained incrementalism as Adapton, which inserts unique labels in the source code to assist figuring out what to update. But as /u/killercup notes, it did inspire some of the ideas in Salsa.
Yeah, and I noted that in the OP. However, I've frequently come across a situation where I have a struct in one module and then pass that struct as a parameter to a function in another module. If I then want to run tests based on the values of the struct in that second module, I'm stuck with struct's public API. Maybe the problem is with my code organization? Should I be defining that sort of struct in a high-level module such that it's being used in sub-modules that could directly access the private fields? But then the privacy rules would provide much less protection altogether, right 
Thanks man I appreciate your wisdom!
Since the nineties, Windows NT had an IPC mechanism similar to sockets. It's named "named pipes". Named pipes could be created only by Windows NT but could be read or written also by Windows 95. Though, it is a low-level mechanism, in which you can read or write only streams of bytes. I suggest some RPC implementation.
Two options: A) The test writes to the database, then checks the read value after doing so. It's a terrible idea because it ties your test to your database and also involves an external service. B) Mock the database in your test. Then, you can provide any value you want, same as A, but without the ties to the external service. There's no reason a read-only field needs to break the access control model.
If you're looking at ZeroMQ, another alternative is [Nanomsg][1] ([Rust crate here][2]) or its successor [NNG][3] ([Nng-rs][4] or [Runng][5]). It is in the same domain as ZeroMQ but I personally find it both lighter and easier to use. You don't have to worry about presenting any IP access if you use the [IPC transport][6], which uses Unix Domain Sockets or Windows Named Pipes depending on the OS. [1]: https://github.com/nanomsg/nanomsg [2]: https://crates.io/crates/nanomsg [3]: https://github.com/nanomsg/nng [4]: https://crates.io/crates/nng [5]: https://crates.io/crates/runng [6]: https://nanomsg.github.io/nng/man/tip/nng_ipc.7
Thanks. Agreed that A) is a terrible idea for exactly the reasons you said. I should *probably* go with B) (mock the DB) but the mocking story in Rust seems a bit immature at the moment—there are several different crates, and the ones that seem ergonomic to use mostly rely on nightly, which I'd like to avoid. I guess I was wondering if `#[cfg(test)]` could provide an easier alternative to mocking—in a way, it basically **is** mocking, in that it's putting in mock data in a way that's protected from use in production code. But it doesn't have the nice features (or complex setup) of a real mock. You're probably right that a real mock is the best way to go, though. ¯\_(ツ)_/¯ 
We should join efforts or even get a fundraiser started. I need email parsing, too. And also iCalendar and vcard handling - there are some crates, one I even contribute to, but these things are really rough around the edges.
Regardless of any of this, having a test is _always_ better than not having a test. A bad test can be fixed, no test has to be written from scratch, which means the existing logic has to be understood, which may or may not be easier. Don't let the perfect be the enemy of the good.
You are probably looking for /r/playrust, glgl
By definition every patent is legal, an illegal patent is impossible.
Plus there is the defense against patent trolls. If Apple does not grab this patent a patent troll might, and sue them. There is a chance Apple has this patent to save itself, and in turn everyone else against patent trolls 
Abolish patents. They totally disempower individual inventors (who almost certainly cannot afford to take out a patent without getting into *mountains* of debt) and stifle competition.
I'm hoping for about 1 order of magnitude from things like replacing LLVM with something else, and just general optimisations. Combined with significant improvements to the incremental compilation system so that it is end-to-end incremental, I feel like this could put Rust in a place of having a "fast" compiler rather than a "slow" one (all a bit subjective, but oh well). I don't suppose it will ever quite catch up with Go or D, but if it can get close then I think that would be a huge win.
The wiki is great, thank you.
Ok, one last question. I found this paper. I bet you're already aware of it. https://laurikari.net/ville/spire2000-tnfa.pdf It introduces the concept of a tagged NFA and how to translate it to a tagged DFA. I think I understand it. My only question is why you said that a smarter way to do start-of-match handling that doesn't require the backwards scan isn't possible in general. What's preventing this method from being possible in general?
You may write an RFC for it? 
Probably "illegal" here is intended to mean "likely invalid if challenged in court by a reasonably strong legal team"? 
&gt; In the first example is &amp;st serving as a reference to st and then getting the length of st? Nope. Method call syntax binds tighter, so you’re calling “.len()” and then making a reference to the result.
i believe you meant `foo()` not `abc()` 
For fun, I started porting Rust's std to Minix. I got to the point where "[hello world](https://oc.ian.ee/s/KSKDod6D23eZrFL)" works (cross compiled from Linux). Of course, I can offer no promises that I'll actually complete this. (I have a feeling running rustc itself on Minix would be problematic since Minix only supports user threads. But maybe I'm wrong, and that isn't as much of a limitation as I am imagining.)
&gt; So, is it me or has Appl really been granted a patent on seemingly every modern programming language? No. Patents are legalese. You have to read them as they're intended. See /u/comex's [explanation](https://www.reddit.com/r/rust/comments/al2xoy/apple_patents_a_programming_language_with/efarihf/).
I meant in a pure DFA. A tagged DFA is actually a transducer. Their performance profile isn't clear; in particular, they can use a lot of memory. Tagged DFAs are something I hope to experiment with some dat, but I don't generally see them as a solution to this problem. They are more likely a solution for doing capturing faster (maybe). Also, the more recent paper from 2017 on re2c.org about tagged DFAs is probably the one you want to read.
Sorry, I hope that wasn't rude, I'm just excited about the thought of garnering more community support for audio stuff. 
Not sure if there's a definitive guide, but [this post](https://manishearth.github.io/blog/2017/01/10/rust-tidbits-box-is-special/) goes over the fact that `Box` is unexpectedly magical. The next post about [lang items](https://manishearth.github.io/blog/2017/01/11/rust-tidbits-what-is-a-lang-item/) is informative too.
No problem. More visibility is a good thing, and if other people are interested in using these data structures, they really should be in a focused crate.
The performance penalty of the locks are at times frustrating, but the safety they guarantee make it worth it in the long run
Heres my favorite game jam that I’ve ever written: https://github.com/steveklabnik/ludum/blob/master/src/game.rs#L103 Error handling? Who needs it!
&gt;st This is a great explanation! Thanks for your help.
Do you have a link to the memo project? I failed to google it.
I think it's reasonable to call a patent gained through illegal means (perjury) illegal.
That makes some sense. So basically by casting a `&amp;mut T` into a `*mut T` I "destroy" the mutable reference so the compiler acts as if the mutable borrow has ended?
`Box&lt;Error&gt;` is handy when you want to return any number of different error types. fn my_method_that_might_not_do_the_thing() -&gt; Result&lt;TheThing, Box&lt;Error&gt;&gt; { let result = call_some_library() .map_err(|e| format!("calling some_library: {}", e).into())?; // Add context to error. let other_result = call_another_library() .map_err(|e| format!("calling another_library: {}", e).into())?; let third_result = foo()?; // or don't bother adding context. Ok(TheThing {}) } 
[Its part of the xray repo](https://github.com/atom/xray/tree/master/memo_core)
I suspect that this change should be benchmarked in a real world application - nothing carries a data dependency on the second cache line and there's not even a load instruction that will be sitting in the reorder buffer to cause any stalls. &amp;#x200B; The intel docs also don't say anything about reads-for-ownership triggering a read-for-ownership on the second cache line, although they do mention that it's possible for a read-for-ownership to trigger the spatial prefetcher. If the prefetches aren't read-for-ownership prefetches, then they won't pull the lines out of other cores. This would be pretty easy to test on a few machines, although I would rather intel be more clear about what is fetched. &amp;#x200B; This would generate spurious cache traffic, but I don't believe that many applications are bounded by coherency traffic as opposed to say cache space. In application I've benchmarked, 64 bytes is sufficient separation to prevent the problems of false sharing.
Yes. Any 3D drawing API can work in 2D the way OpenGL does. Usually with less boilerplate.
lmao. You are looking for /r/playrust/
I haven't had a chance to actually try it yet, but if you read the redox book there are a bunch of interesting differences compared to unix. Check it out: https://doc.redox-os.org/book/
Would something like `recognize!` work? This is what I was able to come up with: ``` named!(parze&lt;&amp;[u8], &amp;str&gt;, do_parse!( recognize!(take_while1!(is_alphabetic)) &gt;&gt; kw: map_res!(take_while1!(is_alphanumeric), str::from_utf8) &gt;&gt; ( kw ) ) ); fn main() { println!("{:?}", parze(b"KW1 KW2")); println!("{:?}", parze(b"1KW 2KW")); } ```
It isn't yet at a point where you can use it full time. It is similar to UNIX, though it has a schemes concept and is a microkernel. There's a new release to happen soon, but it's held back by a severe bug in smoltcp. Once networking is fixed, you can try it out.
Sometimes you can implement a lock-free chest and enjoy the best of both worlds. 
Haha you Rust game people really are a special bunch! :-)
While trying to understand this, the most important thing I learned is that I know nothing about programming.
Arbitrary slices of utf8 is not valid utf8: slices aren't always valid encodings of `char` sequences. That's entirely separate from grapheme clusters which cause arbitrary subsequences of `char`s no longer to encode the right sequence of graphemes. So you need to decide what you want to do about char boundaries within the `str`. If they don't need to be respected - and the only way that's true is if you always put the chunks back together just the way you found them, before using them as utf8 again - then there are functions on `&amp;str` and `&amp;[u8]` which convert between them for free. If you do need to respect char boundaries - which is the only way you can treat your chunks as `str` on their own - then you'll have to do something more complicated. Luckily utf8 is self synchronizing so you can start at the approximate byte index you'd like to slice at and work backward or forward to find a char boundary, which is an O(1) check provided by `std` - something like "is_char_boundary" or so, I forget.
Yea and i wonder what the author of this library does for a job, he seems so far above me in terms of technical knowledge.
That doesn't seem to be a very good idea, because &amp;mut, a reference doesn't dictate the lifetime of the object. So the object reffered to could be freed while a reference still exists. If the AtomicRefcell takes ownership the it is not different from a spinlock or a mutex.
haha thanks
Interesting. I have a project where I build optimized storage for maps/sets which uses match:ing. I compare my benchmarks to using arrays: https://github.com/udoprog/fixed-map For most of cases I've managed to get the code to generate identical assembly. One exception is iteration which fails to peek through an unsafe iterator. I have some ideas for this though.
On top of what /u/JackOhBlades said, take a look at the failure crate.
Thanks. &amp;#x200B; I managed to call the function as below [https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=2b3461c86b53d747187f23d1b7d68af0](https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=2b3461c86b53d747187f23d1b7d68af0) &amp;#x200B; &amp;#x200B; &amp;#x200B;
So with `'static` lifetime this would be possible? 
I have written a math parser in nom some year back, so I'm unsure if the library changed. [In case you need some inspiration](https://github.com/Folling/exprust). They also have a list of example parsers, though most of them are unnecessarily complicated: [https://github.com/Geal/nom/issues/14](https://github.com/Geal/nom/issues/14) I should note, I'm a terrible rust dev, so it 'd only be useful to have a better understanding of the library as the documentation is truly awful. As for your problem, it's been ages, but I think the following should work: `preceeded!(space, take_until(" "))` Don't have rust setup on my machine atm, but let me know if it worked. You might also want to use named parsers, in order to nest them.
I'm working with word wrapping but I don't care (at the moment) about words getting chopped up all that much. Unfortunately, not all languages would make much sense if I butcher up words like that, so I'll probably deal with that at some point by implementing a proper word wrapping algorithm, but for now I don't really need to respect char boundaries (if I interpreted your response correctly) I didn't know that I could convert between `&amp;str` and `&amp;[u8]` for free so I might try that. I was using byte slices instead of strings before I decided to try to ensure UTF-8 validity, so I might just do this. It might not affect anything anyways because I'm taking a `String`, splitting it into chunks and wrapping them, then turning it back into a `String`. Your answer was very helpful! Thank you!
I care
Aw thanks
Try /r/playrust, this is for the programming language by the same name 
No, `()` is unit, not top, and `return x` always has bottom type.
Lockless boxes though are of supreme interest to the kingkiller project 
I loaded up 0.3.5 in a VM yesterday. It was difficult to use (performance reasons), and there is not much you can do with it. None the less, it's a pretty fascinating project.
Char boundaries doesn't have to do with words. In UTF-8, some characters are represented by more than one byte. Splitting those bytes apart (because they happened to lie on a chunk boundary) results in invalid UTF-8. Not only does this mean that the chunks can't individually be interpreted as strings (i.e., sequences of characters) at all, it also means that in rust it's not permitted for these chunks to be behind a `&amp;str` pointer. For example (and I'm going to pick one from my very limited knowledge of languages that require non-ascii characters; here, Koine Greek), the 5-character string "λόγος" is encoded by the u8 sequence (written here in hex) `ce bb | cf 8c | ce b3 | ce bf | cf 82`. Each character happens to be encoded by two bytes (I've represented the boundaries as bars, but that's not part of the encoding), but greater or fewer are possible for other strings. If we split that at byte index 5, we get `ce bb cf 8c ce` and `b3 ce bf cf 82`. **Neither of these is a valid utf8-encoded string.** They can't be decoded into a sequence of `char` and they can't be the contents of a `str` in rust. We *can* split "λόγος" at byte index 4, for example; then we get "λό" and "γος". Of course this happens to split up a word, but rust and utf8 don't care about words. To present how this differs entirely from grapheme splitting, I'll take emojis as the popular substitute for graphemes: The string "👨🏽" is encoded as `f0 9f 91 a8 | f0 9f 8f bd`. This string is a single "grapheme", or rather, a single emoji, but it consists of *two* separate `char`s: `U+1F468: Man` and `U+1F3FD: FITZ-4`. This string ***can*** be split at byte index 4 as far as rust and utf8 are concerned: you will then have two **valid** utf-8 strings with one character each; the two strings are "👨" and "🏽". This string *cannot* be split at any byte index other than 4 (and of course 0 and 8, the beginning/end) for the same reasons that "λόγος" can't be split at odd indexes: that would split up a `char` and result in an invalid encoding. So, to sum up: when dealing with utf8 and Rust's `str` and `String` types, you **must** respect `char` boundaries; you need not respect grapheme (or emoji) or word boundaries.
`?` will automatically convert `String`s (along with any other `Error` implementers) into `Box&lt;Error&gt;`, so you don't need to call `into` constantly.
failure seems to be falling by the wayside; these days I just use [err-derive](https://crates.io/crates/err-derive) plus [err-ctx](https://crates.io/crates/err-ctx).
TIL. Thanks! :) 
It doens't work like that, AtomicPtr points to some allocated pointer, to read from it you need to ensure no thread will swap the pointer and drop what it points to (while another thread is using it). The only way to do that is with a GC. There are alternatives with a limited API, like FillOnceAtomicOption, or Atomic from `voluntary-servitude` or Atomic from crossbeam (which as far as I know uses a GC). What do you want to do with this AtomicRef?
Nice, great work.
Ah okay that makes sense. So would using `str::get` method solve this issue?
Thanks, makes sense. &amp;#x200B; &gt;What do you want to do with this AtomicRef? I have a hash map, where elements cannot be removed, but each element can contain an optional \`next\` value to an element with the same hash. Once, \`next\` is set, it won't be changed anymore. Currently, this is an \`AtomicPtr\`. &amp;#x200B; &amp;#x200B;
Kind of. What are you going to do when you get a `None`? If the answer is "crash" then you're writing a program in 2019 which can't handle most non-English languages.
I created FillOnceAtomicOption exactly for that in `voluntary_servitude`, check it out. I use it in VoluntaryServitude for that.
Dang. You're completely right. I guess I'll need to work on actual word wrapping. For now I'm just going to convert to bytes and back because it's easier, but I will soon fix this. Thank you so much for all your help. I couldn't live without members of the Rust community like you. Thank you
Thanks for pointing that out, it looks a lot like what I need: I'm using a fixed capacity vector for memory, not a `Box`. So I can't use it directly, but I'll take a look at the implementation!
I can extend the API to accept raw pointers, but it kinda loses the purpose of a safe wrapper. Why do you want to avoid using AtomicPtr if you are handling raw pointers? With NonNull it's prettg straight forward.
Maybe the mechanism is new, but this smells like a nontechie rubber stamped preexisting things
It was always safe to dereference the pointer, so I basically treated it as a reference. Then I wondered why there was no `AtomicRef`, so it was more of a thought experiment.
I wish I could show the complete code for some of our complex in-house GTK Rust applications. Organization is key, as well as keeping GTK UI construction, GTK logic, GTK application state, and application logic separate. I typically start with a: struct App { widgets: Rc&lt;GtkWidgets&gt;, state: Arc&lt;State&gt; } Then have a `views`, `widgets`, and `signals` module. Construct each UI view per module in the `views` module, each individual widget in the `widgets` module, and program widgets in the `signals` module. Each signal can clone a reference to the entire UI structure and application state if they need it. It's a great idea to have a primary event loop that listens for UI events from a channel to a background thread. Widgets can program their signals to transmit events through a channel to that background thread, then immediately return. UI freezes are then no longer a thing. Wayland compatibility means the main thread cannot be root. You can achieve this if you spawn the application as root, spawn a background thread for handling privileged tasks, and use some kernel syscalls to downgrade the main thread back to the user before initializing GTK.
Well thanks! I appreciate the advice my man &amp;#x200B;
If you're interested in making a utility iterater to do this kind of chunking at correct char boundaries in the future, it should be totally doable with [char_indices](https://doc.rust-lang.org/std/primitive.str.html#method.char_indices) to get the indices and just using `string[last_index.. this_index]` to get the slices. Something like use std::iter; fn str_chunks(s: &amp;str, chunk_size: usize) -&gt; impl Iterator&lt;Item=&amp;str&gt; { let mut last_idx = 0; s.char_indices() .step_by(chunk_size) .map(Some) // hack to get last slice .chain(iter::once(None)) .filter_map(|next_idx| { match next_idx { Some(next_idx) =&gt; { let slice = &amp;s[last_idx..next_idx]; last_idx = next_idx; Some(slice) } None =&gt; { // grab last nonconforming slice if last_idx != s.len() { Some(&amp;s[last_idx..]) } else { None } } }) } Haven't tested it since I'm on a phone so it probably has a few syntax errors, but the idea should be able to get you a very chunks-like method which acts on chars correctly.
Is https://blog.burntsushi.net/rust-error-handling/ still up to date with best practices (or at least the underlying concepts - if not the usage of newer crates) ? I found it a very good read -but there is a lot to take in. I don't see it referenced as often as i think it should be :)
Whoa that's impressive. And you were on mobile. Wow. I will look into that. Thank you so much
Is [https://crates.io/crates/custom\_error](https://crates.io/crates/custom_error) still the new hotness? It does seem awfully easy to use, but not sure if it's gaining any long-term traction.
Check out the latest crossbeam post that happened to be posted very recently. They want to do atomic ref this year https://stjepang.github.io/2019/01/29/lock-free-rust-crossbeam-in-2019.html#where-to-next
If there's any particular reason I think it would just be that no one's made a successful proposal to give them names. Deciding what the name of a function's type should be isn't a trivial problem, and there are some reasons (confusion, possibly breaking compatibility with code using functions and types with the same name) why the answer isn't just "the type is the function's name". In the long-term, though, this should be solved by the same things which address unnameable closures: `impl Trait` for use in functions and existential types for giving them a permanent name. Right now returning a zero-sized function is totally possible with `impl Fn()`, but we don't have the existential type support which would allow making function types fully nameable.
So many of the highlighted PRs are diagnostic related. Each and every one makes me smile.
I think Haskell and Kotlin code can predate Swift’s use of option chaining.
Given that you had to sign an IP agreement for your employer that assigns to them all your inventions, are you legally able to refuse to sign a patent application for those inventions?
I'm wondering if Redox will one day be able to run Linux applications. The only info I could find in a hurry was: &gt;**Will Redox replace Linux?** &gt; &gt;No.
See [this link](https://github.com/rbalicki2/smithy/blob/master/crates/smd_macro/src/parsers/core.rs) for a few parsers that I wrote for a jsx-like macro. Perhaps that will be of help!
Is the lesser granularity a result of `drop` being bound to a lexical scope that can't be broken down into a smaller compilation unit?
I agree. I'm not huge on economics/business and stuff, but the concept of patents, while it can sound okay at first, just seems very exploitable the more you look into it.
Oh.. Is this not the rust (game) sub reddit? :(
Legally, sure. (Practicality may vary.) Contracts can assign your inventions to the employer, but it can't force you to commit perjury, in this case, claiming what you know to be non-inventive as inventive.
Choices like ZMQ vs protobuf vs whatever else are at a different layer than TCP vs Named Pipes. Even if you decide to use ZMQ, you still have to decide on how to transport your ZMQ messages from process to process (using, for example TCP). TCP is an easy choice most of the time. It’s fairly simple, well supported, mostly cross-platform, and handles scaling to multiple machines fairly transparently is that ever happens. I am not aware of any known security exploits related to local TCP, and the exposed attack vector is not substantially different from other forms of IPC. If you must run on an untrusted platform, or in the presence of untrusted other software, then you will need to do application level validation of the incoming requests and/or encryption, as appropriate. This is true regardless of what IPC mechanism you use. 
This is the subreddit for the Rust programming language.
You're looking for /r/playrust
Swift's C support is more at the semantic level: the compiler incorporated clang itself, and so can load headers/modules directly, and even has a pile of heuristics to rename functions to be more "Swifty".
This is awesome. Will try recursive Fibonacci with it :P
Is there a good open-source example of a 2D adventure game written in rust? Something like the Legend of Zelda? I'm just starting out and it would help to see how things like sprites are used.
Thankfully, software patents aren't a thing in the EU yet and hopefully never will be.
I've found the \[LALRPOP\]([https://crates.io/crates/lalrpop](https://crates.io/crates/lalrpop)) parser generator to be an excellent tool for building parsers in Rust. The only real pain point I've encountered with LALRPOP is that if you want to treat comments as whitespace (which will be the case for any nontrivial parser) you will need to write a custom lexer to produce a token sequence which you then feed into LALRPOP's parser. If you like regular expressions, you can use the \[Regex\]([https://crates.io/crates/regex](https://crates.io/crates/regex)) crate to implement your lexer, although I usually find regular expressions to be \[more trouble than they're worth\]([https://xkcd.com/1171/](https://xkcd.com/1171/)).
Yep! I have seen 10-20x slowdown in debug before. That was over a year ago, but I have some software I work on that requires realtime operation and debug builds kill the performance several times over. A Python script can definitely beat Rust debug builds, though probably not consistently.
Not exactly. Working in a large corp, I had a clause saying I'll help protect the IP and help to get new patents. When I got an application to sign, I responded with a list of prior art. The application went through anyway without my signature, even though I'm listed as an inventor. So yes, sometimes it's corp / legal team, even if you see the names of developers :-(
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Accidentally did a game in rust](https://www.reddit.com/r/rust_gamedev/comments/al9zpc/accidentally_did_a_game_in_rust/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Can I have more details on that please , it's looking intresting topic
Sorry, I'm just an idiot. I saw the token_kid function but just didn't put it together that it could be used before `validate`. Thanks again.
You probably want to use the new syntax for trait objects, `dyn Error`.
Very cool. I run into this issue on occasion, and it's always annoying. Thanks for making this.
My parser is a bit more general than just alphanumeric. Things like operators are grouped with the other keywords, so just matching for alphanumeric characters isn't gonna cut it. But thanks!
I'm using nom as a custom lexer anyway, the whole point here is to transform it all into a stream of tokens and then let the rest of the system take over. The issue is just that writing something that generates tokens seems to be rather nontrivial. And with regular expressions, I usually use regex101 to check if my expressions are valid before I commit them to use
I didn't make this, but I found it on Crates.io today after wishing that rustc would just "do the right thing" when I want to return multiple types from an `impl Trait` function. The docs explain it all, but basically you annotate your function with a special proc macro attribute, and you can magically return multiple types that implement the same trait by having the macro generate a hidden enum for each possible branch in the function with a unique return type.
Like an integrated bindgen?
https://github.com/rust-lang/rust/pull/50000 https://github.com/rust-lang/rust/pull/52019 https://github.com/rust-lang/rust/pull/53031 etc.
if needed, there are parsers that can use regexps: https://docs.rs/nom/4.2.0/nom/macro.re_capture.html If I understand correctly, only the first char should not be a digit? Then something like this should be enough: `recognize!(tuple!(none_of!("0123456789"), alphanumeric))` This will match one char that is not a digit (although I'd recommend using `one_of` with exactly the characters you'd accept, because `none_of` might be too broad here) then a list of alphanumeric characters. `recognize!` will return the consumed input if its child parser was successful.
I always include diagnostic related PRs in the list, even if it's just small span corrections. Glad to read they make you smile, too.
I can't seem to get `re_capture` to work, it says the macro isn't recognised.
you have to activate the `regexp` and `regexp_macros` features for nom in your `Cargo.toml`
[The Rust Reference](https://doc.rust-lang.org/reference/) has some information. Check out the chapter [Special types and traits](https://doc.rust-lang.org/reference/special-types-and-traits.html).
a little help, please? 
Yeah, you're right on both accounts, my bad. The intuition for `return x` being `!` is that control flow is interrupted and there is nothing you can do with your value of type `!`. 
Can you file an issue about this?
I was planning to create a mail forwarder in Rust for my domain, but I don't imagine that it needs that complicated of a parser since the brunt of the work will be done by another server. However, I'll be interested in this domain, so perhaps I can contribute too. Whoever gets there first, announce here and we can check it out.
Oh I totally agree that there's no such library right now. However, if someone is a beginner I definitely wouldn't recommend OpenGL either. I was specifically answering the "learn Vulkan over OpenGL" point; people who are being told to learn Vulkan instead of OpenGL are the ones that are interested in low-level things.
Wow, this is really neat. I always love these nice solutions that leverage existing language features.
It sounds a bit like the D/C++ interoperability, though. Does D have "a type representing the absence of a value"? Because if so, D is prior art for almost everything in this patent; it is a language containing both object-oriented and procedural parts, it can interoperate in the described way with C++, a C-based object-oriented language, it even has some of features for the restricted additional claims: bounds checking, using LLVM - no overflow checking though.
Nice to have a more general solution to this. Normally I manually use something like [this][1], but this would be much more clear. [1]: https://docs.rs/futures/0.2/futures/future/enum.Either.html
If you close stdout and then open a file (with write access), the output from all printfs will now go to that file. File descriptors are reused because they are a limited resource.
Ugh. I totally believe this does happen, but theoretically this makes the patent invalid.
How it's different from?: * https://crates.io/crates/coalesce * https://github.com/Nemo157/impl_sum
Thanks for the explanation. Reading legalese makes my head hurt.
Very often when my code does not compile, \`rustc\` suggest to me what i've guessed anyway. But i remember my first attempts at writing Rust code some years ago ... those compilation errors would have been a major road block to me. I'd have to search the internets, but today the help is right there. estebank and the others are my heroes.
`Nullable` from `std.typecons` perhaps?
https://doc.redox-os.org/book/introduction/what_is_redox.html &gt;We want to be able to use it, without obstructions, as a alternative to Linux on our computers. It should be able to run most Linux programs with only minimal modifications. I interpret that to mean it will have a large degree of source code compatibility.
Are there any plans to add lock-free garbage collection / memory reclamation to crossbeam?
SDL2 maybe. I'm working on bindings to [https://github.com/etorth/libnvc](https://github.com/etorth/libnvc) for an neovim KMS Frontend. Unfortunately most of it still just in my head and theory. At the moment I'm at the "Yes I can run SDL2 on KMS with my device without performance penalty" stage. The next step would be to test if I have to modify rust-sdl2 so I can create a EGL / DRM Context but I don't think that important for you. I also didn't test libnvc yet. It is listed on neovim Wiki but looking at the repository I feel like it might need some patches to work completely.
Damn, that's neat especially if you tend, to handle errors the quick&amp;dirty way like op did
IMO, almost, yes. An update I've been meaning to add is to cover the new [`source`](https://doc.rust-lang.org/nightly/std/error/trait.Error.html#method.source) method on the `Error` trait in order to show how to inspect the causes of errors. And in particular, stop suggesting the use of `description` and `cause`. Otherwise, if there's a difference between my blog post and practice, then I'd say the difference is primarily in the use of helper crates to reduce boiler plate, or the use of things like `failure` to get backtraces. However, I don't think there is an ecosystem consensus yet on which to use unfortunately. Additionally, my understanding is that backtrace support should be making its way to `std` some day.
This is pretty counter balanced by object-oriented code being basically krytonite for performance, especially the ones with GC (countless C# unity 'commercial' games come to mind like 'Shadowrun returns' and others).
Is it necessarily a bad thing, i.e. couldn't those extra instructions be doing something useful?
tfw Apple monomorphizes Haskell types to generate new patents.
I second this. An email parser library in Rust would be a godsend for me. I am unsure if I can contribute in a meaningful way, though.
I feel like just defining a struct and using serde would actually have been faster than this.
As you say, that code should never run for an empty heap. You could even file a PR to fix it and see what feedback you get.
Is the code for your bachelors thesis open source? I'd be interested in seeing it. 
Oh, I thought you were talking about how earlier compilers produced a smaller binary. FWIW, those binaries still performed a redundant bounds check. I'll file an issue for it!
I can't find the conversation, but yes. IIRC the outcome was to wait and see how the ecosystem evolves, and watch the success or failure of third party crates, doing the same thing (I'm sure there are multiple crates offering this trait). The last thing we want is an ill-conceived set of traits like Java's collection interfaces. For example in Java, `Collections.emptySet()` returns an immutable, forever-empty set, which is essentially equivalent to a unit struct. Unfortunately there is no standard interface for immutable collections, so the empty set implements `Set` but throws an exception if you call `set.add()`. This is unfortunate, especially if you are a method that has received this object as a `Set`.
Niko must have some super-human time management skills.
Tip for troubleshooting questions: use https://play.rust-lang.org/ ---- You're probably looking for this syntax: match cur_char { Some(ch) if ch == certain_char =&gt; { I'd also recommend using the destructuring of the match statement to extract the value. There is no need to do `cur_char.unwrap()` after destructuring, you can simply use `ch`.
Thank you for the quick response, could you explain why it works with 'H' and not with a variable.
`sample_iter` is a method on the trait `rand::Rng`, so it must be in scope if you want to call it with method syntax. If the trait is not in scope, then the only way to call the method is with function syntax: extern crate rand; fn main() { rand::Rng::sample_iter(&amp;mut rand::thread_rng(), &amp;rand::distributions::Alphanumeric) .take(10) .collect::&lt;String&gt;(); } I'm not sure why you would want to do that though.
I don’t think there was a serde-toml crate yet.
dope
Yeah, but more than just listing out the definitions: it also converts functions using Objective-C conventions (like `(NSError **)` out-pointers for errors) into have an interface that uses Swift conventions (those errors become `throws` functions), with, I think, no runtime overhead.
Since `std::io::Result&lt;()&gt;` is too big, I don't think we can do that idiomatically in Rust.
If you don't need to modify the same place you can use my library \[region\_buffer\]([https://github.com/Aaronepower/region\_buffer](https://github.com/Aaronepower/region_buffer)) which allows you to have multiple mutable references as long as they don't overlap.
My bad, I should have replied to your post instead. On the other hand, you might be on to something. I don't think the binary heap implementation has changed, so it might still be worth looking into it. It seems to have an extra panic call from the `Hole` constructor, but I don't see why.
Well, one major difference from `impl_sum` is that it's published to crates.io. `impl_sum` was just an experiment to see whether something like this was possible with no intention of polishing it for release (I haven't looked into `auto_enums` to see whether it manages to workaround the downsides of `impl_sum` that made me decide it's not worth trying to get a production-ready version out).
I can point you to relevant explanations :) The language construct here is called pattern matching. It can also be considered destructuring assignment. (Destructuring, as in ripping apart a structure) Read about it in the book: https://doc.rust-lang.org/book/ch06-00-enums.html
You could also make a function and put the use statements and the code that uses them in there.
This is amazing. Is it for sale online? 
That's `crossbeam-epoch`, an epoch-based memory reclamation mechanism. Or did you mean something different?
Yes apologies. My understand is that epoch based reclaimers aren't lock-free. Unless you guys cracked it, admittedly I haven't read the source code. I was wondering if you guys had things like hazard pointers/eras in mind? 
You can't sign a contract agreeing to commit a crime. So of course. If they persist in attempting to get you to sign it after you've made it clear that it would be perjury to do so in any way other than attempting to convince you it's not perjury, not only would you still be committing to commit a crime to sign it, but they are committing a crime to attempt to get you to sign it (subjournation of perjury). At that point you *probably* want to a consult a lawyer in case they retaliate or something... What you can't do is then try and claim to have rights over it yourself, or anything like that. (Not a lawyer/Not legal advice/...)
Oh, it's 3 years old. Serde was definitely more problematic back then in any case. I also do have to admit that I have written quite a bit of code when I Just couldn't be bothered to define types, eg for API calls.
Hm, I'm not sure what you're trying to get at. (Note also that that is only a specific example of things that it does using Clang, there's more.) In any case, Swift was designed from the start with Obj-C compatibility in mind, by a company with a large library of Obj-C with heavy conventions, and it shows: it can use those conventions to do a pile of tricks (e.g. `throws` functions returning errors via an mostly `NSError*`-compatible out pointer, in a special register, is part of the ABI).
Interesting, this solves the problem. Thanks! For others reading this, see below link to the function syntax. [https://docs.rs/rand/0.5.0/rand/trait.Rng.html#method.sample\_iter](https://docs.rs/rand/0.5.0/rand/trait.Rng.html#method.sample_iter) 
&gt; Hm, I'm not sure what you're trying to get at. I mean that rust-bindgen could generate "idiomatic" Rust wrappers over C libraries that follow certain conventions. E.g. most C library functions that return an `int` mean it as an error code. Rust-bindgen could automatically generate wrappers that use an appropriate `Result` type instead of just `c_int` there. 
Actually, using a `get_unchecked` in that place seems to make the extra code (`read_drop_in_place`) go away, so you can fix both at once if you file a PR with that.
Thanks everyone for the suggestions and links.
That's cool. I want one (even though Im just new to the language, so same boat ;))
nice!! did your friend bought or was specially made ?
I want one!!
I hope you take being downvoted as a chance to learn. This feedback is not perfect, but i hope its valuable. Though its valuable that you posted the link, it might come across as putting others down for not knowibg what you know. In my experience,I find that when the tone of what you're sharing comes from a place of being excited about sharing your hobby, the response is often much better all round. Fyi, i didnt downvote you. 
They bought it at an online shop for custom made caps and just uploaded the logo
It was custom made
I'm afraid not yet, I am still working on that project (even though the thesis is finished). But I hope that it will be published one day. FYI, it's in the field of algorithmics, I worked on a graph partitioning algorithm.
You have an awesome friend! :-)
1. You have great friends. 2. You should let us know what service they used to make it :)
How do I decide if multithreading will improve performance (other than benchmarking)? pub fn sum_of_multiples_iterators(limit: u32, factors: &amp;[u32]) -&gt; u32 { (0..limit) .filter(|i| factors.iter().filter(|f| *f != &amp;0u32).any(|f| i % f == 0)) .sum::&lt;u32&gt;() } Exchanging the `(0..limit)` with `(0..limit).into_par_iter()` brings no better results in any of my testcases, but worsens quite a bit overall.
I've already checked out and read through a couple of chapters from the book. It still doesn't match the way other tutorials and examples use the pattern matching. Destructing isn't needed when option is u8 or other data types, why is it need here specially when a char type variable is put inside a Some statement.
Interesting, how did you figure that out? Unfortunately I haven't yet been able to build the Rust repository on my machine :/
Indeed, that happens when you got nerd friends with whom you only communicate via dumb jokes ... I'll let them know that random strangers on the internet liked their idea. They ordered it from [https://styleyourcap.net](https://styleyourcap.net), it's a german site, but they deliver worldwide. But I think there exist similar services outside of Germany :D
&gt; Also, if the `.filter(|f| *f != &amp;0u32)` thing can be improved, please let me know! If I am not mistaken, it can be rewritten to `.filter(|&amp;&amp;f| f != 0)` Regarding performance, `filter` might be the cause as it does not return an `IndexedParallelIterator` which allows random access order and might be easier to parallelize by rayon. And you are using `filter` relatively often (1 + k times). Just a guess though.
I thought maybe process fd 0-2 are reserved for redirection using `dup2`. 
When you use a variable the match statement does a destructing assignment to that variable, shadowing the variable from the outer scope. To get around this, you assign to a new variable and compare them. The reason ‘H’ works is because literals cause a direct match, since there is no way to assign to a literal. Hope that helps!
I copied the `BinaryHeap` code and hacked away at it until it compiled. Using `get_unchecked` in `PeekMut` and the `Hole` constructor seems to eliminate the bounds checks.
Enabling decoding/parsing of emails and even third party libraries around a common definition of email was one of the main goals of the project. I know that Philipp(rustonaut) put a lot of effort into ensuring that the crates are modular and that individual libraries like [mail-headers](http://docs.rs/mail-headers) and [mail-core](https://docs.rs/mail-core/0.6.1/mail_core/struct.Mail.html) can be easily used in different projects. If so many of you are interested in a parser/decoder feel free to reach out to us and I'm sure we'll be able to give some guidance on how to best build a parser and integrate it with the other crates, as well as help on email in general!
Our EBR is lock-free (if we assume the allocator itself is lock-free, too). I believe most EBR implementations are. Yes, I've been experimenting with hazard pointers, but there's nothing concrete yet. The design space is very large here and there are many choices with different tradeoffs. After gaining some experience, we'll hopefully come up with a nice API for hazard pointer-based memory reclamation. 
Couldn't find exactly what you are looking for. Nonetheless, http://arewegameyet.com/#games offers a great compilation of games.
This is a useless semantic argument, it doesn't even make sense in the context being used. An illegal patent is not a patent and no one is claiming it is a patent anymore than someone is claiming a teddy bear is an actual bear. Your statement is like someone objecting to the existence of a teddy bear because by definition all bears are animals and a teddy bear is not an animal, it's an inanimate object. That doesn't mean that they don't exist and similarly it doesn't mean illegal patents don't exist. People get illegal patents for perpetual motion machines even to this day. All it means is that those illegal patents are not lawful and will not stand to a court challenge.
Thanks! Removing the filter (by removing all 0's from the factors beforehand) does improve the performance slightly. Obviously, it does so in both versions!
Do you know how silly having stickers on your hat are? Jeepers if this the generation we have made I’m fucking done. I wish you the best but holy shit. 
Honestly going to kill myself. 
If you could share the design I might order one :)
because of all the recent activities concerning SYCL based vendor independent GPGPU acceleration approaches, rust support for this kind of technique would be very desirable as well! see: https://github.com/intel/llvm/blob/sycl/sycl/doc/GetStartedWithSYCLCompiler.md https://www.youtube.com/watch?v=ZTq8wKnVUZ8 
Great tutorial! We use a very similar approach to deploying our code at CurrySoftware. Only thing that we also do is: - Have live and test versions using the `package.metadata.deb.variants.test` directive in Cargo.toml - Use a reverse proxy (it's config is also shipped with the deb package) - A reprepro to be able to distribute the package - Send ourselves a telegram message when the server fails (not only restart :) ): https://www.curry-software.com/en/blog/telegram_unit_fail/ Especially in comparison with other fast deployment methods, it's very simple and cheap.
&gt;Our EBR is lock-free (if we assume the allocator itself is lock-free, too). I believe most EBR implementations are. My understanding is that all (most: if you count the non-portable posix signal dependent [DEBRA+](https://www.cs.utoronto.ca/~tabrown/debra/fullpaper.pdf)) epoch systems are blocking. The algorithm for epoch checking/incrementing itself is [wait-free population bounded](https://concurrencyfreaks.blogspot.com/2013/05/lock-free-and-wait-free-definition-and.html) but the garbage collection scheme can/will grow indefinitely. The [documentation](https://docs.rs/crossbeam/0.7.1/crossbeam/epoch/index.html) says it itself. &gt;Every time a thread accesses a collection, it checks the current epoch, attempts to increment it, and destructs some garbage that became so old that no thread can be referencing it anymore. If a thread doesn't access the structure again, for whatever reason, or dies during being pinned then reclamation is blocking. Another paper [Stamp-it](https://arxiv.org/abs/1805.08639), has a similar distinction/separation: "With this terminology, Stamp-it is lock-less but reclamation-blocking." As for a nice API. I found it very difficult too to come up with something decent. I think that the [Folly](https://github.com/facebook/folly/tree/master/folly/synchronization) library's implementation of Hazard Pointers has a very clean design. My understand is that it was primarily developed by Maged Michael the original author of Hazard Pointers (who now works at Facebook). Also Trevor's paper on DEBRA+ lays out an API for general memory reclamation including the use of memory pools.
Yeah, I know. The closest thing I found there was the llama game.
I am afraid, it seems like the store just offers this particular cap model in Germany ... It's this one [https://styleyourcap.de/produkt/snapback-classic-schwarzneonorange-6-panel-verstellbar/](https://styleyourcap.de/produkt/snapback-classic-schwarzneonorange-6-panel-verstellbar/). For the logo, I think my friends just used the one from Wikipedia
Great tips, I’ll probably write another one to include them in. This time I just wanted to keep it simple 
Thanks for your kind elaboration of the only acceptable clothing style! Next time I post a photo of a hat right after unboxing, I'll remove all stickers to not bother people on the internet.
Have you tried explaining it to a C++ die hard lately?
seems go was easier for people to pick up and get into. Rust (unavoidable given it's ambition) has a steeper learning curve. I suspect there are people who would use it who just fear the time it might take to learn it, and I have to admit in the years I've been dabbling with it.. i'm still faster at getting things done in C++ - throwing that away is a big ask
IANAL, but it is my understanding that a patent is invalid if you don't intend to enforce it. People use the term "defensive patent" quite a bit, but I think every patent falls into that category. If there are "violators" of a patent and Apple doesn't go after them, then I think the patent can be challenged for that reason. 
It's more complicated than that, yes.
You're right about lock-freedom, although I consider that a pedantic difference. It's true memory can grow indefinitely, but we just assume in the real world it won't. :) I still haven't looked at Stamp-it - it's waiting on my todo list. Yeah, Folly has a nice implementation, but there are some things we could do better. In particular, sometimes it's desirable to destroy garbage eagerly rather than collect later when it accumulates and reaches some threshold. AFAICT, their library doesn't support that. Thanks for the links and references!
This is great. Thank you. 
Thats pretty cool too. Thanks for sharing. 
what /u/meteorMatador says is correct too and actually answers your question more. In your example you are not passing a reference, rather you are making the result of st.len() a reference. len is a method of String, so what I wrote doesn't apply really. 
Is anyone using this with clion for doing FFI stuff? Does it help with interfacing with C/C++ ?
Excellent. Lots to think about. I will play around with all of these
&gt;You're right about lock-freedom, although I consider that a pedantic difference. Tell that to my reviewers :) &gt;It's true memory can grow indefinitely, but we just assume in the real world it won't. :) You're absolutely right. The model for reasoning about these structures was relaxed from an adversarial scheduler to a [stochastic one](http://people.inf.ethz.ch/aldan/papers/non-uniform-podc15.pdf) and a lot of things become easier to reason about. Obstruction-free becomes lock-free, lock-free becomes wait-free. It's lit. &gt;In particular, sometimes it's desirable to destroy garbage eagerly rather than collect later when it accumulates and reaches some threshold. AFAICT, their library doesn't support that. Mmm I guess you'd have to set the threshold length of garbage equal to the number of threads \* hazard pointers... Or something like that. Either way, it'd be pretty inefficient to use it like that, so you're right.
You might also like ArrayFire (more for compute, which is what CUDA/OpenCL and SPIR-V? is for I think).
Your second reply conflicts with your first &gt; People always misunderstand when we say to use Vulkan.... ....In other words, use a library that works on top of Vulkan, instead of using that awful thing that is OpenGL. If there are no libraries then those suggestions were bad to begin with. If someone is a beginner, where should they start for realtime graphics programming? (That's multi platform and haa good learning materials) There's not really a higher level API than OpenGL for graphics. Maybe some variants like WebGL and ES are easier but its still very much similar. Again, the people suggesting Vulkan at all in this thread are giving bad advice to a beginner.
The upcoming(?) build looks interesting. I haven't it recently just because there were no releases since 0.3.5 and I attempted to build it on my system but the repository is so big my machine (slow) would need to run for days lol side question: is there a way to download the entire repository as compressed zip/7z? I tried building last time and it kept downloading (dependency) files separately 
... If you're so worried about somebody's hat sticker ... to judge an entire generation.. I'm worried for you. 
Yes and yes. Stepping into code across FFI boundaries can be a little janky. 
Is it possible for a trait to support two versions of the same operator overloader? // I want to do pub trait Foo&lt;T&gt;: Add&lt;T,Output = T&gt; + Add&lt;i32,Output = T&gt; // But then if I say: Tresult = T1 + T2; //it will error expecting i32 instead of T or Tresult = T1 + anint; //this will error, dependingo n the order of the type constaints &amp;#x200B;
Looks amazing, the orange even matches the color of the subreddit. 
Doesn't rust-imap have an email parser? Looks like it can extract the sender, subject, body, etc...?!?
I'm thinking I need to finally hop on this IDE bandwagon.
Hey, so you're the author of Stamp-it! I've skimmed through your paper but haven't gotten a chance to really dive into it yet. Looks awesome and very comprehensive, by the way! Will reply to you in the GitHub issue with some thoughts as soon as I get a chance :)
I’m currently using CLion for Rust, more specifically for gradual oxidation of a large C++ project, and the IDE’s support for Rust is still amazing.
&gt; I attempted to build it on my system but the repository is so big my machine (slow) would need to run for days lol Redox really lacks documentation currently, but with the right tweaks to the build system, it should be able to pull all the latest packages from https://static.redox-os.org/pkg/x86_64-unknown-redox/ so you don't have to build them. &gt; is there a way to download the entire repository as compressed zip/7z? That's a bit problematic since Redox uses multiple git repositories for different subprojects. So you can download compressed archives, but it would be a bunch of different ones that would need to be extracted to the right places...
&gt; I'm wondering if Redox will one day be able to run Linux applications. What do you mean? As far as binary compatibility, that's not currently a goal. As far as binary compatibility, some software, mainly command-line software, has already been ported. https://gitlab.redox-os.org/redox-os/cookbook/tree/master/recipes
Ah! For some reason I misread the docs and thought all that was under std::num. Thanks!
No I'm not, sorry if I gave off the impression. I am a student researcher in the area though. I was just referring to other reviews I've received on submitted papers.
I choose not to characterize your remarks.
This is also the Ottawa replaces logo-ish if anyone wants the none custom cheaper ripoff version haha
https://gitlab.redox-os.org/redox-os/rine
There was an attempt to do this at https://crates.io/crates/dbus-bytestream but I'm not sure how far it went. FWIW, I'm the author of the D-Bus crate (with bindings to libdbus, the C library) and if you get far enough, I think it could be interesting to see if we could collaborate in the sense that the dbus crate could be used with either libdbus or a Rust native crate as a dependency.
thank for you the links!
Pretty cool. Love seeing some wasm games. Did you have to do anything special for it to me work on touch screens? I was able to control characters but wasn’t able to scroll the screen at all. 
Anyone else not get the update in Intellij?
`impl_sum` seem to require you wrap each returned value in a macro - `auto_enums` seems to be detecting and wrapping the returned values for you. `coalesce` is even more manual than that - you need to pick the `Coalesce#` according to the number of possible returned types, and when you want to use it you need to use a macro (and supply again the number of possible returned types).
Ah that's all right :) For reference, the github thread: https://github.com/crossbeam-rs/rfcs/issues/25#issuecomment-457908900
"SNAPPACK" is misspelled, better remove that sticker
I am not sure if that's the best solution. There is a similar library that converts units, but not temperatures. It has got a different idomatic approach.
Cool stuff. I worked a lot on graph algorithms in my PhD days (although more in distributed setting), so I would lve to see the Rust code one day.
I think an atomic `&amp;'static T where T: Send + Sync + Sized` would be okay. Fat pointers can be problematic if the hardware doesn't support atomic operations larger than a usize. Possibly a non-static `&amp;T` would be okay with scoped threads.
What's the purpose for you to code an email system from zero? And do you still hiring Rust developers?
Yes, there is \`\`\`event.**preventDefault**()\`\`\` for touch events. Did it break anything? It worked well on my phone - [itch.io](https://itch.io) open games fullpage, so there is no need to scroll. Unfortunately ingame map scrolling is unimplemented yet, so the game is playable in landscape mode only :( 
Actually it worked kinda well to implement graph stuff in Rust. I first struggled a bit, because I learned Rust while working on the thesis. It was nice being able to clearly distinguish between immutable objects (like my graph graph representation) and mutable references (like the data structures for graph traversal etc.). I build a nice reusable breadth first search, where you can pass a lambda expression to be executed when a tree edge is traversed and used iterators for graph traversal. The code is by far more readable than it would be in C++. I experimented with different building blocks for the algorithm and used traits for abstracting maximum flow algorithms. Also integrating my code into an existing C++ framework worked like a charm. One of the biggest hurdles was using bit vectors and to prevent array bound checks for performance reasons (and I haven't found the best solution yet). As the adjacency arrays are accessed in a arbitrary fashion, where the compiler can not eliminate the checks, I ended using unsafe code for that.
We're all new to the language, lol
[Android article](https://medium.com/visly/rust-on-android-19f34a2fb43)
My first impression of Rust plugin in CLion is that it feels better than C++ in CLion, haha. But maybe it's just because of different size of my Rust and C++ projects (Rust are just tiny examples while the C++ is a thousands files behemoth).
I think you've missed a 3rd option: disconnect. In general, I've found that it is better design to move I/O as far to the edge of the application as possible. Even the implementation of a network protocol does not require tying I/O and parsing, see [sans I/O](https://sans-io.readthedocs.io/). There are several benefits: 1. `Person` currently violates the Single Responsibility Principle. A piece of *data* should have only a single responsibility: maintaining its own invariants. For example, `name` should never be empty. It should not be tied to a database, or perform I/O of its own. 2. It allows easily swapping from one I/O method, to another. Today `Person` is created from the database, tomorrow it could be created by querying a REST API and the day after tomorrow it could be created by reading an archive from the NAS. 3. Since I/O is at the boundary, everything else can be tested without I/O. This makes tests easy, parallelizable, etc... If you disconnect `Person`, and instead provide a constructor, then you can easily create an instance which suits your needs using this constructor; no shenanigans. 
Now that is interesting. Thanks for the link.
Qt doesn't use X11 for drawing. It does everything itself and then sends a complete image to the display.
IntelliJ doesn't seem to understand the new module system yet, in my project – stuff from `foo/bar.rs` that is being used in [`foo.rs`](https://foo.rs) results in "unresolved references" in the editor, even though it compiles fine. Am I doing something wrong?
From the point of mail, thinks like iCalendar and vcard are "just" attachments so the current mail crate can already do the most basic handling (you can also set it up in a way that you can pass such attachments as data to an template and it will add it as a mail attachment, outside of the template, as it should be). Through my guess is that you want more then this, i.e. creating iCalendar/vcard in a nice way then adding them and also parsing mail and the iCalendar/vcard in the mail. The good news is that I tried to make the library flexible enough so that you can just write your can use independent libraries for writing/parsing iCalendar/vcard. The bad news is, that parsing of mails isn't yet part of the framework and it will likely still take some time. I already scratched out (for myself/non public) how to implement the parsing and incorporate it into the current mail crate. There is one ergonomic related question left about how tightly to integrate parsing with the current parts for creating a mail, but adding parsing is on the timeline of *hobby* projects I want to do, so it might take a while (just to be clear the mail lib itself isn't a hobby project just the parsing part would be it, as 1aim currently doesn't have a need for mail parsing ;), but I really want to add it anyway). Lastly note, that I don't intent to implement iCalendar/vcard myself. But I did (and will in the future) make sure to make it possible to use independent parser/writer implementations with it (well maybe 1aim will need writers for both in \~0.5-1year or so, we will see). PS: If anyone has questions why some parts of the library are exactly the way they are, or want to contribute, feel free to contact me. 
❤️
That would be the basics! Now build Display and FromStr implementations. Bonus points if you try to handle floating point errors. 
Neither did I when I started it, on the other hand if I would have knowen we might not have done it ¯\\\_(ツ)\_/¯. Luckily it turned out that sometimes you can getting away by cutting some corner, e.g. the quoted-printable encoding for encoded words in headers has different requirements on what chars have to be encoded depending on where the header appears, but as encoding chars you don't need to encode is fine you can just have one strict requirement which covers all of them (or just limit yourself to base64). Ironically you can also cut the corner when parsing (if you do multi-pass parsing). As all the "bad" chars will already be hit by the more general parsing passes failing parsing there (through well it would be better to handle them for error messages and preventing mails which are differently parsed by different programs potentially bypassing spam filter). 
Fun game! Thanks for sharing.
&gt;One of the biggest hurdles was using bit vectors and to prevent array bound checks for performance reasons (and I haven't found the best solution yet). To avoid bounds checking, I've implemented my own `Vec` based on `RawVec`, using unchecked accesses in the implementation of `index` and `index_mut`. The only place where I have bounds checking in my code now is in the standard sort functions, because those work on slices. Anyway, I'm wondering if removing bounds checking can actually yield that much improvement. I've had some promising results - ~30% speedup on one instance - but I haven't tested thoroughly.
Bonus points for extending this to have systemd bind the socket and pass it in!
Reminds me of Dex? (as in dexidp/dex on github). Very cool btw.
I'd love to use dbus-bytestream but cannot due to it being licensed under LGPL. I have even [asked](https://github.com/srwalter/dbus-bytestream/issues/13) the author to consider relicensing but haven't received an answer. Actually my plan was to integrate it with with your crate once it's ready for that. Great work btw. Especially the DBus introspection XML to Rust code part is very convenient! My major reason for wanting to replace libdbus with a native Rust library is actually that cross compiling would be a lot less painful afterwards. No special CI setup required. Easy MUSL builds ...
I'm always very happy to see people use `cargo-lipo` :). However in recent times, I have come to the conclusion that `cargo-lipo` actually isn't really necessary, if one configures architecture-specific Library Search Paths: https://imgur.com/a/BDyOEEV Note that I needed to manually edit my `project.pbxproj`, adding lines like this in the relevant places: "LIBRARY_SEARCH_PATHS[arch=arm64]" = ( "$(inherited)", "$(PROJECT_DIR)/../../rs/target/aarch64-apple-ios/release", ); "LIBRARY_SEARCH_PATHS[arch=x86_64]" = ( "$(inherited)", "$(PROJECT_DIR)/../../rs/target/x86_64-apple-ios/release", ); 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/rCF3trK.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20efdznpz) 
/r/gatekeeping
Dex was one of the proxies we evaluated before writing OOProxy, it didn't quite fit our needs (the connector system isn't very well suited for custom OpenID servers).
Hey all! We're thinking of adding `dbg!` style macros to the `log` crate and your thoughts on whether you'd find this useful would be much appreciated.
Sorry for being pedantic, but kelvins aren’t degrees, so you shouldn’t really print ^o . ;)
To put the answer a different way, in `Some(certain_char)`, `certain_char` is *not* a variable; it's a pattern. Patterns create new variables in some scope; they never have anything to do with old variables. In fact, in `let a = b;`, `a` is a pattern.
Good luck! 🦀📈👌
Thanks mate!
what do you mean with floating point errors?
It happened!
Hey, merged 
i never relied on luck, so i wish u productive practice and enjoyment.. (: 
I have very limited experience with extending programs with script interpreters, and that experience is limited only to C, not Rust, so my advice can only be very generic. I've tried Guile (an implementation of Scheme, which is a dialect of Lisp), Lua and Python. Guile has very straightforward API, but the syntax takes some time to get used to; Python is awesome by the virtue of having both a very convenient API and a powerhouse of a standard library; and Lua... well, it uses a state-global *stack* of all things to pass values between functions and to communicate with the calling program, which is an enormous PITA and leads to some very hard to pin down bugs.
can you share the link to the store?
fixed. i am not a scientist :)
Not an expert, but I wouldn't look to do it that way. Here's what I would try doing: You should be able to take something like Lua which allows you to imbed an interpreter in your program, then you define an interface to your own data that is accessible to the Lua engine somehow. Then your program can load the code from a file, pass it to the Lua engine to interpret, and during that process it can pull in any data it needs as inputs through your interface.
Lots of nice wins here - I like the println hint a lot. One thing I'm wondering - I use a lot of generated code using Prost. I never get IDE annotations for it, even if it's in another crate, and even with `impl` blocks in that crate. For example, https://github.com/insanitybit/grapl/tree/master/graph-merger You can see here that I have `graph-descriptions` copied into this `graph-merger` crate (that's how grapl builds work, currently). I then have a `graph-descriptions = {path="./graph-descriptions"}. The generated code lives in the `out` directory of the `graph-descriptions` library, and it is exported with a macro. https://github.com/insanitybit/grapl/blob/master/graph-merger/graph-descriptions/src/lib.rs#L35 Is there any way I can get the autocompletions? I also notice that when I have my IDE pull in the entire `grapl` folder for the project I lose some features compared to when I open up just the directory for the service/ library I'm working on.
Think he means "add error handling so that if you pass an `stemp` that isnt a number, it doesnt panic horribly destroying everything in its wake."
My friend, welcome to computer science. https://floating-point-gui.de/
In my experience basically the only current way to handle this in rust is to have a global Game object, using either thread_local or lazy_static. This is instead of passing it through all your methods like you might currently be doing. Basically, there is no way within rust rules to share the state with the script interpreter except by doing this. Then, you will need to put it inside a Mutex / Refcell to handle the mutability concerns. Unfortunately, this does make much of your code less ergonomic. I would recommend you go with [rlua](https://github.com/kyren/rlua) which is a full featured Lua interpreter for rust which recently gained support for setting limits on script usage: max instruction count, max memory usage, etc. This I think is very useful for a game where you probably eant to make sure your scripts don't run for more than a few milliseconds. I have worked with these limits in my game and the system is quite robust. Also, you can easily and cheaply have lots of Lua states at once that do not interact. I cache one for each logically seperate piece of Lua code, for performance purposes.
Neat! Now I get why folks say you cant compare floats. Kinda terrifying how other languages let you...
Enjoy the future my friend. Just curious, do you know c/c++ already?
I'm just writing a simple forth interpreter in rust. Right now, I'm just trying to get in most of the important forth words in it. 
[This](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=391c398060fcd9dab05171a39bcfe536) compiles fine, but I'm not sure that's what you actually want. What are you trying to achieve?
Ideally it wouldn't be so specialized as for hardcoded cases. The compiler does have enough information to look for functions on all types and see if anything matches the signature you're after, then ordered per relevance. I.e. A method on another object probably isn't relevant, but a deref-reachable type could be. You might want to look into clippy, although this could get builtin support if it works well.
I've been looking for an up-to-date article on this subject. Thanks for sharing!
&gt; Basically, there is no way within rust rules to share the state with the script interpreter except by doing this. That's a real pity! Do you know if it also applies to Rust-centric script interpreters like Dyon and Gluon? 
Enjoy! As a fellow new person, Rust definitely has some "uhh.. wut?" moments, but the explicit detail and safety make it an absolute joy to use. And this is coming from a Go programmer for the last ~4 (5?) years. &lt;3 Rust
I find it similar to Haskell or Scala where when your code compiles, you actually have a reasonable shot of it working.
Yeah, it seems like it would be theoretically possible to build a script interpreter from scratch in Rust to handle this. I don't know Dyon that well but from what I understand it does not solve this problem; everything you are passing in to the API is an Arc&lt;Mutex&gt;. I believe in Gluon the standard way to handle things is by using serde to serialize your Rust structs to Gluon, so that is essentially just copying everything and will not help.
Is there some way to call a method (within a trait) on an enum if all possible values of the enum implement that trait?
Modifying /u/mpevnev's example, the following also works: fn generic_over_add&lt;I, T&gt;(in1: I, in2: T) -&gt; (T, T) where // Copy necessary for using in1 multiple times I: Foo&lt;T&gt; + Copy, { ( // Add I to T in1 + in2, // Add I to i32 in1 + 10, ) } (playground, most of credit to mpevnev: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=bee90a81f6920ac2c954f22c205cf3c1) If this isn't working for you, could you post a full playground that fails to compile?
That looks exactly like what I want. Where in my case F is a SIMD integer vector. The difference is that my constraints are on an associated type instead of on a trait, maybe. Wonder if compiler bug. &amp;#x200B;
Mail was one if the cases where being an early adopter of rust meant that there just wasn't a "good enough" implementation of mail around yet. It's also a way for us to give back to the community so I consider it a win-win. We are hiring, see our website or PM me for more infirmation. 
I haven't used it myself, but perhaps [azul](https://azul.rs/) is what you are looking for?
The bigger issue is when people use floats to handle money. Floats cannot represent every value, and while they are consistent, they are imprecise. All but two countries in the world either don’t have a “cent”, or use 100 cents to a unit. Note that many languages have the concept of a “decimal”, and while they can be implemented in any way, they are a precise alternative. Rust has a decimal crate as well. 
Okay, I know a lot about this, and I'd *like* to give a very detailed answer to this question about how I solved it, but I'm not sure i have the time or energy to go into much detail at the moment. Instead, I'm just going to focus on just what I consider to be the trickiest question you asked: "How do I import and use Rust objects in a scripting language?" This is, in my experience, the absolute hardest problem you will encounter when trying to use a scripting language from a systems programming language like Rust. Language bindings are extremely tricky, and *especially* tricky with Rust and its safety guarantees. Assume that you have some structure which defines your game state `Game`. I assume also that you want to run scripted "systems" on this game state by passing in a reference to `Game`. Well, the vast majority of scripting languages don't have any concept like Rust's lifetimes, so any object that you pass to them in general has to be `'static,`, because Rust has no idea how long it will live. You can't pass a reference to your `Game` object to scripts at all! Okay, so you can place your `Game` state in a shared object like an `Arc` or `Rc` or place it into a global like a global static or thread local variable but it gets worse. Since your object is in a smart pointer or global it must be immutable or use internal-mutability, but internally mutable things like `RefCell` and `Mutex` require locking. You can expose methods on your `Arc&lt;Mutex&lt;Game&gt;&gt;` that mutate its state all at once, but suppose you want to do a multi-step process from a script and only wish to lock once? You can't do this, because `MutexGuard` is not `'static`, so how can you give it to your script to interact with? This was, in my opinion, the single hardest problem in using a scripting language in a game engine. This problem gets even worse if you use some kind of ECS or ECS-like system, because generally they will give you some kind of lock handle to component storages, and they're never `'static` so of course your scripts can't interact with them. Your choices here are basically to use `unsafe`, the `rental` crate (which is not for the faint hearted), or to use a scripting language that has an understanding of lifetimes and can interact with Rust safely (Dyon and Gluon might be like this, I don't know I haven't used them). I hated this problem so much that there is an entire feature `rlua` written *just* to make `rlua` work inside a game engine, and that is the [scope system](https://docs.rs/rlua/0.16.1/rlua/struct.Scope.html). With it, you can write functions and userdata that do not have to be `'static` like Mutex / RefCell / ECS locks, and you can somewhat sanely make a sensible scripting API for your engine. I have no idea how you do this without a feature like the scope system, so much so that `Scope::create_nonstatic_userdata` is actually just a formalization of the exact hack that I had to write when I all I had to work with was '`static` functions / userdata and the `rental` crate. I do not know how other Rust language binding systems handle this problem. I imagine `Dyon` at least might have an easier time since `Dyon` itself has a concept of lifetimes, but I don't know how bindings to scripting languages without lifetimes handle this. I'm not saying even that they *don't* handle it, I just genuinely am unfamiliar with them.
Is there an idiomatic way of implementing an external trait for \`Vec&lt;MyStruct&gt;\` ? I'm trying to \`impl IntoReponse for Vec&lt;MyStruct&gt;\` and the compiler doesn't seem to like it. As a work around I've created another struct \`MyStructVec(Vec&lt;MyStruct&gt;)\` and implement IntoReponse on it, accessing the inner value and compiles but it seems like there should be a less verbose way to do this.
We used to have this! The problem is it had a LOT of false positives.
It's possible, see my answer [here](https://www.reddit.com/r/rust/comments/alhn39/add_scripting_to_game_written_in_rust/efebrya/)
It's in the thread already
my bad, didn't spot it at the first glance
It looks like Rine does the opposite of what is needed for this. Rine = Run redox binaries on linux. Needed = Run linux binaries on redox.
I like it! (and there being a WASM version that I could just load in my browser finally got me to try it). I found the game pretty fun overall, although obviously it's still quite short at the moment! Feedback: - Some kind of button with an "active" state would be nice, so that you can more easily tell which bits are clickable. - It wasn't too obvious how the "move capacity" for each action was measured. For example, can you walk a certain number of squares or only a certain number of times? - I notice that when walking next to an enemy, they can attack. A few times, my character walked past an enemy when there was a route of the same length that would have avoided the dangerous hex. Some logic to avoid that would be nice! Other than that, I think you just need more content, polish, and intro/help screens.
Thanks for the detailed answer, that was super helpful! It's a shame there is not a straightforward, standard way to do this, but at least now I am aware of the issue. I had the false impression that, since many games use scripting, that should have been an easy matter. It definitely appears not to be!
Well, imo with `rlua::Scope` it's not *too* bad really. I think with the scope system it's just as easy as it would be to do unsafely, but it's instead safe. I mean, nothing about binding languages with different runtimes together is *easy*, but I think `Scope` is not much harder than anything else you can do with `rlua`. It's easy-*ish* at least?
&gt; From the point of mail, thinks like iCalendar and vcard are "just" attachments so the current mail crate Maybe you misunderstood: I do not talk about mail&lt;-&gt;vcard/icalendar interaction in any way, I just noted that these two things are also missing/are not "there yet" in the ecosystem! Still good to know that someone is working on the parsing part of email, thank you very much for that!
You might try designing your script system in such a way that instead of operating on "live" object, instead the script gets a way to retrieve current read-only state of the system, and changes to that state are done by script returning a sequence of command objects, which are processed after the script has executed, back in Rust land. And the list doesn't have to be returned in the literal sense - you can create a mutable queue at script call site, and expose API that would look like modifying the game state directly but actually it would modify that queue. It's certainly a lot of work though - be warned.
Just curious, is it possible to compile statically linked executables written in Rust on Android yet? If I remember correctly, the last time I checked, libstd used either dlopen or weak symbols for libc feature detection.
Maybe this a known issue but the kerning was really off for me in Firefox on Windows. Dunno about other platforms. It was especially bad with the "st" in alchemists. I found the summoners really challenging. I used a pretty even mix of swordsmen and alchemists, but when playing against 2 or more summoners it seemed like if they got a good roll on their summons I was done for. Particularly if they got a lot of the grenade demons. Managing cooldowns seems to be key to winning fights.
I did some feature work on Dex. There's a reason I stopped. This looks great, thanks!
&gt; The only gotcha I think is relevant is that you don't want to start lsp-mode when rust-mode is started. Enabling lsp-rust will take care of initializing the language server for you. There is nothing in your configuration that refers to "lsp-rust" so I'm not sure what you mean.
I've been hoping someone would start a meetup in the valley, I'll try to make it! It's about the same time driving to Sacramento for me as it is Mountain View but at least I won't have to contend with Bay Area traffic.
I think I remember Joe Duffy writing that improving the static analysis to remove bounds checks gave some big performance gains, but I can't find the post. 
It's like a whisper on the wind, calling out to us to speak its unholy name: ^(M^(on^(ad.....)))
Ho yes Ho yes Ho yes! 
Is it possible to derive a trait for `test` only. For example, let's say I want to derive `copy` and `clone` for a struct, but I only want to derive `copy` for my tests (and force users outside the test to explicitly clone). Can that be done? My actual use case is around `quickcheck` and `quickcheck_derive`, but I believe the example above is a simpler version of the same thing. 
There were talks about using an attribute for suggestible methods in order to have a whitelist, but I don't think anyone has put on the time to work it out.
r/playrust
It sounds like you're describing a counting [semaphore](https://en.wikipedia.org/wiki/Semaphore_(programming)), in case that helps you search further. It looks like there are a few crates like this already, but I haven't tried them myself. https://crates.io/search?q=semaphore
&gt; You can use multiple versions of a crate in a single application There is your problem, right there. Packages that are out of sync across a program. Honestly, this should be detected and you should get a warning. I hate to bring up C#, but once my workplace built their own nuget feed and started carefully curating what goes in the feed and what doesn't, and forcing upgrades on everyone, it solved a LOT of issues. There was some initial pain for the first few months but I've been able to build locally far more consistently. If I were working on the build and deploy pipeline for a Rust shop, I would ensure we had our own repository for Cargo (I don't know enough about how it works to know if this is an easy thing to do or not) that strictly limited what was available for my developers to use. If they need something that isn't there, then they can request the library, the security team can vet it, we can verify if the liscencing allows us to use it, and all that stuff.
I've had good luck with a similar "sequence of commands" approach in Rust.
You got the wrong rust subreddit bro
IIRC, Guile uses a global context, so you can't easily embed multiple interpreters, but you do get good stuff like real multithreading in scheme. If you want to use a scheme-based scripting language (because Scheme is awesome!), [Chibi](http://synthcode.com/scheme/chibi/) uses a VM model similar to C-Lua where you can instantiate interpreter contexts and environments as needed. It's also a bit easier to generate calls to the vm from the host with Chibi (you can just create an `eval`able list in Rust/C) than Lua with it's stack-machine calling convention.
I've never integrated a scripting language with any systems language (let alone Rust), so I might be overlooking a ton of complexity here... Depending on how performance-critical your scripts are (ie as long as you're not doing something like rendering or collision detection for all entities in your scripts), you might be able to keep Rust and the scripting language completely separated, only communicating serialized messages. It could be as simple as JSON, or for more performance I'd recommend something like \[Flatbuffers\]([https://github.com/anderspitman/omnistreams-spec](https://github.com/anderspitman/omnistreams-spec)), which supports several languages including Rust and Lua.
Alright, I think `std-semaphore` covers my use-case. Thanks!
Half the stuff in that video on elementary OS is grabbed right from Mac OS X.
Never knew there's a hard cover version. The cover picture looks so cute! 
 #[derive(Clone)] #[cfg_attr(test, derive(Copy))] struct S;
i see. will try 
&gt; i never relied on luck What if everything is deterministic? :-O
Can we have it back? Perhaps a RLS feature?
That is exactly what I was looking for. Thanks!
Just ordered this book on amazon :D looking forward to it.
`mod libA::libA1;` is not valid Rust syntax. I think you meant `mod libA; use libA::libA1;`
This stream doesn't implement the std::io::Read trait.
I'm not sure that's hardcover. 
Anyway, paper version
Thanks for the guidance :)
Do you have an example of someone criticizing a C++ feature as *inherently* a bad idea, as opposed to merely un-ergonomic, poorly implemented, or problematic in conjunction with other features? For instance, uniform (brace) initialization and `auto` both seem like good features to me, but the interactions between them are so bad that many people recommend simply avoiding uniform initialization (!!!), and the C++11 standard had a "bug fix" retroactively applied (which is kind of a big deal, but didn't fully resolve the issues). 
...except it's entrenched in decades of tradition and full of Stockholm syndrome sufferers. 
I really wish more C++ devs understood what a proper implementation of move-semantics would look like. So many of them seem not to even be bothered by the idea that the compiler will happily let you access a moved-from type, or to realize that moving something *ought* not incur the cost of invoking some kind of function. 
Oh, hello, experimental incremental compilation for release: https://github.com/rust-lang/cargo/pull/6564 That sounds really cool. :) I hope that it pans out, because speedups for compilation is always welcome!
Having started the Rust meetup in Utah, you've got a tiring but fun road ahead. Good luck!
yeah just half, no need to reinvent the wheel if its good
In a situation like that it seems justified. Just put a comment explaining why.
I'm currently reading the Rust book as well(starting chapter 15). Is learning C/C++ first recommended(just curious)? Personally I've been having a better time with the Rust book than the one semester of C++ I've had.
I wouldn’t necessarily say recommended, but understanding the way C handles memory (I.E pointers, references, objects) will make learning rusts ownership principles way faster. I learned rust before C and had a hard time grasping its memory rules, so after taking a break and learning about C++ pointers and memory handling, I came back to rust and it all made sense. You absolutely don’t need to, it just made it easier for me.
Damn.... that’s awesome
Ah. I have an easier time with C than C++. I LOVED my x86 assembly class. The whole object oriented with classes deal was what I struggled with as far as C++. So far I love Rust far more than C++ simply because to me it always seemed...idk, weird? that classes are just structs that are private by default, and C++ was originally just "C with classe." Why come up with a whole new thing(classes) instead of just fixing structs to be private by default? Versus with Rust(still reading the book, if I'm mistaken bare with me) everything is private by default, unless you make it mut. If my understanding is in anyway incorrect, please feel free to put me on the right track.
&gt; C++ simply because to me it always seemed...idk, weird? that classes are just structs that are private by default, and C++ was originally just "C with classe." Mm, no, there's two concepts you're confusing. **In the context of C++**, `struct` and `class` are identical aside from default privateness of members. However, a C++ `struct` is *way* more powerful than a C struct, and most people use `class` for these powerful features rather than `struct`, but they are strictly equivalent. The main reason C++ didn't change the default privateness of `struct` is because it would have been too backwards-incompatible with C++, where C++ is almost backwards compatible with C. If C++ didn't add the `class` keyword, C++ `struct`s would still be a huge improvement on C. Things C structs can't do that C++ structs/classes can do: - Proper methods (as opposed to just function pointers that get assigned) - Template metaprogramming - Constructors and deconstructors (how you typically manage memory in C++, rather than using `malloc` and `delete`) - Plenty, plenty more. The `class`/`struct` distinction in C++ is basically nothing. Just an extremely small and honestly perfectly reasonable quirk of the language.
“Everything is private by default, unless you make it mut” this is not true. mut simply means you are declaring a variable that can change. For example: let x = 5; x = 5; Will throw you an error. let mut x = 5; x = 5; Will work. Rust doesn’t have a concept of private or public. You declare structs and then make an impl block to add methods to the struct. It’s hard to understand (certainly took me a while) so just play around with it :) Feel free to ask me any more questions.
Correction. Rust has the concept of Public and private, however it works ALOT differently then I. C++. It has a module system which you can google or look in your book for. This should explain it clearly.
The streaming function is correct to require `'static` so that the data handed off to be processed at an arbitrary later time (async) isn't going to have a lifetime problem. If you just want to get your code to work, then you'll have to figure out how to get the iterator to be `'static`, maybe by boxing something or by calling map with a closure that captures the file. I'm not sure whats putting a lifetime on your iterator without the code. However, a performance note: You will then be performing file IO on your actix-web thread, and while it is blocked doing this, it cant asynchronously handle other requests! For simple cases this is ok, but it partially negates the benefits of an async web framework (you still get the benefit of not reading the entire file before starting to send it). If you move the file IO to its own actix actor or use [futures_fs](https://docs.rs/futures-fs/0.0.5/futures_fs/), then having a bunch of requests which stream from files will only slow each other down as your harddrive bottlenecks, but it wont block actix-web threads which keeps your non file IO requests fast. Joining together async file IO and async network IO is a bit trickier than just the normal async in actix. 
Just finished working through that book. Hope you enjoy it. Coming from C++ required a bit of change in thinking, but I'm already using rust for linux system programming and I must admit that Iove the language. Good luck! Just stick with it.
A slightly more rustic instructions: 1. For each triangle in triangles, draw the triangle on frame buffer. 2. Frame buffer display?
Ah, thanks! Had 2 semesters of C# first, so the every time I see something in the book about "mutable" my mind instantly goes back to "get is an accessor, set is a mutator..." I will say I am enjoying learning the language. This week I've been going through the book on my own time, vs the other languages I've dabbled with were class related. I guess my confusion with private by default deals with ownership. My understanding is that there can be "n number of non mutable references" OR "there can be a single mutable reference." As far as the single mutable reference goes, would it be safe to say that its behavior is kind of like private? Since only the owner can change it? 
It's like... nice paper though. 
Not really. It means that you can only have one mutable reference of something at a time. After that reference goes out of scope you can make another.
Damn, that cover somehow reminds me of the famous Ruby book 
Thank you!
New rust programmer (coming from C++). I have this. pub enum Tree&lt;T&gt; { Empty, Head(T, Box&lt;Tree&lt;T&gt;&gt;, Box&lt;Tree&lt;T&gt;&gt;), } use Tree::*; impl &lt;T:PartialOrd&gt; Tree&lt;T&gt; { fn add(&amp;mut self, t:T) { match self { Empty =&gt; { *self = Tree::new(t); }, Head(d, l, r) =&gt; { if t &lt; *d { // Why do I have to dereference d? l.add(t); } else { r.add(t); } } } } } In the line with the comment, why do I need a dereference?
Nice! I love those moments!
I do know the basics of c++. Never dove into C though. Have done some swift and a lot of c#. Have done some java as well.
It's not a hard cover. It looks ;ike that because of perspective of the picture taken.
It is!
Cool project. A couple of comments: * unless you’re doing this to try FFI, it seems a bit strange to use ruby for such a simple API. * why is the ruby mixed into the cargo project directories? I feel this should probably be separated, as you just FFI to the Rust library and there’s nothing shared. * in case you’re planning to run this for real, please consider the security implications of opening this API to the outside. Most of these work with an agent that sends its data to a specific endpoint. Otherwise consider adding authorization to it. 
This is because of [match ergonomics](https://github.com/rust-lang/rfcs/blob/master/text/2005-match-ergonomics.md). Basically, since your matching on a reference to `self`, you have to take `d`, `r`, and `r` by reference too (you can't move out of a reference). The match ergonomics feature implicitly adds the `ref` keyword to indicate to the compiler that you will borrow the field, not take ownership. `t` however, is not borrowed, it is owned. You can't directly compare an owned value to a reference of a value. Instead, you have to dereference the reference in order to compare two values. I'm not sure about this next part, but I think could could also add a borrow to `t` when comparing and that would work as well. Usually when using PartialOrd the two types you're comparing have to be the same type.
Could you please prepare a minimal code that reproduces this problem? The new module system works totally fine in my projects.
This is OBSCURE!
I find this `_` syntax very hard to read but I understand the problem. I think that partial application and currying could solve the problem but I don't think rust will ever have these.
I'd recommend using https://docs.rs/tokio/0.1/tokio/fs/struct.File.html over futures_fs or an actix actor. Current actix is built on tokio, so there will be no interop problems. In addition, `tokio::fs::File` actually using async IO operations for the file too! From the documentation, `futures_fs` uses a thread pool with blocking operations on it, which also kind of negates the purpose of using futures (though not as much as using std's file IO...).
Thanks! The codegen stuff needs to be asyncified, but I've been holding that off until async/await settles. As for D-Bus fundamentals, I think one could separate it into these parts: * Connection setup (addresses, sockets, fds, read/write bytes) * Message serializing / deserializing * Message dispatch I rely on libdbus for all three of these currently, but I want to move the "Message dispatch" part to Rust. So if you want to write a native backend for the two topmost ones - preferably as two composable parts - then I think it would make sense to use these in dbus-rs (at least as an option).
If I have a `Rc&lt;T&gt;` in a function like this, is there any way I can return a reference to the value owned by the `Rc`? ```rust fn toy(r: Rc&lt;T&gt;) -&gt; &amp;T { t.as_ref() } ``` I would just return the `Rc` itself, except the trait I am trying to implement wants a reference to the inner type, not an `Rc`... so I'm not sure what to do. It seems impossible because there is no compiler guarantee that the inner value of the `Rc` will survive into the return value's lifetime?
looks promising, but i want more of an actual HTML DOM rendered GUI while Azul is DOM like in code to avoid 2 way bindings. &amp;#x200B; web-view is the way to go for me right now maybe there will come a better solution with Servo.
I knew you would say that.
Thanks for the Replay, i will stay with Web-view for now and maybe servo can rendere a Web-view GUI in the future.
There's nothing built into the language that does that. That is why this crate implements the trait on the generated enum so it's methods can call the correct method on the returned trait implementation.
It's been working fine for me in my projects.
&gt;\~4 (5?) years. &lt;3 Rust Can't tell whether you love Rust or program in Rust for less than 3 years.
Does anyone know what is the fastest hashmap for \~60.000 entries and UUID as keys?
Oh cool, i think i might move some code around to use that. Will using the tokio File eventually result on blocking reads being performed on the same threadpool that actix-web uses to serve requests or is there a dedicated threadpool in tokio for file IO? From my (admittedly tenuous) understanding, portable async file IO is normally implemented using a thread pool + blocking file reads.
I believe Actix uses the `current_thread` runtime, but the `threadpool` runtime is needed if using `tokio-fs`.
The threadpool has a knob to configure how many "blocking" threads can be used, apart from worker threads. If all "blocking" threads are busy, then the operation on the `tokio::fs::File` will return `NotReady`, and sign up to be notified when a blocking thread is available. So the worker threads should continue to be able to work on the mostly non-blocking futures.
&gt; `if cur_char == ' '` Given that you're in the match branch where the character is known to be 'H', this condition is impossible to fulfill.
Thanks. That makes sense.
Thanks. Is this the best way to implement a binary tree in idiomatic rust? How do the pros do it?
 Thanks. Is this the best way to implement a binary tree in idiomatic rust? How do the pros do it? 
My biggest and practically only complaint with this plugin is it's poor macro support. It's frustrating only because it's otherwise a fantastic tool and soooooo close to think I could exclusively use it. I don't use a ton of macros.. but when I do it's to save me a ton of duplicated effort. Having to fight my editor for simple things like indentation (lack of auto complete can be tolerated), and not being able to get the same feedback when you're writing something that's going to result in a compiler error... Keeps me using emacs and rethinking whether my subscription to jetbrains stuff is worth my munny if it isn't saving me time and effort.
This is correct. Kinda ugly but here is my prototype for preventing a block on fs access... let bytes = bytes::BytesMut::with_capacity(1024 * 1024 * 1024); field .map_err(|_e| ()) .fold(( bytes, 0, ), |( mut bytes, mut size ), item| -&gt; Box&lt;Future&lt;Item=( bytes::BytesMut, usize, ), Error=()&gt;&gt; { size += item.len(); bytes.put(&amp;item); Box::new(futures::future::ok(( bytes, size, ))) }) .and_then(move |( bytes, size, )| -&gt; Box&lt;Future&lt;Item=( usize, ), Error=()&gt;&gt; { let (tx, rx) = futures::oneshot::&lt;Result&lt;(), ()&gt;&gt;(); std::thread::spawn(move || { let mut file = match std::fs::File::create(&amp;file_path.unwrap()) { Ok(file) =&gt; file, Err(_e) =&gt; { tx.ChatErrorsend(Err(())).unwrap(); return; }, }; file.write_all(&amp;bytes).unwrap(); tx.send(Ok(())).unwrap(); }); }) 
Should also mention that lack of parsing the output from the compiler and giving me a nice jumpable list of errors and warnings is a surprising missing feature. Yet another thing that Emacs just happens to do quite easily and naturally.
Or cargo-clippy feature
Initializer lists?
This looks really promising for an application I have. Thanks for sharing it! A few questions: * Are there plans to provide an example or expand the documentation? * Why little-endian for the numeric types instead of native-endian? * Would `stdsimd` make this even faster? Or are speedups achieved some other way?
The previous code has been replaced with a 'straight' port. It turns out, that Rust's inlining works so well, it is not necessary to do manual "optimizations". This 'straight' port of \`gcc #4\` to Rust shows the performance boost as well, compared to original \`gcc #4\` or Fortran. The 'straight' port permits to compare the quality of the compilers gcc and rustc directly. Additionally,, comments have been added to the Rust-code, explaining the different layout of the Rust-code and referring to the corresponding expressions in \`gcc #4\`, 
&gt; Sorry for being pedantic I don't think that's pedantic at all -- it's pretty important to keep that in mind. Or rather: It's pretty important to understand what degrees in Celsius and Fahrenheit mean. Otherwise, you'll end up as one of those people who claim a 20% increase in temperature when comparing 20 degrees Celsius to 24 degrees Celsius.
Good point. This will ease comparing the sources and allow direct comparison of the quality of the compilers gcc and rustc.
Probably no dynamic memory page allocation for stack or heap required, static memory only being setup when loading the binary into memory.
Hehe unit tests. 
Well done, than you !
Rust beginner here. I have a JSON file where my hypothetical users can enter values either as strings or JSON arrays, like this: ``` { "foo": "#AABBCC" } or { "foo": [255,255,255, 1.0] } ``` Internally, I want to only ever have `struct RGBA(u8,u8,u8, f32)`. I therefore want to parse both strings and arrays info this RGBA struct. In Haskell I would simply write a custom `deserialize` for that type which matches on the value given to me by the JSON parser library (`aeson`). So I'd more or less do ``` match value { Value::String =&gt; {..}, Value::Array =&gt; {..} } ``` I tried doing that in Serde but implementing a `visit_str` doesn't make sense for the array. So I'm thinking my approach is entirely wrong and I should probably just let Serde automatically derive the deserializer for the JSON array version and a custom deserializer for the string. I could probably do this with an enum and `deserialize_with` ``` enum ColorValue { RGBA(u8,u8,u8,f32) Hex(u8,u8,u8) } ``` but then I would have to afterwards transform all the parsed values to go from `enum` to only `struct RGBA`. I'm probably thinking about this in the wrong way so some directions would be super appreciated :)
Of only one day this could be done without rustup and Android studio. Great to see progress and guides, though.
It might be helpful to take a more high level look at the problem. Blocking all threads `&gt;y` that low level doesn't feel quite right and also doesn't sound that efficient. Think if you can organize your code in a way that only `x` threads are executing that block of code. 
That is in fact implemented! If you run Cargo run configuration (or use the build project action), the cargo/rustc output is parsed, all links to the source code are highlighted, and you can cycle through them via shortcut. To enable inline errors display, you should enable `use cargo check to analyze` code in the settings. It works OK for smaller project, but scales poorly.
Have you updated the IntelliJ Rust plugin? If so, please create an issue [here](https://github.com/intellij-rust/intellij-rust/issues).
You can't check just the unsafe blocks, you have to check the entire module and any sub modules if there's even one unsafe expression. They are all suspect.
Ah I see! Austria has a tonne of powerhouses in this area. Also, thank you for all your work in Rust. I wish I had the time/willpower to get as involved as you are. It's great.
Servo has a bot that does this for pull requests on Github, for instance: https://github.com/servo/servo/pull/22640#issuecomment-451758004 Code: https://github.com/servo/highfive
Wow, the \[std::simd implementation\]([https://github.com/rust-lang-nursery/packed\_simd/tree/master/examples/nbody](https://github.com/rust-lang-nursery/packed_simd/tree/master/examples/nbody)) is even faster than my one, just it seems to require "nightly features". So, there seems to be more to come, once those features have become 'stable' :) Compilation of \[std::simd implementation\]([https://github.com/rust-lang-nursery/packed\_simd/tree/master/examples/nbody](https://github.com/rust-lang-nursery/packed_simd/tree/master/examples/nbody)) takes ca. 40 seconds, but 50Million iterations take 2.2 seconds only, comparing to 3.4 seconds for my implementation ( i7-6500U CPU @ 2.50GHz)
I don't rely on luck either, in the sense of wishing and hoping. But I'm damn well very glad for how luck I am for everything I got by mere circumstances.
You can probably speed it up some more by enabling some of the `packed_simd` cargo features (sleef-sys, coresimd, etc.).
I appreciate that. Thank you. My intent came from a constructive and supporting mentality. If it didn't come across that way, I apologize.
out of curiosity, what is the use case for a 4096 bit integer?
Although not directly about Rust, the fate of WebAssembly is tied to that of Rust and this article series stems from my experiences writing a WebAssembly compiler in Rust.
As a rule of thumb, if you have an output with a lifetime that's not bound to any of the inputs, then that lifetime could probably just be `'static`. In your case the lifetime definitely can't be `'static`, so this function is impossible. Can say what trait is that and what do you want the implementation to look like? Maybe we could help finding an idiomatic and safe way of doing that.
You may like to talk with the amethyst game engine developers, they have an [RFC](https://github.com/Moxinilian/rfcs/blob/master/0001-scripting.md) talking about that, also you can jump into their discord if you have further questions or want to discuss something. I’m recommending that because both uses ECS and the solutions may be similar.
A lot of trial and error and now I've got something that does the job. No idea how idiomatic that is. ```rust impl&lt;'d&gt; de::Deserialize&lt;'d&gt; for RGBA { fn deserialize&lt;D&gt;(deserializer: D) -&gt; Result&lt;Self, D::Error&gt; where D: Deserializer&lt;'d&gt;, { #[derive(Debug, Serialize, PartialEq, Deserialize)] struct RGBAHelper(u8, u8, u8, f32); let helper: Value = Deserialize::deserialize(deserializer)?; match helper { Value::String(str) =&gt; { println!("{:?}", str); if str.len() != 7 { Err(de::Error::custom( "Hex color string must be of format #ABCDEF", )) } else { // This only works on ASCII let rgb = &amp;str[1..] .as_bytes() .chunks_exact(2) .map(|c| { let s = c.iter().map(|&amp;byte| byte as char).collect::&lt;String&gt;(); u8::from_str_radix(&amp;s, 16) }) .collect::&lt;Result&lt;Vec&lt;u8&gt;, ParseIntError&gt;&gt;() .map_err(de::Error::custom)?; Ok(RGBA(rgb[0], rgb[1], rgb[2], 1.0)) } } Value::Array(vec) =&gt; { let rgba: Result&lt;RGBAHelper, serde_json::Error&gt; = serde_json::from_value(Value::Array(vec)); rgba.map(|RGBAHelper(r,g,b,alpha)| RGBA(r,g,b,alpha)).map_err(de::Error::custom) } _ =&gt; Err(de::Error::custom("foo")), } } } ```
I want that hat, it looks very awesome. shut up and take my money
Manning has a book on that Rust that you might want to read afterwards called Rust in Action.
...because stuff in the same `mod` can ignore Rust's public/private access control system, so you need to check the entire `mod` to make sure that there's no safe code which will trip up the `unsafe` code by doing something it doesn't expect.
&gt; course-grained coarse-grained
RSA, maybe.
Instead of going through `Value`, you could have a helper type that is closer to how `RGBA` is serialized: #[derive(Deserialize)] #[serde(untagged)] enum RgbaHelper { Str(String), Array(u8, u8, u8, f32), }
That is pretty neat, thanks! I did read that part of the docs at some point but I didn't really connect it to my use case.
I learned C before cpp and I can see your struggling. Object oriented programming is a whole different thing, don't mix them. It is very useful in structuring bigger programs. I am not saying that cpp is better than c in general, there are applications for which c is enough and there are applications where cpp makes things easier. Use the right tools for the job.
I attended the meetup at Mountain View Sept.16th 2018, just me and Mason from NY, no locals or host. The host Michael did not answer any messages, AFAICS, the meeting should be removed from calendar.
Absolutely. I'm a bit busy right now, as I'm switching jobs, and moving places, but I would be more than happy about a bunch of tiny bit-by-bit pull requests with good explanations. Step 1: One line tweaks to make it more idiomatic. Step 2: Split the gigantic game.rs - which ended up just getting everything dumped in. Step 3: Improve the high level architecture. &amp;#x200B; But anything is welcome, as long as I understand it ;) &amp;#x200B; I also think that a "render sprites to minifb"-crate would be a nice side product, and very helpful for the next jam. 
To quote Friends: "The learning curve sucks, you're gonna love it!"
Thanks, their RFC is interesting. Though, I should clarify I am not using ECS. I just abused the term "entity" because the object `Entity` in my game represents any kind of "thing," from items to actors to ground types, and it contains all sorts of data.
Rust structs do have private-by-default fields with a `pub` modifier to make them public: https://doc.rust-lang.org/rust-by-example/mod/struct_visibility.html
Your streaming compiler for wasmtime.. lightbeam? Or something else?
to save the next person the trip into the source: looks like it uses diff information to see if any added lines have 'unsafe ' in it. re: https://github.com/servo/highfive/blob/master/handlers/unsafe/__init__.py
As the author of a terminal application based on termion, I can't rely on stdout and stderr for debugging. I would appreciate the comfort of dbg! in my logs (which I send to a file I follow with tail).
Why do you think that the fate of WebAssembly is tied to that of Rust? Also, I've been thinking of writing a WebAssembly compiler for a long time. I have some basic compiler knowledge from undergraduate courses on compilers and virtual machines, but I haven't been able to put it to good use. Do you have any tips/pointers on how to start?
If you need this as a visual aid Rust plugin for JetBrains IDEs does that.
Haha we will see about that! Love the quote!
You have a link maybe?
Huh, last time I looked at the spec I believe wasm was still a register machine. When did the change happen ?
[https://www.manning.com/books/rust-in-action](https://www.manning.com/books/rust-in-action)
Not many people program in Rust for more than 3 years.
This mostly creates a false sense of security since correctness of unsafe code often relies on certain invariants to be upheld by the surrounding safe code. So monitoring code under unsafe blocks alone would not suffice.
My guess is that it doesn't consume `other` so that it can later be used again instead of requiring another new instance of a Vec.
big fucking numbers
[removed]
*No lawyer, and not from the US.* But even if you have a contract which states you have to it's questionable if that contract is legally binding. At last in the case where you now that you "declaration" is a plant lie due to priority art. I mean terms in contracts are not legally/valid just because they say they are, else I could legally create a contract for e.g. assassinating some person or stealing trade secrets (But then even if your contract is not leagally binding, you might still end up following it for personal reasones...).
Yes, it is Lightbeam. It's not ready to be announced properly right now though, so I didn't link it just in case this post got popular.
Well, it is still a register machine, that's the point of the article. According to sunfishcode, the switch to a stack-oriented encoding for instructions was made very close to the MVP's release but I personally never knew a time when WebAssembly wasn't stack-oriented since I wasn't following it until last year.
could you elaborate? It is setting `other`'s length to `0` so there is no difference in reusing `other` or creating new `Vec`
In my opinion very rare usecase (involving micro optimizations which are in general doable by \`Vec::extend\_from\_slice(&amp;other)\` + \`other.clear()\` on calees side), and the cost is, that whenever I want to create some mid-time vector which I will later append to the other one, I need to do it mutable. I also am very not-a-fan of this approach. &amp;#x200B;
You're almost doing exactly [what the book suggests](https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#using-the-newtype-pattern-to-implement-external-traits-on-external-types). The last step is to implement Deref on MyStructVec.
You don't have to allocate a new `Vec`. The allocated space remains intact. 
I haven’t looked at the code, but Vec is supposed to reserve space, even when it’s empty. Setting it to 0 length might not free any memory.
&gt; ...because stuff in the same mod can ignore Rust's public/private access control system, so you need to check the entire mod to make sure that there's no safe code which will trip up the unsafe code by doing something it doesn't expect. The wrapper around your unsafe code should accept literally anything. There should never be a situation where your unsafe code expects a certain thing and you aren't validating that.
IDK why would you need that? Types are inferred not only to not save you few fractions of a second to type the type. But also save you more time when type changes.
And unsafe code that might not accept everything should only be in an unsafe function itself
The fate of WASM is not tied to Rust.
Bravo! I stand happily corrected on this particular matter then. :D
Well yes I agree, and at the same time knowing the types makes the code more readable
The "nice paper" edition is the only edition! 
`extend_from_slice(&amp;other)` only works if `T` is `Clone` – it creates copies (possibly paying whichever overhead Clone has) and later drops everything from other. `append`, on the other hand, does not require `Clone`, as the items are moved around rather than duplicated.
I'm not sure what the question mark is for; is that an example of a feature you've seen criticized, or a question about my comment on using `auto` with braces? 
It really is not.
An example of an inherently bad feature. 
&gt;to save the next person the trip into the source: looks like it uses diff information to see if any added lines have 'unsafe ' in it. code what i'm reading above is that this is indeed potentially the case within a module, i.e "any unsafe renders the whole module unsafe", but do you mean anything beyond the module effect mentioned in other posts? &amp;#x200B;
Might want to try something like this: struct Tree&lt;T&gt; { value: T, left: Option&lt;Box&lt;Tree&lt;T&gt;&gt;&gt;, right: Option&lt;Box&lt;Tree&lt;T&gt;&gt;&gt;, } Since `Box&lt;T&gt;` can't contain null, `Option&lt;Box&lt;T&gt;&gt;` can use null as its `None` value, making them the same size. So, this implementation and yours will be the same size, but this one won't have to contain any pointers to empty nodes.
hmm. so really "any unsafe makes the containing module unsafe", so checking 'a file' for the presence of unsafe isn't actually overkill, it's the right granularity? (given a file is a module) ... it would only be overkill if the unsafe was contained in submodules? &amp;#x200B;
What are your thoughts on the nesting of parenthesis compared to other languages?
... Ah. Then I should have clarified, I meant an example of what you seem to be talking about in your original tweet: someone criticizing a feature as inherently bad, then praising it in Rust. I don't think initializer lists really have a Rust analogue. 
Interesting article, although I don't know enough about virtual machines and compilers to fully understand it. One thing I've been wondering is, what exactly do you call a streaming compiler ? After a quick google search I'm yet to find a definition for the term. I took it to mean JIT compiler but I feel like it's not the whole picture.
A streaming compiler is a compiler that acts on a stream of input data. Basically this means that it can start compiling as the WebAssembly bytecode is being received over the wire. Firefox's baseline compiler acts like this, there's a great post by Lin Clark about it https://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/
Fixed
what would the return type be of an imported Yaml file. Is it a bad idea to return the entire array from a function? &amp;#x200B; pub fn align() -&gt; YamlLoader { let yaml = "config.yml"; &amp;#x200B; let mut handle = File::open(yaml).expect("not found"); &amp;#x200B; let mut config = String::new(); &amp;#x200B; handle.read\_to\_string(&amp;mut config).expect("unable to read"); &amp;#x200B; let docs = YamlLoader::load\_from\_str(config.as\_str()).unwrap(); docs } &amp;#x200B;
Lol, love rust. 
It still looks like microoptimization which: 1) is not needed in most cases 2) is possible to perform by compiler 3) may be achieved by redesign code in clever way 4) may be achieved with `unsafe` (maybe not always good idea, but possible) The problem is than, in most cases it is something which is not even considered, requires some code overhead (very suspicious mut is needed), and has very strange semantic. Going with this mindset, taking `&amp;mut` should be almost always prefered over over ownership, also with self, including functions like `Vec::to_boxed_slice`, or at least every such function should have `&amp;mut` equivalent. Unless it was measured that in most `extend` usecases the vector is later reused AND it gives noticable performance boost, this is not an excuse (at least not a good one).
All appreciated suggestions. 1) I agree. If I wasn't looking to learn FFI, I wouldn't have used Ruby. Very happy to have made the plunge. It's been on my TODO backlog for ages. 2) ) I forgot to add to the README that I got off the ground with [this](https://github.com/alexcrichton/rust-ffi-examples/tree/master/ruby-to-rust) example. I followed the structure, although I agree it's a bit odd (especially considering the Gemfile is alone in the root directory -- I should place `main.rb` there). 3) Authorization, authorization, authorization. A must. Thanks u/mtsr
That's cool. If you find the time to write about how it went, I'd love to read it.
No, I'm just referring to the module effect.
Hey, how did it go?
&gt; I believe in Gluon the standard way to handle things is by using serde to serialize your Rust structs to Gluon, so that is essentially just copying everything and will not help. That is a way mostly there for convenience. It is also possible to embed any `'static + Send + Sync` rust types as `Userdata` https://github.com/gluon-lang/gluon/blob/c478622c99896ae19532e4d58f8ad1cc07b40d2f/examples/marshalling.rs#L334-L398 (meaning `Mutex` or `RwLock` for mutable data) and there is also gluon specific `derive` macros to fill the gaps where `Serialize/Deserialize` does not work. I want to improve this in the near future both to allow non-static data and non-send/non-sync data https://github.com/gluon-lang/gluon/issues/497. (The only feature I think could be more important would be Generalized algebraic data types to support extensible effects fully). 
Too late, my man. We all know what you did.
This way, the memory allocated by the other vector is kept around and can be re-used. That's important performance-wise in a lot of cases. 
See `set_len` here: https://doc.rust-lang.org/src/alloc/vec.rs.html#796 I think you're confusing setting the length to zero versus setting the capacity to zero.
I also would like it for readability. It makes the code's intention more obvious.
Have fun on your first meetup, /u/mehcode! Will you present your `nox` crate there, or will I just stay forever reserved on [crates.io](https://crates.io)? 🤡
A classic use case for it is if the right side is an input buffer. It appends the buffer to an internal storage, but leaves the buffer structure itself (together with its capacity!) intact for reading again.
You only need to check functions which have `unsafe` blocks in them or are `unsafe` themselves.
Empty Vecs don't allocate. But `append` does not change already allocated capacity, so the vector remains intact.
"Tied" can mean merely "connected," and I don't think anyone would disagree that Rust is connected to WASM. Most of the talk I hear about WASM comes from the Rust community rather than the other PL communities I'm involved in.
Access control (like private fields of public types) is a valid way to "validate" the inputs to an `unsafe` function, but even safe code with access to those fields (the whole module) needs to not break invariants. https://doc.rust-lang.org/nomicon/working-with-unsafe.html
Say that your safe function with an unsafe block accepts an instance of some type that is guaranteed to uphold some invariant. The soundness of the unsafe code relies on that invariant. Now, someone makes a change to safe code that breaks that invariant. Oops. See https://www.reddit.com/r/rust/comments/alnm7q/did_a_checkin_change_any_unsafe_code/effwwyu/
I just can't seem to find a use case for learning it. 
you are right, \`fn offset\_momentum\` is not in the critical path; could use \`map\`, but it turned out, a \`straight\` port would be much better to compare output of rustc vs gcc
And you will as well pay for it 
I'm confused why you believe that this is a suspicious `mut`? The function has very clear semantics in my book. Rust has move semantics baked into the language, so it definitely makes sense to have 2 functions where one moves and the other copies and consumes. Vecs as buffers are common in Rust and enabling people to reuse buffers is a core strategy behind many signatures.
Reason being?
If WASM fails, Rust won't fail. If Rust fails, WASM won't fail. Because of that, I think "tied" or "connected" is a stretch, maybe "related". WASM is still _very_ intriguing for any other language that wants to run in the browser. For example, I've heard of game developers looking into it, products like [Google Earth transitioning to it](https://medium.com/google-earth/earth-on-web-the-road-to-cross-browser-7338e0f46278), and support from languages like Go (WASM needs threads to make that work well). The main complaints I hear are: - compile time (caching, JIT, etc) - performance (already usable, and getting better) - needs more features (they're in development) So no, I don't think Rust and WASM are "tied" in any meaningful way. One succeeding certainly helps the other, but one failing doesn't cripple the other.
I’ve made a couple of actions for clippy, rustfmt and cargo-fix already (I was meaning to share it, but I kept forgetting) They provide validation as linters, and might provide fixes driven by Pull Request reviews or automatically modify PRs on push. I was thinking of building other actions, bit at this moment, I think that Travis CI still offers better coverage for testing and building. It has Linux, Windows and Mac runners available, and combining it with [crossgen](https://github.com/yoshuawuyts/crossgen) makes bootstrapping it easier. So I’m using a combo of Travis for tests, builds and release, and GitHub Actions for pairing with bots to keep the code well formated. I hope others find it useful :)
While I can agree that selective and judicious use of type annotations helps readability, it is only up to a point... Too heavy of annotations just turns into clutter. And oftentimes (eg with closures) it's impossible. Everybody ought to know that `Option&lt;T&gt;.into_iter()` returns an `impl Iterator&lt;T&gt;`. But nobody needs to know the exact name of that struct.
Well that clarifies things quite a bit. Thank you.
I remember my first look at a rust code snippet, it was elegant and I could understand what the code does. but this didn't go for along time after seeing a code snippet that contains some macros. It was very frustrating :D
The bracket pair colorizer extension is very useful for that.
Ok
Compared to C++, Rust is dead easy to read. I have a few complaints about the language, but that issue never crossed my mind.
I had the same experience, and found Rust much more approachable than C/C++, it's only nownthat I've learnt Rust that I'm looking at potentially learning them. I think knowing C or C++ first is both an advantage and a hinderance. An advantage because you will already have learnt a lot of the concepts that you need to know when usong Rust. But also a disadvantage because in many ways writing Rust is a lot more like writing higher level langauges than it like writing C/C++ (e.g. it's normal in Rust to `cargo install` a library rather than writing your own data structure. And also, many of the patterns that seem to be standard in the C(++) world just aren't possible in Rust, so you have to unlearn those).
I think this analogy kind of works as long as you don't push it too far. Ownership and public/private can both be used to restrict which parts of the code can read/write different bits of data, but the mechanisms themselves work quite differently. Rust *does* also have the concept of private struct fields (although there are ways of getting around this in some circumstances), but these should only be used for internal state that a user of the struct should never access directly. If you adding getters and setters then you should just make the field public instead.
Which piece of Rust code? Invariably, Rust code tends to be part of a project of some sort, and you won't understand the code unless you understand the project.
I wonder why C has never added methods. It seems like it would be a simple, backwards compatiable addtition, that would make a lot of programs much nicer to write.
https://xkcd.com/297/
For information I made this crate to work around [an old RFC](https://github.com/rust-lang/rfcs/pull/2477) that proposed to add the `group_by/group_by_mut` methods to slices and was never merged.
So I mucked about for a bit on the [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=88bc3aafaded40369fdb7a87f6e955e8) and what you've written seems to hold true. The only thing I can't make sense of is why the first 8 bytes (and only the first 8 bytes) of `v` get zeroed out when `v` is dropped, regardless of the type being stored.
Thanks! the smashing magazine link was extremely informative and helped me a lot in my architecture design. I might unfortunately not implement this in Rust but the information is very interesting and useful. 
Or be prepared to panic as defined behavior
I think your understanding of this phrase is at odds with its usual meaning in English. 
Small clarification for emphasis: It's okay for a safe function to "expect" its input to have a certain structure, but it has to check for that and panic when that expectation is not met. Example: `unwrap` or array accesses.
&gt;a bond or connection, as of affection, kinship, mutual interest, or between two or more people, groups, nations, or the like: family ties; the ties between Britain and the U.S. from https://www.dictionary.com/browse/tied &gt;connect; link. &gt;"self-respect is closely tied up with the esteem in which one is held by one's peers" &gt;synonyms: link, couple, connect, relate, join, marry, wed from Google. This isn't at all tied to my understanding. I'm just showing that the original poster is at least sort of technically correct and so people seem to be being very picky.
Regarding your second article: http://troubles.md/posts/why-do-we-need-the-relooper-algorithm-again/ One not-so-well-known thing about having structured control flow is that it allows you to generate SSA in linear time—in fact, you can generate it at *parse time*. By contrast, the dominance frontiers algorithm has high complexity. I'm not sure that this is something that matters for wasm, but it's worth considering.
Well... The syntax can be a bit of a punctuation soup for people coming from Python or Javascript. This is especially the case if you add in references, lifetimes, lifetime bounds, generic, trait bounds, etc. It always amazes me how much information Rust can cram into one function definition (although it always consistent and the basic rules are straightforward).
One can be connected to reality but let go of it. Someone else can be tied to a train track and won’t be able to get away. Not having ever considered doing this, of course.
The pointer to the buffer being set to NULL for some reason?
That sounds great. Thank you for doing this. It would be great to be able to do the following infov!("Calling foo"; x, y); This could be short for info!("Calling foo: x={} y={}", x, y); However it might also be useful to configure the output format so that log events are stored in json format or something similar.
But also it's important to keep in mind that readability and writability are not zero sum. For instance, function level type inference definitely improves writability and often improves readability.
take a look at [cargo-make](https://github.com/sagiegurari/cargo-make) it enables you (among other things) to run code coverage locally and in CI envs. kcov is support and it installs it for you automatically.
If we look at the documentation for YamlLoader (https://docs.rs/yaml-rust/0.4.2/yaml_rust/yaml/struct.YamlLoader.html), we can see the return type of `load_from_str` is `Result&lt;Vec&lt;Yaml&gt;, ScanError&gt;`. You then `unwrap` the `Result`, meaning `docs` has type `Vec&lt;Yaml&gt;`. So that's your return type.
What's the source on this? I would have assumed it was to say it is close to the metal.
People talk about readability but there are various component to it, that are sometime competing. For instance - can I understand the vague intent easily? - can I proofread the code easily? - can I understand the entire contract easily ? Rust is stellar at all 3.
Ah this is an excellent answer! I already use `cargo-make` I just had no idea that it already had `kcov` support built-in
Bit interleaving and deinterleaving lots of dimensions.
Is this different from [`Itertools::group_by`](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.group_by)?
Well even then, it is hard to say that fate of WASM is connected to Rust. Rust is leading the charge in showing the potential that WASM can have but I don't think Rust's WASM story is that critical to WASM adoption. Ultimately it depends on the browsers and how they decide to move forward with WASM.
Extension to what?
I did see that and tried it. I got an error. Let me try again and see what the error was. I think it was "undeclared Yaml type found".
You'll need to add `use yaml_rust::Yaml;` so Rust knows what the `Yaml` you're referring to in the function return type actually is.
Cool stuff, didn't know bots can auto fix on github actions
Now if we had pure functions, it would be more easy to reason about, a function that could make 10000 calls to other different functions.
&gt; Well... The syntax can be a bit of a punctuation soup for people coming from Python or Javascript. This is especially the case if you add in references, lifetimes, lifetime bounds, generic, trait bounds, etc. Is the alternative ("let's not worry about it until runtime") really more readable, if you are interested in understanding the program?
Probably VSCode. 
Haha. I wasn't planning to but I can chat about it if people want. It's a rewrite of rust-objc and the servo framework crates using some principles from objrs for static selector and class resolution and a significantly rustier API surface than the servo framework crates. Wasn't planning on making a release/making it public until I proved the model a bit more (and inviting the objrs and rust-objc guys for comment) but it all works so far.
Well, that would have been handy [last week](https://github.com/Freaky/cw/blob/ab173b962442426f52fe78f57ae927dcc98a8373/src/count.rs#L87-L129).
To be pedantic, yes, I think. To me reading it doesn't inherently have to mean perfect, full understanding. I think reading it is more akin to expected behavior. The less syntax soup you run into, the more you can get to the understanding of what the program/function does. On the flip side, fully understanding the program is easier in something like Rust. I have less (mental) memory overhead when reading Rust than I do Go, because I'm not having to mentally tally what is a pointer, is it a "safe" pointer *(ie, have I checked for nil yet)*, is it a thread safe action, etcetcetc. So my wording may be wrong, but I definitely think an argument could be made to how rust may be easier to understand than, say, Go, but more difficult to read.
You should probably add a link to GitHub Actions to provide context in the repository; it took me a while to figure that out. (I got in line for the beta; it looks like a useful tool!)
Nice. Thanks
The invisible unsafety basically extends to anything the unsafe code ends up relying on. That includes things like: * Invariants broken from other modules, since modules have access to the private parts of their parent module (and so on). There's also `pub(in module::path)` but at least that's visible. * Any function or value the unsafe code relies on. For example a `len` function for some container returning a wrong value can lead to bad things when unsafe code relies on it being always right. * Loads of things can panic. In some circumstances, even assignments or variable declarations. That said, highlighting unsafe code and its changes still has big value. Because for one it's the membrane that things must somehow go through to become unsafe. But also because they contain important and very-bad-when-wrong invariants that might not be otherwise visible.
&gt; EDIT: I got the playground link wrong. Silly me. It's fixed now.
Yes, you were correct. Thank you so much for your help.
vs code
Maybe there isn't one for you. Without some context it's hard to give you any reason :) I'd say, if you do coding in general, then it makes sense to look at what other languages are doing, and Rust is one of the most interesting ones to come out in recent times. I almost code nothing in Go these days, but I decided to pick it up as my first non-functional language a few years ago (apart from JS -- JS is everything, Go is specifically imperative), and I am a better coder now because of it.
If you at first you don't succeed, just wait and come back later. I have started to learn Rust three or four times now (coming from JS&amp;Co, Elixir, Go); and only this last time did I manage to pull through and actually start producing (semi) useful stuff.
How did you decide which does what and when?
Mmm, I am not the kinda guy to stop and come back later on. I will push through. Even if it will take some time before it "clicks".
Rainbow brackets for intellj 
Go for it then! You got the best written introduction to a programming language that you could hope for in your hands. Dive in :)
Absolutely, the Itertools method use a key to compare elements mine works like, say, [`slice::sort_by`](https://doc.rust-lang.org/std/primitive.slice.html#method.sort_by), it uses a comparison function. Itertools works on every Iterator type, mine just work for immutable and mutable slices, which is the power of this library, it is fast thanks to [data locality](https://en.wikipedia.org/wiki/CPU_cache#Cache_miss).
I will, tomorrow in the evening. Upcoming weekend will be alot more learning! I am so excited!
I'm confused here: &gt; You can, of course, add liveness analysis metadata to the machine, but that liveness analysis is only useful if your code is in SSA form - if it’s not SSA form then the liveness is extremely coarse-grained. Why is liveness on not-SSA-form more coarse-grained? Regardless of registers being mutable or static I would assume you end up with (1) attaching information at the beginning of basic blocks of what registers are alive (i.e. read somewhere after this block runs) and (2) internally inside a basic block tag the instruction where a register is used for the last time. How does the fact that the registers are mutable change the representation?
I think the only reliable answer for something like this is to [write some benchmarks](https://doc.rust-lang.org/unstable-book/library-features/test.html) and measure. The upside is that once you have benchmarks in place, it's easy to re-evaluate your choice when requirements change or when a new implementation becomes available. Here are two of the implementations I've heard of, that you might want to compare to the stdlib implementation: - https://github.com/Amanieu/hashbrown - https://github.com/bluss/indexmap
Hmm, if I create a new project it indeed works fine! Interesting.
Thanks. Any general advice you wouldn't mind sharing, having gone through the process?
Awesome. Happy to have you there. We're based out of Citrus Heights.
I can assure that I at least will be there. It's being hosted by a company as opposed to a single person so that probably helps in logistics.
While useful, I don't like adding commits to repos for fixing things. It makes cherry-picking harder since they're missing their end results. Is it possible to instead amend every commit in a PR with formatting fixes and force-with-lease push the fixed up code back to the PR with a GitHub Action?
I'm used to using the type inference of Haskell to annotate top-level functions. Just leave off the annotation and `intero-mode` parses GHC's recommendation of adding it and provides a keybinding. Now let's say I have a rust program and I want to factor out a bit and I'm moving some stuff to the top level and defining it as functions. I'm forced to figure out these types in order to do the refactor, even though I know the type inference engine can already do it. What I'd like to do is just to reliably get an error message that I can copy the type out of it. (Maybe I'll put the functionality into `rust-mode` at some point.) It's also not really so easy for me to write the type annotations because I have only been using rust for a few hours. E.g. I have an optional containing a tuple containing 4 values of different types, and I don't know even what the optional type annotation looks like. Also on principle I don't like doing things that the computer can do for me. So: is there a trick to make rust output the type reliably?
The funclets proposal refers to Braun et al's SSA construction algorithm, in contrast to dominance frontiers: https://github.com/WebAssembly/funclets/blob/master/proposals/funclets/Overview.md#ssa-construction I [implemented](https://github.com/rpjohnst/dejavu/blob/a3b0981/gml/src/front/ssa.rs) this a while ago and I believe that Cranelift/Cretonne does as well. It's not linear, and IIRC in the presence of certain kinds of control flow it requires some extra cleanup to generate optimal SSA, but it does work at parse time.
I hope to write a blog post once I have time to make further progress on this. I need to fix some issues in the port of the libc crate, where I just assumed Minix is identical to NetBSD (Minix is using NetBSD's libc, so hopefully that's mostly true; but not entirely). Then, assuming std is still compiling, I can try porting a more interesting Rust program than "hello world". Including possibly trying to port rustc and cargo to Minix.
Declare function as returning `()` - then you'll get a type error. Although a 4-tuple is pretty big already, so if it repeats more than once, consider making a dedicated struct with named fields. Alternatively, if it's a private function that's only going to be used in one other function, you can make it a lambda and assign to a local variable - then the type inference kicks in, and you don't have to annotate anything. And option type in Rust is `Option&lt;T&gt;`, where `T` is the inner value type (e.g. `Option&lt;(uint32, uint32)&gt;` for a tuple of two uints).
&gt;My complaints is about not having pure functions. i think it does pretty well with the side effects usually being visible through passed mutable parameters in the 'global-less' style of programming that it encourages.. but true purity would be nice aswell I agree. I think they used to have it but simplified the features?
I really can't agree with this proposal. Infinite register machines are way nicer to generate efficient code for, since you don't need to manage order, and converting that back into SSA isn't all that hard, especially with structured control flow as per /u/pcwalton's comment. It's worth being explicit here that one of WASM's main concerns is being small, since it's to be fed in large quantities over the internet. Stack machines are incredibly efficient when variables are consumed exactly when they are on top of the stack, which is why they make sense inside expressions. When you're interleaving these things, directly addressing them by name is much cleaner. Reordering would be necessary without locals, but that complicates compilation in its own ways. Explicitly listing variables that get carried between blocks works, but you sacrifice code size compared to just letting the JIT reconstruct it. --- As to part 2., I fully agree that more powerful control flow would be useful. This is on the post-MVP consideration roadmap, though, and structured control flow is still useful for optimizations. The issue is simply that irreducible constructs are harder to compile. For instance, &gt; I can also say further that if irreducible constructs were to be added to WebAssembly, they would not work in TurboFan (V8's optimizing JIT), so such functions would either end up being interpreted (extremely slow) or being compiled by a baseline compiler (somewhat slower), since we will likely not invest effort in upgrading TurboFan to support irreducible control flow. That means functions with irreducible control flow in WebAssembly would probably end up with much worse performance. https://github.com/WebAssembly/design/issues/796#issuecomment-298268883 
Why should someone use your library instead of [uuid](https://crates.io/crates/uuid)?
&gt; Any function or value the unsafe code relies on. For example a len function for some container returning a wrong value can lead to bad things when unsafe code relies on it being always right. Is this something that could become a guideline - with a hazard that can be warned about. i.e. if an 'unsafe module' doesn't depend on external modules, it could be considered 'more safe' once debugged, and vice versa an unsafe module that *does* depend on external modules is considered 'less safe'. -&gt; might it always be possible to seperate out the behaviour into layers such that the unsafely is genuinely contained ? a simple example being : throwing bits of unsafe into buffer intialization (mixing logic/calculation and pointer manipulation) , versus making an (integrally unsafe) initialisation function that takes a safe lambda to generate buffer content
Along those lines, why not add `shorter-uuid` as a new [adapter][1]? [1]: https://docs.rs/uuid/0.7.2/uuid/adapter/index.html
If you would read the submission title you would know, that this uses `uuid` and only provides alternative string representation of UUID. 
Vim has it two (several of them, actually). This is such a popular and useful feature that I believe most popular editors will have it either as core functionality or as a plugin.
It should be a standard feature in every editor, tbh.
Well, I want to write programs to automate some stuff which take me way too much time at work. I am a network engineer so configuring switches routers and such costs a lot of work. I can half the time I am configuring a switch. When that time is halfed I have more time for the customer and planning our network.
How does setting a pointer to NULL work?
Thanks! Appreciate the wish &lt;3
I implemented rust_decimal it does error handling too. I guess I am save now and my lib can be used at CERN :)
You should implement [ShortUuid.parse_str](https://github.com/seigert/shorter-uuid-rs/blob/master/src/lib.rs#L251) by implementing the [FromStr](https://doc.rust-lang.org/std/str/trait.FromStr.html) trait And if you have an alphabet, by splitting in two distinct type, for instance, maybe there is another way, You could also replace the [from_uuid](https://github.com/seigert/shorter-uuid-rs/blob/master/src/lib.rs#L210) by the [convert::From trait](https://doc.rust-lang.org/std/convert/trait.From.html) 
IME, reading the actual code is almost never the problem. What seems more important is (1) knowing where the code fits in the overall picture and (2) non-opaque function names etc... That's more about writing adequate top-level documentation and using an IDE with quick reference to function and object level documentation.
I've written a Rust program that translates WASM code into LLVM assembly, and I've dealt with this issue. Translating locals into SSA registers is complex--but it's not as hard as this article makes it out to be. The hard part is dealing with WASMs complex loop breakout system in relation to this problem!
At the start of a project when you're not sure, put all code into a single file. Once that file gets hard to navigate decide on some code that's conceptually grouped and split that into a module of its own. As you get a better sense of the conceptual organization of the project it becomes appropriate to create new files ahead of time.
My experience is quite the opposite; that it makes code more cluttered, and it's need is a code-smell indicating that the function is too big, or that types depends on too many other types. However in recent years I've coded in duck-typed languages a lot, my opinion might be a bit skewed from that. Do you have an example of a piece of code where inferable type annotations inarguably improve readability?
A mutable register may be considered live (read from later) despite it being overwritten before that read. SSA liveness information, in contrast, applies to the values *in* the registers. Re your edit: yes, SSA on its own doesn't have liveness data... but that's exactly what the post is saying- you can "add liveness analysis metadata" on top.
The issue with both `FromStr` and `From` that they allow only one parameter for their methods (i.e. `&amp;str` and `Uuid`). That would require to 'fix' some Alphabet like `BASE57` in those trait implementations and I'm not quite sure it would be good solution without some means of changing it via features or something like that. 
They should not, of course. This crate uses [uuid](https://github.com/uuid-rs/uuid) internally. 
It's absolutely possible OFC. I just wanted to try to implement something like a standalone crate in a separate, say, space. 
Sorry, yes that's what I meant.
I find that hard to believe, are you telling me that you can cause a segfault if you use Box and Vec intentionally incorrectly?
Thank you for your response! I have searched through the documentation but something is off. `AstNode` is defined (here)[https://docs.rs/comrak/0.4.0/src/comrak/nodes.rs.html#381] for me, which is not like in your chunk. I have not been able to find the code you pasted. Where is that from? I also found (this)[https://crates.io/crates/arena-tree] but that seems no good. The root node of the document returned by `parse_document` is a I `comrak::arena_tree::Node`, but it does not have a `next` method for me (even though it would panic according to your snippet). Shouldn't it? I am definitely misunderstanding something.
It might be a good idea to make the struct inner data private and add a builder that check for below absolute zero and not-a-number values (infinity ?). Also why did you choose datatype f32 over f64 ? It would be more precise and this is the default Please note that I am a new rustacean so I am not sure if my opinion is relevant. Thank for the link, for a beginner like me it was interesting to read because I was able to see small implementation of traits and macros.
Nice work! Have you considered adding corresponding `*_group_by_key` methods? And maybe even just `*_group` using `PartialEq`, to make it consistent with `binary_search[_by[_key]]` from the standard library.
I am a noob myself. Often I don't know that an approach leads to issues and sometimes I just do things out of convenience becasue I want to learn something else. I had thought of a simple temperature converter. /r/rust told me to add Decimals. Never thought of any uses that needs that precision. Maybe I'll change that. I'll change the instatiation process too.
You can eliminate a lot of repetition and boilerplate: You created the trait `AbsoluteZero` with only one method `is_baz`. This method is **only ever** used by yourself to **validate the input** in a `TryFrom`-conversion. Thus, you needed to copy-paste this check 12 times. If you create the **invariant** that the value of a temperate never below zero, you can get rid of all those checks entirely. To accomplish that, you have to make the `value` field of each temperature-`struct` private and a `new` function that returns `Option&lt;Self&gt;` and optionally an `unsafe` `new_raw` which does not check the condition. Now, you can remove `AbsoluteZero` because it's unnecessary. If I am not mistaken, you might be able to impl `From` instead of `TryFrom` since `BelowAbsoluteZeroError` will never be thrown with our new invariant! Instead, create a trait `Temperature` with e.g. `ABSOLUTE_ZERO`, `SYMBOL`, `new`, `new_raw`. Why? Well, this just collapses four `impl FromStr` into one and makes the macro `impl_display` obsolete. In an older commit, I saw that your `ABSOLUTE_ZERO` was of type `&amp;f32`. No need throw in a reference, `f32` is cheap to copy! Is there a reason why [you prefer `.ge()`](https://github.com/aspera-non-spernit/temperature/blob/68d83dc5a32b6be66511de4d17f0b9615863fbeb/src/lib.rs#L26) over `&gt;=`? [In this line](https://github.com/aspera-non-spernit/temperature/blob/68d83dc5a32b6be66511de4d17f0b9615863fbeb/src/lib.rs#L38), you have a special case for the type `Kelvin` not being preceeded by `°`. The issue: This happens at runtime! Despite being decidable at compile-time (since it's a type). I think it's better to use a constant `SYMBOL` to store this information. I am not really familiar with `rust_decimal` but I'd avoid [using `from_str`](https://github.com/aspera-non-spernit/temperature/blob/68d83dc5a32b6be66511de4d17f0b9615863fbeb/src/lib.rs#L219) unless absolutely necessary. Use the `new` constructor so there is no runtime-overhead. The macro `into_dec` seems a bit too much and also allocates a `Vec` (heap!) needlessly: `5` and `9` are constants, they shouldn't need to go through a Vec-allocation and be parsed from a string. Use `Decimal::new(5, 0)`. I am not sure whether the commit I am currently checking out is out-dated. Otherwise, if you make use of `rust_decimal` then `f32` can be replaced entirely with it. Only so, you lose the disavantage of base10 rounding errors. --- [Link to a playground where most of the stuff I was writing about is implemented](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=76cd4db2d498a88189ef407e29c7cfb8). [Link to `lib.rs` at the time of this writing](https://github.com/aspera-non-spernit/temperature/blob/68d83dc5a32b6be66511de4d17f0b9615863fbeb/src/lib.rs). --- **I hope I didn't sound all to harsh. Just wanted to share some tips. Greetings!**
I did not considered that, because I have no time to do so but I have already done the most generic functions and `*_group/*_group_by_key` functions can be implemented on them. Pull Requests are welcome :)
It depends if you're writing a library or binary, or if you've got many people working on it, a few, or only yourself. It also depends on what tools you are using to navigate your code. For instance, if I am working on something by myself at home, I use a flattened hierarchy because it presents better in my Sublime Text navigator panel, all modules are private and everything is reexported at the root (except for any submodules which contain 'building block' code which I maybe want to provide externally,) and there's no reason to split the crate unless I want to test it independently.
Thanks, I'm reading over these other responses. It looks like it's quite an undertaking to implement proper streaming I/O with actix\_web, so I might just consider either doing it sequentially (which will introduce a block) or async but all it once (not sure how to do that either but I'm guessing it's easier than the example below). &amp;#x200B; I'm not really sure how to represent this at the language level, but I do feel like there's probably a better way that this could be represented than the existing libraries seem to provide. Even in lieu of async/await (although that would be immensely helpful, but I've been trying to keep things on stable).
Can you link to ranking site of you? :)
&gt; It depends if you're writing a library or binary Could you elaborate on that?
I did it this way before, but after while It ended up in refactoring and asking the compiler for missing imports (I don't use `*` at all besides quick tests) 
That code example is not straight from the source - I wrote that just to show what the module structure is and to explain how you got a `NodeEdge`, even though `NodeEdge` does not appear anywhere in the docs. The point is that: * neither `Node` nor `NodeEdge` is publicly exported - they are marked as `pub`, but the module they are in is not, so they are not in the generated documentation. * `Node` is actually sort-of visible because it is referred to with `comrak::nodes::AstNode` (and in the real code there are a few extra type parameters), but it does not have a generated docs page and so you can't click on it in `AstNode` docs. * you can get `NodeEdge` through `Iterator` impl for `Node`, but that impl is not visible anywhere in the docs because `Node` itself does not appear in the docs.
In a binary it's less important that your modules be private, and you never really have to re-export anything.
Personally I use [cargo-tarpaulin](https://github.com/xd009642/tarpaulin).
Right. Good. As it should be. That's the time to slow down and reflect on organization. If you can't make sense of it now, how will someone else? Never forget: "someone else" also includes "you in 6 months". 
Does futures\_fs use the current\_thread runtime? Or is this something that's implicit in the types so it will stop me if I use a library that uses the wrong runtime?
If you want to consume the `Vec` you are appending from, use `&lt;Vec as Extend&gt;::extend` instead. let mut v1 = vec![1, 2, 3]; let v2 = vec![4, 5]; v1.extend(v2); assert_eq!(vec![1, 2, 3, 4, 5], v1); &amp;#x200B;
/r/playrust
That's a behaviour of the allocation system. I don't know _why_ it does that, but if you switch the allocator to jemalloc, the data remains intact.
Does it compile if you move it into a different folder and compile with rustc? Could be something with the permissions.
This, is, AWESOME!
Huh, this is neat...I never thought of doing something like this before. 
I gave implementing it a try, but since the `*GroupBy` types are generic over the predicate type `P`, I don't know what the return type of e.g. `linear_group_by_key` should be... I guess it would have to be a new struct called `LinearGroupByKey`, but I don't see how that could then forward to `LinearGroupBy`. Any idea?
It is possible to produce a segfault of _a method of Vec_ is written incorrectly. We do not have direct access to modifying `Vec`'s `length` field - _methods defined on `Vec` in the same module do_. For instance, if `Vec::push` had a bug where it incremented `size` twice, that wouldn't require an unsafe block because it's just modifying a regular field. But then that bug would allow consumers to read undefined memory since the vec now has an incorrect `size`. ---- This is purely about non-unsafe methods defined in a place that gives them visibility into private things used by other unsafe methods.
`futures-fs` uses a dedicated and separate threadpool for file operations. When possible, using `tokio-fs` should see better performance because of less message passing.
The catch to punctuation soup is that the punctuation isn't changing how you should read the program, only what the compiler will do with it. You could obfuscate functionality in the punctuation, but who expects to read obfuscated code? If you're trying to read code and care enough about the specifics of how the compiler interprets the punctuation, you should already know what each punctuation does. The only people that benefit from less punctuation soup are the people that want to use the language without learning it. Rust isn't an instructional language; it'll never replace python or scratch, nor should it ever try.
I think if you want to add methods to the `GroupBy` trait you will need to move the `P` type to each funtion that needs it (i.e. The current ones). New methods that you want to add will have their own generic type bounds like `where T: Ord` or something like that. I don’t have a computer at the moment, I will take look in some hours ^^
I think if you want to add methods to the `GroupBy` trait you will need to move the `P` type to each funtion that needs it (i.e. The current ones). New methods that you want to add will have their own generic type bounds like `where T: Ord` or something like that. I don’t have a computer at the moment, I will take look in some hours ^^
&gt;My complaints is about not having pure functions. No, const fn isn't designed to be pure. Now if we had pure functions, it would be more easy to reason about, say a top level pure function that could make 10000 calls to other different functions. I'm not following your reasoning. It can support most pure functions easily; they're just not in the standard library.
cargo-make supports it as well :)
I just wanted to point it out explicitly, because one may not need a full make tool :) 
The backslash escaping may be the problem according to [this post](http://dool.in/2009/03/20/link-fatal-error-lnk1181-cannot-open-input-file-c-program-obj.html). I wonder if you're using a rustc or cargo expecting a MINGW shell (and thereby escaping backslashes). Just a guess.
here is the solution: ``` fn linear_group(&amp;self) -&gt; LinearGroupBy&lt;T, fn(&amp;T, &amp;T) -&gt; bool&gt; where T: Ord { LinearGroupBy::new(self, |a, b| a == b) } ```
Right, I already did all of that, but the return type of the new methods still seems to be unnameable.
So then as we stated originally, the input is correctly validated before access is allowed. You can pass anything to Vec/Box types and it won't cause segfaults. It is a safe interface that validates all possibilities.
re: The "Why?" section -- why not re-design WebAssembly now, before it's too late? I know people will say that it's "too late" now, but frankly it's not as nothing outside of spec academia and some trial implementations actually uses it.
How would that annotate a closure?
This is determined by the workflow. Github uses the \`needs\` to build dependencies between actions. &amp;#x200B; As long as fixers are chained together, they may be put in any order. Fixers might as well be a linter if you don't want them to fix anything, and all linters are allowed to be executed in parallel.
Having a frozen alphabet from those implementation sounds not stupid, and rename your specialized implementation like \`from\_str\_with\_alphabet\` ? &amp;#x200B; I never used shortuuid at all, so I am not sure to see the use case for having many alphabet, and to switch from a shortuuid of one alphabet to another.
Of course, as with naming it's a balance. No types makes code very dense and almost impossible to understand without an IDE, while of everything had types you end up with massive amounts of clutter
The point is that a bug in `Vec::safe_method` can induce `Vec::unsafe_method` to cause a segfault or memory corruption because code within the same module can bypass any validation you might intend to do and directly twiddle private members. Hence, the point that you have to keep an eye on the entire module to use `unsafe` safely.
That seems non-trivial to support, specially with the idea of allowing multiple fixers to be setup on a project. &amp;#x200B; GitHub Actions are not triggered again after the fixer is pushed, so each fixer would need to pull the latest change and push all the files of the previous commit as well. &amp;#x200B; It might be feasible to be done, but it is not a flow I would be able to create anytime soon. &amp;#x200B; Out of curiosity, would using `git fetch origin refs/pull/9/head:pr &amp;&amp; git merge --squash pr`, or even change the merge button on the PR to use squash helpful on this cherry-picking workflow? I'm not a big user of cherry-picks to know how to understand the impact of multiple commits on a branch.
You said: &gt;Adding an environment variable hasn't fixed anything. Can you tell us what environment variable you set? You also said: &gt;`rustup update stable` doesn't work either. Can you tell us exactly what didn't work? Did `rustup` give you an error? Can you show the output of `rustup toolchain list`? Can you try using a regular command shell (not PowerShell)? I don't think this will matter, but it can't hurt to try.
Thank you very much. That was what I wanted to fix next. The repitition, but I had problems with different types returned from the macro. I tried several things. Also had the value of abs zero as part of the temperature once. I will try to implement your solution. Thank you very much. 
/r/playrust my friend. 
What does function size have to do with types for variables?
Now I'm envisioning something like a syntax highlighter for Rust, which also provides further explanations of what each little bit of syntax means when you hover over something. That would be handy for any language, really.
It's been a while but, from what I remember from lurking in /r/rust/ at the time, pure functions turned out to not be as useful as expected.
I think I also remember people saying that everyone had a different definition of purity
I don’t really know anything on the area, but I’d guess having only pure functions requires immutability, which requires a lot of memory copying around, which is not suitable to a systems programming language.
You should probably not create new Iterator types but rather keep the current types and use the comparison function you want (i.e. `PartialEq::eq`). In the other case you will have to duplicate the whole algorithm *or* create a new type wrapping the generic Iterator, it could work too.
When I saw the lots of `'a`s and `'b`s on a more complex code, I thought *what the heck is going on*. I’d like a lot to understand and to write correct Rust, but I just don’t seem to be able to correctly grasp lifetimes.
I hadn't thought about using `fn(&amp;T, &amp;T) -&gt; bool`, but that wouldn't work for `linear_group_by_key`, would it? The `(&amp;T, &amp;T) -&gt; bool` closure needs to close over a given `Fn(&amp;T) -&gt; K` closure, after all.
This is for rust the programming language, your probably looking for https://www.reddit.com/r/playrust/
😂😂😂😂 Indeed sir, thank you and sorry for the confusion. 
You should hace a look at another function by me on the standard slice type that will answer your question :) https://doc.rust-lang.org/src/core/slice/mod.rs.html#1758-1763
I'm Wayland user and I fab about idea to write Wayland on rust, if u need any help, please let me known.
I'm Wayland user and I fab about idea to write Wayland on rust, if u need any help, please let me known.
I'm Wayland user and I fab about idea to write Wayland on rust, if u need any help, please let me known.
np, common mistake
np, common mistake
I'm Wayland user and I fab about idea to write Wayland on rust. if u need any help, please let me known.
I don't *think* that answers it? I had the method body down, the problem was the return type since it can't be `LinearGroupBy&lt;T, fn(&amp;T, &amp;T) -&gt; bool&gt;`.
I'm Wayland user and I fab about idea to write Wayland on rust. if u need any help, please let me known.
Sorry for spam it's a app lag
Sorry for spam it's a Reddit app lag
Its a handy practice. At my work, almost every function in our C++ codebase has a macro in it to trace function entrance/exit with exit state (failure or not). It makes debugging really easy when you have the context of the timeline up until an error occurs.
Code dealing with too many concerns often blow up in both the amount of types, size of the data structures, and size of the functions. In particular, size of function roughly correlates with the amount of (type-inferred) variables in it.
Can't deny, this gave me a chuckle. Have a good day :)
My RustConf 2018 talk is supposed to be about this, it covers how I go about evolving projects. https://youtu.be/2uBbjq-Trnk Feedback definitely welcome!
If you can't afford pants, try borrowing them (non mutable).
Yes, but we're not talking primarily about Vec, but about unsafe in general. The same situation applies to any crate which has _any unsafe_. In a crate with at least one method using unsafe, code changes to entirely safe methods can cause that unsafe code to error. Vec is a safe interface because _none of the methods have bugs_ that we know of. If any method did, including the 100% safe ones, then we could get segfaults. The individual method's use of `unsafe` or not doesn't matter as much as it having access to a structure relied upon by other unsafe methods.
&gt; In a crate with at least one method using unsafe, code changes to entirely safe methods can cause that unsafe code to error. If the unsafe usage is globally affected by changes anywhere in the entire crate then I would argue that the crate was designed incorrectly. The crate should have internal APIs around any unsafe usage that validate that usage.
Yeah. That sounds familiar.
Sorry for the inconveniences, the environment variable was the path variable and a parh to the link.exe, rustup update stable did plain old nothing, no errors it just printed out the default installation message, as for my toolchain i believe i only had the default mvsc x64 one. Ive tries running on cmd and the git for windows console but it yields the same results
I have only tried compiling with cargo run, but i have tried compiling it in several different locations and the results were the same
Best thing for reading Rust code: an IDE that can do the type inference. IntelliJ shows it all by default, but I have that turned off so that it won't show variable types by default. Instead, whenever I'm unsure about the type, I click the variable and press Ctrl-Q, and it shows it.
I believe you’re looking for `std::iter::Iterator::find` ([docs](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.find)). It traverses the iterator for an element that matches a predicate and returns the first one to match as `Some(Element`. If all fail, then it returns `None`. The type is `Self::Item`. So any iterator that uses references would get the behavior you’re looking for. 
Right, I agree. I guess it's my opinion that the only crates which should use unsafe at all are those which revolve around doing something unsafe? If a crate has one or two unsafe usages that are isolated from the rest of the codebase, it's true that they shouldn't matter. But if they're actually fully isolated, I would argue they belong in a separate crate which provides whatever abstraction they achieve. I guess that's a second, different argument though. I concede that if a crate is using a bit of unsafe and it's isolated from other sections of the crate, those other sections can't break its invariants.
This is gonna save so much time, and it looks so clean.
Wrong subreddit, go to /r/playrust 
message passing.
Thanks I couldn't really tell if this was the right subreddit or not.
Power goal: Run this on an ARM cpu, which has a rather different set of design tradeoffs, and see what happens.
The "community details" box on the Reddit web app view (at least whatever one I'm A/B'd into) of /r/rust says: &gt; For everything related to the Rust programming language—an open-source systems language that emphasizes safety, performance, and concurrency. Just out of curiosity, are you using, e.g., one of the mobile apps? You wouldn't believe how frequently people mistake this subreddit for the Rust game subreddit; I'd love to better understand how/when the confusion usually happens! :) 
You are one of the very few who at least excuses for the mistake. 
**fluid is useful to me.**
You can delete this post.
Either way, I like Rust and I like wasm. 🙂حج
Dude, you can delete your comments, you know....
recently I got the bracket pair colorizer for VSCode. But I couldn't get it to match angle brackets `&lt;&gt;` even after digging in the config a bit...this would make writing complex generic types soo much easier.
Previous discussion [here](https://www.reddit.com/r/rust/comments/ah85lu/when_rust_is_safer_than_haskell_fp_complete/).
Does the \[ggez\]([http://ggez.rs/](http://ggez.rs/)) library provide what you're looking for? Or perhaps the examples?
The spaces in "Program Files (x86)" shouldn't normally cause issues because the paths are quoted. That's also what 99.99% of vs2017 installs look like and if it doesn't work then nobody would've been able to use the msvc Rust toolchain on Windows. I think you might want to check and clean up the PATH variable a bit (you can test it by setting the PATH for only the current shell instead of system wide). Also try nuking the rustup install completely and reinstall it.
I've been looking into using that. The examples don't really have that much, but it's the best I've found. 
To access something from the parent module, you need to use `super::`. So in this case, `super::faa`.
I get I have to do that, but I don't understand why. Why is it limited to the parent scope(almost like it was a function)? Let's say I have a bunch of child modules where I would like to access `fee()` , but I don't want to be writing `super::faa::fee()` for each module. Is there any way to get around this? Wouldn't it be nice if the `use` statement would spread down the childs?
I created a new project with three files: * lib.rs: &amp;#8203; mod foo; * foo.rs: &amp;#8203; mod bar; use bar::b; pub fn f() { b(); } * foo/bar.rs: &amp;#8203; pub fn b() {} This compiles fine, but the `b` from `b()` is colored red in the editor because "Unresolved reference". Could you try this out?
I think this is very handy, but isn't the name of the crate a misnomer? it's not a derive macro (which are macros that derive code for structs / enums), but a macro that you apply to a function instead
It's relatively rare to have multiple modules in the same file, so this usually isn't an issue. If there are a large number of imports it might be worth making a `prelude` module which reexports commonly used definitions.
Yep, 5h later I can do it, unfortunately exactly after lag I couldn't remove them.
It doesn't really make sense to generate bindings from an un-managed language (eg. C, C++, Rust, etc.) to a managed language (eg. Python, Ruby, JavaScript, etc.) because the managed language's runtime will so significantly affect the architeture of your program that it's misleading to call them bindings. There are basically two ways you can combine Rust and Python code in the same program: 1. Do the frontend in Python and write Rust libraries that can be `import`ed from Python. (This is what I prefer when feasible. [rust-cpython](https://github.com/dgrunwald/rust-cpython) supports this on stable Rust and [PyO3](https://github.com/pyo3/pyo3) provides a more comfortable API but requires unstable Rust. [setuptools-rust](https://pypi.org/project/setuptools-rust/) allows you to integrate either into `setup.py`.) 2. Embed a Python runtime in a Rust application and use things like this example line from the rust-cpython README to call Python code: let user: String = py.eval("os.getenv('USER') or os.getenv('USERNAME')", None, Some(&amp;locals))?.extract(py)?;
&gt; Wouldn't it be nice if the use statement would spread down the childs? It would defeat the whole point of `use`, which is twofold: 1. Help to make it clear where symbols are coming from, so it's easier to familiarize yourself with a new codebase. 2. Prevent naming collisions. (ie. You don't wan't to be back in the position C programs are in, where you write `my_foo` because some dependency already declared a `foo`.)
Perfect, I love it!!!
Oh, you mean the voting site for new stream ideas? Or something else?
Yes, for the ideas
Thank you for your response. Okay, so I get an iterator for the `NodeEdge`s of the children of `Node` from `node.traverse()`? I can't find `traverse` in the module or as a trait anywhere. Unfortunately, I still havn't been able to find `NodeEdge` in the documentation either so I do not know what functions it implements. However I need to get `Node` from `NodeEdge`, which should be possible, no? Could you point me in the right direction?
A useful not Rust-specific idea is that *users* of a module prefer a flat namespace, while *implementers* prefer hierarchical namespace. So nested module structure plus a flat facade with re-exports as a crate's interface is usually a good idea.
pub(crate) use foo; That makes the "use" be visible across the whole crate, including children.
I wasn't aware you could do this. But yesterday I also came across something I didn't recognise. 'pub(in crate) use foo;'. Does this do the same thing?
Dunno, maybe that's old alternative syntax
Hmm, can apps like sway use this or would they need to be patched?
Thanks for the help! Basically, I'm trying to create a simple trait that defines a tree structure, which has to implement this: ```Rust fn parent(&amp;'a self) -&gt; Option&lt;&amp;'a Self&gt;; ``` My first implementation of this trait is for a reference-counted tree (using `Rc`). So all the nodes are owned by an `Rc`, and each node has a `Vec` of its children `Rc`s, and a weak ptr to its parent. ... and I think I just answered my own question. Initially I wanted to return the owned value of the `Rc` out through `fn parent(&amp;'a self) -&gt; Option&lt;&amp;'a Self&gt;`, as in I wanted to borrow the value out of the `Rc` and pass that borrow out from the fn. But now I'm thinking I can just pass the `Rc` itself, and consider the `Rc` itself to be the node, and not the *content* of the `Rc`...
"Do the frontend in python + flask - and it'll be trivial to interop with the device libraries." Do this one. There's not really any benefit to using Rust in this case. Stick to python (as you say - it will be much easier!). Find a project thst you can use Rust libraries for to try out Rust with :)
You're right - IntelliJ's plugin correctly recognizes `use self::bar::b;`, but not `use bar::b;`; I've never noticed that one myself, since I've always been using the `self::thingy` construction anyway.
Well, this is a rust crate exposing a rust API. Changing sway to use it would basically mean to RIIR sway. However, if you are interested in making a wayland compositor in rust, you can check out [smithay](https://github.com/smithay/smithay), which is a wlroots-like project, but in rust, built on top of wayland-rs :) An other thing I've considered but currently didn't really clearly started working on, is building a C api on top of the internal rust implementation. This would make it possible to replace the system wayland libraries by a rust implementation. If this interests you, I'd put my ideas about it in [this issue](https://github.com/Smithay/wayland-rs/issues/189).
agree for the example case a combination of [`Iterator::find`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.find), [`Option::ok_or()`](https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or) and the `?` operator make a good combo like this let tue = days.iter().find(|&amp;day| day == "tue").ok_or("no match")?; 
I could not find this in the rust book. If you have two attribute-like macros on a function, is one applied first and the result of the macro expansion fed to the other? Which of them is applied first? Does the intermediate result need to semantically valid or only the final result?
It doesn't work with nightly that well as far as I can see. If I have that option enabled I get weird mismatches with crates compiled with wrong compiler versions as I compile the project either in IDE or command line. Using rustup to override the project's toolchain to nightly and normal compilation in Idea uses nightly but it's like it uses the stable toolchain's cargo check to analyze code.
IntelliJ Idea's and CLion's Rust plugin can do that. It's a quick fix you can do by pressing alt + enter while having the cursor on the variable name.
Did your compiler work on a stream? I think the author argues that locals are mainly a problem if you build a streaming compiler 
Very cool! Also thanks for linking to &lt;http://www.redblobgames.com/grids/hexagons/ in the code, that's a resource I really wanted to stumble upon! 
Hi, if you want to write wayland apps in rust, and help us get things rolling, there are basically 3 repos you can have a look at: - [wayland-rs](https://github.com/Smithay/wayland-rs) is a set of crates that deal with the protocol itself, and the integration of protocol extensions. This is kinda the low-level project everything else is built on top of. - [Smithay's Client Toolkit (SCTK)](https://github.com/Smithay/client-toolkit) is, as its name hints, a toolkit for writing client wayland apps. It hides away most of the wayland protocol boilerplate into as-easy-as-possible to use interfaces. - [Smithay](https://github.com/Smithay/smithay) is a library for writing wayland compositors, so it is kind of the server-side equivalent of SCTK. It has a similar feature scope as [wlroots](https://github.com/swaywm/wlroots), but a different design. On these 3 repos there is still a lot of things to be done, we try to expose them as well as possible in the various open issues. If you want to help, go ahead an check them for what inspires you. We'll be happy to mentor anyone trying to get into the codebases. :)
I haven't used Windows in a while but I think that GTK+ applications are usually distributed with bunch of DLLs. Keep in mind that if you're going to statically link GTK+ and related libraries, you need to comply with the LGPL license. What I understand, with static linking, you need to either provide the whole source code or just object files.
This is a bit cleaner if you use `crossbeam` instead of `thread::spawn`. The following code: fn secret(mut f: impl FnMut() + Send + Sync) { crossbeam::scope(|scope| { for _ in 0..1_000 { scope.spawn(|_| { f(); }); } }); } Will fail with the following error message: error[E0499]: cannot borrow `f` as mutable more than once at a time --&gt; src/main.rs:8:25 | 6 | crossbeam::scope(|scope| { | ----- has type `&amp;crossbeam_utils::thread::Scope&lt;'1&gt;` 7 | for _ in 0..1_000 { 8 | scope.spawn(|_| { | - ^^^ mutable borrow starts here in previous iteration of loop | _____________| | | 9 | | f(); | | - borrows occur due to use of `f` in closure 10 | | }); | |______________- argument requires that `f` is borrowed for `'1`
Give the pieces names with `type` definitions. So much nicer to read.
If I have a `fn` returning `impl Deref&lt;Target=Option&lt;Something&gt;&gt;`, can I turn it into an `Option&lt;impl Deref&lt;Target=Something&gt;&gt;`? I'm actually returning an `Option&lt;impl Deref&lt;Target=Option&lt;Something&gt;&gt;&gt;` and want to flatten the `Option`s...
* can be helpful during refactoring, and then you can ask rls to expand it for you.
Extend takes IntoIterator so it cannot just `memcpy` to destination - this is actual overhead which is paid for every call, no matter of context.
Yes it can, you just need to create a closure that maps the elements using the function given by the user `|a, b| f(a).eq(f(b))` and the return type will be `LinearGroupBy&lt;T, fn(&amp;K, &amp;K) -&gt; bool`. Sorry this is `K` not `T` :/
Go advertise your gambling pot scam on the actual play rust subreddit. This one is for the programming language, rust.
&gt; If I have that option enabled I get weird mismatches with crates compiled with wrong compiler versions as I compile the project either in IDE or command line. You mean that you get compiler errors like "this crate was compiled with a different compiler than the current one"? This sounds like a bug in Cargo: different toolchains should coexist just fine. The fact that there's no drop-down to select rustup toolchain for `cargo check` is a missing feature in IntelliJ: IIRC, there's a choice of toolchain for rust-configuration, but there should be a "default" project toolchain as well (preferably with watching for rustup overrides) for actions like "check" or "build".
Beacuse literaly every time I needed to use append, it was something like: ``` let mut to_append = calculate_additional_data(); main_buffer.append(&amp;mut to_append); ``` I will never ever reuse to_append in such cases. If I can afford to push to some `mid_vec`, then append it to some `main_buffer`, and then still use mid_vec, then probably main_buffer was all the time in scope, and I could push directly to it. I can imagine usecases when appending to `mid_vec` is beneficial, but all of them are rather very domain-specific. I never negate using Vec as buffer.
It's the [pub(in path)](https://doc.rust-lang.org/stable/reference/visibility-and-privacy.html#pubin-path-pubcrate-pubsuper-and-pubself) syntax.
You would think setting up a scam betting platform is more complicated than finding the right subreddit.
Yeah, that error. I have even set the toolchain location in Idea/CLion settings for Rust to `.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/bin` and still I get the errors if I have "use cargo check to analyze code" enabled.
I am not sure if this is up to date, but this might help you: https://gtk-rs.org/tuto/cross
Very nice. I do have one suggestion. I havn't looked at your code but the readme states that you generate: let mut closure = || ... Which got me wondering if Rust/LLVM could actually optimize this. It doesn't. Consider using fn fibonacci(n: u32) -&gt; u32 { #[inline(always)] fn _fibonacci(n: u32) -&gt; u32 { match n { 0 =&gt; 1, 1 =&gt; 1, _ =&gt; fibonacci(n - 1) + fibonacci(n - 2), } } let result = _fibonacci(n); ... result } For comparison you can look at the generated assembly [here](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=64d0b1cb809cae49618701383df8b6bc). benchmarks show 6.9 ms (fn) vs 7.4 ms (closure) for fibonacci(20) with printing. ( and 327 ps vs 29 us without printing). 
Aah, some people are good at different things.
The chapters in the 'Nomicon on lifetimes and variance helped me a lot (after The Book of course)
It's because mod creates a new namespace exactly the same way as writing all of its contents in a new file would. So because it act as its own file, you have to use things again.
Thanks for your support, I'm happy to hear that! I'm currently working on the next alpha (0.4) with some cool improvements: * Better handling of `case`s by generating a different function for each case, * Much more assertions, * Adding a modularity to my basecode to permit to write ones own assertions, And, coming soon, a feature to activate a custom test framework with the nightly compiler (see [https://blog.jrenner.net/rust/testing/2018/08/06/custom-test-framework-prop.html](https://blog.jrenner.net/rust/testing/2018/08/06/custom-test-framework-prop.html)). I wish to advance more quickly, but I have 2 little children, so I do not have a lot of time at home. Moreover, I still can't find a good way to structure my code, although I'm making some progress. If you have any idea of improvements, please feel free to post an issue or to talk about it in Reddit!
Rust pretty much always favours explicitness over convenience. It might be contentious to a lot of people used to the relaxed rules of dynamic languages, but it leads to safer and more predictable programs.
Be more declarative. Don't write "how to do" something, but rather "What you want to get". For example "I want walk over a slice". Okay, no prblm: `let xs = [1,2,3]; let iter = xs.iter()` "I want to filter all even elements" Why not? `let evens = iter.filter(|x| x % 2 == 0)` "I want first even element" Do it: `let first_even = evens.next()` --- Loops and so on aren't a `classic way`. LINQ and C# exist for almost two centuries, as well as others languages. `loop` approach was never classic in LISP neither.
On [Compiler Explorer](https://godbolt.org/z/RtsE9F)
*From the* [Wikipedia article on the LGPL](https://en.wikipedia.org/wiki/GNU_Lesser_General_Public_License#Differences_from_the_GPL) &gt;\[...\] if it is a "work that uses the library", then it must be possible for the software to be linked with a newer version of the LGPL-covered program. The most commonly used method for doing so is to use "a suitable shared library mechanism for linking". Alternatively, a statically linked library is allowed if either source code or linkable object files are provided. So you're pretty much spot on.
Great article. Thank you very much for sharing!
Makes sense, thanks for checking!
i tend to separate traits and structs from implementations early. errors in a mod and main in a separate project or in examples. never used re-export don't know what it is for even. not an expert.
As mentioned in a sibling comment, best benchmark it yourself. Criterion is a super neat crate for that, and most crates implementing maps have a similar interface. Also make sure to stress test the actual operations you want to perform, by ideally benchmarking your whole application with only the hashmap impl changing. If you do lots of inserts and deletes this might severely skew benchmarks in another direction as just measuring lookup time. `hashbrown` seems to be very fast, but depending on what you want to do an immutable data structure (like the ones in `im`) might be a better fit.
Why is the remote option constrained to three countries? (Just curious)
I am using CLion, and I love that the IDE shows the inferred type signatures :)
Nice write-up! We're also using this runtime (just updated to 0.2 yesterday) and it has been really smooth rolling this portion of our system out into production!
I believe that is the case, but i don't know ho to fix it, since most fixes are visual studio community fixes, any idea of where are these paths stored?
That was my whole point - you can't find `Node
No, this is not possible. You need a complicated directory structure with with a bunch of dll's and icons. What I did was create an msi installer. The app is ~22.4mb on disk, with only like 1kb being my actual app
I'm new to mutexes. What is the purpose of even having them with Rust? Reading about them, I thought they wouldn't be needed with Rust's ownership model.
That's a funny name! :)
The macro name, `logfn`, might be a decent fit.
Is there any reason to build your own linked list in cpp?
Do you mean picoseconds? That's approximately one clock cycle at 3GHz, which implies the function call optimised down to a constant. Quite possible, but also means this isn't at all representative.
Hmmm, I guess I haven't thought about it thourghly. It's just that there aren't lots of attribute macros out there so that's the first that got to my mind. I'll think about it, does crates.io even support name changing? And if so how does it work with backwards compatibility? 
Technically there's no nice way to do this, because `deref` isn't guaranteed to always return the same value. You could turn `&amp;impl Deref&lt;Target=Option&lt;Something&gt;&gt;` into `Option&lt;&amp;impl Deref&lt;TargetSomething&gt;&gt;` though - but that's basically the same as turning `&amp;Option&lt;Something&gt;` into `Option&lt;&amp;Something&gt;`. If you do need owned values, and know that `Deref` implementation behaves nicely (either always returns `None`, or always returns `Some`), then you could use this abomination: fn move_option&lt;T&gt;(x: impl Deref&lt;Target = Option&lt;T&gt;&gt;) -&gt; Option&lt;impl Deref&lt;Target = T&gt;&gt; { if x.deref().is_some() { struct DerefUnwrap&lt;T&gt; { inner: T, } impl&lt;T, U&gt; Deref for DerefUnwrap&lt;T&gt; where T: Deref&lt;Target = Option&lt;U&gt;&gt;, { type Target = U; fn deref(&amp;self) -&gt; &amp;U { self.inner.deref().as_ref().unwrap() } } Some(DerefUnwrap { inner: x }) } else { None } }
Welcome to the hell of cross-platform GUI development. I'd consider [Electron](https://keminglabs.com/blog/building-a-fast-electron-app-with-rust/).
I think the problem with the angle brackets is that it has another use case as a comparison operators. any way, there is another extension called "Rainbow brackets" you can try.
I see. I'm too new to the Rust ecosystem to properly grasp how it "should be", but I'm glad it was brought to light and the authors notified! Looks like I will have to come up with another hobby project though :) 
I've been writing a lot scala before I discovered rust, but I don't really miss FP much in rust since ownership and the borrow checker solve the same problem FP tries to solve. 
My issue is that there’s no reason to require this at all, it might be relatively easy but it’s unnecessary extra work. Plus, of course, streaming compilers cannot generate good code since it’s much harder to generate SSA while streaming.
In some cases you can't having a single owner for something is not possible or ergonomic. For example a buffer that `println!` uses - you want `println!` to be usable everywhere, but manually having to pass it a reference to the buffer would be very cumbersome. So this is one case where you want sharing *and* mutability - and mutex is one of the ways to have that. There are also other building blocks for shared mutability - `Cell`, `RefCell`, `RwLock`, atomics, with each one having its own benefits and constraints.
I mostly use gdb to see what's going on but this might be useful. Is it possible to use a non-global logger though? I pass around logger objects so I have complete testability.
Would just have been nice to not name it the same as one of the contributors of the Servo framework crates you speak of, is all. I don't want to be highlighted all day on IRC…
Prolly legal. But as I understand it, anyone within EU has a valid working permit for Denmark, Germany or France :D
Sure I agree that long functions tend to be more complex and more difficult to understand. But this seems orthogonal to the problem of having local variables that I don't understand because I don't know what their types are
Any particular reason why the queues are std::mpsc and not crossbeam?
I think a big pitfall is premature organization. Programming is quite a chaotic and creative undertaking and applying rigid structure may stifle development. I'd say, organize it however you think is most pragmatic. Personally I use three top-level modules: libs - unit-level code (small utilities/libraries, can depend on other libs) glocals - Just nested structs, no impl, depends on libs mediators - Code that glues it all together, depends on glocals and libs, passes glocals around instead of using globals Inside each of these there are modules, and those modules can decide what is most pragmatic for them how to organize themselves. It's a problem I've spent a lot of time discussing and thinking about, and the gist of this method is basically to have a simple, shallow, basic organization, and inside of there we have modules that can organize themselves however they want, according to their needs. Because no submodule is the same and some just require different organization to be easy to comprehend. If you apply the same organization throughout, some modules may feel unnatural to navigate. But I could be wrong and am always open for new ideas. This just worked for me so far, both in the way I store files in my filesystem, as well as code. As others have said, rust allows re-exporting symbols, so you can program your module in a way that makes the code good, maintainable, and neat, and re-export inner symbols for anyone using that module. 
Wayland and Rust seems like such a good combination. Very happy to see this project this project actively developed. Would you say wayland-rs and smithay are ready for creating a basic, but functional window manager in pure rust?
Re-exports are good when you commonly use types in a very nested modules. Most of the time it is used for libraries, so users can find and access things easier.
I think you just need a work permit for one of those countries, not to be physically in them.
Are you using that comment's parenthesis as a metaphor to glorify Lisp, or to say that deep nesting is a good thing?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/node] [Exchanging data between Node and Rust FFI](https://www.reddit.com/r/node/comments/am20pe/exchanging_data_between_node_and_rust_ffi/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Attributes are applied one after the other from **top to bottom**. Suppose we have three attributes `alpha`, `beta` and `gamma` which just return the input token stream `item`. Then the code below: #[alpha] #[beta] #[gamma] struct S { field: T } Just means: let input = quote! { #[alpha] #[beta] #[gamma] struct S { field: T } }; let alpha_output = alpha(TokenStream::new(), minus_first_attr(input)); let beta_output = beta(TokenStream::new(), minus_first_attr(alpha_output)); let gamma_output = gamma(TokenStream::new(), minus_first_attr(beta_output)); You could try the above in your `src/lib.rs` (or similar) where `proc-macro = true` (if you'd define `minus_first_attr`). Attributes are just functions which accept streams of tokens. Note: If `beta` returns `TokenStream::new()` instead of `item`, then `gamma` will never be applied because it wasn't returned from `beta`. And yes, every output has to be a valid item. --- The function `minus_first_attr(stream: TokenStream)` would collect all attributes in front of say an item or an expression, filter the first one out and return the the rest plus the item/expression: `minus_first_attr(quote! { #[foo] #[bar] 9 })` =&gt; `quote! { #[bar] 9 }`.
The limitation you read about, "streaming iterators" only affect iterators which return references, or types with lifetimes, and only if those iterators need disjoint lifetimes for each item. This is purely an efficiency thing (the iterator could instead be written to return owned items). You can implement sorting for the existing Iterator trait, have a look at how the `itertools` crate does it: https://docs.rs/itertools/0.8.0/itertools/fn.sorted.html
Good write up. Would be interested to know who's using Rust on AWS, especially when it comes to talking to AWS services I can see https://crates.io/crates/aws-sdk-rust but it hasn't been updated in a while...
Thanks! using iter was actually my first attempt, but I failed due to borrowing rules - I was thinking iter had to consume the slice. Appreciate the example!
I appreciate the help! Iterator methods were actually on my first attempt but I failed on the borrowing implementation, and thought it wouldn't work. Appreciate the correction! &gt; Loops and so on aren't a classic way. So, perhaps you're taking offense to my wording, I meant none. With that said, your assertion seems to indicate that not-loops, aka more functional approaches to programming are more common than loops. Assuming "classic way" is defined as popular, not necessarily historically the "first". If that's the case, I'd wager that loops are more popular. Not to say that they're better, but do you think that functional programming is actually more popular than not? Anyway, my comment of `classic way` was merely in reference to popularity. Super debatable still, but I can at least attest to that being the case for anyone I've ever worked with.
That would be very cool. I can see it being very useful when handling `Result` and `Option` types.
Did you just ask to choose between the same thing?
Because if you can reassign a variable then you only know the total liveness of all values of that variable instead of getting liveness per-value
&gt; for almost two centuries. Ah yes, the roaring 1820's, when Charles Babbage finalized his design of his [Difference Engine](https://en.wikipedia.org/wiki/Difference_engine) and C# finally got LINQ.
I don't think it does that. That's just a reexport of a definition, and that reexport is given crate-wide visibility (as opposed to being private). Other modules still have to explicitly "use" it in order to access it. The difference between "pub(crate) use foo;" and "use foo;" is that the latter only allows child modules to "use" that reexport. In the root module there is no difference between them since all other modules are children.
Spoqa (Korean company) is using Rust on AWS(SQS, ECS, ECR). [Here](https://www.slideshare.net/eunchongyu/slack-rust-amazon-ecs) is a talk slide presented at AWSKRUG(AWS Korea User Group) last September.
They are not \`std::mpsc\`, they are actually not threadsafe at all (because they just don't need to be). I just used "MPSC" to literally mean "multiple producers single consumer", because that is how the API is.
I think most people are using (rustoto)[https://crates.io/crates/rusoto_core]
Is aws-sdk-rust filling a different niche from rusoto? 
Right now, Smithay is still pretty barebones, but should contain most of the logic needed for building a basic wayland compositor. You can have a look at [`anvil`](https://github.com/Smithay/smithay/tree/master/anvil), the reference compositor associated with smithay for example.
thanks.
Things like this are often done with dependency injection frameworks (along with caching and other examples). It's nice that rust has good 'lightweight' compile-time libraries for the particular cases.
I understand that you get better value analysis, but how does this help you generate better machine code from WebAssembly? Considering it's output from an optimizing compiler, we're not interested in doing constant propagation and similar stuff. Example: ``` # Example code: (a) foo = 1 bar = 1 (b) bar = foo foo *= 2 (c) last_use_of(foo, bar) (d) # Liveness with mutable registers: (a) {} is alive (b) {foo, bar} is alive (c) {foo, bar} is alive (d) {} is alive # Liveness with SSA: (a) {} is alive (b) {foo1, bar1} is alive (c) {foo2, foo1} is alive (since bar = foo1) (d) {} is alive ``` Yes, the liveness analysis has shown that there are two different values of foo that are alive at distinct points, but I don't see how that information helps us. We still want to compile it down to the same machine register? It seems like you'll have to do more work because you now need to detect that `foo1` and `foo2` can use the same machine register. I can see that there are cases where you want one register to change location (e.g. at point `(b)` we want to store `foo1` on the stack, and at/after `(c)` we always want it in a machine register), but that decision is also present in SSA form.
The problem with that is how can you do it with a function that accepts \`&amp;self\` as an input. I will look into the optimizations and if there's anything that can be done about it
I have done things like this to make certain internal types unit testable in [parts of xi](https://github.com/xi-editor/xi-editor/blob/master/rust/core-lib/src/linewrap.rs#L433); this is generally in places where certain code paths are hard to access without setting up a bunch of other state, or expect to be driven by callbacks etc. My view is that this approach isn't _ideal_, but given the constraints of the existing design it is practical. If this lets me write good tests for some component that would otherwise not be well tested, that's worth some ideological sacrifice. That said: If I were starting the project from scratch, today, I would try to think more about how to design for testability.
you mean you pass around the log::Level? It's quite possible to extract the log::Level from the input of the function
You could try using mrustc to produce C code, and then use Emscripten on the C code.
There is the `asmjs-unknown-emscripten` compile target, which compiles to asm.js (subset of JS) via emscripten. I've never used it so I can't tell if it will be good enough for you, and I assume it depends on what you're trying to do. It's listed as a Tier 2 platform on [Rust's Platform Support page](https://forge.rust-lang.org/platform-support.html).
i always (mistakenly) emscripten was wasm? Wow, so why doesn't rust have a direct emscripten compiler?
Woops, thank you for my typo
It has, for asm.js emscripten and wasm
&gt; I appreciate the help! Iterator methods were actually on my first attempt but I failed on the borrowing implementation, Just insert random `&amp;`, `*` and `move` before closures until compiler gets happy :)
No passing around a handle to whatever logger you have implemented like `fn(logger: &amp;mut Logger,..)`.
I don't like squashing anyways since it erases information (commit messages, authorship, etc.). I'd rather just have good commits to start with. Cherry-picking is usually done, IME, when a fix done on `master` turns out to also be necessary on an older release branch. In this case, merging might not be usable since it would bring in much more history than necessary. Here, `cherry-pick -x` and a reference to the original MR is usually much preferred. I should note that I've implemented a reformatter which rewrites all commits in one shot [here](https://gitlab.kitware.com/utils/rust-ghostflow/blob/7398ffdd2265119565df36adfd02cbdd12d8d920/src/actions/reformat.rs#L310). It runs all formatters supported on the project at once, so it doesn't have the races that distinct formatting actions has. It is within a larger infrastructure, but could certainly be used in something like a GitHub Action. It does assume some level of conformity out of source formatters. Those are listed [here](https://gitlab.kitware.com/utils/source-formatters) (though an abbreviated version is in the actual source).
Honest, I did not make that connection on purpose. I apologize. &amp;#x200B; Thank you though. It made me rethink the name and I came up with one I like more. Changing the name to **roc** (I checked the servo framework crates contributor list this time) and reserved that one. &amp;#x200B; I can't release the nox crate but I'll add you as an owner soon.
The problem is that I need to keep a "buffer" for external sources (like csv files) to not materialize a very potential huge relation that later will be filtered. Think like: csv("huge.csv") |&gt; where line="..." And because this is for a scripting layer, I can't specialize internally on rust. i.e: I need to build my own iterator/generator protocol that work alike the generators on python/scala. I have a "Relation" trait for cover the possible sources (arrays, trees, RDBMS, files, etc) and need to work on them. 
Can't rust be a combination of both pure and impure functions. Immutable input basically means, it's forbidden to mutate the input, its up-to the user to do memory copying.
Any good resources you'd recommend that I learn this stuff from?
Sorry, what I meant was that, purity should be compiler enforced. Off-course you can write pure functions in today's rust, but its a mental cognitive load, to verify that a function is pure. i,e is not calling a rand number generation inside pure function and determining the return based on it the random number, or calling to a file and getting its data. &amp;#x200B; It would be easier for me as a consumer of a library to rely on function's purity at the api level, without having to dive deep into the implementation. 
What exactly do you mean by snapshots?
When I build on Mac OSX `cargo build --release` I assume that the executable file in target/release is all I need, but when I copy this to another Mac I get complaints about files missing. How can I build a single file executable on any system?
A 404 would create dead links for places like stackoverflow questions. I would prefer using either the 301 or making the link at the top of the second editions pages that allows for jumping to the current version to jump to the equivalent page within the current version rather than jumping to the "Foreword" section everytime.
I don't know, but if it's similarly maintained to Rust itself, then I'd imagine they'd follow the rename/new=&gt;deprecate/old pattern (e.g. they probably wouldn't want you to rename it, but to keep it around and just deprecate it/move what you're actively maintaining to the new title. 
A snapshot is a serialized version of some value that gets persisted. When your test changes output it will be diffed against that already stored value. This is useful particularly when you have complex values that change sometimes because they represent UI layouts or similar things. We use to assert our protocol. 
Jumping to the foreword every time irritates me more than it should.
It's ok, I didn't even expect you to rename it, really no need to apologise, I was just being facetious. :) Props to you, and good luck for refactoring that stack, do ping us whenever you have something ready, I'd be happy to help you make use of it in Servo if it better encodes the invariants of those macOS frameworks!
Am curious as to what is the point in compiling it directly into JS?
I'm still not quite sure where the problem lies, but take a look at the `BufRead` trait: https://doc.rust-lang.org/std/io/trait.BufRead.html The `lines()` method on that trait does exactly what you are asking - it returns an iterator over lines in the file without reading the whole file into memory at once, and you can chain filters etc. onto that iterator and have it work exactly like your csv example. It sounds like you're trying to duplicate what `Iterator` already does.
There’s no built in support, you just start a new crate.
Fixing those links is a matter of putting in the work! I’d happpily take a PR to make this better.
Next time I run into the issue and locate the equivalent page I'll be sure to post a PR for it. 
Thanks!
Handing in a JS assignment for school :)
Yes, but that is only for files. I need for more than that. 
Oh haha smart
If I remember correctly, emscripten only supports executables, not libraries, so it's not always applicable.
Unfortunately node-ffi is super high-overhead. Depends on your workload obviously, but I think a lot of folks end up finding that the overhead wipes out any performance benefits they get to writing hot sections of their app in Rust (or C++ or whatever). You might also consider [neon](https://github.com/neon-bindings/neon), which lets you write regular Node.js addons in Rust instead.
I am seriously considering working on this, and I am re-reading [Cross-Platform Language Design](http://lampwww.epfl.ch/~doeraene/thesis/), the paper behind Scala.js.
wasm was born out of asm.js and emscripten has always been a huge part of that story, so it's not at all surprising you'd conflate the two. asm.js was basically the first version of wasm, and wasm was born out of the desire to compress it further. I think asm.js basically has a 1-to-1 mapping in the wasm spec so you can trivially convert it in one pass.
[You can read about interior mutability in the rust book](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html) - that's what the pattern is called when you have a value that is both shared and mutable. The different types are simply for different use cases: * `Cell` is cheapest, but you can only move values in, and copy them out. It also cannot be shared between threads. * `RefCell` allows getting a references to its contents, and uses flags at runtime to prevent invalid aliasing. Also cannot be shared between threads. * `RwLock` is kind of the same as `RefCell`, but can be shared between threads. * `Mutex` is kind of like `RwLock`, but only allows getting a mutable reference (`RwLock` allows having multiple shared references at the same time). * Atomics are kind of like `Cell` that can be shared between threads, but only for integer types.
I hope the person marking your assignment isn't planning to actually read your code!
Typedef or not, you still have to write the angle brackets. Typedefs only help when you are repeating the type more than once. e.g. ``` future::Join&lt; &lt;&lt;T as TableRouter&gt;::FetchIncoming&gt; as IntoFuture&gt;::Future, &lt;&lt;T as TableRouter&gt;::FetchIncoming&gt; as IntoFuture&gt;::Future, &gt; ``` Either I do this in a typedef or directly in a function signature. Either way matching angle brackets would be nice. I'm sure I could come up with a more contrived example but this is one that came up recently in code that I actually have. Also things like `Arc&lt;Mutex&lt;Option&lt;(Vec&lt;A&gt;, HashMap&lt;B, C&gt;)&gt;&gt;&gt;`. Putting it into a typedef is a separate thing from making those brackets match.
Sure! It's https://jon.thesquareplanet.com/live-coding/.
This is great ! However, I did notice that "safety" isn't in the goal list. Can it just be assumed that wasmer is made to be very safe like wasmi is ? Is it reasonable to run untrusted WASM through wasmer ?
It’s infuriating 
&gt; Empty Vecs don't allocate (or rather: they allocate lazily on first data). If you use `Vec::new()`, yes. `Vec::with_capacity` exists to optimize this for situations where you know how much space you need. 
You can use the asmjs target, which produces perfectly fine JavaScript libs. Alternatively you could try to use the wasm-unknown target and use the wasm2js tool to convert the wasm file to JS: https://rustwasm.github.io/wasm-bindgen/examples/wasm2js.html Unfortunately the latter case produces &gt; 300 MiB JS files for me that break uglifyjs and a custom „uglify-rs“ I wrote can bring it down to almost the size that asmjs produces (still like 50% larger), but it turns out the 300 MiB file never even contained all the data sections, so the file is completely broken. Maybe the situation improves since then though.
Seconded. Neon is also quite easy to use
Hi, I was working on it today. Implemented the From , but removed Decimals. I hope everything is ok. It's currently in a dev branch: https://github.com/aspera-non-spernit/temperature/blob/dev/src/lib.rs
[removed]
This is most likely not a very good idea but you can do it. In fact, [I am doing just that in one of my work-in-progress crates](https://github.com/koute/sarek) binding to Tensorflow's Python API until I'll rewrite those parts in Rust... (: If you're doing this just for fun and maybe to learn something then sure, I don't see why not (especially if the number of APIs you want to call is relatively small), but it's probably just a better idea to either write the whole thing in Python, or if you really want to use Rust then rewrite the relevant Python libraries in Rust.
Realizing this, when learning Rust, was a huge deal for me - it's a big reason that I prefer Rust over other GCed languages even when performance *isn't* a concern.
AFAIK you can use [`wasm2js` from Binaryen](https://github.com/WebAssembly/binaryen) to convert WASM to JS, although I haven't used it myself so I have no idea how well it works.
There seems to be stuff missing from this article. I see this: &gt; Ok, running the function locally is super simple. Just get to your terminal and execute this: &gt; If you browse to http://localhost:8080 you should be able to see something similar to this: with no code snippets (or images?) indicating what I should be executing or seeing.