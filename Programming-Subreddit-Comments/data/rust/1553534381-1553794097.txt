I completely agree with Drew here. Rust cannot compete with C. C++, sure. Rust is far more complex. Rust compile times are still an order of magnitude slower. Cargo is set to become the next npm disaster and nobody seems to be paying attention. I actually started writing Rust *before* C, but nowadays I just prefer C because it's fast, minimal, and doesn't require a huge toolchain to get started.
So yesterday I released the first version of [ndarray-vision](https://github.com/xd009642/ndarray-vision) an ndarray based computer vision library. I'll be continuing to develop that this week as well as working on some more [tarpaulin](https://github.com/xd009642/tarpaulin) investigations to hopefully get rid of the last segfault based issue when tracing certain tests.
Thanks! Edited.
If only I have found Rust sooner (or alternatively, if Rust had stabilized sooner), then I would have [ported XCB to Rust instead of Go](https://github.com/BurntSushi/xgb). Alas, I already have my perfect WM, and I will not tread into those waters again unless I'm dragged kicking and screaming. :-) (I remember spending many nights reading your code. :-))
The best response to this is honestly de-platforming. The author is deeply out of their element and makes not only contradictory, but outright totally incorrect claims. They either are unaware, unable, or unwilling to present a valid criticism in order to express their point. 
I'm sure 10 years from now and 500 CVEs later he might reconsider..
500 CVEs? Yeah, no. Sway doesn't have much of an attack surface to begin with. If you really wanted to, you could probably write a Wayland client and trigger a buffer overflow, but Sway can run without privileges (hence no privilege escalation) and you'd have to choose to run this malicious client to begin with.
&gt; When designing an API, should Copy types generally be passed by reference, or moved in function calls? I've seen both used in libraries so far. I would make this dependent on the size of the type. For types that are known to be small and Copy, i find it more convenient to just use pass by value. After optimization they might end up in CPU registers so there's no real cost involved. It's less of a hassle than a pointer which has to be dereferenced first. For types that are known to be larger I would use `&amp;T` if that's what's sufficient just to avoid copying so many bytes around. In generic contexts it really depends on what the function is supposed to do. You might want to avoid `Copy` as a bound to be more general which could mean using `&amp;T` over `T` to avoid moves &amp; cloning. If ownership transfer is supposed to happen you would still use pass by value. But since you broght up the arithmetic example: I agree with /u/DroidLogician in that you should consider providing multiple implementations for operators that take their arguments by value. For example, the binary arithmetic operators all take their arguments by value. For generic code this means that you might *not* want to require `Copy` in order to support more complicated number-like types like multi-precision floats or big integers. Not being able to rely on `Copy` might result in situations where you would like to reuse arguments and would have to introduce clones to do that: fn triple&lt;T&gt;(x: T) where T: Add&lt;Output=T&gt; { x + x + x // oops! } Here, in this generic context where we didn't require `T: Copy` these operators *consume* their arguments because they are defined to take the arguments by value. One way to "fix" this is: fn triple&lt;T&gt;(x: T) where T: Add&lt;Output=T&gt; + Clone { x.clone() + x.clone() + x } Of course, we could replace Clone with Copy: fn triple&lt;T&gt;(x: T) where T: Add&lt;Output=T&gt; + Copy { x + x + x } But then it wouldn't work anymore for BigInt types or high-precision floats that store their data outside on the heap. What about the following code? fn triple&lt;T&gt;(x: T) where T: Add&lt;Output=T&gt;, for&lt;'a, 'b&gt; &amp;'a T: Add&lt;&amp;'b T,Output=T&gt; { &amp;x + &amp;x + x } The cool thing about it is that the implementation block is readable and does not require any copying or cloning. The bad thing about it is that specifying such trait bounds is kind of a hassle and that you also rely on `Add` implementations for references. Luckily, these implementations are provided in the standard library for all the fundamental types. And in my opinion, all types that are involved in implementations for such arithmetic operators should also provide ones for references so we can avoid unnecessary copying and cloning. The only thing we seem to miss right now, in my opinion, are suitable "shortcut traits" that allow us to define the last version of `triple` with much fewer tokens. ... like fn triple&lt;T&gt;(x: T) where T: Add2&lt;Output=T&gt; { &amp;x + &amp;x + x } where the `Add2` name is, of course, open to bike shedding. This is how I would like to write generic numerics code. But for this to work, we really need more trait implementations for references as well as a set of more high-level traits to reduce the noise. I don't want to name a trait bound for every kind of operation. Let's group those into higher-level traits. Opinions?
In scientific method it doesn‚Äôt matter who someone is. All that ever matters is the argument they provide. If that argument is valid (as in its statements are true and said person proved it) then it‚Äôs valid no matter what. Appealing to authority and therefore taking something as true on blind faith leads into religious territory and is productive.
As per CrumblingStatue's recommendation, I removed interior mutability entirely and adjusted the API to use &amp;mut references: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=45c7bc38ac96a82705fb7afe0982c2fa
\&gt; isn't this Windows-exclusionary? &amp;#x200B; I thought about mentioning that System-V is a \*nix-centric technology and fails to take into account Windows development, and actually deleted it from the draft of my GP post. You're right, it is.
Science was not used in the making of this blog post, clearly, so that's not really relevant. This is closer to an opinion piece, and when it comes to those, credibility matters. 
I have nothing specific to add, but thanks for stepping into the lion's den. The reply is much appreciated. :)
In regards to his comment here: Aside: the term ‚ÄúC/C++‚Äù infuriates me. They are completely different languages. Idiomatic C++ looks nothing like idiomatic C. I work in the Aerospace industry, and Ada code is slowly getting rewritten in "C/C++". Here I specifically choose to use the term C/C++ because the C++ code we write is nothing like idiomatic C++. In this safety-critical, embedded system environment, there is basically no heap, no polymorphism, no standard library or niceties that many enterprise application C++ coders would take for granted. The most problematic problems we face are due to simple issues, such as buffer overflows, or lack of abstractions (modeling and generated code is common). If we were to get enough expertise and buyoff from our certification authorities, Rust would be a godsend. Yes, there are still things we need before we get there (such as the stable ABI), but when you work with people in two or three entirely different timezones, abstractions and compiler checking can make things hard to mis-use. The author of this post seems to be heavily narrow-minded in his specific field and workflow. Maybe Rust isn't the best choice for him, but it seems to me that if he wanted to keep his segfaults and buffer overflows, he could still get the benefits of using a modern language with modern tooling and safer APIs by simply using a higher mix of unsafe code. If his reasoning for his ideal C replacement to be `simpler` is that he wants to get stuff done quicker, then perhaps he's fought with the borrow checker a bit too much. Not all code has to be completely safe Rust code.
I've been looking for it but failed to find it so far; if you do remember how you did it, I'd be VERY interested in knowing it!
&gt; The Rust community has a reputation You also have a reputation
Thanks! After getting the library semi-stable, the next step is probably to implement a better ordered container than rbtree. A concurrent \`BTreeMap\` would probably have pretty amazing performance.
That should work fine. I‚Äôve done it before for sure. Maybe this week I‚Äôll update the example with that use case.
&gt; The Rust community has a reputation, so note that I'm ready to abandon thread as soon as it gets hostile in here. Please let me know if I overstep my bounds. I tend to dwell on it if my attempts at diplomacy fall short. &gt; I'm de-fanging the purported benefit of concurrency being easier in Rust, as it's frequently trotted out as an argument for Rust. But for most programs, concurrent design is bad design, so this argument holds little weight with me. Fair enough, but I think it's important to draw a distinction between waiting in parallel and working in parallel. (Threading/forking is necessary for working in parallel but bad for waiting in parallel. Async APIs are efficient at waiting in parallel but can't get you parallel working on their own.) In the last 15 years, I've only really needs threading APIs for two things: 1. CPU-bound scatter-gather tasks like thumbnailing which correspond to an API like Rayon's `par_iter`. 2. Working around badly designed APIs that insist on having their own main loop rather than letting me get a file descriptor to feed to a descriptor-watching API on GTK+ or Qt's main loop. As for async, I have mixed feelings on it [at best](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/). Overall, the impression I got from the points that you made was that most of them are symptoms of a young language and that it's premature to blame Rust for them. Yes, Rust is more complex than C, so it's taking longer to settle down, but the question shouldn't be about replacing a simple language with another simple language. C didn't entirely replace Fortran or Pascal when it rose to popularity. The question should be "Where has the set of tasks people are doing with systems languages shifted enough that a more complex language than C is necessary?"
Time to plug [cargo-nono](https://github.com/hobofan/cargo-nono) again! üòá With `cargo-nono` you can check for `no_std` support in your dependencies without needing to use a different target, and even without compiling your crate. The biggest downside is that it's not 100% accurate, but in practical tests I've generally found that it does a pretty good job. There is also [an issue](https://github.com/hobofan/cargo-nono/issues/2) for adding a more rigorous check on compiled artifacts, that I've recently started working on.
I have to disagree. People are entitled to their opinions and shutting down discussion just ensures that a common understanding can never be reached.
&gt;Overall, the impression I got from the points that you made was that most of them are symptoms of a young language and that it's premature to blame Rust for them. It follows that it's premature to use Rust for many things for this reason as well. &gt;Yes, Rust is more complex than C, so it's taking longer to settle down, but the question shouldn't be about replacing a simple language with another simple language. C didn't entirely replace Fortran or Pascal when it rose to popularity. I don't think this comparison is apt. I think that because Rust is more complex than C, it will never replace C.
De-platforming? For something like this? Why would you even consider that? It does not matter if the author made a few honest mistakes due to being closed-minded or it made an active effort to denigrate Rust, de-platforming would not make sense. He wanted to say something and he wrote a blog post. Nothing unusual, nothing terrible about it: people have been saying lies or half-truths since the dawn of humanity anyway. The way to address such a blog post is to prove that many of his arguments are bogus and what he said does not reflect the truth. Anyone vaguely interested in a language will find out if Rust is good for them or not.
True, but two wrongs don't make a right :) I've been working on my attitude. I'll agree to be cordial if you will.
Please remember rule 2: &gt; Constructive comments only. 
Um yes, if someone is into unproven opinions, credibility definitely matters, as in increased probability for the authority to be right or wrong. But I thought engineers always preferred having the proof, as opposed to gambling with opinions, therefore the point I made was, from my perspective, irrelevant to how the author wrote his article. But, I get your point.
what do you mean by customizing the diagnostics?
Would calling \`.set\_nonblocking(true)\` on the stream have the same effect? I would have to restructure the read operation with Error::WouldBlock etc. But in principle? 
But it would never reach the code where I ask I it should stop, no? Read is called (and blocks) before i can send the stop signal and shut down the thread
Examples of how to use crates.io dependencies would be nice.
&gt; It follows that it's premature to use Rust for many things for this reason as well. True, but that felt so obvious to me that I didn't think it needed to be stated. You certainly won't see me using Rust to develop web applications before things like async/await abstract away the ugliness in the async APIs. &gt; C is useful today, and clearly moreso than Fortran or Pascal were. Fortran is still used very widely in scientific computing and Pascal lost out, not because of its utility (arguments can be made that Borland's dialect of Object Pascal is a better language than C89), but because UNIX bundled a C compiler and Microsoft threw their support behind C.
I _practice_ science as much as I can, sure. But I gamble with opinions all the time. Any maintainer of any software project with end users will cop to that. :-) There ain't no science that will tell you, with certainty, the optimal set of features to put into a piece of software!
Well by God, a 13 year old account! Is it like only the founders of Reddit that have older accounts?
I stopped reading here: ‚ÄúYes, Rust is more safe. I don‚Äôt really care. ‚Äú Honestly, software is a *mess* because of safety issues. Safety is the single strongest thing that rust brings to the table. If you don‚Äôt value safety I don‚Äôt see how you can hold any sort of a reasonable opinion on Rust. I‚Äôm generally very interested in reading blog posts that are critical of Rust. That‚Äôs how we get better. But this isn‚Äôt a well considered critique, it‚Äôs a screed. 
The best thing you could hope to achieve to assist the database library ecosystem is probably to have very, very experienced existing library maintainers consult/contribute to your database adapters. I don't think a working group works without someone senior involved because after many years of working with RDBMSs, I can say that they are not an easy problem to work on.
Hi, you are right that it doesnt have futures 0.3 support but we are waiting for it to become stable before supporting it. As for using it with rusoto, I currently use it with multiple rusoto services and wrap them with a Service trait, that then allows me to provide a retry policy, timeouts, and in flight limits. That said, tower's power really comes from building thick clients and we are currently working on improving that story. The example is really bad imo but we are working on improving this. Here is a more current example that should be merged soon. https://github.com/tower-rs/tower/blob/d45523004f57dcce70a83e8b4917abe033667691/tower/examples/client.rs#L52 The benefit is that tower is really composable. For 0.3 support you can use the `compat ` layer built in futures 0.3 to compat the call future -&gt; 0.3.
I agree with you for small simple things. But C falls down when it comes it orchestrating large codebases. It can be done (Linux being the prime example) but you need to be incredibly strict with how you modify code, have a massive set of conventions, and be very careful in code review. In my opinion all these things add up to a *larger* cognitive load on large codebases than if you shifted your cognitive load to learning a large language like Rust that uses its feature-set to remove cognitive load in these other areas. 
Almost all of your complaints seem to boil down to "Rust is new and C is old, and I want to use more mature technology when possible". That's a very valid technical decision, but I don't really see how it reflects on Rust as a _language_. The language has the features it needs to accomplish its goal, and its goal is to enable systems programmers to write faster, more readable, and more correct programs. That means replacing C in a lot of cases, and C++ in a lot more, but I don't know that anyone has posited that Rust should _totally_ replace C for _all use cases_. So, given that, what is the use of pointing out, point by point, that Rust is less mature than C? Everyone knows this.
Indeed. If you're looking to improve things now though, at least for zsh, okdana did a phenomenal job setting up custom completions for ripgrep. You can see the script here with great docs: https://github.com/BurntSushi/ripgrep/blob/master/complete/_rg We even have a CI test that fails if a new flag was added to ripgrep but wasn't added to the completion list: https://github.com/BurntSushi/ripgrep/blob/master/ci/test_complete.sh Auto-generation would obviously better, but there's a surprising amount of complexity in building a good set of completion rules.
Indeed. If you're looking to improve things now though, at least for zsh, okdana did a phenomenal job setting up custom completions for ripgrep. You can see the script here with great docs: https://github.com/BurntSushi/ripgrep/blob/master/complete/_rg We even have a CI test that fails if a new flag was added to ripgrep but wasn't added to the completion list: https://github.com/BurntSushi/ripgrep/blob/master/ci/test_complete.sh Auto-generation would obviously better, but there's a surprising (at least, to me) amount of complexity in building a good set of completion rules.
Fixes published, thanks for pointing this out!
Thanks for these thoughts. I just started learning Vue for building web UIs, and I *love it*. The ‚Äúcomponent‚Äù approach is fantastic, especially when combined with a good component library (like veutify). I‚Äôve never felt more productive for creating good UIs. I realize it‚Äôs early days for a Rust UI development, but I would love to see a similar thing happen in this ecosystem. 
The last commit is from 2 years ago, though.
No. Because the only avenue for education isn't writing incorrect opinions online, and having those opinions corrected by others. Pretty bleak view of humanity if this is the only way we can educate people.
To be honest, I'm still unconvinced that a stable ABI for Rust is *necessary*. The C ABI represents a Lingua Franca that is generally sufficient for most cross-language interaction. Going further becomes difficult: there are trade-offs in choosing representations for `enum`, v-tables, generic code, etc... that once enshrined in a stable ABI cannot be altered, even if everyone agree they were sub-optimal. C++ has done very well without a too stable ABI, and the stable parts have regularly caused issues. For example, the atrocious performance of `&lt;regex&gt;` is laid at the feet of de-facto stable ABIs (due to generic code); fixing `&lt;regex&gt;` would break clients, too bad.
&gt; because Rust is more complex than C, it will never replace C How does this follow? C is more complex than assembly on any platform, and yet here we are. C replaced native assembly for _almost_ all use cases. Rust will also probably replace C in a lot of use cases, like network programming when async/await support is more mature and numeric processing when const generics become available. That's not to say C will ever be completely replaced, it's a language with a long history and a lot of software written in it and anyone but a RESF strawman would agree that there's no use rewriting every utility and application ever written.
This is either excessive or a gross misunderstanding of the term de-platforming.
&gt; People need to get their heads out of their asses and realise Rust isn't the second coming of Christ. People need to get their heads out of their asses and realise that nobody thinks anything that can be even humorously characterized thus.
&gt; &gt; Overall, the impression I got from the points that you made was that most of them are symptoms of a young language and that it's premature to blame Rust for them. &gt; It follows that it's premature to use Rust for many things for this reason as well. That's a perfectly valid point. Rust *is* immature, indeed, and immaturity itself brings risk into a project. However, it's important to remain open-minded as well: maturity, after all, is perhaps the easiest property a language can acquire.
"No" what? "No, you're not allowed to disagree?" "No, people aren't entitled to their opinions?" "No, it *is* valid to shut down people for posting incorrect but comparatively harmless opinions on the closest equivalent to their own private property?" "No" isn't very constructive. &gt; Because the only avenue for education isn't writing incorrect opinions online, and having those opinions corrected by others. &gt; &gt; Pretty bleak view of humanity if this is the only way we can educate people. I could equally easily argue that you have a very authoritarian view of the world. Blogging didn't magically invent these aspects of human nature. They were in full force at the time that countries like the U.S.A. included a right to free speech in their constitutions and, at the time, a constitution which only constrained the government was equivalent to banning de-platforming on sites like Facebook, YouTube, and Blogger would be today.
&gt; Yes, there are still things we need before we get there (such as the stable ABI), but when you work with people in two or three entirely different timezones, abstractions and compiler checking can make things hard to mis-use. I would have thought, then, that Ada would remain a better choice than C or C++; would you care to expand why you are moving away from Ada? Is there a lesson to be learned, there, for Rust?
I‚Äôm not entirely sold on all of Rust‚Äôs features, but I don‚Äôt get the criticism on Cargo! Also regarding stability of the language, you can compare the situation as with pre-ANSI C and ANSI C. 
Thank you! Please keep fighting the good fight!
There are zealots in this very thread stating that starting new projects in C is unacceptable and suggesting that C programs are somehow booby traps that will be the root of thousands of horrific CVEs. It's idiotic. 
We're talking about restricting libraries, not the main executable. The runtime keeps track of which library invokes which API call and compares it against the rights of that assembly. Unfortunately it was a hugely complex mess that was nearly impossible to use correctly.
ZEAAAAAALOTS! In this VERY THREAD!!! Oh goodness, how terrifying. There are not. One person said he doesn't think writing software with buffer overflows in it is acceptable. You're positing false things and deleting posts so you don't look as bad. Stop.
I like Sway and Drew, and contributed some of the libinput code to Sway, but the amount that Sway crashed, segfaulted, etc leading up to 1.0 was concerning. There are still a lot of times that handling of configurations and "state" regresses (output handling is regressed on master right now and I haven't had time to make the extensive bug report that will be necessary). I regularly find myself wishing it weren't written in C.
I did some debugging with code and lldb just yesterday. The only problem I encountered was configuration not generated properly: I had to replace "bin" with "test" ( I was debugging integration tests). Everything else worked perfect. Definitely better than I expected :) 
&gt; small, lightweight, orthogonal language that could do what Rust does https://ziglang.org maybe :)
Which is ironic because almost *every single one* of these arguments were levied against Go for many, many, many years.
Yeah, I've been maintaining it.
I've been working on a Zig implementation of the X protocol, but I put it on hold because it's event-based and I need to rework the async/await semantics. I'm excited for an event-based X API though - I think that's what it naturally wants to be.
[https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=77c2170ae1c04f103881dabb664c6eb7](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=77c2170ae1c04f103881dabb664c6eb7) &amp;#x200B; Doesn't look like set\_nonblocking wakes the thread
I haven't posted anything that's false and I haven't deleted anything. Your sarcasm is gross and honestly just makes me want to be a part of this community even less.
I will add that to my things I need to research list and see what I can do. Thanks for the recommendation.
~~npm publish~~ cargo publish
It's better because it's simpler (and I mean [simple not easy](https://www.entropywins.wtf/blog/2017/01/02/simple-is-not-easy/)), in that you don't need to learn any new feature, but just how some features already interact. Moreover this would have to change the semantics of `for` in a way that is not obvious. Let me explain, if and while expressions have a clear conditional, and the pattern clearly is the conditional, so the consequences of failing to match are clear, the same as getting false. For loops instead don't have any conditional, so what the pattern is supposed to mean is not as obvious, is it when the for loop ends? (kind of like calling `take_while`) It would be intuitive to people coming from C++ where they expect that conditionals signal when we stop. We want to keep the terminating condition inside the thing we are looping over, not on the for itself. What I do think that would be nice is a way to get a "matcher", something that takes a pattern and then can tell me if something fits or not a pattern (and also returns whatever values I extracted from that pattern). I'd consider it a macro `matching!(pattern(x)) =&gt; |i| match i { pattern(x) =&gt; Some(x), _ =&gt; None}`. Then you could write the above as `for x in my_vec.iter().filter_map(matching!(Some(x)))` which isn't that much more readable than the above, but can help with even more interesting matches later down the line.
Should `loop {}` be unsafe? It never releases any resources.
What window manager do you use?
As I did some research and it seems like most of the crates use nightly rust. I think I will wait until rust becomes stable enough so that crates can use stable version of rust, maybe until rust gets its own `async/await` . My reason for this is becuase as a begineer its a lot of confusion about whether we should use stable rust or not. 
I wish articles purporting to compare the languages would clearly separate short-term vs long-term differences. Even when they are more opinion piece than objective assessment. Short-term differences are an expression of youth/immaturity, and will be smoothed away in the long-term, whereas long-term differences are caused by a difference in values, and thus choices and trade-offs made, and are there to stay. First of all, the rebuttals: - **C has a consistent and stable ABI**: No. The C ABI is decided by the OS. And while System V is widespread, Windows is a very notable exception, as are, probably, a slew of small embedded platforms. - **Rust refuses to play along**: Rust insists that the stable interface is `cargo` instead of `rustc`, that's quite different from refusing to play along, especially when developers in `cargo` are working with distribution maintainers. It takes time, sure. - **Concurrency is generally a bad thing**: Unrelated to the debate at hand. Now let's first examine the short-term differences: - **C is the most portable programming language**: That's maturity talking, its head start is gradually eroding, and for many applications this is already irrelevant as Rust/LLVM support all desired platforms. - **C has a spec** ^1 : C was developed between 1972 and 1973 (Unix was rewritten in C in 1973), its first specification was drawn up in 1989 (16 years later), and to this day there are still 200+ instances of Undefined Behavior in the C specification (see Annex A). Work on specifying Rust is *already* ongoing, I am relatively confident that it'll take less than 12 years to obtain a specification. Some middle-term differences: - **C has many implementations** ^2 : `mrustc` is a Rust front-end, now slightly dated, which produces bitwise identical output. MIRI is a Rust interpreter which operates on rustc's MIR, thereby offering a parallel implementation of the whole MIR -&gt; LLVM IR -&gt; assembly -&gt; runtime chain. As time passes, this number may grow; although the complexity and rapid development of the language may prove adverse. And finally the long-term difference: - **Rust is a more complex language than C** *(not a literal quote)*: Indeed. Rust is interested in avoid bloat for the sake of ticking features, but is not interested in being minimalist. Key take-away: **Rome was not built in a day.** --- ^1 *Furthermore, C only gained a memory model in 2011 (C11), prior to that portability and multi-threading were antithetic.* ^2 *The CompCert project (a formally verified compiler) started up in 2005; it is unclear whether any prior verification of C existed before. This can be contrasted with the fact that research on verifying Rust has been ongoing for years already, with several partial proofs of its soundness already published. A proof is, arguably, worth a good handful implementations when it comes to ensuring the completeness of a specification.* 
I think it could be partly that none of the new grads know Ada whereas it used to be more common for people to learn Ada for systems programming. Kind of a shame, I had someone point out [Ada SPARK](https://www.adacore.com/sparkpro) to me a few years ago and it's really cool.
https://github.com/BurntSushi/wingo I doubt anyone else uses it at this point (other than my wife). Plus, it's in maintenance mode. It's "done" for me. :-)
I haven't made a release of the rewrite on crates.io yet, the version there is still 0.1 requiring a quite old nighty, maybe I should yank that. The master on GitHub should compile with stable rust.
Yeah but dealing with strings in C can be a huge headache. 
&gt; For example, the atrocious performance of &lt;regex&gt; is laid at the feet of de-facto stable ABIs (due to generic code); fixing &lt;regex&gt; would break clients, too bad. Ooo. Is there more I can read about this?
Basically because zero people coming out of college know any Ada, and it's not easy to pick up. I imagine if Ada was more common, it would be getting much more use. Rust is already working to address most of these issues, and my only fear for Rust is that getting a team from India to get over the "fighting the borrow checker" stage might in some cases be impossible. My personal feelings on Ada are that despite its archaic and unintuitive syntax, it has many language features that are quite useful for what I do. If it had better tooling and documentation (to help new users learn), I would still consider it for new projects.
You guessed correctly. As I mentioned, a very tiny project. Contributing to an open-source project is often even more demanding than paid work. Either you get no feedback at all or complaints. I remember those rare occasions very well when users acknowledged our efforts. It's all about give and take. Contribution to the open-source community is possible on so many different levels, even if only replying with a kind "thank you". I used the idea to develop a new, stand-alone library management back-end for Mixxx for getting into Rust, finally. Just yesterday I posted a semi-official announcement in our [Zulip chat](https://mixxx.zulipchat.com/#narrow/stream/109171-development/topic/Standalone.20(Music).20Library/near/161581282) and made [the project repository](https://gitlab.com/uklotzde/aoide-rs) public for everyone who might be interested. It is far to early for any public announcements! Hopefully no one takes this nested reply on an almost unrelated topic too seriously ;) The focus was mainly on finishing an initial version of the domain model and API. The internal design needs a revamp ...if I only had the time to do this. One of the features that I expect to become a versatile and powerful tool are both *simple* and *faceted tags* with a *score* between [0.0, 1.0] as a measure of confidence or affiliation. All data is currently persisted in an SQL(ite) database using a hybrid data model.
If the major motivation for that is performance then Julia might eventually surpass Python in that particular domain. It has easier integration with C and Fortran and the language itself is really fast despite being about as high level as Python. IDK since I'm just a hobbyist working in an analytical field but IMO it's worth keeping an eye on.
&gt; Author here, .... Oh hey! :) Thanks for taking time to respond, I'm excited to continue the dialogue. &gt; .... [S]tepping into the lion's den. The Rust community has a reputation, so note that I'm ready to abandon thread as soon as it gets hostile in here. First off: whoa, you are more than welcome here in the Rust community, and I'm sorry if you've encountered hostility from Rust users before! What "reputation" are you speaking of, exactly? The one I'm used to seeing shared is positive, so I'm curious. I didn't see a response to my question in the last part of my GP about hostility, and I'd really like to make sure I understand your experience, so I'll ask again! If it means anything, hostility is not representative of the vast majority of my experience with the Rust community (I've been here on Reddit, Discord, Twitter, for ~3 years now), and I've no intention of being hostile here! --- &gt; [The code one writes eventually] is no longer idiomatic. Rust code becomes stale quickly, C code does not. In case it wasn't absolutely clear, I already agreed with you here. Furthermore, the C language doesn't change much *now*, but your "not" applies to "getting stale **quickly**", not "getting stale" in its entirety. There's still fragmentation of what one might consider idiomatic code in C. Off the top of my head (supporting links provided after), there are different approaches for: * Qualifying types (on the left or the right) -- `const` simply has different semantics in different places, but where to place `*`, for instance, is up for debate. * Array and function notation vs. pointer notation -- the former is generally more informative, but some codebases use the latter. * `memset(&amp;thing_to_init, 9, ...)` vs `struct Something thing_to_init = {0}` * [`struct Foo {...}; struct foo bar;` vs. `struct foo {...}; typedef foo_t; foo_t bar;` vs. `typedef struct {...} Foo;`](https://stackoverflow.com/questions/252780/why-should-we-typedef-a-struct-so-often-in-c). I don't think there's much room to argue against that there is less churn now with C than with most other languages. However, the fact that an *ecosystem* can and should churn is also important, and C is not exempt from it. Crypto libraries, for instance, still experience churn. To illustrate, OpenSSL has been forked several times, recently of note are LibreSSL (now the standard for a few popular BSDs, Void Linux), [BoringSSL](https://boringssl.googlesource.com/boringssl/+/HEAD/PORTING.md) (and its [guide](https://boringssl.googlesource.com/boringssl/+/HEAD/PORTING.md) to migrating from OpenSSL). --- &gt; The problem is that Rust talks to itself using one ABI, and talks to everyone else using another (System-V). .... IMO this over-complicates the design in the name of supporting features I don't even think Rust ought to have. So, some thoughts I have here: * Rust hasn't standardized an ABI yet because it's an open question whether it will be beneficial enough versus the possibility of designing an ABI better-suited for Rust's features down the road. That's the rationale -- you may not agree with it, and I'd love to hear why not, but that's my understanding. * Given Rust has an unstable internal ABI, could you elaborate on the alternatives you see for interfacing with older technologies? Until large platforms are written in a language other than C and become popular enough, interfacing with C seems pretty standard. It's important for Rust to be able to interoperate with current C-based systems, and I'm not aware of a great alternative to using C calling conventions like Rust does. * In terms of language design: when one doesn't need FFI or is programming against Rust-based systems, `extern` functions are no longer a concern. The complexity of FFI is then zero-cost -- nobody needs to think about the features developed for FFI unless they're using them in some form. * System-V isn't the only ABI that is used extensively in production. Not important for the meat of this point here, but Windows does exist! Don't forget that ecosystem! :) 
&gt; mrustc is a Rust front-end, now slightly dated, which produces bitwise identical output. That would surprise me a lot, given that it doesn't (to my knowledge) use llvm. Or do you mean that the produced binaries may be different, but they produce the exact same behavior (as far as it has been observed)?
Running with or without privileges doesn't matter if you chain a privilege escalation vulnerability to a RCE vulnerability.
I read the explanation on r/cpp from one of the maintainers of the standard library for Windows, probably either STL or BillyONeal. This [thread](https://www.reddit.com/r/cpp/comments/aetf17/stdregex_replacestdchronohigh_resolution_clocknow/) has some comments from BillyONeal about the topic, notably [this comment](https://www.reddit.com/r/cpp/comments/aetf17/stdregex_replacestdchronohigh_resolution_clocknow/edu74u9?utm_source=share&amp;utm_medium=web2x), with some context: &gt; BillyONeal: Because the slow part of regex_replace is the matching bit that‚Äôs embedded in the type `std::basic_regex`; which thanks to ABI basically can‚Äôt change under the current ABI regime. &gt; Maddimax: That seems like a bad design decision :( &gt; BillyONeal: Agreed. ‚ÄòTis what we get for copying a design decision that made sense for Boost, which gets to break ABI every 6 months, in the standard library. But time machines and all that. At least regex is a leaf; just use RE2, CTRE, et al. instead.
Excellent point; removed the bitwise bit.
&gt; rewriting parts of their storage backend from Go to Rust and seeing dramatic memory savings Honestly this would have been achieved with any non-gc'd language. Go is rather performant as is, but as long as memory release can be deferred, it will never be as memory performant as a language like Rust, C, or C++. 
To provide more context, or rewrite the error messages. &amp;#x200B; I think today elm ([https://elm-lang.org/blog/compiler-errors-for-humans](https://elm-lang.org/blog/compiler-errors-for-humans)) is the closest to the ideal, IMHO. But something more modest, like instead of show &amp;#x200B; `db` `expected ident` &amp;#x200B; To show `db` `After the db object, is expected to apply the query operator "?" or apply a function with pipe "|"`
&gt; I know that people like to pretend Windows doesn't exist, but it's still ~50% of user and developer computers. I think Drew just doesn't care about those people anymore, if he ever did. He has pretty militant views on free software, and seems to prefer to simply refuse to interact with anything that doesn't conform to those views.
 I am writing a new language! Specifically, it's a Lisp that's designed from the ground up to work well with other languages. Languages in the Lisp family have one primitive data structure: the list. These lists can contain arbitrary values and other lists, allowing for lots of complexity. The thing is that these lists also get passed around a lot. Building an interpreter in Rust, there are a few ways to handle this without violating the lifetime rules. The naive solution is to clone everything whenever you pass it anywhere. I hope it's obvious that this is a terrible idea; cloning is a very memory- and time-intensive operation, and using it everywhere on arbitrarily large nested data is a recipe for terrible performance. The next option is `Rc&lt;T&gt;` from the standard library. `Rc` owns its contents and keeps a count of how many references there are to them. When you clone an `Rc&lt;T&gt;`, it actually just increments the reference count and gives you back the same `Rc&lt;T&gt;`. If the reference count ever reaches zero, it knows that its content can never be reached, and frees the memory. You can think of `Rc` as a very primitive "reference-counting" garbage collector. Sometimes, however, that's not enough.Suppose I have two structs... struct A { pub b: Rc&lt;B&gt; } struct B { pub a: Rc&lt;A&gt; } ...and I have an instance of each and they refer to each other? They'll never get freed by `Rc` because the reference count will never reach zero. This is when you need a more sophisticated garbage collector. As it turns out, Lisp code produces a *lot* of circular references, and so if you don't want to leak memory you need a better GC. (Fun fact: Garbage collection was actually invented for Lisp!) Hopefully that was the right level of explanation. 
Oh, I am excited about the upcoming optimizations! The test is using 0.4: ``` [dependencies] pulldown-cmark = { version = "0.4", default-features = false } ``` Thank you for links, I will try to add them as well.
Thanks for the post, I actually set this up a few days ago myself and was surprised that it worked (to some degree). I really miss a good debugger in Rust, it's such a good learning tool. I hope there will be more focus put towards debugging in the future.
&gt; Even better, from my two full attempts, the resultant stage3 files have been binary identical to the same source archive built with the downloaded stage0. https://www.reddit.com/r/rust/comments/7lu6di/mrustc_alternate_rust_compiler_in_c_now_broken/
Just wanted to give /u/chriskrycho a leg up with finding a solution to his problem. Can't have him wasting those hours not making awesome [New Rustacean](https://newrustacean.com/) content! ;)
Cheers!
Just use a native toolkit.
OP is talking about enforcing what dependencies are about to do with a permissions model like apps use in mobile apps. Like "is this crate allowed to do file IO", "do network access", "spawn subprograms", etc.
 fn foo&lt;T&gt;(bar: T) where T: Baz {} fn foo&lt;T: Baz&gt;(bar: T) {} fn foo(bar: impl Baz) {} or impl&lt;T&gt; Foo&lt;T&gt; where T: Baz but this is not valid impl Foo&lt;impl Baz&gt; but this is an alternative impl Foo { type T=Baz And magic like [catching functions / try fn / ok wrapping](https://internals.rust-lang.org/t/pre-rfc-flexible-try-fn/7564) is seriously considered. Don't judge other languages like that. There always are some caveats and some sugar that some people want and other hate.
What do you mean?
You're a liar, my smart bulbs can't.
Certainly not this one. Minus borrow checker, minus traits.
To be clear, I wrote almost none of the code: Jamey and later Josh did most of the initial coding. But I did architect the thing and help a little with coding and stuff. Fun times. XGB looks impressive. As you know, most people just used FFI over XCB core. Thanks for pointing it out!
Dude's a bro
I just wondered why this post had gotten so much attention. I had never heard of this guy, but it seems like a lot of people were taking it, er, more seriously than the arguments presented seemed to warrant.
Oh cool, I was still working from the gitlab sources. Here's a brief benchmark (also against [cadical](https://github.com/arminbiere/cadical): varisat glucose-3 cadical ok_17 205.8 21.9 6.3 ok_21 97.3 103.7 14.6 ok_22 39.5 81.8 12.0 This is a pretty good showing! Beating glucose-3 in 2 out of 3 is quite an accomplishment. I'm interested in following its progress.
Sorry, when we say *crate* are we talking about *build* or *runtime*. First, neither is absurd, and both are totally possible, depending on your threat mode. Second, given the attack described, they're talking about *build* time, which we're perfectly capable of defending.
:-) Yeah, I jumped on early, then got sidetracked and was dormant for quite a while. I'm glad that Reddit didn't dump me before I got started again.
I have a minimal hello world setup here: https://github.com/matklad/rust-piplelines-hello-world. The hard bit though is figuring out the GUI on the MS website, it took me couple of try to correct project/organization names
Cool. I am not really a fan of event-based‚Ä¶anything, really: I find dealing with events to be error-prone and complicated, which is why I tried to make XCB super-friendly to simple thread-based calling. But I think I'm out of sync with most of the rest of the world on this. Certainly the first thing that serious XCB users try to do with it is add an event queue back in, so maybe it was a design mistake to insist on leaving it out. I don't know. I haven't really looked at Zig. Is there a good comparison with Rust somewhere?
Hey, this is pretty cool. I hadn't considered Azure Pipelines but this looks fairly easy to test things out on several platforms. Do you know whether Azure Pipelines can produce release / build artifacts from these runs? Are macOS / windows / Linux targets part of their free tier for open source? 
Working on a (not-yet-ready-for-release) library for doing Rust-to-Rust ffi,with a focus on loading dynamic libraries at program startup . I already implemented ffi compatible trait objects for any permutation of the standard derivable traits,as well as downcasting from those. Libraries which use this crate would then have to provide two different crates: 1. interface crate: which would contain declarations of types for ffi with a fixed layout, declarations of all opaque types, and function signatures for the implementation crate to implement. 2. implementation crate: which would provide implementations of all the function signatures and the definitions of those opaque types.This is the crate that would be compiled into a dynamic library(cdylib) . Right now,working on adding run-time type and semver checking.
From the article: ‚ÄúUnfortunately other containers don't work at all. HashMap is indecipherable crap. :(‚Äú
Looks like the diesel folks are involved? If so then they have someone extremely senior. The main programmer on diesel is also the lead engineer on active record and is heavily involved with the various DB adapters in both the Ruby and Rust communities. 
Oh interesting! I saw your name everywhere. Good to know, thanks for the correction.
clap Author here. First let me say sorry to all. The past few months of my life have been extremely busy with moving, starting a new job, and having a baby. My new job doesn't provide any open source time, and since I need to pay the bills that only leaves a few hours not already occupied by my family. With the very limited time I've had lately I've put 100% of my effort into getting clap v3 done. When I've only got a few hours a week, I can either spend that time doing issue triage, merging PRs, etc on the v2 branch or trying to push v3 forward. And since I see v3 as the future, I picked that. I essentially put blinders on so I dont just get sidetracked doing v2 work (because I'm very much the type of person to not stop working an issue until it's done as soon as I read it.). This is probably where I've messed up the most. To the community it looks like I've faded off and dont care about clap anymore. However this couldn't be further from the truth. Unfortunately most of the work I've been doing on v3 had been behind closed doors, testing and benchmarking, trying different options. Many of these dont make it into even the v3-master branch because they didn't work out. To deal with v2 and issues/PR backlog I have added two new admins to the repo who can merge and triage. However I dont want to add new features to v2 as I dont have the time to support v2 and v3 simultaneously. Bug fixes and such will be merged and pushed out. 
What? Even without panics, there are plenty of ways to leave a loop. I'm talking about control flow.
you meant /r/playrust 
Iterator specializations like `TrustedLen` and `ReverseIterator` are the most obvious example. Right now, if the signature of `map` was `map(f: impl FnMut(T) -&gt; U) -&gt; impl Iterator`, there's no way to communicate that it ALSO implements ReverseIterator, TrustedLen, or any of the other useful iterator traits.
Yes, I'd argue that either the whole struct or its `new` method should be unsafe.
Interesting. As a thought experiment, could they add a new set of methods to their regex type without breaking ABI that would also allow them to add more optimizations? (Keep in mind that I am not a C++ programmer, so this could be a very stupid question.)
Correct me if I'm wrong please, but this doesn't seem to be valid F#. It fails with the following error due to Some(x) being an incomplete match: Microsoft.FSharp.Core.MatchFailureException: The match cases were incomplete at FSI_0001.xs@3.GenerateNext(IEnumerable`1&amp; next) in c:\temp\foo.fsx:line 3 at Microsoft.FSharp.Core.CompilerServices.GeneratedSequenceBase`1.MoveNextImpl() at Microsoft.FSharp.Collections.SeqModule.ToList[T](IEnumerable`1 source) at &lt;StartupCode$FSI_0001&gt;.$FSI_0001.main@() in c:\temp\foo.fsx:line 3 Stopped due to error Tested in F# Interactive version 10.2.3 for F# 4.5.
&gt; Is there a good comparison with Rust somewhere? https://github.com/ziglang/zig/wiki/Why-Zig-When-There-is-Already-CPP%2C-D%2C-and-Rust%3F
Just learning the basics. Got a book and am just gonna read and program
Whoops. You're absolutely right. Must have mixed it up with Way Cooler. Thx for pointing it out.
How do you leave the loop that I wrote? Pull the plug on your machine? Get the OS to kill your process?
Congrats on the new addition to the family. :-) And really, don't sweat it. I'm pretty sure I have PRs that have languished for many months before, and probably still have some open ones right now. The cycle time for looping back around to projects that aren't in cache can be brutal, especially when you want to be focused on something else. This is why I've taken to saying things like, "yes, I totally plan on doing that, but it might take me a few years to get to it."
Nope, sorry. It was several years ago since I did that.
Doesn't Rust 2015 and 2018 count? They recently decided to have more strict and stable versions of Rust that devs could probably depend on.
You‚Äôre awesome dude, thanks for all the hard work! 
I think I can learn a lot from analyzing this code. I just tried it out and it's faster than my C implementation (although that doesn't have the input in the binary).
It's basically perfect for games, where lack of a GC actually matters. For AAA games though, other things matter more.
Possibly an unpopular opinion, but one thing that has frustrated me a little is how good macros are, which seems to lead to many libraries that produce their own DSL further increasing the learning curve to rust. I'd like to see macros treated a little more like unsafe, where they really should be designed away where possible, rather than reaching for them so regularly as part of public user facing APIs. I think it'd be easier as a library user to not have to grok macro definitions to be able to write rust. 
&gt; I can only recommend you come by our next CLI-WG meeting to get invovled. Would you mind pointing me to where can I learn more about that?
&gt; ‚Ñï ‚àà Z ‚àà ‚Ñö The symbol you're looking for is ‚äÜ.
Removing you might be able to do via views. But that's only going to get you so far. Adding rows/columns will always require reallocation. &amp;#x200B; If you need to manipulate the structure of an \`ndarray\`, then it's probably not the right data structure for you, because it's basically an contiguous blob in memory (in the form of a \`Vec\`), where the n-dimensional structure is created through (more or less fancy) indexing.
Now that the \`c\_variadics\` feature is available in nightlies (huge thanks to Dan Robertson and everyone who reviewed and mentored his work), I'm working on translation of variadic C functions to Rust (using [C2Rust](https://github.com/immunant/c2rust)). After that works, we plan to release C2Rust on [crates.io](https://crates.io) :D
Putting the finishing touches on [my OpenXR bindings](https://github.com/Ralith/openxrs), which should provide a relatively pleasant experience for writing VR software in Rust; certainly far more fun than dealing with windowing APIs!
The first thing I recommend to any beginner is clippy. On the playground, go to tools and click on Clippy. It will then show a number of common mistakes and unidiomatic code and what you'd usually see instead. I got 3 suggestions on how to improve when running it on your code. It's not perfect and is no substitute for going over the code with a keen eye, but it's a great way to start.
[in_sized_arena](https://docs.rs/compact_arena/0.1.0/compact_arena/fn.in_sized_arena.html)'s docs reference a `with` function that doesn't seem to exist.
FYI: /r/rustcryptofin 
This seems like a solid use case, but I'm a bit concerned about Helix. It doesn't seem to have been updated in nearly a year, and there are longstanding small PRs open with no movement. Have the developers moved on?
I think you could resolve that by `option_one` (and others) taking and returning `self` rather than `&amp;mut self`?
Why do this code work? [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d9ebbaedd62e1ab1932649481c5cca21](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d9ebbaedd62e1ab1932649481c5cca21)
There's also RwLock. There's a few variants of this (std::sync::RwLock, parking_lot::RwLock). Any number of readers can be present, but if there's a writer no readers can access it. Especially if you don't often write the value it's a pretty nice way to avoid true mutual exclusion. I prefer parking_lots versions of these personally. RwLock doesn't do anything regarding stale reads or fancy STM as /u/ssokolow mentioned, but it's probably enough for your use-case until you find otherwise.
Way to go Pauan!!! 
Does this work with gdb? I hear Rust support in gdb is in a much better shape than in lldb.
Looks like a parser bug that [was just found](https://github.com/rust-lang/rust/issues/59418).
Cool project! I only glanced over it but since you seem to have many mutually exclusive options maybe it is better to model them as rust enumerations? I do it like this in my toy project: https://github.com/NickeZ/backlight/blob/master/src/cli.rs
&gt; Edit: My application does not mind if the value may be outdated for a few requests. But I guess that is the reason why the mutex type is not allowing this, because doing it may lead to inconsistencies Worse than that. You can get a value that's half in one state and half in another because the read can happen at *any* time relative to the write.
The Swift "ABI Stability Manifesto" I linked lays out a good description of this problem. What you're talking about is _source_ compatibility, or the stable interfaces as they're defined by source code. You're right, that's very stable moving forward. What I'm talking about is _binary_ compatibility, or the interfaces between compiled programs and libraries. That is not stable (nor should it be, right now). The problem with binary compatibility is that without a stable ABI, interfacing between binaries compiled with different versions of `rustc` is undefined behavior (not always "here be dragons" UB but it can be unpredictable). There can be nuances and changes in things like a struct's memory layout or alignment that results in nasty memory bugs. You need ABI stability when you distribute shared/static libraries instead of source code (application extensions, closed source libraries, application updates, etc). Basically anywhere you're not sending source code to an end user, you need ABI stability. Right now it's possible by creating an unsafe C wrapper, but you lose just about all the nice parts of safe rust. 
No reason not to get things started, IMHO. More people will join over time. If experience is lacking in some areas, folks with the needed experience will crop up sooner or later, no doubt. 
I'm sorry this is the out of box of this post. But what is exactly pullparser anyway? I've read a github readme, but I'm not figuring out what it is for?
I found it from the same source
sounds like a very grumpy person
The idea of the pull parser is that it gives its results as a stream of events, which are start/end tags and text. The biggest advantage is speed, it doesn't need to do an allocation per AST node as a more traditional parser. The crate does not parse front matter. I don't *believe* that's standardized in any real way.
So far, users are being super nice and even though I have had a decent amount of very bad bugs, users were always super constructive. It's probably because the project was still very new, and users are "early adopters". ... But I have seen some of these crazy aggressive comments in other projects. If tantivy success keeps rising, they will come for sure. Good luck with your backend project for Mixxx !
Thanks much for that first link ‚Äî it's what I was looking for!
Still working on linking a C library to a Rust wasm file. The past weeks I've been figuring out how to use the libwebp library and implemented a higher level interface. It's not super important but in the case of failure I have something safe that can be compiled at least for the desktop. The goal is to use it in Electron (node). I moved from the cmake crate to cc and now use the clang compiler with the llvm archiver llvm-ar to target wasm-unknown-unknown. It took quite some time as I had to find the C headers on Windows and find solutions to errors in a sea of warnings. I had to pass a flag and then remove printing to stderr in the libwebp library in one file. Maybe there is a better flag, maybe nostd? The end result were object files for each c file and one archive file. However, the extension is .a so it already worked (?) because it wasn't compiling for windows anymore. Afterwards, I tried to compile a test but it didn't work but ironically I had forgotten add the wasm target and that the test included Files. It still didn't work which was strange at first but I realized that rust cannot run wasm files and I have now two wasm files, one for the C library and one for the test file. I have no idea if it works but I'm super happy right now and even if that fails I still have a few compile options.
To explain: - "x ‚àà A" means x is an element of A - "A ‚äÜ B" means A is a subset of B
I distinctly remember this not working in a previous rust version but apparently it does in the current version due to an issue with the original builder not living long enough. Trying it out in the playground just now though it seems to be working. Either it was made available with NLL or I am missing something in my trivial test.
Thanks for the feedback! I definitely see how that would be valuable, to be honest I never thought of implementing it that way and it is blowing my mind a little.
&gt; Runtime also puts some constrains on the user - e.g. you cannot use tokio async I/O in Actix actors, as they all run on single thread. Actix is built on top of Tokio and allows the use of futures. It also uses Tokio in a multi-threaded configuration, which should presumably blunt the impact of system calls.
Yeah! I remember porting a number of X11 extensions to XCB including glx. I wrote the original indirect gl bits in Mesa. What a fun time.
So what's the question? Your source says it's a bug.
Indeed. Thank you! 
man, seriously: congrats on the crate name. Genius! 
Nice work, it's super pretty! 
Thanks for the transparency! I think that this is the information most people have been missing -- I've added a comment to the PR in question with a link here and a summary. You've given us something wonderful for free, and we definitely want you to focus on better things to do with your time like your family and providing for them if they aren't leaving you time to hack on the Rust ecosystem with us. Thanks for getting us this far -- we hope that development for v3 goes smoothly in the meantime! :)
Believe it or not, he's gotten a lot better over the years. I interacted with him a bit in IRC many years ago, and back then he was abrasive and completely unproductive and frustrating to try to engage. These days I still find it very frustrating, but at least it's often constructive.
wtf
1.1 + 1.9 = 2.10 Doesn‚Äôt seem right.
Any advice?
welcome!
Looks awesome, especially the responsive GUI! A cool extension would be to allow for non-affine transformations as the iterated functions so that you can render [fractal flames](https://flam3.com/flame_draves.pdf).
What is the best way to read a part (defined by a variable) of a file into a vector? I don't want to read the entire file all at once, as that would make opening large files impossible if your computer can't handle it. The amount that I'm reading ('view size') may change, so I can't just create a static array, so I would use a Vector of u8's. For reading from the file https://doc.rust-lang.org/std/io/trait.Read.html#method.read_exact wants a slice of u8's. I could use the Vector method of 'as_mut_slice()', but the size of the Vector may be larger than the current 'view size' (such as, reading 64bytes of data, then shrinking it to 32bytes and re-reading I assume would read 64bytes). I'm not sure what the best way to do this is, create a slice of the size of 'view size', read the data to that, then clear the vector and set it to that?
that's good to hear, I just saw his comment in here. glad he's willing to engage in discussion
You can slice the vector to a size like so: `f.read_exact(&amp;mut buf[..60])`
Yeah, that's just flagrantly anti-user, and anti-operator. The people who actually use things like TLS libraries and other mission-critical code in important deployments, at scale, do care about safety, and they know that it is observably true that developers do not write safe C.
&gt; Concurrency is generally a bad thing That's also just fundamentally not an argument you can get away with in $current_year. Processors have more cores and the cores aren't getting faster. If your workload is performance-sensitive, concurrency is not optional anymore.
&gt;XCB &amp;#x200B; I always hope that someone can complete this project. [https://github.com/jeandudey/xrb-rs](https://github.com/jeandudey/xrb-rs)
Oh, I thought you meant loops in the abstract. loop {} isn't unsafe because control flow doesn't exit the loop; my issue is specifically with resources going out of scope without their destructors being called.
The three targets are free. Don‚Äôt know about artifacts.
So we're starting to experiment with best practices here. Currently, I have some [experimental templates](https://github.com/crate-ci/resources/tree/master/az-pipeline/unstable) that others can pull into their repo and [use](https://github.com/crate-ci/resources/blob/master/test/azure-pipelines.yml). We're [discussing the path forward](https://github.com/crate-ci/resources/issues/2) and it sounds like we're going to get a `RustToolsInstall` "task" (plugin) that does the basic rustup stuff. I eventually want to turn my github-install experiments into a task as well (think trust's `install.sh` but cross-platform). I'll eventually get back to working on [`cargo-tarball`](https://github.com/crate-ci/cargo-tarball) which will take care of trust's packaging of a binary. You can then use Azure Pipeline's git hub uploading task to publish. I know someone had an example of this but I do not remember which crate it was that I was talking with.
For free - All platforms - I think it is 10 concurrent jobs I don't know about MS's artifact repository but they do support publishing to github releases. I know of at least one CLI that is using that but I don't remember which :(
Also, a [previous discussion on Azure Piplelines](https://www.reddit.com/r/rust/comments/aw4b1g/azure_pipelines_for_rust_projects/?st=jtp8mje2&amp;sh=332b347e) that probably has some relevant stuff.
[Published E-Nguyen 0.1.2 for Linux](https://github.com/e-nguyen/e-nguyen) I'm building a music visualization library / program. Going to start adding some more basic visual sources and open up the road to 3D models &amp; music-based materials. It works using the playback monitors on PulseAudio to get the audio data into the compute module so that you can do GPU-ish things with it. Learned the math for FFT's and started with a library solution for my prototype but decided I need to implement my own solution for transforms using the GPU to get the latency down &amp; quality up.
Thank you for your explanation.
Aren't Rust programs by default compiled towards the main system C library and kernel though, like C++ and other languages? I see there is a C++ library too, but isn't that also compiled against a C library like Glibc? And if there is a Rust library, where the heck is it at?
What's the idiomatic way to represent a directed acyclic graph? My nodes need a way to know who their children are, but I'd also like a way to make the nodes inherently mutable. So I think I need some kind of node manager which tracks their relationships, to avoid borrows and keep them mutable? Suffice it to say I'm still in the "fighting the borrow checker" phase.
It's UB tho
Is RefCell not suitable for you?
Thank you for your guidance, I think your code is better than my code. through your code, I learned &amp;mut self, I really figured out &amp;mut self, &amp;self and self. The purpose of this code is to analyze characters. Will be used to parse the template. So need to care about all the characters. About saving a copy of `&amp;str` -&gt; `text.chars().collect()`. I looked at the std library and found that `text.chars()` needs to recreate Chars every time. If you follow this way, you will create chars multiple times. I still don't know will not cause any effect. `this_line` function will return current line text. So your code is wrong, If I only care of ASCII character. I found a solution: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1817674272df621e0e4c112a68406938 In fact, all the characters to care about are, so this is not feasible. That's why I will create a new String by constructing vec. finally, here is my code after I modified it. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d9654629709edf497b4d470c1e2a0eb8 
About why I use `Rc&lt;RefCell&lt;_&gt;&gt;`, The earliest my code is almost the same as `45c7bc38ac96a82705fb7afe0982c2fa`, But I still haven't mastered `&amp;mut self`, `&amp;self` and `self`. (Now I know it.) And I use `RefCell` because the Rust document say: "Because RefCell&lt;T&gt; allows mutable borrows checked at runtime, you can mutate the value inside the RefCell&lt;T&gt; even when the RefCell&lt;T&gt; is immutable." And then, I found that my code has multiple places that need to be mutable. So I add `Rc`. I think maybe I understand it wrong. I also wrote the wrong code during the process of writing this code. like this: &gt; let mut position = self.position.borrow_mut(); &gt; \*position -= 1 Later confirmed that this is not working. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5e78a7a849825fb1a7140a6f19999f9f Now I can understand a little bit. (not all) &gt; I'm trying to come up with a way to hold the internal string as a &amp;'a str (ie. a view on a string slice) instead of a Vec&lt;char&gt; About this, @CrumblingStatue give a solution, and I also used `text: &amp;str` at first. Soon I found the problem. `text.chars()` Need to create a new `Chars` every time. finally I used `Vec&lt;char&gt;` . I think your last code is better. If you know how to use `text: &amp;str` please let me know. And thanks for your help. 
Thank you
Who says Rust is supposed be a replacement for C. That like saying the airplane is a replacement for the horse. They accomplished similar tasks but the approach is very different. C is essentially portable assembly language. You will never have a replacement for it. Horses can go where airplanes or even cars can go but what would our world be like if our transportation stopped progressing at horses. I just got back from skiing in Nagano. I was able to get there in one day from Shanghai. If I had to go on horseback I would still be on the way there.
You could expand `accumulating_println` into something that creates a symbol in a specific elf section, then use some build tools at build time to list such items and do something with them. A lot of fragile low-level, linking/compile time work, but it could be done.
One of the ways I like to learn new langauges (\*cough\*Rust\*cough\*) is doing Project Euler problems. One of the big utilities I've used a lot in my solutions is a Sieve of Eratosthenes. In Go my api was something like ```is_prime(n)``` where checking if a number was prime that wasn't currently in the sieve would, under the covers, expand the sieve. This improves the ergonomics of needing to check if a number is in the sieve EVERY time ```is_prime(n)``` is called. In Rust, I tried to model the sieve as immutable (so that ```&amp;Sieve``` could do ```is_prime``` checks, without ```mut```). But the hidden expand call is (obviously) a problem. Which leads to my question. Would this be a good use of interior mutability? Or is this a situation where the clarity of ```&amp;mut Sieve``` vs ```&amp;Sieve``` would help down the line? Alternatively, is there a more idiomatic way I could be handling this API?
I've looked into RefCell and RwLock. Still a little hesitant because of the runtime overhead, but I'm willing to hear arguments in favor. For some background, this is to rewrite some legacy c++ software which implements a kind of directed acyclic graph by storing pointers and dereferencing them, with null-checks but no read-write locks of any kind. (think e.g. the hierarchical nature of a SolidWorks model) I imagine from the perspective of Rust this would be "unsafe," but the consequences of a data race in this specific application are insignificant to the user.
&gt;C has a spec: C was developed between 1972 and 1973 (Unix was rewritten in C in 1973), its first specification was drawn up in 1989 (16 years later), and to this day there are still 200+ instances of Undefined Behavior in the C specification (see Annex A). This reminds of an insight from [https://cacm.acm.org/magazines/2010/2/69354-a-few-billion-lines-of-code-later/fulltext](https://cacm.acm.org/magazines/2010/2/69354-a-few-billion-lines-of-code-later/fulltext), that was astonishingly novel to me the first time I read it: &gt;Unfortunately, this view is na√Øve, rooted in the widely believed myth that programming languages exist. &gt; &gt;The C language does not exist; neither does Java, C++, and C#. While a language may exist as an abstract idea, and even have a pile of paper (a standard) purporting to define it, a standard is not a compiler. What language do people write code in? The character strings accepted by their compiler. Further, they equate compilation with certification. A file their compiler does not reject has been certified as "C code" no matter how blatantly illegal its contents may be to a language scholar. Fed this illegal not-C code, a tool's C front-end will reject it. This problem is the tool's problem. C's simplicity means it's spec is easy to follow, but practical realities do catch up. Also see: GNU extensions and the Linux kernel. My own thoughts are captured really well in this talk "Platform values, Rust, and the implications for system software": [https://www.youtube.com/watch?v=2wZ1pCpJUIM](https://www.youtube.com/watch?v=2wZ1pCpJUIM) &gt;Values (positive traits that you're choosing amongst) are really core to the decisions we make. If we have to choose between two things, values will dictate how we make that choice, and **different platforms make that choice differently**. &gt; &gt;Too often we look at the different choices that a different platform has made and we **either criticise those choices or embrace those choices**, but **what we're actually doing is commenting on our own values** relative to the values of a different system. The author's core values are clearly simplicity and portability, which are C's core values as well. On the other hand, robustness and safety are near top of the list of Rust's core values, which perhaps is really really hard if not impossible to also be simple. Then, it is no surprise that Drew does not find Rust as alluring as the Rust community. We have different core values, and that is alright!
This is a somewhat strange implementation of fixed-point: the decimal part is stored in backward bit order. The implementation of `Display` is plausible-looking, but note that `1.5` is now implemented as `(1, 5)`, which can't really be right. I think you'll be much happier just treating the fixed-point number as a single signed integer with an implicit decimal point. This makes writing the `Display` trait kind of tricky and slow, but `Add` becomes easy. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2d2f6408930a4413767e3b03440a8f44)) 
Depends on your use case, but an arena (like [toolshed](https://crates.io/crates/toolshed)) or my own (very young) [compact_arena](https://crates.io/crates/compact_arena) might be a good solution.
Thanks, will fix soon.
&gt;once we make a complicated system.... we can figure out how to make a simple system This is the same sentiment that got us Unix and it‚Äôs sister C, ironically. As a reaction to the convoluted, top-down Multix for the case of the former, and out of necessity for the latter. But I digress. 
I am puzzled when u/nbHtSduS writes: \&gt; \[...\], and Rust is the result of C++ programmers designing a new programming language‚Äù. \&gt; \[...\], and Rust was designed by the folks at Mozilla - whose flagship product is one of the largest C++ codebases in the world. &amp;#x200B; While Rust was originally designed at Mozilla for use in Servo, I don't think it is reflective of the language nor its designers to say that it is a result of C++ programmers designing a new language. As the newest language team member, I can safely say that I'm not a C++ programmer nor do I usually take inspiration from it. Instead, I regularly take inspiration from Haskell et. al. I think this is true of other language designers of Rust as well who came before me and who are still there. There's certainly a disproportionate amount of familiarity with various FP languages (Haskell, Scala, ...) in the language team as compared with the community at large. I think one can also tell from Rust that the Ocaml and Haskell inspiration is strong (to the point that it's fair to call Rust an ML dialect). That said, Rust is a \*detail oriented\* language and so it must care about low level details as C++ and C also must. Thus it should be no surprise that elements (e.g. memory model) of C and C++ exist in Rust as well.
Check out BufRead and BufReader too. Depending on what you actually plan to do with the data we may be able to give better advice.
I don't mean "the" rust library so much as "a" library written in Rust. For example all the shared libraries in a game, a closed source static lib, application extensions distributed as shared libraries, etc. Whenever you want to distribute binaries that aren't executables, the ABI problem rears its head. 
My only answer is yes c++ will stay long I assume ppl will still talk about c++ in 2030. what should change in c++ is the compiler. They need to detect security issue and memory leaks at compile time
Started contributing to [servo](https://github.com/servo/servo)! Very excited to engage with the Rust community. So far the servo people I've interacted with have been awesome. 
I am not an experienced Rust user but in my opinion you should not hide the fact that the sieve is expanded and preserved. So requering mutability is IMHO nicely documenting how the API works.
Attempting to make a basic hex editor. So loading one large portion of the file that the user can 'see' right now, and then loading the next large portion when they scroll down to it. Don't know if I'll finish it, but that's what I'm attempting.
Sorry if I didn't understand well your question, but the new dbg! macro (https://doc.rust-lang.org/std/macro.dbg.html) prints out the line number. Maybe you could use this macro or see its source and make something similar?
Could you explain a bit more? What do you mean by template and dynamic data in this?
Ah, for that I guess just `seek` though the file and then `read_exact`, which you're probably doing.
Yep, thanks.
Which brand? They soon will
Do you really need to do it at build time? You could probably use [inventory crate](https://crates.io/crates/inventory) to register all the call sites. Combine that with some `lazy_static`, and you should be able to do what you want at runtime.
And that's why Add isn't implemented for Semver
Rust implementation of node seems interesting but in README it's stated that this is still a proof of concept. When is the production ready release planned?
Awesome! Been playing with something similar (simplex noise terrain with glium and imgui) in the past weeks. This inspired me to finish!
Anyone have a mirror for this?
You made me laugh :)
I have a problem with this: &gt;impl&lt;T&gt; Foo&lt;T&gt; where T: Baz &gt; &gt;\[...\] &gt; &gt;but this is an alternative &gt; &gt;impl Foo { &gt; &gt;type T=Baz &gt; &gt;} Foo in the second snippet it is not a generic type, and it unconditionally declares an inherent associated type `T` as an alias for the type `Baz` (which in the where clause of the other is a trait instead of a type).
with its "verbose-errors" feature, nom already provides enough context to write good error messages from there, see for example https://github.com/Geal/nom/blob/master/doc/error_management.md#merr-pattern-matching The issue is that most people are looking for a more turnkey solution, especially when the parser is still in development
Neat project! I've considered rebuilding my WM and its supporting infrastructure in Rust, but it took me many years of dealing with X to do it. It's a huge task, and while parts of it were fun, it's not something I'm eager to jump back into. I'd much prefer to keep working on text handling in Rust. I do also kind of wonder for hope long I'll be able to continue using an X window manager with Wayland looming.
Alright this post is of super interest to me. I'm building a scripting sandbox game, and the idea of a multi language sandbox is appealing enough to me that I sat down with the webassembly spec and wrote an interpreter from scratch There's 2 major problems i ran into in this process though which are extremely unfortunate 1. There is no way to compile JS to webassembly, and JS is the most critical language for me to support (widespread even though i hate it) 2. Different languages have different schemes for representing objects This means that A: you cannot have a pure webassembly multi language sandbox, and B: you have to do a lot of faffing to get everything to work Take the example C++ -&gt; JS, where JS is running in some arbitrary backend, and C++ is webassembly. To pass a C++ object through to a JS module by reference, you need to be able to touch on every member of the object, which means that every C++ struct you declare has to look something like struct hello { double member = 0; SERIALISE() WRAP(member); END_SERIALISE(); } The easiest way to then pass it is by value, copy it into the JS execution environment, and then iterate over all the returned values back and stuff them into the C++ struct. Dynamic languages can add properties at runtime though, which means that really your common data format is a key/value store, aka super json which can be a little clunky to work with, although again not unworkable Altogether though this is unfortunate as it means that for most languages you need to define some some of serialisation scheme, which is somewhat non trivial to do Its not undoable overall, but its quite a massive faff to get it going correctly. If there were a simple way to turn JS into WASM it'd certainly help a lot as you could keep everything in-house as it (although there are obvious practicality problems). In the end I canned the project as not worth the time for my particular use case It is a super interesting area to explore though, if I had infinite free time i'd keep trying - and given that redoing the scripting sandbox is on my list of things to thoroughly enjoy I may attempt another go 
Awesome, welcome!
Thanks for spotting the typo, I have just fixed it! &amp;#x200B; Could you elaborate on what you find unclear in the phrase? Would **moving ownership of a value of a type that implements Copy has exactly the same computational cost of copying its value using** `.clone()` be clearer? (i.e. is it a formulation issue or a content issue?)
I am neither a web developer, nor a rust expert. A question though: I would assume that the typical rust developer and typical web developer are very different animals. Is this assumption incorrect? Is webassembly and rust merging the two types a little? How BIG is webassembly, i.e. how much is it used at the moment and will be in the future (approximately)?
Not so sure about webassembly and front end developer but I'm living proof that Rust and web developers are not different animals. I'm a Scala/Vue dev in my day job, building web apps, but have been using Rust for personal projects for a while now and plan to bring Rust into my professional work as a back end tool very soon. 
Yes I find it clearer. I think I just can't parse the *over* right.
Slides repository: https://github.com/azriel91/proc_macro_rules Online presentation: https://gitpitch.com/azriel91/proc_macro_rules/master?grs=github&amp;t=night#/ Was a little rushed for time (sorry! not super polished)
to be honest I only used structopt once, gumdrop was missing two features, I filed two requests on github and some time later the features were added https://github.com/murarth/gumdrop/issues/5 https://github.com/murarth/gumdrop/issues/10 it does the job (for me) with lesser dependencies (smaller filesize?) so I'm happy with it
Can you say anything about the industry in general? How widely used is webassembly? How widely used is rust (outside Mozilla?)
[Assemblyscript](https://github.com/AssemblyScript/assemblyscript) is Typescript to wasm, which is just javascript with explicit types.
This `Fixed` implementation is really broken. `(1, 5)` is no where `1.5`, what about `(1, 20)`? Would `1.1 + 1.10` == `1.11`?
Man so the problem with assemblyscript is that I can't expect users to be able to port regular JS to strictly typed typescript I have a lot of background playing the game hackmud which uses a JS environment, but with just enough differences to make very hard to port code from the wild to assemblyscript, which means that a lot of crypto etc goes out of the window. This raises the bar to entry by quite a bit While i'd love to be able to use this, unfortunately its just simply not javascript
Is there an ergonomic, allocation-free way of doing a case-insensitive string comparison? I really miss C#'s **InvariantIgnoreCase** string comparison option. Followup: has anybody made a HashMap that will take a string as the key and perform case-insensitive lookups?
You escaped all your backquotes and asterisks with backslashes (\\\`impl\\\` instead of \`impl\`)
What kind of applications use an event pump that's faster than a message queue?
So, they built this to cut ties with one unstable dependency, but then they use another unstable dependency as their internal storage?
[unicase](https://crates.io/crates/unicase) does both.
https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/rust-java.html
From a Scala/Vue perspective webassembly is an interesting technology and something to play around with but it's not being widely used. Definitely something to keep an eye on but it has a long way to go before you start seeing widely adopted.
I don't think I have enough details to know if it will work for you, but a good initial plan to try is to replace the use of pointers with indices into a `Vec&lt;Node&gt;` and go from there. You could also look at [`petgraph`](https://docs.rs/petgraph), either as something you might use directly or for implementation ideas. Also, if `RefCell` solves this problem for you nicely, then it might be good enough. It's true that it does have some overhead, but it is very small, so it might be good enough. &gt; but the consequences of a data race in this specific application are insignificant to the user Just a small clarification here: a data race is _always_ undefined behavior. It's never correct to have them. This is just as true in Rust as it is in C++ or C. Rust just won't let you do it in safe code. If you want to "not care" semantically about the corresponding race condition, then using atomics is probably the most straight-forward translation.
Noodling with an disp / imshow equivalent for "debug display for images" use cases.
I was just going to recommend unicase. I've been using it a while myself. The one caveat is that the `HashMap` API was designed around the `Borrow` trait for lookups which means you can only use `&amp;Unicase&lt;String&gt;` for lookup (which must be constructed from an owned value) if you have a `HashMap&lt;UniCase&lt;String&gt;, _&gt;` and not a `&amp;UniCase&lt;&amp;str&gt;`. Implementing `Borrow&lt;UniCase&lt;&amp;str&gt;&gt; for UniCase&lt;String&gt;` is *technically* possible with unsafe code but it isn't compatible with the current internals, AFAICT: https://github.com/seanmonstar/unicase/issues/22 You can work around this by using `UniCase&lt;Cow&lt;'_, str&gt;&gt;` as the key type instead, but it's not exactly what I would call ergonomic.
It‚Äôs quite recent that `Box&lt;FnOnce()&gt;` has become usable. Before that, you needed to use the `Box&lt;FnBox()&gt;` type, but that is also unstable since `Box&lt;FnOnce()&gt;` is objectively superior if it could be made to work‚Äîand it finally has, so `FnBox` will be being killed off. I only discovered this stuff a week or two back when looking at the state of FnBox stabilisation, and discovering that `unsized_locals` was now a thing.
Just so you know, actix documentation has been making long strides even over the past week. Make sure you check out the book (user guide). I'm personally trying to use actix as a runtime model for a company project, and my boss/future self won't be happy with me if I bet this project on an undocumented and hard to use framework, so I'm working at a semi-professional level on making actix proper (not actix web) a first class project. Its days of being a secondary project which only exists as a host for actix-web are numbered. 
Ekhm... First of all - I said: "not that far off", second of all - most of the time in desktop computing you are not performing high-cpu number crunching (what this benchmark does), third of all - even if you have to it makes more sense to write everything in Java and replace bottleneck part in soemthing which may be more performant in that case; and last but not least: https://benchmarksgame-team.pages.debian.net/benchmarksgame/how-programs-are-measured.html - of course it states: "(Note: Those measurements include startup time). " so Java will always be slower (though with new tools that would allow compile to native binary this may help) -- but I was referring to actuall execution speed of the same algorithm, i.e. ignoring startup time...
It does need to happen at build time (for some definition of build time), but I think something like this would work. What I could do is accumulate all the calls and create a binary that outputs the text file. Then my build script could build everything and then run that binary. I think this is the best approach I've seen so far. Thanks! 
Just starting to look into Rust. I'd like to use systemstat as my pet project to tinker with and learn Rust. However, I failed at even executing its simple example :-( Appreciate any help. &amp;#x200B; [https://github.com/myfreeweb/systemstat](https://github.com/myfreeweb/systemstat) &amp;#x200B; I installed latest version of Rust toolchain in a CentOS 7 server. `git clone` [`https://github.com/myfreeweb/systemstat.git`](https://github.com/myfreeweb/systemstat.git) `cd examples` `ls` [`info.rs`](https://info.rs) &amp;#x200B; How do I get execute this example? I tried: `cargo build --release` at the parent directory. It seemed to have built something with a few warnings.. `Finished release [optimized] target(s) in 14.90s` But, when I look at the release directory, I see nothing in the examples directory.. `[root@monitor systemstat]# ls target/release/` `build deps examples incremental libsystemstat.d libsystemstat.rlib native` `[root@monitor systemstat]# ls target/release/examples/` &amp;#x200B; Then I thought, may be I need to use rustc directly to compile a standalone example like this. I ran.. `root@monitor systemstat]# rustc examples/info.rs` `error[E0463]: can't find crate for \`systemstat\`` `--&gt; examples/info.rs:1:1` `|` `1 | extern crate systemstat;` `| ^^^^^^^^^^^^^^^^^^^^^^^^ can't find crate` &amp;#x200B; `error: aborting due to previous error` &amp;#x200B; `For more information about this error, try \`rustc --explain E0463\`.` &amp;#x200B; Inspite of building systemstat earlier, it does not seem to recognise it. I gave up, and thought perhaps I could install systemstat crate using cargo and just try this example first. So, I did.. &amp;#x200B; `root@monitor systemstat]# cargo install systemstat` `Updating` [`crates.io`](https://crates.io) `index` `Downloaded systemstat v0.1.4` `Downloaded 1 crates (23.2 KB) in 1.48s` `Installing systemstat v0.1.4` `error: specified package has no binaries` &amp;#x200B; That fails too... :-( &amp;#x200B; I'm totally lost. How can I execute this example and get started? 
I've been working on [Compiling Pattern Matching to Good Decision Trees](https://github.com/Lapz/Compiling-Pattern-Matching-to-Good-Decision-Trees). My first try was completly wrong and I kinda misunderstood some parts of the paper. This week I plan to try and implement the stuff from [Warnings for pattern matching](http://moscova.inria.fr/~maranget/papers/warn/warn.pdf) into what I have already
The point is that messages in a message queue are transient whereas with an event store you keep the history.
I agree with /u/Indy2222, you should definitely not hide mutation; it's not worth the runtime cost anyway. What you could have is a fallible immutable lookup that doesn't expand the sieve, e.g. `fn try_is_prime(&amp;self, n: &lt;int type&gt;) -&gt; Option&lt;bool&gt;` and then a `fn is_prime(&amp;mut self, n: &lt;int type&gt;) -&gt; bool` that expands the sieve.
Yeah, those benchmarks are far off though. Some of them are four times faster, and the JVM doesn't take 8 seconds to start. Should also be plenty of time for hotspot to do it's thing. Also, you just asked for a benchmark my guy. I'm aware of how hard it is to make a meaningful benchmark, but benchmarksgame is probably the best approximation you're going to find.
X.X I appreciate the response but this sounds like a rabbithole I'm just not willing to go down. 
`cargo build` doesn't build the examples, just the crate itself (produces library artifacts for import in dependent crates). The `--release` flag just builds the crate with optimizations on, which takes longer and produces faster code but I don't think that's worth it if you're just interested in running an example. If you want to build and execute the example itself in one command, that would be `cargo run --example info`. If you want to just build the example, that's `cargo build --example info` and then the executable should be in `target/debug/examples`. `cargo install` only works for crates that specify a binary (executable) target, by having files under `src/bin/` and/or by declaring a `[[bin]]` section in their `Cargo.toml`. You _could_ actually run `cargo install --example info` and that would build a release executable of the `info` example and copy it to `~/.cargo/bin`, but that's probably not what you want to do. 
You should be able to run examples with `cargo run --example info`.
I actually can't find a relevant section in the Cargo docs that talks about dealing with examples, but it is mentioned in the [`cargo build` help page](https://doc.rust-lang.org/cargo/commands/cargo-build.html). Generally, the examples are also build in debug mode when running `cargo test` as well. But here's how you can run it: $ gt clone https://github.com/myfreeweb/systemstat $ cd systemstat $ cargo build --release --examples $ ./target/release/examples/info
Thanks for this. Learnt how examples work now. &amp;#x200B;
Thanks. 
Thanks for the detailed response. I learnt what cargo install does now. &amp;#x200B;
Sure. It also got us Python and Ruby after Perl. And Java/C# after C++, to an extent. Rust is probably the best system level language in existence right now, IMHO (:-P) but I certainly don't think it will remain that way forever.
For web development, Rust is kind of like node/typescript but with a different tradeoff. Node is about bringing libraries and tradeoffs from the frontend to the backend, and wasm(+Rust) is the complement: bringing the libraries and tradeoffs from the backend to the frontend. They also integrate really well together. A winning combination.
I hope the playground can use this. So we can play the "guessing game" example in the playground!
Cool project. More Kafka like tools we have he better. It might be worth changing the readme to better describe the similarities/differences with at least Kafka. For example, Kafka can store events indefinitely. retention.ms = -1 https://kafka.apache.org/documentation.html#topicconfigs
That‚Äôs pretty nice, seems like I know what I‚Äôll be playing with tonight ü§∑‚Äç‚ôÇÔ∏è
Yes, this is right, this way we have the complete control of our tool. I did [many improvements to the EventStore client](https://gitlab.com/YoEight/eventstore-rs/merge_requests?scope=all&amp;utf8=%E2%9C%93&amp;state=all&amp;author_username=Kerollmops) but that wasn't enough, and at the moment we needed to put our tool in production and it seemed better to create a simple version of an event store than fixing the already existing complex one. We used the Redis protocol instead of an obscure one to simplify the implementation. I know that it could be seen as egoism in a sense but doing that contributed to the Rust ecosystem in many ways, [we worked on sled](https://github.com/spacejam/sled/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+author%3AKerollmops) to make it fit a little more our needs, [we produced a generic RESP (Redis serialization protocol) library](https://crates.io/crates/meilies) that provides client and server side tokio codecs. Creating programs using unstable dependencies will likely make them become stable earlier due to more people being involved in them. By the way, we tested sled for a long time and didn't hit any bug, in the other hand the EventStore client closed connection because of problematic re-connection (due to bad handled heartbeating).
Only has `eq` though. Seems a bit underpowered - where are case-insensitive `contains`, `start_with`, `ends_with`, `find` etc.
[Here's the latest I saw](https://ticki.github.io/blog/why_im_leaving_open_source/)
Oops, I forgot to mention `set_read_timeout` as well. You would set a timeout on reads for your socket and check for what type of error you encountered to decide whether or not to break out of your looping read. let timeout = Some(Duration::from_secs(1)); stream.set_read_timeout(timeout).expect("set_read_timeout failed. . ."); loop { match stream.read(&amp;mut buf) { Err(e) =&gt; match e.kind() { ErrorKind::TimedOut | ErrorKind::WouldBlock =&gt; continue, _ =&gt; { println!("Error reading from tcp socket: {:?}", e.kind()); break; }, }, // rust's tcpstream doesn't throw errors if trying to read when the remote end has closed // it just returns a read of 0 bytes Ok(0) =&gt; { println!("Remote connection closed"); break; }, // successfully read data Ok(n) =&gt; { println!("Bytes read {}", n); }, } }
I went off and had a little play, seeing `Into` is implemented this works: ``` let mut m = HashMap::&lt;UniCase&lt;String&gt;, usize&gt;::new(); m.insert("hello".into(), 45); let b = m.contains_key(&amp;"hello".into()); ```
Is this one any better/different than the O'Reilly Rust book?
The tools in radare2 are quality, and it's wonderful to see radeco pushed further. Sharing to interested students!
Meson does not support that currently. It's Rust support does not support cargo at all unless you use a custom build target.
I read about someone who bought the O'Reilly Rust book for new hires with the thought that The Rust Programming Book was available online for free and therefore you could use both. However as far as I remember, TRPL donates proceeds to Black Girls Code, which is why I bought a copy of mine.
&gt; TRPL donates proceeds to Black Girls Code Oh man, wish I hadn't already bought the O'Reilly one...
Sounds right. Also, the online/offline-included-with-your-rustup-install TRPL is probably more recent then the dead-tree version which is stuck in 1.21 land, if I remember correctly, so that manager's thinking makes total sense to me.
Well, to be fair, that's what you asked for. :-) It supports your HashMap use case and supports case-insensitive comparisons. Case insensitive substring search is a totally different beast. If you want that, just use regexes, which will give you `contains`, `starts_with`, `ends_with` and `find`.
No, I mean the source of that issue
Well, good for you. I personally see importing an entire crate for basic standard functionality as excessive. Luckily, a usable prng implementation is short enough that I just end up copying one around my projects. Here's to the libs team eventually adding a prng in the stdlib. Rust should 
Well, good for you. I personally see importing an entire crate for basic standard functionality as excessive. Luckily, a usable prng implementation is short enough that I just end up copying one around my projects. Here's to the libs team eventually adding a prng in the stdlib. Rust should 
&gt; How widely used is webassembly? Extremely early stages; mostly experiments. &gt; How widely used is rust (outside Mozilla?) Back when we used to track production users, we grew from three or four to over a hundred. Then we stopped tracking explicitly. That was a while ago. Some sample companies using Rust in production: Facebook, Amazon, Google, Microsoft.
The thing to note is that converting `&amp;str` (the `"hello"` string literal) to `String` (the inner type of your `HashMap` keys, as `UniCase` is just a wrapper) copies the data to a new allocation, so it has a runtime cost which can add up over many operations. You also have to do this every time you look up a key in the map which is kind of redundant (since you likely already have the key data as a string slice but you're forced into creating a copy of it just to satisfy the API, or at best you have to move an owned string into and out of `UniCase` for the lookup). Constructing a `UniCase` itself has a cost too but all it does is check the string for Unicode multibye codepoints so it can decide whether it needs to do Unicode stuff or if it can use cheap bitmasking comparisons on the string bytes. This has the side effect of preloading the string data into the CPU cache which should speed up the subsequent hashmap lookup, so it ends up not really being an *additional* cost in practice.
You have a good argument. However, it can also be argued that having a basic prng (with documentation / sufficient warning like libc or python) would be useful enough to warrant its inclusion in the stdlib in spite of not being suitable for every usecase. I'd further argue that cryptography library authors who are gullible enough to use a prng will have many other issues plaguing their code. I am a person who tries to use random values when testing my crates. At present, cargo would have to download the appropriate version of `rand` each and every time someone wants to test my code. In my eyes, heavily depended upon functionality like time and random values should be included in the standard library. Luckily the libs team came around for the former, I hope they will also come around for the later. 
Then the safety of code is then dependent upon solving the halting problem.
Nobody can answer this for you. But perhaps we can help you choose a process through which to decide. Here's what I'd do if I were serious about it: * Spend a week reviewing the introductory learning materials for both languages. Write a few trivial programs in each language to get a feel for it. * Pick a non-trivial but small project that you've built before, perhaps in NodeJS, that you know well. It doesn't have to be a project that's "well suited" to Rust or Go. Anything really. But ideally pick a project that resembles what you actually want to do with the language. * Now re-implement that project in both Rust and Go. After each re-implementation, write down your experience. Include objective details such as "it took me X time to do Foo" and subjective details like "I felt Quux when I did Bar." * Compare and contrast your experience reports and make a decision based on them.
Definitely rust in my opinion, go lacks a lot of things I find necessary but in a backend language. 
Go is a stupidly simple language, so I don't think it will be too hard to learn it compared to Rust. If you plan to use Go/Rust for server applications, then Go will be probably a more practical choice right now, as it includes green threading out-of-box and has a huge number of libraries in this space. Though language itself is uninspiring to say at least, I've programmed on it a bit 4 years ago, but got fed up with boilerplate, stop-the-wrold GC (I hear it become better since then, but still) and stupid dependencies management. Nevertheless I think it's a great language for small server applications without hard performance constraints, but outside of this niche personally I don't think it's wort to use it. Rust on the other hand is much more complex and demanding, you will have to learn a much more, which is more difficult and time consuming, but arguably will make you better programmer even outside of Rust. Also a huge plus for you will be an ability to write WASM libraries which can be integrated with the rest of your NodeJS application. See for example this article: https://hacks.mozilla.org/2018/04/hello-wasm-pack/
&gt; exactly the gap I‚Äôm willing to fill For filling gaps, you will have a broader array of capability with Node + Rust than Node + Go. In most dimensions that Go differs from JS, Rust differs more.
Transferring data out of and into a webassembly environment is expensive, I'm not sure whether it's a good idea to constantly do both to allow communication. &amp;#x200B; I just spent the last week on optimizing the performance of a web assembly implementation, and this rubs me the wrong way.
I've written a lot of Go, and I've moved to Rust as my primary language of choice. I believe it's the language of the future in a way that Go just isn't. Having said that, Rust still has a lot of rough edges. For example, if you're writing webservices, I would choose Go over Rust for the time being. 
Entirely depends on the nature of your gap to fill
Coming from Rust, it was really frustrating to not be able to use Generics in Go. Using `interface{}` everywhere and then doing runtime casts that can panic seems pointless to me. Also, `cargo` is amazing compared to what Go has for dependency management.
\&gt; There is no way to compile JS to webassembly, and JS is the most critical language for me to support (widespread even though i hate it) There's something that I don't understand. If you need to support JavaScript, why would you need to crate a custom webAssembly runtime and compile JS to Wasm, since existing JS runtime (SpiderMonkey, V8 or JSC) can already run both Wasm and JavaScript ? What prevents you from using an existing JavaScript runtime ?
I started a prototype game in godot, but i quickly missed working with an environment where i have a fair bit of code control over the project. So I've been building it on top of rust instead. Re-using a lot of pieces from my previous game, but also switched from winit/glutin to sdl2. Have tilemap rendering working. I'm going to expand tiled-rs to support other layer types so i can take more advantage of things like groups &amp; objects.
&gt; A question though: I would assume that the typical rust developer and typical web developer are very different animals. I'm doing both professionally (not at the same time, it depends on the mission) and I don't feel a different animal when I'm switching side ;). &gt; Is webassembly and rust merging the two types a little? I have no idea about WebAssembly though, and I don't personnaly know anyone who actually uses it. Imho, it's more things like `Actix-web` or `Tide`, and the upcoming `async/await` which creates links between Rust and ‚Äútypical web developers‚Äù.
Sounds like a fun project! You are correct on the memory representation thing. I think that's why the C data structures are still so valuable. One standard for all. C-string is a great example.
There's an argument that certain languages are better for certain tasks. As a long time javascript dev, I'd offer that types end up being valuable to even a web dev for large code bases. Alot of people have turned to typescript to get javascript with types. I've turned to Rust to get types with web assembly for web dev, but also a lot more (server programming, systems programming, etc.). Rust for web backend is VERY good performance (critical in building things that scale cheaply), and if you end up being full stack, its super nice to be able to run your backend and front end in the same lang.
Static compilation vs dynamic compilation I think is a classic trade off. There's no one right way for all. I think static compilation will satisfy most people, but I hope my article inspired a few people to consider an alternative that one's language might not need to be in same lang, or even one big package.
Ahh, I think I see what you mean. Yes, that allocation on key lookup is something I want to avoid. I would appreciate it if you could post an example with `Cow`, I can't get it to work.
I don't think you need to declare anything out-of-line, unless I misunderstood something. Take a look at this example: use std::fmt::Debug; #[derive(Debug)] struct AccumulatedPrintln { location_info: &amp;'static str, format_str: String, args: Vec&lt;Box&lt;dyn Debug&gt;&gt; } inventory::collect!(AccumulatedPrintln); macro_rules! acc_println { ($format: expr $(, $rest: expr)*) =&gt; {{ // the mod is needed, because inventory::submit is a proc-macro, and they are disallowed // to expand to statements mod _force_item_context { use super::*; // location_info isn't inside the submit, because proc macros tend to lose location info const location_info: &amp;'static str = concat!(file!(), ":", line!(), ":", column!()); inventory::submit! { AccumulatedPrintln { location_info: location_info, format_str: $format.to_string(), args: vec![$( Box::new($rest) as Box&lt;dyn Debug&gt;, )*] } } } // "true" runtime code goes here... }}; } fn main() { println!("Hello, world!"); acc_println!("foo bar baz", 1, 2, true); for ap in inventory::iter::&lt;AccumulatedPrintln&gt; { println!("{:#?}", ap); } acc_println!("lulz", 42); } (no playground link, because AFAIK you cannot use arbitrary crates there?)
I just want to address some points so you don't mis-inform the op: &gt;Using interface{} everywhere and then doing runtime casts that can panic at runtime makes the type system seems pointless to me. This is not true. You don't have to use interface{} everywhere and casting the the interface to the right type will not panic the runtime if you do it properly. &gt;Also... if x, err := function() pattern frustrates me. The ? operator in Rust is such a better alternative. They are working on better error handling which seems to go into right direction. Personally i don't have a grip with checking errors like that, it's just a nitpick, if you like the language is okay, if you don't, it's the nail in the coffin. &amp;#x200B; &gt;Also, cargo is amazing compared to what Go has for dependency management. They also do good progress in this area as well. &amp;#x200B; To the OP, there's a huge, huge difference between Rust and Go. While with Go you will be up and running in a week, you'll need much much more than this to be productive with rust. Take this into consideration before you make your choice, you'll need a lot of time. &amp;#x200B; Another point for OP, i assume you're using node for web related stuff. Rust does not shine there. &amp;#x200B;
Going through the second chapter of O'Reilly's *[Programming Rust](https://www.amazon.com/Programming-Rust-Fast-Systems-Development/dp/1491927283/ref=sr_1_fkmrnull_2?keywords=programming+rust+oreilly&amp;qid=1553612907&amp;s=gateway&amp;sr=8-2-fkmrnull)*. They start out by walking you through how to build a web-server with the Iron crate, but the final code doesn't compile. Here's the final code: extern crate iron; #[macro_use] extern crate mime; extern crate router; extern crate urlencoded; use iron::prelude::*; use iron::status; use router::Router; use std::str::FromStr; use urlencoded::UrlEncodedBody; fn main() { let mut router = Router::new(); router.get("/", get_form, "root"); router.post("/gcd", post_gcd, "gcd"); println!("Serving on http://localhost:3000..."); Iron::new(router).http("localhost:3000").unwrap(); } fn get_form(_request: &amp;mut Request) -&gt; IronResult&lt;Response&gt; { let mut response = Response::new(); response.set_mut(status::Ok); response.set_mut(mime!(Text/Html; Charset=Utf8)); response.set_mut(r#" &lt;title&gt;GCD Calculator&lt;/title&gt; &lt;form action = "gcd" method="post"&gt; &lt;input type="text" name="n"&gt; &lt;input type="text" name="n"&gt; &lt;button type="submit"&gt;Compute GCD&lt;/button&gt; &lt;/form&gt; "#); Ok(response) } fn gcd(mut n: u64, mut m: u64) -&gt; u64 { assert!(n != 0 &amp;&amp; m != 0); while m != 0 { if m &lt; n { let t = m; m = n; n = t; } m = m % n } n } fn post_gcd(request: &amp;mut Request) -&gt; IronResult&lt;Response&gt; { let mut response = Response::new(); let form_data = match request.get_ref::&lt;UrlEncodedBody&gt;() { Err(e) =&gt; { response.set_mut(status::BadRequest); response.set_mut(format!("Error parsing form data {:?}\n", e)); return Ok(response); } Ok(map) =&gt; map }; let unparsed_numbers = match form_data.get("n") { None =&gt; { response.set_mut(status::BadRequest); response.set_mut(format!("form data has no 'n' parameter\n")); return Ok(response); } Some(nums) =&gt; nums }; let mut numbers = Vec::new(); for unparsed in unparsed_numbers { match u64::from_str(&amp;unparsed) { Err(_) =&gt; { response.set_mut(status::BadRequest); response.set_mut( format!("Value for 'n' parameter not a number: {:?}\n", unparsed)); return Ok(response); } Ok(n) =&gt; { numbers.push(n); } } } let mut d = numbers[0]; for m in &amp;numbers[1..] { d = gcd(d, *m); } response.set_mut(status::Ok); response.set_mut(mime!(Text/Html; Charset=Utf8)); response.set_mut(format!("The greatest common divisor of the numbers {:?} is &lt;b&gt;{}&lt;/b&gt;\n", numbers, d)); Ok(response) } ...and here are the compiler errors I get: error[E0631]: type mismatch in function arguments --&gt; src/main.rs:15:12 | 15 | router.get("/", get_form, "root"); | ^^^ expected signature of `for&lt;'r, 's, 't0&gt; fn(&amp;'r mut iron::request::Request&lt;'s, 't0&gt;) -&gt; _` ... 22 | fn get_form(_request: &amp;mut Request) -&gt; IronResult&lt;Response&gt; { | ----------------------------------------------------------- found signature of `for&lt;'r, 's, 't0&gt; fn(&amp;'r mut iron::Request&lt;'s, 't0&gt;) -&gt; _` | = note: required because of the requirements on the impl of `iron::middleware::Handler` for `for&lt;'r, 's, 't0&gt; fn(&amp;'r mut iron::Request&lt;'s, 't0&gt;) -&gt; std::result::Result&lt;iron::Response, iron::IronError&gt; {get_form}` error[E0631]: type mismatch in function arguments --&gt; src/main.rs:16:12 | 16 | router.post("/gcd", post_gcd, "gcd"); | ^^^^ expected signature of `for&lt;'r, 's, 't0&gt; fn(&amp;'r mut iron::request::Request&lt;'s, 't0&gt;) -&gt; _` ... 52 | fn post_gcd(request: &amp;mut Request) -&gt; IronResult&lt;Response&gt; { | ---------------------------------------------------------- found signature of `for&lt;'r, 's, 't0&gt; fn(&amp;'r mut iron::Request&lt;'s, 't0&gt;) -&gt; _` | = note: required because of the requirements on the impl of `iron::middleware::Handler` for `for&lt;'r, 's, 't0&gt; fn(&amp;'r mut iron::Request&lt;'s, 't0&gt;) -&gt; std::result::Result&lt;iron::Response, iron::IronError&gt; {post_gcd}` error[E0277]: expected a `std::ops::Fn&lt;(&amp;mut iron::Request&lt;'_, '_&gt;,)&gt;` closure, found `router::Router` --&gt; src/main.rs:19:5 | 19 | Iron::new(router).http("localhost:3000").unwrap(); | ^^^^^^^^^ expected an `Fn&lt;(&amp;mut iron::Request&lt;'_, '_&gt;,)&gt;` closure, found `router::Router` | = help: the trait `for&lt;'r, 's, 't0&gt; std::ops::Fn&lt;(&amp;'r mut iron::Request&lt;'s, 't0&gt;,)&gt;` is not implemented for `router::Router` = note: required because of the requirements on the impl of `iron::Handler` for `router::Router` = note: required by `&lt;iron::Iron&lt;H&gt;&gt;::new` error[E0599]: no method named `http` found for type `iron::Iron&lt;router::Router&gt;` in the current scope --&gt; src/main.rs:19:23 | 19 | Iron::new(router).http("localhost:3000").unwrap(); | ^^^^ | = note: the method `http` exists but the following trait bounds were not satisfied: `router::Router : iron::Handler` error[E0277]: the trait bound `urlencoded::UrlEncodedBody: plugin::Plugin&lt;iron::Request&lt;'_, '_&gt;&gt;` is not satisfied --&gt; src/main.rs:55:35 | 55 | let form_data = match request.get_ref::&lt;UrlEncodedBody&gt;() { | ^^^^^^^ the trait `plugin::Plugin&lt;iron::Request&lt;'_, '_&gt;&gt;` is not implemented for `urlencoded::UrlEncodedBody` | = help: the following implementations were found: &lt;urlencoded::UrlEncodedBody as plugin::Plugin&lt;iron::request::Request&lt;'a, 'b&gt;&gt;&gt; error: aborting due to 5 previous errors Some errors occurred: E0277, E0599, E0631. For more information about an error, try `rustc --explain E0277`. error: Could not compile `iron-gcd`. To learn more, run the command again with --verbose. What am I doing wrong here? 
This is the official Rust book, available at `rustup doc`.
Figured it out. In my `Cargo.toml` file, I was using a newer version of the `iron` crate than the book was. I guess the new version isn't backward compatible. Still, any idea how I would write this in the new version?
Having personally read both I'll say that they both do a great job of covering the basics. When it came to the more complicated aspects of the language having two descriptions was very helpful and the examples are good too.
&gt;There's something that I don't understand. If you need to support JavaScript, why would you need to crate a custom webAssembly runtime and compile JS to Wasm, since existing JS runtime (SpiderMonkey, V8 or JSC) can already run both Wasm and JavaScript ? What prevents you from using an existing JavaScript runtime ? Its probably easiest for me to just jot down the bullet points of the thoughts that went into this 1. I initially wanted to create a webassembly runtime from scratch so that I'd be able to do things like quickly serialise the entire memory state to disk easily, in particular for saveable and resumable code, as well as precisely managing timeouts and interrupts 2. The game has uncommon security requirements. In this model, each script has its own global, and its unacceptable for scripts to be able to access the global of any other script. Its a lot easier to enforce this when you own the sandbox. In other execution engines, you either pay a performance/functionality penalty for this (copying), or an implementation hazard penalty (oops figured out a way to get their global) for this security model 3. Even then, having everything under one execution engine doesn't solve much as there is still no way to directly teleport objects from one language (C++) to another (eg Lua) 4. The execution engine I'm using (duktape) does not support webassembly. In my particular use case, performance consistency is often more important than raw speed - if scripts run at the same speed every time, players can build around this. Duktape is generally extremely useful for my use case, although it is unfortunate that it doesn't support webassembly. v8 also REALLY likes to leak source code, which is somewhat unacceptable in my use case 5. There's still problems on the api side with how you represent a generic object, and converting it from eg Lua (scripting language) to C++ (host language) to JS (as a scripting language) (different problem to 3) 6. I'd never written an interpreter before and I wanted to see how well it'd go If JS compiled to WASM I could get memory serialisation super easily and then JS would become just another language to support, instead of a distinct special case. It simplifies the implementation a lot - I could inject a bunch of functions into every webassembly module that are essentially get_value(object, "key"); There's some minor convenience problems as well, eg if JS -&gt; wasm worked you could simply store bytecode, but instead you have to store js or bytecode scripts etc You're not wrong, it'd definitely be easier to use something out of the box, but it doesn't really fix the actually annoying bits There's also https://rustwasm.github.io/wasm-bindgen/contributing/design/js-objects-in-rust.html this and this https://github.com/WebAssembly/host-bindings/issues/18 The real moral of the story is just that it was going to take way longer than it was worth any way it happened, so I cut the feature entirely as other languages are nice but not necessary
My initial plan was to see if I could have everything work using FFI from other languages to C data structures, but the more I got into it the more i realised that that doesn't really make sense What makes more sense is to pass an opaque integer type which represents an object, then inject lookup functions into modules to query parameters using c data types. It probably is a very salvageable project but it was turning into an infinite time and research hole unfortunately
I started a series tailored towards NodeJS developers who want to learn Rust: https://dev.to/gruberb/intro-to-web-programming-in-rust-for-nodejs-developers-lp Feel free to follow along. My two cents: Knowing both languages will put you ahead in the up coming years! Although Rust can (soon) everything Go can as well. 
Thanks for the detailed answer!
No problem, bear in mind that I'm not amazingly well informed about the state of spidermonkey/v8 or web in general so I may have totally missed something in that sphere that massively makes everything easier
This is just pure flamebait. Not worth the trouble. 
Yes.
sry, i should've made my wuestion more clear. I keep seeing rust projects that compile to WASM, so my question was specifically: Of the people using webassemly, are a big chunk using rust to program it? 
Ah. It's all good! I don't know of any statistics on that. I have reason to believe it's a lot, but I don't have any hard numbers.
this has nothing to do with rust &amp;#x200B;
Wow! Nice! Thanks so much! This looks perfect.
I'm working on getting a slackbot, written in Rust, that my company uses internally open sourced. The next thing I need to figure out is if there is a good way to do delayed job processing with actix.
I am currently merging a PR that add a blog post to clarify this point, will be merged soon. [https://github.com/meilisearch/MeiliES/pull/14/files](https://github.com/meilisearch/MeiliES/pull/14/files)
I write go at my day job, and I've dabbled in Rust. I'm often frustrated by go's error handling and lack of generics. The other day I wanted a Set container in go and found that there wasn't a standard one; containers in go are generally awkward because of the generics thing. On stack overflow folks said to just use a map instead, which I did, but IMO it's a hack that obscures the intent of the code. &amp;#x200B; That said, parts of the learning curve for rust are steeper. I bounced off of it a few times before I got comfortable thinking about ownership the way rust does. &amp;#x200B; If you're interested in interfacing rust code with node, the fact that rust doesn't have a GC should make it easier to use rust from node. If you write a library in a GC language and use it from another GC language, you have to think about how to handle cycles between the two, which neither GC will be able to collect on its own. &amp;#x200B; The rust community seems more interested in webassembly than the go one. Perhaps partly because a client-side webassembly library written in go would require the client to download a heavier runtime (including a GC) than a comparable webassembly library written in rust.
Happy to help :)!
Yeah, that's not going to work. You need to tie the `'a` lifetime to the `Arc` and you can't. Besides that, you can't just add a lifetime to a trait like that; you've changed the signature of `next()`. `Iterator` doesn't support streaming iteration which is what you're trying to do.
I guess you need to clone the `Arc` and store it in your iterator. The problem with your code is that the value could be destroyed while your iterator is running. The compiler is correctly rejecting your code because of this.
You can fix this by making `IterByIndex` into `IterByIndex&lt;'a&gt;` and have it hold `&amp;Arc&lt;Vec&lt;T&gt;&gt;`, but in that case why not just use an `Iter&lt;'a&gt;` obtained from `self.0.iter()`?
I also recommend using [Redirector](http://einaregilsson.com/redirector/) with the following rules set: &amp;#x200B; [https://gist.github.com/CoolOppo/d64f2381dab34354d9b38c75f2ad4686](https://gist.github.com/CoolOppo/d64f2381dab34354d9b38c75f2ad4686) &amp;#x200B; This will redirect you to the latest version of the book as well as the latest version of whatever crate you are looking at on [docs.rs](https://docs.rs) (although you might want to disable that one if you use old crate versions).
As others have noted, you're going to have a hard time using the standard Iterator trait for this. If you make a trait that includes a lifetime parameter, you can make this work by guaranteeing that the references returned from next live as long as the IterByIndex itself does (and therefore, as long as any data the IterByIndex refers to): https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=86a20ed6c3e53e87447bf14b66c6e6c6
Looks great, one note: the first `Future` which yields not ready if count isn't high enough is missing a way to notify the task when it *is* ready. Without that, the future may never be polled again...
&gt; This is not true. You don't have to use interface{} everywhere and casting the the interface to the right type will not panic the runtime if you do it properly. The alternative is what? Code generation with a separate tool? 
...so humble is asking for at least $15 for a digital copy of a free book?
This is not fixed point arithmetic. This is, like, string-point arithmetic, if you will.
Maybe as a workaround the project could have both Meson build scripts and Cargo.toml files for anyone that would like to use Cargo for downloading the crate(s) from the Cargo website and everyone else that happens to use Meson build can download the crate(s) with wrapdb. Do not quit on my understanding of wrapper database I just got to that part of the documentation.
My advice as a NodeJs developer myself : learn both. Go is really easy to pick up, just follow the [Go tou\](https://tour.golang.org/welcome/1) and you'll be ready to write your first program. Coming from JS there is almost no new concept except goroutines and channels, and btw theses are also useful for Rust (if you replace goroutine with OS thread) so you won't have lost your time. Then move to Rust. The learning curve is steeper, there is a lot a things you need to understand, mostly low-level things, like pointers, stack and heap, or lifetime and RAII, but also higher level things like generics. Then you'll face the borrow checker and it's restrictions. It's gonna take quite some time, but you'll learn a lot about computers even if you don't stick with Rust afterwards. Read [the book](https://doc.rust-lang.org/book/index.html) first, and then later, when you face your first challenges with the ownership system, read [Learn Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/index.html#learn-rust-with-entirely-too-many-linked-lists). And to forget to ask any question you have [on IRC](https://client00.chat.mibbit.com/?server=irc.mozilla.org&amp;channel=%23rust-beginners) And btw, that's normal if you feel overwhelmed at first. Just give Rust a break for a while, and come back to it later. It took me three times, several month apart, for the whole ownership thing to eventually *click*. And I don't really know what changed between those times, I think it's just my brain thinking about this in background, and it eventually clicked. When it comes to backend stuff, Go is more mature at the moment, but the Rust ecosystem is moving fast here and with `async/await` coming soon to Rust, it may be much more familiar to you than channel juggling.
&gt; Would 1.1 + 1.10 == 1.11 They actually try to "fix" this using a "magnitude" calculation for the fractional part, such that `1.1 + 1.10 = 1.2`, because "10" has a "magnitude" of 2. :( I was very much hoping that after that they would conclude how horribly broken their data structure is, but nope. There really is is no way to express 0.01 as a `Fixed`.
I don't want 3rd party browser engines in any app. Imagine if Facebook or Google could put their bastardized engines in their iOS apps. It'll turn iOS apps to shit like Android.
I think /u/japaric did something like this, for printing stuff in embedded projects with minimal overhead. I don't remember where I read it though and if it's a separate crate or not, but maybe he can help you out :)
Why is this downvoted? .. cause I don‚Äôt get it either. What value is offered here? I have paid for paper versions of free online books. But I don‚Äôt see the point here.
In this code: ``` use std::time::Duration; use std::thread::sleep; fn run&lt;F&gt;(f: F) where F: Future&lt;Item=(), Error=()&gt; { let mut boxed_future = Box::new(f); loop { match boxed_future.poll() { Ok(Async::Ready(_)) =&gt; break, Ok(Async::NotReady) =&gt; (), Err(_) =&gt; break, } sleep(Duration::from_millis(100)); } } ``` Why are you boxing the future?
Yea, my problem with that is that I have a struct similar to `Data` _(in the example)_ that is trying to return an iterator, so `Iter&lt;'a&gt;` outlives the `Arc&lt;_&gt;` that gets returned. I _could_ simply return the `Arc&lt;_&gt;`, but I was trying to understand how to create something like `Iter(_)` from the example. It sounds like what I have is mostly correct, I just can't use the standard `Iterator` to achieve what I want.
Ah hah, so in theory what I was doing was quite close to correct, it's just that it's not compatible with the standard Iterator. Shame. Appreciate the info!
&gt; it's a great language for small server applications without hard performance constraints Unless you're rich like Google and has own many servers to run on. In that case, Go should be the clear choice.
I don‚Äôt even have to go the Russian library for this book and those fuckers are charging for it???
Just charity I guess? But I agree it's still pretty odd
I assume you are talking about the futures 0.3 that are currently in the nursery and on nightly [https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.13/futures/index.html](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.13/futures/index.html). I haven't really looked into the details of how they differ from the futures-rs crate [https://docs.rs/futures/0.1.25/futures/](https://docs.rs/futures/0.1.25/futures/), or am i misunderstanding? &amp;#x200B; I probably could have clarified that in the blog post.
Good question. That's so that my run function has the same signature as the tokio run function, which ultimately boxes up your future so that it can run the `poll` method, which is mutable.
But if you just declared the `f` argument as mutable, you'd be able to call `poll` as well? And you'd avoid a heap allocation?
If there is a worse online shopping experience than humble bundle, I've yet to experience it.
K
If anyone needs an example, [Juniper](https://github.com/graphql-rust/juniper) is using Azure Pipelines with Windows/Linux/OS X builds: https://github.com/graphql-rust/juniper (Check ./azure-pipelines.yml and _build/azure-pipeline-template.yml)
Yeah, but that's not the signature of the tokio `run` method. I went back and forth on avoiding the heap allocation, and giving the function the same signature as the tokio one. I came down on the side of making it run with tokio as is. so you could take your code and switch it out with the real futures-rs and tokio implementations.
Can't you just rebind `f`, with `let mut f = f;`, without the boxing part?
Nope, I'm talk about 0.1. When a future returns `Async::NotReady`, it needs to have grabbed `task::current()` and setup a way to notify the task when it *is* ready. That is, unless its being not ready is because of polling an inner future that has already set up how to notify.
I learn something new every day. Thanks.
&gt; This is not true. You don't have to use interface{} everywhere and casting the the interface to the right type will not panic the runtime if you do it properly. It's the same argument that people make with C, you can write secure and bug-free programs in C. The reality is that people suck and we make mistakes all the time. A programming language should make it hard to screw up.
The main differences to the Futures trait itself are the existence of a Waker to tell the runtime that is ready to run again, only having a single Output associated type instead of an Item and an Error (who said futures can't be infallible?), and the combinators belonging to an extension trait rather than the base Futures trait. There are a few other differences in the codebase, but those are the main ones with the Futures trait itself.
Maybe https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e359c0af12377f9b25d1feb806de86f3.
[Tracking issue](https://github.com/clap-rs/clap/issues/1037)
Thanks, that was my gut feeling, but was having trouble translating that feeling into what a good, idiomatic Rust (Rustic?) API would look like and not feel bad to use.
Adding new functions (non virtual) is indeed backward-compatible, though not forward-compatible of course. The issue that BillyONeal is referring to is, I think, that inlining breaks encapsulation at the ABI level. That is, if you have an internal function `void bar(int)` called by a public function `void foo()`, you'd expect to be able to change the signature/behavior of `bar` unilaterally so long as the overall behavior of `foo` remains unchanged. With inlining, however, this does not work as such, because a client may have a library/binary where `foo` was inlined, and therefore which depends exactly on `void bar(int)`. And since templates in C++ are always inlined, all the levels of abstractions that are "supposedly" encapsulated in `std::basic_regex`, are actually "public" from an ABI point of view, preventing any change to the implementation.
I felt like I shouldn't hide the mutation, but wasn't entirely sure. I like the two ```is_prime``` versions for handling the ergonomics of the two use-cases separately. Thanks a lot!
Nice writeup. I liked the entire series. However this also shows two things very clearly: 1. JMAP cannot arrive soon enough 2. Async/Await will make things a lot easier for all Rustaceans.
I mean... you get 14 books for $20. That's pretty damn cheap. Granted, if you only want the Rust book, probably skip it.
Working on my `tree` implementation for a little bit everyday, in addition to checking out Tide/Gloo/WASM and related projects. https://github.com/fairingrey/tree
I came from node to rust about a month ago. You should check some videos on computer memory, pointers, stack and heap. This will help with the initial learning curve. I chose rust because I wanted a langauge that is not garbage collected and because of all of the areas where it is being used(OS, WASM, embedded, etc) The iterators will also make you more comfy as it feels a lot like js array methods, only there are many more. Almost something like rxjs. I think rust just needs async/await syntax (not stable yet), then node devs will feel much more at home.
Depends on what your definition of random is. You'll most likely have to figure out a way to collect entropy specific to your device, or risk ending up with https://xkcd.com/221/
If the function takes it by value, then adding `mut` wont actually change the signature. This only changes the signature when it's a reference.
Thank you so much for you feedback. I'm realizing that I missed a couple of key pieces here. I'll see if I can fix up this post with some of that a little later today.
Yep. Thanks, I'm updating the post now.
You are looking for /r/playrust
Oof. Wow. That sucks. Thank you for elaborating!
What on earth are you talking about? The places where Drop *should* be called are deterministic. 
A lot of people already said most of the important things. However, I could add: If you're looking for something which might supplement your current stack rather than replace it or overlap it - pick Rust. If raw performance is of importance when also - Rust. Go is quick when compared to languages like Java, but it's still significantly behind when compared to something like C++. And as added bonus, if you'll able to crack Rust. I don't think that picking up Go will cause you any trouble further on. &amp;#x200B;
Thanks. I was wondering what the story was with the walker.
One alternative is using your own interface type which has all the methods you need. Often possible, but certainly not always.
Go has a relatively weak compiler (only basic optimizations), but it is still plenty fast and has a really great and optimized green threading runtime, which is essential for the space where Go is usually used (middle stack networking / backend services). Go might not be the fastest on the block, but it certainly is a valid choice performance wise. 
&gt;Noone under 700hours please Man, I don't think there's even a console I've played for that long since the N64. 
Haha i feel it. But high hours= more experience (sometimes). How many hours you got man?
Automate the boring Stuff is also free. Are all of these books free? In which case 14 free digital books for more than $0 is not a good deal. 
If you want, you can try my [SMTP parser](https://crates.io/crates/rustyknife). It returns a strongly typed result for each SMTP command parsed. The basic parser supports the base RFC 5321 ESMTP syntax. I'm looking for feedback on the interface. &amp;#x200B; [SMTP Parsing example](https://github.com/zerospam/rustyknife/blob/master/examples/parse_smtp.rs) [Main SMTP parsing function](https://zerospam.github.io/rustyknife/rustyknife/rfc5321/fn.command.html)
Could you restructure your code so that the iterator type has a lifetime parameter and borrows the `Vec`, rather than owning an `Arc` strong reference to it? If so, it sounds like you could use the standard `.iter()` method of `Vec` without making a custom iterator. It doesn‚Äôt copy.
They don't seem to be free on No Starch Press (which almost all these books are from, they're ~$30 each there)
Eh, zero, you've asked the wrong sub as someone else already pointed out. I just read the 700 hours requirement and felt kind of amazed people could pour so much time into a single game. Not judging you, though. I've probably put more than 700 hours of my own time into programming with Rust the programming language. 
Understandable. Ive just been playing the game for 2 1/2years. Thats why i have alot
I actually also built a simple ES database based on sled, but it's not in a state where I would feel comfortable open-sourcing it. IMO sled is plenty fast and stable enough for simple use-cases where one instance is enough. I'm also frustrated with the lack of options in this space, it could definitely benefit from a solid product. I guess event sourcing is still a rather niche solution, or most implementors make due with somewhat sub-optimal solutions like Kafka, using a regular SQL db, ... The biggest hurdle is of course distribution / scaling. Sled can only offer a single instance. I have thought about building a solution based on [TiKV](https://github.com/tikv/tikv) or FoundationDB. --- Out of curiosity, at what scale are you using this? (MSG/sec , MB/sec, amount of subscribers/publishers)?
Thanks for sharing, you‚Äôre awesome!
There's a very raw feel to the API. It's as if an entire layer of abstraction is missing from it that would make managing mail intuitive
I would point that Rust generics suffer from the same issue, essentially. Any generic function (which needs to be instantiated with the client side) which calls into a private function essentially exposes this private function at the ABI level. You don't have this issue in Rust because everybody simply recompiles everything for source every time. This issue is partly why I find the idea of a stable ABI dubious for any language with monomorphized generics. Even if the ABI is specified, in practice delivering ABI-compatible DLLs requires a lot of constraints: - The API has to be stable, of course. - A type-erased ABI layer has to be stable. - And all API calls have to go through the type-erased ABI layer. ABI stability works pretty well with object-oriented programming, or erased generics implementations (such as Java), but not so well with monomorphized generics, so you have to roll up your sleeve and erase generics yourself :/
Does this mean "pull parser = SAX parser", or is there a difference between pull and SAX that I am overlooking?
In reality the first issue that our event store fix is replication, this was the first reason why we built it. Instead of using something like the pub/sub system of Redis feature we choosed to use event sourcing to get another great feature: keeping every user input. For information replication is one of the targeted features of sled. https://github.com/spacejam/sled/wiki/sled-architectural-outlook#replication We tried with only 3 clients and something like 53MB/sec of message (every event as a length of 200 bytes) but this was before tokio and the RESP protocol. cat /dev/random | base64 | fold -w 200 | nc localhost 8080 | pv &gt; /dev/null
Thanks.
I'm aware of this and two fixes are planed: 1. Hide some of the more "internal" details behind extension traits (to make API doc more usable). 2. Add a \`simple-mail\` crate (or similar) which provides a more simple builder like API (which will in turn also be much less flexible, but should still cover &gt;75% of use cases). 
Sounds good!
I _could_, but I'm trying to match the `Item` type of another `Iterator` implementation. What I wound up doing was returning an owned type, basically `Foo(Arc&lt;Vec&lt;T&gt;&gt;)`, and that owned type returns a `FooIter&lt;'a&gt;`, which can then iterate with references and lifetimes matching the `&amp;'a Arc&lt;Vec&lt;T&gt;&gt;`
I imagine if we did have a stable ABI, then we'd want to address that? Maybe either by just avoiding inlining of public API functions when you compile a shared object, or at least make it an explicit semantic choice somehow as part of the public API so that it isn't hidden. But yeah, that is a tough nut to crack.
I found many of them for free as PDF
Start writing on a paper for a lecture about secure software engineering. "Attack proven development with Rust". Still tinkering about what to actually write. 
From my rough tests, allowing CIs to opt-out of docs ([issue](https://github.com/rust-lang/rustup.rs/issues/998)) would dramatically reduce rustup toolchain installation time.
Your `send` code is a text-book example of iterator invalidation. The easiest fix will be to add a vector which will contain removal indices and after the main loop do removal loop. But don't forget that you should remove items from the end, not from the beginning (i.e. you should use reverse iteration over vector with removal indices)!
Why is your `RwLock` outside the `Arc`?
You can mark the sockets as closed (in a different `Vec&lt;bool&gt;` or a struct), then filter them out.
This is interesting and helpful, thank you! Those future topics also sound really interesting. What complications would supporting nested transactions bring? (Also, I suppose the reason to use `Vec`s for the logs rather than `HashSet`/`BTreeSet`s - which seem like they would be more efficient for discovering whether a location is already in the log - is because the number of locations is expected to be small, so `Vec` wins on constant factors?)
How are you getting that speed out of `/dev/random`? I think you meant `/dev/urandom`.
On my laptop (Macbook Pro 15' 2017) I am at 66Mio/s. https://user-images.githubusercontent.com/3610253/55028833-ff9dc180-5008-11e9-84f6-e9d069a534db.png
They're quite different. SAX is not a pull parser because it pushes events through callbacks. There is also an XmlPullParser (used in Android because of the memory efficiency), but it's not SAX. Pull parsing is a general technique.
Curious, why make this async at all?
While others have mentioned that what you're looking for isn't necessarily what you need, is like to mention that a linear additive product could be nice to have. Rust's type system might not be powerful enough to really take advantage of a generic instance, but it could be nice. Personally, I hate having to choose between the pure math of Haskell and the memory control of Rust. This could help bridge the gap, especially since Haskell still doesn't have linear types.
Ah, sorry, I always forget about Mac OS :-). On Linux I'm at 4 bytes every couple of seconds, and 2.7 MB/s with `haveged` (`rdrand`).
Firstly, the inner `Arc` is absolutely pointless - you don't clone it, and you won't be able to if the `Vec&lt;TcpStream&gt;` is not `Sync`. And if it is `Sync`, the `RwLock` is unnecessary. Removing that Arc fixes the error in `new_client`. This makes the code look like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c24bd733e3128aa4db088950125ab666). That's when we get to the root of the problem - you can't modify the vector while iterating with `.iter()`. You can change the individual elements if you do `.iter_mut()`, but that still won't let you remove or add them. What you're looking for is `Vec::retain`. You could use it to do what you're trying to do like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=99ea47a68d8ae0f4238fac06ded47835). Finally, there are some code review level stuff I've noticed. For one, the `let mut sock = sock;` on line 56 is unnecessary. [You can just add the `mut` where you originally create the variable](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=aa7642be532344161052290ac6fa2abc). You are also ignoring some potential write errors on the socket, you can do the header sending in a cleaner way [by breaking the string literal onto more lines](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b60febd8ed00e46983459a0eb73e7cc1). The backslash will strip the leading whitespace on the next line.
Because the entire struct is in an arc
I don't think this is the best solution. Personally, I'd use `Vec::retain`, which will iterate over the elements, call a closure passed as an argument on each, and remove the ones where the closure returned false.
Well thats troublesome because as you remove the length of the data changes i found the solution by a while loop i will update the length as you go 
If you want a currently marketable skill: Go If you want personal growth: Rust
I was going to mention `mem::uninitialized` as well. :) Also, channels, [it seems](https://github.com/rust-lang/rust/issues/27800#issuecomment-469600533).
This is why I told you to remove items from the end, this way indices will be kept correct. `while` loop can work as well, but be careful not to skip one item on removal. Also you don't need to update length manually, you can just use `clients.len()` in the loop condition.
In my experience the bugs are introduced later on. I believe I am capable of writing a complicated data structure layout in C with no memory issues. Much later, when changing parts of the code slightly to bolt on new behaviors, it's very possible that I will forget an invariant and introduce an error. Personally the advantage of Rust to me is that it is particularly resilient against whole classes of errors that could be introduced when refactoring. Many more invariants can be made explicit. Go does not have that same resilience.
I guess the followup would be to ask _why_ you might want to hide the mutation? Is there a situation where you want to use the function, but a `&amp;mut` isn't available to you? The situation you're in will help suggest the right fix. Here's a couple off the top of my head: - Is the problem that `a(...)` is calling `b(...)` which is calling `c(...)`, and `a` doesn't take an `&amp;mut` reference, so it's hard to pass one through to `c`? In that situation, if you can, I'd go ahead and change `a` and `b` to take `&amp;mut`. Propagating the "fact of mutation" up the callstack is reasonable, if mutation is what's happening. - Is the problem that what you want to mutate is a global `static`, so it's unsafe to get a `&amp;mut` for it? In that case, I'd want to see if there was a way to avoid the global, maybe by creating the object in `main` and passing it down. - Is the problem that you need multiple threads to access the object? In that case there's definitely no way to give a plain `&amp;mut` to two different threads at the same time. (And thank God there isn't.) So the choice is between "external synchronization" (`Arc&lt;Mutex&lt;MyStruct&gt;&gt;`) and "internal mutability" (`Arc&lt;MyStruct&gt;` where `MyStruct` contains a `Mutex` or similar on the inside). Personally I'd prefer the external option, unless `MyStruct` has multiple separate things inside of it, and it's important for performance not to lock all of those things all at once. A clever multi-threaded tree might want to have separate locks for different subtrees and hide the complexity of that internally, but a struct that's essentially just one big `HashMap` would probably rather sit inside a `Mutex` than hide a `Mutex` inside itself.
Yes, you are right, I forgot about `retain`. The only drawback of it is that it will not allow returning and bubbling errors from the closure, though in this case it fits ideally. 
&gt; `let mut out_data; C_Api_Call(&amp;mut out_data);` &lt;- that is what I want to write Yeah, built-in support for this would be nice. It'd have to be `&amp;out` or so probably, but that should be fine. Unfortunately, that's a lot of language complexity for a fairly niche feature. And without built-in support, we are at an impasse: `let mut out_data = mem::uninitialized();` is basically incompatible with a lot of things we already do, like optimizing the layout of `Option&lt;&amp;T&gt;`. For such optimizations we have to rely on data being well-formed, and that is in direct contradiction with permitting uninitialized data. So I'm afraid I see no way to support straight `mem::uninitialized`.
I'm so curious how you chose `6` :-D
in new client actually theres no issue
I can give you some free facepalm samples if you need that :)
You might need to tell us whether you need randomness for something "not security sensitive" like producing audio white noise to satisfy a human, or for something "definitely security sensitive" like generating cryptographic keys. The former you can do with a hardcoded seed for your random number generator, as other comments are suggesting here. The latter is impossible without taking some kind of dependency on the OS/hardware/environment you're running in, so the options you have will depend on the environment you're in.
I used the OP's seed, they might need a deterministic RNG.
What do you mean with the "dead-tree version"?
A physical paper book.
I added cmark and hoedown to the [repo](https://github.com/1Password/markdown-benchmarks): ``` $ make run -s Blackfriday (Go): 1000 iterations = 0.054s 10000 iterations = 0.517s 100000 iterations = 5.149s Comrak (Rust): 1000 iterations = 0.258s 10000 iterations = 2.560s 100000 iterations = 25.890s Pulldown-cmark (Rust): 1000 iterations = 0.041s 10000 iterations = 0.380s 100000 iterations = 3.709s Cmark (C): 1000 iterations = 0.075s 10000 iterations = 0.787s 100000 iterations = 7.880s Hoedown (C): 1000 iterations = 0.022s 10000 iterations = 0.233s 100000 iterations = 2.262s ```
Awesome, thanks! It'll be interesting to see how much faster we can go.
Actix docs have [limits](https://docs.rs/actix/0.7.10/actix/#tokio-runtime) section, from which it wasn't apparent to me that you can use multithreaded runtime. Thanks
On the other hand, `MaybeUninit` is not marked as Wrapper, so there is no layout guarantee. Creating an array of uninitialized values isn't possible without either `mem::uninitialized` (which is going to be deprecated) or `mem::transmute` (which might fail due to the aforementioned lack of layout guarantee). Here's hope that once const generics land, we can get a `From&lt;MaybeUninit&lt;[T; const N]&gt;&gt;` for `[MaybeUninit&lt;T&gt;; const N]`.
I was inspired by `actress` crate, so I wanted to name the crate after some famous actor or actress of the early 20th century, but none came to my mind, so I named the project `movie`, intending to rename it afterwards. To my surprise, the name was not claimed on crates.io (it was on Github, obviously).
In hopes of averting any unintended consequences of a misleading tutorial, here's an actual (partial) implementation of fixed-point arithmetic in Rust. The type, a basic from impl, and a complete Add impl are presented in 15 lines.
I had bought something similar once. You get epub, mobi and pdf versions. Also the pdf version is typeset in a nicer way compared to the free pdf version.
Some time ago I went through learning enough Actix to do what I wanted to do, with a lot of try-and-error. I faced multiple problems, like: * Understanding what the actor model is * How to do basic things * How to have multiple of the same actor (a.k. a thread-pool) * How to architect my application (still don't have a good way to terminate it) * I never really understood the supervising actor thing in Actix * too much code uses `ctx.address().do_send()`, what is the right way to do it? I liked Actix quite a lot and on the other side I disliked that there was the API but not much information on how to use it. Thanks a lot for your work on improving the documentation. This will help a lot of people and make a great piece of software more accessible for everyone.
One concrete advantage of Rust that may or may not be relevant to your circumstances is that its lack of runtime and GC make it a good option for integrating it into existing Node applications by writing Node add-ons with it. See \[neon\]([https://github.com/neon-bindings/neon](https://github.com/neon-bindings/neon)) for a good library designed for doing exactly that. &amp;#x200B; My team has been doing exactly that for speeding up critical CPU-bound sections of a large production Node app that would be impractical to port in its entirety to a new language (Go or Rust or whatever). If that's of interest to you, it might be worth exploring. &amp;#x200B; On the other hand, if you're mostly looking to do new greenfield development, maybe the more-mature Go ecosystem would be more attractive? (I dunno, I haven't written much Go since it doesn't really work for my usecase, but that's my general impression.)
From the author/publisher or by other means? The two mentioned are freely available from the authors.
I agree. As someone who's been working with asynchronous code for most of his career, and working professionally as a software developer in a variety of languages and disciplines for years, it's really hard to remember what people do and don't know coming straight in. I also just started using Actix, which means a lot of the trials are really fresh in my mind. That said, I'm just always going to end up writing documentation that makes sense to people who know Node and event loops well, so it's just always going to be a struggle. For example, the `do_send` thing is, like you said, not the right way to do it. What is the right way? `.send`, but it's much harder to explain because it has to start with "Okay, do you know what a thread is?" We're pretty blessed (and cursed?) in the Rust community to mostly be filled with people who already know other languages, but this is exceptionally hard in a language like JS where people will come in not even knowing how to program and expecting to be able to learn how to write networked APIs that reference databases. So the good news is that most people already know what threads are. The bad news is that it still seems like most of them don't know what Futures or event loops are, and unfortunately those are kind of pre-requisites to understanding Actix.
Yeah, `MaybeUninit` certainly needs some helpers for better interactions with boxes, slices and arrays. But let's stabilize the core of it first. ;)
That's why I buy C books, C99 will never be irrelevant :laugh:
Check out [i128::saturating_mul](https://doc.rust-lang.org/std/primitive.i128.html#method.saturating_mul) for your "big value" problem. Sidenote: sign extending a 64 bit fixed point number to 128 might be acceptable for some applications, but `i128
I added MD4C to as well but it is a bit trickier than other parsers because it does not return the HTML. It allows the caller to provide a set of callback functions instead. With empty callbacks MD4C is certainly the fastest.
The alternative for what, though? That will ultimately decide the correct strategy. Depending on the type of task, op might never even notice that go doesn't have parametric polymorphism. The builtin generic containers might be enough. For now advanced cases, using closures or type safe interfaces might fit the bill. Now, if op is building container types all day, I'm afraid go will not be their cup of tea.
Hmm, there was on the playground.
Or exactly the problem with the channel implementation in the standard library. 
Check out [`128::saturating_mul`](https://doc.rust-lang.org/std/primitive.i128.html#method.saturating_mul) for your overflow problem. 
Thanks a lot. In a first step, I have fallen back to Python, as I am so much faster with that. &amp;#x200B; If you want to, have a look: [https://github.com/drandreaskrueger/redduser](https://github.com/drandreaskrueger/redduser) &amp;#x200B; &amp;#x200B;
I don't know what this is a repotnse to, and I also wouldn't call this a good fixed point implementation. Care to share some context?
Thanks a lot. &amp;#x200B; \&gt; a more low level version of the api that will cover things like ... that sounds like a very reasonable approach. &amp;#x200B; For now I have fallen back to Python, because I wanted fast results, perhaps if you want to have a look: [https://github.com/drandreaskrueger/redduser](https://github.com/drandreaskrueger/redduser) &amp;#x200B; &amp;#x200B;
It's likely that both will work for your use case, and that the choice will come down to personal preference. One possible exception would be if you want to write fast code that can be called as a library _from within_ a NodeJS program. In that case I think you'll find that Rust is a better fit for being called from other languages. I'm a big Rust fan, so I'm not a reliable source of "reasons not to use Rust", and hopefully you're asking Go fans too :) Here are some downsides to Rust that I hear people mention a lot: - The learning curve is steep. Some of this is that the language is inherently more complicated than other languages, but a big part of it is that it frontloads a lot of that complexity on the beginner. So you might have to understand say 75% of the language before you can build your first non-trivial program, rather than saving all the tricky bits for later. This is fine if you think Rust is the bees knees and you love learning about all its intricacies, or if you have a more experienced Rustacean on hand to help get up to speed, but otherwise it can be painful. - Things are still changing relatively quickly. The 1.0 release of the language was in 2015, and a lot of big features have only been in the wild for a year or two. The addition of `async`/`await` later this year is going to be a big change in how networking code gets written, for example. - Compile times are slow for big programs. Things I personally found annoying about Go when I used it at work: - Verbose error handling means there are more opportunities to accidentally forget to check an error. Linters and other tools help with this somewhat, but there are corner cases. - The lack of templates means that certain nice abstractions aren't possible. One that I particular miss is that the Golang `Mutex` doesn't _contain_ the data it's supposed to lock, so callers can forget to take the locks they're supposed to take. - The conventions for depending on external libraries leaned heavily towards building from `master`. There were tools for working around this, but the general lack of versioning in the ecosystem limited the usefulness of those tools. I understand this has changed in the last couple years, though, and it might've gotten a lot better. - `nil`
Rust. It will make your Go code better as well.
Now I'm feeling less confident about it being multithreaded. I've certain had trouble reading the Actix docs. They are challenging to navigate and a lot of information is buried inside of complex, nested types. At any rate, it definitely works with futures 0.1. That is one of its strengths.
I'm working on a modal text editor: https://github.com/dpc/breeze and it seems to me (one of the future goals is) that wasm would be a perfect solution for plugins. It's sandboxed, and plugins can be written in any language, and conveniently delivered in a compiled form. In fact, I would like the whole core editor be compatible to wasm, so it can run anywhere, and have webUI etc. 
I don't think it matters. If you get someone to build your crate (and run your build.rs file) then it's likely they're going to be running the actual library code at some point in the near future. So it's pointless to have "security" on one without the other.
These other books are almost completely useless... like most humble bundles I've seen.
Probably https://www.reddit.com/r/rust/comments/b5dgy6/rust_basics_the_add_trait/.
I'm writing a web assembly shell and have been wanting to get a web assembly text editor working on it, not sure if such a project interests you! [https://web-dom.github.io/wash/examples/helloworld/](https://web-dom.github.io/wash/examples/helloworld/)
The \`i128\` multiplication will never overflow, as it is multiplying two 64-bit integers. The issue is that after shifting the product to the right by 32 bits, there are still potentially 96 significant bits, which are then converted into 64 bits without checks.
Ah ha! Yes, this version is at least better than that.
Oh wow this is super helpful. It's a bit of a combination between 1 and 3. I don't have parallelization implemented, but it's something I've wanted to keep in mind if I do need to rely on a bit of computer performance over algorithm quality at some point. You mentioned a lot of angles I hadn't considered so I'll try to keep them in mind moving forward. On the topic of 1, I think the ease of passing around non-```mut``` references when possible has given me an aversion to using ```mut``` even when I probably should. There's do definitely at least one data structure I've built on top of the Sieve that cares about what sort of reference is under the hood. So I'll need to look at what I need when I get home tonight.
I have just written a version of my program that is roughly twice as fast as my old C implementation and I learned a lot from posting this. Thank you all for helping out, particularly /u/boomshroom and /u/skrapple. Unfortunately order matters in this particular case, but /u/boomshroom's suggestion of using the swap methods would have been very helpful. In the end, looking at /u/skrapple's code made all the difference (the way you solved this was a real eye-opener, thank you!) so in the end it turns out the *real* `remove` method is the friends we made along the way. What I learned from all of this is that `Vec`s and iterators are extremely performant in Rust and I should not have dismissed them in favor of a linked list. There are still a few things I don't understand in skrapple's code but I'm still learning Rust so I am going to assume I will learn them along the way. Thanks again everyone for indulging me and being patient. When benchmarking, interestingly, I found that using `Vec::new()` and just adding elements is faster than using `Vec::with_capacity()` in my particular case.
I don't know. I just googled a few of them to see the quality of the deal in relation to how many of the books I used. Most are probably not from the author/publisher though. 
The Linux Programming Interface alone is well worth $20. It's probably among the top 20 best computing related books.
You could easily add an overflow check in the multiplication. I would add something like debug_assert!( fullwidth &gt;= (-1i128 &lt;&lt; 95) &amp;&amp; fullwidth &lt; (1i128 &lt;&lt; 95), "overflow" ); That panics on overflow when debug assertions are enabled, and wraps otherwise.
Look at the other response about Vec::retain. It sounds like a bit in library solution to your exact problem.
chosen by fair dice roll, guaranteed to be random let bytes = [4; 16]
Just tried benchmarking this and if I'm doing it right, then that is not significantly faster on my machine than: let v = v.into_iter().filter(|ch| ch != 'a').collect(); However I find the `retain` call a lot more readable - of course that was probably your point in the first place.
The community salutes you for your beautiful family and your hard work! Congrats and best wishes from another rustacean early daddy here! :)
Is there any way to get `std::path::Path` from an `std::fs::File`? I've got a bunch of open files (i.e., `std::fs::File` objects) and need to log their file names in some cases.
Exactly.
Very cool! Will this be usable with beta and stable when the release train moves along? The latest commit shown on GitHub right now is the merge for #666 "explain Miri limitations" -- this seems mildly ominous...
Fair enough
Before anyone gets too excited (like me), they're looking for PhD or motivated MS interns, not BS.
Since you listed yourself as a maintainer of this, a comment: The examples in the crate's [module-level documentation](https://docs.rs/bacon_rajan_cc/0.2.4/bacon_rajan_cc/), which mirror those in [std::Rc](https://doc.rust-lang.org/std/rc/index.html), don't demonstrate any strong cycles or how to collect them. This really confused me when I skimmed the top-level docs, because nothing in there requires a GC.
Yeah, I don't condone getting them from such unofficial sources. I just figure I'd share what I found. 
You want /r/playrust most likely.
Try both. It's great to be curious about technology and want to try new tools. Many of the people responding to you have tried both and some used Go extensively. When you look at Rust for asyncio is where you'll see what it is on the cusp of providing, considering your exposure to asyncio in Node. It's hard not to feel excited about what async-await will bring to Rust. Have fun.
I don't think that's really true, and I think it conflates some threat models. An attacker who can execute arbitrary code at build can execute on a developers host. They can, of course, modify the binary - but this is a much more complex attack, and one that should be modeled as general "service compromise" (which we can mitigate separately). What we've seen is an attacker execute on developer hosts to own the developer, not the company or services. We can protect against this, and have meaningful impact. Pushing an attacker to own a service instead is a huge win, in my opinion.
I'm curious why the reqs are so high
Hi Richard, The repo should probably include the .csv test files. &amp;#x200B;
No. `File` doesn't necessarily even correspond to a file path. It's just a file descriptor. You can do [non-portable hacks like this](https://stackoverflow.com/questions/1188757/retrieve-filename-from-file-descriptor-in-c), but if you need the file path, and you used the file path to open the file in the first place, then you should just keep the path around.
I'm not sure how you've benchmarked these things, but if you're using stdio/ stdout, then it's not measuring pulldown_cmark's true speed since the binary's IO is really unoptimized. Just adding a `std::io::BufWriter` gave a 20s -&gt; 8s reduction in run time on a (huge) test file.
I see, thanks.
Hey Ralf! thanks for the reply. Just keep in mind what is a niche feature for some others are using all the time. chaining a bunch of C API calls in C style Rust is already painful as it is. Yes you're not supposed to use uninitialized memory with enums, references, bools and other neat Rust things but the ergonomic regression of the new API for talking to C is a very real issue.
Cranelift is a compiler, and I think one of the main drivers is to make a compiler that will be very quick, so they probably want someone who can jump right into the deep end of compiler design which is a very computer science heavy topic.
Ah too bad I‚Äôm not in grad school yet. This looks like a great opportunity. 
You should advertise uom as a labelled quantity (unit) library. I didn't understand what it was until I got to the github repository :-)
Thanks for sharing! There's not a ton of material out there on macros in Rust, so I'm sure this will help lots of people. 
Not a Macbook, but my experience with a low-voltage ("Ultrabook") CPU is not good. Two cores often lacks power, as they will quickly saturate with parallel compilation. Laptops are not very good at heat spreading, and as soon as it reaches the Turbo Boost clock it will start to be loud. In general, I'm in favor of those desktop computers maybe in a smaller form factor - they provide enough power for multitasking and any demanding computation you may face.
Or maybe better, use [tempfile](https://github.com/Stebalien/tempfile) to create the files for the test.
CraneLift is a great codebase to browse if you're building your own compiler. I stole the [cranelift-entity](https://github.com/CraneStation/cranelift/tree/master/cranelift-entity) module to build an AST for one of my projects :)
Awesome!
Your toes are too hairy!
Can someone explain to me the difference between: - Rustup components and cargo install - Cargo as a build/dependency manager vs Cargo as a package manager
Thanks! I‚Äôve been thinking about how to implement arbitrary functions but without some kind of compilation it‚Äôd probably be really slow. For now I‚Äôll probably experiment with hardcoding certain transforms in the Rust code while still letting the user tweak the coefficients. 
Its not quite an ultrabook (like the macbook 12), its Core i5 with 2 cores, 4 threads, but I take your point. I've been experimenting with compiling projects on an 8 core Ec2 instance and compilation seems to nicely spread across all cores, but this was only after a 'cargo clean'. I'll have to try a nano instance, and although the initial build will probably be painful, maybe after that its not so bad.
sure, and that's great, and good on them for it. my issue is that the rust book is freely available online, and i think it's important that everyone knows that. i'm concerned that what humble is doing seems dishonest, since they don't make it clear that people can read the rust book without paying humble $15 dollars. that money would go to charity, so i guess one might argue that that's a good thing, but i wouldn't. besides, as you say, the books that humble is *actually* selling are well worth the money, without tacking on something that's supposed to be free.
Ah, thank you! I hadn't thought of that.
Looks like [this SO question](https://stackoverflow.com/questions/54007531/ironmodifierresponse-is-not-implemented-while-trying-to-set-content-type-o) is about the same thing; the first response says that that example doesn't work with current Iron and suggests some solutions.
&gt; What complications would supporting nested transactions bring? Because `TCell`s don't store their data on the heap (e.g. via Arc), transactions need to know the lifetimes of the `TCell`s it's working with. The API end users would expect from nested transactions, would essentially require that any `TCell`s in the nested transaction have the static lifetime. To work around this, some kinda heap allocated `TCell`-like type is needed. I'm not totally happy with the privatization/publication apis in `TPtr` - which is key to solving that problem, so I'm gonna hold off on nested transactions for a while. &gt; the number of locations is expected to be small, so Vec wins on constant factors? Very correct! Even the wonderful `hashbrown` is too slow. `swym` employs a very simple bloom filter to make failed lookups typically O(1).
&gt; I would assume that the typical rust developer and typical web developer are very different animals. I'm going to get down voted mercilessly for this, but if we're talking "typical", then I can confidently say the typical rust developer is working on things that would make the typical javascript developer's head explode.
May I ask why the switch to SDL2?
We got another one boys
To be the devil's advocate: if you are asking what the alternative to interface{} is, you probably aren't writing idiomatic Go.
Hahaha
I'm using a Matebook x pro i8 model running linux. So far the experience has been great. Might be something to take a look at?
&gt; Unless you're rich like Google and has own many servers to run on To play devil's advocate here, if you're rich like Google and have fleets of tens of thousands of servers to run on, even fractional performance gains save the equivalent of an engineer's salary. That said, I still think OP should give both Rust and Go a try, record the differences, and let us know. These kinds of comparisons are very valuable, and the increased language exposure can only help OP as a programmer.
`rustup` is a way of providing your PC with the necessary tools to compile and update rust. It also has a few components that are tightly linked to the compiler, and so makes sense to keep them in lock-step. You can also include extra targets for cross compilation etc.. rustup will install cargo, rustc, etc... but also RLS and other components. `cargo` is responsible for: * Pulling down dependencies your crate needs * Building your crate based on the criteria you want, such as whether it's a debug or release build * Packaging your crate to be published onto crates.io `cargo install` is a subcommand of cargo and allows you to install apps from the crates.io repository, git repos, and local file systems. These apps are pulled down then compiled and live in your `~/.cargo/bin` directory or equivalent. rustup components do not do this, as rustup is focused on a few core tools related to development, where as `cargo install` will install any binary on crates.io, such as my devops tool: Lorikeet. rustup also does not compile anything afaik, just pulls down existing binaries. 
I've been getting into increasingly messy generic types while trying to set up tests for a rocket web server that needs to lug around configuration objects for the lettre crate to set up a stub mail server for tests (so that I don't actually send out emails while running my tests...), while maintaining the ability to communicate with a real mail server. The problem is that I need to store an object that implements the lettre `Transport` trait in rocket's managed state, and retrieve it on specific requests. Here's one of my attempts so far: ```rust #[post("/mail", data = "&lt;mail&gt;")] fn send_mail&lt;T&gt;( mail: Form&lt;EmailData&gt;, mail_server: State&lt;impl T&gt;, ) -&gt; Flash&lt;Redirect&gt; where T: Transport&lt;'static&gt; + Sync + Send + 'static, { match dispatch_mail(mail.into_inner(), mail_server) { Ok(_) =&gt; { Flash::success(Redirect::to("/mail"), "Successfully sent email!") } Err(e) =&gt; Flash::error( Redirect::to("/mail"), format!("Could not send email: {} ({:?})", e, e), ), } } ``` The problem here is that `State&lt;impl T&gt;` is simply not allowed. I'm stuck at finding the correct syntax for this - how can I achieve passing an arbitrary object that implements the `Transport` trait through rocket's managed state? I'm starting to doubt this is even possible - I believe it would be at least a little problematic to figure out the size of the type during compilation, but I really want to be able to do this for testing purposes.
So again, what determines if something is cargo installed vs rustup component added? Why were both of these paradigms introduced?
I am so confused by what exactly Async/Await will be like, so I have a question: The gtk-rs team recently released a new version of gtk-rs which includes a workaround for threads in GTK. Meaning I can push a button and execute a function that takes X seconds to finish without it freezing the entire GUI. Here are the details: https://gtk-rs.org/blog/2019/02/21/new-release.html (refer to "GLib channels") Now I understand that this is a workaround, but what I don't understand: How much easier/straight-forward will this be with Async/Await? Will this be easier than this workaround? A lot easier? Will it be more complicated? A lot more complicated? Thanks so much in advance!
Apply. What's the worst that can happen?
I use a Mac mini (Apple hardware with the exception of the MacPro line is very alike). &amp;#x200B; It have 6 cores. But It stay silent all the time. Only once it spin a lot and was doing a cross-compiling for iOS/android/OSX with multiple cargo clean. &amp;#x200B; For the rest? I use VS Studio Mac, Code, Sublime, Docker with Sql Server, Postgres, Sqlite, IntelliJ, FirefoX, Firefox Developer, Safari, terminal, etc and it stay cool. &amp;#x200B; My brother, at my side, have a customized gaming PC made by parts, Is aloud ALL day.
Well, it's still a 5W low-voltage CPU. It's actually closer to the Macbook than to other models. [This article](https://www.notebookcheck.net/Apple-MacBook-Air-2018-i5-256-GB-Laptop-Review.357481.0.html#toc-performance) has some more information on it. &amp;#x200B; I guess it would be fine for playing with some small crates. But anything big won't be much fun. &amp;#x200B; &amp;#x200B;
blacklisted
I ran into some issues with glutin on hidpi monitors &amp; switching between monitors. Was able to get around it sorta, but is still a bug in my game. Further, SDL works out of the box for platforms such as a mobile, and also supports game controllers.
I have to agree. I also enjoyed the first two parts but this is very far from what I'd want to use. It is WAY too low level. I shouldn't have to care about at least 2/3 of the code shown.
rustup is used to install the rust compiler and toolchain, including cargo. There are only a handful of components that are installed using rustup. cargo install is used to install binary crates, which can be published by anyone. In other words rustup handles rust as a language, cargo install handles applications written in rust
If it's not just `State&lt;T&gt;`, then I think I'd need more information like what `State` is.
I want to convert a Result into a boolean with the following logic: &amp;#x200B; \- if Ok(T), then run function with T which returns a boolean \- if Err, then return false I feel like there is probably some obvious way using the Result API that I'm missing. Any suggestions?
Lgtm! The only thing I noticed is that you might not need `extern crate csv;` in the 2018 edition.
Nice, I‚Äôm actually in the process of building something that falls under the same category. I‚Äôm definitely interested in hearing about your experience with sled. How has that been? Did you roll your own snapshot system? Last I checked it is not implemented yet. I‚Äôve been experimenting with using RocksDB, but I‚Äôm definitely interested in a pure Rust solution. Also, just curious, why go with threading instead of tokio? Easier to program?
That would look something like this: result.map(function).unwrap_or(false)
Continuing to let databases get in the way of my number crunching. I'm tempted to ditch diesel for the `postgres` crate, which looks like it offers 80% of the safety for 20% of the effort, but when I tried it gave me Mysterious Type Errors anyway. Plus some helpful souls on the diesel gitter gave me some tips for making nicer abstractions, so maybe I'll just buckle down and use it anyway. Spending my nights dreaming of a relational model more abstract and easier to use than SQL. Nobody seems to have made one convincingly though. All research and development seems to be in Big Data applications these days, and my data isn't Big enough to benefit from that.
Iterate over the collection using iterators, and it should be fine for both C++and Java
But like... Why have rustup components in the first place? For what possible reason is rustfmt (for example) better delivered via rustup than cargo install?
Not Security Sensitive
Serious thanks to you 
Not sure if Redis Streams fits you use case ‚Äî or what Rust Redis clients support it yet ‚Äî but it looks like ES is possible in Redis 5.x. I‚Äôm guessing you considered this option? https://redislabs.com/blog/use-redis-event-store-communication-microservices/ Since your code uses the Redis protocol, it should be possible to also repackage some of your server parts as a Redis module and just offload the storage to Redis. You‚Äôll also gain all the replication, clustering, and other built-in data types. One thing I don‚Äôt quit understand with Redis Streams is how to write ‚Äúaged‚Äù events/snapshots to disk and load them on-demand. Nice work, btw!
I'm not sure I understand. Do you mean indices?
Ah, fuck I'm stupid. I was thinking it was some programming related tree. I should get more sleep.
/u/lachlan_s, this sounds like you!
Using floating point for `Display` is totally cheating. :-) Here's my implementation from the previous iteration. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b899eede6083df6e1c32f23486947ab3))
I know it's been a week, but after seeing this post, and in particular the point about cycle accuracy, I was curious if it would be possible to use generators to implement a cycle accurate emulator. I just managed to get a prototype with the instruction you used as an example (arithmetic shift left, immediate + x address), and with the help of http://nesdev.com/6502_cpu.txt, I was able to make the instruction take 7 cycles, and have the cycle points match the documentation. :D True cycle accuracy means doing a different part of the instruction each cycle, which means you need a state machine, which is exactly what generators provide! A modified await macro let me write the instruction serially, but behave like a state machine. Turns out most if not all the await points correspond to memory reads or writes, so I don't even have any yields outside the await macro and reading and writing memory.
I would suggest you take a look at arewegameyet.com. They also have a page on VR with 5 GitHub repositories that might be the right thing for you: http://arewegameyet.com/categories/vr/
yea, i've seen them but im not sure which one is the proper one and why not piston which people talk about it a lot. so basically im super beginner in game programming. 
Applying for a job is essentially just asking a question. Why would someone blacklist you for asking? Worst case, they'll just say no. Go for it!
https://github.com/amethyst/amethyst/pull/1413 Amethyst, to my knowledge, is working on it but very slowly and lacking high priority for it.
Looks good. Here's some ideas if you want to take it further (and maybe you should, since you took a great name on crates.io): - add support for "id" (unique) columns and sorting files by them - add support for joins, where you go through multiple files at once and concatenate the rows with the same id; you can do it efficiently if the files are sorted - offer a library interface for applications that want to combine the rows with the same id in a more elaborate manner I know there's some overlap with `xsv`, but not that much. I may be thinking of this specific application because I've recently wrote a couple of programs that go through some 10-20 GBs of CSV files and do these kind of things.
Piston has started to grow stale, development has stalled and it is not being worked on anywhere near as much as it used to, last commit on feb 7th and only a few every month or two: https://github.com/PistonDevelopers/piston/graphs/contributors
You need to use 3 multiplies to get the right answer with `i64` arithmetic. 4 multiplies is easier. See [above](/r/rust/comments/b5v57o/actual_fixed_point_addition_in_15_lines/ejh8hrh/).
OP's point was: with the (current) lack of generics in Go, if you want a generic data structure in Go you need to write `interface{}` everywhere in it. Actually even Go's standard thread-safe map ([`sync.Map`](https://golang.org/src/sync/map.go)) uses `interface{}`.
thanks for sharing. that was hopeful
Is the plan to also add concurrency testing to MIRI or is that best tested with some other tool? 
Amethyst and ggez seems to be the most popular activity maintained ones ATM, but I have also not been following things as closely as I used to. Cannot say much about any of the other ones though. Not sure if any support VR yet.
You _can_ make VR games in Rust, but the tooling may not be good enough to trivialise that process yet. https://twitter.com/setimmediate/status/979380648551968768?s=20
It's hard to say as both languages have quite different pros and cons. Moving purely for performance does give Rust a bit of an advantage although C is more performant still. https://benchmarksgame-team.pages.debian.net/benchmarksgame/which-programs-are-fast.html That said, CPUs and memory are cheaper than your time. Pick a language and a community that you enjoy spending your time with. The only way to do that is to try both and see what you prefer. Personally I started learning Go and then moved to Rust BUT that choice is personal to me and I've no doubt people go the other way too. Good luck! 
I'm certain it's possible, Claps load_yaml macro does basically the opposite, maybe the source code for that would help? https://docs.rs/clap/2.32.0/clap/macro.load_yaml.html
Mozilla never blacklists. It‚Äôs the opposite actually. They keep a pool of people that are interested in case of. Just like Wikipedia does and others.
It's not a bug, its how it works. You cannot have multiple generic implementation for same trait, and you cannot have concrete implementation of trait having generic implementation matching this type. I don't think, that this is possible to implement both iterators for single type, but I don't think, that language tries to proof it anyhow (and it just makes multiple generic implementations invalid, because in many case proving that there is no possible to have type matching both implementation isn't simple). There is incoming feature [https://github.com/rust-lang/rust/issues/31844] which will make some more implementation magic possible, but I am not sure how it affects this very case.
this post is definitely missing the obligatory r/InclusiveOr "yes" answer
Hagagaggagahahdshdahsdahfuqwoldqwodoqosad get it he said "yes" to an x or y question hahahhaha so funny!!!!111!!111!!111!!!!!!1!
&gt; Will this be usable with beta and stable when the release train moves along? No, Miri will be nightly-only for the foreseeable future. It has quite a long ways to go before reaching the kind of quality and stability we expect from stable releases. At least, that's my thinking.^^ If the release team thinks otherwise, that'd be fine for me. ;) &gt; The latest commit shown on GitHub right now is the merge for #666 "explain Miri limitations" -- this seems mildly ominous... :D
Godot supports VR https://docs.godotengine.org/en/3.1/tutorials/vr/vr_primer.html and Rust can be used with Godot https://github.com/GodotNativeTools/godot-rust Amethyst currently has an open [WIP] PR to add basic VR support https://github.com/amethyst/amethyst/pull/1413
While I have some ideas for letting Miri run concurrent programs, there are currently no plans from my side for making it detect data races (I assume that is what you are referring to by "concurrency testing"?). But if someone would want to implement that, I'd certainly support them!
I compare scala performance with rust and found that my rust realisation is slower than scala ;( - **scala**: ~6 seconds to check 5000 seeds - **rust**: ~8 seconds to check 5000 seeds So, obviously, there is some space to improve
This appears to be not working at the moment. welcome to WASH, type "help" to see a list of commands help undefined "help" command not found I use Firefox 65.0.2.
Try using Rayon library in place of manual threading, likely to see some cleaner code and possible performance increase.
can you share your experience on GoDot and how promising is the engine. im looking forward to use it for long term project. Thanks for sharing your thoughts 
OK, so it seems like the idiomatic Rust way for dealing with this problem seems to be using generic trait: &amp;#x200B; \`\`\`rust trait Foo&lt;T, I = Self&gt; { fn foo(self); } &amp;#x200B; impl&lt;I&gt; Foo&lt;i32, I&gt; for I where I: Iterator&lt;Item = i32&gt; { fn foo(self) {} } &amp;#x200B; impl&lt;I&gt; Foo&lt;f32, I&gt; for I where I: Iterator&lt;Item = f32&gt; { fn foo(self) {} } &amp;#x200B; fn main() { } \`\`\` (\[playground\]([https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1134133ab1a8d2a4d1b83a562f01340d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1134133ab1a8d2a4d1b83a562f01340d)))
That's a great point. I was actually thinking of using coroutines in the PPU, but it was simpler for me to use explicit state in the structure. One point against it is, you need to be able to save everything to make savestates work. Are generators serializable into bytes that can be saved and reloaded later?
I use a Macbook Air from 2013. It's not that bad actually. When I timed a incremental recompile against a beefy server there wasn't much difference in it. I guess it depends what you're building? &amp;#x200B; Saying that, I am looking to upgrade currently :P
rustup components like RLS and clippy depend on the compiler - if you updated the compiler but forgot to update clippy then clippy would no longer work. So providing them through rustup makes it easier for the users, because rustup automatically manages updating all the components to the same version as the compiler.
Probably not. :P you can probably snapshot the registers and memory from a separate thread in that case, but out would be best to do so between full instructions. Alternatively, kidnap a member of the rust team and hold them hostage until they find a way to make generators implement serde's Serialize and Deserialize traits.
This is not kafka-like. In general Kafka and other message queues are not suitable for event sourcing (event-based system != event sourcing!): https://medium.com/serialized-io/apache-kafka-is-not-for-event-sourcing-81735c3cf5c
Our experience with sled was really great, expecially if you compare it with the RocksDB fork of pingcap. I do not blame pingcap, they do a great job forking, simplify the process of compilation (they import the C++ library inside the repo itself), but it will always be worst than a pure Rust library like sled. By the way [we worked on RocksDB](https://github.com/pingcap/rust-rocksdb/pulls?utf8=%E2%9C%93&amp;q=author%3AKerollmops) too, even on [the WIP rust-client](https://github.com/tikv/client-rust/issues?utf8=%E2%9C%93&amp;q=author%3AKerollmops) :) The current implementation of MeiliES do not need snapshots at all as we only write one entry at a time which cannot conflict, we use the [generate_id method](https://docs.rs/sled/0.20.0/sled/struct.Db.html#method.generate_id) that return a monotic number, ensuring conflict-less event insertion (this number is global to the database, it means that all events in all stream are orderer too). If you talk about the last paragraph on the README about one thread for each client [this is handled by tokio itself](https://github.com/meilisearch/MeiliES/blob/b787156acb17d82849a76e86d685fa0f1c71a8d0/meilies-server/src/main.rs#L190-L203), it use the tokio internal threadpool. I would have prefered to handle a futures event thrown by sled but currently the [sled::Subscriber](https://docs.rs/sled/0.20.0/sled/struct.Subscriber.html) is cpu blocking. I talked about that to Tyler Neely and it will probably be updated to use std::future when stabilized.
I did apply to that same offer back in january and got a notification that they would'nt be looking for interns on this position anymore due to a change in direction... Disappointed to see that it's back, because I've found an internship in the meantime :( 
I think you really want something like Unity. If you want to make a game use it. If you want to gether new experience and learn something new, try rust-way.
&gt; Instead, I regularly take inspiration from Haskell et. al That's not going to impress someone who praises C for its simplicity. :-)
&gt; I'm curious why the reqs are so high MS isn't "high" really.
Iterating over a changing list in Java usually throws a [`ConcurrentModificationException`](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/ConcurrentModificationException.html) (depends on the `List` implement you use).
Congratulations to your first program! Here are some thoughts: \- please add a license \- instead of checking if the file exist you should just open it and deal with errors ([https://en.wikipedia.org/wiki/Time\_of\_check\_to\_time\_of\_use](https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use)) \- if you want to extend your cli program there are some nice crates / tutorials that will help you: [structopt](https://github.com/TeXitoi/structopt), [assert\_cmd](https://github.com/assert-rs/assert_cmd), [rust cli workgroup](https://rust-lang-nursery.github.io/cli-wg/index.html) (just to name a few)
I don't expect it will nor is it my goal. That said, I think [Haskell is at its core (as in System FC) simpler than C](https://www.youtube.com/watch?v=uR_VzYxvbxg) with its many ways of triggering undefined behavior, inconsistencies, and so on. The source language of Haskell is also probably not substantially more complex than C. Also, in the end, I'm mainly interested in the complexity of programs instead of the complexity of languages. In my view it's easy to see that C produces programs that are hard to understand due to its inability to abstract. Contrast this with Rust or Haskell. However, it's great if you can make a language both simple in terms of definition but yet allow for simply put programs. That's easier said than done.
This is almost straight out of TRPL: The \[guessing game tutorial\]([https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html](https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html)) is this, except more elaborate and without the confusing terminology.
I think that these kinds of things should be possible with [chalk](https://github.com/rust-lang/chalk) in the future.
We did considered using Redis and the pub/sub feature at a point but switched to EventStore to gain real event store fonctionnalities. Sadly, we don't have seen this extension.
How can I create a rust code and compile it in Redox OS. I can't find any rustc or cargo command in Redox to compile the code! How can I install those tools?
This thread feels ironic. /u/rnd_usrnme was basically also just asking a question and got downvoted (~blacklisted) for it. I love the answers (and the fact that he asked so provokingly) as I hadn't looked at it that way yet but this kind of proves his point.
Are you compiling the rust with `--release` to turn on optimisations?
Yes 
It's [this type from the rocket crate](https://api.rocket.rs/v0.4/rocket/struct.State.html). `T` is of course defined as in the snippet.
(FYI, that link is dead)
This is amazing. I'm surprised at how you were able to do so much with relatively little code. I guess the GUI/graphics ecosystem is maturing. Well done.
The specs are like my old macbook pro, and it works well, the part where isn‚Äôt great experience it‚Äôs using intellij IDE‚Äòs, there‚Äôs too much lag using them, and I don‚Äôt feel vscode with rls a good experience, maybe I‚Äôm just too used to the IDE benefits, but you can work for sure with vscode. Also all depends on how big is your project, it for sure takes longer with less cores and less processing power, but as you say, the initial compilation will take a while.
I'm pretty sure that answering "blacklisted" to a question someone else asked is not itself asking a question.
Of course, but that's the analogy. Saying 'blacklisted' as a response to "What's the worst that could happen?" is in a similar way a question as applying to a job is. The end result were constructive answers (by /u/hashedram and /u/Hywan) and that's what matters.
This is a great video, but it was just posted yesterday by the author of the video. https://www.reddit.com/r/rust/comments/b5ny70/proc_macro_rules_an_overview_of_procedural_macros/
[MIR optimization](https://github.com/rust-lang/rust/pull/59290)! I really like the idea of optimizing MIR; this opens the door to high-level optimizations of Rust semantics that more generic backends (such as LLVM or cranelift) may not be able to apply.
Yes, I was thinking of data races but also potential deadlocks. &amp;#x200B;
It's worth benchmarking, but this might very well be down to the random algorithm itself.
For those interested in this work, we have a working group [t-compiler/mir-opt](https://github.com/rust-lang/compiler-team/tree/master/working-groups/mir-opt) for it. Consider joining in there. The specific PR u/matthieum referenced was due to me trying to desugar `if $cond $then else $otherwise` into `match { let _tmp = $cond; _tmp } { true =&gt; $then, _ =&gt; $otherwise }` so that we could get rid of [`hir::ExprKind::If`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc/hir/enum.ExprKind.html#variant.If) to facilitate the implementation of [#53667](https://github.com/rust-lang/rust/issues/53667) and to simplify the compiler.
Mmmm, I think rust random should work at least as fast as jvm, cause it is native, no? Maybe mine [random string generator](https://github.com/invis87/waves-seed-generator/blob/f010d4fef275ab15777dd5cff1817c0c481528b4/src/seed_generator.rs#L19) is not optimal, can you take a look please.
You kind of suck at reading analogies.
Well, Rust's rand number generator is secure by default, not sure if you used that in JVM?
In JVM I use default `java.util.Random` which is not secure ofcourse. Is there are some crate with fast random generator for rust? 
I just tried it on my crate and while compiling dependencies I got this: ``` error[E0080]: constant evaluation error: can't call foreign function: sched_getaffinity --&gt; /home/plhk/.cargo/registry/src/github.com-1ecc6299db9ec823/num_cpus-1.10.0/src/lib.rs:335:17 | 335 | if unsafe { libc::sched_getaffinity(0, std::mem::size_of::&lt;libc::cpu_set_t&gt;(), &amp;mut set) } == 0 { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ can't call foreign function: sched_getaffinity ``` Am I doing something wrong or does it mean foreign functions are not supported? If so, I wonder how does std mentioned in the article work.
At a quick glance, perhaps the performance issue is caused by converting the random seed into a string, right before converting it back to bytes within `waves::address_from_seed`? I'll do some experimenting tonight and make a PR if I find anything concrete.
The `rand` crate also has fast non-secure random number generators. But if you're generating blockchain seeds, you *definitely* want secure randomness.
Nope, here I do not care about security. The result seed is printed to console output, what security you are talking about :D
Hmmm, you mean the function `seed_generator::random_seed` is slowest one. I think the same. Also, looks like `seed_generator::random_seed` can return raw bytes and I should convert it to a string only if it pass `check_address` in `main`. Thanks for catching. 
Jeez... sorry for the duplicate. I checked before posting, apparently not hard enough.
Does CLion offer better debugging tools than VS Code? It would be worth the cost if it allowed me to me easily debug stuff, even though I don't like using multiple IDEs.
Yeah, see the limitations listed in the introduction of &lt;https://github.com/rust-lang/miri/&gt;. Only very little FFI is supported. std also has tons of stuff that needs no FFI, like all of libcore/liballoc ("malloc"/"free" *are* implemented in Miri). What is it that you are trying to run here?
`loop { if rand() { break; }}`? I just don't understand why you think `mem::forget` should be unsafe when there are already infinite very safe ways to do exactly what it does.
Has an extra ] at the end.
Godot is a full game engine and has actual tools to bring a game to production. Amethyst doesn't really have everything yet and would be more limiting, but is pure Rust. If you want to make a VR game see if Godot supports VR. If not, use Unity or something else. You may not need Rust.
Ironic or a coincidence?
The post on builders convinced me that derive_builder should offer an option to make an inherent builder method. I'll try to get an update with that out in the next week or so.
I think someone submitted an issue to Amethyst for VR support, but it doesn't look like anyone really cares enough to make it happen. It's kind of a niche interest.
I think you're looking for the command `cargo run --example info`. Examples are managed by Cargo separately from the main library. `cargo install` will not work, because systemstat is a library, not an application.
As a quick update here, this was posted a few months ago, and we've now hired someone for this position.
Drew writes great software and I'm so happy that he does so. But I have to admit that the few issues I've had with `sway` have been segfaults...
I haven't used VS Code for Rust, but I do use Clion. The debugger works pretty well, but it's not perfect - there aren't formatters for many of the more complex types. You can download it and use the 30 day trial to compare the two if you want to check specific features.
Readme.txt
https://github.com/japaric/stlog
I load the source file in memory before running the tests. 
Right, it's the writing that was slow though. I think that if you'd try the current master branch, it'd be much faster.
Ha I was about to post it. From people who grok Rust, is the codebase sane? I may look for packaging it for Fedora.
&gt;there aren't formatters for many of the more complex types I'm working on our formatters and really want to know about such types. Could you please specify them here (or create an [issue](https://github.com/intellij-rust/intellij-rust/issues))? 
I prefer `${name}.rs` for small modules that are largely self-contained and `${name}/mod.rs` for large modules that are split into multiple files. That's how Python does it, too.
Actually, it seems that the formatters aren't working (or aren't implemented?) for any non-primitive type: The following code shows up as [this in the debugger](https://i.imgur.com/joasAG1.png), with the renderers set to "Bundled Renderers" (under Setinngs -&gt; Build, Execution, and Deployment -&gt; Debugger -&gt; Data Views -&gt; Rust). use std::sync::Arc; fn main() { let int = 10; let bool = true; let vec = vec![1, 2, 3, 4]; let arc = Arc::new(5); let boxed = Box::new(6); let string = String::from("abc"); let option = Some(7); println!("breakpoint here"); } I also found this message in the console after starting the debugger, leading me to believe that it's an issue with my setup: Error during pretty printers setup: Error while executing Python code. Some features and performance optimizations will not be available.
It would usually just be State&lt;T&gt; where T: MyTrait but if this doesn't work then it may be the case that the `post` macro requires a concrete type. In this case, there are two options I can think of. The first is trait objects: Box&lt;dyn MyTrait&gt; The second is using conditional compilation to have a different type for tests. #[cfg(not(test))] type MyState = i32 #[cfg(test)] type MyState = u64 State&lt;MyState&gt;
I didn't use VS Code for long time, but seems like both CLion and VS Code support main debuggers' features. As to the difference: IntelliJ Rust has [own pretty-printers/formatters](https://github.com/intellij-rust/intellij-rust/tree/master/prettyPrinters) (which I'm going to upstream into [rustc](https://github.com/rust-lang/rust/tree/master/src/etc) as soon as I'll have some free time for it). Unlike default rustc formatters, our formatters use synthetic children for lldb, so you can go inside Vec/struct/... and see its children as in gdb; in addition, our formatters support all types that rustc formatters support (as far as I understand) and also support some other types (e.g. `Rc`, `Cell`, `Ref`): \[[lldb](https://twitter.com/intellijrust/status/1067725887880126464)\], \[[gdb](https://twitter.com/intellijrust/status/1098607535324569601)\].
Right now I've been following a similar policy: If the entire module is defined within one file, keep it in `&lt;module&gt;.rs`, otherwise, use `&lt;module&gt;/mod.rs`.
The authors say that it's under internal security review and not ready to be used in production yet. I'd wait for them to finish.
No to `mod.rs`, simply because then any `go to file` action in any IDE and editor will not work that well. 
I hadn't considered that, I rarely use `go to file` - I usually either use `go to declaration`, which works regardless of file name, or just open the file from the sidebar.
Wow, that's really awful! Could you please open an issue [here](https://github.com/intellij-rust/intellij-rust/issues)? I need some additional information (at least versions of rustc, plugin, CLion, OS) to fix it.
I haven't done too much with Rust 2018 yet, but I expect I'll stick to mod.rs. I prefer containing everything in the directory.
What is reason to not use mio/tokio and instead use directly poll/kqueue?
No I mean iterators. https://www.tutorialspoint.com/use-iterator-to-remove-an-element-from-a-collection-in-java
https://www.tutorialspoint.com/use-iterator-to-remove-an-element-from-a-collection-in-java
I think they want to control security of their dependencies.
I usually just type `{part of mod name}/mod.rs` and it works fine
I worked on similar project some time ago, but I am able to call it safe: https://github.com/Dushistov/skia-1 just fork servo/skia , because of it is hard to build google/skia, then I extended C API and in another repo write simple wrapper around `SkCanvas` and so on things.
Ah, I see what you mean. Yes, it works, with the slight disadvantage of being slow (O(N^2)) for large collections. But it's pretty similar to what OP picked.
Then there's also the fact that the editor will have tons of tabs (or whatever the program uses on its UI) that have the same "mod.rs" text.
Cool, I'll take it down then. Though someone ought to tell Mozilla to remove it from the careers page. :)
A person's preference will depend on whether they prefer a bird's eye view approach to file organization or a mole's eye view approach. The old way leads to clean directory structures, which is why it was originally chosen, but in practice it means editors will often have a dozen tabs open all unhelpfully labeled "mod.rs", which is often needlessly frustrating. I prefer the newer approach for this reason, since ease of navigation frustrates me more than self-containededness.
That's a very good point. In CLion, the files will be disambiguated if necessary (`module1/mod.rs`, `module2/mod.rs`, etc), but it's still a bit of a nuisance.
It's really not too much of an issue in most editors https://imgur.com/kCvl2v8
Be sure to post it when done, that sounds super interesting 
Also, it's boring. &amp;#x200B; When MIO/Tokio get boring, it'll probably be incorporated.
Can't agree on this more, I even have a CLI just to fix my messed-up [Back-In-Time recovery](https://github.com/0xpr03/restore_revert).. Could also be done in anything else.
Yes, I think it's normal. /u/steveklabnik1 says (at around 38') that the threads are joined when their `JoinHandle`s go out of scope. But that's not true: &gt; The join handle will implicitly detach the child thread upon being dropped. In this case, the child thread may outlive the parent You need to call join on each of those. If you rename `_guards` to `guards` and add this at the end: guards.into_iter().for_each(|t| t.join().unwrap()); the program will finish in a proper way.
I've got a prototype VR backend for Piston with OpenGL support. It's completely doable to write your own, just implement the `Window` trait and you are done.
Hi, I'm sorry for the late reply! We will have both a conference track and a training track both days to make the best use of the location, so yes, you will have to choose :/
I have a simple question that I've been fighting with the borrow checker about. The summary is: I have an array of structs, and I want to get a reference to an element with a particular value, or, if it doesn't exist, to return one. So say this is the struct: ``` struct Entry { start: u64, length: u64, }; ``` Then I have an array of them: ``` let entries = [ Entry { start: 0, length: 10 }, Entry { start: 20, length: 10 }, ]; ``` Then I want to either get one of those, or get some default object (I realize this search implementation isn't efficient, I just want to strip out complexity for the question): ``` fn get(i: u64) -&gt; Entry { for entry in entries.iter() { if entry.start &gt; i &amp;&amp; entry.start + entry.length &lt; i { return entry; } }; return Entry { start: i, length: 1 }; } ``` The problem is, if I found the entry in the list, I want to return a reference to it. But if I have to create a new one, I can't return a reference because the original object goes out of scope. I imagine I'm doing something wrong, and there's an idiomatic way to handle this situation, but I'm stumped. Any help?
And if you're excited to see this implemented for Rust, I've implemented a \[preview of what a wasi target could look like\]([https://github.com/rust-lang/rust/pull/59464](https://github.com/rust-lang/rust/pull/59464))!
Yes, I think I mis-spoke here. This behavior was true at one point... sigh. Thanks.
If they plan on porting it to windows it makes sense. mio is quite terrible for UDP on windows. 
What do you mean with pretty-printers/formatters? For debugging in the console? I'm talking about debugging with a GUI, if that's the case.
AFAIK, for some applications it's required to have a memory model because it lets you prove that things cannot go wrong in a way that's not possible without such a model. I'm not 100% sure, but I think I've read that you need a memory model to be able to prove lifetimes behave the way they should. 
I‚Äôm using a new MacBook Air to work on Rust stuff, it‚Äôs generally fine for the projects I‚Äôm working on (mostly `futures` related stuff at the moment). I have done some contribution to `rustc` on it, and that is rather painful, multi-hour initial compile then around 15-30 minutes to run tests after making changes. My biggest disappointment was that it is basically the same speed as my old 2013 MacBook Air, which makes sense since it has a slightly slower cpu than my old one. The retina screen definitely makes it much nicer to use in general though.
I don't have any need for web assembly shell right now, but the core logic of my text editor does compile to webassembly, so you could use Breeze for your project already, I belive.
I may just do that with your blessing :) thanks man
You can use crossbeam to easily get the stated behavior use crossbeam_utils::thread; thread::scope(|s| { for _ in 0..10 { s.spawn(|_| { println!("Hello, world!"); }); } }).unwrap(); All the threads are joined before the `scope` call ends.
Check out this soloution: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=03ca73cb8e5154743bb82d3223101e63](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=03ca73cb8e5154743bb82d3223101e63). &gt;But if I have to create a new one, I can't return a reference because the original object goes out of scope. You need to store the one you made somewhere in order to return a reference to it, which also means you need to have a mutable container while you iterate. When you determine that you do not currently have one, make a new one, give ownership to the container, then return a reference to it. 
Cool, I was thinking of something along those lines - kinda lazy loading new data into the structure. That should work!
 Just started learning rust, so wanted to learn writing a useful tool for work. &amp;#x200B; I am writing an AST for SQL statements (for now, only alter table, add FK, etc, no data queries) as we have to constantly write both sql and oracle scripts, and it's always just converting and making sure the semantics are write for the correct language. &amp;#x200B; Tool could read a single file and generate both with our exact names and size contraints, making sure it's valid oracle/sql before we do our checkin process (length contraints, etc). &amp;#x200B; Loving rust so far, and needed this tool for a while, so giving it a go :)
Might be a job for https://doc.rust-lang.org/std/borrow/enum.Cow.html https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=af159dac46902c32315afb1677823b71
From the wireguard mailing list, written by the main developer: Jason A. Donenfeld Hey folks, Looks like Cloudflare finally let their WireGuard implementation drop: https://github.com/cloudflare/boringtun They've been working on it for some time, and we've discussed this privately at various points along the way. Each time it came up, I asked them if they'd consider working with the WireGuard project itself, and they've repeatedly refused. They have insisted on remaining separate and expressed that they don't want to work as part upstream. I expressed various concerns about unity of community and compatibility of implementations, as well as vision for simplicity and security, but they were pretty adamant about remaining separate. I thought the invitation to put their engineers as the head of a WireGuard subproject was a cool invitation, but alas. That's a bummer, but that's how it goes; folks are entitled to do what they wish with software they make. I guess they'll make products or something and control is important to them; I just hope they don't fragment or otherwise yank WireGuard in unfortunate directions with their access to vast engineering resources. It remains to be seen how they'll use it or what their objectives are. The reason I think this matters and why their project is relevant is because WireGuard could really, really use a Rust implementation. Past developers working on it have flaked out, and we've wound up instead with a somewhat iffy Go codebase. I haven't read Cloudflare's implementation yet, and maybe it's garbage, but based on the people involved, I imagine it's going to turn out to be pretty decent. So, given the unwillingness of Cloudflare to work as part of upstream and join our project, and upstream's need for a solid Rust implementation, we may very well wind up forking it into `wireguard-rs`, to create something that matches our standards of security and vision. I think there's significant value in having a first-party Rust implementation that we can maintain and keep up to date with our ongoing research. And naturally the door remains open to Cloudflare if they'd like to work with us. Reviewing this, assessing our options, and determining whether it's a good base from which to start will take some time. But as usual, our progress and development will be in the open, and you're more than welcome to chime in here or #wireguard if you're interested in getting involved in one way or another. Regards, Jason
I remember the API was one of the tricky parts of nebulet. Perhaps WASI is what it needs to get going again.
I prefer your way too, i like everything contained, though i also see the benefit of the new way and may switch eventually. If the entire module fits in the one file then of course no directory, too.
vim shows the directory name as well, so it was not ambiguous on all editors. For the editors that do not show it, there might be editor settings available, e.g. vscode has a setting to show parent folders in the label.
Miri doesn't (and can't) find unsound behavior. What it does is detect (some kinds of) undefined behavior. So if you tested a case that actually did have a use-after-free, then miri would find it. If none of your tests happened to exibit UB, your test suite would pass fine under miri.
_Safe_ Rust is known to be sound (in some capacity, some restrictions apply, etc... the stdlib contains unsafe code). The memory model is required to be able to generally say whether unsafe code is sound or not.
As someone who has only used valgrind in very limited, exploratory contexts years ago, pardon my ignorance but: can this act as a partial replacement for valgrind?
Looks good in general! My comments are: \- Maybe add some in code comments to briefly tell what you're doing at each code block \- Maybe add your own custom error enum? (not sure if this would be too overkill though) \- And indeed the "extern &lt;crate-here&gt;" is not required anymore in the 2018 edition!
Direct link: https://coaxion.net/blog/2019/02/mpsc-channel-api-for-painless-usage-of-threads-with-gtk-in-rust/ My guess is that the threaded actor-model solution is likely a lot easier and is the one which desktop applications should use. Async really shines for servers with a very large number of clients, so many that the overhead of one thread per client doesn't make sense anymore. I'm not sure I would call it a "work-around". It's a straightforward and safe way to do something which, in other languages, is likely a source of subtle but bad bugs. Passing closures across channels to avoid sharing mutable state? That's the Actor model very much like Erlang, and Erlang is awesome. If there's a downside, it would be spawning too many threads. I don't think that's likely for a GUI application, but for simulations or networked services then the added complexity of async programming makes sense. New syntax for async is only going to make it easier and clearer to write async state machines. Actually designing with them is likely to remain difficult - and in practice I'd guess that sticking to the same principles as the Actor model will be the best way to do it.
If you aren't poking into random memory locations, reading from non standard memory modules, or poking and peeking from some obscure hardware, it doesn't really matter. &amp;#x200B; A memory model allows you to get up to all kinds of hardware specific games, it's mostly irrelevant at higher levels since rust guarantees many of the same things but at a higher abstraction level. There \*is\* a memory model underlying on the hardware, but rust just doesn't say 'this is the one we use on top of this stuff'.
I'm sticking to `mod.rs` for my projects. It's a good convention, for the reasons you stated.
I prefer the new way. It never worked for me to have an mod.rs stepping in between the module files. I also considered it a bad positioning, alphabetically-wise. But this was quite a minor issue, which now I consider completely solved..
Interesting to see the capability-based security getting involved!
Excellent. I've been very excited to try this, but could never get it installed on mac. It nicely fills in some gaps in tooling/testing/etc. When the next nightly works on mac I'll give it a go!
FWIW, I hit `sched_getaffinity` myself via the `num_cpus` crate when I tried testing `rayon`. And while you're supposed to be able to avoid this by setting `RAYON_NUM_THREADS`, I found the comment: /// Miri does not expose env vars from the host to the emulated program 
Would be nice if the crypto implementations of chacha20 etc. would be made available as independent crates or joined with existing ones. Having those re-implemented seems to be not best practise - but this pattern seems to be also practised by other wireguard implementations (the linux kernel wireguard module re-implements also some crypto algorithms which were available elsewhere in the kernel before).
The original [mod.rs](https://mod.rs) approach is significantly clearer for me, I personally find it confusing to have a folder and a file have the same name in the same directory.
A memory model is a contract between programmers and compilers (especially future compilers) regarding what *exactly* it means to access memory. This is very important when it comes to concurrently shared mutable location, but it also applies to things you do with pointers. For example, we don't know exactly what the memory model is, but we do know that having two `&amp;mut` references to the same location "at the same time" violates it. But what *exactly* defines "at the same time?" I dunno. In practice, I can sorta guess what the compiler will be doing. I can read the Rustonomicon and the standard library source and get a pretty good sense of what's sane and *should* continue to work. But the exact edge of defined behavior isn't specified and in practice I have to stay out of the gray area. For example, the current compiler passes the majority of the optimization work to LLVM. LLVM doesn't know about lifetimes; it knows about liveness instead. So lifetime violations only cause UB if you *actually dereference* a reference below some operation which invalidates the borrow which created it. But in the future an optimizer might want to use the lifetime information created by the borrow-checker *directly*, without proving an actual dereference. It's easy for me to imagine a bytecode for interpreting Rust which has an explicit "end borrow" instruction. What happens if that "end borrow" instruction is executed, then a reference created during the borrow is passed to a function which is outside the optimizer's scope and that function doesn't dereference it? Safe Rust won't let you do that. LLVM can't prove that undefined behavior is invoked; there's no "end borrow" instruction in its vocabulary. So it will generate code to handle this situation cautiously, possibly sacrificing speed. But an interpreter might throw a runtime error. Miri is intended to catch (possibly) undefined behavior like that. A different compiler or interpreter which focuses on speed instead of safety, might choose to assume the function it calls cannot actually dereference the reference. Therefore it is allowed to call with *any value* as the address. Or maybe it's just allowed to assume that the call *won't happen* and it can backtrack and assume the previous instructions won't happen. Maybe it zeros out a dead reference, turns it into a null pointer. A memory model would require someone who designs a compiler or interpreter to take some of those options off the table.
Memory models help to define what is undefined behavior. Safe rust, by definition, does not have undefined behavior, so it is not relevant for safe rust. Undefined behavior is used by the optimizer to help guide program transformations. if x != 0 { // something } else { x = 0; // the C memory model, the optimizer can remove this store }
&gt;!the linux kernel wireguard module re-implements also some crypto algorithms which were available elsewhere in the kernel before This is because the existing ones were slow and cumbersome. Also zinc isn't intended to be wireguard specific, the goal is that it would be used over the old ones and potentially even replace them down the line. [The developer gave a talk about it here](https://youtu.be/bFhdln8aJ_U).
No, it‚Äôs not about console only. Formatters allow look inside values and correctly show its children (like elements of the vector). I attached two links to gifs at the end of my previous comment.
Is a memory model required for ABI stabilization? 
I'm really exited to see Rust and WebAssembly moving forward :) But I wonder what can by solved by WASI that is not possible on runtimes like the JVM?
I like high pop server, as there is more people to talk about why is Rust such a wonderful programming language.
I experimenting in [branch](https://github.com/invis87/waves-seed-generator/tree/check_performance) - `seed_generator::random_seed` returns `Vec&lt;u8&gt;` instead of `String`, but performance stayed the same
This isn't the rust you're looking for... I don't know how to post images here so imagine Ben Kenobi saying that while pass his hand by your face...
I tend to prefer low pop servers as they let you do session-per-thread which makes ownership and per-session state a lot easier to reason about then futures. 
what are your thoughts on glancing briefly at the sidebar before posting
I think Cloudflare simply wanted to reduce Donenfeld's influence over WireGuard. As it stands, he was the only decisive person and he has made decisions which some people disagreed with.
How does [`wasmer`](https://github.com/wasmerio/wasmer) fit into this story?
I can relate. For me it‚Äôs macros. I also struggle with functional programming, which I would try to avoid, however reading other people‚Äôs code is sometimes a struggle. 
The memory model is a compiler writer's tool for homogenizing the behavior description across various hardware so that compiler changes still produce working code. Since Rust uses LLVM, the compile target is a bit higher level, and I'd have to do more research to form an opinion. https://www.quora.com/What-is-a-memory-model-in-C &gt; The C memory model is a part of the C abstract machine, the imaginary computer for which the C programming language is defined. This imaginary computer has memory, and that memory is a simplified model of what real computer memory might be like. If the concrete machine mappings to the abstract machine are consistent and the abstract machine behavior doesn't change under some optimizing or other transformation, then the transformation is valid and won't break things on the concrete platforms. You can see how this makes maintenance and portability easier.
It's possible to add methods to existing types by using traits, but the only way to add more fields is to wrap it in a new struct. *Your* problem is actually that `dacite-winit` is horribly outdated. dacite is trying to use winit 0.7, but the rest of your project is using winit 0.18, which cargo deems as incompatible. Your only options are to either throw away a year and a half worth of work on winit, fork dacite and update it yourself, or use a different library.
If BoringTun is able to use UDP on Windows without doing that, then why doesn't mio?
&gt; MIO FWIW, there is a plan to fix and it is scheduled for 0.7. Anyone who wants to see it fixed faster can pitch in too.
There's also a Zinc fork that uses kernel primitives which looks like it'll make it in, with the improved Zinc primitives replacing the existing ones as a separate process over time.
Sandboxing is a design tenant for WASI. The capability approach is nice to see. The SecurityManager approach of the JVM has always felt like an afterthought and there has been a long tail of serious implementation flaws with this approach in practice.
&gt; I think I still prefer doing things the old way with mod.rs, since it keeps the entire module in a single, self-contained directory, which seems a bit more organized to me than putting them side-by-side. Do you keep logic in your `mod.rs` or does it just pull in the rest of the module and re-export things? For me personally, I avoid having logic in `mod.rs` and `lib.rs` (and minimize my `main.rs` logic) so I don't think I'll mind `&lt;module&gt;.rs` since all of the logic will still be contained in the directory. If I'm already splitting the logic up into multiple files, I want all of the logic split up into self-contained, named files rather than some being left behind. I find it makes it harder to predict where code will be when it is left in the top-level file for the module or library. 
There is work on [trait aliases](https://github.com/rust-lang/rust/issues/41517) to improve trait bound ergonomics. I foresee a movement in the community to request QoL improvements in the language, especially implicit syntax. I feel like implicit bounds on generics is reasonable. We already got that with lifetime bounds on generics, and [there's been discussion](https://github.com/rust-lang/rfcs/issues/2255) for specific traits. Like what I'd like to do is something like this: struct Foo&lt;T&gt; where T: Bar (T) + Default; impl&lt;T&gt; Default for Foo&lt;T&gt; { fn default() -&gt; Self { Self(T::default()) } } It should be possible to infer the trait bounds on locally defined generic types. Right now if you have generic heavy code with trait bounds your `impl` blocks can get nasty with trait bounds. More controversial, I'd like to be able to write this code without compiler errors: fn foo&lt;T&gt; (t : T) -&gt; T { t + 1.into() } Where the compiler can infer `where T: std::ops::Add&lt;Output = T&gt; + std::convert::From&lt;i32&gt;`. But to argue against myself, templates in C++ can do this and it makes for the most obnoxious error messages known to man. In terms of error handling I have to disagree, but I come from a world where exceptions are avoided so we stick to integer error codes. 
We discussed this in the release team meeting today. It's not our place to decide whether it's stable, but we decided it's fine to let it ship before that as `miri-preview`. [Rust PR59236](https://github.com/rust-lang/rust/pull/59236) did rename the component like that, but with the way rustup handles renames, it's displaying the non-preview name. I filed [issue 1728](https://github.com/rust-lang/rustup.rs/issues/1728) for this.
Even in sophisticated IDEs, files named the same are generally an annoyance. If you try to use something like a "go to file" command, they usually consider the name of the file first and its place in the directory hierarchy second. So if you want to go to module `foo` with the new structure, you can just press whatever shortcut "go to file" functionality is mapped to and type `foo`, and this is generally enough for the file you seek to be at the top of the list, if you try the same approach with `mod.rs` it doesn't always work.
Okey, I found the slowest function that tooks almost 99% of time - `curve25519_base` :D ...
Unless it's very simple logic that's used by the submodules (usually a trait) I only use mod.rs for re-exporting.
That still takes twice as much space and harder to read.
This also seems like a recurring theme with Cloudflare: &amp;#x200B; [https://news.ycombinator.com/item?id=19019150](https://news.ycombinator.com/item?id=19019150)
Functional programming in general or in Rust in particular? FP can be disorienting at first because it requires to think differently, but if you get into it it‚Äôs hard to stop. And I‚Äôm saying this with zero formal education in math or CS. It‚Äôs genuinely a very convenient thing.
Shouldn't language servers solve this since they have much more information than a simple analyzer? Heck, even ctags should have full path information for declaration info.
I tried to run it with: \`\`\` \[dependencies\] pulldown-cmark = { git = "[https://github.com/raphlinus/pulldown-cmark](https://github.com/raphlinus/pulldown-cmark)", default-features = false } \`\`\` &amp;#x200B; I am getting results similar to 0.4.0: \`\`\` Pulldown-cmark 0.4 (Rust): 1000 iterations = 0.043s 10000 iterations = 0.378s 100000 iterations = 3.738s &amp;#x200B; Pulldown-cmark master (Rust): 1000 iterations = 0.043s 10000 iterations = 0.377s 100000 iterations = 3.800s \`\`\`
Interesting. Does `cargo update` change anything?
``` ~/projects/markdown-benchmarks/pulldown-cmark-master (master|‚úö1‚Ä¶) $ cargo update Updating git repository `https://github.com/raphlinus/pulldown-cmark` Updating crates.io index ~/projects/markdown-benchmarks/pulldown-cmark-master (master|‚úö1‚Ä¶) $ cargo run --release Finished release [optimized] target(s) in 0.05s Running `target/release/pulldown-cmark` 1000 iterations = 0.041s 10000 iterations = 0.355s 100000 iterations = 3.546s ```
So basically the same as in the 2015 edition?
Thanks. Reddit changed up their editor around that time, and took away my markdown. 
My `sample1.md` file is pretty small (3399 bytes). I wonder if that makes a difference.
It does seem like you are on the latest version then. Thanks for double checking!
Pretty much.
I don't know but I suspect most of these people write post from main page and choose subreddit in the form. Also does anyone else find /r/playrust posts fun? I open most of them, I enjoy the confusion and reactions and there aren't that many that it would bother me. 
I would say functional programming in general. I had tried Haskell in the past but I was in too deep waters that it created an aversion to FP :)
Deleted in favor of: https://www.reddit.com/r/rust/comments/b65mq1/standardizing_wasi_a_system_interface_to_run/
Some clarifications: &gt; and the standard library source and get a pretty good sense of what's sane and should continue to work. Note that the standard library can get away with doing things that user-space crates may not based on assumptions about the same compiler it is shipped with. You should *not* assume that copying unsafe code from the standard library is OK and defined behavior just because it is in the standard library. Exercise caution. &gt; So lifetime violations only cause UB if you actually dereference a reference below some operation which invalidates the borrow which created it. Your CPU, LLVM's abstract machine, and Rust's abstract machine are all different. It is possible that given unsafe code, we emit LLVM bitcode that is not UB according to LLVM but is UB according to Rust. IOW, behavior defined according to LLVM may be undefined according to Rust.
This is an API that wasmer may choose to implement or not.
Ah, I see. I must have missed those. I was on my phone. Well, maybe I'll consider trying out CLion in the future then.
I feel like this is a non-issue in practice because most modern editors implement fuzzy search when doing "go to file", so if you want to got to `foo/mod.rs` you would type `fomo` or `fmod` or something like that. 
&gt; Miri doesn't (and can't) find unsound behavior. What it does is detect (some kinds of) undefined behavior. "Unsound" and "undefined" are the same thing here. Specifically, Rust has some dynamic (operational) semantics (which is not fully specified). Miri implements Rust's operational semantics as a definitional interpreter (with a degree of fidelity due to unspecified things). You can then run programs through this interpreter, and if the interpreter gets stuck, or performs an illegal transition, then you have UB / the program is unsound wrt. the operational semantics of Rust. Rust's type system, or certain parts thereof, would be unsound if it would admit safe Rust that is UB according to the operational semantics. What miri does not do is perform everything as a static analysis.
 I am having a hard time wrapping my head around calling modules in sub directories. &amp;#x200B; In my example: &gt;[main.rs](https://main.rs) &gt; &gt;| &gt; &gt;| &gt; &gt;\-------bar.rs &gt; &gt;| &gt; &gt;\-------foo.rs &amp;#x200B; Contents of each: &amp;#x200B; Main.rs mod examples; use examples::{foo, bar}; fn main() { let bar = examples::foo::create_bar(); let foo = examples::bar::create_foo(); println!("Bar: {:#?}", bar); println!("Foo: {:#?}", foo); } Foo.rs use crate::examples::bar::InnerBar; pub fn create_bar() -&gt; InnerBar { return InnerBar { id: 5 }; } #[derive(Debug)] pub struct InnerFoo { pub id: i32, } [Bar.rs](https://Bar.rs) use crate::examples::foo::{InnerFoo}; pub fn create_foo() -&gt; InnerFoo { return InnerFoo { id: 5 }; } #[derive(Debug)] pub struct InnerBar { pub id: i32, } &amp;#x200B; &amp;#x200B; The problem is the declaration in [main.rs](https://main.rs). How can I have [main.rs](https://main.rs) call the code in [bar.rs/foo.rs](https://bar.rs/foo.rs) in its subdirectory? I learned how to do with with an examples/mod.rs file, and then mod examples in [main.rs](https://main.rs), but I read in 2018 you don't need to use [mod.rs](https://mod.rs) (and it's not the idiomatic way anymore?) but can't figure out what I need to do to make it work. &amp;#x200B; Thanks
This\^ :+1:
The big one for me is language, memory, and object model. The JVM forces you into Java-style objects, GC, etc. and that limits which kinds of languages people end up running on it. WebAssembly handles memory safety at a lower level so it can support C, C++, (unsafe) Rust, and all the existing code that implies.
`x25519_dalek::x25519(sha256_result, x25519_dalek::X25519_BASEPOINT_BYTES)` instead of `curve25519_base(&amp;sha256_result)` gaves me 30% speed boost
This is a lot faster than the go implementation which I'm currently running on an Atom N2800(yo Netbook CPU) usually maxes out at 50mbit/s. Just gave boringtun a shot which goes up to 70mbit/s consistently :) 
Hi. I'm the author of both Rust crates. The \`publicsuffix\` crate was my first implementation. I redesigned and rewrote it as \`psl\` after one of my users pointed out to me that it wasn't as fast as they were hoping it would be :) Thanks for that benchmark. I hadn't tested to see how well it performed against that \`Go\` implementation. You can also check out the benchmark I wrote against a \`PyPy\` and a \`C\` library at [https://github.com/addr-rs/pslbench](https://github.com/addr-rs/pslbench). &amp;#x200B; The plan is to deprecate \`publicsuffix\` and point users towards \`psl\`. Besides being much faster, it's also more correct so you should totally use it instead. Interesting trivia: that \`psl\` crate is probably the only implementation out there that supports wildcards exactly as specified in the spec. See [https://github.com/publicsuffix/list/issues/145](https://github.com/publicsuffix/list/issues/145).
That's what it looked like. Has anyone talked to the author about it yet? It would be cool to have that project on board from the get-go: I see `wasmer` as a valuable part of the Rust WASM story‚Ä¶
On the hacker news thread, someone from wasmer said they were interested; i have no idea if that's policy or just enthusiasm from one person :)
Thank you for the background story on this! The `publicsuffix` crate was originally suggested by my team. I am guessing it has a better name gets more downloads because of that. It has 28,636 recent downloads vs only 2,737 (all-time!) for `psl`. I just found that our Windows team is currently using `publicsuffix` as well.
Here I'm maybe slightly abusing terminology. I'm using UB as "your program has done something that violates the memory model" and unsound as "your program allows safe code to execute UB" (but not necessarily executed UB currently).
Traits. Every single thing I try to do, rust say NO. &amp;#x200B; Traits are so constrained that is not fun. &amp;#x200B; For example: pub trait Value:Debug {} Ok pub trait Value:Debug + Clone {} Bomb! You can't. error[E0038]: the trait `Value` cannot be made into an object Every nice API I could think of hit a block here or there. Is weird that constrains are 2 concepts, the the useful one (be able to to build a API that cross types) is BLOCKED by the other! Related, Generic. I hate that rust not allow to "see" what T is, neither specialize some T, so If I have: pub struct Apl&lt;T&gt; { } I can't have some generic code for any T and just specialize for i32, for example. This relate to the above: The "solution" is traits but then you are at square 0 with the "cannot be made into an object" and others. Anf BTW, Rust is not OO!
&gt;Thank you for the background story on this! You are welcome :) &gt;I am guessing it has a better name gets more downloads because of that. It has 28,636 recent downloads vs only 2,737 (all-time!) for psl Probably. I imagine the fact that it's also past `v1.0` and that it was already being used in the wild plays to its advantage. I've been too busy to promote the newer crate. &amp;#x200B;
I think "memory model" is too narrow here. It's the totality of the rules, including validity, threading, what operations are legal on what types, and so on, which the definitional interpreter has, that must be considered. &amp;#x200B; \&gt; unsound as "your program allows safe code to execute UB" (but not necessarily executed UB currently). &amp;#x200B; This is the same idea wrt. type system unsoundness that I described above. If the type system let's UB happen in safe code (for any combination of input and states), then the type system is unsound. If you write \`unsafe { .. }\` code yourself which results in UB, then your abstractions are unsound. I think it's important to treat unsound code as-if it already triggered UB. &amp;#x200B; You are right however that there is a distinction between unsound and undefined in that the former lets the latter happen for some inputs/states. This distinction does not entail that miri cannot find unsound behavior. It can. Simply attempt to write a safe abstraction that is unsound, run it in miri, which will hopefully complain, et voil√†, miri has demonstrated unsoundness.
Miri doesn't complain about code it never runs, right? So just stick a `if ( random() &lt; 0.01 ) { unreachable_unchecked() }` and I'm pretty sure your code will pass. If there's an example where miri finds unsoundness without actually (trying to) executing UB, I've not seen one. But yes, this is a tricky problem with lots of gotchas.
&gt; Miri doesn't complain about code it never runs, right? So just stick a if ( random() &lt; 0.01 ) { unreachable_unchecked() } and I'm pretty sure your code will pass. Well it could in theory perform static analysis that is richer than Rust's type system provides for and so it could complain about *some* code that never runs. The analysis will not be sound (reject all bad programs) and might also not be complete (accept all good programs). &gt; So just stick a if ( random() &lt; 0.01 ) { unreachable_unchecked() } and I'm pretty sure your code will pass. If there's an example where miri finds unsoundness without actually (trying to) executing UB, I've not seen one. This is inherent in any dynamic analysis. By definition, dynamic analysis must be run.. ;) It's like any testing. As Dijkstra said, *"Testing shows the presence, not the absence of bugs"*. What I am saying is that miri can show the presence of soundness holes, but not prove the absence thereof.
Great! What is your actual internet speed? 
Thanks for letting me know about dacite-winit. As for extending structs(**in C and CPP they are called members, not fields**) should project add extension fields/members? I worked with an order management database where every table ends with 4 text(30) fields that are never used by the application... And our team used them all the time.
100mbit/s but the server is about 700km away
/r/playrust
I like the idea! This would really benefit from some macros that automatically attach location information in the form of (filename, line number)
Uh...I'm confused. I see a Rust Programming Language tab, but...I don't know what Tom's Hardware would have to do with Rust?
What about the standard implementation?
Your first example [works just fine?](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=701b3b9a610ff9f2865645af3d5c2eea) The `cannot be made into an object` error usually means you're trying to use an unsized trait object. Using `Sized` as a trait bound usually fixes it &gt;I wish I could use a Enum so can mark T as one of: You can use a private trait and implement it for the types you care about. 
No idea I'm running the userspace impl because installing kernel modules under CoreOS is quite cumbersome 
You can run it without an X server, in headless mode (the default in this crate).
Looks like they just added ‚Äúaiming to be fully compatible with WASI‚Äù to their readme: https://github.com/wasmerio/wasmer/commit/2fd430e3358c584a52785d376112a9350182a1e2
Now listed in roadmap: [https://github.com/wasmerio/wasmer#roadmap](https://github.com/wasmerio/wasmer#roadmap) :)
Almost all implementations of Iterator throw on remove - the general advice is never to use it (in fact it was seen as a mistake to put it in the Iterator interface). 
Cool!
Doh! Will do thanks
Thanks, will fix these. I would usually have dealt with the errors upon open but I've not quite got the hang of error handling in Rust yet.
I'll attend to them ASAP!
Additionally, [implied bounds](https://github.com/rust-lang/rfcs/blob/master/text/2089-implied-bounds.md) are already implemented in [chalk](https://github.com/rust-lang/chalk). To an extent, one can experiment with implied bounds with the `-Z chalk` rustc flag, but integration is ongoing. If anyone is interested in how it works, there is a section in the [rustc guide](https://rust-lang.github.io/rustc-guide/traits/implied-bounds.html).
Not one but FIVE tabs that are rust-related. Clearly this is the proper subreddit.
Could someone help me with figuring out how to store a `TcpSocket` and a `BufReader` referring that very same socket, in the same struct. I think that I need to specify the lifetimes so that I can tell the compiler that the TcpSocket will always live long enough, but I'm having a hard time doing that. My naive solution without life-time specifiers: struct Foobar { socket: TcpStream, reader: BufReader&lt;&amp;TcpStream&gt;, } impl Foobar { fn connect&lt;A: ToSocketAddrs&gt;(addr: A) -&gt; Result&lt;Foobar, Box&lt;std::error::Error&gt;&gt; { let socket = TcpStream::connect(addr)?; Ok(Foobar { socket, BufReader::new(&amp;socket) }) } // ... } Trying to add lifetime specifier leads to me having to also give a specifier when calling `Foobar::connect(...)`, which I would like to avoid. Is there a special lifetime that is the lifetime of the struct that I could use? Something like: struct Foobar { socket: TcpStream, reader: BufReader&lt;&amp;'struct TcpStream&gt;, } Would appreciate any help/pointers, thanks!
 &gt; IOW, behavior defined according to LLVM may be undefined according to Rust. Oh, yes, that really bears repeating. Machine language doesn't have anywhere near the same opportunities for UB as abstract machine languages do. If something is UB in Rust or C, it's far more likely to compile to something that crashes or allows self-modifying code than something that executes undefined or undocumented instructions out of the blue. After all, a CPU may be asked to sandbox a virtual machine or user-mode process and it's necessary for any funny business to reliably return control to supervising software. Llvm's abstract machine doesn't know about lifetimes, it doesn't know everything about uninitialized locations, etc. So there are plenty of situations where rustc can't express potential UB in llvm ir. When you combine that with the fact that UB may depend on runtime values, it's kinda scary. Because if something is defined or undefined depending on the data it sees, one's instinct would be to test. However rustc might compile something to llvm in a way that prevents it from failing tests. It's allowed to turn undefined behavior into defined behavior. Miri is intended to be a much more pedantic implementation of Rust, slower but much better at noticing UB. That also means that work on miri (and running published code with miri) is an opportunity to decide what should be defined and what doesn't have to be or shouldn't be.
[Rust calls them fields.](https://doc.rust-lang.org/book/ch05-01-defining-structs.html#defining-and-instantiating-structs) If a struct is in another crate, you can't add fields to it, only wrap the struct in your own data structure. It's not your code. I'm not entirely sure what you're actually trying to accomplish. Are you attaching additional data to an external structure, or are you doing something else?
[associated type bounds](https://github.com/rust-lang/rfcs/blob/master/text/2289-associated-type-bounds.md) will be a nice quality of life improvement too.
&gt;Your first example works just fine? yes, just declaring. But in the moment I use it it show the problems. &amp;#x200B; &gt;You can use a private trait and implement it for the types you care about. I don't understand this. I try to replicate what the enum say with traits, so I have several impl Value for i32 {} but connecting the dots become tricky fast.
stalled after the mess of trying to get my Rust project onto iOS and Android.. complicated by it being SDL2 based which itself used a Java stub instead of pure native activity... horrible. 
I believe address sanitizer would be able to catch a double free, if such code would actually be run under it.
I'm looking for best practices. We know that not being able to extend a struct defined by some code(mine, maybe) is an issue. As a solution we can just tack on 4 pointers to our struct that we don't ever read or write to and define them as such. The first three are a grab all, but whomever uses the fourth should do a little more than just take up the last slot. That is until there is a better solution.
...cool story! :P
Only two hours after the announcement post ? Looks like /u/kibwen was [right](https://www.reddit.com/r/rust/comments/67x46l/announcing_rust_117/dgu8tgb/).
There's some good stuff here! Thanks for sharing it. A few hopefully constructive comments: * The headlines are too absolute in many cases. A good example is "Never ever use Rc, Arc, Cell, RefCell, UnsafeCell. If you do, you are probably doing it wrong." The actual content of that section explains what is really meant: don't try to use dynamic sharing to "work around" borrow checker issues. That is good advice. However, sooner rather than later you'll try to design a data structure and you'll need `Rc&lt;RefCell&lt;T&gt;&gt;` or somesuch. * "Use clone() at will!" An awful lot of beginner uses of `Clone` are misunderstandings of how the Rust memory model works: it would be better to correct those misunderstandings earlier rather than later. That said, it's always better to `clone()` and move on than to get stuck and quit. * "Better be too open than too private." Respectfully disagree. "Carefully audit which types and functions you're making public" isn't that hard for even Rust beginners to do, and will produce better results. * "Your struct should always inherit Debug. Also partialEq and Eq." *Maybe* `Debug` for public structs. Private structs should only derive `Debug` temporarily while it's needed for debugging. Implementing `Display` is almost always better than deriving `Debug` for things that are likely to want to be stringified. `PartialEq` and `Eq` should only be derived where equality tests make sense. * Using `self` rather than `&amp;self` in methods is pretty common for types that implement `Copy`: it generally makes writing code easier rather than harder in this case. It can also be harder to get the borrowing right for callers of a `&amp;mut self` method than just going functional style and saying fn method(self) -&gt; Self * "The thing is, returning an iterator is an advanced topic. Try it for fun if you may, but it‚Äôs not easy to deal to deal with the errors." For Rust 2018 you can return `impl Iterator`, which is really nice: it lets you return the result of some iterator chain from `std` without having to figure out the type nightmare of what you're returning. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=43f55be9428e94221c57283edc12226f)) * "Try and experiment with the Rust Playground." Absolutely. Maybe should be in the top section though? Again, thanks for writing this. It has a bunch of good advice, and I will share it with my Rust class that starts next week.
I bring you toilet humor and this is how you repay me?
If the 4 pointers are just to hold arbitrary data that's not always the same type, then you might be better served by making your struct generic and parametrize it over the contents of those 4 words.
That's a good point, rust isn't good with void pointers. This is for a future crate to extend another crate, the concept should still be usable by a 3rd crate. Perhaps we must ?simply? wait for rust to support traits adding members? They are called members?
Try impl Value for Scalar
Ok, this is my error. I surmised it was the case because I had found guides describing how to use `xvfb` with headless chrome and assumed that it was because it's necessary. [The FAQ](https://developers.google.com/web/updates/2017/04/headless-chrome#faq) answers this explicitly: &gt; _So I still need Xvfb?_ &gt; &gt; No. Headless Chrome doesn't use a window so a display server like Xvfb is no longer needed. You can happily run your automated tests without it.
Got a bit confused with the up/down directions for the stack: "Upstream" is often used to describe where we come from (parent) rather than where we are going (child). "Up the stack" would be in the parent, and "down the stack" in the child. In addition, with the stack itself being usually located "upside-down" (child stacks have a lower address than parents), it maps nicely to actual pointer values.
I think I'll just copy the smallish code from dacite-winit into my project.
One alternative strategy is to attach location like things to \[slog\]([https://docs.rs/slog/2.4.1/slog/](https://docs.rs/slog/2.4.1/slog/)) as key values, so it gets attached when the error is written to the log. It could written to the log with the error. Alternatively when handling some request the logger is cloned and the ip/path is attached to that clone, and that logger is passed around all the function calls related to the request. All logs lines related to that request would have the appropriate location data. 
I don't think Rust will ever plan to support adding data to imported structs that are visible to other libraries using it. If you aren't copying the struct wholesale, I'd suggest wrapping it in your own struct. The only members you can add to types defined outside your crate is to implement them as a trait and them implement the trait with the imported type. Rust *can* do *most* of what C can, but that doesn't mean you *should.* You might have better luck trying to picture how you would right it in a higher level language like Go or Java, and then find a middleground that can work in Rust.
You are trying to create a self-referential struct, which is not (easily) possible in Rust. There are some ways to get around that (e.g. [rental](https://docs.rs/rental/0.5.3/rental/)), but it's generally easier to just avoid it alltogether.
It would help massively if you would take the five seconds necessary to fix the broken formatting in your previous post. 
This is a point of extensability, say you are *working to add a new feature to an existing large project. Changing the type everywhere in that project or implementing every interface on that object might be an bug inducing task. Extending the existing type with what is needed seems less prone to creating new problems. Doing so in a new crate so the new feature can have a wider reach, say across an enterprise. Simply extern the crate and test.
Can you reimplement \`publicsuffix\`'s api with \`psl\`? Does Cargo support a deprecated/replacement attributes? Seems like tooling could help get users migrated quickly/quicker? Just spitballing...
&gt; I hate that rust not allow to "see" what T is, neither specialize some T, so If I have: This is called parametricity and is actually quite valuable because it gives you so-called "free theorems." For example, let's say you see the following declaration: fn foo&lt;T&gt;(t: T) -&gt; T { /* ... */ } Because foo cannot inspect T, you know that this function *must* simply return its argument. In other words, because generic functions are required to actually be *generic*, there are cases where a function's behavior can be inferred entirely from its type signature. If you really do need to inspect the type, you can do so by requiring T: Any, which allows you to downcast it.
Looks fine in the Android client.
Actually the solution is to not expose the changes to library users. Provide constructors so the users don't need to care about new fields. Encapsulation is a concept that most modern programming languages embrace, and is completely absent in C. You only change it at the source, and the benefits ripple outwards as users see new functions and methods, but they don't need to change because the constructor takes care of the new fields for them.
I actually looked at the code you provided; `pub use init::run as init;`
For Rust 2021, I think I might like a `foo/foo.rs` as alternative to `foo/mod.rs`. This way you get the clean directory structure, _and_ the different filenames.
I had to double-take. I wouldn't have bet money that common archs chose that way. Going to change it over to parent child semantics since that's unambiguous.
First of all: Thanks for your reply. :-) It still goes over my head a bit what you actually meant. I suppose I need to look up "actor model"? &gt;I'm not sure I would call it a "work-around". It's a straightforward and safe way to do something which, in other languages, is likely a source of subtle but bad bugs. The way I(!) understood it (which might be wrong) is that GTK (the version written in C) isn't thread safe. So in my Rust code I have to work around this limitation. In the TRPL there's a section about channels and how they can safely send data across threads. I guess this will never be doable with gtk-rs as long as the "root" GTK framework isn't thread safe. Is that a correct assumption?
Now I see why one can't just add to a struct, it would break all the constructors.
Correct, that doesn't seem like it would be valid in an impl block? Thus not extending the struct. I'll try and implement this as a trait.
&gt; Use Rust stable and avoid nightly &gt; If you need something in nightly you probably are over-engineering your problem, &gt; Put somewhere a shortcut to run cargo +nightly clippyeasily and often. Alright. &gt; Use very few dependencies Maybe good advice in go. Terrible in Rust. Learned not reinvent the wheel early on. &gt; As a rule of thumb use String, not &amp;str Is it though? I use String only in places I can't get around lifetime in say 15 minutes. (which is everywhere) &gt; Never have &amp;¬¥a in your structs, always own your data Yes, but what about iterators? There many places you would have temporal struct with `&amp;'` &gt; Prefer templating to dynamic traits (boxed traits) This is going to confuse anyone who ever read about rust traits. Static dispatch vs dynamic dispatch. Also missing a crucial detail - have a static dispatch method that calls to inner method - if you have function that takes `Into&lt;X&gt;`, then have a function that takes X, and make your other function call that one. Otherwise you going to endup with wholelot of code. &gt; Methods: first &amp;self, then &amp;mut self, then self Just learn what they mean and use what you need. &gt; Never ever use Rc, Arc, Cell, RefCell, UnsafeCell. If you do, you are probably doing it wrong Wat. I can agree on `UnsafeCell`, but the rest did to you? You should rather tell which ordering to use when using atomics. &gt; Don‚Äôt return an Iterator, a Vec is easier Oh no. If you have in iterator in your method - return it. Consumer will figure out what to do with it. tl;dr; Wouldn't not recomend folling those advices. 
It looks like you tracked down your performance issues, but I submitted a PR adding benchmarking with criterion. https://github.com/invis87/waves-seed-generator/pull/1
i128 is hardly cheating, considering that both x86_64 and aarch64 offer 128 bit results for 64-bit factors, which is in fact how my implementation compiles.
I wrote a (similar) blog post about it: https://leshow.github.io/post/unit_type_pattern/ In it I also argue for leaving data types unbounded.
Sorry, A little late to this thread. What is the difference between: ``` T: Eq + ::std::hash::Hash,``` and ``` T: Eq + std::hash::Hash``` Why do you use the leading double semicolon? In this one too: ```self.collect::&lt;::std::collections::HashSet&lt;_&gt;&gt;().len()```
Doh I feel silly. Thank you!
Hopefully you find an Android user who can help with your problem then.
I was mostly joking. However, it seems like if you want to take advantage of `i128` you ought to do `Frac64_64`, in which case you're back to splitting up the multiply.
I'm not entirely clear how backtraces are generated, but I think you can get that from the underlying `Fail`-implementing error.
That definitely improves debuggability of the logs. In this case though, I need to be able to print a good error message for users of a binary, so the location needs to be available to add to error messages.
Depends on the content of [mod.rs](https://mod.rs). If it's empty or some cursory re-export statements, I'd put it in the same directory for modularity's sake. Otherwise it should warrant its own file.
I am with you, coming from Go, I tend to like the modules in a single folder. The being said, most other Rust projects I have seen, tend to have modules in files in src as opposed to subdirs.
My `mod.rs` files rarely have anything other than re-exports. (At least, that's my memory speaking. I've written _a lot_ of `mod.rs` files, so I wonder how many have more than just re-exports.) In any case, your advice seems orthogonal to the OP's question...
Or even just do a major version bump on `publicsuffix` and bring in the `psl` API, then drop the `psl` crate.
Short answer: No. Less short answer: The memory model says what operations that operate on memory mean while an ABI says how to lay out memory and what to call to interface with a function.
I really don't like that implicit generics thing :\\ I'd rather use that technique to just power better error messages, or quickfixes in an IDE. I think a lot of the 'sugar' should just move to IDE honestly, leaving the sourcecode as an explicit record of intent.
Isn't VR mainly just rendering to two displays with slightly differing angles in their viewpoint?
&gt; Otherwise it should warrant its own file. Huh? It's its own file either way...
Thanks for sharing your thoughts.
It's out-of-the-box and pretty easy to get started.
i saw the contribution on piston is too low compared to amethyst. is that a good choice to pick piston over amethyst? BTW, can you share the documentation of VR thing in Piston?
hmm, that's a good point. i really didn't know this LOL. sorry im super beginner in gaming. but if it so then as long_void mentioned, can use the Window trait to do the job! im just guessing that the VR is more than the window split. i think the other thing need to think about is the inputs...
Wow that's just a really great explaination! I re-checked my snippet and noticed that I forgot the subtraction of `ALLOCATED`... Kudos for you!
Thanks! It's really informative!
Had the same thought. The commit is dated February 13th though, so it probably has been baking for a while.
What was controversial? The usage of Zinc?
This design seems inherently unsafe to me. A vec of `Val` can hold any `Val`; there's no way to make a `Vec&lt;Val::I32&gt;`.
Wouldn't that not be a real issue since it's open source? Why not just deal with it if the issue arises by creating a fork if Jason makes a decision they disagree with?
Call me a noob but webassembly outside of the web? Why???
S/Works fine in Android/Are you using Android or something else?/
Thanks for the interesting writeup. The definitions do seem to dodge the lifetime issue though, which I thought was a major issue. EG what happens if we start to have `Option&lt;'a str&gt;`.
For an interpreter is hard to model the data, specially because I need to work with heterogenous and homogenous info (I wanna provide Vectors, Hashmaps, Btree + Generators).
For this specific case, you can probably just store the BufReader and then use the BufReader methods get\_ref/get\_mut.
Something that would help this article is **actual rust code that you want to write** that you currently can't write. This article goes down a 5+ layer rabbit hole of abstraction without providing any kind of motivation for it existing. I'm down for theory and "i'm doing it because i can" if that's what this is, but in that case it would be nice to see **that** mentioned as the motivation.
Insignificant background details do not a compliant post make.
It‚Äôs broken in the web client in multiple browsers, Apollo, and the official iOS client. 
I'm confused by the example of Rust monad use: // A simple function making use of a monad. fn double_inner&lt;M: Monad&lt;u64&gt;&gt;(m: M) -&gt; M { m.bind(|x| x * 2) } Given the definition of `bind :: m a -&gt; (a -&gt; m b) -&gt; m b`, I would have thought the closure should be something like type `Fn(u64) -&gt; M`. But it returns `u64` instead of `M`? This looks like a regular `map`.
https://pastebin.com/wsLLg3MQ Insert your fav. Mac bash here. It's just an HTML5 code block on Linux, so you just need to update your browser to support frames.
If you take `self` and return `Self`, that is you take ownership and return ownership, it should work always. Only when you are working with `&amp;self` would you meet the not living long enough problem. 
I have not used PhantomData, but my feeling is that it is similar to Haskell‚Äôs Proxy. 
I don't think OP is saying anything about `src`.
Coming from Haskell, I prefer naming arguments with their types. Type aliases and type wrappers are great. 
Other folks pointed out that this isn't generally possible, and I want to clarify why. That `&amp;TcpStream` is a pointer to a specific location in memory. For a pointer like that to remain valid, the thing its pointing to must never move. That's why the compiler normally doesn't let you move a value while its being borrowed, to avoid creating dangling references. So, if you managed to get both your `TcpStream` and a reference to it into the same struct, that struct would need to be "permanently borrowed". From the very moment it was constructed, it could never move again. Not to go into a collection, not to be passed as an argument or returned, nothing. The only thing you could ever do would be to take more shared references to it. That's ultimately why the lifetime system has never been expanded to represent such a thing -- it would be too restricted to be useful. I think /u/JayDepp's suggestion about letting the `BufReader` own the `TcpStream` is the right one. Note that `BufReader::into_inner` make it possible to get the `TcpStream` back out again later if you need to.
To understand error handling this might be helpful \- [https://medium.com/learning-rust/rust-error-handling-72a8e036dd3](https://medium.com/learning-rust/rust-error-handling-72a8e036dd3) 
FYI, if you're so new to rust that you didn't know about \`serde\`, you may want to reconsider using Rust for this task. Rust and serde are amazing, but they have a steep learning curve.
Despite the weird name and reputation, monads are a pretty useful and powerful things. Basically, a monad is an abstraction over a sequence of computations. If you have a code that does *this* than *that* you have a monad, at least in a conceptual way. Because a "sequence of computations" is a vague concept, you need some rules and more generic abstractions -- hence the need for functors and higher kinds. IMO an useful application of monads in Rust would be in the async/await design, specially with the ~~heavily bikeshedded~~ issue of how the `?` operator would interact with await expressions. With monads you can turn an everything into a sequence of bind calls (do syntax), making the interop seamless. This is how things are done in Scala and Haskell, for example.
I get that, but I feel like they are going way overboard with the NIH here. For example I think using `lazy_static!` would be *much* more boring than [https://github.com/cloudflare/boringtun/blob/master/src/crypto/x25519/mod.rs#L23](what they are doing). `static mut` is very, very hard to use without causing UB. Having it in your crypto code without even a comment as to why it's sound is troublesome.
Answered in the first paragraph of the article.
It is broken on Chrome, Firefox, and Edge across the Mac, Windows, and Linux because reddit comment syntax is not Markdown, and code blocks are created by indenting four spaces, not by surrounding them with triple-backticks. If anything, this would be a bug in your Android client for misrendering reddit comment syntax as Markdown. 
&gt; this than that ... Did you mean to say "then"?
Not sure what u mean? I looked only at the HTML source that Chromium from Debian sid loaded and it showed valid HTML5 code tag. See: https://www.w3schools.com/tags/tag_code.asp
Rust functions must come with type annotations, so they must follow their type annotations. Closures are without type annotations, so their trait bounds can be inferred freely.
I came from Java and I still don't get why we need mod.rs can't it be just the filename and the directory structure.? 
That's fair. I'm coming at this from an ease of writing over ease of reading/maintenance which I know most people edge towards the latter. I lean towards the latter in a very specific use case, which is math heavy code that is generic over arithmetic types (that may be user-defined). I find myself copy/pasting trait bounds extensively when building generic algorithms that gets painful when the traits start building on each other. Trait aliases would solve a lot of the headache. 
I think the rust book is also missing a "here's an example of coding a program the difficult/wrong way in rust(coming from java/python), here's how you should restructure it, here's why you should restructure it" I feel like you would be interested in writing an example like that :)
You can't not have `rust-docs` installed. It's a long-standing issue because it's very slow on Windows systems and makes CI builds painful.
Maybe ask yourself of you really need a database. If you don't need concurrent transactional access, maybe a simple serde frontend will do.
That cannot work in Rust so easily because of non-local control flow like break and return. https://twitter.com/withoutboats/status/1027702535707090944
I'm a little concerned if HKTs can't be easily added to Rust. A sign of a good design is it works one, two, and three+ levels deep. If types of types don't work, something seems fragile.
We don't have similar thing to skia in pure rust?. 
Wouldn't your functor example be overlapping instances? You have a impl&lt;A&gt; Functor&lt;A&gt; for Option&lt;A&gt; and a impl&lt;A, I: Iterator&lt;Item = A&gt;&gt; Functor&lt;A&gt; for I The constraint solver will see both of these as valid choices for `Option&lt;A&gt;`, because it only looks at the patterns at the end without considering any further constraints it will need to satisfy for the implementation.
It has the potential to be everything Java promised for "compile once, run anywhere" but with all the additional benefits of not requiring a garbage collector.
I don't find either one significantly better than the other, for reasons people outlined in this thread. So I'd just stick with what is considered the best practice. Unfortunately, as this thread shows, there are two different best practices. I wonder how we ended up in this situation: shipping a feature, which is an alternative to an existing one, and which is not better, just different (note: this assessment is based primarily on this reddit thread and my gut feeling, it *might* be the case that `mod.rs`-less variant is significantly better for 90% of Rust programmers). To me, it seems clear that "just another way to do X" features should never be added to the language, unless "the new way" is order of magnitude better than the old one: language stability (as in, no new stuff) and orthogonality are super important. Basically, this comment by Graydon resonates strongly with me: https://internals.rust-lang.org/t/rust-2018-an-early-preview/7776/14
FWIW, the post calls this tweet out by name and provides a reasonable solution.
I'll be honest I have no idea where to put this.
&gt; specifically in the heavily bikesheded issue of how the `?` operator would interact with await expressions. With monads you can turn everything into a sequence of `bind` calls, making the interop seamless. But that's stacking two monads. I don't know if they're still considered "state of the art", but I wouldn't call monad transformers seamless.
any thing wrong with [filter_map](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter_map)? let nums = vec![3, 2, 2, 4, 5, 4, 1, 7]; let values: Vec&lt;_&gt; = nums.iter().map(|x| Val::I32(*x)).collect(); fn filter_i32(of: &amp;Val) -&gt; Option&lt;&amp;i32&gt; { match of { Val::I32(x) =&gt; Some(x), _ =&gt; None, } } let ivalues: Vec&lt;&amp;i32&gt; = values.iter().filter_map(|val| filter_i32(val)).collect();
Fixed.
Yep, seamless was a bit of exaggeration on my part. Still with monads we would have more design options to explore from, thanks to the research and long usage in Haskell. Although the design constraints of Rust makes the things pretty hard, not to mention the cognitive overload too...
I've written a bit of Haskell in another life, but the code in this post isn't code I'd like to write (or read) in Rust. And I can't elaborate on this right now, but I feel that the "everything is a monad" discourse is a bit dismissive, since even though some language constructs (LINQ, futures) may appear monadic, they're often more than that.
Though several posts were linked which each provide some additional context, I suspect the audience for this one is mostly the people who have been following the discussion around Rust's typesystem and functional programming abstractions for years, to whom it's already clear why these abstractions are useful and desired. Here's a quick and dirty example. You have at your disposal a function which will check if an integer is even and, if so, return half of it, otherwise nothing. fn half_even(i: u32) -&gt; Option&lt;u32&gt; { if i &amp; 1 == 0 { Some(i &gt;&gt; 1) } else { None } } Your task is to take either zero integers or one integer and, if you were given one, check that's it's even and return it, otherwise nothing. How would you write that? fn maybe_half(opt: Option&lt;u32&gt;) -&gt; Option&lt;u32&gt; { opt.and_then(half_even) } Now you are given a function which takes a number and does a similar thing, except returning all the even halfs it can. fn half_evens(mut i: u32) -&gt; Vec&lt;u32&gt; { let mut v = Vec::new(); while i &amp; 1 == 0 { i &gt;&gt;= 1; v.push(i); } v } Now your task is to almost the same thing as before but for an arbitrary amount of input integers and returning all of their halfs. How would you write that? fn all_half_evens(is: Vec&lt;u32&gt;) -&gt; Vec&lt;u32&gt; { is.into_iter().flat_map(half_evens).collect() } You notice that `maybe_half_even` and `all_half_evens` kind of have a similar structure. They take a kind of container (`Option`, `Vec`) and return the same kind of container. They also do this by using a function from the container's element (`u32`) to that kind of container. It might be nice to write similar code for similar operations. Maybe something like assert_eq!{operation(Some(24), half_even), maybe_half(Some(24)}; assert_eq!{operation(vec![24], half_evens), all_half_evens(vec![24])}; So instead of two different functions `maybe_half` and `all_half_evens` we have the one combining function `operation`. That'd be neat. It could even work for things that aren't strictly "containers", like maybe you have a `Future&lt;u32&gt;` and a `u32 -&gt; Future&lt;u32&gt;`; that sure seems combinable with the same operation. Can you describe this in actual Rust code for any kind of container and element given a suitable function? Let's try. fn operation&lt;E, C&lt;E&gt;, F: FnOnce(E) -&gt; C&lt;E&gt;&gt; (c: C&lt;E&gt;, f: F) -&gt; C&lt;E&gt; { unimplemented!("we don't actually know anything about C to call any methods on it") unreachable!("there's also invalid generic syntax with C&lt;E&gt;") } Or maybe we want this in a trait `Operation` with `fn operation&lt;...&gt;(self: C&lt;E&gt;, f: F) -&gt; C&lt;E&gt;`, so that we could call `Some(24).operation(half_even)` as well as `vec![24].operation(half_evens)` and get the same results as `maybe_half` and `all_half_evens` thanks to the implementation of `operation`? You run into similar implementation issues. It turns out that in current Rust there's actually no way to define `Operation`/`operation` such that we can call both `Some(24).operation(half_even)` as well as `vec![24].operation(half_evens)` (or at least no way that also satisfies the constraints I didn't list in this quick example). This article shows how we could gain the ability to write `operation` for different "containers" in a trait. It just calls the containers "type constructors", the trait `Monad`, and the operation `bind`. What would be ideal for people who like this kind of abstraction is if we could write something like fn bind&lt;C&lt;_&gt;, A, B, F&gt;(c: C&lt;A&gt;, f: F) where C: Monad, F: Func(A) -&gt; C&lt;B&gt; But this requires higher-kinded types (note the `C&lt;_&gt;` filled in with `A` later, and the trait bound only on `C`) and the ability to talk about `Fn`/`FnMut`/`FnOnce` in the same way (traits-for-traits, the `Func` bound), which are both much bigger additions to the language than what's needed for the design in the post.
&gt;"But unless you know what you are doing, you shouldn‚Äôt return a &amp;str. Use String as return type so that" So that what? The sentence just cuts off there.
Literally every program besides one that immediately halts and does nothing else (and even then) is a "sequence of computations". Is "monad" just a goofy word for "program" or "subroutine"?
r/playrust
One nice trick for saving both time and storage space that I've learned is: if your cp supports -a (aka, it's GNU), you can also pass it -l to make hard links of the files it encounters. Look&amp;work like regular files, faster to create, but take up no additional disk space.
When you don't have a virtual memory system, putting the stack at the top of the address space and growing downwards makes sense; it gives it the most room to grow before it collides with everything else. Every architecture since then pretty much inherited this.
You can avoid the copy step and run `rustup doc` to view the std docs that come with Rust. 
As PolarNoise2D is generic, and T has no indications whatsoever other than ‚Äúit‚Äôs a type‚Äù, the compiler runs into problems. Because you‚Äôre using owned type for ‚ÄúT‚Äù, the whole data is there, flat in your data structure, and that‚Äôs a problem because your generic struct doesn‚Äôt know which size it is (or doesn‚Äôt know you know which size it is). As you use your struct on float, you‚Äôre surely wondering why the compilers fails to understanding its size. That‚Äôs because of the generic declaration, what you want is declare your struct generic over a ‚ÄúT + Sized‚Äù (read the Sized doc). If you indeed need unknown size, an eqsy workaround is to ‚ÄúBox&lt;T&gt;‚Äù it. Tl;dr : you surely want ‚ÄúSize‚Äù
Man, I really don't know how to say this any more clearly. In your original post, you tried to use triple-backticks to perform code formatting. This is a Github-Flavored Markdown-ism. Reddit does not use GFM. [Reddit requires indentation of four spaces in order to detect code blocks](https://www.reddit.com/wiki/commenting#wiki_posting). Your post looks like [this](https://imgur.com/8GvFXCz) on *any* Reddit client. The source looks like [this](https://imgur.com/ONq6Sl7), and is clearly not what was intended because Reddit is interpreting mid-string backticks as beginning and ending code blocks.
Thanks, FWIW T will be an unknown size as it could be any of a number of types each surely has a different size.
Fair enough. I'll admit I didn't read past the first half initially as I got lost by then. The post mentions that interaction with lifetimes would need to be tested and possibly special-cased in the compiler to make it work. Having more special cases may or may not be reasonable depending on your perspective.
Can it run browser apps based on wasi without modifications? And the other way around?
Wouldn't the function also need to return an `M::Bind&lt;u64, [closure]&gt;` instead of an `M`?
Wow! Thanks a lot Josh! The performance problem that I fixed was a only about curve25519 algo (which is 98% of all program cpu consuming actually). So others part of code is not so important. But thanks much for refactoring and `bench` - I am new to rust and all code related help is very important. Thanks again)
\`Option&lt;A&gt;\` does not implement \`Iterator\` but \`IntoIterator\`.
I tried using generic associated types, and while they do exist as an unstable feature, The compiler doesn't seem to like me actually constructing the type. trait Functor&lt;X&gt; { type Output&lt;Y&gt;; fn fmap&lt;T&gt;(self, f: impl Fn(X)-&gt;T) -&gt; Self::Output&lt;T&gt;; } resulting in: error[E0109]: type arguments are not allowed for this type --&gt; src/main.rs:4:56 | 4 | fn fmap&lt;T&gt;(self, f: impl Fn(X)-&gt;T) -&gt; Self::Output&lt;T&gt;; | ^ type argument not allowed 
Here is your confusion, the types you want to implement T on are probably all Sized (f64 is known, and a i32 is known too, as well as a i64, even though they‚Äôre not the same size), and the compiler needs to know it can rely on a known size when instanciating a specific implementation. When generating the specific ‚Äúimplementation‚Äù for a Sized type, it will infer its size at compile time, because it cannot change for a given T+Sized. ‚ÄúDifferent known size for each T‚Äù is not similar to ‚Äúunknown size at compile time for each T‚Äù
The point is to have them together with docs for your own code. If one of your functions returns a `Vec&lt;u8&gt;`, clicking on `Vec` in the docs for that function will go to your local copy of the standard library docs. By default it would go to https://doc.rust-lang.org/
This wasn't it, I got it working though. I used this, minus the Box::new calls: [https://doc.rust-lang.org/book/trait-objects.html](https://doc.rust-lang.org/book/trait-objects.html)
I tried to read it but it went whoosh. How do you plan on reconciling HKT with HRTB with for&lt;‚Äòa&gt; syntax?
It works, the magic syntax was: \`impl&lt;T&gt; NoiseFn&lt;f64&gt; for PolarNoise2D&lt;T&gt; where T: NoiseFn&lt;Point2&lt;f64&gt;&gt; {\` [https://bitbucket.org/cheako/polar\_noise/src/c79add641bfa8692fb1b56f74fcf8452e9e2a3b9/src/lib.rs#lines-20](https://bitbucket.org/cheako/polar_noise/src/c79add641bfa8692fb1b56f74fcf8452e9e2a3b9/src/lib.rs#lines-20)
Oh ok, glad you made it work :) thanks for sharing
I wonder how many Rustaceans play Rust game.
more similar to 'lambda' &amp;#x200B; But (at least how I've used them in haskell) they can share state between one another in a way that would probably work pretty well with rust's lifetimes. So you can write a lambda that'd just say 'hey put this thing in a stack please' then another that says 'hey read from the top of the stack and add 3', then string these up in a chain, and run the monad chain with a given 'start state'. This is how IO is handled in haskell, whilst still leaving it 'pure', because each function just returns the monad chain + 1 operation &amp;#x200B; Take this with a pretty big grain of salt mind
This. The article lost me half way through by not showing any example use cases or argumentation for why Rust needs monads. I feel like this is a really bad fit for Rust. It might not have the class keyword but Rust is very much imperative and OOP.
&gt; Now, I wonder if recovering the values of a vector of my Val can be close to just take the vector directly That's exactly what your last snippet is doing. You can't get much more direct than that. Your `I32(Vec&lt;i32&gt;)` solution is the cleanest.
It's like "computational context" conceptually. In practice, in Rust terms, Monad is a trait with the `and_then` method (like on Result). There are other minor requirements (e.g. Monad implies Functor, i.e. the "can be `map`ped over" trait), there are monad laws, but the "bind" is the most useful monadic operation. Option and Result in Rust are monads, but there's no Monad trait (because no HKT), they just have the methods directly on them.
IIRC Rust's deliberate choice to not do inter-procedure lifetime analysis means that this doesn't work.
&gt; We don't have similar thing to skia in pure rust? Because of even `servo` uses it I suppose the answer is no.
&gt; Basically, a monad is an abstraction over a sequence of computations. It's actually more general that that, which is interesting to mention at least in order to avoid responses such as northrupthebandgeek's, saying well, a monad is just an imperative program then, since all imperative programs are sequential by definition, so what's the point. It's better to think of a monad a something that transparently wraps and unwraps values by a hidden type. In the IO monad, which is the one that allows you to sequence IO operations, the wrapping/unwrapping is to conceptually "prefix" each operation with a value, which allows to specify order dependency when it doesn't trivially exist. In other words, `bind :: m a -&gt; (a -&gt; m b) -&gt; m b` means that we define a function taking a value `a` "wrapped" by type `m`, provide `a` directly to some function, and output that function's value newly "wrapped" again by type `m`. So if you have a sequence of functions `do A; B`, then if `m` is an integer type, `B` can be made to depend on the 'hidden integer' output of `A`, which enforces ordering even though `B` doesn't care what `A` does. But the cool thing is that `m` can be quite a variety of things. For example, it can be a list that collects sequential outputs or logging information (the List monad), or it can be a boolean that only calls the next function if it's still true, allowing to "short-circuit" the rest of the function (the Maybe monad). You can even have a tree type and a function that uses it to decide what to do next, which allows to define search algorithms, check the [knight's quest](http://learnyouahaskell.com/a-fistful-of-monads) example. In general it's a pretty neat concept, as it sort of allows you to write a program "around" a program, to define what happens in between statements. Think of monad less as an "ordering" object, and more as a "programmable semicolon" that lets you insert arbitrary logic into how the program runs and what happens to inputs and outputs of each line.
I'm personally hoping for a `foo/_mod.rs` option so that it doesn't get lost in the middle of all the other submodules.
&gt;*Maybe* `Debug` for public structs. Private structs should only derive `Debug` temporarily while it's needed for debugging. Big disagree on this one; you can't use `assert_eq!` in unit tests with types that don't implement `Debug`.
Monads is hard ask, but the ability to abstract over either Rc or Arc is a very obvious win that requires HKTs
You write a wasm library in Ruby.. i can link and use it in .NET or on the JVM.. i write a wasm library in Python and then you can use that in your Node.JS app. This opens up a whole new world of reuse. Reduction of duplicate effort between platforms etc..
Easy question about for-looping over a Vector. Here's the playground link: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=51b07f943f5feb97aac8cecfd5f7ae8b My questions: 1. Why does the commented out code MOVE my testvector? It's not like I pass testvector to another function. I just loop over it. So where exactly is it being moved to? Into "element"? Seems a bit counter-intuitive. I understand what moving is in the context of functions and it makes sense. But why here? 2. What is the difference between looping over `&amp;testvector` vs `testvector.iter()? ? Is it the same thing just with different syntax? Or is there more to it? I googled and found out that there's also `testvector.iter_mut()` which in turn seems to do the exact same thing as `&amp;mut testvector`. So I assume it is/does the exact same thing. Is that correct though?
Where did you read that you don't need mod.rs anymore? I'm just trying it here without with latest rust 1.33 and it doesn't work without it. module examples inside your crate can be either examples.rs or examples/mod.rs
"need" is such a harsh word. Every module has some root to it, so if you want to put a module into a directory, you need some place for the root of the module to exist. In Rust 2015, that place was `mod.rs` inside of the module sub-directory. I personally like that style because it serves as a nice sentinel and keeps every part of a module containing in a single sub-directory. Rust 2018 added another way to do this, where if you have a directory for a sub-module `foo`, then you can put the root of that module in `foo.rs` instead, where `foo` and `foo.rs` are siblings in your directory hierarchy.
If you're not familiar with monads, [https://underscore.io/books/scala-with-cats/](https://underscore.io/books/scala-with-cats/) is a very approachable introduction to the topic. &amp;#x200B; It is in scala, but it assumes very little basic knowledge and is largely talking about the topic, not the language. &amp;#x200B; ...but if you're just interested in the tldr; read [https://stackoverflow.com/questions/28139259/why-do-we-need-monads](https://stackoverflow.com/questions/28139259/why-do-we-need-monads) &amp;#x200B; tldr; it's an abstraction. The idea of 'explain why you want monads' is basically lazy trolling; that's a very nuanced question, with many, very well explained, clearly documented answers... but if you can't be bothered going and reading them, don't expect to understand a 10 line answer to it on a reddit thread.
I would cream my pants if you got the name from the Tao of JKD
I agree. I realize this is a cliche, but one of the hardest parts about maintaining software is saying "no." And I don't say that as someone who is above such things; I fail at it all the time. It is sometimes daunting to even begin to figure out when exactly the right time is to "debate" whether we should do something at all. And even if you do, it is a very difficult role to play. (This isn't to understate the difficulty of any other role in feature development either, of course.)
I'm not convinced that any monad abstraction in stdlib would be beneficial for the popularity of the language. Yes, operating generic functions over generic functions is cool and all, but rust already tries for 98% of the benefit there through other ad-hoc means which usually are more comprehensible for newcomers not from Haskell. It's even mentioned. FnOnce, FnMut, Fn, the Option type, probably the new yield/await... I really doubt that even if this produces something it'll get into the stdlib.
How would that work? I can write a new mutex type, independent from the ones in Rust, and have two threads deadlock on it. How would miri know that these threads are in a deadlock instead of doing "useful work"?
Note: that you can use `#[cfg(miri)]` in your program to "support" the miri "platform"
You're right: that's a typo. It should have been: m.bind(|x| M::unit(x * 2)) I've updated the post. Thanks!
You might want to fill an issue for this, it would be very useful if one could use `cargo miri test --env=key:value --env=env.toml` or something like that to control the environment variables passed to a program more precisely.
I cannot agree with you more. I just don't know what problem this is attempting to solve, and the costs in compile times (combinator-heavy code is slower to compile), user comprehension, and increased complexity worry me. Also, from my own personal experience as an OCaml programmer turned Rust programmer, functional programming is not nearly as nice in Rust as it is in OCaml (or F# or Haskell), and it would be perfectly okay to say that Rust doesn't need to support all the FP idioms that exist out there.
Rust Job https://i.imgur.com/DZjSuLl.png Blockchain
That's true: these particular implementations will conflict. I intended each example to be considered in isolation (in practice, deciding how to implement `Functor` would be a little more nuanced), but I'll add a note about this in the post.
Good questions. The good news is that there's generally one answer to everything: [`IntoIterator`](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html). It's explained in a bit more detail here: https://doc.rust-lang.org/std/iter/index.html#for-loops-and-intoiterator For your first question, the _reason_ why it's being moved is because `for x in foo {` is syntactic sugar for something like `for x in foo.into_iter() {`, and since `Vec&lt;T&gt;` implements `IntoIter`, this consumes the `Vec`. The advantage of this is that the type of `x` in your loop is `T` and not `&amp;T` or `&amp;mut T`. That is, by consuming `Vec&lt;T&gt;`, you also get to consume each of its individual elements. For your second question, you are indeed right that `&amp;testvector` and `testvector.iter()` are doing the same thing (and similarly for `&amp;mut testvector` and `testvector.iter_mut()`). That is, `&amp;testvector` works because it has type `&amp;Vec&lt;T&gt;` _and_ there exists a `impl&lt;'a, T&gt; IntoIterator for &amp;'a Vec&lt;T&gt;` implementation. That means you can call `into_iter` on a `&amp;Vec&lt;T&gt;` and get back an iterator over references to its elements (i.e., `&amp;T`). You can try this by using `(&amp;testvector).into_iter()`, for example.
That's a good point: the introduction could provide more motivation. &gt; I'm down for theory and "i'm doing it because i can" if that's what this is This is essentially the motivation here. Whether monads are useful or not in Rust is a question that has been (and will continue to be) debated, but I'm not particularly concerned with that question here. The fact is that, questions of usefulness aside, a way to even implement monads if we *wanted to* has been historically difficult to envisage, because of all the issues described in the article. My stance is that it's not worth discussing something if it might not even be possible, so I wanted to show that it could be. If this design holds water, then we can start discussing whether we might actually want to facilitate it or not :)
I can not find the question in this text. What does the equal function at the beginning have to do with anything? What allocations do you refer to? What do the list comprehension have to do with your enum type? Why you use the word vectorized at all? If the goal is to have recursive enumerators, the answer is no. You can not nest use of your own enumerator type without pushing it on the heap by using a vector or a box or something like that. How is the compiler going to figure out the layout of your infinite data type? 
`for .. in .. ` sugar utilizes [the `IntoIterator` trait](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html) so that you don't have to call `.iter()` or `.iter_mut()` all the time. Have a look through the implementors and their associated types (`type IntoIter = ...`). When you pass `testvector` by value, it calls `.into_iter()` on it which gives an iterator that yields elements in the vector by-value. For element types that can't be copied or cloned, this is the only way to loop over owned values from a vector. When you pass a reference, it instead uses the `impl IntoIterator for &amp;Vec&lt;i32&gt; {}` which yields references to the elements. This is how you can iterate over a shared reference to a collection. Similarly, passing a mutable reference yields mutable references to the elements.
I tried to address the concerns I was aware of, but I could definitely have overlooked something. Could you give an example of a snippet you think would cause problems?
GATs are effectively unimplemented at the moment (though there's some support for parsing the syntax). You can track the implementation [here](https://github.com/rust-lang/rust/issues/44265). It'll be difficult to play around with the examples here until we do, though.
I need to keep a sorted list of numbers with decimals as part of [topsort](https://github.com/nicofff/topsort). Ended up implementing this so I can use a btree: ``` pub struct Decimal { whole: isize, fractional: usize } ``` With it's respective Eq, PartialOrd and Ord traits. Is there a better way to achieve this?
Ez raid xD
But how come directory with .rs files isn‚Äôt implicitely a module if mod.rs is mostly just used to declare submodules?
Just learning here. Thanks for the article. 
Thanks for the suggestion. I'll see if I can find something more descriptive (but still concise!).
`mod.rs` isn't just for declaring sub-modules. It's also for re-exporting and crafting an API for its entire sub-module structure. Questions like "why can't it just be implicit" like this have easy answers: "it could, but we didn't want it to be." IIRC, I think there _was_ a plan to do this at one point for Rust 2018, but I think enough people pushed back against it in favor of keeping an explicit `mod foo;` that it was dropped. (I also prefer the explicit approach.)
Not quite. Old Reddit (which I'm on and I'm assuming you're on) doesn't support triple backticks. New Reddit (which I find ugly and irritating) renders a new dialect which incorporates some features from CommonMark, including the fenced code blocks pioneered by GitHub-Flavoured Markdown. [Here's the relevant doc](https://www.reddit.com/wiki/markdown#wiki_differences_between_old_reddit_markdown.2C_new_reddit_markdown.2C_and_commonmark)
Cool, that helps me understand the issue. I ended up going with the just storing the \`BufReader\` and using \`get\_ref()\` when I need to access the socket. Thanks for the help!
Thanks, this works! Not sure wether to call the variable \`reader\` or \`socket\` though üòÅ
Seems like avoiding it is the best way to go in this case, thanks for the link to rental though, it was an interesting read!
&gt; Is "monad" just a goofy word for "program" or "subroutine"? No. A monad is a type that implements 2 or 3 functions (you can write either formulation in terms of the other) - either pure, map, and flatten, or pure and flatMap. Those operations allow you to express sequences of computation "within" the confines of that type. Future, Option, Vec, and Fn are a couple examples of types that can be monadic. That basically gives you the power to talk about computations in some context. You can wrap any computation an Identity type, and that will do nothing. If you put things in Option, you'll short-circuit the computation when you get a None. If you use Future, you'll compute asynchronously. If you use Vec, you get nondeterminism of a sort. If you use Fn, you get a read-only context to work in. It's a very useful abstraction, but it's not very obvious at first glance why it's useful until you see examples. 
this might be interesting for you: I'm revamping the routing in the [sozu HTTP reverse proxy](https://github.com/sozu-proxy/sozu), and I've tested various implementations, with benchmarks [here](https://github.com/sozu-proxy/trie_benches). My use case is heavily influenced by a need to edit the data structure at runtime, but some of the ideas could be useful.
I need lots of many-to-many relations for datasets too big to fit in memory, unfortunately. I would love it if there were a better way to do this, I confess. Concurrent access is irrelevant, transactional access is nice for making integrity easy but not essential.
&gt; However, we can use yield just fine within do notation (using the same propagation of control flow from closures as break or return). It seems to me that there is some kind of implicit assumption here that the underlying monad commutes with the "Future monad" (putting in quotes because I don't understand what the type of `yield` is supposed to be). Am I misunderstanding something/Is that not the case?
Out of curiosity, let's say your formulation of monads was made possible by the language tomorrow, where all necessary features are stabilized. What would you do with it?
What's fragile is, we have constraints regarding the machine. These concepts run in the abstract world of math. The task is to translate them into the world of computers. Many languages do that by saying "where computers and math conflict, math wins." So, for example, Haskell is garbage collected, and heap allocates things a lot. This means that there's a uniform representation of values at the machine level, making this stuff easy. Rust says "where computers and math conflict, computers win." So we have a lot of stuff related to efficiency. But this poses implementation challenges that simply don't exist in those kinds of languages. Does that make sense?
I was surprised to see that /u/steveklabnik1 has been looking into Ada, as I've also been trying to learn it recently and been getting slightly dismayed every time the Ada IRC channel helpfully answers one of my questions by referencing a range of pages in a $70 e-book. I've often had to resort to just reading the language reference directly, which is hardly intended for beginners. It really, really makes me appreciate the breadth and availability of Rust learning materials. :)
As it says in the title - any feedback is much appreciated! (I think there are many things I am doing wrong or inefficiently) Right now I am not planning on testing it on a larger scale, even though it should be able to handle many sessions at once.
Damn, i'd be so keen, but I literally moved to NYC because of lack of FP jobs
I have no idea. I've only done it previously by switching to my own implementations of standard lock functions and let them record their usage so it can be analyzed for potential deadlocks.
I'm so happy to live in Austria, where every job ad must include the salary.
But why not just compile something for WASM and then compile for the other architectures that are non-web?
Given that Miri currently cannot spawn threads, there's little points in trying things with `rayon` unfortunately.
Yes, but please keep that to a minimum: if you use Miri for UB testing, code that you swap out using `cfg(miri)` will not be tested!
Yes, you can see it at a complement to valgrind -- one more tool in the toolbox. Miri currently supports way less program features (no concurrency, no networking, no file system access, ...), but OTOH it knows much more about Rust than valgrind does.
Is it possible for it to go to the local copy of the docs then without all this copying, if you have the `rust-docs` component?(Which is apparently currently impossible not to have?)
I have read that many people acknowledge Ada's part-commercial roots, major use in serious engineering (i.e. not hobbyist) disciplines, and old-school documentation and documentation system as all being barriers for new blood. However, a coworker of mine used to write Ada compilers for bespoke hardware and has always been pretty "pro" the language itself and what it could accomplish. Since Ada is old, it was in part designed for portability. You would write an Ada compiler specifically for your board - be that in an airplane, train, satellite, etc. That's why in Steve's blog he found that stuff about the compiler deciding all the appropriate machine details, like word size, green-threads or real-threads, etc. And hey if Steve K. happens to read this, be sure to read up on the Ravenscar profile at some point. That blurb in the blog about a task tree - well, my Ada-compiler-writer friend says that is considered to be one of the mistakes in design in the language. You can use a pragma to disable that so there is a single controller to multiple children (no grandchildren) as a task hierarchy. The problem is that the tasks have to wait for readiness from all related tasks and it becomes polynomial or something like that, and an easy source of bugs in your program too.
&gt; Well it could in theory perform static analysis Miri is explicitly a fully dynamic tool, there is no static analysis. I concur with /u/CAD1997, including their terminology (but also would be fine with another): A library containing unsafe code effectively acts as a type system extension: it allows well-typed programs (aka safe programs, because the safe fragment of Rust is the only type system that can hope to be sound) to execute an operation that they otherwise could not. This library/extension is unsound if it allows safe client code to exhibit UB. We can bikeshed terminology, but I think "soundness" is a reasonable term here. Miri can find UB, but not unsoundness. The latter is a much harder problem. In fact, finding UB ought to be decidable (I will do my best to make sure it is), but soundness certainly is not decidable. 
&gt; Miri is explicitly a fully dynamic tool, there is no static analysis. I know. Emphasis on *could*. ;) &gt; A library containing unsafe code effectively acts as a type system extension: Yes, I'm sold on this idea; it's essentially what I was saying above. &gt; Miri can find UB, but not unsoundness. &gt; [...] &gt; , but soundness certainly is not decidable. Well yes, it's not decidable *in general* since it's a dynamic analysis. If miri runs `fn main() ` which calls a safe `fn` and finds UB for any input then it has found unsoundness by your own idea of a "type system extension". So I don't think it is right to say that miri cannot find any unsoundness. The distinction here is between "any" and "all".
Sort of but my argument was that in Haskell when you write a data type definition, you usually don't bound the type parameters. for instance data Tree a = Leaf a |Node (Tree a) a (Tree a) -- 'a' is unbounded, you almost always want this not: data Tree a where Leaf :: Ord a =&gt; a -&gt; Tree a -&gt; Tree a Node :: Ord a =&gt; Tree a -&gt; a -&gt; Tree a -&gt; Tree a (excuse any mistakes I don't write GADTs very often). While Tree technically should exist without an Ord bound on 'a'. You usually don't include it in the data type definition. Instead you add the constraint to all the functions that use Tree and leave the data type unbounded
&gt; So, given the unwillingness of Cloudflare to work as part of upstream and join our project, and upstream's need for a solid Rust implementation, we may very well wind up forking it into wireguard-rs, I'd say it might be worth giving them the benefit of the doubt. Don't fork until/unless they prove reluctant to accept patches.
It is certainly a problem. Given their positioning in the Ada market, AdaCore would do well to buy the rights to the book and release it publicly -- or hire John Barnes to write yet another version. :) In case you have access to SpringerLink (through a university library, for example), I found that Ben-Ari's book ["Ada for Software Engineers (Ada 2005)"](https://link.springer.com/book/10.1007%2F978-1-84882-314-3) is a very well written and thorough introduction to the language. It doesn't cover the 2012 version, but between Ben-Ari's book and John Barnes' free [introduction to Ada 2012](https://www.adacore.com/uploads/technical-papers/Ada2012_Rational_Introducion.pdf), you can get very far. Of course, your local public library can help -- they can probably get you a copy of the books on interlibrary loan. Yes, I know it's old school (what is this physical book thing of which you speak?), but a quick exchange with your local library might get you the resources you need.
&gt; Rust says "where computers and math conflict, computers win." Hum. I'm not sure we can really say that 'computers conflict with math'. We can certainly model the low level concerns of computers mathematically - just look at separation logic, CompCert, seL4, etc. The real challenge is that we want to expose more of the underlying model of memory management, etc while also finding abstractions that work nice for the model of the machine, and also have useful properties for program composition. At the moment Rust is pretty good at the former, but is lacking in the latter to some extent, which can be seen in a bunch of places in Rust's libraries. Category theory provides a great map for designing highly composable structures - it's literally about generalised composition, but we'll have to think hard about how (or if) we want to map its concepts onto Rust. It may look slightly different to Haskell, which made it's own choices in this regard (eg. `Functor` is not really a true 'functor' from CT). We'll also have to weigh up whether the changes made to satisfy Rust make this stuff even harder for people to understand.
Wow, TIL: "grok" is an actual word I've just never heard before.
Thanks, I'll check it out!
&lt;3
What about C++, which has higher-kinded types via the cleverly named template template parameters? template &lt;template &lt;typename&gt; class m&gt; struct Monad { template &lt;typename a&gt; static m&lt;a&gt; mreturn(const a&amp;); template &lt;typename a, typename b&gt; static m&lt;b&gt; mbind(const m&lt;a&gt;&amp;, m&lt;b&gt;(*)(const a&amp;)); }; template &lt;typename a&gt; struct Maybe { bool isNothing; a value; }; template &lt;&gt; struct Monad&lt;Maybe&gt; { template &lt;typename a&gt; static Maybe&lt;a&gt; mreturn(const a&amp; v) { Maybe&lt;a&gt; x; x.isNothing = false; x.value = v; return x; } template &lt;typename a, typename b&gt; static Maybe&lt;b&gt; mbind(const Maybe&lt;a&gt;&amp; action, Maybe&lt;b&gt;(*function)(const a&amp;)) { if (action.isNothing) return action; else return function(action.value); } }; &amp;#x200B;
I expect a boatload of Ada-inspired RFCs
It's dynamically typed, basically. If you want that in Rust today, you can do it with a macro. That's not what people really want out of this feature though.
Yes, I may be *slightly* over-stepping with this analogy. Your second paragraph is much more clear, and what I'm trying to say, just a lot longer.
Yeah, no worries!
In college our data structures course was taught by a professor that had worked at NASA and damn did he love Ada! To receive full credit on assignments he required us to learn and use Ada. At the time I really hated it because the resources were so sparce. But I respect the hell out of the language now! The syntax is pretty damn friendly for a systems language. For the course it makes sense to require an older, less popular language because students couldn't just Google "Ada Generic Stack Implementation" to breeze through the course. Thanks to that class I know a few of my classmates that got hired at Raytheon because of their knowledge of Ada. Good luck on learning the language man. It doesn't hold your hand much getting started, but once you get the process going it's actually pretty nice 
\&gt; What does the equal function at the beginning have to do with anything? &amp;#x200B; To bootstrap the language I wish to reuse as much as possible the functionality of what rust already give. I figure that because my lang is not scalar but operate on groups of values I could think "vectorized" ie: Apply functions to groups of values. &amp;#x200B; So, I can have a &amp;\[Value(..), Value(..),, ..\]. If I try to create a FFI for the lang, I need to reimplement a lot of functionality with Value(..) like: fn eq(a:Vec&lt;Value&gt;, b:Vec&lt;Value&gt;) -&gt; Vec&lt;Value&gt; And that lead to a lot of repetive code and pattern matching. But instead I wish to just call: //Somewhere, turn Vec&lt;Value&gt; as Vec&lt;i32&gt; then call fn equal&lt;T&gt;(left:&amp;[T], right:&amp;[T]) -&gt; Vec&lt;bool&gt; I have find I can cut a lot of code this way, and probably have more performance. But honestly, is just to be more lazy and easy to me. 
It looks like the stated feature set fits my needs well, so that's great. I'll share any constructive feedback as I use it. My project involves a custom allocator on stable which makes alignment guarantees tricky without align\_offset or siloed sub-heaps based on alignment (as best I know). &amp;#x200B; Thanks for sharing and answering.
I guess it's exactly the use case for LinkedList's drain_filter.
What constraints regarding the machine present obstacles to HKT?
https://twitter.com/withoutboats/status/1027702531361857536 is linked in the parent post, and while it's about do notation, but it's also about HKT. You may want to check it out; it's well argued. But, to be clear, it's not that "the machine can't handle HKT." It's more what your sibling said below: &gt; The real challenge is that we want to expose more of the underlying model of memory management, etc while also finding abstractions that work nice for the model of the machine, and also have useful properties for program composition. At the moment Rust is pretty good at the former, but is lacking in the latter to some extent, which can be seen in a bunch of places in Rust's libraries. Taking this view, combined with the above tweets, it's more like "in order to reduce overhead, Rust has certain APIs that use type system features in a way that makes it extremely hard to combine these things." We could have chosen overhead instead, and it would still *work*, obviously.
&gt; ...and I totally appreciate the line of thought which goes: Well, if you can't explain it in 10 lines, maybe it isn't a thing we actually need, because the use-case is too obscure. /shrug Yes. I don't think the claim is "explain to me why you want monads," it's "explain to me why you want monads *in Rust*." These are different questions.
I typically just have {file}.rs when it's a small enough module for one file. If it is a folder, i have preferred mod.rs for defining the sub modules of that, and for re-exporting. On my game project i have a {file}.rs and {file}/other.rs and it feels weird. https://github.com/agmcleod/spellcaster-sacrifice/tree/master/src screen/ and screen.rs there.
Except higher kinded of types exist entirely at compile time, and they're supported in C++ which is a pretty pragmatic language (arguably too pragmatic).
You can do what C++ does with macros in Rust. They're basically duck typed. (I said "dynamic" below but now that I think about it, "duck" is a better fit.) That's not what people mean when they say they want HKT in Rust.
&gt; Using Sized as a trait bound usually fixes it Do you have a link to an example where this problem is demonstrated and then fixed with `Sized`? I still struggle with traits and especially trait object woes, would love to read up on it more.
As it says in the title, I'm looking for feedback on the many things I must have done wrong (or at least inefficiently). Thanks! Currently I'm not planning on testing this at a larger scale, even though it should be able to handle many pong sessions at once.
I've seen it before, but like my audience, I'd been writing more applications these days, and the CS notion of abstract stack growth takes over, as you can see in the picture I drew. Let us nonbelievers from application land go on a journey! Toy function: ``` int stacker (int steps_left) { if (steps_left &gt; 0) { return 1 + stacker(steps_left - 1); } return 0; } ``` ``` 0000000000001135 &lt;stacker&gt;: 1135: 55 push %rbp 1136: 48 89 e5 mov %rsp,%rbp 1139: 48 83 ec 10 sub $0x10,%rsp 113d: 89 7d fc mov %edi,-0x4(%rbp) 1140: 83 7d fc 00 cmpl $0x0,-0x4(%rbp) 1144: 7e 12 jle 1158 &lt;stacker+0x23&gt; 1146: 8b 45 fc mov -0x4(%rbp),%eax 1149: 83 e8 01 sub $0x1,%eax 114c: 89 c7 mov %eax,%edi 114e: e8 e2 ff ff ff callq 1135 &lt;stacker&gt; 1153: 83 c0 01 add $0x1,%eax 1156: eb 05 jmp 115d &lt;stacker+0x28&gt; 1158: b8 00 00 00 00 mov $0x0,%eax 115d: c9 leaveq 115e: c3 retq 115f: 90 nop ``` # `sub $0x10,%rsp`
I think understand what you're saying -- that in rust it's different because you would have something like traits for traits. but I disagree that macros in rust give you the same effect that you have in C++. In C++ templates get instantiated where they are used. If I have a template function in C++ that takes a template parameter that itself takes a single template parameter (maybe the function take a generic container template and then proceeds to instantiated on different concrete types), when I call the function with vector, deque, etc it will be instantiated where I use it. This means it works even if it's the result of some deep invitations several layers of templating deep. To try and get the same template function with Rust macros, I would need to know ahead of time what the template is going to be instantiated with so that I could call the macro to generate versions that take the different container types. Or no?
Nope, Rust macros work the same way, and you can have macros generate macros. At least, at the high level. I'm not an expert in either, but fundamentally, it's the same idea: expand the code out, then check it.
This is especially nice because when you do a search it will show results from the standard library and your dependencies and your crate. You open a static HTML file and find a comprehensive search tailored to your crates own little universe. Rust definitely did more than the bare minimum here.
Tityt ttytt
When starting to consume the vulkano example code to build e-nguyen, one of my first attempts at breaking up the long procedure was to perform the encapsulation that I describe in the Medium post. The fact that I had self-borrows and was tacking borrowed data onto the object among other forms of evil forced me to read basically the rest of the book before it was apparent that this style of using Structs was precluded by the nature of Rust. Basically 94% of my compiler fighting before I started landing useful code without incident was because I wasn't anticipating how close to the metal the function and memory semantics are.
Well there is GraalVM - https://github.com/oracle/graal. Generally the JVM can run anything already. It is still a bit early for general adoption, but it can execute LLVM bitcode (and therefore C and Rust code) on the JVM. Performance is good, but it still rough around the edges. LLVM for JVM https://github.com/oracle/graal/tree/master/sulong Implementing WASI on top of that should be possible.
This is pedantry, but to make the ‚Äúsafe rust is known to be sound‚Äù claim, we need memory model. Sound here means ‚Äúif program passes static checks, its dynamic behavior on every input does not cause UB‚Äù, and dynamic behavior/UB definitions are basically memory model. Or, at least this is my understanding of the terms, please correct me if I am wrong :)
I dunno; strikes me a bit like Greenspun's Tenth Rule, but replacing Lisp with Forth.
I'm pretty sure that the [RustBelt paper](https://plv.mpi-sws.org/rustbelt/popl18/) (mostly) proves safe Rust is sound. (Thus the "some restrictions apply".) Safe Rust actually has an (informal) memory semantics in how owned, `&amp;`, and `&amp;mut` work. (`UnsafeCell requires `unsafe`.) It's unsafe Rust that is the big open question in what the runtime allows that isn't just purely doable in only safe Rust. (If safe Rust is sound, that roughly means that any valid purely safe `#[no_core]` program cannot exhibit UB, but `core` and `std` have `unsafe` implementation details which mean they aren't entirely covered by that claim.)
Yes, GraalVM is super cool. It's not really the same thing, though- LLVM IR is not a stable format the way WebAssembly is, and there's no clear interface to the host like WebAssembly's. A WebAssembly implementation on GraalVM/Truffle would be really neat, letting you embed it in the JVM the way it can currently be embedded in the browser or a native app.
Ada rationale is a huge set of documents. It in itself helps to understand why Ada capabilities appeared the way they did. They appeared as many different terms in a language. So many terms 300+ in fact it becomes unwieldy and you start to prefer certain terms over others for the sake of convenience and limiting it to a practical subset in other words like a Java full language versus only using a subset like JavaCard to do everything. Another example: Ada vs Ravenscar. Anyways golang and rust have a much smaller set of terms in the language. That is the reason they will succeed over Ada. Rust certainly feels like the new Ada. I'm finding Rust is already practical with its apis for web which is basically everything you need. I'm not impressed with 32-bit wasm when it should be 64-bit from the get-go. Apart from that though, rust is awesome for everything except GUI where developers have to resort to other languages/tools to glue it in. It's the same problem as Ada. No different. The only thing I would recommend is to keep the rust book list short. keep the rust book page count short and provide the most awesome search engine for practical code snippets you can use in common situations. I think crates.io is close to that, but google pops up nice blog articles about rust in different scenarios that have been very useful. If you invest your efforts in Ada, it will only help you to appreciate Rust even more for what you can accomplish with it without reading thousands of pages of Ada.
Okay, that makes slightly more sense. Sounds like they're kinda like promises in certain languages like JS (or I guess promises are some variety or bastardization of monads?), which also have methods for "do your thing, then call this other thing with the result". Or pipes in shell languages (and some non-shell languages like Julia/Elixir/F#). Still don't really know what a "functor" actually is or how it's distinct from any function, nor do I really know what "higher-kinded types" are (are they just types with types?). Most explanations for these sorts of things boil down to either weird analogies about burrito manufacturing or throwing a bunch of Haskell in my face and expecting me to know what to do with it ;)
I understand that rust macros can contain macros, but I still don't think that would work here. Say in C++ I write: void f() { myfunc&lt;std::vector&gt;(); } If I try to write the same thing with a macro implementation of myfunc in rust, as I understand it it can at best expand into a definition of myfunc at the call site and then invoke it -- but to be equivalent the definition should be outside f(). So you can't at the call site cause it to be inside an impl/trait/etc.
Looking forward to it. :) Miri also has some limitations around alignment tests though, because it doesn't actually pick a base address for allocations -- it keeps them symbolic. If program execution ever depends on what the base address is, Miri has to stop. I have ideas for how to fix this but not enough clones of myself to implement them. ;) This might or might not be a problem for you, I guess we'll see.
The typical counterpoint is that the function you really want is normally fn half_evens(elems: impl IntoIterator&lt;Item = u32&gt;) -&gt; impl Iterator&lt;Item = u32&gt; { elems.into_iter().flat_map(|e| half_even(e)) } 
Even if the author thinks they know what the size of a trait is, there might be other types of unknown size eventually made into instances of that trait. A trait represents an unbounded number of types.
I adjusted the semantics and ended up with "upstream" and "downstream" since "parent" &amp; "child" were forcing me to say "into the stack child frame" to avoid ambiguity around there still only being one stack. Thanks for pointing out the upgrade opportunity! 
Ah, good point. You don't need `Debug`, since you can `assert!` instead of `assert_eq!`. But you might need `PartialEq` for testing purposes, in which case you should probably derive it.
Ah, you may be right on this. As I said, my exact macro knowlege is weak. Maybe as a procedural macro?
I'm sorry, is there maybe a version of that post without the disproportionately large screenshots of the code?
It would be a lot easier to fix that straightforward, well-understood issue than to work from scratch instead.
I think examples are what's usually lacking when folks attempt to answer "What is a monad?" or "Why do we need/want monads?".
Well, not much there. Are there too many open RFCs for the language team to keep up?
Is delegation RFC close to completion? Looks like it was the blocker for the above.
[https://doc.rust-lang.org/nightly/edition-guide/rust-2018/module-system/path-clarity.html#no-more-modrs](https://doc.rust-lang.org/nightly/edition-guide/rust-2018/module-system/path-clarity.html#no-more-modrs) in rust-2018 they said you don't need mod.rs in over 95% of scenarios, but I don't get how to make it work without it.
Promises/futures can also be *a* monad ([JS's native ones aren't exactly](https://stackoverflow.com/questions/45712106/why-are-promises-monads)). You need to be thinking of *traits* (/typeclasses), the whole point is that these abstractions are *common* interfaces implemented by multiple things. Option is-a Monad, Result is-a Monad, Promise is-a Monad, [List is-a Monad](https://en.wikibooks.org/wiki/Haskell/Understanding_monads/List)‚Ä¶ &gt; Still don't really know what a "functor" actually is As I just said, &gt; the "can be mapped over" trait so literally just this (in fake "if Rust had HKT" syntax): trait Functor { fn map&lt;A,B&gt;(&amp;self, f: |&amp;A| -&gt; B) -&gt; Self&lt;B&gt;; } There's also Applicative in between Functor and Monad: trait Applicative { fn app&lt;A,B&gt;(&amp;self, f: Self&lt;|&amp;A| -&gt; B&gt;) -&gt; Self&lt;B&gt;; }
As described in the RFC I believe that two proposals are orthogonal to each other. And I don't agree about "main blocker", citing aturon: &gt;Would be good to revisit after Rust 2018 ships!
A monad really is less of a *thing* so much as it's just a common pattern that's useful in so many different situations.
Confirming that, we are officially working on a WASI integration in Wasmer. We are tracking the progress in this issue: [https://github.com/wasmerio/wasmer/issues/297](https://github.com/wasmerio/wasmer/issues/297) &amp;#x200B; News to come soon!
&gt;Sounds like they're kinda like promises in certain languages like JS (or I guess promises are some variety or bastardization of monads?), Promises aren't really a bastardization of monads so much as they simply are a monad. Async/await is little more than do notation specialized to promises/futures. Monads aren't really a *thing* so much as a common pattern. One of the many things they do is abstract imperative control flow into a declarative form.
&gt;"What is a monad?" A pattern, not a thing. &gt;"Why do we need/want monads?" Abstraction.
&gt; You need to be thinking of *traits* (/typeclasses), the whole point is that these abstractions are *common* interfaces implemented by multiple things. Option is-a Monad, Result is-a Monad, Promise is-a Monad, [List is-a Monad](https://en.wikibooks.org/wiki/Haskell/Understanding_monads/List)‚Ä¶ Ohhhhh okay. I think I'm starting to get where they'd be useful. Not yet at the point where I can put it into my own words, but the gears are turning. So if functors are just things that can be mapped over... well, just about anything can be mapped over, no? Maybe I'm just not understanding that fake HKT syntax. Or wait, is "functor" just another word for "iterable"? Or maybe iterables are a kind of functor?
If monads become a key part of using Rust or some part of stdlib, then Rust will never be a mainstream language. It's difficult for people close to these things to appreciate that 95% of programmers do not, will never, and should never need to understand monads. The cognitive burden is far too high for any benefit.
I like both Rust and Ada, and am comfortable programming in either. I agree that Ada has a lot of "terms" (I would call them "concepts", I think). But beyond that I think you've made some odd characterizations about the language, and how it relates to Rust. First, the programming language space is not a zero-sum game. Rust is never going to "succeed over" anything -- it's will succeed, yes, but on its own terms, and its success doesn't mean the failure of another language. (By that metric, both languages would be failures, and the only success story in the world would be PHP.) Second, while Ada certainly does have a lot of terms/concepts in it, Rust is not exactly the poster-child of minimal-concept languages. Borrow checks, lifetimes, traits, safe vs. unsafe, the crate model, etc. -- all of these concepts have a high cognitive load, and a competent Rust programmer needs to absorb them all before making good progress. Ada is no different in this regard. At the same time, it's also true in both languages that you can be quite productive without learning or wrestling with each and every concept. E.g., you don't have to write crates, or unsafe code, to write your first successful Rust program; and you don't need to tackle the Ada package system or all the features in its type system in order to write your first successful Ada program. (To Ada's credit, most of the complex type mechanisms are pay-as-you-go. If you need a simple record type, it's trivial to make; and later if you need an interface/trait type that can be implemented using tagged types, tasks, or protected types, the language affords you ways to evolve your code in that direction. ) Re: "thousands of pages" -- I've probably written about as much Ada as I have Rust, and I don't think I've read any more or fewer pages about one language than the other. I don't think the beginner's story is really that different for either language (with the exception that Rust has excellent, free instructional docs -- I certainly agree about the benefits of this!). Neither language is much harder to learn than, e.g., C# or Java in my opinion. Enjoy Rust, and make great things; or enjoy Ada, and make great things. Better yet, do both! I hope we can encourage people to discover these great tools for themselves. There's no need to scare anyone away from Ada -- their dalliances with another language aren't going to erode the Rust community in any way. Quite the opposite: the cross-fertilization of ideas can only make things better. 
FWIW it might be helpful to write `Use the mouse in the menu. To control player 1, use W, A and D. To control player 2, use the arrow keys.` on the game page