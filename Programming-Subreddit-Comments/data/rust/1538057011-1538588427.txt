No, it copies only the *mutable* fields.
Our namespace has effectively infinite cardinality
https://rustwasm.github.io/wasm-bindgen/reference/js-promises-and-rust-futures.html You can bridge promises and futures 0.1 today. Once futures 0.3 is stable (the version used for async await AIUI) we will update to that version of futures
Just squat all names, then redistribute them with squat protection ;)
I'd like to remove an unnecessary clone from the following code that I'm writing for a Simplex solver (using the ndarray crate). In this code, I'm having to copy pivoting\_row in order to subtract it from all of the other rows in the matrix. Any thoughts? Also, any simple way to use SIMD operations on the Zipped function? fn do_pivot(tableau:&amp;mut Matrix, pivot:&amp;Pivot) { // normalize the pivoting row let mut pivoting_row = tableau.subview_mut(Axis(0), pivot.row); pivoting_row /= pivoting_row[pivot.col]; // own the pivoting_row so that tableau can be // mutably borrowed below. This causes an // unnecessary copy that I would like to remove. let pivoting_row = pivoting_row.to_owned(); // subtract the pivot row from all other rows for (i, mut row) in tableau.outer_iter_mut().enumerate() { if i != pivot.row { let multiplier = row[pivot.col]; Zip::from(&amp;mut r) .and(&amp;pivoting_row) .apply(|w, &amp;x| {*w -= multiplier*x}); } } } &amp;#x200B;
adding \`#\[allow(dead\_code)\]\` remove the warning, but it feel hacky...
You can write a procedural macro that does this, but it is often cheaper to recompile something than to look up a cached value in a globally shared hash table (pointer indirections, locking, atom is, can easily take O(1000-10000) ns, that’s a lot of computing power).
it is probably limited by the max url string length browsers accept, wich is between 2000 and 8000 characters.
Be DESCRIPTIVE!. Be, Be DESCRIPTIVE!
Don't fear any other number either.
Yeah, definitely seems like a bug.
Ok, but this still need to make the bin_op generic. meaning a duplication of the function by the compiler. 
Their way of working with (im-)mutability is interesting and relevant to Rust developers in terms of how to think about these concepts. They flag how and where values are assigned to, see e.g. here: [http://skiplang.com/docs/lvalues.html](http://skiplang.com/docs/lvalues.html)
&gt;Wrong. It doesn't guarantee that they will be compatible, not guarantee that they're incompatible. There is a difference. It's so clear that's what OP meant. That's how I read it. If you can't guarantee they're compatible, they're incompatible. No, it doesn't "guarantee" they're not compatible, but... this is so anti-charitable to what the OP meant that it's basically wrong. The whole point of semvar in this context is to be automatic. Also, "why did you even write this, if you're not gonna do any of the work?" is such a toxic attitude to have. You can ask for discussion or requests without doing it yourself. Also, OP might have what they think is a good idea, but not be able to defend it as rigorously as someone else, but that's not just "not gonna do the work", that's reasonably understand your technical limits - something we should all strive for. 
Sorry about not following/carefully reading the rules.
&gt; You'd need to either specify more concretely that TMath is a trait that has an &gt; add(T, T) -&gt; T How? the compiler reject fn add1&lt;T: TMath&gt;(x: T, y: T) -&gt; T { let r = x + y; r ^ expected type parameter, found associated type }
You can also go with the immutable default by not marking your class as \`mutable\` (which was done in this example). I think the mutability choices are not super different from Rust, what I find interesting is that they use this for memoization and that they have this neat syntax for specifying what you are "mutating" (with the \`!\`, see [http://skiplang.com/docs/lvalues.html](http://skiplang.com/docs/lvalues.html)).
I'd like to parse javascript and have the ast linked to the source string (like line numbers and column number) - does such a crate exist? I've been finding lots of dead projects on GitHub. It'd be really awesome if it could parse typescript too.
What's "Advent of Code"?
All of what you said would be true if we'd never had had this conversation before. That is not the case, as he himself admits this (the recurring conversation on versioning). That is exactly why I wrote what I wrote - too many people keep going in a loop about this and not doing anything about it. Please, stop the circlejerk of hypotheticals and actually present a solution. Talk is cheap. Show me the code.
&gt; and is actually compatible with the spec Is it? The [cargo guide]() says: &gt; This compatibility convention is different from SemVer in the way it treats versions before `1.0.0`. While SemVer says there is no compatibility before `1.0.0`, Cargo considers `0.x.y` to be compatible with `0.x.z`, where `y ≥ z` and `x &gt; 0`. But regardless of this technicality of major version 0, I also think if the rust community could agree (and write in the spec) on when a crate is expected to go from version 0.x to version 1.0, that would be a good thing. The Rust blog has multiple times ([1](https://blog.rust-lang.org/2017/05/05/libz-blitz.html), [2](https://blog.rust-lang.org/2018/03/12/roadmap.html)) referred to pushing libraries to "1.0 status". What is this "1.0 status"? What does that mean? That's what we should write in the spec.
I think there's a number of nursery libraries in use (log, futures, libc, error-chain) which haven't reached 1.0 yet. Since other libraries depend on them, it's hard to justify a 1.0, since a change in those libraries may require adjustment to your own library. And those libraries probably won't reach 1.0 till some other changes to rust itself are available (pin, task, GAT, etc.)
&gt; Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable. The spec does not use RFC 2119 language here. And if it did, it would be MAY. Being “more stable” in some sense, is acceptable, according to the spec. &gt; 1.0... what does that mean? It means “releasing a 1.0.0 version.”
I don't know about doing the visuals in rust (should be fine as long as it's simple, though), but communicating with other languages should be (relatively) easy! Rust "speaks" the C ABI, which is kind of the gold standard in inter-language communication, I guess.
Hello Everyone, fairly new Rustacean here. I've been through the tutorials and a few other materials. I still struggle with things like the Borrow Checker and Ownership system on a daily basis but I'm slowly working out the kinks. I've written a command line application for doing some very simple money management. I'd appreciate it if some people could check it out and give some critiques and recommendations. I'm sure there are many situations where I've tried to do one thing when Rust would prefer I do something else to achieve the desired result. Currently when you run the program it will create an empty config file in a fund directory in your system's config directory. The config file currently doesn't do anything, as a result neither does the command line flag for supplying a config file. This is the next thing I plan on working on. It will also create a file called \`.fund\` in your home directory. Please feel free to leave any critiques here or in a new issue on Gitlab (preferably the latter).
Because1 there1 is1 an1 endless1 supply1 of1 titles1 for1 crates1 and1 you1 can't1 squat1 them1 all111one.
&gt; If you can’t guarantee they’re compatible, they’re incompatible. This is not how spec language works. This kind of implication is not actually valid in this context.
Sorry, you can't use that wording, it's already taken. But if you really want to, here are contact details, maybe you can make a deal.
I might be missing something, but if semver says "going from 0.1.0 to 0.1.1 can break everything" and people read that cargo/crates.io follows semver they might just do that. But the ecosystem will actually consider them to be declared compatible. So, something seems out of alignment there.
\#MeToo on the same question. 
Can you link their arguments please? So far the best two arguments I've come across are "flat namespace promotes creativity when naming crates" and "the current system works fine - why change?", and I find both to be dubious.
Sorry, you didn't get the reference. It's a phrase (I think Torvalds was the one to coin it) meaning exactly what I said prior to the phrase - a lot of talk doesn't lead to anything actually getting done, work does.
Read [The Rust Programming Language](https://doc.rust-lang.org/book/). Then read [Programming Rust](http://shop.oreilly.com/product/0636920040385.do). 
Okay, well tell me (and the OP) what you want. You're just using a meaningless phrase to say what you want. Talk is cheap. Show me the code. If you're not willing to say and defend what you want from the community, etc etc -- get it? I'm making fun of you. 
In theory, that could happen. In practice, this is not how people think about version numbers, which is why this situation happened in the first place, long before Cargo existed. That is, this additional semantic was developed by observing how people actually used version numbers in the real world. 
Well with flat namespacing we can have `swmon-bash`, `ar-pharazon-bash` and `KindaAgrees-bash`. Why add more complexity to the system? 
I'm saying, come back with a draft of an actual spec you're trying to propose and let's have a conversation then. OP, however, already said he is unwilling to write that spec, because " github RFC about it will presumably get a million comments". I don't know what it is that you're making fun of here, as you can't seem to keep a trail of a conversation that is in writing.
Wait, you're saying it's impossible for people to misunderstand? Are you suggesting that the Rust interpretation of semver is the one everyone actually uses instead of whats written down?
\&gt; Thanks to Skip's tracking of side effects the garbage collector only has to scan memory reachable from the root of a computation. \*In practical terms, this means that developers can write code with predictable GC overhead.\* I would love to better understand how this works.
Yes. Community Editions of Idea and PyCharm support Rust plugin, and they are all open source projects as well. Integration with LLDB/GDB works only in CLion(which contains the relevant code for interfacing with debugggers). CLion does not have community version, but you can use Early Acess Program builds which are free, but time limited: https://www.jetbrains.com/clion/nextversion/. If you don’t have existing JetBrains IDE installed, I suggest starting with IntelliJ Community.
Sure, I agree that having something in place would calm some nerves. But to answer your question: --- Because it is not clear what a 'disaster' would be or what a 'fix' would be. The only certainty is that it takes time and effort to implement and maintain it. So the wait is for someone to define both, and make a case for the cost-benefit. --- To put a 'disaster' in context. There are 18,782 crates in stock at time of writing. There are ~170.000 English words in the Oxford English dictionary and ~500.000 unique 4 letter combinations. 
I think the confusion was about 'we', not 'this', in &gt; when we just started talking about this ;)
&gt; Being “more stable” in some sense, is acceptable, according to the spec. Yes, people writing libraries can be "more stable" than the spec requires. But package systems like cargo and npm can not assume that people do that. I can make crate, make it versoin `0.1.0`, upload it to crates.io, get a lot of people to depend on it, then make a breaking change and release it as `0.1.1`, which is allowed according to semver, but it would break everyone's code when they run `cargo update`. &gt; It means “releasing a 1.0.0 version.” The spec has this to say: [...] That’s it. I get the feeling that, to a lot of people, version 1.0.0 means a lot more than that. That it also carries with it a statement of usability and production-readiness. And a pretty strong one at that, because again, 15 of the 20 most-downloaded crates on crates.io feel like they haven't reached the level of "1.0 status" yet. I mean look at the version numbers of some of those crates in that top 20. libc is at version `0.2.43`, rustc-serialize is at `0.3.24`, time is at `0.1.40`. These version numbers indicate that the APIs are stable. The reason that the authors are not releasing version `1.0` has to be something other than API stability. Also from that same [rust blog post](https://blog.rust-lang.org/2017/05/05/libz-blitz.html): &gt; “1.0” status (in terms of quality and API stability, as well as literal version number) So there you have it black on white: yes, version 1.0 is about API stability and literal version number, but *also* about quality.
If you don't want to read any discussion on it til there's a final spec in front of you, that's fine! Very reasonable. However, don't complain anytime someone posts something about it. Just don't read it; this isn't for you, OP isn't claiming they figured everything out. They're asking questions and getting information. I'm not even saying that OP is putting forth anything new; I'm sure it's been done before. But you're on reddit, not some technical conference. Other people have the same questions as OP, and will get the same feedback OP does.
There is another one: having namespace doesn't add anything to the problem of squatting (if `OneCrateName` you like is already taken, nothing prevents you to register `KindaAgrees-OneCrateName`), it just makes it more difficult to find the package you want : you've heard about a crate called `FooBar` but, is that `UserOne/FooBar` or `AnotherUser/FooBar` or `FooBar/FooBar` ? The Java ecosystem uses namespaces, and prefixing my imports with `com.sun.java.[…]` isn't really something I miss …
Of course not, don’t be ridiculous.
If I want to make a family of crates, then I can start off xyz-base xyz-this xyz-that, and then someone else can come along and grab all the common xyz-* names! Then I assuming I want to stick to simple names, I'm blocked. So the only solution is to grab as many xyz-* names as I can think of before I start, just in case. Whereas with namespaces, I could just get 'xyz', and then I can name the crates as I wish, no stress.
Then I don't understand...
“most people act this way” does not mean “it is impossible for any person to act differently”
\&gt;If you don't want to read any discussion on it til there's a final spec in front of you, that's fine! Read what I said again. I said draft. \&gt;However, don't complain anytime someone posts something about it. Just don't read it; this isn't for you, OP isn't claiming they figured everything out. They're asking questions and getting information. Again, what I said was - we've had this conversation repeatedly and regularly. I don't see how asking it AGAIN is helping anything. And OP himself admits that he is aware of this. \&gt;I'm not even saying that OP is putting forth anything new; I'm sure it's been done before. Use the search feature, please. And again, OP is aware of all of these points and has previously stated so. \&gt;But you're on reddit, not some technical conference. What are you saying? Are we having a "reddit conversation" or a technical conversation on a forum about on a technical subject - a programming language and it's ecosystem?
Possible solution: crates with names of less than 8 characters cost 0.0001 BTC per character less than 8.
"Just use the search feature" is kinda silly. It's not just about OP answering their question, but new people seeing it. I'm shit at rust. I have no problem with people asking questions like this, because I get thinking about stuff I wouldn't normally. Also, c'mon, the search feature is shit you get tons of old discussions, and there's always new stuff to add. And if you don't see how having this conversation is helping, then I'm sorry? It might not be helping you, but that doesn't mean it's not helping anyone.
Given the new requirements I think I'd just use a for loop. r/https://play.rust-lang.org/?gist=73763ed16ac759540b9962a97cd48a6c&amp;version=stable&amp;mode=debug&amp;edition=2015
Wow dude, that's clean code! I appreciate your work! Thanks!
Sure, but the argument wasn't "most people think that way and that's good enough". You said it's how it works in the real world. *I* know about the adjustment, don't really care, but still remember a non-zero amount of clarifying discussions about the differences in different places, e.g. HN where people with non-Rust experience come into the mix. Just using a term like "Adjusted SemVer" or "Extended SemVer" or whatever seems like it could have a clarifying effect. Like it was said, a user finding compatibility where he didn't expect it is not harmed. It's just when releasing crates that you have to be aware of the differences. It also only comes into relevance on the second release you make, so it might have been a while since you read the crates.io guides. Having that mention "Adjusted SemVer" or "Semantic Crate Versions" instead of just "SemVer" and linking to something that says "SemVer with these additions, because X" might be enough to cound as solution. Like I said, I'm not really bothered personally. It's just that I can see where OP is coming from.
Interesting. The warning appears because `V` is never used explicitly as a type, only implicitly via `self`. Adding `: V` to any of the `vec!` declarations is sufficient to suppress it. Definitely report a bug.
Huh? When did I "back down"? Is this a fight? Why are you absurdly hostile? 
But let's say KindaAgrees always names his/her crates like that and gets a good reputation. But there's nothing to stop someone else creating crates with the same prefix. So trying to create an identity using prefixes is too dangerous, because anyone can hijack it. So a flat namespace forces you to try and grab top-level names for things, and discourages organizing crates into families.
Welcome! First, you're already returning a boxed error. Why unwrap on opening the config and home directory? It's trivial to just return an IO error instead. Second, that's an interesting match. But the _ option is definitely not unreachable. Invalid input will panic your program. You should return an error there as well. You could also convert it to an enum upon input so that you know you're working with valid input and don't have to have error checking in your lib. This: let goal = if goal.is_some() { Some(goal.unwrap().parse::&lt;f64&gt;()?) } else { None }; Can be written as: let goal = goal.map_or(None, |x| x.parse::&lt;f64&gt;())?; I'm fairly certain you can get rid of a lot of the clones in the run function. Play around with the borrow checker some more :) [Don't record money as a f64](https://stackoverflow.com/questions/3730019/why-not-use-double-or-float-to-represent-currency). Store pennies and convert to dollars on display. This is one of the mortal sins of programming in general. get_by_name could be simplified by the 'contains' function. TYPICALLY, instead of a 'print_all' function, you'd wrap the type and implement std::fmt::Display. It's fine here, just a small thing you could change later if you wanted to Your load function unwraps and panics on a parser error. Should return a result instead. That should keep you busy for another day or so ;) Hope you've enjoyed experimenting with our beloved language!
&gt; Sure, but the argument wasn't "most people think that way and that's good enough". You said it's how it works in the real world. What I meant by "how it works in the real world" is "most people think that way." What understanding do you have of the history of SemVer, as a spec, and as implementations? Maybe that's the big disconnect here. 
&gt; But package systems like cargo and npm can not assume that people do that. They can, and they do, because they define how this works. It's how all major semver implementations actually work. &gt; I can make crate, make it versoin 0.1.0, upload it to crates.io, get a lot of people to depend on it, then make a breaking change and release it as 0.1.1, which is allowed according to semver, but it would break everyone's code when they run cargo update. You *can*, but then people won't use your library, as you cause them to break all the time. In practice this means that libraries that do this don't get used as much as ones that do. &gt; I get the feeling that, to a lot of people, version 1.0.0 means a lot more than that. I don't disagree, but you can't simultaneously make an argument that Cargo does not follow the letter of the spec, and that's bad, while also saying that Cargo does follow the spec, and that's bad. Or rather, I don't find such a set of arguments particularly compelling :) &gt; The reason that the authors are not releasing version 1.0 has to be something other than API stability. You're right! * `libc` is waiting because, due to only being able to use one version in a program, major version releases have huge costs. 0.1 to 0.2 was really brutal. It will eventually release a 1.0, but they have to be *really* sure that there won't be a 2.0, as the ecosystem simply can't take it. * `rustc-serialize` and `time` are both abandoned. 
One thing that comes to mind is gtk + cairo. See https://github.com/gtk-rs/examples/blob/master/src/bin/cairotest.rs for a basic example and http://gtk-rs.org/ for documentation.
You appear more dense by the post. To spoon-feed you - your arguments are absurd. \&gt; "Just use the search feature" is kinda silly. How is it "silly"? If you're bringing up a conversation on a medium that has a record of all previous conversations, why WOULDN'T you see if it's been discussed previously and derived at a conclusion? That's laziness, not humor. \&gt; Also, c'mon, the search feature is shit you get tons of old discussions, and there's always new stuff to add. What did you expect it would give you - future discussions? Suggestions for new topics? If there is something new to add, then you... write an RFC (to decipher that one for you, RFC stands for "REQUEST FOR COMMENTS (for the proposal I have come up with and require external input to refine further)"). OP explicitly stated he is UNWILLING to do so, BECAUSE IT WOULD RECEIVE COMMENTS. \&gt; Why are you absurdly hostile? You're misinterpreting the situation. I'm simply being bluntly honest about the fact that WE, AS A PEOPLE, HAVE ALREADY DONE THIS WORK IN THE PAST, and you are ACTIVELY UNWILLING to learn from our past experiences, instead opting to go in a circle WITHOUT ACTUALLY CONTRIBUTING TO A SOLUTION TO WHAT YOU CONSIDER TO BE A PROBLEM. And the reason why you see in my post history that that is the case is because I consider it an insult to everyone who has previously contributed effort and time that is rendered pointless by you simply being lazy and unimaginative.
Personally? I understood SemVer to be a codification of common usage of "N.X.Y" version relations, with "0.X.Y" being "design phase free-for-all". When I found out about cargo's concern for "0.X.Y" compatibility I thought "nice, makes sense". But it's still good to be aware of it. I followed it when SemVer first started catching on, but at that point I was just happy someone is working on doing away with custom invented versioning schemes where you have to reread library documentation for every upgrade. If I only read SemVer (and not been here from before Rust 1.0) I might assume my "0.1.1" can have a totally different API than "0.1.0" and give people using it unnecessary grief instead of just going to "0.2.0" until someone points it out.
They're still streets ahead of HDDs. I've recently gone in a spate of upgrading friends and family to SSDs, and the difference is remarkable. They go from being slow doing things as basic as opening the start menu to pretty much never being noticably slow.
Thanks, these are good critiques. As for the second one by invalid input you mean command line arguments right? As I understand it, clap handles that before it even gets to that match statement, I think somewhere in the \`get\_matches()\` function. If I try to run the program with an invalid subcommand, it prints an error and quits the program. For example: $ fund display error: Found argument 'display' which wasn't expected, or isn't valid in this context USAGE: fund [FLAGS] [OPTIONS] [SUBCOMMAND] For more information try --help Or am I misunderstanding? Thanks again, I'll definitely be working on those other issues :)
How do I parameterize everything that uses Server over its lifetime? Do I need to add a new generic function that takes in a 'server? I'm still at the bottom of the lifetime cliff, so don't really understand what is going on with these annotations. The only place where the contents of the box should be destroyed or replaced is in this function, when resetting the callback. Looking at the code, I realized that I was potentially overriding the contents of a previous box before giving c a new callback pointer to use. I'm also not stopping C from using this pointer when this struct drops. Is this what you mean? I'm not sure what to do if somehow setting the callback fails from C. I didn't know about the move keyword in closures, so will read up more on what it does.
Ah, good call. Forgot about clap. 
Thank you. I'm trying to convert the script to rust. Guess my case is not needed Tokio timer perhaps. &amp;#x200B; I have another concern though. When the user copies multiple files to the folder. The script read changes in the folder then will spam threads. Example if user copy 10 files. I think I will spam 10 threads to do the job \`checkFileCopyComplete\` then do something after the file is copied. So if I do that, is any drawback by spawning too many threads? Or If there is another way to do that. Cuz, as I read that thread, is more expensive than green thread or like goroutine. In nodejs I just use promise, callback to do the job and don't care about the consequence. Just let the event loop do the job. Rust is my first time learning a low-level language. So dealing with these problems in low-level languages is not my case. &amp;#x200B; Thank you.
yikes 
I'm not sure I have much to add to this, since I only have experience programming Rust on macOS, but I do want to say that one tool I find indispensable when programming Rust is [Dash](https://kapeli.com/dash). Especially when learning Rust, having easy access to the full documentation for the standard library that I can bring up, search quickly and hide with a single keyboard shortcut has greatly aided my learning and I still use it constantly since rls is so frequently unable to determine the type signatures of the functions I'm calling. There is a Windows/Linux alternative ([Zeal](https://zealdocs.org/)), but I've never used it. If you are considering Linux, I'd try to find a way to try it out to see how well it works for you and if you end up going with a Mac, I definitely recommend trying Dash.
Thanks I'll get it tonight!
You'd be surprised - naively sticking that code into the playground, turning on release mode and hitting "ASM" shows that no instances of `bin_op` survive the optimiser (not even one generic-ized one). Rust and LLVM are **very** good at compiling high-level code down to cheap minimal assembler.
Thanks, I'll give that a look!
It's `Ctrl+Shift+Up/Down` on Linux/Windows. Also, you can just press \`cmd+shift+A\` (or \`Ctrl+Shift+A\`) and find any action by its name!
I’ve had zero issues with Rust on macOS
Okay, so, Semver was published in 2009 by Tom Preston-Werner of GitHub. The same year (though I don't remember the months of these two events), Bundler was created by Yehuda Katz. Both coming out of Ruby, the Ruby world adopted this stuff pretty wholesale, and fairly quickly. Bundler developed version ranges as a way of helping you work with semver to automatically update where possible. These ranges were not (and still are not) in the actual spec, so their semantics had to be invented. At first, they literally followed the spec with regards to pre-1.0 versions. You're not wrong that Semver was trying to codify existing practice. However, as people adopted these tools, the "pre-1.0" behavior was a problem. People wanted a way to iterate on their projects before a 1.0 release. This is due to the exact arguments made elsewhere in the thread; people feel that version 1.0.0 means something different than what semver says it means. People were, in practice, doing what Cargo does today; treating the `y` version as a major number, and `v` as a patch number. And so Bundler changed its semantics to respect this. As adoption of SemVer grew outside of Ruby, and people made bundler-like tools, they emulated this behavior. Notably, npm came along in January of 2010, and it did as well. However, people weren't happy for the same reasons mentioned in the other thread about "Don't be afraid of 1.0"; tons of stuff people relied upon was still at major version zero. Which is weird. After a few years npm decided to clean its hands of this and make `npm init` generate a 1.0.0 version number. We talked about maybe doing this with Cargo, but it was a bit controversial. So, when I say "in the real world", what I mean is, these tools and the spec were developed pretty closely with one another, but the spec was developed first. The tools came later. The tools changed in accordance with how people actually acted with regards to these things. The spec, however, hasn't changed. Part of this is because it's been semi-abandoned for a long time. Part of it is because it didn't really matter; the major implementations have this behavior, and so it's a de-facto part of the spec at this point. It's unfortunate that ranges are not in the spec, and that this particular corner has not yet been updated. But in practice, it's worked this way for virtually the entire history of the spec existing, almost a decade. If Cargo broke with this tradition, it would be the one causing unexpected behavior, generally. Does that all make sense?
&gt; (if you care about the one bit) That's kind of the point of this exercise :P If I drop your solution in [godbolt](https://godbolt.org/z/x_bzN8) it shows that it does optimize to a single addition. However this feels like the kind of solution you need to make due to a lack of support from the language, like the way you implement bitwise rotates with shifts in C or stupidly hard it is to do checked signed arithmetic in C. One way I've hit this problem was when creating 'pseudo' pointers (basically wrapping an unsigned integer) for use in some abstraction. Pointer offsetting needs an 'unsigned pointer' + 'signed offset' operation and I ended up just wrapping_add'ing it. I'll consider this instead.
yeah, OP updated post to reflect the right meaning. I thought it was clear what was meant, but deleted mine to avoid misinformation. (of course you're right) 
(Making a new comment instead of editing my first one for the sake of notifying the OP:) I tried to file an LLVM bug and eventually found an existing (four-year-old :/) report, which I commented on: https://bugs.llvm.org/show_bug.cgi?id=20511 In general, although I sympathize with your hatred of AT&amp;T syntax, it's likely to be better tested in LLVM, since LLVM has traditionally been a Unix compiler and most Unix code uses AT&amp;T syntax. That said, LLVM has recently been moving towards first-class Windows support, so maybe things will improve in the future...
It’s cool &lt;3
To be fair, the Skip GC has predictable performance characteristics. So it's not like most GCs you've used before.
1. why not just default to the same as the `("", None)` case instead of unreachable? 2. using structopt you'd get an enum (or possibly a None if you made subcommands optionals) and wouldn't have to deal with matching on literal strings.
I'm biased, but my take is "don't split your monolithic megacrate into smaller ones unless it actually gets you something useful". Namely, either the subcrates are realistically useful to external users without depending on each other or they are performing platform-specific tasks (ie you have a module, and one subcrate implements it on Linux and another implements it on Windows). Or, you know, if you really want to. But I see so many people making their lives more painful for no reason by doing this and I don't understand it. Other than that, it does sound like a task that a Cargo plugin should solve.
I have a related question: is there some way to find dependencies that have new major (semver-incompatible) releases?
Have you tried running clippy?
Yeah but prematurely optimizing can lead to bad architecture. :-P This is why programming is a craft, not a science.
I'm not aware of an automated method, but you should be able to just look at the Cargo.toml and the lib.rs for each crate, and just check the extern crate definitions.
Heck yes! My long-shot goal is to be able to do something similar :)
Agreed. When I first started learning Rust, I tried contributing to Servo and Parity, the two biggest Rust projects at the time (and most likely still are the biggest). I was surprised that maintainers of both projects were willing to hold my hand through trivial pull requests, and even more surprised that I was able to make nontrivial changes after not very long.
That sounds like a good idea! I think some of the other issues /u/usernamedottxt described are worth doing first, but I'll definitely add this to the list and continue investigating it.
Huh; How is this new and notably different than say what Haskell does to distinguish with pure computations and side-effectful ones (with the `IO` monad)? Haskell's runtime should be able to do the same sort of memorization of pure computations with call by need evaluation.
Don't think there's any way to do this without unsafe - rustc would have to know that your use of `tableau.outer_iter_mut()` will never mutate the row that `pivoting_row` references, despite the fact that it totally can. You'd need something like slice's `split_at_mut`, which requires unsafe. You can just do it directly with unsafe by casting pivoting_row to a `*const _`.
Hey! Yes they were described in the same paper and you're right, I should have clarified. QSense is a hybrid system which switches between Epoch and Cadence (A modified Hazard Pointers system). I feel like Cadence is a clever enough system to be mentioned in its own right. I love how it gets around the memory barrier problem by using the context of the process.
I think that you should not worry too much. As your experience grows, you'll find yourself writing cleaner code.
Absolutely, /u/usernamedottxt provides general rust-level suggestions while mine is simply about using a higher-level dependency which you may take or leave depending on your feelings there (e.g. some people find structopt too high-level and "magical")
Sure, makes perfect sense. But I'm still not sure why that prohibits a clarifying specification. I'm coming from Perl 5, where the following: perl -Mversion -E'say $_ for sort map version-&gt;parse($_), "1.2.3", "1.2", "1.2.4"' orders versions as such: 1.2.3 1.2.4 1.2 due to $reasons. Normalized this results in v1.2.3 v1.2.4 v1.200.0 My main issue was the impression that there is the idea that the difference between the SemVer spec and what cargo does doesn't matter in practice, but from a crate publishing standpoint it does. And there might be segments of the population that have different expectations, or none at all, and assume the SemVer spec is used as-is. Both Bundler and NPM are relatively modern things. But things like CPAN are old. I'm sure there's other ecosystems out there in a similar situation. And I'd assume with Rust maturing it will be more likely to draw in developers from the older systems, so having things specced out doesn't seem like a bad idea. Although of course, if I understood you correctly, there is no need because it's intended that at some point that spec will in fact be the/a next version of the official SemVer spec itself.
Can Skip run without a heap at all, garbage collected or otherwise?
&gt; But I'm still not sure why that prohibits a clarifying specification. The fundamental issue is completely unrelated to all of this. I'm working on it. :) &gt; so having things specced out doesn't seem like a bad idea. Agree 100%. &gt; it's intended that at some point that spec will in fact be the/a next version of the official SemVer spec itself. Yup, that's the intention. Of course, until that actually ships, we can't say for sure.
For the record I did do a (admittedly pretty brief) search and while there has (obviously) been a lot of talk about version numbers and about semver in general, I didn't find anyone proposing to create a rust-specific semver spec. I apologize if this has been discussed somewhere that I'm not aware of and if have wasted your time with this thread.
Thank you, that's motivational :)
As usual, thank you for your time and help. To sum up what you said (at least, most of you): don't create yourself problems that don't exist!
Would it be accurate to say instead that it borrows the immutable references?
Neat! Thank you!
I was worried about security updates but it sounds like the norm is Apple is they are likely to continue them for 10.13 until 10.16 or 10.17 ships in a few years. I can go back and forth too I guess. It's an old one not necessary needed to be functional at any given time.
If the IO monad handles reactive invalidation upcalls, maybe nothing!
I don't know. I only read their few introductory pages.
I tried rls in vscode and compared to IDEA it's way more stable and efficient, I think. Refactoring works well and auto-completion is smart. Furthermore, rls sometimes goes crazy when it comes to dependency. However, I like that rls completes common patterns (structs, impl traits). I have a beefier pc now but today I managed to let the ide lag. As someone who likes things minimalistic both can be annoying. I prefer in that sense rls as it doesn't clutter the code with type annotations but instead uses hover for type information.
Not to my reading, no.
This happened to me when I broke semver in my crate MGF. In the end, I was not worried because people didn't use it that much. But I held myself to the standard that if I broke API compatibility I would increase the major version. The only exception is when I yanked version 1.1.0 and released 1.1.1 due to misspelling the name of a method. I think that's fair, but I can see why people would say that I should have released a new major version.
[This](https://github.com/skiplang/skip/blob/master/src/runtime/native/src/intern.cpp#L28) is probably what you're looking for
I don't understand why this required mod intervention. The subreddit description says "For everything related to the Rust programming language", which this clearly was. &amp;#x200B; Disappearing threads that are questioning the status quo doesn't seem healthy for a community. (Yes, this has been discussed lots of times before, but there are lots of topics that come up here regularly without being deleted.)
Also, if you are a student (or at least can get hold of a student email address), you get all JetBrains products for free, no need to worry about community editions at all.
&gt; What are some reasons I might want to try using IDEA over a plain text editor? Not Rust-specific, but I get so much more power out of IDEA, it's a whole new world of programming. Jumping around the code becomes a breeze, I can run tests, servers, debuggers all straight away, I can connect to databases, switch branches (with a lot of stash/unstash fiddling automated completely for me), format my code, compile things, etc - it's all ridiculously easy and intuitive, once you get into it. Almost all of this can be done by a (sufficiently advanced) text editor (Sublime and VSCode are good examples), using plugins, the command line, and shortcuts. However, it often takes much more mucking about trying to get the right plugins installed and working, which I inevitably get really irritated by. It's very much about how things work for you, but I for one was very much on the side of simple text editors for a very long time, because I really liked the minimalism. However, once I started using an IDE, I found it really difficult to go back, simply because there were so many features that I really wanted to use on a regular basis that I couldn't any more. That said, YMMV.
&gt; - Idiomatic Rust is faster than (un)idiomatic C. See Bryan Cantrill's [blog post](http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/), specifically item 9: &gt; &gt; my naive Rust was ~32% faster than my carefully implemented C That's not an accurate statement, a better one would be rust is a similar order of magnitude to c in speed and can at times be faster even without special efforts to optimize
This is https://github.com/rust-lang/rust/issues/47131
This particular topic falls under the category of threads that are frequently reposted, tend to be heated, and are doomed to be unproductive. None of the surrounding context has changed since the last one of these threads, which means that we can expect only to yet again rehash the same arguments all over again, with the same ultimate result--and that we can look forward to the same the next time this thread is posted. If discussions on /r/rust were going to change anything about this specific policy, it would have changed by now; I am not attempting to prop up the status quo (I think namespaces are fine), I am attempting to reroute people's energy to a more productive forum with which the Rust developers are more directly engaged. As for the lots of topics that come up regularly without being deleted, this is subject to survivor bias: we do frequently delete these sorts of threads, especially when history has shown that a specific topic tends towards a flame war. Not every policy needs to be relitigated here every month, especially when this is not the preferred forum to effect significant policy changes, doubly so when considering that the time and effort of the moderation team is finite. Being the internet's punching bag is already near enough to a full-time job, so we have to rely on heuristics sometimes. :)
Oh this very interesting to me! Since switching from Mac OS to FreeBSD and Linux I've been [on the lookout for a replacement for the budgeting app I use, MoneyWell](http://bitcannon.net/post/a-year-away-from-mac-os/#missing-apps). Your app implements the first part of the functionality. The missing bit (MoneyWell's secret sauce) is automatic allocation of income to the virtual accounts according to a spending plan). I'll have to keep an eye on this.
I just mean that you're saying that it copies the non-heap immutable fields, which confused me because earlier the statement was that it didn't copy immutable fields (no modifier). So I was trying to express a different formulation of that which says "If the field is immutable and heap allocated, it is not copied, but instead the pointer to it is copied when a freeze operation occurs." But I guess that's the most succinct way of saying that.
For [alice-rs](https://github.com/cbourjau/alice-rs) the reason to split the project into separate crates was primarily the long compile time. Once I learned about cargo's workspaces there were no headaches at all :)
Isn't developing and applying a cost model to these sorts of things exactly what optimizers do? Obviously it won't be as precise as hand tuning, but automating a solution that gets say 80 percent of the way there would be worth it.
Another thing that splitting a mega crate gets you is smoother (re)compile times. Cargo doesn't need to recompile dependencies so long as you're not changing them (and if you're just testing a crate in the middle, you shouldn't need to recompile the stuff above you either). Additionally, it can be useful to create strict(er) API boundaries for a DAG of subcrates. Separating out libraries forces a strict separation of concerns and decoupling of unrelated functionality. I'll admit I'm biased towards splitting functionality into more crates. You can do everything with modules. But having separate crates gives me convenient API lines and a Rustdoc documentation page to reference. I wouldn't do it in any other language that I've used, as it's too much work to separate out libraries. (Honestly, the other languages I've used, you typically just use stdlib or a single framework because dependencies are a lot of work.) Cargo makes it easy and beneficial.
And funnily enough, I had trouble due to the IDEA plugin not having a feature I wanted: multiple Rust toolchains.
Well, you win some, you lose some! Yeah, if the IDE doesn't have the feature you really need, it's basically just a glorified text editor. But part of the problem here is that the Rust ecosystem is still relatively small and immature compared to, say, Java, or JS. Hopefully it'll get better with time!
It took me way too long to find this: http://skiplang.com/blog/2017/01/04/how-memoization-works.html It's like they actively _don't_ want people to know what makes their language special and instead just want to talk about their boring type system all day.
Oh, look. More of this stuff ಠ_ಠ &gt; When to go from 0.x.y to 1.0.0. The spec says that version 0.x.y is for initial development only and is not considered stable. The spec's FAQ says that if it's used in production or depended on by others, it should be at version &gt;1.0.0 already. But despite our past efforts to push crates to version 1.0.0, we still have many stable, production-quality crates depended on by many people that are at version 0.x.y (15 of the 20 most-downloaded crates on crates.io are version 0.x.y). The fact that people use the software and pretend it to be stable doesn't mean it's actually stable. The spec doesn't seem to account for this scenario. &gt; Write a spec that doesn't fully match how people currently use version numbers. But this should then come paired with a concerted effort to get people to use the version numbers in the way that the new spec dictates. If we say, for example, that production-quality crates should be at version 1.0.0 or above, we should actively go to production-quality crates that are at version 0.x.y to ask them to change the version number. You don't get more production-quality software by writing 1.0.0 on it, that would be like suddenly becoming a democracy because you renamed your country to "Democratic People's Republic". The authors may have higher standards or greater plans for their crates than you do, and you need to respect that. This proposal also sounds like the dishonest marketing trick that was attempted with RLS (the 1.0 release of which was supposed to magically give Rust "great IDE support" despite not fixing all the glaring issues with the program), and also, to some extent, with Rust 1.0 (which was advertised as production ready, but when questions got asked, people paddled back to "well, you see, our definition of 1.0 only considers stability"). You are better than these tricks. Please stop repeating them.
&gt; Another thing that splitting a mega crate gets you is smoother (re)compile times This is entirely true, and I hate it. cargo/rustc should be able to handle that without our help. I am familiar with all the reasons why things are they way they are, and they are good reasons, I just think the results of it are a pain. The API clarity gains are... eh, debatable. I confess it would be nice to have more options for information hiding between "public", "public to crate", and "private"; I believe there's work being done on that anyway, so. But if you break your API into multiple crates that just means less work understanding each individual piece but more work understanding how the pieces interact, which is often harder to document anyway. The times I've seen it done really well and easily usably the collection of subcrates terminates in a crate that re-exports all(?) the relevant sub-crates anyway. We're definitely wandering into opinion rather than fact here, so. My opinion is every time I've used a crate that was divided into a million sub-crates I regret it, that's all. ;-) &gt; ...and a Rustdoc documentation page to reference. Rustdoc gets you documentation pages for each module anyway, so I'm not sure what you mean there.
.fund is a file containing the saved fund data not the config file. There is a config file (although it currently does nothing) in the ~/.config/fund/ directory. Are you saying I should move the .fund file into the config directory as well? Not opposed to the idea, just making sure we're on the same page.
Unfortunately, \`FutureObj\` was already removed despite this not being implemented yet, meaning that anything dealing with \`Future\`s at the moment is stuck.
Sorry I misunderstood. Sounds like the config is already in the right place. The fund data might be better off in the [Documents directory](https://docs.rs/directories/1.0.2/directories/struct.UserDirs.html#method.document_dir). 
Crate == package. Splitting software into packages allows for more explicit control on dependencies, layering, separation of concerns and so on. I like to split even a simple project into several crates like: core abstract types, core business logic, command line binary itself etc. even if I am not (yet) strictly thinking about making some of the usable to the general public. It help me keep the hygiene and good architectural structure from the very beginning. Through my carrier, I've seen plenty of software that was just huge mega-crates (oh Java/Scala, or the horror), and everything was calling everything else, new users had hard times navigating to the bits that were relevant to the task at hand, core business concepts would be reinvented multiple types, because people didn't know they existed elsewhere etc., it was hard to run the relevant tests and so on.
The former, on the first call to resume you must supply a value that will be in `gen arg` up until the first yield point.
Making the type pub also seems to work
I actually started implementing that early on, but it proved to be a bit too much of a challenge at the time. Definitely something I want to come back to though.
I'm planning on buying some. Do I need a PCI port for each one? That kind of limits the amount I could have... . Anything else that I should know / do?
This is great! I've been looking for something like this for a while now. 
The problem is that memory accesses With cache hierarchies is a complicated architecture dependent topic, even for the same target, so... there just aren’t good solutions for this problem available or even possible. The user just has to go and state wether this is a good or bad trade off . There is no cross ISA silver bullet 
You can control visibility at a finer level with `pub(crate)`, `pub(super)`, and `pub(in path)`. Rustdoc doesn't document private details by default (and until recently there wasn't a stable way to do so). By making that a full crate with a public API, I have a documentation page to pull open. And I agree that if to use a project you have to pull in multiple dependencies (and aren't making an actual choice in doing so), then the API hasn't been designed ideally. Crate breaks should either be meaningful choices to pull in options (as with piston), meaningfully usable without parents/siblings (as with UNIC), or strict divisions of functionality exported as a whole (as with the stdlib (libsyntax, miri, stdsimd)) or used as encapsulated building blocks. If it could be versioned separately, my opinion is that it should be a separate crate. If they're still likely to need bumping in sync, or testing infrastructure benefits, then they should be in a workspace. But if they always have in-sync version numbers and have no chance of theoretically graduating to separately developed repositories in the future, then you've just got glorified modules.
https://github.com/rust-lang-nursery/rustfmt Rustfmt accepts and encourages issues :)
If you've got an example that shouldn't use rustfmt's default style, you can opt out with `#[cfg_attr(feature="cargo-fmt", rustfmt_skip)]` (or soon `#[rustfmt::skip]`). I'd consider this a good reason to. Since it's a test, you could also add structure by writing `[[0x00, 0x01], b"abc"].iter().flatten().collect()` (or something similar, untested). In any case, these fn shouldn't be taking a `Vec&lt;u8&gt;` as argument, but rather a `&amp;[u8]` (or even `impl Into Iterator&lt;Item=u8&gt;` if they don't need random access and just go through it once). If they take a `&amp;[u8]`, you can write the whole thing as a byte string: b"\ \x00\x05\x01\0\ \xff\ \0\ \0\ \ \x01\x0c\x02\0\ \xde\xad\xbe\xef\xde\xad\xbe\xef\ deadbeef\0\ \0\ \ \xff\x06\x03\0\ \x01\x02\ abcd\0\ 1234\0\ \0\ "
It'll get a little bit prettier with `#[rustfmt::skip]`: https://play.rust-lang.org/?gist=25d2db1e554e686a3343e46b206dbcb0&amp;version=nightly&amp;mode=debug&amp;edition=2015
1.0.0 will be when I finish everything! Maybe I'd release a 0.1 soon? Let me know what you think!
That's because the compiler can't know if `pub` items aren't used by other crates.
Use `clippy` often, and try out it's suggestions even when you don't think they're useful.
Totally agree. When I'm writing out a 4x4 matrix, it's a lot easier if I can actually coax rustfmt to allow it to remain 4x4. Thanks for bringing it up, some of the workarounds people describe might be useful. And a Real Solution would naturally be better! I wasn't aware of this property of gofmt.
link?
[I think this is what you're looking for.](https://www.youtube.com/watch?v=dQw4w9WgXcQ)
&gt; they have to be really sure that there won't be a 2.0, as the ecosystem simply can't take it How do the `libc` devs feel about that "release one final minor for the previous major that re-exports types from the new major" trick? Is it viable? Or maybe, viable-but-requiring-tons-of-error-prone-work?
I am not sure! I think it doesn’t work in this case because of the linking to a native library thing? Not sure about that though.
It just occurred to me: it might be a good idea to teach `rustc` and `rustfmt` to recognise U+0082 (break permitted here) or U+2028 (line separator) and U+0083 (no break here). Those alone would probably solve a lot of the "one off" problems where the global formatting config isn't optimal for a local case. Downside: editors seem to render those as boxes, so they'd be kinda ugly. Still, maybe the newer ones could be convinced to change their rendition...
https://crates.rs/crates/trove probably
That doesn't sound right to me. If libc releases 0.3.0, along with 0.2.44 which doesn't link directly to a native library but simply reexports types from 0.3.0, then every project depending on any combination of 0.2 and 0.3 will have exactly one version that links directly to a native library in its dependency tree: 0.3.0. Projects that pin patch versions will still be in trouble, but that's not a change from the status quo. The same would apply for post-1.0 versions. I, too, am curious about why the libc developers haven't done this.
One thing I sometimes do is add a comment where I don't want `rustfmt` to join lines: ```rust let foo = vec![ // First line 1, 2, 3, // Second line 4,5, // End of the vec ]; ```
Eliminating all dependencies with unsafe code, I guess.
DISCLAIMER: Hobbyist programmer with NO CS background! I am just working through the official book and I came across this in section 4.3 - slices: &gt;So in the for loop, we specify a pattern that has i for the index in the tuple and &amp;item for the single byte in the tuple. Because we get a reference to the element from .iter().enumerate(), we use &amp; in the pattern. Really? iter() returns a reference? How do I know this? I tried to google "Rust iter docs" to find the source code for the iter function so that I can see/learn how to do this myself. But I didn't find anything. Where do I have to look? I really need to learn to look stuff like this up myself. But when I scroll down [https://doc.rust-lang.org/std/iter/index.html](https://doc.rust-lang.org/std/iter/index.html), all I see is a shitload of syntax that does not (yet) make any sense to me at all. Can someone point me to the exact line in the docs where this becomes apparent please. Also: Is this really how this works? I need to mess through endless pages of gibberisch docs to see what a function returns? That seems quite cumbersome. Is that really te reality of being a Rust programmer? &amp;#x200B; &amp;#x200B;
&gt; While Cargo's docs could be a bit more clear about how it only follows a variation of semver instead of following the spec literally, I think almost every package system uses this variation. I know npm does it, and npm is by most metrics the largest package index in the world. If everyone does something different from the spec, but claims to follow the spec, they're all lying, and wrong. What should have been done, long ago, was make their own version of the spec with the requirements they need, that way people can actually read the spec and be correct. Anything else is simply dishonest and wrong. No matter how much you try to argue it, the simple fact is if i cannot read the semver spec and be correct about how semver implementations work, those implementations are wrong and ***not*** following the spec. &gt; if you're still unconvinced that semver is wrong, not cargo or npm I don't care whether semver is wrong or not. It doesn't matter. If semver didnt meet their requirements, they should have made their own version that did, and then claim to follow that. It is cargo and npms fault for claiming to follow a spec they do not follow. No ifs ands or buts, it's their fault for lying. &gt; We should just change the spec. Yeah, exactly. But since they havnt changed the spec, and as you've so helpfully pointed out, have intentionally not been following it for *years*, but likewise intentionally claim they *do* follow it, they're wrong and lying. The spec may be wrong too, but that doesn't matter, they can make their own. New (non)programmers shouldnt have to magically know "how everyone *actually* does semver" to be able to understand semver, they should be able to read the spec. Or whatever document the documentation links to to describe it, and whatever it calls itself. Someone, hearing about "Semver", should be able to google "Semver" and read the spec and know how it works for everything that claims to use "Semver". Thats the entire point of a spec. They could have just copy pasted the current semver if they wanted to mostly match it's behavior. The license allows this. This defeats the entire purpose of semver, &gt; The problem is that “close” isn’t good enough. Without compliance to some sort of formal specification, version numbers are essentially useless for dependency management. I should be able to write my own semver tool that follows the spec and be correct about it. I shouldnt have to already know "well the spec *says* this, but nobody *actually* follows it", that shouldnt happen. &gt; But really, read all 3 comments Those comments less convince me semver is wrong than they do that 1.x vs 0.x is pointless because in practice they have exactly the same meaning, and are essentially useless for telling between wip development projects and finished, production ready ones. The first comment especially highlights this. Which is an extremely sad state of affairs, and imo, the biggest argument against changing anything. If 1.0 is never used and doesnt offer anything that 0.y.z does, why should it exist? Or why bother with 0.y.z? Whats the point of 1.0 and stability guarantees if everyone just applies those to 0.y.z anyway, and then *never moves up*? This seems to me an extremely serious problem. What is 1.0 supposed to mean? If not production ready or quality, which is held by all the production ready and production used and quality pre 1.0 crates, what? How does this work? The 3rd comment compares semver to a dictionary, and say its wrong to not reflect changing usage. That may be true, but likewise it would be wrong to claim to follow the dictionary definition when actually following the common usage, and only mentioned in project specific documentation. Which is what cargo and npm do.
In section 5.1 of the Rust book it says this: &gt;In the User struct definition in Listing 5-1, we used the owned String type rather than the &amp;str string slice type. This is a deliberate choice because we want instances of this struct to own all of its data and for that data to be valid for as long as the entire struct is valid. I understand ownership and borrowing, but what does "owned" mean here? How is (a) String owned? And why is &amp;str not owned? Because &amp;str is a Pointer and points to something else? But a String is nothing else than a Pointer to a String stored on the Heap, right? So how can one Pointer be owned but not another? &amp;#x200B;
&gt; What should have been done, long ago, was make their own version of the spec with the requirements they need, that way people can actually read the spec and be correct. I created this thread a few hours ago: ["Should we make our own semantic versioning spec?"](https://www.reddit.com/r/rust/comments/9jcwjh/should_we_make_our_own_semantic_versioning_spec/) I argue that this is exactly what we should do. The reaction has been... mixed. Seems like many people are fine with the current situation where the "de facto" meaning of semver is not what it actually says.
I ran that line in the terminal and am still unable to format my code is VS:Code. alt+shift+f does nothing, ctrl+s does nothing, typing `rustfmt` into the terminal that is the same directory does *something.* It sends my cursor to the next line and blinks until I press ctrl+c. 
Yes my program runs fine, I'm just not able to format it.
 /* * * * * * * * * * * * * * C O R R E C T A N S W E R * * * * * * * * * * * * * */ &amp;#x200B;
Use Rust, then you can worry less :P For most cases, you'll want to use a library/framework that (mostly) handles threading for you, such as rayon (for parallelizing Iterator workloads over data sets) or tokio (for a multithreadable task executor). Stay away from anything that requires specifying a memory order unless you really know what you're doing, because how atomicity interacts with compiler and processor optimization is very tricky. And for most workloads, just sticking any thing that needs to be synchronized in a `Mutex` or a dedicated data structure for multithreading is more than enough. But don't forget about MPSC (multiple producer, single consumer) channels and crossbeam; these concurrency tools will be useful any time you need to do something beyond what just rayon/tokio get you. (Also, opinion time! Prefer scoped concurrency over unbounded threads. It's like goto in a way: full unbounded threads (unchecked goto) are powerful and can do whatever you want plus more, but can bite you in the butt, while scoped concurrency (structured control flow) is much more manageable, easier to reason about (for you _and_ the compiler), and can do 99% of what you'll ever need to do.
Right, but the idea would be to get both to agree to interpret them as line breaks, with an extra symbol to denote their existence. I mean, failing that, we could just use regular symbols before a line break to indicate whether it's forced or not.
Cargo doesn’t know about that, the link attribute makes sure there’s only one version in your overall graph. I think.
If you don't have an m.2 port you have to use pcie. You could also use an m.2 external enclosure over usb3 I guess. Not sure if there is a performance hit for that but you would still be over a gigabyte/s for read or write.
Lots of text about macos with no actual details. As for the mouse you put a charger in when you're not using it and its fine. People who use it absolutely love it. 
I think that is out of the scope of the project and would make maintaining the project much more difficult for the author. Time is always a factor
Speaking of memory ordering, if you want to drink from the firehose on that topic, watch Herb Sutter's [Atomic Weapons talk](https://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-1-of-2). I had to watch it twice before it made much sense, but if nothing else, it'll make it clear how tricky the whole area is.
Here's code from a half-polished (but fully working) project of mine: ``` fn query_official_repository(client : &amp;Client&lt;HttpsConnector&lt;HttpConnector&gt;&gt;, name : String) -&gt; impl Future&lt;Item=OfficialRepositoryPackageResult, Error=PackageQueryingError&gt; { let url = Url::parse_with_params( "https://www.archlinux.org/packages/search/json/", iter::once(("name", &amp;name)), ).expect("Silly programmer got the url format wrong"); client.get( url.as_str().parse().expect("URL libraries disagree on valid url format") ).into_stream().map(Response::into_body).flatten().concat2().from_err().and_then(|body_content| { serde_json::from_slice(&amp;body_content.as_ref()).into_future().from_err() }).map(move |information : OfficialRepositoryMultiPackageInformation|{ match information.to_result() { None =&gt; Err(PackageNotFoundInOfficialRepository::new(name)), Some(info) =&gt; Ok((name, info)), } }) } ``` The main annoyance for your use case is that the body is streamed in chunks but for json parsing you probably want the whole body to be available before parsing. That's what the `flatten`/`concat2` parses are for.
&gt;\- Why not run checkFileCopyComplete() for all files Well in nodejs I use chokidar. So even the user put in 10 files. It just returns 1 callback for each file. That why I think I will spawn 10 thread if they put in 10 files. Btw the user might not put 10 files at one time. They use an FTP client, so they might drag and drop file after file so not always 10 files at the time. &amp;#x200B; Thank for you suggest that crate.
&gt; Prefer scoped concurrency over unbounded threads. Just wanted to support this: the more you find constructs that let you write what you want to do rather than *how* to do it, the less problems you're likely to have.
This link is not up to date
Time for an NYAR post? Link to an old- https://www.reddit.com/r/rust/comments/7zpvev/notyetawesome_rust_what_use_cases_would_you_like/
Have you tried "return value" instead of just value? Implicit return only works for the last expression in a function
[`crossbeam::thread::Scope::spawn`](https://docs.rs/crossbeam/0.4.1/crossbeam/thread/struct.Scope.html#method.spawn) (scoped) vs [`std::thread::spawn`](https://doc.rust-lang.org/stable/std/thread/fn.spawn.html) (unbounded). TL;DR: with scoped concurrency you still have a guaranteed happens-after where the scope ends. (This is very useful for deferring destruction, thus allowing borrows.) Further reading: [Go statement considered harmful](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/), and I'm sure there's other stuff but I can't find it right now
&gt; I think that is out of the scope of the project and would make maintaining the project much more difficult for the author. Time is always a factor Totally understandable :)
If you make that first if statement an expression, by uncommenting value, it’ll need a way to find an expression of type i32 for the else branch - and you don’t have an else branch. While you could just chuck “return value;” in there and then have the code after it be an implicit “else” case because the only way to reach that is if you don’t return early, I think it could be more idiomatic. My personal preference would make it one big expression, if true then evaluate to “value” and then chuck the rest of the function into an “else”. Obviously depending on the significance of the if branch, sometimes making it an early return instead can make the code easier to read - there is no one right answer. 
Thanks! I used "return *value" and this does indeed work. :) . I also realized I needed an i64 to get to any meaningful sized number.
Ironically, your nightly is actually *too* new, as some changes to the pinning API have broken things with `futures`: https://github.com/rust-lang/rust/pull/53877 Try `rustup install nightly-2018-09-17` and `cargo +nightly-2018-09-17 build`, that's the nightly from the day before that PR was merged.
I very much want to use [`HashMap::entry`](https://doc.rust-lang.org/stable/std/collections/struct.HashMap.html#method.entry) even though I know it'll probably look more complex for it. Actually, it looks like it could just be *map.entry().or_insert_with(|| { if n &lt;= 1 { n } else { fib(n-1) + fib(n-2) } })
Has there ever been a Rust meeting in Vienna?
There's an open PR to resolve this: https://github.com/rust-lang-nursery/rustup.rs/pull/1517
Excellent article! The triple-pronged approach of "don't use unsafe code where it's not necessary", "prefer vetted unsafe abstractions provided by the stdlib", and "harden your unsafe code with a wide spectrum of tooling" is something that we've been trying to teach for a long time, and it's great to see it laid out so lucidly. And it's worth reiterating often, since stuff in this space matures over time: the language /stdlib receive new optimizations that may obviate unsafe optimizations, the stdlib develops new unsafe abstractions that can replace bespoke unsafe code, and new tools (like the one in this post!) bring new bugs to light. Keep up the good work. :)
IIRC, (break permitted) and (no break) are supposed to be for controlling line wrapping, so using them for hard line breaks would be incorrect. It would be interesting to see them used for controlling what are effectively soft line breaks inserted by rustfmt, though, but soft wrap control isn't enough to get the desired formatting in this case. Trailing whitespace should be trimmed (and is trimmed by many editors), so combining them with a newline is probably a bad idea as well. Another thing to note is that IDEs might normalize whitespace on paste, to prevent accidentally introducing non-whitespace that looks like whitespace to a language that only considers ASCII unprintable characters as whitespace. Ultimately, though I like the idea, using invisible characters is a bad idea. The only invisible characters worth including in a plain text file are those that impact visual presentation.
IIRC, (break permitted) and (no break) are supposed to be for controlling line wrapping, so using them for hard line breaks would be incorrect. It would be interesting to see them used for controlling what are effectively soft line breaks inserted by rustfmt, though, but soft wrap control isn't enough to get the desired formatting in this case. Trailing whitespace should be trimmed (and is trimmed by many editors), so combining them with a newline is probably a bad idea as well. Another thing to note is that IDEs might normalize whitespace on paste, to prevent accidentally introducing non-whitespace that looks like whitespace to a language that only considers ASCII unprintable characters as whitespace. Ultimately, though I like the idea, using invisible characters is a bad idea. The only invisible characters worth including in a plain text file are those that impact visual presentation.
Hi! I have been trying to find out Vim (Veovim) Plugin for lldb integration. But I could not find any document which I can follow. Please inform me of a way to configure a good Plugin. &amp;#x200B;
The main example i'm thinking of is, say you have a B-Tree, or similar structure, and you want a type to represent a branch down the tree, you can just do \`Vec&lt;(HandleMut&lt;Node&gt;, Offset)&gt;\`, and be done with it. The internal \`RefCell\`s will not complain about mutable aliasing, and will even prevent cycles from being created (at runtime, mind you). &amp;#x200B; Redux/React is an interesting comparison, and i don't see why it wouldn't work just as well. As for how exactly you would maintain and update the structure in a web-framework setting, i'm not entierly sure. It's not something i have in mind for right now.
The "popular crate" is https://crates.io/crates/claxon which i haven't known about until now.
Exactly this. Rust does *not* protect you from deadlock. Rust does *not* prevent you from doing things to a shared structure in the wrong order. Data races (doing things to a shared structure at the same time) are dangerous and incredibly gnarly to debug, so preventing them is a Big Deal, but there are still some very subtle pitfalls in concurrency the language can't protect you from.
&gt; This is the second-ever security vulnerability in the standard library This ... isn't true? We've had multiple "vulnerabilities" like this in the past. The most recent one was the Arc memory ordering bug, but there have been others.
Why `-rs` in the crate name?
Ahh that makes sense. Awesome. Thanks man!!
It seems there was some [discussion](https://github.com/phsym/prettytable-rs/issues/32), but I honestly don't know what the developer's plans are. Of course a name without `-rs` would be easier, but for me it's not too big of a problem.
This is exactly the type of answer I needed. Thanks so much! However I need to work through the book further to actually understand your answer. ;-) I bookmarked it and will get back to it in a few days/weeks/months. :-)
Great article, and very interesting approach!
For people who don't know, note how the last character on each line is a backslash, that means the newline character that comes after the backslash is ignored and will not appear in the actual data
Code tip; if you initialize your hashmap ([Example](https://play.rust-lang.org/?gist=eb1ba945b4a6a82bc3cd5671bef64c8b&amp;version=stable&amp;mode=debug&amp;edition=2015)) with the first two entries, you could remove those two if branches completely, and be left with a simple if/else and not need any return statement.
You will be much happier if you do it to play around with multithreading and learn how it works, rather than actually expecting it to solve any problems for you. Also `rayon` is awesome.
&gt; fast, reliable, productive: pick three The proposal in [this thread](https://internals.rust-lang.org/t/pre-rfc-fixed-capacity-view-of-vec/8413) looks like an improvement to all three, great work!
Front-end is using gtk-rs, "backend" is [sysinfo](https://crates.io/crates/sysinfo), so you can definitely use it with another UI. Another project is actually using a web UI upon `sysinfo`, it's called [sysinfo-web](https://crates.io/crates/sysinfo-web).
Noob question here why not to use `usize` instead ?
Because at best it is 64 bits, but can also be much smaller? So if you always want 64 bits just use `u64`. In general you should prefer to use the fixed size integers over `usize`/`isize` when possible.
I really like that Rust also tries to force programmers to keep to the same style. It's really common in my company that everyone uses some kind of different style. Thanks for the tip!
try "cargo fmt" command
`hard_tabs = true`
Oh before I forget: you can actually use `sysinfo` from C so you can also call it from C++. So no problem to integrate it with Qt (the Rust binding doesn't seem to be very advanced for the moment unfortunately...).
I disagree, in my opinion it was a mistake to allow rustfmt to be customizable. The way Go does is really awesome, sure, you don't like the style but you love that everything is styled the same. 
Does the Go community have some convention for distinguishing between projects that use auto-formatting and projects that don't, or is it just not possible/practical/polite to manually format code?
If you try to force too much, you'll get pushback. If rustfmt weren't configurable, I'd just ignore it entirely. As-is, it's not configurable *enough* so I only bother to run it once every few weeks, when I feel up to using `git gui` to cherry-pick the hunks where I slipped up in manually following my preferred style without noticing and then revert the rest.
Great to hear! Hadn't realized it wasn't until now.
The 2010 MBP needs a 2.5" SATA drive. That's not compatible, right?
Not to my knowledge. From my experience, you either use gofmt, or people bother you until you do. It's ingrained. I don't see that same thing happening in Rust.
A big reason why I like and use gofmt, but still do not use rustfmt, is because gofmt generally respects your line breaks. I know the folks building rustfmt pursued that path and found it unworkable for reasons I can't recall at the moment. But a lot of the reason why I'm not using rustfmt yet is because of formatting issues that could generally be resolved if existing line breaks were respected.
Computers just kinda suck in general. Each of the big 3 are workable, especially if you own the machine and take the time and care to customize it to your needs. I can't stand using a Mac with default settings but I love my customized one (though I agree MacOS would be nicer with window snapping). I actually really hated Macs before I started working at a job that gave me one, and was pissed for the first few months I had it. You get used to the little details on the platform over time though.
[Here](https://play.rust-lang.org/?gist=b506873d9e8669dcaeb256bff87384b3&amp;version=stable&amp;mode=debug&amp;edition=2015) is an example where rustfmt will go crazy with inserting newlines. Of course the code *is* pretty terrible and the ridiculous return type could be a simple type alias, but I think it illustrates the problem.
That actually does not seem too bad to me. In that case, you've given rustfmt an input that doesn't really have any possible nice output short of changes like adding a type alias, as you mention. I'm thinking more like this: https://github.com/rust-lang-nursery/rustfmt/issues/2263
`Any` will force you to write more code, (probably) sacrifices performance, and annihilates your code's clarity because you've stepped down from Rust's static type system to the (figuratively) dynamically typed `Any`. Frankly I don't really see how `Any` would make sense to represent the language's types. All you end up doing is emulating an enum, but in the process you sacrifice many important things while gaining nothing on the other hand.
How do I constrain an input lifetime to be invariant? Take the following example: [playground](https://play.rust-lang.org/?gist=39cbdd50499ec999d7d9f685cb56b99a&amp;version=stable&amp;mode=debug&amp;edition=2015) struct MyVec(Vec&lt;u8&gt;); impl MyVec { fn get(&amp;self, offset: usize) -&gt; Option&lt;&amp;u8&gt; { self.0.get(offset) } fn of(&amp;self, byte: &amp;u8) -&gt; usize { byte as *const u8 as usize - self.0.as_ptr() as usize } } fn main() { let my_vec = MyVec(vec![1, 2, 3, 4]); let byte = my_vec.get(3).unwrap(); let offset = my_vec.of(byte); assert_eq!(offset, 3); // Not a compile error! let _ = my_vec.of(&amp;0); } I want the ability to specify that the lifetime given to the byte argument of the 'of' function must be _exactly_ equal to the lifetime of the struct. The idea here is that this parameter only accepts borrows that _it itself_ has created (here the get method). From my limited understand this means that I want to make the byte reference lifetime to be 'invariant', but how do I express this? To be clear, how do I modify the signature of the 'of' function such that the last line in the main function no longer compiles?
I agree, but Github renders tabs with 8 spaces. (used to - now it varies from 2 to 8 for different languages). But I wish Rust went with `tab_spaces = 2`, especially with infamous 80 characters limit
If I understand correctly, \`rustfmt.toml\` does not work with the \`rustfmt-preview\` that's released with stable Rust, which makes it rather useless to me.
I only use stable Rust, and my `rustfmt.toml` files work for me.
Why are fields for Structs omitted in documentation on docs.rs? If I want to use a Struct, I need to see the fields. example: https://docs.rs/rabbit/0.1.0/rabbit/struct.Rabbit.html
The file can also be named `.rustfmt.toml`if you're outside the Windows world and want the file hidden.
&gt; Why are fields for Structs omitted in documentation on docs.rs? Because they're private, and you're not *supposed* to know what they are. &gt; If I want to use a Struct, I need to see the fields. No you don't. That's what the associated functions are for.
This account is copy+pasting articles from other websites.
Hmm. Could you provide some example code where it actually worked for you? Every time I tried to actually use it, it gave me a false positive immediately, with or without libtest, with or without stdlib even.
/u/Shnatsel &gt; the fastest way to initialize a vector of size max_len is actually vec![0, max_len]; should be the fastest way to initialize a vector of size max_len is actually vec![0; max_len]; Semicolon, not comma when specifying length for the vec! macro
It does not matter how github presents tabs. What matters is that each user has the freedom to choose how large a tab is, that freedom is what I stand for, and why I will **never** use spaces for indentation (only for alignment). For freedom! For the tabs!
First thing I'd suggest is heading over to /r/playrust and ask those folks, they sure know a lot about the game rather than the programming language ;)
I was hoping to use "does `rustfmt.toml` exist" as the condition for enabling auto-formatting in my editor; I guess I have to make that check more complex, now.
Apparently they were not considered security bugs, since no security advisory was issued for them. Then again, the [VecDeque bug](https://github.com/rust-lang/rust/issues/44800) was also not considered a security issue originally, I had to apply for CVE by myself.
You're doomed to sata unfortunately. But on a computer as old as that it's all shit anyway.
What editor do you use?
Just posted the same thing in another rustfmt thread :) Here you go, hope this helps: #[rustfmt::skip] // requires nightly Rust and #![feature(tool_attributes)] in crate root #[cfg_attr(rustfmt, rustfmt_skip)] // works in stable Using the skip attribute will let you format that block or functions by hand and simply have rustfmt leave it alone.
If you want IntelliJ to be lightweight(ish), just strip down all plugins you don't need. On my laptop, I disable almost all of them and its running on 600 MB RAM, which is pretty nice since if I turn all plugins on, it consumes with \~1.2 GB RAM. Not a perfect workaround but at least it works :)
[Kakoune](https://kakoune.org/)
Extremely interesting article. As a C++ dev, the more I read about rust, the more I'm interested in that language.
Github supports `.editorconfig`, so you could: root = true [*.rs] indent_style = tab indent_size = 2
Or you could include `cargo fmt -- --check` in your CI script. This way, you could enforce the style in contributions.
If you read up thread, there is another possibility: rustfmt respects any existing line breaks. It sounds like the cost of that though is probably giving up an enforce line length.
I think it's a more friendly contribution experience to have automatic formatting happen... automatically, than to have somebody's contribution mechanically rejected ten minutes after they post it. Of course, you can do both! Have a `rustfmt.toml` to encourage client-side auto-formatting, and a CI hook to enforce it server-side. 
Do you and /u/Quxxy have recommendations for libraries, techniques or codebases to learn from that can help prevent race conditions?
You can use integration tests in the `tests/` folder. Each file in that folder is compiled with your main crate as extern crate. So you just have to `use your_crate::your_macro;` and can test it in `#[test]` functions there. (In edition 2015 you also have to write `extern crate your_crate;`). Apart from that, you often want compile-fail tests too: tests in which you want to assert that something won't compile. For [`auto_impl`](https://github.com/auto-impl-rs/auto_impl) I wrote two custom test-harness that does the testing: [`compile-fail`](https://github.com/auto-impl-rs/auto_impl/blob/d7ba83a43b3cdd2e4c12baadcd8dfd8ed28edde6/tests/compile-fail.rs) and [`compile-pass`](https://github.com/auto-impl-rs/auto_impl/blob/d7ba83a43b3cdd2e4c12baadcd8dfd8ed28edde6/tests/compile-pass.rs). The compile-fail tester is far from perfect; in particular, it doesn't check the error message yet. So the custom test harness should ideally be in an extern crate that can be reused everywhere. There is actually something similar: [`compiletest-rs`](https://github.com/laumann/compiletest-rs). This crate was extracted from the rustc repo (where compile-fail testing is used a lot). However, I don't quite like it because it's super hacky, assumes some internal knowledge about how Cargo builds and some code in it is already quite old. A better solution could be made by using the build-plan feature of Cargo. Via build plans, one can get all the information about how to compile a test. This is what [`compile-fail`](https://github.com/jonas-schievink/compile-fail) uses. Sadly, that crate doesn't seem to be ready yet. And build plans are still unstable. With the recent test framework RFC, we can expect that the situation will become much better.
Quick question. Check this example from the book: #[derive(Debug)] struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(&amp;self) -&gt; u32 { self.width * self.height } } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!( "The area of the rectangle is {} square pixels.", rect1.area() ); } I understand everything about this. However - just for fun - I replaced `&amp;self` with `self` to see what would happen and it stll works. And I'm not quite sure what the implications are. It's not borrowing "itself" but completely giving ownership, right? But what are the consequences of a "non-reference-self" ?
I use it in CI without issues, I can try to get a minimal example uploaded somewhere, but I just followed the Rust-San instructions.
That's pretty much it. Use crossbeam-channel. :)
A major consequence would be that, unless `Rectangle` implemented `Copy`, you couldn't use it again after calling the method, since ownership of it was transferred. If you take that code (with the `self` version of `area`) and, after the `println`, call `rect1.area` again, you'll get a compiler error complaining of using an already-moved value.
Ah ok. This was a while ago, haven't really kept up with it. Good to know!
It sounds like vector and memory initialization is becoming a common pitfall. Why does this happen? I suspect that people are copying/referencing other's unsafe code, which doesn't work well because there are only a few people that really understands unsafe.
Hmm ok I think I almost got it. But just to be extra sure: 1. The instance of Rectangle named "rect1" is what the "&amp;self" is referring to here, correct? 2. If I pass a non-reference-self, rect1 is being moved into its own method named "area()" and once that method has executed and goes out if scope it would destroy "rect1" because it now "owns" "rect1" and hence drops it when area() goes out of scope, correct? Extra question: A int is never moved, because it has a Copy trait, while a String is being moved, because it doesn't have one and would need to be .clone()-d. I get that. But in this example is the instance "rect1" is moved, because the type struct doesn't have a Copy Trait or because my specific struct Rectangle doesn't have a Copy trait? 
https://youtu.be/SsoOG6ZeyUI I'm a soft tabs person. Tab = 4 spaces. But personal style aside, the video is always relevant
I don't think there is a way to know for sure. I'd attribute it to safe methods not having any documentation on their performance characteristics, so people use a slow method of initializing a vector, then find out it's a performance bottleneck and refactor it into unsafe code that has clear performance properties. I've [opened an issue](https://github.com/rust-lang/rust/issues/54628#issuecomment-425423774) against Rust about documenting that. 
Because your specific struct `Rectangle` doesn't implement copy. If you change the Rectangle derive to `#[derive(Clone, Copy, Debug)]`, then you could call a method that requires an owned value as much as you like, since `rect1` would never be moved, only copies of it.
Stick `//` on the end of lines in an array where the linebreaks are significant and it'll preserve them. static CIPHER: &amp;[char] = &amp;[ '0', '1', '2', '3', '4', '5', '6', '7', '8', // '9', 'z', 'y', 'x', 'w', 'v', 'u', 't', 's', // 'r', 'q', 'p', 'o', 'n', 'm', 'l', 'k', 'j', // 'i', 'h', 'g', 'f', 'e', 'd', 'c', 'b', 'a', // ]; https://play.rust-lang.org/?gist=84b806cb9d9d5da0def7e07449087a0b&amp;version=stable&amp;mode=debug&amp;edition=2015
Nice, thank you!
Awesome. I totally understand this. Thanks so much for taking the time and explaining it!
Some extra information: _All_ types are movable. In Rust, Movable means a memcpy of the data structure, also known as a shallow clone in other languages (this has implications for self referencing structs, but that's for another time). By default Rust will restrict access to a variable once it has been moved away. By implementing the Copy trait, Rust allows you to keep access to variables that have been moved, hence 'moved' changes to 'copied'. All this is a consequence of not having a garbage collector, or other mechanism to track 'shared ownership of underlying data' once a shallow copy is made.
Hey. I actually wrote a similar crate few days before this one. It's fun we ended up with a similar syntax, I guess it's because it looks very declarative and a natural way to declare routes. You can check it at [https://crates.io/crates/rouste](https://crates.io/crates/rouste). It doesn't support matching the type of the request in order to be generic to other protocols but rouste is able to capture query parameters as \`Option\`s.
I don't think performance profiles is "enough" to convince people not to use unsafe code? Like, initializing with zeros is safer, and could be done in faster ways the the dev did here, but I don't think that'll stop people from trying to optimize the code into using uninitialized memory, which should always be at least as fast. After all, initializing with 0s makes the program safe, but still not bug free - now the program is just "guaranteed" to read zero'd garbage. More generally, I'm trying to think if there's useful programming patterns for ensuring an uninitialized vector is always written to before being read, but nothing comes to mind. 
&gt; Is it really that surprising when C didn't even have a proper memory model back then? Like, I don't think anyone can really follow threading rules when nobody has an idea what they are to begin with. Multi-threaded programming in Rust is much nicer than in most programming languages, especially C (which is probably the worst choice for multi-threaded programs that you can use in such a way, even with C11 memory model). The bugs don't tend to be memory bugs. They're the same kinds of locking and synchronization bugs you'd have in a parallel Rust program. I *guess* there have been data races, but mostly it's been just logic bugs. &gt; Those are entirely different tools. Neither is an alternative for the other tools. Try to stick to the second and third thing where possible. The first thing is harder. Crossbeam does provide more than just data-structures. I (like the crate description) would characterize Rayon as a way to parallelize sequential code without restructuring it too much.
Thanks for chiming in. I'm happy about any background knowledge I can get. (I dont have a CS background/degree) Let me lay out my current(!) understanding of things. Example: int. An integer is directly stored on the stack -&gt; costs very little and is hence copied. Actually it doesn't just cost very little, but it costs the least possible cost there even is, correct? Meaning you cannot have less cost than pushing something on the stack. Is that correct? Example String. A pointer (which lives on the stack) to a place in memory on the heap. Clone() creates a new Pointer (on the stack) AND a new memory on the heap. And the problem So my first question: Is memcpy and clone() the same thing? Sounds like it?! But I have a feeling I'm wrong! ;-)
Got a question on how to write some code of mine in a nicer way. The gist of what I want is an iterator over a slice that breaks up the slice and returns a smaller subslice of elements that satisfy some predicate based on the first element. For instance, this iterator on the slice \[1,1,1,1,2,2,3,4,4,4,5\] should return \[1, 1, 1, 1\] \[2, 2\] \[3\] \[4, 4, 4\] \[5\] on each of its calls to next. I've written some code [here](https://play.rust-lang.org/?gist=8393b3a40f1f6bd78a46ef4eae70e86d&amp;version=stable&amp;mode=debug&amp;edition=2015) but it's kind of ugly. Is there a nice way to "rustify" this?
They would use it for any project that required it; that's not the point. A project might not decide to use if it weren't configurable.
Vector itself is such a pattern. It allows you to append to it without ever initializing the memory. However, for some reason people tend to just pass slices around. I have described the situation in more detail in my [fixed-capacity vector](https://internals.rust-lang.org/t/pre-rfc-fixed-capacity-view-of-vec/8413) proposal.
If you update the compiler and make a clean build, then all the crates you're using will be compiled with new implementation of `str::repeat` without security issue. 
Begun the Tab Wars have.
You're right, there's an implicit return. It's been years since I last used it, so I just put it in just in case
Ah yes. Enforced line length limit is one of my personal favorite features, in any code formatting tool, not only rustfmt. I work quite a lot on laptops and in addition to that I need quite large font size to read comfortably, and that makes that feature extra important for me.
That’s essentially what soft tabs is. Hit tab to indent, where an indent is 4 spaces. 
I wonder if rustfmt should look and see if you have already broken the numbers onto separate lines, aligned, and then leave it alone, if so. Only auto format if you have it all in a single line, or unaligned multiple lines. &amp;#x200B;
`[T; N]` is an array, not a slice. `[]` is a slice and may be looking at an array or a slice of a heap allocated object. https://doc.rust-lang.org/rust-by-example/primitives/array.html
Could you give an example? I don't understand what you mean by "gofmt allows padding blocks".
Great article. I liked it even just for the &gt; If the implementation is perfectly efficient and uses full memory bandwidth (roughly 100Gb/s for DDR4), filling the entire 64-bit address space would take 16,000,000,000 seconds - or 500 years. bit. It's a great answer to '128bit when' that I never knew I wanted.
I feel like that's more a function of us slowly figuring out what we want our policy on this to be. We haven't had a culture of applying for CVEs for this stuff, especially because many of these are kinda one level removed from a typical CVE (not necessary vulnerabilities, but APIs that can be accidentally used in a way that's vulnerable). There's a spectrum of unsoundness bugs in Rust -- ranging from "it's possible to accidentally use this" to "nobody's going to accidentally write code that exploits this, we can ignore it" The latter includes things like weird [dyn trait unsoundness bugs that are hard to stumble upon](https://github.com/rust-lang/rust/issues/50781) as well as things like the ability to open `/proc/self/mem`, which isn't something we'll ever fix. I don't think we've quite figured out what our bar for considering something a "security issue" is. You can see [pcwalton's comment](https://www.reddit.com/r/rust/comments/988euh/how_rusts_standard_library_was_vulnerable_for/e4guu52) for why it's somewhat reasonable to not consider many of these as vulnerabilities (and yes, I see your response there, but I don't think it's that simple especially for bugs in old, unsupported, compilers).
Personally feel the exact opposite, I don't care if the code is not formatted exactly the same, as long as it is readable. I try to avoid auto-formatting tools. I only use them only in case the formatting is absolutely wrong. A source code carefully formatted by hand, even if it is not formatted according to my preferences, is usually much more readable than a automatically formatted source.
Yes, line length is important to me. I fairly rigidly stick to 79 columns. But, I've done that successfully with gofmt.
I read that, thanks! I think that's a very useful pattern for linear access, which I think this case was - only skimmed. I guess there aren't any useful patterns for non-linear access short of proof based tools. Like, if the first and second half are going to be filled separately, and perhaps at different times, I know you can unsafely slice both parts of the array, and treat that as a safe abstraction, doing whatever you need to do on each side. But I don't know if there are good purely safe patterns like this. 
&amp;\[T\] is a so called fat pointer. So it is actually twice the size of a normal pointer, containing both the pointer and the length of the slice it points to. The slice it points to is just one T after another in memory, with no length information or anything.
Ah so we can basically only have fat pointers to slices? Things are starting to make a bit more sense now. Is it correct if I say that a reference to a trait object is also a fat pointer since it contains the data and vtable?
The `Capstone::disasm()` functions call the `cs_disasm()` C function which allocates and populates an array of `cs_insn` structures. The `cs_disasm()` function eagerly populates the array. The `Instructions` Rust type contains a reference to the array allocated by `cs_disasm()`. The `Instructions::iter()` method returns a `InstructionIterator` that "lazily" returns `Insn` instances. The `Insn` structure contains a `cs_insn` type. 
Also the compiler can optimize out unneeded variable initialization when it can prove the initialized value is never used. And initialization is also often really *cheap* anyway. It seems an odd thing for people to worry about.
[https://eslint.org/docs/rules/padded-blocks](https://eslint.org/docs/rules/padded-blocks)
You misunderstand. I'd ignore for *my* projects. Of *course*, I'd follow whatever formatting convention is established for projects I'm contributing to. (That said, if one of my projects became serious, I'd still have no qualms adding a "format canary" to automate the process of refusing obvious cases of "PR submitter ran rustfmt in violation of project conventions".)
The whole point of automatic code formatters, in my mind, is to *stop* style arguments by deferring the problem to a program that just solves the problem and lets you get on with life. I really don't care what the style is as long as I never have to worry about it. It doesn't really matter for personal projects but the problem gets far bigger when you start working on large projects that have many people collaborating.
If your objective is simply to send a json through a POST request, you can check reqwest which is easy to use https://github.com/seanmonstar/reqwest
&gt; You can control visibility at a finer level with pub(crate), pub(super), and pub(in path). Snap, I thought that `pub(super)` and `pub(in path)` were nightly-only. Thank you! &gt; Rustdoc doesn't document private details by default (and until recently there wasn't a stable way to do so). By making that a full crate with a public API, I have a documentation page to pull open. Very nice point. I've wished for that a time or two, I confess. I like the way you make those decisions, at least. Maybe we need a good write-up on the logic of this sort of stuff.
What does that mean? That all those let statements are made in one "operation" so the Compiler already knows that "a" should hit the stack as the last element?
I think the idea is to use it only in their repos.
I've seen `rustfmt` do weird things but it seems to get better over time.
You're not linking to the Rust book so I can't see context, but I'm guessing that it implicitly says "the stack is LIFO, unless you change the order yourself", which is what you do with the `drop(a)` statement.
Why? What's the point? It's not even a question, just a statement.
Please don't stop asking questions because of one angry guy. If someone thinks this thread is a waste of time they should just close it. I thought it was an interesting read.
Assuming you have a function those are in that looks like: ``` fn foo() { let a = 11; let b = 33; let c = 55; drop(a); } ``` When this function is called, a frame is pushed onto the stack that looks something like this: ``` --- a b c --- ...rest of the stack --- ``` (there's more stuff in the frame, but it doesn't matter for this purpose.) Dropping values doesn't cause anything to happen with the stack. The stack looks exactly the same before and after dropping `a` - this means `a` still exists and everything. Rust simply won't let you talk about it after it's dropped (and, if it implements `Drop`, it will trigger some code to run.)
Ah, great tip! I'll do this. I've received a few PRs like that as well.
Yeah. Don't install via Homebrew, I ran into some difficulty with that version and trying to do cross compilation
It looks like you're trying to make the compiler complain if `byte` is not inside the `MyVec(Vec&lt;&gt;)`. AFAIK, Rust does not support that. Try rethinking your problem at a larger scale. If you're used to using pointers, I wrote [a small guide](https://github.com/diwic/reffers-rs/blob/master/docs/Pointers.md) a while ago that might be helpful to you.
Wrong subreddit. Check out /r/playrust. 
I don't think it's that ugly. You can remove the `Ord` and `Clone` bounds as the code runs fine without them.
That's exactly why I specified "good defaults". If there are good defaults, then just stick to them :). Just like you decided "hey, there is an autoformatter, we'll use it", it is a small jump to also decide "hey, for whatever languages we use, we'll just use the default settings for whatever formatter we use, no fiddling allowed".
Avoid writing explicit parallel code, where possible. Use something like [rayon](https://github.com/rayon-rs/rayon) for data parallelism. And follow the Rust / Go rule of ['don't communicate by sharing memory, share memory by communicating'](https://stackoverflow.com/questions/36391421/explain-dont-communicate-by-sharing-memory-share-memory-by-communicating).
I'm trying to squeeze out a lot of performance from my application. is the collect&lt;Vec&lt;\_&gt;&gt; call going to be expensive and take up extra space?
link to the ordering bug?
One option is to have a second enum that excludes `Entity`. pub enum LightCharType { Separator, Link, TokenPart, } And your main one is that plus `Entity`. pub enum CharType { Light(LightCharType), Entity, } And you can give your `Filter` an associated type which allows you to differentiate between these. pub trait Filter { type CharType; /// Returns a CharType the informs the tokenizer on what to do fn on_char(&amp;self, c: &amp;char) -&gt; Self::CharType; } And now your `LightTokenizer` can be specified to work with `Filter&lt;CharType = LightCharType&gt;` while your `Tokenizer` can specify `Filter&lt;CharType = CharType&gt;`. I'm not fully remembering the rules around specifying equality for associated types like this so you might need an extra trait or something like `CharType: AsRef&lt;LightCharType&gt;`.
You don't need the collect call, I just used it for printing easily.
I'm afraid it would slow the matching, am I wrong?
&gt; now the program is just "guaranteed" to read zero'd garbage. That's a big 'just'. It's the difference between disclosing secrets and disclosing... a bunch of zeroes.
Is there some box where i put my email in the box and it tells me later when this book is available in beta or whatever?
No idea -- I'd try reaching out to the author on twitter: https://twitter.com/KevinHoffman
 &gt; Oh okay. It seems a bit strange, probably because I can't recall having seen code formatted like that. That's just not possible, I can find examples everywhere. &gt; I'm not going to argue with your "sense of aesthetics" jab :P but what does this have to do with Vim? select a paragraph motions in vi will snag the last brace
Döner &lt;3 &lt;3 &lt;3 &lt;3 &lt;3 &lt;3 &lt;3 &lt;3
Hey, I have a couple of questions/points about some of the things you brought up. For the argument parsing with the map function, it didn't work the way you wrote it. I suspect it is because the map\_or function in that state is currently either returning an Option or a Result&lt;f64, std::num::ParseFloatError&gt; in its current state. I tried all sorts of things to make it work while properly handling errors, but I kept getting compiler errors involving std::option::NoneError, which as far as I can tell is a nightly only experimental API. Was I misunderstanding something there? I did end up changing that part of the code anyway as part of storing the money values as pennies instead of float, but it may still be able to be written close to the way you suggested. Also, I'm having trouble figuring out how get\_by\_name could be simplified by the 'contains' method on \`Vec\`. Everything I tried to do with it ended up being more complicated. Do you have any suggestions? 
Right, but there's still a bug. A bug which could have a variety of nasty effects, including expose user data. I agree that it's not as extreme, and it's better practice, etc etc., it just is something I think worth mentioning, cuz the article didn't really. 
I love seeing everything styled the same - which is exactly why I need rustfmt to be customizable at my company. I might be somewhat in the minority, but my company has rather strict style rules, and these rules are followed through C++, C# and JavaScript code bases with minor differences (ie. in everywhere else we have braces on the following line but in JS we specify them to be on the same line to prevent ASI). Sure there are language specific rules (how to write lambdas in C++), but most of the brace/spacing/etc. rules span multiple languages. In C++ it's all up to the developers and reviewers. In C++ we have our own style tools. In JS we have our own eslint plugins. The fact that rustfmt can be customized to abide by the company's internal style guides makes things _more_ consistent, even if that closed source codebase might not be consistent with the open source projects. If rustfmt wasn't customizable at all, my company would just opt to not use it, which would reduce the language penetration and increase the style inconsistencies (not _everything_ is specified by the style rules to the same extent rustfmt enforces them).
Learn the easy types of concurrency and use them as appropriate. Learn your context and targets. &amp;#x200B; Example: At work we have an IO bound system component which should be on a system with plenty of memory and cpu to go around. We \*did\* want to lower the spikes of cpu usage and 'smooth it out'. To do this we added some concurrency and it worked well. Each thread had their own configuration which described the unit of work they were working on. Each one could completely ignore every other and only the results needed to come together at the end. Instead of locking on this configuration we just broke the configuration up into the different parts and handed it out \*and simply cloned the data that was shared\*. The cloned data was something like a few hundred bytes per thread, basically nothing. There was absolutely no need to share it, lock on it, confusion, blah blah. none of that. just do the simple and easy thing and move on! Context. know what you are trying to do, why you are trying to do it, and what places you can give on. You don't need to smartest solution, you need the best solution for your problem. &amp;#x200B;
&gt;Rust simply won't let you talk about it after it's dropped Ahhhh OK. That makes more sense then when you think about a realistic scenario, where loads of variables are put onto and off the stack all the time. Thanks!
[https://www.ralfj.de/blog/2018/07/13/arc-synchronization.html](https://www.ralfj.de/blog/2018/07/13/arc-synchronization.html)
Strongly consider if the Actor model will work for your use-case. It won't eliminate all race conditions/bugs, of course, but it does make certain aspects of parallelism much easier to think about.
Could you post a GitHub or GitLab repository with everything set up to `cargo run` or `cargo doc`? You're much likely to get good reviewers if you can make it a bit easier to get to the code and work with it. If you need any help setting up a repository, let me know.
&gt; e can also be named .rustfmt.tomlif you're outside the Windows world and want the file hidden. Why would anyone want to hide it? It is an important part of the source code. Do people do `.LICENSE` or `.CONTRIBUTING.md`? :D IMO bad idea.
&gt; we can basically only have fat pointers to slices? slices (`&amp;[T]`) are fat pointers. arrays ('[T; n]`) are simply T's in sequence in memory, handled fully at compile time DSTs (`[T]`) are quite exotic and _don't really exist_, only way to look at a DST is via a slice, and only way to store a DST is on the heap.
Done
Done
Rust Qt Binding Generator had a demo app that shows system processes. https://www.vandenoever.info/blog/2017/09/04/demo/screenshots/demo.png shows there is a 'processes' tab. 
Crate author here. I still plan to remove the -rs. I don't know when, I've been quite busy with other stuff recently and just started to find time to dedicate on the crate again. Also, is there an easy way to rename, or alias a crate? Or should I just create a new one and deprecate the old one ?
Wrong subreddit. You are looking for r/playrust.
I'm glad you like it. Next steps are rowspan and using textwrap to limit columns width. For sure, any help would be welcome
Did you even look at the sub before posting?
Pretty sure the fact that gofmt permits padded blocks is more a big than a feature. 
`memcpy` is just a function that takes 1 or more contiguous bytes and copies them into a different memory location - any location whatsoever (it can copy from stack to heap, heap to stack, stack to stack, etc.) That's why it's efficient and useful for stuff like integers - you can just copy the 4 bytes that contain the integer's data to somewhere else. `clone` can be implemented completely differently based on what structure you're cloning. You could totally have a `clone` that calls `memcpy` - and that's what any type that implements `Clone + Copy` does. On the other hand, if you want to make a "copy" of a `String`, you can't just `memcpy` it - if you did, you'd have two owning pointers to the same heap data and modifying one `String` would also change the other. So `String::clone` has to do some extra work; it needs to allocate new space on the heap, and then the internal string data from the first `String` can be `memcpy`ed over to the newly allocated space.
No idea, i just want to help the poor guy out :p
Thanks for your insight. Very interesting. Just one last question: How do you know all this? Is this standard CS knowledge? Does the average Rust programmer know all these bare-metal details? 
yes! hard tabs are the best tabs
Yesterday I google common rust mistakes and only this results relating to this game showed up. This was even after I put “rustling.”
I would go for linode + docker compose with an nginx proxy. Bit manual but gives you more control.
I'm glad to see this title in the making. My only request would be really cater to the "Rust" portion of the title - if that indeed is the final name. And what i mean is that currently, it appears that just about everything that deals with WebAssembly is ultimately sort of a stopgap or in between step, to eventually end up working with Javascript. I personally would prefer to do an entire application - web, desktop and mobile - in WebAssembly with just Rust. So yes, JS might be the language of the web, but WA isn't just for Web as the name implies and for the other platforms, JS isn't the panacea it's painted to be. I rather code in Rust. Rust all the way - no offense to JS.
Show your code!
Remind me in 10 months
Won't that be outdated the second it's released?
If there's a tradeoff between targeting "people who mostly use JS but could be persuaded to learn some Rust" vs "people who are already enthusiastic Rustaceans", it might make sense to target the JS people, if only because there's 100x more of them.
That's true.
Tower is progressing quickly and I'm very excited about it! I may have to give it a shot for an upcoming project...
For those looking for a Rust &amp; WebAssembly book now, I've recently went through the [rustwasm](https://rustwasm.github.io/book/) with great success.
On my blog I wrote about hosting Rust web apps, I don't know much about webfaction though. https://vishus.net/content/tutorials#all-tutorials-&amp;-code
Yep, it should probably live in the web until the whole thing stabilizes..
Immediate comment - use a toml file for config instead of a slew of environmental variables. Optional parameters can be made as Option&lt;T&gt; in your config struct. Use serde &amp; toml crate to read the file, and then you can pass the config struct around as you please (as it is non mutable) 
Noob question, is it reasonable to write non graphic intensive web apps? (e.g. chat app, not image editor. CMS, not video game) Would it perform better/worse compared to DOM+JS?
To the first problem: let gi = g.map_or(Ok(None), |x| x.parse::&lt;i32&gt;().map(Some))?; The issue was that the one I gave you returned an `Option&lt;_&gt;` as the first argument and a `Result` as the second. That error message was really poor though. This one returns `Result&lt;Option&lt;_&gt;, _&gt;` and `Result&lt;Option&lt;i32&gt;, ParserError&gt;&gt;`, which are compatible. To the second: For some reason I thought there was a `contains_by_key`. There isn't. Your program does allow multiple funds with the same name now that I look at it though, the later entries will never be accessible though. Might look into adding some error handling or switch to funds being some type of lookup table instead. 
So delete this post and put it in the right sub?
Did you take a look at this subreddit before posting??
Ok thanks, I didn't think about trying something like that, I'll give that a shot. &amp;#x200B; Yeah realizing it allows multiple funds with the same name is why definitely don't regret going ahead and implementing PartialEq anyway. Allowing multiple funds to have the same name would definitely be considered a bug in the current design, and if I can use contains on a Vector of Funds fixing that becomes trivial. The alternative would be using id's instead of names to identify Funds, but that adds an extra step for users, since they have to first look up the id of their fund instead of just typing the names.
Hi, Even creating a brand new project and importing `std::io::Error` I get the following: https://cl.ly/6757255ff1ef
This is not quite right. `[T]` [is a slice](https://doc.rust-lang.org/std/primitive.slice.html), which is only one kind of dynamically sized type (`str` is another kind, for example). `&amp;[T]` is a reference to a slice, which is not dynamically sized (it's a fat pointer). It's not really correct to claim that DSTs "don't really exist"; they exist both at the type level^(1) and actually in memory at runtime. Additionally, since arrays can coerce to slices, slices do not necessarily have to be heap allocated. There are certain operations that can be performed on DSTs. Operations that can be done directly on DSTs are generally annotated with `T: ?Sized` (although they could not be if the operation isn't generic). &amp;#x200B; ^(1) One of the crucial aspects of DSTs is that they allow types like `&amp;[T]` to dereference to `[T]` instead of `T` (like they would in C)
Not necessarily. Detach the name from the fund. Your data structure becomes a dictionary of String keys and Fund objects, which may or may not contain the same String used as the key. 
Not an invalid question, but I feel that the phrasing could be somewhat off-putting -- feel free to disagree. We should keep our standards high and be welcoming, even if this guy's never heard of the Rust programming language before! :)
Btw, I also tried on Clion 2018.2 and 2018.3, same result.
No purpose, really. Unless you're having performance issues, there's not much of a reason to rewrite in wasm.
We're pretty dang web already. Try building a prototype, you'll be pleasantly surprised at the ergonomics of the ecosystem
That's exactly what I was worrying about, I'll go with the full duplication as it provides more modularity anyway ! The impl became quite verbose now though, do you know if it possible / a pattern to create aliases in the impl blocks and do something like this: ```rust impl Filter for MyFilter&lt;CT = CharType&gt; { // Doesn't work ... CT::Separator =&gt; ..., } ``` I did a `type `CT = CharType` at the beginning of my file so the code now looks like ```rust impl Filter for MyFilter&lt;CharType&gt; { ... CT::Separator =&gt; ..., } ``` but it feels a bit weird to me, do you a better idea ?
Thanks for the follow up. I can confirm I am seeing the same behavior.
I studied EE and I'm now an "engineer" (technically here in Italy I'm just a "Perito" based on my degree, but elsewhere there's no concept of "Perito" so the equivalent title is engineer.), but I'm basically 100% self-taught (high school only had basic classes for C and a badly done Assembly course for a dead architecture) and I do know how memory works. Generally speaking, all professional low-level programmers know how memory works, since you might have to get some extra performance or know what your code is doing while debugging. FYI, before I started programming I played a lot of games (I still do) and that lead to try to cheat in them! This is when Cheat Engine came into my life and I started to gain some insights on the computer world (mind I was just a kid but I at least understood how to search for a value, occasionally trying to make sense of the memory browser). I started to get into programming in 7th grade with Minecraft (wanted to try making a mod in Java), dropped it for a while and read articles I found browsing the web (like today's vulnerability on popular crate), and finding myself more and more interested on low level stuff. Around this time I started Assembly (11th grade) and, even tho it was pretty badly explained, I really enjoyed it since I was free to mess around with memory and get as low as I could. I moved from Java to C++ (in parallel with school, with a drop of web development stuff and python) since I was really into gaming and wanted to land a game dev job. This is when I started messing around with pointers and memory and eventually learned a whole new world: Reverse Engineering. I started reading articles about RE and I'm pretty confident I got my low-level stuff solidly grounded in my brain. I continued with C++ and then last year, while completing my studies, I found Rust. TL;DR: Most low-level programmers know about how memory works. My advice is to try to get a good, but general, understanding how memory works. You should know how pointers work, what's the stack, what's the heap, how the heap's allocated and how the stack works. Also if you want to tickle your curiosity learn what's a stackframe.
Correct me if I'm wrong, but wouldn't that still cause the same issue with users not being able to reference their funds by name if they have two of the same name?
So is there one stack for the entire operating system and all running programs or does every programm have its own stack?
I'm not sure I understand what your complaint is. Maybe post a fuller example with what you see as verbose? If it's just the excess from `CharType::`, you can import all of the variants at once with `use CharType::*;` then match on `Separator` directly.
You're looking for /r/playrust.
I am pretty familiar with all the Rust memory management. I get the stack, heap, allocation, etc. I just am not that familiar with the ultra-low-level stuff. Like my above question about how a stack can actually be LIFO. Since you seem to know your stuff pretty well, one question: Is there one stack for the operating system and all running programs or does each program have its own stack? and heap?
Thanks, just came back to link to the github issue :)
Technically, there's just one stack. I wanted to give you some more information but at the lowest level it's just 1 part in memory with values one after the other. At the Assembly level each routine (you could call them functions) can change the stack as they want but then you'd just mess up a whole lot of stuff. Say: my routine pushes 3 items on the stack, then pops 4: my routine just pop'd a value from the stack that the routine didn't own (and was owned by the caller for that matter), so when I give control back to the caller it might have been expecting to own 3 variables but I stole one of them, so now the caller's gonna steal from the other until at some point the whole system crashes. Of course the higher you go in level the more checks there are so you don't BSOD (or do you?). Say my program tries to do the same stack thing in Windows (note: you don't have access to the stack in any programming language that's higher or egual in level to Assembly, since at that point the stack is managed by the compiler), the program would just get killed by the OS (ever heard of Segmentation Fault? It's akin to that).
I answered the stack on the other thread, so I'm gonna answer heap here. Same deal with stack, 1 for all at the super low level (Assembly). In practical terms (running your program in an OS), each application gets some memory for itself, and can use it however it likes, therefore there's some memory allocated to hold stack's data, some memory allocated for other info, and what remains is the heap ("free memory"). The heap is just a way to refer to memory that has not been already allocated by the compiler, and can be used in the runtime. You can't access another process memory (stack or heap) directly (in theory). You must use your OS's API or get the program killed (Segmentation Fault in the best case or BSOD. The program not being killed without the API being worst since it's a security vulnerability).
As far as I can tell rustfmt tries to be idempotence against the AST, whereas gofmt against the source.
Every process has its own stack (and its own heap; each process runs in its own memory space.) (Technically, each thread in a process has its own stack, but they all share the same memory space, and if you're only running a single-threaded program in a process, it doesn't matter.)
Hey, I think about that kind of stuff all the time, and I'm just 19! I guess I'll get old fast ;) 
Ah yes of course. I should have known that. I once read something about how goroutines in Go work and I think it was talking about this also. Every goroutines has its own Stack. Thanks for your help!
Well seems like all that thinking has clearly paid off! Good on you.
JS isn't really suitable for getting good performance out of wasm. And if you're not doing it for performance, then why not judt serve the JS in first place (I guess you get a parse time win, but that's a very different use case...)
I see. For the dictionary route, do you have any suggestions of what crate to use? The standard crate's HashMap will update the value if a duplicate key is inserted rather than returning an error, as does any other crates I've found so far.
The computer world is huge, I think of myself as a newbie
Well, you most certainly wouldn't write WebAssembly directly (as you usually don't write normal assembly). Instead, you would write your web app in a language that compiles to WASM. And the best one for that purpose is Rust, obviously ;-) And in that case, you get all the advantages of Rust. Speed is one great thing about Rust, but it's not the only one: what about safety and robustness? So yes, I think it's absolutely worth writing a webapp in Rust instead of JavaScript because Rust's type system will prevent many bugs during compilation. Maybe it's not quite worth it yet, especially for small or unimportant applications. It's still a bit of a hassle to setup everything with Rust and WASM (it got *a lot* better tho) -- at least compared to simply including a `.js` file. But: (a) for bigger projects (or more important ones) this setup time is negligible, (b) it will just get better (e.g. load WASM as ES modules in the future, feature complete `web-sys`, ...), and (c) setting up a bigger JS project with bundler thingies, other tools and so on also takes time. As a last note on speed: soon several WASM proposals will land and then WASM can access the DOM natively (without going through JS). With that, WASM will outspeed JS even for "just" DOM related stuff. And given the status of the sluggish web today, more speedy websites would be a welcome change.
Like a browser window? 
It's exactly this! I didn't I could use `use` inside a function, many thanks ! For the second one, I realized I did something very dumb, forget about !
You should be checking if it already exists rather than overwriting it. 
I used to use webfaction, and they were pretty great, but I endes up moving for cost reasons. You can get a VM with vultr or scaleway for 1/4 the price, and setting up nginx is pretty easy these days. That said, you should be able to run rust binaries on webfaction pretty easily. You just need to choose one of the application types that gives you a port to bind to (I believe the node.js one does for example). Then upload your binary, and run it via ssh. You might need to edut some scripts to get it to restart after server maintenance (again this stuff is easier on your own vm). If you're not developing on linux, then you can either use Rust in docker to compile a limux binary, or install Rust (via rustup) on your webfaction server, upload your source code and compile it there. This might be slow though.
It's by convention that the constructor of types are called `new` impl SomeStruct { pub fn new() -&gt; SomeStruct { //stuff } }
Oh I see what you mean now. I thought you meant that the "Dictionary" would automatically return an error if I tried to insert a key that was already present.
I decided to switch to DuckDuckGo as my main search engine driver to prevent Google's tracking, but all my queries related to Rust only showed results about Rust: The Game. I gave up after a week and switched back to Google.
I have found [Zeal](https://zealdocs.org/) to be decent at this. I don't know of any built in plugins. I believe most Rustaceans just use a browser window with the docs pulled up.
Yes? I said that. :-)
I've been doing deployment using docker. So far it has been pretty painless. You just build the app using the Rust docker image and everything is good to go. The one issue I've found is that the images can be rather large in size. I haven't experimented getting things working with alpine linux yet.
I think this is a bit more pessimistic than need be: the overhead of going from wasm through JS to access the DOM is currently a single out of line function call, which is pretty light all things considered. It doesn't need to be *that* long-running of a computation for that cost to be dwarfed by all the actual work you're doing.
Absolutely correct, but we use some old ass AMI which doesn't work on C5s because of a virtualization incompatibility. I need to get around to updating that...
Is there any way to include a `CStr` in the binary like `include_str!` does with `str`? I have some code that calls a C API with a large, constant null-terminated string and it'd be nice if I didn't have to convert it to a heap-allocated `CString` first.
Oh, right. Sorry
/r/playrust
You're on the wrong subreddit, you're looking for /r/playrust
This is super interesting, but less about Rust per se and more about how computer architecture and data structures interact.
Sort of. It's also very much about why and how the design of Rust tends to encourage software design decisions which tend to behave well when executed in modern computer hardware.
Which is you know what else is about? Something called Rust :)
I'm sick of this rubbish and in this instance the op doesn't even care enough to delete their post after having read the comments telling them of their error. It's irritating and lazy. As far as I'm concerned "off putting phrasing" isn't an unworthy goal in this instance.
Your laziness astounds me.
Very interesting. Nice graphs, too. I'm quite happy with rust's speed in general. I find that if my rust code is slow it's pretty much always because I've coded something inefficiently; the language is pliable enough to express whatever low-level operation I want, usually without even dipping into `unsafe`. One note I'd make is that you could get a small speedup on your hashmaps by switching to a hashing algorithm specialized for small integer keys, like [fxhash](https://crates.io/crates/fxhash). I expect most of the workload there isn't in the hashing, but little bits still help :)
Oh so it doesn't actually effect anything, thanks!
A technique that I like to follow: 1. Avoid shared mutable state(anything inside an Arc&lt;Mutex&lt;&gt;&gt;). 2. Avoid sharing reference from one "component" to another(like having a Arc&lt;Mutex&lt;SomeConcurrentComponent&gt;&gt;). Instead: 1. Keep mutable state encapsulated "inside" a concurrent component(so you could have something in a Cell, or just a plain HashMap/Vec), and have only that component mutate that state inside the thread it is running in. 2. Share the sender half of a channel to other components. 3. Structure the "processing model" of your component as a while loop inside of which the component will receive messages on the receiver end of a channel, and handle those messages in a set of predictable steps happening at each "iteration". The way to quit is to return false in the while loop. Example of such component(currently WIP): https://github.com/servo/servo/pull/21673/files#diff-32c6131016718303d2824e09234521b1 It becomes pretty hard to deadlock when the only 'multithreaded' part of your code consists of sending/receiving messages on a channel, especially if it's an un-buffured one. Iteration inside a single thread is also pretty intuitive and familiar, so structuring the "business logic" of your concurrent component in that way is usually helpful in avoiding not only deadlocks but also logical bugs. I quote from another answer that "Rust does not prevent you from doing things to a shared structure in the wrong order.", which is exactly why receiving messages in a loop is great, because the order of your business logic is represented by a set of steps happening sequentially inside a single thread and any data mutation is done as part of those sequential steps... If your code actually needs some sort of request/reply cycle which would need to be "sync" from the client perspective and that you feel woudln't fit in such a "run loop" as described above, you can have the client send a message to the component, representing a "request", and include a sender in the message on which the "reply" can be sent, with the client in the other thread blocking on waiting for it. See for example https://github.com/servo/servo/blob/60b926ade443ad65ff538a57e2f40727c68b4cfb/components/script/dom/windowproxy.rs#L227 Sometimes you're not really writing a 'component', but rather something that represents a shared mutable datasource of some kind, and in that case it might be more natural to indeed share it directly between the various clients (for example inside an RwLock) and also protect it's internal data with mutexes, see for example an HTTP cache at https://github.com/servo/servo/blob/97e3c5f3a9158080b6e9b8d654b4ea3c285c722f/components/net/http_cache.rs#L61 (although one could also structure such a cache using request/reply messages as described above)
Is there a functional difference between these two lifetime annotations? ``` fn foobar&lt;'a&gt;(arg1: 'a SomeType, arg2: 'a SomeOtherType); fn foobar&lt;'a, 'b: 'a&gt;(arg1: 'a SomeType, arg2: 'b SomeOtherType); ``` And generally, which is more appropriate in which situation?
I get a `implementation of `std::cmp::PartialEq` might be missing` for a generic struct that has `derive(PartialEq)`: https://play.rust-lang.org/?gist=530a917f45336829b844f69399d3310e&amp;version=stable&amp;mode=debug&amp;edition=2015 Any idea what is going on?
If the constructor takes an argument there is also the convention to name it `from_XXX()` (often returning `Result`).
I'm not 100% sure, but it seems reasonable that autoderiving only works if all fields are implementing `PartialEq`. You need to constrain the `T` in your `impl` with `PartialEq`.
Very cool article! Since both programs perform quite similarly with a constant offset, it might be a good idea to compile the C code with LLVM (clang), too. And, because it's easy to do so in Rust, you could try out some other data structures, e.g. the persistent map from the `im` crate. I don't expect either of these to significantly change the outcome, though.
Hm. In this case i would have expected a compilation error for the struct definition.
That's what I have been using, so no, not a browser window. 
That's more like it! We only need plug-ins / add-ons now... 
The UI in IntelliJ works like this: http://i.imgur.com/OB3DdtF.png
I don't see how an extension that opens a separate window will be different?
Hi all, Rust in August/September 2018 progress report for [Rust in Action](https://www.manning.com/books/rust-in-action?a_aid=rust&amp;a_bid=0367c58f) is a book on the Rust programming language for intermediate programmers that teaches Rust via systems programming examples. Its dual aims are to demystify Rust and systems programming. I didn't provide an update in August and that has prompted me to explain why. It's actually the first time I've told the world that I have a mental illness. Hoping that those people following the book's will understand!
Ultimately, when you compare languages like C, C++ and Rust, which are by-design on equal footing, you can essentially only compare how easy it is to write performant code or how performant idiomatic code is. Modulo optimizer deficiencies, if you implement the exact same datastructures and same algorithms in these languages, they will perform the same.
That's what I was looking for, basically. 
Browsers are heavy and noisy. Also you might be offline
Use `parking_lot` synchronization primitives and enable deadlock detection.
Except there are races *other* than deadlocks. I'm not even sure a deadlock is a kind of race. In my case, unless `parking_lot` has a type that can upgrade read locks to write locks whilst reasserting external invariants, it wouldn't have helped.
Thanks for sharing your thoughts on this! I am quite eager to get the book because i have read the parts already available and its without a doubt one of the best i have ever read. At the beginning of the year i was hoping to get me a nice Christmas present but to be quite honest i am feeling a little bit bad after i read your post. Its not that i was demanding in your particular case here but i know myself that i can be quite like that. Reading this i came to the conclusion that i make this book my Christmas present whenever it is released – no matter the time – because i think this will be a better Christmas present than all the others for quite some time :D Please take your time! I which i could give you some relieve by saying "i understand what you're going through" but i really just can't. I don't know how real anxiety feels or what happens inside at a panic attack. I had a friend with panic attacks and no matter in how much detail he tried to explain this – i don't feel like i have ever understood. I whish you the best things to happen in the future and that you know that i am happily waiting for the result of your awesome work no matter how long it takes for you to reach this goal healthy! 
Browsers are only as noisy as you make them tho. If all those icons annoy you during the reading of docs, they will annoy you during normal surfing... Also, you can still open the docs with ``cargo docs`` when you're offline.
Small nit: `--release` is `-C opt-level=3` not `-C opt-level=2` (so for a fair comparison, you want clang with `-O3`).
kind?|C++|Rust :--|:--|:-- value|`int`|`i32` reference|`int&amp;`|`&amp;i32` ---|---|--- array|`int[N]`|`[i32; N]` array ref|`int (&amp;)[N]`|`&amp;[i32; N]` ---|---|--- slice ref|`std::span&lt;int&gt;`|`&amp;[i32]` In the above table I try to compare different types between C++ and Rust. In the first group I compare integers and references to the integer. In the second group I compare fixed size array of integers and references to these types where N is a compile time fixed number. In the third group I compare what a reference to slice (a number of values of type T sequentially in memory) look like in both C++ and Rust. The pattern here is that in the first two groups I always talked about the value type and references to the type, extending this to the last group, what is the 'value' type of a slice? C++ does not have an answer, it already required a library type to talk about references to slices (implemented with a pointer + size, aka a 'fat' pointer). Rust makes this consistent and extends its type system with `[i32]` (just drop the `&amp;` part). This type is different as it is meaningless to create instances of this type. But that doesn't mean the type system can't talk about it! Eg traits and implementations can work perfectly with such types without creating instances of it. Because of its dynamically sized nature, Rust calls them DST or dynamically sized type. In a sense this is far less magical, more consistent and uniform than in C++. Does that help?
Sadly `match_block_trailing_comma` is only available on nightly :( unstable_features = true match_block_trailing_comma = true
I hadn't seen that before (thanks for linking!). It's a little surprising to not see stdweb mentioned at all, though. It won't be the case for much longer, but currently, using wasm-bindgen means not using a stable version of the compiler, which might be unworkable for some projects in a business setting. I love wasm-bindgen and am eager to be able to use it for work, but stdweb and the tools/libraries built around it enabled me to write and commit fairly ergonomic code for a small internal tool that would probably remain a local prototype if I couldn't compile it with a stable version of rustc. Minor extra note: Emscripten's ability to also target asmjs as a fallback was useful as, in my particular case, running the tool on older browsers was a goal.
Interesting, I always though it mapped to `-O` which IIRC corresponds to `opt-level=2`, but you're completely right, dumping the build plan does say it's 3. Do you know why?
If you use lockfree data structures, then locking bugs won't happen (such as deadlocks, livelocks). Stuff like lockfree queues and hash tables etc. If your stuff is also wait-free then it also protects against starvation. So generally speaking, if you only use atomics you eliminated a large class of bugs (at the cost of being __locked out__ of some algorithms, heh). But if you use atomics directly you may have added some atomicity bugs (that will show up as race conditions); you will have fewer of them if you limit yourself to sequentially consistent orderings. Or just avoid handling with atomics directly. If you opt out of interior mutability completely (which include atomics), then you won't have race conditions (at least not in your code). But your data will also be read-only and you will be limited to functional programming patterns. Race conditions are a complex topic because sometimes you _do_ want your code to be racy, for performance reasons ([the rayon documentation has an example](https://github.com/rayon-rs/rayon/blob/master/FAQ.md)). And your interface with the external world will always be racy: you to synchronize with another processes when accessing files and network resources, for example. And this will sometimes involve locks, which bring back the locking issues like deadlocks. But if you have a transactional database (like Postgres, that uses [MVCC](https://www.postgresql.org/docs/9.5/static/mvcc-intro.html)) and have it as your only external interface, you can probably avoid most locking bugs.
&gt; more about how computer architecture and data structures interact. And more specifically, how the cache layers of modern CPUs *much prefer* array-based data-structures to node-based data-structures. However, it's important to realize that re-usable array-based data-structures are better implemented in languages with generics and barebone values (by opposition to Java Objects); and there's not that many such languages.
&gt; Furthermore, when using C++20's concepts, you can accidentally use behavior which wasn't part of the concept without a compilation error. I still don't understand why the C++ committee went down this road. I suppose it simplifies adoption in existing (ala gradual typing), however one potential big draw of concepts was the ability to state required functionality up-front and this "feature" completely negates it :(
Not that I know of currently, but it'd be a great starter project for someone looking to play with procedural macros. I'd be willing to mentor or if you want it right away I can throw something together this weekend for fun.
&gt; But in August, I had panic attacks for the first time since I was at university (about 15 years ago). WOW! As eager as I am to see the book released, please do prioritize your health and family over it.
Thanks for the info!
You don't necessarily need to jump to Alpine to get a smaller build size. I've had great success shrinking my docker images by using a multi-stage build, example here: https://blog.jawg.io/docker-multi-stage-build/
You're describing CGI.
This is known as CGI and has been around long before rust: [http://jkorpela.fi/forms/cgic.html](http://jkorpela.fi/forms/cgic.html) Should be possible with rust as it is a common interface but I don't know of anyone actually doing it atm. As far as I know php is the only popular language that uses it a lot, though there are some very old c and perl programs about that still do.
Tab length belongs to the author, the same person who breaks lines and names variables. Tab length alone doesn't matter much compared to those other stylistic choices. You can reformat your code to claim your freedom.
The multi-stage build certainly helps, but from what i can tell the smallest images are produced by statically linking with musl and using alpine linux. I'm talking sub-400mb size builds.
I bought the book primarily to support the the idea the author seems to be pursuing. The contents look great and I liked this style of writing/creating a book out in the open. Timewise (small kids + obligations in the side) I'm in a similar tight spot, so personally I'd much rather see the book finished *when it's done*, rather than seeing a rushed job because of some imagined obligation to the readership. Putting money into such a project comes with a risk (delays, the chance of not finishing it, etc), but that risk is so miniscule to the buyers that I hope everyone would understand that personal health and well-being come first. I hope you are going to be well. And also that I will find the time to read the book. :-D
That would likely be way too annoying and hinder the code reviewing... That's also harder to implement since you would need to actually be able to parse an arbitrary piece of Rust code.
Yes, it works. See the screenshot, one is from a patch on Mozilla's Phabricator I reviewed a while ago.
It may because the phabricator instance is on mozilla.com, though :)
AFAIK even PHP is rarely deployed on CGI, it's usually fastcgi (possibly FPM) or mod_php. And some tools still provide CGI support for easy (very low-constraints) deployment e.g. Mercurial's `hgweb.cgi` or fossil. Assuming your web server supports CGI anyway (nginx famously doesn't so you have to use fcgiwrap or some such).
A zero-day is a vuln which is actively exploited in the wild BEFORE the vendor of the product knows about it. If you find a vuln, report it and noone ever exploited it, then this is NOT a zero-day..
You should try using multistage builds, build the project using ekidd/rust-musl-builder to get a static binary and afterwards (depending on the project) you can use the scratch image. That way, your image will equal the size of your compiled binary.
In this case - no. In both cases inside the function you don't return anything, so neither of the references can escape the function - so it doesn't matter what is the relation between their lifetimes. In the first case you can pass any two references into the function, because covariance allows shortening the longer one to match the lifetime of the shorter. In the second case, you can shorted `'a` if it lives longer than `'b`, so again, any two references can be passed. One example where you need to use two distinct lifetimes is when you have a reference to a reference (or a reference to something that has a lifetime). For example: fn foo&lt;'a, 'b&gt;(x: &amp;'a mut &amp;'b u32) { ... } Because `&amp;mut T` is invariant in `T`, you cannot shorten inner lifetime. So if you instead used `x: &amp;'a mut &amp;'a u32`, then outer reference has to live as long as inner lifetime does, and you wouldn't be able to do anything useful with that function. This does not compile: fn foo&lt;'a&gt;(a: &amp;'a mut &amp;'a u32) {} fn main() { let mut x = &amp;32; foo(&amp;mut x); println!("{}", x); // ~ERROR: cannot borrow `x` } Because `&amp;mut x` borrows `x` for the lifetime of `&amp;32`, which is for the whole function - `foo`'s signature doesn't allow borrowing `x` for a shorter lifetime. This is quite an artificial example though - in this case you can simply not write any lifetimes and lifetime elision will do the right thing. Personally I don't think I ever had a case where I would need two distinct lifetimes where one would outlive another.
Is there any way to handle multiple statements errors with same handler without check it separately? Consider this example: fn one() -&gt; Result&lt;String, ()&gt; { Err(()) } fn two() -&gt; Result&lt;String, ()&gt; { Err(()) } fn three() -&gt; Result&lt;String, ()&gt; { Err(()) } I expect something like `try/catch` fn main() { try { one(); two(); three(); } catch (e) { handle_error(); return; } } But, I handle it like this: fn main() { let x = one(); if x.is_err() { handle_error(); return; } let y = two(); if y.is_err() { handle_error(); return; } let z = three(); if z.is_err() { handle_error(); return; } }
For me, this use case is classified as "eagerly", as if `disasm` method do mutate the `Capstone`, it does not when the iteration occurs. In other words, all data depends on mutating `Capstone` is retrived before the iteration. This means the iteration (or the `Itstructions` instance) shall not need to mutably refer to `Capstone`. It may still need immutable reference, and `disasm` do mutate `Capstone`, it will not be safe to run `disasm` while previous `Instructions` is in scope. Otherwise, if you still have lifetime issues, it might just be a use pattern issue, as in theory this API is good for valid uses. In that case, please post your actual use code and I can look at how to adjust it.
Why not print unsafe with MS Comic Sans?
Interesting. Thank you!
You could use return a Result in main like so: https://play.rust-lang.org/?gist=3874182833ba434be80bf1ee0032279d&amp;version=stable&amp;mode=debug&amp;edition=2015
I love the performance analysis esp wrt cache usage. It would be interesting to develop a probabilistic map between algorithms, CPIs and cache hit rates. And have this info available on a per commit basis to detect regressions. 
I deployed an app to Heroku using the [Rust buildpack](https://github.com/emk/heroku-buildpack-rust). I haven't had any issues, so I'd say this is probably the lowest friction way to deploy a Rust app.
You could use [cargo-profiler's](https://github.com/kernelmachine/cargo-profiler/), `cachegrind` mode, which can run on CI and will detect (simulated) per-function cache miss rates. The probabilistic map will probably take a bit more wrangling tho
Bear with me as I'm not to experienced at explaining the borrow checker But in both cases you are trying to pass a BoxOrRef type, there's no problem passing a ref like this into a recursive function. All of the arguments of the function follow_name work that way without issue. The issue is who owns the actual data? When you call the function follow_name the variable full_name is owned by the calling function and this reference is passed down recursively until the function is resolved. It's easy to see that reference to full_name will live long enough because the actual value lives until the end of the scope in which follow_name is called. Name and root are a little more complicated, they are references generated by a function call and held in the scope of the function, when you recurse who owns them? You will not be returning to that instance of the function, so the actual value of the reference will be dropped when it goes out of scope. What you implicitly are asking the compiler to do is "hey I made this variable, keep this scope around to own the reference until I'm done with it". In this case I'm not actually sure how you can tell the compiler that the reference should live until the base case of the recursive function, but I hope my explanation shines some light on what's going on. 
I'm with you that simply extending the inverted highlight this extension uses would not be the best experience. IMO, a light background highlight (instead of overriding background AND foreground colors) wouldn't be too intrusive -- some configuration there would be nice there. Maybe a good compromise to keep the "intrusive" highlight but not sacrifice readability would be to make the block fade out the highlight when the cursor goes over?
If your analogy applied, I'd definitely agree -- but it doesn't seem to. The Rust programming language community doesn't care for it, but that may not be true for the /r/playrust community.
Yeah, I just barely saw that. Grr, that makes it a LOT harder to want to be patient with this. That said, I believe it's worth being patient about simply thinking about the outcomes -- I don't want to give ANYBODY outside of the community reason to think this subreddit is not awesome. :)
Oh wow, I didn't know that landed. However std is precompiled, so you can't activate / deactivate features for it unless you compile it yourself via xargo or something. So it's quite odd that it landed like that while not really being usable.
As people said, wasm+Rust is probably slightly slower than pure JavaScript if most of what you're doing is manipulating the DOM. This may be the other way round once host bindings are implemented for wasm (and once wasm_bindgen makes use of it). Then Rust/wasm should be a little faster. However, if all you're doing is just manipulating the DOM, is performance really a concern? For a chat app or a CMS, I don't think it is.
To separate your web application into many smaller executables, you might be interrested in Kubernetes and containers in general if you have not looked into that already.
The problem is, that the wasm runtime makes no assumption about the host. Thus, the standard library cannot implement host specific features like time, threads etc.. IIRC, the solution was to let the user provide an implementation of these syscalls which the host would normally provide, hence the `wasm_syscall` feature. I assume that you're targeting the browser, so you have a js environment providing these implementations. For the time being, you can use specific wrappers for these targets, like [stdweb](https://crates.io/crates/stdweb) or [web-sys](https://rustwasm.github.io/2018/09/26/announcing-web-sys.html).
Totally agree with this. Sorry to hear of your troubles Tim. Here to help in any way I can. Thanks again for the book.
&gt;Furthermore, when using C++20's concepts, you can accidentally use behavior which wasn't part of the concept without a compilation error. I expect this to become a warning (which can be turned into an error) in all implementations pretty quickly.
At this point, I feel like source code shouldn't be text but instead an AST, then the editor can choose how to represent it.
Just wanted to also voice my support. I've bought the early access and really enjoyed it. I appreciate your drive to write the best technical book, and am excited for it to be ready when it's ready. Glad you were able to take care of yourself and your family, please continue to do so!
Personally, I am exceedingly happy with Rust's perf (coming from Java/Haskell :p)
Just a short look made one part of your code suspicious: `follow_name` takes `&amp;'a dyn Fmt&lt;'a&gt;`. Traits are always invariant over their parameters, so lifetime `'a` might be forced to be longer than you would want at call site (a bit similar problem to what I just described [here](https://www.reddit.com/r/rust/comments/9icmxp/hey_rustaceans_got_an_easy_question_ask_here/e6un87p/)). That's the source of your problems: taking a reference to a trait object asks for that reference to valid for as long as trait's lifetime parameter, which happens to be longer than the function's scope. Let's go through it step by step. First, here's a shortened example. I changed `BoxOrRef` for simply `Box`, removed all error handling, and most of the formatting parameters. Also, `follow_name` now recurses forever, but that doesn't matter for this example. [playground](https://play.rust-lang.org/?gist=3a45877fc87bb9423ecb43413c53888e&amp;version=stable&amp;mode=debug&amp;edition=2015) pub trait Fmt&lt;'a&gt; { fn get_subfmt(&amp;'a self) -&gt; Box&lt;dyn Fmt&lt;'a&gt;&gt;; } pub trait FormatTable { fn get_fmt&lt;'a&gt;(&amp;'a self) -&gt; Box&lt;dyn Fmt&lt;'a&gt;&gt;; } impl&lt;'a&gt; Fmt&lt;'a&gt; for Box&lt;dyn Fmt&lt;'a&gt;&gt; { fn get_subfmt(&amp;'a self) -&gt; Box&lt;dyn Fmt&lt;'a&gt;&gt; { (*self).get_subfmt() } } fn format_one&lt;T: FormatTable&gt;(table: &amp;T) -&gt; String { let root = table.get_fmt(); follow_name(&amp;root) } fn follow_name&lt;'a&gt;(fmt: &amp;'a dyn Fmt&lt;'a&gt;) -&gt; String { let next = fmt.get_subfmt(); follow_name(&amp;next) } First, let's take a closer look at `follow_name`. `Fmt::get_subfmt`'s signature forces `next` to be `Box&lt;dyn Fmt&lt;'a&gt;&gt;`. Then you take a reference to that `Box` and try to pass it to `follow_name` again. But there's a problem: you have to pass `&amp;'a dyn Fmt&lt;'a&gt;`. Traits are invariant over their parameters, so this forces the reference to be live for at least lifetime `'a`. However, `next` definitely does not live for lifetime `'a` - it's held in current function, and therefore lives until the function returns, but `'a` is a lifetime parameter on that function, and therefore definitely lives for a longer time than the function scope - so `next` does not live long enough, and you can't make it do that. The problem with `format_one` seems to be a different one (at least for me), and actually I don't completely understand what the problem is. I think the compiler should be able to reborrow `table` for a shorter lifetime to call `get_fmt`, and then root could be `Box&lt;dyn Fmt&lt;'b&gt;&gt;` where `'b` would be a lifetime that lasts until the end of `format_one`. Alas, the compiler does not want to do that and I don't yet understand why. And finally, how to fix this. Actually, I don't really know. I don't really understand what the lifetime parameter on `Fmt` is supposed to mean. It seems like you are trying to use it to show for how long the trait object is valid for, but those parameters are invariant and thus you get some unnecessary restrictions. I tried to change `dyn Fmt&lt;'a&gt;` to `dyn Fmt + 'a` everywhere, but then I got stuck on `Borrow` impl. Finally I got it to work with a combination: using `dyn Fmt&lt;'a&gt; + 'a`. [Here's final code on playground](https://play.rust-lang.org/?gist=eb3aeca07eea9197e73bc41070e5556e&amp;version=stable&amp;mode=debug&amp;edition=2015). It compiles, but I'm not really sure if that will work for you.
What about the [`?` operator](https://doc.rust-lang.org/book/2018-edition/ch09-02-recoverable-errors-with-result.html#a-shortcut-for-propagating-errors-the--operator)? You could do something like this. fn main() { let result = one_two_three(); if result.is_err() { handle_error(); } } fn one_two_three() -&gt; Result&lt;String, ()&gt; { one()?; two()?; three()?; Ok("") }
Thanks, I actually think another case when the output of last function call is used as parameter to the next function call. So, it will be looked like this: fn main() { let x = one().unwrap(); let y = two(x).unwrap(); let z = three(y).unwrap(); } How can I handle this case?
Wow, thank you! I think I have misread the documentation. I think the `?` operator would always `panic` when error (same as `unwrap`).
Thanks for the honesty in the delays. We aren't machines, so we have different needs. As someone who already got the MEAP I'm happy to wait so you can get right again. Look forward to when you are able to finish the book, but take the time you need.
I've had my eye on Hands-On, glad to hear it is as good as it sounds, I know Packt is all over the place, with some fantastic books and some that are utter garbage.
This is pretty exciting, but it's tough to know how much time to invest before [WebAssembly Web API hits](https://www.w3.org/TR/wasm-web-api-1/). I'm currently imagining using [handlebars-rust](https://github.com/sunng87/handlebars-rust) for templating on client side with prerendering and such on server side. I guess this book will be perfect then because I'm sure it'll cover everything I'd need to get going on that before WebAPI hits. I'll be sure to purchase!
This is pretty hard to do. A concept is basically just an “expression” which should evaluate to true for the given type. Like “requires is_move_constructible“ will not actually check if the type is move constructible, instead it will instantiate a class of type `is_move_constructible&lt;T&gt;` and check if it inherits from `std::integral_constant&lt;bool, true&gt;`. Its an incredible hacky and dirty system. It makes me happy Rust was build from the ground up using traits.
On the other hand, it's easy to make `unsafe` blocks super small by having them only encapsulate individual unsafe function calls. Meanwhile, all the surrounding code is still conceptually unsafe. I'd rather not incentivize the size of unsafe blocks in either direction.
Is [neon](https://github.com/neon-bindings/neon) no longer maintained? I am having a hard time getting it going for my project and the examples I've been able to find are pretty minimal. I want to use [this](https://crates.io/crates/ga-v4-flattener) in a Node project - am I better off using "plain" FFI or Neon at this point?
Small blocks are much easier to audit, though. And functions that do very basic unsafe stuff and mark them safe (while it’s actually not the case!) would be a huge code smell. Maybe something like normal size functions with one or two unsafe blocks with a couple lines each. 
First of all, thank you for taking the time to analyze and explain this. As to the lifetime parameter on `Fmt`: it arose from purely technical reasons: before that, `Fmt` has no lifetime parameters, instead `get_subfmt` had two: ``` fn get_subfmt&lt;'a, 'b&gt;(&amp;'a self, _name: &amp;'b str) -&gt; Option&lt;BoxOrRef&lt;'a, dyn Fmt&gt;&gt; ; ``` which blew up in my face when I tried to write `get_subfmt` in `impl&lt;'a, T: Borrow&lt;dyn Fmt + 'a&gt;&gt; Fmt for T`. Moving `'a` from inside the `Borrow` to the outside removes the lifetime errors in the body of this particular implementation, but breaks `format_one` and `follow_name` in ways I don't really know how to fix - Rust wants static lifetimes inside `Borrow` there. This is probably not the best reason to stick random lifetimes onto random traits, though.
You're looking for /r/playrust This sub is for the programming language. 
&gt; Small blocks are much easier to audit, though. My point is that you have to audit all the surrounding code, and if your `unsafe` blocks are not maintaining invariants at their boundaries because people have shrunk the boundaries too much, now you effectively have unsafe code that isn't marked `unsafe` and you might as well be using C++.
Not an expert on Piston, but the error message is basically saying "You asked for an OpenGL context with settings the graphics driver can't provide". `glxinfo` should provide exact details of what your graphics card provides, and `apitrace` can tell your exactly what your program is asking for, I believe. I'd suggest comparing the Rust and C program traces and see what the difference is.
bingo. We can abuse almost \*any\* language to get what we need, if it's possible to drop down to assembly in some way (even if it's just running data as code), then the languages are functionally equivalent...with enough pain. &amp;#x200B; This isn't what we care about. &amp;#x200B; What we care about in this context is "if I'm doing what a normal everyday rust programmer would normally do, will I see reasonable performance in comparison to C", the answer? yes. Rust is better then C in this regards, and this shouldn't be a surprise. C was built by smart people, but the industry has moved on, hardware has changed, and we \*should\* be able to build a C replacement that guides the programmer to 'the right thing' better. If we can't then our industry is so backwards as to be incomprehensible.
Thanks for the update. It must take a lot of courage to say this. I hope you get better.
Ah, that explains it then.
If the string is valid UTF8 you could use something like this: macro_rules! include_cstr { ($path:expr) =&gt; { ::std::ffi::CStr::from_bytes_with_nul(concat!(include_str!($path), "\0").as_bytes()).unwrap() } } Unfortunately there's no `concat_bytes!`
Yeah you can do function-style proc macros now, along with attribute style. They're all stabilized now but not all of the `proc_macro` crate is stable. And unfortunately the guide I wrote for them for the Unstable Book disappeared when they were stabilized and it appears no one's written a chapter for them in TRPL yet: https://github.com/rust-lang/book/issues/1283 However, it's not that hard if you're already familiar with implementing custom derives. Just create a `proc-macro` type crate and the declaration for function-likes looks like this: #[proc_macro] pub fn include_cstr(input: TokenStream) -&gt; TokenStream {} The function name becomes the name of the macro and the input does *not* include the kind of parenthesis the macro is invoked with (just the tokens inside). The hardest part would be recreating the "relative to the first file" behavior of the existing `include_[bytes, str]!()` macros, which are implemented as compiler plugins so they have access to all its datastructures. You *can* get the source file of a token via its span, but that API is still unstable: https://doc.rust-lang.org/nightly/proc_macro/struct.Span.html#method.source_file Additionally, this won't be a real path if the token came from a macro and it could also be remapped such that no file actually exists at that path. I believe because the existing macros have access to compiler internals they can work around these edge cases but I think for `include_cstr!()` you'd just have to emit an error (currently, by panicking). I was thinking you wouldn't even need the `syn` crate to parse input because it's just a string literal, but the tokenized API in `proc_macro` is really primitive right now so it might be better to just let `syn` handle actually extracting the contents of the string literal: let path = syn::parse::&lt;syn::LitStr&gt;(input).unwrap("expected string literal"); And `quote` would be nice for producing the output because I figured you'd want to emit like a `&amp;'static CStr` rvalue instead of just a `&amp;'static [u8]`, however there's no `const fn` for constructing a `CStr`, though `from_bytes_with_nul_unchecked()` is a good candidate, but you can simply do what the aforementioned constructor does and [just cast the `&amp;[u8]` to `&amp;CStr`](https://doc.rust-lang.org/nightly/src/std/ffi/c_str.rs.html#1043-1045) in the emitted code: quote! { { // a union is the only way we can transmute in a const context union BytesOrCStr { bytes: &amp;'static [u8], cstr: &amp;'static std::ffi::CStr } unsafe { BytesOrCStr { bytes: &amp;#bytes_with_nul }.cstr } } } 
&gt; Small nit: The difference between -O3 and O2 is like night and day. It's a HUGE difference.
You definitely need \`map\` or \`and\_then\`. Check [the documentation](https://doc.rust-lang.org/1.9.0/std/result/enum.Result.html#method.map) for \`Result\` type, you can find there several useful methods
I also have panic attacks and I also love rust. :)
Take care for yourself and your family first. I've been thinking about getting your book for some time and just pulled the trigger upon reading your post. I've no issues waiting some more time for the full book. There are things more important in life than sticking to the deadlines. 
Nice :) It would be interesting to work in basic type checking / inference too.
&gt; Rust's explicit traits and current lack of metaprogramming What kind of metaprogramming does Rust not have? I'm only learning it now and then in spurts, but I had the impression that it has most things covered with the two macro systems?
oh, right. I’ll write that down and consider adding to the article. thank you, etareduce.
Cool :) I'd recommend something like a System F type system for that.
Most parts of your question have been answered by /u/deltaphc. Still, there are some differences between those three code examples: (2) really is just (3) except you explicitly annotate `b`s type (which is `&amp;mut i32`). You don't need to do that in most cases as the compiler is able to infer/reconstruct this information. Now in (1), you also annotate the type of the *pattern* (left hand side). This could have been written like so, too (letting the type be infered): let &amp;mut b = &amp;mut a; Here, you *dereference* the rhs *inside of a pattern*! You match against a mutable reference and bind its content to `b` (of type `i32`) analoguous to matching against `Some`. Normally as you probably know, there's `*` the deref operator. Above is equivalent to this: let b = *&amp;mut a; You exclusively borrow (reference) `a` and then immediately dereference it copying the contents of `a` (because its type `i32` impls `Copy`).
This seems really similar to the [conclusions I came to after rewriting a small C program in Rust](https://github.com/psl8/babys-first-gc/). It seems like Rust makes any kind of indirection noticeably inconvenient, pushing the programmer towards cache-friendly data structures and algorithms
I *think* that in the past, O3 contained more aggressive, “dangerous” optimizations that were buggy. So many C people still use O2 by default. I don’t think that’s true any more.
This is my understanding, it may be incorrect. Concepts are not *required*. That is, you can still use methods in a templated function that aren’t enforced by a concept. It’s the programmer’s job to ensure that all relevant stuff is guarded by a concept. 
A big one is being able to template over integers. We’ve accepted a design but it’s not implemented yet; early next year!
This looks like it should have gone to r/playrust This subreddit is for the programming language
I've benchmarked `inflate` and it was well worth optimizing. Removing zeroing from just one function sped up the *entire* decompression process by 10%.
Any font designer up to designing a really scary-looking monospace font?
ok thank you! It's too bad that these basic things don't work out of the box in libstd, even though they are implemented.
I too think it's strange. But I can work around it fortunately ;)
&gt; A zero-day (also known as 0-day) vulnerability is a computer-software vulnerability that is unknown to those who would be interested in mitigating the vulnerability (including the vendor of the target software). https://en.wikipedia.org/wiki/Zero-day_(computing) After I've found it, it was known to me, but not to anyone else; therefore I possessed a zero-day vulnerability. It stopped being such only after I've responsibly disclosed it to the project maintainer and a patch was issued. --- Also: do not *ever* belittle pro bono work done by hackers. Every time someone responsibly discloses the vulnerability is a time they chose to do the right thing and only get a "thank you" instead of selling the vulnerability on the black market for thousands of dollars. Once they stop even getting a "thank you", they tend to snap and cash out the vulnerabilities instead, and that way everyone else is worse off. So don't be stingy with a "thank you" - it costs you little, and might just safe your bank account. And yes, I am aware that bug bounties exist, but once you have a vulnerability eligible for bug bounty you can sell it for 10 to 100 times more on the black market, so that's still pretty much the same choice.
Yes, gdb is just a debugger. Openocd is what actually interfaces with the microcontroller.
They cannot work "out of the box" on a generic wasm, because a wasm VM doesn't necessarily have a source of time. The web does, but this isn't the only place for wasm32-unknown-unknown. Maybe there could be a wasm32-unknown-webbrowser, but people are already talking about making the standard lib more modularized and pluggable.
Very excited about const generics!!!
Nice, thanks!
Got the book. Things will get better. Recharge and continue when you feel better. A system can only grow when we put more into it than we take from it and writing a book that will teach others for years to come is a very honorable task and the Universe will reward you for that. Take it easy. 
I'm interested to see how a REPL could be interested in the average Rust workflow. I'm sure that there are benefits to be found even for such a static language.
RSS feeds? Now there's a technology that I would love to see come back from the dead.
To add to what the others have said: You can also have a `*const T` or `*mut T` to a `[T]`, as you would in C. But then you're on your own in terms of bounds checking, and you'll need unsafe code. `&amp;[T]` basically takes the very common C pattern of passing around a pointer and a size and puts it behind a convenient and safe abstraction. Your observation about trait objects is also entirely correct: `dyn SomeTrait` is a DST and every reference to it must contain a vtable pointer as well. Some other DSTs you might know are `str`, `OsStr` and `Path`. All of those are basically `[u8]` with some extra validation, and each has an owned, heap-allocated version as well (String, OsString, PathBuf respectively).
the problem is this: If I port an application to wasm, there is no easy way to supply os specific stuff like a source of time without changing a lot of code or recompiling libstd. There has to be a better way, like maybe a callback that I as User have complete control of..
I haven't really paid attention in years, but my recollection from when I was learning C++ was that O3 was where you started getting to 'this optimization is probably going to improve things but it might also slow things down'. It wasn't recommended to use O3, iirc. I found it interested when I started using Rust that it defaulted to O3. Have I been mistaken this whole time or did something change?
Yeah you're right, I'm not sure what the solution is.
inetd for the win: https://en.m.wikipedia.org/wiki/Inetd 
Not really. Even one-line `unsafe`s typically require some invariants to be enforced externally, and the code you really care about - the code that actually enforces those checks - is usually outside the unsafe block.
I think there might be a GCC vs LLVM difference here, apart from things about GCC that might've changed over time.
I've never heard that before. All talks on speed + benchmarking for C/C++ recommend a minimum of `-O3`. 
The HTTP server server does. The actual CGI application being run by it doesn't need to know very much though. HTTP variables are passed as environment variables, etc.
It took me a bit to understand what you mean with "similar to mpd", but I think I got it now and this is an awesome idea. I don't really like polling all my rss feeds from my laptop for privacy reasons, but this would allow me to poll the rss feeds from a server and then connect my local feed reader to that. That's awesome.
In terms of dependent type theory, one can understand `[T]` as `Σ (N: usize). [T; N]`. This means that there exists some `N: usize` known at runtime and we have a contiguous segment of memory with `N` amount of `T`s. In Idris, this would correspond to `(N : Nat *** Vect N T)` which is not representationally equal to `[T]` but it is semantically equivalent.
Hate to break it to you, but VS Code is a web browser.
You're requesting OpenGL 3.2 in OPENGL_VERSION but the Raspberry Pi only supports 2.1. As a point of reference [this is some code I wrote that worked on a Pi](https://github.com/wezm/WallFlower/blob/3020e9d7d35e20183197ad197ec66850095686ed/src/main.rs) with SDL.
i think you want r/playrust
So you can do void sort(Sortable&amp; thing) { thing.method_not_on_sortable(); } and it'll compile? That's annoying.
Oh, I agree, I read the OP as wanting the "dispatching" server to not know about HTTP, only the executed app.
It is dangerous to go alone, take this https://github.com/rust-embedded/wg Scroll down to after the members.
It’ll compile as long as you only pass things that have both Sortable and method_not_on_sortable implemented, but you’ll only get the good errors for things that aren’t Sortable. Again, *in my understanding* and I could be wrong.
You're remembering correctly. O3 tended to inline too heavily, resulting in programs with bad instruction cache perf. Good for microbenchmarks, bad for real programs
Yeah, aggressive inlining definitely sounds like one of those tradeoff-y optimizations.
It feels like the attributes are over done. Can I access the same template functionality with a manual/chained function call instead of another attribute? Is it a goal to have a non-attribute way of doing things conventionally done with attributes?
I haven't had a chance to try it yet, but I'm planning on giving Triton Elastic Bare Metal a go. They offer 1 CPU, 128MB RAM instances for $2/month.
And yet, Rust `--release` is equivalent to `-O3`. It's not a fair comparison.
haven't read yet, but thanks, with no C background except general c-like-syntax stuff, I need more background on the *why* of certain design decisions in the language to be able to remember them... (and need a better understanding of what the languages I use are built on) 
Pretty normal, I think. I have both stable and nightly x86_64 toolchains installed, and it comes out to 1.79 GB. And no, there's nothing to clean. Far as I know, the `toolchains` folder is never written to except when upgrading. And when it upgrades, it deletes the existing toolchain.
I don't think it really matters. The performance difference is very well attributed to the data structures. Maybe microoptimizations applied by the compiler could have helped, but it's besides the point. The point is, to me, twofold: * Rust encouraged use of a data structure that was easy to use in Rust and ended up faster * We should not be surprised when rust is faster. As an example, I always expect some use cases where Java is faster than C. It can happen. But it's surprising. When you replace Java with Rust it should be less surprising.
I have updated the blog post with Clang `-O3` results. (Spoiler: they're an improvement over GCC, but otherwise not materially different.) My apologies for not having included those results in the initial post!
You can always just return a `Template` value as the handler response type. That said, the goal of Tower Web is to allow decoupling of application logic and HTML logic. Template values are HTML logic, so the goal is to not make it required to do so. You can also look at Warp if you want an API that is more focused on chaining.
What architectures are you hoping to target? I’ve been tinkering with embedded Rust on ARM and it has been a joy, but AVRs, for example, have more limited support. For what it’s worth, I’m personally really excited about embedded Rust. The type system allows compile time encoding of physical constraints, such as preventing inappropriate peripheral use by way of ownership requirements. Progress is being made on [applying futures to DMA transfers](https://www.reddit.com/r/rust/comments/9eku70/comment/e5qevat?st=JMOCBN50&amp;sh=db0790f3), and any other delayed event, all at (supposedly) zero cost - this is quite frankly amazing.
Out of curiosity, are there any plans for something like `wasm32-web-unknown` or a similar specialized target whose standard library implementation can utilize web apis? That seems to me like a good way to avoid the need for libraries like stdweb, at least for functionality already available in `std`.
Yes, exactly, sorry for the somewhat obscure reference. I'd probably be fine with a web UI, but I know some people really like their terminal feed readers.
You are correct. Rust does have limited metaprogramming, but it's not very useful yet in my opinion. Macros are a form of metaprogramming, but they are pretty much just simple code generators. What I was trying to get at is that Rust's metaprogramming is virtually non-existent as compared to C++. Compile-time reflection wouldn't be useful because there's no way to use it.
Sorry, I did not mean to downplay your achievements! You did a great work, I was just annoyed that you used the term in a way I thought it was wrong. Apparently, my understanding of the term was wrong though. So thanks for pointing that out!
It takes a while ro get used to such a code. When I started Rust 2 years ago, such code was totally unreadable for me too. Now, it's totally clear to me what is happening there..
That's a better start. &gt;For the C version, this is a binary search tree (an AVL tree), but Rust (interestingly) doesn’t offer a binary search tree — and it is instead implemented with a BTreeSet, which implements a B-tree. Did you not find a C version of a B-Tree that you could test? 
&gt; I still don't understand why the C++ committee went down this road. Because otherwise it might be useful. As it is now, Concepts are just an extremely thin wrapper and you have to do all the actual work of concepts yourself. Whats the point if you have to enforce it all yourself?
You could try profiling with valgrind. ( valgrind --tool=callgrind ) and use KCachegrind to visualise the results.
I'm an embedded newbie but an experienced rust developer. I do embedded rust as a hobby since August. RTFM is really great. Very rustic, and allow you to do interrupt driven scheduling with fixed priority in a safe way. I can use an elm architecture with software button unbouncing, basic pwm sound and rtc on a e-paper display easily. On the other hand, some crates including RTFM are a bit slow to being up to date because the maintainer is overbooked. You sometime need to use the branch of a PR that you need to have the desired functionalities. For example, you mostly need https://github.com/japaric/cortex-m-rtfm/pull/87 https://github.com/TeXitoi/rusty-clock if you want to take a look. That's still a work in progress, not documented and need a bit of cleaning
I think I had the same problem with go on Windows. It seems like Windows just doesn't return accurate enough time values. I ended up benchmarking in WSL, it may be emulated, but it's fast and has an accurate clock.
On the next stable toolchain 1.30, you can do embedded development on arm cortex without any additional tool (except for flashing and debugging).
You can simplify the `filter_map` code by using `Iterator::count()` instead of collecting into a `Vec&lt;()&gt;`
You're approaching the problem wrong. In Tokio, you don't \_poll\_ connection, you wait for data and react on data being available. Tokio is a perfect choice for that. &amp;#x200B; The biggest problem you need to solve is that you need a structure to broker between the connections. The important part is that this broker is most likely a \_concurrent process by itself\_. This broker should communicate with the IO frontend through channels. &amp;#x200B; Having written such systems before, I will give you a rough overview of what you need: &amp;#x200B; For every connection \`TcpListener#for\_each\`, you want to spawn a future that: * Registers the connection to the broker and provides the broker with a backchannel * reads as much as your server allows * on data, sends data to the broker * on disconnect, sends a notice to the broker to clean up the connection * alternatively wait for a message from the backend, whichever comes first * on data from the broker, send it back into the stream The broker will be another process (a future) and will have: * A channel that allows the IO frontend to register connections * A data storage to hold those connections * Listen to all connection channels and react to data on them by sending data back to all \_other\_ connections (you might want to give each connection an ID for that) To write this, I give you a few hints: * futures::future::select and join\_all are good interfaces to combine independent concurrent processes * futures streams are really good for doing these connections. Especially notice that \`Sender\` is \`Send\` and can be sent through channels. Registering to a backend by sending the Sender part of a stream over is a common pattern. You will most likely end up with something like this to kick of the process: let (broker\_future, connection\_sender) = [broker.run](https://broker.run)(); let listen\_future = .....; let server\_future = select\_all(broker\_future, connection\_sender); tokio::run(server\_future); &amp;#x200B; I hope that helps a little. &amp;#x200B; Also, I have a similar pattern with HTTP implemented here: [https://github.com/skade/hyper-server](https://github.com/skade/hyper-server), it is undocumented, though and based on an old tokio/hyper version :(. But the fundamental principle hasn't changed. &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; For lots of connections using some Event-Based system instead of multithreading should be a lot faster (but also more complex). You might to want to try using [tokio](https://crates.io/crates/tokio) or [actix](https://crates.io/crates/actix). If you don't need to handle thousands of connections simultaneously then you *can* just throw more threads at the problem. Thread-per-connection is less efficient than an event-based system, but event based systems are only really *required* for massive numbers of simultaneous connections (the C10K problem).
# How do I create a function with containing "child function"? Lately I've seen some function only accessible after calling its parent function (i.e : `map()` after `iter()`) What is this called in Rust, and how do I create one by myself? &amp;#x200B; Say that I have this struct, `pub struct Layer {` `}` &amp;#x200B; .. containing this function, `pub fn from() { // accepts data from child function` `}` &amp;#x200B; And its child functions, `pub fn data(value: Vec&lt;i32&gt;) {` `}` `pub fn activation(value: ActivationKind) { // enum that contains ReLU, Sigmoid, and LeakyReLU` `}` &amp;#x200B; How do I make something like `Layer::from().data(vec![1, 0, 1, 1, 0]).activation(ReLU)` works? I want something like builder that each of its child function cannot be invoked twice. 
Yes. I do not completely agree with all the decisions of rustfmt, but I strongly believe in a consistent style. It is an incredible waste of time to have discussions about “should we have a space or not between X and Y” and “should the bracket be on the same line or the next one”. For the greater good, we should all just format using rustfmt and move on.
What? You don’t have a `.README` in your project? How else are people going to skip reading the readme?
Sure
Using aC version of a btree misses the point of the entire blog post.
\&gt; For now, this is my code, but I feel it performs too many allocations, and it starts failing with relatively few connections. &amp;#x200B; What failures do you see? Some operating systems have \_really\_ low default limits on the number of threads you are allowed to spawn, which you usually hit \_way\_ before any memory issues.
Hi, I'm looking to make a function that contains all constant configs in my program an then based on arguments return the relevant configs for this execution. &amp;#x200B; Here's a playground that shows the issue I'm facing right now. r/https://play.rust-lang.org/?gist=a795ebf3ded8b512f741ab4771a7beba&amp;version=beta&amp;mode=debug&amp;edition=2018 &amp;#x200B; My idea to have all the configs here is to after i know which ones I will use, the remaining ones can't be access (and can be removed from memory). &amp;#x200B; I'm having trouble saying to the compiler to move ownership of those configs from the get\_tenant\_and\_environment function to main. 
The main problem with ARV is llvm support.
I don't know much about this. No one is willing to put AVR support into LLVM?
See "scoring", page 13 of the slide deck. 
If you change the return type of `get_tenant_and_environment` to `(Tenant&lt;'static&gt;, Environment)`, add `Clone` to all your derives, put `.cloned()` before both of the `iter()`s, and make the mut tenant &amp; environment variables be `Option&lt;Tenant&gt;` and `Option&lt;Environment&gt;` instead of options of references, it compiles ([here](https://play.rust-lang.org/?gist=cd55b993650af5b35b17784d350e50da&amp;version=beta&amp;mode=debug&amp;edition=2018)'s a link to a working playground.) A way to do this without the cloning is to, instead of having `vec`s of `Tenant` and `Environment` in your function, have a `const TENANTS: [Tenant&lt;'static&gt;; 6] = [...]` and `const ENVIRONMENTS: [Environment; 4] = [...]` instead, and change the return type to `(&amp;'static Tenant&lt;'static&gt;, &amp;'static Environment)`. [Here](https://play.rust-lang.org/?gist=79cb51be3f817713fc436a31fb8fa30c&amp;version=stable&amp;mode=debug&amp;edition=2015)'s a link to that.
Here is [more about NATS](https://www.cncf.io/blog/2018/03/15/cncf-to-host-nats/) (it's a message queue).
I'm personally not a fan since you can accidentally call the same function twice. 
Are the hackers discriminating or being discriminated? \- That is the question. 
Thank you, this is exactly what I was looking for.
At the risk of being a fool and don't get the joke – i was confused at first by the wording, too (you may not idk) but just to give a hint to anybody who is not a native english speaker "discriminating" here has the meaning of "sophisticated/demanding/discerning" – i hope :D Not wanting to lecture you here – i was just using the opportunity to help others, like me. 
I was meaning to make a joke, but it was because the wording was confusing to me as well. Initially I thought someone was accusing the Rust community of being discriminatory, and was of course outraged. So I read through the slides only to become privy to the real meaning. Yeah, the "discriminating hacker" as a noun phrase by itself means someone who is very purposeful and deliberate with the choices they make concerning all aspects of computing. While "for discriminating hackers" as a prepositional phrase implies that Rust is a tool to discriminate hackers. &amp;#x200B;
Hah, sorry! I had the "programming language of choice for the discriminating hacker" interpretation in my mind when posting this, but I can see the ambiguity.
What I did was benchmarking it over a cabled network using tcpkali, and the benchmark starts getting connection reset by peer with as few as 3 connections.
The current one just needs needs a slash in front. /r/rust/comments/9ghwuv/hey_rustaceans_got_an_easy_question_ask_here -&gt; [link](/r/rust/comments/9ghwuv/hey_rustaceans_got_an_easy_question_ask_here)
This is awesome. As somebody who has participated in, coached and judged many programming contests, the ICFP contest is the one I have the most respect for. Also, getting more attention from the academic PL community may be useful. Gratz to Team Unagi!
It could further be interpreted as discriminating the original "old school" meaning of hackers (as some sort of bit wizards ) by suggesting that Rust takes a more rigorous academic structure, and the compiler may argue with the hackers and not let them do things in the unsafe way they want to. 
https://en.m.wikipedia.org/wiki/ICFP_Programming_Contest
Good call, will do! 
Tim, I want to second everything that has already been said here and especially support your original intent -- writing a book that can be a reference for years to come. As much as time is a factor in all of our lives, many (including myself) value quality over quantity. I too would rather wait until it is done rather than getting a rushed version sooner. They say "done is better than perfect", but I didn't find that to always be true. I'd say "done well is better than perfect" :-). Make sure you take your time, take care of you and your family. No rush -- we'll all still be here once you finish the book (youtube's huge!) and will be just as happy to read it!
Get a GitHub account, watch the repository (the button is at the top, next to the repo name). You'll receive notifications about new issues; watch out for those that mention Rust. &amp;#x200B; If you are also able to write C++, browse through existing issues, maybe take a look at the ones tagged with "good-first-issue". Familiarity with existing codebase should open you more opportunities to help with the rewrite, since you'll need less precise instructions on what to do.
Newsboat maintainer here. Any specific take you're interested in? Like, just a list of what's been done, or more howto-style stuff on how we overcame problems we bumped into?
Sorry if that was unclear; it's at [https://github.com/joyent/statemap](https://github.com/joyent/statemap). All of the information you need to reproduce the results is in [https://github.com/joyent/statemap/issues/42](https://github.com/joyent/statemap/issues/42). To reemphasize /u/burntsushi's point: I do not intend to implement (or incorporate) a B-tree in the C implementation, because that does in fact miss the entire point: I wasn't trying to determine if C can outperform Rust, but rather to understand why my idiomatic Rust was outperforming my idiomatic C.
I don't think it is the lack of willing. It is the time to build the back end to match LLVM IR with the actual architecture
or compile rust directly to AVR, but either way is a big big job.
Natural languages are so colorful :)
So you're saying...the hacker...isn't a matrix?
The difference is - to discriminate - to discriminate against That one extra word "against" completely changes the shade of meaning (i.e. the intention of the phrase).
Should all spawned threads be joined by the end of the program? I’m coming from a C++ program where I’ve always made sure that all threads get join called on them before exiting, but I notice in a lot of Rust examples people don’t save the JoinHandle returned from thread::spawn. I’m assuming they’re all joined by the end of the program when main returns?
The YouTube video is a repost of the original: https://www.youtube.com/watch?v=Gh3I9JqFAos While the license allows it, the repost doesn't add any value. Also, here's a link to the slides: https://ashleygwilliams.github.io/a-tale-of-two-asyncs/
Ah i had no idea it was a repost, just came up in my search list.
Never underestimate the size of the JS programmer population.
Oh! Nice to see Rust given such a prominent spot light! Looking at the score board for the full contest, their statistics are pretty crazy (slide 29/35); look at the energy: 1. Unami, Score: 2,669,818, Energy: 6,886,885,323,098 2. manarimo, Score: 2,668,481, Energy: 27,863,838,353,220 3. Frictionless Bananas, Score: 2,667,310, Energy: 30,179,212,951,271 4. shinh, Score: 2,667,121, Energy: 89,429,372,348,781 5. ... The second lowest in energy in the top 15 is number 2 (manarimo, another Japanese team), and they used 4x more energy. I guess energy is not the only discriminating piece of data, given how close the scores are, but I find the gap striking nonetheless. --- Also, from the initial statistics, Rust was apparently used by 7 of the ~123 contestants; same as Go, Java, JavaScript, OCaml and Ruby. That's pretty good company.
Keynote at a JS conference. Talks about Rust for an hour. In seriousness, Javascript does not have a vision since it was designed as a quick and dirty language for adding some dynamicness to static web pages (anybody remember DHTML?). It was never really designed but just kindoff existed suddenly. This is which many of its design decisions are inconsistent, confusing, and misleading.
If the join handles are stored within a scope, their threads are automatically joined at the scope's end when the handles are all dropped.
Just watched your talk - it was great. I'm pretty unfamiliar with the implementation of both systems. Do you have any resources on memory management within an actor system? I always thought it was just the idea of passing messages - didn't know it had memory optimizations over oop like ecs does. 
Right that’s what I figured, so if I had a struct that stored a join handle then the thread would be joined when the struct is dropped. What if the join handle is not stored? Just some piece of code somewhere spawns a thread, moves a receiver into it, and then loops forever on recv (for example). When is the thread joined? I’m assuming once the last sender is dropped and main returns. 
JoinHandle is `#[must_use]`, so you really need to store it in scope. If you want the thread to escape, `mem::forget(_)` the handle.
I felt shew could have gone into more detail about Async designs and how rust language choices contributes to the various patterns. I felt it fell back into a general "this is rust and its ecosystem" talk.
That's cool. Have you considered patching the generated executables instead to remove the rich header?
&gt; was exactly the point Then the title of the article should be "Relative performance of _a_ C AVL tree vs Rust B-Tree" C doesn't have a 'standard' tree structure that comes with the language Std library, so there is no "idiomatic" tree structure. The author themselves said it was a comparison of "idiomatic C with idiomatic Rust", and since there is no standard tree structure that comes with C's libraries, the "idiomatic" comparison here is moot.
It does. You can't perform a review if your code's indentation is as wide as 8 characters.
Please don't waste my time by arguing about titles. There are plenty of other people on the Internet that would be happy to help you with that endeavor. Don't mistake me for one of them. &gt; The author themselves said it was a comparison of "idiomatic C with idiomatic Rust", and since there is no standard tree structure that comes with C's default libraries, the "idiomatic" comparison here and refusal to use an equivalent C structure makes these tests effectively worthless. A comparison between idiomatic code of two languages is certainly not worthless. They are, in my experience, some of the best educational materials on a language because they provide a way to relate between something you understand with something you do. Not every claim about performance requires "apples to apples" comparisons to say something meaningful. I think more reflection on what this article is trying to say in a less narrow context might be beneficial.
Any news?
Excellent name.
Path isn't a module, it's an object. You need https://doc.rust-lang.org/std/fs/struct.ReadDir.html. You need to pull DirEntry out of the ReadDir iterator, then you can use the filename method on your [DirEntry](https://doc.rust-lang.org/std/fs/struct.DirEntry.html) 
&gt; I Know that rust can't do multithreaded things without a crate [A very basic example](https://play.rust-lang.org/?gist=9c560436040c60857922305f83e3acb5&amp;version=stable&amp;mode=debug&amp;edition=2015) What are you talking about? And even then, what's wrong with using a crate?
What a nice talk, I really like her talks.
Very Nice! This is exciting! This cinches it for me. I'm going back to emacs.
Hmm, every example I have come across uses a crate.
I don't like to really on external things, for basic things that I would consider language features. The reason I thought that rust had no std thread lib was because every tutorial and book uses a external crate. I'll have to read into the STD lib version. Still waiting for asyncio tho .. on stable.
Could not agree more. I'm a big fan of RMS. Don't necessarily agree 100% with everything he has to say, but, I feel that he has been consistent over the years and I agree with at least 90% of his views.
This is definitely a possibility. Just zeroing out the data is trivial, however, if you want to remove it altogether you will have to update a lot of offsets in the header and make sure that the correct paddings are used. I think the cleanest way is to not write the data in the first place.
Well, the basic things are in the language, advanced things should not be in the standard library because then the advanced things become hard to change, as advanced things often do.
Not for e.g. microcontrollers. There's no support for AVR. I also don't really see a point in using Rust when there aren't any heap allocations and there isn't any concurrency. 
Ok but than there is no standard way to do advanced things, that might be a bit of a problem when everyone has their own crate to do x.
The title is wildly misleading. This is a talk about the differences in how JavaScript/node.js and Rust articulate their vision, and about the need to have a coherent vision in the first place. I have actually expected a comparison of how async is done in JS and Rust, and there was none of that, async was mentioned very briefly and never discussed comparatively.
Yea agreed, the talk promised a lot but didn't really deliver on content &amp; detail. She's a good speaker though. 
Fair enough, these kind of things tend to be solved in a way the person is most familiar solving them. Follows is some personal thoughts: Personally I have (perhaps unhealthy?) fascination with the PE format ([link](https://github.com/CasualX/pelite) and [link](https://casualhacks.net/pekit), it contains a treasure trove of information) and I would approach it from that angle instead. Because I happen to know that the only offset you'd need to fix is e_lfanew (and recalculate a checksum if you're into that), the only other offset into the headers is the one to the section headers, and that one is relative (not from the start of the file) so you'd be done. Also interesting is the choice of how you find the code to patch. Personally I prefer to be more on the safe side of patching, prefer stricter signatures over potential false positives as they can be hard to debug once you start meddling with assembly. From what I can tell, you find the code section by looking for the first executable section and disassemble it entirely looking for instructions referencing the magic constants. Interestingly the PE header contains `BaseOfCode` and `SizeOfCode` fields (they're entirely information and are of no importance to loading) but compilers mostly fill these in correctly. You can't actually assume that all data in the code section is actual code, msvc puts switch tables along side the function that uses it, which breaks the assumption. Probably not a big issue, but something to be aware of. I've always had trouble to translate what appear to be simple problems (eg. "find instructions which contain magic constants no more than X bytes apart, look for a pattern no longer than Y bytes after that") tend to turn into messy and unreadable code once written. A personal goal of mine is to find a way to express these thoughts into code in a way that's still readable. [I'm still looking](https://github.com/CasualX/pelite/blob/master/examples/csgo/weapondata.rs#L57)... Thanks for sharing (and reading my reaction)!
For 'advanced things" one uses the crate that best solves the problem at hand. For an example of an 'advanced thing' that was baked into the language that some argue should not have been is std::error::Error. It is now forever part of std when things like the Failure crate are arguably providing a better error management story. Another example of seemingly 'standard' functionality that is its own crate is "rand" around 2014 it was removed from 0.1 rust's std. The advantage is that it has continued to evolve from there and has been able to provide an ever increasing sophistication to what it does. If it had remained part of std it is unlikely for it to have developed as quickly, possibly resulting in the std:error:Error situation where lots of people just don't use it and use a crate instead. 
The stdlib threads are explicitly *detached* when dropped: https://doc.rust-lang.org/nightly/std/thread/struct.JoinHandle.html You're thinking of the scoped threads API provided by `crossbeam` or `scoped-threadpool`.
You have to explicitly join on stdlib threads. They're detached when dropped which means they can continue to run in the background (except the entire process dies if the main thread exits). The `#[must_use]` is just to remind you that they won't join by default, you can ignore it by assigning the handle to `_`: let _ = thread::spawn(...);
Rayon is not a green-threading library because it never interrupts threads to give other threads some time; it just has a list of "tasks that must be done", creates `NUM_THREADS` threads, gives each thread one task, and when a thread is done with its task it gets another one. Let's say `NUM_THREADS=4`. If you assign a pool 16 tasks, then rayon will only spawn four threads to handle the first four tasks. When one of those threads finishes its task it will be assigned the fifth task, and so on. But until at least one task if finished, no thread will even start working on tasks 5-16. You seem to be dispatching `handle_client` as part of a thread pool. This means that only up to `NUM_THREADS` clients will be handled simultaneously, the next client will only be handled after a thread handling one of the previous clients has returned. The reason you're getting timeouts after 3 connections is not because your code isn't fast enough, it is because some sockets are not even listened to because their corresponding `handle_client` function has never been called because Rayon is waiting for another thread to return before dispatching a new one. You should use something else than Rayon for this task. Try native OS-threads or some green threading library that actually interrupts threads.
Ah, good to know. Do you have any library suggestion?
I would like to point out that it is simply “discriminating,” so the shade is hidden; it could be either, or both. 
Sorry, no. I only have experience with rayon myself. For some quick benchmarks, I'd recommend switching to unpooled native OS-threads to verify whether this solves your issue.
&gt; They're detached when dropped Ahhh that makes sense to me, thanks and I see now that's in [the documentation](https://doc.rust-lang.org/std/thread/index.html#spawning-a-thread). So I'm using rust 1.30.0 nightly, but I'm not getting a compiler error/warning when I don't store the handle to thread::spawn... am I misunderstanding must_use? I'm doing some prototyping in Rust for a new project at work to prove that we can use it in production, and I'll probably have some devs who are interested in learning Rust working on it with me... but they come from a Java background where you just create and forget about the thread instead of joining so compiler warnings would be great :) This is my example program to illustrate: use std::sync::mpsc::channel; use std::thread; fn main() { let (tx, rx) = channel(); thread::spawn(move || { loop { match rx.recv() { Ok(m) =&gt; println!("M! {}", m), Err(e) =&gt; { println!("Exiting {}", e); break; } } } }); for _ in 0..5 { tx.send("Hello"); } println!("Hello world?"); } And I get no compiler warnings when compiling. This ends up printing M! Hello Hello world? M! Hello And every other run I get a panic because the thread tries to access stdout during shutdown (makes sense). Do I have to enable must_use or something?
`JoinHandle` isn't actually marked `#[must_use]` so you're perfectly fine ignoring it entirely. It seemed reasonable that it might have that attribute so I didn't double-check that part. Unless you have `#[allow(unused_must_use)]` somewhere you will get lint warnings for `#[must_use]` because it is set to warn by default. The `let _ =` trick explicitly ignores it where it would lint otherwise.
I've written several multithreaded applications and never used a crate because I'm allergic to using dependencies. 
Aha! Yeah that makes sense to me. [Looks like it decided against implementing must_use on thread::spawn](https://github.com/rust-lang/rust/pull/48830). Thanks for the help!
I'm assuming this is a joke?
Why would it be a joke? I enjoy programming because I like knowing how things work and implementing it myself. Using someone else's code completely removes all sense of accomplishment and learning for me.
Thank you for your comments. Actually, at one point I was using your crate to parse the executable. I eventually dropped it as I realized that very little parsing work was necessary. I am pretty sure that patching `e_lfanew` is not enough. You are right that there are no more pointers into the header, but the header itself contains pointers to data outside of it. One would at least have to adjust the `PointerToRawData` fields of the section headers, which also has to be a multiple of `FileAlignment` (which needs to be a power of 2 &gt;= 512), so you cannot just cut the 'Rich' header out and move stuff up. You probably also have to change `SizeOfHeaders` in the optional header. But you are right, it is definitely doable. To clarify my approach to patching: I do not disassemble the whole code section at once. I have not tried, but I have my doubts that Capstone would be able to handle that, for exactly the reasons you mentioned. Instead, I scan the byte stream of the code section to find places where the two magic constants appear in close proximity to each other. Then I only disassemble that range of bytes. So far I haven't found an executable that even contained more than one of those candidate ranges. I am the first to admit that my approach is very simplistic and that there are definitely safer ways to do this. But so far it has worked on any version of the Microsoft Linker that I have found (both x86 and x64). Also, my integration tests verify that the patched linkers are still working (at least with my test object files), so that gives me some confidence. If I would have to make this bullet-proof I would probably download the corresponding symbol file from Microsofts symbol server to locate the `IMAGE::CbBuildProdidBlock()` function and completely replace that with a dummy function that just returns 0.
Awesome project. Looks like the main use case here is to fire it up when you want to share some files with a friend. But for almost any other use case you want HTTPS and Basic Authentication at the very least. P.S.: I really appreciate the single binary, no dependencies approach that became popular with rust and go. I don't know if having apache or nginx is better from security point of view. Just recently was installing a php app -- got really frustrated reading nginx docs, then php docs, then systemd docs, endless linux man pages (users, groups, permissions, folders, etc...) -- it just never ends. I don't want to become an expert in LAMP stack -- just want to run a web app! Something written in python is not much better - python versions, system python conflicting with installed python, then you have pyenv, pyvenv, pip, python path... what a nightmare... and I "know" python :-) Yes, it was easy to write -- but I can't "just give it to a friend", if that friend is not also a python developer and has 40 min to set everything up. Running a single executable and it just works -- very refreshing. This is how Software is supposed to be packaged! Have a look at [gotty](https://github.com/yudai/gotty) for inspiration.
I liked the talk, found the RFC process and the impact of feature-creep particularly interesting. Working in a large Node.js team, the proliferation of styles - callbacks / promises / await, or, prototype / classes... I can see first hand the additional cognitive load that adds across the development process. As with a lot of software, I guess balancing the urge for improvements and new features vs simplicity / compactness is a very difficult problem. I'd be curious to see the evolution of Go - currently simple, but on the verge of adding much more complexity.
All of your dependencies are open source, with their code readily browsed offline or online. So if you want to learn how they did it, you can. You also aren't going to get very far without relying on them. Using crates allows you to focus purely on developing the products you want, and less on the minutiae of implemention details that aren't unique to your problem. In addition, you're unlikely to write better solutions than projects those goals are to create the best implementation of that particular detail.
Experimenting with lifetime annotations, I noticed that sometimes the compiler puts a `'_` in its error messages. Out of curiosity, I put it into my code, and it worked. But I'm not sure what it does, and when it's appropriate to use it. It seems it is a "please figure it out yourself" request to the compiler, or do I misunderstand it?
There's a Windows release of emacs btw that is far superior to what you'd get trying to run it on WSL at least (lack of Unicode support from the font used). I used it w/ spacemacs for a while and had a very positive experience, it looked and felt like it was running right out of a terminal. Only stopped using it because I had issues trying to get RLS and such working on it :( so if you find a resource on setting that stuff up on emacs do share. I'm considering going back to it now that I've moved onto Arch but the lack of documentation for setting up the packages is causing me to hesitate lol.
Yeah, I can see this leaning either way in this context.
I'm guess you aren't a native speaker. What you probably meant was something like: "I really enjoy writing lower level libraries myself so I can learn how the lower levels of the stack work. As such, I've written sever multi-threaded applications without using any dependencies outside of the standard library." &amp;#x200B; The problem is the word "allergic" - it's really quite a loaded term, when used in a non-medical context. For example: "Tom is absolutely allergic to Harry". The way that a native speaker will interpret that sentence is that Tom find Harry to be highly irritating. The strong implication of that is that Tom expects that others should also find Harry irritating and that someone is wrong with those people if they do not agree. Compare that with "Tom and Harry aren't all that close" - it expresses a similar idea (that they don't necessarily get along well), but, without the judgmental tone. &amp;#x200B; The problem with using the word "allergic" to describe a technology choice, is that it comes off similarly - as judgmental and arrogant. I'm pretty sure that that wasn't your intent. &amp;#x200B; The word "allergic" also seems to imply that there is something wrong with using dependencies - such a statement would clearly be ludicrous. Of course, using a dependency that already implements a feature that you are interested in implemented yourself to learn how its done (or, improve on how its done) would be highly counter-productive. But, without the additional context provided in your second comment, the reader can't know what you mean by that and is left assuming that you are saying that there is something generally wrong with using dependencies.
Thanks for the link.
Thanks for the video. I've been reading about PyO3 as well. Recently I've been wrapping a C++ library using pybind11 and it's made me wish dearly that I knew how to use rust (got stuck in double deletes because of python trying to delete a raw pointer when the object holding it goes out of scope while a static object in the library does the same, which is something I can't change).
god damn I love these something so relaxing about them
First thing I will say is, just like everyone else, don't reinvent the wheel and use asynchronous I/O. Aside from that, if you keep using Rayon, I'd suggest looking at [`scope`](https://docs.rs/rayon/1.0.2/rayon/struct.ThreadPool.html#method.scope). `scope` lets you keep the closure within the lifetime of `main`, meaning you can save on allocations during startup and when cloning strings and `TCPStream`s. That said, asynchronous I/O like Tokio and Actix are easily the best ways to write a web server in Rust.
&gt;Tbh I don't really see a point in using Rust when there aren't any heap allocations and there isn't any concurrency. At work I program for an embedded ARM target in a subset of C (MISRA C:2012), without heap allocations and concurrency (well, there is, but not in the application layer). We have to use some really slow &amp; user unfriendly static analyser (around an hour for our application layer codebase) to find the same errors the rust compiler would find in minutes. Just getting an error when you miss to match some enum value in a state machine is a huge step forward.
Someone should update the tables of winning languages with 2017 and 2018 :)
This looks great! Very very similar to a file sharing thing I started work on recently, also a rust, single binary web based file sharing app (but slightly different goal). I'll have to have a dig around :) 
Landing a remote Rust job :)
I'm currently working on [breaking pest's bootstrap chain](https://github.com/pest-parser/pest/pull/290). Other than that, I've got so much school work to get done. Slowly I convert some of that workload into working in Rust... Turning in a prospectus paper for my Seminar project Tuesday, and the project is going to be 90% implementation/experimentation in Rust. And I guess there's that Graduate student position that I need to collect my resources to apply for. (If anyone knows any Rust-friendly grad positions are open, I'd love to cast my net wider; I'm definitely applying for the RustBelt one just as soon as I've got my resources collected.) Then if I have spare time (yeah right) I might work on my hobby language some more, or potentially some more work on pest_deconstruct for the benefit of said project.
Makes sense with this perspective, thanks.
Poking at my discord dice roller bot here and there. Perhaps sadly, table top rpg design has taken up most of my time instead of rust programming. I say "perhaps sadly" because I'm unfortunately a much better rust programmer than I am a table top RPG designer XD
What crate are you using to interact with the Discord API? The last time I looked I didn't see anything that stood out as obviously the library to use.
serenity. They have a setup that makes sense as far as I've seen, but I don't really know the full extend of what Discord does. I was able to take my basic experience having done an IRC bot in the past and cargo cult it into a Discord bot instead. If you check their github they've got a link to their discord server, and response times to questions are very good. You can often get help within minutes or seconds.
Is the online voxel simulation still online? Sounds like a neat thing to play around with
I think the biggest source of confusion here is `Result` implementing `IntoIterator`, which allows you to do a `for` loop over a `Result`. If you [insert a few `unwrap`s](https://play.rust-lang.org/?gist=19707530f28ee36aa400451433756c23&amp;version=stable&amp;mode=debug&amp;edition=2015), the program will work. Clippy actually has a lint for this, but unfortunately, it only triggers after the rustc errors have been resolved. &gt; error: for loop over `fs::read_dir(p)`, which is a `Result`. This is more readably written as an `if let` statement.
Thanks a lot. I had taken a look at it before but was put off by the lack of a basic guide. On checking out the repo again I can see how to use from the examples. 
(disclaimer: I work for Clever Cloud) You can host your Rust applications on [Clever Cloud](https://www.clever-cloud.com/en/rust-hosting) ([documentation here](https://www.clever-cloud.com/doc/rust/rust/)). Mostly, you set up a git remote, `git push` and you're done :) We've been very invested in Rust for a while: parts of our infrastructure are built in Rust, and we're working on the [sozu HTTP reverse proxy](https://github.com/sozu-proxy/sozu) to handle load balancing for all our apps.
If you're not familiar with the contest, here is a short excerpt from [Wikipedia](https://en.m.wikipedia.org/wiki/ICFP_Programming_Contest) &gt; The winners reserve "bragging rights" to claim that their language is "the programming tool of choice for discriminating hackers"
Non-Mobile link: https://en.wikipedia.org/wiki/ICFP_Programming_Contest *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^216346
I've talked to people who have growing Go codebases at their jobs. Said they didn't grow very well, got very messy since they had to make up for lack of methods of abstraction. Maybe better suited to smaller projects. (Of course, with larger projects you also have to make sure that the methods of abstraction used are consistent and sensible - as you just alluded to w/ your node example. Probably wouldn't love working on a 1mil LOC Rust project with half a team of macro loving cowboys)
Going to try to get my hyper [update](https://github.com/servo/servo/pull/21644) merged in servo.
The satisfying keyboard sounds help for sure. 
When should a function take full ownership instead of just borrowing? I find myself just borrowing all over the place, and can't find a reason as to why one would take ownership in a function
&gt; Thank you for your comments. Actually, at one point I was using your crate to parse the executable. I eventually dropped it as I realized that very little parsing work was necessary. This is something I'm struggling with, finding a reason for my crate to exist. Most of the times you're only interested in a very small part of the PE header and dragging in a library that does so much more doesn't feel nice. So I'm trying to pivot and aiming at a higher level (like exposing the pe headers as json or others for consumption at a higher level than Rust). Thanks for giving it a try! &gt; I am pretty sure that patching `e_lfanew` is not enough. You are right that there are no more pointers into the header, but the header itself contains pointers to data outside of it. [...] I'm not sure what you mean? I meant to only shift the bytes inside the PE headers, ie. only shifting bytes starting from `e_lfanew` up to `SizeOfHeaders`. The only reason this could cause problems is if there are _relative_ offsets (ie. offsets calculated starting from within the region that was shifted, not those calculated starting from the image base) of which there are none. You wouldn't need to modify `SizeOfHeaders` as it's a multiple of `FileAlignment` anyway and already includes padding. That brings up an interesting point. If you want to [hide the fact that the header was modified](https://securelist.com/the-devils-in-the-rich-header/84348/) for one reason or another it's a different ball game. It's incredibly tricky to make sure you've not missed anything (like not adjusting SizeOfHeaders). &gt; To clarify my approach to patching: I do not disassemble the whole code section at once. I have not tried, but I have my doubts that Capstone would be able to handle that, for exactly the reasons you mentioned. [...] Hmm it does appear that you simply look for the constant, and start disassembling a fixed offset (`LOOK_BACK_BUFFER`) before that address without any guarantee that you start at a complete instruction. This is what threw me off into assuming you disassembled the whole code section. I like your dedication to a ton of tests though :)
Article not by me, but by Adam Perry. Their summary: &gt; TLDR: lolbench compiles ~350 benchmarks with every Rust nightly. It then runs them and highlights potential performance regressions in the standard library and the output of the compiler. Each toolchain’s run is summarized with a list of likely candidates, as seen in the image below, and we’re now getting started using these to safeguard the performance of Rust programs. Come help! Also a great quote: &gt; Rust is a Fast Programming Language. Rust programs are therefore “fast,” especially so if you write them with the correct observations to the arcane ley lines of birth and death known as “lifetimes,” and also remember to pass cargo the --release flag.
An important one is when you want to transform the data type, say from an string to a boxed string. It only really makes sense to move the data in this case (and invalidate the original reference) because the box owns the string.
I see. The last one especially is really neat, but doesn't it mean we have to reassign the value every time we use the method? Example code: let mut var1 = Struct1::new(); var1 = var1.meth1().meth2(); 
Working on a simple framework like [Processing](https://processing.org) for Rust using traits. I've been on and off working on stuff but it's coming along nicely.
Hey, thanks for reading! I realize my post was a bit of a mess so I rewrote it with purely context from Rust. I hope that this explains it better. Specifically yes, Rust can talk at the type level about these types. The notion of _'fixed length'_ isn't something that makes much sense either as you can create cheap sub slices (which are effectively changing the pointer and length to point inside the slice).
I'm not sure what your question is, but the chain in the 2nd row only works if `meth1` takes `self` rather than `&amp;mut self` and returns a `Struct1`.
Thank you :) well you are right, actor systems in general don’t assume anything. About memory management/optimization. That’s why I said that this is a speciality of my actor system implementation. It’s really a custom thing, that’s why I wouldn’t know where to point you to regarding “standard” actor system implementations 
Hey! don't hesitate to ask me for help with the nom part :)
Amazing as usual. Easily the best Rust content out there when you want something beyond the simple beginner stuff, I always learn something new and useful. A side effect of watching these is that I now often find myself using the words "fantastic", "unclear", "unfortunate" and "awful" way more than usual :D
&gt; This is something I'm struggling with, finding a reason for my crate to exist. Most of the times you're only interested in a very small part of the PE header and dragging in a library that does so much more feels like bloat. So I'm trying to pivot and aiming at a higher level (like exposing the pe headers as json or others for consumption at a higher level than Rust). TBH, I also was not comfortable with having to memory map the whole file. I wanted to be able to handle read errors more directly. &gt; I'm not sure what you mean? I meant to only shift the bytes inside the PE headers, ie. only shifting bytes starting from `e_lfanew` up to `SizeOfHeaders`. Now I get you. Yes, that would work, but in my mind, it is not much better than zeroing out the data and leaving the header where it is. I want to actually make the executable smaller, for this all of the data in the executable has to be moved up. This is what happens with the patched linker. It produces a header of 512 bytes instead of 1024 and of course sets all of the other values correctly. &gt; Hmm it does appear that you simply look for the constant, and start disassembling a fixed offset (LOOK_BACK_BUFFER) before that address without any guarantee that you start at a complete instruction. This is what threw me off into assuming you disassembled the whole code section. Sort of, I actually disassemble in a loop using different offsets (starting at LOOK_BACK_BUFFER going to 0) until I hit the correct instruction boundary.
Any link to your GitHub or something? Also about to start something similar using vulkano!
&gt; The strong implication of that is that Tom expects that others should also find Harry irritating and that something is wrong with people if they do not agree. Why? Just because someone is allergic to lactose (to name one example) doesn't mean they expect others to react badly to lactose, so why would it be different in a non-medical context. (Note I'm also not a native english speaker, but my own language has the same usage of allergic in non-medical contexts, it might have the same context you think it has there and I might simply have never noticed).
No, sorry. Good job one upping me haha. I want to get into Vulkan using gfx-hal or vulkano but I have to actually finish learning how to use OpenGL first :P.
I'm also writing one :-). How are your goals different from `thumbcloud`'s?
Solved ```rust use serde::ser::{SerializeSeq, Serializer}; impl Serialize for Recipients { fn serialize&lt;S&gt;(&amp;self, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; where S: Serializer, { match self { Recipients::LocalList(ref list) =&gt; { let mut seq = serializer.serialize_seq(Some(list.len()))?; for element in list { seq.serialize_element(element)?; } seq.end() } Recipients::ListName(ref list_name) =&gt; { serializer.serialize_str(list_name) } } } } ```
Take a look at the builder pattern and the clap crate. It uses this pattern to build up complex command line argument parsers.
I tried scope, but for some reason it wasn't spawning the first thread. 
Ease the orhan rules for the cases like \`impl ForeighTrait for ForeignStruct&lt;MyType&gt;\` or \`impl &lt;T: MyTrait&gt; ForeignTrait for ForeignStruct&lt;T&gt;\` or \`impl ForeignTrait&lt;MyType&gt; for ForeignStruct\`.
Done.
This is if a rustfmt.toml serves as a default for all projects, eg. in ~/ or ~/src/ where you might want it hidden.
Cool. As far as I know, you're using macOS, so you don't need xembed support.
Presumably, anyone who has access to sum types also has access to discriminants?
Rewriting some compsci assignments in Rust even though I have very many assignments due soon. Gotta love the university (college) life.
Wrong subreddit. 
Wow, this guy is fast. Both in reading/understanding code and writing it. Almost a bit *too* fast though. I get the impression that the streamer considered it almost a "race" to get the PRs submitted as fast as possible, and the submitted code feels like it's a bit rushed as a result. The PR submitted to juniper_hyper still has comments like // TODO: these clones are sad and // TODO: maybe use Body chunks instead? that could have been resolved if the streamer spent like 10 minutes more time on it. From my experience reading open-source code, these TODOs may remain there for *years*. I know that you, as a streamer, want to keep things moving fast to keep it entertaining, but by streaming you're also broadcasting yourself as an example for others to follow. Don't get me wrong, I enjoyed the video a lot. Please make more!
Writing up a post on some new developments in Rust's CUDA support since [my GPGPU Overview post](https://bheisler.github.io/post/state-of-gpgpu-in-rust/). After that it's a toss-up between working on Criterion.rs or building a better CPU-side CUDA wrapper library.
No man I'm nowhere near started.. but what are you thinking of building it with?
Ah ok good to know, thanks for for responding. I’ll try to check out the github code when I have some time. Thanks again 
You may want to take a look at https://serde.rs/enum-representations.html and look for the untagged explanation. You don't need to implement the serde traits by yourself for a lot of stuff. 
But you're also using code that other people wrote it you're using the standard library, and if you use the rust compiler. What's the difference between using that and a well-written library? 
&gt; I wanted to target #[no_std] environments in a FFI and core doesn't have a c_void type IIRC `core::ffi::c_void` is stable in Rust 1.30.0.
There's a lot of details [here](https://doc.rust-lang.org/nomicon/exotic-sizes.html) If you want type-level unreachability, an empty enum is a good solution. For opaque pointers you could also use them, but there's not really any benefit to do so over e.g. `*const ()`.
Published the [winlog](https://crates.io/crates/winlog) create to enable logging to the Windows event log.
to expand on what /u/Ekranos said, you can get rid of the custom \`Serialize\` implementation using \`#\[serde(untagged)\]\` &amp;#x200B; r/https://play.rust-lang.org/?gist=c65f251e1060f187958c1d7b6e6abc88&amp;version=stable&amp;mode=debug&amp;edition=2015
I have never used embedded Ruby. From a quick glance rutie looks nice, and also claims to be a continuation of ruru. If you haven't settled on a language, however, maybe it helps to know there are some [pretty good Lua bindings](https://github.com/kyren/rlua)? Lua is quite a different language than Ruby; it is small(er), general purpose, and can be written in an OO style.
Thanks! That's what I figured, but why is a enum with hidden variants preferable to a empty struct? But it would be pretty cool if the compiler allowed empty enums as pointer. Because they increase safety even more. It crashes if you try to deref a empty enum, it triggers a invalid instruction instead of just causing UB. If you deref a pointer to a empty struct it constructs it. If you deref a enum with one variant it will instantiate some variant. https://play.rust-lang.org/?gist=6344288a68a51a47024fc42ef5314400&amp;version=stable&amp;mode=release&amp;edition=2015
This is normally called a Void in type systems literature type and indicates that it can never be constructed or function can never be implemented 
I have this piece of code and I fully understand what it does: fn main() { let some_string = String::from("Test-String"); for element in some_string.chars() { println!("{}", &amp;element); } } When I change `&amp;element` to `element` it still works. So I just want to make sure I fully understand this: I wanna say that I should be using `&amp;element` because that is faster. But would that even be the case here? I suppose `char()` returns a character type which is completely stored on the stack (unlike an actual String). So there really shouldn't be a performance difference. Is that correct? 
I've taken a closer look at *rutie* ale you are right, it looks very appealing and well documented. However, do I see correctly that it only deals with one, global Ruby VM? It's kinda strange for me, I would love to have many, separated VMs. &amp;#x200B; Actually I've been working with Lua quite extensively ;) now I would like to try something else, I also evaluated [Wren](https://wren.io) which looks very nice as well. &amp;#x200B; Thanks for response!
*const () would be very cool, but it seems you need a type that's represented as i8 by LLVM. https://github.com/rust-lang/rust/blob/master/src/libcore/ffi.rs#L20
You want /r/playrust mate
It doesn't matter. `println!` needs the `Display` trait for all of its formatting arguments, so if you pass `element` it's just going to get auto-ref'd. There's never really a reason to pass references to `println!`.
My reasoning was the same for hiding `.editorconfig`. `rustfmt.toml` isn't an important part of the source code, it's just a bit of configuration. `rustfmt` usage isn't ubiquitous right now but likely will eventually become so and the existence or contents of the file aren't important. Just run `rustfmt`.
OK then let's say I'd do something else with "element" than just printing it out. This totally does not matter even then? So what's the most Rust way of doing it? Passing "&amp;element" or "element" ?
Just released a first version of my project management CLI app [archivar](https://github.com/ysndr/archivar) which is my toy project for some time now which I'm working on from time to time. It's probably a bit oversized for what it offers atm but was mainly build to learn the language and create a structure that fits into the chaos of my mind. I plan to write a blog post about this sometime telling more about what it is for and what I've learned building it.
No, you're right, in general it does matter which one you use. There are only a few exceptions: - The `println!` macro will insert `&amp;` for you. So will the `assert_eq!` macro. On the one hand, it doesn't make much sense to pass anything to those macros by value, so it's convenient. On the other hand, it does make things look a little inconsistent. I'm not sure how I feel about it. In any case, this is mostly an implementation detail of those macros (ignoring that `println` gets some special support from the compiler), rather than a language feature per se. - Some things can be coerced without an explicit cast, and the biggest example here is `Deref` coercions. For example, if I have `f(x: &amp;i32)`, and I pass it a `&amp;&amp;i32`, Rust will automatically insert the extra `*` for me. This feels a little bit quirky in that example, but it enables you to use smart pointers in a lot more places. For example, you can pass `&amp;Arc&lt;String&gt;` to a function that wants `&amp;str`, because Rust can `Deref` it twice: first to `&amp;String` and then second to `&amp;str`. A future version of Rust might even add the `&amp;` for you, though today that's still required. I believe this sort of thing was inherited from C++, and it's also something people debate, in terms of convenience vs consistency. I think one of the best arguments in favor of magical derefs, is that it makes it more likely that a beginner example will Just Work, so that a beginner can have just a little bit of breathing room before they're forced to learn advanced language features. But yeah, there are different opinions here.
That is a very good point! That said, it's not clear to me the alternatives would be better. I could have not moved on to another crate, and instead kept at it to polish the PRs, but I think that would have been much less useful to the audience. Showing them the experience across multiple crates (I believe) is much more of a teaching experience, and makes it more likely that we cover something pertinent to each viewer's interest. Alternatively, I could have moved on without submitting the PRs, but then the changes risk just sitting in my local checkout without ever getting submitted. I _think_ submitting the PRs was the right thing to do, but if you have other suggestions for a better approach, I'd be all ears. This all happened with no planning, and it's the first stream in this style that I've attempted, so suggestions for improvements for next time are welcome! I do think there's an argument to be made that many PRs "in the wild" are initially subpar, and that the authors of the target repositories should take care to read through the PRs they receive to provide comments and suggestions. And then the PRs can be improved as a result. That's what I do on PRs to my own projects at least. I wasn't expecting these to get merged to quickly without (much) comment, and with no modification, and in my experience that is relatively rare. Don't know how to show that in-stream though.
That makes sense, thanks.
Using rust at work to take raw chrome js coverage data for minified code and traversing the source maps referenced in it to generate coverage data for the reals source files. I'm hoping to get permission to release it as open source. We didn't like the other tools we found before - they either didn't deal with source maps or had to instrument the code beforehand. We have found it be a viable alternative, allowing us to generate baseline data for interactions against our production website without tweaking our production deployment :D (in terms of our reals source code). Caveats at this point include not catching branch coverage and being overzealous in counting lines (e.g. counting each line of an object instantiation as separate lines). I think I can resolve both though by also referencing the lcov output from our js unit tests :) Big shout out to the [VLQ crate](https://crates.io/crates/vlq) (I had fun writing an iterator over the full map string in the source map spec, instead of just fragments), and to /u/dtolnay for answering a [json deserialization performance question](https://github.com/serde-rs/json/issues/488) (answer: use mmap instead of anun) on github.
Trying to move [flamer](https://github.com/llogiq/flamer) to syn, TWiR and some small things here&amp;there...
Sloooooowly gnawing more on [ggez](https://github.com/ggez/ggez)'s math bugs, and cleaning up some other bits in between. I think I have it sorted out for `Image`, and I know what the problem is with `Text`, just have to gnaw the matrices into the right shape. `Canvas` is still unsolved. Once all that works though, we'd be getting dangerously close to release candidate territory, I hope.
My biggest problem with that is that there are links in the docs to the module, so the link would be dead. I made the link not be dead, but to be uncallable.
Do you think that rust will have a nice GUI system in the near future? I did some research, but as far as I understood there is no de facto way to do it, and many crates seem to be in a alpha stage kinda phase. Although I'm learning rust because of some wicked fast websites I saw, it'd be nice to program some guis. If I didn't research that correctly I'm sorry, but would be glad to get some links, if that's the case.
I bought it and enjoyed it, but I felt it was a little unfocused in certain places and kind of digressed more than it should. I did learn how to use AFL and learned about fuzzing in general though, which was cool. I guess my main criticism is that there was a lot more non-concurrency focused material than I expected given the title.
If I recall correctly C has no zero-sized types, so the smallest possible type is 1 byte :)
It's a psychological difference mostly. I wrote my own (basic) x86 operating system with context switches and a usermode, along with a minimal libc, so I guess I feel that I have a pretty good understanding of how those things work. I also find myself digging through the rust stdlib and rustc code frequently. I'm always impressed at how well written it is. Note that I do not currently work as a programmer - I'm a research scientist - so I'm not beholden to use any kind of framework/libraries/etc for my job. 
Oops! Looks like my small mistake on setting up rendering for draft posts bit you. sorry! I'm really happy you like the post :D. would you be OK with deleting this thread until I'm able to finish it?
No, it's fine. I agree that there is a trade-off between going fast to keep it entertaining and going slow to try to get the details right. Looking at the code a bit more, the submitted code really is higher quality than it seemed to be when I watched it. I think that is largely due to how fast you are in reading/writing code compared to me. I couldn't be half as fast if I tried, so that probably made it *seem* rushed, but it's not. You're obviously highly experienced in rust, tokio, and the whole futures ecosystem. Still though, to go from knowing nothing about a crate to submitting a PR for a non-trivial refactor of it in an hour and a half, that's incredible. Is that how long it takes for you off-stream as well? I think part of the reason why the PR got accepted so quickly and without comment was that the author of the crate was watching the stream. It must be a pretty weird feeling seeing someone else hack on your own code live.
It's unlikely that Rust will add autoref/deref for function arguments (AFAIK - there's talk about autoref/deref for operands of an operator like +), but there's already plenty of magic: any method call on `T` will automatically traverse all the derefs of `T` (and the single ref of each of these) to find a method with a matching receiver. It's why code like: ``` struct Foo; impl Foo { fn bar(&amp;self) {} } fn main() { let foo = Foo; // foo is a Foo... foo.bar() // but it can be passed to a method expecting &amp;Foo. } ``` works.
I've labeled a few issues in the [Rust Cookbook](https://github.com/rust-lang-nursery/rust-cookbook/issues) I hope to get more issues ready for contributors this week. I really like my shirt from last year, and it actually starts a lot of conversations about open source.
I seem to have a interest in web assembly ... What do I need to learn apart from rust ? And can you show me an example on how to host on github pages (a link to your github page will do) :)
&gt; this is a fantastic excuse to call it done and take a break Perfect way to look at it :) You can always write a follow-up! Sorry again for posting here without checking if it was meant to be public.
Hehe, yeah, things can get a bit hectic when you're in the middle of it. I think it comes down to being able to keep a mental stack in your head of what you're currently doing, and why you're doing it, so that you can dive into the details without losing the bigger picture. And I think part of what makes it difficult to follow the changes as I'm making them is that you don't have access to my mental context; you need to keep track of where we are and why without being the person in charge of the changes. I try to address this in-stream by occasionally pointing out why we're making a particular change, but it is a challenge without doubt. As for whether it "normally" takes me this long, it _really_ depends on the change and how motivated I am to make it. Streams are a little artificial in that I am motivated by having people watching me live, even if the change isn't all that exciting. If I'm working to fix a bug that I'm experiencing the effects of, that has a similar effect. I don't normally go around submitting PRs to random projects though, and if I did, I suspect progress would be slower ;) And yes, I think you're right that the authors watching was a big part of it! Which is also exciting! I still think (or at least hope) they'd point out flaws in the change, and take time to sit down and review it before merging. Watching it being written live shouldn't be enough to convince you that the change is good or worthwhile!
Last year's shirt was really nice, I still wear it often.
Thanks for the notes! I'll add these to my projects. 
Yes, that's what I did, but in this case there is also a function that I would like to document. It's not really target, it's just to enable serde integration and logging.
You mean this one [https://crates.io/crates/ruby-sys](https://crates.io/crates/ruby-sys)? I'll take a look. Thanks!
 &gt; And the second one is as a opaque pointer, You shouldn't use enums with no variants for an opaque type. In Rust, it is not valid to have a value of `&amp;Void` where `Void` is `enum Void {}`, and your purpose here is to work with these values. Use `struct Void;` or `struct Void(())` if you want to prevent it from even being constructed.
Writing up homework assignments for my Compilers and Network Fundamentals classes at University in Rust. Later I'd like to try writing something similar to flutter with a gfx-hal backend or maybe just a piston or vulkano backend. I would love to make something Yew/React/Flutter-like for writing native ui's. (Except not in Dart or Javascript for obvious reasons...) Yew is AMAZING, except that it doesn't provide a native backend/renderer. It might be cool to see if I could reuse the exact things that Yew does, except where instead of pushing to a DOM, I push to something running via Piston. 
Oh no worries at all! It's a long post, can't expect everyone to scan the entire thing for TODOs before posting it somewhere. Definitely going to enhance my blog theme to print big DRAFT text at the top though :D.
one thing these long running benchmarks could use is a long term view, say a month and a year before, to prevent boiling frog syndrome! 
I agree! All of the graphs are rendered with all of the data we have, currently.
&gt; The problem is the word "allergic" - it's really quite a loaded term when used in a non-medical context. For example: "Tom is absolutely allergic to Harry". The way that a native speaker will interpret that sentence is that Tom finds Harry to be highly irritating. The strong implication of that is that Tom expects that others should also find Harry irritating and that something is wrong with people if they do not agree Where are you from that this is true? I am also a native speaker and have never heard of this connotation of "allergic" in my life.
True. I was looking into this recently myself and there are QT bindings which work cross-platform. Then there's GTK which is pretty Linux centric and which is what I use. But there's also conrod, which is completely written in Rust and is really quite cool. But you won't get a native UI of course. So there are plenty of options available and as far as I could tell they are also pretty well maintained.
Not contending that Ruby is a better choice than Lua, but Ruby is also general purpose and can be written in an OO style. IMO Ruby is the most flexible language design I've ever seen.
Why does my variable equals '0' after a integer overflow? I tried to run the following code on the playground: ``` fn main() { let a:u8 = 255; let a = a + 1; println!("a = {}", a); } ``` If I remove the 2nd "let" it works and prints "a = 255". 
woooooooooh nice work Adam
OK, I finished up my final edits. This is good to go :).
Oh, now I see that it actually "works" on release but panics on debug. Neat!
&lt;3
https://github.com/rust-lang-nursery/rustup.rs/#other-installation-methods
The binaries don't have signatures...
Yikes. My reading comprehension skills aren't 100% today.
[graphql-client](https://github.com/tomhoule/graphql-client) also has a couple issues marked "Hacktoberfest" now :)
https://www.reddit.com/r/unintentionalASMR/ ?
What's the performance implication for the string concatenation? Is it the fact that the memory needed to construct the entire body is doubled compared to a streaming approach? Great stream by the way, but I kind of lost track when you were fighting the borrow checker, even with your explanation.
It would be super interesting to run these against all of the stable releases and get the big picture trend for rust performance!
Can you give me your gitlab ID? I'll try to give you private access. This might take some more time as I'm on small vacation 
It depends a little on exactly what you have to do to the string. A `String` is _basically_ a `Vec&lt;u8&gt;` (not _quite_ true, but close enough), so adding things to the end is fast. However, putting stuff at the beginning is costly, because you have to shift all the subsequent elements back. You can either do that by copying all the characters you have already into a new `String`, or by shifting them in place. Both of them are essentially a `memcpy` that's proportional in cost to the length of the string. For most, but not all, applications, a `memcpy` like that you won't even notice. If you ever do I/O, that's just [soooo much slower](https://blog.codinghorror.com/the-infinite-space-between-words/). In this particular context, the strings are likely to be short, and the syscalls + I/O are probably the bottleneck anyway, so it's unlikely this particular string concatenation will matter. I still like to keep track of these things, because software [shouldn't need to be slow](http://tonsky.me/blog/disenchantment/), and things like this are what cause that to happen! Yeah, it's *really* hard to articulate my thoughts when I fight the borrow checker, and I'm painfully aware that viewers fall off. I don't quite know what to do about it though -- when it happens, I really just have to try to reason myself to what's going on, and sometimes try and fail, which is disorienting to watch (and for me as well!). If you have any suggestions for how to deal with that when it occurs, let me know!
Happy to discover flamer, and BTW thank your for TWiR and the "What’s everyone working on this week" thread!
Sorry, I'm not sure I understand. Why would String concatenation in this case require shifting all subsequent elements? Wouldn't the result of the join be created by creating a new String then appending each element of the Vec? The only difference with the streaming approach that I'm seeing is that you're required to keep all of the Strings in memory before joining them, instead of the last String in the stream. Please correct me if I'm wrong.
What are your goals and has any of you two a github link to your projects ?
working on a simple standalone rest service that does patching.
How are these benchmarks different from the compiler benchmarks that I've occasionally seen posted here?
Added a single issue to support full URIs for my small zsh package manager. Should be a really manageable as the total lines of code for the project is &lt;400. https://github.com/jedahan/zr/issues/8
Are you planning a retroarch core support? End users programs that are cli-only tend to not explode in popularity until get get a 'optional' GUI, even if they're superior to what's currently available (eg: medafen). It would be nice to see a emulator made in rust run in retroarch (which crashes with segmentation faults often nach). Goddamn complex C programs.
See [`String::insert_str`](https://doc.rust-lang.org/std/string/struct.String.html#method.insert_str), which lets you insert a string into an existing one. It needs to shift all the following characters, but does not need to do an allocation! I think what you have in mind is: ``` let s = format!("{}{}", str_a, str_b); ``` That allocates a new string, and then pushes all of `str_a`, and then all of `str_b`. Both of these require you to do two `memcpy`'s, one of length `str_a.length()`, and one of length `str_b.length()`. With both these approaches, when you ultimately want to write the contents out to the network, you then have to walk the final string and write all the bytes from that (`s` in this case). The argument for using a [`Body`](https://docs.rs/hyper/0.12/hyper/struct.Body.html) with many [`Chunk`s](https://docs.rs/hyper/0.12/hyper/struct.Chunk.html) is that you now only ever need to touch each character once (the characters are only ever copied when they're written from the `Chunk` onto the network), and you don't need to do any allocation (no `String` is ever constructed that holds all the characters).
Well I am familiar with NATS but I haven't had a reason to learn Tokio yet, so this might be a good one to experiment with. 
We talked about it before. I was the one who complained that clearing out the DOM tree on navigation was slow :-). I haven't announced it, but mine supports streaming TAR archives and -- more recently -- authentication.
I'm assuming you're referring to r/https://perf.rust-lang.org, which measures time taken to compile various crates and projects IIUC. Because rustc is built with Rust, these do implicitly measure the performance of Rust code, but I think it's fair to say that even a very large compiler won't meaningfully exercise all parts of the language. If you are thinking of different benchmarks, I might have a little egg on my face in neglecting to compare them so please let me know.
Luckily, stable releases are AFAIK "just" promoted nightlies, which means it's just a matter of figuring out which nightly becomes which stable and making a graph of those. PRs very welcome!
Oh, ok. Got it. Thank you.
Excellent, I have a use in mind for these. Good to see the steady growth of arewedatascienceyet
&gt; why is a enum with hidden variants preferable to a empty struct? Uninhabited enums can't be instantiated, unlike empty structs. Meaning, you have to create enums using one of their variants like `Option::Some` or `Result::Ok`so when there are no variants, you can't create the type. A struct like `struct Bar;`, on the other hand, can still be instantiated like `let foo = Bar;`. 
I’m not sure of the specifics of how ! can be used, but I’ve had some clever uses for Never in the past. In particular, where I’ve wanted to satisfy some interface but drastically narrow the scope of possible return values. As an example, a function that returns Option&lt;Never&gt; can only return None. Similarly, a function that returns Result&lt;T, Never&gt; can only ever return Ok(T). 
Is it possible to get rls to show compiler internal documentation? I'm trying to work with clippy but its made more difficult by the fact that I can't easily jump to documentation for functions that come from the rust compiler rather than clippy itself. I can for the most part make up for that by perusing https://doc.rust-lang.org/nightly/nightly-rustc/rustc/ but it would be nice if I could let rls find the right crate and function for what im working with rather than having to hunt stuff down myself.
Ironically what gives me a lot of trouble is when rustc is being helpful. Automatically deferencing is a good example of that, and I see in the forums a lot of beginners are getting confused by this. &amp;#x200B; In the following example, is the &amp;a slice syntax part of the "regular" syntax or is the compiler just swapping in &amp;a\[..\], which looks much more meaningful to me. let a: [i32; 4] = [1, 2, 3, 4]; let b = &amp;a; let c= &amp;a[..]; 
Then build it yourself from the source code. If you don't trust the source code then a "signature" wouldn't help.
The shell script is under 400 lines. Auditing it yourself is not too bad. That doesn't provide an answer to the solution of rustup-init itself, but just to be clear, that's what you'd be really concerned with here, not the thing you're piping into sh.
Cool thanks
Thanks for the reply. My plan for Euphrates at the moment actually doesn't include a really great end-user experience. As I mentioned, I really ultimately want to use it as a platform for exploring some AI techniques. I'd \*like\* to make a GUI and lots of other things, but time is limited.
Looks like it's an improvement. On the other hand, I don't think it goes far enough. To my taste, these names have always had way too much semantic information awkwardly serialized into them. I'd prefer to see a name that just indicates the pathname of the symbol in question. Then, put all that other info in a separate section of the object file in some record format. When I'm trying to debug or link with my Rust, I don't really want to look at serial encodings of fancy type information. The compiler and various tools need it, so put it where they can find it.
Thank you!
All threads spawned within cb_thread::scope must terminate before cb_thread::scope can return. That's how it makes sure the scoped variables exist at least as long as the spawned threads. You need to move the for loop into the cb_thread::scope's closure, and spawn multiple threads within the one call to cb_thread::scope. Alternatively the Rayon crate's thread pool and API may be more appropriate for this use case than crossbeams scoped threads.
I understand. The tools will have to change to support the new serialization format anyhow: I think it would be nice to clean things up instead.
The tools would have to look in two places, but I would be able to read the symbols in the assembly code without going blind, and I would be able to guess what symbols to link against from non-Rust code without a full understanding of the type information. Also, if the semantic information was changed again, the bare symbol format would not have to change, which might mean that it would be easier to make backward-compatible changes by adding new information.
They are mostly, but there are sometimes backports, which may change things. They’re usually small, but still.
I'd highly recommend that you voice these thoughts on the IRLO thread; this subreddit is not an official avenue for discussion about the development of Rust.
Is this a step towards a stable(r) Rust ABI?
Fair enough.
I can't really help you much but have you looked into maud for templating?
I have a problem maybe more regarding wasm / JS than Rust itself - I wrote a Rust library to translate coordinates between lat/lon and Mercator. But now I want to use the library on the web. So I compiled it to WASM, and used wasm-gc to get the size down. The project is here: https://fschutt.github.io/proj5/ - take a look at the console and the index.html (which has the JS embedded). Right now all I'm trying to do is to get `WebAssembly.instantiate` working, so that I can at least compile the WASM and call my function ([this function](https://github.com/fschutt/proj5/blob/fdc03de5629f6fdb79cad092602277e799d925fa/src/lib.rs#L206-L209)) from JavaScript. The error I'm getting is basically: ``` Uncaught (in promise) LinkError: Import #0 module="env" function="Math_tan" error: function import requires a callable ``` ... which I interpret as "WASM tries to call tan() from the JavaScript side" - but I **don't want that**. I don't want my Rust code to call the slow JavaScript implementation, I want to use the Rust version of tan(). So my problem is that I don't know what settings I have to use to compile those into the WASM file and make it use that. I just used `cargo build --release --target wasm32-unknown-unknown`. Note that I don't want any "magical tools" like "just use wasm-bindgen" or something like that because I'd like to understand why Rust is trying to call the JS `tan()` function, bindgen may help in the concrete situation, but that doesn't tell me how to solve the general problem of Rust WASM trying to call JavaScript functions.
Still steadily working on [FundWarrior](https://gitlab.com/leggettc18/fundwarrior), just changed implementation around a bit, now using a HashMap rather than a Vector to store funds, so it should be much more efficient now.
That was it. Thanks.
It’s certainly a component of one. You need a lot more than this. Also, as mentioned in the thread, this isn’t intended to be stable at this time, and possibly not on the order of years.
It does mention that performance is a goal.
Makes sense. Thanks. 
I read somewhere that LLVM was built for the modified Harvard architecture (the base of most modern processors), but AVR [works differently](https://en.wikipedia.org/wiki/Harvard_architecture#Contrast_with_modified_Harvard_architecture), and some of the implicit assumptions inside LLVM are incompatible with the design of AVR, so it takes a lot of time to generalize it.
There's a problem of source code needing a valid rust install to build, though. @OP (if you're still reading this after deleting this post/account?): there are alternative download methods still, like you could download the debian package `rustc`, then build `rustup` from that.
Having skimmed the ToC I can see that (I already bought it as Packt had a $10 ebook sale).
You wrote a tool in C and barely know C? Why didn't you write it in a language you're more familiar with? Were you just trying to learn C?
This is a question on game dev, but I didn't think it was worth its own post in that subreddit, and really the question can be applied to several things. I come from a heavy OO background, and I'm working on a game that will have projectiles like fireball, magic missile, ice shard, etc. My gut wants to make a base class (Projectile, or something) and several children classes. Then the game's state would hold a Vec&lt;Projectile&gt;. My two questions are: how would you model this with Rust's type system and what would the game state hold (ex: Vec&lt;Box&lt;Projectile&gt;&gt; or something).
Same. If only they were taught in Rust...
You have remarkably good timing, because I just [published it](https://bheisler.github.io/post/ptx-builder-and-linker/).
:) !
I’m just getting into programming gpus and your last article was a great help. 
You *could* have something like that - a Projectile trait and several implementers of it that are stored in a Vec&lt;Box&lt;dyn Projectile&gt;&gt;. However, you might want to look into the [entity-component-system](https://en.wikipedia.org/wiki/Entity–component–system) architecture. In short, instead of having class hierarchies for your projectiles, you'd have Entities that represented these projectiles, and the entities could have, say, a Projectile component that controlled how its Entity moves, and maybe an ElementalDamage component that adds an elemental effect whenever the projectile hits something. You'd store each type of component in its own Vec (or other structure depending on how each component is distributed over the set of entities.) This is the way systems like Unity handle game elements, and Rust has [specs](https://slide-rs.github.io/specs/) (and probably several other ECSes by now.) There was [a talk at RustConf](https://www.youtube.com/watch?v=aKLntZcp27M) about using an ECS that you might be interested in.
The explanation is simple: I had an existing C tool lying around that did *almost* what I needed, so I decided to adapt the existing one instead of writing my own from scratch.
[lolbench](https://blog.anp.lol/rust/2018/09/29/lolbench/) was just announced, has plenty of low-hanging fruit and has a pretty clear contribution guide 
Let me know if you want some help reviewing PRs :)
Working on a TTRPG helper/bot. I'm not new to programming, but I'm super out of practice with low level languages and Rust is kicking my ass, but I'm loving it. 
Working on a TTRPG helper/bot. I'm not new to programming, but I'm super out of practice with low level languages and Rust is kicking my ass, but I'm loving it.
Is [neon](https://github.com/neon-bindings/neon) no longer maintained? Should I look into using "plain" FFI instead to make a Rust Node module?
There's a nice little trick you can use to get the compiler to tell you what it thinks the type of a value is if you're unsure - assign it to a variable that's unit type like so: fn main() { let a: [i32; 4] = [1, 2, 3, 4]; let b: () = &amp;a; } This won't compile, and you'll get something like `expected (), found &amp;[i32; 4]` as expected. (note that this doesn't work if the value is of type `!` since that will actually coerce to `()`)
Still working on my text editor. I've gotten text movement working now, which is nice. It uses the [ropey](https://docs.rs/ropey) library. I store (currently in the renderer) a character index, which with the rest of Ropey's functions allows you to find things like offset into the current line, length of a line, etc. If ropey's developer is here: please add utility functions that do the things I described above. Almost _every_ user of your library (text editors) could benefit from this!
Thanks for sharing. Actually we need more tokio client exameple. After the reform I found almost all client examples on the internet is no longer valid. For the request/response model, we can have a generic library for client development, and handles things like reconnect well.
I've wanted to make a retro emulator for quite a while now. I've also been looking into Rust recently. Maybe this is my calling to do so.
All the parts for my guitar pedal are in, got the LED on the board to blink. I messed up and got the wrong rotary encoder so it will be a week or two before everything is up and running. The DSP is written in pure rust, working alright and tested it with a plugin. The heavy lifting is going to be writing the codec drivers, so I'm considering using the existing vendor libraries to start and then porting what I can to Rust. I'm a little over budget but it's a learning experience. Still cheaper than buying a pedal with the features I want! 
Is it possible to attempt the task and submit your solution to see if it is correct now that the contest has ended? I mean, is the grader still active?
Wouldn't this be an insert-only hashtable? In that case, could it be made lockless?
Fantastic!
&gt; I currently do that, but when you generate a doc for a environment without the feature it is hidden. Is it preferable to hide it? Depending on what you mean by this, it might be preferable to just generate different copies of the docs, and just link them all from the crate documentation. * stdsimd does this in the top level docs: https://rust-lang-nursery.github.io/stdsimd/x86_64/stdsimd/arch/index.html#other-architectures * The libc crate does this in their readme: https://github.com/rust-lang/libc#platforms-and-documentation
Would you recommend this book in general? 
Can you ELI5 why it can't just use base64 on fully qualified signature?
How would you compare just one member of an enum variant? I fail to using binding: https://play.rust-lang.org/?gist=a4038d13717bbcf1af4f20cc327fbd5e&amp;version=stable&amp;mode=debug&amp;edition=2015
I have meant sha for binary archives, not rustup script. Yes, script is easy to review, but binaries are not. Also the binaries might be located (cached) on another server (mirror) that can get compromised independently of the main website.
For a few reasons: - base64 produces non-human-readable gibberish, but it would be nice to have at least a few recognisable symbols when looking at a symbol table in a non-Rust-aware tool. - Most non-rust-aware tools already support almost exactly this scheme for C++ symbols, so adopting a scheme like this makes tooling support just a bit easier. - Not everything with a symbol has a name. For example, Rust code might pass a closure to another function, which means the closure code needs a symbol, but it doesn't have a name in Rust, so there needs to be *some* extra standard for naming such things. - Not everything with a name has (exactly) one symbol. For example, one crate might provide a generic function `foo&lt;T&gt;()` that's used as `foo&lt;u32&gt;()` in two separate downstream crates, so both of those crates will have a `foo&lt;u32&gt;()` symbol. There needs to be some extra standard so both those functions get different symbols despite having the same name.
I could have sworn i've tried something like this, too. Works, thanks.
This is a perspective issue...for you having a single word per concept pairing is easier to remember, for me having only one concept per word is easier. It also has the beauty of being explicit, so you don't have to look up stuff but can logic it out.
Programming in Rust makes you think more about what things can do rather than what things are. When you add some bounds to generic type parameter you effectively say what the type *can* do. And you absolutely don't care what the type *is*. So naming choice for `Clone` and `Copy` is good, nothing confusing. You don't care if it's a value, resource, your laundry, cat. You do care that values could be cloned/copied.
Thanks, that's very useful. It's a shame the compiler doesn't use some "magic" to generate debug for all functions.
Just had a quick look at your project and found a bug in your Makefile production: cargo build --release strip target/release/iridium mv target/debug/iridium /usr/local/bin/ chmod ugo+x /usr/local/bin/ I think you probably want to move the release target, not the debug target.
I forgot to note that you can cast the fn-pointer to a regular pointer to get the typical hex pointer formatting instead of printing an undignified `usize`.
Writing a version of Processing in Rust, designed to be as unintrusive and ergonomic as possible while retaining Rust's safety and speed. [Repo here](https://github.com/Vurich/pollock).
&gt; I think 'borrow', 'lend', 'share' would have been less confusing because share and lend do not require the 'mutable' adjective. As a non-native English speaker, the distinction is completely lost on me.
I'm just guessing but at least stable symbols, memory layout, calling convention (CPU register fiddling), concurrency structuring/model, error handling (panic) propagation (result type is very helpful, but still, there could be \[or must not be\] stack unwinding through the ABI).
I really like the ideas/concepts here, and would love to contribute! Out of interest, what hardware/software platforms are you running the performance measurements on? I've got a HiKey 960 board sitting on my desk that I could potentially run some tests on once in a while if that helps?
As a native English speaker with quite the knack for language, I share /u/wojcech's perspective. It would have been more confusing if I didn't have the word "borrow" tying together the different terms. Likewise, "move" has plenty of history as related technical jargon (often in context with "copy"), while "give" has no history of existing use that I'm aware of.
I see. Thanks. :)
Oh! That's really interesting, I've started on basically the same thing, except focussed on ergonomics and simplicity. https://github.com/Vurich/pollock
The problem is that \`Arc&lt;Mutex&lt;Box&lt;SOME\_TYPE&gt;&gt;&gt;\` is a different type with a different memory representation from \`Arc&lt;Mutext&lt;Box&lt;dyn OnChange&gt;&gt;&gt;\`. You can't use them interchangably. (Note the \`dyn\` keyword, which will be mandatory soon in the 2018 edition for boxed trait objects). This would work: impl Subscription { pub fn new&lt;CB&gt;(data_change_callback: CB) -&gt; Subscription where CB: OnDataChange + 'static { Subscription { data_change_callback: Arc::new(Mutex::new(Box::new(data_change_callback))), } } } If you already have a \`Arc&lt;Mutex&lt;Box&lt;SOME\_TYPE&gt;&gt;&gt;\`, you need to get the CB out and then construct a new \`Arc&lt;Mutext&lt;Box&lt;dyn OnChange&gt;&gt;&gt;\` from it. 
Wow. That's really awesome. I never even thought about using closures for the callbacks, I used a trait instead. Take my star already :).
I'd suggest to make trait method take `&amp;self` and then just use `Arc&lt;Trait&gt;`. Use mutex internally if necessary
Thanks, I thought the compiler would see the fn needs to coerce the struct to be the trait but clearly not. I think I can work around the issue.
Agreed! That wouldn't have fixed the problem here though. ;)
Sorry but your suggestions are absolutely awful.
&gt;But that obviously depends on your use case.The point is though that you have to construct a Arc&lt;Mutex&lt;Box&lt;x&lt;dyn OnChange&gt;&gt;&gt; immediately without putting a normal boxed struct in a Mutex first. I changed the constructor function signature to "`data_change_callback: Arc&lt;Mutex&lt;Box&lt;dyn OnDataChange + Send + Sync + 'static&gt;&gt;&gt;`" and changed how I call it. That seems to do the trick.
&gt; foo&lt;u32&gt;() in two separate downstream crates, so both of those crates will have a foo&lt;u32&gt;() symbol. There needs to be some extra standard so both those functions get different symbols despite having the same name. This is one thing I'm still trying to understand. I see that there's a "crate disambiguator" to help allow multiple versions of the same crate to co-exist. What's the use-cases of the _same_ version of a symbol co-existing with itself?
There are several options https://github.com/rust-unofficial/awesome-rust#template-engine and I could try all of them, but as I'm still learning Rust I have a hard time by looking at a crate to decide how good it is, so that's why I'm asking for suggestions. Maybe someone had a similar scenario before and can recommend specific crates that are a good fit :-)
Is there an ide or bash script crutch for rust that allows debugging and autocompletion, except jetbrainless/eclipse aids?
The compiler tells you why: attempt to use a non-constant value in a constant Array sizes have to be constant. `size` isn't a constant.
So I have to write a separate function for every size, lol. Great language. https://play.rust-lang.org/?gist=9f0009bb51ce6c5615621b895096e3dd&amp;version=stable&amp;mode=debug&amp;edition=2015
Why can't I get a native UI? :/ Will e.g. QT be faster than Java GUI? Thanks anyways for your answer
The problem is known and the corresponding RFC can be read here: [https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md](https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md) I'm not sure about the implementation status though. &amp;#x200B; Instead of writing a function you could try using a macro.
If you want a dynamic array you can just return a slice. A slice is a fat pointer : a pointer to the beginning and the length. The length is not coded into the type system.
Or you can return a `Vec`. Or pass a scratch buffer in as an argument and write to that. As an aside, I'd be surprised to find *any* language that let you return different types based on a runtime argument that's comparable to Rust (natively compiled, no runtime, no heap allocations). I don't think expecting that from Rust is reasonable.
It’s such a SLOW language to develop in, I find myself wishing I could just turn the type checker off. When it’s faster to develop in C, something has gone wrong.
No. In case size is actually compile-time constant you may create array and then fill it, giving mutable slice to the function, or use one of tha crates with `Array` trait. If size is not constant then you just need to use `Vec` instead of array.
It is always faster to write in language you are familiar with. Also you spend only 10% of the time coding in C, and 90% chasing segfaults. With Rust you run debugger once in a while, like once in month.
&gt; When it’s faster to develop in C, something has gone wrong. Yes - almost certainly the C code. Can you post a representative sample of how you'd do this in C more ergonomically? BTW Rust has a single function that does what you want: [slice::from_raw_parts](https://doc.rust-lang.org/std/slice/fn.from_raw_parts.html).
Speed isn't everything. The whole *point* of using Rust is the more pedantic type system. I've recently been rewriting an old project from D to Rust. The Rust version has been slower to write, but is much easier to understand, more stable, faster, and has less bugs. Just the act of porting to Rust revealed several bugs in the old code by the simple virtue of Rust not letting me get away with cutting as many corners. If I want development speed, I'll use Python. If I want to get the code *right*, I'll use Rust.
You can already use `?` with Options because of the [`Try` trait](https://doc.rust-lang.org/std/ops/trait.Try.html). While the trait is unstable the implementations are usable through the `?` operator.
"[The State of GPGPU in Rust](https://bheisler.github.io/post/state-of-gpgpu-in-rust.md)" and "[GPU Path Tracer](https://bheisler.github.io/post/writing-gpu-accelerated-path-tracer-part-1.md)" are dead links.
&lt;3
Thanks! I'd love to have your help, and if you have any problems getting started pls ping me on irc! The benchmarks are currently running on some cheap dedicated servers from hetzner, there's some work to do there. 
Thanks! I didn't realize Nightly has NoneError. However, it doesn't implement std::error::Error. What's the reasoning behind that?
'move' is a real term for that type of operation. C++ has it too with 'move constructors' and the like. So even if the terms are bad, there is value in matching existing terminology.
sure, but it instantiates a `NoneError`, which you can't actually use without enabling the nightly-only feature since there is no `From&lt;Error&gt;` impl for `NoneError` so you have to import it so you can add any necessary plumbing for it
I watched the rest today (only watched the juniper_hyper part yesterday). The change to beanstalkd was definitely an improvement, but I'm on the fence about the change to argonautica. I made my comments [here](https://github.com/bcmyers/argonautica/pull/7#issuecomment-426279336) so the author of the crate can see them too. But I do want to talk a little bit more about changing uses of futures-cpupool to Tokio's cpu pool in general. From this admittedly very small sample size of only 3 crates, it looks like it comes up quite a bit than I thought it would. It seems like there is a need for an abstraction here. Given that the ideal situation is to have only 1 cpu-pool per application, it's not good if the libraries themselves make the choice of which cpu-pool implementation they use. It should be the application that makes that choice, and libraries should be generic over the cpu-pool. Could [`std::task::Executor`](https://doc.rust-lang.org/std/task/trait.Executor.html) be that abstraction? I'm not sure.
You’d have to ask the infra team.
Yep
You’re welcome :)
Because conrod is an OpenGL based UI. And yes QT should be faster then a Java GUI. And less clunky/ugly.
If function returns `Option` then `?` will simply return `None`
&gt; Accel has its own crate that provides wrappers for the block_idx/etc. functions, but I followed @denzp’s guide and used the nvptx_builtins crate. nvptx_builtins is super bare-bones, but that’s probably what you want here - the magic CUDA functions are very limited in scope so you don’t really need anything complex. IIRC all nvptx builtins are available in `core::arch::nvptx`, so you should not need to use an external crate for this.
Thanks, do you mind explaining why the compiler doesn't say `... for `&amp;T` ` ?
To elaborate a little bit, the destructor of the scope object automatically waits for any threads that it's spawned to terminate. That's actually critical for safety, because otherwise the threads could outlast some object on your stack that you'd given them a reference to.
I mentioned VSCode a while back -- although I've been told the debugging doesn't work on Windows, so YMMV
some links I found: https://internals.rust-lang.org/t/should-noneerror-implement-the-error-trait/6312/6 https://github.com/rust-lang/rust/pull/42526#issuecomment-309912689 https://github.com/rust-lang/rfcs/blob/master/text/1859-try-trait.md#support-interconversion-but-with-caution
Indeed you are right! Thanks!
&gt; Sorry but your suggestions are absolutely awful. I don't think this particular phrase is necessary for constructive feedback...
Username checks out. You forgot a few words in your post: "They absolutely are not in any way more clear" *to me.*. If I have learned nothing else from the times when I've had the opportunity to teach people, I've learned that different people learn differently. Long ago, clouded by the mists of time, I took a calculus class that was taught not by the math professor, but by a lowly graduate student. That was fortuitous, because what this brilliant person did when presenting concepts was something like this: Instructor: "So ... that's how that works. [Thoughtful pause]. Or, you could do it like this ..." (proceeds to demonstrate an alternate path to the solution). Depending on the material, the instructor could explain the concept several different ways. As the instructor moved through the alternative perspectives, I could see the lightbulbs going off over the heads of various students in the lecture hall as a particular method 'clicked' with them and they experienced a moment of clarity that helped them understand. The instructor saw that too, which is why time was spent to do that. I have much respect for this. Interestingly, once the moment of insight happened, the other perspectives made more sense as well, but for each person, it was that one viewpoint, that one angle that made it all come together for them. I never forgot that class because it was a very important lesson in how people see the same world differently and there is no one 'right' way to teach concepts. This post reminds me of that. Whatever the particular terminology chosen for Rust (sanity dictates you have to pick one), when trying to *explain* Rust, alternative but relevant terminology can be extremely helpful to bring people to that moment of insight. Once you are there, you're golden.
Is there a good way for existing crates to target the wasm32-unknown-unknown + web-sys environment so they can easily interop with other WebAssembly crates/applications (which also use web APIs)?
I labeled a few issues on [Crater](https://github.com/rust-lang-nursery/crater) as [hacktoberfest](https://github.com/rust-lang-nursery/crater/labels/hacktoberfest), and wrote a small [contributing guide](https://github.com/rust-lang-nursery/crater/blob/master/CONTRIBUTING.md). Any help is appreciated!
Stagnation. For example, optimizing the layout of enums, encoding the discriminant in niche values, is an ABI-breaking change.
&gt; but I would be able to read the symbols in the assembly code without going blind That's actually one of the big motivation for the proposal: by encoding all the type information in the symbols, demanglers can be created for the Rust scheme which will offer you a nice display. If, however, you were to step outside of what other languages/tools do, then support for the Rust way would lag behind considerably and you'd go blind for far longer.
Ah, I wasn't aware of that. Thanks!
It would have to be implemented to check exactly. Naively, longer symbols generate slightly more work for optimizers and linkers, use slightly more space in the binary, and may take slightly longer to load (PLT/...). The question, of course, is what proportion of symbols would end up longer and what the impact would be. Given Rust's heavy use of generics, I'd bet on longer in average, but the exact impact is hard to predict and probably a case by case thing.
Published my first crate: https://crates.io/crates/borrow_with_ref_obj It's basically `Borrow`/`BorrowMut` but the returned reference is an object rather than `&amp;T`, so it can work with `Rc&lt;RefCell&lt;T&gt;&gt;` and `Arc&lt;Mutex&lt;T&gt;&gt;`. Feedback appreciated!
The compiler can coerce a Box&lt;T&gt; to a Box&lt;dyn Trait&gt; because they exist on the stack where the extra data (the vtable) can be added, but it can't do the same behind a pointer such as an Arc since it would have to point to different data.
It's a fair point. It seems like there are a number of reasonable arguments against my proposal. I think it's probably too late to fix the name-mangling mess: I could wish that we did a better job 30 years ago when Cfront started us down this road, but there we are.
That is supercool, have you everseen Symengine (https://github.com/symengine/symengine, by the folks of sympy), and talked to the authors ? Could some primitive data structures be shared or send from one project to the other to use functionality implemented in one and not the other ? Also ever thought of making a Jupyter Kernel ? I saw https://github.com/google/evcxr recently so most of the binding should already be written in rust. 
It appears at some point these were "hidden", but there is a PR open to fix that.
Will this include (1) automated differentiation, and (2) evaluation on the GPU? This would allow the framework to compete favorably with the likes of Theano and Tensorflow.
I always get confused when double references (`&amp;&amp;`) are involved, so I hope maybe somebody could me understand what is happing here. This fails to compile (expected &amp;&amp;str, found String) ``` fn foo(needle: String, haystack: &amp;[&amp;str]) -&gt; bool { haystack.contains(needle) } ``` This also fails (expected &amp;&amp;str, found &amp;String) ``` haystack.contains(&amp;needle) ``` This also fails (expected &amp;&amp;str, found &amp;&amp;String) ``` haystack.contains(&amp;&amp;needle) ``` However, this works? ``` haystack.contains(&amp;&amp;*needle) ``` This also works for some reason? ``` haystack.contains(&amp;needle.deref()) ``` Even this works??? ``` haystack.contains(&amp;&amp;needle.deref()) ``` My main questions is: why is Rust able to coerce &amp;String to &amp;str under normal circumstances, but it is not able to coerce &amp;&amp;String to &amp;&amp;str and suddenly requires the awkward `&amp;&amp;*needle` or `&amp;needle.deref()` syntax? 
Overflow checking is disabled in release builds (for performanxe reasons). Probably it's happening in both cases: In the debug build this causes a panic, but in release mode it will wrap silently and you're probably just not noticing it happening?
Ah, I see. Thanks for the explanation!
Sorry for asking here about this, but I'm wondering how to handle `spawn` failures in `crossbeam 0.4`. Consider the example here: https://rust-lang-nursery.github.io/rust-cookbook/concurrency/threads.html#spawn-a-short-lived-thread. I see no easy way of rewriting it without sticking `unwrap` in there.
I have Error 520 with this page, Could any one help me to read it (aka html file to me or a full page screen shot) THANKS RUSTACEANS
[Here you go](https://screenshots.firefox.com/LZDtQsL3FCHTlwVh/medium.com)
Debug panics on overflow, release does not (for all rust programs, not just yours). Looking at the code, 'cycles' is added to `self.div_counter`. `cycles` is an i32, `div_counter` is a u8. Your overflow check happens *after* this addition occurs. 
&gt; A better distinction between `&amp;` and `&amp;mut` would to refer to them as a ‘unique’ reference and a ‘shared’ reference. You should be careful about the relative order here: `&amp;` is shared, and `&amp;mut` is unique.
You can do this trivially with a macro assuming your function input is always a constant. I'll be out of hospital in an hour or so and I'll write this up with proper safety and ergonomics.
Or you could write a rust compiler yourself.
THANKS so much
Huh, this is something I wouldn't expect to fail. `contains` is using a generic parameter, but in this case it's forced to be `&amp;str`. I think this is a particular case where the compiler thinks the situation is less certain than it is, and thus won't coerce `&amp;String` to `&amp;str`. Usually `&amp;x` operator corresponds to `&amp;&lt;any number of *s necessary&gt;x`, and the compiler will automatically do this. `&amp;*x` is equivalent to `x.deref()`, and as you've seen `String::deref` turns `&amp;String` into `&amp;str`. For any method taking a concrete `&amp;str`, passing `&amp;an_owned_string` will automatically translate to `&amp;*an_owned_string` and it will work correctly. As far as I can tell, the compiler _should_ do this for `contains` as well since `T` in [contains](https://doc.rust-lang.org/std/primitive.slice.html#method.contains) is fixed to `&amp;str` - it just doesn't.
TBH that's not a horrible idea if you _really_ need signature verification. OP could easily compile https://github.com/thepowersgang/mrustc using a verified C++ compiler then use that to bootstrap rustc.
These work for me (since the comments are mostly voting ;). I personally use "give", "lend", and "show" for move, &amp;mut, and &amp;. But, different strokes for different folks.
&gt; you give the executor (in this case tokio) the ability to choose how to co-schedule your tasks. And in theory it can then do better than if you placed a fixed divide between the compute and async parts of your code. Yeah, but if you use `tokio::blocking` to spawn more cpu-bound threads than you have cores, aren't you at the mercy of the OS's preemption anyway? It's not like Tokio can preempt the blocking threads that it started either. I also find it hard to believe that Tokio's executor can do a better job if it doesn't know what the `blocking` threads are actually blocked on (CPU or not).
Your example compiles if you remove the `Box` indirection and leave just Arc&lt;Mutex&lt;dyn OnDataChange&gt;&gt; ! ([Playground](https://play.rust-lang.org/?gist=91cc293575c1106a19d8baf7f6d17767&amp;version=stable&amp;mode=debug&amp;edition=2015)) The coercion can happen if the dynamic trait object is behind exactly one pointer indirection. In your case, there are two pointer indirections – Arc and Box. [I've made a quick sketch, I hope it helps explain it a little :)](https://imgur.com/DqFPwNs)
Autoderef does not happen in the face of generic parameters. Rust does not try to autoderef to see if the resulting type passes the where clauses. Here Rust is looking for `T: PartialEq&lt;T&gt;` where T is `&amp;str`. Since `&amp;String` is not the same as `&amp;str` and Rust won't autoderef because it's a generic argument it won't work. Introducing an extra generic parameter to the compare function, `fn contains&lt;U&gt;(&amp;self, x: &amp;U) -&gt; bool where T: PartialEq&lt;U&gt;` would find and accept `U = String` but that is not the case.
I understand that rust doesn't do autoderef for generic parameters, but I don't understand why it's treating `T` as generic for this purpose. The function signature has fixed `T = &amp;str`, so shouldn't it be equivalent to a non-generic parameter? I mean yes, it's called `T`, but it's generic on the slice, not on the method- it's completely fixed for this method call.
Also, the link to the witnet-rust repo is [here](https://github.com/witnet/witnet-rust), if you want to go directly. Thanks for your interest! 
I've taken out the inner box and have it working more or less I wanted it now. Cheers!
Looking at the warp WebSocket example here: https://github.com/seanmonstar/warp/blob/master/examples/websockets_chat.rs I can see that the method start_send is used to send messages to the sink half of the WebSocket in order that it's received by the other users. When I read the docs for start_send however, I get the impression that other functions need to be called to ensure it works. From https://docs.rs/futures/0.1.24/futures/sink/trait.Sink.html#tymethod.start_send The line "You must use poll_complete in order to drive completion of a send" stands out, and suggests to me that if I don't take other action, my messages may not be fully sent. Methods like "send" on the other hand promise to complete the send and return a future which must be run, but is much less ergonomic to use. I guess my questions form this are: when is it safe to use start_send and when must I use send, or do other things to ensure that the message will eventually arrive? My mental model of futures is that everything you want done must be part of a big future that is run to completion, and so how do methods that don't return futures, like start_send, perform useful work? 
For automatic differentiation, I would recommend using the [dual_num](https://github.com/novacrazy/dual_num) library. Dual numbers inherently provide AD. Disclaimer: although I'm not the author of dual_num, I've contributed to it, and I'm currently writing research which uses dual numbers for automatic differentiation of multivariate functions (gradients and matrices of partials).
Is there really no stable ABI? Does this mean that (for implementing plugins for my application) I need an embedded scripting language?
Hmm, considering what would be the best way to represent a data structure that can be converted to a (winapi) SAFEARRAY structure. My initial draft was something like: pub enum RSafeArray { Shorts(Vec&lt;i16&gt;), Longs(Vec&lt;i32&gt;, ... } But I'm unhappy with that. It doesn't look right to me. So second draft is currently: pub enum RSafeArrayItem { Short(i16), ... } pub type RSafeArray = Vec&lt;RSafeArrayItem&gt;; But I am also unhappy with this. (Primer on [SAFEARRAY](https://msdn.microsoft.com/en-us/magazine/mt778923.aspx ) ) Suggestions or ideas? Basically the idea is that you can wrap up a vector of one type of data and convert it to a SAFEARRAY structure or convert a SAFEARRAY structure into said vector of data for FFI. 
`impl Trait` only works when there's a single type to resolve to, but the two match arms return different types: `std::slice::Iter&lt;T&gt;` and `std::iter::Take&lt;T&gt;`. For this to work as you'd like you'd need dynamic dispatch, which would need `Box&lt;dyn Iterator...&gt;`. For this specific example I'd do this: let limit: Option&lt;usize&gt; = Some(2); let nums = vec![1,2,3]; let take = limit.unwrap_or(nums.len()); let iter_nums = nums.iter().take(take);
Yes there is no stable ABI. Other solutions for plugins would be: - Compile plugins with the same version of the rust compiler. - Expose a C interface for a plugin dlls. - Expose a RPC interface (capnproto, protobufs, gRPC, dBUS etc.) - Use a higher level object system like COM or GObject. 
Wouldn't that depend on function size? I would imagine that duplication of large functions would have negative effects on instruction cache.
It looks like you're using Rust 2018 edition (available on beta and nightly), you can check it in your `Cargo.toml`. [The module system was changed a little, you can read more in 2018 guide](https://rust-lang-nursery.github.io/edition-guide/rust-2018/module-system/path-clarity.html). Tldr, you need use crate::event_system::EventSystem;
Learning rust by building a branch and bound implementation for solving the knapsack problem.
&gt; what's so hard? Check out [this thread](https://www.reddit.com/r/rust/comments/9kizz2/prerfc_a_new_symbol_mangling_scheme_post_your/) which touches on a bunch of related stuff.
That link was perfect! I've been away from rust for a while, I'm glad I'm not just going insane. Thanks so much!
I had a discussion yesterday; we may want to work on the errors here to help explain to people who just run into this like you did. We’ll see!
That's what I was looking for. Thanks! Your response led me to [this](https://joshleeb.com/posts/rust-traits-and-trait-objects/) blog post which, for anyone else interested, really helped me understand `dyn Trait` better. 
Well, you can set a different limit for the number of allowed blocking threads and the number of threads used to run tasks. So that'd be how you prevent it from running too many compute-heavy threads. You are totally right that it's tricky for `tokio` to know how to handle a `blocking` tasks without knowing what it is blocked on though. I think there's an argument to be made that it _could_ do better if it's the only one managing a single pool, whereas any such optimization isn't _possible_ if you have multiple pools. So I still don't think that's an argument for *not* using the `tokio` pool for both?
That's basically the approach the compiler currently uses: (some portion of) the symbol name is random/meaningless (currently the hash that is appended). In any case, my impression is the information being encoded is all *required* to get a unique symbol encoding. That is, without all that information two functions (in the binary) may end up with the same symbol name. For instance, for methods, a type `Foo` could define an inherent `f` and also implement a trait `Bar` with an `f` method, meaning the trait name has to be encoded. I think you're being somewhat dismissive of the advantages of having the information be (vaguely) human-readable: existing tools (debuggers, profilers, etc.) work on Rust code without having to have support added, and humans can interpret the results directly (and tool support, like a demangler, makes this easier, rather than making it *possible* at all). The new scheme improves this: I personally repeatedly hit cases where a profiler shows that a trait method is a hot function, but there's *no* way to tell which definition (i.e. which impl) the method comes from.
I'm so pumped for this! Eijebong is delightful and makes so many wonderful contributions to Servo.
Continuing to implement Robotic commands for my [MegaZeux clone](https://github.com/jdm/mzxplay). The title screens for Caverns of Zeux, Chronos Stasis, Forest of Zeux, and Catacombs of Zeux all work great now, with Smiley RPG and Shining Legend in good shape, and Demon Earth and Bernard the Bard looking recognizable.
I've got a rough sketch of a solution: https://gist.github.com/783e8174d71b6b7437c7d195de6ba905 This is the best thing my non-expert self could make which would work on stable Rust.
https://play.rust-lang.org/?gist=2d40215b3a6b8abc7d6f5ca7dfba3c14&amp;version=stable&amp;mode=debug&amp;edition=2015
YES!
I think a good first step would be to have Cargo warn people that it's set their new manifest to the 2018 edition, and that this will change language behaviour. Maybe even (for a few versions) require it to be explicitly enabled before switching over the default. This is the... third (?) case of this I've seen in the last few days. It's clear people don't realise what's going on and are getting confused.
I don't know a whole lot about this subject, but it looks like it's expecting you to pass it an implementation of tan and atan. I got it to instantiate in the browser console by changing the env you're passing to look like this: ``` env: { abortStackOverflow: () =&gt; { throw new Error('Stack overflow'); }, table: new WebAssembly.Table({ initial: 0, maximum: 0, element: 'anyfunc' }), tableBase: 0, memory: memory, memoryBase: 0, // 1024? Not sure. STACKTOP: 0, STACK_MAX: memory.buffer.byteLength, Math_tan: Math.tan, Math_atan: Math.atan } ```
Shouldn't you use `wrapping_add` if you explicitly want it to wrap on overflow?
Community rules: "All submitted posts must explicitly reference Rust or link to repositories written in Rust."
`sum &gt;= i32::MAX as i64`
Hunh, that's a pretty good idea. 
Glad I could help :) I would recommend looking into dependent types (but not the theory of it unless you're into that sort of thing...) from a users perspective if you have the time; it really opens up the mind about what is possible to model and say about programs. When Rust gets const generics, you'll also have a head start as const generics essentially constitute dependent types for a limited subset of values (i.e. types dependent on values known at compile time). Idris and Agda are good languages to learn about dependent types.
Yay :) Waiting for 0.5RC to try porting Zemeroth to it and start tinkering with Android port.
Good points. I don't feel dismissive of the proposal's advantages: I think it's a definite improvement on the current scheme. I definitely want as much readability as possible in undemangled symbol names, because as much as I wish it were otherwise I occasionally find myself looking at them.
Working on my [type\_level](https://github.com/rodrimati1992/type_level) set of crates (for defining and using type-level values and functions) . Thinking of what to write as an example in the [guide chapter 12,](https://docs.rs/type_level_values/0.0.20/type_level_values/docs/guide_12/index.html)about parameterized \`type modules\`. Also thinking about how I am going to test the derive macros. &amp;#x200B;
When building a chain of future combinators, what is the easiest way to share data between them? I'm using futures-rs 0.1.24. My current approach means cloning the data for each combinator: let conn = Arc::new(Connection::new()); send_request(conn.clone()) .and_then({ let conn = conn.clone(); move |r| process_response(r, conn) }) .and_then({ let conn = conn.clone(); move |x| send_reply(x, conn) }) All this cloning is a lot of noise. If I implemented the whole future chain as a hand-rolled state machine, I would just hold on to `conn` for the lifetime of the chain. I could see passing down the state by constructing a tuple `(result, conn)` and then unpacking it in the next lambda, but that seems even more awkward to use. Is `task_local!` the right tool here? I'm not sure about the scope of a "task" though, the way I understand it, it might live longer than my state.
Things are even harder here in Europe :/
Thanks for the explanation. This clears up alot. It would be nice if Deref was called in more circumstances and also derefs &amp;&amp;String to &amp;&amp;str since it feels like odd cornercase.
Ah yes happy to revive the meetup group, but give me a few months to build out my team. I'll be heading to the LLVM social meetup tonight in Sydney, if you're around :) BTW: Not from maidsafe, but am planning to use their code (naturally open-sourcing our contributions).
Maybe the template main.rs/lib.rs cargo creates should start with a comment about the edition the crate was create with.
That pre-supposes people are going to look in `Cargo.toml` for the source of a problem when, up to this point, it can't be the source of the problem. If they know to look in `Cargo.toml`, odds are they already know about editions. I know I didn't think to look in `Cargo.toml` when I ran into this issue the first time because `cargo new` doesn't set an edition. It never has. I don't expect it to. Why would I look there?
Just FYI I recently found there is a bit of a movement in academic circle called ["The Third Manifesto"](http://thethirdmanifesto.com/) to bring relational algebra to general programming languages with proper type information as the next big thing after SQL. There is [a book](https://www.dcs.warwick.ac.uk/~hugh/TTM/DTATRM.pdf) and several implementations: - [HaskRel (Haskell)](https://hackage.haskell.org/package/HaskRel) - [Alf (Ruby)](http://www.try-alf.org/) - [Dee (Python)](https://www.quicksort.co.uk/) Maybe something v11 can expand to join. 
Could you explain more what this does, and how it compares to include_str! ? Also I'm not even sure the word "tangle" has the meaning you ascribe to it.
This takes a Markdown file containing embedded Rust code and outputs a Rust file with just the code. The name "Tangle" is derived from Knuth's [Tangle/Weave](https://en.wikipedia.org/wiki/Literate_programming).
Too bad I'm not confident enough in Rust, it would be a cool project to work on.
I know that unsized types are handled as fat pointers (pointer + size). Looking at the implementation of `Mutex`, it uses a `UnsafeCell` to store the `T`, but where comes the memory from, the fat pointer is pointing to?
Thanks for the great sketch!
holy molly i thought vscode was some kind of repackaged visual studio aids but it's actually a great ide. almost as good as qtcreator, haven't yet figured out how rust projects work though but thanks!
Do you consider a relocation/visa from overseas?
Seems similar to my [waltz](https://github.com/killercup/waltz) crate (which is a play on [tango](https://github.com/pnkfelix/tango))
Obligatory link to [Reflections on Trusting Trust](https://www.archive.ece.cmu.edu/~ganger/712.fall02/papers/p761-thompson.pdf)
Since fibonacci numbers will always be positive you could use u32/u64 instead. If you're interested in some further optimizing (you don't need a function to add two `i64`), take a look here: [https://play.rust-lang.org/?gist=58d797c55ae53d9a7d38c8a6f2d38bb8&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=58d797c55ae53d9a7d38c8a6f2d38bb8&amp;version=stable&amp;mode=debug&amp;edition=2015)
An alternative would be to have `add_two` return an `Option&lt;i64&gt;` and use [i64::checked_add](https://doc.rust-lang.org/std/primitive.i64.html#method.checked_add).
I think it makes a lot of sense to submit an initial version of the PR without the added work, both in terms of keeping your stream interesting to your viewers and because it can be really useful to get feedback from the crate maintainer on your TODOs or FIXMEs before you spend a bunch more time on them.
I attended the last two rust Meetup at Atlassian. I think at the moment there are not many to give talks which is the reason they are held infrequently.
Impressed
Because that’s what the function I am calling expects.
Thank you for sharing! Is Sasha Grunert a reddit member? Can we get them to become one and host a rust AMA?
Yeah, I actually live in the UK and trying to stay there or Europe...not easy :/
Awesome! Have you published any resource about this work?
Github: [https://github.com/csharad/ruukh/](https://github.com/csharad/ruukh/)
This looks really cool! I've been working on an Elm inspired frontend framework using web-sys but was stuck trying to figure out how to implement stateful components. I'm going to read ruukh's source code tonight!
You may want to look into the \[typenum\](r/https://github.com/paholg/typenum) crate that does something very similar, also has macros and compiletests for them.
Glad I could be of help.
Thanks for the update! I read your post last weekend and was spelunking in your source and noticed all those changes. So this is a very timely! What do you think is the biggest pain point for Yew right now?
typenum is one of my public dependencies.
This looks super cool. Maybe it's just because of my react background but I like the feel of this more than previous attempts I've seen.
Is this a reference to Thrawn's bodyguard in Star Wars?
No, it is actually a Nepali word which means Tree which itself derives from Sanskrit Ruuksha.
I have question about parsing. I have a `struct Ident(String)` that wraps a `String` with some additional conditions: it must be nonempty, not start with a digit, and contain no whitespace or parentheses. On the one hand, I want to enforce these conditions via a function ``` Ident::new(s: String) -&gt; Option&lt;Ident&gt; ``` The easiest way of doing this that I have found is to have `new` check whether the argument conforms to the regex `^[^0-9()\s][^()\s]*$`, using the `regex` crate. This is pretty convenient. On the other hand, I want to be able to parse `Ident`s with `nom`, and this is where it gets a little ugly. Currently, this is the parser I have: ``` named! { ident&lt;CompleteStr, Ident&gt;, do_parse!( first: none_of!("0123456789() \t \n") &gt;&gt; rest: many0!(none_of!("()\t\n ")) &gt;&gt; (Ident::new(first.to_string() + &amp;(rest.into_iter().collect::&lt;String&gt;())).unwrap()) ) } ``` This more or less just recreates the regex logic from before. I know that there are combinators in `nom` to work directly with regular expressions, but I can’t seem to find one that matches greedily, i.e. gives me the longest initial segment that matches. `re_find` returns the first match, whereas `re_match` returns the whole input if it matches. Is there a better way to organize this? Should I get rid of the `regex` dependency, or lean into it and make the `nom` parser use it?
Thank you for the feedback. For me the main pain points for yew is testing and performance in relation to incremental updates of components (DOM manipulations). I think there is a lots of work to do there. In the end yew should reach some 1.0.0 API stability to be usable in production environments.
This kind of thing is what async/await is meant for, though it hasn't stabilized yet.
Not every crate needs explicit support to be able to work this way. The easiest way to tell is to try to compile your crate to `wasm32-unkonwn-unknown`, and see if the compile fails. If it does, then you have to sort out why, and maybe `cfg` some stuff. Does that make sense?
C doesn't allow returning variable-sized arrays from a function either.
Well in C you just pass pointers around.
So... Using Ruukh, I can write all the code in Rust, without any HTML, CSS, or JavaScript, and make a website? I've never used React.js/Vue.js, but I've made websites. I want to use Rust and WASM, but my primary issue is that to use wasm-bindgen you currently probably require webpack... (for the polyfill, I think)
Is there a way to instantiate this `A` struct? struct A&lt;'a&gt; { b: B&lt;'a&gt;, } struct B&lt;'a&gt; { parent: &amp;'a A&lt;'a&gt;, } 
Nice, hopefully anything will work out
From a function? Would you do char * bytes_to_fixed_size_array(char * ptr, size_t size) { char array[size]; memcpy(array, ptr, size); return array; } in C?
I shared your confusion with the word "tangle". I can understand wanting to create a new vocabulary, but I couldn't find an explanation of the term anywhere! :(
No, nobody would do that
Except that's kind of what you are trying to do in Rust. 
Like this: http://tpcg.io/3x2SGd
But in C you wouldn’t have functions taking those kind of arguments, so you wouldn’t need to. In C it’s simpler; pointers.
That's semantically equivalent to a `Box&lt;[u8]&gt;` in Rust, or a `Vec&lt;u8&gt;` if you don't mind a very small overhead. 
Looks like it's not possible with unsafe code. But is this code "safe"? #[derive(Debug)] struct A&lt;'a&gt; { b: B&lt;'a&gt;, x: u8, } struct B&lt;'a&gt; { parent: &amp;'a A&lt;'a&gt;, u: u8, } use std::fmt; impl&lt;'a&gt; fmt::Debug for B&lt;'a&gt; { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { write!(f, "B {{ u: {}, parent.x*x: {} }}", self.u, self.parent.x * self.parent.x) } } fn main() { let dummy = unsafe { std::mem::transmute(std::ptr::null() as *const A) }; let mut a = A { x: 2, b: B { parent: dummy, u: 255 } }; a.b.parent = unsafe { std::mem::transmute(&amp;a) }; println!("{:?}", a); }
But the function I’m calling in Rust doesn’t want a Box or a Vec or a Fluff, etc.
Also bold of you to assume the existence of malloc on your target system. I'm usually not that lucky.
No, you would still require CSS for styling and also Ruukh is an alpha library, so it is discouraged to use it for production sites. It uses wasm-bindgen under the hood and the CLI provided to run Ruukh apps makes use of `wasm-bindgen --no-modules` flag to run without the need of webpack.
Can I ask why not? Both Box and Vec are abstractions for memory allocations so that, unlike the C program you wrote, your application doesn't leak memory. And don't give me an "It's only a toy example" or "At the end of the program, the OS will reclaim the memory anyway". Rust doesn't distinguish between a simple main function in a toy program and a library function that will be called millions of times in a tight loop: it has to be safe either way, so randomly allocating memory and storing the reference in a context-less pointer is wildly unsafe and thus difficult to work with.
It was an example. Feel free to call free if you like. I don’t find it difficult to work with pointers. I don’t know why the function wants what it wants, I didn’t write it, and I’m not at liberty to change it.
&gt;At the end of the program, the OS will reclaim the memory anyway That's true. At the end of the program, the OS will reclaim the memory. Why would you call free on the last line of a program? You wouldn't.
Couldn't correct the title, the actual title is: "Reporting: A hot woman’s take on AI"
Thanks, seems like this is a common experience. Previous discussions of Rust books from Packt: - https://www.reddit.com/r/rust/comments/6uguph/rust_cookbook_packt/dlui5cx/ - https://www.reddit.com/r/rust/comments/35qqzv/rust_essentials_packt_books/cr72o2f/ - https://www.reddit.com/r/rust/comments/2rnked/rust_book_by_packt_publishing/cnhkrxe/
Totally epic. I'm going to submit this for my compsci assignment.
Nope. Don’t worry about it, it’s all working fine, if you scroll up you will see a guy gave me a macro, it works perfectly, very impressed.
I think you'll want `io::read` (https://docs.rs/tokio-io/0.1.9/tokio_io/io/fn.read.html) rather than `reader.read`. All the reading methods directly on TCP streams seem to be only the building blocks for futures, and not really something you would want to use yourself as a consumer of tokio. `io::read` on the other hand should give you an actual `Future` like `io::read_exact` does.
I still want to see the library you're calling. There's a good chance that it could be improved regardless.
You can get good books on Packt, but it's a crapshoot. Haskell community noticed the lack of quality controls a while back. Disappointed, but not surprised, that the affects Rust offerings from Packt, too.