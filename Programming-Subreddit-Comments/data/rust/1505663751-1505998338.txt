Here's a project I wrote tusing rust-cpython and setuptools-rust that works: https://github.com/saethlin/rust-lather. All the interface to Python is in the src/lib.rs. I wish I could have use PyO3 for this, but around the time I was writing it nightly kept breaking all the numerical libraries.
You might look into https://github.com/termoshtt/rust-numpy as numpy is heavily used in machine learning in Python.
You are right, it is more like autocorrect. I think it is good. üëç
Huh, that might be the problem. I'll try again.
Yeah that looks intersting but unfortunately it can't do what I need it to. In particular I need to be able to open a channel just by supplying a path to a local socket and have multiple clients but what I have now works for that.
Just thinking out loud, if your rust code compiles to a library with c exports, you could write a C style header file that declares the API functions. Then you should be able to use swig ( http://www.swig.org ) to autogenerate bindings for you C headerfile. Then build the bindings, and link with your rust library, and you should be able to call your rust code from python after doing a normal import.
Ripgrep is a great rust program and grep replacement and is blindingly fast by using rayon. 
For systems programming memory handling matters. So languages like Haskell where a left fold or right fold sometimes can lead to tricky memory usage explosions are kinda not usable. Course this mostly an issue because Haskell is default lazy. But Idris is eager so that might be better. 
I think you should talk a bit in the readme/documentation about what kind of conversions are considered unsafe but defined, and which are straight out undefined behaviour. Having the conversion traits encourages people to implement unchecked conversions, but unless there isn't education about what is UB and what is not, people are likely to do the wrong thing. Lately, there was was this thread about converting a slice of i8 to a slice of u8 efficiently, and it was pointed out that transmuting between them was explicitly undefined behaviour: https://www.reddit.com/r/rust/comments/7058ps/efficient_way_to_convert_an_i8_vecslicearray_to/ It's tempting to use transmute, and it's tempting to implement an unchecked type conversion that uses transmute. As people easily have the mental model of both i8 and u8 being "just a byte", interpreted differently, they tend to think that transmuting between them is safe, because there is no trap values. However, that is not so, unless the types are also `#[repr(C)]`: https://doc.rust-lang.org/nomicon/transmutes.html The transmute is likely to _work_, but there is no _guarantee_ that it always works, continues to work or works on all platforms. Because Rust types without `repr` don't have defined memory layouts, the compiler is within its rights to represent the slices in any way it wants, as long as "nobody notices". And because transmutes between "non-repr(C)-types" are UB, the compiler is allowed to pretend that no such transmute even happens, so the "nobody notices" rule doesn't hold. And this allows getting a type, which might have a completely broken memory layout, because the compiler did some tricks, and the memory layout wasn't what the user expected. These are all subtle things, so I think people should be educated about them wherever there are chances that they might do the "wrong thing".
* The simplest way to do it is to treat Rust as C, expose a bunch of `extern` functions, and consume these using from Python using cffi (or ctypes). It also works with both CPython and Pypy, and even other languages with an FFI (e.g. R or Ruby or whatever) which is nice. The downside is that it's less expressive (you're limited to C semantics) and less safe (since the interop layer is via C, you've got all the safety of C semantics) * A more complex but somewhat better integrated way ‚Äî though exclusive to cpython ‚Äî is to use the cpython or pyo3 libraries and build *native extensions*. That's got the advantage that you can directly interact with "proper" CPython objects from Rust and can thus provide richer and better API from Rust directly (rather than need a pure Python layer over your native code) but the use is limited to CPython.
The counter-example is Python: urllib, urllib2, ...
Doing this for a living, this is pretty much exactly how I do it in C. *thumbs up*
I strongly agree; this is wildly inadvisable for some data types, because rust naively assumes that the alignment of the target type is the same as that of the source type. This caused no end of problems when I and a colleague were working on a port of rust. The rust compiler itself could probably solve this in many cases by applying the source type's alignment to the target type (e.g. if source type has alignment 1 and target type has alignment 4, then use alignment 1). Of course, solving the alignment problem is just part of the issue as you also point out.
I haven't tried it out, but I'm aware of these: https://github.com/jamesmunns/bluepill http://blog.japaric.io/quickstart/ (not specific to blue pill) 
IIRC it has to do with what _you_ work on, not what your company works on. But yes, this is tricky business.
Not the Blue Pill, but I just came across this today: https://japaric.github.io/discovery/README.html The author of this has done work with Blue Pill: https://github.com/japaric/blue-pill
The presentation that I mentioned in the edit uses the second approach, right? If so, that works for me now (on Ubuntu). It seems pretty nice. CPython is okay for me, I don't need anything else.
Right, Ruby even has a whole class of bugs that fall into this category of "modify-while-iterating" problems. (Obviously this depends on the specifics of the objects being iterated over.) Avoiding these bugs while still being performant can require knowledge of implementation specifics, such as whether a given `Enumerable` class's `#each` method returns a reference or a copy. Rust's compile-time explicitness makes it perfectly clear what's going on, without too much syntactic complication. All that might seem irrelevant to concurrency, but in my mind the question "who owns the stuff in this block (or closure)?" is a core concern of the foundations of concurrency.
I'd start with rulinalg, but would recommend not relying too much on any one framework at this point. The ecosystem around Rust ML projects is fairly small, so it's a "wait and see" problem regarding production code, but rulinalg and [rusty-machine](https://github.com/AtheMathmo/rusty-machine) work together nicely and both have active user bases focused on ML (rather than 3d graphics), and the maintainer is responsive.
I am just starting to look into Rust, even though I don't expect my code to become faster. I currently work with seismic data acquisition and processing. A good deal of the code will be IO bound, due to the sheer volumes, and when CPU speed is an issue either hand coded SSE / AVX code or gcc vectorization will be used. From what I have seen Rust does not have any particular advantage here. The work we handle is also embarrassingly parallelizable, and running more jobs in parallel is usually the easiest way to utilize the HW. That having been said, I am excited about rust for entirely different reasons, namely the inherent safety aspect. One possible use area will be to schedule and do load balance the existing C++ jobs, where it would be a requirement that that the scheduler is rock solid from the start, which can be tricky when it has a very high degree of concurrency. ( Starting, stopping, and monitoring ongoing jobs- maybe do some message brokerage to monitor progress and performance + interact with databases ) Rust seems like an excellent tool to have in my programming toolbox, along with a handful of other languages. 
Hey, I'm the author of the first one. Use Japaric's instead, I only worked on mine for a few days, and he uses his much more. I believe his is linked in another comment here.
It looks like you got down voted for asking this and I'm going to give you a serious answer on the assumption that you don't recognize what they're saying is bad in a non patronizing way, I have no idea what your background is here. In relation to needing to have a GitHub profile with FOSS work: &gt; We want not only the best and the brightest but also the intrepid. Yes, I want to see that you know your stuff and no, passing a whiteboard puzzle interview is not the best way to show it. I want to see your code but I also want to see you raise the bar on yourself and then pull up to it. In other words, do something if you want the job. Make time, take a few evenings or weekends to put some code out there. If you only complain and shrug your shoulders then you don't want it bad enough! I'm talking from personal experience, 25 years of working mostly closed-source jobs. This is an unhealthy view. Not everyone has time in their life to just code all the time. I don't know about you but I like spending time with friends, catching up on some Anime, or reading. It's what lets me decompress. Do I like doing FOSS? Yes! Not everyone has that kind of time though so to dismiss candidates as being worthless if you don't is troublesome. It has a tinge of they want a workaholic or that's the kind of stuff they expect. It's not an attitude that lends to letting employees have a good work life balance. But you might think well that's just an easy way to see someone's code! True, it is but here's their attitude about not having one: &gt; It also weeds out the incompetent and the lazy. Yeah no thanks, this is your attitude towards others? This is the statement of someone who lacks empathy and can't extend their thoughts about why someone might not have a profile beyond their own needs. I don't want to work for someone who lacks the ability to understand others conditions and has contempt for other human beings without actual proof as to why they should feel that way. &gt; I want the folks who can dig into our code base on their own. There will be readme files and design docs but no lectures on how things are done. You are confusing on-the-job learning with training. Over time people will learn a code base but it takes like 6 months on average. Sorry, I don't believe chucking people at code and expecting them to "git gud" is the right way to do it. Show people where things are, get them up to speed, show them the ropes until they get it. Learning a new code base, especially a giant one is a tough task and not easy. Constructive help and mentoring is good. Throwing people at it and expecting them to do it with no help is one where I see someone wanting to use coders rather than helping them grow or invest in them. Investing in people and investing in their well being as well as knowledge, will grow a company. It will make it open and fun and rewarding to work at, but having a leader with this kind of callous attitude will only bring ruin. I don't and refuse to work for someone who acts like this because I've already worked for enough people like this in my lifetime to know this isn't leadership, this is just someone with authority trying to act like a leader, when all they care about is their own interests. Oh the other thing is the whole company looks like a pump and dump ICO block chain company and I want nowhere near that space in general. This is just the icing on the cake. Hopefully this answers your question. I want Rust to be used in production, but just like every tool, not everyone who wields it is a good person.
&gt; The basic problem I would describe it even more basic than that: Whenever you call a function in Rust (and this is *any* function call all the way down to basic operations), the arguments must obey the uniqueness rule: - A unique reference (`&amp;mut`) may not overlap with the bytes of any other reference. Safe Rust gives compile errors, unsafe may silently compile an incorrect program. Either way, you always have to follow this rule.
Agreed, though one does not need to be part of this community to downvote someone here. It may very well be that other redditors are voting, too.
Agreed! I'll definitely add info to the docs as to what is explicitly defined behavior and what isn't. The only `transmute` done is converting C-like enums from their representative type. As far as I know, this is ok as long as the input value is a valid instance of the `enum` type. Is there a list describing what common mistakes are in reality undefined behavior in Rust? Thanks!
Agreed. "Modify while iterating" problems also exist in other languages (Python, C++, Java etc).
What an awesome overview! Sadly, quite a few images aren't loading on the results page. They might be embedded improperly. Luckily Archive.org stored a snapshot of them: https://web.archive.org/web/20170915092135/https://sites.google.com/view/energy-efficiency-languages/results#close
Absolutely, I just mention Ruby b/c that's what the OP said he used. That said, idiomatic Ruby is more or less built on closures ("blocks"), and so the ambiguity of closures capturing by reference or by copy (clarified in Rust's `Fn` or `FnMut` traits and the `move` keyword) is always something that I have to get used to when returning to Ruby after a long time in Rust-land.
Check the link to nomicon! But I'm not sure if that's up to date, since there's ongoing discussion about the memory model and what should be considered UB. Ping /u/RalfJung ! Btw. is there any reason why using transmute considered is UB but casting raw pointers (in the case you're not producing invalid values) not? Isn't it essentially a similar kind of thing?
I also think that there should be a lint against uses of `transmute` that are likely to be UB. I just tested on the playground, and there was nothing...
Yeah that's a good idea, I have exams this week but I can probably pull it together after that.
I remember reading in the docs somewhere that pointer casting should be preferred over `transmute` in some cases.
Trying to double-borrow like in the second case, sure, but in the first case the compiler is actually *too* conservative, as the arguments have to be evaluated before the method call anyway. 
I'm surprised no one has mentioned [snaek](https://github.com/mitsuhiko/snaek) yet. I like it's approach of pure c API exposing rust shared libraries and automatic cffi python side bindings for them using cbindgen.
&gt; (Windows later)
hm, the rust version with push works just fine, i wonder why :/
`new` is not `malloc`, one can replace `new` with anything at link-time, and that anything can just `throw` 100% of the time, meaning that removing it would change the semantics of your program.
1.20 is the current stable version. EDIT: however the docs are wrong, it's not available until 1.21. I sent a PR to update them.
I don't see how Haskell's unsoundness around newtype deriving is related to specialization. Newtype deriving &amp; specialization are not related at all.
That isn't really better, most design work is public and can be linked in a portfolio. Code is almost never open, even if the application is public.
I don't know how low his score was when you posted, but -10 is hardly "aggressive downvoting". Besides, if ae-cto was more qualified at writing comments maybe they woudn't have been downvoted
You're looking for /r/playrust. This subreddit is about the Rust Programming Language.
I'm super-curious about this "rust flange nursery", though.
[**Edit: my opinion has changed**](https://www.reddit.com/r/rust/comments/70pl49/clarify_and_streamline_paths_and_visibility_rfc/dn66kfr/) I'm very disappointed in the several of the choices: - `src/foo.rs` + `src/foo/` instead of `src/foo/mod.rs`. This requires code churn, doesn't have the same idea as `src/lib.rs` and `src/main.rs` and generally INCREASES confusion at almost no benefit. - Completely changing the definition of `pub` (and adding a *weird* visibility of `crate`) does NOT make things clearer, will cause unnecessary code churn and is radically out of scope of the RFC. Both of these were brought up several times and they were **never addressed by any of the community team** and appears to have been outright ignored. I'm feeling like the RFC process isn't working very well when comments are completely ignored by those in control so they can push through accepting [**17 RFC's in the last month**](https://this-week-in-rust.org/) (count over the last 4 weeks). This rate of **more than two massive changes per day** is completely absurd and uncalled for, and is going to continue to make the community feel unheard if they continue this trend. Why even comment if the team responsible for considering those comments are too busy with 10 other RFC's they are in the process of merging? **Edit:** The proper response to not being able to hash out concerns would have been to reduce the scope of the RFC to only it's core features and split out the more concerning features into separate RFC's. Instead they charged through without even addressing the concerns. I think [this comment](https://github.com/rust-lang/rfcs/pull/2126#issuecomment-328698148) summarizes things nicely.
"Beginner friendly. No previous experience with microcontrollers or embedded systems is required." As someone who has been learning Rust, and as someone who has been wanting to learn microcontroller development this is fantastic. I look forward to reading it.
If you are using Neovim, you might want to take a look at [RLS](https://github.com/rust-lang-nursery/rls). It uses Racer and rustfmt behind the scenes, and also provides linting without doing a full build each time. It also provides functionality that your setup doesn't have, like renaming and finding references to a symbol. And it has code actions support - from [glancing at the code](https://github.com/rust-lang-nursery/rls/blob/9c3c4b924250a79a69d410b36dfbf4123cca0251/src/actions/requests.rs#L588) it looks like they are based on the fix suggestions rustc spits on it's warning and errors, but [LangugeClient-neovim](https://github.com/autozimu/LanguageClient-neovim) does not support code actions, so I can't verify this(they did [start the implement it](https://github.com/autozimu/LanguageClient-neovim/blob/88430f57cda28b575b1a586c79ce143ef73d16cd/rplugin/python3/LanguageClient/LanguageClient.py#L1140) though - so we should see it in the hopefully near future...)
/u/japaric and everyone else who is involved's work is just phenomenal. I keep intending to get involved, but I haven't made time yet :/
[`assert_cli`](https://docs.rs/assert_cli/)
Link for the lazy: https://github.com/stainless-steel
`mod.rs` will still be possible. In fact, there will be less churn by allowing you *not* to rename your `my_module.rs` files to `my_module/mod.rs`, should you want sub modules (`my_module/new_submod.rs`). Another benefit is that you wont have a dozen`mod.rs` files open at the same time, in your editor. The `crate`/`pub` distinction will make it a lot easier to reason, from a local perspective, about the visibility of items. `pub` will be public API, and `crate` visibility will be visible to the current crate alone. These things have been discussed for months. You're completely misrepresenting everything for who knows what reason... The RFC process has been working wonderfully. Thanks to many insightful members of the community the discussions have been a real pleasure to read, seeing that no stone has been left unturned. I think that all decisions that have been made recently are going to turn Rust into a significantly more ergonomic and productive language. 2018 will be a great year!
Your description of the RFC itself is wrong: * This does *not* require "`src/foo.rs` + `src/foo/` instead of `src/foo/mod.rs`." It *allows* it as an option, and it doesn't have to be stabilized if it turns out to be a bad option during experimentation. * It also does *not* change the definition of `pub`. It adds a lint that suggests people use what *already exists* as `pub(crate)`, a more restricted visibility, under a new name `crate`. This also does not have to be stabilized as deny-by-default. There was extensive discussion on both of these points that *was* addressed by the team, including the comment you link. The RFC was *drastically* reduced in scope several times with the more concerning features dropped or split into separate RFCs. This is also perhaps too alarmist of an interpretation of what's going on: Many of these RFCs merged in the run-up to the "impl period" have been going on for a really, really long time. Many of them still have explicit "unresolved questions" that are intended to be resolved with experience from experimentation/implementation. In fact, even outside of unresolved questions, merging an RFC doesn't mean anything is set in stone- it means the concept has enough consensus to start working on an implementation. The team is trying to move even farther in this direction to avoid a "waterfall" planning style with massive RFC threads that are mostly speculation without any actual experience.
&gt; The proper response to not being able to hash out concerns would have been to reduce the scope of the RFC to only it's core features and split out the more concerning features into separate RFC's I believe this is exactly what happened. I think I saw 3 successive modules RFCs, each of which was smaller and more focused. Of course, one can maybe argue that this process didn't happen enough, but the RFC process is doing *exactly* what you want it to: the original proposals were discussed/rejected and refined versions constructed. It can definitely be annoying if an RFC is merged that one doesn't like and doubly so if one's concerns are seemingly not answered, but I'm not sure trying to turn it into an "us vs. them" pitched battle between the "community" and the "teams" is very productive (in many ways, the teams are the community: most of the members are volunteers who did, and still do, great work, both technical and not).
Hi, I am Zack. I am building a blockchain too, but I am not hiring programmers right now. I made this virtual machine in rust for my blockchain. https://github.com/zack-bitcoin/forth-in-rust
Playing with rayon now. Thanks for the podcast!
I added a [section on defined behavior](https://github.com/nvzqz/uncon-rs#defined-behavior) to the readme. Let me know if there's anything else I should add. Feel free to make a PR.
What can I do with this? Writing drivers or user space programs? Would it lead to Rust bindings for flutter?
I'm looking forward to one day writing Rust code for the ESP32. Does anyone know if there is any active development going on for having LLVM emit code that can run on an xtensa processor? I'd love to help out with that though in no way could I do it alone.
Yes, they did back off from massive backwards incompatible changes into a 4-for-1 RFC. That, at least, I am thankful for.
well, you are right that according to the RFC text it is not required to use `src/foo.rs` + `src/foo/`. However, I find it highly unlikely they won't eventually create some lint to enforce the new way of doing things. Even worse, for a while there is going to be two ways of doing the same thing with no clear standard. That is moving *backwards* on learn-ability. When `foo.rs + foo/` is the "standard" it is going to make `main.rs` and `lib.rs` seem even more weird... why doesn't `lib.rs` live outside of `src/`? Should we change it to `lib.rs` + `lib/`? Maybe...
Not via rustc+LLVM, but possibly via mrustc. See the thread at https://news.ycombinator.com/item?id=15270583
These are definitely questions that we should explore with a working implementation. :)
&gt; i8 / u8 I don't believe that is UB proper or even an undefined value. It's not well documented, sure, but three points: - i8 is defined as isomorphic to eight bit two's complement representation https://doc.rust-lang.org/1.17.0/reference/types.html -- there is no sane reason to expect any other representation. When's the last time you saw a one's complement microprocessor? - if the definition of `transmute` ever becomes anything other than `bitcast` that will break a *lot* of code. - i8 and other primitive scalar types don't need to be repr(C) 
I think the point was that `Vec` is not `#[repr(C)]` and thus should not be transmuted. The proper mechanism for doing such an operation would be `Vec::from_raw_parts` and a pointer cast from `*mut u8` to `*mut i8`. I actually recently wrote about this [within this crate's docs](https://docs.rs/uncon/1.1.0/uncon/index.html#safety).
OK, the problem is that the `setuptools-rust` example code really isn't written with novices in mind and definitely wasn't written to match up with the `rust-cpython` example code. Now, before I explain how to fix it, I just want to point out that `setuptools-rust` isn't strictly necessary. If you don't mind manually copying (and, on Windows, renaming) the built Rust library into place, `rust-cpython` is all you need. `setuptools-rust` is just a very nice way to integrate `rust-cpython` or `PyO3` into the Python build/install process. **That said, some of the mistakes I'm going to explain how to fix can bite you with *any* compiled Python module, so I recommend you read on.** Here are the missing steps to get something you can experiment with: 1. Your immediate problem is that the `setup.py` given assumes that your Python project builds a module named `hello_rust` (`packages=['hello_rust']`) but you haven't actually created the Python code to match that. You either need to create that package (create a folder named `hello_rust` and, inside that, a file named `__init__.py` which can be empty) or set up a different "Here's how my code is laid out" definition and change the `hello_rust._helloworld` field in the `RustExtension` declaration which tells it where the compiled library should end up. For this case, let's just create `hello_rust/__init__.py` inside the `pppp` project and move on. 2. Once you've resolved that, you'll run into an error saying that your package "does not have these features: `pyo3`". This is because the `setuptools-rust` example assumes you're using PyO3 (the enhanced fork which requires nightly Rust) rather than rust-cpython. To fix that, just change `binding=Binding.PyO3` to `binding=Binding.RustCPython` in `setup.py`. 3. Now, if you're trying to build against Python 2.7, you'll run into an error about `PYTHONSYS_ENV_VAR` already being defined. This is because `rust-cpython` defaults to building against Python 3.x and the build errors out if you try to build for both Python major versions in one go. If you're working with Python 2.7, just change the `features` line in `Cargo.toml` to default-features = false features = ["python27-sys", "extension-module-2-7"] 4. Now let's add some example Python code to actually use the Rust module. Put this in `hello_rust/__main__.py`: from . import _helloworld def main(): print("Calculated with Rust: " + _helloworld.sum_as_string(1, 2)) # This allows main() to be called both via `python -m` # and via setuptools entry points. if __name__ == '__main__': main() 5. Attempting to run that with `python -m hello_rust` after running `python setup.py develop` will reveal one final error: ImportError: dynamic module does not define init function (init_helloworld) This confusing message comes about because of how Python loads compiled modules. It expects certain entry points within the compiled module to match the filename, and the two examples don't agree on what the module should be called. Specifically, the `py_module_initializer!` directive from the `rust-cpython` example says it's supposed to be `librust2py`, but the `RustExtension` definition from `setuptools-rust` and the test code we just added assumes it'll be called `_helloworld`. Change the `py_module_initializer!` line in `lib.rs` as follows: py_module_initializer!(_helloworld, init_helloworld, PyInit__helloworld, |py, m| { (I chose to change this one since it's the one that tripped me up when I got started for want of a second known-valid example to compare.) **With that done, you should have a working project, but there are two final caveats I'd like to point out:** 1. It may be fixed now, but, when I was initially working with `setuptools-rust`, I sometimes ran into situations where it didn't realize the module needed to be rebuilt. (This ability for "do we need to rebuild?" detection to trip up seems to be something every build system encounters sooner or later.) If you're getting confusing errors, try manually deleting the built module, running `cargo clean`, and triggering a rebuild to make sure stale files aren't your problem. Because `cargo clean` doesn't know about the copy of the build artifact that `setuptools-rust` puts into the Python package, I like to use some build automation ([just](https://github.com/casey/just), a shell script or batch file, etc.) so I can type something like `just clean` and have it call `cargo clean`, then go on to remove any extra files it's unaware of. Here's what a `justfile` snippet to do that on Linux would look like: # Clear out all built files clean: cargo clean rm hello_rust/*.so hello_rust/*.pyc || true # vim: set ft=make textwidth=100 colorcolumn=101 noexpandtab sw=8 sts=8 ts=8 : 2. While you seem to not have gotten hung up on it, convention is that `setup.py` should install any extra dependencies rather than dying for lack of them, so I'd also suggest replacing the `from setuptools_rust import Binding, RustExtension` line in `setup.py` with a workaround like this: # Workaround from https://github.com/PyO3/setuptools-rust/issues/2 try: from setuptools_rust import Binding, RustExtension except ImportError: import os, subprocess, sys try: subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'setuptools-rust']) os.execvp(sys.executable, [sys.executable] + sys.argv) except subprocess.CalledProcessError as err: print("Please install setuptools-rust package") raise SystemExit(err.errno) [Here's a GitHub gist](https://gist.github.com/ssokolow/34ce62a0d98054810c488a7f0d3fd4e0) with all of the relevant files (though some will need to be moved into subdirectories as stated in the comment at the top of the file, since Gist doesn't allow subdirectories.)
Overall I like this RFC, but I‚Äôm still kind of bothered that this didn‚Äôt completely eliminated the leading ugly :: syntax. I like how use decelerations auto adds it since they are fully qualified, and I guess within the code you can‚Äôt do it due to name conflicts, but it‚Äôs still ugly. Also I think the whole thing would be much less of a problem once IDEs support auto importing and managing use statements.
Might be a good Clippy lint
I have been looking for something like this Thanks
In case you're curious, here's a [screenshot](https://i.imgur.com/2yQMBZI.png) of the current state of the frontend... though most of the effort so far has been poured into refactoring and improving the heuristics, which are, by definition, the kind of things you only notice when thet fail. The sidebar is going to be turned into a tree view where you can create your own groups of tags and multi-select provides a visual way to implement AND/OR filtering by ORing together items within a group, then ANDing together groups. (eg. (play_status: in-progress OR play_status: endless) AND (install_status: installed OR install_status: downloaded)"
I'd really prefer a written article or transcript. 
I'll start practicing for my [RustFest](http://rustfest.EU) talk. I also *may* do some clippy work and start looking into variable-length array implementation if I find the time.
Receiving a benefit from subverting the ranking algorithm via multiple posts to the same content is most certainly gaming the site. In fact, while I don't have time to check right now, I wouldn't be surprised if Reddit's rules have something to say about it.
That's a reasonable viewpoint, and after tumbling Nomicon a bit, it indeed says the layout being undefined in the context of structs and tuples, not primitives. If that is the case, I think that the transmute page in Nomicon should be clarified. I mean, as long as the memory model discussion is still ongoing and the reference doesn't cover everything, it might be possible to say what is reasonable, but hard to say what is RIGHT. Btw. regarding your second point, I don't mean that transmute would be anything other than bitcast, but the question is: what are the bits going to be casted? Does it say somewhere that the primitive scalars don't need to be repr(C)? I believe the reference speaks about semantics, that is, which values are allowed for which types, but I could find whether they also guarantee a specific memory representation.
Sorry for off-topic -- how do I use your colorscheme? Tried to copy it to my .vim/colors but for some reason `:color nnkd` doesn't change anything.
You're looking for /r/playrust
I'm working on something a bit like rustup, but with an interface inspired by Cargo and POSIX conventions. My working name is "rustenv", but I don't like it much and I'm looking for a better one. The idea is that running `rustenv activate` will spawn a subshell (or any other command you want) with sensible versions of Rust and Cargo in `$PATH`, so you can get to work immediately. If you need to define "sensible" more precisely, there's a Cargo-style `rustenv.toml`/`rustenv-lock.json` system so you can be sure your CI builds will use exactly the same toolchain as your development environment. I don't expect to replace rustup, but it's the toolchain-updating-tool I want to exist, so I'm going to try to make it happen.
I love it. "." is too overburden if it replaced "::"
Yeah, but wouldn't that then show the same alert for the correct crate?
Sorry, apparently my comment rubbed you the wrong way. Lisp machines were built a long while ago when processors looked very very different. Now we have instruction pipelining/reordering, cache prefetch that does its best to work around long latency when fetching memory, etc. You can't go back to the naive approach Lisp machines took two decades ago when without giving up on what makes today's processor fast (it makes little sense in particular if your motivation is speed). What you are suggesting is run the add operation for all possible types of the object. This means that either you give up on running instructions in parallel the way any decent processor does today, or you multiply the amount of silicon on the process as well as the energy required to run it. Next is the comparison between lisp and JS. The only number type in JS is 64bit floats (sadly). When your JS runtime does other kind of arithmetic it's actually because the JIT compiler has figured out that a series of operations can be performed on integers or whatnot through runtime analysis. If you give up on the JIT and concentrate on js-cpu that does addition in integers and floats in parallel, that case is actually quite rare because without a jit, every number is a double, and with a jit, well you don't need that hypothetical CPU. What is very common, and what is actually the meat of "type-checking" in javascript, is taking a JS object which we can see (for the sake of simplicity here) as a glorified hash map, and laying its members contiguously in memory at constants offsets. Then the jit will do its best to avoid looking up members from their (string) names and instead fetch the values from offsets that are set directly in the generated code. *This*, is almost the number one thing that speeds up JS execution (number two after getting rid of the branchiness of the fetch-decode-run instruction loop of a typical software interpreter which is trivially removed by both the jit and an hypothetical JS-cpu), and it seems to me that it is far away from the stuff of lisp machines. Are you suggesting having hash maps hard coded in hardware? what would that (instruction?) do? Do you think you could have it outperform a jit that generates simple fetches at constant offsets on an x86 cpu (I really don't think anyone could). Another big thing to speed up JS execution is getting rid of branches all over the place that give the CPU branch predictor a hard time, gets in the way of reordering and pipelining instructions and bloats the number instructions that has to fetched from memory (while so many of them are not going to be run). Here again, remember that the lisp machines were from a time where fetching a value from memory was not that much slower than adding two integers (now there's a 300x difference). Running all branch arms in parallel would be insane (it's not one instruction you need but dedicate threads at this point, and the silicon could be much better spent elsewhere) but that would not help with the cost of instruction cache misses. I could go on for a while about what makes JS fast and how it looks very far from what you are suggesting. I maintain that the cost of type checking is not a matter of adding numbers but really being able to pack objects in memory and fetching data from constant offsets instead of a map which I still don't see as a parallel problem *at all*.
I actually like this RFC, because it eliminates some useless boilerplate, but does it mean that Rust slowly moving from explicit to implicit ideology? 
Wasn't the ideology always "be explicit if it helps, implicit if it doesn't? It has type inference in functions after all.
[removed]
Smooth scroll (hijacking scrolling), modal popups... yeah, I agree.
I would expect that "casting" a &amp;[u8] to a &amp;[i8], or even to a bigger integer type (assuming the alignment is correct) would work when going via `slice::from_raw_parts` and `slice::as_ptr`. It is guaranteed that the underlying memory (as returned by `as_ptr`) is just the raw bytes without anything else. What am I missing?
I was aware of it, but consider it far too low-level to be a viable answer for a "Simplest way to..." question in /r/rust. (After all, if you're talking about using Rust to build something for a managed language that's traditionally built using C, it carries certain implications about what "simplest" is meant to entail.)
&gt; `src/foo.rs` + `src/foo/` instead of `src/foo/mod.rs`. This requires code churn, doesn't have the same idea as `src/lib.rs` and `src/main.rs` and generally INCREASES confusion at almost no benefit. Actually, I am reading rust book right now and was very confused with whole `path/mod.rs` thing. It is counterintuitive. And today this RFC got into my feed and I am pretty happy feeling I might not need to get used to this `mod.rs` thing after all. If this change means to make it easier for newcomers to understand module paths, it hits the mark.
Just to be clear, I‚Äôm not against :: in general, in fact I‚Äôm used to it from c++. I‚Äôm talking about when it‚Äôs in the leading position like in ::std::something
That would be awesome!
Is RLS faster than `cargo check` for linting?
The difference between using [rusty-tags](https://github.com/dan-t/rusty-tags) and [ctags](http://ctags.sourceforge.net/) directly on a cargo project is, that `rusty-tags` doesn't give you only tags for the projects code, but also for the standard library and the dependencies of the project.
I use Blue Pills with Rust. It works perfectly and is supported out-of-the-box by your usual rustc (although using xargo is preferred by some). When considering a Blue Pill, you must keep in mind that it is not plug-and-play like majority of the microcontrollers out there. You must have some way to program it -- either via its bootloader that only supports serial or via SWD pins (using something like ST-Link or a knockoff). I made myself a black magic probe [out of another blue pill](https://kazlauskas.me/entries/black-magic-driven-development.html) for that, for example. Once you have something like that, flashing your code is as simple as giving your rustc-generated binaries to your ELF-aware programmer tool (e.g. gdb).
&gt; This was my guess, do you think that more crates will be integrated into the stdlib as Rust matures? I believe this is the plan. A fair amount of stuff was removed pre-1.0 because it wasn't deemed good enough / ready enough to be committed to as a stable API at that point. I would anticipate `rand` making it back in at some point. 
On the other hand, it looks to me like trying to write a binding turned out to be an excellent way for the OP to learn about the difference between references and raw pointers! Generally, i have learned an awful lot by trying to do things just outside the limit of my understanding, and then asking questions about them. Please don't discourage people from learning this way.
&gt; It's really, really useful to distinguish between how code is internally structured, and how it's publicly exported. I'm not convinced. Most other languages don't have this, and don't suffer for the lack. It seems like a needless overcomplication to me. One reason Rust might need it a bit more is that Rust's module system encourages a high level of ramification into submodules, because that's the only way to split code into multiple files. Again, i think this is a mistake in the module system, and two wrongs don't make a right. 
IMHO, it would be better if there were no immutable variables. Then there wouldn't be any confusion between the immutability of the variables and of the borrow. Instead, we would focus only on the mutability of borrows, which is the thing that really matters. Immutability of variables is pretty much decorative anyway. This is legal: fn main() { let mut mutable_map = HashMap::new(); let immutable_map = mutable_map; let mut mutable_again_map = immutable_map; mutable_again_map.insert(23, "wat"); } So is this: fn main() { let mut only_map = HashMap::new(); let only_map = only_map; let mut only_map = only_map; only_map.insert(23, "wat"); } My involvement with mutable variables is 90% adding and removing mut as i refactor to get rid of unused_mut warnings. A key thing to understand is that if you *own* something, then you can do whatever you like with it. Not marking it mutable is more of a reminder than a real constraint. It's only when something gets borrowed that stringent rules come into play. This [supremacy of ownership, rather than mutability](http://smallcultfollowing.com/babysteps/blog/2014/05/13/focusing-on-ownership/), is something that is unique(ish) to Rust, and trips up people who are coming from immutability-oriented languages. 
Simply make a pullrequest. :-)
Just look [here](https://www.reddit.com/r/rust/comments/70ipmk/crates_you_should_know_rayonsafe_threaded/dn3tlbu/). :-)
In this release: - lots of stability improvements. - a manual: https://pijul.org/manual/ - as a bonus, an updated release of Thrussh.
So it should work with the Maple mini (that comes with a bootloader and works with the arduino IDE/programmer)? Thanks.
The ownership and MPSC concepts made me want to implement lockless mechanism when I wouldn't even think about it using Java (my everyday** language). ** for now :)
I think it's my local connection issue, which is slow. However youtube videos and other website loads just fine.
Disclaimer: I'm not an expert. I hope that someone more experienced tells me where I'm wrong. Thinking about this a bit more, it may be that the difference is between using raw pointers and not. When a raw pointer pointing at a type is created, rustc must be a little careful about the representation and aliasing of the type. On the other hand, when using transmutes; to play devil's advocate, let's think of a hypothetical situation: we introduce as a local variable, an array `let arr = [0u8; 32];`. We never mutate the array, nor we let any references to it to leak from the function. We only read values from the array: `println!("Index 2: {}", arr[2]);`. I think that everyone can agree that the compiler would be legitimately able to optimise these reads to just constants being printed out, and elide creating the array completely. Now, let's introduce a `let signed = transmute::&lt;&amp;[u8], &amp;[i8]&gt;(&amp;arr[..]);`. If this is UB, like the Rustonomicon says, Rust is able to do anything. Even if it would be relatively benevolent and doesn't summon nasal demons or format your hard drive, it could still do something crazy, like pass transmute a bogus pointer, that is going to result into a bogus value. The point is that if this is not UB, doing the transmute should inhibit any crazy optimisation, but if it is, there is no need for that. Also, remember that were are talking about what the spec allows, not what rustc actually does. On the other hand, if this isn't UB, then Rustonomicon is wrong and should be corrected. What keeps bugging me is the standing of Rustonomicon. Is it supposed to be normative, or just a guide book? It might be that the remark there is a similar than the story about Kelpie: don't go swimming in the river, Kelpie's going to get you, as the children wouldn't believe that they aren't as good swimmers as the think they are. I think that there needs to be a clarification.
At last, I can program microcontrollers without using C/C++. I hate it so much.
[Direct link to exas website](https://the.exa.website) that was posted in this subreddit a few months back so you can avoid this terribly designed site.
Maybe it's just a newbie question, but there is a way to program to gpu using rust? Something like CUDA, OpenACC, OpenMP, OpenCL? 
RLS is not (yet?) usable with vim, I deduce?
&gt;... so it‚Äôs **small**, fast, and portable. Not so much: &gt; $ ls -lh ./target/release/exa /bin/ls &gt; &gt; -rwxr-xr-x 2 user group **1.6M** Sep 18 14:10 ./target/release/exa &gt; &gt; -rwxr-xr-x 1 root wheel **38K** Jan 13 2017 /bin/ls It does look kind of nice, though.
I'm getting rather tired of refuting this silly paragraph as it gets shuffled between RFCs without change: &gt; Is an item marked pub actually public? It's a fairly common idiom today to have a private module that contains pub items used by its parent and siblings only. This idiom arises in part because of ergonomic concerns; writing pub(super) or pub(crate) on these internal items feels heavier. But the consequence is that, when reading code, visibility annotations tell you less than you might hope, and in general you have to walk up the module tree looking for re-exports to know exactly how public an item is. [I've said it before](https://www.reddit.com/r/rust/comments/6w0urn/third_and_hopefully_final_version_of_the_module/dm5bzmu/), though, and I'm gonna say it again. You're trying to redefine what essentially every other language and every programmer means by a "public" symbol. It's _always_ public with respect to the scope it's defined in. A great example of _local reasoning_, stubbornly mislabeled as its opposite. If this gets through in the final implementation, it will confuse newcomers a lot, possibly more so than any warts in the current module system.
/u/eholk had the [RustGPU](https://github.com/eholk/RustGPU) project I have no idea how much work it would take to update as it is from the time before the boomy booms. Take a look at his [Harlan DSL](https://github.com/eholk/harlan) for GPU computing. This this /r/rust post from a year ago asking the same question, https://www.reddit.com/r/rust/comments/4dnq0h/gpu_programming_using_rust/
Yes, `Deref` coercion, type inference... `move`/`Copy` based on type... Rust is not "explicit" in many, many cases, and that's a good thing.
Everything should be preferred over `transmute` whenever possible.
I've removed the `error-chain` dependency from all my projects. I've continued to work on [titanium](https://github.com/antoyo/titanium), a keyboard-driven web browser. I've added some features: * Hint modes to download and copy URL. * Accept a number prefix to `G` to scroll to a specify percentage. * Add support for marks (also with the `'` mark to go to the position before the last jump). * Add private browsing. * Use another abstract namespace for the unix domain socket in debug mode (for easier debugging). * Add command to kill the window. * Show the URL in yellow when insecure content is detected and red when there's an SSL error. I've fixed many issues in it: * Fix scroll percentage in certain cases. * Detach the web inspector in a new window in every case. * Fix some downloads not working. * Decode the username the browser gets from `pass` to input the right username for the password filler. * Show the URL in the title bar when there's no title. As you can see, I've fixed long-standing issues because I want to make the first release of titanium soon. I added the ability to set the color for a status bar item in [`mg`](https://github.com/antoyo/mg) and it now accepts `'` in key mapping. I also made some tiny changes to [`mg-settings`](https://github.com/antoyo/mg-settings).
I took a diversion from my not-very-useful github webhook verifier to build out a tool to use at work: a fully-merged-branch cleaner upper. [branch-destroyer](https://github.com/BaconSoap/branch-destroyer) takes a look at all branches in a repo, compares them to the default branch of the repo, and deletes fully merged branches (well, right now it just lists all the branches and if they'll be deleted, but I hope to have the delete work today/tomorrow). We go through a ton of branches a day at my work, and about 1/4 accidentally get left open after they are merged. We were up to about 800 branches before I deleted 200 by hand (and then realized that I could script it pretty easily...). This mini project has been a great crash course that touched a lot of new things to learn for me and also is producing something I can get value from: HTTP calls, Serde, cli arguments, lifetimes, setting up travis/appveyor builds. Edit: it works! And I cleaned up another 154 branches. I don't have much reason to continue on it but I do need to make it respect protected branches (right now it tries to delete and just logs the fail and continues) and need to add an exclusion list. I'd also like to refactor some, especially around the github api calls.
Yeah already tried but he do not find it in the crate. I get: Could not find 'tests' in 'juniper'
I would definitely read how you fixed those bugs if you ever decide to write about them
can you give a quick explanation or reasoning behind your `error-chain` removal? I am planning to add it to all of my projects ;)
Outch, bad idea.
As much as I conceptually love rust, I spent at least 6-8 hours over the weekend unsuccessfully trying to hit a public API using hyper, and then deserializing the response using serde. After spending that time frustratingly banging my head against the wall, I ended up switching back to C# (my main language), and got further in 1-2 hours than the time spent trying to rustify it. It was pretty disheartening, to be honest, but one day I hope that rust's barrier for entry, and my ability to understand lower level coding, get to the point where I can develop quickly in it. Until then, though, I'll just stick with C# and all its baggage.
Still working on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). I've been tearing everything apart of change how the library defined marker traits are used and just started putting the pieces back together yesterday. If I can get everything working again I've have better code with fewer types that is also a lot more powerful.
Seconded!
Mad props for this answer
I plan to write a blog post about it. Here's some thoughts that I posted on IRC: &gt; One reason is that it can cause serious performance degradation with a feature that is enabled by default: https://github.com/rust-lang-nursery/error-chain/issues/129 &gt; Using simple things like bail!() or chain_err() causes the call to the backtrace crate even though it's not obvious at all from reading the source code. &gt; More importantly, I feel like error-chain makes the code harder to read when you want to match on inner (linked) errors with complicated match statements needed. &gt; Also, no it's [backtrace] not something for debugging only: at my workplace, we enable backtraces in production because when the system crashes, we want to know why. &gt; In normal Rust, the backtrace is zero-cost, so error-chain should be the same. &gt; [Without error-chain,] It's only when there's a panic that something happens. &gt; Also, this backtrace feature is enabled by default, so if you use any dependency using error-chain (and there's alas more and more), you have chances that this costly feature is enabled‚Ä¶ &gt; In my opinion, error-chain brings many complexities whithout bringing much advantage. &gt; If people want to avoid the boilerplate of errors, I'd say using a crate like derive-error will lead to less surprise (but this crate needs to be fixed to works on more kind of variants). &gt; But, I'd go even further than that: to me, the whole error story in Rust needs to be fixed. Perhaps we could take inspiration from Midori (http://joeduffyblog.com/2016/02/07/the-error-model/ - I haven't read it completely yet, but I plan to do it soon). That will be mostly the content of the blog post that I want to write.
&gt; Outch, bad idea. Planning is never bad ... :P doing could be!
I hope, Pijul will be an interesting alternative to git soon and there will be services like github for Pijul!
Exactly, though care should *definitely* be taken when pushing recently learned stuff to production. For learning, messing with pointers and whatnot is totally fine, but please make sure you're *very* confident before releasing something that needs to work consistently.
There is already a service that would like to grow and try to be a little like Github, but easier to use, distributed, open source and for Pijul: https://nest.pijul.com
I have a blog post in preparation for that.
Have you tried reqwest? That would probably be easier to use then hyper (it's built on top of hyper) 
I... don't know. `cargo check` seems like a mere wrapper around `cargo rustc` that adds `-Zno-trans` to avoid the last step of the build, after the checks were done. I tried looking at RLS' source, but couldn't find where it adds it. And yet - it does not produce an executable like actual builds, so I do think it skips that test... I don't have benchmarks, but theoretically it should be faster because it's a server: * It remembers the last compilation, and [this comment implies it uses this info to avoid a full build where it can](https://github.com/rust-lang-nursery/rls/blob/6996868356d577da5d48fe16ffbb699fe15c06d8/src/build/mod.rs#L372). * It does not need to to load the compiler code to memory each time. * `cargo check` doesn't add any optimizations over `cargo rustc` - all it does is add a flag.
\*chuckle\* Now that I've written it, I'm thinking I'll probably adapt it into a blog post.
Please provide a benchmark, and try explain why pijul is better. 
Transmuting `Vec` is a no-go, but it isn't involved in the definition of `&amp;[u8]`. The compiler does a bit of magic and has a special representation for pointers\* to unsized types, the slice representation. It's twice the size of a pointer to a sized type and not compatible with C. \* [Yes, even raw pointers](https://play.rust-lang.org/?gist=06a9e414045b6790575a60b190848f74&amp;version=stable) The only way to manipulate this representation is via the slice type `[T]` -- while you may define an unsized struct, you can't actually allocate one without [*really* sketchy transmutation](https://play.rust-lang.org/?gist=2bbba082c8bacb0688352a0bcde73339&amp;version=stable). There's precious little documentation of what the sound way is to do this. The mechanism is there, but not policy.
I haven't heard of that. Let me take a look at it and see if it'd be easier / usable for me.
Exciting! :D
* [nvim-langserver-shim](https://github.com/tjdevries/nvim-langserver-shim) is listed under "Vim" in http://langserver.org/ but has `nvim` in it's name. From the source it looks like it may work with Vim(it has some redundantly complicated code to check which version it runs on and pick the proper async job API), but I have no idea if it actually works with Vim. At any rate, [it seems to be deprecated in favour of a PR into Neovim itself](https://github.com/tjdevries/nvim-langserver-shim#notice), and after that the author says they'll delete it - so I doubt it was ever meant to be used in Vim. * The one I use is [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim). It uses Neovim's remote plugin API, so no Vim support. * Never heard of it before, and it's not in the LSP index, but [vim-lsp](https://github.com/prabirshrestha/vim-lsp) seems to support both Vim8 and Neovim. So... the third option may work. I was not aware of it when I wrote my original comment.
Thank you for the comments on [my post](https://www.reddit.com/r/rust/comments/70pl49/clarify_and_streamline_paths_and_visibility_rfc/dn57b7x/). Instead of just having non-constructive criticisms I have distilled my thoughts and hope to make improvements to the mental model of modules. I have opened [an RFC](https://github.com/rust-lang/rfcs/pull/2155) with my concerns and some new ideas as well. Check it out! **Update:** After the great response from here and the RFC, my opinion has changed pretty much 180*. Thanks to everyone for the discussions! 
An easy counterexample here is Java, which provides [a range](http://docs.oracle.com/javase/tutorial/java/javaOO/accesscontrol.html) of visibility for class members very similar to what this RFC is doing. In addition, Rust [has offered `pub(restricted)`](https://github.com/rust-lang/rfcs/pull/1422), which exerts finer control over visibility, for a while now. More generally, these issues were discussed extensively in the RFC comment thread, and in particular the importance and meaning of "local reasoning" in this context.
let me know what you think of my [new proposal](https://www.reddit.com/r/rust/comments/70pl49/clarify_and_streamline_paths_and_visibility_rfc/dn66kfr/). Creating folder-modules is the *same process* as creating crates. Since you have to learn how to create a crate first that should be easier to do than learning a whole new system. You just have to use `mod.rs` instead of `lib.rs` or `main.rs`. However, I think having `crate/` instead of `src/` would significantly help in this for beginners, since the mental model of the full path would be preserved.
Is it possible to make the github authentication on nest.pijul.com less intrusive? Right now it asks for the right to "read and write all user data," which seems like a high ask just for a login.
It's on their website under the [FAQ](https://pijul.org/faq.html). &gt;Please provide a benchmark The algorithmic efficiency is explained on their site. Benchmarks are probably not critical for version control.
You can [check out the faq](https://pijul.org/faq.html) This is a rust form where he has been making updates to pijul. Most of us already know what pijul is and that information would not be useful.
I also found that it took longer to run than normal ls on my system 
Yes, we should provide a benchmark, but we're not yet at the stage of optimising performance to an extreme. That said, if anyone is up for benchmarking it, we can provide all the assistance they need. As to why Pijul is "better", there is a quite detailed explanation https://pijul.org/manual/why_pijul.html Feel free to ask questions here, or on [our discourse](https://discourse.pijul.org) In a nutshell: In Pijul, patches commute. This has a number of consequences, including: - sane cherry-picking, for instance you can cherry pick as many times as you want from a remote branch without the artifical conflicts that Git would create. This is helpful for instance if you want to maintain a "stable" branch of a product that keeps getting patches from an "unstable" branch. - scalable to larger repositories, for instance you can get the patches that apply to just one directory. I believe this is better than Git submodules (which are great to follow a dependency, less so to work on just a part of your monorepo), and better than shallow clones, which only truncate time, not space. - Pijul allows you to be less organised when producing new stuff or debugging. A fairly common work pattern of mine is, I start tracking a bug, and end up refactoring tons of stuff, updating dependencies, and so on. I prefer to forget about my VCS when doing that, simply because I usually have no real idea of what I'm doing. With patch commutation, I can do my debugging, record my patches afterwards, and push them selectively, no matter which order I recorded them in. People used to darcs sometimes call this "spontaneous branches" (Pijul has proper branches too). In Git, doing this would involve complicated invocations of rebase to move the commits in the order that would allow you to push them. Sure, there's the reflog, but how many Git users know how to use it? There are also some drawbacks to patch commutation, for instance it's hard to communicate an exact commit number. Pijul does not implement that yet, but we could have "Git-style repos" where this exists (and it's actually super easy to do). Another cool property of Pijul is associativity, which is explained in the link above. Basically, Git merges are unpredictable, and can sometimes shuffle your files in totally bizarre ways (even to experienced Git users).
Sure, sorry about that, I was not even aware of that fact.
I'm very excited to see where Pijul ends up. So far, it seems to be on track for its promise of darcs' flexibility without all the slowness. I'm looking forward to not using git ever again.
No worries, I figured you didn't set it up like that on purpose.
I made a snake - clone with piston in order to familiarize myself with this game - framework. I also submitted it to r/rust_gamedev (https://www.reddit.com/r/rust_gamedev/comments/70hu9u/please_critique_my_tiny_snake_clone/) for some feedback
You should use raw pointers for ffi because that guarantees that pointers must go through `unsafe`. Think of it as customs control for the ffi.
You can probably make it smaller with `strip`.
I think it makes a lot of sense. It works like Unix paths.
Indeed! :p
Thank you for this kind response, that's the kind of community I like to be involved with. I understand I am still not capable enough to push rust code to production environment responsibly. This is a toy project that I am using to learn rust for the stuff I do everyday which is mostly interface with drivers and system services through DLLs.
Obligatory question: How close is Pijul to "go ahead, actually use it for projects" status? I'm never gonna get around to playing with it until I can use it as VCS for a hobby project without concern of corruption / blocker bugs, so I'm looking forward to that point.
Thanks for the detailed answer!
Excellent question. We hope we're not very far. Bugs are still being found for edge cases, but since Pijul 0.6 we've always been able to recover the entire history: the patch format is stable, and you can recover everything from that. The most important parts, record and apply, have received a fair amount of testing. I'm not as happy with unrecord. Anyway, we have plans to prove the algorithms this month. **EDIT:** what people who use Pijul and the Nest (outside of me) currently complain about is essentially the lack of a UI to display patches (even the CLI cannot do it).
Btw. your FAQ page contains a broken link to a "performance page": https://pijul.org/fast.html Additionally, on mobile the link to the main page isn't as obvious as it is on desktop: on mobile there is the separate menu, and it doesn't include the main page. I was a bit lost a moment ago when I followed the link here, and after that was trying to look up what even is Pijul. There is no "About" page, and the FAQ page doesn't contain a question "What is Pijul?". Of course this was stated on the front page, but it's not in the menu; only the text "Pijul" that doesn't look like a link leads there.
Yes, but it brings developer attention to misleadingly named crates, and it goes away after your final choice is recorded in the Cargo.lock. (and does not change any of the Cargo.lock contents because the information is already the same dependency and version data that's already stored there...)
Thanks for reporting! (I have no mobile device with a browser myself).
&gt;&gt; But the consequence is that, when reading code, visibility annotations tell you less than you might hope, and in general you have to walk up the module tree looking for re-exports to know exactly how public an item is. I have to admit, that part made me sigh a bit, because it feels like getting that point recognized for the `mod` discussion was quite a fight :) In any case, wouldn't this point of contention be mitigated by simply having the crate-instead-of-pub lint off by default? Things marked `crate` can't accidentally leak, and an unexported `pub` won't hurt anyone. Could even be added to `lib.rs` on `cargo new` so beginners are presented with it first. Plus, now that you are forced into using `crate` to satisfy the visibility rules, you lose it as a marker for required privacy. In my current strategy, there's: * `pub` for things that are safe to be called by everyone. * `pub(crate)` for things I want to allow the crate as a whole to do, but wouldn't be a good idea to do from outside. * `pub(self)` (or rather: nothing) for things that I only want to be able to act on locally. So, when things are private, or crate local, there's a reason for that within the code. If I see something `pub` even if it ends up not being exported, I know it's still safe functionality. If I see `pub(crate)` I know I have to be aware of the code being only sane inside the context of the crate. So, with the new lint: * I have lost the information that something is depending on crate-wide-upheld invariants. * It's much easier to become messy with regards to invariants because there's no visual difference between "must be internal" and "isn't visible outside". An example with some internal type: impl Record { pub fn title(&amp;self) -&gt; &amp;str { ... } crate fn internal_cache_id -&gt; usize { ... } } will now have to be impl Record { crate fn title(&amp;self) -&gt; &amp;str { ... } crate fn internal_cache_id -&gt; usize { ... } } and there's no more raised level of awareness for the `internal_cache_id`. I should mention: My code since `pub(crate)` became available is mostly fully private or fully public, with a couple of `pub(crate)` in between. So the loss of information in certain situations is definite for me. But I do like the availability of the lint and a shorter way of saying `pub(crate)`. At this point I simply believe that some issues don't have one-size-fits-all solutions. Edit: Sorry this got a bit longer than I intended.
&gt; I got the impression that Fuchsia is comparable to Android, and Zircon is comparable to Linux. [Zircon is just renamed Magenta](https://fuchsia.googlesource.com/magenta-rs/+/3e9d7e06203ed12303e04dd4fe6194bfa4f5ee3a) Magenta is to Zircon/Fuchsia as GNU/Linux is to Linux
Is there any chance pijul can grow an interactive `pijul record -p` command (or is this best done in a separate tool)? Interactively reviewing hunks/lines to make sure they belong in a patch is a critical part of my git workflows, and seems like it would make even more sense in a VCS where patches are first-class. EDIT: oh, maybe this is the case by default. I tried pijul some time ago but it's been a while, and the docs for record don't mention that it's interactive. Thanks for all your work on Pijul! EDIT: also, a formatting note‚Äîthe usage synopsis for some subcommands like `record` is very wide and causes horizontal scrolling in the online manual. They should probably be linewrapped.
Nice, if this is your website: The links on the footer like "Terms" link don't work. https://nest.pijul.com/site/terms.html
On the other hand, if it doesn't get at least near git in performance, then hosting large repositories with pijul may become out of the question (e.g. a linux kernel repository). From a practical standpoint performance is one reason git displaced some other version control systems. 
Thank you! Do you know if one can use the USB port with a bootloader (e.g. stm32duino) to upload binaries?
With [tarpaulin](https://github.com/xd009642/tarpaulin) I closed some issues last week that should allow people to disable certain tests and skip collecting the hit count statistic to speed up runs for larger projects. I also got to a point with my syntex stuff where I'm implementing the visitor now so that should trim out the false coverable lines as well as letting users apply filtering rules to what gets covered/ignored.
&gt; The RFC process has been working wonderfully. Thanks to many insightful members of the community the discussions have been a real pleasure to read, seeing that no stone has been left unturned. I think that all decisions that have been made recently are going to turn Rust into a significantly more ergonomic and productive language. 2018 will be a great year! As someone who was on the "other side" for the `mod` discussion, I wouldn't say it has "worked wonderfully" exactly. There's certainly issues with the volume of discussion which makes it quite a burden for the authors as well as commenters. That leads to things being overlooked (longer posts work better), people feeling ignored, arguments going in circles forever instead of zeroing in on common understanding. Plus that it makes it hard work to keep up with all the changes and plans for the future. I have actually not really participated in the recent debates anymore not because I don't have an opinion on these parts, but because I'm too mentally exhausted after the `mod` parts. It also made me feel way more cynical, and at the end I feel I wasn't as nice to the authors as I should have been, and I really don't like that. It's also what soured me on the epochs idea, as much as I appreciate the spirit, because I feel like it opens the door to struggles like with `mod` for a long time. I also follow the language design talk close enough that I already know what changes I'll have issue with next, and I'm already struggling with the decision if I should participate or not. I'd certainly feel better about epochs if the RFC system itself would face improvements. It would also help if RFCs are more widely distributed once they reach FCP, like having an FCP-Bot post it here and to the discourse forums.
I'm very happy that `mod.rs` is going away. * Having a quarter of the files in crates called `mod.rs` has always been unpractical and unhelpful. `mod foo;` can now live in `foo.rs` which is perfectly sane and logical. * Sibling modules will now all be living side by side instead of having some children mixed with their `mod.rs` parents, and those same parents' own siblings living one level above or even in a sibling folder. I always felt that was messy. Yes `main.rs` and `lib.rs` will now be exceptions but at least *all the rest* will be consistent. It doesn't sound unreasonable that entry points would be a bit different.
The fact that some things in Rust are implicit and that this is a good thing shouldn't be abused as a blanket license to make all the remained explicit things implicit as well.
Thanks for reporting. The terms basically are "use at your own risk, come back later for a more stable service", which a HTTP 404 also conveys pretty well.
Totally. Rust *is* explicit in many places. The point is that it's not as simple as "explicit &gt; implicit."
Not sure why you got downvoted, it's slower than ls on my system as well. Not that 5 ms vs 3 ms really matters.
No idea, actually. All `cargo check` does is to pass `-Zno-trans`, and I can't find in RLS code where it passes it(or something similar), but it doesn't look like RLS lints are doing full builds(they don't produce executables)
Ripgrep has a lot going for it, but AFAICS no, it does not use rayon.
&gt; Pijul is mostly a formally correct version of Darcs' theory of patches, as well as a new algorithm for merging changes. So you have a formal argument somewhere? Let's see it.
I made case after case for Mercurial where I work. Easy glide from Subversion, good UI tools, yaddah yaddah. But we are stuck with whatever the "industry" coalesces around - you know how these decisions get made. I might switch to this for personal projects, but it's going to be hard to unseat git at work.
It is indeed the case that record is interactive (I don't remember Pijul ever having a non-interactive record). Thanks for your note about the manual. I'll correct that.
Congratulations! Btw: I'm really amazed by how snappy the Nest is!
Propably because exa includes the rust stdlib (statically linked), ls is dynamically linked to libc. If you were to create create a dynamically linked executable with rust you'd get a similiar sized binary.
We do have a formal theory behind all that, with theorems, proofs and algorithmic complexity. It is yet not published though, but should be made available before the end of 2017. Meanwhile, Joe Neeman wrote an amazing explanation of how it works: https://jneem.github.io/merging
I know you're at 1.0 and can't technically change these things now without breaking everything in the universe, but I'd prefer it if your utility functions accepted `&amp;str` or even `T: AsRef&lt;Path&gt;` rather than `String`. Also, I'd like a version of those decoding functions that let me supply a buffer instead of just making their own. Maybe as a `T: Write`? I dunno.
The first hours are the hardest. üòé
I'd suggest a less confusing/misleading title. :)
&gt;I want to use Rust functions from Python to speed up my machine learning code For what it's worth, most of the major python ML libraries end up dropping down to C for CPU-heavy tasks, and the projects that do that are mature and heavily optimized. If you're trying to speed up your model-building from something like `sklearn`, you're probably just gonna spin your wheels.
Absolutely. But it seems odd to me to advertise something as small if it's actually fairly large unless you manually intervene.
&gt; There are also some drawbacks to patch commutation, for instance it's hard to communicate an exact commit number. As somebody who used to use Darcs in production, this made it almost impossible to safely use, and ultimately resulted in us abandoning it for Git (along with the 20+ minute operation time). Not being able to describe a consistent repository state meant that doing some very common operations was hard: * Help a newbie co-worker debug something on a long-running branch * Be 100% confident that the server's view of the release branch was the same as your own That last one was a kicker. I pushed some bad code to production more than once. I'm sure we weren't using it to its full capability, so what were we doing wrong?
Youtube/Netflix etc. are all using expensive content delivery networks, you're probably just fetching Rust from wherever it's natively hosted.
&gt; There are also some drawbacks to patch commutation, for instance it's hard to communicate an exact commit number. As somebody who used to use Darcs in production, this made it almost impossible to safely use, and ultimately resulted in us abandoning it for Git (along with the 20+ minute operation time). Not being able to describe a consistent repository state meant that doing some very common operations was hard: * Help a newbie co-worker debug something on a long-running branch * Be 100% confident that the server's view of the release branch was the same as your own That last one was a kicker. I pushed some bad code to production more than once. I'm sure we weren't using it to its full capability, so what were we doing wrong?
So, darcs has tags, which could have prevented part of these problems. As I said, Pijul could have a "git-like mode" where each new patches depends on all previous patches, without any overhead. (In case you wonder, Pijul is not a reimplementation of darcs, its theoretical foundations are completely different). But I'd be super interested in understanding what your workflow was. Could you tell me more about it? How many were you? Who was responsible for deploying into production? What was your review process?
Thanks (:
When I'm opening the `Learn more` links on my iPad, it opens in the Dropbox app and says "Forbidden." On a laptop it works fine (shows in browser.)
Well, the main difference between Git and Mercurial is UI. Mercurial is more user-friendly, but the main idea is quite similar: branch + 3-way merge. The hope is that at least the next generation of programmers, and even those in college now, can finally work with a simple and sane tool for that job.
I feel somewhat uneasy that patch identifiers contain dashes and underscores. You can see it e.g. [here](https://nest.pijul.com/pijul_org/pijul:master/patches). This makes it impossible to select them by double-click and looks aesthetically unpleasant.
In case anyone's reading the comments without reading the article (unbelievable, I know), steganography is super nifty and you need to know about it: https://en.wikipedia.org/wiki/Steganography One cool example of its use: in the video game Spore, save files for the creature creator are just plain images of the creatures themselves; no metadata header shenanigans, no fancy custom hybrid formats, literally just an image of your creature with the save data invisibly encoded in the pixels.
**Steganography** Steganography ( STEG-…ô-NOG-r…ô-fee) is the practice of concealing a file, message, image, or video within another file, message, image, or video. The word steganography combines the Greek words steganos (œÉœÑŒµŒ≥Œ±ŒΩœåœÇ), meaning "covered, concealed, or protected," and graphein (Œ≥œÅŒ¨œÜŒµŒπŒΩ) meaning "writing". The first recorded use of the term was in 1499 by Johannes Trithemius in his Steganographia, a treatise on cryptography and steganography, disguised as a book on magic. Generally, the hidden messages appear to be (or be part of) something else: images, articles, shopping lists, or some other cover text. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Why? It is literally a rallying call to *implement* a *future Rust*.
I'm porting the Raspberry Pi side of a robot I'm working on from python to rust! Already it's so much more robust - the python would crash in difficult situations, but the rust will almost never `panic!`. I look forward to writing more rust! 
At first glance, I thought it had something to do with plugging in your own `Future` into `tokio`, so async/io was the first thing that came to mind. I clicked on it and was really confused that it was talking about the Rust roadmap.
Respectfully: there are lots of those on the internet already. Complaints about there being *additional* media by which people can learn about Rust seem rather unhelpful to me. :)
I agree with you. I've been using error-chain for over a year now and have it as a dependency of almost every one of my projects, and I'm really starting to want to move away from it. It's become clear to me that while error-chain was an interesting experiment and has been a helpful tool for quite a while, it is not the end-game for error handling in Rust. I've been thinking off-and-on about some concepts that I would like to explore and I'm interested to see what the next error-handling breakthrough will be.
Alright, what do you propose instead? We could certainly make them shorter in a backwards-compatible way, but base64 is kind of standard for that sort of things.
&gt; WG-dev-tools-vscode Improve Rust's IDE experience for VSCode. Can someone clarify why does Rust team wants to implement its own extension when there is already an existing community extension? Last time I checked community extension was much better than the one from the Rust team. However, community extension is completely ignored in any official Rust channels (like in this blog) like if it doesn't exist at all.
How would Pijul handle something like package manager dependencies? [dependencies.foo] git = "..." rev = "a123456" It sounds like it would need a git-like mode for that?
I can add those functions for 1.1! I see the Util module as more flexible than the Encode/Decode ones. It's primarily for making the crate easy to use so adding `&amp;str` should be no problem. I could add `T: Write` for 2.0 and live with the breaking changes maybe?
Wow, I didn't know that Spore did that, that's incredible awesome! I guess you could send that picture to a friend and then they could play with it?
Not necessarily, we have lightweight tags (not yet in the CLI, though) which could be used for that. There are ongoing discussions about tagging features and patchsets to make this easier than `rev = "a123456"`, feel free to join on https://discourse.pijul.org if you're interested.
It's a pun.
Perhaps you're having packet drops then? Videos and websites can load out of order, but I'm guessing that `rustup` does in-order packets, so packet loss could definitely explain the issue you're seeing.
I've pinged nick, maybe he can say more, but he wrote this a while ago: https://www.reddit.com/r/rust/comments/6tsafl/these_weeks_in_devtools_issue_1/dlow994/
When I was once with AT&amp;T for my ISP, I found odd throttling on certain extended download streams like linux isos, or apt update downloads. It seems like they would burst the first xx MB at expected speeds, but then downthrottle longer connections. But then apt didn't necessarily use the same connection the whole time, so some other rules were in play that ended up with the same effect. Videos/websites for the most part were unaffected by the throttling. I was fortunately able to get rid of AT&amp;T over time.
 When get_message function is exited memory belonging to `mt_one` and `mt_two` is deallocated. This code won't work, even in C. I assume you need that for C compatibility considering this pretty much looks like C code converted to Rust. In such an event, call a function before a value is deallocated on stack. Alternatively, you may want to do heap allocation with `libc::malloc`, but then the value needs to be freed with `libc::free`.
Reason for asking is my crate [byte-slice-cast](https://crates.io/crates/byte-slice-cast) btw, which goes via raw pointers instead of transmuting the slice. Transmuting the slice is *probably* safe (why would the compiler represent &amp;[u8] and &amp;[i8] differently?), but unneeded here as you can go via the raw pointers which generally is more safe than transmuting.
Yep, and Spore also provided a website where people could share creatures just by uploading and downloading images: http://www.spore.com/sporepedia/ Here's an article with some reverse-engineered details of their approach: http://www.rouli.net/2008/08/spores-png-format-illustrated.html
I have never seen base64 being used for similar purposes, i.e. where there is a need to make a human readable identifier from a hash. Some examples off the top of my head: * git commits - base16 * bitcoin addresses - base58 (old format), base32 (new format) * onion addresses - base32 * bittorrent info hash - base16 or base32 I think everyone is trying to restrict resulting strings to alphanumeric characters. I don't know how often one will need to deal with patch hashes in Pijul and thus whether it is actually important how they look like.
Why the switch to Gitter when everything else is on IRC? To make it more accessible?
Youtube/Netflix etc. are all using expensive content delivery networks, you're probably just fetching Rust from wherever it's natively hosted. Which probably isn't in a CDN, not even you're service provider's.
Thanks for the response. So if this isn't the correct pattern, is there a better one I should be using? 
Probably, but it'd be hard to create comparable benchmarks because the concepts themselves can be so different. The idea behind patches as a first class citizen vs snapshots is that patches naturally limit themselves to the scope of the files they change. If you have two patches that change different files you don't need to care about how they'd conflict. Huge repositories, such as LKR, would then not be a huge problem, huge files OTOH, could. There are other things that make it hard to do benchmarks. This means that the variable that matters for performance on either git or pijul would be a completely different thing. Benchmarks would only hide the difference in the focus and use-cases of this algorithm. It may be the case the Pijul isn't better than Git for the Linux Kernel Repository, for reasons completely unrelated to its size, but simply because Git was made exactly for the needs of the LKR, while Pijul was not. With that said. I do think that one of the requirements for v 1.0 is benchmarks showing how pijul scales in different scenarios and considerations (independent of how it works compared to other systems right now).
Yes, we're trying it out. There's been a lot of talk over the years about IRC vs other platforms. Something like the impl period is a great way to give something a try without committing to it.
What do you mean "all the rest will be consistent"? There will now be two completely separated schemes for declaring a "code unit", `main.rs/lib.rs` and `foo.rs+foo/`. Before it was a single way, `main.rs/lib.rs/mod.rs`. It is *already consistent*. The changes only make it inconsistent. Thinking of the "files as being named `mod.rs`" is misleading. The files are "named" `foo/mod.rs`. The *directory* is important. As I point out in the [RFC I opened](https://github.com/rust-lang/rfcs/pull/2155), the new syntax will change the definition of `self::` in `foo.rs` based on whether the folder `foo/` exists. This is pretty confusing behavior.
Of all communication 'platforms' I've used the Gitter UX has been the worst, by far. Not that that should really count for much, but before switching from something that works, hopefully more feedback can be taken from the community. I could be alone in that opinion.
If you only have two message types it sounds like you really just want an `enum`...
Awesome, thanks for the link! I may have to consider doing this for a project I'm working on.
Note, an IRC bridge is available.
Ok, thanks for the suggestions. They were base16 in the beginning, but they were too long. Maybe using a shorter hash + base32 would work. I also don't know how often we'll have to deal with them. The only cases we use them when working on Pijul is to reproduce bugs.
in reality I have many, many, many more message types. This is simplified down to explain the problem. Also, to the best of my knowledge, enums aren't FFI safe
If I were you, I'd just add the write thing as another method with a slightly different name or something like that. Maybe someone else has some better ideas, though.
Cool, good to know.
I tried doing a steganography library for my final year college project last year because I wanted to be the first, oh well :-/. I tried doing mine using the 2-d Discrete Cosine Transform though and it gave me nothing but heartaches and headaches so I wish you all the best if you ever try converting your library to the DCT.
I think IRC is just fine, but Gitter is a great community chat for coding related projects. It's just there in your browser, you can search the history and not miss out on messages without a complicated daemon on your own server, you get syntax highlighting...
Clearly a `build.rs` would need to exist for it to be executed, yes. It means that the same typosquatting attack would get you the ability to execute arbitrary code anytime builds the package, whether that is because someone builds a package that pulls in the typoed package name, or because they happened to `cargo-install` it. And since people generally build things as their user, it could potentially do anything the user themselves could do, including e.g. try running things under sudo, and many people would either have run sudo recently or have `NOPASSWD` sudo enabled. It could also try to for example start a background process with a reverse ssh tunnel to whoever uploaded the typosquatted package.
It might be a good idea to replace one of the pinned posts with this one temporarily, so it looks more official.
I meant my own implementations and feature extraction etc. in general. Basically, for anything that takes long in Python.
https://static.rust-lang.org/ is an S3 bucket; I forget if CloudFlare or something is in front.
&gt; All cargo check does is to pass -Zno-trans This is not true anymore.
tripple-click works.
&gt;From a practical standpoint performance is one reason git displaced some other version control systems. Indeed, but `darcs` for instance was the only thing comparable to `pijul` in the past, and was unusably slow for large projects because merges were `O(2^n)`. Pijul gets a bit more wiggle room than `git` in terms of constant-time performance (at least in the short term), since it has some nicer features. I've never been in a `git` repo where I noticed merges taking too long (though I am sure some exist).
I'm playing around with Rocket right now (nothing in production yet) and I think that the way of thinking about writing web apps in Rust is somewhat backwards right now. I think we focus far too much on Rust dominating the entire piece: the web server and the app server. I think we should only be focusing on Rust at the app server level. Rather than having Rust code serve all of our static assets, instead we should architect our apps to have something like Nginx be a reverse-proxy into the application itself. This allows Rust to do what it does best without requiring too much extra work and it allows Nginx and other web servers the ability to do what they do best. My plan is to develop an SPA-style app with Rocket and host it in a similar way. I'll have several Rocket workers running while I have a single Nginx server stood up as a reverse-proxy. At least that's my thinking thus far.
&gt;It may be the case the Pijul isn't better than Git for the Linux Kernel Repository, for reasons completely unrelated to its size Eh, even if `pijul` isn't suited to e.g. the windows codebase, it can still be a great tool for the rest of us. I use `darcs` on some of [my own](https://hub.darcs.net/vmchale/wordchoice) projects. It works great.
Care to elaborate?
&gt;I might switch to this for personal projects, but it's going to be hard to unseat git at work. I use `darcs` for my personal projects for the time being. I've used `pijul` just to learn it, but... I don't 100% trust it for production repos yet. It's corrupted repos before. Every release makes me more confident, though :)
https://blog.rust-lang.org/2017/03/16/Rust-1.16.html has a huge section on it. The main bit is this bit at the end, though: &gt; To support cargo check, rustc has learned to emit a new kind of file: .rmeta. This file will contain only the metadata about a particular crate. cargo check needs this for your dependencies, to let the compiler check types and such from them. It‚Äôs also useful for the Rust Language Server, and possibly more tools in the future.
Hi, I thought about starting to contribute, I even found an issue that looks pretty interesting, but I'm not sure how to start. Should I just put a comment in the issue tracker saying "hi, I'm new and I would like to do this" or what?
Thanks! Is this your library? https://github.com/hgallagher1993/rsteglib If it is I was going to message you about working together! Never hurts to have a more fleshed out library :)
I know, that's what made the decision even more frustrating. I can't tell you how many hours we've wasted trying to teach people git UI, or dealing with mistakes from bad or confusing UI. 3+way merges are hard enough without having a bad UI on top. I'll definitely be watching your development. Thanks for responding.
Yes! Basically, if you don't need any help, then just getting going is awesome! If you do need some help, posting about it in the related channel or on the issue is a good way to get help.
I know, I just think titles should be informative.
I'm using Iron and Tera on stable Rust. Tera is just great, Iron needs some boilerplate of functions to be more convenient to use. Things I use: - HTML templates, - serving static files, - hot reloading of templates (for development), - JSON output, - GET and POST parameters. Not the best web-framework yet, but gets the job done and doesn't stay in my way.
Thanks for answer! Yes, so that was my thinking so far as well. I don't care much about async io etc. in Rocket, as I can load-balance it with something else. I was more worried about other issues, like lack of libraries for common things (eg. oauth), unkown problems etc.
Could be called .consume() or .force() or something
&gt; error[E0277]: the trait bound `Foo: std::convert::From&lt;&amp;[u8; 12]&gt;` is not satisfied The issue is, `b""` does *not* create a slice, it creates a reference to an array; the coercion kicks in with `from_u8`, but not for `From`.
I'll do that tomorrow, given that we just cycled the normal weekly posts and I like to give them at least a day or so before unpinning them (and this post will be on the front page till then anyway).
A workaround is to make a blanket implementation based on AsRef::as_ref: impl&lt;'a, T: AsRef&lt;[u8]&gt;&gt; From&lt;T&gt; for Foo { fn from(v: T) -&gt; Foo { Foo { value: v.as_ref().to_vec() } } } This basically folds the as_ref() you would be doing anyway into the From implementation. Edit: Note that this only works for a limited number of array sizes currently.
You beat me to it; I was *just* cooking this up in the playpen :)
Thanks, that's a useful workaround though it strikes me as the kind of thing the compiler should do automatically. Just grit that has no reason to be there. Wonder if there is an RFC for it
I agree completely. My whole argument is that benchmarks and specific examples only work when both systems work in very similar fashions. When there's fundamental differences between the two cases it becomes hard to compare benchmarks without focusing on specific use-cases, which, as you pointed out, may have nothing to do with your own. It's more honest to show the differences.
It's a pity that it doesn't kick in for the From case. That would be intuitive. I find myself writing as_ref() way too much just to persuade the compiler to do what it could probably figure for itself.
Just a quick note: if you want to get involved in any of this work, please sign into the chat for the relevant work groups and say hello!
Yeah, having chat history saved as part of the service is a huge + for me
[removed]
It's a tricky one because the different sized arrays are distinct types, which are in turn distinct from slices. Just sticking in a simple coercion rule would break backwards compatibility.
For a side project (https://github.com/flosse/openfairdb) I use rocket in combination with Ngnix. It's a simple API for a JavaScript frontend (https://github.com/flosse/kartevonmorgen). Rocket is still a young project and depending on your use case you'll need to implement a lot of functionalities yourself. BUT: Every feature rocket offers is in IMHO absolutely ready for production. So my guess is, that rocket will mature faster than a side project can be developed ;-) If you're not really forced to use stable rust, I'd recommend to go with rocket :) 
I suppose they're used like git hashes, when applying identifying a commit/patch for operations like reset/revert/cherry-pick (not all such commits are marked by a tag or are head of a branch)?
Its also a huge minus, as it means that mods can delete or edit messages. I don't think either is really good. Every time I see a cascade of [deleted] I've got not idea what was going on.
/u/nikomatsakis wrote a great post on precisely this issue: https://github.com/rust-lang/rfcs/pull/2126#issuecomment-326328217 There is certainly a tradeoff between the two distinctions. But it's not one we can get around without adding an entirely new visibility level and *truly* changing the meaning of `pub`, which is backwards-incompatible. (This alternative *has* been extensively discussed- generally under the name `export` or `pub(export)`, also `pub(api)`.)
In a sense I kind of like the ugliness of a leading `::`, since it points out that it's not something that's being `use`d higher up in the file (or defined within it). If it's a one-off use, it lets it stand out; if it's common, it encourages adding an import.
Edit: Sorry, I misread part of that post. Took out my disagreement based on understanding. I guess I just value the local information over the global one. Either way, I'm not proposing a new visibility mode. Just saying that the "unreachable `pub`" lint could be optional.
For the curious (/u/razrfalcon?), the original [ergonomics initiative](https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html) blogpost lays out some more detail about *when* explicitness or implicitness are helpful.
But in current Rust, it *doesn't* have to be both in order to be `pub`- it only has to be the second one. The point of the lint (which *is* optional, that's what lints are) is to distinguish between the two, at the cost of conflating the two use cases for `pub(crate)` (doesn't happen to be in the API vs can't be in the API).
You can open a local copy of the rust book (second edition is the way to go) and stdlib api documentation through rustup using `rustup doc --book` and `rustup doc`.
Yeah, I misread `pub` as in `pub` for the thing, sorry about that.
`&amp;[u8;12]` is not the same as a `&amp;[u8]` `&amp;[T;N]` is actually just a `*const T` who's length is guaranteed by the type system. `&amp;[T]` is actually a tuple in the form of `(* const T, usize)` which carries its length at runtime. --- The notation is similar but the implementation is worse apart. Overall I agree that `&amp;[T;N]` _should_ alias to `&amp;[T]` auto-magically by the compiler. 
Ah, no. 
It actually doesn't suck, either. You can paste straight markdown in and get it out correctly on the web browser side and pretty much everything "just works" You might have to customize your IRC client to be a bit creative with filtering and rendering if you want all of the fancy gittr features to not spam the client with weirdness (like extraneous ASCII, a lack of color highlighting, or a bunch of urls to emojis)
&gt; In this reply, let me call your mechanism "co-own" for the sake of not confusing it with the "borrowed alias" I mention in my paper. They are different mechanisms, as I will come back to. I saw it as a generalization of the "borrowed-alias" mechanism you were planning to implement. Hence the use of the word borrow ("I'm taking a reference to this value and will cease referencing it before you cease to own it") rather than the words "co-own". There's only one true owner/allocator and it doesn't actually change. So to give a concrete example: - `Obj` with allocator `GC` can be referenced by `&amp;Obj` with allocator `RC`. Mechanically this is done by keeping `Obj` alive for as long as the borrow `&amp;Obj` exists. - In turn `&amp;Obj` with allocator `RC` can be referenced by `&amp;&amp;Obj` with allocator `lexical` simply because lexical know how long the original `&amp;Obj` will be valid and unmoved, and can thus ensure the reference `&amp;&amp;Obj` doesn't outlive it. Hence objects owned by GC and RC can be borrowed by anyone (because both GC and RC allow extending the owned object's duration), and lexical can borrow from anyone (because it can enforce that it will be done before the owned object is dropped). As an aside: it seems that any allocator that supports multiple owners (`GC`/`RC`) cannot support `Move` to transfer to a new allocator that has a single owner, without losing memory safety: - Obj,GC is owned by 2 different GC owners. - One of them is moved to lexical. - lexical de-allocates the moved data. - The other reference is accessed.
I've recently been teaching Git to a lot of inexperienced students, so I definitely see the need for a VCS built on better conceptual foundations. I've been trying to understand how Pijul (and Darcs) differ from Git (and Mercurial et al) exactly. The best explanation I've come up for myself is something like this: Git records snapshots of the history. Each commit represents the state of the repository at a particular time. To merge things, we have to find a common ancestor and reconstruct the changes made in each branch by diffing, then resolving conflicts; to record only a subset of changes made, we have some weird operation where the "snapshot" is partly current and partly old. And so the system of branching, committing, and merging has all sorts of weird conceptual corner cases which confuse students. You're mostly interested in *changes* between versions, but Git only records static *snapshots* of single versions, and the changes must be reconstructed from these. As I understand it, Pijul (and Darcs) reverse this, and the VCS cares only about changes. Snapshots are reconstructed from changes. Merging is conceptually simpler because we only care if two sets of changes can be combined. Is this an accurate depiction of the difference, or have I missed part of the concept? If it's vaguely correct, it may be a better way of explaining the differences than saying "patches commute" or talking about the theory of patches. Or maybe I've missed the point, I'm not sure.
The Read trait doesn't start back at the beginning of the source on each read call, instead it requires some mutable internal state to store what has already been read. I just read through the docs and this isn't really said anywhere All the utility methods like read_to_string are built on top of read and mutate self to ensure the same bytes aren't read twice.
Reading also advances the stream. For example, a second call to `read_to_end` for a file will read 0 bytes as the steam is now at the end of the file.
I'm working toward the 0.2 release of [Rudy](https://github.com/adevore/rudy/), an associative array implementation based on [Judy arrays](http://judy.sourceforge.net/). The largest feature additions are iteration, support for signed integers, and a set implementation (equivalent to Judy1).
I hadn't seen this before, looks like a great resource! Is there a PDF available for offline reading? I know part of the idea here is to be able to run/modify the examples, but having an offline version would make it easy to read on a tablet or similar while travelling.
Not exactly, but you could click "print" in the upper-right corner and print to PDF.
The only thing I can think to add to this is to download all the crates you want to play with before the flight. Cloning the repos would be ideal, but I suppose adding them as a dependency would work too.
Had a quick look at the code in your nest. Whoever was responsible for the website did a good job. Loads refreshingly fast, is not bloated, has a familiar and good UI. Good to see that not just your core tool has good effort put into it. ;)
good bot
Thank you mgattozzi for voting on WikiTextBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
I mean. These days 1.6MB is pretty small. It's smaller I bet if you turn on LTO and strip all the symbols.
&gt; Pijul could have a "git-like mode" where each new patches depends on all previous patches, without any overhead. I don't think this is exactly what we want. The patches not depending on each other, except when necessary, is what makes Pijul powerful. What you want is actually to have branches and tags which refer to sets of patches currently applied. You could do that easily enough by just storing a hash of the identifiers of all of the patches applied, sorted in some canonical order. You would also want a branch to contain a log of what patch sets it has contained. That log would wind up being something like git's reflog, or a log of which features were merged when (if a feature were implemented in a set of patches instead of one). Of course, a tag is generally supposed to be immutable, so it might not have a log, or might but it would just ever have one entry. I think that would help a lot with being able to keep track of what is changing at a higher level than just the full set of patches. I see that there is a notion of branches in pijul now, but not an explanation of what they consist of. Is there any documentation on what the model for branches is?
Adding them as a dependency is nice cause you can just run "cargo doc" to get locally stored documentation if I recall correctly. 
In the grand scheme of things, yes 1.6MB is small. But when your main competitor is 38KB, 1.6MB is not a bragging point. In a vacuum, I wouldn't care about that little memory.
I'd mainly become concerned that developers would ignore it because it would mostly be a false alarm. 
*I'd mainly become concerned that* *developers would ignore it because it would* *mostly be a false alarm.* ______________________________________________________________________________ ^^^-english_haiku_bot
Every time I see no logs, I've got no idea what was going on. It seems like having *some* logs is both a strict and large improvement over having none at all.
I'd recommend cloning locally and then using as a dependency via `path = ...` in `Cargo.toml`, that way it's easy to look at source or whatever in your editor.
&gt; The notation is similar but the implementation is worse apart. Overall I agree that &amp;[T;N] should alias to &amp;[T] auto-magically by the compiler. I think you mean their implementations are worlds apart. And `&amp;[T;N]` should [coerce](https://doc.rust-lang.org/nomicon/coercions.html) to `&amp;[T]` (probably as an additional case to what the nomicon calls "pointer weakening").
You need to allocate the messages on the heap. let mt_one = message_type_one { somevalue: 1, anotherval: 2, }; //cast into c_void let raw_mt_one_ptr = Box::into_raw(Box::new(mt_one)) as *const c_void; let hold = holder { message_type: 1, message: raw_mt_one_ptr, }; If you want to be able to deallocate the messages without having to pass them back to rust, you'll need to use a shared deallocation function that properly re-boxes the pointers, or allocate the memory with standard libc::malloc so the other side can use free() on the message.
I'll give something like this a try tonight. Thank you
Yes, that does work. But it also works if you have a local clone of the repository.
dont forget to clone both of: https://github.com/rust-lang/rust-by-example/ and https://github.com/rust-lang-nursery/rust-cookbook and install mdbook to read it locally as a book
That's a fair enough argument to me.
I'm not an expert on rust or cargo, but it sounds like because there could be a vulnerability at the point of execution of build.rs of an external package - this would be seem to be the earliest prevention point to getting owned by a crate that is intentionally typosquatting. Maybe one could reduce false alarms via some network of review/approval so that correctly spelled, favored choices wouldn't trigger an alarm? Long term it would be nice if crate names basically ended up separating more than one-two typo away from one another - but I have no guess as to how close the crate repo is to that right now, nor if it's reasonable to get that kind of separation in the future without painfully constraining crate naming.
Unless you have an irc bouncer, in which case you have all the history, unaltered.
&gt; scalable to larger repositories, for instance you can get the patches that apply to just one directory. I believe this is better than Git submodules (which are great to follow a dependency, less so to work on just a part of your monorepo), and better than shallow clones, which only truncate time, not space. Can "patches that apply to just one directory" (or some other pijul feature) ALSO truncate in time, like shallow clones? The prime use case for shallow clones is to build some software (as opposed to developing it). It's typical that you don't know what directories you will need (you might need everything), so truncating in time is all that can be done.
Thank you for the clarification on your idea. To your last point first, I agree that multiple allocators owning the same object cannot safely be moved to a lexical owner. Worse than that, lexical (and stack) allocators cannot share ownership to start with. Wrt borrowed aliases, let me be sure we are on the same page first on what the paper proposes. You said: &gt; "I'm taking a reference to this value and will cease referencing it before you cease to own it". There is only one true owner/allocator and it doesn't change. Your summary is mostly true to the paper, but I want to be sure you are clear that the paper has borrowing aliases borrow from a specific owner alias, not from an allocator. Thus, the static lifetime of a borrowed alias cannot outlive that specific owner alias it borrowed from, as verified by the compiler's borrow checker. The compiler has no knowledge of the runtime lifetime of the object itself (which may well outlast that specific owner alias we borrowed from). Furthermore, it can borrow from an owner alias typed to any allocator, but the borrowed alias loses the owner's allocator info. Thus the owner alias may be rc, tgc, lex, whatever, but the allocator type of the borrowed alias is "borrowed" (without any memory of the allocator used by the alias it borrowed from). So, this mechanism is almost the same as your second example, with one exception: the borrowed alias has as its allocator `borrowed` rather than `lexical`. The nature of lexical memory management is there is only one owner alias at a time to a specific object. All borrowed aliases from that (or any) owner alias are a different allocator type: `borrowed` or `&amp;`. Your first example is a different kind of borrowing mechanism, since you indicate you want `&amp;Obj` to have allocator type Rc and be managed by that allocator, even though it is already being managed by another allocator Gc. When you start using runtime allocators, either Rc or Gc, the compiler no longer does lifetime dependency checks, because it can't do that: it has no access to the runtime bookkeeping info. So, the compiler allows a runtime-managed alias to be aliased into a longer-lasting alias. So, as I said earlier, I do think your non-static-borrowing mechanism could be implemented. Perhaps &amp;Obj would not have to be a sum allocator type, but what I said before still stands, I think. The runtime GCs would have to not only agree on a unified metadata, but also both runtime GCs would have to be sensitive to both types of metadata, so that an object is not freed until BOTH the ref count is 0 AND it cannot be traced from the root. What would be the benefit of having an object be managed by two runtime allocators, given the added interdependency of metadata and slower performance?
I'm no gitter user but I think mods can remove/edit messages *while you have the window open*. So it doesn't just apply to history, it also applies to ongoing discussions. I don't say moderation is bad. Trolls exist and so do people who sometimes cross limits. You can ban them/slience them or whatever. But I think "unsay" is a feature that is harmful, regardless of whom its applied to.
This isn't really beginner material, but there is also this book: https://doc.rust-lang.org/nomicon/
Rustlings are great: https://github.com/carols10cents/rustlings And as many exercism.io problems as you can for other example problems.
Lets desugar fully to understand why. let foo2 = Foo::from(b"I don't work"); Is in reality something more like let foo2: _ = &lt;Foo as From&lt;_&gt;&gt;::from(b"I don't work"); Where the `_` are inferred types. Now the type of `b"I don't work"` is `&amp;[u8; 12]` *which is not* `&amp;[u8]`. The error here is that it's not finding the right trait. This isn't a problem when you call `from_u8` because it is able to easily find the method it needs to call (since the impl is not generic) and then it can easily coerce the type internally. You can easily verify this by forcing the type correctly, something like let foo2 = &lt;Foo as From&lt;&amp;[u8]&gt;&gt;::from(b"I do work"); So how do we do this? One is to make the trait over `impl&lt;'a, T: AsRef&lt;[u8]&gt;&gt; From&lt;T&gt; for Foo`. This is the best solution as it is the most Rusty. It's not a workaround as other posters said, it's actually honest: it states that anything that can be converted can be done. `AsRef` is supposed to be cheap so it won't be that bad efficiency-wise.
I found that even from mobile if I open it in a new tab it's fine. Just the app that's messed up for some reason. 
Git is terrible all others are worse. I don't like mercurial because until recently cheap short lived local dev branches weren't available. Everything you did was remembered and out there. Git is also fast. Polynomial time for pijul does not sound promising ... The number of times I've been bit by weird merges in git I could count on a hand. And I've been able to fix them.
22 hours is a long time. After you've finished the 2nd edition of the book, you can step through `alacritty`, a terminal emulator written in rust. You can start with the main function here: https://github.com/jwilm/alacritty/blob/master/src/main.rs#L39 ...and see how it defines and loads yaml configuration and does multi-threading. It has been instructive to me. Also it's a nice terminal to use. Make sure you clone and build the project before your flight. It needs to download a lot of dependencies.
As a project maintainer, I would be more or less ok with this if there were some authoritative repo I was aiming at. A computer-readable-only representation of a list of diff hashes to specify an unambiguous version might be acceptable if I can refer to it easily with a tag or such... And they were easily composable.
You really want to break new ground, make it handle large binary files well. Most game dev shops and other organizations that need to handle large files still use perforce or svn because they're the best at that... Which is just tragic.
Just bought my hardware. I cannot wait to work through this book. Thank you for putting it together!
thanks for the explanation, do you know why they would do that, since it is kind of confusing that the second time you call the file it would start on a different place.
At the beginning when I wrote the neovim plugin, I couldn't find a reliable language server to support codeAction, so the functions is just there as a stub. Now, it seems a good time to revisit the function, to make it actually work.
&gt; Git is terrible all others are worse. Agreed. I use git because it's the least bad revision control system. &gt; I don't like mercurial because until recently cheap short lived local dev branches weren't available. Yeah, never liked Mercurial's branching model of "each repo is a branch", and even once they added branches within repos it wasn't quite a first class citizen. History rewriting of local history was something that I wanted before Git or Mercurial even existed; I implemented a basic version of it in Monotone, a predecessor of both Git and Mercurial. &gt; Git is also fast. Polynomial time for pijul does not sound promising ... O(1) and O(n) are both polynomial. Pijul is advertising polynomial time in comparison to Darcs, which operated similarly on patches but could sometimes hit exponential time operations. Compared to exponential time, polynomial is a huge improvement. I don't know what the actual running time for various operations are in Pijul, but "polynomial time" does not mean bad, it means "not completely unusable." &gt; The number of times I've been bit by weird merges in git I could count on a hand. And I've been able to fix them. If I had a penny for every time I've had a debate about whether we should be rebasing or merging feature branches (and if rebasing, if we should be rebasing with `--no-ff` or not), and likewise if we should be applying fixes to the oldest supported branch and merging forward or if we should be applying to the master branch and cherry-picking back, I'd have a heck of a lot of pennies. Properly handling merging of sets of patches, including their conflict resolution, means that there's no difference between merging, rebasing, and cherry-picking, eliminating that whole set of questions. It does raise some others, like how to properly track the state of a repository at a time, but I think that could be relatively easily solved with a sort of a reflog like I've proposed.
I use sapper in production, compiled by stable rust. That's very well.
This made my day :D
Treat the `Read` trait more as a stream of data than as a fixed block of data, then it makes more sense. In other words, does thinking of `Read` as standard input rather than an on-disk file help?
&gt; src/foo.rs + src/foo/ instead of src/foo/mod.rs wait, what? The RFC proposed `src/foo.rs + src/foo/` as an alternative to `src/foo/mod.rs + src/foo/*`, no? The original RFCs were more aggressive about deprecating the latter, but this one doesn't seem to suggest that.
&gt; However, I find it highly unlikely they won't eventually create some lint to enforce the new way of doing things. So you're complaining about a hypothetical proposal that only exists in your mind. This lint you talk of has never been mentioned (except perhaps in previous, rejected RFCs), and doesn't seem to be planned. Rust is pretty conservative when it comes to lints. The RFC explicitly proposes a deprecation lint for one thing, it's not likely that other lints will "sneak in" without getting RFCd similarly. Sure, in the future the community may decide that they want it to be linted and write an RFC for that, but that's a future thing, and you can express your objection there. As it stands this is an invalid complaint.
Please be nice.
Has science gone too far?
&gt; the too-many-linked-lists tutorial. This isn't really a beginner tutorial. Unsafe code in Rust is not a beginner topic. Probably should just download the book and read through it. rust-by-example is nice too.
I never find mercury friendly. I even haven't found a good tutorial to read. But git has a very good one with good translation. Git invokes a pager when needed. Git has colors. Mercury only has short aliases that everybody wants.
Isn't that to select a whole paragraph?
Thanks! Btw, do you know by any chance where one can find libwebkit dll binaries for Windows? :)
I created a crate that includes the top 100 most frequently recently downloaded crates from crates.io as dependencies (plus a couple others that I was interested in), then ran cargo doc on it. Now, between that and `rustup doc` and `rustup doc --book` I have all kinds of official docs on my hard drive. 
Yes, they are used by `pijul unrecord` at the very least.
[my opinion has changed](https://www.reddit.com/r/rust/comments/70pl49/clarify_and_streamline_paths_and_visibility_rfc/dn66kfr/)
`src/foo/mod.rs` implies `src/foo/mod.rs + src/foo/*`. Anyway, [my opinion has changed](https://www.reddit.com/r/rust/comments/70pl49/clarify_and_streamline_paths_and_visibility_rfc/dn66kfr/)
You can flash a 2nd stage bootloader (yes, stm32duino) to make it possible to flash it via USB directly, but doing so still requires you to go through serial or SWD at least once. If there‚Äôs any choice to be made here, I would just go straight for a ST-Link knockoff ‚Äì it will be both more hassle-free and will have more features.
My website is actually fully implemented in Rust. Supports HTTPS, Brotli/Gzip compression, RSS, serves as a blog, and has a web CMS. It's very doable. https://mmstick.tk/
Hi, the main reason for two extensions is that they have quite different goals and architectural approaches and it has proven difficult to unify them. The rusty-code fork aims to make a full-featured extension, backed by multiple sources of information. The reference extension aims to be a 'pure RLS' extension and uses only the RLS and VSCode features (it does not depend *directly* on Racer for example, but note that the RLS does use Racer for some features). This approach means that for some projects you don't get any support right now where the other extension can provide partial support. However, if your project does work well with the RLS, then this extension should give a better experience. Timing-wise, the reference extension has existed somewhat longer than the rusty-code fork. One of our reasons for picking VSCode as a reference platform was that at the time there was no maintained community extension. &gt; extension was much better than the one from the Rust team Do you have specific issues? Please let me know, or if you prefer file an issue on GitHub. We've been working pretty hard on the extension recently and you should get a better experience, if you haven't tried it recently. 
Yes, one's in the mail. I flashed stm32duino using a spare Uno as a programmer, and was hoping to use the USB for convenience, but it's clearly no more convenient. I'll definitely go back to direct programming when the st-link arrives.
Right, my point was that the RFC doesn't propose deprecating mod.rs, just provides an alternative. But yeah, I see. Thanks.
Looks like it turned out pretty similar to [mine](https://github.com/durka/macrolisp)!
Thanks for the comments! This sounds really interesting. So, conceptually, branches in Pijul are essentially lists of patches (plus some stuff to make it efficient), in the order in which they were applied. Two branches with the same set of patches (even with different lists) are equivalent, in the sense that the same interactions with them will produce the same results. A "git mode" would be for conservative people afraid of switching. I agree it's not an optimal use of Pijul, since it would only improve over Git on the few wrong merges. If you would like to discuss your idea more, there is a discussion going on, feel free to join: https://discourse.pijul.org/t/spontaneous-non-branching-vs-tree-style-branches/47
I wrapped up a couple issues on [release-party](https://github.com/matthewkmayer/release-party-BR) including respecting Github throttling limits, even though I never coming close to hitting them. This week I plan on working on a couple blog posts. The Rust-related one will be test driven development in Rust. I'm finally well versed enough to make this work and there are new tools out such as [mocktopus](https://crates.io/crates/mocktopus) I hope will make it easier.
It's a quite accurate understanding of the concept. Technically, speaking, Pijul actually combines both approaches, by internally using a data structure that can be thought of as a "combination of all snapshots", but this can be manipulated as just diffs by a user (we can prove that operations on the datastructure are equivalent to operations on the patches). Thanks for the suggestion! I'll make sure this appears first on our website, before a description of the advantages.
`curl` hints it's fronted by CloudFront: ``` X-Cache: Miss from cloudfront Via: 1.1 ebc28fb0ad14691ee5d6c1a49f41b878.cloudfront.net (CloudFront) ```
I am using it at work. The main missing point for me is the swagger generation. Apart from that, it really is a nice experience.
&gt;&gt; Git is also fast. Polynomial time for pijul does not sound promising ... &gt; &gt;O(1) and O(n) are both polynomial. Pijul is advertising polynomial time in comparison to Darcs, which operated similarly on patches but could sometimes hit exponential time operations. Compared to exponential time, polynomial is a huge improvement. I don't know what the actual running time for various operations are in Pijul, but "polynomial time" does not mean bad, it means "not completely unusable." This statement is confusing. Polynomial time is not necessarily better than exponential. Usually people don't describe time complexity as polynomial unless it is exponential; otherwise, they'd go for the more specific "constant" or "linear." I don't know anything about the merging algorithms that either git or pijul use, but if pijul describes itself as solving darcs's exponential time problem, then does that mean it uses a linear-time algorithm? If not, then it's still exponential, so I don't understand in what sense the problem has been solved.
But then, wouldn't I need to [patch] their dependcies?
Well, it's might not be the best to think about it as "start on a different place" as it is "continue from where you stopped last time"
I really hope this kind of criticism will hit extremely rarely in Impl-period working groups.
Soon we will just port emacs to rust with nothing more than wrapping all it's files in `lisp!()` macros. I also think it would be hilarious to call this with `lisp![]` just to spite the parenthesis gods.
working on a simple HTTP server to learn rust. so far its going smooth. now adding more options to learn more about rust.
Is there support for lisp macro definitions, in order to be able to use rust syntax inside a lisp macro inside a rust macro?
Sure, but it's a significant hurdle, especially now that a lot of people only use laptops, and don't have a machine that's permanently on (and, yes, you can get a cheap server somewhere, that's what I do for my bouncer, but it's still annoying). The fretting over moderation is silly when the choice is "no automatic logging (only manual logs)" or "automatic logging (plus manual logs if you want)"; the latter is a strict improvement.
Reading is easier than listening to audio. I can browse it, glance at it, search it, read it, pause easily. Audio isn't like that. This is a trend all along the internet, written pieces are slowly being replaced by imo inferior tutorial videos and that kind of things. I could've read an article at work while sitting in the coffee table, but I sure won't be listening to a podcast or any video because that would disturb others. Just my two cents.
You seem to be changing your point. Your complaint seems to be that gitter gives some tools to those big bad scary *Moderators* (I'm holding a flashlight below my face, it's very scary), not that it has logging.
The author has a writeup at http://qiita.com/JunSuzukiJapan/items/7b106a1f755f125f2871 (Japanese). I wonder how a simple, real-world example like [tokio-echo-server](https://github.com/hustshawn/rust-tokio-echo-server) might look using this or /u/burkadurka 's [macrolisp](https://github.com/durka/macrolisp).
This coercion already exists
How much experience are you guys looking for? I'm an undergrad with minimal real world experience, but I can still write code competently and would absolutely love to get involved.
Can I ask what the purpose of the project you're using this for is? Like work, just to learn, etc?
There's no experience level required. It probably makes sense to start with smaller/easier issues (e.g. the 'starter bugs' on https://www.rustaceans.org/findwork ), but the reasoning is so that you can get the environment set up and familiar with the project's processes, all while still making helpful contributions, not because you won't be able to do the harder things. :)
When [talking about asymptotic running time](https://en.wikipedia.org/wiki/Time_complexity#Table_of_common_time_complexities), polynomial refers to time like 1, *n*, *n*^(2), *n*^(3), etc. That is, the running time is a function of some polynomial in the size of the input. In such a polynomial, the base of the exponential operator increases with the size of the input, but the exponent is a constant. Exponential running time refers to a running time like 2^*n*. That is, the *exponent* varies with the size of the input. If the *n* gets big enough, any exponential running time like 2^*n* will eventually grow larger than *any* polynomial. It doesn't matter what constants are involved. The fact that polynomial time is asymptotically faster than exponential time is why there is so much interest in the unsolved problem of whether or not **P** = **NP**. **P** is the class of problems which can be solved in polynomial time. **NP** is the class of problems for which a solution can be verified in polynomial time. Problems in **NP** can be solved in exponential time, by simply trying every possible solution and using your polynomial time verifier to check the result, but the big question is whether there is any way to transform a polynomial time verifier into a polynomial time solver. By the way, talking about asymptotic running time means talking about the behavior of the running time as the inputs get very large. It is possible for a polynomial running time with high exponents or very high constants to start out much higher than a particular exponential running time. But as the input gets bigger and bigger, it is guaranteed that at some point, any exponential running time will exceed that of any polynomial time.
This looks very ambitious and much needed. Don't be disheartened if it is a slow start. It might be helpful to mentor some assistants to help onboard contributors.
Thanks for the reply, I never realized that site existed.
 * https://github.com/gitterHQ/irc-bridge * https://irc.gitter.im/ "100% compatible with Lynx. Seriously."
I wrote about this a while ago: https://pijul.org/2017/07/02/web-stack.html I've changed a little since then, using Hyper as my only "web framework", and I'm really happy with it. I was planning on writing another blog post soon about how I use it. From a performance point of view, Tokio is great, the pages load really faster than I imagined at first. I had to write a driver for PostgreSQL, (pleingres, on crates.io), to be able to fully use the power of Tokio. Feel free to ask questions!
Earlier discussion of the result tables (not the paper) at https://www.reddit.com/r/rust/comments/704c27/rust_is_one_of_the_most_energy_efficient_languages/ 
Ok, good points about the complexity. So, the two initial authors of Pijul are initially computer science theorists (with obviously a strong interest in fast programs and other applications too). In the theory of computing, saying "polynomial time", for a problem that was previously exponential, means "problem solved". As you guys pointed out, this is definitely not the end of the story, as far as implementation and usability is concerned. So, the exact computational complexity of the current Pijul is: 1. For applying a patch: O((|P| + |C|) * log |H|), where |X| means "size of X", P is the patch (number of lines), C is the largest conflict P has with the current repository, and H is the history. This is actually slightly better than Git. In the early prototype (in OCaml), we had benchmarks showing that Pijul would get faster than Git at applying patches when files were big enough. - In Git, merging is proportional to (size of the **file** + the size of the conflicts), since you have to output the file in 3-way merge, whose output is the file + the conflicts. - In Git, merging is also proportional to log |H|, because opening a single commit on a file system like ext4, when there are already |H| commits, costs O(log |H|). 2. For outputting a repository: Pijul is linear in the size of each file, although the algorithm to get there is not 100% trivial (but uses old ideas). 3. For unrecording a patch, things get a little trickier, and this is not yet completely optimised. It usually runs with the same complexity as apply, but the absolute worst case might be linear in |H| (that would be when you delete consecutive lines, one at a time, in a very large file, and then unrecord the last patch).
Thanks! The design certainly was part of it, but Rust, Tokio, Hyper, Pleingres and Maud helped a lot with the speed.
&gt; Huge repositories, such as LKR, would then not be a huge problem, huge files OTOH, could. There are other things that make it hard to do benchmarks. Good point. The cool thing about the internal representation of files in Pijul is that patches can be applied anywhere in the file, independently from the size of the file. Outputting the internal representation to an actual file has a cost, but it's just linear in the file size. One potential tradeoff is on disk space, but there's too little data to measure that exactly (and Git doesn't moderate its disk usage that much either). &gt; I do think that one of the requirements for v 1.0 is benchmarks showing how pijul scales in different scenarios and considerations Agreed 100%
hi,@dpc_pw kylyp: The project use rust, rocket, diesel, postgresql, and responsive design to build a new Forum. https://github.com/mcux/kylyp
```impl Rust : Future``` less confusing because it keeps the order of the types more coherent with other contexts :)
I still do not understand why there is still a difference on name-import when bringing-into-scope vs not-bringing-into-scope, e.g. ``` impl ::serde::Serialize for MyType { ... } ``` instead of simply ``` impl serde::Serialize for MyType { ... } ``` This is actually something that has really really confused me in the old design. :( Now it seems to be that it must be somewhat important but cannot find the reason. Can someone here tell me? PS: Besides that I also find the leading `::` to be really ugly but that is just personal preference.
Ah, Maud! So that's why it feels like almost serving static pages.
 lisp! { }
This is what I ended up implementing. impl&lt;'a, T&gt; From&lt;&amp;'a T&gt; for Foo where T: AsRef&lt;[u8]&gt; + ? Sized { fn from(value: &amp;'a T) -&gt; Self { Foo { value: v.as_ref().to_vec() } } } Note that this works on a straight byte string but only up to length 32 - seems like there are AsRef impls on [T; 0], [T; 1] ... [T; 32]. I had one unit test with a 33 byte string that still broke and required an explicit .as_ref(). Very messy stuff.
https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule
**Greenspun's tenth rule** Greenspun's tenth rule of programming is an aphorism in computer programming and especially programming language circles that states: Any sufficiently complicated C or Fortran program contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp. This expresses the opinion that the argued flexibility and extensibility designed into the Lisp programming language includes all functionality that is theoretically necessary to write any complex computer program, and that the features required to develop and manage such complexity in other programming languages are equivalent to some subset of the methods used in Lisp. It can also be interpreted as a satirical critique of systems that include complex, highly configurable sub-systems. Rather than including a custom interpreter for some domain-specific language, Greenspun's rule suggests using a widely accepted, fully featured language like Lisp. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
&gt; Any other ideas? Good noise-blocking earphones, warm socks, flapjacks. 
Thinking in another direction, i wonder if it would be useful to adopt the kanban idea of limiting work in progress. If there were no more than three RFCs on the go at any point in time, it would be much easier for the wider community to keep up. This might limit the rate at which RFCs actually get merged, but that feels like it might be a good and necesarry thing. This could be combined with a staged approach, where an unlimited number of RFCs can be in preparation, but only a limited number are being publicly discussed with a view to being merged.
I don't really see that helping. Most folks don't care about _all_ RFCs, they care about a few. The problem here was not too-many-rfcs, it was too-many-comments on one RFC (multiple times) Also, this already kind of happens to some extent. RFCs get postponed when that area has other priorities at the moment.
The consensus on this talk is documented and was "hold", though. The corresponding RFC was not accepted and closed. In April this year. https://github.com/rust-lang/rfcs/pull/1865 This is literally the first time I read about Gitter being used for this, while we're fully in organising one of the conferences kicking of the project. I appreciate trying out things, and even favor the approach, but trying out things undercutting the RFC consensus while at the same time pushing for the community team to take part in the RFC process is not fun. Either the approach is "let's try out and see what sticks" _or_ RFCs, but RFCs and ignoring them a few months later isn't it. (Edit: digging through emails, I found a plan of this communicated. I'd still appreciate if this subject were pointed out.) 
Had exactly the same reaction. I was both disappointed *and* delighted. Weird feeling!
`impl Future for Rust`?
basically other places there's ```&lt;SomeType as SomeTrait&gt;::method_name``` (rusts' UFCS), ```and Box&lt;Foo&gt; as Box&lt;SomeTrait&gt;``` for making trait objects. (so imagine if we could write ```impl Rust : Future```, or ```impl Rust as Future``` ..) Also when you implement operators, we have to write things like ```impl Add&lt;Bar&gt; for Foo``` to do Foo.add(Bar) .. **that's** the bit that really bugs me.. the swap breaks your rhythm reading and writing it.. the incoherence between the trait and the method. my thinking is putting the type before the trait keeps everything in a more consistent order between the contexts.. e.g. (```impl Matrix:Mul&lt;Vector&gt;``` == ```Matrix*Vector```, rather than ```Mul&lt;Vector&gt; for Matrix``` == ```Matrix*Vector``` etc)
&gt; An easy counterexample here is Java, which provides a range of visibility for class members very similar to what this RFC is doing. I don't see how that's a counterexample. In Java, 'public' means public with respect to the scope it's defined in, exactly as /u/ksion says. it's true that Java also has the mildly wacky default and protected access modifiers, but that seems orthogonal to this point. The big difference between Rust and Java is that in Java, packages themselves don't have access control; they're effectively always public. So if a class is public, it's visible throughout the universe. There's never a need to "walk up the module tree". I'm biased, but i much prefer that to Rust's approach; access control on modules seems to me like a misfeature that adds work and confusion without much benefit. Java does have the walk-the-tree problem for features inside classes: a public method in a default-access class is actually effectively default-access, as there's no way to refer to it from outside the package (if we ignore reflection). How about a private field in a protected inner class of a public class? I have absolutely no idea. I'd type it and then pound alt-enter until it compiled.
As a organizing member of both RustFest and Rust Belt Rust I was surprised and disappointed that Gitter was to be used as well. I'm further surprised that members of the community team were not privy to this decision. This could have been done better.
I'd be sad to discourage you, but I'd like to point out that it'd be beneficial for both you and whole Rust ecosystem if you learned a bit more about how idiomatic Rust APIs look. Especially before releasing 1.0 versions, which may be mistaken for "stable". The moment I've read about you writing utility functions for converting strings to bytes, I was suspicious, so I looked at it. My recommendations here: * It's better to put such utilities into separate crate, since they aren't related to steganography. * I think that writing val.as_bytes() is much cleaner, idiomatic and readable than str_to_bytes(&amp;val) * you have unnecessary lifetime parameter in file_to_bytes * Never use unwrap() nor expect() in library functions (unless they can only happen because of programmer error, not because of OS error). Learn about proper error handling. (Rust has absolutely the best error handling out of all languages.) * if you don't have to load whole file into memory, don't do it. Use Read trait instead. Bonus points if you support Read trait from genio crate too. Same goes for writing. * one can chain readers, so taking any reader takes care of reading from multiple files too. * if you need file name, use &lt;P: AsRef&lt;Path&gt;&gt;, just as stdlib does. * don't take String if you don't have to store it or append to it. Use &amp;str instead Finally, I'd like to add that I'm glad someone is doing steganography work. I think it might be important for our freedom and I have some steganography projects too. Keep it up!
If the byte string is utf8 encoded, you can just pass in a regular string literal. There is an AsRef&lt;[u8]&gt; implementation for str as well.
Foo in my examples comes from a type called ByteString that despite its name holds any kind of binary data, not just UTF-8 or strings. I use b"" strings a lot in tests simply to feed arbitrary bytes into functions that use the type. https://github.com/locka99/opcua/blob/master/core/src/tests/comms.rs#L58 All those as_refs() in the code will go away when I push the impl above but that'll probably be tonight. I'm sweeping through the code in waves trying to make use of things like From, Into, AsRef to chop out a surfeit of constructors.
Why weak-refs? Or rather - why refs at all? Who owns the objects - the client? The client can't own them - it's a different process...
/u/pmeunier This is super good advice! Game studios and other places that deal with large binary files often use no version control or sub-par version control. If you can make something that works for them they'll be an easy sell.
You'd need to use [overrides](http://doc.crates.io/config.html)... which is less bad. Good point, forgot about that, still think it's the right route.
It's a complete rewrite (+ some new stuff) of our company product web UI previously implemented in Ruby/Rack. So it is work, and it is a production use. But it's quite small yet: around 5000 lines of Rust, 1000 lines of JavaScript, and a C/C++ lib.
Yes, I think this is a necessary requirement. It should also be possible to sign this kind of tag. One nice feature of git is, when signing a commit is, that you effectively sign the history too. But what I do not understand yet: A pristine is an inherently conflict free datastructure, right? Conflicts appear only, when trying to project this onto a working directory. So how are conflic resolutions recorderd? How do you agree upon the actual state in terms of files then?
`? Sized`: This is usually written as `?Sized` AFAIK. &gt; Note that this works on a straight byte string but only up to length 32 - seems like there are AsRef impls on [T; 0], [T; 1] ... [T; 32]. Yes, because const generics are not implemented yet. The [RFC](https://github.com/rust-lang/rfcs/pull/2000) has been accepted though and the impl period blog post has drawn in me and as at least one other person to try to get the implementation work done. So I'd say there is a good chance that the underlying reason for all these redundant impl's is going to be fixed by the end of the year, and from there it shouldn't take too long until the stdlib gets a single `impl&lt;T, const N: usize&gt; AsRef&lt;[T]&gt; for [T; N]` :)
I'm attempting to write an emulator for a CPU which operates on 8 bits but has many 16 bit instructions. I would like to implement many instructions which do the exact same thing on u8's as well as on u16's but mutate the state of my CPU struct. Can I define a trait and implement traits from within the struct?
I use explicit references because it makes it more obvious how the layering works. I understand that you're trying to avoid that in the final language but understanding which things are by-value or by-reference is crucial here. So for the scope of this discussion, I'll use `&amp;` to denote pointer-indirection. Firstly, while you may be right that the `borrowed` allocator type you write about is, by-definition, borrowing by-value an existing reference, it could just as easily borrow that reference by an additional layer of referencing, or alternatively by borrowing by-reference the result of dereferrencing the original reference. In Rust-speak, given `let a : &amp;Obj;` 1. `let b : &amp;Obj = a;` 2. `let b : &amp;&amp;Obj = &amp;a;` 3. `let b : &amp;Obj = &amp;*a;` All end up with a similar lifetime (since the compiler knows the referred-to value lives at least as long as the original reference to it). So then my point is that `borrowed` isn't special at all, it's merely the `lexical` allocator owning the reference (as far as I can tell anything that lives on the stack is always owned by `lexical`). Whether that's done by 2 or 3 is irrelevant here, but for our purposes I'll use 3 because it is cleaner. Let's make the ownership explicit throughout the examples: Borrowing something owned by any allocator, with `lexical` as the owner of the resulting borrow: ``` let a : (&amp;;lexical)(Obj;?); let b : (&amp;;lexical)(Obj;?) = &amp;*a; ``` Borrowing something owned by `GC` with `RC` as the owner of the resulting borrow: ``` let a : (&amp;;lexical)(Obj;GC); let b : (&amp;;lexical)(&amp;;RC)(Obj:GC) = RC::new_from_owned(&amp;*a); ``` At this point the layering structure is that we have the sole stack-reference to an `RC`-allocated reference living in the heap which is one of potentially many references to a `GC`-allocated `Obj`. In traditional Rust allocator-in-the-type parlance, an `RC&lt;GC&lt;Obj&gt;&gt;`. Therefore there's no sharing of metadata, only the `Borrow` and `Return` calls letting the underlying allocator know there's a reference to some of its data from outside its own domain (and that the reference has ended). Now `Borrow/Return` may need to be specialized on both the source/target allocators so it's somewhat nasty, but there's no need for the two to be aware of deep implementation details of the other, or share the same metadata. As to why you'd want to add that: - It gives you an implementation of `borrowed` without a new allocator type. - It solves the problem of multi-owner objects (`RC`/`GC`) for whom `Move` cannot be implemented safely (but `Borrow` can). - It means I can write a generic container that uses reference counting internally and yet can be used to hold references to GC-managed objects. This is especially important for gradual memory management, because otherwise you can get a [red-blue split](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) in your data structures, which is not fun.
Note that in some cases, `Read` is actually implemented on a `&amp;T` so you merely need a `&amp;mut &amp;T` instead of a `&amp;mut T`. The most notable example of this is the impl of `Read` for `&amp;File` because it doesn't actually need mutability because the current position within the file is managed behind the scenes by the OS. `File` is nothing more than a wrapper around a file descriptor or handle which it never mutates.
It might be helpful to think about the most typical use cases for `Read`: files, pipes, and TCP streams. In the case of files, a file might be larger than the computer's memory, so it's natural to read through it in small chunks, rather than always from the beginning. But even more importantly in the case of pipes and TCP streams, the bytes you're reading might not be stored _anywhere_. (Think about reading output of `cat /dev/urandom` or `curl www.bigwebsite.com`.) There's no way to "go back to the front" after reading bytes from a pipe, unless your program stores the bytes itself somewhere, and that might take up more space than you have. In that case "moving the reader forward" is just recognizing that new bytes have come over the wire, and the previously read bytes aren't getting stored anywhere. That said, you might be interested to notice that if you read [the docs for `File`](https://doc.rust-lang.org/std/fs/struct.File.html) (or [for `TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html)), you find _two_ implementations of `Read`: impl Read for File impl&lt;'a&gt; Read for &amp;'a File What is that second one? That's saying that you can read from a shared reference to a `File`, just like you can read from a `File` that you own. How does that work, if there's mutable internal state involved? It turns out that _the operating system itself_ is responsible for keeping track of our "cursor position" in the files we've opened, and it's happy to synchronize multiple threads trying to read, so it Just Works. And that's another reason for the "move the reader forward" behavior: this sort of thing is baked into operating systems, so it tends to give good performance, and programmers are used to working with it.
&gt; The consensus on this talk is documented and was "hold", though. It still is. This isn't a permanent move to anything.
It's new! It's linked in the post, but there are lots of links in the post.
Git stores the complete compressed snapshot history of files though. So applying a patch only applies when you need to literally 'apply a patch'. Otherwise it just unpacks the file and done. Whereas pijul has to build the recent state of the file from the complete patch history applied to that file. Short when history is short but gets longer when history is longer. But pijul could speed this up by snapshotting the files. And then it could compress them by using deltas. And then you have git. üòé The mistake is people assume git is a vcs. Really it's a compressed object store. üòâ Patch histories, etc are derived after fact. You really saved the delta of the two files. When you do a git log -p then you see the reconstructed patch history. 
Yes that is mine! Can't actually remember if it's *completely* up to date, but it mostly is. Some parts are pretty much thrown together to try and get it finished for the deadline so it's not the most beautiful or efficient code ever written. I'd honestly say it's not worth looking at the decoder because it's got very little work put into it. The 2-D DCT is pretty much where I hit the immovable object, because there isn't actually an enormous amount of material on it. Aside from some research papers for Masters degrees etc there's actually very little. Even just finding worked examples of a 2-D DCT on an 8x8 block of numbers was hard to find. I found 1 through google images and mine got the same answers in column 0 but no others...which was strange. I probably won't be going back to it for a week or 2 at least because work is pretty busy and I've been assigned an issue on rust-bindgen which has a bit more to it than I originally thought. I'll hopefully have a proper look through yours in the next few days :-) 
VLAs would be really useful. Hopefully any research you can do will help [RFC 618](https://github.com/rust-lang/rfcs/issues/618) move toward a consensus.
Why not use Into&lt;Vec&lt;u8&gt;&gt; instead? I find it more precise because it states the minimal requirement for type to be usable and you do the conversion anyway.
Ah, thanks for correcting me! It must have been too long since my college class that covered this stuff. I've been apparently misusing "exponential time" for a while now, when I meant polynomial.
But 1.6 MB won't fit a floppy disk!
Not even 3 months passed since Aaron's blog post, the module revamp RFCs were pushed like crazy and many complaints about it were dismissed fast.
&gt;Maybe someone else has some better ideas, though. Rich Hickey had the same idea, https://youtu.be/oyLBGkS5ICk?t=40m33s. The whole thing is worth the watch though.
&gt; It can also be interpreted as a satirical critique of systems that include complex, highly configurable sub-systems. I think it's alright, that a compiler is such a complex, highly configurable system.
Wow, thanks. I'll try again soon. :P
Your problem is in this line: impl&lt;'a&gt; Iterator for &amp;'a mut MyStruct&lt;'a&gt; { You're saying the mutable borrow lasts as long as `MyStruct.d`, which is `&amp;'static str` in your example. Try changing the above line to impl&lt;'a, 'b: 'a&gt; Iterator for &amp;'a mut MyStruct&lt;'b&gt; {
&gt; Whereas pijul has to build the recent state of the file from the complete patch history applied to that file. No, darcs did that, but it is sometimes slow, especially so when there are conflicts. Pijul is different, it uses patches, but applies them to a datastructure that is neither a snapshot nor a patch (it's actually close to a representation of the snapshot, but with a lot more information about history). I don't see any obstactle at the moment to handling large files. This is already possible (in principle), but poorly tested. Also, it isn't clear that the way of handling large chunks of data in Sanakirja is optimal for that. It optimises disk occupation, but maybe not performance. Also, I don't know too much about disk performance (for instance I'm not sure how the caches internal to the disk work, and even if there are any on different types of disks).
Thanks for the description! Sounds like things are coming along great.
Honestly, the small performance difference between Rust anc C/C++ looks promising for Rusts future. I'll start using it soon for small personal projects to see how I like it.
https://en.wikipedia.org/wiki/M-expression
**M-expression** In computer programming, M-expressions (or meta-expressions) were an early proposed syntax for the Lisp programming language, inspired by contemporary languages such as Fortran and ALGOL. In particular, they did not feature the heavy use of parentheses for which Lisp became notorious. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
I am looking to use oci_rs towards a Oracle DB backend that has some really hairy PL/SQL procedures that (sometimes) returns values by mutating the bound variables. Naturally I would expect this to cause a few problems with Rust, and I am not surprised that this doesn't work. ( I.e the bound variable does not get updated ) Example here: ( C++ updates the value of num2 to 43, Rust does not ) https://pastebin.com/DsaJLVTR My question is, does anyone have a suggestion as to how I can get the desired results in Rust ?
I'm unsure what you mean in your last sentence; does this resemble what you want? -&gt; https://play.rust-lang.org/?gist=4353256e3d06f06d46641afd32381cda&amp;version=stable
Magic! Thanks. Can you explain why it's needed? AFAIU `'b` will have the same lifetime as `'a`.
Does gitter even offer any accessibility tools? In the RFC someone specifically claimed it wasn't accessible (as in blind accessible)
My apologies; this is my fault. I completely understand the frustration that, after a lengthy, failed RFC process, this decision seems made by fiat. I think I personally didn't place enough consideration on the fact that this would be *the* major discussion venue for this period, and therefore has significant weight as an "official" channel. As Steve said, the *spirit* was one of "oh, we're running a short-term program which will require a bunch of fresh channels, and one where we want high accessibility; this is the perfect opportunity to try out a different platform". But you're right that, in practice, there's more significance to it than that.
Please see my reply above. But in particular, with respect to the community team: the team lead sits in the core team, where this was discussed, and it was mentioned in emails sent out to *all* Rust teams. (Not to say it couldn't've been done better, just that it was communicated.)
&gt; For example, in the regex-redux benchmark, which manipulates strings using regular expressions, interpreted languages seem to be an energy efficient choice (TypeScript, JavaScript and PHP, all interpreted, are in the top 5), although they tend to be not very energy efficient in other scenarios. Thus, the answer for RQ2 is: No, a faster language is not always the most energy efficient. This is not very surprising, since those languages AFAIK use regex implementations written in C. I don't think this benchmark supports their conclusion.
If too many comments are a problem, why not use threaded comments like Reddit? This scales a lot better than chronological comments like on Github or Discourse.
No, they will not be the same. `'a` will be set to the scope of the mutable borrow of `v`, which ends after the for-loop.
That's how Rust used to write it, but it was very confusing in practice, lots of people couldn't remember which way it went.
Thanks for the reasoned and transparent response.
&gt;**EDIT:** what people who use Pijul and the Nest (outside of me) currently complain about is essentially the lack of a UI to display patches (even the CLI cannot do it). Is that something that could be contributed by someone outside the project? 
Look at the weld project. 
You're welcome to make that call. You're clearly not my audience, and that's fine! Truly! But note that there are a lot of people for whom this *is* helpful ‚Äì people who listen on their commutes, or while working out, or any number of other scenarios. That it isn't for you is fine; but that doesn't mean it shouldn't exist. :-)
&gt; lots of people couldn't remember which way it went. to me it's also closer to the 'plain impls'. ```impl type{}``` ```impl type:trait {}``` I guess there's always conflicting opinions , I remember suggesting ```impl Type as Trait``` rather than just the plain ':' separator but people thought that looked too weird (even though it's seen elsewhere) I can sort of see that alongside bounds ":" it might be hard to visually seperate, but it still makes sense IMO ... it's saying 'this type, satisfying this bound' .. the type can slot as a typeparameter, as seen in the bounds expressions I'm guessing having the option retrofitted would meet with heavy resistance (r.e. fighting over style, if you can write it both ways). I guess we could make macros for implementing 'operator overloads'
It may be, but it's not the easiest thing.
Hmmm yes looks quite like what I'm looking for. I'll go try it now. Thanks. Edit: I would like to do something like take an operand then use methods like wrapping_add that is implemented for both u8 and u16. 
Science hasn't gone far enough.
That would create a whole lot of pressure to choose the right RFCs to move from the "preparation" to the "public discussion" phase. Cutting it down to 3 RFCs in flight would probably quickly make the backlog stretch out to years. I can see this rapidly resulting in many unhappy people.
Enums are horrible. You don't have a guaranteed width, it's implementation defined. Rust enums are fine - you can use #[repr(u32)] or similar to fix the width, or use the default repr if you're not exposing the API to another language. Because the type of an enum is implementation defined, it's not possible to provide a #[repr(C)] for every compiler/arch
Depending upon your setup you might be able to use [sccache](https://github.com/mozilla/sccache) to reuse your compilation artifacts. This might make sense if you are using EC2 as a build server.
Huge files, well, huge binary files, are already something git doesn't handle well so I don't think pijul is in any worse place than git in that area. While I appreciate the value of thinking of benchmarks that pertain to unique aspects of pijul's architecture, I think most calls for benchmarks could be satisfied on a first order by cases common to all VCS concerns. e.g. How fast can one clone or commit with a repository of x files and y commits for increasingly large numbers of x and y; how fast can one branch out a different line of development, and merge it back in after z commits. Sorry, falling back onto git terminology here but most VCSs can do the same benchmarks at this set of operations for at least a single user (I'm thinking svn vs git). At some point, I'd agree then benchmarks become more and more VCS sepecific and less quantitatively comparable between systems.
If you are doing `--release` with `lto=true` (which you should for release build farm binaries) your builds will be single threaded so multiple CPU cores are a slight waste, GHz is the main thought-put indicator. You could use `cargo vendor` will let you skip external calls to `crates.io` as you'll cache your dependencies locally, and they can be part of your `tmpfs` mount. `tmpfs` is a huge win. This requires keeping a `.cargo/config` within your project's root. This also helps with long term stability, but makes adding deps a bit harder on the end developers.
Rust has by-reference output parameters, but the signature for the parameters of `Statement::bind` is `&amp;[&amp;ToSqlValue]` without a `mut` in sight. oci_rs is missing that feature; `bind` is input only. And that design choice makes sense to me. The signature `&amp;mut [SqlValue]` would be required. You'd need to declare `let mut parameters: = ["foo".to_sql_value(), ...];` to use it. That's a bit ugly for the read-only by reference use case. It's most likely possible to implement a `bind_mut` method that would do what you want. But the oci_rs library needs enhancement. (Could be a fun introduction to unsafe if you're up to a challenge.) 
Is there a document platform that is capable of handling discussions at the scale of Rust RFCs? The only one I can think of is Google Docs, but comment threads there tend to quickly get out of hand if more than a ~dozen people participate in them actively. On the other hand, people able to discuss specific fragments rather than making sweeping statements would possibly help move the discussion forward much quicker and ground it in concrete proposals, thereby reducing the noise/signal ratio.
It would be nice if Rust had its equivalent of WSGI, so that Rustic webservers can be developed independently from both web frameworks and actual web applications.
It has a good IRC bridge, and is an open protocol with multiple clients.
Anyone else having trouble with that link?
Again, I think that it's completely missing the point. Just like benchmarks comparing allocation speed in C++ and Java, it's not the reason you'd choose one over the other. Git and Pijul work in fundamentally different ways, which means that certain code bases may benefit more from one or the other. Comparing benchmarks can, at best, hide this fact and, at worst, make it more obvious. Say, for example, that we have a repository that contains pictures, and it completely wrecks pijul's solutions. It wouldn't matter at first, because it'd be fast enough eitherway, but as things scale up I might see that git is a better choice. I can make examples that cater to Pijul's strength, maybe making testing easier or such. For example repositories were there are many binaries with few shared dependencies. A lot of the merges could probably be partially tested, and we wouldn't have to retest every merge. Pijul makes this easier. Benchmarks is the wrong way to compare things. Just as only looking at horsepower in a car is the wrong way to make a choice. Instead it's better to understand how and why it's better. I do want benchmarks, showing me how pijul scales, and what numbers it gives me. I don't care if it's faster or slower than git for operation X, instead I care if the way in which it does operation X is better for me. Think of how people that were looking at how git handled long chains of commits were completely missing the point about branches and merging. Benchmarks hide the important non-numeric differences. I think that what we need is a better explanation of how they are different. An explanation of concepts and basically showing us what the difference is. An honest listing of the pros and cons of each solution, and a way of understanding what compromises you have to make. A VCS is not a critical part of a loop that needs to be fast as possible, it's a part of a huge and complex process that can lead to very complex and long processes to guarantee quality and do releases. How it can fit these processes is the important difference.
I'd agree that it doesn't need to be as fast as possible, but below a certain speed for common operations will make uptake difficult.
This seems to be largely a limitation of GitHub's commenting functionality; particularly, its lack of threading. Hmm, what if RFC discussions took place on a widely different UI paradigm? Perhaps something graph-like, such as an [argument map](https://en.wikipedia.org/wiki/Argument_map)?
I see. This is most advance usage of lifetimes for me yet.
Its a side effect of doing logging in a central place. The party doing that centralized logging has the ability to edit history and delete comments, and all the other fun. And gitter is actually giving that ability to moderators. On the other hand, if a message goes to a bunch of bouncers right after it was written, its not possible to alter the history any more except if you add additional functionality on top of that into which the bouncers have to opt-in. Its definitely a huge plus to have the history saved, but its *also* a huge minus if the history can be manipulated.
Has anyone shown lto=true to improve performance in real-world rust programs?
It's likely that I'm completely missing what you're trying to do. But it sounds like you're asking about classes, and Rust just doesn't do that. If so: In Rust, intimately related types would be defined in the same module, which gives them access to each other's private items. That is, just because A and B are different types doesn't mean that A must be protected from B's code. Instead we worry about the size and comprehensibility of module that contains both. Encapsulation is good but we have tools that *only* manage encapsulation without tangling it up with data typing. Therefore, `struct MyType {...}` and `impl MyType {...}` are sibling declarations within the same `mod`. We don't have a `class` keyword that tries to do all three. 
I wrote process management tool, similar to supervisord, circus, etc. https://github.com/fafhrd91/fectl
Can you get a bigger instance? Four cores plus hyper threading isn't that great for parallel compilation.
Huh, a Rust-RFC subreddit... sounds great to me. A lot of the time, I get lost quickly in those *(occasionally huge)* linear GitHub-RFC discussions. This would also ease scrolling back for context, and I could easily hide whole sections of an RFC's discussions I'm not interested it.
The `:` operator is used for sub-type relationships already though with lifetimes, so I don't think that would make sense. For instance, `'a: 'b` is saying 'a is a subtype of 'b ('a outlives 'b). There was a proposal for adding subtype relationships to structs that used the exact syntax you're using, if memory serves. There's also super/subtraits using the `:` operator. Unless that's what you meant? 
One thing that helped me is the idea that when you see the : in lifetime types, it reads as "outlives." So "For a lifetime tick-a, and a lifetime tick-b that outlives tick-a, implement an Iterator for a tick-a mutable reference to a MyStruct with a lifetime tick-b." Or, interpreted a little further: "Implement Iterator for a mutable reference to MyStruct, where MyStruct has a lifetime that outlives its reference. 
 &gt; The : operator is used for sub-type relationships already though with lifetimes but isn't it also used to express trait bounds, ```A:B``` means 'A satisfies B' , e.g. in trait bounds such as ```T:Num```... wouldn't this make sense to read: ```impl FixedPoint4pt12 : Num {}``` ... suggests that 'FixedPoint4pt12' can slot in as a 'T' in ```fn some_numeric_func&lt;T:Num&gt;(x:T,y:T)-&gt;T {}``` I sort of see traits as analogous to 'distributed multiple inheritance'... it's as if the 'bases' just don't have to be declared in one place . anyway the part that bugged me was the flipping back and forth with the operator traits, and with 'From' / 'Into' // thought: 'I want to implement Matrix Times Vector' // what do I write? // flip.. // other self impl Mul&lt;Vector&gt; for Matrix { type Output=.. // and flip them back.. // matrix vector fn mul(&amp;self,&amp;other)-&gt;.. } I know it doesn't sound like much but it makes it stand out even more, compared to just writing an overloaded function (it takes more mental steps to figure out the trait bound for the function you want). Sometimes all the bounds etc can be bigger than the actual functions you're writing .. the more you break things down into re-useable components, factoring out common pieces - the more true this becomes maybe there's other cases where it was clearer the other way.. is it simply the choice of the preposition (for vs as)?
At least slacks interface is sensible. I tried gitter again and its just plain confusing. IRC is simpler, that should say enough.
Seconding this suggestion. We've got a rather large project with lots of dependencies and sccache *dramatically* reduced our compile times. It's especially nice if you're working with a continuous integration system that supports distributed workers (like gitlab) since it can use a shared S3 bucket as the storage backend.
I've used Slack and Flowdock. Both were trivial to understand and learn. Gitter has repeatedly confused me.
Most report it as a 10-25% performance increase. 
Nice disclosure, thanks for doing it right. Solid timeline as well.
You've got to be careful with the generic impl's though - it's pretty easy to end up with duplicate trait impl errors, at least until [trait specialization](https://github.com/rust-lang/rust/issues/31844) gets implemented.
AFAICT, the only way you'd get a crate's tarball in your cache would be if you built a project which used that crate. In that case, you're already running arbitrary code from the crate being built (`build.rs`), and so that code could still quite easily overwrite whatever it wants in the global crate cache, or do any other nefarious thing as the current user. Did this security issue actually expose any new vulnerabilities?
I agree. It's easy for me to get an absolute point of reference of how certain operations would work with my repository (do a transfer with no history) and see how it feels. The benchmarks that I would want are things that show me how the system would scale to my needs later on (will I need to change again?).
I feel you. It took me way longer than I thought to write the following code pub fn get_response_str(url: &amp;str) -&gt; Result&lt;String, Error&gt; { let mut core = Core::new()?; let client = Client::new(&amp;core.handle()); let uri = url.parse()?; let init = Vec::new(); let future_action = client.get(uri).and_then(|res| { res.body().fold(init, |mut acc, x| { acc.extend_from_slice(&amp;x); Ok::&lt;_, hyper::Error&gt;(acc) }) }).map_err(Error::from).and_then( |x| { match String::from_utf8(x) { Ok(st) =&gt; {Ok::&lt;_, Error&gt;(st)}, Err(e) =&gt; {Err(Error::from(e))} } }); core.run(future_action) } to be fair, hyper is bare bones and supposed to give you complete control, and that is exactly what is happening. Reqwest is like python requests and probably much easier and more in line for what most people want to do
I made a functional demo website for my boss for the project the told me to make, and he yelled at me for" wasting time" on a language that "can't be maintained" (because apparently php is).
For the 2D DCT you could always look to the OpenCV source code as there's an implementation in that. Maybe also BLAS. Or you could try a DWT as well it might be more well published. JPEG2000 uses DWT instead of DCT iirc
+1 this issue was managed well
&gt; Did this security issue actually expose any new vulnerabilities? Yes. You depend on Serde. I upload a new version of the foo crate, which is malicious, and over-writes the Serde crate's contents. You build your project. You are now running whatever code I inserted into Serde. It is totally true that in the end, you are building and running arbitrary code, but this is a serious issue. For example, say you've done your due diligence and read all of Serde's code, and found it to be without a problem. This exploit means you weren't actually reading the correct version of the code.
Yup. I was going to add a note that there might be a benefit of handling other types (ie. `Vec&lt;u8&gt;`) differently and specialization would allow for that (and if needed now on stable there's some ways of doing it through double dispatch) but really clone, behind the scenes, converts to `&amp;[u8]` and copies that, so it makes no difference atm. In this case I think it's completely fine. `impl&lt;T: AsRef&lt;[u8]&gt;&gt; From&lt;T&gt; for Foo` reads in english as: "We can make Foo from anything that is as a `[u8]`, be it an array, a slice or a vector or any other collection that can be seen in memory as a slice. I think that the statement is not overly broad.
It kinda would be great to tell cargo by default to run build scripts and proc macros under a different user with severely restricted permissions.
With the recently-merged in-band lifetimes RFC and the implied outlives relation RFC this will be just `impl Iterator for &amp;'a mut MyStruct&lt;'b&gt; { ... }`. Sooo much easier :D.
An alternate simpler fix is to implement `Iterator` for `MyStruct` directly, not for `&amp;mut MyStruct`. This auto-implements Iterator and IntoIterator for `&amp;mut MyStruct`. 
Yeah, but now there are *three* Rust extensions on VSCode Marketplace (with the old defunct one still outpacing the other two in the number of installs). Which is confusing (which one should I install?) and suggests some amount of NIH-ism in the community. &gt; The reference extension aims to be a 'pure RLS' extension and uses only the RLS and VSCode features (it does not depend directly on Racer for example, but note that the RLS does use Racer for some features). vscode-rust does that too, if RLS is available. It can still fall back to external tools, because this support predates RLS, but I don't see the reason to hold this against it. Can you please talk to the author of vscode-rust (and RustyCode, if he can be reached) about joining forces? After which two of the three extensions can hopefully be delisted from the marketplace.
This took me longer than I'd care to admit... If someone could make sure this is the "clean" way I'd appreciate it (sticking to generics). -&gt; https://play.rust-lang.org/?gist=dcdd1c5b02bfcdf099a641fe57512de9&amp;version=stable The `wrapping_add` function is a direct `impl` for each numeric type, rather than being exposed via a trait; (There is an Int trait in compiler_builtins that exposes it, but it's not implemented for `u8` and `u16`; Over my head), so you can't put a trait bound on it like I did with the Display trait; Since `wrapping_add` only accepts two values of the same type, we put a constraint on the `Operand` trait such that the RHS is of type `Self`, then implement it for both `u16`'s and `u8`'s; since the type of 'self' is guaranteed to be the same as `rhs`, we can call `wrapping_add` correctly. Not sure it's the best way, but it works.
That and it's only 1 of 2 since 1.0 and both were logic bugs only.
I think the benefits are highest when the crate you depend on doesn't have `#[inline]` quite everywhere where it should (in non-generic code), so you need `lto` to allow you to inline some small method you call in a hot loop.
Agreed, before stabilizing procedural macros I think we need to have a discussion about how we present the potential security risk to users and attempt to mitigate it. (It may be obvious that build scripts can run arbitrary code, but I think that's less obvious for proc macros.)
This is something that package signing would have mitigated, yes? https://github.com/rust-lang/crates.io/issues/75
I really wonder how people manage to read/learn/program while on an airplane. I usually hope that I don't get a nausea.
I don't really see why -- there's no way to even tell if dependencies use build scripts short of going through them all; at least proc macros are more obvious.
It depends on *specifically* what you mean by signing. Off the top of my head, I don't know TUF well enough to say. It would, at the very least, make it harder.
This means better type annotations and better completion suggestions. Some explanation of the screenshot: * The small grey rounded boxes contain inferred information and are added by IntelliJ * The type of 'vec' is inferred to be Vec&lt;u8&gt; from the push() of 'elem' * The completion suggestions are those you get from using a u8
Have you tried looking into Realtek RTL8710? [Similar to ESP8266](http://www.instructables.com/id/Realtek-RTL8710-Alternative-to-ESP8266/), but has ARM Cortex M3 which seems to be [supported by rustc](http://www.acrawford.com/2017/03/09/rust-on-the-cortex-m3.html).
Nest is one of production deployments of Rust that I am actually aware of. Everything you do is very impressive. It's a bit different from what I envision, because I want to go "an easy route" with Rocket + Diesel, while you're not afraid to get your hands dirty and work on your own tools. May I ask about the scalability and deployement/infrastructure story so far? How many instances do you need ATM, and how do you envision scalability story after inevitable Pijul success? :) . I am aware of NixOps + RustNix - is it working as well as it promises?
Does this imply that there's some way to know whether or not a deep dependency is using proc macros without going through them all?
No. I'm saying that until this problem is solved the problem you mention can't be "fixed" reasonably well
Wrt proc macros the point was that using a proc macro directly is more obvious than a dependency with build scripts. It doesn't work for deep deps, but it's _slightly_ better
Yes, I was extremely impressed with the fast response by the security team! I think it took me longer to write up the initial disclosure than it did to receive a response with the proposed patch, which was then deployed the next morning. 
How would your foo crate end up on my machine to overwrite Serde in the first place? That seems to me what /u/Diggsey was getting at.
Shouldn't it know that elem is a `u8` just because of the literal? Without needing the extra annotation? Or are they in funny boxes because they're not really in the code and the editor is just showing the inferred values.. or something?
You misunderstand my intention. I'm not asking for it to be "fixed" in terms of providing a bulletproof solution. I think it's reasonable to assume that an average developer understands the risk of *running* third-party code. And if we believe that most developers both compile and run code under the same account, then perhaps my point is moot. But I *do* think that there's a whole lot of people out there who would be surprised to learn that compiling a library containing proc macros constitutes running arbitrary code. Rather than enforce an airtight solution, I really just want to make sure we do our part to teach people about how this works, and let them consider the security implications for themselves. It could be as simple as, whenever new dependencies get added, having Cargo prompt the user with something like "The following dependencies are capable of running arbitrary code during compilation: foo, bar, baz. Would you like to continue? [Yes/No/Yes and never give this warning again]". I also think your line from above: "It kinda would be great to tell cargo by default to run build scripts and proc macros under a different user with severely restricted permissions." counts as exactly the sort of thing I'm suggesting.
Yes, those are inferred types displayed by the editor.
Along these lines, using a temporary spot instance you can quadruple your instance size for roughly the same price. * Current on-demand price for a c4.2xlarge: 39.8 cents per hour * Current spot bid price for a c4.8xlarge: 38 cents per hour That's going from 15.0 GiB/8 vCPUs to 60.0 GiB/36 vCPUs. Obvious difficulty is that you'll need an orchestration system to launch/teardown the instance. Also, you'll have to account for the time it takes to bring the instance online in your compile time (roughly a minute if you're using a pre-baked AMI)
The line `vec.push(value: elem)`, isn't even valid Rust syntax, so I presume that the `value:` part is being added by the editor (and indeed, in the stdlib source, `value` is the name of that parameter to `push`). And the `u8` annotation above is in the same odd font as `value:`, so I presume that's also being added by the editor, but then again the comment seems to imply otherwise...
I'm guessing it's specifically when your project build has to pull a new copy of serde from crates.io, not if it's already cached locally.
IntelliJ's rust plugin doesn't use RLS and doesn't have plans to do so, does it?
My understanding of the vulnerability from reading the linked forum thread is that it consists of a piece of your local cache (e.g. Serde) being overwritten by a crate that you meant to download (e.g. foo). Downloading Serde from crates.io would always get the correct Serde tarball. &gt; Source code is stored on crates.io as a tarball, and Cargo uses the tar crate to parse these tarballs and extract them. That is, Cargo running locally could unpack a tarball for a crate you intended to download but that was maliciously constructed by the author.
This is exactly what I've observed in careful benchmarking of a largeish performance sensitive application.
I think they want to build their own thing that uses JetBrain's API. They already have tons of lexing and parsing tools for other languages.
Yes, intellij labels parameters.
Oh, if that's the case then it does seem strange.
&gt; This exploit means you weren't actually reading the correct version of the code I'm guessing Cargo and crates.io don't do any code signing. Has this been looked into as an opt-in feature? It would be nice to know when installing *and* when compiling that the code you're using is the code as released from the project. I think that the compile-time validation step could be safely ignored when doing debug builds but should be on by default in release builds for dependencies that opt in to it. I'm sure it's been brought up but I don't know whether it's actually been entertained as a serious proposal. Do you by chance know off the top of your head if this is a thing? EDIT: oops, looks like [someone else in this thread mentioned it](https://www.reddit.com/r/rust/comments/714bhi/security_advisory_for_cratesio_20170919/dn8435t/) ([link to the bug report in crates.io](https://github.com/rust-lang/crates.io/issues/75)).
Correct. IntelliJ does not use RLS. This means they have to do a bunch more work to get good type information but allows them to have infrastructure that's a more appropriate for generating incremental results quickly. A concrete advantage of this is that IntelliJ currently gives much better completion results than RLS because it has better type information than Racer (which is what RLS currently uses for completion)
Works for me on Firefox on desktop. It's a link to a PDF, so perhaps that's your issue?
I'm building some things with Rocket (nothing production yet) and it's been great, but the one giant elephant in the room so far is WebSockets, which don't seem to be a thing at all in the Rust ecosystem if you're looking for running it on the same port as your HTTP routing. Because of that, I haven't been able to use it on my more interesting applications, so it's mostly be relegated to CRUD-style apps.
I would probably use a trait that more directly represents what actually needs to be done with the input object, namely convert it to a `Vec&lt;u8&gt;`. So rather than `AsRef&lt;[u8]&gt;`, `Into&lt;Vec&lt;u8&gt;&gt;` might be a better option since it could cover things that are logically a list of bytes, but don't necessarily store them in a contiguous slice.
I might try IntelliJ Rust again, this looks really good.
Or even a sandboxed (jailed, containered, ‚Ä¶) process when available? chroot would probably be a good start though, if it's not already being used.
I admittedly only follow the RFC process casually, but in the latest rush prior to the impl period, there were so many pending RFCs that I could hardly even keep up with which few I should care about. It was quite a flood and I kept discovering things that were relevant to me but I hadn't realized were being discussed. But, like I said, I just follow along at home.
I'm fine up to the Codec layer, but even futures/sinks are hard to get right, and very few real world code out there to show some good, proven ways to use it. 
Gitter still allows the IRC style logging by individuals (in fact, it allows exactly IRC logging, since it has an IRC bridge). The moderator tools are orthogonal to logging.
The one complaint I have is explosive memory usage. Otherwise it's great.
Are they going to reimplement the typechecker in java? Sounds interesting.
Then an attacker can *only* patch your tests, code, etc. If this is to be solved it's not on the dev's system. Once an attacker can arbitrarily execute code there I think we're in really bad shape, not to mention how complicated that system would have to be - we need a whole permissions model for build scripts and proc macros and anything that executes since some crates will want to connect to the internet. Sandboxing is not the right solution here, I think.
Sure, I worked a little on my own tools, but now the only networking things still in activity on the Nest are pleingres (PostgreSQL) and thrussh (SSH). Overall, Tokio is extremely easy to use, and you can be productive really fast with it, and scale waaaay better. From what I've heard of Rails, I don't believe one can be as productive as Rails immediately. One of the reasons is the many uncertainties about what will emerge as the canonical solution for doing web in Rust: because of that, trying out new things (and failing) is tempting. About Diesel, it looks great, but I still prefer to write my own SQL. Some queries when you run a larger website can become pretty complex and SQL-engine-specific. I've certainly been hit by unspotted syntax errors a few times, or by missing tables, which Diesel would have avoided. About the scalability, the Nest doesn't have too many users, and is super efficient, so it doesn't need more than a single machine at the moment. Now that Pijul is becoming usable, I will hopefully have more data in a few weeks/months. About nix-rust, I didn't believe it would be possible when I started it, but I do like it now. It doesn't support all possible sources (git for instance), nor all the cases (like platform-specific dependencies, or when two packages have the same name and version, but come from different sources), but overall it works fairly well. I've invested some time in that, but it has probably saved me several times the investment in just a few months. So, the next step is to move to Google Compute Engine (it's hosted at Hetzner at the moment). The kind of things I'm not too sure about, is how to organise my database servers when the first machine gets busier. One of the reasons the Nest is currently fast is that there is a fixed number of threads, started at the beginning of the server, in all processes involved: fixed number of PostgreSQL connections, equal to the number of cores, and fixed number of threads in the server, equal to the number of cores. My plan is to start tracking the performance of all the parts (I'm not currently doing it), and to decide what to do based on that.
Ah, I see. I basically don't want to block proc macros on this; I feel that given that both build scripts and custom derives can do this already it is not much different for proc macros. But yeah, a `cargo audit` would be nice. For unsafe code too.
&gt; I think that writing val.as_bytes() is much cleaner, idiomatic and readable than str_to_bytes(&amp;val) `str_to_bytes` is also very confusing as it does not take an `str` but a `String`, and `bytes_to_str` does *not* do the opposite. Then there's `bytes_to_file` which despite using the same naming scheme *takes* a file. And things get stranger as the utils module is not actually used in the project, it's convenience functions for users of the library...
Neat. I didn't know that `&amp;mut T` will be implemented automatically.
Yes, but the plugin is written in Kotlin. https://github.com/intellij-rust/intellij-rust/pull/1727
Rights restriction (privdrop, pledging, sandboxing, ...) is not a *solution* it's a *mitigation technique* for when "solutions" fail.
It's great that you've pointed out missing things! Thanks. 
Absolutely not. Verifying the authenticity and integrity of a tarball doesn't mean the tarball doesn't have an unexpected directory structure that interacts with cargo in undesired ways :)
IntelliJ normally implements their own parser (*or really a compiler front end*) so they can quickly control/fix bugs with their parser handling incomplete/incorrect code. At least that is the logic they've used C/Go/Java/Scala/Koltin/Python/Php so far
Ok, so the PDF is not the problem, it seems to be weirder. If I log into the VPN of my university, it works. But not, if I try to access it without the VPN. Normally I use the VPN, if I want to download books from link.springer.com. Do you use some *academic* internet connection?
My main complain is a horrible performance. As soon a they fix it I will switch to it from Sublime.
I really like Rocket so far, but it's far from complete. I'm not sure if anyone's mentioned it yet, but performance is also sub-par since it's not yet using async `hyper`, which means that it's using a threadpool for requests. This means that it may be competitive to other threadpool-based servers, but there's still quite a bit of performance gain to be had by switching. For me personally, I won't go to production until those two issues (async i/o and WebSockets) have been fixed, and even then I'll be a bit hesitant to go to production with anything super mission critical until it reaches 1.0 and compiles on stable Rust. I also need to have something less critical in production for a time (a few months or so) without major issues, which I don't have yet. I definitely think it could work for less critical, relatively low traffic sites in production.
Nope, I'm at work, and besides blocking a few sites, we don't have anything in the way of content filters. Since you're on a university connection, they probably have content filters. I'm guessing your VPN is over an encrypted connection, which mean they can't filter the content of your requests, thus it works. It's also possible that they've flagged the domain for some reason. If the domain isn't flagged, then you can check out [this link](http://greenlab.di.uminho.pt/publications/) which has the list of publications (there's a link to the author's blog, which contains [a brief abstract about the paper](http://greenlab.di.uminho.pt/2017/06/27/new-paper-accepted-sblp17/)) or you can just look at [the results](https://sites.google.com/view/energy-efficiency-languages/results?authuser=0), which is hosted by Google sites and thus probably isn't blocked.
Do you intend to publish in a peer-reviewed journal?
I think the comment is talking about the *suffix* on the literal.
Yes.
Ah I see, from my first reading of the post I thought that it was saying that the attack was happening server-side, with the code on crates.io itself being overwritten by a malicious upload. In my mind this meant that anyone using any package on crates.io could have been potentially compromised, but it looks like this would actually require users to actively add the malicious package to their deps, which is far less severe than I thought it was.
Sure, but it isn't a very good one in this case - you don't limit the attack surface much, you don't protect the system much, an attacker still has a ton to work with. And it would be pretty complicated to implement, too. Sandboxes are a great solution for when you have a tight policy, ideally one that's easily determined. For a browser, you can just say "This component needs only these things ever" and build around that. For a crate, some need network, some might need file IO. How do you differentiate those? You could pass a definition of the sandbox with the crate, but now you have to protect that - probably through digital signing. OK, so we have our digitally signed manifest and we can shut off network and IO for our build.rs. Cool - now the attacker patches your tests. You run 'cargo test' and you're owned. OK, maybe you don't run your tests. The attacker rewrites your code to mine bitcoins. The attacker overwrites another crate's build.rs file? Gotta protect those too... If we can't limit the attack surface meaningfully, given the complexity of a sandboxing solution here, and there are easier ways to tackle this problem, I feel that a sandbox shouldn't even be considered - it'll only provide a false sense of security and increase the complexity of deploying a crate and building a rust program. Digitally sign crates, accept that we're executing arbitrary code, deal with problems case by case. That's my opinion. edit: And I call it a 'solution' but 'mitigation' and all these words are so muddied by the security world at this point. Just read 'approach' I guess.
I actually haven't had performance problems, except for huge memory consumption, which can lock my system up. But when there's RAM enough it's pretty quick.
It just seems weird, why would anyone block the website of a computer science department of a protuguese university? (http://di.uminho.pt/ does not work). On the other hand, www.uminho.pt does work. And to clarify, the VPN I use actually is provided by my university. Is there no way they could block this equally as they block my normal connection?
Tho it may be like: "Compiling somecrate... Done, took X seconds"
&gt; And to clarify, the VPN I use actually is provided by my university. Is there no way they could block this equally as they block my normal connection? That depends on the VPN and where you are accessing things from. If you're on a guest network, there are likely tighter restrictions than if you're on an authenticated network (e.g. you logged in with a username and password), and perhaps the VPN is on an even less restricted network. University firewalls can be quite bizarre, and quite often they have a policy of "if in doubt, block it" for the more restricted networks. I'm guessing you could contact IT and have them whitelist that domain (I've done that before at my work and at my university). If your VPN is encrypted (most likely the case), then it definitely falls under the restrictions of wherever the VPN is hosted, and if not, all kinds of stupid things could be to blame.
Why I got impression that the Chalk itself will be integrated? Any idea?
That's true. What's interesting is a way to hide such exploit. Someone would have to manually inspect the tarball to find out.
Using a VM template might be more secure and possibly easier to implement. Something like what Qubes OS PDF viewer template does.
I think it does. In my mind, it's more about the normal usage of the language. If that isn't the case, you'd have to disregard every single `[x for x in y]` in Python, because that part runs in C (in CPython). And maybe every Java benchmark because the Sun JVM is written in C. It's less about "what language did these instructions come from" and more about "how energy efficient is using this language".
That would definitely be nice. As it is, I think Rocket makes local development and testing pretty easy with their workers that listen on non-80 ports. Being able to configure the worker ports is also nice because it means you can go for an approach where Rocket is the app and app server while Nginx is the web server/reverse-proxy. 
For convenience, the RFC URL is https://github.com/tokio-rs/tokio-rfcs/pull/2
Thank you all for the massive effort in refactoring a tough part of rust. Hopefully I can find a way to contribute.
Sounds like the second Rust compiler is going to written in Kotlin. I find that amusing.
We'd love to have you! I hope to have more to say on how people can get involved in the next couple of weeks.
0.40 an hour is like 250$ a month. Two months of that and one could have a build box under their desk. Like this low end [ryzen gaming build](https://www.pcworld.com/article/3214626/computers/build-a-budget-ryzen-gaming-pc.html). If a cloud build server is the goal, I'd keep the whole install on a persistent volume so it can get re-attached to new ephemeral instances when they get created. * Spawn Ubuntu 17 LTS * Attach EBS Vol, /home/builder * install rustup, etc When you shutdown or lose the spot instance, your `/home/builder` will still exist on your EBS vol. If you install everything locally in the home dir, and keep the AMI totally vanilla, then your respawn times will be as low as possible. AWS EBS Vols, http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html But! You don't have to use AWS. Vultr has better low end instances that are significantly cheaper if they work for your usecase. I would definitely give the $20 and $40 / month instance types a test. https://www.vultr.com/pricing/ They have block storage (mountable persistent vols), but I have never used them. Also take a look at GCP, using preemptible instances (1/8 of regular) and a 50GB persistent vol is $30 a month for a build server that is running 8 hrs a day. GCP preemptibles *cannot* live more than 24 hrs, which i think is good. I have gotten burned leaving spot instance clusters running over the weekend (oopsie). https://cloud.google.com/products/calculator/#id=228ef8ef-ca94-4968-b8fd-8a358a00fd43 
You're right. By using boxed, nested allocation structures, it is technically feasible to wrap a Gc-managed object reference within a separately-allocated, RC-managed object. Metadata would not need to be unified and it would be safe without the allocators having to know how to cooperate with each other. That is a very viable approach. My typing nomenclature might be somewhat different than Rust's, because I distinguish the value type from the allocator type. So, let's use your tuple, where the first term is the object it points to and the second is the allocator. The Gced object has type (Obj;GC). The RCed object has type (GCObjRef; RC). GCObjRef would be a separately RC-allocated structure with a single member `ref` whose type is (Obj; GC). I think this matches the scenario you describe, which I agree would work and be safe. And it satisfies the second and third "why" in your bulleted list, other than this: You still have the red-blue split, but you have at least explicitly married them together in this context, which I agree might be useful. So, thank you for your patience in highlighting and explaining this possibility. That said, the borrow mechanism I describe is distinctly different and still highly valuable for two reasons: it is cost-free from a runtime performance standpoint (your solution bears the runtime cost of both RC and GC) and it eliminates a huge amount of parametric polymorphism. On the latter point, a huge number of functions and methods do not care which allocator created the object. That is what `borrowed` gives: a melting point in which all references are purely object references. I do not need to use generics to instantiate all methods for all classes for every allocator type, I can use borrow to coerce them to the melting point allocator type `borrowed` and read and write object contents cleanly without regard for which allocator created them. That benefit is huge in code size, programmer complexity and performance. So, two very different mechanisms, each with distinct advantages and disadvantages. My borrow mechanism (actually Rust's) is efficient, but lexically constrained. Yours is inefficient but suitable for indetermined lifetimes. I might give them different names to avoid confusion, but both definitely bring value. &gt; borrowed isn't special at all, it's merely the lexical allocator owning the reference (as far as I can tell anything that lives on the stack is always owned by lexical) `borrowed` absolutely is special and distinct from the lexical allocator, to both Rust and to my paper. First, what matters is not the memory location of the reference pointer, but the memory location of the allocated object, and specifically how it gets there and how it gets freed. Owner aliases are typed with an allocator type which tells the compiler who allocates memory for the object (and its metadata) and who frees the memory when the object's lifetime expires. Rust's and my borrowed alias never allocates memory for the object and never frees it either. It neither knows nor cares about the object's allocation status or bookkeeping metadata. It is just a pointer to the object's contents; that's all. Furthermore, the compiler treats borrowed aliases and owner aliases by *very* different lifetime-checking, move semantics and generated code rules. So, `borrowed` is semantically equivalent to saying the allocator type for those aliases is `None`, as `borrowed` aliases are completely divorced from any allocation logic. By contrast, in your scheme for borrowing, the indirect reference we packaged inside the RC allocated object does have an explicit allocator type: RC, the same type as any other RC allocated object. Thank you for a fruitful and illuminating discussion. Let me know if I finally got what you are saying.
Sounds cool! Do you intend to extend/fork rustup itself, or are you rewriting it from scratch? I know `rustup` has the `rustup run &lt;toolchain&gt; &lt;command&gt;` functionality that could be used to do the cargo/rustc versions. It'd be awesome to have a portable configuration file which would control rustc/cargo versions and other settings on all computers and the CI.
The GCP example you used is roughly equivalent to an m4.xlarge instance in AWS. Running that as a spot instance for eight hours a day with a 50 gb SSD, like in your example, is $18 a month. 
Thank you to everyone involved in working on these changes! I'm happy to see concrete plans like this announced, as we've known for some time that they were coming. I happily and impatiently await (pun intended) the time when we have the async-friendly version of Rust described as the long-term goal (i.e. `async fn` and bare `async` instead of `async_block!`.)
Thanks this seems very promising. I really like how you tackle the problem that the event loop may hangs because something just runs for a decent amount of time on It. Also that you keep the old way which maybe is required for some uses. When I was using tokio-proto a few months ago I tried to use a protocol which has async responses from the server. So the server was sending the client a message without the client asking for It. If I remember right there was no easy way doing this with the tokio-proto crate. I think It was also kinda complex to read. However I think the tokio-proto crate is very unique and very powerful If It reaches a good state. The ability to implement a protocol with just having data structures is very nice to have and probably makes alot of librarys robust If It has no drawbacks.
I'm writing my own thing, partially because I want to learn about the design constraints for myself, partially because "how hard can it be, really" ;)
It was initially a possibility, and even afterward its easy to abbreviate "chalk-inspired refactoring to the compiler" to something that sounds like integrating the literal chalk implementation.
Rls is buggy and unstable as heck.
That used to be my big gripe too, and they have significantly improved performance recently. Now it just uses my entire CPU instead of using my entire CPU and lagging a few keystrokes. It still misses too many will-be compile errors, so for now I'm sticking with VScode. I should add I'm on an i5-4690k and the CPU load is strongly correlated to project size.
I didn't know about that! Looks great as an esp8266 replacement, but unfortunately I'm drawn to the esp32 at the moment due to its Bluetooth support and various hardware peripherals. For a future project though I'll have to try the rtl8710.
[You can make life quite a bit easier using macros :)](https://play.rust-lang.org/?gist=1c5fa4a560618a73f14ec95cd034333d&amp;version=stable).
[You might try using macros if the different types have syntactically similar behavior but no shared trait.](https://play.rust-lang.org/?gist=1c5fa4a560618a73f14ec95cd034333d&amp;version=stable)
Didn't pcwalton develop some kind of [gaol](https://github.com/pcwalton/gaol)? Maybe it would be worth using it to restrain what the code can do. Ideally, hyper-restricted per default (just reading files in current `src` and writing to new files there, but not overwriting any existing one) and couple that with a section in `Cargo.toml` to specify additional rights?
~~Non-js~~ Basic HTML version: https://webcache.googleusercontent.com/search?q=cache:https%3A%2F%2Fusers.rust-lang.org%2Ft%2Fsecurity-advisory-for-crates-io-2017-09-19%2F12960 I'm very surprised that crates are (still?) not handled in an isolated environment. Rather than patching out the specifics of this vulnerability, the root of the issue should be addressed. I strongly urge the rust ops team to consider using control groups or other containerization/sandboxing mechanisms to isolate packages (and processing software) from each other. Otherwise, this will likely not be the last security issue of this type. **edit**: There seems to be confusion in this thread and elsewhere about whether the issue was occurring server-side or client-side. The advisory names crates.io as the effected component. Can someone confirm?
So is this 1 global event loop, or per thread event loops?
One global, default event loop.
If you don't want to do the "Web Server in Rust" thing, Rust can also work with Lambda or Cloud Functions through [Neon](https://github.com/neon-bindings/neon). I'm working on a side project right now and plan to host the API portion that way and the static resources in S3/Cloud Storage or Netlify. Since it's a side project, it's nice not to have to monitor or maintain server(s) and Rust's speed and tight control over memory usage are nice when using a FaaS product that charges based on CPU/memory usage. Rust FaaS is probably not the answer for most projects, but it's an option that most people are probably unaware of, I thought I'd mention it.
I was (and still am) under the same impression. Can someone elaborate? Is this a client side issue? Should we be updating our rust installations?
In on my phone and it's late, so all I'll say right now is, the page renders without JS.
It doesn't for me. I get a white page.
How do you block it? I turned it off entirely through about:config.
Surprised that D was not in the list.
[removed]
Since we have [mrustc](https://github.com/thepowersgang/mrustc), we know the second Rust compiler is written in C++.
Its a bit off-topic from the RFC itself but about tokio so maybe this is useful to you: I've a crate that does decoding (and encoding) of the ogg format and I'd got a request to provide async support so decoding can happen on the main thread so I've checked out the tokio documentation to find out whether and how I could integrate it into my crate. I pretty quickly ran into the problem that almost all of the documentation was about how to write *applications* with tokio, not actual libraries that provide async support. I get that most coders will write applications with tokio, but being usable by library writers who want to get their library async-ready should be a goal for documentation as well. That was for me at least an issue and it took me a bit of figuring out to get it implemented... Eventually I did. Another issue I had from my perspective is the `tokio-core` crate. I've initially based my implementation on that crate, until I saw the great number of dependencies it pulled in. The list of dependencies just didn't end! Previously, I had precisely one dependency, byteorder, so it would have meant quite a change. I've ended up using `tokio-io` (which still has quite a lot of dependencies) and doing a bit of duplication to make tokio an optional dependency. `tokio-core` pulls in a bunch of libraries/crates that I feel are not needed for my library, and the library use case in general. Especially, I want stuff like which main loop to have or something be decided by my users. I don't want any business in that, but `tokio-core` just gives you the whole package and downloads really a *large* amount of dependencies, without giving you the option. What I'd want from tokio is better docs on how to use it from a library standpoint, and maybe a minimal crate that libraries that are no applications can depend on (I said maybe here because tokio-io already covers most of the things I need... I just feel its important to express that there is demand for something like tokio-io). Now you can argue that if you use tokio inside an application you will have to use a loop either way, so including dependencies for stuff like loops is not a big deal. I'd say thats not true. First, there is a separation of concerns issue. You should pull in dependencies at the location you need them. Second, I have users who don't care about async but do deeply care about number of dependencies. I've gotten criticism by them for already *implementing* support for tokio, even if its completely optional and all features of the library are available separately in a sync-only fashion.
I am the creator of Redox OS. It is a microkernel based operating system mostly written in Rust. Please ask any questions or make any comments you have about Redox! EDIT: I am going to sleep soon. I will be up in 8 hours, 7 A.M. Mountain Time.
I'm using uMatrix to block third-party and first-party js. Everything else is allowed through. I'm currently using chromium 60. That said, you are completely right. I just took a look at the page source, and It seems that post text is included in its entirety between a pair of noscript tags. The problem seems entirely on my end; Maybe uMatrix is interfering with how the browser handles the noscript tag. I was was wrong to attribute the problem to a javascript requirement. I will edit my original post to reflect this. On the topic of this thread: I would appreciate it if you clarified were this security issue existed: was it effecting cargo clients or crates.io? Do we need to update cargo? Thank you.
The suffix is required because there is no other `u8` annotation. If there is no annotation anywhere, it will default to `i32`.
Oh, good that this was taken care of so swiftly. When I read the headline I immediately assumed that this was crates.io discovering typosquatting attacks similar to the ones recently uncovered at PyPI. Speaking of which, is there any mitigation for typosquatting by untrustworthy packages on crates.io? Should there be?
I'm pretty sure tokio-io is the layer library authors should use whereas core is for application authors. 
*I'm pretty sure tokio-io is* *the latter library authors should use whereas* *core is for application authors.* ______________________________________________________________________________ ^^^-english_haiku_bot
can I install it on vmware to test it ?
The ISO should run in vmware. Please let me know if you have issues
Keep up the good work!
This is impressive, and I know not every project needs to have a motivation beyond "I wanted to build it," and sometimes I roll my eyes when people question the need for a given project... But this one really has me scratching my head. I don't think the Rust developers like to make this statement nowadays, but let's face it, Rust is supposed to be a better language for many of the areas that C++ targets. And if I were going to write a compiler, C++ might be just about my *last* choice of implementation language. So... why?
&gt; Thankfully, (from what I have seen), the borrow checker is not needed to compile rust code (just to ensure that it's valid) This is an absolutely *fantastic* statement, and actually something that I have been wondering. I get the feeling that rust's compilation times have more to do with it being the "most powerful linting tool ever built" rather than any kind of flaw with the language. (I mean it's also NOT golang... it actually has types, generics and other useful features).
I just want to say that the progress on async/await has been fantastic. This RFC should make things even better. I'm so excited
[CHALLENGE ACCEPTED](https://gist.github.com/1a33f9bc8b0eaa1c80469c39c89c5f29). ^(Requires a few unreleased updates to `macrolisp`.)
200 already? Man time flies.
I think the main motivator is trying to [reduce possibility](https://www.dwheeler.com/trusting-trust/) of [trusting trust](http://wiki.c2.com/?TheKenThompsonHack) attack and for that the language you want to write it in should be one that is as widely used as possible.
What has your research showed you so far? I would be interested in your opinion. - rocket: https://github.com/SergioBenitez/Rocket - gotham: https://github.com/gotham-rs/gotham At first glance rocket is more mature and has a far better landing page, but it requires nightly and uses macros extensively. Gotham on the other hand is pretty but I prefer it's design philosophy. *Personally* I am waiting for the tokio/async/await/etc landscape to calm down before I switch off of nickel (to literally *anything* else). But it's not like I care about performance very much for my applications.
Heads up: your link seems to be broken.
It will allow for easier bootstrapping for environments with only a C++ compiler. Though a MIR to gimple compiler would probably have higher payoff. 
What changes made such a dramatic difference in memory usage?
I'd recommend you also take a look at [Shio](https://github.com/mehcode/shio-rs). It's intended to be a "simple" library and does work on stable rust.
https://github.com/redox-os/kernel/commit/d6b9768dc3e9cd967df0acf3eafb10d02c9f0ba6 https://github.com/redox-os/redox/commit/345c6bc4349d135c79fe20a6f5dcc3ea8c0e2349 These two changes made the live filesystem much more efficient.
I'm actually using [Shio](https://github.com/mehcode/shio-rs) with Diesel for a tiny API server and it's running great.
&gt; remove overzealous Box optimization Could someone say why it's overzealous? Neither the PR nor commit say what was wrong, and it's not entirely obvious from the code (something about `Box` not allocating?).
Incredible work. Can't wait to play with this!
Author here - I've kinda been holding off on making a reddit post about this until I have a full rustc bootstrap done, but it looks like someone beat me to it :)
Rocket does not work on stable yet because it uses syntax extensions heavily. I find it makes it more ergonomic than other frameworks. For example in every other framework I've seen so far if you want something from the request, you have to "extract" it in your handler, and that returns an `Option` or a `Result`. With Rocket, you directly declare the things you want extracted from the request as arguments to your handler (can even be admin credentials from the headers for example) and the handler won't be called if the request doesn't meet the requirements. The Rocket guide explains it very nicely and I'd also recommend [this talk](https://www.youtube.com/watch?v=t_FUZ34ahBE) by the author. I'd love to see a counterexample if somebody has one.
I find the effort put into mentoring like this to be deeply inspiring, and a steady reminder of why I &lt;3 the Rust community.
I am a newcomer and am using Tokio in a new moonlight project. Thank you for improving it a lot. Working with Tokio code was nice (though documentation needs a lot of attention). My main hurdle right now is that a future must be consumed in order to be processed. That forces me to take ownership of all the futures I create. For reference, this is a bit easier with Seastar: seastar::sleep(200ms).then([] { std::cout &lt;&lt; "200ms " &lt;&lt; std::flush; }); seastar::sleep(100ms).then([] { std::cout &lt;&lt; "100ms " &lt;&lt; std::flush; }); return seastar::sleep(1s).then([] { std::cout &lt;&lt; "Done.\n"; }); This code creates 3 futures but only returns one. The two "forgotten" ones will still fire up. I do not think this can be done the same in Rust with Tokio. But perhaps Tokio may have a universal Sink-like method which would make the core to take ownership of a future and to discard it once it is done. This is basically for any async operation, which produces some side effect and no result. In my side project that is a cleanup thread.
You lack perspective, have you ever tried Netbeans or Eclipse? :P Remember that it's primarily a Java-IDE.
No, the compilation times have to do almost entirely with it producing very verbose IR (not to say slapdash) and leaning on LLVM a LOT to reduce it to something sane. Frontend is like 25% of compilation time, max, and usually far less.
It's not just the quality of the IR -- it's the fact that, due to monomorphization, you end up generating IR for a ton of your dependencies too, to specialize it for your usage. Incremental compilation should ultimately help with that a *lot*.
Thanks for the kind words! The support is appreciated.
Thanks so much for saying so! &lt;3
That's the primary reason, other reason is that I know C++ pretty well (and don't know any other suitable languages for such a project).
Been following /u/mutabah's status reports on IRC... big fan of this great project! Wonderful to see that its possible for a single individual to write a Rust compiler that can compile one of the most complicated Rust codebases in existence :). IIRC, he actually achieved compilation of one stage of rustc itself at one point, but didn't get later stages and then made a source upgrade).
Offtopic, I am just wondering what is your use case and why you chose rust for your web project ?
Same. Here is my issue: https://github.com/intellij-rust/intellij-rust/issues/1572 Not resolved yet.
My primary IDE (for C++) is Qt Creator. And it's blazingly fast.
How will bootstrapping be easier?
Well it's written with C++, isn't it? 
This will be great for targeting the ESP8266 MCU. 
80 KLOC is incredible for a one person. Are you working full time on it? PS: why do you use `::std` prefix/namespace?
Qt, technically. But I don't believe that Java is so slow.
That's why crate's readme should have an Alternatives section.
I do not understand why you are putting tokio in that crate (lewton). Why not write an API where the actual reading/writing to file is done client side and your library works with buffers? 
Not full time... but I have spent many a weekend working solidly on it. The use of `::std` in paths is mainly personal preference (I like how in rust, all paths are relative unless prefixed by ::)
You can compile a Rust compiler from the already existing C++ compiler and don't need to have a working snapshot to download.
Since Rust was originally compiled with OCaml wouldn't the second compiler be written in Rust itself?
probably a *lot* harder to do (not sure if it's even possible.. ), but I would be interested in a compiler whose internal representation can handle *both* C++ and Rust constructs (as a superset), in a manner similar to how Clang is built for C, C++ and Objective-C with a unified AST (... yielding '[objective-C++](https://stackoverflow.com/questions/3684112/what-is-objective-c)' as a result). There wouldn't be a single (accepted) input syntax that can handle both, however it might have utility toward refactoring and inter-operability. (I'm imagining a single AST that represents both). Is there any possibility that this project could be extended in the direction I describe ? I guess what I really want is a heavy modification of **clang**. They do have a static analyser in progress; now imagine if the machinery for the static analyser was built like this. how to handle 'safety/unsafety'? - there'd be an AST node to switch into 'unsafe{}', and an AST node to switch into 'safe{}'. Rust and C++ code would simply start out wrapped in safe{} and unsafe{} blocks respectively (and there' just isn't a C++ language 'safe block' , yet..) C++ references vs borrowed pointers? - these would be different kinds of pointer; rust &amp; might translate into const restrict. the name spacing rules might be one of the more difficult aspects to figure out .. or would it be as simple as trait methods translating into an extra namespace layer in the C++ model? impl's would generate something like C++ 'extention methods' (.. those don't exist in C++, but our unified AST would understand this concept)
&gt; very **promis**ing \me chuckles
Have you been bitten by ADL one too many times?
I've been using http://devdocs.io/offline, enable all you need. It's been a really great documentation in 1 offline webapp.
&gt; you don't limit the attack surface much You can restrict the access to only write access within the crate itself and only have networked interactions with the outside world? &gt; you don't protect the system much, an attacker still has a ton to work with. They also have a ton less to work with A simple "install ~/.ssh/authorized_keys entry" would be thwarted. They also wouldn't be able to communicate with password agents or interact with other processes run by the current user (which can be used to extract runtime secrets using ptrace eg.). &gt; And it would be pretty complicated to implement, too. If you want to be able to always offer it to everybody. But in the beginning you'd start by offering simple hooks that allow one to seamlessly run the commands using some wrapper. And a simple coherent (optional) implementation using something like Docker would really be usable by a large number of users. &gt; For a crate, some need network, some might need file IO In it's most basic form you can just allow all of that, just limit write access and process access to the rest of the system. Perhaps in the future this can be augmented with a Cargo.toml option that specifies what type of access is required to build some crate. &gt; [...] Gotta protect those too... No, we don't. Sure it would be nice, but that would be entirely outside the scope of these hardenings. These hardenings would allow you to simply constrain what build scripts are allowed to do. They can help prevent unintended damage to the rest of the system and help limit the impact of some indirect attacks (eg. the buildscript downloads some specification from the internet and that specification file triggers a parsing error which leads to some code execution). But even simply sandboxing crate building and unittesting would help. I write multiple crates that get build and unittested on my workstation, but which are never actually run there. So sandboxing these processes would protect me from a number of abuses. &gt; If we can't limit the attack surface meaningfully, given the complexity of a sandboxing solution here The sandbox doesn't need to be complicated, a relatively simple systemd-nspawn or BSD jail based container (based on the running system) would already significantly limit possible abuses. &gt; it'll only provide a false sense of security and increase the complexity of deploying a crate and building a rust program. It's not something to be bragged about as secure package building, it's just basic hardening. And that's mostly due diligence. &gt; Digitally sign crates, accept that we're executing arbitrary code, deal with problems case by case. This will always be the best solution. But even if I vetted all my dependencies, I realistically can't fully audit every change for every one of them to be even reasonably sure somebody didn't add some clever hack in there. I can be reasonably sure, but not fully. And it would only take one trusted crated from one trusted developer who's keys were hijacked to introduce one obscure codepath that acts as a trampoline for further code execution to make this whole endeavour futile. That's not saying it should not be done, but I'd personally take any hardening on every level next to that strategy to help limit the possible impact of such occurrences. &gt; That's my opinion. Amen.
&gt; compiles rustc that can compile the standard library and hello world To clarify that I understand what this means: mrustc can compile rustc, but the compiled binary can't complete a bootstrap?
Makes sense. Thanks!
Would it run on a Raspberry Pi?
Hi, thanks for the clear response. Stuff happens :).
Still, the default product should be accessible. Discovery of channels and such happens through the main website, even when using the bridge.
From what I have seen so far, Rocket really appears to be more noob friendly because of its guide. The Gotham book is there, but its is an ongoing effort and not yet complete, you are left much to figure out on your own. The use of macros and nightly has also resulted in a pretty api that takes care of lot of things for you to get started with. 
&gt; Not full time... but I have spent many a weekend working solidly on it. I feel ashamed, I barely scratched the surface on my own project (though, I have a wife and other things to do). Have you tried compiling on some architecture that rustc itself doesn't support? If yes, how did it go?
Someone is actually trying to run Rust on ESP8266 using mrustc: https://github.com/emosenkis/esp-rs
One's an editor, the other one's an IDE...
Yes, as I understand, it doesn't complete bootstrap yet.
We need a Rust compiler in Python! Interpreted languages are hard to KTH though.
I mean, for Wheeler's DDC mitigation you don't even need a compiler in C++, two self-hosted Rust compilers will do fine. The entire point of DDC is that C compilers are all in C which kinda puts a dampener on breaking the bootstrap chain to mitigate trusting trust, and the same would be the case if we had two Rust compilers in Rust. In both cases DDC is sufficient to mitigate trusting trust. With a Rust compiler in C++, the bootstrap chain is broken already. You don't need to diverse double compile, you simply need to compile mrustc, use that to compile rustc, and then self-compile rustc.
This is extremely impressive, I saw the project a few times before, but I hadn't realised how advanced it is. Could this focus on just compiling from MIR instead? I guess MIR isn't that stable yet, but it would probably simplify the work significantly (AFAIU it would get rid of typeck entirely) and one could still use `rustc` on a different platform to generate the MIR.
It should start easy and built in assembler (or assembler in Rust) would be easier and more helpful for me. 
There's technically one kink in the language which _could_ affect this, but this has never actually been implemented and might have been rectified in later RFCs. The issue is that you can technically use specialization on `'static`. Which has its uses. However, due to the way regionck/borrowck work, lifetimes get stretched and squeezed and the original static-ness of a lifetime is unavailable during monomorphization. Furthermore, this means that for the same object `foo`, `foo.bar()` will do different things based on where it is. So rustc doesn't actually do this (and there was a move to forbid lifetime specialization except in some cases, unsure what happened to that). It's a very obscure corner of the language that's possibly history now. &gt; I get the feeling that rust's compilation times have more to do with it being the "most powerful linting tool ever built" rather than any kind of flaw with the language. Not really. Borrowck isn't _that_ heavy a "lint"; many aliasing lints in C++ are much heavier -- in fact optimizers have such heavy analyses built in already. Our compile times are bad because: - Rust lends itself to very generic code, which puts a lot of focus on monomorphization in crates down the chain - Rust doesn't have a header/code separation like C/++. This is both good and bad. I find header files to be an awful concept that conflate code organization with dependency management. However, this dependency management creates a makeshift incremental compilation framework driven by the programmer. _Ideally_ the compiler would track these dependencies itself and compile _exactly_ as much as it needs to, not more. Unlike in C++ where editing a header file to add a non-virtual method or even a comment will trigger a rebuild of a large chunk of your codebase, if the compiler has in built dependency tracking, it can figure out exactly what needs recompilation regardless of how your code is organized. Rust's incremental compilation is just that! It just isn't fully polished yet. - We produce terrible IR. Rust code has lots of abstractions/generics. These compile away, but LLVM has to put in effort into removing these. Furthermore, IIRC LLVM spends some time recomputing aliasing info that we actually already _know_ but have no way of conveying. (I could be wrong on this part). Doing more optimizations in MIR would help here.
I'd like to add that IRC channels on moznet are accessible through an alternative platform already: Matrix. With Riot.im, this provides many of the modern features that people miss in IRC (like history and support for multiple devices), along with a lower risk of alienating or separating anyone based on their choice between the two. Matrix having Free software servers and clients also aligns more closely with the ethos of Rust, compared to closed solutions like Gitter. Matrix may even be able to bridge IRC, Slack, and Gitter in one room. It would be messy, but it beats splitting the community when people will refuse to use certain platforms. If there are future experiments with different communications platforms, I propose that Matrix and IRC are promoted equally, with a clarification that they are not separate communities.
For those interested in the bits necessary for trustable rustc builds, the other half is getting [reproducible builds working](https://users.rust-lang.org/t/testing-out-reproducible-builds/9758) It seems like we're almost there, and that _excellent_ users forum post lists not only the sources of differences between compiles, but also the tools used to suss those out. Help here would be appreciated! (and if you need mentorship, I can help) -------- This is pretty great! I've been slowly trying to get an Original Rustc bootstrap working (and having a script so others can do the same), but getting the first build running requires compiling an old llvm which no longer compiles. If mrustc is almost there, this may be unnecessary :)
Let the environment that has a C++ compiler but not a Rust compiler be called X. If rustc targets X, we can crosscompile rustc to X and have a rust compiler on X. If rustc does not target X, we can crosscompile rustc to X using mrustc, and we end up with a rustc that runs on X, but still cannot target X. So it seems that mrustc doesn't really help with bootstrapping. But apparently mrustc compiles rust to C, so in that regard it can itself target almost any platform (in combination with the appropriate C compiler), so there is less of a need to get a working rustc.
Redox doesn't start properly on Hyper-V. It gets to the point where it asks if a 800x600 resolution is okay (at which point I pressed s to save the resolution) and then the screen went [black-ish](https://i.imgur.com/iVAFZLx.png) EDIT: After I increased the amount of RAM the machine could use to 2GB it worked. EDIT 2: It also turned out I wasn't using the new 3.3 release yet as I forgot to tell the machine to use the new ISO. After changing that Redox was able to start with 1 GB of RAM.
Accept underscores in Unicode escapes: `\u{1_f_____d_____00______}`. It seems to be quite common for the syntax to change, but there‚Äôs no system in place to notify syntax highlighter authors, so they‚Äôre commonly missing various features. (I just did this one for Vim; I *think* it‚Äôs up to date on syntax.) We need something like a mailing list for syntax highlighters where syntax changes can be announced. Regular expression highlighters will now need something like `\\u\{(?:\x_*){1,6}\}`.
&gt; I am happy to work with anyone from around the world as long as communication is not an issue with language and time zones. Maybe you could share which time zone you live in :)
Are there any areas on which a beginner can help?
&gt; In my mind, it's more about the normal usage of the language. If your benchmark is essentially `call_some_function_implemented_in_C()` and you claimed that as evidence that "a faster language is not always the most energy efficient", I would not be convinced. Your energy efficiency was bought by using a faster language. &gt; If that isn't the case, you'd have to disregard every single [x for x in y] in Python, because that part runs in C (in CPython). And maybe every Java benchmark because the Sun JVM is written in C. It is a big difference whether you interpret some byte code with an interpreter written in C or just execute some machine code translated from C source code by an optimizing compiler. Just calling a function implemented in a more efficient language is not always possible, see the benchmarks where the interpreted languages suffer.
I'd love to hear more about the app-dir support added to Ion. I couldn't find it mentioned in the manual. Thanks for the awesome work!
Specialization on lifetimes doesn't really work, because *no lifetime is absolute* (barring `'static`, I suppose), and you can actually have *infinite* Œº-like "recursive type" constructs out of lifetimes in tail-recursive functions, so monomorphization is out of the window. But also it makes HRTB unsound, and we support dynamic higher-ranked lifetimes in stable Rust (literally `fn(&amp;T)`), even if you ignore [the `indexing` crate](https://docs.rs/indexing). We've *already* decided that there is no path forward for Rust other than lifetime parameterism (as Haskell requires for types). In [the tracking issue](https://github.com/rust-lang/rust/issues/31844), the lack of checks around lifetimes is considered a soundness hole that has to be fixed before specialization.
jesus everloving christ, what the hell happened to c2? You do not need megabytes of javascript to serve text, guys. 
It was a client side issue (cargo would not check if the tarballs were well-formed), but it was mitigated server-side, by only allowing well-formed tarballs to be uploaded in the first place. They also mentioned that new versions of cargo also check the well-formedness of the tarball, as an additional layer of defense.
&gt; Furthermore, IIRC LLVM spends some time recomputing aliasing info that we actually already know but have no way of conveying. At least part of the problem is that if rustc does provide aliasing info, [LLVM miscompiles things](https://github.com/rust-lang/rust/issues/31681).
The compiled rustc hasn't been tested with bootstrap, because to do so requires cargo - which I'm "currently" working on compiling. (Yes, I could download a cargo build and plug the built rustc into that, but that would be cheating)
This looks really cool.
Eventually. There is no port to any CPU architecture other than BIOS based x86-64 PCs at the moment.
my website is in Rust/Iron/Tera -- https://gildedhonour.com
There is [a "petition" ticket](https://youtrack.jetbrains.com/issue/IDEABKL-7409) for LSP support in IntelliJ.
There seems to be some [improvements](https://github.com/rust-lang/llvm/pull/92) coming soon though 
You're assuming a second build environment, Y. What if somebody wants to compile rustc on his own, because he doesn't like downloading binaries? Right now, you'd have to have a rust compiler at hand, chicken-egg problem (or you check out a pre-self hosting version of rust, compile that and repeat that process until you have an up to date compiler - cumbersome). But many systems have a (trusted) c++ compiler preshipped, which they could use to compile rustc via mrustc, breaking the circle.
Mine: [kbgpg](https://crates.io/crates/kbgpg). Allows signing of Git commits and Clojure packages with your [Keybase](https://keybase.io/) key directly.
It even has a bunch of mir optimizations that rustc doesn't have. Neat.
&gt;[podcast] New Rustacean - crates you show know: Rayon. Safe, threaded, parallel code in Rust! Points to the Rocket podcast
how can it seem to be broken if it's really broken?
I hope there is a way to take out all the !#[*] fixes for micro controllers at some point... Also, since the target used for the stm32 is whatever ‚Äúthumbv7...‚Äù target. Does that mean it generates only thumb instructions? Isn‚Äôt that rather limiting?
Amazing work. But reading through the code... what's up with the inconsistent curly braces formating? Is there any pattern I'm not grasping? 
I don't know anything about compiler building or the rust building process, but would it be possible to first use `mrustc` to compile `rustc`, and then use the built `rustc` to compile `cargo`?
Pretty much every instruction has an ARM and Thumb encoding on ARMv7, I don't think this is really limiting.
Is there a good example of how to handle errors when writing an iterator? I've started trying to use something like: struct SomeParser { file: BufReader&lt;File&gt; } impl Iterator for SomeParser { type Item = Result&lt;String&gt;; fn next(&amp;mut self) -&gt; Option&lt;Result&lt;String&gt;&gt; { let mut line = String::new(); self.file.read_line(&amp;mut line)?; // rest omitted ... process line, return result etc. } } This of course fails with: "the `?` operator can only be used in a function that returns `Result` (or another type that implements `std::ops::Try`)". Is the correct approach just to manually match the result of each IO operation and then wrap the result before returning? Is there a helper function that's suitable for this? Similarly, for consuming the iterator, is there a good pattern for iterating until first error? I've still not fully got to grips with the more functional aspects of iterators (map/collect) etc., so not 100% how/if this would be achieved.
Yes, that would be good. I live in US/Central.
Im sorry, but I don‚Äôt think that‚Äôs correct. The whole point of thumb was to use the most common arm instructions since instruction memory was usually very small, but with some limitations since they are only 16-bit (excluding Thumb-2h). For example in memory loads you can only address manual registers r0-r7. You also don‚Äôt get to directly use the CPSR/SPSR registers... the list goes on. http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0068b/ch02s02s09.html
Thanks, I am very new to rust, and I one question I have with regards to making such a mutable binding, is how the lifetime should be managed ? You would neet to ensure that the bound variable does not go out of scope before the query has completed. One way I can think of to address this is to have the bind_mut method on the statement return a new struct with the same lifetime as the statement, and then do an explicit get access on this object in order to retrieved the mutated value. I think this is one way of making what goes on more clear, but I don't know if this is very "idiomatic". What is the proper way to handle the lifetime in this scenario ?
The program is actually a financial application with the web component serving as the interface - think of an intranet line-of-business program. I initially chose python to build the prototype due to its mature web frameworks and simplicity but i found working in a dynamically typed language was not ideal for doing the calculations. I also did not like the deployment story as this application is delivered to the end-user to run, so I would have to use pyinstaller or a similar tool if I wanted to provide a single binary. Pythons speed was also a bit disappointing and using libraries like pandas or numpy helped but increased the complexity of the application unnecessarily. The industry standard is C# but that is windows only and I try not to support vendor lock-in (.net core was announced after I started). Furthermore both of these languages can easily be disassembled back into source and while it's unlikely my clients would take advantage of that it's not unheard of in the industry, from my experience. My final "traditional" option was C++ and being not particularly strong in the language and seeing the unmitigated disaster it could become I opted to give Rust a try. Despite its learning curve and younger libraries Rust has been perfect for my needs. While it is fast and productive I would say the most important characteristic of Rust is it's approachability. I am much more comfortable with the quality of my software when using Rust than I have felt with any other language.
I don't know what you mean by "excluding Thumb-2h". On ARMv7 there any many two-word Thumb instructions (16 + 16), e.g. you could read the CPSR/SPSR register with the [`MRS` instruction](http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0489c/CIHGJHHH.html) which has a Thumb encoding. MRS Rd, CPSR(s=0)/SPSR(s=1) =&gt; 11110011111s1111 1000dddd00000000 e.g. MRS R8, CPSR =&gt; 1111001111101111 1000100000000000 =&gt; F3EF 8800 See also https://stackoverflow.com/questions/28669905/arm-thumb-and-thumb-2-instructions-confusion.
Hi, all. I'm confused with `PhantomData` type. Why do we need it? For me, it feels like some workaround for particular implementation detail in the compiler. 
Sorry, the h was a typo. I didn‚Äôt actually know about Thumb-2 until today, that seems to answer my initial question. Thanks!
Thanks for the clarification. I use a number of crates that are not on crates.io, so I am still susceptible to this particular vulnerability. (Luckily, all those dependencies can be trusted.) 
Fixed.
Cargo requires itself to be able to compile (same as rustc), so I'm using the same cargo clone as was used to compile rustc to compile cargo.
You can take a look at https://github.com/stephank/hyper-staticfile, although I'm not convinced it does what it should. It seems to read the file directly from the event loop, which isn't a good idea. There's also https://docs.rs/tokio-file-unix/0.4.0/tokio_file_unix/struct.File.html, but it doesn't work on Windows and I don't know how to integrate it with `hyper`.
It seems that this is a client issue, and will persist until a newer version of cargo is installed: https://www.reddit.com/r/rust/comments/714bhi/security_advisory_for_cratesio_20170919/dn95st3/ 
See also the issue for reproducible builds: https://github.com/rust-lang/rust/issues/34902
I've been wondering, is there any semantic reason why we couldn't translate to virtual dispatch rather than monomorphizing when compiling with opt-level=0? The end result will certainly be of dreadful quality, but that will probably suffice for a large number of people, and we could push the current default behavior to opt-level=1. We could then have `cargo build` use opt-level=1 and perhaps have `cargo build --quick` for opt-level=0.
&gt; lewton I was actually talking about the ogg crate, but the two crates are related so I'll clarify a bit. Lewton takes care of the vorbis codec. The bulk functionality of the crate is to take in a stream of *packets* and to output decoded audio data. A *packet* is handled by the API as a slice, so there is an API of lewton which only works via slices. The Ogg crate however takes in anything that implements `Read+Seek` and outputs those Ogg packets. There is glue code inside the lewton crate to directly get decoded data for "anything that implements `Read+Seek`". You can use all `Read+Seek` based APIs with buffers only, if you cache the entire file in memory and create a `Cursor` on it. Now to answer your question about why Ogg doesn't just have a buffer based API. The problem is that it would be far more inconvenient to use than a `Read+Seek` based API. With the `Read+Seek` based API, you just pass the result of `File::open`, or `Cursor::new` and you're done. With the other APIs you need to do a lot of manual work. Similar for async users. I want to make using my library feel natural for them. 
Cool, but.. why?
Ah that static file looks like it might do what I'm after! I had no idea about the `Body::pair()` function, and completely missed it when I was looking at hyper's Body struct. Very light on documentation!
Finally had time to work on my style-preserving TOML parser a bit! In the process of adding a real test suite (and discovering quite a few bugs in the process)
The proposed `spawn_daemon` method will allow you to background a future in the new design. edit: What you are describing is the difference between a "hot" future and a "cold" future. future-rs is "cold", your design along with javascript are "hot": they start execution immediately. "hot" futures can be more ergonomic for the general case, which is why they're used in javascript, however, they make other patterns such as cancellation difficult and expensive. Moreover, when you get `async`/`await` syntax hot promises are much harder to optimize because the compiler can't implicitly insert `Future::join` in the right places. In js, let foo = await work(); let bar = await work(); let baz = await moreWork(foo, bar); Would optimally be written: let baz = Promise.all([work(), work()]).then((args) =&gt; moreWork(...args)); Which would use 2 event loop ticks instead of 3 to schedule all of the work. But because the compiler can't know that `work` doesn't potentially modify something bar depends on it so can't implicitly do that. Cold promises on the other hand can be automatically optimized to insert join points exemplified by Haskell's `ApplicitiveDo` extension and the [Haxl](https://github.com/facebook/Haxl) library.
I believe it should help with the problem of traceable builds for Linux distribution packagers. They already have some way to get C/C++ working to their satisfaction, so mrustc would let them get from there to a working rustc: 1. Compile mrustc with $CC 2. Compile bootstrap rustc with mrustc 3. Compile rustc with bootstrap rustc Without something like mrustc, they have to trace rustc back through its history to the point where it was bootstrapped from OCaml or whatever.
Haskell might be overkill. Not sure how much theory you know, but it will take a long time before you 'master' all of Haskell. The most important parts imo are types. Specifically the Iterator type and Option and Result. Haskell will teach you how to use them ( but so will Elm ). So learn how to use them , and after a while, look at their source code. But if the target is Rust , you can always just start with Rust. The book is written for beginners.
I don't like that it seems to block the event loop while reading from disk. A better way would be to use the other crate I linked, or maybe make a thread that reads chunks from disk and sends them over a channel. I don't know how to write that, though.
It's definitely not the Java part. It's faster to edit Java than Rust in IntelliJ, and they're both using he same platform. It's probably something to do with inference, and/or some really obvious algorithmic problem somewhere. I'm leaning towards the latter because it used to be much, much faster...
Cheers!
&gt; wouldn't this make sense to read: &gt; &gt; impl FixedPoint4pt12 : Num {} This is just an objective thing but no it doesn't really make sense to me. I think impl Trait for Type is much more clear. Even if we set aside the fact that the notation you used has been floated for subtyping structs in Rust, and is currently being used as a subtype operator for lifetimes and traits. I implement a trait, then think "I want to implement multiplication for vector". Or I find a trait I want to implement in documentation for a type I have locally available. Whether it's because I've been influence by the existing syntax or not, I don't know. Haskell, who's typeclasses share a lot in common with traits, also work this way: `instance Functor Type where` is how you start an `impl Functor for Type`. I'm glad for the discussion though, thank you. 
I ain't ever heard of a 10-12-9 haiku structure. Bad bot!
Can't you introduce an intermediate function returning `Result&lt;Option&lt;String&gt;&gt;` (so that you can easily use `?` inside it)? Then, if this function is named `f(‚Ä¶)`, you can transform its result into the desired type by doing f(‚Ä¶).map(|a| a.map(Ok)).unwrap_or_else(|e| Some(Err(e)))
How do we request a standardized API for Database and Time?
Our long national nightmare is over!
It seems like async file operations aren't really cross platform at the moment. [memmap](https://github.com/danburkert/memmap-rs) may be an appropriate stop-gap though.
This is why I like having really detailed commit messages that explain the change and the problem. Commit titles like this and a body with barely anything makes for a terrible git log and leaves people more confused than it being helpful.
&gt; Rust doesn't have a header/code separation like C/++. Sorry if this is a silly question and a bit off-topic, but this has been bugging me for a while - won't that also make shipping precompiled libraries harder? I mean, with C/++ you can pretty much just ship a dynamic library and a header and you're good to go, while in Rust AFAIK it's a no-go if you don't have access to the whole source (at least if you're interested in something more than just C-like interface). Or am I wrong? And I just want to note that I know Rust has no stable ABI for now, which might be a part of the problem, but I think it's not the _whole_ problem (or is it? I'm not sure here, either). 
This isn't about requesting new things, it's about building all of the things that were previously requested :)
We had a whole thread on it the other day https://www.reddit.com/r/rust/comments/70aq3b/attackers_are_typosquatting_package_names_in_the/
its much clearer the other way:- matrix ```*``` vector type - Matrix : trait - Mul&lt;vector&gt; method: (self:&amp;Matrix).mul(other:&amp;Vector) using it.. ```let transformed_point = my_matrix * my_vector``` much more coherence; **everything in the same order**. With the current method, you have an annoying flip in the middle. (I don't even need to think about the trait in c++, i just directly think 'matrix * vector', thats best, but if the trait was ordered better, it wouldn't stick out so much but as a compromise how about we allow impl Trait for Type impl Type as Trait .. use whichever is clearer.
&gt; Haskell, who's typeclasses share a lot in common with traits, also work this way: instance Functor Type where is how you start an impl Functor for Type. Haskell is also different to Rust, and clearer: because it doesn't have a separate 'self', when you have a 'multi parameter type class', you can still order the types however you want, e.g in the same order as the args in my 'multiply' example -- multi parameter type-class - e.g. multiply function depending on 2 types, 'out' determined by inputs a,b -- in rust you'd write trait Mul&lt;B&gt; { .. implied A='Self..' handled differently } class Mul a b out |a b -&gt;out where mul::a-&gt;b-&gt;out // Matrix*Vector -&gt; Vector instance ... =&gt; Mul Matrix Vector Vector mul matrix_a vector_b = .... // Matrix*Matrix -&gt; Matrix instance ... =&gt; Mul Matrix Matrix Matrix mul matrix_a matrix_b = .... 
What have you read to try to learn it? The API docs? The nomicon? https://doc.rust-lang.org/nomicon/phantom-data.html
I always wonder what kind of person would dislike downloading binaries, but would happily download, compile, and run a project of hundreds of thousands of lines of source code :p
You'd need to ship docs, as you couldn't just read the header, but other than that, it should work fine. What specifically are you worried about? (Ignoring the ABI thing, which is in fact an issue.)
In my opinion, a sandbox that's full of holes is worse than no sandbox. What you've described to me seems full of holes. I think you're also underestimating the complexity this adds to the build process. Maybe if this were an attack I actually felt were likely, given package signing, name squatting protections, and other low hanging fruit mitigations, I'd be more amenable to the idea.
Memory-mapped files aren't that much better than `read` wrt. blocking the event loop. I would go for that worker thread instead.
Shouldn't that be part of: [`Rust should have 1.0-level crates for essential tasks.`](https://github.com/rust-lang/rust-roadmap/issues/11)? 
&gt; Haskell might be overkill. Not sure how much theory you know, but it will take a long time before you 'master' all of Haskell. Who said anything about mastering all of it? It's true that with Haskell there's *always* more to learn ‚Äî it's a moving target and people are always doing a thousand weird new things with the language and its ever-growing set of extensions. But if you're interested in learning Haskell because you feel like it can enrich your programming life in some way, there's no reason that context should dissuade you. Elm might be the best place to start, it's a lovely language that I prefer to Haskell in Many ways, but there's a bunch of meaty, rewarding stuff to discover in Haskell that is accessible to anyone as long as they aren't attached to the idea that they need to master all of it. This book is an excellent way to learn: http://haskellbook.com Edit: &gt; But if the target is Rust , you can always just start with Rust. The book is written for beginners. This is also true :)
The code in my comment above is from the seastar tutorial: http://docs.seastar-project.org/master/md_doc_tutorial.html I do not know JavaScript inner workings that well and in general do not like the async/await syntax. Will see how it is going to work in Rust. Perhaps the troubles of async/await come from the implementation, and are not inherent to the design.
ADL?
I feel like that was sufficiently explained in the comments here by the author hours before you posted your comment. just an observation.
~~/r/archlinux~~
Most people won't check the source themselves, but the minuscule chance that any given person might look at any given portion of the source (with some probability distribution over what parts of the source are likely to be looked at) could provide a tiny additional disincentive to anyone thinking of inserting a back door. You would need to be sure that any source distribution has the same (or better) hash/signature checks as a binary distribution, though.
My comment still seems to apply: "hot" and "cold" refer to whether the future is automatically scheduled or not. I talk about JavaScript in my post because it's probably the most widely used "hot" futures ecosystem and so the problems with it are well documented and well understood. 
&gt; and then the screen went black-ish I can confirm that's kind of black.
Cool!
In some sense, yes! What I'm trying to say is this: the "impl period", that is, from now until the end of the year, is about *not* adding new work. It's about executing the plans we've been working on all year. That *is* one of the plans, but it's being fulfilled by the Libz Blitz: https://blog.rust-lang.org/2017/05/05/libz-blitz.html which is largely about cleaning up and getting to 1.0 crates that already exist. See the "What crates are we going to focus on?" section in the post.
That'd be the dynamic library?
Let's say there is a generic struct, or a trait, or a macro in the library that I'm interested in. In C++, a generic type would be just a template in the header, I guess, and a macro would also be in a header. Do Rust binaries contain enough information to use things like that from a precompiled lib? Is it something that is or will be a part of the ABI?
So how fast is it?
well, I didn't mean that that the borrow check is the only lint. Rust has a fantastic linting and reporting system built into the compiler itself, which is completely non-optional. Are you saying that *all* lints/checks/etc don't take a significant chunk of time? I guess when doing `--release` mode, the majority is spent in LLVM... mostly because our IR is terrible. That makes sense.
Congrats on issue 200!! üéäüçæüéàüéâ 
That's my impression as well. I plan to go with Gotham once async/await stabilizes and it has static file handling (those are the only things I am interested in for my app). But I haven't researched enough to know for *sure* which way I will go. Also, that's probably a year or so from now so anything can happen.
As long as they're using the same version of the compiler, it should work, in my understanding. See my response to your sibling.
&gt; Do Rust binaries contain enough information to use things like that from a precompiled lib? In my understanding, the rlib metadata is what contains this information, yes. &gt; Is it something that is or will be a part of the ABI? We haven't even yet figured out if and when we want to have a discussion about a stable ABI, let alone know what would be in it.
I'm guessing http://en.cppreference.com/w/cpp/language/adl
Something like that would work, thanks. This seems like it must be a fairly common pattern (i.e. dealing with errors during iteration), mostly wanted to check there wasn't some common/established pattern used.
&gt; Are you saying that all lints/checks/etc don't take a significant chunk of time? Yes, that's correct. Run `-Z time-passes` sometime, and you can see for yourself. 
I'd recommend using [futures-fs](https://crates.io/crates/futures-fs) to do the file reading in a thread pool. This prevents disk access from blocking the event loop. Then, you can either combine that with `Body::pair()`, OR you can just change the generic body type to the `FsReadStream`.
Well, not really. LLVM provides a very limited interface for conveying aliasing rules, the mut-noalias bug is in that interface. However it then computes aliasing information within function bodies itself, which we already know but have no way of conveying to it.
&gt; Rust has a fantastic linting and reporting system built into the compiler itself, which is completely non-optional. Are you saying that all lints/checks/etc don't take a significant chunk of time? GCC/clang have far more lints than Rust. Lints are super fast. I say this as someone who works on clippy, who often checks `-Ztime-passes` to ensure that a new lint does not make linting super slow suddenly. Lints are a fraction, usually less than a second, of compile time.
so much of modern libraries are compile time templates/generics, source makes more sense
&gt; Do Rust binaries contain enough information to use things like that from a precompiled lib? Rust rlibs, yes. Not rust staticlibs. We store the AST of the generic function.
Basically namespace foo { struct Foo{}; template &lt;typename T&gt; auto do_something(T) -&gt; int; } namespace bar { struct Bar {}; template &lt;typename T&gt; auto do_something(T) -&gt; int; auto do_with_foo() -&gt; void { foo::Foo my_foo; do_something(my_foo); // will call foo::do_something, even though bar::do_something is in scope, due to ADL } } Unqualified calls will look for functions in the same namespaces as the arguments.
&gt; I mean, with C/++ you can pretty much just ship a dynamic library and a header and you're good to go, while in Rust AFAIK it's a no-go if you don't have access to the whole source (at least if you're interested in something more than just C-like interface). Or am I wrong? No. Rust metadata (in an rlib) contains everything you need. They convey the types, the interface, and contain the AST of generic/inline-marked functions. When you do `cargo build` `cargo` just invokes `rustc` on each dependency source, individually. So when compiling a crate all `rustc` has for the dependencies are the rlibs, not the source. It works. Rust having no stable metadata is the _whole_ problem. The caveat here is that this won't work for a dynamic library, though in that case you can probably ship a metadata-lib (the thing used for `cargo check`) and a dynlib and the metadata-lib counts as the header.
Precompiled generic code in Rust rlibs can be pre-parsed, pre-typechecked, and potentially even pre-optimized at the MIR level. Pre-built C++ modules could have the same benefits.
Saw "beginner" in title, thinking maybe I can share it to my inexperienced friends, saw "Haskell" in the first note, gives up. 
A formal specification of tokens and grammar, with changelog?
/r/playrust
I totally agree, but it's *hard*. The committer by definition knows everything about the problem and solution, and so doesn't know what other people *don't* know. Plus it's usually something that's been discussed to death in an issue somewhere, on gitter, in IRC, or wherever. And sometimes it's a logical follow-up to a previous commit to fix a bug or make a tweak that was only noticed a few days later. But yes, at least linking to an issue describing the change would be ideal.
Man that did really sound like a good beginner guide for r/rust. Was looking forward to it! :/
&gt; We've already decided that there is no path forward for Rust other than lifetime parameterism Ah, this is news to me. Last I saw there was a lot of discussion about trying to avoid this. Good to know.
I think it should be in the git commit anyways cause it's an immutable history that won't be deleted or lost cause it was in some transitive discussion method like a GitHub issue (what if it fails for instance)? I get it though no one wants to but people should, like documentation. Sean Griffin covered what a good PR should be in his talk [Anatomy of a Great Pull Request](https://www.youtube.com/watch?v=u2xzRUYrsWA).
What? Do you mean Gentoo? Arch is a binary distribution. 
I'm interested in the answer to this, because many things can be `Read`. However, specifically for sending a file there are even more efficient alternatives: [`sendfile`](http://man7.org/linux/man-pages/man2/sendfile.2.html) or [`splice`](http://man7.org/linux/man-pages/man2/splice.2.html) for Linux and [`TransmitFile`](https://msdn.microsoft.com/en-us/library/windows/desktop/ms740565(v=vs.85\).aspx) for Windows. Cross-platform it would probably be necessary to have a more generic fallback. I'm looking forward to the day when we can simply pull the crate that implements this from crates.io :D
would this work better for you? https://play.rust-lang.org/?gist=2c973b0c58058153f0373c391b9eb2d6&amp;version=stable
You could always provide a high-level API (for file based IO, async, etc) on top of a lower-level, buffer based API. Without having such a low-level API, it will likely be difficult to properly integrate it in other software that might not work on files to begin with. Or instead of a Read+Seek abstraction you could just have an API that gets buffers passed, and then returns results. Which among other things could be "please give me Y bytes of data from offset X next". This is one of the main problems many container format and codec libraries in C also have, and which makes it a pain to integrate them in other software.
&gt; There's an RFC and all That's not an RFC. There's some discussion and drafting in there, but nobody has laid out a formal RFC. The reasoning behind why this doesn't work today is laid out in the thread you linked to. Ultimately all that's missing is for someone to write and propose a formal RFC (the draft in that thread uses an older format, and there are new questions about how we teach this that would need to be answered)
That's very interesting. What kind of optimizations?
I was of course referring to the top of the picture which has blue stripes. :)
The library contains a metadata section with all that stuff. I don't think it looks at raw source again at all. e.g. you can link to libstd just fine without the rust-src component.
I hadn't tried turning on incremental compilation in a while. Just tried it on Diesel's codebase after seeing this. On my machine, doing `touch diesel/src/query_builder/insert_statement.rs` (just an arbitrary file I've been touching a lot lately), and then building our integration test suite is 50% faster (82.5s vs 42.5s). Nice!
Iirc it's the edit distance, i.e. how many operations (of a very small set) do I need to do to turn string A into string B.
I'm pretty sure it was settled by the time Mozlando finished (so the end of 2015), and the more we looked at it, the more lifetime parameterism made sense, the only tricky part then was how to enforce it, because you can cause unsoundness from an orthogonal combination of innocent `impl`s.
Not in a way that will allow trait resolution. We have to do this all over the place in Diesel's test suite: let new_stuff: &amp;[_] = &amp;[ ... ]; insert(new_stuff)
I imagine it wouldn't work for methods that aren't object safe. That said, a sufficiently smart compiler‚Ñ¢ could probably translate to virtual dispatch in a significant subset of functions/methods. Might be worth looking into.
You could also try my unpublished [http-file](https://github.com/scottlamb/http-entity) crate. (I need to pick a better name and publish it. It didn't feel right to claim part of the "hyper" namespace as I'm not hyper's author.) It serves the file in chunks from a thread pool and supports byte range serving, conditional GET, and HEAD requests. Edit: now the master branch is based on released hyper 0.11.x and the matching reqwest.
mmap doesn't avoid blocking when accessing the actual bytes, unless you've mlocked the memory range ahead of time. Either way, there's a step that may block. Edit for a bit more info: In particular, accessing the actual memory-mapped bytes will cause a major page fault if they're not in the page cache. You can guarantee they're in the cache ahead of time with mlock, but that call itself will block if the bytes need to be read in. Another caveat of mmap is that your process will get a `SIGBUS` (which typically crashes) if the file is truncated as you're reading it. Also, open can block, and you need to call open before mmap.
Oh cool, I wasn't aware of that crate.
I think it's to help with operator overloading, since operator overloading in C++ requires you to define specially named functions. namespace foo { struct Foo{}; auto operator+(Foo, Foo) -&gt; Foo; auto operator+(int, Foo) -&gt; Foo; auto operator+(Foo, int) -&gt; Foo; struct Bar { auto operator+(Bar) -&gt; Bar; auto operator+(int) -&gt; Bar; }; } auto add_stuff() -&gt; void { foo::Foo my_foo; foo::Bar my_bar; auto a = my_foo + my_foo; // calls foo::operator+(Foo, Foo) found through ADL auto b = my_foo + 1 + my_foo; //foo::operator+(foo::operator+(my_foo, 1), my_foo) auto c = my_bar + my_bar; // foo::Bar::operator+(Bar), not ADL, operator is a member function (method) auto d = 1 + my_bar; //error: no operator+(int, Bar) found, impossible to implement without a free function, since you can't extend types with additional methods } So yeah, it's a well-intentioned feature, but it can really mess you up if you are unlucky. The alternative would be having to define operators in a global scope, or force users to put the operator functions into scope before using them (which is another can of worms since there's no file-scope in C or C++).
Ouch. In your boss defense: if you're the only Rust dev around, there might be noone to take over if you're to leave, while there's plenty of people that can hack PHP. ¬Ø\\_(„ÉÑ)_/¬Ø
I was really surprised to see that the crate of the week is copyleft. It's always seemed like the defacto rule for crates.io is MIT/Apache.
hyper doesn't support sendfile, splice, or TransmitFile. It needs the stream to be chunks of something `&amp;[u8]`, and it does the write calls itself. I'm sure hyper could make an interface change to support them for http, but keep in mind that these aren't useful anyway if you're doing https, as any directly Internet-facing webserver should these days IMO. So I think they'd only be useful if you're using some proxy server such as nginx in front of hyper.
I got the exact same CPU and no performance problems at all, even with big projects. Maybe try another JDK?
Can you suggest one? I don't know my way around Javaland
always nice to have the source for reference this is why game engines eventually moved to licenses where you get access to the source .. think about tracing through in the debugger . Rust wont crash, but it can still panic .. you'll still have logic problems to work through
Yes, that's true -- and all coercions have this trait selection problem. Are you doing so for more than the &amp;array to &amp;slice coercion? If it's just that, I'd probably use `&amp;foo[..]` or `as &amp;[_]`. (Coercions are valid casts.)
Yeah, I'm a jackass. I had [Gentoo is Rice](http://funroll-loops.teurasporsaat.org/) in my head, but for some reason associated it with Arch.
I'm using Oracle JDK 8 update 141 right now. But I guess that's what you're using already?
Interesting! Do you have any examples of how a "buffer based" API would look like? Read+Seek is "buffer based" in some way as well...
Its is, but GMP is an already existing library and LGPL/GPL dual licensed. I guess the crate author chose the LGPL license due to that...
I don't know if I'd recommend Rust as someone's first language, but for someone who already knows the fundementals of programming I think it's definitely not a bad choice! [The second edition of the Rust book](https://doc.rust-lang.org/book/second-edition/) is an excellent starting point. Also, if you're already learning Ruby, you'll probably notice a few parallels in some of the syntax and design - a lot of people who work on Rust are/were members of the Ruby community.
This is exactly what I was planning on building myself. Thank you for pointing this out and saving me the time!
Nice, but I won't be able to call Base::test on a Extended trait object (dynamic / run time dispatch )...
I don't know the project's name, but there is also a rust implementation without llvm. Why not contributing there?
could you implement rust macros in lisp macros in rust macros in..
OCaml/Haskell have been used in a lot of compilers successfully. 
Is it possible to display inferred type annotations and function parameter names as mouse tool tip instead?
Sure, but that's a problem better solved directly (and independently of pre-compiled binaries) rather than by baking header files into your build process. :)
I believe your parent meant: "I am not familiar or skilled in using any languages that are suitable for writing a compiler" not "I am not aware of any other languages that would be suitable"
The Ion shell has a lot of areas that are simple for a beginner to contribute to.
I think they literally meant "don't know any other languages" rather than "don't know *of* any other languages". 
I'm not defending header files, just distributing source. Something to observe here: one thing I like about Rust is using type-parameters more pervasively seems more natural; if you used type-params *everywhere*, the equivalent in C++ would be putting everything in headers (and de-facto unity build)
XDG app dir support was added back on July 5th. When the shell starts, it prints a message that details the location of the init and history files. Typically, that will be `~/.config/ion/initrc` and `~/.local/share/ion/history`. Plugins are also stored in `~/.config/ion/plugins/` at the moment. Support for the app-dir crate on Redox to get app dirs working properly with Redox was just recently added though.
Could this perhaps become a subcommand in rustup itself?
I see, but std can be built without cargo, right? Do you think once you have a cargo the bootstrap is likely to succeed or are there more significant challenges?
Awesome---it's a big deal for a language to have an alternative compiler implementation. I'm wondering whether the RFCs/language manual are enough to reimplement by? Or do you have to refer to behavior in rustc itself? IIRC there's no formal spec document for Rust at the moment.
It would require all generic parameters to be boxed. Once you do that, you don't need the object safety rules as I understand it.
This will always require nightly for the foreseeable future, right? Or are there any plans to make this available on stable?
I noticed Redox is using the `termion` library, and that termion is up to version 1.5.1 now. Any idea what's changed in termion since 1.0? The changelog is way out of date.
Well, not quite over: https://github.com/rust-lang/rust/labels/A-incr-comp
Sorry! I have been programming for a couple of years, I just meant to indicate this was the first time I'd looked at Rust.
Maybe you mean something different, but boxing is how you create a trait object; if it's not object-safe, you can't do that.
&gt; I see, but std can be built without cargo, right? Any Rust code *can* be built without cargo, but even std, by default, uses cargo to build today. I'm not sure how much work it would take to come up with an alternative build.
Are there any ideas on how to access/modify/communicate with the page content from the embedder? Would I need to make some sort of loopback websocket hack to communicate with JS etc? That is kinda essential if this is used to create UIs.
The reference is the closest thing to a spec, and it's not even really a spec, let alone a formal one. Don't forget there are also tons of tests, I'm sure that helps too.
Will it ever be possible to build libservo without it containing a JS engine? So libservo can be used as a HTML/CSS engine, but everything else is executed in Rust? I assume this would be a giant improvement over CEF and a fantastic cross platform GUI engine.
Oh, right! This is an interface that would be too dangerous for C. The short of it is that the signature of `bind_mut` can tell the caller to not touch the bound location until the query object is dead. I'm on mobile now, but I'll throw together a skeleton example once I'm home. If you implement `bind_mut` in safe Rust you can't get this dangerously wrong. Safe rust doesn't allow pointer escapes unless they're protected by external lifetime bounds. I.e. you can't move the mutable reference into the Query structure (not sure Query is the right name) unless the signature of `bind_mut` allows it. Even if you use unsafe Rust, you mostly only need to be careful when unsafe casting of pointers to references. Reference to raw pointer is safe. Reference to raw pointer to C call is no more tricky than C. Raw pointer to reference, *then* you need to understand Rust's pointer system in detail.
Can you turn it off with a feature flag or something? I'm not sure why I'd want to, but I'm sure *someone* would.
What's the recommended way to get a hash in hexadecimal representation, like the rust version hash (git commit hash) or the sha1sum hash? The hash trait and implementations of it return a `[u8]` representation, and the only obvious way I found to convert it was for single `u8`s, so I have to allocate and format each digit individually: let hex = hashslice.iter().map(|c| format!("{:x}", *c)).collect::&lt;String&gt;(); Is this the right way to go about it, or did I miss something? (The [LowerHex doc](https://doc.rust-lang.org/std/fmt/trait.LowerHex.html) also mentions a `FmtWrap&lt;[&amp;u8]&gt;` that it's apparently implemented for, but the link to that is dead and google doesn't turn up any living doc for it either.)
Thank you! Only 56 issues until the next round number! üòÅ
It sure does. On the other hand Rust development isn't sluggish either.
Are you imagining implementing a JS engine in Rust and plugging it into Servo? Just not executing any JS? Note that even parts of the HTML/CSS bits of Servo rely on SpiderMonkey's GC to manage memory.
We'd like to make Servo build on stable Rust and have made some progress on this. Firefox is built with stable Rust, so all of the crates shared by Firefox and Servo are already stable-compatible. Here's a [tracking issue](https://github.com/servo/servo/issues/5286) of unstable features still used by Servo. We meet with the Rust team periodically to figure out which features can be stabilized, and which we should find workarounds for.
There are a good number of nightly features used by servo. I think it is a safe bet for the foreseeable future. $ git grep '#!\[feature' | cut -d ':' -f3 | sort -u - Added checking for alphabetical order for JSON keys and ``#![feature(...)]`` #![feature(aaa)] #![feature(abc)] #![feature(abc, def, ghi)] #![feature(abd, hef)] #![feature(ascii_ctype)] #![feature(box_patterns)] #![feature(box_syntax)] #![feature(box_syntax, plugin, plugin_registrar, rustc_private)] #![feature(cfg_target_feature)] #![feature(conservative_impl_trait)] #![feature(const_fn)] #![feature(core_intrinsics)] #![feature(def)] #![feature(def, ghi, abc)] #![feature(ghi)] #![feature(iterator_step_by)] #![feature(link_args)] #![feature(mpsc_select)] #![feature(nonzero)] #![feature(on_unimplemented)] #![feature(plugin)] #![feature(plugin, test)] #![feature(proc_macro)] #![feature(range_contains)] #![feature(raw)] #![feature(start, core_intrinsics)] #![feature(step_trait)] #![feature(stmt_expr_attributes)] #![feature(try_from)] #![feature(unboxed_closures)] #![feature(unique)] #![feature(untagged_unions)] Some of those are from tests, and aren't real features, but others are hard to remove/replace. Edit: see mbrubeck's reply as well; this comment isn't trying to say that running on stable isn't desired.
I feel like they're imagining not executing any JS period, just having a simple HTML/CSS rendering engine where events (like button presses) could be handled in native Rust code, and Rust code could arbitrarily update the HTML/CSS.
My information is quite old, but as far as I understand you need at minimum something that does DOM memory management even if you don't have the rest of JS engine in place. So something very stripped down should work, but getting competitive performance might be challenging as I imagine SpiderMonkey GC being quite aggressively optimized and difficult to separate from the rest of the engine. The problem is that you'll end up with just a static page then. To get more you'd need some way to interact with the content from Rust code, which I was also asking about in a sibling comment.
If you need upcasting then it is often easier to use enums instead of trait objects http://keepcalmandlearnrust.com/2017/03/polymorphism-in-rust-enum-vs-trait-struct/ 
What I meant is that there is no need for the object safety rules if you require generic parameters to be boxed (not necessarily instances of `Box` but boxed in the more general sense). And you have to if you don't want monomorphization.
I think you're stuck thinking in OOP. Rust doesn't use inheritance as a design pattern, and the usage of traits you're trying to achieve isn't the same as what you do with classes. When you "inherit" traits in reality you're still building a flat hierarchy, so there is no common base class or whatever. When using traits you pick whatever functionality fragments you need for your objects by specifying trait bounds. A more detailed explanation here: https://play.rust-lang.org/?gist=c24021e50f360c062dbf952339bd11a9&amp;version=stable
Why does Diesel look at my database at compile time, and is that a sound design decision? That feels like a scary hack, but it's such a nice and popular project that I feel like I must be missing something.
These APIs aren't in place yet, these requirements will be addressed exhaustively. You'll at the very least be able to * provide content directly instead of having Servo load it from a URL. * query and modify existing content. * expose custom functionality to content as JS functions. This is an area where we're very interested in hearing details about use cases to ensure we're making the right design decisions.
Yep. I believe you can turn off the type annotations and function parameters with a preference for the Rust plugin. e.g. "Show local variable type hints". Then you can hover while holding ‚åò (on Mac) to see the type.
I've had https://github.com/rust-lang/rfcs/issues/1916 open since February but there's been no movement on it. I'd have written the RFC myself by now but I've kind of forgotten. I don't know when RFCs close down for the impl period though.
Completely agree, most people do not realize how the history of a project might go. The only thing a code repo mantains is the code repo and its history, everything else will go the way of Ozymandias. This is doubly important with a compiler, where decisions may have very obscure reasoning and edgecases and you do not want repeating of mistakes nor promoting of cargo cults.
I see. As mentioned, we still would need to include SpiderMonkey for its GC.
It doesn't necessarily need to look at the production database, you could give it an empty database with the same schema instead. I don't see any harm in that.
Some of these aren't actually used or necessary anymore. I've submitted a [pull request to remove them](https://github.com/servo/servo/pull/18579).
Rust is the most learnable optimized system-level language because the concepts of pointer ownership, aliasing, and who-frees-what are so well formalized. Jump straight in, maybe some Go first if Rust is overwhelming. Haskell is a great mind-broadening experience but it's pretty dang heady. I would almost consider Ruby dead. It's fun and kinda crazy, but the performance disadvantage buggyness of dynamic typing just drives me up the wall these days.
I found OCaml helpful (by way of O'Reilly's Real World OCaml), for helping me get the hang of working with a solid type system. Learning OCaml helped me figure that stuff out before tackling the borrow checker and manual memory management. I don't know if you'll need that or not. One general suggestion: Use clippy. It's not just a linter, it's your mentor. 
From what I remember, the HTML spec requires the DOM GC to be the same as the Javascript GC.
Why is SpiderMokey used for GC in Servo? That really sounds unintuitive to me. Doesn't that fight against Rust's non-GC practices and conventions. Or am I seeing this wrong? 
/r/nixos much? Yes, NixOS can use trusted binary channels, but I always think it's more funny to build the thing from sources.
My use case is to be able to pratically do anything you can do in JS (scrolling, adding elements for hints, ‚Ä¶) for my web browser [titanium](https://github.com/antoyo/titanium). Also, having something to handle arbitrary communication between the web process and the UI process would be nice, even though this might fall outside the scope of this.
I'm not sure why you'd want to share anything at the AST level. You could get much of the interoperability you describe by defining an ABI (even just one internal to a single compiler version) that includes namespaces and a way to map or convert between pointer types. Beyond that you just need a shared backend.
I think it has to be at the AST level because of generic programming. ABI inter-operability isn't enough when you're throwing templated/generic abstractions around (collection-classes &amp; smart pointers). I think you need to be able to interpret and swap rust/c++ 'views' of the same ideas , and in turn allow generic code that actually takes those as arguments to propagate them internally
Templates/generics are indeed an interesting case. I still think you could fit those into the ABI along with a way to request the appropriate frontend instantiate something for you. Trying to build a common structure to represent Rust and C++ syntax just seems like overkill.
I think the clear next step is to compile this to WebAssembly so we can run Servo inside of Chrome. /s
That is sadly incorrect. Take `u8` and `u64`, both of which implement `Eq`. But you can't do `let boxed_u8 : Box&lt;Eq&gt; = Box::new(5u8); let boxed_u64: Box&lt;Eq&gt; = Box::new(10u64); boxed_u8 == boxed_u64`, because of the obvious reasons.
Why? Javascript needs to hold references to DOM nodes, and DOM nodes hold references to each other as well as some Javascript values. Even if you do use different GCs for DOM/Javascript, they're going to be so intertwined you may as well call them the same thing.
It's only used to manage DOM nodes and Javascript values, since the DOM is completely designed around manipulation from GCed languages.
Yes, think this will be the way to go for me. Thanks.
No need to apologize fellow Haskeller :D Good luck on your ride with Rust!
The Linux kernel gained support for HTTPS data framing and encryption recently, so in fact that does work (if you're okay with only working on very new kernels...) You just need a library that properly handles the session setup and other control messages the kernel doesn't handle. 
&gt; Trying to build a common structure to represent Rust and C++ syntax just seems like overkill. or getting ahead of the curve: eventually C++ will get constrained templates, and I'm sure even ADTs eventually. recently Rust gained Unions (and I've seen talk of wanting 'thin-pointers' i.e. embedded vtables for some use-cases) One way to look at it... you can do similar things in both languages, it's just they have different 'shortcuts' inbuilt. (e.g. yes we can hack embedded vtables into Rust). we can do things close to overloading in Rust, rolling traits with type-params anyway.. I did admit 'it would be very difficult' (and maybe not even possible, but if I did have the ability to slow external time down to spend a few years on it myself.. I'd start out optimistically and work through each problem - I'm not sure it's provably impossible from what I've seen.. just extremely fidly)
Sorry, I don't follow. The boxing I'm talking about would not be visible to the type system, it's just a code generation strategy to make all values the same size (a pointer) so that generated code can be polymorphic.
I'm not expert on standards, but typically they never require this at the implementation level. It's rather that it has to look or act this way, even if it's doing something different under the hood. I would expect the requirement is only from a logical point of view. That logically speaking, all DOM elements on the page should act as though they are JS objects allocated and owned in the JS environment. Acting like that doesn't mean it has to be that way.
&gt; eventually C++ will get constrained templates If by this you mean concepts, I doubt it. They backed off of full concepts years ago and are only planning on concepts-lite. But even then, there are too many differences for a shared AST to be worth it. Just leave the AST as what it is - syntax - and build the interop one level lower where it doesn't have to deal with it. This would be more future-proof as well- neither language's AST would be at all constrained by the other's.
Yeah I've been using Haskell in production for like two years now and I keep learning new stuff.
That is a good point, if the code type-checks with normal generics, virtualization shouldn't be able to introduce problems. I stand corrected :)
&gt; They backed off of full concepts years ago and are only planning on concepts-lite. Perhaps an experimental implementation would push things along. When we have a palette of features demonstrated in 2 different places, if we could combine them , it might accelerate cross pollination. and there's still many things from C++ that I'd like in Rust. &gt; Just leave the AST as what it is - syntax, perhaps I mean the AST and a layer down aswell, but it is decoupled from syntax.. e.g. we could imagine 'what C++ would be like with Tagged-Unions and pointer lifetimes' by making a working AST (and rest of compiler) without having settled on exactly what that should look like syntactically (e.g. try it out with an experimental syntax before making formal proposals) &gt;neither language's AST would be at all constrained by the other's. the idea of a superset would be that they don't interfere: we would obviously have to pad out the naming etc to achieve that (i guess , for example, extending the picture of 'const' vs 'mut', but i think we already have some complexity like this in the transition from safe code unsafe raw pointers)
Sounds interesting! I have sent you an email.
[Code here.](https://play.rust-lang.org/?version=stable&amp;mode=debug) Walking through the lifetime stuff: `struct Query&lt;'querying&gt;` declares the lifetime parameter `'querying` for the first time. It's actually a kind of *generic type parameter*. Values can't move between types unless the types are compatible. Same rule as usual, but Rust applies it to pointer-escape analysis. Wherever you work with borrowed data (and safe pointers) the compiler *invents* a new type to mark the pointers. I call these lifetypes. Within the definition of `struct Query` there is the reference type `&amp;'querying mut i32`. This means that whenever you work with a `Query` the compiler *may* associate it with a lifetype, and this lifetype must be compatible with any pointer value contained in a `Query` value. So far that's all the compiler knows. I read `impl&lt;'querying&gt; Query&lt;'querying&gt;` as "implement Query whenever querying". The first mention declares a new lifetime parameter. Mathematically, it's a *universal* quantifier. "For any lifetime `'querying`, associate these methods with the type `Query&lt;'querying&gt;`." Yes, this is more verbose than necessary. Rust is experimenting with ways to make these declarations shorter. `'querying` anywhere within the `impl` block refers back to this parameter. `new` should be self-explanatory. `query` does some safe pointer arithmetic that's interesting. `bind_mut` uses the `'querying` lifetime parameter again. If we take it away (at line 18), we get a pointer escape error &gt; error[E0495]: cannot infer an appropriate lifetime for automatic coercion due to conflicting requirements Paraphrased, it says: "I have no guarantee that `p_mut` will be valid after this function returns, but it must escape ("be assignable") to a location which has lifetype `'querying`. This is fixed by exposing the requirement as part of the signature `&amp;'querying mut i32`. `query` does safe pointer arithmetic. And oops... I brain-glitched on the first write by forgetting that `match` can operate on lvalues. So [look at this, it's cleaner](https://play.rust-lang.org/?gist=35c6dae0282fd0737749274e10aaf2e8&amp;version=stable) There are two pointer arithmetic operations. The first is an offset: `*self` (location of the Query) is transformed to `self.param` (location of one field of the structure). The second checks enum variant and offsets. The match arm `Some(ref mut p_mut)` is a destructure: it takes the lvalue and if the variant matches binds a unique reference (`ref mut`) to the name `p_mut`. If you don't say `ref mut`, it'll try to grab the contents of `Some(_)` by value. This isn't possible because `&amp;mut _` can't be copied. The compiler error is `cannot move out of borrowed content` with `hint: to prevent move, use ref p_mut or ref mut p_mut`. This ends up being a pointer to pointer. `p_mut` points to the `&amp;'querying mut i32` inside `Some` located at `.param` inside `*self`. Deref twice to access the location of the parameter.
Exactly. Since using the rug crate requires linking to GMP et al., it would be misleading to license rug with a permissive license. Crate users would still be linking to a copyleft license, and they might miss that.
It's actually there for some rather subtle details of unsafe Drop and thinking about lifetimes contained in lifetimes. Crazy stuff like that.
It's set up lazily, and will be customizable, so if you don't want the default one you can avoid it entirely.
Sweet! I was thinking we need a C++ compiler written in Rust. But this is actually better. Maybe it could lead to a way for C++ folks to drop some Rust into their codebases.
Ahhh I see now too. Thanks /u/MalenaErnman!
[Wadja da boolya ra 1.9 megabytes](http://www.boyter.org/wp-content/uploads/2016/05/ChnulxvW0AEUs1J.jpg-large.jpg)
The lifetimes of DOM objects and pretty much anything else that touches (or is touched by) JavaScript is deeply tied to JS. The reference counted objects need to correspond with JavaScript, such as serving as GC roots for any JS objects and being kept alive by any JS objects that hold references. Instead of having two shared ownership schemes with a corresponding impedance mismatch, it's nicer to have just one.
&gt; I notice that my disk does a whole lot of thrashing when I boot up. I have a lot of stuff that gets loaded into memory every time I boot, like X11, ion2, Firefox, Eterm, Thunderbird, etc. It seems to me that putting all of the files necessary to those apps in a contiguous section on the disk and loading that into memory in one shot would be a whole lot faster. Is there a way to do this? Is it stupid? That was funny until - a) various distros (and Windows) actually started doing something about that symptom - b) SSDs made it kinda moot point (though read-ahead does still help)
I was thinking about this, I'd consider it the same lineage? But still distinct, so I could see it being the 2nd. But yeah, `mrustc` looks like the second Rust compiler or the first third party implementation? 
I meant my comment more as a joke than anything, but definitely mrustc is the first third-party impl!
The compiler is free to shrink lifetimes to make them match. In this case, it's probably shrinking the lifetime of `string2` to match that of `string1.as_str()`. Incidentally, you can just [use `&amp;string1` instead of `string1.as_str()`](https://doc.rust-lang.org/book/second-edition/ch15-02-deref.html#implicit-deref-coercions-with-functions-and-methods).
That is a great use case, and one that we very much want to support. I'm not entirely sure what you mean by "arbitrary communication". If you mean JS communicating with the UI then yes, we plan to support that by allowing the embedder to install functions in JS that are backed by Rust functions. Note that the embedding API itself doesn't create a different process for Servo, so there aren't different processes for web and UI by default. Running Servo in a fully sandboxed process with all I/O delegated to the embedding application is explicitly a goal, though.
wait, i thought if you have one generic life time, the output life type must be the longest of all input life time? For example this will run into error fn main() { let string1 = String::from("normal"); { let string2 = String::from("normal"); let result = longest(string1.as_str(), string2.as_str()); println!("The longest string is {}", result); } } fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str { if x.len() &gt; y.len() { x } else { y } } But the problem is, I don't understand why the following code will not run into error. fn main() { let string1 = String::from("normal"); { let string2 = "superlonggggggg"; let result = longest(string1.as_str(), string2); println!("The longest string is {}", result); } } fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str { if x.len() &gt; y.len() { x } else { y } }
&gt; For example &gt; &gt; &gt; &gt; this will run into error No it doesn't.
hmm, but I did get error 122 | result = longest(string1.as_str(), string2.as_str()); | ------- borrow occurs here 123 | } | ^ `string2` dropped here while still borrowed I must be missing something.
I don't know the spec, but there are IIRC old versions of IE that had two GCs and you could end up with JS &lt;=&gt; DOM reference cycles that would not be collected.
Did you just out-RIIR the Rust Evangelical Strikeforce?
The code you posted is not 123 lines long. If you post a piece of code to show a problem, and it's not the original code, you *need to check that the problem still exists.*
[related](https://github.com/sourcelair/xterm.js/pull/938)
this solves the trusting trust problem, right? :D pretty cool!
ok, that is fair, so I delete all the other code and here are the remaining code fn main() { // This will compile and run successfully let string1 = String::from("normal"); let result; { let string2 = "super long"; result = longest(string1.as_str(), string2); println!("The longest string is {}", result); } println!("The longest string is {}", result); // This will NOT compile // let string1 = String::from("loio"); // let result; // { // let string2 = String::from("xyz"); // result = longest(string1.as_str(), string2.as_str()); // } // println!("The longest string is {}", result); } fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str { if x.len() &gt; y.len() { x } else { y } } The commented out part will not compile.
That's because `result` outlives `string2`. You can't have a pointer to something that might not exist. In the un-commented part, `string2` is a string literal, which lives forever.
but why is there a discrepancy dependent on the type of `string2` ? If `string2` is slice it will run into error, if it is not slice but rather `str` it will not run into error.
&gt; I totally agree, but it's hard. Yeah, definitely, this is one of (the many) places where code review should step in, because the reviewer is usually more experienced than the committer (at least, more experienced on that particular project) and also a step or two removed. The latter means that they either may need the motivation themselves, or isn't so deep in the solution and so can see the big picture more easily.
I think we're mostly on the same page, but I do think that the `borrowed`/`lexical` distinction is not as clear as you think. For example, references are in fact objects whose ownership can be passed around: fn move_owned_recurively&lt;A&gt;(a : A, times : usize) -&gt; A { if times == 0 { a } else { move_owned_recurively(a, times - 1) } } fn move_mut_reference() { let mut integer = 35; move_owned_recurively(&amp;mut integer, 6); integer -= 3; } fn copy_value_recursively&lt;A&gt;(a : A, times : usize) where A : Copy { if times &gt; 0 { copy_value_recursively(a, times - 2); copy_value_recursively(a, times - 1); } } fn copy_immut_reference() { let mut integer = 35; copy_value_recursively(&amp;integer, 6); integer -= 3; } Rust doesn't care too much about references being special outside of the act of borrowing (which creates them) and their expiration (which ends the borrow). Once the reference exists, and until it expires, it can be passed around like any other value (and non-mutable references implement copy). In fact I'm pretty sure you can make a `FakeBorrow&lt;'a, T&gt;{PhantomData&lt;&amp;'a T&gt;}` with the appropriate constructor and it behaves fundamentally the same as an actual reference. So from that perspective, once the borrow happens, it is a `lexical`-ly managed value. You can try to use a special allocator for `borrowed`, or you can provide a syntax-level way to not care about the allocator type of the value being referenced. Which one makes more sense seems like an implementation question (although I think it's useful to think about data structures with explicit lifetimes and whether they can hold a reference to a GC'ed object or not).
Because the type is absolutely critical. In the first example, it's a string literal. It's stored in the binary itself. It lives forever, so it can have any lifetime. The compiler can choose the lifetime of `string1`, and everything is fine. In the second, it's a dynamically allocated `String`. *It doesn't exist after the closing brace*. Once it goes out of scope, it gets deallocated. If it was possible to store a pointer to it after that moment, the pointer would be invalid, and Rust won't allow that to happen.
the string literal is technically `&amp;'static str`, which means it has infinite lifetime, since it is just stored in the binary. If you created a string slice with a smaller lifetime, like when you create the `String` object and then create a slice into that `String`, the slice cannot outlive the `String` in memory.
Why didn't you use Rust? It provides zero-cost abstractions, guaranteed memory safety, efficient C bindings and fearless concurrency. You should look into learning Rust at https://www.rust-lang.org/en-US/ today! :)
Apart from making all of the contents of the `Node` in cells (thus making it so your `calculate` function able to be called with `&amp;self` and solve the mutable aliasing issue), you could store the `interface` as a `Rc&lt;Cell&lt;T&gt;&gt;` if you're ok with the performance hit.
Unfortunately that's exactly what I'm trying to avoid. I ran some benchmarks and for the number of times that this is going to need to be called it's too slow.
Try converting an algebra problem to the language of your choice. For some, C or C++ might feel better for them than something like Rust b/c Rust has type system, decimal conversion issues, casting etc. Algebra -&gt; to the language of your choice usually will tell you what your language is
I can't wait to compile my browser in-a-browser in my browser's browser's terminal. It's the inevitable [birth and death of JavaScript](https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript).
Anything's possible, but I'm not sure it would be appropriate; it's quite a different model to the rest of rustup. Just writing the documentation to explain how this subcommand relates to all the other subcommands feels a bit daunting. But I guess there's no point worrying before I've even written the thing.
Qt was written in C++, was it not?
I've tried using FsReadStream but seem to be getting stuck on some weird type issue: let fspool = FsPool::new(num_cpus::get()); let file = fspool.read(path) .map(|bytes| { Ok(hyper::Chunk::from(bytes)) }); let (tx, rx) = hyper::Body::pair(); tx.send_all(file); While I think this should work OK, there is a type mismatch I have no idea how to resolve: error[E0271]: type mismatch resolving `&lt;futures::stream::Map&lt;futures_fs::FsReadStream, [closure@src/front.rs:74:18: 76:14]&gt; as futures::Stream&gt;::Error == futures::sync::mpsc::SendError&lt;std::result::Result&lt;hyper::Chunk, hyper::Error&gt;&gt;` --&gt; src/front.rs:80:12 | 80 | tx.send_all(file); | ^^^^^^^^ expected struct `std::io::Error`, found struct `futures::sync::mpsc::SendError` | = note: expected type `std::io::Error` found type `futures::sync::mpsc::SendError&lt;std::result::Result&lt;hyper::Chunk, hyper::Error&gt;&gt;` error: aborting due to previous error **Edit**: Changing the SendError struct in [futures/mpsc/mod.rs](https://github.com/alexcrichton/futures-rs/blob/master/src/sync/mpsc/mod.rs#L137) to have a public struct member, and then casting the err type works. I don't think this is the correct approach though but I've raised an [issue](https://github.com/alexcrichton/futures-rs/issues/587) on futures anyway 
How are you liking the `abc` feature? I personally like it a lot better than `def`, and hope it gets stabilized soon. Possibly alongside `ghi` as they complement each other quite well.
I think we may have different meanings for "lexical", which could be tripping us up in seeing eye-to-eye. You correctly point out that move semantics can apply to mutable borrowed references. I agree. Move semantics apply *whenever* we want to exclusively restrict a certain kind of object access to only one alias. Thus, it also applies to aliases of any allocator type (including runtime!) that use the unique permission. So move semantics understood correctly has to with restricting aliasing based on the alias's specification of allocator type and permission type. Certain aliasing combinations are forbidden, some move and some copy. That is the compiler's typing system at play, coordinating how aliasing takes place. In my paper, all aliases of every allocator type are lexical in the broad sense of the word, their lifetime is bound to the lexical block they are declared within. All aliases that are parameters or local variables are effectively copied pointers on the execution stack, from the point of view of the generated code. This broader meaning for lexical applies to all aliases across all allocator types. In my paper, I describe allocator type as a very specific compiler mechanism. The allocator type determines, among other things, how the compiler handles four key events: allocation, free, aliasing and de-aliasing. What I have called the "lexical" allocator type behaves just like Rust's owner aliases: * Allocates the object from the heap without any runtime bookkeeping metadata. * Frees the object back to the heap * Forces aliasing to be a move, making the alias inactive * De-aliasing frees the object if the alias is still active Other allocator types, such as RC and Tracing GC, handle these events differently, as described in the paper. Now let's look at these four events from the perspective of a borrowed reference: * Never allocates an object * Never frees an object * Allows copy semantics (unless permissions dictate otherwise), which means the alias is still active * Does nothing when de-aliasing. For all four events, the compiler does effectively nothing for borrowed references. That is why I say the borrowed reference is very much like a `None` allocator type. In this description, please notice that I am echoing what you said when you pointed out that Rust does treat borrowed references differently when borrowing (aliasing) and their expiration (de-aliasing). So, when I talk about the `lexical` **allocator type**, I am most emphatically speaking about a specific set of compiler behaviors for those four events which are different than for the runtime allocators and different from how borrowed references work. In the context of allocator types, I am not using the word lexical in any broader sense than this. Here is a Rust-centric way of understanding allocator types: Rust makes a very useful distinction between owner and borrowed aliases. It distinguishes them both syntactically and in terms of specific compiler behaviors. In my paper, I call this distinction "allocator types", I call Rust's owner alias mechanism the "lexical allocator type". I call Rust's borrowed alias mechanism the "borrowed allocator type". I am then adding to the ranks of allocator types things like "rc allocator type", "tgc allocator type", and so on. I state that all these added allocator types are also owners, in that they too can be borrowed from (in Rust's sense of borrowed and as described by the bullets above). Any time I borrow an alias from *any* alias using this mechanism, the allocator type is `borrowed`, meaning it exhibits the four "nothing" behaviors highlighted above (and also is subject to the borrow checker's lifetime dependencies). That is why I call the `borrowed` allocator type the "mixing pot" that forgets how the object was allocated and helps us avoid parametric polymorphism! So, I am guessing the confusion over whether borrowed aliases are lexical revolves around the meaning we give to lexical: a broader meaning, as I started with, or the narrower meaning as a specifically named allocator type which operates identically to Rust's owner aliases (but differently from other allocator types, including borrowed). The kind of borrowing you correctly proposed to me, wrapping one runtime allocator reference in a structure owned by another runtime allocator, is not the same `borrowed` mechanism I have described above, nor the one baked into Rust using '&amp;'. Your mechanism is one that leverages what I already described in a way I had not foreseen. And I thank you for that. Does clarifying the different meanings for lexical help bring us together? All aliases are indeed lexically managed, in the broad sense of the word, but `lexical` allocator type is a specific type of alias that operates exactly like Rust's owner aliases. 
You can change function to accept reference and then use `&amp;*` incantation to apply `Deref` trait: fn f&lt;T: A&gt;(x: &amp;T) -&gt; bool { ... } f(&amp;*arc_d) If you don't want to deal with explicit `&amp;T` you may do`impl&lt;'a, T: A&gt; A for &amp;'a T {..}`, but `&amp;*` will still have to be used. UPD: If you want to be more explicit you also can write `arc_d.deref()` instead of `&amp;*`.
`hef` has some pretty major soundness holes ATM, though, so I can't imagine it stabilizing any time soon (at least not without a major reduction in scope).
Great post with plenty of thought to consider. I don't think one really ever masters a computer language, any more than one masters an oral. There's always a set of moving goal posts somewhere! I have some of the theory but not much and it's a long ways back (graduated last century!). I have degrees in what are now called STEM subjects BTW, not CS - most of which is now probably considered as GCSE. Happy to learn, and it's not like I'm doing this under time pressure. FP intrigues me and, yes, my interest is understanding the/a type system. Perhaps I could try to ask my question another way: where has the major evolution in computer languages (generality) been in the last two decades or so? Then I can make a judgement on how to go about it. Thank-you again.
Great post with plenty of thought to consider. I don't think one really ever masters a computer language, any more than one masters an oral. There's always a set of moving goal posts somewhere! I have some of the theory but not much and it's a long ways back (graduated last century!). Happy to learn, and it's not like I'm doing this under time pressure. FP intrigues me.
The impl period has already started. I wonder if that even needs an RFC though; they might just take a PR.
I see. Yeah I think at this point the distinction is pretty much a matter of definitions. Certainly `lexical`-as-`Box` is very different from what I had in mind when talking about the lexical allocator (which, if anything, was more of the lives-on-the-stack kind of allocation). At this point the exact labels matter much less than how they behave and interact.
I thought that was going to get a little rant-y! Respect for pulling it back! I'm (another) one but waiting for the print edition of Haskell book. Seems like the process caught a bug a while ago. I'm curious c. Elm, now you two have mentioned it, but then I never have done anything the right way! That's why I was into C when trading floors really were staffed with barrow-boys from where I grew up.
Will OpenGl be the only option or is it just for now?
Learned nothing getting it right. If I had a quid for every time I rewrote this same little Ruby script..! I know you don't have that luxury.
I don't blame you at all on this. I learn weird stuff with Haskell and trying to write a have rust ffi lib. Because I'm forced to I learn. That luxury is not bestowed on everyone, not sure everyone have the time to learn it find out all that.
I figured Rust over modern C because I'd rather have fun than dedicate significant time to coding for safety. Perhaps that's the wrong attitude/view? My formative years were spent breaking the copy protection on 300-1200 baud cassette tape distributed games (Acorn Atom -&gt; BBC micro); guaranteed far more fun than the game itself. Bastards! I enjoyed your comment about Ruby cum Rust! üòé. Made me smile quite a lot - I appreciate the insight. Toyed with Crystal rather than Ruby. I needed to have a scripting language to administer, so.. Python my point of view, playing on Exherbo Linux (think: Gentoo redesigned in generality), has been a pain. Staying well clear - even if I do have gross of Pis and clones waiting for me to build a heating system!
Thank-you. Very succinct expansion of Rust. The GC put me off Go. (Not that I really know what I'm talking about!) Rust looked cleaner; I couldn't personally imagine a GC in Linus' kernel for example. I feel rather intimidated by Rust in a way that Haskell doesn't. Seems to be the low level habitat (threads etc, race conditions, and passing stuff between them vs learning pure/applied maths if I can hack it still). I'm not likely to write anything big. Ruby is just nicer shell scripting to me. I'm just hitting that point now where I've want to create Objects that mimic fixed types. Asserts everywhere. Tells me it's time to try something new. 
Exactly. Thank you again for a very helpful conversation.
&gt;Make sure you have a redox toolchain (x86_64-unknown-redox-gcc). Any chance I can get this to compile on aarch64?
Exactly that. I could have used another language, but that would have required learning it (for a probably 40-50k line project), and would have increased the barrier to use (because now that language's compiler would be needed)
Sorry for the dumb question: I couldn't figure out whether you were aiming that comment about Rust or Haskell. My bad. I guessed Haskell. I probably need it! I have noticed that quite a few Haskell people use that method to get a handle on it. Seems quite obvious when lurking with Twitter's Haskellers too. Will bear in mind. Thank-you. There's a live coding YouTube of someone starting the basics of a chess game. Only two videos (which stop before it gets scary) but I got an amuse bouche for Haskell from them. Took me ages to figure out how the code was doing the simplest thing like layout off the pieces. Couldn't get over quite how elegant it is to write. It's quite beautiful. I'm not making good use of linters yet. Could improve my technique/style no end. Another LPT - you've been very practically helpful! Thank-you.
&gt; #![feature(def)] &gt; #![feature(def, ghi, abc)] &gt; #![feature(ghi)] what do these do, exactly?
I never take a job without an exit strategy, either they fire me or I fire them when it stops being fun. No good deed goes unpunished. tl;dr I hear you, large.
Those appear in a file that's used as test input for a style linter.
For those interested in that, my idea was to just port the Rust compiler code directly to C or some other language. Especially one with a lot of compilers. BASIC‚Äôs and Scheme's are the easiest if you want diversity in implementation and jurisdiction. Alternatively, a Forth, Small C, Tcl, or Oberon if aiming for something one can homebrew a compiler or interpreter for. Far as mathematically-verified compilers (i.e. certifying compilers), I‚Äôd hand-convert it to Clight to use CompCert or a low IR of CakeML‚Äôs compiler to use that. Then, if the Rust code is correct and the new source is equivalent, then the binary is likely correct... maybe more so than original since optimizations won't mess it up. Aside from Karger-Thompson attack, CSmith-style testing comparing output of reference version and twin done through certified compiler could detect problems in reference compiler where its transformations (esp optimizations) broke it. rain1 and I got a lot more tools for bootstrapping and defeating Karger's compiler-compiler attack listed here: https://bootstrapping.miraheze.org/wiki/Main_Page
You want /r/playrust buddy 
This problem seems to come up for many beginners, and I'm trying to think through why this is the case. When using a garbage collected language, memory is freed after all references, so the lifetime of the memory allocation is until the last reference either gets popped off of the stack or is itself garbage collected from the heap In Rust, lifetimes are the exact reverse: the lifetime of memory is fixed, and all lifetimes of references to the memory must be shorter (in safe Rust, anyways). I think there's this expectation in some developers that the lifetime of the memory would be extended to the lifetime of the reference, rather than the 'dropped while borrowed error' compiler error, because the 'lifetimes much match'. This is why I think calling `'a` a lifetime is horribly confusing because the term is overloaded with the how long memory (on the stack) is in scope. It's really a lifetime constraint. 
So one would be able to manipulate the DOM and implement events in Rust? Would it have to go through some sort of JS bridge? As in my other comment, what I would see as an amazing value proposition is having a GUI layer that is now slowed down by too much JS. Being able to write a well performing cross platform GUI app (desktop and mobile) in HTML/CSS/Rust would be the Rust killer app. It would bring a huge amount of people to the platform, as there is a very large need in the industry for it. Right now companies either have separate teams for various platforms because they care about having an app that runs well, or they use Chromium/React native and convince themselves the user experience is not that bad.
oof
&gt; Had extensive experience in assembly on multiple processors way (way way) back when. Rust is much like C in that it abstracts away many of the processor specifics. So you'll be doing a lot of the same stuff, but it's definitely an abstraction. &gt; IYHO, do I need an extra stop (another precursor language)? Probably not. Rust is quite ergonomic, and I learned it with only a background in Python and Haskell. &gt; What would you say were the most important concepts I should pay attention to when learning (I hope to tackle concurrency for the first time ever.)? Type safety and the type system! Mostly because I'm guessing your background there is less solid. Especially how the type system helps with safe, low-level concurrency. 
&gt; Haskell might be overkill. Not sure how much theory you know, but it will take a long time before you 'master' all of Haskell. It's a very expressive language, though definitely slower than Rust. It complements Rust pretty well. 
Huh. TIL. Found [this blog entry](https://blog.filippo.io/playing-with-kernel-tls-in-linux-4-13-and-go/) discussing it. Apparently it's entirely for the benefit of sendfile (and presumably also splice).
I... honestly would love to see this
KISS - declare your modules in main.rs as long as it is sufficient.
Let's transpile chrome to JavaScript.
It sounds like you want your function to accept a type R where `R: Borrow&lt;T&gt;`. The example they give sounds exactly like what you're trying to do. And `Arc&lt;T&gt;: Borrow&lt;T&gt;` like you'd hope. use std::borrow::Borrow; fn check&lt;T: Borrow&lt;str&gt;&gt;(s: T) { assert_eq!("Hello", s.borrow()); } let s = "Hello".to_string(); check(s); let s = "Hello"; check(s); [Here's the docs](https://doc.rust-lang.org/std/borrow/trait.Borrow.html)
I like putting stuff in lib because I tend to build little tools and whatnot using parts of my application for manual testing or whatever. I guess that falls under "as long as it is sufficient" though.
No, it doesn't. Diverse Double Compilation (the solution to the Trusting Trust attack) requires a trusted compiler. On what evidence do you trust your C++ compiler used to compile mrustc?
It does not. Firefox uses a CC for the DOM. (This has both advantages and disadvantages)
No, Arc and Rc would not be enough, DOM objects often have cycles. We could use a CC and manually break cycles but this quickly gets tedious when you have stuff like callback closures which close the loop between the DOM and JS. ---- I don't see what Gecko has anything to do with this. Servo uses Spidermonkey for its JS engine, we don't have our own. As a part of that we use the JS GC to GC DOM objects, because it's convenient and has its benefits.
The DOM needs to be GCd, that's how JavaScript works. And DOM objects are tied to JS objects anyway, so they get managed by the GC as a unit which is cleaner.
On the basis that a trusting trust attack in a C++ compiler designed to insert an attack into mrustc to insert an attack into rustc would be beyond astronomically implausible.
I can compile mrustc with both gcc and clang
Ah, so DOM element that are contained in something like `RefCell&lt;Rc&lt;Node&gt;&gt;` So, even if the DOM element is detached from the Document that doesn't really goes out of scope since the Javascript code might have to put it back somewhere in the Document. In a nutshell, is this the reason why the GC is still needed? 
The idea is to write a compiler that does everything (from source through to codegen). Sure it would be faster to convert existing MIR into C, but that wouldn't be as satisfying (or as useful)
So, this is the signature of the function you are calling: `fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str` And this is the actual call: `let result = longest(string1.as_str(), string2);` First and the second parameters in the function signature having the same lifetime does not mean that the two variables you are calling the function with need to live in exactly the same scope. It only signals to the compiler (and to the other people looking at your code) that the result variable (that has that same lifetime 'a according to the function signature) must not outlive neither one of the arguments given to the function. So, when you give different function parameters the same lifetime and declare that the return value also has that lifetime, you are telling the compiler to find which one of the supplied function arguments actually has the minimal scope and to use that scope as the scope of the return value. This way, you can treat any function like a blackbox, knowing from only its signature how long the returned value can live. 
Sadly, not very fast as yet (It's slower than rustc on quite a few crates). Optimising is a task for after it's feature-complete :)
That is exact definition of hack :)
Pretty much yeah. DOM objects are basically fancy JavaScript objects, so it makes sense to GC them.
Servo code already manipulates the DOM in rust. Unsure what the plans are for libservo's api though. Currently for the DOM stuff to be safe we have some custom safety lints, it would not be great if embedders needed to use that. OTOH embedders have different needs and a post-rooting API might work.
Hey friend, probably want this on r/playrust 
Well, it's complicated. Almost all of the nightly features we use are unnecessary and could be "fixed" with some additional boilerplate and refactoring. Except for custom lints. We need that for GC safety. One plan for stable servo is to slowly move off all nightly features _except_ custom lints, and only run the lints in dev/CI builds.
You'll want to recruit on /r/playrust
What would be the other options? We are thinking of returning the display list directly.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/servo] [Pre-alpha of libservo available](https://np.reddit.com/r/servo/comments/71h8lj/prealpha_of_libservo_available/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
In your opinion, what are the problems that C++ has when it comes to building a compiler?
Out of curiosity, could you write Ok(acc) instead of Ok::&lt;_, hyper::Error&gt;(acc) ?
I understand, thank you! 
http://badassjs.com/post/20294238453/webkitjs-yes-it-has-finally-happened-browser
You can already use https://janitor.technology/ to work on Servo, Firefox, or some other projects from a browser. (The in-browser parts are a text editor/IDE, a terminal emulator, and a VNC client. Terminal commands and an X11/VNC server run in a remote container.)
Thanks ! That's more or less the solution I came up with on my own, but now I understand how and why it works. Those composable traits makes you want to think in OOP I agree, that's why I asked if there was a rusty way of doing this.
I thought you should be able to, but when I tried compiling it that way I got a compiler error saying type annotations needed. I did read something about this, I think maybe futures make the type inference system unhappy sometimes
Returning the display list directly without forcing people to use OpenGL would be awesome.
I usually do it like this, but with AsRef&lt;T&gt; instead of Borrow&lt;T&gt;. Is there a benefit to using Borrow&lt;T&gt;?
Really nice to see this, screenshots don't really do an OS justice. I'm massively surprised by the progress that has been made.
Small nit: we store MIR, not AST.
I like that! Thanks for all the great work! As far as I'm concerned, the main two things I need from Tokio are: - Thread separation. I absolutely love the fact that I don't have to worry about synchronisation strategies. For instance, I can produce a complicated data structure once in a thread, and then reuse it over and over without locks, because I know the current thread is not going to be interrupted. The only case maybe is when a single thread holds locks into something, for the whole app. I seems to be still the case with this RFC. - I use `Either` way too often, and I even wrote a derive plugin to implement instances of `Either3`, `Either4`, `Either5` ‚Ä¶ for futures and streams. It would be really cool if async/await also had a "areturn" thing that generates these instances automatically and uses them to return different `Future` with the same `Item` and `Error` (with impl trait or Box).
AFAIK `impl&lt;T&gt; Borrow&lt;T&gt; for T` but **not** `impl&lt;T&gt; AsRef&lt;T&gt; for T`, therefore in case of `Borrow`, `T` may be used directly.
Cool work! Just two comments: - You probably want to mention the KTH and DDC in your readme. It took me a while to figure out what the intended use for this project was. - How do you plan to update it with the new features added to rustc with every release?
You mean inside [Firefox v57](https://www.cnet.com/special-reports/mozilla-firefox-fights-back-against-google-chrome/)
Would injecting a content JS script be enough? 
&gt; DOM objects often have cycles. Huh? I thought DOM is a tree.
Np! I don't know about webkit (is it part of chrome? wikipedia seems to say that used to be the case), but if you're asking for CEF DLLs then here: http://opensource.spotify.com/cefbuilds/index.html 
&gt; the "unnamed lifetime" error keeps me from allowing a Node to hold a reference Can you give an example of this? It's a stupid error message with a relatively easy fix, as long as the lifetimes match up. Just need to know how to declare them in this context.
"Rewrite it in C++!" :-D
That's just the nodes (which have parent and sibling pointers, so it does have cycles). The DOM is a lot more than that, including stuff like `Event`s and `EventHandler`s and a _ton_ of other APIs like XHR (which you may or may not call "DOM", we do).
Oh, nice, that got fixed. Good to know :)
Ditto! As someone trying to learn the language stuff like this really brightens my day. üòÅ
Luckily we don't have to wonder, because gentoo already exists
Well, we can't codegen from AST, so we *need* MIR. OTOH, constant expressions *in types* are still AST-based (we use MIR for `const` / `static` not used from a type), and miri will soon solve that.
It's a philosophical question. Qt extends C++ a lot. Not to mention that it has it's own std.
Let's just do the whole thing in Go
I like this person! Answers the question I wanted to ask; should have asked. My bad. Are you sure I only get one up-vote? I only had 12k to play with; went searching for nooks and crannies (spelling?). Sue me! Yep, no CS background. Did a couple of courses for marks: a pox on you, Pascal; be gone. Blaise would have puked, and then some. Got into group theory because I was supposed to be making beetles horny. That was a kinda left field detour. I guess you're supposed to do dumb shit when first away from home, but I thought they meant booze! Go figure.
Isn't half the point of servo to serve as a test bed for rust features and development ? Doesn't that go directly against moving it completely to stable rust ?
Using servo directly without OpenGl in a window created by the OS (cocoa, winapi, gtk) would be nice, just like tomaka said.
The generic lifetime isn't the maximum lifetime of the concerned variables, it is the *intersection* of their lifetimes. That is, the lifetime syntax works out the period for which all of them are live.
What is a good way work with a (layered) graph? I have a node struct like this: struct Node { neighbors: Vec&lt;usize&gt;, other data... } And the whole graph is layered in a Vec&lt;Vec&lt;Node&gt;&gt;. I would like to do something like this (simplified of course): let nodes: Vec&lt;Vec&lt;Node&gt;&gt; = ...; for layer in &amp;mut nodes { for node in layer { for neighborIndex in &amp;node.neighbors { some operation on node; some operation on nodes[0][neighborIndex] } } } But this doesn't work because I borrow nodes in the first for loop and then need it again to perform operations on nodes[0][neighborIndex]. (Note that I don't actually use index 0, just a simplification). Is there a more elegent way to do this?
As of today, you don't have to use a window created by the OS. You need to provide a OpenGL context.
Could somebody tell me how i can change the keyboard layout in Redox 0.3.3 ?
I am imagining a sane alternative to Electron and React Native. A cross platform (mobile and desktop) GUI framework using HTML/CSS/Rust. It would be the killer app for Rust. There is a huge demand for something like this. If it needs SpiderMonkey as well that's fine. Having JS and Rust on equal footing would be ideal if you ask me.
Unless this changed without me noticing, `cargo doc` defaults to only building documentation for libraries. So if you're writing an application that you plan on maintaining and is non-trivial, I'd recommend going the lib route.
As long as you like expressing things with line-noise operators. :o)
Is iron actually still actively developed? The repository looked kinda dead in comparison to rocket
&gt; Firefox uses a CC for the DOM. What does CC stand for? 
Thanks for clarification!
You're looking for /r/playrust
üòÅThanks
Run linux in the browser and avoid the remote container: https://bellard.org/jslinux/ 
Yes, but I prefer to use Rust to have stronger guarantees about my code. That's what I use right now for titanium: the web process is entirely programmed in Rust.
Thanks for your answer. By arbitrary communication, I meant having the ability to have the Rust code of the UI communicate with the Rust code of the DOM web content (usually JS) so that I can do something like: "when the user enter this command, execute this action on the web page". I'm not sure you planned to support using Rust to manipulate the DOM (instead of JS) but that's something I'd really like.
I'd like to second the mention of Vimperator functionality. I don't know much about browser and web development. But from a user prospective, there are actions Vimperator supports (via gecko obviously) that other similar tools don't. For example, emulating focus and clicks for almost everything that is clickable, not just links (e.g. `FILTER` in YouTube). There are many things that Vimperator does. And it's hard to list it all here. Some of those things interact with FF''s UI, and thus irrelevant to this discussion. You can try it yourself (with FF ESR). Or even better, imagine you can only communicate with your browser with voice commands: load style green-visited show links follow 15 zoom full 20% down 50% page show insertables focus 3 insert &lt;some text&gt;
Historically, it's more the other way around: mozilla funded development of Rust with the use case of building a browser engine in mind. Regardless, by now Rust is mature enough and has sufficient uptake that it doesn't need any single application to serve as a driver for development in this way. (Also, moving to stable Rust wouldn't preclude feature development for Rust from being informed by Servo's needs. The feedback would become less direct, obviously.)
/u/paulrouget By the way, is there some kind of issue or discussion I could track to know if/when libservo gets the possibility to return the display list directly?
I'm glad. I only with the rust community copylefted more things