What would the size of `LinkedList` be without using `Box`, i.e. a pointer? 
It's required that the elements of the `enum` have a size known at compile time. The compiler can't know the size of `LinkedList&lt;A&gt;` (`A` could be a 1000x1000 matrix). Wrapping it in a `Box` gives it a known size. In memory this is equivalent to adding a pointer to the inner `LinkedList&lt;A&gt;` - the pointer is a fixed, known width.
If it’s single linked like the one above, wouldn’t you own the tail of the list rather than point to it?
Would the same problem be solved by adding the ‘Sized’ constraint to the generic type of ‘A’? 
I'm pretty sure that it could be done wait-free as well (well, until the buffer is full at least).
Now I'm just confused. If you had named parameters, you obviously wouldn't repeat them in the function name.
You *do* own the tail (thus the use of `Box` rather than `&amp;` or `&amp;mut`) but you can’t have the tail inline or else you end up using unlimited amounts of stack space.
I used a simple bash script: Only needs: Curl Dig Upnpc =&gt; to get external IP this could possible be replaced with another lookup https://pastebin.com/pNsNxUM7 
Any plans for teaching it to talk to bind to update zones with TKIP authkeys?
[All type parameters have an implicit bound of `Sized`](https://doc.rust-lang.org/std/marker/trait.Sized.html)
In this case, you own the `Box`. Imagine you had `Cons(A, LinkedList&lt;A&gt;)`. The whole `LinkedList` enum would be either `Nil` (zero bytes) or `Cons` (`size_of::&lt;A&gt;() + size_of::&lt;LinkedList&lt;A&gt;&gt;()` bytes). So you have `size_of::&lt;LinkedList&lt;A&gt;&gt;() == size_of::&lt;A&gt;() + size_of::&lt;LinkedList&lt;A&gt;&gt;()`. Obviously that equation can only be satisfied if `size_of::&lt;A&gt;()` is itself zero, and that's not useful. That's true independently of whether `A` is `Sized`.
What exactly makes you thing that moving purchasing power from society to central bank is less harmful to society than falling prices? What exactly was wrong with gold standard? What makes you think that government ability to function is prosperous for society? How would you put in jail an armed person that is determined to defend with guns, without killing that person?
This is what made it click, thank you :) 
Yes, it's at the bottom, while often it's at the top.
always happy to help :)
Yes, but that is identical to what I wrote in my original question. :-) It's a bit ugly as it creates the BTreeMap instance, but doesn't normally use it.
There's no way to have tail-sharing in these lists in Rust, I think? The list transitively owns all its cells. Most functional languages use garbage collection to manage list storage. You could derive `Clone` and make a copy of the list every time you wanted to take the tail (cdr), but… [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c672b87be39b8a46f6d538fb5c86cc61)
I've heard they lowered it to 10000 later, but I'm not sure. Anyway, I don't think the amount matters. Theft is theft.
&gt; I'm basically forced to clone my database object, or have the reference have a static lifetime. Is that correct as well? Yes. This is why people can't wait (pun intended) for async/await, as it removes these kinds of restrictions. For more: https://aturon.github.io/2018/04/24/async-borrowing/ (Also, since you say you're getting back into it... you should know that futures have made their way into the standard library, but aren't quite stable yet. There's also a new signature for this stuff, and a new concept, "pin", which is the mechanism by which the async/await stuff works.)
Just use object pool (arena), like this: https://github.com/artemshein/obj-pool/blob/master/examples/linked_list.rs
Insert_at_end() is a practically impossible in safe rust. I found this the hard way. Also this makes implementation of tree a tough challenge.
Ah, that's a little different. Per the [documentation](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_string) read_to_string() reads until EOF is received. In your case here, it is waiting for a EOF signal. On linux, you can send this to a terminal by pressing CTRL-D.
I think that entirely depends on the number of individuals, their collective economic power and other things. For instance, if government wanted to 51% attack Bitcoin, they'd have to either: * collect enough ASICs from the entire world and transport them to one place with a huge power plant - this may mean invading other countries or overpaying. (The price of ASIC is slightly lower than the sum of returns expected to be produced by it during its lifetime.) * coerce enough miners to mine certain blocks - this almost definitely involves invading other countries (maybe except if it's China, which is somewhat concerning, but I don't think there's actual evidence of more than 50% miners being physically located in China and known by China government) &gt; 5 or 6 miners account for a very large portion That's not correct, because they are [pools](https://www.blockchain.com/en/pools), not miners. Pools don't have the same power as miners, miners can disconnect from a misbehaving pool and connect to another one at any time. The miners don't have incentive to attack the network, because their hardware would become worthless.
Updated, I added some translations to the README and to the implemented examples, as I continue with the implementation I improve the documentation Thanks :)
Haha I love that you asked this. I'm currently trying to reproduce this server structure design in Dual Universe https://www.youtube.com/watch?v=QeZtqoydXpc. When it's done it will be open source and I'll post another article to explain just like this one. But of course, this optimization only works for particular games where behavior is easily localized (say for large space exploration games). But there are many ways to functionally partition the state to parallelize computation. Communication across machines is going to be slower than inner-communication so however you do the split, you want to minimize the necessary communication. To keep everything internal to Rust, a simple method would be to open communication channels between parallel nodes using the same socket channel that the clients use to connect to the server. A message can either be tagged as coming from a player or coming from a neighbor client.
Monomorphization, when abused, can cause a combinatorial explosion of types and functions. There is a real cost, in compile time and in binary size. Until you know for certain that virtual dispatch is too costly, you shouldn't exclude it as a design choice.
I don't have a answer but I thin both of us are working on the same kind of problem (example: [https://www.reddit.com/r/rust/comments/aeqv74/alternative\_to\_impl\_iteratoritem\_u32\_in\_a\_trait/](https://www.reddit.com/r/rust/comments/aeqv74/alternative_to_impl_iteratoritem_u32_in_a_trait/)) about how create a generic query interface. I have modeled several times on rust this and slowly solving each problem. Is for a relational language (build on top of a internal relational engine on rust): &amp;#x200B; [https://bitbucket.org/tablam/tablam/wiki/Home](https://bitbucket.org/tablam/tablam/wiki/Home) &amp;#x200B; If interested, we could join forces.. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
The expected way to implement a linked list is with unsafe. That's exactly the kind of problem `unsafe` is intended for, so doing this without it is going to be convoluted and frustrating, if it is possible at all.
Especially because they're not even really useful for anything at the end of the day
Do web scraping or automate tasks on a site. Learning hyper client programming, TLS and kuchiki (HTML scraping lib with CSS selectors) was somewhat of a challenge at first but I found it very rewarding. Plus, working with futures is a great way to explore Rust’s ownership system and multithreading support.
Great, is this a public fork you are maintaining?
No. It's not about the size of `A` but the ill-defined size of the hypothetical recursive `LinkedList` type itself. Consider: What's the size of `Cons(1, Cons(2, Nil))` if there's no indirection? Now, what's the size of `Cons(1, Cons(2, Cons(3, Nil))`? The sizes can't be different but they *must* if each `Cons` contains its tail. Also, this hypothetical list structure would by definition not be a *linked* list, and has none of the characteristics of a linked list. In fact, it's strictly isomorphic to a regular array.
It should be quite possible with `Rc` (a reference-counted pointer). There shouldn't be problems with cycles because the shared tails form a DAG.
New rendered version of the book `Learning Rust With Entirely Too Many Linked Lists` here: https://github.com/lzutao/too-many-lists/releases/download/v0.1.0/too-many-lists.zip I have created a pull request in their reposity. Hope this merged soon.
Exactly. I do understand why people try to implement basic data structures as beginner exercises: if you study CS you'll have learned about them very early in your first year, it's relatively well-contained and it's easy to write something that works™ in most other languages. But yeah, in practice you'll rarely (if ever) need to implement such a data structure in the first place, so I'm fine with it being difficult in Rust. 
&gt; kuchiki Ah, I neat library I haven't seen! I normally use the Python library Beautiful Soup. I don't know how fully featured kuchiki is currently, but since it uses servo's html parser it looks like it definitely has potential.
I think it's still O(1). Imagine you have this structure: ``` Cons(1, Cons(3, Nil)) ``` If you want to insert `2` in the middle, you walk to the parent node (`Cons(1, Tail)`) and wrap `Tail` into `Cons(2, Tail)`. That's still O(1) insertion time, no?
The point is, you can't do that! The recursive structure `Cons(1, Cons(3, Nil))` is a single block of memory, looking exactly like the array [1, 3] does. A) you can't insert *anything* there because the object can't grow, and B) even if there were extra allocated space (making it more like a vector) you'd have to move the elements after the insertion point to make room for the new element (just like in a vector).
Yeah, I definitely agree with all of that. The ideal situation is that all crates are maximally performant _and_ maximally safe, so help verifying/fixing the safety of a crate is always a good thing! And in the end, memory unsafety is a bug, and finding and fixing bugs is a goal for any project regardless of other priorities. :-) For Ropey, for example, I would be thrilled if the unsafe parts were audited/fuzzed/etc. by someone. The only caveat is that since the goals of Ropey are performance- rather than security-oriented, future changes may invalidate the parts of such an audit. But I don't think that would strictly be a problem, because Ropey could still say e.g. "version 1.2.3 was audited by Jane Doe Inc. for memory safety", and people who need memory safety could stick to that exact version.
Interleaving data [is not a data race](https://doc.rust-lang.org/nomicon/races.html), so Rust is not required to make such guarantee. And you can call the kernel API from any thread you like, so this is also not a problem.
It could be done by just iterating over the list everytime and adding it after the last item, but this is very inefficient.
Yes. The most common case is to have a trait that requires `'static` lifetime, e.g. `trait ComplexNumber: 'static`, then any struct, e.g. `ComplexFloat` that implements this trait would be required to not contain any data whose lifetime is bound to a particular stack frame. Which means all references within should have `'static` lifetime, which is also true when there are no references, see [vacuous truth](https://en.wikipedia.org/wiki/Vacuous_truth).
Don’t click. It’s a phishing link.
Think of it like Rust's arrays. Each length of array is a different type, because they're different sized objects. If you didn't have the `Box`, then you'd have the same thing here. But it still wouldn't work, because there is no way to tell the compiler how many levels of recursion you are using.
&gt; A type can belong to multiple kinds Is that so?
&gt; But... why does it need to be behind locked in the first place? Convenience. It makes writing simple `stdin`/`stdout` scripts in Rust easy, and the performance hit there does not matter; it'd be far worse in Python anyway. D makes the same choice, for the same reasons. It's easier to be correct by default. If performance of I/O really suffers from the mutex, then the interface allows you to lock it yourself, trading convenience for performance... I've rarely seen the performance of `stdin` and `stdout` really matter in the real world, though, most often it seems to only matter in benchmarks.
I scoured alot but could not find any implementation( efficient and inefficient. ) Can you suggest a source or code segment for such implentation in safe rust?
You can always contribute to a project. For example, liquid-rust has some [good first issues](https://github.com/cobalt-org/liquid-rust/labels/good%20first%20issue) and can gradually move on to more complex ones. You can also talk with us on [gitter](https://gitter.im/cobalt-org/cobalt.rs?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge).
It seems to me it would be possible to provide `core::HashMap` without a `HashBuilder` (no default), then have `std` wrap the `core` implementation and default the `HashBuilder` to `RandomState` (in C++, it would be a template alias, but I don't think Rust has them quite yet).
I still can't understand this "unimplemented &lt;certain language feature&gt; for &lt;another feature&gt;". * Why do I see this so often? * What is going on here? * How do I solve it? Its really annoying because whatever I do it keeps coming out of nowhere or maybe I'm just too dumb for this. I know I should manually implement something but I get lost when it comes to the details. Help? Thanks before.
Right. Precisely the same thing is possible in Rust. What I'm curious about is whether the syntax in Python is more expressive or more concise.
Yes, I was a big ddclient user (and a similar shell script to a sibling's post), but focusing on ddclient for a moment: - One needs perl installed and appropriate dependencies. Amazingly, this is easier said than done -- I don't want to jump through these hoops for each platform I'm on. - An update to the latest ddclient (I think it's v3.9.0) caused failure as one of the perl dependencies changed. One has to dive past the v3.9.0 release post and into the changelog to determine that there was a breaking change hidden! - I have log spam of ddclient warning me the cache is invalid, despite removing the file and starting from scratch - And since a dynamic dns client is something to set and forget, I didn't discover these issues until my IP address changed and it failed to update. I'm thankful for ddclient for all the times it was there for me, but between the cache errors, installation, and maintenance it just wasn't worth it. I needed something dependable. Same story with shell scripts (and I love scripts). While you can accomplish the same thing with just dig and curl, I believe that maintaining a Rust project is easier than maintaining a shell project. In the end, choose what works for you. ddclient and shell scripts are still awesome :D
I used BeautifulSoup as well! I’m rewriting a project I did in Python ATM, and I’ve supplanted BS with Kuchiki. It’s a little sparse on documentation, but if you read the examples in conjunction with the documentation, you should be able to make decent sense of how it works.
How do you do that in Rust?
Would you be looking for r/playrust?
If you want a linked list that can be used in the standard immutable way, where different owners can share parts of the same "immutable" list, you kinda have to use Rc. That being said, what you are trying to do is counter to idiomatic Rust. It can be done, of course, but it is going to feel awkward, and the performance and memory usage of the resulting code is going to be nowhere near just using a Vec to do the same thing - especially if you are working with fixed-length items. I think the O'Reilley book has perhaps the best explanation of the idiomatic way to think of memory management in Rust I have seen. 
Thanks! I’ve been working a lot with futures and streams lately—I think this may have given me solutions to a few problems I have been facing in doing so :)
Got it. I strongly favour software that is in the repository of my system, but if ddclient stops working for me, I'll check out your client and see if it is compatible with my dynamic-DNS provider (in case they differ, I don't know).
rustling on github is amazing. It sends you to a rust play sandbox in your browser so you can do it at work.
It's not the generic that needs to be put in a `Box`, the size of that can be known at compile time. For instance, `enum Option&lt;T&gt; { Some(T), None }` doesn't need a `Box`. The reason for the `Box` is because of the recursive nature of of that `List` enum. The `Cons` variant needs to hold the size of `List`, which is the tag plus the size of `Cons`, which is the size of `List`, which is the tag plus the size of `Cons`... By putting a `Box&lt;List&gt;` inside `Cons` instead, the size is just a pointer, no matter how far it nests.
You can already write game UIs in HTML. The Guild Wars 2 UI is made has a HTML-based GUI, for example (using Mithril as a fronted framework, I don't remember what WebKit/Blink embedding toolkit).
You can't. The book should have said that.
Thank you very much for the crate by the way, it saved me a lot of time!
You can probably observe similar things with other methods as well. For instance: ```rust fn foo&lt;T&gt;(i: vs::Iter&lt;T&gt;) { let idx = i.index(); let next = i.next(); assert!(i.len() &gt;= idx); } ``` The read in `len()` might not pick up the new value from an append in time, which makes it appear as if the iterator has more elements than it does. Sequential consistency can't fix this race, because you could read `len()` first, see that `len() &gt; index() + 1`, which normally implies a new element, and then get surprised when `next()` returns `None`. You may find [this page](https://en.cppreference.com/w/cpp/atomic/memory_order) helpful, which goes into technical detail about the meanings of the various orderings and their use. Note also that on many systems, x86 in particular, release-acquire is the weakest ordering supported by the hardware, so using an ordering like `Relaxed` won't show its most insidious effects until you turn on compiler optimizations on x86.
Good to know that our engineering department consists of nonexistent people :P Debian packaging is actually very simple. The issue is only that documentation for beginners to Debian packaging is nonexistent. Once you know what tools are available for each of the problems, it's a breeze. It requires a bit of menial labor at times, but otherwise it's easy to do. These are the main tools you'd use: - dget: curl-like tool for GETting deb packages from a remote dsc file - dput: POST the .changes file to a remote PPA to submit a package - dch: Update the debian/changelog file with your creds - quilt: version control for debian packages - dpkg-source: useful for committing changes to a package as a new quilt patch - dpkg-buildpackage: create the source package for uploading - sbuild: building the package in a schroot for a specific suite - gbp: tool for cloning / building / managing git repos with debian packaging I don't think it's too uncommon to find someone that is both a programmer on Linux and knows how to perform Debian packaging. If you know how to write Makefiles and use the terminal, you're already halfway there. Getting your packages upstream into Debian, however. That's a whole different can of worms. You'd have to ensure that your package adheres to all their policies. That includes linting your deb packages and separating out cargo dependencies. Our standards aren't that strict -- we include cargo-vendored sources in our Rusty source packages, whereas Debian would prefer that each cargo dep is packaged separately. &gt; Surely, a person with all those qualifications would be able to grok Rust in a month? It is possible to learn Rust in a month, regardless of prior experience, but learning all the different optimal patterns and tricks for the different scenarios they may encounter is likely to take much longer, especially with the kind of software we are writing: systems software. That is, if they are able to wrap their mind around Rust at all.
Could you clarify what you mean by this? Do you mean compiler errors like `StructName doesn't implement std::fmt::Debug` when you derive a trait? You need to derive the same traits (`Debug`, `Clone`, `Hash`, `Eq`) for all the types used in the fields of a struct (and cases of an enum) all the way down, recursively. Some traits require other traits, e.g `Copy` requires `Clone´ and `Eq` requires `PartialEq`.
Debian packaging is easy until you hit a corner case. Which in practice you will, repeatedly. Learning those is a big investment, but once you've done it, actually applying this knowledge doesn't take up much of your time. Which is why I'm puzzled why you want a kernel developer and Debian maintainer in the same package. Good luck with the search. FWIW I only know half the things on the list, and I work at Google.
Pick a library/tool you like in a language you know and that doesn't exist yet in Rust and port it. If it already exists, check if there are issues you could contribute to.
I like it, this should work well in my current home setup. I'll give it a test run. 
Not in the classical way. Could have indexes into an array of nodes.
There has been talk of getting a thin abstraction over OS RNG in libcore.
Yeah, you're right, apologies for the mistake.
You are right that in practice we don’t need to implement a linked list by our own. However, the fundamental data structure of linked list is very much similar to a tree or a graph. And in practice, you may need to implement them for tree/graph search algorithms. 
&gt;The expression `1 + 1` evaluating to 3 is not a data race, so Rust is allowed to have that happen.
I linked the Learning Rust With Entirely Too Many Linked Lists in my question. However, it does not show a solution without unsafe code. I understand using unsafe code is much easy. However, one of main reasons to use Rust is to guarantee memory/type safety. As such, I wonder if there is a possible pure safe code solution. 
If you have all IP addresses assigned to the name Linux OS, this should just work. When you create a [`TcpListener`](https://docs.rs/tokio/0.1.14/tokio/net/struct.TcpListener.html), you give it an IP to listen to. If you make one `TcpListener` per IP, you can listen to all of them concurrently. If you want them all to go to a single handler, future's [`mpsc`](https://docs.rs/futures/0.1.25/futures/sync/mpsc/index.html) should let you do this. Or you could handle each separately. I've got no clue on how to make the multiple emulated devices, but once you've done that Rust can definitely listen to connections aimed at specific IP addresses.
I don’t see your definition has any fundamental difference to the one in the question. For example, it is impossible to implement `append` in O(1) with your definition of the data structure. 
Oh, I see. You want *O*(1) `append` and `prepend`? Yeah, you can't do that without either `Rc`/`Arc` or `unsafe`. That's what single ownership means.
Thanks for the reference. Using object pool and manual index ID is indeed a neat solution. But I think this is equivalent to manual memory management as it just completely bypasses the borrow check and has the same safe guarantee of that using unsafe code.
The point is can we implement such linked list like structure (including linked list, tree, and graph) with the guarantee to memory/type safety. And that is one of the main reasons to use Rust instead of say C/C++
The function is documented about the race-condition tho. It's more of a hint than somethig you should depend on. Only iter reads from the list and only 'next' should be dependend on.
When you start learning a language, it's much better to learn the basics before taking on more complex challenges. In Rust, implementing recursive data structures like lists and trees is one of these complex challenges, and graphs are impossible to implement in safe Rust AFAIK. Yes, they're conceptually very simple. That doesn't necessarily make them simple to implement. I think you're better off searching on crates.io to see if the specific data structure you're looking for is already available and using that crate to implement those algorithms. You can also look for crates that implement those algorithms already and study how they're implemented. 
In an ideal world: /r/rustlang = Rust (The language) /r/rustgame = Rust (The game) /r/rust = rust (The iron oxidation)
No. You still need to handle the invariants manually in the design, just like in C++. Which is good in a way, since it forces you to understand that something simple like a doubly linked list isn't simple at all when you need it to be memory safe. Implementing data structures is a terrible way to learn Rust, since it's unrealistic. 
Great! I'm glad it can help.
&gt; And in practice, you may need to implement them for tree/graph search algorithms. In practice your data is very unlikely to be stored in a literal tree or graph structure. It's far more likely to be stored in a standard container with an adjacency list/matrix used to represent the graph/tree relationship. For things where you _do_ need tree structures with memory safety guarantees then yes, you need to write unsafe code and handle things manually like in C++. That's a feature, not a bug. `unsafe` is a warning to you that you need to think carefully about your implementation. 
how does evmap compare to existing concurrent hash table like [https://github.com/efficient/libcuckoo](https://github.com/efficient/libcuckoo) My understanding is that evmap is mainly a concurrent hash table. The video compare to using a Read write lock but I am curious how it compare to more serious solution to implementing a concurrent hash table.
It's really, really, really easy. struct MyStuff { // ... whatever state you need goes here ... } impl Iterator for MyStuff { type Item = Foo; // &lt;-- Foo = the type of thing you produce fn next(&amp;mut self) -&gt; Option&lt;Foo&gt; { if there_is_more_stuff() { return Some(foo); } else { return None; } } } } That's all there is to it. 
Btw, if you want to post a code snippet, just use a prefix of 4 spaces at the beginning of each line. Not ```. Like so: fn main() { // ... } 
Yes, I know. It's more verbose and trivially more inconvenient, leading myself (and I am pretty sure rustc developers and many others) not to bother, but with yield, will define iterator.
The approach I'd try is to keep your nodes in a [`Slab`](https://docs.rs/slab/0.4.1/slab/). That's basically a `Vec`, except that it keeps track of elements that have been deleted and reuses those slots for future inserts. You'll be able to insert and remove as cheaply as in a real linked list (if you're willing to amortize the cost of growing the slab). You'll also be able to return real `&amp;T` references when you iterate, without any of the guard/wrapper types that `RefCell` and `Mutex` force you to deal with. And you can keep a tail "pointer" without making the borrow checker upset, because the pointer is really just an index into the slab. Two problems with that approach though: - Because the nodes are tied to their backing slab instead of to a global allocator, it's not as cheap as it should be to join two linked lists. Instead, one of them would need to allocate more space and then insert each individual element of the other. - Implementing `IterMut` in safe code is problematic. The backing slab provides its own `IterMut`, but the problem is that front-to-back in the slab isn't the same as front-to-back in the linked list. If you want the `IterMut` order to be correct with respect to the linked list, I think at that point you have to resort to unsafe code. (You know that by walking your next pointers you're never going to return the same `&amp;mut T` twice, because you won't allow the caller to make a circular linked list, or have two lists share the same tail, or anything wacky like that. But there's no way to prove to the compiler that you've done that properly.)
Thank you for the answer. And thanks for all you've done for Rust (so far). Also, I can't believe I didn't realize that async/await will fix this borrow issue! All this time I thought it was basically just more sugar, but if it actually changes the semantics that you can write, that's great! I was actually really bummed out when I started my project and realized that we were still on Futures 0.1. A year ago I thought we were almost done with it...
Yes, you can start down that road: [The Book](https://cglab.ca/~abeinges/blah/too-many-lists/book/) gives the details.
Any time! Yeah, the borrowing issue made stuff take a while. There was an 0.2, and an 0.3; 0.3 (now called futures-preview) is the one that ended up going into the stdlib.
Is there anyway to download rust using curl and rustup (the “recommended way”) but exclude the rust-doc component? I’m using Travis CI, whose environment downloads a fresh copy of rust using rustup. As you probably well know, rust-doc takes the longest when downloading a new toolchain. I noticed that the default version was being specified using flags so I was wondering if there is any way to exclude certain components from being downloaded as well. This is not really a priority, as my build doesn’t exceed any time limits, but I would like it to go faster (and hopefully not waste Travis CI’s resources?) Any help is appreciated! Thank you in advance!
To put it simply, doubly-linked lists and other similar data structures are simple for humans to think about, but very difficult to verify correctness of at compile time because of the need to have more than one reference to each node. The borrow checker isn't smart enough to do that and the whole *point* of having `unsafe` is for situations like these, where either the standard library or a mature 3rd-party crate uses `unsafe` to build a safe abstraction. Most languages which provide linked lists safely (eg. functional programming languages) solve the problem by requiring a garbage collector and `Rc` is essentially the simplest possible means of runtime garbage collection. (You're essentially asking "How do I safely use arrays without runtime bounds checks". It's technically possible, but painfully crippling, as anyone will tell you who had to deal with the "safety over utility" focus of the constraints imposed by early versions of Pascal.)
Thanks for the explanation. 
A \`ty\` is a full type that includes type parameters. So, for example \`BlockRng&lt;Fake&gt;\` is a \`ty\`, while \`BlockRng\` is just an \`ident\`. Also, it should be \`$block::&lt;$t&gt;::from\_seed()\` and \`$block::&lt;$t&gt;::from\_rng()\`.
Rust aims to provide safety guarantees beyond protection from data races where its developers consider it a readonable trade-off. That's the whole point of using monadic error handling (`Result&lt;T, E&gt;`) rather than special return values like `-1` when anything that's not exceptions would satisfy the concerns related to avoiding data races. In this case, the goal is to ensure that, if something goes wrong in heavily multi-threaded code, any status/log messages needed to detect and/or diagnose it won't be garbled. Having a lock around stdout *is* in line with the Rust philosophy of defaulting to the safe choice and letting people opt out.
Found the project manager
The absolute #1 spot to start is the official Rust book: https://doc.rust-lang.org/book/index.html It's really excellent. 
The Rust game came out 3 years after Rust was first released. If you *don't* want to learn a memory-efficient safe programming language "empowering everyone to build reliable and efficient software.", try /r/playrust.
There's "the book", the official way to learn rust. I currently am reading O'Reilly s book "programming Rust" which isn't the greatest but it's something and I just prefer paperback stuff for learning
If I am reading this correctly, currently to use librsvg in Rust, we need to use rsvg-rs to access the C ffi. Which seems odd for a library that is predominately in Rust at this point. Is there a plan for a pure Rust path to use librsvg?
Well, it's not so much being a Debian maintainer, but being able to debug and fix packaging issues in the software you maintain. As well as being able to write the packaging scripts for any software you happen to create. The ability to debug and fix packaging issues with hardware projects is part of the position. For example, packaging for NVIDIA drivers, or maintaining packaging scripts for any of our own drivers and software that you may happen to work on.
I’m going to use that it seems great! 
Thank you so much
I would also recommend the ebook 'beginning rust' which is available as a free pdf download and is a really good introduction. 
If it's the most significant one it doesn't seem too bad, since std libraries can always use no_std ones. Could you say more about the significance that you see?
Hi, thanks for the response! I looked into mpsc and it's not clear to me how it would help with listening on multiple `TcpListener` structs. In all the examples I see in the tokio github, the executor only ever listens for incoming connections on one socket, using the following pattern: let done = socket.incoming() .map_err(|e| println!("error accepting socket; error = {:?}", e)) .for_each(move |client| { // ... }); tokio::run(done); As far as I know, `tokio::run(done);` blocks the main thread indefinitely, so it wouldn't be possible to do multiple of this patterns in one function. I also don't really know enough about tokio, would `tokio::spawn()` be of any help for this? For now I've started writing some single threaded code using [mio](https://docs.rs/mio/0.6.16/mio/), but I'd be interested to know if this is possible using tokio.
You can do graphs in safe Rust, but you'll have to keep indices into a vector rather than references to other nodes.
Isn't it just a very simple tree (having only one child instead of two or more)? I would say trees are fairly useful.
You may be interested in the [Soup](https://crates.io/crates/soup) crate, also built on top of html5ever, which tries to be similar to Python's Beautiful Soup
Yeah, `tokio::spawn` is quite useful for things like this. I would recommend using `incoming` on each socket, then sending the results to an `mpsc` stream, and then handling the connections in the `mpsc` receiver stream. There's one problem with using `spawn` in that the tokio runtime needs to have started for it to work. So we'll need to use `tokio::run()` _first_, and then inside the initially started future, we can spawn the connections. `spawn` is the standard way to get multiple tasks running concurrently, but it does have to be used within the tokio runtime. Here's a bit of what I'm imagining: tokio::run(lazy(|| { let (send, recv) = mpsc::unbounded(); for ip in &amp;["127.0.0.1:80", "127.0.0.1:8080"] { let listener = TcpListener::bind(&amp;ip.parse().expect("expected valid ip")) .expect("expected all listener bindings to succeed"); let cloned_send = send.clone(); let fut = cloned_send.send_all(listener.incoming().then(|res| { res.expect("expected listening to succeed"); Ok(()) })); tokio::spawn(fut.then(|_ignored_send_error| Ok(()))); } tokio::spawn(recv.for_each(|stream| { // this will run once for any incoming connection on any listener. Ok(()) })); Ok(()) })); (playground: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1bce5dbee96154bc6ccc4d6b6fb73910) This first starts the runtime, starts listeners on two addresses, forwards the result of both listeners to the `mpsc` stream, then starts another future reading the mpsc stream. Not a complete example, and it'll panic if any errors occur, but it should be enough to get started?
Welcome to the Rust community! Don't worry about anything - we've all been new at some point. :) Judging by the amount of questions, I would advise you to go through "The Book": https://doc.rust-lang.org/book/2018-edition/ if you haven't . "The Book" is really good and fast way to get up to speed. 10 threads is nothing. Until you hit 1000, don't worry. :D For argument parsing use `structopt`. It's awesome. https://docs.rs/structopt/0.2.14/structopt/ For logging use `log` + `env_logger`. https://docs.rs/env_logger/0.6.0/env_logger/ 
After reading the book that doc recommended, the next step is to install clippy and run it on your codebase. It detects common mistakes and misconceptions and provides suggestions on how you can improve your code.
Awesome thanks 
Sounds interesting, could you share the link to this?
As mentioned in that blog and similar posts, unsafe code does not mean _unsound_ code. Everything in rust is built on unsafe code. `Vec`, `LinkedList`, even `Box` is implemented with unsafe. The key is that this code is encapsulated into small modules with _safe interfaces_. Safe rust projects get to be safe by relying on the unsafe code that exists, not by avoiding it. To answer your question: this is not possible. You need unsafe code to implement a performant linked list. Even if you're using `Rc`, `Rc` is implemented using unsafe! You can't have a doubly-linked list without an unsafe base because the rust compiler does not analyze (and does not pretend or try to analyze) multiple ownership.
Oh very cool! Thanks for the code sample, I wouldn't have known how to get started without it. This is a great starting point for when I want to try and wrangle with futures.
I think all of this is only true if you have an explicit deserialization step that unpacks the whole message at once. You could build an lazy/iterator-style zero-copy parser instead that I think probably wouldn't need to allocate at all. [Protozero](https://github.com/mapbox/protozero) is an example of such a parser on the C++ side.
A correctly implemented linked list will be safe, even if it uses `unsafe` internally. (It doesn't mean much if you implement it incorrectly, even without unsafe.) The main motivation for Rust's safety features is that you can share and build safe code on top of other safe or unsafe code, not that you can always build things from scratch with safe code. Especially not clever "pointer tricks" data structures like graphs.
I hate you, OP. I hate you.
&gt; I know I'm not trying to catch error states. I'm not yet familiar with rust try/catch/except alternative. Any tips? [Result](https://doc.rust-lang.org/std/result/enum.Result.html) is how "normal errors" are handled in Rust: if a function can not fail it returns a value, otherwise it returns a `Result&lt;Value, SomeErrorType&gt;`. `unwrap` or `expect` should only be for one-offs (scripting) or exploratory code. Basically, rather than have one codepath for "success" and one codepath for "error", "result" is reified (is an actual value you can manipulate) and the result can be a success (`Ok`) or an error (`Err`). There's syntactic sugar &amp; various methods (on `Result`) to make manipulating them more convenient. [The Rust book provides more information](https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html). &gt; I use nested functions which are common in Python. What about Rust? Technically you can define nested functions in Rust but they're not very useful as they're not closures, external visibility is explicit, and you can create nested modules (to package helpers) without having to create new files. Most cases where I'd use a nested function in Python would be a [Closure](https://doc.rust-lang.org/book/ch13-01-closures.html) in Rust. &gt; I would like to comment my code in some common style - like JSdoc for Javascript with those @param stuff etc. What's the standard for Rust? [Rustdoc](https://doc.rust-lang.org/rustdoc/index.html). Sadly the rustdoc book is very bare-bones, but that's what both the standard library and the vast majority of crates use, so you can just check out their source code. &gt; Argument parser - yes, the input/output file is hardcoded for now. Look at structopt. Or clap if you don't like structopt's declarative nature. Or getopts if you want something much simpler which leaves most of the work to you. &gt; I will be glad for any sane feedback. * since you're using edition 2018, the `extern crate` statements are unnecessary * some of your `use` are unnecessary because they're already [in std::prelude](https://doc.rust-lang.org/std/prelude/index.html#prelude-contents) (~ python's builtins, but they're just re-exports of other bits) * Rust's functional ancestry means it's an *expression-based* language, as opposed to Python which is statements-based. This means many of the constructs which are statements (don't generate a value) in Python are expressions in Rust. Combined with the language's type-centricity and the utility functions on the types means e.g. let mut channel = None; match re.captures(&amp;html) { Some(cap) =&gt; { channel = Some(String::from(cap.get(1).map_or("", |m| m.as_str()))); }, None =&gt; (), } is overly complex and the mutable binding is completely unnecessary: this could be written along the lines of let channel = re.captures(&amp;html).map(|cap| cap.get(1).map_or("", |m| m.as_str()).into()); alternatively, *blocks* are also expressions so you can use them to package small computations: let channel = { match re.captures(&amp;html) { Some(cap) =&gt; { Some(String::from(cap.get(1).map_or("", |m| m.as_str()))); }, None =&gt; None, } } (this is mostly useful for multi-step computations). * assuming `parse` is called repeatedly / in a loop, you'd usually use lazy_static to initialise all regex at the start of the program and avoid initialising them on every call (think of it as a module-level `re.compile` in Python, though `re` also has a regex cache which I don't think `regex` has) * avoid `&amp;String` and `&amp;Vec&lt;T&gt;` function parameters, prefer `&amp;str` and `&amp;[T]` respectively: they provide more flexibility to the caller * don't fear blocks e.g. in `load_playlist`, the `parse_urls` nested function would usually be a block. And I'd use [Option::filter](https://doc.rust-lang.org/std/option/enum.Option.html#method.filter) and [Option::map](https://doc.rust-lang.org/std/option/enum.Option.html#method.map) to avoid splitting the codepath and explicitly moving values in and out of options. * in `format_title`, you could use [the `format!` macro](https://doc.rust-lang.org/std/macro.format.html) which returns a string * also the same could probably take its parameter by reference (`&amp;Video`) making cloning it unnecessary (though you'd have to rejigger some of the types within). Or formatting a title could be a method on Video. Or it could be the `Display` implementation for video. * incidentally it's a bit odd that you used `write!` to write to a string in `format_title`, but didn't use it to write to a file in `save_playlist` (`f.write_fmt(format_args!(...` could be replaced by `write!(f, …`) * rustdoc has a nice find-as-you-type box, you've probably missed a few utility functions which are available e.g. `std::cmp::min` (which you basically hand-rolled in to_chunks) * speaking of to_chunks, [slice::chunks](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks) would probably make it simpler, that function is basically `urls.chunks(10).map(|s| s.to_vec()).collect()` (with more state-tracking)
Mystified by this one today; I have a `Vec&lt;Vec&lt;u8&gt;&gt;` and I want to pass it to a function which accepts `&amp;[&amp;[u8]]`. How can I get to that point without having to allocate a new `Vec` to hold references? I know `&amp;Vec&lt;Vec&lt;u8&gt;&gt;` automatically becomes `&amp;[Vec&lt;u8&gt;]` but I can't figure out how to do the nest too, without allocation of another `Vec` (which is a complete waste in my current situation). I'm happy to use `unsafe` if necessary, since this is extremely limited in scope and can be guaranteed manually (the use of a slice is purely to avoid committing to a `Vec` in the public API).
Here's an implementation for the struct mentioned in the OP: fn append(&amp;mut self, val: i32) { match self.head { Some(mut cur) =&gt; loop { if cur.next.is_none() { cur.next = ListNode { val, next: None }; } cur = &amp;mut cur.next; }, None =&gt; { self.head = ListNode { val, next: None }; } } } Playgroud with test: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=53ac3e5dd6c011139c958e2d90888ee4
Since you have `edition = "2018"` in your `Cargo.toml`, you don't need the `extern crate` statements at the top of `main.rs`. Rather than recompiling the regular expressions in `parse` each time, you might want to use the `lazy_static` crate to create them as global statics. This way you can avoid repaying the cost of compiling them each time you call `parse`. let title = match re.captures(&amp;html) { Some(cap) =&gt; cap.get(1).map_or("", |m| m.as_str()), None =&gt; "" }; can become let title = re.captures(&amp;html).and_then(|m| m.get(1)).map_or("", |s| s.as_str()); Rather than defining `duration` as `mut, giving it a default value and then overriding it, you can use `match` as an expression: let duration = match cap.and_then(|c| c.get(1)) { Some(duration_str) =&gt; Duration::from_secs(duration_str.as_str().parse::&lt;u64&gt;().unwrap()), None =&gt; Duration::new(0, 0) }; (This also handles missing captures by defaulting to a duration of 0, rather than trying to parse an empty string as a `u64`.) For `channel`, you can do something similar to `title`, and `published`, something similar to `duration`. Rather than taking `&amp;String` as an argument, it's better to take `&amp;str`, since there's (almost?) nothing that `&amp;String` can do that `&amp;str` doesn't, and now people can pass in string literals. Similarly, prefer `&amp;[T]` to `&amp;Vec&lt;T&gt;` since various other types expose slices. `parse_urls` can be written fn parse_urls(line: io::Result&lt;String&gt;) -&gt; Option&lt;String&gt; { line.ok().filter(|s| s.starts_with('#')).map(|s| s.trim().to_string()) } which differs in that it won't panic if line is `Err`. I don't think the turbofish (`::&lt;...&gt;`) on `reader.lines().filter_map(parse_urls).collect::&lt;Vec&lt;String&gt;&gt;()` is necessary since the compiler can infer the type that it's collecting to from the function signature. In `format_title`, I don't see anything that requires ownership of a mutable `Video`, rather than `&amp;Video`. Also, instead of using `write!` to build a string, you can use the `format!` macro, which will return a new `String`. Similarly, you can write `let new_path = format!("new_{}", path);`. Is there a reason you're not writing the header/content using the `writeln!` macro? It seems more appropriate here. E.g. // Write header. writeln!(f, "# Created by YTitler"); writeln!(f, "# See: https://gitlab.com/n1_/ytitler\n"); writeln!(f, "#EXTM3U"); // Write content. for v in videos { writeln!(f, "#EXTINF:{},{}", v.duration_as_secs(), format_title(v)); writeln!(f, "{}", v.url); } (N.B. that I removed the `clone()` call from `v` since I'm assuming you've changed `format_title` to take the argument by reference. Also note that I'm ignoring error handling here for now; in reality, you'd probably have the function return a `Result` and just stick a `?` at the end of each call to `writeln!`.) `to_chunks` could probably be replaced by the `chunks` method on `&amp;[T]`. You'd need to change how you consume things a bit (you get an iterator of slices, rather than a `Vec` of `Vec`s), but it might be worth it. Aside from that, your `while` look can be mostly rewritten as `for i = 0..steps`. Your calculation for steps can also be written as const LIMIT: usize = 10; let steps = (urls.len() + LIMIT - 1) / LIMIT; which is simpler and avoids doing doing anything with floating point. `reqwest`'s `Response` type has a `text()` method which returns `Result&lt;String&gt;`. This is easier than using `read_to_string()`. In `fetch_chunk`, you're spinning up a bunch of threads to process the videos, then blocking on all of them being completed before handling the results. This seems like a good candidate for `rayon`. If `chunk` is a `&amp;[String]`, then you can write `let videos: Vec&lt;Result&lt;Video, _&gt;&gt; = chunk.par_iter().map(fetch_url).collect()`, and change `fetch_url` to have a signature of `fn fetch_one(url: &amp;str) -&gt; Result&lt;Video, Error&gt;`, returning the parsed Video instead of using an mpsc channel. You want to return a `Result&lt;Video, ???&gt;` to handle `reqwest` failing, or the video not parsing properly. Even more wonderfully, you can write `let videos: Result&lt;Vec&lt;Video&gt;, _&gt; = ...` and then if any of the requests failed, you just get a single `Err`, instead of having to check each separate `Result`. Rather than let mut videos = vec![]; for ch in chunks { let mut chunk_videos = fetch_chunk(ch); videos.append(&amp;mut chunk_videos); } I believe you can write let videos = chunks.into_iter().flat_map(fetch_chunk); Above I suggested changing the signature of `fetch_one` to return `Result&lt;Video, Error&gt;`. In general, more of your functions should be returning `Result`s, and using `?` to propagate errors up to a point where you can either handle them, or terminate the program gracefully. The state of error handling in Rust might be shifting a bit in the upcoming year, but for a binary like this, you can do a lot worse than adding `failure = "0.1"` to your `Cargo.toml`, putting `use failure::Error;` at the top of the file, having your functions return `Result&lt;OldReturnType, Error&gt;`, and sticking `?` after every `Result` value you can't handle better. There are certainly *better* ways to handle errors, but IMO this is better than just `unwrap`ping everything. 
I don't think *I* mentioned QuickCheck, but sure... It's indeed possible in any language (even C) given enough effort. However, there is the danger of the Turing Tarpit. (... and the point of my comment was more towards the practical. Not what's theoretically possible.) 
You can't do that. The best you can do is a `Vec&lt;&amp;[u8]&gt;`. A `Vec&lt;T&gt;` isn't even the same size as a `&amp;[T]`, let alone guaranteed to have the same layout.
I'm not aware of any public information from MS on the CFG format. Even though there is lot of documentation on the final implementation of it (PE format), I don't think anyone reversed the information in the object files that is used by the linker (the one Rustc should emit).
Here's some code review notes I took. This is all in the spirit of improving things, so I hope none of this is unwanted feedback. Line 6: Avoid renaming types when you import them, e.g. `use std::io::Write as IOWrite}`, if you can avoid it. Instead, use `use std::io`, and in your code use `io::Write`. Or, since it's a fairly short path, just use `std::io::Write` in your code to be unambiguous. Line 49: Don't do this: if cap.is_some() { ... cap.unwrap() ... } This is exactly the right situation to use "if let", like so: if let Some(c) = cap { ... use c ... } Because Rust allows (even encourages) name shadowing, you can even do this: if Some(cap) = cap { ... use cap ... } Depending on whether you're moving or borrowing, though, you might need to add `ref`, like so: if let Some(ref cap) = cap { // use cap, which is a reference } Line 52: This is where you need to be handling or propagating errors. Convert it to this: duration = Duration::from_secs(duration_str.parse::&lt;u64&gt;()?); The `?` operator will either resolve the expression to the `Ok` value (the successful value), or it will return the `Err` value (the error value) as a new `Result` that is returned from this method. So you'll also need to change the return type of this method to `Result&lt;Video, YourErrorTypeHere&gt;`. You can use String as an error type, if you just want the textual string of the errors. Line 52: Don't use `&amp;String`, pretty much ever. Use `&amp;str`. The reason is that you can get `&amp;str` from many, many places (such as static fields, literals, fixed-length no-alloc arrays on the stack), but you can only get `&amp;String` from one place (from a `String`), *and* `&amp;str` can do everything that `&amp;String` can do. (The same is not true for `&amp;mut String`.) Line 59: This is where you should use the `Option::map` method, like so: let channel = match re.captures(&amp;html).map( |cap| String::from(cap.get(1).map_or("", |m| m.as_str()))); This lets you focus on the transformation of the data that is stored in an `Option`, without dealing with `Some` vs. `None`. Line 70: same as line 59 Line 73: convert unwrap() to `?` Line 90: convert arg to `&amp;str` Line 93: Super weird for this function to take `io::Result&lt;String&gt;`. Change it to take `&amp;str` as its input. Then again, you need to handle / propagate errors correctly, so probably best to convert it to this: // Read lines and filter the URLs. let mut filtered_urls = Vec::new(); for line in reader.lines() { let line = line?; // propagate errors if let Some(parsed_url) = parse_urls(line) { filtered_urls.push(parsed_url); } } I can't think of a good way to handle errors with functional-style iterator pipelines. Line 115: Why are you moving `Video` into this function? This should take `&amp;Video` (a reference), since all you're doing is reading data from `Video`. Line 121: Convert to: video.channel.as_ref().unwrap_or_else(|| "[unknown]"), That does no allocations, btw. Line 125: Convert to: video.published.map(|s| s.format("%Y-%m-%d").to_string()) .unwrap_or_else("[someday]".to_string()), Line 135: Just make this: let mut new_path = format!("new_{}", path); Line 145: You're using "into" iteration here, where you consume the list. That's fine, but idiomatically usually you want to just read data, so either use "videos.iter()" or use "for v in &amp;videos". That does not alter / drop / consume the `videos` list. Line 177: Don't manually step your indices. Do this: for i in 0..steps { // ... } And convert i and steps to `usize`. Better yet, do this: let chunks = urls.chunks(step).collect(); It does what you want. L197: Convert arg to `&amp;str` (and everywhere else). L256: Since you're using `try_iter`, you may not get all the results. Are you sure that's what you want? If so, you can replace that loop with just: receiver.try_iter().collect() L264: You can combine a bunch of this as: let videos = chunks.flat_map(|c| fetch_chunk(c)).collect(); L280: Here's a good example of why your args should be typed `&amp;str`, not `&amp;String`. Once you do that, you can combine these lines together into the obviously simpler code: let mut urls: Vec&lt;String&gt; = load_playlist("youtube_streams.m3u"); 
That’s kinda what I figured, my current implementation creates a new Vector to hold the references. I was curious if there was some magic to make the inference work, but I guess not Thanks for confirming!
Awesome little tutorial! I out it on my todo-list for new arewegameyet.rs listings. Have you heard about Laminar? The team behind it is very friendly and open to contributors if you’re interested in teaming up :)
Try storing the results of calling `config()` in a variable, and then calling methods on that variable. I'm guessing that `config()` returns a value, and then `big_endian()` takes a reference to that value as its input. In your code, that value is a temporary, and the lifetime of the temporary is the end of this statement. Think about the lifetimes and it will be clear that your code is unsafe, and the compiler is spotting a real bug.
If I'm interpreting [this docs.rs commit](https://github.com/rust-lang/docs.rs/commit/ccac550ad6953fef75057d0ed24b58f145da7fe4) correctly (as well as [this rustdoc PR](https://github.com/rust-lang/rust/pull/51384)) this should already be happening.
I’ve been wanting to write that article for a while and it took me weeks to write it. So here it is. It’s just a feedback and retrospection about AoC and the problems I solved. It’s a bit long, yeah I know. \\o/
I actually heard great things about Programming Rust, causing me to pick it up. I heard it was better than "the book" fwiw. I'm about a 3rd of the way through it and so far I like it. It's been one of the more easy technical readings I've done - which are normally a snooze fest for me hah.
Did you mean to write TSIG instead of TKIP?
I'm afraid I don't see this plan as a good thing. One of my quixotic crusades is to eliminate timeouts. Timeouts are evil and wrong, and the session keepalive timeout is a great example. Like most timeouts there's no reasonably correct setting for it. It's always either; too short — disconnect early for no reason; too long — hanging around waiting for no reason. It's sort of inherent in what a timeout is, really. If you knew how long you had to wait, you wouldn't *need* a timeout. At any rate, as far as I am aware there is by design no keepalive timeout in TCP. (TCP is full of timeouts; just not that one.) Keepalive must be handled by higher-level code. If you *wanted* a timeout lock there are way more efficient and easier ways to get that than borrowing a TCP timer.
Ah right, good point. 
I think I am missing something, but how will the pointers in the `first` and `last` fields be set to NULL when the element is dropped as shown in the playground link below? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=39d1f554893a6c21630937fe9a8774d7
All these answers are exactly why Rust is so fantastic! Never in my life have I experienced such a welcoming and dedicated community.
Ah, I don’t think you understand what I am talking about. I’m not talking about timeouts in any way, shape or form. I am talking about using a socket (maybe a tcp connection with keepalive semantics, which includes heartbeats back and forth) as a mechanism for holding a distributed lock. Not talking about a way to avoid or control general timeout issues. 
The [slotmap crate achieves this with a doubly-linked list](https://github.com/orlp/slotmap/blob/master/examples/doubly_linked_list.rs)
I've grown to like nested functions as a way to create a mini function specific DSL that has no visibility outside that function. Even if they aren't closures, it provides context to a maintainer that this nested function was written with only this other function in mind, and it allows for very terse names since the affected namespace is so constrained. Typically it will be something like a gnarly one liner that I used two or three times in my function that I want to give a name to and DRY up a little.
Is there a way to check if `stdin` is empty? I want to build a CLI tool that will check for a file path argument and if that isn't provided assume the file is `stdin` but there doesn't seem to be a way to exit if nothing was pipped to the command.
It might help if you shared a larger chunk of the code you're working with (or maybe link to it in the [Rust Playground](https://play.rust-lang.org/)). For instance, it's not clear what `StartBattle` is and why `Box::new(StartBattle)` is of type `Box&lt;dyn Fn(&amp;mut Context) -&gt; ()&gt;`.
Read some of "the book" but I'm an experienced C programmer, and I didn't quite get it until I started reading Programming Rust. It's written with that sort of background in mind.
I'm wondering why an `Either&lt;Arc&lt;str&gt;, (u32, bool)&gt;` takes 24 bytes on amd64 rather than 16. Shouldn't it be possible to store it as: ``` Either::Left(s) | NonZero ArcInner&lt;T&gt; addr | length for fat pointer | Either::Right(a, b) | 0 | a | b | padding | ```
It might make sense to check if `stdin` is a TTY? on Linux, at least, this will return true if nothing is piped/redirected.
You can only work this out if you try to read from it (and get nothing). So from that perspective, treat is as if it were simply an empty file provided directly rather than something specific. 
It is just a hobby project and it's based on old version of rmp so expect bugs. I use it on stm32 micro controller and it should compile on latest stable. [Link](https://drive.google.com/file/d/1fNNYjIqOiEHpSoVkCw1JJcPng-kPtXgm/view?usp=sharing)
I agree, there is nothing wrong with using reddit to air one's grievances but it is important to understand that it is nothing more than that. It is unfair to expect a reply to your grievance. I would like to quote the original comment I was replying to. &gt; I brought this exact user up before. Crates team didn't do piss all about it, it's an awful policy and really should be changed. Bringing up something outside of an officially supported channel (like the rust forum or a community meeting) is fine but the language of this post is, in my opinion, unfair. You are not entitled to change because of a single communication on reddit. To go a point further I don't believe you are entitled to a response to your post. I want to reiterate, there is nothing wrong with posting on reddit to complain, commiserate and/or resource share, feeling entitled to anything is where I take issue. 
Do you have any ideas for a good solution here? LLVM's codegen is the best for what Rust does, and compiling to C is a dangerous mess. I don't see any better solutions here other than waiting for/contributing to LLVM to add support for other architectures.
That is what I thought but stdin being empty will block until something is read. let mut std_in = ::std::io::stdin(); let mut ret = String::new(); let mut buf = [0; 128]; while let Ok(b) = std_in.read(&amp;mut buf) { if b == 0 { break; } ret.push_str(&amp;String::from_utf8_lossy(&amp;buf)); buf = [0; 128]; } will simply block. I have also tried `read_to_string` and `read_line` which both behave the same way.
That is an interesting idea, thanks!
&gt; Please hate me We're kind of famous for not doing that.
Ah, yes, the documentation actually does say that it doesn't guarantee whether blocking will happen or not. :(
Your guess is basically correct; what gets bound to `bytes` is the output of serialize which is a `Result&lt;Vec&lt;u8&gt;&gt;`**.** This data is not tied to the Config object constructed by config(), no reference to it, so it doesn't matter that the Config doesn't live past that line. `big_endian()` on the other hand returns a `&amp;mut Config`, which means you are trying to bind a mutable reference of a temporary to `ser`. If `big_endian()` took `self` and returned a `Config` you would be able to write as you did. As it is you could write something like: `let ser = config();` `let ser = ser.big_endian();` &amp;#x200B; &amp;#x200B;
I'm learning Vulkan atm (dont reccomend this to beginners) but doing something neat with graphics that's just a toy or something is an idea. I'd consider learning OGL or one of the popular safe graphics wrappers in rust and just making a silly game or 3d model viewer.
I don't think I do understand. If you want a communication channel for holding a distributed lock, there's Rust's `channel` primitive. You could implement some kind of "lock server" on top of it (or on top of a TCP channel for that matter), but you're still going to need a locking protocol. There's something I'm missing, I think.
perfect answer. Thanks!
[https://imgur.com/a/f2R7zSQ](https://imgur.com/a/f2R7zSQ)
Looking at the type error, I think rustc is saying "you have a map containing functions taking one input, a `&amp;mut Context`, but you need a map containing functions taking _no input_". Your function needs to be `Fn() -&gt; ()`, not `Fn(&amp;mut Context) -&gt; ()` - it shouldn't take an `&amp;mut Context` parameter. Either that, or you need to change `new_from_buttons` to accept functions taking `&amp;mut Context` rather than ones taking no input.
/r/playrust
This in for the rust programming language, unrelated to the game called rust. I think you want /r/playrust.
Say I have a this custom macro... ``` macro_rules! create_Struct { ( $type:ident ) =&gt; { pub struct $type; }; } ``` Is it possible to have the structs created by this macro use derive macros? Like can I use #[derive(Debug)] somehow? Or do I have to manually implement it in the macro?
Is there a reason why `new_from_buttons` takes a hashmap with `Box&lt;dyn Fn() -&gt; ()&gt;` and not `Box&lt;dyn Fn(&amp;mut Context) -&gt; ()&gt;`?
You can write a linked list without boxes. It's just that then two linked lists of different sizes will have different types, and the lengthhas to be known at compile time. That is usually not desirable.
This raises an interesting (to me, at least) question about the implementation of the "builder" pattern in `bincode`: Is there a good reason not to have the builder methods take ownership of the config struct and return a modified version? It seems like this would be easier to work with, since the builder chain could be tapped at any point. Might the builder be more performant as it is currently implemented? Or is there something else I'm missing?
Well what about `no_std` with `alloc` ? * https://rust-embedded.github.io/book/intro/no-std.html * https://github.com/dropbox/rust-alloc-no-stdlib
You have the issue right, but the solution doesn't work. The [working code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ccbb5ea612b5a8ddcae6491be4381546) has a few of the macro types switched up so that they can be combined -- `$block` has to be an ident, because as you said a type without enough parameter isn't a complete type, and `$rng` has to be a path if it's going to be called like a function. Unrelated to the macro syntax, `from_seed` also needed to be fixed to wrap its output in the wrapper struct.
It seems like the other comments have already covered a lot of stuff, so I'll just give you one suggestion on organization. Since your code is in `main.rs`, you've technically written a binary/executable, not a library. A common pattern in Rust, even for projects just meant to be an executable, is to write the majority of the code as a library, and then have only a small `main` function (handling argument parsing and then just delegating to the library) in a separate file. This way, your library can be reused in other projects without needing the executable part. So, how its usually done is by having `src/lib.rs` as the start of your code, with whatever modules, etc. you want from that. Then, you have one or more executables (probably one in your case) in `src/bin/` each with a `main` function. So what you would want to do is just rename what your current `main.rs` to `lib.rs` and then move the `main` function from within it to `src/bin/ytitler.rs`. Note that from within `ytitler.rs` you will have to refer to your library as if it is a crate, e.g. `use ytitler::load_playlist;`.
Yea, that’s more along the lines of what I am talking about. There are lots of ways to implement it, no doubt. It would be interesting if etcd implemented something like this. I think the piece that you were missing was the “distributed locking” piece. I’m just talking about a type of locking mechanism. 
&gt; The fact west-europeans cannot compete (the timezone issue). &gt; ... &gt; The difficulty of the puzzles is not correctly balanced. Some puzzle are insanely simple to solve and some others take you hours (if not days if you don’t have a lot of spare time). Sometimes I felt frustrated at this, because I’ve been lacking sleep time for weeks and had to go to bed in order not to destroy my physical health. I’m curious to hear about other west-europeans: how did you manage your time, social life and work life with AoC? Just to commiserate a bit with you... Competition requires sacrifice. I'm in the US on the east coast, and I couldn't realistically compete either. Not because I physically couldn't---no timezone can physically prevent you from competing---but because I wasn't willing to sacrifice in order to do it. This is entirely reasonable! In my situation, my work schedule is 6:30am-2:30am to avoid traffic, since I commute from the burbs into Cambridge every day. There's no way I could stay up until midnight (when the AoC puzzles are released) just to start to work on the problem without either 1) changing my work schedule or 2) neglecting my family by changing my sleep schedule. In terms of varying difficulty, again, I think this fosters competitive spirit. Some problems I could not solve in my allotted time for the day, so I had to put them on hold until I could go back to them on the weekend (or whatever). That wasn't easy. I think that's the point, too. It's the same deal in competitive sports (which I grew up in).
I also quit after a few days (basically, when the puzzles took more time than an hour or so), because I value contributing to my open source projects more. 
Paste the definition of Struct Gui?
But there is a variant with only the fulfill callback as well. The reject one is optional.
r/playrust maybe?
In response to "but there is unsafe somewhere in my dependencies so why bother?" I recommend reading: https://www.reddit.com/r/rust/comments/a7kkw9/looking_for_someone_to_change_my_view_on_this/ec3r38n/
As an interesting data point, I'm curious whether you were aware of The Book before reading this advice. If not, maybe it should be even more prominent in the website.
I knew about it. I was trying to find out if there were any apps or sites that teach Rust the way SoloLearn etc do
Yes. The genius of Hypothesis is getting the ergonomics right without static types. And for eg shrinking, the change in design needed not to rely on the types actually turned out to be a backport-worthy advantage in the end. I mentioned that Go is one of those languages where the ergonomics will be terrible; and the whole language community and culture is opposed.
Gotcha, good to know.
Not currently. There’s a ticket open but nobody has implemented it yet.
Oh okay thank you. I might look into adding that or something. Thanks for answering!
&gt; I believe that MessagePack is much more suitable in embedded context than protobuf. Not really. Protobuf is more compact, since it doesn't encode field names and enum variants as strings. Protobuf for embedded systems works great - I built a quite complex device using `nanopb` in C. However it seems like there isn't a comparable Rust lib available up to now. 
Alas, I don't know about rust in particular. But in eg Haskell that's definitely the case. It's easy to see when you look at the analogy between types:kinds to values:types. Most values belong in multiple types. And some values even belong in an infinite number of types.
You can do most of these in no-std without allocations. See the C `nanopb` library for ideas. In general: - Repeated fields, strings and byte arrays can specify a maximum size, and then a fixed-length vector (like the one in the `heapless` crate can be used). - Alternatively, the deserializer can return iterators over datastructures, which allow to lazily deserialize infinite-length arrays. Or callbacks for each item can be used, as like nanopb does it. Usability isn't as great as within a normal environment, and extra annotations are needed, but most things are solvable. Recursive messages probably aren't, but I would argue that in most definitions they aren't needed. 
I really like it. Allows with a single look to determine whether a library is suitable for an embedded system. Compared to that in C, many people think libraries might be usable on those environments just because they had been built in C too. However in reality they might be far from usable, e.g. because they allocate a ton of dynamic memory under the hood.
&gt; writing this using unsafe code might be easy, but writing sound unsafe code is actually quite hard. This is exactly what I am thinking. AFAIK, the only ways to ensure true safe and soundness for memory safety are either using safe code or using unsafe code along with formal methods. However, using formal method to verify codes is non-trivial. Therefore, I think it would be better to avoid unsafe if it can be done. 
Thanks for the reference. I fully understand there are needs to use unsafe codes when dealing with low lever system calls, FFI, directly interfacing hardwares, and in certain performance sensitive cases. But it is surprising to me that unsafe is a must when dealing with very common data structures such as linked list or trees. 
Wow thanks for introducing me to StructOps. I prefer the inline declarations way more than using clap, and it uses clap as a backend so I get the upsides from it anyways!
This is a sub for the rust programming language, you're looking for r/playrust.
hmm, if you done a lot of research on rust GUIs and haven't found anything, then there's probably not anything ready for your use unfortunately
It's fixed in nightly.
&gt; I'm not really interested in immature libraries still in BETA etc which may ultimately fail and force me to rewrite my GUI. Unfortunately this is largely the current state of things. The only stable aspects are fairly low level libraries that you would need to build on top of quite a bit. Nothing like QT or whatever just yet. I suggest checking again in a year or so. These things take time. 
:D
It's not even letting me load into the server it just says I'm banned now.
I was just having a laugh. You posted in the wrong subreddit. This is the Rust programming language, not the Rust video game.
Have you seen [Azul](https://azul.rs/)? Also this [thread](https://users.rust-lang.org/t/current-state-of-gui-development-in-rust/11643/106). 
Thank you, will do!
Great! Will have a look after the weekend. 
(Espressif employee here) we are planning to release our work on LLVM for Xtensa soon. It can already compile and run most of the ESP-IDF, and we are cleaning up code a bit prior to the release.
Yeah, if you only depend on `next()`, I believe that it works out.
Shhh don’t ruin the joke
What library are you using for this?
 let document = kuchiki::parse_html().one(html.clone()); 
if your needs are simple maybe use bindings to libui.
I'm glad to hear that :). This doesn't quite answer the question if you want to upstream to the LLVM project? Also, are you taking contributions? Can we help out in any way? 
No, I don't publish it yet, but I can if you wish. Ideally it should be merged in the main quick-protobuf repo, but it may be blocked by significant changes I made.
Programming Rust is a very well written book and I can credit most of my real understanding of Rust to it. I did find the Mandelbrot example hard to follow at first but had no issue with the rest of examples. I highly recommend the book.
I've wrote a windows-only GUI minesweeper game in Rust, but its libraries are immature, so maybe you won't be interested in it though. Check it out anyway: [https://github.com/crlf0710/charlesmine-rs](https://github.com/crlf0710/charlesmine-rs).
Hey. Welcome to Rust! I also came to Rust from Python and am a big fan of both languages and both communities! It seems you've already received some good responses below, but I had some free time tonight and it seemed like a fun exercise to figure out how I would write what you're trying to do. So that's what I did. Hopefully you find it helpful! Below is a Gist of my take. A couple of really important caveats: First: There's no way I'm doing everything right here (still learning Rust myself, of course). Second: I tried to explain some things in comments along the way, but I guess I took a slightly different approach than the other responders, as I thought you might like to see someone actually "rewrite" your code from scratch as opposed to point out individual tips on such and such line here and such and such line there (both approaches I hope are valuable!). In any case, hopefully this is helpful and encourages you to continue with Rust. It's a great language and great community! One final note (to you and to everyone else), please let me know what I could be doing better! Oh - and one final note - This code might not work. It compiles, but I don't have access to the actual input files you're using; so I couldn't run / test it. Even if it might not work, hopefully the patterns / idioms used are instructive. Good luck with your future Rust code! https://gist.github.com/bcmyers/c8b603096f4ee4a81b6fee36a7939c88
https://docs.rs/kuchiki/0.7.2/kuchiki/ Ok, let's trace through the docs. Or just skip to the part below the line, since this part is just digging through to find where the `RefCell` is coming from. `parse_html()` returns a `Parser&lt;Sink&gt;` ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/fn.parse_html.html)). `Parser&lt;Sink&gt;` implements the trait `TendrilSink&lt;UTF8&gt;`([page](https://docs.rs/html5ever/0.22.3/html5ever/driver/struct.Parser.html)). `TendrilSink` has the method `one`, which returns whatever type `Sink::Output` is ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/traits/trait.TendrilSink.html#method.one)). For some reason the struct `Sink` doesn't show up in the documentation, so I had to go to the source code to find it. `Sink::Output` is a `NodeRef` ([src](https://docs.rs/kuchiki/0.7.2/src/kuchiki/parser.rs.html#45)). `select` on a `NodeRef` returns a `Result&lt;Select&lt;Elements&lt;Descendants&gt;&gt;, ()&gt;`, so when you unwrap it you get a `Select&lt;Elements&lt;Descendants&gt;&gt;`. ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/struct.NodeRef.html#method.select)). `Select&lt;Elements&lt;Descendants&gt;&gt;` is iterable, and the item it returns is a `NodeDataRef&lt;ElementData&gt;` ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/iter/struct.Select.html#implementations)), which is automatically dereferenced into an `ElementData` ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/struct.NodeDataRef.html#implementations), through the `Deref` trait). `ElementData.attributes` is a `RefCell&lt;Attributes&gt;` ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/struct.ElementData.html#structfield.attributes)). That's what you already found from the printout. ------------------------- With a `RefCell`, you need to call `borrow` or `borrow_mut` to get a thing that acts like a reference. It isn't a plain reference, since the `RefCell` needs to know when you lose the reference so that it knows it's safe to give out another one. Here you can treat the return value of `borrow` as a `&amp;Attributes` reference. `Attributes` has the `get` method to get an attribute's value from a `LocalName`, ([page](https://docs.rs/kuchiki/0.7.2/kuchiki/struct.Attributes.html)). There's no link to say what a `LocalName` is, but I'm guessing you can just put `"href"` there. See if it works. So the full thing is `link.attributes.borrow().get("href").unwrap()` if that last guess is right.
If all you care about is Windows and don't want to bet on anything that's likely to be abandoned or radically changed, you might try [native-windows-gui](https://crates.io/crates/native-windows-gui). It's just a thin layer on top of the [winapi](https://crates.io/crates/winapi) crate, so it's mostly exposing Microsoft's time-tested GUI APIs. Here's the [Hello World](https://gabdube.github.io/native-windows-gui/book/getting_started.html) example for your consideration.
Unfortunately, most of the GUI libraries are either wrappers for C/C++ libraries, or else are still very much in production. Conrod currently only has eleven issues open for its 1.0.0 milestone though, so it's certainly getting there.
&gt; but since only very very few people are being paid to work on Rust itself, we need everyone in the community to help out – in one way or the other. And preferably, on stuff on the roadmap. Why bother with a roadmap if "it doesnt matter because uhh volunteers"? &gt; The roadmap is mostly the latter, except that it combines what a lot of people have been asking nicely for and which is thus more motivating. If "no progress" is what "more motivation" looks like.. RIP rust.
You can create multiple TCP listeners before calling `tokio::run`...
I upgrade to Ammonia 2.0 and everything compiles now. &amp;#x200B; I had Ammonia 1.2 in my `Cargo.toml` and changed it to version 2.0.
Although I have to think it more thoroughly, the short answer I can give is privacy. Ideally, ListNode should not be a pub struct and a LinkedList user should never be able to access the ListNodes of a List. All accesses to the List should yield &amp;T and &amp;mut T and never the underlying types.
Maybe it's because you don't bother to look where you type.
As a rust beginner from python, thanks for all the detail. You've made me believe those differences between rust and python kinda "that's not so bad." Anyone know where can I find similar materials like this?
Thank you a lot!
I just wish they could capture type parameters from the enclosing functions so I wouldn't have to repeat them every time.
What does the universes change do?
I've looked over this - functionally it looks good, but if you want it to be readable to other rust programmers, there are a few things I would change. If you're interested in improving the style / usability: - the function/const in `lib.rs` `_ADDR` and `_make_endpoint` could probably be called just `ADDR` and `make_endpoint`? It reminds me of the convention in python or other languages to make things private by the name - but since rust has explicit `pub` and implicitly makes everything else private, this is an anti-pattern. At least style wise. Similar thing with `_build_response` and other private functions, not having `pub` already marks them as private? The other issue with this is that rust uses a leading `_` to indicate "this function is expected to be unused". If you name functions or variables like this, you won't get unused code warnings for this functions and variables that you otherwise might. For this reason I'd also recommend not using variable names like `_headers` in `_build_response`. - `_build_headers` in `request` has unnecessary lifetime bounds. Rust infers lifetimes in most cases, and a declaration like `fn _build_headers&lt;'a&gt;(map: &amp;'a HashMap&lt;String, String&gt;) -&gt; Box&lt;HeaderMap&gt;` is exactly equivalent to `fn _build_headers(map: &amp;HashMap&lt;String, String&gt;) -&gt; Box&lt;HeaderMap&gt;`. The latter is usually preferred for simplicity. - In `types.rs`, you have a number of non-standard enum variant names. I'd recommend instead having regular `MixedCase` enum variant names and using the `#[serde(rename_all = "...")]` to have them converted to the right casing when serializing/deserializing. See https://serde.rs/container-attrs.html: you can do `#[serde(rename_all = "snake_case")]` for most of them, and `#[serde(rename_all = "SCREAMING_SNAKE_CASE")]` for the first one? This would just be so you can use the standard style to reference the variables in the rust program, and the rename_all attribute keeps a correct serialized form. - In a few places, like when calling `make_endpoint` in `payment.rs`, you use `some_string.as_str()` to convert from `String` to `&amp;str`. This isn't explicitly bad, but it's usually more standard to just use `&amp;some_string`. Like `make_endpoint(&amp;format!(...))` gives a more intuitive description of what you're doing - you're formatting a string and borrowing it- the fact that the result is `&amp;str` not `&amp;String` shouldn't matter too much to anyone reading the code. `as_str` has a place, and is necessary for some code dealing with generics, but `&amp;string` conveys the meaning more correctly in most places. Few things that could have a small impact on performance, but overall won't make much of a difference: - In `request.rs`, you convert your `reqwest::StatusCode` to a `String` immediately after the request finishes. This will allocate a new string, and is in general a less efficient representation than what `StatusCode` has itself. In addition, it hides things like whether the status represents a success or not. I would recommend not converting to a string until you need to display it, and just storing `StatusCode` in `ResponseData`. - In `request::_build_headers`, you box a concrete type `HeaderMap`, return it, then immediately unbox it using `*` every time you use it? This seems unnecessary. Rust deals with direct, concrete types well, and as far as I can tell this just introduces an allocation when you wouldn't otherwise need one. I'd recommend just returning `HeaderMap`. - You currently store a `Vec&lt;(String, String)&gt;` for headers in `ResponseData`. The conversion of the value to `String` will currently fail if any of the headers has non-ASCII data. If you don't need to immediately use it as a string, I'd recommend storing `(String, reqwest::HeaderValue)` instead and just using `.clone()` rather than the whole conversion to string. - Similarly, when you're building headers, you first create a `HashMap&lt;String, String&gt;`, then convert it to a `HeaderMap`. This isn't a bad idea at all, but it will be slower than just directly creating a `HeaderMap` and avoiding the intermediate value. Unless you're pressed for performance, the current way is perfectly fine. --- With all that said, I think the library is quite well built over all! There's the tiny bit of non-standard style, and you could _definitely_ use some documentation, but it's well modularized and reasonably efficient for an API crate. My style notes are all definitely nit-picks, and while I recommend making them, all they do is bring the crate into more standard style so more people can read it with less effort. Honestly, if you were to change one thing, I'd say adding doc-comments for public methods and a `README.md` with a crate description and example usage would do the most good. All in all, cool project!
The people of Amethyst game engine recently added some GUI options for their editor, still as most ppl pointed rust doesn’t have any mature GUI yet. But you can check the [post about it in forum](https://community.amethyst-engine.org/t/exploring-possible-ui-toolkits-for-the-editor/75) 
Well, now I feel stupid. That was indeed it. Thanks!
I had a go at AOC 2018 in Haskell. In the end I became frustrated that so many of the puzzles required lots of state management and seemed far away from Haskell's sweet spot. It took me something like 6 hours to complete problem 15 and I quit thereafter. My instinct is that I would have had an easier time with Rust, but then I wouldn't have learnt anything!
Azul is not ready for production yet.
When 2-3 reddit comments are more substantial than anything I’ve ever read on medium, about anything, I know where the passion lies. Not long ago it was python. Also, get off my lawn! Fine, you can borrow it. Immutably!
The SYSTICK is optional on Cortex-M0 chips, and unfortunately Nordic didn’t implement one on the NRF51822 that’s used in the micro:but. It does have a TIMER2 peripheral that can be used instead, there’s a C example at https://github.com/NordicPlayground/nrf51-TIMER-examples/blob/master/timer_example_timer_mode/main.c, but I’m not aware of any pure-Rust implementations of the timer.
Once you got the gist of the language, you will greatly benefit by joining a project. Many Rust projects have mentored issues. This will give you valuable real-world experience.
I did it this year and last year. In both cases I completed 7 days, but ultimately stopped because some of the problems just took up too much time. I might do it again next year, but I expect a similar pattern of quickly falling behind on the days and stopping around day 7.
In this case, I think using [clippy](https://github.com/rust-lang/rust-clippy) will give you a lot of good feedback. Further you should consider formatting your code using [rustfmt](https://github.com/rust-lang/rustfmt). I know a lot of people have their own style that they like the best, but I do think having a common style for a language is valuable. E.g even though I didn't like the way `go fmt` formatted my code, I used it to maintain a consistent formatting in my code base. That way anyone that is used to the style will easily be able to read the code. After sometime I think you will learn to appreciate that every Rust code base looks the same if we all use `rustfmt`. 
Thanks /u/dt-wood , that was quick! There is an nrf51 crate on crates.io, so I'll check if what I'm trying can be done with that crate.
I have been looking for something like that. Could you name some so I can start looking there?
hi, thanks for your review. Some of the things you mentioned like accepting directly HeaderMap or HeaderValue, I used custom types in order to isolate libraries from my code so if I decide to change the underlying request library one day it won't affect my code at all exported functions will still stay intact 
I guess they did ask for it...
They are tremendously important in some RTC applications though, because adding and removing element can be done in constant time at any known position. Especially stacks and queues (or any container where you only add/remove at a few positions) are often implemented this way in RTC.
Try libui-rs?
You are a hero for giving this level of quality feedback. You deserve gold for this.
If you need a tree or graph and think a variation of a linked listed is suitable then you probably shouldn't be the one implementing that data structure. This sounds very harsh, but the truth is that in most cases you should leave data structures to the experts and just use the code they put out, because they've already done all the stupid mistakes that you and I would commit if we tried to do their job. Unless you are doing RTC or embedded systems, locality is way too important to use linked lists or similar structures. So if you are programming for any PC or video game console or smartphone or anything that has a cache, you will use an array like data structure under the hood.
Which is what you should do anyway because caches are a thing. 
You will seriously struggle if you don't take the time to read and learn the fundamentals. Rust is the worst language to use for trying to hack something together without understanding how things work. You don't have to read every chapter of the book before you get started but you will eventually need to read every chapter in piecemeal. The book is the best resource available to help you learn Rust. 
I found the Programming Rust memory allocation diagrams very valuable. It's a useful book.
True to that. But I'd liked it better if they explained heap and stackframe. Also I found the opening chapter not good at all (to the point where I skipped the rest of it after a while)
The very definition of Box is that it's an _owned_ pointer, in contrast to say Rc which is a _shared_ pointer.
I grew up in competitive sports as well (race swimming) but I don’t really see the relationship with difficulty. The difficulty (in swimming at least) is only related to your own performance, not the other racers. Thanks for your feedback. Yeah, east coast people might have gone through the same issues. I wish I had enough time to complete all the puzzles (and I think I could have done them all), but damn, time is a valuable asset.
[this-week-in-rust.org](https://this-week-in-rust.org) has a weekly updates list.
Banker's method to create a functional data structure is possible too.
Native-windows-gui is gplv3 so unusable if you want your code to be anything but gplv3
&gt; I grew up in competitive sports as well (race swimming) but I don’t really see the relationship with difficulty. The difficulty (in swimming at least) is only related to your own performance, not the other racers. It's not about varying difficulty itself. It's about testing your mental fortitude. Varying difficulty in puzzles is a way to throw you off balance. Competitive sports also test your mental toughness, but in different ways.
&gt;I linked the Learning Rust With Entirely Too Many Linked Lists in my question. Ah, now I feel dumb for missing that. &amp;#x200B; I think others have done a good job explaining `safe` vs `unsafe` and their relation to performance so I won't repeat what they said here. If you are still unsure about something I'd be happy to try and explain it with my (admittedly limited) knowledge.
I concur
Welcome to reddit, please double-check the subreddit's topic before posting. /r/rust is for the programming language, meanwhile /r/playrust is for the game
Wtf
I have a Struct which is made up of other structs made up of other structs and so on. I wanted to derive Debug on them all so I added that to the top of each Struct definition. Is there a better way to say to derive Debug on the parent and all of its children?
Hey, while you have clearly posted in the wrong subreddit this is literally the nicest /r/playrust post i have read so far, so props to you. If you like you can make videos about Rust, the language. Something that would benefit from a visual medium would probably be lifetimes and how to implement graph structures in rust. Or something about recursion. Or how (proc)-macros transform the token-stream.
I just tried Azul last night and it is currently so broken that copying and pasting even the Hello World from their front page causes tons of errors and doesn't compile.
I'm having trouble finding a legit use case for unit tests. I feel like when I see must unit test examples that they are things which would be prevented by Rust's compiler anyway. Does anyone have any examples of a really world test they have which has saved them in some way?
Can you share a snippet of the code you currently have?
&gt; don't want to bet on anything that's likely to be abandoned Unfortunately [the readme](https://github.com/gabdube/native-windows-gui) says: &gt; Native Windows GUI is no longer maintained.
I ported cat and yes to Rust. They were awesome projects to get me started/more familiar with the syntax.
Porting simple Unix tools to be written in Rust like cat, and yes etc.
Those aren't errors (I think) since they're actually at the `DEBUG` level. In a project where I use `actix_web` I actually restrict what comes out in the logs for `tokio_reactor` when I use `fern`: ``` // Setup/Initialize fern based logging pub fn setup_logging() { // Configure logger fern::Dispatch::new() .format(|out, message, record| { out.finish(format_args!( "{}[{}][{}] {}", chrono::Local::now().format("[%Y-%m-%d][%H:%M:%S]"), record.target(), record.level(), message )) }) // Add blanket level filter - .level(log::LevelFilter::Debug) // - and per-module overrides .level_for("tokio", log::LevelFilter::Warn) .level_for("tokio_reactor", log::LevelFilter::Warn) .level_for("tokio_core", log::LevelFilter::Warn) // Output to stdout, files, and other Dispatch configurations .chain(std::io::stdout()) // Apply globally .apply() .unwrap() } ``` Looks like the client is [closing the connection early](https://www.oreilly.com/library/view/http-the-definitive/1565925092/ch04s07.html) other than that is it possible that your handler is trying to send data that has the wrong content length specified or something?
Wrong. It is entirely legal to sell the application to customers or business partners or for usage in house only. And you only have to distribute your source code only to those parties that have received the binaries. If you do stuff in house and the binary belongs to your own company, other company has no right to ask for the source code.
Just Windows GUI? Use the amazing win32 api by using the equally amazing winapi crate by the amazing author who posts on this amazing subreddit. 
I played around a bit more with the code, and added benchmarks to the PR. The gist of it is that while the generated loops perform better in general; for some reason they foil LLVM's ability to transform loops into closed formula, which in hindsight is probably what prevents the const-folding. I have no idea what the substantially more complex code currently used by `RangeInclusive` can be transformed while the one I submitted cannot; however @ranman demonstrated that it appears the transformation is fickle to start with: using `(0..n).chain(::std::iter::once(n))` to do the sum by hand, the transformation kicks in with `for_each` but not with a `for` loop. Of course, `for_each` is simpler than `for` in the case of `chain`, but it's still unexpected to see such a trivial syntactic change have such drastic consequences; and my PR might very well be hitting the same limitations.
Very cool and in-depth read. Thanks for the writeup!
I have only tried comparing it against [`chashmap`](https://docs.rs/chashmap/), not against any other concurrent hash tables. In theory it should be pretty easy to plug in another map just by implementing the [`Backend` trait](https://github.com/jonhoo/rust-evmap/blob/d307999c1ad78d10ecb6ea911b6e94d36bc841ca/benchmark/src/main.rs#L165L168) in the benchmarker, and then adding [a section](https://github.com/jonhoo/rust-evmap/blob/d307999c1ad78d10ecb6ea911b6e94d36bc841ca/benchmark/src/main.rs#L133) for benchmarking that backend as well. `libcuckoo` would be a very interesting comparison point, though you'd have to write a Rust wrapper for it first :) It's also worth noting that `evmap`'s performance is [primarily bottlenecked](https://news.ycombinator.com/item?id=18840399) by that of Rust's `HashMap`, which it uses internally. However, `evmap`'s design is independent of the underlying hash map implementation (which I consider a huge feature!), so even if `evmap` does appear to be slower, using a faster underlying hash table (like [`hashbrown`](https://github.com/rust-lang/rust/issues/55514)) may change the numbers significantly!
Sure, I would love to see you fight the borrow checker on stream!
Writing a UI directly against Win32 is a fate undeserved even by your worst enemy.
Yep, even for Win16 the sane among us were already using either Object Windows Library or Microsoft Foundation Classes.
That was the part I was missing. Thanks for the replies. If you ever flesh it out, I'd be interested to see it. 
The current method of implementing data bindings in Azul for your own isolated components is to use unsafe as well - hopefully the author figures out a better pattern for this in the future (or at least encapsulates this unsafely into a safe abstraction that new widget authors can use). 
Without any indication of what’s being locked and how, this isn’t a complete question. And it’s impossible to avoid talking about timeouts. In the super simple case where clients want mutex access to the same server they have keepalives against, then sure, run in single thread with max one connection, if you happen to control the entire stack top to bottom. (I think many TCP implementations manage keepalives invisibly, such that your listener loop could think it has moved on but multiple connections stay alive, so this might make the whole discussion moot.) But a single node single thread computation doesn’t sound like a realistic use case for distributed locking, it just sounds like you’re creating either a massive bottleneck or running a tiny workload on way too many nodes. If TCP clients are trying to mediate mutex access to a separate resource by using a single threaded single connection server as the lock, then that might fail when: 1. server kills A due to missed acks 2. B connects and gains “mutex” 3. There’s a partition on A’s line, some other delay or GC pause or page fault such that it knows none of this, and its timeout has not yet fired so it still thinks it owns the resource and continues writing or reading. TCP clients don’t magically know when connections die. That would require synchronisation, i.e. an active unhindered connection, while TCP is obviously designed to continue working despite lacking one of these. So the end of this mutex can only be defined by a timeout. You would need a second layer of timeouts to be sure that all the first timeouts had drained. Say client keepalives are guaranteed to be less than 3 minutes (as is typical); the server has to refuse new connections for at least 3 minutes to be sure the old connection is actually dead and the client has notice. Plus however long the upper bound is on actually freeing the resource. Just don’t do it. There are better distributed locking systems that have actually be designed and tested to do that job, not just as a cache for connection setup and tear down cost where the implications of getting it wrong are utterly inconsequential.
Including the source code is generally a deal-breaker for most shops...
&gt; A const implementation of a trait T for a type A is an implementation of T for A such that every function is a const fn. Wouldn't this be a problem if the trait decides to add a default-implemented function? That wouldn't be `const`, so code using it as such would break.
That's being discussed in the following issue: https://github.com/rust-lang/rust/issues/46213 The general concern seems to be that more complicated discriminant extractions (i.e. determining the variant of the enum) can have detrimental effects on optimization.
No, there isn't but that makes sense: You are asking the compiler to go through all the fields of your struct and derive Debug for all types you defined yourself. Suddenly, a type defined somewhere in your crate implements a trait at a totally different location. You as someone who needs to maintain the code would be forced to trace through the definitions of abitrary structs, go through each field until finally you know that some struct impls a given trait. That's totally unintuitive and opaque. Nonetheless, you might be able to write a procedural macro that does exactly that. But I am not sure about that.
Yes, this is what I mean. Can you give an example?
Well, the default implementation *could* be `const` if it were declared as such; *e.g.*, ``` trait Foo { fn bar(&amp;self, i32) -&gt; i32; const baz(&amp;self) -&gt; i32 where Self: const Foo { self.bar(self.bar(1)) } } ```
Yes, my point is that the trait could come from an upstream crate, and that could add the function as a non-breaking change, while it would still break the code in this case.
That’s why I’m going to read the book! The knowledge from the book will probably carry over into other languages 
Good advice thank you that’s exactly how I’ll approach this. 
&gt; Wouldn't this be a problem if the trait decides to add a default-implemented function? That wouldn't be `const` so code using it as such would break. This is indeed a point considered in the post. I would say this is a problem that can be resolved later (though before stabilization), and I personally would favor explicitness here: - A `trait` is `const` if marked as such: `const trait ...`. - If a `trait` is `const`, then every single method must *also* be marked as `const`. I don't see much benefit to saving 6 key strokes via either deduction (considering the `trait` to be `const` if all methods are) or sugar (considering all methods to be `const` if the `trait` is). On the other hand, I do see benefit in having it being fully explicit: - Obvious to the reader: - No deduction means no need to scan the full list of methods to see if they all are `const` or not; quick test: is `Iterator` `const`? - No sugar means no need to go back to the top of the `trait` to check whether the method is callable in a `const` context or not. - Double-checking for the maintainer, to avoid accidental "loss". 
I *really* appreciate that this design takes care of the *conditionally* `const` implementation case. I can see an immediate benefit for the `Add` trait, for example, which can be implemented `const` for built-in integrals, but not for Big Integers, Matrices, etc...
The most useful ones for me are behind macros, so they might not be too easy to follow. But have a look at [this one](https://github.com/KillTheMule/nvimpam/blob/master/src/card/keyword.rs#L387), it very simply tests two not too complicated functions, but helped uncover quite some bugs after writing the functions subtly wrong at first, and when changing them later. The more complicated tests that were even more useful for finding somewhat subtle bugs are e.g. [here](https://github.com/KillTheMule/nvimpam/blob/master/src/folds.rs#L367).
&gt;let threads = chunk.into\_iter().map(|url| spawn(move || fetch\_one(&amp;url))).collect::&lt;Vec&lt;\_&gt;&gt;(); threads.into\_iter().filter\_map(|t| t.join().ok().and\_then(|v| v)).collect() I think having only one `collect()` leads to better performance. let threads = chunk.into_iter() .map(|url| spawn(move || fetch_one(&amp;url))) .collect::&lt;Vec&lt;_&gt;&gt;().into_iter() .filter_map(|t| t.join().ok().and_then(|v| v)) .collect();
Wrong. Once you sell the application to any customer or business partner for use "in house only" they have the right do demand the source and distribute it (and the binaries) publicly under a GPL3 license.
The druid toolkit is currently windows-only but is very much not ready for prime-time. That said, if you're doing very simple things you might be able to make it work.
What is the difference between \`cargo build\`, \`cargo build --target\`, \`cargo build --release\`, etc?.
Hi, thanks for your reply. I understood that part; the part that I was missing was how to put those multiple TCP listeners into the tokio executor, which /u/daboross kindly showed an example for how to do.
`--release` turns on optimizations; without it, you're building in debug mode. `--target &lt;TRIPLE&gt;` allows you to build for a different target than your default, which is used in cross-compilation (like choosing to compile to wasm.)
and again. notice difference between rust playing and rust programming...
We are using web-view. It is MUCH lighter weight than Electron, and HTML is an established UI layer. Unless you are going for national e widgets, then this is my recommendation. This is what I eventually settled upon :/.
I definitely agree with the ethos of this. If we want Rust to grow and eat the world, we need to empower the people writing the code that reaches outside of the confines of safe Rust and interfaces with that unsafe world. (A big thanks to everyone who has contributed to this effort; I'm not trying to shame anyone!) 
The two collects are necessary to ensure all the threads are created before we join() the first one. Otherwise, we'll create the first thread, wait on it, then create the second thread and wait on it, … which would not parallelise the IO.
Ok, that's amazing !
That makes sense - sound like a good idea! I'd agree with your choice there - modularzation over complete speed. I just included it since it _could_ have performance drawbacks. With HeaderValue/StatusCode, that does make sense. I was thinking more with the mindset of functionality and with the assumption that you could always do a major version bump when changing backing libraries. If you want to keep independent from `reqwest`, maybe you could make the fields private and only expose methods for getting `String`s and other info (success?, or maybe a `try_headers` method for header values as results so non-ascii doesn't cause a panic?) That way you could still provide the full functionality of StatusCode and avoid panicking on non-ASCII headers while still wing freedom to change the internal representation.
Is there any way to use OpenCV in Rust? I'm new to both and I see there is a crate in development with binding for OpenCV but I wasn't sure if I just have to wait on that to be done or if there's another way.
I've read that Option and Result are algebraic data types. Why are they called algebraic?
Check sciter if you are not afraid of a proprietary library. 
Typo in the title, should be "renderer".
Perfect, thanks a lot!
Oh ok. I see your point now. :)
&gt; That's as low-level as it gets, which, of course, carries the obvious advantages and disadvantages A small correction — Vulkano is actually *higher* level than gfx-hal (what I assume you meant when you were talking about gfx-rs). The lowest level Vulkan library for Rust is ash, which is basically just Vulkan function pointed bindings plus a few helpers to let you pass slices instead of pointer + length.
Thanks for the tip on filtering out the debug messages (I did want DEBUG output from my own code, and I just happened to notice these messages as well). You may be right about the client closing the connection early. I have no idea if the `Content-Length` is being set correctly, but that'll be the next thing I check.
Nice piece, thanks! I think we need to do the incredibly capital-H Hard thing and build a formal semantics for Rust. I know folks are working on this: IMHO it needs to be a priority. English is a good language for describing a formal semantics; it's not so good for specifying one. One effect of requiring a formal semantics would probably be to slow down the pace of change in Rust: new features would have to be integrated with the semantics as well as the compiler. I don't see this as a bad thing: it would make sure that folks have thought twice about the thing, and make sure that it is understood what is being added.
&gt; Without any indication of what's being locked So, as mentioned in the post, the thing that is being lock (at least in the scenario I laid out) `could be something like: "/system/locks/&lt;lock-id&gt;" in our theoretical KV store like system.` Think of something like `etcd`. This could just be a new feature of `etcd`. A client could acquire what would be called a "Keepalive Lock" (I used the term heartbeat lock in the post). Consider the following: - A client requests a "keepalive lock" on the key `/locks/&lt;lock-id&gt;`. - The server (the `etcd` like system) receives the request, checks the key `/locks/&lt;lock-id&gt;` to see if it is currently held. - if it is not held, then the server responds with a frame indicating that the client has acquired the requested lock. - if the lock is held by another client somewhere, then the server will respond with a frame indicating such. - the lock will be held in a mutex like fashion for as long as the client's connection with the server is held. - as soon as the connection is severed (for any reason whatsoever) the lock will be released on the server side. So, as you can see, this is very similar to `etcd`'s watch interface, where a client can watch a particular key, receiving frames from the server with information on updated values for the key. In the scenario above, the feature could be implemented such that if multiple clients have submitted a locking request for a key, the key will be leased out to each caller in order. As one client drops its "keepalive lock" connection (because it is done with its work, or whatever), then the next client will receive the lock, so on and so forth. If a client makes a locking request and does not immediately acquire the lock, it could just drop the connection and move on with its life. Hopefully that clarifies things a bit.
Why wouldn't it be const for big integers?
For now, there is no plan to have const functions being able to return dynamically allocated memory. Big Integers, being unbounded, require dynamically allocated memory.
&gt; This approach requires texture mip-mapping, which is not currently implemented in Vulkano. There is no high level helper API, but blitting the images to generate the mip maps like suggested by vulkan-tutorial.com works just fine with vulkano.
How does Rust currently fare in the game development world? Are there plans for it to become like C++ for Unreal Engine or like C# for Unity, perhaps an entirely separate entity even ?
For applications, I find that tests aren't needed that much, but for library code, I find them indispensable. How else will you know how to call your code?
I think there is a proc_macro to add attrs to all items within a scope: https://GitHub.com/regexident/apply_attr or something.
An algebra is a set of elements and a set of operations closed over those elements. Types have a set of elements; these are the individual types. For example, `()` or `bool`, though you might call those `1` and `2` respectively. Rust defines the sum and product operations on types; sum being the operator that produces enums, and product producing tuples (or structs.) Every operation takes one or more types and produces a new type that is still a member of the "set" of types. Because we can define a set and operations over it for types, we can view the types as an algebra. As an example, the Option type is defined as: ``` enum Option&lt;T&gt; { Some(T), None, } ``` This can be algebraically defined as `1 * T + 1` - that is, a pair of unit and a T (signifying Some(T),) or just a unit (None.) Similarly, `Result&lt;T, E&gt;` can be interpreted as `1 * T + 1 * E`. (You can intuitively understand these equations to mean "the number of inhabitants of their type"; `Result&lt;bool, ()&gt;` is `1 * 2 + 1 * 1` which simplifies to `3`; and indeed there are 3 possible values of that type: `Ok(true)`, `Ok(false)`, and `Err(())`. Of course this is less useful when dealing with types like `&amp;T`, since a pointer isn't really countable in the way a `bool` is.)
Interesting, I've tried following vulkan-tutorial, but ran into this issue: [https://github.com/vulkano-rs/vulkano/issues/989](https://github.com/vulkano-rs/vulkano/issues/989)
http://arewegameyet.com/
This seems pretty cool, better `const fn`s would be awesome for some things (embedded, for example). While reading the article, I found some (what I think are) minor errors: 1. Under the heading "The universe of types", after the first example the text says "`X` implicitly has type `const u8`", but in the example the base type is `bool`, not `u8`. 2. The comment in the last example in the same section explains that the error is that "`foo` expects a (run-time) `A`, but we've given it a `const A`". However, in the next paragraph it is explained that `const` types can be implicitly converted to non-`const` types. I think the correct error is that the return type of `foo` is `()`, but the return type of `bar` is `const ()`, which would be a conversion from non-`const` \-&gt; `const`.
Have you delved into minimizing motion to photon latency? I skimmed the article but didn't see any discussion on it.
They are called algebraic data types because both are defined using enum types. The term _algebraic_ comes from mathematics. Algebraic expressions like `2x + 3y` consist of sums and products. These are all algebraic expressions: * `3x` * `x * y` * `x` * `100x + y` Enum types are sometimes called sum types, and tuples and structs are sometimes known as product types. The terms might seem weird at first - how on earth an enum type is a sum? What does a struct have to do with multiplication? Let me try to demonstrate with an example. Let's say we're trying to count the number of possible values in a data type. Seems simple enough. A single byte (`u8`) can have 256 different values. A pair of bytes `(u8, u8)` has 256 * 256 = 256^2 different values, because both bytes can be any of the 256. A tuple of three bytes has 256^3 different values, and so on. Similarly, if we have a struct like `struct Cake { layers: u8, contains_strawberries: bool }`, it has 256 * 2 = 512 different values. It doesn't matter if the values are in a tuple, an array or in a struct - adding an another field **multiplies** the number of combined values by the number of possible values the type of the field itself has. This is why tuples, structs and so on are known as product types. Sum types can be a bit harder to grasp. If we have an enum like `enum YesOrNo { Yes, No }`, it is fairly obvious that there are exactly 2 possible values. For simple enums, the set of possible values is the number of enum cases. However, let's say we have enum like this: ``` enum Cake { FlatCake, LayeredCake(u8) } ``` A cake can be a flat cake, or a layered cake with a number of layers. This means the type has 1 (flat cake) + 256 (layered cake with `u8` layers) different values. If we had two different types of flat cake (each with a different enum case) we would have `1 + 1 + 256` different combinations, and so on and so forth. Adding a new case has an **additive** effect, because the cases are mutually exclusive. Combining these, let's say we have the following type: ``` enum Cake { ChocolateCake { contains_strawberries: bool, layers: u8 }, FruitCake { contains_raisins: bool, layers: u8 }, BoringCake { layers: u8 } } ``` Now the number of possible cakes is (2 * 256) + (2 * 256) + 256. Following the same logic as maths, sum types, product types and combinations of them are called algebraic data types. 
This was a really nice explanation, unfortunately with the side effect that I now have a craving for cake. :-)
There’s some indie games, like Chucklefish’s new in development game. EA’s SEED division is using Rust, and some people quit it and founded a new AAA studio that’s using all Rust. Ready at Dawn is moving all future development to Rust.
i've always thought that rust/cargo should have a 'valgrind mode' for unsafe code especially. Since the number of unsafe regions tend to be a small part of the codebases it might be worth it to have it as part of the debug built too.
Dumb question, is there a more compact way of expressing the following: let mut vec: Vec&lt;i32&gt; = Vec::new();
You can write it as : let mut v = vec![];
&gt; let mut v = vec![]; Unfortunately, that's where I started out, but it gives the following error. ` Compiling playground v0.0.1 (/playground) error[E0282]: type annotations needed --&gt; src/main.rs:3:13 | 3 | let mut v = vec![]; | ----- ^^^^^^ cannot infer type for `T` | | | consider giving `v` a type | = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info) error: aborting due to previous error For more information about this error, try `rustc --explain E0282`. error: Could not compile `playground`. To learn more, run the command again with --verbose.` 
Totally agree, this sounds like important work and all these items feel like we can make good progress in 2019. Much longer term, I'd love to see practical work on formal semantics, so for really critical code such as the implementation of containers, it would be possible to prove correct the use of unsafe. That is going to take a lot more time, but I feel that the use of Rust as a foundation, the resulting system will be a lot more productive than other alternatives, mostly because we're seeing safety guarantees compose. Proving a module in C correct basically means you have to start all over again when you compose it into a larger system, as there are so many ways the global invariants can be violated.
Having an extensive test suite gives you two things: 1. You have confidence that the basic blocks you use in your program/library are doing what you want them to. This way, when you combine them, and something goes wrong, you know that it's the combination that is faulty, which simplifies finding and fixing the problem. 2. If you mess something up accidentally - during refactoring or some such - you immediately know about it. My somewhat paranoid approach of having a unit test for every function I intend to use did save me several times. The last time was when I rewrote the parser used by my library. When I run the tests, I was immediately alerted that I'd messed up big time: I don't remember exactly, but I think four or six of them failed. Find the commit 'Rewrite the parser' [here](https://github.com/mpevnev/pfmt/commits/master). As you can see, the is a lot of 'fix ...' commits immediately afterwards. It was nice to be able to find these bugs fast, and find the source of them equally fast.
Thanks! The issues should be fixed now. (I've rephrased the second example so that it may still talk about the value passed to `foo`, which I think is slightly clearer, but you're right in that the return type is also a problem in that example.)
You can use the "turbofish" syntax to specify type parameters: ``` let mut v = Vec::&lt;i32&gt;::new(); ```
For an example of how to use the TIMER peripherals (it looks like there’s more than one), you could also take a look at the nrf41-hal crate (https://github.com/nrf-rs/nrf51-hal/blob/master/src/timer.rs). The ‘-hal’ crates provide a higher-level wrapper around the raw registers, and hopefully are easier to use, although can’t cover every possible use-case.
I first wanted to ensure the crucial parts of the glTF spec are implemented before I add VR rendering support, but as far as I know, SteamVR provides asynchronous reprojection, which I might make use of, because OpenVR seems like the best way to interface with VR devices.
You need to specify the type somewhere. It can be in the declaration but the type can also be inferred later automatically. For example: let mut v = Vec::new(); v.push(1i32); In real application the types are usually inferred from explicitly written struct fields and function parameters.
&gt; let mut v = Vec::&lt;i32&gt;::new(); D'oh! I was trying this but it wouldn't compile. ` let mut v = Vec&lt;i32&gt;::new();` Thanks!
Thanks. I was aware of the type being required (at declaration or later) but I wasn't sure of the best way to write it.
Could you clarify or share some source how could const fn return dynamically allocated memory?
I'm not completely sure that I understand it correctly why we need `const` in the trait bound. Is this because we want the exposed API to clearly communicate what is needed? If so, shouldn't the function being marked `const` itself be enough to communicate that? The idea of `const impl` and `const trait` sounds like a good idea regardless. One thing I'm a bit concerned is what it means for breaking changes. Anything dropping `const` is apparently going to be a breaking change. Previously it was just at single function level, but now we are extending it to `impl` and `trait` level, which can be trickier to make a judge call for whether one should be given `const`. It's probably similar to the situation of `Copy`... We may don't want to encourage library authors to use `const trait`, and probably should be very cautious for any usage of it in std?
Small parts of the code, but also usually amongst the most performance critical I would guess.
This isn't really Rust specific question. In a dynamically typed language you may write more tests because the language allows things that Rust doesn't. However Rust doesn't prevent all bugs and with proper unit tests you can be more sure that your code works correctly.
After a friend mentioned how `pytest`'s `assert` works (&amp; how it provides that level of detail), I got curious and realized that you can absolutely achieve this kind of thing in rust with proc macros ([proc_macro_hack](https://crates.io/crates/proc_macro_hack), in fact). So here it is: an assertion macro that can automatically give you details about the actual values that caused certain assertions to fail. Current limitations: * It only supports binary and unary operators, but it should support ~all of them: So you can test that `x &gt;= y` and get meaningful test failures! * Of the binary operators, only the left and right branches are evaluated like that; if you chain `foo == bar &amp;&amp; baz == qux`, it will show you the left and right sides of the `&amp;&amp;` for now. Future work! Please let me know what you think; I hope this ends up being useful to somebody (:
You could try an interface where `T: IntoIterator&lt;Item=U&gt;, U: IntoIterator&lt;Item=u8&gt;`. That could accommodate both nested vecs and nested slices.
Not sure if this is possible. Is this done by any other application? In my experience many Linux/UNIX utilities will just read from keyboard if nothing is piped. I've found it useful in some cases. I think when reading from stdin it's better to require `-` as filename or flag like `--stdin`.
One thing I've noticed more recently is people implying unsafe is, like, evil or something. I'm not by any means advocating a cavalier attitude but the std is chock full of unsafe, for example. Unsafe is like a table saw, it's a hugely valuable tool that needs to be handled with great care and prudence. Developing a community-wide understanding of its role will take time, but it seems we are prone to extreme attitudes currently. 
Complete speculation on my part because I don't know how rustc would do it, but the constexpr interpreter should be able know how large a Vec or a String is. The compiler could store the "dynamically allocated" buffer in the binary like any other constant data, and create a Vec at run time which points to that address within the program binary (instead of the heap). This should be safe as long we only access the type through an immutable reference, and there's no interior mutability.
Let's be a little tricky :) let time = "01:13AM"; let new_time = format!("{} {}", Local::today().format("%Y-%m-%d"), time); // 1547255580 Local.datetime_from_str(&amp;new_time, "%Y-%m-%d %I:%M%p").unwrap().timestamp(); So it leaks info about year/month/day, let's add it into your time string and parse it again. Maybe not the fastest way, but simple.
You're looking for r/playrust, this is a subreddit about the rust programming language.
Thank you Steve for all your hard work, especially on documentation! You was the first person I heard to talk about Rust, and because of you I started looking into it. Good luck in your next adventure!
There's been work on making [miri](https://github.com/solson/miri) work kind of like a valgrind for unsafe. Which is mentioned in the posted article.
&gt; 6:30am-2:30am Is this normal game play or am I not doing life correctly? 
This should work: let time = NaiveTime::parse_from_str(time, "%I:%M%p").unwrap(); let local = Local::today().and_time(time).unwrap(); let timestamp = local.timestamp();
What would i flair then?
Your way is much better. Didn't know about \`and\_time\`.
I'm not sure what you mean by "normal game play," but it's pretty typical for folks with longer commutes to shift their schedule to avoid making the commute longer because of traffic.
Aha! I *was* missing something big—the local `and_time` method! I was thinking there should be something like the `NaiveDateTime::new()` method to construct a local time from a date and a time … but there wasn't a `new`. But the `and_time` method serves the same function and I missed it! Odd API inconsistency, that. Thanks for pointing that out! 
Well, that makes me feel a bit better about missing it too :) The API/docs really aren't that clear or consistent, which is a bit odd for such a high-profile crate. Maybe I'll open a PR—even as a rust novice, I feel like I can help out with the docs. 
Hi Jon Gjengset, I didn't want to sounds rude or anything but only trying to understand what is the tradeoff and when using evmap would be better. It sounds like evmap is better than a Hashtable based on read-write lock per bucket like chashmap. But Java standard Concurrent Hashmap for example is much more concurrent because it does not lock on read but simply perform a volatile read. see: http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/tip/src/share/classes/java/util/concurrent/ConcurrentHashMap.java#l934 So far my understanding is the main benefit of evmap is to leverage eventual consistency by not calling WriteHandle::refresh after each update. I am wondering if you investigated sharding reader state per bucket so that call to WriteHandle::refresh does not have to wait for all reader but only reader currently reading the bucket we are trying to publish? 
Regarding the threading, there's a library [Rayon](https://github.com/rayon-rs/rayon) (not affiliated, just a fan) that looks like it can make what you're doing much easier. Instead of creating threads manually, you give tasks to Rayon, which automatically creates threads for you and implements work-stealing for better performance. It also integrates very nicely with the standard library's iterators.
[https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.iter](https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.iter) [https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.values](https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.values) [https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.keys](https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.keys)
The most simple way would be to put it, or a reference to it, in a `for` loop. For example, lets say we have a map of people and their age let mut ages = HashMap::new(); ages.insert("John", 32); ages.insert("Ben", 24); for (name, age) in &amp;ages { println!("{} is {} years old", name, age); } This is possible because `HashMap`, and `&amp;HashMap` implements `IntoIterator`. If you're only interested in their names you would use [`ages.keys()`](https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.keys), if you're only interested in their ages you would use [`ages.values()`](https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.values). Hope this helps :)
Most things currently seem to use the "implicit-locked" versions of stdio, which only guarantees that individual writes will be atomic, not that writes won't be arbitrarily interleaved. The OS kernel will do this anyway, so the schemes I mentioned will be the same in this case, I think? It's a question of how sophisticated you want the stdio behavior to be in the presence of multiple threads. The current stdio chooses to provide an infrequently-used and slightly awkward option for making a sequence of reads or writes atomic via `lock()`. The downside is that this makes all stdio operations a bit slower and occasionally complicates things for users who don't care about getting several lines out as a chunk with separate `println!` calls. This current plan is not necessarily the wrong choice, but it is at least worthy of thought. Yes, the suggestions I posed would give this up, and yes that would be a change to how things are done. You could still provide this functionality as an opt-in thing, but it really only seems practical if all stdio operations in a multithreaded program opt in as a whole. Is it the case that `stdout().lock()` locks the whole stdio system or just `stdout`? Either way, the consequences of that seem problematic to me. If I want a thread to atomically prompt and read, I need to lock all of `stdout`, `stderr` and `stdin` so that I can be assured that the thread doing the read is the thread that prompted: this seems deadlock-prone and awkward. If it's a global lock, that means that programs can't pipeline data from stdin to stdout quite as efficiently. (Or am I confused? It does happen.)
Thanks again. While you're demystifying the chrono API for me, you wouldn't happen to know how to add to a date with proper wrapping, would you? (See edit to the OP). 
Thanks, that is a good approach. I was able to get the behavior I wanted by using `atty`. If StdIn is not a tty, it is somewhat reliable to expect a pipped value. 
Maybe I'm reading it wrong, but I think /u/Programmurr is refering to the fact that you seem to work 20 hours a day?
Holy crap this is such an awesome answer. Thank you so much! I wish all tutorials and explanations online were as good as this.
Oh. Hahahaha. Should be 2:30pm. Missed that. Thanks!
Distribution as is being distributed / clustering? Any thoughts on when it will be more polished?
can't you already print out a custom message with assert with all the information you could need or am I missing something?
Use Duration: let now = Local::now(); let after_5_min = now + Duration::minutes(5);
It depends *why* unsafe is used. If it's because the author is familiar with C idioms and uses it because to escape the constraints of Rust memory discipline, then yes, I think that should be roundly discouraged. Crates written in such a style should not be considered suitable dependencies. Of course, there are also very good reasons to use unsafe, for example the lock-free data structures in my synthesizer cannot be done without it. In those cases, there is almost always an effort to isolate the unsafe parts into the minimal component that needs it.
Yes, everything you can do with a macro you can already do by manually writing more code.
You can assert that x equals y and if that's not the case print out that x and y are unequal. But that's not so useful as you'd like to know what each of those was. So you change your error message to include that too. And do do the same for all your asserts. But you figure out it's kinda repetitive and there should be a macro that does it for you. That's what this package is.
If you are writing a function and you find yourself using `println` to check that it works the way you want it to work, you could instead be using tests. The benefit of using automated testing is that the tests stay forever, while your `println` checks would probably be deleted after you finish writing the function. Since the tests are there forever, if you have to fix a bug or add functionality to that function later, you have test coverage to ensure you don't break something which previously worked. The tests can also serve as nice documentation for what the function does. 
You can actually use valgrind with Rust now. Just make sure to switch to system allocator - on nightly it is already the default. There is also address sanitizer support which is a lot better than valgrind.
But I am talking about customer who want it private.
&gt; `foo` may only accept `const` implementations of the trait `T`. Otherwise, it would be possible to write invalid code inside the function body Would this prohibit any construction of values containing phantom types with non-const constraints? If so, wouldn't it be possible to simply disallow the usage of any members of the non-const trait?
Yep. In some ways, Python decorators seem do pretty similar to custom attribute-style procedural macros. The way they work is inherently very different, but the result is more or less a dynamic programming language equivalent, which can be used for fairly similar things. That said, I don't specifically what influenced that design in Rust.
Yes! It'll run rustc just fine.
If I understand this correctly then it is not possible for a `const fn` to use any methods from a non-const trait. Unfortunately it would make this code impossible (taken from [here](https://docs.rs/crate/lock_api/0.1.5/source/src/mutex.rs)): trait RawMutex { const INIT: Self; fn lock(&amp;self); fn unlock(&amp;self); } struct Mutex&lt;R: RawMutex, T&gt; { data: UnsafeCell&lt;T&gt;, mutex: R, } struct Mutex&lt;R: RawMutex, T&gt; { const fn new(val: T) -&gt; Self { Mutex { data: UnsafeCell::new(val), mutex: R::INIT, } } }
Since slices can only be accessed with references, it's illegal to move values out of them (as far as I can tell). What I need to do is loop over the values in a slice and move them to functions, and the only way I can think of doing this is creating a vector out of the slice and then iterating over that. This seems a bit overkill, and I can't find a function that returns an iterator or something. I'm fairly new, and just encountered this issue in a project I'm working on. Also, the slice comes from a Box&lt;[T]&gt;, and I'm thinking of just using a vector instead (although I plan on it being constant-sized)
Hmm... I almost resemble that remark.
Thank you so much for this kind of a review.
I think you could say that it is a feeling. When you look at your older Rust code and cringe--"Why did I do it that way? This way is so much better." Or think about the problems you have solved using Rust and realize that it really did scratch that itch--- that bit of a program that solved some issue you've always wanted to smash. Or you can think about all of your frustrations with other programming environments and consider how much better things are with Rust (or your next future language.)
Hmm, I hadn't thought about this before. Are you saying I'd put a `println` in the test or that the test would replace the `println`? If that's the case, how would I be able to see the actual data I'm working with to know what the issue is?
I think you've completely missed the point of your parent commenter though, which was that it's basically just a wrapper around native Windows API widgets. There's not a whole lot there to maintain. If your assumption is that every crate *must* needs to be updated constantly to stay "up-to-date", I think you're incorrect.
There isn't. This is a known fact. What we really need is a unified cross-platform crate that abstracts the best performing native GUI frameworks on each platform in a homogeneous way. This is *not* impossible. I used to think it was, like many appear to, but I became aware in the last little while of at least one language that compiles to native code and is not garbage collected with something along these lines that is used with a great deal of success by a relatively large number of people. It just takes work, basically.
I don't think it ever will be, not to be rude. [Look at their demo that implements a simple calculator](https://github.com/maps4print/azul/blob/master/examples/calculator.rs#L1), for example. That kind of "everything boils down to a single rendering loop" approach does not scale to complex multi-form desktop applications that need to keep track of a variety of data and constantly-changing state over a large period of time. It's a web-design concept that has no place outside of, uh, designing websites IMO. Also the CSS stuff performs poorly, generally speaking. Again, keep it on the web.
What you're describing applies to array-based "lists" though, not linked lists.
It applies to linked lists as well. Searching for the position takes time of course but the insertion is always in constant time if you implemented your list properly.
One question I have is if you have a function or trait implementation that you can make const, but only if the provided type parameter is const, how would that work?
how does it compare feature parity / performance wise?
I just discovered it so haven't run any tests yet, but I did see some comments in the issues that say it should be able to crush Elasticsearch in performance solely because of it being written in Rust instead of Java.
What is the best way to work with sensitive data like passwords? I want to make a CLI program that needs to authenticate itself against an API, so I am thinking of storing the password in a config TOML file in `~/.config/myapp/config`. Is this a good practice or is there a different / better way?
Hi, Rustaceans! I've applied your suggestions with putting all repos under one umbrella and i've made short game demonstration project that show how to embed and write programs in Kaiju! Here is project repo: [https://github.com/PsichiX/kaiju-toolset](https://github.com/PsichiX/kaiju-toolset) And here is code and resources for oldschool console demo: [https://github.com/PsichiX/kaiju-toolset/tree/master/demo-emulator](https://github.com/PsichiX/kaiju-toolset/tree/master/demo-emulator) Have a nice day, it's time to sleep for me now - see you tomorrow! :D
&gt; it should be able to crush Elasticsearch in performance solely because of it being written in Rust instead of Java That's an incredibly ignorant statement, since this is a completely new service. The TechEmpower benchmarks show that language is not the only thing that matters for performance..
Elasticsearch is a distributed system built on top of Lucene, a full text search. Full text search in general is a somewhat complex field. Lucene has well over two decades of performance improvements, and optimized Java code can actually be quite fast. I don’t believe for a second that this project is better than Lucene “simply because it’s rewritten in Rust”. Maybe it’s better, but it would take significant effort. And then there’s elasticsearch. It’s a distributed system that’s responsible for replicating data between hosts to provide higher availability and throughput. A lot of research has gone into this stuff and [elasicsearch has historically had a rough time](https://aphyr.com/posts/317-jepsen-elasticsearch). The performance of networking apps generally centers around their ability to handle I/O, so it’s probably a draw between Rust and Java here. Most likely, better performance would likely come at some undesirable trade-off like availability or consistency.
slice implements to_owned() which just calls to_vec(). This clones the slice, returning a moved vec.
Unfortunately, I haven't needed to do that sort of multi-threaded input prompting, so I haven't researched that detail. I'd guess that the principle of least surprise in the common case would lean toward three independent locks.
I agree. Just repeating what I read. That being said, I do thing Rust would give it a leg up in terms of performance, but optimizations obviously matter a great deal.
/r/playrust
To complete the picture, it looks like Elasticsearch is to Lucene what Toshi is to Tantivy. https://github.com/tantivy-search/tantivy
Don't want to be annoying, but where did you read that?
[Or you could have one GUI framework to rule them all, on every platform.](https://gitlab.redox-os.org/redox-os/orbtk) It's being spearheaded by the Redox OS project. You should look to Redox OS as the driving force for desktop projects in Rust.
Yes, distributed searching and indexing similar to that of elastic (but not using zen discovery), I'm working on this right now. I've ironed most of the design out, but for the most part it's a project I work on alone in my free time, so it'll become more polished when I nail down the full functionality and iterate a few times on top of that. Any help I can get down the line from other people would of course expedite this, but right now I expect to write all of it myself.
In one of the issues regarding distribution. I think it was just a random commenter though, not the author.
You expect to or prefer to? I think there are a lot of people out there who would love to contribute.
I’m assuming “Programming Rust” is the name of a book? 
Thanks, I’ll look for it on Google Play Books 
Thank you! 
Is the book the one written by Jim Brandy and Jason Orendorff ? 
Don't shoot the messenger guys
also [Desktop Application Frameworks Thoughts?](https://www.reddit.com/r/rust/comments/adr5iz/desktop_application_frameworks_thoughts/)
&gt; In particular, generic type parameters with trait bounds in any form are not permitted. Thus is available in nightly, though almost useless, since traits never have const methods yet.
For clarification, I think they (and what I was also going for) we're saying that it should *eventually* be able to crush Elasticsearch in performance. Like I said, I haven't even tested it yet. I don't think the comment was even about the current performance either. I don't think that simply saying Rust is a better language for something like Elasticsearch than Java is ignorant in that regard.
I was able to get it working on Windows but the tutorial needs a summary listing before it explains the details.
Yeah the issue is with Mac
The test would replace the need for the `println`. Typically when I see people using `println` in this way, they are setting up some test, and then visually inspecting the output to determine if the function is behaving as intended. Instead, you can convert the visual inspection into `assert` or `assert_eq` statements in the test. 
You don't have to encode enums as strings, or include field names inside the message, the format is flexible in that regard, and some implementations let you choose how individual structs are handled. Personally I think having field names is good for debugging purposes, but I don't mind either way. Also the way messagepack is encoding it's values may be more compact than protobuf for some cases like small integers or short strings, because it can fit both value and type (or length and type) in the same byte. I don't know if protobuf can do this, but i assume no. In any case, having more options is always good, so if someone creates no_std protobuf library for Rust I'll be glad to give it a try.
I've had a several thousand word rant about how all current Volatile handling is actually a lot worse than the standard we should hold ourselves to. Perhaps I'll dust it off and push it out the door.
Nobody said it is currently better. I think people are misunderstanding my wording. The original quote, along with what I would agree with, are about what the project can become in the future. I haven't even tested this yet. All I am excited about is the performance benefits of using Rust for this over Java. I am not saying it is faster or even will be soon.
I recently had a person I know write out an appveyor script for how to download the gtk3 setup (using msys) and then build it (using the rust-gnu toolchain) on win32. I've stored a copy of said project with appveyor script here https://gitlab.com/Lokathor/gtk-test
The customer can want it privately but you don't have any right to sell it to them in a way that enforces it. They can later decide after they have privately received it to demand the source and release it all publicly under the GPLv3.
Thanks! I mean it's a big long, but I don't feel like this is particularly better than other similar reviews I've seen on /r/rust. Glad to help in any case.
No it doesn't. What you just said is literally meaningless. Linked lists are a legacy C-ism that need to go away entirely.
The "Orb" family looks interesting in general, however from what I've seen the majority of the people closely associated with Redox are kind of openly Linux elitists of the sort that would unironically argue that cross platorm development is "difficult" in 2018/2019, which doesn't inspire much confidence.
ohhh I see. Thanks!
Yea, I also think this has the ability to be better than Elastic Search, especially when dealing with high I/O and large data sets, among other things. However, as you also pointed out, we're a long way from that point.
Does this mean we have to do this kind of thing a lot? Especially libraries, etc: Instead of trait A { fn foo_notconst() { ... } fn bar_couldbeconst() { ... } } write trait A_const { const fn bar_couldbeconst() { ... } } trait A: A_const { fn foo_notconst() { ... } } ? And then extra hassle when implementing the traits... Or is there a better way?
Lucene is a great project. I've used it myself in toy projects and i like it, and it definitively didn't rest on laurels when it came time to optimize even to the point of breaking the public interface.
Also, here are some existing benchmarks for Tantivy, which this uses under the hood: https://tantivy-search.github.io/bench/
Also, here are some current benchmarks for Tantivy vs Lucene: https://tantivy-search.github.io/bench/
Going through the Graceful shutdown chapter from the [book](https://doc.rust-lang.org/book/ch20-03-graceful-shutdown-and-cleanup.html), made a slight tweak in my implementation by placing the worker's `join` and a drop implementation on the `worker`. Are there any concerns when I do that? The only difference I see is that the termination messages aren't grouped nicely. impl Drop for Worker { fn drop(&amp;mut self) { println!("Shutting down wokrer {}", self.id); if let Some(thread) = self.thread.take() { thread.join().unwrap(); } } } impl Drop for ThreadPool { fn drop(&amp;mut self) { for _ in &amp;mut self.workers { self.sender.send(Message::Terminate).unwrap(); } } } Logs: Worker 0 got a job; executing. Shutting down! Shutting down wokrer 0 Worker 1 got a job; executing. Worker 2 was told to terminate. Worker 3 was told to terminate. Worker 0 was told to terminate. Shutting down wokrer 1 Worker 1 was told to terminate. Shutting down wokrer 2 Shutting down wokrer 3 If there are no concerns with this way, I find it to be more elegant in that each structure deals with its own cleanup.
If you don't need the vector and just want to use each element, you can iterate over the slice and then just clone each element where you use it. There's also a method on iterators called `cloned` that turns an `Iterator&lt;Item = &amp;T&gt;` into `Iterator&lt;Item = T&gt;` by cloning each element.
Etcd v3 has locks which can be unlocked with key leases that time out, just google it. The queueing even uses key watchers. My point is mainly that keepalive doesn’t solve any of the hard problems in distributed locking, and the easy bit that it would do (TTL) is not even a good fit for the job because it’s designed for invisibility, and wouldn’t be easy to use with any real datastore since they are usually designed to hide the transport layer and be transport-independent, not glean information from its inner workings. 
Can you elaborate on what the performance problems with the CSS rendering model are? In general, WebRender should significantly outperform native frameworks.
Where is this talk happening at? I'd like to be part of it.
Thank you all of you guys for the feedback. I will go thru every single post here and I will add comment if needed. I really appriciate your time while helping me.
So judging from that benchmark, it seems Toshi's Tantivy beat's elasticsearch's lucene. Although we can't really determine how this translates to real world performance, this is already a win
Just because it's in Rust, it becomes a competitor?
Competitor just means that it's in the same field, not necessarily that it's better.
&gt; I realize I'm probably going to get a lot of flack from this Why? I don't know how representative an example I am but, despite my strong preference for Qt so my creations will fit in on my KDE desktop and my never having experienced Atari hardware back in the day, I find it a fascinating idea. (It may help that I have a bit of a retro-computing hobby and one of the projects I'm trying to get back into at the moment is a free installer builder for DOS, analogous to InnoSetup or NSIS.)
I should try to attempt to understand pytest source code again. It black magic but I'd like to emulate macros in python as well
Thanks for the typo find - fixed. :) Qt had hooks using signals, which were an interesting concept, however, many developers found it tedious - you had to use a special tool to incorporate with your build, which added an extra step, which added complexity. Again. Keep it simple! This weekend, I'll be starting work on the widget library. It's not going to have a concept of parent or child - yet. These will be the base level widgets that accept base level actions, like mouse enter/exit, click, etc. I will expand as I get time.
I don't doubt that even slightly in a vacuum. However looking at the WebRender demos, zero of them appear to do anything directly with CSS at all, especially not loading CSS layouts from files. They moreso just resemble exactly what I'd expect from any other OpenGL-based GUI library ever. It's not really the same thing as what the way Azul uses it appears to the best of my knowledge to generally amount to. The bigger point was moreso the one about scalability WRT large, complex applications though: I've never seen anyone do anything with *any* Rust GUI lib that was more than a single window doing something very simplistic.
Yea, I mention that exact feature of etcd in the post. I’ve used etcd quite a lot. No single concept solves all of the hard parts of distributed locking. Parts work together to solve aspects of the hard problems, each with trade offs. I think you are missing the fact that I am not saying a TCP connection should be used as a lock. I am saying that it should be used to represent ownership of a lock. And once it is dropped, the lock drops with it. All of the other features of distributed locking would still be at play and available. Take the NATS protocol, for example. It uses TCP connections to keep track of publishers and subscribers, and as soon as a subscriber starts missing its ping pong heartbeats, the connection is severed, and no more messages are sent through. Now, just take that principle, and apply it here. Once the “keepalive lock” connection has missed too many consecutive heartbeats, connection will be reckoned as dead, and lock will be released. Think about that for a sec. You would no longer need to configure TTLs on your locks. Think about the potential speed ups. 
&gt; Much longer term, I'd love to see practical work on formal semantics, so for really critical code such as the implementation of containers, it would be possible to prove correct the use of unsafe Yeah, definitely hoping for more progress on this front. At the moment it seems the only solution for formally-verified, ultra high-assurance systems is compiling a subset of C via CompCert.
I might be biased, given that I've done all my GUI programming thus far in Python, but, even ignoring the whole "want it to feel native as an end user" part, Qt has been the most pleasant of the APIs I've developed against over the years. I certainly understand how `moc` could be bothersome when working in C++.
Unfortunately, yes. I'm not aware of any better way to do it.
I remember seeing a while back some discussion of a "generic mutability" idea that would solve this somehow, but I don't think it went anywhere sadly.
Sure. I have no idea where things will end up. I'm hoping things will not become a horribly unmanageable mess. :) And being biased is what got me to this point with Pushrod. :D
Truth be told, I have no idea what you're talking about. Every platform means every platform. States so right on README: &gt; Cross platform: Redox OS, Linux, macOS, Windows
Yeah, I think this is idiomatic. It's how the standard library does it, and I think it's encouraged, the idea being that if you want mutability, having to explicitly ask for it is safer cause then the programmer knows what they're getting into.
\*chuckle* I know *that* feeling. I actually have to hold back my impulses to reimplement the world "properly" because I know it would lead to burn-out as it has in the past.
I may be wrong but I think rayon is for parallelising cpu-bound work, I’m not sure it’s suitable for io bound. 
Yeah, I'm not 100% sure what could be wrong, but if you're getting the right behavior on the client side it might not be the end of the world. If you *really* want to try and track it down [this line in actix_web might help](https://github.com/actix/actix-web/blob/477bf0d8ae0b22a4ac2d1f52d0cdcd91599546bd/src/server/h1.rs#L266), but outside of that I'd say maybe try with another endpoint that maybe has simpler logic (or one that just does nothing), and see if you *still* get the same error. I've also been using [tower_web](https://github.com/carllerche/tower-web) for my recent projects, though I have a project written with `actix_web` still.
I think that would work. It will only error if the impl of RawMutex for R is not const.
If you want an example of using the real time clock on the bbc micro:bit, check out the comment linked to [here](https://github.com/cgm616/punda/blob/24600a42bee16cc3129a0d5592d78f71747e6c1e/src/main.rs#L125). It’s from an older commit of a project I’m working on for the micro:bit. Using the timer should be very similar. I would suggest using the nrf51 and nrf51-hal crates to handle peripherals for you, and then interfacing with the TIMER0 peripheral following along with the example from the code and the PDF “data sheet” for the nrf51 that’s available online. 
Yes
Rust has a great tradition of taking old research work and polishing it until it is fit for consumption by the masses. In that vein, I would jump with joy if we found a *usable* way to verify safety (or even correctness) of unsafe code.
I did not mean anything bad. I just thiught it would be difficult for them to find a guy which is good in all of that.
Recently, https://github.com/themadprofessor came along and added support for no_std. Empowered by the contribution, I've cobbled up some code for ISBN hyphenation. It's been a long time since I've last used Rust so I'm looking for reviewers before I publish to crates.io. Thank you in advance!
Here is somewhat related [previous discussion](https://www.reddit.com/r/rust/comments/6tpirh/debianpolicy_packages_should_be_reproducible/).
Ayy I'm also working on my own little Vulkan framework, although I decided not to use rust for the earlier prototypes. Prototyping in python is so much faster. Best of luck with your project. The VR sounds particularly interesting.
I imagine so since being explicit about mut is a feature of the language. It might not be a popular way to go about it, but I imagine in a lot of cases you could also write the function as a macro where you pass in the symbol 'mut' to generate the mutable version and maybe wrap it with regular functions for each of the mut/non-mut cases if you are concerned with preserving DRY in this case. However since you're only repeating yourself the once in this case I'd consider the rule of three before embarking on a meta-programming journey to fix this issue.
One solution is to use macros, this way it is not possible to have code duplication. The `slice::chunk_exact ` in the standard use this technique for example. I use it in my `group-by` library. https://github.com/Kerollmops/group-by/blob/master/src/binary_group_by.rs#L8-L56
This works on nightly: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=df79307a8855b97fbbf5bec320bb7a38
Signals are cool, but debugging the event graph in an existing, fairly mature Qt project is tedious af. Like, okay, what all slots are connected here that’s calling this function? And I agree that the requirement of having an extra compilation step to generate your moc files is less than ideal. I like Qt overall, but something simple would be much appreciated. Also, something... Rustier.
[This kind of work](https://gitlab.com/dhardy/kas)? The design is experimental, needs a lot of work, and may have issues meeting all of the goals, but places a lot of emphasis on good developer experience. [Check the examples](https://gitlab.com/dhardy/kas/tree/master/kas-gtk/examples).
Many applications store encrypted passwords and such on disk. I think that this is acceptable if isn't anything too critical. However, if possible, use tokens with limited access if this is supported by the API you're using. You could leave encryption up to the user. To support this you need to provide a way to read the password from external command. Another option is to use key store/chain provided by the operating system but this usually only used by graphical applications.
Go for it! I don't know about the Chrono project precisely but most crate authors will happily merge PRs adding more docs (maybe with examples?) :)
In my opinion, there is a long tail of well-isolated safe abstractions implemented with unsafe, a longer tail of such abstractions that needs to be written but not yet, and an even longer tail of unsafe uses which are reasonable but hard to abstract in such way.
AddressSanitizer is faster than Valgrind, but Valgrind catches memory leaks (I think that's the most common use, actually) and AddressSanitizer doesn't.
When people post these threads is about the time the project is coming to a close. https://www.psychologytoday.com/us/blog/ulterior-motives/200905/if-you-want-succeed-don-t-tell-anyone
https://github.com/rust-random/rand/issues/648 https://github.com/dhardy/rfcs/blob/system-random/text/0000-system-random.md And the Secure Code WG chat: https://rust-lang.zulipchat.com/#narrow/stream/146229-wg-secure-code/topic/secure.20rng
Address Sanitizer also does catch at least some of them these days.
&gt; Proving a module in C correct basically means you have to start all over again when you compose it into a larger system, as there are so many ways the global invariants can be violated. Thanks a lot for this, I should make it a testimony when I advertise researching *modular* approaches to verifying program correctness. :) &gt; At the moment it seems the only solution for formally-verified, ultra high-assurance systems is compiling a subset of C via CompCert. Beyond CompCert, there's also other things like [seL4](https://sel4.systems/), and projects like [CakeML](https://cakeml.org/). Having this for Rust would require much more than just a formal semantics though: you also need a formally verified compiler. That's a *lot* of work, and unfortunately -- the way incentives work out in academia -- since there already are two advanced formally verified compilers (CompCert and CakeML), I am not sure it would academically make sense to have another one for Rust. I'd love to see it happen, but I wouldn't hold my breath. A formal semantics, on the other hand, seems much more realistic -- at least mid-term. There are already several projects ongoing to formalize various aspects of Rust in various frameworks to varying degrees of precision.
Ah man I love doing GEM development, this sounds really cool.
&gt; In those cases, there is almost always an effort to isolate the unsafe parts into the minimal component that needs it. I think that is the key point that distinguishes Rust with unsafe code from C: unsafe code gets *hidden behind an abstraction barrier*. I stopped counting how often I had to explain that to someone. ;) But I think it is important that we make this a key part of our messaging, both towards new people interested in Rust but also when evaluating the use of unsafe.
Looks like a great library and nice example of Rust code generation. Too bad I don't need it for anything right now! Anyway it seems to consider AAAAAAAAA0 as a valid ISBN.
But that's the point! The `RawMutex` impl is not going to be const (since `lock` needs to block). However we only use the associated constant from `RawMutex` and don't call any of the functions.
&gt; unusable if you want your code to be anything but gplv3 and distribute it Doesn't that only apply to code related to that project though? Like FFMPEG has a similar license iirc, where if you made any changes to it's code, you have to make that available, but if your program is just using FFMPEG to process some video content, your code is isolated from it and you've just got some glue perhaps to interface with it? As long as it's binary is separate from your proprietary binary, it's ok? 
&gt; A formal semantics, on the other hand, seems much more realistic Yeah, good clarification there. We're still a long way off something a formally verified compiler for Rust. I think there's work being done on verifying parts of LLVM, but they run into the issue of constantly falling behind what's currently in trunk. Hopefully with some of the work being done to modularise the back ends (eg. CranLift vs. LLVM), plugging in a formally verified code generator would be easier, but it's still a ton of work no matter which way you look at it. End-to-end verification is even further off too... so much still to do!
Maybe you can add methods that transforms you mutable reference to immutable and vice versa? Just like in standard library there are methods like '.as_ref()', '.as_mut_ref()', etc. 
https://crates.io/crates/ring
That's way simplier. If expression is evalueted in cons context then vec can be allocated and used during compilation. If vec leaves const context (returned from const fn into runtime context) the whole const expression can be compiled down to creating ordinary vec initialized with constant data array.
Some of the replies seem to be about whether to only expose one 'mut' function instead of two (mut and non-mut) functions ...I don't think that is what OP is asking. I think OP is asking whether there's a way to implement the two functions without duplicating code in the implementation.
Agreed; [gtk-rs](gtk-rs.org) appears to be the most mature (cross-platform) Rust GUI system so far. And agreed, many of the current approaches don't feel very "rustic". Which is why I started KAS (the [toolKit Abstraction System](https://gitlab.com/dhardy/kas)) last Autumn. This actually takes quite a bit of inspiration from Relm, in the sense of an abstraction layer over an existing toolkit, but then adds some twists of its own: - use sufficient toolkit abstraction to allow other toolkits to be used as the "backend" with very little change to user code - make heavy use of macros to enable succinct GUI specifications In keeping with Rust traditions, - the abstraction is light-weight (not zero-cost, but insignificant relative to the complexity of something like GTK) - it makes heavy use of typing and generics to enforce correctness at compile-time - (dare I say it) the internals are quite complex [See some examples here](https://gitlab.com/dhardy/kas/tree/master/kas-gtk/examples).
Parent was talking about "abandoned", which this crate apparently has. "Not having been updated in a long time" also is very different from being unmaintained. In the former case there'd still be someone willing to write or merge features and especially bugfixes, while you're essentially forced to fork in the latter case. For example, the [documentation](https://gabdube.github.io/native-windows-gui/docs/book/introduction.html) link of native-windows-gui is a 404, and assuming the maintainer doesn't change his mind there's no way to fix this other than forking and renaming the crate.
Yes: http://shop.oreilly.com/product/0636920040385.do
cbindgen or rust_swig
Wasn't `assert!` supposed to supplant `assert_eq!` by offering the same functionality?
I made a pull request to your repo which does better error handling. Read through it and accept it if it still does what you want (I could not test that)
I'd check out the Matrix and IRC servers as well.
Update: All of these but `integer_atomics` have been merged; `uniform_paths` ship in 1.32 and the rest in 1.33.
Interesting project. I shamelessly copied some code from your latest version and got some of what I was trying to work. Thanks for the link.
Yeah, I need to investigate a little further. It was near the end of the day on a Friday, so I didn't get to dig too much. The client does appear to work correctly. How do you like Tower compared to Actix? When I looked into my options, I felt like they both seemed fairly similar in terms of what I needed, but I went with Actix specifically because I have a bias against macros.
It is probably slightly faster. As of now, rustc/LLVM can't get rid of all the intermediate copies in many cases. Whether that is actually relevant is a different question though. That's probably not exactly a hot path
Heads-up about the name - "arse" is back-side in British English, so this sounds like a play on that to me.
Hi there, I try to generate a setup struct based on the input of the user. I get the \`match arms have incompatible types [\`](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=047528b0bc92a2f4bedbcb8982349ff0#) error, because I either want to generate a \`Setup&lt;f32&gt;\` or a \`Setup&lt;f64&gt;\` type. I know there are two types of solutions for this: 1. I could wrap the block into a \`Box&lt;T&gt;\`. But I want to avoid using \`Box\` since it looks like bad habit. 2. I could implement Setup using the \`enum DataType\` (see code below), but then I would have to also implement the \`Default+Copy\` traits. Is there a third solution? What is the most idiomatic way make this code work? [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7550e9af232d17fa315401ea8bbe6c96) \`\`\`rust // A minimal example of the problem fn main() { struct Setup&lt;T&gt; { data: Vec&lt;T&gt; } impl&lt;T: Default+Copy&gt; Setup&lt;T&gt; { fn new() -&gt; Self { let d = vec!\[Default::default(); 10\]; Setup {data: d} } } enum Datatype { F64, F32 } let arg = Datatype::F32; let v = match arg { Datatype::F32 =&gt; Box::new(Setup::&lt;f32&gt;::new()), Datatype::F64 =&gt; Box::new(Setup::&lt;f64&gt;::new()), \_ =&gt; panic!("Error"), }; } \`\`\`
I also got confused. Would it be possible, instead of signature/API checks, the scope in question be analyzed instead, as a fallback at least? If nothing not const is called, then it's const (recursive-like analysis).
I do like GTK, but I wouldn't advertise its cross platform property. Cross compiling it is pretty complicated compared to other Rust crates.
Thanks for mentioning KAS! One reason the site exist is to gather all the great projects. And to be honest i have never heard of KAS before even though i am often looking out for them in the Rust ecosystem. 
Yeah -- I personally would probably have left it there. There are so many other things to do with developing any application that if I couldn't get down to the bottom of it with some pathological cases (empty handlers, etc) or going line-by-line and removing functionality/code, I would have just dropped it... I've only used tower on a very recent project, but it's been pretty great. [documentation for tower](http://rust-doc.s3-website-us-east-1.amazonaws.com/tower-web/v0.3.3/tower_web/) (it's the usual rustdoc which isn't terrible but certainly isn't outstanding) is not as good as [Actix web's user guide](https://actix.rs/docs/), but tower_web is a much newer project but is showing a *lot* of promise. I think it's a toss up between the two, actix_web is older, more reliable, and is basically "HTTP as solved by an general actor framework" in my mind, but tower is more just the one thing (a good http server). Tower leverages more of the new rust 2018 features IMO (for example the `impl_web` macro), but in return you get all the nice micro-framework things like `#[get("/")]`. I agree with your bias against macros -- at least when they're over-used, I love the annotation-like macros though as long as it doesn't get too crazy, less of a fan of the `!` style macros. Anyway I'm meandering now but tower is great, and making great progress -- but it sounds like you're happy with actix and I can't say that tower is definitively better or you should switch to it...
Indeed. From a memory representation point of view, a `Vec` is just: - a tuple: pointer, size, capacity. - pointing to a dynamically allocated array. Since Rust requires that `const` expressions be `Copy`, you would need end up with: const VEC: &amp;Vec&lt;i32&gt; = &amp;(0..10).collect(); Which would be represented as: - A pointer. - To a tuple. - To an array of size 16, with 10 elements inside. It may even be beneficial to tune codegen to eliminate the pointer (in storage) and simply create the pointer on-the-fly at the use site, but that's just a little memory optimization.
How about [libui](https://github.com/andlabs/libui) alternative?
I disagree, let's shoot the messenger. I am tired of half-baked statements being repeated (and often, transformed) with absolutely no vetting of the information repeated; this is how you get an Internet full of half-baked "facts" that everybody "knows". And a disclaimer of "So, I haven't checked myself, but I heard that..." is not a valid excuse either. Don't gossip. Either check it out or don't mention it. Stop confusing others (and yourself).
To be fair, the problem is exactly the same in C and C++. There are generally ways to factorize the code into a 3rd (private) method, though this is dependent on the architecture of the data and may require some `unsafe` thrown in... which may be worse than the ill.
I want to notify that in the new version (1.3.2), there is a command line file `--cache-fallback`. If the flag is used then the client will respond with an expired cache entry if no response is received from the server.
The tag filtering doesn't work on [areweguiyet.com](http://areweguiyet.com).
Are there plans to render to a vulkan texture at all?
You should crossplay this to r/pixelart. It looks awesome!
you want a pure Rust implementation, even if it doesn't go through and pass comprehensive review?..
Maybe `alternative` instead of `competitor`?
Why?
&gt; http://areweguiyet.com/newsfeed/2018-01-13_rust2019.html shouldn't the url be http://areweguiyet.com/newsfeed/2019-01-13_rust2019.html?
Well, OrbTk and Azul are fairly close since OrbTk is moving towards webrender lately. The webrender API is still heavily undocumented, so many problems with Azul were due to missing documentation / examples from webrenders side. So even if it dies, Azul can serve as additional documentation for webrender. Debug-build performance is still a big problem. While Azul (minimum features) can now compile in roughly 2 minutes on my machine, the performance in debug builds for GUIs is often so sub-par, that I have to use release builds to even operate the UI because the unoptimized assembly is so slow - but compiling in release mode then leads to long recompilation times. I commonly have debug-run cycles of roughly 30 - 45 seconds because of this, which isn't exactly great. And there are of course things about Rust that make GUI development generally worse than it needs to be, on a language level (like [function pointer equality bugs](https://github.com/rust-lang/rust/issues/54508), [custom try operators](https://github.com/rust-lang/rust/issues/31436#issuecomment-441408288), etc.). I could mostly work around these bugs / missing features, but only with a few hundred lines of extra code, so getting these things resolved would be great for GUI projects in general, but there was very little activity over the past year, so I doubt they'll be resolved this year. I'm okay with having 10 dead webrender frameworks, it's inevitable if you want progress. So what - people experiment, spend a few weeks making their own rendering system until they realize that using cassowary was a horrible idea and then move onto something else. In order to progress, you need to experiment, not just talk about things - I've seen this mistake so often, people discuss and discuss and discuss and in the end they have a wonderful hypothetical API that completely fails in practice. The correct step would be to make it fast and easy for people to experiment.
I said, as I stated several times, that my comment as well as the other person's was saying it has the potential to be faster in the future. Nobody is talking about its current status. Also, Tantivy, the underlying component which is the Rust based Lucene competitor is already beating it in almost all benchmarks, which you can view in the links I provided. If anyone is making claims due to them not reading, it's you.
I agree with having `const` explicitly because of the common case when a user of a crate quickly looks up the docs for a single function or trait, or with 'go to definition' in an IDE. One could **easily miss** that a `fn` or `trait` is `const` if it was omited.
This depends on what you're planning on doing with `v`. The match arms have to match to give `v` its type, so the way you use `v` after the match will determine what type those should have.
Yes I was having fun, but also felt slightly concerned that it were true.
I would always write a macro for one function definition but the problem is that macro definitions can't exist inside of `impl { ... }` blocks so you need to write it somewhere else. Rust should definitely have an easier way to do it.
&gt;Wouldn't this be a problem if the trait decides to add a default-implemented function? You're right, this should be specifically addressed. I've updated the post to clarify that point. Thanks!
Thank you!
&gt;I'm not completely sure that I understand it correctly why we need const in the trait bound. Is this because we want the exposed API to clearly communicate what is needed? If so, shouldn't the function being marked const itself be enough to communicate that? `const` is only necessary in the trait bound when we need the bound to be `const` even at run-time. This is a relatively uncommon scenario. Being explicit about `const` is important for API stability and also to align with mental models about what trait bounds mean. (Otherwise it could be easy to accidentally break something just by modifying a function body.)
&gt;Unfortunately it would make this code impossible You're right, this was overlooked beforehand. It's useful to have some way to opt-out of the `const` bound. I've updated the post to facilitate this pattern (though it requires a small piece of additional syntax, `?const`).
&gt;Would this prohibit any construction of values containing phantom types with non-const constraints? It would do. I've updated the post to address this flaw (see also [https://www.reddit.com/r/rust/comments/af7qog/const\_types\_traits\_and\_implementations\_in\_rust/edza34r/](https://www.reddit.com/r/rust/comments/af7qog/const_types_traits_and_implementations_in_rust/edza34r/)).
&gt;Does this mean we have to do this kind of thing a lot? No, you can simply declare the `new` method to be `const`, which requires all implementers to define `const fn`s for that method: trait A { fn log() { ... } const fn new() { ... } } &amp;#x200B;
Could you give an example of the sort of scenario you're thinking about?
Have you considered approximating the curve with small lines and then using Bresenham's algorithm to draw the lines? That should produce mostly pixel perfect curves without a postpass, I think.
Correct
&gt; However looking at the WebRender demos, zero of them appear to do anything directly with CSS at all, especially not loading CSS layouts from files. They moreso just resemble exactly what I'd expect from any other "immediate" OpenGL-based GUI library ever. Right. I think I misunderstood you, then :) I thought you were saying that the CSS-like model that WebRender exposes is inherently slow. My feeling is that the CSS *painting* model (not talking about the rest of CSS, like the older layout stuff which is a mess) is actually reasonably designed and is pretty close to what you'd come up with from scratch.
I think you are in the wrong subreddit. I think you wanted to go here [https://www.reddit.com/r/playrust/](https://www.reddit.com/r/playrust/). This is a subreddit for the programming language rust, not the game rust.
\&gt; Okay, I realize I'm probably going to get a lot of flack from this, I doubt that. The rust community is one of the most open-minded and helpful. I've yet to see anyone to take flak for a new attempt at anything. \&gt; but I wanted to do this project, as I feel there's always room for improvement for UI. True that! Do you have any plans regarding rendering to a Vulkan context etc? Is Pushrod supposed to be a general GUI library or (also) used for e.g. Game GUIs? &amp;#x200B; In any case I wish you all the best.
First time I heard about qmetaobject-rs. Seems very impressive.
I have some thoughts here (and am very happy to answer questions). It's good to see so many different approaches, as I consider "how to build a good UI in Rust" a research problem. My work is in modular pieces, with a strong philosophy of mix and match. So, for example, I'd be quite fine with people using [piet](https://github.com/linebender/piet) as a common API layer for 2D graphics, but having a different vision for the higher layers. That said, I believe my vision is compelling, though the current state of the code is young. Among other things, being able to use platform 2D graphics and text means a small amount of code in the critical path of an iteration cycle, as well as quite usable performance in debug builds. It also means small executable sizes (the calculator example is around 333k on Windows) and ability to deploy on web. It will soon be time for people to start comparing these frameworks qualitatively. There's lots of things people will care about, but here are some of mine. What is the compile time for a simple example? Executable size? Can it resize a window smoothly and re-layout the interior without wobbling? Lastly, performance. I haven't built all the performance infrastructure, such in particular incremental rendering, but when I do I expect to be *way* ahead of alternatives that paint the world every frame. I am also very sensitive to latency and will be using an Arduino-based USB-injection and light measurement setup to measure it empirically. I think this will be a very exciting year, and look forward to friendly competition. I am happy with others stealing my ideas, and hopefully with multiple teams thinking about this we can synthesize a better solution.
&gt; If anyone is making claims due to them not reading, it's you. Actually, I am not making any particular claim about your particular case. At all. I am not even mentioning any of your comment, or the article. I am very specifically replying to /u/cipperz's comment as I find the attitude of "excusing" spreading unchecked information tiring in general.
My personal opinion, if you advertise working on a Rust project, you'll find a fair amount of passionate and highly skilled developers who want to work with the technology. As long as you are willing to have a remote team, it should work.
If you want a cross platform desktop application with some degree of sophistication, I'm assuming you probably want to use Qt, in which case C++ would be the better choice. As far as I am aware, it's incredibly difficult to make Rust work with Qt outside of what you can do with standard QML.
Well I am the one being referred to as "the messenger" and it seems /r/rust has already formed a lynch mob to get me because of some ambiguous wording I had in my original comment. I just wanted to share a repo I thought was exciting and shows a lot of promise, but now I feel like I should avoid even saying anything in this subreddit or I may get downvoted to hell. How about instead of shooting messengers, or anyone for that matter, you talk with them and then any problems with either be clarified or valuable information will be given to people taking part in the conversation or stumbling upon it in the future.
&gt; To be fair, the problem is exactly the same in C and C++. True, though that's hardly a justification. Actually, it's less justified in C++, since it has overloading.
&gt; It would involve a cross platform desktop application Do you have any specific technology in mind, here? The [Are We GUI Yet?](https://www.reddit.com/r/rust/comments/afhrru/rust2019_areweguiyet/) post was just posted and may give you an idea of how to attack GUIs in Rust; notably, you'll have to choose between working with native APIs on top of a core to have that "native" feel, or forego the native feel if you wish to have a single GUI library to deal with.
&gt; True, though that's hardly a justification. It's not intended to be; it just shows that is mostly an unsolved problem. Abstracting away mutability is relatively hard in general... and even more so in Rust when `&amp;T` is `Copy` and `&amp;mut T` is not. &gt; Actually, it's less justified in C++, since it has overloading. I don't quite see how overloading helps; you still have to code both overloads.
I guess you don't really understand macros. They are meant to generate real code, but it just looks nicer because you don't have repeated source code. The macro itself is a good example though. 
Personal pet peeve: Why is the entire readme just "Kaiju - Modern Assembly Language"? It's less than helpful in determining what exactly the project is, why I should consider using it, and how to go about using it. Please consider providing actual documentation
"ass" in "assert" is back-side in American English which makes me feel this is entirely intentional.
Thanks for mentioning! Should be working now.
Good point. Perhaps what I meant is "the most mature available on Linux".
It was only just published.
For my understanding, why is it important to develop GUI in Rust. For my use case, I do prefer web technology. HTML+JavaScript+ SVG. I didn’t considered yet wasm and webgl. Is pure rust GUI a mandatory item for games?
Do you really think I don’t understand macros ?
We at work seriously considered using Rust for a cross platform commercial desktop application. We ultimately chose C++, but Rust is a competitive option. Do you have any toolkit choice in mind? From my research, [rust-sciter](https://github.com/sciter-sdk/rust-sciter) is a strong option. Sciter is a commercially supported (binary only, not an open source, but it works great) GUI toolkit, and what a surprise, upstream Sciter supports Rust binding! In my opinion, commercial viability of Sciter is beyond any doubt, and similarly for rust-sciter. Since Sciter is based on web technology, you should have no problem outsourcing UI work.
&gt; Well I am the one being referred to as "the messenger" I am sorry that you felt targeted. I never intended to refer to *anything* in particular, and if I had to ascribe a target it would have *your comment* (to be downvoted for inaccuracy) and certainly not *you as a person*. &gt; and it seems /r/rust has already formed a lynch mob to get me because of some ambiguous wording I had in my original comment. There are exactly 2 people who "shot down" your comment; that is not a mob. &gt; I just wanted to share a repo I thought was exciting and shows a lot of promise, Thank you, it does look neat. &gt; but now I feel like I should avoid even saying anything in this subreddit or I may get downvoted to hell. Inaccurate information will hopefully get downvoted, yes. That's not a judgement of value on the *person* (you), it's a judgement of value on the *content*. Your post sits at a comfortable +170 right now, so clearly folks have enjoyed the link you shared. Likewise, all of your comments have a positive aggregate score. &gt; How about instead of shooting messengers, or anyone for that matter, you talk with them and then any problems with either be clarified or valuable information will be given to people taking part in the conversation or stumbling upon it in the future. I honestly feel that both are needed: - Downvotes on inaccurate content, so it disappears. - Requests for clarifications/corrections/qualifications/..., so that content improves in quality. I *wish* the latter was sufficient, but experience has proven it's not as some never bother to edit their previous comments. As a result, the former is unfortunately necessary. In general, though, earlier downvotes will be compensated by later upvotes (or even rescinded) once the comment's content has improved. Also, be wary of reading too much into early scores: Reddit uses a fuzzing algorithms on comment I think, so that the score displayed may well be within -2/+2 of the actual score. 
This could be one of many reasons :D
Hmm. Could you elaborate a bit in why it depends on my handling of `v`? The `Setup` struct has additional functions I omitted in the above snippet. It implements method in reading data from a file using the appropiate functions from the `byteorder` crate. Currently I am only supporting `f32` and `f64` for `Setup`. The actual application I am using `Datatype::F32` to determine how the next argument (filename) should be read in and written out. 
&gt; This seems to violate the DRY principle, `&amp;mut T` and `&amp;T` are very different things with very different guarantees, even though the implementations might look similar.
For me, I see it as web-technology GUIs as having two problems: 1. Heavy and bloated compared to native toolkits 2. They don't fit in with the rest of the apps on my desktop and odds are that they won't match platform idioms and features properly either. I see them as such a bad option that, even on point #1 (bloat), I still prefer to use PyQt to write my GUIs in Python... possibly with a Rust backend using rust-cpython if there's stuff that lends itself well to a frontend-backend split.
GUI support in Rust... isn't great. If you're familiar with C++, I'd highly recommend writing the UI with QT (and C++). Rust bindings for QT are not suitable for production apps. However, it could well be worth investigating writing the business logic / non-ui parts in rust. Rust has really good support for exposing a C api (which can obviously be easily consumed from C++), and it would allow you to make use of rust's excellent selection of libraries for that part of your code.
Why Qt? You could use [Sciter](https://sciter.com/) with $620 (this is an unimaginable bargain, really), or [web-view](https://github.com/Boscop/web-view), or other similar UI technologies.
proper readme, docs and wiki are on the way in next version, if i forgot to tell :D
Well clearly writing rayon and other crates has taught you nothing /s
Thanks. I just wonder if the _portable_ rationale was sufficient to value web-GUI compared to HW/OS dependant solution (native GUI) Note, I completely understand that for demanding games, only native counts.
Thank you! I also thought about that. The fact that Rust engineers (and jobs) are yet a bit rare can actually play in project's advantage. I'm all for remote work.
Wow! That's a lot of info, amazing! Thank you! 
Sciter looks cool and I have actually used it a bit a couple of years ago. I think that you can actually use it for free even for commercial apps as long as you don't need static linking or source access.
Indeed, looks promising! 
I agree, Webrender just recently became "usable" and i mean not "user friendly". I remember that i tried my own little tests a year ago and i basically just gave up because i couldn't get basic things going. This is better today, in a way that i can make something simple but if you get down to the details i think you described it accurately. Compile times are a really big problem in Rust and i fear the more time gets by without really tackle the problem very seriously it gets harder and harder to resolve this. I am looking enviously at Jai's compile times :/ And i agree with you on the language side, i think rust has a problem in the upcoming years with scalability of the hole ecosystem especially with dependency management and cargo/crates.io. I ran into problems with broken dependencies for some little projects and i took me a wile to fix them (even reporting it upstream to the library author to fix it) and i can imagine that projects can get more and more affected by this when the code grows. I am also very ok for people to experiment. All i wanted to point out in the post was that maybe – if one of the people experimenting did know about the others – some people had joined forces. I do think there is a difference if 20 people just randomly experiment with something for a year and go to something else (regardless of the outcome, that's what you do with a hobby) or if you have 2-3 people that really want to get something done and see that they are building basically the same thing and have the same goals. At least some of the goals – they could easily build a foundation from which other could profit, by creating some general building blocks. 
Yup, basic uses are free, even for commercial.
I'm pretty sure we do know about each other, but there is a very strong NIH. That said, there are ways to encourage collaboration and your post is a good step in that direction. Thanks.
Thanks! To learn some Rust and decided to copy dmenu. After spending a day or two, trying to figure out how to put a square with some text on the screen I dropped the project. I still wouldn't know what library to use, but it's nice to see where we are at and that things are progressing.
Fair enough, although I'm still not sure what was inaccurate about my comment.
I'd like to put out [fungui](https://github.com/Thinkofname/fungui) which was previously called stylish. Its based on webrender and its still alpha but /u/thinkofdeath has used it to develop the gui in his video game [Univercity](https://store.steampowered.com/app/808160/UniverCity/?curator_clanid=33022141)
Why would I spend $620 on Sciter to program my gui with html, Javascript and css when election will do that for free?
I am very interested in your measurement apparatus. I recently came across [this post](https://danluu.com/input-lag/) i wanted to build something similar. Would be cool if we could have something that anybody could rebuild at home to make their own tests as a reference point. I agree that there is an opportunity right here to have something like piet/OrbGL being more of something foundational that many people can derive from. I think it would be wise to increase the communication between both piet/druid and OrbTk/OrbGL because it looks like both projects are trying to have a similar core even though being different at a higher level. 
&gt; but there is a very strong NIH I didn't mean to imply that, but I think you're right to some degree. I mean, we try to be good as human beings but it looks like NIH is something deeply encoded into our genes :/ 
In C++ the usual idiom is to write the mutable impl and then use const_cast to implement the const one. It does mostly eliminate the duplication, if you don't mind seeing const_cast sprinkled around. :p
&gt; Note, I completely understand that for demanding games, only native counts. Nope, you can use web GUI for "demanding" games just fine, go buy [Coherent Gameface](https://coherent-labs.com/products/coherent-gameface/) or any of its competitors. It integrates with Unreal Engine and Unity. What's going on is that they render HTML to UE/Unity objects, just as Chrome renders HTML to Skia. It's a lot like WebRender but commercially ready.
This is not new. Note that Coherent Gameface is targeting Scaleform users. Scaleform also rendered to UE/Unity, but from Adobe Flash instead of HTML5. Scaleform is at least 10 years old, but maybe some of its users want to migrate from Flash. Hence HTML5 competitors.
Correct - note also the section in the readme where I apologise and request suggestions for names (:
Yeah, you're kinda stuck without using macros. Ideally you'd implement one in terms of the other but if you try you'll find out both attempts would require `&amp; -&gt; &amp;mut` somewhere, which is of course illegal.
Thanks 
Great. Bought it 
First, you can also use Sciter for free, $620 is for source and support. Next, Sciter is less than 10 MB (&gt;10x smaller than Electron), integrates much better with native code (plain C API, no more V8 native module stupidity). Really, go check their samples.
I'll try to resurrect it soonish. It's very much something anybody can build, about $50 in parts, in fact here's the [Amazon list](https://www.amazon.com/ideas/amzn1.account.AGSZP5AWBGH7772O35NTI7RN3JLQ/2LZEHRCO3YHSZ) for it. I need to rewrite the code, partly because Google owns the copyright on the old version and I never went through the open-sourcing process, partly to make it more robust.
Regarding Windows, I think the best approach would be to have COM/UWP tooling comparable to what Delphi, C++ Builder, C++/CX or the younger C++/WinRT are capable of. This way it would be possible to easily integrate Rust code into any Forms, WPF or UWP application.
I couldn't say; I didn't see it before your edit, and there's no history on reddit :/
could we stay in contact about that? I would love to have a project like that for people that are interested in this and i could see myself writing a start-up guide, tutorial etc. 
 pub struct MyInt&lt;T&gt; (T); impl &lt;T: Add&gt; Add for MyInt&lt;T&gt; { ... }
I prefer the other way around: write the const impl, and const_cast the result. It avoids accidentally mutating the object in a const method.
What we really need here is some form of mutability-polymorphism, but I don't think anyone's developed an approach to that yet.
Do you need E**C**DSA or can you use E**D**DSA schemes such as Ed25519? If so, I'd recommend you look into [https://dalek.rs](https://dalek.rs) or better the [https://ristretto.group](https://ristretto.group) implemented on top of that, in the same crate. [https://doc-internal.dalek.rs/curve25519\_dalek/](https://doc-internal.dalek.rs/curve25519_dalek/) 
Definitely!
&gt; use platform 2D graphics and text This is a problem for applications like 3D games where platform 2D/text is difficult or impossible to integrate.
\&gt; Safe, fast, small crypto using Rust with \[Google's\] BoringSSL's cryptography primitives. IIUC this is only the Rust binding for the C/ASM implementations?
&gt; odds are that they won't match platform idioms and features properly either. I don't mind not matching idioms too much, however not working with the accessibility features of the host, such as text-to-speech, is quite problematic.
Okay. No problem.
Rust brands and prides itself of being better than C and C++ and producing cleaner code. What I think would be nice would be immediate macros which are instantized at creation like say: struct Foo ( i32 ); impl Foo { macro_instances! { pub fn $(get, get_mut) ( $(&amp;, &amp;mut) self ) -&gt; $(&amp;, &amp;mut) i32 { $(&amp;, &amp;mut) self.0 } } } Naturally this would expand to two different definitions
It's as much rust-native as is feasible, given the need to support hardware-accelerated and constant-time operations.
&gt; Heavy and bloated compared to native toolkits How? [Sciter](https://sciter.com/) is less than half the size (&lt;10 MB) of [Qt](https://www.qt.io/) (&gt;20 MB), also faster, also cheaper (both are free, but you almost certainly want to buy both for licensing reasons), etc.
Cargo, crates, and the module system is a significant win in favor of Rust. Code reviews are also much easier for Rust given that the borrow checker does most of the reviewing for you. &gt; can it be to find Rust contractors compared to the C++ contractors? I think it can be easy for either language, depending on the nature of the work and how flexible you are with allowing remote work. People are always looking for job opportunities around here on Reddit and the users forum. You could make a post on rustjobs. It may be difficult to find Rust talent on the usual job websites, so you have to go where the Rust programmers are to find them.
Does Rust even support UWP? I got the impression UWP needs to be a new target with a new triple.
rust-sciter's maintainer here. Since Sciter itself and so do its bindings are "customer driven" libraries, I'd be happy to hear about any feedback. 
Bezier curves are designed to be subsampled: you can get as much accuracy as you want. Perhaps render the curve with about 8x oversampling, then apply a threshold to each pixel. If you want to get fancy, you could grab a second pixel color and "antialias". (Does not actually remove aliasing, because giant pixels, but should make the curve look smoother.)
That's fine. The goal of piet is to enable platform 2d and text, not require it. I very much want to integrate with Pathfinder in particular, which I think will play nicely in a 3d world.
`ensure!()`, `check!()` come to mind.
&gt; In fact there should probably just be a macro `!ref_mut()` which expands to `$(&amp;, &amp;mut)` specifically for use in this macro. Actually, I'd argue that such getters are *harmful* in Rust. In any language, returning a mutable reference to a data-member is dubious. It completely breaks encapsulation and prevents any invariant involving the data-member in question... Really, the data-member might as well be public. In Rust, however, the balance tilts even further in favor of public fields because functions are not transparent to the borrow-checker. That is: - Using `let x = foo.x_mut();` means that the whole of `foo` is mutably borrowed. - Using `let x = &amp;mut foo.x;` means that only `foo.x` is mutably borrowed. I really don't see any benefit for the compiler and standard library to implement new features to facilitate what is generally an anti-pattern, and thus should be rarely used, if ever.
Hi, I'm the author of this, thanks for posting! Everything is in a pretty rough state right now, I'm working on the distribution aspects of Toshi right now. I'm happy to answer any questions people might have and suggestions for improvements.
I think I’m gonna try it soon. I will PM you the feedback or open a discussion on github!
Say that it will be, and then make it so
I am not familiar with sciter, but other similar products use the built in browser of the OS, which automatically makes your app not so cross platform. That's why electron is so huge - it bundles chrome, but you know your app will look the same everywhere. Also, you should consider runtime size - ram. 10mb executable is fine and dandy, but when I open hello world and it uses 200mb ram I will nope right out of it in milliseconds.
That would be really interesting, and considering how mutability is only considered during compile-time it would probably fit the language pretty well.
Nope, unlike "other similar products", Sciter uses its own engine, there is no cross platform problem, you get pixel identical result. Therefore, no, that's not why Electron is so huge.
The only downside I can think of is that someone reading the ThreadPool's drop impl might wonder whether workers are getting joined properly, so you'd probably need a comment there saying "don't worry, worker joining happens in the worker's destructor."
Building generic functionality around diesel is usually very cumbersome due to the many traits involved. I would ask on the gitter channel, you can usually get great advice from the maintainers there.
I'm obviously just using a simple getter/setter here as an illustration of the most basic thing; I agree that in Rust the problem is that just making the field itself public is probably better because of this problem which is a real waste that this granularity can apply to accessing fields but not getters and setters as I do believe that gettres and setters are more future proof but that's how it is. I'm with this macro more so talking about say you write a data structure and you have to implement both `Index` and `IndexMut` or `Deref` and `DerefMut`; in 99% of cases the body of both implementations is identical modulo replacing `&amp;` with `&amp;mut` at a couple of places so you run into repeating yourself without such a convenient macro or having to define the macro on a case-by-case basis yourself.
Care to explain why electron is huge then?
Yes, Tantivy is already better than Lucene because it's a search library. We can both agree on that. But that has little to do with our current discussion. In fact, I like how you admit that your original statement was wrong, and then everything you say afterwards has been trying to negate that retraction. Like, I appreciate your enthusiasm for Rust and all, but try not to blindly label it as the next coming or something because that's just super annoying. 
This is a problem I constantly think about —cross platform GUI framework. GTK is too heavy in my opinion. It’s a valiant effort but we can do much better for a minimal abstracted GUI library. Using something like XAML for declarative UI/bindings and a minimal MVC/MVVM framework. It would be very similar to WPF development but cross platform. Another goal would be hardware accelerated rendering and scaling for HiDPI. The entire GUI can be rendered in something like OpenGL. It needs to be easy to deploy on all platforms, require minimal dependencies, loosely coupled with backend data, and allow UI layout and customization similar to CSS.
I don't know. But it's not "you know your app will look the same everywhere". That's false. You can do that without 100 MB.
For example, consider this: Chromium does process separation for sandboxing. This includes a lot of serialization and IPC code. It's a great feature if you handle untrusted content. Do you need it for your UI where all content is trusted? Probably not.
This should work similarly to `const fn` bounds. `const impl` would imply all bounds are `const` at compile-time, etc. It would be good to mention in the post though.
Sciter is ineligible because I have a strong policy of only allowing games and a small selection of grandfathered-in components to be closed-source. (BIOS/UEFI, nVidia binary drivers, Flash, etc.) Also, my default license is GPL and, if I use the Qt bindings formerly known as PySide 2, LGPL is a perfectly satisfactory option for non-GPLed stuff. Aside from that, a big part of the problem is how painfully bloated things get if you want a framework to run *inside* something like Sciter to provide a (probably still half-assed) implementation of all the things Qt does that you never think about unless you download/buy the big pile of platform convention and HIG docs and run through them item-by-item. (In my experience, even something as basic as supporting the X11 `SELECTION` copy-paste mechanism sometimes behaves in flaky ways under Chromium.)
Yup, if you are looking for open source, no Sciter, or other similar great technologies. But I think most people are okay with closed source, isn't it the case? "Strong policy against closed source" sounds incredibly niche to me.
No, it's huge because it bundles chrome with it, which leads to the same look everywhere
&gt; It's about future-proofness; if you do it like this you can later find a way to remove the member or store it in a different way or maybe enable some other caching optimizations that you can't when you return the member itself because then it can never become a function. The problem is that creating a reference on the fly is not *easy*, and imposes a significant run-time cost ever after. The immutable reference case is already a headache: class Foo { public: bool const&amp; get_foo() const { if (!mBools) { /* copy */ } return mBools[FOO_INDEX]; } private: std::bitset&lt;64&gt; mBits; mutable std::unique_ptr&lt;bool[]&gt; mBools; // lazily allocated. }; First of all, the lifetime of the reference is only bounded by that of `Foo`, so you can only ever de-allocated `mBools` in the destructor. Oh, and be careful about that move assignment operator, the user expects the current reference `mBools` to remain valid. Secondly, once allocated, updates need be visible immediately; so suddenly any method updating `mBits` needs to *also* update `mBools` if set. GREAT. However, it only gets worse with mutable references; which is why I said they were in general an anti-pattern. bool&amp; get_foo() { if (!mBools) { /* copy */ } return mBools[FOO_INDEX]; } The getter is simple enough, but what of the implication? Well it means that now `mBools` has become the primary source: if allocated, it is the most up-to-date representation. The great news: you don't need double updates, actually. You only need double-execution paths: once `mBools` is allocated you can ditch `mBits`, it's no longer in use. *Note: a setter does not suffer the issues of a mutable getter, it also has other performance implications...* --- Honestly, at that point I'd rather pick between: - Continue with the current design, and forego the `mBits` optimization. - Or just swallow the cost and release a breaking change. The craziness above is a maintenance nightmare... especially since there's a nasty surprise in the code above, an undocumented behavior which did break despite all our care, do you see it?
Note that I began my original comment with "For me,". Speaking more generally, use of Sciter will hurt efforts to get adoption on Linux platforms because end users are still quite used to expecting good stuff to make it into the main Debian repos as it gets noticed and then trickle down to Ubuntu and Mint... and closed-source components don't meet the requirements.
Honestly, I'd say "who cares about Linux adoption" but I will be gentle and you can certainly run your own APT repository for applications using Sciter, you can make it as good as "add-apt-repository" things which I found many Linux users are willing to do for backports, etc.
I’ve seen this idiom before, but I’m not really sure I understand it. Aren’t const methods callable on a non-const object? struct Foo { int DoSomething() const; }; Foo foo{}; int value = foo.DoSomething();
Ah cool! Thanks
Pushrod's whole philosophy is to be as simple as possible, which would - in theory - mean it's fast. There's no plan for game specific UI, but there will be support for themes and skins at a later date. There's currently only support for OpenGL, but seeing as I'm maintaining my own draw loop, I may modify this to use other methods.
Was a GEM developer for 6 years. Loved it!
In C++ with overloading the const and non-const versions are usually called the same. Thus, if you could write something like template &lt;qualifier cv&gt; int cv&amp; get(int i) cv { return data_ptr[i]; } then that's perfectly idiomatic. In Rust, the two versions have different names, making a single generic version unidiomatic.
Is PathFinder opengl specific? It would be great if any GPU-based solutions were built on top of gfx-hal, which would seem to align with the goal of being platform-native (DX12 on windows, Metal on iOS/OS X, Vulkan on Linux, webGL in the browser).
Despite the Rust developer pool being much smaller than other languages, you’re likely to find those hungry programmers who care.
@rhinotation, you are correct. The etcd v3 API does support exactly what I am talking about. Awesome. Turns out it is a good idea to have something like this after all. You know, I feel the like the etcd docs could be improved a bit. Seems like features are not always make as clear as they could be.
For anyone coming to read this, turns out etcd already has essentially this exact functionality in its v3 API. The lease API: https://coreos.com/etcd/docs/latest/learning/api.html#lease-api All the best.
Those pure rust gui frameworks look really nice, especially azul and orbtk. Another cool pure rust webframework is [relm](https://github.com/antoyo/relm), development is pretty active, and it's based on how gui development with elm is done.
That would be awesome!
thank you for the hint! Iv'e managed to get it working thanks to macro ([https://users.rust-lang.org/t/creating-a-generic-insert-method-for-diesel/24124/5](https://users.rust-lang.org/t/creating-a-generic-insert-method-for-diesel/24124/5)) but it's very ugly and not satisfying so I will ask on gitter.
Pathfinder relies on a number of glsl shaders, which can in principle be compiled to SPIR-V and translated into whatever representation some platform finds convenient; I think the gfx project is attempting to support doing that, for example.
I always love docs PRs!
I wonder if the connotation is regional, because it’s the reverse where I live: alternative is neutral, and competitor seeks to dominate, to make the other inferior.
Just two small comments: * The `::new()` constructors may be a bit cumbersome to use and hurt composability. I'd use `fn new(digits: [u8; 10])` and `[u8; 12]` instead. * How about generating enums for the registration groups instead of using strings? 
sciter looks really neat!
&gt; You don't have to encode enums as strings, or include field names inside the message, the format is flexible in that regard, and some implementations let you choose how individual structs are handled. All implementations would need to handle it the same way, otherwise they won't be interoperable. If one implementation sends the enum discriminator, and the other side expects the string, then it can't be deserialized. &gt; Also the way messagepack is encoding it's values may be more compact than protobuf for some cases like small integers or short strings, because it can fit both value and type (or length and type) in the same byte. I don't know if protobuf can do this, but i assume no. It does the same.
i like how the linked [chesrelm sground](https://github.com/niklasf/rust-chessground) is a widget you can drop into another project. i hope relm develops a widget library ecosystem (though admittedly there aren't that many gui components that are easily reusable).
Rust engineers are rare, but the jobs are even rarer.
I think the support is very flaky, if at all. However it needs to support COM/UWP, if it is to be taken seriously as system programming language on Windows.
gfx-rs does indeed support that. It would more be a matter of porting over the rendering code into the lower-level Vulkan-like API. 
The problem is that, as written, the type of `v` is either `Setup&lt;f64&gt;` or `Setup&lt;f32&gt;`. If you were to call a method on the result - even if the method was implemented on both types - the compiler wouldn't know what function actually needs to be called (since monomorphization will make them different.) That's why it's important to know what you are going to use `v` for. If you're just going to call some method on it that doesn't depend externally on the type `T`, you'd probably be best making that a trait that `Setup` implements and then having `b` be a `Box&lt;dyn SetupTrait&gt;`. But if the method types are different based on `T`, then you might just need to do your handling in the match block itself.
Embedded devices are not websites, it doesn't need to be compatible with every implementation in the existence, only with the ones you control on the other end. &gt; It does the same. Looking [at this documentation](https://developers.google.com/protocol-buffers/docs/encoding), it seems that it always storing the type and length in a separate bytes. I don't see how it's the same, sorry.
If you are testing a struct you made, and want to use \`assert\_eq\` you need to have the \`Debug\` and \`PartialEq\` trait because assert is expecting that. If you used \#\[derive(Debug, PartialEq)\] on your \`struct\` you need to use it on all custom struct inside that structure because \`derive\` implements it for every part. For example struct Verb \{ word : String, pos: usize, \} If you try to compair two \`Verb\` it will check if \`Verb.word\` are the same and \`Verb.pos\` are the same. \`Derive\` only works if each of these pieces \`pos\`, \`word\` already implement \`PartialEq\`, and this case they do because they are built in types. But if you made your own struct then you'd need to manually implement \`PartialEq\` or use \`derive\`. In this example you might not want your comparison to work this way because maybe you don't care about position. You just want to see if it's the same word. You can manually implement \`PartialEq\` only using \`word\` so none of the other members would need to implement \`PartialEq\`
I would call it an alternative, it will be very difficult to complete (nor do I want to) with Lucene / ES's simply staggering level of functionality and time in the ecosystem.
I have a struct `DirectoryChange&lt;'a, 'b, 'c&gt;`. I'm having a problem in `DirectoryChange::new`: pub fn new(old: &amp;'b Dir, new: &amp;'c Dir) -&gt; self::Result&lt;Self&gt; { /* omitted for brevity */ /* Dir::get_directories(&amp;self) -&gt; Vec&lt;&amp;Dir&gt; */ let os_dirs = old.get_directories() .into_iter() .collect::&lt;BTreeSet&lt;_&gt;&gt;(); let ns_dirs = new.get_directories() .into_iter() .collect::&lt;BTreeSet&lt;_&gt;&gt;(); let created_directories = ns_dirs.difference(&amp;os_dirs) .map(std::ops::Deref::deref) .collect::&lt;Vec&lt;_&gt;&gt;(); /* omitted for brevity */ } I am getting the error: error[E0495]: cannot infer an appropriate lifetime for autoref due to conflicting requirements --&gt; src/lib.rs:58:27 | 58 | let os_dirs = old.get_directories() | ^^^^^^^^^^^^^^^ | note: first, the lifetime cannot outlive the lifetime 'b as defined on the impl at 47:10... --&gt; src/lib.rs:47:10 | 47 | impl&lt;'a, 'b: 'a, 'c: 'a&gt; DirectoryChange&lt;'a, 'b, 'c&gt; { | ^^ note: ...so that reference does not outlive borrowed content --&gt; src/lib.rs:58:23 | 58 | let os_dirs = old.get_directories() | ^^^ note: but, the lifetime must be valid for the lifetime 'c as defined on the impl at 47:18... --&gt; src/lib.rs:47:18 | 47 | impl&lt;'a, 'b: 'a, 'c: 'a&gt; DirectoryChange&lt;'a, 'b, 'c&gt; { | ^^ = note: ...so that the expression is assignable: expected std::vec::Vec&lt;&amp;'c dir::Dir&gt; found std::vec::Vec&lt;&amp;dir::Dir&gt; I think that the problem is that `BTreeSet::difference` uses a late bound lifetime argument in the form `pub fn difference&lt;'late&gt;(&amp;'late self, other: &amp;'late Self) -&gt; Difference&lt;'late&gt;` Is there a way to fix this?
This is a very useful project and I really appreciate the work. Do you store the LoC from the Badges somewhere? I mean it could be a feature to show some code activity graph like on GitHub or some sort of “activity badge”.
Is "Gameface" what they rebranded "Hummingbird" to or is it something else?
That's awesome, thanks
I really appreciate the --columns option, makes it so much more readable on large screens. Congrats on the great work!
I would definitely go for a Qt C++ app. None of the Rust options are remotely mature enough yet. Depending on what your app is you may be able to write the logic in Rust and just wrap it with a C++ GUI.
Mostly curious if others would find this useful as well. Unfortunately the current test runners don't leave much space for a good user experience here but this is the best I could come up with. Would love to get feedback on this.
Sciter is definitely quite light weight, but it does not have the amount of functionality that qt has. Also, sciter is not exactly web technology. Sciter may allow some web things, but it does not use JavaScript and you could not run angular, react, or Vue on it for example. Electron truly gives you the entire power of the web and that is why it must be larger than sciter.
I honestly see Rust Qt binding generator as one of the most promising projects, but it really needs a community and like a website with guide information etc.
Please correct me if I'm wrong, but isn't it UB? It was my understanding that mutating a value behind a pointer/reference \[that was initially \`const\` but lost its qualifier with \`const\_cast\`\] leads to UB..
Cool project, thanks for posting!
What do you mean by “OrbTk… is moving toward WebRender”? Will it eventually offer webrender as a backend?
Great?
Interestingly, this ended up being the [single most impactful]( https://www.timqian.com/star-history/#tantivy-search/tantivy&amp;toshi-search/Toshi ) post for both Toshi and Tantivy's visibility.
Oh no, no offense. I wish I lived closer to where System76 is.
Another option, one that I'm using currently, is electron, using neon to interface between rust and js.
this is definitely the correct approach.
&gt; In any language, returning a mutable reference to a data-member is dubious. It completely breaks encapsulation and prevents any invariant involving the data-member in question... Really, the data-member might as well be public. I agree for most cases, but there are a lot of scenarios where the whole point of the type is to contain some other data, e.g. any collection, any iterator. These are less common cases, but they still come up pretty frequently.
A sentence or two on what snapshot testing is (and perhaps a link to learn more) in the project README would be appreciated.
Nice, you may want to post it as an option over [here](https://github.com/dlech/KeeAgent/issues/159). I was previously using the socat + npiperelay solution but yours much more directly solves the problem.
"GTK is too heavy, I want something like WPF, with OpenGL rendering, with CSS" hmmmmm. Maybe you want… GTK? :) Usually when people say they want "minimal" they're thinking of something like imgui/conrod, not of all the features that make GTK "heavy". Upcoming GTK 4 actually renders everything with GL or Vulkan, by the way.
It's just generally something I've based on observations/previous statements I've heard. Not even only of/from the Redox developers, but of many people in the Rust community at large. The number of crates that don't compile out of the box on every platform simply because the author decided to do something like use `fork` and `waitpid` directly (or vice versa depending on the platform) is embarassing as far as I'm concerned. That kind of abject incompatibility is exactly the sort of tired trope of various other languages that Rust is supposed to (and can/does) solve.
"most people" as in regular users? Sure. But developing "mass market apps" is probably not the most popular thing right now, since that market is saturated. Many people here work specifically in the Unix/freedesktop "closed source is unacceptable" niche. I'm honestly very surprised to see someone from outside this niche :)
Interesting! I’ll take a look at it. I admit I’m not well-versed in GTK, so I may have some misconceptions about it. Definitely will look further to see if I can leverage it.
I have been thinking about this problem for quite a while now and came up with a pretty similar solution (using frunk). You end up with some absolutely crazy type-signatures. For example here is the signature for an outer join between two frames. (It checks at compile time that the joining columns are compatible). pub fn outer_join&lt;LCol, RCol, Oth, LIx, RIx&gt;( self, other: &amp;Frame&lt;Oth&gt;, ) -&gt; Frame&lt;&lt;&lt;Oth as Plucker&lt;Column&lt;RCol&gt;, RIx&gt;&gt;::Remainder as Concat&lt;H&gt;&gt;::Combined&gt; where Oth: HList + Selector&lt;Column&lt;RCol&gt;, RIx&gt; + Plucker&lt;Column&lt;RCol&gt;, RIx&gt; + Concat&lt;H&gt; + HListClonable, &lt;Oth as Plucker&lt;Column&lt;RCol&gt;, RIx&gt;&gt;::Remainder: Concat&lt;H&gt; + HList, LCol: ColId, LCol::Output: Eq + Clone + Ord, RCol: ColId&lt;Output = LCol::Output&gt;, H: Selector&lt;Column&lt;LCol&gt;, LIx&gt; + Replacer&lt;LCol, LIx&gt;, { // impl... } I have a WIP library that aims to be a typesafe version of `pandas`. But there are pretty significant ergonomic issues at the moment, and I'm not sure they will ever be solved. But I'm hopeful that some of the const-generics, GATs and macros 2.0 features will help.
When people say GUI, in many cases they're referring to, you know, actual complex multi-form desktop applications. As in the kind of thing that has never been implemented as a website, for obvious reasons. Please try to think on a slightly grander scale in general, folks.
&gt; Many people here work specifically in the Unix/freedesktop "closed source is unacceptable" niche. Not as many as you might suspect, I don't think. Regardless, as always the glaring problem *with* that "niche" is the generally lower level of quality as far as the options it offers for most things. You can talk abut licenses all you want, but personally the *only* thing I care about at all is using whatever allows me to produce software for the widest possible audience. The enduser experience &gt; vague moralizing 100% of the time as far as I'm concerned.
Definitely useful. Proc macros could provide a nice convenience layer, eg: ```rust #[spapshot_test(serialize)] fn test_whatever() -&gt; MyType { ... } ```
Thanks for the tip! I left a note there in case anybody is interested.
Rust seems to me like a very "unixy" space. There's a reason the most mature Rust UI toolkit binding is to GTK ;) Well, it's fine to care about different things. I care about being able to port software to any of my unusual environments, about preserving software for the future (same thing, porting), about being able to fix any issues myself… That's not moralizing, that's practical issues. And as a developer, being able to fix any bugs by yourself in any of your dependencies and tools – in anything in the whole stack below your application – is *immensely* powerful. Not something to give up lightly! Recent example: Chrome and Firefox switching from MSVC to clang-cl precisely because waiting for Microsoft to fix issues was terrible.
I' making this battle for a while now, because I wanna build [a relational language](https://bitbucket.org/tablam/tablam/wiki/browse/) and just to make my life too hard use both columnar and row-oriented layouts. &amp;#x200B; I think is impossible to be efficient both ways. One direction or another must be riddled with clones. However, reading this article this part caught my eye: To make this more efficient, you could make a function like fn write_row(&amp;self, write_into: &amp;mut Planet) to write a row from the frame into an existing Planet. This way, you could get the value of a row without needing to allocate new memory. But need to think how do it. What I getting very hard is how provide a generic solution to implement the relational operators that work across different containers and also, streaming sources like files and databases. &amp;#x200B; But some things that could help: \- Check ndarray-like crates. I like [https://github.com/AtheMathmo/rulinalg](https://github.com/AtheMathmo/rulinalg) but is not updated. However the code is easy to understand. \- Pick what direction is the "default" If columnar, maybe hlist are used for the row representation. \- You can do Array-Of-Structure-Of-Arrays ([https://github.com/ispc/ispc/wiki/Better-in-language-support-for-aosoa-layout](https://github.com/ispc/ispc/wiki/Better-in-language-support-for-aosoa-layout)) to have a bit of both. I haven't truly explored how implement the idea. &amp;#x200B;
This definitely is trickier than I would have expected, given the behavior you are seeing from LLVM. The updates are informative too--thank you for doing this!
Electron is huge because chrome is huge, and electron uses chrome. Chrome (and firefox) use *significantly* more system resources than Safari or Edge, which are actually pretty efficient. This is super noticable on a Macbook, where I can get 10 hours of battery life while running Safari, but only 6-8 while running Chrome or Firefox.
&gt; Honestly, I'd say "who cares about Linux adoption" Quite a few Rust devs I'd imagine. Linux is pretty popular among programmers, and especially those using "lower-level" languages.
I came up with the following a while ago, but it has a stupid amount of type constraints, which I can't at the moment guarantee are all needed: ``` /// Generic function for creating a row for a given table with a given "new" struct for that row type. #[inline(always)] pub fn create_row&lt;Model, NewModel, Tab&gt;(table: Tab, insert: NewModel, conn: &amp;PgConnection) -&gt; Result&lt;Model, Error&gt; where NewModel: Insertable&lt;Tab&gt;, InsertStatement&lt;Tab, NewModel&gt;: AsQuery, Pg: HasSqlType&lt;&lt;InsertStatement&lt;Tab, NewModel&gt; as AsQuery&gt;::SqlType&gt;, InsertStatement&lt;Tab, &lt;NewModel as Insertable&lt;Tab&gt;&gt;::Values&gt;: AsQuery, Model: Queryable&lt;&lt;InsertStatement&lt;Tab, &lt;NewModel as Insertable&lt;Tab&gt;&gt;::Values&gt; as AsQuery&gt;::SqlType, Pg&gt;, Pg: HasSqlType&lt;&lt;InsertStatement&lt;Tab, &lt;NewModel as Insertable&lt;Tab&gt;&gt;::Values&gt; as AsQuery&gt;::SqlType&gt;, &lt;InsertStatement&lt;Tab, &lt;NewModel as Insertable&lt;Tab&gt;&gt;::Values&gt; as AsQuery&gt;::Query: QueryId, &lt;InsertStatement&lt;Tab, &lt;NewModel as Insertable&lt;Tab&gt;&gt;::Values&gt; as AsQuery&gt;::Query: QueryFragment&lt;Pg&gt;, Model: TypeName, { insert .insert_into(table) .get_result::&lt;Model&gt;(conn) .map_err(handle_err::&lt;Model&gt;) } ``` So there it is, a generic `create_row()` function accomplished without macros, but I can't say the result is pretty.
I think I saw some mention of qml which had rust code as its code object instead of the Js style code. That looked cool 
I realized I need to develop my question further. One stipulation in the link is that "any `const` function definition of the form ... may take only `const` implementations for each of the traits [appearing in the function header]". A `const` implementation of a trait is one in which all functions are implemented as `const`. As a consequence, the trait "A" above cannot have a `const` implementation, so it cannot be used as a trait bound on a generic type parameter in a `const` function. This is annoying for library developers, since whenever they provide a non-`const` trait with a function that *might* be useful in a `const` context, they would have to separate the `const` and non-`const` parts of the trait out, so that a user could still get a `const` implementation of the `const` parts of the function. It looks like this was addressed by the addition of `?const`. But I have to ask- is there any point in time where I'd *lose* functionality by adding in `?const`? For example, there can be at most one `T: ?Sized` in a struct.
No one is using the fork syscall unless there's good reason to do so. There are legitimate use cases for the fork syscall, such as in system shell designs, and even some networking applications. It's a core component that enables process expansions in shells. There isn't a good alternative that doesn't involve neutering process expansions to borderline uselessness. The NT kernel is the only kernel today that does not expose a fork syscall for programmers to interact with, despite supporting this feature internally in private APIs. This is why Windows will forever lack a decent system shell. You can compile and use the Ion shell on Mac, Linux, and the BSDs, but until Microsoft decides to revert their decision to keep the fork syscall hidden, it will never be available on Windows.
I think a system-native-toolkit abstraction layer is the way to go, honestly. If it abstracts other UI toolkits that's a bonus. 
Googling, looks like snapshot testing is about comparing screenshots of GUIs to see if something changed. But here I guess that strings comparison are being made to see if structs change debug strings? ({:?})
&gt; COM/UWP to be taken seriously as a system programming language on Windows Throwing away their C-compatible FFI (COM/Win32) isn't a good business decision. UWP is the shiny new thing intended to attract Android developers, which is also a good business decision. Microsoft can be counted on for good business decisions. I'm typing this using Firefox Quantum on Windows 10 - a Win32 app with Rust components doing serious "engine" level stuff. I don't think UWP is necessary for Rust to be taken seriously (though a mature safe-Rust wrapper for COM/Win32 probably is) and it's unlikely to happen without Microsoft deciding that Rust should be one of the WinRT languages. [They've chosen which languages to support: C#, C++, Visual Basic, JavaScript.](https://docs.microsoft.com/en-us/windows/uwp/get-started/universal-application-platform-guide) The walled garden has a back gate, however. The [desktop bridge](https://docs.microsoft.com/en-us/windows/uwp/porting/desktop-to-uwp-root), which I think just shows the extent to which Microsoft wants to continue to allow systems programming without needing to use the UWP APIs.
Obviously. I said "hurt Linux adoption", not "stymie Linux adoption".
I wish I could see it as promising, but it's developed and dogfooded by KDE developers, who are used to working in C++. Last I checked, it was for incorporating Rust modules into a Qt/C++ project, meaning that you still need to trust yourself to write C++ to talk to Qt and to write build automation for C++, like CMake. At least, if I combine Rust, rust-cpython, Qt, and Qt bindings for Python, I know I can't write a memory-safety bug... even though Python's ability to detect bugs at build time is limited to glaring syntax errors which prevent `.pyc` bytecode generation.
&gt; Well, it's fine to care about different things. I care about being able to port software to any of my unusual environments, about preserving software for the future (same thing, porting), about being able to fix any issues myself… That's not moralizing, that's practical issues. Agreed. For example, if I'd used Sciter for anything, I wouldn't be able to port my creation to my OpenPandora handheld or its upcoming successor, the Pyra. (Both ARM-based devices using desktop Linux rather than Android. The Pandora's default desktop session is Xfce-based and the Pyra will be using Debian with a custom repo overlay.) Likewise, it's the reason that I insist on also having Windows versions for any Linux games that are allowed to exist on my system as closed-source applications... so I have the option of using Wine as a patchable insulation layer between a static application and a shifting platform. (I *do* still play Win16 applications from my childhood. Bricklayer is my favourite Tetris clone, for example.)
Technically speaking, isn't Winrt based on and interfaceable through COM?
&gt;No one is using the fork syscall unless there's good reason to do so. They absolutely do. For very simplistic things at that, like simple process handling that would be better done through any number of abstractions. Don't ask me why, but they do. &gt;*Bunch of stuff about shells* Honestly this is mostly irrelevant to me. Our overly heavy focus on simplistic CLI stuff as a community is very strange IMO, and not especially helpful in the grand scheme of anything. That mindset is what got us where we are now, where people think terminal-UI crates with functionality that is literally not even equivalent to various TUI libraries that were available in the early 90's are somehow noteworthy/technically impressive, when they are simply not. I don't want to be *discouraging* of anyone, but I just really think our general bar for what is and isn't considered "news" is way way way to low currently.
&gt;Rust seems to me like a very "unixy" space. That's true, sure. I don't think that means what you appear to think it means, though. &gt;Well, it's fine to care about different things. I care about being able to port software to any of my unusual environments, about preserving software for the future (same thing, porting), about being able to fix any issues myself… That's not moralizing, that's practical issues. I don't disagree with you, but from what I've observed nearly no one in the Rust community really embodies what you're describing (which drips of legacy C API problems to begin with if you ask me.) The Rust community is chock full of people who know absolutely jack poop about any platform other than the one they use, and who regularly and constantly make wrong assumptions in their `cargo.toml` and `build.rs` files. This more than anything else is what makes me dislike the way Cargo is built around assuming the original author of a Crate definitely knows everything and is 100% correct about what they've put in their project/build files, because it's an assumption that doesn't reflect reality at all. People are regularly *very* wrong in various ways that do in fact require directly editing the files in order to fix them.
I actually just edited my initial post to point to this fact. It's all well and good to say "use Sciter", but, from my perspective, it's not really that different from trying to convince someone to ditch Qt in favour of reinventing an accessible, native-feeling widget toolkit inside SDL. It's never "Qt vs. Sciter vs. Electron vs. ..." but, rather, "Qt vs. some web engine **plus** a framework that provides all the equivalent functionality".
Yes, but it's also a code smell and one of the many, many ways that Rust amplifies the pain factor of OOP when OOP might not be the best solution to the problem. In this case it looks like a Law of Demeter violation. Note that when the standard library does this it's because the structure functions as a container. If `cur_tape_and_idx` is a method of type `U`, that suggests the *purpose* of type `U` is to serve as a collection of tapes - and not only that, a collection which knows which tape is "current". It's possible that a structure is just a big ball of state machinery. That's not necessarily a bad thing - it's just a *procedural* thing and OOP and LoD don't apply. Under the procedural paradigm your functions are actually *non-reentrant subroutines* and it makes sense to use `&amp;mut StateMachine` but less sense to use `&amp;StateMachine`. Rust strongly encourages organizing `StateMachine` so that breaking it down into substructures parallels how the call graph will break down the task of updating state into subroutines. If they match well enough the borrow checker will be happy. If not, well, you may need a tasteful amount of `RefCell`. All that said, it's probably possible to factor out the part of the methods which identifies the current tape.
It now supports cargo for building instead of cmake. A basic application has a single main.cpp that is very minimal and is prewritten in the template. You will still use qml for frontend(or c++ if you use qt widgets instead of qt quick). Based on what I can tell, once the project is setup you just have to write rust, qml, and json. I am still new to it, but that is what makes it promising. Side note, because it is new I am sure edge cases will exist that force you to use c++ to get some form of functionality.
No.
I have seen this with a hyper client such as reqwest. I think it's just noise in the debug logs indicating that the other side has dropped the connection. No issues in production with these messages so far.
It definitely is. Keep in mind also that a Windows application built with "classic" WinAPI calls *looks* entirely identical to a WinRT application as long as the native "theming" is enabled.
Doesn't this proposal make adding non-const default functions a breaking change, then? If I have a trait trait FooBar { fn thing1(&amp;self); } Right now, it's a non-breaking change to transform it into trait FooBar { fn thing1(&amp;self); default fn thing2(&amp;self) { println!("hi"); } } But with this proposal, `const impl`s for the trait would _break_ when I made this (previously non-breaking) change. Is there any way to do this without removing the ability for `default` to transform traits?
Can I tag along on this request? Affordable and open source UI latency measurement would be a very awesome public good.
Interesting article. Thanks for writing it up and posting it here. I think you could contribute a lot to the Rust implementation of Apache Arrow should you wish to get involved ;-) There has been some great progress lately and the 0.12.0 release should be available in the next few days. It might be worth taking another look at it. &amp;#x200B;
Do you have any proposed defaults for associated type bounds in traits? For instance, if I have a trait trait Outer { type Inner: Default; fn process(&amp;self, in: Inner); } and a function const fn do_thing&lt;T: Outer&gt;(input: T) { // ... } Does `do_thing` require `T::Inner: const Default`, or just `T::Inner: Default`?
&gt; Better Integer Range Analysis for Bound Check Elision This is my pet issue too. 20 years old technology called ABCD(Array Bound Checks on Demand) handles all cases mentioned in the article and more and standard in HotSpot JVM for a decade. LLVM routinely gets request for ABCD or its variants or even prototype implementation, but they invariably go nowhere. As I understand ABCD does not pay for itself for C or C++ because bound checks are rare in existing wild codebase. That's why it's only standard in Java. I am pessimistic this will ever be in LLVM...
Don't UWP apps have their own theme that looks completely different and like it should be on mobile? Or do they not call that one "native"
I don't have any immediate use for it either, but I'm thinking of building an ISBN validation/hyphenation demo website with WebAssembly.
This is a milestone. It means all transitive dependencies of ripgrep are also reproducible. This is full reproduction including build path difference. I think we can breathe easy on /u/Manishearth worry [a year ago](https://www.reddit.com/r/rust/comments/6tpirh/debianpolicy_packages_should_be_reproducible/dlmgwvb/). Thanks to all who made this happen. 0.9.0 didn't reproduce. See the [full history](https://tests.reproducible-builds.org/debian/history/rust-ripgrep.html).
I'm not saying it's a great option, but it works. I'm familiar with web dev and not with GTK or QT. I don't have to worry about cross-platform, at least in the UX layer, and it looks consistent on multiple platforms while still having native-looking dialogs and menus. Since everything but the display code is Rust, the application logic itself gets all the benefits of Rust. The code is highly modular, and it's easy to write unit tests for the application logic and separate tests for the UX. For me and my project, it's a nice fit, and it's an option I thought other people should be aware of.
The library admittedly does validate its inputs optimistically, and using enums sounds like a good suggestion. I'll definitely look into improving those! On constructors, I mostly copied ideas from [https://doc.rust-lang.org/std/net/enum.IpAddr.html](`std::net::IpAddr`). The intention is that people should mainly use `from_str`, but at the same time I'm torn between multiple arguments and arrays for `::new()`.
Can't even sort floats in Rust without a 3rd party library
If you have #[derive(Debug)] struct Sandwich { spread: Spread, cheese: Cheese, } enum Spread { Mustard, } enum Cheese { Cheddar, } The compiler will complain because in writing `#[derive(Debug)]`, you are saying "Hey, compiler, write some code so I can `Debug` my `Sandwhich`". The compiler will tell you "But I don't know how to debug `Spread` or `Cheese`, and I need to in order to debug `Sandwhich`". It can make code, but it does things in a straightforward manner and won't try to figure out how to work with `Cheese` or `Spread` when all you've told it to do is figure out `Sandwhich`. The solution, in this case, would be to ask it to make code to `Debug` `Spread` and `Cheese` as well. Then it can use that to write code for `Sandwhich`. #[derive(Debug)] struct Sandwich { spread: Spread, cheese: Cheese, } #[derive(Debug)] enum Spread { Mustard, } #[derive(Debug)] enum Cheese { Cheddar, } ---- This is just one instance where you might get this error, but they all mean approximately the same thing. The compiler is telling you that you are asking it to do something it _doesn't know how to do_. Maybe that's debugging `Cheese`, or maybe it's cloning something, or `Copy`ing. The solution will always be to either: A) tell the compiler how to do the operation for the thing, or B) stop trying to do that specific thing. A is usually only feasible if the structure in question is one you've written. I can't really give you more specific advice than that, because what you want to do will always depend on what operation it is, and what structure lacks that operation. This error will show up in many different places (it's every single time something lacks a trait impl), and it will have many different good solutions for each of those different places. If you have some specific ones which are hard, maybe we could help with those?
&gt;Basically is there a very short way to transform an iterator on references to an iterator on values? Try [cloned](https://doc.rust-lang.org/1.31.1/std/iter/trait.Iterator.html#method.cloned): &gt;This is useful when you have an iterator over `&amp;T`, but you need an iterator over `T`. &amp;#x200B;
This is Paul Graham's [Python Paradox](http://www.paulgraham.com/pypar.html): the more esoteric your tech stack, the easier it is to hire great people. 
Thanks! That's precisely what I was looking for. Do you have any help for the second question?
What do you mean didn't reproduce? 
Yes, two builds were not bit-for-bit identical. See https://reproducible-builds.org/ for the related general information.
Reproducible build means the resulting binary code is always the same after compilation. Right. It means the binary wasn't the same. 
Ah, missed that part. Are you looking for [for\_each](https://doc.rust-lang.org/1.31.1/std/iter/trait.Iterator.html#method.for_each)? You'd have to first create an iterator, though.
Another: this is i386/amd64/arm/arm64 4-way reproduction. Reproducible build in all four architectures.
How different is reproducibility in Debian from reproducibility with stock rustc/cargo?
&gt; You will still use qml for frontend(or c++ if you use qt widgets instead of qt quick). There's the problem I was talking about. QWidgets is the API I need and `rust-cpython` allows me to use Python as a "QML for QWidgets".
It's mostly the same. Debian is just a specific environment so that everything can be specified.
Regarding benchmarking, apart from the `black_box` function (which will be stabilized in some way), crates like [bencher](https.//crates.io/crates/bencher) and [criterion](https://crates.io/crates/criterion) can do benchmarking on stable just fine (both fudge black_box on stable using a volatile write).
&gt; I ran into problems with broken dependencies for some little projects and i took me a wile to fix them Funny that you say that, because I ran into this too - but five times during the last year. The problem is that cargo ignores Cargo.lock files on libraries (not binaries!) and completely relies on the version number in the Cargo.toml for semantic versioning (as far as I can tell). It relies completely on semantic versioning, which is susceptible to human error, so if a dependency messes up semver, it can break your already-on-crates-io deployed crate. But as a library author, I essentially got bug reports for downstream crates, which, as you have more and more dependencies, gets increasingly annoying. This "feature" of cargo has already broken my code five times last year (and is the reason Azul currently doesn't build if you add it as a dependency). The only way I currently know of to permanently fix it is to vendor and lock all dependencies and publish the dependencies as a separate crate [like this](https://github.com/maps4print/azul-dependencies). This is problematic because you'll have to compile some dependencies twice, then, however choosing between "every five days your code breaks" and "more compile time", it's the lesser evil, from a library author perspective. As for a more clean workaround, I think cargo needs automatic semver (to reduce the human error) like Elm does, but this might be very hard to implement. For example, right now cargo didn't "know" that upgrading the Rust edition was a breaking change, so some users got the 2018 version for a 2015 compiler, which of course doesn't work. And then I got the blame for that a la "this repository is so badly maintained it doesn't even build" - no, it's just that cargo has severe structural issues with its version selection algorithm. I just found it funny that you mention it because right now it's the number one problem for Azul, making the code actually build reliably. I did submit a [bug report](https://github.com/rust-lang/cargo/issues/5263) back in March, but as far as I can tell, nothing has been done so far about the underlying problem.
I have been in contact with one of the maintainers and as far as he told me, yes, OrbTK should be getting a webrender port (which would mean that webrender could possibly run on Redox, which would mean that Azul might possibly run on Redox, too).
Thanks for the info. Interesting I wonder if it was things like rng seeds causing it.
Does this mean that Nix packages can be created? I guess they require reproducible builds
You may ask for a paid relocation.
As I understand, Nix is doing something completely orthogonal and different and unrelated to Reproducible Builds effort. This neither helps nor hinders.
There is an increasingly obscure long tail of nondeterminism causes. Yes randomness is one, but there are tens more. You can start [here](https://reproducible-builds.org/docs/source-date-epoch/).
Wait... which other places? I read the Book but only see examples with `match` and destructuring. And I can't see `|` working for destructuring... am I missing something?
You can. You simply need to tell Rust you know what you are doing. fn main() { let mut floats = [1.2, 3.4, 0.5, 2.3]; floats.sort_by(|a, b| a.partial_cmp(b).unwrap()); println!("{:?}", floats); } This will panic on `NaN`, but this is better than undefined behaviour you would get in C++.
Same here, though in my case the thing I have to contribute is my infant daughter's care.
You can als use `for &amp;val in items` (notice the &amp;) in for loops which will automatically make a copy (only if the item is `Copy`)
I've just started lesrning Rust. Not even finished the book yet. I'm about 25% through porting my Haskell NES emulator (github.com/dbousamra/hnes) to Rust. Its fun so far
I’m personally not a huge fan of the idea that a snapshot is created for an entire test. Makes it hard to do multiple snapshots and to share code. The cargo command is an interesting idea. 
It’s for instance useful to debug parsers. If the input evolves for a testcase the expected output is easy to update. 
For the second question, you could do `slice.iter_mut().for_each(func)`, like so: fn transform(it: &amp;mut u32) { *it += 1; } fn main() { let mut x = [1, 2, 3, 4, 5]; x.iter_mut().for_each(transform); println!("{:?}", x); } https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c32415649166cbb44a842b6ae36ca10e
From my understanding Nix relies on the underlying compilers being able to be deterministic in their output so that caching of binaries can be used etc.
My understanding is Nix provides deterministic build graph. Not deterministic build result. With Nix, you will run exactly equivalent binaries on exactly same files in exactly same order. This does not guarantee bit-for-bit identical result. For example, there may be pointer comparison in build toolchain somewhere which is affected by address space randomization done by kernel. And 100 more nondeterminism sources like that. My understanding is Nix needs "functional equivalence" determinism, that is, output needs to work the same. Output doesn't need to be bit-for-bit identical.
PS: the crate would be much nicer as a part of a larger testing framework. Sadly, no one seems to be working on the accepted custom test frameworks RFC currently.
Last week I started writing trcc, the tiny &amp; rusty C89/99 compiler. On Saturday I started working on a (probably scheme-ish) dialect of Lisp. Today I'll be writing the parser for trcc live on Twitch and I hope to get some special forms working in my Lisp by the end of the week. Just now I got the 5 (+, -, \*, /, %) arithmetic operators compiling for constant expressions.
People seem mystified by what reproducible build is, so I will give an actual example of problems fixed in Rust. Rustdoc generates a JavaScript index so that you can search for types and methods. Let's say, `index = {"foo": "some link 1", "bar": "some link 2"};`. If you are not careful, this can print as `index = {"bar": "some link 2", "foo": "some link 1"};`. Searching in Rustdoc works exactly the same. But build output is not bit-for-bit identical. So if you build locally and create a distribution, it may not bit-for-bit match official build distribution, because JSON index key order is different. Since checksum doesn't match, you can't be sure whether official build distribution binary is really built from the purported source. Checksum match gives you that confidence.
Yeah, .cloned is so convenient, works on `Option` too. I learned about it from clippy. Highly recommend running cargo clippy for this type of questions, you may just find an answer right away.
I've done something similar for a VM emulator, with a `run` method that runs it for as much as possible, then returns a couple of possible states: - IO required (print/read) - execution error - halted
Thanks!
I realized that just after making the post, thanks!
&gt; Rust seems to me like a very "unixy" space. I think we should strive such that this becomes entirely false.
That's it!
Yes that seems to be the case. Thanks for the explanation
Yes, Gameface is a new name for Hummingbird.
I like being more generic. use std::ops::Mul; fn multiply&lt;T: Clone + Mul&gt;(x: T) -&gt; impl Fn(T) -&gt; &lt;T as Mul&gt;::Output { move |y| x.clone() * y }
Awesome! This is exactly the thing I need for rust-analyzer. There, all high-level API return a bunch of PODs, and asserting results with a gazillion of assert_eq is horrible. I tried comparing `Debug`s, but the "gold value" quickly becomes unreadable. Keeping it in a separate file as YAML should fix this. One think I am worried about though is that, to use YAML, I need to make my structs to implement `Serialize`, and that's a huge change to the public API. I wonder if it is possible to make struct "serializable, but only for testing". I guess `#[cfg_attr(test, derive(Serialize))]` would work? An alternative would be to have `#[derive(Snapshot)]` which either creates a mirrored structs and derives implements `Serialized` for that, or (more work, but better compile times) uses roll-your-own miniserde-like derive. 
Very few types would implement a custom trait that’s why i went with Serialize as an alternative to Debug. YAML because it diffs well (eg: no comma issues). 
Probably I should use more generics too..
I don't understand why this code doesn't compile ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0fb8c43bbcb598d8d51917514d22d46c)): fn f&lt;Q: ?Sized&gt;(s: &amp;Q) where String: std::borrow::Borrow&lt;Q&gt; { f("a"); } (I understand that it would cause a stack overflow if it did compile, but that's beside the point). The error message says &gt;note: expected type `&amp;Q` &gt; &gt;found type `&amp;'static str` suggesting that it has to be the same `Q`. But isn't it allowed to call a function recursively with a different generic type?
It's possible to shorten this: use std::ops::Mul; fn multiply&lt;L: Clone + Mul&lt;R&gt;, R&gt;(x: L) -&gt; impl Fn(R) -&gt; L::Output { move |y| x.clone() * y }
This may actually be a bug because it works if you specify the type in the function call: [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a779a61a4f354be6903d5be6ac5db927) fn f&lt;Q: ?Sized&gt;(s: &amp;Q) where String: std::borrow::Borrow&lt;Q&gt; { f::&lt;str&gt;("a"); } (Now that the compilation succeeds, it does warn about the infinite recursion.)
I'm using ggez to write a hideous connect 4 game as a frontend for a nigh-invincible connect 4 god bot, once the bot works I may switch from ggez to a more practical engine like Amethyst
Hello, a Rust beginner here looking for help. &amp;#x200B; I am trying to get my head around properly handling and propagating errors, and is having a hard time deciding how I should do it for `std::process::Command.` &amp;#x200B; I see that Command returns a `Result&lt;Output&gt;`, which uses the `std::io::Result` instead of `std::result::Result`, and that the Output struct contains the `status`, `stdout` and `stderr` fields. Does this mean that the Error will always be empty, and my error handling needs to be based on the `stderr` field? Also, in this case if I wish to propagate the errors upwards, should I a) 'handle' the `stderr` field errors, and return a `Result&lt;T,E&gt;`, such that the error propagated upwards uses the standard `std::result::Result`, which conforms with the rest of my program. b) Propagate `Result&lt;Output&gt;` upwards, meaning the other modules need to know about `std::process::Output` and specially handle it. &amp;#x200B;
Ah, I hadn't thought of trying that, I guess it's a bug then!
If you haven't already, check out kdb+ for ideas and inspiration on well thought out design for column-oriented data.
Debian are actually going out of their way to not ~~fix~~ pin too many things, unlike other projects. The [full list of variations](https://tests.reproducible-builds.org/debian/index_variations.html) is pretty extensive. Varying the build time and path are the most annoying issues. Many projects are pinning these (i.e. the code is always in `/build/ripgrep/Cargo.toml`, and the build is always run at `2000-01-02T03:04:05Z`), but Debian are not.
I've introduced \[ropey\]([https://github.com/cessen/ropey](https://github.com/cessen/ropey)) to my text editor project \[Accepted\]([https://github.com/hatoo/Accepted](https://github.com/hatoo/Accepted)) instead of Vec&lt;Vec&lt;char&gt;&gt;. I'm very satisfied with \[ropey\]([https://github.com/cessen/ropey](https://github.com/cessen/ropey)). It's faster to load bigger files and uses fewer momory. &amp;#x200B; I've also add some tests to \[Accepted\]([https://github.com/hatoo/Accepted](https://github.com/hatoo/Accepted)). It's still very simple but helpful to find bugs.
Honestly I wish there was something like Android sdk, but in rust and on desktop. Layout tools are amazing. Surprised why every single rust framework that isn't using web is ignoring that part.
Yeah. It's kind of amazing Debian got to 80% reproducibility with this. I am happy that wave of Rust packages are not regressing that percentage. :)
So basically the idea is that there is some canonical form the compiler should compile the code into?
The error case of the `io::Result&lt;Output&gt;` you get from `Command::output()` actually covers any errors encountered when trying to spawn the child process or read from its stdout/stderr pipes. These are situations where the current process (the one running your code) doesn't actually have permission to spawn a process (or to run the target executable), or the command path was wrong, or the OS was out of memory to create the pipes, etc. The content of the stderr stream of the child process and its importance is entirely based on the executable you're running. Typically, error messages and other important notifications are output to this stream while normal output goes to `stdout`. When running a program directly in the terminal it usually interleaves both streams into one so it's hard to remember that they're actually two distinct data streams. For Rust executables, panic messages and backtraces are printed on `stderr` so if you don't get the output you expected from `stdout` then you might want to print the `stderr` contents for debugging.
Other than there not being a system-native-toolkit on Linux, I agree in principle, though it does depend how feasible this ends up being. A Rust-native toolkit would also be very valuable in my opinion, because (a) there should be a lot less `unsafe` code and (b) it will be portable anywhere the windowing and drawing libraries are available.
It means that without overloading you can't call the function with both callbacks `then_with_callbacks`, unless you call the one with only the fulfill callback something else. You could of course call it something like `then_with_callback` or `then_with_fulfill_callback` but it'll be confusing and you'll have to look up the name of the function you want to call every time. Overloading makes it all a lot easier. All these functions would just be called `then()`, and the right one will be called depending on the number of arguments.
Wow thank you! According to my errors its seems that was what the compiler wanted me to implement, but I never could figured it .... Is this kind of function signature frequent in rust ? Can we call this the trait inheritance hell ? &amp;#x200B;
Still working on my wrapper for [CLIPS](http://www.clipsrules.net) on GitHub [here](https://github.com/mtsr/clips-rs). C FFI is tricky, especially for complex C code. I’m also making progress on the trading card game I’m using it for, but that part isn’t public yet. I’m currently working on exposing the state and events from CLIPS through an API so I can start building a client for it. For the client I’m stuck choosing between a commercial engine (Unity or Unreal) or using Amethyst. Currently leaning towards Unity because of how much faster it’d be to prototype with and because Amethyst is quite unfinished in places (support for web, iOS, Android among other things). 
I've been looking at at Azul today and I think I quite like its approach.
You don't even have to panic on NaN. For example, you can sort NaNs the end of the array with use std::f32::*; use std::cmp::Ordering; fn main() { let mut floats = [1.2, 3.4, INFINITY, -INFINITY, NAN, 0.5, 2.3]; floats.sort_by(|a, b| if a.is_nan() { Ordering::Greater } else if b.is_nan() { Ordering::Less } else { a.partial_cmp(b).unwrap() } ); println!("{:?}", floats); } [Try it online](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=fec739bb1f2533182530bd662520e739)
Sorry for the short answer, but yes, as far as I know. I believe RLS has an older version. Are you using the stable toolchain or nightly?
Stable. If RLS has the older version, why can't I see \`unused\_io\_amount\` when running \`cargo clippy\`? The \`unused\_io\_amount\` error comes from a test, but I run \`cargo clippy\` with \`--tests\`
Driving a library for renderer writers, [rendy](https://github.com/omni-viral/rendy), toward first release on crates.io
ABCD was in LLVM 10 years ago, but [it got removed in 2010](https://github.com/llvm/llvm-project/commit/504e5100d30106850f1e059e27af4cae03425ac4) due to lack of usage, maintenance, and perceived value. I only searched cursorily but didn't find anything about more recent attempts to get it implemented. But are you sure that lacking this kind of algorithm is the main issue? I'd wager that it's more about LLVM's inability to prove that arithmetic expressions don't overflow, as mentioned in Henri's other bullet points. Or would ABCD solve that as well?
My [own OS kernel](https://github.com/Dentosal/rust_os) uses `alloc::vec::Vec` with `no_std`. It's feature gated, but it works.
If I'm not mistaken, there is work to turn the `assert!` macro from the stdlib to a clever assert, just like your macro, so you can maybe help on that end. I'm on mobile right now, but I think there is an RFC and a tracking issue. 
Sometimes if the going gets tough with the borrow checker, I switch to continuation passing style a la return impl. I find CPS works beautifully with lifetimes, especially with values on the stack. You can, for example, implement data structures that live entirely on the call stack and it works bc all values can only point to data with a longer lifetime. Any time you would normally allocate, just put it in a callback. There's probably a better way; but it's a fun little challenge and it's worked well for me :-)
In general this is called [currying](https://en.wikipedia.org/wiki/Currying). In languages like Haskell all functions are implicitly curried, so eg. calling a two-parameter function with just a single parameter simply returns a partially-applied version of the function. Specifically in Rust, you can these days write this using `impl Fn` without heap allocation 🥳
Currying always feels nice no matter the language, wish I knew all the currying tricks inside of Rust.
Some code example will be nice, cause I can get what you mean but if a beginner reads this he will likely be confused.
I experimented a bit with fitting a curve to some data points and made a very rough [interactive visualization thingy](https://github.com/fkaa/curve_fit_test)!
That's not wrong, but maybe too abstract. Compiling the same source code twice should generate exactly the same binary both times, independently of whether the environment changed "slightly" (e.g. time of day, date, build path, etc.). 
I've decided to switch my personal accounting from a spreadsheet to [ledger](https://www.ledger-cli.org). And while ledger is awesome, I miss some of the custom plots I previously had. Looking around for a while, there were a few options but none of them were satisfactory to me, so I decided to write my own app. Once the basic functionality has been implemented and tested, I'll make it available on GitHub.
In haskell there are no functions of more than one argument. `a -&gt; b -&gt; c`, or more explicitly `a -&gt; (b -&gt; c)`, is type of function that takes `a` and returns `b -&gt; c`.
`Option` implements `IntoIter`. Very useful :)
I don't know, that's why I asked. I use Nightly without any `#[feature]`, to help with testing and because RLS usually worked better. I know that RLS used to have its own version of `rustfmt` (different from the one in `rustup`, and apparently older), and I assumed it was similar with `clippy`. Note that I haven't used tool attributes yet.
Writing typescript ast. Want to generate typescript using rust
Thanks for the pointer! I'll look it up!
 fn do_twice(f: fn(i32) -&gt; i32, arg: i32) -&gt; i32 { f(arg) + f(arg) } This function accepts both closures and function pointers, it has function pointers as param When should I prefer this over using a trait object, like &amp;dyn Fn(i32) -&gt; i32 or Box&lt;dyn Fn(i32)-&gt; i32&gt; instead of fn
Now that AGDQ is over (my productivity always takes a nose-dive during GDQ, so this time around I decided not to fight it and take the week off side-project work to watch), I'm picking up my various side-projects again. First up, handling all of the issue triage and similar from the last week or so, then finishing up [TinyTemplate](https://github.com/bheisler/TinyTemplate) and starting to work on [Criterion.rs](https://github.com/bheisler/criterion.rs) 0.2.8. 0.2.8 should be a small release to switch to TinyTemplate for generating HTML and reduce the size of Criterion.rs' dependency tree in a few other ways.
`Box&lt;[T]&gt;` will implement `FromIterator` in 1.32. Useful too sometimes (e.g. `.collect()` should now work).
[`dbg!`](https://doc.rust-lang.org/beta/std/macro.dbg.html) macro, absolutely awesome for tracing program logic and println-style debugging. (should be available in stable 1.32 in a few weeks from now)
It's not that frequent; no. It arises from Diesel being composed of a bunch of individual traits and blanket impls for `T`s with a long list of constraints. It also makes the documentation hard to read to figure out where a method comes from or how to extend the API (as in this case). I kinda like "constraint hell" for this problem.
The source code of https://tokei.rs is [available on GitHub](https://github.com/Aaronepower/tokei_rs). Right now the only thing that is stored is the commit hash, and the results of that run, this cache only survives 3 months and then is deleted from the database. The repositories are stored in a temporary directory. The only current way for me to see who is using it is to look at the nginx logs and see what routes are being requested. Even those are removed after some time.
To be more specific, in Nix binaries (or other output) is cached based on a hash of the _inputs_. So given the same source files and the same build instructions, the hash will be the same so it can be cached. The hash of the _output_ is not used precisely because (especially when Nix was created) reproducible builds were nearly impossible.
With overloading, you have to look up the arguments of the function every time you want to call it. And it'll call the *wrong* function when you use the wrong number of arguments. And *every* function call you make could resolve to any number of functions, so you have to look in the docs constantly to ensure they all do what you think they do. And wouldn't it be so wonderful if only a few versions of the function had bugs? Let's audit our code and see if we hit it. My point is, function overloading is break-even at best. The only thing it helps is that you no longer have to think up function names, which isn't even really an obstacle in the first place.
Pyrite, my GBA emulator, no longer compiles because it was written pre-1.0 so I've started rewritting it while using a few things from the original. At the moment I've got a GUI going using my own bindings for Dear ImGUI. I also wrote an assembler for ARMv4T which allows me to test instructions like [this](https://gitlab.com/ExPixel/pyrite-gba/blob/master/src/gba/cpu/test.rs) instead of having to compile a test case separately and copying the generated ARM code into an array by hand. 
After the 2018 edition landed, I vowed to be content with the features available on stable and patiently wait for new and shiny things to stabilize. I'm seriously reconsidering that vow right now.
Awesome news.
Got some free time again and spent it working on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis ) over the weekend. Finished a long-open PR to implement formatting traits. I'm planning on pushing the update to [crates.io](https://crates.io/crates/uom) today.
I'm sort of surprised Rust didn't inherently do that already. I thought that was an important goal for the "newer" binary output languages (Rust, Go, etc?). 
I'm just starting a x680 (asn1) parser. Currently all the code is on my home computer. But I hope to have the lexer and start of the parser on GitHub by the end of the week. https://github.com/mehmooda/x680 It wired what sort of rabbit hole you go down. I can't even remember what I was doing that required a asn1 parser. But there you go.
I am new to qt, but based on what I have seen online qt quick is what qt seems to be focusing on as there main interface, especially with qt quick controls 2. Is qt quick really behind qt widgets? If so, is it by a large amount?
So I'm trying to get a better understanding of generics and sized/DST. This produces a compile error: trait Engine{} struct V8 {} impl Engine for V8{} struct Car { engine: Engine } fn main() { let c = Car { engine: V8{} }; } And this makes sense to me. The compiler can't possibly know what the size of Car will be, and you can't allocate memory of an unknown size on the stack. But then I change Car to this: struct Car&lt;E: Engine&gt; { engine: E } And now everything compiles fine. Why does this work? Is the compiler now seeing that Engine is a V8 which has a known size?
It's not always deemed important especially for whole program optimizing compilers (good luck getting Haskell to be reproducible without a shit ton of work) and it's also extraordinarily hard to maintain. You need extensive testing on a huge array of platforms and differing environments just to be "fairly sure"; couple that with rust's adoption speed and I'm more surprised they've made as much progress on this as they have. Major kudos to them :)
`std::mem::transmute` is magical (in addition to being super dangerous). It is generic over both its argument type and its return type, **but checks that they have the same size**. If they don’t (or if it can’t tell because they are not fully concrete) the compiler emits an error. The less well-known part is that **the magic happens even if you don’t call the function**, but only instantiate it with concrete type parameters (with a turbofish). This makes a static assertion. struct Foo(…); fn _static_assert_size_of() { let _ = std::mem::transmute::&lt;Foo; [u8; 56]&gt;; } The above is similar to `assert_eq!(std::mem::size_of::&lt;Foo&gt;(), 56)`, but at compile time.
I think I just fixed a bug and therefore finished the [subsurface scattering](https://en.wikipedia.org/wiki/Subsurface_scattering) code. I'm in the middle of re-rendering the test scene with 8192 `pixelsamples`, but a lower pixel sample value looks already promising (see [issue](https://github.com/wahn/rs_pbrt/issues/84)). The high res version will render a couple of hours, so once it's confirmed to **match the C++ code** I will not only close the issue, but cleanup and prepare/release a new [rs-pbrt](https://www.rs-pbrt.org/about) version. After that I might have some time to contemplate a bit about last years progress, and write a blog post about future plans for the renderer, where I could use some help, or where to focus research on ...
This function does not accept closures, to accept those you would need this: fn do_twice&lt;F: Fn(i32) -&gt; i32&gt;(f: F, arg: i32) -&gt; i32 { f(arg) + f(arg) } I'd say this is strictly better than having one that accepts trait objects - you can still call this one when you have a trait object, but this version will be monomorphised for each distinct function given to it, allowing inlining and thus generally giving better performance.
The reason build time is often not varied with rust is because cargo would fail to download if you increase your system time beyond the validity of the crates.io https certificate. The reason we can do that in debian is because we download all dependencies from debian mirrors instead.
The Criminally Awesome. I had NO idea that was possible.
If you say that a field has type `Engine` it means "value of some unknown type, and there is an implementation of `Engine` for that type". Now what if you wrote `impl Engine for [u8; 1000000] { ... }`? Do all values that have type `Engine` suddenly have to be a million bytes large just to allow this case? And what if you wrote `impl&lt;A, B&gt; Engine for (A, B) { ... }`? Now you can construct values of any size that implement `Engine`, so how much space would the compiler need to allocate for `Car`? When you write `struct Car&lt;E: Engine&gt; { engine: E }`, it's basically the same as `struct Car&lt;E&gt; { engine: E }`. And then the compiler knows exactly what type of the field is, because then you have values of type `Car&lt;V8&gt;` (which basically becomes `struct CarV8 { engine: V8 }` - a completely fine type), or `Car&lt;SomeOtherEngine&gt;` - but the point is that the compiler know the exact type, and thus knows how much space it takes up.
The 3rd and 4th entries in this, showing how to turn a collection of Result&lt;T, E&gt;'s into either a collection of T's and an error, or a partitioned tuple with the T's on the left, Errs on the right with one method call: [https://doc.rust-lang.org/rust-by-example/error/iter\_result.html](https://doc.rust-lang.org/rust-by-example/error/iter_result.html) For as common as mapping a fallible function over an iterator and then needing to collect the results in a usable form is, this particular behavior of \`collect\` is not very well advertised. &amp;#x200B; &amp;#x200B;
Thanks for the context, interesting!
You can have a macro, a function and a type (struct, enum, module or trait) that all have the same name, and import all three with a single use statement. Not useful in normal day usage, but super convenient when writing macros. Or using serde (being able to import the derive and the trait at the same time)
I don't know how much progress you've made, but please consider whether what you're working on could be adapted for [Encrusted](https://github.com/DeMille/encrusted). Pooling effort will probably result in a better interpreter quicker. 
All sorts of stuff: Working some on ggez! Writing up an overview post for ggez 0.5! Working on Super Secret Side Project (which I've already shown several people)! Looking for jobs! Petting cats! It's been a pretty good week, really.
To everyone who is snobbish, it's also sometimes called "Schönfinkeling" after https://en.wikipedia.org/wiki/Moses_Sch%C3%B6nfinkel#Work Has a much nicer ring to it.
`Iterator::collect()` is still my favorite. It can build any type that implements `FromIterator`. But there are some very cool implementations of that trait for `Result`: let results: Vec&lt;Result&lt;T, E&gt;&gt; = do_stuff(); let collected_results: Result&lt;Vec&lt;T&gt;, E&gt; = results.iter().collect(); Basically, if there are any `Err` results, `collect()` returns the first `Err`. Otherwise, it returns `Ok` containing a `Vec&lt;T&gt;` (or whatever other `FromIterator` type you care for). Basically, "Give me all the successful results, OR the first error." Using `collect()` on an iterator of `Option` works similarly, it gives you either `None` if the iterator returns only `None`, or `Some(stuff)` if it doesn't.
Me too, but it's hard to do without garbage collection. Every time you call a curried function it has to possibly create a closure environment for the `b -&gt; c` part, which means it needs to decide where to deallocate it as well, and that's very hard to figure out well unless you can just let the GC handle it.
Thanks! I had the same thought, which eventually led towards the idea of continuation-passing style. In your implementation, (how) do you ensure that the needed input has indeed been provided before the VM is asked to continue? 
If you can't solve a trivial problem on your own, I don't see what problems you'd have using a third party library anyway.
Well that's both true and not so true, in GCed language you can be care free of handling memory but in Rust even without the GC you can sure of cleaning as after owner dies so does the owned data. Probably a pro of having affine typing. Functional languages are sort of similar in this respect.
I've got one: using a few interesting details about how `const` items work, you can make it look like the `=` operator is overloadable. &amp;#x200B; [Playground demo.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=bef701dfa58bb7718c14a58098d57430) &amp;#x200B; In particular, this works because: \- While you can't assign to a \`const\` item, you *can* assign to their fields. \- Assigning to a field in a \`const\` item creates a temporary copy of it which is dropped immediately. \- You can have \`const\` items for types which have a \`Drop\` impl. 
Seems interesting...
Well collect() really is super cool.
Thanks, I hadn't heard of Encrusted before! It looks pretty cool, well ahead of mine in terms of functionality, although I'm not hugely fond of [2500-line source files](https://github.com/DeMille/encrusted/blob/master/src/rust/zmachine.rs). My own goal is mostly to learn, so I'm OK with reinventing a wheel or two.
Also sometimes confusing, if you have an `Option&lt;Vec&lt;...&gt;&gt;` and forget to unwrap it before using it in a `for` loop :)
I love `tokei`. It and `ripgrep` are basically the poster children of "yes, we shouldn't usually re-invent the wheel... but with modern tools we can make *really good* wheels." Both are super specific tools that don't *seem* really important, until you use them twice and then find yourself reaching for them ever after, and being annoyed when they're not just there by default.
Will kernel modules be written in Rust?
I don't ensure it in the type system, if that's what you mean. If the caller doesn't fill the input buffer, the execution will get suspended once again.
This is my favorite blog series. I'm stoked to read this next post.
Here’s another less-well known (although quite obvious) trick, in those rare cases when you want to transmute `A` to `B` and you can’t prove to the compiler they are of the same size, `mem::transmute` is no longer sufficient... the answer is — do it yourself! Kind of like so: ``` unsafe fn vile_transmute&lt;B&gt;(a: A) -&gt; B { let b = ptr::read(&amp;a as *const _ as *const _); mem::forget(a); b } ``` ([example](https://github.com/aldanor/hdf5-rs/commit/9103597ee712825a577cfaf11868d73db8295b7c))
Thanks so much! I hope you like it :)
But it’s great together with `chain` :)
What other sources do you recommend for learning OS Dev (a practical approach if may) apart from your series ?
Command line app to control my bluetooth LED bulbs. Reverse engineered the protocol the app used and now I am sending commands to it using Rust. C/C++ would have been an option but Rust feels way safer when pushing bits and bytes around. Hooked it up to snips.ai et voila, offline voice controlled smart lights.
I've started working on a replacement for locate / mlocate / updatedb which I've decided to name Lolcate. As my first serious project in Rust, the overall experience has been great so far. The main crates I'm using are all from /u/burntsushi : regex, ignore, and walkdir. It's still unreleased because I wish to take advantage of iterators first, but on the other hand I'd be delighted if someone would be willing to mentor me or even participate.
The [OSDev Wiki](https://wiki.osdev.org/Main_Page) is probably a good resource.
Also a REST microservice which runs git commands. Basically a backend service for a GitLab-like setup. That way I can write a frontend to communicate with it and replace my gitea instance one day.
I'm working on porting a git extension I wrote in Bash (with a little Python for JSON parsing) to Rust. I was stalled on this for a while since I hit a roadblock with `git2` with the repositories that used user/pass auth, but I was able to get around it by using `duct` to shell out and proxy the auth prompt. Now it's a matter of cleaning up my code, colorizing the output, and setting up a CI build + release process! Does anyone have a favorite terminal prompt library? Preferably one that allows users to use their arrow keys to select options.
&gt; I am new to qt, but based on what I have seen online qt quick is what qt seems to be focusing on as there main interface, especially with qt quick controls 2. QWidget is considered mature and, as such, not in need of as much development. Nonetheless, they are still working on it. I don't think their 2019 roadmap is out yet, but here's an excerpt from the 2018 roadmap they posted in February: &gt; So, quite many new things for Qt Quick users, but not to worry – we have not forgotten users of Qt Widgets. On the contrary, already during the past year we have been increasingly addressing open bugs of Qt Widgets and intend to continue doing so during 2018 and beyond. Both Widgets and Qt Quick have their strong points and they complement each other nicely as fully supported parts of the Qt offering. They're focusing on Qt Quick for two main reasons: 1. Qt Quick can be rendered using a scene graph on the GPU (same as GTK+ 4.x intends) while QWidget is stuck with CPU rendering like GTK+ 3.x and below, so it *is* eventually going to be the future of Qt widgets in some way or other. 2. More importantly for them, Qt Quick is much better suited for embedded UIs, like in-vehicle entertainment consoles. As I understand it, embedded and, to a lesser extent, mobile are the most important slice of their paying customer base these days. Qt Quick is behind QWidget in three main ways: 1. I'm having trouble tracking down the listing I remember, but Qt Quick *is* still catching up to QWidget on available selection of widgets. For example, TableView was only added to Qt Quick in Qt 5.12. I think I remember editable combo-boxes also being added around the same time. 2. Doesn't exactly feel native on desktops. (It's got a very flat, minimalist [Default](https://doc.qt.io/qt-5/qtquickcontrols2-default.html) theme, a [Material](https://doc.qt.io/qt-5/qtquickcontrols2-material.html) to fit in on Android devices, a [Universal](https://doc.qt.io/qt-5/qtquickcontrols2-universal.html) theme to fit in with UWP apps, an [Imagine](https://doc.qt.io/qt-5/qtquickcontrols2-imagine.html) theme to let people with web-app theming experience easily build a custom look using image files, and a [Fusion](https://doc.qt.io/qt-5/qtquickcontrols2-fusion.html) theme which sort of resembles GTK+'s Clearlooks and QWidget's Plastique, but doesn't really match either one. 3. Regarding using Qt Quick without pulling in the QML runtime, last I checked, their stance was "We want to eventually support C++ use of Qt Quick, but we don't yet consider it API-stable enough to feel comfortable setting a C++ interface in stone." As such, you *must* access it through the runtime for their QML dialect of ECMAScript. (ECMAScript being the standard of which JavaScript, ActionScript, and QML are all dialects.)
This `read` might need to be `read_unaligned`. This is what `std::mem::transmute_copy` does. (Or you could use that.)
It's a bit dated but there's also the BrokenThorn osdev series: http://www.brokenthorn.com/Resources/OSDevIndex.html
This is not really assigning to the const item’s field, right? To the field of a temporary anonymous local variable that is initialized with the value of the const.
Thanks for the information. Very useful.
Couldn't agree more. Rust is the first language I've learned in *all* the high-level languages I've tried that has really made me stop and think in a new way about what my code is doing at a deep level. I have done some basic reverse engineering and done dll injection with C++, but rust feels even heavier than that...It feels like I know what every single line is doing with the memory at all times, because I have to. It's such an exciting feeling learning it...I feel like I'm back in the good old days when learning some crazy shit in c++ was neat, but this is even closer to the metal while being safer and easier to understand once you actually struggle through some rough patches. Such a great language. Really excited to see where it is in 3 years from now, but it's complete enough to get so much done with right now that it seems like the perfect time to learn it.
Ah, yes indeed - thanks for noting!
&gt; I'd say this is strictly better than having one that accepts trait objects I wouldn't say it is strictly better, because it will increase code size compared to trait objects, which has negative effects on compilation time and binary size.
It can probably run OpenCL in some capacity, but considering it's an old TeraScale card, it's probably not going to perform well at all.
What are you using for indexing and search? [Tantivy](https://github.com/tantivy-search/tantivy)?
Should there be a clippy lint for this?
https://teachyourselfcs.com/#operating-systems
https://teachyourselfcs.com/#operating-systems
Currently I'm just using a lz4-compressed file. The idea being that reindexing everything is fast enough. It works fine in practice, but I'd be glad to explore alternatives.
Thanks for sharing!
I believe it's currently only useful in match arms, but seems to be on track for stabilization in if/while patterns ([tracked as feature `if_while_or_patterns`](https://doc.rust-lang.org/unstable-book/language-features/if-while-or-patterns.html).)
Haha, its half Tera flops but when I was in college a decade back that was considered great! I remember being in awe of PS3!
You need to clone `state` before it gets moved into the closure, not after. So instead of this: ``` let future = stream::iter_ok(cmds).for_each(move |i| { let state = Arc::clone(&amp;state); // ... }); ``` Try this: ``` let future = stream::iter_ok(cmds).for_each({ let state = Arc::clone(&amp;state); move |i| { // ... } }); ```
You can also do \`(a,b) -&gt; c\` which looks like and is called like functions in more traditional languages. Yes, it can also be thought of as a function which takes a tuple as an argument, but that's not unfamiliar to Python or Javascript programmers.
The book OSTEP, which is free, to learn about OS's would be a great supplement.
Is there a Rust issue on implementing ABCD in MIR? Seems like a good opportunity for a MIR pass.
I am not sure about this, but I think having a `Mutex` in a future is a antipattern because it could stop the entire "event" loop if the `Mutex` is locked from another place. Have you considered using [`collect`](https://docs.rs/futures/0.1.23/futures/stream/trait.Stream.html#method.collect)?
Well, step one would be to get some ancient OS running - the only OpenCL driver for that card has been discontinued for a while now, and the last time I checked, it required kernel 4.9 and an older X11 version. 
Can confirm. Am beginner, am confused.
why don't you use and_then on the stream and then .collect instead of spawning a new future and collecting results by yourself like stream::iter_ok(cmds).and_then(|cmd| Command::new("bash").arg("-c") .arg(i) .output_async() .timeout(Duration::from_secs(3)) .map_err(|e| println!("failed to collect output: {}", e)) ).collect() this future yields a vector containing the result of all commands. The future is aborted if one fails though, so you would have to drop errors before collection if that's not what ypu want.
If he doesn't post an example anytime soon I will do it myself don't worry.
https://learnxinyminutes.com/
Sice risc-v is an official target now everything should be in the main rust repo. You should be able to install risc-v with rustup target add ... . And compile it with cargo build --release --target ... .
I suggested something similar. However in retrospect I think this will actually run the commands in sequence because collect will poll the first future in the stream until completion before polling the next? (I am not sure about this but it seems to work that way)
You can look at [https://github.com/rust-embedded/wg#the-riscv-team](https://github.com/rust-embedded/wg#the-riscv-team) for interesting links about RISC-V with Rust.
That's interesting and not something I knew was possible. I suppose if I want to write obfuscated Rust it could be handy... &gt; Assigning to a field in a const item creates a temporary copy of it which is dropped immediately. What exactly is the motivation for the compiler doing this? It seems very unintuitive. I would have asssumed this just errors.
If Linux, then C, else if Redox, then Rust. Any software you write which interacts with that kernel module will be written in Rust, even if the module itself may not. You still may have to write C if this software is a patch for GNOME Control Center.
Thanks
Hum, true. You could probably use `map` and `buffered` or `buffered_unordered` instead of `then` if you want to run the futures in parallel
Even without generics, changing your code to use the `impl Trait` syntax would be a win because it would save you the allocation.
awesome, thanks :D
thanks! 
TIL about [`buffered_unordered`](https://docs.rs/crate/futures/0.1.25/source/src/stream/buffer_unordered.rs), which is probably what he wants, as the proposed solution does not "care" about the order of the futures added to the `Vec`.
You don't need to box your multiply anymore: fn multiply(a : i32) -&gt; impl Fn(i32) -&gt; i32 { move |b| b * a }
It's UB to modify a `const` value: const std::string X; // const_cast&lt;std::string&amp;&gt; is UB. std::string Y; // const_cast&lt;std::string&amp;&gt;(const_cast&lt;const std::string&amp;&gt;(Y)) is fine. Which is exactly why it's better to implement the mutable version by re-using the `const` version (and not vice-versa as suggested by ravixp): - The `const` version does not accidentally modify the object, since it's `const`. - The non-`const` version can only be invoked on a non-`const` object, and therefore the reference it returns can be safely `const_cast`.
This is similar to how traverse and sequence work in haskell. The haskell version is much more generic due to HKT, but when I found out Rust could do it at least for Result it brought a smile. ``` traverse :: (Applicative f, Traversable t) =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) ``` Note the inversion of f and t, in this case those represent Result (f) and Vec (t)
Mind elaborating a use case where you've used IntoIter on an Option
Also, I don't think you need `#![cfg_attr]`. `#![deny(clippy::all)]` should be enough.
I have already figured that out... There are about 3 post about that already here 🤣😁 Seems like I need to use Rust more frequently.
Excellent blog, really looking forward to this next part!
I'm probably going to continue work with [tarpaulin](https://github.com/xd009642/tarpaulin), last week or the week before released a new version with improved logging and html reports. This week debug some issues maybe refine the logging some more.
Perhaps I didn't select the best example of the kind of long function names you can get if you don't have overloading. Here, I found another one: [`add_event_listener_with_callback_and_add_event_listener_options_and_wants_untrusted`](https://rustwasm.github.io/wasm-bindgen/api/web_sys/struct.AudioNode.html#method.add_event_listener_with_callback_and_add_event_listener_options_and_wants_untrusted). It's ridiculous.
Not really a 'trick' per say but I use a lot of generic conversion traits on methods to be polymorphic over string types. ex. ``` fn foo&lt;S: AsRef&lt;str&gt;&gt;(s: S) // instead of &amp;str fn foo&lt;S: Into&lt;String&gt;&gt;(s: S) // instead of String fn foo&lt;S: Into&lt;Cow&lt;'a, str&gt;&gt;&gt;(s: S) // instead of Cow&lt;'a, str&gt; ``` The way conversion traits work in Rust is very well designed IMO.
Depends, what crates does your server have preinstalled? Also I hope that the code is formatted somewhat readable
/r/playrust `!=` /r/rust
And how would arity-overloading fix that function?
My bad, I reflexively wrote it without checking.
Be aware that this will not pre-allocate the correct size for the vector in `collected_results` today ([#48994](https://github.com/rust-lang/rust/issues/48994)).
I'm really looking forward to going over these when I get the time. They look excellent, many thanks for all the work you put in!
😂 Thankyou 
&gt; *Full series last reviewed: Sept 12, 2008* For an OS resource, that seems fairly recent. I see some updates actually date to 2010. That is, considering how long Unix has been around... &amp;#x200B;
Interesting, Typescript as a target. Is it for one off generation of code that is later edited? Or is there an upside to generating typescript over JavaScript?
I tend to use it in conjunction with `flat_map` in order to convert an iterator of `Option&lt;T&gt;` to an iterator of `T`
I think there's a clippy lint against that.
From Error like this pub enum MyOwnError {...}; impl From&lt;IOError&gt; for MyOwnError { fn from(err: IOError) -&gt; MyOwnError { MyOwnError::IOError(err) } } is really clean for handling errors there is also mem::replace which is great to know in some situations.
This is very interesting. I have some knowledge about virtual memory and paging but aparently that was outdated or incomplete.
I often find myself wanting to slice "the first `n` elements starting from index `i`". Rather than repeating the starting point by writing &amp;some_list[i..i+n] I like to write &amp;some_list[i..][..n] It makes a bigger difference when the endpoints are more complicated than single letter variables.
For my first Rust project, implementing something new rather than just typing in and playing with the examples out of the book, I have chosen to implement [Brzozowski's Algorithm for Rust Regular Expressions](https://github.com/elfsternberg/barre), along with several significant additions: parse tree generation by epsilon, Might's parse tree catamorphisms by combinator, Darais's smart constructors for recognition performance, Darais's DFA lattice for production performance, extended regular expressions (intersection, interleaf, and negation operators), alphabet/language independence via generics, recursive regular expression via ambiguity (again, Darais's invention), and alternation disambiguation as a function via Fischer's semiring algorithms. Recursive regular expressions lift regular expressions to be capable of handling context-free grammars. CFG expressions with alternation disambiguation, intersection and negation operators implement PEG semantics. Other disambiguations can exactly support POSIX, PCRE, or BSD semantics for alternation without changing the core algorithm. Since regular expressions are membership determinants ("Is this string a member of the set of strings recognized by this expression?"), regular expressions exactly map 1:1 with type determination; with an iterator producing chars at the front, BARRE can produce a parse tree for a programming language; with an iterator producing parse sequences at the front, BARRE can be used to determine if a code sequence's type(s) are members of the expected type for that sequence. If your alphabet/language is "symbols in a programming language," (yaccing instead of lexing) the interleaf operator allows you to define syntax that can be presented in any order. If you're wondering "Who wants that?" consider that parsing HTML tags requires you accept the attributes in any order. BARRE is a solution to the "Can you parse HTML with regular expressions?" conundrum that replies "YES!" (Am I cheating? No; underneath the covers, BARRE crafts NFAs that exactly map to a regular language.) At least, that's the ambition. Right now it only produces epsilon parse trees, and not very descriptive ones, but it does have all of Darais's improvements (it even does recursive regular expressions!), and type independence means it works with either `char` or `u8`. Performance is about 85% of Rust Regex (and RE2) in NFA mode, but its theoretical capabilities are much broader. It uses a (currently home-built, ugh!) TypedArena with no block re-use, so its memory profile utterly *sucks*, but I intend to build a two-pass exact-roots garbage collector to make abandoned blocks re-usable. I've been stalled for two weeks while I cram Haskell into my brain, since there are almost no implementations of Brzozowski's algorithm outside the ivory tower, and reading Haskell has become imperative to my understanding some of the algorithms.
What's the benefit of reproducible builds? Caching is the only thing I can think of.
I have written a turtle-rdf parser (Which is a the recommmended way to send rdf documents.) [available on GitHub](https://github.com/Aaronepower/chelone). It doesn’t fully pass the standard test suite, but does pass over 90% of them.
I will create a handful of code generation tools for the business based on the ast I am working on currently. Typescript because it has types. I can't stand these things ```js function fetchStuff(stuff) {} ``` Go figure what if takes as `stuff` and what it returns. Besides it will be so easy to just implement interfaces that were previously generated by your tool :)
Oh, nice, I've needed this.
Please, please, *please* make it a library with a `C` interface! For several small projects, nothing has frustrated me more than having to *shell out* to locate because there's no library version of it and no other way to expose it to scripting languages.
I believe the goal is to be able to build packages locally and verify that the distributed packages are identical and thus not maliciously altered.
You can split logic by having multiple impl blocks. Built in pretty printer: {:#?}
Let me ask you then, why is the kind of overloading that happens when you use the + operator (or others) ok, while overloading with regular functions isn't? I also don't know which `fn add` gets called when I write `a + b`. It doesn't even depend on the number of arguments, only the types. Why is operator overloading ok but function overloading not ok?
Couldn't you just use equality constraints in your Cargo.toml? Something like: ``` [dependencies] time = "=0.1.12" ```
&gt; ary with a C interface! For several small projects Could you please elaborate on how it should ideally look like to you, and what you'd be using it for ?
I don't think pathfinder *has* any CPU-side rendering code, just logic to generate suitable data for you to render in whatever way you want, provided you can get the shaders working.
Tanenbaums operating system are also worth reading .
The CSS on this sub is terrible on mobile 
My vote goes to the usage of `Option::map`.
Same here but on my laptop... Probably it's the GTK theme messing with me.
Because operators are not *supposed* to be overloaded unless they do exactly what you already expect. And that's only a concession to mathematical elegance. You don't need operators at all if you ave functions, but we use them because they make mathematical expressions easy to write. Now, you could claim that your domain has just as much right to overloading as mathematics, but down that road lies C++'s brand of feature + macro soup where you can make almost any syntax invoke any code, which is not a place that a language for inter-human communication wants to be.
You might want to check out \`filter\_map\` &amp;#x200B;
Basically a conditional version of iter::once to prepend an element without needing different types which you can’t return from and impl Iterator function. 
Updated the readme. Let me know if that makes more sense. 
Do you have repeated bits in your code that you'd love to extract to a function but the number of arguments you'd have to pass to it would be prohibitively unwieldy? Define a closure instead and just capture the common arguments: Before something_a(&amp;mut foo, &amp;bar, &amp;baz); some_count += 1; something_b(&amp;mut bar, &amp;baz, &amp;some_count); // bunch of other stuff something_a(&amp;mut foo, &amp;bar, &amp;baz); some_count += 1; something_b(&amp;mut bar, &amp;baz, &amp;some_count); After let mut do_stuff = || { something_a(&amp;mut foo, &amp;bar, &amp;baz); some_count += 1; something_b(&amp;mut bar, &amp;baz, &amp;some_count); }; do_stuff(); // bunch of other stuff do_stuff(); However, this pattern doesn't always work out because maybe `// bunch of other stuff` needs mutable access to some of the captures. Well, did you know `macro_rules!` can be declared inside functions, and it can reference locals in the function? And because it's not a closure it doesn't capture anything so you can use that stuff in between invocations! Before something_a(&amp;mut foo, &amp;bar, &amp;baz); some_count += 1; something_b(&amp;mut bar, &amp;baz, &amp;some_count); // bunch of other stuff something_c(&amp;mut baz); // bunch of other stuff something_a(&amp;mut foo, &amp;bar, &amp;baz); some_count += 1; something_b(&amp;mut bar, &amp;baz, &amp;some_count); After macro_rules! do_stuff ( () =&gt; { something_a(&amp;mut foo, &amp;bar, &amp;baz); some_count += 1; something_b(&amp;mut bar, &amp;baz, &amp;some_count); } ); do_stuff!(); // bunch of other stuff something_c(&amp;mut baz); // bunch of other stuff do_stuff!(); (In this case it hasn't made the code any shorter but it has reduced repetition which is really nice when `do_stuff!()` involves a lot of steps.) That really came in handy in this bit of code, where I generate demo gifs for my `img_hash` library (in this case, I wanted to get something working quickly, so it's not exactly full of best practices): https://github.com/abonander/img_hash/blob/3-alpha/src/bin/demo_dct_hash.rs#L287-L328 I originally tried to implement `animate!()` as a closure but wanted to pass `inflights` as an argument since it needs to be mutated in-between invocations; however, the compiler couldn't infer the type of the argument and wanted it to be explicit, but that would have been unwieldy (and maybe not possible) since the type was something like `&amp;mut VecDeque&lt;(impl Iterator&lt;Item = (u32, u32)&gt;, (u32, u32)&gt;)&gt;`. Rewriting the closure as a macro meant that I could just reference the locals directly and not have to worry about borrowing issues. Also, since macros can affect control flow, it makes it really nice for implementing state machines with fallible transitions, like here: https://github.com/abonander/multipart-async/blob/master/src/server/boundary.rs#L54-L131 Since the `State` enum carries non-copyable state that needs to be taken by-value, I replace it with a sentinel during the state transitions and then the macro resets the state if it can't proceed.
What is the difference between `futures-rs` and `tokio`?
Oh man, how did I not know about cargo-expand yet. This would have saved me so much time... I created a PR to add it to awesome-rust: https://github.com/rust-unofficial/awesome-rust
No, that is not possible, because if you have two crates like this `time = "=0.1.12"` and `time = "0.1"` somewhere in your dependencies, cargo will simply fail to build (instead of merging the two crates or compiling both or being a bit smarter about it). I don't understand why that is the case either, but that's the way it is. It usually ends with a "failed to select version" error. While you can use "=" temporarily, you can't do it as a library author, or as a long-term solution, because it might break the build of your users.
Does it end up generating different code?
Will all rust binaries need to contain all their crate dependencies, or will it be possible to have some crates as shared libs?
Amazing. I will definitely check that out as soon as I jump off that "work train" which seems not to have breaks :) Give my a few days please.
The output looks *nearly* identical, runtime differences are probably negligible: https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=5aa0bc624bbc815c77923839ae58c53b playground::first_form: # @playground::first_form # %bb.0: subq $24, %rsp movq $5, 8(%rsp) leaq 8(%rsp), %r8 #APP #NO_APP movq 8(%rsp), %rax movq $10, 8(%rsp) #APP #NO_APP movq 8(%rsp), %rdx movq %rdx, %rcx addq %rax, %rcx jb .LBB4_3 # %bb.1: cmpq %rsi, %rcx ja .LBB4_4 # %bb.2: addq %rax, %rdi movq %rdi, 8(%rsp) movq %rdx, 16(%rsp) #APP #NO_APP addq $24, %rsp retq .LBB4_3: movq %rax, %rdi movq %rcx, %rsi callq *core::slice::slice_index_order_fail@GOTPCREL(%rip) ud2 .LBB4_4: movq %rcx, %rdi callq *core::slice::slice_index_len_fail@GOTPCREL(%rip) ud2 # -- End function playground::second_form: # @playground::second_form # %bb.0: subq $24, %rsp movq $5, 8(%rsp) leaq 8(%rsp), %rdx #APP #NO_APP movq 8(%rsp), %rax movq $10, 8(%rsp) #APP #NO_APP cmpq %rsi, %rax ja .LBB5_3 # %bb.1: movq 8(%rsp), %rcx subq %rax, %rsi cmpq %rcx, %rsi jb .LBB5_4 # %bb.2: addq %rax, %rdi movq %rdi, 8(%rsp) movq %rcx, 16(%rsp) #APP #NO_APP addq $24, %rsp retq .LBB5_3: movq %rax, %rdi callq *core::slice::slice_index_order_fail@GOTPCREL(%rip) ud2 .LBB5_4: movq %rcx, %rdi callq *core::slice::slice_index_len_fail@GOTPCREL(%rip) ud2 # -- End function
This post should be more admired. Definitely amazing. What an effort. Thank you. I will check out the code asap. Feel free to update it over time.
It's non-breaking now only because you can't have `const` implementations yet. This is still a nonbreaking change for non-`const` implementations, even with this proposal. If you want to provide a nonbreaking default, you'll have to define a `default const fn` instead.
&gt;But I have to ask- is there any point in time where I'd lose functionality by adding in ?const? As far as I'm aware, no: it just gives you more restricted access to the trait (in terms of only being able to use items declared `const` in the trait itself). There aren't any less obvious drawbacks.
Yes, `do_thing` would impose the same restrictions on associated type bounds as type parameter bounds. If you want `T::Inner: Default`, you'd use `T: ?const Outer`.
Yeeeeeessssss it continues!! 
Still waiting for the day that the compiler inserts this automatically (or maybe a proc macro could do it).
&gt; (should be available in stable 1.32 in a few weeks from now) Closer, 1.32 should be released this Thursday!
Why? How would the compiler know your error type subsumes some other one unless you told it to?
There's no inheritance here. This is just what happens when you try to abstract over multiple large systems at the same time. Would end up being a problem in any language. (Rust just makes it a compile time problem rather than a runtime problem.)
The lack of a remote option makes this a no go for me. Is there something about the job that makes it on-site required?
FWIW I got the continuation style to work too, with something along the lines of: pub enum Continuation&lt;'a&gt; { Print(String, Box&lt;'a + FnOnce() -&gt; Continuation&lt;'a&gt;&gt;), Read(Box&lt;'a + FnOnce(&amp;str) -&gt; Continuation&lt;'a&gt;&gt;), Quit, } To actually call a `Box&lt;FnOnce&lt;...&gt;&gt;` turns out to be nontrivial; you need nightly and `#![feature(unsized_locals)]`. Or some stuff with unstable `FnBox` or the `boxfnonce` crate.
It doesn't need to be that complicated: use diesel::{ RunQueryDsl, query_dsl::LoadQuery, PgConnection, Insertable, query_builder::InsertStatement, }; pub fn create_row&lt;Model, NewModel, Table, Values&gt;( model_to_insert: NewModel, table: Table, connection: &amp;PgConnection, ) -&gt; Model where NewModel: Insertable&lt;Table, Values=Values&gt;, InsertStatement&lt;Table, Values&gt;: LoadQuery&lt;PgConnection, Model&gt;, { model_to_insert.insert_into(table) .get_result::&lt;Model&gt;(connection) .expect("Oops!") } It looks like /u/HenryZimmerman was following the compiler error messages and adding whatever trait was missing. But most of the messages were saying "the trait X is not implemented for Y... required because of the requirements on the impl of `LoadQuery&lt;_, Model&gt; for Y". If you add `LoadQuery` directly, it's much simpler.
Though most use sites will probably want to use [`static_assertions::assert_eq_size!`](https://docs.rs/static_assertions/0.3.1/static_assertions/macro.assert_eq_size.html) instead of `transmute` directly, as it better captures intent.
Also `parse()`!
For the record, I find those types of compiler error messages to be very confusing: error[E0277]: the trait bound `Model: diesel::deserialize::Queryable&lt;_, _&gt;` is not satisfied --&gt; src/main.rs:20:10 | 20 | .get_result::&lt;Model&gt;(connection) | ^^^^^^^^^^ the trait `diesel::deserialize::Queryable&lt;_, _&gt;` is not implemented for `Model` | = note: required because of the requirements on the impl of `diesel::query_dsl::load_dsl::LoadQuery&lt;_, Model&gt;` for `diesel::query_builder::insert_statement::InsertStatement&lt;Table, Values&gt;` The error message should be more direct about what the real problem is: that `LoadQuery` isn't implemented. I think there's an issue about this that's been open for years, but I don't know how to find it.
Well, if you have an enum like `enum MyError { IOError(IOError), FooError(FooError), BarError(BarError) }` that it pretty clear that `IOError` should be converted to `MyError::IOError` since it is the only enum variant that has that type as its only member. It would make writing error enums a lot easier and avoids having to implement `impl From&lt;XError&gt; for MyError` for every single variant. However, on second thought, the compiler inserting these might be too much magic. An explicit proc macro might be better.
I don't think `impl From&lt;XError&gt; for MyError` is difficult to write in the first place. A little tedious maybe, but copy &amp; paste was invented aeons ago and remains a simple and greate solution to that problem.
There is also [`web-view`](https://crates.io/crates/web-view), but it uses the Native WebView.
I know this may be controversial, but [`web-view`](https://crates.io/crates/web-view) is a lightweight alternative that utilizes the OS's built-in WebView on Mac/Win/Linux. You get the benefit of HTML/UI, with Rust as the backend.
Operating system designs don't evolve super fast, do they? I know compiler designs don't.
The former defines the Future trait and some plumbing to work with them. Tokio is the async io adapter for Futures.
I'm having some trouble understanding how the `&amp;` operator works in relation to declaring variables. Specifically in closures or `if let EnumVariant(&amp;thing) = enum_value { ... }` [Here](https://pastebin.com/WfKQtG14) (it will compile on play.rust-lang.org also) is a more concrete example. It is taken from my solution to advent of code day 14 (so if you started way late like I did and don't want spoilers... be warned). Specifically, on lines 23-24, I have `carts.iter().skip(i+1)` `.filter(|(&amp;p2, _)| p2 == new_point)` And on lines 30-31, I have `updates.iter()` `.filter(|(_, p2, _)| p2 == &amp;new_point)` If I change line 31 to `.filter(|(_, &amp;p2, _)| p2 == new_point)` it no longer compiles, and I don't understand what is different about this than the one on line 24. Similarly, on line 38, I have `if let Some(&amp;turn) = turns.get(&amp;new_point) {...}` Does this use of `&amp;` follow the same rules as in a closure? Finally, I'm assuming using `&amp;` this way simply dereferences the thing being passed in, creating a copy of it. In all of my examples above, the types involved are all `Copy`
I've been trying out the musl variant of void linux and I've been running into problems with compiling things that depend on the openssl-sys crate. The openssl crate does support libressl (which is used by void linux). Now as far as I see x86_64-unknown-linux-musl is only a Tier 2 platform so I guess it's expected for things not to work but i was just wondering if there is an easy fix for this or if this is just not supported. Thanks!
This is amazing that you can expand just a path-to. I've done a decent amount of work with macros recently that would've been made a lot easier if I could expand _just_ the part I cared about.
Is that really the easiest way to validate that packages are not altered? Ultimately, distribution of packages requires some sort of key infrastructure and package signing, right?
From a user facing perspective, yes. In the compiler, it does treat `a -&gt; b -&gt; c` as 1 function with 2 arguments.
You can try using `Box::pin(foo())` ([playground link](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=1c788ab2d70df742996fc2f3b0d081de); [docs link](https://doc.rust-lang.org/nightly/std/boxed/struct.Box.html#method.pin)). That will place the future on the heap. That will allow you to call `poll` on `future` without risking unsafe behavior.
PKI lets you to trust the distribution. Reproducible Build lets you to practice "trust, but verify" the distribution. (The latter doesn't exactly work now, but it is the goal.)
In my experience, it's not always pretty. Often I have a list of something and I'd rather put each element on its own line, but make each element print inline.
This is somewhat orthogonal and unrelated, sorry.
It _should_ work if you just do `Pin::new_unchecked(&amp;mut future).pool(lw)`. (Code is provided AS-IS with no warranty, implied or otherwise, including fitness for any task.) I don't know what I'm doing though so don't trust me at all, and I can't even test it since the playground doesn't have `futures_executor:0.2`.
We would like this person close to an Imperva/Prevoty office. However for the right person, fully remote could be an option. email me [nicholas.purdy@imperva.com](mailto:nicholas.purdy@imperva.com) for more information. 
Could you elaborate on the difference between trust and trust but verify? It seems like with PKI verification is the premise - you can verify that the package is from who it is said to be from. With a reproducible package, how would I even verify? Pulling source down and recompiling, then checking it matches the distributed source? I'm not trying to be picky or argue, just curious.
I guess that being a breaking change is what I'd object to. If this proposal is implemented, adding a non-const `default fn` will be a breaking change, whereas part of the whore motivation for adding `default fn` is not be able to transform traits without making breaking changes. This makes it kind of impossible to add new methods to existing non-consn traits. Like, what if I wanted to add `fn default_into(&amp;mut self)` to `std::default::Default`? I won't want to make it a `const default fn` because then people won't be able to write non-const implementations of it, and further it won't be able to call the non-`const` `default()` method. But if I don't make a `default fn`, then it breaks all `const` `Default` implementations. Unless I'm missing something, accepting this proposal will remove the ability for anyone to evolve possibly-const traits?
And you can do those `impl`s in private sub-modules. Very useful for types with large API surfaces like `Iterator` and `f32`.
I would be really interested in `cargo-expand` that does not expand the macros, as per: https://github.com/dtolnay/cargo-expand/issues/11#issuecomment-450088656 :)
LLVM does have IRCE "inductive range check elimination", which seemingly _hasn't_ been investigated for Rust: https://github.com/rust-lang/rust/issues/22987.
How do you envisage `default fn` interacting with `const` in a way that it's not a breaking change? This seems incompatible with `const` trait bounds (in any form) to me.
For what?
&gt;The library support for the cargo bench feature has been in the state “basically, the design is problematic, but we haven’t had anyone work through those issues yet” since 2015 I think there's been a lot of discussion on that, maybe just not on the rust-lang forum? Afaict [cargo bench will not be stabilized](https://github.com/rust-lang/rfcs/pull/2287#issuecomment-362431922), rather support would be through [custom test frameworks](https://github.com/rust-lang/rfcs/pull/2318). Which is how Criterion does it iirc. 
Thanks. This compiles but it's still blowing up at runtime: ``` failures: ---- cmd::expr::tests::hello_world_works stdout ---- Error: Driver(Io(Os { code: 32, kind: BrokenPipe, message: "Broken pipe" })) thread 'cmd::expr::tests::hello_world_works' panicked at 'assertion failed: `(left == right)` left: `1`, right: `0`: the test returned a termination value with a non-zero status code (1) which indicates a failure', src/libtest/lib.rs:332:5 note: Run with `RUST_BACKTRACE=1` environment variable to display a backtrace. ```
Wow, this is great! &amp;#x200B; You note that macro expansion is lossy, and can lead to invalid results. Is there any path forward to improve on the accuracy of it?
I got the impression IRCE is like minor version of ABCD which is appropriate for C or C++, but yes, this should be investigated.
&gt;LoadQ Thank you! But how did you found that the missing 'root' trait was `LoadQuery` ? You deduced it from the error message where it doesn't appear ?
You can do pattern matching on function: fn f((a, b): (u32, &amp;str)) { println!("{}: {}", a, b); } fn main() { f((1, "abc")); } Of course the pattern has to be exhaustive, but it can be useful if you're only interested in a few members of an argument: struct S { a: u32, b: i64, c: Option&lt;String&gt; } fn s(S{c, ..}: &amp;S) { println!("{:?}", c); } fn main() { let val = S { a: 1, b: 2, c: None }; s(&amp;val); } You can even match with enums if (for some reason) they only have one variant: enum E { Variant(u32) } use self::E::Variant; fn e(Variant(x): E) { println!("{}", x); } fn main() { e(Variant(20)) }
Do you have a link to your full code? That error seems to suggest an issue with a pipe, but your post doesn't indicate any use of pipes or the like.
&gt; With a reproducible package, how would I even verify? Pulling source down and recompiling, then checking it matches the distributed source? I think you meant "distributed binary", but yes. This doesn't exactly work now but etc etc.
I see the osdev wiki recommended a lot, but it honestly is extremely subpar. It’s good to get an overview of how some features work, but the technical information is generally lacking, and sometimes extremely misleading if not inaccurate... My biggest recommendation is for people to get the technical details from the appropriate official documentation (for intel, that would be the Programmer’s Guide). It can be a bit daunting, but they aren’t that hard to navigate once you get used to them, and will reveal a whole world of small but important details that are generally missed from online tutorials.
Debian is the most impressive project for its ability to mobilize vast time and expertise once policy and goal is set. I think the most important event was in 2017 that Debian Policy decreed "Packages should be reproducible". It will happen for Haskell, it's just a matter of time :) Wait and see. Debian Project has &gt;1000 people. It's the force to be reckoned with.
Returns the char value for a 'a' as u8 probably works also 
When using a string or char literal, you can prefix them with a \`b\` to specify that you want the byte or byte array representation of them instead of a Unicode character or UTF-8 string slice. In this case, \`b'a'\` is the same as \`97u8\` - it's the character \`a\`'s byte value. You can manually look these up somewhere like here: [http://www.asciitable.com/](http://www.asciitable.com/). In this case, it's used to cycle through the characters by manipulating the bytes directly and interpreting them as ASCI/UTF-8 :)
b'a' evaluates to the numeric value of the character a for the character encoding being used (which if I recall correctly Rust uses UTF-16 for its character encoding). This makes b'a' evaluate to 61 (once again pretty sure, someone correct me if I get the actual value here wrong). So that line of code converts the letter a to its numeric value and then adds value of index cast to an 8-bit number. It then casts the result of the addition back to a character. This is a handy trick for generating a sequence of characters which are adjacent in a character encodings value table. Feel free to ask for elaboration or if anyone here has a critique on my explanation, I welcome that as well.
The [derive_more](https://crates.io/crates/derive_more) crate has a proc macro for that. It can also do `Display`.
I'm hoping for union types (incl anonymous) to ever get us here. (Without further magic) Note though that I mean union types, not sum types, and not the C-idea of union. I.E. `fn foo() -&gt; (io:: Error | domain::Error)`. Would improve error-handling quite a bit. Not holding my breath though, it seems to be a lot of decisions left to resolve.
Mind explaining what expand actually does?
Is there some hidden way to enable proc macros on a binary? I'd like to use custom derives to clean up my code, but am not seeing a way to do so.
Yeah, my mistake. Alright, thanks.